<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 05 Sep 2024 18:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[AlphaProteo generates novel proteins for biology and health research (131 pts)]]></title>
            <link>https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/</link>
            <guid>41457331</guid>
            <pubDate>Thu, 05 Sep 2024 15:05:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/">https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/</a>, See on <a href="https://news.ycombinator.com/item?id=41457331">Hacker News</a></p>
Couldn't get https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Hacker League – Open-Source Rocket League on Linux (148 pts)]]></title>
            <link>https://github.com/moritztng/hacker-league</link>
            <guid>41456411</guid>
            <pubDate>Thu, 05 Sep 2024 13:24:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/moritztng/hacker-league">https://github.com/moritztng/hacker-league</a>, See on <a href="https://news.ycombinator.com/item?id=41456411">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><details open="">
  <summary>
    
    <span aria-label="Video description hacker-league.mp4">hacker-league.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/19519902/364779763-3a630d46-ec17-4da8-8879-76320ea563fe.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU1NTA1MDEsIm5iZiI6MTcyNTU1MDIwMSwicGF0aCI6Ii8xOTUxOTkwMi8zNjQ3Nzk3NjMtM2E2MzBkNDYtZWMxNy00ZGE4LTg4NzktNzYzMjBlYTU2M2ZlLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTA1VDE1MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNkMDg3MjdiZmFkMTZiODk4YTJiYzBkYzc4MTk4ZGNmOTJjZjYxMjY3NzI1MGMzOTFjNTg1Y2YxNWVkOWE1OWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.C7QQg92wm3q0awLIIoj6I8rQuGAJsOeWGMyqE9soFcQ" data-canonical-src="https://private-user-images.githubusercontent.com/19519902/364779763-3a630d46-ec17-4da8-8879-76320ea563fe.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU1NTA1MDEsIm5iZiI6MTcyNTU1MDIwMSwicGF0aCI6Ii8xOTUxOTkwMi8zNjQ3Nzk3NjMtM2E2MzBkNDYtZWMxNy00ZGE4LTg4NzktNzYzMjBlYTU2M2ZlLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTA1VDE1MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNkMDg3MjdiZmFkMTZiODk4YTJiYzBkYzc4MTk4ZGNmOTJjZjYxMjY3NzI1MGMzOTFjNTg1Y2YxNWVkOWE1OWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.C7QQg92wm3q0awLIIoj6I8rQuGAJsOeWGMyqE9soFcQ" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto">Currently only debian based distros with x86_64. Please help me build it on other platforms. If you have an external GPU, make sure the drivers are installed</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo apt install curl &amp;&amp; curl -sL https://raw.githubusercontent.com/moritztng/hacker-league/main/install.sh | bash"><pre>sudo apt install curl <span>&amp;&amp;</span> curl -sL https://raw.githubusercontent.com/moritztng/hacker-league/main/install.sh <span>|</span> bash</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Play</h2><a id="user-content-play" aria-label="Permalink: Play" href="#play"></a></p>
<p dir="auto">Use a gamepad for maximum fun</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd hacker-league
./hacker-league"><pre><span>cd</span> hacker-league
./hacker-league</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build from source</h2><a id="user-content-build-from-source" aria-label="Permalink: Build from source" href="#build-from-source"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/moritztng/hacker-league.git
cd hacker-league
sudo apt install libvulkan-dev vulkan-validationlayers-dev spirv-tools libglfw3-dev libglm-dev libeigen3-dev vim-common xxd g++ make
curl -L -o ./shaders/glslc https://github.com/moritztng/hacker-league/releases/download/glslc/glslc
chmod +x ./shaders/glslc
make debug
curl -L -o &quot;gamepad.txt&quot; https://raw.githubusercontent.com/mdqinc/SDL_GameControllerDB/master/gamecontrollerdb.txt"><pre>git clone https://github.com/moritztng/hacker-league.git
<span>cd</span> hacker-league
sudo apt install libvulkan-dev vulkan-validationlayers-dev spirv-tools libglfw3-dev libglm-dev libeigen3-dev vim-common xxd g++ make
curl -L -o ./shaders/glslc https://github.com/moritztng/hacker-league/releases/download/glslc/glslc
chmod +x ./shaders/glslc
make debug
curl -L -o <span><span>"</span>gamepad.txt<span>"</span></span> https://raw.githubusercontent.com/mdqinc/SDL_GameControllerDB/master/gamecontrollerdb.txt</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<ul dir="auto">
<li>Discord Server: <a href="https://discord.gg/BbNH27st" rel="nofollow">https://discord.gg/BbNH27st</a></li>
<li>I build in public on X: <a href="https://x.com/moritzthuening" rel="nofollow">https://x.com/moritzthuening</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Porting systemd to musl Libc-powered Linux (164 pts)]]></title>
            <link>https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-powered-linux/</link>
            <guid>41454779</guid>
            <pubDate>Thu, 05 Sep 2024 08:44:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-powered-linux/">https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-powered-linux/</a>, See on <a href="https://news.ycombinator.com/item?id=41454779">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-449">
	<!-- .entry-header -->

	
	
	<div>
		
<p>I have completed an <a href="https://code.atwilcox.tech/sphen/scaly/systemd/-/commits/adelie-v256">initial new port</a> of systemd to musl.  This patch set does not share much in common with the existing OpenEmbedded patchset.  I wanted to make a fully updated patch series targeting more current releases of systemd and musl, taking advantage of the latest features and updates in both.  I also took a focus on writing patches that could be sent for consideration of inclusion upstream.</p>



<p>The final result is a system that appears to be surprisingly reliable considering the newness of the port, and very fast to boot.</p>



<h2>Why?</h2>



<p>I have wanted to do this work for almost a decade.  In fact, a mention of multiple service manager options – including systemd – is present on the <a href="https://web.archive.org/web/20160109133511/http://adelielinux.org/">original Adélie Web site from 2015</a>.  Other initiatives have always taken priority, until someone contacted us at <a href="https://www.wilcoxti.com/">Wilcox Technologies Inc. (WTI)</a> interested in paying on a contract basis to see this effort completed.</p>



<p>I want to be clear that I did not do this for money.  I believe strongly that there is genuine value in having multiple service managers available.  User freedom and user choice matter.  There are cases where this support would have been useful to me and to many others in the community.  I am excited to see this work nearing public release and honoured to be a part of creating more choice in the Linux world.</p>



<h2>How?</h2>



<p>I started with the latest release tag, v256.5.  I wanted a version closely aligned to upstream’s current progress, yet not too far away from the present “stable” 255 release.  I also wanted to make sure that the fallout from upstream’s removal of split-/usr support would be felt to its maximum, since reverting that decision is a high priority.</p>



<p>I fixed build errors as they happened until I finally had a built systemd.  During this phase, I consulted the original OE patchset twice: once for usage of <code>GLOB_BRACE</code>, and the other for usage of <code>malloc_info</code> and <code>malloc_trim</code>.  Otherwise, the patchset was authored entirely originally, mostly through the day (and into the night) of August 16th, 2024.</p>



<p>Many of the issues seen were related to inclusion of headers, and I am already working on <a href="https://github.com/systemd/systemd/pull/34064">bringing</a> those fixes <a href="https://github.com/systemd/systemd/pull/34066">upstream</a>.  It was then time to run the test suite.</p>



<h2>Tests!</h2>



<p>The test suite started with 27 failures.  Most of them were simple fixes, but one that gave me a lot of trouble was the <code>time-util</code> test.  The <a href="https://git.musl-libc.org/cgit/musl/tree/src/time/strptime.c"><code>strptime</code> implementation in musl</a> does not support the <code>%z</code> format specifier (for time zones), which the systemd test relies on.  I could have disabled those tests, but I felt like this would be taking away a lot of functionality.  I considered things like important journals from other systems – they would likely have timestamps with <code>%z</code> formats.  I wrote a <code>%z</code> translation for systemd and saw the tests passing.</p>



<p>Other test failures were simple <a href="https://github.com/systemd/systemd/pull/34065">C portability fixes</a>, which are also in the process of being sent upstream.</p>



<p>The test suite for <code>systemd-sysusers</code> was the next sticky one.  It really exercises the POSIX library functions <code>getgrent</code> and <code>getpwent</code>.  The musl implementations of these are fine, but they don’t cope well with the old NIS compatibility shims from the glibc world.  They also <a href="https://www.openwall.com/lists/musl/2021/10/11/1">can’t handle “incomplete” lines</a>.  The fix for incomplete line handling is pending, so in the meantime I made the test have no incomplete lines.  I added a shim for the NIS compatibility entries in systemd’s <code>putgrent_sane</code> function, making it a little less “sane” but fixing the support perfectly.</p>



<p>Then it was time for the final failing test: <code>test-recurse-dir</code>, which was receiving an <code>EFAULT</code> error code from <code>getdents64</code>.  Discussing this with my friends on the Gentoo IRC, we began to wonder if this was an architecture-specific bug.  I was doing my port work on my Talos II, a 64-bit PowerPC system.  I copied the code over to an Intel Skylake and found the test suite passed.  That was both good, in that the tests were all passing, but also bad, because it meant I was dealing with a PPC64-specific bug.  I wasn’t sure if this was a kernel bug, a musl bug, or a systemd bug.</p>



<p>Digging into it further, I realised that the pointer math being done would be invalid when cast to a pointer-to-structure on PPC64 due to object alignment guarantees in the ABI.  I changed it to use a temporary variable for the pointer math and casting that temporary, and it passed!</p>



<p>And that is how I became the first person alive to see systemd passing its entire test suite on a big-endian 64-bit PowerPC musl libc system.</p>



<h2>The moment of truth</h2>



<p>I created a small disk image and ran a very strange command: <code>apk add adelie-base-posix dash-binsh systemd</code>.  I booted it up as a KVM VM in Qemu and saw “Welcome to Adélie Linux 1.0 Beta 5” before a rather ungraceful – and due to Qemu framebuffer endian issues, colour-swapped – segmentation fault:</p>



<figure><img data-attachment-id="453" data-permalink="https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-powered-linux/the-dawn-of-a-new-error/" data-orig-file="https://catfox.life/wp-content/uploads/2024/09/the-dawn-of-a-new-error.png" data-orig-size="1736,1392" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="the-dawn-of-a-new-error" data-image-description="" data-image-caption="" data-medium-file="https://catfox.life/wp-content/uploads/2024/09/the-dawn-of-a-new-error.png?w=300" data-large-file="https://catfox.life/wp-content/uploads/2024/09/the-dawn-of-a-new-error.png?w=840" tabindex="0" role="button" width="1024" height="821" src="https://catfox.life/wp-content/uploads/2024/09/the-dawn-of-a-new-error.png?w=1024" alt=""><figcaption>Welcome to an endian-swapped systemd core dump!</figcaption></figure>



<p>Debugging this was an experience in early systems debugging that I haven’t had in years.  There’s a great summary on this methodology at <a href="https://linus.schreibt.jetzt/posts/debugging-pid1.html">Linus’s blog</a>.</p>



<p>It turned out that I had disabled a test from build-util as I incorrectly assumed that was only used when debugging in the build root.  Since I did not want to spend time digging around how it manually parses ELF files to find their RPATH entries for a feature we are unlikely to use, I stubbed that functionality out entirely.  We can always fix it later.</p>



<p>Recreating the disk image and booting it up, I was greeted by an Adélie “rescue” environment booted by systemd.  It was frankly bizarre, but also really cool.</p>



<figure><img data-attachment-id="454" data-permalink="https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-powered-linux/habbening/" data-orig-file="https://catfox.life/wp-content/uploads/2024/09/habbening.png" data-orig-size="2064,1470" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="habbening" data-image-description="" data-image-caption="" data-medium-file="https://catfox.life/wp-content/uploads/2024/09/habbening.png?w=300" data-large-file="https://catfox.life/wp-content/uploads/2024/09/habbening.png?w=840" tabindex="0" role="button" width="1024" height="729" src="https://catfox.life/wp-content/uploads/2024/09/habbening.png?w=1024" alt=""><figcaption>The first time systemd ever booted an Adélie Linux system.</figcaption></figure>



<h2>From walking to flying</h2>



<p>Next, I built test packages on the Skylake builder we are using for x86_64 development.  I have a 2012 MacBook Pro that I keep around for testing various experiments, and this felt like a good system for the ultimate experiment.  The goal: swapping init systems with a single command.</p>



<p>It turns out that D-Bus and PolicyKit require systemd support to be enabled or disabled at build-time.  There is no way to build them in a way that allows them to operate on both types of init system.  This is an area I would like to work on more in the future.</p>



<p>I wrote package recipes for both that are built against systemd and “replace” the non-systemd versions.  I also marked them to <code>install_if</code> the system wanted systemd.</p>



<p>Next up were some more configuration and dependency fixes.  I found out via this experiment that some of the Adélie system packages do not place their pkg-config files in the proper place.  I also decided that if I’m already testing this far, I’d use networkd to bring up the laptop in question.</p>



<p>I ran the fateful command <code>apk del openrc; apk add systemd</code> and rebooted.  To my surprise, it all worked!  The system booted up perfectly with systemd.  The oddest sight was my utmps units running:</p>



<figure><img data-attachment-id="455" data-permalink="https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-powered-linux/need-more-fromage-2/" data-orig-file="https://catfox.life/wp-content/uploads/2024/09/need-more-fromage-2.png" data-orig-size="1280,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="need-more-fromage-2" data-image-description="" data-image-caption="" data-medium-file="https://catfox.life/wp-content/uploads/2024/09/need-more-fromage-2.png?w=300" data-large-file="https://catfox.life/wp-content/uploads/2024/09/need-more-fromage-2.png?w=840" tabindex="0" role="button" width="1024" height="640" src="https://catfox.life/wp-content/uploads/2024/09/need-more-fromage-2.png?w=1024" alt=""><figcaption>systemd running s6-ipcserver.  The irony is not lost on me.</figcaption></figure>



<h2>Still needed: polish…</h2>



<p>While the system works really well, and boots in 1/3rd the time of OpenRC on the same system, it isn’t ready for prime time just yet.</p>



<p>Rebooting from a KDE session causes the compositor to freeze.  I can reboot manually from a command line, or even from a Konsole inside the session, but not using Plasma’s built-in power buttons.  This may be a PolicyKit issue – I haven’t debugged it properly yet.</p>



<p>There aren’t any service unit files written or packaged yet, other than OpenSSH and utmps.  We are working with our sponsor on an effort to add -systemd split packages to any of the packages with -openrc splits.  We should be able to rely on upstream units where present, and lean on Gentoo and Fedora’s systemd experts to have good base files to reference when needed.  I’ve already landed <a href="https://git.adelielinux.org/adelie/abuild/-/merge_requests/16">support for this in abuild</a>.</p>



<h2>…and You!</h2>



<p>This project could not have happened without the generous sponsors of Wilcox Technologies Inc (WTI) making it possible, nor without the generous sponsors of Adélie Linux keeping the distro running.  Please consider supporting both <a href="https://www.adelielinux.org/contribute/">Adélie Linux</a> and <a href="https://www.patreon.com/WilcoxTech">WTI</a> if you have the means.  Together, we are creating the future of Linux systems – a future where users have the choice and freedom to use the tooling they desire.</p>



<p>If you want to help test this new system out, please reach out to me on IRC (awilfox on Interlinked or Libera), or the Adéliegram Telegram channel.  It will be a little while before a public beta will be available, as more review and discussion with other projects is needed.  We are working with systemd, musl, and other projects to make this as smooth as possible.  We want to ensure that what we provide for testing is up to our highest standards of quality.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building a WoW (World of Warcraft) Server in Elixir (163 pts)]]></title>
            <link>https://pikdum.dev/posts/thistle-tea/</link>
            <guid>41454741</guid>
            <pubDate>Thu, 05 Sep 2024 08:36:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pikdum.dev/posts/thistle-tea/">https://pikdum.dev/posts/thistle-tea/</a>, See on <a href="https://news.ycombinator.com/item?id=41454741">Hacker News</a></p>
Couldn't get https://pikdum.dev/posts/thistle-tea/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Desed: Demystify and debug your sed scripts (129 pts)]]></title>
            <link>https://github.com/SoptikHa2/desed</link>
            <guid>41453557</guid>
            <pubDate>Thu, 05 Sep 2024 04:46:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/SoptikHa2/desed">https://github.com/SoptikHa2/desed</a>, See on <a href="https://news.ycombinator.com/item?id=41453557">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Desed</h2><a id="user-content-desed" aria-label="Permalink: Desed" href="#desed"></a></p>
<p dir="auto">Demystify and debug your sed scripts, from comfort of your terminal.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SoptikHa2/desed/blob/master/img/desed.gif"><img src="https://github.com/SoptikHa2/desed/raw/master/img/desed.gif" alt="desed usage example" data-animated-image=""></a></p>
<p dir="auto">Desed is a command line tool with beautiful TUI that provides users with comfortable interface and practical debugger, used to step through complex sed scripts.</p>
<p dir="auto">Some of the notable features include:</p>
<ul dir="auto">
<li>Preview variable values, both of them!</li>
<li>See how will a substitute command affect pattern space before it runs</li>
<li>Step through sed script - both forward and backwards!</li>
<li>Place breakpoints and examine program state</li>
<li>Hot reload and see what changes as you edit source code</li>
<li>Its name is a palindrome</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Alpine Linux</h3><a id="user-content-alpine-linux" aria-label="Permalink: Alpine Linux" href="#alpine-linux"></a></p>
<p dir="auto"><code>aports/testing/desed</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Arch Linux</h3><a id="user-content-arch-linux" aria-label="Permalink: Arch Linux" href="#arch-linux"></a></p>
<p dir="auto">Via AUR: <a href="https://aur.archlinux.org/packages/desed-git/" rel="nofollow">desed-git</a> or <a href="https://aur.archlinux.org/packages/desed/" rel="nofollow">desed</a> as stable version.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">DragonFly BSD</h3><a id="user-content-dragonfly-bsd" aria-label="Permalink: DragonFly BSD" href="#dragonfly-bsd"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Fedora</h3><a id="user-content-fedora" aria-label="Permalink: Fedora" href="#fedora"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">FreeBSD</h3><a id="user-content-freebsd" aria-label="Permalink: FreeBSD" href="#freebsd"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Void Linux</h3><a id="user-content-void-linux" aria-label="Permalink: Void Linux" href="#void-linux"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Source</h3><a id="user-content-source" aria-label="Permalink: Source" href="#source"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/soptikha2/desed
cd desed
cargo install --path .
cp &quot;desed.1&quot; &quot;$(manpath | cut -d':' -f1)/man1&quot;"><pre>git clone https://github.com/soptikha2/desed
<span>cd</span> desed
cargo install --path <span>.</span>
cp <span><span>"</span>desed.1<span>"</span></span> <span><span>"</span><span><span>$(</span>manpath <span>|</span> cut -d<span><span>'</span>:<span>'</span></span> -f1<span>)</span></span>/man1<span>"</span></span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cargo</h3><a id="user-content-cargo" aria-label="Permalink: Cargo" href="#cargo"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Precompiled binaries</h3><a id="user-content-precompiled-binaries" aria-label="Permalink: Precompiled binaries" href="#precompiled-binaries"></a></p>
<p dir="auto">See <a href="https://github.com/SoptikHa2/desed/releases">releases</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dependencies:</h3><a id="user-content-dependencies" aria-label="Permalink: Dependencies:" href="#dependencies"></a></p>
<p dir="auto">Development: <code>rust</code>, <code>cargo</code> (&gt;= 1.38.0)</p>
<p dir="auto">Runtime: <code>sed</code> (GNU version, &gt;= 4.6) (desed works on BSD if you installed <code>gsed</code>)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Controls</h2><a id="user-content-controls" aria-label="Permalink: Controls" href="#controls"></a></p>
<ul dir="auto">
<li>Mouse scroll to scroll through source code, click on line to toggle breakpoint</li>
<li><code>j</code>, <code>k</code>, <code>g</code>, <code>G</code>, just as in Vim. Prefixing with numbers works too.</li>
<li><code>b</code> to toggle breakpoint (prefix with number to toggle breakpoint on target line)</li>
<li><code>s</code> to step forward, <code>a</code> to step backwards</li>
<li><code>r</code> to run to next breakpoint or end of script, <code>R</code> to do the same but backwards</li>
<li><code>l</code> to instantly reload code and continue debugging in the exactly same place as before</li>
<li><code>q</code> to <a href="https://github.com/hakluke/how-to-exit-vim">quit</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How does it work?</h2><a id="user-content-how-does-it-work" aria-label="Permalink: How does it work?" href="#how-does-it-work"></a></p>
<p dir="auto">GNU sed actually provides pretty useful debugging interface, try it yourself with <code>--debug</code> flag. However the interface is not interactive and I wanted something closer to traditional debugger. <a href="https://soptik.tech/articles/building-desed-the-sed-debugger.html" rel="nofollow">I've written something here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Does it really work?</h2><a id="user-content-does-it-really-work" aria-label="Permalink: Does it really work?" href="#does-it-really-work"></a></p>
<p dir="auto">Depends. Sed actually doesn't tell me which line number is it currently executing, so I have to emulate parts of sed to guess that. Which might not be bulletproof. But it certainly worked good enough to debug tetris without issues.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why sed??</h2><a id="user-content-why-sed" aria-label="Permalink: Why sed??" href="#why-sed"></a></p>
<p dir="auto">Sed is the perfect programming language, <a href="https://tildes.net/~comp/b2k/programming_challenge_find_path_from_city_a_to_city_b_with_least_traffic_controls_inbetween#comment-2run" rel="nofollow">especially for graph problems</a>. It's plain and simple and doesn't clutter your screen with useless identifiers like <code>if</code>, <code>for</code>, <code>while</code>, or <code>int</code>. Furthermore since it doesn't have things like numbers, it's very simple to use.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">But why?</h2><a id="user-content-but-why" aria-label="Permalink: But why?" href="#but-why"></a></p>
<p dir="auto">I wanted to program in sed but it lacked good tooling up to this point, so I had to do something about it.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<p dir="auto">Because it's the standard stream editor for filtering and transforming text. And someone wrote <a href="https://github.com/uuner/sedtris">tetris</a> in it!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is the roadmap for future updates?</h2><a id="user-content-what-is-the-roadmap-for-future-updates" aria-label="Permalink: What is the roadmap for future updates?" href="#what-is-the-roadmap-for-future-updates"></a></p>
<p dir="auto">I would like to introduce syntax highlighting and add this tool to standard repositories of all major distributions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Is this a joke?</h2><a id="user-content-is-this-a-joke" aria-label="Permalink: Is this a joke?" href="#is-this-a-joke"></a></p>
<p dir="auto">I thought it was. But apparently it's actually useful for some people.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Other projects</h2><a id="user-content-other-projects" aria-label="Permalink: Other projects" href="#other-projects"></a></p>
<ul dir="auto">
<li><a href="https://github.com/soptikha2/video-summarizer">video summarizer</a>, a tool and browser extensions that determines if people in video are currently talking or not, and speeds up the video accordingly. Great for long lecture videos for skipping time spent writing on a whiteboard.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kids who use ChatGPT as a study assistant do worse on tests (159 pts)]]></title>
            <link>https://hechingerreport.org/kids-chatgpt-worse-on-tests/</link>
            <guid>41453300</guid>
            <pubDate>Thu, 05 Sep 2024 03:50:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hechingerreport.org/kids-chatgpt-worse-on-tests/">https://hechingerreport.org/kids-chatgpt-worse-on-tests/</a>, See on <a href="https://news.ycombinator.com/item?id=41453300">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content">
		<main id="main">

								

				
				<div>

					<section id="block-2"><p><em>The Hechinger Report is a national nonprofit newsroom that reports on one topic: education. Sign up for our&nbsp;<a href="https://hechingerreport.org/newsletters" target="_blank" rel="noreferrer noopener">weekly newsletters</a>&nbsp;to get stories like this delivered directly to your inbox.&nbsp;Consider supporting our stories and becoming&nbsp;<a href="https://hechingerreport.fundjournalism.org/?campaign=701VK000003ezHZYAY" target="_blank" rel="noreferrer noopener">a member</a>&nbsp;today.</em></p></section>

<article id="post-103317">
	<div>

		
		
					<p>Does AI actually help students learn? A recent experiment in a high school provides a cautionary tale.&nbsp;</p><p>Researchers at the University of Pennsylvania found that Turkish high school students who had access to ChatGPT while doing practice math problems did worse on a math test compared with students who didn’t have access to ChatGPT. Those with ChatGPT solved 48 percent more of the practice problems correctly, but they ultimately scored 17 percent worse on a test of the topic that the students were learning.&nbsp;</p><p>A third group of students had access to a revised version of ChatGPT that functioned more like a tutor. This chatbot was programmed to provide hints without directly divulging the answer. The students who used it did spectacularly better on the practice problems, solving 127 percent more of them correctly compared with students who did their practice work without any high-tech aids. But on a test afterwards, these AI-tutored students did no better. Students who just did their practice problems the old fashioned way — on their own — matched their test scores.</p><p>The researchers titled their paper, “Generative AI Can Harm Learning,” to make clear to parents and educators that the current crop of freely available AI chatbots can “substantially inhibit learning.” Even a fine-tuned version of ChatGPT designed to mimic a tutor doesn’t necessarily help.</p><p>The researchers believe the problem is that students are using the chatbot as a “crutch.” When they analyzed the questions that students typed into ChatGPT, students often simply asked for the answer. Students were not building the skills that come from solving the problems themselves.&nbsp;</p><p>ChatGPT’s errors also may have been a contributing factor. The chatbot only answered the math problems correctly half of the time. Its arithmetic computations were wrong 8 percent of the time, but the bigger problem was that its step-by-step approach for how to solve a problem was wrong 42 percent of the time. The tutoring version of ChatGPT was directly fed the correct solutions and these errors were minimized.</p><p>A <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4895486">draft paper about the experiment</a> was posted on the website of SSRN, formerly known as the Social Science Research Network, in July 2024. The paper has not yet been published in a peer-reviewed journal and could still be revised.&nbsp;</p><p>This is just one experiment in another country, and more studies will be needed to confirm its findings. But this experiment was a large one, involving nearly a thousand students in grades nine through 11 during the fall of 2023. Teachers first reviewed a previously taught lesson with the whole classroom, and then their classrooms were randomly assigned to practice the math in one of three ways: with access to ChatGPT, with access to an AI tutor powered by ChatGPT or with no high-tech aids at all. Students in each grade were assigned the same practice problems with or without AI. Afterwards, they took a test to see how well they learned the concept. Researchers conducted four cycles of this, giving students four 90-minute sessions of practice time in four different math topics to understand whether AI tends to help, harm or do nothing.</p><p>ChatGPT also seems to produce overconfidence. In surveys that accompanied the experiment, students said they did not think that ChatGPT caused them to learn less even though they had. Students with the AI tutor thought they had done significantly better on the test even though they did not. (It’s also another good reminder to all of us that our <a href="https://hechingerreport.org/proof-points-college-students-often-dont-know-when-theyre-learning/">perceptions of how much we’ve learned are often wrong</a>.)</p><p>The authors likened the problem of learning with ChatGPT to autopilot. They recounted how an overreliance on autopilot led the Federal Aviation Administration to recommend that pilots minimize their use of this technology. Regulators wanted to make sure that pilots still know how to fly when autopilot fails to function correctly.&nbsp;</p><p>ChatGPT is not the first technology to present a tradeoff in education. Typewriters and computers reduce the need for handwriting. Calculators reduce the need for arithmetic. When students have access to ChatGPT, they might answer more problems correctly, but learn less. Getting the right result to one problem won’t help them with the next one.</p><p><em>This story about&nbsp;using <a href="https://hechingerreport.org/kids-chatgpt-worse-on-tests/">ChatGPT to practice math</a>&nbsp;was written by Jill Barshay and produced by&nbsp;<a href="https://hechingerreport.org/special-reports/higher-education/" target="_blank" rel="noreferrer noopener">The Hechinger Report</a>, a nonprofit, independent news organization focused on inequality and innovation in education. Sign up for&nbsp;<a href="https://hechingerreport.org/proofpoints/" target="_blank" rel="noreferrer noopener"><em>Proof Points</em></a>&nbsp;and other&nbsp;<a href="https://hechingerreport.org/newsletters/" target="_blank" rel="noreferrer noopener"><em>Hechinger newsletters</em></a>.</em></p>
<div id="custom_html-3">
	
<p>The Hechinger Report provides in-depth, fact-based, unbiased reporting on education that is free to all readers. But that doesn't mean it's free to produce. Our work keeps educators and the public informed about pressing issues at schools and on campuses throughout the country. We tell the whole story, even when the details are inconvenient. Help us keep doing that.</p>

<p><a href="https://checkout.fundjournalism.org/memberform?amount=15&amp;installmentPeriod=monthly&amp;org_id=hechingerreport&amp;campaign=701f4000000dsvy">Join us today.</a></p>
</div>	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
			<div>
															<p><a href="https://hechingerreport.org/author/jill-barshay/" rel="author">
											<img alt="Avatar photo" src="https://hechingerreport.org/wp-content/uploads/2015/01/Barshay-80x80.jpg" srcset="https://i0.wp.com/hechingerreport.org/wp-content/uploads/2015/01/Barshay.jpg?fit=154%2C150&amp;ssl=1 2x" height="80" width="80">											</a></p><!-- .author-bio-text -->

			</div><!-- .author-bio -->
			
</article><!-- #post-${ID} -->

<!-- #comments -->
				</div><!-- .main-content -->

			
		</main><!-- #main -->
	</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yi-Coder: A Small but Mighty LLM for Code (205 pts)]]></title>
            <link>https://01-ai.github.io/blog.html?post=en/2024-09-05-A-Small-but-Mighty-LLM-for-Code.md</link>
            <guid>41453237</guid>
            <pubDate>Thu, 05 Sep 2024 03:38:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://01-ai.github.io/blog.html?post=en/2024-09-05-A-Small-but-Mighty-LLM-for-Code.md">https://01-ai.github.io/blog.html?post=en/2024-09-05-A-Small-but-Mighty-LLM-for-Code.md</a>, See on <a href="https://news.ycombinator.com/item?id=41453237">Hacker News</a></p>
Couldn't get https://01-ai.github.io/blog.html?post=en/2024-09-05-A-Small-but-Mighty-LLM-for-Code.md: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Accelerando (2005) (145 pts)]]></title>
            <link>https://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html</link>
            <guid>41452962</guid>
            <pubDate>Thu, 05 Sep 2024 02:33:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html">https://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html</a>, See on <a href="https://news.ycombinator.com/item?id=41452962">Hacker News</a></p>
Couldn't get https://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html: Error: unable to verify the first certificate]]></description>
        </item>
        <item>
            <title><![CDATA[Canadian mega landlord using AI 'pricing scheme' as it hikes rents (132 pts)]]></title>
            <link>https://breachmedia.ca/canadian-mega-landlord-ai-pricing-scheme-hikes-rents/</link>
            <guid>41452781</guid>
            <pubDate>Thu, 05 Sep 2024 01:59:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://breachmedia.ca/canadian-mega-landlord-ai-pricing-scheme-hikes-rents/">https://breachmedia.ca/canadian-mega-landlord-ai-pricing-scheme-hikes-rents/</a>, See on <a href="https://news.ycombinator.com/item?id=41452781">Hacker News</a></p>
Couldn't get https://breachmedia.ca/canadian-mega-landlord-ai-pricing-scheme-hikes-rents/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Tinystatus: A tiny status page generated by a Python script (164 pts)]]></title>
            <link>https://github.com/harsxv/tinystatus</link>
            <guid>41452339</guid>
            <pubDate>Thu, 05 Sep 2024 00:40:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/harsxv/tinystatus">https://github.com/harsxv/tinystatus</a>, See on <a href="https://news.ycombinator.com/item?id=41452339">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">TinyStatus</h2><a id="user-content-tinystatus" aria-label="Permalink: TinyStatus" href="#tinystatus"></a></p>
<p dir="auto">TinyStatus is a simple, customizable status page generator that allows you to monitor the status of various services and display them on a clean, responsive web page. <a href="https://status.harry.id/" rel="nofollow">Check out an online demo.</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/32115753/364659939-28227221-d1e1-442e-89a4-2a0a09615514.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU1MzYxMDIsIm5iZiI6MTcyNTUzNTgwMiwicGF0aCI6Ii8zMjExNTc1My8zNjQ2NTk5MzktMjgyMjcyMjEtZDFlMS00NDJlLTg5YTQtMmEwYTA5NjE1NTE0LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTA1VDExMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA2Zjc0OGQxMGYxYzRjYmI0MmU0MGVkMzczMmIxMGZjNDQ4YzdkYWEyY2VmMTgxYWQ2YTMyYzA5MzFiZWJjYTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QCCL41W8KUg1xVUkqRXKeIjf9PYclCeikbDKVyKaZK4"><img src="https://private-user-images.githubusercontent.com/32115753/364659939-28227221-d1e1-442e-89a4-2a0a09615514.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU1MzYxMDIsIm5iZiI6MTcyNTUzNTgwMiwicGF0aCI6Ii8zMjExNTc1My8zNjQ2NTk5MzktMjgyMjcyMjEtZDFlMS00NDJlLTg5YTQtMmEwYTA5NjE1NTE0LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTA1VDExMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA2Zjc0OGQxMGYxYzRjYmI0MmU0MGVkMzczMmIxMGZjNDQ4YzdkYWEyY2VmMTgxYWQ2YTMyYzA5MzFiZWJjYTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QCCL41W8KUg1xVUkqRXKeIjf9PYclCeikbDKVyKaZK4" alt="image"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Monitor HTTP endpoints, ping hosts, and check open ports</li>
<li>Responsive design for both status page and history page</li>
<li>Customizable service checks via YAML configuration</li>
<li>Incident history tracking</li>
<li>Automatic status updates at configurable intervals</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prerequisites</h2><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<ul dir="auto">
<li>Python 3.7 or higher</li>
<li>pip (Python package manager)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Clone the repository or download the source code:</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/yourusername/tinystatus.git
cd tinystatus"><pre><code>git clone https://github.com/yourusername/tinystatus.git
cd tinystatus
</code></pre></div>
</li>
<li>
<p dir="auto">Install the required dependencies:</p>
<div data-snippet-clipboard-copy-content="pip install -r requirements.txt"><pre><code>pip install -r requirements.txt
</code></pre></div>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Create a <code>.env</code> file in the project root and customize the variables:</p>
<div data-snippet-clipboard-copy-content="CHECK_INTERVAL=30
MAX_HISTORY_ENTRIES=100
LOG_LEVEL=INFO
CHECKS_FILE=checks.yaml
INCIDENTS_FILE=incidents.md
TEMPLATE_FILE=index.html.theme
HISTORY_TEMPLATE_FILE=history.html.theme
STATUS_HISTORY_FILE=history.json"><pre><code>CHECK_INTERVAL=30
MAX_HISTORY_ENTRIES=100
LOG_LEVEL=INFO
CHECKS_FILE=checks.yaml
INCIDENTS_FILE=incidents.md
TEMPLATE_FILE=index.html.theme
HISTORY_TEMPLATE_FILE=history.html.theme
STATUS_HISTORY_FILE=history.json
</code></pre></div>
</li>
<li>
<p dir="auto">Edit the <code>checks.yaml</code> file to add or modify the services you want to monitor. Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="- name: GitHub Home
  type: http
  host: https://github.com
  expected_code: 200

- name: Google DNS
  type: ping
  host: 8.8.8.8

- name: Database
  type: port
  host: db.example.com
  port: 5432"><pre>- <span>name</span>: <span>GitHub Home</span>
  <span>type</span>: <span>http</span>
  <span>host</span>: <span>https://github.com</span>
  <span>expected_code</span>: <span>200</span>

- <span>name</span>: <span>Google DNS</span>
  <span>type</span>: <span>ping</span>
  <span>host</span>: <span>8.8.8.8</span>

- <span>name</span>: <span>Database</span>
  <span>type</span>: <span>port</span>
  <span>host</span>: <span>db.example.com</span>
  <span>port</span>: <span>5432</span></pre></div>
</li>
<li>
<p dir="auto">(Optional) Customize the <code>incidents.md</code> file to add any known incidents or maintenance schedules.</p>
</li>
<li>
<p dir="auto">(Optional) Modify the <code>index.html.theme</code> and <code>history.html.theme</code> files to customize the look and feel of your status pages.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Run the TinyStatus script:</p>

</li>
<li>
<p dir="auto">The script will generate two HTML files:</p>
<ul dir="auto">
<li><code>index.html</code>: The main status page</li>
<li><code>history.html</code>: The status history page</li>
</ul>
</li>
<li>
<p dir="auto">To keep the status page continuously updated, you can run the script in the background:</p>
<ul dir="auto">
<li>On Unix-like systems (Linux, macOS):
<div data-snippet-clipboard-copy-content="nohup python tinystatus.py &amp;"><pre><code>nohup python tinystatus.py &amp;
</code></pre></div>
</li>
<li>On Windows, you can use the Task Scheduler to run the script at startup.</li>
</ul>
</li>
<li>
<p dir="auto">Serve the generated HTML files using your preferred web server (e.g., Apache, Nginx, or a simple Python HTTP server for testing).</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Customization</h2><a id="user-content-customization" aria-label="Permalink: Customization" href="#customization"></a></p>
<ul dir="auto">
<li>Adjust the configuration variables in the <code>.env</code> file to customize the behavior of TinyStatus.</li>
<li>Customize the appearance of the status page by editing the CSS in <code>index.html.theme</code> and <code>history.html.theme</code>.</li>
<li>Add or remove services by modifying the <code>checks.yaml</code> file.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions are welcome! Please feel free to submit a Pull Request.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is open source and available under the <a href="https://github.com/harsxv/tinystatus/blob/master/LICENSE">MIT License</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Laminar – Open-Source DataDog + PostHog for LLM Apps, Built in Rust (175 pts)]]></title>
            <link>https://github.com/lmnr-ai/lmnr</link>
            <guid>41451698</guid>
            <pubDate>Wed, 04 Sep 2024 22:52:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lmnr-ai/lmnr">https://github.com/lmnr-ai/lmnr</a>, See on <a href="https://news.ycombinator.com/item?id=41451698">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a href="https://www.ycombinator.com/companies/laminar-ai" rel="nofollow"><img src="https://camo.githubusercontent.com/3bf938994198a5b1d850adab39ba81e5675045b3b2b496b9856ce7b833eae93a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f59253230436f6d62696e61746f722d5332342d6f72616e6765" alt="Static Badge" data-canonical-src="https://img.shields.io/badge/Y%20Combinator-S24-orange"></a>
<a href="https://x.com/lmnrai" rel="nofollow"><img src="https://camo.githubusercontent.com/7217689996b50018699ee10564c16fa62744b484f8ab968cfcd2b4b992212b15/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f6c6d6e726169" alt="X (formerly Twitter) Follow" data-canonical-src="https://img.shields.io/twitter/follow/lmnrai"></a>
<a href="https://discord.gg/nNFUUDAKub" rel="nofollow"> <img src="https://camo.githubusercontent.com/3c567c02e658b3bbc878a42c214883dc7706c5206ceea744dd66138c5b9e348f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4a6f696e5f446973636f72642d3436343634363f266c6f676f3d646973636f7264266c6f676f436f6c6f723d353836354632" alt="Static Badge" data-canonical-src="https://img.shields.io/badge/Join_Discord-464646?&amp;logo=discord&amp;logoColor=5865F2"> </a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Laminar - Open-Source observability, analytics, evals and prompt chains for complex LLM apps.</h2><a id="user-content-laminar---open-source-observability-analytics-evals-and-prompt-chains-for-complex-llm-apps" aria-label="Permalink: Laminar - Open-Source observability, analytics, evals and prompt chains for complex LLM apps." href="#laminar---open-source-observability-analytics-evals-and-prompt-chains-for-complex-llm-apps"></a></p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14181915/364260202-88e1f801-1dbf-4e5b-af71-1a3923661cd1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU1MTgxMDIsIm5iZiI6MTcyNTUxNzgwMiwicGF0aCI6Ii8xNDE4MTkxNS8zNjQyNjAyMDItODhlMWY4MDEtMWRiZi00ZTViLWFmNzEtMWEzOTIzNjYxY2QxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTA1VDA2MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTYyYTBmYjliYjg1YjAzYWJmY2IyZTBhMGIzNDRhMGFjNTdmZmMxODQ1MDliZGRkOWE2ZDdjOWY4YzQxMzQzMmYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.7I9SrNoGGdke9Vnw-RjlOeneRQgabGyiRu8uDYQadi4"><img width="1439" alt="traces" src="https://private-user-images.githubusercontent.com/14181915/364260202-88e1f801-1dbf-4e5b-af71-1a3923661cd1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU1MTgxMDIsIm5iZiI6MTcyNTUxNzgwMiwicGF0aCI6Ii8xNDE4MTkxNS8zNjQyNjAyMDItODhlMWY4MDEtMWRiZi00ZTViLWFmNzEtMWEzOTIzNjYxY2QxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTA1VDA2MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTYyYTBmYjliYjg1YjAzYWJmY2IyZTBhMGIzNDRhMGFjNTdmZmMxODQ1MDliZGRkOWE2ZDdjOWY4YzQxMzQzMmYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.7I9SrNoGGdke9Vnw-RjlOeneRQgabGyiRu8uDYQadi4"></a>
<p dir="auto">Think of it as DataDog + PostHog for LLM apps.</p>
<ul dir="auto">
<li>OpenTelemetry-based instrumentation: automatic for LLM / vector DB calls with just 2 lines of code + decorators to track functions (powered by an amazing <a href="https://github.com/traceloop/openllmetry">OpenLLMetry</a> open-source package by TraceLoop).</li>
<li>Semantic events-based analytics. Laminar hosts background job queues of LLM pipelines. Outputs of those pipelines are turned into metrics. For example, you can design a pipeline which extracts "my AI drive-through agent made an upsell" data, and track this metric in Laminar.</li>
<li>Built for scale with a modern stack: written in Rust, RabbitMQ for message queue, Postgres for data, Clickhouse for analytics</li>
<li>Insightful, fast dashboards for traces / spans / events</li>
</ul>
<p dir="auto">Read the <a href="https://docs.lmnr.ai/" rel="nofollow">docs</a>.</p>
<p dir="auto">This is a work in progress repo and it will be frequently updated.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting started" href="#getting-started"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Laminar Cloud</h3><a id="user-content-laminar-cloud" aria-label="Permalink: Laminar Cloud" href="#laminar-cloud"></a></p>
<p dir="auto">The easiest way to get started is with a generous free tier on our managed platform -&gt; <a href="https://www.lmnr.ai/" rel="nofollow">lmnr.ai</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Self-hosting with Docker compose</h3><a id="user-content-self-hosting-with-docker-compose" aria-label="Permalink: Self-hosting with Docker compose" href="#self-hosting-with-docker-compose"></a></p>
<p dir="auto">Start local version with docker compose.</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone git@github.com:lmnr-ai/lmnr
cd lmnr
docker compose up"><pre>git clone git@github.com:lmnr-ai/lmnr
<span>cd</span> lmnr
docker compose up</pre></div>
<p dir="auto">This will spin up the following containers:</p>
<ul dir="auto">
<li>app-server – the core app logic, backend, and the LLM proxies</li>
<li>rabbitmq – message queue for sending the traces and observations reliably</li>
<li>qdrant – vector database</li>
<li>semantic-search-service – service for interacting with qdrant and embeddings</li>
<li>frontend – the visual front-end dashboard for interacting with traces</li>
<li>postgres – the database for all the application data</li>
<li>clickhouse – columnar OLAP database for more efficient event and trace analytics</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Instrumenting Python code</h3><a id="user-content-instrumenting-python-code" aria-label="Permalink: Instrumenting Python code" href="#instrumenting-python-code"></a></p>
<p dir="auto">First, create a project and generate a Project API Key. Then,</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install lmnr
echo &quot;LMNR_PROJECT_API_KEY=<YOUR_PROJECT_API_KEY>&quot; >> .env"><pre>pip install lmnr
<span>echo</span> <span><span>"</span>LMNR_PROJECT_API_KEY=&lt;YOUR_PROJECT_API_KEY&gt;<span>"</span></span> <span>&gt;&gt;</span> .env</pre></div>
<p dir="auto">To automatically instrument LLM calls of popular frameworks and LLM provider libraries just add</p>
<div dir="auto" data-snippet-clipboard-copy-content="from lmnr import Laminar as L
L.initialize(project_api_key=&quot;<LMNR_PROJECT_API_KEY>&quot;)"><pre><span>from</span> <span>lmnr</span> <span>import</span> <span>Laminar</span> <span>as</span> <span>L</span>
<span>L</span>.<span>initialize</span>(<span>project_api_key</span><span>=</span><span>"&lt;LMNR_PROJECT_API_KEY&gt;"</span>)</pre></div>
<p dir="auto">In addition to automatic instrumentation, we provide a simple <code>@observe()</code> decorator, if you want to trace inputs / outputs of functions</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example</h4><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import os
from openai import OpenAI

from lmnr import observe, Laminar as L
L.initialize(project_api_key=&quot;<LMNR_PROJECT_API_KEY>&quot;)

client = OpenAI(api_key=os.environ[&quot;OPENAI_API_KEY&quot;])

@observe()  # annotate all functions you want to trace
def poem_writer(topic=&quot;turbulence&quot;):
    prompt = f&quot;write a poem about {topic}&quot;
    response = client.chat.completions.create(
        model=&quot;gpt-4o&quot;,
        messages=[
            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt},
        ],
    )
    poem = response.choices[0].message.content
    return poem

if __name__ == &quot;__main__&quot;:
    print(poem_writer(topic=&quot;laminar flow&quot;))"><pre><span>import</span> <span>os</span>
<span>from</span> <span>openai</span> <span>import</span> <span>OpenAI</span>

<span>from</span> <span>lmnr</span> <span>import</span> <span>observe</span>, <span>Laminar</span> <span>as</span> <span>L</span>
<span>L</span>.<span>initialize</span>(<span>project_api_key</span><span>=</span><span>"&lt;LMNR_PROJECT_API_KEY&gt;"</span>)

<span>client</span> <span>=</span> <span>OpenAI</span>(<span>api_key</span><span>=</span><span>os</span>.<span>environ</span>[<span>"OPENAI_API_KEY"</span>])

<span>@<span>observe</span>()  <span># annotate all functions you want to trace</span></span>
<span>def</span> <span>poem_writer</span>(<span>topic</span><span>=</span><span>"turbulence"</span>):
    <span>prompt</span> <span>=</span> <span>f"write a poem about <span><span>{</span><span>topic</span><span>}</span></span>"</span>
    <span>response</span> <span>=</span> <span>client</span>.<span>chat</span>.<span>completions</span>.<span>create</span>(
        <span>model</span><span>=</span><span>"gpt-4o"</span>,
        <span>messages</span><span>=</span>[
            {<span>"role"</span>: <span>"system"</span>, <span>"content"</span>: <span>"You are a helpful assistant."</span>},
            {<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: <span>prompt</span>},
        ],
    )
    <span>poem</span> <span>=</span> <span>response</span>.<span>choices</span>[<span>0</span>].<span>message</span>.<span>content</span>
    <span>return</span> <span>poem</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span>:
    <span>print</span>(<span>poem_writer</span>(<span>topic</span><span>=</span><span>"laminar flow"</span>))</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Sending events</h4><a id="user-content-sending-events" aria-label="Permalink: Sending events" href="#sending-events"></a></p>
<p dir="auto">You can send events in two ways:</p>
<ul dir="auto">
<li><code>.event(name, value)</code> – instant event with a value.</li>
<li><code>.evaluate_event(name, evaluator, data)</code> –  event that is evaluated by evaluator pipeline based on the data.</li>
</ul>
<p dir="auto">Note that to run an evaluate event, you need to crate an evaluator pipeline and create a target version for it.</p>
<p dir="auto">Laminar processes background job queues of pipeline processes and records outputs of pipelines as events.</p>
<p dir="auto">Read our <a href="https://docs.lmnr.ai/" rel="nofollow">docs</a> to learn more about event types and how they are created and evaluated.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from lmnr import Laminar as L
# ...
poem = response.choices[0].message.content

# this will register True or False value with Laminar
L.event(&quot;topic alignment&quot;, topic in poem)

# this will run the pipeline `check_wordy` with `poem` set as the value
# of `text_input` node, and write the result as an event with name
# &quot;excessive_wordiness&quot;
L.evaluate_event(&quot;excessive_wordiness&quot;, &quot;check_wordy&quot;, {&quot;text_input&quot;: poem})"><pre><span>from</span> <span>lmnr</span> <span>import</span> <span>Laminar</span> <span>as</span> <span>L</span>
<span># ...</span>
<span>poem</span> <span>=</span> <span>response</span>.<span>choices</span>[<span>0</span>].<span>message</span>.<span>content</span>

<span># this will register True or False value with Laminar</span>
<span>L</span>.<span>event</span>(<span>"topic alignment"</span>, <span>topic</span> <span>in</span> <span>poem</span>)

<span># this will run the pipeline `check_wordy` with `poem` set as the value</span>
<span># of `text_input` node, and write the result as an event with name</span>
<span># "excessive_wordiness"</span>
<span>L</span>.<span>evaluate_event</span>(<span>"excessive_wordiness"</span>, <span>"check_wordy"</span>, {<span>"text_input"</span>: <span>poem</span>})</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Laminar pipelines as prompt chain managers</h4><a id="user-content-laminar-pipelines-as-prompt-chain-managers" aria-label="Permalink: Laminar pipelines as prompt chain managers" href="#laminar-pipelines-as-prompt-chain-managers"></a></p>
<p dir="auto">You can create Laminar pipelines in the UI and manage chains of LLM calls there.</p>
<p dir="auto">After you are ready to use your pipeline in your code, deploy it in Laminar by selecting the target version for the pipeline.</p>
<p dir="auto">Once your pipeline target is set, you can call it from Python in just a few lines.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from lmnr import Laminar as L

L.initialize('<YOUR_PROJECT_API_KEY>')

result = l.run(
    pipeline = 'my_pipeline_name',
    inputs = {'input_node_name': 'some_value'},
    # all environment variables
    env = {'OPENAI_API_KEY': 'sk-some-key'},
)"><pre><span>from</span> <span>lmnr</span> <span>import</span> <span>Laminar</span> <span>as</span> <span>L</span>

<span>L</span>.<span>initialize</span>(<span>'&lt;YOUR_PROJECT_API_KEY&gt;'</span>)

<span>result</span> <span>=</span> <span>l</span>.<span>run</span>(
    <span>pipeline</span> <span>=</span> <span>'my_pipeline_name'</span>,
    <span>inputs</span> <span>=</span> {<span>'input_node_name'</span>: <span>'some_value'</span>},
    <span># all environment variables</span>
    <span>env</span> <span>=</span> {<span>'OPENAI_API_KEY'</span>: <span>'sk-some-key'</span>},
)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Learn more</h2><a id="user-content-learn-more" aria-label="Permalink: Learn more" href="#learn-more"></a></p>
<p dir="auto">To learn more about instrumenting your code, check out our client libraries:</p>
<p dir="auto"><a href="https://www.npmjs.com/package/@lmnr-ai/lmnr" rel="nofollow"> <img src="https://camo.githubusercontent.com/6b3081997512b3addac3266d3dcaa06d9fe0cfdc9d34a7b64f56c68ee0e10398/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f2534306c6d6e722d61692532466c6d6e723f6c6162656c3d6c6d6e72266c6f676f3d6e706d266c6f676f436f6c6f723d434233383337" alt="NPM Version" data-canonical-src="https://img.shields.io/npm/v/%40lmnr-ai%2Flmnr?label=lmnr&amp;logo=npm&amp;logoColor=CB3837"> </a>
<a href="https://pypi.org/project/lmnr/" rel="nofollow"> <img src="https://camo.githubusercontent.com/667df376d1224a1681f52ee5b358b52d73094911caecd6bcfa5fd55e6622df40/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6c6d6e723f6c6162656c3d6c6d6e72266c6f676f3d70797069266c6f676f436f6c6f723d333737354139" alt="PyPI - Version" data-canonical-src="https://img.shields.io/pypi/v/lmnr?label=lmnr&amp;logo=pypi&amp;logoColor=3775A9"> </a></p>
<p dir="auto">To get deeper understanding of the concepts, follow on to the <a href="https://docs.lmnr.ai/" rel="nofollow">docs</a> and <a href="https://docs.lmnr.ai/tutorials" rel="nofollow">tutorials</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Origami-Inspired Phased Arrays Are Reshaping the Future of Antennas (107 pts)]]></title>
            <link>https://www.viksnewsletter.com/p/origami-inspired-phased-arrays</link>
            <guid>41451431</guid>
            <pubDate>Wed, 04 Sep 2024 22:13:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.viksnewsletter.com/p/origami-inspired-phased-arrays">https://www.viksnewsletter.com/p/origami-inspired-phased-arrays</a>, See on <a href="https://news.ycombinator.com/item?id=41451431">Hacker News</a></p>
Couldn't get https://www.viksnewsletter.com/p/origami-inspired-phased-arrays: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Lesser known parts of Python standard library – Trickster Dev (174 pts)]]></title>
            <link>https://www.trickster.dev/post/lesser-known-parts-of-python-standard-library/</link>
            <guid>41450824</guid>
            <pubDate>Wed, 04 Sep 2024 21:07:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.trickster.dev/post/lesser-known-parts-of-python-standard-library/">https://www.trickster.dev/post/lesser-known-parts-of-python-standard-library/</a>, See on <a href="https://news.ycombinator.com/item?id=41450824">Hacker News</a></p>
Couldn't get https://www.trickster.dev/post/lesser-known-parts-of-python-standard-library/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Internet Archive loses appeal over eBook lending (198 pts)]]></title>
            <link>https://www.theverge.com/2024/9/4/24235958/internet-archive-loses-appeal-ebook-lending</link>
            <guid>41449229</guid>
            <pubDate>Wed, 04 Sep 2024 18:56:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/9/4/24235958/internet-archive-loses-appeal-ebook-lending">https://www.theverge.com/2024/9/4/24235958/internet-archive-loses-appeal-ebook-lending</a>, See on <a href="https://news.ycombinator.com/item?id=41449229">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The Internet Archive has lost its appeal in a fight to lend out scanned ebooks without the approval of publishers. In a <a href="https://www.documentcloud.org/documents/25091194-internet-archive-appeal?responsive=1&amp;title=1">decision on Wednesday</a>, the Second Circuit Court of Appeals ruled that permitting the Internet Archive’s digital library would “allow for widescale copying that deprives creators of compensation and diminishes the incentive to produce new works.”</p><p>The decision is another blow to the nonprofit in the <em>Hachette v. Internet Archive</em> case. In 2020, four major publishers — Hachette, Penguin Random House, Wiley, and HarperCollins — <a href="https://www.theverge.com/2020/6/1/21277036/internet-archive-publishers-lawsuit-open-library-ebook-lending">sued the Internet Archive</a> over claims its digital library constitutes “willful digital piracy on an industrial scale.”</p><p>The Internet Archive has long offered a system called the Open Library, where users can “check out” digital scans of physical books. The library was based on a principle called controlled digital lending, where each loan corresponds to a physically purchased book held in a library — avoiding, in theory, a piracy claim. It’s a fundamentally different system from programs like OverDrive, where publishers sell limited-time licenses to ebooks on their own terms.</p><p>However, the Internet Archive <a href="https://blog.archive.org/2020/03/30/internet-archive-responds-why-we-released-the-national-emergency-library/">expanded its library project during the covid-19 pandemic</a>. It launched the National Emergency Library, allowing an unlimited number of people to access the same copies of ebooks. That’s when the publishers banded together to file the lawsuit, targeting both online libraries.</p><p>The Second Circuit Court’s decision acknowledges the benefits and drawbacks of the Internet Archive’s digital library in its decision. But it ultimately sides with publishers:</p><div><blockquote><p>On the one hand, eBook licensing fees may impose a burden on libraries and reduce access to creative work. On the other hand, authors have a right to be compensated in connection with the copying and distribution of their original creations. Congress balanced these “competing claims upon the public interest” in the Copyright Act. We must uphold that balance here.</p></blockquote></div><div><p>Last year, <a href="https://www.theverge.com/2023/3/24/23655804/internet-archive-hatchette-publisher-ebook-library-lawsuit">a federal judge ruled that the Internet Archive</a> doesn’t have the right to scan and lend out books in the same way a library would. The Internet Archive later <a href="https://www.theverge.com/2023/9/11/23868870/internet-archive-hachette-open-library-copyright-lawsuit-appeal">appealed that decision</a>. </p></div><p>“We are disappointed in today’s opinion about the Internet Archive’s digital lending of books that are available electronically elsewhere,” Chris Freeland, the director of library services at the Internet Archive, <a href="https://blog.archive.org/2024/09/04/internet-archive-responds-to-appellate-opinion/">writes in a post on the site</a>. “We are reviewing the court’s opinion and will continue to defend the rights of libraries to own, lend, and preserve books.” Freeland also <a href="https://www.change.org/p/let-readers-read-an-open-letter-to-the-publishers-in-hachette-v-internet-archive?utm_medium=custom_url&amp;utm_source=share_petition&amp;recruited_by_id=eb10e620-2915-11ef-99de-71750e499499">points to a petition</a> you can sign to restore access to the 500,000 books publishers restricted access to.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kagi: Announcing The Assistant (457 pts)]]></title>
            <link>https://blog.kagi.com/announcing-assistant</link>
            <guid>41448985</guid>
            <pubDate>Wed, 04 Sep 2024 18:35:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.kagi.com/announcing-assistant">https://blog.kagi.com/announcing-assistant</a>, See on <a href="https://news.ycombinator.com/item?id=41448985">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
            <div>
  <p>
    <iframe width="800" height="450" src="https://www.youtube-nocookie.com/embed/0cMcOtVQUkE?si=0cMcOtVQUkE&amp;rel=0&amp;vq=hd1080" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
  </p>
</div>
<p><em>Yes, the rumours are true!</em></p>

<p>Kagi has been thoughtfully integrating AI into our search experience, creating a smarter, faster, and more intuitive search. This includes <a href="https://help.kagi.com/kagi/ai/quick-answer.html">Quick Answer</a> which delivers knowledge instantly for many searches (can be activated by appending ? to the end of your searches), <a href="https://help.kagi.com/kagi/ai/summarize-page.html">Summarize Page</a> for the quick highlights of a web page, and even the ability to <a href="https://help.kagi.com/kagi/ai/ask-questions.html">ask questions about a web page</a> in your search results. And all of these features are on-demand and ready when you need them.</p>

<p>Today we’re excited to unveil the Assistant by Kagi.  A user friendly Assistant that has everything you want and none of the things you don’t (such as user data harvesting, ads &amp; tracking).  Major features include:</p>

<ul>
<li>Integration with Kagi’s legendary quality search results<br>
</li>
<li>Choice of leading LLM models from all the leading providers (OpenAI, Anthropic, Google, Mistral, …)<br>
</li>
<li>Powerful Custom Assistants that include your own custom instructions, choice of leading models, and tools like search and internet access<br>
</li>
<li>Mid-thread editing and branching for making the most of your conversations without starting over<br>
</li>
<li>All threads are private by default, retained only as long as you want and subscriber data is not used for training models.</li>
</ul>

<h2>Powered by Kagi Search</h2>

<p>Kagi Assistant has the ability to use Kagi Search to source the highest quality information meaning that its responses are grounded in the most up-to-date factual information while disregarding most “spam” and “made for advertising” sites with our unique ranking algorithm and user search personalizations on top.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725361807-334029-upload-5b01ebb868ee82236b769125e19d2b10.png" alt="image">
</p><center><em>Assistant with References</em></center>

<h2>Choice of Best Models</h2>

<p>Kagi Assistant provides the best in class capabilities for coding, information retrieval, problem solving, brainstorming, creative writing, and other LLM applications by leveraging the finest LLM models available. You can select from any model and switch whenever you like. The Assistant can always make use of the latest models as they become available. In addition, you can decide whether to give the model web access (via Kagi Search) or you want to use the model in ‘raw’ mode.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725361807-99305-upload-0c181df6fd10988592f870adcabf9142.png" alt="image">
</p><center><em>Model Selection</em></center>

<h2>Powerful Custom Assistants</h2>

<p>LLMs are incredibly flexible tools you can use for many tasks.  With Kagi’s Custom Assistants you can build a tool that meets your exact needs.  For example you may be a car enthusiast and are looking for advice about your VW Bus.</p>

<p>You could create a Custom Assistant to help with the myriad of questions a owner of a classic vehicle might have.  Start by naming your Custom Assistant and select the tools and options.<br>
<img src="https://kagifeedback.org/assets/files/2024-09-03/1725389662-205507-image.png" alt="image">
</p><center><em>Custom Assistant Options</em></center>

<p><br>
Then give the Custom Assistant context and clear instructions on how it should respond.  In this case providing relevant details on your car and guidelines for the advice.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725389665-535788-image2.png" alt="image">
<em></em></p><center><em>Custom Assistant Instructions</em></center>

<p>Use the Custom Assistant to get the answers you need with the context and instructions provided.  Here the model provides relevant advice on diagnosing a oil leak.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725389839-290214-image3.png" alt="image">
<em></em></p><center><em>Using Custom Assistant</em></center>

<h2>Mid-Thread Editing and Branching</h2>

<p>Any LLM user has seen that sometimes they can get data wrong, hallucinate or just become confused.  Or we might want to refine our prompt as we see how a model responds. For instance if you’re interested in understanding how to handle imbalanced data sets you might ask Assistant:</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725361806-569146-upload-744debb8ceb4547fd753110a30e3c18a.png" alt="image"></p>

<center><em>Starting a Thread</em></center>


<p>The response is correct, but a little too generic; you can edit the question and add that you’re working on a binary classification problem to get a more specific answer.  You could even switch the model or turn on/off web access.<br>
<img src="https://kagifeedback.org/assets/files/2024-09-03/1725361806-385380-upload-5a8180e572dc07ebe4ac4c8be278b5fc.png" alt="image">
</p><center><em>Editing the Prompt to add Specifics</em></center>

<p><br>
Clarifying the question yields much more useful advice but if it didn’t you could just go back to the original branch and continue on.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725361806-284938-upload-baca920305f0b650338782e0d3e109a3.png" alt="image"></p>

<center><em>Updated Answer with New Detail &amp; Branch Navigation</em></center>

<h2>Private by Default</h2>

<p>We know many of you are concerned about what AI companies may be doing with your data. According to a <a href="https://www.pewresearch.org/internet/2023/10/18/how-americans-view-data-privacy/">survey by the Pew Research Center</a> about 80% of people “familiar with AI say its use by companies will lead to people’s personal information being used in ways they won’t be comfortable with (81%) or that weren’t originally intended (80%)” and “Among those who’ve heard about AI, 70% have little to no trust in companies to make responsible decisions about how they use it in their products.”</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725386335-668027-pi-20231018-data-privacy-0-04.webp"></p>



<p>Kagi is committed to protecting your information. Your threads automatically expire and are deleted according to your settings (default is after 24 hours) and you can choose to save threads you really need for later.  This approach helps not only with protecting your data, but with managing the thread clutter as well.
<img src="https://kagifeedback.org/assets/files/2024-09-03/1725391573-898057-screenshot-2024-09-03-at-122557.png" alt="image">
</p><center><em>Thread Saving Settings</em></center>


<p>Since we don’t show ads (and never will) and don’t train on subscriber data there’s no reason for us to harvest your data, track your clicks, searches, threads, or build a profile of you.  When we use third party models via their APIs it is protected under terms of service that forbid using data for training their models (e.g. <a href="https://support.anthropic.com/en/articles/7996885-how-do-you-use-personal-data-in-model-training">Anthropic Terms</a> &amp; <a href="https://ai.google.dev/gemini-api/terms#data-use-paid">Google Terms</a>).</p>

<h2>Pricing &amp; Availability</h2>

<p>The Assistant by Kagi is available today as part of the Kagi Ultimate Plan for $25 per month, which also includes full access to Kagi Search. Discount available for annual subscriptions.  <a href="https://kagi.com/">Learn more at Kagi.com</a>.</p>

<h2>FAQ:</h2>

<p><strong>Q:</strong> Can I try out Assistant today?<br>
<strong>A:</strong> Yes, the Assistant is generally available today to all Kagi Ultimate tier members   You can create an account today to try it out and cancel at any time with no long term commitments.</p>

<p><strong>Q:</strong> Is the Assistant available in Kagi’s Starter or Professional tier?<br>
<strong>A:</strong> As of today the Assistant is only available on our Ultimate tier (and Family plan members upgraded to Ultimate tier).  We are always looking for ways to provide more value to our members and are evaluating how we can offer Assistant to the Starter and Professional tiers.</p>

<p><strong>Q:</strong> What are the LLM limitations in place?<br>
<strong>A:</strong> The Assistant currently has no hard limits on usage. We would like it to stay unlimited and will be monitoring this actively. Please do not abuse so everyone can enjoy no-limit access. Provider APIs may have limitations in place.</p>

<p><strong>Q:</strong> Does the Assistant have file upload capability?<br>
<strong>A:</strong> The Assistant will have file upload capabilities very soon (work in progress). You can still access beta version that had it using <a href="https://kagi.com/v1_assistant">this link</a>.</p>

<p><strong>Q:</strong> I found a bug in Assistant, how do I report it?<br>
<strong>A:</strong> Please report all bugs and feature suggestions using <a href="https://kagifeedback.org/">Kagi Feedback</a>.</p>

<p><strong>Q:</strong> What is Kagi’s overall strategy about using LLMs in search?<br>
<strong>A:</strong> We are continuing to relentlessly focus on the core search experience and build thoughtfully integrated features on top of it. Read more about it in our <a href="https://blog.kagi.com/what-is-next-for-kagi#8">recent blog post</a>.</p>

        </div></div>]]></description>
        </item>
    </channel>
</rss>