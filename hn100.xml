<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 20 Dec 2023 12:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[LLM in a Flash: Efficient LLM Inference with Limited Memory (171 pts)]]></title>
            <link>https://huggingface.co/papers/2312.11514</link>
            <guid>38704982</guid>
            <pubDate>Wed, 20 Dec 2023 03:02:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huggingface.co/papers/2312.11514">https://huggingface.co/papers/2312.11514</a>, See on <a href="https://news.ycombinator.com/item?id=38704982">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div data-props="{&quot;comments&quot;:[{&quot;id&quot;:&quot;65825e287cec0a2080cbaf0b&quot;,&quot;author&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/88bb4c4a67dc8958069e9014f5e73a0b.svg&quot;,&quot;fullname&quot;:&quot;Michael Barry&quot;,&quot;name&quot;:&quot;MichaelBarryUK&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false},&quot;createdAt&quot;:&quot;2023-12-20T03:23:20.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;💩&quot;,&quot;html&quot;:&quot;<p>💩</p>\n&quot;,&quot;updatedAt&quot;:&quot;2023-12-20T03:23:20.638Z&quot;,&quot;author&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/88bb4c4a67dc8958069e9014f5e73a0b.svg&quot;,&quot;fullname&quot;:&quot;Michael Barry&quot;,&quot;name&quot;:&quot;MichaelBarryUK&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false}},&quot;numEdits&quot;:0,&quot;editors&quot;:[&quot;MichaelBarryUK&quot;],&quot;reactions&quot;:[{&quot;reaction&quot;:&quot;😔&quot;,&quot;users&quot;:[&quot;nlpguy&quot;,&quot;10100101j&quot;,&quot;IsoSpandy&quot;,&quot;hyper88&quot;,&quot;saidattax&quot;],&quot;count&quot;:5}],&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.7121967673301697},&quot;isReport&quot;:false}}],&quot;primaryEmailConfirmed&quot;:false,&quot;paper&quot;:{&quot;id&quot;:&quot;2312.11514&quot;,&quot;authors&quot;:[{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af2&quot;,&quot;name&quot;:&quot;Keivan Alizadeh&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af3&quot;,&quot;name&quot;:&quot;Iman Mirzadeh&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af4&quot;,&quot;user&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/8e440bdf6241be32ea45f72d3f00e05b.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Dmitry Belenko&quot;,&quot;user&quot;:&quot;depthwise&quot;,&quot;type&quot;:&quot;user&quot;},&quot;name&quot;:&quot;Dmitry Belenko&quot;,&quot;status&quot;:&quot;admin_assigned&quot;,&quot;statusLastChangedAt&quot;:&quot;2023-12-20T08:59:28.800Z&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af5&quot;,&quot;name&quot;:&quot;Karen Khatamifard&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af6&quot;,&quot;name&quot;:&quot;Minsik Cho&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af7&quot;,&quot;name&quot;:&quot;Carlo C Del Mundo&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af8&quot;,&quot;name&quot;:&quot;Mohammad Rastegari&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af9&quot;,&quot;user&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/fc3d149a27bc8396010a2a02148e8ca0.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Mehrdad Farajtabar&quot;,&quot;user&quot;:&quot;mfarajtabar&quot;,&quot;type&quot;:&quot;user&quot;},&quot;name&quot;:&quot;Mehrdad Farajtabar&quot;,&quot;status&quot;:&quot;admin_assigned&quot;,&quot;statusLastChangedAt&quot;:&quot;2023-12-20T08:21:56.790Z&quot;,&quot;hidden&quot;:false}],&quot;publishedAt&quot;:&quot;2023-12-12T18:57:08.000Z&quot;,&quot;title&quot;:&quot;LLM in a flash: Efficient Large Language Model Inference with Limited\n  Memory&quot;,&quot;summary&quot;:&quot;Large language models (LLMs) are central to modern natural language\nprocessing, delivering exceptional performance in various tasks. However, their\nintensive computational and memory requirements present challenges, especially\nfor devices with limited DRAM capacity. This paper tackles the challenge of\nefficiently running LLMs that exceed the available DRAM capacity by storing the\nmodel parameters on flash memory but bringing them on demand to DRAM. Our\nmethod involves constructing an inference cost model that harmonizes with the\nflash memory behavior, guiding us to optimize in two critical areas: reducing\nthe volume of data transferred from flash and reading data in larger, more\ncontiguous chunks. Within this flash memory-informed framework, we introduce\ntwo principal techniques. First, \&quot;windowing'\&quot; strategically reduces data\ntransfer by reusing previously activated neurons, and second, \&quot;row-column\nbundling\&quot;, tailored to the sequential data access strengths of flash memory,\nincreases the size of data chunks read from flash memory. These methods\ncollectively enable running models up to twice the size of the available DRAM,\nwith a 4-5x and 20-25x increase in inference speed compared to naive loading\napproaches in CPU and GPU, respectively. Our integration of sparsity awareness,\ncontext-adaptive loading, and a hardware-oriented design paves the way for\neffective inference of LLMs on devices with limited memory.&quot;,&quot;upvotes&quot;:33},&quot;canReadDatabase&quot;:false,&quot;canManageCommunity&quot;:false,&quot;hasHfLevelAccess&quot;:false,&quot;publishedOnDailyAt&quot;:&quot;2023-12-20T02:32:43.361Z&quot;,&quot;upvoted&quot;:false,&quot;upvoters&quot;:[{&quot;avatarUrl&quot;:&quot;/avatars/2e476fce12c4d48bb1f0ac3e68ddc209.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Kaio Ken&quot;,&quot;user&quot;:&quot;kaiokendev&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/1b4c9afab0c4b10ac50fca0c738bb61a.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;lbn&quot;,&quot;user&quot;:&quot;llbn&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1637711517996-6039478ab3ecf716b1a5fd4d.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:true,&quot;fullname&quot;:&quot;taesiri&quot;,&quot;user&quot;:&quot;taesiri&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/358503a958bacff790c5830f24946378.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Xin&quot;,&quot;user&quot;:&quot;Nuclear6&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1649899774659-6254f8e5d21e4cc386b881ad.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Somshubra Majumdar&quot;,&quot;user&quot;:&quot;smajumdar94&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62ce50353529c21a228ab2d8/153N-GZ0Vj5YXWMW3noQe.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Se June Joo&quot;,&quot;user&quot;:&quot;Joocjun&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/d44dee29d7aae9e545cb7847d835bae7.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Aiden Shihadeh&quot;,&quot;user&quot;:&quot;sdkv2&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/1e9617311b04bbf296f061a9a85b12cc.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Ai Studio Lab&quot;,&quot;user&quot;:&quot;aistudiolab&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Arthur Zucker&quot;,&quot;user&quot;:&quot;ArthurZ&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/d6f733991b3011ce53c9055f3083332f.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Erland Hilman Fuadi&quot;,&quot;user&quot;:&quot;Masa-Erland&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/637b53a7a2460cde612b127b/urzriWZ00OvHgESYnBlKX.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Krinal Joshi&quot;,&quot;user&quot;:&quot;krinal&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/8860b175ae0d292bb5ad8502a97b9b9f.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Mous&quot;,&quot;user&quot;:&quot;Anony&quot;,&quot;type&quot;:&quot;user&quot;}],&quot;acceptLanguages&quot;:[&quot;*&quot;]}" data-target="PaperContent">

<div><h2>Abstract</h2>
	<p>Large language models (LLMs) are central to modern natural language
processing, delivering exceptional performance in various tasks. However, their
intensive computational and memory requirements present challenges, especially
for devices with limited DRAM capacity. This paper tackles the challenge of
efficiently running LLMs that exceed the available DRAM capacity by storing the
model parameters on flash memory but bringing them on demand to DRAM. Our
method involves constructing an inference cost model that harmonizes with the
flash memory behavior, guiding us to optimize in two critical areas: reducing
the volume of data transferred from flash and reading data in larger, more
contiguous chunks. Within this flash memory-informed framework, we introduce
two principal techniques. First, "windowing'" strategically reduces data
transfer by reusing previously activated neurons, and second, "row-column
bundling", tailored to the sequential data access strengths of flash memory,
increases the size of data chunks read from flash memory. These methods
collectively enable running models up to twice the size of the available DRAM,
with a 4-5x and 20-25x increase in inference speed compared to naive loading
approaches in CPU and GPU, respectively. Our integration of sparsity awareness,
context-adaptive loading, and a hardware-oriented design paves the way for
effective inference of LLMs on devices with limited memory.</p></div>

<p><a href="https://arxiv.org/abs/2312.11514" target="_blank" rel="noreferrer">View arXiv page</a>
	<a href="https://arxiv.org/pdf/2312.11514" target="_blank" rel="noreferrer">View PDF</a>
	<a href="https://huggingface.co/login?next=%2Fpapers%2F2312.11514">
			Add to collection
		</a></p>



<div><h3>Community</h3>

	


</div>

</div>
		<section>

			<h2>
				Models citing this paper
				<span>0</span></h2>
			<p>No model linking this paper</p>
				<p>Cite arxiv.org/abs/2312.11514 in a model README.md to link it from this page.
				</p>

			<h2>
				Datasets citing this paper
				<span>0</span></h2>
			<p>No dataset linking this paper</p>
				<p>Cite arxiv.org/abs/2312.11514 in a dataset README.md to link it from this page.
				</p>

			<h3>
				Spaces citing this paper
				<span>0</span></h3>

			<p>No Space linking this paper</p>
				<p>Cite arxiv.org/abs/2312.11514 in a Space README.md to link it from this page.
				</p>

			<h2>
				Collections including this paper
				<span>5</span></h2>
			<nav>








					<a href="https://huggingface.co/collections?paper=2312.11514">Browse 5 collections that include this paper
						</a></nav></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rite Aid banned from using AI facial recognition for five years (194 pts)]]></title>
            <link>https://www.ftc.gov/news-events/news/press-releases/2023/12/rite-aid-banned-using-ai-facial-recognition-after-ftc-says-retailer-deployed-technology-without</link>
            <guid>38704830</guid>
            <pubDate>Wed, 20 Dec 2023 02:38:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ftc.gov/news-events/news/press-releases/2023/12/rite-aid-banned-using-ai-facial-recognition-after-ftc-says-retailer-deployed-technology-without">https://www.ftc.gov/news-events/news/press-releases/2023/12/rite-aid-banned-using-ai-facial-recognition-after-ftc-says-retailer-deployed-technology-without</a>, See on <a href="https://news.ycombinator.com/item?id=38704830">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span><span><span>Rite Aid will be prohibited from using facial recognition technology for surveillance purposes for five years to settle Federal Trade Commission charges that the retailer failed to implement reasonable procedures and prevent harm to consumers in its use of facial recognition technology in hundreds of stores. </span></span></span></p>



<p><span><span>“<span><span>Rite Aid's reckless use of facial surveillance systems left its customers facing humiliation and other harms, and its order violations put consumers’ sensitive information at risk," </span></span>said Samuel Levine, Director of the FTC’s Bureau of Consumer Protection. <span>“Today’s groundbreaking order makes clear that the Commission will be vigilant in protecting the public from unfair biometric surveillance and unfair data security practices.” </span></span></span></p>



<p><span><span><span><span><span><span>The <a href="https://www.ftc.gov/system/files/ftc_gov/pdf/2023190_riteaid_stipulated_order_filed.pdf">proposed order</a>&nbsp;will require Rite Aid to implement comprehensive safeguards to prevent these types of harm to consumers when deploying automated systems that use biometric information to track them or flag them as security risks. It also will require Rite Aid to discontinue using any such technology if it cannot control potential risks to consumers.</span></span> To settle charges it violated a <a href="https://www.ftc.gov/news-events/news/press-releases/2010/07/rite-aid-settles-ftc-charges-it-failed-protect-medical-financial-privacy-customers-employees">2010 Commission data security order</a> by failing to adequately oversee its service providers, Rite Aid will also be required to implement a robust information security program, which must be overseen by the company’s top executives.</span></span></span></span></p>



<p><span><span><span>In a <a href="https://www.ftc.gov/system/files/ftc_gov/pdf/2023190_riteaid_complaint_filed.pdf">complaint</a><b>&nbsp;</b>filed in federal court<b>,</b> the FTC says that from 2012 to 2020, Rite Aid deployed artificial intelligence-based facial recognition technology in order to identify customers who may have been engaged in shoplifting or other problematic behavior. The complaint, however, charges that the company failed to take reasonable measures to prevent harm to consumers, who, as a result, were erroneously accused by employees of wrongdoing because facial recognition technology falsely flagged the consumers as matching someone who had previously been identified as a shoplifter or other troublemaker. </span></span></span></p>



<p><span><span><span><span><span>Preventing the misuse of biometric information is a high priority for the FTC, </span><a href="https://www.ftc.gov/news-events/news/press-releases/2023/05/ftc-warns-about-misuses-biometric-information-harm-consumers"><span>which issued a warning earlier this year</span></a><span> that the agency would be closely monitoring this sector. Rite Aid’s actions subjected consumers to embarrassment, harassment, and other harm, according to the complaint. </span>The company did not inform consumers that it was using the technology in its stores and employees were discouraged from revealing such information. <span>Employees, acting on false positive alerts, followed consumers around its stores, searched them, ordered them to leave, called the police to confront or remove consumers, and </span><span>publicly accused them, sometimes in front of friends or family, of shoplifting or other wrongdoing, according to the complaint. In addition, the FTC says Rite Aid’s actions disproportionately impacted people of color.</span></span></span></span></span></p>



<p><span><span><span>According to the complaint, Rite Aid contracted with two companies to help create a database of images of individuals—considered to be<span> “persons of interest” because Rite Aid believed they engaged in or attempted to engage in criminal activity at one of its retail locations—along with their names and other information such as any criminal background data. The company collected tens of thousands of images of individuals, many of which were low-quality and came from Rite Aid’s security cameras, employee phone cameras and even news stories, according to the complaint.</span></span></span></span></p>



<p><span><span><span><span><span>The system generated thousands of false-positive matches, the FTC says. For example, the technology sometimes matched customers with people who had originally been enrolled in the database based on activity thousands of miles away, or flagged the same person at dozens of different stores all across the United States, according to the complaint. Specifically, the complaint says Rite Aid failed to: </span></span></span></span></span></p>



<ul><li><span><span><span><span><span>Consider and mitigate potential risks to consumers from misidentifying them, including heightened risks to certain consumers because of their race or gender. For example, Rite Aid’s facial recognition technology was more likely to generate false positives in stores located in plurality-Black and Asian communities than in plurality-White communities;</span></span></span></span></span></li>
<li><span><span><span><span>Test, assess, measure, document, or inquire about the accuracy of its facial recognition technology before deploying it, including failing to seek any information from either vendor it used to provide the facial recognition technology about the extent to which the technology had been tested for accuracy;</span></span></span></span></li>
<li><span><span><span><span>Prevent the use of low-quality images in connection with its facial recognition technology, increasing the likelihood of false-positive match alerts; </span></span></span></span></li>
</ul><ul><li><span><span><span><span><span>Regularly monitor or test the accuracy of the technology after it was deployed, including by failing to implement or enforce any procedure for tracking the rate of false positive matches or actions that were taken based on those false positive matches; and </span></span></span></span></span></li>
<li><span><span><span><span><span>Adequately train employees tasked with operating facial recognition technology in its stores and flag that the technology could generate false positives. Even after Rite Aid switched to a technology that enabled employees to report a “bad match” and required employees to use it, the company did not take action to ensure employees followed this policy.</span></span></span></span></span></li>
</ul>

<p><span><span><span><span>In its complaint, the FTC also says Rite Aid violated its </span><span>2010 data security order</span><span> with the Commission by failing to adequately implement a comprehensive information security program. Among other things, the 2010 order required Rite Aid to ensure its third-party service providers had appropriate safeguards to protect consumers’ personal data. For example, the complaint alleges the company conducted many security assessments of service providers orally, and that it failed to obtain or possess backup documentation of such assessments, including for service providers Rite Aid deemed to be “high risk.” </span></span></span></span></p>



<p><span><span><span><span><span>In addition to the ban and required safeguards for automated biometric security or surveillance systems, other provisions of the proposed order prohibit Rite Aid from misrepresenting its data security and privacy practices and also require the company to: </span></span></span></span></span></p>



<ul><li><span><span><span><span><b><span>Delete, and direct third parties to delete</span></b><span>, any images or photos they collected because of Rite Aid’s facial recognition system as well as any algorithms or other products that were developed using those images and photos;</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Notify consumers</span></b><span> when their biometric information is enrolled in a database used in connection with a biometric security or surveillance system and when Rite Aid takes some kind of action against them based on an output generated by such a system;</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Investigate and respond</span></b><span> in writing to consumer complaints about actions taken against consumers related to an automated biometric security or surveillance system;</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Provide clear and conspicuous notice</span></b><span> to consumers about the use of facial recognition or other biometric surveillance technology in its stores;</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Delete any biometric information</span></b><span> it collects within five years; </span></span></span></span></span></li>
<li><span><span><span><span><b><span>Implement a data security program</span></b><span> to protect and secure personal information it collects, stores, and shares with its vendors; </span></span></span></span></span></li>
<li><span><span><span><span><b><span>Obtain independent third-party assessments</span></b><span> of its information security program; and</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Provide the Commission with an annual certification</span></b><span> from its CEO documenting Rite Aid’s adherence to the order’s provisions.</span></span></span></span></span></li>
</ul>

<p><span><span><span><span>The Commission voted 3-0 to<span><span> authorize staff&nbsp;to file the complaint and the proposed stipulated order against Rite Aid</span></span>. Commissioner Alvaro Bedoya <a href="https://www.ftc.gov/legal-library/browse/cases-proceedings/public-statements/statement-commissioner-alvaro-m-bedoya-ftc-v-rite-aid-corporation">released a statement</a>. </span></span></span></span></p>



<p><span><span><span><span>The complaint and order were filed in the Eastern District of Pennsylvania. Rite Aid is currently going through bankruptcy proceedings and the order will go into effect after approval from the bankruptcy court and the federal district court as well as modification of the 2010 order by the Commission.</span></span></span></span></p>



<p><span><span><span><span><span>The principal attorneys on these matters are </span></span><span>Robin Wetherill, Leah Frazier, Diana Chang, Christopher Erickson, and Brian Welke in the FTC’s Bureau of Consumer Protection.</span><span><span></span></span></span></span></span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build a search engine, not a vector DB (110 pts)]]></title>
            <link>https://blog.elicit.com/search-vs-vector-db/</link>
            <guid>38703943</guid>
            <pubDate>Wed, 20 Dec 2023 00:27:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.elicit.com/search-vs-vector-db/">https://blog.elicit.com/search-vs-vector-db/</a>, See on <a href="https://news.ycombinator.com/item?id=38703943">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <p>In the last 12 months there has been a proliferation of vector DB startups. I’m not here to debate the specific design tradeoffs of any of them. Instead, I want to push back on several common approaches to what a vector database is, what it’s for, and how you should use one to solve problems.</p><h3 id="vector-databases-aren%E2%80%99t-memory">Vector databases aren’t memory</h3><p>Many vector databases frame their basic utility as solving the problem of language models lacking long term memory, or the fact that you can’t place all of the context for a question into your prompt.</p><figure><a href="https://www.trychroma.com/blog/seed?ref=blog.elicit.com"><img src="https://blog.elicit.com/content/images/2023/12/Search-Engine.png" alt="" loading="lazy" width="653" height="581" srcset="https://blog.elicit.com/content/images/size/w600/2023/12/Search-Engine.png 600w, https://blog.elicit.com/content/images/2023/12/Search-Engine.png 653w"></a><figcaption><span>https://trychroma.com/blog/seed</span></figcaption></figure><p>However, vector search is ultimately just a particular kind of search<em>.</em> Giving your LLM access to a database it can write to and search across is very useful, but it’s ultimately best conceptualized as giving an agent access to a search engine, versus actually “having more memory”.</p><p>Imagine you’re a company that wants to build an LLM-powered documentation experience. If you think of a vector database as just providing an expanded memory to your language model, you might just embed all of your company’s product docs, and then let users ask questions to your bot. When a user hits enter, you do a vector search for their query, find all of the chunks, load them into context, and then have your language model try to answer the question. In fact, that’s the approach we initially took at Stripe when I worked on their <a href="https://stripe.com/newsroom/news/stripe-and-openai?ref=blog.elicit.com">AI docs product</a>.</p><p>Ultimately though, I found that approach to be a dead-end. The crux is that while vector search is better along some axes than traditional search, it's not magic. Just like regular search, you'll end up with irrelevant or missing documents in your results. Language models, just like humans, can only work with what they have and <a href="https://arxiv.org/abs/2302.00093?ref=blog.elicit.com" rel="noreferrer">those irrelevant documents will likely mislead them</a>. </p><p>If you want to make a good RAG tool that uses your documentation, you should start by making a search engine over those documents that would be good enough for a human to use themselves. This likely something your organization has considered before, and if it doesn’t exist it’s because building a good search engine has traditionally been a significant undertaking.</p><h3 id="the-good-news">The good news</h3><p>You’ve sat down and decided to build good search, how do you actually do it? It turns out that in this case LLMs can actually save the day.</p><p>Embeddings, for all that they aren’t a magic wand, are still pretty amazing. High-quality embedding search will have a lower false negative rate than keyword search, and combining the two results in much better performance than any pure fulltext search (Google has been doing this for years with <a href="https://blog.google/products/search/search-language-understanding-bert/?ref=blog.elicit.com">BERT</a>). However, both embeddings themselves and the tools needed to use them in large-scale search, have improved by leaps and bounds. There are plenty of battle-tested databases that let you combine keyword and vector search, and I highly recommend using one of these (at Elicit we use <a href="https://vespa.ai/?ref=blog.elicit.com">Vespa</a>, but vector databases like Chroma now often support this as well).</p><p>Once you’ve improved your overall search by blending embeddings with more traditional methods, you get to the fun stuff. A savvy human trying to find information via a search engine knows how to structure their query in order to ensure they find relevant information (<a href="https://supple.com.au/tools/google-advance-search-operators/?ref=blog.elicit.com">Google-fu used to be a powerful art form</a>), language models can do the same. If your model wants to find “what’s the latest news on malaria vaccines,” you could have a language model construct a query that includes a date filter. There is a ton of low hanging fruit here, and after that an almost endless amount of tweaking that can be done to result in incredible quality search. Like in many other cases, similar things were <strong>possible</strong> in the world before LLMs, but they took a lot of specialized skill and effort. Now you can get competitive performance with a few hours of your time and some compute.</p><p>The final stage in the traditional search pipeline is re-ranking. It used to be the case that to do re-ranking you would <a href="https://www.kdd.org/kdd2016/papers/files/adf0361-yinA.pdf?ref=blog.elicit.com">train a relevancy model</a> on signals like which items a user clicks on for a given search results page, and then use that model to sort your top results. If you’re not a whole team structured around building a search engine, this isn’t a viable problem to tackle. Now with language models, you can provide some details on a query:result pair to a model and get a relevancy score that will <a href="https://arxiv.org/abs/2311.07994?ref=blog.elicit.com" rel="noreferrer">beat out all but the best purpose-built systems</a>.</p><p>Ultimately, recent advancements in AI make it much easier to build cutting-edge search, using orders of magnitude less effort than once required. Because of that, the return on sitting down and seriously building good search is extremely high.</p><p>If you want to build a RAG-based tool, first build search.</p><h3 id="postscript-the-bad-news"><em>Postscript (The bad news)</em></h3><p>You’ve built a nice search engine using the above techniques, now it’s time to deploy it. Unfortunately, language models don’t let you avoid the other half of building a search engine: evaluating it.</p><p>Specifically, this means being able to answer questions like:</p><ul><li>“When is doing a search appropriate?”</li><li>“When you do a search, what content are you actually trying to locate?”</li><li>“How high does that content rank in your results?”</li></ul><p>Answering any of those questions requires building evaluation and monitoring infrastructure that you can use to iterate on your search pipeline and know whether the changes you make are improvements. For a followup on evaluating search engines, I recommend this excellent <a href="https://dtunkelang.medium.com/evaluating-good-search-part-i-measure-it-5507b2dbf4f6?ref=blog.elicit.com">series of posts</a>.</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: Microsoft.com added 192.168.1.1 to their DNS record (415 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38702783</link>
            <guid>38702783</guid>
            <pubDate>Tue, 19 Dec 2023 22:30:52 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38702783">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38703553"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703553" href="https://news.ycombinator.com/vote?id=38703553&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Through a series of connections I know a guy that knows a guy that works at Microsoft that was made aware and the changes have been reverted. Give 'er 30 minutes TTL ;)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38703993"><td></td></tr>
            <tr id="38703779"><td></td></tr>
            <tr id="38703891"><td></td></tr>
                <tr id="38703982"><td></td></tr>
                  <tr id="38703940"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703940" href="https://news.ycombinator.com/vote?id=38703940&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>TTL appears to be set to an hour. But either way, its been 45 min and the primary ns1-39.azure-dns.com is still offering up 0.1</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38704070"><td></td></tr>
            <tr id="38703929"><td></td></tr>
            <tr id="38703720"><td></td></tr>
            <tr id="38703905"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703905" href="https://news.ycombinator.com/vote?id=38703905&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>This isn’t something that I think should be diluted.<p>If it’s that simple for a stray record to be included in the dns round robin it could have been bad if it was an external ip with a machine setup by a phisherman especially since control of a domain is all you need to get an ssl cert now.</p><p>Couple this with the fact that it’s Microsoft, one of the most relied on companies in our computer world, this is pretty darn horrible.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38704042"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38704042" href="https://news.ycombinator.com/vote?id=38704042&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>For all this to work you need to control the domain.
Is that easier than simply breaking into their systems and owning their servers?</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38704217"><td></td></tr>
            <tr id="38703917"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703917" href="https://news.ycombinator.com/vote?id=38703917&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Wait wait wait wait. Bunny.net accidentally changed their DNS to 127.0.0.1 and took a bunch of their CDN users down today too. Coincidence? Weird day.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38704225"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38704225" href="https://news.ycombinator.com/vote?id=38704225&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>Wait... Can DNS resolvers be configured so that RFC1918 is respected?<p>I mean: I don't expect anything less from Microsoft than doing stuff like that and it cannot affect me for I nullroute microsoft.com from my <i>unbound</i> server (<i>unboud</i> takes wildcard when nullrouting or NXDOMAINing crap domains like microsoft.com or meta.com etc., which is sweet).</p><p>However I'd expect my trusty DNS resolver to also prevent me from <i>anyone</i> not on my private LANs to impersonate addresses reserved for private uses.</p><p>Does anyone know here if it's easily doable?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38704159"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38704159" href="https://news.ycombinator.com/vote?id=38704159&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>microsoft.com is currently IPv6-only on my network, because OpenWrt's DNS rebinding protection filters out the A records:<pre><code>  $ ping -4 microsoft.com
  ping: microsoft.com: Address family for hostname not supported

  $ ping -6 microsoft.com
  PING microsoft.com(2603:1030:c02:8::14 (2603:1030:c02:8::14)) 56 data bytes
  64 bytes from 2603:1030:c02:8::14 (2603:1030:c02:8::14): icmp_seq=1 ttl=112 time=68.4 ms</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703344"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703344" href="https://news.ycombinator.com/vote?id=38703344&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>I'm trying to figure out how this could have happened, but I control so few IP addresses that many of my DNS entries are manually assigned. And you'd have to be incompetent if you have access to set DNS records and you set them to RFC 1918 addresses.<p>Anyone have any theories on how this could happen?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38703876"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703876" href="https://news.ycombinator.com/vote?id=38703876&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>I'll go with Joseph Conrad on this one.<p>"It's only those who do nothing that make no mistakes, I suppose."</p><p>Now the persons that did it have some proof that they did something.</p><p>They will surely put some check in place because there should be another adage somewhere that says that you only learn to use the handrails after you fell in the stairs.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38703738"><td></td></tr>
                <tr id="38704144"><td></td></tr>
                  <tr id="38703375"><td></td></tr>
                <tr id="38703870"><td></td></tr>
                        <tr id="38703523"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703523" href="https://news.ycombinator.com/vote?id=38703523&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>that's what happens when you buy address space from the back of a van in the parking lot ;)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38702845"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38702845" href="https://news.ycombinator.com/vote?id=38702845&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>I get it too, with .1.0 as well<pre><code>    Name: microsoft.com
    Address: 192.168.1.1

    Name: microsoft.com
    Address: 192.168.1.0
</code></pre>
"ooopsie!"</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38703802"><td></td></tr>
                <tr id="38703895"><td></td></tr>
                        <tr id="38703179"><td></td></tr>
                <tr id="38703239"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703239" href="https://news.ycombinator.com/vote?id=38703239&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>Potential timeouts for clients/workstations trying to reach microsoft.com.<p>Which entry is picked for use is generally random depending on the client.</p><p>Most systems will retry using another entry though on issues connecting through. That said, if you are on a network that is 192.168 based, trying to get to Microsoft.com may just send you to your local router!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38703419"><td></td></tr>
                  <tr id="38703525"><td></td></tr>
            <tr id="38703773"><td></td></tr>
            <tr id="38703953"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703953" href="https://news.ycombinator.com/vote?id=38703953&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>So let me see if I understand. With this DNS record, if me or Windows tries to hit “microsoft.com” there’s a 1/7 chance it hit my router instead?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38703965"><td></td></tr>
                  <tr id="38703705"><td></td></tr>
                <tr id="38703756"><td></td></tr>
                <tr id="38703834"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38703834" href="https://news.ycombinator.com/vote?id=38703834&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Do most DNS forwarders not block addresses that resolve to a local IP these days? I know dnsmasq does, and NextDNS too I think.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38704185"><td></td></tr>
            <tr id="38703969"><td></td></tr>
                <tr id="38704067"><td></td></tr>
                        <tr id="38704109"><td></td></tr>
                <tr id="38704149"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38704149" href="https://news.ycombinator.com/vote?id=38704149&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>They do: the updates are signed so our hypothetical spies would need to have a zero day in Authenticode or to have compromised the signing keys.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38703031"><td></td></tr>
            <tr id="38703826"><td></td></tr>
                <tr id="38703893"><td></td></tr>
                <tr id="38704064"><td></td></tr>
                <tr id="38704130"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38704130" href="https://news.ycombinator.com/vote?id=38704130&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Even if that is the case, if it is random, some section of DNS would send traffic to it. Maybe it was OK because most resolvers would ignore the local address on the list??</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38703958"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703958" href="https://news.ycombinator.com/vote?id=38703958&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>How the hell did that pass any sort of responsible review process at Microsoft?<p>Now Microsoft owns all your home networks, only like the default address on every home router out there...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38704063"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38704063" href="https://news.ycombinator.com/vote?id=38704063&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>You have the danger of this backwards: this is a very bad security problem <i>for Microsoft</i>, and not a problem for people outside of MS (except to the extent that we're all indirectly reliant on MS being secure). Pointing a domain at an IP address does not give you any power over than IP address, and you can point a domain at anything you want.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38704016"><td></td></tr>
            <tr id="38704040"><td></td></tr>
            <tr id="38704138"><td></td></tr>
            <tr id="38704039"><td></td></tr>
                  <tr id="38704015"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38704015" href="https://news.ycombinator.com/vote?id=38704015&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>Y'all, instead of the constant confirmed here. Just do an authoritative lookup.<p>dig +trace +short microsoft.com</p><p>NS a.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS b.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS c.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS d.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS e.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS f.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS g.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS h.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS i.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS j.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS k.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS l.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS m.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>RRSIG NS 8 0 518400 20240101050000 20231219040000 46780 . fG/YHtUJu3YMAm9Mlzzvp3xG4UCPG01aYNnlyF1HfAHdZpR+L88CVUcz NFHq9M45KjB7ZTlSFt2JvEyK/8FcavZLOthkXRREbJQswjLCbhiPQCbq tQLF+tKaNYUihqawCfjgZy1i5YwYjmphbjfzwoKo1POtepf0YCIcuLBi nQFw4Lr79O6cjyg6qlYnqaK6z4Xi5qt6ocohJafjs86LuuRo2WvmJ1IK k0ZUoAC6Qyjz4MVhqHMvQGdp7EnzjoL8Y9PTXeUuD6Ixp/Aklj2psLjD TZDPYN1q+zDd1giFyuwNRX9DG1zrxzN2lzQiLWmGKrzP3DvFWL1L2Ts1 FWjy/Q== from server 100.100.100.100 in 10 ms.</p><p>;; UDP setup with 2001:502:7094::30#53(2001:502:7094::30) for microsoft.com failed: network unreachable.</p><p>;; UDP setup with 2001:502:7094::30#53(2001:502:7094::30) for microsoft.com failed: network unreachable.</p><p>;; UDP setup with 2001:502:7094::30#53(2001:502:7094::30) for microsoft.com failed: network unreachable.</p><p>A 20.112.250.133 from server 150.171.10.39 in 20 ms.</p><p>A 20.231.239.246 from server 150.171.10.39 in 20 ms.</p><p>A 20.76.201.171 from server 150.171.10.39 in 20 ms.</p><p>A 20.70.246.20 from server 150.171.10.39 in 20 ms.</p><p>A 20.236.44.162 from server 150.171.10.39 in 20 ms.</p><p>A 192.168.1.0 from server 150.171.10.39 in 20 ms.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38704190"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38704190" href="https://news.ycombinator.com/vote?id=38704190&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Or from a bunch of dnses:<pre><code>  $ export srch="192.168.1.0"; echo "as of $(date '+%s';):"; for dns in 1.1.1.1 8.8.8.8 76.76.2.0 9.9.9.9 208.67.222.222 185.228.168.9 76.76.19.19 94.140.14.14; do dig @${dns} microsoft.com +short | grep "${srch}" &gt; /dev/null; if [  $? == 0  ]; then echo "${dns} still has ${srch} for microsoft.com"; else echo "${dns} no longer has ${srch} for microsoft.com"; fi; done
  as of 1703033639:
  1.1.1.1 still has 192.168.1.0 for microsoft.com
  8.8.8.8 still has 192.168.1.0 for microsoft.com
  76.76.2.0 still has 192.168.1.0 for microsoft.com
  9.9.9.9 still has 192.168.1.0 for microsoft.com
  208.67.222.222 still has 192.168.1.0 for microsoft.com
  185.228.168.9 still has 192.168.1.0 for microsoft.com
  76.76.19.19 still has 192.168.1.0 for microsoft.com
  94.140.14.14 still has 192.168.1.0 for microsoft.com
  $ pbpaste | sed 's;^;  ;' | pbcopy</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38703687"><td></td></tr>
                <tr id="38703952"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703952" href="https://news.ycombinator.com/vote?id=38703952&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>Well in my case (and a lot of other people), 192.168.1.1 is the local address of my home router. So if I go to microsoft.com I have a 1 in 7 chance of getting my home router instead (if I ignore the certificate warning). Other random breakage will happen depending on what that local address is assigned to for you.<p>In theory this could be leveraged for hacking, but I think that would require setup in advance.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38703740"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703740" href="https://news.ycombinator.com/vote?id=38703740&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Since 2 out of the 7 IPs are 192.168 (private ips), 2/7 visitors to microsoft.com will load the private ones assumign equal weight and not get the page to load.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703696"><td></td></tr>
                  <tr id="38703761"><td></td></tr>
                <tr id="38703793"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703793" href="https://news.ycombinator.com/vote?id=38703793&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Nah, if it's already reverted, they're good to go. A post-mortem with how something like that got through will definitely be on the table though.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703964"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703964" href="https://news.ycombinator.com/vote?id=38703964&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>I'm wondering how such a change would get "merged" in to begin with. I imagine even non-network engineers would get this huge itch having a large corporate contain a private IP in the changelist (I'm the non network engineer and can't really explain why it's bad. But it FEELS wrong and sometimes you at least need to use instinct to get another pair of eyes on something).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703975"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703975" href="https://news.ycombinator.com/vote?id=38703975&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>I hope not. Failures are on a spectrum and this was unfortunate but probably not malicious. All things considered this should be a lesson learned. There should be more failsafe mechanisms in place so juniors can fail safely and learn from them. The absolute worst thing we can do is shame an individual so they don’t attempt to try new things in fear of ridicule.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703830"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703830" href="https://news.ycombinator.com/vote?id=38703830&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>The seniors all go on leave and the interns are left to run the place. If they fired the juniors the seniors would have to come back from holiday!</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38703730"><td></td></tr>
            <tr id="38703118"><td></td></tr>
            <tr id="38702823"><td></td></tr>
            <tr id="38703700"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703700" href="https://news.ycombinator.com/vote?id=38703700&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>I don’t know man, putting microsoft.com on your router sounds like a massive reduction in latency. Congrats on the achievement.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38702903"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Linux graphics stack in a nutshell (211 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/955376/b3fba3bbfabbc411/</link>
            <guid>38702271</guid>
            <pubDate>Tue, 19 Dec 2023 21:59:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/955376/b3fba3bbfabbc411/">https://lwn.net/SubscriberLink/955376/b3fba3bbfabbc411/</a>, See on <a href="https://news.ycombinator.com/item?id=38702271">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<!-- $Id: slink-none,v 1.2 2005-11-04 22:11:18 corbet Exp $ -->
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>

<p>
Linux graphics developers often speak of <em>modern</em> Linux graphics
when they refer to  a number of individual software components and how they
interact 
with each other.
Among other things, it's a mix of kernel-managed display resources, 
Wayland for compositing, accelerated 3D rendering, and decidedly not X11.
In a two-part series, we will take a fast-paced journey
through the graphics code to see how it converts application data
to pixel data and displays it on the screen. In this installment, we look
at application rendering, Mesa internals, and the
necessary kernel features.
</p>

<h4>
Application rendering
</h4>

<p>
Graphics output starts in the application, which processes and
stores formatted data that is to be visualized.
The common data structure for visualization is the
<a href="https://en.wikipedia.org/wiki/Scene_graph">scene graph</a>, which
is 
a tree where each node stores either a model in 3D space or its
attributes. Model nodes contain the data to be visualized, such as a
game's scenery or elements of a scientific simulation. Attribute
nodes set the orientation or location of the models. Each attribute
node applies to the nodes below. To render its scene graph into an
on-screen image, an application walks the tree from top to
bottom and left to right, sets or clears the attributes and renders
the 3D models accordingly.
</p>

<p>
In the example scene graph shown below, rendering starts at the root node,
which prepares the renderer and sets the output location. The application
first takes the branch to the left and renders "Rectangle&nbsp;1" at
position (0,&nbsp;0) with the surface pattern stored in texture&nbsp;1.
The application then moves back to the root node 
and takes the branch to the right where it enters the attribute node named
"Transform". Applications describe transformations, 
such as positioning or scaling, in&nbsp;4x4 matrices that the algorithm
applies during 
the rendering process. In the example, the transform node
scales all of its child nodes by a factor of&nbsp;0.5. So rendering
"Rectangle&nbsp;2" 
and "Rectangle&nbsp;3" displays them at half their original sizes, with their
positions adjusted to (10,&nbsp;10) and (15,&nbsp;15), respectively. Both
rectangles
use different textures:&nbsp;2 and&nbsp;3, respectively.
</p>

<blockquote>
<img src="https://static.lwn.net/images/2023/scenegraph.png" alt="[Scene graph]" title="Scene graph">
</blockquote>


<p>
To simplify rendering and make use of hardware acceleration, most
applications utilize one of the standard APIs, such as
<a href="https://opengl.org/">OpenGL</a>
or
<a href="https://vulkan.org/">Vulkan</a>.
Details vary among the individual APIs, but each provides interfaces
to manage graphics memory, fill it with data, and render the
stored information. The result is an image that the application can
either display as-is or use as input data to further processing.
</p>

<p>
All graphics data is held in buffer objects, each of which is a
range of graphics memory with a handle or ID attached. For example,
each 3D model is stored in a
<a href="https://en.wikipedia.org/wiki/Vertex_buffer_object">vertex-buffer object</a>,
each texture is stored in a <a href="https://www.khronos.org/opengl/wiki/Texture">texture-buffer object</a>, each object's <a href="https://en.wikipedia.org/wiki/Normal_(geometry)">surface
normals</a> are stored in a buffer object, and so on. The output image
is itself <a href="https://www.khronos.org/opengl/wiki/Framebuffer_Object">stored in a buffer object</a>. So graphics rendering is, in large
part, an exercise in memory management.
</p>

<p>
The application can provide input data in any format, as long as
the graphics shader can process it. A
<a href="https://en.wikipedia.org/wiki/Shader">shader</a>
is a program that contains the instructions to transform the input
data into an output image. It is provided by the application and executed by the
graphics card.
</p>

<p>
Real-world shader programs can implement
complex, multi-pass algorithms, but for this example we break it
down to the minimum required. Probably the two most common operations
in shaders are vertex transformations and texture lookups. We can think
of a vertex as a corner of a polygon. Written in
<a href="https://www.khronos.org/opengl/wiki/OpenGL_Shading_Language">OpenGL
Shading Language</a> (GLSL),
transforming a vertex looks like this:
</p>

<pre>    uniform mat4 Matrix; // same for all of a rectangles's vertices
    in vec4 inVertexCoord; // contains a different vertex coordinate on each invocation

    gl_Position = Matrix * inVertexCoord;
</pre>


<p>
The variable <tt>inVertexCoord</tt> is an input coordinate coming from the
application's scene graph. The variable <tt>gl_Position</tt>
is the coordinate within the application's output buffer. In broad terms,
the former coordinate is within the displayed scenery, while the latter is
within the application window.
<tt>Matrix</tt> is the&nbsp;4x4 matrix that describes the transformation between
the two coordinate systems. This shader operation runs for each vertex in
the scene graph. In the example of the application's scene graph of
rectangles above, <tt>inVertexCoord</tt> contains each vertex of each rectangle
at least once. The matrix <tt>Matrix</tt> then contains that vertex's
transformation, such as moving it to the correct position or scaling it by
the factor of&nbsp;0.5 as specified in the transform node.
</p>

<p>
Once the vertices are transformed to the output coordinate system, the
shader program computes the values of the covered "fragments",
which is graphics jargon for an output pixel with a depth value along the Z
axis and
maybe other information. Each fragment requires a color. In GLSL, the
shader's <tt>texture()</tt> function retrieves the color from a texture
like this:
</p>

<pre>    uniform sampler2D Tex; // the texture object of the current rectangle
    in vec2 vsTexCoord; // interpolated texture coordinate for the fragment

    Color = texture(Tex, vsTexCoord);
</pre>


<p>
Here, <tt>Tex</tt> represents a texture buffer. The value <tt>vsTexCoord</tt>
is the texture coordinate; the position where to read within the texture.
Using both values, <tt>texture()</tt> returns a
color value. Assigning it to <tt>Color</tt> writes a colored pixel to the
output buffer. To fill the output buffer with pixel data, this shader code runs
for each individual fragment. The texture buffer is designated by the model
that is being drawn, the texture coordinate is provided by OpenGL's
internal computation. For the example scene graph, the application invokes
this code for each of the rectangles using that rectangle's texture buffer.
</p>

<p>
Running these shader instructions on the whole scene graph generates the
complete output image for the application.
</p>

<h4>
Mesa
</h4>

<p>
Nothing we have discussed so far is specific to Linux, but it gives us the
framework to look at how it's all implemented. On Linux, the
<a href="https://mesa3d.org/">Mesa&nbsp;3D</a>
library, Mesa for short, implements 3D rendering interfaces and support
for various graphics hardware. To applications, it provides OpenGL or
Vulkan for desktop graphics,
<a href="https://www.khronos.org/opengles/">OpenGL ES</a>
for mobile systems, and
<a href="https://www.khronos.org/opencl/">OpenCL</a>
for computation. On the hardware side, Mesa implements drivers for most
of today's graphics hardware.
</p>

<p>
Mesa drivers generally do not implement these application interfaces by
themselves as Mesa contains plenty of helpers and abstractions.
For stateful interfaces, such as OpenGL, Mesa's
<a href="https://www.freedesktop.org/wiki/Software/gallium/">Gallium3D</a>
framework connects interfaces and drivers
with each other. This is called a state tracker. Mesa contains
state trackers for various versions of OpenGL, OpenGL ES, and OpenCL. When the
application uses 
the API, it modifies the state tracker for the given interface.
</p>

<p>
A hardware driver within Mesa further converts the state-tracker information
to hardware state and rendering instructions.
For example, calling OpenGL's
<a href="https://registry.khronos.org/OpenGL-Refpages/gl4/html/glBindTexture.xhtml"><tt>glBindTexture()</tt></a>
selects the current texture buffer within the OpenGL
state tracker. The hardware driver then installs the texture-buffer
object in graphics memory and links the active shader program to
refer to the buffer object as its texture. In our example above, the
texture becomes available as <tt>Tex</tt> in the
shader program.
</p>

<p>
Vulkan is a stateless interface, so Gallium3D is not useful
for those drivers; Mesa instead offers the <a href="https://docs.mesa3d.org/vulkan/index.html">Vulkan runtime</a> to help
with their 
implementation. If there is a Vulkan driver available, though, there
might not be a need for Gallium3D-based OpenGL support at all for
that hardware.
<a href="https://docs.mesa3d.org/drivers/zink.html">Zink</a>
is a Mesa driver that maps Gallium3D to Vulkan. With Zink, OpenGL state
turns into Gallium3D state, which is then forwarded to hardware via standard
Vulkan interfaces. In principle, this works with any hardware's Vulkan
driver. One can imagine that future drivers within Mesa only implement
Vulkan and rely on Zink for OpenGL compatibility.
</p>

<p>
Besides Gallium3D, Mesa provides more helpers, such as winsys or GBM, to
its hardware 
drivers. Winsys wraps the details of the
window system. GBM, the Generic Buffer Manager, simplifies buffer-object
allocation.
There are also a number of shader languages, such as
GLSL
or
<a href="https://www.khronos.org/spir/">SPIR-V</a>,
available to the application.  Mesa compiles the
application-provided shader code to the "New Interface Representation" or
NIR, which Mesa drivers turn into 
hardware instructions. To get the shader instructions and the associated
data processed by Mesa's hardware acceleration, their buffer objects have
to be stored in memory locations accessible to the graphics card.
</p>

<h4>
Kernel memory management
</h4>

<p>
Any memory accessible to the graphics hardware is commonly subsumed under
the umbrella term of graphics memory; it is the graphics
stack's central resource, as all of the stack's components interact with
it. On the hardware side, graphics memory comes in a variety of
configurations that range from dedicated memory on discrete graphics
adapters to regular system memory of system-on-chip (SoC) boards. In between are
graphics chips with DMA-able or 
<a href="https://en.wikipedia.org/wiki/Shared_graphics_memory">shared graphics memory</a>,
<a href="https://en.wikipedia.org/wiki/Graphics_address_remapping_table">graphics
address remapping table</a> (GART) memory
of discrete devices, or the so-called stolen graphics memory
of on-board graphics.
</p>

<p>
Being a system-wide resource, graphics memory is maintained by the kernel's
<a href="https://en.wikipedia.org/wiki/Direct_Rendering_Manager">Direct
Rendering Manager</a> (DRM)
subsystem. To access DRM functionality, Mesa opens
the graphics card's device file under <tt>/dev/dri</tt>, such as
<tt>/dev/dri/renderD128</tt>. As required by its
user-space counterparts, DRM exposes graphics memory in the form
of buffer objects, where each buffer object represents a slice of the
available memory.
</p>

<p>
The DRM framework provides a number of memory managers for the most
common cases. The DRM drivers for the discrete graphics cards
from AMD, NVIDIA, and (soon) Intel use the <a href="https://docs.kernel.org/gpu/drm-mm.html">Translation Table Manager</a>
(TTM). It supports discrete graphics memory, GART memory, and system memory.
TTM can move buffer objects between these areas, so if the device's
discrete memory fills up, unused buffer objects can be swapped out to
system memory.
</p>

<p>
Drivers for simple framebuffer devices often use the
SHMEM helpers, which allocate buffer objects in shared memory. Here,
regular system memory acts as a shadow buffer for the device's
limited resources. The graphics driver maintains the device's
graphics memory internally, but exposes buffer objects in system memory
to the outside. This also makes it
possible to memory-map buffer objects of devices on the USB or I2C bus,
even though these buses do not support page mappings of
device memory;  the shadow buffer can be mapped instead.
</p>

<p>
The other common
allocator, the DMA helper, manages buffer
objects in DMA-able areas of the physical memory. This design is often used
in SoC boards, where graphics chips fetch and store data via DMA operations.
Of course, DRM drivers with additional requirements have the option of extending
one of the existing memory managers or implementing their own.
</p>

<p>
The <tt>ioctl()</tt> interface for managing buffer objects is called the <a href="https://docs.kernel.org/gpu/drm-mm.html#the-graphics-execution-manager-gem">Graphics 
Execution Manager</a> (GEM). Each DRM driver implements GEM according to its
hardware's 
features and requirements.
The GEM interface allows mapping a buffer object's memory pages to user-space
or kernel address space, allows pinning the pages at a certain location, or
exporting them to other drivers. For example, an application in user space
can get access to a buffer object's memory pages by invoking <tt>mmap()</tt>
with the
correct offset on the DRM device file's file descriptor. The call will eventually
end up in the DRM driver's GEM code, which sets up the mapping. As we will see
below, it's a useful feature for software rendering.
</p>

<p>
The one common operation that GEM does not provide is buffer allocation.
Each buffer object has a specific use case, which affects and is affected by
the object's allocation parameters, memory location, or hardware constraints.
Hence, each DRM driver offers a dedicated <tt>ioctl()</tt> operation for buffer-object
allocation that captures these hardware-specific settings. The DRM driver's
counterpart in Mesa invokes said <tt>ioctl()</tt> operation accordingly.
</p>

<h4>
Rendering operations
</h4>

<p>
Just having buffer objects for storing the output image, the input data, and
the shader programs is not enough. To start rendering, Mesa instructs DRM to
put all necessary buffer objects in graphics memory and invokes the
active shader program. It's again all specific to the hardware and provided
as <tt>ioctl()</tt> operations by each DRM driver individually. As with buffer allocation,
the hardware driver within Mesa invokes the DRM driver's <tt>ioctl()</tt> operations.
For Mesa drivers based on Gallium3D, this happens when the driver converts the
state tracker information into hardware state.
</p>

<p>
The graphics driver ideally acts only as a proxy between the application
in user space and the hardware. The hardware renderer runs asynchronously to
the rest of the graphics stack and reports back to the driver only in
case of an error or on successful completion; much like the system CPU
informs the operating system on page faults or illegal instructions. As long
as there's nothing to report, driver overhead is minimal. There are
exceptions; for example, older models of Intel graphics chips do not
support 
vertex transformations, so the driver within Mesa has to implement them in
software. On the Raspberry Pi, the kernel's DRM driver has to validate each
shader's memory access, as the VideoCore&nbsp;4 chip does not contain
an I/O MMU to isolate the shader from the system.
</p>

<h4>
Software rendering
</h4>

<p>
So far, we have assumed hardware support for graphics rendering. What if
there's no such support or the user-space application cannot use it? For
example, a user-space GUI toolkit might prefer rendering in
software because hardware-centric interfaces like OpenGL do not fit its needs.
And there's Plymouth, the program that displays the boot-up logo and prompts
for disk-encryption passwords during boot, which usually does not have a full
graphics stack available. For these scenarios, DRM offers the dumb-buffer
<tt>ioctl()</tt> interface.
</p>

<p>
By utilizing dumb buffers, an application allocates
buffer objects in graphics memory, but without support for hardware
acceleration. So any returned buffer object is only usable with software
rendering. The application in user space, such as a GUI
toolkit or Plymouth, maps the buffer object's pages into its address space
and copies over the output image. Mesa's software renderer works similarly:
the input buffer objects all live in system memory and the system CPU
processes the shader instructions. The output buffer is a dumb-buffer
object that stores the rendered image. While that's neither fast nor fancy,
it's good enough to run a modern desktop environment on simple hardware that
does not support accelerated rendering.
</p>

<p>
We have now gone through the application's graphics stack for rendering. After
having completed the traversal of the scene graph, the application's output
buffer object contains the visualized scenery or data that it wants to
display. But the buffer is not 
yet on the screen. Whether accelerated or dumb, putting the buffer on the
screen requires compositing and mode setting, which form the other half of
the graphics stack. In part&nbsp;2, we will look at Wayland
compositing, setting display modes with DRM, and a few other features of the
graphics stack.
</p><br clear="all"><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Device_drivers-Graphics">Device drivers/Graphics</a></td></tr>
            <tr><td><a href="https://lwn.net/Archives/GuestIndex/">GuestArticles</a></td><td><a href="https://lwn.net/Archives/GuestIndex/#Zimmermann_Thomas">Zimmermann, Thomas</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/955376/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VideoPoet A large language model for zero-shot video generation (116 pts)]]></title>
            <link>https://sites.research.google/videopoet/</link>
            <guid>38702141</guid>
            <pubDate>Tue, 19 Dec 2023 21:47:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sites.research.google/videopoet/">https://sites.research.google/videopoet/</a>, See on <a href="https://news.ycombinator.com/item?id=38702141">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<h3 size="3">
<p>Quick Links</p>
</h3>
<p>To view additional results, please also visit our other pages:</p>
<p><a target="_blank" href="http://sites.research.google/videopoet/text-to-video">Text-to-Video</a> - <a target="_blank" href="http://sites.research.google/videopoet/image-to-video">Image-to-Video</a> - <a target="_blank" href="http://sites.research.google/videopoet/video-editing">Video Editing</a> - <a target="_blank" href="http://sites.research.google/videopoet/stylization">Stylization</a> - <a target="_blank" href="http://sites.research.google/videopoet/inpainting">Inpainting</a></p>

<h3 size="3">
<p>Authors</p>
</h3>
<p>Dan Kondratyuk*, Lijun Yu*, Xiuye Gu*, José Lezama*, Jonathan Huang, Rachel Hornung, Hartwig Adam, Hassan Akbari, Yair Alon, Vighnesh Birodkar, Yong Cheng, Ming-Chang Chiu,&nbsp;Josh Dillon, Irfan Essa, Agrim Gupta, Meera Hahn, Anja Hauth, David Hendon, Alonso Martinez, David Minnen, David Ross, Grant Schindler, Mikhail Sirotenko, Kihyuk Sohn, Krishna Somandepalli, Huisheng Wang, Jimmy Yan, Ming-Hsuan Yang, Xuan Yang, Bryan Seybold*, Lu Jiang*</p>
<hr>
<p>*Equal technical contribution</p>
<h3 size="3">
<p>Acknowledgements</p>
</h3>
<p><i>We give special thanks to Alex Siegman and Victor Gomes for managing computing resources. We also give thanks to Aren Jansen, Marco Tagliasacchi, Neil Zeghidour, John Hershey for audio tokenization and processing, Angad Singh for storyboarding in “Rookie the Raccoon”, Cordelia Schmid for research discussions, Alonso Martinez for graphic design, David Salesin, Tomas Izo, and Rahul Sukthankar for their support, and Jay Yagnik as architect of the initial concept.</i></p>
<hr>
<p><i>**Referenced works:</i></p>
<ul>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Bierstadt_Albert_Old_Faithful.jpg">Old Faithful</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Pillars_of_creation_2014_HST_WFC3-UVIS_full-res.jpg">Pillars of Creation</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://www.artic.edu/artworks/120885/milk-drop-coronet">Milk Drop Coronet</a>, <a target="_blank" href="https://creativecommons.org/publicdomain/zero/1.0/">CC0 1.0</a>.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Rembrandt_Christ_in_the_Storm_on_the_Lake_of_Galilee.jpg">The Storm on the Sea of Galilee</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:George_III_Statue.jpg">George III Statue</a>, <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">CC BY-SA 4.0</a>.</p>
</li>
<li>
<p><a target="_blank" href="https://en.wikipedia.org/wiki/File:Raising_the_Flag_on_Iwo_Jima,_larger_-_edit1.jpg">Raising the Flag on Iwo Jima</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Caspar_David_Friedrich_-_Wanderer_above_the_Sea_of_Fog.jpeg">Wanderer above the Sea of Fog</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Mona_Lisa,_by_Leonardo_da_Vinci,_from_C2RMF_retouched.jpg">Mona Lisa</a>, public domain.</p>
</li>
</ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vulkan video extensions for accelerated H.264 and H.265 encode (203 pts)]]></title>
            <link>https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-encode</link>
            <guid>38701780</guid>
            <pubDate>Tue, 19 Dec 2023 21:21:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-encode">https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-encode</a>, See on <a href="https://news.ycombinator.com/item?id=38701780">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><time itemprop="dateCreated" datetime="2023-12-19T06:00:00-08:00"><i></i> December 19, 2023</time>
        by <span itemprop="author">Lynne Iribarren, Khronos Member of the Vulkan Video TSG and Ahmed Abdelkhalek, AMD, Vulkan Video TSG Chair</span>
        <span itemtype="keywords"><i></i>
        
            <a href="https://www.khronos.org/news/tags/tag/vulkan" title="vulkan">vulkan</a>, 
            <a href="https://www.khronos.org/news/tags/tag/video" title="video">video</a>
        </span>
    </p><div itemprop="description">
    <p>In April 2021, the Vulkan® Working Group at Khronos® <a href="https://www.khronos.org/blog/an-introduction-to-vulkan-video">released a set of provisional extensions</a>, collectively referred to as ‘Vulkan Video’ which provide seamless encoding and decoding of video streams using a variety of video coding standards. The December 2022 release of Vulkan 1.3.238 saw the <a href="https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-decode">finalization of the extensions to decode H.264 and H.265</a>, and today, with the release of Vulkan <strong>1.3.274</strong>, Khronos has finalized their counterpart: the extensions to enable <strong>encoding</strong> of H.264 and H.265 video streams. Leveraging the Vulkan framework, they provide a standardized, seamless, low-overhead, and highly controllable way to produce H.264 and H.265 video via hardware accelerators, with applications ranging from real-time, low-latency streaming to offline server-scale transcoding.</p>
<p>Incorporating industry feedback, the extensions saw many improvements since their introduction, from a bidirectional interface (overrides) to help with coding and exposing advanced hardware capabilities, to rate control configuration parameters and an interface to aid with quality vs. performance trade-offs. This feedback also prompted the release of the first video maintenance extension. In addition, given the high industry demand for AV1 codec support, an AV1 decode extension release is imminent, with an AV1 encode extension development also underway. Figure 1 depicts Vulkan Video extensions along with their status and relations.</p>


<figure><img src="https://www.khronos.org/assets/uploads/blogs/2023-blog-vulkan-video-1.jpg">Figure 1. Vulkan Video extensions</figure>


<p>The encode extensions grant low-level control over much of the encoding process, while still keeping the efficiency and performance of hardware encoding acceleration. Implementers have the freedom to tweak details such as quantization index, per-slice bit allocation, arithmetic coder, deblocking, and more. Given this flexibility and complexity, a balanced programming interface for rate control gives users a choice between more automated operation and low-level tweaking of frame parameters.</p>
<h2>So, What Changed?</h2>
<p>This section briefly summarizes the changes included in this release relative to <a href="https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-decode">prior descriptions</a> of the Vulkan Video extensions.</p>
<h3>Changes to Video Encode</h3>
<h4>Encoder Rate Control</h4>
<p>Often the most important aspect of encoder configuration for applications, the encoder rate control API was given special attention in Vulkan Video. From exposing parameters for standard rate control modes (e.g. CBR/VBR), to allowing applications to provide hints about other intended stream encoding parameters (e.g. picture/reference patterns), to providing the ability to configure per-layer rate control parameters (e.g. for streams with multiple temporal layers), the rate control API offers a rich set of features for various use cases and lays a solid foundation for future extensions. Encoder rate control configuration is performed using the <strong><em>vkCmdControlVideoCodingKHR</em></strong> command.</p>
<h4>Encoder Quality Levels</h4>
<p>Video encoder implementations often fine tune the use of various encoding tools and rate control parameters depending on the desired quality versus performance/latency trade-offs of different use cases. Now implementations report the number of quality levels supported for a given video profile and usage. A new API <strong><em>vkGetPhysicalDeviceVideoEncodeQualityLevelPropertiesKHR </em></strong>may be used to retrieve implementation recommendations for various encoding parameters and configurations (e.g. rate control).</p>
<h4>Implementation Overrides</h4>
<p>Due to the complex nature of video encoding, and the ever-changing nature of hardware encoders and their capabilities, an interface, known as <strong>overrides</strong>, permits bidirectional communication that <strong>guarantees</strong> that the output video stream will be compliant. In addition, applications may opt-in for optimization overrides to allow implementations more flexibility to optimize for the specified usage and hints. Full disclosure about the occurrence of overrides for video session parameters or frame parameters is also reported for developers interested in more detailed analysis of such overrides.</p>
<h4>Retrieval of encoded video session parameters bitstream segments</h4>
<p>To facilitate implementation overrides for bitstream compliance and optimizations, applications are expected to retrieve the encoded video session parameter bitstream segments (e.g. H.264 SPS/PPS) from the implementation using the new API call <strong><em>vkGetEncodedVideoSessionParametersKHR</em></strong> against the given <strong><em>VkVideoSessionParametersKHR</em></strong> object.</p>
<h4>Encoder Feedback Query</h4>
<p>To allow future extension of encoder feedback statistics in a manner similar to pipeline statistics, the new <strong><em>VK_QUERY_TYPE_VIDEO_ENCODE_FEEDBACK_KHR</em></strong> is now used to retrieve the video bitstream offset and size.</p>
<p>Figure 2 depicts the Vulkan Video encoding process, which remains largely unchanged compared to previous descriptions.</p>


<figure><img src="https://www.khronos.org/assets/uploads/blogs/2023-blog-vulkan-video-2.jpg">Figure 2. Vulkan Video Encode Process</figure>


<h3>Changes to Video Decode &amp; Encode</h3>
<h4>VK_KHR_video_maintenance1</h4>
<p>Along with the video encoding extensions, Khronos is releasing a maintenance extension incorporating community and industry feedback, which improves flexibility for both decoding and encoding. This extension permits decoding implementations to create images usable with video decoding without the need to explicitly specify the video profiles they will be used with. The same applies for encoding, where an attached per-image video profile limits usability with large and complex transcoding frameworks.</p>
<p>In addition to flexibility improvements, a new, simpler interface for specifying video queries <strong>inline with video decode and encode operation commands</strong> has been added, known as inline queries.</p>
<h4>Requiring pSetupReferenceSlotKHR for non-reference pictures</h4>
<p>When the Vulkan Video decode extensions were finalized applications were required to provide a reconstructed picture resource and DPB slot (via <strong><em>VkVideoDecodeInfoKHR::pSetupReferenceSlot</em></strong>) only if the picture being decoded will become a reference. However, no shipping implementation actually supported specifying <strong><em>NULL</em></strong>for <strong><em>pSetupReferenceSlot</em></strong>, and further some implementations discovered cases that require the use of the reconstructed picture resource and/or DPB slot for transient storage during decoding a non-reference picture. A similar situation applies to encoding non-reference pictures. As a result, the vulkan video extensions were updated to require providing <strong><em>pSetupReferenceSlotKHR</em></strong> for non-reference pictures.</p>
<h2>I Want All The Details!</h2>
<p>The following <strong>proposal documents</strong> provide a much more detailed and thorough review of all finalized Vulkan Video extensions, including the rationale behind the chosen design approach, various issues encountered during the development of Vulkan Video and how they were resolved, as well as code samples to aid in application development:</p>
<ul>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_queue.adoc"><strong><em>VK_KHR_video_queue</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_decode_queue.adoc"><strong><em>VK_KHR_video_decode_queue</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_decode_h264.adoc"><strong><em>VK_KHR_video_decode_h264</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_decode_h265.adoc"><strong><em>VK_KHR_video_decode_h265</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_encode_queue.adoc"><strong><em>VK_KHR_video_encode_queue</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_encode_h264.adoc"><strong><em>VK_KHR_video_encode_h264</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_encode_h265.adoc"><strong><em>VK_KHR_video_encode_h265</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_maintenance1.adoc"><strong><em>VK_KHR_video_maintenance1</em></strong></a></li>
</ul>
<p>Developers interested in using Vulkan Video are strongly encouraged to read the above proposal documents - they really give you a good head start!</p>
<p>All details about the Vulkan Video API are available in the final extensions <strong>specification</strong> links:</p>
<ul>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_queue.html"><strong><em>VK_KHR_video_queue</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_decode_queue.html"><strong><em>VK_KHR_video_decode_queue</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_decode_h264.html"><strong><em>VK_KHR_video_decode_h264</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_decode_h265.html"><strong><em>VK_KHR_video_decode_h265</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_encode_queue.html"><strong><em>VK_KHR_video_encode_queue</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_encode_h264.html"><strong><em>VK_KHR_video_encode_h264</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_encode_h265.html"><strong><em>VK_KHR_video_encode_h265</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_maintenance1.html"><strong><em>VK_KHR_video_maintenance1</em></strong></a></li>
</ul>
<h2>Call for Action, Feedback &amp; Support!</h2>
<p>The finalization and release of these Vulkan Video extensions marks a significant milestone in the Vulkan ecosystem roadmap, adding fully accelerated H.264 and H.265 encode to this widely available cross-platform GPU API. We encourage developers to utilize these extensions to bring new levels of performance and functionality to their video applications on Windows and Linux.</p>
<p>We welcome you to join <a href="https://vulkan.org/events/vulkanised-2024">Vulkanised 2024</a> (February 5-7 in MountainView CA.), which will include a presentation &amp; live demo about Vulkan Video and much more!</p>
<p>NVIDIA, Intel &amp; AMD are the first IHVs implementing support for these extensions:</p>
<ul>
<li>NVIDIA: Windows and Linux <a href="https://developer.nvidia.com/vulkan-driver">BETA drivers</a> available now</li>
<li>Intel: Coming soon</li>
<li>AMD: Coming soon</li>
</ul>
<p>Additionally, the open-source drivers <a href="https://airlied.blogspot.com/2023/12/radv-vulkan-video-encode-status.html">RADV</a> and <a href="https://gitlab.freedesktop.org/zzoon/mesa/-/tree/h264enc_anv_4?ref_type=heads">ANV</a> are adding support for the finalized Vulkan Video encode extensions, in addition to already supporting the Vulkan Video decode extensions.</p>
<p>Strong ecosystem adoption continues for Vulkan Video, and there are several implementers of the spec:</p>
<ul>
<li>The <a href="https://github.com/nvpro-samples/vk_video_samples">reference app</a> part of the Vulkan Video samples repository with encoding support is coming soon in 1Q24.</li>
<li>FFmpeg, in a <a href="http://lynne.ee/vulkan-video-encoding.html">branch</a> currently under development, soon to be merged into the <a href="https://git.videolan.org/?p=ffmpeg.git;a=log;h=HEAD">main repository</a>.</li>
<li>Gstreamer, in a <a href="https://gitlab.freedesktop.org/gstreamer/gstreamer/-/merge_requests/5739">branch</a> currently under development and a description of the journey can be found <a href="https://blogs.igalia.com/scerveau/vulkan-video-encoder-in-gstreamer/">here</a>.</li>
</ul>
<p>Those interested in testing the code should follow their guidelines and are welcome to submit feedback.</p>
<p>An upcoming release of Vulkan SDK will include updated Vulkan headers and Validation Layer support for the newly released video extensions. In the meantime, you can find the Vulkan headers <a href="https://github.com/KhronosGroup/Vulkan-Headers">here</a>.</p>
<p>We look forward to your use and feedback on Vulkan Video! Please share your experience and thoughts through the <a href="https://github.com/KhronosGroup/Vulkan-Docs/issues/2284">Vulkan Video Encode Release GitHub Issue</a>. This issue will also be updated to provide links to Vulkan Video-related resources as they become available.</p>
<p>We also encourage your participation in extending Vulkan Video to support more codecs and features. See <a href="https://www.khronos.org/members/">khronos.org/members</a> for information about how to join Khronos and participate in the definition of any of our standards.</p>
<p>Thank you for your interest and support of Vulkan Video. We hope you find it effective for your use cases and applications, and we look forward to supporting your needs with more codecs and features!</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CUDA vs. ROCm: A case study (135 pts)]]></title>
            <link>https://shihab-shahriar.github.io//blog/2023/Cuda-vs-Rocm-A-Case-Study-Through-Random-Number-Libraries/</link>
            <guid>38700060</guid>
            <pubDate>Tue, 19 Dec 2023 19:09:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shihab-shahriar.github.io//blog/2023/Cuda-vs-Rocm-A-Case-Study-Through-Random-Number-Libraries/">https://shihab-shahriar.github.io//blog/2023/Cuda-vs-Rocm-A-Case-Study-Through-Random-Number-Libraries/</a>, See on <a href="https://news.ycombinator.com/item?id=38700060">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <div id="markdown-content"> <p>How far along is AMD’s ROCm in catching up to Cuda? AMD has been on this race for a while now, with ROCm debuting 7 years ago. Answering this question is a bit tricky though. CUDA isn’t a single piece of software—it’s an entire ecosystem spanning compilers, libraries, tools, documentation, Stack Overflow/forum answers, etc. Today, I’m going to zoom in on a particular slice of these vast ecosystems, the random number generation libraries: cuRAND and rocRAND, part of the suite of around ten libraries that come standard on both systems. Hopefully, this sheds some light on the current state-of-affairs of the broader landscape.</p> <p>Most of these observations grew out of my work on a research project a few months ago. As I worked, I realized I was forming some pretty strong takes that I can’t really put in an academic paper. So here I am.</p> <p>One of the key advantages of rocRAND is it is open-source. So let’s start at their <a href="https://github.com/ROCm/rocRAND" rel="external nofollow noopener" target="_blank">GitHub repo</a> first.</p> <h2 id="design">Design</h2> <p>Going through the README, one of the first things you notice is AMD actually offers two random number libraries: rocRAND and hipRAND, the latter being a thin client that chooses cuRAND or rocRAND depending on the platform. So, for today’s discussion, we’ll set aside hipRAND.</p> <p>Next comes a list of random number generators implemented in the library. You won’t find a discussion about them here (or anywhere else for that matter), Just a list of names. Moving on, in the Requirements section, ROCm is listed as a dependency for AMD platforms, as expected. However, clicking on the ROCm link leads to the first 404 error on this page. To run this library on CPU, you need something referred to as “HIP-CPU”. This link thankfully works, and the tagline of its Github repo reads- “An implementation of HIP that works on CPUs, across OSes.”</p> <p>Let’s pause for a moment. We’re not even halfway through the README and we have already seen 3 different platforms from AMD- ROCm, HIP, HIP-CPU. I really wonder about the necessity or the wisdom behind this fragmentation- splitting HIP in particular. A single standard or library like SYCL or Kokkos seems to support multiple hardware platforms just fine under one codebase. To me this felt like a half-hearted attempt to tick one more box in a head-to-head battle with (intel-supported) SYCL. And I say half-hearted because HIP-CPU has been under development for more than 3 years, last commit pushed 3 months ago, and this is the first paragraph of its README: “Please note the library is being actively developed, and is known to be incomplet; it might also be incorrekt and there could be a few bad bugs lurking.” Let’s return to our focus on rocRAND.</p> <p>One of the key challenges in developing a parallel, reproducible random number library is ensuring statistical robustness. This might not matter for most users, but for applications like Brownian simulations, a weak generator can silently wreak havoc. Rigorous testing with standard, widely accepted statistical frameworks is crucial - something cuRAND of course does. However, I couldn’t find any discussion on this for rocRAND, aside from two self-written simple tests. There’s mention of a statistical test suite in the README, but again, that link leads to a 404 error.</p> <p>It’s not looking great, but at this point, I found a feature that cuRAND doesn’t have, a Python API! It’s an interesting choice: to attach such a high-level language interface for such a low-level library. So let’s go to the documentation and see what’s it for, shall we?</p> <h2 id="documentation">Documentation</h2> <figure> <picture> <source media="(max-width: 480px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/py-480.webp"> <source media="(max-width: 800px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/py-800.webp"> <source media="(max-width: 1400px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/py-1400.webp"> <img src="https://shihab-shahriar.github.io/assets/img/rocm/py.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption>Figure 1: rocRAND's Python API.</figcaption> </figure> <p>That’s it! That’s the entirety of the Python API documentation – and no, those headers aren’t clickable. <a href="https://rocm.docs.amd.com/projects/rocRAND/en/latest/python_api.html" rel="external nofollow noopener" target="_blank">This is it</a>!</p> <p>So, that was a bonus feature. What about the C++ API documentation? well, it exists, but it’s hardly any different. The API reference is almost entirely just a dump of function docstrings, with same comment copy/pasted for all the functions. And this mindless copy/pasting has predictable result- you’ll find, for example, the “documentation” mention 64 bit int return type for a function while it actually returns 32-bit.</p> <p>The Programming Guide again starts (and ends) with the list of generators, with only one piece of extra information here, whether a generator is for pseudo-random or quasi-random number generation. The next (and final) section is titled “Ordering”, and the very first sentence starts talking about “how results are ordered in global memory.” If you just thought- wait, what results? that’s a very valid response. You <em>might</em> eventually figure out they are talking about the host-side API that generates a buffer of random numbers on device. Being GPU, it uses multiple threads behind the scene, and ordering here refers to how to order the numbers coming out of each thread in the output buffer. They list 5 ways of doing it, after commenting how this choice impacts performance and reproducibility. Go on, <a href="https://rocm.docs.amd.com/projects/rocRAND/en/latest/programmers_guide.html#" rel="external nofollow noopener" target="_blank">read about them a little bit</a>, you’ll soon discover a pretty interesting relationship between them. For the lazy among you, here’s a clue:</p> <figure> <picture> <source media="(max-width: 480px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/Spiderman-480.webp"> <source media="(max-width: 800px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/Spiderman-800.webp"> <source media="(max-width: 1400px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/Spiderman-1400.webp"> <img src="https://shihab-shahriar.github.io/assets/img/rocm/Spiderman.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption></figcaption> </figure> <p>They are all the same! Of course, they don’t say that directly, it’s another little thing for you to figure out. (well, technically I can’t say “all” are same, becuase they don’t mention the fifth one anywhere else in the page.)</p> <p>Frankly, this isn’t just bad documentation; this is horrendous. There is no attempt anywhere to introduce or explain anything: just data dumps and lists. You get the sense, once again, that this “documentation work” was another box for someone to tick, without any consideration paid to a potential user of the software.</p> <p>But the code follows the same API as cuRAND. So someone familar with cuRAND will be able to manage eventually. Let’s look at how that code fares against cuRAND next.</p> <h2 id="performance">Performance</h2> <p>I’ll start with a real-world benchmark, using a classic example of GPGPU programming: Ray tracing in one weekend in cuda (<a href="https://github.com/rogerallen/raytracinginoneweekendincuda" rel="external nofollow noopener" target="_blank">Github</a>). For meaningful performance comparison of random number libraries, we need a program that uses random numbers beyond just the initialization phase. Ray tracer is a good example of that. Both libraries offer a variety of generators; for this test, I chose Philox.</p> <figure> <picture> <source media="(max-width: 480px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/comb-480.webp"> <source media="(max-width: 800px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/comb-800.webp"> <source media="(max-width: 1400px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/comb-1400.webp"> <img src="https://shihab-shahriar.github.io/assets/img/rocm/comb.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption>Figure 2: Time taken to render the image on the right by cuRAND and rocRAND libraries (left)</figcaption> </figure> <p>4.03 seconds vs 5.5s- the raytracer with the rocRAND version is 37% slower. Remember this isn’t a micro-benchmark of just random number generation part, the timings are for whole program. With that in mind, I think this is a pretty substantial slowdown.</p> <p>The benchmark was performed on an Nvidia V100 GPU. Is that fair? I think yes, especially since rocRAND’s developers <a href="https://streamhpc.com/blog/2017-11-29/learn-amds-prng-library-developed-rocRAND/" rel="external nofollow noopener" target="_blank">claimed</a> to have performance parity with cuRAND on Nvidia GPUs. But maybe cuRAND has some hardware-specific optimizations? I really don’t think that’s the case. Philox algorithm isn’t that complicated, it doesn’t really need any advanced GPU primitives. But don’t take just my word for it: our lab made a pretty simple implementation of Philox, (you can find it <a href="https://github.com/msu-sparta/OpenRAND/blob/main/include/openrand/philox.h" rel="external nofollow noopener" target="_blank">here</a>), it is orders of magnitude smaller than rocRAND’s implementation in terms of LOC, yet it performs on par with CuRAND (4.09 seconds).</p> <p>Still, it’s just one benchmark. I’m sure there are other hardware-software combinations where this performance gap disappears. But, just to ensure that the ray tracer isn’t some outlier, I wrote a pretty basic 2D brownian dynamics simulation code. The story is even worse here for rocRAND, 6.30 seconds vs cuRAND’s 4.23- a 48% slowdown.</p> <h2 id="final-thoughts">Final Thoughts</h2> <p>After the ChatGPT phenomenon, there has recently been lots of focus on Nvidia’s “CUDA moat”. As we all watched the vast AI riches going almost exclusively to Nvidia thanks mostly to that moat, many assumed this will be a big wake-up call for AMD, their <a href="https://www.vanityfair.com/news/2016/06/how-mark-zuckerberg-led-facebooks-war-to-crush-google-plus" rel="external nofollow noopener" target="_blank">Carthage must be destroyed</a> moment that radically alters their well-known laid-back attitude to software. There are hints of this shift in their recent events and press releases, and I hope this trend continues.</p> <p>But in my little corner of HPC world, I’m yet to see any meaningful movement in that regard. And AMD needs to hurry up- as I wrote this article, I took a cursory glance at Intel’s <a href="https://spec.oneapi.io/versions/1.2-rev-1/elements/oneMKL/source/domains/rng/onemkl-rng-overview.html" rel="external nofollow noopener" target="_blank">documentation</a> for SYCL (a competitor of HIP) on this topic- a clean, well-organized, professional site- as you’d expect.</p> <p>Like many, I’m looking forward to a real showdown in the GPGPU space someday- I’m just not sure that will necessarily be between Nvidia and AMD.</p> </div> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[At Least 15% of Reddit Content Is Corporate Trolls Manipulating Public Opinion (145 pts)]]></title>
            <link>https://medium.com/collapsenews/new-study-at-least-15-of-all-reddit-content-is-corporate-trolls-trying-to-manipulate-public-b249bd42ab42</link>
            <guid>38700038</guid>
            <pubDate>Tue, 19 Dec 2023 19:07:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/collapsenews/new-study-at-least-15-of-all-reddit-content-is-corporate-trolls-trying-to-manipulate-public-b249bd42ab42">https://medium.com/collapsenews/new-study-at-least-15-of-all-reddit-content-is-corporate-trolls-trying-to-manipulate-public-b249bd42ab42</a>, See on <a href="https://news.ycombinator.com/item?id=38700038">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://medium.com/@chrisjeffrieshomelessromantic?source=post_page-----b249bd42ab42--------------------------------"><div aria-hidden="false"><p><img alt="Homeless Romantic" src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*P3NFVEPEgZp88pjg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a><a href="https://medium.com/collapsenews?source=post_page-----b249bd42ab42--------------------------------" rel="noopener follow"><div aria-hidden="false"><p><img alt="Collapse News" src="https://miro.medium.com/v2/resize:fill:48:48/1*U7BJY5ZImQnK_eaz_2oTMg.jpeg" width="24" height="24" loading="lazy" data-testid="publicationPhoto"></p></div></a></div><figure><figcaption>Photo by <a href="https://unsplash.com/@brett_jordan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Brett Jordan</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b680"><a href="https://www.journals.elsevier.com/computers-in-human-behavior%0A" rel="noopener ugc nofollow" target="_blank">https://www.journals.elsevier.com/computers-in-human-behavior%0A</a></p><h2 id="9f33">The Impact of Corporate Trolls on Reddit: A Growing Problem</h2><p id="36a2">The rise of social media has brought about a new battleground for the spread of misinformation, manipulation of public opinion, and promotion of products and services. Reddit, one of the most popular social media platforms, has not been immune to this phenomenon.</p><p id="b57c">Two significant studies, <strong>the Pew Research Center study conducted in 2018 and the Computers in Human Behavior study published in 2020, have shed light on the prevalence and impact of corporate trolls on Reddit.</strong></p><h2 id="c308">Pew Research Center Study: Unveiling the Reach of Corporate Trolls</h2><p id="c3b6">The Pew Research Center study, conducted in 2018, delved into the experiences of 2,505 adult Americans who use Reddit.</p><p id="03b9">The findings were alarming, revealing that a considerable portion of Reddit users had directly encountered the influence of corporate trolls.</p><p id="5911"><strong>The study found that 11% of the respondents had been contacted by a bot or troll attempting to promote a product or service</strong>. Even more concerning was the discovery that 13% of the respondents had witnessed a company manipulate public opinion on the platform.</p><p id="2b6f">The study’s demographic analysis further highlighted the targeted nature of corporate trolling. Younger users, particularly those aged 18–29, were significantly more likely to be contacted by corporate trolls, with 17% of them reporting such experiences, compared to only 7% of users aged 65 and over. This age-based discrepancy underscores the strategic approach of corporate trolls in engaging with a demographic that is often more susceptible to their influence.</p></div><div><p><h2 id="5841">Computers in Human Behavior Study: Uncovering Strategic…</h2></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Lufthansa A350's frustrating Oakland diversion (231 pts)]]></title>
            <link>https://onemileatatime.com/news/lufthansa-a350-oakland-diversion/</link>
            <guid>38699343</guid>
            <pubDate>Tue, 19 Dec 2023 18:19:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://onemileatatime.com/news/lufthansa-a350-oakland-diversion/">https://onemileatatime.com/news/lufthansa-a350-oakland-diversion/</a>, See on <a href="https://news.ycombinator.com/item?id=38699343">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>A San Francisco-bound Lufthansa jet recently had to divert to Oakland due to a company policy, even though the weather was nice, and all other planes were having no issues landing in San Francisco. Were air traffic controller just being petty, is Lufthansa’s policy unnecessary, or is this just the price you pay when you err on the side of extreme caution?</p>
<div id="ez-toc-container">

<nav><ul><li><a href="#lufthansa_pilots_cant_do_visual_approaches_at_night" title="Lufthansa pilots can’t do visual approaches at night">Lufthansa pilots can’t do visual approaches at night</a></li><li><a href="#who_was_in_the_wrong_here" title="Who was in the wrong here?">Who was in the wrong here?</a></li><li><a href="#bottom_line" title="Bottom line">Bottom line</a></li></ul></nav></div>
<h2 id="h-lufthansa-pilots-can-t-do-visual-approaches-at-night"><span id="lufthansa_pilots_cant_do_visual_approaches_at_night"></span>Lufthansa pilots can’t do visual approaches at night<span></span></h2>
<p>This incident happened on Monday, October 16, 2023, and involves Lufthansa flight LH458 from Munich (MUC) to San Francisco (SFO). The flight was operated by a six-year-old Airbus A350-900 with the registration code D-AIXC. VASAviation did a great job creating a video that has both a visualization of the flight path, plus the audio between the Lufthansa pilots and the air traffic controller. </p>
<p>This incident revolves around how Lufthansa reportedly has a company policy whereby pilots can’t do visual approaches at night, but rather require instrument landing system&nbsp;(ILS) approaches. I wasn’t aware of this restriction, and I’m not sure if it only applies on certain flights (like long hauls), or what. I assume the intent is that this is an extra operational safety layer.</p>
<p>Why does it matter that Lufthansa doesn’t allow visual approaches? Well, air traffic controllers have to space planes out a bit more for instrument approaches rather than visual approaches, especially at airports like SFO, where parallel landings are performed.</p>
<p>When visual approaches are allowed, controllers can tell pilots to maintain visual separation from other aircraft, so they don’t have to leave as much of a buffer as with an instrument landing (where it’s entirely on the controllers to provide proper spacing). And that brings us to the issue here… </p>
<p>Here’s what happens between the Lufthansa pilots and the approach controllers:</p>
<ul>
<li>The controller clears the Lufthansa jet to make a visual approach, and the Lufthansa pilot advises “due to company procedures, we are unable visual approach at nighttime”</li>
<li>The controller then advises that “if that’s the case, then it will be extended delays”</li>
<li>The Lufthansa pilot responds “if that’s the case, that’s the case,” at which point the controller puts the Lufthansa jet into an extended holding pattern</li>
<li>After some time, the Lufthansa pilot advises “if we are not set up for base soon, we will have to declare fuel emergency and that would really **** up your sequence” (I can’t tell if he says s*ck or f*ck)</li>
<li>At this point the controller asks “what is your divert field?” suggesting that rather than letting the Lufthansa jet declare a fuel emergency at SFO, the plane will just have to fly to its diversion point</li>
<li>The Lufthansa pilot says “it would be Oakland,” to which the controller responds “you need vectors to Oakland?”</li>
<li>The Lufthansa pilot responds “no, but I just don’t understand why everybody is taking… my company forbids visual separation at night, so what is the problem here?”</li>
<li>The controller responds “I can’t have this conversation with you, you either divert to Oakland or you can continue to hold, it’s up to you”</li>
<li>The Lufthansa pilot responds “okay, you promised me 10 minutes, that ran out four minutes ago, so how many more minutes?”</li>
<li>The controller responds “conversation is over,” and then says “what are your intentions, you want to divert or you want to continue with the delay?”</li>
<li>When the controller advises that it will be an additional 10-15 minute delay, the Lufthansa pilot requests to divert to Oakland</li>
</ul>
<figure></figure>
<p>Unfortunately this turned into quite the messy delay for Lufthansa:</p>
<ul>
<li>The flight was initially supposed to leave Munich at 4:20PM, but only departed at 6:30PM</li>
<li>The flight was supposed to arrive in San Francisco at 7PM, but ended up landing in Oakland at 9:43PM, after a 12hr13min flight</li>
<li>Then at 11:30PM the plane departed Oakland for San Francisco, where it landed at 11:55PM</li>
</ul>
<h2 id="h-who-was-in-the-wrong-here"><span id="who_was_in_the_wrong_here"></span>Who was in the wrong here?<span></span></h2>
<p>Usually in these interactions between pilots and air traffic controllers, there’s one party that’s clearly acting out of line.</p>

<p>In this case, the Lufthansa pilots are doing nothing wrong. They’re following company procedures, and there’s no flexibility when it comes to that. It’s a pretty black and white matter. I am curious how the pilots announced this diversion to passengers. “Ja, so unfortunately even though the weather is nice in San Francisco, we will be diverting to Oakland because of a specific company procedure that only we follow, when all other planes are landing just fine?”</p>
<p>The rest of this is totally beyond my area of expertise, but I’d be curious to know what any OMAAT readers who are pilots or air traffic controllers think. A few thoughts and questions:</p>
<ul>
<li>Are there any other airlines that require instrument landings at night? And is this Lufthansa policy specific to long haul flights where fatigue could be more of an issue, or all flights?</li>
<li>If this is Lufthansa’s company policy, you’d think that this wouldn’t be the first time that this has come up at SFO, and that this is something that air traffic controllers would have dealt with before</li>
<li>To the credit of air traffic controllers, they may have very well had a consistent traffic flow, and allowing in an instrument approach could have messed up the spacing a bit, and could have caused problems for other planes</li>
<li>At the same time, it seems like the air traffic controllers aren’t exactly trying to go above and beyond to accommodate the Lufthansa jet, and even seem to have quite an attitude with the Lufthansa pilots, and almost get joy out of their diversion; at least that’s the tone that I sense</li>
</ul>
<figure><img fetchpriority="high" decoding="async" width="1200" height="753" src="https://cdn.onemileatatime.com/wp-content/uploads/2020/07/Lufthansa-A350.jpg" alt="" srcset="https://cdn.onemileatatime.com/wp-content/uploads/2020/07/Lufthansa-A350.jpg?width=360&amp;auto_optimize=low&amp;quality=75 360w, https://cdn.onemileatatime.com/wp-content/uploads/2020/07/Lufthansa-A350.jpg?width=1200&amp;auto_optimize=low&amp;quality=75 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>A Lufthansa Airbus A350 had to divert to Oakland</figcaption></figure>
<h2 id="h-bottom-line"><span id="bottom_line"></span>Bottom line<span></span></h2>
<p>A San Francisco-bound Lufthansa Airbus A350 had to divert to Oakland, due to a company policy whereby Lufthansa pilots apparently can’t make visual approaches at night. Air traffic controllers were unwilling or unable to help the Lufthansa pilots, and that caused a bit of a spat between the two parties.</p>
<p>This is an interesting situation, and it seemed like the circumstances were the perfect storm for this to happen, given that SFO often has parallel approaches and is consistently busy, so there’s not much room for extra spacing.</p>
<p><strong>What do you make of this Lufthansa situation?</strong></p>





 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[C++ Should Be C++ (116 pts)]]></title>
            <link>https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p3023r1.html</link>
            <guid>38699223</guid>
            <pubDate>Tue, 19 Dec 2023 18:11:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p3023r1.html">https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p3023r1.html</a>, See on <a href="https://news.ycombinator.com/item?id=38699223">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="doc" data-hard-breaks="true"><p><strong><span>Document number</span></strong><span>: P3023R1</span><br>
<strong><span>Date</span></strong><span>: 2023-10-31</span><br>
<strong><span>Authors</span></strong><span>: David Sankel &lt;</span><a href="mailto:dsankel@adobe.com" target="_blank" rel="noopener"><span>dsankel@adobe.com</span></a><span>&gt;</span><br>
<strong><span>Audience</span></strong><span>: Evolution, Library Evolution</span></p><h2 id="Abstract" data-id="Abstract"><a href="#Abstract" title="Abstract"><span></span></a><span>Abstract</span></h2><p><span>Over the past few years, the C++ community has coped with challenging social media situations, calls for a so-called successor, and signs of upcoming anti-C++ safety regulations. This piles on top of the ordinary committee stress of competing designs and prioritization difficulties. In a time like this it’s easy to dwell on troubles or adopt fiercely defensive positions.</span></p><p><span>This paper attempts to reframe unconstructive narratives and argue that the committee’s real opportunity is to improve people’s lives. We’ll show how this outlook leads to guidance on committee participation, direction, and responsibilities.</span></p><h2 id="Introduction" data-id="Introduction"><a href="#Introduction" title="Introduction"><span></span></a><span>Introduction</span></h2><p><span>The C++ community has been through a lot over the past few years. This paper makes no attempt to recount this history (God forbid!), but instead acknowledges that present circumstances have led committee members to question “Why are we here?”, “Is participation in C++ standardization still worthwhile?”, “What does the future hold for C++?”, and “Where should I invest my efforts?”. Today’s answers to these questions will define C++ for years to come.</span></p><p><span>This document makes the case for my personal perspective and the technical directions that flow from it. My opinions are formed from 23 years of industry C++ experience and 8 years of active committee participation. Equally contributing are countless conversations with engineers flowing from participation in the Boost Foundation, the Bloomberg C++ Guild, C++ conferences, and #include&lt;C++&gt;. However, I don’t pretend to have all the answers and maintain the right to change my mind when new information presents itself.</span></p><p><span>This document is split into the three parts. The first considers different ideas for a C++ Standardization Committee mission and argues that the most compelling one is to improve people’s lives. The second discusses some social patterns and temptations that lead to counter-productive decisions. The final part focuses on technical biases and considers some of the immediate choices the committee faces.</span></p><h3 id="Acknowledgements" data-id="Acknowledgements"><a href="#Acknowledgements" title="Acknowledgements"><span></span></a><span>Acknowledgements</span></h3><p><span>Some of what I say here has been more eloquently said elsewhere. I refer the reader especially to </span><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2000r4.pdf" target="_blank" rel="noopener"><em><span>Direction for ISO C++</span></em><span> (P2000R4)</span></a><span> from the direction group and </span><a href="https://dl.acm.org/doi/pdf/10.1145/3386320" target="_blank" rel="noopener"><em><span>Thriving in a Crowded and Changing World</span></em></a><span> from Bjarne Stroustrup. I’ll be quoting extensively from these documents. </span><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1962r0.pdf" target="_blank" rel="noopener"><em><span>How can you be so certain?</span></em><span> (P1962R0)</span></a><span> and </span><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0559r0.pdf" target="_blank" rel="noopener"><em><span>Operating principles for evolving C++</span></em><span> (P0559R0)</span></a><span> also cover similar topics.</span></p><p><span>I’d be remiss if I did not also credit Niall Douglas, Inbal Levi, Bjarne Stroustrup, and Herb Sutter for providing valuable feedback that substantially improved this document.</span></p><h2 id="Mission" data-id="Mission"><a href="#Mission" title="Mission"><span></span></a><span>Mission</span></h2><h3 id="The-biggest-threat" data-id="The-biggest-threat"><a href="#The-biggest-threat" title="The-biggest-threat"><span></span></a><span>The biggest threat</span></h3><p><em><span>How can you be so certain?</span></em><span> states “if we are not careful, C++ can still fail”. </span><em><span>Operating principles for evolving C++</span></em><span> suggests principles “in order to keep C++ alive, healthy and progressing”. These statements, representing a wider community outlook, imply C++ is an entity that has acquired something valuable that can be lost. What does this mean, exactly?</span></p><p><span>It is easy to see that C++ is fit as a general-purpose programming language–adoption by millions is a testament to that. Engineers gain proficiency in a reasonable amount of time and use it to solve their problems. C++'s usefulness it what matters.</span></p><p><span>Many think other programming languages “threaten” C++ or have the potential to “take away” what it has. A closer look reveals that the presence of a new tool doesn’t make an existing tool less capable, but potentially more capable.</span></p><p><span>What about regulatory legislation? It cannot change C++'s capabilities any more than those of my hammer. C++ does what it does and is useful where it is used. Unlike my hammer, however, there </span><em><span>is</span></em><span> an entity with the power to degrade C++'s fitness: the C++ standardization committee.</span></p><p><span>The surest way to make a standard irrelevant is to say yes to everything. It is easy to see why: standardizing a complex mess of incoherent ideas quickly becomes “insanity to the point of endangering the future of C++”</span><sup><a href="#fn1" id="fnref1">[1]</a></sup><span>. If my hammer is replaced with a complex gadget requiring thousands of pages of instructions, it is no longer useful for me. Yet, this is exactly our tendency with C++.</span></p><p><span>If C++'s biggest threat is the standardization committee then that begs the question of how to mitigate its risk and align it to a greater good.</span></p><h3 id="Mission1" data-id="Mission"><a href="#Mission1" title="Mission1"><span></span></a><span>Mission</span></h3><p><span>A body comprised of hundreds of individuals cannot function without a unifying mission. There are many ideas of what this should be for WG21, but here are a few strawmen worth considering:</span></p><ol>
<li><span>Make/keep C++ the best language in the world.</span></li>
<li><span>Make C++ the only language people use.</span></li>
<li><span>Make C++ the most popular language.</span></li>
</ol><p><span>The ideas of a “best”, “sole”, or “most popular” language are questionable, but more concerning is their impact. First, this outlook leads to an aversion of other languages both from pride and fear that those other languages might be “better”. Consider, for example, that 40% of C++ developers want to use Rust and 22% already do; ignorance of Rust is ignorance of our users.</span><sup><a href="#fn2" id="fnref2">[2]</a></sup><span> Second, positioning C++ as the “best” language leads to grafting features of other languages at the expense of complexity and consistency. Finally, a lot of energy is expended in useless arguments claiming the benefits of “competing” languages are overblown and that the drawbacks of C++ are exaggerated.</span></p><p><span>We need a more constructive mission and I think there is one: to improve people’s lives. When the range-based for loop reached compilers, millions of developers smiled and said “Ah, that’s nice.” It may have even made their day. This is the kind of massive good within WG21’s control and aligning ourselves to it is incredibly rewarding.</span></p><p><span>An altruistic mindset eliminates the idea of “competitor”. Would Habitat for Humanity morn if the Peace Corps reached a distressed area first? Of course not! They would celebrate the arrival of help. It should be the same with us when our users solve their problem using a different tool. Other language communities helping our users are our allies. We must not forget that. Turf wars don’t serve our users’ interests.</span></p><p><span>Some patterns of thought frustrate a mission of improving people’s lives. Awareness of these is important as they undoubtedly crop up.</span></p><h3 id="C-as-personal-and-group-identity" data-id="C-as-personal-and-group-identity"><a href="#C-as-personal-and-group-identity" title="C-as-personal-and-group-identity"><span></span></a><span>C++ as personal and group identity</span></h3><p><span>One of the first questions programmers ask each other in a social setting is “What language do you program in?”. This frequently sets the stage for unfortunate stereotypes. “Oh, a Java programmer who writes slow code”. “Oh, a Python programmer who cannot program in a ‘real’ language”. “Oh, a Go programmer who …”. When we think of C++ we may find pride in mastery of a difficult language, the ability to write high performance code, and a relationship to the world’s greatest C++ works.</span></p><p><span>While there are benefits to identification with C++ as a source of greatness and purpose, this comes at a cost. First, being primarily an emotional transference, it clouds reason. At my first committee meeting I was advised to avoid mentioning functional programming lest people dismiss my arguments upon hearing the words. Second, deep identification with C++ can create deep seated fears that C++ will become a “legacy” language making one’s skillset (and person even!) obsolete.</span></p><p><span>I mention these things because they frequently compromise a standardization mission to improve people’s lives. We need to assess the programming language world without tribalism tempting us to ignore or overcompensate for issues.</span></p><h3 id="Counterproductive-rhetoric" data-id="Counterproductive-rhetoric"><a href="#Counterproductive-rhetoric" title="Counterproductive-rhetoric"><span></span></a><span>Counterproductive rhetoric</span></h3><p><span>C++ is frequently written and talked about as if it were a living thing. Words like “fatal”</span><sup><a href="#fn3" id="fnref3">[3]</a></sup><span>, “fail”</span><sup><a href="#fn4" id="fnref4">[4]</a></sup><span>, “dead”</span><sup><a href="#fn5" id="fnref5">[5]</a></sup><span>, and “death”</span><sup><a href="#fn6" id="fnref6">[6]</a></sup><span> are common in our literature. When we imagine C++ as a living thing, we naturally associate finite resources (active users), competition (other languages), and death (obsolescence). This thinking is fundamentally inaccurate. C++ is not alive, cannot die, and isn’t competing against anything. It is a merely a tool that is sometimes useful.</span></p><p><span>We must move away from this thinking. In combination with the transference previously discussed, it generates fear and encourages the idea of enemies. The current lack of cooperation and credit between different language communities is quite unfortunate. At its worst people are put down because of the programming language they associate with.</span></p><p><span>Let us remember that a) languages don’t battle, people do, b) smearing other languages doesn’t improve people’s lives, and c) C++ living forever is not our goal.</span></p><h3 id="Standardization-as-personal-opportunity-vs-stewardship" data-id="Standardization-as-personal-opportunity-vs-stewardship"><a href="#Standardization-as-personal-opportunity-vs-stewardship" title="Standardization-as-personal-opportunity-vs-stewardship"><span></span></a><span>Standardization as personal opportunity vs. stewardship</span></h3><p><span>When first joining the committee, it is easy to see participation as primarily a personal opportunity to gain C++ expertise, rub shoulders with celebrities, and, worse of all, leave a mark on the world by getting a proposal accepted. While all these things do indeed happen, there is something much larger at play here.</span></p><p><span>The direction group warns “we are writing a standard for millions of programmers to rely on for decades, a bit of humility is in order.”</span><sup><a href="#fn7" id="fnref7">[7]</a></sup><span> This is not an earnable privilege and none of us are really qualified to make these decisions, but here we are. Our heavy responsibility outweighs the personal opportunities.</span></p><p><span>What does that responsibility entail? It means rejecting proposals without an understandable value proposition. It means resisting social pressure when you are against something. It means building an informed opinion by reading the paper, testing the feature, and collaborating with others. It means saying “yes” only when there is minimal risk. Above all, it means stewardship: you are a caretaker and guardian of something beyond yourself.</span></p><p><span>If you do write a proposal, save time and frustration by enlisting the help of experienced designers and wording experts. They want to help! Also, carefully consider if the problem you’re solving justifies the additional complexity and risk. C++ is a language that is “trying to do too much too fast”</span><sup><a href="#fn8" id="fnref8">[8]</a></sup><span> and needs “to become more restrained and selective”</span><sup><a href="#fn9" id="fnref9">[9]</a></sup><span>.</span></p><h2 id="The-technical-aspect" data-id="The-technical-aspect"><a href="#The-technical-aspect" title="The-technical-aspect"><span></span></a><span>The technical aspect</span></h2><p><span>Equally important to our social tendencies are the technical tendencies that work against us. This section calls out several anti-patterns, none of which are new </span><sup><a href="#fn10" id="fnref10">[10]</a></sup><span>.</span></p><h3 id="Neophilia" data-id="Neophilia"><a href="#Neophilia" title="Neophilia"><span></span></a><span>Neophilia</span></h3><p><span>Bjarne succinctly stated “Enthusiasm favors the new”</span><sup><a href="#fn11" id="fnref11">[11]</a></sup><span>. Technological innovations and fads follow a familiar hype curve </span><sup><a href="#fn12" id="fnref12">[12]</a></sup><span> that begins with a peak of inflated expectations. We risk getting caught up in enthusiasm and standardizing features that, in retrospect, don’t deliver on their promise, poorly integrate with the rest of the language, and increase learning costs.</span></p><p><span>Consider Rust traits which solve similar problems to those of C++ concepts. Traits’s explicit opt-in semantics offers several advantages including separately type-checked generics. Should we add traits to C++? If we do so, we’ll end up with two ways to solve the same problem with millions of lines of code using the old way. Moreover, most developers will need to be familiar with both to be effective in a large, existing codebase, compounding C++'s learning costs.</span></p><p><span>Just because another language has something potentially better than C++ doesn’t mean we should incorporate it. “Keeping up with the Joneses” is a disservice. We should ask ourselves how non-experts, making up most of our users, will react when seeing a feature for the first time in someone else’s code. Frequently it is frustration from having to spend time learning something with marginal benefit over what it replaces.</span></p><h3 id="Features-and-prioritization-bias-towards-experts" data-id="Features-and-prioritization-bias-towards-experts"><a href="#Features-and-prioritization-bias-towards-experts" title="Features-and-prioritization-bias-towards-experts"><span></span></a><span>Features and prioritization bias towards experts</span></h3><p><span>The C++ committee, predominantly comprised of experts, leaves average programmers “seriously underrepresented”</span><sup><a href="#fn13" id="fnref13">[13]</a></sup><span>. This “biases the committee towards language lawyering, advanced features, and implementation issues, rather than directly addressing the needs of the mass of C++ developers, which many committee members know only indirectly”</span><sup><a href="#fn14" id="fnref14">[14]</a></sup><span>.</span></p><p><span>Time spent on expert features squanders opportunities to improve lives at scale. When we prioritize a proposal, we should ask “is this solving a problem for experts or for the average developer?”. If it’s the former, we should seriously consider moving on.</span></p><p><span>Our expert imbalance also results in over-complicated solutions that require advanced proficiencies for simple tasks. Consider the hoops one needs to jump through to make </span><code>std::print</code><span> work with a custom type when compared to the old stream operators. It is too easy for experts to lose touch with novices and professional engineers who don’t spend their free time learning advanced C++ complexities, especially when surrounded by other experts.</span></p><p><span>One of the most valuable things committee members can do is discuss proposals with application engineers. “Is this something you would use?”. “Is this ergonomic?”. “How hard is this to learn?”. “Is this worth another chapter in the C++ book?”. This kind of feedback should weigh more heavily than abstract theories on what an ideal developer should want.</span></p><h3 id="Complexity" data-id="Complexity"><a href="#Complexity" title="Complexity"><span></span></a><span>Complexity</span></h3><p><span>The direction group sees “C++ in danger of losing coherency due to proposals based on differing and sometimes mutually contradictory design philosophies and differing stylistic tastes.” </span><sup><a href="#fn15" id="fnref15">[15]</a></sup><span> Bjarne suspects this is due to a combination of committee growth, an influx of new people, specialization of membership, and a decrease of knowledge of C++'s history among the members.</span><sup><a href="#fn16" id="fnref16">[16]</a></sup></p><p><span>Changes reducing coherence increase complexity and this elevates training costs. Hiring C++ developers is much more challenging than hiring other developers not because of demand, but because the barrier to entry is too high. Fewer people want to learn C++ and fewer schools want to teach it. One of the important ways we can improve people’s lives is to help our users find colleagues.</span></p><p><span>The direction group recalls Alex Stepanov rescuing C++ from disaster by bringing consistency and coherence to the standard library</span><sup><a href="#fn17" id="fnref17">[17]</a></sup><span>, yet we actively debate breaking these same rules for a relatively niche library addition. We recently replaced a simple </span><code>std::function</code><span> template with no less than three alternatives: </span><code>std::copyable_function</code><span>, </span><code>std::function_ref</code><span>, and </span><code>std::move_only_function</code><span>. This isn’t helping our complexity problems!</span></p><p><span>I agree with the design group that we must “aim for coherence”</span><sup><a href="#fn18" id="fnref18">[18]</a></sup><span>. Here are three concrete suggestions for doing so:</span></p><ol>
<li><span>Curb the tendency to focus proposal discussions on a narrow problem domain by asking how it fits within the entire C++ offering. “Is this in the common C++ style?”. “Is this increasing C++'s barrier to entry?”. “How would this impact the hypothetical ‘C++ book’?”</span></li>
<li><span>Encourage study groups to get early feedback from the evolution groups (EWG and LEWG) on the desirability of features.</span><sup><a href="#fn19" id="fnref19">[19]</a></sup><span> Evolution groups are responsible for considering the bigger picture. Getting this feedback before extensive study group iteration can prevent undesirable features gaining difficult-to-stop momentum.</span></li>
<li><span>Overcome reluctance to say, “I don’t think this belongs in C++.” We don’t do authors any favors by providing improvement feedback on proposals that are ultimately undesirable.</span></li>
</ol><h3 id="Niche-problems-getting-more-than-niche-effort" data-id="Niche-problems-getting-more-than-niche-effort"><a href="#Niche-problems-getting-more-than-niche-effort" title="Niche-problems-getting-more-than-niche-effort"><span></span></a><span>Niche problems getting more than niche effort</span></h3><blockquote>
<p><span>[I]t is hard for a committee to remember that a language cannot be all things to all people. It is even harder to accept that it cannot solve even the most urgent problems of every member.</span></p>
<p><span>Bjarne Stroustrup, </span><em><span>Thriving in a Crowded and Changing World</span></em></p>
</blockquote><p><span>In committee, we frequently spend time on things that only a small number of people care about. It’s difficult to say “no” when someone, somewhere would benefit. There’s also a tendency to mentally check-out during these discussions which results in proposals not getting an appropriate rigor.</span></p><p><span>When we fall into these traps, we 1) deny the greater number of users time spent on proposals that can improve their lives, 2) needlessly increase the complexity of the language and library, and 3) encourage more niche proposals.</span></p><p><span>Solving these problems boils down to saying “no” more often and, if needed, repeatedly. Bug fixes aside, the committee should spend its time on a fewer number of proposals that have a bigger impact. Effort spent writing papers solving pet peeves in C++ is better spent writing up analyses and experience reports on higher-impact proposals. We should be doing more to acknowledge such work.</span></p><h2 id="Moving-ahead" data-id="Moving-ahead"><a href="#Moving-ahead" title="Moving-ahead"><span></span></a><span>Moving ahead</span></h2><p><span>This section considers a memory safety and a major C++ overhaul in light this paper’s principles.</span></p><h3 id="Memory-safety" data-id="Memory-safety"><a href="#Memory-safety" title="Memory-safety"><span></span></a><span>Memory safety</span></h3><p><span>Official documents discussing legislation against C++ due its “memory unsafety” have caused community uproar. We’ve seen gigantic email threads, a new study group dedicated to safety, and numerous talks at C++ conferences. What is much less prevalent is a demand from average C++ users for memory safety features; they’re much more concerned about compilation speed. When most C++ developers haven’t adopted tools like Coverity and C++ core guidelines checkers, it is hard to claim that memory safety features substantially improve their lives at least from their point of view.</span></p><p><span>Where memory safety </span><em><span>is</span></em><span> a serious concern, we see the adoption of Rust for critical components. Yet we see little demand from even these developers for C++ safety features. Their problem is already solved.</span></p><p><span>The direction group states “no language can be everything for everybody”</span><sup><a href="#fn20" id="fnref20">[20]</a></sup><span> and I cannot agree more. Rust and other languages are successfully filling engineering needs for memory safety guarantees in critical components. This is not a space our users are demanding us to go into and doing so risks both failure and, yes, even more complexity.</span></p><h3 id="Major-C-overhaul" data-id="Major-C-overhaul"><a href="#Major-C-overhaul" title="Major-C-overhaul"><span></span></a><span>Major C++ overhaul</span></h3><p><span>Over the past two years it’s become in vogue to talk about “C++ successors” which range from dramatic syntax changes to replacing the C++ committee with another organization. What should the committee’s response be to this phenomenon?</span></p><p><span>For groups attempting a new language outside of the committee, I think our response should be support. If these initiatives don’t confuse or otherwise harm our users, they share our goal of improving people’s lives. When they succeed, that’s a good thing. Even if they fail, the ideas they generate might help our users in the end.</span></p><p><span>What about the option to drastically change the face of C++ in the context of WG21? A C++ 2.0, perhaps? If you ask a typical C++ developer how we can improve their lives, a modern and snazzy new syntax will not top their list. Yes, </span><code>template</code><span> and </span><code>typename</code><span> are tedious to read and type, but it’s what they know and they’d rather it not be mucked with. This is more than reluctance to change–our users want coherence in their C++ code base as much as we want coherence in the standard.</span></p><p><span>If a C++ successor ever gains traction, our users would want it to be the best it can be. The committee composition doesn’t have a magical quality that makes it more suited to build a successor than any other entity. The inertia from C++ 1.0’s adoption may even lead to a C++ 2.0 getting adopted when other successor attempts are more fit for purpose. That wouldn’t be good for our users.</span></p><p><span>In summary, the C++ committee’s biggest opportunity to improve people’s lives is to focus on C++ as it is today to serve us better in a few years time under the constraints of compatibility. Let’s leave speculative successor projects to external entities. We’re distracted enough as it is.</span></p><h3 id="What-should-we-do" data-id="What-should-we-do"><a href="#What-should-we-do" title="What-should-we-do"><span></span></a><span>What should we do?</span></h3><p><span>I’ve said a lot about what we should not do. That’s intentional–we need to do less. However, I don’t want to give the impression we should say no to </span><em><span>all</span></em><span> proposals. There are plenty of opportunities to improve our user’s lives through proposals. Here are a few concrete examples:</span></p><ul>
<li>
<p><strong><span>Faster hashing and hash combiners</span></strong><span>. The standard library’s hash map and hash set interfaces are now decades old. Over that time, we’ve seen an explosion in their utility and many algorithmic advancements, advancements that require an interface change. By adding more modern hashing data structures to the standard, we can substantially improve the performance, and environmental impact, of newly written code. Our users also desperately need a standardized way to combine hashes in their own hash functions.</span></p>
</li>
<li>
<p><strong><span>JSON parsing</span></strong><span>. A simple, ergonomic, standardized JSON parsing and serialization library will save many users from searching libraries or, worse, writing custom formats. A non-goal is to be the world’s fastest JSON parser.</span></p>
</li>
<li>
<p><strong><span>Command-line parsing</span></strong><span>. A simple, standardized library for command-line parsing will also improve the lives of the 99% by replacing the common </span><code>argv[1]</code><span> parsing in small applications.</span></p>
</li>
</ul><p><span>There are many more ideas like these. The goal is to give as many people as possible the “ah, that’s nice” reaction.</span></p><h2 id="Conclusion" data-id="Conclusion"><a href="#Conclusion" title="Conclusion"><span></span></a><span>Conclusion</span></h2><p><span>This paper advocates for a C++ standardization mission: improving people’s lives. It also identified the social and technical biases that obstruct this mission. Finally, it considered major ongoing WG21 discussions and suggested ideas for future work.</span></p><p><span>In the end, when I say “C++ should be C++” I mean that C++ is a useful tool as it is–drastic changes aren’t helpful. To avoid it becoming what it is not, we need to say “no” more often, recognize our biases, and, above all, put our users first.</span></p><h2 id="References" data-id="References"><a href="#References" title="References"><span></span></a><span>References</span></h2><p><span>“2023 Developer Survey.” </span><em><span>Stack Overflow</span></em><span>, 2023, </span><a href="https://survey.stackoverflow.co/2023/" target="_blank" rel="noopener"><span>https://survey.stackoverflow.co/2023/</span></a><span>.</span></p><p><span>Hinnant, Howard et al. “Direction for ISO C++.” 15 October 2022, </span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>https://wg21.link/P2000R4</span></a><span>.</span></p><p><span>Stroustrup, Bjarne. “How can you be so certain?” 18 November 2019, </span><a href="https://wg21.link/P1962R0" target="_blank" rel="noopener"><span>https://wg21.link/P1962R0</span></a><span>.</span></p><p><span>Stroustrup, Bjarne. “Remember the Vasa!” 6 March 2018, </span><a href="https://wg21.link/P0977R0%5D" target="_blank" rel="noopener"><span>https://wg21.link/P0977R0</span></a><span>.</span></p><p><span>Stroustrup, Bjarne. “Thriving in a Crowded and Changing World: C++ 2006-2020.” </span><em><span>Proc. ACM Program. Lang.</span></em><span>, vol. 4, HOPL, June 2020, Article 70, pp. 1-167,  </span><a href="https://doi.org/10.1145/3386320" target="_blank" rel="noopener"><span>https://doi.org/10.1145/3386320</span></a><span>.</span></p><p><span>van Winkel, J.C. et al. “Operating principles for evolving C++” 31 Janurary 2017, </span><a href="https://wg21.link/P0559R0" target="_blank" rel="noopener"><span>https://wg21.link/P0559R0</span></a><span>.</span></p><hr><section>
<ol>
<li id="fn1"><p><em><span>Remember the Vasa!</span></em><span> (</span><a href="https://wg21.link/P0977R0" target="_blank" rel="noopener"><span>P0977R0</span></a><span>)</span> <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p><span>The Stack Overflow 2023 survey had 89,184 respondents. 19,634 indicated they did "extensive development work" C++ over the past year and 4,269 claimed extensive development work in both Rust and C++ over the past year. Of those who used C++, 7,918 indicated a desire to work in Rust over the next year.</span> <a href="#fnref2">↩︎</a></p>
</li>
<li id="fn3"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a> <a href="#fnref3">↩︎</a></p>
</li>
<li id="fn4"><p><em><span>How can you be so certain</span></em><span> (</span><a href="https://wg21.link/P1962R0" target="_blank" rel="noopener"><span>P1962R0</span></a><span>)</span> <a href="#fnref4">↩︎</a></p>
</li>
<li id="fn5"><p><em><span>Operating principles for evolving C++</span></em><span> (</span><a href="https://wg21.link/P0559R0" target="_blank" rel="noopener"><span>P0559R0</span></a><span>)</span> <a href="#fnref5">↩︎</a></p>
</li>
<li id="fn6"><p><span>ibid.</span> <a href="#fnref6">↩︎</a></p>
</li>
<li id="fn7"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref7">↩︎</a></p>
</li>
<li id="fn8"><p><em><span>How can you be so certain?</span></em><span> (</span><a href="https://wg21.link/P1962R0" target="_blank" rel="noopener"><span>P1962R0</span></a><span>)</span> <a href="#fnref8">↩︎</a></p>
</li>
<li id="fn9"><p><span>ibid.</span> <a href="#fnref9">↩︎</a></p>
</li>
<li id="fn10"><p><span> See </span><em><span>Thriving in a Crowded and Changing World</span></em><span> and </span><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref10">↩︎</a></p>
</li>
<li id="fn11"><p><span> </span><em><span>Thriving in a Crowded and Changing World</span></em><span> </span> <a href="#fnref11">↩︎</a></p>
</li>
<li id="fn12"><p><span> https://en.wikipedia.org/wiki/Gartner_hype_cycle </span> <a href="#fnref12">↩︎</a></p>
</li>
<li id="fn13"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref13">↩︎</a></p>
</li>
<li id="fn14"><p><em><span>Thriving in a Crowded and Changing World</span></em> <a href="#fnref14">↩︎</a></p>
</li>
<li id="fn15"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref15">↩︎</a></p>
</li>
<li id="fn16"><p><em><span>Thriving in a Crowded and Changing World</span></em> <a href="#fnref16">↩︎</a></p>
</li>
<li id="fn17"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref17">↩︎</a></p>
</li>
<li id="fn18"><p><span>ibid.</span> <a href="#fnref18">↩︎</a></p>
</li>
<li id="fn19"><p><span>Credit to Niall Douglas for this idea</span> <a href="#fnref19">↩︎</a></p>
</li>
<li id="fn20"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref20">↩︎</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bit banging a 3.5" floppy drive (201 pts)]]></title>
            <link>https://floppy.cafe/</link>
            <guid>38699201</guid>
            <pubDate>Tue, 19 Dec 2023 18:09:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://floppy.cafe/">https://floppy.cafe/</a>, See on <a href="https://news.ycombinator.com/item?id=38699201">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <h2>Bit Banging a 3.5" Floppy Drive</h2>
      
      <p>
        Welcome to the <b>floppy cafe</b>! These pages are the lost and sacred
        texts you've been looking for if you happen to be writing a driver for
        a 3.5" floppy. To learn these mysteries, I bit-banged a floppy drive
        using a
        <a href="https://www.pjrc.com/store/teensy40.html" target="_blank" rel="noreferrer">teensy4.0</a>
        and managed to write a full driver for it. My project code is hosted
        <a href="https://github.com/SharpCoder/floppy-driver-rs" target="_blank" rel="noreferrer">here on github</a>
        in case you'd like to learn more. Continue reading for an extremely
        detailed overview of the project and all my findings on this adventure.
        <b>Although the information is largely common for any floppy drive,
          floppy.cafe is dedicated specifically to 3.5" media.
        </b>
      </p>
      <h2>Table of Contents</h2>
      
        
        
        
        
        
        
      
      <h2>
        <a id="how-do-floppy-disks-work" href="#how-do-floppy-disks-work"><img src="https://floppy.cafe/media/link.png"></a>How do Floppy Disks
        Work?
      </h2>
      <p>
        This
        <a href="http://philipstorr.id.au/pcbook/book4/floppyd.htm" target="_blank">website</a>
        has a good overview and some nice pictures. Fundamentally, your floppy
        houses a magnetized disk that spins at about 300rpm. For 3.5" media,
        that disk contains 80 tracks. Each track has 18 sectors. Each sector has
        512 bytes of user-space data (and some more bytes used for metadata).
        Most "modern" floppies are double-sided, so you can multiply all that by
        2 in order to find the total amount of usable space per disk.
        <code>1,474,560 bytes</code> in all.
      </p>
      <p>
        <b>Fun fact!</b> floppy disks actually contain a lot more surface area
        than 1.44mb. By my calculation, you'll get closer to 1.70mb but a lot of
        that extra space is earmarked for
        <a href="#synchronization-barriers">synchronization barriers</a> and
        sector / track metadata.
      </p>
      <h2>
        <a id="wiring-guide" href="#wiring-guide"><img src="https://floppy.cafe/media/link.png"></a>
        Wiring Guide
      </h2>
      <p>
        Here's the cool thing about floppy drives: they have no communication
        protocol! It's just a bunch of gpio pins. For most of them, pulling the
        pin <code>HIGH</code> means it is in the "disabled" or "off" state.
        Pulling a pin <code>LOW</code> will activate it. You can read about the
        very detailed specifications for the
        <a href="https://floppy.cafe/resources/SAMSUNG-SFD321B-070103.pdf" target="_blank">SAMSUNG-SFD321B</a>
        floppy drive. The top row of pins are the functions, the bottom row of
        pins are all <b>LOGIC GROUND</b>. Logic. Did you get that? LOGIC! Not
        motor ground. I had them wired up wrong for weeks and wondered why
        nothing worked. And, yes, there's like a million ground pins but you
        only need 1 to get it working.
      </p>
      <p>
        <b>An important note!</b> the logic-level pins are rated for 5v,
        however, you can use 3v3 in a pinch! Why is that? All these data pins
        are <i>open drain</i> and should be hooked up to a
        <i>pull-up resistor</i>. That means the only way these floppy drives
        communciate back is by sinking the voltage. So 3v3, 5v, it doesn't
        matter. The floppy drive will happily pull it down.
      </p>
      <p>
        <b>Protip!</b> Some of the bottom row of pins are
        <b>not connected internally!</b> So if you are plugging in just 1 ground
        wire and it's not working, chances are the ground pin you selected is
        disconnected. Try another one.
      </p>
      <img alt="A page from a guide showing what each pin on the back of a floppy drive does." src="https://floppy.cafe/media/pins.png">
      <p>
        You'll notice the power section only needs two wires. 5v+ and another
        ground. For your sanity, I suggest using a separate power bus than
        whatever your microcontroller is on.
      </p>
      <p>
        Please do not connect the 5v+ to an arduino or a GPIO! It can draw
        upwards of 1A during really feisty operations and it will
        <b>fry your microcontroller!</b>
      </p>
      <h2>
        <a id="sending-commands" href="#sending-commands"><img src="https://floppy.cafe/media/link.png"></a>Sending Commands
      </h2>
      <p>
        There are a number of commands and proceedures you will need to
        implement in order to assume control of the floppy drive. In general,
        commands are issued by pulling a given pin <code>LOW</code>.
      </p>

      <p>
        <b>A word of warning:</b> I've read online the Arduino internal pull-ups
        aren't great. They'll work for most of these pins
        <i>except the data line</i>. You may want to add a 4.5k pull-up to the
        <code>DATA</code> line instead of relying on the built-in pull-ups.
      </p>
      <p>Alright! Let's explore each function you have access to.</p>

      <h3>Index</h3>
      <p>
        The floppy drive doesn't really know <i>where</i> you are at any given
        time. You can suss this out with various mechanisms, and one of those
        mechanisms is the <b>INDEX</b> pin. The index pin is the first usable
        pin on the top row (pin 8). When this pin is <code>LOW</code>, the disk
        has made one complete revolution and is currently at the start of the
        data stream.
      </p>
      <p>
        In my driver, I would often look for <code>HIGH</code> to
        <code>LOW</code> transitions and use this to increment an error counter.
        If I can't complete some task after 10 revolutions or so, I consider the
        drive in a bad state.
      </p>

      <h3>Drive Select</h3>
      <p>
        There are a few different drive select pins (often for drive 0, 1, and
        2) but the main one we're interested in is
        <code>PIN 12</code> also known as <code>DRIVE SELECT 1</code>. The other
        ones are reserved for controlling multiple floppy drives at once. This
        function is used to enable the floppy drive. Pulling it
        <code>LOW</code>
        will provide you access to all the other I/O functions except
        <code>MOTOR ON</code>. That one is agnostic of drive select.
      </p>
      <h3>Motor On</h3>
      <p>
        As the name suggests, this pin is dedicated to controlling the motor. To
        enable the motor, pull this pin
        <code>LOW</code> and then wait 500ms. It's good practice to monitor the
        <code>INDEX</code> line as well for a <code>HIGH</code> to
        <code>LOW</code> transition, indicating that the spindle has made a
        complete revolution.
      </p>
      <h3>Direction Select</h3>
      <p>
        This pin controls the direction that the track <b>stepper motor</b> pin
        will move in, when you pulse the <code>STEP</code> pin. Pulling this pin
        <code>LOW</code> will orient the track stepper motor to move towards the
        center of the magnetic disk (increasing the track number). Pulling this
        pin <code>HIGH</code> will orient the track stepper to move towards the
        outside of the magnetic disk (decreasing the track number).
      </p>
      <h3>Step</h3>
      <p>
        There are 80 tracks on your average 3.5" floppy drive. You can select a
        given track by pulsing the <code>STEP</code> pin and combining it with
        the <b>direction select</b> pin.
      </p>
      <p>
        Pulsing this pin will charge and actuate a stepper motor. As such, there
        are some specific timing requirements. I like to pull it
        <code>LOW</code> for <code>3ms</code> and then pull it
        <code>HIGH</code> for an additional <code>3ms</code> and leave it in the
        high state until the next pulse. The documentation states it can be low
        for as short as <code>0.15us</code> but that didn't work for me
        consistently across other drives.
      </p>
      <h3>Write Data</h3>
      <p>
        If you want to know a lot more about this pin, head on over to the
        <a href="https://floppy.cafe/mfm.html">MFM ENCODING</a> page for a primer on how to use it.
        From a technical perspective, pulsing this pin will reverse the flux
        direction on the magnetized disk. In general, you will hold the pin
        <code>LOW</code> for about <code>0.15us to 1.1us</code> and then bring
        it back to a <code>HIGH</code> state. How long it remains in the high
        state determines the encoded value according to the MFM rules.
      </p>
      <h3>Write Gate</h3>
      <p>
        Pusling the write data pin will do nothing if the gate is closed. To
        begin writing data, you must pull this pin <code>LOW</code> and keep it
        low during your write operation.
      </p>
      <p>
        <b>You cannot read and write at the same time.</b>
      </p>
      <p>
        <b>Fun fact!</b> While I was developing my driver, I ruined many entire
        tracks by leaving this open for too long. If you aren't careful, it'll
        wreck the sector metadata and synchronization barriers and totally
        destroy your floppy disk. Reformatting the disk should restore balance
        to the force, so this won't be a total loss.
      </p>
      <h3>Track 00</h3>
      <p>
        The floppy drive controls this pin, and when it gets pulled
        <code>LOW</code> that means the read/write head is positioned on
         the first track  (<b>track 0</b>).
      </p>
      <h3>Write Protect</h3>
      <p>
        When a write-protected media is insertted, this pin will be pulled
        <code>LOW</code> by the floppy drive and the data on the disk is
        protected from mis-erasing. When the pin is <code>HIGH</code> the
        floppy drive can be written.
      </p>
      <p>
        This only seems to work if the <b>drive select</b> pin has been pulled
        low.
      </p>
      <h3>Read Data</h3>
      <p>
        A <code>HIGH</code> to <code>LOW</code> transition on this line
        indicates the flux direction has changed on the underlying magnetic
        disk. Once you encouter this transition, count all the clock cyles
        between the <i>leading edge</i> of the <code>LOW</code> signal to the
        <i>trailing edge</i> of the <code>HIGH</code> signal.
      </p>
      <h3>Side Select</h3>
      <p>
        These 3.5" floppy disks have 2 sides. Pulling this pin
        <code>HIGH</code> selects the lower side (side 0). Pulling this pin
        <code>LOW</code> selects the upper side (side 1).
      </p>
      <h3>Ready/Disk Change</h3>
      <p>
        I never got this to work, but the spec says it will either tell you if
        the drive is in a ready state or not. When the floppy drive pulls this
        pin <code>LOW</code>, the drive is ready for operation. Otherwise, the
        pin will be left in a <code>HIGH</code> state.
      </p>
      <h2>
        <a id="synchronization-barriers" href="#synchronization-barriers"><img src="https://floppy.cafe/media/link.png"></a>Synchronization
        Barriers
      </h2>
      <p>
        Between each track is a synchronization barrier. This barrier is
        surprisingly easy to find because it is just 12 <code>0x0</code> bytes
        followed by 3 <code>0xA1</code> bytes. In terms of pulses, it amounts to
        to 96 short pulses followed by the sequence of pulses <code>MLMLMSLMLMSLMLM</code>.
        You may have trouble reading all 96 pulses because of timing. A common
        practice is to seek for at least 80 pulses instead.
        This will give you a bit more resilience.
      </p>
      <h2>
        <a id="sector-metadata" href="#sector-metadata"><img src="https://floppy.cafe/media/link.png"></a>Sector Metadata
      </h2>
      <p>
        Each sector is comprised of some metadata to describe it. The metadata
        is formatted like so:
        </p><ul>
          <li>12 bytes of <b>0x0</b></li>
          <li>3 bytes of <b>0xA1</b></li>
          <li>One byte of <b>0xFE</b></li>
          <li>One byte to indicate the track number</li>
          <li>One byte to indicate the side (or head)</li>
          <li>One byte to indicate thes sector number</li>
          <li>One byte to indicate the sector size</li>
          <li>2 bytes of CRC (cyclic redundancy code) computed from the sector
            metadata</li>
          <li>22 bytes of <b>0x4E</b></li>
          <li>12 bytes of <b>0x0</b></li>
          <li>3 bytes of <b>0xA1</b></li>
          <li>1 byte of either <b>0xFA</b> or <b>0xFB</b></li>
          <li>512 bytes of user data</li>
          <li>2 bytes of CRC computed from the user data</li>
          <li>Unspecified amount of <b>0x4E</b> bytes filling in the remaining
            space between sectors</li>
        </ul>
      
      <p>
        Upon careful inspection, we can see there are actually two
        synchronization barriers. One to find the sector metadata, and another
        to find the userspace data.
        The only difference is the byte that follows. For sectors, the immediate
        byte after the barrier is <b>0xFE</b>. For userspace data, it's either
        <b>0xFA</b> or <b>0xFB</b>.
        This is how we can determine which kind of barrier we've run into.
      </p>
      <h2>
        <a id="track-metadata" href="#track-metadata"><img src="https://floppy.cafe/media/link.png"></a>Track Metadata
      </h2>
      <p>
        Each track also has its own set of metadata which is formatted like so:
        </p><ul>
          <li>80 bytes of <b>0x4E</b></li>
          <li>12 bytes of <b>0x00</b></li>
          <li>3 bytes of <b>0xC3</b></li>
          <li>One byte of <b>0xFC</b></li>
          <li>50 bytes of <b>0x4E</b></li>
        </ul>
      
      <h2>
        <a id="further-reading" href="#further-reading"><img src="https://floppy.cafe/media/link.png"></a>Further Reading
      </h2>
      <p>
        Here is a comprehensive list of additional resources:
        </p><ul>
          <li><a href="https://floppy.cafe/resources/SAMSUNG-SFD321B-070103.pdf" target="_blank" rel="noreferrer">SFD321B-070103.pdf</a></li>
          <li><a href="http://philipstorr.id.au/pcbook/book4/floppyd.htm" target="_blank" rel="noreferrer">Floppy Disk Formats</a></li>
          <li><a href="http://www.interfacebus.com/PC_Floppy_Drive_PinOut.html" target="_blank" rel="noreferrer">Floppy Drive PinOut</a></li>
          <li><a href="https://www.5volts.ch/posts/mfmreader/" target="_blank" rel="noreferrer">MFM Reader</a></li>
          <li><a href="https://github.com/SharpCoder/floppy-driver-rs" target="_blank" rel="noreferrer">(github) Floppy Driver RS</a></li>
          <li><a href="https://github.com/adafruit/Adafruit_Floppy/tree/main" target="_blank" rel="noreferrer">(github) Adafruit Floppy Reader</a></li>
          <li><a href="https://github.com/dhansel/ArduinoFDC" target="_blank" rel="noreferrer">(github) Arduino FDC</a></li>
        </ul>
      
      <p>
        Next, let's check out <a href="https://floppy.cafe/mfm.html">MFM ENCODING</a> to learn more
        about how data is stored.
      </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK plan to digitise wills and destroy paper originals "insane" say experts (158 pts)]]></title>
            <link>https://www.theguardian.com/society/2023/dec/18/ministry-of-justice-plan-to-destroy-historical-wills-is-insane-say-experts</link>
            <guid>38699007</guid>
            <pubDate>Tue, 19 Dec 2023 17:57:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/society/2023/dec/18/ministry-of-justice-plan-to-destroy-historical-wills-is-insane-say-experts">https://www.theguardian.com/society/2023/dec/18/ministry-of-justice-plan-to-destroy-historical-wills-is-insane-say-experts</a>, See on <a href="https://news.ycombinator.com/item?id=38699007">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>“Sheer vandalism” and “insane”. This is how leading historians on Monday described government plans to destroy millions of historical wills to save on storage costs.</p><p>The Ministry of Justice is <a href="https://www.gov.uk/government/news/easier-access-to-historic-wills-under-new-government-plans" data-link-name="in body link">consulting</a> on digitising and then throwing away about 100m paper originals of the last wills and testaments of British people dating back more than 150 years in an effort to save £4.5m a year.</p><p>But Tom Holland, the classical and medieval historian and co-host of The Rest is History podcast, said the proposal to empty shelves at the Birmingham archive was “obviously insane”. Sir Richard Evans, historian of modern Germany and modern Europe, said “to destroy the original documents is just sheer vandalism in the name of bureaucratic efficiency”.</p><p>Ministers believe digitisation will speed up access to the papers, but the proposal has provoked a backlash among historians and archivists who took to X to decry it as “<a href="https://twitter.com/onslies/status/1736355233066815905" data-link-name="in body link">bananas</a>” and “<a href="https://twitter.com/richove/status/1736349743008059523" data-link-name="in body link">a seriously bad idea</a>”.</p><p>The government is proposing to keep the originals of some wills of “famous people” – likely including those of Charles Darwin, Charles Dickens and Diana, Princess of Wales – but others would be destroyed after 25 years and only a digital copy would be kept.</p><p>It is feared that wills of ordinary people, some of whom may become historically significant in the future, risk being lost.</p><p>Wills are considered essential documents, particularly for social historians and genealogists, as they capture what people considered important at the time and reveal unknown family links.</p><p>The proposal comes amid growing concern at the fragility of digital archives, after a cyber-attack on the British Library left the online catalogue and digitised documents <a href="https://blogs.bl.uk/living-knowledge/2023/11/cyber-incident.html" data-link-name="in body link">unavailable</a> to users since late October.</p><p>The apparent vulnerability was also revealed this month when the prime minister, Rishi Sunak, and the former prime minister Boris Johnson both claimed they could no longer access WhatsApp messages sought by the UK Covid-19 public inquiry.</p><p>“My real anxiety is that if everything is digitised, somebody pulls the plug,” said Holland whose awareness of the risks of mixing digitisation and archives is all the greater as he is a board member of the British Library.</p><p>Hardware goes out of date and so it might not be available in the future to recall the scanned documents, he said. Access to original documents was vital as “the physicality of the evidence matters … it is an important part of the material culture”.</p><p>Evans, who advises the government on handling claims for art works looted by the Nazis, said he felt “shock and horror” at the plan. He said the idea that officials can choose which wills to keep because, in the words of the MoJ, they “belong to notable individuals or have significant historical interest”, is “the typical arrogance of bureaucracy”.</p><p>The government is seeking views on suitable criteria for deciding whose wills to keep.</p><p>He cited the example of Mary Seacole, the <a href="https://www.maryseacoletrust.org.uk/learn-about-mary/" data-link-name="in body link">Jamiacan nurse</a> who helped British soldiers during the Crimean war in the 1850s, whose story has been revived in recent years.</p><p>“Fifty years ago, who would have thought that Mary Seacole was important or her will worth preserving?” he said. “People who are now thought of as obscure will become famous in the future because what we consider important changes over time.”</p><p>The human connection of handling the original wills and “the feel of the old rag-based pulp paper” would be lost too, he said.</p><p>“You can see the indent of the pen and if the writer is excited or tense. There are minute details on the page which digitisation [can’t capture]. There is a thrilling sensation that you are looking at a document that a real human being wrote on. You get a connection to the past that digitised versions won’t give you.”</p><p>Will Iredale, a second world war historian, and author of The Pathfinders, said: “There’s nothing like getting your hands on the original documents – you can be sure of the source and that is really important. How can you trust whoever is digitising them has scanned them correctly and you are seeing the entire document. Are there going to be robust enough websites to store and deliver this wonderful history?” he said.</p><p>The MoJ is considering “keeping hard copies for about 25 years, in recognition of their sentimental value to families, while saving them digitally longer term.”</p><p>Justice minister, Mike Freer, said: “We want to make it as easy for amateur and professional historians alike to access these documents. Digitalisation allows us to move with the times and save the taxpayer valuable money, while preserving paper copies of noteworthy wills which hold historical importance.”</p><p>A programme of working backwards to digitise all older documents will begin, the MoJ said, claiming that once digitised, access requests will be serviceable much more quickly.</p><p>But the Society of Genealogists is “seriously concerned”, said Natalie Pithers, interim co-chief executive. She said wills are “absolutely vital” social-historical documents and highlighted the emotional impact of seeing an original signature on a historic will for a family member.</p><p>“We are advocates of digitisation but not at the cost of destroying originals,” she said. “In any digitisation projects mistakes get made. We don’t know what further information could be gained in the future from the original documents. There could be somebody in there who did something extraordinary.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Simulating fluids, fire, and smoke in real-time (601 pts)]]></title>
            <link>https://andrewkchan.dev/posts/fire.html</link>
            <guid>38698907</guid>
            <pubDate>Tue, 19 Dec 2023 17:51:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andrewkchan.dev/posts/fire.html">https://andrewkchan.dev/posts/fire.html</a>, See on <a href="https://news.ycombinator.com/item?id=38698907">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <h2>Notes on the math, algorithms, and methods involved in simulating fluids like fire and smoke in real-time.</h2>
    <dt-byline></dt-byline>
    <p>
      <em>Source code for this article can be found on <a href="https://github.com/andrewkchan/andrewkchan.github.io/tree/main/source/posts-source/blog-fire">my GitHub</a>.</em>
    </p>
    <p>
      Fire is an interesting graphics problem. Past approaches generally faked it. For example,
      <i>Lord of the Rings</i> <dt-cite key="Aitken:2004:LRV:1103900.1103911"></dt-cite> used sprites with lots and lots of smoke
      (the fluid sim was too expensive at the time, even for movies).
      Real-time applications like video games have pretty much exclusively
      used non-physical approaches.
    </p>
    <iframe width="560" height="400" src="https://www.youtube.com/embed/OieygwngQ6E?si=9kSBKO0WiDgVV0Oe" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
    <p>
      But in the last 10 years GPUs have made fast fluid simulation easy.
      Basic fluid dynamics algorithms are straightforward to implement on the GPU <dt-cite key="harris2005fast"></dt-cite>. In 2009, ILM used these techniques to model and render fire in
      <i>Harry Potter</i> <dt-cite key="horvath2009directable"></dt-cite>.
      And in 2014, NVIDIA released FlameWorks, a whole system for generating fire and smoke effects for games.
    </p>
    <p>
      This post takes notes on how fire can be simulated on the GPU. It walks through the math behind fluid dynamics,
      parallel algorithms for modeling fluids, and the extra combustion bits that make fire special. Readers should have a reasonable
      background in vector calculus and differential equations (know how to take the gradient of a vector). Demos are implemented with WebGL.
    </p>
    <dt-byline></dt-byline>
    <h2>1. Fluid Simulation</h2>
    <p>
      Before we simulate fire, we need to simulate fluid. We assume
      our fluid is <a href="https://en.wikipedia.org/wiki/Incompressible_flow">incompressible</a> and
      <a href="https://en.wikipedia.org/wiki/Inviscid_flow">inviscid</a>, which will vastly simplify our problem.
    </p>
    <h3>1.1 Basic Fluid Dynamics</h3>
    <p>
      Suppose \(D\) is a region in space filled with a fluid. At any point \( \mathbf{x} \in D \) and time \(t\), the fluid has velocity \(\mathbf{u}(\mathbf{x}, t)\).
      Computationally, we can represent the 2D velocity field \( \mathbf{u} \) with an \( N \times N \) grid, where the equally spaced grid points give the value of
      the velocity field at that point in space.
    </p>
    
    <p>
      <em>Ex: A 16\(\times\)16 grid representing \( \mathbf{u} = (y, -x) \)</em>
    </p>
    <p>
      What will happen if we put a drop of dye in the fluid?
    </p>
    <p>
      Let's define a scalar field \( \psi (\mathbf{x}, t) \) as the density of the dye at any point in space and time.
      The transport of quantities like \( \psi \) within a fluid by the fluid's velocity is called <b>advection</b>.
      Given some fluid's velocity field and an initial density field of our dye, we'd like to see how the dye's density everywhere
      evolves over time by simulating its advection through the fluid.
    </p>
    <p><b>A Naive Method for Advection</b></p>
    <p>
      One idea <dt-fn>As seen below, our scalar field can be expressed as a differential equation. This idea is using Euler's method to solve it.</dt-fn> to compute
      the advection is to take each grid point, move forward the direction and distance that would be traveled
      by a particle at the grid point's velocity and the simulation timestep \( \Delta t \), and update the grid point nearest to where the particle lands:

      $$
      \psi (\mathbf{x} + \mathbf{u} (\mathbf{x}, t), t + \Delta t) = \psi (\mathbf{x}, t)
      $$
    </p>
    <p>
      But this is tricky to parallelize, since 2 grid points can end up in the same target point after forward evaluation.
      And in practice, the target point will fall between grid points, meaning it has to be interpolated into the surrounding grid points. Finally, this process is
      unstable for time steps above some number, causing  \( \psi \) to blow up.
    </p>
    <p><b>The Advection Partial Differential Equations</b></p>
    <p>
      This whole time we've been solving a partial differential equation! If we're going to derive a stable method for advection, we'll need to
      first get an explicit expression for this PDE. Let's start from first principles.
    </p>
    <p>
      Consider a fixed region of space \(W\) (that is, \(W\) does not vary with time). The total mass of dye within \(W\)
      is \( \int_{W} \psi dV\). Over time, the change in mass is:

      $$
      \frac{d}{dt} \int_{W} \psi (\mathbf{x}, t) dV = \int_{W} \frac{\partial}{\partial t} \psi (\mathbf{x}, t) dV \\
      $$

      Now, letting \(S\) denote the surface of \(W\) and \( \mathbf{n} \) the outward normal vector defined along the surface, we can examine
      the mass flow rate through the surface of \(W\). In particular, observe that the volume flow rate - the <i>volume</i> of fluid that
      flows through per second  - across \(S\) per unit area is \( \mathbf{u} \cdot \mathbf{n} \) and the mass flow rate per unit area
      is \( \psi \mathbf{u} \cdot \mathbf{n} \).
    </p>
    
    <p>
      This gives us the <b>law of conservation of mass</b> in integral form:

      $$
      \frac{d}{dt} \int_{W} \psi dV = - \int_{S} \psi \mathbf{u} \cdot \mathbf{n} dA
      $$

      Can we get rid of the integrals and say something similar for points? By divergence theorem, the above is equivalent to

      $$
      \int_{W} [\frac{\partial \psi}{\partial t} + \nabla \cdot (\psi \mathbf{u})] dV = 0
      $$

      Then for a unit subregion \( W = dV \), we can say that

      $$
      \frac{\partial \psi}{\partial t} + \nabla \cdot (\psi \mathbf{u}) = 0
      $$

      This gives us an explicit PDE that we need to solve for \( \psi \)!
    </p>
    <p>
      Hmm... we could stop here, but we might be able to simplify this more. Specifically, it looks like we could isolate out
      a term \( \nabla \cdot \mathbf{u} \) that goes to zero because of incompressibility.

      $$
      \begin{aligned}
      &amp;\frac{\partial \psi}{\partial t} = - \nabla \cdot (\psi \mathbf{u}) \\
      &amp;= - (\frac{\partial}{\partial x} \psi u + \frac{\partial}{\partial y} \psi v) \\
      &amp;= - (\frac{\partial \psi}{\partial x} u + \frac{\partial u}{\partial x} \psi +  \frac{\partial \psi}{\partial y} v + \frac{\partial v}{\partial y} \psi) \\
      &amp;= - (\psi \nabla \cdot \mathbf{u} + \mathbf{u} \cdot \nabla \psi) \\
      &amp;= - \mathbf{u} \cdot \nabla \psi \\
      \end{aligned}
      $$

      Applying our incompressibility constraint \( \nabla \cdot \mathbf{u} = 0 \) at the end yields a scalar PDE, the first of our <b>incompressible flow advection equations</b>:

      $$
      \frac{\partial \psi}{\partial t} = \text{advection} (\mathbf{u}, \psi) = - \mathbf{u} \cdot \nabla \psi \tag{1}
      $$
      $$
      \frac{\partial \mathbf{v}}{\partial t} = \text{advection} (\mathbf{u}, \mathbf{v}) = - \mathbf{u} \cdot \nabla \mathbf{v} \tag{2}
      $$

      Eq. 2 for advecting a vector field \( \mathbf{v} \) through our velocity field can be derived similarly to the scalar advection equation.
    </p>
    <p><b>A Stable Method for Advection</b></p>
    <p>
      Let's look closely at eqn. (1):
      $$
      \frac{\partial \psi}{\partial t} = - \mathbf{u} \cdot \nabla \psi
      $$
    </p>
    <p>
      Notice that the right-hand term is a directional derivative in the \( -\mathbf{u} \) direction. This gives us a wonderful new method for
      advecting \( \psi \) by an incompressible fluid - starting at a grid point \( \mathbf{x} \), trace the fluid velocity <i>backwards</i>,
      replacing the value at our original point by the value that we land on (if we land between points, we can interpolate):

      $$
      \psi (\mathbf{x}, t + \Delta t) = \psi (\mathbf{x} - \mathbf{u} (\mathbf{x}, t), t)
      $$

      In GPU pseudocode:
    </p>
    <!-- <dt-code block language="glsl"> -->
      <pre>        <code>
          global Vec2Field u;
          global FloatField density;
          global float dt;

          // Run for each point in our scalar grid that we want to update
          float advectPoint(vec2 x) {
            vec2 coord = x - dt * getVec2At(u, x);
            return getFloatAt(density, coord);
          }
        </code>
      </pre>
    <!-- </dt-code> -->
    <p>
      This method is called
      <b>Semi-Lagrangian advection</b> and was invented in 1999 by Jos Stam <dt-cite key="stam1999stable"></dt-cite>.
      Like Euler, it's first-order accurate, but has exactly the additional properties we need:
    </p>
    <ol>
      <li>
        It's extremely easy to parallelize because each grid point only gets updated once per iteration.
      </li>
      <li>
        It's <i>unconditionally stable</i>. Why? Observe that for any grid point, the maximum value it can get updated to is the maximum value
        of all the grid points.
      </li>
    </ol>
    <p>
      For a fixed velocity field fulfilling the incompressibility constraint, it works great.
    </p>
    
    <p>
      <em>Click anywhere above to drop some dye in the flow</em>
    </p>
    <dt-byline></dt-byline>
    <h3>1.2 The Navier-Stokes Equations</h3>
    <p>
      So far we've found a model that describes how scalar properties of a fluid evolve over time, assuming the flow is fixed. What about the fluid flow itself -
      how does the velocity field \( \mathbf{u} \) affect itself over time?
    </p>
    <p>
      The <b>Navier-Stokes equations</b>
      <dt-fn>For a detailed derivation, see Chapter 1.3 of Chorin and Marsden (1993).</dt-fn>
      <dt-fn>
        Famous for the <a href="https://en.wikipedia.org/wiki/Navier%E2%80%93Stokes_existence_and_smoothness">Navier-Stokes existence
        and smoothness</a> problem, one of the Clay Institute's seven Millenium Prize problems in math.
      </dt-fn>
      for incompressible flow define how the velocity at any point in a fluid evolves over time:

      $$
      \frac{\partial \mathbf{u}}{\partial t} =
      {\underbrace{ - \mathbf{u} \cdot \nabla \mathbf{u} }_\text{self-advection}} +
      {\underbrace{ \mu^2 \nabla \mathbf{u} }_\text{diffusion}} -
      {\underbrace{ \nabla p }_\text{pressure}} +
      {\underbrace{ \textbf{F} }_\text{ext. forces}}
      $$
      $$
      \text{where~}\forall t{~,~} \nabla \cdot \mathbf{u} = 0
      $$

      Here, the constant \( \mu \) is the fluid's viscosity and \( \mathbf{F} \) are
      external forces. But we assumed earlier that our fluid was <a href="https://en.wikipedia.org/wiki/Inviscid_flow">inviscid</a>,
      so \( \mu = 0 \), and we can just ignore external forces for now. So we're left with two terms - self-advection and pressure.

      $$
      \frac{\partial \mathbf{u}}{\partial t} =
      {\underbrace{ - \mathbf{u} \cdot \nabla \mathbf{u} }_\text{self-advection}} -
      {\underbrace{ \nabla p }_\text{pressure}}
      \tag{3}
      $$
      $$
      \text{where~}\forall t{~,~} \nabla \cdot \mathbf{u} = 0
      $$

      If at every timestep we numerically compute these terms and add them, we can simulate our fluid! In pseudocode:

      <!-- <dt-code block language="javascript"> -->
        </p><pre>          <code>
          let u = createVectorGrid();
          let density = createScalarGrid();
          let p = createScalarGrid();

          while (true) {
            // Solve for the next velocity field.
            u = advect(u, u);

            p = computePressure(...);
            u = u - gradient(p);

            // Advect dye through the new velocity field.
            density = advect(u, density);
          }
          </code>
        </pre>
        <!-- </dt-code> -->
    
    <p>
      Let's take a closer look at each of these.
    </p>
    <p><b>Self-Advection</b></p>
    <p>
      From our incompressible advection equations, we can see that the self-advection term is the advection of the fluid's velocity
      field \( \mathbf{u} \) through itself:

      $$
      \text{advection} (\mathbf{u}, \mathbf{u}) = - \mathbf{u} \cdot \nabla \mathbf{u} \tag{4}
      $$
    </p>
    <p>
      Where do the other terms come from? Well, advecting \( \mathbf{u} \) through itself yields a new velocity field
      \( \mathbf{u}^\prime \) (computable via the Semi-Lagrangian backtracing algorithm from above):

      $$
      \mathbf{u}^\prime = \mathbf{u} - \mathbf{u} \cdot \nabla \mathbf{u}
      $$
    </p>
    <p><b>Pressure</b></p>
    <p>
      We don't know if this new velocity field follows the incompressibility constraint (e.g. has zero divergence).
      So the pressure term \( p \) needs to correct this somehow:

      $$
      \nabla \cdot (\mathbf{u}^\prime - \nabla p) = 0
      $$

      We rearrange this to get

      $$
      \nabla^2 p = \nabla \cdot \mathbf{u}^\prime \tag{5}
      $$

      which is a type of equation known as a <i>Poisson equation</i>, where the left-hand side is
      the <a href="https://en.wikipedia.org/wiki/Laplace_operator">Laplacian</a> of an unknown scalar field and the
      right-hand side is a known scalar. Solving this Poisson equation is really the slowest computational step
      in fluid simulation, for reasons we will see shortly.
    </p>
    <p><b>Solving for Pressure</b></p>
    <p>
      So how do we solve this particular PDE for \( p \)? Well, we know the value of our candidate velocity field \( \mathbf{u}^\prime \)
      at all of our grid points, so we can approximately compute the right-hand side of the Poisson equation by applying a discrete
      version <dt-fn>We are using a <a href="https://en.wikipedia.org/wiki/Finite_difference">finite difference</a> where the independent variable is the grid index.</dt-fn> of the divergence everywhere:

      $$
      \nabla \cdot \mathbf{u}^\prime \approx
      \frac{ u_{i+1, j} - u_{i-1, j} }{ 2 } +
      \frac{ v_{i, j+1} - v_{i, j-1} }{ 2 }
      $$

      where \( \mathbf{u}^\prime = (u, v) \) in 2 dimensions.
    </p>
    <p>
      Then we can use a discrete version of the Laplacian

      $$
      \nabla^2 p \approx
      p_{i+1, j} + p_{i-1, j} + p_{i, j+1} + p_{i, j-1} - 4p_{i, j}
      $$

      to transform the whole equation into a linear equation with five unknowns.
    </p>
    <p>
      But really, we are solving the Poisson equation (5) over all of space at once, so for an \( N \times N \) grid,
      we end up with a system of \( N^2 \) linear equations with exactly \( N^2 \) unknowns! So we end up with
      the familiar old equation

      $$
      \mathbf{Ax} = \mathbf{b}
      $$

      where \( \mathbf{A} \) is a matrix applying the Laplacian operator to the whole grid and \( \mathbf{b} \) is a vector containing
      the velocity field's divergence at all grid points.
    </p>
    <p>
      There are many off-the-shelf algorithms for solving linear systems exactly. Unfortunately for us, even the fastest algorithms
      scale superlinearly with our grid size.
    </p>
    <p><b>Solving for Pressure... Efficiently</b></p>
    <p>
      If we're going to make a real-time simulation, we need to go fast. Can we leverage the GPU?
    </p>
    <p>
      Well, it's not really possible to achieve an exact solution to the linear system efficiently, but we should
      note that the linear system is already an approximation to the Poisson equation. And it is possible to achieve
      arbitrarily accurate approximations with iterative methods - which begin with an estimate and improve solution
      accuracy every iteration - so we can just pick an iterative algorithm and run it
      until we have something that's "good enough". One particularly simple and easy-to-implement iterative algorithm for solving
      linear equations is the <a href="https://en.wikipedia.org/wiki/Jacobi_method">Jacobi method</a>.
    </p>
    <p>
      We start with the very first equation in the system:
      $$
      A_{11}x_1 + A_{12}x_2 + ... + A_{1n}x_n = b_1
      $$
      At the \(k\)th iteration, given some guess \( \mathbf{x}^k \) for the solution \( \mathbf{x} \), we have some error.
      We can use this error to update our guess for \( x_1 \) as follows:
      $$
      x_1^{k+1} = \frac{ b_1 - A_{12}x_2^k - ... - A_{1n}x_n^k }{ A_{11} }
      $$
      In Jacobi, our guesses for all elements of \( \mathbf{x} \) are executed in parallel, giving a perfect
      match for implementation on the GPU. In pseudocode:
    </p>
    <!-- <dt-code block language="glsl"> -->
      <pre>        <code>
          global FloatField divergence;
          global FloatField pressure;
          global float texelSize;

          // Run for each point in our pressure grid that we want to update
          float iterateJacobi(vec2 x) {
            float div = getFloatAt(divergence, x);
            float L = getFloatAt(pressure, x + vec2(-texelSize, 0.));
            float R = getFloatAt(pressure, x + vec2(texelSize, 0.));
            float T = getFloatAt(pressure, x + vec2(0., texelSize));
            float B = getFloatAt(pressure, x + vec2(0., -texelSize));
            return (div - L - R - T - B) / -4.;
          }
        </code>
      </pre>
    <!-- </dt-code> -->
    <p>
      It's worth noting that other, faster-converging solvers can also be
      implemented on the GPU, like the Conjugate Gradient method and the Multigrid method. But depending on
      the fluid and application, pressure accuracy may not be as important as advection accuracy or ease of implementation.
      For smoke and fire, changes in fluid volume aren't as apparent as they are for fluids like water
      <dt-cite key="Crane07"></dt-cite>, and high-quality advection tends to matter more<dt-cite key="Green2014"></dt-cite>.
    </p>
    <p><b>Summary: Simulating Navier Stokes</b></p>
    <p>
      The math behind Navier-Stokes can be a little bit dense, but at a high-level, simulating a fluid by solving the equations
      comes down to a few key update procedures on a grid per timestep. For our dye problem, here's our simulation
      might look:

      <!-- <dt-code block language="javascript"> -->
      </p><pre>        <code>
        let u = createVectorGrid();
        let density = createScalarGrid();
        let div = createScalarGrid();
        let p = createScalarGrid();

        while (true) {
          // Solve for the next velocity field.
          u = advect(u, u);

          // Enforce incompressibility with pressure projection.
          div = divergence(u);
          for (let i = 0; i &lt; JACOBI_ITERATIONS; i++) {
            p = updatePressure(p, div);
          }
          u = u - gradient(p);

          // Advect dye through the new velocity field.
          density = advect(u, density);
        }
        </code>
      </pre>
      <!-- </dt-code> -->

    
    <dt-byline></dt-byline>
    <h3>1.3 Vorticity Confinement</h3>
    <p>
      Using a grid to store our velocity field is extremely convenient, but it results in unwanted
      numerical smoothing whenever we have to interpolate values between grid points.
      This combined with the relatively coarse approximation of a first-order Semi-Lagrangian advection
      scheme has the effect of dissipating out turbulent vortices in our flow. Physically, the velocity field
      loses energy, and the end result is generally overly smooth, "boring" fluid flow.
    </p>
    <p>
      One way to combat lost vorticity is to increase the resolution of our grid, but this isn't really feasible
      for real-time simulations that have limited computational resources. What we would ideally
      like to do is find all the small details that get smoothed over each step of the simulation, and <i>amplify</i>
      them. This process is called vorticity confinement - admittedly, it's not totally realistic, but succeeds in
      preserving small scale details in more or less physically correct locations <dt-cite key="fedkiw2001visual"></dt-cite>.
      Indeed, it was originally invented to resolve very complex flow fields in engineering simulations of helicopter blades,
      where it just wasn't possible to add the number of necessary grid points <dt-cite key="steinhoff1994modification"></dt-cite>.
    </p>
    <p>
      The smallest turbulent features we can find are the vortices centered at each grid point in our simulation.
      We can measure the intensity of these vortices (the <i>vorticity</i> of them) by taking the curl of \( \mathbf{u} \)
      at each point, and amplify them by essentially adding a circular flow scaled by vorticity about each point.
      Mathematically, the vorticity is defined by

      $$
      \bm{\omega} = \nabla \times \mathbf{u}
      $$

      For each grid point, we compute a normalized location vector that points to the highest nearby vorticity concentration:

      $$
      \mathbf{N} = \frac{ \nabla | \bm{\omega} | }{ | \nabla | \bm{\omega} | | }
      $$

      And finally, we compute the confined vorticity vector field and add it to our flow:

      $$
      \mathbf{f_{conf}} = \epsilon (\mathbf{N} \times \bm{\omega})
      $$
      $$
      \mathbf{u_{conf}} = \mathbf{u} + \mathbf{f_{conf}}
      $$

      Here, the confinement constant \( \epsilon &gt; 0 \) is a parameter controlling the amount of small scale detail added
      back to the flow. Even low confinement levels (around 0-15) can make a huge difference, especially for simulations
      using Semi-Lagrangian advection schemes, and higher confinement levels can create highly stylized, billowing flows.
    </p>
    
    <p>
      <em>Click and drag to drop some dye in the turbulent simulation above</em>
    </p>
    <p>
      On the GPU, we can compute curl and confinement like so:
    </p>
    <!-- <dt-code block language="glsl"> -->
      <pre>        <code>
          global Vec2Field u;
          global float texelSize;

          // Run to get curl for each point in grid
          float computeCurl(vec2 x) {
            float L = getVec2At(u, x + vec2(-texelSize, 0.)).y;
            float R = getVec2At(u, x + vec2(texelSize, 0.)).y;
            float T = getVec2At(u, x + vec2(0., texelSize)).x;
            float B = getVec2At(u, x + vec2(0., -texelSize)).x;
            return (R - L) - (T - B);
          }

          global Vec2Field curl;
          global float confinement;

          // Run to get confinement force for each point in grid
          vec2 confinementForce(vec2 x) {
            float L = getFloatAt(curl, x + vec2(-texelSize, 0.));
            float R = getFloatAt(curl, x + vec2(texelSize, 0.));
            float T = getFloatAt(curl, x + vec2(0., texelSize));
            float B = getFloatAt(curl, x + vec2(0., -texelSize));
            float C = getFloatAt(curl, x);

            vec2 N = vec2(abs(T) - abs(B), abs(R) - abs(L));
            N = N / length(N);
            return confinement * C;
          }
        </code>
      </pre>
    <!-- </dt-code> -->
    <p>
      The full simulation with turbulence:
      <!-- <dt-code block language="javascript"> -->
        </p><pre>          <code>
          let u = createVectorGrid();
          let density = createScalarGrid();
          let div = createScalarGrid();
          let p = createScalarGrid();
          let curl = createVectorGrid();

          while (true) {
            // Solve for the next velocity field.
            u = advect(u, u);

            // Use vorticity confinement to amplify turbulence of velocity field.
            curl = computeCurl(u);
            u = u + confinementForce(curl, CONFINEMENT);

            // Enforce incompressibility with pressure projection.
            div = divergence(u);
            for (let i = 0; i &lt; JACOBI_ITERATIONS; i++) {
              p = updatePressure(p, div);
            }
            u = u - gradient(p);

            // Advect dye through the new velocity field.
            density = advect(u, density);
          }
          </code>
        </pre>
      <!-- </dt-code> -->
    
    <p><b>Curl-Noise Turbulence</b></p>
    <p>
      Curl noise is a method that essentially does the same thing as vorticity confinement, but instead of measuring
      and amplifying the vorticity of the velocity field, a scalar vorticity field is made from scratch using noise functions.
      Mathematically, we can combine vorticity confinement and curl-noise turbulence by  synthesizing a random
      vorticity field

      $$
      \bm{\phi} = \text{rand} * \mathbf{z}
      $$

      Then computing our final vorticity field by

      $$
      \bm{\omega}^* = \bm{\omega} + \bm{\phi}
      $$

      Fast-moving, highly-turbulent fluids like smoke and fire benefit the most from vorticity confinement and curl noise,
      and in practice the curl noise field \( \bm{\phi} \) both evolves with time and is also advected by the fluid flow.
    </p>
    <dt-byline></dt-byline>
    <h2>2. Fire Simulation</h2>
    <p>
      If you've gotten this far, pat yourself on the back! The methods in the previous section let us efficiently
      and accurately simulate fluids with varying physical parameters (oil, water, honey)
      assuming the fluid domain is a fixed space. Those interested in handling varying domains (that is, fluids that occupy different regions
      within the grid, like a half-full cup of water that sloshes around) will want to explore accounting for different boundary conditions
      within the grid simulation <dt-fn>I suggest <b>Dynamic Obstacles</b> in
      <a href="https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch30.html">GPU Gems 3 Chapter 30.2</a>
      <dt-cite key="Crane07"></dt-cite> for details on adding this to our grid simulation.
      There are also non grid-based methods, but those are outside scope here. </dt-fn>.
    </p>
    <p>
      Simulating fire and smoke requires a couple additions. First, we'll need to add channels representing
      fuel and temperature to our simulation, and model the combustion of fuel to create heat. Next we'll address how hot pockets
      of our fluid rise with a thermal buoyancy model, and finally, we'll need to render our flames correctly, taking into account
      blackbody radiation of the flames, human perception of light, and fire movement.
    </p>
    <h3>2.1 A Basic Combustion Model</h3>
    <p>
      Chemically, fire is caused by the oxidation of a fuel material in a reaction that releases both heat and light.
      In our case, we can assume that any fuel in our system has already ignited and is actively adding heat; we won't worry
      about the problem of unignited fuel.
    </p>
    <p>
      To be more specific, let's define a scalar field \( \rho \) where \( 0 \leq \rho \leq 1 \) represents the density of fuel and
      another scalar field \( T &gt; 0 \) representing the temperature of the fluid everywhere. At every timestep, temperature is
      added to the system by the fuel, which burns at a given burn temperature:

      $$
      T^\prime = \text{max} ( T, \rho * T_{\text{burn}} )
      $$

      Of course, temperature isn't static - heat diffuses from hot to cold areas, and with fluids in particular, large-scale movements
      of molecules transport heat. The combination of these 2 processes defines <a href="https://en.wikipedia.org/wiki/Convection">heat convection</a>,
      and conveniently, we already have a mathematical model for how it works - advection! Simulation-wise, we advect our temperature
      field along our velocity field. Since any reacting molecules are also moved by the fluid, we should advect fuel as well.
      The heat itself also affects the movement of the fluid - we'll see how to handle this shortly.
    </p>
    <p>
      Furthermore, hot molecules radiate off temperature as light<dt-fn>This is called blackbody radiation, and we'll return
      to it when rendering the fire color. The soot particles present in most fire radiate like ideal blackbodies.</dt-fn> according to the
      <a href="https://en.wikipedia.org/wiki/Stefan%E2%80%93Boltzmann_law">Stefan-Boltzmann Law</a>,
      in a quintic equation <dt-cite key="nguyen2002physically"></dt-cite>:

      $$
      T^\prime = T - \sigma_{\text{cool}} ( \frac{T}{T_{\text{max}}} )^4 * \Delta t
      $$

      Here, \( \sigma_{\text{cool}} \) is the cooling rate parameter. For a physically correct simulation, we would set it to the Stefan-Boltzmann constant,
      but for a graphical simulation, it's nice for the artist to be able to control the rate of cooling.
    </p>
    <p>
      To complete our combustion model, note that our fuel is always burning (we can imagine it as the density of ionized gas particles
      that give off thermal energy and return to a lower energy state), so every timestep we dissipate it by some given burn
      rate \( \gamma_{fuel} \):
      $$
      \rho^\prime = \rho (1 - \gamma_{fuel})^{\Delta t}
      $$
    </p>
    <h3>2.2 Thermal Buoyancy</h3>
    <p>
      So far, our temperature field doesn't do anything to our fluid flow. But it should - hot pockets of air should expand and rise, and cooler pockets should fall.
      We can model this with a thermal buoyancy force. Since we're assuming incompressibility, we won't actually handle air expansion, but the fluid flow
      should experience an upward force depending on temperature:

      $$
      \mathbf{u}^\prime = \mathbf{u} + (\beta T \Delta t) \mathbf{j}
      $$

      Here, \( \beta \) is a given positive buoyancy constant, and \( \mathbf{j} \) is the upward unit vector.
    </p>
    <p>
      Adding a combustion model and thermal buoyancy force gives us a fantastic simulator for a decidedly "fire-like" fluid -
      with the right values of buoyancy and cooling, we can get bulky, billowing plumes of material.
      Not exactly flames, but very similar to smoke.
    </p>
    <p>
      Tap and drag in the simulation below to inject some combusting fuel.
      The displayed pixels represent density of smoke particles, which dissipate at a constant rate instead of being used
      up during combustion, but are still advected by the fluid simulation.
    </p>
    
    <p>
      <em>Click and drag to add smoke above</em>
    </p>
    <p>
      The simulation code builds off the basic fluid routines:
      <!-- <dt-code block language="javascript"> -->
        </p><pre>          <code>
          let u = createVectorGrid();
          let density = createScalarGrid();
          let div = createScalarGrid();
          let p = createScalarGrid();
          let curl = createVectorGrid();
          let fuel = createScalarGrid();
          let temp = createScalarGrid();

          while (true) {
            // Solve for the next velocity field.
            u = advect(u, u);

            // Combustion step.
            temp = combust(temp, fuel);

            // Use vorticity confinement to amplify turbulence of velocity field.
            curl = computeCurl(u);
            u = u + confineVorticity(curl, CONFINEMENT);

            // Add thermal buoyancy.
            u = u + buoyancy(temp);

            // Enforce incompressibility with pressure projection.
            div = divergence(u);
            for (let i = 0; i &lt; JACOBI_ITERATIONS; i++) {
              p = updatePressure(p, div);
            }
            u = u - gradient(p);

            // Advect dye through the new velocity field.
            density = advect(u, density);
          }
          </code>
        </pre>
      <!-- </dt-code> -->
    
    <h3>2.3 Fire Rendering</h3>
    <p>
      Fire is a <a href="http://old.cescg.org/CESCG-2000/SMaierhofer/node6.html">participating medium</a>,
      meaning it emits light through blackbody radiation<dt-fn>Besides emitting its own blackbody radiation, fire also scatters light that passes through it. For more, see
      5.1 in <a href="http://physbam.stanford.edu/~fedkiw/papers/stanford2002-02.pdf">Nguyen et al. 2002</a>
      <dt-cite key="nguyen2002physically"></dt-cite>.</dt-fn>. This is what gives fire its orange and red colors;
      rendering our combusting fuel simulation using the correct formula is then all we need to go from smoke to fire!
    </p>
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Gluehfarben_no_language_horizontal.svg/2880px-Gluehfarben_no_language_horizontal.svg.png">
    <p>
      <em>The temperature-to-color spectrum as described by Planck's law</em>
    </p>
    <p>
      <a href="https://en.wikipedia.org/wiki/Planck%27s_law">Planck's Law</a> describes the spectral density of light radiated by
      a black body at a given temperature \( T \):

      $$
      M(\lambda, T) = \frac{ c_1 }{ \lambda^5 } \frac{ 1 }{ \exp{ \frac{c_2}{\lambda T} } - 1 }
      $$

      where
      $$
      c_1 = 2 \pi h c^2 \\
      c_2 = \frac{hc}{k}
      $$

      and \(h\), \(c\), and \(k\) are Planck's constant, the speed of light, and Boltzmann's constant, respectively.
    </p>
    <p>
      After implementing blackbody rendering using fragment shaders, we have a complete fire simulation!
    </p>
    
    <p>
      <em>Click and drag to add fire above</em>
    </p>
    <p>
      That's it for these notes! There is of course much more to fluid and fire simulation not covered here, like
      different (e.g. non-grid-based) techniques for solving the same problem of simulation within a fixed volume,
      different problems to solve involving varying domains or dynamic obstacles, enhancements to rendering like
      more accurate blackbody radiation, light scattering, or post-processing effects. Helpful introductions
      to these topics can be found in references below.
    </p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perplexity Labs Playground (260 pts)]]></title>
            <link>https://labs.perplexity.ai/</link>
            <guid>38698782</guid>
            <pubDate>Tue, 19 Dec 2023 17:44:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://labs.perplexity.ai/">https://labs.perplexity.ai/</a>, See on <a href="https://news.ycombinator.com/item?id=38698782">Hacker News</a></p>
Couldn't get https://labs.perplexity.ai/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Google agrees to pay $700M in antitrust settlement reached with states (169 pts)]]></title>
            <link>https://apnews.com/article/google-android-play-store-apps-antitrust-settlement-e4e2f422baa846c66deac90c7866c5fd</link>
            <guid>38698707</guid>
            <pubDate>Tue, 19 Dec 2023 17:40:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/google-android-play-store-apps-antitrust-settlement-e4e2f422baa846c66deac90c7866c5fd">https://apnews.com/article/google-android-play-store-apps-antitrust-settlement-e4e2f422baa846c66deac90c7866c5fd</a>, See on <a href="https://news.ycombinator.com/item?id=38698707">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>Google has agreed to pay $700 million and make several other concessions to settle allegations that it had been stifling competition against its Android app store — the same issue that went to trial in another case that could result in even bigger changes.</p><p>Although Google <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/business/colombia-mobile-apps-alphabet-inc-software-legal-proceedings-28c38a5f6981ffd856dc12d4bf3c4537" target="_blank" rel="noopener">struck the deal with</a></span> state attorneys general in September, the settlement’s terms weren’t revealed until late Monday in documents filed in San Francisco federal court. The disclosure came a week after <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/google-epic-games-antitrust-trial-android-app-store-dd6b26be7447b5ff8cc0d20a4d01b6b4" target="_blank" rel="noopener">a federal court jury rebuked Google</a></span> for deploying anticompetitive tactics in its Play Store for Android apps.</p><p>The settlement with the states includes $630 million to compensate U.S. consumers funneled into a payment processing system that state attorneys general alleged drove up the prices for digital transactions within apps downloaded from the Play Store. That store caters to the Android software that powers most of the world’s smartphones.</p>
    

<p>Like Apple does in its iPhone app store, Google collects commissions ranging from 15% to 30% on in-app purchases — fees that state attorneys general contended drove prices higher than they would have been had there been an open market for payment processing. Those commissions generated billions of dollars in profit annually for Google, according to evidence presented in the recent trial focused on its Play Store.</p>
    
        
    
<p>Eligible consumers will receive at least $2, according to the settlement, and may get additional payments based on their spending on the Play store between Aug. 16, 2016 and Sept. 30, 2023. The estimated 102 million U.S. consumers who made in-app purchases during that time frame are supposed to be automatically notified about various options for how they can receive their cut of the money.</p>
    
<p>Another $70 million of the pre-trial settlement will cover the penalties and other costs that Google is being forced to pay to the states. </p><p>Although Google is forking over a sizeable sum, it’s a fraction of the $10.5 billion in damages that the attorneys general estimated the company could be forced to pay if they had taken the case to trial instead of settling.</p>
    

<p>Google also agreed to make other changes designed to make it even easier for consumers to download and install Android apps from other outlets besides its Play Store for the next five years. It will refrain from issuing as many security warnings, or “scare screens,” when alternative choices are being used. </p><p>The makers of Android apps will also gain more flexibility to offer alternative payment choices to consumers instead of having transactions automatically processed through the Play Store and its commission system. Apps will also be able to promote lower prices available to consumers who choose an alternate to the Play Store’s payment processing.</p><p>Investors seemed unfazed by the settlement as shares in Google’s corporate parent, Alphabet Inc., rose slightly in Tuesday’s midday trading.</p><p>The settlement represents a “loud and clear message to Big Tech — attorneys general across the country are unified, and we are prepared to use the full weight of our collective authority to ensure free and fair access to the digital marketplace,” said Connecticut Attorney General William Tong.</p><p>Wilson White, Google’s vice president of government affairs and public policy, framed the deal as a positive for the company, despite the money and concessions it entails. The settlement “builds on Android’s choice and flexibility, maintains strong security protections, and retains Google’s ability to compete with other (software) makers, and invest in the Android ecosystem for users and developers,” White <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://blog.google/outreach-initiatives/public-policy/reaffirming-choice-and-openness-on-android-and-google-play/" target="_blank" rel="noopener">wrote in a blog post.</a></span></p>
    

<p>Although the state attorneys general hailed the settlement as a huge win for consumers, it didn’t go far enough for Epic Games, which spearheaded the attack on Google’s app store practices with an antitrust lawsuit filed in August 2020.</p><p>Epic, the maker of the popular Fortnite video game, rebuffed the settlement in September and instead chose to take its case to trial, even though it had already lost on most of its key claims <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/technology-business-prices-76b30a844324db04f06a144f888a6f0d" target="_blank" rel="noopener">in a similar trial targeting Apple and its iPhone app store in 2021.</a></span></p><p>The Apple trial, though, was decided by a federal judge instead of the jury that vindicated Epic with a unanimous verdict that Google had built anticompetitive barriers around the Play Store. Google has vowed to appeal the verdict.</p><p>Corie Wright, Epic’s vice president of public policy, derided the states’ settlement as little more than a one-time payout that provides “no true relief for consumers or developers,” in a blog post. </p><p>In court documents, the attorneys general said they decided to settle because of significant risks posed by a trial, including the possibility that a jury may have thought their plan to seek $10.5 billion in damages was exorbitant. The attorneys general also cited for the potential of jurors becoming confused had their case been presented alongside Epic’s claims in the trial, as had been the original plan.</p>
    

<p>But now the Epic trial’s outcome nevertheless raises the specter of Google potentially being ordered to pay even more money as punishment for its past practices and making even more dramatic changes to its lucrative Android app ecosystem.</p><p>Those changes will be determined next year by U.S. District Judge James Donato, who presided over the Epic Games trial. Donato also still must approve Google’s Play Store settlement with the states.</p><p>“In the next phase of the case, Epic will seek meaningful remedies to truly open up the Android ecosystem so consumers and developers will genuinely benefit from the competition that U.S. antitrust laws were designed to promote,” Wright pledged.</p><p>Google faces an even bigger legal threat in another antitrust case targeting its dominant search engine that serves as the centerpiece of a digital ad empire that generates more than $200 billion in sales annually. Closing arguments in a trial pitting Google against the Justice Department are scheduled for early May before a federal judge in Washington D.C.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The changing face of post-pandemic New York City (146 pts)]]></title>
            <link>https://www.osc.ny.gov/press/releases/2023/12/changing-face-post-pandemic-new-york-city</link>
            <guid>38698353</guid>
            <pubDate>Tue, 19 Dec 2023 17:15:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.osc.ny.gov/press/releases/2023/12/changing-face-post-pandemic-new-york-city">https://www.osc.ny.gov/press/releases/2023/12/changing-face-post-pandemic-new-york-city</a>, See on <a href="https://news.ycombinator.com/item?id=38698353">Hacker News</a></p>
Couldn't get https://www.osc.ny.gov/press/releases/2023/12/changing-face-post-pandemic-new-york-city: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Comcast says hackers stole data of close to 36M Xfinity customers (206 pts)]]></title>
            <link>https://techcrunch.com/2023/12/19/comcast-xfinity-hackers-36-million-customers/</link>
            <guid>38698343</guid>
            <pubDate>Tue, 19 Dec 2023 17:14:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2023/12/19/comcast-xfinity-hackers-36-million-customers/">https://techcrunch.com/2023/12/19/comcast-xfinity-hackers-36-million-customers/</a>, See on <a href="https://news.ycombinator.com/item?id=38698343">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">Comcast has confirmed that hackers exploiting a critical-rated security vulnerability accessed the sensitive information of almost 36 million Xfinity customers.</p>
<p>This vulnerability, known as “CitrixBleed,” is found in Citrix networking devices often used by big corporations and has been <a href="https://techcrunch.com/2023/11/14/citrix-bleed-critical-bug-ransomware-mass-cyberattacks/" target="_blank" rel="noopener">under mass-exploitation by hackers since late August</a>. Citrix made patches available in early October, but many organizations did not patch in time. Hackers have used the CitrixBleed vulnerability to hack into big-name victims, including aerospace giant Boeing, the Industrial and Commercial Bank of China and international law firm Allen &amp; Overy.</p>
<p>Xfinity, Comcast’s cable television and internet division, became the latest CitrixBleed victim, the company confirmed in <a href="https://www.businesswire.com/news/home/20231218979935/en/Notice-To-Customers-of-Data-Security-Incident/" target="_blank" rel="noopener">a notice to customers</a> on Monday.</p>
<p>The U.S. telecom giant said that hackers exploiting the CitrixBleed vulnerability had access to its internal systems between October 16 and October 19, but that the company did not detect the “malicious activity” until October 25.</p>
<p>By November 16, Xfinity determined that “information was likely acquired” by the hackers, and in December, the company concluded that this included customer data, including usernames and “hashed” passwords, which are scrambled and stored in a way that makes them unreadable to humans. It’s not immediately clear how the passwords were scrambled or using which algorithm, as some weaker hashing algorithms can be cracked.</p>
<p>The company says for an unspecified number of customers, hackers may have also accessed names, contact information, dates of birth, the last four digits of Social Security numbers and their secret questions and answers.</p>
<p>Comcast notes that “our data analysis is continuing, and we will provide additional notices as appropriate,” suggesting additional types of data may also have been accessed.</p>
<p>The notice doesn’t say how many Xfinity customers have been impacted, and Comcast spokesperson Joel Shadle declined to say when asked by TechCrunch. In <a href="https://apps.web.maine.gov/online/aeviewer/ME/40/49e711c6-e27c-4340-867c-9a529ab3ca2c.shtml" target="_blank" rel="noopener">a filing with Maine’s attorney general</a>, Comcast confirmed that almost 35.8 million customers are affected by the breach. Comcast’s latest <a href="https://www.cmcsa.com/news-releases/news-release-details/comcast-reports-2nd-quarter-2023-results" target="_blank" rel="noopener">earnings report</a> shows the company has more than 32 million broadband customers, suggesting this breach has impacted most, if not all Xfinity customers.</p>
<p>It’s not yet known whether Xfinity received a ransom demand, how the incident has impacted the company’s operators or whether the incident has been filed with the U.S. Securities and Exchange Commission, <a href="https://techcrunch.com/2023/12/18/new-sec-data-breach-disclosure-rules/" target="_blank" rel="noopener">as required by the regulator’s new data breach reporting rules</a>. Comcast’s spokesperson would not say.</p>
<p>“We are not aware of any customer data being leaked anywhere, nor of any attacks on our customers,” said Shadle in an email to TechCrunch.</p>
<p>Xfinity says it is requiring that customers reset their passwords and recommends the use of two-factor or multi-factor authentication — which the company doesn’t require by default — for all customer accounts.</p>
<p><em>Updated with additional comment from Comcast.</em></p>
<p><strong>Read more on TechCrunch:</strong></p>
<ul>
<li><a href="https://techcrunch.com/2023/12/18/why-extortion-is-the-new-ransomware-threat/" target="_blank" rel="noopener">Why extortion is the new ransomware threat</a></li>
<li><a href="https://techcrunch.com/2023/11/02/government-sanctions-ransomware-effective/" target="_blank" rel="noopener">Do government sanctions against ransomware groups work?</a></li>
<li><a href="https://techcrunch.com/2023/10/31/ransomware-victims-paying-hackers-ransom/" target="_blank" rel="noopener">Why ransomware victims can’t stop paying off hackers</a></li>
<li><a href="https://techcrunch.com/2023/12/18/new-sec-data-breach-disclosure-rules/" target="_blank" rel="noopener">SEC’s new data breach disclosure rules take effect: what you need to know</a></li>
</ul>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tsdocs.dev: Type docs for any JavaScript library (207 pts)]]></title>
            <link>https://tsdocs.dev</link>
            <guid>38697752</guid>
            <pubDate>Tue, 19 Dec 2023 16:34:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tsdocs.dev">https://tsdocs.dev</a>, See on <a href="https://news.ycombinator.com/item?id=38697752">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>tsdocs.dev helps you browse reference typescript documentation for any package or version of a library.</p><p>Made with the help of<!-- --> <a target="_blank" href="https://github.com/TypeStrong/typedoc">typedoc</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[National Engineering Handbook (135 pts)]]></title>
            <link>https://directives.sc.egov.usda.gov/RollupViewer.aspx?hid=17092</link>
            <guid>38697723</guid>
            <pubDate>Tue, 19 Dec 2023 16:32:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://directives.sc.egov.usda.gov/RollupViewer.aspx?hid=17092">https://directives.sc.egov.usda.gov/RollupViewer.aspx?hid=17092</a>, See on <a href="https://news.ycombinator.com/item?id=38697723">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Plasmic.app: Visual editing and content platform for building websites and apps (194 pts)]]></title>
            <link>https://www.plasmic.app/</link>
            <guid>38697650</guid>
            <pubDate>Tue, 19 Dec 2023 16:27:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.plasmic.app/">https://www.plasmic.app/</a>, See on <a href="https://news.ycombinator.com/item?id=38697650">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/60b3e3671cb40385e961c5d242dc284b.png?q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/60b3e3671cb40385e961c5d242dc284b.png?q=75&amp;f=webp 2x"><img alt="" loading="eager" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/60b3e3671cb40385e961c5d242dc284b.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/60b3e3671cb40385e961c5d242dc284b.png?q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/60b3e3671cb40385e961c5d242dc284b.png?q=75 2x"></picture></div><h2>The <span>visual builder</span> for your tech stack</h2><p>Plasmic is an open-source visual editing and content platform for building websites and apps. Integrate with existing codebases. Ship incredibly fast.</p><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=2048&amp;q=75&amp;f=webp 2048w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=3840&amp;q=75&amp;f=webp 3840w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=3840&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=2048&amp;q=75 2048w, https://img.plasmic.app/img-optimizer/v1/img/cef25fefcd72c5f60e8bbf06ba611750.png?w=3840&amp;q=75 3840w" sizes="100vw"></picture></div></div><div><p>Loved by teams around the world</p></div><div><div><p><h2><span><h2>Build experiences <span>blazingly fast</span></h2></span></h2></p><p><span><span>Get started with a growing library of ready-made components and popular data and app integrations. Build custom experiences with interactions and dynamic values.</span></span></p></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?q=75&amp;f=webp 2048w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/d66055708b35e227b5036f3624192887.png?q=75 2048w" sizes="100vw"></picture></div><div><div><div><p><span><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/744209a6041e927f550afff230a012f5.svg"></picture></div><div><p><h3>Connect to
<span>any data source</span></h3></p><p>Tap into popular data sources like Airtable, PostgreSQL and Shopify with built-in connectors, or connect to any GraphQL or REST API endpoint.</p></div></span></p></div><a href="https://www.plasmic.app/integrations"></a></div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/7bfabb2cc067bbd2ae1b27b89ad77138.svg"></picture></div></div></div></div><div><div><div><h2><span><p>Integrate with any <span> codebase</span></p></span></h2></div><p><span><span>Unlike other no-code and low-code builders, Plasmic integrates with your existing codebase, so you're never confined to a walled garden. </span></span></p></div><div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/4ab412da6ffdb7a2bbe708a6bd414eea.svg"></picture></div><h3><span><h3>Build with your <span>components</span></h3></span></h3><p><span><p>Harness the flexibility to create apps that fit your exact requirements. Bring your data sources, React components, deployment environments, design system, and more.</p></span></p></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?q=75&amp;f=webp 2048w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/ea68c8c10edb0b4a4a48bf2bc4a0019a.jpg?q=75 2048w" sizes="100vw"></picture></div></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?q=75&amp;f=webp 2048w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/00d6dd3f35d1abfabe8c5313d1dab888.jpg?q=75 2048w" sizes="100vw"></picture></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/5de1532ef36fdb0c3219a61fbdaf943a.svg"></picture></div><h3><span><p>Build within <span>existing apps</span></p></span></h3><p><span><span>Instead of iframes, Plasmic lets you build pages that integrate seamlessly within your current applications. Leverage your existing components and code for better performance and more cohesive user experiences. </span></span></p></div></div></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/d3a95bc39e6d8ad9e3f7cfb1d914084c.jpg?w=1920&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/d3a95bc39e6d8ad9e3f7cfb1d914084c.jpg?w=3840&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/d3a95bc39e6d8ad9e3f7cfb1d914084c.jpg?w=3840&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/d3a95bc39e6d8ad9e3f7cfb1d914084c.jpg?w=1920&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/d3a95bc39e6d8ad9e3f7cfb1d914084c.jpg?w=3840&amp;q=75 2x"></picture></div><div><div><h2><span><p>Design experiences your users will <span>love</span></p></span></h2></div><p><span><span>Design custom UIs with responsive layouts and styling that set you apart and delight your users.</span></span></p></div><div><div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/a6887322c6092824ff615637e3eeb553.svg"></picture></div><h3><span><h3>Create completely <span>custom UIs</span></h3></span></h3><p><span><span>Create unique, custom UIs with arbitrary layouts and styling that can be tailored to your specific needs and requirements.</span></span></p></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/d7212315ca176185fe605c0b7f5eb63c.svg"></picture></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?q=75&amp;f=webp 2048w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/cbd52787b7e77a2bc7d792176e181249.png?q=75 2048w" sizes="100vw"></picture></div></div></div><div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/3acd2cc408b37baabe2f4c4dd9af6bed.svg"></picture></div><video autoplay="" muted="" src="https://site-assets.plasmic.app/64f55665dba8fc2cd5a4a9dd7737ce91.mp4"></video></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/c1759e00a445383ed90fa900b53b1a4a.svg"></picture></div><h3><span><h3>Import with <span>Figma</span></h3></span></h3><p><span><span>Quickly turn your Figma designs into React code for production in Plasmic Studio using the best-in-class Figma to code plugin.</span></span></p></div></div></div></div><section><div><div><div><h2><span><p><span>Bridge the gap</span>
between teams</p></span></h2></div><p><span><p>Plasmic makes the development process more collaborative, so everyone can build better experiences together.</p></span></p></div><div><div><h3>Empower 
<span>non-developers</span></h3><p>Empower marketing, content, design, and product teams to build and publish. Developers can register custom components as building blocks that other team members can use.</p></div><div><h3>Collaborate 
<span>effortlessly</span></h3><p>Go from silos and endless backlogs to streamlined workflows between development and business teams. Let everyone focus on what they do best with branching and multiplayer mode.</p></div></div></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=2048&amp;q=75&amp;f=webp 2048w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=3840&amp;q=75&amp;f=webp 3840w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=3840&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=2048&amp;q=75 2048w, https://img.plasmic.app/img-optimizer/v1/img/33950786c9d6e7c370807f338a4dedcc.jpg?w=3840&amp;q=75 3840w" sizes="100vw"></picture></div></section><section><div><div><h2><span><p>Build <span>internal tools</span> and <span>customer-facing</span> apps</p></span></h2></div><p><span><p>Start from a template and make it your own. Or, build from scratch.
From dashboards and admin panels to portals and marketplaces, you can create software for every area of your business.</p></span></p></div><div dir="ltr"><div tabindex="-1" data-index="1" aria-hidden="false"><a href="https://www.plasmic.app/templates/applicant-tracker-template"><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/81514d152c2640ee2577f54792057f38.png?q=75&amp;f=webp 640w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/81514d152c2640ee2577f54792057f38.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/81514d152c2640ee2577f54792057f38.png?q=75 640w" sizes="100vw"></picture></div></a></div><div tabindex="-1" data-index="2" aria-hidden="false"><a href="https://www.plasmic.app/templates/community-forum-template"><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/43f464687631ceb8b342519aec81d7b8.png?q=75&amp;f=webp 640w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/43f464687631ceb8b342519aec81d7b8.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/43f464687631ceb8b342519aec81d7b8.png?q=75 640w" sizes="100vw"></picture></div></a></div></div></section><section><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?q=75&amp;f=webp 2048w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/422b6f87807dae7603046ca99a2e391c.png?q=75 2048w" sizes="100vw"></picture></div><div><div><h2><span><p>Deploy
<span>anywhere</span></p></span></h2></div><p><span><p>Deploy to your choice of hosting infrastructure, so you can maintain control and easily scale your app.</p></span></p></div></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?q=75&amp;f=webp 2048w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/9728863435cdb7545c478c9ecc8d66cb.png?q=75 2048w" sizes="100vw"></picture></div></section><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=640&amp;q=75&amp;f=webp 640w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=750&amp;q=75&amp;f=webp 750w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=828&amp;q=75&amp;f=webp 828w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=1080&amp;q=75&amp;f=webp 1080w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=1200&amp;q=75&amp;f=webp 1200w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=1920&amp;q=75&amp;f=webp 1920w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=2048&amp;q=75&amp;f=webp 2048w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=3840&amp;q=75&amp;f=webp 3840w"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=3840&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=640&amp;q=75 640w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=750&amp;q=75 750w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=828&amp;q=75 828w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=1080&amp;q=75 1080w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=1200&amp;q=75 1200w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=1920&amp;q=75 1920w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=2048&amp;q=75 2048w, https://img.plasmic.app/img-optimizer/v1/img/5646b8e207ff8474ea3ed9bac8895af3.jpg?w=3840&amp;q=75 3840w" sizes="100vw"></picture></div><div><p><h2><span><span>Scale without limits</span></span></h2></p><p><span><span>Manage enterprise-level growth with ease. Scale up and maintain control, even as your application grows and evolves.</span></span></p></div><div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/15ce42b029501d230c3a4f1050ba4671.svg"></picture></div><div><p><span><span>SOC 2 Compliance</span></span></p><p><span><p>Plasmic meets SOC 2 standards for secure handling of sensitive information.</p></span></p></div></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/5f11191c651613ea8ac42e586fc21cb3.svg"></picture></div><div><p><span><span>SSO and Domain Capture</span></span></p><p><span><span>Available for for both Plasmic collaborators and end users of your application.</span></span></p></div></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/6d17f6812d8eea260651594dfbbf36c2.svg"></picture></div><div><p><span><p>Fine-Grained Permissions</p></span></p><p><span><span>Assign and manage fine grained access controls both within Plasmic and your applications.</span></span></p></div></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/08919b5fc0ef66ab0f804e718704c0d2.svg"></picture></div><div><p><span><span>Branching &amp; approvals</span></span></p><p><span><span>Collaborate at scale by working on isolated copies, then review and merge when ready.</span></span></p></div></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/250fa2c1841ecccfce418363815616b0.svg"></picture></div><div><p><span><span>Shared Libraries</span></span></p><p><span><span>Centrally manage assets across your organization. Import and reuse within various projects with ease.</span></span></p></div></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/0ee3a473c9dee543eb3f3d810b0b7c3d.svg"></picture></div><div><p><span><span>On-Premise App Deployment</span></span></p><p><span><span>Deploy your applications on-premise or behind firewalls for enhanced control and security.</span></span></p></div></div></div></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/48c8e1ebfeb87f0954ce3f11fde76c3b.png?w=1920&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/48c8e1ebfeb87f0954ce3f11fde76c3b.png?q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/48c8e1ebfeb87f0954ce3f11fde76c3b.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/48c8e1ebfeb87f0954ce3f11fde76c3b.png?w=1920&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/48c8e1ebfeb87f0954ce3f11fde76c3b.png?q=75 2x"></picture></div><div><p><span><h2>Our customers</h2></span></p><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/5c55aa50c60f65d214350e5916ac3c6f.svg"></picture></div><p><span><h2>us</h2></span></p></div><div><div><div><div><p><span><p>It’s already been a huge increase in efficiency for me, personally. I’m really looking forward to a huge drop in scope for our tests that require new components (most of them).</p></span></p></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/9918cfa817cb7a87732e9b5b73b29c69.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/9918cfa817cb7a87732e9b5b73b29c69.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/9918cfa817cb7a87732e9b5b73b29c69.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/9918cfa817cb7a87732e9b5b73b29c69.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/9918cfa817cb7a87732e9b5b73b29c69.png?w=96&amp;q=75 2x"></picture></div></div><div><div><p><span><span>Really excited about this UI to React components platform. Definitely see a bright future!</span></span></p></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/2fa5844f601b6093616f6c2ed0904149.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/2fa5844f601b6093616f6c2ed0904149.png?q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/2fa5844f601b6093616f6c2ed0904149.png?q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/2fa5844f601b6093616f6c2ed0904149.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/2fa5844f601b6093616f6c2ed0904149.png?q=75 2x"></picture></div><div><p><span><p>Software Engineer
Sidecar Health</p></span></p></div></div></div><div><div><p><span><p>fellow UI engineers and designers, you should pay attention to what the folks over at @plasmicapp are doing. I've been using the beta and it is pretty excellent—this is certainly the future of component development.</p></span></p></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/7b92e878f9571353d6815ebc436e8db7.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/7b92e878f9571353d6815ebc436e8db7.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/7b92e878f9571353d6815ebc436e8db7.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/7b92e878f9571353d6815ebc436e8db7.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/7b92e878f9571353d6815ebc436e8db7.png?w=96&amp;q=75 2x"></picture></div></div></div><div><div><p><span><span>“I had the opportunity to test out an early version of Plasmic and it’s awesome! Excited for the future of this design tool”</span></span></p><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/613fe74c0343aa57d4c1c1f2ad3666e1.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/613fe74c0343aa57d4c1c1f2ad3666e1.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/613fe74c0343aa57d4c1c1f2ad3666e1.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/613fe74c0343aa57d4c1c1f2ad3666e1.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/613fe74c0343aa57d4c1c1f2ad3666e1.png?w=96&amp;q=75 2x"></picture></div><div><p>Cole Bemis</p><p>Design Systems Engineer <a href="https://www.plasmic.app/#">@GitHub</a></p></div></div></div><div><div><div><div><p><span><span>I was pleasantly surprised and at times, blown away, with the Plasmic approach to solving the problem. The whole concept of variants, interactive variants, and slots feels natural and intuitive.</span></span></p></div><div><div><picture><img alt="" loading="lazy" decoding="async" src="https://site-assets.plasmic.app/7ebccefb6961482b121341e26b20a600.svg"></picture></div><div><p><span><span>Software Developer
APS Physics</span></span></p></div></div></div><div><div><p><span><span>We're totally blown away many times a day because of plasmic. You're doing god's work.</span></span></p></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/fee0c90fd2ef5228cafc28301422a439.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/fee0c90fd2ef5228cafc28301422a439.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/fee0c90fd2ef5228cafc28301422a439.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/fee0c90fd2ef5228cafc28301422a439.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/fee0c90fd2ef5228cafc28301422a439.png?w=96&amp;q=75 2x"></picture></div></div></div><div><div><div><p><span><span>By far one of the most empowering tools to come out in a while. If you’re a designer/no coder/visual developer who wants to make world class applications, or a design or development studio looking for a way to serve your clients better and faster—check out Plasmic.</span></span></p></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/988251f9e89e946d6328469374c01a1e.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/988251f9e89e946d6328469374c01a1e.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/988251f9e89e946d6328469374c01a1e.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/988251f9e89e946d6328469374c01a1e.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/988251f9e89e946d6328469374c01a1e.png?w=96&amp;q=75 2x"></picture></div></div><div><div><p><span><span>Plasmic is the most important app to be released in the last five years.</span></span></p></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/d4ecb40ded95cb3243344d66fa12e179.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/d4ecb40ded95cb3243344d66fa12e179.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/d4ecb40ded95cb3243344d66fa12e179.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/d4ecb40ded95cb3243344d66fa12e179.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/d4ecb40ded95cb3243344d66fa12e179.png?w=96&amp;q=75 2x"></picture></div><div><p><span><span>Senior UX Designer
Coupa Software</span></span></p></div></div></div></div></div></div><div><div><div><p><span><span>After using this for about an hour, I'm convinced it's the future.</span></span></p></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/b0877dfabcb2143ddd919d209527fb11.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/b0877dfabcb2143ddd919d209527fb11.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/b0877dfabcb2143ddd919d209527fb11.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/b0877dfabcb2143ddd919d209527fb11.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/b0877dfabcb2143ddd919d209527fb11.png?w=96&amp;q=75 2x"></picture></div><div><p><span><span>Design Director
Outdoorsy</span></span></p></div></div></div><div><div><p><span><span>Watching @yaaang demo quickly creating #react components with ease using his app @plasmicapp for the second time tonight at a @_collab_lab exclusive presentation. AND I’m just as blown away as I was last time! Check out this app, y’all!</span></span></p></div><div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/95184deb5782f4d59c545e8e0382b8f4.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/95184deb5782f4d59c545e8e0382b8f4.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/95184deb5782f4d59c545e8e0382b8f4.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/95184deb5782f4d59c545e8e0382b8f4.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/95184deb5782f4d59c545e8e0382b8f4.png?w=96&amp;q=75 2x"></picture></div><div><p><span><span>Front-End Engineer
Zapier</span></span></p></div></div></div><div><div><p><span><span>I'm super surprised more folks aren't talking about Plasmic — I just got a demo and it's awesome. It's like Figma and Webflow had a baby that outputs React code.</span></span></p></div><div><picture><source type="image/webp" srcset="https://img.plasmic.app/img-optimizer/v1/img/fded68d6821ced242ba6f4040a02329c.png?w=48&amp;q=75&amp;f=webp 1x, https://img.plasmic.app/img-optimizer/v1/img/fded68d6821ced242ba6f4040a02329c.png?w=96&amp;q=75&amp;f=webp 2x"><img alt="" loading="lazy" decoding="async" src="https://img.plasmic.app/img-optimizer/v1/img/fded68d6821ced242ba6f4040a02329c.png?w=96&amp;q=75" srcset="https://img.plasmic.app/img-optimizer/v1/img/fded68d6821ced242ba6f4040a02329c.png?w=48&amp;q=75 1x, https://img.plasmic.app/img-optimizer/v1/img/fded68d6821ced242ba6f4040a02329c.png?w=96&amp;q=75 2x"></picture></div></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nobody knows what's happening online anymore (238 pts)]]></title>
            <link>https://www.theatlantic.com/technology/archive/2023/12/internet-information-trends-virality-tracking/676888/</link>
            <guid>38697227</guid>
            <pubDate>Tue, 19 Dec 2023 16:00:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/technology/archive/2023/12/internet-information-trends-virality-tracking/676888/">https://www.theatlantic.com/technology/archive/2023/12/internet-information-trends-virality-tracking/676888/</a>, See on <a href="https://news.ycombinator.com/item?id=38697227">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header data-event-module="hero"><div><div><p>Why you’ve probably never heard of the most popular Netflix show in the world</p></div><div><figure><div data-flatplan-lead_figure_media="true"><picture><img alt="An image of an iPhone with a TikTok logo on the screen. The screen is cracked and there is a whole in the middle." sizes="(min-width: 976px) 976px, 100vw" srcset="https://cdn.theatlantic.com/thumbor/GQWsQKxK18BdSVDMyh8IQNMUqhA=/0x0:2000x1125/750x422/media/img/mt/2023/12/broken_popularity2/original.png 750w, https://cdn.theatlantic.com/thumbor/ZoAWEW1OQwRfnVVqWr-X8nFeG0M=/0x0:2000x1125/828x466/media/img/mt/2023/12/broken_popularity2/original.png 828w, https://cdn.theatlantic.com/thumbor/3cAp3RGRbWo8WkXVJjdbwvqYclg=/0x0:2000x1125/960x540/media/img/mt/2023/12/broken_popularity2/original.png 960w, https://cdn.theatlantic.com/thumbor/-NyhltUrCtYu7hMQTBUqwwBTphA=/0x0:2000x1125/976x549/media/img/mt/2023/12/broken_popularity2/original.png 976w, https://cdn.theatlantic.com/thumbor/Vz7t0QuPasSkguy2ZwLh1sLXUvY=/0x0:2000x1125/1952x1098/media/img/mt/2023/12/broken_popularity2/original.png 1952w" src="https://cdn.theatlantic.com/thumbor/3cAp3RGRbWo8WkXVJjdbwvqYclg=/0x0:2000x1125/960x540/media/img/mt/2023/12/broken_popularity2/original.png" width="960" height="540"></picture></div><figcaption data-flatplan-lead_figure_caption="true">Illustration by The Atlantic; Source: Getty.</figcaption></figure></div></div><div><p><time datetime="2023-12-18T18:11:00Z" data-flatplan-timestamp="true">December 18, 2023, 1:11 PM ET</time></p></div><gpt-ad format="injector" sizes-at-0="mobile-wide" targeting-pos="injector-article-start" sizes-at-976="desktop-wide"></gpt-ad></header><section data-event-module="article body" data-flatplan-body="true"><p data-flatplan-paragraph="true">You are currently logged on to the largest version of the internet that has ever existed. By clicking and scrolling, you’re one of the 5 billion–plus people contributing to an unfathomable array of networked information—<a data-event-element="inline link" href="https://www.ciobulletin.com/big-data/how-much-data-is-created-every-day-and-how-to-collect-it#:~:text=Key%20Data%20Growth%20Statistics,will%20be%20sent%20every%20second.">quintillions of bytes</a> produced each day.</p><p data-flatplan-paragraph="true">The sprawl has become disorienting. Some of my peers in the media have written about how the internet has started to feel <a data-event-element="inline link" href="https://nymag.com/intelligencer/2023/07/the-2024-election-will-be-an-informational-nightmare.html">“placeless”</a> &nbsp;and more ephemeral, even like it is “<a data-event-element="inline link" href="https://www.garbageday.email/p/is-the-web-actually-evaporating">evaporating</a>.” Perhaps this is because, as my colleague Ian Bogost has <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2022/11/twitter-facebook-social-media-decline/672074/">argued</a>, “the age of social media is ending,” and there is no clear replacement. Or maybe artificial intelligence is flooding the internet with synthetic information and <a data-event-element="inline link" href="https://www.theverge.com/2023/6/26/23773914/ai-large-language-models-data-scraping-generation-remaking-web">killing the old web</a>. Behind these theories is the same general perception: Understanding what is actually happening online has become harder than ever.</p><p data-flatplan-paragraph="true">The internet destroyed any idea of a monoculture long ago, but new complications cloud the online ecosystem today: TikTok’s opaque “For You” recommendation system, the ascension of paywalls that limit access to websites such as this one, the collapse of Twitter—now X—under Elon Musk, <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2023/11/social-media-news-readership-decline/675890/">the waning relevance of news across most social-media sites</a>. The broad effect is an online experience that feels unique to every individual, depending on their ideologies and browsing habits. The very idea of popularity is up for debate: <em>Is that trend really viral? Did everyone see that post, or is it just my little corner of the internet? </em>More than before, it feels like we’re holding a fun-house mirror up to the internet and struggling to make sense of the distorted picture.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/technology/archive/2023/11/social-media-news-readership-decline/675890/">Read: The great social media-news collapse</a></p><p data-flatplan-paragraph="true">“There’s a real lack of understanding of what’s going on across platforms,” Ryan Broderick, who writes the newsletter Garbage Day, told me. For the past six months, Broderick has been partnering with NewsWhip and other online-analytics companies and independently building <a data-event-element="inline link" href="https://www.garbageday.email/p/garbage-intelligence-reports">intelligence reports</a>, tracking the most popular content and personalities across sites such as Facebook, X, Reddit, TikTok, Twitch, and YouTube. In the 2010s, he said, a curious person was better equipped to take the temperature of the web: “The stuff going viral on Facebook was of a different flavor and demographic than, say, YouTube or Twitter, but it felt easier to look at it all, shuffle the decks together, and say,<em> There’s the internet</em>.” Sometime between mid-2021 and early 2022, Broderick noticed that information was moving differently. News stories blew up in corners of the internet and died out, completely bypassing his feeds, and fake “viral” trends popped up with increasing frequency, despite little evidence that anyone was participating in them.</p><p data-flatplan-paragraph="true">Consider TikTok for a second—arguably the most vibrant platform on the internet. Try to imagine which posts might have been most popular on the site this year. Perhaps a dispatch from the Middle East or incendiary commentary on the mass bombings in Gaza? Or maybe something lighter, like a Gen Z dance trend or gossip about Taylor Swift and Travis Kelce? Well, no: According to TikTok’s year-end <a data-event-element="inline link" href="https://newsroom.tiktok.com/en-us/year-on-tiktok-2023">report</a>, the most popular videos in the U.S.—clips racking up as many as half a billion views each—aren’t topical at all. They include makeup tutorials, food ASMR, a woman showing off a huge house cat, and a guy spray-painting his ceiling to look like Iron Man. As a <em>Verge</em> <a data-event-element="inline link" href="https://www.theverge.com/2023/12/6/23989124/tiktoks-biggest-hits-2023-viral-videos-trends-recommendation-algorithm">headline</a> noted earlier this month, “TikTok’s biggest hits are videos you’ve probably never seen.” Other platforms have the same issue: Facebook’s most recent <a data-event-element="inline link" href="https://transparency.fb.com/data/widely-viewed-content-report/#widely-viewed-content">“Widely Viewed Content Report”</a> is full of vapid, pixelated, mostly repackaged memes and videos getting tens of millions of views.</p><p data-flatplan-paragraph="true">The dynamic extends beyond social media too. Just last week, Netflix unexpectedly <a data-event-element="inline link" href="https://about.netflix.com/en/news/what-we-watched-a-netflix-engagement-report">released</a> an unusually comprehensive “engagement report” revealing audience-consumption numbers for most of the TV shows and movies in its library—more than 18,000 titles in all. The attempt at transparency caused confusion among some viewers: Netflix’s single most popular <em>anything</em> from January and June 2023 was a recent thriller series called <em>The Night Agent</em>, which was streamed for 812 million hours globally. “I stay pretty plugged in with media, especially TV shows - legit have never heard of what’s apparently the most watched scripted show in the world,” one person <a data-event-element="inline link" href="https://www.threads.net/@zachhallnc/post/C0xB66huDJk">posted</a> on Threads.</p><p data-flatplan-paragraph="true">This confusion is a feature of a fragmented internet, which can give the impression that two opposing phenomena are happening simultaneously: Popular content is being consumed at an astounding scale, yet popularity and even celebrity feel miniaturized, siloed. We live in a world where it’s easier than ever to be blissfully unaware of things that other people are consuming. It’s also easier than ever to assign outsize importance to information or trends that may <em>feel</em> popular but are actually contained.</p><p data-flatplan-paragraph="true">Last month, a claim began to circulate online that TikTok was awash in viral videos of users reading from and praising Osama bin Laden’s 2002 “Letter to America.” The trend was quickly cited by journalists as a worrying indicator of rising anti-Semitism. But a quick analysis of the platform offered more nuance. Although some videos did exist, <em>The Washington Post</em> <a data-event-element="inline link" href="https://www.washingtonpost.com/style/2023/11/16/guardian-osama-bin-laden-letter-to-america/">found</a> that the “Letter to America” hashtag was on only 274 of them during the two-day period in question. The videos received 1.8 million views—far, far fewer than videos hashtagged with <em>travel</em>, <em>skincare</em>, and <em>anime</em> in another 24-hour stretch, according to examples named by the <em>Post</em>.</p><p data-flatplan-paragraph="true">What followed was a messy postmortem, one that I fear might foreshadow the way 2024-election stories will play out: Internet-savvy reporters <a data-event-element="inline link" href="https://nymag.com/intelligencer/2023/11/did-bin-laden-really-go-viral-on-tiktok.html">tried</a> to offer important <a data-event-element="inline link" href="https://www.garbageday.email/p/tiktok-teens-arent-stanning-osama">correctives</a> to the notion that the letter had gone viral. But others rightly <a data-event-element="inline link" href="https://www.threads.net/@ebakerwhite/post/CzwdeOnvHx7">noted</a> that the videos, at least one of which had more than 10,000 likes, were still troubling, even if they were not viral by TikTok standards. Politicians <a data-event-element="inline link" href="https://x.com/SenHawleyPress/status/1726682198408102081?s=20">seized</a> on the news to further their own long-standing grievances, namely that TikTok, which they fear is controlled by the Chinese government, is influencing and even radicalizing younger American users. TikTok did not respond to my request for comment.</p><p data-flatplan-paragraph="true">As interested parties debated whether the trend was real, the coverage drew greater attention to the videos, causing them to go far more viral on secondary platforms; a video compilation of the TikToks has been <a data-event-element="inline link" href="https://twitter.com/yashar/status/1724942399431217457">viewed</a> more than 41 million times on X. Should this cycle repeat in the same way next year, the 2024 presidential campaign will be an especially punishing affair: It will be the TikTok Shadowboxing Election, where virality becomes a meaningless descriptor that nevertheless justifies any number of conflicts.</p><p data-flatplan-paragraph="true">After the “Letter to America” controversy, I reached out to Brandon Silverman, the founder of CrowdTangle, a platform that tracks the most popular posts across Facebook (which acquired it in 2016). Silverman quit Facebook in 2021, and he now says that big technology platforms are making it harder to verify trends and trace where they came from. Unlike Twitter before Musk, X is a black box, he told me, and TikTok only gives access to its research interface to academic researchers by application. “We’re mostly arguing over data that we don’t have” and “chasing our own tails around the internet,” Silverman said.</p><p data-flatplan-paragraph="true">CrowdTangle itself paused new user sign-ups last year, arguably a major turning point in this entire conversation: Researchers and transparency groups argued that Meta defanged CrowdTangle’s team as part of an <a data-event-element="inline link" href="https://www.rappler.com/technology/features/things-to-know-meta-to-reportedly-shut-down-crowdtangle/">internal</a> reorganization, and reporters have <a data-event-element="inline link" href="https://www.bloomberg.com/news/articles/2022-06-23/meta-pulls-support-for-tool-used-to-keep-misinformation-in-check">speculated</a> that the transparency tool caused too many headaches for Meta executives when it became clear that conspiracy theories, election-denial content, and far-right influencers were popular across the social network. In a statement, a Meta spokesperson told me that paid CrowdTangle accounts are still active and that, last month, the company <a data-event-element="inline link" href="https://about.fb.com/news/2023/11/new-tools-to-support-independent-research/">rolled</a> out a new series of tools to “provide access to near real-time public content from Pages, Posts, Groups and Events” on Facebook, as well as from professional accounts on Instagram.</p><p data-flatplan-paragraph="true">Popularity and virality aren’t the only metrics to determine what’s important, but without an understanding of what is happening online, we’re much more likely to let others take advantage of us or to waste precious time thinking about, debunking, and debating issues and controversies that are actually insignificant or have little impact on the world around us. Likewise, politicians can take trends out of context to fit their own political agenda. Last month on the Senate floor, Senator Marsha Blackburn <a data-event-element="inline link" href="https://www.c-span.org/video/?c5094966/blackburn-tik-tok">cited</a> “the appalling popularity” of the bin Laden letter on TikTok. “This didn’t happen on its own,” Blackburn argued. “You had TikTok pushing along on this.” Some high-profile Democrats, including New York Governor Kathy Hochul, <a data-event-element="inline link" href="https://www.foxnews.com/politics/hochul-slams-tiktok-osama-bin-laden-letter-says-ny-social-media-task-force-wont-penalize-politics">similarly called out TikTok</a>. When we waste our time chasing shadows, Silverman argued, “we miss the more important issues that actually do deserve our time and attention and tell us something truly meaningful about platforms, ourselves, or the world.”</p><p data-flatplan-paragraph="true">Not that a more centralized social-media experience was perfect. “What I saw at CrowdTangle is that, more often than not, it was actually just a few influential accounts that made something ‘go viral,’” Silverman told me. He argued that, because the platform audiences were less fragmented, a few large accounts dictated virality way more often than an army of small ones did. Broderick agreed, noting that, especially on networks such as Twitter, media organizations could identify and amplify trends, thereby increasing their reach—a kind of self-fulfilling prophecy. “One reason why there’s so much consternation is that if you can’t see what’s going on, you can’t rig the game anymore,” he said.</p><p data-flatplan-paragraph="true">A shift away from a knowable internet might feel like a return to something smaller and purer. An internet with no discernable monoculture may feel, especially to those who’ve been continuously plugged into trending topics and viral culture, like a relief. But this new era of the internet is also one that entrenches tech giants and any forthcoming emergent platforms as the sole gatekeepers when it comes to tracking the way that information travels. We already know them to be unreliable narrators and poor stewards, but on a fragmented internet, where recommendation algorithms beat out the older follower model, we rely on these corporations to give us a sense of scale. This might sound overdramatic, but without an innate sense of what other people are doing, we might be losing a way to measure and evaluate ourselves. We’re left shadowboxing one another and arguing in the dark about problems, the size of which we can’t identify.</p></section><gpt-ad format="injector" sizes-at-0="mobile-wide,native,house" targeting-pos="injector-most-popular" sizes-at-976="desktop-wide,native,house"></gpt-ad></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NASA’s tech demo streams first video from deep space via laser (109 pts)]]></title>
            <link>https://www.jpl.nasa.gov/news/nasas-tech-demo-streams-first-video-from-deep-space-via-laser</link>
            <guid>38697195</guid>
            <pubDate>Tue, 19 Dec 2023 15:56:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jpl.nasa.gov/news/nasas-tech-demo-streams-first-video-from-deep-space-via-laser">https://www.jpl.nasa.gov/news/nasas-tech-demo-streams-first-video-from-deep-space-via-laser</a>, See on <a href="https://news.ycombinator.com/item?id=38697195">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-block-key="fpup9">NASA’s <a href="https://www.nasa.gov/mission/deep-space-optical-communications-dsoc/">Deep Space Optical Communications</a> experiment beamed an ultra-high definition streaming video on Dec. 11 from a record-setting 19 million miles away (31 million kilometers, or about 80 times the Earth-Moon distance). The milestone is part of a <a href="https://www.nasa.gov/tdm/">NASA technology demonstration</a> aimed at streaming very high-bandwidth video and other data from deep space – enabling future human missions beyond Earth orbit.</p><p data-block-key="2tr4r">“This accomplishment underscores our commitment to advancing optical communications as a key element to meeting our future data transmission needs,” said NASA Deputy Administrator Pam Melroy. “Increasing our bandwidth is essential to achieving our future exploration and science goals, and we look forward to the continued advancement of this technology and the transformation of how we communicate during future interplanetary missions.”</p><p data-block-key="agam6">The demo transmitted the 15-second test video via a cutting-edge instrument called a <a href="https://photojournal.jpl.nasa.gov/catalog/PIA24569">flight laser transceiver</a>. The video signal took 101 seconds to reach Earth, sent at the system’s maximum bit rate of 267 megabits per second (Mbps). Capable of sending and receiving near-infrared signals, the instrument beamed an encoded near-infrared laser to the Hale Telescope at Caltech’s Palomar Observatory in San Diego County, California, where it was downloaded. Each frame from the looping video was then sent “live” to NASA’s Jet Propulsion Laboratory in Southern California, where the video was played in real time.</p></div><div><p data-block-key="fpup9">The laser communications demo, which <a href="https://www.jpl.nasa.gov/news/nasas-psyche-spacecraft-optical-comms-demo-en-route-to-asteroid">launched</a> with NASA’s Psyche mission on Oct. 13, is designed to transmit data from deep space at rates 10 to 100 times greater than the state-of-the-art radio frequency systems used by deep space missions today. As Psyche travels to the main asteroid belt between Mars and Jupiter, the technology demonstration will send high-data-rate signals as far out as the Red Planet’s greatest distance from Earth. In doing so, it paves the way for higher-data-rate communications capable of sending complex scientific information, high-definition imagery, and video in support of humanity’s next giant leap: <a href="https://www.nasa.gov/moontomarsarchitecture/">sending humans to Mars</a>.</p><p data-block-key="962ql">“One of the goals is to demonstrate the ability to transmit broadband video across millions of miles. Nothing on Psyche generates video data, so we usually send packets of randomly generated test data,” said Bill Klipstein, the tech demo’s project manager at JPL. “But to make this significant event more memorable, we decided to work with designers at JPL to create a fun video, which captures the essence of the demo as part of the Psyche mission.”</p><h3 data-block-key="7kago"><b>Feline Frequency</b></h3><p data-block-key="2kj1o">Uploaded before launch, the short ultra-high definition video features an orange tabby cat named Taters, the pet of a JPL employee, chasing a laser pointer, with overlayed graphics. The graphics illustrate several features from the tech demo, such as Psyche’s orbital path, Palomar’s telescope dome, and technical information about the laser and its data bit rate. Tater’s heart rate, color, and breed are also on display.</p></div><div><p data-block-key="l2mew">“Despite transmitting from millions of miles away, it was able to send the video faster than most broadband internet connections,” said Ryan Rogalin, the project’s receiver electronics lead at JPL. “In fact, after receiving the video at Palomar, it was sent to JPL over the internet, and that connection was slower than the signal coming from deep space. JPL’s <a href="https://www.jpl.nasa.gov/thestudio">DesignLab</a> did an amazing job helping us showcase this technology – everyone loves Taters.”</p><p data-block-key="15ri6">There’s also a historical link: Beginning in 1928, a small statue of the popular cartoon character Felix the Cat was featured in television test broadcast transmissions. Today, cat videos and memes are some of the most popular content online.</p><h3 data-block-key="3bai2"><b>Milestone After Milestone</b></h3><p data-block-key="bp9fu">This latest milestone comes after <a href="https://www.jpl.nasa.gov/news/nasas-deep-space-optical-comm-demo-sends-receives-first-data">“first light” was achieved</a> on Nov. 14. Since then, the system has demonstrated faster data downlink speeds and increased pointing accuracy during its weekly checkouts. On the night of Dec. 4, the project demonstrated downlink bit rates of 62.5 Mbps, 100 Mbps, and 267 Mbps, which is comparable to broadband internet download speeds. The team was able to download a total of 1.3 terabits of data during that time. As a comparison, NASA’s Magellan mission to Venus downlinked 1.2 terabits <a href="https://science.nasa.gov/mission/magellan/">during its entire mission</a> from 1990 to 1994.</p><p data-block-key="427s7">“When we achieved first light, we were excited, but also cautious. This is a new technology, and we are experimenting with how it works,” said Ken Andrews, project flight operations lead at JPL. “But now, with the help of our Psyche colleagues, we are getting used to working with the system and can lock onto the spacecraft and ground terminals for longer than we could previously. We are learning something new during each checkout.”</p><h3 data-block-key="1mbjj"><b>More About the Mission</b></h3><p data-block-key="gmhv">The Deep Space Optical Communications demonstration is the latest in a series of optical communication demonstrations funded by the Technology Demonstration Missions (TDM) program under NASA’s Space Technology Mission Directorate and supported by NASA’s SCaN (Space Communications and Navigation) program within the agency’s Space Operations Mission Directorate.</p><p data-block-key="4jka4">The <a href="https://www.jpl.nasa.gov/missions/psyche">Psyche mission</a> is led by Arizona State University. JPL is responsible for the mission’s overall management, system engineering, integration and test, and mission operations. Psyche is the 14th mission selected as part of NASA’s Discovery Program under the Science Mission Directorate, managed by the agency’s Marshall Space Flight Center in Huntsville, Alabama. NASA’s Launch Services Program, based at the agency’s Kennedy Space Center in Florida, managed the launch service. Maxar Technologies in Palo Alto, California, provided the high-power solar electric propulsion spacecraft chassis</p><p data-block-key="3pji8">For more information about the laser communications demo, visit:</p><p data-block-key="8s13e"><a href="https://www.jpl.nasa.gov/missions/dsoc"><b>https://www.jpl.nasa.gov/missions/dsoc</b></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Diablo 2 Parallax (205 pts)]]></title>
            <link>https://simonschreibt.de/gat/dont-starve-diablo-parallax-7/</link>
            <guid>38697000</guid>
            <pubDate>Tue, 19 Dec 2023 15:44:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonschreibt.de/gat/dont-starve-diablo-parallax-7/">https://simonschreibt.de/gat/dont-starve-diablo-parallax-7/</a>, See on <a href="https://news.ycombinator.com/item?id=38697000">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<div>

<p><img decoding="async" src="https://data.simonschreibt.de/assets/flag_ru.png"></p>


</div>
<p>In the 1990s, games started to move from 2D to 3D and if an alien would have landed on earth back then, it surely would have thought that nobody needs these low-res polygon-models without any filtering. Then it would destroy the earth.</p>
<p>Later his mother would teach him what made humans special: Even during the 2D-Era they had enormous willpower to render 3D – even if it wasn’t yet possible!&nbsp;It started with implementing a <a href="http://en.wikipedia.org/wiki/Parallax_scrolling" target="_blank">parallax effect</a> (depending on the “distance” some elements move faster than others). This parallax effect blew people away back in 1982:</p>

<p>It’s really interesting that a bunch of (differently) moving “planes” have such a strong effect. But it’s a bit flat, right? A perspective camera above the ground would be cool but isn’t possible without “real” 3D? Well, let’s have a look through a time machine to the SNES-Era:</p>

<p>This <em>looks</em> 3D but it’s not! It is <a href="http://en.wikipedia.org/wiki/Super_Nintendo_Entertainment_System" target="_blank">SNES</a> tech and is called “<a href="http://en.wikipedia.org/wiki/Mode_7" target="_blank">Mode 7</a>“. To render it, <a href="http://en.wikipedia.org/wiki/Nintendo" target="_blank">Nintendo</a> manipulated textures (trading height for depth) with some coder magic. Here’s someone who knows the recipe (he talks about the <a href="http://en.wikipedia.org/wiki/Game_Boy_Advance" target="_blank">Gameboy Advance</a> but as far as i know it’s true for the SNES either):</p>
<blockquote><p>“The GBA doesn’t have any real 3D hardware capabilities, but you can fake it by cleverly manipulating the scaling and translation REG_BGxX-REG_BGxPD for every scanline.”<br>
<a href="http://www.coranac.com/tonc/text/mode7.htm" target="_blank">-Cearn</a></p></blockquote>
<p>By the way: even today some people are crazy about the Mode 7 and use it for <a href="http://www.youtube.com/watch?v=BO_GZzrdE9Y" target="_blank">some projects</a> with the <a href="http://www.rpgmakerweb.com/products/programs/rpg-maker-xp" target="_blank">RPG Maker</a>. Impressive!</p>
<p>Nowadays we <em>could</em> render every asset in “real” 3D to give them volume but there are examples where this is just not needed. In fact, it’s sometimes even better to do it old-schoolish:</p>

<p>All the bushes, trees and enemies in <a href="http://www.dontstarvegame.com/" target="_blank">Don’t Starve</a> are flat. And i think it looks awesome!</p>
<p><strong>For me</strong>, <a href="http://us.blizzard.com/en-us/games/d2/" target="_blank">Diablo 2</a> (2D ARPG from year 2000) was the first game which brought the “Moon Patrol”-parallax effect and something like the “Mode 7”-floor-rendering together.</p>
<p>Let’s look at the game with standard settings. Pure 2D. No perspective. No parallax effects:</p>

<p>But the game had a “Perspective Mode”. Let’s turn it <strong>on</strong>! Pay attention, how the pales <strong>don’t</strong> cover the same floor-pixels all the time:</p>

<p>It looks like in Don’t Starve, but remember: Diablo 2 is a <strong>2D</strong> game! There’s no official information about this mode. All what you read now, was only possible by using the awesome tools/documentation by <a href="http://www.angelfire.com/sc/mpq/" target="_blank">Tom Amigo</a> and <a href="http://paul.siramy.free.fr/" target="_blank">Paul Siramy</a> – special thanks to Paul, which answered all my questions and supported me a lot!</p>
<p>It might seem, that Blizzards coders only move the sprites somehow but if you compare the game with perspective mode <span>on</span> and <span>off</span> while standing still, it gets better visible, that they actually “tilt” everything towards the horizon.</p>

<p>This gets even better visible when i add a beautiful checker pattern to the floor textures:</p>

<p>I mean, think of it: every asset has to be transformed somehow, to look perspectively <strong>without any gaps</strong> at the sprite-borders. This is even more impressive if you see of how much sprites the scene consists (a lot chances for gaps…):</p>


<p>And game-tech can’t be complicated enough! So please consider that Blizzard subdivides the sprites <a href="http://paul.siramy.free.fr/_divers/dt1_doc/" target="_blank">into 32x32px parts</a>. This seems to be an optimization to only load necessary parts of an image. Additionally it becomes handy when the transformation is happening. Here you see how an ingame sprite is subdivided:</p>

<p>For every 32px I painted a line on the pale-texture to show a faked wireframe. The result was more interesting than i expected! Like the vertical lines indicate, the sprite got a “real” vanishing point deep in the ground (which you would expect when it comes to perspective):</p>

<p>However, I don’t know why the lower edge of the sprite is bent that way. For the perspective it wouldn’t be necessary (below is a 3Ds Max scene to show that the horizontal lines are straight if the camera isn’t rotated around its front axis):</p>
<p><img decoding="async" loading="lazy" alt="" src="https://data.simonschreibt.de/gat047/d2_persp_test.jpg" width="560" height="600"></p>
<p>Anyway, Blizzards wizards will know why they do that. It may be worth noting, that this deformation is depended on the “angle” you’re looking at the sprite (or the position of the player/camera). Here you can see how the lower edge is straightened up:</p>

<p>For those who are interested in seeing the deformation on a checker pattern, here’s a screenshot:</p>

<p>If you think that all this is interesting enough, than be amazed by reading more.&nbsp;<a href="http://paul.siramy.free.fr/_divers/dt1_doc/" target="_blank">Paul writes</a> that Sprites can have an orientation value. Depending on this value the sprites are deformed differently (yeah…more complexity)! Here’s an example of some wall which have directions defined like (<span>Left Wall</span>, <span>Upper Wall</span>, <span>Lower-Left corner</span>, etc.)</p>

<p>Let me demonstrate what (i <strong>assume</strong>) has to be done. On the next picture you can see a standard ISO view. Below that, there are the steps which i had to make to “fit” the sprites to a “perspective” ground. I had to re-position, re-scale and deform twice to fit them to the floor-grid.</p>
<p><img decoding="async" loading="lazy" alt="" src="https://data.simonschreibt.de/gat047/d2_persp_tilingtest.gif" width="560" height="500"></p>
<p>As you see, this sprite-transformation (as i imagine it) is kind of complicated. Let’s have a look how it actually was made in the game:</p>

<p>This sprite is oriented in a different way than the example i mentioned before. And as you see, the deformation is very different! No bending of the upper/lower edges but instead it looks like the edges “point” to a vanishing point to the left. Again an example how it looks in 3Ds Max:</p>
<p><img decoding="async" loading="lazy" alt="" src="https://data.simonschreibt.de/gat047/d2_persp_test_02.jpg" width="560" height="600"></p>
<p>It’s seems that the game exaggerates the deformation to avoid any gaps between the sprites and i think it’s very successful with that because every sprite of the fence fits perfectly. Pay attention how the edge-orientation (<span>upper</span> edges, <span>lower</span> edges) changes depending on their position:</p>

<p>How important the sprite-orientation values is, shows the next example. If i just tell the game that this isn’t a “right” but a “left” oriented wall, it’s gap-time:</p>

<p>This mode was only activatable with D3D in fullscreen (Diablo 2 also supported Glide and Software Rendering) what made me trying to get my hands on old DirectX-Documentation to get more information. But i wasn’t successful.</p>
<p>So…here ends our trip and i hope you are amazed as I am by this crazy example of the will to make 2D look more 3D. The lack of official information or statements of the government (search your government website for “Diablo 2 perspective mode” … you’ll find nothing!) leads me to one inevitable conclusion:</p>
<p><strong>All this is alien technology!</strong></p>
<p>Tools/Tutorials used for this article</p>
<ul>
<li><a href="http://www.angelfire.com/sc/mpq/" target="_blank">MPQ Editor</a> (for extracing DT1 files out of the MPQ) by <a href="http://www.angelfire.com/sc/mpq/" target="_blank">Tom Amigo</a></li>
<li><a href="http://paul.siramy.free.fr/_divers/dt1/DT1%20Tools.zip" target="_blank">DT1 Tools</a> (for extracting PCX files out of the DT1) by <a href="http://paul.siramy.free.fr/" target="_blank">Paul Simary</a></li>
<li><a href="http://paul.siramy.free.fr/_divers/dt1_doc/" target="_blank">DT1 Tutorial</a> (for understanding the DT1 format) by <a href="http://paul.siramy.free.fr/" target="_blank">Paul Simary</a></li>
<li><a href="http://www.gimp.org/" target="_blank">GIMP</a> (for edit/save the extracted PCX files)</li>
<li><a href="http://paul.siramy.free.fr/_divers/ds1/doc/index.html" target="_blank">Diablo 2 Map Editor</a> (for understanding D2 maps) by <a href="http://paul.siramy.free.fr/" target="_blank">Paul Simary</a></li>
</ul>
<section id="update1">
<p><img decoding="async" src="https://data.simonschreibt.de/assets/icon_update_01.png">Update 1</p>
<p>
Thanks <strong>hans wurst</strong> for <a href="http://toothwalker.org/optics/distortion.html" target="_blank">this link about image aberration</a> which really looks like what we see in Diablo 2 (with activated perspective mode). I don’t know, if this is what the D2-Coders used but at least it looks very similar.
</p>
</section>
<section id="update2">
<p><img decoding="async" src="https://data.simonschreibt.de/assets/icon_update_01.png">Update 2</p>
<div id="update-content">
<p><a href="http://paul.siramy.free.fr/" target="_blank">Paul Simary</a> just mentioned <a href="https://www.gamasutra.com/blogs/DavidCraddock/20180706/321425/How_StarCraft_and_Shower_Epiphanies_Influenced_Diablo_2s_Design.php" rel="noopener" target="_blank">this article on Gamasutra</a> where more details about the perspective mode where revealed. Thanks Paul! That’s awesome!</p>
<blockquote><p>
A 3D graphics card was required to enable Diablo 2’s Perspective Mode. (Lord of Destruction expansion shown.)</p>
<p>A solution occurred to him late one morning. Like the original game, Diablo IIunfolds on a grid, with one major difference. Each diamond-shaped tile is composed of several smaller diamond tiles that allow for some overlap. This meant that objects such as player-characters, monsters, treasure chests, and items can occupy the same squares on a grid by standing in smaller squares within each larger square, an impossibility in the first Diablo. A more granular layout facilitated Dave’s pseudo-3D solution, which he called Perspective Mode.</p>
<p>His idea was to take the texture stored in every miniature tile and rotate it just a smidge, so that it wasn’t quite orthogonal, as players moved around the screen. The game passed those textures to the video card, which painted them onto two polygons and then stretched them vertically and horizontally so that they appeared larger or smaller depending on the player-character’s position. Trees and buildings, for example, seemed larger or smaller as players moved closer or further away, and scrolled by at a different speed than other objects in the foreground and background, creating a parallax effect. Objects shimmered slightly, the result of bilinear filtering, a process baked into graphics cards that smooths out textures when objects are rendered larger or smaller than their native resolutions.</p>
<p>Everything, from characters and items to structures such as the cabins and towers in Act I, expanded and shrank in Perspective Mode, an option only available to users running 3D cards that the game supported. “It was doing real, 3D math, and making this grid scale slightly, stretch slightly,” Dave explained. “It gave a real sense of depth to the world.”</p>
<p>In an impressively short span of time, Perspective Mode was finished and rolled into the latest build of the game. “There were a bunch of things I had to do to make sure walls lined up properly, and the lighting, but I think I wrote that fairly quickly,” Dave continued. “I think it only took me a week or two to get it working. People loved the way it looked, and it really was awesome, but the artists weren’t super happy they had to go back and chop up things and render them differently. We did feel it was worth it in the end, and added a lot to the game.”
</p></blockquote>
<p>Source: <a href="https://www.gamasutra.com/blogs/DavidCraddock/20180706/321425/How_StarCraft_and_Shower_Epiphanies_Influenced_Diablo_2s_Design.php" rel="noopener" target="_blank">How StarCraft and Shower Epiphanies Influenced Diablo 2’s Design</a></p>
</div>
</section>

					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Inner Ring (1944) (158 pts)]]></title>
            <link>https://www.lewissociety.org/innerring/</link>
            <guid>38696764</guid>
            <pubDate>Tue, 19 Dec 2023 15:27:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lewissociety.org/innerring/">https://www.lewissociety.org/innerring/</a>, See on <a href="https://news.ycombinator.com/item?id=38696764">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><div>
	<div>
			<h2>The Inner Ring</h2>
<p><strong>By C. S. Lewis*</strong></p>

		</div> 
	<div>
			<p>May I read you a few lines from Tolstoy’s&nbsp;<i><a href="http://www.amazon.com/exec/obidos/ASIN/0375760644/lewissociety-20">War and Peace</a></i>?<br>
When Boris entered the room, Prince Andrey was listening to an old general, wearing his decorations, who was reporting something to Prince Andrey, with an expression of soldierly servility on his purple face. “Alright. Please wait!” he said to the general, speaking in Russian with the French accent which he used when he spoke with contempt. The moment he noticed Boris he stopped listening to the general who trotted imploringly after him and begged to be heard, while Prince Andrey turned to Boris with a cheerful smile and a nod of the head. Boris now clearly understood—what he had already guessed—that side by side with the system of discipline and subordination which were laid down in the Army Regulations, there existed a different and more real system—the system which compelled a tightly laced general with a purple face to wait respectfully for his turn while a mere captain like Prince Andrey chatted with a mere second lieutenant like Boris. Boris decided at once that he would be guided not by the official system but by this other unwritten system.</p>
<p>When you invite a middle-aged moralist to address you, I suppose I must conclude, however unlikely the conclusion seems, that you have a taste for middle-aged moralising. I shall do my best to gratify it. I shall in fact, give you advice about the world in which you are going to live. I do not mean by this that I am going to talk on what are called current affairs. You probably know quite as much about them as I do. I am not going to tell you—except in a form so general that you will hardly recognise it—what part you ought to play in post-war reconstruction.</p>
<p>It is not, in fact, very likely that any of you will be able, in the next ten years, to make any direct contribution to the peace or prosperity of Europe. You will be busy finding jobs, getting married, acquiring facts. I am going to do something more old-fashioned than you perhaps expected. I am going to give advice. I am going to issue warnings. Advice and warnings about things which are so perennial that no one calls them “current affairs.”</p>
<p>And of course everyone knows what a middle-aged moralist of my type warns his juniors against. He warns them against the World, the Flesh, and the Devil. But one of this trio will be enough to deal with today. The Devil, I shall leave strictly alone. The association between him and me in the public mind has already gone quite as deep as I wish: in some quarters it has already reached the level of confusion, if not of identification. I begin to realise the truth of the old proverb that he who sups with that formidable host needs a long spoon. As for the Flesh, you must be very abnormal young people if you do not know quite as much about it as I do. But on the World I think I have something to say.</p>
<p>In the passage I have just read from Tolstoy, the young second lieutenant Boris Dubretskoi discovers that there exist in the army two different systems or hierarchies. The one is printed in some little red book and anyone can easily read it up. It also remains constant. A general is always superior to a colonel, and a colonel to a captain. The other is not printed anywhere. Nor is it even a formally organised secret society with officers and rules which you would be told after you had been admitted. You are never formally and explicitly admitted by anyone. You discover gradually, in almost indefinable ways, that it exists and that you are outside it; and then later, perhaps, that you are inside it.</p>
<p>There are what correspond to passwords, but they are too spontaneous and informal. A particular slang, the use of particular nicknames, an allusive manner of conversation, are the marks. But it is not so constant. It is not easy, even at a given moment, to say who is inside and who is outside. Some people are obviously in and some are obviously out, but there are always several on the borderline. And if you come back to the same Divisional Headquarters, or Brigade Headquarters, or the same regiment or even the same company, after six weeks’ absence, you may find this secondary hierarchy quite altered.</p>
<p>There are no formal admissions or expulsions. People think they are in it after they have in fact been pushed out of it, or before they have been allowed in: this provides great amusement for those who are really inside. It has no fixed name. The only certain rule is that the insiders and outsiders call it by different names. From inside it may be designated, in simple cases, by mere enumeration: it may be called “You and Tony and me.” When it is very secure and comparatively stable in membership it calls itself “we.” When it has to be expanded to meet a particular emergency it calls itself “all the sensible people at this place.” From outside, if you have dispaired of getting into it, you call it “That gang” or “they” or “So-and-so and his set” or “The Caucus” or “The Inner Ring.” If you are a candidate for admission you probably don’t call it anything. To discuss it with the other outsiders would make you feel outside yourself. And to mention talking to the man who is inside, and who may help you if this present conversation goes well, would be madness.</p>
<p>Badly as I may have described it, I hope you will all have recognised the thing I am describing. Not, of course, that you have been in the Russian Army, or perhaps in any army. But you have met the phenomenon of an Inner Ring. You discovered one in your house at school before the end of the first term. And when you had climbed up to somewhere near it by the end of your second year, perhaps you discovered that within the ring there was a Ring yet more inner, which in its turn was the fringe of the great school Ring to which the house Rings were only satellites. It is even possible that the school ring was almost in touch with a Masters’ Ring. You were beginning, in fact, to pierce through the skins of an onion. And here, too, at your University—shall I be wrong in assuming that at this very moment, invisible to me, there are several rings—independent systems or concentric rings—present in this room? And I can assure you that in whatever hospital, inn of court, diocese, school, business, or college you arrive after going down, you will find the Rings—what Tolstoy calls the second or unwritten systems.</p>
<p>All this is rather obvious. I wonder whether you will say the same of my next step, which is this. I believe that in all men’s lives at certain periods, and in many men’s lives at all periods between infancy and extreme old age, one of the most dominant elements is the desire to be inside the local Ring and the terror of being left outside. This desire, in one of its forms, has indeed had ample justice done to it in literature. I mean, in the form of snobbery. Victorian fiction is full of characters who are hag-ridden by the desire to get inside that particular Ring which is, or was, called Society. But it must be clearly understood that “Society,” in that sense of the word, is merely one of a hundred Rings, and snobbery therefore only one form of the longing to be inside.</p>
<p>People who believe themselves to be free, and indeed are free, from snobbery, and who read satires on snobbery with tranquil superiority, may be devoured by the desire in another form. It may be the very intensity of their desire to enter some quite different Ring which renders them immune from all the allurements of high life. An invitation from a duchess would be very cold comfort to a man smarting under the sense of exclusion from some artistic or communistic côterie. Poor man—it is not large, lighted rooms, or champagne, or even scandals about peers and Cabinet Ministers that he wants: it is the sacred little attic or studio, the heads bent together, the fog of tobacco smoke, and the delicious knowledge that we—we four or five all huddled beside this stove—are the people who know.</p>
<p>Often the desire conceals itself so well that we hardly recognize the pleasures of fruition. Men tell not only their wives but themselves that it is a hardship to stay late at the office or the school on some bit of important extra work which they have been let in for because they and So-and-so and the two others are the only people left in the place who really know how things are run. But it is not quite true. It is a terrible bore, of course, when old Fatty Smithson draws you aside and whispers, “Look here, we’ve got to get you in on this examination somehow” or “Charles and I saw at once that you’ve got to be on this committee.” A terrible bore… ah, but how much more terrible if you were left out! It is tiring and unhealthy to lose your Saturday afternoons: but to have them free because you don’t matter, that is much worse.</p>
<p>Freud would say, no doubt, that the whole thing is a subterfuge of the sexual impulse. I wonder whether the shoe is not sometimes on the other foot. I wonder whether, in ages of promiscuity, many a virginity has not been lost less in obedience to Venus than in obedience to the lure of the caucus. For of course, when promiscuity is the fashion, the chaste are outsiders. They are ignorant of something that other people know. They are uninitiated. And as for lighter matters, the number of people who first smoked or first got drunk for a similar reason is probably very large.</p>
<p>I must now make a distinction. I am not going to say that the existence of Inner Rings is an Evil. It is certainly unavoidable. There must be confidential discussions: and it is not only a bad thing, it is (in itself) a good thing, that personal friendship should grow up between those who work together. And it is perhaps impossible that the official hierarchy of any organisation should coincide with its actual workings. If the wisest and most energetic people held the highest spots, it might coincide; since they often do not, there must be people in high positions who are really deadweights and people in lower positions who are more important than their rank and seniority would lead you to suppose. It is necessary: and perhaps it is not a necessary evil. But the desire which draws us into Inner Rings is another matter. A thing may be morally neutral and yet the desire for that thing may be dangerous. As Byron has said:</p>
<ul>
<li>Sweet is a legacy, and passing sweet</li>
<li>The unexpected death of some old lady</li>
</ul>

		</div> </div><div>
			<p>The painless death of a pious relative at an advanced age is not an evil. But an earnest desire for her death on the part of her heirs is not reckoned a proper feeling, and the law frowns on even the gentlest attempts to expedite her departure. Let Inner Rings be unavoidable and even an innocent feature of life, though certainly not a beautiful one: but what of our longing to enter them, our anguish when we are excluded, and the kind of pleasure we feel when we get in?</p>
<p>I have no right to make assumptions about the degree to which any of you may already be compromised. I must not assume that you have ever first neglected, and finally shaken off, friends whom you really loved and who might have lasted you a lifetime, in order to court the friendship of those who appeared to you more important, more esoteric. I must not ask whether you have derived actual pleasure from the loneliness and humiliation of the outsiders after you, yourself were in: whether you have talked to fellow members of the Ring in the presence of outsiders simply in order that the outsiders might envy; whether the means whereby, in your days of probation, you propitiated the Inner Ring, were always wholly admirable. I will ask only one question—and it is, of course, a rhetorical question which expects no answer. IN the whole of your life as you now remember it, has the desire to be on the right side of that invisible line ever prompted you to any act or word on which, in the cold small hours of a wakeful night, you can look back with satisfaction? If so, your case is more fortunate than most.</p>
<p>My main purpose in this address is simply to convince you that this desire is one of the great permanent mainsprings of human action. It is one of the factors which go to make up the world as we know it—this whole pell-mell of struggle, competition, confusion, graft, disappointment and advertisement, and if it is one of the permanent mainsprings then you may be quite sure of this. Unless you take measures to prevent it, this desire is going to be one of the chief motives of your life, from the first day on which you enter your profession until the day when you are too old to care. That will be the natural thing—the life that will come to you of its own accord. Any other kind of life, if you lead it, will be the result of conscious and continuous effort. If you do nothing about it, if you drift with the stream, you will in fact be an “inner ringer.” I don’t say you’ll be a successful one; that’s as may be. But whether by pining and moping outside Rings that you can never enter, or by passing triumphantly further and further in—one way or the other you will be that kind of man.</p>
<p>I have already made it fairly clear that I think it better for you not to be that kind of man. But you may have an open mind on the question. I will therefore suggest two reasons for thinking as I do. It would be polite and charitable, and in view of your age reasonable too, to suppose that none of you is yet a scoundrel. On the other hand, by the mere law of averages (I am saying nothing against free will) it is almost certain that at least two or three of you before you die will have become something very like scoundrels. There must be in this room the makings of at least that number of unscrupulous, treacherous, ruthless egotists. The choice is still before you: and I hope you will not take my hard words about your possible future characters as a token of disrespect to your present characters.</p>
<p>And the prophecy I make is this. To nine out of ten of you the choice which could lead to scoundrelism will come, when it does come, in no very dramatic colours. Obviously bad men, obviously threatening or bribing, will almost certainly not appear. Over a drink, or a cup of coffee, disguised as triviality and sandwiched between two jokes, from the lips of a man, or woman, whom you have recently been getting to know rather better and whom you hope to know better still—just at the moment when you are most anxious not to appear crude, or naïf or a prig—the hint will come. It will be the hint of something which the public, the ignorant, romantic public, would never understand: something which even the outsiders in your own profession are apt to make a fuss about: but something, says your new friend, which “we”—and at the word “we” you try not to blush for mere pleasure—something “we always do.”</p>
<p>And you will be drawn in, if you are drawn in, not by desire for gain or ease, but simply because at that moment, when the cup was so near your lips, you cannot bear to be thrust back again into the cold outer world. It would be so terrible to see the other man’s face—that genial, confidential, delightfully sophisticated face—turn suddenly cold and contemptuous, to know that you had been tried for the Inner Ring and rejected. And then, if you are drawn in, next week it will be something a little further from the rules, and next year something further still, but all in the jolliest, friendliest spirit. It may end in a crash, a scandal, and penal servitude; it may end in millions, a peerage and giving the prizes at your old school. But you will be a scoundrel.</p>
<p>That is my first reason. Of all the passions, the passion for the Inner Ring is most skillful in making a man who is not yet a very bad man do very bad things. My second reason is this. The torture allotted to the Danaids in the classical underworld, that of attempting to fill sieves with water, is the symbol not of one vice, but of all vices. It is the very mark of a perverse desire that it seeks what is not to be had. The desire to be inside the invisible line illustrates this rule. As long as you are governed by that desire you will never get what you want. You are trying to peel an onion: if you succeed there will be nothing left. Until you conquer the fear of being an outsider, an outsider you will remain.</p>
<p>This is surely very clear when you come to think of it. If you want to be made free of a certain circle for some wholesome reason—if, say, you want to join a musical society because you really like music—then there is a possibility of satisfaction. You may find yourself playing in a quartet and you may enjoy it. But if all you want is to be in the know, your pleasure will be short lived. The circle cannot have from within the charm it had from outside. By the very act of admitting you it has lost its magic.</p>
<p>Once the first novelty is worn off, the members of this circle will be no more interesting than your old friends. Why should they be? You were not looking for virtue or kindness or loyalty or humour or learning or wit or any of the things that can really be enjoyed. You merely wanted to be “in.” And that is a pleasure that cannot last. As soon as your new associates have been staled to you by custom, you will be looking for another Ring. The rainbow’s end will still be ahead of you. The old ring will now be only the drab background for your endeavor to enter the new one.</p>
<p>And you will always find them hard to enter, for a reason you very well know. You yourself, once you are in, want to make it hard for the next entrant, just as those who are already in made it hard for you. Naturally. In any wholesome group of people which holds together for a good purpose, the exclusions are in a sense accidental. Three or four people who are together for the sake of some piece of work exclude others because there is work only for so many or because the others can’t in fact do it. Your little musical group limits its numbers because the rooms they meet in are only so big. But your genuine Inner Ring exists for exclusion. There’d be no fun if there were no outsiders. The invisible line would have no meaning unless most people were on the wrong side of it. Exclusion is no accident; it is the essence.</p>
<p>The quest of the Inner Ring will break your hearts unless you break it. But if you break it, a surprising result will follow. If in your working hours you make the work your end, you will presently find yourself all unawares inside the only circle in your profession that really matters. You will be one of the sound craftsmen, and other sound craftsmen will know it. This group of craftsmen will by no means coincide with the Inner Ring or the Important People or the People in the Know. It will not shape that professional policy or work up that professional influence which fights for the profession as a whole against the public: nor will it lead to those periodic scandals and crises which the Inner Ring produces. But it will do those things which that profession exists to do and will in the long run be responsible for all the respect which that profession in fact enjoys and which the speeches and advertisements cannot maintain.</p>
<p>And if in your spare time you consort simply with the people you like, you will again find that you have come unawares to a real inside: that you are indeed snug and safe at the centre of something which, seen from without, would look exactly like an Inner Ring. But the difference is that the secrecy is accidental, and its exclusiveness a by-product, and no one was led thither by the lure of the esoteric: for it is only four or five people who like one another meeting to do things that they like. This is friendship. Aristotle placed it among the virtues. It causes perhaps half of all the happiness in the world, and no Inner Ring can ever have it.</p>
<p>We are told in Scripture that those who ask get. That is true, in senses I can’t now explore. But in another sense there is much truth in the schoolboy’s principle “them as asks shan’t have.” To a young person, just entering on adult life, the world seems full of “insides,” full of delightful intimacies and confidentialities, and he desires to enter them. But if he follows that desire he will reach no “inside” that is worth reaching. The true road lies in quite another direction. It is like the house in <a href="https://www.amazon.com/exec/obidos/ASIN/1858943299//lewissociety-20" target="_blank" rel="noopener">Alice Through the Looking Glass.</a></p>

		</div><div>
		<p>*&nbsp;<b><a href="#">C. S. Lewis</a></b>&nbsp;(1898-1963) was Professor of Medieval and Renaissance Literature at Cambridge University and a Fellow of Magdalene College, Cambridge. “The Inner Ring” was the Memorial Lecture at King’s College, University of London, in 1944.</p> 
	</div>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fedora Asahi Remix (186 pts)]]></title>
            <link>https://asahilinux.org/fedora/</link>
            <guid>38696612</guid>
            <pubDate>Tue, 19 Dec 2023 15:17:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://asahilinux.org/fedora/">https://asahilinux.org/fedora/</a>, See on <a href="https://news.ycombinator.com/item?id=38696612">Hacker News</a></p>
<div id="readability-page-1" class="page">
<div id="eye-catch">
<div>
<p>Introducing</p><p>The most polished Linux® for Apple Silicon Macs.</p><h2>Install from macOS</h2><pre><code id="curl">curl https://alx.sh | sh</code> <a id="copy-button" href="#"><i></i></a></pre></div><p><img src="https://asahilinux.org/img/far_landing/far_laptop.svg" alt="Fedora Asahi Remix on a laptop">
</p></div><section>
<h2 id="divfedora-linux-39--apple-silicon--fedora-asahi-remixdiv"><p>Fedora Linux 39 + Apple Silicon = Fedora Asahi Remix</p></h2><p><img width="200" src="https://asahilinux.org/img/far_landing/fedora_remix.png">Fedora Asahi Remix is the result of a close multi-year collaboration between the Asahi Linux project and the <a href="https://fedoraproject.org/">Fedora Project</a>. We’ve worked hard in order to bring you a fully integrated distro, cooperating closely to get improvements and bug fixes to users as quickly as possible. All of our Asahi platform-specific packages are in upstream Fedora and fully supported in Fedora Linux 39.</p><p>With Fedora’s excellent 64-bit ARM support and mature development process, you can expect a solid and high-quality experience without any unwanted surprises. Fedora Asahi Remix is based on Fedora Linux 39, the latest Fedora Linux release with the newest software versions across the board. All M1 and M2 series MacBook, Mac Mini, Mac Studio, and iMac devices are supported.</p></section><section>
<h2 id="divfedora-asahi-remix--kde-plasmadiv"><p>Fedora Asahi Remix ❤️ KDE Plasma</p></h2><p><img width="150" src="https://asahilinux.org/img/far_landing/kde-logo-white-blue-rounded-source.svg">We are proud to offer <a href="https://kde.org/plasma-desktop/">KDE Plasma</a> as our flagship desktop environment. With leading edge Wayland support and a highly customizable experience plus wide support for Apple hardware features, KDE Plasma is a joy to use on Apple Silicon.</p><p>Want to use Night Color to keep your screen from disrupting your sleep cycle? No worries, it just works. Tweak your trackpad settings for a more comfortable experience? Everything’s right there in System Settings. Are things on screen too big or too small? Just adjust the display scale to your heart’s content, even in 5% increments. We’ve worked with the KDE project to bring you bug fixes and improvements to improve platform support, and we’ve also built a custom Calamares-based initial setup wizard so you can be up and running in no time with minimal fuss.</p><p>Fedora Linux 39 comes with KDE Plasma 5.27, with the latest patches and improvements. But that’s not all: Stay tuned for the upcoming Fedora Linux 40, which will bring us KDE Plasma 6 with even more improvements.</p><p>Rather use <a href="https://www.gnome.org/">GNOME</a>? No worries, we’ve got you covered with GNOME 45. Or, if you prefer to roll your own desktop configuration or want to set up a headless server, our Server and Minimal images will let you set things up exactly the way you want to.</p></section><section>
<h2 id="div100-wayland-experiencediv"><p>100% Wayland Experience</p></h2><p><img width="150" src="https://asahilinux.org/img/far_landing/Wayland_Logo.svg">Whether you’re a KDE enthusiast or a GNOME lover, Fedora Asahi Remix comes right out of the box with a 100% <a href="https://wayland.freedesktop.org/">Wayland</a> environment, bringing you the newest desktop and display server technologies, which are a perfect match for Apple hardware. You’ll get a buttery smooth desktop, with absolutely no tearing or glitching, just like on macOS. Experience seamless HiDPI support in our KDE Plasma builds, even across multiple displays with different display scales.</p><p>And with upcoming improvements in the Wayland ecosystem, we’ll be able to support new technologies such as HDR and display notches, as well as proper display calibration. Have some X11 apps to run? No worries, XWayland is available and fully supported as a bridge for legacy applications.</p></section><section>
<h2 id="divopengl-deprecated-not-herediv"><p>OpenGL, deprecated? Not here</p></h2><p><img width="200" src="https://asahilinux.org/img/far_landing/OpenGL_ES_logo.svg">Fedora Asahi Remix ships with non-conformant OpenGL 3.3 support including GPU-accelerated geometry shaders and transform feedback, as well as the world’s first and only <a href="https://www.khronos.org/conformance/adopters/conformant-products/opengles#submission_1007">certified conformant OpenGL ES 3.1</a> implementation for Apple Silicon.</p><p>We support open graphics standards and test against official and industry-standard test suites, which means you can be confident that your apps and games will run correctly and render as they’re intended to. And we’re not stopping there, with OpenGL 4.x and Vulkan support in the works. We aim to unlock the full potential of Apple Silicon graphics, well beyond what is possible by layering on top of vendor-proprietary APIs like Metal.</p></section><section>
<h2 id="divthe-best-linux-laptop-audio-youve-ever-hearddiv"><p>The best Linux laptop audio you’ve ever heard</p></h2><p><img width="200" src="https://asahilinux.org/img/far_landing/curves.svg">Over the past two years, we’ve worked hard to pioneer the world’s first fully integrated DSP solution for the desktop Linux ecosystem. Just install Fedora Asahi Remix and enjoy high-quality audio right out of the box, no setup needed. We’ve worked together with the <a href="https://pipewire.org/">PipeWire</a> and <a href="https://gitlab.freedesktop.org/pipewire/wireplumber">WirePlumber</a> projects to add support for fully automatic and transparent DSP configuration, and then individually measured and calibrated 8+ different machine models, designing a customized DSP filter configuration for each one.</p><p>With our in-house <a href="https://github.com/chadmed/bankstown">Bankstown</a> bass boost technology and our own pioneering open source <a href="https://github.com/AsahiLinux/speakersafetyd">Smart Amp</a> implementation to safely provide full loudness and dynamic range, the result is the best audio you’ve ever heard on a Linux laptop. And we’ve even optimized the scheduling and power consumption of the DSP processing, so you’ll get excellent battery life while playing back audio.</p></section><section id="device-support">
<p>
<h2 id="device-support">Device support</h2></p><div>
<div id="info-dev1">
<h3>Chips</h3><h3>Features</h3><div>
<p>Display</p><p>Keyboard (+ Backlight)</p><p>Trackpad</p><p>Headset Jack</p><p>Speakers</p><p>Camera</p><p>MagSafe*</p><p>USB Type C (USB 3.0)</p><p>Wi-Fi</p><p>Bluetooth</p><p>USB-C Displays</p><p>Thunderbolt / USB4</p><p>Microphone</p><p>Touch ID</p></div><p>* Available on M2 model only.</p></div><div id="info-dev2">
<h3>Chips</h3><div>
<p>M1</p><p>M1 Pro</p><p>M1 Max</p><p>M2</p><p>M2 Pro</p><p>M2 Max</p></div><h3>Features</h3><div>
<p>Display*</p><p>Keyboard (+ Backlight)</p><p>Trackpad</p><p>Touch Bar†</p><p>Headset Jack</p><p>Speakers</p><p>Camera</p><p>MagSafe‡</p><p>USB Type C (USB 3.0)</p><p>HDMI‡</p><p>SD Card‡</p><p>Wi-Fi</p><p>Bluetooth</p><p>USB-C Displays</p><p>Thunderbolt / USB4</p><p>Microphone</p><p>Touch ID</p></div><p>* Local dimming available on 14" and 16" models. Maximum 60Hz refresh rate on all models. HDR/120Hz not yet supported.</p><p>† Available on 13" models only.</p><p>‡ Available on 14" and 16" models only.</p></div><div id="info-dev3">
<h3>Chips</h3><h3>Features</h3><div>
<p>Headset Jack</p><p>Speaker</p><p>USB Type A (3.0)</p><p>USB Type C (3.0)</p><p>HDMI</p><p>Ethernet (1/10 Gbps)</p><p>Wi-Fi</p><p>Bluetooth</p><p>USB-C Displays</p><p>Thunderbolt / USB4</p></div></div><div id="info-dev4">
<h3>Chips</h3><div>
<p>M1 Max</p><p>M1 Ultra</p><p>M2 Max</p><p>M2 Ultra</p></div><h3>Features</h3><div>
<p>Headset Jack</p><p>Speaker</p><p>USB Type A (3.0)</p><p>USB Type C (3.0)</p><p>HDMI</p><p>SD Card</p><p>Ethernet (10 Gbps)</p><p>Wi-Fi</p><p>Bluetooth</p><p>USB-C Displays</p><p>Thunderbolt / USB4</p></div></div><div id="info-dev5">
<h3>Chips</h3><h3>Features</h3><div>
<p>Display</p><p>Headset Jack</p><p>Speakers</p><p>Camera</p><p>USB Type C (3.0)</p><p>Ethernet (1 Gbps)</p><p>Wi-Fi</p><p>Bluetooth</p><p>USB-C Displays</p><p>Thunderbolt / USB4</p><p>Microphone</p></div></div></div></section>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[JetBrains forces AI freemium plugin that cannot be completely removed into IDEs (138 pts)]]></title>
            <link>https://youtrack.jetbrains.com/issue/LLM-1760/Can-not-remove-Jetbrains-AI-Assistant-plugin-completely</link>
            <guid>38696325</guid>
            <pubDate>Tue, 19 Dec 2023 15:00:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://youtrack.jetbrains.com/issue/LLM-1760/Can-not-remove-Jetbrains-AI-Assistant-plugin-completely">https://youtrack.jetbrains.com/issue/LLM-1760/Can-not-remove-Jetbrains-AI-Assistant-plugin-completely</a>, See on <a href="https://news.ycombinator.com/item?id=38696325">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The day I started believing in unit tests (127 pts)]]></title>
            <link>https://mental-reverb.com/blog.php?id=42</link>
            <guid>38695938</guid>
            <pubDate>Tue, 19 Dec 2023 14:32:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mental-reverb.com/blog.php?id=42">https://mental-reverb.com/blog.php?id=42</a>, See on <a href="https://news.ycombinator.com/item?id=38695938">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
Right after getting my degree, I was lucky to be hired into a small but decent R&amp;D department as an embedded software engineer. My first task was to create a Unit Test project and have it run in our build pipeline after compilation. I was not particularly excited about this task, it seemed like busywork to me. I believed that Unit Tests are largely worthless throwaway code. They probably didn't want me to immediately dive into production code. Fair enough, I thought. I'm the newcomer and this is something that is requested by engineers who are way more experienced than I am. So for now, I should just go along with it, even if I believe it's a waste of time.
</p>

<p>
So, ahead I went. I implemented the test suite and some basic tests, including some that I ported from our old, deprecated test framework to googletest. The test was started by our build pipeline after compilation, it actually transferred the test binary to a physical device which was (and still is) situated in our office and ran the QNX operating system to perform on-target tests. This was necessary because the code used many QNX primitives and needed to be tested on that operating system. So, the test was something between a Unit Test and an Integration Test. The mechanism worked well and it ran multiple times per day. Since the test coverage was quite small and nobody ever touched that code anyway, it always succeeded - another reason why I thought it's a waste of time. Also, it was rare for new tests to be added. It's very hard to write Unit Tests for embedded firmware and hardware abstractions because the very thing you want to test is the interaction with the hardware, which is precisely what you can't do in pure code. Because the test ran automatically and always succeeded, we all soon forgot about it and moved on to other things.
</p>

<p>
Fast forward about a year. The test ran hundreds if not thousands of times successfully. What a waste of time... But then, one day, we started observing test failures. Not many, maybe three over the course of a few weeks. The test actually crashed with a Segmentation Fault, so it was clear that it was a severe error. Interestingly, none of the code under test had actually changed. Well, that's definitely something we had to investigate! I spare you the details of the search for the error, but eventually, I was able to reproduce the problem while a debugger was attached, so the entire context of the problem was handed to me on a silver platter.
</p>

<p>
The problem had to do with how our threading abstraction, which worked with inheritance, was used in the test framework. There is a base class that starts the thread with a virtual function and the user of the abstraction is supposed to <code>override</code> that function, kind of like this:
</p>

<p><code>/* Library code: */
class Thread {
	public:
		Thread() { /* ... */ }
		virtual ~Thread() { stop(); }
		void stop() { /* join the thread if running */ }
	protected:
		virtual void singlepassThreadWork() = 0;
};

/* User code: */
class MyThread : public Thread {
	protected:
		void singlepassThreadWork() override {
			/* do stuff with foobar */
		}
	private:
		std::vector&lt;int&gt; foobar;
};
</code></p><p>

Now, what happens when <code>MyThread::singlepassThreadWork()</code> uses a member variable of <code>MyThread</code> like <code>foobar</code> and we <code>delete</code> the <code>MyThread</code> object while the thread is still running? The destruction sequence is such that <code>MyThread</code> is deleted first and <i>after that</i>, the destructor of its parent object <code>Thread</code> runs and the thread is joined. Thus, there is a race condition: We risk accessing the vector <code>foobar</code> in <code>singlepassThreadWork()</code> after it was already deleted. We can fix the user code by explicitly stopping the thread in its destructor:

</p><p><code>/* User code: */
class MyThread : public Thread {
	public:
		~MyThread() { stop() }
	protected:
		void singlepassThreadWork() override {
			/* do stuff with foobar */
		}
	private:
		std::vector&lt;int&gt; foobar;
};
</code></p>

<p>
My disappointment was immeasurable. The bug was in the test framework itself, not in the code under test. Unit Tests really are worthless and this is a waste of time... Right? But then I had to think of a <a href="https://multicians.org/thvv/comix.html">comic</a> that I had found on the internet and I had actually printed out this comic and put it on the wall in our office:
</p>

<p>
<img src="https://mental-reverb.com/img/believeinunittest_comix-1.gif">
</p>

<p>
Even though this comic is older than I am, from a long bygone hacker era, it resonated with me a lot because the wisdom within it still holds true. Whenever you encounter a bug, ask yourself the following three questions:
</p>

<ol>
	<li>Have I made this error anywhere else?</li>
	<li>What happens when I fix the bug?</li>
	<li>How can I change my ways to make this bug impossible?</li>
</ol>

<p>
It seems so simple, but it's a really powerful methodology to prevent further errors and raise code quality. With this comic in mind, I asked myself whether this error existed anywhere else in the code - and boy did I find a boatload of instances of this race condition. It was <i>everywhere</i>. A co-worker and I combed through the entire code base and fixed this type of error in a few large commits, adding a <code>stop()</code> call in the destructor of the class that was the lowest in the inheritance hierarchy for each thread. Furthermore, we made all the developers aware of this pitfall and kept an eye on new code that could be affected. We never observed this bug again in the years since. In addition, we were now aware that this inheritance-based abstraction is defective by design, since most of its uses suffer from a race condition that has to be mitigated manually by the programmer. Designs of new abstractions would not be subject to such pitfalls as we encouraged developers to use composition and dependency injection over inheritance, which raised the overall code quality significantly.
</p>

<p>
We never found out why the race condition suddenly started causing crashes after a year's worth of successful runs. As mentioned, none of the involved code was changed. As far as I know, the operating system on the test system was not modified during that time period. The crashes must have been caused by subtle differences in how the threads were scheduled. Perhaps the addition of unrelated tests made the Unit Test binary larger and caused side-effects regarding CPU caches and timings? We'll never know.
</p>

<p>
The day I found this race condition thanks to Unit Tests was the day I truly started to believe in their value. I kept expanding the test project and even achieved 100% test coverage of a crucial library we depended on, which later prevented disaster when a code modification introduced a subtle but critical bug that was caught by the test suite. The effort spent on Unit Tests is worth it.
</p>

<p>
This event also taught me not to reject concepts and development methodologies based on half-knowledge and prejudice. When in doubt, just try it. What's the worst that could happen? You wasted a bit of time. On the other hand, the potential upside is that you added a useful tool to your toolbox for the rest of your life.
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jepsen: MySQL 8.0.34 (232 pts)]]></title>
            <link>https://jepsen.io/analyses/mysql-8.0.34</link>
            <guid>38695750</guid>
            <pubDate>Tue, 19 Dec 2023 14:17:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jepsen.io/analyses/mysql-8.0.34">https://jepsen.io/analyses/mysql-8.0.34</a>, See on <a href="https://news.ycombinator.com/item?id=38695750">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><a href="https://www.mysql.com/">MySQL</a> is a popular relational database. We revisit Kleppmann’s 2014 <a href="https://github.com/ept/hermitage/blob/master/mysql.md">Hermitage</a> and confirm that MySQL’s Repeatable Read still allows G2-item, G-single, and lost update. Using our transaction consistency checker <a href="https://github.com/jepsen-io/elle">Elle</a>, we show that MySQL Repeatable Read also violates internal consistency. Furthermore, it violates Monotonic Atomic View: transactions can observe some of another transaction’s effects, then later fail to observe other effects of that same transaction. We demonstrate violations of ANSI SQL’s requirements for Repeatable Read. We believe MySQL Repeatable Read is somewhat stronger than Read Committed. As a lagniappe, we show that AWS RDS MySQL clusters routinely violate Serializability. This work was performed independently without compensation, and conducted in accordance with the <a href="https://jepsen.io/ethics">Jepsen ethics policy</a>.</p><article>
  <div>
<h2 data-number="1" id="background"> Background</h2>
<p><a href="https://www.mysql.com/">MySQL</a> needs little introduction. Over the last 28 years it has become one of the most widely deployed SQL databases. MySQL is primarily used for online transaction processing (OLTP) workloads, but is also deployed as a part of OLAP and queuing systems.</p>
<p>MySQL was designed as a single-server database, but has been extended with various multi-node replication schemes, including <a href="https://www.percona.com/blog/overview-of-different-mysql-replication-solutions/">several flavors</a> of <a href="https://dev.mysql.com/doc/refman/8.0/en/binlog-replication-configuration-overview.html">binlog replication</a>, <a href="https://dev.mysql.com/blog-archive/mysql-group-replication-a-quick-start-guide/">group replication</a>, <a href="https://dev.mysql.com/doc/refman/8.0/en/mysql-cluster.html">NDB cluster</a>, and third-party plugins like <a href="https://galeracluster.com/">Galera Cluster</a> &amp; <a href="https://www.percona.com/software/mysql-database/percona-xtradb-cluster">Percona XtraDB Cluster</a>. Previous Jepsen work discussed <a href="https://aphyr.com/posts/328-call-me-maybe-percona-xtradb-cluster">Percona XtraDB Cluster</a> and <a href="https://aphyr.com/posts/327-jepsen-mariadb-galera-cluster">Galera Cluster</a>. In this analysis we focus on single-server MySQL, but we also evaluated clusters with a single writeable primary and read-only secondaries using <a href="https://dev.mysql.com/doc/refman/8.0/en/replication-howto.html">binlog replication</a>.</p>
<p>MySQL also supports multiple storage engines which have different safety properties. We focus on the default: <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-introduction.html">InnoDB</a>. Throughout this text, we use “MySQL” to mean “MySQL using the InnoDB storage engine.”</p>
<h2 data-number="1.1" id="ansi-sql-isolation-is-bad-actually"> ANSI SQL Isolation is Bad, Actually</h2>
<p>In order to discuss the nuances of SQL isolation levels, we must first explain some history. In 1977 Gray, Lorie, Putzolu, and Traiger published <a href="https://www.cs.cmu.edu/~natassa/courses/15-721/papers/GrayLocks.pdf">Granularity of Locks and Degrees of Consistency in a Shared Data Base</a>, which introduced four increasingly safe degrees of transaction consistency. In 1973 IBM developed System R, one of the first relational databases, and shortly thereafter <a href="https://learnsql.com/blog/history-of-sql/">introduced SQL</a> as a query language for it. System R’s success spawned a slew of relational databases using SQL, many with distinct flavors of concurrency control. Starting in <a href="https://archive.org/details/federalinformati127nati">1986</a> ANSI <a href="https://blog.ansi.org/sql-standard-iso-iec-9075-2023-ansi-x3-135/">released</a><a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a> a <a href="https://learnsql.com/blog/history-of-sql-standards/">series of standards</a> codifying SQL behavior. The third revision of the standard, SQL-92, defined the semantics of concurrent transactions through four transaction isolation levels, again with increasing degrees of safety. As with Gray et al., these isolation levels were related to the behavior of increasingly conservative locking regimes. However, to allow databases which used non-locking concurrency control, ANSI phrased their levels in terms of three possible phenomena which should not occur. As the standard puts it, “the following phenomena are possible:”<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<dl>
<dt>P1 (“Dirty Read”)</dt>
<dd>SQL-transaction T1 modifies a row. SQL-transaction T2 then reads that row before T1 performs a COMMIT. If T1 then performs a ROLLBACK, T2 will have read a row that was never committed and that may thus be considered to have never existed.
</dd>
<dt>P2 (“Non-Repeatable Read”)</dt>
<dd>SQL-transaction T1 reads a row. SQL-transaction T2 then modifies or deletes that row and performs a COMMIT. If T1 then attempts to reread the row, it may receive the modified value or discover that the row has been deleted.
</dd>
<dt>P3 (“Phantom”)</dt>
<dd>SQL-transaction T1 reads the set of rows N that satisfy some &lt;search condition&gt;. SQL-transaction T2 then executes SQL-statements that generate one or more rows that satisfy the &lt;search condition&gt; used by SQL-transaction T1. If SQL-transaction T1 then repeats the initial read with the same &lt;search condition&gt;, it obtains a different collection of rows.
</dd>
</dl>
<p>ANSI SQL defines four isolation levels in terms of these anomalies. It begins by stating that transactions which execute at the Serializable isolation level must be equivalent to some serial execution, i.e., one in which that set of transactions executed one after the other. Then it says “the isolation levels are different with respect to phenomena P1, P2, and P3.” The standard provides the following table which “specifies the phenomena that are possible and not possible for a given isolation level”:</p>
<table>
<thead>
<tr>
<th>Level</th>
<th>P1</th>
<th>P2</th>
<th>P3</th>
</tr>
</thead>
<tbody>
<tr>
<td>Read Uncommitted</td>
<td>Possible</td>
<td>Possible</td>
<td>Possible</td>
</tr>
<tr>
<td>Read Committed</td>
<td>Not Possible</td>
<td>Possible</td>
<td>Possible</td>
</tr>
<tr>
<td>Repeatable Read</td>
<td>Not Possible</td>
<td>Not Possible</td>
<td>Possible</td>
</tr>
<tr>
<td>Serializable</td>
<td>Not Possible</td>
<td>Not Possible</td>
<td>Not Possible</td>
</tr>
</tbody>
</table>
<p>In 1995 Berenson, Bernstein, Gray,<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> Melton, and the O’Neils published <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf">A Critique of ANSI SQL Isolation Levels</a>, which laid out critical flaws in these definitions. “The three ANSI phenomena are ambiguous. Even their broadest interpretations do not exclude anomalous behavior.”</p>
<p>For example, P1 says something bad might happen if <span><em>T</em><sub>1</sub></span> were to abort, but doesn’t actually say whether it aborts or not. Some people interpreted the standard to require <span><em>T</em><sub>1</sub></span> aborts. This would make it legal under read committed for transactions to read as-yet-uncommitted state from other transactions (so long as they went on to commit). <span><em>T</em><sub>1</sub></span> could write <span><em>x</em> = 1</span>, <span><em>T</em><sub>2</sub></span> could write <span><em>y</em> = 2</span>, and <span><em>T</em><sub>1</sub></span> and <span><em>T</em><sub>2</sub></span> could both see each other’s effects. This kind of circular information flow seems bad, but whether the standard allows it is a matter of interpretation. Similar ambiguities exist for P2 and P3.</p>
<p>Even interpreted broadly, preventing P1, P2, and P3 does not ensure Serializability. The standard omits a critical phenomenon P0 (“dirty write”), in which transaction <span><em>T</em><sub>1</sub></span> writes some row, transaction <span><em>T</em><sub>2</sub></span> overwrites <span><em>T</em><sub>1</sub></span>’s write, and <span><em>T</em><sub>1</sub></span> commits. This is clearly undesirable, but legal under ANSI Read Uncommitted, Read Committed, and Repeatable Read. Furthermore, ANSI SQL P3 only prohibits inserts affecting a predicate, but not updates or deletes.</p>
<p>In 1999, <a href="https://pmg.csail.mit.edu/papers/adya-phd.pdf">Atul Adya built on Berenson et al.’s critique</a> and developed formal and implementation-independent definitions of various transaction isolation levels, including those in ANSI SQL.<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a> As he notes:</p>
<blockquote>
<p>The ANSI definitions are imprecise because they allow at least two interpretations; furthermore, the anomaly interpretation is definitely incorrect. The preventative interpretation [meaning Berenson et al.’s interpretation which added P0, expanded P3, and so on] is correct in the sense that it rules out undesirable (i.e., non-serializable) histories. However, this interpretation is overly restrictive since it also rules out correct behavior that does not lead to inconsistencies and can occur in a real system. Thus, any system that allows such histories is disallowed by this interpretation, e.g., databases based on optimistic mechanisms.</p>
</blockquote>
<p>Adya first defines a dependency graph between transactions. There are three main types of dependencies, which we summarize informally:</p>
<dl>
<dt>Write-Write</dt>
<dd>Transaction <span><em>T</em><sub>1</sub></span> writes some version <span><em>x</em><sub>1</sub></span> of object <span><em>x</em></span>, which transaction <span><em>T</em><sub>2</sub></span> overwrites by installing the next version of <span><em>x</em></span>: <span><em>x</em><sub>2</sub></span>.
</dd>
<dt>Write-Read</dt>
<dd>Transaction <span><em>T</em><sub>1</sub></span> writes version <span><em>x</em><sub>1</sub></span>, which transaction <span><em>T</em><sub>2</sub></span> reads.
</dd>
<dt>Read-Write</dt>
<dd>Transaction <span><em>T</em><sub>1</sub></span> reads version <span><em>x</em><sub>1</sub></span>, which transaction <span><em>T</em><sub>2</sub></span> overwrites by installing the next version of <span><em>x</em></span>: <span><em>x</em><sub>2</sub></span>.
</dd>
</dl>
<p>Adya then defines portable isolation levels PL-1, PL-2, PL-2.99, and PL-3, which capture what the ANSI SQL standard (arguably) intended. Each level rules out progressively broader kinds of cycles in the transaction dependency graph:</p>
<dl>
<dt>PL-1 (“Read Uncommitted”)</dt>
<dd>Prohibits G0 (“write cycle”): a cycle of write-write dependencies. This is analogous to Berenson’s P0 (“dirty write”).
</dd>
<dt>PL-2 (“Read Committed”)</dt>
<dd>Prohibits G0 and G1. G1 consists of three anomalies: G1a (“aborted read”), G1b (“intermediate read”)<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a>, and G1c (“cyclic information flow”): a cycle of write-write or write-read dependencies. This captures the essence of the preventative interpretation of P1.
</dd>
<dt>PL-2.99 (“Repeatable Read”)</dt>
<dd>Prohibits G0, G1, and G2-item: a cycle involving write-write, write-read, or read-write edges <em>without predicates</em>. This captures the essence of ANSI SQL Repeatable Read, which is distinguished from Serializable only by predicate safety.
</dd>
<dt>PL-3 (“Serializable”)</dt>
<dd>Prohibits G0, G1, and G2: a cycle involving write-write, write-read, or read-write edges (with or without predicates). This guarantees equivalence to a serial execution.
</dd>
</dl>
<p>Adya’s dependency graph-based isolation levels resolved the ambiguities of the ANSI definitions, and remains the most widely-used formalism for characterizing transaction histories and anomalies. Jepsen generally uses Adya’s formalism.</p>
<p>Although the database community has known for decades that ANSI SQL’s isolation level definitions are broken, the standard’s language remained unchanged. The same ambiguous, incomplete definitions are still present in the <a href="https://webstore.ansi.org/standards/iso/isoiec90752023-2502169">2023 revision of the standard</a>.</p>
<h2 data-number="1.2" id="repeatable-read"> Repeatable Read</h2>
<p>ANSI SQL’s isolation levels are bad, but some levels have caused more problems than others.&nbsp; The fact that different database vendors provide isolation levels with the same names is useful only if the semantics of a particular level are consistent across vendors. And for three of the isolation levels, this is usually true. Most databases we’ve evaluated do ensure at least PL-1 for read uncommitted, PL-2 for Read Committed, and PL-3 for Serializable.<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a> However, there is less agreement on the semantics of Repeatable Read.</p>
<p>Adya’s PL-2.99 definition of Repeatable Read is quite strict, ruling out all dependency cycles except those involving predicate edges. The ANSI definition, while ambiguous, appears similarly strict: it prohibits all listed anomalies except “phantoms,” which depend on predicate reads. This is not surprising when we consider the roots of the isolation levels in locking regimes: the original Repeatable Read was the isolation level you got when you followed strict two-phase locking (holding read and write locks until the end of the transaction) but did not enforce predicate locking.</p>
<p>For some reason DB vendors have chosen different definitions of Repeatable Read than Adya and the ANSI standard, and almost no vendors provide the same guarantees at Repeatable Read. In fact, Microsoft SQL Server is the only database that we have tested for which Repeatable Read appears to correspond to PL-2.99 and the ANSI definition. In Postgres, <a href="https://jepsen.io/analyses/postgresql-12.3">Repeatable Read means Snapshot Isolation</a>, a level that is neither stronger nor weaker than PL-2.99.<a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>With this diversity of implementations in mind, we turn to the question at hand: what does MySQL do?</p>
<h2 data-number="1.3" id="mysql-isolation"> MySQL Isolation</h2>
<p>The <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html">transaction isolation levels</a> documentation for MySQL indicates that MySQL with InnoDB “offers all four transaction isolation levels described by the SQL:1992 standard”: <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html#isolevel_read-uncommitted">Read Uncommitted</a>, <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html#isolevel_read-committed">Read Committed</a>, <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html#isolevel_repeatable-read">Repeatable Read</a>, and <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html#isolevel_serializable">Serializable</a>. The documentation goes on to explain how MySQL achieves these isolation levels.</p>
<p>At MySQL Read Uncommitted, transactions should behave “like <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html#isolevel_read-uncommitted">Read Committed</a>,” except for allowing <a href="https://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_dirty_read">dirty read</a>: an anomaly where a read observes “data that was updated by another transaction but not yet committed.”</p>
<p>At MySQL <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html#isolevel_read-committed">Read Committed</a>, every individual <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-consistent-read.html">consistent read</a> reads from a fresh snapshot of committed state. A “consistent read” is the default behavior for reads (e.g.&nbsp;<code>SELECT * FROM problems</code>) and is the focus of this report. <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locking-reads.html">There are also</a> stronger reads (e.g.&nbsp;<code>SELECT ... FOR UPDATE</code>) which explicitly request locks, and weaker reads (e.g.&nbsp;<code>SELECT ... SKIP LOCKED</code>) which skip some of the default locks.</p>
<p>MySQL <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html#isolevel_repeatable-read">Repeatable Read</a>, the default isolation level, ensures safety through a snapshot mechanism:</p>
<blockquote>
<p>Consistent reads within the same transaction read the snapshot established by the first read. This means that if you issue several plain (nonlocking) <code>SELECT</code> statements within the same transaction, these <code>SELECT</code> statements are consistent also with respect to each other.</p>
</blockquote>
<p>MySQL’s <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-consistent-read.html">consistent read documentation</a> further emphasizes that reads should operate on a snapshot of the database taken by the first read in a transaction.</p>
<blockquote>
<p>If the transaction isolation level is <code>REPEATABLE READ</code> (the default level), all consistent reads within the same transaction read the snapshot established by the first such read in that transaction….</p>
<p>Suppose that you are running in the default <code>REPEATABLE READ</code> isolation level. When you issue a consistent read (that is, an ordinary <code>SELECT</code> statement), InnoDB gives your transaction a timepoint according to which your query sees the database. If another transaction deletes a row and commits after your timepoint was assigned, you do not see the row as having been deleted. Inserts and updates are treated similarly.</p>
</blockquote>
<p>The documentation for <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html#isolevel_serializable">Serializable</a> isolation says Serializable is “like <code>REPEATABLE READ</code>, but <code>InnoDB</code> implicitly converts all plain <code>SELECT</code> statements to <code>SELECT ... FOR SHARE</code> if <code>autocommit</code> is disabled.”</p>
<p>There ends the isolation level documentation. However, if one digs deeper into the <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-consistent-read.html">consistent read documentation</a>, there is a curious note on the semantics of Repeatable Read:</p>
<blockquote>
<p>The snapshot of the database state applies to <code>SELECT</code> statements within a transaction, not necessarily to DML statements. If you insert or modify some rows and then commit that transaction, a <code>DELETE</code> or <code>UPDATE</code> statement issued from another concurrent <code>REPEATABLE READ</code> transaction could affect those just-committed rows, even though the session could not query them. If a transaction does update or delete rows committed by a different transaction, those changes do become visible to the current transaction.</p>
</blockquote>
<p>This is confusing: the ANSI SQL standard and MySQL’s <a href="https://dev.mysql.com/doc/refman/8.0/en/sql-data-manipulation-statements.html">own reference manual</a> both consider <code>SELECT</code> to be a DML statement, but this note seems to think they’re different. It appears that writes made by a Repeatable Read transaction can affect rows that the transaction could not read. But what does it mean for a different transaction’s updates to become visible to the current transaction? How does that align with MySQL’s claim that multiple reads in a Repeatable Read transaction “read the snapshot established by the first read”? What happened to the timepoint assigned by the first read?</p>
<p>This calls for a test.</p>
<h2 data-number="2" id="test-design"> Test Design</h2>
<p>We designed a <a href="https://github.com/jepsen-io/mysql">small test suite for MySQL</a> using the <a href="https://github.com/jepsen-io/jepsen">Jepsen testing library</a> at version 0.3.4. We used the <code>mysql-connector-j</code> JDBC adapter as our client. We tested MySQL 8.0.34, and <a href="https://mariadb.org/">MariaDB</a> 10.11.3 on Debian Bookworm. Our tests ran against a single MySQL node as well as binlog-replicated clusters with one or two read-only followers, without failover. We also ran our test suite against a hosted MySQL service: AWS’s <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/multi-az-db-clusters-concepts.html">RDS Cluster</a>, using the “Multi-AZ DB Cluster” profile. This is the recommended default for production workloads, and offers a binlog-replicated deployment of MySQL 8.0.34 where secondary nodes support read queries.</p>
<p>Our tests included basic fault injection for process pauses, crashes, and network partitions, as well as the loss of un-fsynced writes to disk. However, almost every finding we discuss in this work occurred in healthy, single-node MySQL instances.</p>
<h2 data-number="2.1" id="list-append"> List Append</h2>
<p>Our main workload used <a href="https://github.com/jepsen-io/elle">Elle</a>’s list-append checker for transactional isolation. In a nutshell, Elle infers Adya’s write-write, write-read, and read-write dependencies between transactions, then looks for cycles in the resulting dependency graph. Each cycle it finds demonstrates that a particular set of isolation levels do not hold.</p>
<p>At a high level the <a href="https://github.com/jepsen-io/mysql/blob/4c239cb5c66a7f1a55fa02ce4c9f43b7a70e9d0b/src/jepsen/mysql/append.clj">append workload</a> performs randomly generated transactions comprising reads and appends of unique integer elements to a collection of lists identified by primary key. As in <a href="https://jepsen.io/analyses/postgresql-12.3">our previous tests of SQL databases</a>, we encoded these lists as a <code>text</code> field of comma-separated values, one per row, and used SQL <code>CONCAT</code> to append elements.<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a> We split these rows across multiple tables with a structure like</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>create</span> <span>table</span> <span>"txn0"</span> (</span>
<span id="cb1-2">  <span>id</span> <span>int</span> <span>not</span> <span>null</span> <span>primary</span> <span>key</span>,</span>
<span id="cb1-3">  val text</span>
<span id="cb1-4">);</span></code></pre></div>
<p>Over the last few years we’ve made several improvements to Elle which allow it to detect more anomalies.<a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a> When some appended elements are never read in a list-append test, Elle now <a href="https://github.com/jepsen-io/elle/commit/bccbc1ed6bc175453b40d514bdf873e554494633">infers ww and rw dependencies</a>, placing them after the last value seen in the longest successful read. <a href="https://github.com/jepsen-io/elle/commit/9da9f48d4bf1ab998533d9d6f5c0de4b732365ce">We now detect P4 (lost update)</a> anomalies explicitly, even when version orders are uninferable. Elle also searches for <a href="https://github.com/jepsen-io/elle/commit/3abdb6a56b6c816199796d8c635125f7ecd197cd">cycles involving multiple nonadjacent read-write anti-dependencies which also include real-time and process edges</a>. This lets us detect more subtle violations of both strong and strong session Snapshot Isolation.</p>
<h2 data-number="2.2" id="non-repeatable-read"> Non-Repeatable Read</h2>
<p>When Elle identified internal consistency violations at Repeatable Read, we designed a <a href="https://github.com/jepsen-io/mysql/blob/4c239cb5c66a7f1a55fa02ce4c9f43b7a70e9d0b/src/jepsen/mysql/nonrepeatable_read.clj">workload specifically to stress</a> MySQL’s Repeatable Read semantics, which works as follows. We create a simple table of people identified by primary key, and populate it with a single row:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>create</span> <span>table</span> people (</span>
<span id="cb2-2">  <span>id</span>     <span>int</span> <span>not</span> <span>null</span>,</span>
<span id="cb2-3">  name   text <span>not</span> <span>null</span>,</span>
<span id="cb2-4">  gender text <span>not</span> <span>null</span>,</span>
<span id="cb2-5">  <span>primary</span> <span>key</span> (<span>id</span>))</span>
<span id="cb2-6">);</span>
<span id="cb2-7"><span>insert</span> <span>into</span> people (<span>id</span>, name, gender)</span>
<span id="cb2-8">  <span>values</span> (<span>0</span>, <span>"moss"</span>, <span>"enby"</span>);</span></code></pre></div>
<p>We then perform a series of write transactions which update only the row’s name. Concurrently, a second series of transactions each read the row’s name, update its gender field, and read the name again. Violations of Repeatable Read manifest as the row’s name changing between the two reads. We also perform deletions and re-insertions of row 0, in case they behave differently than plain updates.</p>
<h2 data-number="2.3" id="monotonic-atomic-view"> Monotonic Atomic View</h2>
<p>We also designed a <a href="https://github.com/jepsen-io/mysql/blob/4c239cb5c66a7f1a55fa02ce4c9f43b7a70e9d0b/src/jepsen/mysql/mav.clj">second targeted workload</a> to illustrate violations of <a href="https://jepsen.io/consistency/models/monotonic-atomic-view">Monotonic Atomic View</a>. This workload creates a single table with two rows:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>create</span> <span>table</span> mav (</span>
<span id="cb3-2">  <span>id</span>      <span>int</span> <span>not</span> <span>null</span>,</span>
<span id="cb3-3">  `value` <span>int</span> <span>not</span> <span>null</span>,</span>
<span id="cb3-4">  noop    <span>int</span> <span>not</span> <span>null</span>,</span>
<span id="cb3-5">  <span>primary</span> <span>key</span> (<span>id</span>)</span>
<span id="cb3-6">);</span>
<span id="cb3-7"><span>insert</span> <span>into</span> mav (<span>id</span>, `value`, noop)</span>
<span id="cb3-8">  <span>values</span> (<span>0</span>, <span>0</span>, <span>0</span>);</span>
<span id="cb3-9"><span>insert</span> <span>into</span> mav (<span>id</span>, `value`, noop)</span>
<span id="cb3-10">  <span>values</span> (<span>1</span>, <span>0</span>, <span>0</span>);</span></code></pre></div>
<p>We perform a mix of write and read transactions. Each write increments the <code>value</code> of row 0, then increments row 1. Reads select the value of row 0, set the <code>noop</code> field of row 1 to a random value, then read the values of 1 and 0. Under Monotonic Atomic View, these reads should be monotonically increasing. For example, once a reader observes value <code>2</code>, it should thereafter see every row’s value as <code>2</code> or higher.</p>
<h2 data-number="2.4" id="lazyfs"> LazyFS</h2>
<p>In 2022 Jepsen commissioned the University of Porto’s <a href="https://www.inesctec.pt/en">INESC TEC</a> to develop <a href="https://github.com/dsrhaslab/lazyfs">LazyFS</a>: a FUSE filesystem for simulating the loss of un-fsynced writes. LazyFS maintains an in-memory page cache of data which has been written but not fsynced, flushing it to underlying storage only as the cache fills or <code>fsync</code> calls are made. A test harness can ask LazyFS to discard its cache at any time, simulating what might happen during a power failure. João Pedro Rodrigues Azevedo’s <a href="https://repositorium.sdum.uminho.pt/bitstream/1822/84475/1/Joao%20Pedro%20Rodrigues%20Azevedo.pdf">dissertation</a> discusses this work in detail, including several database bugs.</p>
<p><a href="https://github.com/dsrhaslab/lazyfs">LazyFS</a> has been <a href="https://github.com/jepsen-io/jepsen/blob/f69fe9929af8528d289b9ba4f72bdc18bad35157/jepsen/src/jepsen/lazyfs.clj">integrated with Jepsen</a> for a little over a year, but this is the first public Jepsen report including it. We tested MySQL by killing the MySQL process, <a href="https://github.com/jepsen-io/mysql/blob/4c239cb5c66a7f1a55fa02ce4c9f43b7a70e9d0b/src/jepsen/mysql/db/mysql.clj#L200-L203">asking LazyFS to drop uncommitted writes</a>, then restarting the process.</p>
<h2 data-number="3" id="results"> Results</h2>
<h2 data-number="3.1" id="g2-item-at-repeatable-read"> G2-item at Repeatable Read</h2>
<p>Adya’s Repeatable Read (PL-2.99) prohibits G2-item: a cycle of write-write, write-read, and read-write dependency edges, where those edges do not involve predicates. However, MySQL’s Repeatable Read routinely allows G2-item, even on a single healthy node. Kleppmann <a href="https://github.com/ept/hermitage/blob/master/mysql.md#write-skew-g2-item">reported this behavior</a> in 2014 and it still occurs today. Take for example <a href="https://s3.amazonaws.com/jepsen.io/analyses/mysql-8.0.34/rr-g2-item-20230929T000636.621.zip">this list-append test</a>, which exhibited 214 cycles in just 40 seconds. Here is one of those cycles comprising two transactions, neither of which saw each other’s effects.</p>

<p>In this diagram the top transaction read key 141 and saw the value <code>[1 2]</code>, then appended <code>1</code> to key 140. The bottom transaction appended <code>3</code> to key 141, read key 141 and observed the value <code>[1 2 3]</code>, then read key 140 and found it did not exist. The top transaction must have executed before the bottom transaction, since it failed to observe the bottom transaction’s append of <code>3</code>. But the bottom transaction must have executed before the top transaction, since it read key 140 before any append! This cycle involves purely reads and updates by primary key, and is therefore G2-item.<a href="#fn10" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<p>Transactions which fail to see each other’s effects could violate important invariants. Consider two independent electricians, each adding a new 20 amp circuit to a breaker panel. Each might visit the site to check<a href="#fn11" id="fnref11" role="doc-noteref"><sup>11</sup></a> that the total load on each circuit (including the one they intend to add) would not exceed the 100 amp capacity of the panel, then return a few days later to add the circuit. Under MySQL’s Repeatable Read, both could see a load of 70 amps, add a 20 amp circuit, and create a total load of 110 amps—exceeding the safe load of the panel.<a href="#fn12" id="fnref12" role="doc-noteref"><sup>12</sup></a></p>
<p>While this behavior is prohibited by PL-2.99 Repeatable Read, it could be interpreted as legal under ANSI SQL Repeatable Read. The standard’s definition of P2 (non-Repeatable Read) only discusses a transaction which reads the same row twice and observes some other transaction’s effects. Since these transactions never read a row twice, they do not exhibit P2! This is one of many ways in which the standard fails to capture anomalous behavior.</p>
<h2 data-number="3.2" id="g-single-at-repeatable-read"> G-single at Repeatable Read</h2>
<p>The example of G2-item we presented above involved a pair of transactions linked by adjacent read-write edges: in short, neither observed the other’s effects. However, MySQL Repeatable Read also exhibits G-single (a.k.a. read skew): cycles composed of write-write, write-read, and read-write edges, but where read-write edges are never adjacent to one another. <a href="https://github.com/ept/hermitage/blob/master/mysql.md#read-skew-g-single">Kleppmann reported this behavior in 2014</a>, and we can confirm it still occurs in MySQL 8.0.34. Like G2-item, G-single cycles involving only item dependencies are prohibited under PL-2.99 Repeatable Read.</p>
<p>Take, for example, this <a href="https://s3.amazonaws.com/jepsen.io/analyses/mysql-8.0.34/rr-everything-20231003T100453.595-0500.zip">sixty-second append test</a> of a single MySQL node without any faults. At roughly 140 transactions per second it exhibited 244 instances of G-single (plus 305 more instances of G2-item). Since the append test uses no predicate operations, all of these are violations of Repeatable Read. Here is one of those cycles:</p>

<p>The top transaction here appended <code>9</code> to key 363, then <code>5</code> to key 377. The bottom transaction failed to observe the append to 377, but also managed to append <code>10</code> to key 363 after the top transaction. We know this because a later read observed key 363’s value as <code>[5 6 4 7 8 9 10]</code>. This violates both Repeatable Read (which rules out any cycle of item edges) and Snapshot Isolation (which rules out G-single in general).</p>
<p>In short: one transaction can both fail to observe but also overwrite another. More complex cycles involving write-read edges also occur. In this case the dependency edges involved different keys, which suggests an interesting question: what would happen if two transactions conflicted on a <em>single</em> key?</p>
<h2 data-number="3.3" id="lost-update-at-repeatable-read"> Lost Update at Repeatable Read</h2>
<p>Phenomenon P4 (lost update) is a special case of G-single in which exactly two transactions are linked by a write-write and read-write cycle on a single key. In other words: two transactions read the same version of some key, and both go on to update it. This is expressly prohibited by <a href="https://jepsen.io/consistency/models/snapshot-isolation">Snapshot Isolation</a> and <a href="https://jepsen.io/consistency/models/repeatable-read">PL-2.99 Repeatable Read</a>. However, <a href="https://github.com/ept/hermitage/blob/master/mysql.md#lost-update-p4">Kleppmann showed</a> in 2014 that MySQL Repeatable Read allowed lost update, and we can confirm that it still occurs routinely, even on a single node without faults. Here is a second cycle from the <a href="https://s3.amazonaws.com/jepsen.io/analyses/mysql-8.0.34/rr-everything-20231003T100453.595-0500.zip">same test run</a>:</p>

<p>Both of these transactions read key 636, found it missing, and went on to write what they thought would be the first element. This is an obvious instance of lost update: at most one of these transactions should have been able to commit.<a href="#fn13" id="fnref13" role="doc-noteref"><sup>13</sup></a> We also have less obvious examples:</p>

<p>This cluster involves two G-single cycles. The smaller, comprising just the bottom two transactions, has no read of key 1167 before the middle transaction’s write: it is not a classic instance of lost update. However, its read of key 1167 = [1] implies that the state of that key <em>prior</em> to its append of 1 must have been empty, which looks “lost-update-esque.” Moreover, the top transaction <em>also</em> read the unborn version of key 1167 before appending 4 to it. That, together with the bottom transaction, must be lost update.</p>
<p>A later read <code>[:r 1167 [1 3 4]]</code> suggests the following sequence of events. All three transactions must have started before 1167 existed. The middle transaction appended <code>1</code> and read <code>[1]</code> back. Then the bottom transaction appended <code>3</code>, and finally the top transaction appended <code>4</code>. All three transactions eventually committed.</p>
<p>These instances of lost update were caught by Elle’s cycle detection system, since they were involved in G-single. However, Elle’s cycle detection relies on inferring the order of writes to a given key, which we can (mostly) do only if some read observes them. We have recently extended Elle to detect instances of lost update which are invisible to the cycle detector. In these tests, we search for two or more committed transactions which read the same version of some key <span><em>k</em></span>, then all write <span><em>k</em></span>. Regardless of whether we see their effects or not, the mere fact that both committed implies lost update. For example:</p>
<div id="cb4"><pre><code><span id="cb4-1">{<span>:key</span> <span>892</span>,</span>
<span id="cb4-2"> <span>:value</span> <span>nil</span>,</span>
<span id="cb4-3"> <span>:txns</span></span>
<span id="cb4-4"> [{<span>:process</span> <span>6</span>,</span>
<span id="cb4-5">   <span>:type</span> <span>:ok</span>,</span>
<span id="cb4-6">   <span>:f</span> <span>:txn</span>,</span>
<span id="cb4-7">   <span>:value</span> [[<span>:r</span> <span>892</span> <span>nil</span>]</span>
<span id="cb4-8">           [<span>:r</span> <span>891</span> <span>nil</span>]</span>
<span id="cb4-9">           [<span>:append</span> <span>892</span> <span>1</span>]</span>
<span id="cb4-10">           [<span>:r</span> <span>892</span> [<span>2</span> <span>5</span> <span>4</span> <span>1</span>]]],</span>
<span id="cb4-11">   <span>:index</span> <span>14806</span>,</span>
<span id="cb4-12">   <span>:time</span> <span>49518094450</span>}</span>
<span id="cb4-13">  {<span>:process</span> <span>18</span>,</span>
<span id="cb4-14">   <span>:type</span> <span>:ok</span>,</span>
<span id="cb4-15">   <span>:f</span> <span>:txn</span>,</span>
<span id="cb4-16">   <span>:value</span> [[<span>:r</span> <span>892</span> <span>nil</span>]</span>
<span id="cb4-17">           [<span>:append</span> <span>892</span> <span>8</span>]</span>
<span id="cb4-18">           [<span>:r</span> <span>891</span> [<span>2</span> <span>3</span>]]</span>
<span id="cb4-19">           [<span>:append</span> <span>891</span> <span>9</span>]],</span>
<span id="cb4-20">   <span>:index</span> <span>14842</span>,</span>
<span id="cb4-21">   <span>:time</span> <span>49636093552</span>}]}</span></code></pre></div>
<p>Both of these committed transactions read the unborn (<code>nil</code>) version of key 892 and wrote to it. Out of 9,048 successful transactions in this test, our new checker found 446 distinct transactions involved in 198 instances of lost update. Only 47 of those instances appeared in some cycle.</p>
<p>In short: MySQL Repeatable Read transactions cannot safely read a value and then write it. The standard ORM pattern where a program starts a transaction, loads an object into memory, manipulates it, saves it back to the database, then commits, may find that MySQL silently discards those committed changes. Although PL-2.99 Repeatable Read is supposed to make this pattern safe, MySQL Repeatable Read does not. MySQL users must instead perform their own explicit locking.</p>
<p>An attentive reader may have noticed the above example is more alarming than first meets the eye. The first transaction read the empty state of key 892, appended a single value, then read a version of key 892 including <em>three additional values</em>. Where did those come from?</p>
<h2 data-number="3.4" id="non-repeatable-read-at-repeatable-read"> Non-Repeatable Read at Repeatable Read</h2>
<p>MySQL Repeatable Read exhibits <em>internal consistency anomalies</em>: consistency violations whose effects are visible within a single transaction. These occur even on a single healthy MySQL node. In that <a href="https://s3.amazonaws.com/jepsen.io/analyses/mysql-8.0.34/rr-everything-20231003T100453.595-0500.zip">same test run</a>, 126 of 9,048 committed transactions exhibited internal consistency errors. For example:</p>
<div id="cb5"><pre><code><span id="cb5-1">{<span>:op</span></span>
<span id="cb5-2"> {<span>:process</span> <span>12</span>,</span>
<span id="cb5-3">  <span>:type</span> <span>:ok</span>,</span>
<span id="cb5-4">  <span>:f</span> <span>:txn</span>,</span>
<span id="cb5-5">  <span>:value</span> [[<span>:r</span> <span>1185</span> <span>nil</span>]</span>
<span id="cb5-6">          [<span>:append</span> <span>1185</span> <span>6</span>]</span>
<span id="cb5-7">          [<span>:append</span> <span>1182</span> <span>8</span>]</span>
<span id="cb5-8">          [<span>:r</span> <span>1185</span> [<span>3</span> <span>4</span> <span>2</span> <span>6</span>]]],</span>
<span id="cb5-9">  <span>:index</span> <span>19874</span>,</span>
<span id="cb5-10">  <span>:time</span> <span>65980191472</span>},</span>
<span id="cb5-11"> <span>:mop</span> [<span>:r</span> <span>1185</span> [<span>3</span> <span>4</span> <span>2</span> <span>6</span>]],</span>
<span id="cb5-12"> <span>:expected</span> [<span>6</span>]}</span></code></pre></div>
<p>This transaction read the unborn (<code>nil</code>) state of key 1185, and decided to append <code>6</code> to it. It then read key 1185 and observed <code>[3 4 2 6]</code>. Three elements appeared out of thin air. Or consider:</p>
<div id="cb6"><pre><code><span id="cb6-1">{<span>:op</span></span>
<span id="cb6-2"> {<span>:process</span> <span>19</span>,</span>
<span id="cb6-3">  <span>:type</span> <span>:ok</span>,</span>
<span id="cb6-4">  <span>:f</span> <span>:txn</span>,</span>
<span id="cb6-5">  <span>:value</span> [[<span>:append</span> <span>1099</span> <span>10</span>]</span>
<span id="cb6-6">          [<span>:r</span> <span>1096</span> [<span>1</span> <span>2</span> <span>3</span>]]</span>
<span id="cb6-7">          [<span>:append</span> <span>1096</span> <span>7</span>]</span>
<span id="cb6-8">          [<span>:r</span> <span>1096</span> [<span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>5</span> <span>6</span> <span>7</span>]]],</span>
<span id="cb6-9">  <span>:index</span> <span>18404</span>,</span>
<span id="cb6-10">  <span>:time</span> <span>61061580955</span>},</span>
<span id="cb6-11"> <span>:mop</span> [<span>:r</span> <span>1096</span> [<span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>5</span> <span>6</span> <span>7</span>]],</span>
<span id="cb6-12"> <span>:expected</span> [<span>1</span> <span>2</span> <span>3</span> <span>7</span>]}</span></code></pre></div>
<p>This transaction read key 1096 and obtained the list <code>[1 2 3]</code>. It appended <code>7</code>, then read the key again, and found three additional values (<code>4</code>, <code>5</code>, and <code>6</code>) inserted in its place. This is forbidden under PL-2.99 Repeatable Read: there must be a read-write dependency from this transaction to some other, and a write-read (or similar) dependency chain leading back. It is forbidden under ANSI Repeatable Read: the transaction performed two reads of the same object and saw different states resulting from a different transaction! The point of Repeatable Read—both for ANSI and Adya—is that once a transaction observes some value, it can count on that value being stable for the remainder of the transaction. MySQL does the opposite: a write is an invitation for another transaction to sneak in and clobber the state you just read.</p>
<p>This behavior allows <a href="https://s3.amazonaws.com/jepsen.io/analyses/mysql-8.0.34/gender-20231003T193907.588.zip">incredible transactions</a> like the following, recorded during a repeatable-read workload:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>set</span> <span>transaction</span> <span>isolation</span> <span>level</span> Repeatable <span>Read</span>;</span>
<span id="cb7-2"></span>
<span id="cb7-3"><span>start</span> <span>transaction</span>;</span>
<span id="cb7-4"><span>select</span> name <span>from</span> people <span>where</span> <span>id</span> <span>=</span> <span>0</span>;</span>
<span id="cb7-5">  <span>--&gt; "pebble"</span></span>
<span id="cb7-6"><span>update</span> people <span>set</span> gender <span>=</span> <span>"femme"</span> <span>where</span> <span>id</span> <span>=</span> <span>0</span>;</span>
<span id="cb7-7"><span>select</span> name <span>from</span> people <span>where</span> <span>id</span> <span>=</span> <span>0</span>;</span>
<span id="cb7-8">  <span>--&gt; "moss"</span></span>
<span id="cb7-9"><span>commit</span>;</span></code></pre></div>
<p>This transaction read a person’s name, set their gender, and read their name again. Despite executing at Repeatable Read, their name spontaneously changed from “pebble” to “moss”.</p>
<p>Violations of internal consistency <a href="https://software.imdea.org/~andrea.cerone/works/Framework.pdf">are forbidden under</a> Read Atomic, Causal Consistency, Parallel Snapshot Isolation, Prefix Consistency, Snapshot Isolation, and Serializability. It also seems clear that this transaction satisfies ANSI SQL’s informal definition of a “non-repeatable read.” It violates MySQL’s <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html#isolevel_repeatable-read">isolation levels documentation</a>, which claims that “consistent reads within the same transaction read the snapshot established by the first read.” It contradicts MySQL’s <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-consistent-read.html">consistent read documentation</a>, which specifically states that InnoDB assigns a timepoint on a transaction’s first read, and the effects of concurrent transactions should not appear in subsequent reads.</p>
<p>If we add other transactions which insert or delete the row, we can observe rows <a href="https://s3.amazonaws.com/jepsen.io/analyses/mysql-8.0.34/rr-nonrepeatable-insert-delete-20231003T231826.zip">popping into existence</a> in the middle of a Repeatable Read transaction:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>start</span> <span>transaction</span>;</span>
<span id="cb8-2"><span>select</span> name <span>from</span> people <span>where</span> <span>id</span> <span>=</span> <span>0</span> <span>--&gt; nil</span></span>
<span id="cb8-3"><span>update</span> people <span>set</span> gender <span>=</span> <span>"butch"</span> <span>where</span> <span>id</span> <span>=</span> <span>0</span>;</span>
<span id="cb8-4"><span>select</span> name <span>from</span> people <span>where</span> <span>id</span> <span>=</span> <span>0</span>; <span>--&gt; "moss"</span></span>
<span id="cb8-5"><span>commit</span>;</span></code></pre></div>
<p>However, we have not yet observed a row vanishing due to a concurrent delete. Perhaps this is because the update statement updates <em>no</em> rows, leaving the snapshot intact. Whatever the reason, the consistent read documentation’s claim that deletes, inserts, and updates “are treated similarly” appears incorrect: deletes seem to work differently from inserts and updates.</p>
<h2 data-number="3.5" id="non-monotonic-view"> Non-Monotonic View</h2>
<p><a href="https://github.com/ept/hermitage">Kleppmann’s Hermitage</a> lists MySQL Repeatable Read as <a href="https://jepsen.io/consistency/models/monotonic-atomic-view">monotonic atomic view</a>. Per <a href="https://amplab.cs.berkeley.edu/wp-content/uploads/2013/10/hat-vldb2014.pdf">Bailis et al</a>, Monotonic Atomic View ensures that once a transaction <span><em>T</em><sub>2</sub></span> observes an effect of transaction <span><em>T</em><sub>1</sub></span>, <span><em>T</em><sub>2</sub></span> observes <em>all</em> effects of <span><em>T</em><sub>1</sub></span>. Even if MySQL Repeatable Read fetches a fresh snapshot on each write, it might still provide Monotonic Atomic View if the snapshots are monotone. This is how <a href="https://github.com/ept/hermitage/blob/master/postgres.md">Postgres read committed</a> works.</p>
<p>This is not the case in MySQL. In healthy single-node deployments, MySQL routinely violates Monotonic Atomic View at Repeatable Read. Recall that our Monotonic Atomic View workload has two rows whose <code>value</code>s are initially <code>0</code>. Writer transactions increment the value of row 0, then row 1: both rows’ values should appear to advance in lockstep. However, the first read transaction from <a href="https://s3.amazonaws.com/jepsen.io/analyses/mysql-8.0.34/rr-mav-20231005T140119.171-0500.zip">this monotonic-atomic-view test</a> observed:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>start</span> <span>transaction</span>;</span>
<span id="cb9-2"><span>select</span> <span>value</span> <span>from</span> mav <span>where</span> <span>id</span> <span>=</span> <span>0</span>;    <span>--&gt; 0</span></span>
<span id="cb9-3"><span>update</span> mav <span>set</span> noop <span>=</span> <span>73</span> <span>where</span> <span>id</span> <span>=</span> <span>1</span>;</span>
<span id="cb9-4"><span>select</span> <span>value</span> <span>from</span> mav <span>where</span> <span>id</span> <span>=</span> <span>1</span>;    <span>--&gt; 1</span></span>
<span id="cb9-5"><span>select</span> <span>value</span> <span>from</span> mav <span>where</span> <span>id</span> <span>=</span> <span>0</span>;    <span>--&gt; 0</span></span>
<span id="cb9-6"><span>commit</span>;</span></code></pre></div>
<p>This read transaction saw the state of row 0 prior to the first write transaction. Then it saw the writer’s increment of row 1. Under monotonic atomic view, it should have gone on to observe all of the writer’s effects—including the increment of row 0. However, when it selected row 0 it saw the old value, not the new one. This is a non-monotonic read!</p>
<p>MySQL’s <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-consistent-read.html">consistent read documentation</a> talks about snapshots extensively, but this behavior doesn’t look like a snapshot at all. Snapshot systems usually provide a consistent, point-in-time view of the database state. They are usually atomic: either all of a transaction’s effects are included, or none are. Even if MySQL had somehow obtained a non-atomic snapshot from the <em>middle</em> of the write transaction, it must have seen the increment of row 0 before the increment of row 1. This is not the case: this read transaction observed the increment of row 1 but <em>not</em> row 0. In what sense can this possibly be considered a snapshot?</p>
<h2 data-number="3.6" id="fractured-read-like-anomalies-with-rds-serializable"> Fractured Read-Like Anomalies with RDS Serializable</h2>
<p>A common strategy for improving both the availability and throughput of a production MySQL database is to deploy one or more <em>read replicas</em>. These replicas continually apply binlogs that are shipped to them by the read/write primary instance, accept connections, and permit read-only transactions to run. Some cloud vendors (e.g.&nbsp;Amazon RDS) configure one or two read replicas as a part of their default production deployment profile.</p>
<p>We found that AWS RDS MySQL routinely violated Serializability at Serializable isolation, even in healthy clusters. Consider <a href="http://jepsen.io.s3.amazonaws.com/analyses/mysql-8.0.34/20230829T165306.964Z.zip">this append test</a> which ran on an RDS MySQL cluster with the default recommended production profile. It exhibited several G2-item and G-single anomalies, like the following:</p>

<p>The top transaction appended <code>3</code> to key 2215, and that write was visible to the middle transaction. The middle transaction appended <code>8</code> to key 2219, which was visible to the bottom transaction. However, the bottom transaction missed the top transaction’s write! All G-single anomalies we found involved at least three transactions linked by at least two write-read edges.</p>
<p>Exactly what kind of anomaly is this, and how severe is it? It is clearly an instance of G-single, since it has exactly one read-write edge. It is also G2-item, since it does not involve predicates. This implies RDS MySQL’s “Serializable” isolation violates Snapshot Isolation, Repeatable Read, and Serializability.</p>
<p>However, G-single is a broad class of anomalies, and this appears unlike the other instances of G-single we’ve discussed so far. It is not lost update: no transaction reads then writes the same key. Unlike our previous example of G-single which involved a write-write edge, this anomaly has only write-read and read-write edges. It somewhat resembles <a href="https://people.eecs.berkeley.edu/~alig/papers/ramp.pdf">fractured read</a>, in which a transaction reads only a subset of another transaction’s writes. However, this anomaly involves a reader <span><em>T</em><sub>3</sub></span> which observes a writer <span><em>T</em><sub>2</sub></span>’s effects, but does not observe an earlier <span><em>T</em><sub>1</sub></span> which was visible to <span><em>T</em><sub>2</sub></span>. It is in some sense a “transitive” fractured read.</p>
<p>Regarding severity, we observe first that <em>any</em> instance of G-single, when running all transactions at the Serializable isolation level, is significant. The received wisdom in the MySQL community is to avoid using Serializable unless absolutely necessary. The MySQL manual discourages users from using Serializable at all, stating:</p>
<blockquote>
<p><code>SERIALIZABLE</code> enforces even stricter rules than <code>REPEATABLE READ</code>, and is used mainly in specialized situations, such as with XA transactions and for troubleshooting issues with concurrency and deadlocks.</p>
</blockquote>
<p>Given this guidance, we would expect users to run transactions at this strongest isolation level only when they know they need a high degree of safety, and are willing to pay the performance cost of extra synchronization in order to rule out anomalies. Graver still, fractured read-like anomalies (as instances of G2-item) are forbidden by Repeatable Read. They should occur only at Read Committed and below. That they arise at “Serializable” is troubling.</p>
<p>We suspect this behavior is due in part to RDS’s choice of default parameters for production clusters. Among the large variety of configuration parameters that govern the behavior of read replicas is one whose very name should make us uneasy: <a href="https://dev.mysql.com/doc/refman/8.0/en/replication-options-replica.html#sysvar_replica_preserve_commit_order"><code>replica_preserve_commit_order</code></a>.<a href="#fn14" id="fnref14" role="doc-noteref"><sup>14</sup></a></p>
<blockquote>
<p>For multithreaded replicas (replicas on which <code>replica_parallel_workers</code> is set to a value greater than 0), setting <code>replica_preserve_commit_order=ON</code> ensures that transactions are executed and committed on the replica in the same order as they appear in the replica’s relay log. This prevents gaps in the sequence of transactions that have been executed from the replica’s relay log, and preserves the same transaction history on the replica as on the source (with the limitations listed below).</p>
</blockquote>
<p>Serializable systems are supposed to guarantee transactions execute in (what appears to be) a total order. Failing to preserve that order on a replica seems like it would be a bad thing, even if it permitted more parallelism in applying the log entries. The documentation goes on to say that while this parameter used to be disabled by default, MySQL version 8.0.27 and higher default to <code>replica_preserve_commit_order=ON</code>. However, RDS’s default parameters still choose <code>replica_preserve_commit_order=OFF</code>. If we apply this setting to our local test clusters, we observe similar instances of G-single and G2-item.</p>
<table>
<thead>
<tr>
<th>№</th>
<th>Summary</th>
<th>Event Required</th>
<th>Fixed in</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>G2-item at Repeatable Read</td>
<td>None</td>
<td>Unresolved</td>
</tr>
<tr>
<td>2</td>
<td>G-single at Repeatable Read</td>
<td>None</td>
<td>Unresolved</td>
</tr>
<tr>
<td>3</td>
<td>Lost update at Repeatable Read</td>
<td>None</td>
<td>Unresolved</td>
</tr>
<tr>
<td>4</td>
<td>Non-Repeatable read at Repeatable Read</td>
<td>None</td>
<td>Unresolved</td>
</tr>
<tr>
<td>5</td>
<td>Non-monotonic view at Repeatable Read</td>
<td>None</td>
<td>Unresolved</td>
</tr>
<tr>
<td>6</td>
<td>Fractured read-like anomalies at Serializable (in RDS)</td>
<td>None</td>
<td>Unresolved</td>
</tr>
</tbody>
</table>
<h2 data-number="4" id="discussion"> Discussion</h2>
<p>First, the good news. In our testing, MySQL 8.0.34’s Read Uncommitted, read committed, and Serializable isolation levels appeared to satisfy PL-1 read uncommitted, PL-2 Read Committed, and PL-3 Serializable, respectively. This held both for single nodes and small clusters with read-only replicas using binlog replication, and through process pauses, crashes, and network partitions.</p>
<p>Our LazyFS fault injection scheme did not discover problems with MySQL’s default settings. With <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_flush_log_at_trx_commit"><code>innodb_flush_log_at_trx_commit</code></a> at the default setting of <code>1</code>, process crashes followed by the loss of un-fsynced data did not result in the loss of committed transactions. When we adjusted that setting to <code>0</code>, MySQL fsynced only once every <span><em>n</em></span> seconds and we observe data loss.</p>
<p>The bad news: MySQL’s “Repeatable Read” does not satisfy PL-2.99 Repeatable Read: it exhibits G2-item anomalies including write skew. It does not satisfy Snapshot Isolation: it exhibits G-single, including read skew and lost update. Lost update rules out cursor stability. Reads in MySQL “Repeatable Read” are not repeatable, even under the ambiguous definitions of the ANSI SQL standard. Its transactions violate internal consistency, which rules out Read Atomic, Causal, Consistent View, Prefix, and Parallel snapshot isolation. <a href="https://github.com/ept/hermitage#summary-of-test-results">Kleppmann’s 2014 Hermitage</a> suggested MySQL Repeatable Read might be Monotonic Atomic View, but this cannot be true: we found monotonicity violations.</p>
<p>Some authors <a href="https://fileadmin.cs.lth.se/cs/Education/EDAF20/lectures/transactions.pdf">characterize</a> MySQL Repeatable Read as <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf">Snapshot Isolation</a>. For example, Kleppmann’s <a href="https://www.oreilly.com/library/view/designing-data-intensive-applications/9781491903063/"><em>Designing Data-Intensive Applications</em></a> says “PostgreSQL and MySQL call their Snapshot Isolation level Repeatable Read”.<a href="#fn15" id="fnref15" role="doc-noteref"><sup>15</sup></a> Formalizations of Snapshot Isolation <a href="https://jepsen.io/consistency/models/snapshot-isolation">vary</a>, but most make it appear as if all of a transaction’s reads occurred at the transaction start time (plus local changes). This is not true in MySQL: when a write occurs, multiple reads of a key may reveal <em>newer</em> versions of that key resulting from other transactions’ writes. Moreover, Snapshot Isolated systems generally appear as if all of a transaction’s writes occur atomically. MySQL allows a transaction to read some, but not all, of another transaction’s writes. This is inconsistent with every version of Snapshot Isolation we are familiar with.</p>
<p>It isn’t clear what MySQL Repeatable Read actually <em>is</em>. It allows histories which violate Monotonic Atomic View and cursor stability; we know it cannot be equal to or stronger than those models. We have not observed G0 (dirty writes), G1a (aborted reads), G1b (intermediate reads), or G1c (cyclic infomation flow); it appears at least as strong as Read Committed. The repeatability of <em>some</em> reads means it is actually stronger than Read Committed.</p>

<p>In this <a href="https://jepsen.io/consistency">graph of consistency models</a> an arrow from A to B means that B is strictly stronger than A. By this we mean the histories permitted by B are a strict subset of those permitted by A: a system which provides B provides A as well. It seems likely that MySQL Repeatable Read is incomparable to Monotonic Atomic View: it allows violations of Monotonic Atomic View, but also rules out some non-repeatable reads that Monotonic Atomic View allows. Likewise, it is incomparable to Repeatable Read: MySQL Repeatable Read <a href="https://www.pythian.com/blog/understanding-mysql-isolation-levels-repeatable-read">appears to prohibit certain phantoms</a> which are legal under both ANSI and PL-2.99 Repeatable Read. However, we are unsure exactly which other models are strictly stronger than MySQL Repeatable Read. Is every prefix-consistent history legal under MySQL Repeatable Read? Or are they too incomparable? Because MySQL Repeatable Read’s behavior is so unusual, and because we lack a formal definition of its properties, we are unsure where to draw additional arrows in the diagram above.</p>
<p>As always, we caution that Jepsen takes an experimental approach to safety verification: we can prove the presence of bugs, but not their absence. While we make extensive efforts to find problems, we cannot prove correctness.</p>

<p>The behavior of MySQL Repeatable Read appears poorly understood in the MySQL community. <a href="https://priyankvex.com/2018/10/20/tackling-lost-updates-problem-in-database-using-better-isolation-level/">Several</a> <a href="https://levelup.gitconnected.com/preventing-data-inconsistencies-in-mysql-strategies-for-avoiding-lost-updates-cfdb04107f7c">authors</a> <a href="https://www.zghurskyi.com/lost-update/">believe</a> <a href="https://forums.mysql.com/read.php?22,56420,56420#msg-56420">Repeatable</a> <a href="https://vladmihalcea.com/a-beginners-guide-to-database-locking-and-the-lost-update-phenomena/">Read</a> <a href="https://amirsoleimani.medium.com/understanding-database-isolation-level-via-examples-mysql-and-postgres-a86b5502d404">should</a> <a href="https://flylib.com/books/en/1.63.1.107/1/">prevent</a> lost update. However, <a href="https://stackoverflow.com/questions/46315232/how-to-use-transactions-in-mysql-to-avoid-lost-updates">several</a> <a href="https://forums.mysql.com/read.php?22,56420,57733">others</a> <a href="https://stackoverflow.com/questions/9060400/repeatable-read-and-second-lost-updates-issue">acknowledge</a> <a href="https://www.up-2date.com/post/lost-update">it</a> <a href="https://blog.jcoglan.com/2020/10/12/reading-and-writing-part-3/">actually</a> <a href="https://forum.hibernate.org/viewtopic.php?p=2489608">does</a> <a href="https://stackoverflow.com/questions/10040785/mysql-repeatable-read-and-lost-update-phantom-reads?rq=3">not</a>, and advise (for example) explicit locking tactics. Similarly, <a href="https://www.prisma.io/dataguide/mysql/inserting-and-modifying-data/using-transactions">many</a> <a href="https://mydbops.wordpress.com/2018/06/22/back-to-basics-isolation-levels-in-mysql/">internet</a> <a href="https://buildatscale.tech/transaction-isolation-level-in-innodb/">sources</a> <a href="https://stackoverflow.com/questions/42668158/mysql-repeatable-read-transaction-unexpected-behavior">state</a> (<a href="https://decentro.tech/blog/decoding-isolation-levels-in-mysql/">incorrectly</a>) that MySQL repeatable reads <a href="https://www.prisma.io/dataguide/mysql/inserting-and-modifying-data/using-transactions">are</a> <a href="https://www.tutorialspoint.com/mysql/mysql_set_transaction.htm">repeatable</a>. This is understandable: <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html#isolevel_repeatable-read">MySQL</a> and <a href="https://mariadb.com/kb/en/set-transaction/#repeatable-read">MariaDB</a>’s own documentation makes this claim. Those claims are contradicted by a single sentence in a note buried in the <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-consistent-read.html">MySQL consistent reads documentation</a>. Other blog posts and articles <a href="https://yizhang82.dev/innodb-repeatable-read">acknowledge</a> (<a href="https://dev.to/techschoolguru/understand-isolation-levels-read-phenomena-in-mysql-postgres-c2e">some indirectly</a>) that MySQL Repeatable Read <a href="https://www.pythian.com/blog/understanding-mysql-isolation-levels-repeatable-read">actually</a> <a href="https://www.percona.com/blog/what-if-mysqls-repeatable-reads-cause-you-to-lose-money/">allows</a> non-repeatable reads.</p>
<p>Cabral and Murphy’s 2009 <a href="https://www.oreilly.com/library/view/mysql-administrators-bible/9780470416914/"><em>MySQL Administrator’s Bible</em></a> states that MySQL “supports the four standard isolation levels,” and emphasizes at length that Repeatable Read prevents a transaction from observing another transaction’s concurrent writes:</p>
<blockquote>
<p>Using the <code>REPEATABLE READ</code> isolation level, all reads within a transaction show the same data values, even if a second transaction has committed a data change while the first transaction was still running. If a transaction starts, reads a row, waits 60 seconds, and reads the same row again, both data reads will be the same—even if in those 60 seconds another transaction has changed and committed data. The first transaction has the same data when it repeats the read….</p>
<p><code>REPEATABLE READ</code> may not seem like a good idea—after all, if the data changes, shouldn’t a transaction be aware of that? The problem is that a transaction may take different actions based on the values of the data. Data values changing within a transaction may lead to unexpected consequences.</p>
</blockquote>
<p>Cabral and Murphy repeat that Repeatable Read “allows a transaction to see the same data for values it has already read regardless of whether or not the data has been changed.” In their section on multi-version concurrency control, they emphasize the independence of transaction snapshots:</p>
<blockquote>
<p>If a second transaction starts, it “checks out” its own copy of the data. If the first transaction makes changes and commits, the second transaction will not see the data. The second transaction can only work with the data it has. There is no way to update the data that the second transaction sees, though the second transaction could issue a ROLLBACK and start the transaction again to see the new data.</p>
</blockquote>
<p>This is also wrong: writing a row modifies the transaction’s local copy of the data.</p>
<p>Grippa &amp; Kuzmichev’s 2021 <a href="https://www.oreilly.com/library/view/learning-mysql-2nd/9781492085911/"><em>Learning MySQL</em></a> states that MySQL supports all of the SQL:1992 standard isolation levels. They too claim:</p>
<blockquote>
<p>With the <code>REPEATABLE READ</code> isolation level, there are thus no dirty reads and or non-repeatable reads. Each transaction reads the snapshot established by the first read.</p>
</blockquote>
<p>However, the section on Serializable isolation actually demonstrates (perhaps inadvertently) that MySQL’s Repeatable Read allows both lost update, a change in read snapshot, and a resulting internal consistency violation! It then shows that <code>Serializable</code> prevents those anomalies. It doesn’t name the anomalies, instead opting to say that “this doesn’t make sense”, but the behavior is visible to a careful reader. It’s not clear if the authors realize the example contradicts their earlier claims about non-repeatable reads and snapshot integrity.</p>
<h2 data-number="4.2" id="recommendations"> Recommendations</h2>
<p>The core problem is that MySQL claims to implement Repeatable Read but actually provides something much weaker. We see two avenues to resolve this problem.</p>
<p>The first is to keep MySQL’s behavior as it is, and to clearly document the consistency model “Repeatable Read” actually provides. There is precedent in other databases: PostgreSQL’s Repeatable Read <a href="https://jepsen.io/analyses/postgresql-12.3">is actually Snapshot Isolation</a>, and exhibits behaviors which violate PL-2.99 Repeatable Read. However, PostgreSQL’s documentation eventually <a href="https://www.postgresql.org/docs/current/transaction-iso.html#XACT-REPEATABLE-READ">mentions</a> that their Repeatable Read implementation is actually Snapshot Isolation. MySQL could similarly document that their “Repeatable Read” means “Read Committed, plus some sort of guarantees that hold until the transaction writes something, at which point mysteries occur.” A precise characterization of those mysteries would be most welcome.</p>
<p>The second option is to treat these behaviors as bugs and fix them. Jepsen would be delighted if MySQL and other vendors were to commit to providing PL-2.99 Repeatable Read. However, even satisfying the incomplete, ambiguous ANSI definition of Repeatable Read would be an improvement over current affairs.</p>
<p>In the meantime, MySQL users who require PL-2.99 or ANSI Repeatable Read should be cautious of MySQL Repeatable Read. Reads may not be repeatable, or even reflect a snapshot of committed state. The common ORM pattern in which a transaction reads an object into memory, modifies it, then writes it back within a transaction, may cause committed updates to be silently lost. Users requiring Repeatable Read semantics should use MySQL’s Serializable isolation instead. Alternatively, they can selectively strengthen reads performed at <code>READ COMMITTED</code> using locking techniques like <code>SELECT ... FOR UPDATE</code>.</p>
<h2 data-number="4.3" id="rds"> RDS</h2>
<p>AWS RDS MySQL cluster exhibits read skew and G2-item at its “Serializable” isolation level. Users who rely on Serializability should set <code>slave_preserve_commit_order</code> to <code>ON</code> in their RDS parameter groups. Jepsen suggests that AWS either change the default, or clearly explain the allowed violations of Serializability in the <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MySQL.KnownIssuesAndLimitations.html">known limitations</a> documentation for RDS MySQL.</p>
<h2 data-number="4.4" id="future-work"> Future Work</h2>
<p>MySQL’s binlog replication appears fragile. We observed a number of mysterious scenarios in which replication halted in our local Jepsen tests. We also found that a few minutes of testing could <a href="https://mastodon.jepsen.io/@jepsen/111231274947177218">completely break</a> AWS RDS’s MySQL replication: even a simple <code>CREATE DATABASE</code> would succeed on the primary and fail to appear on the secondaries. We waited an hour without observing recovery. MySQL’s <a href="https://dev.mysql.com/doc/refman/8.0/en/replication-solutions-unexpected-replica-halt.html">default settings are known to be unsafe</a> in replicated systems. We made no attempt to promote nodes from secondaries to primaries, or to explore <a href="https://mariadb.com/kb/en/replication-overview/#common-replication-setups">exciting topologies</a> like ring or star replication. Future work might explore these behaviors.</p>
<p>We have begun research into more general-purpose predicate tests, but this work is still early. Once ready, we’d like to evaluate MySQL predicate safety and see if it differs from primary-key operations.</p>
<h2 data-number="4.5" id="a-plea-to-standards-bodies"> A Plea to Standards Bodies</h2>
<p>Twenty-eight years after Berenson et al.&nbsp;demonstrated that ANSI SQL’s isolation levels are ambiguous and incomplete, seven revisions of the ANSI &amp; ISO standards have left its definitions unchanged.<a href="#fn16" id="fnref16" role="doc-noteref"><sup>16</sup></a> P0 is still legal at every level up to Repeatable Read. We still don’t know whether circular information flow is legal at Read Committed. P3 still doesn’t mention deletes. Internal behavior remains unspecified. <a href="https://www.vldb.org/pvldb/vol7/p181-bailis.pdf">The</a> <a href="https://www.cs.cornell.edu/lorenzo/papers/Crooks17Seeing.pdf">research</a> <a href="https://arxiv.org/abs/1903.00731">community</a> <a href="https://software.imdea.org/~andrea.cerone/works/Framework.pdf">has</a> <a href="https://software.imdea.org/~gotsman/papers/si-podc16.pdf">moved</a> <a href="http://www.cs.ox.ac.uk/people/hongseok.yang/paper/popl14-final.pdf">on</a> <a href="https://asc.di.fct.unl.pt/~nmp/pubs/europar-2-2013.pdf">to</a> <a href="https://dsf.berkeley.edu/cs286/papers/ssi-tods2005.pdf">new</a> <a href="https://www.inf.usi.ch/faculty/pedone/Paper/2004/IC_TECH_REPORT_200421.pdf">formalisms</a>. Many are based on <a href="https://pmg.csail.mit.edu/papers/adya-phd.pdf">Adya’s 1999 thesis</a>, which struggled to capture “what the SQL standard actually meant.”</p>
<p>If you happen to sit on the ISO/IEC JTC1/SC 32 Data Management and Interchange committee, please imagine the soft chords of a heart-tugging piano lament have begun to play. A montage of transactional anomalies appears on your screen. Internal anomalies. Lost updates. Dirty writes. Jepsen is looking into the camera, holding a database.</p>
<blockquote>
<p>Hi. This is Jepsen. Will you be an angel for a helpless database? Every day major databases exhibit anomalous behavior which ISO/IEC 9075-2 fails to characterize. For just <a href="https://pmg.csail.mit.edu/papers/icde00.pdf">a few pages of formalism</a>, you can give vendors and users a clear, meaningful, and portable definition of isolation levels.</p>
<p>It’s been almost three decades. Act now.</p>
</blockquote>
<p><em>Jepsen wishes to thank <a href="https://www.inesctec.pt/en">INESC TEC</a> and in particular João Azevedo, Ricardo Macedo, João Tiago Paulo, José Pereira, and Maria Ramos, for building LazyFS. Our thanks also to <a href="https://github.com/jgpc42">Justin Conklin</a>, who contributed ASM advice and code for a significant performance improvement in Jepsen’s underlying analysis library. <a href="https://www.irenekannyo.com/">Irene Kannyo</a> provided invaluable editorial support. This work was performed independently by Jepsen without compensation, in accordance with the <a href="https://jepsen.io/ethics">Jepsen ethics policy</a>.</em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>Ever sticklers for precision, ANSI <a href="https://blog.ansi.org/sql-standard-iso-iec-9075-2023-ansi-x3-135/">reminds readers</a> that while ANSI approves, copyrights, and publishes standards, “there are no ANSI standards, only standards developed by ANSI-approved committees, many operating in accordance with the ANSI Essential Requirements (American National Standards).” In this work, “the ANSI SQL standard” refers to ANSI X3.135, also known as ISO/IEC 9075. ANSI X3.135 (<a href="https://www.youtube.com/watch?v=3xe7uS62fwY">not an ANSI standard</a>) was originally produced by the Accredited Standards Committee (ASC)’s ANSI Database Technical Committee (ANSI X3H2). ISO 9075, a technically identical standard, was published a few months later. Today ISO/IEC 9075 is developed by the ISO/IEC Joint Technical Committee (JTC) 1 for Information Technology, and INCITS (an ANSI-accredited standards developing organization and the successor to ANSI X3), adopts it for use as an American National Standard.<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>The relevant portion of the SQL standard <a href="https://webstore.ansi.org/standards/iso/isoiec90752023-2502169?source=blog">costs over two hundred dollars</a>, making it inaccessible to casual readers. Precise phrasing is critical for this work, so we reproduce its definitions verbatim.<a href="#fnref2" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Yes, that Jim Gray, of System R fame!<a href="#fnref3" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Readers looking for a shorter version should try <a href="https://pmg.csail.mit.edu/papers/icde00.pdf">Adya’s ICDE paper</a> with Barbara Liskov and Patrick O’Neil.<a href="#fnref4" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>We omit a detailed explanation of the non-cyclic anomalies, as well as a discussion of aborted and committed transactions, internal and external reads/writes, version orders, etc., for brevity.<a href="#fnref5" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>Vendors rarely come out and <em>say</em> they intend to provide the Adya levels, but in practice their implementations either prevent (e.g.) G0 at Read Committed, or, when informed of the behavior, correct it. There are exceptions. For instance, RedPanda <a href="https://jepsen.io/analyses/redpanda-21.10.1">considers G0 legal</a> at “Read Committed,” and Oracle’s “Serializable” is <a href="https://github.com/ept/hermitage/blob/master/oracle.md">actually Snapshot Isolation</a>. Many databases provide higher isolation than is required under Adya’s formalism. For instance, PostgreSQL appears to provide Monotonic Atomic View at read committed.<a href="#fnref6" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>Because write skew can occur in Snapshot Isolation but not PL-2.99, and phantoms can occur in PL-2.99 but some are prevented by Snapshot Isolation, neither is strictly stronger than the other. For more details, see <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf">Berenson et al.</a>, which explains that while A3 (the strict interpretation of phantoms) is prohibited by Snapshot Isolation, it sometimes permits P3 (the broad interpretation).<a href="#fnref7" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>There has been <a href="https://arxiv.org/abs/2301.07313">some confusion</a> about whether Elle’s list-append workload requires a custom datatype not supported by SQL databases. We are happy to share that the SQL standard has included both string and array concatenation since 1999, and that these datatypes and operators are broadly supported by vendors. Elle also includes a workload for plain read-write registers.<a href="#fnref8" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p><a href="http://mpaxos.com/pub/viper-eurosys23.pdf">Some</a> <a href="https://arxiv.org/abs/2301.07313">authors</a> have claimed some or all of Elle’s checkers are unsound. To the best of our knowledge Elle is sound: every anomaly it finds is “real.” As our paper discussed, Elle is not complete: it may fail to detect some anomalies. This work makes Elle more complete.<a href="#fnref9" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>Write skew (A5B) as presented by <a href="https://arxiv.org/pdf/cs/0701157.pdf">Berenson et al</a> requires both transactions read before writing. This particular anomaly is write-skew-esque: the two transactions have overlapping read sets and disjoint write sets causing each to fail to observe the other’s effects. However, one transaction happened to read after writing, rather than before.<a href="#fnref10" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>Breaker panels have a fixed number of slots, some of which may be left free. Adding a circuit involves installing a circuit breaker in a free slot. In this model of G2-item, the electricians check each slot on the breaker panel by performing a series of primary-key reads. If they used a predicate read, this would be G2.<a href="#fnref11" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p>This scenario happened to one of your authors. Thankfully the panel limit was not exceeded.<a href="#fnref12" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p>Some readers might contend that while this meets the formal definition of “lost update,” the updates themselves aren’t so much “lost” as simply “stacked on top of each other in potential violation of constraints.” Consider, however, that if these update operations were blind writes instead of list appends, the resulting state would be indistinguishable from a history in which one of the writes simply never happened. This is the reason P4 is called “lost update.”<a href="#fnref13" role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p>The RDS parameter group for configuring MySQL uses an older name for this setting: <code>slave_preserve_commit_order</code>. MySQL is in the process of adopting more inclusive language, and Jepsen uses the newer “replica” term wherever possible.<a href="#fnref14" role="doc-backlink">↩︎</a></p></li>
<li id="fn15" role="doc-endnote"><p>Kleppman goes on to note in a later section that MySQL/InnoDB fails to prevent lost update, and that this fails to meet “some authors” definitions of Snapshot Isolation.<a href="#fnref15" role="doc-backlink">↩︎</a></p></li>
<li id="fn16" role="doc-endnote"><p>From the late 1980s through 1995 <a href="https://tdan.com/is-sql-a-real-standard-anymore/4923">NIST performed conformance testing</a> to evaluate whether databases correctly implemented the SQL standard. One wonders how they would evaluate transaction safety today.<a href="#fnref16" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
  </div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An In-depth Look at Gemini's Language Abilities (115 pts)]]></title>
            <link>https://arxiv.org/abs/2312.11444</link>
            <guid>38695583</guid>
            <pubDate>Tue, 19 Dec 2023 14:01:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2312.11444">https://arxiv.org/abs/2312.11444</a>, See on <a href="https://news.ycombinator.com/item?id=38695583">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2312.11444.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>The recently released Google Gemini class of models are the first to comprehensively report results that rival the OpenAI GPT series across a wide variety of tasks. In this paper, we do an in-depth exploration of Gemini's language abilities, making two contributions. First, we provide a third-party, objective comparison of the abilities of the OpenAI GPT and Google Gemini models with reproducible code and fully transparent results. Second, we take a closer look at the results, identifying areas where one of the two model classes excels. We perform this analysis over 10 datasets testing a variety of language abilities, including reasoning, answering knowledge-based questions, solving math problems, translating between languages, generating code, and acting as instruction-following agents. From this analysis, we find that Gemini Pro achieves accuracy that is close but slightly inferior to the corresponding GPT 3.5 Turbo on all tasks that we benchmarked. We further provide explanations for some of this under-performance, including failures in mathematical reasoning with many digits, sensitivity to multiple-choice answer ordering, aggressive content filtering, and others. We also identify areas where Gemini demonstrates comparably high performance, including generation into non-English languages, and handling longer and more complex reasoning chains. Code and data for reproduction can be found at <a href="https://github.com/neulab/gemini-benchmark" rel="external noopener nofollow">this https URL</a>
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Graham Neubig [<a href="https://arxiv.org/show-email/6908451c/2312.11444">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 18 Dec 2023 18:47:42 UTC (3,372 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox 121 defaults to Wayland on Linux (181 pts)]]></title>
            <link>https://www.omgubuntu.co.uk/2023/12/firefox-121-released-now-defaults-to-wayland-on-linux</link>
            <guid>38695533</guid>
            <pubDate>Tue, 19 Dec 2023 13:56:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.omgubuntu.co.uk/2023/12/firefox-121-released-now-defaults-to-wayland-on-linux">https://www.omgubuntu.co.uk/2023/12/firefox-121-released-now-defaults-to-wayland-on-linux</a>, See on <a href="https://news.ycombinator.com/item?id=38695533">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                <article id="post-275524">
                                                
                            <div>
                        
<p><strong>Mozilla Firefox 121 has been released, and it’s a notable one for Linux Wayland users.</strong></p>



<p>For the Ubuntu 23.10 release, the <a href="https://www.omgubuntu.co.uk/2023/09/wayland-firefox-snap-default">Firefox Snap runs in Wayland mode</a> by default (and like many of you I’ve noticed nothing but bountiful benefits resulting from the switch). </p>



<p>Mozilla’s workshop elves were clearly happy with the success of that trial as they’ve now chosen to make Firefox 121 run in Wayland mode by default for all Linux users (who use Wayland; the browser runs under Xorg/X11 as well as it ever did).</p>



<p>Why is Firefox enabling native Wayland mode by default a big deal? And how does that mode differ to the xWayland mode the browser has been running in on Wayland sessions prior to this release?</p>



<ul>
<li><strong>Better graphics performance</strong></li>



<li><strong>Non-blurry rendering on HiDPI displays/fractional scaling</strong></li>



<li><strong>Per-monitor DPI settings respected</strong></li>



<li><strong>Full support for touchpad <em>and</em> touchscreen gestures</strong></li>
</ul>



<p>Plus:</p>



<ul>
<li><strong>It’s embracing the future ✨</strong></li>
</ul>



<p>Okay, so that bullet point isn’t something Mozilla is talking up but, as a Linux user, it’s clear that Wayland <strong>is</strong> the future for modern, secure, performant display server needs on Linux. Like 64-bit computing, it just is.</p>



<p>The days of Wayland being a “someday” feature, off in the distance, obscured by wisps of hope and concern, are gone. It’s here, it’s in use, it’s where the momentum and demand are at, and it’s bringing cool new things with it, like HDR support to Linux.</p>



<p>And for Mozilla Firefox to continue providing Linux users with a solid, dependable, and integrated experience on Linux, it too has to keep pace with technological changes — and defaulting to Wayland by default (where supported) is a key play in that.</p>



<p>Got a bit sidetracked there, sorry 😅.</p>



<p>Other notable <a href="https://www.mozilla.org/en-US/firefox/121.0/releasenotes/" target="_blank" rel="noreferrer noopener">changes in Firefox 121</a>:</p>



<ul>
<li><strong>New option to force-underline links in websites</strong></li>



<li><strong>Easier to delete drawings/text/images when editing PDFs</strong></li>



<li><strong>Support for Voice Control commands on macOS</strong></li>



<li><strong>Prompts users to install Microsoft AV1 Extension on Windows</strong></li>
</ul>



<p>Linux-specific bug fixes include:</p>



<ul>
<li><strong>PiP window showing black borders on top and bottom</strong></li>



<li><strong>AppStream metainfo in Firefox Flatpak now follows latest spec</strong></li>



<li><strong>Dialogs/windows becoming ‘unnecessarily’ large in KDE Wayland</strong></li>



<li><strong>Mouse cursor inappropriately changes icon</strong></li>



<li><strong><a href="https://hg.mozilla.org/mozilla-central/rev/86de5a0de5cd" target="_blank" rel="noreferrer noopener">Fix for issue causing slow startup</a> on certain distros</strong></li>



<li><strong><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1849186" target="_blank" rel="noreferrer noopener">Browsing history being leaked to syslogs</a> in GNOME</strong></li>
</ul>



<p>Firefox 121 boasts further expansion to its web platform capabilities, including support for&nbsp;<code>hanging</code>&nbsp;&amp;&nbsp;<code>each-line</code>&nbsp;keywords in the CSS text-indent property, and support for <code>text-wrap: balance</code> to ‘harmonize’ line lengths in short, multi-line text blocks.</p>



<h2>Download Firefox 121</h2>



<p>I think that covers the bulk of the changes here, but if you happen to notice something I didn’t, do let me know by leaving a comment down in, well the comments section.</p>



<p>Otherwise, look out for an update to Mozilla Firefox 121 on your system in the next day or so. It’ll come as an in-app update (existing Firefox users on Windows and macOS, Linux binary users); a background update (users of the Firefox Snap); or as a repo update (users of PPAs, AUR, etc).</p>



<p>Alternatively, you can download Mozilla Firefox from the official website.</p>
                                                                                                
                                                                    </div>
                </article>
                                
                
                
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[James Webb Space Telescope captures high-resolution image of Uranus (565 pts)]]></title>
            <link>https://webbtelescope.org/contents/news-releases/2023/news-2023-150</link>
            <guid>38695337</guid>
            <pubDate>Tue, 19 Dec 2023 13:37:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://webbtelescope.org/contents/news-releases/2023/news-2023-150">https://webbtelescope.org/contents/news-releases/2023/news-2023-150</a>, See on <a href="https://news.ycombinator.com/item?id=38695337">Hacker News</a></p>
Couldn't get https://webbtelescope.org/contents/news-releases/2023/news-2023-150: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Volkswagen Will Bring Back Physical Buttons in New Cars (374 pts)]]></title>
            <link>https://insideevs.com/news/701296/vw-physical-controls-to-return/</link>
            <guid>38694886</guid>
            <pubDate>Tue, 19 Dec 2023 12:51:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://insideevs.com/news/701296/vw-physical-controls-to-return/">https://insideevs.com/news/701296/vw-physical-controls-to-return/</a>, See on <a href="https://news.ycombinator.com/item?id=38694886">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post_box"> <div> <p><span data-time="1702909828"></span><span>Dec 18, 2023</span><span> at</span> 2:30pm ET</p>  </div> <div> <p>Volkswagen is still intent on marching its entire lineup of vehicles toward electrification in many of its markets. With that modernization of vehicle powertrains also comes more contemporary interiors; that means meshing design languages with current industry trends like minimalism, which involves ditching physical interior buttons with touch screen controls.</p> <section contenteditable="false" draggable="true" data-widget="widget_faq" data-noinit="1"> <h3><span><svg><use xlink:href="https://insideevs.com/design/dist/critical/icons/sprite-common-0-dc6b7de11d922cb73553899f27128303.svg#sqr-arrow"></use></svg></span>Get Fully Charged</h3>  </section> <p>Unfortunately for VW, that hasn't exactly been well received by consumers. Owners have pushed back against the German automaker moving controls to the large tablet-like infotainment touch screen on the dashboard and haptic-based steering wheel buttons, finally forcing the automaker to reverse its decision on going buttonless—and that all starts with the new <a href="https://insideevs.com/news/682384/vw-id2all-concept-walkaround-brand-ceo/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22682384%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22vw-id2all-concept-walkaround-brand-ceo%22%7D">ID.2all concept</a>.</p> <section contenteditable="false" draggable="true" data-widget="image" data-border="" data-id="7184833"> <span> <svg> <use xlink:href="https://insideevs.com/design/dist/critical/icons/sprite-common-4-aab71d103bb6c273cab9291678c627d9.svg#search"></use> </svg> </span> <picture> <source type="image/webp" data-srcset=" https://cdn.motor1.com/images/mgl/P3nPeA/s5/volkswagen-id.2all.webp 213w, https://cdn.motor1.com/images/mgl/P3nPeA/s6/volkswagen-id.2all.webp 445w, https://cdn.motor1.com/images/mgl/P3nPeA/s4/volkswagen-id.2all.webp 889w, https://cdn.motor1.com/images/mgl/P3nPeA/s3/volkswagen-id.2all.webp 1280w, https://cdn.motor1.com/images/mgl/P3nPeA/s2/volkswagen-id.2all.webp 1440w, https://cdn.motor1.com/images/mgl/P3nPeA/s1/volkswagen-id.2all.webp 1920w " sizes="(max-width: 767px) calc(100vw - 30px), (max-width: 1023px) calc(100vw - 50px), 649px"> <source type="image/jpeg" data-srcset=" https://cdn.motor1.com/images/mgl/P3nPeA/s5/volkswagen-id.2all.jpg 213w, https://cdn.motor1.com/images/mgl/P3nPeA/s6/volkswagen-id.2all.jpg 445w, https://cdn.motor1.com/images/mgl/P3nPeA/s4/volkswagen-id.2all.jpg 889w, https://cdn.motor1.com/images/mgl/P3nPeA/s3/volkswagen-id.2all.jpg 1280w, https://cdn.motor1.com/images/mgl/P3nPeA/s2/volkswagen-id.2all.jpg 1440w, https://cdn.motor1.com/images/mgl/P3nPeA/s1/volkswagen-id.2all.jpg 1920w " sizes="(max-width: 767px) calc(100vw - 30px), (max-width: 1023px) calc(100vw - 50px), 649px"> <img src="https://cdn.motor1.com/images/static/16x9-tr.png" alt="Volkswagen ID.2all" width="16" height="9" loading="lazy"> </picture> </section> <p>Volkswagen has been trying to fix its interiors for a few years now. Under former CEO Herbert Diess, the German automaker decided to follow in<a href="https://insideevs.com/news/696419/tesla-cybertruck-interior-video/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22696419%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22tesla-cybertruck-interior-video%22%7D"> Tesla's footsteps</a> and centralize a vast majority of its controls to the infotainment screen. It also removed the physical buttons from its steering wheels and replaced them with touch-sensitive capacitive buttons instead. This move, according to VW, "frustrated customers who shouldn't be frustrated."</p> <p>The automaker has since reverted its since on the steering wheel buttons and is looking to now claw back its reputation for something that its current CEO, Thomas Schäfer, says "did a lot of damage" to the brand.</p> <p>That change all starts with the Volkswagen ID 2. Recently, VW's interior designer, Darius Watola, spoke to <a href="https://www.autocar.co.uk/car-news/new-cars/volkswagen-id-2" target="_blank" rel="noopener">Autocar</a> on the ID.2 concept's take on the company's design language for future vehicle interiors. Watola confirmed that the concept showed a new approach for all models across the VW brand which was revamped due to customer feedback.</p> <p>A row of physical, backlit buttons now sits directly below the <a href="https://insideevs.com/news/700047/bmw-3d-touchscreen-prototype/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22700047%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22bmw-3d-touchscreen-prototype%22%7D">touch screen</a> on the ID.2 concept. The buttons provide customers with easy access to commonly used HVAC controls, which—while it doesn't address <em>every</em> control in the car—is a step in the right direction. The car will also get a manual volume button and a large center knob (a la BMW iDrive) which provides complementary controls for other aspects of the vehicle.</p> <p>The controls also clearly lean on the importance of feel, even featuring metal knurling so occupants can easily feel them without taking their eyes off of the road.</p> <section contenteditable="false" draggable="true" data-widget="video"><img draggable="false" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAJCAYAAAA7KqwyAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAABpJREFUeNpi/P//PwMlgImBQjBqwLAwACDAAOVfAw9/ZDvcAAAAAElFTkSuQmCC" alt=""> <p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="315" title="YouTube video player" width="560" data-src="https://www.youtube.com/embed/I1MgIf7UP-0?si=kfNSJ8ZneVK3jwD_" data-src-param=""></iframe></p> </section> <p>"Once you have it, don't touch it again," said Volkswagen CEO Thomas Schäfer in an interview with <a href="https://www.autocar.co.uk/car-news/new-cars/volkswagen-ceo-fixing-frustrating-interiors-did-lot-damage" target="_blank" rel="noopener"><em>Autocar</em></a> earlier this year. "Bloody leave it. Don't confuse our customers every time a new model comes out and something is completely different. Optimize it. Bring into the future. But don't change buttons from here to there, to there and here."</p> <p>It's no secret that consumers have pushed back on automakers who simply slapped an iPad on the dashboard in place of physical controls. Heck, <a href="https://slate.com/business/2023/04/cars-buttons-touch-screens-vw-porsche-nissan-hyundai.html" target="_blank" rel="noopener">Volkswagen isn't the first automaker to change its stance back to the old-school physical button approach</a>, either. Let's be real—if Volkswagen is really trying to regain its relevancy in markets like the United States (even if this change was geared at the European market), it has to take customer feedback seriously. And it looks like the Germans are starting to do exactly that.</p> <section contenteditable="false" draggable="true" data-widget="related-content" data-widget-size="content" data-params="%7B%22type_id%22%3A0%2C%22title_id%22%3A%22%22%2C%22items%22%3A%5B%7B%22article_edition_id%22%3A%22700676%22%2C%22title%22%3A%22You%20Can%20Get%20An%20Incredible%20Deal%20On%20A%20Volkswagen%20ID.4%20Right%20Now%22%2C%22alias%22%3A%22vw-id4-holiday-deals%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2Fx7xyk%2Fs5%2Fid.4-charging.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22700247%22%2C%22title%22%3A%22This%20Volkswagen%20ID.3%20Lost%2010%25%20Of%20Its%20Battery%20Capacity%20After%2030%2C000%20Miles%22%2C%22alias%22%3A%22vw-id3-battery-degradation-30k-miles-video%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%221%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FNGj48j%2Fs5%2Fvolkswagen-id.3-battery-degradation-after-30-000-miles-source-bjorn-nyland-youtube.jpg%22%7D%7D%5D%7D"> <p>More VW News</p>  </section> </div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making my own bed sensor (105 pts)]]></title>
            <link>https://www.homeautomationguy.io/blog/making-my-own-bed-sensor</link>
            <guid>38694880</guid>
            <pubDate>Tue, 19 Dec 2023 12:50:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.homeautomationguy.io/blog/making-my-own-bed-sensor">https://www.homeautomationguy.io/blog/making-my-own-bed-sensor</a>, See on <a href="https://news.ycombinator.com/item?id=38694880">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">
        
          
<article id="sections" data-page-sections="640350396f7f413d978a46a5">
  
  
    
    


  


<div data-content-field="main-content" data-item-id="" data-test="page-section" data-section-theme="" data-section-id="640350396f7f413d978a46a4" data-controller="SectionWrapperController" data-current-styles="{
                    &quot;imageOverlayOpacity&quot;: 0.15,
                    &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                    &quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
                    &quot;customSectionHeight&quot;: 10,
                    &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                    &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                    &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                    &quot;customContentWidth&quot;: 50,
                    &quot;backgroundColor&quot;: &quot;&quot;,
                    &quot;sectionTheme&quot;: &quot;&quot;,
                    &quot;sectionAnimation&quot;: &quot;none&quot;,
                    &quot;backgroundMode&quot;: &quot;image&quot;
                  }" data-current-context="{
                    &quot;video&quot;: {
                      &quot;playbackSpeed&quot;: 0.5,
                      &quot;filter&quot;: 1,
                      &quot;filterStrength&quot;: 0,
                      &quot;zoom&quot;: 0,
                      &quot;videoSourceProvider&quot;: &quot;none&quot;
                    },
                    &quot;backgroundImageId&quot;: null,
                    &quot;backgroundMediaEffect&quot;: null,
                    &quot;divider&quot;: null,
                    &quot;typeName&quot;: &quot;blog-side-by-side&quot;
                  }" data-animation="none">
  <article id="article-">
  
    <div data-layout-label="Post Body" data-type="item" id="item-64ef56a0384e5519066eb888"><div data-block-type="2" id="block-c217fda8e0a0abec3774">

<p>I recently created some “bed sensors” for my smart home that detect if one of us, or both of us, is in bed.  I use a couple of pressure mats that detect when weight is applied to them, and stuck then under our mattress at around hip level and these tell my Home Assistant home automation platform if someone is lying on top of that part of the bed.</p>






















</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_3379">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be74e130-01ea-47c4-9b15-c8529663218b/PXL_20230806_085643631.TS_exported_1739_1692366175497.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be74e130-01ea-47c4-9b15-c8529663218b/PXL_20230806_085643631.TS_exported_1739_1692366175497.jpg" data-image-dimensions="1920x1080" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be74e130-01ea-47c4-9b15-c8529663218b/PXL_20230806_085643631.TS_exported_1739_1692366175497.jpg" width="1920" height="1080" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be74e130-01ea-47c4-9b15-c8529663218b/PXL_20230806_085643631.TS_exported_1739_1692366175497.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be74e130-01ea-47c4-9b15-c8529663218b/PXL_20230806_085643631.TS_exported_1739_1692366175497.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be74e130-01ea-47c4-9b15-c8529663218b/PXL_20230806_085643631.TS_exported_1739_1692366175497.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be74e130-01ea-47c4-9b15-c8529663218b/PXL_20230806_085643631.TS_exported_1739_1692366175497.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be74e130-01ea-47c4-9b15-c8529663218b/PXL_20230806_085643631.TS_exported_1739_1692366175497.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be74e130-01ea-47c4-9b15-c8529663218b/PXL_20230806_085643631.TS_exported_1739_1692366175497.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be74e130-01ea-47c4-9b15-c8529663218b/PXL_20230806_085643631.TS_exported_1739_1692366175497.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_4325">
  <p>I originally thought that these would be more of a gimmick, than actually useful, but this turned out to be totally wrong!  These now form an integral part of my smart home and I use them to not only trigger certain automations, but also prevent other automations from running if someone is in bed.  For example, I don’t want the ceiling lights coming on in the bedroom if someone is in bed having a sleep!</p><p>This article shows you two ways I went about making one of these bed sensors.  If you want to see the full end to end build process, check out my video about it!</p><h3>Equipment Needed</h3><p>The first thing you’ll need is a pressure mat, or pressure sensor.  I used one I <a href="https://www.amazon.co.uk/gp/product/B07P5Z7L77" target="_blank">sourced from Amazon</a>, and it costs less than $25. You can also <a href="https://www.switchelectronics.co.uk/products/large-pressure-alarm-switch-mat-720-x-390mm-pm156?currency=GBP&amp;variant=45392025387317">buy them from here</a>, and they're much cheaper. These are pretty basic things, and are essentially just pressure switches - if weight is applied to the mat, it completes the circuit.  Make sure you get one with these exposed wires, so you can wire it up to the rest of the sensor.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_6767">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/3583404f-62a1-47ab-bc58-a56aec47a750/Pressure+Mat.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/3583404f-62a1-47ab-bc58-a56aec47a750/Pressure+Mat.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/3583404f-62a1-47ab-bc58-a56aec47a750/Pressure+Mat.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/3583404f-62a1-47ab-bc58-a56aec47a750/Pressure+Mat.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/3583404f-62a1-47ab-bc58-a56aec47a750/Pressure+Mat.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/3583404f-62a1-47ab-bc58-a56aec47a750/Pressure+Mat.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/3583404f-62a1-47ab-bc58-a56aec47a750/Pressure+Mat.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/3583404f-62a1-47ab-bc58-a56aec47a750/Pressure+Mat.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/3583404f-62a1-47ab-bc58-a56aec47a750/Pressure+Mat.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/3583404f-62a1-47ab-bc58-a56aec47a750/Pressure+Mat.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_15605">
  <p>You will need to identify which of the wires you need use in your sensor.  Two of these wires loop together to make contact when you press down on the pad, and the other two… well I have NFI what they do.</p><p>Using a multimeter on continuity mode you can hold the wires to the two probes and press down on the mat.  If you’ve got the right wires the meter should beep indicating that contact has been made when you press down.  These are the wires you need to use, so make a note of them with some tape or something.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_16506">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5ac07690-0c4e-4270-9443-ae41d71e9b10/Multimeter.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5ac07690-0c4e-4270-9443-ae41d71e9b10/Multimeter.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5ac07690-0c4e-4270-9443-ae41d71e9b10/Multimeter.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5ac07690-0c4e-4270-9443-ae41d71e9b10/Multimeter.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5ac07690-0c4e-4270-9443-ae41d71e9b10/Multimeter.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5ac07690-0c4e-4270-9443-ae41d71e9b10/Multimeter.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5ac07690-0c4e-4270-9443-ae41d71e9b10/Multimeter.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5ac07690-0c4e-4270-9443-ae41d71e9b10/Multimeter.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5ac07690-0c4e-4270-9443-ae41d71e9b10/Multimeter.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5ac07690-0c4e-4270-9443-ae41d71e9b10/Multimeter.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>BEEEEEP!</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_7827">
  <p>As I mentioned, there are two ways you can make these sensors.  </p><h4>Using an Aqara Leak Sensor</h4><p>The first way is the easiest and uses a <a href="https://www.aqara.com/en/product/water-sensor/" target="_blank">Zigbee Aqara Leak Sensor</a>.  You can buy these in a lot of places, and they conveniently have two removable terminals on the back that you can attach the wires from the pressure mat to.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_9165">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/7c3a0ec7-7cbb-4f80-b8d1-142fc97413a3/Leak+Sensor.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/7c3a0ec7-7cbb-4f80-b8d1-142fc97413a3/Leak+Sensor.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/7c3a0ec7-7cbb-4f80-b8d1-142fc97413a3/Leak+Sensor.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/7c3a0ec7-7cbb-4f80-b8d1-142fc97413a3/Leak+Sensor.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/7c3a0ec7-7cbb-4f80-b8d1-142fc97413a3/Leak+Sensor.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/7c3a0ec7-7cbb-4f80-b8d1-142fc97413a3/Leak+Sensor.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/7c3a0ec7-7cbb-4f80-b8d1-142fc97413a3/Leak+Sensor.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/7c3a0ec7-7cbb-4f80-b8d1-142fc97413a3/Leak+Sensor.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/7c3a0ec7-7cbb-4f80-b8d1-142fc97413a3/Leak+Sensor.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/7c3a0ec7-7cbb-4f80-b8d1-142fc97413a3/Leak+Sensor.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_11153">
  <h4>Using ESPHome</h4><p>You can also create a bed sensor using an <a href="https://en.wikipedia.org/wiki/ESP32" target="_blank">ESP Device</a>, and <a href="https://esphome.io/" target="_blank">ESPHome</a>.  ESP Devices are small Bluetooth and WiFi enabled microcomputers, and when you combine them with the ESPHome software platform you can create almost any type of smart home sensor you want.</p><p>I figured that this project was the perfect way for me to get started with, and learn more about, ESPHome. If you want to take this route, you’ll need to buy an ESP Device.  I recommend <a href="https://www.amazon.co.uk/gp/product/B08DR5T897" target="_blank">these ESP32s</a>, and to make life easier I suggest getting these <a href="https://www.amazon.co.uk/gp/product/B0BCWBW4SR/" target="_blank">green companion development boards</a> which let you screw cables into terminals for testing and prototyping - so you don’t need to bother with all that soldering.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_13469">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c22d926e-8940-4d9d-be2e-32b3a9ff291a/Dev+Board.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c22d926e-8940-4d9d-be2e-32b3a9ff291a/Dev+Board.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c22d926e-8940-4d9d-be2e-32b3a9ff291a/Dev+Board.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c22d926e-8940-4d9d-be2e-32b3a9ff291a/Dev+Board.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c22d926e-8940-4d9d-be2e-32b3a9ff291a/Dev+Board.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c22d926e-8940-4d9d-be2e-32b3a9ff291a/Dev+Board.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c22d926e-8940-4d9d-be2e-32b3a9ff291a/Dev+Board.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c22d926e-8940-4d9d-be2e-32b3a9ff291a/Dev+Board.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c22d926e-8940-4d9d-be2e-32b3a9ff291a/Dev+Board.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c22d926e-8940-4d9d-be2e-32b3a9ff291a/Dev+Board.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_14991">
  <h3>The Build - Easy Mode</h3><p>All you really need to do is attach the two wires you identified previously to the terminals on the back of the Leak Sensor. You can use a small Allen Key to remove the terminals and then just shove the wires underneath and tighten them up.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_18173">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/bd205a28-3b1b-4bc1-a8e1-b55470ab4028/PXL_20230830_151553267.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/bd205a28-3b1b-4bc1-a8e1-b55470ab4028/PXL_20230830_151553267.jpg" data-image-dimensions="4032x2268" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/bd205a28-3b1b-4bc1-a8e1-b55470ab4028/PXL_20230830_151553267.jpg" width="4032" height="2268" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/bd205a28-3b1b-4bc1-a8e1-b55470ab4028/PXL_20230830_151553267.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/bd205a28-3b1b-4bc1-a8e1-b55470ab4028/PXL_20230830_151553267.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/bd205a28-3b1b-4bc1-a8e1-b55470ab4028/PXL_20230830_151553267.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/bd205a28-3b1b-4bc1-a8e1-b55470ab4028/PXL_20230830_151553267.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/bd205a28-3b1b-4bc1-a8e1-b55470ab4028/PXL_20230830_151553267.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/bd205a28-3b1b-4bc1-a8e1-b55470ab4028/PXL_20230830_151553267.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/bd205a28-3b1b-4bc1-a8e1-b55470ab4028/PXL_20230830_151553267.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_19324">
  <p>Now pair the leak sensors with your favourite smart home platform, like the Aqara Hub, HomeKit, or Home Assistant using ZHA or Zigbee2MQTT.</p><p>When you now press down on the pad, you should see that smart home platform tell you that a leak has been detected!</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_19870">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/cd457f24-98d4-416e-a0fb-27278dd378d8/Leak.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/cd457f24-98d4-416e-a0fb-27278dd378d8/Leak.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/cd457f24-98d4-416e-a0fb-27278dd378d8/Leak.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/cd457f24-98d4-416e-a0fb-27278dd378d8/Leak.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/cd457f24-98d4-416e-a0fb-27278dd378d8/Leak.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/cd457f24-98d4-416e-a0fb-27278dd378d8/Leak.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/cd457f24-98d4-416e-a0fb-27278dd378d8/Leak.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/cd457f24-98d4-416e-a0fb-27278dd378d8/Leak.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/cd457f24-98d4-416e-a0fb-27278dd378d8/Leak.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/cd457f24-98d4-416e-a0fb-27278dd378d8/Leak.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_20737">
  <p>You could use this sensor in your automations right now, triggering any automation when the sensor goes from dry to wet… but do you really want your bed sensor telling you that you’ve leaked into the bed? No, probably not.</p><p>In Home Assistant you can go to the settings of that entity, and change the Show As part from Moisture to Occupancy.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_21511">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/8d2c6b71-6a38-411d-b3d4-ae16e7f1fbd9/Occupancy.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/8d2c6b71-6a38-411d-b3d4-ae16e7f1fbd9/Occupancy.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/8d2c6b71-6a38-411d-b3d4-ae16e7f1fbd9/Occupancy.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/8d2c6b71-6a38-411d-b3d4-ae16e7f1fbd9/Occupancy.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/8d2c6b71-6a38-411d-b3d4-ae16e7f1fbd9/Occupancy.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/8d2c6b71-6a38-411d-b3d4-ae16e7f1fbd9/Occupancy.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/8d2c6b71-6a38-411d-b3d4-ae16e7f1fbd9/Occupancy.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/8d2c6b71-6a38-411d-b3d4-ae16e7f1fbd9/Occupancy.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/8d2c6b71-6a38-411d-b3d4-ae16e7f1fbd9/Occupancy.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/8d2c6b71-6a38-411d-b3d4-ae16e7f1fbd9/Occupancy.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_22495">

<p>Now, Home Assistant will report Clear or Detected, instead of Dry and Wet when you press down on the pressure mat</p>






















</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_22914">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/753d1216-2f9b-430c-b083-676f579c2715/Sequence+01.00_05_02_12.Still007.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/753d1216-2f9b-430c-b083-676f579c2715/Sequence+01.00_05_02_12.Still007.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/753d1216-2f9b-430c-b083-676f579c2715/Sequence+01.00_05_02_12.Still007.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/753d1216-2f9b-430c-b083-676f579c2715/Sequence+01.00_05_02_12.Still007.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/753d1216-2f9b-430c-b083-676f579c2715/Sequence+01.00_05_02_12.Still007.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/753d1216-2f9b-430c-b083-676f579c2715/Sequence+01.00_05_02_12.Still007.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/753d1216-2f9b-430c-b083-676f579c2715/Sequence+01.00_05_02_12.Still007.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/753d1216-2f9b-430c-b083-676f579c2715/Sequence+01.00_05_02_12.Still007.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/753d1216-2f9b-430c-b083-676f579c2715/Sequence+01.00_05_02_12.Still007.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/753d1216-2f9b-430c-b083-676f579c2715/Sequence+01.00_05_02_12.Still007.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_24001">
  <p>And you’re done, you now have your very own pressure sensor that you can put under your mattress, under a sofa, wherever you want to know if something, or someone, has been placed on top of it!</p><h3>The Build - ESPHome</h3><p>A bed sensor is a very simple binary sensor, it’s either ON (Someone is in bed) or OFF (No-one is in the bed).  For me, this was the perfect project to use to learn more about <a href="https://en.wikipedia.org/wiki/ESP32" target="_blank">ESP devices</a> and <a href="https://esphome.io/index.html" target="_blank">ESPHome</a>.</p><p>The concept is pretty much the same:  When pressure is applied to the mat, it closes the connection and completes the circuit, so we can use ESPHome to detect that and tell Home Assistant.</p><h4>Wire it up</h4><p>To get started, we screw the same two wires from the pressure mat to the ESP Device.  One of the wires needs to connect to the Ground terminal (GND), and the other to one of the GPIO Pins.  I’ve chosen GPIO13, because it happens to be the one that’s next to the GND terminal on my device.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_26355">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c600cc75-e8f7-4455-82e3-32fd246094c1/Pinout+Guide.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c600cc75-e8f7-4455-82e3-32fd246094c1/Pinout+Guide.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c600cc75-e8f7-4455-82e3-32fd246094c1/Pinout+Guide.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c600cc75-e8f7-4455-82e3-32fd246094c1/Pinout+Guide.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c600cc75-e8f7-4455-82e3-32fd246094c1/Pinout+Guide.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c600cc75-e8f7-4455-82e3-32fd246094c1/Pinout+Guide.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c600cc75-e8f7-4455-82e3-32fd246094c1/Pinout+Guide.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c600cc75-e8f7-4455-82e3-32fd246094c1/Pinout+Guide.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c600cc75-e8f7-4455-82e3-32fd246094c1/Pinout+Guide.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c600cc75-e8f7-4455-82e3-32fd246094c1/Pinout+Guide.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-aspect-ratio="56.24461670973299" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_27780">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/9ae8808b-ae3b-45b1-835b-4b175485569b/ESP+Device+Connected.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/9ae8808b-ae3b-45b1-835b-4b175485569b/ESP+Device+Connected.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/9ae8808b-ae3b-45b1-835b-4b175485569b/ESP+Device+Connected.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/9ae8808b-ae3b-45b1-835b-4b175485569b/ESP+Device+Connected.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/9ae8808b-ae3b-45b1-835b-4b175485569b/ESP+Device+Connected.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/9ae8808b-ae3b-45b1-835b-4b175485569b/ESP+Device+Connected.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/9ae8808b-ae3b-45b1-835b-4b175485569b/ESP+Device+Connected.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/9ae8808b-ae3b-45b1-835b-4b175485569b/ESP+Device+Connected.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/9ae8808b-ae3b-45b1-835b-4b175485569b/ESP+Device+Connected.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/9ae8808b-ae3b-45b1-835b-4b175485569b/ESP+Device+Connected.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_29798">
  <h4>Install the ESPHome firmware</h4><p>Once you’ve wired up the device, plug it into a PC using a USB data cable.  The key term there is DATA CABLE. So many times I’ve plugged them into my PC using a generic USB charging cable that has no data wires inside it, and then I pull my hair out wondering why it won’t connect.</p><p>Then open up <a href="https://web.esphome.io/">https://web.esphome.io</a> and click the connect button.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_31176">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4b1d61ae-5e01-4f11-ae54-5be031c9fd14/ESPHome1.png" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4b1d61ae-5e01-4f11-ae54-5be031c9fd14/ESPHome1.png" data-image-dimensions="2161x1304" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4b1d61ae-5e01-4f11-ae54-5be031c9fd14/ESPHome1.png" width="2161" height="1304" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4b1d61ae-5e01-4f11-ae54-5be031c9fd14/ESPHome1.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4b1d61ae-5e01-4f11-ae54-5be031c9fd14/ESPHome1.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4b1d61ae-5e01-4f11-ae54-5be031c9fd14/ESPHome1.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4b1d61ae-5e01-4f11-ae54-5be031c9fd14/ESPHome1.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4b1d61ae-5e01-4f11-ae54-5be031c9fd14/ESPHome1.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4b1d61ae-5e01-4f11-ae54-5be031c9fd14/ESPHome1.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4b1d61ae-5e01-4f11-ae54-5be031c9fd14/ESPHome1.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_32239">
  <p>Click on the device in the list, and click connect.  </p><p><strong>If you get a message saying that no compatible devices could be found</strong> then click Cancel, and follow the troubleshooting steps.  Most likely you will need to install the drivers for the ESP devices, and there are links in the pop up message for your operating system.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_33219">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/d1e6381e-2345-430c-a1a2-a48de09cce42/ESPHome2.png" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/d1e6381e-2345-430c-a1a2-a48de09cce42/ESPHome2.png" data-image-dimensions="2114x1098" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/d1e6381e-2345-430c-a1a2-a48de09cce42/ESPHome2.png" width="2114" height="1098" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/d1e6381e-2345-430c-a1a2-a48de09cce42/ESPHome2.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/d1e6381e-2345-430c-a1a2-a48de09cce42/ESPHome2.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/d1e6381e-2345-430c-a1a2-a48de09cce42/ESPHome2.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/d1e6381e-2345-430c-a1a2-a48de09cce42/ESPHome2.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/d1e6381e-2345-430c-a1a2-a48de09cce42/ESPHome2.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/d1e6381e-2345-430c-a1a2-a48de09cce42/ESPHome2.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/d1e6381e-2345-430c-a1a2-a48de09cce42/ESPHome2.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_34193">

<p>Once you’ve checked the drivers and cable, you can click Connect again and hopefully the devices is found.  Connect to it and then you can press Prepare for First Use, which will install the default ESPHome firmware onto it.</p>






















</div><div data-test="image-block-inline-outer-wrapper" data-aspect-ratio="56.23100303951368" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_34719">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/74219529-9bff-42b3-bcc4-6635bea63008/First+ESP+Install.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/74219529-9bff-42b3-bcc4-6635bea63008/First+ESP+Install.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/74219529-9bff-42b3-bcc4-6635bea63008/First+ESP+Install.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/74219529-9bff-42b3-bcc4-6635bea63008/First+ESP+Install.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/74219529-9bff-42b3-bcc4-6635bea63008/First+ESP+Install.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/74219529-9bff-42b3-bcc4-6635bea63008/First+ESP+Install.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/74219529-9bff-42b3-bcc4-6635bea63008/First+ESP+Install.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/74219529-9bff-42b3-bcc4-6635bea63008/First+ESP+Install.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/74219529-9bff-42b3-bcc4-6635bea63008/First+ESP+Install.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/74219529-9bff-42b3-bcc4-6635bea63008/First+ESP+Install.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_35846">

<p>Once it is installed, connect it to your Wifi network and you’re ready for the next step.</p>






















</div><div data-test="image-block-inline-outer-wrapper" data-aspect-ratio="56.12968591691996" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_36246">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c95708d8-de14-43ba-9aab-5ca9e695d59a/Install+Wifi.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c95708d8-de14-43ba-9aab-5ca9e695d59a/Install+Wifi.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c95708d8-de14-43ba-9aab-5ca9e695d59a/Install+Wifi.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c95708d8-de14-43ba-9aab-5ca9e695d59a/Install+Wifi.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c95708d8-de14-43ba-9aab-5ca9e695d59a/Install+Wifi.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c95708d8-de14-43ba-9aab-5ca9e695d59a/Install+Wifi.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c95708d8-de14-43ba-9aab-5ca9e695d59a/Install+Wifi.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c95708d8-de14-43ba-9aab-5ca9e695d59a/Install+Wifi.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c95708d8-de14-43ba-9aab-5ca9e695d59a/Install+Wifi.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/c95708d8-de14-43ba-9aab-5ca9e695d59a/Install+Wifi.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_37367">
  <h4>Connect ESPHome to Home Assistant</h4><p>Now pop over to Home Assistant and go to the Add Ons section.  Here you’ll need to install the ESPHome Add On, which acts as the control center for all your ESPHome devices.</p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1693412965287_32126">

<p>If you aren’t using Home Assistant Operating System, you can install the ESPHome control center using Docker.  The ESPHome website has <a href="https://esphome.io/guides/getting_started_command_line.html" target="_blank">all the instructions you need</a>.</p>






















</div><div data-block-type="2" id="block-yui_3_17_2_1_1693412965287_32229">

<p>Once you’ve installed it, go to the ESPHome Add On web interface and hopefully you see the new ESPDevice auto discovered.</p>






















</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_38615">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/35fdae25-d80e-4cb1-9f08-43631f037628/ESP+Device+Detected.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/35fdae25-d80e-4cb1-9f08-43631f037628/ESP+Device+Detected.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/35fdae25-d80e-4cb1-9f08-43631f037628/ESP+Device+Detected.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/35fdae25-d80e-4cb1-9f08-43631f037628/ESP+Device+Detected.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/35fdae25-d80e-4cb1-9f08-43631f037628/ESP+Device+Detected.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/35fdae25-d80e-4cb1-9f08-43631f037628/ESP+Device+Detected.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/35fdae25-d80e-4cb1-9f08-43631f037628/ESP+Device+Detected.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/35fdae25-d80e-4cb1-9f08-43631f037628/ESP+Device+Detected.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/35fdae25-d80e-4cb1-9f08-43631f037628/ESP+Device+Detected.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/35fdae25-d80e-4cb1-9f08-43631f037628/ESP+Device+Detected.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_39774">
  <p>Click the Adopt button, give the device a name, and click Install.  This will make it yours and install the default configuration on it for your Home Assistant.</p><p>You can now start programming the device by adding some configuration to it!</p><h4>Configuring the ESPHome device as a bed sensor</h4><p>You can now click Edit on that device’s card, which should bring up the default configuration for it.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_41367">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5add3652-fe4b-40cb-ba18-9398009afcad/Default+Config.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5add3652-fe4b-40cb-ba18-9398009afcad/Default+Config.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5add3652-fe4b-40cb-ba18-9398009afcad/Default+Config.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5add3652-fe4b-40cb-ba18-9398009afcad/Default+Config.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5add3652-fe4b-40cb-ba18-9398009afcad/Default+Config.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5add3652-fe4b-40cb-ba18-9398009afcad/Default+Config.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5add3652-fe4b-40cb-ba18-9398009afcad/Default+Config.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5add3652-fe4b-40cb-ba18-9398009afcad/Default+Config.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5add3652-fe4b-40cb-ba18-9398009afcad/Default+Config.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5add3652-fe4b-40cb-ba18-9398009afcad/Default+Config.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_42423">
  <p>Scroll to the bottom of the configuration, and add the following lines under the captive_portal: area.</p><pre><code>binary_sensor:</code></pre><pre><code>&nbsp; - platform: gpio</code></pre><pre><code>&nbsp; &nbsp; pin:</code></pre><pre><code>&nbsp; &nbsp; &nbsp; number: 13</code></pre><pre><code>&nbsp; &nbsp; &nbsp; inverted: true</code></pre><pre><code>&nbsp; &nbsp; &nbsp; mode:</code></pre><pre><code>&nbsp; &nbsp; &nbsp; &nbsp; input: true</code></pre><pre><code>&nbsp; &nbsp; &nbsp; &nbsp; pullup: true</code></pre><pre><code>&nbsp; &nbsp; name: Bed Occupancy Sensor</code></pre><pre><code>&nbsp; &nbsp; device_class: occupancy</code></pre><pre><code>&nbsp; &nbsp; filters:</code></pre><pre><code>&nbsp; &nbsp; &nbsp; - delayed_on: 5s</code></pre><pre><code>&nbsp; &nbsp; &nbsp; - delayed_off: 30s</code></pre><p>This creates a new binary sensor using the Pin 13 GPIO port.  If you used a different pin for yours, then you will need to change this value here.</p><p>The <strong>inverted, input </strong>and<strong> pullup </strong>attributes tell ESPHome that you are using a switch that is ON when closed.  I’m not 100% familiar with the specifics of this as I’m still learning, but it is all <a href="https://esphome.io/components/binary_sensor/gpio.html" target="_blank">documented right here</a> on the ESPHome documentation page.</p><p>The name attribute should be pretty obvious, it’s the name that you have given your sensor and what will be listed in Home Assistant.  </p><p>The device class tells Home Assistant that this is an occupancy sensor.  You can make contact sensors, motion sensors, leak sensors, any number of things really.</p><p>Finally, the filters helped me make these sensors more accurate and useful.  </p><p>The delayed_on attribute means that the sensor won’t trigger as ON until pressure has been applied to the mat for at least 5 seconds.  The delayed_off attribute means that the sensor won’t be triggered as OFF until someone has gotten out of bed for at least 30 seconds.</p><p>Without these values I saw the sensor flip flopping between on and off all night as I rolled around in the bed asleep, and adding the values made it much more consistent and accurate.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_53003">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5d1e9065-0c66-4ba5-a29e-3c58498731c2/Accuracy.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5d1e9065-0c66-4ba5-a29e-3c58498731c2/Accuracy.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5d1e9065-0c66-4ba5-a29e-3c58498731c2/Accuracy.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5d1e9065-0c66-4ba5-a29e-3c58498731c2/Accuracy.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5d1e9065-0c66-4ba5-a29e-3c58498731c2/Accuracy.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5d1e9065-0c66-4ba5-a29e-3c58498731c2/Accuracy.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5d1e9065-0c66-4ba5-a29e-3c58498731c2/Accuracy.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5d1e9065-0c66-4ba5-a29e-3c58498731c2/Accuracy.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5d1e9065-0c66-4ba5-a29e-3c58498731c2/Accuracy.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/5d1e9065-0c66-4ba5-a29e-3c58498731c2/Accuracy.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_54117">
  <p>Now click Save and Install in the top right of that screen to push these new sensor changes to the ESP device over the Wifi.</p><p>Once it’s done you should see in the logs screen that the sensor is online and ready.  If we now push down on the mat for more than 5 seconds, you should see the binary sensor flipping to ON in the logs.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-aspect-ratio="56.23100303951368" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_55213">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4e193233-e57c-48f0-a8ae-1a72e7cc0243/Sensor+ON.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4e193233-e57c-48f0-a8ae-1a72e7cc0243/Sensor+ON.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4e193233-e57c-48f0-a8ae-1a72e7cc0243/Sensor+ON.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4e193233-e57c-48f0-a8ae-1a72e7cc0243/Sensor+ON.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4e193233-e57c-48f0-a8ae-1a72e7cc0243/Sensor+ON.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4e193233-e57c-48f0-a8ae-1a72e7cc0243/Sensor+ON.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4e193233-e57c-48f0-a8ae-1a72e7cc0243/Sensor+ON.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4e193233-e57c-48f0-a8ae-1a72e7cc0243/Sensor+ON.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4e193233-e57c-48f0-a8ae-1a72e7cc0243/Sensor+ON.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/4e193233-e57c-48f0-a8ae-1a72e7cc0243/Sensor+ON.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_56363">

<p>When you then lift off the sensor for more than 30 seconds, the logs should reflect this by telling you the sensor is OFF.</p>






















</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_56799">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/a6e38c83-2948-471a-97df-3ae266490174/Sensor+Off.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/a6e38c83-2948-471a-97df-3ae266490174/Sensor+Off.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/a6e38c83-2948-471a-97df-3ae266490174/Sensor+Off.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/a6e38c83-2948-471a-97df-3ae266490174/Sensor+Off.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/a6e38c83-2948-471a-97df-3ae266490174/Sensor+Off.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/a6e38c83-2948-471a-97df-3ae266490174/Sensor+Off.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/a6e38c83-2948-471a-97df-3ae266490174/Sensor+Off.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/a6e38c83-2948-471a-97df-3ae266490174/Sensor+Off.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/a6e38c83-2948-471a-97df-3ae266490174/Sensor+Off.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/a6e38c83-2948-471a-97df-3ae266490174/Sensor+Off.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_57743">

<p>This sensor should also now have been autodiscovered in your integrations section, and if you add it to Home Assistant you should see these same states update in that entity when you press down and release the pad for the required time.</p>






















</div><div data-test="image-block-inline-outer-wrapper" data-aspect-ratio="56.23100303951368" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_58133">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/6e16a254-072b-45f7-88b2-04fdd65c3b63/HA+Sensor.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/6e16a254-072b-45f7-88b2-04fdd65c3b63/HA+Sensor.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/6e16a254-072b-45f7-88b2-04fdd65c3b63/HA+Sensor.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/6e16a254-072b-45f7-88b2-04fdd65c3b63/HA+Sensor.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/6e16a254-072b-45f7-88b2-04fdd65c3b63/HA+Sensor.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/6e16a254-072b-45f7-88b2-04fdd65c3b63/HA+Sensor.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/6e16a254-072b-45f7-88b2-04fdd65c3b63/HA+Sensor.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/6e16a254-072b-45f7-88b2-04fdd65c3b63/HA+Sensor.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/6e16a254-072b-45f7-88b2-04fdd65c3b63/HA+Sensor.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/6e16a254-072b-45f7-88b2-04fdd65c3b63/HA+Sensor.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_61450">
  <p>Congratulations! You’ve built an ESPHome Bed Sensor!</p><p>The best part about using these ESP devices is that you can now connect a second pressure sensor to the same GND port, and the other wire to GPIO port 12, and create a two zone bed sensor - one for each side of the bed.  Just go to the ESPHome control panel, edit the config of that device, and copy and paste the configuration from the first sensor and paste it below.  You’ll need to give them both unique names, and modify the config to make sure you’re using the correct pins, but everything else should be the same.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_63094">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/af2b9dc7-aa41-4114-83d9-0fffe3798fa8/Double+Sensor.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/af2b9dc7-aa41-4114-83d9-0fffe3798fa8/Double+Sensor.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/af2b9dc7-aa41-4114-83d9-0fffe3798fa8/Double+Sensor.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/af2b9dc7-aa41-4114-83d9-0fffe3798fa8/Double+Sensor.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/af2b9dc7-aa41-4114-83d9-0fffe3798fa8/Double+Sensor.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/af2b9dc7-aa41-4114-83d9-0fffe3798fa8/Double+Sensor.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/af2b9dc7-aa41-4114-83d9-0fffe3798fa8/Double+Sensor.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/af2b9dc7-aa41-4114-83d9-0fffe3798fa8/Double+Sensor.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/af2b9dc7-aa41-4114-83d9-0fffe3798fa8/Double+Sensor.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/af2b9dc7-aa41-4114-83d9-0fffe3798fa8/Double+Sensor.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_64208">

<p>Save and re-install this configuration and you should see two bed sensors entities inside that ESPDevice in Home Assistant.</p>






















</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_64735">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/16f3178a-fe85-4642-a25d-9bf96cbeb7f7/Two+sensors+in+HA.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/16f3178a-fe85-4642-a25d-9bf96cbeb7f7/Two+sensors+in+HA.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/16f3178a-fe85-4642-a25d-9bf96cbeb7f7/Two+sensors+in+HA.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/16f3178a-fe85-4642-a25d-9bf96cbeb7f7/Two+sensors+in+HA.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/16f3178a-fe85-4642-a25d-9bf96cbeb7f7/Two+sensors+in+HA.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/16f3178a-fe85-4642-a25d-9bf96cbeb7f7/Two+sensors+in+HA.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/16f3178a-fe85-4642-a25d-9bf96cbeb7f7/Two+sensors+in+HA.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/16f3178a-fe85-4642-a25d-9bf96cbeb7f7/Two+sensors+in+HA.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/16f3178a-fe85-4642-a25d-9bf96cbeb7f7/Two+sensors+in+HA.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/16f3178a-fe85-4642-a25d-9bf96cbeb7f7/Two+sensors+in+HA.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_65717">
  <h3>Combining two bed sensors into one</h3><p>In my house I’m using two pads connected into the same ESP device to create two independent bed sensors in Home Assistant.  My partner and I have our own sides of the bed that we sleep on each night, and I combine these two bed sensors into two more sensors for use in my automations.  This same theory can be used if you create two independent bed sensors out of two Aqara leak detectors.</p><p>One sensor is called <strong>Main Bed Occupied</strong> and the other is <strong>Both in Bed.</strong></p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_67055">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/b391f79f-c9e2-4157-bfb9-1bee7bacde28/Sensors+in+HA.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/b391f79f-c9e2-4157-bfb9-1bee7bacde28/Sensors+in+HA.jpg" data-image-dimensions="3840x2160" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/b391f79f-c9e2-4157-bfb9-1bee7bacde28/Sensors+in+HA.jpg" width="3840" height="2160" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/b391f79f-c9e2-4157-bfb9-1bee7bacde28/Sensors+in+HA.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/b391f79f-c9e2-4157-bfb9-1bee7bacde28/Sensors+in+HA.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/b391f79f-c9e2-4157-bfb9-1bee7bacde28/Sensors+in+HA.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/b391f79f-c9e2-4157-bfb9-1bee7bacde28/Sensors+in+HA.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/b391f79f-c9e2-4157-bfb9-1bee7bacde28/Sensors+in+HA.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/b391f79f-c9e2-4157-bfb9-1bee7bacde28/Sensors+in+HA.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/b391f79f-c9e2-4157-bfb9-1bee7bacde28/Sensors+in+HA.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_68246">
  <p>The Main Bed Occupied sensor tells Home Assistant if SOMEONE is in bed.  I use this in certain automations, for example as a condition in my Automated Lights automation to make sure that the ceiling lights don’t turn on when someone is having a sleep.</p><p>This is a Home Assistant <a href="https://www.home-assistant.io/integrations/group/" target="_blank">binary sensor group helper</a> that has both my bed sensors as group members.  I then make sure that the All Entities toggle at the bottom is OFF.  This will make the sensor turn ON if any ONE of the bed sensors turns to ON.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_69375">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/afae9954-97bf-483a-b8a6-c555e3353f3b/Main+Bed+Occupied.png" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/afae9954-97bf-483a-b8a6-c555e3353f3b/Main+Bed+Occupied.png" data-image-dimensions="892x1130" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/afae9954-97bf-483a-b8a6-c555e3353f3b/Main+Bed+Occupied.png" width="892" height="1130" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/afae9954-97bf-483a-b8a6-c555e3353f3b/Main+Bed+Occupied.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/afae9954-97bf-483a-b8a6-c555e3353f3b/Main+Bed+Occupied.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/afae9954-97bf-483a-b8a6-c555e3353f3b/Main+Bed+Occupied.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/afae9954-97bf-483a-b8a6-c555e3353f3b/Main+Bed+Occupied.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/afae9954-97bf-483a-b8a6-c555e3353f3b/Main+Bed+Occupied.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/afae9954-97bf-483a-b8a6-c555e3353f3b/Main+Bed+Occupied.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/afae9954-97bf-483a-b8a6-c555e3353f3b/Main+Bed+Occupied.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1693407040632_70318">
  <p>The Both in Bed sensor is turned on when both bed sensors are triggered.  This is usually because we’ve both gone to bed in the evening.  I use this sensor to automatically turn on Night Mode for our house, which powers down all my smart plugs, sonos devices, our work desks, the TV cabinet, and it arms our home alarm into Night mode</p><p>This is also a Home Assistant Group sensor, and is almost identical to the previous one - with one exception - the All Entities Toggle is set to ON.  This means that ALL the bed sensors need to be triggered to on before the helper group gets set to ON.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1693407040632_71159">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be9a00e8-03cb-4081-abac-e73d66b1cdab/Both+in+Bed.png" data-image="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be9a00e8-03cb-4081-abac-e73d66b1cdab/Both+in+Bed.png" data-image-dimensions="862x1129" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be9a00e8-03cb-4081-abac-e73d66b1cdab/Both+in+Bed.png" width="862" height="1129" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be9a00e8-03cb-4081-abac-e73d66b1cdab/Both+in+Bed.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be9a00e8-03cb-4081-abac-e73d66b1cdab/Both+in+Bed.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be9a00e8-03cb-4081-abac-e73d66b1cdab/Both+in+Bed.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be9a00e8-03cb-4081-abac-e73d66b1cdab/Both+in+Bed.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be9a00e8-03cb-4081-abac-e73d66b1cdab/Both+in+Bed.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be9a00e8-03cb-4081-abac-e73d66b1cdab/Both+in+Bed.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6403432da91078458f6aeec2/be9a00e8-03cb-4081-abac-e73d66b1cdab/Both+in+Bed.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div></div>
  
</article>

</div>

  
</article>


          

          
            
              

            
          
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My cat water fountain comes with a spicy USB power adapter (285 pts)]]></title>
            <link>https://ounapuu.ee/posts/2023/12/19/spicy-usb-adapter/</link>
            <guid>38694549</guid>
            <pubDate>Tue, 19 Dec 2023 12:03:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ounapuu.ee/posts/2023/12/19/spicy-usb-adapter/">https://ounapuu.ee/posts/2023/12/19/spicy-usb-adapter/</a>, See on <a href="https://news.ycombinator.com/item?id=38694549">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <p>It turns out that you can’t trust any USB type A power adapter to be within spec.</p>







  




<figure>
    
    <a href="https://ounapuu.ee/posts/2023/12/19/spicy-usb-adapter/media/cover.jpg">
        <img src="https://ounapuu.ee/posts/2023/12/19/spicy-usb-adapter/media/cover_hu274ae1922594f3b973c5b875085287a1_706710_800x0_resize_q80_box.jpg" width="800" height="375" alt="image">
    </a>
	
</figure>

<p>I have a <a href="https://www.catit.com/products/drinking-fountains/flower-fountain/">Catit Flower Fountain</a>
for my two adorable cats. The idea of a water fountain for cats may sound odd,
but having one really helps with cats staying hydrated and that alone avoids all
sorts of health issues.</p>
<p>At one point I wanted to see if I could create a sort of a DIY UPS for the
water fountain. It would be quite bad if I was at work and a power outage results
in cats not being able to drink water (they don’t really care for normal water
bowls after getting the fountain). I had some battery banks available for testing,
and I noticed that the pump for the water fountain is powered over a USB type A cable.</p>
<p>Should be easy, right?</p>
<p>Apparently not.</p>
<p>I tried multiple different power banks between the water fountain and the
USB power adapter that came with it, and all of them would work for a bit
and turn off after some time. I didn’t think much of it back then, but I did
notice that two of the power banks I used started glitching out during
normal use elsewhere.</p>
<p>Months later, I attached an IKEA power strip to the side of my work desk
to make charging various things easier. It also has two USB type A ports and the
water fountain was near the desk temporarily, so I plugged it in there. It worked,
but I noticed that the water fountain was quieter now, the “hum” that it makes
was almost gone. That made me curious, so I used the original adapter again
and the “hum” was there again.</p>
<p>I took a look at the original power adapter specs to see if there’s a difference
in the amount of current that these two different USB power sources provide.
What I discovered instead was that the power adapter that comes with the fountain
outputs a solid <em><strong>7.5V</strong></em>. USB type A ports typically provide about 5V, with a maximum
of 5.25V from my observations in the real world.</p>







  




<figure>
    
    <a href="https://ounapuu.ee/posts/2023/12/19/spicy-usb-adapter/media/image0.jpg">
        <img src="https://ounapuu.ee/posts/2023/12/19/spicy-usb-adapter/media/image0_hu274ae1922594f3b973c5b875085287a1_176314_800x0_resize_q80_box.jpg" width="800" height="499" alt="Yikes.">
    </a>
    <figcaption>
      Yikes.
    </figcaption>
    
</figure>

<p>7.5V over USB type A is <em>probably</em> not safe with other devices, especially since a normal person
only sees a USB port on the adapter and thinks that it is perfectly safe to use
it to charge their phone or other devices. Yes, properly implemented USB type <em><strong>C</strong></em>
ports can negotiate all sorts of voltages, but this is not one of them.</p>
<p>Probably explains why my power banks are acting odd now and glitching out.</p>
<p>This is why I have trust issues.</p>
<h3 id="2023-12-19-update">2023-12-19 update</h3>
<p>By popular demand, here are the two adorable cats.</p>







  




<figure>
    
    <a href="https://ounapuu.ee/posts/2023/12/19/spicy-usb-adapter/media/cats.jpg">
        <img src="https://ounapuu.ee/posts/2023/12/19/spicy-usb-adapter/media/cats_hu380fbf338ff34647e66732a5f1fb677a_1888448_800x0_resize_q80_box.jpg" width="800" height="600" alt="Tux and Põssa. Põssa can be roughly translated to &quot;Piggy&quot; in English. I'll let you guess how he got that name.">
    </a>
    <figcaption>
      Tux and Põssa. Põssa can be roughly translated to "Piggy" in English. I'll let you guess how he got that name.
    </figcaption>
    
</figure>


<p>If you’re not a spammer,
<a href="mailto:ihavesomethoughtsonyourblog@ounapuu.ee">just send me an e-mail!</a></p>
<p>Places where you can discuss this post:</p>
<ul>
<li>
<p><a href="https://news.ycombinator.com/item?id=38694549">Hacker News</a></p>
</li>
<li>
<p><a href="https://www.linkedin.com/posts/%F0%9F%94%A5-herman-%C3%B5unapuu-600516152_my-cat-water-fountain-comes-with-a-spicy-activity-7142846707364528128-Jt7U">LinkedIn</a></p>
</li>
</ul>

    </div></div>]]></description>
        </item>
    </channel>
</rss>