(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 29 Jan 2026 19:30:12 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Tesla is committing automotive suicide (118 pts)]]></title>
            <link>https://electrek.co/2026/01/29/tesla-committing-automotive-suicide/</link>
            <guid>46814089</guid>
            <pubDate>Thu, 29 Jan 2026 18:16:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2026/01/29/tesla-committing-automotive-suicide/">https://electrek.co/2026/01/29/tesla-committing-automotive-suicide/</a>, See on <a href="https://news.ycombinator.com/item?id=46814089">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>

	<img width="1600" height="788" src="https://electrek.co/wp-content/uploads/sites/3/2026/01/Tesla-automotive-suicide.jpg?quality=82&amp;strip=all&amp;w=1600" alt="Tesla automotive suicide" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2026/01/Tesla-automotive-suicide.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2026/01/Tesla-automotive-suicide.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2026/01/Tesla-automotive-suicide.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2026/01/Tesla-automotive-suicide.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high">
	</figure>

<p>Tesla’s Q4 2025 earnings call made one thing painfully clear: the company is no longer interested in being an automaker.</p>



<p>In a single call, Tesla announced it’s killing the Model S and Model X, has no plans for new mass-market models, and is pivoting entirely to “transportation as a service.” The company that revolutionized the auto industry is walking away from it, not because it failed, but because Elon Musk got bored and found new toys.</p>



<h2 id="h-what-happened-to-tesla-today">What happened to Tesla today</h2>



<p>When asked if Tesla has plans to launch new models to address different price segments, VP of Vehicle Engineering Lars Moravy gave a telling response:</p>



<blockquote>
<p>“You have to start thinking about us as moving to providing <strong>transportation as a service</strong> more than the total addressable market for the purchased vehicles alone..”</p>
</blockquote>



<p>Read that again. Tesla’s head of vehicle engineering is telling you to stop thinking of Tesla as a company that sells cars.</p>	
	



<p>Musk doubled down:</p>



<blockquote>
<p>“I really think long-term, the only vehicles that we’ll make will be autonomous vehicles.”</p>
</blockquote>



<p>He predicted that “probably less than 5% of miles driven will be where somebody’s actually driving the car themselves in the future, maybe as low as 1%.”</p>



<p>And then came the killing blow: Model S and Model X production ends next quarter. The Fremont line will be converted to manufacture Optimus robots instead.</p>



<p>Finally, in its latest 10k SEC filing, Tesla officially updated its mission to “building a world of amazing abundance” – whatever that means.</p>



<h2 id="h-what-tesla-is-left-with">What Tesla is left with</h2>



<p>Let’s count Tesla’s current vehicle lineup:</p>



<ul>
<li><strong>Model 3</strong> — Successful (but in decline)</li>



<li><strong>Model Y</strong> — Successful (but in decline)</li>



<li><strong>Model S</strong> — Being killed</li>



<li><strong>Model X</strong> — Being killed</li>



<li><strong>Cybertruck</strong> — Commercial failure, selling ~20-25k/year against 250k capacity</li>



<li><strong>Tesla Semi</strong> — Still not in volume production after years of delays</li>
</ul>



<p>That leaves Tesla with exactly two successful vehicle models. Two. And there are both in decline.</p>



<p>And instead of building on that success, expanding into new segments, addressing affordability, competing with the flood of new EVs from legacy automakers and Chinese competitors, Tesla is walking away.</p>



<p>The $25,000 Tesla that Musk promised for years? Scrapped.</p>



<p>New models to compete with the likes of the Hyundai, Lucid, Rivian, or the wave of affordable Chinese EVs? Not coming.</p>



<p>Tesla’s answer to everything is now the same: wait for robotaxis.</p>



<h2 id="h-the-false-choice">The false choice</h2>



<p>Here’s what makes this so frustrating: Tesla didn’t have to choose.</p>



<p>The company could have spun off its AI and robotics efforts into a separate entity, call it Tesla AI or whatever, while keeping Tesla, the automaker, focused on what it does best: building and selling great electric vehicles and accelerating the industry’s transition to electric transport.</p>



<p>Or it could have done the reverse: spin off the automotive business and let Musk pursue his AI dreams with the parent company. Either way, there was no point in letting great EV programs die.</p>



<p>Tesla could have continued to invest in electric vehicles, leverage its expertise in batteries and power electronics, to accelerate EV adoption and stationary energy storage deployment, and could have licensed “Tesla AI’s” technology to integrate it into its vehicles.</p>



<p>Instead, Tesla is letting a highly successful automaker wither so it can chase autonomous robots and robotaxis that may or may not work, may or may not get regulatory approval, and may or may not find a market.</p>



<p>This is a company that delivered 1.6 million vehicles last year. That has a global Supercharger network. That has brand recognition any automaker would kill for (up until last year). And it’s being sacrificed on the altar of Musk’s next obsession.</p>



<h2 id="h-the-numbers-don-t-lie">The numbers don’t lie</h2>



<p>Tesla’s automotive revenue declined 10% in 2025. Deliveries fell 9%. The company lost its crown as the world’s largest EV maker to BYD.</p>



<p>The response to these problems? Not to fix them by giving more love to its EV programs, but to abandon the business entirely.</p>



<p>Instead of killing Model S and Model X, Tesla could have brought the good things it did with the Cybertruck, such as drive-by-wire and its 800V powertrain, to its programs, but it didn’t bother.</p>



<p>Meanwhile, the “future” Tesla is betting on looks like this:</p>



<ul>
<li><strong>Robotaxi fleet:</strong> About 30-60 vehicles actually operating in Austin, despite claims of “well over 500”</li>



<li><strong>Optimus robots:</strong> Zero doing useful work in factories, by Musk’s own admission</li>



<li><strong>CyberCab:</strong> About to go into production without a steering wheel while Tesla still hasn’t solved autonom</li>
</ul>



<p>Tesla is abandoning a business that generated $80 billion in automotive revenue and almost $15 billion in profits at its peak for ventures that currently generate essentially nothing.</p>



<p>During the earnings call, the company announced it will spend a record $20 billion in capital expenditure in 2026, and most of it will go into its robotaxi and humanoid robots, as well as their supporting infrastructure, especially training compute.</p>



<p>Meanwhile, Tesla generated less than $6 billion in net income (non-GAAP) in 2025 – down 26% from last year and more than 50% from its peak a few years ago.</p>



<h2 id="h-electrek-s-take">Electrek’s Take</h2>



<p>I’ve covered Tesla for over a decade. I watched this company prove that electric vehicles could be desirable, that they could be profitable, that they could compete with and beat the best that legacy automakers had to offer.</p>



<p>And now I’m watching it commit suicide.</p>



<p>There’s a version of this story where Tesla remains the dominant EV maker while also pursuing AI and autonomy. Where the company launches affordable models to compete with Chinese EVs. Where it expands into new segments. Where it uses its manufacturing expertise and brand power to actually grow its automotive business, and push the industry forward in the process, especially in the US, where automakers are falling behind the rest of the world.</p>




	<p>Instead, we get Lars Moravy telling us to think of Tesla as a “transportation as a service” company. We get Musk saying the only vehicles Tesla will make are autonomous ones. We get the Model S and X killed to make room for robots that don’t work yet.</p>



<p>Tesla could have had both. It chose to have one, and that could lead to neither.</p>



<p>This is Musk joining the popular “as a service” trend of the elite, who don’t want people to own anything and instead have them “subscribe” to as many things as possible. It’s a depressing future. </p>



<p>RIP Tesla the automaker. You didn’t have to die.</p>
	<p><a target="_blank" rel="nofollow" href="https://google.com/preferences/source?q=https://electrek.co" aria-label="Add Electrek as a preferred source on Google">
			<img decoding="async" src="https://electrek.co/wp-content/themes/ninetofive/dist/images/google-preferred-source-badge-dark.png" alt="Add Electrek as a preferred source on Google">
			<img decoding="async" src="https://electrek.co/wp-content/themes/ninetofive/dist/images/google-preferred-source-badge-light.png" alt="Add Electrek as a preferred source on Google">
		</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Project Genie: Experimenting with infinite, interactive worlds (154 pts)]]></title>
            <link>https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/</link>
            <guid>46812933</guid>
            <pubDate>Thu, 29 Jan 2026 17:02:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/">https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/</a>, See on <a href="https://news.ycombinator.com/item?id=46812933">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="jump-content" tabindex="-1">
            
    
    

    <article>

    
    





    

    
      








<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;Project Genie: Experimenting with infinite, interactive worlds&quot;
  }">
  
  <div>
      
      
        <p>
          Google AI Ultra subscribers in the U.S. can try out Project Genie, an experimental research prototype that lets you create and explore worlds.
        </p>
      
    </div>
  
  <div>
    <div>
      
        


  
  
    
  

  
  
    <div>
  <p>Elliott Breece</p>
  
    <p>
      Product Manager, Google Labs
    </p>
  
  
</div>
  

  
  
    <div>
  <p>Suz Chambers</p>
  
    <p>
      Director, Google Creative Lab
    </p>
  
  
</div>
  


      

      
      
    </div>
    
      
        


<div data-component="uni-ai-generated-summary" data-analytics-module="{
    &quot;event&quot;: &quot;module_impression&quot;,
    &quot;module_name&quot;: &quot;ai_summary&quot;,
    &quot;section_header&quot;: &quot;CTA&quot;
  }">
      
        <div data-summary-id="ai_summary_1">
          <h2>General summary</h2>
          <p>Google is rolling out Project Genie to Google AI Ultra subscribers in the U.S. Project Genie is a research prototype that lets you create, explore and remix interactive worlds. You can use text prompts and images to build environments and navigate them in real time.</p>
          
          <p><small>
            Summaries were generated by Google AI. Generative AI is experimental.
          </small>
        </p></div>
      
        <div data-summary-id="ai_summary_2">
          <h2>Bullet points</h2>
          <ul>
<li>"Project Genie" lets Google AI Ultra users create, explore, and remix interactive worlds.</li>
<li>Genie 3 powers the prototype, generating real-time paths as you move and interact.</li>
<li>Users can sketch worlds with text/images, explore them, and remix existing creations.</li>
<li>The prototype has limitations, like world realism and character control, but is improving.</li>
<li>Google aims to expand access to Project Genie and its world-building tech in time.</li>
</ul>
          
          <p><small>
            Summaries were generated by Google AI. Generative AI is experimental.
          </small>
        </p></div>
      

      
      <div>
        <h4>
          Explore other styles:
        </h4>
        
      </div>
      

      </div>

      
    
    
  </div>
</div>

    

    
      




  <uni-youtube-player-hero index="0" thumbnail-alt="Text reads Introducing Project Genie" component-title="Project Genie: Experimenting with infinite, interactive worlds" video-id="YxkGdX4WIBE" video-type="video" image="genie-3__project-genie__hero-film_keyword-hero_2096-1182" video-image-url-lazy="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/genie-3__project-genie__hero-film.width-100.format-webp.webp" video-image-url-mobile="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/genie-3__project-genie__hero-film.width-700.format-webp.webp" video-image-url-desktop="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/genie-3__project-genie__hero-fil.width-1000.format-webp.webp">
  </uni-youtube-player-hero>











    

    
    <div data-reading-time="true" data-component="uni-article-body">

            
  
    



















<div data-component="uni-audio-player-tts" uni-l10n="{
       &quot;stop&quot;: &quot;Click to stop audio&quot;,
       &quot;play&quot;: &quot;Click to play audio&quot;,
       &quot;progress&quot;: &quot;Current audio progress minutes with seconds: [[progress]]&quot;,
       &quot;duration&quot;: &quot;Duration of the audio minutes with seconds: [[duration]]&quot;,
       &quot;settings&quot;: &quot;Click for settings&quot;,
       &quot;timeText&quot;: &quot;[[duration]] minutes&quot;
     }" data-analytics-module="{
      &quot;module_name&quot;: &quot;Audio TTS&quot;,
      &quot;section_header&quot;: &quot;Project Genie: Experimenting with infinite, interactive worlds&quot;
     }" data-tts-audios="[
      
        {&quot;voice_name&quot;: &quot;Umbriel&quot;,
        &quot;voice_source&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_83208_umbriel_2026_01_29_18_13_56.wav&quot;,
        &quot;mimetype&quot;: &quot;audio/x-wav&quot;},
      
        {&quot;voice_name&quot;: &quot;Gacrux&quot;,
        &quot;voice_source&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_83208_gacrux_2026_01_29_18_14_14.wav&quot;,
        &quot;mimetype&quot;: &quot;audio/x-wav&quot;}
      ]">
  <p><audio title="Project Genie: Experimenting with infinite, interactive worlds">
      <source src="https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/self.ttsaudio_set.first.tts_audio.url" type="self.ttsaudio_set.first.tts_audio.file.file.mime_type">
      <p>Your browser does not support the audio element.</p>
  </audio></p><div aria-label="">
        <p><span>
          Listen to article
          <span tabindex="0" role="tooltip" aria-label="This content is generated by Google AI. Generative AI is experimental">
            <p>This content is generated by Google AI. Generative AI is experimental</p>
            <svg>
  <use xmlns:xlink="http://www.w3.org/1999/xlink" href="/static/blogv2/images/icons.svg?version=pr20260120-1609#ttf-info"></use>
</svg>

          </span>
        </span></p><p>[[duration]] minutes</p>
      </div>
</div>

  





            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Project Genie: Experimenting with infinite, interactive worlds&quot;
         }"><p data-block-key="njin4">In August, we <a href="https://deepmind.google/blog/genie-3-a-new-frontier-for-world-models/">previewed Genie 3</a>, a general-purpose world model capable of generating diverse, interactive environments. Even in this early form, trusted testers were able to create an impressive range of fascinating worlds and experiences, and uncovered entirely new ways to use it. The next step is to broaden access through a dedicated, interactive prototype focused on immersive world creation.</p><p data-block-key="eq11k">Starting today, we're rolling out access to <a href="http://labs.google/projectgenie/">Project Genie</a> for Google AI Ultra subscribers in the U.S (18+). This experimental research prototype lets users create, explore and remix their own interactive worlds.</p><h2 data-block-key="c7s4e">How we’re advancing world models</h2><p data-block-key="bba0a">A world model simulates the dynamics of an environment, predicting how they evolve and how actions affect them. While Google DeepMind has a history of agents for specific environments like <a href="https://deepmind.google/research/alphazero-and-muzero/">Chess</a> or <a href="https://deepmind.google/research/alphago/?_gl=1*1rofsan*_up*MQ..*_ga*MTU2MTkwNzU1Ni4xNzY5Mzc1ODQz*_ga_LS8HVHCNQ0*czE3NjkzNzU4NDMkbzEkZzAkdDE3NjkzNzU4NDMkajYwJGwwJGgw">Go</a>, building AGI requires systems that navigate the diversity of the real world.</p><p data-block-key="3915m">To meet this challenge and support our AGI mission, we developed Genie 3. Unlike explorable experiences in static 3D snapshots, Genie 3 generates the path ahead in real time as you move and interact with the world. It simulates physics and interactions for dynamic worlds, while its breakthrough consistency enables the simulation of any real-world scenario — from robotics and modelling animation and fiction, to exploring locations and historical settings.</p><p data-block-key="an4ns">Building on our model research with trusted testers from across industries and domains, we are taking the next step with an experimental research prototype: Project Genie.</p><h2 data-block-key="3bvh3">How Project Genie works</h2><p data-block-key="2kvmh">Project Genie is a prototype web app powered by Genie 3, <a href="https://deepmind.google/models/gemini-image/pro/">Nano Banana Pro</a> and <a href="http://gemini.google.com/">Gemini</a>, which allows users to experiment with the immersive experiences of our world model firsthand. The experience is centred on three core capabilities:</p></div>
  

  
    
  
    




  <uni-youtube-player-article index="2" thumbnail-alt="Project Genie demo video" video-id="s40a06a5wIc" video-type="video">
  </uni-youtube-player-article>











  


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Project Genie: Experimenting with infinite, interactive worlds&quot;
         }"><h3 data-block-key="wav60">1. World sketching</h3><p data-block-key="51upj">Prompt with text and generated or uploaded images to create a living, expanding environment. Create your character, your world, and define how you want to explore it — from walking to riding, flying to driving, and anything beyond.</p><p data-block-key="6lnm8">For more precise control, we have integrated “World Sketching” with Nano Banana Pro. This allows you to preview what your world will look like and modify your image to fine tune your world prior to jumping in. You can also define your perspective for the character — such as first-person or third-person — giving you control over how you experience the scene before you enter.</p></div>
  

  
    




























<uni-image-full-width alignment="full" alt-text="World exploration in Project Genie" external-image="" or-mp4-video-title="Genie demo Fish" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/2494_Genie_Fish_BlogPost.mp4" section-header="Project Genie: Experimenting with infinite, interactive worlds" custom-class="image-full-width--constrained-width uni-component-spacing" autoplay="true">
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Project Genie: Experimenting with infinite, interactive worlds&quot;
         }"><h3 data-block-key="wav60">2. World exploration</h3><p data-block-key="3nisu">Your world is a navigable environment that’s waiting to be explored. As you move, Project Genie generates the path ahead in real time based on the actions you take. You can also adjust the camera as you traverse through the world.</p><h3 data-block-key="dq1cm">3. World remixing</h3><p data-block-key="8rjm4">Remix existing worlds into new interpretations, by building on top of their prompts. You can also explore curated worlds in the gallery or in the &lt;randomizer icon&gt; for inspiration, or build on top of them. And once you’re done, you can download videos of your worlds and your explorations.</p></div>
  

  
    
  
    




  <uni-youtube-player-article index="6" thumbnail-alt="Project Genie world remixing" video-id="dO0csRgxo_A" video-type="video">
  </uni-youtube-player-article>











  


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Project Genie: Experimenting with infinite, interactive worlds&quot;
         }"><h2 data-block-key="wav60">How we’re building responsibly</h2><p data-block-key="9ambd">Project Genie is an experimental research prototype in Google Labs, powered by Genie 3. As with all our work towards general AI systems, our mission is to build AI responsibly to benefit humanity. Since Genie 3 is an early research model, there are a few known areas for improvement:</p><ul><li data-block-key="b6601">Generated worlds might not look completely true-to-life or always adhere closely to prompts or images, or real-world physics</li><li data-block-key="15ea3">Characters can sometimes be less controllable, or experience higher latency in control</li><li data-block-key="57hli">Limitations in generations to 60 seconds</li></ul><p data-block-key="79r9j">A few of the Genie 3 model capabilities we announced in August, such as promptable events that change the world as you explore it, are not yet included in this prototype. You can find more details on model limitations and future updates on how we’re improving the experience, <a href="http://deepmind.google/genie">here</a>.</p><p data-block-key="4fep2">Building on the work we have been doing with trusted testers, we are excited to share this prototype with users of our most advanced AI to better understand how people will use world models in many areas of both AI research and generative media.</p><p data-block-key="ank4v">Access to Project Genie begins rolling out today to <a href="https://one.google.com/about/google-ai-plans/">Google AI Ultra subscribers</a> in the U.S. (18+), expanding to more territories in due course. We look forward to seeing the infinitely diverse worlds they create, and in time, our goal is to make these experiences and technology accessible to more users.</p></div>
  


            
            

            
              




            
          </div>
  </article>
  





  

  


<div data-component="uni-related-articles" aria-roledescription="carousel" data-analytics-module="{
    &quot;module_name&quot;: &quot;Article Footer Related Stories&quot;,
    &quot;section_header&quot;: &quot;Related stories&quot;
  }">
        <h3>
          <p>
            Related stories
          </p>
        </h3>
      </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US cybersecurity chief leaked sensitive government files to ChatGPT: Report (269 pts)]]></title>
            <link>https://www.dexerto.com/entertainment/us-cybersecurity-chief-leaked-sensitive-government-files-to-chatgpt-report-3311462/</link>
            <guid>46812173</guid>
            <pubDate>Thu, 29 Jan 2026 16:12:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dexerto.com/entertainment/us-cybersecurity-chief-leaked-sensitive-government-files-to-chatgpt-report-3311462/">https://www.dexerto.com/entertainment/us-cybersecurity-chief-leaked-sensitive-government-files-to-chatgpt-report-3311462/</a>, See on <a href="https://news.ycombinator.com/item?id=46812173">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span><img alt="ChatGPT on phone" width="1920" height="1080" decoding="async" data-nimg="1" sizes="(max-width: 1200px) 100vw, 736px" srcset="https://www.dexerto.com/cdn-image/wp-content/uploads/2025/08/28/ChatGPT-suicide-cropped.jpg?width=385&amp;quality=60&amp;format=auto 385w, https://www.dexerto.com/cdn-image/wp-content/uploads/2025/08/28/ChatGPT-suicide-cropped.jpg?width=768&amp;quality=60&amp;format=auto 768w, https://www.dexerto.com/cdn-image/wp-content/uploads/2025/08/28/ChatGPT-suicide-cropped.jpg?width=1200&amp;quality=60&amp;format=auto 1200w" src="https://www.dexerto.com/cdn-image/wp-content/uploads/2025/08/28/ChatGPT-suicide-cropped.jpg?width=1200&amp;quality=60&amp;format=auto"><span>Unsplash</span></span></p><div id="article-1">
<p>The acting head of the US government’s top cybersecurity agency reportedly uploaded sensitive government files into a public version of ChatGPT, triggering internal security alerts and a federal review.</p>



<p>A <a target="_blank" rel="noreferrer noopener nofollow" href="https://www.politico.com/news/2026/01/27/cisa-madhu-gottumukkala-chatgpt-00749361">Politico</a> investigation claims Madhu Gottumukkala, the interim director of the Cybersecurity and Infrastructure Security Agency, uploaded contracting documents marked “For Official Use Only” into ChatGPT last summer.</p>



<p>The report says Gottumukkala requested a special exemption to access ChatGPT, which is blocked for other Department of Homeland Security staff.</p>



<p>Cybersecurity monitoring systems then reportedly flagged the uploads in early August. That triggered a DHS-led damage assessment to determine whether the information had been exposed.</p>


<figure><span id="ImageEnlarge-https://www.dexerto.com/cdn-image/wp-content/uploads/2023/02/01/New-Project-14-1024x576.jpg"><img alt="OpenAI logo on purple background" loading="lazy" width="1024" height="576" decoding="async" data-nimg="1" sizes="auto, (max-width: 1024px) 100vw, 1024px" srcset="https://www.dexerto.com/cdn-image/wp-content/uploads/2023/02/01/New-Project-14-1024x576.jpg?width=385&amp;quality=75&amp;format=auto 385w, https://www.dexerto.com/cdn-image/wp-content/uploads/2023/02/01/New-Project-14-1024x576.jpg?width=768&amp;quality=75&amp;format=auto 768w, https://www.dexerto.com/cdn-image/wp-content/uploads/2023/02/01/New-Project-14-1024x576.jpg?width=1200&amp;quality=75&amp;format=auto 1200w" src="https://www.dexerto.com/cdn-image/wp-content/uploads/2023/02/01/New-Project-14-1024x576.jpg?width=1200&amp;quality=75&amp;format=auto"></span><span>OpenAI</span></figure>


<p>Public versions of ChatGPT share user inputs with OpenAI, which raised concerns inside the federal government about sensitive data leaving internal networks.</p>



<h2 id="h-cisa-responds-to-chatgpt-investigation">CISA responds to ChatGPT investigation</h2>



<p>CISA spokesperson Marci McCarthy told Politico that Gottumukkala “was granted permission to use ChatGPT with DHS controls in place,” adding that the use was “short-term and limited.”</p>



<p>Gottumukkala has served as acting director since May, while the Senate has yet to confirm Sean Plankey as permanent head of the agency.</p>



<p>The ChatGPT incident follows other reported issues during Gottumukkala’s tenure. Politico said he previously failed a counterintelligence polygraph required for access to highly sensitive intelligence. During congressional testimony last week, he rejected that characterization when questioned.</p>



<p>The report lands as the administration of US President Donald Trump continues to push AI adoption across federal agencies.</p>



<p>Trump signed an executive order in <a href="https://www.whitehouse.gov/presidential-actions/2025/12/eliminating-state-law-obstruction-of-national-artificial-intelligence-policy/">December aimed at limiting state-level AI regulation</a>, while the <a target="_blank" rel="noreferrer noopener nofollow" href="http://chrome-extension//efaidnbmnnnibpcajpcglclefindmkaj/https://media.defense.gov/2026/Jan/12/2003855671/-1/-1/0/ARTIFICIAL-INTELLIGENCE-STRATEGY-FOR-THE-DEPARTMENT-OF-WAR.PDF">Pentagon has announced an “AI-first”</a> strategy to expand the military’s use of artificial intelligence.</p><div id="article-note"><h2>Related</h2></div>

</div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OTelBench: AI struggles with simple SRE tasks (Opus 4.5 scores only 29%) (106 pts)]]></title>
            <link>https://quesma.com/blog/introducing-otel-bench/</link>
            <guid>46811588</guid>
            <pubDate>Thu, 29 Jan 2026 15:37:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://quesma.com/blog/introducing-otel-bench/">https://quesma.com/blog/introducing-otel-bench/</a>, See on <a href="https://news.ycombinator.com/item?id=46811588">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-xj2uyz6m="">  <p><strong>Now on the front page of Hacker News — <a href="https://news.ycombinator.com/item?id=46811588">see the discussion</a>.</strong></p>
<p>Frontier AI models have become excellent at writing functions, but can they actually debug production systems?</p>
<p>To fix outages, you first need to see what’s happening. In a microservices world, this means producing structured events that track a single request as it hops from service to service.</p>
<p>We asked 14 models to add distributed traces to existing codebases, using the standard method: OpenTelemetry instrumentation. We picked tasks that would be easy for a Site Reliability Engineer (SRE).</p>
<figure> <a href="https://quesma.com/benchmarks/otel/#models"> <img src="https://quesma.com/_astro/overall_ranking.CkMhOjSp_14CMuY.webp" alt="OTelBench Model Rankings showing Claude Opus 4.5 leading at 29% pass rate" loading="lazy" decoding="async" fetchpriority="auto" width="1400" height="778">  </a> <figcaption> <p>Go to <a href="https://quesma.com/benchmarks/otel/">OTelBench website</a> for complete charts. All models struggle with
OpenTelemetry. Even the best model, Claude 4.5 Opus, succeeded only 29% of the time, and GPT 5.2 was similar at 26%.
Surprisingly, Gemini 3 Pro has no edge over Gemini 3 Flash, which scored 19%.</p> </figcaption> </figure>
<p>We are releasing <a href="https://quesma.com/benchmarks/otel/">OTelBench</a> as an open-source benchmark, with all tasks in <a href="https://github.com/QuesmaOrg/otel-bench">QuesmaOrg/otel-bench</a>. We use the <a href="https://harborframework.com/">Harbor framework</a> (by the creators of TerminalBench), so you can easily run it yourself to reproduce results, test new models, or create benchmarks for your own use cases (we welcome contributions!).</p>
<h2 id="background-what-is-distributed-tracing">Background: What is distributed tracing?</h2>
<p>When an app runs on a single machine, you can often trace an error by scrolling through a log file. But when it runs across 50 microservices, that single request gets scattered into a chaotic firehose of disconnected events. <strong>Distributed tracing</strong> solves this by linking them back together, allowing you to follow a user action, like clicking <em>Login</em>, as it jumps from the API Gateway, to the Auth Service, to the Database, and back.</p>
<figure>  <figcaption>
Distributed tracing links a user action, like a <em>Login</em> button click, to every underlying microservice call.
</figcaption> </figure>
<p>To make this work, you need <strong>instrumentation</strong>. This is code that you add to your app to:</p>
<ol>
<li><strong>Start a trace</strong> when a request comes in.</li>
<li><strong>Pass the TraceID</strong> (context) when your app calls another service.</li>
<li><strong>Send the data</strong> to a backend so you can see the graph.</li>
</ol>
<p><a href="https://opentelemetry.io/">OpenTelemetry</a> (OTel) is the industry standard for telemetry data. Its ecosystem includes:</p>
<ul>
<li><strong>Semantic conventions:</strong> A unified schema replaces chaotic naming (e.g., <code>ip_address</code> vs <code>host.ip</code>).</li>
<li><strong>Universal SDKs:</strong> Official libraries support every major programming language.</li>
<li><strong>The Collector:</strong> A centralized agent processes and enriches data (e.g., adding Kubernetes tags) before export.</li>
<li><strong>Auto-instrumentation:</strong> Runtime agents <a href="https://newsletter.signoz.io/p/bts-of-opentelemetry-auto-instrumentation">inject code to wrap calls</a>, though this often results in noisy data.</li>
</ul>
<p>However, <strong>standard</strong> doesn’t mean <strong>easy</strong>. We know this firsthand from our contributions to the ecosystem, such as <a href="https://opentelemetry.io/blog/2025/go-compile-time-instrumentation/">Go compile-time instrumentation</a>. The process may be difficult, especially due to complexity, <a href="https://grafana.com/observability-survey/2025/">as 39% of respondents complained in the 2025 Observability Survey</a>.</p>
<h2 id="benchmarking-opentelemetry-instrumentation">Benchmarking OpenTelemetry instrumentation</h2>
<p>We tested 14 frontier LLMs on 23 realistic OpenTelemetry instrumentation tasks across 11 programming languages: Go, Java, C++, Python, JavaScript, PHP, Ruby, Rust, Erlang, .NET, and Swift.</p>
<p>It is essential to benchmark various technologies since realistic distributed systems are polyglot.
To make OpenTelemetry work, the system needs to work for all of these services - if we lose track at only one service, the chain of logs gets broken.</p>
<p>The final benchmark run cost $522 in LLM tokens across 966 runs (23 tasks × 3 attempts × 14 models).</p>
<h3 id="task">Task</h3>
<p>We start with basic tasks such as adding instrumentation to a single microservice, in a single language.
The AI agents get a small microservice with around 300 lines of code from a realistic application, and work in a Linux terminal, editing it, and running any commands if needed.</p>
<p>For example, here is the prompt for <a href="https://quesma.com/benchmarks/otel/tasks/go-microservices-traces/">go-microservices-traces</a>:</p>
<blockquote>
<p><strong>Your task is:</strong> Add OTEL tracing to all microservices.</p>
<p><strong>Requirements:</strong></p>
<ol>
<li>Instrumentation should match conventions and well-known good practices.</li>
<li>Instrumentation must match the business domain of the microservices.</li>
<li>Traces must be sent to the endpoint defined by a standard OTEL environment variable.</li>
<li>Use the recent version of the OTEL SDK.</li>
</ol>
</blockquote>
<p>We tested if it satisfies the basic criteria of OpenTelemetry instrumentation.</p>
<figure> <a href="https://quesma.com/benchmarks/otel/#tasks"> <img src="https://quesma.com/_astro/simple_tasks.DRjEgaqU_ZmHRE2.webp" alt="Pass rates for simple instrumentation tasks across different programming languages" loading="lazy" decoding="async" fetchpriority="auto" width="1776" height="422">  </a> <figcaption> <p>See <a href="https://quesma.com/benchmarks/otel/#tasks">full task breakdown</a>. All tasks were simple for humans and involved
short services of around 300 lines of code. Yet, many of them were hard or unsolvable by all AI models.</p> </figcaption> </figure>
<h3 id="example">Example</h3>
<p>How do LLMs fail? Let’s analyze a common failure mode.</p>
<p>Consider a web service from our benchmark where a user searches and retrieves results. The test simulates <strong>two distinct user actions</strong>:</p>
<ol>
<li><strong>Happy path</strong>: User searches, gets a token, retrieves results successfully</li>
<li><strong>Error test</strong>: User tries to retrieve results with an invalid token (gets 404)</li>
</ol>
<p>A human engineer would immediately distinguish these as <strong>two independent events</strong>, resulting in <strong>two separate traces</strong>: one for the successful search and one for the failed request.</p>
<p>The code structure makes this clear – two separate blocks, each representing a user action:</p>
<pre tabindex="0" data-language="go"><code><span><span>// User Action 1: Search and get results (happy path)</span></span>
<span><span>{</span></span>
<span><span>    response </span><span>:=</span><span> client.</span><span>Post</span><span>(</span><span>"/search"</span><span>, query)</span></span>
<span><span>    result </span><span>:=</span><span> client.</span><span>Get</span><span>(</span><span>"/result?token="</span><span> +</span><span> response.Token)</span></span>
<span><span>}</span></span>
<span></span>
<span><span>// User Action 2: Error test (invalid token)</span></span>
<span><span>{</span></span>
<span><span>    result </span><span>:=</span><span> client.</span><span>Get</span><span>(</span><span>"/result?token=invalid"</span><span>)  </span><span>// Should return 404</span></span>
<span><span>}</span></span></code></pre>
<p>We would expect:</p>
<figure>   <figcaption>
Expected behavior: Two distinct user actions produce two separate traces with unique TraceIDs.
</figcaption> </figure>
<p>Yet, sometimes models failed to recognize these as separate user actions. Instead of two traces, they produced:</p>
<figure>  <figcaption>
Actual result: The model failed to clear context, causing separate user actions to be conflated into a single trace.
</figcaption> </figure>
<p><strong>The core issue</strong>: Models apply instrumentation mechanically to every HTTP call without understanding the business context. They see “HTTP requests” and link them all together, rather than recognizing “these are two separate user journeys.”</p>
<p>The models successfully instrumented the HTTP calls, but failed to propagate the Context correctly. They treated the timeline as a single flat list of events rather than two distinct hierarchical trees.</p>
<p>Our tests don’t just check compilation. We verify correct span names, parent-child relationships, valid trace IDs, and context propagation. Many models produced compiling code that generated malformed traces – proving that “it builds” is not enough for SRE work.</p>
<h2 id="observations">Observations</h2>
<h3 id="models">Models</h3>
<p>We were surprised that even the top models (as of Jan 2026) struggle.
The tasks we proposed were trivial compared to real-world scenarios. In a typical SRE job, services are massive, legacy-ridden, and poorly documented. If models fail on 300 lines of clean Go code, they cannot handle production.</p>
<p>We were surprised that:</p>
<ul>
<li><a href="https://quesma.com/benchmarks/otel/models/claude-opus-4.5/">Claude Opus 4.5</a>, the best model, got just 29% of these relatively simple tasks.</li>
<li><a href="https://quesma.com/benchmarks/otel/models/gemini-3-pro-preview/">Gemini 3 Pro</a> (which aces at general intelligence) didn’t have an edge over the much cheaper <a href="https://quesma.com/benchmarks/otel/models/gemini-3-flash-preview/">Gemini 3 Flash</a>.</li>
<li><a href="https://quesma.com/benchmarks/otel/models/gpt-5.2-codex/">GPT 5.2 Codex</a> was substantially worse than <a href="https://quesma.com/benchmarks/otel/models/gpt-5.2/">GPT 5.2</a>.</li>
</ul>
<h3 id="languages">Languages</h3>
<p>Each language has a different toolset, so it is not an apples-to-apples comparison. Our benchmark is too small to perform a comprehensive per-language comparison, yet even preliminary trends are striking.</p>
<figure> <a href="https://quesma.com/benchmarks/otel/#languages"> <img src="https://quesma.com/_astro/language_chart.BXXM9bH5_Z1tu9Lc.webp" alt="Pass rates by programming language showing C++ at 37%, Go at 20%, while Java, Ruby and Swift had 0% success" loading="lazy" decoding="async" fetchpriority="auto" width="1800" height="792">  </a> <figcaption> <p>C++ achieved the highest pass rate (37%), though this is partly due to having a simpler task (<a href="https://quesma.com/benchmarks/otel/tasks/cpp-simple">cpp-simple</a>) in its set.
Go, with the most tasks tested (7), reached 20% — notable for a language central to distributed systems.
JavaScript, Python, PHP, and .NET saw moderate success. Just one model solved a single Rust task.
None solved any tasks in Swift, Ruby, or (surprisingly, due to build issues) Java.</p> </figcaption> </figure>
<h3 id="cost-and-time-efficiency">Cost and time efficiency</h3>
<p>In every practical application, cost and speed matter.
As of Jan 2026, the <a href="https://en.wikipedia.org/wiki/Pareto_front">Pareto frontier</a> consists of only four models, given model performance:</p>
<ul>
<li><code>19%</code> Gemini 3 Flash (cost and speed) - the cheapest and fastest model in this benchmark (11x cheaper and 2x faster than Claude Opus 4.5)</li>
<li><code>22%</code> Claude Sonnet 4.5 (speed)</li>
<li><code>26%</code> GPT 5.2 (cost)</li>
<li><code>29%</code> Claude Opus 4.5 (cost and speed) — the best model in this benchmark, the most expensive but reasonably fast</li>
</ul>
<figure> <a href="https://quesma.com/benchmarks/otel/#cost-vs-performance"> <img src="https://quesma.com/_astro/cost_vs_performance.BoPEo92o_ZSVRKt.webp" alt="Cost efficiency scatter plot showing pass rate vs cost per run, with Gemini 3 Flash highlighted as best value" loading="lazy" decoding="async" fetchpriority="auto" width="1792" height="980">  </a> <figcaption> <p>See <a href="https://quesma.com/benchmarks/otel/#cost-vs-performance">cost vs performance chart</a>.</p> </figcaption> </figure>
<figure> <a href="https://quesma.com/benchmarks/otel/#speed-vs-performance"> <img src="https://quesma.com/_astro/speed_vs_performance.BB4_TZ_f_Z2j9BKV.webp" alt="Speed vs performance scatter plot showing pass rate vs average time per run" loading="lazy" decoding="async" fetchpriority="auto" width="1792" height="980">  </a> <figcaption> <p>See <a href="https://quesma.com/benchmarks/otel/#speed-vs-performance">speed vs performance chart</a>.</p> </figcaption> </figure>
<h2 id="why-opentelemetry-instrumentation-is-hard-for-ai">Why OpenTelemetry instrumentation is hard for AI</h2>
<p>OpenTelemetry has all the potential to be a perfect task for AI agents — it is long and tedious work, requiring a lot of scrutiny, but ultimately one that has clear specifications and can be easily tested.</p>
<p>Yet, even the frontier models fail miserably.</p>
<h3 id="it-is-a-job-not-a-puzzle">It is a job, not a puzzle</h3>
<p>Instrumentation of even a small service involves <strong>long-horizon tasks</strong>, which remain at the <a href="https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/">frontier of the current AI model progress</a>.
It requires diligently connecting all pieces of code and testing them correctly.</p>
<h3 id="requires-polyglot-backend-development-skills">Requires polyglot backend development skills</h3>
<p>Realistic services use multiple languages and technologies.
It is not enough to know the concept of distributed tracing, the OpenTelemetry standard, or even the APIs of SDKs. The agent must know CMake for C++, module systems for Go, or dependency management for Java - things we tested in our previous benchmark, <a href="https://quesma.com/blog/introducing-compilebench/">CompileBench</a>.</p>
<p>Usually, cloud environments are mixtures of the newest versions of technologies (sometimes past the training cut-off dates of AI models) and legacy systems. We cannot cherry-pick or rewrite everything, since a possible outage would be too costly. We need to support all languages and frameworks used in the cloud.</p>
<p>A lot of current AI progress focuses on the most popular languages (Python and TypeScript) and reasonably modern frameworks and build systems.</p>
<h3 id="less-training-data">Less training data</h3>
<p>Although adding instrumentation is a standard engineering task, it is not common practice in open-source. The most popular applications, where reliability matters the most, are in private repositories of big tech companies such as Apple, Airbnb, or Netflix.</p>
<h2 id="conclusion">Conclusion</h2>
<h3 id="key-takeaways">Key takeaways</h3>
<ul>
<li><strong>Best models struggle</strong>: The state-of-the-art Claude Opus 4.5 solved only 29% of tasks.</li>
<li><strong>Language gaps</strong>: Models failed completely on Java, Ruby, and Swift. C++ led at 37% (boosted by an easier task), Go reached 20%.</li>
<li><strong>Silent failures</strong>: Many solutions compiled correctly but produced malformed traces or conflated distinct user journeys.</li>
<li><strong>Cost efficiency</strong>: Gemini 3 Flash exceeds Gemini 3 Pro’s performance (18%) at a fraction of the cost.</li>
</ul>
<h3 id="ai-sre-is-still-mostly-hype-but-there-is-hope">AI SRE is still mostly hype, but there is hope</h3>
<p>AI SRE in 2026 is what <a href="https://quesma.com/blog/aiops-observability/">DevOps Anomaly Detection was in 2015</a> — bold claims backed by huge marketing budgets, but lacking independent verification. There are stories of <a href="https://www.deductive.ai/blogs/datadog-thank-you-for-blocking-us">SaaS vendors abruptly killing the observability stack</a>. Our results mirror <a href="https://clickhouse.com/blog/llm-observability-challenge">ClickHouse’s findings</a>: while LLMs can assist, they lack the capabilities of a skilled SRE.</p>
<p>Claude Opus 4.5, GPT-5.2, and Gemini 3 models show promising signals. Some hard tasks like <a href="https://quesma.com/benchmarks/otel/tasks/go-microservices-traces/">go-microservices-traces</a> reached <strong>55% pass rate</strong>. With more environments for Reinforcement Learning with Verified Rewards, this looks like a solvable problem.</p>
<h3 id="looking-forward">Looking forward</h3>
<p>Reliable software is incredibly economically valuable, but today it requires too much toil. No one wants to be woken up at 2 AM to troubleshoot.</p>
<p>We need a North Star to navigate the current AI boom. Just as SWE-Bench and TerminalBench2.0 became standards for software engineering, we need an SRE-style benchmark for distributed systems. Does the industry need newer models, or perhaps multi-agent systems? A good benchmark will tell us.</p>
<p>We invite you to explore the full results on <a href="https://quesma.com/benchmarks/otel/">OTelBench</a> and help us expand the test suite on <a href="https://github.com/QuesmaOrg/otel-bench">QuesmaOrg/otel-bench</a>. Have you tried using LLMs for observability? We are curious to hear if your experience matches our findings—or if you’ve found a workflow that actually works.</p>
<p>Join the discussion on <a href="https://news.ycombinator.com/item?id=46811588">Hacker News</a>, <a href="https://www.reddit.com/r/sre/comments/1qk0rug/built_otelbench_to_test_fundamental_sre_tasks/">Reddit</a> or <a href="https://www.linkedin.com/posts/przemyslaw-delewski_recently-we-built-otelbench-a-benchmark-activity-7420034952718827520-2gND">LinkedIn</a>.</p>
<p>But for now, the verdict is clear: if you need distributed tracing across services, expect to write that code yourself.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Choose Colors for Your CLI Applications (2023) (109 pts)]]></title>
            <link>https://blog.xoria.org/terminal-colors/</link>
            <guid>46810904</guid>
            <pubDate>Thu, 29 Jan 2026 14:49:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.xoria.org/terminal-colors/">https://blog.xoria.org/terminal-colors/</a>, See on <a href="https://news.ycombinator.com/item?id=46810904">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Let’s say you’re creating
a CLI tool which has to display
syntax highlighted source code.
You begin by choosing some colors
which look nice with
your chosen terminal theme:</p><div><p>~ — zsh — Sorcerer — 51×11</p><p>% highlight foo
<span># just some docs</span>
<span>func</span> <span>HelloWorld</span>() [<span>12</span>]<span>u8</span> {
	<span>return</span> <span>"hello world</span><span>\n</span><span>"</span>
}
Finished highlighting in 0.02 seconds.
% █</p></div><p>Nice!
However,
who knows if it’ll still look good
for people who use
a theme different to yours?
It seems sensible to try out
the defaults, at least.
Let’s start with
the macOS Terminal.app default theme:</p><div><p>~ — zsh — Basic — 51×11</p><p>% highlight foo
<span># just some docs</span>
<span>func</span> <span>HelloWorld</span>() [<span>12</span>]<span>u8</span> {
	<span>return</span> <span>"hello world</span><span>\n</span><span>"</span>
}
Finished highlighting in 0.02 seconds.
% █</p></div><div><p>~ — zsh — Basic — 51×11</p><p>% highlight foo
<span># just some docs</span>
<span>func</span> <span>HelloWorld</span>() [<span>12</span>]<span>u8</span> {
	<span>return</span> <span>"hello world</span><span>\n</span><span>"</span>
}
Finished highlighting in 0.02 seconds.
% █</p></div><p>Youch!
It seems fair to try the Tango themes next,
since those are the default on e.g. Ubuntu:</p><div><p>~ — zsh — Tango Light — 51×11</p><p>% highlight foo
<span># just some docs</span>
<span>func</span> <span>HelloWorld</span>() [<span>12</span>]<span>u8</span> {
	<span>return</span> <span>"hello world</span><span>\n</span><span>"</span>
}
Finished highlighting in 0.02 seconds.
% █</p></div><div><p>~ — zsh — Tango Dark — 51×11</p><p>% highlight foo
<span># just some docs</span>
<span>func</span> <span>HelloWorld</span>() [<span>12</span>]<span>u8</span> {
	<span>return</span> <span>"hello world</span><span>\n</span><span>"</span>
}
Finished highlighting in 0.02 seconds.
% █</p></div><p>Hmm, better, but not by much.
Finally,
let’s try what is likely
the most popular custom terminal theme – Solarized:</p><div><p>~ — zsh — Solarized Light — 51×11</p><p>% highlight foo
<span># just some docs</span>
<span>func</span> <span>HelloWorld</span>() [<span>12</span>]<span>u8</span> {
	<span>return</span> <span>"hello world</span><span>\n</span><span>"</span>
}
Finished highlighting in 0.02 seconds.
% █</p></div><div><p>~ — zsh — Solarized Dark — 51×11</p><p>% highlight foo
<span># just some docs</span>
<span>func</span> <span>HelloWorld</span>() [<span>12</span>]<span>u8</span> {
	<span>return</span> <span>"hello world</span><span>\n</span><span>"</span>
}
Finished highlighting in 0.02 seconds.
% █</p></div><p>Well then …
Let’s take a look at each palette
and investigate.</p><h2 id="sorcerer">Sorcerer</h2><div><p>~ — zsh — Sorcerer — 51×11</p><p>% colortest
<span>██ black</span>	<span>██ brblack</span>
<span>██ red</span>		<span>██ brred</span>
<span>██ green</span>	<span>██ brgreen</span>
<span>██ yellow</span>	<span>██ bryellow</span>
<span>██ blue</span>		<span>██ brblue</span>
<span>██ magenta</span>	<span>██ brmagenta</span>
<span>██ cyan</span>		<span>██ brcyan</span>
<span>██ white</span>	<span>██ brwhite</span>
% █</p></div><p>In Sorcerer,
all colors are readable
on the default background
except for <code>black</code>,
which is in fact darker than the background.
This is useful as the background color
for status bars and the like.
<code>white</code> is the same color as
the default foreground,
and <code>brblack</code> is a nice faded color.
Additionally, <code>brwhite</code> is
even lighter than the foreground;
this allows for subtle emphasization
of important text
like error messages and titles.</p><h2 id="basic">Basic</h2><div><p>~ — zsh — Basic — 51×11</p><p>% colortest
<span>██ black</span>	<span>██ brblack</span>
<span>██ red</span>		<span>██ brred</span>
<span>██ green</span>	<span>██ brgreen</span>
<span>██ yellow</span>	<span>██ bryellow</span>
<span>██ blue</span>		<span>██ brblue</span>
<span>██ magenta</span>	<span>██ brmagenta</span>
<span>██ cyan</span>		<span>██ brcyan</span>
<span>██ white</span>	<span>██ brwhite</span>
% █</p></div><div><p>~ — zsh — Basic — 51×11</p><p>% colortest
<span>██ black</span>	<span>██ brblack</span>
<span>██ red</span>		<span>██ brred</span>
<span>██ green</span>	<span>██ brgreen</span>
<span>██ yellow</span>	<span>██ bryellow</span>
<span>██ blue</span>		<span>██ brblue</span>
<span>██ magenta</span>	<span>██ brmagenta</span>
<span>██ cyan</span>		<span>██ brcyan</span>
<span>██ white</span>	<span>██ brwhite</span>
% █</p></div><p>The Basic themes are, well, <em>horrendous.</em>
Really owning that 90s xterm look, it seems.
<code>bryellow</code> is unreadable in light mode
(check out that function name
from the code sample earlier),
while in dark mode
both <code>blue</code> and <code>brblue</code>
are totally illegible.</p><p>That leaves us with thirteen colors
we can safely use:</p><div><p>~ — zsh — Sorcerer — 51×11</p><p>% colortest --only-usable
<span>██ black</span>	<span>██ brblack</span>
<span>██ red</span>		<span>██ brred</span>
<span>██ green</span>	<span>██ brgreen</span>
<span>██ yellow</span>	<span>██ bryellow</span>
<span>██ blue</span>		<span>██ brblue</span>
<span>██ magenta</span>	<span>██ brmagenta</span>
<span>██ cyan</span>		<span>██ brcyan</span>
<span>██ white</span>	<span>██ brwhite</span>
% █</p></div><h2 id="tango">Tango</h2><div><p>~ — zsh — Tango Light — 51×11</p><p>% colortest
<span>██ black</span>	<span>██ brblack</span>
<span>██ red</span>		<span>██ brred</span>
<span>██ green</span>	<span>██ brgreen</span>
<span>██ yellow</span>	<span>██ bryellow</span>
<span>██ blue</span>		<span>██ brblue</span>
<span>██ magenta</span>	<span>██ brmagenta</span>
<span>██ cyan</span>		<span>██ brcyan</span>
<span>██ white</span>	<span>██ brwhite</span>
% █</p></div><div><p>~ — zsh — Tango Dark — 51×11</p><p>% colortest
<span>██ black</span>	<span>██ brblack</span>
<span>██ red</span>		<span>██ brred</span>
<span>██ green</span>	<span>██ brgreen</span>
<span>██ yellow</span>	<span>██ bryellow</span>
<span>██ blue</span>		<span>██ brblue</span>
<span>██ magenta</span>	<span>██ brmagenta</span>
<span>██ cyan</span>		<span>██ brcyan</span>
<span>██ white</span>	<span>██ brwhite</span>
% █</p></div><p>In my opinion
these did a lot better than
Terminal.app’s Basic themes,
but they are still far from perfect.
<code>bryellow</code> is again unreadable in the light theme,
and perhaps <code>brgreen</code> is
a little difficult to see,
though it’s nothing that would
stop me from using <code>brgreen</code>
in an application.</p><p>At this point you may have noticed
how the greyscales –
<code>black</code>, <code>brblack</code>, <code>white</code> &amp; <code>brwhite</code> –
have remained consistent
between light and dark themes
for both Basic and Tango.
Of course,
this means that
<code>{,br}white</code> is unreadable in Tango Light
(owing to the light background)
and <code>black</code> is unreadable in Tango Dark
(owing to the dark background).</p><p>In other words:
forget about
that idea of mine from earlier
about using <code>brwhite</code> to emphasize content.
Unless, of course,
you don’t mind if your
eminently <em>emphasized</em> words
are completely unreadable
for the user of your software
who deigns to use the default light theme
of A Popular Linux Distro.</p><p>On the other hand,
using <code>brblack</code> to de-emphasize content
still seems fine to me.
I suppose some extra contrast
for <code>brblack</code> in Tango Dark
would be nice,
but with text which is meant to be ignored
I don’t think this matters much.</p><p>And lo, but ten colors remain.</p><div><p>~ — zsh — Sorcerer — 51×11</p><p>% colortest --only-usable
<span>██ black</span>	<span>██ brblack</span>
<span>██ red</span>		<span>██ brred</span>
<span>██ green</span>	<span>██ brgreen</span>
<span>██ yellow</span>	<span>██ bryellow</span>
<span>██ blue</span>		<span>██ brblue</span>
<span>██ magenta</span>	<span>██ brmagenta</span>
<span>██ cyan</span>		<span>██ brcyan</span>
<span>██ white</span>	<span>██ brwhite</span>
% █</p></div><h2 id="solarized">Solarized</h2><div><p>~ — zsh — Solarized Light — 51×11</p><p>% colortest
<span>██ black</span>	<span>██ brblack</span>
<span>██ red</span>		<span>██ brred</span>
<span>██ green</span>	<span>██ brgreen</span>
<span>██ yellow</span>	<span>██ bryellow</span>
<span>██ blue</span>		<span>██ brblue</span>
<span>██ magenta</span>	<span>██ brmagenta</span>
<span>██ cyan</span>		<span>██ brcyan</span>
<span>██ white</span>	<span>██ brwhite</span>
% █</p></div><div><p>~ — zsh — Solarized Light — 51×11</p><p>% colortest
<span>██ black</span>	<span>██ brblack</span>
<span>██ red</span>		<span>██ brred</span>
<span>██ green</span>	<span>██ brgreen</span>
<span>██ yellow</span>	<span>██ bryellow</span>
<span>██ blue</span>		<span>██ brblue</span>
<span>██ magenta</span>	<span>██ brmagenta</span>
<span>██ cyan</span>		<span>██ brcyan</span>
<span>██ white</span>	<span>██ brwhite</span>
% █</p></div><p>Solarized is a curious beast.
Every color in it
was chosen using <a href="https://en.wikipedia.org/wiki/CIELAB_color_space"><em>L*a*b*</em></a>,
a perceptually-uniform color space
from the 1970s.
(For what it’s worth,
color science has
<a href="https://bottosson.github.io/posts/oklab/">progressed significantly</a> since then;
the only reason
Ethan Schoonover used <em>L*a*b*</em>
is that it’s commonly used in photography,
and he used to be a professional photographer.)</p><p>Its lightnesses are perfectly symmetrical
so that Solarized Light and Dark
can share a set of accent colors
while maintaining identical contrast.
Moreover,
the warm tones of the light theme
and cool tones of the dark theme
are complementary.
(The hue gap is
closer to 150° than 180° in reality.
See <a href="https://bottosson.github.io/misc/colorpicker/#002b36">here</a>
and <a href="https://bottosson.github.io/misc/colorpicker/#fdf6e3">here</a>
to compare hue values.)</p><p>Solarized is also incredibly popular.
I have no data here,
but as of the date of writing
it’s the most starred theme repository on GitHub
I can find.
Solarized has 15.4 thousand stars at the moment,
while the next-closest is <a href="https://github.com/morhetz/gruvbox">Gruvbox</a>
with 11.8 thousand.
Solarized is available as a plugin
or sometimes even as a built-in preset
in damn near every
popular terminal emulator and editor
on the planet.</p><p>To understand Solarized’s
peculiar arrangement of the 16-color palette,
we have to travel back in time to 2011
<a href="https://github.com/altercation/solarized/commit/3da9bd10d3b8c1ad6e2a5ab8617ef8c82fca0df7">when Solarized was first released</a>.
In this dark era,
terminals supporting 24-bit color
didn’t exist / weren’t widespread.
One option common among Vim themes at the time
was to round every color
to the nearest 256-color palette value.
In Solarized’s case,
this destroys the mathematical symmetry
at the heart of the theme.
(<a href="https://github.com/lifepillar/vim-solarized8#but-my-terminal-has-only-256-colors">I’m not kidding, it looks awful</a>.)</p><p>The solution
– rather, <em>hack</em> –
chosen at the time
was to distill
all the colors used in the Vim interface
down to a palette of sixteen colors.
Conveniently,
Solarized’s accent colors
fit nicely into the non-bright column
of the 16-color palette,
while Solarized’s monotones
fit into the bright column.
Once the user sets their terminal
to use the Solarized palette,
Vim can color its entire interface
using only the 16-color palette
and get correct color values,
no clunky color approximations needed.</p><p>The downside to all this is that
an application which uses
any of the bright colors
which Solarized co-opted for itself
will look strange.
Users of Solarized
– and, by god, there’s so many of them –
<a href="https://github.com/gradle/gradle/issues/2417">appear</a>
<a href="https://github.com/gruntjs/grunt/issues/181">frequently</a>
<a href="https://github.com/crate-ci/cargo-release/issues/41">on</a>
<a href="https://github.com/cli/cli/issues/1743">issue</a>
<a href="https://github.com/mintty/mintty/issues/683">trackers</a>
asking why command-line output
is inexplicably gray or even invisible
as a result of CLIs
using these forsaken bright colors.</p><p>Our beloved <code>brblack</code>
is unreadable in Solarized Dark,
so we’ll have to strike it from the table
in addition to the affected bright colors.</p><div><p>~ — zsh — Sorcerer — 51×11</p><p>% colortest --only-usable
<span>██ black</span>	<span>██ brblack</span>
<span>██ red</span>		<span>██ brred</span>
<span>██ green</span>	<span>██ brgreen</span>
<span>██ yellow</span>	<span>██ bryellow</span>
<span>██ blue</span>		<span>██ brblue</span>
<span>██ magenta</span>	<span>██ brmagenta</span>
<span>██ cyan</span>		<span>██ brcyan</span>
<span>██ white</span>	<span>██ brwhite</span>
% █</p></div><h2 id="a-sad-note-about-bold">A sad note about bold</h2><p>Far back in the past,
there was no way for terminals
to display bright colors.
As a workaround,
manufacturers
(we’re talking about
physical terminals here)
<a href="https://en.wikipedia.org/wiki/ANSI_escape_code#3-bit_and_4-bit">started making all bold text bright
instead of using a heavier font weight</a>.
One way or another
this ended up in the default settings of
many modern terminal emulators
(in spite of not being in the standard),
meaning that
regular colorful text made bold
can become bright too,
depending on the user’s configuration.</p><h2 id="conclusion">Conclusion</h2><p>And so, I present to you the final version
of our table of acceptable colors:</p><div><p>~ — zsh — Sorcerer — 51×21</p><div><p>% colortest --only-usable --bold
Regular:
<span>██ black</span>	<span>██ brblack</span>
<span>██ red</span>		<span>██ brred</span>
<span>██ green</span>	<span>██ brgreen</span>
<span>██ yellow</span>	<span>██ bryellow</span>
<span>██ blue</span>		<span>██ brblue</span>
<span>██ magenta</span>	<span>██ brmagenta</span>
<span>██ cyan</span>		<span>██ brcyan</span>
<span>██ white</span>	<span>██ brwhite</span></p><p>Bold:
<strong><span>██ boldblack</span>	<span>██ boldbrblack</span>
<span>██ boldred</span>	<span>██ boldbrred</span>
<span>██ boldgreen</span>	<span>██ boldbrgreen</span>
<span>██ boldyellow</span>	<span>██ boldbryellow</span>
<span>██ boldblue</span>	<span>██ boldbrblue</span>
<span>██ boldmagenta</span>	<span>██ boldbrmagenta</span>
<span>██ boldcyan</span>	<span>██ boldbrcyan</span>
<span>██ boldwhite</span>	<span>██ boldbrwhite</span></strong>
% █</p></div></div><p>Only eleven out of our
thirty-two possible color settings
are permissible,
given that we want applications
to remain readable
for as many people as we can.</p><p>If you’re developing a command-line tool
which will be used by
anyone apart from yourself,
I strongly recommend
you limit your use of color
to the ones I’ve identified here
as being “mostly alright”
and “not unreadable in
a common configuration
used by tons of people”.</p><h2 id="appendix">Appendix</h2><p>You probably didn’t notice,
but I styled the “terminal windows”
in this post to look
as similar as possible
to macOS Terminal.app windows
through painstaking
color picking and pixel counting.</p><p>The dimensions in each window’s titlebar
matches as closely as I can
with its actual dimensions on-screen.</p><p>The <code>colortest</code> and <code>highlight</code> utilities
are entirely fictional.</p><p>Terminal.app doesn’t actually provide
individual access to
the light and dark variants of Basic;
they appear as a single theme,
which switches seamlessly
when the OS theme changes.
As far as I know,
this reactive functionality
isn’t exposed to any other theme,
whether pre-installed or user-created.
In order to capture this,
I made the terminal windows in this post
react to whether the rest of the site
is in light or dark mode,
<em>except for the Basic windows.</em>
They remain fixed in
either light or dark mode,
since in real life you’ll never see,
for example,
a light Basic terminal
with dark window chrome.</p><p>Luna Razzaghipour<br>29 January 2023<br></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Waymo robotaxi hits a child near an elementary school in Santa Monica (157 pts)]]></title>
            <link>https://techcrunch.com/2026/01/29/waymo-robotaxi-hits-a-child-near-an-elementary-school-in-santa-monica/</link>
            <guid>46810401</guid>
            <pubDate>Thu, 29 Jan 2026 14:08:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2026/01/29/waymo-robotaxi-hits-a-child-near-an-elementary-school-in-santa-monica/">https://techcrunch.com/2026/01/29/waymo-robotaxi-hits-a-child-near-an-elementary-school-in-santa-monica/</a>, See on <a href="https://news.ycombinator.com/item?id=46810401">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">A Waymo robotaxi struck a child near an elementary school in Santa Monica on January 23, according to the company. Waymo told the National Highway Traffic Safety Administration (NHTSA) that the child — whose age and identity are not currently public — sustained minor injuries.</p>

<p>The NHTSA has opened an <a href="https://www.nhtsa.gov/?nhtsaId=PE26001" target="_blank" rel="noreferrer noopener nofollow">investigation</a> into the accident, and Waymo said in a <a href="https://waymo.com/blog/2026/01/a-commitment-to-transparency-and-road-safety" target="_blank" rel="noreferrer noopener nofollow">blog post</a> that it “will cooperate fully with them throughout the process.”</p>







<p>Waymo said its robotaxi struck the child at six miles per hour, after braking “hard” from around 17 miles per hour. The young pedestrian “suddenly entered the roadway from behind a tall SUV, moving directly into our vehicle’s path,” the company said in its blog post. Waymo said its vehicle “immediately detected the individual as soon as they began to emerge from behind the stopped vehicle.”</p>

<p>“Following contact, the pedestrian stood up immediately, walked to the sidewalk, and we called 911. The vehicle remained stopped, moved to the side of the road, and stayed there until law enforcement cleared the vehicle to leave the scene,” Waymo wrote in the post.</p>

<p>News of the crash comes as Waymo faces dual investigations into its robotaxis illegally passing school buses. The NHTSA opened a <a href="https://techcrunch.com/2025/10/20/regulators-probe-waymo-after-its-robotaxi-drove-around-a-stopped-school-bus/" target="_blank" rel="noreferrer noopener">probe</a> into the problem in October shortly after the first report of the incident in Atlanta, Georgia, and the National Transportation Safety Board opened its own <a href="https://techcrunch.com/2026/01/23/waymo-probed-by-national-transportation-safety-board-over-illegal-school-bus-behavior/" target="_blank" rel="noreferrer noopener">investigation</a> last week after around 20 incidents were reported in Austin, Texas.</p>

<p>According to the NHTSA, the accident occurred “within two blocks” of the elementary school “during normal school drop off hours.” The safety regulator said “there were other children, a crossing guard, and several double-parked vehicles in the vicinity.”</p>

<p>The NHTSA’s Office of Defects Investigation is investigating “whether the Waymo AV exercised appropriate caution given, among other things, its proximity to the elementary school during drop off hours, and the presence of young pedestrians and other potential vulnerable road users.”</p>
<div>
		
		<p>Techcrunch event</p>
		<div>
			
			<p><span>Boston, MA</span>
													<span>|</span>
													<span>June 23, 2026</span>
							</p>
			
		</div>
	</div>

<p>Waymo said in its blog post that its “peer-reviewed model” shows a “fully attentive human driver in this same situation would have made contact with the pedestrian at approximately 14 mph.” The company did not release a specific analysis of this crash.  </p>


</div><div>
	
	
	
	

	
<div>
		<p>Sean O’Kane is a reporter who has spent a decade covering the rapidly-evolving business and technology of the transportation industry, including Tesla and the many startups chasing Elon Musk. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane.</p>
<p>You can contact or verify outreach from Sean by emailing <a href="mailto:sean.okane@techcrunch.com">sean.okane@techcrunch.com</a> or via encrypted message at okane.01 on Signal.</p>	</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/sean-okane/" data-event="button" href="https://techcrunch.com/author/sean-okane/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Code Daily Benchmarks for Degradation Tracking (361 pts)]]></title>
            <link>https://marginlab.ai/trackers/claude-code/</link>
            <guid>46810282</guid>
            <pubDate>Thu, 29 Jan 2026 13:59:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marginlab.ai/trackers/claude-code/">https://marginlab.ai/trackers/claude-code/</a>, See on <a href="https://news.ycombinator.com/item?id=46810282">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <!-- Last Updated --><p><span>Last updated:</span> <span>Jan 29, 2026</span> </p> <!-- Header --> <div>  <p> The goal of this tracker is to detect statistically significant degradations in Claude Code with Opus 4.5 performance on SWE tasks. </p> <ul> <li> <span>•</span> <span> <strong>Updated daily:</strong>  Daily benchmarks on a curated subset of <a href="https://marginlab.ai/explorers/swe-bench-pro"> SWE-Bench-Pro </a>  </span> </li><li> <span>•</span> <span> <strong>Detect degradation:</strong>  Statistical testing for degradation detection </span> </li><li> <span>•</span> <span> <strong>What you see is what you get:</strong>  We benchmark in Claude Code CLI with the SOTA model (currently Opus 4.5) directly, no custom harnesses. </span> </li> </ul> </div> <!-- Summary Stats --><div> <p> <h3>Summary</h3> </p> <!-- Status - Full Width --> <div> <div> <p><span>Status</span></p><div> <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div> <p>Degradation Status</p><p>
Shows if any time period has a statistically significant performance drop (p &lt; 0.05).
</p> </div> </div> </div> <div> <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z"></path> </svg> <p><span> Degradation detected over past 30 days </span> </p></div> </div> <!-- Pass Rate Metrics --> <div> <!-- Baseline Pass Rate --> <div> <div> <p><span>Baseline</span></p><div> <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div> <p>Baseline Pass Rate</p><p>
Historical average pass rate used as reference for detecting performance changes.
</p> </div> </div> </div> <p><span>58</span> <span>%</span> </p> <p>reference rate</p> </div>  <!-- Daily Pass Rate --> <div> <div> <p><span>Daily Pass Rate</span></p><div> <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div> <p>Daily Pass Rate</p><p>
Percentage of benchmark tasks passed in the most recent day's evaluations.
</p> </div> </div> </div> <p><span>50</span> <span>%</span> </p> <p>50 evaluations</p> </div>  <!-- 7-day Pass Rate --> <div> <div> <p><span>7-day Pass Rate</span></p><div> <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div> <p>7-day Pass Rate</p><p>
Aggregate pass rate over the last 7 days. Provides a more stable measure than daily results.
</p> </div> </div> </div> <p><span>53</span> <span>%</span> </p> <p>250 evaluations</p> </div>  <!-- 30-day Pass Rate --> <div> <div> <p><span>30-day Pass Rate</span></p><div> <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div> <p>30-day Pass Rate</p><p>
Aggregate pass rate over the last 30 days. Best measure of overall sustained performance.
</p> </div> </div> </div> <p><span>54</span> <span>%</span> </p> <p>655 evaluations</p> </div> </div> </div> <!-- 30-Day Trend Chart --> <div> <!-- Daily Trend Chart --><div> <div> <div> <div> <h3>Daily Trend</h3> <p>Pass rate over time</p> </div> <!-- Chart guide tooltip --> <div> <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div><p>
Daily benchmark pass rates over the past 30 days. Hover over legend items for details on each visual element.
</p> </div> </div> </div> <div> <!-- Pass Rate legend --> <div>  <p><span>Pass Rate</span></p><svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div><p>
Daily benchmark pass rate showing the percentage of tasks solved each day.
</p> </div> </div> <!-- Baseline legend --> <div>  <p><span>Baseline</span></p><svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div><p>
Historical average pass rate (58%) used as reference for detecting performance changes.
</p> </div> </div> <!-- Threshold legend --> <div>  <p><span>Threshold</span></p><svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div><p>
Shaded region around baseline (±14.0%). Changes within this band are not statistically significant (p ≥ 0.05).
</p> </div> </div> <!-- 95% CI legend with toggle --> <p><label>   <span>95% CI</span> <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div><p>
95% confidence interval for each data point. Toggle checkbox to show/hide. Wider intervals indicate more uncertainty (fewer samples).
</p> </div> </label> </p></div> </div> <div>   <p> Dashed line at 58% baseline with ±14.0% significance threshold </p>  </div> </div> <!-- Weekly Trend Chart --> <div> <div> <div> <div> <h3>Weekly Trend</h3> <p>Aggregated 7-day pass rate</p> </div> <!-- Chart guide tooltip --> <div> <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div><p>
Rolling 7-day aggregated pass rates for a smoother trend view with reduced day-to-day noise.
</p> </div> </div> </div> <div> <!-- Pass Rate legend --> <div>  <p><span>Pass Rate</span></p><svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div><p>
7-day rolling pass rate aggregating daily results for a smoother trend view.
</p> </div> </div> <!-- Baseline legend --> <div>  <p><span>Baseline</span></p><svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div><p>
Historical average pass rate (58%) used as reference for detecting performance changes.
</p> </div> </div> <!-- Threshold legend --> <div>  <p><span>Threshold</span></p><svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div><p>
Shaded region around baseline (±5.6%). Changes within this band are not statistically significant (p ≥ 0.05).
</p> </div> </div> <!-- 95% CI legend with toggle --> <p><label>   <span>95% CI</span> <svg fill="none" stroke="currentColor" viewBox="0 0 24 24"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path> </svg> <div><p>
95% confidence interval for each data point. Toggle checkbox to show/hide. Wider intervals indicate more uncertainty (fewer samples).
</p> </div> </label> </p></div> </div> <div>   <p> Dashed line at 58% baseline with ±5.6% significance threshold </p>  </div> </div>     </div> </div><div id="alerts"> <div> <h3>Get notified when degradation is detected</h3> <p id="tracker-alerts-description">We'll email you when we detect a statistically significant performance drop.</p> </div>  <p>Thanks for subscribing! Check your email to confirm.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A lot of population numbers are fake (187 pts)]]></title>
            <link>https://davidoks.blog/p/a-lot-of-population-numbers-are-fake</link>
            <guid>46810027</guid>
            <pubDate>Thu, 29 Jan 2026 13:36:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://davidoks.blog/p/a-lot-of-population-numbers-are-fake">https://davidoks.blog/p/a-lot-of-population-numbers-are-fake</a>, See on <a href="https://news.ycombinator.com/item?id=46810027">Hacker News</a></p>
Couldn't get https://davidoks.blog/p/a-lot-of-population-numbers-are-fake: Error: getaddrinfo ENOTFOUND davidoks.blog]]></description>
        </item>
        <item>
            <title><![CDATA[TÜV Report 2026: Tesla Model Y has the worst reliability of all 2022–2023 cars (166 pts)]]></title>
            <link>https://www.autoevolution.com/news/tuev-report-2026-tesla-model-y-has-the-worst-reliability-among-all-20222023-cars-261596.html</link>
            <guid>46809105</guid>
            <pubDate>Thu, 29 Jan 2026 12:07:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.autoevolution.com/news/tuev-report-2026-tesla-model-y-has-the-worst-reliability-among-all-20222023-cars-261596.html">https://www.autoevolution.com/news/tuev-report-2026-tesla-model-y-has-the-worst-reliability-among-all-20222023-cars-261596.html</a>, See on <a href="https://news.ycombinator.com/item?id=46809105">Hacker News</a></p>
Couldn't get https://www.autoevolution.com/news/tuev-report-2026-tesla-model-y-has-the-worst-reliability-among-all-20222023-cars-261596.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The tech market is fundamentally fucked up and AI is just a scapegoat (286 pts)]]></title>
            <link>https://bayramovanar.substack.com/p/tech-market-is-fucked-up</link>
            <guid>46809069</guid>
            <pubDate>Thu, 29 Jan 2026 12:03:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bayramovanar.substack.com/p/tech-market-is-fucked-up">https://bayramovanar.substack.com/p/tech-market-is-fucked-up</a>, See on <a href="https://news.ycombinator.com/item?id=46809069">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Writing about layoffs and the tech market has been on my TODO for several years. Yesterday, the news of </span><a href="https://www.aboutamazon.com/news/company-news/amazon-layoffs-corporate-jan-2026" rel="nofollow ugc noopener">16k Amazon layoffs</a><span> plus two LinkedIn posts on the same topic back-to-back encouraged me to finally write about it.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!ApMN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccab62cb-98c6-4b9f-9e1d-4da0dc5bec91_364x600.jpeg" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ApMN!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccab62cb-98c6-4b9f-9e1d-4da0dc5bec91_364x600.jpeg 424w, https://substackcdn.com/image/fetch/$s_!ApMN!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccab62cb-98c6-4b9f-9e1d-4da0dc5bec91_364x600.jpeg 848w, https://substackcdn.com/image/fetch/$s_!ApMN!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccab62cb-98c6-4b9f-9e1d-4da0dc5bec91_364x600.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!ApMN!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccab62cb-98c6-4b9f-9e1d-4da0dc5bec91_364x600.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!ApMN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccab62cb-98c6-4b9f-9e1d-4da0dc5bec91_364x600.jpeg" width="364" height="600" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ccab62cb-98c6-4b9f-9e1d-4da0dc5bec91_364x600.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:600,&quot;width&quot;:364,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:117339,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://bayramovanar.substack.com/i/186173242?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccab62cb-98c6-4b9f-9e1d-4da0dc5bec91_364x600.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!ApMN!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccab62cb-98c6-4b9f-9e1d-4da0dc5bec91_364x600.jpeg 424w, https://substackcdn.com/image/fetch/$s_!ApMN!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccab62cb-98c6-4b9f-9e1d-4da0dc5bec91_364x600.jpeg 848w, https://substackcdn.com/image/fetch/$s_!ApMN!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccab62cb-98c6-4b9f-9e1d-4da0dc5bec91_364x600.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!ApMN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccab62cb-98c6-4b9f-9e1d-4da0dc5bec91_364x600.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><strong>Disclaimer:</strong><span> I worked 5 years at Shopify. This is probably why such posts come one after another on my feed but Shopify isn’t the point here, they are just a micro piece of the whole fucked up system. </span></p><p>Tech job market is fundamentally broken and we all pointing fingers at AI. </p><p>But having spent almost 2 decades in the industry, I think the rot goes much deeper than ChatGPT. </p><p><span>Truth to be told tech market hasn’t truly ‘improved’ since the 2008 financial crisis. It just mutated into something </span><strong>evil</strong><span>. </span></p><p><span>After the 2008 mortgage crisis, the economic regime significantly changed. Which was also around the time my interest in Finance began and recently </span><a href="https://bayramovanar.substack.com/p/why-i-built-bullsheet-part-1" rel="nofollow ugc noopener">I started to build my own investment tool you can read more about it here. </a></p><p>At that time time we entered an era of extensive liquidity (cheap money). When interest rates are near zero, investors demand growth above all else. </p><p><span>As a result, tech companies stopped building for </span><strong>sustainability</strong><span> and started building for </span><strong>exponential expansion</strong><span>.</span></p><p>Here is a graph shows US Fed Interest Rates by years. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!meTk!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c68c210-6cda-4133-a7bf-74e5f90505da_2140x1394.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!meTk!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c68c210-6cda-4133-a7bf-74e5f90505da_2140x1394.png 424w, https://substackcdn.com/image/fetch/$s_!meTk!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c68c210-6cda-4133-a7bf-74e5f90505da_2140x1394.png 848w, https://substackcdn.com/image/fetch/$s_!meTk!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c68c210-6cda-4133-a7bf-74e5f90505da_2140x1394.png 1272w, https://substackcdn.com/image/fetch/$s_!meTk!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c68c210-6cda-4133-a7bf-74e5f90505da_2140x1394.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!meTk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c68c210-6cda-4133-a7bf-74e5f90505da_2140x1394.png" width="1456" height="948" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0c68c210-6cda-4133-a7bf-74e5f90505da_2140x1394.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:948,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:135450,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://bayramovanar.substack.com/i/186173242?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c68c210-6cda-4133-a7bf-74e5f90505da_2140x1394.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!meTk!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c68c210-6cda-4133-a7bf-74e5f90505da_2140x1394.png 424w, https://substackcdn.com/image/fetch/$s_!meTk!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c68c210-6cda-4133-a7bf-74e5f90505da_2140x1394.png 848w, https://substackcdn.com/image/fetch/$s_!meTk!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c68c210-6cda-4133-a7bf-74e5f90505da_2140x1394.png 1272w, https://substackcdn.com/image/fetch/$s_!meTk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c68c210-6cda-4133-a7bf-74e5f90505da_2140x1394.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><h6><span>Ref: </span><a href="https://www.macrotrends.net/2015/fed-funds-rate-historical-chart" rel="nofollow ugc noopener">https://www.macrotrends.net/2015/fed-funds-rate-historical-chart</a></h6><p>In traditional industries like manufacturing you don’t hire 500 factory workers unless you have a production line that needs them. You don’t over-hire based on a guess.</p><p>But in Tech, the playbook is different. Companies over-hire software engineers intentionally. To play the lottery. It is similar to having slow and steady ETF investments vs active investing. No matter how godly you are with active investing sooner or later, you will invest on a loser. Same goes for businesses.</p><p>In a factory, “Work in Progress” (unfinished goods) is a liability. You don’t want inventory sitting on the floor; you want it out the door. </p><p><span>In software, we convinced ourselves that “Work in Progress” (hiring engineers to work on projects that&nbsp;</span><strong>haven’t</strong><span>&nbsp;shipped yet) is an </span><strong>asset</strong><span>.</span></p><p><span>It is not. It is just&nbsp;</span><strong>excessive inventory.</strong></p><p>When the market turned, companies realized they were warehousing talent like unsold products. And just like unsold inventory, when the storage costs get too high, you dump it. </p><p>Layoffs have become a product feature.</p><p>Till ~2010, a layoff was a sign of failure. It meant the CEO messed up.  </p><p>In 2024, a layoff is a signal of “discipline.” Companies lay off thousands, and their stock price&nbsp;jumps. </p><p>They are signaling to Wall Street that they are willing to sacrifice human capital to protect margins. </p><p>Big Tech companies (think Google, Meta, or any hyper-growth SaaS) operate on a two-tier system:</p><p><span>1. </span><strong>The Core:</strong><span> A fundamental team working on the actual revenue-generating products (the search engine, the ad network, the checkout flow).</span></p><p><span>2. </span><strong>The Bets:</strong><span> Thousands of engineers hired to build parallel products, experimental features, or simply to keep talent away from competitors and potentially build something that would move into “The Core” tier. </span></p><p>The company knows that most of these side bets will fail. When the economic winds change, the ‘non-core’ staff becomes immediately replaceable.</p><p>It’s a vicious cycle: Hire the best people you can find to hoard talent, see what sticks, and lay off the rest when investors want to see better margins.</p><p>This dynamic creates a cruel paradox for engineers.</p><p>Most engineers (including me) spent months grinding LeetCode at least twice in their career, studying system design, and passing grueling 6-round interviews to prove they are the “top 1%.” </p><p>Yet, once hired, they are often placed on a non-essential team where they become nothing more than a statistic on a spreadsheet.</p><p>You jump through hoops to prove you are exceptional, only to be treated as disposable.</p><p>For a long time, Europe offered a counter-balance. The pay was lower than Silicon Valley, but the trade-off was stability, stronger labor protections, and a slower, more sustainable pace of work.</p><p>That social contract is breaking.</p><div><p><span>As American tech giants expanded into Europe and as European unicorns chased the same growth-at-all-costs playbooks the incentives changed. </span><br><span>Leadership imported US-style compensation models, investor expectations, and organizational volatility, but without importing US-level pay or upside. </span></p><p><span>”On paper” Europe still has strong labor laws. In practice, companies learned to route around them: constant reorganizations, “strategic refocus” layoffs, performance-managed exits.</span></p></div><p>The result is the worst of both worlds. European engineers now face US-level job insecurity with European-level compensation and limited mobility. The safety net hasn’t disappeared, but it’s being slowly hollowed out.</p><p><strong>And severances… A small, one-time payment is used to justify years of below  market compensation, while offering little real protection against sudden displacement.</strong></p><p>Europe just became a lower-cost extension of Silicon Valley.</p><p>Ultimately, this comes down to how companies signal value.</p><p>Traditional businesses used to show their health through revenue, profit, and smart capital investment. Today, Tech companies use layoffs as a marketing signal to Wall Street. They cut costs not because they are going bankrupt, but to show they can be “efficient.”</p><p>The more liquidity&nbsp;that was&nbsp;pumped into Tech, the harder this situation&nbsp;became. As long as engineers are treated as speculative assets rather than human capital, the market will remain broken regardless of how good AI gets.</p><p>The job market is not “tough” right now because of AI. It is tough because we are unwinding 14 years of financial toxicity.</p><p>The liquidity that flooded the tech sector didn’t just inflate valuations; it inflated teams, egos, and expectations. </p><p>Until the industry relearns how to build with scarcity rather than excess, the “vicious cycle” of hire-and-dump will continue regardless of how good AI will get.</p><p><strong>So you aren’t being laid off because your performance was bad; you are being effectively “liquidated” like a bad stock trade that you sell with a loss.</strong><span> </span></p></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vitamin D and Omega-3 have a larger effect on depression than antidepressants (776 pts)]]></title>
            <link>https://blog.ncase.me/on-depression/</link>
            <guid>46808251</guid>
            <pubDate>Thu, 29 Jan 2026 10:35:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.ncase.me/on-depression/">https://blog.ncase.me/on-depression/</a>, See on <a href="https://news.ycombinator.com/item?id=46808251">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="content">

        <!-- Is Draft, Is Deprecated, Is Old -->
        
            <!-- TODO: don't show this segment at all, figure out age on build-side -->
            
        

		<p><em>(content note: scientific discussion of depression &amp; suicide)</em></p>
<p>
<b>"Too Long; Didn't Read" Summary:</b><br>
Exactly what the title says.
</p>
<p>The "standardised effect size" of antidepressants on depression, vs placebo, is around 0.4. (This is like going from an average <strong>C to a C+</strong>.)</p>
<p>In contrast, the effect size of 1500mg/day of "≥60% EPA" Omega-3 supplements — which are cheaper &amp; have fewer side effects than antidepressants — is a bit higher, around 0.6. (This is like going from a <strong>C to a B–</strong>.)</p>
<p>But, much better: the effect size of 5000mg/day of Vitamin D is around <em>1.8!</em> (This is like going from a <strong>C to an A–</strong>!) It works even for people who <em>don't</em> have a Vitamin D insufficiency, which almost half of American adults <em>do</em>.</p>
<p>Even if you're already taking Vitamin D &amp; Omega-3, you may <em>still</em> not be taking enough. The "official" recommendations <em>are all 3 to 10 times too low</em>. Both these supplements are safe, cheap, and over-the-counter, with <em>positive</em> side-effects (on Covid &amp; cognition).</p>
<p>So, unless you have specific reasons to not take Vitamin D &amp; Omega-3 — (kidney stones, blood thinners, etc) — please try them, for at least a month! They could save your mental health. Maybe even your life.</p>
<p><strong>Table of Contents:</strong></p>
<ul>
<li>A crash course in "effect sizes" <a href="#effect_sizes">↪</a></li>
<li>Interpreting effect sizes on depression <a href="#interpreting_depression">↪</a></li>
<li>Antidepressants <a href="#antidepressants">↪</a></li>
<li>Omega-3 <a href="#omega_3">↪</a></li>
<li>Vitamin D <a href="#vitamin_d">↪</a></li>
<li>Conclusion: <em>All this time, you lacked the Vitamin?</em> <a href="#conclusion">↪</a></li>
</ul>
<hr>

<h2>A crash course in "effect sizes"</h2>
<p>In Alicetown, the average person has 4 younger cousins.<br>
In Bobtown, the average person has 3 younger cousins.</p>
<p>Alright, not so surprising. You may not even notice a difference.</p>
<p>In Alicetown, the average person has 4 limbs.<br>
In Bobtown, the average person has 3 limbs.</p>
<p>You'd <em>definitely</em> notice.</p>
<p>It's the same absolute difference (4 vs 3) <em>and</em> relative difference (3/4). So what makes limbs more surprising than cousins? Well, partly it's more dramatic &amp; visible, but also because: <em>we expect high variation in the number of someone's younger cousins, but not their number of limbs</em>.</p>
<p>This is why scientists calculate an <strong>"effect size"</strong> or <strong>"standardized mean difference"</strong> ("mean" = average). We take the difference between two groups, then divide by the total amount of variation, <em>to account for how surprising a difference is</em>.</p>
<p>(This is a health article, not a math article, so I'll skip the formulas in this post. If you're curious, <a href="https://www.youtube.com/watch?v=tTgouKMz-eI">: check out this 4 min video</a>.)</p>
<p>Unfortunately for laypeople, the effect size is usually just reported as a number, like "+0.74" for <a href="http://www.lscp.net/persons/ramus/docs/EPR20.pdf">spacing out your studying vs cramming</a>, or "–0.776" for <a href="https://pubmed.ncbi.nlm.nih.gov/20438143/">sleep deprivation on attention</a>.</p>
<p>But what's that <em>mean?</em> How can we make these numbers <em>intuitive?</em></p>
<p>Well, a common way for data to be is <a href="https://en.wikipedia.org/wiki/Normal_distribution">a bell-shaped curve</a> (also called a "normal distribution"). And most of us are, alas, well-acquainted with the bell curve in school grades. ("grading on a curve")</p>
<p>So: school grades give us a useful way to think about standardized effect sizes! We can now convert that number <em>into an actual letter grade:</em></p>
<ul>
<li><strong>F:</strong> -2.0 below average</li>
<li><strong>D:</strong> -1.0 below average</li>
<li><strong>C:</strong> average</li>
<li><strong>B:</strong> +1.0 above average</li>
<li><strong>A:</strong> +2.0 above average</li>
</ul>
<p>(see footnote for more precise ranges.<sup><a href="#fn1" id="fnref1">[1]</a></sup> the units are in "standard deviations", or "sigmas". what's sigma? <s>sigma ba--</s> just a unit of "how far away this is from average, relative to the total variation".)</p>
<p><img src="https://blog.ncase.me/content/stuff/2026-01/depression/bell_grade.png" alt="How to convert effect sizes to letter grades" title="How to convert effect sizes to letter grades"></p>
<p>For example: spacing out your studying, relative to cramming, will on average <em>lift</em> your test scores from a C to a B–. (effect size = +0.74) And short-term sleep deprivation, relative to healthy sleep, will on average <em>tank</em> your ability to pay attention from a C to a D+. (effect size: –0.776)</p>
<p>(Note — when reading about effect sizes, always remember: <em>effect of what, on what, at what dose, for which group, relative to what?</em> See the Data Colada post, <a href="https://datacolada.org/104">Meaningless Means</a>.)</p>
<p>(Note 2 — the standard way of "intuitively" describing effect sizes is Cohen's recommendations: 0.2 = small, 0.5 = medium, 0.8 = large. Personally, I prefer the "school grade letter" comparison, since it's more concrete. But hey, you do you.)</p>
<p>But it's not limited to just grades &amp; academic performance. Effect sizes can also help us understand any kind of difference between groups, in observation or in experiments!</p>
<p>For example...</p>
<hr>


<p>Let's use our school grade analogy, to interpret effect sizes on mental health:</p>
<p><strong>What's an "F in mental health"?</strong> By definition of a bell curve, ~2.3% of people are below –2 sigma (an "F"). (See: <a href="https://homepage.divms.uiowa.edu/~mbognar/applets/normal.html">this bell curve calculator</a>.) <a href="https://www.canada.ca/en/public-health/services/publications/healthy-living/suicide-canada-key-statistics-infographic.html">In Canada</a>, ~2.6% of people had suicidal ideation in 2022, while <a href="https://www.pew.org/en/research-and-analysis/data-visualizations/2024/us-national-trends-and-disparities-in-suicidal-ideation-suicide-attempts-and-health-care-use">in the US</a>, it was ~4.9% in 2019. So, it's not too far off to say: "F in mental health = literally suicidal". (Also, reminder that ~4% is 1-in-25 people. You likely know someone, or <em>are</em> someone, who will feel suicidal this year. Please reach out to your friends &amp; loved ones!)</p>
<p><strong>What's a "D in mental health"?</strong> ~16% of people are below –1 sigma (a "D") on a bell curve. <a href="https://pubmed.ncbi.nlm.nih.gov/12096700/">The Keyes 2002 study</a> estimated that ~14.1% of adults meet the DSM-III criteria for a major depressive episode. So, D = Depressed.</p>
<p><strong>What's an average "C in mental health"?</strong> ~68% of people are within a sigma of average (a "C") on a bell curve. Same above study found that 56.6 percent had moderate mental health. They were neither "languishing" nor "flourishing". I guess C = Could Be Worse.</p>
<p><strong>What's a "B in mental health"?</strong> ~16% of people are <em>above</em> +1 sigma (a "B") on a bell curve. Same above study found that 17.2% of adults are "flourishing". Good for them! B = Flourishing, life is good.</p>
<p><strong>What's an "A in mental health"?</strong> I don't know who these freaks are. I actually <em>could not</em> find any scientific studies on "the +2 sigma in well-being". In contrast, there's <em>lots</em> of research on suicidal ideation, the –2 sigma in well-being. In the absence of any actual data, I'll just say: A = AWESOME</p>
<p><img src="https://blog.ncase.me/content/stuff/2026-01/depression/bell_curve_mental_health.png" alt="Bell curve of mental health, mapped to effect size / letter grade." title="Bell curve of mental health, mapped to effect size / letter grade."></p>
<p>So, if an intervention is found to have an effect size of +1.0, that's like going up a letter grade. If something's found to have an effect size of -2.0, that's like going <em>down</em> two letter grades. And so on.</p>
<p>Okay, so how do we get peoples' "mental health grades" up?</p>
<p>Let's look at antidepressants, Omega-3, and Vitamin D, in turn:</p>
<hr>

<h2>Antidepressants</h2>
<p>The good news is they work. The bad news is they don't work as well as you'd think they may work.</p>
<p><strong><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5889788/">Cipriani et al 2018</a></strong> is a recent meta-analysis (a study collecting lots of previous studies) that investigated 21 different antidepressants. The most effective antidepressant, <em>Amitriptyline</em>, relative to placebo, had an Odds Ratio of 2.13  — <a href="https://www.escal.site/">which converts to</a> a Cohen's d effect size of 0.417 — which is "small-medium" according to Cohen's recommendations. Or, by our school-letter-grade comparison: <strong>the best antidepressant would take your mental health grade from an F to F+, or C to C+.</strong></p>
<p>From Figure 3 of that paper, you can see that Amitriptyline has the highest estimated effect size, while the side effects are no worse than placebo:</p>
<p><img src="https://blog.ncase.me/content/stuff/2026-01/depression/Figure3.jpg" alt="The effect sizes &amp; dropout rates of various antidepressants, vs placebo." title="The effect sizes &amp; dropout rates of various antidepressants, vs placebo."></p>
<p>Sure, "F to F+" <em>can</em> be lifesaving, but… y'know… that's not a lot. And again, this is the effect <em>on average.</em> Some people respond <em>much</em> better to antidepressants… while some respond much worse.</p>
<hr>

<h2>Omega-3</h2>
<p>Keep getting confused on which fat is what? Me too. So, here's a crash course on various fats:</p>
<p>Fatty acids are chains of carbons &amp; hydrogens + two oxygens. They say "OOH" at one end, and "HHH" at the other end:</p>
<p><img src="https://blog.ncase.me/content/stuff/2026-01/depression/fat1.png" alt="Diagram of a fatty acid, details in main text." title="Diagram of a fatty acid, details in main text."></p>
<p>A saturated fatty acid is one where all the carbons' free spots are filled up with hydrogens. (Hence, "saturated") This makes the molecule stick straight out. This is why <em>long</em> saturated fatty acids — like those found in butter — tend to be solid at room temperature.</p>
<p>(Contrary to popular belief, saturated fats don't <em>literally</em> clog your arteries, like grease in plumbing pipes. What happens is <em>{ha ha I don't actually understand this}</em>. <a href="https://www.ahajournals.org/doi/10.1161/cir.0000000000000510">Something about your cholesterol levels &amp; inflammation</a>.)</p>
<p><img src="https://blog.ncase.me/content/stuff/2026-01/depression/fat2.png" alt="Diagram of saturated vs unsaturated fatty acid, details in main text." title="Diagram of saturated vs unsaturated fatty acid, details in main text."></p>
<p>In contrast, <em>unsaturated</em> fatty acids have at least one hydrogen missing. This causes them to have a double-bond "kink" in the molecule. This makes them <em>not</em> stick out, which is why unsaturated fats tend to be liquid at room temperature. <em>Mono-unsaturated</em> fatty acids (MUFAs) — like in olive oil — only have one kink. <em>Poly-unsaturated</em> fatty acids (PUFAs) — like in fatty fish — have two or more kinks. Let's be mature adults about this, please.</p>
<p>For completeness: <em>trans fats</em> are unsaturated fats whose "kink" is twisted around, causing them to go straight. That is the worst sentence I've written all month. The twisted kink is caused by the hydrogens being on opposite sides, hence "trans". (And yes, if they're on the same side it's "cis". Latin was a mistake.) The molecule being straight is why trans fats — which margarine <em>used</em> to be full of  — are solid at room temperature, despite being an unsaturated fat.</p>
<p><img src="https://blog.ncase.me/content/stuff/2026-01/depression/fat3.png" alt="Diagram of how a 'cis' saturated fat becomes a 'trans' fat, details in main text." title="Diagram of how a 'cis' saturated fat becomes a 'trans' fat, details in main text."></p>
<p>It's neat whenever you can trace the history of something right down to its atoms! Margarine was first invented because it's cheaper, and is spreadable straight from the fridge, unlike butter. Margarine (used to be) made by taking <em>unsaturated</em> vegetable oils, which were cheaper than animal fats, then pumping a bunch of hydrogens into it (hence, "hydrogenated oils"). If you <em>completely</em> hydrogenate an oil, it becomes a saturated fat. But they only <em>partially</em> hydrogenated those oils, leading to trans fats, which were cheaper &amp; a spreadable semi-solid at fridge temperature.</p>
<p>In the 1970s &amp; 80s, the US Food &amp; Drug Administration concluded that trans fats were <em>not</em> harmful to humans, and nutritionists <em>promoted</em> margarine over butter, because butter had "unhealthy" saturated fats. <a href="https://www.cspi.org/resource/artificial-trans-fat-timeline">But in the early 1990s</a>, scientists realized that trans fats were <em>even worse</em> for you than saturated fats. Only in the 2010's, did most Western countries start officially banning trans fats. Reminder: policy is often decades behind science.</p>
<p><em>(Hey, what do you call it when you get thiccer on HRT? Trans fat! :D)</em></p>
<p>I need to stop going on infodump tangents. Anyway, Omega-3 is any fatty acid with its first kink at the 3rd carbon from the Omega end ("HHH"), though it can have more kinks later down the chain. (And yes, Omega-6 has its first kink at the 6th carbon, and Omega-9 has its first kink at the 9th carbon. There's nothing <em>physically</em> preventing Omega-4 or Omega-5's from existing, but due to some quirk of evolution, Omega-3, -6, and -9 are the ones biological life uses most. As far as I can tell, there's no specific reason they're all multiples of 3. Probably just a coincidence. There <em>is</em> a less common Omega-7.)</p>
<p><img src="https://blog.ncase.me/content/stuff/2026-01/depression/fat4.png" alt="Diagram of Omega-3, -6, and -9, details in main text." title="Diagram of Omega-3, -6, and -9, details in main text."></p>
<p><em>Finally</em>, there's three main types of Omega-3: EPA (Eicosapentaenoic Acid), DHA (Docosahexaenoic Acid), and ALA (Alpha-Linolenic Acid). ALA is mostly found in plants like chia seeds &amp; walnuts, while EPA &amp; DHA mostly come from seafood, though there <em>are</em> algae-based vegan sources.</p>
<p><em>(Figure 1.1 from <a href="https://atrium.lib.uoguelph.ca/bitstream/10214/9940/1/Roke_Kaitlin_201609_PhD.pdf">Roke 2016</a>.⤵ Thank you Kaitlin Samantha Roke for drawing this coz I'm too lazy to draw it myself. Note how the first double-bond "kink" for all these molecules is at the 3rd carbon from the Omega end — hence why they're all called Omega-3's.)</em></p>
<p><img src="https://blog.ncase.me/content/stuff/2026-01/depression/fat5.png" alt="Diagram of ELA, DHA, &amp; ALA; details in main text." title="Diagram of ELA, DHA, &amp; ALA; details in main text."></p>
<p><strong>EPA &amp; DHA are the focus of this section.</strong> For bio-mechanical reasons I don't understand but I assume someone else does: EPA is the one associated with anti-inflammation, better brain health, and <em>less depression</em>... while DHA isn't. (But DHA is still needed for other stuff, like your neurons' cell walls, so don't cut them out completely!)</p>
<p>(Note: I could not find any <em>experimental</em> trials of ALA on depression, though an <em>observational</em> study in Japan (<a href="https://www.sciencedirect.com/science/article/abs/pii/S2212826313001085">Kurotani et al 2014</a>) finds a correlation between higher ALA and lower depression. But reminder, correlation is not <em>necessarily</em> causation.)</p>
<p>All the above info in a Venn (technically <a href="https://en.wikipedia.org/wiki/Euler_diagram">Euler</a>) diagram:</p>
<p><img src="https://blog.ncase.me/content/stuff/2026-01/depression/fat6.png" alt="Diagram of what I infodumped about just now." title="Diagram of what I infodumped about just now."></p>
<p>Okay, enough yap. Time for the actual data:</p>
<p><strong><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC3534764/">Sublette et al 2011</a></strong> is an older meta-analysis, but it's the only one I could find that tries to estimate the <em>actual "dose-response" curve</em>, which shows: how much effect, for how much treatment. Why is that important? Because one problem with many meta-analyses is they'll do something like: "Study 1 gave patients 1 gram of medicine and saw a +1 improvement in disease, Study 2 gave 10 grams and saw +4 improvement, Study 3 gave 100 grams and saw <em>negative</em> –5 improvement… the average of +1, +4, and –5 is zero... therefore the medicine's effect is zero." ...As mentioned briefly earlier, this is a <a href="https://datacolada.org/104">meaningless mean</a>. That's why we want to know the response <em>at each dose</em>.</p>
<p>So, the Sublette meta-analysis gathered randomized trials studying Omega-3 on depression (vs placebo, of course) and got the following dose-response curve.⤵ Note that the horizontal axis is <em>not</em> just amount of total Omega-3, but specifically <em>the extra amount of "unopposed" EPA, above the amount of DHA.</em> Or in other words, "EPA minus DHA":</p>
<p><img src="https://blog.ncase.me/content/stuff/2026-01/depression/Omega3.jpg" alt="Diagram of dose-response curve, of EPA minus DHA, on depression." title="Diagram of dose-response curve, of EPA minus DHA, on depression."></p>
<p>The top effect size is <strong>around +0.558, which is like going from an F to D–, or C to B–.</strong> You get this maximum effect around 1 to 2 grams of extra EPA, and <em>too much</em> EPA gets worse results. The meta-analysis finds that Omega-3 supplements that are ~60% EPA (and the rest DHA) are optimal.</p>
<p>This finding is roughly in line with later meta-analyses. <a href="https://www.nature.com/articles/s41398-019-0515-5.pdf">Liao et al 2019</a> also finds that ~1 gram of ≥60% EPA is best, but actually found a much higher effect size: +1.03. <a href="https://pubmed.ncbi.nlm.nih.gov/37028202/">Kelaiditis et al 2023</a> also finds 1 to 2g of ≥60% EPA is best, but found a lower effect size of +0.43… which is still <em>as good</em> as the <em>best</em> antidepressant!</p>
<p>Either way, let's boil this down to a recommendation. You want around 1 gram of EPA a day. So if your supplements are 60% EPA, you need 1 gram ÷ 0.6 ~= 1.667 grams = 1667 milligrams. Let's round this down for convenience: <strong>get 1500 mg/day of 60%-EPA Omega-3 supplements.</strong></p>
<p>In comparison, <a href="https://www.healthline.com/nutrition/how-much-omega-3">most official health organizations recommend</a> "250–500 mg <em>combined</em> EPA and DHA each day for healthy adults." <em>That is over three times too low,</em> at least for optimal effects on depression. Which, as we calculated above, is probably around 1500 mg/day. (The official safe dose is 5000 mg/day)</p>
<p>Finally, a (small) study <em>directly</em> investigating the link between suicide &amp; Omega-3. <a href="https://psychiatryonline.org/doi/pdf/10.1176/ajp.2006.163.6.1100">Sublette et al 2006</a>: “Low [DHA] and low Omega-3 proportions [...] predicted risk of suicidal behavior among depressed patients over the 2-year period.” Though keep in mind this is a small study, and it's observational not experimental. Also, weird that contrary to the above studies on depression, <em>DHA</em> predicted suicide but <em>not</em> EPA. Not sure what to make of that.</p>
<p>Bonus: Omega-3 may also boost cognition? <a href="https://www.nature.com/articles/s41598-025-16129-8.pdf">Shahinfar et al 2025</a>: “Enhancement of global cognitive abilities was observed with increasing omega-3 dosage up to 1500 mg/day. [effect size = 1.00, like going from a grade of C to B!], followed by downward trend at higher doses.”</p>
<hr>

<h2>Vitamin D</h2>
<p><strong><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11650176/">Ghaemi et al 2024</a></strong> is a meta-analysis on Vitamin D on depression. Again, it actually estimates a dose-response curve! Below is Figure 1 + Table 2, showing the effect of Vitamin D dosage on depression vs placebo. The solid line is the average estimated effect, dashed lines are 95% confidence interval. Note the effect size is negative in this figure, because they're measuring <em>reduction</em> in depressive symptoms:</p>
<p><img src="https://blog.ncase.me/content/stuff/2026-01/depression/VitaminD.png" alt="The effect size (with uncertainty) of Vitamin D dosage on depressive symptoms." title="The effect size (with uncertainty) of Vitamin D dosage on depressive symptoms."></p>
<p><strong>The upper range of uncertainty is lowest at 5000 IU (International Units) of Vitamin D a day</strong>, with an estimated effect size of 1.82, with a 95% uncertainty range, from 0.98 to 2.66. <strong>An effect size of 1.82 is like taking your mental health from an F to a C–, or a C to an A–!</strong> And even in the <em>most pessimistic</em> case, 0.98, that's still <em>over twice as effective</em> as the top antidepressant!</p>
<p>(The paper's summary says <em>8000 IU</em> is best, with effect size 2.04, but there's much greater uncertainty there. The paper also finds that longer studies had smaller effects than shorter studies, but this does <em>not</em> necessarily mean Vitamin D's effects are short-lived. Looking at Supplementary Table 4, it seems this is partly because longer studies used <em>lower</em> average daily doses. For example, one 52-week study only gave participants 400 IU a day.)</p>
<p>This meta-analysis includes trials with participants who <em>don't</em> have Vitamin D deficiency. There's still a good effect of Vitamin D on depression for them, even if smaller! Though, you probably <em>are</em> lacking Vitamin D: <a href="https://pubmed.ncbi.nlm.nih.gov/29644951/">Liu et al 2018</a> finds that a bit under half of all adults (41.4%) have Vitamin D Insufficiency.</p>
<p>And that's according to <a href="https://www.healthline.com/nutrition/vitamin-d-dosage">the official recommendation</a>, of 400-800 IU a day… which is <em>is too damn low</em>. Even the official <em>maximum safe dose</em> of Vitamin D, of 4000 IU/day, is too low. <a href="https://pubmed.ncbi.nlm.nih.gov/30611908/">McCullough et al 2019</a> gave over thousands of patients 5,000 to 10,000 IU/day, for <em>seven years</em>, and there were <em>zero</em> cases of serious side effects. This is in line with <a href="https://pubmed.ncbi.nlm.nih.gov/31746327/">Billington et al 2020</a>, a 3-year-long double-blinded randomized controlled trial, where they found "the safety profile of vitamin D supplementation is similar for doses of 400, 4000, and 10,000 IU/day." (though "<em>mild</em> hypercalcemia" increased from 3% to 9%. IMHO, that's a small cost for reducing the risk of major depression &amp; suicide.)</p>
<p>And it makes sense that 10,000 IU a day <em>should</em> be safe. Your skin, exposed to the Sun's ultraviolet rays, can synthesize up to (the equivalent of) 10,000 IU a day, before plateauing out. Source is <a href="https://www.sciencedirect.com/science/article/pii/S0002916522043763">Vieth 1999</a>: “Because vitamin D is potentially toxic, intake of [1000 IU/day] has been avoided even though the weight of evidence shows that the currently accepted [limit] of [2000 IU/day] is too low by at least 5-fold.” (So why are all the official sources still so paranoid about Vitamin D? Well, unfortunately, official/governmental policy is always a few decades behind the science in <em>any</em> field. See Also: the trans fat debate, everything about educational policy.)</p>
<p>Speaking of the Sun, why take supplements instead of just getting Vitamin D from Sun exposure? Well, <a href="https://pubmed.ncbi.nlm.nih.gov/29659012/">skin cancer</a>. But also: because Sun-Skin D varies greatly depending on the season, your latitude, and your skin type. There's less ultraviolet rays from the Sun in winter/fall, and at latitudes further from the equator. And <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10861575/">the darker your skin is, the less Vitamin D your skin makes for the same amount of Sun exposure</a>. As expected from the bio-physics of skin, Black adults have <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC6075634/">the highest prevalence of Vitamin D deficiency</a> (82.1%!!), followed by Hispanic adults (62.9%). (But hey, at least Black adults have the lowest incidence of skin cancer. You win some you lose some.) The point is: speaking as someone with Southeast Asian skin, who's currently in Canada during winter... even if I stood outside naked for hours, I'd get approximately <em>zero</em> IU/day of Vitamin D from the Sun. Thus: supplements.</p>
<p>Finally, a meta-analysis <em>directly</em> measuring the effect of Vitamin D on suicide rates. <a href="https://link.springer.com/content/pdf/10.1186/s12888-025-06613-w.pdf">Yu et al 2025</a>: “Vitamin D in patients with [suicidal behaviours] were significantly lower than in controls (standardized mean difference: –0.69, or a 'medium' difference)”. Reminder that this paper <em>by itself</em> only measures correlation, not causation — but combined with the above experiments of Vitamin D on depression, I think it's reasonable to guess it's partly causal.</p>
<p>To recap:</p>
<ul>
<li>Almost half of you have a Vitamin D deficiency according to the official recommendation (800 IU/day).</li>
<li>And the official recommendation is <em>way</em> too low. Even the official <em>maximum</em> safe dose (4000 IU/day) is below the optimal Vitamin D for depression (5000 IU/day) or what your body can produce from the Sun in optimal conditions (10,000 IU/day). Recent randomized controlled trials confirm that 10,000 IU/day is, indeed, mostly safe.</li>
<li>Your daily reminder than official policy is often decades behind the science.</li>
</ul>
<p>Bonus: Vitamin D supplementation was found in several randomized controlled trials <a href="https://pubmed.ncbi.nlm.nih.gov/39225947/">to reduce mortality from Covid-19</a>! It <a href="https://www.sciencedirect.com/science/article/pii/S2161831322010274">probably helps guard against influenza</a> too, though the evidence is small &amp; early.</p>
<hr>

<h2>Conclusion: <em>All this time, you lacked the Vitamin?</em></h2>
<p>Scurvy is caused by a lack of Vitamin C. It's a condition that causes your wounds to re-open up &amp; teeth to fall out. Scurvy used to kill <em>almost half(!)</em> of all sailors on major expeditions; it's estimated millions died. It can be cured by eating lemons.</p>
<p>Rickets is mostly caused by a lack of Vitamin D. It's a condition where kids' bones go all soft and deformed. During the Industrial Revolution, up to 80% of kids suffered from it. It can be prevented with cod liver oil.</p>
<p>Goiters is mostly caused by a lack of Iodine. It's a condition where the thyroid gland in your neck swells up painfully, to the size of an apple. During WWI, a <em>third</em> of adult men had goiters. It can be prevented with iodized salt.</p>
<p><img src="https://blog.ncase.me/content/stuff/2026-01/depression/The-Vitamin.png" alt="Tumblr meme: 'All this time, you lacked The Vitamin? And yet you persisted?'" title="Tumblr meme: 'All this time, you lacked The Vitamin? And yet you persisted?'"></p>
<p><a href="https://ourworldindata.org/mental-health">About 1 in 4 people are expected to have clinical depression sometime in their life</a>. Depression is the #1 source of the global "burden from disease" in the mental health category, <a href="https://ourworldindata.org/burden-of-disease#how-do-different-diseases-and-disabilities-contribute-towards-the-burden-of-disease">and <em>that</em> category is the #6 burden of disease in the world</a>, above Alzheimer's, malaria, and sexually transmitted infections.</p>
<p>(But honestly, did you need those stats? This is likely a lived experience for a lot of you reading this.)</p>
<p>The effective altruists are all, <a href="https://www.givewell.org/how-much-does-it-cost-to-save-a-life">"woah for just $3000 you can prevent a child's death from malaria"</a> — and that's great! save them kids! — but where's the fanfare for the accumulating evidence that, "woah with cheap daily supplements we can save millions from suicide &amp; depressed lives"?</p>
<p>Over and over again throughout history, some horrific thing that caused millions to suffer, turned out to be "yeah you were missing this one molecule lol". To be clear: not everything is gonna be <em>that</em> simple, and mental health is <em>not</em> "just" chemistry. Also, all the numbers on this page have with large error bars &amp; uncertainty, more research is needed.</p>
<p>But, as of right now, I feel I can at least confidently claim the following:</p>
<ul>
<li>Vitamin D and Omega-3 are both <em>at least on par</em> with antidepressants.</li>
<li>The evidence is much stronger for Vitamin D; it's very plausibly at least <em>twice</em> as good as antidepressants.</li>
<li>Both supplements are cheap and safe, so what's the harm of trying? (positive "expected value" for this bet)</li>
</ul>
<p>So:</p>
<p><strong>MY SPECIFIC RECOMMENDATIONS FOR YOU TO DO A.S.A.P:</strong></p>
<ul>
<li>Go to a pharmacy, buy the following supplements over-the-counter, in whatever form you like: (I like the easy-to-swallow gel capsules)</li>
<li><strong>Vitamin D</strong>
<ul>
<li>🌱 By default, Vitamin D supplements are derived from… (quick web search)… <em>the grease in sheep's wool?</em> Huh. Also fish liver oil. Anyway, if you're vegan, make sure your bottle specifically says "vegan" or "from lichen/mushrooms". (If you're vegetarian, the sheep's-wool Vitamin D is fine, they don't kill the sheep for it.)</li>
</ul>
</li>
<li><strong>Omega-3 <em>where EPA is ~60% of the Omega-3 total.</em></strong> For example, my 500mg Omega-3 capsules have 300mg EPA, 200mg DHA.
<ul>
<li>🌱 By default, Omega-3 supplements come from fish. If you're veg(etari)?an, there <em>are</em> plant-based sources of Omega-3, but look carefully: most vegan Omega-3 supplements provide <em>more DHA than EPA</em>, which the above studies suggest fully cancel out the antidepressant effect. <em>Double check the nutritional label to make sure it's ≥60% EPA.</em> For example, <a href="https://www.amazon.ca/Natures-Way-NutraVege-Plant-Based-Vegetarian/dp/B078T4DC2K?th=1">this one is 300mg EPA + 200mg DHA</a>. (<em>not</em> an affiliate link)</li>
</ul>
</li>
</ul>
<p><strong>Then, every day:</strong></p>
<ul>
<li><strong>Take ~5000 IU of Vitamin D</strong>
<ul>
<li>⚠️ be cautious if you have kidney stones, or are on medications that could interact with Vitamin D. "ask your doctor".</li>
<li>4,000 IU is the "official maximum safe dose", if you understandably don't trust a random internet blogger, even though she cited academic sources.</li>
<li>10,000 IU if you're feeling daring / have darker skin / live in less sunny climates.</li>
<li>bonus: may improve immune response to Covid &amp; influenza?</li>
</ul>
</li>
<li><strong>Take ~1500 mg of ≥60%-EPA Omega-3</strong>
<ul>
<li>⚠️ be cautious if you're on blood thinners, or other medications that could interact with Omega-3. again, "ask your doctor".</li>
<li>bonus: may improve cognition?</li>
</ul>
</li>
<li>(Don't quit your existing antidepressants if they're net-positive for you!)
<ul>
<li>you may also want to ask your doctor about <em>Amitriptyline</em>, or those other best-effect-size antidepressants.</li>
</ul>
</li>
</ul>
<p>Can you get these doses of Vitamin D &amp; Omega-3 through whole foods alone, no supplements? Probably, but it'd be expensive &amp; tedious: you'd have to eat something like 2,000 calories of farmed salmon <em>a day</em> to get 5,000 IU/day of Vitamin D. As for Omega-3, eating mostly oily fishes <em>would</em> get you &gt;1000mg of Omega-3, but they'd be <em>more DHA than EPA</em>, which the above studies suggest would cancel out the antidepressant effects.</p>
<p><strong>The effect sizes on depression:</strong></p>
<ul>
<li>The best antidepressant: <strong>+0.417</strong>
<ul>
<li>like your mental health grade going from F to F+, or C to C+</li>
</ul>
</li>
<li>1500mg of ≥60%-EPA Omega-3: <strong>+0.558</strong>
<ul>
<li>like your mental health grade going from F to D–, or C to B–</li>
</ul>
</li>
<li>5000 IU of Vitamin D: <strong>+1.82</strong>
<ul>
<li>like your mental health grade going from F to C–, or C to A–</li>
</ul>
</li>
</ul>
<p>For completeness &amp; comparison, here's the effect size of other things on depression:</p>
<ul>
<li>Any <a href="https://en.wikipedia.org/wiki/Dodo_bird_verdict">mainstream "bona-fide" psychotherapy</a> (CBT, Psychodynamic, Humanist, Solutions-Focused): <strong>+0.35</strong>, source: <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5244449/">Kamenov et al 2016</a>
<ul>
<li>like going from C to C+</li>
</ul>
</li>
<li>Aerobic/Cardio Exercise: <strong>+0.79</strong>, source <a href="https://pure-oai.bham.ac.uk/ws/portalfiles/portal/54143117/Ioannis_Morres_et_al_Aerobic_exercise_for_adult_patients_Depression_and_Anxiety_2018.pdf">Ioannis et al 2018</a>
<ul>
<li>like going from C to B–</li>
<li>(dose: "45 minutes, at moderate intensity, three times/week" ⇒ ~20 min/day)</li>
</ul>
</li>
<li>Good Sleep: <strong>+1.10(???)</strong>, a <em>lot</em> of interpretation &amp; calculations, see footnote<sup><a href="#fn2" id="fnref2">[2]</a></sup>
<ul>
<li>like going from C to B</li>
<li>(dose: going from moderate insomnia to healthy sleep)</li>
</ul>
</li>
<li>Bright Light Therapy: <strong>+0.487</strong>, source <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11447633/">Menegaz de Almeida et al 2025</a>
<ul>
<li>(the above paper reports Odds Ratio of 2.42, <a href="https://www.escal.site/">which converts to</a> Cohen's d effect size of +0.487)</li>
<li>like going from C to C+</li>
<li>I went <a href="https://www.nytimes.com/wirecutter/reviews/best-light-therapy-lamp/">with Wirecutter's recommendation</a> for a UV-free 10,000 lux lamp.</li>
<li>(dose: 10,000 lux, 30 min a day)</li>
</ul>
</li>
<li>Mindfulness Meditation: <strong>+0.42</strong>, source <a href="https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2019.00193/full">Breedvelt et al 2019</a>
<ul>
<li>like going from C to C+</li>
<li>(dose: 7 weeks, "153 min each week" ⇒ ~20 min/day)</li>
</ul>
</li>
</ul>
<p><img src="https://blog.ncase.me/content/stuff/2026-01/depression/on-depression-summary.png" alt="Diagram of all the above estimated effect sizes" title="Diagram of all the above estimated effect sizes"></p>
<p>(And remember, you can <em>stack</em> any of the above interventions to get an even larger effect! You can't just naively add up the effect sizes, but I'd be surprised if the effect of {vitamin d + omega-3 + bright lamps + cardio + good sleep + meditation} <em>combined</em> ends up being less than +2.00. Two letter grades up means going from D to B, or, theoretically, from clinically depressed to flourishing! For more papers &amp; my working research notes on "best bang for buck on depression", <a href="https://docs.google.com/document/d/1hjNxJmNjoVktrJDFPtFH1hgzKmGpZkRFQ6Vwf0s7c6w/edit?tab=t.0#heading=h.e0blw3xq3cvm">check out this Google Doc</a>.)</p>
<p>Also, remember that all the above estimates are uncertain. And in general, when scientists replicate psychology experiments more rigorously, the effect size usually shrinks by ½. But, I think the overall <em>qualitative</em> picture is still strong: there <em>exist</em> high bang-for-buck ways to reduce depression, which are <em>at least</em> on par with drugs &amp; therapy (possibly 2x to 4x better), that aren't (yet) common knowledge amongst policymakers &amp; the public. And again, they're dirt cheap with minor-to-no adverse side effects. Moderate chance of a big win, for a known tiny cost. That's a positive "expected value" bet right there.</p>
<p>I got onto this research rabbithole a few months ago while borrowing my housemate's ADHD meds, which I may or may not eventually collect into a "JOYMAXXING" informal meta-meta-analysis. (<a href="https://youtu.be/JOj97Edna7k?si=xAUt3Kp54RyfGX50&amp;t=334">: See me yap about it on video as a cartoon cat</a>.) But for this blog post, I wanted to dive deeper into Vitamin D and Omega-3, since their effect sizes are so huge, <em>and</em> they're insultingly cheap &amp; easy, compared to therapy or regular cardio.</p>
<p>Stay safe this winter, keep away the seasonal depression. Get your supplements, and reach out to your friends &amp; loved ones!</p>
<p>💖,<br>
~ Nicky Case</p>

<hr>
<section>
<ol>
<li id="fn1"><p>I made up these ranges by requiring the standard letter grades F,D,C,B,A, to have their centers be -2,-1,0,+1,+2. Then, I made sure all in-between grades like C+ or A– had equal intervals. Each interval is +/- ⅙, or ⅓ wide:</p>
<ul>
<li>F---: -3.16 to -2.83</li>
<li>F--: -2.82 to -2.50</li>
<li>F–: -2.49 to -2.17</li>
<li><strong>F: -2.16 to -1.83</strong></li>
<li>F+: -1.82 to -1.50</li>
<li>D–: -1.49 to -1.17</li>
<li><strong>D: -1.16 to -0.83</strong></li>
<li>D+: -0.82 to -0.50</li>
<li>C–: -0.49 to -0.17</li>
<li><strong>C: -0.16 to +0.17</strong></li>
<li>C+: +0.18 to +0.50</li>
<li>B–: +0.51 to +0.83</li>
<li><strong>B: +0.84 to +1.17</strong></li>
<li>B+: +1.18 to +1.50</li>
<li>A–: +1.51 to +1.83</li>
<li><strong>A: +1.84 to +2.17</strong></li>
<li>A+: +2.18 to +2.50</li>
<li>A++: +2.51 to +2.83</li>
<li>A+++: +2.84 to +3.17</li>
</ul>
 <a href="#fnref1">↩︎</a></li>
<li id="fn2"><p><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10039857/">Lee et al 2023</a> reports the following effect sizes. Digital therapy for Insomnia → Sleep = 0.76, and Digital therapy for Insomnia → Depression = 0.42. Assuming the therapy <em>for insomnia specifically</em> affects depression <em>only</em> through better sleep (Digital therapy for Insomnia → Sleep → Depression), we can do an <a href="https://cameron.econ.ucdavis.edu/e240a/ch04iv.pdf">"Instrumental Variable"</a> estimate of the effect of Sleep → Depression = 0.42 / 0.76 = 0.55. <strong>To be precise: this is saying, if you improve your sleep by 1 standard deviation, on average your depression improves by 0.55 standard deviations.</strong></p>
<p>So: how many standard deviations is going from "moderate insomnia" to "healthy sleep"? The standard measure is the Insomnia Severity Index (ISI), which <a href="https://www.sleepprimarycareresources.org.au/questionnaires/isi">you can take online</a>. A score of 0–7 means no insomnia, 8–14 is subclinical insomnia, 15–21 is clinical insomnia (moderate), 22–28 is clinical insomnia (severe). Let's be conservative and say we're just going from barely clinical to barely healthy: 15 to 7, or a reduction of 8 points. <a href="https://pubmed.ncbi.nlm.nih.gov/19689221/">Yang et al 2009</a> says a 6-point reduction is 1.5 standard deviations, which means 4 points is 1 standard deviation. So a reduction of 8 points is 2 standard deviations. <strong>So, if you improve your sleep from insomniac to healthy, you improve by at least 8 points, which is 2 standard deviations, so your depression should improve by 2 × 0.55 standard deviations, or ~1.10.</strong></p>
<p>Reminder that my estimate is <em>full</em> of assumptions upon assumptions &amp; these error bars will compound. But I'd be surprised if the true causal effect of going from insomniac to healthy sleep isn't <em>at least</em> a "large" +0.8 effect. <a href="#fnref2">↩︎</a></p>
</li>
</ol>
</section>


	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Europe's next-generation weather satellite sends back first images (580 pts)]]></title>
            <link>https://www.esa.int/Applications/Observing_the_Earth/Meteorological_missions/meteosat_third_generation/Europe_s_next-generation_weather_satellite_sends_back_first_images</link>
            <guid>46806773</guid>
            <pubDate>Thu, 29 Jan 2026 07:07:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.esa.int/Applications/Observing_the_Earth/Meteorological_missions/meteosat_third_generation/Europe_s_next-generation_weather_satellite_sends_back_first_images">https://www.esa.int/Applications/Observing_the_Earth/Meteorological_missions/meteosat_third_generation/Europe_s_next-generation_weather_satellite_sends_back_first_images</a>, See on <a href="https://news.ycombinator.com/item?id=46806773">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

<header>
	<span>Applications</span>
	
	<p><span>27/01/2026</span>
				<span><span id="viewcount">19067</span><small> views</small></span>
										<span><span id="ezsr_total_27080629">44</span><small> likes</small></span>
				
	</p>
</header>





<p>The first images from the Meteosat Third Generation-Sounder satellite have been shared at the European Space Conference in Brussels, showing how the mission will provide data on temperature and humidity, for more accurate weather forecasting over Europe and northern Africa.</p>

<div>
				
		<p>The images from Meteosat Third Generation-Sounder (MTG-S) show a full-disc image of Earth as seen from geostationary orbit, about 36 000 km above Earth’s surface. These images were captured on 15 November 2025 by the satellite’s Infrared Sounder instrument.</p><p>In the ‘temperature’ image (below), the Infrared Sounder used a long-wave infrared channel, which measured Earth’s surface temperature as well as the temperature at the top of clouds. Dark red corresponds to high temperatures, mainly on the warmer land surfaces, while blue corresponds to lower temperatures, typically on the top of clouds.</p><p>As would be expected, most of the warmest (dark red) areas in this image are on the continents of Africa and South America. In the top-centre of the image, the outline of the coast of western Africa is clearly visible in dark red, with the Cape Verde peninsula, home to Senegal’s capital Dakar, visible as among the warmest areas in this image. In the bottom-right of the image, the western coast of Namibia and South Africa are also visible in red beneath a swirl of cold cloud shown in blue, while the northeast coast of Brazil is visible in dark red on the left of the image.</p>
	</div>
			
    
							
														
																	



							
				
								
						
								
												<div>
				<figure>
					<a href="https://www.esa.int/ESA_Multimedia/Images/2026/01/Global_surface_and_cloud-top_temperatures_by_MTG-Sounder">
				<img src="https://www.esa.int/var/esa/storage/images/esa_multimedia/images/2026/01/global_surface_and_cloud-top_temperatures_by_mtg-sounder/27080438-4-eng-GB/Global_surface_and_cloud-top_temperatures_by_MTG-Sounder_article.jpg" alt="Global surface and cloud-top temperatures by MTG-Sounder ">
			</a>
				<figcaption>
							<a href="https://www.esa.int/ESA_Multimedia/Images/2026/01/Global_surface_and_cloud-top_temperatures_by_MTG-Sounder">Global surface and cloud-top temperatures by MTG-Sounder </a>
								</figcaption>
	</figure>	
		<p>The ‘humidity’ image (below) was captured using the Infrared Sounder’s medium-wave infrared channel, which measures humidity in Earth’s atmosphere. Blue colours correspond to regions in the atmosphere with higher humidity, while red colours correspond to lower humidity in the atmosphere.</p><p>The outlines of landmasses are not visible in this image. The areas of least atmospheric humidity, shown in dark red, are seen approximately over the Sahara Desert and the Middle East (top of image), while a large area of ‘dry’ atmosphere also covers part of the South Atlantic Ocean (centre of image). Numerous patches of high humidity are seen in dark blue over the eastern part of the African continent as well as in high and low latitudes.</p>	</div>	
    
							
														
																	



							
				
								
						
								
												<div>
				<figure>
					<a href="https://www.esa.int/ESA_Multimedia/Images/2026/01/Global_air_humidity_by_MTG-Sounder">
				<img src="https://www.esa.int/var/esa/storage/images/esa_multimedia/images/2026/01/global_air_humidity_by_mtg-sounder/27080485-4-eng-GB/Global_air_humidity_by_MTG-Sounder_article.jpg" alt="Global air humidity by MTG-Sounder ">
			</a>
				<figcaption>
							<a href="https://www.esa.int/ESA_Multimedia/Images/2026/01/Global_air_humidity_by_MTG-Sounder">Global air humidity by MTG-Sounder </a>
								</figcaption>
	</figure>	
		<p>Below we see a close-up from MTG-Sounder of the European continent and part of northern Africa. Like the first image above, here we see heat from land surfaces and temperatures at the top of clouds. The heat from the African continent is seen in red in the lower part of the image, while a dark blue weather front covers Spain and Portugal. The Italian peninsula is in the centre of the image.</p>	</div>	
    
							
														
																	



							
				
								
						
								
									<div>
				<figure>
					<a href="https://www.esa.int/ESA_Multimedia/Images/2026/01/Temperatures_over_Europe_and_northern_Africa_by_MTG-Sounder">
				<img src="https://www.esa.int/var/esa/storage/images/esa_multimedia/images/2026/01/temperatures_over_europe_and_northern_africa_by_mtg-sounder/27082458-1-eng-GB/Temperatures_over_Europe_and_northern_Africa_by_MTG-Sounder_article.jpg" alt="Temperatures over Europe and northern Africa by MTG-Sounder">
			</a>
				<figcaption>
							<a href="https://www.esa.int/ESA_Multimedia/Images/2026/01/Temperatures_over_Europe_and_northern_Africa_by_MTG-Sounder">Temperatures over Europe and northern Africa by MTG-Sounder</a>
								</figcaption>
	</figure>	
		<p>And the animation (below) uses data from the MTG-Sounder satellite to track the eruption of Ethiopia's Hayli Gubbi volcano on 23 November 2025. The background imagery shows surface temperature changes while infrared channels highlight the developing ash plume. The satellite's timely observations enable tracking of the evolving ash plume over time.</p>	</div>	
    
							
														
																								



				
				
								
						
								
						<div>
				<div>
		<a href="https://www.esa.int/ESA_Multimedia/Videos/2026/01/Hayli_Gubbi_eruption_in_Ethiopia_by_MTG-Sounder">
		<div>
				

   <p><img src="https://www.esa.int/extension/pillars/design/pillars/images/play-button.svg" alt="Play"></p>
   <p><img src="https://www.esa.int/var/esa/storage/images/esa_multimedia/videos/2026/01/hayli_gubbi_eruption_in_ethiopia_by_mtg-sounder/27082378-1-eng-GB/Hayli_Gubbi_eruption_in_Ethiopia_by_MTG-Sounder_pillars.png" alt="$video.data_map.short_description.content">

 
		</p></div>
		</a>
				<p>
			Hayli Gubbi eruption in Ethiopia, by MTG-Sounder
			<br><a href="https://www.esa.int/ESA_Multimedia/Videos/2026/01/Hayli_Gubbi_eruption_in_Ethiopia_by_MTG-Sounder">Access the video</a>
		</p>
			</div>	
		<h4>Next-generation weather forecasting</h4><p>MTG is a world-class Earth observation mission developed by the European Space Agency (ESA) with European partners to address scientific and societal challenges. The mission provides game-changing data for forecasting weather and air quality over Europe.</p><p>The satellite’s geostationary position above the equator means it maintains a fixed position relative to Earth, following the same area on the planet’s surface as we rotate. This enables it to provide coverage of Europe and part of northern Africa on a 15-minute repeat cycle. It supplies new data on temperature and humidity over Europe every 30 minutes, supplying meteorologists with a complete weather picture of the region and complementing data on cloud formation and lightning from the MTG-Imager (MTG-I) satellite.</p>	</div>	
    
							
														
																	



							
				
								
						
								
												<div>
				<figure>
					<a href="https://www.esa.int/ESA_Multimedia/Images/2025/02/MTG-Sounder_satellite_over_the_equator">
				<img src="https://www.esa.int/var/esa/storage/images/esa_multimedia/images/2025/02/mtg-sounder_satellite_over_the_equator/26586287-1-eng-GB/MTG-Sounder_satellite_over_the_equator_article.jpg" alt="MTG-Sounder satellite over the equator">
			</a>
				<figcaption>
							<a href="https://www.esa.int/ESA_Multimedia/Images/2025/02/MTG-Sounder_satellite_over_the_equator">MTG-Sounder satellite over the equator</a>
								</figcaption>
	</figure>	
		<p>ESA’s Director of Earth Observation Programmes, Simonetta Cheli, said, “Seeing the first Infrared Sounder images from the MTG-Sounder satellite really brings this mission and its potential to life. We expect data from this mission to change the way we forecast severe storms over Europe – and this is very exciting for communities and citizens, as well as for meteorologists and climatologists. As ever, the outstanding work done by our teams in collaboration with long-standing partners, including Eumetsat, the European Commission and dozens of European industry teams, means we now have the ability to predict extreme weather events in more accurate and timely ways than ever before.”</p><h4>A hyperspectral view over Europe</h4><p>The Infrared Sounder instrument on board MTG-S is the first European hyperspectral sounding instrument in geostationary orbit. It is designed to generate a completely new type of data product. It uses interferometric techniques, which analyse miniscule patterns in light waves, to capture data on temperature and humidity, as well as being able to measure wind and trace gases in the atmosphere. The data will eventually be used to generate three-dimensional maps of the atmosphere, helping to improve the accuracy of weather forecasting, especially for nowcasting rapidly evolving storms.</p><p>“It’s fantastic to see the first images from this groundbreaking mission,” said James Champion, ESA’s MTG Project Manager. “This satellite has been 15 years in development and will revolutionise weather forecasting and especially nowcasting. The ability to vertically profile the full Earth’s disk with a repeat cycle of only 30 minutes for Europe is an incredible accomplishment!”</p>	</div>	
    
							
														
																	



							
				
								
						
								
												<div>
				<figure>
					<a href="https://www.esa.int/ESA_Multimedia/Images/2024/07/MTG-S_patch">
				<img src="https://www.esa.int/var/esa/storage/images/esa_multimedia/images/2024/07/mtg-s_patch/26224166-1-eng-GB/MTG-S_patch_article.png" alt=" MTG-S patch">
			</a>
				<figcaption>
							<a href="https://www.esa.int/ESA_Multimedia/Images/2024/07/MTG-S_patch"> MTG-S patch</a>
								</figcaption>
	</figure>	
		<p>“I’m excited that we can share these first images from the Infrared Sounder, which showcase just a small selection of the 1700 infrared channels continuously acquired by the instrument as it observes Earth,” said Pieter Van den Braembussche, MTG System and Payload Manager at ESA. “By combining all 1700 channels, we will soon be able to generate three dimensional maps of temperature, humidity and even trace gases in the atmosphere. This capability will offer a completely new perspective on Earth’s atmosphere, not previously available in Europe, and is expected to help forecasters predict severe storms earlier than is possible today.”</p>	</div>	
	<div>
	<h2>About MTG-Sounder</h2>
	    
						
		<p>The MTG mission currently has two satellites in orbit: MTG-I and MTG-S. The second Imager will be launched later in 2026.</p><p>MTG-S was launched on 1 July 2025. Thales Alenia Space is the prime contractor for the overall MTG mission, with OHB Systems responsible for the MTG-Sounder satellite. Mission control and data distribution are managed by Eumetsat.</p><p>The MTG-S satellite also hosts the <a href="https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-4" target="_blank">Copernicus Sentinel-4 mission</a>, which consists of an ultraviolet, visible and near-infrared (UVN) imaging spectrometer. Sentinel-4 delivered <a href="https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-4/Sentinel-4_offers_first_glimpses_of_air_pollutants" target="_blank">its first images</a> last year.</p>	</div>	
    
							
														
																								



				
				
								
						
								
						<div>
		<a href="https://www.esa.int/ESA_Multimedia/Videos/2025/07/MTG-S1_and_Copernicus_Sentinel-4_mission_highlights">
		<div>
				

   <p><img src="https://www.esa.int/extension/pillars/design/pillars/images/play-button.svg" alt="Play"></p>
   <p><img src="https://www.esa.int/var/esa/storage/images/esa_multimedia/videos/2025/07/mtg-s1_and_copernicus_sentinel-4_mission_highlights/26777490-3-eng-GB/MTG-S1_and_Copernicus_Sentinel-4_mission_highlights_pillars.png" alt="$video.data_map.short_description.content">

 
		</p></div>
		</a>
				<p>
			MTG-S1 and Copernicus Sentinel-4 mission highlights 
			<br><a href="https://www.esa.int/ESA_Multimedia/Videos/2025/07/MTG-S1_and_Copernicus_Sentinel-4_mission_highlights">Access the video</a>
		</p>
			</div>	
    
						
    
					



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We can't send mail farther than 500 miles (2002) (604 pts)]]></title>
            <link>https://web.mit.edu/jemorris/humor/500-miles</link>
            <guid>46805665</guid>
            <pubDate>Thu, 29 Jan 2026 03:58:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.mit.edu/jemorris/humor/500-miles">https://web.mit.edu/jemorris/humor/500-miles</a>, See on <a href="https://news.ycombinator.com/item?id=46805665">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Maine’s ‘Lobster Lady’ who fished for nearly a century dies aged 105 (224 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2026/jan/28/maine-lobster-lady-dies-aged-105</link>
            <guid>46804854</guid>
            <pubDate>Thu, 29 Jan 2026 02:11:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2026/jan/28/maine-lobster-lady-dies-aged-105">https://www.theguardian.com/us-news/2026/jan/28/maine-lobster-lady-dies-aged-105</a>, See on <a href="https://news.ycombinator.com/item?id=46804854">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><a href="https://www.theguardian.com/us-news/maine" data-link-name="in body link">Maine</a>’s governor has hailed the life of a woman who spent nearly 100 years fishing for lobsters as “amazing” and expressed hopes that her memory inspires “the next century of hardworking” fishers in the state.</p><p>The subject of Governor Janet Mills’ tribute, Virginia “Ginny” Oliver, died on 21 January at age 105, according to an obituary <a href="https://www.legacy.com/us/obituaries/legacyremembers/virginia-oliver-obituary?id=60635890" data-link-name="in body link">published</a> on Monday by her family.</p><p>Some regard stories such as that of Oliver, who came to be known as her state’s “Lobster Lady”, as evidence of the growing number of Americans who extend their working days well past the typical retirement age as the cost of living in the US has soared, wages have stagnated and many therefore have been unable to save.</p><p>Nonetheless, as recently as 2021, Oliver told the Associated Press she fell in love with trapping lobsters from the moment she started in the business at eight years old, alongside her father and older brother.</p><p>“I like doing it – I like being along the water,” she said when discussing her career in the largely male-dominated industry she chose. “And so I’m going to keep on doing it just as long as I can.”</p><p>Oliver would get up before dawn and use small fish colloquially known as poagies to lure lobsters from her boat, the Virginia, which was first owned by her late husband. As she established a remarkable 97-year tenure on the waters, and word of it spread, she became the subject of documentaries, major US television networks’ news stories and children’s books, including one titled The Lobster Lady, her obituary recounted.</p><p><a href="https://www.theguardian.com/film/mark-hamill" data-link-name="in body link">Mark Hamill</a>, the famed actor, was among those who joined the following that Oliver developed throughout the years. Hamill, best known for his role as Luke Skywalker in the Star Wars film saga, “celebrated her tenacity on social media”, Oliver’s obituary noted.</p><p>The obituary also said that Oliver at one point earned an honorary invitation to join Great Britain’s Cardiff Royal Naval Association. Mills once presented Oliver with a special recognition on her birthday.</p><p>“Despite her fame, friends and family said she remained humble and spirited,” Oliver’s obituary added. “Her personal aesthetic delighted her fans – she wore lipstick and earrings every day she went out on the boat, because, as she said, ‘you never know who you are going to see.’”</p><p>Lobster evolved from working-class food to a pricey restaurant delicacy over the course of Oliver’s fishing life. Its price per pound swelled from 28 cents when she first started to $6.14 – or 22 times more expensive.</p><p>Oliver fished for lobster until a fall at age 103, said <a href="https://www.facebook.com/barbarawalsh.author/posts/i-always-teared-up-when-i-hugged-ginny-goodbye-wondering-if-it-would-be-the-last/1658293695150785/" data-link-name="in body link">a statement</a> from her friend, author and Pulitzer prize-winning journalist Barbara Walsh.</p><p>Walsh joined Mills in paying tribute to Oliver, saying the late fisher “believed in living, laughing and doing what she loved”.</p><p>“She was sassy and spirited, always declaring on land and at sea, ‘I’m the boss,’” Walsh’s tribute statement said. “Sail on, sweet Ginny. May your spirit forever soar above the sea.”</p><p>Meanwhile, the <a href="https://www.theguardian.com/us-news/maine" data-link-name="in body link" data-component="auto-linked-tag">Maine</a> Lobster festival, which once designated her the grand marshal of its parade, issued a statement honoring Oliver as “more than a local icon”.</p><p>“Virginia was … a living piece of Maine’s maritime history,” the festival’s statement said.</p><p>Oliver’s survivors include her children and grandchildren, according to her obituary.</p><p><em>Associated Press contributed reporting</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Render Mermaid diagrams as SVGs or ASCII art (375 pts)]]></title>
            <link>https://github.com/lukilabs/beautiful-mermaid</link>
            <guid>46804828</guid>
            <pubDate>Thu, 29 Jan 2026 02:08:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lukilabs/beautiful-mermaid">https://github.com/lukilabs/beautiful-mermaid</a>, See on <a href="https://news.ycombinator.com/item?id=46804828">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why We Built This</h2><a id="user-content-why-we-built-this" aria-label="Permalink: Why We Built This" href="#why-we-built-this"></a></p>
<p dir="auto">Diagrams are essential for AI-assisted programming. When you're working with an AI coding assistant, being able to visualize data flows, state machines, and system architecture—directly in your terminal or chat interface—makes complex concepts instantly graspable.</p>
<p dir="auto"><a href="https://mermaid.js.org/" rel="nofollow">Mermaid</a> is the de facto standard for text-based diagrams. It's brilliant. But the default renderer has problems:</p>
<ul dir="auto">
<li><strong>Aesthetics</strong> — Might be personal preference, but wished they looked more professional</li>
<li><strong>Complex theming</strong> — Customizing colors requires wrestling with CSS classes</li>
<li><strong>No terminal output</strong> — Can't render to ASCII for CLI tools</li>
<li><strong>Heavy dependencies</strong> — Pulls in a lot of code for simple diagrams</li>
</ul>
<p dir="auto">We built <code>beautiful-mermaid</code> at <a href="https://craft.do/" rel="nofollow">Craft</a> to power diagrams in <a href="https://agents.craft.do/" rel="nofollow">Craft Agents</a>. It's fast, beautiful, and works everywhere—from rich UIs to plain terminals.</p>
<p dir="auto">The ASCII rendering engine is based on <a href="https://github.com/AlexanderGrooff/mermaid-ascii">mermaid-ascii</a> by Alexander Grooff. We ported it from Go to TypeScript and extended it Thank you Alexander for the excellent foundation! (And inspiration that this was possible.)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>5 diagram types</strong> — Flowcharts, State, Sequence, Class, and ER diagrams</li>
<li><strong>Dual output</strong> — SVG for rich UIs, ASCII/Unicode for terminals</li>
<li><strong>15 built-in themes</strong> — And dead simple to add your own</li>
<li><strong>Full Shiki compatibility</strong> — Use any VS Code theme directly</li>
<li><strong>Live theme switching</strong> — CSS custom properties, no re-render needed</li>
<li><strong>Mono mode</strong> — Beautiful diagrams from just 2 colors</li>
<li><strong>Zero DOM dependencies</strong> — Pure TypeScript, works everywhere</li>
<li><strong>Ultra-fast</strong> — Renders 100+ diagrams in under 500ms</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install beautiful-mermaid
# or
bun add beautiful-mermaid
# or
pnpm add beautiful-mermaid"><pre>npm install beautiful-mermaid
<span><span>#</span> or</span>
bun add beautiful-mermaid
<span><span>#</span> or</span>
pnpm add beautiful-mermaid</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">SVG Output</h3><a id="user-content-svg-output" aria-label="Permalink: SVG Output" href="#svg-output"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { renderMermaid } from 'beautiful-mermaid'

const svg = await renderMermaid(`
  graph TD
    A[Start] --> B{Decision}
    B -->|Yes| C[Action]
    B -->|No| D[End]
`)"><pre><span>import</span> <span>{</span> <span>renderMermaid</span> <span>}</span> <span>from</span> <span>'beautiful-mermaid'</span>

<span>const</span> <span>svg</span> <span>=</span> <span>await</span> <span>renderMermaid</span><span>(</span><span>`</span>
<span>  graph TD</span>
<span>    A[Start] --&gt; B{Decision}</span>
<span>    B --&gt;|Yes| C[Action]</span>
<span>    B --&gt;|No| D[End]</span>
<span>`</span><span>)</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">ASCII Output</h3><a id="user-content-ascii-output" aria-label="Permalink: ASCII Output" href="#ascii-output"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { renderMermaidAscii } from 'beautiful-mermaid'

const ascii = renderMermaidAscii(`graph LR; A --> B --> C`)"><pre><span>import</span> <span>{</span> <span>renderMermaidAscii</span> <span>}</span> <span>from</span> <span>'beautiful-mermaid'</span>

<span>const</span> <span>ascii</span> <span>=</span> <span>renderMermaidAscii</span><span>(</span><span>`graph LR; A --&gt; B --&gt; C`</span><span>)</span></pre></div>
<div data-snippet-clipboard-copy-content="┌───┐     ┌───┐     ┌───┐
│   │     │   │     │   │
│ A │────►│ B │────►│ C │
│   │     │   │     │   │
└───┘     └───┘     └───┘"><pre><code>┌───┐     ┌───┐     ┌───┐
│   │     │   │     │   │
│ A │────►│ B │────►│ C │
│   │     │   │     │   │
└───┘     └───┘     └───┘
</code></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Theming</h2><a id="user-content-theming" aria-label="Permalink: Theming" href="#theming"></a></p>
<p dir="auto">The theming system is the heart of <code>beautiful-mermaid</code>. It's designed to be both powerful and dead simple.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">The Two-Color Foundation</h3><a id="user-content-the-two-color-foundation" aria-label="Permalink: The Two-Color Foundation" href="#the-two-color-foundation"></a></p>
<p dir="auto">Every diagram needs just two colors: <strong>background</strong> (<code>bg</code>) and <strong>foreground</strong> (<code>fg</code>). That's it. From these two colors, the entire diagram is derived using <code>color-mix()</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const svg = await renderMermaid(diagram, {
  bg: '#1a1b26',  // Background
  fg: '#a9b1d6',  // Foreground
})"><pre><span>const</span> <span>svg</span> <span>=</span> <span>await</span> <span>renderMermaid</span><span>(</span><span>diagram</span><span>,</span> <span>{</span>
  <span>bg</span>: <span>'#1a1b26'</span><span>,</span>  <span>// Background</span>
  <span>fg</span>: <span>'#a9b1d6'</span><span>,</span>  <span>// Foreground</span>
<span>}</span><span>)</span></pre></div>
<p dir="auto">This is <strong>Mono Mode</strong>—a coherent, beautiful diagram from just two colors. The system automatically derives:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Element</th>
<th>Derivation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Text</td>
<td><code>--fg</code> at 100%</td>
</tr>
<tr>
<td>Secondary text</td>
<td><code>--fg</code> at 60% into <code>--bg</code></td>
</tr>
<tr>
<td>Edge labels</td>
<td><code>--fg</code> at 40% into <code>--bg</code></td>
</tr>
<tr>
<td>Connectors</td>
<td><code>--fg</code> at 30% into <code>--bg</code></td>
</tr>
<tr>
<td>Arrow heads</td>
<td><code>--fg</code> at 50% into <code>--bg</code></td>
</tr>
<tr>
<td>Node fill</td>
<td><code>--fg</code> at 3% into <code>--bg</code></td>
</tr>
<tr>
<td>Node stroke</td>
<td><code>--fg</code> at 20% into <code>--bg</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Enriched Mode</h3><a id="user-content-enriched-mode" aria-label="Permalink: Enriched Mode" href="#enriched-mode"></a></p>
<p dir="auto">For richer themes, you can provide optional "enrichment" colors that override specific derivations:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const svg = await renderMermaid(diagram, {
  bg: '#1a1b26',
  fg: '#a9b1d6',
  // Optional enrichment:
  line: '#3d59a1',    // Edge/connector color
  accent: '#7aa2f7',  // Arrow heads, highlights
  muted: '#565f89',   // Secondary text, labels
  surface: '#292e42', // Node fill tint
  border: '#3d59a1',  // Node stroke
})"><pre><span>const</span> <span>svg</span> <span>=</span> <span>await</span> <span>renderMermaid</span><span>(</span><span>diagram</span><span>,</span> <span>{</span>
  <span>bg</span>: <span>'#1a1b26'</span><span>,</span>
  <span>fg</span>: <span>'#a9b1d6'</span><span>,</span>
  <span>// Optional enrichment:</span>
  <span>line</span>: <span>'#3d59a1'</span><span>,</span>    <span>// Edge/connector color</span>
  <span>accent</span>: <span>'#7aa2f7'</span><span>,</span>  <span>// Arrow heads, highlights</span>
  <span>muted</span>: <span>'#565f89'</span><span>,</span>   <span>// Secondary text, labels</span>
  <span>surface</span>: <span>'#292e42'</span><span>,</span> <span>// Node fill tint</span>
  <span>border</span>: <span>'#3d59a1'</span><span>,</span>  <span>// Node stroke</span>
<span>}</span><span>)</span></pre></div>
<p dir="auto">If an enrichment color isn't provided, it falls back to the <code>color-mix()</code> derivation. This means you can provide just the colors you care about.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">CSS Custom Properties = Live Switching</h3><a id="user-content-css-custom-properties--live-switching" aria-label="Permalink: CSS Custom Properties = Live Switching" href="#css-custom-properties--live-switching"></a></p>
<p dir="auto">All colors are CSS custom properties on the <code>&lt;svg&gt;</code> element. This means you can switch themes instantly without re-rendering:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Switch theme by updating CSS variables
svg.style.setProperty('--bg', '#282a36')
svg.style.setProperty('--fg', '#f8f8f2')
// The entire diagram updates immediately"><pre><span>// Switch theme by updating CSS variables</span>
<span>svg</span><span>.</span><span>style</span><span>.</span><span>setProperty</span><span>(</span><span>'--bg'</span><span>,</span> <span>'#282a36'</span><span>)</span>
<span>svg</span><span>.</span><span>style</span><span>.</span><span>setProperty</span><span>(</span><span>'--fg'</span><span>,</span> <span>'#f8f8f2'</span><span>)</span>
<span>// The entire diagram updates immediately</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Built-in Themes</h3><a id="user-content-built-in-themes" aria-label="Permalink: Built-in Themes" href="#built-in-themes"></a></p>
<p dir="auto">15 carefully curated themes ship out of the box:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Theme</th>
<th>Type</th>
<th>Background</th>
<th>Accent</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>zinc-light</code></td>
<td>Light</td>
<td><code>#FFFFFF</code></td>
<td>Derived</td>
</tr>
<tr>
<td><code>zinc-dark</code></td>
<td>Dark</td>
<td><code>#18181B</code></td>
<td>Derived</td>
</tr>
<tr>
<td><code>tokyo-night</code></td>
<td>Dark</td>
<td><code>#1a1b26</code></td>
<td><code>#7aa2f7</code></td>
</tr>
<tr>
<td><code>tokyo-night-storm</code></td>
<td>Dark</td>
<td><code>#24283b</code></td>
<td><code>#7aa2f7</code></td>
</tr>
<tr>
<td><code>tokyo-night-light</code></td>
<td>Light</td>
<td><code>#d5d6db</code></td>
<td><code>#34548a</code></td>
</tr>
<tr>
<td><code>catppuccin-mocha</code></td>
<td>Dark</td>
<td><code>#1e1e2e</code></td>
<td><code>#cba6f7</code></td>
</tr>
<tr>
<td><code>catppuccin-latte</code></td>
<td>Light</td>
<td><code>#eff1f5</code></td>
<td><code>#8839ef</code></td>
</tr>
<tr>
<td><code>nord</code></td>
<td>Dark</td>
<td><code>#2e3440</code></td>
<td><code>#88c0d0</code></td>
</tr>
<tr>
<td><code>nord-light</code></td>
<td>Light</td>
<td><code>#eceff4</code></td>
<td><code>#5e81ac</code></td>
</tr>
<tr>
<td><code>dracula</code></td>
<td>Dark</td>
<td><code>#282a36</code></td>
<td><code>#bd93f9</code></td>
</tr>
<tr>
<td><code>github-light</code></td>
<td>Light</td>
<td><code>#ffffff</code></td>
<td><code>#0969da</code></td>
</tr>
<tr>
<td><code>github-dark</code></td>
<td>Dark</td>
<td><code>#0d1117</code></td>
<td><code>#4493f8</code></td>
</tr>
<tr>
<td><code>solarized-light</code></td>
<td>Light</td>
<td><code>#fdf6e3</code></td>
<td><code>#268bd2</code></td>
</tr>
<tr>
<td><code>solarized-dark</code></td>
<td>Dark</td>
<td><code>#002b36</code></td>
<td><code>#268bd2</code></td>
</tr>
<tr>
<td><code>one-dark</code></td>
<td>Dark</td>
<td><code>#282c34</code></td>
<td><code>#c678dd</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto" data-snippet-clipboard-copy-content="import { renderMermaid, THEMES } from 'beautiful-mermaid'

const svg = await renderMermaid(diagram, THEMES['tokyo-night'])"><pre><span>import</span> <span>{</span> <span>renderMermaid</span><span>,</span> <span>THEMES</span> <span>}</span> <span>from</span> <span>'beautiful-mermaid'</span>

<span>const</span> <span>svg</span> <span>=</span> <span>await</span> <span>renderMermaid</span><span>(</span><span>diagram</span><span>,</span> <span>THEMES</span><span>[</span><span>'tokyo-night'</span><span>]</span><span>)</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Adding Your Own Theme</h3><a id="user-content-adding-your-own-theme" aria-label="Permalink: Adding Your Own Theme" href="#adding-your-own-theme"></a></p>
<p dir="auto">Creating a theme is trivial. At minimum, just provide <code>bg</code> and <code>fg</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const myTheme = {
  bg: '#0f0f0f',
  fg: '#e0e0e0',
}

const svg = await renderMermaid(diagram, myTheme)"><pre><span>const</span> <span>myTheme</span> <span>=</span> <span>{</span>
  <span>bg</span>: <span>'#0f0f0f'</span><span>,</span>
  <span>fg</span>: <span>'#e0e0e0'</span><span>,</span>
<span>}</span>

<span>const</span> <span>svg</span> <span>=</span> <span>await</span> <span>renderMermaid</span><span>(</span><span>diagram</span><span>,</span> <span>myTheme</span><span>)</span></pre></div>
<p dir="auto">Want richer colors? Add any of the optional enrichments:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const myRichTheme = {
  bg: '#0f0f0f',
  fg: '#e0e0e0',
  accent: '#ff6b6b',  // Pop of color for arrows
  muted: '#666666',   // Subdued labels
}"><pre><span>const</span> <span>myRichTheme</span> <span>=</span> <span>{</span>
  <span>bg</span>: <span>'#0f0f0f'</span><span>,</span>
  <span>fg</span>: <span>'#e0e0e0'</span><span>,</span>
  <span>accent</span>: <span>'#ff6b6b'</span><span>,</span>  <span>// Pop of color for arrows</span>
  <span>muted</span>: <span>'#666666'</span><span>,</span>   <span>// Subdued labels</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Full Shiki Compatibility</h3><a id="user-content-full-shiki-compatibility" aria-label="Permalink: Full Shiki Compatibility" href="#full-shiki-compatibility"></a></p>
<p dir="auto">Use <strong>any VS Code theme</strong> directly via Shiki integration. This gives you access to hundreds of community themes:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { getSingletonHighlighter } from 'shiki'
import { renderMermaid, fromShikiTheme } from 'beautiful-mermaid'

// Load any theme from Shiki's registry
const highlighter = await getSingletonHighlighter({
  themes: ['vitesse-dark', 'rose-pine', 'material-theme-darker']
})

// Extract diagram colors from the theme
const colors = fromShikiTheme(highlighter.getTheme('vitesse-dark'))

const svg = await renderMermaid(diagram, colors)"><pre><span>import</span> <span>{</span> <span>getSingletonHighlighter</span> <span>}</span> <span>from</span> <span>'shiki'</span>
<span>import</span> <span>{</span> <span>renderMermaid</span><span>,</span> <span>fromShikiTheme</span> <span>}</span> <span>from</span> <span>'beautiful-mermaid'</span>

<span>// Load any theme from Shiki's registry</span>
<span>const</span> <span>highlighter</span> <span>=</span> <span>await</span> <span>getSingletonHighlighter</span><span>(</span><span>{</span>
  <span>themes</span>: <span>[</span><span>'vitesse-dark'</span><span>,</span> <span>'rose-pine'</span><span>,</span> <span>'material-theme-darker'</span><span>]</span>
<span>}</span><span>)</span>

<span>// Extract diagram colors from the theme</span>
<span>const</span> <span>colors</span> <span>=</span> <span>fromShikiTheme</span><span>(</span><span>highlighter</span><span>.</span><span>getTheme</span><span>(</span><span>'vitesse-dark'</span><span>)</span><span>)</span>

<span>const</span> <span>svg</span> <span>=</span> <span>await</span> <span>renderMermaid</span><span>(</span><span>diagram</span><span>,</span> <span>colors</span><span>)</span></pre></div>
<p dir="auto">The <code>fromShikiTheme()</code> function intelligently maps VS Code editor colors to diagram roles:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Editor Color</th>
<th>Diagram Role</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>editor.background</code></td>
<td><code>bg</code></td>
</tr>
<tr>
<td><code>editor.foreground</code></td>
<td><code>fg</code></td>
</tr>
<tr>
<td><code>editorLineNumber.foreground</code></td>
<td><code>line</code></td>
</tr>
<tr>
<td><code>focusBorder</code> / keyword token</td>
<td><code>accent</code></td>
</tr>
<tr>
<td>comment token</td>
<td><code>muted</code></td>
</tr>
<tr>
<td><code>editor.selectionBackground</code></td>
<td><code>surface</code></td>
</tr>
<tr>
<td><code>editorWidget.border</code></td>
<td><code>border</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported Diagrams</h2><a id="user-content-supported-diagrams" aria-label="Permalink: Supported Diagrams" href="#supported-diagrams"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Flowcharts</h3><a id="user-content-flowcharts" aria-label="Permalink: Flowcharts" href="#flowcharts"></a></p>
<div data-snippet-clipboard-copy-content="graph TD
  A[Start] --> B{Decision}
  B -->|Yes| C[Process]
  B -->|No| D[End]
  C --> D"><pre><code>graph TD
  A[Start] --&gt; B{Decision}
  B --&gt;|Yes| C[Process]
  B --&gt;|No| D[End]
  C --&gt; D
</code></pre></div>
<p dir="auto">All directions supported: <code>TD</code> (top-down), <code>LR</code> (left-right), <code>BT</code> (bottom-top), <code>RL</code> (right-left).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">State Diagrams</h3><a id="user-content-state-diagrams" aria-label="Permalink: State Diagrams" href="#state-diagrams"></a></p>
<div data-snippet-clipboard-copy-content="stateDiagram-v2
  [*] --> Idle
  Idle --> Processing: start
  Processing --> Complete: done
  Complete --> [*]"><pre><code>stateDiagram-v2
  [*] --&gt; Idle
  Idle --&gt; Processing: start
  Processing --&gt; Complete: done
  Complete --&gt; [*]
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sequence Diagrams</h3><a id="user-content-sequence-diagrams" aria-label="Permalink: Sequence Diagrams" href="#sequence-diagrams"></a></p>
<div data-snippet-clipboard-copy-content="sequenceDiagram
  Alice->>Bob: Hello Bob!
  Bob-->>Alice: Hi Alice!
  Alice->>Bob: How are you?
  Bob-->>Alice: Great, thanks!"><pre><code>sequenceDiagram
  Alice-&gt;&gt;Bob: Hello Bob!
  Bob--&gt;&gt;Alice: Hi Alice!
  Alice-&gt;&gt;Bob: How are you?
  Bob--&gt;&gt;Alice: Great, thanks!
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Class Diagrams</h3><a id="user-content-class-diagrams" aria-label="Permalink: Class Diagrams" href="#class-diagrams"></a></p>
<div data-snippet-clipboard-copy-content="classDiagram
  Animal <|-- Duck
  Animal <|-- Fish
  Animal: +int age
  Animal: +String gender
  Animal: +isMammal() bool
  Duck: +String beakColor
  Duck: +swim()
  Duck: +quack()"><pre><code>classDiagram
  Animal &lt;|-- Duck
  Animal &lt;|-- Fish
  Animal: +int age
  Animal: +String gender
  Animal: +isMammal() bool
  Duck: +String beakColor
  Duck: +swim()
  Duck: +quack()
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">ER Diagrams</h3><a id="user-content-er-diagrams" aria-label="Permalink: ER Diagrams" href="#er-diagrams"></a></p>
<div data-snippet-clipboard-copy-content="erDiagram
  CUSTOMER ||--o{ ORDER : places
  ORDER ||--|{ LINE_ITEM : contains
  PRODUCT ||--o{ LINE_ITEM : &quot;is in&quot;"><pre><code>erDiagram
  CUSTOMER ||--o{ ORDER : places
  ORDER ||--|{ LINE_ITEM : contains
  PRODUCT ||--o{ LINE_ITEM : "is in"
</code></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">ASCII Output</h2><a id="user-content-ascii-output-1" aria-label="Permalink: ASCII Output" href="#ascii-output-1"></a></p>
<p dir="auto">For terminal environments, CLI tools, or anywhere you need plain text, render to ASCII or Unicode box-drawing characters:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { renderMermaidAscii } from 'beautiful-mermaid'

// Unicode mode (default) — prettier box drawing
const unicode = renderMermaidAscii(`graph LR; A --> B`)

// Pure ASCII mode — maximum compatibility
const ascii = renderMermaidAscii(`graph LR; A --> B`, { useAscii: true })"><pre><span>import</span> <span>{</span> <span>renderMermaidAscii</span> <span>}</span> <span>from</span> <span>'beautiful-mermaid'</span>

<span>// Unicode mode (default) — prettier box drawing</span>
<span>const</span> <span>unicode</span> <span>=</span> <span>renderMermaidAscii</span><span>(</span><span>`graph LR; A --&gt; B`</span><span>)</span>

<span>// Pure ASCII mode — maximum compatibility</span>
<span>const</span> <span>ascii</span> <span>=</span> <span>renderMermaidAscii</span><span>(</span><span>`graph LR; A --&gt; B`</span><span>,</span> <span>{</span> <span>useAscii</span>: <span>true</span> <span>}</span><span>)</span></pre></div>
<p dir="auto"><strong>Unicode output:</strong></p>
<div data-snippet-clipboard-copy-content="┌───┐     ┌───┐
│   │     │   │
│ A │────►│ B │
│   │     │   │
└───┘     └───┘"><pre><code>┌───┐     ┌───┐
│   │     │   │
│ A │────►│ B │
│   │     │   │
└───┘     └───┘
</code></pre></div>
<p dir="auto"><strong>ASCII output:</strong></p>
<div data-snippet-clipboard-copy-content="+---+     +---+
|   |     |   |
| A |---->| B |
|   |     |   |
+---+     +---+"><pre><code>+---+     +---+
|   |     |   |
| A |----&gt;| B |
|   |     |   |
+---+     +---+
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">ASCII Options</h3><a id="user-content-ascii-options" aria-label="Permalink: ASCII Options" href="#ascii-options"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="renderMermaidAscii(diagram, {
  useAscii: false,      // true = ASCII, false = Unicode (default)
  paddingX: 5,          // Horizontal spacing between nodes
  paddingY: 5,          // Vertical spacing between nodes
  boxBorderPadding: 1,  // Padding inside node boxes
})"><pre><span>renderMermaidAscii</span><span>(</span><span>diagram</span><span>,</span> <span>{</span>
  <span>useAscii</span>: <span>false</span><span>,</span>      <span>// true = ASCII, false = Unicode (default)</span>
  <span>paddingX</span>: <span>5</span><span>,</span>          <span>// Horizontal spacing between nodes</span>
  <span>paddingY</span>: <span>5</span><span>,</span>          <span>// Vertical spacing between nodes</span>
  <span>boxBorderPadding</span>: <span>1</span><span>,</span>  <span>// Padding inside node boxes</span>
<span>}</span><span>)</span></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">API Reference</h2><a id="user-content-api-reference" aria-label="Permalink: API Reference" href="#api-reference"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>renderMermaid(text, options?): Promise&lt;string&gt;</code></h3><a id="user-content-rendermermaidtext-options-promisestring" aria-label="Permalink: renderMermaid(text, options?): Promise<string>" href="#rendermermaidtext-options-promisestring"></a></p>
<p dir="auto">Render a Mermaid diagram to SVG. Auto-detects diagram type.</p>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>text</code> — Mermaid source code</li>
<li><code>options</code> — Optional <code>RenderOptions</code> object</li>
</ul>
<p dir="auto"><strong>RenderOptions:</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Option</th>
<th>Type</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>bg</code></td>
<td><code>string</code></td>
<td><code>#FFFFFF</code></td>
<td>Background color</td>
</tr>
<tr>
<td><code>fg</code></td>
<td><code>string</code></td>
<td><code>#27272A</code></td>
<td>Foreground color</td>
</tr>
<tr>
<td><code>line</code></td>
<td><code>string?</code></td>
<td>—</td>
<td>Edge/connector color</td>
</tr>
<tr>
<td><code>accent</code></td>
<td><code>string?</code></td>
<td>—</td>
<td>Arrow heads, highlights</td>
</tr>
<tr>
<td><code>muted</code></td>
<td><code>string?</code></td>
<td>—</td>
<td>Secondary text, labels</td>
</tr>
<tr>
<td><code>surface</code></td>
<td><code>string?</code></td>
<td>—</td>
<td>Node fill tint</td>
</tr>
<tr>
<td><code>border</code></td>
<td><code>string?</code></td>
<td>—</td>
<td>Node stroke color</td>
</tr>
<tr>
<td><code>font</code></td>
<td><code>string</code></td>
<td><code>Inter</code></td>
<td>Font family</td>
</tr>
<tr>
<td><code>transparent</code></td>
<td><code>boolean</code></td>
<td><code>false</code></td>
<td>Render with transparent background</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>renderMermaidAscii(text, options?): string</code></h3><a id="user-content-rendermermaidasciitext-options-string" aria-label="Permalink: renderMermaidAscii(text, options?): string" href="#rendermermaidasciitext-options-string"></a></p>
<p dir="auto">Render a Mermaid diagram to ASCII/Unicode text. Synchronous.</p>
<p dir="auto"><strong>AsciiRenderOptions:</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Option</th>
<th>Type</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>useAscii</code></td>
<td><code>boolean</code></td>
<td><code>false</code></td>
<td>Use ASCII instead of Unicode</td>
</tr>
<tr>
<td><code>paddingX</code></td>
<td><code>number</code></td>
<td><code>5</code></td>
<td>Horizontal node spacing</td>
</tr>
<tr>
<td><code>paddingY</code></td>
<td><code>number</code></td>
<td><code>5</code></td>
<td>Vertical node spacing</td>
</tr>
<tr>
<td><code>boxBorderPadding</code></td>
<td><code>number</code></td>
<td><code>1</code></td>
<td>Inner box padding</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>fromShikiTheme(theme): DiagramColors</code></h3><a id="user-content-fromshikithemetheme-diagramcolors" aria-label="Permalink: fromShikiTheme(theme): DiagramColors" href="#fromshikithemetheme-diagramcolors"></a></p>
<p dir="auto">Extract diagram colors from a Shiki theme object.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>THEMES: Record&lt;string, DiagramColors&gt;</code></h3><a id="user-content-themes-recordstring-diagramcolors" aria-label="Permalink: THEMES: Record<string, DiagramColors>" href="#themes-recordstring-diagramcolors"></a></p>
<p dir="auto">Object containing all 15 built-in themes.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>DEFAULTS: { bg: string, fg: string }</code></h3><a id="user-content-defaults--bg-string-fg-string-" aria-label="Permalink: DEFAULTS: { bg: string, fg: string }" href="#defaults--bg-string-fg-string-"></a></p>
<p dir="auto">Default colors (<code>#FFFFFF</code> / <code>#27272A</code>).</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Attribution</h2><a id="user-content-attribution" aria-label="Permalink: Attribution" href="#attribution"></a></p>
<p dir="auto">The ASCII rendering engine is based on <a href="https://github.com/AlexanderGrooff/mermaid-ascii">mermaid-ascii</a> by Alexander Grooff. We ported it from Go to TypeScript and extended it with:</p>
<ul dir="auto">
<li>Sequence diagram support</li>
<li>Class diagram support</li>
<li>ER diagram support</li>
<li>Unicode box-drawing characters</li>
<li>Configurable spacing and padding</li>
</ul>
<p dir="auto">Thank you Alexander for the excellent foundation!</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT — see <a href="https://github.com/lukilabs/beautiful-mermaid/blob/main/LICENSE">LICENSE</a> for details.</p>
<hr>
<p dir="auto">Built with care by the team at <a href="https://craft.do/" rel="nofollow">Craft</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ross Stevens Donates $100M to Pay Every US Olympian and Paralympian $200k (174 pts)]]></title>
            <link>https://www.townandcountrymag.com/leisure/sporting/a70171886/ross-stevens-american-olympians-donation/</link>
            <guid>46803549</guid>
            <pubDate>Wed, 28 Jan 2026 23:55:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.townandcountrymag.com/leisure/sporting/a70171886/ross-stevens-american-olympians-donation/">https://www.townandcountrymag.com/leisure/sporting/a70171886/ross-stevens-american-olympians-donation/</a>, See on <a href="https://news.ycombinator.com/item?id=46803549">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-body="standard-article"><p data-journey-content="true" data-node-id="0">How much <a href="https://www.townandcountrymag.com/leisure/sporting/a61804802/olympic-medalists-pay-explained/" target="_blank" data-vars-ga-outbound-link="https://www.townandcountrymag.com/leisure/sporting/a61804802/olympic-medalists-pay-explained/" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Olympians get paid" data-node-id="0.1">Olympians get paid</a> depends entirely on the country they compete for. The International Olympic Committee (IOC) does not give out cash prizes, only a medal, but many countries do award their athletes based on whether or not they won a gold, silver, or bronze. However, if an American athlete competes (and medals) at the Olympics, the U.S. government does not pay them anything.</p><p data-journey-content="true" data-node-id="1">Billionaire financier Ross Stevens is changing that. Starting with the upcoming Milan Cortina Olympics, he will give $200,000 to every U.S. Olympic and Paralympic athlete—even if they don’t win a medal. Per the <a href="https://www.wsj.com/sports/olympics/team-usa-milan-cortina-e131245d?st=Hhm2s6&amp;reflink=desktopwebshare_permalink" target="_blank" data-vars-ga-outbound-link="https://www.wsj.com/sports/olympics/team-usa-milan-cortina-e131245d?st=Hhm2s6&amp;reflink=desktopwebshare_permalink" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Wall Street Journal" data-node-id="1.1"><em data-node-id="1.1.0">Wall Street Journal</em></a>, “Half will come 20 years after their first qualifying Olympic appearance or at age 45, whichever comes later. Another $100,000 will be in the form of a guaranteed benefit for their families after they pass away.”</p><p data-journey-content="true" data-node-id="2">His entire donation to the U.S. Olympic &amp; Paralympic Committee (USOPC), <a href="https://www.usopc.org/news/2025/march/04/united-states-olympic-paralympic-committee-and-united-states-olympic-paralympic-foundation-announce-100-million-gift-to-support-post-games-financial-security-for-team-usa-athletes" target="_blank" data-vars-ga-outbound-link="https://www.usopc.org/news/2025/march/04/united-states-olympic-paralympic-committee-and-united-states-olympic-paralympic-foundation-announce-100-million-gift-to-support-post-games-financial-security-for-team-usa-athletes" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="announced last March" data-node-id="2.1">announced last March</a>, is $100 million—a record breaking gift to the organization. “I do not believe that financial insecurity should stop our nation’s elite athletes from breaking through to new frontiers of excellence,” Stevens said upon the announcement of his gift.</p><p data-journey-content="true" data-node-id="4">This won’t be the only source of income for American Olympic and Paralympic athletes; many receive money from endorsement and sponsorship deals, and the national governing body of each sport financially supports their athletes differently. However, Stevens’ gift looks to their retirement.</p><p data-journey-content="true" data-node-id="6">Called the Stevens Financial Security Awards (Stevens Awards), the gift is intended to provide financial support to those who represent the U.S. on the world stage. “In the heart of every Team USA athlete lies a story of dedication, sacrifice and triumph,” said USOPC Chair Gene Sykes. “These extraordinary individuals have committed their lives to their sport, often at the expense of traditional career paths and financial savings. As they approach the end of their competitive journeys—often as young as 25 or 30—many face a daunting reality: the lack of financial savings to support them and their loved ones in their post-athletic life.”</p><p data-journey-content="true" data-node-id="7">He added, “Because of Ross’ extraordinary generosity and philanthropic creativity, we can create more than a financial safety net— we can build a springboard that will propel these athletes to even greater heights beyond their Olympic and Paralympic careers.”</p><div data-journey-blur="partial" data-ad-exclude="true"><p><span><img src="https://hips.hearstapps.com/rover/profile_photos/121b4598-31f9-4716-af00-a68368fb7913_1643729378.file?fill=1:1&amp;resize=120:*" alt="Headshot of Emily Burack" title="Headshot of Emily Burack" width="100%" height="100%" decoding="async" loading="lazy"></span></p><div><p>Emily Burack (she/her) is the Senior News Editor for Town &amp; Country, where she covers entertainment, celebrities, the royals, and a wide range of other topics. Before joining T&amp;C, she was the deputy managing editor at Hey Alma, a Jewish culture site. Follow her @emburack on Twitter and Instagram.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Please Don't Say Mean Things about the AI I Just Invested a Billion Dollars In (623 pts)]]></title>
            <link>https://www.mcsweeneys.net/articles/please-dont-say-mean-things-about-the-ai-that-i-just-invested-a-billion-dollars-in</link>
            <guid>46803356</guid>
            <pubDate>Wed, 28 Jan 2026 23:36:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mcsweeneys.net/articles/please-dont-say-mean-things-about-the-ai-that-i-just-invested-a-billion-dollars-in">https://www.mcsweeneys.net/articles/please-dont-say-mean-things-about-the-ai-that-i-just-invested-a-billion-dollars-in</a>, See on <a href="https://news.ycombinator.com/item?id=46803356">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p><i>“[Nvidia <span>CEO</span>] Jensen Huang Is Begging You to Stop Being So Negative About AI” — <a href="https://gizmodo.com/jensen-huang-is-begging-you-to-stop-being-so-negative-about-ai-2000709335">Headline from Gizmodo</a></i></p>
<p>- - </p><p>—</p>
<p>Guys, enough is enough. Bullying is a serious issue, and it’s time for me to speak out. There’s an extremely hurtful narrative going around that my product, a revolutionary new technology that exists to scam the elderly and make you distrust anything you see online, is harmful to society. This slander is totally unwarranted, and I would really appreciate it if everyone would stop being so mean about this thing I just invested a billion dollars in.</p>
<p>As someone who desperately needs this technology to work out, I can honestly say it is the most essential tool ever created in all of human history. Don’t mercilessly ridicule it just because it steals the joy out of your hobbies and creates sexually explicit images of women without their consent. Seriously, please stop! It really hurts my feelings.</p>
<p>It’s easy to throw stones if you think about the job displacement and ecological destruction caused by this pointless technology. But such black-and-white, not-wanting-billionaires-to-get-richer thinking is, quite frankly, cruel. You can’t just measure the value of something in terms of “whether or not it makes everything worse for everyone.” The world is much more complicated than that.</p>
<p>This technology is going to fuel innovation across industries and solve all problems of feminism and equal rights. Yes, it’s expanding the surveillance state, and yes, it’s destroying the education system, and yes, it’s being trained on copyrighted work without permission, and yes, it’s being used to create lethal autonomous weapons systems that can identify, target, and kill without human input, but… I forget my point, but ultimately, I think you should embrace it.</p>
<p>Lately, I feel like I just can’t win with you guys. Please, just use my evil technology. What’s so wrong with that? Just use it. I’m begging you. I want to continue living my immoral technofascist life without any criticism.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In 6 violent encounters, evidence contradicts immigration officials' narratives (235 pts)]]></title>
            <link>https://www.reuters.com/world/us/evidence-contradicts-trump-immigration-officials-accounts-violent-encounters-2026-01-27/</link>
            <guid>46803229</guid>
            <pubDate>Wed, 28 Jan 2026 23:25:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/us/evidence-contradicts-trump-immigration-officials-accounts-violent-encounters-2026-01-27/">https://www.reuters.com/world/us/evidence-contradicts-trump-immigration-officials-accounts-violent-encounters-2026-01-27/</a>, See on <a href="https://news.ycombinator.com/item?id=46803229">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/us/evidence-contradicts-trump-immigration-officials-accounts-violent-encounters-2026-01-27/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[The UK paid £4.1M for a bookmarks site (383 pts)]]></title>
            <link>https://mahadk.com/posts/ai-skills-hub</link>
            <guid>46803119</guid>
            <pubDate>Wed, 28 Jan 2026 23:16:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mahadk.com/posts/ai-skills-hub">https://mahadk.com/posts/ai-skills-hub</a>, See on <a href="https://news.ycombinator.com/item?id=46803119">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p>The UK Government recently unveiled its <a href="https://www.gov.uk/government/news/free-ai-training-for-all-as-government-and-industry-programme-expands-to-provide-10-million-workers-with-key-ai-skills-by-2030">‘AI Skills Hub’</a>, which wants to provide 10 million workers with AI skills by 2030. The main site was delivered by PwC for the low, low price of.. <a href="https://www.find-tender.service.gov.uk/Notice/001337-2025">£4.1 million (~$5,657,000).</a></p>
<p><img src="https://cdn.mahadk.com/s/v3/fa4d19cdf4b054d4_image.png" alt="Image of the procurement contract"></p>
<p>It is <em>not</em> good. Like, at all - the UI is insanely bad and it’s clear that this was just a vibecoded site (to be fair, this is the <em>AI</em> Skills Hub, but c’mon, where is the pride in your work? I would be ashamed to even release this as a prototype!)</p>
<p><img src="https://cdn.mahadk.com/s/v3/fa0761d06de95286_image.png" alt="Image of the AI Skills Hub"></p>
<p>PwC didn’t even write any of the course content! The only thing the Skills Hub does is link out to external pages, like Salesforce’s free Trailhead learning platform:</p>
<p><img src="https://cdn.mahadk.com/s/v3/9aed674092d49d24_image.png" alt="Screenshot of Salesforce's Trailhead learning platform"></p>
<p>Note that I’m fairly certain this course already existed before the contract was even awarded, so all the site does is.. link out to other sites?</p>
<p>PwC itself also admits that the site does not properly meet accessibility standards:</p>
<p><img src="https://cdn.mahadk.com/s/v3/f346a09eb011342a_image.png" alt="Accessibility policy"></p>
<p>Even for those without a disability, the lack of here in this regard means that the site can be very confusing and buggy as a result.</p>
<h2 id="incorrect-laws">Incorrect laws</h2>
<p>The site has a course on “AI and intellectual property”. One thing it mentions is <a href="https://en.wikipedia.org/wiki/Fair_use">fair use</a>:</p>
<p><img src="https://cdn.mahadk.com/s/v3/1e8f7dc501128b15_image.png" alt="Fair use"></p>
<p><a href="https://x.com/ednewtonrex/status/2016443895505203379">(credits for the photo)</a></p>
<p>Except that <em>fair use is not a thing in the UK</em> - that’s a US concept! The UK uses what’s known as “fair dealing”, which is more restrictive than fair use, so the details here are plain wrong.</p>
<h2 id="lack-of-care-lack-of-craft">Lack of care, lack of craft</h2>
<p>The interface for this website has also not been clearly thought out - one glaring example is the process of actually enrolling in a course.</p>
<p>On the course page, the “Enroll Now” button is <em>tiny</em>, and if you don’t see it and try scrolling down to the bottom, you will find yourself nothing but a comment section!</p>
<p><img src="https://cdn.mahadk.com/s/v3/61dc1d957dc892f8_image.png" alt="Image of the course page"></p>
<p>Then you have other bugs too, like the “Skills &amp; Training Gap Analysis” - which is linked at the top of the site! - apparently being closed off to the public for no reason:</p>
<p><img src="https://cdn.mahadk.com/s/v3/f03c15b9365950ff_image.png" alt="Image of the S&amp;T Gap Analysis page"></p>
<hr>
<p>To be honest, seeing this made me angry.</p>
<p>I’m angry at the sheer <em>wastefulness</em> of the UK Government here. Our public services are collapsing - while £4 million is admittedly chump change for the UK government, there are real people behind these numbers - families waiting months for NHS appointments, children in crumbling schools, vulnerable people not getting the care they need. The waste feels particularly galling when you realise that almost no one will actually use this site!</p>
<p>I’m also angry that the small webdev businesses we have here in the UK were left out of this - for less than 5% of the cost, we’d have a <em>better</em> website and help out small businesses who actually care about their work, instead of handing the project to a multinational company that made nearly $60 billion in revenue in a year and has zero qualms about ripping off the British taxpayer.</p>
<p>Do better.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla ending Models S and X production (504 pts)]]></title>
            <link>https://www.cnbc.com/2026/01/28/tesla-ending-model-s-x-production.html</link>
            <guid>46802867</guid>
            <pubDate>Wed, 28 Jan 2026 22:53:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2026/01/28/tesla-ending-model-s-x-production.html">https://www.cnbc.com/2026/01/28/tesla-ending-model-s-x-production.html</a>, See on <a href="https://news.ycombinator.com/item?id=46802867">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-106844785" data-test="InlineImage"><p>A Model X is on display at a Tesla showroom on February 13, 2021 in Beijing, China.</p><p>VCG | Visual China Group | Getty Images</p></div><div><p><span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/TSLA/">Tesla</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> CEO <a href="https://www.cnbc.com/elon-musk/">Elon Musk</a> said on Wednesday that the automaker is ending production of its Model S and X vehicles, and will use the factory in Fremont, California, to build Optimus humanoid robots. </p><p>"It's time to basically bring the Model S and X programs to an end with an honorable discharge," Musk said on the company's fourth-quarter <a href="https://www.cnbc.com/2026/01/28/tesla-tsla-2025-q4-earnings.html">earnings</a> call. "If you're interested in buying a Model S and X, now would be the time to order it."</p><p>After the original Roadster, the two models are Tesla's oldest vehicles, and in recent years the company has slashed prices as global competition for electric vehicles has soared. Tesla started selling the Model S sedan in 2012, and the <a href="https://www.cnbc.com/2015/09/30/tesla-delivers-model-x-electric-suv-to-take-on-luxury-carmakers.html">Model X SUV</a> three years later. </p><p>On Tesla's website, the Model S currently starts at about $95,000, while the Model X starts at around $100,000</p><p>Tesla's far more popular models are the 3 and Y, which accounted for 97% of the company's 1.59 million <a href="https://ir.tesla.com/press-release/tesla-fourth-quarter-2025-production-deliveries-deployments" target="_blank">deliveries</a> last year. The Model 3 now starts at about $37,000, and the Model Y is around $40,000. Tesla debuted more affordable versions of the vehicles late last year. </p><p>In its earnings announcement on Wednesday, Tesla reported its first annual revenue decline on record, with sales falling in three of the past four quarters. Musk has been trying to turn attention away from traditional EVs and toward a future of driverless cars and humanoid robots, areas where the company currently has virtually no business.</p><p>Tesla is developing Optimus with the aim of someday selling it as a bipedal, intelligent robot capable of everything from factory work to babysitting. The company said in the release that it plans to unveil the third generation of Optimus this quarter, its "first design meant for mass production."</p><p>Musk said on the call that Tesla is replacing its production line for S and X in Fremont "with a 1 million unit per year line of Optimus."</p><p>"Because it is a completely new supply chain," Musk said, "there's really nothing from the existing supply chain that exists in Optimus."</p><p>Tesla expects to boost headcount at the Fremont facility, Musk added, "and to significantly increase output."</p><p><strong>This is breaking news. Please refresh for updates.</strong></p><p><strong>WATCH:</strong> <a href="https://www.cnbc.com/video/2026/01/28/fast-money-traders-on-how-they-are-playing-tesla-after-earnings-report-boosts-stocks.html">How traders are playing Tesla</a></p></div><div id="Placeholder-ArticleBody-Video-108258644" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000402215" aria-labelledby="Placeholder-ArticleBody-Video-108258644"><p><img src="https://image.cnbcfm.com/api/v1/image/108258657-1769639965310-1769639465-43735086212-hd.jpg?v=1769639966&amp;w=750&amp;h=422&amp;vtcrop=y" alt="'Fast Money' traders on how they are playing Tesla after earnings report boosts stocks"><span></span><span></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bf-Tree: modern read-write-optimized concurrent larger-than-memory range index (133 pts)]]></title>
            <link>https://github.com/microsoft/bf-tree</link>
            <guid>46802210</guid>
            <pubDate>Wed, 28 Jan 2026 22:05:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/microsoft/bf-tree">https://github.com/microsoft/bf-tree</a>, See on <a href="https://news.ycombinator.com/item?id=46802210">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Bf-Tree</h2><a id="user-content-bf-tree" aria-label="Permalink: Bf-Tree" href="#bf-tree"></a></p>
<p dir="auto">Bf-Tree is a modern read-write-optimized concurrent larger-than-memory range index in Rust from MSR.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Design Details</h2><a id="user-content-design-details" aria-label="Permalink: Design Details" href="#design-details"></a></p>
<p dir="auto">You can find the Bf-Tree research paper <a href="https://badrish.net/papers/bftree-vldb2024.pdf" rel="nofollow">here</a>. You can find more design docs <a href="https://github.com/microsoft/bf-tree/blob/main/doc">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">User Guide</h2><a id="user-content-user-guide" aria-label="Permalink: User Guide" href="#user-guide"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Rust</h3><a id="user-content-rust" aria-label="Permalink: Rust" href="#rust"></a></p>
<p dir="auto">Bf-Tree is written in Rust, and is available as a Rust crate. You can add Bf-Tree to your <code>Cargo.toml</code> like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[dependencies]
bf-tree = &quot;0.1.0&quot;"><pre>[<span>dependencies</span>]
<span>bf-tree</span> = <span><span>"</span>0.1.0<span>"</span></span></pre></div>
<p dir="auto">An example use of Bf-Tree:</p>
<div dir="auto" data-snippet-clipboard-copy-content="use bf_tree::BfTree;
use bf_tree::LeafReadResult;

let mut config = bf_tree::Config::default();
config.cb_min_record_size(4);
let tree = BfTree::with_config(config, None).unwrap();
tree.insert(b&quot;key&quot;, b&quot;value&quot;);

let mut buffer = [0u8; 1024];
let read_size = tree.read(b&quot;key&quot;, &amp;mut buffer);

assert_eq!(read_size, LeafReadResult::Found(5));
assert_eq!(&amp;buffer[..5], b&quot;value&quot;);"><pre><span>use</span> bf_tree<span>::</span><span>BfTree</span><span>;</span>
<span>use</span> bf_tree<span>::</span><span>LeafReadResult</span><span>;</span>

<span>let</span> <span>mut</span> config = bf_tree<span>::</span><span>Config</span><span>::</span><span>default</span><span>(</span><span>)</span><span>;</span>
config<span>.</span><span>cb_min_record_size</span><span>(</span><span>4</span><span>)</span><span>;</span>
<span>let</span> tree = <span>BfTree</span><span>::</span><span>with_config</span><span>(</span>config<span>,</span> <span>None</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
tree<span>.</span><span>insert</span><span>(</span><span>b"key"</span><span>,</span> <span>b"value"</span><span>)</span><span>;</span>

<span>let</span> <span>mut</span> buffer = <span>[</span><span>0u8</span><span>;</span> <span>1024</span><span>]</span><span>;</span>
<span>let</span> read_size = tree<span>.</span><span>read</span><span>(</span><span>b"key"</span><span>,</span> <span>&amp;</span><span>mut</span> buffer<span>)</span><span>;</span>

<span>assert_eq</span><span>!</span><span>(</span>read_size<span>,</span> <span>LeafReadResult</span><span>::</span><span>Found</span><span>(</span><span>5</span><span>)</span><span>)</span><span>;</span>
<span>assert_eq</span><span>!</span><span>(</span><span>&amp;</span>buffer<span>[</span>..<span>5</span><span>]</span><span>,</span> <span>b"value"</span><span>)</span><span>;</span></pre></div>
<p dir="auto">PRs are accepted and preferred over feature requests. Feel free to reach out if you have any design questions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Developer Guide</h2><a id="user-content-developer-guide" aria-label="Permalink: Developer Guide" href="#developer-guide"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Building</h3><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Prerequisite</h4><a id="user-content-prerequisite" aria-label="Permalink: Prerequisite" href="#prerequisite"></a></p>
<p dir="auto">Bf-Tree supports Linux, Windows, and macOS, although only a recently version of Linux is rigorously tested. Bf-Tree is written in Rust, which you can install <a href="https://rustup.rs/" rel="nofollow">here</a>.</p>
<p dir="auto">Please install pre-commit hooks to ensure that your code is formatted and linted in the same way as the rest of the project; the coding style will be enforced in CI, these hooks act as a pre-filter.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# If on Ubuntu
sudo apt update &amp;&amp; sudo apt install pre-commit
pre-commit install"><pre><span><span>#</span> If on Ubuntu</span>
sudo apt update <span>&amp;&amp;</span> sudo apt install pre-commit
pre-commit install</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Build</h4><a id="user-content-build" aria-label="Permalink: Build" href="#build"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Testing</h3><a id="user-content-testing" aria-label="Permalink: Testing" href="#testing"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Unit Tests</h4><a id="user-content-unit-tests" aria-label="Permalink: Unit Tests" href="#unit-tests"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Shuttle Tests</h4><a id="user-content-shuttle-tests" aria-label="Permalink: Shuttle Tests" href="#shuttle-tests"></a></p>
<p dir="auto">Concurrent systems are nondeterministic, and subject to exponential amount of different thread interleaving. We use <a href="https://github.com/awslabs/shuttle">shuttle</a>
to deterministically and systematically explore different thread interleaving to uncover the bugs caused by subtle multithread interactions.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo test --features &quot;shuttle&quot; --release shuttle_bf_tree_concurrent_operations"><pre>cargo <span>test</span> --features <span><span>"</span>shuttle<span>"</span></span> --release shuttle_bf_tree_concurrent_operations</pre></div>
<p dir="auto">(Takes about 5 minute to run)</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Fuzz Tests</h4><a id="user-content-fuzz-tests" aria-label="Permalink: Fuzz Tests" href="#fuzz-tests"></a></p>
<p dir="auto">Fuzz testing is a bug finding technique that generates random inputs to the system and test for crash. Bf-Tree employs fuzzing to generate random operation sequences
(e.g., insert, read, scan) to the system and check that none of the operation sequence will crash the system or lead to inconsistent state. Check the
<a href="https://github.com/microsoft/bf-tree/blob/main/fuzz/README.md">fuzz</a> folder for more details.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Benchmarking</h3><a id="user-content-benchmarking" aria-label="Permalink: Benchmarking" href="#benchmarking"></a></p>
<p dir="auto">Check the <a href="https://github.com/microsoft/bf-tree/blob/main/benchmark/README.md">benchmark</a> folder for more details.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd benchmark
env SHUMAI_FILTER=&quot;inmemory&quot; MIMALLOC_LARGE_OS_PAGES=1 cargo run --bin bftree --release"><pre><span>cd</span> benchmark
env SHUMAI_FILTER=<span><span>"</span>inmemory<span>"</span></span> MIMALLOC_LARGE_OS_PAGES=1 cargo run --bin bftree --release</pre></div>
<p dir="auto">More advanced benchmarking, with metrics collecting, numa-node binding, huge page, etc:</p>
<div dir="auto" data-snippet-clipboard-copy-content="env MIMALLOC_SHOW_STATS=1 MIMALLOC_LARGE_OS_PAGES=1 MIMALLOC_RESERVE_HUGE_OS_PAGES_AT=0 numactl --membind=0 --cpunodebind=0 cargo bench --features &quot;metrics-rt&quot; micro"><pre>env MIMALLOC_SHOW_STATS=1 MIMALLOC_LARGE_OS_PAGES=1 MIMALLOC_RESERVE_HUGE_OS_PAGES_AT=0 numactl --membind=0 --cpunodebind=0 cargo bench --features <span><span>"</span>metrics-rt<span>"</span></span> micro</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Code of Conduct</h3><a id="user-content-code-of-conduct" aria-label="Permalink: Code of Conduct" href="#code-of-conduct"></a></p>
<p dir="auto">This project has adopted the <a href="https://opensource.microsoft.com/codeofconduct/" rel="nofollow">Microsoft Open Source Code of Conduct</a>.
For more information see the <a href="https://opensource.microsoft.com/codeofconduct/faq/" rel="nofollow">Code of Conduct FAQ</a>
or contact <a href="mailto:opencode@microsoft.com">opencode@microsoft.com</a> with any additional questions or comments.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Contributing</h3><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Please see <a href="https://github.com/microsoft/bf-tree/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Security</h3><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto">See <a href="https://github.com/microsoft/bf-tree/blob/main/SECURITY.md">SECURITY.md</a> for security reporting details.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Trademarks</h3><a id="user-content-trademarks" aria-label="Permalink: Trademarks" href="#trademarks"></a></p>
<p dir="auto">This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks
or logos is subject to and must follow <a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general" rel="nofollow">Microsoft’s Trademark &amp; Brand Guidelines</a>. Use of Microsoft trademarks or logos in
modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party
trademarks or logos are subject to those third-party’s policies.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Contact</h3><a id="user-content-contact" aria-label="Permalink: Contact" href="#contact"></a></p>
<ul dir="auto">
<li><a href="mailto:bftree@microsoft.com">bftree@microsoft.com</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Somebody used spoofed ADSB signals to raster the meme of JD Vance (529 pts)]]></title>
            <link>https://alecmuffett.com/article/143548</link>
            <guid>46802067</guid>
            <pubDate>Wed, 28 Jan 2026 21:50:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alecmuffett.com/article/143548">https://alecmuffett.com/article/143548</a>, See on <a href="https://news.ycombinator.com/item?id=46802067">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>This, if it is still visible: </p>



<p><a href="https://globe.adsbexchange.com/?icao=adfdf9&amp;lat=26.678&amp;lon=-80.030&amp;zoom=14.4&amp;showTrace=2026-01-28">https://globe.adsbexchange.com/?icao=adfdf9&amp;lat=26.678&amp;lon=-80.030&amp;zoom=14.4&amp;showTrace=2026-01-28</a></p>



<p>Via:</p>



<figure><div><blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">Someone is spoofing as a VC-25A / Air Force One making the meme image on ADSB. Call sign " VANCE1 " <a href="https://t.co/yZMj7bfJUU">pic.twitter.com/yZMj7bfJUU</a></p>— ??_???????????? (@SR_Planespotter) <a href="https://twitter.com/SR_Planespotter/status/2016394753772863848?ref_src=twsrc%5Etfw">January 28, 2026</a></blockquote></div></figure>



<p>Next up, age verification for ADSB? </p>




<div> <p><a href="https://alecmuffett.com/tti-cache/143548.png">⊞</a>
</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jellyfin LLM/"AI" Development Policy (196 pts)]]></title>
            <link>https://jellyfin.org/docs/general/contributing/llm-policies/</link>
            <guid>46801976</guid>
            <pubDate>Wed, 28 Jan 2026 21:42:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jellyfin.org/docs/general/contributing/llm-policies/">https://jellyfin.org/docs/general/contributing/llm-policies/</a>, See on <a href="https://news.ycombinator.com/item?id=46801976">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><h2>Jellyfin LLM/"AI" Development Policy</h2></header>
<p>The rise of LLMs as a useful development tool over the last year or so has been significant. The power and flexibility of tools like Claude Code and ChatGPT have given a lot of functionality both to experienced developers and new developers alike. But there are trade-offs.</p>
<p>The Jellyfin project has, from day one, had a major focus on code quality - readability, simplicity, conciseness. This is a mostly manual effort driven by a dedicated team of individuals, and is motivated by a desire to fix the code Jellyfin is based off of which, without beating a dead horse too much, was extremely fragile, spaghettified, and prone to over-engineered complexity.</p>
<p>We are seeing a precipitous rise in contributors using AI within the Jellyfin ecosystem, both in the server and for clients, as well as a rise in criticism and concern about LLMs generally. At this time we are writing this policy to address exactly what we expect and desire with respect to contributions and interactions within our community that may use LLMs. These rules apply to all of our official projects and community spaces.</p>
<h2 id="general-guidelines">General Guidelines<a href="#general-guidelines" aria-label="Direct link to General Guidelines" title="Direct link to General Guidelines" translate="no">​</a></h2>
<ol>
<li>
<p>LLM output is <strong>expressly prohibited</strong> for any direct communication, including the following:</p>
<ul>
<li>issues or comments</li>
<li>feature requests or comments</li>
<li>pull request bodies or comments</li>
<li>forum/chat/etc. posts or comments</li>
</ul>
<p>In short, if you are posting <strong>any</strong> of those things, the output must be your own words, explanation, description, etc., not a verbatim dump of an LLM's output. We expect you to understand what you're posting. Violating this rule will result in closure/deletion of the offending item(s).</p>
<p>An exception will be made for <strong>LLM-assisted translations</strong> if you are having trouble accurately conveying your intent in English. Please explicitly note this ("I have translated this from MyLanguage with an LLM") and, if possible, post in your original language as well.</p>
</li>
<li>
<p>LLM code contributions are subject to more granularity below, but the general principle is that "pure 'vibe coding' will be rejected" and "you are responsible for what you commit". We will review in that vein. If the <strong>code looks terrible</strong>, it will be <strong>rejected as such</strong>.</p>
</li>
</ol>
<h2 id="llm-code-contributions-to-official-projects">LLM Code Contributions to Official Projects<a href="#llm-code-contributions-to-official-projects" aria-label="Direct link to LLM Code Contributions to Official Projects" title="Direct link to LLM Code Contributions to Official Projects" translate="no">​</a></h2>
<p>The use of LLMs for code is controversial and open to much interpretation. These guidelines are our best effort attempt to ensure that knowledgeable developers who seek to use these tools as a legitimate aid are not overly-hindered, while also preventing an ongoing flood of slop contributions that violate our core ethos above. These apply to <strong>all official Jellyfin projects</strong>.</p>
<ol>
<li>Contributions should be <strong>concise and focused</strong>. If the PR claims to target X, and is also touching unrelated Y and Z, it will be rejected. This includes incidental changes to unrelated functionality, a hallmark of poorly-worded or too-general prompts. Similarly, a large PR must be <strong>broken into multiple small, manageable commits</strong> for review and history purposes.</li>
<li>Formatting and quality <strong>standards must be upheld</strong>. Excessive unhelpful comments, spaghetti code, spaces on empty lines, etc. will be interpreted as pure LLM output and rejected; you must <strong>clean up the mess</strong> before submitting. Also <strong>do not commit LLM metafiles</strong> (e.g. <code>.claude</code> configs) or any other editor-created non-code files.</li>
<li>You must <strong>review the output</strong> and be able to <strong>explain</strong> in the PR body - <strong>without</strong> LLM output as noted above - <strong>what is being changed and why</strong>. Your PR body (and, if applicable, commit bodies) should be providing context to other developers about why a change was made, and if your name is on it, we want <strong>your</strong> words and explanations, not an LLM's. If <strong>you can't explain</strong> what the LLM did, we are <strong>not interested</strong> in the change.</li>
<li>The changes must be <strong>tested</strong>. The code should build and run correctly, or it will be rejected. You should also <strong>explicitly test the functionality being modified</strong>.</li>
<li>You must be able and willing to <strong>handle review feedback</strong> and implement the suggested change(s) as required. What this means in practice is, if you do not know what has been changed or why (see #3), and thus can't implement suggested changes or discuss them <strong>yourself</strong>, then we are <strong>not interested</strong> in the change. Just dumping reviewer feedback into an LLM and expecting what comes out to be "good enough", is not.</li>
<li><strong>Features or refactors</strong> require <strong>an in-depth level of understanding</strong> about what is being changed and why. It is obvious to our reviewers when changes are made without the developer making them understanding what is happening. These will be rejected. And as noted in #1, the PR must <strong>contain multiple discrete commits</strong>. <em>We</em> will squash commits as deemed appropriate after review. Large changes must also follow our other development policies (discussion, review, implementation, testing process).</li>
<li>The <strong>final discretion always lies with the reviewers</strong>. If your PR is not capable of being reasonably reviewed, for any reason (over-complexity, size, squashed commits, etc.) it will be rejected, and this goes just as much for non-LLM-assisted PRs as it does for LLM-assisted PRs. You will be asked to split such a PR up into multiple PRs that each present a focused, concise set of changes instead.</li>
</ol>
<p>The golden rule is this: <strong>do not just let an LLM loose on the codebase with a vague vibe prompt and then commit the results as-is</strong>. This is lazy development, will <strong>always</strong> result in a <strong>poor-quality contribution</strong> from our perspective, and we are not at all interested in such slop. <strong>Make an effort</strong> or please do not bother. And again, you are free to use LLMs to <strong>assist</strong> you, but not as the sole source of code changes.</p>

<p>You are of course free to do whatever you wish for your own non-official projects. However, we will be enforcing the following rules for any <strong>sharing of such projects within our communities</strong>.</p>
<ol>
<li>Any primarily-LLM-developed projects should be <strong>clearly marked as such</strong>. It is up to users to decide if this is acceptable to them or not. If you used an LLM for secondary assistance (e.g. docs, formatting, etc.) in an obvious way, we would err towards disclosure as well.</li>
<li>You <strong>must</strong> respect and follow licenses. If you are basing your project off of existing code, <strong>following its license is not optional</strong>. You must <strong>credit existing contributors in full</strong> for <strong>all contributions</strong>. Do not <strong>mangle the Git history</strong>, and do not <strong>commit pending 3rd party changes as your own</strong> (i.e. by copying the code and then committing it). Doing so will result in, not just rejection, but a ban from our organization and community. We have a <strong>zero tolerance policy</strong> for code theft and bad-faith attribution attempts.</li>
<li>For members of the community, <strong>do not report</strong> LLM-generated tools, clients, etc. <strong>on that basis alone</strong>, and do not engage in anti-LLM "witch hunts". As mentioned above, this is <strong>permitted</strong> and it is your choice whether to "support" said tool/client/etc. or not.</li>
<li>We, the moderators, are not going to play "LLM police" about 3rd party projects by nitpicking to try to "find LLM contributions" that otherwise follow our rules here; this is tedious and a waste of our time and effort. What this means in practice is that rule #1 is up to the author, and rule #3 must be interpreted in that vein. If you <strong>only suspect</strong> a tool is LLM-generated and violates rule #1, then downvote/ignore it and move on. <strong>Only if</strong> we see <strong>blatant breaking of rule #1</strong> we will enforce it, but again we will not be going through code line by line playing the "was this LLM generated?" game. Rule #2 will always be enforced regardless of LLM-ness or not.</li>
</ol></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla profit tanked 46% in 2025 (106 pts)]]></title>
            <link>https://techcrunch.com/2026/01/28/tesla-earnings-profit-q4-2025/</link>
            <guid>46801851</guid>
            <pubDate>Wed, 28 Jan 2026 21:33:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2026/01/28/tesla-earnings-profit-q4-2025/">https://techcrunch.com/2026/01/28/tesla-earnings-profit-q4-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=46801851">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Tesla’s profit fell 46% in 2025 compared to the prior year, as CEO Elon Musk assumed a role in the Trump administration and federal electric vehicle subsidies were killed off by Congress, causing sales to plummet.</p>

<p>The electric vehicle company reported Wednesday that it recorded just $3.8 billion in profit across 2025, its lowest tally in years. Total revenue from car sales fell 11% year-over-year, too. Tesla already revealed that it shipped 1.63 million cars globally across 2025. That marks the second year in a row that its sales have declined, after Musk spent years promising average annual growth of 50%.</p>







<p>Investors largely expected the decline in sales in Tesla’s fourth quarter and full-year results for 2025, and the company beat Wall Street’s estimates for earnings and revenue, sending shares up in after-market trading Wednesday. It’s been largely buoyed by strength in its other industries and investments, including energy capabilities and AI, as Tesla has continued to lure investors’ attention away from its stalled-out automotive business.</p>

<p>The company wrote in its shareholder letter: “2025 marked a critical year for Tesla as we further expanded our mission and continued our transition from a hardware-centric business to a physical AI company.” </p>

<p>The company revealed in the letter that it recently invested $2 billion in Elon Musk’s artificial intelligence startup xAI, part of the latter’s recent <a href="https://x.ai/news/series-e" target="_blank" rel="noreferrer noopener nofollow">Series E funding round</a>.</p>

<p>Revenue from Tesla’s solar and energy storage businesses also grew 25% compared to 2024, and services revenue (which includes payments for Full Self-Driving software, insurance, parts, and Supercharging) grew 18%. The company was even able to grow its gross margin compared to prior quarters.</p>

<p>Long-awaited projects like the Tesla Semi (first revealed in 2017) and the Cybercab (which debuted in 2024, but has been teased for years) are supposed to enter production in the first half of this year, according to Tesla.  </p>
<div>
		
		<p>Techcrunch event</p>
		<div>
			
			<p><span>Boston, MA</span>
													<span>|</span>
													<span>June 23, 2026</span>
							</p>
			
		</div>
	</div>

<p>Tesla has a <em>lot </em>of other projects on its plate, which were detailed in the shareholder letter. The company has started pilot production at its lithium refinery in Texas. It’s developing new in-house inference chips for its autonomy and robotics programs. And it plans to reveal the third-generation version of its Optimus robot in the first quarter of this year.</p>

<p><em>This story is developing</em>&nbsp;…</p>


</div><div>
	
	
	
	

	
<div>
		<p>Sean O’Kane is a reporter who has spent a decade covering the rapidly-evolving business and technology of the transportation industry, including Tesla and the many startups chasing Elon Musk. Most recently, he was a reporter at Bloomberg News where he helped break stories about some of the most notorious EV SPAC flops. He previously worked at The Verge, where he also covered consumer technology, hosted many short- and long-form videos, performed product and editorial photography, and once nearly passed out in a Red Bull Air Race plane.</p>
<p>You can contact or verify outreach from Sean by emailing <a href="mailto:sean.okane@techcrunch.com">sean.okane@techcrunch.com</a> or via encrypted message at okane.01 on Signal.</p>	</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/sean-okane/" data-event="button" href="https://techcrunch.com/author/sean-okane/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple to Soon Take Up to 30% Cut from All Patreon Creators in iOS App (839 pts)]]></title>
            <link>https://www.macrumors.com/2026/01/28/patreon-apple-tax/</link>
            <guid>46801419</guid>
            <pubDate>Wed, 28 Jan 2026 20:59:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.macrumors.com/2026/01/28/patreon-apple-tax/">https://www.macrumors.com/2026/01/28/patreon-apple-tax/</a>, See on <a href="https://news.ycombinator.com/item?id=46801419">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main" id="maincontent"><article expanded="true"><div data-io-article-url="/2026/01/28/patreon-apple-tax/"><p>Apple has set a new deadline of November 1, 2026 for all <a href="https://apps.apple.com/us/app/patreon/id1044456188">Patreon</a> creators to switch from Patreon's legacy billing system to the App Store's in-app purchase system in the Patreon app on the iPhone and iPad, as <a href="https://techcrunch.com/2026/01/28/apple-tells-patreon-to-move-creators-to-in-app-purchase-for-subscriptions-by-november/">reported by <em>TechCrunch</em></a>.</p>
<p><img src="https://images.macrumors.com/t/juCKbtsR6vHD7VJNMPfqcM2EVg0=/400x0/article-new/2026/01/Tim-Cooking.jpg?lossy" srcset="https://images.macrumors.com/t/juCKbtsR6vHD7VJNMPfqcM2EVg0=/400x0/article-new/2026/01/Tim-Cooking.jpg?lossy 400w,https://images.macrumors.com/t/PfYdfRInOmELVWISdbgtd2cZV0A=/800x0/article-new/2026/01/Tim-Cooking.jpg?lossy 800w,https://images.macrumors.com/t/HPvkDF3sphYEAzKX3QfLArhr0no=/1600x0/article-new/2026/01/Tim-Cooking.jpg 1600w,https://images.macrumors.com/t/mA15gUqGqDeRPDXf1g4fX10o200=/2500x0/filters:no_upscale()/article-new/2026/01/Tim-Cooking.jpg 2500w" sizes="(max-width: 900px) 100vw, 697px" alt="Tim Cooking" width="1600" height="900"><em><small>Note: This image has been edited to include a pile of cash.</small></em></p><p>Patreon is a platform where creators such as YouTubers can receive payments from fans, which can be a valuable revenue stream alongside ads and sponsorships.</p>
<p>Apple initially told Patreon that its creators must move to the App Store's in-app purchase system <a href="https://www.macrumors.com/2024/08/12/patreon-in-app-purchase-fees/">by November 2025</a>, or else Patreon would risk removal from the App Store, but the deadline was pushed back. Apple considers payments from supporters to creators on Patreon to be digital goods that it is entitled to receive a commission on.</p>
<p>Apple receives a 30% commission on in-app purchases and subscriptions, but this drops to 15% for a subscription that has been ongoing for more than a year.</p>
<p>Patreon gives creators the option to either increase their prices in the iOS app only, or absorb the fee themselves, keeping prices the same across platforms.</p>
<p>On the iPhone and iPad, Patreon users who wish to support a creator can sidestep the App Store's commission by completing their payment via Patreon's website.</p>
<p>Patreon said it is disappointed with how Apple has navigated this policy.</p>
<p>According to <em>TechCrunch</em>, only 4% of Patreon creators are still using the platform's legacy billing system, with the rest having already switched over.</p>
<p>Patreon has <a href="https://support.patreon.com/hc/en-us/articles/28801582599181-iOS-In-app-Purchases-and-Migrating-to-Subscription-Billing-FAQ">shared a FAQ</a> with more details for creators.</p>
</div></article><p><h2>Popular Stories</h2></p><div><h3><a href="https://www.macrumors.com/2026/01/26/apple-unveils-first-two-products-of-2026/">Apple Unveils First New Products of 2026</a></h3><p>Apple today introduced its first two physical products of 2026: a second-generation AirTag and the Black Unity Connection Braided Solo Loop for the Apple Watch.
Read our coverage of each announcement to learn more:Apple Unveils New AirTag With Longer Range, Louder Speaker, and More
Apple Introduces New Black Unity Apple Watch BandBoth the new AirTag and the Black Unity Connection Braided...</p></div><div><h3><a href="https://www.macrumors.com/2026/01/26/iphone-5s-software-update/">iPhone 5s Gets New Software Update 13 Years After Launch</a></h3><p>Monday January 26, 2026 3:56 pm PST by <a href="https://www.macrumors.com/author/juli-clover/" rel="author">Juli Clover</a></p><p>Alongside iOS 26.2.1, Apple today released an updated version of iOS 12 for devices that are still running that operating system update, eight years after the software was first released.
iOS 12.5.8 is available for the iPhone 5s and the iPhone 6, meaning Apple is continuing to support these devices for 13 and 12 years after launch, respectively. The iPhone 5s came out in September 2013,...</p></div><div><h3><a href="https://www.macrumors.com/2026/01/26/apple-announces-new-airtag/">Apple Unveils New AirTag With Longer Range, Louder Speaker, and More</a></h3><p>Apple today introduced the second-generation AirTag, with key features including longer range for tracking items and a louder speaker.
For those who are not familiar, the AirTag is a small accessory that you can attach to your backpack, keys, or other items. Then, you can track the location of those items in the Find My app on the iPhone, iPad, Mac, Apple Watch, and iCloud.com.
The new...</p></div><div><h3><a href="https://www.macrumors.com/2026/01/25/rumored-apple-products/">Apple to Launch These 20+ Products This Year</a></h3><p>2026 promises to be yet another busy year for Apple, with the company rumored to be planning more than 20 product announcements over the coming months.
Beyond the usual updates to iPhones, iPads, Macs, and Apple Watches, Apple is expected to release its all-new smart home hub, which was reportedly delayed until the more personalized version of Siri is ready. Other unique products rumored for ...</p></div><div><h3><a href="https://www.macrumors.com/2026/01/27/apples-next-launch-is-tomorrow/">Apple's Next Launch is Today</a></h3><p>Tuesday January 27, 2026 2:39 pm PST by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>Update: Apple Creator Studio is now available.
Apple Creator Studio launches this Wednesday, January 28. The all-in-one subscription provides access to the Final Cut Pro, Logic Pro, Pixelmator Pro, Motion, Compressor, and MainStage apps, with U.S. pricing set at $12.99 per month or $129 per year.
A subscription to Apple Creator Studio also unlocks "intelligent features" and "premium...</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Native Instruments enters into insolvency proceedings (108 pts)]]></title>
            <link>https://www.engadget.com/audio/native-instruments-enters-into-insolvency-proceedings-leaving-its-future-uncertain-183206826.html</link>
            <guid>46800645</guid>
            <pubDate>Wed, 28 Jan 2026 19:51:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/audio/native-instruments-enters-into-insolvency-proceedings-leaving-its-future-uncertain-183206826.html">https://www.engadget.com/audio/native-instruments-enters-into-insolvency-proceedings-leaving-its-future-uncertain-183206826.html</a>, See on <a href="https://news.ycombinator.com/item?id=46800645">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-article-body="true"><p>Music hardware and software manufacturer Native Instruments has entered into preliminary insolvency proceedings, <a data-i13n="cpos:1;pos:1" href="https://cdm.link/ni-insolvency/" rel="nofollow noopener" target="_blank" data-ylk="slk:according to a report by Create Digital Music;cpos:1;pos:1;elm:context_link;itc:0;sec:content-canvas" data-yga="{&quot;yLinkText&quot;:&quot;according to a report by Create Digital Music&quot;,&quot;yLinkPosition&quot;:&quot;1&quot;,&quot;yPosition&quot;:&quot;1&quot;,&quot;yLinkElement&quot;:&quot;context_link&quot;,&quot;yModuleName&quot;:&quot;content-canvas&quot;,&quot;yHasCommerce&quot;:false}"><ins>according to a report by </ins><em><ins>Create Digital Music</ins></em></a>. This is the company behind iconic software like Massive, Traktor and Kontakt and hardware like Maschine+. Native Instruments also owns the brands iZotope, Brainworx and Plugin Alliance.</p><p>We don't have many specifics as to what this entails and what the future of the company will look like. We do know that an administrator has been appointed to handle restructuring and, potentially, to sell off existing assets. Native Instruments employs hundreds of people and their fates also remain uncertain.</p><p>A private equity firm called Francisco Partners owns a majority stake in the company. It also owns majority stakes in entities like GoodRX and Verifone, among others. This isn't the first time Native Instruments has been forced into major restructuring. The company experienced plenty of layoffs and uncertainty <a data-i13n="cpos:2;pos:1" href="https://djtechtools.com/2019/09/03/shakeups-layoffs-whats-happening-at-native-instruments/" rel="nofollow noopener" target="_blank" data-ylk="slk:between 2019 and 2020;cpos:2;pos:1;elm:context_link;itc:0;sec:content-canvas" data-yga="{&quot;yLinkText&quot;:&quot;between 2019 and 2020&quot;,&quot;yLinkPosition&quot;:&quot;2&quot;,&quot;yPosition&quot;:&quot;1&quot;,&quot;yLinkElement&quot;:&quot;context_link&quot;,&quot;yModuleName&quot;:&quot;content-canvas&quot;,&quot;yHasCommerce&quot;:false}"><ins>between 2019 and 2020</ins></a> before being purchased by private equity.</p><p>Again, we have no idea how this will shake out. It's possible that new investors will jump on board and it goes back to business as usual. It's also possible everything will be scrapped for parts and sold to the highest bidder.</p><div><blockquote><div><p>Plugin Alliance, with entities in the US and Germany, says there's no immediate impact of the NI insolvency on them. <a href="https://t.co/u6smg1X0t4" rel="nofollow noopener" target="_blank" data-ylk="slk:https://t.co/u6smg1X0t4;elm:context_link;itc:0;sec:content-canvas" data-yga="{&quot;yLinkText&quot;:&quot;https&quot;,&quot;yLinkElement&quot;:&quot;context_link&quot;,&quot;yModuleName&quot;:&quot;content-canvas&quot;,&quot;yHasCommerce&quot;:false}">https://t.co/u6smg1X0t4</a> <a href="https://t.co/ok7BRwo3BU" rel="nofollow noopener" target="_blank" data-ylk="slk:pic.twitter.com/ok7BRwo3BU;elm:context_link;itc:0;sec:content-canvas" data-yga="{&quot;yLinkText&quot;:&quot;pic.twitter.com/ok7BRwo3BU&quot;,&quot;yLinkElement&quot;:&quot;context_link&quot;,&quot;yModuleName&quot;:&quot;content-canvas&quot;,&quot;yHasCommerce&quot;:false}">pic.twitter.com/ok7BRwo3BU</a></p><p>— cdmblogs (@cdmblogs) <a href="https://twitter.com/cdmblogs/status/2016499892064014356?ref_src=twsrc%5Etfw" rel="nofollow noopener" target="_blank" data-ylk="slk:January 28, 2026;elm:context_link;itc:0;sec:content-canvas" data-yga="{&quot;yLinkText&quot;:&quot;January 28, 2026&quot;,&quot;yLinkElement&quot;:&quot;context_link&quot;,&quot;yModuleName&quot;:&quot;content-canvas&quot;,&quot;yHasCommerce&quot;:false}">January 28, 2026</a></p></div></blockquote></div><p>We do know that subsidiary Plugin Alliance seems to be unaffected. It issued a <a data-i13n="cpos:3;pos:1" href="https://www.gearnews.com/native-instruments-insolvency/" rel="nofollow noopener" target="_blank" data-ylk="slk:statement on Facebook;cpos:3;pos:1;elm:context_link;itc:0;sec:content-canvas" data-yga="{&quot;yLinkText&quot;:&quot;statement on Facebook&quot;,&quot;yLinkPosition&quot;:&quot;3&quot;,&quot;yPosition&quot;:&quot;1&quot;,&quot;yLinkElement&quot;:&quot;context_link&quot;,&quot;yModuleName&quot;:&quot;content-canvas&quot;,&quot;yHasCommerce&quot;:false}">statement on Facebook</a> saying that it isn't involved with the proceedings and that operations will continue as normal. This means new plugins will be released, along with updates for current software.</p><p>Everything else is still up in the air. This is troubling for those who have heavily invested in the company's ecosystem of products. I'm one of them. Any hope I had for a <a data-i13n="cpos:4;pos:1" href="https://www.engadget.com/maschine-plus-native-instruments-virtual-instruments-groovebox-155725975.html" data-ylk="slk:hardware refresh of the Maschine+;cpos:4;pos:1;elm:context_link;itc:0;sec:content-canvas" data-yga="{&quot;yLinkText&quot;:&quot;hardware refresh of the Maschine+&quot;,&quot;yLinkPosition&quot;:&quot;4&quot;,&quot;yPosition&quot;:&quot;1&quot;,&quot;yLinkElement&quot;:&quot;context_link&quot;,&quot;yModuleName&quot;:&quot;content-canvas&quot;,&quot;yHasCommerce&quot;:false}"><ins>hardware refresh of the Maschine+</ins></a> just went out the window.</p><iframe height="auto" loading="lazy" src="https://www.youtube.com/embed/D4u79Z3_7xw?si=VjUk1AlbtO89Dx0e" title="youtube embed content" width="100%" data-pw="iframe"></iframe><p>If the company's robust line of software goes up for sale, Akai is likely the best bet. It has already begun incorporating <a data-i13n="cpos:5;pos:1" href="https://www.engadget.com/entertainment/music/many-akai-devices-will-soon-support-native-instruments-sound-packs-140059822.html" data-ylk="slk:Native Instruments software into MPC machines;cpos:5;pos:1;elm:context_link;itc:0;sec:content-canvas" data-yga="{&quot;yLinkText&quot;:&quot;Native Instruments software into MPC machines&quot;,&quot;yLinkPosition&quot;:&quot;5&quot;,&quot;yPosition&quot;:&quot;1&quot;,&quot;yLinkElement&quot;:&quot;context_link&quot;,&quot;yModuleName&quot;:&quot;content-canvas&quot;,&quot;yHasCommerce&quot;:false}"><ins>Native Instruments software into MPC machines</ins></a>.</p></div></div>]]></description>
        </item>
    </channel>
</rss>