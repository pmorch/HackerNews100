<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 24 Jul 2024 07:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[What "consent" looks like for the DEA and TSA (160 pts)]]></title>
            <link>https://papersplease.org/wp/2024/07/23/what-consent-really-looks-like-for-the-dea-and-tsa/</link>
            <guid>41053329</guid>
            <pubDate>Wed, 24 Jul 2024 03:16:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://papersplease.org/wp/2024/07/23/what-consent-really-looks-like-for-the-dea-and-tsa/">https://papersplease.org/wp/2024/07/23/what-consent-really-looks-like-for-the-dea-and-tsa/</a>, See on <a href="https://news.ycombinator.com/item?id=41053329">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primary" role="main">	
			
<article id="post-18773">
			
	
	<p><span>Jul</span>
		<span>23</span>
		<span>2024</span>
	</p>
		
	<div>
		<p>The Drug Enforcement Agency (DEA) and the Transportation Security Administration (TSA) have been <a href="https://papersplease.org/wp/2015/05/01/secondary-inspection-used-as-pretext-for-airport-drug-searches/">working together</a> for years to steal travelers’ money.</p>
<p>The DEA <a href="https://papersplease.org/wp/2016/08/10/dea-recruits-airline-travel-industry-staff-to-inform-on-travelers/">pays informers</a> to finger people who might be flying with large amounts of cash, and gets the TSA to identify these people when they go through TSA checkpoints at airports, claims that they “consent” to be searched, and then finds any money they are carrying and seizes it through “civil forfeiture”.</p>
<p>The DEA carries out <a href="https://papersplease.org/wp/2016/10/03/how-the-dea-uses-travel-company-spies-to-confiscate-travelers-cash/">similar cash-seizure operations on Amtrak trains</a> — mostly domestic trains that don’t cross the US border — in collaboration with US Customs and Border Protection (CBP).</p>
<p>A new <a href="https://www.youtube.com/watch?v=0XBzV0bDZdQ">video</a> released by the <a href="https://ij.org/press-release/new-institute-for-justice-video-exposes-unconstitutional-airport-interdiction-tactic">Institute for Justice</a> shows how this “consent” works in practice.</p>
<p>In the w <a href="https://www.youtube.com/watch?v=0XBzV0bDZdQ">video</a>, a DEA agent won’t take “<a href="https://www.youtube.com/watch?v=0XBzV0bDZdQ">I don’t consent to a search</a>” for an answer. The agent follows an airline passenger onto their plane (without objection by airline staff), snatches the passenger’s carry-on bag, carries it off the plane, and refuses to return it. The agent claims the right to keep the passenger’s bag as long as it takes to get a warrant (although they don’t have that right, and don’t actually get a warrant).</p>
<p>This is not meaningful “consent”, and it’s not a valid legal basis for a search.</p>
<p>An ongoing <a href="https://www.courtlistener.com/docket/16702479/brown-v-transportation-security-adminstration/">class-action lawsuit</a> by the <a href="https://ij.org/case/dea-tsa-forfeitures/">Institute for Justice</a> on behalf&nbsp; of air travelers who have been searched without probable cause on the pretextual claim of “consent” in order to find, seize, and “forfeit” their cash has shown just how common this pattern of illegal search and seizure is.</p>
<p>We reported on the <a href="https://papersplease.org/wp/2020/01/17/is-the-tsa-screening-for-threats-to-aviation-or-for-cash-and-drugs/">filing&nbsp; of this lawsuit</a> in 2020, and on the <a href="https://papersplease.org/wp/2021/04/05/can-tsa-checkpoints-be-used-as-a-general-law-enforcement-dragnet/">first substantive ruling</a> in the case, in favor of the plaintiffs and allowing the case to move forward, in 2021.</p>
<p>Since then, the case has <a href="https://www.courtlistener.com/docket/16702479/brown-v-transportation-security-adminstration/">bogged down</a> in foot-dragging by the DEA and TSA, <a href="https://storage.courtlistener.com/recap/gov.uscourts.pawd.263087/gov.uscourts.pawd.263087.127.0.pdf">resisting discovery</a> of their records of&nbsp; searches and seizures of cash from travelers at airports.</p>
<p>The DEA and TSA continue to claim — despite the <a href="https://papersplease.org/wp/2021/04/05/can-tsa-checkpoints-be-used-as-a-general-law-enforcement-dragnet/">initial ruling against them</a> on this point —&nbsp; that they don’t have an actionable “policy” of targeting travelers with cash for searches because they haven’t put this policy in writing. But the latest <a href="https://storage.courtlistener.com/recap/gov.uscourts.pawd.263087/gov.uscourts.pawd.263087.127.0.pdf">status report</a> on discovery to date indicates that the DEA and TSA have made thousands of seizures of “bulk currency” from air travelers in recent years. This is clearly a routine and officially sanctioned agency practice, whether or not anyone has put it in writing.</p>
<p>The DEA and TSA claim that the volume of records of these searches and seizures would make producing them unduly burdensome. But the volume of these records is symptomatic of the scale and systemic nature of the problem — which is what the plaintiffs are trying to prove. The plaintiffs have suggested examining a statistical sample of the records of airport searches and seizures, but the DEA and TSA are resisting even that.</p>
<p>We wish the plaintiffs in this case and their lawyers success in their pursuit of justice for travelers.</p>
			</div>
</article><!-- #post-18773 -->
	<!-- #nav-below -->
	

	<!-- #comments .comments-area -->
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You can opt out of airport face scans (220 pts)]]></title>
            <link>https://www.vox.com/future-perfect/360952/summer-travel-airport-facial-recognition-scan</link>
            <guid>41051327</guid>
            <pubDate>Tue, 23 Jul 2024 21:50:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vox.com/future-perfect/360952/summer-travel-airport-facial-recognition-scan">https://www.vox.com/future-perfect/360952/summer-travel-airport-facial-recognition-scan</a>, See on <a href="https://news.ycombinator.com/item?id=41051327">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Here’s something I’m embarrassed to admit: Even though I’ve been reporting on <a href="https://www.vox.com/future-perfect/2019/4/27/18518598/ai-facial-recognition-ban-apple-amazon-microsoft">the problems</a> with <a href="https://www.vox.com/future-perfect/2019/5/16/18625137/ai-facial-recognition-ban-san-francisco-surveillance">facial recognition</a> for <a href="https://www.theatlantic.com/international/archive/2018/08/china-surveillance-technology-muslims/567443/">half a dozen years</a>, I have allowed my face to be scanned at airports. Not once. Not twice. Many times. </p><p>There are lots of reasons for that. For one thing, traveling is stressful. I feel time pressure to make it to my gate quickly and social pressure not to hold up long lines. (This alone makes it feel like I’m not truly consenting to the face scans so much as being coerced into them.) Plus, I’m always getting “randomly selected” for additional screenings, maybe because of my Middle Eastern background. So I get nervous about doing anything that might lead to extra delays or interrogations.</p><p>But the main reason I haven’t declined airport face scans is actually very simple: I had no idea I could opt out. </p><p>It turns out that saying no is not only doable, but <a href="https://keepbeyond.com/optout/">surprisingly easy</a> — at least in theory. Everyone, regardless of citizenship, can opt out when it comes to domestic flights in the US. (For international flights, US citizens can opt out but foreign nationals have to participate in face scanning, <a href="https://www.cbp.gov/about/congressional-resources/testimony/statement-record-assessing-cbps-use-facial-recognition-technology">with some exceptions</a>.) Simply stand away from the camera or keep your face covered with a mask, present your ID, and say, “I opt out of biometrics. I want the standard verification process.” </p><div><p>In theory, an officer is then supposed to manually look over your ID and compare it to your face, as they used to do before facial recognition. But in practice, there have been <a href="https://www.washingtonpost.com/technology/2023/07/11/tsa-airport-security-facial-recognition/">reports of passengers — even a senator — facing resistance or intimidation</a> when they try to go this route. </p></div><p>The Transportation Security Administration (TSA) and Customs and Border Protection (CBP) are also supposed to have clear signs informing passengers of the right to opt out. But at many airports, you have to look really, really hard to spot that message. Be prepared to crane your neck at an unnatural angle or squint at a very small font!</p><p>This is why the Algorithmic Justice League, a nonprofit that sheds light on AI harms, launched a campaign this month called <a href="https://www.ajl.org/campaigns/fly">“Freedom Flyers”</a> to raise awareness of your right to opt out. The timing is perfect: The TSA <a href="https://thehill.com/regulation/transportation/4738416-transportation-security-administration-record-air-travel-day/">recorded</a> an all-time record day for air travel on June 23, with nearly 3 million people screened at the country’s airports as summer vacation season picked up. </p><p>Now is the ideal time to make sure you know your rights when you pass through airport security — and understand exactly what’s at stake. The implications go way beyond air travel. </p><div><p id="how-facial-recognition-works-at-the-airport"><h2>How facial recognition works at the airport</h2></p></div><p>In the US, <a href="https://apnews.com/article/facial-recognition-tsa-airport-security-privacy-7b97462591c49184d1cb19cda9c95211">over 80 airports</a> are currently piloting facial recognition technology. The TSA’s goal is to roll out the tech in all of the more than 430 airports that it covers, <a href="https://www.tsa.gov/sites/default/files/tsa_biometrics_roadmap.pdf">arguing</a> that this kind of automation would reduce “friction” at airports — meaning, presumably, how long it takes passengers to move through security. </p><p>That should raise some eyebrows, because there are known risks with this AI technology, from the possibility that your face data will be <a href="https://www.oversight.gov/report/dhs/review-cbps-major-cybersecurity-incident-during-2019-biometric-pilot">stolen due to breaches</a> to the chance that you’ll be <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html">misidentified as a criminal suspect — and jailed</a>. Neither of these are hypothetical scenarios; the former has happened due to CBP system vulnerabilities and the latter has happened at the hands of police. And then, of course, there’s <a href="https://www.vox.com/future-perfect/22916602/ai-bias-fairness-tradeoffs-artificial-intelligence">AI bias</a>; facial recognition tech is known to disproportionately <a href="https://www.vox.com/future-perfect/2019/4/19/18412674/ai-bias-facial-recognition-black-gay-transgender">misidentify people of color</a>. (A CBP spokesperson insisted that the agency’s facial comparison algorithm “shows virtually no measurable differential performance in results based on demographic factors.”)</p><p>But as dangerous as face recognition can be if it goes wrong, a greater concern could be what happens if it’s seen to work as intended. When I asked <a href="https://www.vox.com/future-perfect/23365558/future-perfect-50-ai-joy-buolamwini-founder-algorithmic-justice-league">Joy Buolamwini</a>, the founder of the Algorithmic Justice League, what worries her about the use of this tech in airports, she said, “The big one for me is normalizing surveillance.”</p><p>Buolamwini argued that airport face recognition is a way of acclimating the public to having more and more sensitive information taken. “I see this on a longer trajectory,” she said. “And they’ve shown you the trajectory.”</p><p>She was referring to <a href="https://www.tsa.gov/sites/default/files/tsa_biometrics_roadmap.pdf">a roadmap released in 2018 by the TSA</a>. It distinguishes between two types of facial recognition: There’s one-to-one matching, where the TSA compares the photo in your passport with the photo they take of you at the airport, to make sure that the photos match. (If you ever use your face to unlock your iPhone, this is the kind of facial recognition you’re using.)</p><p>Then there’s one-to-many matching, where your image is compared with images of others. One-to-many matching is already in use by CBP and airline partners in that they compare a passenger’s photo to a database of government documents (like US passports) for verification, TSA press secretary Carter Langston told me by email.</p><p>A particularly worrisome form of one-to-many matching is live biometrics. “Live biometrics is the <em>Minority Report</em> kind of thing — where you’re just walking around and they can identify you,” Buolamwini said. And if everyone’s face becomes fair game for live biometrics, your likeness could one day be checked against a criminal database any time you walk through a drug store or show up at a protest, which may <a href="https://www.vox.com/future-perfect/2019/5/16/18625137/ai-facial-recognition-ban-san-francisco-surveillance">create a dangerous chilling effect</a> across society. </p><p>The TSA’s own 2018 roadmap says they aim to use “live biometrics” in the future. However, Langston disputed Buolamwini’s interpretation of that term. “That interpretation of TSA’s use case is nothing that I have heard anyone involved in the program indicate. TSA’s use case is and continues to be about identity verification,” he told me.</p><p>For now, Buolamwini said, “You might hear people say ‘Oh, we’re only doing one-to-one matching. You show us your ID, you show us your face, and we delete the data.’” But, she stressed, the full story is more complicated.</p><div><p id="do-airports-really-delete-your-photo-after-taking-it"><h2>Do airports really delete your photo after taking it?</h2></p></div><p>The first thing to know is that if you’re not a US citizen, you have no guarantee that your photo will be deleted. </p><p>In fact, <a href="https://www.cbp.gov/sites/default/files/assets/documents/2022-Sep/CPE%20Final%20Report%20Traveler%20Verification%20Service%2020220815%20Final_%20Redacted_0.pdf">according to CBP documents</a>, “Facial images for in-scope [noncitizen] travelers are also transmitted to the Department’s Automated Biometric Identification System (IDENT) and Homeland Advanced Recognition Technology System (HART). All biometrics of in-scope travelers are transmitted to IDENT/HART as encounters and are retained for 75 years in support of immigration, border management, and law enforcement activities.”</p><p>That means your photo could end up in the database for the rest of your life. What’s more, CBP <a href="https://www.dhs.gov/sites/default/files/publications/privacy-pia-cbp056-tvs-february2021.pdf">notes</a> that “CBP may share information with federal, state, and local authorities, which may be authorized to use the information for purposes beyond the scope of CBP’s mission.”</p><p>If you’re a US citizen, you might breathe a bit easier upon reading on the CBP <a href="https://www.cbp.gov/travel/biometrics/biometric-privacy-policy">website</a>, “CBP retains U.S. citizen photos for no more than 12 hours after identity verification, and only for continuity of operations purposes.” But even so, Buolamwini says, there’s reason to wonder whether all your data is really deleted after those 12 hours.</p><p>When you submit to facial recognition, the tech analyzes a photo of your face and creates what’s called a “face print” or “face template.” This is not an image — it comes in the form of a series of numbers. You can think of it as your face’s metadata. </p><p>The problem is, even if airports do delete your photo, that does not necessarily mean they’re deleting your face print. And that face print is the real informational gold. Researchers have shown that <a href="https://ieeexplore.ieee.org/document/8338413">they can reconstruct an image of your actual face</a> as long as they’ve got the face print. </p><p>I asked CBP what happens to that precious series of numbers. A CBP spokesperson did not answer the question about whether face prints get deleted in time for publication. After we published this story, the CBP spokesperson said that “CBP does not store or share the templates generated during the matching process, for either US citizens or non-citizens.”</p><div><p id="if-youve-already-let-airports-scan-your-face-is-there-a-point-in-saying-no-next-time"><h2>If you’ve already let airports scan your face, is there a point in saying no next time?</h2></p></div><p>Maybe you’re in the same situation as me. Maybe you’ve already let airports scan your face. And maybe you’re wondering whether saying no in the future will make any difference, given that your face data is probably already in a database — or two — or three. (Separate from TSA, your individual airline may also scan your face instead of your boarding pass before letting you on the plane, though airlines <a href="https://www.pcmag.com/opinions/you-can-say-no-to-face-scans-for-airplane-boarding">say</a> you can opt out for domestic flights.)</p><p>Buolamwini’s opinion? It’s definitely still worth declining the face scan next time you fly. “Every opt-out opportunity is a way to vote for your biometric rights,” she said.</p><p>We’ve already seen that when there’s enough of a public outcry, it can lead to deletion of face data. After Facebook’s facial recognition system sparked a class-action lawsuit, government investigations, and public furor, the company ended up <a href="https://www.nytimes.com/2021/11/02/technology/facebook-facial-recognition.html">deleting the face prints of more than a billion users</a> in 2021. </p><p>“Face purges can and do happen,” Buolamwini said. </p><p>Remember, the TSA’s stated reason for rolling out facial recognition in airports is to minimize friction. If you’re unhappy about the use of the tech, you can consider generating more friction next time you fly. </p><div><p><em>A version of this story originally appeared in the </em><a href="https://www.vox.com/future-perfect"><em><strong>Future Perfect</strong></em></a><em> newsletter. </em><a href="https://www.vox.com/pages/future-perfect-newsletter-signup"><em><strong>Sign up here!</strong></em></a></p></div><p><em><strong>Update, July 19, 2:30 pm ET: </strong>This story was originally published July 17 and has been updated with new comment from US Customs and Border Protection.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hydrothermal explosion at Yellowstone National Park (378 pts)]]></title>
            <link>https://www.jhnewsandguide.com/the_hole_scroll/video-biscuit-basin-geyser-explodes-sending-yellowstone-tourists-packing/article_6862fda2-4923-11ef-b5c4-abdc9bc8cd83.html</link>
            <guid>41050055</guid>
            <pubDate>Tue, 23 Jul 2024 19:49:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jhnewsandguide.com/the_hole_scroll/video-biscuit-basin-geyser-explodes-sending-yellowstone-tourists-packing/article_6862fda2-4923-11ef-b5c4-abdc9bc8cd83.html">https://www.jhnewsandguide.com/the_hole_scroll/video-biscuit-basin-geyser-explodes-sending-yellowstone-tourists-packing/article_6862fda2-4923-11ef-b5c4-abdc9bc8cd83.html</a>, See on <a href="https://news.ycombinator.com/item?id=41050055">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p><label for="field-postal-state-super-purchase">
                            State
                        </label>
                        
                    </p>
                    <p><label for="field-postal-postcode-super-purchase">
                            Zip Code
                        </label>
                        
                    </p>
                    <p><label for="field-postal-country-super-purchase">
                            Country
                        </label>
                        
                    </p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: All VC Funded Startups Aggregated (Statistics) (370 pts)]]></title>
            <link>https://old.reddit.com/r/LeadGeneration/comments/1ea8r16/httpswwwredditcomremailcomments1ea8qd2i_built_a/</link>
            <guid>41049968</guid>
            <pubDate>Tue, 23 Jul 2024 19:41:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/LeadGeneration/comments/1ea8r16/httpswwwredditcomremailcomments1ea8qd2i_built_a/">https://old.reddit.com/r/LeadGeneration/comments/1ea8r16/httpswwwredditcomremailcomments1ea8qd2i_built_a/</a>, See on <a href="https://news.ycombinator.com/item?id=41049968">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="searchexpando"><p><label>limit my search to r/LeadGeneration</label></p><div id="moresearchinfo"><p>use the following search parameters to narrow your results:</p><dl><dt>subreddit:<i>subreddit</i></dt><dd>find submissions in "subreddit"</dd><dt>author:<i>username</i></dt><dd>find submissions by "username"</dd><dt>site:<i>example.com</i></dt><dd>find submissions from "example.com"</dd><dt>url:<i>text</i></dt><dd>search for "text" in url</dd><dt>selftext:<i>text</i></dt><dd>search for "text" in self post contents</dd><dt>self:yes (or self:no)</dt><dd>include (or exclude) self posts</dd><dt>nsfw:yes (or nsfw:no)</dt><dd>include (or exclude) results marked as NSFW</dd></dl><p>e.g. <code>subreddit:aww site:imgur.com dog</code></p><p><a href="https://www.reddit.com/wiki/search">see the search faq for details.</a></p></div><p><a href="https://www.reddit.com/wiki/search" id="search_showmore">advanced search: by author, subreddit...</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Drive scans files for copyright infringement (116 pts)]]></title>
            <link>https://twitter.com/1littlecoder/status/1815830211612586255</link>
            <guid>41049799</guid>
            <pubDate>Tue, 23 Jul 2024 19:26:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/1littlecoder/status/1815830211612586255">https://twitter.com/1littlecoder/status/1815830211612586255</a>, See on <a href="https://news.ycombinator.com/item?id=41049799">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How Olympics officials try to catch “motor doping” (154 pts)]]></title>
            <link>https://spectrum.ieee.org/motor-doping-cycling</link>
            <guid>41049399</guid>
            <pubDate>Tue, 23 Jul 2024 18:43:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/motor-doping-cycling">https://spectrum.ieee.org/motor-doping-cycling</a>, See on <a href="https://news.ycombinator.com/item?id=41049399">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="How Olympics Officials Try to Catch “Motor Doping”"><p>A French cycling official confronts a rider suspected of doping and ends up jumping onto the hood of a van making a high-speed getaway. This isn’t a tragicomedy starring <a href="https://en.wikipedia.org/wiki/G%C3%A9rard_Depardieu" target="_blank">Gérard Depardieu</a>, sending up the sport’s well-earned reputation for cheating. This scenario played out in May at the <a href="https://www.cyclingweekly.com/news/motor-doping-suspect-runs-down-race-organiser-while-escaping-inspection" target="_blank">Routes de l’Oise cycling competition</a> near Paris, and the van was believed to contain evidence of a distinctly 21st-century cheat: a hidden electric motor.<strong></strong></p><p>Cyclists call it “motor doping.” At the Paris Olympics opening on Friday, officials will be deploying electromagnetic scanners and X-ray imaging to combat it, as cyclists race for gold in and around the French capital. The officials’ prey can be quite small: Cycling experts say just 20 or 30 watts of extra power is enough to tilt the field and clinch a race.</p><p>Motor doping has been confirmed only once in professional cycling, way back in 2016. And the sport’s governing body, the <a href="https://www.uci.org/" target="_blank"><u>Union Cycliste Internationale</u></a> (UCI), has since introduced increasingly sophisticated motor-detection methods. But illicit motors remain a scourge at high-profile amateur events like the Routes de l’Oise. Some top professionals, past and present, continue to raise an alarm.</p><p>“It’s 10 years now that we’re speaking about this…. If you want to settle this issue you have to invest.” <strong>—Jean-Christophe Péraud, former Union Cycliste Internationale official</strong></p><p>Riders and experts reached by <em><a href="https://spectrum.ieee.org/">IEEE Spectrum</a></em> say it’s unlikely that technological doping still exists at the professional level. “I’m confident it’s not happening any more. I think as soon as we began to speak about it, it stopped. Because at a high level it’s too dangerous for a team and an athlete,” says <a href="https://www.procyclingstats.com/rider/jean-christophe-peraud" target="_blank"><u>Jean-Christophe Péraud</u></a>, an <a href="https://olympics.com/en/athletes/jean-christophe-peraud" target="_blank"><u>Olympic silver medalist</u></a> who <strong></strong>was UCI’s first <a href="https://www.uci.org/pressrelease/the-uci-presents-a-robust-action-plan-to-combat-technological-fraud/6omY2RZitUwewjShNVCAYH" target="_blank">Manager of Equipment and the Fight against Technological Fraud</a>. </p><p>But trust is limited. Cycling is still recovering from the scandals surrounding U.S. Olympian Lance Armstrong, whose extensive use of transfusions and drugs to boost blood-oxygen levels fueled <a href="https://www.theguardian.com/sport/2015/mar/09/lance-armstrong-uci-colluded-circ-report-cycling" target="_blank"><u>allegations of collusion by UCI officials</u></a> and threats to <a href="https://www.reuters.com/article/idUSBRE90E0ZX/" target="_blank"><u>boot cycling out of the Olympics</u></a>. </p><p>Many—including Péraud—say more vigilance is needed. The solution may be next-generation detection tech: onboard scanners that provide continuous assurance that human muscle alone is powering the sport’s dramatic sprints and climbs.</p><h2>How Officials Have Hunted for Motor Doping in Cycling</h2><p>Rumors of hidden motors first <a href="https://www.france24.com/en/20100602-fabio-cancellara-youtube-video-motorized-bike-rubbish-cycling-cheating" target="_blank"><u>swirled into the mainstream in 2010</u></a> after a Swiss cyclist clinched several European events with stunning accelerations. At the time the UCI lacked means of detecting concealed motors, and its technical director promised to “speed up” work on a “quick and efficient way” to do so. </p><p>The UCI began with <a href="https://road.cc/content/news/188441-mechanical-doping-uci-tested-and-rejected-thermal-imaging-detect-motors" target="_blank"><u>infrared cameras</u></a>, but they are useless for pre- and post-race checks when a hidden motor is cold. Not until 2015, amidst <a href="https://www.espn.com/sports/endurance/story/_/id/13272428/endurance-sports-velonews-tour-de-france-leader-chris-froome-facing-more-accusations" target="_blank"><u>further motor doping rumors</u></a> and <a href="https://road.cc/content/news/186575-hidden-motors-used-strade-bianche-claims-french-tv-video#:~:text=Jean-Pierre%20Vedry,%20the%20former,no%20reply,%20no%20checks.%E2%80%9D" target="_blank"><u>allegations of UCI inaction</u></a>, did the organization begin beta testing a better tool: an iPad-based “magnetometric tablet” scanner. </p><p>According to the UCI, an adapter plugged into one of these tablet scanners creates an ambient magnetic field. Then, a magnetometer and custom software register disruptions to the field that may indicate the presence of metal or magnets in and around a bike’s carbon-fiber frame.</p><p>UCI’s tablets delivered in their debut appearance, at the 2016 Cyclocross World Championships held that year in Belgium. Scans of bikes at the rugged event—a blend of road and mountain biking—<a href="https://www.cxmagazine.com/motor-mechanical-doping-femke-van-den-driessche-suspected-2016-cyclocross-world-championships-update" target="_blank"><u>flagged a bike</u></a> bearing the name of local favorite Femke Van den Driessche. Closer inspection revealed a motor and battery lodged within the hollow frame element that angles down from a bike’s saddle to its pedals, and wires connecting the seat tube’s hidden hardware to a push-button switch under the handlebars. </p><p><img alt="person in biking gear pushing bike up a hill on muddy terrain" data-rm-shortcode-id="7595488c2c38efa50c0515ed1fc5e689" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/person-in-biking-gear-pushing-bike-up-a-hill-on-muddy-terrain.jpg?id=52956711&amp;width=980" height="1875" id="57041" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/person-in-biking-gear-pushing-bike-up-a-hill-on-muddy-terrain.jpg?id=52956711&amp;width=980" width="2500"><small placeholder="Add Photo Caption...">In 2016, a concealed motor was found in a bike bearing Belgian cyclist Femke Van Den Driessche’s name at the world cyclo-cross championships. (Van Den Driessche is shown here with a different bike.)</small><small placeholder="Add Photo Credit...">AFP/Getty Images</small></p><p>Van den Driessche, banned from competition for six years, withdrew from racing while maintaining her innocence. (Giovambattista Lera, the amateur cyclist implicated earlier this year in France, <u><a href="https://road.cc/content/news/cyclist-accused-motor-doping-denies-wrong-doing-308633" target="_blank">also denies using electric assistance</a></u> in competition.)</p><p>The motor in Van den Driessche’s bike engaged with the bike’s crankshaft and added 200 W of power. The equipment’s Austrian manufacturer, <a href="https://web.archive.org/web/20171015031645/http://www.vivax-assist.com/en/" target="_blank"><u>Vivax Drive</u></a>, is now defunct. But anyone with cash to spare can experience 200 W of extra push via a racer equipped by Monaco-based HPS-Bike, such as the HPS-equipped <a href="https://www.lotuscars.com/en-GB/type-136" target="_blank">Lotus Type 136 racing bike</a> from U.K. sports car producer Lotus Group, which starts at £15,199 (US $19,715).<strong></strong></p><p>HPS founder &amp; CEO <a href="https://www.linkedin.com/in/harry-gibbings-ab8065201/?originalSubdomain=mc" target="_blank"><u>Harry Gibbings</u></a> says the company seeks to empower weekend riders who don’t want to struggle up steep hills or who need an extra boost here and there to keep up with the pack. Gibbings says the technology is not available for retrofits, and is thus off limits to would-be cheats. Still, <a href="https://www.ride-hps.com/watt-assist/" target="_blank"><u>the HPS Watt Assist system</u></a> shows the outer bounds of what’s possible in discreet high-performance electric assist. </p><p>The 30-millimeter-diameter, 300-gram motor, is manufactured by Swiss motor maker <a href="https://www.maxongroup.com/en" target="_blank"><u>Maxon Group</u></a>, and Gibbings says it uses essentially the same power-dense brushless design that’s propelling NASA’s <a href="https://robotsguide.com/robots/perseverance" target="_blank">Perseverance rover</a> on Mars. HPS builds the motor into a bike’s downtube, the frame element angling up from a bike’s crank toward its handlebars. </p><p>Notwithstanding persistent media speculation about <a href="https://spectrum.ieee.org/tag/electric-motors">electric motors</a> built into rear hubs or solid wheels, Gibbings says only a motor placed in a frame’s tubes can add power without jeopardizing the look, feel, and performance of a racing bike. </p><h2>UCI’s New Techniques to Spot Cheating in Cycling</h2><p>Professional cycling got its most sophisticated detection systems in 2018, after criticism of UCI motor-doping policies <a href="https://www.bbc.com/sport/cycling/41347950.amp" target="_blank"><u>helped fuel a change of leadership</u></a>. Incoming President David Lappartient <a href="http://www.apple.com/" target="_blank"><u>appointed Péraud to push detection</u></a> to new levels, and five months later UCI announced its first X-ray equipment at a press conference in Geneva. </p><p>Unlike the tablet scanners, which yield many false positives and require dismantling of suspect bikes, X-ray imaging is definitive. The <a href="https://www.youtube.com/watch?v=-iRwwquk7v0&amp;t=3s" target="_blank"><u>detector</u></a> is built into a shielded container and driven to events.</p><p>UCI told the cycling press that its X-ray cabinet would “remove any suspicion regarding race results.” And it says it maintains a high level of testing, with close to <a href="https://www.uci.org/pressrelease/the-uci-unveils-its-programme-to-combat-doping-and-technological-fraud-for/5j3GqEVkRlbPZaa3HfwVag#:~:text=At%20last%20year's%20Tour%20de,of%20technological%20fraud%20were%20detected." target="_blank"><u>1,000 motor-doping checks at last year’s Tour de France</u></a>. </p><p>UCI declined to speak with <em>IEEE Spectrum</em> about its motor-detection program, including plans for the Paris Olympics. But it appears to have stepped up vigilance. Lappartient recently acknowledged that UCI’s controls are “<a href="https://www.theguardian.com/sport/article/2024/jun/27/uci-to-pay-whistleblowers-for-motor-doping-tip-offs-at-tour-de-france?CMP=share_btn_url" target="_blank"><u>not 100 percent secure</u></a>” and announced a reward for whistleblowers who deliver evidence of motor fraud. In May, UCI once again <a href="https://www.uci.org/pressrelease/uci-appoints-nicholas-raudenski-as-head-of-the-fight-against-technological/2pu13dvS3ykOj9YOiCg4Aj" target="_blank"><u>appointed a motor-doping czar</u></a>—a first since <a href="https://www.insidethegames.biz/articles/1096111/peraud-loses-uci-role" target="_blank">Péraud departed</a> amidst budget cuts in 2020. Among other duties, former U.S. Department of Homeland Security criminal investigator Nicholas Raudenski is tasked with “development of new methods to detect technological fraud.” </p><p>Unlike the tablet scanners, X-ray imaging is definitive.</p><p>Péraud is convinced that only real-time monitoring of bikes throughout major races can prove that motor fraud is in the past, since big races provide ample opportunities to sneak in an additional bike and thus evade UCI’s current tools.</p><p>UCI has already laid the groundwork for such live monitoring, partnering with France’s <a href="https://www.cea.fr/english/Pages/Welcome.aspx" target="_blank">Alternative Energies and Atomic Energy Commission</a> (Commissariat à l’énergie atomique et aux énergies alternatives, or CEA) to capitalize on the national lab’s deep magnetometry expertise. UCI disclosed some details at its 2018 Geneva press conference, where a CEA official <a href="https://www.uci.org/article/the-uci-presents-a-robust-action-plan-to-combat-technological-fraud-185708/1RaUU9mAQ4qkyXKwN0rXp0" target="_blank"><u>presented its concept</u></a>: an embedded, high-resolution magnetometer to detect a hidden motor’s electromagnetic signature and wirelessly alert officials via receivers on race support vehicles. </p><p>As of June 2018, CEA researchers in Grenoble had <a href="https://www.minatec.org/en/cycling-detecting-hidden-electric-motors/" target="_blank"><u>identified an appropriate magnetometer</u></a> and were evaluating the electromagnetic noise that could challenge the system—“from rotating wheels and pedals to passing motorcycles and cars.” </p><p>Mounting detectors on every bike would not be cheap, but Péraud says he is convinced that cycling needs it: “It’s 10 years now that we’re speaking about this…. If you want to settle this issue you have to invest.” </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why is it so hard to share links on LinkedIn? (113 pts)]]></title>
            <link>https://tedium.co/2024/07/23/linkedin-complex-linking-schemes/</link>
            <guid>41049016</guid>
            <pubDate>Tue, 23 Jul 2024 18:08:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tedium.co/2024/07/23/linkedin-complex-linking-schemes/">https://tedium.co/2024/07/23/linkedin-complex-linking-schemes/</a>, See on <a href="https://news.ycombinator.com/item?id=41049016">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<p><strong>LinkedIn is a social network</strong> that deeply confuses me. It’s a social network that sends messages with such a level of vagueness, seemingly to ensure you’ll never figure them out.</p>
<p>It gamifies profile-viewing in a way that feels less professional and more creepy. Plus, it charges money—a lot of money—for most of its features. It’s a hugely successful network, one that some have suggested is the true heir to the “new Twitter” discourse.</p>
<p>But it has an algorithmic problem that must be called out: Despite the fact that “link” is literally in the network’s name, the network has an allergy towards external links.</p>
<p>And increasingly desperate posters and social media marketers are going through comically complex hoops to work around it. Recently, I caught a video from a guy named <a href="https://www.linkedin.com/in/markpjung/">Mark P. Jung</a>, a consultant whose startup <a href="https://authorityb2b.com/">Authority B2B</a> basically teaches companies and desired influencers the road they need to take to attain LinkedIn success. And to me, it seemed like he was trying to sell some magic beans that appear to actually function.</p>
</div><div>
    
<p>Jung, in a video <a href="https://www.linkedin.com/feed/update/urn:li:activity:7220040502555897856/">shared by content marketer Lindsay McGuire</a>, characterizes the changes as “interesting UI decisions” made since Microsoft acquired the company about eight years ago, changes that have invalidated linking hacks used by the network in prior eras.</p>
<p><a href="https://www.linkedin.com/feed/update/urn:li:activity:7220040502555897856/"><img data-src="https://images.tedium.co/uploads/zeroclick.jpg" width="1000" height="529" alt="Zeroclick" src="https://images.tedium.co/uploads/zeroclick.jpg"></a></p>
<p><em>Jung, in the video of his <a href="https://www.linkedin.com/feed/update/urn:li:activity:7220040502555897856/">that drew attention recently</a>. The use of the term “zero-click” is telling.</em></p>
<p>“Back in the day, people used to sort of get around LinkedIn stuff by just dropping a link in the comments and saying, ‘Hey, check out the comments,’” Jung explains. “Problem is, LinkedIn actually parses if you're the first person to comment in your post, if you're the first person to add a link, even if you actually write, like, the website, but remove the .com and say ‘dot com,’ this algorithm is on to you. It's immediately going to take your post and downrank it.”</p>
<p>So basically, Jung explains the alternative options for sharing a link on LinkedIn as such:</p>
<ol>
<li><strong>Post your thing,</strong> making it sufficiently long so the algorithm might enjoy it.  </li>
<li><strong>Get a little engagement</strong> on said thing, so you signal the post has some interest.</li>
<li><strong>Wait about 15 or 20 minutes.</strong>  </li>
<li><strong>Edit the post,</strong> adding content equivalent to up to 15 percent of the post length, including a URL (which you should shortlink, using a service like Bitly, because every character of the URL counts against the added length). </li>
<li><strong>If you did it right,</strong> watch number go up.</li>
</ol>
<p>Does that sound like a lot of work for a single social post? You betcha. You basically have to make this someone’s job because of how long it takes to do. And it’s likely why every post on LinkedIn is like 100,000 words.</p>
<p>To be clear, my beef is not with Jung, who knows how to build social influence and understands the secrets to algorithmic growth. He sounds like someone who spent his time in the salt mines and doesn’t particularly like that it works like this, either. That he knows about it, apparently having uncovered it through a bunch of trial and error with client work, and is sharing his secrets, is fair.</p>
<p>Rather, my issue is with LinkedIn itself, which has clearly put in a lot of work to devalue the link, even more than other networks that do the same thing, like Instagram and Facebook.</p>
<p>At the ISP and mobile provider level, <a href="https://www.eff.org/deeplinks/2016/02/zero-rating-what-it-is-why-you-should-care">there’s this concept called zero-rating</a>, in which an internet provider provides free access to a selection of sites without the sites counting against the bandwidth limits. (An example of this is T-Mobile <a href="https://www.theregister.com/2015/12/23/youtube_t_mobile_us/">limiting users to 480p-quality videos</a> when streaming on mobile, but requiring you to pay an upcharge for higher-quality videos.) It is seen as a controversial workaround for net neutrality rules—though, while it’s still out there, it has become less of a problem in developed nations as internet connections have gotten faster and more unlimited. LinkedIn is doing something similar with its platform, something called zero-click content, as Jung puts it.</p>
<p>The terminology Jung uses is more telling than you might expect—essentially, it basically implies a social media version of zero-rating, which is a very controversial concept on telecom circles. LinkedIn wants you to create more content for its platform, and it wants you to do so at the cost of any outwardly facing content. So, it downranks anything it sees as damaging to that goal, even if it means breaking the original point of the internet in the process. It is essentially the same concept as zero-rating, except at a more granular level.</p>
<p>The problem with this is twofold: First, it forces content on LinkedIn to take an extremely unnatural shape that doesn’t make sense for a social media platform, often extending well beyond what people want out of it, and two, it limits reach to anyone that doesn’t play by LinkedIn’s rules. It’s a free-trade issue, essentially, and LinkedIn is dominant enough in its niche of business content that a regulator should look into this.</p>
<p>In many ways, social media has these kinds of issues in spades—including on that site I still call Twitter, which has forced people to write gigantic threads instead of linking to blog posts, and Instagram, which is so dominant that it has allowed the creation of secondary businesses around the link in bio.</p>
<p>This is what social media has become, an attempt to work around algorithms, rather than a way to engage with people. <a href="https://www.anildash.com/2019/12/10/link-in-bio-is-how-they-tried-to-kill-the-web/">As Anil Dash wrote</a> back in 2019, with a focus on Instagram rather than LinkedIn, social media seems to be doing all it can to destroy the value of the link:</p>
<blockquote><p>There are some legitimate reasons platforms limit links. Spammers abuse links. Trust is hard to verify around links—too many scammers make links that look real, but lead to sketchy sites. Building a system to monitor all the links being posted on a big platform does take some cost. Maybe you can have a link again, if you are already in the 1% most influential users on the platform and put it in a story—the part of Instagram's experience that drives the engagement metrics they care about. Maybe you just give up, and pay for links, by buying advertising.</p>
<p>But killing off links is a strategy. It may be presented as a cost-saving measure, or as a way of reducing the sharing of untrusted links. But it is a strategy, designed to keep people from the open web, the place where they can control how, and whether, someone makes money off of an audience. The web is where we can make sites that don’t abuse data in the ways that Facebook properties do.</p>
</blockquote>
<p>If you’re committed to one ecosystem or another, you’re really committed. And LinkedIn wants committed users. But on the other hand, people don’t run their entire lives on LinkedIn. It’s not like Nike or Blackstone or your local cupcake shop or your local neighborhood content hustlers can just live on LinkedIn. But LinkedIn acts as if that’s what you need to do to get ahead, and it feels like something we should start talking about in earnest.</p>
<p>What is the value of the link? Why are there so many barricades between the audience you’ve built and the link you want to share? (Hint: They think it’s not really your audience.) And when should regulators step in to ensure that our social networks aren’t impeding commerce by impeding links?</p>
<p>I know Lina Khan is pretty busy these days, but it feels like a question she might be well-suited to help answer.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chinese-born chemist cleared of last conviction under US’s espionage probe (141 pts)]]></title>
            <link>https://www.chemistryworld.com/news/chinese-born-chemist-cleared-of-last-conviction-under-uss-espionage-probe/4019849.article</link>
            <guid>41048747</guid>
            <pubDate>Tue, 23 Jul 2024 17:41:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chemistryworld.com/news/chinese-born-chemist-cleared-of-last-conviction-under-uss-espionage-probe/4019849.article">https://www.chemistryworld.com/news/chinese-born-chemist-cleared-of-last-conviction-under-uss-espionage-probe/4019849.article</a>, See on <a href="https://news.ycombinator.com/item?id=41048747">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Following a five-year legal battle, Chinese-born former University of Kansas chemistry professor Feng ‘Franklin’ Tao, who was <a href="https://www.chemistryworld.com/news/us-chemistry-professor-convicted-under-now-defunct-china-initiative/4015510.article">arrested and convicted under the former Trump administration’s now-defunct ‘China Initiative’</a>, has been vindicated. An appeals court in Denver, Colorado has <a href="https://x.com/Profleoyu/status/1811593615514259592">acquitted Tao of his one remaining conviction</a> that he made a false statement about his relationship with a Chinese university.</p>
<p>In April 2022, Tao – a permanent US resident who before his arrest in 2019 had served as a tenured associate professor at the University of Kansas since 2014 – was not only convicted of making a ‘materially false statement’, but also of three counts of wire fraud. He faced up to 20 years in prison and substantial fines. However, he <a href="https://www.chemistryworld.com/news/us-chemist-feng-tao-avoids-prison-sentence-for-hiding-ties-to-china/4016855.article">was subsequently acquitted of the wire fraud charges and so only the now-overturned false statements conviction remained</a>. Ultimately, he was sentenced to time served with a $100 (£81) fine.</p>
<p>At issue in the new ruling, issued 11 July, is whether Tao’s lack of disclosure about his affiliation with Fuzhou University in China affected federal agency funding decisions. The Denver appeals court agreed 2-1 that it was irrelevant because Tao had no grant proposals pending before those two agencies in question – the US Department of Energy and National Science Foundation – at the time he made his affiliation statement.</p>
<p>Tao’s lawyer, Peter Zeidenberg welcomed the court’s ruling. ‘Even though there was not a scintilla of evidence that Dr Tao was engaged in espionage or theft of trade secrets, the government nevertheless relentlessly investigated him and ultimately charged him with 10 felonies – all based on an alleged omission on a single internal form he submitted to the University of Kansas research office and which was never shared with any federal agency,’ he stated. Those initial 10 charges were first reduced to three, then one, and now zero.</p>
<p>Zeidenberg emphasised that Tao’s reputation has been ‘unfairly dragged to the mud’, and he was ‘wrongly fired’ by the University of Kansas. ‘Dr Tao, a world-renowned expert in catalysis, has been unable to do his research, depriving all of us who benefit from scientific advances,’ Zeidenberg continued, noting that his legal fight has virtually bankrupted his family. Even with assistance from friends and family and a GoFundMe campaign, Tao still owes over $1 million in legal fees, he said.</p>
<p>Tao was one of an estimated two dozen academics who were charged under the US government’s China Initiative. The programme, launched in<strong> </strong>2018 to counter trade secret theft and economic espionage, was widely criticised as racially biased and harmful to academic freedom. It was eventually <a href="https://www.chemistryworld.com/news/us-ends-anti-espionage-china-initiative/4015301.article">terminated under President Biden in 2022</a> following <a href="https://www.chemistryworld.com/news/us-programme-targeting-researchers-with-china-links-crumbling-under-intense-scrutiny/4014572.article">the dismissal of many of the government’s criminal cases that were brought against university researchers under the initiative</a>.</p>
<p>The Asian–American Scholar Forum <a href="https://www.aasforum.org/2024/07/17/aasf-celebrates-dr-franklin-taos-appeal-victory/">called Tao’s latest court win ‘a significant victory’</a> and celebrated it as ‘a crucial step toward rectifying the unjust treatment of Chinese American and immigrant scientists under the now-defunct China Initiative’.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Warsaw came close to never being rebuilt (2015) (162 pts)]]></title>
            <link>https://culture.pl/en/article/how-warsaw-came-close-to-never-being-rebuilt</link>
            <guid>41048677</guid>
            <pubDate>Tue, 23 Jul 2024 17:33:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://culture.pl/en/article/how-warsaw-came-close-to-never-being-rebuilt">https://culture.pl/en/article/how-warsaw-came-close-to-never-being-rebuilt</a>, See on <a href="https://news.ycombinator.com/item?id=41048677">Hacker News</a></p>
Couldn't get https://culture.pl/en/article/how-warsaw-came-close-to-never-being-rebuilt: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Zerox – Document OCR with GPT-mini (136 pts)]]></title>
            <link>https://github.com/getomni-ai/zerox</link>
            <guid>41048194</guid>
            <pubDate>Tue, 23 Jul 2024 16:49:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/getomni-ai/zerox">https://github.com/getomni-ai/zerox</a>, See on <a href="https://news.ycombinator.com/item?id=41048194">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/getomni-ai/zerox/blob/main/examples/heroImage.png"><img src="https://github.com/getomni-ai/zerox/raw/main/examples/heroImage.png" alt="Hero Image"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Zerox OCR</h2><a id="user-content-zerox-ocr" aria-label="Permalink: Zerox OCR" href="#zerox-ocr"></a></p>
<p dir="auto">A dead simple way of OCR-ing a document for AI ingestion. Documents are meant to be a visual representation after all. With weird layouts, tables, charts, etc. The vision models just make sense!</p>
<p dir="auto">The general logic:</p>
<ul dir="auto">
<li>Pass in a PDF (URL or file buffer)</li>
<li>Turn the PDF into a series of images</li>
<li>Pass each image to GPT and ask nicely for Markdown</li>
<li>Aggregate the responses and return Markdown</li>
</ul>
<p dir="auto">Sounds pretty basic! But with the <code>gpt-4o-mini</code> this method is price competitive with existing products, with meaningfully better results.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Pricing Comparison</h4><a id="user-content-pricing-comparison" aria-label="Permalink: Pricing Comparison" href="#pricing-comparison"></a></p>
<p dir="auto">This is how the pricing stacks up to other document processers. Running 1,000 pages with Zerox uses about 25M input tokens and 0.4M output tokens.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Service</th>
<th>Cost</th>
<th>Accuracy</th>
<th>Table Quality</th>
</tr>
</thead>
<tbody>
<tr>
<td>AWS Textract <a href="https://aws.amazon.com/textract/pricing/#:~:text=Amazon%20Textract%20API%20pricing" rel="nofollow">[1]</a></td>
<td>$1.50 / 1,000 pages</td>
<td>Low</td>
<td>Low</td>
</tr>
<tr>
<td>Google Document AI <a href="https://cloud.google.com/document-ai/pricing" rel="nofollow">[2]</a></td>
<td>$1.50 / 1,000 pages</td>
<td>Low</td>
<td>Low</td>
</tr>
<tr>
<td>Azure Document AI <a href="https://azure.microsoft.com/en-us/pricing/details/ai-document-intelligence/" rel="nofollow">[3]</a></td>
<td>$1.50 / 1,000 pages</td>
<td>Mid</td>
<td>Low</td>
</tr>
<tr>
<td>Unstructured (PDF) <a href="https://unstructured.io/api-key-hosted#:~:text=Cost%20and%20Usage%20%0AGuidelines" rel="nofollow">[4]</a></td>
<td>$10.00 / 1,000 pages</td>
<td>Mid</td>
<td>Mid</td>
</tr>
<tr>
<td>------------------------</td>
<td>--------------------</td>
<td>--------</td>
<td>-------------</td>
</tr>
<tr>
<td>Zerox (gpt-mini)</td>
<td>$ 4.00 / 1,000 pages</td>
<td>High</td>
<td>High</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>

<p dir="auto">Zerox uses <code>graphicsmagick</code> and <code>ghostscript</code> for the pdf =&gt; image processing step. These should be pulled automatically, but you may need to manually install.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><strong>With file URL</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { zerox } from &quot;zerox&quot;;

const result = await zerox({
  filePath: &quot;https://omni-demo-data.s3.amazonaws.com/test/cs101.pdf&quot;,
  openaiAPIKey: process.env.OPENAI_API_KEY,
});"><pre><span>import</span> <span>{</span> <span>zerox</span> <span>}</span> <span>from</span> <span>"zerox"</span><span>;</span>

<span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>zerox</span><span>(</span><span>{</span>
  <span>filePath</span>: <span>"https://omni-demo-data.s3.amazonaws.com/test/cs101.pdf"</span><span>,</span>
  <span>openaiAPIKey</span>: <span>process</span><span>.</span><span>env</span><span>.</span><span>OPENAI_API_KEY</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><strong>From local path</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="import path from &quot;path&quot;;
import { zerox } from &quot;zerox&quot;;

const result = await zerox({
  filePath: path.resolve(__dirname, &quot;./cs101.pdf&quot;),
  openaiAPIKey: process.env.OPENAI_API_KEY,
});"><pre><span>import</span> <span>path</span> <span>from</span> <span>"path"</span><span>;</span>
<span>import</span> <span>{</span> <span>zerox</span> <span>}</span> <span>from</span> <span>"zerox"</span><span>;</span>

<span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>zerox</span><span>(</span><span>{</span>
  <span>filePath</span>: <span>path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span> <span>"./cs101.pdf"</span><span>)</span><span>,</span>
  <span>openaiAPIKey</span>: <span>process</span><span>.</span><span>env</span><span>.</span><span>OPENAI_API_KEY</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Options</h3><a id="user-content-options" aria-label="Permalink: Options" href="#options"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="const result = await zerox({
  // Required
  filePath: &quot;path/to/file&quot;,
  openaiAPIKey: process.env.OPENAI_API_KEY,

  // Optional
  concurrency: 10, // Number of pages to run at a time.
  maintainFormat: false, // Slower but helps maintain consistent formatting.
  cleanup: true, // Clear images from tmp after run.
  outputDir: undefined, // Save combined result.md to a file
  tempDir: &quot;/os/tmp&quot;, // Directory to use for temporary files (default: system temp directory)
});"><pre><span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>zerox</span><span>(</span><span>{</span>
  <span>// Required</span>
  <span>filePath</span>: <span>"path/to/file"</span><span>,</span>
  <span>openaiAPIKey</span>: <span>process</span><span>.</span><span>env</span><span>.</span><span>OPENAI_API_KEY</span><span>,</span>

  <span>// Optional</span>
  <span>concurrency</span>: <span>10</span><span>,</span> <span>// Number of pages to run at a time.</span>
  <span>maintainFormat</span>: <span>false</span><span>,</span> <span>// Slower but helps maintain consistent formatting.</span>
  <span>cleanup</span>: <span>true</span><span>,</span> <span>// Clear images from tmp after run.</span>
  <span>outputDir</span>: <span>undefined</span><span>,</span> <span>// Save combined result.md to a file</span>
  <span>tempDir</span>: <span>"/os/tmp"</span><span>,</span> <span>// Directory to use for temporary files (default: system temp directory)</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">The <code>maintainFormat</code> option trys to return the markdown in a consistent format by passing the output of a prior page in as additional context for the next page. This requires the requests to run synchronously, so it's a lot slower. But valueable if your documents have a lot of tabular data, or frequently have tables that cross pages.</p>
<div data-snippet-clipboard-copy-content="Request #1 => page_1_image
Request #2 => page_1_markdown + page_2_image
Request #3 => page_2_markdown + page_3_image"><pre><code>Request #1 =&gt; page_1_image
Request #2 =&gt; page_1_markdown + page_2_image
Request #3 =&gt; page_2_markdown + page_3_image
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example Output</h3><a id="user-content-example-output" aria-label="Permalink: Example Output" href="#example-output"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  completionTime: 10038,
  fileName: 'invoice_36258',
  inputTokens: 25543,
  outputTokens: 210,
  pages: [
    {
      content: '# INVOICE # 36258\n' +
        '**Date:** Mar 06 2012  \n' +
        '**Ship Mode:** First Class  \n' +
        '**Balance Due:** $50.10  \n' +
        '## Bill To:\n' +
        'Aaron Bergman  \n' +
        '98103, Seattle,  \n' +
        'Washington, United States  \n' +
        '## Ship To:\n' +
        'Aaron Bergman  \n' +
        '98103, Seattle,  \n' +
        'Washington, United States  \n' +
        '\n' +
        '| Item                                       | Quantity | Rate   | Amount  |\n' +
        '|--------------------------------------------|----------|--------|---------|\n' +
        &quot;| Global Push Button Manager's Chair, Indigo | 1        | $48.71 | $48.71  |\n&quot; +
        '| Chairs, Furniture, FUR-CH-4421             |          |        |         |\n' +
        '\n' +
        '**Subtotal:** $48.71  \n' +
        '**Discount (20%):** $9.74  \n' +
        '**Shipping:** $11.13  \n' +
        '**Total:** $50.10  \n' +
        '---\n' +
        '**Notes:**  \n' +
        'Thanks for your business!  \n' +
        '**Terms:**  \n' +
        'Order ID : CA-2012-AB10015140-40974  ',
      page: 1,
      contentLength: 747
    }
  ]
}"><pre><span>{</span>
  <span>completionTime</span>: <span>10038</span><span>,</span>
  <span>fileName</span>: <span>'invoice_36258'</span><span>,</span>
  <span>inputTokens</span>: <span>25543</span><span>,</span>
  <span>outputTokens</span>: <span>210</span><span>,</span>
  <span>pages</span>: <span>[</span>
    <span>{</span>
      <span>content</span>: <span>'# INVOICE # 36258\n'</span> <span>+</span>
        <span>'**Date:** Mar 06 2012  \n'</span> <span>+</span>
        <span>'**Ship Mode:** First Class  \n'</span> <span>+</span>
        <span>'**Balance Due:** $50.10  \n'</span> <span>+</span>
        <span>'## Bill To:\n'</span> <span>+</span>
        <span>'Aaron Bergman  \n'</span> <span>+</span>
        <span>'98103, Seattle,  \n'</span> <span>+</span>
        <span>'Washington, United States  \n'</span> <span>+</span>
        <span>'## Ship To:\n'</span> <span>+</span>
        <span>'Aaron Bergman  \n'</span> <span>+</span>
        <span>'98103, Seattle,  \n'</span> <span>+</span>
        <span>'Washington, United States  \n'</span> <span>+</span>
        <span>'\n'</span> <span>+</span>
        <span>'| Item                                       | Quantity | Rate   | Amount  |\n'</span> <span>+</span>
        <span>'|--------------------------------------------|----------|--------|---------|\n'</span> <span>+</span>
        <span>"| Global Push Button Manager's Chair, Indigo | 1        | $48.71 | $48.71  |\n"</span> <span>+</span>
        <span>'| Chairs, Furniture, FUR-CH-4421             |          |        |         |\n'</span> <span>+</span>
        <span>'\n'</span> <span>+</span>
        <span>'**Subtotal:** $48.71  \n'</span> <span>+</span>
        <span>'**Discount (20%):** $9.74  \n'</span> <span>+</span>
        <span>'**Shipping:** $11.13  \n'</span> <span>+</span>
        <span>'**Total:** $50.10  \n'</span> <span>+</span>
        <span>'---\n'</span> <span>+</span>
        <span>'**Notes:**  \n'</span> <span>+</span>
        <span>'Thanks for your business!  \n'</span> <span>+</span>
        <span>'**Terms:**  \n'</span> <span>+</span>
        <span>'Order ID : CA-2012-AB10015140-40974  '</span><span>,</span>
      <span>page</span>: <span>1</span><span>,</span>
      <span>contentLength</span>: <span>747</span>
    <span>}</span>
  <span>]</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">License</h3><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Switzerland now requires all government software to be open source (137 pts)]]></title>
            <link>https://www.zdnet.com/article/switzerland-now-requires-all-government-software-to-be-open-source/</link>
            <guid>41047172</guid>
            <pubDate>Tue, 23 Jul 2024 15:38:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.zdnet.com/article/switzerland-now-requires-all-government-software-to-be-open-source/">https://www.zdnet.com/article/switzerland-now-requires-all-government-software-to-be-open-source/</a>, See on <a href="https://news.ycombinator.com/item?id=41047172">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure><div><picture><source media="(max-width: 767px)" srcset="https://www.zdnet.com/a/img/resize/370ca9eb455fc4b33122e82c2bc262cde418770a/2024/07/23/6460fecb-d560-4184-ae74-c7d47a991ce1/gettyimages-1173550939.jpg?auto=webp&amp;width=768" alt="Switzerland flag on keyboard"><source media="(max-width: 1023px)" srcset="https://www.zdnet.com/a/img/resize/48c1efdb118a09fdf69b74e130635533fef2db04/2024/07/23/6460fecb-d560-4184-ae74-c7d47a991ce1/gettyimages-1173550939.jpg?auto=webp&amp;width=1024" alt="Switzerland flag on keyboard"><source media="(max-width: 1440px)" srcset="https://www.zdnet.com/a/img/resize/65fa58548e14c621214db2cdf42bec50d30b4185/2024/07/23/6460fecb-d560-4184-ae74-c7d47a991ce1/gettyimages-1173550939.jpg?auto=webp&amp;width=1280" alt="Switzerland flag on keyboard"> <img src="https://www.zdnet.com/a/img/resize/65fa58548e14c621214db2cdf42bec50d30b4185/2024/07/23/6460fecb-d560-4184-ae74-c7d47a991ce1/gettyimages-1173550939.jpg?auto=webp&amp;width=1280" alt="Switzerland flag on keyboard" width="1280" height="837.3527272727273" fetchpriority="low"></picture></div> <figcaption> <span>Bojanikus/Getty Images</span></figcaption></figure><p>Several European countries are betting on open-source software. In the United States, eh, not so much. In the latest news from across the Atlantic, Switzerland has taken a major step forward with its "<a href="https://datenrecht.ch/en/bundesgesetz-ueber-den-einsatz-elektronischer-mittel-zur-erfuellung-von-behoerdenaufgaben-embag-in-schlussabstimmung-angenommen/" target="_blank" rel="noopener nofollow">Federal Law on the Use of Electronic Means for the Fulfillment of Government Tasks" (EMBAG).</a> This groundbreaking legislation mandates using open-source software (OSS) in the public sector.</p><p>This new law requires all public bodies to disclose the source code of software developed by or for them unless third-party rights or security concerns prevent it. This "public money, public code" approach aims to enhance government operations' transparency, security, and efficiency.</p><p><strong>Also: <a href="https://www.zdnet.com/article/german-state-ditches-microsoft-for-linux-and-libreoffice/" rel="follow">German state ditches Microsoft for Linux and LibreOffice</a></strong></p><p>Making this move wasn't easy. It began in 2011 when the Swiss Federal Supreme Court <a href="https://www.openjustitia.ch/DE/interne_Open_Justitia.html" target="_blank" rel="noopener nofollow">published its court application, Open Justitia, under an OSS license</a>. The proprietary legal software company <a href="https://www.weblaw.ch/" target="_blank" rel="noopener nofollow">Weblaw</a> wasn't happy about this. There were heated political and legal fights for more than a decade. Finally, the EMBAG was passed in 2023. Now, the law not only allows the release of OSS by the Swiss government or its contractors, but also requires the code to be released under an open-source license "unless the rights of third parties or security-related reasons would exclude or restrict this."</p><p>Professor Dr. Matthias Stürmer, head of the Institute for Public Sector Transformation at the <a href="https://www.bfh.ch/en/" target="_blank" rel="noopener nofollow">Bern University of Applied Sciences</a>, led the fight for this law. He hailed it as&nbsp;<a href="https://joinup.ec.europa.eu/collection/open-source-observatory-osor/news/new-open-source-law-switzerland" target="_blank" rel="noopener nofollow">"a great opportunity for government, the IT industry, and society."</a> Stürmer believes everyone will benefit from this regulation, as it reduces vendor lock-in for the public sector, allows companies to expand their digital business solutions, and potentially leads to reduced IT costs and improved services for taxpayers.</p><!----><p>In addition to mandating OSS, the EMBAG also requires the release of non-personal and non-security-sensitive government data as Open Government Data (OGD). This dual "open by default" approach marks a significant paradigm shift towards greater openness and practical reuse of software and data.</p><p>Implementing the EMBAG is expected to serve as a model for other countries considering similar measures. It aims to promote digital sovereignty and encourage innovation and collaboration within the public sector.</p><p>The Swiss Federal Statistical Office (BFS) is leading the law's implementation, but the organizational and financial aspects of the OSS releases still need to be clarified.</p><p><strong>Also:&nbsp;<a href="https://www.zdnet.com/article/why-dont-more-people-use-desktop-linux-i-have-a-theory-you-might-not-like/" rel="follow">Why don't more people use desktop Linux? I have a theory you might not like</a></strong></p><p>Other countries in Europe have long supported open source. For example, in 2023, <a href="https://eucloudedgeiot.eu/summary-of-the-open-source-key-areas-for-digital-autonomy-workshop/" target="_blank" rel="noopener nofollow">French President Macron stated, "We love open source,"</a> and France's National Gendarmerie (Think FBI if you're an American) <a href="https://www.zdnet.com/article/french-police-move-from-windows-to-ubuntu-linux/" rel="follow">uses Linux on its PCs</a>. The European Union (EU) has long worked on securing OSS via the EU's&nbsp;<a href="https://commission.europa.eu/about-european-commission/departments-and-executive-agencies/digital-services/eu-fossa-2-free-and-open-source-software-auditing_en" target="_blank" rel="noopener nofollow">Free and Open Source Software Auditing (FOSSA)</a> project.</p><p>That said, it's not all wine and roses in the EU. There's some worry that the European Commission will <a href="https://fossforce.com/2024/07/is-the-european-commission-dropping-support-for-important-open-source-funding/" target="_blank" rel="noopener nofollow">cut funding for the NGI Zero Commons Fund</a>, an important funding source for OSS projects.</p><p>In the US, there's some support for open source, but not nearly as much as in Europe. The <a href="https://open.gsa.gov/oss-policy/" target="_blank" rel="noopener nofollow">Federal Source Code Policy,</a> for instance, requires federal agencies to release at least 20% of new custom-developed code as open-source software. It doesn't, however, mandate the use of open source.</p><p><strong>Also: <a href="https://www.zdnet.com/article/do-you-need-antivirus-on-linux/" rel="follow">Do you need antivirus on Linux?</a></strong></p><p>Similarly, the General Services Administration (GSA) has an <a href="https://open.gsa.gov/oss-policy/#:~:text=c.-,GSA%20Service%20and%20Staff%20Offices%20(Project%20teams)%20are%20responsible%20for,knowledge%20to%20improve%20the%20project." target="_blank" rel="noopener nofollow">OSS Policy that requires GSA organizations to account for and publish their open-source code</a>. This policy promotes an "open first" approach for new custom code development.</p><p>So, while this legislative move positions Switzerland at the forefront of the global open-source movement, more work needs to be done both in Europe and the US.</p><div id="pinbox-d1027a65-751c-48cb-a4ee-4b3907aaaccf"><h4>Featured</h4> <!---->  </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Unix Pipe Card Game (192 pts)]]></title>
            <link>https://punkx.org/unix-pipe-game/</link>
            <guid>41047110</guid>
            <pubDate>Tue, 23 Jul 2024 15:35:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://punkx.org/unix-pipe-game/">https://punkx.org/unix-pipe-game/</a>, See on <a href="https://news.ycombinator.com/item?id=41047110">Hacker News</a></p>
<div id="readability-page-1" class="page">
    

    This is a card game for teaching kids how to combine unix commands through <mark>pipes</mark>.<p>
    This game assumes the parent knows the basic unix commands: <code>cat, grep, tail, head, wc, sort, uniq</code>. The parent should show also show those commands in action the computer as well, if you do not have any UNIX system you can use <a href="https://bellard.org/jslinux/vm.html?url=alpine-x86.cfg&amp;mem=192">jslinux</a> in your browser.

    <a target="_blank" href="https://punkx.org/unix-pipe-game/photos/deck.jpg"><img src="https://punkx.org/unix-pipe-game/photos/deck.jpg" height="70%"></a><br>

    <a href="https://shop.punkx.org/products/unix-pipe-game">Buy now: €5,00 EUR</a></p><ul>
      <li>print it yourself: <a href="https://punkx.org/unix-pipe-game/unix-pipe-cards.pdf">unix-pipe-cards.pdf</a>, <a href="https://punkx.org/unix-pipe-game/unix-pipe-box.pdf">unix-pipe-box.pdf</a></li>
      <li>code: <a href="https://github.com/jackdoe/programming-for-kids/tree/master/projects/unix-pipe-game">unix-pipe-game</a></li>
      <li>author: <a href="https://github.com/jackdoe">github.com/jackdoe</a></li>
      <li>co author: <a href="https://punkjazz.org/jackie">Jackie</a></li>
      <li>contact: <a href="mailto:b0000@fastmail.com">b0000@fastmail.com</a></li>
      <li>license: CC BY 4.0</li>
    </ul>

    If you want to play the <b>more difficult</b> version, you can also get the Expansion pack: <a href="https://punkx.org/unix-pipe-game/ext-0.1/index.html">UNIX Pipe Game - Process Substitution</a><p>

    
    Example game round:

    </p><dl>task: <b>print the most common line from a file</b>, we need to first cat the file (in our case the file is card 03.txt), then sort it, uniq count it, then do numeric sort, then tail -1:
      <p>

    <b>cat 03.txt | sort | uniq -c | sort -n | tail -1</b></p></dl>


    <a target="_blank" href="https://punkx.org/unix-pipe-game/photos/example.jpg"><img src="https://punkx.org/unix-pipe-game/photos/example.jpg" width="100%"></a>

    <br>

    <pre>                 RULES:

&gt; 0. The youngest player chooses one of
  two formats for the game:

* Whoever has the <span>smallest</span> pipe chain to 
  complete the task wins the round.
* Whoever has the <span>largest</span> pipe chain to 
  complete the task wins the round.

&gt; 1. The youngest player picks a task
  from the tasks card. You can not pick
  the same task twice.

&gt; 2. Shuffle the cards.

&gt; 3. Put the cards face down on the
  table.

&gt; 4. Going clockwise each player picks
  the top card from the deck and tries 
  to complete the task.

&gt; 5. The first player who completes the
  task gets a point.

&gt; 6. <span>IF</span> there are no more tasks, <span>GOTO</span> 8

&gt; 7. <span>GOTO</span> 1.

&gt; 8. GAME OVER. INSERT COIN. <span>GOTO</span> 8

TASKS

  * print the second line

  * print the second to last line

  * print the 7th line

  * print the most common line

  * print the least common line

  * count how many lines have "rises"

  * print the first line that has W in it

  * count the lines that have "in" in them

  * show two random lines

  * count the words on the last two lines

  * print the 7th and 8th line

  * count the lines with !

  * count the lines without !

  * make a command chain that does not
    print anything
</pre>

    This is how the card decks look:

    <a target="_blank" href="https://punkx.org/unix-pipe-game/photos/many-decks.jpg"><img src="https://punkx.org/unix-pipe-game/photos/many-decks.jpg" width="100%"></a>



    If you are a parent teaching your kid, and is exploring more tools to help you, I made few other card games:

    <p>
      <a target="_blank" href="https://punkjazz.org/programming-time/">
        <img src="https://punkjazz.org/programming-time/photos/b-800.jpg">
      </a>
      <span>
        <a target="_blank" href="https://punkjazz.org/programming-time/">Programming Time</a>, which is a game to teach python and some more fundamental algorithms, from hash tables to RSA
      </span>
    </p>

    <p>
      <a target="_blank" href="https://punkx.org/c-pointer-game/">
        <img src="https://punkx.org/c-pointer-game/photos/deck.jpg">
      </a>
      <span>
        <a target="_blank" href="https://punkx.org/c-pointer-game/">The C Pointer Game - Pointers, Arrays and Strings</a>, a game to teach kids to look at the computer memory and understand references and values
      </span>
    </p>

    <p>
      <a target="_blank" href="https://punkx.org/4917/">
        <img src="https://punkx.org/4917/photos/a.jpg">
      </a>
      <span>
        <a target="_blank" href="https://punkx.org/4917/">4917</a>, a game to teach kids machine code and how the CPU works with memory and registers
      </span>
    </p>


    <p>
      <a target="_blank" href="https://punkx.org/unix-pipe-game/ext-0.1">
        <img src="https://punkx.org/unix-pipe-game/ext-0.1/photos/deck.jpg">
      </a>
      <span>
        <a target="_blank" href="https://punkx.org/unix-pipe-game/ext-0.1">The Unix Pipes Game - Process Substitution</a>, an expansion of the Unix Pipes Game to teach process substitution and also: <code>paste, tr, cut, bc</code>
      </span>
    </p>

    <p>
      <a target="_blank" href="https://punkx.org/runlength-for-kids/">
        <img src="https://punkx.org/runlength-for-kids/photos/deck.jpg">
      </a>
      <span>
        <a target="_blank" href="https://punkx.org/runlength-for-kids/">RunLength Encoding for Kids</a>, small cards "game" to explain runlength encoding
      </span>
    </p>

    <p>
      <a target="_blank" href="https://punkx.org/punk0/">
        <img src="https://punkx.org/punk0/photos/deck.jpg">
      </a>
      <span>
        <a target="_blank" href="https://punkx.org/punk0/">PUNK0 - The Function Composition Card Game</a>, use cards to manipulate a list and use its values to win the game
      </span>
    </p>

    <p>
      <a target="_blank" href="https://punkx.org/overflow/">
        <img src="https://punkx.org/overflow/logo.svg">
      </a>
      <span>
        <a target="_blank" href="https://punkx.org/overflow/">PROJEKT: OVERFLOW</a>, RISCV assembler boardgame
      </span>
    </p>


    <p>
      <a target="_blank" href="https://github.com/jackdoe/programming-for-kids/blob/master/book.md">
        <img src="https://punkx.org/github.png">
      </a>
      <span>
        <a target="_blank" href="https://github.com/jackdoe/programming-for-kids/blob/master/book.md">Programming for kids</a>, a log of my journey of teaching my daughter how to code
      </span>
    </p>

  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intent to End OCSP Service (306 pts)]]></title>
            <link>https://letsencrypt.org/2024/07/23/replacing-ocsp-with-crls.html</link>
            <guid>41046956</guid>
            <pubDate>Tue, 23 Jul 2024 15:25:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://letsencrypt.org/2024/07/23/replacing-ocsp-with-crls.html">https://letsencrypt.org/2024/07/23/replacing-ocsp-with-crls.html</a>, See on <a href="https://news.ycombinator.com/item?id=41046956">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	<article>
		<p>Today we are announcing our intent to end <a href="https://en.wikipedia.org/wiki/Online_Certificate_Status_Protocol">Online Certificate Status Protocol (OCSP)</a> support in favor of <a href="https://letsencrypt.org/2022/09/07/new-life-for-crls">Certificate Revocation Lists (CRLs)</a> as soon as possible. OCSP and CRLs are both mechanisms by which CAs can communicate certificate revocation information, but CRLs have significant advantages over OCSP. Let’s Encrypt has been providing an OCSP responder since our launch nearly ten years ago. We added support for CRLs in 2022.</p>
<p>Websites and people who visit them will not be affected by this change, but some non-browser software might be.</p>
<p>We plan to end support for OCSP primarily because it represents a considerable risk to privacy on the Internet. When someone visits a website using a browser or other software that checks for certificate revocation via OCSP, the Certificate Authority (CA) operating the OCSP responder immediately becomes aware of which website is being visited from that visitor’s particular IP address. Even when a CA intentionally does not retain this information, as is the case with Let’s Encrypt, CAs could be legally compelled to collect it. CRLs do not have this issue.</p>
<p>We are also taking this step because keeping our CA infrastructure as simple as possible is critical for the continuity of compliance, reliability, and efficiency at Let’s Encrypt. For every year that we have existed, operating OCSP services has taken up considerable resources that can soon be better spent on other aspects of our operations. Now that we support CRLs, our OCSP service has become unnecessary.</p>
<p>In August of 2023 the <a href="https://cabforum.org/">CA/Browser Forum</a> passed <a href="https://lists.cabforum.org/pipermail/servercert-wg/2023-September/003998.html">a ballot</a> to make providing OCSP services optional for publicly trusted CAs like Let’s Encrypt. With one exception, Microsoft, the root programs themselves no longer require OCSP. As soon as the <a href="https://learn.microsoft.com/en-us/security/trusted-root/program-requirements">Microsoft Root Program</a> also makes OCSP optional, which we are optimistic will happen within the next six to twelve months, Let’s Encrypt intends to announce a specific and rapid timeline for shutting down our OCSP services. We hope to serve our last OCSP response between three and six months after that announcement. The best way to stay apprised of updates on these plans is to <a href="https://community.letsencrypt.org/c/api-announcements/18">subscribe to our API Announcements</a> category on Discourse.</p>
<p>We recommend that anyone relying on OCSP services today start the process of ending that reliance as soon as possible. If you use Let’s Encrypt certificates to secure non-browser communications such as a VPN, you should ensure that your software operates correctly if certificates contain no OCSP URL. Fortunately, most OCSP implementations “fail open” which means that an inability to fetch an OCSP response will not break the system.</p>
<p><em><a href="https://abetterinternet.org/">Internet Security Research Group (ISRG)</a> is the parent organization of <a href="http://letsencrypt.org/">Let’s Encrypt</a>, <a href="http://memorysafety.org/">Prossimo</a>, and <a href="http://divviup.org/">Divvi Up</a>. ISRG is a 501(c)(3) nonprofit. If you’d like to support our work, please consider <a href="https://www.abetterinternet.org/getinvolved/">getting involved</a>, <a href="https://www.abetterinternet.org/donate/">donating</a>, or encouraging your company to <a href="https://www.abetterinternet.org/sponsor/">become a sponsor</a>.</em></p>

	</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open Source AI Is the Path Forward (1741 pts)]]></title>
            <link>https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/</link>
            <guid>41046773</guid>
            <pubDate>Tue, 23 Jul 2024 15:08:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/">https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/</a>, See on <a href="https://news.ycombinator.com/item?id=41046773">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><span>In the early days of high-performance computing, the major tech companies of the day each invested heavily in developing their own closed source versions of Unix. It was hard to imagine at the time that any other approach could develop such advanced software. Eventually though, open source Linux gained popularity – initially because it allowed developers to modify its code however they wanted and was more affordable, and over time because it became more advanced, more secure, and had a broader ecosystem supporting more capabilities than any closed Unix. Today, Linux is the industry standard foundation for both cloud computing and the operating systems that run most mobile devices – and we all benefit from superior products because of it.</span></p>
<p><span>I believe that AI will develop in a similar way. Today, several tech companies are developing leading closed models. But open source is quickly closing the gap. Last year, Llama 2 was only comparable to an older generation of models behind the frontier. This year, Llama 3 is competitive with the most advanced models and leading in some areas. Starting next year, we expect future Llama models to become the most advanced in the industry. But even before that, Llama is already leading on openness, modifiability, and cost efficiency.</span></p>
<p><span>Today we’re taking the next steps towards open source AI becoming the industry standard. We’re releasing Llama 3.1 405B, the first frontier-level open source AI model, as well as new and improved Llama 3.1 70B and 8B models. In addition to having significantly better cost/performance relative to closed models, the fact that the 405B model is open will make it the best choice for fine-tuning and distilling smaller models.</span></p>
<p><span>Beyond releasing these models, we’re working with a range of companies to grow the broader ecosystem. Amazon, Databricks, and Nvidia are launching full suites of services to support developers fine-tuning and distilling their own models. Innovators like Groq have built low-latency, low-cost inference serving for all the new models. The models will be available on all major clouds including AWS, Azure, Google, Oracle, and more. Companies like Scale.AI, Dell, Deloitte, and others are ready to help enterprises adopt Llama and train custom models with their own data. As the community grows and more companies develop new services, we can collectively make Llama the industry standard and bring the benefits of AI to everyone.</span></p>
<p><span>Meta is committed to open source AI. I’ll outline why I believe open source is the best development stack for you, why open sourcing Llama is good for Meta, and why open source AI is good for the world and therefore a platform that will be around for the long term.</span></p>
<h2><span>Why Open Source AI Is Good for Developers</span></h2>
<p><span>When I talk to developers, CEOs, and government officials across the world, I usually hear several themes:</span></p>
<ul>
<li><b>We need to train, fine-tune, and distill our own models.</b><span> Every organization has different needs that are best met with models of different sizes that are trained or fine-tuned with their specific data. On-device tasks and classification tasks require small models, while more complicated tasks require larger models. Now you’ll be able to take the most advanced Llama models, continue training them with your own data and then distill them down to a model of your optimal size – without us or anyone else seeing your data.</span></li>
<li><b>We need to control our own destiny and not get locked into a closed vendor.</b><span> Many organizations don’t want to depend on models they cannot run and control themselves. They don’t want closed model providers to be able to change their model, alter their terms of use, or even stop serving them entirely. They also don’t want to get locked into a single cloud that has exclusive rights to a model. Open source enables a broad ecosystem of companies with compatible toolchains that you can move between easily.&nbsp;</span></li>
<li><b>We need to protect our data.</b><span> Many organizations handle sensitive data that they need to secure and can’t send to closed models over cloud APIs. Other organizations simply don’t trust the closed model providers with their data. Open source addresses these issues by enabling you to run the models wherever you want. It is well-accepted that open source software tends to be more secure because it is developed more transparently.</span></li>
<li><b>We need a model that is efficient and affordable to run. </b><span>Developers can run inference on Llama 3.1 405B on their own infra at roughly 50% the cost of using closed models like GPT-4o, for both user-facing and offline inference tasks.</span></li>
<li><b>We want to invest in the ecosystem that’s going to be the standard for the long term.</b><span> Lots of people see that open source is advancing at a faster rate than closed models, and they want to build their systems on the architecture that will give them the greatest advantage long term.&nbsp;</span></li>
</ul>
<h2><span>Why Open Source AI Is Good for Meta</span></h2>
<p><span>Meta’s business model is about building the best experiences and services for people. To do this, we must ensure that we always have access to the best technology, and that we’re not locking into a competitor’s closed ecosystem where they can restrict what we build.</span></p>
<p><span>One of my formative experiences has been building our services constrained by what Apple will let us build on their platforms. Between the way they tax developers, the arbitrary rules they apply, and all the product innovations they block from shipping, it’s clear that Meta and many other companies would be freed up to build much better services for people if we could build the best versions of our products and competitors were not able to constrain what we could build. On a philosophical level, this is a major reason why I believe so strongly in building open ecosystems in AI and AR/VR for the next generation of computing.</span></p>
<p><span>People often ask if I’m worried about giving up a technical advantage by open sourcing Llama, but I think this misses the big picture for a few reasons:</span></p>
<p><span>First, to ensure that we have access to the best technology and aren’t locked into a closed ecosystem over the long term, Llama needs to develop into a full ecosystem of tools, efficiency improvements, silicon optimizations, and other integrations. If we were the only company using Llama, this ecosystem wouldn’t develop and we’d fare no better than the closed variants of Unix.</span></p>
<p><span>Second, I expect AI development will continue to be very competitive, which means that open sourcing any given model isn’t giving away a massive advantage over the next best models at that point in time. The path for Llama to become the industry standard is by being consistently competitive, efficient, and open generation after generation.</span></p>
<p><span>Third, a key difference between Meta and closed model providers is that selling access to AI models isn’t our business model. That means openly releasing Llama doesn’t undercut our revenue, sustainability, or ability to invest in research like it does for closed providers. (This is one reason several closed providers consistently lobby governments against open source.)</span></p>
<p><span>Finally, Meta has a long history of open source projects and successes. We’ve saved billions of dollars by releasing our server, network, and data center designs with Open Compute Project and having supply chains standardize on our designs. We benefited from the ecosystem’s innovations by open sourcing leading tools like PyTorch, React, and many more tools. This approach has consistently worked for us when we stick with it over the long term.</span></p>
<h2><span>Why Open Source AI Is Good for the World</span></h2>
<p><span>I believe that open source is necessary for a positive AI future. AI has more potential than any other modern technology to increase human productivity, creativity, and quality of life – and to accelerate economic growth while unlocking progress in medical and scientific research. Open source will ensure that more people around the world have access to the benefits and opportunities of AI, that power isn’t concentrated in the hands of a small number of companies, and that the technology can be deployed more evenly and safely across society.</span></p>
<p><span>There is an ongoing debate about the safety of open source AI models, and my view is that open source AI will be safer than the alternatives. I think governments will conclude it’s in their interest to support open source because it will make the world more prosperous and safer.</span></p>
<p><span>My framework for understanding safety is that we need to protect against two categories of harm: unintentional and intentional. Unintentional harm is when an AI system may cause harm even when it was not the intent of those running it to do so. For example, modern AI models may inadvertently give bad health advice. Or, in more futuristic scenarios, some worry that models may unintentionally self-replicate or hyper-optimize goals to the detriment of humanity. Intentional harm is when a bad actor uses an AI model with the goal of causing harm.</span></p>
<p><span>It’s worth noting that unintentional harm covers the majority of concerns people have around AI – ranging from what influence AI systems will have on the billions of people who will use them to most of the truly catastrophic science fiction scenarios for humanity. On this front, open source should be significantly safer since the systems are more transparent and can be widely scrutinized. Historically, open source software has been more secure for this reason. Similarly, using Llama with its safety systems like Llama Guard will likely be safer and more secure than closed models. For this reason, most conversations around open source AI safety focus on intentional harm.</span></p>
<p><span>Our safety process includes rigorous testing and red-teaming to assess whether our models are capable of meaningful harm, with the goal of mitigating risks before release. Since the models are open, anyone is capable of testing for themselves as well. We must keep in mind that these models are trained by information that’s already on the internet, so the starting point when considering harm should be whether a model can facilitate more harm than information that can quickly be retrieved from Google or other search results.&nbsp;</span></p>
<p><span>When reasoning about intentional harm, it’s helpful to distinguish between what individual or small scale actors may be able to do as opposed to what large scale actors like nation states with vast resources may be able to do.</span></p>
<p><span>At some point in the future, individual bad actors may be able to use the intelligence of AI models to fabricate entirely new harms from the information available on the internet. At this point, the balance of power will be critical to AI safety. I think it will be better to live in a world where AI is widely deployed so that larger actors can check the power of smaller bad actors. This is how we’ve managed security on our social networks – our more robust AI systems identify and stop threats from less sophisticated actors who often use smaller scale AI systems. More broadly, larger institutions deploying AI at scale will promote security and stability across society. As long as everyone has access to similar generations of models – which open source promotes – then governments and institutions with more compute resources will be able to check bad actors with less compute.&nbsp;</span></p>
<p><span>The next question is how the US and democratic nations should handle the threat of states with massive resources like China. The United States’ advantage is decentralized and open innovation. Some people argue that we must close our models to prevent China from gaining access to them, but my view is that this will not work and will only disadvantage the US and its allies. Our adversaries are great at espionage, stealing models that fit on a thumb drive is relatively easy, and most tech companies are far from operating in a way that would make this more difficult. It seems most likely that a world of only closed models results in a small number of big companies plus our geopolitical adversaries having access to leading models, while startups, universities, and small businesses miss out on opportunities. Plus, constraining American innovation to closed development increases the chance that we don’t lead at all. Instead, I think our best strategy is to build a robust open ecosystem and have our leading companies work closely with our government and allies to ensure they can best take advantage of the latest advances and achieve a sustainable first-mover advantage over the long term.</span></p>
<p><span>When you consider the opportunities ahead, remember that most of today’s leading tech companies and scientific research are built on open source software. The next generation of companies and research will use open source AI if we collectively invest in it. That includes startups just getting off the ground as well as people in universities and countries that may not have the resources to develop their own state-of-the-art AI from scratch.</span></p>
<p><span>The bottom line is that open source AI represents the world’s best shot at harnessing this technology to create the greatest economic opportunity and security for everyone.</span></p>
<h2><span>Let’s Build This Together</span></h2>
<p><span>With past Llama models, Meta developed them for ourselves and then released them, but didn’t focus much on building a broader ecosystem. We’re taking a different approach with this release. We’re building teams internally to enable as many developers and partners as possible to use Llama, and we’re actively building partnerships so that more companies in the ecosystem can offer unique functionality to their customers as well.&nbsp;</span></p>
<p><span>I believe the Llama 3.1 release will be an inflection point in the industry where most developers begin to primarily use open source, and I expect that approach to only grow from here. I hope you’ll join us on this journey to bring the benefits of AI to everyone in the world.</span></p>
<p><span>You can access the models now at <a href="https://llama.meta.com/">llama.meta.com</a>.&nbsp;</span></p>
<p><span>💪,&nbsp;</span></p>
<p><span>MZ</span></p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama 3.1 Official Launch (367 pts)]]></title>
            <link>https://llama.meta.com/</link>
            <guid>41046540</guid>
            <pubDate>Tue, 23 Jul 2024 14:47:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://llama.meta.com/">https://llama.meta.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41046540">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[A free tool to quickly detect counterfeit flash (2017) (169 pts)]]></title>
            <link>https://fight-flash-fraud.readthedocs.io/en/latest/introduction.html#correcting-capacity-to-actual-size-with-f3fix</link>
            <guid>41046397</guid>
            <pubDate>Tue, 23 Jul 2024 14:34:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fight-flash-fraud.readthedocs.io/en/latest/introduction.html#correcting-capacity-to-actual-size-with-f3fix">https://fight-flash-fraud.readthedocs.io/en/latest/introduction.html#correcting-capacity-to-actual-size-with-f3fix</a>, See on <a href="https://news.ycombinator.com/item?id=41046397">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
            
  <div id="f3-fight-flash-fraud">

<p>f3 is a simple tool that tests flash cards capacity and performance to
see if they live up to claimed specifications. It fills the device with
pseudorandom data and then checks if it returns the same on reading.</p>
<p>F3 stands for Fight Flash Fraud, or Fight Fake Flash.</p>
<p><strong>Table of Contents</strong></p>
<ul>
<li><a href="#examples">Examples</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#other-resources">Other resources</a></li>
</ul>
</div>
<div id="examples-1">
<h2>Examples<a href="#examples-1" title="Permalink to this headline">¶</a></h2>
<p>We’ll use <code><span>/dev/sdX</span></code> as a placeholder here, you need to replace
<code><span>X</span></code> with a lowercase letter so that it matches the device you
want to use.
<code><span>lsblk</span></code> will show you an overview of your current devices.</p>
<div id="testing-performance-with-f3read-f3write">
<h2>Testing performance with f3read/f3write<a href="#testing-performance-with-f3read-f3write" title="Permalink to this headline">¶</a></h2>
<p>Use these two programs in this order. f3write will write large files to
your mounted disk and f3read will check if the flash disk contains
exactly the written files:</p>
<div><pre><span></span>$ ./f3write /media/michel/5EBD-5C80/
$ ./f3read /media/michel/5EBD-5C80/
</pre></div>
<p>Please replace “/media/michel/5EBD-5C80/” with the appropriate path. USB
devices are mounted in “/Volumes” on Macs.</p>
<p>If you have installed f3read and f3write, you can remove the “./” that
is shown before their names.</p>
</div>
<div id="quick-capacity-tests-with-f3probe">
<h2>Quick capacity tests with f3probe<a href="#quick-capacity-tests-with-f3probe" title="Permalink to this headline">¶</a></h2>
<p>f3probe is the fastest drive test and suitable for large disks because
it only writes what’s necessary to test the drive. It operates directly
on the (unmounted) block device and needs to be run as a privileged
user:</p>
<div><pre><span></span><span># ./f3probe --destructive --time-ops /dev/sdX</span>
</pre></div>
<div>
<p>Warning</p>
<p>This will destroy any previously stored data on your disk!</p>
</div>
</div>
<div id="correcting-capacity-to-actual-size-with-f3fix">
<h2>Correcting capacity to actual size with f3fix<a href="#correcting-capacity-to-actual-size-with-f3fix" title="Permalink to this headline">¶</a></h2>
<p>f3fix creates a partition that fits the actual size of the fake drive.
Use f3probe’s output to determine the parameters for f3fix:</p>
<div><pre><span></span><span># ./f3fix --last-sec=16477878 /dev/sdX</span>
</pre></div>
</div>
</div>
<div id="installation">
<h2>Installation<a href="#installation" title="Permalink to this headline">¶</a></h2>
<div id="download-and-compile">
<h2>Download and Compile<a href="#download-and-compile" title="Permalink to this headline">¶</a></h2>
<p>The files of the stable version of F3 are
<a href="https://github.com/AltraMayor/f3/tags">here</a>. The
following command uncompresses the files:</p>

</div>
<div id="compile-stable-software-on-linux-or-freebsd">
<h2>Compile stable software on Linux or FreeBSD<a href="#compile-stable-software-on-linux-or-freebsd" title="Permalink to this headline">¶</a></h2>
<p>To build:</p>

<p>If you want to install f3write and f3read, run the following command:</p>

</div>
<div id="compile-stable-software-on-windows-cygwin">
<h2>Compile stable software on Windows/Cygwin<a href="#compile-stable-software-on-windows-cygwin" title="Permalink to this headline">¶</a></h2>
<p>f3write and f3read can be installed on Windows, but currently f3probe, f3fix,
and f3brew <a href="#the-extra-applications-for-linux">require Linux</a>.  To use them
on a Windows machine, use the <a href="#docker">Docker Installation</a>.  For f3write
and f3read, read on.</p>
<p>If you haven’t already, install the following Cygwin packages and their dependencies:</p>
<ul>
<li><cite>gcc-core</cite></li>
<li><cite>make</cite></li>
<li><cite>libargp-devel</cite></li>
</ul>
<p>To build, you need special flags:</p>
<div><pre><span></span><span>export</span> <span>LDFLAGS</span><span>=</span><span>"</span><span>$LDFLAGS</span><span> -Wl,--stack,4000000 -largp"</span>
make
</pre></div>
<p>If you want to install f3write and f3read, run the following command:</p>

</div>
<div id="compile-stable-software-on-apple-mac">
<h2>Compile stable software on Apple Mac<a href="#compile-stable-software-on-apple-mac" title="Permalink to this headline">¶</a></h2>
<p>f3write and f3read can be installed on Mac, but currently f3probe, f3fix, and
f3brew <a href="#the-extra-applications-for-linux">require Linux</a>.  To use them on
Mac, use the <a href="#docker">Docker Installation</a>.  For f3write and f3read, read
on.</p>
<div id="using-homebrew">
<h3>Using HomeBrew<a href="#using-homebrew" title="Permalink to this headline">¶</a></h3>
<p>If you have Homebrew already installed in your computer, the command
below will install F3:</p>

</div>
<div id="using-macports">
<h3>Using MacPorts<a href="#using-macports" title="Permalink to this headline">¶</a></h3>
<p>If you use MacPorts instead, use the following command:</p>

</div>

</div>
<div id="docker">
<h2>Docker<a href="#docker" title="Permalink to this headline">¶</a></h2>
<div id="quick-start">
<h3>Quick Start<a href="#quick-start" title="Permalink to this headline">¶</a></h3>
<p>A pre-built <a href="https://cloud.docker.com/repository/docker/peron/f3">image</a>
is available over at Docker Hub, ready to be used.  With docker started, just
run:</p>
<div><pre><span></span>docker run -it --rm --device &lt;device&gt; peron/f3 &lt;f3-command&gt; <span>[</span>&lt;f3-options&gt;<span>]</span> &lt;device&gt;
</pre></div>
<p>For example, to probe a drive mounted at /dev/sdX:</p>
<div><pre><span></span>docker run -it --rm --device /dev/sdX peron/f3 f3probe --destructive --time-ops /dev/sdX
</pre></div>
<p>Optionally, you can also build your own container <em>if</em> you don’t want to use the
pre-built image.  From this directory, run:</p>

<p>or:</p>
<div><pre><span></span>docker build -t f3:latest .
</pre></div>
<p>To run f3 commands using your newly built Docker image:</p>
<div><pre><span></span>docker run -it --rm --device &lt;device&gt; f3:latest &lt;f3-command&gt; <span>[</span>&lt;f3-options&gt;<span>]</span> &lt;device&gt;

docker run -it --rm --device /dev/sdX f3:latest f3probe --destructive --time-ops /dev/sdX
docker run -it --rm -v /path/to/mounted/device:/mnt/ f3:latest f3write /mnt/
docker run -it --rm -v /path/to/mounted/device:/mnt/ f3:latest f3read /mnt/
</pre></div>
</div>
<div id="drive-permissions-passthrough">
<h3>Drive Permissions / Passthrough<a href="#drive-permissions-passthrough" title="Permalink to this headline">¶</a></h3>
<p>Getting the drive device to map into the Docker container is tricky for Mac and
Windows.  Passing through devices on Mac and Windows is a well-documented issue
(<a href="https://github.com/docker/for-mac/issues/3110#issuecomment-456853036">[github]</a>
<a href="https://devops.stackexchange.com/questions/4572/how-to-pass-a-dev-disk-device-on-macos-into-linux-docker/6076#6076">[stackexchange]</a>
<a href="https://christopherjmcclellan.wordpress.com/2019/04/21/using-usb-with-docker-for-mac/#tldr">[tty]</a>)
On Linux it should just work, but on Mac or Windows, Docker tends to map the
drive as a normal directory rather than a mounted drive and you will get an
error like <code><span>f3probe:</span> <span>Can't</span> <span>open</span> <span>device</span> <span>'/opt/usb':</span> <span>Is</span> <span>a</span> <span>directory</span></code>, that
is if you can map it at all.</p>
<p>To solve this, we can use docker-machine to create a VirtualBox VM
(boot2docker), in which to run the Docker container.  Since VirtualBox <em>can</em>
handle device pass-through, we can pass the device through to the VirtualBox VM
which can then pass the device through to the Docker container.  Milad Alizadeh
wrote up some good instructions <a href="https://mil.ad/blog/2018/access-usb-devices-in-container-in-mac.html">here</a>
which are geared towards USB devices, but it shouldn’t be too hard to adapt to
other drive types.  Here’s what I typed into my Mac terminal (probably
similar for Windows, but untested):</p>
<div><pre><span></span>docker-machine create -d virtualbox default
docker-machine stop
vboxmanage modifyvm default --usb on
docker-machine start
vboxmanage usbfilter add <span>0</span> --target default --name flashdrive --vendorid 0x0123 --productid 0x4567
<span>eval</span> <span>$(</span>docker-machine env default<span>)</span>
</pre></div>
<p>For the usbfilter add command, note that the “name” argument is the new name
you’re giving the filter so you can name it whatever you want.
<code><span>--vendorid</span></code> and <code><span>--productid</span></code> can be found on Mac in “System
Information” under “USB”. You can also try searching for the right device in
<code><span>vboxmanage</span> <span>list</span> <span>usbhost</span></code>.</p>
<p>Alternatively, you may opt to add the device through the VirtualBox GUI
application instead:</p>
<div><pre><span></span>docker-machine create -d virtualbox default
docker-machine stop
<span># open VirtualBox and manually add the drive device before proceeding to the next command</span>
docker-machine start
<span>eval</span> <span>$(</span>docker-machine env default<span>)</span>
</pre></div>
<p>Once you’ve run the above commands, unplug and replug the flash drive and run:</p>
<div><pre><span></span>docker-machine ssh default <span>"lsblk"</span>
</pre></div>
<p>to list the devices. Search for the correct drive - the “SIZE” column may be
helpful in locating the device of interest. For example, <code><span>sdb</span></code> is a common
mount point for a USB drive.  Now you should be able to run the command from
Quick Start:</p>
<div><pre><span></span>docker run --rm -it --device /dev/sdX peron/f3 f3probe --destructive --time-ops /dev/sdX
</pre></div>
<p>You may find it useful to enter a bash prompt in the Docker container to poke
around the filesystem:</p>
<div><pre><span></span>docker run --rm -it --device /dev/sdX peron/f3 bash
</pre></div>
<p>so that you can run commands like <code><span>ls</span> <span>/dev/*</span></code>.</p>
</div>
</div>

</div>
<div id="other-resources">
<h2>Other resources<a href="#other-resources" title="Permalink to this headline">¶</a></h2>
<div id="graphical-user-interfaces">
<h2>Graphical User Interfaces<a href="#graphical-user-interfaces" title="Permalink to this headline">¶</a></h2>
<p>Thanks to our growing community of flash fraud fighters,
we have the following graphical user interfaces (GUI) available for F3:</p>
<p><a href="https://github.com/zwpwjwtz/f3-qt">F3 QT</a> is a Linux GUI that uses
QT. F3 QT supports <code><span>f3write</span></code>, <code><span>f3read</span></code>, <code><span>f3probe</span></code>, and <code><span>f3fix</span></code>. Author:
Tianze.</p>
<p><a href="https://github.com/vrunkel/F3XSwift">F3XSwift</a> is a Mac GUI. F3XSwift supports <code><span>f3write</span></code> and <code><span>f3read</span></code>. Author:
Volker Runkel.</p>
<p>Please support the above projects by testing them and giving feedback to their
authors. This will improve their code as it has improved mine.</p>
</div>
<div id="files">
<h2>Files<a href="#files" title="Permalink to this headline">¶</a></h2>
<div><pre><span></span>changelog   - Change log <span>for</span> package maintainers
f3read.1    - Man page <span>for</span> f3read and f3write
            In order to <span>read</span> this manual page, run <span>`</span>man ./f3read.1<span>`</span>
            To install the page, run
            <span>`</span>install --owner<span>=</span>root --group<span>=</span>root --mode<span>=</span><span>644</span> f3read.1 /usr/share/man/man1<span>`</span>
LICENSE     - License <span>(</span>GPLv3<span>)</span>
Makefile    - make<span>(</span><span>1</span><span>)</span> file
README      - This file
*.h and *.c - C code of F3
</pre></div>
</div>
<div id="bash-scripts">
<h2>Bash scripts<a href="#bash-scripts" title="Permalink to this headline">¶</a></h2>
<p>Although the simple scripts listed in this section are ready for use,
they are really meant to help you to write your own scripts. So you can
personalize F3 to your specific needs:</p>
<div><pre><span></span>f3write.h2w - Script to create files exactly like H2testw.
    Use example: <span>`</span>f3write.h2w /media/michel/5EBD-5C80/<span>`</span>

log-f3wr    - Script that runs f3write and f3read, and records
              their output into a log file.
    Use example: <span>`</span>log-f3wr log-filename /media/michel/5EBD-5C80/<span>`</span>
</pre></div>
<p>Please notice that all scripts and use examples above assume that
f3write, f3read, and the scripts are in the same folder.</p>
</div>
<div id="flakyflash">
<h2>Flakyflash<a href="#flakyflash" title="Permalink to this headline">¶</a></h2>
<p>If your flash isn’t fraudulent (or you’ve run f3fix to “fix” it) but
you’re still seeing some sporadic data corruption, then you may have
“flaky flash.” If your flash is formatted using the FAT file system,
then you can use <a href="https://github.com/whitslack/flakyflash">Flakyflash</a>
to find the flaky data clusters and mark them as bad in the FAT. This
may allow you to get a little more use out of your flash, but you
should still consider it as failing and replace it ASAP.</p>
</div>
</div>


          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trunk: Build, bundle and ship your Rust WASM application to the web (101 pts)]]></title>
            <link>https://trunkrs.dev/</link>
            <guid>41046226</guid>
            <pubDate>Tue, 23 Jul 2024 14:15:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trunkrs.dev/">https://trunkrs.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=41046226">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
            <p>Overview</p>
            <p>Trunk is a WASM web application bundler for Rust. Trunk uses a simple, optional-config pattern for building &amp; bundling WASM, JS snippets &amp; other assets (images, css, scss) via a source HTML file.</p>
<h2 id="getting-started">Getting Started</h2>
<h2 id="install">Install</h2>
<p>First, install Trunk via one of the following options.</p>
<h3 id="plain-cargo">Plain cargo</h3>
<p>Download the sources and build them yourself:</p>
<pre data-lang="bash"><code data-lang="bash"><span>cargo install --locked trunk
</span></code></pre>
<p>You can also toggle some features using the <code>--features</code> flag:</p>
<dl>
<dt><code>rustls</code> (default)</dt><dd>Use rustls for client and server sockets</dd>
<dt><code>native-tls</code></dt><dd>Enable the use of the system native TLS stack for client sockets, and `openssl` for server sockets</dd>
<dt><code>update_check</code> (default)</dt><dd>Enable the update check on startup</dd>
</dl>
<p><strong>NOTE:</strong> If both <code>rustls</code> and <code>native-tls</code> are enabled, <code>rustls</code> will be used. You can disable the default <code>rustls</code> using
<code>--no-default-features</code>.</p>
<h3 id="cargo-binstall">Cargo binstall</h3>
<p>You can download a released binary from GitHub releases through <a href="https://github.com/cargo-bins/cargo-binstall"><code>binstall</code></a>.</p>
<pre data-lang="bash"><code data-lang="bash"><span>cargo binstall trunk
</span></code></pre>
<h3 id="github-release-download">GitHub release download</h3>
<p>Fetch and unpack a released binary from the <a href="https://github.com/trunk-rs/trunk/releases">release page</a>.</p>
<p>For example (be sure to check for the most recent version):</p>
<pre data-lang="bash"><code data-lang="bash"><span>wget -qO- https://github.com/trunk-rs/trunk/releases/download/0.17.10/trunk-x86_64-unknown-linux-gnu.tar.gz </span><span>| </span><span>tar -xzf-
</span></code></pre>
<h3 id="nixos">NixOS</h3>
<pre data-lang="bash"><code data-lang="bash"><span>nix-env -i trunk
</span></code></pre>
<h3 id="brew">Brew</h3>
<pre data-lang="bash"><code data-lang="bash"><span>brew install trunk
</span></code></pre>

<p>Any additional tools like <code>wasm-bindgen</code> and <code>wasm-opt</code> are automatically downloaded and managed by trunk. Therefore, no further steps required 🎉.</p>
<p><strong>Note:</strong> Until <code>wasm-bindgen</code> has pre-built binaries for Apple M1, M1 users will need to install <code>wasm-bindgen</code> manually.</p>
<pre data-lang="bash"><code data-lang="bash"><span>cargo install --locked wasm-bindgen-cli
</span></code></pre>
<h2 id="app-setup">App Setup</h2>
<p>Any <code>wasm-bindgen</code>-based framework will work with Trunk. If you're new to <a href="https://github.com/flosse/rust-web-framework-comparison#frontend-frameworks-wasm">frontend development in Rust</a>, <a href="https://yew.rs/">Yew</a> and <a href="https://leptos.dev/">Leptos</a> are two popular options.</p>
<p>The easiest way to ensure that your application launches properly is to <a href="https://doc.rust-lang.org/cargo/guide/project-layout.html">setup your app as an executable</a> with a standard <code>main</code> function:</p>
<pre data-lang="rust"><code data-lang="rust"><span>fn </span><span>main</span><span>() {
</span><span>    </span><span>// ... your app setup code here ...
</span><span>}
</span></code></pre>
<p>Trunk uses a source HTML file to drive all asset building and bundling. Trunk also uses the official <a href="https://github.com/sass/dart-sass">dart-sass</a>, so let's get started with the following example. Copy this HTML to the root of your project's repo as <code>index.html</code>:</p>
<pre data-lang="html"><code data-lang="html"><span>&lt;</span><span>html</span><span>&gt;
</span><span>  &lt;</span><span>head</span><span>&gt;
</span><span>    &lt;</span><span>link </span><span>data-trunk rel</span><span>=</span><span>"scss" </span><span>href</span><span>=</span><span>"path/to/index.scss"</span><span>/&gt;
</span><span>  &lt;/</span><span>head</span><span>&gt;
</span><span>&lt;/</span><span>html</span><span>&gt;
</span></code></pre>
<p><code>trunk build</code> will produce the following HTML at <code>dist/index.html</code>, along with the compiled scss, WASM &amp; the JS loader for the WASM:</p>
<pre data-lang="html"><code data-lang="html"><span>&lt;</span><span>html</span><span>&gt;
</span><span>  &lt;</span><span>head</span><span>&gt;
</span><span>    &lt;</span><span>link </span><span>rel</span><span>=</span><span>"stylesheet" </span><span>href</span><span>=</span><span>"/index-c920ca43256fdcb9.css"</span><span>&gt;
</span><span>    &lt;</span><span>link </span><span>rel</span><span>=</span><span>"preload" </span><span>href</span><span>=</span><span>"/index-7eeee8fa37b7636a_bg.wasm" </span><span>as</span><span>=</span><span>"fetch" </span><span>type</span><span>=</span><span>"application/wasm" </span><span>crossorigin</span><span>=</span><span>""</span><span>&gt;
</span><span>    &lt;</span><span>link </span><span>rel</span><span>=</span><span>"modulepreload" </span><span>href</span><span>=</span><span>"/index-7eeee8fa37b7636a.js"</span><span>&gt;
</span><span>  &lt;/</span><span>head</span><span>&gt;
</span><span>  &lt;</span><span>body</span><span>&gt;
</span><span>    &lt;</span><span>script </span><span>type</span><span>=</span><span>"module"</span><span>&gt;
</span><span>      </span><span>import </span><span>init, </span><span>* </span><span>as </span><span>bindings </span><span>from </span><span>'/index-7eeee8fa37b7636a.js'</span><span>;
</span><span>      </span><span>window</span><span>.wasmBindings </span><span>= </span><span>bindings;
</span><span>      init(</span><span>'/index-7eeee8fa37b7636a_bg.wasm'</span><span>);
</span><span>    &lt;/</span><span>script</span><span>&gt;
</span><span>  &lt;/</span><span>body</span><span>&gt;
</span><span>&lt;/</span><span>html</span><span>&gt;
</span></code></pre>
<p>The contents of your <code>dist</code> dir are now ready to be served on the web.</p>
<h2 id="next-steps">Next Steps</h2>
<p>That's not all! Trunk has even more useful features. Head on over to the following sections to learn more about how to use Trunk effectively.</p>
<ul>
<li><a href="https://trunkrs.dev/assets/">Assets</a>: learn about all of Trunk's supported asset types.</li>
<li><a href="https://trunkrs.dev/configuration/">Configuration</a>: learn about Trunk's configuration system and how to use the Trunk proxy.</li>
<li><a href="https://trunkrs.dev/commands/">Commands</a>: learn about Trunk's CLI commands for use in your development workflows.</li>
<li><a href="https://trunkrs.dev/advanced/">Advanced topics</a>: learn about some more advanced topics.</li>
<li>Join us on Discord by following this link <a href="https://discord.gg/JEPdBujTDr"><img src="https://img.shields.io/discord/793890238267260958?logo=discord&amp;style=flat-square" alt="" title="Discord Chat"></a></li>
</ul>
<h2 id="contributing">Contributing</h2>
<p>Anyone and everyone is welcome to contribute! Please review the <a href="https://github.com/trunk-rs/trunk/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> document for more details. The best way to get started is to find an open issue, and then start hacking on implementing it. Letting other folks know that you are working on it, and sharing progress is a great approach. Open pull requests early and often, and please use GitHub's draft pull request feature.</p>
<h2 id="license">License</h2>
<p><span><img src="https://img.shields.io/badge/license-MIT%2FApache--2.0-blue?style=flat-square" alt="license badge"></span>
<br>
trunk is licensed under the terms of the MIT License or the Apache License 2.0, at your choosing.</p>

            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Briefer – multiplayer notebooks with schedules, SQL, and built-in LLMs (157 pts)]]></title>
            <link>https://briefer.cloud/launches/notebooks/</link>
            <guid>41045834</guid>
            <pubDate>Tue, 23 Jul 2024 13:30:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://briefer.cloud/launches/notebooks/">https://briefer.cloud/launches/notebooks/</a>, See on <a href="https://news.ycombinator.com/item?id=41045834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="the-file-tree"><h2>The file tree</h2><div><article><p><strong>The file tree is where you can manage your notebooks and navigate through them.</strong></p>
<p>Like in Notion, you can choose icons for each notebook, reorder them, or put one inside another. That way, you can organize your notebooks in a way that makes sense to you and your team.</p>
<p>Additionally, whenever you delete a notebook, we keep a copy in the trash so you can restore it if needed.</p>
</article></div></div><div id="blocks-and-tabs"><h2>Blocks and tabs</h2><div><article><p><strong>Briefer notebooks are made of blocks of different types.</strong></p>
<p>Each block has a specific purpose and performs different tasks.</p>
<ul>
<li><strong>Text blocks</strong> are for you to add context to your notebook.</li>
<li><strong>Query blocks</strong> are for you to gather data from files or connected data sources, like Postgres, BigQuery, Redshift, Athena, and others.</li>
<li><strong>File upload blocks</strong> are for you to add CSV, XLS, or other files to your notebook in case your data is not in a connected data source.</li>
<li><strong>Python blocks</strong> are for you to write Python code to manipulate data, create visualizations, or do whatever else you want.</li>
<li><strong>Input blocks</strong> are for you to add interactive elements to your notebook, like text inputs or dropdowns.</li>
<li><strong>Visualization blocks</strong> are for you to create visualizations without writing any code.</li>
</ul>
<p><strong>After adding blocks to your notebook, you can group them into tabs to organize your notebook and make it easier to navigate through.</strong></p>
</article></div></div><div id="files-and-databases"><h2>Files and databases</h2><div><article><p><strong>You can use query blocks to query data from files and databases without having to write wrappers or connectors.</strong></p>
<p>If your data is in a database, you can use query blocks to write SQL queries and get the data you need.</p>
<p>In case your data is in a file (CSV, XLSX, Parquet, or others), you can upload that file and query it using regular SQL.</p>
<p>Briefer's query blocks also allow you to query dataframes using regular SQL.</p>
</article></div></div><div id="automatic-dataframes"><h2>Automatic dataframes</h2><div><article><p><strong>Every query block automatically creates a Pandas dataframe containing the query's result.</strong></p>
<p>This way, you can use this data in further Python blocks.</p>
<p>Let's say you want to plot your app's signups per month.</p>
<p>To do that, you can start by using a query block to fetch the signups from your database. This query block will automatically create a dataframe containing the query's results.</p>
<p>Then, you can use this dataframe in Python blocks to aggregate the data by month and create a plot using <code>matplotlib</code> or <code>seaborn</code>, for example.</p>
<p>By default, dataframes have names like <code>query_1</code>, but you can rename them to something more meaningful.</p>
</article></div></div><div id="ai-assistant"><h2>AI Assistant</h2><div><article><p>SQL and Python blocks include an AI assistant.</p>
<p>Whenever you want the AI assistant's help, you can click "edit with AI" and tell it what you want to do.</p>
<p>Then, the AI assistant will come up with a suggestion and show you a diff that you can try, accept, or reject.</p>
<p>In the Python block, the AI assistant is aware of the existing dataframes and its columns.</p>
<p>In the SQL block, the AI assistant already knows the tables and columns in your database, so it can give better suggestions and help you get complex queries right.</p>
<p>Whenever an error comes up, you can click "Fix with AI" to get the AI assistant to try to fix it for you.</p>
</article></div></div><div id="schedules"><h2>Schedules</h2><div><article><p><strong>You can schedule your notebooks to run at a specific interval, like every hour, every day, every week, or every month.</strong></p>
<p>Let's say you're working on a notebook that fetches live data from a database and creates a detailed report with leads generated by your marketing campaigns.</p>
<p>In that case, you can schedule this notebook to run every day at 8:00 AM, so you have the report ready for your sales team when they start their day.</p>
<p>When creating schedules, you can also set up notifications to receive an email or Slack message when the schedule runs successfully or fails. In the case of successful runs you will also receive a PDF file with the notebook's outputs.</p>
</article></div></div><div id="snapshots-versioning"><div><h2>Snapshots and versioning</h2><div><article><p><strong>Whenever you publish a notebook, we automatically save the notebook's state so you can see the changes over time and roll back to previous versions if needed.</strong></p>
<p>This way, you can keep track of the changes you make to your notebooks and revert to a previous version if something goes wrong.</p>
<p><strong>Additionally, every successful scheduled run creates a snapshot of the notebook's state at that time.</strong></p>
<p>Snapshots are useful when you want to see how results changed over time or compare the outputs of different runs.</p>
</article></div></div><div><p><span>snapshots_and_versioning.mp4</span></p></div></div><div id="notebooks-to-dashboards"><div><h2>Notebooks to dashboards</h2><div><article><p><strong>You can use your notebook's outputs to create dashboards.</strong></p>
<p>This way, you can share results with others without including unnecessary code or explanations, like when you have to do a lot of data wrangling before plotting a chart.</p>
<p>Dashboard views are also useful for building data apps, where you want to allow users to interact with inputs and dropdowns but don't want them to see the code behind the scenes.</p>
</article></div></div><div><p><span>notebooks_to_dashboards.mp4</span></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Convert HTML DOM to semantic markdown for use in LLMs (103 pts)]]></title>
            <link>https://github.com/romansky/dom-to-semantic-markdown</link>
            <guid>41043771</guid>
            <pubDate>Tue, 23 Jul 2024 08:13:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/romansky/dom-to-semantic-markdown">https://github.com/romansky/dom-to-semantic-markdown</a>, See on <a href="https://news.ycombinator.com/item?id=41043771">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/romansky/dom-to-semantic-markdown/blob/main/d2m_color.svg"><img width="100" height="100" src="https://github.com/romansky/dom-to-semantic-markdown/raw/main/d2m_color.svg" alt=""></a><br>
    DOM to Semantic Markdown
</h2><a id="user-content---------dom-to-semantic-markdown" aria-label="Permalink: 
    DOM to Semantic Markdown
" href="#--------dom-to-semantic-markdown"></a></div>
<p dir="auto"><a href="https://github.com/romansku/dom-to-semantic-markdown/actions/workflows/ci.yml"><img src="https://github.com/romansky/dom-to-semantic-markdown/actions/workflows/ci.yml/badge.svg" alt="CI"></a>
<a href="https://badge.fury.io/js/dom-to-semantic-markdown" rel="nofollow"><img src="https://camo.githubusercontent.com/ccb34feda3afb709eaa3677eb22e9e7e7151dcc811d66a910d7355d92b95c8bf/68747470733a2f2f62616467652e667572792e696f2f6a732f646f6d2d746f2d73656d616e7469632d6d61726b646f776e2e737667" alt="npm version" data-canonical-src="https://badge.fury.io/js/dom-to-semantic-markdown.svg"></a>
<a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/6552afb9038154d801c50b6e55a76db78a6787a8d6e2b5252a44864503c52887/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d626c75652e737667" alt="License: ISC" data-canonical-src="https://img.shields.io/badge/License-MIT-blue.svg"></a></p>
<p dir="auto">Convert HTML DOM to Semantic Markdown for use in LLMs (Large Language Models).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#why-dom-to-semantic-markdown">Why DOM to Semantic Markdown?</a></li>
<li><a href="#features">Features</a></li>
<li><a href="#semantic-format">Semantic Format</a></li>
<li><a href="#use-cases">Use Cases</a></li>
<li><a href="#tools">Tools</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#usage">Usage</a></li>
<li><a href="#adding-to-an-existing-project">Adding to an Existing Project</a></li>
<li><a href="#api">API</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#license">License</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why DOM to Semantic Markdown?</h2><a id="user-content-why-dom-to-semantic-markdown" aria-label="Permalink: Why DOM to Semantic Markdown?" href="#why-dom-to-semantic-markdown"></a></p>
<p dir="auto">DOM to Semantic Markdown addresses several key challenges in extracting web content for LLMs:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Maximizing Semantic Information</strong>: Preserves the semantic structure of web content, unlike traditional HTML-to-text conversion.</p>
</li>
<li>
<p dir="auto"><strong>Token Efficiency</strong>: Produces a concise yet information-rich format, reducing token usage compared to verbose HTML.</p>
</li>
<li>
<p dir="auto"><strong>Preserving Metadata</strong>: Retains essential metadata like links, image descriptions, and structural information.</p>
</li>
<li>
<p dir="auto"><strong>Semantic Clarity</strong>: Converts web content to a format more easily "understandable" for LLMs, enhancing their processing and reasoning capabilities.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>HTML to Semantic Markdown AST conversion</li>
<li>Detection and extraction of main content</li>
<li>Semantic structure preservation (e.g., <code>&lt;header&gt;</code>, <code>&lt;footer&gt;</code>, <code>&lt;nav&gt;</code>)</li>
<li>Metadata capture for images, tables, and other rich media elements</li>
<li>URL refification for token optimization</li>
<li>Customizable conversion options</li>
<li>Browser and Node.js support</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Semantic Format</h2><a id="user-content-semantic-format" aria-label="Permalink: Semantic Format" href="#semantic-format"></a></p>
<p dir="auto">DOM to Semantic Markdown's format captures rich web content structure:</p>
<ul dir="auto">
<li>Preserves HTML semantic tags (<code>&lt;header&gt;</code>, <code>&lt;footer&gt;</code>, <code>&lt;nav&gt;</code>, <code>&lt;aside&gt;</code>, etc.)</li>
<li>Captures image metadata (alt text, dimensions, etc.)</li>
<li>Maintains table structures and data relationships</li>
<li>Preserves link destinations while optimizing for token efficiency</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Use Cases</h2><a id="user-content-use-cases" aria-label="Permalink: Use Cases" href="#use-cases"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Content-Focused Q&amp;A</strong>: Extract main content for focused question-answering tasks.</p>
</li>
<li>
<p dir="auto"><strong>Full-Page Analysis</strong>: Convert entire web pages for comprehensive site analysis.</p>
</li>
<li>
<p dir="auto"><strong>Rich Media Understanding</strong>: Preserve image descriptions and table structures for visual or structured data tasks.</p>
</li>
<li>
<p dir="auto"><strong>SEO and Content Auditing</strong>: Analyze page structure and content distribution across semantic sections.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tools</h2><a id="user-content-tools" aria-label="Permalink: Tools" href="#tools"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Abstract Syntax Tree (AST)</h3><a id="user-content-abstract-syntax-tree-ast" aria-label="Permalink: Abstract Syntax Tree (AST)" href="#abstract-syntax-tree-ast"></a></p>
<ul dir="auto">
<li>Enables programmatic content manipulation and analysis.</li>
<li>Facilitates advanced filtering, restructuring, and content transformation.</li>
</ul>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { htmlToMarkdownAST, findInMarkdownAST } from 'dom-to-semantic-markdown';

const html = '<div><h1>Title</h1><p>Content</p></div>';
const ast = htmlToMarkdownAST(html);

const headingNode = findInMarkdownAST(ast, node => node.type === 'heading' &amp;&amp; node.level === 1);
console.log(headingNode); // { type: 'heading', level: 1, content: 'Title' }"><pre><span>import</span> <span>{</span> <span>htmlToMarkdownAST</span><span>,</span> <span>findInMarkdownAST</span> <span>}</span> <span>from</span> <span>'dom-to-semantic-markdown'</span><span>;</span>

<span>const</span> <span>html</span> <span>=</span> <span>'&lt;div&gt;&lt;h1&gt;Title&lt;/h1&gt;&lt;p&gt;Content&lt;/p&gt;&lt;/div&gt;'</span><span>;</span>
<span>const</span> <span>ast</span> <span>=</span> <span>htmlToMarkdownAST</span><span>(</span><span>html</span><span>)</span><span>;</span>

<span>const</span> <span>headingNode</span> <span>=</span> <span>findInMarkdownAST</span><span>(</span><span>ast</span><span>,</span> <span>node</span> <span>=&gt;</span> <span>node</span><span>.</span><span>type</span> <span>===</span> <span>'heading'</span> <span>&amp;&amp;</span> <span>node</span><span>.</span><span>level</span> <span>===</span> <span>1</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>headingNode</span><span>)</span><span>;</span> <span>// { type: 'heading', level: 1, content: 'Title' }</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">URL Refification</h3><a id="user-content-url-refification" aria-label="Permalink: URL Refification" href="#url-refification"></a></p>
<ul dir="auto">
<li>Converts long URLs into shorter, token-efficient references.</li>
<li>Preserves link information while reducing token count.</li>
</ul>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { convertHtmlToMarkdown } from 'dom-to-semantic-markdown';

const html = '<a href=&quot;https://example.com/very/long/url&quot;>Link</a>';
const markdown = convertHtmlToMarkdown(html, { refifyUrls: true });
console.log(markdown);
// Output: [Link](ref1)
// ref1: https://example.com/very/long/url"><pre><span>import</span> <span>{</span> <span>convertHtmlToMarkdown</span> <span>}</span> <span>from</span> <span>'dom-to-semantic-markdown'</span><span>;</span>

<span>const</span> <span>html</span> <span>=</span> <span>'&lt;a href="https://example.com/very/long/url"&gt;Link&lt;/a&gt;'</span><span>;</span>
<span>const</span> <span>markdown</span> <span>=</span> <span>convertHtmlToMarkdown</span><span>(</span><span>html</span><span>,</span> <span>{</span> <span>refifyUrls</span>: <span>true</span> <span>}</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>markdown</span><span>)</span><span>;</span>
<span>// Output: [Link](ref1)</span>
<span>// ref1: https://example.com/very/long/url</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Main Content Detection</h3><a id="user-content-main-content-detection" aria-label="Permalink: Main Content Detection" href="#main-content-detection"></a></p>
<ul dir="auto">
<li>Automatically identifies the primary content section of a webpage.</li>
<li>Focuses on relevant information, excluding boilerplate content when not needed.</li>
</ul>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { convertHtmlToMarkdown } from 'dom-to-semantic-markdown';

const html = `
  <header>Site Header</header>
  <main><h1>Main Content</h1><p>Important stuff.</p></main>
  <footer>Site Footer</footer>
`;
const markdown = convertHtmlToMarkdown(html, { extractMainContent: true });
console.log(markdown);
// Output: # Main Content
//
// Important stuff."><pre><span>import</span> <span>{</span> <span>convertHtmlToMarkdown</span> <span>}</span> <span>from</span> <span>'dom-to-semantic-markdown'</span><span>;</span>

<span>const</span> <span>html</span> <span>=</span> <span>`</span>
<span>  &lt;header&gt;Site Header&lt;/header&gt;</span>
<span>  &lt;main&gt;&lt;h1&gt;Main Content&lt;/h1&gt;&lt;p&gt;Important stuff.&lt;/p&gt;&lt;/main&gt;</span>
<span>  &lt;footer&gt;Site Footer&lt;/footer&gt;</span>
<span>`</span><span>;</span>
<span>const</span> <span>markdown</span> <span>=</span> <span>convertHtmlToMarkdown</span><span>(</span><span>html</span><span>,</span> <span>{</span> <span>extractMainContent</span>: <span>true</span> <span>}</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>markdown</span><span>)</span><span>;</span>
<span>// Output: # Main Content</span>
<span>//</span>
<span>// Important stuff.</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using <code>npx</code></h3><a id="user-content-using-npx" aria-label="Permalink: Using npx" href="#using-npx"></a></p>
<p dir="auto">You can use the tool directly with <code>npx</code> without needing to install it globally:</p>
<div dir="auto" data-snippet-clipboard-copy-content="> npx d2m@latest -h
Usage: d2m [options]

Convert DOM to Semantic Markdown

Options:
  -V, --version        output the version number
  -i, --input <file>   Input HTML file
  -o, --output <file>  Output Markdown file
  -e, --extract-main   Extract main content
  -u, --url <url>      URL to fetch HTML content from
  -h, --help           display help for command

> npx d2m@latest -i tryme.html -o output.md"><pre><span>&gt;</span> npx d2m@latest -h
Usage: d2m [options]

Convert DOM to Semantic Markdown

Options:
  -V, --version        output the version number
  -i, --input <span>&lt;</span>file<span>&gt;</span>   Input HTML file
  -o, --output <span>&lt;</span>file<span>&gt;</span>  Output Markdown file
  -e, --extract-main   Extract main content
  -u, --url <span>&lt;</span>url<span>&gt;</span>      URL to fetch HTML content from
  -h, --help           display <span>help</span> <span>for</span> <span>command</span>

<span>&gt;</span> npx d2m@latest -i tryme.html -o output.md</pre></div>
<p dir="auto"><a href="https://github.com/romansky/dom-to-semantic-markdown/blob/main/examples/cli/README.md">See more <code>npx</code> examples in the cli readme</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Adding to Existing Project</h3><a id="user-content-adding-to-existing-project" aria-label="Permalink: Adding to Existing Project" href="#adding-to-existing-project"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install -g dom-to-semantic-markdown"><pre>npm install -g dom-to-semantic-markdown</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Browser</h3><a id="user-content-browser" aria-label="Permalink: Browser" href="#browser"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { convertHtmlToMarkdown } from 'dom-to-semantic-markdown';

const html = '<h1>Hello, World!</h1><p>This is a <strong>test</strong>.</p>';
const markdown = convertHtmlToMarkdown(html);
console.log(markdown);"><pre><span>import</span> <span>{</span> <span>convertHtmlToMarkdown</span> <span>}</span> <span>from</span> <span>'dom-to-semantic-markdown'</span><span>;</span>

<span>const</span> <span>html</span> <span>=</span> <span>'&lt;h1&gt;Hello, World!&lt;/h1&gt;&lt;p&gt;This is a &lt;strong&gt;test&lt;/strong&gt;.&lt;/p&gt;'</span><span>;</span>
<span>const</span> <span>markdown</span> <span>=</span> <span>convertHtmlToMarkdown</span><span>(</span><span>html</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>markdown</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><a href="https://github.com/romansky/dom-to-semantic-markdown/blob/main/examples/browser.html">full browser example</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Node.js</h3><a id="user-content-nodejs" aria-label="Permalink: Node.js" href="#nodejs"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="const { convertHtmlToMarkdown } = require('dom-to-semantic-markdown');
const jsdom = require('jsdom');
const { JSDOM } = jsdom;

const html = '<h1>Hello, World!</h1><p>This is a <strong>test</strong>.</p>';
const dom = new JSDOM(html);
const markdown = convertHtmlToMarkdown(html, { overrideDOMParser: dom.window.DOMParser });
console.log(markdown);"><pre><span>const</span> <span>{</span> convertHtmlToMarkdown <span>}</span> <span>=</span> <span>require</span><span>(</span><span>'dom-to-semantic-markdown'</span><span>)</span><span>;</span>
<span>const</span> <span>jsdom</span> <span>=</span> <span>require</span><span>(</span><span>'jsdom'</span><span>)</span><span>;</span>
<span>const</span> <span>{</span> <span>JSDOM</span> <span>}</span> <span>=</span> <span>jsdom</span><span>;</span>

<span>const</span> <span>html</span> <span>=</span> <span>'&lt;h1&gt;Hello, World!&lt;/h1&gt;&lt;p&gt;This is a &lt;strong&gt;test&lt;/strong&gt;.&lt;/p&gt;'</span><span>;</span>
<span>const</span> <span>dom</span> <span>=</span> <span>new</span> <span>JSDOM</span><span>(</span><span>html</span><span>)</span><span>;</span>
<span>const</span> <span>markdown</span> <span>=</span> <span>convertHtmlToMarkdown</span><span>(</span><span>html</span><span>,</span> <span>{</span> <span>overrideDOMParser</span>: <span>dom</span><span>.</span><span>window</span><span>.</span><span>DOMParser</span> <span>}</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>markdown</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><a href="https://github.com/romansky/dom-to-semantic-markdown/blob/main/examples/node">full node example</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Adding to an Existing Project</h2><a id="user-content-adding-to-an-existing-project" aria-label="Permalink: Adding to an Existing Project" href="#adding-to-an-existing-project"></a></p>
<p dir="auto">To add <code>dom-to-semantic-markdown</code> to your existing project, follow these steps:</p>
<ol dir="auto">
<li>Install the library:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="npm add dom-to-semantic-markdown"><pre>npm add dom-to-semantic-markdown</pre></div>
<ol start="2" dir="auto">
<li>Import and use it in your project:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="import { convertHtmlToMarkdown } from 'dom-to-semantic-markdown';
import jsdom from 'jsdom';
const { JSDOM } = jsdom;

const html = '<h1>Hello, World!</h1><p>This is a <strong>test</strong>.</p>';
const dom = new JSDOM(html);
const markdown = convertHtmlToMarkdown(html, { overrideDOMParser: dom.window.DOMParser });

console.log(markdown);
// Output:
// # Hello, World!
// 
// This is a **test**."><pre><span>import</span> <span>{</span> <span>convertHtmlToMarkdown</span> <span>}</span> <span>from</span> <span>'dom-to-semantic-markdown'</span><span>;</span>
<span>import</span> <span>jsdom</span> <span>from</span> <span>'jsdom'</span><span>;</span>
<span>const</span> <span>{</span> <span>JSDOM</span> <span>}</span> <span>=</span> <span>jsdom</span><span>;</span>

<span>const</span> <span>html</span> <span>=</span> <span>'&lt;h1&gt;Hello, World!&lt;/h1&gt;&lt;p&gt;This is a &lt;strong&gt;test&lt;/strong&gt;.&lt;/p&gt;'</span><span>;</span>
<span>const</span> <span>dom</span> <span>=</span> <span>new</span> <span>JSDOM</span><span>(</span><span>html</span><span>)</span><span>;</span>
<span>const</span> <span>markdown</span> <span>=</span> <span>convertHtmlToMarkdown</span><span>(</span><span>html</span><span>,</span> <span>{</span> <span>overrideDOMParser</span>: <span>dom</span><span>.</span><span>window</span><span>.</span><span>DOMParser</span> <span>}</span><span>)</span><span>;</span>

<span>console</span><span>.</span><span>log</span><span>(</span><span>markdown</span><span>)</span><span>;</span>
<span>// Output:</span>
<span>// # Hello, World!</span>
<span>// </span>
<span>// This is a **test**.</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">API</h2><a id="user-content-api" aria-label="Permalink: API" href="#api"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>convertHtmlToMarkdown(html: string, options?: ConversionOptions): string</code></h3><a id="user-content-converthtmltomarkdownhtml-string-options-conversionoptions-string" aria-label="Permalink: convertHtmlToMarkdown(html: string, options?: ConversionOptions): string" href="#converthtmltomarkdownhtml-string-options-conversionoptions-string"></a></p>
<p dir="auto">Converts an HTML string to Semantic Markdown.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>convertElementToMarkdown(element: Element, options?: ConversionOptions): string</code></h3><a id="user-content-convertelementtomarkdownelement-element-options-conversionoptions-string" aria-label="Permalink: convertElementToMarkdown(element: Element, options?: ConversionOptions): string" href="#convertelementtomarkdownelement-element-options-conversionoptions-string"></a></p>
<p dir="auto">Converts an HTML Element to Semantic Markdown.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>ConversionOptions</code></h3><a id="user-content-conversionoptions" aria-label="Permalink: ConversionOptions" href="#conversionoptions"></a></p>
<ul dir="auto">
<li><code>websiteDomain?: string</code>: The domain of the website being converted.</li>
<li><code>extractMainContent?: boolean</code>: Whether to extract only the main content of the page.</li>
<li><code>refifyUrls?: boolean</code>: Whether to convert URLs to reference-style links.</li>
<li><code>debug?: boolean</code>: Enable debug logging.</li>
<li><code>overrideDOMParser?: DOMParser</code>: Custom DOMParser for Node.js environments.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions to DOM to Semantic Markdown are welcome!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License. See the <a href="https://github.com/romansky/dom-to-semantic-markdown/blob/main/LICENSE">LICENSE</a> file for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Types as Interfaces (148 pts)]]></title>
            <link>https://two-wrongs.com/types-as-interfaces</link>
            <guid>41043568</guid>
            <pubDate>Tue, 23 Jul 2024 07:34:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://two-wrongs.com/types-as-interfaces">https://two-wrongs.com/types-as-interfaces</a>, See on <a href="https://news.ycombinator.com/item?id=41043568">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>
For the past few days, I have been toying with an idea for a board game. To test
it out, I wanted to write a simple implementation of it. Here’s an example of a
type we might need in a critical phase of the game.
</p>

<div>
<pre><span>-- | A quote for a proposal.</span>
<span>data</span> <span>Quote</span> <span>=</span> <span>Quote</span>
  { _proposal <span>::</span> <span>Proposal</span>
  , _premium <span>::</span> <span>Int</span>
  , _share <span>::</span> <span>Int</span>
  }
</pre>
</div>

<p>
In that phase, values of this type need to be communicated back and forth
between players in a unicast fashion, so we might want to add fields to indicate
who sent it and who received it.
</p>

<div>
<pre><span>-- | A quote that has both owner and offering player.</span>
<span>data</span> <span>QuoteEtc</span> <span>=</span> <span>QuoteEtc</span>
  { _proposal <span>::</span> <span>Proposal</span>
  , _premium <span>::</span> <span>Int</span>
  , _share <span>::</span> <span>Int</span>
  , _owner <span>::</span> <span>PlayerId</span> <span>-- ^ Player that owns the process.</span>
  , _offering <span>::</span> <span>PlayerId</span> <span>-- ^ Player that offers this quote.</span>
  }
</pre>
</div>

<p>
But then I realised there are quite a lot of these types where source-and-target
fields are required, and that we could annotate them without modifying the
underlying type, by creating another type to hold that data:
</p>

<div>
<pre><span>-- | Create a unicast message from any type a.</span>
<span>data</span> <span>Msg</span> a <span>=</span> <span>Msg</span>
  { _sender <span>::</span> <span>PlayerId</span>
  , _recipient <span>::</span> <span>PlayerId</span>
  , _payload <span>::</span> a
  }
</pre>
</div>

<p>
With this, we can construct a value of type <code>Msg Quote</code> which represents the
<code>Quote</code> annotated by sender and recipient.
</p>

<div>
<pre><span>Msg</span>
  { _sender <span>=</span> <span>PlayerId</span> 2
  , _recipient <span>=</span> <span>PlayerId</span> 0
  , _payload <span>=</span> <span>Quote</span>
      { _proposal <span>=</span> undefined
      , _premium <span>=</span> 5
      , _share <span>=</span> 3
      }
  }
</pre>
</div>

<p>
Functions that only operate on the <code>_sender</code> and <code>_recipient</code> fields can be
written with the appropriate type signature and be generic over
payload.<label for="fn.1">1</label><span><sup>1</sup> This example uses object oriented style getters. If you’re
unfamiliar with optics/lenses, think of the operator <code>^.</code> as you would a regular
<code>.</code> to get a property from a value in a language like Python or C#.</span>
</p>

<div>
<pre><span>-- | Determines if a message is intended for player.</span>
<span>msg_for</span> <span>::</span> <span>Player</span> <span>-&gt;</span> <span>Msg</span> a <span>-&gt;</span> <span>Bool</span>
<span>msg_for</span> player msg <span>=</span>
  player<span>^.</span>name <span>==</span> msg<span>^.</span>recipient
</pre>
</div>

<p>
This function does not care what the payload of the message is; it can be used
on any list of messages, like
</p>

<div>
<pre>filter (msg_for broker) messages
</pre>
</div>

<p>
to extract a list of messages intended for that player, regardless of whether
the payload is <code>Quote</code> or anything else.<label for="fn.2">2</label><span><sup>2</sup> Though beginners with Haskell
beware: whenever we pass a list of messages into this funcion, it still needs to
be a homogeneous list of just one concrete type. We cannot mix both <code>Msg
Proposal</code> and <code>Msg Quote</code> in the same list.</span>
</p>

<p>
Even though <code>Msg</code> is a plain type constructor, it acts an awful lot like an
interface. That is the main point of this article; that’s a pattern that can be
used to design simple code.
</p>

<hr>

<p>
There is a common complaint against what we just did above. People say that
types-as-interfaces are not <i>composable</i>. Let’s find out what they mean. Imagine
we wanted some messages to be timestamped. We could add an optional <code>_timestamp</code>
field to the message type:
</p>

<div>
<pre><span>-- | Create a message from any type a, with optional timestamp.</span>
<span>data</span> <span>MsgEtc</span> a <span>=</span> <span>MsgEtc</span>
  { _sender <span>::</span> <span>PlayerId</span>
  , _recipient <span>::</span> <span>PlayerId</span>
  , _timestamp <span>::</span> <span>Maybe</span> <span>UTCTime</span>
  , _payload <span>::</span> a
  }
</pre>
</div>

<p>
but what if we also wanted to timestamp some of the other objects we have, like
<code>Quote</code>? Aha! We just learned how to do this! We create a new wrapper type:
</p>

<div>
<pre><span>-- | Annotate any value with a timestamp.</span>
<span>data</span> <span>Timestamped</span> a <span>=</span> <span>Timestamped</span>
  { _timestamp <span>::</span> <span>UTCTime</span>
  , _contents <span>::</span> a
  }
</pre>
</div>

<p>
Just as we before we can now tack on another layer of data and make a
<code>Timestamped (Msg Quote)</code>.
</p>

<div>
<pre><span>Timestamped</span>
  { _timestamp <span>=</span> now
  , _contents <span>=</span> <span>Msg</span>
      { _sender <span>=</span> <span>PlayerId</span> 2
      , _recipient <span>=</span> <span>PlayerId</span> 0
      , _payload <span>=</span> <span>Quote</span>
          { _proposal <span>=</span> undefined
          , _premium <span>=</span> 5
          , _share <span>=</span> 3
          }
      }
  }
</pre>
</div>

<p>
Clearly, this approach <i>does</i> compose, because we just composed both
<code>Timestamped a</code> and <code>Msg a</code>. But remember the <code>msg_for</code> function we had that
determined whether a message was intended for a particular recipient? It had the
signature
</p>

<div>
<pre><span>msg_for</span> <span>::</span> <span>Player</span> <span>-&gt;</span> <span>Msg</span> a <span>-&gt;</span> <span>Bool</span>
</pre>
</div>

<p>
meaning it takes any <code>Msg a</code> but it will not be possible to give it a
<code>Timestamped (Msg a)</code>; we have to unwrap the message from the timestamp first.
However, if we gave it an <code>Msg (Timestamped Quote)</code>, it would have worked,
perhaps counter-intuitively.
</p>

<p>
The complaint here is not that the approach does not compose at all (clearly it
does), but that it does not compose <i>well</i>: the order in which we choose to
annotate our data with extra fields affects whether or not we can pass them into
existing functions.
</p>

<p>
I think that’s basically fine. If we think about it, isn’t <code>Timestamped (Msg
Quote)</code> a different-feeling <i>thing</i> from a <code>Msg (Timestamped Quote)</code>? But let’s
assume we wanted to fix it. What is near at hand?
</p>

<hr>

<p>
We could make a typeclass
</p>

<div>
<pre><span>class</span> <span>HasRecipient</span> a <span>where</span>
  get_receiver <span>::</span> a <span>-&gt;</span> <span>PlayerId</span>
</pre>
</div>

<p>
This is more like a real interface, which can be implemented by any type that
has a receiver. Here are two implementations we would want:
</p>

<div>
<pre><span>instance</span> <span>HasRecipient</span> (<span>Msg</span> a) <span>where</span>
  get_receiver msg <span>=</span> msg<span>^.</span>receiver

<span>instance</span> <span>HasRecipient</span> (<span>Timestamped</span> (<span>Msg</span> a)) <span>where</span>
  get_receiver tsd <span>=</span> tsd<span>^.</span>contents<span>.</span>receiver
</pre>
</div>

<p>
We could then rewrite <code>msg_for</code> in terms of this typeclass instead.
</p>

<div>
<pre><span>msg_for</span> <span>::</span> <span>HasRecipient</span> msg <span>=&gt;</span> <span>Player</span> <span>-&gt;</span> msg <span>-&gt;</span> <span>Bool</span>
<span>msg_for</span> player msg <span>=</span>
  player<span>^.</span>name <span>==</span> get_receiver msg
</pre>
</div>

<p>
and this will work for any value of a type that implements <code>HasRecipient</code>,
including <code>Msg a</code> and <code>Timestamped (Msg a)</code>.
</p>

<p>
Okay, so let’s roll down this slippery slope. Maybe we have a function
</p>

<div>
<pre><span>logger</span> <span>::</span> <span>Show</span> a <span>=&gt;</span> [<span>Timestamped</span> a] <span>-&gt;</span> <span>IO</span> <span>()</span>
</pre>
</div>

<p>
which logs things in order of timestamp. This function will not take a list of
<code>Msg (Timestamped Quote)</code> because there the outer value is not timestamped but
the <code>Quote</code> inside.
</p>

<p>
We could apply our newly discovered hammer and create a similar <code>HasTimestamp</code> typeclass.
</p>

<div>
<pre><span>class</span> <span>HasTimestamp</span> a <span>where</span>
  get_timestamp <span>::</span> a <span>-&gt;</span> <span>UTCTime</span>

<span>instance</span> <span>HasTimestamp</span> (<span>Timestamped</span> a) <span>where</span>
  get_timestamp tsd <span>=</span> tsd<span>^.</span>timestamp

<span>instance</span> <span>HasRecipient</span> (<span>Msg</span> (<span>Timestamped</span> a)) <span>where</span>
  get_timestamp msg <span>=</span> msg<span>^.</span>payload<span>.</span>timestamp
</pre>
</div>

<p>
But at this point it gets a little confusing for this author’s brain – at least
if long-term maintenance is desired. What would be the best instance for
<code>Timestamped (Msg (Timestamped Quote))</code>, for example?
</p>

<p>
And as we said before, aren’t <code>Timestamped (Msg Quote)</code> and <code>Msg (Timestamped
Quote)</code> slightly different kinds of things? Do we <i>really</i> need to be able to
pass both unaltered into that logging function?
</p>

<hr>

<p>
What we really should do is take a cue from network protocol design. These are
robust things that have stood the test of time.
</p>

<p>
Image data might be stored in a <abbr>tga</abbr> file with headers giving information on
how to interpret it. It will be placed into a <abbr>http</abbr> request with its own headers.
This gets stuffed inside a <abbr>tcp</abbr> packet with further headers. That in turn is
enveloped in an <abbr>ip</abbr> datagram with headers. Which might then run along a wire
inside an ethernet frame, carrying – you guessed it – its own headers.
</p>

<p>
At no point during transmission<label for="fn.3">3</label><span><sup>3</sup> To be fair, I would not be surprised if it
was possible to find network switches in the wild that inspect <abbr>ip</abbr> headers, or
routers that look at <abbr>http</abbr> headers. So maybe that whole layered protocol thing
was a mistake and I’m full of crap!</span> does a switch hold up an ethernet frame to
the light and ask, “So what <abbr>http</abbr> content type are you transmitting?” We have
designed these protocols to be layered with meaningful structure from
outside to in. Maybe we can do that in our code as well.
</p>

<p>
Maybe we don’t need both <code>Timestamped (Msg Quote)</code> and <code>Msg (Timestamped Quote)</code>
in our application, and just one of them is enough. A mathematician creates
generalisations that work with everything. An engineer strips away the variants
that are less important and adapts the code to the big demands at hand. This
makes things simpler along the way.
</p>

<p>
If we do need both, maybe it’s fine to treat them as two different types (they
are!) and not try to make functions generic over them.
</p>

            </div></div>]]></description>
        </item>
    </channel>
</rss>