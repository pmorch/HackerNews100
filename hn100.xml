<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 16 Mar 2024 03:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Great Ideas in Theoretical Computer Science (149 pts)]]></title>
            <link>https://www.cs251.com</link>
            <guid>39720388</guid>
            <pubDate>Fri, 15 Mar 2024 20:30:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cs251.com">https://www.cs251.com</a>, See on <a href="https://news.ycombinator.com/item?id=39720388">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>
<h2>Great Ideas in Theoretical Computer Science</h2>
<h2>Great Ideas in Theoretical Computer Science</h2>
<h2>Great Ideas in Theoretical Computer Science</h2>
<h2>Great Ideas in Theoretical Computer Science</h2>
<h2>Great Ideas in Theoretical Computer Science</h2>
</p>
</div><div>
<p><img src="https://www.cs251.com/static/images/cs251_pic.jpg">
</p>
<div>
<p>Welcome to <span>CS251</span> at <a href="https://www.cmu.edu/">CMU</a>!</p>
<p>This course is about the rigorous study of computation, which is a fundamental component of our universe, the societies we live in, the new technologies we discover, as well as the minds we use to understand these things. Therefore, having the right language and tools to study computation is important. In this course, we explore some of the central results and questions regarding the nature of computation.</p>
</div>
</div><div>



<div>
<p><span>MODULE 1</span>
</p>
<p><span>MODULE 1</span>
<span>Introduction</span>
</p>
</div>
<div>
<div>
<p><img src="https://www.cs251.com/static/images/Module_Introduction.jpg">
</p>
</div>
<div>
<p>Welcome to CS251! In this module, our main goal is to explain at a high-level what theoretical computer science is about and set the right context for the material covered in the future.</p>
<p>In the first part of the course, we want to build up formally/mathematically, the important notions related to computation and algorithms. We start this journey here by discussing how to formally represent data and how to formally define the concept of a computational problem.</p>
</div>
</div>
<div>
<p><span>MODULE 2</span>
</p>
<p><span>MODULE 2</span>
<span>Finite Automata</span>
</p>
</div>
<div>
<div>
<p><img src="https://www.cs251.com/static/images/Module_Finite_Automata.jpg">
</p>
</div>
<div>
<p>The goal of this module is to introduce you to a simple (and restricted) model of computation known as <em>deterministic finite automata</em> (DFA). This model is interesting to study in its own right, and has very nice applications, however, our main motivation to study this model is to use it as a stepping stone towards formally defining the notion of an <em>algorithm</em> in its full generality. Treating deterministic finite automata as a warm-up, we would like you to get comfortable with how one formally defines a model of computation, and then proves interesting theorems related to the model. Along the way, you will start getting comfortable with using a bit more sophisticated mathematical notation than you might be used to. You will see how mathematical notation helps us express ideas and concepts accurately, succinctly and clearly.</p>
</div>
</div>
<div>
<p><span>MODULE 3</span>
</p>
<p><span>MODULE 3</span>
<span>Formalizing Computation</span>
</p>
</div>
<div>
<div>
<p><img src="https://www.cs251.com/static/images/Module_Formalizing_Computation.jpg">
</p>
</div>
<div>
<p>In this module, our main goal is to introduce the definition of a Turing machine, which is the standard mathematical model for any kind of computational device. As such, this definition is very foundational. As we discuss in lecture, the physical Church-Turing thesis asserts that any kind of physical device or phenomenon, when viewed as a computational process mapping input data to output data, can be simulated by some Turing machine. Thus, rigorously studying Turing machines does not just give us insights about what our laptops can or cannot do, but also tells us what the universe can and cannot do computationally. This module kicks things off with examples of computable problems. In the next module, we will start exploring the limitations of computation.</p>
</div>
</div>
<div>
<p><span>MODULE 4</span>
</p>
<p><span>MODULE 4</span>
<span>Limits of Computation</span>
</p>
</div>
<div>
<div>
<p><img src="https://www.cs251.com/static/images/Module_Limits_of_Computation.jpg">
</p>
</div>
<div>
<p>In this module, we prove that most problems are undecidable, and give some explicit examples of undecidable problems. The two key techniques we use are diagonalization and reductions. These are two of the most fundamental concepts in mathematics and computer science.</p>
</div>
</div>
<div>
<p><span>MODULE 5</span>
</p>
<p><span>MODULE 5</span>
<span>Limits of Human Reasoning</span>
</p>
</div>
<div>
<div>
<p><img src="https://www.cs251.com/static/images/Module_Limits_of_Human_Reasoning.jpg">
</p>
</div>
<div>
<p>The late 19th to early 20th century was an important time in mathematics. With various problems arising with the usual way of doing mathematics and proving things, it became clear that there was a need to put mathematical reasoning on a secure foundation. In other words, there was a need to mathematically formalize mathematical reasoning itself. As mathematicians took on the task of formalizing mathematics, two things started to become clear. First, a complete formalization of mathematics was not going to be possible. Second, formalization of mathematics involves formalizing what we informally understand as “algorithm” or “computation”. This is because one of the defining features of mathematical reasoning is that it is a computation. In this module we will make this connection explicit and see how the language of theoretical computer science can be effectively used to answer important questions in the foundations of mathematics.</p>
</div>
</div>



<div>
<p><span>MODULE 6</span>
</p>
<p><span>MODULE 6</span>
<span>Time Complexity</span>
</p>
</div>
<div>
<div>
<p><img src="https://www.cs251.com/static/images/Module_Time_Complexity.jpg">
</p>
</div>
<div>
<div>
<p>So far, we have formally defined what a computational/decision problem is, what an algorithm is, and saw that most (decision) problems are undecidable. We also saw some explicit and interesting examples of undecidable problems. Nevertheless, it turns out that many problems that we care about are actually decidable. So the next natural thing to study is the computational complexity of problems. If a problem is decidable, but the most efficient algorithm solving it takes vigintillion computational steps even for reasonably sized inputs, then practically speaking, that problem is still undecidable. In a sense, computational complexity is the study of practical computability.</p>
<p>Even though computational complexity can be with respect to various resources like time, memory, randomness, and so on, we will be focusing on arguably the most important one: time complexity. In this module, we will set the right context and language to study time complexity.</p>
</div>

<div>
<p>
To be added (under construction).
</p>
</div>
</div>
</div>
<div>
<p><span>MODULE 7</span>
</p>
<p><span>MODULE 7</span>
<span>Graph Theory</span>
</p>
</div>
<div>
<div>
<p><img src="https://www.cs251.com/static/images/Module_Graph_Theory.jpg">
</p>
</div>
<div>
<div>
<p>In the study of computational complexity of languages and computational problems, graphs play a very fundamental role. This is because an enormous number of computational problems that arise in computer science can be abstracted away as problems on graphs, which model pairwise relations between objects. This is great for various reasons. For one, this kind of abstraction removes unnecessary distractions about the problem and allows us to focus on its essence. Second, there is a huge literature on graph theory, so we can use this arsenal to better understand the computational complexity of graph problems. Applications of graphs are too many and diverse to list here, but we’ll name a few to give you an idea: communication networks, finding shortest routes in various settings, finding matchings between two sets of objects, social network analysis, kidney exchange protocols, linguistics, topology of atoms, and compiler optimization.</p>
<p>This module introduces basic graph theoretic concepts as well as some of the fundamental graph algorithms.</p>
</div>

<div>
<p>
To be added (under construction).
</p>
</div>
</div>
</div>
<div>
<p><span>MODULE 8</span>
</p>
<p><span>MODULE 8</span>
<span>P vs NP</span>
</p>
</div>
<div>
<div>
<p><img src="https://www.cs251.com/static/images/Module_P_vs_NP.jpg">
</p>
</div>
<div>
<div>
<p>In this module, we introduce the complexity class NP and discuss the most important open problem in computer science: the P vs NP problem. The class NP contains many natural and well-studied languages that we would love to decide in polynomial time. In particular, if we could decide the languages in NP efficiently, this would lead to amazing applications. For instance, in mathematics, proofs to theorems with reasonable length proofs would be found automatically by computers. In artificial intelligence, many machine learning tasks we struggle with would be easy to solve (like vision recognition, speech recognition, language translation and comprehension, etc). Many optimization tasks would become efficiently solvable, which would affect the economy in a major way. Another main impact would happen in privacy and security. We would say “bye” to public-key cryptography which is being used heavily on the internet today. (We will learn about public-key cryptography in a later module.) These are just a few examples; there are many more.</p>
<p>Our goal in this module is to present the formal definition of NP, and discuss how it relates to P. We also discuss the notion of NP-completeness (which is intimately related to the question of whether NP equals P) and give several examples of NP-complete languages.</p>
</div>

<div>
<p>
To be added (under construction).
</p>
</div>
</div>
</div>
<div>
<p><span>MODULE 9</span>
</p>
<p><span>MODULE 9</span>
<span>Randomized Algorithms</span>
</p>
</div>
<div>
<div>
<p><img src="https://www.cs251.com/static/images/Module_Randomized_Algorithms.jpg">
</p>
</div>
<div>
<div>
<p>Randomness is an essential concept and tool in modeling and analyzing nature. Therefore, it should not be surprising that it also plays a foundational role in computer science. For many problems, solutions that make use of randomness are the simplest, most efficient and most elegant solutions. And in many settings, one can prove that randomness is absolutely required to achieve a solution. (We mention some concrete examples in lecture.)</p>
<p>One of the primary applications of randomness to computer science is randomized algorithms. A randomized algorithm is an algorithm that has access to a randomness source like a random number generator, and a randomized algorithm is allowed to err with a very small probability of error. There are computational problems that we know how to solve efficiently using a randomized algorithms, however, we do not know how to solve those problems efficiently with a deterministic algorithm (i.e. an algorithm that does not make use of randomness). In fact, one of the most important open problems in computer science asks whether every efficient randomized algorithm has a deterministic counterpart solving the same problem. In this module, we start by reviewing probability theory, and then introduce the concept of randomized algorithms.</p>
</div>

<div>
<p>
To be added (under construction).
</p>
</div>
</div>
</div>
<div>
<p><span>MODULE 10</span>
</p>
<p><span>MODULE 10</span>
<span>Cryptography</span>
</p>
</div>
<div>
<div>
<p><img src="https://www.cs251.com/static/images/Module_Cryptography.jpg">
</p>
</div>
<div>
<div>
<p>The quest for secure communication in the presence of adversaries is an ancient one. From Caesar shift to the sophisticated Enigma machines used by Germans during World War 2, there have been a variety of interesting cryptographic protocols used in history. But it wasn’t until the computer science revolution in the mid 20th century when the field of cryptography really started to flourish. In fact, it is fair to say that the study of computational complexity completely revolutionized cryptography. The key idea is to observe that any adversary would be computationally bounded just like anyone else. And we can exploit the computational hardness of certain problems to design beautiful cryptographic protocols for many different tasks. In this module, we will first review the mathematical background needed (modular arithmetic), and then present some of the fundamental cryptographic protocols to achieve secure communication.</p>
</div>

<div>
<p>
To be added (under construction).
</p>
</div>
</div>
</div>

<div>
<p>
Highlights of Theoretical Computer Science
</p>
</div>

<div>
<p><span>MODULE 11</span>
</p>
<p><span>MODULE 11</span>
<span>Extra Topics</span>
</p>
</div>
<div>
<div>
<p><img src="https://www.cs251.com/static/images/Module_Extra_Topics.jpg">
</p>
</div>
<div>
<div>
<p>In this module, we present a selection of highlights from theoretical computer science.</p>
</div>

<div>
<p>
To be added (under construction).
</p>
</div>
</div>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nix is a better Docker image builder than Docker's image builder (148 pts)]]></title>
            <link>https://xeiaso.net/talks/2024/nix-docker-build/</link>
            <guid>39720007</guid>
            <pubDate>Fri, 15 Mar 2024 19:56:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xeiaso.net/talks/2024/nix-docker-build/">https://xeiaso.net/talks/2024/nix-docker-build/</a>, See on <a href="https://news.ycombinator.com/item?id=39720007">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
    

    


<article>
    
    <p>
        Fri Mar 15 2024
    </p>

    

    <div><div><h2><big>$50 of Fly.io Credits</big></h2><p>Coupon code <a href="http://fly.io/ref/go-fly-nix"><code>go-fly-nix</code></a>. Only valid for new accounts that have not used a DevRel coupon code before.</p></div><div><h2><big>Slides and Video</big></h2><p>Slides: <a href="https://drive.google.com/file/d/18-Bz9422oyQH1KKkguHirWr_dEsbB6pT/view?usp=sharing">Google Drive</a><br>
Script: <a href="https://drive.google.com/file/d/1sNhkcT1IlqtFYTj-gg8-gneC604PcTrH/view?usp=sharing">Google Drive</a><br>
Video: <strong>Coming Soon!</strong></p></div></div>
<div><p><img alt="Cadey is coffee" loading="lazy" src="https://cdn.xeiaso.net/sticker/cadey/coffee/64"></p><div><p>&lt;<a href="https://xeiaso.net/characters#cadey"><b>Cadey</b></a>&gt; </p><p>A full copy of the talk will be available later today. The video may take
longer. Conference wifi is horrible.</p></div></div>
<h2>The Talk</h2>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/001.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/001.webp"><img alt="The title slide of the talk. It features a hot air balloon breaking into a shipping container with a crowbar. Art by Annie Rugyt." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/001.jpg"></picture><figcaption>The title slide of the talk. It features a hot air balloon breaking into a shipping container with a crowbar. Art by Annie Rugyt.</figcaption></figure>
<p>Hi, I'm Xe Iaso and today I'm gonna get to talk with you about one of my favourite tools: Nix. Nix is many things, but my super hot take is that it's a much better Docker image builder than Docker's image builder.</p>
<p>As many of you know, Nix is a tool that makes it easy to build packages based on the instructions you give it using its little domain-specific language. For reasons which are an exercise to the listener, this language is also called Nix.</p>
<p>A Nix package can be just about anything, but usually you'll see Nix being used to build software packages, your own custom python tooling, OS hard drive image, or container images.</p>
<p>If you've never used it before, Nix is gonna seem a bit weird. It's going to feel like you're doing a lot of work up front, and that's because at some level it is. You're doing work today that you would have done in a few months anyways. I'll get into more detail about this as the talk goes on.</p>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/005.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/005.webp"><img alt="Slide 2024/nix-docker-builder/005" loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/005.jpg"></picture></figure>
<p>As I said, I'm Xe Iaso. I'm the Senior Technophilosopher at Fly.io where I do developer relations. My friends and loved ones can attest that I have a slight tendency to write on my blog. I've been using Nix and NixOS across all of my personal and professional projects for the last four years. I live in Ottawa with my husband.</p>
<p>It's the morning and I know we're all waiting for that precious bean juice to kick in. Let's get that blood pumping with a little exercise. If you've read my blog before, can you raise your hand?</p>
<p>(Ad-lib on the number of hands raised)</p>
<p>Okay, that's good. Raise your hand if this is your first introduction to Nix or NixOS.</p>
<p>(Ad-lib again)</p>
<p>How about if you're a Nix or NixOS expert? Raise your hand if you'd call yourself a Nix or NixOS expert.</p>
<p>(Ad-lib again)</p>
<p>Finally, Raise your hand if you got into Nix or NixOS because of my blog.</p>
<p>(Ad-lib again)</p>
<p>Alright thanks, you can lower your hands now.</p>
<p>This talk is a bit more introductory. There's a mixed audience here of people that are gonna be more hardcore Nix users and people that have probably never heard of Nix before. I want this talk to be a bridge so that those of you who are brand new to Nix can understand what it's about and why you should care. For those of you who have ascended the mortal plane with NixOS powers, maybe this can help you realize where we're needed most. Today I'm gonna cover what Nix is, why it's better than Docker at making Docker images, and some neat second-order properties of Nix that makes it so much more efficient in the long run.</p>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/008.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/008.webp"><img alt="The holy trinity of Nix, showing that Nix the language, the package manager, and the OS are different facets of the same thing." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/008.jpg"></picture><figcaption>The holy trinity of Nix, showing that Nix the language, the package manager, and the OS are different facets of the same thing.</figcaption></figure>
<p>Nix is just a package manager, right? Well, it's a bit more. It's a package manager, a language, and an operating system. It's kind of a weird balance because they all have the name "Nix", but you can use this handy diagram to split the differences. You use Nix the language to make Nix the package manager build packages. Those packages can be anything from software to entire NixOS images.</p>
<p>This is compounded by the difficulty of adopting Nix at work if you have anything but a brand new startup or homelab that's willing to burn down everything and start anew with Nix. Nix is really different than what most developers are used to, which makes it difficult to cram into existing battle-worn CI/CD pipelines.</p>
<p>This is not sustainable. I'm afraid that if there's not a bridge like this, Nix will wilt and die because of the lack of adoption.</p>
<p>I want to show you how to take advantage of Nix today somewhere that it's desperately needed: building and deploying container images.</p>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/012.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/012.webp"><img alt="The docker logo on a sky background." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/012.jpg"></picture><figcaption>The docker logo on a sky background.</figcaption></figure>
<p>To say that Docker won would be an understatement. My career started just about the same time that Docker left public beta. Docker and containerization has been adopted so widely that I'd say that Docker containers have become the de-facto universal package format of the Internet. Modern platforms like Fly.io, Railway, and Render could let people run arbitrary VM images or Linux programs in tarball slugs, but they use Docker images because that works out better for everyone.</p>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/013.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/013.webp"><img alt="The docker logo with a badly photoshopped muscle-bound beefy arm on a sky background." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/013.jpg"></picture><figcaption>The docker logo with a badly photoshopped muscle-bound beefy arm on a sky background.</figcaption></figure>
<p>This gives people a lot of infrastructure superpowers and the advantages make the thing sell itself. It's popular for a reason. It solves real-world problems that previously required complicated cross-team coordination. No more arguing with your sysadmin or SRE team over upgrading your local fork of Ubuntu to chase the dragon with package dependencies!</p>
<p>However, there's just one fatal flaw:</p>
<p>Docker builds are not deterministic. Not even slightly. Sure, the average docker file you find on the internet will build 99.99% of the time, but that last 0.01% is where the real issues come into play.</p>
<p>Speaking as a former wielder of the SRE shouting pager, that last 0.01% of problems ends up coming into play at 4am. Always 4am, never while you are at work.</p>
<div><p><img alt="Cadey is coffee" loading="lazy" src="https://cdn.xeiaso.net/sticker/cadey/coffee/64"></p><div><p>&lt;<a href="https://xeiaso.net/characters#cadey"><b>Cadey</b></a>&gt; </p><p>Ask me how I know.</p></div></div>
<p>One of the biggest problems that doesn't sound like a problem at first is that Docker builds have access to the public Internet. This is needed to download packages from the Ubuntu repositories, but that also means that it's hard to go back and recreate the exact state of the Ubuntu repositories when you inevitably need to recreate an image at a future date.</p>
<p>Remember, Ubuntu 18.04 is going out of support this year! You're going to have a flag day finding out what depends on that version of Ubuntu when things break and not any sooner.</p>
<p>Even more fun, adding packages to a docker image the naïve way means that you get wasted space. If you run <code>apt-get upgrade</code> at the beginning of your docker build, you can end up replacing files in the container image. Those extra files end up being some "wasted space" shadow copies that will add up over time, especially with AWS charging you per millibyte of disk space and network transfer or whatever.</p>
<div><p><img alt="Aoi is wut" loading="lazy" src="https://cdn.xeiaso.net/sticker/aoi/wut/64"></p><div><p>&lt;<a href="https://xeiaso.net/characters#aoi"><b>Aoi</b></a>&gt; </p><p>What if we had the ability to know all of the dependencies that are needed
ahead of time and then just use those? What if your builds didn't need an
internet connection at all?</p></div></div>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/021.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/021.webp"><img alt="The Nix/NixOS logo on a purple and black gradient background." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/021.jpg"></picture><figcaption>The Nix/NixOS logo on a purple and black gradient background.</figcaption></figure>
<p>This is the real advantage of Nix when compared to docker builds. Nix lets you know exactly what you're depending on ahead of time and then can break that into the fewest docker layers possible. This means that pushing updates to your programs only means that the minimal number of changes are actually made. You don't need to wait for apt or npm to install your dependencies yet again just to change a single line of code in your service.</p>
<p>I think one of the best ways to adopt it is to use it to build docker images. This helps you bridge the gap so that you can experiment with new tools without breaking too much of your existing workflows.</p>
<p>As an example, let's say I have a Go program that gives you quotes from Douglas Adams. I want to deploy it to a platform that only takes Docker images, like Fly.io, Railway, or Google Cloud Functions.</p>
<p>In order to do this, I'd need to do a few things: First, I'd need to build the program into a package with Nix and make sure it works. Then I'd need to turn that into a docker image, load it into my docker daemon, and push it to their registry. Finally I can deploy my application and everyone can benefit from the wisdom of days gone past.</p>
<p>Here's what that package definition looks like in my project's Nix flake. Let's break this down into parts.</p>
<pre><code><span>bin <span>=</span> pkgs<span>.</span>buildGoModule <span>{</span>
</span><span>  pname <span>=</span> <span>"douglas-adams-quotes"</span><span>;</span>
</span><span>  <span>inherit</span> version<span>;</span>
</span><span>  src <span>=</span> <span>./.</span><span>;</span>
</span><span>  vendorHash <span>=</span> <span>null</span><span>;</span>
</span><span><span>}</span><span>;</span>
</span></code></pre>
<p>This project is in a Go module, so <code>pkgs.buildGoModule</code> tells Nix to use the Go module template. That template will set everything up for us: mainly the Go compiler, a C compiler for CGo code, and downloading any external dependencies for you.</p>
<p>Here are the arguments to the <code>buildGoModule</code> function: a package name, the version, the path to the source code, and the hash of the external dependencies.</p>
<p>The name of the package is "Douglas Adams Quotes" in kebab case, the version is automagically generated from the git commit of the service, the source code is in the current working directory, and I don't need anything beyond Go's standard library. If you need external dependencies, you can specify the hash of all the dependencies here or use <a href="https://github.com/nix-community/gomod2nix"><code>gomod2nix</code></a> to automate this (it's linked in the description at the end of the talk).</p>
<pre><code><span># nix build .#bin
</span></code></pre>
<p>Now that we have a package definition, you can build it with nix build dot hash bin. That makes Nix build the bin package in your flake and put the result in dot slash result.</p>
<p>Next comes building that into a Docker image with the dockerTools family of helpers. dockerTools lets you take that Nix package you just made and put it and all its dependencies into a Docker image so you can deploy it.</p>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/031.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/031.webp"><img alt="An onion and an onion with an X over it. An onion is a visual metaphor for layered Docker images." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/031.jpg"></picture><figcaption>An onion and an onion with an X over it. An onion is a visual metaphor for layered Docker images.</figcaption></figure>
<p>There's two basic ways to use it, making a layered image and a non-layered image.</p>
<p>A non-layered image is the simplest way to use Nix to build a docker image. It takes the program, its dependencies, any additional things like TLS root certificates and puts it all into a folder to be exposed as a single-layer docker image.</p>
<p>This works, but it doesn't really let us take advantage of the benefits of Nix. Making any change to a non-layered image means you have to push all of the things that haven't changed. Nix knows what all your dependencies are, so it should be able to take advantage of that when building a container image. Why should you have to upload new copies of glibc and the python interpreter over and over?</p>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/034.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/034.webp"><img alt="An onion pointing to a bunch of folders with Nix packages in its layers." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/034.jpg"></picture><figcaption>An onion pointing to a bunch of folders with Nix packages in its layers.</figcaption></figure>
<p>Nix also lets you make a layered image. A layered image puts every dependency into its own image layer so you only upload the parts of your image that have actually changed. Made an update to the webp library to fix a trivial bounds checking vulnerability because nobody writes those libraries in memory-safe languages? The only thing that'd need to be uploaded is that single webp library layer.</p>
<p>The reason why this works is that there's a dirty secret deep into Docker that nobody can really take advantage of: Docker has a content-aware store baked into the heart of it, but because <code>docker build</code> isn't made with it in mind, nothing is really able to take advantage of it.</p>
<p>Except Nix! A layered image means that every package is in its own layer, so glibc only needs to get uploaded once...</p>
<div><p><img alt="Cadey is coffee" loading="lazy" src="https://cdn.xeiaso.net/sticker/cadey/coffee/64"></p><div><p>&lt;<a href="https://xeiaso.net/characters#cadey"><b>Cadey</b></a>&gt; </p><p>...until we find yet another trivial memory safety vulnerability in glibc
that's been ignored for my entire time on this planet and need to have a fire
day rebuilding everything to cope.</p></div></div>
<p>Here's what a layered docker image build for that Douglas Adams quotes service would look like:</p>
<pre><code><span>docker <span>=</span> pkgs<span>.</span>dockerTools<span>.</span>buildLayeredImage <span>{</span>
</span><span>  name <span>=</span> <span>"registry.fly.io/douglas-adams-quotes"</span><span>;</span>
</span><span>  tag <span>=</span> <span>"latest"</span><span>;</span>
</span><span>  config<span>.</span>Cmd <span>=</span> <span>"<span><span>$</span><span>{</span>bin<span>}</span></span>/bin/douglas-adams-quotes"</span><span>;</span>
</span><span><span>}</span><span>;</span>
</span></code></pre>
<p>Again, let's break it down.</p>
<p>You start by saying that you want to build a layered image by calling the <code>dockerTools.buildLayeredImage</code> function with the image name and tag, just like you would with <code>docker build</code>. Now comes the fun part: the rest of the container image.</p>
<pre><code><span>config<span>.</span>Cmd <span>=</span> <span>"<span><span>$</span><span>{</span>bin<span>}</span></span>/bin/douglas-adams-quotes"</span><span>;</span>
</span></code></pre>
<p>Just tell Nix that the container should run the built version of the Douglas Adams quotes server and bam, everything'll be copied over for you. Glibc will make it over as well as whatever detritus you need to make Glibc happy these days.</p>
<p>If you need to add something like the CA certificate root, you can specify it with the <code>contents</code> argument. You can use this to add any package from nixpkgs into your image. My website uses this to add Typst, Deno, and Dhall tools to the container.</p>
<pre><code><span>docker <span>=</span> pkgs<span>.</span>dockerTools<span>.</span>buildLayeredImage <span>{</span>
</span><span>  name <span>=</span> <span>"registry.fly.io/douglas-adams-quotes"</span><span>;</span>
</span><span>  tag <span>=</span> <span>"latest"</span><span>;</span>
</span><span>  contents <span>=</span> <span>with</span> pkgs<span>;</span> <span>[</span> cacert <span>]</span><span>;</span> <span># &lt;--</span>
</span><span>  config<span>.</span>Cmd <span>=</span> <span>"<span><span>$</span><span>{</span>bin<span>}</span></span>/bin/douglas-adams-quotes"</span><span>;</span>
</span><span><span>}</span><span>;</span>
</span></code></pre>
<p>Then you type in <code>nix build .#docker</code> and whack enter. A shiny new image will show up in <code>./result</code>.</p>
<pre><code><span>nix build .#docker
</span></code></pre>
<p>Load it using <code>docker load &lt; ./result</code> and it'll be ready for deployment.</p>
<pre><code><span>docker load &lt; ./result
</span></code></pre>
<p>TODO: embed video</p>
<p>Opening the image in <code>dive</code>, we see that every layer adds another package from nixpkgs until you get to the end where it all gets tied together and any contents are symlinked to the root of the image.</p>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/045.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/045.webp"><img alt="A successful slide with a lot of cheery imagery." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/045.jpg"></picture><figcaption>A successful slide with a lot of cheery imagery.</figcaption></figure>
<p>And that's it! All that's left is to deploy it to the cloud and find out if you just broke production. It should be fine, right?</p>
<p>The really cool part is that this will work for the cases where you have single images exposed from a code repository, but that content-aware hackery doesn't end at making just one of your services faster to upload.</p>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/050.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/050.webp"><img alt="A diagram showing several programs sharing the same layers." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/050.jpg"></picture><figcaption>A diagram showing several programs sharing the same layers.</figcaption></figure>
<p>If you have multiple services in the same repository, they'll share docker layers between each other. For free. Without any extra configuration. I don't think you can even dream of doing this with Docker without making a bunch of common base images that have a bunch of tools and bloat that some of your services will never make use of.</p>
<p>As a practical example, I have a repo I call <a href="https://github.com/Xe/x">"x"</a>. It's full of a decade's worth of side projects, experiments, and tools that help me explore various bits of technology. It's also a monorepo for a bunch of other projects:</p>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/049.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/049.webp"><img alt="A diagram showing several programs sharing the same layers." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/049.jpg"></picture><figcaption>A diagram showing several programs sharing the same layers.</figcaption></figure>
<p>This is a lot of stuff and I don't expect anyone to read that, so I made the text small enough to discourage it. Most of it is deployed across like three platforms too, but I've been slowly converging on one common deployment backbone by shoving everything into Docker images.</p>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/050.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/050.webp"><img alt="A diagram showing several programs sharing the same layers." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/050.jpg"></picture><figcaption>A diagram showing several programs sharing the same layers.</figcaption></figure>
<p>Pushing updates to any one of these services also pushes parts of the updates to most of the other ones. This saves me a lot of time and money across my plethora of projects. Take that, Managed NAT Gateway!</p>
<p>Oh no, I think I sense it, you do too right? It's the pedantry alert! Yes in theory I could take advantage of Docker caching to build the images just as efficiently as Nix, but then my build steps would have to look like this:</p>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/052.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/052.webp"><img alt="A giant depressing mess of wires." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/052.jpg"></picture><figcaption>A giant depressing mess of wires.</figcaption></figure>
<p>Sure, you can do it, but you'd end up with unmaintainable balls of mud that would have you install shared libraries into their own layers and then you risk invoking the wrath of general protection fault. Not only would you have to turn the network stack back on during builds (there goes reproducibility!), I'd have to rejigger search paths, compiler flags, CGO-related goat sacrifices and more. It'd just be a mess.</p>
<pre><code><span>docker <span>=</span> pkgs<span>.</span>dockerTools<span>.</span>buildLayeredImage <span>{</span>
</span><span>  name <span>=</span> <span>"registry.fly.io/douglas-adams-quotes"</span><span>;</span>
</span><span>  tag <span>=</span> <span>"latest"</span><span>;</span>
</span><span>  contents <span>=</span> <span>with</span> pkgs<span>;</span> <span>[</span> cacert <span>]</span><span>;</span>
</span><span>  config<span>.</span>Cmd <span>=</span> <span>"<span><span>$</span><span>{</span>bin<span>}</span></span>/bin/douglas-adams-quotes"</span><span>;</span>
</span><span><span>}</span><span>;</span>
</span></code></pre>
<p>Look at this though, it's just so much simpler. It takes the package and shoves it into a container for you so you don't need to care about the details. It's so much more beautiful in comparison.</p>
<p>Above all though, the biggest advantage Nix gives you is the ability to travel back in time and build software exactly as it was in the past. This lets you recreate a docker image exactly at a later point in the future when facts and circumstances demand because that one on-prem customer had apparently never updated their software and was experiencing a weird bug.</p>
<p>This means that in theory, when you write package builds today, you're taking from that time you would have spent in the future to recreate it. You don't just build your software though, you crystallize a point in time that describes the entire state of the world including your software to get the resulting packages and docker images.</p>
<p>I've been working on a project called <a href="https://cdn.xeiaso.net/">XeDN</a> for a few years. Here's how easy it is to build a version from 14 months ago:</p>
<pre><code><span>nix build github:Xe/x/567fdc2#xedn-docker
</span></code></pre>
<p>That's it. That's the entire command. I say that I want to build the <a href="https://github.com/Xe/x">GitHub repo Xe/x</a> at an arbitrary commit hash and get the xedn-docker target. I can then load it into my docker daemon and then I have the exact same bytes I had back then, Go 1.19 and all.</p>
<p>This party trick isn't as easy to pull off with vanilla docker builds unless you pay a lot for storage.</p>
<p>An even cooler part of that is that most of the code didn't even need to be rebuilt thanks to the fact that I upload all of my builds into a Nix cache. A Nix cache lets you put the output of Nix commands into a safe place so that they don't need to be run again in the future. This means that developer laptops don't all need to build new versions of nokogiri every time it's bumped ever so slightly. It'll already be built for you with the power of the cloud.</p>
<p>I have that uploaded into a cache through <a href="https://garnix.io/">Garnix</a>, which I use to do CI on all of my flakes projects. Garnix is effortless. Turn it on and then wait for it to report build status on every commit. It's super great because I don't have to think about it.</p>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/060.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/060.webp"><img alt="A terrible picture of my homelab." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/060.jpg"></picture><figcaption>A terrible picture of my homelab.</figcaption></figure>
<p>I even have all of my homelab machine configurations built with Garnix so that when they update every evening, they just pull the newest versions of their config from the Garnix cache instead of building it themselves. Around 7pm or so I hear them reboot after the day of a kernel upgrade. It's really great.</p>
<p>Not to mention never having to ever wait for my custom variant of Iosevka to build on my MacBook or shellbox.</p>
<p>In conclusion:</p>
<ul>
<li>Nix is a better docker image builder than docker's image builder.</li>
<li>Nix makes you specify the results, not the steps you take to get there.</li>
<li>Building Docker images with Nix makes adopting Nix easy if you already use Docker.</li>
<li>Nix makes docker images that share layers between parts of your monorepo.</li>
<li>Nix lets you avoid building code that was built in the past thanks to binary caches.</li>
<li>And you end up with normal, ordinary container images that you can deploy anywhere. Even platforms like AWS, Google Cloud, or Fly.io.</li>
</ul>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/068.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/068.webp"><img alt="A slide listing everyone I have to thank for the talk." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/068.jpg"></picture><figcaption>A slide listing everyone I have to thank for the talk.</figcaption></figure>
<p>Before I get all of this wrapped up, I want to thank everyone on this list for their input, feedback, and more to help this talk shine. Thank you so much!</p>
<figure><picture><source type="image/avif" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/069.avif"><source type="image/webp" srcset="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/069.webp"><img alt="A conclusion slide showing information about me and the link to this page." loading="lazy" src="https://cdn.xeiaso.net/file/christine-static/talks/2024/nix-docker-builder/069.jpg"></picture><figcaption>A conclusion slide showing information about me and the link to this page.</figcaption></figure>
<p>And thank you for watching! I've been Xe Iaso and I'm gonna linger around afterwards for questions. If I don't get to you and you really want a question answered, please email <a href="mailto:dockerimage@xeserv.us">dockerimage@xeserv.us</a>. I promise I'll get back to you as soon as possible.</p>
<p>If you want to work with me to make developer relations better, my employer Fly.io is hiring. Catch up with me if you want stickers!</p>
<p>I have some extra information linked at the QR code on screen. This includes the source code for the Douglas Adams quotes server so you can clone it on your laptop and play around with it.</p>
<p>Be well, all.</p>

    <hr>

    

    

    <p>Facts and circumstances may have changed since publication. Please contact me before jumping to conclusions if something seems wrong or unclear.</p>

    <p>Tags: </p>

    <a href="">View slides</a>
</article>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing whistleblower before death: "If anything happens, it's not suicide" (191 pts)]]></title>
            <link>https://futurism.com/the-byte/boeing-whistleblower-warning-not-suicide</link>
            <guid>39718672</guid>
            <pubDate>Fri, 15 Mar 2024 17:55:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://futurism.com/the-byte/boeing-whistleblower-warning-not-suicide">https://futurism.com/the-byte/boeing-whistleblower-warning-not-suicide</a>, See on <a href="https://news.ycombinator.com/item?id=39718672">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="incArticle"><h2>"I know that he did not commit suicide."</h2><h2>Curious Causes</h2><p>As Boeing continues <a href="https://futurism.com/the-byte/jet-tire-falls-off">to be in the news</a> for its <a href="https://futurism.com/the-byte/plane-wing-breaking-footage">repeatedly</a> <a href="https://futurism.com/the-byte/boeing-plane-fire">malfunctioning</a> <a href="https://futurism.com/the-byte/boeing-trouble-crack-cockpit">planes</a>, the fallout from one ex-employee's death continues — and new reports complicate the coroner's initial suicide ruling.</p><p>In an <a href="https://abcnews4.com/news/local/if-anything-happens-its-not-suicide-boeing-whistleblowers-prediction-before-death-south-carolina-abc-news-4-2024">interview with Charleston, South Carolina's&nbsp;<em>ABC4 News</em></a>, a friend of Boeing whistleblower John Barnett, whose body was found dead in a car parked in a hotel lot amid his testimony against his former employer last weekend, said that he warned her that something might happen to him.</p><p>"I said, 'Aren't you scared?'" the woman, who gave only her first name Jennifer, told the local broadcaster. "And he said, 'No, I ain't scared, but if anything happens to me, it's not suicide.'"</p><p>Jennifer said that Barnett's words were spoken ahead of his deposition against Boeing. At the time, he'd mentioned that the company had retaliated against him for raising safety concerns before — which was, indeed, the subject of his Occupational Safety and Health Administration (OSHA) <a href="https://www.corporatecrimereporter.com/news/200/john-barnett-on-why-he-wont-fly-on-a-boeing-787-dreamliner/">complaint</a> that led to his now-unfinished deposition.</p><p>The woman, who lives in the whistleblower's home state of Louisiana where he'd moved in recent years to take care of his aging mother, said that that cryptic warning has come back to haunt her since Barnett's death, which a coroner in Charleston says was self-inflicted.</p><p>"I know that he did not commit suicide," Jennifer told <em>ABC4</em>. "There's no way. He loved life too much. He loved his family too much. He loved his brothers too much to put them through what they're going through right now."</p><h2>Hearsay</h2><p>She's not alone in that sentiment either, it seems.</p><p>In a statement to&nbsp;<em>Futurism</em>, Barnett's attorneys said that they also "<a href="https://futurism.com/boeing-whistleblowers-lawyers-statement">didn't see any indication</a>" that the whistleblower may have been planning to take his own life, and that he'd seemed in "good spirits" as his deposition was coming to a close.</p><p>Not everyone close to the longtime Boeing quality control manager agrees with that sentiment, however.</p><p>In an <a href="https://www.seattletimes.com/business/boeing-787-whistleblower-found-dead-in-apparent-suicide/">interview with the&nbsp;<em>Seattles Times</em></a>, Barnett's niece, Katelyn Gillespie, said that her "fun uncle" had become "stressed and depressed" in recent months as his ex-employer was in the news amid the same kinds of safety concerns he'd raised and ultimately resigned over.</p><p>"He battled a lot due to the Boeing stuff," the whistleblower's niece said. "It took a major toll on him."</p><p>Despite the Charleston County coroner's preliminary autopsy report on the cause of death being a self-inflicted gunshot wound and that local police found, <a href="https://www.live5news.com/2024/03/12/brave-honest-man-boeing-whistleblowers-attorneys-release-statement-his-death/">per the city's <em>Live 5 News</em></a>, "some sort of note," authorities said they are still actively investigating the case while awaiting an official coroner's ruling.</p><p>As in other <a href="https://www.theguardian.com/politics/2013/jul/16/david-kelly-death-10-years-on">suspicious</a> <a href="https://www.cbsnews.com/sacramento/news/dhs-whistleblower-philip-haney-death-ruled-suicide/">whistleblower</a> <a href="https://foreignpolicy.com/2022/05/17/robert-mcfarlane-death-national-security-advisor-iran-contra/">suicides</a>, it's almost impossible for anyone to know exactly what happened when Barnett died — but with this new claim from someone close to Barnett, things just got a lot more complicated.</p><p><strong>More on Boeing:</strong> <a href="https://futurism.com/the-byte/pilot-boeing-gauges-nosedive"><em>Pilot Lost Control of Boeing Jet Because Gauges “Went Blank," Causing Nosedive</em></a></p><br></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ollama now supports AMD graphics cards (483 pts)]]></title>
            <link>https://ollama.com/blog/amd-preview</link>
            <guid>39718558</guid>
            <pubDate>Fri, 15 Mar 2024 17:47:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ollama.com/blog/amd-preview">https://ollama.com/blog/amd-preview</a>, See on <a href="https://news.ycombinator.com/item?id=39718558">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <h2>March 14, 2024</h2>
      <section>
        <p><a href="https://ollama.com/download"><img src="https://ollama.com/public/blog/amd-preview.png" alt="Ollama AMD"></a></p>

<p>Ollama now supports AMD graphics cards in preview on Windows and Linux. All the features of Ollama can now be accelerated by AMD graphics cards on Ollama for <a href="https://ollama.com/download/linux">Linux</a> and <a href="https://ollama.com/download/windows">Windows</a>.</p>

<video autoplay="" controls="">
  <source src="https://github.com/ollama/ollama/assets/3325447/671a8031-1915-448e-b033-16b367b359d9" type="video/mp4">
</video>

<h2>Supported graphics cards</h2>

<table>
<thead>
<tr>
<th>Family</th>
<th>Supported cards and accelerators</th>
</tr>
</thead>

<tbody>
<tr>
<td>AMD Radeon RX</td>
<td><code>7900 XTX</code> <code>7900 XT</code> <code>7900 GRE</code> <code>7800 XT</code> <code>7700 XT</code> <code>7600 XT</code> <code>7600</code> <br><code>6950 XT</code> <code>6900 XTX</code> <code>6900XT</code> <code>6800 XT</code> <code>6800</code><br><code>Vega 64</code> <code>Vega 56</code></td>
</tr>

<tr>
<td>AMD Radeon PRO</td>
<td><code>W7900</code> <code>W7800</code> <code>W7700</code> <code>W7600</code> <code>W7500</code> <br><code>W6900X</code> <code>W6800X Duo</code> <code>W6800X</code> <code>W6800</code><br><code>V620</code> <code>V420</code> <code>V340</code> <code>V320</code><br><code>Vega II Duo</code> <code>Vega II</code> <code>VII</code> <code>SSG</code></td>
</tr>

<tr>
<td>AMD Instinct</td>
<td><code>MI300X</code> <code>MI300A</code> <code>MI300</code><br><code>MI250X</code> <code>MI250</code> <code>MI210</code> <code>MI200</code><br><code>MI100</code> <code>MI60</code> <code>MI50</code></td>
</tr>
</tbody>
</table>
<p>Support for more AMD graphics cards is coming soon.</p>

<h2>Get started</h2>

<p>To get started with Ollama with support for AMD graphics cards, download Ollama for <a href="https://ollama.com/download/linux">Linux</a> or <a href="https://ollama.com/download/windows">Windows</a>.</p>

      </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Compressing Chess Moves for Fun and Profit (138 pts)]]></title>
            <link>https://mbuffett.com/posts/compressing-chess-moves/</link>
            <guid>39717615</guid>
            <pubDate>Fri, 15 Mar 2024 16:35:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mbuffett.com/posts/compressing-chess-moves/">https://mbuffett.com/posts/compressing-chess-moves/</a>, See on <a href="https://news.ycombinator.com/item?id=39717615">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>Chess notation has come a long way since <a href="https://en.wikipedia.org/wiki/Descriptive_notation">descriptive
notation</a>, now we have nice
and decipherable Standard Algebraic Notation, like <code>Qxf7</code> (queen takes on
f7) or <code>Nf3</code> (knight takes on f3).</p><p>This is a great text format, but a massive waste of
space if you’re trying to store a lot of these. <code>Qxf7</code> takes 4 bytes, or 32 bits. Let’s do some rough back-of-the-envelope math of how much information is actually being transmitted though.
This move affects one of 6 pieces (3 bits), this move is also a capture (1
bit), and it specifies a destination squuare (64 possibilities == 6 bits). Add those up, you get 10 bits. Far from the 32 bits that the textual representation needs.</p><p>Why do I care? I run a site that stores a <em>ton</em> of
chess lines, something like 100 million in total. Assume an average of 6 moves for each line, that’s 600 million moves. The database is growing large
enough that querying it is IO-constrained. I want to speed up the reads from this database when I’m fetching thousands of lines.</p><h2 id="a-first-pass">A first pass</h2><p>First some general numbers:</p><ul><li>Encoding a file or rank (a-h or 1-8) takes 3 bits (8 possibilities)</li><li>Encoding a piece (k, q, r, b, n, p) takes 3 bits (6 possibilities)</li><li>Encoding a square takes 6 bits (64 possibilities)</li></ul><p>So let’s see the pieces we’re working with for encoding a SAN.</p><p>So let’s go with the most naive approach.</p><ul><li>Which piece was it? 3 bits</li><li>Is it a capture? 1 bit</li><li>Do we have to disabiguate it (ie <code>Ngf3</code>)? Maximum of 2 bits + 6 bits (this is explained more further down)</li><li>Where did it go? 6 bits</li><li>Is it a promotion, and to which piece? 7 bits</li><li>Is it a check? 1 bit</li><li>Is it a checkmate? 1 bit</li><li>Is it a castle? Short or long? 2 bits</li></ul><p>This gives us a total of <code>3+1+2+6+6+7+1+1+2 = 29</code> bits, or about 3.5 bytes per move. That’s not great though. A lot of moves actually take up less bits than that in text format.</p><h2 id="getting-smarter">Getting smarter</h2><h3 id="the-first-few-bits">The first few bits</h3><p>In the first pass, we just encoded the piece that moved using 3 bits, but that
leaves 2 unused permutations available, since there are only 6 pieces in chess.
Luckily, there are two very common moves that fit neatly into this hole, those
being short castles (<code>O-O</code>) and long castles (<code>O-O-O</code>).</p><p>So we can encode the first 3 bits like so:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>match</span> first_bytes {
</span></span><span><span>    FirstBytes::Pawn <span>=&gt;</span> bits.extend(<span>&amp;</span>[<span>false</span>, <span>false</span>, <span>false</span>]),
</span></span><span><span>    FirstBytes::Knight <span>=&gt;</span> bits.extend(<span>&amp;</span>[<span>false</span>, <span>false</span>, <span>true</span>]),
</span></span><span><span>    FirstBytes::Bishop <span>=&gt;</span> bits.extend(<span>&amp;</span>[<span>false</span>, <span>true</span>, <span>false</span>]),
</span></span><span><span>    FirstBytes::Rook <span>=&gt;</span> bits.extend(<span>&amp;</span>[<span>false</span>, <span>true</span>, <span>true</span>]),
</span></span><span><span>    FirstBytes::Queen <span>=&gt;</span> bits.extend(<span>&amp;</span>[<span>true</span>, <span>false</span>, <span>false</span>]),
</span></span><span><span>    FirstBytes::King <span>=&gt;</span> bits.extend(<span>&amp;</span>[<span>true</span>, <span>false</span>, <span>true</span>]),
</span></span><span><span>    FirstBytes::ShortCastling <span>=&gt;</span> bits.extend(<span>&amp;</span>[<span>true</span>, <span>true</span>, <span>false</span>]),
</span></span><span><span>    FirstBytes::LongCastling <span>=&gt;</span> bits.extend(<span>&amp;</span>[<span>true</span>, <span>true</span>, <span>true</span>]),
</span></span><span><span>}
</span></span></code></pre></div><h3 id="the-destination-square">The destination square</h3><p>In all cases except castling, you need to know the square that the piece is moving to, to reproduce the SAN. So we’ll skip this entirely when castling, but otherwise always include 6 bits for the destination square.</p><h4 id="just-kidding-pawn-moves">Just kidding, pawn moves!</h4><p>There’s another exception to the destination square rule that might not seem so
obvious. Let’s take the move <code>exf6</code>. We know it’s a pawn move from the e-file,
so we don’t really need to encode the file it’s capturing using 6 bits. After
all, you’ll never see <code>exa6</code>. So in these cases instead of 6 bits for the
destination square, we only need 4 (one for the direction, and one for the
rank).</p><p>But we can get even more clever here. Take <code>hxg6</code> for example. You know as soon as you see <code>hx</code>, that the file is going to be the g-file. So we don’t even need the extra bit to encode direction, we can just encode the file once, and the rank once.</p><p>So here’s the setup:</p><ul><li>Pawn capture from b-g files: 3 bits for the file you’re capturing from, 1 bit for the direction of the capture, and 3 bits for the rank<ul><li>Total: 10 bits for movement</li></ul></li><li>Pawn capture from a and h files: 3 bits for the file you’re capturing from, 3 bits for rank<ul><li>Total: 6 bits for movement</li></ul></li></ul><h3 id="special-moves">“Special” moves</h3><p>It’s a bit of a waste to encode for each move, whether it’s a promotion, check,
checkmate, capture, etc. After all, the vast majority of chess moves in a game are not any of these.</p><p>So we’ll devote one bit to determining whether a move is “special”. It means we
have to use an extra bit for moves that are promotions/checks/captures, but it
also means that we save a whole lot of bits for “regular” moves.</p><h3 id="promotions">Promotions</h3><p>Promotions are nice, because even though there are 6 chess pieces, there are
only 4 valid pieces that you can promote to (after all, you can’t promote to a
King or Pawn). So we only need 2 bits instead of 3, to encode the promotion
piece.</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>if</span> <span>let</span> Some(promotion) <span>=</span> promotion {
</span></span><span><span>    bits.push(<span>true</span>);
</span></span><span><span>    bits.extend(<span>match</span> promotion {
</span></span><span><span>        PromotionPiece::Queen <span>=&gt;</span> <span>&amp;</span>[<span>false</span>, <span>false</span>],
</span></span><span><span>        PromotionPiece::Rook <span>=&gt;</span> <span>&amp;</span>[<span>false</span>, <span>true</span>],
</span></span><span><span>        PromotionPiece::Bishop <span>=&gt;</span> <span>&amp;</span>[<span>true</span>, <span>false</span>],
</span></span><span><span>        PromotionPiece::Knight <span>=&gt;</span> <span>&amp;</span>[<span>true</span>, <span>true</span>],
</span></span><span><span>    });
</span></span><span><span>} <span>else</span> {
</span></span><span><span>    bits.push(<span>false</span>);
</span></span><span><span>}
</span></span></code></pre></div><h3 id="disambiguation">Disambiguation</h3><p>Disambiguation is a bit thorny. You have to encode a surprising amount of information, to be able to decode the SAN exactly as you received it.</p><p>Take <code>Ngf3</code> for example. Besides the usual stuff you also need to encode the
disambiguation (file=g). There are 3 different disambiguation possibilities (rank, file, or whole square), so
we need 2 bits. One goes to waste but disambiguated moves aren’t that common
and I can’t think of a nice way to take advantage of that last permutation.</p><p>So we always use 2 bits, then either 3 bits for the rank, 3 bits for the file, or 6 bits for a whole square (very rare).</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>if</span> <span>let</span> Some(disambiguate) <span>=</span> disambiguate {
</span></span><span><span>    bits.push(<span>true</span>);
</span></span><span><span>    <span>match</span> disambiguate {
</span></span><span><span>        Disambiguation::File(file) <span>=&gt;</span> {
</span></span><span><span>            bits.extend(<span>&amp;</span>[<span>false</span>, <span>true</span>]);
</span></span><span><span>            bits.extend(square_component_to_bits(file));
</span></span><span><span>        }
</span></span><span><span>        Disambiguation::Rank(rank) <span>=&gt;</span> {
</span></span><span><span>            bits.extend(<span>&amp;</span>[<span>true</span>, <span>false</span>]);
</span></span><span><span>            bits.extend(square_component_to_bits(rank));
</span></span><span><span>        }
</span></span><span><span>        Disambiguation::Square(square) <span>=&gt;</span> {
</span></span><span><span>            bits.extend(<span>&amp;</span>[<span>true</span>, <span>true</span>]);
</span></span><span><span>            bits.extend(square_component_to_bits(square.<span>0</span>));
</span></span><span><span>            bits.extend(square_component_to_bits(square.<span>1</span>));
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>} <span>else</span> {
</span></span><span><span>    bits.push(<span>false</span>);
</span></span><span><span>}
</span></span></code></pre></div><h2 id="how-does-this-do">How does this do?</h2><table><thead><tr><th>Move</th><th>Original bits</th><th>Encoded bits</th><th>Savings</th></tr></thead><tbody><tr><td>e4</td><td>16</td><td>10</td><td>37.5%</td></tr><tr><td>exd5</td><td>32</td><td>12</td><td>62.5%</td></tr><tr><td>Nf3+</td><td>24</td><td>10</td><td>58.33%</td></tr><tr><td>Qxa5+</td><td>40</td><td>16</td><td>60%</td></tr><tr><td>cxd8=Q#</td><td>56</td><td>16</td><td>71.43%</td></tr></tbody></table><p>Not bad! We’re saving anywhere from 37.5% to 71.43% of the bits.</p><h2 id="pgns">PGNs</h2><p>You may be thinking something like this: “Isn’t is sorta cheating to measure these in bits? Since you can only address one byte at a time, needing 10 bits for a move is virtually the same as 16 bits”</p><p>Well yes, that’s true and means that we get less savings when storing individual SANs. But they don’t account for the majority of what I’m storing, which are PGNs.</p><p>PGNs are a way to store lines or games, and they look something like this:</p><pre tabindex="0"><code>1.e4 d5 2.exd5 Nf6 3.d4 Bg4 4.Be2 Bxe2 5.Nxe2 Qxd5 6.O-O Nc6 7.c3 O-O-O 8.Qb3 Qh5 9.Nf4 Qh4 10.Qxf7 Ng4 11.h3 Nf6 12.Be3 e6 13.Qxe6+ Kb8 14.Nd2 Bd6 15.g3 Qh6 16.Qf5 Ne7 17.Qa5 b6 18.Qa6 Bxf4 19.Bxf4 Qxh3 20.Nf3 Ned5 21.Be5 Qh5 22.Kg2 Qg6 23.Rae1 Nh5 24.Nh4 Nhf4+ 25.Bxf4 Nxf4+ 26.Kh2 b5 27.Qxg6 hxg6 28.gxf4 Rxh4+ 29.Kg3 Rdh8 30.Re5 Rh3+ 31.Kg4 R8h4+ 32.Kg5 Rh5+ 33.Kxg6 Rh6+ 34.Kf7 Rh7 35.Rxb5+ Kc8 36.Rg5 g6+ 37.Kxg6 R3h6+ 38.Kf5 Rf7+ 39.Kg4 Rhf6 40.f5 Kd7 41.Re1 Kd6 42.Re8 Kd7 43.Ra8 Rh6 44.Rxa7 Rfh7 45.Kf4 Rh4+ 46.Rg4 Rh2 47.f3 Rxb2 48.f6 Rf7 49.Rg7 Ke6 50.Rxf7 Kxf7 51.Rxc7+ Kxf6 52.a4 Ra2 53.Rc4 Ra3 54.d5 Ke7 55.Ke5 Kd7 56.f4 Ra2 57.Kd4 Rd2+ 58.Kc5 Ra2 59.Kb5 Kd6 60.Rd4 Rb2+ 61.Ka6 Ra2 62.a5 Kc5 63.d6 Ra3 64.d7 Kc6 65.d8=Q Rxa5+ 66.Kxa5 Kc5 67.Qc7#
</code></pre><p>This PGN is 759 bytes. There’s a ton of wasted space though. One byte between each move (the space). Then <strong>at least 3 bytes</strong> between full moves (<code> 2.</code>). This is sort of crazy, and if we combine our SAN encoding, we can compress this to be way smaller.</p><p>If we encode the whole PGN using our SAN encoding, with no space between moves because we know once we’ve reached the end of a move, we can compress this specific 759-byte PGN down to <strong>195 bytes</strong>, for a savings of <strong>74%</strong>.</p><h2 id="impact">Impact</h2><p>This hasn’t been deployed yet, I’m working on a ton of other performance
improvements. But I anticipate this along with EPD compression (which I may
write another at article on) will reduce the size of the database by about 70%.
We’re almost entierly read-constrained, which should mean a 3x speedup for the
most expensive queries we run.</p><h2 id="speed">Speed</h2><p>Another consideration here is the speed of doing this encoding/decoding; will
it just cancel out the gains from having a much smaller database? Turns out,
computers are really fast at this stuff, and conversion to and from this
encoding is a rounding error.</p><p>I’m using Rust + the <code>bitvec</code> library. Encoding and then decoding 1000 moves
takes about 600,000ns, or 0.6ms. I haven’t taken a performance pass at all
either, and there’s a few places I know are very inefficient. I’m guessing I’m
not even within 10x of optimal, but it should be good enough.</p></div></article><div><p>Thanks for reading! If you have any questions, comments, or just want to say hi,
please email me at <a href="mailto:me@mbuffett.com">me@mbuffett.com</a>. I'm not
very active <a href="https://twitter.com/MarcusBuffett">on twitter</a>,
but you can choose to follow me in case that changes.</p><p>If you're into chess, I've made a <a href="https://chessbook.com/">repertoire builder</a>. It uses statistics from
hundreds of millions of games at your level to find the gaps in your
repertoire, and uses spaced repetition to quiz you on them.</p><p>Samar Haroon, my girlfriend, has started a podcast where she talks about the
South Asian community, from the perspective of a psychotherapist.
<a href="https://open.spotify.com/show/7teSzaHt5I3r9s5PPLZFrF?si=J1-h-uFCTLyXGPbZnYSIGQ" target="_blank">Go check it out!</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FTC and DOJ want to free McDonald's ice cream machines from DMCA repair rules (252 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/03/ftc-and-doj-want-to-free-mcdonalds-ice-cream-machines-from-dmca-repair-rules/</link>
            <guid>39717558</guid>
            <pubDate>Fri, 15 Mar 2024 16:30:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/03/ftc-and-doj-want-to-free-mcdonalds-ice-cream-machines-from-dmca-repair-rules/">https://arstechnica.com/tech-policy/2024/03/ftc-and-doj-want-to-free-mcdonalds-ice-cream-machines-from-dmca-repair-rules/</a>, See on <a href="https://news.ycombinator.com/item?id=39717558">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      I scream, you scream, we all scream for 1201(c)3 exemptions    —
</h4>
            
            <h2 itemprop="description">McFlurries are a notable part of petition for commercial and industrial repairs.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/03/ice_cream_fix-800x536.jpg" alt="Taylor ice cream machine, with churning spindle removed by hand.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/03/ice_cream_fix-scaled.jpg" data-height="1714" data-width="2560">Enlarge</a> <span>/</span> Taylor's C709 Soft Serve Freezer isn't so much mechanically complicated as it is a software and diagnostic trap for anyone without authorized access.</p></figcaption>  </figure>

  




<!-- cache hit 149:single/related:70bb8fbbd06d2f1057c24bd5f3501ac0 --><!-- empty -->
<p>Many devices have been made difficult or financially nonviable to repair, whether by design or because of a lack of parts, manuals, or specialty tools. Machines that make ice cream, however, seem to have a special place in the hearts of lawmakers. Those machines are often broken and locked down for only the most profitable repairs.</p>
<p>The Federal Trade Commission and the antitrust division of the Department of Justice have <a href="https://www.ftc.gov/system/files/ftc_gov/pdf/ATR-FTC-JointComment.pdf">asked the US Copyright Office</a> (PDF) to exempt "commercial soft serve machines" from the anti-circumvention rules of <a href="https://www.copyright.gov/1201/2018/">Section 1201</a> of the Digital Millennium Copyright Act (DMCA). The governing bodies also submitted proprietary diagnostic kits, programmable logic controllers, and enterprise IT devices for DMCA exemptions.</p>
<p>"In each case, an exemption would give users more choices for third-party and self-repair and would likely lead to cost savings and a better return on investment in commercial and industrial equipment," the joint comment states. Those markets would also see greater competition in the repair market, and companies would be prevented from using DMCA laws to enforce monopolies on repair, according to the comment.</p>
<p>The joint comment builds upon a petition filed by repair vendor and advocate iFixit and interest group Public Knowledge, which advocated for broad reforms while keeping a relatable, ingestible example at its center. McDonald's soft serve ice cream machines, which are <a href="https://mcbroken.com/">famously frequently broken</a>, are supplied by industrial vendor Taylor. <a href="https://publicknowledge.org/public-knowledge-petitions-copyright-office-for-dmca-exemption-for-ice-cream-machines/">Taylor's C709 Soft Serve Freezer</a> requires lengthy, finicky warm-up and cleaning cycles, produces obtuse error codes, and, perhaps not coincidentally, costs $350 per 15 minutes of service for a Taylor technician to fix. iFixit <a href="https://www.ifixit.com/News/80215/whats-inside-that-mcdonalds-ice-cream-machine-broken-copyright-law">tore down such a machine</a>, confirming the lengthy process between plugging in and soft serving.
</p><p>After one company built a Raspberry Pi-powered device, the <a href="https://www.kytch.com/landing">Kytch</a>, that could provide better diagnostics and insights, Taylor moved to ban franchisees from installing the device, then offered up its own competing product. Kytch has <a href="https://www.wired.com/story/kytch-ice-cream-machine-hackers-sue-mcdonalds-900-million/">sued Taylor for $900 million</a>&nbsp;in a case that is still pending.</p>                                            
                                                        
<p>Beyond ice cream, the petitions to the Copyright Office would provide more broad exemptions for industrial and commercial repairs that require some kind of workaround, decryption, or other software tinkering. Going past technological protection measures (TPMs) was made illegal by the 1998 DMCA, which was put in place largely because of the concerns of media firms facing what they considered rampant piracy.</p>
<p>Every three years, the Copyright Office allows for petitions to exempt certain exceptions to DMCA violations (and renew prior exemptions). Repair advocates have won exemptions for farm equipment repair, <a href="https://arstechnica.com/tech-policy/2021/10/us-copyright-office-oks-right-to-repair-for-video-game-console-optical-drives/">video game consoles</a>, cars, and certain medical gear. The exemption is often granted for device fixing if a repair person can work past its locks, but not for the distribution of tools that would make such a repair far easier. The esoteric nature of such "release valve" offerings has led groups like the EFF to <a href="https://arstechnica.com/tech-policy/2016/07/eff-sues-us-government-saying-copyright-rules-on-drm-are-unconstitutional/">push for the DMCA's abolishment</a>.</p>
<p>DMCA exemptions occur on a parallel track to <a href="https://arstechnica.com/tech-policy/2024/03/oregon-oks-right-to-repair-bill-that-bans-the-blocking-of-aftermarket-parts/">state right-to-repair bills</a> and broader federal action. President Biden issued <a href="https://arstechnica.com/tech-policy/2021/07/bidens-right-to-repair-order-could-stop-companies-from-blocking-diy-fixes/">an executive order</a> that included a push for repair reforms. The FTC has issued studies that call out <a href="https://www.ftc.gov/system/files/documents/reports/nixing-fix-ftc-report-congress-repair-restrictions/nixing_the_fix_report_final_5521_630pm-508_002.pdf">unnecessary repair restrictions</a> and has taken <a href="https://www.ftc.gov/news-events/news/press-releases/2022/10/ftc-approves-final-orders-right-repair-cases-against-harley-davidson-mwe-investments-weber">action</a> against firms like Harley-Davidson, Westinghouse, and grill maker Weber for tying warranties to an authorized repair service.</p>
<p><i>Disclosure: Kevin Purdy previously worked for iFixit. He has no financial ties to the company.</i></p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Open-source, browser-local data exploration using DuckDB-WASM and PRQL (140 pts)]]></title>
            <link>https://github.com/pretzelai/pretzelai</link>
            <guid>39717268</guid>
            <pubDate>Fri, 15 Mar 2024 16:02:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/pretzelai/pretzelai">https://github.com/pretzelai/pretzelai</a>, See on <a href="https://news.ycombinator.com/item?id=39717268">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">🥨 Pretzel</h2><a id="user-content--pretzel" aria-label="Permalink: 🥨 Pretzel" href="#-pretzel"></a></p>
<p dir="auto"><a href="https://github.com/pretzelai/pretzelai/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/c74c83918e248d250e94ac5b8c93771ebb0d3127155fc17220595489455e643d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f707265747a656c61692f707265747a656c6169" alt="License" data-canonical-src="https://img.shields.io/github/license/pretzelai/pretzelai"></a>
<a href="https://github.com/pretzelai/pretzelai"><img src="https://camo.githubusercontent.com/93e4c3cd9a6b630a89aaa2c6a9309d696c0ca515a050ac7ea5245a5b1122af91/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707265747a656c61692f707265747a656c61693f7374796c653d736f6369616c" alt="GitHub Stars" data-canonical-src="https://img.shields.io/github/stars/pretzelai/pretzelai?style=social"></a></p>
<p dir="auto">Live deployed build: <a href="https://pretzelai.github.io/" rel="nofollow">https://pretzelai.github.io</a></p>
<p dir="auto">Pretzel is an open-source, offline browser-based tool for fast and intuitive data exploration and visualization. It can handle large data files, runs locally in your browser, and requires no backend setup. Pretzel makes it easy to manipulate data via visual chained data transform blocks. It's also reactive - chaging an tranform block in the chain automatically updates all transform blocks and charts that follow.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/121360087/313066071-e7f20a16-b19c-4a29-b468-88d42eaa9b43.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1NDM5MDYsIm5iZiI6MTcxMDU0MzYwNiwicGF0aCI6Ii8xMjEzNjAwODcvMzEzMDY2MDcxLWU3ZjIwYTE2LWIxOWMtNGEyOS1iNDY4LTg4ZDQyZWFhOWI0My5naWY_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwMzE1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDMxNVQyMzAwMDZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xNGIzOWM4ZDRmMTRhMDEyMWIzMmVjMGFlOGQ0ZDNkMjRhYzIyNjNhMjBlOTdhZGJlYjhmMTI5ZTM3ZjYxNjE4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.gcFiE42OSFIMDrDV7Z6IdBzOBgxHjnEOVfO4V2X5aSU"><img src="https://private-user-images.githubusercontent.com/121360087/313066071-e7f20a16-b19c-4a29-b468-88d42eaa9b43.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1NDM5MDYsIm5iZiI6MTcxMDU0MzYwNiwicGF0aCI6Ii8xMjEzNjAwODcvMzEzMDY2MDcxLWU3ZjIwYTE2LWIxOWMtNGEyOS1iNDY4LTg4ZDQyZWFhOWI0My5naWY_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwMzE1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDMxNVQyMzAwMDZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xNGIzOWM4ZDRmMTRhMDEyMWIzMmVjMGFlOGQ0ZDNkMjRhYzIyNjNhMjBlOTdhZGJlYjhmMTI5ZTM3ZjYxNjE4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.gcFiE42OSFIMDrDV7Z6IdBzOBgxHjnEOVfO4V2X5aSU" alt="demo.gif" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>🚀 Blazing-fast performance with WebAssembly-based <a href="https://duckdb.org/" rel="nofollow">DuckDB</a> and <a href="https://prql-lang.org/" rel="nofollow">PRQL</a></li>
<li>🔍 Intuitive data exploration with a visual, top-down pipeline of data transformations and visualizations</li>
<li>🧠 AI-powered transformation block to help with fast data manipulation</li>
<li>🔒 Privacy-first design: run Pretzel AI locally or host it yourself for full control over your data</li>
<li>📊 Upcoming features: Local LLM support, API calls, in-browser Python support with <a href="https://github.com/pyodide/pyodide">Pyodide</a>, save and share workflows securely and canvas based table rendering</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#demo-video">Demo video</a></li>
<li><a href="#getting-started">Getting started</a>
<ul dir="auto">
<li><a href="#website-easiest">Website (Easiest)</a></li>
<li><a href="#offline-standalone-app">Offline standalone app</a></li>
<li><a href="#developers">Developers</a>
<ul dir="auto">
<li><a href="#run-locally">Run locally</a></li>
<li><a href="#host-pretzel">Host Pretzel</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#optional-configuration">Optional Configuration</a></li>
<li><a href="#implemented-transformation-blocks">Implemented Transformation Blocks</a></li>
<li><a href="#known-bugs">Known Bugs</a></li>
<li><a href="#contact">Contact</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo video</h2><a id="user-content-demo-video" aria-label="Permalink: Demo video" href="#demo-video"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description Pretzel.mp4">Pretzel.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/161899563/313245661-cb5b0f00-4add-40e8-b0c8-f59a0186e3ff.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1NDM5MDYsIm5iZiI6MTcxMDU0MzYwNiwicGF0aCI6Ii8xNjE4OTk1NjMvMzEzMjQ1NjYxLWNiNWIwZjAwLTRhZGQtNDBlOC1iMGM4LWY1OWEwMTg2ZTNmZi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwMzE1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDMxNVQyMzAwMDZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0zMjU1N2M2YzNmMTg5YmE1NDljZjRiZTcwNTE2NzI0YmY4YWI0YmYzODBlMjc4NTNlOTg4ZjQ3OWNkMjcxMTU1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.p9Cwumfo8cZKz_5umvOXFKLi_sVhkhB5q0S65SARwZs" data-canonical-src="https://private-user-images.githubusercontent.com/161899563/313245661-cb5b0f00-4add-40e8-b0c8-f59a0186e3ff.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1NDM5MDYsIm5iZiI6MTcxMDU0MzYwNiwicGF0aCI6Ii8xNjE4OTk1NjMvMzEzMjQ1NjYxLWNiNWIwZjAwLTRhZGQtNDBlOC1iMGM4LWY1OWEwMTg2ZTNmZi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwMzE1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDMxNVQyMzAwMDZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0zMjU1N2M2YzNmMTg5YmE1NDljZjRiZTcwNTE2NzI0YmY4YWI0YmYzODBlMjc4NTNlOTg4ZjQ3OWNkMjcxMTU1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.p9Cwumfo8cZKz_5umvOXFKLi_sVhkhB5q0S65SARwZs" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Website (Easiest)</h3><a id="user-content-website-easiest" aria-label="Permalink: Website (Easiest)" href="#website-easiest"></a></p>
<p dir="auto">The easiest way to use Pretzel is to visit <a href="https://pretzelai.github.io/" rel="nofollow">https://pretzelai.github.io</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Offline standalone app</h3><a id="user-content-offline-standalone-app" aria-label="Permalink: Offline standalone app" href="#offline-standalone-app"></a></p>
<p dir="auto">Since Pretzel doesn't have a backend you can easily install it as a Chrome app and it will work even without internet (for those long flights!)</p>
<ol dir="auto">
<li>
<p dir="auto">Visit <a href="https://pretzelai.github.io/" rel="nofollow">https://pretzelai.github.io</a> in Chrome</p>
</li>
<li>
<p dir="auto">Click the install app icon</p>
</li>
</ol>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/121360087/313066187-c6276699-5109-4e59-8bf5-2858c51cb4c3.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1NDM5MDYsIm5iZiI6MTcxMDU0MzYwNiwicGF0aCI6Ii8xMjEzNjAwODcvMzEzMDY2MTg3LWM2Mjc2Njk5LTUxMDktNGU1OS04YmY1LTI4NThjNTFjYjRjMy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwMzE1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDMxNVQyMzAwMDZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00OWNhNTYyZWM4NDNkYmFkYzc2ZDRiMmIyM2Y4NjRhZTFhYWVhODgwODM0MTNlNGQ3NzBiMjI3ZTc1Y2IzYzU4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.GbmRczgdy_3OGVxJiejCrCV8iI2cODu7sqC7w45rRFA"><img width="521" alt="pretzel_chrome_install" src="https://private-user-images.githubusercontent.com/121360087/313066187-c6276699-5109-4e59-8bf5-2858c51cb4c3.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1NDM5MDYsIm5iZiI6MTcxMDU0MzYwNiwicGF0aCI6Ii8xMjEzNjAwODcvMzEzMDY2MTg3LWM2Mjc2Njk5LTUxMDktNGU1OS04YmY1LTI4NThjNTFjYjRjMy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwMzE1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDMxNVQyMzAwMDZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00OWNhNTYyZWM4NDNkYmFkYzc2ZDRiMmIyM2Y4NjRhZTFhYWVhODgwODM0MTNlNGQ3NzBiMjI3ZTc1Y2IzYzU4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.GbmRczgdy_3OGVxJiejCrCV8iI2cODu7sqC7w45rRFA"></a>
<ol start="3" dir="auto">
<li>Now you can launch Pretzel as a standalone app. It will also work offline, it may error if you try to use some internet feature (like the AI Block), just close it and open it again to fix it</li>
</ol>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/121360087/313066562-cc13e552-d93a-4990-be22-1f6b5d906b15.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1NDM5MDYsIm5iZiI6MTcxMDU0MzYwNiwicGF0aCI6Ii8xMjEzNjAwODcvMzEzMDY2NTYyLWNjMTNlNTUyLWQ5M2EtNDk5MC1iZTIyLTFmNmI1ZDkwNmIxNS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwMzE1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDMxNVQyMzAwMDZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wYzQzMzg0MzRjY2MyYTFiMjVlN2EwMzg3NTNhYTRiYjIwMGM1YTMxYzY4ZmM5MTY4OGFmMDYwYWFkNmVhZTNlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.6kReT3qm1l4_zW6J34SEr9DyUpEEYNDXSKkbJaA-Smo"><img width="268" alt="pretzel_app_icon" src="https://private-user-images.githubusercontent.com/121360087/313066562-cc13e552-d93a-4990-be22-1f6b5d906b15.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1NDM5MDYsIm5iZiI6MTcxMDU0MzYwNiwicGF0aCI6Ii8xMjEzNjAwODcvMzEzMDY2NTYyLWNjMTNlNTUyLWQ5M2EtNDk5MC1iZTIyLTFmNmI1ZDkwNmIxNS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwMzE1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDMxNVQyMzAwMDZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wYzQzMzg0MzRjY2MyYTFiMjVlN2EwMzg3NTNhYTRiYjIwMGM1YTMxYzY4ZmM5MTY4OGFmMDYwYWFkNmVhZTNlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.6kReT3qm1l4_zW6J34SEr9DyUpEEYNDXSKkbJaA-Smo"></a>
<p dir="auto"><h3 tabindex="-1" dir="auto">Developers</h3><a id="user-content-developers" aria-label="Permalink: Developers" href="#developers"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Run locally</h4><a id="user-content-run-locally" aria-label="Permalink: Run locally" href="#run-locally"></a></p>
<p dir="auto">To run Pretzel locally, follow these steps:</p>
<ol dir="auto">
<li>
<p dir="auto">Clone the repository:</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/pretzelai/pretzelai.git"><pre><code>git clone https://github.com/pretzelai/pretzelai.git
</code></pre></div>
</li>
<li>
<p dir="auto">Install dependencies:</p>

</li>
<li>
<p dir="auto">Start the development server:</p>

</li>
<li>
<p dir="auto">Open your browser and navigate to <code>http://localhost:3000</code></p>
</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Host Pretzel</h4><a id="user-content-host-pretzel" aria-label="Permalink: Host Pretzel" href="#host-pretzel"></a></p>
<p dir="auto">To host Pretzel, follow these steps (it's just a static website!):</p>
<ol dir="auto">
<li>Build the app</li>
</ol>

<ol start="2" dir="auto">
<li>Upload the contents of the <code>build</code> folder to your hosting. This is what you can find live at <a href="https://pretzelai.github.io/" rel="nofollow">https://pretzelai.github.io</a></li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Optional configuration</h2><a id="user-content-optional-configuration" aria-label="Permalink: Optional configuration" href="#optional-configuration"></a></p>
<ul dir="auto">
<li>Bug report box: Update <code>/src/lib/config.ts</code> with your PostHog config to let users report bugs directly on the website</li>
<li>AI Endpoint: Deploy a cloud function to provide an AI endpoint for users without an OpenAI API key. Check the <code>cloud</code> folder for instructions.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Implemented transformation blocks</h2><a id="user-content-implemented-transformation-blocks" aria-label="Permalink: Implemented transformation blocks" href="#implemented-transformation-blocks"></a></p>
<ul dir="auto">
<li><strong>Upload:</strong> accepts CSV / Excel (XLSX) files</li>
<li><strong>Filter</strong>: string/number/date filtering including nested filters</li>
<li><strong>Ask AI</strong>: connects to OpenAI to transform user command to SQL</li>
<li><strong>Pivot</strong>: to create a pivot table (you can also go group-by using this - only use the <code>Rows</code> and <code>Values</code> fields)</li>
<li><strong>Sort</strong>: sorts ascending or descending on multiple columns</li>
<li><strong>Chart</strong>: supports line (including multi-line) charts, bar charts (grouped and stacked) and scatter plot</li>
<li><strong>Create column</strong>: make a new column with basic math or use <a href="https://prql-lang.org/book/reference/declarations/functions.html" rel="nofollow">PRQL functions</a></li>
<li><strong>Remove columns</strong>: easily add/remove columns with visual toggles</li>
<li><strong>Table</strong>: add a table in the middle of your workflow to visualize data in a intermediate step</li>
<li><strong>Download</strong>: export your transformed data in CSV</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Known Bugs</h2><a id="user-content-known-bugs" aria-label="Permalink: Known Bugs" href="#known-bugs"></a></p>
<ul dir="auto">
<li>Dates are sometimes parsed incorrectly - existing GH issue <a href="https://github.com/pretzelai/pretzelai/issues/23" data-hovercard-type="issue" data-hovercard-url="/pretzelai/pretzelai/issues/23/hovercard">here</a></li>
<li>Table panel is slow for large datasets. We're planning on moving to a canvas based table</li>
<li>[Rare] Charts axes can sometimes not be ordered correctly</li>
</ul>
<p dir="auto">Please report any bugs you find in <a href="https://github.com/pretzelai/pretzelai">GitHub issues</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contact</h2><a id="user-content-contact" aria-label="Permalink: Contact" href="#contact"></a></p>
<p dir="auto">You can email us at founders [at] withpretzel [dot] com.</p>
<p dir="auto">We also read all the feedback and bugs you report at the top left of <a href="https://pretzelai.github.io/" rel="nofollow">https://pretzelai.github.io</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reversing for dummies – x86 assembly and C code (Beginner/ADHD friendly) (114 pts)]]></title>
            <link>https://0x44.cc/reversing/2021/07/21/reversing-x86-and-c-code-for-beginners.html</link>
            <guid>39716494</guid>
            <pubDate>Fri, 15 Mar 2024 14:58:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://0x44.cc/reversing/2021/07/21/reversing-x86-and-c-code-for-beginners.html">https://0x44.cc/reversing/2021/07/21/reversing-x86-and-c-code-for-beginners.html</a>, See on <a href="https://news.ycombinator.com/item?id=39716494">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <h3 id="context">Context</h3>

          <p>
            Before I got into reverse engineering, executables always seemed
            like black magic to me. I always wondered how stuff worked under the
            hood, and how binary code is represented inside .exe files, and how
            hard it is to modify this ‘compiled code’ without access to the
            original source code.
          </p>

          <p>
            But one of the main intimidating hurdles always seemed to be the
            assembly language, it’s the thing that scares most people away from
            trying to learn about this field.
          </p>

          <p>
            That’s the main reason why I thought of writing this
            straight-to-the-point article that only contains the essential stuff
            that you encounter the most when reversing, albeit missing crucial
            details for the sake of brevity, and assumes the reader has a reflex
            of finding answers online, looking up definitions, and more
            importantly, coming up with examples/ideas/projects to practice on.
          </p>

          <p>
            The goal is to hopefully guide an aspiring reverse engineer and
            arouse motivation towards learning more about this seemingly elusive
            passion.
          </p>

          <p>
            <strong><em>Note</em></strong>: This article assumes the reader has elementary knowledge
            regarding the
            <a href="https://en.wikipedia.org/wiki/Hexadecimal" rel="noopener noreferrer" target="_blank">hexadecimal numeral system</a>, as well as the
            <a href="https://en.wikipedia.org/wiki/C_(programming_language)" rel="noopener noreferrer" target="_blank">C programming language</a>, and is based on a 32-bit Windows executable case study - results
            might differ across different OSes/architectures.
          </p>

          <h3 id="introduction">Introduction</h3>

          <h4 id="compilation">Compilation</h4>

          <p>
            After writing code using a
            <a href="https://en.wikipedia.org/wiki/Compiled_language" rel="noopener noreferrer" target="_blank">compiled language</a>, a compilation takes place <del>(duh)</del>, in order to generate
            the output binary file (an example of such is an .exe file).
          </p>

          <p>
            <img src="https://i.0x44.cc/b/compilation-c-to-exe-file.png">
          </p>

          <p>
            Compilers are sophisticated programs which do this task. They make
            sure the syntax of your <del>ugly</del> code is correct, before
            compiling and optimizing the resulting machine code by minimizing
            its size and improving its performance, whenever applicable.
          </p>

          <h4 id="binary-code">Binary code</h4>

          <p>
            As we were saying, the resulting output file contains binary code,
            which can only be ‘understood’ by a CPU, it’s essentially a
            succession of varying-length instructions to be executed in order -
            here’s what some of them look like:
          </p>

          <table>
            <thead>
              <tr>
                <th>CPU-readable instruction data (in hex)</th>
                <th>Human-readable interpretation</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>55</td>
                <td>push ebp</td>
              </tr>
              <tr>
                <td>8B EC</td>
                <td>mov ebp, esp</td>
              </tr>
              <tr>
                <td>83 EC 08</td>
                <td>sub esp, 8</td>
              </tr>
              <tr>
                <td>33 C5</td>
                <td>xor eax, ebp</td>
              </tr>
              <tr>
                <td>83 7D 0C 01</td>
                <td>cmp dword ptr [ebp+0Ch], 1</td>
              </tr>
            </tbody>
          </table>

          <p>
            These instructions are predominantly arithmetical, and they
            manipulate CPU registers/flags as well as volatile memory, as
            they’re executed.
          </p>

          <h4 id="cpu-registers">CPU registers</h4>

          <p>
            <a href="https://en.wikipedia.org/wiki/Processor_register" rel="noopener noreferrer" target="_blank">A CPU register</a>
            is almost like a temporary integer variable - there’s a small fixed
            number of them, and they exist because they’re quick to access,
            unlike memory-based variables, and they help the CPU keep track of
            its data (results, operands, counts, etc.) during execution.
          </p>

          <p>
            It’s important to note the presence of a special register called the
            <a href="https://en.wikipedia.org/wiki/FLAGS_register" rel="noopener noreferrer" target="_blank"><code>FLAGS</code>
              register</a>
            (<code>EFLAGS</code> on
            32-bit), which houses a bunch of flags (boolean indicators), which
            hold information about the state of the CPU, which include details
            about the last arithmetic operation (zero:
            <code>ZF</code>,
            overflow:
            <code>OF</code>,
            parity:
            <code>PF</code>, sign:
            <code>SF</code>, etc.).
          </p>

          <p>
            <img src="https://i.0x44.cc/b/x32dbg-cpu-registers.png">
            <small>CPU registers visualized while debugging a 32-bit process on
              x64dbg, a debugging tool.</small>
          </p>

          <p>
            Some of these registers can also be spotted on the assembly excerpt
            mentioned <a href="#binary-code">previously</a>, namely:
            <code>EAX</code>,
            <code>ESP</code> (stack
            pointer) and
            <code>EBP</code> (base
            pointer).
          </p>

          <h4 id="memory-access">Memory access</h4>

          <p>
            As the CPU executes stuff, it needs to access and interact with
            memory, that’s when the role of the <em>stack</em> and the
            <em>heap</em> comes.
          </p>

          <p>
            These are (without getting into too much detail) the 2 main ways of
            ‘keeping track of variable data’ during the execution of a program:
          </p>

          <h5 id="-stack">🥞 <em>Stack</em></h5>
          <p>
            The simpler and faster of the two - it’s a linear contiguous LIFO
            (last in = first out) data structure with a push/pop mechanism, it
            serves to remember function-scoped variables, arguments, and keeps
            track of calls (ever heard of a
            <a href="https://en.wikipedia.org/wiki/Stack_trace" rel="noopener noreferrer" target="_blank">stack trace</a>?)
          </p>

          <h5 id="-heap">⛰ <em>Heap</em></h5>
          <p>
            The heap, however, is pretty unordered, and is for more complicated
            data structures, it’s typically used for dynamic allocations, where
            the size of the buffer isn’t initially known, and/or if it’s too
            big, and/or needs to be modified later.
          </p>

          <h3 id="assembly-instructions">Assembly instructions</h3>

          <p>
            As I’ve mentioned earlier, assembly instructions have a varying
            ‘byte-size’, and a varying number of arguments.
          </p>

          <p>
            Arguments can also be either immediate (‘hardcoded’), or they can be
            registers, depending on the instruction:
          </p>

          <div>
              <pre><code>55         push    ebp     ; size: 1 byte,  argument: register
6A 01      push    1       ; size: 2 bytes, argument: immediate
</code></pre>
            </div>

          <p>
            Let’s quickly run through a very small set of some of the common
            ones we’ll get to see - feel free to do your own research for more
            detail:
          </p>

          <h4 id="stack-operations">Stack operations</h4>
          <ul>
            <li>
              <strong>push
                <code>value</code></strong>
              <em>; pushes a value into the stack (decrements
                <code>ESP</code> by
                4, the size of one stack ‘unit’).</em>
            </li>
            <li>
              <strong>pop
                <code>register</code></strong>
              <em>; pops a value to a register (increments
                <code>ESP</code> by
                4).</em>
            </li>
          </ul>

          <h4 id="data-transfer">Data transfer</h4>
          <ul>
            <li>
              <strong>mov
                <code>destination</code>,
                <code>source</code></strong>
              ; <em><del>moves</del> copies a value from/to a register.</em>
            </li>
            <li>
              <strong>mov
                <code>destination</code>, [<code>expression</code>]</strong>
              ;
              <em>copies a value from a memory address resolved from a ‘register
                expression’ (single register or arithmetic expression involving
                one or more registers) into a register.</em>
            </li>
          </ul>

          <h4 id="flow-control">Flow control</h4>
          <ul>
            <li>
              <strong>jmp
                <code>destination</code></strong>
              ;
              <em>jumps into a code location (sets
                <code>EIP</code>
                (instruction pointer)).</em>
            </li>
            <li>
              <strong>jz/je
                <code>destination</code></strong>
              ;
              <em>jumps into a code location if
                <code>ZF</code>
                (the zero flag) is set.</em>
            </li>
            <li>
              <strong>jnz/jne
                <code>destination</code></strong>
              ;
              <em>jumps into a code location if
                <code>ZF</code> is
                not set.</em>
            </li>
          </ul>

          <h4 id="operations">Operations</h4>
          <ul>
            <li>
              <strong>cmp
                <code>operand1</code>,
                <code>operand2</code></strong>
              ;
              <em>compares the 2 operands and sets
                <code>ZF</code> if
                they’re equal.</em>
            </li>
            <li>
              <strong>add
                <code>operand1</code>,
                <code>operand2</code></strong>
              ; <em>operand1 += operand2;</em>
            </li>
            <li>
              <strong>sub
                <code>operand1</code>,
                <code>operand2</code></strong>
              ; <em>operand1 -= operand2;</em>
            </li>
          </ul>

          <h4 id="function-transitions">Function transitions</h4>
          <ul>
            <li>
              <strong>call
                <code>function</code></strong>
              ;
              <em>calls a function (pushes current
                <code>EIP</code>,
                then jumps to the function).</em>
            </li>
            <li>
              <strong>retn</strong> ;
              <em>returns to caller function (pops back the previous
                <code>EIP</code>).</em>
            </li>
          </ul>

          <p>
            <strong><em>Note</em></strong>: You might notice the words ‘equal’ and ‘zero’ being used
            interchangeably in x86 terminology - that’s because comparison
            instructions internally perform a subtraction, which means if the 2
            operands are equal,
            <code>ZF</code> is set.
          </p>

          <h3 id="assembly-patterns">Assembly patterns</h3>

          <p>
            Now that we have a rough idea of the main elements used during the
            execution of a program, let’s get familiarized with the patterns of
            instructions that you can encounter reverse engineering your average
            everyday 32-bit
            <a href="https://en.wikipedia.org/wiki/Portable_Executable" rel="noopener noreferrer" target="_blank">PE</a>
            binary.
          </p>

          <h4 id="function-prologue">Function prologue</h4>

          <p>
            A
            <a href="https://en.wikipedia.org/wiki/Function_prologue" rel="noopener noreferrer" target="_blank">function prologue</a>
            is some initial code embedded in the beginning of most functions, it
            serves to set up a new stack frame for said function.
          </p>

          <p>It typically looks like this (X being a number):</p>

          <div>
              <pre><code>55          push    ebp        ; preserve caller function's base pointer in stack
8B EC       mov     ebp, esp   ; caller function's stack pointer becomes base pointer (new stack frame)
83 EC XX    sub     esp, X     ; adjust the stack pointer by X bytes to reserve space for local variables
</code></pre>
            </div>

          <h4 id="function-epilogue">Function epilogue</h4>

          <p>
            The
            <a href="https://en.wikipedia.org/wiki/Function_epilogue" rel="noopener noreferrer" target="_blank">epilogue</a>
            is simply the opposite of the prologue - it undoes its steps to
            restore the stack frame of the caller function, before it returns to
            it:
          </p>

          <div>
              <pre><code>8B E5    mov    esp, ebp    ; restore caller function's stack pointer (current base pointer) 
5D       pop    ebp         ; restore base pointer from the stack
C3       retn               ; return to caller function
</code></pre>
            </div>

          <p>
            Now at this point, you might be wondering - how do functions talk to
            each other? How exactly do you send/access arguments when calling a
            function, and how do you receive the return value? That’s precisely
            why we have calling conventions.
          </p>

          <h4 id="calling-conventions-__cdecl">Calling conventions: __cdecl</h4>

          <p>
            A
            <a href="https://en.wikipedia.org/wiki/Calling_convention" rel="noopener noreferrer" target="_blank">calling convention</a>
            is basically a protocol used to communicate with functions, there’s
            a few variations of them, but they share the same principle.
          </p>

          <p>
            We will be looking at the
            <a href="https://en.wikipedia.org/wiki/X86_calling_conventions#cdecl" rel="noopener noreferrer" target="_blank">__cdecl (C declaration) convention</a>, which is the standard one when compiling C code.
          </p>

          <p>
            In __cdecl (32-bit), function arguments are passed on the stack
            (pushed in reverse order), while the return value is returned in the
            <code>EAX</code>
            register (assuming it’s not a float).
          </p>

          <p>
            This means that a
            <code>func(1, 2, 3);</code>
            call will generate the following:
          </p>

          <div>
              <pre><code>6A 03             push    3
6A 02             push    2
6A 01             push    1
E8 XX XX XX XX    call    func
</code></pre>
            </div>

          <h4 id="putting-everything-together">Putting everything together</h4>

          <p>
            Assuming
            <code>func()</code>
            simply does an addition on the arguments and returns the result, it
            would probably look like this:
          </p>

          <div>
              <pre><code>int __cdecl func(int, int, int):

           prologue:
55           push    ebp               ; save base pointer
8B EC        mov     ebp, esp          ; new stack frame

           body:
8B 45 08     mov     eax, [ebp+8]      ; load first argument to EAX (return value)
03 45 0C     add     eax, [ebp+0Ch]    ; add 2nd argument
03 45 10     add     eax, [ebp+10h]    ; add 3rd argument

           epilogue:
5D           pop     ebp               ; restore base pointer
C3           retn                      ; return to caller
</code></pre>
            </div>

          <p>
            Now if you’ve been paying attention and you’re still confused, you
            might be asking yourself one of these 2 questions:
          </p>

          <p>
            1) Why do we have to adjust
            <code>EBP</code> by 8
            to get to the first argument?
          </p>

          <ul>
            <li>
              If you
              <a href="#assembly-instructions">check the definition</a> of the
              <code>call</code>
              instruction we mentioned earlier, you’ll realize that, internally,
              it actually pushes
              <code>EIP</code> to
              the stack. And if you also check the definition for
              <code>push</code>,
              you’ll realize that it decrements
              <code>ESP</code>
              (which is copied to
              <code>EBP</code>
              after the prologue) by 4 bytes. In addition, the prologue’s first
              instruction is also a
              <code>push</code>, so
              we end up with 2 decrements of 4, hence the need to add 8.
            </li>
          </ul>

          <p>
            2) What happened to the prologue and epilogue, why are they
            seemingly ‘truncated’?
          </p>

          <ul>
            <li>
              It’s simply because we haven’t had a use for the stack during the
              execution of our function - if you’ve noticed, we haven’t modified
              <code>ESP</code> at
              all, which means we also don’t need to restore it.
            </li>
          </ul>

          <h4 id="if-conditions">If conditions</h4>

          <p>
            To demo the flow control assembly instructions, I’d like to add one
            more example to show how an if condition was compiled to assembly.
          </p>

          <p>Assume we have the following function:</p>

          <div>
              <pre><code><span>void</span> <span>print_equal</span><span>(</span><span>int</span> <span>a</span><span>,</span> <span>int</span> <span>b</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>a</span> <span>==</span> <span>b</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"equal"</span><span>);</span>
    <span>}</span>
    <span>else</span> <span>{</span>
        <span>printf</span><span>(</span><span>"nah"</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre>
            </div>

          <p>
            After compiling it, here’s the disassembly that I got with the help
            of
            <a href="https://hex-rays.com/ida-pro/" rel="noopener noreferrer" target="_blank">IDA</a>:
          </p>

          <div>
              <pre><code>void __cdecl print_equal(int, int):

     10000000   55                push   ebp
     10000001   8B EC             mov    ebp, esp
     10000003   8B 45 08          mov    eax, [ebp+8]       ; load 1st argument
     10000006   3B 45 0C          cmp    eax, [ebp+0Ch]     ; compare it with 2nd
  ┌┅ 10000009   75 0F             jnz    short loc_1000001A ; jump if not equal
  ┊  1000000B   68 94 67 00 10    push   offset aEqual  ; "equal"
  ┊  10000010   E8 DB F8 FF FF    call   _printf
  ┊  10000015   83 C4 04          add    esp, 4
┌─┊─ 10000018   EB 0D             jmp    short loc_10000027
│ ┊
│ └ loc_1000001A:
│    1000001A   68 9C 67 00 10    push   offset aNah    ; "nah"
│    1000001F   E8 CC F8 FF FF    call   _printf
│    10000024   83 C4 04          add    esp, 4
│
└── loc_10000027:
     10000027   5D                pop    ebp
     10000028   C3                retn
</code></pre>
            </div>

          <p>
            Give yourself a minute and try to make sense of this disassembly
            output (for simplicity’s sake, I’ve changed the real addresses and
            made the function start from
            <code>10000000</code>
            instead).
          </p>

          <p>
            In case you’re wondering about the
            <code>add esp, 4</code>
            part, it’s simply there to adjust
            <code>ESP</code> back
            to its initial value (same effect as a
            <code>pop</code>,
            except without modifying any register), since we had to
            <code>push</code> the
            printf string argument.
          </p>

          <h3 id="basic-data-structures">Basic data structures</h3>

          <p>
            Now let’s move on and talk about how data is stored (integers and
            strings especially).
          </p>

          <h4 id="endianness">Endianness</h4>

          <p>
            <a href="https://en.wikipedia.org/wiki/Endianness" rel="noopener noreferrer" target="_blank">Endianness</a>
            is the order of the sequence of bytes representing a value in
            computer memory.
          </p>

          <p>There’s 2 types - big-endian and little-endian:</p>

          

          <p>
            For reference, x86 family processors (the ones on pretty much any
            computer you can find) always use little-endian.
          </p>

          <p>
            To give you a live example of this concept, I’ve compiled a Visual
            Studio C++ console app, where I declared an
            <code>int</code>
            variable with the value
            <code>1337</code>
            assigned to it, then I printed the variable’s address using
            <code>printf()</code>,
            on the main function.
          </p>

          <p>
            Then I ran the program attached to the debugger in order to check
            the printed variable’s address on the memory hex view, and here’s
            the result I obtained:
          </p>

          <p>
            <img src="https://i.0x44.cc/b/vs-debug-memory-view.png" alt="">
          </p>

          <p>
            To elaborate more on this -
            <code>int</code>
            variables are 4 bytes long (32 bits) (in case you didn’t know), so
            this means that if the variable starts from the address
            <code>D2FCB8</code> it
            would end right before
            <code>D2FCBC</code>
            (+4).
          </p>

          <p>
            To go from human readable value to memory bytes, follow these steps:
          </p>

          <p>
            decimal:
            <code>1337</code> -&gt;
            hex:
            <code>539</code> -&gt;
            bytes:
            <code>00 00 05 39</code>
            -&gt; little-endian:
            <code>39 05 00 00</code>
          </p>

          <h4 id="signed-integers">Signed integers</h4>

          <p>
            This part is interesting yet relatively simple. What you should know
            here is that integer signing (positive/negative) is typically done
            on computers with the help of a concept called
            <a href="https://en.wikipedia.org/wiki/Signed_number_representations#Two's_complement" rel="noopener noreferrer" target="_blank">two’s complement</a>.
          </p>

          <p>
            The gist of it is that the lowest/first half of an integer is
            reserved for positive numbers, while the highest/last half is for
            negative numbers, here’s what this looks like in hex, for a 32-bit
            signed int (highlighted = hex, in parenthesis = decimal):
          </p>

          <p>
            Positives (1/2):
            <code>00000000</code>
            (0) -&gt;
            <code>7FFFFFFF</code>
            (2,147,483,647 or
            <code>INT_MAX</code>)
          </p>

          <p>
            Negatives (2/2):
            <code>80000000</code>
            (-2,147,483,648 or
            <code>INT_MIN</code>)
            -&gt;
            <code>FFFFFFFF</code>
            (-1)
          </p>

          <p>
            If you’ve noticed, we’re always <em>ascending</em> in value. Whether
            we go up in hex or decimal. And that’s the crucial point of this
            concept - arithmetical operation do not have to do anything special
            to handle signing, they can simply treat all values as
            unsigned/positive, and the result would still be interpreted
            correctly (as long as we don’t go beyond
            <code>INT_MAX</code> or
            <code>INT_MIN</code>),
            and that’s because integers will also <em>‘rollover’</em> on
            overflow/underflow by design, kinda like an analog odometer.
          </p>

          <p>
            <img src="https://i.0x44.cc/b/odometer-rollover.jpg">
          </p>

          <p>
            <strong><em>Protip</em></strong>: The Windows calculator is a very helpful tool - you can set it to
            programmer mode and set the size to DWORD (4 bytes), then enter
            negative decimal values and visualize them in hex and binary, and
            have fun performing operations on them.
          </p>

          <p>
            <img src="https://i.0x44.cc/b/calcexe-int-signing.png" alt="">
          </p>

          <h4 id="strings">Strings</h4>

          <p>
            In C, strings are stored as
            <code>char</code>
            arrays, therefore, there’s nothing special to note here, except for
            something called null termination.
          </p>

          <p>
            If you ever wondered how
            <code>strlen()</code>
            is able to know the size of a string, it’s very simple - strings
            have a character that indicates their end, and that’s the null
            byte/character -
            <code>00</code> or
            <code>'\0'</code>.
          </p>

          <p>
            If you declare a string constant in C code, and hover over it in
            Visual Studio, for instance, it will tell you the size of the
            generated array, and as you can see, for this reason, it’s one
            element more than the ‘visible’ string size.
          </p>

          <p>
            <img src="https://i.0x44.cc/b/vs-null-termination.png" alt="">
          </p>

          <p>
            <strong><em>Note</em></strong>: The endianness concept is not applicable on arrays, only on
            single variables. Therefore, the order of characters in memory would
            be normal here - low to high.
          </p>

          <h3 id="making-sense-of-call-and-jmp-instructions">
            Making sense of
            <code>call</code> and
            <code>jmp</code>
            instructions
          </h3>

          <p>
            Now that you know all of this, you’re likely able to start making
            sense of some machine code, and emulate a CPU with your brain, to
            some extent, so to speak.
          </p>

          <p>
            Let’s take the
            <a href="#if-conditions"><code>print_equal()</code>
              example</a>, but let’s only focus on the
            <code>printf()</code>
            <code>call</code>
            instructions this time.
          </p>

          <div>
              <pre><code>void print_equal(int, int):
...
     10000010   E8 DB F8 FF FF    call   _printf
...
     1000001F   E8 CC F8 FF FF    call   _printf
</code></pre>
            </div>

          <p>
            You might be wondering to yourself - wait a second, if these are the
            same instructions, then why are their bytes different?
          </p>

          <p>
            That’s because,
            <code>call</code> (and
            <code>jmp</code>)
            instructions (usually) take an <em>offset</em> (relative address) as
            an argument, not an absolute address.
          </p>

          <p>
            An offset is basically the difference between the current location,
            and the destination, which also means that it can be either negative
            or positive.
          </p>

          <p>
            As you can see, the
            <a href="https://en.wikipedia.org/wiki/Opcode" rel="noopener noreferrer" target="_blank">opcode</a>
            of a
            <code>call</code>
            instruction that takes a 32-bit offset, is
            <code>E8</code>, and is
            followed by said offset - which makes the full instruction:
            <code>E8 XX XX XX XX</code>.
          </p>

          <p>
            Pull out your calculator,
            <del>why’d you close it so early?!</del> and calculate the
            difference between the offset of both instructions (don’t forget the
            endianness).
          </p>

          <p>
            You’ll notice that (the absolute value of) this difference is the
            same as the one between the instruction addresses (<code>1000001F</code>
            -
            <code>10000010</code> =
            <code>F</code>):
          </p>

          <p>
            <img src="https://i.0x44.cc/b/calcexe-call-inst-diff.png" alt="">
          </p>

          <p>
            Another small detail that we should add, is the fact that the CPU
            only executes an instruction after fully ‘reading’ it, which means
            that by the time the CPU starts ‘executing’,
            <code>EIP</code> (the
            instruction pointer) is already pointing at the
            <em>next</em> instruction to be executed.
          </p>

          <p>
            That’s why these offsets are actually accounting for this behaviour,
            which means that in order to get the <em>real</em> address of the
            target function, we have to also <em>add</em> the size of the
            <code>call</code>
            instruction: 5.
          </p>

          <p>
            Now let’s apply all these steps in order to resolve
            <code>printf()</code>’s
            address from the first instruction on the example:
          </p>

          <div>
              <pre><code>10000010   E8 DB F8 FF FF    call   _printf
</code></pre>
            </div>

          <p>
            1) Extract the offset from the instruction:
            <code>E8 (DB F8 FF FF)</code>
            -&gt;
            <code>FFFFF8DB</code>
            (-1829)
          </p>

          <p>
            2) Add it to the instruction address:
            <code>10000010</code> +
            <code>FFFFF8DB</code> =
            <code>0FFFF8EB</code>
          </p>

          <p>
            3) And finally, add the instruction size:
            <code>0FFFF8EB</code> +
            5 =
            <code>0FFFF8F0</code>
            (<code>&amp;printf</code>)
          </p>

          <p>
            The exact same principle applies to the
            <code>jmp</code>
            instruction:
          </p>

          <div>
              <pre><code>...
┌─── 10000018   EB 0D             jmp    short loc_10000027
...
└── loc_10000027:
     10000027   5D                pop    ebp
...
</code></pre>
            </div>
          <p>
            The only difference in this example is that
            <code>EB XX</code> is a
            short version
            <code>jmp</code>
            instruction - which means it only takes an 8-bit (1 byte) offset.
          </p>

          <p>
            Therefore:
            <code>10000018</code> +
            <code>0D</code> + 2 =
            <code>10000027</code>
          </p>

          <h3 id="conclusion">Conclusion</h3>

          <p>
            That’s it! You should now have enough information (and hopefully,
            motivation) to start your journey reverse engineering executables.
          </p>

          <p>
            Start by writing dummy C code, compiling it, and debugging it while
            single-stepping through the disassembly instructions (Visual Studio
            allows you to do this, by the way).
          </p>

          <p>
            <a href="https://godbolt.org/" rel="noopener noreferrer" target="_blank">Compiler Explorer</a>
            is also an extremely helpful website which compiles C code to
            assembly for you in real time using multiple compilers (select the
            <code>x86 msvc</code>
            compiler for Windows 32-bit).
          </p>

          <p>
            After that, you can try your luck with closed-source native
            binaries, by the help of disassemblers such as
            <a href="https://ghidra-sre.org/" rel="noopener noreferrer" target="_blank">Ghidra</a>
            and
            <a href="https://hex-rays.com/ida-free" rel="noopener noreferrer" target="_blank">IDA</a>, and debuggers such as
            <a href="https://x64dbg.com/" rel="noopener noreferrer" target="_blank">x64dbg</a>.
          </p>

          <p>
            <strong><em>Note</em></strong>: If you’ve noticed inaccurate information, or room for improvement
            regarding this article, and would like to improve it, feel free to
            <a href="https://github.com/thedroidgeek/0x44.cc/edit/master/_posts/2021-07-21-reversing-x86-and-c-code-for-beginners.md" rel="noopener noreferrer" target="_blank">submit a pull request</a>
            on GitHub.
          </p>

          <p>Thanks for reading!</p>

          <p>
            <a href="https://github.com/thedroidgeek/0x44.cc/commits/master/_posts/2021-07-21-reversing-x86-and-c-code-for-beginners.md" rel="noopener noreferrer" target="_blank">(edited)</a>
          </p>

          
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing Whistleblower: "If Anything Happens to Me, It's Not Suicide" (133 pts)]]></title>
            <link>https://twitter.com/WallStreetSilv/status/1768517997285482626</link>
            <guid>39715161</guid>
            <pubDate>Fri, 15 Mar 2024 13:20:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/WallStreetSilv/status/1768517997285482626">https://twitter.com/WallStreetSilv/status/1768517997285482626</a>, See on <a href="https://news.ycombinator.com/item?id=39715161">Hacker News</a></p>
Couldn't get https://twitter.com/WallStreetSilv/status/1768517997285482626: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[IAM Is the Worst (211 pts)]]></title>
            <link>https://matduggan.com/iam-is-the-worst/</link>
            <guid>39714155</guid>
            <pubDate>Fri, 15 Mar 2024 10:55:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matduggan.com/iam-is-the-worst/">https://matduggan.com/iam-is-the-worst/</a>, See on <a href="https://news.ycombinator.com/item?id=39714155">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
<p>Imagine your job was to clean a giant office building. You go from floor to floor, opening doors, collecting trash, getting a vacuum out of the cleaning closet and putting it back. It's a normal job and part of that job is someone gives you a key. The key opens every door everywhere. Everyone understands the key is powerful, but they also understand you need to do your job. </p><p>Then your management hears about someone stealing janitor keys. So they take away your universal key and they say "you need to tell Suzie, our security engineer, which keys you need at which time". But the keys don't just unlock one door, some unlock a lot of doors and some desk drawers, some open the vault (imagine this is the Die Hard building), some don't open any doors but instead turn on the coffee machine. Obviously the keys have titles, but the titles mean nothing. Do you need the "executive_floor/admin" key or the "executive_floor/viewer" key? </p><p>But you are a good employee and understand that security is a part of the job. So you dutifully request the keys you think you need, try to do your job, open a new ticket when the key doesn't open a door you want, try it again, it still doesn't open the door you want so then there's another key. Soon your keyring is massive, just a clanging sound as you walk down the hallway. It mostly works, but a lot of the keys open stuff you don't need, which makes you think maybe this entire thing was pointless. </p><p>The company is growing and we need new janitors, but they don't want to give all the new janitors your key ring. So they roll out a new system which says "now the keys can only open doors that we have written down that this key can open, even if it says "executive_floor/admin". The problem is people move offices all the time, so even if the list of what doors that key opened was true when it was issued, it's not true tomorrow. The Security team and HR share a list, but the list sometimes drifts or maybe someone moves offices without telling the right people. </p><p>Soon nobody is really 100% sure what you can or cannot open, including you. Sure someone can audit it and figure it out, but the risk of removing access means you cannot do your job and the office doesn't get cleaned. So practically speaking the longer someone works as a janitor the more doors they can open until eventually they have the same level of access as your original master key even if that wasn't the intent. </p><p>That's IAM (Identity and access management) in cloud providers today. </p><h3 id="stare-into-madness">Stare Into Madness</h3><figure><img src="https://docs.aws.amazon.com/images/IAM/latest/UserGuide/images/PolicyEvaluationHorizontal111621.png" alt="" loading="lazy"><figcaption><span>AWS IAM Approval Flow</span></figcaption></figure><figure><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_copy_3.max-2000x2000.jpg" alt="" loading="lazy"><figcaption><span>GCP IAM Approval Flow</span></figcaption></figure><figure><img src="https://images.fastcompany.com/upload/Simple.jpg" alt="It's Not Natural, It's Just Simple: Food Branding Co-Opts Another Mean" loading="lazy"></figure><p>Honestly I don't even know why I'm complaining. Of course it's entirely reasonable to expect anyone working in a cloud environment to understand the dozen+ ways that they may or may not have access to a particular resource. Maybe they have permissions at a folder level, or an org level, but that permission is gated by specific resources. </p><p>Maybe they don't even have access but the tool they're interacting with the resource with has permission to do it, so they can do it but only as long as they are SSH'd into host01, not if they try to do it through some cloud shell. Possibly they had access to it before, but now they don't since they moved teams. Perhaps the members of this team were previously part of some existing group but now new employees aren't added to that group so some parts of the team can access X but others cannot. Or they actually have the correct permissions to the resource but the resource is located in another account and they don't have the right permission to traverse the networking link between the two VPCs.</p><p>Meanwhile someone is staring at these flowcharts trying to figure out what in hell is even happening here. As someone who has had to do this multiple times in my life, let me tell you the real-world workflow that ends up happening. </p><ul><li>Developer wants to launch a new service using new cloud products. They put in a ticket for me to give them access to the correct "roles" to do this. </li><li>I need to look at two elements of it, both what are the permissions the person needs in order to see if the thing is working and then the permissions the service needs in order to complete the task it is trying to complete. </li><li>So I go through my giant list of roles and try to cobble together something that I think based on the names will do what I want. Do you feel like a <code>roles/datastore.viewer</code> or more of a <code>roles/datastore.keyVisualizerViewer</code>? To run backups is <code>roles/datastore.backupsAdmin</code> sufficient or do I need to add <code>roles/datastore.backupSchedulesAdmin</code> in there as well?</li><li>They try it and it doesn't work. Reopen the ticket with "I still get authorizationerror:foo". I switch that role with a different role, try it again. Run it through the simulator, it seems to work, but they report a new different error because actually in order to use service A you need to also have a role in service B. Go into bathroom, scream into the void and return to your terminal.</li><li>We end up cobbling together a custom role that includes all the permissions that this application needs and the remaining 90% of permissions are something it will never ever use but will just sit there as a possible security hole. </li><li>Because /* permissions are the work of Satan, I need to scope it to specific instances of that resource and just hope nobody ever adds a SQS queue without....checking the permissions I guess. In theory we should catch it in the non-prod environments but there's always the chance that someone messes up something at a higher level of permissions that does something in non-prod and doesn't exist in prod so we'll just kinda cross our fingers there. </li></ul><h3 id="gcp-makes-it-worse">GCP Makes It Worse</h3><p>So that's effectively the AWS story, which is terrible but at least it's possible to cobble together something that works and you can audit. Google looked at this and said "what if we could express how much we hate Infrastructure teams as a service?" Expensive coffee robots were engaged, colorful furniture was sat on and the brightest minds of our generation came up with a system so punishing you'd think you did something to offend them personally. </p><p>Google looked at AWS and said "this is a tire fire" as corporations put non-prod and prod environments in the same accounts and then tried to divide them by conditionals. So they came up with a folder structure:</p><figure><img src="https://infosec.rodeo/assets/img/blog/gcp_resource_hierarchy.png" alt="GCP Resource Hierarchy" loading="lazy"></figure><p>The problem is that this design encourages unsafe practices by promoting "groups should be set at the folder level with one of the default basic roles". It makes sense logically at first that you are a viewer, editor or owner. But as GCP adds more services this model breaks down quickly because each one of these encompasses thousands upon thousands of permissions. So additional IAM predefined roles were layered on. </p><p>People were encouraged to move away from the basic roles and towards the predefined roles. There are ServiceAgent roles that were designated for service accounts, aka the permissions you actual application has and then everything else. Then there are 1687 other roles for you to pick from to assign to your groups of users. </p><figure><img src="https://matduggan.com/content/images/2024/03/image-2.png" alt="" loading="lazy" width="860" height="334" srcset="https://matduggan.com/content/images/size/w600/2024/03/image-2.png 600w, https://matduggan.com/content/images/2024/03/image-2.png 860w" sizes="(min-width: 720px) 720px"></figure><p>The problem is none of this is actually best practice. Even when assigning users "small roles", we're still not following the principal of least privilege. Also the roles don't remain static. As new services come online permissions are added to roles. </p><figure><img src="https://matduggan.com/content/images/2024/03/image-4.png" alt="" loading="lazy" width="2000" height="1254" srcset="https://matduggan.com/content/images/size/w600/2024/03/image-4.png 600w, https://matduggan.com/content/images/size/w1000/2024/03/image-4.png 1000w, https://matduggan.com/content/images/size/w1600/2024/03/image-4.png 1600w, https://matduggan.com/content/images/size/w2400/2024/03/image-4.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>The above is an automated process that pulls down all the roles from the gcloud CLI tool and updates them for latest. It is a constant state of flux with roles with daily changes. It gets even more complicated though. </p><p>You also need to check the launch stage of a role. </p><blockquote>Custom roles include a launch stage as part of the role's metadata. The most common launch stages for custom roles are ALPHA, BETA, and GA. These launch stages are informational; they help you keep track of whether each role is ready for widespread use. Another common launch stage is DISABLED. This launch stage lets you disable a custom role.</blockquote><blockquote>We recommend that you use launch stages to convey the following information about the role:</blockquote><blockquote>EAP or ALPHA: The role is still being developed or tested, or it includes permissions for Google Cloud services or features that are not yet public. It is not ready for widespread use.<br>BETA: The role has been tested on a limited basis, or it includes permissions for Google Cloud services or features that are not generally available.<br>GA: The role has been widely tested, and all of its permissions are for Google Cloud services or features that are generally available.<br>DEPRECATED: The role is no longer in use.</blockquote><h3 id="who-cares">Who Cares?</h3><p>Why would anyone care if Google is constantly changing roles? Well it matters because with GCP to make a custom role, you cannot combine predefined roles. Instead you need to go down to the permission level to list out all of the things those roles can do, then feed that list of permissions into the definition of your custom role and push that up to GCP. </p><p>In order to follow best practices this is what you have to do. Otherwise you will always be left with users that have a ton of unused permissions along with the fear of a security breach allowing someone to execute commands in your GCP account through an applications service account that cause way more damage than the actual application justifies. </p><p>So you get to build automated tooling which either queries the predefined roles for change over time and roll those into your custom roles so that you can assign a user or group one specific role that lets them do everything they need. Or you can assign these same folks multiple of the 1600+ predefined roles, accept that they have permissions they don't need and also just internalize that day to day you don't know how much the scope of those permissions have changed. </p><h3 id="the-obvious-solution">The Obvious Solution</h3><p>Why am I ranting about this? Because the solution is so blindly obvious I don't understand why we're not already doing it. It's a solution I've had to build, myself, multiple times and at this point am furious that this keeps being my responsibility as I funnel hundreds of thousands of dollars to cloud providers. </p><p>What is this obvious solution? You, an application developer, need to launch a new service. I give you a service account that lets you do almost everything inside of that account along with a viewer account for your user that lets you go into the web console and see everything. You churn away happily, writing code that uses all those new great services. Meanwhile, we're tracking all the permissions your application and you are using. </p><p>At some time interval, 30 or 90 or whatever days, my tool looks at the permissions your application has used over the last 90 days and says "remove the global permissions and scope it to these". I don't need to ask you what you need, because I can see it. In the same vein I do the same thing with your user or group permissions. You don't need viewer everywhere because I can see what you've looked at. </p><p>Both GCP and AWS support this and have all this functionality baked in. GCP has the <a href="https://cloud.google.com/policy-intelligence/docs/role-recommendations-overview" rel="noreferrer">role recommendations</a> which tracks exactly what I'm talking about and recommends lowering the role. <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_access-advisor.html" rel="noreferrer">AWS tracks the exact same information</a> and can be used to do the exact same thing. </p><p><strong>What if the user needs different permissions in a hurry?</strong></p><p>This is not actually that hard to account for and <em>again</em> is something I and countless others have been forced to make over and over. You can issue expiring permissions in both situations where a user can request a role be temporarily granted to them and then it disappears in 4 hours. I've seen every version of these, from Slack bots to websites, but they're all the same thing. If user is in X group they're allowed to request Y temporary permissions. OR if the user is on-call as determined with an API call to the on-call provider they get more powers. Either design works fine. </p><p><strong>That seems like a giant security hole</strong></p><p>Compared to what? Team A guessing what Team B needs even though they don't ever do the work that Team B does? Some security team receiving a request for permissions and trying to figure out if the request "makes sense" or not? At least this approach is based on actual data and not throwing darts at a list of IAM roles and seeing what "feels right". </p><h3 id="conclusion">Conclusion</h3><p>IAM started out as an easy idea that as more and more services were launched, started to become nightmarish to organize. It's too hard to do the right thing now and it's even harder to do the right thing in GCP compared to AWS. The solution is not complicated. We have all the tools, all the data, we understand how they fit together. We just need one of the providers to be brave enough to say "obviously we messed up and this legacy system you all built your access control on is bad and broken". It'll be horrible, we'll all grumble and moan but in the end it'll be a better world for us all. </p><p>Feedback: <a href="https://c.im/@matdevdug">https://c.im/@matdevdug</a></p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Matrix Multiplication with Half the Multiplications (230 pts)]]></title>
            <link>https://github.com/trevorpogue/algebraic-nnhw</link>
            <guid>39714053</guid>
            <pubDate>Fri, 15 Mar 2024 10:36:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/trevorpogue/algebraic-nnhw">https://github.com/trevorpogue/algebraic-nnhw</a>, See on <a href="https://news.ycombinator.com/item?id=39714053">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">This repository contains the source code for ML hardware architectures that require nearly half the number of multiplier units to achieve the same performance, by executing alternative inner-product algorithms that trade nearly half the multiplications for cheap low-bitwidth additions, while still producing identical output as the conventional inner product. This increases the theoretical throughput and compute efficiency limits of ML accelerators. See the following journal publication for the full details:</p>
<p dir="auto">T. E. Pogue and N. Nicolici, "Fast Inner-Product Algorithms and Architectures for Deep Neural Network Accelerators," in IEEE Transactions on Computers, vol. 73, no. 2, pp. 495-509, Feb. 2024, doi: 10.1109/TC.2023.3334140.</p>

<p dir="auto">Article URL: <a href="https://ieeexplore.ieee.org/document/10323219" rel="nofollow">https://ieeexplore.ieee.org/document/10323219</a></p>
<p dir="auto">Open-access version: <a href="https://arxiv.org/abs/2311.12224" rel="nofollow">https://arxiv.org/abs/2311.12224</a></p>
<p dir="auto">Abstract: We introduce a new algorithm called the Free-pipeline Fast Inner Product (FFIP) and its hardware architecture that improve an under-explored fast inner-product algorithm (FIP) proposed by Winograd in 1968. Unlike the unrelated Winograd minimal filtering algorithms for convolutional layers, FIP is applicable to all machine learning (ML) model layers that can mainly decompose to matrix multiplication, including fully-connected, convolutional, recurrent, and attention/transformer layers. We implement FIP for the first time in an ML accelerator then present our FFIP algorithm and generalized architecture which inherently improve FIP's clock frequency and, as a consequence, throughput for a similar hardware cost. Finally, we contribute ML-specific optimizations for the FIP and FFIP algorithms and architectures. We show that FFIP can be seamlessly incorporated into traditional fixed-point systolic array ML accelerators to achieve the same throughput with half the number of multiply-accumulate (MAC) units, or it can double the maximum systolic array size that can fit onto devices with a fixed hardware budget. Our FFIP implementation for non-sparse ML models with 8 to 16-bit fixed-point inputs achieves higher throughput and compute efficiency than the best-in-class prior solutions on the same type of compute platform.</p>
<p dir="auto">The following diagram shows an overview of the ML accelerator system implemented in this source code:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/12535207/285502293-11a7d485-04a3-4e9d-b9fb-91c35c80086f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1MTg3MDUsIm5iZiI6MTcxMDUxODQwNSwicGF0aCI6Ii8xMjUzNTIwNy8yODU1MDIyOTMtMTFhN2Q0ODUtMDRhMy00ZTlkLWI5ZmItOTFjMzVjODAwODZmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMTUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzE1VDE2MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNjZTJkM2MyZDdkODdkNDZlODg3NTJkZDcyZmYzNjhhMzJiYmM1NzRlNDk3MjM3YTM3MzMwMjNkODllOTdiZGUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.9a6yVkzLncS7pXRGFoxzDOrjm01sfCz7jQEFtOGf5oE"><img src="https://private-user-images.githubusercontent.com/12535207/285502293-11a7d485-04a3-4e9d-b9fb-91c35c80086f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1MTg3MDUsIm5iZiI6MTcxMDUxODQwNSwicGF0aCI6Ii8xMjUzNTIwNy8yODU1MDIyOTMtMTFhN2Q0ODUtMDRhMy00ZTlkLWI5ZmItOTFjMzVjODAwODZmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMTUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzE1VDE2MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNjZTJkM2MyZDdkODdkNDZlODg3NTJkZDcyZmYzNjhhMzJiYmM1NzRlNDk3MjM3YTM3MzMwMjNkODllOTdiZGUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.9a6yVkzLncS7pXRGFoxzDOrjm01sfCz7jQEFtOGf5oE" width="450"></a></p>
<p dir="auto">The FIP and FFIP systolic array/MXU processing elements (PE)s shown below in (b) and (c) implement the FIP and FFIP inner-product algorithms and each individually provide the same effective computational power as the two baseline PEs shown in (a) combined which implement the baseline inner product as in previous systolic-array ML accelerators:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/12535207/300184475-d9b956a2-25fa-4173-8ba9-8fd27d02f0c1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1MTg3MDUsIm5iZiI6MTcxMDUxODQwNSwicGF0aCI6Ii8xMjUzNTIwNy8zMDAxODQ0NzUtZDliOTU2YTItMjVmYS00MTczLThiYTktOGZkMjdkMDJmMGMxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMTUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzE1VDE2MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRkMWY4NjIyODBkNDAwNjExNzZkZTJiMmJiZDk0YTRlY2I1Zjk0MDE1YjZlM2UyMGNiMzIyYzA1NjQyZGY0OTcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.433P7aTz05yurSzH_kAJDMyMGRZZAi1IUDxKuesO_zU"><img src="https://private-user-images.githubusercontent.com/12535207/300184475-d9b956a2-25fa-4173-8ba9-8fd27d02f0c1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1MTg3MDUsIm5iZiI6MTcxMDUxODQwNSwicGF0aCI6Ii8xMjUzNTIwNy8zMDAxODQ0NzUtZDliOTU2YTItMjVmYS00MTczLThiYTktOGZkMjdkMDJmMGMxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMTUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzE1VDE2MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRkMWY4NjIyODBkNDAwNjExNzZkZTJiMmJiZDk0YTRlY2I1Zjk0MDE1YjZlM2UyMGNiMzIyYzA1NjQyZGY0OTcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.433P7aTz05yurSzH_kAJDMyMGRZZAi1IUDxKuesO_zU" width="450"></a></p>
<p dir="auto">The following is a diagram of the MXU/systolic array and shows how the PEs are connected:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/12535207/300986120-baf3e2f7-1767-49ec-811e-7cb44fac8d92.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1MTg3MDUsIm5iZiI6MTcxMDUxODQwNSwicGF0aCI6Ii8xMjUzNTIwNy8zMDA5ODYxMjAtYmFmM2UyZjctMTc2Ny00OWVjLTgxMWUtN2NiNDRmYWM4ZDkyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMTUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzE1VDE2MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBlYWRkZWQ0MjM3YWJkNWRkZjYyOGNmZTc5ZWQ1M2RkNjEyYmFiOGZjOWFkYTg4ZGZhNjlhNmUwOThkOTViNzEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QnLh8a3ntuJUB_ICABvi0rG-Czg0Yt2kVquJBTFXLZ0"><img src="https://private-user-images.githubusercontent.com/12535207/300986120-baf3e2f7-1767-49ec-811e-7cb44fac8d92.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTA1MTg3MDUsIm5iZiI6MTcxMDUxODQwNSwicGF0aCI6Ii8xMjUzNTIwNy8zMDA5ODYxMjAtYmFmM2UyZjctMTc2Ny00OWVjLTgxMWUtN2NiNDRmYWM4ZDkyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMTUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzE1VDE2MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBlYWRkZWQ0MjM3YWJkNWRkZjYyOGNmZTc5ZWQ1M2RkNjEyYmFiOGZjOWFkYTg4ZGZhNjlhNmUwOThkOTViNzEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QnLh8a3ntuJUB_ICABvi0rG-Czg0Yt2kVquJBTFXLZ0" width="450"></a></p>
<p dir="auto">The source code organization is as follows:</p>
<ul dir="auto">
<li>compiler
<ul dir="auto">
<li>A compiler for parsing Python model descriptions into accelerator instructions that allow it to accelerate the model. This part also includes code for interfacing with a PCIe driver for initiating model execution on the accelerator, reading back results and performance counters, and testing the correctness of the results.</li>
</ul>
</li>
<li>rtl
<ul dir="auto">
<li>Synthesizable SystemVerilog RTL.</li>
</ul>
</li>
<li>sim
<ul dir="auto">
<li>Scripts for setting up simulation environments for testing.</li>
</ul>
</li>
<li>tests
<ul dir="auto">
<li>UVM-based testbench source code for verifying the accelerator in simulation using Cocotb.</li>
</ul>
</li>
<li>utils
<ul dir="auto">
<li>Additional Python packages and scripts used in this project that the author created for general development utilities and aids.</li>
</ul>
</li>
</ul>
<p dir="auto">The files rtl/top/define.svh and rtl/top/pkg.sv contain a number of configurable parameters such as FIP_METHOD in define.svh which defines the systolic array type (baseline, FIP, or FFIP), SZI and SZJ which define the systolic array height/width, and LAYERIO_WIDTH/WEIGHT_WIDTH which define the input bitwidths.</p>
<p dir="auto">The directory rtl/arith includes mxu.sv and mac_array.sv which contain the RTL for the baseline, FIP, and, FFIP systolic array architectures (depending on the value of the parameter FIP_METHOD).</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking (250 pts)]]></title>
            <link>https://arxiv.org/abs/2403.09629</link>
            <guid>39713634</guid>
            <pubDate>Fri, 15 Mar 2024 09:24:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2403.09629">https://arxiv.org/abs/2403.09629</a>, See on <a href="https://news.ycombinator.com/item?id=39713634">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2403.09629">Download PDF</a>
    <a href="https://arxiv.org/html/2403.09629v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>When writing and talking, people sometimes pause to think. Although reasoning-focused works have often framed reasoning as a method of answering questions or completing agentic tasks, reasoning is implicit in almost all written text. For example, this applies to the steps not stated between the lines of a proof or to the theory of mind underlying a conversation. In the Self-Taught Reasoner (STaR, Zelikman et al. 2022), useful thinking is learned by inferring rationales from few-shot examples in question-answering and learning from those that lead to a correct answer. This is a highly constrained setting -- ideally, a language model could instead learn to infer unstated rationales in arbitrary text. We present Quiet-STaR, a generalization of STaR in which LMs learn to generate rationales at each token to explain future text, improving their predictions. We address key challenges, including 1) the computational cost of generating continuations, 2) the fact that the LM does not initially know how to generate or use internal thoughts, and 3) the need to predict beyond individual next tokens. To resolve these, we propose a tokenwise parallel sampling algorithm, using learnable tokens indicating a thought's start and end, and an extended teacher-forcing technique. Encouragingly, generated rationales disproportionately help model difficult-to-predict tokens and improve the LM's ability to directly answer difficult questions. In particular, after continued pretraining of an LM on a corpus of internet text with Quiet-STaR, we find zero-shot improvements on GSM8K (5.9%$\rightarrow$10.9%) and CommonsenseQA (36.3%$\rightarrow$47.2%) and observe a perplexity improvement of difficult tokens in natural text. Crucially, these improvements require no fine-tuning on these tasks. Quiet-STaR marks a step towards LMs that can learn to reason in a more general and scalable way.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Eric Zelikman [<a href="https://arxiv.org/show-email/094380da/2403.09629">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 14 Mar 2024 17:58:16 UTC (510 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sunlight, a Certificate Transparency log implementation (171 pts)]]></title>
            <link>https://letsencrypt.org/2024/03/14/introducing-sunlight.html</link>
            <guid>39713370</guid>
            <pubDate>Fri, 15 Mar 2024 08:37:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://letsencrypt.org/2024/03/14/introducing-sunlight.html">https://letsencrypt.org/2024/03/14/introducing-sunlight.html</a>, See on <a href="https://news.ycombinator.com/item?id=39713370">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	<article>
		<p><img alt="Logo for Sunlight" src="https://letsencrypt.org/images/blog/sunlight_logo_main.png">
</p>
<p>Let’s Encrypt is proud to introduce Sunlight, a new implementation of a Certificate Transparency log that we built from the ground up with modern Web PKI opportunities and constraints in mind. In partnership with <a href="https://filippo.io/">Filippo Valsorda</a>, who led the design and implementation, we incorporated feedback from the broader transparency logging community, including the Chrome and TrustFabric teams at Google, the Sigsum project, and other CT log and monitor operators. Their insights have been instrumental in shaping the project’s direction.</p>
<p>CT plays an important role in the Web PKI, enhancing the ability to monitor and research certificate issuance. The operation of a CT log, however, faces growing challenges with the increasing volume of certificates. For instance, Let’s Encrypt issues over four million certificates daily, each of which must be logged in two separate CT logs. Our well-established “Oak” log currently holds over 700 million entries, reflecting the significant scale of these challenges.</p>
<p>In this post, we’ll explore the motivation behind Sunlight and how its design aims to improve the robustness and diversity of the CT ecosystem, while also improving the reliability and performance of Let’s Encrypt’s logs.</p>
<h2 id="bottlenecks-from-the-database">Bottlenecks from the Database</h2>
<p>Let’s Encrypt has been <a href="https://letsencrypt.org/docs/ct-logs/">running public CT logs</a> since 2019, and we’ve gotten a lot of operational experience with running them, but it hasn’t been trouble-free. The biggest challenge in the architecture we’ve deployed for our “Oak” log is that the data is stored in a relational database. We’ve <a href="https://letsencrypt.org/2022/05/19/nurturing-ct-log-growth">scaled that up</a> by splitting each year’s worth of data into a “shard” with its own database, and then later shrinking the shards to cover six months instead of a full year.</p>
<p>The approach of splitting into more and more databases is not something we want to continue doing forever, as the operational burden and costs increase. The current storage size of a CT log shard is between 5 and 10 terabytes. That’s big enough to be concerning for a single database: We previously had a test log fail when we ran into a <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MySQL.KnownIssuesAndLimitations.html#MySQL.Concepts.Limits.FileSize">16TiB limit</a> in MySQL.</p>
<p>Scaling read capacity up requires large database instances with fast disks and lots of RAM, which are not cheap. We’ve had numerous instances of CT logs becoming overloaded by clients attempting to read all the data in the log, overloading the database in the process. When rate limits are imposed to prevent overloading, clients are forced to slowly crawl the API, diminishing CT’s efficiency as a fast mechanism for detecting mis-issued certificates.</p>
<h2 id="serving-tiles">Serving Tiles</h2>
<p>Initially, Let’s Encrypt only planned on building a new CT log implementation. However, our discussions with Filippo made us realize that other transparency systems had improved on the original Certificate Transparency design, and we could make our logs even more robust and scalable by changing the read path APIs. In particular, the <a href="https://golang.org/design/25530-sumdb">Go Checksum Database</a> is inspired by Certificate Transparency, but uses a more efficient format for publishing its data as a series of easily stored and cached tiles.</p>
<p>Certificate Transparency logs are a binary tree, with every node containing a hash of its two children. The “leaf” level contains the actual entries of the log: the certificates, appended to the right side of the tree. The top of the tree is digitally signed. This forms a cryptographically verifiable structure called a Merkle Tree, which can be used to check if a certificate is in the tree, and that the tree is append-only.</p>
<p>Sunlight tiles are files containing 256 elements each, either hashes at a certain tree “height” or certificates (or pre-certificates) at the leaf level. Russ Cox has a great explanation <a href="https://research.swtch.com/tlog#tiling_a_log">of how tiles work on his blog</a>, or you can read <a href="https://c2sp.org/sunlight#merkle-tree">the relevant section of the Sunlight specification</a>. Even Trillian, the current implementation of CT we run, <a href="https://github.com/google/trillian/blob/master/docs/storage/storage.md">uses a subtree system</a> similar to these tiles as its internal storage.</p>
<p>Unlike the dynamic endpoints in previous CT APIs, serving a tree as tiles doesn’t require any dynamic computation or request processing, so we can eliminate the need for API servers. Because the tiles are static, they’re efficiently cached, in contrast with CT APIs like get-proof-by-hash which have a different response for every certificate, so there’s no shared cache. The leaf tiles can also be stored compressed, saving even more storage!</p>
<p>The idea of exposing the log as a series of static tiles is motivated by our desire to scale out the read path horizontally and relatively inexpensively. We can directly expose tiles in cloud object storage like S3, use a caching CDN, or use a webserver and a filesystem.</p>
<p>Object or file storage is readily available, can scale up easily, and costs significantly less than databases from cloud providers. It seemed like the obvious path forward. In fact, we already have an S3-backed cache in front of our existing CT logs, which means we are currently storing our data twice.</p>
<h2 id="running-more-logs">Running More Logs</h2>
<p>The tiles API improves the read path, but we also wanted to simplify our architecture on the write path. With Trillian, we run a collection of nodes along with etcd for leader election to choose which will handle writing. This is somewhat complex, and we believe the CT ecosystem allows a different tradeoff.</p>
<p>The key realization is that Certificate Transparency is already a distributed system, with clients submitting certificates to multiple logs, and gracefully failing over from any unavailable ones to the others. Each individual log’s write path doesn’t require a highly available leader election system. A simple single-node writer can meet the 99% Service Level Objective of a CT log.</p>
<p>The single-node Sunlight architecture lets us run multiple independent logs with the same amount of computing power. This increases the system’s overall robustness, even if each individual log has lower potential uptime. No more leader election needed. We use a simple compare-and-swap mechanism to store checkpoints and prevent accidentally running two instances at once, which could result in a forked tree, but that has much less overhead than leader election.</p>
<h2 id="no-more-merge-delay">No More Merge Delay</h2>
<p>One of the goals of CT was to have limited latency for submission to the logs. A design feature called Merge Delay was added to support that. When submitting a certificate to a log, the log can return a Signed Certificate Timestamp (SCT) immediately, with a promise to include it in the log within the log’s Maximum Merge Delay, conventionally 24 hours. While this seems like a good tradeoff to not slow down issuance, there have been multiple incidents and near-misses where a log stops operating with unmerged certificates, missing its maximum merge delay, and breaking that promise.</p>
<p>Sunlight takes a different approach, holding submissions while it batches and integrates certificates in the log, eliminating the merge delay. While this leads to a small latency increase, we think it’s worthwhile to avoid one of the more common CT log failure cases.</p>
<p>It also lets us embed the final leaf index in an extension of our SCTs, bringing CT a step closer to direct client verification of Merkle tree proofs. The extension also makes it possible for clients to fetch the proof of log inclusion from the new static tile-based APIs, without requiring server-side lookup tables or databases.</p>
<h2 id="a-sunny-future">A Sunny Future</h2>
<p>Today’s announcement of Sunlight is just the beginning. We’ve released <a href="https://github.com/FiloSottile/sunlight">software</a> and a <a href="https://c2sp.org/sunlight">specification</a> for Sunlight, and have Sunlight CT logs running. Head to <a href="https://sunlight.dev/">sunlight.dev</a> to find resources to get started. We encourage CAs to start test submitting to <a href="https://letsencrypt.org/docs/ct-logs/#Sunlight">Let’s Encrypt’s new Sunlight CT logs</a>, for CT Monitors and Auditors to add support for consuming Sunlight logs, and for the CT programs to consider trusting logs running on this new architecture. We hope Sunlight logs will be made usable for SCTs by the CT programs run by the browsers in the future, allowing CAs to rely on them to meet the browser CT logging requirements.</p>
<p>We’ve gotten positive feedback so far, with comments such as “Google’s TrustFabric team, maintainers of Trillian, are supportive of this direction and the Sunlight spec. We have been working towards the same goal of cacheable tile-based logs for other ecosystems with <a href="https://github.com/transparency-dev/serverless-log">serverless tooling</a>, and will be folding this into Trillian and ctfe, along with adding support for the Sunlight API.”</p>
<p>If you have feedback on the design, please join in the conversation on the <a href="https://groups.google.com/a/chromium.org/g/ct-policy">ct-policy mailing list</a>, or in the <a href="https://transparency-dev.slack.com/archives/C06PCS2P75Y">#sunlight</a> channel on the transparency-dev Slack (<a href="https://join.slack.com/t/transparency-dev/shared_invite/zt-27pkqo21d-okUFhur7YZ0rFoJVIOPznQ">invitation</a> to join).</p>
<p>We’d like to thank Chrome for supporting the development of Sunlight, and Amazon Web Services for their ongoing support for our CT log operation. If your organization monitors or values CT, please consider a financial gift of support. Learn more at <a href="https://www.abetterinternet.org/sponsor/">https://www.abetterinternet.org/sponsor/</a> or contact us at: <a href="mailto:sponsor@abetterinternet.org">sponsor@abetterinternet.org</a>.</p>

	</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Berlin's techno scene added to Unesco intangible cultural heritage list (367 pts)]]></title>
            <link>https://www.theguardian.com/world/2024/mar/15/berlins-techno-scene-added-to-unesco-intangible-cultural-heritage-list</link>
            <guid>39713323</guid>
            <pubDate>Fri, 15 Mar 2024 08:29:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/2024/mar/15/berlins-techno-scene-added-to-unesco-intangible-cultural-heritage-list">https://www.theguardian.com/world/2024/mar/15/berlins-techno-scene-added-to-unesco-intangible-cultural-heritage-list</a>, See on <a href="https://news.ycombinator.com/item?id=39713323">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Germany’s culture ministry and Unesco commission have added Berlin’s techno scene to the country’s list of intangible cultural heritage, in recognition of the scene’s contribution to the cultural identity of the city.</p><p>Berlin’s Clubcommission, a network for Berlin’s techno clubs and musicians, <a href="https://twitter.com/clubcommission/status/1767979957173580132" data-link-name="in body link">described</a> the move as “another milestone for Berlin techno producers, artists, club operators and event organisers”.</p><p>Lutz Leichsenring, an executive member of Clubcommission’s board, <a href="https://www.dw.com/en/berlin-techno-added-to-unesco-cultural-heritage-list/a-68515354" data-link-name="in body link">told the German broadcaster DW</a>: “The decision will help us ensure that club culture is recognised as a valuable sector worthy of protection and support.”</p><p>For more than a decade there has been a campaign to have techno culture and music added to Germany’s list, spearheaded by Rave the Planet, a non-profit supporting electronic music culture.</p><p>“Congratulations to all the cultural creators who have shaped and contributed to Berlin’s techno culture,” the group said in a statement on social media. “This is a major milestone for the entire culture, and our joy is beyond words.”</p><p>Rave the Planet submitted the application for techno to be included in the list in November 2022.</p><p>Intangible cultural heritage status is more commonly granted to more traditional cultural activities, such as Malawian Mwinoghe dancing or Slovakian bagpipe culture. The recent recognition on Unesco’s list of intangible cultural heritage of Jamaican reggae and India’s huge Kumbh Mela festival, however, prompted techno community leaders in Berlin to campaign for their scene to be included in Germany’s register, which is separate to the Unesco list.</p><p>Techno is a fundamental part of the city, according to Peter Kirn, a Berlin-based DJ and music producer. In 2021 he told the Observer: “In other cities, people wouldn’t accept music that’s really hard or weird and full of synthesisers and really brutal, distorted drum machines. You can’t play that at peak hour in a club, let alone over lunch. And here it’s totally acceptable to play that over lunch.</p><p>“Techno has become a refuge for people who are marginalised, and there’s a natural attraction to Berlin as a place which is more permissive when you come from places that are less permissive.”</p><p>The techno scene is one of six new entries on the intangible cultural heritage list in Germany; others include fruit wine and mountaineering. A parade in Bavaria known as the <em>Kirchseeoner Perchtenlauf</em>, where attenders dress as furry monsters, was also added to the list.</p></div><div><p><span data-dcr-style="bullet"></span> The headline and text of this article were amended on 15 March 2024. The techno scene has been added to the national intangible cultural heritage list compiled by the German commission for Unesco, not the global intangible cultural heritage list compiled by Unesco as an earlier version indicated.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I figured out how DMARC works, and it almost broke me (101 pts)]]></title>
            <link>https://simonandrews.ca/articles/how-to-set-up-spf-dkim-dmarc</link>
            <guid>39712634</guid>
            <pubDate>Fri, 15 Mar 2024 06:35:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonandrews.ca/articles/how-to-set-up-spf-dkim-dmarc">https://simonandrews.ca/articles/how-to-set-up-spf-dkim-dmarc</a>, See on <a href="https://news.ycombinator.com/item?id=39712634">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>How to prevent email spoofing on your domain, using an unholy combination of silly standards.</p><p>Recently, I encountered a problem. My domain didn't correctly implement SPF, DKIM, or DMARC.</p><p>Then, I encountered a second problem: I had no idea what those were, and seemingly <em>nobody</em> has written about SPF, DKIM, or DMARC in a way that a human can understand, not to mention implement. Every article I found was either highly technical, trying to game SEO to sell me something, or too high level to be useful.</p><p>As a result, I've had to do a lot of hard work and research to understand this problem. Hopefully, because I had to do this, you won't.</p><p>There's two main sections here: a human explanation of what these things are, followed by a reasonably straightforward way to implement them.</p><p>This might not be easy, but if you've landed here, it's probably not optional. I hope this helps.</p><p><em>I'm keeping this article up-to-date as I learn more, so it'll change and grow. If you want to keep track of what's changed since the last time you were here, <a href="https://github.com/simon360/simonandrews.ca/commits/main/pages/articles/how-to-set-up-spf-dkim-dmarc.mdx">check the diffs on GitHub</a>.</em></p><h2 id="table-of-contents">Table of contents</h2><ul><li><p><a href="#what-are-these-weird-acronyms">What are these weird acronyms?</a></p><ul><li><p><a href="#spf">SPF</a></p><ul><li><a href="#on-envelopes-vs-letters">On envelopes vs. letters</a></li></ul></li><li><p><a href="#dkim">DKIM</a></p></li><li><p><a href="#dmarc">DMARC</a></p><ul><li><a href="#lets-talk-about-alignment">Let's talk about alignment</a></li></ul></li></ul></li><li><p><a href="#how-do-i-use-them">How do I use them?</a></p><ul><li><p><a href="#implement-spf">Implement SPF</a></p><ul><li><a href="#main-takeaway">Main takeaway</a></li><li><a href="#resources">Resources</a></li></ul></li><li><p><a href="#implement-dkim">Implement DKIM</a></p><ul><li><a href="#main-takeaway-1">Main takeaway</a></li><li><a href="#resources-1">Resources</a></li></ul></li><li><p><a href="#implement-dmarc">&nbsp;Implement DMARC</a></p><ul><li><a href="#the-lenient-policy">The lenient policy</a></li><li><a href="#sit-back-and-watch">Sit back and watch</a></li><li><a href="#increase-the-strictness">Increase the strictness</a></li><li><a href="#resources-2">Resources</a></li></ul></li></ul></li><li><p><a href="#troubleshooting">Troubleshooting</a></p><ul><li><a href="#not-receiving-reports-you-might-need-edv">Not receiving reports? You might need EDV</a></li></ul></li><li><p><a href="#wrapping-up">Wrapping up</a></p><ul><li><a href="#corrections">Corrections</a></li></ul></li></ul><h2 id="what-are-these-weird-acronyms">What are these weird acronyms?</h2><p>SPF, DKIM, and DMARC are complementary systems. SPF and DKIM are used by email servers as indicators of whether or not an email is spam. DMARC then does two things: it tells email servers how <em>important</em> SPF and DKIM are, <em>and</em> what to do when an email fails to pass their tests.</p><p>This probably doesn't make much sense yet - that's fine. Let's dig a little deeper.</p><h3 id="spf">SPF</h3><p><code>SPF</code> is a way to declare who's allowed to send emails from your domain. It stands for the "sender policy framework," but you don't need to know that. Just call it SPF, or "spoof." It's meant to make it harder to send spoof emails.</p><p>For example, it's a way to say "emails from mycompany.com can only be sent from Google and Postmark." Declaring SPF makes it harder for me to send emails from your domain in an attempt to phish.</p><p>Here's how it works, for a <em>valid, non-phishing</em> email:</p><ol><li>I send an email to you from <code>hello@sadl.io</code>, using my Fastmail SMTP server.</li><li>Gmail (your email service) receives the email.</li><li>The email is from someone at <code>sadl.io</code>, so Gmail grabs the DNS records for <code>sadl.io</code></li><li><code>sadl.io</code> has a DNS record that declares its SPF policy. It says that emails can be sent from Fastmail.</li><li>This email was sent from Fastmail, so it passes the SPF test.</li><li>The email lands in your inbox.</li></ol><p>That's all great! <code>SPF</code> hasn't stopped me from sending a real email to you. But it seems pretty simple. So... what <em>would</em> it stop?</p><p>Emails are notoriously easy to spoof. To me, even though I haven't written PHP in years, <em>nothing</em> demonstrates this more simply than this PHP script:</p><pre><code><span><span>&lt;?php</span>

<span>// Adapted from this vulnerability report: https://hackerone.com/reports/34112</span>

<span>$to</span> <span>=</span> <span>"employee@example.com"</span><span>;</span> <span>// Try to phish an employee of example.com</span>
<span>$headers</span> <span>=</span> <span>"From: payroll@example.com"</span><span>;</span> <span>// Pretend I'm example.com's payroll account</span>

<span>$subject</span> <span>=</span> <span>"Verify your bank details for your paycheque"</span><span>;</span> <span>// You can see where this is going...</span>
<span>$txt</span> <span>=</span> <span>"Hi Simon, we're updating our payroll software, and in order to continue receiving your paycheque, we'll need you to enter your details here: http://nefarious-payroll-software.com."</span><span>;</span>

<span>mail</span><span>(</span><span>$to</span><span>,</span> <span>$subject</span><span>,</span> <span>$txt</span><span>,</span> <span>$headers</span><span>)</span><span>;</span> <span>// Yikes.</span>
</span></code></pre><p>This script sends an email to <code>employee@example.com</code>, which looks like it comes from <code>payroll@example.com</code>, and asks the employee to enter their banking details. It's a pretty compelling email, and could probably get a few people to, at least, click the link - or worse.</p><p>You could run this script <em>right now</em>, and if <code>example.com</code> hasn't set up SPF, an email might actually reach the inbox of <code>employee@example.com</code>.</p><p>Seriously, it's that simple. We've all learned this at one time or another: emails are easy to spoof. It's always been just a cost of doing business. "You can't stop spoofers! Email is too complicated to fix!" are probably things you've heard, or said. We shove it to the back of our minds. We know emails are insecure, but we use them anyway. Turns out that's not entirely true. SPF can actually start to help cut down on spoofing.</p><p>If SPF were set up, here's what would happen when that script runs:</p><ol><li>An email gets sent to <code>employee@example.com</code>.</li><li>This email gets received by Google, who run the mail server for <code>example.com</code></li><li>Since it's an email from <code>example.com</code>, Google gets the DNS records for <code>example.com</code></li><li><code>example.com</code> has an SPF policy declared, which states that emails can only be sent from Google.</li><li>This email wasn't sent from Google; it was sent from a local mail server.</li><li>Since the sending domain doesn't match a domain that's allowed by <code>example.com</code>, the email is marked as spam. <em>Maybe</em>.</li></ol><p>Wait... <em>maybe</em>? Yeah. SPF sounds great in principle. But it often has no effect without DMARC. We'll get to that, but suffice to say: if you've just set up SPF, it's mostly informational. Some email servers <em>might</em> use it, but they might not treat it with much importance. DMARC lets you increase its importance.</p><h4 id="on-envelopes-vs-letters">On envelopes vs. letters</h4><p>This section gets even weirder, but bear with me. You might want to skim this now, read the rest of the article, and come back to it again after. It makes a lot more sense once you understand DMARC alignment, but we're not there yet. Alright. Here goes.</p><p>First off: shout out to Liam, who correctly pointed out an inaccuracy with this description of SPF. SPF <em>actually</em> checks the validity of the "envelope from", not "from".</p><p>Liam pointed me to an article that explains the difference between two things: an email (think of it as a letter), and the SMTP interactions that transport that letter (an envelope). It's from XEAMS, and you can (and should!) <a href="https://www.xeams.com/difference-envelope-header.htm">read it here</a>. But I'll paraphrase it:</p><p>The <strong>email</strong> is what you see in your client. It includes the message body, and a whole bunch of headers. Those headers include the <code>From</code> header, which we spoofed in that PHP script, as well as the email subject, DKIM headers (we'll get to those in a moment!) and a whole bunch of other headers. Most email headers are soft-hidden from users by their email clients, but you can always view them - in your email client, whether it's an app or a website, you'll probably be able to find a menu item called "View original" or "View raw message". That'll show you what an email <em>really</em> is. But it doesn't show you the envelope.</p><p>The <strong>envelope</strong> is what happens at the SMTP level. I'll defer to the XEAMS article on what SMTP looks like, but in effect: the <em>envelope</em> can contain a <em>completely</em> different <code>MAIL FROM</code> email address than the email's <code>From</code> header.</p><p>You'll hear a few different terms thrown around to describe the SMTP <code>MAIL FROM</code> command: envelope from, return to, bounce address. They're all the same thing. I like "envelope from" colloquially, because the analogy is clever, but I think it's useful to know that it comes from the SMTP protocol command used to deliver your email.</p><p>Which brings us to this: SPF <em>doesn't actually care about the From header in your email</em>. It only cares about the <code>MAIL FROM</code> value.</p><p>Later on, we'll talk about DMARC alignment. But here's a spoiler: with DMARC alignment, DKIM notwithstanding, you're saying "in order for an email to be valid, the FROM address has to pass SPF, and the domain in the From <em>header</em> has to be the same as the domain in the FROM address." In effect, it makes that PHP spoofing example run <em>roughly</em> the way you'd expect, but it takes a bit of a circuitous route to get there.</p><p>I've left this inaccuracy in the above section. Why? Well... explaining the difference between envelope from and the From header has taken up as much space on this page as the explanation of SPF itself. If I explained this <em>first</em>, you'd be too far in the weeds by the time we get to the real example. Sorry for misleading you - but if it helps, I wrote the first version of this article not knowing the difference, and I still <em>essentially</em> got a decent understanding of SPF out of it.</p><h3 id="dkim">DKIM</h3><p><code>DKIM</code> is a way to declare signing keys for emails from your domain. It stands for DomainKeys Identified Mail. Again... that doesn't matter. It's Dee-Kim. You can think of it as SPF's cryptographic cousin.</p><p>It means that an email server that receives an email can check if that email was sent by a server that knows a secret. Since it's public-key cryptography, there's two keys: a private one, held by your email sending server (SMTP) and known by no one else, and a public one, set in your DNS, which can be seen by <em>anybody</em> and used to determine if a signature was made using that secret key.</p><p>A domain can have multiple DKIM keys, by the way. That took me a long time to figure out. In all likelihood, most of the email sending services you use (Gmail, Office 365, Fastmail, Mailchimp, Postmark, Sendgrid, Mandrill, Postmark, or whatever) will provide a DKIM key you can add to your DNS records. If you add that key, you're authorising those services to send on behalf of your domain - it's similar to adding them in SPF, but instead of being about domains, it's about knowing a secret,</p><p>Here's how it works in a happy path:</p><ol><li>I send an email from <code>hello@sadl.io</code> to <code>somebody@gmail.com</code>.</li><li>This email goes through my Fastmail SMTP server in order to be sent.</li><li>The Fastmail SMTP server generates a signature using the secret key, and attaches it to the email, then sends it to <code>example.com</code>'s receiving server.</li><li>The Google email server receives this email. It's from <code>sadl.io</code>, so it gets the DNS records.</li><li>The email has a signature embedded, and the DNS records for <code>sadl.io</code> declare a few public DKIM keys which can be used to verify that signature.</li><li>One of those DKIM keys matches the one used to make this signature - specifically, the one that Fastmail provides. So the DKIM test passes.</li><li>The email lands in <code>somebody@gmail.com</code>'s inbox.</li></ol><p>The unhappy path here is fairly straightforward. You could use the same PHP script from the SPF section. Here's what would happen:</p><ol><li>I run this script. An email gets sent to <code>employee@example.com</code>.</li><li>This email gets received by Google, who run the mail server for <code>example.com</code></li><li>Since it's an email from <code>example.com</code>, Google gets the DNS records for <code>example.com</code></li><li>The <code>SPF</code> test fails. But that <em>might</em> be ok, because <code>example.com</code> declares some DKIM keys in its DNS records.</li><li>This email doesn't have a signature attached. So none of those DKIM keys are useful. (Alternative: the email <em>does</em> have a signature attached, but it doesn't match the signature that would be generated by any of the public keys on <code>example.com</code>).</li><li>Since the email failed the SPF test <em>and</em> the DKIM test, it's marked as spam. <em>Maybe</em>.</li></ol><p>Yup. Once again: <em>maybe</em>. An email could fail <em>both</em> of these tests, and still land in a user's inbox. You've put all this work in, and <em>still</em>, your email domain can be spoofed with 5 lines of <em>incredibly basic</em> PHP.</p><p>If you're me, it's taken hours to get to this point. You're dejected and demotivated. Everything you've tried has been hard to understand, and required a bunch of research. You've nervously updated DNS records, afraid that you're going to break your organisation's email services - only to discover that, on the contrary, you've effectively accomplished nothing. Everything is terrible. You briefly reconsider your career choices.</p><p>There's one acronym left on your list of things to implement: DMARC. Another miserable email security practice to implement, and - you expect - one more solution that leads to a dead end.</p><p>Alright. Fine. Screw it. Let's get into it. But if this doesn't work, I give up.</p><h3 id="dmarc">DMARC</h3><p>I have good news for you. DMARC <em>will</em> make SPF and DKIM work better.</p><p>But there's some bad news, too: it's a bit complicated, and requires some more infrastructure.</p><p>So, what is DMARC? At its core, it's actually two things, packaged up into one DNS record:</p><ol><li>It's a policy, which declares what email servers should do when an email fails SPF and DKIM tests</li><li>It's a reporting system, so that you can figure out who is trying to spoof your domain</li></ol><p>You're probably more interested in 1, but 2 is super important. To understand why, let's talk about why SPF and DKIM don't do the thing you thought they did.</p><p>Emails are complicated. If you haven't come to that conclusion by this point, I'd like to talk to you. It's an old system that's held together by a bazillion standards that have been written over decades. People do unexpected things with emails. There are intricate systems that were set up in the 90s that still run, unobstructed, on top of email.</p><p>Changing how emails works tends to break things. And that's what SPF and DKIM do.</p><p>SPF and DKIM are used as <em>indicators</em> of whether an email is spoofed or not. But if you added an SPF record on your domain, and you forget to add one of your email systems - say, Postmark, which you use to send mission-critical notifications from your application to your customers - then your customers could stop getting emails. If you added DKIM keys to your domain, but one of your email services doesn't support DKIM - or you forgot to add DKIM keys for that service - your customers could stop getting emails.</p><p>But they <em>don't</em> stop getting emails. Some emails will fail both SPF <em>and</em> DKIM, and still end up in users' inboxes. It's entirely at the discretion of the receiving email server, and they can be quite lenient. That's good for the services you forgot to add, but it's bad for the spoofers you're trying to squash.</p><p>You want to do two things:</p><ol><li>Find out what services you misconfigured, so you can fix them.</li><li>Stop spoofers from abusing your domain.</li></ol><p>The "reporting" part of DMARC helps you, in the early days of your email domain security endeavour, figure out what services you misconfigured and need to update. You can enable the reporting part, <em>without</em> enforcing a strict SPF/DKIM policy. In other words: you can use DMARC to find out about emails sent from your domain that <em>would</em> fail the SPF/DKIM tests, <em>without</em> telling email servers that all emails failing those tests should be marked as spam.</p><p>Once you're satisfied that you've configured everything, and all the reports you get are for spoof emails, you can update your policy to tell email servers that those tests are now important. It gives you a bit of time to validate and test, before you switch over to enforcing your SPF/DKIM rules.</p><p>Implementing DMARC goes something like this:</p><ol><li>Read this article, bash your head against a wall, openly weep.</li><li>Implement a lenient DMARC record in your domain's DNS, so that you start getting reports.</li><li>Read through the reports you get over the next days and weeks. Check if any valid emails are getting flagged for failing DKIM or SPF. If they are, fix them.</li><li>Update your DMARC record to make it less lenient.</li></ol><p>Unfortunately, implementing DMARC is a process. When I started investigating this problem, I was hoping I could copy some good SPF, DKIM, and DMARC records, update them to match my domains, and implement them, all within an hour or two. That's not how it works. This takes some effort, and you need to let some time elapse.</p><p>In other words: email is complicated.</p><p>Luckily, as I said, I've done the hard work here, because I don't think <em>anybody</em> should have to figure this out on their own again. For you, this process will have to play out over the course of a few days or, more likely, a few weeks, but within a few minutes, you can be well on your way.</p><h4 id="lets-talk-about-alignment">Let's talk about alignment</h4><p>Here's the magic bit of DMARC, that makes all of this sing: it enforces <em>alignment</em> between either the <em>envelope from</em> (aka SMTP MAIL FROM) and the From header, <em>or</em> the domain on the DKIM signature and the From header. In both cases, the From header can be thought of as the anchor: it's the thing users see, so either SPF or DKIM needs to vouch that the From header is what it should be.</p><p>This finally does the thing we set out to do. That PHP script at the top will, now, only succeed in getting an email to the inbox if one of two things is true:</p><ol><li>The PHP script is running on an IP address that is authorised to send for <code>example.com</code> using SPF, <em>and</em> both the SMTP MAIL FROM and the From header end in <code>example.com</code>, <em>or</em></li><li>The PHP script is hooked up to a mail server that can sign an email with DKIM, using a key that's valid for <code>example.com</code>, and the From header ends in <code>example.com</code>.</li></ol><p>(In both cases, assume the <code>mail()</code> function is hooked up to a mail server on the same IP. Otherwise, the words I have to use just become a jumble. The script could be hooked up to an external mail server, and as long as <em>that</em> mail server is allowed in SPF, or can sign for the domain with DKIM, it'll work fine.)</p><p>Now might be a good time to jump back to the <a href="#on-envelopes-vs-letters">envelope from</a> section - it pairs nicely with this section.</p><h2 id="how-do-i-use-them">How do I use them?</h2><p>Here's the good news: you <em>probably</em> have SPF and DKIM records set up for your domain. These days, most email services will give you the correct DNS records to add, and offer tools to verify that they're set up correctly.</p><h3 id="implement-spf">Implement SPF</h3><p>SPF is set up as a <code>TXT</code> record in your domain's DNS. Here's what mine looks like for simonandrews.ca:</p><pre><code>v=spf1 include:spf.messagingengine.com include:spf.mandrillapp.com -all
</code></pre><p>It's declared directly on <code>simonandrews.ca</code> as a <code>TXT</code> record - not on a subdomain. If I were sending emails from <code>newsletter.simonandrews.ca</code>, I'd need <em>another</em> record for that subdomain.</p><p>Most SPF records are going to look like this, though many will have more than one <code>include:</code> clause. Let's break this down:</p><ul><li><code>v=spf1</code>: Declares this as an SPF record, as distinct from the other things you might declare in a TXT record. It's SPF v1.</li><li><code>include:spf.messagingengine.com</code>: Emails are allowed to be sent from anything <code>spf.messagingengine.com</code> (Fastmail's SPF subdomain) allows. Normally, this means that <code>spf.messagingengine.com</code> has its own SPF DNS record, which will probably list some valid IP addresses that emails can be sent from. There's also one for Mandrill, for transactional emails. You can have as many of these as you want. If you want to see what <code>include:</code> does after you've set up SPF on your domain, check out the dmarc analyser <a href="https://www.dmarcanalyzer.com/spf/checker/">SPF Record Checker</a>.</li><li><code>-all</code>: This one's confusing, so pay attention. You might think it's an argument, like you'd use on a terminal command. It's not. It's actually saying "fail" (<code>-</code>) on "all others" (<code>all</code>). In other words: "if none of the previous declarations matched an email you received from our domain, then the email you received is probably spoofed."</li></ul><p>The last one, <code>-all</code>, is especially confusing because of what many email services recommend - which is <code>~all</code>. That's a tilde, not a dash. It's easy to miss. The tilde means "this should fail, but don't do anything." Some other services suggest <code>?all</code>, which may look like an encoding error, but actually means "if an email doesn't match these domains, it doesn't matter." <em>If you use <code>~all</code> or <code>?all</code>, your SPF record isn't doing very much, even if you set up DMARC.</em> Use <code>-all</code> instead. <strong>Seriously, use <code>-all</code> instead.</strong> Always put it at the end of your SPF record.</p><p>Like I said, most email services these days provide the SPF record you should set at the time you set up the service, and they will then <em>validate</em> your SPF record by checking your DNS from their side. You should double check with each of your providers that your SPF is currently configured the way it should be. In the service's dashboard or configuration, there's probably a "domains" section that will guide you and validate your settings. Their support teams may be able to help, failing that. And, remember: if they suggest <code>~all</code> or <code>?all</code>, ignore it and use <code>-all</code> instead.</p><p><strong>N.B.</strong> SPF used to be its own DNS record type - instead of declaring a TXT record in your domain's DNS that contains SPF information, you'd declare an SPF record. If your domain has SPF-type records and TXT-type records, remove the SPF records. If you <em>only</em> have SPF-type records, move them to be TXT-type records. It's DNS, so this probably gives you anxiety, but trust me here. SPF-type records are going away, and all email services that obey SPF records will read them from TXT-type records. You want to do this.</p><h4 id="main-takeaway">Main takeaway</h4><p>You probably have SPF set up, even if you didn't know you were setting it up at the time. It was probably just one of a hundred small tasks you did when you signed up for an emailing platform. But you should check it. Use your email services' tools to check them, but do a manual check, too. And never forget to use <code>-all</code>.</p><h4 id="resources">Resources</h4><ul><li>dmarcian has a good overview of the <a href="https://dmarcian.com/spf-syntax-table/">syntax for SPF records</a>. There's quite a lot more available than I've described, but in my experience, you don't need all that detail. Regardless, now that you know the basics (congratulations, by the way!), this page should make sense.</li><li>The dmarc analyser <a href="https://www.dmarcanalyzer.com/spf/checker/">SPF Record Checker</a> is a good way to check your SPF records.</li></ul><h3 id="implement-dkim">Implement DKIM</h3><p>With DKIM, you're even more at the whims of your email providers. They might provide instructions to set up DKIM, like with SPF. If they don't provide instructions, it probably means they don't support DKIM. If they <em>do</em> provide instructions, you'll want to follow them <em>to the letter</em>.</p><p>Normally, a DKIM public key lives in your DNS records on a subdomain of <code>_domainkey.yourdomain.net</code> - for example, for Fastmail, I have keys on <code>fm1._domainkey.simonandrews.ca</code>, <code>fm2._domainkey.simonandrews.ca</code>, and <code>fm3._domainkey.simonandrews.ca</code>, per their instructions. It might be a <code>TXT</code> record, with the key directly inline, or a <code>CNAME</code> record that points to a public key hosted by your email providers.</p><p>When an email gets signed by the sending server using DKIM, the signature will include the identifier to use - for example, on my domain, it would be one of <code>fm1</code>, <code>fm2</code>, or <code>fm3</code>.</p><p>I won't get into the structure here <em>at all</em>. It varies by provider, but <em>will</em> end up with a DNS record underneath <code>_domainkey.yourdomain.net</code>. Again, there's probably something in a service's Domains dashboard that tells you what to do, and validates your configuration. You may have set DKIM up already, and didn't know it.</p><h4 id="main-takeaway-1">Main takeaway</h4><p>Your email providers will tell you how to set up DKIM, if they support it. Trust them, and follow their instructions. If they don't support DKIM, it's not the end of the world - but make sure SPF is set up correctly.</p><h4 id="resources-1">Resources</h4><ul><li>Postmark have a <a href="https://postmarkapp.com/guides/dkim">very good write-up of DKIM</a>. It's better than anything I could write - though understanding the basics, as you do now, will help you understand that document on your first read.</li><li>Once again, dmarc analyser have a good <a href="https://www.dmarcanalyzer.com/dkim/dkim-checker/">DKIM record checker</a> you can use to validate your setup. You'll need your domain name, and the key (like <code>fm1</code> for Fastmail), because DKIM is declared on subdomains, not your domain root.</li></ul><h3 id="implement-dmarc">&nbsp;Implement DMARC</h3><p>Oh boy, you're gonna hate this part.</p><p>This is the part that I've found most difficult to research. There are a <em>bunch</em> of companies that are gaming SEO to promote their DMARC analysis service - but none of them explain what DMARC is, at least not publicly. They don't give you the information to understand what's going on and what you'll need to do - instead, they're trying to sell you something that will just fix it for you.</p><p>I don't trust companies that game SEO, so I didn't trust any of these articles. I wanted to get down to basics.</p><p>Here's the bad news, though. I glossed over something earlier, when we talked about reporting. Forgive me. I didn't want to scare you away. We're <em>so close</em> now. You understand most of the concepts we're dealing with, and even if your email domains aren't locked down yet, they're definitely better. But... DMARC reports are sent as XML files.</p><p>I'm so, so sorry.</p><p>DMARC reports aren't meant to be read by humans. If you have a domain that has any volume of emails, you'll probably get a lot of DMARC reports of spoofing. Those reports are meant to be interpreted and aggregated by a machine.</p><p>In other words: unless you're willing to manually read XML reports to figure out what's happening (hey, on small domains, that's totally possible!), you're either going to be setting up some software on a server, or using a third party provider. Those companies that are gaming SEO, and being cryptic about what DMARC actually is so they can sell you something? You're probably going to give one of them some money.</p><p>Anyway. Let's start with the basics. Pretend that I didn't just say that. While the reports aren't fun to interpret manually, it'd be good to get our hands on some so we can get a feel for what this is. We're going to go through 3 phases:</p><ol><li>Implement a lenient DMARC policy and start collecting reports</li><li>Wait, watch and analyze</li><li>Increase the strictness of your DMARC policy</li></ol><p>That's not too bad. Let's start with a super simple DMARC policy.</p><h4 id="the-lenient-policy">The lenient policy</h4><p>Set up an email address that can receive the reports. I used <a href="mailto:postmaster@simonandrews.ca">postmaster@simonandrews.ca</a>, which actually just forwards to my personal email address. Then, I added a <code>TXT</code>-type DNS record on <code>_dmarc.simonandrews.ca</code> that looks like this - yours will go on <code>_dmarc.mydomain.net</code>:</p><pre><code>v=DMARC1;p=none;pct=100;rua=mailto:postmaster@simonandrews.ca;ruf=mailto:postmaster@simonandrews.ca
</code></pre><p>Whoa whoa whoa... what's that? Ok. Let's break it down.</p><p>There's the <em>policy</em> declarations:</p><ul><li><code>v=DMARC1</code> says "this is DMARC version 1"</li><li><code>p=none</code> says "if SPF or DKIM fail, you don't need to do anything." Remember when I said we'd implement a lenient policy? This is it.</li><li><code>pct=100</code> says "apply this policy to <em>all</em> emails from my domain"</li></ul><p>And then we've got the <em>reporting</em> declarations:</p><pre><code>rua=mailto:postmaster@simonandrews.ca
</code></pre><p>This tells an email server to send <strong>aggregate</strong> reports of spoofed emails to <code>postmaster@simonandrews.ca</code></p><pre><code>ruf=mailto:postmaster@simonandrews.ca
</code></pre><p>This tells an email server to send <strong>forensic</strong> reports of spoofed emails to <code>postmaster@simonandrews.ca</code></p><p>This policy... works. If you set up your own postmaster email address, and use this DMARC record, you'll be well on your way. Go ahead and do that. Within a few days, you'll start getting reports.</p><p>Don't believe me? Try setting up DMARC using a configuration like this, giving it a bit of time to propagate (because DNS is slow), and then run the PHP script from earlier, using your domain and a "to" email address you own. You won't get a report right away, and the spoofed email generated by the script might even end up in your inbox. But within 24 hours, you'll probably get your first DMARC report.</p><h4 id="sit-back-and-watch">Sit back and watch</h4><p>Start collecting these reports. If it's just a personal domain, you might be happy to look through them manually. If it's your company's domain, you might get a high volume of reports - you'll probably want to stand up a DMARC server like <a href="https://github.com/LinkedInAttic/lafayette">lafayette</a>, or use a third party service, to handle these reports.</p><p>Regardless, after you've got some reports through, start analysing the reports. Are emails failing SPF or DKIM tests, that shouldn't be? Did you misconfigure a service? Are you or your company sending emails with a service you weren't aware of? Or, is there a spoofer who's aggressively abusing your domain?</p><p>What can you expect? Well, here's a report I got, after I ran that PHP script from earlier and sent to a Gmail address I have. I added in some comments, to outline what it's telling you.</p><pre><code><span>&lt;?xml version="1.0" encoding="UTF-8" ?&gt;</span>
<span><span><span>&lt;</span>feedback</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>report_metadata</span><span>&gt;</span></span>
    <span>&lt;!-- Details who prepared this report (Google's mail servers) --&gt;</span>
    <span><span><span>&lt;</span>org_name</span><span>&gt;</span></span>google.com<span><span><span>&lt;/</span>org_name</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>email</span><span>&gt;</span></span>noreply-dmarc-support@google.com<span><span><span>&lt;/</span>email</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>extra_contact_info</span><span>&gt;</span></span>https://support.google.com/a/answer/2466580<span><span><span>&lt;/</span>extra_contact_info</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>report_id</span><span>&gt;</span></span>14538673265069095400<span><span><span>&lt;/</span>report_id</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>date_range</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>begin</span><span>&gt;</span></span>1628899200<span><span><span>&lt;/</span>begin</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>end</span><span>&gt;</span></span>1628985599<span><span><span>&lt;/</span>end</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>date_range</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>report_metadata</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>policy_published</span><span>&gt;</span></span>
    <span>&lt;!-- This is the DMARC policy that Google's mail servers found for simonandrews.ca --&gt;</span>
    <span><span><span>&lt;</span>domain</span><span>&gt;</span></span>simonandrews.ca<span><span><span>&lt;/</span>domain</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>adkim</span><span>&gt;</span></span>r<span><span><span>&lt;/</span>adkim</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>aspf</span><span>&gt;</span></span>r<span><span><span>&lt;/</span>aspf</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>p</span><span>&gt;</span></span>none<span><span><span>&lt;/</span>p</span><span>&gt;</span></span> <span>&lt;!-- This is what we set, p=none --&gt;</span>
    <span><span><span>&lt;</span>sp</span><span>&gt;</span></span>none<span><span><span>&lt;/</span>sp</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>pct</span><span>&gt;</span></span>100<span><span><span>&lt;/</span>pct</span><span>&gt;</span></span> <span>&lt;!-- This is also what we set - pct=100 --&gt;</span>
  <span><span><span>&lt;/</span>policy_published</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>record</span><span>&gt;</span></span>
    <span>&lt;!-- Here's some details about the offending email(s) Google received --&gt;</span>
    <span><span><span>&lt;</span>row</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>source_ip</span><span>&gt;</span></span>81.100.0.0<span><span><span>&lt;/</span>source_ip</span><span>&gt;</span></span> <span>&lt;!-- (I censored out the IP) --&gt;</span>
      <span><span><span>&lt;</span>count</span><span>&gt;</span></span>2<span><span><span>&lt;/</span>count</span><span>&gt;</span></span> <span>&lt;!-- I ran the script 2 times, which is reflected here --&gt;</span>
      <span><span><span>&lt;</span>policy_evaluated</span><span>&gt;</span></span>
        <span><span><span>&lt;</span>dkim</span><span>&gt;</span></span>fail<span><span><span>&lt;/</span>dkim</span><span>&gt;</span></span> <span>&lt;!-- DKIM failed --&gt;</span>
        <span><span><span>&lt;</span>spf</span><span>&gt;</span></span>fail<span><span><span>&lt;/</span>spf</span><span>&gt;</span></span> <span>&lt;!-- SPF failed --&gt;</span>
        <span><span><span>&lt;</span>disposition</span><span>&gt;</span></span>none<span><span><span>&lt;/</span>disposition</span><span>&gt;</span></span> <span>&lt;!-- But, since p=none, no action was taken, except producing this report --&gt;</span>
      <span><span><span>&lt;/</span>policy_evaluated</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>row</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>identifiers</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>header_from</span><span>&gt;</span></span>simonandrews.ca<span><span><span>&lt;/</span>header_from</span><span>&gt;</span></span> <span>&lt;!-- These emails were trying to spoof simonandrews.ca --&gt;</span>
    <span><span><span>&lt;/</span>identifiers</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>auth_results</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>spf</span><span>&gt;</span></span>
        <span><span><span>&lt;</span>domain</span><span>&gt;</span></span>simons-mbp.lan<span><span><span>&lt;/</span>domain</span><span>&gt;</span></span> <span>&lt;!-- But they were actually sent from simons-mbp.lan --&gt;</span>
        <span><span><span>&lt;</span>result</span><span>&gt;</span></span>none<span><span><span>&lt;/</span>result</span><span>&gt;</span></span>
      <span><span><span>&lt;/</span>spf</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>auth_results</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>record</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>feedback</span><span>&gt;</span></span>
</code></pre><p>If you're running a large domain, you'll get a bunch of these reports. If you're running a small one, you might be able to handle it yourself.</p><p>Regardless, with a bit of time, you'll be confident you've set the policy correctly.</p><h4 id="increase-the-strictness">Increase the strictness</h4><p>When we first added DMARC, we set <code>p=none</code>. That says, basically, "don't <em>do</em> anything, just tell me about SPF and DKIM when they fail."</p><p>If you're comfortable with the reports you've been receiving - that is, all of the emails in the reports are from spoofers, and all of the emails <em>you're</em> sending are passing the tests - you can increase this parameter. You have two options:</p><ol><li>Set <code>p=quarantine</code>. This tells the receiving server that, if both SPF and DKIM fail, the email should be quarantined. That might mean it gets marked as spam right away, and sent to the receiver's spam folder. It might mean that it's put in a quarantine where an administrator for the receiving domain can approve or reject it. Either way, this option is good: it locks your domain down, but gives users recourse when something goes wrong.</li><li>Set <code>p=reject</code>. This is stricter. It tells the receiving server that, if both SPF and DKIM fail, the email should just be rejected. If you're <em>absolutely confident</em> that you've got everything configured correctly, <em>and</em> you're confident that future services will be set up correctly, then this is probably the option for you. I'd say it's fine to set <code>p=quarantine</code>, and then ramp yourself up to set <code>p=reject</code> at a later date.</li></ol><p>It's in your hands now, though.</p><h4 id="resources-2">Resources</h4><ul><li>dmarc.org have a good overview of <a href="https://dmarc.org/overview/">what DMARC records are made of</a>. If you want to skip right to the meaty stuff, read the section titled "Anatomy of a DMARC resource record in the DNS"</li><li>dmarc.org also have a list of <a href="https://dmarc.org/resources/code-and-libraries/">code and libraries</a> you can use. That's where I found lafayette.</li><li>dmarcian have a <a href="https://dmarcian.com/dmarc-inspector/">DMARC Record Checker</a>, which will help validate that your policy is set up well.</li><li>Postmark have a <a href="https://postmarkapp.com/blog/best-dmarc-tools">guide to DMARC tools</a>. This guide is a good, fairly-unbiased breakdown. You're likely going to pay for a service here, <s>and Postmark come at it with an unbiased perspective because - as of this writing - they don't provide such a service themselves.</s> but Postmark give a reasonable breakdown (it turns out DMARC Digests is a service they provide, so it's not an unbiased source. Thanks to <a href="https://news.ycombinator.com/item?id=28193601">max1cc on Hacker News</a> for pointing this out.)</li></ul><h2 id="troubleshooting">Troubleshooting</h2><h3 id="not-receiving-reports-you-might-need-edv">Not receiving reports? You might need EDV</h3><p><em>Thanks to <a href="https://www.eisfunke.com/">Nicolas Lenz</a> for reaching out with this!</em></p><p>If you've set everything up right, and are waiting for DMARC reports that just aren't coming, you might need to set up EDV.</p><p>You can't send DMARC reports to <em>just anyone</em>. I can't, for example, set up DMARC on <code>simonandrews.ca</code> and send the reports to <code>tim@apple.com</code>. It's likely that Tim Cook doesn't want to know about the deliverability of mail from my domain (his loss). To prevent annoying, unsolicited reports, DMARC implements a system known as EDV (which, depending on who you talk to, means either External Domain Verification or External Destination Verification).</p><p>So, when might you need it? You'd need to meet these two main conditions:</p><ol><li>You're sending your DMARC reports to a different domain. (EDV wouldn't be necessary if I were sending reports from <code>simonandrews.ca</code> to <code>postmaster@simonandrews.ca</code>, because it's not external. Remember: <em>external</em> domain verification.)</li><li>You're <em>not</em> using a third-party DMARC reporting service. (These tools should have EDV set up automatically.)</li></ol><p>An example that <em>would</em> require EDV: I'm setting up DMARC on <code>sadl.io</code>, a domain that I own, and I want to send reports to <a href="mailto:postmaster@simonandrews.ca">postmaster@simonandrews.ca</a>, an email address on another domain that I own. In order for reporting to work, I'd need to configure DMARC on <code>sadl.io</code>, <em>and</em> configure EDV on <code>simonandrews.ca</code> to allow DMARC reports related to <code>sadl.io</code>.</p><p>Once you understand all of that, it's easy: add a DNS <code>TXT</code> record on the receiving domain (<code>simonandrews.ca</code>, in this case), on the <code>sadl.io._report._dmarc</code> subdomain, with a value of <code>v=DMARC1</code>. In other words, something like...</p><pre><code>sadl.io._report._dmarc.simonandrews.ca TXT "v=DMARC1"
</code></pre><p>Now, before a provider sends off a report to <code>postmaster@simonandrews.ca</code>, for emails related to <code>sadl.io</code>, it'll check <code>sadl.io._report._dmarc.simonandrews.ca</code> to see if it's willing to receive them.</p><p>You can find more on the dmarc.org article, <a href="https://dmarc.org/2015/08/receiving-dmarc-reports-outside-your-domain/">Receiving DMARC Reports Outside Your Domain</a>.</p><h2 id="wrapping-up">Wrapping up</h2><p>Chances are, you should implement all of these. But your implementation will probably fork off from mine, as you learn about it.</p><p>My main goal here was to provide you with a vocabulary, so you understand what SPF, DKIM, and DMARC are. I'm not an expert. I probably got some things wrong here. And this article, explicitly, only goes into the basics.</p><p>But hopefully, now that you're here, you've got a basic understanding, and perhaps the start of an implementation. You can go read some other posts, and you won't be completely lost. I'd suggest looking at some of the resources I linked - they're not too complicated, and most won't try to sell you things.</p><p>Thanks for coming along on this crazy, not-really-that-satisfying journey with me. I'll try and keep this post updated as I learn more, and welcome any and all feedback you might have. If I got anything wrong here (I'm absolutely certain I did), please reach out to <a href="mailto:hello@sadl.io">hello@sadl.io</a>.</p><h3 id="corrections">Corrections</h3><p>You can take a look through all the changes I've made <a href="https://github.com/simon360/simonandrews.ca/commits/main/pages/articles/how-to-set-up-spf-dkim-dmarc.mdx">on GitHub</a> - if you've read this article before, and just want to check the new stuff, I'd suggest reading the diffs.</p><ol><li>A previous version of this article claimed that Postmark provided an unbiased view on DMARC analysis services, because they did not provide such a service. In fact, they do, called DMARC Digests, which is mentioned in their guide. <strong>Thanks to <a href="https://news.ycombinator.com/item?id=28193601">max1cc on Hacker News</a> for correcting this.</strong></li><li>The SPF section claims that SPF works on the From header. In fact, it works on the "envelope from", which only exists at the SMTP transport level. Rather than correcting this (I <em>did</em> try, but the section came out too complex), I added an additional section that explains the difference. <strong>Thanks to Liam for reaching out over email and setting me straight.</strong></li></ol><p><small>Last updated:<!-- --> <time datetime="2021-08-17T19:10:00.000+0100">17 August 2021, 7:10 PM BST</time></small></p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[John Barnett before death "if anything happens, it's not suicide", claims friend (551 pts)]]></title>
            <link>https://abcnews4.com/news/local/if-anything-happens-its-not-suicide-boeing-whistleblowers-prediction-before-death-south-carolina-abc-news-4-2024</link>
            <guid>39712618</guid>
            <pubDate>Fri, 15 Mar 2024 06:32:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abcnews4.com/news/local/if-anything-happens-its-not-suicide-boeing-whistleblowers-prediction-before-death-south-carolina-abc-news-4-2024">https://abcnews4.com/news/local/if-anything-happens-its-not-suicide-boeing-whistleblowers-prediction-before-death-south-carolina-abc-news-4-2024</a>, See on <a href="https://news.ycombinator.com/item?id=39712618">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>John Barnett's family friend Jennifer doesn't think the Boeing whistleblower committed suicide in Charleston. In fact, she says he predicted what may happen to him days before he left for his deposition. March 14, 2024. (Provided-FILE, WCIV)</p><div id="js-Story-Content-0"><p><span>CHARLESTON COUNTY, S.C. (WCIV)  — </span>A close family friend of John Barnett said he predicted he might wind up dead and that a story could surface that he killed himself. </p><p>But at the time, he told her not to believe it. </p><p>"I know that he did not commit suicide," said Jennifer, a friend of Barnett's. "There's no way." </p><p>Jennifer said they talked about this exact scenario playing out. However, now, his words seem like a premonition he told her directly not to believe. </p><p>"I know John because his mom and my mom are best friends," Jennifer said. "Over the years, get-togethers, birthdays, celebrations and whatnot. We've all got together and talked." </p><p><strong><em>READ MORE:<a href="https://abcnews4.com/news/local/mystery-lingers-around-boeing-whistleblower-death-at-charleston-hotel-charleston-county-john-barnett-boeing-news-lawsuit-abc-news-4-wciv-2024" target="_blank" title="https://abcnews4.com/news/local/mystery-lingers-around-boeing-whistleblower-death-at-charleston-hotel-charleston-county-john-barnett-boeing-news-lawsuit-abc-news-4-wciv-2024"> "Mystery lingers around Boeing whistleblower's death at Charleston hotel."</a></em></strong></p><p>When Jennifer needed help one day, Barnett came by to see her. They talked about his upcoming deposition in Charleston. Jennifer knew Barnett filed an extremely damaging complaint against Boeing. He said the aerospace giant retaliated against him when he blew the whistle on unsafe practices. <br></p><p>For more than 30 years, he was a quality manager. He'd recently retired and moved back to Louisiana to look after his mom. </p><p>"He wasn't concerned about safety because I asked him," Jennifer said. "I said, 'Aren't you scared?' And he said, 'No, I ain't scared, but if anything happens to me, it's not suicide.'" </p><p>Jennifer added: "I know that he did not commit suicide. There's no way. He loved life too much. He loved his family too much. He loved his brothers too much to put them through what they're going through right now." </p><p>Jennifer said she thinks somebody "didn't like what he had to say" and wanted to "shut him up" without it coming back to anyone. </p><p><strong><em>READ MORE: <a href="https://abcnews4.com/news/local/john-was-a-brave-boeing-whistleblowers-lawyer-responds-to-news-of-his-death-john-barnett-boeing-news-abc-news-wciv-news-4-2024" target="_blank" title="https://abcnews4.com/news/local/john-was-a-brave-boeing-whistleblowers-lawyer-responds-to-news-of-his-death-john-barnett-boeing-news-abc-news-wciv-news-4-2024">"'John was brave': Boeing whistleblower's lawyer responds to news of his death."</a></em></strong></p><p>"That's why they made it look like a suicide," Jennifer said. </p><p>The last time Jennifer saw Barnett was at her father's funeral in late February. He was one of the pallbearers. Sometimes family and friends referred to him by his middle name – Mitch. </p><p>"I think everybody is in disbelief and can't believe it," Jennifer said. "I don't care what they say, I know that Mitch didn't do that." </p><p>Just because Barnett is dead doesn't mean the case won't move forward. </p><p>His attorney said they're still prepared to go to trial in June. </p><p>News 4 reached out to Boeing following Barnett's death. They provided the following statement: </p><p>"We are saddened by Mr. Barnett’s passing, and our thoughts are with his family and friends.”<br></p><p><strong><em>READ MORE: <a href="https://abcnews4.com/news/local/boeing-whistleblower-dies-in-charleston-charleston-county-coroners-office-confirms-south-carolina-boeing-news-abc-news-4" target="_blank" title="https://abcnews4.com/news/local/boeing-whistleblower-dies-in-charleston-charleston-county-coroners-office-confirms-south-carolina-boeing-news-abc-news-4">"Boeing whistleblower dies in Charleston, Charleston County Coroner's Office confirms."</a></em></strong></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Harvard concluded that a dishonesty expert committed misconduct (241 pts)]]></title>
            <link>https://www.chronicle.com/article/heres-the-unsealed-report-showing-how-harvard-concluded-that-a-dishonesty-expert-committed-misconduct</link>
            <guid>39712173</guid>
            <pubDate>Fri, 15 Mar 2024 04:53:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chronicle.com/article/heres-the-unsealed-report-showing-how-harvard-concluded-that-a-dishonesty-expert-committed-misconduct">https://www.chronicle.com/article/heres-the-unsealed-report-showing-how-harvard-concluded-that-a-dishonesty-expert-committed-misconduct</a>, See on <a href="https://news.ycombinator.com/item?id=39712173">Hacker News</a></p>
Couldn't get https://www.chronicle.com/article/heres-the-unsealed-report-showing-how-harvard-concluded-that-a-dishonesty-expert-committed-misconduct: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[RSS was released 25 years ago today (112 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/RSS</link>
            <guid>39712025</guid>
            <pubDate>Fri, 15 Mar 2024 04:16:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/RSS">https://en.wikipedia.org/wiki/RSS</a>, See on <a href="https://news.ycombinator.com/item?id=39712025">Hacker News</a></p>
<div id="readability-page-1" class="page"><div lang="en" dir="ltr" id="mw-content-text">




<table><caption>RSS</caption><tbody><tr><td colspan="2"><span typeof="mw:File"><a href="https://en.wikipedia.org/wiki/File:Feed-icon.svg" title="Feed Computer icon."><img alt="Feed Computer icon." src="https://upload.wikimedia.org/wikipedia/en/thumb/4/43/Feed-icon.svg/128px-Feed-icon.svg.png" decoding="async" width="128" height="128" srcset="https://upload.wikimedia.org/wikipedia/en/thumb/4/43/Feed-icon.svg/192px-Feed-icon.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/en/thumb/4/43/Feed-icon.svg/256px-Feed-icon.svg.png 2x" data-file-width="128" data-file-height="128"></a></span></td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/Filename_extension" title="Filename extension">Filename extension</a></th><td><p><kbd>.rss, .xml</kbd></p></td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/Media_type" title="Media type">Internet media&nbsp;type</a></th><td><code>application/rss+xml</code>&nbsp;(registration not finished)<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup></td></tr><tr><th scope="row">Developed&nbsp;by</th><td><a href="https://en.wikipedia.org/wiki/RSS_Advisory_Board" title="RSS Advisory Board">RSS Advisory Board</a></td></tr><tr><th scope="row">Initial release</th><td>RSS 0.90 (Netscape), March&nbsp;15, 1999<span>; 25 years ago</span></td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/Software_release_life_cycle" title="Software release life cycle">Latest release</a></th><td><p>RSS 2.0 (version 2.0.11)<br>March&nbsp;30, 2009<span>; 14 years ago</span> </p></td></tr><tr><th scope="row">Type of format</th><td><a href="https://en.wikipedia.org/wiki/Web_syndication" title="Web syndication">Web syndication</a></td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/Digital_container_format" title="Digital container format">Container&nbsp;for</a></th><td>Updates of a website and its related metadata (<a href="https://en.wikipedia.org/wiki/Web_feed" title="Web feed">web feed</a>)</td></tr><tr><th scope="row">Extended&nbsp;from</th><td><a href="https://en.wikipedia.org/wiki/XML" title="XML">XML</a></td></tr><tr><th scope="row"><span><a href="https://en.wikipedia.org/wiki/Open_file_format" title="Open file format">Open format</a>?</span></th><td>Yes</td></tr><tr><th scope="row">Website</th><td><span><a rel="nofollow" href="http://rssboard.org/rss-specification">rssboard<wbr>.org<wbr>/rss-specification</a></span></td></tr></tbody></table>
<p><b>RSS</b> (<b><a href="https://en.wikipedia.org/wiki/Resource_Description_Framework" title="Resource Description Framework">RDF</a> Site Summary</b> or <b>Really Simple Syndication</b>)<sup id="cite_ref-powers-2003-1_2-0"><a href="#cite_note-powers-2003-1-2">[2]</a></sup> is a <a href="https://en.wikipedia.org/wiki/Web_feed" title="Web feed">web feed</a><sup id="cite_ref-Netsc99_3-0"><a href="#cite_note-Netsc99-3">[3]</a></sup> that allows users and applications to access updates to websites in a <a href="https://en.wikipedia.org/wiki/Standardization" title="Standardization">standardized</a>, computer-readable format. Subscribing to RSS feeds can allow a user to keep track of many different websites in a single <a href="https://en.wikipedia.org/wiki/News_aggregator" title="News aggregator">news aggregator</a>, which constantly monitor sites for new content, removing the need for the user to manually check them. News aggregators (or "RSS readers") can be built into a <a href="https://en.wikipedia.org/wiki/Web_application" title="Web application">browser</a>, installed on a <a href="https://en.wikipedia.org/wiki/Application_software" title="Application software">desktop computer</a>, or installed on a <a href="https://en.wikipedia.org/wiki/Mobile_app" title="Mobile app">mobile device</a>.
</p><p>Websites usually use RSS feeds to publish frequently updated information, such as <a href="https://en.wikipedia.org/wiki/Blog" title="Blog">blog</a> entries, news headlines, episodes of audio and video series, or for distributing <a href="https://en.wikipedia.org/wiki/Podcast" title="Podcast">podcasts</a>. An RSS document (called "feed", "web feed",<sup id="cite_ref-GuardWF_4-0"><a href="#cite_note-GuardWF-4">[4]</a></sup> or "channel") includes full or summarized text, and <a href="https://en.wikipedia.org/wiki/Metadata" title="Metadata">metadata</a>, like publishing date and author's name. RSS formats are specified using a generic <a href="https://en.wikipedia.org/wiki/XML" title="XML">XML</a> file.
</p><p>Although RSS formats have evolved from as early as March 1999,<sup id="cite_ref-Qstart_5-0"><a href="#cite_note-Qstart-5">[5]</a></sup> it was between 2005 and 2006 when RSS gained widespread use, and the ("<span typeof="mw:File"><a href="https://en.wikipedia.org/wiki/File:Feed-icon.svg"><img src="https://upload.wikimedia.org/wikipedia/en/thumb/4/43/Feed-icon.svg/16px-Feed-icon.svg.png" decoding="async" width="16" height="16" srcset="https://upload.wikimedia.org/wikipedia/en/thumb/4/43/Feed-icon.svg/24px-Feed-icon.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/en/thumb/4/43/Feed-icon.svg/32px-Feed-icon.svg.png 2x" data-file-width="128" data-file-height="128"></a></span>") icon was decided upon by several major web browsers. RSS feed data is presented to users using software called a news aggregator and the passing of content is called <a href="https://en.wikipedia.org/wiki/Web_syndication" title="Web syndication">web syndication</a>. Users subscribe to feeds either by entering a feed's <a href="https://en.wikipedia.org/wiki/Uniform_Resource_Identifier" title="Uniform Resource Identifier">URI</a> into the reader or by clicking on the browser's <a href="https://en.wikipedia.org/wiki/Web_feed#Feed_icon" title="Web feed">feed icon</a>. The RSS reader checks the user's feeds regularly for new information and can automatically download it, if that function is enabled.
</p>
<meta property="mw:PageProp/toc">
<h2><span id="History">History</span></h2>
<table role="presentation"><tbody><tr><td><p><span typeof="mw:File"><span><img alt="" src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/Ambox_current_red.svg/42px-Ambox_current_red.svg.png" decoding="async" width="42" height="34" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/Ambox_current_red.svg/63px-Ambox_current_red.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/Ambox_current_red.svg/84px-Ambox_current_red.svg.png 2x" data-file-width="360" data-file-height="290"></span></span></p></td><td><p>This section needs to be <b>updated</b>.<span> Please help update this article to reflect recent events or newly available information.</span>  <span><i>(<span>October 2013</span>)</i></span></p></td></tr></tbody></table>

<p>The RSS formats were preceded by several attempts at <a href="https://en.wikipedia.org/wiki/Web_syndication" title="Web syndication">web syndication</a> that did not achieve widespread popularity. The basic idea of restructuring information about websites goes back to as early as 1995, when <a href="https://en.wikipedia.org/wiki/Ramanathan_V._Guha" title="Ramanathan V. Guha">Ramanathan V. Guha</a> and others in <a href="https://en.wikipedia.org/wiki/Apple_Inc." title="Apple Inc.">Apple</a>'s <a href="https://en.wikipedia.org/wiki/Apple_Advanced_Technology_Group" title="Apple Advanced Technology Group">Advanced Technology Group</a> developed the <a href="https://en.wikipedia.org/wiki/Meta_Content_Framework" title="Meta Content Framework">Meta Content Framework</a>.<sup id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup>
</p><p><a href="https://en.wikipedia.org/wiki/Resource_Description_Framework" title="Resource Description Framework">RDF</a> Site Summary, the first version of RSS, was created by <a href="https://en.wikipedia.org/w/index.php?title=Dan_Libby&amp;action=edit&amp;redlink=1" title="Dan Libby (page does not exist)">Dan Libby</a> and Ramanathan V. Guha at <a href="https://en.wikipedia.org/wiki/Netscape" title="Netscape">Netscape</a>. It was released in March 1999 for use on the My.Netscape.Com portal.<sup id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup> This version became known as RSS 0.9.<sup id="cite_ref-Qstart_5-1"><a href="#cite_note-Qstart-5">[5]</a></sup> In July 1999, Dan Libby of Netscape produced a new version, RSS 0.91,<sup id="cite_ref-Netsc99_3-1"><a href="#cite_note-Netsc99-3">[3]</a></sup> which simplified the format by removing RDF elements and incorporating elements from <a href="https://en.wikipedia.org/wiki/Dave_Winer" title="Dave Winer">Dave Winer</a>'s news syndication format.<sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup> Libby also renamed the format from RDF to RSS <b>Rich Site Summary</b> and outlined further development of the format in a "futures document".<sup id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup>
</p><p>This would be Netscape's last participation in RSS development for eight years. As RSS was being embraced by web publishers who wanted their feeds to be used on My.Netscape.Com and other early RSS portals, Netscape dropped RSS support from My.Netscape.Com in April 2001 during new owner <a href="https://en.wikipedia.org/wiki/AOL" title="AOL">AOL</a>'s restructuring of the company, also removing documentation and tools that supported the format.<sup id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup>
</p><p>Two parties emerged to fill the void, with neither Netscape's help nor approval: The <a href="https://en.wikipedia.org/wiki/RSS-DEV_Working_Group" title="RSS-DEV Working Group">RSS-DEV Working Group</a> and Dave Winer, whose <a href="https://en.wikipedia.org/wiki/UserLand_Software" title="UserLand Software">UserLand Software</a> had published some of the first publishing tools outside Netscape that could read and write RSS.
</p><p>Winer published a modified version of the RSS 0.91 specification on the UserLand website, covering how it was being used in his company's products, and claimed copyright to the document.<sup id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup> A few months later, UserLand filed a U.S. trademark registration for RSS, but failed to respond to a <a href="https://en.wikipedia.org/wiki/United_States_Patent_and_Trademark_Office" title="United States Patent and Trademark Office">USPTO</a> trademark examiner's request and the request was rejected in December 2001.<sup id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup>
</p><p>The RSS-DEV Working Group, a project whose members included <a href="https://en.wikipedia.org/wiki/Aaron_Swartz" title="Aaron Swartz">Aaron Swartz</a>,<sup id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup> Guha and representatives of <a href="https://en.wikipedia.org/wiki/O%27Reilly_Media" title="O'Reilly Media">O'Reilly Media</a> and <a href="https://en.wikipedia.org/wiki/Moreover_Technologies" title="Moreover Technologies">Moreover</a>, produced RSS 1.0 in December 2000.<sup id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup> This new version, which reclaimed the name RDF Site Summary from RSS 0.9, reintroduced support for RDF and added <a href="https://en.wikipedia.org/wiki/XML_namespace" title="XML namespace">XML namespaces</a> support, adopting elements from standard metadata vocabularies such as <a href="https://en.wikipedia.org/wiki/Dublin_Core" title="Dublin Core">Dublin Core</a>.
</p><p>In December 2000, Winer released RSS 0.92<sup id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup>
a minor set of changes aside from the introduction of the enclosure element, which permitted audio files to be carried in RSS feeds and helped spark <a href="https://en.wikipedia.org/wiki/Podcast" title="Podcast">podcasting</a>. He also released drafts of RSS 0.93 and RSS 0.94 that were subsequently withdrawn.<sup id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup>
</p><p>In September 2002, Winer released a major new version of the format, RSS 2.0, that redubbed its initials Really Simple Syndication. RSS 2.0 removed the <i>type</i> attribute added in the RSS 0.94 draft and added support for namespaces. To preserve backward compatibility with RSS 0.92, namespace support applies only to other content included within an RSS 2.0 feed, not the RSS 2.0 elements themselves.<sup id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup> (Although other standards such as <a href="https://en.wikipedia.org/wiki/Atom_(standard)" title="Atom (standard)">Atom</a> attempt to correct this limitation, RSS feeds are not aggregated with other content often enough to shift the popularity from RSS to other formats having full namespace support.)
</p><p>Because neither Winer nor the RSS-DEV Working Group had Netscape's involvement, they could not make an official claim on the RSS name or format. This has fueled ongoing controversy<sup>[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citing_sources" title="Wikipedia:Citing sources"><span title="Statement needs to be more specific about the content to which it refers. (September 2016)">specify</span></a></i>]</sup> in the syndication development community as to which entity was the proper publisher of RSS.
</p><p>One product of that contentious debate was the creation of an alternative syndication format, Atom, that began in June 2003.<sup id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup> The Atom syndication format, whose creation was in part motivated by a desire to get a clean start free of the issues surrounding RSS, has been adopted as <a href="https://en.wikipedia.org/wiki/IETF" title="IETF">IETF</a> Proposed Standard <a href="https://en.wikipedia.org/wiki/RFC_(identifier)" title="RFC (identifier)">RFC</a>&nbsp;<a rel="nofollow" href="https://datatracker.ietf.org/doc/html/rfc4287">4287</a>.
</p><p>In July 2003, Winer and UserLand Software assigned the copyright of the RSS 2.0 specification to Harvard's <a href="https://en.wikipedia.org/wiki/Berkman_Klein_Center_for_Internet_%26_Society" title="Berkman Klein Center for Internet &amp; Society">Berkman Klein Center for Internet &amp; Society</a>, where he had just begun a term as a visiting fellow.<sup id="cite_ref-20"><a href="#cite_note-20">[20]</a></sup> At the same time, Winer launched the <a href="https://en.wikipedia.org/wiki/RSS_Advisory_Board" title="RSS Advisory Board">RSS Advisory Board</a> with <a href="https://en.wikipedia.org/wiki/NetNewsWire" title="NetNewsWire">Brent Simmons</a> and <a href="https://en.wikipedia.org/wiki/Jon_Udell" title="Jon Udell">Jon Udell</a>, a group whose purpose was to maintain and publish the specification and answer questions about the format.<sup id="cite_ref-21"><a href="#cite_note-21">[21]</a></sup>
</p><p>In September 2004, Stephen Horlander created the now ubiquitous <a href="https://en.wikipedia.org/wiki/Web_feed#Feed_icon" title="Web feed">RSS icon</a> (<span typeof="mw:File"><a href="https://en.wikipedia.org/wiki/File:Feed-icon.svg"><img src="https://upload.wikimedia.org/wikipedia/en/thumb/4/43/Feed-icon.svg/16px-Feed-icon.svg.png" decoding="async" width="16" height="16" srcset="https://upload.wikimedia.org/wikipedia/en/thumb/4/43/Feed-icon.svg/24px-Feed-icon.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/en/thumb/4/43/Feed-icon.svg/32px-Feed-icon.svg.png 2x" data-file-width="128" data-file-height="128"></a></span>) for use in the <a href="https://en.wikipedia.org/wiki/Mozilla" title="Mozilla">Mozilla</a> <a href="https://en.wikipedia.org/wiki/Firefox" title="Firefox">Firefox</a> <a href="https://en.wikipedia.org/wiki/Web_Browser" title="Web Browser">browser</a>.<sup id="cite_ref-22"><a href="#cite_note-22">[22]</a></sup>
</p><p>In December 2005, the Microsoft Internet Explorer team and
<a href="https://en.wikipedia.org/wiki/Microsoft_Outlook" title="Microsoft Outlook">Microsoft Outlook</a> team<sup id="cite_ref-23"><a href="#cite_note-23">[23]</a></sup> announced on their blogs that they were adopting Firefox's RSS icon. In February 2006, <a href="https://en.wikipedia.org/wiki/Opera_Software" title="Opera Software">Opera Software</a> followed suit.<sup id="cite_ref-24"><a href="#cite_note-24">[24]</a></sup> This effectively made the orange square with white radio waves the industry standard for RSS and Atom feeds, replacing the large variety of icons and text that had been used previously to identify syndication data.
</p><p>In January 2006, <a href="https://en.wikipedia.org/wiki/Rogers_Cadenhead" title="Rogers Cadenhead">Rogers Cadenhead</a> relaunched the RSS Advisory Board without Dave Winer's participation, with a stated desire to continue the development of the RSS format and resolve ambiguities. In June 2007, the board revised their version of the specification to confirm that namespaces may extend core elements with namespace attributes, as Microsoft has done in Internet Explorer 7. According to their view, a difference of interpretation left publishers unsure of whether this was permitted or forbidden.
</p>
<h2><span id="Example">Example</span></h2>
<p>RSS is <a href="https://en.wikipedia.org/wiki/XML" title="XML">XML</a>-formatted plain text. The RSS format itself is relatively easy to read both by automated processes and by humans alike. An example feed could have contents such as the following:
</p>
<div dir="ltr"><pre><span></span><span>&lt;?xml version="1.0" encoding="UTF-8"&nbsp;?&gt;</span>
<span>&lt;rss</span><span> </span><span>version=</span><span>"2.0"</span><span>&gt;</span>
<span>&lt;channel&gt;</span>
<span> </span><span>&lt;title&gt;</span>RSS<span> </span>Title<span>&lt;/title&gt;</span>
<span> </span><span>&lt;description&gt;</span>This<span> </span>is<span> </span>an<span> </span>example<span> </span>of<span> </span>an<span> </span>RSS<span> </span>feed<span>&lt;/description&gt;</span>
<span> </span><span>&lt;link&gt;</span>http://www.example.com/main.html<span>&lt;/link&gt;</span>
<span> </span><span>&lt;copyright&gt;</span>2020<span> </span>Example.com<span> </span>All<span> </span>rights<span> </span>reserved<span>&lt;/copyright&gt;</span>
<span> </span><span>&lt;lastBuildDate&gt;</span>Mon,<span> </span>6<span> </span>Sep<span> </span>2010<span> </span>00:01:00<span> </span>+0000<span>&lt;/lastBuildDate&gt;</span>
<span> </span><span>&lt;pubDate&gt;</span>Sun,<span> </span>6<span> </span>Sep<span> </span>2009<span> </span>16:20:00<span> </span>+0000<span>&lt;/pubDate&gt;</span>
<span> </span><span>&lt;ttl&gt;</span>1800<span>&lt;/ttl&gt;</span>

<span> </span><span>&lt;item&gt;</span>
<span>  </span><span>&lt;title&gt;</span>Example<span> </span>entry<span>&lt;/title&gt;</span>
<span>  </span><span>&lt;description&gt;</span>Here<span> </span>is<span> </span>some<span> </span>text<span> </span>containing<span> </span>an<span> </span>interesting<span> </span>description.<span>&lt;/description&gt;</span>
<span>  </span><span>&lt;link&gt;</span>http://www.example.com/blog/post/1<span>&lt;/link&gt;</span>
<span>  </span><span>&lt;guid</span><span> </span><span>isPermaLink=</span><span>"false"</span><span>&gt;</span>7bd204c6-1655-4c27-aeee-53f933c5395f<span>&lt;/guid&gt;</span>
<span>  </span><span>&lt;pubDate&gt;</span>Sun,<span> </span>6<span> </span>Sep<span> </span>2009<span> </span>16:20:00<span> </span>+0000<span>&lt;/pubDate&gt;</span>
<span> </span><span>&lt;/item&gt;</span>

<span>&lt;/channel&gt;</span>
<span>&lt;/rss&gt;</span>
</pre></div>
<h3><span id="Aggregators">Aggregators</span></h3>

<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Tiny_Tiny_RSS_English_Interface.png"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Tiny_Tiny_RSS_English_Interface.png/330px-Tiny_Tiny_RSS_English_Interface.png" decoding="async" width="330" height="186" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Tiny_Tiny_RSS_English_Interface.png/495px-Tiny_Tiny_RSS_English_Interface.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Tiny_Tiny_RSS_English_Interface.png/660px-Tiny_Tiny_RSS_English_Interface.png 2x" data-file-width="1366" data-file-height="768"></a><figcaption>User interface of an RSS feed reader on a desktop computer</figcaption></figure>
<p>When retrieved, RSS reading software could use the XML structure to present a neat display to the end users. There are various news aggregator software for desktop and mobile devices, but RSS can also be built-in inside <a href="https://en.wikipedia.org/wiki/Web_browser" title="Web browser">web browsers</a> or <a href="https://en.wikipedia.org/wiki/Email_client" title="Email client">email clients</a> like <a href="https://en.wikipedia.org/wiki/Mozilla_Thunderbird" title="Mozilla Thunderbird">Mozilla Thunderbird</a>.
</p>
<h2><span id="Variants">Variants</span></h2>
<p>There are several different versions of RSS, falling into two major branches (RDF and 2.*).
</p><p>The RDF (or RSS 1.*) branch includes the following versions:
</p>
<ul><li>RSS 0.90 was the original Netscape RSS version. This RSS was called <i>RDF Site Summary</i>, but was based on an early working draft of the RDF standard, and was not compatible with the final RDF Recommendation.</li>
<li>RSS 1.0 is an open format by the RSS-DEV Working Group, again standing for <i>RDF Site Summary</i>. RSS 1.0 is an RDF format like RSS 0.90, but not fully compatible with it, since 1.0 is based on the final RDF 1.0 Recommendation.</li>
<li>RSS 1.1 is also an open format and is intended to update and replace RSS 1.0. The specification is an independent draft not supported or endorsed in any way by the RSS-Dev Working Group or any other organization.</li></ul>
<p>The RSS 2.* branch (initially UserLand, now Harvard) includes the following versions:
</p>
<ul><li>RSS 0.91 is the simplified RSS version released by Netscape, and also the version number of the simplified version originally championed by Dave Winer from Userland Software. The Netscape version was now called <i>Rich Site Summary</i>; this was no longer an RDF format, but was relatively easy to use.</li>
<li>RSS 0.92 through 0.94 are expansions of the RSS 0.91 format, which are mostly compatible with each other and with Winer's version of RSS 0.91, but are not compatible with RSS 0.90.</li>
<li>RSS 2.0.1 has the internal version number 2.0. RSS 2.0.1 was proclaimed to be "frozen", but still updated shortly after release without changing the version number.  RSS now stood for <i>Really Simple Syndication</i>.  The major change in this version is an explicit extension mechanism using XML namespaces.<sup id="cite_ref-W3C_REC_XML_Namespace_25-0"><a href="#cite_note-W3C_REC_XML_Namespace-25">[25]</a></sup></li></ul>
<p>Later versions in each branch are <a href="https://en.wikipedia.org/wiki/Backward_compatibility" title="Backward compatibility">backward-compatible</a> with earlier versions (aside from non-conformant RDF syntax in 0.90), and both versions include properly documented extension mechanisms using XML Namespaces, either directly (in the 2.* branch) or through RDF (in the 1.* branch).  Most syndication software supports both branches. "The Myth of RSS Compatibility", an article written in 2004 by RSS critic and <a href="https://en.wikipedia.org/wiki/Atom_(standard)" title="Atom (standard)">Atom</a> advocate <a href="https://en.wikipedia.org/wiki/Mark_Pilgrim" title="Mark Pilgrim">Mark Pilgrim</a>, discusses RSS version compatibility issues in more detail.
</p><p>The extension mechanisms make it possible for each branch to copy innovations in the other. For example, the RSS 2.* branch was the first to support <a href="https://en.wikipedia.org/wiki/RSS_enclosure" title="RSS enclosure">enclosures</a>, making it the current leading choice for podcasting, and as of 2005 is the format supported for that use by <a href="https://en.wikipedia.org/wiki/ITunes" title="ITunes">iTunes</a> and other podcasting software; however, an enclosure extension is now available for the RSS 1.* branch, mod_enclosure.  Likewise, the RSS 2.* core specification does not support providing full-text in addition to a synopsis, but the RSS 1.* markup can be (and often is) used as an extension.  There are also several common outside extension packages available, e.g. one  from <a href="https://en.wikipedia.org/wiki/Microsoft" title="Microsoft">Microsoft</a> for use in <a href="https://en.wikipedia.org/wiki/Internet_Explorer" title="Internet Explorer">Internet Explorer</a> 7.
</p><p>The most serious compatibility problem is with HTML markup. Userland's RSS reader—generally considered as the reference implementation—did not originally filter out <a href="https://en.wikipedia.org/wiki/HTML" title="HTML">HTML</a> markup from feeds. As a result, publishers began placing HTML markup into the titles and descriptions of items in their RSS feeds. This behavior has become expected of readers, to the point of becoming a <a href="https://en.wikipedia.org/wiki/De_facto" title="De facto">de facto</a> standard.<sup id="cite_ref-26"><a href="#cite_note-26">[26]</a></sup> Though there is still some inconsistency in how software handles this markup, particularly in titles. The RSS 2.0 specification was later updated to include examples of entity-encoded HTML; however, all prior plain text usages remain valid.
</p><p>As of January&nbsp;2007, tracking data from www.syndic8.com indicates that the three main versions of RSS in current use are 0.91, 1.0, and 2.0, constituting 13%, 17%, and 67% of worldwide RSS usage, respectively.<sup id="cite_ref-27"><a href="#cite_note-27">[27]</a></sup> These figures, however, do not include usage of the rival web feed format Atom. As of August&nbsp;2008, the syndic8.com website is indexing 546,069 total feeds, of which 86,496 (16%) were some dialect of Atom and 438,102 were some dialect of RSS.<sup id="cite_ref-28"><a href="#cite_note-28">[28]</a></sup>
</p>
<h2><span id="Modules">Modules</span></h2>
<p>The primary objective of all RSS modules is to extend the basic XML schema established for more robust syndication of content. This inherently allows for more diverse, yet standardized, transactions without modifying the core RSS specification.
</p><p>To accomplish this extension, a tightly controlled vocabulary (in the RSS world, "module"; in the XML world, "schema") is declared through an XML namespace to give names to concepts and relationships between those concepts.
</p><p>Some RSS 2.0 modules with established namespaces are:
</p>
<ul><li><a href="https://en.wikipedia.org/wiki/Media_RSS" title="Media RSS">Media RSS</a> (MRSS) 2.0 Module</li>
<li><a rel="nofollow" href="http://www.opensearch.org/Specifications/OpenSearch/1.1">OpenSearch RSS 2.0 Module</a></li></ul>
<h2><span id="Interoperability">Interoperability</span></h2>
<p>Although the number of items in an RSS channel is theoretically unlimited, some <a href="https://en.wikipedia.org/wiki/News_aggregators" title="News aggregators">news aggregators</a> do not support RSS files larger than 150KB. For example, applications that rely on the Common Feed List of <a href="https://en.wikipedia.org/wiki/Microsoft_Windows" title="Microsoft Windows">Windows</a> might handle such files as if they were corrupt, and not open them. <a href="https://en.wikipedia.org/wiki/Interoperability" title="Interoperability">Interoperability</a> can be maximized by keeping the file size under this limit.
</p><p><a href="https://en.wikipedia.org/wiki/Podcast" title="Podcast">Podcasts</a> are distributed using RSS. To listen to a podcast, a user adds the RSS feed to their podcast client, and the client can then list available episodes and download or stream them for listening or viewing. To be included in a podcast directory the feed must for each episode provide a title, description, artwork, category, language, and explicit rating. There are some services that specifically indexes and is a <a href="https://en.wikipedia.org/wiki/Search_engine" title="Search engine">search engine</a> for podcasts.<sup id="cite_ref-29"><a href="#cite_note-29">[29]</a></sup>
</p><p>Some <a href="https://en.wikipedia.org/wiki/BitTorrent" title="BitTorrent">BitTorrent</a> clients support RSS. RSS feeds which provide links to .torrent files allow users to <a href="https://en.wikipedia.org/wiki/Broadcatching" title="Broadcatching">subscribe and automatically download</a> content as soon as it is published.
</p>
<h3></h3>

<p>Some services deliver RSS to an email inbox, sending updates from user's personal selection and schedules. Examples of such services include <a href="https://en.wikipedia.org/wiki/IFTTT" title="IFTTT">IFTTT</a>, <a href="https://en.wikipedia.org/wiki/Zapier" title="Zapier">Zapier</a> and others.<sup id="cite_ref-30"><a href="#cite_note-30">[30]</a></sup> Conversely, some services deliver email to RSS readers.<sup id="cite_ref-31"><a href="#cite_note-31">[31]</a></sup> Further services like e. g. <a href="https://en.wikipedia.org/wiki/Gmane" title="Gmane">Gmane</a> allow to subscribe to feeds via <a href="https://en.wikipedia.org/wiki/NNTP" title="NNTP">NNTP</a>.
</p><p>It may be noted that <a href="https://en.wikipedia.org/wiki/Email_client" title="Email client">email clients</a> such as <a href="https://en.wikipedia.org/wiki/Mozilla_Thunderbird" title="Mozilla Thunderbird">Thunderbird</a> supports RSS natively.<sup id="cite_ref-32"><a href="#cite_note-32">[32]</a></sup>
</p>
<h2></h2>
<p>Both RSS and <a href="https://en.wikipedia.org/wiki/Atom_(web_standard)" title="Atom (web standard)">Atom</a> are widely supported and are compatible with all major consumer feed readers. RSS gained wider use because of early feed reader support. Technically, Atom has several advantages: less restrictive licensing, <a href="https://en.wikipedia.org/wiki/Internet_Assigned_Numbers_Authority" title="Internet Assigned Numbers Authority">IANA</a>-registered <a href="https://en.wikipedia.org/wiki/MIME_type" title="MIME type">MIME type</a>, XML namespace, <a href="https://en.wikipedia.org/wiki/URI" title="URI">URI</a> support, <a href="https://en.wikipedia.org/wiki/RELAX_NG" title="RELAX NG">RELAX NG</a> support.<sup id="cite_ref-33"><a href="#cite_note-33">[33]</a></sup>
</p><p>The following table shows RSS elements alongside Atom elements where they are equivalent.
</p><p>Note: the <a href="https://en.wikipedia.org/wiki/Asterisk" title="Asterisk">asterisk</a> character (*) indicates that an element must be provided (Atom elements "author" and "link" are only required under certain conditions).
</p>
<table>

<tbody><tr>
<th scope="col">RSS 2.0
</th>
<th scope="col">Atom 1.0
</th></tr>
<tr>
<td><code>author</code>
</td>
<td><code>author</code>*
</td></tr>
<tr>
<td><code>category</code>
</td>
<td><code>category</code>
</td></tr>
<tr>
<td><code>channel</code>
</td>
<td><code>feed</code>
</td></tr>
<tr>
<td><code>copyright</code>
</td>
<td><code>rights</code>
</td></tr>
<tr>
<td>—
</td>
<td><code>subtitle</code>
</td></tr>
<tr>
<td><code>description</code>*
</td>
<td><code>summary</code> and/or <code>content</code>
</td></tr>
<tr>
<td><code>generator</code>
</td>
<td><code>generator</code>
</td></tr>
<tr>
<td><code>guid</code>
</td>
<td><code>id</code>*
</td></tr>
<tr>
<td><code>image</code>
</td>
<td><code>logo</code>
</td></tr>
<tr>
<td><code>item</code>
</td>
<td><code>entry</code>
</td></tr>
<tr>
<td><code>lastBuildDate</code> (in <code>channel</code>)
</td>
<td><code>updated</code>*
</td></tr>
<tr>
<td><code>link</code>*
</td>
<td><code>link</code>*
</td></tr>
<tr>
<td><code>managingEditor</code>
</td>
<td><code>author</code> or <code>contributor</code>
</td></tr>
<tr>
<td><code>pubDate</code>
</td>
<td><code>published</code> (subelement of <code>entry</code>)
</td></tr>
<tr>
<td><code>title</code>*
</td>
<td><code>title</code>*
</td></tr>
<tr>
<td><code><a href="https://en.wikipedia.org/wiki/Time_to_live" title="Time to live">ttl</a></code>
</td>
<td>—
</td></tr></tbody></table>
<h2><span id="Current_usage">Current usage</span></h2>
<p>Several major sites such as <a href="https://en.wikipedia.org/wiki/Facebook" title="Facebook">Facebook</a> and <a href="https://en.wikipedia.org/wiki/Twitter" title="Twitter">Twitter</a> previously offered RSS feeds but have reduced or removed support. Additionally, widely used readers such as <a href="https://en.wikipedia.org/wiki/Shiira" title="Shiira">Shiira</a>, FeedDemon, and particularly <a href="https://en.wikipedia.org/wiki/Google_Reader" title="Google Reader">Google Reader</a>, have all been discontinued as of 2013, citing declining popularity in RSS.<sup id="cite_ref-ClosureAnnouncement_34-0"><a href="#cite_note-ClosureAnnouncement-34">[34]</a></sup> RSS support was removed in <a href="https://en.wikipedia.org/wiki/OS_X_Mountain_Lion" title="OS X Mountain Lion">OS X Mountain Lion</a>'s versions of <a href="https://en.wikipedia.org/wiki/Apple_Mail" title="Apple Mail">Mail</a> and <a href="https://en.wikipedia.org/wiki/Safari_(web_browser)" title="Safari (web browser)">Safari</a>, although the features were partially restored in Safari 8.<sup id="cite_ref-36"><a href="#cite_note-36">[36]</a></sup> Mozilla removed RSS support from <a href="https://en.wikipedia.org/wiki/Mozilla_Firefox" title="Mozilla Firefox">Mozilla Firefox</a> version 64.0, joining <a href="https://en.wikipedia.org/wiki/Google_Chrome" title="Google Chrome">Google Chrome</a> and <a href="https://en.wikipedia.org/wiki/Microsoft_Edge" title="Microsoft Edge">Microsoft Edge</a> which do not include RSS support, thus leaving <a href="https://en.wikipedia.org/wiki/Internet_Explorer" title="Internet Explorer">Internet Explorer</a> as the last major browser to include RSS support by default.<sup id="cite_ref-37"><a href="#cite_note-37">[37]</a></sup><sup id="cite_ref-38"><a href="#cite_note-38">[38]</a></sup>
</p><p>Since the late 2010s there has been an uptick in RSS interest again. In 2018, <i><a href="https://en.wikipedia.org/wiki/Wired_(magazine)" title="Wired (magazine)">Wired</a></i> published an article named "It's Time for an RSS Revival", citing that RSS gives more control over content compared to algorithms and trackers from social media sites. At that time, <a href="https://en.wikipedia.org/wiki/Feedly" title="Feedly">Feedly</a> was the most popular RSS reader.<sup id="cite_ref-39"><a href="#cite_note-39">[39]</a></sup> Chrome on <a href="https://en.wikipedia.org/wiki/Android_(operating_system)" title="Android (operating system)">Android</a> has added the ability to follow RSS feeds as of 2021.<sup id="cite_ref-40"><a href="#cite_note-40">[40]</a></sup>
</p>
<h2><span id="See_also">See also</span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/JSON_Feed" title="JSON Feed">JSON Feed</a></li>
<li><a href="https://en.wikipedia.org/wiki/Aaron_Swartz" title="Aaron Swartz">Aaron Swartz</a></li>
<li><a href="https://en.wikipedia.org/wiki/Comparison_of_feed_aggregators" title="Comparison of feed aggregators">Comparison of feed aggregators</a></li>
<li><a href="https://en.wikipedia.org/wiki/Data_portability" title="Data portability">Data portability</a></li>
<li><a href="https://en.wikipedia.org/wiki/FeedSync" title="FeedSync">FeedSync</a> previously Simple Sharing Extensions</li>
<li><a href="https://en.wikipedia.org/wiki/HAtom" title="HAtom">hAtom</a></li>
<li><a href="https://en.wikipedia.org/wiki/Mashup_(web_application_hybrid)" title="Mashup (web application hybrid)">Mashup (web application hybrid)</a></li>
<li><a href="https://en.wikipedia.org/wiki/WebSub" title="WebSub">WebSub</a></li></ul>
<h2><span id="Notes">Notes</span></h2>
<div>
<ul><li><cite id="CITEREFPowers2003"><a href="https://en.wikipedia.org/wiki/Shelley_Powers" title="Shelley Powers">Powers, Shelley</a> (2003). <i>Practical RDF</i>. <a href="https://en.wikipedia.org/wiki/O%27Reilly_Media" title="O'Reilly Media">O'Reilly</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Practical+RDF&amp;rft.pub=O%27Reilly&amp;rft.date=2003&amp;rft.aulast=Powers&amp;rft.aufirst=Shelley&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></li></ul>
</div>
<h2><span id="References">References</span></h2>
<div>
<ol>
<li id="cite_note-1"><span><b><a href="#cite_ref-1">^</a></b></span> <span><cite><a rel="nofollow" href="https://tools.ietf.org/id/draft-nottingham-rss-media-type-00">"The application/rss+xml Media Type"</a>. Network Working Group. May 22, 2006. <a rel="nofollow" href="https://web.archive.org/web/20220614140253/https://tools.ietf.org/id/draft-nottingham-rss-media-type-00.txt">Archived</a> from the original on June 14, 2022<span>. Retrieved <span>August 16,</span> 2007</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+application%2Frss%2Bxml+Media+Type&amp;rft.pub=Network+Working+Group&amp;rft.date=2006-05-22&amp;rft_id=https%3A%2F%2Ftools.ietf.org%2Fid%2Fdraft-nottingham-rss-media-type-00&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-powers-2003-1-2"><span><b><a href="#cite_ref-powers-2003-1_2-0">^</a></b></span> <span><a href="#CITEREFPowers2003">Powers 2003</a>, p.&nbsp;10: "Another very common use of RDF/XML is in a version of RSS called RSS 1.0 or RDF/RSS. The meaning of the RSS abbreviation has changed over the years, but the basic premise behind it is to provide an XML-formatted feed consisting of an abstract of content and a link to a document containing the full content. When Netscape originally created the first implementation of an RSS specification, RSS stood for RDF Site Summary, and the plan was to use RDF/XML. When the company released, instead, a non-RDF XML version of the specification, RSS stood for Rich Site Summary. Recently, there has been increased activity with RSS, and two paths are emerging: one considers RSS to stand for Really Simple Syndication, a simple XML solution (promoted as RSS 2.0 by Dave Winer at Userland), and one returns RSS to its original roots of RDF Site Summary (RSS 1.0 by the RSS 1.0 Development group)."</span>
</li>
<li id="cite_note-Netsc99-3"><span>^ <a href="#cite_ref-Netsc99_3-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Netsc99_3-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFLibby,_Dan1999">Libby, Dan (July 10, 1999). <a rel="nofollow" href="https://web.archive.org/web/20001204093600/http://my.netscape.com/publish/formats/rss-spec-0.91.html">"RSS 0.91 Spec, revision 3"</a>. <a href="https://en.wikipedia.org/wiki/Netscape" title="Netscape">Netscape ttem</a>. Archived from <a rel="nofollow" href="http://my.netscape.com/publish/formats/rss-spec-0.91.html">the original</a> on December 4, 2000<span>. Retrieved <span>February 14,</span> 2007</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=RSS+0.91+Spec%2C+revision+3&amp;rft.pub=Netscape+ttem&amp;rft.date=1999-07-10&amp;rft.au=Libby%2C+Dan&amp;rft_id=http%3A%2F%2Fmy.netscape.com%2Fpublish%2Fformats%2Frss-spec-0.91.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-GuardWF-4"><span><b><a href="#cite_ref-GuardWF_4-0">^</a></b></span> <span>"Web feeds | RSS | The Guardian | guardian.co.uk",
  <i>The Guardian</i>, London, 2008, webpage:
  <a rel="nofollow" href="https://www.theguardian.com/help/feeds">GuardianUK-webfeeds</a>. <a rel="nofollow" href="https://web.archive.org/web/20171215111443/https://www.theguardian.com/help/feeds">Archived</a> December 15, 2017, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>.</span>
</li>
<li id="cite_note-Qstart-5"><span>^ <a href="#cite_ref-Qstart_5-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Qstart_5-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20001208063100/http://my.netscape.com/publish/help/quickstart.html">"My Netscape Network: Quick Start"</a>. <a href="https://en.wikipedia.org/wiki/Netscape" title="Netscape">Netscape Communications</a>. Archived from <a rel="nofollow" href="http://my.netscape.com/publish/help/quickstart.html">the original</a> on December 8, 2000<span>. Retrieved <span>October 31,</span> 2006</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=My+Netscape+Network%3A+Quick+Start&amp;rft.pub=Netscape+Communications&amp;rft_id=http%3A%2F%2Fmy.netscape.com%2Fpublish%2Fhelp%2Fquickstart.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>

<li id="cite_note-7"><span><b><a href="#cite_ref-7">^</a></b></span> <span><cite id="CITEREFLash,_Alex1997">Lash, Alex (October 3, 1997). <a rel="nofollow" href="https://web.archive.org/web/20110809151456/http://news.cnet.com/2100-1001-203893.html">"W3C takes first step toward RDF spec"</a>. Archived from <a rel="nofollow" href="http://news.cnet.com/2100-1001-203893.html">the original</a> on August 9, 2011<span>. Retrieved <span>February 16,</span> 2007</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=W3C+takes+first+step+toward+RDF+spec&amp;rft.date=1997-10-03&amp;rft.au=Lash%2C+Alex&amp;rft_id=http%3A%2F%2Fnews.cnet.com%2F2100-1001-203893.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-8"><span><b><a href="#cite_ref-8">^</a></b></span> <span><cite id="CITEREFHines1999">Hines, Matt (March 15, 1999). "Netscape Broadens Portal Content Strategy". <i>Newsbytes</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Newsbytes&amp;rft.atitle=Netscape+Broadens+Portal+Content+Strategy&amp;rft.date=1999-03-15&amp;rft.aulast=Hines&amp;rft.aufirst=Matt&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=RSS+History&amp;rft.date=2007-06-07&amp;rft.au=RSS+Advisory+Board&amp;rft_id=http%3A%2F%2Fwww.rssboard.org%2Frss-history&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-10"><span><b><a href="#cite_ref-10">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20001204123600/http://my.netscape.com/publish/help/futures.html">"MNN Future Directions"</a>. <a href="https://en.wikipedia.org/wiki/Netscape" title="Netscape">Netscape Communications</a>. Archived from <a rel="nofollow" href="http://my.netscape.com/publish/help/futures.html">the original</a> on December 4, 2000<span>. Retrieved <span>October 31,</span> 2006</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=MNN+Future+Directions&amp;rft.pub=Netscape+Communications&amp;rft_id=http%3A%2F%2Fmy.netscape.com%2Fpublish%2Fhelp%2Ffutures.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-11"><span><b><a href="#cite_ref-11">^</a></b></span> <span><cite id="CITEREFAndrew_King2003">Andrew King (April 13, 2003). <a rel="nofollow" href="https://web.archive.org/web/20070119031128/http://www.webreference.com/authoring/languages/xml/rss/1/">"The Evolution of RSS"</a>. Archived from <a rel="nofollow" href="http://www.webreference.com/authoring/languages/xml/rss/1/">the original</a> on January 19, 2007<span>. Retrieved <span>January 17,</span> 2007</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Evolution+of+RSS&amp;rft.date=2003-04-13&amp;rft.au=Andrew+King&amp;rft_id=http%3A%2F%2Fwww.webreference.com%2Fauthoring%2Flanguages%2Fxml%2Frss%2F1%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-12"><span><b><a href="#cite_ref-12">^</a></b></span> <span><cite id="CITEREFWiner,_Dave2000">Winer, Dave (June 4, 2000). <a rel="nofollow" href="https://web.archive.org/web/20061110001520/http://backend.userland.com/rss091#copyrightAndDisclaimer">"RSS 0.91: Copyright and Disclaimer"</a>. UserLand Software. Archived from <a rel="nofollow" href="http://backend.userland.com/rss091#copyrightAndDisclaimer">the original</a> on November 10, 2006<span>. Retrieved <span>October 31,</span> 2006</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=RSS+0.91%3A+Copyright+and+Disclaimer&amp;rft.pub=UserLand+Software&amp;rft.date=2000-06-04&amp;rft.au=Winer%2C+Dave&amp;rft_id=http%3A%2F%2Fbackend.userland.com%2Frss091%23copyrightAndDisclaimer&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-13"><span><b><a href="#cite_ref-13">^</a></b></span> <span><cite id="CITEREFU.S._Patent_&amp;_Trademark_Office">U.S. Patent &amp; Trademark Office. <a rel="nofollow" href="http://tarr.uspto.gov/servlet/tarr?regser=serial&amp;entry=78025336">"<span></span>'RSS' Trademark Latest Status Info"</a>. <a rel="nofollow" href="https://web.archive.org/web/20070816233807/http://tarr.uspto.gov/servlet/tarr?regser=serial&amp;entry=78025336">Archived</a> from the original on August 16, 2007<span>. Retrieved <span>September 4,</span> 2007</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=%27RSS%27+Trademark+Latest+Status+Info&amp;rft.au=U.S.+Patent+%26+Trademark+Office&amp;rft_id=http%3A%2F%2Ftarr.uspto.gov%2Fservlet%2Ftarr%3Fregser%3Dserial%26entry%3D78025336&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-14"><span><b><a href="#cite_ref-14">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.harvardmagazine.com/2013/01/rss-creator-aaron-swartz-dead-at-26">"RSS Creator Aaron Swartz Dead at 26"</a>. <i>Harvard Magazine</i>. January 14, 2013. <a rel="nofollow" href="https://web.archive.org/web/20210629135531/https://www.harvardmagazine.com/2013/01/rss-creator-aaron-swartz-dead-at-26">Archived</a> from the original on June 29, 2021<span>. Retrieved <span>June 29,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Harvard+Magazine&amp;rft.atitle=RSS+Creator+Aaron+Swartz+Dead+at+26&amp;rft.date=2013-01-14&amp;rft_id=https%3A%2F%2Fwww.harvardmagazine.com%2F2013%2F01%2Frss-creator-aaron-swartz-dead-at-26&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-15"><span><b><a href="#cite_ref-15">^</a></b></span> <span><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=RDF+Site+Summary+%28RSS%29+1.0&amp;rft.date=2000-12-09&amp;rft.au=RSS-DEV+Working+Group&amp;rft_id=http%3A%2F%2Fweb.resource.org%2Frss%2F1.0%2Fspec&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-16"><span><b><a href="#cite_ref-16">^</a></b></span> <span><cite id="CITEREFWiner,_Dave2000">Winer, Dave (December 25, 2000). <a rel="nofollow" href="https://web.archive.org/web/20110131184230/http://backend.userland.com/rss092">"RSS 0.92 Specification"</a>. UserLand Software. Archived from <a rel="nofollow" href="http://backend.userland.com/rss092">the original</a> on January 31, 2011<span>. Retrieved <span>October 31,</span> 2006</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=RSS+0.92+Specification&amp;rft.pub=UserLand+Software&amp;rft.date=2000-12-25&amp;rft.au=Winer%2C+Dave&amp;rft_id=http%3A%2F%2Fbackend.userland.com%2Frss092&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-17"><span><b><a href="#cite_ref-17">^</a></b></span> <span><cite id="CITEREFWiner,_Dave2001">Winer, Dave (April 20, 2001). <a rel="nofollow" href="https://web.archive.org/web/20061102171227/http://backend.userland.com/rss093">"RSS 0.93 Specification"</a>. UserLand Software. Archived from <a rel="nofollow" href="http://backend.userland.com/rss093">the original</a> on November 2, 2006<span>. Retrieved <span>October 31,</span> 2006</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=RSS+0.93+Specification&amp;rft.pub=UserLand+Software&amp;rft.date=2001-04-20&amp;rft.au=Winer%2C+Dave&amp;rft_id=http%3A%2F%2Fbackend.userland.com%2Frss093&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-18"><span><b><a href="#cite_ref-18">^</a></b></span> <span><cite id="CITEREFHarvard_Law2007">Harvard Law (April 14, 2007). <a rel="nofollow" href="http://cyber.law.harvard.edu/rss/toplevelNamespace.html">"Top-level namespaces"</a>. <a rel="nofollow" href="https://web.archive.org/web/20110605164517/http://cyber.law.harvard.edu/rss/toplevelNamespace.html">Archived</a> from the original on June 5, 2011<span>. Retrieved <span>August 3,</span> 2009</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Top-level+namespaces&amp;rft.date=2007-04-14&amp;rft.au=Harvard+Law&amp;rft_id=http%3A%2F%2Fcyber.law.harvard.edu%2Frss%2FtoplevelNamespace.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-19"><span><b><a href="#cite_ref-19">^</a></b></span> <span><cite id="CITEREFFesta2003">Festa, Paul (August 4, 2003). <a rel="nofollow" href="http://news.cnet.com/Battle-of-the-blog/2009-1032_3-5059006.html">"Dispute exposes bitter power struggle behind Web logs"</a>. news.cnet.com. <a rel="nofollow" href="https://web.archive.org/web/20090806234534/http://news.cnet.com/Battle-of-the-blog/2009-1032_3-5059006.html">Archived</a> from the original on August 6, 2009<span>. Retrieved <span>August 6,</span> 2008</span>. <q>The conflict centers on something called Really Simple Syndication (RSS), a technology widely used to syndicate blogs and other Web content. The dispute pits Harvard Law School fellow Dave Winer, the blogging pioneer who is the key gatekeeper of RSS, against advocates of a different format.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Dispute+exposes+bitter+power+struggle+behind+Web+logs&amp;rft.pub=news.cnet.com&amp;rft.date=2003-08-04&amp;rft.aulast=Festa&amp;rft.aufirst=Paul&amp;rft_id=http%3A%2F%2Fnews.cnet.com%2FBattle-of-the-blog%2F2009-1032_3-5059006.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-20"><span><b><a href="#cite_ref-20">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.rssboard.org/advisory-board-notes">"Advisory Board Notes"</a>. <a href="https://en.wikipedia.org/wiki/RSS_Advisory_Board" title="RSS Advisory Board">RSS Advisory Board</a>. July 18, 2003. <a rel="nofollow" href="https://web.archive.org/web/20070927051743/http://www.rssboard.org/advisory-board-notes">Archived</a> from the original on September 27, 2007<span>. Retrieved <span>September 4,</span> 2007</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Advisory+Board+Notes&amp;rft.pub=RSS+Advisory+Board&amp;rft.date=2003-07-18&amp;rft_id=http%3A%2F%2Fwww.rssboard.org%2Fadvisory-board-notes&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-21"><span><b><a href="#cite_ref-21">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.scripting.com/2003/07/18.html#rss20News">"RSS 2.0 News"</a>. <i>Scripting News</i>. <a href="https://en.wikipedia.org/wiki/Dave_Winer" title="Dave Winer">Dave Winer</a>. July 18, 2003. <a rel="nofollow" href="https://web.archive.org/web/20070822014007/http://www.scripting.com/2003/07/18.html#rss20News">Archived</a> from the original on August 22, 2007<span>. Retrieved <span>September 4,</span> 2007</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Scripting+News&amp;rft.atitle=RSS+2.0+News&amp;rft.date=2003-07-18&amp;rft_id=http%3A%2F%2Fwww.scripting.com%2F2003%2F07%2F18.html%23rss20News&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-22"><span><b><a href="#cite_ref-22">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.squarefree.com/burningedge/2004/09/26/2004-09-26-branch-builds/">"2004-09-26 Branch builds"</a>. <i>The Burning Edge</i>. September 26, 2004. <a rel="nofollow" href="https://web.archive.org/web/20141009071447/http://www.squarefree.com/burningedge/2004/09/26/2004-09-26-branch-builds/">Archived</a> from the original on October 9, 2014<span>. Retrieved <span>October 6,</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Burning+Edge&amp;rft.atitle=2004-09-26+Branch+builds&amp;rft.date=2004-09-26&amp;rft_id=http%3A%2F%2Fwww.squarefree.com%2Fburningedge%2F2004%2F09%2F26%2F2004-09-26-branch-builds%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-23"><span><b><a href="#cite_ref-23">^</a></b></span> <span>"<a rel="nofollow" href="https://web.archive.org/web/20051217102644/http://blogs.msdn.com/michael_affronti/archive/2005/12/15/504316.aspx">RSS icon goodness</a>", blog post by Michael A. Affronti of Microsoft (Outlook Program Manager), December 15, 2005</span>
</li>
<li id="cite_note-24"><span><b><a href="#cite_ref-24">^</a></b></span> <span><cite id="CITEREFtrond2006">trond (February 16, 2006). <a rel="nofollow" href="https://web.archive.org/web/20100417170259/http://my.opera.com/desktopteam/blog/show.dml/146296">"Making love to the new feed icon"</a>. Opera Desktop Team. Archived from <a rel="nofollow" href="http://my.opera.com/desktopteam/blog/show.dml/146296">the original</a> on April 17, 2010<span>. Retrieved <span>July 4,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Making+love+to+the+new+feed+icon&amp;rft.pub=Opera+Desktop+Team&amp;rft.date=2006-02-16&amp;rft.au=trond&amp;rft_id=http%3A%2F%2Fmy.opera.com%2Fdesktopteam%2Fblog%2Fshow.dml%2F146296&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-W3C_REC_XML_Namespace-25"><span><b><a href="#cite_ref-W3C_REC_XML_Namespace_25-0">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.w3.org/TR/REC-xml-names/">"Namespaces in XML 1.0"</a> (2nd&nbsp;ed.). W3C. August 16, 2006. <a rel="nofollow" href="https://web.archive.org/web/20110316043909/http://www.w3.org/TR/REC-xml-names/">Archived</a> from the original on March 16, 2011<span>. Retrieved <span>May 22,</span> 2008</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Namespaces+in+XML+1.0&amp;rft.edition=2nd&amp;rft.pub=W3C&amp;rft.date=2006-08-16&amp;rft_id=http%3A%2F%2Fwww.w3.org%2FTR%2FREC-xml-names%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-26"><span><b><a href="#cite_ref-26">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.w3.org/2001/10/glance/doc/howto.html">"W3C RSS 1.0 News Feed Creation How-To"</a>. <i>www.w3.org</i>. <a rel="nofollow" href="https://web.archive.org/web/20220614140126/https://www.w3.org/2001/10/glance/doc/howto.html">Archived</a> from the original on June 14, 2022<span>. Retrieved <span>February 5,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.w3.org&amp;rft.atitle=W3C+RSS+1.0+News+Feed+Creation+How-To&amp;rft_id=https%3A%2F%2Fwww.w3.org%2F2001%2F10%2Fglance%2Fdoc%2Fhowto.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-27"><span><b><a href="#cite_ref-27">^</a></b></span> <span><cite id="CITEREFHolzner">Holzner, Steven. <a rel="nofollow" href="http://www.peachpit.com/articles/article.aspx?p=674690">"Peachpit article"</a>. Peachpit article. <a rel="nofollow" href="https://web.archive.org/web/20111109173320/http://www.peachpit.com/articles/article.aspx?p=674690">Archived</a> from the original on November 9, 2011<span>. Retrieved <span>December 11,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Peachpit+article&amp;rft.pub=Peachpit+article&amp;rft.aulast=Holzner&amp;rft.aufirst=Steven&amp;rft_id=http%3A%2F%2Fwww.peachpit.com%2Farticles%2Farticle.aspx%3Fp%3D674690&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-28"><span><b><a href="#cite_ref-28">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20020803040757/http://www.syndic8.com/stats.php?Section=feeds#tabtable">"Syndic8 stats table"</a>. Syndic8.com. Archived from <a rel="nofollow" href="http://www.syndic8.com/stats.php?Section=feeds#tabtable">the original</a> on August 3, 2002<span>. Retrieved <span>August 12,</span> 2011</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Syndic8+stats+table&amp;rft.pub=Syndic8.com&amp;rft_id=http%3A%2F%2Fwww.syndic8.com%2Fstats.php%3FSection%3Dfeeds%23tabtable&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-29"><span><b><a href="#cite_ref-29">^</a></b></span> <span><cite><a rel="nofollow" href="https://lifehacker.com/the-best-podcast-search-engine-1818560337">"The Best Podcast Search Engine"</a>. <i>Lifehacker</i>. September 20, 2017. <a rel="nofollow" href="https://web.archive.org/web/20201129195032/https://lifehacker.com/the-best-podcast-search-engine-1818560337">Archived</a> from the original on November 29, 2020<span>. Retrieved <span>February 5,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Lifehacker&amp;rft.atitle=The+Best+Podcast+Search+Engine&amp;rft.date=2017-09-20&amp;rft_id=https%3A%2F%2Flifehacker.com%2Fthe-best-podcast-search-engine-1818560337&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-30"><span><b><a href="#cite_ref-30">^</a></b></span> <span><cite><a rel="nofollow" href="https://blogtrottr.com/">"Free realtime RSS and Atom feed to email service. Get your favourite blogs, feeds, and news delivered to your inbox"</a>. <a rel="nofollow" href="https://web.archive.org/web/20170128081150/http://blogtrottr.com/">Archived</a> from the original on January 28, 2017<span>. Retrieved <span>January 26,</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Free+realtime+RSS+and+Atom+feed+to+email+service.+Get+your+favourite+blogs%2C+feeds%2C+and+news+delivered+to+your+inbox.&amp;rft_id=https%3A%2F%2Fblogtrottr.com%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-31"><span><b><a href="#cite_ref-31">^</a></b></span> <span><cite><a rel="nofollow" href="https://rss.com/">"RSS Feed Reader, your tool for saving time and money at RSS.com"</a>. <a rel="nofollow" href="https://web.archive.org/web/20170125224151/https://www.rss.com/">Archived</a> from the original on January 25, 2017<span>. Retrieved <span>January 26,</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=RSS+Feed+Reader%2C+your+tool+for+saving+time+and+money+at+RSS.com&amp;rft_id=https%3A%2F%2Frss.com%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-32"><span><b><a href="#cite_ref-32">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.uslsoftware.com/how-to-use-thunderbird-to-get-rss-feeds/">"How to use Thunderbird to get RSS feeds! Here's How it Works"</a>. October 17, 2018. <a rel="nofollow" href="https://web.archive.org/web/20210413005112/https://www.uslsoftware.com/how-to-use-thunderbird-to-get-rss-feeds/">Archived</a> from the original on April 13, 2021<span>. Retrieved <span>February 5,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=How+to+use+Thunderbird+to+get+RSS+feeds%21+Here%27s+How+it+Works&amp;rft.date=2018-10-17&amp;rft_id=https%3A%2F%2Fwww.uslsoftware.com%2Fhow-to-use-thunderbird-to-get-rss-feeds%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-33"><span><b><a href="#cite_ref-33">^</a></b></span> <span><cite id="CITEREFLeslie_Sikos2011">Leslie Sikos (2011). <a rel="nofollow" href="https://web.archive.org/web/20150402152305/http://www.masteringhtml5css3.com/"><i>Web standards – Mastering HTML5, CSS3, and XML</i></a>. <a href="https://en.wikipedia.org/wiki/Apress" title="Apress">Apress</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-1-4302-4041-9" title="Special:BookSources/978-1-4302-4041-9"><bdi>978-1-4302-4041-9</bdi></a>. Archived from <a rel="nofollow" href="http://www.masteringhtml5css3.com/">the original</a> on April 2, 2015<span>. Retrieved <span>June 14,</span> 2022</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Web+standards+%E2%80%93+Mastering+HTML5%2C+CSS3%2C+and+XML&amp;rft.pub=Apress&amp;rft.date=2011&amp;rft.isbn=978-1-4302-4041-9&amp;rft.au=Leslie+Sikos&amp;rft_id=http%3A%2F%2Fwww.masteringhtml5css3.com&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-ClosureAnnouncement-34"><span><b><a href="#cite_ref-ClosureAnnouncement_34-0">^</a></b></span> <span><cite id="CITEREFHölzle">Hölzle, Urs. <a rel="nofollow" href="http://googleblog.blogspot.com/2013/03/a-second-spring-of-cleaning.html">"A second spring of cleaning"</a>. googleblog.blogspot.com. <a rel="nofollow" href="https://web.archive.org/web/20130314045128/http://googleblog.blogspot.com/2013/03/a-second-spring-of-cleaning.html">Archived</a> from the original on March 14, 2013<span>. Retrieved <span>March 14,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=A+second+spring+of+cleaning&amp;rft.pub=googleblog.blogspot.com&amp;rft.aulast=H%C3%B6lzle&amp;rft.aufirst=Urs&amp;rft_id=http%3A%2F%2Fgoogleblog.blogspot.com%2F2013%2F03%2Fa-second-spring-of-cleaning.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>

<li id="cite_note-36"><span><b><a href="#cite_ref-36">^</a></b></span> <span><cite><a rel="nofollow" href="http://osxdaily.com/2014/11/03/subscribe-rss-feeds-safari-os-x/">"Subscribe to RSS Feeds in Safari for OS X Yosemite"</a>. OSX Daily. November 3, 2014. <a rel="nofollow" href="https://web.archive.org/web/20150121185232/http://osxdaily.com/2014/11/03/subscribe-rss-feeds-safari-os-x/">Archived</a> from the original on January 21, 2015<span>. Retrieved <span>January 24,</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Subscribe+to+RSS+Feeds+in+Safari+for+OS+X+Yosemite&amp;rft.pub=OSX+Daily&amp;rft.date=2014-11-03&amp;rft_id=http%3A%2F%2Fosxdaily.com%2F2014%2F11%2F03%2Fsubscribe-rss-feeds-safari-os-x%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-37"><span><b><a href="#cite_ref-37">^</a></b></span> <span><cite id="CITEREFCimpanu2018">Cimpanu, Catalin (July 26, 2018). <a rel="nofollow" href="https://www.bleepingcomputer.com/news/software/mozilla-to-remove-support-for-built-in-feed-reader-from-firefox/">"Mozilla to Remove Support for Built-In Feed Reader From Firefox"</a>. <i>BleepingComputer</i>. <a rel="nofollow" href="https://web.archive.org/web/20180726144716/https://www.bleepingcomputer.com/news/software/mozilla-to-remove-support-for-built-in-feed-reader-from-firefox/">Archived</a> from the original on July 26, 2018<span>. Retrieved <span>July 26,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=BleepingComputer&amp;rft.atitle=Mozilla+to+Remove+Support+for+Built-In+Feed+Reader+From+Firefox&amp;rft.date=2018-07-26&amp;rft.aulast=Cimpanu&amp;rft.aufirst=Catalin&amp;rft_id=https%3A%2F%2Fwww.bleepingcomputer.com%2Fnews%2Fsoftware%2Fmozilla-to-remove-support-for-built-in-feed-reader-from-firefox%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-38"><span><b><a href="#cite_ref-38">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.mozilla.org/en-US/firefox/64.0/releasenotes/">"Firefox 64.0, See All New Features, Updates and Fixes"</a>. <i>Mozilla</i>. December 11, 2018. <a rel="nofollow" href="https://web.archive.org/web/20181211143259/https://www.mozilla.org/en-US/firefox/64.0/releasenotes/">Archived</a> from the original on December 11, 2018<span>. Retrieved <span>December 12,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Mozilla&amp;rft.atitle=Firefox+64.0%2C+See+All+New+Features%2C+Updates+and+Fixes&amp;rft.date=2018-12-11&amp;rft_id=https%3A%2F%2Fwww.mozilla.org%2Fen-US%2Ffirefox%2F64.0%2Freleasenotes%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-39"><span><b><a href="#cite_ref-39">^</a></b></span> <span><cite id="CITEREFBarrett2018">Barrett, Brian (March 30, 2018). <a rel="nofollow" href="https://www.wired.com/story/rss-readers-feedly-inoreader-old-reader/">"It's Time for an RSS Revival"</a>. <i>Wired</i>. <a rel="nofollow" href="https://web.archive.org/web/20210812114050/https://www.wired.com/story/rss-readers-feedly-inoreader-old-reader/">Archived</a> from the original on August 12, 2021<span>. Retrieved <span>July 26,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Wired&amp;rft.atitle=It%27s+Time+for+an+RSS+Revival&amp;rft.date=2018-03-30&amp;rft.aulast=Barrett&amp;rft.aufirst=Brian&amp;rft_id=https%3A%2F%2Fwww.wired.com%2Fstory%2Frss-readers-feedly-inoreader-old-reader%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
<li id="cite_note-40"><span><b><a href="#cite_ref-40">^</a></b></span> <span><cite id="CITEREFCampbell2021">Campbell, Ian Carlos (October 8, 2021). <a rel="nofollow" href="https://www.theverge.com/2021/10/8/22716813/google-chrome-follow-button-rss-reader">"Google Reader is still defunct, but now you can 'follow' RSS feeds in Chrome on Android"</a>. <i>The Verge</i>. <a rel="nofollow" href="https://web.archive.org/web/20220605165318/https://www.theverge.com/2021/10/8/22716813/google-chrome-follow-button-rss-reader">Archived</a> from the original on June 5, 2022<span>. Retrieved <span>June 19,</span> 2022</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Verge&amp;rft.atitle=Google+Reader+is+still+defunct%2C+but+now+you+can+%27follow%27+RSS+feeds+in+Chrome+on+Android&amp;rft.date=2021-10-08&amp;rft.aulast=Campbell&amp;rft.aufirst=Ian+Carlos&amp;rft_id=https%3A%2F%2Fwww.theverge.com%2F2021%2F10%2F8%2F22716813%2Fgoogle-chrome-follow-button-rss-reader&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARSS"></span></span>
</li>
</ol></div>
<h2><span id="External_links">External links</span></h2>

<ul><li><a rel="nofollow" href="http://www.rssboard.org/rss-0-9-0">RSS 0.90 Specification</a></li>
<li><a rel="nofollow" href="http://www.rssboard.org/rss-0-9-1-netscape">RSS 0.91 Specification</a></li>
<li><a rel="nofollow" href="http://web.resource.org/rss/1.0/">RSS 1.0 Specifications</a></li>
<li><a rel="nofollow" href="http://www.rssboard.org/rss-specification">RSS 2.0 Specification</a></li>
<li><a rel="nofollow" href="https://web.archive.org/web/20110718034619/http://diveintomark.org/archives/2002/09/06/history_of_the_rss_fork">History of the RSS Fork</a> (Mark Pilgrim)</li>
<li><a rel="nofollow" href="https://www.xul.fr/en-xml-rss.html">Building an RSS feed</a> Tutorial with example</li></ul>





<!-- 
NewPP limit report
Parsed by mw‐web.eqiad.main‐7d644d6d99‐qsftd
Cached time: 20240315110540
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.817 seconds
Real time usage: 1.060 seconds
Preprocessor visited node count: 4966/1000000
Post‐expand include size: 166970/2097152 bytes
Template argument size: 5945/2097152 bytes
Highest expansion depth: 24/100
Expensive parser function count: 17/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 148753/5000000 bytes
Lua time usage: 0.512/10.000 seconds
Lua memory usage: 8675186/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  915.847      1 -total
 27.41%  251.036      1 Template:Reflist
 16.24%  148.715     34 Template:Cite_web
 10.77%   98.630      9 Template:Navbox
  8.56%   78.396      1 Template:Web_syndication
  8.45%   77.375      1 Template:Infobox_file_format
  8.43%   77.162      1 Template:Short_description
  8.05%   73.749      1 Template:Infobox
  7.57%   69.316     13 Template:Main_other
  6.33%   58.011      2 Template:Cite_book
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:93489-0!canonical and timestamp 20240315110540 and revision id 1210081177. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Postgres is eating the database world (247 pts)]]></title>
            <link>https://medium.com/@fengruohang/postgres-is-eating-the-database-world-157c204dcfc4</link>
            <guid>39711863</guid>
            <pubDate>Fri, 15 Mar 2024 03:43:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@fengruohang/postgres-is-eating-the-database-world-157c204dcfc4">https://medium.com/@fengruohang/postgres-is-eating-the-database-world-157c204dcfc4</a>, See on <a href="https://news.ycombinator.com/item?id=39711863">Hacker News</a></p>
Couldn't get https://medium.com/@fengruohang/postgres-is-eating-the-database-world-157c204dcfc4: Error: Request failed with status code 429]]></description>
        </item>
        <item>
            <title><![CDATA[Vision Pro: What we got wrong at Oculus that Apple got right (498 pts)]]></title>
            <link>https://hugo.blog/2024/03/11/vision-pro/</link>
            <guid>39711725</guid>
            <pubDate>Fri, 15 Mar 2024 03:15:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hugo.blog/2024/03/11/vision-pro/">https://hugo.blog/2024/03/11/vision-pro/</a>, See on <a href="https://news.ycombinator.com/item?id=39711725">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><em>by <a href="https://twitter.com/hbarra" target="_blank" rel="noreferrer noopener">Hugo Barra</a></em> (former Head of Oculus at Meta)</p>



<p>Friends and colleagues have been asking me to share my perspective on the Apple Vision Pro as a product. Inspired by my dear friend <a href="https://ma.tt/category/birthday/" target="_blank" rel="noreferrer noopener">Matt Mullenweg’s 40th post</a>, I decided to put pen to paper.</p>



<p>This started as blog post and became an essay before too long, so I’ve structured my writing in multiple sections each with a clear lead to make it a bit easier to digest — peppered with my own ‘takes’. I’ve tried to stick to original thoughts for the most part and link to what others have said where applicable.</p>



<p>Some of the topics I touch on:</p>



<ul>
<li>Why I believe Vision Pro may be an over-engineered “devkit”</li>



<li>The genius &amp; audacity behind some of Apple’s hardware decisions</li>



<li><em>Gaze &amp; pinch</em> is an incredible UI superpower and major industry ah-ha moment</li>



<li>Why the Vision Pro software/content story is so dull and unimaginative</li>



<li>Why most people won’t use Vision Pro for watching TV/movies</li>



<li>Apple’s bet in immersive video is a total game-changer for <em>Live Sports</em></li>



<li>Why I returned my Vision Pro… and my Top 10 wishlist to reconsider</li>



<li>Apple’s VR debut is the best thing that ever happened to Oculus/Meta</li>



<li>My unsolicited product advice to Meta for <em>Quest Pro 2</em> and beyond</li>
</ul>



<h2><strong>The Apple Vision Pro is the Northstar the VR industry needed, whether we admit it or not</strong></h2>



<p>I’ve been a VR enthusiast for most of my adult life, from working as an intern at <a href="https://www.roadtovr.com/end-of-an-era-disneyquest-first-vr-attraction-set-to-close/" target="_blank" rel="noreferrer noopener">Disney Quest VR</a> in the 1990s, to being an early backer of the <a href="https://www.kickstarter.com/projects/1523379957/oculus-rift-step-into-the-game">Oculus Rift DK1 on Kickstarter</a> in 2013, to leading the Oculus VR/AR team at Meta from 2017 to 2020 (and getting to work alongside VR legends like John Carmack, Brendan Iribe and Jason Rubin), and always testing every VR product or experience I can get my hands on.</p>



<p>Back in my Oculus days, I used to semi-seriously joke with our team (and usually got a lot of heat for it!) that the best thing that could ever happen to us was having Apple enter the VR industry and become a direct competitor to Oculus. I’ve always believed that strong competition pushes a team to do their best work in any industry. This became clear to me especially after living for nearly 10 years at the center of the iOS/Android battle of ecosystems where each side made the other infinitely better by constantly raising the bar on UX, features, performance, developer APIs etc, and seeing each side respond by not only fast following but usually also improving on what the other had released. (And this definitely went both ways: iOS copied Android as much as Android copied iOS).</p>



<p>But in the case of VR at Oculus, we also never really felt like the world had a Northstar that could truly capture human hearts and minds, and without that it would be impossible to transition VR from being a niche gamer tech to the incredible spatial computing paradigm that we always thought it potentially represented (which I still very much believe in). Apple could <em>really </em>help us if they cared about VR.</p>



<p>The Vision Pro launch has more or less done exactly what I had always hoped for, which is to build a huge wave of awareness and curiosity that elevates the spatial computing ecosystem and could ultimately lead to mass-market consumer demand and a lot more developer interest that VR has ever had. Now it’s up to the industry to create enough user value and demonstrate whether this is in fact the future of computing.</p>



<h2><strong>The Vision Pro’s <em>instant magic</em> comes down to just: (1) an unprecedented new level of presence in VR, and (2) a new UI superpower using <strong>gaze &amp; pinch</strong></strong></h2>



<p>Using Vision Pro is an instantly magical and intuitive experience — whether or not you’ve used other VR headsets — purely because of Apple’s unrelenting focus on delivering two specific capabilities that speak to our humanity:</p>



<p><strong>1) Feeling present and connected to your physical world</strong>: thanks to a high-fidelity passthrough (“mixed reality”) experience with very low latency, excellent distortion correction (<em>much</em> better than Quest 3), and sufficiently high resolution that allows you to even see your phone/computer screen through the passthrough cameras (i.e. without taking your headset off).</p>



<p>Even though there are major gaps left to be filled in future versions of the Vision Pro hardware (which I’ll get into later), this level of connection with the real world — or “presence” as VR folks like to call it — is something that no other VR headset has ever come even close to delivering and so far was only remotely possible with AR headsets (ex: HoloLens and Magic Leap) which feature physically transparent displays but have their own significant limitations in many other areas. Apple’s implementation of Optic ID as an overlay on top of live passthrough is a beautiful design decision that only enhances this sense of presence.</p>







<blockquote>
<p><mark><strong>MY TAKE: </strong>The Vision Pro high-fidelity passthrough experience parallels <strong>Apple’s introduction of the iPhone’s original <em>retina display</em></strong>, which set a new experience bar and gold standard in mobile display fidelity. While much remains to be improved in the Vision Pro passthrough experience, Apple is unquestionably setting a new standard for all future headsets (by any vendor) that VR passthrough must be good enough to closely resemble reality.</mark></p>
</blockquote>



<p><strong>2) Having a new UI superpower with gaze &amp; pinch</strong>, thanks to a very precise eye tracking system (with 2 dedicated cameras per eye) embedded into the lenses, coupled with a wide-field-of-view hand tracking system that can “see” a finger pinch even with your hands are down or resting on your lap. Because it works so effortlessly for the user, it really feels like having a new “laser vision” superpower.</p>



<p>The hardware needed to track eyes and hands in VR has been around for over a decade, and it’s Apple unique ability to bring everything together in a magical way that makes this UI superpower the most important achievement of the entire Vision Pro product, without a shadow of doubt.</p>







<blockquote>
<p><mark><strong>MY TAKE: </strong>The Vision Pro’s new “gaze + pinch” input modality is <strong>the VR equivalent of the iPhone’s capacitive multi-touch gestures</strong>. Introduced by Apple with the first iPhone launch nearly 17 years ago, multi-touch instantly became a new standard that changed computing forever. “Gaze + pinch” is so groundbreaking that it’s an instant defacto standard for VR interaction that future VR headsets be forced to adopt sooner or later. It’s also going to be a huge developer unlock that leads to gaze-based interaction ideas that will blow our minds. </mark></p>
</blockquote>



<h2>Hardware</h2>



<h2><strong>Vision Pro is a meticulously over-engineered “devkit” that is <em>far too heavy</em> <em>to have product-market fit</em> but good enough to seed curiosity into the world</strong></h2>



<p>The Oculus VR story began with the 2013 launch of <em><a href="https://en.wikipedia.org/wiki/Oculus_Rift#Development_Kit_1" target="_blank" rel="noreferrer noopener">Oculus Rift DK1</a></em> (short for “devkit v1” or “development kit v1”). This was a headset launched by the original Oculus startup team — years before it was acquired by Facebook — with the explicit goal of seeding developer interest well before a commercial release. Given that VR was a non-existing market then, releasing a devkit was the correct and necessary strategy <em>there and then</em> for a startup to start building a content library as well as momentum among enthusiasts ahead of launching a consumer product. The team released a <a href="https://en.wikipedia.org/wiki/Oculus_Rift#Development_Kit_2" target="_blank" rel="noreferrer noopener"><em>DK2</em></a> about a year later in 2014, and finally launched the first Oculus Rift consumer headset in 2015.</p>







<figure><img data-attachment-id="208" data-permalink="https://hugo.blog/2024/03/11/vision-pro/palmer-luckey-oculus-dk1/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/03/palmer-luckey-oculus-dk1.png" data-orig-size="1500,844" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="palmer-luckey-oculus-dk1" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/03/palmer-luckey-oculus-dk1.png?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/03/palmer-luckey-oculus-dk1.png?w=1024" width="1024" height="576" src="https://hugobarracom.files.wordpress.com/2024/03/palmer-luckey-oculus-dk1.png?w=1024" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/03/palmer-luckey-oculus-dk1.png?w=1024 1024w, https://hugobarracom.files.wordpress.com/2024/03/palmer-luckey-oculus-dk1.png?w=150 150w, https://hugobarracom.files.wordpress.com/2024/03/palmer-luckey-oculus-dk1.png?w=300 300w, https://hugobarracom.files.wordpress.com/2024/03/palmer-luckey-oculus-dk1.png?w=768 768w, https://hugobarracom.files.wordpress.com/2024/03/palmer-luckey-oculus-dk1.png 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Oculus co-founder Palmer Luckey wearing the original Oculus Rift DK1 released in 2013 </figcaption></figure>



<p>When I joined Facebook to lead the Oculus team in 2017 after the acquisition, one of the many battles I found myself in the middle of almost immediately was the “devkit war”. The Oculus team’s DK1 and DK2 legacy was so strong that it was not uncommon to hear arguments in product meetings pushing for us to launch VR headsets still in prototype stage as “devkits” to end users. Since Oculus was no longer a startup — and had the resources to both extensively test prototypes without launching them as products <em>and </em>run extensive pre-launch developer programs — it no longer made sense for Oculus devkits to exist. This stance often didn’t make me very popular amongst some of my Oculus OG colleagues.</p>



<p>Fast forward to 2024. After the Vision Pro launch, the VR hardware enthusiast community (including Oculus OG folks I’m still in touch with) quickly arrived at the conclusion that Apple really played it safe in the design of this first VR product by over-engineering it. For starters, Vision Pro ships with more sensors than what’s likely necessary to deliver Apple’s intended experience. This is typical in a first-generation product that’s been under development for so many years. It makes Vision Pro start to feel like a devkit.</p>







<figure><img data-attachment-id="148" data-permalink="https://hugo.blog/2024/03/11/vision-pro/visionpro_sensors/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/02/visionpro_sensors.png" data-orig-size="804,486" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="visionpro_sensors" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/02/visionpro_sensors.png?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/02/visionpro_sensors.png?w=804" width="804" height="486" src="https://hugobarracom.files.wordpress.com/2024/02/visionpro_sensors.png?w=804" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/02/visionpro_sensors.png 804w, https://hugobarracom.files.wordpress.com/2024/02/visionpro_sensors.png?w=150 150w, https://hugobarracom.files.wordpress.com/2024/02/visionpro_sensors.png?w=300 300w, https://hugobarracom.files.wordpress.com/2024/02/visionpro_sensors.png?w=768 768w" sizes="(max-width: 804px) 100vw, 804px"><figcaption>A sensor party: 6 tracking cameras, 2 passthrough cameras, 2 depth sensors<br>(plus 4 eye-tracking cameras not shown)</figcaption></figure>



<p>Here’s a quick comparison with existing VR headsets:</p>







<figure><table><thead><tr><th>Sensor</th><th>Vision Pro</th><th>Meta <br>Quest 3</th><th>Meta <br>Quest Pro</th></tr></thead><tbody><tr><td>Environment passthrough cameras</td><td>2</td><td>2</td><td>1</td></tr><tr><td>World tracking cameras</td><td>6</td><td>4</td><td>6</td></tr><tr><td>Depth sensors</td><td>2</td><td>1</td><td>–</td></tr><tr><td>Eye tracking cameras</td><td>4</td><td>–</td><td>2</td></tr><tr><td><strong>Total</strong></td><td><strong>14</strong></td><td><strong>7</strong></td><td><strong>9</strong></td></tr></tbody></table><figcaption>Side-by-side comparison with the sensor stacks of other VR headsets</figcaption></figure>



<p>This over-spec’ing is unsurprising and characteristic of a v1 product where its creator wants to ensure it survives the hardest tests early users will no doubt want to put the product through. It’s also a way for Apple to see how far developers will push the product’s capabilities, as Apple is no doubt relying on that community to produce the majority of software/content magic for this new type of computer, as they’ve previously done with every other device class.</p>



<p>Apple’s decision to over-spec the Vision Pro does, however, lead to the inevitable consequence of a headset weighing above 600g — heavier than most other VR headsets in the market to date — that <strong>makes it difficult for most people to wear it for more than 30-45 minutes at a time without suffering a lot of discomfort</strong>. Most of the discomfort comes in the form of pressure against the user’s face and the back of the person’s head.</p>







<blockquote>
<p><mark><strong>MY TAKE:</strong> Because of its heavy weight, Vision Pro has inevitably landed in the world as a high-quality “devkit” designed to capture everyone’s curiosity, hearts &amp; minds with its magic (especially through the voice of enthusiastic tech influencers) while being realistically focused on developers as its primary audience. In other words, the Vision Pro is a devkit that helps prepare the world to receive a more mainstream Apple VR headset that could have product-market fit in 1 or 2 generations.</mark></p>
</blockquote>



<p>All things considered, I do believe Apple’s calculus was correct in prioritizing launching a first-generation product with fewer experience and design compromises at the expense of user comfort. And while many people have argued Apple could have avoided this major comfort issue by redistributing weight or using lighter materials, those attempts would have come at the expense of beauty and design. (I’ll come back to the weight issue shortly.)</p>



<p>With this in mind, it’s easy to understand two particularly important decisions Apple made for the Vision Pro launch:</p>



<ul>
<li><strong>Designing an incredible in-store Vision Pro demo experience</strong>, with the primary goal of getting as many people as possible to experience the magic of VR through Apple’s lenses — most of whom have no intention to even consider a $4,000 purchase. The demo is only secondarily focused on actually selling Vision Pro headsets.</li>



<li><strong>Launching an iconic woven strap that photographs beautifully</strong> even though this strap simply isn’t comfortable enough for the vast majority of head shapes. It’s easy to conclude that this decision paid off because nearly every bit of media coverage (including and especially third-party reviews on YouTube) uses the woven strap despite the fact that it’s less comfortable than the dual loop strap that’s “hidden in the box”.</li>
</ul>



<h2><strong>The existence of Vision Pro in 2024 is entirely a function of Apple managing to ship a <em>first-of-its-kind</em> ultra <strong>high-resolution display</strong></strong></h2>



<p>One of our biggest product positioning struggles within the Oculus VR team from the very beginning — especially when trying to convince reviewers — was always related to having <em>underwhelming displays</em>. Every single Oculus headset that ever shipped (including the latest Quest 3) has suffered from resolution/pixelation issues varying from “terrible” to “pretty bad”. It’s like we’re living in the VR-equivalent world of VGA computer monitors.</p>







<blockquote>
<p><mark><strong>MY TAKE: </strong>In order For Apple to make a huge splash entering the VR market — a category that’s been around the consumer world for nearly 10 years — they needed to launch a product that was unambiguously better than anything that had ever existed. The obvious way to do that was to <strong>attack the Achilles heel of all existing headsets and reinvent the VR display</strong>, and that’s exactly what Apple did with the Vision Pro.</mark></p>
</blockquote>



<p>Vision Pro is the first VR headset that offers good enough resolution and visual acuity with little semblance of a <a href="https://pimax.com/what-is-the-screen-door-effect-in-vr/" target="_blank" rel="noreferrer noopener"><em>screen door effect</em></a> or pixelation artifacts. This level of presence and fidelity could only be made possible with an ultra high-res display, and it’s 100% clear that achieving an first-of-its-kind level of display quality was the internal launch bar for Vision Pro at Apple.</p>



<p>Apple’s relentless and uncompromising hardware insanity is largely what made it possible for such a high-res display to exist in a VR headset, and it’s clear that this product couldn’t possibly have launched much sooner than 2024 for one simple limiting factor — the maturity of micro-OLED displays plus the existence of power-efficient chipsets that can deliver the heavy compute required to drive this kind of display (i.e. the M2).</p>



<p>Micro-OLED displays differ from any other previous consumer display technology because they are manufactured on top of a silicon substrate (similar to how semiconductor chips are made). To put the insanity of micro-OLED displays in perspective, the <strong>Vision Pro panel has a 7.4x higher pixel density than the latest iPhone and nearly 3x the Quest 3</strong>:</p>







<figure><table><thead><tr><th>Feature</th><th>Vision Pro</th><th>Bigscreen Beyond</th><th>Quest 3</th><th>iPhone 15 Pro Max</th></tr></thead><tbody><tr><td>Display Type</td><td>Micro-OLED</td><td>Micro-OLED</td><td>LCD</td><td>OLED</td></tr><tr><td>Resolution <br>(pixels per eye)</td><td>3660 x 3200</td><td>2560 x 2560</td><td>2064 x 2208</td><td>2796 x 1290</td></tr><tr><td>Total Pixels</td><td>23 million</td><td>13 million</td><td>9 million</td><td>3.6 million</td></tr><tr><td>Pixels Per Inch (PPI)</td><td>3386</td><td>(unknown)</td><td>1218</td><td>460</td></tr><tr><td>Pixels Per Degree (PPD)</td><td>34</td><td>32</td><td>25</td><td>94 <br>(at 1 foot distance)</td></tr></tbody></table></figure>



<p><em>(See the appendix of this essay for a quick explanation of <strong>Pixels Per Degree </strong>or <strong>PPD</strong>)</em></p>



<p>The folks at iFixit created this stunning GIF using a scientific microscope to compare the pixel size of the Vision Pro display — which measures 7.5 μm, the size of a human red blood cell — with the pixel size of the latest iPad and iPhone displays:</p>







<figure><img data-attachment-id="54" data-permalink="https://hugo.blog/2024/03/11/vision-pro/avp-display/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/02/avp-display.gif" data-orig-size="940,520" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="avp-display" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/02/avp-display.gif?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/02/avp-display.gif?w=940" width="940" height="520" src="https://hugobarracom.files.wordpress.com/2024/02/avp-display.gif?w=940" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/02/avp-display.gif 940w, https://hugobarracom.files.wordpress.com/2024/02/avp-display.gif?w=150 150w, https://hugobarracom.files.wordpress.com/2024/02/avp-display.gif?w=300 300w, https://hugobarracom.files.wordpress.com/2024/02/avp-display.gif?w=768 768w" sizes="(max-width: 940px) 100vw, 940px"><figcaption>Source: <a href="https://www.ifixit.com/News/90409/vision-pro-teardown-part-2-whats-the-display-resolution" target="_blank" rel="noreferrer noopener">iFixit</a></figcaption></figure>



<p>The Apple Vision Pro’s micro-OLED display has created a lot of chatter in my hardware supply chain world, with lots of companies — predominantly smartphone OEMs — quickly racing to try and build a product that can deliver a similar experience to Vision Pro. Apple has secured a 1-year exclusive with <a href="https://www.sony-semicon.com/en/products/microdisplay/oled.html" target="_blank" rel="noreferrer noopener">Sony Semiconductor Solutions Group</a> and its second supplier <a href="https://www.seeya-tech.com/en/" target="_blank" rel="noreferrer noopener">SeeYA Technology</a>. There are also rumors Apple is dropping Sony as a display supplier and replacing it with <a href="https://www.boe.com/en/Enterprise/VR_AR">BOE</a> (whose <a href="https://www.boe.com/en/Enterprise/VR_AR">website</a> says a panel equivalent to Vision Pro is at “sample” stage).</p>







<blockquote>
<p><mark><strong>MY TAKE: </strong>I fully expect the <a href="https://www.prnewswire.com/news-releases/lg-and-meta-forge-collaboration-with-meta-to-accelerate-xr-business-302073794.html" target="_blank" rel="noreferrer noopener">recently announced Meta/LG partnership</a> to be all about creating a supply chain advantage for Meta so they can race a <em>Quest Pro 2 </em>product into market that can compete with Vision Pro with LG putting some skin in the game to lower the street price of the headset.</mark></p>
</blockquote>



<p>(P.S. For anyone who wants to dig into more details of the Vision Pro display and pass-through system, I highly recommend <a href="https://www.ifixit.com/News/90409/vision-pro-teardown-part-2-whats-the-display-resolution" target="_blank" rel="noreferrer noopener">this article from iFixit</a> and <a href="https://kguttag.com/about-karl-guttag/" target="_blank" rel="noreferrer noopener">this article from Karl Guttag</a>, who’s an amazingly talented expert in display devices).</p>



<h2><strong>Apple made the Vision Pro display <em>intentionally blurry</em> in order to hide pixelation artifacts and make graphics appear smoother</strong></h2>



<p>There is a very good reason Apple has not used the word <em>retina</em> anywhere in their marketing materials for Vision Pro. It’s the simple fact that Vision Pro’s display does not pass the retina test — which is a <em>resolution high enough that the human eye can no longer discern individual pixels</em>. The Vision Pro display is nowhere near retina quality for a VR headset (see appendix for details) and yet <strong>our eyes cannot see individual pixels when looking at it</strong>. What gives?</p>



<p>During the first few days using Vision Pro, there was something that kept calling my attention but which I struggled to get my arms (or eyes) around. Everything my eyes saw in the headset felt a bit softer than I expected, and I initially attributed this to the seemingly refreshing absence of any <em><a href="https://pimax.com/what-is-the-screen-door-effect-in-vr/" target="_blank" rel="noreferrer noopener">screen door effect</a></em> — a pixelation artifact that has essentially doomed all VR headsets created up until now.</p>



<p>Well, as it turns out, the incredible <a href="https://kguttag.com/about-karl-guttag/" target="_blank" rel="noreferrer noopener">Karl Guttag</a> ran a meticulous <a href="https://kguttag.com/2024/03/01/apple-vision-pros-optics-blurrier-lower-contrast-than-meta-quest-3/" target="_blank" rel="noreferrer noopener">photographic analysis of the Vision Pro display</a> and came to a curious and possibly disturbing conclusion: <strong>Apple <em>intentionally calibrated the Vision Pro display slightly out of focus</em> to make pixels a bit blurry and hide the screen door effect “in plain sight”</strong>.</p>



<p>This image from Karl’s blog explains this well by comparing Vision Pro and Quest 3 displays side by side at a close enough distance where it’s possible to see individual pixels and clearly see the intentional blur that was added to the Vision Pro display:</p>







<figure><img data-attachment-id="179" data-permalink="https://hugo.blog/2024/03/11/vision-pro/avp-vs-mq3-close-up-crop-copy/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/03/avp-vs-mq3-close-up-crop-copy.webp" data-orig-size="471,519" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="avp-vs-mq3-close-up-crop-copy" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/03/avp-vs-mq3-close-up-crop-copy.webp?w=272" data-large-file="https://hugobarracom.files.wordpress.com/2024/03/avp-vs-mq3-close-up-crop-copy.webp?w=471" loading="lazy" width="471" height="519" src="https://hugobarracom.files.wordpress.com/2024/03/avp-vs-mq3-close-up-crop-copy.webp?w=471" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/03/avp-vs-mq3-close-up-crop-copy.webp 471w, https://hugobarracom.files.wordpress.com/2024/03/avp-vs-mq3-close-up-crop-copy.webp?w=136 136w, https://hugobarracom.files.wordpress.com/2024/03/avp-vs-mq3-close-up-crop-copy.webp?w=272 272w" sizes="(max-width: 471px) 100vw, 471px"><figcaption>Extreme close-up comparison between Vision Pro (AVP) and Quest 3 (MQ3) displays (Source: <a href="https://kguttag.com/2024/03/01/apple-vision-pros-optics-blurrier-lower-contrast-than-meta-quest-3/">KGOnTech</a>)</figcaption></figure>



<p>What Karl concluded is that even though Quest 3 has a much lower display resolution than Vision Pro (1,218 PPI vs. 3,386 PPI), Quest 3 appears objectively crisper especially when showing high-contrast graphics. In other words, Quest 3 is squeezing the highest possible resolution out of its display at the expense of a “harsher look” while Apple is giving up some of the Vision Pro’s display resolution in order to achieve a “softer look”. Karl may disagree with my conclusion on this point:</p>







<blockquote>
<p><mark><strong>MY TAKE: </strong> Intentionally making the Vision Pro optics blurry is a clever move by Apple because it results in way smoother graphics across the board by hiding the screen door effect (which in practice means that you won’t see pixelation artifacts). This is also where Apple’s “taste” comes in, essentially resulting in the Vision Pro display being tuned to have a unique, softer, and more refined aesthetic than Quest 3 (or any other VR headsets). This is certainly a refreshing approach to designing VR hardware.</mark></p>
</blockquote>



<p>With this design decision, Apple is no doubt giving up a bit of the Vision Pro display’s high pixel resolution in order to achieve overall smoother graphics. You are definitely losing some text crispness in order to gain a higher perception of quality for images, video and 3D animations. This is a big benefit of starting with an ultra high-resolution micro-OLED display — Apple had enough pixels to work with that they could afford to make this trade-off. <strong>This is the kind of thing that our hardcore VR engineers at Oculus would have fought against to the end of the world, and I doubt we could have ever shipped a “blurred headset”, LOL!</strong></p>



<h2><strong>Sadly, the Vision Pro display suffers from <em>significant motion blur &amp; image quality issues</em> that render passthrough mode unusable for longer periods</strong></h2>



<p>While Apple’s decision to make individual pixels blurry on the Vision Pro display was extremely clever, the headset unfortunately suffers from a completely different type of blur that’s extremely problematic for the overall experience.</p>



<p>From the very first time I put on my Vision Pro, I noticed <strong>a lot of motion blur in passthrough</strong> mode even in excellent ambient lighting conditions and a still noticeable amount even when viewing immersive content. While my immediate instinct was to think that all VR headsets have that kind of motion blur and it’s just more noticeable on Vision Pro, a side-by-side comparison with Quest 3 quickly proved it’s significantly more serious on Vision Pro. This is particularly surprising considering that the passthrough cameras and display are both running at 90 hertz.</p>



<p>Since none of the initial Vision Pro reviews pointed out this issue, I ended up even calling Apple support to find out if this might be a known problem or possibly even a hardware defect. But then more in-depth reviews began pointing out the same problem (I highly recommend <a href="https://youtu.be/eOH33sWgds8?si=TTWCd8-UqX-D9-Eg" target="_blank" rel="noreferrer noopener">this review by Snazzy Labs</a>).</p>



<p>Motion blur in passthrough mode ended up being one of the many reasons why I decided to return my Vision Pro, because it’s just uncomfortable, leads to unnecessary eye strain, and really gets in the way of anyone using the headset for longer periods of time in passthrough mode.</p>



<p>There are other noticeable issues as well which affect passthrough mode, including <strong>very little dynamic range, incorrect white balance in most indoor use cases, and signs of edge distortion and chromatic aberration</strong>. Some of these might be addressed by software updates, but I expect most will not as they probably are limitations of the hardware stack.</p>



<h2><strong>The Vision Pro packs <em>a lot more computing power </em>than most people might realize — the M2 + R1 combination puts it at the level of a MacBook Pro</strong></h2>



<p>Any standalone VR headset is basically a 2-in-1 system: a regular “computing” computer and a spatial computer bundled together.</p>



<ul>
<li><strong>A <em>regular computer</em> in charge of running applications and performing general computation</strong>: this is everything that happens on your smartphone, tablet or notebook, including running the OS, executing applications across CPU/GPU loads, and doing computation work in the background.</li>



<li><strong>A <em>spatial computer</em> in charge of the environment</strong>: it keeps track of the whole environment, tracks your hands &amp; eyes, and ensures that everything — your surroundings, the OS system UI, and your apps — gets rendered in the right physical place in space and updated at 90 to 120 times per second while your head and body are moving around.</li>
</ul>



<p>These two “computers” must operate together without missing a beat — any latency above 20 milliseconds becomes quickly noticeable in VR and will often translate very quickly into user perception of unresponsiveness or jankiness, which can cause discomfort, eye strain or even dizziness for many people.</p>



<p>Enter the Vision Pro dual-chip design:</p>







<blockquote>
<p>“<em>A unique dual‑chip design enables the spatial experiences on Apple Vision Pro. The powerful M2 chip simultaneously runs visionOS, executes advanced computer vision algorithms, and delivers stunning graphics, all with incredible efficiency. And the brand-new R1 chip is specifically dedicated to process input from the cameras, sensors, and microphones, streaming images to the displays within 12 milliseconds — for a virtually lag-free, real-time view of the world.</em>“</p>
<cite>Apple Vision Pro website</cite></blockquote>



<p>The Vision Pro ships with the same M2 chip as the 2022 iPad Pro (or 2022 MacBook Air) alongside the new R1 chip which handles the massive amount of data coming from the 20+ tracking cameras and depth sensors (sensor fusion). What’s interesting to note is that Vision Pro actually does perform largely like an iPad Pro in benchmark tests that push CPU and GPU to their limits in both single-core and multi-core scenarios (see chart below). </p>







<figure><img data-attachment-id="83" data-permalink="https://hugo.blog/2024/03/11/vision-pro/vision-pro_geekbench/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/02/vision-pro_geekbench.png" data-orig-size="1542,1416" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="vision-pro_geekbench" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/02/vision-pro_geekbench.png?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/02/vision-pro_geekbench.png?w=1024" loading="lazy" width="1024" height="940" src="https://hugobarracom.files.wordpress.com/2024/02/vision-pro_geekbench.png?w=1024" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/02/vision-pro_geekbench.png?w=1024 1024w, https://hugobarracom.files.wordpress.com/2024/02/vision-pro_geekbench.png?w=150 150w, https://hugobarracom.files.wordpress.com/2024/02/vision-pro_geekbench.png?w=300 300w, https://hugobarracom.files.wordpress.com/2024/02/vision-pro_geekbench.png?w=768 768w, https://hugobarracom.files.wordpress.com/2024/02/vision-pro_geekbench.png 1542w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Source: <a href="https://www.pcmag.com/reviews/apple-vision-pro" target="_blank" rel="noreferrer noopener">PC Magazine</a></figcaption></figure>



<p>This is more impressive than it seems, and demonstrates that the R1 chip is doing a very significant amount of heavy lifting — essentially the vast majority the spatial computing workload — leaving a lot of compute room for the M2 chip to deliver the same level of performance as if it was just running inside an iPad Pro. </p>



<p>By all accounts so far, the R1 chip appears to be of a fairly similar package size as the M2 chip (though built using a specialized architecture), which puts the Vision Pro well ahead of any current generation iPad or MacBook Air, and likely more on par with a MacBook Pro from a silicon performance perspective. Definitely an impressive achievement by the Apple Silicon team.</p>



<p>This also begs the question… what if you could completely offload the Vision Pro’s compute to another Apple device?</p>



<h2><strong>Apple’s decision to use a tethered pack <em>will</em> <em>enable future Vision headsets to be much lighter</em> by offloading compute to an iPhone, iPad or MacBook </strong></h2>



<p>One of the most controversial aspects of Vision Pro is the fact that it sports a tethered battery pack, differently from all other commercially available standalone VR headsets. Many people have heavily criticized Apple for this decision because of the inconvenience of the “hanging” external battery.</p>



<p>I agree with Palmer Luckey (<a href="https://youtu.be/S-sD2FTjSaw?si=AQUTyJria4TKmSbc&amp;t=1437" target="_blank" rel="noreferrer noopener">from his recent interview with Peter Diamandis</a>) that this was a necessary short-term decision on Apple’s part given the reality of the hardware shipping inside the Vision Pro, but more importantly it was a very intentional long-term decision, which I’ll explain.</p>



<p>As I mentioned earlier, the Vision is a meticulously over-engineered computer with a very significant collection of power-hungry components:</p>



<ul>
<li>2x laptop-class processors (the R1 chip is almost the same size as the M2, which is the same processor shipping on MacBooks)</li>



<li>2x very bright micro-OLED displays with high pixel density</li>



<li>1x auxiliary EyeSight display</li>



<li>12x cameras and other sensors</li>



<li>2x blower fans</li>



<li>2x speakers</li>
</ul>



<p>As Quin from Snazzy Labs carefully explains <a href="https://youtu.be/eOH33sWgds8?si=M_-SlaOYK5k-1SPP&amp;t=988" target="_blank" rel="noreferrer noopener">in his excellent review</a>, the Vision Pro likely draws as much as <strong>40 watts of power</strong>, which is more than most MacBook laptops. This also means it has a power supply with the potential of generating a lot of heat. So, in addition to transferring the battery weight out of the headset, the decision to move to a tethered pack also keeps a huge heat source safely away from your head.</p>







<blockquote>
<p><mark><strong>MY TAKE: </strong>All that said, the long-term strategic reason for having an external battery pack is to set expectations with Vision Pro users that there will <em>always</em> be an external box connected to the headset. In future Vision headsets, Apple should be able to comfortably start moving a lot of electronics off the headset, possibly shaving off as much half of the weight over a few generations and <strong>target around 300g</strong>. This also opens an extremely interesting path for Apple in a few years to <strong>use an iPhone, iPad or MacBook as the tethered computer driving the headset</strong>, which would dramatically simplify the headset.</mark> </p>
</blockquote>



<p>Interestingly, there is a tethered VR headset in the market today that demonstrates this desirable end state. It’s the <a href="https://www.bigscreenvr.com/" target="_blank" rel="noreferrer noopener"><strong>Bigscreen Beyond</strong></a>, the world’s smallest PC VR headset (i.e. needs to be tethered to a computer) that is lighter than even most ski goggles at 127 grams. Bigscreen’s ability to build this product is in many ways a bit of cheating since the headset was stripped of all sensors (no external cameras or eye tracking), but its existence nonetheless plays an important role in letting us experience what the future holds and where Apple’s sights are focused.</p>







<figure><img data-attachment-id="152" data-permalink="https://hugo.blog/2024/03/11/vision-pro/carmack_bigscreen-beyond/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/02/carmack_bigscreen-beyond.jpeg" data-orig-size="1600,1183" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="carmack_bigscreen-beyond" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/02/carmack_bigscreen-beyond.jpeg?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/02/carmack_bigscreen-beyond.jpeg?w=1024" loading="lazy" width="1024" height="757" src="https://hugobarracom.files.wordpress.com/2024/02/carmack_bigscreen-beyond.jpeg?w=1024" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/02/carmack_bigscreen-beyond.jpeg?w=1024 1024w, https://hugobarracom.files.wordpress.com/2024/02/carmack_bigscreen-beyond.jpeg?w=150 150w, https://hugobarracom.files.wordpress.com/2024/02/carmack_bigscreen-beyond.jpeg?w=300 300w, https://hugobarracom.files.wordpress.com/2024/02/carmack_bigscreen-beyond.jpeg?w=768 768w, https://hugobarracom.files.wordpress.com/2024/02/carmack_bigscreen-beyond.jpeg 1600w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>John Carmack wearing the Bigscreen Beyond VR headset, <br>which weighs 127g (vs. the Vision Pro’s 600g)</figcaption></figure>



<h2>Software</h2>



<h2><strong>The Vision Pro software story is a <em>bold antithesis of VR</em> — and the lack of exciting AR apps at launch paints the product into an empty corner</strong></h2>



<p><em>“Welcome to the era of spatial computing”</em> is Apple’s leading slogan for Vision Pro and, and as expected by everyone in the VR industry, Apple is going all-in on AR (augmented reality) to deliver on this proposition. The company has gone out of their way to actively ignore everything that VR has been know for over the last decade.</p>



<p>At the center of Apple’s marketing for Vision Pro is <em>“keeping users connected to their surroundings and other people”</em>. Reading in-between these lines, it’s not hard to see that Apple is taking an anti-VR stance that borderline accuses Meta’s approach to VR of promoting human isolation while positioning Vision Pro as the antithesis of that.</p>







<blockquote>
<p><mark><strong>MY TAKE:</strong> Apple’s anti-VR stance is a risky move because it negates most of the traditional immersive content that has made the VR medium popular until now, and at least for now is painting Vision Pro into an empty corner. This reminds me of Apple’s broad </mark><mark>stance on privacy — built to be in complete opposition to Meta/Google — which has put them in a tight spot by severely limiting their options and restricting innovation in the age of Gen AI. </mark></p>
</blockquote>



<p><strong>There are no fully immersive games in the Vision Pro app store</strong>, whereas easily &gt;90% of the Oculus Quest catalog is made of immersive VR games. Instead of leveraging the existing community of high-quality immersive VR content developers, Apple is focusing all of its energy exclusively on AR use cases that play to the company’s ecosystem strengths — iOS apps and MacOS productivity — which I’ll dive into over the next few sections.</p>



<p>The launch roster of 3D AR apps &amp; games is a tremendous disappointment — in both quality and quantity — and mostly includes a few simple casual games, some of which are originally 2D games hastily converted into 3D art. The fact that <em>ARKit</em> has been available for so many years on iPad and iPhone (despite its limited success) should have made it possible for Apple to easily round up developers into building a sufficient number of exciting and impressive AR titles for Vision Pro. Instead, <strong>we’re seeing an initial lack of developer excitement for the category that should have been the <em>most defining and inspiring category </em>on Vision Pro.</strong></p>



<p>Ironically, Meta made almost exactly the same mistake launching Quest Pro in 2022. That headset shipped with close to zero AR apps despite their emphasis in the launch messaging on “full-color mixed reality”.</p>







<blockquote>
<p><mark><strong>MY TAKE</strong>: This may be the first device category where Apple’s “build it and they will come” approach to creating developer traction may simply not work as previously. It will be many years (and possibly even more than a decade) before there are tens of millions of active Vision Pro users willing to pay for spatial AR apps. Apple will need to take a page out of the Oculus playbook and actively motivate developers financially to develop for Vision Pro.</mark></p>
</blockquote>



<h2><strong>Vision Pro’s positioning as <strong>a </strong><em><strong>productivity &amp; movie watching “big scree</strong>n”</em></strong> <strong>is dull &amp; unimaginative <strong>but Apple is unashamedly owning it</strong> </strong></h2>



<p>With a weak and limited launch roster of AR apps that doesn’t include a single flagship 3D app or game, Apple had to focus the entire positioning for Vision Pro at launch almost entirely on how it plugs into the existing Apple ecosystem of 2D apps.</p>



<p>In the usual Apple-style product marketing, the launch messaging for Vision Pro is very explicitly codified in the <a href="https://www.apple.com/apple-vision-pro/" target="_blank" rel="noreferrer noopener">product webpage</a> and every single marketing asset is consistent with it. How Apple has chosen to sequence their product messaging matters just as much as the messages themselves. <strong>Vision Pro is 60% about 2D productivity and 40% about watching media/movies on a big screen</strong>:</p>







<figure><table><tbody><tr><td><strong>Use case</strong></td><td><strong>Apple Slogans</strong></td></tr><tr><td>Productivity</td><td><em>“Free your desktop. And your apps will follow.”</em><p><em>“How to work&nbsp;in all‑new ways.”</em></p></td></tr><tr><td>Media</td><td><em>“The ultimate theater. Wherever you are. </em><p>“<em>An immersive way to experience entertainment.”</em></p></td></tr></tbody></table></figure>



<p>On a side note, <em>FaceTime with Persona avatars</em> and <em>spatial photos &amp; videos</em> are also pushed as core pillars in the Vision Pro product messaging, but they’re clearly just ancillary use cases to support marketing. Though too small to matter for now, they may (and for Apple’s sake, hopefully will) end up playing a much bigger role in the future.</p>







<blockquote>
<p><mark><strong>MY TAKE:</strong> The Vision Pro launch is a significant missed opportunity, with Apple “welcoming us into the era of spatial computing” with a software and services stack that is practically only focused on 2D use cases. Though the in-store demos paint an exciting future, the experience delivered by Apple at launch is dull and unimaginative at best.</mark></p>
</blockquote>



<p>Putting aside my criticism to Apple’s focus for the Vision Pro at launch, the next few sections will offer a deep dive into my thoughts and opinions on the software and experience enabling <em>Productivity</em> and <em>Media</em> use cases. </p>



<div>
<h2><strong>The Vision Pro desperately wants to be <em>the “future of work</em>” and pick up where Meta Quest Pro completely dropped the ball, but…</strong></h2>



<p>One of our strongest thesis from the early Oculus days was always about VR playing a defining role in the “future of work”, from running 2D apps in massive virtual displays to having native 3D apps that would make it a lot easier to work and collaborate with others on a project.</p>



<p>When Meta announced the Quest Pro in 2022, much of its marketing hype was in fact around the <a href="https://www.youtube.com/watch?v=eYjU9mV7-6g" target="_blank" rel="noreferrer noopener"><strong>Workrooms app</strong></a> (at the time led by my incredibly talented friend Mike LeBeau). The app allows you use your Mac from within VR, with a lot of attention to details needed to make it truly possible to work in VR for several hours, including support for up to 3 virtual monitors and the ability to see your physical keyboard in passthrough or replace it with a fully 3D rendered tracked twin.</p>



<figure><img data-attachment-id="196" data-permalink="https://hugo.blog/2024/03/11/vision-pro/quest-pro_workrooms-2/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/03/quest-pro_workrooms.png" data-orig-size="719,479" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="quest-pro_workrooms" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/03/quest-pro_workrooms.png?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/03/quest-pro_workrooms.png?w=719" loading="lazy" width="719" height="479" src="https://hugobarracom.files.wordpress.com/2024/03/quest-pro_workrooms.png?w=719" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/03/quest-pro_workrooms.png 719w, https://hugobarracom.files.wordpress.com/2024/03/quest-pro_workrooms.png?w=150 150w, https://hugobarracom.files.wordpress.com/2024/03/quest-pro_workrooms.png?w=300 300w" sizes="(max-width: 719px) 100vw, 719px"><figcaption>Image from the Quest Pro launch marketing</figcaption></figure>



<p>Quest Pro was designed with the goal of being a lot more comfortable than other VR headsets so that people could wear it for longer periods of time. While this was a well-intended attempt, the product had a major flaw which made it less than a “minimum viable product” and simply did not justify a price tag well above $1,000. The display resolution — at 22 PPD (pixels per degree) — was too low and vastly insufficient to unlock “working in VR” because of poor text readability. This shortcoming (in addition to very poor quality passthrough) was so massive that it rendered the product practically irrelevant at launch — I ended up returning my unit within 24 hours of first use.</p>



<p><strong><em>Can Vision Pro deliver where Quest Pro (and Quest 3) have failed?</em></strong></p>



<p>In order to really put Vision Pro to the test in real-life scenarios, I spent well over 100 hours trying to deploy as many of my own productivity workflows as I could, including about 1/3 of the work in this essay. I’ll share my conclusions over the next couple of sections.</p>



<p>First off, before diving into the value proposition of Vision Pro as a work/productivity computer, I needed to clearly frame my “jobs to be done” as specifically as possible. When I’m in “work mode” — whether doing actual professional work or just life management stuff — I have three distinct workstations that I use back and forth (aside from my smartphone, which I won’t include here):</p>



<ul>
<li><strong>Office workstation</strong> <strong>| Mac Pro with 2x Apple XDR 6K displays:</strong> my highest productivity setup because it gives me access to everything I need in a single view and enables zero-hurdle multi-tasking; it’s basically my gold standard for any task or project no matter how complex with the highest speed &amp; quality</li>



<li><strong>Laptop | MacBook Pro 16-inch:</strong> medium-high productivity setup with a sufficiently large retina-quality display that still enables complex tasks with good enough multi-tasking though I do feel noticeably less productive; it requires a backpack to carry when going outside of home/office</li>



<li><strong>Tablet | iPad Pro 11-inch with keyboard:</strong> a low-medium productivity setup good for focused single-app work with extremely limited multi-tasking (ex. email, writing that doesn’t require research, some life planning) but still better than using my phone; one great advantage is that I can carry this “mini computer” more easily than a laptop without really needing a backpack</li>
</ul>



<p>Here’s a table summarizing these workstations:</p>



<figure><table><tbody><tr><td><strong>Device</strong></td><td><strong>Number of Pixels</strong></td><td><strong>Number of simult. windows</strong></td><td><strong>Ideal for</strong></td><td><strong>Ergonomics</strong></td><td><strong>Portability</strong></td><td><strong>Cost</strong></td></tr><tr><td>Mac Pro + 2x XDR displays</td><td>XXLarge<br><em>(2×20 million)</em></td><td>8+</td><td>Any creative project with lots of multitasking</td><td>Ideal</td><td>–</td><td>&gt;$10,000</td></tr><tr><td>MacBook Pro 16-inch</td><td>Large<br><em>(7.7 million)</em></td><td>2-4</td><td>Most creative projects with limited multitasking</td><td>Good</td><td>Medium</td><td>$3,000</td></tr><tr><td>iPad Pro 11-inch + keyboard case</td><td>Medium<br><em>(4 million)</em></td><td>1</td><td>Full email, simple editing</td><td>Not great</td><td>High</td><td>$1,200</td></tr></tbody></table></figure>



<p><strong>I then asked myself: </strong>Could I see myself using Vision Pro as a productivity device instead of (or in conjunction with) any of my existing workstations?</p>



<p>These are the specific questions I set off to answer (from the lowest to highest bar):</p>



<ul>
<li>Can Vision Pro be a complete alternative to my Tablet Workstation so that I could carry it around instead of an iPad Pro?</li>



<li>Can Vision Pro enhance my Laptop Workstation enough that it feels like having a “virtual XDR display” or two?</li>



<li>Could Vision Pro ever be better than ALL of my workstations at least for some productivity tasks? <strong><em>⇒ This is what excites me the most!</em></strong></li>
</ul>
</div>



<div>
<h2><strong><span>Productivity Thesis #1</span>: Vision Pro as an iPad Pro replacement </strong></h2>



<blockquote>
<p><strong>Status:</strong> ❌ NOT READY <em>(but it’s promising!)</em></p>



<p><mark><strong>MY TAKE: </strong>The Vision Pro aspires to become your “spatial iPad Pro” with really good potential for much better multi-tasking (than an iPad) and the ability to do focused work anywhere, but there’s simply too much usability friction and too many important apps missing for that to be a reality today (or likely in the next 1-2 years).</mark></p>
</blockquote>



<p>The Vision Pro is conveniently designed by Apple to immediately fit right into the existing Apple ecosystem as a (rather expensive) alternative to an iPad Pro. The headset has identical compute (same M2 chip) to an iPad Pro and conveniently supports iPad apps running natively. In fact, it’s easy to claim the Vision Pro should in principle be better than an iPad Pro because you can run multiple iPad apps side-by-side in full screen mode, which would overcome one of the biggest productivity limitations of iPads — poor multitasking.</p>



<p>However, in reality this claim really doesn’t hold true at all (at least not yet) for a few important limitations of Vision Pro at launch:</p>



<ul>
<li><strong>Many iPad apps don’t work well </strong>(or at all) on Vision Pro despite <a href="https://developer.apple.com/help/app-store-connect/manage-your-apps-availability/manage-availability-of-iphone-and-ipad-apps-on-apple-vision-pro/" target="_blank" rel="noreferrer noopener">Apple automatically opting in developers</a>. There is substantial friction and instability navigating inside productivity apps given that they’re designed for a multi-touch UI (ex: some iPad gestures don’t exist in Vision Pro, and some touch targets are too small). A lot of apps will require some effort by their developers to work well enough.</li>



<li><strong>Most productivity apps are still missing from the App Store</strong> (likely for the reason above), which would leave large holes in most people’s workflows. For example, the most important missing apps for my own workflows include Chrome, Gmail, GDocs/Sheets/Slides, Asana.</li>



<li><strong>Text input is still quite buggy</strong> which adds more friction to any productivity workflow. Cursor placement, text selection and editing are super error prone. Dictation doesn’t stream results as you speak.</li>



<li><strong>You must carry a keyboard and a trackpad</strong> (mice are <span>not</span> supported) for the vast majority of your iPad-class productivity workflows on Vision Pro, which could be an added inconvenience (compared to carrying an iPad with a keyboard case or even a laptop). Editing documents, spreadsheets or presentations without those is virtually impossible.</li>



<li><strong>There is no reliable workspace persistency</strong> which adds even more friction — you are forced to re-open apps, and then re-size and reposition windows almost every time. The capabilities we all want (which Apple should be able to ship soon if they want to) are (i) persistent workspaces, (ii) location-specific workspaces, and (iii) a spatial computing equivalent of Mission Control.</li>
</ul>



<p>All that said, these limitations can all be addressed by Apple and the potential of Vision Pro as an iPad Pro replacement really is there. Even though the iPad Pro has nearly twice the PPD (pixels per degree) as the Vision Pro, text readability of iPad apps on Vision Pro is good enough for you to run 3 or 4 side-by-side apps plus a number of ambient widgets.</p>



<p>I also really believe there’s a large enough white canvas for lots of Apple-style innovation and magic around letting users configure and manage their workspace with a combination of 2D panels and virtual 3D objects. The potential is really significant as long as Apple really empowers developers to innovate here (try <em>Nicholas Jitkoff’s <a href="https://www.widget.vision/" target="_blank" rel="noreferrer noopener">widget.vision</a></em> to see some great early examples — the NY Times front page widget is my favorite). </p>



<p><strong>Call me crazy, but I personally could get quite excited by the idea of a “spatial iPad Pro”</strong> if I was able to actually get all of my iPad apps on the Vision Pro, and if Apple addresses all of the issues causing friction in my workflows. The reason why is simply that of focus – to be able to really “dial down reality” and tune into the work wherever I am, without carrying my laptop with me but still having some degree of multitasking available.</p>



<h2><strong><span>Productivity Thesis #2</span>: Vision Pro as a MacBook virtual external monitor </strong></h2>



<blockquote>
<p><strong>Status:</strong> ✅ ALMOST READY <em>(needs some bug fixing!)</em></p>



<p><mark><strong>MY TAKE: </strong>The Vision Pro is a few software bug fixes away from being a suitable virtual-equivalent to an external monitor similar to a 27-inch Apple Studio Display that makes it easy to work immersively in VR using all your existing MacOS apps and workflows on a huge screen (but don’t expect an Apple XDR 6K experience!).</mark></p>
</blockquote>



<p>One of Vision Pro’s best pieces of pure software/experience magic is the ability to seamlessly connect to a MacBook by simply looking at the computer while wearing the headset. This is a simple improvement to the traditional AirPlay UI that creates a profound sense of seamlessness which VR has always lacked.</p>



<p>Before diving into this thesis, I’ll establish that the Vision Pro will <em>never</em> become a suitable alternative for my office workstation with dual Apple XDR 6K displays. At 32 inches per-monitor and a total of 40 million pixels (with pixel density of 218 PPI and angular resolution &gt;100 PPD) and without a weight around my head, it is simply not a bar I would hold a VR headset against today or at any point in the future.</p>



<p>The more interesting question to focus on is whether Vision Pro could even begin to look like a suitable replacement for one or more 27-inch Apple Studio Displays (or equivalent). The short answer today is that Vision Pro can indeed come close (or very close) to that, but there are some important limitations that Apple needs to address to make this a relatively frictionless use case:</p>



<ul>
<li><strong>Lack of dual (or triple) monitor support</strong> is a huge bummer despite the fact that there are decent reasons for it (largely related to requiring a lot of local Wi-Fi bandwidth). Even though Vision Pro has a relatively narrow field of view that still feels like looking through binoculars, if I could get two or three virtual monitors out of a MacBook Air for example, things would start to look more interesting.</li>



<li><strong>Inconsistent keyboard and trackpad behaviors</strong> makes it very hard to switch back and forth between iPad/Vision apps and the Mac virtual display. I constantly find myself looking for my cursor, seeing the virtual keyboard pop up onscreen when clearly I don’t need it (if I’m using a physical keyboard), not to mention that I cannot use my beloved Logitech MX mouse.</li>



<li><strong>There is no reliable workspace persistency</strong> which is exactly the same issue I discussed when talking about the iPad Pro use case in the previous section. This should be an easy fix.</li>



<li><strong>Eye tracking doesn’t work in MacOS</strong> which not only leads to inconsistent input modalities as I said above but also just feels like a huge missed opportunity to offer a magical capability that MacOS has never seen before. This is not a low-hanging bug fix, but I don’t see it as a huge technical leap for Apple if the MacOS team wants to address it.</li>



<li><strong>MacOS apps are “stuck” inside the virtual monitor</strong> instead of being allowed to move around the entire space. This is another missed opportunity to deliver a truly spatial/immersive experience with Vision Pro, though significantly more complicated for Apple to address and would require really careful engineering by both MacOS and visionOS teams.</li>
</ul>



<p>Many of the issues I highlighted above are straightforward software challenges that Apple is well equipped to address and would make a world of difference. I suspect it’s a matter of dealing with the usual internal politics/collaboration challenges getting the MacOS team to dedicate the necessary resources to address bugs and feature requests from the visionOS team.</p>



<p>The bottom line for me is that <strong>we can see a relatively near future where carrying a MacBook Air and a Vision Pro in your backpack could give you a reasonably good workstation</strong>, one that delivers enough benefits in the form of productivity gains that you might be willing to wear a headset for a few hours in a café, on an airplane, or even on your couch at home. (This perspective is of course made in complete absence of value-for-money considerations).</p>



<p>Unsurprisingly, this is Apple’s strongest hand with the Vision Pro launch as it’s 100% controlled by them and uniquely leverages the existing Apple ecosystem. Yes, it’s a very uninspiring and unimaginative use case, but it might be powerful enough for Apple to move a lot of headsets.</p>



<h2><strong>Watching movies in Vision Pro is great at first but most people will stop doing it after the initial novelty excitement wears off</strong></h2>



<p>Watching TV/movies in virtual reality seemed like such an incredibly compelling idea that we (the Oculus team at Meta/Facebook) built an entire product around that idea — <em>Oculus Go</em>. Launched in 2018, Oculus Go was the biggest product failure I’ve ever been associated with for the simple reason that it had extremely low retention despite strong partnerships with Netflix and YouTube. <strong>Most users who bought Oculus Go completely abandoned the headset after a few weeks.</strong> The full story is much more nuanced (including the fact that the Oculus Go failure got us on the path to Oculus Quest very quickly), but it taught us an important lesson.</p>



<p>The lesson we learned is that watching traditional (rectilinear) TV or movies in VR feels incredibly compelling at first, but the novelty wears off for most people after a few weeks. The reasons are:</p>



<ul>
<li><strong>It’s just not physically comfortable</strong> compared to watching TV or movies on an TV, tablet, or laptop, primarily because of the pressure on your head and face, plus the fact that you can’t comfortably sit in any position or lie down while wearing with the headset</li>



<li><strong>There’s a lot of friction </strong>to start watching a video in a VR headset if you’re not already in VR — frequently a lot more steps required (especially finding and putting on the headset) and a more cumbersome navigation UI compared to our other devices</li>



<li><strong>It’s socially isolating and lonely</strong> to watch videos in VR, which will be a deal breaker for many people (although definitely not all)</li>
</ul>



<p>Back in the Oculus Go days, we concluded rather quickly that media consumption in VR is simply not a core “daily driver” pillar but more an ancillary use case that adds some value to other core pillars (such as productivity or gaming).</p>



<p>Vision Pro does bring more to the table with a much better display than previous VR headsets which can create magical movie experiences on occasion. For instance, watching an animated Disney or Pixar movie in 3D is absolutely stunning. But the essential product-market fit challenge remains:  </p>



<blockquote>
<p><mark><strong>MY TAKE:</strong> VR is simply not a medium people will gravitate towards for watching 2D media on a regular basis. Adding to this all of the Vision Pro’s </mark><mark>comfort and friction issues, most people who get excited about watching media in the headset will eventually find themselves going back to their TV, tablet or laptop as their primary devices for video.</mark></p>
</blockquote>



<p>Watching 3D movies on Vision Pro is a fun entertainment experience, but these videos are “boxed” and don’t feel anything like witnessing real life. With the Vision Pro, Apple launched its new <em>Apple Immersive</em> video format, which opens the door for a new class of entertainment.</p>



<h2><strong>Apple Immersive Video opens a new world of possibilities for media in VR — but its <em>hyperrealism</em> may bring an unexpected <em>uncanny valley challenge</em></strong></h2>



<p>One of the big original bets we made at Facebook/Meta with the launch of <em>Oculus Go</em> in 2018 was that immersive 180-degree video would attract a massive amount of consumer interest and that this would somehow trigger a chain reaction in the world of entertainment. We were able to secure partnerships with a small number of media companies who had become specialized in capturing VR video early on, and we were off to the races.</p>



<p>Our initial excitement cooled off quickly. VR180 video quality on Oculus Go was decent but flat, washed out and far from amazing mostly due to low resolution. These videos didn’t create a true sense of presence, of feeling transported to another reality. And most of the content was of one-off nature, with no real franchises that would have people coming back for more (with the exception of sports, which failed initially for other reasons that I’ll come back to later).</p>



<p>Within a year, the Oculus team pivoted to VR gaming and stopped investing in immersive video almost completely.</p>



<p>In 2020, Apple acquired <a href="https://www.youtube.com/@Nextvr" target="_blank" rel="noreferrer noopener"><strong>NextVR</strong></a>, one of the small but highly respected companies we had been working with as they were edging into bankruptcy (we passed on the acquisition at Meta/Oculus). NextVR had spent over a decade building and perfecting VR 180 camera technology and production pipelines for broadcast-quality video. <a href="https://www.youtube.com/@Nextvr" target="_blank" rel="noreferrer noopener">The NextVR YouTube channel</a> is still live and provides amazing examples of what became possible with their technology <em>(make sure to pan around using your mouse/finger while watching videos in their YT channel)</em>.</p>



<figure><img data-attachment-id="102" data-permalink="https://hugo.blog/2024/03/11/vision-pro/nextvr_camera/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/02/nextvr_camera.png" data-orig-size="1200,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nextvr_camera" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/02/nextvr_camera.png?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/02/nextvr_camera.png?w=1024" loading="lazy" width="1024" height="682" src="https://hugobarracom.files.wordpress.com/2024/02/nextvr_camera.png?w=1024" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/02/nextvr_camera.png?w=1024 1024w, https://hugobarracom.files.wordpress.com/2024/02/nextvr_camera.png?w=150 150w, https://hugobarracom.files.wordpress.com/2024/02/nextvr_camera.png?w=300 300w, https://hugobarracom.files.wordpress.com/2024/02/nextvr_camera.png?w=768 768w, https://hugobarracom.files.wordpress.com/2024/02/nextvr_camera.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The latest publicly displayed NextVR 180-3D camera in 2018 (Source: <a href="https://www.theverge.com/2018/1/8/16862048/nextvr-six-degrees-of-freedom-augmented-reality-events-ces-2018" target="_blank" rel="noreferrer noopener">The Verge</a>)</figcaption></figure>



<p>The NextVR acquisition is what led to the incredibly <strong>Apple Immersive </strong>video format, which enables capture of <em>3D video in 180 degrees in 8K resolution at 90 frames per second</em>, an absolute juggernaut format with 8 times the number of pixels of a regular 4K video. <strong>The best way to think of the new <em>Apple Immersive</em> video format is kind of like a new IMAX-3D</strong>, but the real magic is the fact that it’s projected inside an imaginary 180-degree sphere (horizontally <em>and</em> vertically) that takes over your entire field of view.</p>



<p>Vision Pro is the first VR headset that enables playback of 180-degree 3D video at what feels to the eyes like 4K quality. At launch, there are four Apple TV short films on Vision Pro shot in Apple Immersive video format. My absolute favorite of these films — <em>Adventure</em> — is a jaw-dropping cinematic piece that is likely to win its share of movie awards. Experiencing the Norwegian fjords with this level of immersion is completely breathtaking, so much so that it might be my favorite experience so far in Vision Pro. I have never felt transported to another place in this manner in any experience I’ve ever had, anywhere, period.</p>



<figure><img data-attachment-id="112" data-permalink="https://hugo.blog/2024/03/11/vision-pro/011623_immersive_originals_storytellers_apple_vision_big_image_03_big_image_post-jpg-slideshow_large/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/02/011623_immersive_originals_storytellers_apple_vision_big_image_03_big_image_post.jpg.slideshow_large.jpg" data-orig-size="1960,1104" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="011623_immersive_originals_storytellers_apple_vision_big_image_03_big_image_post.jpg.slideshow_large" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/02/011623_immersive_originals_storytellers_apple_vision_big_image_03_big_image_post.jpg.slideshow_large.jpg?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/02/011623_immersive_originals_storytellers_apple_vision_big_image_03_big_image_post.jpg.slideshow_large.jpg?w=1024" loading="lazy" width="1024" height="576" src="https://hugobarracom.files.wordpress.com/2024/02/011623_immersive_originals_storytellers_apple_vision_big_image_03_big_image_post.jpg.slideshow_large.jpg?w=1024" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/02/011623_immersive_originals_storytellers_apple_vision_big_image_03_big_image_post.jpg.slideshow_large.jpg?w=1024 1024w, https://hugobarracom.files.wordpress.com/2024/02/011623_immersive_originals_storytellers_apple_vision_big_image_03_big_image_post.jpg.slideshow_large.jpg?w=150 150w, https://hugobarracom.files.wordpress.com/2024/02/011623_immersive_originals_storytellers_apple_vision_big_image_03_big_image_post.jpg.slideshow_large.jpg?w=300 300w, https://hugobarracom.files.wordpress.com/2024/02/011623_immersive_originals_storytellers_apple_vision_big_image_03_big_image_post.jpg.slideshow_large.jpg?w=768 768w, https://hugobarracom.files.wordpress.com/2024/02/011623_immersive_originals_storytellers_apple_vision_big_image_03_big_image_post.jpg.slideshow_large.jpg 1960w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><strong>Adventure</strong> is one of the short films shot in Apple Immersive format released with the Vision Pro launch</figcaption></figure>



<p>My second favorite Apple Immersive video — <em><a href="https://www.youtube.com/watch?v=d555q5vaYns" target="_blank" rel="noreferrer noopener">Alicia Keys: Rehearsal Room</a></em> — is a super fun and intimate concert that really makes you feel what presence in VR could be like with another human. While it’ll be fun for nearly everyone to see Alicia Keys in a close-up VR performance, it may not be nearly as happy and inspiring to see a human in close proximity in other situations.</p>



<blockquote>
<p><mark><strong>MY TAKE:</strong> The super high-fidelity <mark>Apple Immersive </mark>video format will run into an unexpected and significant “uncanny valley” challenge as a consequence of its <em>hyperrealism</em>. Seeing someone right in such close proximity to you and in such high fidelity may feel cool to one person but will feel uncomfortable or overwhelming to others. Less so in a scene like this intimate music concert or sports game, but probably a lot more so in dramatic storytelling and other types of more realistic films.</mark></p>
</blockquote>



<p>Back in the Oculus days, we used to run experiments to try and really understand which lines could not be crossed in VR content to avoid people feeling overwhelmed or even unsafe. One of the findings in these experiments was that too much realism and fidelity could be one of the things that crosses a line. In other words, <em>hyperrealism</em> could quickly drag people into the <em>uncanny valley</em>, one of two places we always want to avoid in VR (the other place is motion sickness).</p>



<figure><img data-attachment-id="139" data-permalink="https://hugo.blog/2024/03/11/vision-pro/alicia/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/02/alicia.jpeg" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="alicia" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/02/alicia.jpeg?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/02/alicia.jpeg?w=1024" loading="lazy" width="1024" height="576" src="https://hugobarracom.files.wordpress.com/2024/02/alicia.jpeg?w=1024" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/02/alicia.jpeg?w=1024 1024w, https://hugobarracom.files.wordpress.com/2024/02/alicia.jpeg?w=150 150w, https://hugobarracom.files.wordpress.com/2024/02/alicia.jpeg?w=300 300w, https://hugobarracom.files.wordpress.com/2024/02/alicia.jpeg?w=768 768w, https://hugobarracom.files.wordpress.com/2024/02/alicia.jpeg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Many people will feel themselves crossing the uncanny valley while<br>watching <em><a href="https://www.youtube.com/watch?v=d555q5vaYns" target="_blank" rel="noreferrer noopener">Alicia Keys: Rehearsal Room</a></em> on Vision Pro</figcaption></figure>



<p>Navigating this creative challenge will take time and a lot of experimentation on Apple’s side, and they’re the one company in the world we can trust to have the level of sensitivity and artistry for this journey, not to mention the ability to hire the best of the best talent. Practically, it probably means we can expect to see beautiful experiential films in Apple Immersive format exploring topics such as beautiful landscapes, wildlife, travel and music, but are less likely to see deep human storytelling with people in close proximity to the camera (which is typical of nearly all traditional filmmaking).</p>



<p>Luckily for Apple, there is one category where hyperrealism is much less likely to be an issue especially for hardcore fans — <strong><em>Live Sports</em></strong>.</p>



<h2><b><em>Live sports</em> will be Apple’s secret weapon to sell a huge number of Vision Pro headsets to hardcore fans — but it’s going to be a long &amp; expensive journey</b></h2>



<p>One of the original Oculus Go 30-second TV commercials featured an <a href="https://www.youtube.com/watch?v=SUdJt_3i0Us" target="_blank" rel="noreferrer noopener">NBA courtside banter between Adam Levine and Jonah Hill</a> wearing the Oculus headset while watching a live game together in VR (each sitting in their own physical living room):</p>



<figure><img data-attachment-id="121" data-permalink="https://hugo.blog/2024/03/11/vision-pro/nextvr_nba/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/02/nextvr_nba.png" data-orig-size="3476,1844" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nextvr_nba" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/02/nextvr_nba.png?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/02/nextvr_nba.png?w=1024" loading="lazy" width="1024" height="543" src="https://hugobarracom.files.wordpress.com/2024/02/nextvr_nba.png?w=1024" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/02/nextvr_nba.png?w=1024 1024w, https://hugobarracom.files.wordpress.com/2024/02/nextvr_nba.png?w=2048 2048w, https://hugobarracom.files.wordpress.com/2024/02/nextvr_nba.png?w=150 150w, https://hugobarracom.files.wordpress.com/2024/02/nextvr_nba.png?w=300 300w, https://hugobarracom.files.wordpress.com/2024/02/nextvr_nba.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Screenshot from an original <em>Oculus Go</em> TV commercial (<a href="https://www.youtube.com/watch?v=SUdJt_3i0Us" target="_blank" rel="noreferrer noopener">full video</a>)</figcaption></figure>



<p>This TV commercial did extremely well, drove a significant amount of Oculus Go sales (after all, that headset only cost $199) and definitely showed that we were on to something potentially quite powerful with hardcore sports fans. But as I explained in the previous section, we did not manage to bring it to reality in a way that would meet expectations.</p>



<p>In the end, our team at Oculus completely failed to realize the opportunity of redefining the sports audience experience through VR for a number of reasons, but primarily because we just didn’t have the patience to develop that market. We were unable to build the necessary industry support with sports leagues and broadcast right holders initially, so we stopped trying and the VR sports segment nearly died. There are small efforts on Quest today such as <a href="https://xtadiumvr.com/" target="_blank" rel="noreferrer noopener"><em>Xtadium</em></a> and <a href="https://www.oculus.com/vr/6525150070834263/" target="_blank" rel="noreferrer noopener"><em>Meta Horizons</em></a>, but the quality of the experience and the limited live content make it all too insignificant to matter. To date, nobody ever really tried hard enough to create this market.</p>



<p>Apple has the opportunity to completely change this, for a few reasons:</p>



<ul>
<li><strong>Apple Immersive on Vision Pro is a transformative experience</strong> in terms of video quality and its ability to deliver a real sense of presence. Watching a game in high-resolution VR has the <em>potential</em> to be legitimately better than a regular 4K TV broadcast by enabling hardcore fans to feel much closer to the action.</li>



<li><strong>Apple has VR broadcast expertise</strong> with its acquisition of NextVR, and could have been painstakingly building a robust production pipeline for live 8K video, which is a tall technical challenge requiring non-trivial investment and specialized talent.</li>



<li><strong>Apple is already active in the sports broadcast rights world</strong> through their existing MLS license and several other rumored conversations that may lead to Apple buying a lot more broadcast rights to continue to strengthen Apple TV (ex. English Premier League, Formula 1).</li>
</ul>



<p>The first place where Apple will likely explore using Apple Immersive and Vision Pro for a live broadcast is Major League Soccer in the US. Their recent announcement is a strong indicator this is likely coming in late 2024 or early 2025 (to continue building momentum for Vision Pro):</p>



<blockquote>
<p><em>Coming soon, all Apple Vision Pro users can experience the best of the 2023 MLS Cup Playoffs with <strong>the first-ever sports film captured in Apple Immersive Video</strong>. Viewers will feel every heart-pounding moment in 8K 3D with a 180-degree field of view and Spatial Audio that transports them to each match. </em></p>
<cite><a href="https://www.apple.com/newsroom/2024/02/2024-mls-season-kicks-off-today-exclusively-on-mls-season-pass-on-apple-tv/" target="_blank" rel="noreferrer noopener">Apple Press Release – February 2024</a></cite></blockquote>



<figure><img data-attachment-id="110" data-permalink="https://hugo.blog/2024/03/11/vision-pro/nextvr_mls/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/02/nextvr_mls.webp" data-orig-size="1500,750" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nextvr_mls" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/02/nextvr_mls.webp?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/02/nextvr_mls.webp?w=1024" loading="lazy" width="1024" height="512" src="https://hugobarracom.files.wordpress.com/2024/02/nextvr_mls.webp?w=1024" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/02/nextvr_mls.webp?w=1024 1024w, https://hugobarracom.files.wordpress.com/2024/02/nextvr_mls.webp?w=150 150w, https://hugobarracom.files.wordpress.com/2024/02/nextvr_mls.webp?w=300 300w, https://hugobarracom.files.wordpress.com/2024/02/nextvr_mls.webp?w=768 768w, https://hugobarracom.files.wordpress.com/2024/02/nextvr_mls.webp 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Apple will likely use MLS as a testing ground for developing Apple Immersive live broadcasts</figcaption></figure>



<p>Beyond MLS (where Apple already has a long-term agreement and the ability to basically do anything), it will take a significant amount of time and money for Apple to strike the necessary agreements with the main sports leagues (NBA, NFL, MLB, Premier League etc) to enable this kind of immersive broadcast experience. That said, this is likely only a matter of time, as the opportunity to rethink audience sports is large enough that it would matter a lot even to a multi-trillion dollar company like Apple.</p>



<blockquote>
<p><mark><strong>MY TAKE: </strong>Just to put things in perspective, prices of tickets for watching live sports (in the actual venue) have been going steadily up and are now in the $100s even for average to bad seats, with premium tickets easily going into the $1000s (<a href="https://www.cbsnews.com/news/how-much-super-bowl-2024-tickets-prices/" target="_blank" rel="noreferrer noopener"><strong>the cheapest SuperBowl ticket in 2024 was around $2,000 at face value</strong></a>). The business case for a high-quality immersive “courtside” experience on Vision Pro is almost unquestionably very strong.</mark></p>
</blockquote>



<p>There are two major aspects Apple will have to nail in order to successfully monetize this opportunity, both of which will require a lot of design, engineering and experimentation:</p>



<ul>
<li><strong>Live sports are very social</strong>, which means Apple will have to invest heavily in delivering a co-watching experience that works equally well for people who are physically in the same room or virtually co-located, and which feels as natural as casually watching a game sitting on the couch with your family or at a bar with your friends.</li>



<li><strong>The experience bar will be very high</strong>, which means Apple will have to really customize every aspect of the experience to the nature of each sports to make it better than watching a game on a large 4K television — including camera angles, special replays, birds-eye visualizations, analysis overlays, game stats etc.</li>
</ul>



<p>This is a massive canvas for innovation, and it will take several generations of Vision Pro to get there. I’m optimistic and, speaking from the position of having been part of a team that really tried to go after this opportunity, I really believe this is one of those things where “it takes an Apple” to change the game (pun very much intended!).</p>



<figure><img data-attachment-id="137" data-permalink="https://hugo.blog/2024/03/11/vision-pro/xtadium_tennis/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/02/xtadium_tennis.png" data-orig-size="1024,591" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="xtadium_tennis" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/02/xtadium_tennis.png?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/02/xtadium_tennis.png?w=1024" loading="lazy" width="1024" height="591" src="https://hugobarracom.files.wordpress.com/2024/02/xtadium_tennis.png?w=1024" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/02/xtadium_tennis.png 1024w, https://hugobarracom.files.wordpress.com/2024/02/xtadium_tennis.png?w=150 150w, https://hugobarracom.files.wordpress.com/2024/02/xtadium_tennis.png?w=300 300w, https://hugobarracom.files.wordpress.com/2024/02/xtadium_tennis.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Watching live tennis on Xtadium app on Quest: <br>multiple cameras to choose from <em>plus</em> simultaneous TV broadcast on giant virtual floating screen</figcaption></figure>



<figure><img data-attachment-id="142" data-permalink="https://hugo.blog/2024/03/11/vision-pro/visionpro_golf/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/02/visionpro_golf.webp" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="visionpro_golf" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/02/visionpro_golf.webp?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/02/visionpro_golf.webp?w=1024" loading="lazy" width="1024" height="576" src="https://hugobarracom.files.wordpress.com/2024/02/visionpro_golf.webp?w=1024" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/02/visionpro_golf.webp?w=1024 1024w, https://hugobarracom.files.wordpress.com/2024/02/visionpro_golf.webp?w=150 150w, https://hugobarracom.files.wordpress.com/2024/02/visionpro_golf.webp?w=300 300w, https://hugobarracom.files.wordpress.com/2024/02/visionpro_golf.webp?w=768 768w, https://hugobarracom.files.wordpress.com/2024/02/visionpro_golf.webp 1280w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>PGA app on Vision Pro: <br>birds-eye view of a 3D model of the course and ability to track shots of a recorded prior match</figcaption></figure>



<figure><img data-attachment-id="174" data-permalink="https://hugo.blog/2024/03/11/vision-pro/visionpro_f1/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/03/visionpro_f1.png" data-orig-size="3448,1910" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="visionpro_f1" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/03/visionpro_f1.png?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/03/visionpro_f1.png?w=1024" loading="lazy" width="1024" height="567" src="https://hugobarracom.files.wordpress.com/2024/03/visionpro_f1.png?w=1024" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/03/visionpro_f1.png?w=1024 1024w, https://hugobarracom.files.wordpress.com/2024/03/visionpro_f1.png?w=2048 2048w, https://hugobarracom.files.wordpress.com/2024/03/visionpro_f1.png?w=150 150w, https://hugobarracom.files.wordpress.com/2024/03/visionpro_f1.png?w=300 300w, https://hugobarracom.files.wordpress.com/2024/03/visionpro_f1.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Concept of a Formula 1 mixed reality broadcast by viz artist John LePore (Source: <a href="https://www.youtube.com/watch?v=y9FpgxNeWJk" target="_blank" rel="noreferrer noopener">YouTube</a>):<br>birds-eye track view, main broadcast on giant floating screen, multi-camera access, live telemetry</figcaption></figure>



<h2>Conclusions<strong> </strong></h2>



<h2><strong>Why I returned my Vision Pro, and my wish list for what Apple could do to fix &amp; improve the product</strong> </h2>



<p>As a “product guy”, I usually force myself to behave like a real consumer making real trade-offs as much as I possibly can. I believe that always putting myself in the user’s shoes is an important part of what I do not just for my own products but also for products built by other people. I admit Vision Pro is the ultimate tech toy, but since I’m not an active developer I can’t justify the $4,049.78 price tag (512GB model + California sales tax) simply for keeping up with the VR market, so I returned my Vision Pro for a full refund inside the 14-day return window.</p>



<figure><img data-attachment-id="201" data-permalink="https://hugo.blog/2024/03/11/vision-pro/vision-pro_return/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/03/vision-pro_return.png" data-orig-size="2018,1046" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="vision-pro_return" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/03/vision-pro_return.png?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/03/vision-pro_return.png?w=1024" loading="lazy" width="1024" height="530" src="https://hugobarracom.files.wordpress.com/2024/03/vision-pro_return.png?w=1024" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/03/vision-pro_return.png?w=1024 1024w, https://hugobarracom.files.wordpress.com/2024/03/vision-pro_return.png?w=150 150w, https://hugobarracom.files.wordpress.com/2024/03/vision-pro_return.png?w=300 300w, https://hugobarracom.files.wordpress.com/2024/03/vision-pro_return.png?w=768 768w, https://hugobarracom.files.wordpress.com/2024/03/vision-pro_return.png 2018w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>In Apple’s journey of <em>product-market fit</em> in VR, the Vision Pro has a long way to be able to deliver true retention. Apple’s high-risk decision to completely exclude immersive VR games from the Vision Pro app store — <em>plus</em> their inexplicable failure to create exciting momentum by not having high-quality AR apps at launch — don’t leave them with many options to deliver user value in the near term to non-developers.</p>



<p>The only low-hanging fruit is to make productivity really good, which despite being incredibly unimaginative and dull, should be one of Apple’s biggest focus in the next iterations of visionOS. I don’t discard the possibility of once again owning a 1st-gen Vision Pro in the future once Apple addresses all of the friction issues I uncovered and shared above. </p>



<p>During the 2 weeks of my Vision Pro experience, I accumulated a very long list of bug fixes and feature requests based on 2 weeks of Vision Pro usage. I’m going to share my Top 10 here:</p>



<ol>
<li><strong>Make productivity use cases frictionless </strong>first of all by closing the gap with developers to bring essential iPad apps to Vision Pro // fix text input &amp; editing and make it seamless // add support for 2 (and ideally 3) MacOS remote displays // add workspace window persistency // build “spatial Mission Control” and enforce a minimal recommended focal distance</li>



<li><strong>Have developers build amazing AR games</strong> and do everything possible to set a really high quality bar &amp; reward their creativity // add SharePlay support with <em>Personas</em> and really push for multi-player support, enabling people to be <em>and</em> play together.</li>



<li><strong>Improve passthrough mode</strong> to the extent that the hardware sensor stack allows, ideally reducing motion blur, improving white balance, and making seeing your hands more seamless (when viewing immersive content)</li>



<li><strong>Create workspace spatial persistency</strong> and allow me to configure different rooms in my home or office in such a way that Vision Pro always remembers my room-specific configurations</li>



<li><strong>Make 3D widgets &amp; objects first-class citizens </strong>in visionOS and enable people to decorate their homes &amp; offices persistently</li>



<li><strong>Let people bring their iPhone into VR</strong> by simply looking at the device (like the MacOS virtual display feature) and then getting a floating panel that they can place anywhere in their space — this will work wonders in reducing FOMO while in VR</li>



<li><strong>Add a <em>Guest mode</em> so anyone can give the Apple in-store demo</strong> and make it possible for Vision Pro users to “spread the love” — there’s nothing more magical than giving someone their first VR demo</li>



<li><strong>Add Persona support to SharePlay </strong>for watching video to so people can actually feel like they’re together — VR has a bad reputation of loneliness &amp; isolation, so making VR social must be a priority even though few people will use social features at first. There aren’t enough people with Vision Pro for this to be a practical use case today, but it’s important for Apple to set the right tone.</li>



<li><strong>Launch tons of beautiful environments</strong> ideally with a steady frequency, taking a page out of the Apple TV screensaver playbook — and include beautiful indoor environments as well (not just landscapes)</li>



<li><strong>(Lastly…) Find a way to let people play immersive VR games</strong> by implementing <a href="https://en.wikipedia.org/wiki/OpenXR" target="_blank" rel="noreferrer noopener">OpenXR</a> support, forming a partnership with <em>SteamVR</em> or simply opening up visionOS a bit to allow VR developers and enthusiasts to build compatibility themselves</li>
</ol>
</div>



<h2><strong>ONE MORE THING: (1) Why Meta’s Android moment is finally here, (2) My unsolicited product advice for <em>Quest Pro 2</em> and beyond</strong></h2>



<p>As I said at the beginning of this essay, while working at Meta/Oculus I used to semi-seriously joke that the best thing that could ever happen to us was having Apple enter the VR industry. One of the main reasons for me to say this was that I knew Apple would do the best job of any company making people really <em>want</em> VR through its unparalleled brand, design and marketing. Oculus co-founder Palmer Luckey puts it best:</p>







<blockquote>
<p><em>“VR will become something everyone wants before it becomes something everyone can afford.”</em></p>
<cite><a href="https://twitter.com/palmerluckey/status/679907802962214912" target="_blank" rel="noreferrer noopener">Palmer Luckey, 2015 tweet</a></cite></blockquote>



<p>For Meta, the Vision Pro launch is the best marketing tool for Quest VR that the company could have dreamed of but could have never achieved on its own, for a few reasons:</p>



<ul>
<li><strong>It elevates VR to a level of mainstream consumer curiosity</strong> and breaks away from gamer and VR enthusiast niches; in media coverage alone the Vision Pro probably had 1,000x more reach than any Oculus/Quest launch in history</li>



<li><strong>It sets a new experience gold standard for VR</strong> especially by pushing the existing boundaries in display resolution and creating a new paradigm of “UI magic” with gaze &amp; pinch which may be an instant defacto standard</li>



<li><strong>It establishes a pricing envelope</strong> that enables Meta to break away from the $500 price point that Quest has been stuck in, and specifically allows them to ship a Quest Pro 2 headset priced at a $1,000 to $1,500 (but likely not higher) without being completely rejected by consumers</li>



<li><strong>It creates a formidable competitor</strong> for Meta teams to maniacally chase and will almost certainly force the company to move with a much greater sense of urgency internally (which would be a great outcome as friends on the inside are constantly complaining Meta Reality Labs moves too slowly)</li>
</ul>



<p><strong><em>What should Meta do in response to the Vision Pro launch?</em></strong></p>



<p>In order to really seize this moment and opportunity created by the Vision Pro launch, Meta needs to ensure it ships a VR headset by mid-2025 that both builds on the new experience gold standard created by the Vision Pro <em>and </em>is objectively a better product across as many dimensions as possible. It is imperative for Meta not to repeat the inexplicable debacle that was the <em>Quest Pro</em> launch in 2022.</p>



<p>I put together my own <strong>Top 10</strong> <strong>wish list for <em>Quest Pro 2</em></strong>:</p>



<ol>
<li><strong>Double down investment in micro-OLED</strong> as it’s likely the only way to achieve display resolution at or near Vision Pro; I suspect this may be exactly what the <a href="https://www.roadtovr.com/meta-lg-xr-partnership/" target="_blank" rel="noreferrer noopener">recently announced LG partnership</a> is about</li>



<li><strong>Build an ergonomic headset</strong> <strong>that can be worn for 2-4 hours</strong> without causing any major discomfort issues; ideally offering two battery options: (1) a head-strap with a built-in battery in the back of the head, and (2) a wired pack (like the Vision Pro) that moves the battery off the head and reduces the headset weight to below 500 grams while increasing energy capacity. </li>



<li><strong>Deliver better passthrough than Vision Pro</strong> by dramatically improving Quest 3’s latency and distortion correction and improving upon all of the Vision Pro passthrough issues — ensure no perceivable motion blur, high dynamic range, accurate white balance</li>



<li><strong>Take Apple’s gaze+pinch UI to the next level</strong> by productizing all of the amazing research on hand tracking done at Meta (ex: Rob Wang’s super talented group) to enable fine-grained gestures such as scrolling and D-pad selection by detecting small finger movements solely via camera input (this is <em>not</em> the CTRL Labs stack… that’s for the future)</li>



<li><strong>Partner with Microsoft to make Windows computers 1st class citizens</strong> in Quest Pro 2 and enable advanced desktop productivity use cases that go well beyond virtual monitors (ex: make it possible to take any window and place it in space)</li>



<li><strong>Launch Android 2D tablet apps natively on Quest</strong> to match the Vision Pro iPad compatibility library either by partnering with Google to license <em>Play Store</em> (which <a href="https://www.theinformation.com/articles/meta-rebuffed-google-proposal-for-a-vr-and-ar-tie-up">seems unlikely these days</a> though I still believe Ash Jhaveri and Hiroshi could work together to pull it off) or just build a curated tablet app store directly (which we had considered in the past at Oculus but passed on)</li>



<li><strong>Launch human-like avatars with Quest Pro 2</strong> by productizing Meta’s mind-blowing <a href="https://www.uploadvr.com/meta-codec-avatars-might-be-coming-to-quest/" target="_blank" rel="noreferrer noopener">Codec Avatars technology</a>, likely one of the VR research areas that has received the most R&amp;D dollars for the last 7+ years, used by <a href="https://youtu.be/MVYrJJNdrEg?si=EIZJ_Op4xRY9PD-h&amp;t=605" target="_blank" rel="noreferrer noopener">Lex Friedman in his interview with Mark Zuckerberg in late 2023</a></li>



<li><strong>Launch high-definition room scanning and unlock teleportation</strong> using technology that has existed within Oculus Research for several years now; it is time for Meta to make this future a reality where people can be remote but <em>feel</em> truly present by visiting each other’s home, office or favorite place</li>
</ol>



<h2>Appendix: Other Fun Things</h2>



<h2><strong>Despite all of its hardware insanity the Vision Pro display is still a far cry from a VR retina display (and may never get there)</strong></h2>



<p>As noted above the Vision Pro display delivers insane pixel density at over 3,000 PPI (compared to 500 PPI for the highest resolution smartphones), but because the panel is so close to our eyes, it still doesn’t come even close to the resolution it would need to have in order to qualify as a <em><a href="https://en.wikipedia.org/wiki/Retina_display">retina display</a></em>.</p>



<p>A retina display, by <a href="https://www.kybervision.com/Blog/files/AppleRetinaDisplay.html" target="_blank" rel="noreferrer noopener">Apple’s definition</a>, is a display with a high enough resolution that the human eye cannot resolve individual pixels. Because different devices are used at varying distances from the eye, there is no single PPI (pixels per inch) standard for retina across all device categories. Instead, it’s useful to look at PPD (pixels per degree), which is a measure of angular resolution independent of viewing distance, or specifically the number of horizontal pixels per degree of <em>viewing angle</em>. See <a href="https://simulavr.com/blog/ppd-optics/" target="_blank" rel="noreferrer noopener">this article from SimulaVR</a> for an excellent explanation, and here’s an image from that article:</p>







<figure><img data-attachment-id="74" data-permalink="https://hugo.blog/2024/03/11/vision-pro/ppd/" data-orig-file="https://hugobarracom.files.wordpress.com/2024/02/ppd.png" data-orig-size="460,286" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ppd" data-image-description="" data-image-caption="" data-medium-file="https://hugobarracom.files.wordpress.com/2024/02/ppd.png?w=300" data-large-file="https://hugobarracom.files.wordpress.com/2024/02/ppd.png?w=460" loading="lazy" width="460" height="286" src="https://hugobarracom.files.wordpress.com/2024/02/ppd.png?w=460" alt="" srcset="https://hugobarracom.files.wordpress.com/2024/02/ppd.png 460w, https://hugobarracom.files.wordpress.com/2024/02/ppd.png?w=150 150w, https://hugobarracom.files.wordpress.com/2024/02/ppd.png?w=300 300w" sizes="(max-width: 460px) 100vw, 460px"><figcaption>Source: <a href="https://simulavr.com/blog/ppd-optics/" target="_blank" rel="noreferrer noopener">SimularVR</a></figcaption></figure>



<p>A human eye with 20/20 vision has a resolution of 60 PPD. This means very specifically that we can resolve 60 pixels per each 1 degree of viewing angle (or 1 pixel per arc minute, which is 1/60th of a degree). The Vision Pro has an angular resolution of 34, which is 1/3 more than the Meta Quest 3 but still very far away from the 60 PPD we’d need for a retina-quality display.</p>



<p>Achieving angular resolution anywhere near 60 PPD in a VR headset is likely not possible with any technology in the mid-term horizon.</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>