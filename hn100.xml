<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 17 Mar 2025 01:30:12 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Tesla drives into Wile E. Coyote fake road wall in camera vs. Lidar test (111 pts)]]></title>
            <link>https://electrek.co/2025/03/16/tesla-autopilot-drives-into-wall-camera-vs-lidar-test/</link>
            <guid>43382230</guid>
            <pubDate>Sun, 16 Mar 2025 20:55:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/03/16/tesla-autopilot-drives-into-wall-camera-vs-lidar-test/">https://electrek.co/2025/03/16/tesla-autopilot-drives-into-wall-camera-vs-lidar-test/</a>, See on <a href="https://news.ycombinator.com/item?id=43382230">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="834" src="https://electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=1600" alt="Tesla cameras vs radar wall" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/03/Tesla-cameras-vs-radar-wall.png?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>Tesla Autopilot drove into Wile E. Coyote-style fake road wall in the middle of the road in a camera versus lidar test.</p>



<p>While most companies developing self-driving technologies have been using a mix of sensors (cameras, radar, lidar, and ultrasonic), Tesla insists on only using cameras.</p>



<p>The automaker removed radars from its vehicle lineup and even deactivated radars already installed in existing vehicles.</p>



<p>The strategy has yet to pay off as Tesla’s systems are still stuck at level 2 driver assist systems.</p>	
	



<p>CEO Elon Musk claims that Tesla’s advantage is that once it solves autonomy, it will be able to scale faster than competitors because its vision plus neural net system is designed to work like a human driver and, therefore, will be able to adapt to any road.</p>



<p>Critics have pushed back against those claims, especially since Musk mentioned Tesla achieving “level 5 autonomy”, which means “in any conditions,” and cameras have limitations on that front that are fixed by lidar sensors.</p>



<p>A new video by engineering Youtuber Mark Rober has provided a very interesting demonstration of that very problem:</p>



<figure><p>
<iframe id="post-youtube-video-1" title="Can You Fool A Self Driving Car?" width="500" height="281" data-src="https://www.youtube.com/embed/IQJL3htsDyQ?feature=oembed&amp;rel=0&amp;enablejsapi=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>In the video, Rober puts a Tesla Model Y on Autopilot against a vehicle using a lidar system in a series of tests in different conditions.</p>



<p>The Tesla on Autopilot managed to stop for a kid mannequin in the middle of the road when statics, moving, and blinded by lights, but it couldn’t stop in fog or heavy rain:</p>



<figure><img decoding="async" src="https://electrek.co/wp-content/uploads/sites/3/2025/03/Screenshot-2025-03-16-at-12.25.18%E2%80%AFPM.png?w=1024" alt=""></figure>



<p>It’s not surprising that the lidar, a laser-based system, is capable of detecting better in heavy fog than a camera system.</p>



<p>The heavy rain was a bit more surprising, but to be fair, the level of rain was quite spectacular.</p>



<p>The last scenario of a Wile E. Coyote-style wall with a fake road painted on it was obviously not realistic, but it serves to illustrate the issue with cameras versus radar or lidar sensors: they rely on the perception of potential obstacles rather than hard data about potential obstacles.</p>



<p>In simple words, the lidar sensors didn’t care what was painted on the wall, they only cared that it was a wall, while cameras can be tricked.</p>



<h2 id="h-electrek-s-take">Electrek’s Take</h2>



<p>I think it’s clear that no Tesla vehicle currently available will be capable of level 5 autonomy as Elon claimed.</p>




	<p>Level 4 is also questionable.</p>



<p>I think you can accomplish a lot with cameras, but I think it’s undeniable that adding radars and lidars can make systems safer.</p>



<p>In DMs with us during Tesla’s transition to vision only, Elon even admitted that “very high-resolution radars would be better than pure vision”, but he claimed that “such a radar does not exist”: </p>



<blockquote>
<p>“A very high-resolution radar would be better than pure vision, but such a radar does not exist.”</p>
</blockquote>



<p>When we pointed one out to him, he didn’t respond. Also, while they use light rather than radio waves, lidars are basically high-resolution radars, but the problem is that Musk has taken such a strong stance against them for so long that now that they have improved immensely and reduced in prices, he still can’t admit that he was wrong and use them.</p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Military grade sonic weapon is used against protesters in Serbia (374 pts)]]></title>
            <link>https://twitter.com/nexta_tv/status/1901244199220982213</link>
            <guid>43382093</guid>
            <pubDate>Sun, 16 Mar 2025 20:40:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/nexta_tv/status/1901244199220982213">https://twitter.com/nexta_tv/status/1901244199220982213</a>, See on <a href="https://news.ycombinator.com/item?id=43382093">Hacker News</a></p>
Couldn't get https://twitter.com/nexta_tv/status/1901244199220982213: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Zlib-rs is faster than C (157 pts)]]></title>
            <link>https://trifectatech.org/blog/zlib-rs-is-faster-than-c/</link>
            <guid>43381512</guid>
            <pubDate>Sun, 16 Mar 2025 19:35:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trifectatech.org/blog/zlib-rs-is-faster-than-c/">https://trifectatech.org/blog/zlib-rs-is-faster-than-c/</a>, See on <a href="https://news.ycombinator.com/item?id=43381512">Hacker News</a></p>
Couldn't get https://trifectatech.org/blog/zlib-rs-is-faster-than-c/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[AI Is Making Developers Dumb (147 pts)]]></title>
            <link>https://eli.cx/blog/ai-is-making-developers-dumb</link>
            <guid>43381215</guid>
            <pubDate>Sun, 16 Mar 2025 18:51:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eli.cx/blog/ai-is-making-developers-dumb">https://eli.cx/blog/ai-is-making-developers-dumb</a>, See on <a href="https://news.ycombinator.com/item?id=43381215">Hacker News</a></p>
Couldn't get https://eli.cx/blog/ai-is-making-developers-dumb: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Our Interfaces Have Lost Their Senses (256 pts)]]></title>
            <link>https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses</link>
            <guid>43380930</guid>
            <pubDate>Sun, 16 Mar 2025 18:11:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses">https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses</a>, See on <a href="https://news.ycombinator.com/item?id=43380930">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>





<article id="our-interfaces-have-lost-their-senses">



<a href="https://wattenberger.com/"><svg style="width: min(8vw, 8vh)" viewBox="0 0 245 213" fill="none" xmlns="http://www.w3.org/2000/svg"><g style="mix-blend-mode:multiply"><path fill-rule="evenodd" clip-rule="evenodd" d="M122.692 0.712992L163.395 71.213L163.394 71.2143L204.097 141.713H122.7L122.692 141.713L122.69 141.713H41.2939L81.993 71.2201L81.9889 71.213L122.692 0.712992Z" fill="#102A3D22"></path></g><g style="mix-blend-mode:multiply"><path fill-rule="evenodd" clip-rule="evenodd" d="M81.9889 212.213L122.692 141.713L122.691 141.712L163.394 71.213H81.9972L81.9889 71.2129L81.9873 71.213H0.590759L41.2898 141.706L41.2857 141.713L81.9889 212.213Z" fill="#102A3D22"></path></g><g style="mix-blend-mode:multiply"><path fill-rule="evenodd" clip-rule="evenodd" d="M163.39 212.213L204.094 141.713L204.093 141.712L244.795 71.213H163.399L163.39 71.2129L163.389 71.213H81.9922L122.691 141.706L122.687 141.713L163.39 212.213Z" fill="#102A3D22"></path></g></svg></a>




<p>Think about how you experience the world—</p>
<p>you touch, you hear, you move.</p>

<div>
		
		<p>But our digital world has been getting flatter, more muted.</p>
		<p>Reduced to text under glass screens.</p>
		<p>This shift made interfaces simpler.<br>But was that really the goal?
			</p></div>


<p>An interface is the bridge between
	</p>



<div><p>It's how we tell computers what we want,
			</p>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/arrow-right.png" alt=""></p><p>and it's how computers communicate back to us.
		</p>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/arrow-left.png" alt=""></p><div><div><p>The shape should fit how we work,
				</p><p>for ergonomics and ease of use</p></div>
			<div><p>and it should fit how the computer works.
			</p><p>for simplicity and a good mental model</p></div></div>

	<p>Recently, we've been too focused on fitting to the computer's shape, and not enough to our own bodies.
	</p></div>

<h2>The Great Flattening</h2>
<p>Computers used to be physical beasts.</p>
<p>We programmed them by punching cards, plugging in wires, and flipping switches. Programmers walked among banks of switches and cables, physically choreographing their logic. Being on a computer used to be a full-body experience.
</p>


<div><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/transition1.png"></p>
	<p><span><span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span>
    <span>Then came terminals and command lines. Physical knobs turned into typed commands—more powerful,
		but our digital world became less embodied.
	</span></span></p></div>

<div><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/transition2.png"></p>
	<p><span><span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span>
    <span>We brought back some of the tactile controls with GUIs—graphical user interfaces. We skeumorphed
		the heck out of our screens, with digital switches, flat sliders, and folder
		icons. But we kept some of the the functionality in the physical world, with slots to stick disks into
		and big ol' power buttons.
	</span></span></p></div>


<div><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/transition3.png"></p>
	<p><span><span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span>
    <span>Then came touchscreens.<br>What a beautiful thing! We get to
		<a href="https://www.youtube.com/watch?v=RyBEUyEtxQo" target="_blank">poke things directly</a>!<br>But now we live in an flat land, with everything behind a glass display case.
	</span></span></p></div>

<div><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/transition4.png"></p>
	<p><span><span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span>
    <span>With increasing amounts of AI chatbots, we're losing even more: texture, color, shape.<br>Instead
		of interactive controls, we have a text input.<br>Want to edit an image? Type a command.<br>Adjust a setting? Type into a text box.<br>Learn something? Read another block of text.
	</span></span></p></div>



<h2>The Joy of Doing</h2>

<p>We've been successfully removing all friction from our apps — think about how effortless it is to scroll
	through a social feed. But is that what we want? Compare the feeling of doomscrolling to kneading
	dough, playing an instrument, sketching... these take effort, but they're also deeply
	satisfying. When you strip away too much friction, meaning and satisfaction go with it.
</p>

<p>Think about how you use physical tools. Drawing isn't just moving your hand—it's the
	feel of the pencil against paper, the tiny adjustments of pressure, the sound of graphite
	scratching. You shift your body to reach the other side of the canvas. You erase with your other
	hand. You step back to see the whole picture.
</p>

<p>We made painting feel like typing,</p>

<div>
	<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/typing.png"></p>
	
	<div><p>but we should have made <em>typing</em> feel like <em>painting</em>.
			</p>
			<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/artist.png"></p></div></div>

<h2>Putting the you back in UI</h2>

<p>So how might our interfaces look if we shaped them to fit us?
</p>


<div><p>We think in <em>movement</em>,
		<img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/movement.png"></p>
	<p>in <em>space</em>,
		<img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/space.png"></p>
	
	<div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/sound.png"></p></div>
	<div><p>in <em>patterns</em>.
		</p><p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/patterns.png"></p></div>
	</div>
<p>We use our hands to sculpt, our eyes to scan, our ears to catch patterns.
	</p>







<p>Our computers can communicate to us in many different formats, each with their own strengths:</p>

<div><div><div><p>Text</p>
			<p>Great for depth, detail, and precision.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/images.png"></p><p>But it doesn't always have to be in full paragraphs. How about showing key points first, then letting users expand?
		</p></div>
	<div><div><p>Visualizations</p>
			<p>Ideal for spatial relationships, trends, and quick insights.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/vision.png"></p><p>Can we show more content spatially? Or encode it in charts or colors?</p></div>
	<div><div><p>Sound</p>
			<p>Perfect for alerts and background awareness. Also, patterns.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/hearing.png"></p><p>Why are most web UIs silent? Can we use subtle chimes or sonification to highlight patterns?</p></div>
	<div><div><p>Haptics</p>
			<p>Provides passive feedback (vibrations, force).</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/touch.png"></p><p>Here's one I always forget about! We can vibrate phones to alert or convey patterns.
		</p></div></div>

<p>And what about the reverse! We can communicate to our computers in many different ways, each with their own strengths:
</p>

<div><div><div><p>Typing</p>
			<p>Precise, detailed, and familiar</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/typing2.png"></p><p>Good for composing long-form thoughts, keyboard shortcuts, and rough direction.
		</p></div>
	<div><div><p>Clicking &amp; Dragging</p>
			<p>Direct, fine-grained control.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/clicking.png"></p><p>Great for spatial tasks (design, organization) and pointing at things-on-a-screen.
		</p></div>
	<div><div><p>Tapping, Swiping, Pinching</p>
			<p>Intuitive for direct manipulation.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/tapping.png"></p><p>Great for mobile, but do we have to limit guestures to mimicking mouse interactions?
		</p></div>
	<div><div><p>Gesturing</p>
			<p>Hands-free, fluid, and expressive.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/guesturing.png"></p><p>Could be powerful for accessibility, quick actions, and complex fine control—reliable detection feels very possible at this time.
		</p></div>
	<div><div><p>Speaking</p>
			<p>Easy for loose thoughts.</p></div>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/speaking.png"></p><p>LLMs have made speech more viable—can we let users think out loud or navigate roughly with their voice?
		</p></div></div>



<p>And the real magic happens when we combine different modalities. You can't read and listen and speak
	at the same time—try reading this excerpt while talking about your day:
</p>

<div><p>If it had not rained on a certain May morning Valancy Stirling’s whole life would have been
		entirely different. She would have gone, with the rest of her clan, to Aunt Wellington’s
		engagement picnic and Dr. Trent would have gone to Montreal. But it did rain and you shall hear
		what happened to her because of it.
	</p>
	</div>

<div><div><p>But you can talk while clicking,</p>
		<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/click.png"></p></div>
<div><p>listen while reading,</p>
	<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/listen.png"></p></div>
<div><p>look at an image while spinning a knob,</p>
	<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/look.png"></p></div>
<div><p>guesture while talking.</p>
	<p><img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/guesture.png"></p></div>
</div>

<p>Let's build interfaces that let us multitask across senses.</p>

<h2>Rebuilding the bridge</h2>
<p>So, what might a richer interface look like? I have strong conviction that our future interfaces should:
</p>
<ul><li>let us collaborate on <strong>tangible artifacts</strong>, not just ephemeral chat logs.</li>
	<li>support <strong>multiple concurrent modalities</strong>—voice, gestures,
		visuals, spatial components.
	</li>
	<li>respond to <strong>ambient signals</strong>—detecting context, organizing information, helping
		us think better.
	</li></ul>

<p>Last year, I did a rough exploration of what this could look like for a thought organizing tool. One that listened as you talked or typed, and organized your rambling thoughts into cards.
</p>



<p>This interface is very rough, but felt like a different way of working with technology. Especially how it let me bumble through rough ideas one second, then responded to commands like "re-group my cards" or "add 3 cards about this" the next.
</p>

<p>I would love to see more explorations like this!
</p>

<h2>Our interfaces have lost their senses</h2>
<p>All day, we poke, swipe, and scroll through flat, silent
	screens. But we're more than just eyes and a pointer finger. We think with our hands, our ears,
	our bodies.
</p>

<p>The future of computing is being designed right now. Can we build something richer—something that
	moves with us, speaks our language, and molds to our bodies?
</p>

<img src="https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/footer.png">
</article>


			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["Wait, not like that": Free and open access in the age of generative AI (103 pts)]]></title>
            <link>https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/</link>
            <guid>43380617</guid>
            <pubDate>Sun, 16 Mar 2025 17:23:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/">https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=43380617">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

        <header>

                <a href="https://www.citationneeded.news/tag/artificial-intelligence/">Artificial intelligence</a>
            
                <p>The real threat isn’t AI using open knowledge — it’s AI companies killing the projects that make knowledge free</p>

            <div>
                <p><a href="https://www.citationneeded.news/author/molly/">
                                <img src="https://www.citationneeded.news/content/images/size/w160/2023/12/molly-sq.jpeg" alt="Molly White">
                            </a>
                </p>
                
            </div>

                <figure>
        <img srcset="https://www.citationneeded.news/content/images/size/w320/2025/03/ai-vampire-1.jpg 320w,
                    https://www.citationneeded.news/content/images/size/w600/2025/03/ai-vampire-1.jpg 600w,
                    https://www.citationneeded.news/content/images/size/w960/2025/03/ai-vampire-1.jpg 960w,
                    https://www.citationneeded.news/content/images/size/w1200/2025/03/ai-vampire-1.jpg 1200w,
                    https://www.citationneeded.news/content/images/size/w2000/2025/03/ai-vampire-1.jpg 2000w" sizes="(max-width: 1200px) 100vw, 1120px" src="https://www.citationneeded.news/content/images/size/w1200/2025/03/ai-vampire-1.jpg" alt="A digital collage depicting a vampire biting onto a laptop displaying the Wikipedia homepage">
    </figure>

        </header>

        <section>
            <div><p><img src="https://www.citationneeded.news/content/media/2025/03/2025-03-14-Wait-not-like-that_thumb.png" alt="audio-thumbnail"></p><div><p>“Wait, not like that”: Free and open access in the age of generative AI</p></div></div>
<!--kg-card-begin: html-->
<p>Listen to me read this post here (not an AI-generated voice!), <a href="https://www.citationneeded.news/podcast/">subscribe</a> to the feed in your podcast app, or <a href="https://www.citationneeded.news/content/media/2025/03/2025-03-14-Wait-not-like-that.mp3">download</a> the recording for later.</p>


<!--kg-card-end: html-->

<!--kg-card-begin: html-->
<p>The visions of the open access movement have inspired countless people to contribute their work to the commons: a world where “every single human being can freely share in the sum of all knowledge” (Wikimedia), and where “education, culture, and science are equitably shared as a means to benefit humanity” (Creative Commons<sup id="footnote-anchor-1"><a href="#footnote-1">a</a></sup>).</p>
<!--kg-card-end: html-->
<p>But there are scenarios that can introduce doubt for those who contribute to free and open projects like the Wikimedia projects, or who independently release their own works under free licenses. I call these “wait, no, not like that” moments.</p><p>When a passionate Wikipedian discovers their carefully researched article has been packaged into an e-book and sold on Amazon for someone else’s profit? <em>Wait, no, not like that</em>.</p><p>When a developer of an open source software project sees a multi-billion dollar tech company rely on their work without contributing anything back? <em>Wait, no, not like that.</em></p><p>When a nature photographer discovers their freely licensed wildlife photo was used in an NFT collection minted on an environmentally destructive blockchain? <em>Wait, no, not like that</em>.</p><p>And perhaps most recently, when a person who publishes their work under a free license discovers that work has been used by tech mega-giants to train extractive, exploitative large language models? <strong><em>Wait, no, not like that</em>.</strong></p><p>These reactions are understandable. When we freely license our work, we do so in service of those goals: free and open access to knowledge and education. But when trillion dollar companies exploit that openness while giving nothing back, or when our work enables harmful or exploitative uses, it can feel like we've been naïve. The natural response is to try to regain control.</p><p>This is where many creators find themselves today, particularly in response to AI training. But the solutions they're reaching for — more restrictive licenses, paywalls, or not publishing at all — risk destroying the very commons they originally set out to build.</p><div><p><i><em>Citation Needed</em></i> is an independent publication, entirely supported by readers like you. Consider <a href="https://www.citationneeded.news/signup">signing up</a> for a free or pay-what-you-want subscription — it really helps me to keep doing this work.</p></div>
<!--kg-card-begin: html-->
<p>The first impulse is often to try to tighten the licensing, maybe by switching away to something like the <a href="https://en.wikipedia.org/wiki/Creative_Commons_NonCommercial_license" target="_blank" rel="noopener noreferrer nofollow">Creative Commons’ non-commercial</a> (and thus, non-free) license. When NFTs enjoyed a moment of popularity in the early 2020s, some artists looked to Creative Commons in hopes that they might declare NFTs fundamentally incompatible with their free licenses (they didn’t<sup id="reference-anchor-1"><a href="#reference-1">1</a></sup>). The same thing happened again with the explosion of generative AI companies training models on CC-licensed works, and some were disappointed to see the group take the stance that, not only do CC licenses not prohibit AI training wholesale, AI training should be considered non-infringing by default from a copyright perspective.<sup id="reference-anchor-2"><a href="#reference-2">2</a></sup></p>
<!--kg-card-end: html-->

<!--kg-card-begin: html-->
<p>But the trouble with trying to continually narrow the definitions of “free” is that it is impossible to write a license that will perfectly prohibit each possibility that makes a person go “wait, no, not like that” while retaining the benefits of free and open access. If that is truly what a creator wants, then they are likely better served by a traditional, all rights reserved model in which any prospective reuser must individually negotiate terms with them; but this undermines the purpose of free, and restricts permitted reuse only to those with the time, means, and bargaining power to negotiate on a case by case basis.<sup id="footnote-anchor-2"><a href="#footnote-2">b</a></sup></p>
<!--kg-card-end: html-->

<!--kg-card-begin: html-->
<p>Particularly with AI, there’s also no indication that tightening the license even <i><em>works</em></i>. We already know that major AI companies have been training their models on all rights reserved works in their ongoing efforts to ingest as much data as possible. Such training may prove to have been permissible in US courts under fair use, and it’s probably best that it does.<sup id="reference-anchor-3"><a href="#reference-3">3</a></sup><sup id="reference-anchor-4"><a href="#reference-4">4</a></sup><sup id="reference-anchor-5"><a href="#reference-5">5</a></sup><sup id="reference-anchor-6"><a href="#reference-6">6</a></sup></p>
<!--kg-card-end: html-->
<p>There’s also been an impulse by creators concerned about AI to dramatically limit how people can access their work. Some artists have decided it’s simply not worthwhile to maintain an online gallery of their work when that makes it easily accessible for AI training. Many have implemented restrictive content gates — paywalls, registration-walls, “are you a human”-walls, and similar — to try to fend off scrapers. This too closes off the commons, making it more challenging or expensive for those “every single human beings” described in open access manifestos to access the material that was originally intended to be common goods.</p>
<!--kg-card-begin: html-->
<p>Often by trying to wall off those considered to be bad actors, people wall off the very people they intended to give access to. People who gate their work behind paywalls likely didn’t set out to create works that only the wealthy could access. People who implement registration walls probably didn’t intend for their work to only be available to those willing to put up with the risk of incessant email spam after they relinquish their personal information. People who try to stave off bots with CAPTCHAs asking “are you a human?” probably didn’t mean to limit their material only to abled people<sup id="reference-anchor-7"><a href="#reference-7">7</a></sup> who are willing to abide ever more protracted and irritating riddles.<sup id="reference-anchor-8"><a href="#reference-8">8</a></sup> And people using any of these strategies likely didn’t want people to struggle to even find their work in the first place after the paywalls and regwalls and anti-bot mechanisms thwarted search engine indexers or social media previews.</p>
<!--kg-card-end: html-->
<p>And frankly, if we want to create a world in which every single human being can freely share in the sum of all knowledge, and where education, culture, and science are equitably shared as a means to benefit humanity, we should stop attempting to erect these walls. If a kid learns that carbon dioxide traps heat in Earth's atmosphere or how to calculate compound interest thanks to an editor’s work on a Wikipedia article, does it really matter if they learned it via ChatGPT or by asking Siri or from opening a browser and visiting Wikipedia.org?</p><p><strong>Instead of worrying about “wait, not like that”, I think we need to reframe the conversation to “wait, not <em>only</em> like that” or “wait, not in ways that threaten open access itself”.</strong> The true threat from AI models training on open access material is not that more people may access knowledge thanks to new modalities. It’s that those models may stifle Wikipedia and other free knowledge repositories, benefiting from the labor, money, and care that goes into supporting them while also bleeding them dry. It’s that trillion dollar companies become the sole arbiters of access to knowledge after subsuming the painstaking work of those who made knowledge free to all, killing those projects in the process.</p><p>Irresponsible AI companies are already imposing huge loads on Wikimedia infrastructure, which is costly both from a pure bandwidth perspective, but also because it requires dedicated engineers to maintain and improve systems to handle the massive automated traffic. And AI&nbsp;companies that do not attribute their responses or otherwise provide any pointers back to Wikipedia prevent users from knowing where that material came from, and do not encourage those users to go visit Wikipedia, where they might then sign up as an editor, or donate after seeing a request for support. (This is most AI companies, by the way. Many AI “visionaries” seem perfectly content to promise that artificial superintelligence is just around the corner, but claim that attribution is somehow a permanently unsolvable problem.)</p><p>And while I rely on Wikipedia as an example here, the same goes for any website containing freely licensed material, where scraping benefits AI companies at often extreme cost to the content hosts. This isn't just about strain on one individual project, it's about the systematic dismantling of the infrastructure that makes open knowledge possible.</p><p>Anyone at an AI company who stops to think for half a second should be able to recognize they have a vampiric relationship with the commons. While they rely on these repositories for their sustenance, their adversarial and disrespectful relationships with creators reduce the incentives for anyone to make their work publicly available going forward (freely licensed or otherwise). They drain resources from maintainers of those common repositories often without any compensation. They reduce the visibility of the original sources, leaving people unaware that they can or should contribute towards maintaining such valuable projects. AI companies should want a thriving open access ecosystem, ensuring that the models they trained on Wikipedia in 2020 can be continually expanded and updated. Even if AI companies don’t care about the benefit to the common good, it shouldn’t be hard for them to understand that by bleeding these projects dry, they are destroying their own food supply.</p><p>And yet many AI companies seem to give very little thought to this, seemingly looking only at the months in front of them rather than operating on years-long timescales. (Though perhaps anyone who has observed AI companies’ activities more generally will be unsurprised to see that they do not act as though they believe their businesses will be sustainable on the order of years.)</p><p>It would be very wise for these companies to immediately begin prioritizing the ongoing health of the commons, so that they do not wind up strangling their golden goose. It would also be very wise for the rest of us to not rely on AI companies to suddenly, miraculously come to their senses or develop a conscience en masse.</p><p>Instead, we must ensure that mechanisms are in place to <em>force</em> AI companies to engage with these repositories on their creators' terms.</p>
<!--kg-card-begin: html-->
<p>There are ways to do it: models like Wikimedia Enterprise, which welcomes AI companies to use Wikimedia-hosted data, but requires them to do so using paid, high-volume pipes to ensure that they do not clog up the system for everyone else and to make them financially support the extra load they’re placing on the project’s infrastructure. Creative Commons is experimenting with the idea of “<a href="https://www.ietf.org/slides/slides-aicontrolws-creative-commons-position-paper-on-preference-signals-00.pdf">preference signals</a>” — a non-copyright-based model by which to communicate to AI companies and other entities the terms on which they may or may not reuse CC licensed work.<sup id="footnote-anchor-3"><a href="#footnote-3">c</a></sup> Everyday people need to be given the tools — both legal and technical — to enforce their own preferences around how their works are used.</p>
<!--kg-card-end: html-->
<p>Some might argue that if AI companies are already ignoring copyright and training on all-rights-reserved works, they'll simply ignore these mechanisms too. But there's a crucial difference: rather than relying on murky copyright claims or threatening to expand copyright in ways that would ultimately harm creators, we can establish clear legal frameworks around consent and compensation that build on existing labor and contract law. Just as unions have successfully negotiated terms of use, ethical engagement, and fair compensation in the past, collective bargaining can help establish enforceable agreements between AI companies, those freely licensing their works, and communities maintaining open knowledge repositories. These agreements would cover not just financial compensation for infrastructure costs, but also requirements around attribution, ethical use, and reinvestment in the commons.</p><p>The future of free and open access isn't about saying “wait, not like that” — it’s about saying "yes, like that, but under fair terms”. With fair compensation for infrastructure costs. With attribution and avenues by which new people can discover and give back to the underlying commons. With deep respect for the communities that make the commons — and the tools that build off them —&nbsp;possible. Only then can we truly build that world where every single human being can freely share in the sum of all knowledge.</p><hr>
<!--kg-card-begin: html-->
<p>As I was writing this piece, I discovered that a SXSW panel featuring delegates from the Wikimedia Foundation and Creative Commons, titled “<a href="https://schedule.sxsw.com/2025/events/PP153044">Openness Under Pressure: Navigating the Future of Open Access</a>”, discussed some of the same topics. (I was, sadly, scheduled to speak at the same time and so was unable to attend in person). The audio recording is available online, and I would highly recommend giving it a listen if this is a topic that interests you!</p>
<!--kg-card-end: html-->

<!--kg-card-begin: html-->

<!--kg-card-end: html-->

<!--kg-card-begin: html-->
<div>
  <h4>References</h4>
  <ol><li id="reference-1"><p>“<a href="https://creativecommons.org/cc-and-nfts/" target="_blank" rel="noopener noreferrer nofollow">FAQ: CC and NFTs</a>”, Creative Commons. <a href="#reference-anchor-1" title="Jump back to reference 1 in the text.">↩</a></p></li><li id="reference-2"><p>“<a href="https://creativecommons.org/2021/03/04/should-cc-licensed-content-be-used-to-train-ai-it-depends/" target="_blank" rel="noopener noreferrer nofollow">Should CC-Licensed Content be Used to Train AI? It Depends.</a>” Creative Commons. <a href="#reference-anchor-2" title="Jump back to reference 2 in the text.">↩</a></p></li><li id="reference-3"><p>“<a href="https://www.regulations.gov/comment/COLC-2023-0006-8735" target="_blank" rel="noopener noreferrer nofollow">Comment from Creative Commons</a>”, published by the US Copyright Office. <a href="#reference-anchor-3" title="Jump back to reference 3 in the text.">↩</a></p></li><li id="reference-4"><p>“<a href="https://www.eff.org/deeplinks/2025/02/ai-and-copyright-expanding-copyright-hurts-everyone-heres-what-do-instead" target="_blank" rel="noreferrer">AI And Copyright: Expanding Copyright Hurts Everyone—Here’s What to Do Instead</a>”, EFF. <a href="#reference-anchor-4" title="Jump back to reference 4 in the text.">↩</a></p></li><li id="reference-5"><p>“<a href="https://pluralistic.net/2024/06/21/off-the-menu/" target="_blank" rel="noopener noreferrer nofollow">Neither the devil you know nor the devil you don’t</a>”, Cory Doctorow. <a href="#reference-anchor-5" title="Jump back to reference 5 in the text.">↩</a></p></li><li id="reference-6"><p>“<a href="https://www.techdirt.com/2023/12/04/if-creators-suing-ai-companies-over-copyright-win-it-will-further-entrench-big-tech/" target="_blank" rel="noopener noreferrer nofollow">If Creators Suing AI Companies Over Copyright Win, It Will Further Entrench Big Tech</a>”, <i><em>TechDirt</em></i>. <a href="#reference-anchor-6" title="Jump back to reference 6 in the text.">↩</a></p></li><li id="reference-7"><p>“<a href="https://www.w3.org/TR/turingtest/#the-accessibility-challenge" target="_blank" rel="noopener noreferrer nofollow">Inaccessibility of CAPTCHA</a>”, W3C. <a href="#reference-anchor-7" title="Jump back to reference 7 in the text.">↩</a></p></li><li id="reference-8"><p>“<a href="https://www.thetimes.com/business-money/technology/article/youre-not-imagining-it-captchas-are-getting-harder-x73kr720x?region=global" target="_blank" rel="noopener noreferrer nofollow">You’re not imagining it, Captchas are getting harder</a>”, <i><em>The Times</em></i>. <a href="#reference-anchor-8" title="Jump back to reference 8 in the text.">↩</a></p></li></ol>
</div>
<!--kg-card-end: html-->

<!--kg-card-begin: html-->

<!--kg-card-end: html-->

        </section>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DiceDB (110 pts)]]></title>
            <link>https://dicedb.io/</link>
            <guid>43379262</guid>
            <pubDate>Sun, 16 Mar 2025 14:20:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dicedb.io/">https://dicedb.io/</a>, See on <a href="https://news.ycombinator.com/item?id=43379262">Hacker News</a></p>
Couldn't get https://dicedb.io/: Error: getaddrinfo ENOTFOUND dicedb.io]]></description>
        </item>
        <item>
            <title><![CDATA[Learn You Some Erlang for Great Good (2013) (101 pts)]]></title>
            <link>https://learnyousomeerlang.com/content</link>
            <guid>43378415</guid>
            <pubDate>Sun, 16 Mar 2025 12:14:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://learnyousomeerlang.com/content">https://learnyousomeerlang.com/content</a>, See on <a href="https://news.ycombinator.com/item?id=43378415">Hacker News</a></p>
Couldn't get https://learnyousomeerlang.com/content: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Big LLMs weights are a piece of history (239 pts)]]></title>
            <link>https://antirez.com/news/147</link>
            <guid>43378401</guid>
            <pubDate>Sun, 16 Mar 2025 12:13:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antirez.com/news/147">https://antirez.com/news/147</a>, See on <a href="https://news.ycombinator.com/item?id=43378401">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<section id="newslist"><article data-news-id="147"></article></section><topcomment><article data-comment-id="147-" id="147-"><span><span><a href="https://antirez.com/user/antirez">antirez</a></span> 4 hours ago. 19973 views.  </span><pre>By multiple accounts, the web is losing pieces: every year a fraction of old web pages disappear, lost forever. We should regard the Internet Archive as one of the most valuable pieces of modern history; instead, many companies and entities make the chances of the Archive to survive, and accumulate what otherwise will be lost, harder and harder. I understand that the Archive headquarters are located in what used to be a church: well, there is no better way to think of it than as a sacred place.

Imagine the long hours spent by old programmers hacking with the Z80 assembly on their Spectrums. All the discussions about the first generation of the Internet. The subcultures that appeared during the 90s. All things that are getting lost, piece by piece.

And what about the personal blogs? Pieces of life of single individuals that dumped part of their consciousness on the Internet. Scientific papers and processes that are lost forever as publishers fail, their websites shut down. Early digital art, video games, climate data once published on the Internet and now lost, and many sources of news, as well.

This is a known issue and I believe that the obvious approach of trying to preserve everything is going to fail, for practical reasons: a lot of efforts for zero economic gains: the current version of the world is not exactly the best place to make efforts that cost a lot of money and don't pay money. This is why I believe that the LLMs' ability to compress information, even if imprecise, hallucinated, lacking, is better than nothing. DeepSeek V3 is already an available, public lossy compressed view of the Internet, as other very large state of-art models are.

This will not bring back all the things we are losing, and we should try hard supporting The Internet Archive and other similar institutions and efforts. But, at the same time, we should focus on a much simpler effort: to make sure that the weights of LLMs publicly released do not get lost, and also to make sure that the Archive is part of the pre-training set as well.</pre></article></topcomment>


<p><a href="https://disqus.com/">blog comments powered by <span>Disqus</span></a>

</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The good times in tech are over (158 pts)]]></title>
            <link>https://www.seangoedecke.com/good-times-are-over/</link>
            <guid>43378321</guid>
            <pubDate>Sun, 16 Mar 2025 11:59:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seangoedecke.com/good-times-are-over/">https://www.seangoedecke.com/good-times-are-over/</a>, See on <a href="https://news.ycombinator.com/item?id=43378321">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>For most of the last decade, being a software engineer has been a lot of fun. Every company offered lots of perks, layoffs and firings were almost unheard of, and in general we were treated as special little geniuses who needed to be pampered so we could work our magic. That’s changed in the last two years. The <a href="https://techcrunch.com/2024/05/01/a-comprehensive-archive-of-2023-tech-layoffs/">first round</a> of tech layoffs in 2023 came as a shock, but at least companies were falling over themselves to offer generous severance and teary CEO letters regretting the necessity. Two years later, Meta is explicitly <a href="https://fortune.com/2025/02/13/meta-low-performer-layoffs-staff-experts-criticism/">branding</a> its layoffs as “these were our lowest performers, good riddance”. What the hell happened?<sup id="fnref-1"><a href="#fn-1">1</a></sup> What does it mean for us?</p>
<h3>Why did the vibe shift?</h3>
<p>In the 2010s, interest rates were zero or close to zero<sup id="fnref-2"><a href="#fn-2">2</a></sup>. Investors could thus borrow a <em>lot</em> of money. Much of that money was spent on tech companies in the hope of outsized returns. Tech companies were thus incentivized to (a) hire like crazy, and (b) do a lot of low-risk high-reward things, even if that ends up wasting money. Tech companies definitely did <em>not</em> have to be profitable. In fact, they didn’t even need to make money - they just had to acquire users, or at least hype, to drive up the valuation of the company itself. In that environment, throwing money at their software engineers (in the form of paid trips, in-house chefs, and huge comp packages) was a sensible business decision.</p>
<p>In 2023, this underlying economic situation reversed: interest rates went up to around 5%<sup id="fnref-3"><a href="#fn-3">3</a></sup>. Tech company incentives completely flipped: now it’s suddenly important to be profitable, or at least to make lots of money. That means it’s not wise for most companies to hire like crazy, or to continue throwing near-unlimited amounts of money at their software engineers.</p>
<p>I think that’s a sufficient explanation for the vibe shift all by itself. What about COVID? It helped, but it wasn’t the root cause. Two years (or thereabouts) of people staying inside more meant much more engagement with tech products, which meant much more money flowing into tech companies. <em>Everyone</em> was hiring during COVID. Once that short-term boom finished, companies naturally wanted to get rid of some of those engineers, which is what triggered a lot of the initial layoffs. However, I do think that even without COVID, we’d still be in something like the current situation. Companies were constantly hiring pre-2020 as well.</p>
<p>This idea that AI is taking software engineering jobs or contributing to layoffs is - as far as I can tell - currently pure fantasy. I do believe in the power of AI, and I wouldn’t be surprised if it takes software jobs at some point in the future, but it’s certainly not behind the vibe shift in software engineering right now.</p>
<h3>What does that mean for us?</h3>
<p>I think a lot of software engineers right now are planting their feet and refusing to change. After ten years of their opinion being consulted on big company decisions, they’re trying to hold on to that power. I have respect for anyone who stands up for what they think is right at personal cost. I just want to stress that there <em>is</em> going to be a personal cost to not going along with the vibe shift, particularly for more junior or more vulnerable engineers. As someone who lives in Australia, I feel <a href="https://www.seangoedecke.com/working-for-americans">pretty vulnerable</a> myself.</p>
<p>The biggest thing to internalize is that <strong>companies now are actually trying to focus</strong>. In 2015, there was a lot of appetite to do everything at the same time: building out new product lines, transitioning from a product to a platform, making significant open-source contributions, working on a top-tier developer experience, and so on. In 2025, most of these initiatives have been abruptly defunded in order to put more resources into a handful of bets that the company executives actually care about.</p>
<p>During the 2010s, it was as if companies <em>were</em> their software engineers, and were interested in the same things as their engineers were. A lot of engineers were fooled by this into identifying strongly with their employer. But this was a mirage: in part caused by companies’ desire to attract and retain talent, and in part by there being no real pressure on companies to say no to anything. Now the mirage has vanished. Companies are their executive leadership, and their executive leadership are interested in a much smaller set of things.</p>
<p>If you were an engineer who loved working on your company’s open-source libraries, it’s probably sensible to confront the fact that the company never really cared about it that much. When interest rates were zero, it was worth doing because most things were worth doing. At 5% interest rates, most open-source work doesn’t meet that bar. In other words, <strong>your interests now conflict with your company’s interests</strong>.</p>
<p>It’s okay for your interests to conflict with your company’s. You get to decide what you care about, and what you’re willing to fight for. But when you act in ways that don’t further your company’s interests, you risk being seen as ineffective or unreliable. In 2025, that makes you vulnerable to being laid off.</p>
<h3>Is there a silver lining?</h3>
<p>The good news is that tech companies now live in (or at least a lot closer to) the “real world”. It was nice to be pampered, but there was a fundamental ridiculousness about it, even at the time. I know a lot of engineers who found that offputting, including myself. It’s why many engineers found the TV show <em>Silicon Valley</em> hard to watch - the satire was too real to laugh at. It was mainly embarrassing.</p>
<p>If I had to choose, I’d definitely choose to return to the job market of the 2010s, so I can be paid more to work less and have more job security. I’m not an idiot. But the silver lining to <em>actually having to ship</em> is that you’re no longer living in a dream. If you’re realistic about how things work, <a href="https://www.seangoedecke.com/how-to-ship">the job of software engineering</a> becomes much easier to understand:</p>
<ol>
<li>Providing value to the company gets you rewarded</li>
<li>Not providing value to the company gets you punished</li>
<li>“Value to the company” means furthering the explicit plans of your company’s executives</li>
</ol>
<p>It’s not much of a mission statement! Certainly nothing on <a href="https://www.youtube.com/watch?v=B8C5sjjhsso&amp;ab_channel=BrianJ.Hall">“making the world a better place”</a>. But it has the comforting solidity of the truth. The good thing about the music finally stopping is that you don’t have to worry about when it’s going to stop.</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Docs – Open source alternative to Notion or Outline (1133 pts)]]></title>
            <link>https://github.com/suitenumerique/docs</link>
            <guid>43378239</guid>
            <pubDate>Sun, 16 Mar 2025 11:38:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/suitenumerique/docs">https://github.com/suitenumerique/docs</a>, See on <a href="https://news.ycombinator.com/item?id=43378239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://github.com/suitenumerique/docs">
    <img alt="Docs" src="https://github.com/suitenumerique/docs/raw/main/docs/assets/docs-logo.png" width="300">
  </a>
</p>
<p dir="auto">
Welcome to Docs! The open source document editor where your notes can become knowledge through live collaboration
</p>
<p dir="auto">
  <a href="https://matrix.to/#/#docs-official:matrix.org" rel="nofollow">
    Chat on Matrix
  </a> - <a href="https://github.com/suitenumerique/docs/blob/main/docs">
    Documentation
  </a> - <a href="#getting-started-">
    Getting started
  </a> - <a href="mailto:docs@numerique.gouv.fr">
    Reach out
  </a>
</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/suitenumerique/docs/blob/main/docs/assets/docs_live_collaboration_light.gif"><img src="https://github.com/suitenumerique/docs/raw/main/docs/assets/docs_live_collaboration_light.gif" width="100%" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why use Docs ❓</h2><a id="user-content-why-use-docs-" aria-label="Permalink: Why use Docs ❓" href="#why-use-docs-"></a></p>
<p dir="auto">Docs is a collaborative text editor designed to address common challenges in knowledge building and sharing.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Write</h3><a id="user-content-write" aria-label="Permalink: Write" href="#write"></a></p>
<ul dir="auto">
<li>😌 Simple collaborative editing without the formatting complexity of markdown</li>
<li>🔌 Offline? No problem, keep writing, your edits will get synced when back online</li>
<li>💅 Create clean documents with limited but beautiful formatting options and focus on content</li>
<li>🧱 Built for productivity (markdown support, many block types, slash commands, keyboard shortcuts).</li>
<li>✨ Save time thanks to our AI actions (generate, sum up, correct, translate)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Collaborate</h3><a id="user-content-collaborate" aria-label="Permalink: Collaborate" href="#collaborate"></a></p>
<ul dir="auto">
<li>🤝 Collaborate with your team in real time</li>
<li>🔒 Granular access control to ensure your information is secure and only shared with the right people</li>
<li>📑 Professional document exports in multiple formats (.odt, .doc, .pdf) with customizable templates</li>
<li>📚 Built-in wiki functionality to turn your team's collaborative work into organized knowledge <code>ETA 02/2025</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Self-host</h3><a id="user-content-self-host" aria-label="Permalink: Self-host" href="#self-host"></a></p>
<ul dir="auto">
<li>🚀 Easy to install, scalable and secure alternative to Notion, Outline or Confluence</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started 🔧</h2><a id="user-content-getting-started-" aria-label="Permalink: Getting started 🔧" href="#getting-started-"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Test it</h3><a id="user-content-test-it" aria-label="Permalink: Test it" href="#test-it"></a></p>
<p dir="auto">Test Docs on your browser by logging in on this <a href="https://impress-preprod.beta.numerique.gouv.fr/docs/0aa856e9-da41-4d59-b73d-a61cb2c1245f/" rel="nofollow">environment</a></p>
<div data-snippet-clipboard-copy-content="email: test.docs@yopmail.com
password: I'd<3ToTestDocs"><pre><code>email: test.docs@yopmail.com
password: I'd&lt;3ToTestDocs
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Run it locally</h3><a id="user-content-run-it-locally" aria-label="Permalink: Run it locally" href="#run-it-locally"></a></p>
<blockquote>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> Running Docs locally using the methods described below is for testing purposes only.  It is based on building Docs using Minio as the S3 storage solution: if you want to use Minio for production deployment of Docs, you will need to comply with Minio's AGPL-3.0 licence.</p>
</blockquote>
<p dir="auto"><strong>Prerequisite</strong></p>
<p dir="auto">Make sure you have a recent version of Docker and <a href="https://docs.docker.com/compose/install" rel="nofollow">Docker Compose</a> installed on your laptop:</p>
<div data-snippet-clipboard-copy-content="$ docker -v

Docker version 20.10.2, build 2291f61

$ docker compose version

Docker Compose version v2.32.4"><pre lang="shellscript"><code>$ docker -v

Docker version 20.10.2, build 2291f61

$ docker compose version

Docker Compose version v2.32.4
</code></pre></div>
<blockquote>
<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> You may need to run the following commands with sudo but this can be avoided by adding your user to the <code>docker</code> group.</p>
</blockquote>
<p dir="auto"><strong>Project bootstrap</strong></p>
<p dir="auto">The easiest way to start working on the project is to use GNU Make:</p>
<div data-snippet-clipboard-copy-content="$ make bootstrap FLUSH_ARGS='--no-input'"><pre lang="shellscript"><code>$ make bootstrap FLUSH_ARGS='--no-input'
</code></pre></div>
<p dir="auto">This command builds the <code>app</code> container, installs dependencies, performs database migrations and compile translations. It's a good idea to use this command each time you are pulling code from the project repository to avoid dependency-related or migration-related issues.</p>
<p dir="auto">Your Docker services should now be up and running 🎉</p>
<p dir="auto">You can access to the project by going to <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a>.</p>
<p dir="auto">You will be prompted to log in, the default credentials are:</p>
<div data-snippet-clipboard-copy-content="username: impress
password: impress"><pre><code>username: impress
password: impress
</code></pre></div>
<p dir="auto">📝 Note that if you need to run them afterwards, you can use the eponym Make rule:</p>

<p dir="auto"><g-emoji alias="warning">⚠️</g-emoji> For the frontend developer, it is often better to run the frontend in development mode locally.</p>
<p dir="auto">To do so, install the frontend dependencies with the following command:</p>
<div data-snippet-clipboard-copy-content="$ make frontend-development-install"><pre lang="shellscript"><code>$ make frontend-development-install
</code></pre></div>
<p dir="auto">And run the frontend locally in development mode with the following command:</p>
<div data-snippet-clipboard-copy-content="$ make run-frontend-development"><pre lang="shellscript"><code>$ make run-frontend-development
</code></pre></div>
<p dir="auto">To start all the services, except the frontend container, you can use the following command:</p>

<p dir="auto"><strong>Adding content</strong>
You can create a basic demo site by running:</p>

<p dir="auto">Finally, you can check all available Make rules using:</p>

<p dir="auto"><strong>Django admin</strong></p>
<p dir="auto">You can access the Django admin site at</p>
<p dir="auto"><a href="http://localhost:8071/admin" rel="nofollow">http://localhost:8071/admin</a>.</p>
<p dir="auto">You first need to create a superuser account:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Feedback 🙋‍♂️🙋‍♀️</h2><a id="user-content-feedback-️️" aria-label="Permalink: Feedback 🙋‍♂️🙋‍♀️" href="#feedback-️️"></a></p>
<p dir="auto">We'd love to hear your thoughts and hear about your experiments, so come and say hi on <a href="https://matrix.to/#/#docs-official:matrix.org" rel="nofollow">Matrix</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<p dir="auto">Want to know where the project is headed? <a href="https://github.com/orgs/numerique-gouv/projects/13/views/11">🗺️ Checkout our roadmap</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Licence 📝</h2><a id="user-content-licence-" aria-label="Permalink: Licence 📝" href="#licence-"></a></p>
<p dir="auto">This work is released under the MIT License (see <a href="https://github.com/suitenumerique/docs/blob/main/LICENSE">LICENSE</a>).</p>
<p dir="auto">While Docs is a public driven initiative our licence choice is an invitation for private sector actors to use, sell and contribute to the project.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing 🙌</h2><a id="user-content-contributing-" aria-label="Permalink: Contributing 🙌" href="#contributing-"></a></p>
<p dir="auto">This project is intended to be community-driven, so please, do not hesitate to <a href="https://matrix.to/#/#docs-official:matrix.org" rel="nofollow">get in touch</a> if you have any question related to our implementation or design decisions.</p>
<p dir="auto">You can help us with translations on <a href="https://crowdin.com/project/lasuite-docs" rel="nofollow">Crowdin</a>.</p>
<p dir="auto">If you intend to make pull requests see <a href="https://github.com/suitenumerique/docs/blob/main/CONTRIBUTING.md">CONTRIBUTING</a> for guidelines.</p>
<p dir="auto">Directory structure:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docs
├── bin - executable scripts or binaries that are used for various tasks, such as setup scripts, utility scripts, or custom commands.
├── crowdin - for crowdin translations, a tool or service that helps manage translations for the project.
├── docker - Dockerfiles and related configuration files used to build Docker images for the project. These images can be used for development, testing, or production environments.
├── docs - documentation for the project, including user guides, API documentation, and other helpful resources.
├── env.d/development - environment-specific configuration files for the development environment. These files might include environment variables, configuration settings, or other setup files needed for development.
├── gitlint - configuration files for `gitlint`, a tool that enforces commit message guidelines to ensure consistency and quality in commit messages.
├── playground - experimental or temporary code, where developers can test new features or ideas without affecting the main codebase.
└── src - main source code directory, containing the core application code, libraries, and modules of the project."><pre>docs
├── bin - executable scripts or binaries that are used for various tasks, such as setup scripts, utility scripts, or custom commands.
├── crowdin - for crowdin translations, a tool or service that helps manage translations for the project.
├── docker - Dockerfiles and related configuration files used to build Docker images for the project. These images can be used for development, testing, or production environments.
├── docs - documentation for the project, including user guides, API documentation, and other helpful resources.
├── env.d/development - environment-specific configuration files for the development environment. These files might include environment variables, configuration settings, or other setup files needed for development.
├── gitlint - configuration files for <span>`</span><span>gitlint</span><span>`</span>, a tool that enforces commit message guidelines to ensure consistency and quality in commit messages.
├── playground - experimental or temporary code, where developers can test new features or ideas without affecting the main codebase.
└── src - main source code directory, containing the core application code, libraries, and modules of the project.</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits ❤️</h2><a id="user-content-credits-️" aria-label="Permalink: Credits ❤️" href="#credits-️"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Stack</h3><a id="user-content-stack" aria-label="Permalink: Stack" href="#stack"></a></p>
<p dir="auto">Docs is built on top of <a href="https://www.django-rest-framework.org/" rel="nofollow">Django Rest Framework</a>, <a href="https://nextjs.org/" rel="nofollow">Next.js</a>, <a href="https://www.blocknotejs.org/" rel="nofollow">BlockNote.js</a>, <a href="https://tiptap.dev/docs/hocuspocus/introduction" rel="nofollow">HocusPocus</a> and <a href="https://yjs.dev/" rel="nofollow">Yjs</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Gov ❤️ open source</h3><a id="user-content-gov-️-open-source" aria-label="Permalink: Gov ❤️ open source" href="#gov-️-open-source"></a></p>
<p dir="auto">Docs is the result of a joint effort led by the French 🇫🇷🥖 (<a href="https://www.numerique.gouv.fr/dinum/" rel="nofollow">DINUM</a>) and German 🇩🇪🥨 governments (<a href="https://zendis.de/" rel="nofollow">ZenDiS</a>).</p>
<p dir="auto">We are proud sponsors of <a href="https://www.blocknotejs.org/" rel="nofollow">BlockNotejs</a> and <a href="https://yjs.dev/" rel="nofollow">Yjs</a>.</p>
<p dir="auto">We are always looking for new public partners (we are currently onboarding the Netherlands 🇳🇱🧀), feel free to <a href="mailto:docs@numerique.gouv.fr">reach out</a> if you are interested in using or contributing to Docs.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/suitenumerique/docs/blob/main/docs/assets/europe_opensource.png"><img src="https://github.com/suitenumerique/docs/raw/main/docs/assets/europe_opensource.png" width="50%"></a>
</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT 4.5 level for 1% of the price (281 pts)]]></title>
            <link>https://twitter.com/Baidu_Inc/status/1901089355890036897</link>
            <guid>43377962</guid>
            <pubDate>Sun, 16 Mar 2025 10:23:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Baidu_Inc/status/1901089355890036897">https://twitter.com/Baidu_Inc/status/1901089355890036897</a>, See on <a href="https://news.ycombinator.com/item?id=43377962">Hacker News</a></p>
Couldn't get https://twitter.com/Baidu_Inc/status/1901089355890036897: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Lynx is the oldest web browser still being maintained (211 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=43377829</link>
            <guid>43377829</guid>
            <pubDate>Sun, 16 Mar 2025 09:37:59 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=43377829">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=43377829: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: My high school team’s space probe (132 pts)]]></title>
            <link>https://drive.google.com/file/d/1_9V6lBTIfDsPdKCohQBc5Ed5UzDbnsrI/view?usp=sharing</link>
            <guid>43377690</guid>
            <pubDate>Sun, 16 Mar 2025 08:48:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://drive.google.com/file/d/1_9V6lBTIfDsPdKCohQBc5Ed5UzDbnsrI/view?usp=sharing">https://drive.google.com/file/d/1_9V6lBTIfDsPdKCohQBc5Ed5UzDbnsrI/view?usp=sharing</a>, See on <a href="https://news.ycombinator.com/item?id=43377690">Hacker News</a></p>
Couldn't get https://drive.google.com/file/d/1_9V6lBTIfDsPdKCohQBc5Ed5UzDbnsrI/view?usp=sharing: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Generate impressive-looking terminal output, look busy when stakeholders walk by (409 pts)]]></title>
            <link>https://github.com/giacomo-b/rust-stakeholder</link>
            <guid>43376824</guid>
            <pubDate>Sun, 16 Mar 2025 03:45:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/giacomo-b/rust-stakeholder">https://github.com/giacomo-b/rust-stakeholder</a>, See on <a href="https://news.ycombinator.com/item?id=43376824">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">rust-stakeholder</h2><a id="user-content-rust-stakeholder" aria-label="Permalink: rust-stakeholder" href="#rust-stakeholder"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/928b7efc3d1b0e9e30663663cfacfb717a77c7c0df15609127fd24ffeaa6290f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6361726565722d73617665642d73756363657373"><img src="https://camo.githubusercontent.com/928b7efc3d1b0e9e30663663cfacfb717a77c7c0df15609127fd24ffeaa6290f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6361726565722d73617665642d73756363657373" alt="Career Status" data-canonical-src="https://img.shields.io/badge/career-saved-success"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/f9a73e8084b12756c8e993885fb4ff3e247543ae2e838cb3228c375dc86aabb7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7374616b65686f6c646572732d696d707265737365642d79656c6c6f77"><img src="https://camo.githubusercontent.com/f9a73e8084b12756c8e993885fb4ff3e247543ae2e838cb3228c375dc86aabb7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7374616b65686f6c646572732d696d707265737365642d79656c6c6f77" alt="Stakeholders" data-canonical-src="https://img.shields.io/badge/stakeholders-impressed-yellow"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/giacomo-b/rust-stakeholder/blob/master/assets/demo.gif"><img src="https://github.com/giacomo-b/rust-stakeholder/raw/master/assets/demo.gif" alt="til" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Become an irreplaceable 10x developer in 30 seconds flat</h2><a id="user-content-become-an-irreplaceable-10x-developer-in-30-seconds-flat" aria-label="Permalink: Become an irreplaceable 10x developer in 30 seconds flat" href="#become-an-irreplaceable-10x-developer-in-30-seconds-flat"></a></p>
<p dir="auto">Why learn actual skills when you can just <em>look</em> impressive instead?</p>
<p dir="auto">Introducing <strong>rust-stakeholder</strong> - a CLI tool that generates absolutely meaningless but impressive-looking terminal output to convince everyone you're a coding genius without writing a single line of useful code.</p>
<blockquote>
<p dir="auto">"After using rust-stakeholder, my boss stopped asking about my deadlines and started asking for my insights during board meetings." - Developer who still hasn't completed their tickets from last sprint</p>
</blockquote>
<p dir="auto">Remember, it's not about your actual contribution to the codebase, it's about how complicated your terminal looks when the VP of Engineering walks by. Nothing says "I'm vital to this company" like 15 progress bars, cryptic error messages you seem unfazed by, and technical jargon nobody understands.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features that add zero value but look incredibly important</h2><a id="user-content-features-that-add-zero-value-but-look-incredibly-important" aria-label="Permalink: Features that add zero value but look incredibly important" href="#features-that-add-zero-value-but-look-incredibly-important"></a></p>
<ul dir="auto">
<li>🖥️ <strong>Dazzling Development Simulations</strong>: Make it look like you're solving CERN-level computing problems when you're actually just refreshing Reddit</li>
<li>🧠 <strong>Meaningless Jargon Generator</strong>: Impress with phrases like "Implemented non-euclidean topology optimization for multi-dimensional data representation" (no, it doesn't mean anything)</li>
<li>📊 <strong>Convincing Progress Bars</strong>: Nothing says "I'm working" like a progress bar slowly advancing while you're in the break room</li>
<li>🌐 <strong>Fake Network Activity</strong>: Simulate mission-critical API requests that are actually just your computer talking to itself</li>
<li>🚨 <strong>Artificial Crisis Mode</strong>: Generate realistic-looking alerts so people think you're heroically averting disasters</li>
<li>👥 <strong>Imaginary Team Activity</strong>: Pretend your invisible friends are sending you important pull requests</li>
<li>🎮 <strong>Domain Chameleon</strong>: Switch between backend, frontend, blockchain and 7 other domains faster than you can say "full-stack developer"</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div data-snippet-clipboard-copy-content="cargo install --git https://github.com/giacomo-b/rust-stakeholder.git"><pre><code>cargo install --git https://github.com/giacomo-b/rust-stakeholder.git
</code></pre></div>
<p dir="auto">Or build from source (warning: might involve actual programming):</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/giacomo-b/rust-stakeholder.git
cd rust-stakeholder
cargo build --release # Look at you doing real developer things!"><pre><code>git clone https://github.com/giacomo-b/rust-stakeholder.git
cd rust-stakeholder
cargo build --release # Look at you doing real developer things!
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docker</h2><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<p dir="auto">Build image</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker build -t rust-stakeholder ."><pre>docker build -t rust-stakeholder <span>.</span></pre></div>
<p dir="auto">Usage</p>
<p dir="auto">Basic usage:</p>
<div data-snippet-clipboard-copy-content="docker run -t --rm rust-stakeholder"><pre><code>docker run -t --rm rust-stakeholder
</code></pre></div>
<p dir="auto">All commands below can be used through:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run -t --rm rust-stakeholder [arguments]"><pre>docker run -t --rm rust-stakeholder [arguments]</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage for career advancement</h2><a id="user-content-usage-for-career-advancement" aria-label="Permalink: Usage for career advancement" href="#usage-for-career-advancement"></a></p>
<p dir="auto">Basic usage (for entry-level imposters):</p>

<p dir="auto">Advanced usage (for senior imposters):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Impress the blockchain VC investors
rust-stakeholder --dev-type blockchain --jargon extreme --alerts

# Look busy during performance review season
rust-stakeholder --complexity extreme --team --duration 1800

# Convince everyone you're a 10x game developer
rust-stakeholder --dev-type game-development --framework &quot;Custom Engine&quot; --jargon high

# For the data science frauds
rust-stakeholder --dev-type data-science --jargon extreme --project &quot;Neural-Quantum-Blockchain-AI&quot;

# Emergency mode: Your project is due tomorrow and you haven't started
rust-stakeholder --dev-type fullstack --complexity extreme --alerts --team"><pre><span><span>#</span> Impress the blockchain VC investors</span>
rust-stakeholder --dev-type blockchain --jargon extreme --alerts

<span><span>#</span> Look busy during performance review season</span>
rust-stakeholder --complexity extreme --team --duration 1800

<span><span>#</span> Convince everyone you're a 10x game developer</span>
rust-stakeholder --dev-type game-development --framework <span><span>"</span>Custom Engine<span>"</span></span> --jargon high

<span><span>#</span> For the data science frauds</span>
rust-stakeholder --dev-type data-science --jargon extreme --project <span><span>"</span>Neural-Quantum-Blockchain-AI<span>"</span></span>

<span><span>#</span> Emergency mode: Your project is due tomorrow and you haven't started</span>
rust-stakeholder --dev-type fullstack --complexity extreme --alerts --team</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Career benefits</h2><a id="user-content-career-benefits" aria-label="Permalink: Career benefits" href="#career-benefits"></a></p>
<ul dir="auto">
<li><strong>Promotion Fast-Track</strong>: Skip the tedious "delivering value" step entirely</li>
<li><strong>Meeting Domination</strong>: Let it run in the background during Zoom calls to seem busy</li>
<li><strong>Deadline Extensions</strong>: "Sorry, still resolving those critical system alerts"</li>
<li><strong>Salary Negotiation Tool</strong>: Just leave it running during your performance review</li>
<li><strong>Job Security</strong>: Become the only person who seems to understand your fictional systems</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Testimonials</h2><a id="user-content-testimonials" aria-label="Permalink: Testimonials" href="#testimonials"></a></p>
<blockquote>
<p dir="auto">"I left rust-stakeholder running over the weekend. When I came back on Monday, I had been promoted to Principal Engineer." - Anonymous</p>
</blockquote>
<blockquote>
<p dir="auto">"My manager doesn't know what I do, and thanks to rust-stakeholder, neither do I." - Satisfied User</p>
</blockquote>
<blockquote>
<p dir="auto">"Since installing rust-stakeholder, my colleagues have stopped asking me for help because my work 'looks too advanced'." - Senior Imposter Engineer</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tests? What tests?</h2><a id="user-content-tests-what-tests" aria-label="Permalink: Tests? What tests?" href="#tests-what-tests"></a></p>
<p dir="auto">Currently, this package has the same amount of test coverage as your excuses for missing deadlines - absolutely none.</p>
<p dir="auto">Much like your actual development skills while using this tool, tests are purely theoretical at this point. But, if you're feeling particularly productive between fake terminal sessions, consider adding some!</p>
<p dir="auto">After all, nothing says "I'm a serious developer with impostor syndrome" like meticulously testing a package designed to help you fake being a developer. It's beautifully recursive.</p>
<p dir="auto">Remember: Red, Green, Refactor...</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributing? That would involve actual coding. But if you insist:</p>
<ol dir="auto">
<li>Fork the repo (whatever that means)</li>
<li>Add more useless but impressive-looking output</li>
<li>Submit a PR and pretend you understand the codebase</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Disclaimer</h2><a id="user-content-disclaimer" aria-label="Permalink: Disclaimer" href="#disclaimer"></a></p>
<p dir="auto">rust-stakeholder is satire. If your entire technical reputation is built on running a fake terminal program, I am not responsible for the inevitable moment when someone asks you to actually, you know, code something.</p>
<p dir="auto">I am also not responsible if you accidentally impress your way into a position you're completely unqualified for. Though if that happens, congratulations on your new career in management.</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>