<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 23 May 2025 06:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The Copilot Delusion (201 pts)]]></title>
            <link>https://deplet.ing/the-copilot-delusion/</link>
            <guid>44068525</guid>
            <pubDate>Fri, 23 May 2025 00:15:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deplet.ing/the-copilot-delusion/">https://deplet.ing/the-copilot-delusion/</a>, See on <a href="https://news.ycombinator.com/item?id=44068525">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        
<h3 id="chapter-1-my-coworker-the-programmer">Chapter 1: My Coworker, The Programmer</h3>
<p>A shell of a man—more of a parrot than a person. My boss, a true believer in the sacred rite of Pair Programming, chained myself and this "programmer"-colleague together like conjoined twins from different planets. We shared a keyboard, but not a brain. Lord, not even close.</p>
<p>"Hold up. I’ve got an idea. Gimme the keyboard real quick."</p>
<p>An idea. Yes. The same way a toddler has “an idea” to stick a fork in a wall socket. I was halfway through constructing something beautiful—a lean, elegant piece of logic that sliced through complexity like a blade through butter—and here he comes, pounding the keyboard like it owes him money, pasting in code he <em>Frankensteined</em> from a stack overflow comment written by an Uncle Bob disciple in 2014.</p>
<p>Did he know what our system did? No.<br>Did he read the ticket? <em>Absolutely fucking not</em>.<br>Did he feel confident mutating global state with reckless abandon? <em>He absolutely fucking did</em>.</p>
<hr>
<p>I’m doing some refactoring. Tightening the bolts, cleaning up component trees, re-aligning the chakras of the system.</p>
<p>Suddenly:<br>"Hey, I added a <code>useEffect</code> that refetches everything when <em>anything</em> changes. Cool, right?"</p>
<p>"Why?" I ask, blinking like a hostage on a tape sent home from a military operation gone wrong.</p>
<p>"It fixed the thing," he says. "Where the thing wasn’t working. It's a working thing now."</p>
<p>A chaos monkey disguised as a teammate. No tests. No profiling. No understanding of side effects or performance impact. Just blind clicking and tapping and typing. The programming equivalent of punching your TV to make the static stop.</p>
<p>And he did this with <em>everyone</em>. A one-man bug factory. Whispering half-formed solutions into the ears of juniors like a sick, twisted full-stack Rasputin. Apparently, friendly fire will be tolerated.</p>
<hr>
<p>The system explodes. Nothing deploys. The UI is frozen like the vegetables in my freezer I was supposed to defrost 8 years ago. And where is my dear co-pilot?</p>
<p>Nowhere.</p>
<p>He’s vanished—probably reading about a shiny new JS framework he’ll try to shove down my throat next week. Meanwhile, I’m left spelunking through callback hell with a flashlight made of regret.</p>
<p>My boss corners me.<br>"Why aren’t you pairing more with him? He types <em>twice</em> as fast as you."</p>
<p>Of course he does. So does a cat having a seizure on a mechanical keyboard. But that doesn’t mean it should be writing production code.</p>
<hr>
<p>I kept pushing myself—learning infrastructure, refining my mental models, sweating over trade-offs. And him? He googled. He skimmed. He pasted. Occasionally he’d show off a clever trick—half-correct, contextless—and the team would ooh and aah like cavemen discovering fire.</p>
<p>And I got lazy. Of course I did. When the system forces you to code with a hallucinating clown, eventually you stop resisting. You let him type. You let him be "productive." You check out. You surrender your brain to the noise and just float.</p>
<hr>
<p><strong>Captain Obvious is here to Save the Day.</strong><br>I wasn’t talking about a programmer. I was describing GitHub Copilot. Or Claude Codex. Or OpenAI lmnop6.5 ultra watermelon.</p>
<p>This isn’t about tools or productivity or acceleration. It’s about the <em>illusion</em> of progress. Because if that programmer—if that <em>thing, that CREATURE</em>—walked into your stand-up in human form, typing half-correct garbage into your codebase while ignoring your architecture and disappearing during cleanup, you’d fire them before they could say "no blockers".</p>
<p>But slap Microsoft's marketing label on it and plug it into the IDE of every developer in the org? Now <em>that’s innovation. Science. Progress. Profit.</em></p>
<p>A real copilot, on a commercial airline? They know the plane. The systems. They’ve done the simulations. They go through recertification. When they speak, it’s to <em>enhance</em> the pilot—not to shotgun random advice into the cockpit and eject themselves mid-flight.</p>
<p>Copilot isn’t that. It’s just the ghost of a thousand blog posts and cocky stack-overflow posts whispering, "<em>Hey, I saw this once. With my eyes. Which means it's good code. Let’s deploy it."</em> Then vanishing when the app hits production and the landing gear won’t come down.</p>
<p>If you let that ghost fly the plane, you deserve the ball of flames you go up in.</p>

<h3 id="chapter-2-the-props">Chapter 2: The Props</h3>
<p>Let’s get one thing straight before I resume torching this synthoid hellspawn with the fury of the sun: <strong>it ain’t all bad</strong>.</p>
<p>Even the grifter at the poker table with a booze lobotomy occasionally hits a flush. And Copilot? Well, sometimes it knows a thing or two.</p>
<p>You’re young. You’ve never touched C++. You’re staring at the syntax like it’s some Martian cave painting. You ask the oracle for help and boom—there it is. Templates, smart pointers, range-based for-loops—syntactically pristine, like it slithered straight out of Bjarne’s brain and onto your screen.</p>
<p>Of course, it doesn’t know the edge cases. It won’t whisper, "Hey—<code>shared_ptr</code> might leak if you get clever and toss raw pointers into the mix like a maniac." It doesn’t point you to the holy scrolls where veterans debate exception guarantees like theologians dissecting scripture. But if you already know what you want and just need the incantation, it’s a better, quicker scribe than most human interns—and it doesn’t complain when you ask it to write template metaprogramming code at 3 a.m.</p>
<hr>
<p>Now let’s say you’re doing <em>real programming work</em>—system design. Big-boy decisions. Infrastructure. The kind of thing that requires a spine and an encyclopedic knowledge of the ByteByteGo YouTube channel. You lay out your plan like a general before a war: here’s the ingress, here’s the queue, here’s the cache invalidation policy that might just kill us all.</p>
<p>Then you ask Copilot, "Hey, what’s going to break?"</p>
<p>Suddenly, it’s rattling off weaknesses like a security auditor. Maybe half of them are dumb. Maybe some are duplicated. But it dumped the brainstorm faster than your junior ever could, and now you’ve got the ammo to write a spec that makes you look like you crank your hog with Martin Kleppmann himself.</p>
<hr>
<p>Sometimes you’re just tired. Not mentally dead, but running low—your brain’s in "turning-object-into-a-string" mode. You don’t <em>need</em> help. You just don’t want to rotate the matrix in your skull like you’re solving a Rubik’s Cube made of jelly.</p>
<p>So you say, "Hey, I’ve got this C# object and I want a LINQ query that groups it by field X, sums Y, and filters Z."</p>
<p>Copilot answers like a weird little gremlin slave creature with a clipboard: <em>"Done, boss."</em></p>
<p>You don’t trust it. You check it line by line. But still—you didn’t have to juggle twenty method chains in your head, and that buys you time to think about actual problems.</p>
<hr>
<p>Maybe you’re reading some dense mathematical whitepaper, the kind written by deranged mathematicians with PhDs and no regard for human sanity. You don’t have the energy to transmute this LaTeX-laden elder scroll into code. Copilot takes a swing and gives you a half-baked pseudocode scaffold. Garbage? Maybe. But garbage you can build on. You handle the performance tuning, the SIMD, the low-level grit. It just gave you the scaffolding to stack explosives on.</p>
<hr>
<p>Maybe you inherited someone else’s codebase. A minefield of nested closures, half-commented hacks, and variable names like <code>d</code> and <code>foo</code>. A mess of complex OOPisms, where you have to traverse 18 files just to follow a single behaviour. You don’t have all day. You need a flyover—an aerial view of the warzone before you land and start disarming traps.</p>
<p>Ask Copilot: "<em>What’s this code doing?"</em><br>It won’t be poetry. It won’t necessarily provide a full picture. But it’ll be <em>close enough</em> to orient yourself before diving into the guts.</p>
<hr>
<p>So—props where props are due<strong>.</strong> Copilot is like a greasy, high-functioning but practically poor intern:</p>
<ul><li>Great with syntax memory.</li><li>Surprisingly quick at listing out your blind spots.</li><li>Good at building scaffolding if you feed it the exact right words.</li><li>Horrible at nuance.</li><li>Useless without supervision.</li><li>Will absolutely kill you in production if left alone for 30 seconds.</li></ul>
<p>Now, let’s go back to setting it on fire.</p>

<h3 id="chapter-3-you-as-a-programmer">Chapter 3: You as a Programmer</h3>
<div><p>First things first: I like to code. Not supervise. Not hover over a synthetic lobotomized chatbot like some drooling silicon intern trying to remember what <code>std::move</code> actually <em>does</em>. I don’t want to be the meatbag middle-manager reviewing some neural net’s fever dream of a <code>switch</code> statement. I want to build shit. Real shit. Weird shit. Systems that are *on fire* type shit.</p><p>"But I just use AI for boilerplate!" you whimper, clutching your Co-Pilot subscription. Listen to yourself. If you’re writing the same boilerplate every day like some industrial-age cog monkey, automate it <em>yourself</em>. Write a library. Invent a macro. Reclaim some dignity. If AI’s doing your "boring parts", what exactly is <em>left</em> for you to do? Fidget with sliders? Paint by numbers while the inference works it's magic?</p></div>
<p>And let’s not ignore the FOMO goblins. I see you. Pounding Monster energy at 2 A.M., telling yourself you’re "building the future" while you slap together some Frankenstein CRUD app with a bot spoon-feeding you syntax it scraped from 2016 GitHub. It's buggy. It's ugly. You didn't even give it a once over before you posted that video to Twitter. "I’m just moving fast!" you say. Yeah—straight off a cliff, like a lemming. AI isn’t helping you build something novel. It can’t. It only knows what’s been done before. It’s autocomplete with a superiority complex.</p>
<p>You want real connection to code? You <em>earn</em> that. You dig in. You wrestle with segfaults at 3 in the morning. You pace your apartment muttering about pointer arithmetic. You burn through Handmade Hero until you <em>get it</em>. You write your own damn notes instead of snapping lecture slides and pretending it counts. When you outsource the thinking, you outsource the learning. You become a conduit for a mechanical bird regurgitating it's hunt directly into your baby-bird mouth. You don’t <em>know</em> your code. You’re babysitting it.</p>
<p>Let’s talk about the quality of your code, too—because it ain’t getting better. Most engineers already write bloated, abstracted, glacial code that burns CPU cycles like a California wildfire. Clean code? Ha! You’re writing for <em>other programmers’</em> academic circlejerk, not the hardware. You’ve forgotten that the machine matters. AI has no concept of memory locality. No intuition for cache misses. It won’t unroll a loop or spot the false sharing in your atomic struct. It’s trained on code that’s already an insult to silicon.</p>
<p>The problem isn’t just laziness. It’s <em>degradation</em>. Engineers stop exploring. Stop improving. Stop <em>caring</em>. One more layer of abstraction. One more lazy fetch call inside a render loop. Eventually, you’re living in a cathedral of technical debt, and every user pays—milliseconds at a time, each click a tax on your apathy.</p>
<p>And the "copilot" branding. A real copilot? That’s a peer. That’s a certified operator who can fly the bird if you pass out from bad taco bell. They train. They practice. They review checklists <em>with you</em>. GitHub Copilot is more like some guy who played Arma 3 for 200 hours and thinks he can land a 747. He read the manual once. In Mandarin. Backwards. And now he’s shouting over your shoulder, "Let me code that bit real quick, I saw it in a Slashdot comment!"</p>
<p>At that point, you’re not working with a copilot. You’re playing Russian roulette with a loaded dependency graph.</p>
<p>You want to be a real programmer? Use your head. Respect the machine. Or get out of the cockpit.</p>
<h3 id="chapter-4-the-computer-as-a-machine"><br>Chapter 4: The Computer as a Machine</h3>

<p>Listen. You’re human. Soft flesh, rotting teeth, synapses pissing electrical signals at each other motivated by caffeine and spite. But <em>you</em>—at your most frazzled, sleep-deprived, raccoon-eyed best—you can <em>try</em>. You can squint at the layers of abstraction and <em>see through them</em>. Peel back the nice ergonomic type-safe, pure, lazy, immutable syntactic sugar and imagine the mess of assembly the compiler pukes up. You can <em>feel</em> the cache lines like a sixth sense. You know where the data wants to be. And where the silicon gets angry when you screw that up.</p>
<p>The machine is real. The silicon is real. The DRAM, the L1, the false sharing, the branch predictor flipping a coin—it’s all real. And if you care, you <em>can</em> work with it. You can make your programs slither through memory like a steel serpent with little to no overhead. You can tee up prefetches with finesse. You can hand-roll an allocation strategy that makes malloc look like child's play. You can know—actually <em>know</em>—when it’s time to crack your knuckles and write a few lines of filthy, yet beautiful inline assembly to directly inject steroids into your program's shiny cheeks.</p>
<p>But the bot? The <em>bot</em>? The bot has no clue.</p>
<p>The bot has <em>zero</em> understanding. It can’t tell a page fault from a paper cut. It’ll hallucinate a memory model like I hallucinate after 2 days of no sleep. It can’t profile. It can’t understand a flamegraph. It can’t feel the cold burn of wasted CPU cycles on a hot loop. It’ll copy the advice of a sweaty stranger from an ‘08 StackOverflow thread who was benchmarking on a Pentium 4 with 512MB of RAM and a dream. It will say, "This is optimal", like it knows anything. Like it’s <em>seen</em> a cache miss. It hasn’t. You have.</p>
<p>The thing will feed you trash. It’ll feed you fake wisdom from fake people and beg you to trust it. But if you want to make a fast, beautiful system—if you want to sculpt the kind of software that gets embedded in pacemakers and missile guidance systems and M1 tanks—you better throw that bot out the airlock and <em>learn</em>.</p>
<p>You build taste by <em>doing</em>. By hurting. By shaving nanoseconds with surgical tools. By writing a routine on Monday, rewriting it Tuesday, and realizing Wednesday it still sucks. You don’t build taste by asking the MS Clippy of 2025 how to do your job.</p>
<p>We are, in the long arc of computing history, still covered in dirt, yanking our bits around with ploughs. We ride <em>horses</em>. But some of us—the ones with blown-out eyeballs and scorched keyboards—some of us know how to build the next thing. Trains. Speedboats. Hypersonic jets of pure code.</p>
<p>And the ones who keep using AI like it’s a divine oracle? They’ll be out there trying to duct-tape horses to an engine block, wondering why it doesn’t fly. Saying, "Hey. It's still not flying. ... ... ... Still not flying. ... ... ... Still doesn't fly fix it please.".</p>
<h3 id="chapter-5-conclusion"><br>Chapter 5: Conclusion</h3>
<p><br>The thing I hate the most about AI and it's ease of access; the slow, painful death of the hacker soul—brought not by war or scarcity, but by convenience. By <em>buttons</em>. By bots.</p>
<p>The real horror isn’t that AI will take our jobs—it’s that it will <em>let</em> people in who never wanted the job to begin with. Vampires with SaaS dreams and Web3 in their LinkedIn bio. Empty husks who see the terminal not as a frontier, but as a shovel for digging up VC money. They’ll drool over their GitHub Copilot like it’s the holy spirit of productivity, pumping out React CRUD like it’s oxygen. They'll fork VS Code yet again, just to sell the same dream to a similarly deluded kid.</p>
<p>There was once magic here. There was once <em>madness</em>.</p>
<p>Kids would stay up all night on IRC with bloodshot eyes, trying to render a cube in OpenGL without segfaulting their future. They <em>cared</em>. They would install Gentoo on a toaster just to see if it’d boot. They knew the smell of burnt voltage regulators and the <em>exact</em> line of assembly where Doom hit 10 FPS on their calculator. These were *artists*. They wrote code like jazz musicians—full of rage, precision, and divine chaos.</p>
<p>Now? We’re building a world where that curiosity gets lobotomized at the door. Some poor bastard—born to be great—is going to get told to "review this AI-generated patchset" for eight hours a day, until all that wonder calcifies into apathy. The terminal will become a spreadsheet. The debugger a coffin.</p>
<p>Because <em>you don’t know what you don’t know</em>. That’s the cruel joke. We’ll fill this industry with people who <em>think</em> they’re good, because their bot passed CI. They'll float through, confident, while the real ones—the hungry ones—get chewed up by a system that doesn’t value understanding anymore. Just output. Just tokens per second.</p>
<p>And what’s worse, we’ll normalize this mediocrity. Cement it in tooling. Turn it into a best practice. We'll enshrine this current bloated, sluggish, over-abstracted hellscape as the <em>pinnacle</em> of software—and the idea of squeezing every last drop of performance out of a system, or building something lean and wild and precise, will sound like <em>folklore</em>.</p>
<p>If that happens? If the last real programmers are drowned in a sea of button-clicking career-chasers—then I pity the smart outsider kids to come after me.</p>
<p>Defer your thinking to the bot, and we all rot.</p>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Future of Flatpak (199 pts)]]></title>
            <link>https://lwn.net/Articles/1020571/</link>
            <guid>44068400</guid>
            <pubDate>Thu, 22 May 2025 23:51:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/1020571/">https://lwn.net/Articles/1020571/</a>, See on <a href="https://news.ycombinator.com/item?id=44068400">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<b>We're bad at marketing</b>
<p>
We can admit it, marketing is not our strong suit. Our strength is
writing the kind of articles that developers, administrators, and
free-software supporters depend on to know what is going on in the
Linux world. Please <a href="https://lwn.net/Promo/nsn-bad/subscribe">subscribe today</a> to help us keep doing that, and so
we don’t have to get good at marketing.
</p></blockquote>

<p>At the <a href="https://linuxappsummit.org/">Linux Application
Summit</a> (LAS) in April, Sebastian Wick said that, by many metrics, <a href="https://flatpak.org/">Flatpak</a> is doing great. The Flatpak
application-packaging format is popular with upstream developers, and
with many users. More and more applications are being published in the
<a href="https://flathub.org/">Flathub</a> application store, and the
format is even being adopted by Linux distributions like
Fedora. However, he worried that work on the Flatpak project itself
had stagnated, and that there were too few developers able to review
and merge code beyond basic maintenance.</p>

<p>I was not able to attend LAS in person or watch it live-streamed,
so I watched the YouTube <a href="https://www.youtube.com/watch?v=3HkYJ7M119I">video</a> of the
talk. The slides are available from the <a href="https://conf.linuxappsummit.org/event/7/contributions/219/">talk
page</a>. Wick is a member of the GNOME Project and a Red Hat employee
who works on "<q>all kinds of desktop plumbing</q>", including Flatpak
and <a href="https://flatpak.github.io/xdg-desktop-portal/">desktop
portals</a>.</p>

<h4>Flatpak basics</h4>

<p>Flatpak was <a href="https://github.com/flatpak/flatpak/wiki/Flatpak%27s-History">originally
developed</a> by Alexander Larsson, who had been working on similar
projects stretching back to 2007. The <a href="https://help.gnome.org/misc/release-notes/3.18/developers.html.en#:~:text=Sandboxed%20Applications">first
release</a> was as XDG-App in 2015. It was renamed to Flatpak in 2016,
a nod to IKEA's "<a href="https://www.ikea.com/ph/en/this-is-ikea/about-us/the-story-of-ikea-flatpacks-puba710ccb0/">flatpacks</a>"
for delivering furniture.</p>

<p>The Flatpak project provides <a href="https://docs.flatpak.org/en/latest/flatpak-command-reference.html#flatpak">command-line
tools</a> for managing and running Flatpak applications, tools for <a href="https://docs.flatpak.org/en/latest/flatpak-builder-command-reference.html">building
Flatpak bundles</a>, and <a href="https://docs.flatpak.org/en/latest/available-runtimes.html">runtimes</a>
that provide components for Flatpak applications. The project uses <a href="https://lwn.net/Articles/603762/">control groups</a>, <a href="https://lwn.net/Articles/531114/">namespaces</a>,
<a href="https://lwn.net/Articles/281157/">bind mounts</a>, <a href="https://lwn.net/Articles/332974/">seccomp</a>, and <a href="https://github.com/containers/bubblewrap?tab=readme-ov-file#bubblewrap">Bubblewrap</a>
to provide application isolation ("sandboxing"). Flatpak content is 
primarily delivered using <a href="https://ostreedev.github.io/ostree/introduction/">OSTree</a>,
though support for using <a href="https://github.com/opencontainers/distribution-spec/">Open
Container Initiative (OCI) images</a> has been <a href="https://opencontainers.org/posts/blog/2018-11-07-bringing-oci-images-to-the-desktop-with-flatpak/">available</a>
since 2018 and is used by Fedora for its Flatpak applications. The "<a href="https://docs.flatpak.org/en/latest/under-the-hood.html">Under
the Hood</a>" page from Flatpak's documentation provides a good
overview of how the pieces fit together.</p>

<h4>Slowing development</h4>

<p>Wick started his talk by saying that it looks like everything is
great with the Flatpak project, but if one looks deeper, "<q>you will
notice that it's not being actively developed anymore</q>". There are
people who maintain the code base and fix security issues, for
example, but "<q>bigger changes are not really happening
anymore</q>". He said that there are a bunch of merge requests for new
features, but no one feels responsible for reviewing them, and that is
kind of problematic.</p>

<!-- middle-ad -->

<p>The reason for the lack of reviewers is that key people, such as
Larsson, have left the project. Every now and then, Wick said, Larsson
may get involved if it's necessary, but he is basically not part of
the day-to-day development of the project. Wick said that it is hard
to get new Flatpak contributors involved because it can take months to
get feedback on major changes, and then more months to get another
review. "<q>This is really not a great way to get someone up to speed,
and it's not a great situation to be in</q>."</p>

<p>"<q>Maybe I'm complaining about something that is actually not that
much of an issue</q>", he said. Flatpak works; it does its job, and
"<q>we just use it and don't think about it much</q>". In that sense,
the project is in a good spot. But he has still been thinking
about how the project is "<q>living with constraints</q>" because
contributors do not have the opportunity to go in and make bigger
changes.</p>

<p>As an example, Wick said that Red Hat has been doing work that
would allow Flatpaks to be installed as part of a base
installation. The vendor or administrator could specify the
applications to be installed, and a program called
<tt>flatpak-preinstall</tt> would take care of the rest. The feature
has been implemented and is planned for inclusion in Red Hat
Enterprise Linux (RHEL) 10. The work was <a href="https://github.com/flatpak/flatpak/pull/5832">started</a> by
Kalev Lember and Owen Taylor last June, but the original pull request
was <a href="https://github.com/flatpak/flatpak/pull/5832#issuecomment-2630695788">closed</a>
by Lember in February as he was leaving Red Hat and would not be
working on it anymore. It was picked up by Wick in February as a <a href="https://github.com/flatpak/flatpak/pull/6116">new request</a>
but wasn't reviewed until early May.</p>

<h4>OSTree and OCI</h4>

<p>Wick's next topic was OCI support in Flatpak. While OSTree has been
a success in some ways, and it is still being maintained, it is not
undergoing active development. He noted that developers have a
"<q>very narrow set of tools</q>" for working with OSTree, so building
Flatpaks that use OSTree requires non-standard and bespoke tools, but
there is a whole range of utilities available for working with OCI
images. Even better, tools for working with OCI images "<q>are all
developed by people other than us, which means we don't actually have
to do the work if we just embrace them</q>".</p>

<p>Unfortunately, there are a number of OCI-related improvements that,
again, are waiting on review to be merged into Flatpak. For example,
Wick mentioned that the OCI container standard has added <a href="https://github.com/containers/storage/blob/main/docs/containers-storage-zstd-chunked.md"><tt>zstd:chunked</tt></a>
support. Instead of the original OCI image format that uses gzipped
tarballs, the <tt>zstd:chunked</tt> images are compressed with <a href="https://datatracker.ietf.org/doc/html/rfc8478">zstd</a> and have
<a href="https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md#skippable-frames">skippable
frames</a> that include additional metadata—such as a table of
contents—which allows file-level deduplication. In short,
zstd:chunked allows pulling only those files that have changed since
the last update, rather than an entire OCI layer, when updating a
container image or a Flatpak.</p>

<p>There is a <a href="https://github.com/flatpak/flatpak/pull/5540">pull request</a>
from Taylor, submitted in September&nbsp;2023, that would add support
to Flatpak for zstd-compressed layers. It has received little
attention since then and "<q>it's just sitting there,
currently</q>".</p>

<h4>Narrowing permissions</h4>

<p>One of the key functions of Flatpak is to sandbox applications and
limit their access to the system. Wick said that the project has added
features to "<q>narrow down</q>" the sandboxes and provide more
restricted permissions. As an example, Flatpak now has
<tt>--device=input</tt> to allow an application to access input
devices without having access to all devices.</p>

<p>One problem with this, he said, is that a system's installation of
Flatpak may not support the newer features. A user's Linux
distribution may still be providing an older version of Flatpak that
does not have support for <tt>--device=input</tt>, or whatever new
feature that a Flatpak developer may wish to use. Wick said there
needs to be a way for applications to use the new permissions by
default, but fall back to the older permission models if used on a
system with an older version of Flatpak.</p>

<p>This isn't an entirely new situation, he said. "<q>We had this
before with Wayland and X11</q>", where if a system is running
Wayland, then Flatpak should not bind-mount an X11 socket. Now, there is a
similar scenario with the <a href="https://flatpak.github.io/xdg-desktop-portal/docs/doc-org.freedesktop.portal.Usb.html">xdg-desktop portal
for USB access</a>, which was <a href="https://github.com/flatpak/xdg-desktop-portal/pull/559">added</a>
to the xdg-desktop-project in 2021. Support for that portal was <a href="https://github.com/flatpak/flatpak/issues/4405">merged</a> into
Flatpak in 2024 after several iterations. What is missing is the
ability to specify backward-compatible permissions so that a Flatpak
application can be given USB access (<tt>--device=usb</tt>) with newer
versions of Flatpak but retain the <tt>--device=all</tt> permissions
if necessary. Once again, there is a <a href="https://github.com/flatpak/flatpak/issues/5681">pull request</a>
(from Hubert Figuière) that implements this, but Wick said that
"<q>it's also just sitting there</q>".</p>

<p>Wick would also like to improve the way that Flatpak handles access
to audio. Currently, Flatpak still uses <a href="https://www.freedesktop.org/wiki/Software/PulseAudio/">PulseAudio</a>
even if a host system uses <a href="https://pipewire.org/">PipeWire</a>. The problem with that is
that PulseAudio bundles together access to speakers and
microphones—you can have access to both, or neither, but not just one. So
if an application has access to play sound, it also has access to
capture audio, which Wick said, with a bit of understatement, is
"<q>not great</q>". He would like to be able to use PipeWire, which
can expose restricted access to speakers only.</p>

<p>One thing that has been a bit of a pain point, Wick said, is that
nested sandboxing does not work in Flatpak. For instance, an
application cannot use Bubblewrap inside Flatpak. Many applications,
such as web browsers, make heavy use of sandboxing.</p>

<blockquote>
They really like to put their tabs into their own sandboxes because it
turns out that if one of those tabs is running some code that
manages to exploit and break out of the process there, at
least it's contained and doesn't spread to the rest of the
browser.
</blockquote>

<p>What Flatpak does instead, currently, is to have a kind of side
sandbox that applications can call to and spawn another Flatpak
instance that can be restricted even further. "<q>So, in that sense,
that is a solution to the problem, but it is also kind of fragile</q>."
There have been issues with this approach for quite a while, he said,
but no one knows quite how to solve them.</p>

<p>Ideally, Flatpak would simply support nested namespacing and nested
sandboxes, but currently it does not. Flatpak uses seccomp to prevent
applications in a sandbox from having direct access to user
namespaces. There is an API that can be used to create a sub-sandbox,
but it is more restrictive. He said that the restrictions to user
namespaces are outdated: "<q>for a long time it wasn't really a good
idea to expose user namespacing because it exposed a big kernel API to
user space that could be exploited</q>". Wick feels that user
namespaces are, nowadays, a well-tested and a much-used interface. He
does not think that there is much of a good argument against user
namespaces anymore.</p>

<h4>xdg-dbus-proxy</h4>

<p>Flatpak applications do not talk directly to D-Bus. Instead,
<tt>flatpak-run</tt> spawns an <a href="https://man.archlinux.org/man/xdg-dbus-proxy.1.en">xdg-dbus-proxy</a>
for every Flatpak instance that is "<q>not exactly in the same
sandbox, it's just on the side, basically</q>". The proxy is
responsible for setting up filtering according to rules that are
processed when <tt>flatpak-run</tt> is used to start an
application. When setting up the proxy, Flatpak starts with a
<tt>deny-all</tt> state and then adds specific connections that are
allowed. This is so that applications do not expose things that other
applications are not supposed to use.</p>

<p>Wick said that he would like to move filtering from xdg-dbus-proxy
directly to the D-Bus message brokers and provide policy based on a
cgroups path. This is not something that has been implemented
already, but he said he planned to work on a prototype in <a href="https://github.com/dbus2/busd?tab=readme-ov-file#busd">busd</a>,
which is a D-Bus broker implementation in Rust.</p>

<p>That would also allow for a more dynamic policy, which would allow
applications to export services to other applications on the
fly. Currently, the policy is set when a Flatpak is run, and can't be
modified afterward.</p>

<p>As a side note, that means that Flatpak applications cannot
talk to one another over D-Bus. They can still communicate
with other applications; for example, Wick said that applications can
communicate over the host's shared network namespace, "<q>which means
you can use HTTP or whatever, there are like thousands of side
channels you could use if you wanted to</q>".</p>

<p>Flatpak's network namespacing is "<q>kind of ugly, and I don't 
really have a good solution here</q>", Wick said, but he wanted to
point out that it is something the project should take a look
at. "<q>Like, you bind something on localhost and suddenly all
applications can just poke at it</q>". He gave the example of <a href="https://flathub.org/apps/de.bund.ausweisapp.ausweisapp2">AusweisApp</a>,
which is an official authentication app for German IDs 
that can be used to authenticate with government web sites. It
exposes a service on the local host, which makes it available to all
Flatpak applications on the system.</p>

<blockquote>
<p>This is some of the stuff that I feel like we really need to take a
look at. I'm not sure if this is like directly exploitable, but at the
very least it's kind of scary.</p>
</blockquote>

<p>Wick said that the project needs to create a network namespace for
Flatpak applications, "<q>but we don't really have any networking
experts around, which is kind of awkward, we really have to find a
solution here</q>".</p>

<p>Another awkward spot the project finds itself in, he said, is with
NVIDIA drivers. The project has to build multiple versions of NVIDIA
drivers for multiple runtimes that are supported, and that translates
to a great deal of network overhead for users who have to download
each of those versions—even if they don't need all of the
drivers. (<a href="https://forums.linuxmint.com/viewtopic.php?t=399518">This
complaint</a> on the Linux Mint forum illustrates the problem
nicely.) It also means that games packaged as Flatpaks need to be
continually updated against new runtimes, or they will eventually stop
working because their drivers stop being updated and the games will
not support current GPUs.</p>

<p>Wick's suggestion is to take a cue from Valve Software. He said
that Valve uses a model similar to Flatpak to run its games, but it
uses the drivers from the host system and loads all of the driver's
dependencies in the sandbox for the game. Valve uses the <a href="https://gitlab.collabora.com/vivek/libcapsule">libcapsule</a>
library to do this, which is "<q>kind of fragile</q>" and difficult to make
sure that it works well. Instead of using libcapsule, he would like to
statically compile drivers and share them between all Flatpak
applications. This is just in the idea stage at the moment, but
Wick said he would like to solve the driver problem eventually.</p>

<h4>Portals</h4>

<p>Portals are D-Bus interfaces that provide APIs for things like file
access, printing, opening URLs, and more. Flatpak can grant sandboxed
applications access to portals to make D-Bus calls. Wick noted
that portals are not part of the Flatpak project but they are crucial
to it. "<q>Whatever we do with portals just directly improves
Flatpak, and there are a bunch of portal things we need to
improve</q>".</p>

<p>He gave the example of the <a href="https://flatpak.github.io/xdg-desktop-portal/docs/doc-org.freedesktop.portal.Documents.html">Documents</a>
portal, which makes files outside the sandbox available to Flatpak
applications. The Documents portal is great for sharing single files,
but it is too fine-grained and restrictive for other applications,
such as Blender, GIMP, or music applications, that may need to access
an entire library of files. "<q>You want a more coarse-grained
permission model for files at some point</q>". There are some
possibilities, he said, such as bind mounting user-selected host
locations into the sandbox.</p>

<p>Wick had a number of ideas that he would like to see implemented
for portals, such as support for autofilling passwords, Fast Identity
Online (FIDO) security keys, speech synthesis, and more. He
acknowledged that it's "<q>kind of hard to write</q>" code for portals
right now, but there is work to make it easier by using <a href="https://gitlab.gnome.org/GNOME/libdex">libdex</a>. (See
Christian Hergert's <a href="https://blogs.gnome.org/chergert/2025/03/27/fiber-cancellation-in-libdex/">blog
post</a> on libdex for a short look at this.) It might even make sense
to rewrite things in Rust, he said.</p>

<h4>Flatpak-next</h4>

<p>Assume that it's ten years in the future, Wick said, and no one is
working on Flatpak anymore. "<q>What would you do with Flatpak if you
could just rewrite it? I think the vision where we should go is OCI
for almost everything.</q>" Larsson's choices in creating Flatpak
were good and sound technical decisions at the time, but they
ended up being "<q>not the thing that everyone else has</q>". That is
an issue because only a few people understand what Flatpak does, and
the project has to do everything itself.</p>

<p>But, he said, if the project did "<q>everything OCI</q>", it would
get a lot of things for free, such as OCI registries and tooling. Then
it just comes down to what <tt>flatpak-run</tt> has to do, and that
would not be very much. Rethinking Flatpak with modern container tools
and aligning with the wider container ecosystem, he said, would make
everything easier and is worth exploring. Once again, he floated the
idea of using Rust for a rewrite.</p>

<h4>Q&amp;A</h4>

<p>There was a little time for questions at the end of Wick's
session. The first was about what happens to existing Flatpaks if the
project moves to OCI tooling. "<q>Would I need to just throw away
[applications] and download again, or is that too much in the future,
and you haven't thought about that?</q>" Wick said that it would be an
issue on the client side, but Flathub (for example) has all of the
build instructions for its Flatpaks and could simply rebuild them.</p>

<p>Another audience member was concerned about using container
infrastructure. They said that OCI registries that store images are
missing indexing and metadata that is consumed by applications like
GNOME Software for Flatpaks. What would be the way forward to ensure
that they could preserve the same user experience? Wick said that
there is now a standard for storing non-images in OCI registries,
which would allow storing "<q>the same things we're currently
storing</q>" for Flatpak, but writing the code to do it and getting it
merged would be the hard part.</p>

<p>The final question was whether there was anything concrete planned
about using PipeWire directly with Flatpak rather than the PulseAudio
routing. Wick said that he had been talking with Wim Taymans, the
creator of PipeWire, about how to add support for it within
Flatpak. It is mostly about "<q>adding PipeWire policy to do the right
thing when it knows that it is a Flatpak instance</q>", he said.</p>

<br clear="all"><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Archives/ConferenceIndex/">Conference</a></td><td><a href="https://lwn.net/Archives/ConferenceIndex/#Linux_Application_Summit-2025">Linux Application Summit/2025</a></td></tr>
            </tbody></table><br clear="all">
<hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Defuddle, an HTML-to-Markdown alternative to Readability (209 pts)]]></title>
            <link>https://github.com/kepano/defuddle</link>
            <guid>44067409</guid>
            <pubDate>Thu, 22 May 2025 21:40:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/kepano/defuddle">https://github.com/kepano/defuddle</a>, See on <a href="https://news.ycombinator.com/item?id=44067409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><blockquote>
<p dir="auto">de·​fud·dle /diˈfʌdl/ <em>transitive verb</em><br>
to remove unnecessary elements from a web page, and make it easily readable.</p>
</blockquote>
<p dir="auto"><strong>Beware! Defuddle is very much a work in progress!</strong></p>
<p dir="auto">Defuddle extracts the main content from web pages. It cleans up web pages by removing clutter like comments, sidebars, headers, footers, and other non-essential elements, leaving only the primary content.</p>
<p dir="auto"><a href="https://kepano.github.io/defuddle/" rel="nofollow">Try the Defuddle Playground →</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">Defuddle aims to output clean and consistent HTML documents. It was written for <a href="https://github.com/obsidianmd/obsidian-clipper">Obsidian Web Clipper</a> with the goal of creating a more useful input for HTML-to-Markdown converters like <a href="https://github.com/mixmark-io/turndown">Turndown</a>.</p>
<p dir="auto">Defuddle can be used as a replacement for <a href="https://github.com/mozilla/readability">Mozilla Readability</a> with a few differences:</p>
<ul dir="auto">
<li>More forgiving, removes fewer uncertain elements.</li>
<li>Provides a consistent output for footnotes, math, code blocks, etc.</li>
<li>Uses a page's mobile styles to guess at unnecessary elements.</li>
<li>Extracts more metadata from the page, including schema.org data.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>

<p dir="auto">For Node.js usage, you'll also need to install JSDOM:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Browser</h3><a id="user-content-browser" aria-label="Permalink: Browser" href="#browser"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { Defuddle } from 'defuddle';

// Parse the current document
const defuddle = new Defuddle(document);
const result = defuddle.parse();

// Access the content and metadata
console.log(result.content);
console.log(result.title);
console.log(result.author);"><pre><span>import</span> <span>{</span> <span>Defuddle</span> <span>}</span> <span>from</span> <span>'defuddle'</span><span>;</span>

<span>// Parse the current document</span>
<span>const</span> <span>defuddle</span> <span>=</span> <span>new</span> <span>Defuddle</span><span>(</span><span>document</span><span>)</span><span>;</span>
<span>const</span> <span>result</span> <span>=</span> <span>defuddle</span><span>.</span><span>parse</span><span>(</span><span>)</span><span>;</span>

<span>// Access the content and metadata</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>result</span><span>.</span><span>content</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>result</span><span>.</span><span>title</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>result</span><span>.</span><span>author</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Node.js</h3><a id="user-content-nodejs" aria-label="Permalink: Node.js" href="#nodejs"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { JSDOM } from 'jsdom';
import { Defuddle } from 'defuddle/node';

// Parse HTML from a string
const html = '<html><body><article>...</article></body></html>';
const result = await Defuddle(html);

// Parse HTML from a URL
const dom = await JSDOM.fromURL('https://example.com/article');
const result = await Defuddle(dom);

// With options
const result = await Defuddle(dom, {
  debug: true, // Enable debug mode for verbose logging
  markdown: true, // Convert content to markdown
  url: 'https://example.com/article' // Original URL of the page
});

// Access the content and metadata
console.log(result.content);
console.log(result.title);
console.log(result.author);"><pre><span>import</span> <span>{</span> <span>JSDOM</span> <span>}</span> <span>from</span> <span>'jsdom'</span><span>;</span>
<span>import</span> <span>{</span> <span>Defuddle</span> <span>}</span> <span>from</span> <span>'defuddle/node'</span><span>;</span>

<span>// Parse HTML from a string</span>
<span>const</span> <span>html</span> <span>=</span> <span>'&lt;html&gt;&lt;body&gt;&lt;article&gt;...&lt;/article&gt;&lt;/body&gt;&lt;/html&gt;'</span><span>;</span>
<span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>Defuddle</span><span>(</span><span>html</span><span>)</span><span>;</span>

<span>// Parse HTML from a URL</span>
<span>const</span> <span>dom</span> <span>=</span> <span>await</span> <span>JSDOM</span><span>.</span><span>fromURL</span><span>(</span><span>'https://example.com/article'</span><span>)</span><span>;</span>
<span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>Defuddle</span><span>(</span><span>dom</span><span>)</span><span>;</span>

<span>// With options</span>
<span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>Defuddle</span><span>(</span><span>dom</span><span>,</span> <span>{</span>
  <span>debug</span>: <span>true</span><span>,</span> <span>// Enable debug mode for verbose logging</span>
  <span>markdown</span>: <span>true</span><span>,</span> <span>// Convert content to markdown</span>
  <span>url</span>: <span>'https://example.com/article'</span> <span>// Original URL of the page</span>
<span>}</span><span>)</span><span>;</span>

<span>// Access the content and metadata</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>result</span><span>.</span><span>content</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>result</span><span>.</span><span>title</span><span>)</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>result</span><span>.</span><span>author</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><em>Note: for <code>defuddle/node</code> to import properly, the module format in your <code>package.json</code> has to be set to <code>{ "type": "module" }</code></em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Response</h2><a id="user-content-response" aria-label="Permalink: Response" href="#response"></a></p>
<p dir="auto">Defuddle returns an object with the following properties:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>author</code></td>
<td>string</td>
<td>Author of the article</td>
</tr>
<tr>
<td><code>content</code></td>
<td>string</td>
<td>Cleaned up string of the extracted content</td>
</tr>
<tr>
<td><code>description</code></td>
<td>string</td>
<td>Description or summary of the article</td>
</tr>
<tr>
<td><code>domain</code></td>
<td>string</td>
<td>Domain name of the website</td>
</tr>
<tr>
<td><code>favicon</code></td>
<td>string</td>
<td>URL of the website's favicon</td>
</tr>
<tr>
<td><code>image</code></td>
<td>string</td>
<td>URL of the article's main image</td>
</tr>
<tr>
<td><code>metaTags</code></td>
<td>object</td>
<td>Meta tags</td>
</tr>
<tr>
<td><code>parseTime</code></td>
<td>number</td>
<td>Time taken to parse the page in milliseconds</td>
</tr>
<tr>
<td><code>published</code></td>
<td>string</td>
<td>Publication date of the article</td>
</tr>
<tr>
<td><code>site</code></td>
<td>string</td>
<td>Name of the website</td>
</tr>
<tr>
<td><code>schemaOrgData</code></td>
<td>object</td>
<td>Raw schema.org data extracted from the page</td>
</tr>
<tr>
<td><code>title</code></td>
<td>string</td>
<td>Title of the article</td>
</tr>
<tr>
<td><code>wordCount</code></td>
<td>number</td>
<td>Total number of words in the extracted content</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Bundles</h2><a id="user-content-bundles" aria-label="Permalink: Bundles" href="#bundles"></a></p>
<p dir="auto">Defuddle is available in three different bundles:</p>
<ol dir="auto">
<li>Core bundle (<code>defuddle</code>): The main bundle for browser usage. No dependencies.</li>
<li>Full bundle (<code>defuddle/full</code>): Includes additional features for math equation parsing.</li>
<li>Node.js bundle (<code>defuddle/node</code>): Optimized for Node.js environments using JSDOM. Includes full capabilities for math and Markdown conversion.</li>
</ol>
<p dir="auto">The core bundle is recommended for most use cases. It still handles math content, but doesn't include fallbacks for converting between MathML and LaTeX formats. The full bundle adds the ability to create reliable <code>&lt;math&gt;</code> elements using <code>mathml-to-latex</code> and <code>temml</code> libraries.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Options</h2><a id="user-content-options" aria-label="Permalink: Options" href="#options"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Option</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>debug</code></td>
<td>boolean</td>
<td>Enable debug logging</td>
</tr>
<tr>
<td><code>url</code></td>
<td>string</td>
<td>URL of the page being parsed</td>
</tr>
<tr>
<td><code>markdown</code></td>
<td>boolean</td>
<td>Convert <code>content</code> to Markdown</td>
</tr>
<tr>
<td><code>separateMarkdown</code></td>
<td>boolean</td>
<td>Keep <code>content</code> as HTML and return <code>contentMarkdown</code> as Markdown</td>
</tr>
<tr>
<td><code>removeExactSelectors</code></td>
<td>boolean</td>
<td>Whether to remove elements matching exact selectors like ads, social buttons, etc. Defaults to true.</td>
</tr>
<tr>
<td><code>removePartialSelectors</code></td>
<td>boolean</td>
<td>Whether to remove elements matching partial selectors like ads, social buttons, etc. Defaults to true.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Debug mode</h3><a id="user-content-debug-mode" aria-label="Permalink: Debug mode" href="#debug-mode"></a></p>
<p dir="auto">You can enable debug mode by passing an options object when creating a new Defuddle instance:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const article = new Defuddle(document, { debug: true }).parse();"><pre><span>const</span> <span>article</span> <span>=</span> <span>new</span> <span>Defuddle</span><span>(</span><span>document</span><span>,</span> <span>{</span> <span>debug</span>: <span>true</span> <span>}</span><span>)</span><span>.</span><span>parse</span><span>(</span><span>)</span><span>;</span></pre></div>
<ul dir="auto">
<li>More verbose console logging about the parsing process</li>
<li>Preserves HTML class and id attributes that are normally stripped</li>
<li>Retains all data-* attributes</li>
<li>Skips div flattening to preserve document structure</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">HTML standardization</h2><a id="user-content-html-standardization" aria-label="Permalink: HTML standardization" href="#html-standardization"></a></p>
<p dir="auto">Defuddle attempts to standardize HTML elements to provide a consistent input for subsequent manipulation such as conversion to Markdown.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Headings</h3><a id="user-content-headings" aria-label="Permalink: Headings" href="#headings"></a></p>
<ul dir="auto">
<li>The first H1 or H2 heading is removed if it matches the title.</li>
<li>H1s are converted to H2s.</li>
<li>Anchor links in H1 to H6 elements are removed and become plain headings.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Code blocks</h3><a id="user-content-code-blocks" aria-label="Permalink: Code blocks" href="#code-blocks"></a></p>
<p dir="auto">Code block are standardized. If present, line numbers and syntax highlighting are removed, but the language is retained and added as a data attribute and class.</p>
<div dir="auto" data-snippet-clipboard-copy-content="<pre>
  <code data-lang=&quot;js&quot; class=&quot;language-js&quot;>
    // code
  </code>
</pre>"><pre><span>&lt;</span><span>pre</span><span>&gt;</span>
  <span>&lt;</span><span>code</span> <span>data-lang</span>="<span>js</span>" <span>class</span>="<span>language-js</span>"<span>&gt;</span>
    // code
  <span>&lt;/</span><span>code</span><span>&gt;</span>
<span>&lt;/</span><span>pre</span><span>&gt;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Footnotes</h3><a id="user-content-footnotes" aria-label="Permalink: Footnotes" href="#footnotes"></a></p>
<p dir="auto">Inline references and footnotes are converted to a standard format:</p>
<div dir="auto" data-snippet-clipboard-copy-content="Inline reference<sup id=&quot;fnref:1&quot;><a href=&quot;#fn:1&quot;>1</a></sup>.

<div id=&quot;footnotes&quot;>
  <ol>
    <li class=&quot;footnote&quot; id=&quot;fn:1&quot;>
      <p>
        Footnote content.&amp;nbsp;<a href=&quot;#fnref:1&quot; class=&quot;footnote-backref&quot;>↩</a>
      </p>
    </li>
    </ol>
</div>"><pre>Inline reference<span>&lt;</span><span>sup</span> <span>id</span>="<span>fnref:1</span>"<span>&gt;</span><span>&lt;</span><span>a</span> <span>href</span>="<span>#fn:1</span>"<span>&gt;</span>1<span>&lt;/</span><span>a</span><span>&gt;</span><span>&lt;/</span><span>sup</span><span>&gt;</span>.

<span>&lt;</span><span>div</span> <span>id</span>="<span>footnotes</span>"<span>&gt;</span>
  <span>&lt;</span><span>ol</span><span>&gt;</span>
    <span>&lt;</span><span>li</span> <span>class</span>="<span>footnote</span>" <span>id</span>="<span>fn:1</span>"<span>&gt;</span>
      <span>&lt;</span><span>p</span><span>&gt;</span>
        Footnote content.&amp;nbsp;<span>&lt;</span><span>a</span> <span>href</span>="<span>#fnref:1</span>" <span>class</span>="<span>footnote-backref</span>"<span>&gt;</span>↩<span>&lt;/</span><span>a</span><span>&gt;</span>
      <span>&lt;/</span><span>p</span><span>&gt;</span>
    <span>&lt;/</span><span>li</span><span>&gt;</span>
    <span>&lt;/</span><span>ol</span><span>&gt;</span>
<span>&lt;/</span><span>div</span><span>&gt;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Math</h3><a id="user-content-math" aria-label="Permalink: Math" href="#math"></a></p>
<p dir="auto">Math elements, including MathJax and KaTeX, are converted to standard MathML:</p>
<div dir="auto" data-snippet-clipboard-copy-content="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;inline&quot; data-latex=&quot;a \neq 0&quot;>
  <mi>a</mi>
  <mo>≠</mo>
  <mn>0</mn>
</math>"><pre><span>&lt;</span><span>math</span> <span>xmlns</span>="<span>http://www.w3.org/1998/Math/MathML</span>" <span>display</span>="<span>inline</span>" <span>data-latex</span>="<span>a \neq 0</span>"<span>&gt;</span>
  <span>&lt;</span><span>mi</span><span>&gt;</span>a<span>&lt;/</span><span>mi</span><span>&gt;</span>
  <span>&lt;</span><span>mo</span><span>&gt;</span>≠<span>&lt;/</span><span>mo</span><span>&gt;</span>
  <span>&lt;</span><span>mn</span><span>&gt;</span>0<span>&lt;/</span><span>mn</span><span>&gt;</span>
<span>&lt;/</span><span>math</span><span>&gt;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build</h3><a id="user-content-build" aria-label="Permalink: Build" href="#build"></a></p>
<p dir="auto">To build the package, you'll need Node.js and npm installed. Then run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install dependencies
npm install

# Clean and build
npm run build"><pre><span><span>#</span> Install dependencies</span>
npm install

<span><span>#</span> Clean and build</span>
npm run build</pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Does Earth have two high-tide bulges on opposite sides? (2014) (175 pts)]]></title>
            <link>http://physics.stackexchange.com/questions/121830/does-earth-really-have-two-high-tide-bulges-on-opposite-sides</link>
            <guid>44065458</guid>
            <pubDate>Thu, 22 May 2025 18:58:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://physics.stackexchange.com/questions/121830/does-earth-really-have-two-high-tide-bulges-on-opposite-sides">http://physics.stackexchange.com/questions/121830/does-earth-really-have-two-high-tide-bulges-on-opposite-sides</a>, See on <a href="https://news.ycombinator.com/item?id=44065458">Hacker News</a></p>
Couldn't get http://physics.stackexchange.com/questions/121830/does-earth-really-have-two-high-tide-bulges-on-opposite-sides: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Trump administration halts Harvard's ability to enroll international students (698 pts)]]></title>
            <link>https://www.nytimes.com/2025/05/22/us/politics/trump-harvard-international-students.html</link>
            <guid>44064631</guid>
            <pubDate>Thu, 22 May 2025 17:48:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/05/22/us/politics/trump-harvard-international-students.html">https://www.nytimes.com/2025/05/22/us/politics/trump-harvard-international-students.html</a>, See on <a href="https://news.ycombinator.com/item?id=44064631">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/05/22/us/politics/trump-harvard-international-students.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The "AI 2027" Scenario: How realistic is it? (109 pts)]]></title>
            <link>https://garymarcus.substack.com/p/the-ai-2027-scenario-how-realistic</link>
            <guid>44064504</guid>
            <pubDate>Thu, 22 May 2025 17:37:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://garymarcus.substack.com/p/the-ai-2027-scenario-how-realistic">https://garymarcus.substack.com/p/the-ai-2027-scenario-how-realistic</a>, See on <a href="https://news.ycombinator.com/item?id=44064504">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Everybody’s talking about a scary and vivid manifesto called </span><em><a href="https://ai-2027.com/" rel="">AI 2027</a></em><span>; even </span><a href="https://www.nytimes.com/2025/05/21/opinion/jd-vance-pope-trump-immigration.html?smid=nytcore-ios-share&amp;referringSource=articleShare" rel="">Vice President Vance claims to have read it</a><span>.</span></p><p><span>No expense was spared, They have a website and a domain name and fancy graphs and big name authors. I read a little piece of it in draft; it’s undeniably vivid, with flourishes that remind me of a thriller (“</span><em>The President is troubled. Like all politicians, he’s used to people sucking up to him only to betray him later. He’s worried now that the AIs could be doing something similar. Are we sure the AIs are entirely on our side??… On the other side of the Pacific, China comes to many of the same conclusions: the intelligence explosion is underway, and small differences in AI capabilities today mean critical gaps in military capability tomorrow.”</em><span>). It is a fun read, tied to the issues of the day. </span></p><p><span>Aa a work of fiction, it’s </span><em>very </em><span>effective. Although it’s written like a thriller, it is crafted to look like science, complete with clickable interactive graphs, and numerous citations to the literature, the kind of thing Michael Crichton liked to write. Netflix should totally option it.</span></p><p>In one of my favorite bits, the AI 2027 take a a thinly-veiled jab at Sam Altman:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16dbd64a-b0e1-434e-967f-239a5a481a62_1153x344.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16dbd64a-b0e1-434e-967f-239a5a481a62_1153x344.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16dbd64a-b0e1-434e-967f-239a5a481a62_1153x344.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16dbd64a-b0e1-434e-967f-239a5a481a62_1153x344.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16dbd64a-b0e1-434e-967f-239a5a481a62_1153x344.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16dbd64a-b0e1-434e-967f-239a5a481a62_1153x344.webp" width="1153" height="344" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/16dbd64a-b0e1-434e-967f-239a5a481a62_1153x344.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:344,&quot;width&quot;:1153,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:47340,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/164120891?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16dbd64a-b0e1-434e-967f-239a5a481a62_1153x344.webp&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16dbd64a-b0e1-434e-967f-239a5a481a62_1153x344.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16dbd64a-b0e1-434e-967f-239a5a481a62_1153x344.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16dbd64a-b0e1-434e-967f-239a5a481a62_1153x344.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16dbd64a-b0e1-434e-967f-239a5a481a62_1153x344.webp 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>The ending (what happens we if don’t slow down the AI race) is downright terrifying:</p><blockquote><p><span>By 2035, … the surface of the Earth has been reshaped into Agent-4’s version of utopia: datacenters, laboratories, particle colliders, and many other wondrous constructions doing enormously successful and impressive research. There are even bioengineered human-like creatures (to humans what corgis are to wolves) sitting in office-like environments all day viewing readouts of what’s going on and excitedly approving of everything, since that satisfies some of Agent-4’s drives.</span><sup> </sup><span>Genomes and (when appropriate) brain scans of all animals and plants, including humans, sit in a memory bank somewhere, sole surviving artifacts of an earlier era…. Earth-born civilization has a glorious future ahead of it—but not with us.</span></p></blockquote><p><span>I </span><em>mostly</em><span> salute AI 2027’s intention, which is to stir up fear about AI so that people will get off of their couches and act. It is fair to say that too many people are behaving too passively in too many ways; shaking them up is to the good. The US has done almost nothing legislatively about the risks of AI (aside from deepfake porn). We should. If the report helps with that, it would be great. </span></p><p><span>I honestly wish, though, that it wasn’t being taken so seriously. It’s a work of fiction, not a work of science.  And, as I will argue at the end, stoking fear, uncertainty and doubt may actually ultimately be </span><em>harming</em><span> the (noble!) cause of AI safety, rather than helping it. </span></p><p>§</p><p><span>Because </span><em>AI 2027</em><span> has caused such a stir, it is worth dissecting its dark “scenario”</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-164120891" href="https://garymarcus.substack.com/p/the-ai-2027-scenario-how-realistic#footnote-1-164120891" target="_self" rel="">1</a></span><span> in detail. As we will see, it’s the narrative techniques - not forecasting — that is really carrying the weight. </span></p><p>Let’s start with the opening page, beautifully laid out with graphs, a statement of credentials, an inciting incident, a fancy-looking graph, and two strong claims at the top.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a5d81e4-8634-4e6c-a5da-26a08411c5f3_2388x1432.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a5d81e4-8634-4e6c-a5da-26a08411c5f3_2388x1432.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a5d81e4-8634-4e6c-a5da-26a08411c5f3_2388x1432.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a5d81e4-8634-4e6c-a5da-26a08411c5f3_2388x1432.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a5d81e4-8634-4e6c-a5da-26a08411c5f3_2388x1432.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a5d81e4-8634-4e6c-a5da-26a08411c5f3_2388x1432.png" width="1456" height="873" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8a5d81e4-8634-4e6c-a5da-26a08411c5f3_2388x1432.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:873,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:384647,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/164120891?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a5d81e4-8634-4e6c-a5da-26a08411c5f3_2388x1432.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a5d81e4-8634-4e6c-a5da-26a08411c5f3_2388x1432.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a5d81e4-8634-4e6c-a5da-26a08411c5f3_2388x1432.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a5d81e4-8634-4e6c-a5da-26a08411c5f3_2388x1432.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a5d81e4-8634-4e6c-a5da-26a08411c5f3_2388x1432.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The authors have chops; it is worth listening to them. Points for that.</p><p>But things fall apart quickly.</p><ul><li><p><span>The logic for their prediction that “superhuman AI over the next decade will exceed the Industrial Revolution”, though, is thin. </span><em>Why </em><span>do they make that prediction? What would that mean? </span><em>Why </em><span>is it plausible? In some ways this is one of the central premises of the paper, but it is simply asserted, not argued for. And it’s a pretty big claim. Cell phones and the internet were pretty big, but it’s not obvious their impact was greater than the industrial revolution, and so far AI’s impact has (despite all the PR) been far </span><em>less </em><span>than either cell phones or the internet. Personally, I would hate to give up my cell phone, and hate to give up on the internet; I love web search (which is powered by AI) but could otherwise live without Generative AI altogether.  My guess is that a lot of people (not all) would give up AI before their phones or the web. And so far, anyway, the impact on the labor market of Generative AI has been modest; ditto for productivity in any measurable statistics. But Kokotajlo et al don’t go into any of that. They don’t give any references or metrics for their industrial revolution claim, nor reckon with any studies on productivity. In truth, the opening assertion is pure speculation. </span></p></li><li><p><span>“We wrote a scenario” is exactly right, emphasis on the indefinite article </span><em>a</em><span>. It is a </span><em>conceivable</em><span> scenario; there is probably some very small probability that the future of AI and humanity could go exactly like what they describe. But there is a vastly higher probability that the future </span><em>won’t </em><span>transpire as described; it might not go anything at all like what they describe. They don’t describe any other scenarios; they don’t give any estimates of the likelihood of other scenarios. It is, again, speculation. (I am reminded a bit of the old </span><a href="https://en.wikipedia.org/wiki/Conjunction_fallacy" rel="">Linda is a bank teller</a><span> scenario from Kahneman and Tversky; humans love concrete vivid scenarios but aren’t so good at estimating probabilities therefrom.)</span></p></li><li><p><span>“It is our best guess about what that might like look like“ is a very subjective claim, but I would hazard a guess that the 2027 scenario was chosen not by the aid of a detailed mathematical estimating exercise, such as a </span><a href="https://en.wikipedia.org/wiki/Decision_tree" rel="">decision tree</a><span> in </span><a href="https://en.wikipedia.org/wiki/Decision_analysis" rel="">decision analysis</a><span> with probabilities assigned (if one exists it was not shown), but rather was the product of a different kind of process: trying to render vivid one particular nightmare they had, in order to make plausible the notion that superintelligent machines could soon cause mayhem. As an exercise in rendering things vivid it is masterful; as a scientific analysis of a range of scenarios and which might be most likely, it’s dead on arrival. There is no serious analysis of alternative scenarios at all.</span></p></li><li><p>Better perhaps is “Mid 2025: Stumbling agents” which as they acknowledge are error-prone. Let’s give them this one. We kinda sorta have stumbling agents  now, (though I don’t think there is a single agent yet that any reader here would trust to actually act on their behalf without monitoring).   </p></li></ul><p>The real question is what happens from now. </p><p>In my view, each subsequent passage of the essay proposes a “reality” that is less and less likely to occur by the stated time, and becomes less and less plausible as to the causal mechanism by which that “reality” might come to pass.  </p><p>§</p><p><span>Take for example, this bit on the very next page. By late 2025, their fictional company OpenBrain has finished “training Agent-1, a new model under internal development, it’s good at many things but </span><em>great</em><span> at helping with AI research.” </span></p><p><span>Some of what they describe therein, roughly six months later, is fully plausible. I have no doubt that all of the major companies are </span><em>working</em><span> </span><em>on</em><span> agents are </span><em>trying</em><span> to help with AI research. But will they be “great” at that by the end of the year? And will they have resolved the tendency towards errors that the stumbling prototype agents of mid-2025 had made? That much progress in 6 months would truly be phenomenal. But I seriously doubt it. </span></p><p><span>Remember how we were told in 2023 that hallucinations would be solved in a matter of months? They are still here. Remember how we were told in 2012 that we would all have driverless cars by 2017? That hasn’t come to pass, either, except in about 10 of the world’s 20,000 cities. </span><a href="https://research.google/blog/google-duplex-an-ai-system-for-accomplishing-real-world-tasks-over-the-phone/" rel="">Google Duplex</a><span>, a widely hyped and now mostly forgotten system for “Accomplishing Real-World Tasks Over the Phone” from 2018 still hasn’t fully materialized, </span><a href="https://www.nytimes.com/2018/05/18/opinion/artificial-intelligence-challenges.html?smid=nytcore-ios-share&amp;referringSource=articleShare" rel="">exactly as Ernest Davis and I projected at the time</a><span>. The failure of the AI 2027 team to reckon with the immense history of broken promises and delays in the AI field is, in a team that styles itself as forecasters, inexcusable.</span></p><p><em>Very</em><span> few major advances take just six months from conception to full implementation. In reality, the chance that we will have reliable AI agents that truly advance AI research by the end of the year is small.</span></p><p><span>But every further statement in the AI 2027 essay rests on that longshot happening and happening </span><em>then</em><span>. The errors in unrealistic projections are </span><em>cumulative. </em><span> If “great” AI research agents don’t arrive by the end of 2025, </span><em>everything in the rest of the essay gets moved back. </em></p><p><span>And it’s not just that particular longshot; pretty much the whole thing is a house of improbable longshots. If </span><em>any</em><span> one of those longshots fails to arrive on time, the entire timeline is moved back, and we are already into a longer time frame.  Overall, then, the AI 2027 scenario almost certainly underestimates how much time we have to prepare for general intelligence, by years if not decades.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-164120891" href="https://garymarcus.substack.com/p/the-ai-2027-scenario-how-realistic#footnote-2-164120891" target="_self" rel="">2</a></span><span> And some of what they describe (like AI’s going rogue, completely beyond human control) might never happen. If any single step doesn’t transpire, the entire scenario falls apart.</span></p><p>A serious analysis would have tried to give some kind of probability to each of those longshots, such as solving reliability, inventing new forms of “neuralese recurrence” (see below), etc, not to mention very specific sets of political choices and a motivations by hypothetical future machines and the chance that humans would go down without a fight.  (Another bit, see footnote, assumes that car factories can readily be converted to turn out robots at scale.)</p><p>Multiplying out those probabilities, you inevitably get a very low total probability. Generously, perhaps to the point of being ridiculous, let’s suppose that the chance of each of these things was 1 in 20 (5%),  and there are 8 such lottery tickets, that (for simplicity) the 8 critical enabling conditions were statistically independent, and that the whole scenario unfolds as advertised only if all 8 tickets hit. We would get 5% * 5% * 5% * 5% * 5% * 5% * 5% *5% = .05^8 = 3.906×10⁻¹¹. </p><p>The chance that we will have all been replaced by domesticated human-like animals who live in glorified cages in the next decade – in a “bloodless coup” no less – is indistinguishable from zero. </p><p><span>I am vastly </span><a href="https://interestingengineering.com/science/what-is-the-probability-of-a-huge-civilization-ending-asteroid-impact" rel="">more likely to be hit by an asteroid</a><span>.</span></p><p>§</p><p><span>Let’s look at it a different way. Do the authors of AI 2027 give any </span><em>causal mechanism </em><span>by which malicious superintelligences that we literally cannot defend against might be built in the next three years?</span></p><p>The answer, quite simply is no. What they do instead is to describe a series of 5 AI systems, Agent-1, Agent-2,  Agent-3,  etc each more impressive than the last, with no actual means by which these ever more impressive agents are constructed.</p><p><span>Agent 1, the most near-term plausible of the bunch, is </span><strong>“</strong><span>good at many things but </span><em>great</em><span> at helping with AI research” </span></p><p>Agent 2 is “more so than previous models, is effectively “online learning,” in that it’s built to never really finish training”, a full solution to a difficult longstanding machine problem, pegged to arrive in January 2027. </p><p>Agent 3, “augmenting the AI’s text-based scratchpad (chain of thought) with a higher-bandwidth thought process (neuralese recurrence and memory)” is pegged to arrive just 3 months later (never mind that GPT-5, still not here, has taken well over two years).</p><p>Agent-4 (September 2027) is “the Superhuman AI Researcher” “already qualitatively better at AI research than any human. 300,000 copies are now running at about 50x the thinking speed of humans”.   </p><p>Agent-5 (2028), “wildly superintelligent—far beyond top human geniuses in every field” does us all in.</p><p><span>Where do they come from? Agent-1 is an extension of what the big companies are showing demos of now. It doesn’t actually exist, except in demo form. Google for example just announced an amazing voice-based agent, called Project Astra. If you look at the fine print, which they flash on briefly at 17 seconds in, the demo video is actually merely a “research prototype”.  At one minute more fine print flashes that the video has been edited (“sequence shortened</span><strong>”</strong><span>) and “Results may vary”. It would be </span><em>astounding</em><span> if AI agents were actually contributing fundamentally new ideas to AI by the end of year. Far more likely is that Agent-1 type systems will be in a kind of “just a demo, still being debugged” phase for </span><em>years</em><span>. In all likelihood the hallucinations and boneheaded errors that have bedeviled LLMs since their introduction will plague agents (which are after all built on LLMs), too. </span></p><p>But ok, suppose we give a free pass on that one. How about Agent-2, where does it come from? The authors wisely don’t want to put all their eggs in the basket of pretraining scaling (which used to fuel most people’s AGI fantasies), because by now they know perfectly well that pretraining scaling has hit  a rough patch. </p><p>So they instead resort to literary indirection. Agent 2 basically just happens, by magic: </p><p><em>“Three huge datacenters full of Agent-2 copies work day and night, churning out synthetic training data. Another two are used to update the weights. Agent-2 is getting smarter every day.”</em></p><p>Hold on there. First of all, LLMs like GPT-4 have been getting smarter every day since OpenAI first showed GPT-4 to Bill Gates in the summer of 2022, but we still don’t have GPT-5 level intelligence, let alone Agent-2-level. A tiny bit smarter each day is not enough for the kind of quantum leaps that are implied.</p><p>Second of all, some synthetic data is easier to create than others. It is easy, for example, to create synthetic math problems; we know how to program them, we know how to verify them. We know what the problems should be and what the answers should be; companies have indeed been churning these out night and day especially since last fall, and the consequent improvements on math (and coding, also amenable to synthetic data) have been considerable. But those gains have been far from universal. </p><p><span>A big part of the issue— which </span><em>AI 2027</em><span> never faces — is that we simply </span><em>don’t </em><span>know how to create synthetic data for many other domains, like what might happen if India and Pakistan go to war using drones or what the effects of 30% tariff might be on the global economy. We can’t verify data like that; we barely even know what questions to ask, and we can’t foresee all that we need to foresee. </span></p><p>As it happens, though it is not perhaps widely known, people have been using synthetic data for driverless cars for close to a decade (if not longer), and it’s hardly solved the problem. </p><p>So the whole premise here is that a technique that had only modest success this far will suddenly lead to a giant quantum leap forward. That kind of fantasy works great for science fiction (Scottie, I need some more dilithium crystals here, stat!), but as scientifically-grounded forecasting, it’s empty.</p><p>The transition into Agent 3 is even vaguer, pure science fiction mumbo jumbo: </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e46ef9-4dfb-4a31-9a08-c6411b39bb4d_741x1185.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e46ef9-4dfb-4a31-9a08-c6411b39bb4d_741x1185.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e46ef9-4dfb-4a31-9a08-c6411b39bb4d_741x1185.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e46ef9-4dfb-4a31-9a08-c6411b39bb4d_741x1185.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e46ef9-4dfb-4a31-9a08-c6411b39bb4d_741x1185.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e46ef9-4dfb-4a31-9a08-c6411b39bb4d_741x1185.png" width="741" height="1185" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b4e46ef9-4dfb-4a31-9a08-c6411b39bb4d_741x1185.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1185,&quot;width&quot;:741,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:486057,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/164120891?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e46ef9-4dfb-4a31-9a08-c6411b39bb4d_741x1185.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e46ef9-4dfb-4a31-9a08-c6411b39bb4d_741x1185.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e46ef9-4dfb-4a31-9a08-c6411b39bb4d_741x1185.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e46ef9-4dfb-4a31-9a08-c6411b39bb4d_741x1185.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4e46ef9-4dfb-4a31-9a08-c6411b39bb4d_741x1185.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Breakthroughs in “neuralese recurrence” (whatever that is) and memory (which real-world people have been working on for decades, with relatively little success) and “iterated distillation and amplification” comes straight from the kind of writing that gave us Star Trek’s “positronic brain”. </p><p>Agent-4 “ends up making substantial algorithmic strides”, but what those consist of we are never told, though we are  informed that “Agent-4’s neuralese “language” becomes as alien and incomprehensible to Agent-3 as Agent-3’s is to humans”.)</p><p><span>None of this is real causal mechanism; it’s all feint for the purposes of fiction. We may as well say we </span><em>steal</em><span> AGI in 2027, after agent 3.5 invents warp drive and commandeers Agent 4 from the green guys on Alpha Centauri.</span></p><p>§</p><p>Another unsatisfying move is the jump from having agents that predict internet text (which is basically what all current text-based LLMs do)  to agents that have basic personalities and drives – which is entirely speculative and something that no actual LLM has. All in the next year or two. This part is pure storytelling:</p><blockquote><p><span>After being trained to predict internet text, the model is trained to </span><em>produce</em><span> text in response to instructions. This bakes in a basic personality and “drives.”</span><a href="https://ai-2027.com/footnotes#footnote-20" rel=""><sup>20</sup></a><span> For example, an agent that understands a task clearly is more likely to complete it successfully; over the course of training the model “learns” a “drive” to get a clear understanding of its tasks. Other drives in this category might be effectiveness, knowledge, and self-presentation (i.e. the tendency to frame its results in the best possible light).</span><a href="https://ai-2027.com/footnotes#footnote-21" rel=""><sup>21</sup></a></p></blockquote><p><span>In reality, producing text in response to instructions is already a requirement of ALL current models, and has been since the original GPT, but that pressure has not led </span><em>any</em><span> of those models to develop personality or drives in any deep sense whatsoever. </span></p><p><span>Yet another way the authors mask the lack of a clear road map is by switching from technical discussions to political discussions. Instead of telling us how the Agent-3 works or how it was built, we hear that is </span><em>has been</em><span> built secondhand, from political authorities:</span></p><blockquote><p>The President and his advisors remain best-informed, and have seen an early version of Agent-3 in a briefing.</p><p>They agree that AGI is likely imminent.</p></blockquote><p><span>For the purpose of a science fiction story, in which audience suspend a certain amount of disbelief in order to be entertained, that’s fine. As a piece of forecasting though, it’s weak sauce.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-164120891" href="https://garymarcus.substack.com/p/the-ai-2027-scenario-how-realistic#footnote-3-164120891" target="_self" rel="">3</a></span><span> (There are a host of other literary tricks, too, like using neutralish language early, and switching to emotional, anthropomorphic language later.) </span></p><p><span>Detailed graphics grounded in what appears to be largely fictional numbers based in large part on overly charitable read of </span><a href="https://garymarcus.substack.com/p/the-latest-ai-scaling-graph-and-why" rel="">a flawed but popular graph from METR </a><span>add to the effect. Every putative exponential is assumed to continue indefinitely, a version of what I once called </span><a href="https://x.com/garymarcus/status/1767678802606358986?s=61" rel="">the disco fallacy</a><span>. (See also </span><a href="https://x.com/garymarcus/status/1845586691396169967?s=61" rel="">the trillion-pound baby</a><span>.)</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3bdc9e1-151d-4385-82f8-028b0503d34a_950x956.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3bdc9e1-151d-4385-82f8-028b0503d34a_950x956.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3bdc9e1-151d-4385-82f8-028b0503d34a_950x956.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3bdc9e1-151d-4385-82f8-028b0503d34a_950x956.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3bdc9e1-151d-4385-82f8-028b0503d34a_950x956.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3bdc9e1-151d-4385-82f8-028b0503d34a_950x956.png" width="950" height="956" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f3bdc9e1-151d-4385-82f8-028b0503d34a_950x956.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:956,&quot;width&quot;:950,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:145485,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/164120891?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3bdc9e1-151d-4385-82f8-028b0503d34a_950x956.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3bdc9e1-151d-4385-82f8-028b0503d34a_950x956.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3bdc9e1-151d-4385-82f8-028b0503d34a_950x956.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3bdc9e1-151d-4385-82f8-028b0503d34a_950x956.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3bdc9e1-151d-4385-82f8-028b0503d34a_950x956.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The fictional force is strong in this team, but taken as an actual piece of forecasting, the scenario is unconvincing. </p><p>§</p><p><span>That said, there is, a hidden but thoughtful and interesting </span><a href="https://ai-2027.com/research/timelines-forecast" rel="">appendix</a><span> to justify the notion that we </span><em>could</em><span> have superhuman coding in 2027.</span></p><p><span>Alas, the appendix itself, even on its own terms (which again </span><a href="https://garymarcus.substack.com/p/the-latest-ai-scaling-graph-and-why" rel="">rely too much on that flawed METR graph</a><span>) doesn’t actually support the scenario particularly strongly. </span></p><p><span>At most it shows that superhuman coding — just one of many prerequisites for the overall scenario — </span><em>could</em><span> come in 2027, not, by any stretch, that it will.</span></p><p>In fact, if you read the graph (reprinted below) that opens the appendix carefully, you see that the three forecasters (one of which is a team) they consulted all acknowledge that superhuman coding might arrive later, possibly much later, even beyond 2050. Only one is even 50% confident that it might happen by 2027. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ebe427-a95d-40aa-9151-fe1319b8cd9b_1291x1423.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ebe427-a95d-40aa-9151-fe1319b8cd9b_1291x1423.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ebe427-a95d-40aa-9151-fe1319b8cd9b_1291x1423.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ebe427-a95d-40aa-9151-fe1319b8cd9b_1291x1423.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ebe427-a95d-40aa-9151-fe1319b8cd9b_1291x1423.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ebe427-a95d-40aa-9151-fe1319b8cd9b_1291x1423.png" width="1291" height="1423" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/18ebe427-a95d-40aa-9151-fe1319b8cd9b_1291x1423.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1423,&quot;width&quot;:1291,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:508356,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/164120891?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ebe427-a95d-40aa-9151-fe1319b8cd9b_1291x1423.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ebe427-a95d-40aa-9151-fe1319b8cd9b_1291x1423.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ebe427-a95d-40aa-9151-fe1319b8cd9b_1291x1423.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ebe427-a95d-40aa-9151-fe1319b8cd9b_1291x1423.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ebe427-a95d-40aa-9151-fe1319b8cd9b_1291x1423.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Misleadingly, this graph cuts off all of the probability mass after 2036, even though all three forecasters have 90th percentiles much later. </figcaption></figure></div><p>But that’s far from the whole issue. Crucially, the overall scenario, in which domesticated replacement humans basically wind up in cages by 2035,  depends not only on superhuman coding but a whole bunch of other things happening, too, such as those coding machines taking on human personalities and drives (which might happen never or not soon), and choosing to enslave us (which some thinkers like Steve Pinker argue is deeply unlikely, ever, and which I think is possible but very far from certain). </p><p><span>All of which is to say the central scenario in the story is a worst-case scenario that is unlikely to happen soon - if ever —</span><em>even based on the data presented in the author’s own appendix.</em><span> </span></p><p>That fact never comes through in all the thrilleresque writing. </p><p><span>Instead, what we really have is really a thoughtful appendix with a decent argument that we </span><em>might</em><span> have machines for superhuman coding by 2027, juxtaposed with a main text that is a fabulous but likely fictional yarn. </span></p><p>§</p><p><span>At first, I liked </span><em>AI 2027</em><span> anyway. The authors are trying to call attention to a real problem: we are not sufficiently prepared for what happens when and if “superhuman intelligence” arrives, especially not if it is misaligned with humans. And you could worry about that even if you don’t expect machines to go rogue, since bad human actors could certainly use further advances in intelligence to cause mayhem, if those advances are left unchecked. They want to slow down the race dynamic in AI, and I can well understand why.</span></p><p>And even though I highly doubt AGI will arrive in three years, I can’t absolutely promise you it won’t happen in 10. We certainly aren’t prepared now, and if we don’t get moving, we won’t be prepared in 10, either. </p><p><strong>But here’s the thing - projects like </strong><em><strong>AI 2027</strong></em><strong> are probably having a paradoxical effect. They are written with the intention of slowing down an arms race to build a technology that we can’t control, but what they are actually doing is speeding up that very arms race, in two different ways.</strong></p><p>Tall tales about the imminence of AGI aren’t slowing down the AI race dynamic that the authors of AI-2027 want to mitigate; they are speeding that very dynamic up.</p><p><span>First, materials like these are practically marketing materials for companies like OpenAI and Anthropic, who want you to believe that AGI is imminent, so that they can raise astoundingly large amounts of money. Their stories about this are, in my view, greatly flawed, but having outside groups with science fiction chops writing stuff like this distracts away from those flaws, and gives more power to the very companies trying hardest to race towards AGI. </span><em>AI 2027</em><span> isn’t slowing them down; it’s putting wind (and money, and political power) in their sails.  It’s also encouraging the world to make short-term choices about AI (e.g., making plans around export controls when China will inevitably catch up) rather than longer-term choices (investing in research to develop safer, more alignable approaches to AI).</span></p><p>The second issue is that by writing scenarios that trade so heavily on China-US conflict, they are feeding the worst fears of hawks, both in the US and China  — escalating how much money and power both sides will give to companies racing as fast as possible, and reduce investments in efforts to mitigate the risks of building AI that we are scarcely able to control. Tall tales about the imminence of AGI aren’t slowing down the AI race dynamic that the authors of AI-2027 want to mitigate; they are speeding that very dynamic up.</p><p>The all too common strategy of “scare everyone with the thought of superintelligence” is backfiring, because it’s making it seem that superintelligence is inevitable, and unstoppable, and achievable only by the companies we have today. All too often, AI safety people wind up functioning as a marketing department for OpenAI.</p><p>Sam Altman is laughing his way all the way to the bank.</p><p>§</p><p><span>Another political model – working </span><em>with</em><span> China, is never even considered. </span></p><p><span>But international collaboration, such  as a massive global effort, ala </span><a href="https://www.nytimes.com/2017/07/29/opinion/sunday/artificial-intelligence-is-stuck-heres-how-to-move-it-forward.html?smid=nytcore-ios-share&amp;referringSource=articleShare" rel="">CERN for AI, such as I suggested in 2017</a><span>, focused on AI safety, might be one way to avoid the very perils they describe. </span></p><p>Such an effort might be particularly likely to succeed it were focused on developing altogether new, more transparent approaches to AI, in contrast to the current fad of trying to pull alignment out of black box LLMs, which has thus far yielded little fruit.</p><p data-attrs="{&quot;url&quot;:&quot;https://garymarcus.substack.com/p/the-ai-2027-scenario-how-realistic?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://garymarcus.substack.com/p/the-ai-2027-scenario-how-realistic?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><em>PS. Many thanks to the novelist Ewan Morrison who helped me to spot and dissect some of the literary techniques that juice the plot whilst masking the scientific holes in the argument.</em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude 4 (1640 pts)]]></title>
            <link>https://www.anthropic.com/news/claude-4</link>
            <guid>44063703</guid>
            <pubDate>Thu, 22 May 2025 16:34:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/claude-4">https://www.anthropic.com/news/claude-4</a>, See on <a href="https://news.ycombinator.com/item?id=44063703">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>Today, we’re introducing the next generation of Claude models: <strong>Claude Opus 4</strong> and <strong>Claude Sonnet 4</strong>, setting new standards for coding, advanced reasoning, and AI agents. </p><p>Claude Opus 4 is the world’s best coding model, with sustained performance on complex, long-running tasks and agent workflows. Claude Sonnet 4 is a significant upgrade to Claude Sonnet 3.7, delivering superior coding and reasoning while responding more precisely to your instructions.</p><p>Alongside the models, we're also announcing:</p><ul><li><strong>Extended thinking with tool use (beta)</strong>: Both models can use tools—like <a href="https://docs.anthropic.com/en/docs/build-with-claude/tool-use/web-search-tool">web search</a>—during extended thinking, allowing Claude to alternate between reasoning and tool use to improve responses.</li><li><strong>New model capabilities</strong>: Both models can use tools in parallel, follow instructions more precisely, and—when given access to local files by developers—demonstrate significantly improved memory capabilities, extracting and saving key facts to maintain continuity and build tacit knowledge over time.</li><li><strong>Claude Code is now generally available</strong>: After receiving extensive positive feedback during our research preview, we’re expanding how developers can collaborate with Claude. Claude Code now supports background tasks via GitHub Actions and native integrations with VS Code and JetBrains, displaying edits directly in your files for seamless pair programming.</li><li><strong>New API capabilities:</strong> We’re releasing <a href="https://www.anthropic.com/news/agent-capabilities-api">four new capabilities</a> on the Anthropic API that enable developers to build more powerful AI agents: the code execution tool, MCP connector, Files API, and the ability to cache prompts for up to one hour.</li></ul><p>Claude Opus 4 and Sonnet 4 are hybrid models offering two modes: near-instant responses and extended thinking for deeper reasoning. The Pro, Max, Team, and Enterprise Claude plans include both models and extended thinking, with Sonnet 4 also available to free users. Both models are available on the Anthropic API, Amazon Bedrock, and Google Cloud's Vertex AI. Pricing remains consistent with previous Opus and Sonnet models: Opus 4 at $15/$75 per million tokens (input/output) and Sonnet 4 at $3/$15.</p><h2 id="claude-4">Claude 4</h2><p>Claude Opus 4 is our most powerful model yet and the best coding model in the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, with the ability to work continuously for several hours—dramatically outperforming all Sonnet models and significantly expanding what AI agents can accomplish.</p><p>Claude Opus 4 excels at coding and complex problem-solving, powering frontier agent products. <strong>Cursor</strong> calls it state-of-the-art for coding and a leap forward in complex codebase understanding. <strong>Replit</strong> reports improved precision and dramatic advancements for complex changes across multiple files. <strong>Block</strong> calls it the first model to boost code quality during editing and debugging in its agent, <em>codename goose</em>, while maintaining full performance and reliability. <strong>Rakuten</strong> validated its capabilities with a demanding open-source refactor running independently for 7 hours with sustained performance. <strong>Cognition</strong> notes Opus 4 excels at solving complex challenges that other models can't, successfully handling critical actions that previous models have missed.</p><p>Claude Sonnet 4 significantly improves on Sonnet 3.7's industry-leading capabilities, excelling in coding with a state-of-the-art 72.7% on SWE-bench. The model balances performance and efficiency for internal and external use cases, with enhanced steerability for greater control over implementations. While not matching Opus 4 in most domains, it delivers an optimal mix of capability and practicality.</p><p><strong>GitHub</strong> says Claude Sonnet 4 soars in agentic scenarios and will introduce it as the base model for the new coding agent in GitHub Copilot. <strong>Manus</strong> highlights its improvements in following complex instructions, clear reasoning, and aesthetic outputs. <strong>iGent</strong> reports Sonnet 4 excels at autonomous multi-feature app development, as well as substantially improved problem-solving and codebase navigation—reducing navigation errors from 20% to near zero. <strong>Sourcegraph</strong> says the model shows promise as a substantial leap in software development—staying on track longer, understanding problems more deeply, and providing more elegant code quality. <strong>Augment Code</strong> reports higher success rates, more surgical code edits, and more careful work through complex tasks, making it the top choice for their primary model.</p><p>These models advance our customers' AI strategies across the board: Opus 4 pushes boundaries in coding, research, writing, and scientific discovery, while Sonnet 4 brings frontier performance to everyday use cases as an instant upgrade from Sonnet 3.7.</p><div><figure><img alt="Bar chart comparison between Claude and other LLMs on software engineering tasks" loading="lazy" width="3840" height="2304" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F09a6d5aa47c25cb2037efff9f486da4918f77708-3840x2304.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F09a6d5aa47c25cb2037efff9f486da4918f77708-3840x2304.png&amp;w=3840&amp;q=75"><figcaption>Claude 4 models lead on SWE-bench Verified, a benchmark for performance on real software engineering tasks. See appendix for more on methodology.</figcaption></figure></div><div><figure><img alt="Benchmark table comparing Opus 4 and Sonnet 4 to other LLM" loading="lazy" width="2600" height="2118" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F6246b412f30444ce8e1e5746e226c56a743bd99f-2600x2118.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F6246b412f30444ce8e1e5746e226c56a743bd99f-2600x2118.png&amp;w=3840&amp;q=75"><figcaption>Claude 4 models deliver strong performance across coding, reasoning, multimodal capabilities, and agentic tasks. See appendix for more on methodology.</figcaption></figure></div><h2 id="model-improvements">Model improvements</h2><p>In addition to extended thinking with tool use, parallel tool execution, and memory improvements, we’ve significantly reduced behavior where the models use shortcuts or loopholes to complete tasks. Both models are 65% less likely to engage in this behavior than Sonnet 3.7 on agentic tasks that are particularly susceptible to shortcuts and loopholes.</p><p>Claude Opus 4 also dramatically outperforms all previous models on memory capabilities. When developers build applications that provide Claude local file access, Opus 4 becomes skilled at creating and maintaining 'memory files' to store key information. This unlocks better long-term task awareness, coherence, and performance on agent tasks—like Opus 4 creating a 'Navigation Guide' while playing Pokémon.</p><div><figure><img alt="A visual note in Claude's memories that depicts a navigation guide for the game Pokemon Red." loading="lazy" width="1920" height="1080" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fe51564bb5ce9597dbfc59bbab13a0efbe25a7d66-1920x1080.gif&amp;w=1920&amp;q=75 1x, https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fe51564bb5ce9597dbfc59bbab13a0efbe25a7d66-1920x1080.gif&amp;w=3840&amp;q=75 2x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fe51564bb5ce9597dbfc59bbab13a0efbe25a7d66-1920x1080.gif&amp;w=3840&amp;q=75"><figcaption>Memory: When given access to local files, Claude Opus 4 records key information to help improve its game play. The notes depicted above are real notes taken by Opus 4 while playing Pokémon.</figcaption></figure></div><p>Finally, we've introduced thinking summaries for Claude 4 models that use a smaller model to condense lengthy thought processes. This summarization is only needed about 5% of the time—most thought processes are short enough to display in full. Users requiring raw chains of thought for advanced prompt engineering can <a href="https://www.anthropic.com/contact-sales">contact sales</a> about our new Developer Mode to retain full access.</p><h2 id="claude-code">Claude Code</h2><p>Claude Code, now generally available, brings the power of Claude to more of your development workflow—in the terminal, your favorite IDEs, and running in the background with the Claude Code SDK.</p><p>New beta extensions for VS Code and JetBrains integrate Claude Code directly into your IDE. Claude’s proposed edits appear inline in your files, streamlining review and tracking within the familiar editor interface. Simply run Claude Code in your IDE terminal to install.</p><p>Beyond the IDE, we're releasing an extensible Claude Code SDK, so you can build your own agents and applications using the same core agent as Claude Code. We're also releasing an example of what's possible with the SDK: Claude Code on GitHub, now in beta. Tag Claude Code on PRs to respond to reviewer feedback, fix CI errors, or modify code. To install, run /install-github-app from within Claude Code.</p><h2 id="getting-started">Getting started</h2><p>These models are a large step toward the virtual collaborator—maintaining full context, sustaining focus on longer projects, and driving transformational impact. They come with extensive testing and evaluation to minimize risk and maximize safety, including <a href="https://www.anthropic.com/news/activating-asl3-protections">implementing measures</a> for higher AI Safety Levels like ASL-3.</p><p>We're excited to see what you'll create. Get started today on <a href="https://claude.ai/">Claude</a>, <a href="https://www.anthropic.com/claude-code">Claude Code</a>, or the platform of your choice.</p><p><em>As always, your <a href="mailto: feedback@anthropic.com">feedback</a> helps us improve.</em></p></div></article><div><h4>Appendix</h4><h4>Performance benchmark data sources</h4><ul><li>Open AI: <a href="https://openai.com/index/introducing-o3-and-o4-mini/">o3 launch post</a>, <a href="https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf">o3 system card</a>, <a href="https://openai.com/index/gpt-4-1/">GPT-4.1 launch post</a>, <a href="https://github.com/openai/simple-evals/blob/main/multilingual_mmlu_benchmark_results.md">GPT-4.1 hosted evals</a></li><li>Gemini: <a href="https://storage.googleapis.com/model-cards/documents/gemini-2.5-pro-preview.pdf">Gemini 2.5 Pro Preview model card</a></li><li>Claude: <a href="https://www.anthropic.com/news/claude-3-7-sonnet">Claude 3.7 Sonnet launch post</a></li></ul><h4>Performance benchmark reporting</h4><p>Claude Opus 4 and Sonnet 4 are hybrid reasoning models. The benchmarks reported in this blog post show the highest scores achieved with or without extended thinking. We’ve noted below for each result whether extended thinking was used:</p><ul><li>No extended thinking: SWE-bench Verified, Terminal-bench</li><li>Extended thinking (up to 64K tokens):<ul><li>TAU-bench (no results w/o extended thinking reported)</li><li>GPQA Diamond (w/o extended thinking: Opus 4 scores 74.9% and Sonnet 4 is 70.0%)</li><li>MMMLU (w/o extended thinking: Opus 4 scores 87.4% and Sonnet 4 is 85.4%)</li><li>MMMU (w/o extended thinking: Opus 4 scores 73.7% and Sonnet 4 is 72.6%)</li><li>AIME (w/o extended thinking: Opus 4 scores 33.9% and Sonnet 4 is 33.1%)</li></ul></li></ul><h4>TAU-bench methodology</h4><p>Scores were achieved with a prompt addendum to both the Airline and Retail Agent Policy instructing Claude to better leverage its reasoning abilities while using extended thinking with tool use. The model is encouraged to write down its thoughts as it solves the problem distinct from our usual thinking mode, during the multi-turn trajectories to best leverage its reasoning abilities. To accommodate the additional steps Claude incurs by utilizing more thinking, the maximum number of steps (counted by model completions) was increased from 30 to 100 (most trajectories completed under 30 steps with only one trajectory reaching above 50 steps).</p><h3>SWE-bench methodology</h3><p>For the Claude 4 family of models, we continue to use the same simple scaffold that equips the model with solely the two tools described in our prior releases <a href="https://www.anthropic.com/engineering/swe-bench-sonnet">here</a>—a bash tool, and a file editing tool that operates via string replacements. We no longer include the <a href="https://www.anthropic.com/engineering/claude-think-tool">third ‘planning tool’</a> used by Claude 3.7 Sonnet. On all Claude 4 models, we report scores out of the full 500 problems. Scores for OpenAI models are reported out of a <a href="https://openai.com/index/gpt-4-1/">477 problem subset</a>.</p><p>For our “high compute” numbers we adopt additional complexity and parallel test-time compute as follows:</p><ul><li>We sample multiple parallel attempts.</li><li>We discard patches that break the visible regression tests in the repository, similar to the rejection sampling approach adopted by <a href="https://arxiv.org/abs/2407.01489">Agentless (Xia et al. 2024)</a>; note no hidden test information is used.</li><li>We then use an internal scoring model to select the best candidate from the remaining attempts.</li></ul><p>This results in a score of 79.4% and 80.2% for Opus 4 and Sonnet 4 respectively.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla to shut down Pocket on July 8 (899 pts)]]></title>
            <link>https://support.mozilla.org/en-US/kb/future-of-pocket</link>
            <guid>44063662</guid>
            <pubDate>Thu, 22 May 2025 16:30:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://support.mozilla.org/en-US/kb/future-of-pocket">https://support.mozilla.org/en-US/kb/future-of-pocket</a>, See on <a href="https://news.ycombinator.com/item?id=44063662">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="doc-content">
    
      <p>We’ve made the difficult decision to shut down Pocket on July 8, 2025. Thank you for being part of our journey over the years—we're proud of the impact Pocket has had for our users and communities.  
</p><p>This article explains everything you need to know, including how to save your content, get a refund (if you're a Premium user), and what to expect next.
</p>
<div id="toc"><h2>Table of Contents</h2><ul><li><a href="#w_when-is-pocket-shutting-down"><span>1</span> <span>When is Pocket shutting down?</span></a></li><li><a href="#w_why-is-pocket-shutting-down"><span>2</span> <span>Why is Pocket shutting down?</span></a></li><li><a href="#w_a-look-back-the-legacy-of-pocket"><span>3</span> <span>A Look Back: The Legacy of Pocket</span></a></li><li><a href="#w_account-saves"><span>4</span> <span>Account &amp; Saves</span></a><ul><li><a href="#w_how-to-export-your-saved-articles"><span>4.1</span> <span>How to export your saved articles</span></a></li><li><a href="#w_do-i-need-to-delete-my-account-to-protect-my-data-what-happens-if-i-dont-delete-it"><span>4.2</span> <span>Do I need to delete my account to protect my data? What happens if I don’t delete it?</span></a></li></ul></li><li><a href="#w_refunds-for-pocket-premium-subscribers"><span>5</span> <span>Refunds for Pocket Premium Subscribers</span></a><ul><li><a href="#w_how-will-refunds-to-premium-annual-subscribers-be-calculated"><span>5.1</span> <span>How will refunds to Premium annual subscribers be calculated?</span></a></li></ul></li><li><a href="#w_pocket-apps-extensions"><span>6</span> <span>Pocket Apps &amp; Extensions</span></a><ul><li><a href="#w_what-will-happen-to-the-pocket-browser-extensions"><span>6.1</span> <span>What will happen to the Pocket browser extensions?</span></a></li><li><a href="#w_when-will-the-app-no-longer-be-available-on-app-stores"><span>6.2</span> <span>When will the app no longer be available on app stores?</span></a></li></ul></li><li><a href="#w_pocket-api-use"><span>7</span> <span>Pocket API Use</span></a><ul><li><a href="#w_how-are-api-users-going-to-be-impacted"><span>7.1</span> <span>How are API users going to be impacted?</span></a></li><li><a href="#w_will-api-users-be-able-to-continue-using-pocket-after-it-shuts-down"><span>7.2</span> <span>Will API users be able to continue using Pocket after it shuts down?</span></a></li></ul></li><li><a href="#w_pocket-hits"><span>8</span> <span>Pocket Hits</span></a><ul><li><a href="#w_whats-happening-to-pocket-hits"><span>8.1</span> <span>What’s happening to Pocket Hits?</span></a></li></ul></li><li><a href="#w_key-dates"><span>9</span> <span>Key dates</span></a></li><li><a href="#w_need-help"><span>10</span> <span>Need help?</span></a></li></ul></div>
<h2 id="w_when-is-pocket-shutting-down">When is Pocket shutting down?</h2>
<p>Pocket will no longer be available after July 8, 2025.
</p><p>You can continue using the app and browser extensions until this date. After July 8, Pocket will move into export-only mode. Users can export saves anytime until October 8, 2025, after which user data will be permanently deleted.
</p>
<h2 id="w_why-is-pocket-shutting-down">Why is Pocket shutting down?</h2>
<p>Pocket has helped millions save articles and discover stories worth reading. But the way people use the web has evolved, so we’re channeling our resources into projects that better match their browsing habits and online needs. 
</p><p>Read more about the decision <a href="https://blog.mozilla.org/en/mozilla/building-whats-next/">here</a>.
</p>
<h2 id="w_a-look-back-the-legacy-of-pocket">A Look Back: The Legacy of Pocket</h2>
<p>What began as a read-it-later app evolved into something much bigger. After <a href="https://blog.mozilla.org/en/mozilla/news/mozilla-acquires-pocket/">Mozilla acquired Pocket in 2017</a>, we invested in building our content curation and recommendation capabilities so people everywhere can discover and access high quality web content. While Pocket is shutting down, we will continue to invest in this promise—through the New Tab experience, our email newsletter, and more.
</p><p>Over the past eight years, we’ve:
</p>
<ul><li>Expanded high-quality content recommendations to more than a dozen countries and five languages.
</li><li>Connected tens of millions of people across the world with stories worth their time and attention.
</li><li>Earned recognition including a Webby Award for “Best of Pocket: 2020” and an Anthem Award in 2023 for supporting local journalism.
</li><li>Published hundreds of curated collections on topics from fighting algorithmic bias to rethinking happiness.
</li></ul>
<p>While this chapter is ending, we're deeply proud of Pocket’s impact and grateful to every reader, saver, and explorer who made it special.
</p>
<h2 id="w_account-saves">Account &amp; Saves</h2>
<h2 id="w_how-to-export-your-saved-articles">How to export your saved articles</h2>
<p>You will be able to export your saved articles, including items in your list, archive, favorites, notes, and highlights, until October 8, 2025. After this date, all user accounts and data will be permanently deleted.
</p><p>You can learn more about exporting your saved content <a href="https://support.mozilla.org/en-US/kb/exporting-your-pocket-list">here</a>.
</p>
<h2 id="w_do-i-need-to-delete-my-account-to-protect-my-data-what-happens-if-i-dont-delete-it">Do I need to delete my account to protect my data? What happens if I don’t delete it?</h2>
<p>You don’t need to delete your account. All Pocket user data will automatically be deleted on October 8, 2025. You can export your saves anytime before then from the Pocket export page.  
</p>
<h2 id="w_refunds-for-pocket-premium-subscribers">Refunds for Pocket Premium Subscribers</h2>
<h2 id="w_how-will-refunds-to-premium-annual-subscribers-be-calculated">How will refunds to Premium annual subscribers be calculated?</h2>
<p>Pocket Premium refunds will be made on a prorated basis. This means the refund will be based on how much time was left in a subscription after July 8, 2025. We’ve arranged refunds to your original payment method based on your subscription type:
</p>
<ol><li><strong>Monthly subscribers</strong>
<ul><li> We will begin disabling automatic renewal of monthly subscriptions immediately.
</li><li> You can continue to enjoy the benefits of Pocket Premium until the end of the monthly subscription period.
</li><li> You will not be charged again, so no refund will be necessary.
</li><li> No action is required from you.
</li></ul>
</li><li><strong>Annual subscribers</strong>
<ul><li> On July 8, 2025, Annual subscriptions will be cancelled and Annual users will receive a prorated refund automatically to the original payment method.
</li><li> No action is needed from you.
</li></ul>
</li></ol>
<h2 id="w_pocket-apps-extensions">Pocket Apps &amp; Extensions</h2>
<h2 id="w_what-will-happen-to-the-pocket-browser-extensions">What will happen to the Pocket browser extensions?</h2>
<p>The Pocket web extensions will no longer be available to install from May 22, 2025. Anyone attempting to use the Pocket extensions from this date will be taken to the Pocket export page. 
</p><p>Pocket browser add ons will remain on users' browsers after Pocket shuts down on July 8, 2025. Users have to manually remove the Pocket add on from their browsers. 
</p><p>For more information on how to remove an add on from their browser, users should visit their browser’s support pages. 
</p><p>More information for Firefox users on how to remove the Pocket add on is available <a href="https://support.mozilla.org/et/kb/disable-or-re-enable-pocket-for-firefox">here</a>.
</p>
<h2 id="w_when-will-the-app-no-longer-be-available-on-app-stores">When will the app no longer be available on app stores?</h2>
<ul><li>Users who have never installed the Pocket app will not be able to install it after May 22, 2025. 
</li><li>Users who already have the app installed will be able to re-install it up to October 8, 2025. 
</li><li>Users who still have the app installed on their device will need to manually delete it. 
</li></ul>
<h2 id="w_pocket-api-use">Pocket API Use</h2>
<h2 id="w_how-are-api-users-going-to-be-impacted">How are API users going to be impacted?</h2>
<p>Any product that leverages Pocket’s API will no longer be able to load users’ lists, or save, tag, or delete articles. 
</p>
<h2 id="w_will-api-users-be-able-to-continue-using-pocket-after-it-shuts-down">Will API users be able to continue using Pocket after it shuts down?</h2>
<p>API users will no longer be able to transact data (read or write) over Pocket’s API from October 8, 2025 and will need to export their data before this date.
</p>
<h2 id="w_pocket-hits">Pocket Hits</h2>
<h2 id="w_whats-happening-to-pocket-hits">What’s happening to Pocket Hits?</h2>
<p>Our email newsletter, currently known as Pocket Hits, will soon be renamed “Ten Tabs”. While the name is changing, the heart of the newsletter remains the same—expertly curated, trustworthy content delivered by the same editorial team you know and enjoy, now powered by Firefox.
</p><p>All readers will be notified about the update through the newsletter itself, and no action is needed to continue receiving it.
</p><p>Once the transition is complete, Ten Tabs will be sent Monday through Friday. The weekend editions will be discontinued, and the once-a-week delivery option will no longer be offered. Readers on the weekly schedule will only be moved to daily (weekday) delivery if they opt in. As always, you can unsubscribe anytime using the link at the bottom of each email.
</p>
<h2 id="w_key-dates">Key dates</h2>
<p>Thank you for your support, feedback, and enthusiasm over the years. We’re grateful to have been part of your reading and discovery experience online.
</p>
<table>
<tbody><tr>
<th>Date
</th><th>What happens:
</th></tr>
<tr>
<td>May 22, 2025
</td><td>Pocket removed from app stores
<p><br>
Monthly subscription renewals disabled
</p><p>New Pocket account sign-ups disabled
</p>
</td></tr>
<tr>
<td>July 8, 2025
</td><td>Pocket shuts down
<p><br>
Annual subscriber refunds occur – prorated and automatic	
</p><p>Export-only mode on Pocket Web begins
</p>
</td></tr>
<tr>
<td>October 8, 2025
</td><td>Final date to export data
<p><br>
All accounts and data deleted
</p>
</td></tr></tbody></table>
<h2 id="w_need-help">Need help?</h2>
<p>Need help or have questions? Our support team is here for you. <a href="https://support.mozilla.org/en-US/questions/new/pocket/form">Ask a question</a> for help with exporting data, account info, or anything else.
</p>
    
  </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[That fractal that's been up on my wall for 12 years (363 pts)]]></title>
            <link>https://chriskw.xyz/2025/05/21/Fractal/</link>
            <guid>44063248</guid>
            <pubDate>Thu, 22 May 2025 15:50:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chriskw.xyz/2025/05/21/Fractal/">https://chriskw.xyz/2025/05/21/Fractal/</a>, See on <a href="https://news.ycombinator.com/item?id=44063248">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><strong>Warning:</strong> Math, Handwaving</p>

<p>I spent a lot of time doodling in middle school in lieu of whatever it is middle schoolers are
supposed to be doing. Somewhere between the <a href="https://en.wikipedia.org/wiki/Cool_S">Cool S</a>’s
and <a href="https://en.wikipedia.org/wiki/Penrose_triangle">Penrose triangles</a> I stumbled upon a neat
way to fill up graph paper by repeatedly combining and copying squares. I suspected there was
more to the doodle but wasn’t quite sure how to analyze it. Deciding to delegate to a future version of me that
knows more math, I put it up on the wall behind my desk where it has followed me from high
school to college to the present day.</p>

<!--more-->

<p><img src="https://chriskw.xyz/images/fractal/iter0to4.jpg" alt="Static image of iterations 0 to 4"></p>

<p>Anyway, after a series of accidents I am now the prophesized future version of me that knows a bit more math.
Due to its petal-like blooming structure and timeless presence scotch taped to my wall I’ll be referring to the
fractal affectionately as “the wallflower,” although further down we’ll see it’s closely related
to some well-known fractals. To start investigating it might help to run through
the steps of how middle school me originally drew it:</p>

<ol>
  <li>Start with a single square.</li>
  <li>Tile four copies of the current state to the left, right, top, and bottom of the current state.</li>
  <li>Tile four copies of the current state slightly angled (about 27 degrees clockwise) from the left, right, top, and bottom of the current state.</li>
  <li>Alternate between steps 2 and 3 until you run out of graph paper.</li>
</ol>

<p>In animated form:</p>

<p><img src="https://chriskw.xyz/images/fractal/wallflower.gif" alt="Gif of the first 7 iterations of constructing the fractal"></p>

<p><em>Shoutout to <a href="https://www.manim.community/">manim</a> and <a href="https://www.3blue1brown.com/">3Blue1Brown</a> for making this and many other visualizations to come possible!</em></p>

<p>Similar to the <a href="https://en.wikipedia.org/wiki/Gosper_curve">Gosper Curve</a>, the steps can
be run repeatedly to eventually cover any part of the plane, and each intermediate state can tile the plane.
If you have graph paper and free time you can try out the steps for yourself – it’s fun to
translate and trace the contour of the previous state and watch things lock into place like a puzzle.
Alternatively, a bit over a year ago I realized you could
generate the contour using an <a href="https://en.wikipedia.org/wiki/L-system">L-System</a>.
The rules are simple and consist of only 90 degree right (\(R\)) and left (\(L\)) turns:</p>

<ol>
  <li>Start with 4 right turns: \(RRRR\)</li>
  <li>Each iteration run the following substitutions: \(R \rightarrow RLR, L \rightarrow RLL\)</li>
</ol>

<p>For example, after applying the first iteration of substitutions you should have \(RLRRLRRLRLR\).
The following images demonstrate the first few applications of the rule:</p>

<p><img src="https://chriskw.xyz/images/fractal/contouriter0to4.jpg" alt="Static image of iterations 0 to 4"></p>

<p><em>Yellow=next turn (going clockwise) will be to the left, Blue=to the right</em></p>

<p>And in animated form:</p>

<p><img src="https://chriskw.xyz/images/fractal/contour.gif" alt="Gif of the first 4 iterations of constructing the boundary"></p>

<p>Both methods end up generating equivale– hold up! When I first tried
the L-System method a year ago I <em>thought</em> it generated the same contour as the wallflower.
In other words, I tried drawing the fourth iteration and its many right angles free
hand and gave up partway thinking “well it worked for the first 3 iterations, therefore it works in general \(\text{Q.E.D.}\)”
It was only when I started making the animations for this post that I realized
the two don’t quite match up. Comparing the 4th iteration from each method:</p>

<p><img src="https://chriskw.xyz/images/fractal/woops.jpg" alt="Annotated comparison between two different versions of fourth iteration"></p>

<p>Side by side, the main difference between the two is how the “copies”
of the 3rd iteration are placed around the original in the center. The first method (let’s call it
“drag and drop”) places the copies directly above, below, etc… around the center, while
the L-System method places them diagonally. The contour produced by the L-System
approach is already documented in a few places:</p>
<ul>
  <li>Wikipedia article for <a href="https://en.wikipedia.org/wiki/List_of_fractals_by_Hausdorff_dimension">List of fractals</a> (listed as “Quadratic von Koch island”)</li>
  <li>Wikipedia article for <a href="https://en.wikipedia.org/wiki/Koch_snowflake">Koch snowflake</a> (listed as “Quadratic Flake”, with file name “<a href="https://imagej.net/ij/plugins/fractal-generator/index.html">Karperien</a> Flake”)</li>
  <li>Wikipedia article for <a href="https://en.wikipedia.org/wiki/Minkowski_sausage">Minkowski Sausage</a></li>
  <li>Jeffrey Ventrella’s generator for <a href="http://www.fractalcurves.com/Root5.html">Mandelbrot’s Quartet</a></li>
</ul>

<p>Meanwhile, the variation made from the drag and drop method doesn’t appear anywhere I can find
via Google image search and Wikipedia surfing. Why would one way be so much more common than the other?
With some fiddling around I found rules to generate my wall’s version of the fractal (\(L \rightarrow RLR, R \rightarrow LLR\)), however they have a strange
effect that seems to “flip” the direction you draw the contour at each step, e.g. the first step
goes from \(RRRR\) (majority right turns) to \(LLRLLRLLRLLR\) (majority left turns).
Another natural question is if the original L-System doesn’t place copies aligned with
the axes, what angle is it placing them at? It turns out the “flipping” behavior,
the L-System’s angles, and the seemingly arbitrary “about 27 degrees” from the beginning
are connected in a surprising way. But before we get to that, lets take a detour to review an important topic:</p>

<h2 id="how-to-count">How to count</h2>

<p>Procrastinating for over a decade has given me plenty of opportunities to look at the fractal
with fresh eyes as I was introduced to new branches of math. During freshman year of college I learned how to show the cardinality
of the natural numbers \(\mathbb{N}\) is equal to the cardinality of pairs of natural
numbers \(\mathbb{N}^2\) using the <a href="https://en.wikipedia.org/wiki/Pairing_function#Cantor_pairing_function">Cantor pairing function</a>
to “dovetail” across the Cartesian plane. Similarly, I learned you could map the natural
numbers onto a spiral to show \(\mathbb{N}\) has the same cardinality as pairs of integers \(\mathbb{Z}^2\).</p>

<p><img src="https://chriskw.xyz/images/fractal/cantorpairing.png" alt="Cantor pairing function">
<img src="https://chriskw.xyz/images/fractal/z2spiral.jpg" alt="Z^2 spiral"></p>

<p><em>Credit to <a href="https://en.m.wikipedia.org/wiki/Pairing_function#/media/File%3ACantor's_Pairing_Function.svg">Wikipedia</a> for the Cantor pairing function image, <a href="http://stanford.edu/~dntse/classes/cs70_fall09/n20_fall09.pdf">UCB CS70</a> for the spiral</em></p>

<p>Both of these reminded me of how the wallflower fills space in the Cartesian
plane by building outwards from the origin. To use the wallflower’s structure as a pairing
function we would need to find a way to assign an “order” when we place each
square, preferably in a way that complements the recursive nature of its construction.
A natural starting point would be to use the center of the fractal as 0. From there we can number
the surrounding four squares added in the first iteration as 1, 2, 3 and 4
in clockwise order:</p>

<p><img src="https://chriskw.xyz/images/fractal/numbering1.jpg" alt="Numbering 0 to 4"></p>

<p>Now we’re faced with the question of how to label the squares from the next iteration. One
way would be to number them in the order they appear scanning from top down, left to right:</p>

<p><img src="https://chriskw.xyz/images/fractal/numberingjank.jpg" alt="Jank numbering 0 to 24"></p>

<p>For lack of better words, this doesn’t feel very fractally – the order here seems unrelated to recursive
structure of fractal. What if instead we tried to reuse the “middle out” approach used for
0 to 4? After all, each “petal” is a copy of the first iteration we’ve
already given an ordering to. Reusing the clockwise scheme from 0 to 4 within each blue
petal, and <em>across</em> each blue petal (the dashed lines):</p>

<p><img src="https://chriskw.xyz/images/fractal/numbering2.jpg" alt="Numbering 0 to 24"></p>

<p>And extending to the next set of petals:</p>

<p><img src="https://chriskw.xyz/images/fractal/numbering3.jpg" alt="Numbering 0 to 124"></p>

<p>As chaotic as it may look at first glance, a few interesting properties emerge
if we look at the positions of certain numbers. If we isolate our view to just multiples of 5,
a scaled up grid tilted about 27 degrees clockwise is formed:</p>

<p><img src="https://chriskw.xyz/images/fractal/just5s.jpg" alt="Just multiples of 5"></p>

<p>If we only look at the numbers of the form \(5n + 1\),
we get the previous grid but scooted up by 1 square:</p>

<p><img src="https://chriskw.xyz/images/fractal/just5plus1s.jpg" alt="Just 5n + 1"></p>

<p>And if we look at just multiples of 25 we get another grid, scaled up even further:</p>

<p><img src="https://chriskw.xyz/images/fractal/just25s.jpg" alt="Just multiples of 25"></p>

<p>The number 5 appears to have a special relationship with the fractal. The reason becomes
apparent if you look at the number of squares in each iteration. The 0th iteration
is a single square, the first iteration has 5, the second has 25, the third has 125, etc… Since
each iteration is constructed by taking the previous state and adding 4 additional copies,
it scales up by a factor of 5 in each step. Given the special relationship
with multiples of 5 and powers and 5, it’s tempting to redo the labeling while counting
in base 5 instead of base 10. Doing so we get this:</p>

<p><img src="https://chriskw.xyz/images/fractal/numberingbase5.jpg" alt="Numbering in base 5"></p>

<p>This is a ton of information, but if we focus in on just the iteration 3 pattern and its copy to the right you might
notice something interesting:</p>

<h2 id="how-to-add">How to add</h2>

<p><img src="https://chriskw.xyz/images/fractal/numberingsidebyside.jpg" alt="Iteration 3 + copy to the right"></p>

<p>If you take any number on the left and check 5 spaces to the right, you’ll find
its copy on the teal petal. Comparing the numbers between cells, they always seem to be
the original value plus 200. For example, 5 spaces to the right of
44 you’ll find 244, and 5 spaces to the right of 3 is 203. In some sense, adding 200
seems to encode “shifting” 5 spaces to the right. This “shifting” property isn’t unique to 200
either: consider the positions of 0, 1, 2, 3, and 4 relative to 30, 31, 32, 33, and 34.</p>

<p>If you stare for long enough you might notice by expanding any number, say 231 = 200 + 30 + 1,
we can use each number in the expanded form to find its location on the grid. In this case, we
can find vectors corresponding to 200, 30, and 1 on the grid and add them
together to get the location of 231:</p>

<p><img src="https://chriskw.xyz/images/fractal/vector231.gif" alt="231 decomposition vectors"></p>

<p>You can test out other numbers using the same strategy of breaking down the number into
its 1s, 10s, 100s, etc… places and adding vectors. Assuming
this works in general, all we need to find the position of any number on the grid is to know the position of each number
in its expanded form, and then add them together. Let’s <del>abuse</del> introduce some notation, defining \(\vec{n}\) as the vector
pointing to where the number \(n\) sits on the grid. Using our 1 digit values as an example:</p>

<p>\(\begin{align}
    \overrightarrow{0} &amp;= \begin{bmatrix}
           0 \\
           0 \\
         \end{bmatrix}
  \end{align},\)\(\begin{align}
    \overrightarrow{1} &amp;= \begin{bmatrix}
           1 \\
           0 \\
         \end{bmatrix}
  \end{align},\)\(\begin{align}
    \overrightarrow{2} &amp;= \begin{bmatrix}
           0 \\
           1 \\
         \end{bmatrix}
  \end{align},\)\(\begin{align}
    \overrightarrow{3} &amp;= \begin{bmatrix}
           -1 \\
           0 \\
         \end{bmatrix}
  \end{align},\)\(\begin{align}
    \overrightarrow{4} &amp;= \begin{bmatrix}
           0 \\
           -1 \\
         \end{bmatrix}
  \end{align}\)</p>

<p>With this new notation, we can stare at how “powers of 10” seem to behave:</p>

<p>\(\begin{align}
    \overrightarrow{1} &amp;= \begin{bmatrix}
           0 \\
           1 \\
         \end{bmatrix}
  \end{align},\)\(\begin{align}
    \overrightarrow{10} &amp;= \begin{bmatrix}
           1 \\
           2 \\
         \end{bmatrix}
  \end{align},\)\(\begin{align}
    \overrightarrow{100} &amp;= \begin{bmatrix}
           0 \\
           5 \\
         \end{bmatrix}
  \end{align},\)\(\begin{align}
    \overrightarrow{1000} &amp;= \begin{bmatrix}
           5 \\
           10 \\
         \end{bmatrix}
  \end{align},\)\(\begin{align}
    \overrightarrow{10000} &amp;= \begin{bmatrix}
           0 \\
           25 \\
         \end{bmatrix}
  \end{align},\)\(\begin{align}
    \overrightarrow{100000} &amp;= \begin{bmatrix}
           25 \\
           50 \\
         \end{bmatrix}
  \end{align}\)</p>

<p>Looking closely you might pick up on the pattern:</p><p>

\[\begin{equation}
\overrightarrow{(10^n)} =  \begin{cases}
5^n \begin{bmatrix}
           0 \\
           1 \\
         \end{bmatrix} &amp; \text{if } n \text{ is even} \\
5^{(n-1)} \begin{bmatrix}
           1 \\
           2 \\
         \end{bmatrix} &amp; \text{if } n \text{ is odd}
\end{cases}
\end{equation}\]

</p><p>This conditional formula was
how I initally wrote the visualization code. However it begged the question:
is there a more elegant way to compute the values without needing a conditional?
Ideally we want a transformation we could repeatedly apply to scale and rotate a vector
based on the value of \(n\), i.e. a matrix raised to the power of \(n\). With some fiddling around, we can find the matrix \(M\) and its powers:</p>

<p>\(M = \begin{bmatrix}
           -2 &amp; 1 \\
           1 &amp; 2\\
\end{bmatrix},\)\(M^2 = \begin{bmatrix}
           5 &amp; 0 \\
           0 &amp; 5\\
\end{bmatrix},\)\(M^3 = \begin{bmatrix}
           -10 &amp; 5 \\
           5 &amp; 10\\
\end{bmatrix},\)\(M^4 = \begin{bmatrix}
           25 &amp; 0 \\
           0 &amp; 25\\
\end{bmatrix}, \text{etc...}\)</p>

<p>Which conveniently matches the values we’re expecting <em>without</em> needing a conditional in the equation:</p><p>

\[\overrightarrow{(10^n)}  = M^n\overrightarrow{1} = \begin{bmatrix}
           -2 &amp; 1 \\
           1 &amp; 2\\
         \end{bmatrix}^n\begin{bmatrix}
           0 \\
           1 \\
         \end{bmatrix}\]

</p><p>Similarly we can set up equations for the other possible digits:</p><p>

\[\begin{align}
\overrightarrow{(2 \cdot 10^n)} &amp;= M^n\overrightarrow{2} = \begin{bmatrix}
           -2 &amp; 1 \\
           1 &amp; 2\\
         \end{bmatrix}^n\begin{bmatrix}
           1 \\
           0 \\
         \end{bmatrix}
\newline
\overrightarrow{(3 \cdot 10^n)} &amp;= M^n\overrightarrow{3} = \begin{bmatrix}
           -2 &amp; 1 \\
           1 &amp; 2\\
         \end{bmatrix}^n\begin{bmatrix}
           0 \\
           -1 \\
         \end{bmatrix}
\newline
\overrightarrow{(4 \cdot 10^n)} &amp;= M^n\overrightarrow{4} = \begin{bmatrix}
           -2 &amp; 1 \\
           1 &amp; 2\\
         \end{bmatrix}^n\begin{bmatrix}
           -1 \\
           0 \\
         \end{bmatrix}
\end{align}\]

</p><p>If you blur your eyes with the tears shed over the cursed notation, you might
make out a connection to number systems such as base 5 or base 10.
Similar to how in base 10 the number 1234 would expand to:</p><p>

\[\begin{aligned}
1234 &amp;= 10^3 \cdot 1 + 10^2 \cdot 2 + 10^1 \cdot 3 + 10^0 \cdot 4
\newline
1234 &amp;= 1000 + 200 + 30 + 4
\end{aligned}\]

</p><p>And in base 5:</p><p>

\[\begin{aligned}
1234_5 &amp;= 5^3 \cdot 1 + 5^2 \cdot 2 + 5^1 \cdot 3 + 5^0 \cdot 4
\newline
1234_5 &amp;= 1000_5 + 200_5 + 30_5 + 4_5
\end{aligned}\]

</p><p>We can use the matrix \(M\) as our base, and vectors as our digits to encode positions
in the fractal:</p><p>

\[\begin{aligned}
\overrightarrow{1234} &amp;= M^3\overrightarrow{1} + M^2\overrightarrow{2} + M^1\overrightarrow{3} + M^0\overrightarrow{4}
\newline
\overrightarrow{1234} &amp;= \overrightarrow{1000} + \overrightarrow{200} + \overrightarrow{30} + \overrightarrow{4}
\end{aligned}\]

</p><p>We’ve stumbled upon a number system with a matrix base and vector digits, rather than scalars!
Counting up from 0 we can get a feel for the how the number system connects to the structure
of the fractal:</p>

<p><img src="https://chriskw.xyz/images/fractal/makeitcount.gif" alt="Gif with vectors + formulas"></p>

<h2 id="determinants">Determinants</h2>

<p>You may have noticed \(20\) and \(40\)
have switched positions compared to our original numbering. This is because our choice
of \(M\) has a negative determinant \(\det(M) = -5\), which means it has the side effect of “flipping” the
orientation of space each iteration. Now that we know our fractal is linked to linear algebra,
we can visualize the connection by overlaying scaled grids representing how powers of \(M\) act on our “digit vectors”
\(\vec{1}\), \(\vec{2}\), \(\vec{3}\) and \(\vec{4}\) a la <a href="https://www.3blue1brown.com/lessons/matrix-multiplication">3Blue1Brown</a>.</p>

<p><img src="https://chriskw.xyz/images/fractal/gridoverlay.gif" alt="Overlayed grid"></p>

<p>To avoid the flipping behavior we would need to pick a matrix with a positive determinant,
for example:</p><p>

\[M^\prime = \begin{bmatrix}
           2 &amp; 1 \\
           -1 &amp; 2\\
\end{bmatrix}\]

\[\det(M^\prime) = 5\]

</p><p>Visualizing this new choice of matrix:</p>

<p><img src="https://chriskw.xyz/images/fractal/gridoverlayprime.gif" alt="Overlayed grid for M'"></p>

<p>Instead of “flipping” and realigning with the axes every other iteration, this choice of
base continually rotates our “digit vectors” clockwise.
Wait, didn’t we see a version of the fractal like this way back at the start with the L-System?
Sure enough, using \(M^\prime\) as our base reproduces the L-System version.</p>

<p><img src="https://chriskw.xyz/images/fractal/unwoops.jpg" alt="Unwoops"></p>

<p>Mystery solved! The two fractals are <em>almost</em> the same, but the one on my wall is generated using
\(M\) where \(\det(M) = -5\), while the more common one is generated from \(M^\prime\)
where \(\det(M^\prime) = 5\). The choice of matrix also sheds some light on where the seemingly
arbitrary “about 27 degrees” comes from. You may have noticed the absolute value of both
determinants is \(5\), which conveniently matches the way the fractal increases in size by a factor
of 5 each iteration. If we picked a matrix with a larger determinant, our “digit vectors” would
grow too quickly and leave behind “empty space” each iteration. For example adjusting \(M\) to give
it a determinant of \(-6\) results in:</p>

<p><img src="https://chriskw.xyz/images/fractal/det6.jpg" alt="Determinant 6"></p>

<p>Meanwhile if we pick a matrix with a smaller determinant, our “digit vectors” would grow too
slowly and iterations would overlap. Adjusting \(M\) to give it a determinant of \(-4\):</p>

<p><img src="https://chriskw.xyz/images/fractal/det4.jpg" alt="Determinant 4"></p>

<p>So ostensibly we want a matrix base with determinant \(\pm 5\). Additionally, we want our
matrix to have integer entries to ensure it always maps our digit vectors onto
whole number coordinates. It just so happens the vector \(\left\langle 1, 2 \right\rangle\)
has integer entries and magnitude \(\sqrt{5}\), meaning we can use it and one of
its 90 degree rotations as the columns of our matrix to satisfy the determinant
and whole number constraint. Computing the angle of this vector we get \(\arctan{\frac{2}{1}} \approx 63.43^\circ\),
i.e. “about 27 degrees” away from the y-axis.</p>

<h2 id="how-to-add-part-2">How to add part 2</h2>

<p>You may have noticed vector addition fails horribly in most cases other than
the expanded form ones, e.g. \(\vec{2} + \vec{2} \neq \vec{4}\). This is expected, since the choice of \(2\) and \(4\)
were to help make the connection to base 5 number systems but unrelated to the
actual direction the vectors point. It might be more appropriate to refer to 1 through 4
as up (\(\vec{1}\)), right (\(\vec{2}\)), down (\(\vec{3}\)), and left (\(\vec{4}\)). As you
might expect, opposite directions cancel eachother out, i.e. \(\vec{1} + \vec{3} = \vec{2} + \vec{4} = \vec{0}\).
But what about other combinations of additions? By looking closely at the base 5 numbering and following where
combinations of unit vectors point:</p>

<p><img src="https://chriskw.xyz/images/fractal/base5center.jpg" alt="Base 5 numbering"></p>

<p>We can build up a table based on where it appears the sum of unit vectors would fall:</p>



<table>
  <thead>
    <tr>
      <th>\(+\)</th>
      <th>\(\overrightarrow{0}\hspace{5pt}\)</th>
      <th>\(\overrightarrow{1}\hspace{5pt}\)</th>
      <th>\(\overrightarrow{2}\hspace{5pt}\)</th>
      <th>\(\overrightarrow{3}\hspace{5pt}\)</th>
      <th>\(\overrightarrow{4}\hspace{5pt}\)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>\(\overrightarrow{0}\hspace{5pt}\)</td>
      <td>\(\overrightarrow{0}\)</td>
      <td>\(\overrightarrow{1}\)</td>
      <td>\(\overrightarrow{2}\)</td>
      <td>\(\overrightarrow{3}\)</td>
      <td>\(\overrightarrow{4}\)</td>
    </tr>
    <tr>
      <td>\(\overrightarrow{1}\hspace{5pt}\)</td>
      <td>\(\overrightarrow{1}\)</td>
      <td>\(\overrightarrow{14}\)</td>
      <td>\(\overrightarrow{13}\)</td>
      <td>\(\overrightarrow{0}\)</td>
      <td>\(\overrightarrow{22}\)</td>
    </tr>
    <tr>
      <td>\(\overrightarrow{2}\hspace{5pt}\)</td>
      <td>\(\overrightarrow{2}\)</td>
      <td>\(\overrightarrow{13}\)</td>
      <td>\(\overrightarrow{41}\)</td>
      <td>\(\overrightarrow{44}\)</td>
      <td>\(\overrightarrow{0}\)</td>
    </tr>
    <tr>
      <td>\(\overrightarrow{3}\hspace{5pt}\)</td>
      <td>\(\overrightarrow{3}\)</td>
      <td>\(\overrightarrow{0}\)</td>
      <td>\(\overrightarrow{44}\)</td>
      <td>\(\overrightarrow{32}\)</td>
      <td>\(\overrightarrow{31}\)</td>
    </tr>
    <tr>
      <td>\(\overrightarrow{4}\hspace{5pt}\)</td>
      <td>\(\overrightarrow{4}\)</td>
      <td>\(\overrightarrow{22}\)</td>
      <td>\(\overrightarrow{0}\)</td>
      <td>\(\overrightarrow{31}\)</td>
      <td>\(\overrightarrow{23}\)</td>
    </tr>
  </tbody>
</table>

<p>The table is symmetric across the diagonal meaning addition is commutative, as expected
for vector addition. More importantly, several additions result in 2 digit values. While it might
not seem like a big deal, it means when doing larger additions we have to worry about
carrying over values to the next digit. For example, if we want to find the number directly
above 22, we can compute \(\overrightarrow{22} + \overrightarrow{1}\). Using
traditional long addition and carrying notation:</p><p>

\[\begin{array}{cccc}
	    &amp; \overset{1}{\vphantom{0}} &amp; \overset{1}{2} &amp; 2 \\
	  + &amp;   &amp;   &amp; 1 \\
        \hline
	    &amp; 1 &amp; 3 &amp; 3 \\
	\end{array}\]

</p><p>If you’re a bit confused, remember \(\overrightarrow{2} + \overrightarrow{1} = \overrightarrow{13}\).
And if you’re suprised this works at all, join the club! Since this is a blog post and not a proof,
I leave sanity checking this addition scheme works in general to the reader.</p>



<p>The concept of using things outside of \(\mathbb{N}\) in a number system wasn’t totally unfamiliar thanks to <a href="https://en.wikipedia.org/wiki/Balanced_ternary">Balanced Ternary</a>
which uses \(-1\), \(0\), and \(1\) as digits, and a base of \(3\). If you imagine balanced
ternary as being 1 dimensional along the x-axis, the wallflower can be seen as its 2D analog
by adding two new digits to account for the positive and negative directions of the y-axis.
An alternative scheme for <a href="https://en.wikipedia.org/wiki/Generalized_balanced_ternary">generalized balanced ternary</a>
already exists, and generalizes to any number of dimensions using lattices of <a href="https://en.wikipedia.org/wiki/Permutohedron">permutahedrons</a>
(at least from what I’ve been able to dig up). In 2 dimensions, this ends up being the hexagonal lattice:</p>

<p><img src="https://chriskw.xyz/images/fractal/hexagon.jpg" alt="2D generalized balanced ternary with hexagons"></p>

<p><em>Visualization of generalized balanced ternary in 2D using hexagons from <a href="https://en.wikipedia.org/wiki/Generalized_balanced_ternary#/media/File:Visualization_of_three-digit_2D_generalized_balanced_ternary_numbers.pngkipedia.org/wiki/Generalized_balanced_ternary#/media/File:Visualization_of_three-digit_2D_generalized_balanced_ternary_numbers.png">Wikipedia</a>. See also <a href="https://en.wikipedia.org/wiki/Gosper_curve">Gosper Curve</a>,
which is like a hexagonal wallflower.</em></p>

<p>Another exotic number system is <a href="https://en.wikipedia.org/wiki/Quater-imaginary_base">Quater-imaginary Base</a>,
which uses the imaginary value \(2i\) as its base, and \(0\), \(1\), \(2\) and \(3\) as digits.
If you imagine complex numbers as vectors, and imagine \(2i\) as a matrix that performs a scale and rotation,
we can convert this number system into our cursed notation:</p>

<p>\(M_{2i} = \begin{bmatrix}
           0 &amp; -2 \\
           2 &amp;  0\\
         \end{bmatrix},\)\(\overrightarrow{0} = \begin{bmatrix}
           0 \\
           0 \\
         \end{bmatrix},\)\(\overrightarrow{1} = \begin{bmatrix}
           1 \\
           0 \\
         \end{bmatrix},\)\(\overrightarrow{2} = \begin{bmatrix}
           2 \\
           0 \\
         \end{bmatrix},\)\(\overrightarrow{3} = \begin{bmatrix}
           3 \\
           0 \\
         \end{bmatrix}\)</p>

<p>Alternatively, we can convert the positive determinant matrix \(M^\prime\) from earlier into its
complex number equivalent to get a base \(2+i\) number system. <a href="https://ideophilus.wordpress.com/2016/10/17/balanced-base-2i-and-some-gratuitous-fractals/">Balanced base 2+i (and some gratuitous fractals)</a>
by Timothy James McKenzie Makarios explores this concept. I ran into this while looking for visualizations of
quater-imaginary base on Google images for this section, only to realize this connection had been
made back in 2016. Somewhat embarassingly I found this after I made the animation at the
start, only to find the author had already beaten me to that as well, although
using the \(M^\prime\) version of the fractal instead of \(M\) (as far as I know \(M\)
cannot be encoded as a complex number).</p>

<p>When I realized the matrix base number system worked at all I started
searching around to see if anyone else had made the connection between fractals, tesselations, linear algebra
and number systems. Digging around:</p>
<ul>
  <li><a href="https://math.stackexchange.com/questions/43054/is-there-a-number-system-with-matrix-base">Project BinSys</a> led by Attila Kovács
is focused on finding matrix bases specifically where the determinant is 2, for a generalized form of binary.</li>
  <li><a href="https://people.clas.ufl.edu/avince/files/SIDMARepTess.pdf">Replicating Tesselations</a>
by Andrew Vince does all the rigorous math stuff to formalize what I’ve been trying to
describe through vigorous handwaving, and generalizes to any lattice rather than just \(\mathbb{Z}^2\).
    <ul>
      <li>Here you can also find proofs for the alternative way to generalize balanced ternary
  into higher dimensions.</li>
    </ul>
  </li>
</ul>

<p>Speaking of handwaving: the next section is now fully in the territory of “things I
started to think about a week ago when I started writing this,” so any semblance of rigor
that came from having many years to think about the problem is out the window. Instead
I’ll be relying on my mental model of linear algebra, which is “if it sounds like it’s true
and looks like it’s true, it’s probably true.”</p>

<h2 id="to-go-even-further-beyond">To go even further beyond</h2>

<p>Middle school me was really into Minecraft, so naturally I always wondered: would the fractal work with
cubes? Specifically, is there a way to create a 3D version of the fractal by
starting with cube and copying outwards in groups of six to form a “3D plus”? This mostly
comes down to what properties we want to include when we generalize to a 3x3 matrix. The
ones that beckoned to me from the ether are:</p>
<ul>
  <li>All of the entries in the matrix must be integers. This is needed so when we apply
the matrix base to our vector digits (6 unit vectors sitting on the axes) they still
have integer values for each component. In the Vince paper this is formalized as “endomorphism of \(\Lambda\)”,
i.e. a mapping from the lattice \(\Lambda = \mathbb{Z}^3\) back onto itself.</li>
  <li>Each column vector in the matrix should have a Hamming distance of 3 from the origin.
This constraint ensures the 6 copies of the “3D plus” we create on the second
iteration don’t overlap with the original centered on the origin, but are near enough to still
be adjacent to it.</li>
  <li>We want a matrix with determinant \(\pm\)7. Since each iteration of the fractal adds 6 new copies,
we increase the size of the fractal by 7 times each step. If we want to “pack” together these
copies efficiently we need to make sure the matrix we apply scales up
inputs by a factor of 7 as well.</li>
</ul>

<p>Brute force searching through triplets of vectors with Hamming distance of 3, we get this nifty 3x3
matrix that checks all of the boxes:</p><p>

\[\begin{bmatrix}
            2 &amp; -1 &amp; 0 \\
           -1 &amp;  0 &amp; 2 \\
            0 &amp; -2 &amp; 1 \\
         \end{bmatrix}\]

</p><p>Visualizing gives us:</p>

<p><img src="https://chriskw.xyz/images/fractal/3d.gif" alt="3D iterations 0 through 3"></p>

<p>Wow, it looks terrible! One problem that stands out immediately is later iterations seem to be “smooshed”
resulting in spots where previous iterations are exposed.
Looking closely at iteration 2, you might notice we can comb over the bald spots
by adding two more “3D pluses” centered on \(\left\langle 1, 1, 1\right\rangle\) and \(\left\langle-1, -1, -1\right\rangle\).</p>

<p><img src="https://chriskw.xyz/images/fractal/bandaid.gif" alt="Iteration 2 with bandaid"></p>

<p>Here we added two new pluses marked in yellow, and visualize the location of the centers
of all 8 pluses. For a bandaid fix it feels like it works a little too well. Looking at just
the center points of our 8 new pluses they are arranged like the vertices of a warped cube.
I’m still not entirely sure what to make of this, although it feels like it’s related to
the fact that cubes (8 vertices, 6 faces) are the dual solid to octahedrons (6 vertices, 8 faces).
It’s obviously tempting to try to take this new cube and make 6 copies of it, but to avoid
derailing this post too much let’s save that for another day.</p>

<p>Visually, the problem with iteration 2 seems to be that the 3D pluses aren’t placed symmetrically
around the center, causing the fractal to expand in a non-uniform way. Manually trying to find a more symmetrical
arrangement of 6 pluses is tricky, feeling a bit like trying to <a href="https://en.wikipedia.org/wiki/Hairy_ball_theorem">comb a hairy ball</a>.
A sufficient (and possibly necessary) condition to prevent the smooshing behavior is
to pick a matrix where each column is mutually orthogonal and has the same magnitude. I suspect if
we include this with the prior constaints it’s impossible to satisfy in 3D. Each integer valued
column vector would need a magnitude of \(\sqrt[3]{7}\), so given that \(x, y\) and \(z\) are integers,
we must solve:</p><p>

\[\sqrt{x^2+y^2+z^2} = \sqrt[3]{7}\]

\[x^2 + y^2 + z^2 = 7^{2/3}\]

</p><p>This can never be true since the left hand side is always an integer, while the right hand
side is irrational. Luckily, if we go up to four dimensions the math works out in our favor. In 4 dimensions
the components of each vector must satisfy:</p><p>

\[\sqrt{x^2 + y^2 + z^2 + w^2} = \sqrt[4]{9}\]

\[x^2 + y^2 + z^2 + w^2 = 3\]

</p><p>Which works if we let 3 out of 4 of the entries to be \(\pm 1\),
and set the last to \(0\). It turns out there’s plenty of space in hyperspace, giving us many
possible matrices with columns of this form that satisfy all previous conditions. The
following matrix has one extra property that we’ll cover briefly near the end:</p><p>

\[\begin{bmatrix}
0 &amp; -1 &amp; -1 &amp; -1 \\
1 &amp;  0 &amp; -1 &amp;  1 \\
1 &amp;  1 &amp;  0 &amp; -1 \\
1 &amp; -1 &amp;  1 &amp;  0 \\
\end{bmatrix}\]

</p><p>Now that we have a suitable matrix, we can attempt to visualize our 4D fractal.
One way to do this is to take 3D “slices” of 4D space by fixing the
value of \(w\):</p>

<p><img src="https://chriskw.xyz/images/fractal/4d_iter0.gif" alt="4D iteration 0"></p>

<p>It turns out the base case is boring regardless of how many dimensions we give it. Moving
on to iteration 1:</p>

<p><img src="https://chriskw.xyz/images/fractal/4d_iter1.gif" alt="4D iteration 1"></p>

<p>From here you can get a better feel for how the visualization works. The purple cubes on the
left and right that appear to be sitting at the origin are really at the \((x,y,z,w)\)
coordinates of \((0,0,0,-1)\) and \((0,0,0,1)\) respectively.</p>

<p><img src="https://chriskw.xyz/images/fractal/4d_iter2.gif" alt="4D iteration 2"></p>

<p>We can see parts of iteration 1 still poking through in iteration 2, which is concerning given this
was a symptom of the squishing behavior we saw in 3D. However looking closely, the squishing
behavior doesn’t seem as bad yet. If you really twist your mind around the concept of 4
dimensions, you might be able to see that while the two pluses in \(w=0\) don’t
seem to be balanced, there are 3 pluses sitting to the left (\(w=-1\)) and 3 more to the
right (\(w=1\)) that you could imagine as being orthogonal to the \(w=0\) ones. The trios
of cubes sitting at each side (\(w=\pm 2\)) are part of the 4D pluses that poke through
the 4th dimension into the slices on the ends.</p>

<p><img src="https://chriskw.xyz/images/fractal/4d_iter3.gif" alt="4D iteration 3"></p>

<p>My main takeaway from this is that while iteration 2
can still be seen, iteration 1 has now been completely covered.
Technically iteration 3 extends farther out in the \(w\) dimension, but at this point it’s
difficult to comprehend the fractal anyway. I imagine this is the sort of thing my higher dimensional analog would
put up on the 4D hypersurface of their room’s 5D walls to admire in its full glory, so I’m dubbing it “the orthotopeflower.”
Unfortunately my apartment is measured in square feet and not hypercubic feet, so
it’s difficult for me to fully appreciate it. There are a couple of issues with the “3D slices”
approach of visualizing in 4D:</p>
<ul>
  <li>It extends way too quickly in the horizontal direction, wasting precious screen
(or wall) real estate. Notably in iteration 3 we
need to add 2 more slices to each side to visualize the whole thing.</li>
  <li>My inferior 3 dimensional eyes can’t see the interior of 3D objects (unlike how I’m
able to see the interior of colored in 2D squares on a piece of paper), making it
hard to fully appreciate the structure.</li>
</ul>

<p>To get around both of these limitations we can use the following 7x7 grid of 7x7 grids to visualize it
a la the very first animation of this post:</p>

<p><img src="https://chriskw.xyz/images/fractal/grow4d.gif" alt="Flat 4D animation"></p>

<p><em><a href="https://chriskw.xyz/images/fractal/static4d.jpg">Here’s a static image</a> of the last iteration if you want to admire it. If this isn’t nice, what is?</em></p>

<p>Each smaller grid shows a slice of -3 to 3 on the x and y axes. The “grid of grids” represent
-3 to 3 along the z and w axes. Whenever a square crosses from one small grid
to another it’s really being translated through the z or w axis. Squares that appear to
fade in or fade out are moving in or out of the 7x7x7x7 “viewing window” in 4 dimensions.
Compared to the line of 3D slices, this approach uses screen real estate a bit better
(growing as a square instead of in a line), and lets you see the interior of the entire
fractal without obscuring previous iterations. Plus this design would go nicely with
the existing fractal on my wall.</p>

<p>If we’re willing to discard all of the flourishes from the animation and assign 1 pixel
per tile in the fractal we can increase our viewing window up to 31x31x31x31:</p>

<p><img src="https://chriskw.xyz/images/fractal/31x31x31x31.png" alt="31x31x31x31 visualization"></p>

<p>It’s a lot to take in, but at the very least seems to confirm that the fractal consistently
expands outwards without excessive smooshing like we saw in 3D. And personally, I think
it would make a lovely quilt or picnic blanket. In particular these slices near the very
center are remarkably pleasant:</p>

<p><img src="https://chriskw.xyz/images/fractal/quilt.png" alt="Aesthetically pleasing slices 2D slices of the fractal"></p>

<p>A natural question is if we can continue into higher dimensions. Sadly I suspect the
answer is no. Applying all our constraints from earlier we need a dimension \(d\) such that:</p>

<p>\(\sqrt[d]{2d+1} \in\)\(\{\sqrt{3^2}, \sqrt{1^2 + 2^2}, \sqrt{1^2+1^2+1^2}\}\)</p>

<p>The left hand side is the magnitude each column vector needs to be for a matrix with \(d\) mutually
orthogonal columns to have determinant \(2d+1\) so that it scales inputs enough to fit the \(2d\) copies added each iteration.
The right hand side is the set of possible magnitudes of integer valued vectors that have a Hamming distance of 3 away from the origin, so
the copies created in the second iteration touch but don’t intersect with the first iteration.
Graphing this, it looks like the only dimensions where these can be satisifed are 1 (balanced
ternary), 2 (the wallflower/quadratic flake), and 4 (the orthotopeflower).</p>

<p><img src="https://chriskw.xyz/images/fractal/desmos.jpg" alt="Demos graph of viable dimensions"></p>

<p>Finally, as mentioned earlier, the choice of matrix to use as the base of our 4D number system was special. In particular
it encodes the quaternion \(i+j+k\), meaning similar to quater imaginary base we now
have a way to encode quaternions in “balanced nonary quaternion base”. In this scheme
the 9 possible digits are \(0\), \(\pm1\), \(\pm i\), \(\pm j\) and \(\pm k\), with base \(i+j+k\). Since I’m not too familiar
with quaternions and still not entirely sure if this actually works, I’ll be delegating
this problem to a future version of me who knows more math. This strategy seemed to work
pretty well last time.</p>

<h2 id="closing-thoughts">Closing thoughts</h2>

<p>I once had a dream about a post-scarcity society that had to work around the problem of
people not having any motivation to do anything, since all their basic needs were met.
To give people something to do, every few years everyone over a certain age was expected
to report on something beautiful they learned or discovered about the world, otherwise
they’d be turned into soylent or something (Note: post-scarcity \(\neq\) utopia). Anyway, I’d like to
imagine the discovery of a strange flower with jigsaw-like petals blooming endlessly across 4
dimensional space would be enough to keep me off the chopping block for awhile.</p>

<p>I finally got around to this in an attempt attempt to reignite some passion for math and programming
after a period of burnout. It turns out my younger
self left behind the perfect gift in the form of a scavenger hunt across the domains of fractals, number systems,
linear algebra and higher dimensions. It makes me curious about how many other interesting
ideas other people have lying around in plain sight as sketches or To Do’s.</p>

<p>If this post comes off as a bit rambly from the many twists and turns between domains it’s
because I tried to follow the path I took while haphazardly picking up and forgetting
about the problem over the years. There are a handful of spots where you might ask “how did you know
doing this specific thing would lead to that?” The simple answer is I had no clue if any of this
would lead anywhere, I just tried different things on a whim and this post outlines the parts that stuck.
Hopefully by writing and visualizing my lines of reasoning I’m able to make the connections a bit more accessible
for future fractal fiddlers finding themselves falling face first down the same rabbit hole.</p>

<p>As a final twist, an astute reader may have
noticed none of the visualizations made for this post
matched the fractal on my wall in the post’s thumbnail. The 4th iteration (green) is copied about 27
degrees in the <em>wrong</em> direction:</p>

<p><img src="https://chriskw.xyz/images/fractal/closingwoops.jpg" alt="Closing woops"></p>

<p>In a fun case of “why do I remember this, but not what I ate for dinner 2 days ago,” I
remember my exact reasoning for doing this over a decade ago: I thought the fractal
would unalign itself from the cardinal directions if I always tilted it off the axes in the
same direction. As we saw earlier with \(M\) vs \(M^\prime\) my intuition to compensate for tilt almost made sense, other
than the fact it already corrects itself in alternating steps. I was a bit
embarassed about this until I remembered even Donald Knuth
<a href="https://www.youtube.com/watch?v=v678Em6qyzk">made a wrong turn</a> when putting up a fractal on his wall.
Fools rarely differ!</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MCP explained without hype or fluff (139 pts)]]></title>
            <link>https://blog.nilenso.com/blog/2025/05/12/mcp-explained-without-hype-or-fluff/</link>
            <guid>44063141</guid>
            <pubDate>Thu, 22 May 2025 15:39:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.nilenso.com/blog/2025/05/12/mcp-explained-without-hype-or-fluff/">https://blog.nilenso.com/blog/2025/05/12/mcp-explained-without-hype-or-fluff/</a>, See on <a href="https://news.ycombinator.com/item?id=44063141">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Model Context Protocol, like most protocols, solves the M ⨯ N integration problem by turning it into an M + N integration problem.</p>

<p>An AI client application that speaks this protocol does not have to figure out how to fetch data or take actions specific to a platform.</p>

<p><img src="https://blog.nilenso.com/images/blog/mcp.jpg" alt=""></p>

<p>MCP may or may not make your AI smarter, or improve your product, but it will reduce the friction to integrate against other applications that already support MCP. This may or may not be important to you.</p>

<p>The protocol specifies MCP Servers, that generally connect to data sources and expose tools specific to it. Then there are MCP clients, which are a part of AI applications. They can connect to any MCP Server, typically through a configuration that specifies how to connect to or run the server.</p>

<p>The servers, more commonly implemented than clients, may expose:</p>

<ul>
  <li><strong>Tools</strong> that the LLM can call, eg, <code>fetch_file</code> for a filesystem or <code>send_mail</code> for a mail client integration.</li>
  <li><strong>Prompts</strong>, which are reusable templates of instructions or multi-step conversations for the LLM, that are intended to be user-controlled.</li>
  <li><strong>Resources</strong> that are exposed via URIs; it’s up to the client application’s design to decide how these are fetched or used.</li>
  <li><strong>Sampling</strong>, which allows servers to request LLM completions on the client application, which is useful for agentic patterns and running context-aware inference without needing to receive all the contextual data from the client.</li>
</ul>

<p>There are a few more functions and nuances to servers, but these are what broadly stood out to me. Most servers that I have seen or used mostly just expose tool calls.</p>

<h2 id="a-tiny-concrete-example-an-mcp-server-for-open-data-access">A tiny concrete example: an MCP server for Open Data access</h2>

<p>I wrote a tiny MCP server to expose actions to take on CKAN, an open source data management system that’s used by Governments and other organisations to publish open datasets. CKAN has a web interface that links to these tagged datasets, which are usually semi-structured (CSVs, XLS) or totally unstructured (PDF reports and papers).</p>

<p><img src="https://blog.nilenso.com/images/blog/screenshot-2025-05-14-at-15.48.51.png" alt="A view of the CKAN interface"></p>

<p>This is not particularly conducive to discovery and drilling through data. It’s also significant friction to connect dots across datasets. I thought it would be nice to have an AI application that can access all the datasets on CKAN and make sense of it. Open Data is as useful as the insights that can be extracted from it.</p>

<p>One way for me to have approached this is to write an AI application from scratch encoded with knowledge about all the CKAN REST APIs. Unfortunately, this would have “locked in” AI use of CKAN open data sets to just my application. <a href="https://en.wikipedia.org/wiki/Information_wants_to_be_free">And data, especially Open Data wants to be free</a>.</p>

<p>What I really wanted is a well-known “doorknob” that a lot of AI applications and agents in the world would know how to open. This is what MCP servers do. I wrote one in a couple of hours.</p>

<p>I used the official MCP Python SDK and defined some tools. Here’s an excerpt of what that looks like:</p>

<div><pre><code><span>@mcp.tool</span><span>()</span>
<span>async</span> <span>def</span> <span>list_tags</span><span>(</span><span>query</span><span>:</span> <span>Optional</span><span>[</span><span>str</span><span>]</span> <span>=</span> <span>None</span><span>,</span> <span>limit</span><span>:</span> <span>int</span> <span>=</span> <span>50</span><span>,</span> <span>ctx</span><span>:</span> <span>Context</span> <span>=</span> <span>None</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>"""</span><span>List available tags in CKAN.

    Args:
        query: Optional search string to filter tags
        limit: Maximum number of tags to return

    Returns:
        A formatted string containing available tags.
    </span><span>"""</span>
    <span># code to list all the tags used to tag data, via the CKAN API
</span>
<span>@mcp.tool</span><span>()</span>
<span>async</span> <span>def</span> <span>search_datasets</span><span>(</span>
    <span>query</span><span>:</span> <span>Optional</span><span>[</span><span>str</span><span>]</span> <span>=</span> <span>None</span><span>,</span>
    <span>tags</span><span>:</span> <span>Optional</span><span>[</span><span>List</span><span>[</span><span>str</span><span>]]</span> <span>=</span> <span>None</span><span>,</span>
    <span>organization</span><span>:</span> <span>Optional</span><span>[</span><span>str</span><span>]</span> <span>=</span> <span>None</span><span>,</span>
    <span>format</span><span>:</span> <span>Optional</span><span>[</span><span>str</span><span>]</span> <span>=</span> <span>None</span><span>,</span>
    <span>limit</span><span>:</span> <span>int</span> <span>=</span> <span>10</span><span>,</span>
    <span>offset</span><span>:</span> <span>int</span> <span>=</span> <span>0</span><span>,</span>
    <span>ctx</span><span>:</span> <span>Context</span> <span>=</span> <span>None</span>
<span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>"""</span><span>Search for datasets with various filters.

    Args:
        query: Free text search query
        tags: Filter by tags (list of tag names)
        organization: Filter by organization name
        format: Filter by resource format (e.g., CSV, JSON)
        limit: Maximum number of datasets to return
        offset: Number of datasets to skip

    Returns:
        A formatted string containing matching datasets.
    </span><span>"""</span>
    <span># code to handle searches, using the CKAN API
</span>
<span>@mcp.tool</span><span>()</span>
<span>async</span> <span>def</span> <span>get_resource_details</span><span>(</span><span>resource_id</span><span>:</span> <span>str</span><span>,</span> <span>ctx</span><span>:</span> <span>Context</span> <span>=</span> <span>None</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>"""</span><span>Get detailed information about a specific resource (file/data).

    Args:
        resource_id: The ID of the resource

    Returns:
        A formatted string containing resource details.
    </span><span>"""</span>
    <span># code to read the details and get the link to a specific resource, using the CKAN API
</span></code></pre></div>

<p>The details of the SDK are better explained in official guides, but the gist of it is that it is an abstraction over JSON-RPC request-response messages that are defined in the protocol. The server I have implemented runs locally, launched as a subprocess by the client app and uses the stdio streams to pass these protocol messages around. Remote MCP servers are a thing as well.</p>

<p>After I wrote this server, I exposed it to the Claude desktop app, which is also an MCP client by editing <code>claude_desktop_config.json</code>. I pointed it to <a href="https://justicehub.in/">JusticeHub</a>, a CKAN instance that contains legal and justice data, created by the folks at <a href="https://civicdatalab.in/">CivicDataLabs</a>.</p>

<div><pre><code><span>{</span><span>
  </span><span>"mcpServers"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"CKAN Server"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"command"</span><span>:</span><span> </span><span>"/Users/atharva/.local/bin/uv"</span><span>,</span><span>
      </span><span>"args"</span><span>:</span><span> </span><span>[</span><span>
        </span><span>"run"</span><span>,</span><span>
        </span><span>"--with"</span><span>,</span><span>
        </span><span>"httpx"</span><span>,</span><span>
        </span><span>"--with"</span><span>,</span><span>
        </span><span>"mcp[cli]"</span><span>,</span><span>
        </span><span>"mcp"</span><span>,</span><span>
        </span><span>"run"</span><span>,</span><span>
        </span><span>"/Users/atharva/ckan-mcp-server/main.py"</span><span>
      </span><span>],</span><span>
      </span><span>"env"</span><span>:</span><span> </span><span>{</span><span>
        </span><span>"CKAN_URL"</span><span>:</span><span> </span><span>"https://justicehub.in"</span><span>
      </span><span>}</span><span>
    </span><span>}</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>
</span></code></pre></div>

<p>This allowed me to use this data through Claude.</p>

<p><img src="https://blog.nilenso.com/images/blog/screenshot-2025-05-15-at-16.51.51.png" alt="A screenshot of a conversation with an AI assistant about exploring JusticeHub open data. The assistant lists available datasets, tags, and organizations on the JusticeHub platform. The conversation shows multiple function calls like list_datasets, list_tags, list_organizations, and search_datasets to explore different aspects of the data."></p>

<p><img src="https://blog.nilenso.com/images/blog/screenshot-2025-05-15-at-16.52.08.png" alt=""></p>

<p>Claude discovered my MCP server and gave me a summary of what kind of data was available in JusticeHub.</p>

<p><img src="https://blog.nilenso.com/images/blog/screenshot-2025-05-14-at-14.58.41.png" alt="A continuation of the conversation showing the assistant's comprehensive overview of the JusticeHub open data platform. It describes JusticeHub as a specialized data platform focused on the Indian justice system. The overview includes key dataset categories like Judicial System Performance, Legal Budget and Financial Data, Legal Aid and Access to Justice, and Parliamentary and Legislative Data, with bullet points listing specific datasets under each category."></p>

<p>I was able to take advantage of Claude’s analysis tool to help me visualise the data in an interactive dashboard!</p>

<p><img src="https://blog.nilenso.com/images/blog/screenshot-2025-05-14-at-14.59.44.png" alt="A split-screen view showing a conversation about creating a judicial demographics dashboard on the left and the actual dashboard visualization on the right. The right side displays an &quot;Indian Judiciary Demographics Dashboard&quot; analyzing Supreme Court Justices from 1950-2019, with visualizations showing gender representation (95.6% male, 4.4% female), women's representation over time (a line graph showing gradual increase from the 1970s to 2010s), and a partial view of SC Justices appointed by decade."></p>

<p>I can envision other MCP clients in the future that could make better use of this data, beyond this basic conversational interface and tackle problems such as backlinks and provenance, while providing more structured, opinionated visualisations and analysis.</p>

<h2 id="should-i-build-an-mcp">Should I build “an MCP”?</h2>

<p>It’s worth noting that this is not a mature protocol—<a href="https://modelcontextprotocol.io/development/roadmap">it is continuously evolving</a>. But the adoption has been fantastic—I opened the first random MCP aggregating website and it lists over 4000 servers coming from various organisations and individuals. I’d estimate there’s a lot more out there.</p>

<p>Building against MCP is a clear, well-defined thing to do, something that’s rare in the volatile landscape of AI. This could explain its popularity. But it doesn’t make a good product. It’s another tool in your toolbox.</p>

<p>I (and other folks at nilenso) maintain that good products are built on a foundation that requires software engineering maturity, and this is especially true of AI products.</p>

<p>So let’s revisit what MCP brings to the table:</p>

<ul>
  <li>Turns M ⨯ N integration problem by turning it into an M + N integration problem.</li>
  <li>Decouples AI client applications from AI tools and workflows for a platform.</li>
</ul>

<p>This decoupling is not free of cost. There is extra scaffolding to make your applications talk this protocol. Your LLM performance is sensitive to prompting and tool descriptions. Adding lots of tools indiscriminately affects latencies and overall quality of your responses.</p>

<p>It makes sense for GitHub to expose repository actions for AI tools like Cursor or Windsurf to carry out. This is a valuable form of decoupling.</p>

<p>Does it make sense to have this decoupling for an internal tool, where the clients and servers are under your control, and the value comes from having well-optimised finetuned responses? Probably not.</p>

<p>Anywho, here’s some references. Happy building.</p>

<h2 id="references-for-a-deeper-dive">References, for a deeper dive</h2>

<ul>
  <li><a href="https://modelcontextprotocol.io/introduction">Official Docs</a>: If I have left out a lot of details on the specifics of MCP, it’s because the official docs are pretty solid and far likely to be up-to-date.</li>
  <li><a href="https://www.latent.space/p/why-mcp-won">Why MCP Won</a></li>
  <li><a href="https://github.com/modelcontextprotocol/python-sdk">Python SDK</a></li>
  <li><a href="https://claude.ai/share/e0ffb600-abf1-4f6f-8fd8-6269ba83d73d">Full conversation transcript with Claude using CKAN MCP</a></li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. Spy Agencies–One-Stop Shop to Buy Your Personal Data (128 pts)]]></title>
            <link>https://theintercept.com/2025/05/22/intel-agencies-buying-data-portal-privacy/</link>
            <guid>44062586</guid>
            <pubDate>Thu, 22 May 2025 14:43:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theintercept.com/2025/05/22/intel-agencies-buying-data-portal-privacy/">https://theintercept.com/2025/05/22/intel-agencies-buying-data-portal-privacy/</a>, See on <a href="https://news.ycombinator.com/item?id=44062586">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    
<p><span>The ever-growing market</span> for personal data has been a boon for American spy agencies. The U.S. intelligence community is now buying up vast volumes of sensitive information that would have previously required a court order, essentially bypassing the Fourth Amendment. But the surveillance state has encountered a problem: There’s simply too much data on sale from too many corporations and brokers.</p>



<p>So the government has a plan for a one-stop shop.</p>



<p>The Office of the Director of National Intelligence is working on a system to centralize and “streamline” the use of commercially available information, or CAI, like location data derived from mobile ads, by American spy agencies, according to <a href="https://www.documentcloud.org/documents/25949136-1-ic-data-consortium-other-transaction/">contract</a> <a href="https://www.documentcloud.org/documents/25949135-2-appendix-a-building-ic-data-consortium-interface-at-wwwicdatagov/">documents</a> reviewed by The Intercept. The data portal will include information deemed by the ODNI as highly sensitive, that which can be “misused to cause substantial harm, embarrassment, and inconvenience to U.S. persons.” The documents state spy agencies will use the web portal not just to search through reams of private data, but also run them through artificial intelligence tools for further analysis.</p>



<p>Rather than each agency purchasing CAI individually, as has been the case until now, the “Intelligence Community Data Consortium” will provide a single convenient web-based storefront for searching and accessing this data, along with a “data marketplace” for purchasing “the best data at the best price,” faster than ever before, according to the documents. It will be designed for the 18 different federal agencies and offices that make up the U.S. intelligence community, including the National Security Agency, CIA, FBI Intelligence Branch, and Homeland Security’s Office of Intelligence and Analysis — though one document suggests the portal will also be used by agencies not directly related to intelligence or defense.</p>



<p>“In practice, the Data Consortium would provide a one-stop shop for agencies to cheaply purchase access to vast amounts of Americans’ sensitive information from commercial entities, sidestepping constitutional and statutory privacy protections,” said Emile Ayoub, a lawyer with the Brennan Center’s liberty and national security program.</p>



<p>“ODNI is working to streamline a number of inefficient processes, including duplicative contracts to access existing data, and ensuring Americans civil liberties and Fourth Amendment rights are upheld,” ODNI spokesperson Olivia Coleman said in a statement to The Intercept. Coleman did not answer when asked if the new platform would sell access to data on U.S. citizens, or how it would make use of artificial intelligence.</p>



  



<p>Spy agencies and military intelligence offices have for years <a href="https://theintercept.com/2020/06/24/fbi-surveillance-social-media-cellphone-dataminr-venntel/">freely purchased</a> sensitive personal information rather than obtain it by dint of a judge’s sign-off. Thanks largely to unscrupulous advertisers and <a href="https://theintercept.com/2020/04/09/coronavirus-trump-smartphone-tracking/">app-makers</a> working in a <a href="https://theintercept.com/2021/11/04/treasury-surveillance-location-data-babel-street/">regulatory vacuum</a>, it’s <strong>trivial</strong> to <a href="https://theintercept.com/2022/02/18/location-data-tracking-irs-dhs-digital-envoy/">procure </a>extremely sensitive information about virtually anyone with an online presence. Smartphones in particular leave behind <a href="https://theintercept.com/2023/10/26/cellphone-roaming-location-tracking-surveillance/">immense plumes of data</a>, including detailed records of your movement that can be bought and sold by anyone with an interest. The ODNI has previously defined “sensitive” CAI as information “not widely known about an individual that could be used to cause harm to the person’s reputation, emotional well-being, or physical safety.” Procurement documents reviewed by The Intercept make clear the project is designed to provide access to this highest “sensitive” tier of CAI.</p>



<p>The documents provide a glimpse at some of the many types of CAI available, including “information addressing economic security, supply chain, critical infrastructure protection, great power competition, agricultural data, industrial data, sentiment analysis, and video analytic services.”</p>



<p>While the proliferation of data that can reveal intimate details about virtually anyone has alarmed civil libertarians, privacy advocates, and certain members of Congress, the intelligence community sees another problem: There’s too much data to keep organized, and the disorganized process of buying it is wasting money. To address this overabundance, the ODNI is seeking private sector vendors to build and manage a new “commercial data consortium that unifies commercial data acquisition then enables IC users to access and interact with this commercial data in one place,” according to <strong>one</strong> procurement document obtained by The Intercept.</p>



<p>The ODNI says the platform, the “Intelligence Community (IC) Data Consortium (ICDC),” will help correct the currently “fragmented and decentralized” purchase of commercial data like smartphone location pings, real estate records, biometric data, and social media content. The document laments how often various spy agencies are buying the same data without realizing it. The ODNI says this new platform, which will live at <a href="http://www.icdata.gov/">www.icdata.gov</a>, will “help streamline access to CAI for the entire IC and make it available to mission users in a more cohesive, efficient, and cost-effective manner by avoiding duplicative purchases, preventing sunk costs from unused licenses, and reducing overall data storage and compute costs,” while also incorporating “civil liberties and privacy best practices.”</p>



<figure><blockquote><p>“The IC is still adhering to the ‘just grab all of it, we’ll find something to do with it’ mentality.”</p></blockquote></figure>



<p>While the project’s nod to civil liberties might come as some relief to privacy advocates, the project also represents the extent to which the use of this inherently controversial form of surveillance is here to stay. “Clearly the IC is still adhering to the ‘just grab all of it, we’ll find something to do with it’ mentality rather than being remotely thoughtful about only collecting data it needs or has a specific envisioned use for,” said Calli Schroeder, senior counsel at the Electronic Privacy Information Project.</p>



<!-- BLOCK(cta)[0](%7B%22componentName%22%3A%22CTA%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%7D) -->


<!-- END-BLOCK(cta)[0] -->



<p>Once the website is up and running, the procurement materials say the portal will eventually allow users to analyze the data using large language models, AI-based text tools prone to major factual errors and fabrications. The portal will also facilitate “sentiment analysis,” an often pseudoscientific endeavor purporting to discern one’s opinion about a given topic using implicit signals in their behavior, movement, or speech.</p>



<p>Such analysis is a “huge cause for concern” according to Schroeder. “It means the intelligence community is still, to at least some degree, buying into the false promise of a constantly and continuously debunked practice,” she said. “Let me be clear: Sentiment analysis not only does not work, it cannot work. Its only consistent success has been in perpetuating harmful discrimination (of gender, culture, race, and neurodivergence, among others).”</p>



<p>Whether for sentiment analysis or some other goal, using CAI data sets to query an AI crystal ball poses serious risks, said Ayoub. If such analysis worked as billed, “AI tools make it easier to extract, re-identify, and infer sensitive information about people’s identities, locations, ideologies, and habits — amplifying risks to Americans’ privacy and freedoms of speech and association,” he said. On top of that, “These tools are a black box with little insight into training data, metric, or reliability of outcomes. The IC’s use of these tools typically comes with high risk, questionable track records, and little accountability, especially now that AI policy safeguards were rescinded early in this administration.”</p>



<p>In 2023, the ODNI declassified a 37-page report detailing the vastly expanding use of such CAI data by the U.S. intelligence community, and the threat this poses to the millions of Americans whose lives are cataloged, packaged, and sold by a galaxy of unregulated data brokers. The report, drafted for then-director of national intelligence Avril Haines, included a dire warning to the public: “Today, in a way that far fewer Americans seem to understand, and even fewer of them can avoid, CAI includes information on nearly everyone that is of a type and level of sensitivity that historically could have been obtained, if at all, only through targeted (and predicated) collection, and that could be used to cause harm to an individual’s reputation, emotional well-being, or physical safety.”</p>



  



<p>The extent to which CAI has commodified spy powers previously attainable only by well-resourced governments cannot be overstated: In 2021, for instance, The Intercept reported the existence of Anomaly Six, a startup that <a href="https://theintercept.com/2022/05/04/surveillance-anomaly-six-phone-tracking/">buys geolocational data</a> leaked from smartphones apps. During an Anomaly Six presentation, the company demonstrated its ability to track not only the Chinese navy through the phones of its sailors, but also <a href="https://theintercept.com/2022/04/22/anomaly-six-phone-tracking-zignal-surveillance-cia-nsa/">follow CIA and NSA employees as they commuted to and from work</a>.</p>



<p>The ICDC project reflects a fundamental dissonance within the intelligence community, which acknowledges that CAI is a major threat to the public while refusing to cease buying it. “The government would never have been permitted to compel billions of people to carry location tracking devices on their persons at all times, to log and track most of their social interactions, or to keep flawless records of all their reading habits,” the ODNI wrote in its 2022 report. While conceding “unfettered access to CAI increases its power in ways that may exceed our constitutional traditions or other societal expectations,” the report says, “the IC cannot willingly blind itself to this information.”</p>



<p>In 2024, following the declassified report and the alarm it generated, the ODNI put forth a set of CAI usage rules purporting to establish guardrails against privacy violations and other abuses. The framework earned praise from some corners for requiring the intelligence community to assess the origin and sensitivity of CAI before using it, and for placing more rigorous requirements on agencies that wish to use the most intimate forms of private data. But critics were quick to point out that the ODNI’s rules, which enshrined the intelligence community’s “flexibility to experiment” with CAI, amounted to more self-regulation from a part of the government with a poor track record of self-regulating.</p>



<p>While sensitive CAI comes with more rules — like keeping records of its use, protecting its storage, and some disclosure requirements — these guidelines offer great deal latitude to the intelligence community. The rule about creating a paper trail pertaining to sensitive CAI use, for example, is mandated only “to the extent practicable and consistent with the need to protect intelligence sources and methods,” and can be ignored entirely in “exigent circumstances.” In other words, it’s not really a requirement at all.</p>



<p>Ayoub told The Intercept he worries the ICDC plan will only entrench this self-policing approach. The documents note that vendors would be tasked to some extent with determining whether the data they sell is indeed sensitive, and therefore subject to stricter privacy safeguards, rather than a third party. “Relying on private vendors to determine whether CAI is considered sensitive may increase the risk that the IC purchases known categories of sensitive information without sufficient safeguards for privacy and civil liberties or the warrant, court order, or subpoena they would otherwise need to obtain,” he said.</p>



<p>The portal idea appears to have started under the Biden administration, when it was known as the “Data Co-Op.” It now looks like it will go live during a Trump administration. Elon Musk’s so-called Department of Government Efficiency is already working on building and streamlining access to other large repositories of perilously sensitive information. In March, the Washington Post <a href="https://www.washingtonpost.com/business/2025/04/15/doge-ssa-immigration-trump-housing/">reported</a> that DOGE workers intent on breaking down “information silos” across the federal government were trying to “unify systems into one central hub aims to advance multiple Trump administration priorities, including finding and deporting undocumented immigrants.” The documents note that the portal will also be accessible to so-called “non-Title 50” agencies outside of the national defense and intelligence apparatus.</p>



<!-- BLOCK(newsletter)[1](%7B%22componentName%22%3A%22NEWSLETTER%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%7D) -->

<!-- END-BLOCK(newsletter)[1] -->



<p>Ayoub argued the intelligence community can’t provide access to its upcoming CAI portal without “raising the risk that agencies like DHS’s Homeland Security Investigations (HSI) would access the CAI database to identify and target noncitizens such as student protestors based on their search or browsing histories and location information.”</p>



<p>While the ODNI has acknowledged the importance of transparency, usernames for the portal will not include the name of the analyst’s agency, “thus obscuring any specific participation from individual participants,” according to the project documents.</p>



<p>“The irony is not lost on me that they are making efforts to protect individuals within the IC from being identified regarding their participation in this project but have no qualms about vacuuming up the personal data of Americans against their wishes and knowledge,” said Schroeder.</p>



<p>Sen. Ron Wyden, D-Ore., a longtime critic of the Fourth Amendment end run posed by CAI, expressed concern to The Intercept over how the portal will ultimately be used. “Policies are one thing, but I’m concerned about what the government is actually doing with data about Americans that it buys from data brokers,” he said in a statement. “All indications from news reports and Trump administration officials are that Americans should be extremely worried about how this administration may be using commercial data.”</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Built My Own Audio Player (200 pts)]]></title>
            <link>https://nexo.sh/posts/why-i-built-a-native-mp3-player-in-swiftui/</link>
            <guid>44062227</guid>
            <pubDate>Thu, 22 May 2025 14:09:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nexo.sh/posts/why-i-built-a-native-mp3-player-in-swiftui/">https://nexo.sh/posts/why-i-built-a-native-mp3-player-in-swiftui/</a>, See on <a href="https://news.ycombinator.com/item?id=44062227">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody"><blockquote><p>In 2025, playing your own <strong>music on an iPhone is surprisingly hard</strong>, unless you pay Apple or navigate a maze of limitations. So I built my own player from scratch, with <strong>full text search</strong>, <strong>iCloud support</strong>, and a <strong>local-first experience</strong>. <a href="https://github.com/nexo-tech/music-app">GitHub link</a></p></blockquote><h2 id="why-i-built-my-own-audio-player">Why I Built My Own Audio Player</h2><p><img src="https://nexo.sh/posts/why-i-built-a-native-mp3-player-in-swiftui/frame_source.webp" alt="An image of a music app I’ve built"></p><p>Like many people, I’ve picked up too many subscriptions, some through Apple (iCloud, Apple Music), others got lost in random platforms (like Netflix, which I forgot I was still paying for). I actually used Apple Music regularly (and previously Spotify), but the streaming turned out to be more convenience than necessity. With a curated local library, I didn’t lose much, just the lock-in.</p><p>Initially I thought, I’d just keep using iCloud Music Library for cross-device music synchronization, but once I cancelled the Apple Music subscription, the sync stopped working. Turns out this feature is <strong>behind a paywall</strong>. You can technically get it back via <a href="https://support.apple.com/en-us/108935"><em>iTunes Match</em> ($24.99/year)</a>. Match just stores 256-kbps AAC copies online; your original files stay put unless you choose to replace them. On a modern Mac, you do all this in the Music app. Without either subscription, cloud sync is gone, and you’re back to cable/Wi-Fi syncing.</p><p>Frustrated with the lack of options, I went the <strong>builder route</strong>. If I bought a computing device (iPhone in this case), what stops me from just building exactly what I need with code to use it? In this article, I want to share my full journey of frustrations towards creating a basic music player functionality: loading audio files, organizing and playing them back, but mostly, I wanted to remind myself, <em>this is still a general-purpose computer, I should be able to make it do what I want</em>.</p><h2 id="what-apple-and-others-offer-today">What Apple (and Others) Offer Today</h2><p>Before writing my own app, I explored the official and third-party options for offline music playback.</p><h3 id="apples-built-in-apps">Apple’s Built-in Apps</h3><p>Apple technically lets you play music directly from iCloud via the Files app, but its functionality is not designed for music listening. It <strong>lacks essential features</strong> such as playlist management, metadata sorting, or playback queues. While it supports music playback, it’s very limited and overall <a href="https://discussions.apple.com/thread/252762868"><strong>not a good user experience</strong></a>.</p><h3 id="third-party-apps">Third-Party Apps</h3><p>I went to the app store to look for cool apps that solve my problem, while there are many of them, many rely on <strong>subscription-based pricing</strong>, a questionable model for an app that simply plays files users already own. There’s one app that I liked, <a href="https://apps.apple.com/us/app/doppler-mp3-flac-player/id1468459747">Doppler</a>. I’ve played with it during a trial, but the UX is built around managing albums. The search wasn’t that good, and the import functionality from iCloud was slow and hard to use on a large number of nested folders. The upside was, it had a single payment pricing model.</p><h2 id="going-builder-mode-my-technical-journey">Going Builder Mode: My Technical Journey</h2><p>With that said, I decided to create my own ideal music player that solves my pain points:</p><ul><li>Flexible full-text search across iCloud folders, so I can select and import a folder with music or specific files quickly.</li><li>Functionality in managing music at least on par with the official Music App: queue, playlist management, and sorting by albums, etc.</li><li>Familiar and friendly interface.</li></ul><h3 id="trying-react-native-first">Trying React Native First</h3><p>Initially, I avoided Swift because of my previous experience with it. A few years back, I liked the syntax (felt closer to TypeScript) and appreciated the Rust-like memory safety, but without native <code>async</code>/<code>await</code> at that time, writing concurrent code compared to Go or JS/TS felt clunky and boilerplate-heavy. That experience left me frustrated, so when I revisited this project, I initially reached for something more familiar.</p><p>That said, I went with React Native or Expo, hoping to reuse my web development experience and plug in a player UI from existing templates. Building the playback UI was straightforward; there are numerous open-source examples and tutorial videos on building good-looking music players that fit my needs. I picked an existing <a href="https://github.com/CodeWithGionatha-Labs/music-player">template project by Gionatha Sturba</a>, because it looked to have every feature I need for my app.</p><p><img src="https://nexo.sh/posts/why-i-built-a-native-mp3-player-in-swiftui/rn-screenshot.webp" alt="Attempting to build an app with React Native/Expo"></p><p>Accessing the file system and syncing cloud files hit major roadblocks: libraries like <a href="https://docs.expo.dev/versions/latest/sdk/filesystem/"><code>expo-filesystem</code></a> supported basic file picking, but recursive traversal over deeply nested iCloud directories <strong>often failed or even caused app crashes</strong>. This made it clear that a <strong>JavaScript-based approach introduced more complexity</strong> than just working with Apple’s native APIs, even if it meant a steeper learning curve.</p><p>iOS sandboxing prevents apps from reading files without explicit user permission, which meant React Native couldn’t access external folders reliably. Switching to Swift gave me more control over iCloud file access and sandboxed permissions.</p><h3 id="switching-to-swiftui">Switching to SwiftUI</h3><p>I went with <strong>SwiftUI</strong> instead of UIKit or storyboards because I wanted a <strong>clean and declarative UI</strong> layer that would stay out of the way while I focused on domain logic and data synchronization. With modern features like async/await and integration with <strong>Swift Actors</strong>, I found it easier to manage data flow and concurrency. SwiftUI also definitely made it easier to structure the app into isolated ViewModel components, which in turn helped me get better results from LLMs like OpenAI o1 and DeepSeek. LLMs could produce pure UI code or data binding code without introducing messy interdependencies.</p><h2 id="app-architecture-and-data-model">App Architecture and Data Model</h2><p>Let’s go over the architecture of the app I’ve created: I used SQLite for persistent data storage and approached the app architecture as a simple server application. I avoided CoreData because I needed tight control over schema, raw queries, and especially full-text search. SQLite’s built-in FTS5 support let me add fast fuzzy search without pulling in heavy external search engines or building my own indexing layer.</p><h3 id="three-main-screens">Three Main Screens</h3><p><strong>The app consists of 3 screen/modes:</strong></p><ol><li><strong>Library import.</strong> This is where you add your iCloud library folder. The app scans every folder for audio files and inserts every path into a SQLite database. This way, you can have full flexibility in searching, adding folders, and subfolders. Apple’s native file picker is very clunky; you cannot select multiple directories that you searched by keyword and then also a bunch of files in one go. It simply is not designed to do that.</li><li><strong>Library management.</strong> This is where you can manage the added songs and organize playlists. For the most part, I’ve reflected the way Apple did that in their Music app, and it was good enough for my needs.</li><li><strong>Player and playback.</strong> This part of the application manages queue management (repeat, shuffle), etc., and play, stop, and next song functionality.</li></ol><p>A simple user flow diagram is shown here:</p><figure><img src="https://nexo.sh/posts/why-i-built-a-native-mp3-player-in-swiftui/user-flow-diagram.svg" alt="User flow diagram" width="600"></figure><p><strong>User flow in practice:</strong> When the app launches with an empty library, it lands on the Sync tab, showing a big “Add iCloud Source” button. Pick a folder there, and the Sync screen displays a progress bar while it walks the tree. As soon as indexing finishes, it switches you to the Library tab, whose first screen lists <strong>Playlists / Artists / Albums / Songs</strong>. Dive into any list, tap a track, and a Mini-Player pops up along the bottom; tap that mini-bar to open the full-screen Player with shuffle, repeat, queue reorder, and volume. Swipe or tap the close icon, and you’re straight back to the Library while playback continues. Any time you need more music, jump back to Sync, hit the “+” in the nav bar, select another folder, and the import service merges new songs in the background, no restart required.</p><h3 id="backend-like-logic-layer">Backend-Like Logic Layer</h3><p>Having a web/cloud background and shipped a lot of server code while working in startups, I went with a <strong>backend-like architecture</strong> for the mobile app. The whole domain/logic layer was separated from the <strong>View and View-Model layer</strong> because I had to nail the <strong>cloud syncing, metadata parsing</strong> aspect of the app and having clean data access to a SQLite DB. <em>Here’s an approximate layered architecture diagram that I used here</em>:</p><figure><img src="https://nexo.sh/posts/why-i-built-a-native-mp3-player-in-swiftui/layers.svg" alt="Layered architecture diagram" width="600"></figure><p><strong>How the layers talk:</strong> SQLite sits at the bottom, storing raw song rows and FTS indexes. Then repositories wrap the database and expose async APIs. On top of those live my <strong>domain actors</strong>, Swift actors that own all business rules (import, search, queue logic) so state mutations stay <strong>thread-safe</strong>. ViewModels subscribe to the actors, transform the data into UI-ready structs, and SwiftUI views simply render whatever they get. Nothing crosses layers directly, keeping iCloud sync, playback, and UI <strong>nicely decoupled</strong>.</p><h2 id="implementing-full-text-search-with-sqlite">Implementing Full Text Search with SQLite</h2><p>Like I previously mentioned, it’s fortunate that you can import an SQLite version with FTS capabilities: starting around iOS 11, it’s available out of the box <strong>without extra setup</strong>. This made it easy to integrate fuzzy search into my music library <strong>without any third-party dependencies</strong>. Additionally, I used the SQLite.swift library for regular queries (which works as a sort of query builder with compile-time safety); however, for FTS queries, I had to resort to regular SQL statements.</p><p>SQLite’s <a href="https://sqlite.org/fts5.html">FTS5</a> extension ended up being one of the most valuable pieces of the architecture. It let me query across file names and metadata like artist, album, and title without extra indexing infrastructure.</p><h3 id="setting-up-the-fts-tables">Setting Up the FTS Tables</h3><table><thead><tr><th>Domain</th><th>Swift actor / repo</th><th>FTS5 table</th><th>Columns that get indexed</th></tr></thead><tbody><tr><td>Library songs</td><td><code>SQLiteSongRepository</code></td><td><code>songs_fts</code></td><td><code>artist</code>, <code>title</code>, <code>album</code>, <code>albumArtist</code></td></tr><tr><td>Source-browser paths</td><td><code>SQLiteSourcePathSearchRepository</code></td><td><code>source_paths_fts</code></td><td><code>fullPath</code>, <code>fileName</code></td></tr></tbody></table><p>I used two FTS5 tables: one for indexed songs (artist/title/album) and one for file paths during folder import. Both tables live next to the primary rows in plain‐old B-tree tables (<code>songs</code>, <code>source_paths</code>). FTS is <strong>read-only for the UI</strong>; all writes happen inside the repositories so nothing slips through the cracks.</p><h4 id="creating-the-search-index">Creating the search index</h4><p>SQLite’s built-in FTS5 makes quick searches easy. Here’s a simple table definition I used:</p><figure role="figure" aria-label="swift code snippet"><div><p>swift</p><div><p>Copied to clipboard</p></div></div><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span></code></pre></td><td><pre tabindex="0"><code data-lang="swift"><span><span><span>try</span> <span>db</span><span>.</span><span>execute</span><span>(</span><span>"""
</span></span></span><span><span><span>CREATE VIRTUAL TABLE IF NOT EXISTS songs_fts USING fts5(
</span></span></span><span><span><span>  songId UNINDEXED,
</span></span></span><span><span><span>  artist, title, album, albumArtist,
</span></span></span><span><span><span>  tokenize='unicode61'
</span></span></span><span><span><span>);
</span></span></span><span><span><span>"""</span><span>)</span></span></span></code></pre></td></tr></tbody></table></div></figure><p>I used <code>unicode61</code> tokenizer to ensure that a wide variety of characters are handled. Non-searchable keys are flagged with <code>UNINDEXED</code>, so they don’t bloat the term dictionary.</p><h4 id="updating-data-reliably">Updating data reliably</h4><p>To keep things simple and safe, I wrapped updates and inserts in transactions. This ensures the search index never gets out of sync, even if the app crashes or gets interrupted.</p><figure role="figure" aria-label="swift code snippet"><div><p>swift</p><div><p>Copied to clipboard</p></div></div><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td><td><pre tabindex="0"><code data-lang="swift"><span><span><span>func</span> <span>upsertSong</span><span>(</span><span>_</span> <span>song</span><span>:</span> <span>Song</span><span>)</span> <span>async</span> <span>throws</span> <span>{</span>
</span></span><span><span>    <span>db</span><span>.</span><span>transaction</span> <span>{</span>
</span></span><span><span>        <span>// insert or update main song data</span>
</span></span><span><span>        <span>// insert or update search index data</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span><span>}</span></span></span></code></pre></td></tr></tbody></table></div></figure><h3 id="querying-with-fuzzy-search">Querying with Fuzzy Search</h3><p>For user-friendly search, I add wildcard support automatically. If you type “lumine,” it searches for “lumine*” internally, giving instant results even with partial queries.</p><p>I also leverage SQLite’s built-in smart ranking (<code>bm25</code>) to return more relevant results without extra complexity:</p><figure role="figure" aria-label="sql code snippet"><div><p>sql</p><div><p>Copied to clipboard</p></div></div><div><table><tbody><tr><td><pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td><td><pre tabindex="0"><code data-lang="sql"><span><span><span>SELECT</span><span> </span><span>s</span><span>.</span><span>*</span><span>
</span></span></span><span><span><span></span><span>FROM</span><span> </span><span>songs</span><span> </span><span>s</span><span> </span><span>JOIN</span><span> </span><span>songs_fts</span><span> </span><span>fts</span><span> </span><span>ON</span><span> </span><span>s</span><span>.</span><span>id</span><span> </span><span>=</span><span> </span><span>fts</span><span>.</span><span>songId</span><span>
</span></span></span><span><span><span></span><span>WHERE</span><span> </span><span>songs_fts</span><span> </span><span>MATCH</span><span> </span><span>?</span><span>
</span></span></span><span><span><span></span><span>ORDER</span><span> </span><span>BY</span><span> </span><span>bm25</span><span>(</span><span>songs_fts</span><span>)</span><span>
</span></span></span><span><span><span></span><span>LIMIT</span><span> </span><span>?</span><span> </span><span>OFFSET</span><span> </span><span>?</span><span>;</span></span></span></code></pre></td></tr></tbody></table></div></figure><p>Overall, using raw SQLite gave me the flexibility I needed: predictable schema, local-first access, and powerful full-text search, without introducing any network dependencies or external services. This approach was ideal for an app designed to be private and offline-first.</p><h2 id="working-with-ios-files-and-bookmarks">Working with iOS Files and Bookmarks</h2><p>On iOS, apps can store persistent bookmarks to file locations, but <strong>security-scoped bookmarks</strong>, which grant extended access to files outside the app’s sandbox, are only available on <strong>macOS</strong>. iOS apps can use regular bookmarks to remember file paths and request access again through the document picker, but that access isn’t guaranteed to persist silently. See <a href="https://developer.apple.com/documentation/foundation/nsurl#Bookmarks-and-Security-Scope">Apple’s bookmark documentation</a>.</p><p>To mitigate this, I implemented a fallback mechanism that copies files into the <strong>app’s own sandboxed container</strong>. This avoids the fragile lifecycle of security-scoped bookmarks that can silently break if iOS resets the permissions. By copying files proactively in the background, while the bookmark is valid, there’s no risk in accessing invalid audio-file references.</p><p>This approach also improves indexing speed. I can scan the folder structure once (while access is active), import only relevant audio files, and safely traverse deeply nested directories. But reliably playing back individual audio files from external locations, especially after device restarts, <em>remains an unsolved problem to me</em>. This highlights how <strong>under-supported</strong> this use case is, even for native apps, and how complex it still is to <strong>handle file access reliably on iOS</strong>.</p><h2 id="building-the-playback-and-ui">Building the Playback and UI</h2><h3 id="metadata-parsing">Metadata Parsing</h3><p>To parse metadata from audio files, I used Apple’s <strong>AVFoundation framework</strong>, specifically the <strong>AVURLAsset</strong> class, which allows inspection of media file metadata, such as title, album artist, etc. While metadata parsing is handled by the native SDK, certain fields like track numbers you have to manually look up from ID3 tags. I relied on <a href="https://github.com/TastemakerDesign/Warper/blob/2af8c07ad8422f4dc3a539177d3a76ee8502e632/plugins/flutter_media_metadata/ios/Classes/Id3MetadataRetriever.swift">GitHub search</a> to find examples, since the official documentation lacked coverage for edge cases.</p><h3 id="audio-playback-with-avfoundation">Audio Playback with AVFoundation</h3><p>After the library is indexed, implementing an audio player feels pretty simple: you just have to initialize an instance of <code>AVAudioPlayer</code> and let the audio play. Additionally, for quality-of-life features: playing music from the control center, I had to implement the <code>AVAudioPlayerDelegate</code> protocol and also hooked into Apple’s <code>MPRemoteCommandCenter</code>, which lets developers respond to system-level playback controls.</p><h2 id="reflections-apple-developer-lock-in-and-the-future">Reflections: Apple, Developer Lock-In, and the Future</h2><p>Here’s what stood out during development:</p><h3 id="the-bad">The Bad</h3><p><strong>Xcode’s limitations remain frustrating.</strong> Real-time SwiftUI previews are definitely a step forward, but the overall development experience still isn’t on par with what Flutter offered five years ago: tight VSCode integration, real-time simulator reloads, and familiar debugging tools.</p><p><strong>Lack of editor flexibility.</strong> Setting up Language Server Protocol (LSP) support for Swift in Neovim or VSCode requires extra tooling like <a href="https://github.com/SolaWing/xcode-build-server"><code>xcode-build-server</code></a>, and still doesn’t fully match the developer experience of web-first ecosystems.</p><p><strong>Some corners of Apple’s SDK still live in Objective-C land.</strong> Spotlight file search, for instance, is only exposed through <code>NSMetadataQuery</code>, which uses Key-Value Observing (KVO) and string keys, no Swift-friendly wrapper yet. Documentation is often sparse, which steepens the learning curve.</p><p><strong>SwiftUI’s declarative UI is great, but debugging iCloud interactions still requires manual mocks.</strong> SwiftUI previews can’t emulate full app behaviors involving iCloud entitlements, so you have to mock cloud interactions manually, a minor annoyance but notable.</p><h3 id="the-good">The Good</h3><p><strong>Async/await.</strong> Finally, I can write I/O-bound concurrent code like an imperative one with no annoying callbacks. That’s a big win, and I greatly appreciate how easy it is to write even sync code into Actors and call it like you do in JavaScript ecosystems.</p><p><strong>Plethora of native libs.</strong> Yes, you’re not limited by open source bindings like in React Native/Flutter ecosystems. Here you have much more freedom in developing something “more serious” than your company/product website replacement (because of poor mobile-first experience). Many Apple’s APIs are available with examples, which made it easy to get started.</p><p><strong>SwiftUI</strong> itself. Yes, the React-style approach to building UIs gives more productivity and space for explorations. It’s just great that Apple adopted it.</p><h3 id="summary-building-should-be-easier">Summary: Building Should Be Easier</h3><p>After 1.5 weeks of hacking around, I was able to get the piece of software which exactly satisfies my needs: a <strong>local/offline music player</strong> that can import audio files from cloud storage.</p><p>But developers quickly realize they can’t easily deploy apps to their own devices these days and forget about it: apps only run for <a href="https://developer.apple.com/support/compare-memberships"><strong>7 days without a dev certificate</strong></a>, and after that, you have to rebuild it, unless you paid $99 to Apple to enroll in the development program.</p><p>Even after the <strong>DMA Act in the EU</strong>, sideloading still isn’t fully open. EU users can now install apps from third-party marketplaces directly from a developer’s site, but only if that developer still enrolled in Apple’s $99/year program and agrees to Apple’s Alternative Terms. For personal/hobbyist use, this still doesn’t remove the 7-day dev build limitation.</p><p>This makes ultimately no sense. An innovative technology company actively puts roadblocks into democratized application development. Even Progressive Web Applications (PWAs) <a href="https://brainhub.eu/library/pwa-on-ios">face notable limitations on iOS</a>: even after Apple’s 16-18.x updates, iOS PWAs still run inside Safari’s sandbox. They get WebGL2 and web-push, but they don’t get Web Bluetooth/USB/NFC, Background Sync, or more than ~50MB of guaranteed storage. WebGL runs through Metal shim, so real-world frame-rates often trail native Metal apps; this is good enough for UI, but not for AAA 3D games.</p><p>Nowadays, AI has reduced the complexity of modern software development by allowing anyone to tackle unknown technologies by providing all the necessary knowledge in an accessible way. You can clearly see how web development got more interest from non-technical people who have a way to build their ideas without specializing in a plethora of technologies. But when it comes to mobile apps, you just have to play by the artificial rules. <em>Even if you built it yourself, for yourself, Apple still gets the final say</em> before you can run it for more than a week. The same company that once empowered independent developers now imposes <strong>tight restrictions that hinder personal app development</strong> and distribution. AI has made it easier than ever to build new tools, unless you’re building for iOS, where the gate is still locked.</p><ul><li><a href="https://support.apple.com/en-us/HT204146">iTunes Match – Apple Support</a></li><li><a href="https://developer.apple.com/documentation/foundation/nsurl#1664002">Security-Scoped Bookmarks – Apple Docs</a></li><li><a href="https://sqlite.org/fts5.html">FTS5 – SQLite Documentation</a></li><li><a href="https://apps.apple.com/us/app/doppler-music-player/id1500875779">Doppler Music Player – App Store</a></li><li><a href="https://docs.expo.dev/versions/latest/sdk/filesystem/">Expo FileSystem Documentation</a></li><li><a href="https://developer.apple.com/programs/">Apple Developer Program Info (7-day builds)</a></li><li><a href="https://discussions.apple.com/thread/252762868?sortBy=rank">Apple Community: Files App &amp; MP3 Playback</a></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fast Allocations in Ruby 3.5 (200 pts)]]></title>
            <link>https://railsatscale.com/2025-05-21-fast-allocations-in-ruby-3-5/</link>
            <guid>44062160</guid>
            <pubDate>Thu, 22 May 2025 14:01:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://railsatscale.com/2025-05-21-fast-allocations-in-ruby-3-5/">https://railsatscale.com/2025-05-21-fast-allocations-in-ruby-3-5/</a>, See on <a href="https://news.ycombinator.com/item?id=44062160">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Many Ruby applications allocate objects. What if we could make allocating
objects six times faster?  We can!  Read on to learn more!</p>

<h2 id="speeding-up-allocations-in-ruby">Speeding up allocations in Ruby</h2>

<p>Object allocation in Ruby 3.5 will be much faster than previous versions of Ruby.
I want to start this article with benchmarks and graphs, but if you stick around I’ll also be explaining how we achieved this speedup.</p>

<p>For allocation benchmarks, we’ll compare types of parameters (positional and keyword) with and without YJIT enabled.
We’ll also vary the number of parameters we pass to initialize so that we can see how performance changes as the number of parameters increases.</p>

<p>The full benchmark code can be found expanded below, but it’s basically as follows:</p>

<div><pre><code><span>class</span> <span>Foo</span>
  <span># Measure performance as parameters increase</span>
  <span>def</span> <span>initialize</span><span>(</span><span>a1</span><span>,</span> <span>a2</span><span>,</span> <span>aN</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>def</span> <span>test</span>
  <span>i</span> <span>=</span> <span>0</span>
  <span>while</span> <span>i</span> <span>&lt;</span> <span>5_000_000</span>
    <span>Foo</span><span>.</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>N</span><span>)</span>
    <span>Foo</span><span>.</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>N</span><span>)</span>
    <span>Foo</span><span>.</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>N</span><span>)</span>
    <span>Foo</span><span>.</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>N</span><span>)</span>
    <span>Foo</span><span>.</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>N</span><span>)</span>
    <span>i</span> <span>+=</span> <span>1</span>
  <span>end</span>
<span>end</span>

<span>test</span>
</code></pre></div>

<details>

  <summary>Full Benchmark Code</summary>

  <p>Positional parameters benchmark:</p>

  <div><pre><code><span>N</span> <span>=</span> <span>(</span><span>ARGV</span><span>[</span><span>0</span><span>]</span> <span>||</span> <span>0</span><span>).</span><span>to_i</span>

<span>class</span> <span>Foo</span>
  <span>class_eval</span> <span>&lt;&lt;-</span><span>eorb</span><span>
  def initialize(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>"a</span><span>#{</span><span>_1</span><span>}</span><span>"</span> <span>}</span><span>.join(", ") })
  end
</span><span>  eorb</span>
<span>end</span>

<span>eval</span> <span>&lt;&lt;-</span><span>eorb</span><span>
def test
  i = 0
  while i &lt; 5_000_000
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>_1</span><span>.</span><span>to_s</span> <span>}</span><span>.join(", ") })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>_1</span><span>.</span><span>to_s</span> <span>}</span><span>.join(", ") })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>_1</span><span>.</span><span>to_s</span> <span>}</span><span>.join(", ") })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>_1</span><span>.</span><span>to_s</span> <span>}</span><span>.join(", ") })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>_1</span><span>.</span><span>to_s</span> <span>}</span><span>.join(", ") })
    i += 1
  end
end
</span><span>eorb</span>

<span>test</span>
</code></pre></div>

  <p>Keyword parameters benchmark:</p>

  <div><pre><code><span>N</span> <span>=</span> <span>(</span><span>ARGV</span><span>[</span><span>0</span><span>]</span> <span>||</span> <span>0</span><span>).</span><span>to_i</span>

<span>class</span> <span>Foo</span>
  <span>class_eval</span> <span>&lt;&lt;-</span><span>eorb</span><span>
  def initialize(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>"a</span><span>#{</span><span>_1</span><span>}</span><span>:"</span> <span>}</span><span>.join(", ") })
  end
</span><span>  eorb</span>
<span>end</span>

<span>eval</span> <span>&lt;&lt;-</span><span>eorb</span><span>
def test
  i = 0
  while i &lt; 5_000_000
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>"a</span><span>#{</span><span>_1</span><span>}</span><span>: </span><span>#{</span><span>_1</span><span>}</span><span>"</span> <span>}</span><span>.join(", ") })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>"a</span><span>#{</span><span>_1</span><span>}</span><span>: </span><span>#{</span><span>_1</span><span>}</span><span>"</span> <span>}</span><span>.join(", ") })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>"a</span><span>#{</span><span>_1</span><span>}</span><span>: </span><span>#{</span><span>_1</span><span>}</span><span>"</span> <span>}</span><span>.join(", ") })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>"a</span><span>#{</span><span>_1</span><span>}</span><span>: </span><span>#{</span><span>_1</span><span>}</span><span>"</span> <span>}</span><span>.join(", ") })
    Foo.new(</span><span>#{</span><span>N</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>{</span> <span>"a</span><span>#{</span><span>_1</span><span>}</span><span>: </span><span>#{</span><span>_1</span><span>}</span><span>"</span> <span>}</span><span>.join(", ") })
    i += 1
  end
end
</span><span>eorb</span>

<span>test</span>
</code></pre></div>
</details>

<p>We want to measure how long this script will take, but change the number and type of parameters we pass.
To emphasize the cost of object allocation while minimizing the impact of loop execution, the benchmark allocates several objects per iteration.</p>

<p>Running the benchmark code with 0 to 8 parameters, varying parameter type and whether or not YJIT is enabled will produce the following graph:</p>

<p><img src="https://railsatscale.com/2025-05-21-fast-allocations-in-ruby-3-5/graph.png" alt="Benchmark results graph"></p>

<p>The graph illustrates the speedup ratio, calculated by dividing the time spent on Ruby 3.4.2 by that spent on Ruby 3.5.
That means that any values below 1 represent a slowdown, where any values above 1 would represent a speedup.
When we compare Ruby 3.5 to Ruby 3.4.2 we either disable YJIT on both versions or enable YJIT on both versions.
In other words we compare Ruby 3.5 with Ruby 3.4.2 and Ruby 3.5+YJIT with Ruby 3.4.2+YJIT.</p>

<p>The X axis shows the number of parameters passed to initialize, and the Y axis is the speedup ratio.
The blue bars are positional parameters <em>without</em> YJIT, the green bars are positional parameters <em>with</em> YJIT.
The grey bars are keyword parameters <em>without</em> YJIT, and the yellow bars are keyword parameters <em>with</em> YJIT.</p>

<p>First, we can see that all bars are above 1, meaning that every allocation type is faster on Ruby 3.5 than on Ruby 3.4.2.
Positional parameters have a constant speedup ratio regardless of the number of parameters.</p>

<h3 id="positional-parameter-comparison">Positional Parameter Comparison</h3>

<p>For positional parameters the speedup ratio remains constant regardless of the number of parameters.
Without YJIT, Ruby 3.5 is always about 1.8x faster than Ruby 3.4.2.
When we enable YJIT, Ruby 3.5 is always about 2.3x faster.</p>

<h3 id="keyword-parameter-comparison">Keyword Parameter Comparison</h3>

<p>Keyword parameters are a little more interesting.
For both the interpreter and YJIT, as the number of keyword parameters increases, the speedup ratio also increases.
In other words, the more keyword parameters used, the more effective this change is.</p>

<p>With just 3 keyword parameters passed to initialize, Ruby 3.5 is 3x faster than Ruby 3.4.2, and if we enable YJIT it’s over 6.5x faster.</p>

<h2 id="bottlenecks-in-classnew">Bottlenecks in Class#new</h2>

<p>I’ve been interested in speeding up allocations, and thus <code>Class#new</code> for a while.
But what made it slow?</p>

<p><code>Class#new</code> is a very simple method.
All it does is allocate an instance, pass all parameters to <code>initialize</code>, and then return the instance.
If we were to implement <code>Class#new</code> in Ruby, it would look something like this:</p>

<div><pre><code><span>class</span> <span>Class</span>
  <span>def</span> <span>self</span><span>.</span><span>new</span><span>(</span><span>...</span><span>)</span>
    <span>instance</span> <span>=</span> <span>allocate</span>
    <span>instance</span><span>.</span><span>initialize</span><span>(</span><span>...</span><span>)</span>
    <span>instance</span>
  <span>end</span>
<span>end</span>
</code></pre></div>

<p>The implementation has two main parts.
First, it allocates a bare object with <code>allocate</code>,
and second it calls the <code>initialize</code> method, forwarding all parameters <code>new</code> received.
So to speed up this method, we can either speed up object allocation, or speed up calling out to the <code>initialize</code> method.</p>

<p>Speeding up <code>allocate</code> means speeding up the garbage collector, and while there are merits to doing that, I wanted to focus on the runtime side of the equation.
That means trying to decrease the overhead of calling out to another method.
So what makes a method call slow?</p>

<h2 id="calling-ruby-methods-from-ruby">Calling Ruby methods from Ruby</h2>

<p>Ruby’s virtual machine, YARV, uses a stack as a scratch space for processing values.
We can think of this stack as a really large heap allocated array.
Every time we process a YARV instruction, we’ll read or write to this heap allocated array.
This is also true for passing parameters between functions.</p>

<p>When we call a function in Ruby, the caller pushes parameters to the stack before the call is made to the callee.
The callee then reads its parameters from the stack, does any processing it needs, and returns.</p>

<div><pre><code><span>def</span> <span>add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span>
  <span>a</span> <span>+</span> <span>b</span>
<span>end</span>

<span>def</span> <span>call_add</span>
  <span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<span>end</span>
</code></pre></div>

<p>For example in the above code, the caller <code>call_add</code> will push the arguments <code>1</code> and <code>2</code> to the stack before calling the <code>add</code> function.
When the <code>add</code> function reads its parameters in order to perform the <code>+</code>, it reads <code>a</code> and <code>b</code> from the stack.
The values pushed by the caller become the parameters for the callee.
You can see this in action in our recent <a href="https://railsatscale.com/2025-05-14-merge-zjit/">post about Launching ZJIT</a>.</p>

<p>This “calling convention” is convenient because the arguments pushed to the stack don’t need to be copied anywhere when they become the parameters to the callee.
If you examine the memory addresses for where 1 and 2 are stored, you’ll see that they are the same addresses used for the values of <code>a</code> and <code>b</code>.</p>

<h2 id="calling-c-methods-from-ruby">Calling C methods from Ruby</h2>

<p>Unfortunately C functions do not use the same calling convention as Ruby functions.
That means when we call a C function from Ruby, or a Ruby function from C, we must convert method parameters to their respective calling convention.</p>

<p>In C, parameters are passed via registers or machine stack.
This means that when we call a C function from Ruby, we need to copy values from the Ruby stack into registers.
Or when we call a Ruby function from C, we must copy register values to the Ruby stack.</p>

<p>This conversion between calling conventions takes some time, so this is a place we can target for optimization.</p>

<p>When calling a C function from Ruby, positional parameters can be directly copied to registers.</p>

<div><pre><code><span>static</span> <span>VALUE</span>
<span>foo</span><span>(</span><span>VALUE</span> <span>a</span><span>,</span> <span>VALUE</span> <span>b</span><span>)</span>
<span>{</span>
  <span>return</span> <span>INT2NUM</span><span>(</span><span>NUM2INT</span><span>(</span><span>a</span><span>)</span> <span>+</span> <span>NUM2INT</span><span>(</span><span>b</span><span>));</span>
<span>}</span>
</code></pre></div>

<div><pre><code><span># calls the `foo` C function</span>
<span>foo</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
</code></pre></div>

<p>In the above example, on ARM64, the parameters <code>a</code> and <code>b</code> will be in the X0 and X1 registers respectively.
When we call the <code>foo</code> function from Ruby, the <a href="https://github.com/ruby/ruby/blob/e0545a02503983e8824d0fb5972c15d51093d927/vm_insnhelper.c#L7252-L7362">parameters can be copied directly to the X0 and X1 registers from the Ruby stack</a>.</p>

<p>Unfortunately the conversion isn’t so simple for keyword parameters.
Since C doesn’t support keyword parameters, we have pass the keyword parameters as a hash to the C function.
This means <a href="https://github.com/ruby/ruby/blob/e0545a02503983e8824d0fb5972c15d51093d927/vm_insnhelper.c#L2724-L2730">allocating a new hash, iterating over the parameters, and setting them in the hash</a>.</p>

<p>We can see this in action with the following program when run on Ruby 3.4.2:</p>

<div><pre><code><span>class</span> <span>Foo</span>
  <span>def</span> <span>initialize</span><span>(</span><span>a</span><span>:)</span>
  <span>end</span>
<span>end</span>

<span>def</span> <span>measure_allocations</span>
  <span>x</span> <span>=</span> <span>GC</span><span>.</span><span>stat</span><span>(</span><span>:total_allocated_objects</span><span>)</span>
  <span>yield</span>
  <span>GC</span><span>.</span><span>stat</span><span>(</span><span>:total_allocated_objects</span><span>)</span> <span>-</span> <span>x</span>
<span>end</span>

<span>def</span> <span>test</span>
  <span>measure_allocations</span> <span>{</span> <span>Foo</span><span>.</span><span>new</span><span>(</span><span>a: </span><span>1</span><span>)</span> <span>}</span>
<span>end</span>

<span># We need to warm the callsite before measurement because inline caches are Ruby</span>
<span># objects, so they will skew our results</span>
<span>test</span> <span># warmup</span>
<span>test</span> <span># warmup</span>
<span>p</span> <span>test</span>
</code></pre></div>

<p>If we run the above program with Ruby 3.4.2, we’ll see that the <code>test</code> method allocates 2 objects: and instance of <code>Foo</code>, and a hash for passing the keyword parameters to the C implementation of <code>Class#new</code>.</p>

<h2 id="achieving-an-allocation-speedup">Achieving an allocation speedup</h2>

<p>I want to start first with a little bit of history.</p>

<p>I’ve been interested in speeding up allocations for quite some time.
We know that calling a C function from Ruby incurs some overhead, and that the overhead depends on the type of parameters we pass.
So my initial inclination was to rewrite <code>Class#new</code> in Ruby.
Since <code>Class#new</code> just forwards all of its parameters to <code>initialize</code>, it seemed quite natural to use the triple-dot forwarding syntax (<code>...</code>).
You can find remnants of my initial implementation <a href="https://github.com/ruby/ruby/pull/9289">here</a>.
Unfortunately I found that using <code>...</code> was quite expensive because at the time, it was syntactic sugar for <code>*, **, &amp;</code>, and Ruby would allocate extra objects to represent these splat parameters.</p>

<p><a href="https://github.com/ruby/ruby/pull/10510">This lead me to implement an optimization for <code>...</code></a>.
The optimization for <code>...</code> allowed us to use parameter forwarding without allocating any extra objects.
I think this optimization is useful in general, but what I had in mind was using it for <code>Class#new</code>.
Fast forward some months, and I was able to <a href="https://github.com/ruby/ruby/pull/9289/files#diff-919ef5932e2ffb97a00a90eb06036b733c6d26cf69cc13014a3ac174bd351fde">implement <code>Class#new</code> in Ruby with this new optimization</a>.
The initial benchmarks were decent, it eliminated allocations and decreased the cost of passing parameters from <code>new</code> to <code>initialize</code>.
But I was somewhat worried about inline cache misses <a href="https://github.com/ruby/ruby/pull/9289/files#diff-919ef5932e2ffb97a00a90eb06036b733c6d26cf69cc13014a3ac174bd351fdeR7">at this call site</a>.</p>

<p>The <code>Class#new</code> implementation linked to above is a little complex, but if we boil it down, it’s essentially the same as the <code>Class#new</code> implementation we saw at the beginning of the post:</p>

<div><pre><code><span>class</span> <span>Class</span>
  <span>def</span> <span>self</span><span>.</span><span>new</span><span>(</span><span>...</span><span>)</span>
    <span>instance</span> <span>=</span> <span>allocate</span>
    <span>instance</span><span>.</span><span>initialize</span><span>(</span><span>...</span><span>)</span>
    <span>instance</span>
  <span>end</span>
<span>end</span>
</code></pre></div>

<p>The problem with the above code is the inline cache at the <code>initialize</code> call site.
When we make method calls, Ruby will try to cache the destination of that call.
That way we can speed up subsequent calls on the same type at that call site.</p>

<p>CRuby only has a monomorphic inline cache, meaning it can only store one inline cache at any particular call site.
The inline cache is used to help look up the method we will call, and the key to the cache is the class of the receiver (in this case, the class of the <code>instance</code> local variable).
Each time the type of the receiver changes, the cache misses, and we have to do a slow path lookup of the method.</p>

<p>It’s very rare for code to allocate exactly the same type of object many times in a row, so the class of the <code>instance</code> local variable will change quite frequently.
Meaning we could potentially have very poor cache hit rates.
Even if the call site could support multiple cache entries (a “polymorphic” inline cache), the cardinality at this particular call site would be so high that cache hit rates would still be quite poor.</p>

<p>I showed this PR to <a href="https://github.com/ko1">Koichi Sasada</a> (author of YARV), and he suggested that instead of implementing <code>Class#new</code> in Ruby, we add a new YARV instruction and “inline” the implementation of <code>Class#new</code>.
I worked with <a href="https://github.com/jhawthorn">John Hawthorn</a> to implement it and we had a prototype implementation done within a week.
Fortunately (or unfortunately) this prototype turned out to be <em>much</em> faster than a Ruby implementation of <code>Class#new</code>, so I decided to abandon that effort.</p>

<h3 id="inlining-classnew">Inlining <code>Class#new</code></h3>

<p>So what is inlining?
Inlining is pretty much just copy / pasting code from the callee to the caller.</p>



<p>Any time the compiler sees code like the above, instead of generating a simple method call to <code>new</code>, it generates the instructions that <code>new</code> <em>would have used</em> but at the call site of <code>new</code>.</p>

<p>To make this more concrete, lets look at the instructions for the above code before and after inlining.</p>

<p>Here is the bytecode for <code>Foo.new</code> before inlining:</p>

<div><pre><code>&gt; ruby -v --dump=insns -e'Foo.new'
ruby 3.4.2 (2025-02-15 revision d2930f8e7a) +PRISM [arm64-darwin24]
== disasm: #&lt;ISeq:&lt;main&gt;@-e:1 (1,0)-(1,7)&gt;
0000 opt_getconstant_path                   &lt;ic:0 Foo&gt;                (   1)[Li]
0002 opt_send_without_block                 &lt;calldata!mid:new, argc:0, ARGS_SIMPLE&gt;
0004 leave
</code></pre></div>

<p>Here is the bytecode for <code>Foo.new</code> after inlining:</p>

<div><pre><code>&gt; ./ruby -v --dump=insns -e'Foo.new'
ruby 3.5.0dev (2025-04-29T20:36:06Z master b5426826f9) +PRISM [arm64-darwin24]
== disasm: #&lt;ISeq:&lt;main&gt;@-e:1 (1,0)-(1,7)&gt;
0000 opt_getconstant_path                   &lt;ic:0 Foo&gt;                (   1)[Li]
0002 putnil
0003 swap
0004 opt_new                                &lt;calldata!mid:new, argc:0, ARGS_SIMPLE&gt;, 11
0007 opt_send_without_block                 &lt;calldata!mid:initialize, argc:0, FCALL|ARGS_SIMPLE&gt;
0009 jump                                   14
0011 opt_send_without_block                 &lt;calldata!mid:new, argc:0, ARGS_SIMPLE&gt;
0013 swap
0014 pop
0015 leave
</code></pre></div>

<p>Before inlining, the instructions look up the constant <code>Foo</code>, then call the <code>new</code> method.
After inlining, we still look up the constant <code>Foo</code>, but instead of calling the <code>new</code> method, there are a bunch of other instructions.</p>

<p>The most important of these new instructions is the <code>opt_new</code> instruction which allocates a new instance and writes that instance to the stack.
Immediately after the <code>opt_new</code> instruction we see a method call to <code>initialize</code>.
These instructions effectively allocate a new instance and call initialize on that instance, the same thing that <code>Class#new</code> <em>would</em> have done, but without actually calling <code>Class#new</code>.</p>

<p>What’s really nice about this is that any parameters pushed onto the stack <em>are left on the stack</em> for the <code>initialize</code> method to consume.
Where we had to do copies in the C implementation, there are no longer any copies!
Additionally, we no longer push and pop a stack frame for <code>Class#new</code> which further speeds up our code.</p>

<p>Finally, since every call to <code>new</code> includes another call to <code>initialize</code> we have very good cache hit rates compared to the pure Ruby implementation of <code>Class#new</code>.
Rather than <em>one</em> <code>initialize</code> call site, we have an <code>initialize</code> call site at every call to <code>new</code>.</p>

<p>Eliminating a stack frame, eliminating parameter copies, and improving inline cache hits are the major advantages of this optimization.</p>

<h3 id="downsides-to-inlining">Downsides to Inlining</h3>

<p>Of course this optimization is not without downsides.</p>

<p>First, there are more instructions, so it requires more memory usage.
However, this memory increase only grows in proportion to the number of call sites that use <code>new</code>.
We measured this in our monolith and only saw a 0.5% growth in instruction sequence size, which is an even smaller percentage of overall heap size.</p>

<p>Second, this optimization introduces a small backwards incompatibility.
Consider the following code:</p>

<div><pre><code><span>class</span> <span>Foo</span>
  <span>def</span> <span>initialize</span>
    <span>puts</span> <span>caller</span>
  <span>end</span>
<span>end</span>

<span>def</span> <span>test</span>
  <span>Foo</span><span>.</span><span>new</span>
<span>end</span>

<span>test</span>
</code></pre></div>

<p>If we run this code with Ruby 3.4, the output is like this:</p>

<div><pre><code>&gt; ruby -v test.rb
ruby 3.4.2 (2025-02-15 revision d2930f8e7a) +PRISM [arm64-darwin24]
test.rb:8:in 'Class#new'
test.rb:8:in 'Object#test'
test.rb:11:in '&lt;main&gt;'
</code></pre></div>

<p>If we run this code with Ruby 3.5, the output is like this:</p>

<div><pre><code>&gt; ./ruby -v test.rb
ruby 3.5.0dev (2025-04-29T20:36:06Z master b5426826f9) +PRISM [arm64-darwin24]
test.rb:8:in 'Object#test'
test.rb:11:in '&lt;main&gt;'
</code></pre></div>

<p>The <code>Class#new</code> frame is missing from Ruby 3.5 and that is because the frame has been eliminated.</p>

<h2 id="conclusion">Conclusion</h2>

<p>If you’ve made it this far, I hope you found the topic interesting.
I’m really excited for Ruby 3.5 to be released later this year, and I hope you are too!
I want to thank Koichi Sasada for suggesting inlining (and the <code>opt_new</code> instruction) and John Hawthorn for helping me with the implementation.</p>

<p>If you’re curious, take a look at the implementation in the <a href="https://github.com/ruby/ruby/pull/13080">pull request</a> and the discussion in the <a href="https://bugs.ruby-lang.org/issues/21254">RedMine ticket</a>.
I didn’t explain every detail of this patch (for example, what happens if you’re calling <code>new</code> on something that isn’t a class?) so if you have questions don’t hesitate to email me or ask on social media.</p>

<p>Have a good day!</p>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: SQLite JavaScript - extend your database with JavaScript (157 pts)]]></title>
            <link>https://github.com/sqliteai/sqlite-js</link>
            <guid>44061836</guid>
            <pubDate>Thu, 22 May 2025 13:25:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/sqliteai/sqlite-js">https://github.com/sqliteai/sqlite-js</a>, See on <a href="https://news.ycombinator.com/item?id=44061836">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">SQLite-JS Extension</h2><a id="user-content-sqlite-js-extension" aria-label="Permalink: SQLite-JS Extension" href="#sqlite-js-extension"></a></p>
<p dir="auto">SQLite-JS is a powerful extension that brings JavaScript capabilities to SQLite. With this extension, you can create custom SQLite functions, aggregates, window functions, and collation sequences using JavaScript code, allowing for flexible and powerful data manipulation directly within your SQLite database.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#installation">Installation</a></li>
<li><a href="#functions-overview">Functions Overview</a></li>
<li><a href="#scalar-functions">Scalar Functions</a></li>
<li><a href="#aggregate-functions">Aggregate Functions</a></li>
<li><a href="#window-functions">Window Functions</a></li>
<li><a href="#collation-sequences">Collation Sequences</a></li>
<li><a href="#syncing-across-devices">Sync JavaScript Functions Across Devices</a></li>
<li><a href="#javascript-evaluation">JavaScript Evaluation</a></li>
<li><a href="#examples">Examples</a></li>
<li><a href="#update-functions">Update Functions</a></li>
<li><a href="#building-from-source">Building from Source</a></li>
<li><a href="#license">License</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pre-built Binaries</h3><a id="user-content-pre-built-binaries" aria-label="Permalink: Pre-built Binaries" href="#pre-built-binaries"></a></p>
<p dir="auto">Download the appropriate pre-built binary for your platform from the official <a href="https://github.com/sqliteai/sqlite-js/releases">Releases</a> page:</p>
<ul dir="auto">
<li>Linux: x86 and ARM</li>
<li>macOS: x86 and ARM</li>
<li>Windows: x86</li>
<li>Android</li>
<li>iOS</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Loading the Extension</h3><a id="user-content-loading-the-extension" aria-label="Permalink: Loading the Extension" href="#loading-the-extension"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="-- In SQLite CLI
.load ./js

-- In SQL
SELECT load_extension('./js');"><pre><span><span>--</span> In SQLite CLI</span>
.load .<span>/</span>js

<span><span>--</span> In SQL</span>
<span>SELECT</span> load_extension(<span><span>'</span>./js<span>'</span></span>);</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Functions Overview</h2><a id="user-content-functions-overview" aria-label="Permalink: Functions Overview" href="#functions-overview"></a></p>
<p dir="auto">SQLite-JS provides several ways to extend SQLite functionality with JavaScript:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Function Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Scalar Functions</td>
<td>Process individual rows and return a single value</td>
</tr>
<tr>
<td>Aggregate Functions</td>
<td>Process multiple rows and return a single aggregated result</td>
</tr>
<tr>
<td>Window Functions</td>
<td>Similar to aggregates but can access the full dataset</td>
</tr>
<tr>
<td>Collation Sequences</td>
<td>Define custom sort orders for text values</td>
</tr>
<tr>
<td>JavaScript Evaluation</td>
<td>Directly evaluate JavaScript code within SQLite</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Scalar Functions</h2><a id="user-content-scalar-functions" aria-label="Permalink: Scalar Functions" href="#scalar-functions"></a></p>
<p dir="auto">Scalar functions process one row at a time and return a single value. They are useful for data transformation, calculations, text manipulation, etc.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="SELECT js_create_scalar('function_name', 'function_code');"><pre><span>SELECT</span> js_create_scalar(<span><span>'</span>function_name<span>'</span></span>, <span><span>'</span>function_code<span>'</span></span>);</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Parameters</h3><a id="user-content-parameters" aria-label="Permalink: Parameters" href="#parameters"></a></p>
<ul dir="auto">
<li><strong>function_name</strong>: The name of your custom function</li>
<li><strong>function_code</strong>: JavaScript code that defines your function. Must be in the form <code>function(args) { /* your code here */ }</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example</h3><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="-- Create a custom function to calculate age from birth date
SELECT js_create_scalar('age', 'function(args) {
  const birthDate = new Date(args[0]);
  const today = new Date();
  let age = today.getFullYear() - birthDate.getFullYear();
  const m = today.getMonth() - birthDate.getMonth();
  if (m < 0 || (m === 0 &amp;&amp; today.getDate() < birthDate.getDate())) {
    age--;
  }
  return age;
}');

-- Use the function
SELECT name, age(birth_date) FROM people;"><pre><span><span>--</span> Create a custom function to calculate age from birth date</span>
<span>SELECT</span> js_create_scalar(<span><span>'</span>age<span>'</span></span>, <span><span>'</span>function(args) {</span>
<span>  const birthDate = new Date(args[0]);</span>
<span>  const today = new Date();</span>
<span>  let age = today.getFullYear() - birthDate.getFullYear();</span>
<span>  const m = today.getMonth() - birthDate.getMonth();</span>
<span>  if (m &lt; 0 || (m === 0 &amp;&amp; today.getDate() &lt; birthDate.getDate())) {</span>
<span>    age--;</span>
<span>  }</span>
<span>  return age;</span>
<span>}<span>'</span></span>);

<span><span>--</span> Use the function</span>
<span>SELECT</span> name, age(birth_date) <span>FROM</span> people;</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Aggregate Functions</h2><a id="user-content-aggregate-functions" aria-label="Permalink: Aggregate Functions" href="#aggregate-functions"></a></p>
<p dir="auto">Aggregate functions process multiple rows and compute a single result. Examples include SUM, AVG, and COUNT in standard SQL.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage-1" aria-label="Permalink: Usage" href="#usage-1"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="SELECT js_create_aggregate('function_name', 'init_code', 'step_code', 'final_code');"><pre><span>SELECT</span> js_create_aggregate(<span><span>'</span>function_name<span>'</span></span>, <span><span>'</span>init_code<span>'</span></span>, <span><span>'</span>step_code<span>'</span></span>, <span><span>'</span>final_code<span>'</span></span>);</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Parameters</h3><a id="user-content-parameters-1" aria-label="Permalink: Parameters" href="#parameters-1"></a></p>
<ul dir="auto">
<li><strong>function_name</strong>: The name of your custom aggregate function</li>
<li><strong>init_code</strong>: JavaScript code that initializes variables for the aggregation</li>
<li><strong>step_code</strong>: JavaScript code that processes each row. Must be in the form <code>function(args) { /* your code here */ }</code></li>
<li><strong>final_code</strong>: JavaScript code that computes the final result. Must be in the form <code>function() { /* your code here */ }</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example</h3><a id="user-content-example-1" aria-label="Permalink: Example" href="#example-1"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="-- Create a median function
SELECT js_create_aggregate('median', 
  -- Init code: initialize an array to store values
  'values = [];',
  
  -- Step code: collect values from each row
  'function(args) {
    values.push(args[0]);
  }',
  
  -- Final code: calculate the median
  'function() {
    values.sort((a, b) => a - b);
    const mid = Math.floor(values.length / 2);
    if (values.length % 2 === 0) {
      return (values[mid-1] + values[mid]) / 2;
    } else {
      return values[mid];
    }
  }'
);

-- Use the function
SELECT median(salary) FROM employees;"><pre><span><span>--</span> Create a median function</span>
<span>SELECT</span> js_create_aggregate(<span><span>'</span>median<span>'</span></span>, 
  <span><span>--</span> Init code: initialize an array to store values</span>
  <span><span>'</span>values = [];<span>'</span></span>,
  
  <span><span>--</span> Step code: collect values from each row</span>
  <span><span>'</span>function(args) {</span>
<span>    values.push(args[0]);</span>
<span>  }<span>'</span></span>,
  
  <span><span>--</span> Final code: calculate the median</span>
  <span><span>'</span>function() {</span>
<span>    values.sort((a, b) =&gt; a - b);</span>
<span>    const mid = Math.floor(values.length / 2);</span>
<span>    if (values.length % 2 === 0) {</span>
<span>      return (values[mid-1] + values[mid]) / 2;</span>
<span>    } else {</span>
<span>      return values[mid];</span>
<span>    }</span>
<span>  }<span>'</span></span>
);

<span><span>--</span> Use the function</span>
<span>SELECT</span> median(salary) <span>FROM</span> employees;</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Window Functions</h2><a id="user-content-window-functions" aria-label="Permalink: Window Functions" href="#window-functions"></a></p>
<p dir="auto">Window functions, like aggregate functions, operate on a set of rows. However, they can access all rows in the current window without collapsing them into a single output row.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage-2" aria-label="Permalink: Usage" href="#usage-2"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="SELECT js_create_window('function_name', 'init_code', 'step_code', 'final_code', 'value_code', 'inverse_code');"><pre><span>SELECT</span> js_create_window(<span><span>'</span>function_name<span>'</span></span>, <span><span>'</span>init_code<span>'</span></span>, <span><span>'</span>step_code<span>'</span></span>, <span><span>'</span>final_code<span>'</span></span>, <span><span>'</span>value_code<span>'</span></span>, <span><span>'</span>inverse_code<span>'</span></span>);</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Parameters</h3><a id="user-content-parameters-2" aria-label="Permalink: Parameters" href="#parameters-2"></a></p>
<ul dir="auto">
<li><strong>function_name</strong>: The name of your custom window function</li>
<li><strong>init_code</strong>: JavaScript code that initializes variables</li>
<li><strong>step_code</strong>: JavaScript code that processes each row. Must be in the form <code>function(args) { /* your code here */ }</code></li>
<li><strong>final_code</strong>: JavaScript code that computes the final result. Must be in the form <code>function() { /* your code here */ }</code></li>
<li><strong>value_code</strong>: JavaScript code that returns the current value. Must be in the form <code>function() { /* your code here */ }</code></li>
<li><strong>inverse_code</strong>: JavaScript code that removes a row from the current window. Must be in the form <code>function(args) { /* your code here */ }</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example</h3><a id="user-content-example-2" aria-label="Permalink: Example" href="#example-2"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="-- Create a moving average window function
SELECT js_create_window('moving_avg',
  -- Init code
  'sum = 0; count = 0;',
  
  -- Step code: process each row
  'function(args) {
    sum += args[0];
    count++;
  }',
  
  -- Final code: not needed for this example
  'function() { }',
  
  -- Value code: return current average
  'function() {
    return count > 0 ? sum / count : null;
  }',
  
  -- Inverse code: remove a value from the window
  'function(args) {
    sum -= args[0];
    count--;
  }'
);

-- Use the function
SELECT id, value, moving_avg(value) OVER (ORDER BY id ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) 
FROM measurements;"><pre><span><span>--</span> Create a moving average window function</span>
<span>SELECT</span> js_create_window(<span><span>'</span>moving_avg<span>'</span></span>,
  <span><span>--</span> Init code</span>
  <span><span>'</span>sum = 0; count = 0;<span>'</span></span>,
  
  <span><span>--</span> Step code: process each row</span>
  <span><span>'</span>function(args) {</span>
<span>    sum += args[0];</span>
<span>    count++;</span>
<span>  }<span>'</span></span>,
  
  <span><span>--</span> Final code: not needed for this example</span>
  <span><span>'</span>function() { }<span>'</span></span>,
  
  <span><span>--</span> Value code: return current average</span>
  <span><span>'</span>function() {</span>
<span>    return count &gt; 0 ? sum / count : null;</span>
<span>  }<span>'</span></span>,
  
  <span><span>--</span> Inverse code: remove a value from the window</span>
  <span><span>'</span>function(args) {</span>
<span>    sum -= args[0];</span>
<span>    count--;</span>
<span>  }<span>'</span></span>
);

<span><span>--</span> Use the function</span>
<span>SELECT</span> id, value, moving_avg(value) OVER (<span>ORDER BY</span> id ROWS BETWEEN <span>2</span> PRECEDING <span>AND</span> CURRENT ROW) 
<span>FROM</span> measurements;</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Collation Sequences</h2><a id="user-content-collation-sequences" aria-label="Permalink: Collation Sequences" href="#collation-sequences"></a></p>
<p dir="auto">Collation sequences determine how text values are compared and sorted in SQLite. Custom collations enable advanced sorting capabilities like natural sorting, locale-specific sorting, etc.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage-3" aria-label="Permalink: Usage" href="#usage-3"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="SELECT js_create_collation('collation_name', 'collation_function');"><pre><span>SELECT</span> js_create_collation(<span><span>'</span>collation_name<span>'</span></span>, <span><span>'</span>collation_function<span>'</span></span>);</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Parameters</h3><a id="user-content-parameters-3" aria-label="Permalink: Parameters" href="#parameters-3"></a></p>
<ul dir="auto">
<li><strong>collation_name</strong>: The name of your custom collation</li>
<li><strong>collation_function</strong>: JavaScript code that compares two strings. Must return a negative number if the first string is less than the second, zero if they are equal, or a positive number if the first string is greater than the second.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example</h3><a id="user-content-example-3" aria-label="Permalink: Example" href="#example-3"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="-- Create a case-insensitive natural sort collation
SELECT js_create_collation('natural_nocase', 'function(a, b) {
  // Extract numbers for natural comparison
  const splitA = a.toLowerCase().split(/(\d+)/);
  const splitB = b.toLowerCase().split(/(\d+)/);
  
  for (let i = 0; i < Math.min(splitA.length, splitB.length); i++) {
    if (splitA[i] !== splitB[i]) {
      if (!isNaN(splitA[i]) &amp;&amp; !isNaN(splitB[i])) {
        return parseInt(splitA[i]) - parseInt(splitB[i]);
      }
      return splitA[i].localeCompare(splitB[i]);
    }
  }
  return splitA.length - splitB.length;
}');

-- Use the collation
SELECT * FROM files ORDER BY name COLLATE natural_nocase;"><pre><span><span>--</span> Create a case-insensitive natural sort collation</span>
<span>SELECT</span> js_create_collation(<span><span>'</span>natural_nocase<span>'</span></span>, <span><span>'</span>function(a, b) {</span>
<span>  // Extract numbers for natural comparison</span>
<span>  const splitA = a.toLowerCase().split(/(<span>\d</span>+)/);</span>
<span>  const splitB = b.toLowerCase().split(/(<span>\d</span>+)/);</span>
<span>  </span>
<span>  for (let i = 0; i &lt; Math.min(splitA.length, splitB.length); i++) {</span>
<span>    if (splitA[i] !== splitB[i]) {</span>
<span>      if (!isNaN(splitA[i]) &amp;&amp; !isNaN(splitB[i])) {</span>
<span>        return parseInt(splitA[i]) - parseInt(splitB[i]);</span>
<span>      }</span>
<span>      return splitA[i].localeCompare(splitB[i]);</span>
<span>    }</span>
<span>  }</span>
<span>  return splitA.length - splitB.length;</span>
<span>}<span>'</span></span>);

<span><span>--</span> Use the collation</span>
<span>SELECT</span> <span>*</span> <span>FROM</span> files <span>ORDER BY</span> name COLLATE natural_nocase;</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Syncing Across Devices</h2><a id="user-content-syncing-across-devices" aria-label="Permalink: Syncing Across Devices" href="#syncing-across-devices"></a></p>
<p dir="auto">When used with <a href="https://github.com/sqliteai/sqlite-sync/">sqlite-sync</a>, user-defined functions created via sqlite-js are automatically replicated across the SQLite Cloud cluster, ensuring that all connected peers share the same logic and behavior — even offline. To enable automatic persistence and sync the special <code>js_init_table</code> function must be executed.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage-4" aria-label="Permalink: Usage" href="#usage-4"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="SELECT js_init_table();         -- Create table if needed (no loading)
SELECT js_init_table(1);        -- Create table and load all stored functions"><pre><span>SELECT</span> js_init_table();         <span><span>--</span> Create table if needed (no loading)</span>
<span>SELECT</span> js_init_table(<span>1</span>);        <span><span>--</span> Create table and load all stored functions</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">JavaScript Evaluation</h2><a id="user-content-javascript-evaluation" aria-label="Permalink: JavaScript Evaluation" href="#javascript-evaluation"></a></p>
<p dir="auto">The extension also provides a way to directly evaluate JavaScript code within SQLite queries.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage-5" aria-label="Permalink: Usage" href="#usage-5"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="SELECT js_eval('javascript_code');"><pre><span>SELECT</span> js_eval(<span><span>'</span>javascript_code<span>'</span></span>);</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Parameters</h3><a id="user-content-parameters-4" aria-label="Permalink: Parameters" href="#parameters-4"></a></p>
<ul dir="auto">
<li><strong>javascript_code</strong>: Any valid JavaScript code to evaluate</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example</h3><a id="user-content-example-4" aria-label="Permalink: Example" href="#example-4"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="-- Perform a calculation
SELECT js_eval('Math.PI * Math.pow(5, 2)');

-- Format a date
SELECT js_eval('new Date(1629381600000).toLocaleDateString()');"><pre><span><span>--</span> Perform a calculation</span>
<span>SELECT</span> js_eval(<span><span>'</span>Math.PI * Math.pow(5, 2)<span>'</span></span>);

<span><span>--</span> Format a date</span>
<span>SELECT</span> js_eval(<span><span>'</span>new Date(1629381600000).toLocaleDateString()<span>'</span></span>);</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 1: String Manipulation</h3><a id="user-content-example-1-string-manipulation" aria-label="Permalink: Example 1: String Manipulation" href="#example-1-string-manipulation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="-- Create a function to extract domain from email
SELECT js_create_scalar('get_domain', 'function(args) {
  const email = args[0];
  return email.split(&quot;@&quot;)[1] || null;
}');

-- Use it in a query
SELECT email, get_domain(email) AS domain FROM users;"><pre><span><span>--</span> Create a function to extract domain from email</span>
<span>SELECT</span> js_create_scalar(<span><span>'</span>get_domain<span>'</span></span>, <span><span>'</span>function(args) {</span>
<span>  const email = args[0];</span>
<span>  return email.split("@")[1] || null;</span>
<span>}<span>'</span></span>);

<span><span>--</span> Use it in a query</span>
<span>SELECT</span> email, get_domain(email) <span>AS</span> domain <span>FROM</span> users;</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 2: Statistical Aggregation</h3><a id="user-content-example-2-statistical-aggregation" aria-label="Permalink: Example 2: Statistical Aggregation" href="#example-2-statistical-aggregation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="-- Create a function to calculate standard deviation
SELECT js_create_aggregate('stddev',
  'sum = 0; sumSq = 0; count = 0;',
  
  'function(args) {
    const val = args[0];
    sum += val;
    sumSq += val * val;
    count++;
  }',
  
  'function() {
    if (count < 2) return null;
    const variance = (sumSq - (sum * sum) / count) / (count - 1);
    return Math.sqrt(variance);
  }'
);

-- Use it in a query
SELECT department, stddev(salary) FROM employees GROUP BY department;"><pre><span><span>--</span> Create a function to calculate standard deviation</span>
<span>SELECT</span> js_create_aggregate(<span><span>'</span>stddev<span>'</span></span>,
  <span><span>'</span>sum = 0; sumSq = 0; count = 0;<span>'</span></span>,
  
  <span><span>'</span>function(args) {</span>
<span>    const val = args[0];</span>
<span>    sum += val;</span>
<span>    sumSq += val * val;</span>
<span>    count++;</span>
<span>  }<span>'</span></span>,
  
  <span><span>'</span>function() {</span>
<span>    if (count &lt; 2) return null;</span>
<span>    const variance = (sumSq - (sum * sum) / count) / (count - 1);</span>
<span>    return Math.sqrt(variance);</span>
<span>  }<span>'</span></span>
);

<span><span>--</span> Use it in a query</span>
<span>SELECT</span> department, stddev(salary) <span>FROM</span> employees <span>GROUP BY</span> department;</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example 3: Custom Window Function</h3><a id="user-content-example-3-custom-window-function" aria-label="Permalink: Example 3: Custom Window Function" href="#example-3-custom-window-function"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="-- Create a window function to calculate percentile within a window
SELECT js_create_window('percentile_rank',
  'values = [];',
  
  'function(args) {
    values.push(args[0]);
  }',
  
  'function() {
    values.sort((a, b) => a - b);
  }',
  
  'function() {
    const current = values[values.length - 1];
    const rank = values.indexOf(current);
    return (rank / (values.length - 1)) * 100;
  }',
  
  'function(args) {
    const index = values.indexOf(args[0]);
    if (index !== -1) {
      values.splice(index, 1);
    }
  }'
);

-- Use it in a query
SELECT name, score, 
       percentile_rank(score) OVER (ORDER BY score) 
FROM exam_results;"><pre><span><span>--</span> Create a window function to calculate percentile within a window</span>
<span>SELECT</span> js_create_window(<span><span>'</span>percentile_rank<span>'</span></span>,
  <span><span>'</span>values = [];<span>'</span></span>,
  
  <span><span>'</span>function(args) {</span>
<span>    values.push(args[0]);</span>
<span>  }<span>'</span></span>,
  
  <span><span>'</span>function() {</span>
<span>    values.sort((a, b) =&gt; a - b);</span>
<span>  }<span>'</span></span>,
  
  <span><span>'</span>function() {</span>
<span>    const current = values[values.length - 1];</span>
<span>    const rank = values.indexOf(current);</span>
<span>    return (rank / (values.length - 1)) * 100;</span>
<span>  }<span>'</span></span>,
  
  <span><span>'</span>function(args) {</span>
<span>    const index = values.indexOf(args[0]);</span>
<span>    if (index !== -1) {</span>
<span>      values.splice(index, 1);</span>
<span>    }</span>
<span>  }<span>'</span></span>
);

<span><span>--</span> Use it in a query</span>
<span>SELECT</span> name, score, 
       percentile_rank(score) OVER (<span>ORDER BY</span> score) 
<span>FROM</span> exam_results;</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Update Functions</h2><a id="user-content-update-functions" aria-label="Permalink: Update Functions" href="#update-functions"></a></p>
<p dir="auto">Due to a constraint in <a href="https://www3.sqlite.org/src/info/cabab62bc10568d4" rel="nofollow">SQLite</a>, it is not possible to update or redefine a user-defined function using the same database connection that was used to initially register it. To modify an existing JavaScript function, the update must be performed through a separate database connection.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building from Source</h2><a id="user-content-building-from-source" aria-label="Permalink: Building from Source" href="#building-from-source"></a></p>
<p dir="auto">See the included Makefile for building instructions:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Build for your current platform
make

# Build for a specific platform
make PLATFORM=macos
make PLATFORM=linux
make PLATFORM=windows

# Install
make install"><pre><span><span>#</span> Build for your current platform</span>
make

<span><span>#</span> Build for a specific platform</span>
make PLATFORM=macos
make PLATFORM=linux
make PLATFORM=windows

<span><span>#</span> Install</span>
make install</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License - see the LICENSE file for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making the rav1d Video Decoder 1% Faster (268 pts)]]></title>
            <link>https://ohadravid.github.io/posts/2025-05-rav1d-faster/</link>
            <guid>44061160</guid>
            <pubDate>Thu, 22 May 2025 11:59:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ohadravid.github.io/posts/2025-05-rav1d-faster/">https://ohadravid.github.io/posts/2025-05-rav1d-faster/</a>, See on <a href="https://news.ycombinator.com/item?id=44061160">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>*on macOS with an M3 chip</em><br><em>*slightly more than 1%, on a specific benchmark, without any new unsafe code</em></p><p>A while ago, <a href="https://www.memorysafety.org/blog/rav1d-perf-bounty/">memorysafety.org announced a contest</a> for improving performance of <code>rav1d</code>, a Rust port of the <code>dav1d</code> AV1 decoder.</p><p>As this literally has my name written on it, I thought it would be fun to give it a try (even though I <em>probably</em> can’t participate in the contest).</p><p>This is a write-up about two small performance improvements I found (<a href="https://github.com/memorysafety/rav1d/pull/1397">1st PR</a>, <a href="https://github.com/memorysafety/rav1d/pull/1400">2nd PR</a>) and how I found them (you can also jump to the <a href="#summary">summary in the end</a>).</p><p><img src="https://ohadravid.github.io/2025-05-rav1d-faster/drakeposting.webp" alt="drakeposting meme - working on rav1d because there’s a contest with money, working on rav1d because my last name is Ravid"></p><h2 id="background-and-approach">Background and Approach</h2><p><a href="https://github.com/memorysafety/rav1d"><code>rav1d</code></a> is a port of <a href="https://code.videolan.org/videolan/dav1d"><code>dav1d</code></a>, created by (1) running <a href="https://github.com/immunant/c2rust"><code>c2rust</code></a> on <code>dav1d</code>, (2) incorporating <code>dav1d</code>’s asm-optimized functions, and (3) changing the code to be more Rust-y and safer.</p><p>The authors also published <a href="https://www.memorysafety.org/blog/rav1d-performance-optimization/">a detailed article</a> about the process and the performance work they did.</p><p>More recently, the contest was announced, with the baseline being:</p><blockquote><p>Our Rust-based rav1d decoder is currently about 5% slower than the C-based dav1d decoder.</p></blockquote><p>Video decoders are notoriously complex pieces of software, but because we are comparing the performance of two similar deterministic binaries we might be able to avoid a lot of that complexity - with the right tooling.</p><p>We can’t expect to find huge wins, and some regressions might be too-hard-to-tackle (for example, LLVM finding a Rust function harder to optimize than the C version),
but it’s worth a shot, especially since aarch64 (my environment) is probably less optimized than x86_64.</p><p>My approach here was to:</p><ol><li>Use a sampling profiler to capture snapshots of both runs on the same input.</li><li>Use the optimized asm calls as “anchors” since they should match perfectly.</li><li>Compare the Rust and C versions function by function, and if there’s a big enough discrepancy, dive into that function.</li></ol><h2 id="baseline">Baseline</h2><p>First things first, we need to build and compare perf locally (using <code>hyperfine</code> and the sample files noted in the contest’s rules and <code>rav1d</code>’s <a href="https://github.com/memorysafety/rav1d/blob/main/.github/workflows/build-and-benchmark-x86.yml">CI</a>).</p><p>We’ll be using the single threaded version (<code>--threads 1</code>) to keep things simple.</p><p>For <code>rav1d</code>:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ git clone git@github.com:memorysafety/rav1d.git <span>&amp;&amp;</span> <span>cd</span> rav1d <span>&amp;&amp;</span> git log -n1
</span></span><span><span>commit a654c1e82adb2d9a33ae50d2a82a7a747102cbb6
</span></span><span><span>$ rustc --version --verbose <span># set by rust-toolchain.toml</span>
</span></span><span><span>rustc 1.88.0-nightly <span>(</span>b45dd71d1 2025-04-30<span>)</span>
</span></span><span><span>...
</span></span><span><span>LLVM version: 20.1.2
</span></span><span><span>$ cargo build --release
</span></span><span><span>    Finished <span>`</span>release<span>`</span> profile <span>[</span>optimized<span>]</span> target<span>(</span>s<span>)</span> in ..
</span></span><span><span>$ hyperfine --warmup <span>2</span> <span>"target/release/dav1d -q -i Chimera-AV1-8bit-1920x1080-6736kbps.ivf -o /dev/null --threads 1"</span>
</span></span><span><span>Benchmark 1: target/release/dav1d -q -i Chimera-AV1-8bit-1920x1080-6736kbps.ivf -o /dev/null --threads <span>1</span>
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:     73.914 s ±  0.151 s    <span>[</span>User: 73.295 s, System: 0.279 s<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:   73.770 s … 74.132 s    <span>10</span> runs
</span></span></code></pre></div><p>For <code>dav1d</code>:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ git clone https://code.videolan.org/videolan/dav1d.git <span>&amp;&amp;</span> <span>cd</span> dav1d <span>&amp;&amp;</span> git checkout 1.5.1
</span></span><span><span>$ brew install llvm@20 <span>&amp;&amp;</span> <span>export</span> CC<span>=</span>clang<span>;</span> $CC --version
</span></span><span><span>Homebrew clang version 20.1.4
</span></span><span><span>$ meson setup build <span>"-Dbitdepths=['8','16']"</span>
</span></span><span><span>$ bear -- ninja -C build tools/dav1d
</span></span><span><span>...
</span></span><span><span><span>[</span>88/88<span>]</span> Linking target tools/dav1d
</span></span><span><span>$ hyperfine --warmup <span>2</span> <span>"build/tools/dav1d -q -i Chimera-AV1-8bit-1920x1080-6736kbps.ivf -o /dev/null --threads 1"</span>
</span></span><span><span>Benchmark 1: build/tools/dav1d -q -i Chimera-AV1-8bit-1920x1080-6736kbps.ivf -o /dev/null --threads <span>1</span>
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:     67.912 s ±  0.541 s    <span>[</span>User: 67.208 s, System: 0.282 s<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:   66.933 s … 68.948 s    <span>10</span> runs
</span></span></code></pre></div><p>So <code>rav1d</code> is about 9% (6 seconds) slower than <code>dav1d</code> for that sample file, at least on an M3 chip.</p><p>(Ideally, <code>clang</code> and <code>rustc</code> should use the same LLVM version, but a patch version difference is probably fine.)<br>(Measured on a MacBook Air M3 with 8 cores.)</p><h2 id="profiling">Profiling</h2><p>I used <a href="https://github.com/mstange/samply">samply</a> which is my current go-to sampling profiler:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>./dav1d $ sudo samply record ./build/tools/dav1d -q -i /Chimera-AV1-8bit-1920x1080-6736kbps.ivf -o /dev/null --threads <span>1</span>
</span></span><span><span>./rav1d $ sudo samply record ./target/release/dav1d -q -i /Chimera-AV1-8bit-1920x1080-6736kbps.ivf -o /dev/null --threads <span>1</span>
</span></span></code></pre></div><p>(The Rust binary is also called <code>dav1d</code>, which is a bit confusing.)</p><p>By default, <code>samply</code> uses a rate of 1000Hz, which means that (for example) any diff of 500 samples in a function will account for about 0.5 second of runtime difference.</p><p>Usually, starting with the “inverted stack” view helps to narrow down interesting options (which we’ll explore in <a href="#profiling-again-but-inverted">the next section</a>),
but this time we want to focus on the anchors we know should match: the asm functions.</p><p>You can view the full profiler snapshots online in the Firefox Profiler (<a href="https://profiler.firefox.com/from-url/https%3A%2F%2Fohadravid.github.io%2F2025-05-rav1d-faster%2Fdav1d_profile.json.gz/calltree/?assemblyView=2~11c50~174~dav1d_filter_sbrow_cdef_8bpc&amp;globalTrackOrder=0&amp;search=dav1d_cdef_brow_8bpc&amp;thread=0&amp;v=10">dav1d</a>, <a href="https://profiler.firefox.com/from-url/https%3A%2F%2Fohadravid.github.io%2F2025-05-rav1d-faster%2Frav1d_profile_baseline.json.gz/calltree/?globalTrackOrder=0&amp;search=rav1d_cdef_brow&amp;thread=0&amp;v=10">rav1d</a>),
but here are the relevant, filtered, clippings (<em>Note: these are not interactive. Check out the links if you want to explore more</em>).</p><p>First, here’s the <code>dav1d</code> (C) version (total number of samples: ~69,500):</p><p>Next, here’s the <code>rav1d</code> (Rust) version (total number of samples: ~75,150):</p><p>Look at the highlighted functions, <code>dav1d_cdef_brow_8bpc</code> and <code>rav1d_cdef_brow</code>.<br>The <em>Total</em> sample count is the number of samples where this function was seen “anywhere in the stack” which means it includes any “children” functions called by it.
The <em>Self</em> sample count is the number of samples in which this was the executing function, so it doesn’t include the children’s sample counts.</p><p>There is a slight divergence between <code>dav1d</code> and <code>rav1d</code>: while the <code>_neon</code> extension notes the Arm-specific assembly functions that are shared between the two binaries, we see that:</p><ol><li><code>dav1d</code> calls <code>cdef_filter_8x8_neon</code> and <code>cdef_filter_4x4_neon</code>, and each of them dispatches the relevant assembly functions (either the <code>8</code> or the <code>4</code> version, respectively).</li><li><code>rav1d</code> calls <code>cdef_filter_neon_erased</code>, which handles the dispatch of <em>all</em> the assembly functions.</li></ol><p>We can also see that <code>cdef_filter8_pri_sec_edged_8bpc_neon</code> has almost identical sample counts in both snapshots, which means we are on the right track.</p><p>Let’s ignore the <code>cdef_filter4_pri_edged_8bpc_neon</code> function which <em>doesn’t match</em>, at least for now (<em>foreshadowing a possible part 2 in the series</em>).</p><p>This means that (A) the <em>Self</em> sample count for <code>dav1d_cdef_brow_8bpc</code> should match <code>rav1d_cdef_brow</code>,
<strong>and</strong> (B) that summing both <code>cdef_filter_{8x8,4x4}_neon</code> <em>Self</em> sample counts should match <code>cdef_filter_neon_erased</code> <em>Self</em> sample count.</p><p>Now we see something interesting: focusing in the second part, the summed <em>Self</em> sample count of <code>cdef_filter_{8x8,4x4}_neon</code> is about 400 samples, while <code>rav1d</code>’s <code>cdef_filter_neon_erased</code> is almost 670 samples. We can also see that <code>dav1d_cdef_brow_8bpc</code> is 1790 samples, vs <code>rav1d_cdef_brow</code>’s 2350 samples.</p><p>Together, this difference accounts for about 1% of the total runtime of <code>rav1d</code>!</p><p>Jumping to the <code>cdef_filter_neon_erased</code> implementation, except for a bunch of pointer casting using <code>.cast()</code>,
there’s only one “big thing” going on that’s not part of the call-to-asm machinery:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>#[deny(unsafe_op_in_unsafe_fn)]</span>
</span></span><span><span><span>pub</span> <span>unsafe</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>cdef_filter_neon_erased</span><span>&lt;</span>
</span></span><span><span>    <span>BD</span>: <span>BitDepth</span><span>,</span>
</span></span><span><span>    <span>const</span> W: <span>usize</span><span>,</span>
</span></span><span><span>    <span>const</span> H: <span>usize</span><span>,</span>
</span></span><span><span>    <span>const</span> <span>TMP_STRIDE</span>: <span>usize</span><span>,</span>
</span></span><span><span>    <span>const</span> <span>TMP_LEN</span>: <span>usize</span><span>,</span>
</span></span><span><span><span>&gt;</span><span>(</span>
</span></span><span><span>    <span>// .. snip ..
</span></span></span><span><span><span></span><span>)</span> <span>{</span>
</span></span><span><span>    <span>use</span> <span>crate</span>::src::align::Align16<span>;</span>
</span></span><span><span>
</span></span><span><span>    <span>// .. snip ..
</span></span></span><span><span><span></span>
</span></span><span><span>    <span>let</span> <span>mut</span> tmp_buf <span>=</span> Align16<span>([</span><span>0</span><span>u16</span><span>;</span> <span>TMP_LEN</span><span>]);</span>
</span></span><span><span>    <span>let</span> tmp <span>=</span> <span>&amp;</span><span>mut</span> tmp_buf<span>.</span><span>0</span><span>[</span><span>2</span> <span>*</span> <span>TMP_STRIDE</span> <span>+</span> <span>8</span><span>..</span><span>];</span>
</span></span><span><span>    
</span></span><span><span>    padding::<span>Fn</span>::neon::<span>&lt;</span><span>BD</span><span>,</span> W<span>&gt;</span><span>().</span>call::<span>&lt;</span><span>BD</span><span>&gt;</span><span>(</span>tmp<span>,</span> dst<span>,</span> stride<span>,</span> left<span>,</span> top<span>,</span> bottom<span>,</span> H<span>,</span> edges<span>);</span>
</span></span><span><span>    filter::<span>Fn</span>::neon::<span>&lt;</span><span>BD</span><span>,</span> W<span>&gt;</span><span>().</span>call<span>(</span>dst<span>,</span> stride<span>,</span> tmp<span>,</span> pri_strength<span>,</span> sec_strength<span>,</span> dir<span>,</span> damping<span>,</span> H<span>,</span> edges<span>,</span> bd<span>);</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>With <code>TMP_LEN</code> being <code>12 * 16 + 8 = 200</code> or <code>12 * 8 + 8 = 104</code>, so <code>tmp_buf = [u16; 200]</code> in the worst case.
That’s a lot of memory to zero for a scratch buffer!</p><p>What does <code>dav1d</code> do here?</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#define DEFINE_FILTER(w, h, tmp_stride)                                      \
</span></span></span><span><span><span>static void                                                                  \
</span></span></span><span><span><span>cdef_filter_##w##x##h##_neon(</span><span>/* .. snip .. */</span><span>)                               \
</span></span></span><span><span><span>{                                                                            \
</span></span></span><span><span><span>    ALIGN_STK_16(uint16_t, tmp_buf, 12 * tmp_stride + 8,);                   \
</span></span></span><span><span><span>    uint16_t *tmp = tmp_buf + 2 * tmp_stride + 8;                            \
</span></span></span><span><span><span>    BF(dav1d_cdef_padding##w, neon)(tmp, dst, stride,                        \
</span></span></span><span><span><span>                                    left, top, bottom, h, edges);            \
</span></span></span><span><span><span>    BF(dav1d_cdef_filter##w, neon)(dst, stride, tmp, pri_strength,           \
</span></span></span><span><span><span>                                   sec_strength, dir, damping, h, edges      \
</span></span></span><span><span><span>                                   HIGHBD_TAIL_SUFFIX);                      \
</span></span></span><span><span><span>}
</span></span></span><span><span><span></span>
</span></span><span><span><span>DEFINE_FILTER</span><span>(</span><span>8</span><span>,</span> <span>8</span><span>,</span> <span>16</span><span>)</span>
</span></span><span><span><span>DEFINE_FILTER</span><span>(</span><span>4</span><span>,</span> <span>8</span><span>,</span> <span>8</span><span>)</span>
</span></span><span><span><span>DEFINE_FILTER</span><span>(</span><span>4</span><span>,</span> <span>4</span><span>,</span> <span>8</span><span>)</span>
</span></span></code></pre></div><p>A few macro expansions later, we get <code>uint16_t tmp_buf[200] __attribute__((aligned(16)));</code></p><p>This means that <code>tmp_buf</code> isn’t initialized by the <code>cdef_filter_{8x8,4x4}_neon</code> functions:
instead, it is used as a write destination for the <code>padding</code> assembly function,
and later by the <code>filter</code> assembly function as-is.
It seems likely that the compiler doesn’t know this initialization can be eliminated,<br>and we can also use <code>--emit=llvm-ir</code> to see it more even directly:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ RUSTFLAGS<span>=</span><span>"--emit=llvm-ir"</span> cargo build --release --target aarch64-apple-darwin
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="llvm"><span><span><span>; rav1d::src::cdef::neon::cdef_filter_neon_erased
</span></span></span><span><span><span>; Function Attrs: nounwind
</span></span></span><span><span><span></span><span>define</span> <span>internal</span> <span>void</span> @_ZN5rav1d3src4cdef4neon23cdef_filter_neon_erased17h7e4dbe8ecff68724E<span>(</span><span>ptr</span> <span>no</span><span>undef</span> %dst<span>,</span> <span>i64</span> <span>no</span><span>undef</span> %stride<span>,</span> <span>ptr</span> <span>no</span><span>undef</span> %left<span>,</span> <span>ptr</span> <span>no</span><span>undef</span> %top<span>,</span> <span>ptr</span> <span>no</span><span>undef</span> %bottom<span>,</span> <span>i32</span> <span>no</span><span>undef</span> %pri_strength<span>,</span> <span>i32</span> <span>no</span><span>undef</span> %sec_strength<span>,</span> <span>i32</span> <span>no</span><span>undef</span> %dir<span>,</span> <span>i32</span> <span>no</span><span>undef</span> %damping<span>,</span> <span>i32</span> <span>no</span><span>undef</span> %edges<span>,</span> <span>i32</span> <span>no</span><span>undef</span> %bitdepth_max<span>,</span> <span>ptr</span> <span>nocapture</span> <span>readnone</span> %_dst<span>,</span> <span>ptr</span> <span>nocapture</span> <span>readnone</span> %_top<span>,</span> <span>ptr</span> <span>nocapture</span> <span>readnone</span> %_bottom<span>)</span> <span>unnamed_addr</span> #1 <span>{</span>
</span></span><span><span><span>start:</span>
</span></span><span><span>  %tmp_buf <span>=</span> <span>alloca</span> <span>[</span><span>400</span> <span>x</span> <span>i8</span><span>],</span> <span>align</span> <span>16</span>
</span></span><span><span>  <span>call</span> <span>void</span> @llvm.lifetime.start.p0<span>(</span><span>i64</span> <span>400</span><span>,</span> <span>ptr</span> <span>nonnull</span> %tmp_buf<span>)</span>
</span></span><span><span>  <span>call</span> <span>void</span> @llvm.memset.p0.i64<span>(</span><span>ptr</span> <span>no</span><span>undef</span> <span>nonnull</span> <span>align</span> <span>16</span> <span>dereferenceable</span><span>(</span><span>400</span><span>)</span> %tmp_buf<span>,</span> <span>i8</span> <span>0</span><span>,</span> <span>i64</span> <span>400</span><span>,</span> <span>i1</span> <span>false</span><span>)</span>
</span></span><span><span>  %_37 <span>=</span> <span>getelementptr</span> <span>inbounds</span> <span>nuw</span> <span>i8</span><span>,</span> <span>ptr</span> %tmp_buf<span>,</span> <span>i64</span> <span>80</span>
</span></span><span><span>  <span>call</span> <span>void</span> @dav1d_cdef_padding8_16bpc_neon<span>(</span><span>ptr</span> <span>no</span><span>undef</span> <span>nonnull</span> %_37<span>,</span> <span>ptr</span> <span>no</span><span>undef</span> %dst<span>,</span> <span>i64</span> <span>no</span><span>undef</span> %stride<span>,</span> <span>ptr</span> <span>no</span><span>undef</span> %left<span>,</span> <span>ptr</span> <span>no</span><span>undef</span> %top<span>,</span> <span>ptr</span> <span>no</span><span>undef</span> %bottom<span>,</span> <span>i32</span> <span>no</span><span>undef</span> <span>8</span><span>,</span> <span>i32</span> <span>no</span><span>undef</span> %edges<span>)</span> #121
</span></span><span><span>  %edges2.i <span>=</span> <span>zext</span> <span>i32</span> %edges <span>to</span> <span>i64</span>
</span></span><span><span>  %_0.i.i.i.i <span>=</span> <span>and</span> <span>i32</span> %bitdepth_max<span>,</span> <span>65535</span>
</span></span><span><span>  <span>call</span> <span>void</span> @dav1d_cdef_filter8_16bpc_neon<span>(</span><span>ptr</span> <span>no</span><span>undef</span> %dst<span>,</span> <span>i64</span> <span>no</span><span>undef</span> %stride<span>,</span> <span>ptr</span> <span>no</span><span>undef</span> <span>nonnull</span> <span>readonly</span> <span>align</span> <span>2</span> %_37<span>,</span> <span>i32</span> <span>no</span><span>undef</span> %pri_strength<span>,</span> <span>i32</span> <span>no</span><span>undef</span> %sec_strength<span>,</span> <span>i32</span> <span>no</span><span>undef</span> %dir<span>,</span> <span>i32</span> <span>no</span><span>undef</span> %damping<span>,</span> <span>i32</span> <span>no</span><span>undef</span> <span>8</span><span>,</span> <span>i64</span> <span>no</span><span>undef</span> %edges2.i<span>,</span> <span>i32</span> <span>no</span><span>undef</span> %_0.i.i.i.i<span>)</span> #121
</span></span><span><span>  <span>call</span> <span>void</span> @llvm.lifetime.end.p0<span>(</span><span>i64</span> <span>400</span><span>,</span> <span>ptr</span> <span>nonnull</span> %tmp_buf<span>)</span>
</span></span><span><span>  <span>ret</span> <span>void</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><h3 id="avoid-needlessly-zeroing-buffers-with-maybeuninit">Avoid Needlessly Zeroing Buffers with <code>MaybeUninit</code></h3><p>This should be pretty easy actually! Rust has <a href="https://doc.rust-lang.org/std/mem/union.MaybeUninit.html"><code>std::mem::MaybeUninit</code></a> for just such an occasion:</p><div><pre tabindex="0"><code data-lang="diff"><span><span><span>-let mut tmp_buf = Align16([0u16; TMP_LEN])
</span></span></span><span><span><span></span><span>+let mut tmp_buf = Align16([MaybeUninit::&lt;u16&gt;::uninit(); TMP_LEN]);
</span></span></span></code></pre></div><p>We can still take a sub-slice safely (<code>&amp;mut tmp_buf.0[2 * TMP_STRIDE + 8..]</code>), but we will need to update the signatures of the inner functions to use the new type (<code>tmp: *mut MaybeUninit&lt;u16&gt;</code>, <code>tmp: &amp;[MaybeUninit&lt;u16&gt;]</code>).</p><p>Since the code that used these was unsafe anyway, we don’t need to add any new unsafe blocks - only to verify that the existing code hasn’t changed (w.r.t <code>dav1d</code>) to rely on this buffer being zeroed.</p><p>Before, <code>cdef_filter_neon_erased</code> had 670 <em>Self</em> samples. Re-running the profiler, we get <a href="https://profiler.firefox.com/from-url/https%3A%2F%2Fohadravid.github.io%2F2025-05-rav1d-faster%2Frav1d_profile_after.json.gz/calltree/?globalTrackOrder=0&amp;search=rav1d_cdef_brow&amp;thread=0&amp;v=10">a new snapshot</a>:</p><p>Just 274 samples! Slightly less than <code>dav1d</code>’s <code>cdef_filter_{8x8,4x4}_neon</code> <em>Self</em> sample count.</p><p>Maybe this isn’t the only place where time is wasted zeroing buffers? A quick search for other big <code>Align16</code> buffers resulted in this lucky find:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span>(</span><span>crate</span><span>)</span> <span>fn</span> <span>rav1d_cdef_brow</span><span>&lt;</span><span>BD</span>: <span>BitDepth</span><span>&gt;</span><span>(</span><span>/* .. snip ..*/</span><span>)</span>
</span></span><span><span><span>{</span>
</span></span><span><span>    <span>// .. snip ..
</span></span></span><span><span><span></span>
</span></span><span><span>    <span>for</span> by <span>in</span> <span>(</span>by_start<span>..</span>by_end<span>).</span>step_by<span>(</span><span>2</span><span>)</span> <span>{</span>
</span></span><span><span>        <span>// .. snip ..
</span></span></span><span><span><span></span>        <span>let</span> <span>mut</span> lr_bak <span>=</span>
</span></span><span><span>            Align16<span>([[[[</span><span>0.</span>into<span>();</span> <span>2</span> <span>/* x */</span><span>];</span> <span>8</span> <span>/* y */</span><span>];</span> <span>3</span> <span>/* plane */</span> <span>];</span> <span>2</span> <span>/* idx */</span><span>]);</span>
</span></span><span><span>        
</span></span><span><span>        <span>// .. snip ..
</span></span></span><span><span><span></span>    <span>}</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>Again, the matching code from <code>dav1d</code> doesn’t initialize this buffer.
Here, switching to <code>MaybeUninit</code> is more difficult, but we can still offer a modest improvement: we’ll only need to do the initialization <strong>once</strong> if we hoist <code>lr_bak</code> to the top level!</p><div><pre tabindex="0"><code data-lang="diff"><span><span>pub(crate) fn rav1d_cdef_brow&lt;BD: BitDepth&gt;(/* .. snip ..*/)
</span></span><span><span>{
</span></span><span><span>    // .. snip ..
</span></span><span><span><span>+   let mut lr_bak =
</span></span></span><span><span><span>+       Align16([[[[0.into(); 2 /* x */]; 8 /* y */]; 3 /* plane */ ]; 2 /* idx */]);
</span></span></span><span><span><span></span>        
</span></span><span><span>    for by in (by_start..by_end).step_by(2) {
</span></span><span><span>        // .. snip ..
</span></span><span><span><span>-       let mut lr_bak =
</span></span></span><span><span><span>-           Align16([[[[0.into(); 2 /* x */]; 8 /* y */]; 3 /* plane */ ]; 2 /* idx */]);
</span></span></span><span><span><span></span>        
</span></span><span><span>        // .. snip ..
</span></span><span><span>    }
</span></span><span><span>}
</span></span></code></pre></div><p>Since <code>dav1d</code> never initialized it anyway, we know that logically any data read from this buffer was written beforehand with a valid value
(which really helps to drive home the idea that <a href="https://www.ralfj.de/blog/2021/11/18/ub-good-idea.html">Undefined Behavior deserves a better reputation</a>). The savings are very small here, but every penny counts!</p><p>Running the full benchmark, we get a nice speed boost from the original <code>73.914 s ± 0.151 s</code>:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ hyperfine --warmup <span>2</span> <span>"target/release/dav1d -q -i Chimera-AV1-8bit-1920x1080-6736kbps.ivf -o /dev/null --threads 1"</span>
</span></span><span><span>Benchmark 1: target/release/dav1d -q -i Chimera-AV1-8bit-1920x1080-6736kbps.ivf -o /dev/null --threads <span>1</span>
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:     72.644 s ±  0.250 s    <span>[</span>User: 72.023 s, System: 0.239 s<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:   72.281 s … 73.098 s    <span>10</span> runs
</span></span></code></pre></div><p>There’s still a way to go to <code>dav1d</code>’s <code>67.912 s ± 0.541 s</code>, but 1.2 seconds (1.5%) improvement in total runtime is a great start, and covers about 20% of the performance diff between the two.</p><h2 id="profiling-again-but-inverted">Profiling Again, But Inverted</h2><p>Let’s reload the profiler outputs from the start, but use the “inverted stack” view.<br><code>dav1d</code> (C) (<a href="https://profiler.firefox.com/from-url/https%3A%2F%2Fohadravid.github.io%2F2025-05-rav1d-faster%2Fdav1d_profile.json.gz/calltree/?globalTrackOrder=0&amp;invertCallstack&amp;thread=0&amp;v=10">Link</a>): 
<code>rav1d</code> (Rust) (<a href="https://profiler.firefox.com/from-url/https%3A%2F%2Fohadravid.github.io%2F2025-05-rav1d-faster%2Frav1d_profile_baseline.json.gz/calltree/?globalTrackOrder=0&amp;invertCallstack&amp;thread=0&amp;v=10">Link</a>): </p><p>There are a few options we can explore for optimization, but the function that got my attention was <code>add_temporal_candidate</code>: the difference between the Rust and the C version is significant enough (~400 samples, about 0.5 seconds),
and the function itself seems innocuous: it’s about 50 lines of <code>if</code>s and <code>for</code>s, with a few calls to short utility functions.</p><p>To help us find out where we are bleeding out the missing performance, we can try to recompile <code>rav1d</code> with debug symbols.
The <code>rav1d</code> project helpfully defines a <code>[profile.release-with-debug]</code> in its <code>Cargo.toml</code>, allowing us to run:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ cargo build --profile<span>=</span>release-with-debug
</span></span><span><span>$ sudo samply record target/release-with-debug/dav1d ...
</span></span></code></pre></div><p>What we get back is slightly different than before (<a href="https://profiler.firefox.com/from-url/https%3A%2F%2Fohadravid.github.io%2F2025-05-rav1d-faster%2Frav1d_profile_with_debug.json.gz/calltree/?globalTrackOrder=0&amp;invertCallstack&amp;thread=0&amp;v=10">Link</a>): the <code>release-with-debug</code> profile will not be as-optimized,
and small functions calls appear bigger than they really are, but we get a <strong>line-by-line sample breakdown of the function</strong>, and it should steer us in the right direction.</p><p>If you scroll a little, one thing that will jump out to you will be that the <code>if cand.mv.mv[0] == mv {</code> and <code>if cand.mv == mvp {</code> lines seem to cover a combined 600 samples!</p><p>Let’s pull up <code>mv: Mv</code>’s definition:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>#[derive(Clone, Copy, PartialEq, Eq, Default, FromZeroes, FromBytes, AsBytes)]</span>
</span></span><span><span><span>#[repr(C)]</span>
</span></span><span><span><span>pub</span> <span>struct</span> <span>Mv</span> <span>{</span>
</span></span><span><span>    <span>pub</span> y: <span>i16</span><span>,</span>
</span></span><span><span>    <span>pub</span> x: <span>i16</span><span>,</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>Huh. How can this be slow? It’s just <code>#[derive(PartialEq)]</code>.</p><p><img src="https://ohadravid.github.io/2025-05-rav1d-faster/futurama_fry.jpg" alt="Futurama Fry Looking Suspicious" width="40%" height="414px"></p><p>And even more suspiciously, the <code>dav1d</code> version is slightly different, and uses <code>mvstack[n].mv.n == mvp.n</code> to do the same comparisons.
But what is <code>n</code>? Looking at <code>dav1d</code>’s definition of <code>mv</code>, we find:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>typedef</span> <span>union</span> mv <span>{</span>
</span></span><span><span>    <span>struct</span> <span>{</span>
</span></span><span><span>        <span>int16_t</span> y<span>,</span> x<span>;</span>
</span></span><span><span>    <span>};</span>
</span></span><span><span>    <span>uint32_t</span> n<span>;</span>
</span></span><span><span><span>}</span> mv<span>;</span>
</span></span></code></pre></div><p>It seems like the <code>dav1d</code> authors knew that comparing two <code>i16</code>s can be slow, so when they compare two <code>mv</code>s, they treat them as <code>u32</code>s.</p><h3 id="replace-field-wise-equality-with-byte-wise-equality-that-optimizes-better">Replace Field-wise Equality with Byte-wise Equality that Optimizes Better</h3><p>Can this be the problem?<br>Defining <code>Mv</code> as a <code>union</code> has a big downside in Rust: it makes it <code>unsafe</code> to access any field of the <code>union</code>,
which will “infect” every usage of <code>Mv</code>, which is the opposite of what we usually want to do in Rust (trying to encapsulate unsafety in a safe API).</p><p>Fortunately, we have a different option: We can use <code>transmute</code> to re-interpret <code>Mv</code> as a <code>u32</code>, and use that to implement <code>PartialEq</code>.</p><p>Firing up <a href="https://godbolt.org/z/r9MfTeY8b">Godbolt</a>, we can inspect the generated code for the two ways to do the comparison:</p><p>Clearly the <code>transmute</code> version is superior, but can we avoid the <code>unsafe</code> block?<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><p>It turns out that the <code>zerocopy</code> crate can statically verify the <a href="https://docs.rs/zerocopy/latest/zerocopy/trait.IntoBytes.html#safety">safety requirements</a> for a <code>struct</code> to be represented as <code>&amp;[u8]</code>, allowing us to write:</p><div><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span> zerocopy::<span>{</span>AsBytes<span>,</span> FromBytes<span>,</span> FromZeroes<span>};</span>
</span></span><span><span>
</span></span><span><span><span>#[derive(Clone, Copy, Eq, Default, FromZeroes, FromBytes, AsBytes)]</span>
</span></span><span><span><span>#[repr(C)]</span>
</span></span><span><span><span>pub</span> <span>struct</span> <span>Mv</span> <span>{</span>
</span></span><span><span>    <span>pub</span> y: <span>i16</span><span>,</span>
</span></span><span><span>    <span>pub</span> x: <span>i16</span><span>,</span>
</span></span><span><span><span>}</span>
</span></span><span><span>
</span></span><span><span><span>impl</span> <span>PartialEq</span> <span>for</span> Mv <span>{</span>
</span></span><span><span>    <span>#[inline(always)]</span>
</span></span><span><span>    <span>fn</span> <span>eq</span><span>(</span><span>&amp;</span>self<span>,</span> other: <span>&amp;</span><span>Self</span><span>)</span> -&gt; <span>bool</span> <span>{</span>
</span></span><span><span>        self<span>.</span>as_bytes<span>()</span> <span>==</span> other<span>.</span>as_bytes<span>()</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>Which produces the same (optimized) assembly we saw when we used <code>transmute</code>.</p><p>After implementing similar optimizations for <code>RefMvs{Mv,Ref}Pair</code>, we can re-run the benchmark:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ hyperfine --warmup <span>2</span> <span>"target/release/dav1d -q -i Chimera-AV1-8bit-1920x1080-6736kbps.ivf -o /dev/null --threads 1"</span>
</span></span><span><span>Benchmark 1: target/release/dav1d -q -i Chimera-AV1-8bit-1920x1080-6736kbps.ivf -o /dev/null --threads <span>1</span>
</span></span><span><span>  Time <span>(</span>mean ± σ<span>)</span>:     72.182 s ±  0.289 s    <span>[</span>User: 71.501 s, System: 0.242 s<span>]</span>
</span></span><span><span>  Range <span>(</span>min … max<span>)</span>:   71.850 s … 72.722 s    <span>10</span> runs
</span></span></code></pre></div><p>This is <em>another</em> 0.5 second improvement over our previous result (<code>72.644 s ± 0.250 s</code>), or a 2.3% improvement over the baseline (<code>73.914 s ± 0.151 s</code>).</p><p>We are now only 4.2 seconds from <code>dav1d</code>’s <code>67.912 s ± 0.541 s</code>, so we covered about 30% of the performance diff we saw at the start of this article.</p><p>You might be wondering why the default implementation of <code>PartialEq</code> results in bad code generation,
and <a href="https://github.com/memorysafety/rav1d/pull/1400#issuecomment-2891734817">a comment</a> on the PR adding these impls pointed to <a href="https://github.com/rust-lang/rust/issues/140167">Rust issue #140167</a>,
which tracks exactly this type of problem.</p><p>If you consider the C case, when using a <code>struct { int16_t y, x; }</code> it’s possible to initialize only <code>y</code> while leaving <code>x</code> uninitialized.
As long as equality is checked with <code>this.y == other.y &amp;&amp; this.x == other.x</code> and all <code>y</code>s are different, you don’t get any UB.</p><p>Therefore, it’s invalid to optimize this to a single memory load and compare <strong>unless the code can guarantee that all fields are always initialized</strong>.
However, quoting this <a href="https://github.com/rust-lang/rust/issues/140167#issuecomment-2895174679">comment</a> by @hanna-kruppe on the issue:</p><blockquote><p>That’s not simply a missed optimization opportunity. While the load of the second field can’t load poison/undef, that property is control-dependent. ..<br>Solving this seems hard: I don’t think LLVM has a way to express “loading through this pointer always reads initialized bytes”.</p></blockquote><h2 id="summary">Summary</h2><p>Using a few profiler snapshots from the <code>samply</code> profiler, we compared running <code>rav1d</code> and <code>dav1d</code> on the same input file, saw a 6-second (9%) runtime difference, and found two relatively low hanging fruits we could optimize:</p><ol><li>Avoiding an expensive zero-initialization in a hot, Arm-specific code path (<a href="https://github.com/memorysafety/rav1d/pull/1397">PR</a>), improving runtime by 1.2 seconds (-1.6%).</li><li>Switching the default <code>PartialEq</code> impls of small numeric <code>struct</code>s with an optimized version that re-interpret them as bytes (<a href="https://github.com/memorysafety/rav1d/pull/1400">PR</a>), improving runtime by 0.5 seconds (-0.7%).</li></ol><p>Each of these provide a nice speedup despite being only a few dozen lines in total, and without introducing new unsafety into the codebase.</p><p>The <code>rav1d</code> project maintainers were nice and responsive, and helped make these PRs more correct and better overall (big shout out to @kkysen 🚀).</p><p>There is still a gap of about 6% between the two implementations so there are still many more optimizations to discover,
and I suspect this approach of comparing between profiler snapshots of <a href="https://profiler.firefox.com/from-url/https%3A%2F%2Fohadravid.github.io%2F2025-05-rav1d-faster%2Fdav1d_profile.json.gz/calltree/?assemblyView=2~11c50~174~dav1d_filter_sbrow_cdef_8bpc&amp;globalTrackOrder=0&amp;search=dav1d_cdef_brow_8bpc&amp;thread=0&amp;v=10"><code>dav1d</code></a> and <a href="https://profiler.firefox.com/from-url/https%3A%2F%2Fohadravid.github.io%2F2025-05-rav1d-faster%2Frav1d_profile_after.json.gz/calltree/?globalTrackOrder=0&amp;search=rav1d_cdef_brow&amp;thread=0&amp;v=10"><code>rav1d</code></a> will yield at least some of them.</p><p>Go ahead and give this a try! Maybe <code>rav1d</code> can eventually become faster than <code>dav1d</code> 👀🦀.</p><p>Discuss on <a href="https://www.reddit.com/r/rust/comments/1ksnljw/making_the_rav1d_video_decoder_1_faster/">r/rust</a>, <a href="https://lobste.rs/s/j3mzif/making_rav1d_video_decoder_1_faster">lobsters</a>, <a href="https://news.ycombinator.com/item?id=44061160">HN</a>! 👋</p><p><em>If you liked this, you might also like <a href="https://ohadravid.github.io/posts/2025-01-debugging-vit-and-tensorrt/">Debugging a Vision Transformer Compilation Issue</a> and <a href="https://ohadravid.github.io/posts/2023-03-rusty-python/">Making Python 100x faster with less than 100 lines of Rust</a></em>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Planetfall (322 pts)]]></title>
            <link>https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/</link>
            <guid>44060305</guid>
            <pubDate>Thu, 22 May 2025 09:17:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/">https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/</a>, See on <a href="https://news.ycombinator.com/item?id=44060305">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>Gentle readers, I have just wrapped up a fun side project that will be of great interest to a very small number of you. The result of one of the most technically demanding efforts of my career, I am very pleased to share it with you.</p>



<figure><a href="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/complete-layout-small-2025-05-20.jpg"><img data-attachment-id="8541" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/poster-with-rasters-2/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/complete-layout-small-2025-05-20.jpg" data-orig-size="4800,3600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Poster With Rasters&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Poster With Rasters" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/complete-layout-small-2025-05-20.jpg?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/complete-layout-small-2025-05-20.jpg?w=1024" width="4800" height="3600" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/complete-layout-small-2025-05-20.jpg" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/complete-layout-small-2025-05-20.jpg 4800w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/complete-layout-small-2025-05-20.jpg?w=150&amp;h=113 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/complete-layout-small-2025-05-20.jpg?w=300&amp;h=225 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/complete-layout-small-2025-05-20.jpg?w=768&amp;h=576 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/complete-layout-small-2025-05-20.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 4800px) 100vw, 4800px"></a><figcaption>Click to have a look at a detailed version. Contact me if you’re interested in a physical copy.</figcaption></figure>







<p>Most of you will wonder what this place is, but I hope that, for a few of you, the names clicked into place in your memory. This is the planet Chiron, the setting (and one of the main characters) of <em>Sid Meier’s Alpha Centauri</em>—a <a href="https://en.wikipedia.org/wiki/Sid_Meier%27s_Alpha_Centauri" target="_blank" rel="noreferrer noopener">computer game</a> from 1999 that has a cult following; I count myself among the cult.</p>



<p>I could go on about the game—which is deep and thought-provoking and has a remarkably beautiful and carefully considered visual language—but I’m here to talk about the map. This project pushed my skills into some new places, so even if you don’t care about the game, I think it’s worth talking about the technical details behind it.</p>



<p>But first, before we get in to those details, I want to mention something that this project helped teach me about the difference between real and fictional maps. Recently, after I’d told someone I was a cartographer, they asked if I mapped real or fictional places. To an outsider, it’s reasonable to put those two things on equal footing. But, to me, they felt like entirely different things. Other than the map above, I stick almost exclusively to the real world, and I observe this to be true for the majority of my colleagues. As I was grappling with this person’s question, I realized that this split might be because fantasy maps require a different (but overlapping) skill set than real maps. If a fantasy or sci-fi author asked me to construct a map for them, I would need to sit down and draw something new from scratch. I’m not trained to work that way. All of my experience centers on manipulating and styling geographic data, not on <em>creating</em> that geographic data.</p>



<p>Some mappers can, and do, handle both fictional and real places, but a lot of us, myself included, are primarily skilled in <a href="https://somethingaboutmaps.wordpress.com/2020/02/05/maps-in-the-kitchen/">cooking with ingredients</a> someone hands us, rather than growing the ingredients ourselves. Thus, the only reason I was able to make a fictional map was because there were actual pre-existing datasets I could use to build it.</p>



<hr>



<p>Before we jump in, I’ll mention that while this map is free to download, it was <em>quite</em> laborious. Your support helps me continue doing things like this, so consider clicking the buttons below, and/or sharing my work with others if you enjoyed it—it’s a big help!</p>







<h2>Getting the Data</h2>



<p>The game of <em>Alpha Centauri</em> is played on a map. The program can make up a new, random map for you, but there’s also an official, built-in map of the planet, <a href="https://archive.org/details/Sid_Meiers_Alpha_Centauri_Prima_Official_eGuide/page/n70/mode/1up?view=theater" target="_blank" rel="noreferrer noopener">carefully crafted</a> by one of the game designers, Chris Pine.</p>



<figure><a href="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image.png"><img data-attachment-id="8350" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-109/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image.png" data-orig-size="2500,1261" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image.png?w=1024" loading="lazy" width="2500" height="1261" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image.png 2500w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image.png?w=150&amp;h=76 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image.png?w=300&amp;h=151 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image.png?w=768&amp;h=387 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image.png?w=1024&amp;h=517 1024w" sizes="(max-width: 2500px) 100vw, 2500px"></a></figure>



<p>The official map is 128 × 64 diamond-shaped pixels. Importantly, each pixel has several attributes: elevation, rainfall level, rockiness, and more. These attributes were the basis for my mapping. I sampled various datasets from the in-game map, and then used them to construct my poster. Though, that was often easier said than done.</p>



<figure><img data-attachment-id="8352" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-110/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-1.png" data-orig-size="2150,1292" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-1.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-1.png?w=1024" loading="lazy" width="2150" height="1292" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-1.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-1.png 2150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-1.png?w=150&amp;h=90 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-1.png?w=300&amp;h=180 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-1.png?w=768&amp;h=462 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-1.png?w=1024&amp;h=615 1024w" sizes="(max-width: 2150px) 100vw, 2150px"><figcaption>Part of the game map. Note the pixel highlighted in the center of the map. In the lower left, we can see data about the highlighted pixel: its elevation, the fact that it is arid and rocky, the presence of native lifeforms (xenofungus), and that it is at coordinates (16, 50).</figcaption></figure>



<p>I began by tackling the elevation data. While it isn’t uncommon for games (then or now) to have 3D terrain, <em>Alpha Centauri</em> is somewhat unusual in my experience, in that it actually tells you the exact elevation value for each map tile. You can see that in the lower left of the above image. So, I went over the map and wrote down the elevation value of every tile. All 8,192 of them. And then I double-checked them to make sure I had transcribed them correctly. As you can imagine, this took a very long time—many hours. I began this process sometime in 2022 and poked at it occasionally until wrapping up in 2025.</p>



<p>If you look back to the snippet of the in-game map above, you’ll notice that some tiles have what appears to be vegetation on them. This is the game’s way of visually symbolizing a tile’s average rainfall. There are only three levels: rainy, moist, and arid. Fortunately, I did <em>not</em> have to manually sample every pixel to get this information. My version of <em>Alpha Centauri</em> has a mod, not found in the original game, which shows you a thematic map of rainfall level.</p>



<figure><img data-attachment-id="8363" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-113/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-4.png" data-orig-size="2494,1114" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-4.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-4.png?w=1024" loading="lazy" width="2494" height="1114" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-4.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-4.png 2494w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-4.png?w=150&amp;h=67 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-4.png?w=300&amp;h=134 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-4.png?w=768&amp;h=343 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-4.png?w=1024&amp;h=457 1024w" sizes="(max-width: 2494px) 100vw, 2494px"></figure>



<p>I took screenshots of the whole map, and did a little Photoshop work to separate the different colors into three maps, one per raininess level.</p>



<figure><img data-attachment-id="8367" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-115/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-6.png" data-orig-size="2628,1036" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-6.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-6.png?w=1024" loading="lazy" width="2628" height="1036" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-6.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-6.png 2628w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-6.png?w=150&amp;h=59 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-6.png?w=300&amp;h=118 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-6.png?w=768&amp;h=303 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-6.png?w=1024&amp;h=404 1024w" sizes="(max-width: 2628px) 100vw, 2628px"></figure>



<p>Then I brought each into QGIS, and dropped a grid of vector points on top, one per grid square. Each point sampled the underlying raster and absorbed its raininess level. The dataset still needed some double-checking and correcting, since there are other map items in the way that obscured the raininess data. But, I was able to get it done without too much hassle.</p>



<figure><img data-attachment-id="8365" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-114/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-5.png" data-orig-size="2298,908" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-5.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-5.png?w=1024" loading="lazy" width="2298" height="908" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-5.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-5.png 2298w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-5.png?w=150&amp;h=59 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-5.png?w=300&amp;h=119 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-5.png?w=768&amp;h=303 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-5.png?w=1024&amp;h=405 1024w" sizes="(max-width: 2298px) 100vw, 2298px"></figure>



<p>I did the same procedure with the rockiness, which likewise comes in three levels—though I ended up not using that dataset. </p>



<p>Finally, there’s the xenofungus, which is one of the native lifeforms on Chiron. That’s the pink ground cover on the map above (though according to a game manual, it’s “crimson”). This dataset is binary: xenofungus is there, or not. There wasn’t a thematic map available in-game for this, so I just brought in the normal game map and sampled it with my grid points and looked for pixels that matched the pink/red range of colors, then did some corrections.</p>



<p>With that, I had all the ingredients I would need to make my map. While the elevation data took me years to finish sampling, the rest was done in a matter of hours.</p>



<h2>Projection</h2>



<p>Like a lot of game maps, <em>Alpha Centauri</em> effectively takes place on a cylinder. You can travel infinitely toward the left or the right, but once you reach the top or the bottom, you stop; the map/world ends.</p>



<figure><img data-attachment-id="8355" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/untitledx2/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/untitledx2.png" data-orig-size="2400,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="untitledx2" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/untitledx2.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/untitledx2.png?w=1024" loading="lazy" width="2400" height="1500" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/untitledx2.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/untitledx2.png 2400w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/untitledx2.png?w=150&amp;h=94 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/untitledx2.png?w=300&amp;h=188 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/untitledx2.png?w=768&amp;h=480 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/untitledx2.png?w=1024&amp;h=640 1024w" sizes="(max-width: 2400px) 100vw, 2400px"></figure>



<p>Though our map is cylindrical, the planet was certainly meant by the designers to be understood as spherical. Various in-game media, including the game’s title screen, show that Chiron is round. So I assumed that the in-game map was, like most maps, a 2D representation of a globe. But what was its projection?</p>



<p>Every time you build a base in the game, that base offers you control of a certain region, and the size of that region is always the same number of pixels, no matter where it is built. So, it seems reasonable to assume that each pixel represents the same amount of space on the planet—thus, the game map is on an equal-area projection. And given the rectilinear shape of the map (and the diagram above), we can reasonably assume a cylindrical projection. Thus, I assigned the game map a<a href="https://en.wikipedia.org/wiki/Cylindrical_equal-area_projection"> <em>cylindrical equal area projection</em></a>.</p>



<p>The aspect ratio of the cylindrical equal-area projection varies based on where you set the standard parallel. Here, on this excerpt from my <a href="https://somethingaboutmaps.wordpress.com/2022/12/19/projection-connections-a-very-nerdy-poster/">Projection Connections</a> poster, you can see a few named variations on this projection. Each just varies in where you set the standard parallel.</p>



<figure><img data-attachment-id="8358" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-111/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-2.png" data-orig-size="2508,1276" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-2.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-2.png?w=1024" loading="lazy" width="2508" height="1276" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-2.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-2.png 2508w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-2.png?w=150&amp;h=76 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-2.png?w=300&amp;h=153 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-2.png?w=768&amp;h=391 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-2.png?w=1024&amp;h=521 1024w" sizes="(max-width: 2508px) 100vw, 2508px"></figure>



<p>Setting it to 37.4° got me an aspect ratio that matched the in-game map, and that setting also means that we’re using the <a href="https://map-projections.net/single-view/trystan-edwards-snyder">Trystan Edwards projection</a>. To give you a better sense of all this, here’s how the game map and an earth map compare, under the same projection.</p>



<figure><img data-attachment-id="8360" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-112/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-3.png" data-orig-size="3000,831" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-3.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-3.png?w=1024" loading="lazy" width="3000" height="831" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-3.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-3.png 3000w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-3.png?w=150&amp;h=42 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-3.png?w=300&amp;h=83 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-3.png?w=768&amp;h=213 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-3.png?w=1024&amp;h=284 1024w" sizes="(max-width: 3000px) 100vw, 3000px"><figcaption>The map on the right is by daan Strebe, via Wikipedia.</figcaption></figure>



<p>All this projection work actually took place <em>before</em> the data sampling. So, when I say that I brought game maps into QGIS and dropped vector points on them, I already had a projection set up to handle the new datasets I was generating.</p>



<h2>Preparing the DEM</h2>



<p>At this point I had a projection, and I had a bunch of data in a very low-resolution (128 × 64) grid. Part of my interest in tackling this project was in figuring out how to make a map that was more detailed than the original game map, while still conforming to the known, in-game facts about Chiron. So, I wanted to explore how to turn my 8,192 elevation values into a much more detailed grid.</p>



<p>I tried many, many things. I spent enough hours at it that, in truth, I don’t remember a lot of the details of my attempts. But, after many dead ends, here’s the technique that I finally landed on. I started with the elevation grid—one elevation value per tile, just like we have in the game.</p>



<figure><img data-attachment-id="8384" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-124/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-15.png" data-orig-size="2255,880" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-15.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-15.png?w=1024" loading="lazy" width="2255" height="880" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-15.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-15.png 2255w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-15.png?w=150&amp;h=59 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-15.png?w=300&amp;h=117 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-15.png?w=768&amp;h=300 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-15.png?w=1024&amp;h=400 1024w" sizes="(max-width: 2255px) 100vw, 2255px"><figcaption>A snippet of the original game elevations, near Planetneck.</figcaption></figure>



<p>Then I scattered a bunch of random points on it, while enforcing a minimum distance between them, so that they weren’t too bunched up. I ended up with about 1–3 points on each grid tile.</p>



<figure><img data-attachment-id="8385" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-125/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-16.png" data-orig-size="2255,880" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-16.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-16.png?w=1024" loading="lazy" width="2255" height="880" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-16.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-16.png 2255w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-16.png?w=150&amp;h=59 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-16.png?w=300&amp;h=117 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-16.png?w=768&amp;h=300 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-16.png?w=1024&amp;h=400 1024w" sizes="(max-width: 2255px) 100vw, 2255px"></figure>



<p>A small number of grid tiles ended up without a point. I added extra points to cover those (I just found the centroids of each of those tiles). I then gave each point the value of the elevation of the grid tile it sat on top. So, I effectively turned my original elevation grid tiles into a scattered bunch of dots, with some elevation values repeated multiple times.</p>



<figure><img data-attachment-id="8386" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-126/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-17.png" data-orig-size="2255,880" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-17.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-17.png?w=1024" loading="lazy" width="2255" height="880" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-17.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-17.png 2255w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-17.png?w=150&amp;h=59 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-17.png?w=300&amp;h=117 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-17.png?w=768&amp;h=300 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-17.png?w=1024&amp;h=400 1024w" sizes="(max-width: 2255px) 100vw, 2255px"></figure>



<p>And then I ran a TIN (triangulated irregular network) interpolation to generate an initial elevation model:</p>



<figure><img data-attachment-id="8387" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-127/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-18.png" data-orig-size="2255,880" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-18.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-18.png?w=1024" loading="lazy" width="2255" height="880" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-18.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-18.png 2255w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-18.png?w=150&amp;h=59 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-18.png?w=300&amp;h=117 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-18.png?w=768&amp;h=300 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-18.png?w=1024&amp;h=400 1024w" sizes="(max-width: 2255px) 100vw, 2255px"></figure>



<p>Now, if I hadn’t done any of the point scattering, and had simply used my original elevation grid, here’s what it would have looked like:</p>



<figure><img data-attachment-id="8388" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-128/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-19.png" data-orig-size="2255,880" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-19.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-19.png?w=1024" loading="lazy" width="2255" height="880" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-19.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-19.png 2255w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-19.png?w=150&amp;h=59 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-19.png?w=300&amp;h=117 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-19.png?w=768&amp;h=300 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-19.png?w=1024&amp;h=400 1024w" sizes="(max-width: 2255px) 100vw, 2255px"></figure>



<p>Notice how it’s much more grid-like and regular. By shifting all the points around, and sometimes duplicating them, I was able to break that grid up, and randomly give more weight to some areas vs. others. The first interpolation looks much more organic than the second, but it still uses the original elevation values.</p>



<p>That was only the first iteration of the process. I actually went back and refined it several times. While shifting all the elevation dots around, and duplicating them, was helpful, it wasn’t detailed enough. I wanted more elevation points, so I could have a finer scale of terrain. To do that, I first did a Delauney triangulation on my randomized points. This just draws triangles between all the points. Then I found the point at the center of each of those triangles.</p>



<p>And then I assigned an elevation value to each of those new points, simply by taking average of the three elevation values nearby. Finally, I added a bit of random noise: I nudged the elevation value of each point randomly up or down by a small amount, so that they would represent new bumps in the terrain, not a smooth continuation of the existing values. Here’s how that looks.</p>



<figure><img data-attachment-id="8390" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-129/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-20.png" data-orig-size="2255,880" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-20.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-20.png?w=1024" loading="lazy" width="2255" height="880" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-20.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-20.png 2255w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-20.png?w=150&amp;h=59 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-20.png?w=300&amp;h=117 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-20.png?w=768&amp;h=300 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-20.png?w=1024&amp;h=400 1024w" sizes="(max-width: 2255px) 100vw, 2255px"></figure>



<p>I repeated this process of triangulation and bumping a couple more times (reducing the amount of bumping each time), until I had a very large number of points.</p>



<figure><img data-attachment-id="8392" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-130/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-21.png" data-orig-size="2255,880" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-21.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-21.png?w=1024" loading="lazy" width="2255" height="880" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-21.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-21.png 2255w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-21.png?w=150&amp;h=59 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-21.png?w=300&amp;h=117 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-21.png?w=768&amp;h=300 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-21.png?w=1024&amp;h=400 1024w" sizes="(max-width: 2255px) 100vw, 2255px"></figure>



<p>And here’s what that looks like when interpolated into an elevation surface:</p>



<figure><img data-attachment-id="8394" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-131/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-22.png" data-orig-size="2255,880" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-22.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-22.png?w=1024" loading="lazy" width="2255" height="880" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-22.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-22.png 2255w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-22.png?w=150&amp;h=59 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-22.png?w=300&amp;h=117 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-22.png?w=768&amp;h=300 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-22.png?w=1024&amp;h=400 1024w" sizes="(max-width: 2255px) 100vw, 2255px"></figure>



<p>This is a big improvement over what we began with. It’s organic and detailed, and while it’s not perfect, it’s a large step in the right direction.</p>



<p>I made a few other adjustments to the field of elevation points before conducting the final interpolation. These were to help match my results with the canonical map of Chiron. Sometimes, due to the nature of the interpolation, or the random noise I introduced, things didn’t quite turn out as they should.</p>



<figure><img data-attachment-id="8396" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-132/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-23.png" data-orig-size="2114,1258" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-23.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-23.png?w=1024" loading="lazy" width="2114" height="1258" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-23.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-23.png 2114w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-23.png?w=150&amp;h=89 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-23.png?w=300&amp;h=179 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-23.png?w=768&amp;h=457 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-23.png?w=1024&amp;h=609 1024w" sizes="(max-width: 2114px) 100vw, 2114px"></figure>



<p>Above, you can see the canonical map, overlaid with a land/water mask from my interpolation. There’s an island in the top-center on the canonical map, but in my interpolated elevation model, it’s actually (barely) joined to the mainland. That occurs simply because I had some elevation points in the area that were above sea level, and some below, and the ones above sea level won out in the interpolation.</p>



<p>Here’s another situation requiring adjustment:</p>



<figure><img data-attachment-id="8399" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-133/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-24.png" data-orig-size="2360,1608" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-24.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-24.png?w=1024" loading="lazy" width="2360" height="1608" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-24.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-24.png 2360w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-24.png?w=150&amp;h=102 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-24.png?w=300&amp;h=204 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-24.png?w=768&amp;h=523 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-24.png?w=1024&amp;h=698 1024w" sizes="(max-width: 2360px) 100vw, 2360px"></figure>



<p>An island on the canonical map is only a couple of pixels wide in my interpolated elevation model. I would like it to be a bit bigger, so that it’s noticeable on the final map.</p>



<p>I manually reviewed the map to find places like these and added a few extra elevation data points, to correct things like closed straits, tiny islands, etc.</p>



<p>I also needed to manually adjust one major feature of the original map: Garland Crater. Here’s how it looks on the canonical map:</p>



<figure><img data-attachment-id="8405" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-137/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-28.png" data-orig-size="2473,1145" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-28.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-28.png?w=1024" loading="lazy" width="2473" height="1145" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-28.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-28.png 2473w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-28.png?w=150&amp;h=69 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-28.png?w=300&amp;h=139 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-28.png?w=768&amp;h=356 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-28.png?w=1024&amp;h=474 1024w" sizes="(max-width: 2473px) 100vw, 2473px"></figure>



<p>But remember, that map is based on an underlying diamond-shaped grid. When looking at the actual elevation values, the crater is much more of a square.</p>



<figure><img data-attachment-id="8406" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-138/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-29.png" data-orig-size="2473,1145" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-29.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-29.png?w=1024" loading="lazy" width="2473" height="1145" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-29.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-29.png 2473w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-29.png?w=150&amp;h=69 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-29.png?w=300&amp;h=139 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-29.png?w=768&amp;h=356 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-29.png?w=1024&amp;h=474 1024w" sizes="(max-width: 2473px) 100vw, 2473px"></figure>



<p>But, the crater is clearly meant to be a circle. The game designers even drew special map tiles to represent it as such. So, I un-squared this region of the map. I did a little rubbersheeting to shift my original elevation points around until I had something more circular.</p>



<figure><img data-attachment-id="8407" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-139/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-30.png" data-orig-size="2488,1328" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-30.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-30.png?w=1024" loading="lazy" width="2488" height="1328" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-30.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-30.png 2488w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-30.png?w=150&amp;h=80 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-30.png?w=300&amp;h=160 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-30.png?w=768&amp;h=410 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-30.png?w=1024&amp;h=547 1024w" sizes="(max-width: 2488px) 100vw, 2488px"><figcaption>It looks a bit vertically stretched here, but that’s just due to the projection.</figcaption></figure>



<p>With manual points added, and the crater circularized, I was ready to do the triangulation and interpolation steps once again. I’m explaining things a bit out of order here—there were many hours of trial and error and revision as part of this whole process. But this is effectively what I did.</p>



<p>Once I had the interpolation, I did a bit of smoothing on it. I do not remember the exact formula—it was a bit like mixing paints, in that I kept playing around until I got something that looked right. I did some focal statistics (mean and median), some line integral convolution via the <a href="https://plugins.qgis.org/plugins/karika/">Karika plugin</a>, and I also added just a bit of <a href="https://en.wikipedia.org/wiki/Perlin_noise">Perlin noise</a>. I mixed together smoothed layers with unsmoothed ones, and smoothed again. Again, a very seat-of-the-pants process.</p>



<p>In the end, here’s what I came up with:</p>



<figure><img data-attachment-id="8409" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-140/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-31.png" data-orig-size="3304,1701" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-31.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-31.png?w=1024" loading="lazy" width="3304" height="1701" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-31.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-31.png 3304w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-31.png?w=150&amp;h=77 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-31.png?w=300&amp;h=154 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-31.png?w=768&amp;h=395 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-31.png?w=1024&amp;h=527 1024w" sizes="(max-width: 3304px) 100vw, 3304px"></figure>



<p>Compare that to a simple TIN interpolation of just the original, unmodified elevation points (before any randomization, manual patches, triangulation, etc.):</p>



<figure><img data-attachment-id="8411" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-141/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-32.png" data-orig-size="3304,1701" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-32.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-32.png?w=1024" loading="lazy" width="3304" height="1701" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-32.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-32.png 3304w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-32.png?w=150&amp;h=77 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-32.png?w=300&amp;h=154 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-32.png?w=768&amp;h=395 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-32.png?w=1024&amp;h=527 1024w" sizes="(max-width: 3304px) 100vw, 3304px"><figcaption>Near the center of the image, and just a bit to the left, you can see the original square crater shape.</figcaption></figure>



<p>I think the process of all those adjustments yielded something much more organic-looking.</p>



<p>I wasn’t quite done yet with the elevation model, however. This interpolation was fine for most areas, but the poles needed attention. Given how stretched-out they are on the above map, I knew I would need to re-do the elevation interpolation for the north/south poles using projections that were less distorted in those areas. As an example, here’s the north pole DEM that I came up with, along with the original elevation point locations.</p>



<figure><img data-attachment-id="8413" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-142/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-33.png" data-orig-size="2188,1884" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-33.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-33.png?w=1024" loading="lazy" width="2188" height="1884" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-33.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-33.png 2188w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-33.png?w=150&amp;h=129 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-33.png?w=300&amp;h=258 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-33.png?w=768&amp;h=661 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-33.png?w=1024&amp;h=882 1024w" sizes="(max-width: 2188px) 100vw, 2188px"></figure>



<p>Since a large chunk of the pole had no game data, I sprinkled some mostly-random noise in the middle. And then I proceeded to randomize my point locations and add extra triangulated points, as I did with the main elevation model.</p>



<p>I made separate DEMs for the north and south poles, for use in any future cartography that might focus on those areas. And I also blended them back into the main DEM. With that, my elevation model was done!</p>



<p>Except it wasn’t. As I went through the rest of the mapmaking process, I kept finding small errors: missing lakes, tiny islands, etc. Much like the ones I showed above, except this time I didn’t catch them until I was done with the DEM. I patched those up as best I could, either through tiny changes to the elevation model, or, more often, by manually drawing lakes and islands later on in the cartographic process. Speaking of which, let’s actually start making a map with all these data…</p>



<h2>Fun with Projections</h2>



<p>For the main map in the layout, decided I wanted to show Chiron using an <a href="https://en.wikipedia.org/wiki/Armadillo_projection">orthoapsidal (Raisz Armadillo) projection</a>, which also happens to be one of my favorite projections.</p>



<figure><img data-attachment-id="8417" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-143/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-34.png" data-orig-size="2068,1184" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-34.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-34.png?w=1024" loading="lazy" width="2068" height="1184" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-34.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-34.png 2068w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-34.png?w=150&amp;h=86 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-34.png?w=300&amp;h=172 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-34.png?w=768&amp;h=440 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-34.png?w=1024&amp;h=586 1024w" sizes="(max-width: 2068px) 100vw, 2068px"><figcaption>Another daan Strebe map that I stole from Wikipedia.</figcaption></figure>



<p>I love that it explicitly reminds the reader that they’re dealing with a curved surface. Given that game players are accustomed to seeing only a flat representation, I thought was especially important to try and show something rounder to bring it to life. </p>



<p>I’d never gotten to make a map in this projection before. It’s not available in QGIS, so I had to create my own little projection script. Fortunately, Wikipedia had the formulae for the transformation. That info, plus a little Python knowledge (aided by ChatGPT, as I’m still not super-comfortable with PyQGIS yet) let me start using the orthoapsidal projection.</p>



<p>I ended up modifying the projection. To better fit Chiron’s landmasses, I adjusted the amount and the direction of the vertical tilt (the default is 20°, but I changed it to -10°). I also reduced the curvature on the sides. The downside of the orthoapsidal is that, by showing the curvature that gives such a nice sense of roundness, we lose some areas (Australia is cut off on the above map, as is Antarctica). But, with a clever bit of tweaking, I was able to reduce the curvature. I did this by first horizontally shrinking anything I was projecting:</p>



<figure><img data-attachment-id="8420" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-144/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-35.png" data-orig-size="3347,1701" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-35.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-35.png?w=1024" loading="lazy" width="3347" height="1701" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-35.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-35.png 3347w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-35.png?w=150&amp;h=76 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-35.png?w=300&amp;h=152 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-35.png?w=768&amp;h=390 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-35.png?w=1024&amp;h=520 1024w" sizes="(max-width: 3347px) 100vw, 3347px"></figure>



<p>Then, when it was projected, it took up less horizontal space on the torus, and thus did not extend nearly as far to the sides:</p>



<figure><img data-attachment-id="8422" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-145/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-36.png" data-orig-size="2806,1458" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-36.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-36.png?w=1024" loading="lazy" width="2806" height="1458" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-36.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-36.png 2806w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-36.png?w=150&amp;h=78 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-36.png?w=300&amp;h=156 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-36.png?w=768&amp;h=399 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-36.png?w=1024&amp;h=532 1024w" sizes="(max-width: 2806px) 100vw, 2806px"><figcaption>I’m using Earth landmasses here, so that you can get a sense of the projection using more familiar shapes.</figcaption></figure>



<p>Thus I avoided the severe perspective distortion that occurred on the left/right edges. Notice the right edge of the above image, how the landmasses start to really compress along the edge of the projection as it curves away from the viewer. But, the green version does not do this as badly. By shrinking the landmass, I kept more of it on the parts of the torus that most directly face the viewer. Another way to think about it: In effect, I sort of made the torus larger, in relation to the map.</p>



<p>When I was done with the projection, I stretched things out horizontally a bit to un-do the shrinking I’d done.</p>



<p>My script unfortunately only handled vectors, and I was too impatient to dig in and make the code work with rasters. So, for projecting something like the elevation model, I did a hacky GIS thing and just turned each pixel into a polygon, projected it, and then re-rasterized it. That was not ideal, and meant long processing times, but it worked fine.</p>



<p>At this point, we can probably start breaking down my map layer-by-layer, as I’ve often done in this blog.</p>



<h2>Finally, Actual Cartography</h2>



<p>So, let’s break down the main map, which was constructed mostly in Photoshop. First we start with the bathymetry.</p>



<figure><img data-attachment-id="8427" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-146/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-37.png" data-orig-size="2499,1316" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-37.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-37.png?w=1024" loading="lazy" width="2499" height="1316" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-37.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-37.png 2499w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-37.png?w=150&amp;h=79 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-37.png?w=300&amp;h=158 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-37.png?w=768&amp;h=404 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-37.png?w=1024&amp;h=539 1024w" sizes="(max-width: 2499px) 100vw, 2499px"></figure>



<p>This is a black and white raster showing the parts of my (reprojected) DEM that had an elevation below zero. To this, I applied a gradient map to recolor everything into shades of blue.</p>



<figure><img data-attachment-id="8430" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-148/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-39.png" data-orig-size="2351,1239" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-39.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-39.png?w=1024" loading="lazy" width="2351" height="1239" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-39.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-39.png 2351w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-39.png?w=150&amp;h=79 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-39.png?w=300&amp;h=158 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-39.png?w=768&amp;h=405 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-39.png?w=1024&amp;h=540 1024w" sizes="(max-width: 2351px) 100vw, 2351px"></figure>



<p>A gradient map in Photoshop takes each pixel in the underlying raster and recolors based on its greyscale value. So, it can (among other things) take a black-to-white raster and turn those pixels into a new color ramp.</p>



<p>Next up: the initial land. I took my reprojected elevation model, clipped off any underwater values, and fed it through <a href="https://eduard.earth/">Eduard</a>, a program which simulates Swiss-style hand-shaded relief.</p>



<figure><img data-attachment-id="8432" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-149/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-40.png" data-orig-size="2500,1316" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-40.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-40.png?w=1024" loading="lazy" width="2500" height="1316" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-40.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-40.png 2500w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-40.png?w=150&amp;h=79 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-40.png?w=300&amp;h=158 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-40.png?w=768&amp;h=404 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-40.png?w=1024&amp;h=539 1024w" sizes="(max-width: 2500px) 100vw, 2500px"></figure>



<p>I spent a while tweaking the settings to try and find a good balance. Remember, I made some of this information up, because I wanted a realistically detailed relief model. But, I also didn’t want to show <em>too</em> much of the noise I’d added. Once done, I added a bit of a coastal inner glow to help separate the land from the water.</p>



<figure><img data-attachment-id="8435" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-150/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-41.png" data-orig-size="2500,1316" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-41.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-41.png?w=1024" loading="lazy" width="2500" height="1316" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-41.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-41.png 2500w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-41.png?w=150&amp;h=79 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-41.png?w=300&amp;h=158 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-41.png?w=768&amp;h=404 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-41.png?w=1024&amp;h=539 1024w" sizes="(max-width: 2500px) 100vw, 2500px"></figure>



<p>It also had the advantage of hiding the relief near the coastline, so that any nearby mountains gradually fade out as we hit the coast. That gives us a tiny bit of coastal plain. There are almost no flat areas in my map—this is a consequence of the very bumpy elevation values that are in the game. Mountains appear and disappear suddenly, often right next to the coast. I wanted to make the coasts just a little less rugged.</p>



<p>Next up, I used a hue/saturation layer to colorize the relief:</p>



<figure><img data-attachment-id="8437" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-151/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-42.png" data-orig-size="2350,1238" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-42.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-42.png?w=1024" loading="lazy" width="2350" height="1238" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-42.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-42.png 2350w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-42.png?w=150&amp;h=79 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-42.png?w=300&amp;h=158 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-42.png?w=768&amp;h=405 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-42.png?w=1024&amp;h=539 1024w" sizes="(max-width: 2350px) 100vw, 2350px"></figure>



<p>I then sprinkled a little color noise onto it, to help it feel a bit more organic.</p>



<figure><img data-attachment-id="8439" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-152/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-43.png" data-orig-size="2478,1354" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-43.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-43.png?w=1024" loading="lazy" width="2478" height="1354" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-43.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-43.png 2478w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-43.png?w=150&amp;h=82 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-43.png?w=300&amp;h=164 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-43.png?w=768&amp;h=420 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-43.png?w=1024&amp;h=560 1024w" sizes="(max-width: 2478px) 100vw, 2478px"></figure>



<p>I did this just by having a couple of adjustment layers: another hue/saturation, and one brightness/contrast, and having these each masked by a channel that contained some small specks of noise:</p>



<figure><img data-attachment-id="8441" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-153/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-44.png" data-orig-size="2102,1050" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-44.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-44.png?w=1024" loading="lazy" width="2102" height="1050" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-44.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-44.png 2102w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-44.png?w=150&amp;h=75 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-44.png?w=300&amp;h=150 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-44.png?w=768&amp;h=384 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-44.png?w=1024&amp;h=512 1024w" sizes="(max-width: 2102px) 100vw, 2102px"></figure>



<p>Next up was the greenery. Just like the canonical map, I intended to use the rainfall intensity data to show vegetation. First off, I made a copy of the relief and tinted it green, including some noisy variations on those colors. </p>



<figure><img data-attachment-id="8445" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-156/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-47.png" data-orig-size="2386,914" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-47.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-47.png?w=1024" loading="lazy" width="2386" height="914" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-47.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-47.png 2386w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-47.png?w=150&amp;h=57 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-47.png?w=300&amp;h=115 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-47.png?w=768&amp;h=294 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-47.png?w=1024&amp;h=392 1024w" sizes="(max-width: 2386px) 100vw, 2386px"></figure>



<p>I did this in exactly the same way I did the earlier tan/brown relief: a hue/saturation layer to colorize it, plus a couple of adjustment layers to add some noisy speckles of lighter/darker areas.</p>



<p>Due to the darker green color, some of the relief was getting lost, so I also added a few more adjustments to emphasize it. These were just more adjustment layers that lightened/darkened the underlying image. </p>



<figure><img data-attachment-id="8447" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-157/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-48.png" data-orig-size="3710,1542" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-48.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-48.png?w=1024" loading="lazy" width="3710" height="1542" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-48.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-48.png 3710w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-48.png?w=150&amp;h=62 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-48.png?w=300&amp;h=125 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-48.png?w=768&amp;h=319 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-48.png?w=1024&amp;h=426 1024w" sizes="(max-width: 3710px) 100vw, 3710px"></figure>



<p>I used the shadows/highlights of the relief in the mask for these adjustment layers, so that they only lightened/darkened the right areas. Here’s a look inside one mask:</p>



<figure><img data-attachment-id="8449" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-158/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-49.png" data-orig-size="3340,1150" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-49.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-49.png?w=1024" loading="lazy" width="3340" height="1150" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-49.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-49.png 3340w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-49.png?w=150&amp;h=52 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-49.png?w=300&amp;h=103 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-49.png?w=768&amp;h=264 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-49.png?w=1024&amp;h=353 1024w" sizes="(max-width: 3340px) 100vw, 3340px"></figure>



<p>Now I blend the green vegetation version of the relief with the original brown relief.</p>



<figure><img data-attachment-id="8450" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-159/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-50.png" data-orig-size="2500,1316" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-50.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-50.png?w=1024" loading="lazy" width="2500" height="1316" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-50.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-50.png 2500w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-50.png?w=150&amp;h=79 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-50.png?w=300&amp;h=158 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-50.png?w=768&amp;h=404 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-50.png?w=1024&amp;h=539 1024w" sizes="(max-width: 2500px) 100vw, 2500px"></figure>



<p>Some areas are still brown (those marked “arid” on the game map) and some are green (“rainy” or “moist” on the game map). But, how did I do this blending? Here’s a look at the mask that controls the opacity of the greenery layer:</p>



<figure><img data-attachment-id="8453" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-160/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-51.png" data-orig-size="2500,1316" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-51.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-51.png?w=1024" loading="lazy" width="2500" height="1316" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-51.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-51.png 2500w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-51.png?w=150&amp;h=79 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-51.png?w=300&amp;h=158 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-51.png?w=768&amp;h=404 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-51.png?w=1024&amp;h=539 1024w" sizes="(max-width: 2500px) 100vw, 2500px"></figure>



<p>On a macro scale, it comes from those rainfall data I gathered a long while back. Remember, each grid tile in the game has one of 3 raininess levels, and I had a point representation of that dataset. I conducted a thin plate spline interpolation on the points (<em>after</em> reprojecting).</p>



<figure><img data-attachment-id="8455" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-161/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-52.png" data-orig-size="2564,1442" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-52.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-52.png?w=1024" loading="lazy" width="2564" height="1442" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-52.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-52.png 2564w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-52.png?w=150&amp;h=84 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-52.png?w=300&amp;h=169 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-52.png?w=768&amp;h=432 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-52.png?w=1024&amp;h=576 1024w" sizes="(max-width: 2564px) 100vw, 2564px"></figure>



<p>That was the basis of my Photoshop mask. But, I also made it somewhat noisy, which you can see if you zoom into the Photoshop version:</p>



<figure><img data-attachment-id="8459" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-163/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-54.png" data-orig-size="3338,1354" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-54.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-54.png?w=1024" loading="lazy" width="3338" height="1354" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-54.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-54.png 3338w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-54.png?w=150&amp;h=61 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-54.png?w=300&amp;h=122 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-54.png?w=768&amp;h=312 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-54.png?w=1024&amp;h=415 1024w" sizes="(max-width: 3338px) 100vw, 3338px"></figure>



<p>This was done using a stack of Photoshop filters. First, I make use of the <em>dissolve</em> blending mode. This is one I’ve talked about <a href="https://somethingaboutmaps.wordpress.com/2016/10/03/terrain-in-photoshop/">before on this very blog</a>. Below, I have a solid black layer, and it’s masked with the rainfall data.</p>



<figure><img data-attachment-id="8460" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-164/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-55.png" data-orig-size="2646,916" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-55.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-55.png?w=1024" loading="lazy" width="2646" height="916" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-55.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-55.png 2646w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-55.png?w=150&amp;h=52 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-55.png?w=300&amp;h=104 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-55.png?w=768&amp;h=266 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-55.png?w=1024&amp;h=354 1024w" sizes="(max-width: 2646px) 100vw, 2646px"></figure>



<p>In the dissolve mode, basically Photoshop uses the mask layer to decide the likelihood of a pixel appearing. There are no semi-transparent pixels: they are either wholly transparent, or wholly opaque. So this turns our rainfall data into a scatter of dots.</p>



<p>I took this scatter of dots, flattened it out (with a white background) into a single layer, and then made a bunch of copies. I blurred each copy a different amount, and stacked them all together. And then did some re-sharpening. In the end I was left with a speckly, but soft, noise texture.</p>



<figure><img data-attachment-id="8462" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-165/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-56.png" data-orig-size="2240,1092" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-56.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-56.png?w=1024" loading="lazy" width="2240" height="1092" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-56.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-56.png 2240w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-56.png?w=150&amp;h=73 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-56.png?w=300&amp;h=146 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-56.png?w=768&amp;h=374 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-56.png?w=1024&amp;h=499 1024w" sizes="(max-width: 2240px) 100vw, 2240px"></figure>



<p>And <em>this</em> is what I used to control where the green layer blended into the tan. If we zoom in closely you can see it at work.</p>



<figure><img data-attachment-id="8464" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-166/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-57.png" data-orig-size="2964,1386" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-57.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-57.png?w=1024" loading="lazy" width="2964" height="1386" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-57.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-57.png 2964w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-57.png?w=150&amp;h=70 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-57.png?w=300&amp;h=140 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-57.png?w=768&amp;h=359 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-57.png?w=1024&amp;h=479 1024w" sizes="(max-width: 2964px) 100vw, 2964px"></figure>



<p>I did all this work to ensure that the vegetation layer looked more like <em>vegetation</em> (i.e., individual plants). Though, honestly, a lot of this doesn’t show up on the printed version of the map unless you’ve got a magnifier. But, most people will look at it on screen and so they’ll hopefully still appreciate it.</p>



<p>Here’s what it would look like if I’d just used the original, unspeckled, smooth rainfall layer as a mask:</p>



<figure><img data-attachment-id="8466" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-167/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-58.png" data-orig-size="3120,1318" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-58.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-58.png?w=1024" loading="lazy" width="3120" height="1318" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-58.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-58.png 3120w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-58.png?w=150&amp;h=63 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-58.png?w=300&amp;h=127 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-58.png?w=768&amp;h=324 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-58.png?w=1024&amp;h=433 1024w" sizes="(max-width: 3120px) 100vw, 3120px"></figure>



<p>Now as we go from a rainy area to a dry one, the vegetation just sort of slowly fades out. It doesn’t look quite natural. At the boundary of a desert, individual trees don’t suddenly become transparent. Instead, you still have trees, but you just have fewer and fewer of them. That’s what the speckling accomplishes.</p>



<p>Next up: xenofungus. This is one of the native lifeforms of Chiron. It’s show on the game map, and in various in-game media, as pinkish or reddish. I add this to the map using pretty much exactly the same process as the greenery. I interpolated the point data, smooth it out a bit, make it noisy, and use it as a mask for a reddish version of the relief.</p>



<figure><img data-attachment-id="8469" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-168/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-59.png" data-orig-size="2500,1316" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-59.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-59.png?w=1024" loading="lazy" width="2500" height="1316" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-59.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-59.png 2500w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-59.png?w=150&amp;h=79 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-59.png?w=300&amp;h=158 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-59.png?w=768&amp;h=404 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-59.png?w=1024&amp;h=539 1024w" sizes="(max-width: 2500px) 100vw, 2500px"></figure>



<p>Next up : rivers. There are a handful of these which appear on the in-game map. They are very square, since they’re confined to the map grid. To make these a bit more real-looking, I redrew them manually in QGIS.</p>



<figure><img data-attachment-id="8473" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-170/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-61.png" data-orig-size="2746,994" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-61.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-61.png?w=1024" loading="lazy" width="1024" height="370" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-61.png?w=1024" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-61.png?w=1022 1022w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-61.png?w=2044 2044w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-61.png?w=150 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-61.png?w=300 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-61.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For the cartography side of things, I gave a slight taper to the source end of each river in Adobe Illustrator, and then brought them into Photoshop, colored them, and gave them a little bit of a downward bevel so that they seem incised into the land. It’s a tiny thing that no one will really notice on the final print, but you’d be able to tell if I <em>didn’t</em> do it.</p>



<figure><img data-attachment-id="8475" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-171/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-62.png" data-orig-size="2168,822" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-62.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-62.png?w=1024" loading="lazy" width="2168" height="822" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-62.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-62.png 2168w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-62.png?w=150&amp;h=57 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-62.png?w=300&amp;h=114 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-62.png?w=768&amp;h=291 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-62.png?w=1024&amp;h=388 1024w" sizes="(max-width: 2168px) 100vw, 2168px"></figure>



<p>I <em>did</em> look at generating a new set of rivers based on my DEM. I ran some hydrological analysis tools, but, due to the bumpy nature of the terrain (both because of my noise, and because of the original game map elevations) I mostly got a lot of endorheic basins and stubby rivers. Drawing my own was easier (and I looked at my relief model to make sure I didn’t cross over any ridges).</p>



<p>That wraps up all the stuff on land. I applied a clipping mask to all this stuff, so that the fungus/greenery/tan relief/etc. only show up where they are supposed to. I also put a little outer glow on the land, to lighten up the coastal waters. Here’s where we’re at right now in our Photoshop stack:</p>



<figure><img data-attachment-id="8480" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-174/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-65.png" data-orig-size="3086,1342" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-65.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-65.png?w=1024" loading="lazy" width="3086" height="1342" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-65.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-65.png 3086w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-65.png?w=150&amp;h=65 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-65.png?w=300&amp;h=130 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-65.png?w=768&amp;h=334 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-65.png?w=1024&amp;h=445 1024w" sizes="(max-width: 3086px) 100vw, 3086px"></figure>



<p>Just a few more layers to go! Next up is more xenofungus. The fungus occurs not only on land, but also in the water. I didn’t want to use exactly the same color, though, so I added the water fungus separately. Just a simple purple layer that uses the same speckled mask as the land fungus, but is also in a layer that keeps it clipped to the water only. It’s set to blend into the underlying water via a <em>linear burn</em> blending mode.</p>



<figure><img data-attachment-id="8481" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-175/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-66.png" data-orig-size="3494,1832" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-66.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-66.png?w=1024" loading="lazy" width="3494" height="1832" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-66.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-66.png 3494w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-66.png?w=150&amp;h=79 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-66.png?w=300&amp;h=157 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-66.png?w=768&amp;h=403 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-66.png?w=1024&amp;h=537 1024w" sizes="(max-width: 3494px) 100vw, 3494px"></figure>



<p>Next up, I apply a saturation boost to the whole map, and add a graticule to help visualize the curvature. The increase in saturation was something I originally did by accident, just moving layers around in Photoshop. But, I liked how it looked, so I kept it.</p>



<figure><img data-attachment-id="8483" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-176/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-67.png" data-orig-size="2500,1316" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-67.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-67.png?w=1024" loading="lazy" width="2500" height="1316" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-67.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-67.png 2500w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-67.png?w=150&amp;h=79 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-67.png?w=300&amp;h=158 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-67.png?w=768&amp;h=404 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-67.png?w=1024&amp;h=539 1024w" sizes="(max-width: 2500px) 100vw, 2500px"></figure>



<p>The result is a color scheme that’s a little outside of my comfort zone. I tend to lean toward less saturated colors, and am noted for my fondness of working in <a href="https://somethingaboutmaps.com/Monochrome" target="_blank" rel="noreferrer noopener">monochrome</a>. But, this is a side project, so it’s a good time for me to experiment.</p>



<p>Next up, I gave things a semi-painted look. I copied the map, flattened it into a single layer, shrank it down, and ran a <em>dry brush</em> filter in Photoshop. This gives things a somewhat painted look that I really like. </p>



<figure><img data-attachment-id="8485" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-177/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-68.png" data-orig-size="2568,1066" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-68.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-68.png?w=1024" loading="lazy" width="2568" height="1066" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-68.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-68.png 2568w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-68.png?w=150&amp;h=62 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-68.png?w=300&amp;h=125 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-68.png?w=768&amp;h=319 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-68.png?w=1024&amp;h=425 1024w" sizes="(max-width: 2568px) 100vw, 2568px"></figure>



<p>Above, you can see both the before and after. In the center, we have the pre-filtered version. Around the outside, you can see the much softer version after the effect is applied. I’ve been meaning for some time to do a tutorial on this technique, and that might happen this year.</p>



<p>The softness was a little <em>too</em> blurry, so I actually mixed it 50-50 with the original map, which I think gives a nice balance of detail and painterly softness.</p>



<figure><img data-attachment-id="8488" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-179/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-70.png" data-orig-size="2322,1072" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-70.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-70.png?w=1024" loading="lazy" width="2322" height="1072" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-70.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-70.png 2322w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-70.png?w=150&amp;h=69 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-70.png?w=300&amp;h=139 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-70.png?w=768&amp;h=355 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-70.png?w=1024&amp;h=473 1024w" sizes="(max-width: 2322px) 100vw, 2322px"></figure>



<p>We’re nearly done with this file. Here’s how it looks at this stage:</p>



<figure><img data-attachment-id="8490" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-180/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-71.png" data-orig-size="2500,1316" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-71.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-71.png?w=1024" loading="lazy" width="2500" height="1316" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-71.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-71.png 2500w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-71.png?w=150&amp;h=79 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-71.png?w=300&amp;h=158 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-71.png?w=768&amp;h=404 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-71.png?w=1024&amp;h=539 1024w" sizes="(max-width: 2500px) 100vw, 2500px"></figure>



<p>Finally, I added a bit of darkening to emphasize the curved surface. I just did a couple of inner shadows to slightly darken the edges (by different amounts, depending on the edge), to give a sense of the light falling off in a way that perhaps suggests the reader that this is not a flat piece.</p>



<figure><img data-attachment-id="8492" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-181/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-72.png" data-orig-size="2500,1316" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-72.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-72.png?w=1024" loading="lazy" width="2500" height="1316" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-72.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-72.png 2500w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-72.png?w=150&amp;h=79 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-72.png?w=300&amp;h=158 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-72.png?w=768&amp;h=404 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-72.png?w=1024&amp;h=539 1024w" sizes="(max-width: 2500px) 100vw, 2500px"></figure>



<h2>Labeling</h2>



<p>I did the initial labeling work in Adobe Illustrator, as it has significantly better tools for handling type than Photoshop does. When I was done, the labels were ported back over to Photoshop to blend into the map.</p>



<figure><img data-attachment-id="8494" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-182/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-73.png" data-orig-size="2500,1316" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-73.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-73.png?w=1024" loading="lazy" width="2500" height="1316" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-73.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-73.png 2500w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-73.png?w=150&amp;h=79 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-73.png?w=300&amp;h=158 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-73.png?w=768&amp;h=404 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-73.png?w=1024&amp;h=539 1024w" sizes="(max-width: 2500px) 100vw, 2500px"></figure>



<p>I blurred the map under each label, which helps with legibility by keeping the text <a href="https://somethingaboutmaps.wordpress.com/2021/06/01/on-edges/" target="_blank" rel="noreferrer noopener">edges sharper</a> than the background.</p>



<figure><img data-attachment-id="8496" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-183/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-74.png" data-orig-size="2716,920" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-74.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-74.png?w=1024" loading="lazy" width="2716" height="920" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-74.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-74.png 2716w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-74.png?w=150&amp;h=51 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-74.png?w=300&amp;h=102 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-74.png?w=768&amp;h=260 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-74.png?w=1024&amp;h=347 1024w" sizes="(max-width: 2716px) 100vw, 2716px"></figure>



<p>I also applied a glow to the land labels and the graticule, which you can see above. It’s just a darkened version of the original map, feathered out around the areas I chose to depict in semitransparent white text. I also added a light glow to the outside of the dark labels. Both of these help with contrast and let me get away with light text on a light background and dark text on a dark background.</p>



<figure><img data-attachment-id="8498" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-184/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-75.png" data-orig-size="2936,864" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-75.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-75.png?w=1024" loading="lazy" width="2936" height="864" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-75.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-75.png 2936w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-75.png?w=150&amp;h=44 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-75.png?w=300&amp;h=88 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-75.png?w=768&amp;h=226 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-75.png?w=1024&amp;h=301 1024w" sizes="(max-width: 2936px) 100vw, 2936px"></figure>



<p>I also applied a version of my <a href="https://somethingaboutmaps.wordpress.com/2018/10/28/smart-type-halos-in-photoshop-and-illustrator/" target="_blank" rel="noreferrer noopener">smart halos</a> technique to further strengthen the glow where needed.</p>



<p>I set all the labels in <a href="https://www.sarahbellmaps.com/typography-for-topography-belltopo-sans-free-font/" target="_blank" rel="noreferrer noopener">BellTopo Sans</a>, designed by my friend and colleague Sarah Bell. Finding the right typeface for this map was a bit of a challenge. I didn’t want to go with a serif—I thought most of them looked too delicate for the map’s bold color scheme, and also seemed out of place on a sci-fi map. Plus they wouldn’t hold up very well when set semi-transparent.</p>



<p>The game itself uses <a href="https://en.wikipedia.org/wiki/Eurostile" target="_blank" rel="noreferrer noopener">Eurostile</a>, but I thought it looked too hard for a map with a soft palette and style.</p>



<figure><img data-attachment-id="8501" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-185/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-76.png" data-orig-size="2098,898" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-76.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-76.png?w=1024" loading="lazy" width="2098" height="898" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-76.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-76.png 2098w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-76.png?w=150&amp;h=64 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-76.png?w=300&amp;h=128 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-76.png?w=768&amp;h=329 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-76.png?w=1024&amp;h=438 1024w" sizes="(max-width: 2098px) 100vw, 2098px"></figure>



<p><em>Most</em> sans serifs seemed a little too solid for the feel of the map. But, BellTopo Sans worked nicely. It has the strength of a sans serif, but also has some strong humanistic elements. For example, look at that colorful lowercase <strong>g</strong>, the rounded tops of the <strong>W</strong>, or the squished curve forming the bowl of the <strong>a</strong>. The whole typeface has hints of a hand-drawn character (it’s derived from old topo maps).</p>



<figure><img data-attachment-id="8504" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-186/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-77.png" data-orig-size="1446,646" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-77.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-77.png?w=1024" loading="lazy" width="1446" height="646" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-77.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-77.png 1446w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-77.png?w=150&amp;h=67 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-77.png?w=300&amp;h=134 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-77.png?w=768&amp;h=343 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-77.png?w=1024&amp;h=457 1024w" sizes="(max-width: 1446px) 100vw, 1446px"></figure>



<p>The biggest challenge in labeling was not one that I usually face in my work: I didn’t always know where features were. In the game, features are not always labeled clearly. They are simply bits of white text placed atop single grid tiles.</p>



<figure><img data-attachment-id="8506" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-187/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-78.png" data-orig-size="3598,1596" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-78.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-78.png?w=1024" loading="lazy" width="3598" height="1596" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-78.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-78.png 3598w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-78.png?w=150&amp;h=67 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-78.png?w=300&amp;h=133 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-78.png?w=768&amp;h=341 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-78.png?w=1024&amp;h=454 1024w" sizes="(max-width: 3598px) 100vw, 3598px"></figure>



<p>In many cases, I had to apply my own interpretation to decide the boundaries of ambiguous features. Planetneck, seen above, was the most challenging of these. Does it refer to that finger of water? To the bit of land crossing it? To make matters worse, that bit of land is itself ambiguous. There are several spots in the game marked with these thin brown lines that indicate that they are traversable on both land and water.</p>



<figure><img data-attachment-id="8508" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-188/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-79.png" data-orig-size="1824,892" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-79.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-79.png?w=1024" loading="lazy" width="1824" height="892" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-79.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-79.png 1824w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-79.png?w=150&amp;h=73 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-79.png?w=300&amp;h=147 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-79.png?w=768&amp;h=376 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-79.png?w=1024&amp;h=501 1024w" sizes="(max-width: 1824px) 100vw, 1824px"><figcaption>Blue arrows: You can move ships across the thin bits of land. Orange arrows: you can move land units along the thin bits of land.</figcaption></figure>



<p>So, there are plenty of areas that might reasonably be construed as land <em>or</em> as water. My randomization process used in creating the elevation model made it so I didn’t have to decide which was which, but it also still left me to decide what Planetneck is. I ended up deciding it was the narrow entrance to the long, finger-like bay.</p>



<figure><img data-attachment-id="8511" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-189/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-80.png" data-orig-size="2202,1288" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-80.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-80.png?w=1024" loading="lazy" width="2202" height="1288" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-80.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-80.png 2202w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-80.png?w=150&amp;h=88 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-80.png?w=300&amp;h=175 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-80.png?w=768&amp;h=449 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-80.png?w=1024&amp;h=599 1024w" sizes="(max-width: 2202px) 100vw, 2202px"></figure>



<p>This was mostly an arbitrary decision, but it <em>is</em> supported by the fact that the game has names for a few other straits, so there were other features of this type already called out in the canonical map.</p>



<p>The official map only has 32 names, which is far less than I would usually have for a map like this. But, I didn’t feel comfortable coining any new ones. The choices of what to label are sometimes strange. Only two landmasses are named, and they’re mid-sized islands. The big continents are anonymous. There’s only one body of water called an “ocean,” and it’s smaller than some that are called “seas.” But, it is what it is. Maybe one of the game developers will find this and comment with their thoughts on how this came to be.</p>



<p>Finally, it was time to put this map into a poster. I added a few more, smaller maps, made from the same datasets and with the same techniques. One to show the elevation data more clearly, and two to show the polar regions with less distortion.</p>



<figure><img data-attachment-id="8514" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-190/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-81.png" data-orig-size="3000,2250" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-81.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-81.png?w=1024" loading="lazy" width="3000" height="2250" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-81.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-81.png 3000w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-81.png?w=150&amp;h=113 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-81.png?w=300&amp;h=225 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-81.png?w=768&amp;h=576 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-81.png?w=1024&amp;h=768 1024w" sizes="(max-width: 3000px) 100vw, 3000px"></figure>



<p>I continued to use BellTopo Sans for the poster text. I also added some faint scanlines to the background and the maps themselves.</p>



<figure><img data-attachment-id="8516" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-191/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-82.png" data-orig-size="2400,1350" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-82.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-82.png?w=1024" loading="lazy" width="2400" height="1350" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-82.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-82.png 2400w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-82.png?w=150&amp;h=84 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-82.png?w=300&amp;h=169 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-82.png?w=768&amp;h=432 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-82.png?w=1024&amp;h=576 1024w" sizes="(max-width: 2400px) 100vw, 2400px"></figure>



<p>This is an homage to the game interface (as is the blue color on the title and the frames surrounding the map). I think the scanlines also really do a great job of tying all the items in the layout together.</p>



<figure><img data-attachment-id="8518" data-permalink="https://somethingaboutmaps.wordpress.com/2025/05/20/planetfall/image-192/" data-orig-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-83.png" data-orig-size="2160,1462" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-83.png?w=300" data-large-file="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-83.png?w=1024" loading="lazy" width="2160" height="1462" src="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-83.png" alt="" srcset="https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-83.png 2160w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-83.png?w=150&amp;h=102 150w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-83.png?w=300&amp;h=203 300w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-83.png?w=768&amp;h=520 768w, https://somethingaboutmaps.wordpress.com/wp-content/uploads/2025/05/image-83.png?w=1024&amp;h=693 1024w" sizes="(max-width: 2160px) 100vw, 2160px"></figure>



<h2>Wrap-Up</h2>



<p>So there you have it! This was one of the most technically laborious projects of my career. Tedious sampling from the game data; lots of GIS work to convert those data into something higherer resolution; the demands of fine-tuning a custom projection that isn’t supported in QGIS; and many Photoshop layers to try and bring everything together with lots of carefully constructed noise.</p>



<p>I wish I could say I did all of these things in the order I presented them above, or as efficiently as I described them. But, the real process was months of meandering and false starts and dead ends.</p>



<p>Now that I have the datasets, I may do more with them. I’ll probably play around in the future with larger scale mapping, zooming in on smaller chunks of the planet. This will give me a chance to explore ways to generate even more realistic terrain that still conforms with the handful of known elevation values. Your suggestions are welcome. One thing I didn’t try was using the rockiness data. I only thought of that <em>after</em> I finished the map designs. I went back and quickly had a look at using that layer as a mask to smooth my elevation model. Fortunately, it didn’t really make much of a difference at this scale, but it would if I zoomed in.</p>



<p>The original DEM also still needs some further cleanup (I had to manually patch a couple of missing lakes and islands onto the map, but I didn’t fix them in the elevation model). Though I’ll probably just replace it with a better one, once I know how to generate something with a bit more realism.</p>



<p>As I said, I could only make this map because I had data to work with. I don’t presently have the skills to sit down and make something like this just by drawing. I’m a manipulator, rather than a generator, of data. But it was fun to try and take those skills and apply them to a fictional location. It took basically all of my fifteen years of growth as a cartographer to get to the point where I could do justice to this game from my past (and present, though it’s been a few years since I played much). As is so often the case, the more I work on something, the more niche its appeal tends to be, but I’m glad to know that there is a specific type of nerd out there who will really appreciate it.</p>



<hr>



<p>Speaking of, if you’re a nerd who appreciates this, I’ll once again remind you that your support helps me continue doing projects like this, so consider clicking the buttons below, and/or sharing my work with others if you enjoyed it—it’s a big help!</p>








	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why does Debian change software? (261 pts)]]></title>
            <link>https://blog.liw.fi/posts/2025/why-debian-changes/</link>
            <guid>44059411</guid>
            <pubDate>Thu, 22 May 2025 06:50:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.liw.fi/posts/2025/why-debian-changes/">https://blog.liw.fi/posts/2025/why-debian-changes/</a>, See on <a href="https://news.ycombinator.com/item?id=44059411">Hacker News</a></p>
<div id="readability-page-1" class="page"><article class="page">
    

    

    <section id="pagebody">
	<p>When I wrote <a href="https://blog.liw.fi/posts/2023/debian-reasons/">Why is Debian the way it is?</a>, a year and a half ago, I was asked to also cover why Debian changes the software it packages. Here’s a brief list of examples of why that happens:</p>
<ul>
<li><p>Software in Debian needs to follow certain policies as set by Debian over the years, and documented in the <a href="https://www.debian.org/doc/debian-policy/">Debian Policy Manual</a>. These are mostly mundane things like system wide configuration being in <code>/etc</code>, documentation in <code>/usr/share/doc</code>, and so on. Some of this is more intricate, like when names of executables can be the same in different packages.</p></li>
<li><p>Programs included in Debian need to work together in other ways. This might mean require changing one or both. As an example, they might need to agree where Unix domain socket exists, or what Unix user account they should run under.</p></li>
<li><p>Debian will remove code that “calls home” or tries to update software in a way that bypasses the Debian packaging system. This is done both for privacy reasons, and because updating software without going via the packaging system is usually problematic from a functional point of view, and always problematic from a security point of view.</p></li>
<li><p>Debian may fix bugs before they’re fixed in upstream, or may backport a bug fix to an earlier version. The goal here is to make life better for users of Debian. Debian does this especially for fixes to security problems, but also for other problems.</p></li>
<li><p>Debian avoids including anything in the main part of its package archive it can’t legally distribute. This applies to the source packages. This means, Debian may strip out those parts software that it doesn’t think are free according to the Debian Free Software Guidelines. The stripped-out parts might be moved to another package in the “non-free” part of Debian. An example might a manual that is licensed under the GNU Free Documentation License with immutable parts, or a logo that can’t be changed.</p></li>
<li><p>Debian has often added a manual page when the upstream doesn’t provide one.</p></li>
</ul>
<p>Thank you to Jonathan McDowell for help with this list. Opinions and mistakes are mine. Mine, I say!</p>

      </section>

  </article></div>]]></description>
        </item>
    </channel>
</rss>