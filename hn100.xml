<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 10 Feb 2025 12:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[To buy a Tesla Model 3, only to end up in hell (320 pts)]]></title>
            <link>https://www.myteslaexperience.com/2025-02-01/to-buy-a-tesla-mode-3-only-to-end-up-in-hell</link>
            <guid>42998024</guid>
            <pubDate>Mon, 10 Feb 2025 08:25:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.myteslaexperience.com/2025-02-01/to-buy-a-tesla-mode-3-only-to-end-up-in-hell">https://www.myteslaexperience.com/2025-02-01/to-buy-a-tesla-mode-3-only-to-end-up-in-hell</a>, See on <a href="https://news.ycombinator.com/item?id=42998024">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p><span>Written by</span>
    
        My Tesla Experience
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2025-02-01 23:00:00 +0000">February 01, 2025</time>
    
  </p>

  
  

  <p>In October 2024 I decided to buy a <a href="https://www.tesla.com/model3">Tesla Model 3</a>. When I picked up the car, many of its features did not work (cameras, GPS navigation system, autopilot, software updates, etc.). It turned out to be <a href="https://electrek.co/2024/12/16/tesla-major-issue-self-driving-computer-inside-new-cars/">a major issue with Tesla’s brand-new on-board computer</a>. This is a common failure in Tesla Model 3 cars manufactured in the last quarter of 2024. The issue has affected thousands of Tesla customers. Two weeks later, the car began to <strong>lose 8% battery daily</strong>. Several drivers experiencing the same failure have also reported <strong>problems with the braking (ABS) and suspension (EPS) systems</strong>.</p>

<p>Tesla acknowledges all faults in the vehicle (except for battery losses, a fact on which it has not yet formally commented). The company refuses to accept a return of the vehicle without penalty, even though the problems were reported immediately. The only solution they offer is to make me wait 3 months for a miraculous replacement part. Ignored and without any type of compensation, I live attached to a car that needs a <strong>full recharge every 12 days to not die</strong>. For my own safety, and that of other drivers, I have stopped driving the vehicle.</p>

<p>In this blog I tell you how it happened. If you are the owner of a Tesla car, or you are thinking about buying one, I encourage you to read my blog and see up close how <strong>Elon Musk’s company</strong> treats their own customers. It is possible that if you have problems with your car, you will end up living in hell.</p>

<h2 id="the-road-to-a-tesla">The road to a Tesla</h2>

<p>It’s been over 4 years since I stopped driving regularly.</p>

<p>At the end of 2020, my partner and I moved to <strong>Shenzhen</strong> (China). My old car, a <strong>Renault Clio DCI 1.5</strong>, stayed in Spain. I had bought it second-hand in 2007, and it served me well for more than 10 years. I never had big problems. Upon returning from China, at the end of 2023, my wife and I went to live in <strong>Slovakia</strong>, where she is from. That’s when I made the decision that in 2024 I would buy a new car.</p>

<p>I’m not a motor enthusiast. I like to drive, and I have had the opportunity to take long car trips through Spain and other countries, but I know little about cars. Therefore, when purchasing a new vehicle, I decided to follow the advice of what experts call <a href="https://en.wikipedia.org/wiki/Wisdom_of_the_crowd">“the wisdom of the crowd”</a>. Of the list of the <a href="https://www.xataka.com/movilidad/coches-vendidos-2023-2024-espana">10 best-selling cars in Spain</a>, the one that caught my attention the most was the <strong>Toyota Corolla</strong>. It is a car that I had already driven as a rental vehicle on several occasions. The decision was almost made, my next car would be a Toyota Corolla.</p>

<p>It was during a family gathering in August when I decided to ask my cousins, much more educated than me in the world of motors, for advice. One of them had a <a href="https://www.autocar.co.uk/car-review/kia/ev6">Kia EV6</a>. He was very satisfied with it, so the idea of buying an electric car began to float around in my head.</p>

<p>I started reading blogs and online magazines about electric cars. I soon came to the conclusion that the <strong>Tesla Model 3</strong> is, today, the best EV in terms of quality and price. It is the electric car with the lowest consumption (12.5 kW / 100 km), and it is also the best-selling EV in the world (again <em>the wisdom of the crowd</em>). In addition, there is the incentive of the <a href="https://en.wikipedia.org/wiki/Tesla_Supercharger">Tesla Charger Network</a>. After reading an article on my friend Alberto Ruibal’s blog in which he argues <a href="https://www.alonsoruibal.com/el-tesla-model-3-sale-mas-barato-que-un-dacia-sandero/">why the Tesla Model 3 is cheaper than a Dacia Sandero</a> (in Spanish), I ended up being completely convinced. My next car would be a Tesla Model 3.</p>

<h2 id="buying-a-tesla-where-there-is-no-tesla">Buying a Tesla where there is no Tesla</h2>

<p>A Tesla car is always purchased through <a href="https://www.tesla.com/">Tesla’s website</a>. If you live in a country where Tesla is officially present, you would simply go to the website and buy your car from your country (for example, <em>Tesla Spain</em>). Unfortunately, Tesla is still not present in some countries in Europe. That is the case of countries such as Slovenia, Latvia, Lithuania or <strong>Slovakia</strong>, where I live. If Tesla is not present in your country of residence, you would go to Tesla’s website and buy your car at <strong>Tesla Europe</strong>, which is physically located in <strong>Tilburg</strong> (Holland). In short, when you live in a European country where there is no Tesla you have to import your car from Holland (See <strong>NOTE</strong>).</p>

<p>Importing the car from Holland implies an additional investment of time and money. More time, because you will have to complete <strong>more bureaucratic procedures to register the car</strong> in your country of residence. More money, because you will need to hire a transport company to <strong>bring your car from Holland</strong>. It is not possible to travel to Holland, get to Tilburg, and drive the car from there.</p>

<p>Another problem with importing the car is that, in case there is some type of subsidy for the acquisition of EVs in your country of residence, it is likely you will not be able to use it if the vehicle is imported.</p>

<p>I estimate that the total import costs were slightly over 2000 EUR.</p>

<p><strong>NOTE</strong>: In some Internet online boards I read that it is possible to buy the car in any other country in Europe, but normally users who choose this option usually have problems with VAT refunds.</p>

<h2 id="transporting-a-car-from-holland">Transporting a car from Holland</h2>

<p>I made my reservation on <strong>October 5, 2024</strong>. Three weeks later, specifically on <strong>October 31</strong>, the car was already available for pickup. I then contacted a vehicle transport company, <a href="https://www.tradisa.com/">Tradisa</a>, to organize the delivery.</p>

<p>Incidentally, just when the car was arriving, I was in Spain. Therefore, Tradisa suggested me to contact <a href="https://www.drivetesla.sk/">DriveTesla.sk</a>. This is a company in Slovakia that is dedicated to importing Tesla cars. They offer services such as vehicle purchase, registration, insurance, etc. I contracted several services with them: insurance, car registration and deposit service (in addition to winter tires). On <strong>November 4</strong>, Tradisa dropped the car off at DriveTesla facilities and three weeks later, once I was back in Slovakia, I went to Bratislava to pick up the car. It was <strong>Friday, November 29</strong>. After almost 2 months since the reservation, the car was finally in my hands!</p>

<p>But not everything was going to be good news. One of DriveTesla’s staff members warned me: <em>“By the way, the cameras are not working. Probably it can be fixed by updating the Operating System.”</em> I didn’t know it at the time, but my nightmare was about to begin…</p>

<h2 id="hands-on-the-wheel">Hands on the wheel</h2>

<p>Making the jump from a <strong>20-year-old Renault Clio</strong> to a <strong>Tesla Model 3</strong> is not trivial. I’d driven automatic cars before, but at least they had a physical gear-shifter! :) For 45 minutes, one of the DriveTesla staff members taught me the gist of how the car worked. We also took the opportunity to try to update the Operating System and solve the <strong>cameras problem</strong>, but <strong>the download got stuck halfway through</strong>. It seems like I wasn’t going to be able to fix the cameras, but did I really need them? <em>“My old Clio didn’t have cameras, I’m not going to miss them”</em>, I thought.</p>

<p>I was expecting a long trip, so before hitting the road I decided to take a few laps to practice. I practiced until I felt comfortable. Before leaving, I looked up my destination on the car’s <strong>GPS navigator</strong>. Bad luck, the GPS didn’t work either. <em>“What difference does it make? My old Clio didn’t have a GPS navigator either. I’m not going to miss it”</em>, I thought again. I pulled my phone out of my pocket, looked for my destination on Google Maps (a small town in the middle of Slovakia where I would meet my wife), and this time, I hit the road.</p>

<p>On the way it started to rain. I remembered what I was told me during the instruction: <em>“the Tesla Model 3 has a <strong>windshield wiper that comes into operation automatically</strong> when it starts raining”</em>. It was raining and raining, but the automatic windshield wipers didn’t kick in. On the steering wheel hub, there is also a physical button to activate the wipers manually. I had no choice but to start pressing that button, and continue doing it often because unfortunately it wasn’t raining, it was pouring. From the Tesla’s main screen, it’s possible to set the windshield wiper speed. However, I prefer to <strong>not take my eyes off the road</strong> when I drive. After a long time of almost continuously pressing the button, I discovered that the speed can also be set by pressing the button twice in a row very quickly.</p>

<p>After an hour and a half of driving, I stopped the car to rest and stretch my legs. That’s when I understood what was happening. Since the cameras were not working, the automatic windshield wipers did not work either. Paying more attention to the information screen, I realized of several notifications warning that other functionalities in the car were not available. For example, <strong>lane departure detection</strong>, <strong>sleep detection</strong> or <strong>emergency brake</strong>. That is to say, <strong>everything that depended on the car’s cameras didn’t work</strong>, including <strong>Autopilot</strong> obviously (but luckily it didn’t occur to me to try it lol). Another thing that didn’t work was <strong>syncing with Spotify</strong>. I mean, I managed to pair Spotify from my phone to the Tesla, but when I started playing music, the song stopped after 10 seconds. This always happened, regardless of which song.</p>

<p>Even so, I still had hope inside of me all this could be solved by updating the Operating System. Because we already know that hope is the last thing ever lost and we human beings are forever optimists.</p>

<h2 id="a-broken-car">A broken car</h2>

<p>On Sunday <strong>December 1</strong>, when I got home, I tried to update the Operating System again. No luck. Same problem again, the download hung halfway.</p>

<p>The next day, I gave it another try with the same result. So on Tuesday, <strong>December 3</strong>, I gave up completely and opened a ticket, through the Tesla app, at the <strong>Budapest Service Center</strong> (my closest Tesla Service Center). I described all the technical problems I had observed in the car so far:</p>
<ul>
  <li>The <strong>cameras</strong> are not working.</li>
  <li>The <strong>GPS navigator</strong> is not working.</li>
  <li>Nothing that depends on the cameras works: <strong>Autopilot</strong>, <strong>automatic windshield wipers</strong>, <strong>automatic lights</strong>, <strong>lane departure detection</strong>, <strong>drowsiness detection</strong>, etc.</li>
  <li><strong>OS updates</strong> are not working</li>
  <li><strong>Spotify</strong> is not working.</li>
</ul>

<p>After four days without receiving a response from the <strong>Budapest Service Center</strong>, I texted them again. On the sixth day, terribly worried, I called <strong>Tesla Customer Service</strong>. After a long wait, I managed to speak to an agent. As I was describing the problem, he already knew what the issue was about. This article, authored by <strong>Fred Lambert</strong> for <strong>Electrek</strong>, explains the problem in the car: <a href="https://electrek.co/2024/12/16/tesla-major-issue-self-driving-computer-inside-new-cars">Tesla is having major issue with its self-driving computer inside new cars</a>. The article describes a fault present in many of the Tesla Model 3 manufactured in the last quarter of 2024. A short circuit when calibrating the cameras leaves the new on-board computer, known as HW4, unusable.</p>

<p><em>“The problem is linked to a new version of Tesla’s HW4 (sometimes called AI4) onboard self-driving computer. Internally, some refer to the new version as AI4.1. The computers are short-circuiting.”</em></p>

<p>And then it continues:</p>

<p><em>“Tesla drivers are reporting computer failures after driving off with their brand-new cars over just the first few tens to hundreds of miles. Wide-ranging features powered by the computer, like active safety features, cameras, and even GPS, navigation, and range estimations, fail to work.”</em></p>

<p>These are exactly the problems that I had observed in the vehicle, along with other additional dysfunctions such as the inability to update the Operating System and the data transfer problems in Spotify.</p>

<p>The article also explains that Tesla <strong>does not have replacement stock</strong> for the new on-board computer, and is making its customers believe that the car is drivable in this state and poses no risk:</p>

<p><em>“One source said that Tesla service is being told to play down any safety concerns related to this problem to avoid people believing their brand-new cars are not drivable. It’s unclear if Tesla reported the issue to NHTSA despite the fact that the broken rear-view camera goes against federal safety regulations, which should force a recall.”</em></p>

<p><em>“Tesla service is currently being overwhelmed by the issue, and Tesla is pushing service appointments to next year.”</em></p>

<p>On <strong>December 10, 2024</strong>, I received a response from the Budapest Service Center <strong>confirming the problems in the vehicle</strong> and that <strong>the on-board computer had to be replaced</strong>. As the article points out, they informed me that at the moment they did not have the part in stock and they did not know when it would be available.</p>

<p><img src="https://www.myteslaexperience.com/files/2025/02/confirmation-budapest.png" alt="Confirmación Budapest"></p>

<p>Exactly one week later, I received a message in Hungarian from the Budapest Service Center letting me choose a date for my appointment. The earliest date, <strong>February 28, 2025</strong>.</p>

<p><img src="https://www.myteslaexperience.com/files/2025/02/appointment-date-budapest.png" alt="Fecha cita en Centro de Servicio de Budapest"></p>

<p>Almost 3 months of waiting to, hypothetically, repair the vehicle. Apparently, Tesla considers OK their customers to drive vehicles with the following features not working:</p>
<ul>
  <li><strong>Cameras</strong>: essential for parking, surveillance, etc.</li>
  <li><strong>GPS navigation system</strong>: a crucial feature in the Tesla Model 3, as when planning a route, the car indicates where to stop for charging. Additionally, when approaching a charging point, the vehicle automatically preheats the battery for a faster recharge.</li>
  <li><strong>Braking (ABS) and suspension (EPS) systems</strong>: I have no way of knowing whether these systems are working correctly in my vehicle or not, as I never had the chance to drive the car in perfect condition. Regardless, I don’t believe I have to risk my own safety, or that of others, to find out whether these systems are working reliably.</li>
  <li><strong>Software updates</strong> and <strong>data downloads</strong> (e.g., from Spotify).</li>
  <li><strong>Other systems that rely on cameras</strong>: Autopilot, automatic windshield wipers, automatic lights, lane departure detection, drowsiness detection, etc.</li>
</ul>

<h2 id="renault-clio-vs-tesla-model-3">Renault Clio vs Tesla Model 3</h2>

<p>The <a href="https://electrek.co/2024/12/16/tesla-major-issue-self-driving-computer-inside-new-cars">Electrotek article</a> cited above was published on <strong>December 15, 2024</strong>. Until I read it, I wasn’t fully aware of the impact of the breakdown. Especially, the part that affects the <strong>braking</strong> (ABS) and <strong>suspension</strong> (EPS) systems. In fact, I kept driving the car and joked with my friends that I had an <strong>Analog Tesla</strong>. That is, on the outside the car looked like a Tesla Model 3, but on the inside it worked like my old <strong>Renault Clio DCi 1.5</strong>. Let’s compare:</p>

<table>
  <tbody>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Renault Clio DCI 1.5</strong></td>
      <td><strong>Tesla Model 3</strong> (Analógico)</td>
    </tr>
    <tr>
      <td>Cameras</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Software updates</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Autopilot</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Automatic windshield wiper</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <td>automatic lights</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Lane departure detection</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Sleep detection</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Emergency brake</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Surveillance (Sentry mode)</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Spotify</td>
      <td><strong>Yes</strong> (external)</td>
      <td><strong>Yes</strong> (10 seconds)</td>
    </tr>
    <tr>
      <td>Price</td>
      <td>6,600 EUR</td>
      <td>35,970 EUR</td>
    </tr>
  </tbody>
</table>

<p>In fact, a 20-year-old Clio DCI is slightly superior to this <em>Analog Tesla Model 3</em>. It is true that the Clio does not have heated seats and steering wheel, but that does not justify the price difference I think.</p>

<p>The comparison may seem humorous, but it reveals something obvious: <strong>a Tesla Model 3 is superior to other cars for these and other features</strong>. These functionalities are not extras in the vehicle, they are an integral part of it, and have a cost for which customers pay. Some of these features are essential in a Tesla Model 3, such as <strong>GPS navigation</strong> or the <strong>camera system</strong>. Why should I take risks, whether or not I’m going to hit the car, when parking it? Planning a long-distance trip is much more difficult without GPS navigation since I have to schedule the stops myself to recharge the car and I cannot preheat the battery. When I charge on a Tesla charger, I do not know the cost since this information is only available in the GPS navigator, etc. I have left out of the picture the problems, reported by other users, in the braking (ABS) and suspension (EPS) systems, but without a doubt, they pose a risk to the safety of drivers.</p>

<p>But this story doesn’t end here. The worst was yet to come…</p>

<h2 id="doctor-my-car-is-losing-battery-is-it-serious">Doctor, my car is losing battery. Is it serious?</h2>

<p>It is expected for an EV to lose battery while it remains parked. There’s even a technical term for this. It is called <a href="https://www.ev.guide/lesson-articles/what-is-vampire-drain"><em>vampire drain</em></a> or <em>phantom drain</em>.</p>

<p>The <em><strong>vampire drain</strong></em> is the <strong>discharge that occurs in an electric car while we are not using it</strong>. It is something similar to what happens with mobile phones. Even if we are not using a cell phone, it loses battery unless it remains plugged in. The same thing happens in an EV. I don’t know what the average expected battery loss value is for a Tesla Model 3. During the 3 weeks the car was parked in Bratislava, the battery went from 83% to 79%. That is, 4% loss in 3 weeks. I think it’s a pretty reasonable number.</p>

<p>In addition to <em>vampire discharge</em>, EV owners need to be more aware about the care and maintenance of their vehicle’s battery. For example, the usual thing is to <strong>charge the car up to 80-85%</strong>, and <strong>never leave it below 20%</strong>. If the car falls below 20%, it is recommended to recharge it immediately. Electric car batteries, unlike laptop batteries, <strong>do not have a memory effect</strong>. Therefore, the battery is not damaged if the car is charged from 20% to 50%, for example. On the other hand, Tesla recommends <strong>charging the battery up to 100% at least once a week</strong>.</p>

<p>I don’t know whether it was a coincidence or not, but just when I charged the car for the first time to 100%, the battery started to drain. I charged the battery to 100% and just <strong>4 days later</strong>, without having used the car, <strong>the battery was at 83%</strong>. That means, the car had lost 4% battery daily. Just that day, my wife and I had planned a long trip to the <strong>High Tatras</strong>.</p>

<p>While driving, my wife was searching the Internet for information about what could have caused this sudden battery loss. <em>«Could it have been the cold?»</em> The car sleeps in a garage, and although it was winter the temperature never dropped below 0 degrees. It is true that extreme temperatures (very high or very low) can affect the battery, but <a href="https://www.visitnorway.com/plan-your-trip/getting-around/by-car/electric-cars">Norway has the highest number of EVs in the world per person</a>. Common sense tells me that it must be colder in Norway than in Slovakia. Therefore, it couldn’t be the cold. Another possibility could be some feature that had been left activated. It is known that the <strong>Sentry mode</strong> of the Tesla Model 3 consumes 1% every 2.5 hours. That means, if you inadvertently leave <em>Sentry mode</em> activated, the car <strong>can lose almost 10% of battery in a day</strong>. But <em>Sentry mode</em> was not activated.</p>

<p>Either way, this unexpected setback was a huge inconvenience to our trip. Arriving at our first stop, we had to spend all of our time finding a Tesla charger before resuming our journey. Fortunately, one recharge was enough to get me back home without having to stop again.</p>

<p>As soon as I returned, I went to charge the car. This time I decided to charge it up to 82-83%. This happened on Saturday <strong>December 21, 2024</strong>.</p>

<h2 id="christmas-in-hell">Christmas in hell</h2>

<p>The next day, I was flying from Budapest (Hungary) to Porto (Portugal). It was a bumpy flight, and I ended up arriving in Porto on Monday morning. Upon arrival, I opened the Tesla app to see if the car was still losing battery at 4%. My surprise was huge when I checked the <strong>battery was at 69%</strong>. That is to say, the car was losing battery at a greater pace than expected, around <strong>8% daily</strong>!! A chill ran through my entire body.</p>

<p>I was going to spend approximately a week in Spain. On <strong>December 29</strong> I would take a plane from Vigo to London to spend New Year’s Eve there with my wife and some friends. Until <strong>January 2</strong> I would not be back in Slovakia. I did a quick calculation. With a battery loss of 8% per day <strong>the battery would end up being consumed</strong> between <strong>December 31</strong> and <strong>January 1</strong>. Once I had made this calculation, the first thing that crossed my mind was to <strong>cancel my trip to London</strong> and <strong>make a 3000 km trip</strong> to Slovakia <strong>to charge the car</strong>. It was an absolutely irrational thought. I was putting my life, well-being and relationships with family and friends before the needs of a car. I had bought a car so I could move around more freely. But now the car was conditioning me. My life and my plans revolved around an object. I didn’t have a car, I had a <strong>tamagotchi with wheels</strong>. I had to take care of it, I had to see if it had slept well, and above all, I had to check if it still had battery left.</p>

<p>Going back to my senses, I looked for a <strong>plan B</strong>. I called my wife, who was still in Slovakia, and told her the bad news. The idea was to somehow charge the car enough so that it wouldn’t die before returning. I knew it wasn’t going to be easy for her because she hadn’t driven in years. In addition, she didn’t have much time since she was taking a flight to London that same day. Even so, with the help of a friend, she managed to charge the car up to 98% before leaving.</p>

<p>I spent Christmas <strong>calling Tesla</strong> and trying to figure out <strong>why the car had started losing 8% battery daily</strong>. I remember that on Christmas Eve I managed to speak with Tesla Spain. When I asked whether it was normal for the car to lose 8% of battery daily, the agent on the other end of the line answered: <em>“I don’t know”</em>. I was stunned. Now I really didn’t understand anything. <em>“Was it within expectations that the car would lose 8% battery per day? But, who could live with a car like that?”</em>, I thought. In my phone call with Tesla Spain, I insisted that they speak to the <strong>Budapest Service Center</strong> so that they could get back me. I had notified them immediately when I saw the car was losing battery, but I still had not received a response. I also sent an email to <strong>DeliveryEMEA</strong> (my only contact when purchasing the vehicle), demanding either a replacement of the vehicle or a full refund of the amount, since the car was defective from the very first day I laid my hands on it and now there was this huge battery problem. I also tried to contact the <strong>Tesla Sales Department</strong>, without success.</p>

<p>The days I went through were not pleasant at all. My head was constantly spinning around the car. Every day since <strong>December 23</strong>, I started sending a screenshot to the <strong>Budapest Service Center</strong> showing how the car was losing 8% battery per day. I asked them directly, repeatedly, what was causing this problem. But I never received a response. They had deliberately decided to ignore me. To this day, and as I write these lines, I am still waiting for the Budapest Service Center to explain to me what the battery losses are due to. I continue sending screenshots daily.</p>

<p><img src="https://www.myteslaexperience.com/files/2025/02/daily-report-battery-drainage.jpg" alt="Informe diario pérdida de batería"></p>

<h2 id="epilogue">Epilogue</h2>

<p>When I returned to Slovakia, the first thing I did was to charge the car. Then, I called Tesla again. On the other end of the line, an agent told me the battery losses were due to previous problems already existing in the car. I insisted that the <strong>Budapest Service Center</strong> confirmed this diagnosis, but as I have explained previously <strong>they have never done so</strong>. I asked for solutions or mitigations to this situation. The only solution they gave me was to keep waiting for that miraculous replacement part. There are no contingency plans, no replacement vehicles, no compensation for these problems.</p>

<p>The lack of management and planning at Tesla left me greatly disappointed and in disbelief. A car that is known to be defective should be evaluated at a mechanic immediately. Making a customer to wait 3 months for a proper diagnosis or replacement part is unacceptable. Forcing thousands of customers to drive a dysfunctional car, which depends so much on technology, is not only unacceptable but also <strong>irresponsible</strong>. It poses a serious risk to your safety, that of your companions, passers-by and other drivers. Forcing someone to live with a car that loses 8% battery a day is like forcing someone to live tied to a chain. Even charging the car to 100%, the battery does not last more than 12 days. <strong>I can’t go on vacation for 2 weeks because otherwise this car would die</strong>.</p>

<p>During my conversation with the Tesla agent, I asked whether the <strong>Vienna Service Center</strong> could handle my case more quickly. The agent told me that he could not check the waiting times of the centers, and suggested me not to switch Service Centers as I would lose my turn. All Tesla’s customers have their hands tied, even though they do not know it yet. I have absolutely lost my trust in this company, and the worst of all is that I feel like a prisoner of it.</p>

<p>I came to the conclusion that, even if Tesla were able to fix the problems in my car, I would not like to live within their <strong>walled garden</strong>. I don’t want to plan my life around the ineptitude and inefficiency of a company, which also <strong>ignores me</strong> and in a banal way <strong>puts my life at risk</strong>. On <strong>January 5, 2025</strong> I called <strong>Tesla Netherlands Sales Department</strong> to request the return of the vehicle and a refund of my money. Nobody picked up the phone on the other end of the line. Finally, after several calls, I managed to talk to an agent from another department. I requested a refund of my money since the vehicle was delivered broken and now the battery problems were added. The agent was not sure whether I was entitled to a full refund since the car had more than 100 km. He was also not sure whether I could leave the car in Budapest or should I transport it back to Tilburg. He promised me that on Monday, <strong>January 6, 2025</strong>, someone from the Sales Department would contact me. We agreed on a time, between 4 and 6 PM. After almost a month, I’m still waiting for that call.</p>

<p>All of this can be summarized in a single sentence: <strong>The Head of the Department of Government Efficiency is the CEO of an disfunctional company</strong>.</p>

<p>Since the battery problems occurred I have stopped driving the vehicle. Even more so, after reading the <a href="https://www.motorpasion.com/tesla/abs-esp-limpiaparabrisas-tesla-nuevos-se-estan-quedando-ayudas-marca-dice-que-sus-coches-electricos-siguen-siendo-seguros">article by Daniel Murias for Motorpasión</a> (in Spanish). I consider it a risk to drive the car in this state. And I don’t think I should risk my life, or the lives of other people, to find out whether the car’s braking or suspension systems are working properly. This should be done by a mechanic, either at a garage or a Tesla Service Center. But this is Tesla, and it seems like <strong>no one is behind the wheel</strong>.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TL;DR of Deep Dive into LLMs Like ChatGPT by Andrej Karpathy (261 pts)]]></title>
            <link>https://anfalmushtaq.com/articles/deep-dive-into-llms-like-chatgpt-tldr</link>
            <guid>42997340</guid>
            <pubDate>Mon, 10 Feb 2025 05:56:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://anfalmushtaq.com/articles/deep-dive-into-llms-like-chatgpt-tldr">https://anfalmushtaq.com/articles/deep-dive-into-llms-like-chatgpt-tldr</a>, See on <a href="https://news.ycombinator.com/item?id=42997340">Hacker News</a></p>
Couldn't get https://anfalmushtaq.com/articles/deep-dive-into-llms-like-chatgpt-tldr: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[How does Ada's memory safety compare against Rust? (123 pts)]]></title>
            <link>https://ajxs.me/blog/How_Does_Adas_Memory_Safety_Compare_Against_Rust.html</link>
            <guid>42996831</guid>
            <pubDate>Mon, 10 Feb 2025 04:07:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ajxs.me/blog/How_Does_Adas_Memory_Safety_Compare_Against_Rust.html">https://ajxs.me/blog/How_Does_Adas_Memory_Safety_Compare_Against_Rust.html</a>, See on <a href="https://news.ycombinator.com/item?id=42996831">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>
	This article takes a look at the most common memory-related errors, 
	and compares how well Rust and Ada 
	<u><em>prevent</em> you from making them in the first place</u>.
</p>

<p><span>TL;DR:</span> 
	Rust is better at outright preventing common memory-related errors,
	however Ada's avoidance of dynamic memory allocation 
	and support for formal proof of correctness 
	help you avoid many of the common errors altogether.
</p>

<div>
	<p>Table of Contents</p>
	<ol>
		<li><a href="#foreword">Foreword</a></li>
		<li>
			<a href="#common_Memory_errors">Common Memory-Related Errors</a>
			<ol>
				<li><a href="#memory_leaks">Memory Leaks</a></li>
				<li><a href="#buffer_overflow">Buffer Overflow</a></li>
				<li><a href="#use_after_free">Use After Free</a></li>
				<li><a href="#double_free">Double Free</a></li>
				<li><a href="#race_conditions">Race Conditions</a></li>
				<li><a href="#dangling_pointer">Dangling Pointer</a></li>
				<li><a href="#freeing_stack_memory">Freeing Stack Memory</a></li>
			</ol>
		</li>
		<li><a href="#am_i_being_unfair">Am I Being Unfair to Ada?</a></li>
		<li><a href="#conclusions">Conclusions?</a></li>
	</ol>
</div>

<h2 id="foreword">Foreword <a href="#foreword">#</a></h2>

<p>
	The Rust programming language has 
	<a href="https://github.blog/developer-skills/programming-languages-and-frameworks/why-rust-is-the-most-admired-language-among-developers/" target="_blank">exploded in popularity</a>
	in the last few years,
	consistently ranking as one of the 
	<a href="https://stackoverflow.blog/2020/01/20/what-is-rust-and-why-is-it-so-popular/" target="_blank">most loved languages</a>
	in Stack Overflow's
	<a href="https://survey.stackoverflow.co/2024/technology#admired-and-desired" target="_blank">Developer Survey</a>.
	Designed by Mozilla to be <i>memory-safe</i>,
	it's steadily gaining ground as a viable alternative to languages like C++.
	This focus on safety has invited comparisons with Ada;
	An older, but battle-tested language designed for safety-critical industries.
	Despite all the things they have in common, 
	a bitter 
	<a href="https://www.reddit.com/r/rust/comments/pm4k1f/rust_vs_ada_how_do_they_compare/" target="_blank">rivalry</a>
	has grown between the Ada and Rust communities.
	For years I've been defending Ada online from a motley crew of 
	<a href="https://news.ycombinator.com/item?id=20935953" target="_blank">angry Rustaceans</a>,
	<a href="https://www.fulltextarchive.com/book/7625/#p203" target="_blank">crusty old greybeards</a>,
	and 
	<a href="https://news.ycombinator.com/item?id=20932467" target="_blank">bitter old haters</a>.
	Most of whom either haven't used it,
	or haven't used it since Reagan was in office.
	I've been critical of Rust's design in the past,
	but have I actually given Rust a fair go?
	When it comes to <em>memory safety</em>, 
	how do the two languages <em>really</em> stack up?
	Does Rust offer us anything new that Ada doesn't?
	Let's find out!
</p>

<p>
	This article assumes you're already familiar with the basics of Rust.
	If you're not, the best place to start is 
	<a href="https://www.rust-lang.org/learn" target="_blank">Learn Rust</a>,
	particularly the
	<a href="https://doc.rust-lang.org/book/" target="_blank">Rust Book</a>.
	For an introduction to Ada,
	check out AdaCore's
	<a href="https://learn.adacore.com/courses/intro-to-ada/" target="_blank">Introduction to Ada</a>.
</p>

<p>
	Before we begin,
	it's worth noting that
	<u><em>you can do a lot in Ada without ever allocating heap memory</em></u>,
	or even using pointers at all.
	In fact, most guides on Ada programming recommend avoiding pointers altogether.
	Language constructs such as in/out parameter modes, 
	creating dynamically sized arrays at runtime,
	and the ability to return variable length arrays from functions 
	address many of the scenarios where pointers would be necessary in other languages.
	Keep this in mind when reading:
	<u><em>You can avoid many of these situations altogether in Ada</em></u>.
</p>

<p>
	All the examples in this article are tested on an x86-64 machine running Debian 12,
	with glibc 2.36;
	Compiled with GCC 12.2.0,
	GNAT native 14.2.1,
	and rustc 1.80.1.
</p>

<h2 id="common_Memory_errors">Common Memory Errors <a href="#common_Memory_errors">#</a></h2>

<h3 id="memory_leaks">Memory Leaks <a href="#memory_leaks">#</a></h3>
<p>
	<a href="https://cwe.mitre.org/data/definitions/401.html" target="_blank"><i>CWE-401: Memory Leak</i></a>
	refers to a program failing to release the memory that it's allocated.
	Left unchecked, a leaky program could drain all your system's memory.
	The most common cause of 
	<a href="https://devblogs.microsoft.com/oldnewthing/20180228-00/?p=98125" target="_blank">memory leaks</a> 
	in C is mismatched <code>malloc()</code>, and <code>free()</code> statements.
</p>

<p>
	While not impossible<sup><a href="#footnote_1" id="footnote_1_link">1</a></sup>, 
	Rust does actually make leaking memory pretty difficult.
	Variables in Rust are automatically deallocated when their <i>owner</i> goes out of scope.
	Most of the time this means a variable will be deallocated at the end of the scope it's declared in.
</p>
<p>
	For
	<a href="https://en.wikipedia.org/wiki/Reference_counting" target="_blank"><i>reference counted</i></a>
	smart pointers, like <code>Rc&lt;T&gt;</code> and <code>Arc&lt;T&gt;</code>,
	Rust will automatically deallocate the memory they point to when the reference count reaches zero. 
</p>

<p>
	In Ada, pointers are called <i>Access Types</i>.
	Like in C, they <i>point</i> at a memory location;
	However <em>unlike</em> C, they're <em>not</em> an address.
	This means you can't assign an address to an access variable, 
	or perform arithmetic on it.
</p>

<p>
	In Ada, dynamically allocated memory needs to be deallocated <em>manually</em> with the generic
	<code>Ada.Unchecked_Deallocation</code> procedure.
	With <i>unchecked</i> 
	referring to checking whether the variable being deallocated is still in use.
</p>
<p>
	While Ada's 
	<a href="https://learn.adacore.com/courses/advanced-ada/parts/resource_management/controlled_types.html" target="_blank"><i>controlled types</i></a>
	do support implementing RAII-like functionality,
	under normal circumstances forgetting to manually deallocate heap memory will cause it to leak.
</p>
<p> 
	The only scenario where Ada <em>will</em> automatically<sup><a href="#footnote_2" id="footnote_2_link">2</a></sup> 
	deallocate memory is when the user specifies a static size for an access type's <i>storage pool</i>
	using the <code>Storage_Size</code> aspect.
	This controls exactly how many bytes of heap memory can be allocated for variables of a particular type.
	If this is specified, the compiler automatically allocates all the required memory up front<sup><a href="#footnote_3" id="footnote_3_link">3</a></sup>,
	and automatically <em>deallocates</em> it when the type goes out of scope.
	If this pool is exhausted, the program will raise a <code>Storage_Error</code> exception.
</p>

<div><pre><span></span><span>procedure</span> <span>Access_Type_With_Explicit_Pool_Size</span> <span>is</span>
   <span>--  This sets aside a total of 128 bytes for the pool of Int_Access.</span>
   <span>--  Allocating more than 128 bytes will raise a Storage_Error exception.</span>
   <span>type</span> <span>Int_Access</span> <span>is</span> <span>access</span> <span>Integer</span>
   <span>with</span> <span>Storage_Size</span> <span>=&gt;</span> <span>128</span><span>;</span>
<span>begin</span>
   <span>for</span> <span>I</span> <span>in</span> <span>1</span> <span>..</span> <span>16</span> <span>loop</span>
      <span>declare</span>
         <span>Q</span> <span>:</span> <span>constant</span> <span>Int_Access</span> <span>:=</span> <span>new</span> <span>Integer</span><span>'(</span><span>I</span><span>);</span>
      <span>begin</span>
         <span>Put_Line</span> <span>(</span><span>Q</span><span>.</span><span>all</span><span>'</span><span>Image</span><span>);</span>
      <span>end</span><span>;</span>
   <span>end</span> <span>loop</span><span>;</span>
<span>end</span> <span>Access_Type_With_Explicit_Pool_Size</span><span>;</span>
</pre></div>
<p>
	Running Valgrind on the example above shows that the memory is indeed deallocated automatically.
</p>

<h3 id="buffer_overflow">Buffer Overflow <a href="#buffer_overflow">#</a></h3>
<p>
	<a href="https://cwe.mitre.org/data/definitions/119.html" target="_blank"><i>CWE-119: Buffer Overflow</i></a>
	refers to reading or writing past the end of an array, 
	and into adjacent memory.
	Buffer overflows are probably responsible for more 
	<a href="https://github.com/johnjhacking/Buffer-Overflow-Guide" target="_blank">security vulnerabilities</a>
	than any other kind of bug,
	and are a common technique for 
	<a href="https://cturt.github.io/ps4.html" target="_blank">jailbreaking</a>
	<a href="https://github.com/singi/oob_timestamp" target="_blank">hardware</a>.
	The infamous
	<a href="https://en.wikipedia.org/wiki/Morris_worm" target="_blank">Morris Worm</a>,
	and <a href="https://en.wikipedia.org/wiki/Heartbleed" target="_blank">Heartbleed</a>
	vulnerabilities both relied on buffer overflows.
</p>
<div><pre><span></span><span>void</span><span> </span><span>buffer_overflow</span><span>()</span><span> </span><span>{</span>
<span>  </span><span>char</span><span> </span><span>email_address</span><span>[</span><span>10</span><span>];</span>

<span>  </span><span>printf</span><span>(</span><span>"Please enter your email address:</span><span>\n</span><span>"</span><span>);</span>
<span>  </span><span>// Modern versions of GCC will spew a litany of warnings about using 'gets'.</span>
<span>  </span><span>gets</span><span>(</span><span>email_address</span><span>);</span>
<span>  </span><span>printf</span><span>(</span><span>"Sending welcome email to %s</span><span>\n</span><span>"</span><span>,</span><span> </span><span>email_address</span><span>);</span>
<span>}</span>

<span>// $ gcc -o buffer_overflow buffer_overflow.c</span>
<span>// $ ./buffer_overflow</span>
<span>// $ Please enter your email address:</span>
<span>// $ anthony@this_will_overwrite_the_function's_return_address_on_the_stack.com</span>
<span>// $ Segmentation fault</span>
</pre></div>
<p>
	One of the few things that Rust and Ada agree on is
	<a href="https://shnatsel.medium.com/how-to-avoid-bounds-checks-in-rust-without-unsafe-f65e618b4c1e" target="_blank">runtime bounds checking</a>.
	Attempting to access an out-of-bounds array index will result in a 'panic'.
</p>
<div><pre><span></span><span>fn</span><span> </span><span>overflow_this_buffer</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>buffer</span><span> </span><span>=</span><span> </span><span>[</span><span>0</span><span>;</span><span> </span><span>10</span><span>];</span>

<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>raw_input</span><span> </span><span>=</span><span> </span><span>String</span><span>::</span><span>new</span><span>();</span>
<span>    </span><span>println!</span><span>(</span><span>"What array index should be cleared? "</span><span>);</span>
<span>    </span><span>io</span><span>::</span><span>stdin</span><span>()</span>
<span>        </span><span>.</span><span>read_line</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>raw_input</span><span>)</span>
<span>        </span><span>.</span><span>expect</span><span>(</span><span>"Failed to read line"</span><span>);</span>
<span>    </span><span>let</span><span> </span><span>index</span><span>:</span><span> </span><span>usize</span><span> </span><span>=</span><span> </span><span>raw_input</span>
<span>        </span><span>.</span><span>trim</span><span>()</span>
<span>        </span><span>.</span><span>parse</span><span>()</span>
<span>        </span><span>.</span><span>expect</span><span>(</span><span>"Please enter a valid integer"</span><span>);</span>

<span>    </span><span>buffer</span><span>[</span><span>index</span><span>]</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>
<span>}</span>

<span>// $ cargo run</span>
<span>// $ What array index should be cleared?</span>
<span>// $ 12</span>
<span>// $ thread 'main' panicked at buffer_overflow.rs:14:5:</span>
<span>// $ index out of bounds: the len is 10 but the index is 12</span>
<span>// $ note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace</span>
<span>// $ ...</span>
</pre></div>

<p>
	Similar to Rust, 
	attempting to access an array index outside of its valid range will raise a
	<code>Constraint_Error</code> exception at runtime,
	which can be handled programmatically.
	This is the same type of exception raised in the case of a scalar range constraint violation,
	such as an integer overflow.
</p>
<div><pre><span></span><span>procedure</span> <span>Buffer_Overflow</span> <span>is</span>
   <span>Email_Address</span> <span>:</span> <span>String</span> <span>(</span><span>1</span> <span>..</span> <span>10</span><span>);</span>
<span>begin</span>
   <span>Put_Line</span> <span>(</span><span>"Please enter your email address:"</span><span>);</span>
   <span>Email_Address</span> <span>:=</span> <span>Get_Line</span><span>;</span>
   <span>Put_Line</span> <span>(</span><span>"Sending welcome email to "</span> <span>&amp;</span> <span>Email_Address</span><span>);</span>
<span>exception</span>
   <span>when</span> <span>Constraint_Error</span> <span>=&gt;</span>
      <span>Put_Line</span> <span>(</span><span>"Buffer overflowed!"</span><span>);</span>
<span>end</span> <span>Buffer_Overflow</span><span>;</span>

<span>--  $ alr run</span>
<span>--  $ Please enter your email address:</span>
<span>--  $ anthony@this_will_overflow_the_buffer.com</span>
<span>--  $ Buffer overflowed!</span>
</pre></div>

<h4>SPARK</h4>
<p>
	SPARK is a subset of Ada which can be 
	<a href="https://en.wikipedia.org/wiki/Formal_verification" target="_blank">formally verified</a>.
	Meaning that it's possible to verify the absence of runtime errors in your code using formal methods.
</p>

<p>
	All SPARK code is valid Ada,
	but to determine whether the Ada code is valid SPARK I'm using
	<a href="https://docs.adacore.com/hilite-docs/html/ug/usage.html" target="_blank"><i>GNATprove</i></a>.
	GNATprove is a component of AdaCore's <i>GNAT</i> 
	Ada compiler used to formally verify the correctness of SPARK code.
	If you're using <i><a href="https://alire.ada.dev/" target="_blank">Alire</a></i>,
	you can add GNATprove to your project by running <code>alr with gnatprove</code>.
</p>

<p>
	Let's see if we can reimplement the previous Rust example in SPARK,
	and prove that a buffer overflow can't occur.
</p>
<div><pre><span></span><span>procedure</span> <span>Overflow_This_Buffer</span>
   <span>with</span> <span>SPARK_Mode</span> <span>=&gt;</span> <span>On</span>
<span>is</span>
   <span>type</span> <span>Integer_Array</span> <span>is</span> <span>array</span> <span>(</span><span>Positive</span> <span>range</span> <span>&lt;&gt;)</span> <span>of</span> <span>Integer</span><span>;</span>
   <span>Int_Array</span> <span>:</span> <span>Integer_Array</span> <span>(</span><span>1</span> <span>..</span> <span>10</span><span>)</span> <span>:=</span> <span>[</span><span>others</span> <span>=&gt;</span> <span>1</span><span>];</span>
   <span>Index_To_Clear</span> <span>:</span> <span>Integer</span><span>;</span>
<span>begin</span>
   <span>Ada</span><span>.</span><span>Text_IO</span><span>.</span><span>Put</span> <span>(</span><span>"What array index should be cleared? "</span><span>);</span>
   <span>--  Read the new array size from stdin.</span>
   <span>Ada</span><span>.</span><span>Integer_Text_IO</span><span>.</span><span>Get</span> <span>(</span><span>Index_To_Clear</span><span>);</span>

   <span>Int_Array</span> <span>(</span><span>Index_To_Clear</span><span>)</span> <span>:=</span> <span>0</span><span>;</span>
<span>end</span> <span>Overflow_This_Buffer</span><span>;</span>
</pre></div>
<p>
	Attempting to prove the absence of runtime errors gives us the following warnings:
</p>

<div><pre><span></span>buffer_overflow.adb:162:26: medium: unexpected exception might be raised
  162 |      Ada.Integer_Text_IO.Get (Index_To_Clear);
      |      ~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~

buffer_overflow.adb:164:18: medium: array index check might fail
  164 |      Int_Array (Index_To_Clear) := 0;
      |                 ^~~~~~~~~~~~~~
  reason for check: value must be a valid index into the array
  possible fix: postcondition of call at line 162 should mention Item 
  (for argument Index_To_Clear)
  162 |      Ada.Integer_Text_IO.Get (Index_To_Clear);
      |                         ^ here
</pre></div>
<p>
	The SPARK prover correctly notices that there's nothing stopping us
	from entering a value outside the array bounds. 
	It also points out that the <code>Get</code> 
	call we're using to read the integer from <code>stdin</code>
	can raise an <i>unexpected</i> <code>Constraint_Error</code>
	at runtime if you type in anything that can't be parsed as an integer.
	To keep this example simple, we'll ignore this warning and push on.
	We'll talk more about exceptions in SPARK 
	<a href="#use_after_free">later</a>
	in the article.
</p>
<p>
	If we wrap the <code>Get</code> call in a loop, 
	and <i>poll</i> the user continuously until we have a value within the array bounds,
	SPARK can actually prove that a buffer overflow can't occur.
	(Remember to initialise the <code>Index_To_Clear</code> 
	variable to something outside this range!)
</p>

<div><pre><span></span><span>procedure</span> <span>Overflow_This_Buffer</span>
   <span>with</span> <span>SPARK_Mode</span> <span>=&gt;</span> <span>On</span>
<span>is</span>
   <span>type</span> <span>Integer_Array</span> <span>is</span> <span>array</span> <span>(</span><span>Positive</span> <span>range</span> <span>&lt;&gt;)</span> <span>of</span> <span>Integer</span><span>;</span>
   <span>Int_Array</span> <span>:</span> <span>Integer_Array</span> <span>(</span><span>1</span> <span>..</span> <span>10</span><span>)</span> <span>:=</span> <span>[</span><span>others</span> <span>=&gt;</span> <span>1</span><span>];</span>
   <span>Index_To_Clear</span> <span>:</span> <span>Integer</span> <span>:=</span> <span>Int_Array</span><span>'</span><span>First</span> <span>-</span> <span>1</span><span>;</span>
<span>begin</span>
   <span>while</span> <span>Index_To_Clear</span> <span>not</span> <span>in</span> <span>Int_Array</span><span>'</span><span>Range</span> <span>loop</span>
      <span>Ada</span><span>.</span><span>Text_IO</span><span>.</span><span>Put</span> <span>(</span><span>"What array index should be cleared? "</span><span>);</span>
      <span>--  Read the new array size from stdin.</span>
      <span>Ada</span><span>.</span><span>Integer_Text_IO</span><span>.</span><span>Get</span> <span>(</span><span>Index_To_Clear</span><span>);</span>
   <span>end</span> <span>loop</span><span>;</span>

   <span>Int_Array</span> <span>(</span><span>Index_To_Clear</span><span>)</span> <span>:=</span> <span>0</span><span>;</span>
<span>end</span> <span>Overflow_This_Buffer</span><span>;</span>
</pre></div>

<h3 id="use_after_free">Use After Free <a href="#use_after_free">#</a></h3>

<p>
	<a href="https://cwe.mitre.org/data/definitions/416.html" target="_blank"><i>CWE-416: Use After Free</i></a>
	refers to 
	<a href="https://stackoverflow.com/a/14224977/5931673" target="_blank"><i>dereferencing</i></a>
	a pointer after the value it points to has been freed.
	The C standard specifies that doing so is 
	<a href="https://en.wikipedia.org/wiki/Undefined_behavior" target="_blank"><i>Undefined Behaviour</i></a>
	(ISO/IEC 9899:2018, Section J.2), 
	potentially leading to a variety of different stability and 
	<a href="https://www.youtube.com/watch?v=PKqMsaKGdlM" target="_blank">security issues</a>. 
	(ISO/IEC 9899:2018, Section 3.4.3).
</p>
<p>
	Most of the time this just results in unpredictable behaviour because the pointer 
	now points to memory reallocated to something else.
	But occasionally <i>use-after-free's</i>
	can be leveraged for <a href="https://en.wikipedia.org/wiki/BlueKeep" target="_blank">something more sinister</a>.
</p>
<p>
	Rust's borrow checker automatically prevents you from using a value after it's been freed.
	Calling <code>drop</code> to manually free a variable <i>moves</i> it,
	meaning that any attempt to use it afterwards will raise a compile-time error.
</p>

<div><pre><span></span><span>fn</span><span> </span><span>use_after_free</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>greeting</span><span> </span><span>=</span><span> </span><span>"Hello, World!"</span><span>.</span><span>to_string</span><span>();</span>
<span>    </span><span>drop</span><span>(</span><span>greeting</span><span>);</span>
<span>    </span><span>// This will trigger an error at compile-time, because the variable</span>
<span>    </span><span>// `something` was moved by the first call to `std::mem::drop`.</span>
<span>    </span><span>println!</span><span>(</span><span>"{}"</span><span>,</span><span> </span><span>greeting</span><span>);</span>
<span>}</span>
</pre></div>

<p>
	Nothing prevents you from writing Ada code that dereferences an access type after it's been freed;
	However any access dereference triggers a runtime check to ensure it's non-null.
	Unlike in C,
	freeing an access type in Ada automatically sets its value to <code>null</code>,
	and any subsequent attempt to dereference it will raise a 
	<code>Constraint_Error</code> exception,
	which can be caught and handled.
</p>

<div><pre><span></span><span>procedure</span> <span>Use_After_Free</span> <span>is</span>
   <span>type</span> <span>String_Access</span> <span>is</span> <span>access</span> <span>String</span><span>;</span>
   <span>Example_String</span> <span>:</span> <span>String_Access</span> <span>:=</span> <span>null</span><span>;</span>

   <span>--  The Ada.Unchecked_Deallocation package is a generic package, and</span>
   <span>--  needs to be instantiated for each type to be deallocated.</span>
   <span>procedure</span> <span>Free</span> <span>is</span> <span>new</span>
     <span>Ada</span><span>.</span><span>Unchecked_Deallocation</span> <span>(</span><span>String</span><span>,</span> <span>String_Access</span><span>);</span>
<span>begin</span>
   <span>Example_String</span> <span>:=</span> <span>new</span> <span>String</span><span>'(</span><span>"Hello, world!"</span><span>);</span>
   <span>Free</span> <span>(</span><span>Example_String</span><span>);</span>

   <span>--  This will raise a Constraint_Error exception at runtime.</span>
   <span>Put_Line</span> <span>(</span><span>Example_String</span><span>.</span><span>all</span><span>);</span>
<span>exception</span>
   <span>when</span> <span>Constraint_Error</span> <span>=&gt;</span>
      <span>Put_Line</span> <span>(</span><span>"Used after freed!"</span><span>);</span>
<span>end</span> <span>Use_After_Free</span><span>;</span>
</pre></div>

<p>
	The GNAT Ada compiler allows you to 
	<a href="https://docs.adacore.com/gnat_ugn-docs/html/gnat_ugn/gnat_ugn/building_executable_programs_with_gnat.html#run-time-checks" target="_blank">
		disable runtime checking</a>
	with the <code>-gnatp</code> compiler switch.
	In this case, dereferencing a null access type will result in the same kind of undefined behaviour you'd get in C.
</p>

<p>
	Ada allows you to specify a <i>null-excluding</i> constraint on access types,
	This restricts assignment to only non-null values,
	and forbids any unchecked deallocation.
</p>

<div><pre><span></span><span>type</span> <span>Non_Null_String_Access</span> <span>is</span> <span>not</span> <span>null</span> <span>access</span> <span>String</span><span>;</span>
<span>--  Since this is a 'null-excluding' access type, it must be initialised,</span>
<span>--  otherwise a Constraint_Error exception will occur immediately at runtime.</span>
<span>Example_String</span> <span>:</span> <span>Non_Null_String_Access</span> <span>:=</span> <span>new</span> <span>String</span><span>'(</span><span>"Hello, world!"</span><span>);</span>
<span>--  This will raise a compile-time error. The compiler won't let us</span>
<span>--  create an instance of Ada.Unchecked_Deallocation for a</span>
<span>--  null-excluding access type.</span>
<span>procedure</span> <span>Free</span> <span>is</span>
  <span>new</span> <span>Ada</span><span>.</span><span>Unchecked_Deallocation</span> <span>(</span><span>String</span><span>,</span> <span>Non_Null_String_Access</span><span>);</span>
</pre></div>

<h4>SPARK</h4>
<p>
	GNATprove will detect the use-after-free error in the above code,
	and issue a warning<sup><a href="#footnote_4" id="footnote_4_link">4</a></sup>:
</p>

<div><pre><span></span><span>procedure</span> <span>Use_After_Free</span>
   <span>with</span> <span>SPARK_Mode</span> <span>=&gt;</span> <span>On</span>
<span>is</span>
   <span>type</span> <span>String_Access</span> <span>is</span> <span>access</span> <span>String</span><span>;</span>
   <span>Example_String</span> <span>:</span> <span>String_Access</span><span>;</span>

   <span>procedure</span> <span>Free</span> <span>is</span> <span>new</span> <span>Ada</span><span>.</span><span>Unchecked_Deallocation</span> <span>(</span><span>String</span><span>,</span> <span>String_Access</span><span>);</span>
<span>begin</span>
   <span>Example_String</span> <span>:=</span> <span>new</span> <span>String</span><span>'(</span><span>"Hello, world!"</span><span>);</span>
   <span>Free</span> <span>(</span><span>Example_String</span><span>);</span>

   <span>--  This line will raise a warning during static analysis.</span>
   <span>Put_Line</span> <span>(</span><span>Example_String</span><span>.</span><span>all</span><span>);</span>
<span>end</span> <span>Use_After_Free</span><span>;</span>
</pre></div>
<div><pre><span></span>use_after_free.adb:13:32: medium: pointer dereference check might fail
  13  |      Put_Line (Example_String.all);
      |                ~~~~~~~~~~~~~~~^~~
</pre></div>

<p>
	Note the removal of the exception handling block.
	SPARK <em>does</em> technically allow run-time exception handling, 
	but only exceptions that are <em>explicitly</em> raised in the code.
	Exceptions in SPARK are
	<a href="https://docs.adacore.com/spark2014-docs/html/lrm/exceptions.html" target="_blank">complicated</a>:
	You <em>can</em> still explicitly raise exceptions with the <code>raise</code> statement,
	but to be valid SPARK, the flow analyser will need to prove that the statement raising the exception can never actually be reached;
	Making exceptions almost like a form of compile-time assertion.
	This means that our <code>Constraint_Error</code> exception handler is unreachable,
	and needs to be removed.
</p>

<h3 id="double_free">Double Free <a href="#double_free">#</a></h3>
<p>
	<a href="https://cwe.mitre.org/data/definitions/415.html" target="_blank"><i>CWE-415: Double Free</i></a>
	refers to freeing a heap allocated variable more than once.
	The C standard (as usual) specifies that doing so is <i>Undefined Behaviour</i> (ISO/IEC 9899:2018, Section J.2).
	Double frees can be exploited in
	<a href="https://book.hacktricks.xyz/binary-exploitation/libc-heap/double-free" target="_blank">various</a>
	<a href="https://heap-exploitation.dhavalkapil.com/attacks/double_free" target="_blank">ways</a>
	to cause all kinds of nonsense.
</p>
<p>
	On Linux,
	<a href="https://sourceware.org/glibc/wiki/MallocInternals" target="_blank">glibc</a>
	stores extra <i>metadata</i> about each allocated memory block right before the block's address,
	such as its size, and a <i>magic number</i> to identify it as a valid allocation.
	When you pass an address to <code>free</code>, 
	glibc uses this metadata to determine the amount of memory being freed.
	Freeing a small block of heap memory can place it in a <i>cache</i> of recently freed blocks,
	known as a <i>fast bin</i>.
	The next time you call <code>malloc</code> for a block of the same size,
	glibc will give you the recently deallocated block from the fast bin,
	rather than allocating new memory.
	This process is much quicker than allocating a new block, hence the <em>fast</em> in the name.
	Freeing the same address twice runs the risk of the same block being placed in the fast bin 
	<em>multiple times</em>.
	This could lead to multiple subsequent memory allocations pointing to the same address.
</p>
<p>
	<a href="https://azeria-labs.com/heap-exploitation-part-1-understanding-the-glibc-heap-implementation/" target="_blank">This</a>
	article contains a great in-depth look at glibc's heap implementation.
</p>
<p>
	Rust's borrow checker effectively prevents you from freeing the same variable more than once.
	As mentioned <a href="#use_after_free">earlier</a>,
	calling <code>drop</code> to free a variable will <i>move</i> it out of scope forever.
</p>
<div><pre><span></span><span>fn</span><span> </span><span>double_free</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>something</span><span> </span><span>=</span><span> </span><span>"Hello, World!"</span><span>.</span><span>to_string</span><span>();</span>
<span>    </span><span>drop</span><span>(</span><span>something</span><span>);</span>
<span>    </span><span>// This will trigger an error at compile-time, because the variable</span>
<span>    </span><span>// `something` was moved by the first call to `std::mem::drop`.</span>
<span>    </span><span>drop</span><span>(</span><span>something</span><span>);</span>
<span>}</span>
</pre></div>
<p>
	According to
	<a href="https://www.adaic.org/resources/add_content/standards/05rm/html/RM-13-11-2.html" target="_blank">section 13.11.2</a>
	of the Ada Reference Manual, 
	freeing an access type with a <code>null</code> value has no effect,
	just like in C (ISO/IEC 9899:2018, Section 7.22.3.3).
	That's a relief!
	As mentioned earlier, freeing a pointer in Ada will automatically set its value to <code>null</code>,
	preventing most accidental double free errors from causing any serious issues.
</p>
<p>
	It's still possible to cause a double free in Ada by creating an alias to a pointer.
</p>
<div><pre><span></span><span>procedure</span> <span>Double_Free</span> <span>is</span>
   <span>type</span> <span>String_Access</span> <span>is</span> <span>access</span> <span>String</span><span>;</span>

   <span>Str_Acc</span>       <span>:</span> <span>String_Access</span><span>;</span>
   <span>Str_Acc_Alias</span> <span>:</span> <span>String_Access</span><span>;</span>

   <span>procedure</span> <span>Free</span> <span>is</span> <span>new</span> <span>Ada</span><span>.</span><span>Unchecked_Deallocation</span> <span>(</span><span>String</span><span>,</span> <span>String_Access</span><span>);</span>
<span>begin</span>
   <span>Str_Acc</span> <span>:=</span> <span>new</span> <span>String</span><span>'(</span><span>"Hello, world!"</span><span>);</span>
   <span>Put_Line</span> <span>(</span><span>"Pointer Address: "</span> <span>&amp;</span> <span>Str_Acc</span><span>.</span><span>all</span><span>'</span><span>Address</span><span>'</span><span>Image</span><span>);</span>

   <span>Str_Acc_Alias</span> <span>:=</span> <span>Str_Acc</span><span>;</span>

   <span>Free</span> <span>(</span><span>Str_Acc</span><span>);</span>

   <span>Put_Line</span> <span>(</span><span>"Pointer Alias Address: "</span> <span>&amp;</span> <span>Str_Acc_Alias</span><span>.</span><span>all</span><span>'</span><span>Address</span><span>'</span><span>Image</span><span>);</span>
   <span>Free</span> <span>(</span><span>Str_Acc_Alias</span><span>);</span>
<span>exception</span>
   <span>when</span> <span>Program_Error</span> <span>=&gt;</span>
      <span>Put_Line</span> <span>(</span><span>"Program Error!"</span><span>);</span>
<span>end</span> <span>Double_Free</span><span>;</span>

<span>--  $ alr run</span>
<span>--  $ Pointer Address:  25715368</span>
<span>--  $ Pointer Alias Address:  25715368</span>
<span>--  $ free(): double free detected in tcache 2</span>
<span>--  $ Program Error!</span>
</pre></div>
<p>
	As you can see in the example above,
	actually freeing the same memory location twice<sup><a href="#footnote_5" id="footnote_5_link">5</a></sup> will raise a 
	<code>Program_Error</code> exception at runtime.
	The below example shows how you can corrupt the heap by double freeing a pointer in Ada.
	Again, Ada will raise a <code>Program_Error</code> exception when it gets the error signal from glibc,
	which can be handled at runtime.
</p>

<div><pre><span></span><span>procedure</span> <span>Double_Free</span> <span>is</span>
   <span>type</span> <span>String_Access</span> <span>is</span> <span>access</span> <span>String</span><span>;</span>
   <span>type</span> <span>String_Access_Array</span> <span>is</span> <span>array</span> <span>(</span><span>1</span> <span>..</span> <span>16</span><span>)</span> <span>of</span> <span>String_Access</span><span>;</span>

   <span>procedure</span> <span>Free</span> <span>is</span> <span>new</span> <span>Ada</span><span>.</span><span>Unchecked_Deallocation</span> <span>(</span><span>String</span><span>,</span> <span>String_Access</span><span>);</span>

   <span>Str_Acc_Array</span>   <span>:</span> <span>String_Access_Array</span><span>;</span>
   <span>Str_Acc_Array_2</span> <span>:</span> <span>String_Access_Array</span><span>;</span>

   <span>--  Create a pointer to alias one of the elements in the array.</span>
   <span>Str_Acc_Alias</span> <span>:</span> <span>String_Access</span><span>;</span>
<span>begin</span>
   <span>for</span> <span>I</span> <span>in</span> <span>Str_Acc_Array</span><span>'</span><span>Range</span> <span>loop</span>
      <span>Str_Acc_Array</span> <span>(</span><span>I</span><span>)</span> <span>:=</span> <span>new</span> <span>String</span><span>'(</span><span>"Hello, world!"</span><span>);</span>
   <span>end</span> <span>loop</span><span>;</span>

   <span>Str_Acc_Alias</span> <span>:=</span> <span>Str_Acc_Array</span> <span>(</span><span>8</span><span>);</span>

   <span>for</span> <span>I</span> <span>in</span> <span>Str_Acc_Array</span><span>'</span><span>Range</span> <span>loop</span>
      <span>Free</span> <span>(</span><span>Str_Acc_Array</span> <span>(</span><span>I</span><span>));</span>
   <span>end</span> <span>loop</span><span>;</span>

   <span>--  Freeing the alias will add the same address to the fast bin twice,</span>
   <span>--  leading to a double free error.</span>
   <span>Free</span> <span>(</span><span>Str_Acc_Alias</span><span>);</span>

   <span>for</span> <span>I</span> <span>in</span> <span>Str_Acc_Array_2</span><span>'</span><span>Range</span> <span>loop</span>
      <span>Str_Acc_Array_2</span> <span>(</span><span>I</span><span>)</span> <span>:=</span> <span>new</span> <span>String</span><span>'(</span><span>"Hello, again!"</span><span>);</span>
   <span>end</span> <span>loop</span><span>;</span>

<span>exception</span>
   <span>when</span> <span>Program_Error</span> <span>=&gt;</span>
      <span>Put_Line</span> <span>(</span><span>"Program Error!"</span><span>);</span>
<span>end</span> <span>Double_Free</span><span>;</span>

<span>--  $ alr run</span>
<span>--  $ malloc(): unaligned fastbin chunk detected 3</span>
<span>--  $ Program Error!</span>
</pre></div>

<h4>SPARK</h4>
<p>
	Like Rust, SPARK has its own concept of 
	<a href="https://docs.adacore.com/spark2014-docs/html/ug/en/source/language_restrictions.html#memory-ownership-policy" target="_blank"><i>'ownership'</i></a>.
	Assignment between access objects creates a transfer of ownership, 
	with the source object losing permission to read or write to the underlying allocated memory.
</p>
<p>
	In this case, aliasing the string pointers in the examples above is not valid SPARK,
	preventing us from causing this particular double free error.
</p>
<div><pre><span></span>alr gnatprove
Phase 1 of 3: generation of data representation information ...
Phase 2 of 3: generation of Global contracts ...
Phase 3 of 3: flow analysis and proof ...

double_free.adb:14:13: error: "Str_Acc" is not readable
   14 |      Free (Str_Acc);
      |            ^~~~~~~
  object was moved at line 12 [E0010]
   12 |      Str_Acc_Alias := Str_Acc;
      |                       ^ here
  launch "gnatprove --explain=E0010" for more information
</pre></div>
<p>
	SPARK doesn't allow you to use <code>Unchecked_Deallocation</code>
	with a <em>general</em> access type (which we'll discuss in more detail <a href="#freeing_stack_memory">later</a>),
	so we can't try to sidestep SPARK's ownership system by doing something tricky like this:
</p>

<div><pre><span></span><span>procedure</span> <span>Double_Free</span>
   <span>with</span> <span>SPARK_Mode</span> <span>=&gt;</span> <span>On</span>
<span>is</span>
   <span>type</span> <span>String_Access</span> <span>is</span> <span>access</span> <span>all</span> <span>String</span><span>;</span>

   <span>Str_Acc</span>       <span>:</span> <span>String_Access</span><span>;</span>
   <span>Str_Acc_Alias</span> <span>:</span> <span>String_Access</span><span>;</span>

   <span>procedure</span> <span>Free</span> <span>is</span> <span>new</span> <span>Ada</span><span>.</span><span>Unchecked_Deallocation</span> <span>(</span><span>String</span><span>,</span> <span>String_Access</span><span>);</span>
<span>begin</span>
   <span>Str_Acc</span> <span>:=</span> <span>new</span> <span>String</span><span>'(</span><span>"Hello, world!"</span><span>);</span>
   <span>Put_Line</span> <span>(</span><span>Str_Acc</span><span>.</span><span>all</span><span>);</span>

   <span>--  Here we create an access to the dereferenced value of Str_Acc.</span>
   <span>Str_Acc_Alias</span> <span>:=</span> <span>Str_Acc</span><span>.</span><span>all</span><span>'</span><span>Access</span><span>;</span>

   <span>Free</span> <span>(</span><span>Str_Acc</span><span>);</span>

   <span>Free</span> <span>(</span><span>Str_Acc_Alias</span><span>);</span>
<span>end</span> <span>Double_Free</span><span>;</span>
</pre></div>

<p>
	SPARK sees what we're up to and stops us in our tracks:
</p>

<div><pre><span></span>double_free.adb:13:17: error: instance of Unchecked_Deallocation with a 
  general access type is not allowed in SPARK
   13 |      procedure Free is new Ada.Unchecked_Deallocation (String, String_Access);
      |                ^~~~
  violation of aspect SPARK_Mode at line 6
    6 |     with SPARK_Mode =&gt; On
      |          ^ here
</pre></div>

<h3 id="race_conditions">Race Conditions <a href="#race_conditions">#</a></h3>
<p>
	In a multi-threaded program, 
	a <i>Race condition</i> is a situation where the outcome of the program depends on the order in which the threads execute.
	Because an operating system can switch between threads at any time in any order,
	it's impossible to guarantee when threads will access shared resources.
	This really becomes a problem when two threads try to write to the same memory at the same time;
	Leading to some of the most 
	<a href="https://en.wikipedia.org/wiki/Meltdown_(security_vulnerability)" target="_blank">infuriating</a>, 
	<a href="https://en.wikipedia.org/wiki/Northeast_blackout_of_2003" target="_blank">time-consuming</a>, 
	and 
	<a href="https://en.wikipedia.org/wiki/Therac-25" target="_blank">hair-raising</a>
	bugs in software development.
</p>
<p>
	One common race condition is a
	<a href="https://en.wikipedia.org/wiki/Time-of-check_to_time-of-use" target="_blank"><i>Time-of-check to time-of-use</i></a>
	error, or <i>TOC/TOU</i>;
	In which a resource changes between the time it's checked for validity, and the time it's used.
	Maybe one thread checks to see if a file already exists before creating it,
	gets interrupted after the initial check, 
	and then another thread creates the new file before the first thread can.
	This has led to 
	<a href="https://www.bleepingcomputer.com/news/security/windows-11-tesla-ubuntu-and-macos-hacked-at-pwn2own-2023/" target="_blank">real world vulnerabilities</a>
	in the past.
</p>

<p>
	Consider the following example:
</p>

<div><pre><span></span><span>#define THREAD_COUNT 2</span>
<span>#define STARTING_BALANCE 10000</span>

<span>int</span><span> </span><span>balance</span><span> </span><span>=</span><span> </span><span>STARTING_BALANCE</span><span>;</span>
<span>int</span><span> </span><span>withdrawn_amounts</span><span>[</span><span>THREAD_COUNT</span><span>];</span>

<span>void</span><span> </span><span>update_account_balance</span><span>(</span><span>int</span><span> </span><span>new_balance</span><span>)</span><span> </span><span>{</span>
<span>  </span><span>// Simulate a delay consistent with a real-world system.</span>
<span>  </span><span>nanosleep</span><span>(</span><span>&amp;</span><span>(</span><span>struct</span><span> </span><span>timespec</span><span>){</span><span>0</span><span>,</span><span> </span><span>rand</span><span>()</span><span> </span><span>%</span><span> </span><span>100000</span><span>},</span><span> </span><span>NULL</span><span>);</span>
<span>  </span><span>balance</span><span> </span><span>=</span><span> </span><span>new_balance</span><span>;</span>
<span>}</span>

<span>bool</span><span> </span><span>withdraw</span><span>(</span><span>int</span><span> </span><span>thread_id</span><span>,</span><span> </span><span>int</span><span> </span><span>amount</span><span>)</span><span> </span><span>{</span>
<span>  </span><span>bool</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>false</span><span>;</span>

<span>  </span><span>if</span><span> </span><span>(</span><span>balance</span><span> </span><span>&gt;=</span><span> </span><span>amount</span><span>)</span><span> </span><span>{</span>
<span>    </span><span>update_account_balance</span><span> </span><span>(</span><span>balance</span><span> </span><span>-</span><span> </span><span>amount</span><span>);</span>
<span>    </span><span>withdrawn_amounts</span><span>[</span><span>thread_id</span><span>]</span><span> </span><span>+=</span><span> </span><span>amount</span><span>;</span>
<span>    </span><span>result</span><span> </span><span>=</span><span> </span><span>true</span><span>;</span>
<span>  </span><span>}</span>

<span>  </span><span>return</span><span> </span><span>result</span><span>;</span>
<span>}</span>

<span>void</span><span> </span><span>*</span><span>spend_recklessly</span><span>(</span><span>void</span><span> </span><span>*</span><span>_thread_id</span><span>)</span><span> </span><span>{</span>
<span>  </span><span>while</span><span>(</span><span>withdraw</span><span>((</span><span>long</span><span>)</span><span>_thread_id</span><span>,</span><span> </span><span>100</span><span> </span><span>+</span><span> </span><span>(</span><span>rand</span><span>()</span><span> </span><span>%</span><span> </span><span>5</span><span>)</span><span> </span><span>*</span><span> </span><span>200</span><span>));</span>
<span>  </span><span>return</span><span> </span><span>NULL</span><span>;</span>
<span>}</span>

<span>int</span><span> </span><span>main</span><span>()</span><span> </span><span>{</span>
<span>  </span><span>pthread_t</span><span> </span><span>threads</span><span>[</span><span>THREAD_COUNT</span><span>];</span>

<span>  </span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>THREAD_COUNT</span><span>;</span><span> </span><span>i</span><span>++</span><span>)</span><span> </span><span>{</span>
<span>    </span><span>withdrawn_amounts</span><span>[</span><span>i</span><span>]</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>
<span>    </span><span>pthread_create</span><span>(</span><span>&amp;</span><span>threads</span><span>[</span><span>i</span><span>],</span><span> </span><span>NULL</span><span>,</span><span> </span><span>spend_recklessly</span><span>,</span><span> </span><span>(</span><span>void</span><span> </span><span>*</span><span>)</span><span>i</span><span>);</span>
<span>  </span><span>}</span>

<span>  </span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>THREAD_COUNT</span><span>;</span><span> </span><span>i</span><span>++</span><span>)</span><span> </span><span>{</span>
<span>    </span><span>pthread_join</span><span>(</span><span>threads</span><span>[</span><span>i</span><span>],</span><span> </span><span>NULL</span><span>);</span>
<span>  </span><span>}</span>

<span>  </span><span>printf</span><span>(</span><span>"Starting balance: %d</span><span>\n</span><span>Final balance: %d</span><span>\n</span><span>"</span><span>,</span><span> </span><span>STARTING_BALANCE</span><span>,</span><span> </span><span>balance</span><span>);</span>

<span>  </span><span>int</span><span> </span><span>total_withdrawn</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>
<span>  </span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>THREAD_COUNT</span><span>;</span><span> </span><span>i</span><span>++</span><span>)</span><span> </span><span>{</span>
<span>    </span><span>printf</span><span>(</span><span>"Thread %d withdrew: %d</span><span>\n</span><span>"</span><span>,</span><span> </span><span>i</span><span>,</span><span> </span><span>withdrawn_amounts</span><span>[</span><span>i</span><span>]);</span>
<span>    </span><span>total_withdrawn</span><span> </span><span>+=</span><span> </span><span>withdrawn_amounts</span><span>[</span><span>i</span><span>];</span>
<span>  </span><span>}</span>

<span>  </span><span>printf</span><span>(</span><span>"Total amount withdrawn: %d</span><span>\n</span><span>"</span><span>,</span><span> </span><span>total_withdrawn</span><span>);</span>

<span>  </span><span>return</span><span> </span><span>EXIT_SUCCESS</span><span>;</span>
<span>}</span>

<span>// $ gcc -o bank_race_condition bank_race_condition.c</span>
<span>// $ ./bank_race_condition</span>
<span>// $ Starting balance: 10000</span>
<span>// $ Final balance: 400</span>
<span>// $ Thread 0 withdrew: 9700</span>
<span>// $ Thread 1 withdrew: 7700</span>
<span>// $ Total amount withdrawn: 17400</span>
</pre></div>
<p>
	This example spawns two threads using the
	<a href="https://en.wikipedia.org/wiki/Pthreads" target="_blank">POSIX threads</a> API.
	Each thread withdraws money from a shared 'bank account' until there's nothing left.
	I've introduced an artificial delay when 'saving' the new account balance to simulate real world conditions, 
	like communicating over a network, or writing to a database.
	Because of the delay between checking the available balance and updating it after a withdrawal,
	over time each thread will consistently withdraw much more than the account's total balance.
	This bank might have a hard time balancing its sheets.
</p>
<p>
	The most common way to resolve this problem is to use a 
	<a href="https://stackoverflow.com/a/34558/5931673" target="_blank"><i>mutex</i></a>.
	A mutex (from <i><b>Mut</b>ual <b>Ex</b>clusion</i>) 
	is a construct that restricts access to a certain section of code to only one thread at a time.
	The first thread to <i>acquire</i> the mutex gets access,
	other threads need to wait until the first thread <i>releases</i> it.
	This area of code protected by the mutex is known as a
	<a href="https://en.wikipedia.org/wiki/Critical_section" target="_blank"><i>critical section</i></a>
</p>
<p>
	Wrapping the <code>withdraw</code> 
	function in a mutex so that only one thread can withdraw at a time will prevent the race condition:
</p>

<div><pre><span></span><span>// ...</span>
<span>pthread_mutex_t</span><span> </span><span>bank_account_mutex</span><span> </span><span>=</span><span> </span><span>PTHREAD_MUTEX_INITIALIZER</span><span>;</span>
<span>// ...</span>

<span>bool</span><span> </span><span>withdraw</span><span>(</span><span>int</span><span> </span><span>thread_id</span><span>,</span><span> </span><span>int</span><span> </span><span>amount</span><span>)</span><span> </span><span>{</span>
<span>  </span><span>pthread_mutex_lock</span><span>(</span><span>&amp;</span><span>bank_account_mutex</span><span>);</span>
<span>  </span><span>bool</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>false</span><span>;</span>

<span>  </span><span>if</span><span> </span><span>(</span><span>balance</span><span> </span><span>&gt;=</span><span> </span><span>amount</span><span>)</span><span> </span><span>{</span>
<span>    </span><span>update_account_balance</span><span> </span><span>(</span><span>balance</span><span> </span><span>-</span><span> </span><span>amount</span><span>);</span>
<span>    </span><span>withdrawn_amounts</span><span>[</span><span>thread_id</span><span>]</span><span> </span><span>+=</span><span> </span><span>amount</span><span>;</span>
<span>    </span><span>result</span><span> </span><span>=</span><span> </span><span>true</span><span>;</span>
<span>  </span><span>}</span>

<span>  </span><span>pthread_mutex_unlock</span><span>(</span><span>&amp;</span><span>bank_account_mutex</span><span>);</span>
<span>  </span><span>return</span><span> </span><span>result</span><span>;</span>
<span>}</span>

<span>// ...</span>

<span>// $ gcc -o bank_race_condition bank_race_condition.c</span>
<span>// $ ./bank_race_condition</span>
<span>// $ Starting balance: 10000</span>
<span>// $ Final balance: 0</span>
<span>// $ Thread 0 withdrew: 4700</span>
<span>// $ Thread 1 withdrew: 5300</span>
<span>// $ Total amount withdrawn: 10000</span>
</pre></div>

<p>
	Out of the box,
	Rust supports two methods of synchronising threads:
	shared-state concurrency using 
	<a href="https://doc.rust-lang.org/book/ch16-03-shared-state.html" target="_blank"><i>Mutexes</i></a>,
	and message-passing using 
	<a href="https://doc.rust-lang.org/book/ch16-02-message-passing.html" target="_blank"><i>Channels</i></a>.
</p>
<p>
	When spawning a new thread,
	Rust's memory model guarantees that any memory it accesses lives at least as long as the thread itself,
	and that the data can't be <i>moved</i> into two threads at the same time.
	The Rust compiler prevents race conditions by enforcing that shared data access only takes place through Rust's concurrency primitives:
	The only way to actually share memory between threads is to wrap it in a Mutex,
	and access it using Rust's
	<i>Atomic Reference Counted</i> smart pointer type (<code>Arc&lt;T&gt;</code>).
</p>

<p>
	The below example demonstrates a simplified version of our 'bank' program in Rust:
</p>
<div><pre><span></span><span>fn</span><span> </span><span>spending_safely</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>account_balance</span><span> </span><span>=</span><span> </span><span>Arc</span><span>::</span><span>new</span><span>(</span><span>Mutex</span><span>::</span><span>new</span><span>(</span><span>STARTING_BALANCE</span><span>));</span>
<span>    </span><span>let</span><span> </span><span>withdrawn_amounts</span><span> </span><span>=</span><span> </span><span>Arc</span><span>::</span><span>new</span><span>(</span><span>Mutex</span><span>::</span><span>new</span><span>(</span><span>vec!</span><span>[</span><span>0</span><span>;</span><span> </span><span>THREAD_COUNT</span><span>]));</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>thread_handles</span><span> </span><span>=</span><span> </span><span>vec!</span><span>[];</span>

<span>    </span><span>for</span><span> </span><span>thread_id</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>THREAD_COUNT</span><span> </span><span>{</span>
<span>        </span><span>let</span><span> </span><span>balance_pointer</span><span> </span><span>=</span><span> </span><span>Arc</span><span>::</span><span>clone</span><span>(</span><span>&amp;</span><span>account_balance</span><span>);</span>
<span>        </span><span>let</span><span> </span><span>amounts_pointer</span><span> </span><span>=</span><span> </span><span>Arc</span><span>::</span><span>clone</span><span>(</span><span>&amp;</span><span>withdrawn_amounts</span><span>);</span>

<span>        </span><span>thread_handles</span><span>.</span><span>push</span><span>(</span><span>thread</span><span>::</span><span>spawn</span><span>(</span><span>move</span><span> </span><span>||</span><span> </span><span>{</span>
<span>            </span><span>let</span><span> </span><span>mut</span><span> </span><span>rng</span><span> </span><span>=</span><span> </span><span>rand</span><span>::</span><span>thread_rng</span><span>();</span>
<span>            </span><span>let</span><span> </span><span>amount</span><span> </span><span>=</span><span> </span><span>100</span><span> </span><span>+</span><span> </span><span>rng</span><span>.</span><span>gen_range</span><span>(</span><span>0</span><span>..</span><span>5</span><span>)</span><span> </span><span>*</span><span> </span><span>200</span><span>;</span>

<span>            </span><span>while</span><span> </span><span>(</span><span>*</span><span>balance_pointer</span><span>.</span><span>lock</span><span>().</span><span>unwrap</span><span>())</span><span> </span><span>&gt;=</span><span> </span><span>amount</span><span> </span><span>{</span>
<span>                </span><span>*</span><span>balance_pointer</span><span>.</span><span>lock</span><span>().</span><span>unwrap</span><span>()</span><span> </span><span>-=</span><span> </span><span>amount</span><span>;</span>
<span>                </span><span>amounts_pointer</span><span>.</span><span>lock</span><span>().</span><span>unwrap</span><span>()[</span><span>thread_id</span><span>]</span><span> </span><span>+=</span><span> </span><span>amount</span><span>;</span>
<span>                </span><span>std</span><span>::</span><span>thread</span><span>::</span><span>sleep</span><span>(</span><span>Duration</span><span>::</span><span>from_nanos</span><span>(</span><span>100</span><span>));</span>
<span>            </span><span>}</span>
<span>        </span><span>}));</span>
<span>    </span><span>}</span>

<span>    </span><span>for</span><span> </span><span>handle</span><span> </span><span>in</span><span> </span><span>thread_handles</span><span> </span><span>{</span>
<span>        </span><span>handle</span><span>.</span><span>join</span><span>().</span><span>unwrap</span><span>();</span>
<span>    </span><span>}</span>

<span>    </span><span>println!</span><span>(</span><span>"Starting balance: {}"</span><span>,</span><span> </span><span>STARTING_BALANCE</span><span>);</span>
<span>    </span><span>println!</span><span>(</span><span>"Final balance: {}"</span><span>,</span><span> </span><span>*</span><span>account_balance</span><span>.</span><span>lock</span><span>().</span><span>unwrap</span><span>());</span>

<span>    </span><span>let</span><span> </span><span>total_withdrawn</span><span>:</span><span> </span><span>i32</span><span> </span><span>=</span><span> </span><span>withdrawn_amounts</span><span>.</span><span>lock</span><span>().</span><span>unwrap</span><span>().</span><span>iter</span><span>().</span><span>sum</span><span>();</span>
<span>    </span><span>for</span><span> </span><span>(</span><span>thread_id</span><span>,</span><span> </span><span>&amp;</span><span>amount</span><span>)</span><span> </span><span>in</span><span> </span><span>withdrawn_amounts</span><span>.</span><span>lock</span><span>().</span><span>unwrap</span><span>().</span><span>iter</span><span>().</span><span>enumerate</span><span>()</span><span> </span><span>{</span>
<span>        </span><span>println!</span><span>(</span><span>"Thread {} withdrew: {}"</span><span>,</span><span> </span><span>thread_id</span><span>,</span><span> </span><span>amount</span><span>);</span>
<span>    </span><span>}</span>

<span>    </span><span>println!</span><span>(</span><span>"Total amount withdrawn: {}"</span><span>,</span><span> </span><span>total_withdrawn</span><span>);</span>
<span>}</span>

<span>// $ cargo run</span>
<span>// $ Starting balance: 10000</span>
<span>// $ Final balance: 0</span>
<span>// $ Thread 0 withdrew: 7500</span>
<span>// $ Thread 1 withdrew: 2500</span>
<span>// $ Total amount withdrawn: 10000</span>
</pre></div>

<p>
	Ada has its own nomenclature for multithreading: <i>Tasks</i>,
	and provides its own built-in mechanism for preventing data races between them.
	Ada's <i>Protected Objects</i> encapsulate data inside an implicit mutex,
	allowing only one thread access at a time via a public interface.
</p>
<p>
	The following example builds on the previous one,
	showing two Ada 'tasks' sharing access to a single, 'protected' resource:
</p>

<div><pre><span></span><span>procedure</span> <span>Bank</span> <span>is</span>
   <span>Float_Generator</span> <span>:</span> <span>Ada</span><span>.</span><span>Numerics</span><span>.</span><span>Float_Random</span><span>.</span><span>Generator</span><span>;</span>

   <span>function</span> <span>Get_Random_Delay</span> <span>return</span> <span>Duration</span>
   <span>is</span> <span>(</span><span>Duration</span> <span>(</span><span>Ada</span><span>.</span><span>Numerics</span><span>.</span><span>Float_Random</span><span>.</span><span>Random</span> <span>(</span><span>Float_Generator</span><span>)));</span>

   <span>function</span> <span>Get_Random_Amount</span> <span>return</span> <span>Integer</span>
   <span>is</span> <span>(</span><span>Integer</span> <span>(</span><span>Ada</span><span>.</span><span>Numerics</span><span>.</span><span>Float_Random</span><span>.</span><span>Random</span> <span>(</span><span>Float_Generator</span><span>)</span> <span>*</span> <span>999.0</span><span>));</span>

   <span>protected</span> <span>Bank_Account</span> <span>is</span>
      <span>function</span> <span>Get_Balance</span> <span>return</span> <span>Integer</span><span>;</span>
      <span>procedure</span> <span>Withdraw</span> <span>(</span><span>Amount</span> <span>: </span><span>Integer</span><span>);</span>
   <span>private</span>
      <span>Balance</span> <span>:</span> <span>Integer</span> <span>:=</span> <span>10000</span><span>;</span>
   <span>end</span> <span>Bank_Account</span><span>;</span>

   <span>protected</span> <span>body</span> <span>Bank_Account</span> <span>is</span>
      <span>function</span> <span>Get_Balance</span> <span>return</span> <span>Integer</span>
      <span>is</span> <span>(</span><span>Balance</span><span>);</span>

      <span>procedure</span> <span>Withdraw</span> <span>(</span><span>Amount</span> <span>: </span><span>Integer</span><span>)</span> <span>is</span>
      <span>begin</span>
         <span>Balance</span> <span>:=</span> <span>Balance</span> <span>-</span> <span>Amount</span><span>;</span>
      <span>end</span> <span>Withdraw</span><span>;</span>
   <span>end</span> <span>Bank_Account</span><span>;</span>

   <span>task</span> <span>type</span> <span>Reckless_Spender_Task</span> <span>(</span><span>Id</span> <span>: </span><span>Integer</span><span>);</span>

   <span>task</span> <span>body</span> <span>Reckless_Spender_Task</span> <span>is</span>
      <span>Amount</span> <span>:</span> <span>Integer</span> <span>:=</span> <span>Get_Random_Amount</span><span>;</span>
      <span>Cash</span>   <span>:</span> <span>Integer</span> <span>:=</span> <span>0</span><span>;</span>
   <span>begin</span>
      <span>while</span> <span>not</span> <span>(</span><span>Bank_Account</span><span>.</span><span>Get_Balance</span> <span>&lt;</span> <span>Amount</span><span>)</span> <span>loop</span>
         <span>Bank_Account</span><span>.</span><span>Withdraw</span> <span>(</span><span>Amount</span><span>);</span>
         <span>Cash</span> <span>:=</span> <span>Cash</span> <span>+</span> <span>Amount</span><span>;</span>
         <span>Amount</span> <span>:=</span> <span>Get_Random_Amount</span><span>;</span>
         <span>delay</span> <span>Get_Random_Delay</span><span>;</span>
      <span>end</span> <span>loop</span><span>;</span>

      <span>Put_Line</span> <span>(</span><span>"Spender"</span> <span>&amp;</span> <span>Id</span><span>'</span><span>Image</span> <span>&amp;</span> <span>" withdrew"</span> <span>&amp;</span> <span>Cash</span><span>'</span><span>Image</span><span>);</span>
   <span>end</span> <span>Reckless_Spender_Task</span><span>;</span>

   <span>Spender_1</span> <span>:</span> <span>Reckless_Spender_Task</span> <span>(</span><span>1</span><span>);</span>
   <span>Spender_2</span> <span>:</span> <span>Reckless_Spender_Task</span> <span>(</span><span>2</span><span>);</span>
<span>begin</span>
   <span>null</span><span>;</span>
<span>end</span> <span>Bank</span><span>;</span>
</pre></div>
<p>
	Wrapping the <code>Balance</code> 
	variable inside the protected <code>Bank_Account</code> 
	object ensures that only the task holding the mutex can access it.
</p>

<p>
	Unfortunately, like in C,
	nothing actually prevents you from writing code that accesses shared memory from multiple tasks.
</p>
<div><pre><span></span><span>procedure</span> <span>Bank</span> <span>is</span>
   <span>Float_Generator</span> <span>:</span> <span>Ada</span><span>.</span><span>Numerics</span><span>.</span><span>Float_Random</span><span>.</span><span>Generator</span><span>;</span>

   <span>function</span> <span>Get_Random_Delay</span> <span>return</span> <span>Duration</span>
   <span>is</span> <span>(</span><span>Duration</span> <span>(</span><span>Ada</span><span>.</span><span>Numerics</span><span>.</span><span>Float_Random</span><span>.</span><span>Random</span> <span>(</span><span>Float_Generator</span><span>)));</span>

   <span>function</span> <span>Get_Random_Amount</span> <span>return</span> <span>Integer</span>
   <span>is</span> <span>(</span><span>Integer</span> <span>(</span><span>Ada</span><span>.</span><span>Numerics</span><span>.</span><span>Float_Random</span><span>.</span><span>Random</span> <span>(</span><span>Float_Generator</span><span>)</span> <span>*</span> <span>999.0</span><span>));</span>

   <span>Balance</span> <span>:</span> <span>Integer</span> <span>:=</span> <span>10000</span><span>;</span>

   <span>task</span> <span>type</span> <span>Reckless_Spender_Task</span> <span>(</span><span>Id</span> <span>: </span><span>Integer</span><span>);</span>

   <span>task</span> <span>body</span> <span>Reckless_Spender_Task</span> <span>is</span>
      <span>Amount</span> <span>:</span> <span>Integer</span> <span>:=</span> <span>Get_Random_Amount</span><span>;</span>
      <span>Cash</span>   <span>:</span> <span>Integer</span> <span>:=</span> <span>0</span><span>;</span>
   <span>begin</span>
      <span>while</span> <span>not</span> <span>(</span><span>Balance</span> <span>&lt;</span> <span>Amount</span><span>)</span> <span>loop</span>
         <span>Cash</span> <span>:=</span> <span>Cash</span> <span>+</span> <span>Amount</span><span>;</span>
         <span>delay</span> <span>Get_Random_Delay</span><span>;</span>
         <span>Amount</span> <span>:=</span> <span>Get_Random_Amount</span><span>;</span>
         <span>Balance</span> <span>:=</span> <span>Balance</span> <span>-</span> <span>Amount</span><span>;</span>
      <span>end</span> <span>loop</span><span>;</span>

      <span>Put_Line</span> <span>(</span><span>"Spender"</span> <span>&amp;</span> <span>Id</span><span>'</span><span>Image</span> <span>&amp;</span> <span>" withdrew"</span> <span>&amp;</span> <span>Cash</span><span>'</span><span>Image</span><span>);</span>
   <span>end</span> <span>Reckless_Spender_Task</span><span>;</span>

   <span>Spender_1</span> <span>:</span> <span>Reckless_Spender_Task</span> <span>(</span><span>1</span><span>);</span>
   <span>Spender_2</span> <span>:</span> <span>Reckless_Spender_Task</span> <span>(</span><span>2</span><span>);</span>
   <span>Spender_3</span> <span>:</span> <span>Reckless_Spender_Task</span> <span>(</span><span>3</span><span>);</span>
   <span>Spender_4</span> <span>:</span> <span>Reckless_Spender_Task</span> <span>(</span><span>4</span><span>);</span>
<span>begin</span>
   <span>null</span><span>;</span>
<span>end</span> <span>Bank</span><span>;</span>

<span>--  $ alr run</span>
<span>--  $ Spender 2 withdrew 1711</span>
<span>--  $ Spender 3 withdrew 3910</span>
<span>--  $ Spender 1 withdrew 2269</span>
<span>--  $ Spender 4 withdrew 2254</span>
</pre></div>

<h4>SPARK</h4>
<p>
	SPARK supports tasking when the
	<a href="https://en.wikipedia.org/wiki/Ravenscar_profile" target="_blank">Ravenscar profile</a>
	is used, 
	and is able to prove the absence of race conditions and other concurrency-related errors.
	Ravenscar is a build configuration designed for hard real-time, safety-critical systems.
	It restricts language features unsuitable for safe multi-threaded programming.
</p>
<p>
	Describing how to write formally verifiable concurrent code in SPARK would need an article all of its own.
	For a good starting point,
	check out AdaCore's 
	<a href="https://docs.adacore.com/spark2014-docs/html/lrm/tasks-and-synchronization.html" target="_blank">SPARK Reference Manual</a>,
	and their 
	<a href="https://learn.adacore.com/courses/spark-introduction/chapters/tasking.html" target="_blank">Introduction To SPARK</a> 
	course.
</p>

<p>
	This article only scratches the surface of concurrent programming in Ada and Rust.
	To learn more, check out the
	<a href="https://doc.rust-lang.org/book/ch16-00-concurrency.html" target="_blank"><i>Fearless Concurrency</i></a>
	chapter in the <i>Rust Book</i>,
	and the 
	<a href="https://learn.adacore.com/courses/intro-to-ada/chapters/tasking.html" target="_blank"><i>Tasking</i></a>
	chapter in AdaCore's 
	<i>Introduction to Ada</i> course.
</p>

<h3 id="dangling_pointer">Dangling Pointer <a href="#dangling_pointer">#</a></h3>
<p>
	A pointer that still points to an object in memory after it's been deallocated is known as a <i>Dangling Pointer</i>.
</p>
<p>
	Try as I might, 
	I couldn't find a way to create a dangling pointer in <em>safe</em> Rust.
	The borrow-checker was way ahead of me.
</p>

<div><pre><span></span><span>fn</span><span> </span><span>create_dangling_pointer</span><span>()</span><span> </span><span>-&gt;</span><span> </span><span>&amp;</span><span>String</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>s</span><span> </span><span>=</span><span> </span><span>String</span><span>::</span><span>from</span><span>(</span><span>"hello"</span><span>);</span>
<span>    </span><span>&amp;</span><span>s</span>
<span>}</span>

<span>// $ cargo run</span>
<span>// $    Compiling dangling_pointer v0.1.0 (/home/ajxs/src/rust_examples)</span>
<span>// $ error[E0106]: missing lifetime specifier</span>
<span>// $   --&gt; src/main.rs:10:33</span>
<span>// $    |</span>
<span>// $ 10 | fn create_dangling_pointer() -&gt; &amp;String {</span>
<span>// $    |                                 ^ expected named lifetime parameter</span>
<span>// $    |</span>
<span>// $    = help: this function's return type contains a borrowed value,</span>
<span>// $ but there is no value for it to be borrowed from</span>
<span>// $ ...</span>
</pre></div>
<p>
	I had to heavily abridge the avalanche of warnings the Rust compiler generated from this example.
</p>

<p>
	Ada has a mechanism for preventing dangling pointers, 
	called <i>accessibility levels</i>.
	An object's accessibility level reflects the nesting of the scope it's defined in,
	and determines what objects an access type is allowed to point to.
	For example, if <code>Procedure_B</code> is nested within <code>Procedure_A</code>,
	it's said to have a <i>deeper</i> accessibility level than its parent.
	An access type in Ada can only point to an object at the same accessibility level, 
	or <em>shallower</em>,
	ensuring that an object lives at least as long as any access types pointing to it.
	Every type has its own accessibility level, 
	and objects have the same accessibility level as their type.
</p>
<p>
	The following example illustrates how Ada's accessibility levels prevent dangling pointers.
</p>
<div><pre><span></span><span>procedure</span> <span>Accessibility_Levels</span> <span>is</span>
   <span>type</span> <span>Level_0_Integer_Access_T</span> <span>is</span> <span>access</span> <span>all</span> <span>Integer</span><span>;</span>

   <span>Level_0_Integer</span>        <span>:</span> <span>aliased</span> <span>Integer</span>          <span>:=</span> <span>0</span><span>;</span>
   <span>Level_0_Integer_Access</span> <span>:</span> <span>Level_0_Integer_Access_T</span> <span>:=</span> <span>Level_0_Integer</span><span>'</span><span>Access</span><span>;</span>

   <span>procedure</span> <span>Level_1_Procedure</span> <span>is</span>
      <span>type</span> <span>Level_1_Integer_Access_T</span> <span>is</span> <span>access</span> <span>all</span> <span>Integer</span><span>;</span>

      <span>Level_1_Integer_Access</span> <span>:</span> <span>Level_1_Integer_Access_T</span> <span>:=</span> <span>null</span><span>;</span>
      <span>Level_1_Integer</span>        <span>:</span> <span>aliased</span> <span>Integer</span>          <span>:=</span> <span>1</span><span>;</span>
   <span>begin</span>
      <span>--  LEGAL: Level_1_Integer_Access is declared at the same</span>
      <span>--  accessibility level as Level_1_Integer.</span>
      <span>Level_1_Integer_Access</span> <span>:=</span> <span>Level_1_Integer</span><span>'</span><span>Access</span><span>;</span>

      <span>--  LEGAL: Level_1_Integer_Access is declared at a deeper</span>
      <span>--  accessibility level as Level_0_Integer.</span>
      <span>--  An object of type Level_1_Integer_Access can't possibly outlive</span>
      <span>--  the Level_0_Integer object.</span>
      <span>Level_1_Integer_Access</span> <span>:=</span> <span>Level_0_Integer</span><span>'</span><span>Access</span><span>;</span>

      <span>--  ILLEGAL: This will cause a compile-time error.</span>
      <span>--  The object Level_1_Integer is declared at a deeper accessibility</span>
      <span>--  level than Level_0_Integer_Access.</span>
      <span>--  The compiler can't be sure that the object would live as long as</span>
      <span>--  the access type pointing to it.</span>
      <span>Level_0_Integer_Access</span> <span>:=</span> <span>Level_1_Integer</span><span>'</span><span>Access</span><span>;</span>
   <span>end</span> <span>Level_1_Procedure</span><span>;</span>
<span>begin</span>
   <span>Level_1_Procedure</span><span>;</span>
   <span>Put_Line</span> <span>(</span><span>"Value: "</span> <span>&amp;</span> <span>Level_0_Integer_Access</span><span>.</span><span>all</span><span>'</span><span>Image</span><span>);</span>
<span>end</span> <span>Accessibility_Levels</span><span>;</span>
</pre></div>
<p>
	Ada allows developers to ignore the accessibility levels system with the
	<code>Unchecked_Access</code> <i>aspect</i>.
	The above code would compile without any errors if the failing line above was replaced with:
</p>
<div><pre><span></span><span>-- ...</span>
      <span>--  LEGAL: No problem! The compiler figures you know what you're doing...</span>
      <span>Level_0_Integer_Access</span> <span>:=</span> <span>Level_1_Integer</span><span>'</span><span>Unchecked_Access</span><span>;</span>
   <span>end</span> <span>Level_1_Procedure</span><span>;</span>
<span>begin</span>
   <span>Level_1_Procedure</span><span>;</span>
   <span>--  Uh oh...</span>
   <span>Put_Line</span> <span>(</span><span>"Value: "</span> <span>&amp;</span> <span>Level_0_Integer_Access</span><span>.</span><span>all</span><span>'</span><span>Image</span><span>);</span>
<span>end</span> <span>Accessibility_Levels</span><span>;</span>
</pre></div>

<h3 id="freeing_stack_memory">Freeing Stack Memory <a href="#freeing_stack_memory">#</a></h3>
<p>
	As mentioned earlier in the section on <a href="#double_free">double freeing</a> memory,
	glibc stores metadata about each allocated memory block right before the block's address.
	This lets it determine the amount of memory being freed,
	and 
	<a href="https://github.com/bminor/glibc/blob/3374de90386f1814cec58567248d43a4632b16f0/malloc/malloc-check.c#L211" target="_blank">check</a>
	whether the address actually points to something allocated on the heap.
</p>
<p>
	Attempting to free an object allocated on the stack will bring your program to a screeching halt once glibc figures out what you're upto.
</p>

<div><pre><span></span><span>void</span><span> </span><span>free_stack_memory</span><span>()</span><span> </span><span>{</span>
<span>  </span><span>// Note that modern versions of gcc will issue a warning about this:</span>
<span>  </span><span>// warning: ‘free’ called on unallocated object ‘x’ [-Wfree-nonheap-object]</span>
<span>  </span><span>int</span><span> </span><span>x</span><span> </span><span>=</span><span> </span><span>10</span><span>;</span>
<span>  </span><span>free</span><span>(</span><span>&amp;</span><span>x</span><span>);</span>
<span>  </span><span>printf</span><span>(</span><span>"Phew! We made it!</span><span>\n</span><span>"</span><span>);</span>
<span>}</span>

<span>// $ gcc -o free_stack_memory free_stack_memory.c</span>
<span>// $ ./free_stack_memory</span>
<span>// $ free(): invalid pointer</span>
<span>// $ Aborted</span>
</pre></div>

<p>
	As mentioned earlier, Rust automatically deallocates variables when they go out of scope;
	Calling their destructor when necessary.
	Calling <code>std::mem::drop</code> 
	on a stack allocated variable (that implements the <code>Drop</code> trait<sup><a href="#footnote_6" id="footnote_6_link">6</a></sup>) 
	will explicitly call its destructor, and deallocate the object.
	The fact that it was allocated in stack memory has no effect.
</p>
<p>
	In Ada, access types ordinarily only point to heap-allocated memory;
	However you can create a <i>general</i> access type by adding the 
	<code>all</code> keyword to its type declaration,
	which allows it to point to <em>any</em> object of its type, 
	including objects allocated on the stack, 
	provided they are <em>actually</em> addressable<sup><a href="#footnote_7" id="footnote_7_link">7</a></sup>.
</p>
<p>
	Freeing a general access type pointing to stack memory will raise a 
	<code>Program_Error</code> exception at runtime,
	which can be caught and handled in the normal way.
</p>

<div><pre><span></span><span>procedure</span> <span>Free_Stack_Memory</span> <span>is</span>
   <span>--  The 'all' specifier here indicates that this is a 'general access type',</span>
   <span>--  which can point to objects allocated on the heap OR the stack.</span>
   <span>type</span> <span>String_Access</span> <span>is</span> <span>access</span> <span>all</span> <span>String</span><span>;</span>

   <span>String_On_Stack</span> <span>:</span> <span>aliased</span> <span>String</span> <span>:=</span> <span>"Hello from the stack!"</span><span>;</span>
   <span>Example_String</span> <span>:</span> <span>String_Access</span> <span>:=</span> <span>String_On_Stack</span><span>'</span><span>Access</span><span>;</span>

   <span>procedure</span> <span>Free</span> <span>is</span> <span>new</span> <span>Ada</span><span>.</span><span>Unchecked_Deallocation</span> <span>(</span><span>String</span><span>,</span> <span>String_Access</span><span>);</span>
<span>begin</span>
   <span>--  Attempting to free this variable will raise a 'Program_Error' exception.</span>
   <span>Free</span> <span>(</span><span>Example_String</span><span>);</span>
<span>exception</span>
   <span>when</span> <span>E</span> <span>:</span> <span>Program_Error</span> <span>=&gt;</span>
      <span>Put_Line</span> <span>(</span><span>"Program_Error: "</span> <span>&amp;</span> <span>Exception_Message</span> <span>(</span><span>E</span><span>));</span>
<span>end</span> <span>Free_Stack_Memory</span><span>;</span>
</pre></div>

<h2 id="am_i_being_unfair">Am I Being Unfair to Ada? <a href="#am_i_being_unfair">#</a></h2>
<p>
	Am I being unfair to Ada?
	Have I turned my back on the Ada community, betrayed my own kind?
	Have I been converted from an Ada zealot into a born-again Rustacean? Not quite.
</p>
<p>
	A comparison on memory safety might tilt slightly in Rust's favour,
	but Ada's real strengths 
	<a href="https://ajxs.me/blog/Giving_Ada_a_Chance.html" target="_blank">lie elsewhere</a>. 
	Its strong typing, intuitive low-level programming semantics, 
	and static analysis capability are still unmatched by other systems languages.
</p>
<p>
	As I stated earlier you can do a lot in Ada without ever needing to use pointers,
	or even using heap memory at all,
	sparing yourself the risk of most of these problems.
</p>
<p>
	Unlike Rust, Ada allows stack variables of statically unknown size.
	The <code>Vec<t></t></code> type in Rust's standard library is great,
	but it stores its contents on the heap, 
	and won't be suitable for all use-cases.
</p>

<div><pre><span></span><span>procedure</span> <span>Variable_Size_Stack_Array</span> <span>is</span>
   <span>Array_Size</span> <span>:</span> <span>Integer</span><span>;</span>
<span>begin</span>
   <span>Ada</span><span>.</span><span>Text_IO</span><span>.</span><span>Put</span> <span>(</span><span>"What array size would you like? "</span><span>);</span>
   <span>--  Read the new array size from stdin.</span>
   <span>Ada</span><span>.</span><span>Integer_Text_IO</span><span>.</span><span>Get</span> <span>(</span><span>Array_Size</span><span>);</span>

   <span>Integer_Array</span> <span>:</span> <span>array</span> <span>(</span><span>1</span> <span>..</span> <span>Array_Size</span><span>)</span> <span>of</span> <span>Integer</span> <span>:=</span> <span>[</span><span>others</span> <span>=&gt;</span> <span>0</span><span>];</span>
   <span>Ada</span><span>.</span><span>Text_IO</span><span>.</span><span>Put_Line</span> <span>(</span><span>"Array Size: "</span> <span>&amp;</span> <span>Integer_Array</span><span>'</span><span>Length</span><span>'</span><span>Image</span><span>);</span>
<span>end</span> <span>Variable_Size_Stack_Array</span><span>;</span>
</pre></div>

<p>
	In Ada, stack-allocated, variable length arrays are first-class values.
	You can return them from functions,
	and accept them as function parameters.
	They implicitly contain their bounds as part of their value.
	The following example builds on the code above.
	Note that everything here is happening on the stack.
</p>

<div><pre><span></span><span>procedure</span> <span>Stack_Allocated_Array_Examples</span> <span>is</span>
   <span>type</span> <span>Integer_Array</span> <span>is</span> <span>array</span> <span>(</span><span>Positive</span> <span>range</span> <span>&lt;&gt;)</span> <span>of</span> <span>Integer</span><span>;</span>

   <span>--  Ada has no problem returning a variable length, stack-allocated</span>
   <span>--  array from a function.</span>
   <span>function</span> <span>Create_Variable_Size_Stack_Array</span> <span>return</span> <span>Integer_Array</span> <span>is</span>
      <span>Array_Size</span> <span>:</span> <span>Integer</span><span>;</span>
   <span>begin</span>
      <span>Ada</span><span>.</span><span>Text_IO</span><span>.</span><span>Put</span> <span>(</span><span>"What array size would you like? "</span><span>);</span>
      <span>--  Read the new array size from stdin.</span>
      <span>Ada</span><span>.</span><span>Integer_Text_IO</span><span>.</span><span>Get</span> <span>(</span><span>Array_Size</span><span>);</span>

      <span>Int_Array</span> <span>:</span> <span>constant</span> <span>Integer_Array</span> <span>(</span><span>1</span> <span>..</span> <span>Array_Size</span><span>)</span> <span>:=</span> <span>[</span><span>others</span> <span>=&gt;</span> <span>0</span><span>];</span>

      <span>return</span> <span>Int_Array</span><span>;</span>
   <span>end</span> <span>Create_Variable_Size_Stack_Array</span><span>;</span>

   <span>--  Ada also has no problem accepting a variable length, stack-allocated</span>
   <span>--  array as a parameter.</span>
   <span>procedure</span> <span>Print_Variable_Length_Array</span> <span>(</span><span>Int_Array</span> <span>: </span><span>Integer_Array</span><span>)</span> <span>is</span>
   <span>begin</span>
      <span>for</span> <span>I</span> <span>in</span> <span>Int_Array</span><span>'</span><span>Range</span> <span>loop</span>
         <span>Ada</span><span>.</span><span>Text_IO</span><span>.</span><span>Put_Line</span> <span>(</span><span>Int_Array</span> <span>(</span><span>I</span><span>)'</span><span>Image</span><span>);</span>
      <span>end</span> <span>loop</span><span>;</span>
   <span>end</span> <span>Print_Variable_Length_Array</span><span>;</span>

<span>begin</span>
   <span>Int_Array</span> <span>:</span> <span>constant</span> <span>Integer_Array</span> <span>:=</span> <span>Create_Variable_Size_Stack_Array</span><span>;</span>
   <span>Print_Variable_Length_Array</span> <span>(</span><span>Int_Array</span><span>);</span>
<span>end</span> <span>Stack_Allocated_Array_Examples</span><span>;</span>
</pre></div>

<p>
	Ada's aversion to dynamic memory allocation is reminiscent of a 
	<a href="https://www.adahome.com/History/Steelman/intro.htm" target="_blank">different time</a>;
	When embedded systems ran on 16-bit microcontrollers,
	with no operating system, no heap memory,
	and memory fragmentation could —quite literally—
	send your program crashing down to earth.
</p>

<p>
	Despite this, 
	the <i>systems programming language</i>
	ecosystem is only just now catching up to where Ada has been since the 90s.
	That's not to say Ada has stood still!
	Under AdaCore's stewardship the language has moved forward in leaps and bounds,
	and the 
	<a href="https://alire.ada.dev/" target="_blank">Alire</a>
	package manager has made Ada more accessible than ever.
	Whether you're ever going to write Ada or not,
	there's a lot you can learn from it.
	If you're designing a modern systems language,
	understanding what makes Ada good is <em>essential</em><sup><a href="#footnote_8" id="footnote_8_link">8</a></sup>.
</p>

<h2 id="conclusions">Conclusions? <a href="#conclusions">#</a></h2>
<p>
	I actually came away from writing this article with more respect for Rust.
	It does a great job of preventing lots of common bugs entirely at compile-time.
	I still think Rust is clunky and frustrating at times,
	but all in all it's an impressive language that really advances the state of the art.
</p>
<p>
	A lot of people are put off by the excessive technicality of Rust's semantics. 
	Myself included.
	One thing Ada does really well is keeping a lot of its complicated machinery hidden. 
	That might sound a bit dangerous for a low-level programming language, 
	but Ada manages it perfectly,
	and has been battle-tested by 
	<a href="https://www.adacore.com/company/our-customers" target="_blank">decades of use</a>
	in safety-critical systems.
	You never miss worrying about whether a parameter is passed by value or reference,
	or envy Rust's 
	<a href="https://stackoverflow.com/questions/24158114/what-are-the-differences-between-rusts-string-and-str" target="_blank">confusing multitude</a>
	of <i>string</i> types.
</p>
<p>
	To give Rust its due, 
	I think its designers had the right idea. 
	For all its technicality,
	Rust's design is forward-thinking and modern.
	I hope the new programming languages of 2050 will look at 
	<a href="https://github.com/johnperry-math/AoC2023/blob/master/More_Detailed_Comparison.md" target="_blank">both Ada and Rust</a>,
	see what each of them did right, 
	and be better than both of them.
</p>

<h2 id="references">References <a href="#references">#</a></h2>
<ul id="references-list">
	<li>
		ISO/IEC 9899 (2018) <i>Information technology — Programming languages — C</i>
	</li>
</ul>

<hr>
<ol>
	<li id="footnote_1">
		<p>
			The Rust Handbook even
			<a href="https://doc.rust-lang.org/book/ch15-06-reference-cycles.html" target="_blank">gives us a recipe</a>
			for creating our very own memory leak! By creating a <i>reference cycle</i>,
			where two smart pointers reference each other.
			When this happens, 
			the amount of references to each pointer will never reach zero,
			and the objects will never be deallocated.
		</p>
		
		<div><pre><span></span><span>#[derive(Debug)]</span>
<span>struct</span><span> </span><span>Node</span><span> </span><span>{</span>
<span>    </span><span>value</span><span>:</span><span> </span><span>i32</span><span>,</span>
<span>    </span><span>next</span><span>:</span><span> </span><span>Option</span><span>&lt;</span><span>Rc</span><span>&lt;</span><span>RefCell</span><span>&lt;</span><span>Node</span><span>&gt;&gt;&gt;</span><span>,</span>
<span>    </span><span>prev</span><span>:</span><span> </span><span>Option</span><span>&lt;</span><span>Rc</span><span>&lt;</span><span>RefCell</span><span>&lt;</span><span>Node</span><span>&gt;&gt;&gt;</span><span>,</span>
<span>}</span>

<span>fn</span><span> </span><span>reference_cycle</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>node1</span><span> </span><span>=</span><span> </span><span>Rc</span><span>::</span><span>new</span><span>(</span><span>RefCell</span><span>::</span><span>new</span><span>(</span><span>Node</span><span> </span><span>{</span>
<span>        </span><span>value</span><span>:</span><span> </span><span>1</span><span>,</span>
<span>        </span><span>next</span><span>:</span><span> </span><span>None</span><span>,</span>
<span>        </span><span>prev</span><span>:</span><span> </span><span>None</span><span>,</span>
<span>    </span><span>}));</span>

<span>    </span><span>let</span><span> </span><span>node2</span><span> </span><span>=</span><span> </span><span>Rc</span><span>::</span><span>new</span><span>(</span><span>RefCell</span><span>::</span><span>new</span><span>(</span><span>Node</span><span> </span><span>{</span>
<span>        </span><span>value</span><span>:</span><span> </span><span>2</span><span>,</span>
<span>        </span><span>next</span><span>:</span><span> </span><span>None</span><span>,</span>
<span>        </span><span>prev</span><span>:</span><span> </span><span>None</span><span>,</span>
<span>    </span><span>}));</span>

<span>    </span><span>// Create a reference cycle between the two nodes.</span>
<span>    </span><span>node1</span><span>.</span><span>borrow_mut</span><span>().</span><span>next</span><span> </span><span>=</span><span> </span><span>Some</span><span>(</span><span>Rc</span><span>::</span><span>clone</span><span>(</span><span>&amp;</span><span>node2</span><span>));</span>
<span>    </span><span>node2</span><span>.</span><span>borrow_mut</span><span>().</span><span>prev</span><span> </span><span>=</span><span> </span><span>Some</span><span>(</span><span>Rc</span><span>::</span><span>clone</span><span>(</span><span>&amp;</span><span>node1</span><span>));</span>

<span>    </span><span>println!</span><span>(</span>
<span>        </span><span>"Reference counts: </span><span>\n</span><span>  First = {}</span><span>\n</span><span>  Second = {}"</span><span>,</span>
<span>        </span><span>Rc</span><span>::</span><span>strong_count</span><span>(</span><span>&amp;</span><span>node1</span><span>),</span>
<span>        </span><span>Rc</span><span>::</span><span>strong_count</span><span>(</span><span>&amp;</span><span>node2</span><span>)</span>
<span>    </span><span>);</span>
<span>}</span>
</pre></div>

		<p>Running the above code in Valgrind confirms there's a memory leak:</p>
		
		<div><pre><span></span>$ valgrind ./target/debug/reference_cycle_example
==60830== Memcheck, a memory error detector
==60830== Copyright (C) 2002-2022, and GNU GPL'd, by Julian Seward et al.
==60830== Using Valgrind-3.19.0 and LibVEX; rerun with -h for copyright info
==60830== Command: ./target/debug/reference_cycle_example
==60830==
Reference counts:
  First = 2
  Second = 2
==60830==
==60830== HEAP SUMMARY:
==60830==     in use at exit: 96 bytes in 2 blocks
==60830==   total heap usage: 11 allocs, 9 frees, 2,256 bytes allocated
==60830==
==60830== LEAK SUMMARY:
==60830==    definitely lost: 48 bytes in 1 blocks
==60830==    indirectly lost: 48 bytes in 1 blocks
==60830==      possibly lost: 0 bytes in 0 blocks
==60830==    still reachable: 0 bytes in 0 blocks
==60830==         suppressed: 0 bytes in 0 blocks
==60830== Rerun with --leak-check=full to see details of leaked memory
==60830==
==60830== For lists of detected and suppressed errors, rerun with: -s
==60830== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
</pre></div>
		<p>
			It's also interesting that printing the value of either of the nodes
			in the above code will result in a stack overflow.
		<a href="#footnote_1_link">↲</a></p>
	</li><li id="footnote_2">
		<a href="https://www.adaic.org/resources/add_content/standards/22rm/html/RM-4-8.html" target="_blank">Section 4.8</a>
		of the Ada Reference Manual 
		states that an <i>implementation</i> is free, 
		but not required, to implement a 
		<a href="https://en.wikipedia.org/wiki/Garbage_collection_%28computer_science%29" target="_blank"><i>garbage collector</i></a>.

		Aside from one experimental 
		<a href="https://www.enyo.de/fw/software/gnat-gc/" target="_blank">patch</a>
		for GCC,
		I'm not aware of any <em>mainstream</em> Ada compiler that uses a garbage collector.
		However at one point there were
		<a href="https://www.adahome.com/Resources/Ada_Java.html" target="_blank">several</a>
		commercial Ada compilers that targeted the <i>Java Virtual Machine</i>,
		which would have featured the JVM's default garbage collector.
	<a href="#footnote_2_link">↲</a></li><li id="footnote_3">
		Ada's <a href="https://blog.adacore.com/header-storage-pools" target="_blank"><i>storage pool</i></a>
		feature gives it native support for <i>arena allocators</i>,
		and gives developers fine-grained control of how an access type is allocated, and deallocated.
		This can be used to create custom reference-counted types, 
		or give a program control over its own memory management at runtime.
	<a href="#footnote_3_link">↲</a></li><li id="footnote_4">
		Funnily enough, the static analyser can only prove the <em>absence</em> of runtime errors.
		When it can't prove that a runtime error <em>won't</em> occur, it'll give you a warning.
		Here, the static analyser has identified a situation where it's <em>possible</em> 
		that the pointer could be null when accessed. 
	<a href="#footnote_4_link">↲</a></li><li id="footnote_5">
		Note also that glibc will only detect freeing the same address <em>consecutively</em>.
		Also note that dereferencing the already freed aliased pointer to print its address
		<em>doesn't</em> raise a <code>Constraint_Error</code> exception for some unknown reason.
	<a href="#footnote_5_link">↲</a></li><li id="footnote_6">
		Explicitly calling <code>std::mem::drop</code> 
		on a variable that doesn't implement the <code>Drop</code> 
		trait does nothing, other than raising a compile-time warning.
	<a href="#footnote_6_link">↲</a></li><li id="footnote_7">
		The C standard specifies that <em>objects</em> must be addressable,
		unless they are declared with the <code>register</code> storage-class specifier
		(ISO/IEC 9899:2018, Section 6.5.3.2).
		The Ada standard does not impose this restriction, 
		and Ada compilers are free to allocate objects entirely within registers.
		In Ada, the <code>aliased</code>
		keyword is used to indicate that a particular object must be addressable.
	<a href="#footnote_7_link">↲</a></li><li id="footnote_8">
		For what it's worth, I'm led to believe the Rust designers 
		<a href="https://news.ycombinator.com/item?id=7824570#7824948" target="_blank"><em>did</em></a>
		study Ada to some extent.
		Discussions of Ada's features have featured in Rust's 
		<a href="https://github.com/rust-lang/rfcs/issues/671" target="_blank">RFCs</a> in the past.

	<a href="#footnote_8_link">↲</a></li></ol>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don't Be Frupid (115 pts)]]></title>
            <link>https://selix.net/notes/dont-be-frupid</link>
            <guid>42996796</guid>
            <pubDate>Mon, 10 Feb 2025 04:01:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://selix.net/notes/dont-be-frupid">https://selix.net/notes/dont-be-frupid</a>, See on <a href="https://news.ycombinator.com/item?id=42996796">Hacker News</a></p>
Couldn't get https://selix.net/notes/dont-be-frupid: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Thomas Aquinas' skull reveals appearance and cause of death (113 pts)]]></title>
            <link>https://www.ncregister.com/blog/face-of-aquinas-revealed-after-750-years</link>
            <guid>42996671</guid>
            <pubDate>Mon, 10 Feb 2025 03:38:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ncregister.com/blog/face-of-aquinas-revealed-after-750-years">https://www.ncregister.com/blog/face-of-aquinas-revealed-after-750-years</a>, See on <a href="https://news.ycombinator.com/item?id=42996671">Hacker News</a></p>
Couldn't get https://www.ncregister.com/blog/face-of-aquinas-revealed-after-750-years: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Searchable Library of Free Audiobooks (132 pts)]]></title>
            <link>https://booksearch.party/</link>
            <guid>42994440</guid>
            <pubDate>Sun, 09 Feb 2025 21:52:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://booksearch.party/">https://booksearch.party/</a>, See on <a href="https://news.ycombinator.com/item?id=42994440">Hacker News</a></p>
Couldn't get https://booksearch.party/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Analysis of 2024 Election Results in Clark County Indicates Manipulation (177 pts)]]></title>
            <link>https://www.wcia.com/business/press-releases/ein-presswire/776992724/analysis-of-2024-election-results-in-clark-county-indicates-manipulation/</link>
            <guid>42994293</guid>
            <pubDate>Sun, 09 Feb 2025 21:37:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wcia.com/business/press-releases/ein-presswire/776992724/analysis-of-2024-election-results-in-clark-county-indicates-manipulation/">https://www.wcia.com/business/press-releases/ein-presswire/776992724/analysis-of-2024-election-results-in-clark-county-indicates-manipulation/</a>, See on <a href="https://news.ycombinator.com/item?id=42994293">Hacker News</a></p>
Couldn't get https://www.wcia.com/business/press-releases/ein-presswire/776992724/analysis-of-2024-election-results-in-clark-county-indicates-manipulation/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Three Observations (154 pts)]]></title>
            <link>https://blog.samaltman.com/three-observations</link>
            <guid>42993987</guid>
            <pubDate>Sun, 09 Feb 2025 21:06:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.samaltman.com/three-observations">https://blog.samaltman.com/three-observations</a>, See on <a href="https://news.ycombinator.com/item?id=42993987">Hacker News</a></p>
Couldn't get https://blog.samaltman.com/three-observations: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[OpenStreetMap Calendar (110 pts)]]></title>
            <link>https://osmcal.org/</link>
            <guid>42993044</guid>
            <pubDate>Sun, 09 Feb 2025 19:32:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://osmcal.org/">https://osmcal.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42993044">Hacker News</a></p>
Couldn't get https://osmcal.org/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Daily omega-3 fatty acids may help human organs stay young (128 pts)]]></title>
            <link>https://medicalxpress.com/news/2025-02-daily-omega-fatty-acids-human.html</link>
            <guid>42992729</guid>
            <pubDate>Sun, 09 Feb 2025 18:59:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2025-02-daily-omega-fatty-acids-human.html">https://medicalxpress.com/news/2025-02-daily-omega-fatty-acids-human.html</a>, See on <a href="https://news.ycombinator.com/item?id=42992729">Hacker News</a></p>
Couldn't get https://medicalxpress.com/news/2025-02-daily-omega-fatty-acids-human.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[AI Demos by Meta (250 pts)]]></title>
            <link>https://aidemos.meta.com/</link>
            <guid>42992643</guid>
            <pubDate>Sun, 09 Feb 2025 18:49:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aidemos.meta.com/">https://aidemos.meta.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42992643">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Persistent packages on Steam Deck using Nix (141 pts)]]></title>
            <link>https://chrastecky.dev/gaming/persistent-packages-on-steam-deck-using-nix</link>
            <guid>42992345</guid>
            <pubDate>Sun, 09 Feb 2025 18:15:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chrastecky.dev/gaming/persistent-packages-on-steam-deck-using-nix">https://chrastecky.dev/gaming/persistent-packages-on-steam-deck-using-nix</a>, See on <a href="https://news.ycombinator.com/item?id=42992345">Hacker News</a></p>
<div id="readability-page-1" class="page"><p _ngcontent-ng-c3018183921="">The Steam Deck (and SteamOS) delivers a fantastic console-like experience on a Linux system. However, its immutable filesystem means that installing packages that persist across system upgrades isn’t straightforward. Fortunately, with a little Nix magic, you can work around that limitation.</p><div _ngcontent-ng-c3018183921=""><p>Immutable systems offer many benefits—until you need to customize your filesystem by installing packages. While installing software isn’t difficult per se, SteamOS’s design means that most customizations are wiped during system upgrades. About a year ago, Valve added <code>/nix</code> to the list of directories that remain intact during updates, and that’s where Nix stores all of its packages.</p>

<blockquote>
<p>If you’re not familiar with Nix: it’s a package manager that uses declarative definitions for your software instead of commands like <code>apt install</code> or <code>dnf install</code>. You simply list all your desired packages in a configuration file, and Nix takes care of installing them. Additionally, the handy <code>nix-shell</code> utility lets you spawn temporary shells with the packages you specify.</p>
</blockquote>

<p>There are two primary ways to work with Nix comfortably: you can either run <a href="https://nixos.org/" rel="noopener noreferrer" target="_blank">NixOS</a> (which isn’t ideal on a Steam Deck) or use <a href="https://nix-community.github.io/home-manager/" rel="noopener noreferrer" target="_blank">Home Manager</a>.</p>

<h2>Installing Nix</h2>

<p>Switch to Desktop Mode and open Konsole for the following steps. First, install Nix itself using this command (see the <a href="https://nixos.org/download/" rel="noopener noreferrer" target="_blank">official installation instructions</a>):</p>

<p><code>sh &lt;(curl -L https://nixos.org/nix/install) --no-daemon</code></p>

<p>This command installs Nix in single-user mode (<code>--no-daemon</code>), which is a good fit for SteamOS since it may not require <code>sudo</code> for most operations. (If it does ask for sudo, you’ll need to <a href="https://www.gamingonlinux.com/guides/view/how-to-set-change-and-reset-your-steamos-steam-deck-desktop-sudo-password/" rel="noopener noreferrer" target="_blank">set up sudo on your Steam Deck</a>.)</p>

<p>Next, load Nix into your current terminal session:</p>

<p><code>source .bash_profile</code></p>

<p>By default, Nix uses the unstable branch of packages. To switch to the stable channel, run:</p>

<p><code>nix-channel --add https://nixos.org/channels/nixos-24.11 nixpkgs</code></p>

<p>This command sets your <code>nixpkgs</code> channel to the latest stable version (in this example, 24.11). In the future, check the current stable version on the <a href="https://nixos.org/" rel="noopener noreferrer" target="_blank">NixOS homepage</a>.</p>

<p>Nix is now installed—but without Home Manager, it isn’t very user-friendly.</p>

<h2>Installing Home Manager</h2>

<p>First, add the Home Manager channel to your Nix configuration:</p>

<p><code>nix-channel --add https://github.com/nix-community/home-manager/archive/release-24.11.tar.gz home-manager</code></p>

<p><strong>Note:</strong> Ensure that the version for both Nix and Home Manager match. In this example, both are 24.11.</p>

<blockquote>
<p>If you prefer the unstable branch, you can instead run: <code>nix-channel --add https://github.com/nix-community/home-manager/archive/master.tar.gz home-manager</code></p>
</blockquote>

<p>Update your channels to include these changes:</p>

<p><code>nix-channel --update</code></p>

<p>Before proceeding, back up your Bash configuration files:</p>

<ul>
	<li><code>mv .bash_profile .bash_profile.bckp</code></li>
	<li><code>mv .bashrc .bashrc.bckp</code></li>
</ul>

<blockquote>
<p>If you choose not to back them up, you’ll need to remove them because Home Manager creates these files during installation and will fail if they already exist.</p>
</blockquote>

<p>Now, run the Home Manager installation:</p>

<p><code>nix-shell '&lt;home-manager&gt;' -A install</code></p>

<p>Once the installation completes, create your Home Manager configuration file using a text editor:</p>

<p><code>kate ~/.config/home-manager/home.nix</code></p>

<p>Paste in the following configuration:</p>

<pre><code>{ config, pkgs, ... }:
{
  home.username = "deck";
  home.homeDirectory = "/home/deck";

  programs.bash = {
    enable = true;
    initExtra = ''
      if [ -e $HOME/.nix-profile/etc/profile.d/nix.sh ]; then . $HOME/.nix-profile/etc/profile.d/nix.sh; fi

      export NIX_SHELL_PRESERVE_PROMPT=1
      if [[ -n "$IN_NIX_SHELL" ]]; then
        export PS1="$PS1(nix-shell) "
      fi
    '';
  };

  home.stateVersion = "24.11"; # don't change this even if you upgrade your channel in the future, this should stay the same as the version you first installed nix on

  home.packages = with pkgs; [
    
  ];

  programs.home-manager.enable = true;
}</code></pre>

<p>This configuration does the following:</p>

<ul>
	<li>Sets your username to <strong>deck</strong> (the default on Steam Deck).</li>
	<li>Specifies the correct path to your home directory.</li>
	<li>Enables Home Manager to manage your Bash shell and ensures the Nix environment is loaded automatically—so you won’t have to source it manually each time.</li>
	<li>Adds a <code>(nix-shell)</code> suffix to your terminal prompt when you’re in a Nix shell, which is a subtle but useful improvement over the default behavior.</li>
	<li>Defines the <code>home.stateVersion</code>, which should remain the same as when you first installed Nix (even if you later change your channels). <strong>You should never change it after the initial Nix installation</strong></li>
	<li>Enables Home Manager itself.</li>
	<li>Provides an empty list (<code>home.packages</code>) where you can later add your desired packages.</li>
</ul>

<p>Apply your new configuration by running:</p>

<p><code>home-manager switch</code></p>

<p>This is the basic workflow for managing your environment with Nix: update your configuration file and then run <code>home-manager switch</code> to apply the changes.</p>

<p>After closing and reopening your terminal, test the setup by running <code>nix-shell</code>. If you see an error indicating that <code>default.nix</code> is missing, everything is working as expected. (If the command isn’t found at all, something went wrong.)</p>

<h2>Installing packages</h2>

<p>To install packages, simply add them to the <code>home.packages</code> list in your configuration file. For example, to install <code>nmap</code> (for network scanning) and <code>cowsay</code> (because a cow makes everything better), update your configuration as follows:</p>

<pre><code>  home.packages = with pkgs; [
      nmap
      cowsay
  ];</code></pre>

<p>Keep the rest of the file unchanged, then apply the new configuration with <code>home-manager switch</code>. You can test the setup by running:</p>

<p><code>echo "Hello from my Steam Deck!" | cowsay</code></p>

<p>You should see this beauty in your terminal:</p>

<pre><code> ___________________________ 
&lt; Hello from my Steam Deck! &gt;
 --------------------------- 
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||
</code></pre>

<p>Running <code>nmap</code> should display its usage instructions. If you decide to remove <code>nmap</code> (you're keeping <code>cowsay</code>, right?), just delete it from the configuration file and run <code>home-manager switch</code> again.</p>

<h2>Tips</h2>

<ul>
	<li>Create a desktop shortcut to your configuration file:
	<ul>
		<li><code>ln -s ~/.config/home-manager/home.nix ~/Desktop/Nix_Config</code></li>
	</ul>
	</li>
	<li>Run <code>nix-collect-garbage</code> periodically to remove unused packages and free up space.</li>
	<li>Install the <code>comma</code> package. This nifty tool lets you run any package on the fly by simply prefixing the command with a comma.
	<ul>
		<li>For example, instead of adding <code>nmap</code> to your configuration, you could run <code>, nmap</code> to temporarily use it. (notice the comma in front of nmap)</li>
	</ul>
	</li>
	<li>Nix can do much more than just manage packages—for instance, you can use it to create environment variables, shell aliases, systemd services, files, and more.</li>
</ul>

<p><small>Cover image sources:&nbsp;<a href="https://commons.wikimedia.org/wiki/File:Steam_Deck_(front).png" rel="noopener noreferer" target="_blank">Wikimedia Commons</a>, <a href="https://github.com/NixOS/nixos-artwork/blob/master/wallpapers/nix-wallpaper-nineish-catppuccin-frappe-alt.png" rel="noopener noreferer" target="_blank">NixOS</a> </small></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PhD Knowledge Not Required: A Reasoning Challenge for Large Language Models (122 pts)]]></title>
            <link>https://arxiv.org/abs/2502.01584</link>
            <guid>42992336</guid>
            <pubDate>Sun, 09 Feb 2025 18:14:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2502.01584">https://arxiv.org/abs/2502.01584</a>, See on <a href="https://news.ycombinator.com/item?id=42992336">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2502.01584">View PDF</a>
    <a href="https://arxiv.org/html/2502.01584v2">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Existing benchmarks for frontier models often test specialized, ``PhD-level'' knowledge that is difficult for non-experts to grasp. In contrast, we present a benchmark based on the NPR Sunday Puzzle Challenge that requires only general knowledge. Our benchmark is challenging for both humans and models, however correct solutions are easy to verify, and models' mistakes are easy to spot.
<br>Our work reveals capability gaps that are not evident in existing benchmarks: OpenAI o1 significantly outperforms other reasoning models that are on par on benchmarks that test specialized knowledge. Furthermore, our analysis of reasoning outputs uncovers new kinds of failures. DeepSeek R1, for instance, often concedes with ``I give up'' before providing an answer that it knows is wrong. R1 can also be remarkably ``uncertain'' in its output and in rare cases, it does not ``finish thinking,'' which suggests the need for an inference-time technique to ``wrap up'' before the context window limit is reached. We also quantify the effectiveness of reasoning longer with R1 and Gemini Thinking to identify the point beyond which more reasoning is unlikely to improve accuracy on our benchmark.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Arjun Guha [<a href="https://arxiv.org/show-email/1e111933/2502.01584" rel="nofollow">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2502.01584v1" rel="nofollow">[v1]</a></strong>
        Mon, 3 Feb 2025 18:10:38 UTC (291 KB)<br>
    <strong>[v2]</strong>
        Thu, 6 Feb 2025 10:45:16 UTC (291 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Blog If Nobody Reads It? (638 pts)]]></title>
            <link>https://andysblog.uk/why-blog-if-nobody-reads-it/</link>
            <guid>42992159</guid>
            <pubDate>Sun, 09 Feb 2025 17:50:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andysblog.uk/why-blog-if-nobody-reads-it/">https://andysblog.uk/why-blog-if-nobody-reads-it/</a>, See on <a href="https://news.ycombinator.com/item?id=42992159">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    
        
    

    
        

        <p>
            <i>
                <time datetime="2025-02-05T08:13Z">
                    05 Feb, 2025
                </time>
            </i>
        </p>
    

    <p>Back in the day, advertising legend Bill Bernbach said, “The most powerful element in advertising is the truth.”</p>
<p>Let’s tell the truth, then: Nobody reads your blog.</p>
<p>At least, not as many as you’d like. Maybe a handful, maybe none. You pour your thoughts into it, craft each sentence, pick the right image — then silence. No likes, no shares, no engagement.</p>
<p>So what’s the point?</p>
<p>There’s two lies we tell ourselves:</p>
<ol>
<li><em>If I write it, they will come.</em> They won’t. There are billions of blog posts out there. The internet is an infinite void, and your blog is a whisper in a hurricane.</li>
<li>If nobody reads it, it’s a waste of time.</li>
</ol>
<p>Is it, though?</p>
<p>There is a hidden value in blogging.
There’s an old Zen saying: “Chop wood, carry water.” You do it not for the applause but because it needs doing.</p>
<p>Blogging forces clarity. It makes you structure your thoughts, sharpen your perspective. You stop writing fluff because — let’s be honest — you’re writing for yourself. And if you can’t keep yourself interested, nobody else stands a chance.</p>
<p>When you write, you think better. When you think better, you create better.</p>
<p>So, who’s there real audience?</p>
<p>You’re not just writing for today’s invisible audience. You’re writing for:</p>
<ul>
<li>Future you. Your posts become a time capsule of your evolving mind.</li>
<li>One right person. Maybe one day, someone stumbles across your words at exactly the right moment. And that changes something for them.</li>
<li>The work itself. Consistency beats virality. A hundred posts with depth will outlast a single viral hit.</li>
</ul>
<p>And there’s another thing. My other passion is street photography. Which is a bit like blogging.</p>
<p>You walk through the city, camera in hand. You see a scene — a moment of light, shadow, humanity. You capture it.</p>
<p>Nobody cares.</p>
<p>But that’s not why you did it. You did it because you saw something.</p>
<p>Like blogging. You write because you think, because you observe, because you need to put it somewhere.</p>
<p>If someone reads it? Bonus. If not? The work still got done.</p>
<p>And that’s the real point.</p>


    

    
        
            <p>
                
                    <a href="https://andysblog.uk/blog/?q=blogging">#blogging</a>
                
                    <a href="https://andysblog.uk/blog/?q=writing">#writing</a>
                
            </p>
        

        
            


        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UnitedHealth Is Sick of Everyone Complaining About Its Claim Denials (147 pts)]]></title>
            <link>https://www.rollingstone.com/culture/culture-news/unitedhealth-defends-image-claim-denials-mangione-thompson-1235259054/</link>
            <guid>42992121</guid>
            <pubDate>Sun, 09 Feb 2025 17:43:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rollingstone.com/culture/culture-news/unitedhealth-defends-image-claim-denials-mangione-thompson-1235259054/">https://www.rollingstone.com/culture/culture-news/unitedhealth-defends-image-claim-denials-mangione-thompson-1235259054/</a>, See on <a href="https://news.ycombinator.com/item?id=42992121">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

		

		


<p>Two months after UnitedHealthcare's CEO was murdered, the insurer is moving to protect its image    </p>
	</div><div><p>
	Two months after the <a href="https://www.rollingstone.com/culture/culture-news/unitedhealthcare-ceo-shooting-details-emerge-everything-to-know-1235193146/">killing</a> of <a href="https://www.rollingstone.com/t/unitedhealthcare/">UnitedHealthcare</a> CEO Brian Thompson sent shockwaves through the <a href="https://www.rollingstone.com/politics/political-commentary/luigi-mangione-unitedhealthcare-health-care-scam-1235214858/">much-reviled U.S. health insurance industry</a>, the company’s parent, UnitedHealth Group, is making aggressive moves to protect its image.</p>



<p>
	Responding to a slew of attacks online, often coupled with the glorification of <a href="https://www.rollingstone.com/t/luigi-mangione/">Luigi Mangione</a> (who was charged with Thompson’s murder outside a Midtown Manhattan hotel in December, and allegedly wrote a short manifesto calling health insurers “parasites”), the company has hired a law firm that specializes in defamation cases. Clare Locke, the Virginia-based practice, previously represented Dominion Voting Systems in a bombshell defamation suit that saw Fox News pay a settlement of <a href="https://www.rollingstone.com/politics/politics-news/foxs-primetime-hosts-dominion-settlement-1234717513/">$787.5 million</a> for airing false allegations about the company’s supposed role in voter fraud during the 2020 election.</p>



<p>
	UnitedHealth appears eager to make a similar example of Elisabeth Potter, an Austin, Texas, plastic surgeon, and is accusing the doctor of “using her social media following to perpetuate inaccuracies, which is irresponsible, unethical and dangerous.” On Jan. 7, Potter posted a <a href="https://www.instagram.com/p/DEid-1npNbA/?hl=en" rel="nofollow" target="_blank">video</a> on <a href="https://www.rollingstone.com/t/instagram/">Instagram</a> sharing her frustration with the U.S. insurance system, explaining in a text caption that during a procedure, “I was interrupted by a call from United Healthcare — while the patient was already asleep on the operating table. They demanded information about her diagnosis and inpatient stay justification. I had to scrub out mid-surgery to call United, only to find that the person on the line didn’t even have access to the patient’s full medical information, despite the procedure already being pre-approved.” 

	</p>




<p>
	“It’s beyond frustrating and, frankly, unacceptable,” Potter continued. “We should be focused on care, not bureaucracy.” The comments were rife with fury at UniteHealthcare and for-profit health insurance more broadly. “Luigi for President,” wrote one person, while another put in, “One day these health insurance companies will be dead.” 


</p><section>
			

	<h2 id="section-heading">

	
		Editor’s picks
	
	</h2>

	
	
</section>




<p>
	Days later, according to reporting from <em><a href="https://news.bloomberglaw.com/business-and-practice/unitedhealth-hires-defamation-firm-to-counter-social-media-posts" rel="nofollow" target="_blank">Bloomberg</a></em>, Potter’s attorney received a letter from Clare Locke instructing her to amend the post, apologize, and disavow threats of violence that UnitedHealth claimed had stemmed from the video. But Potter’s legal counsel, Jessica Underwood, has said that there is nothing inaccurate in the video that needs correcting. “Dr. Potter will not be silenced by UnitedHealthcare’s attempts to threaten and harass her,” Underwood has said. The company, meanwhile, has argued that “Dr. Potter’s claims that she was called out of surgery are false.” Potter’s Instagram video remains up on the platform, where it has received more than 350,000 likes.

	</p>




<p>
	Elsewhere, UnitedHealth took measures to prevent the dissemination of internal data about its denials of customer claims. (UnitedHealth Group’s individual market plans are known to have one of the <a rel="nofollow" href="https://www.startribune.com/unitedhealth-group-two-blues-plans-had-highest-denial-rates-for-aca-health-plans-in-2023/601212605" target="_blank">highest denial rates</a> among all U.S. insurers, a fact that received much media attention in the wake of Thompson’s death.) As <a rel="nofollow" href="https://www.levernews.com/amazon-and-unitedhealths-inaugural-demands-post/" target="_blank">The Lever reported</a>, a day after <a href="https://www.rollingstone.com/t/donald-trump/">President Donald Trump</a>‘s inauguration in January, UnitedHealth submitted a <a rel="nofollow" href="https://www.sec.gov/files/corpfin/no-action/14a-8/muellerunitedhealth12125-14a8inc.pdf" target="_blank">letter</a> to the Securities and Exchange Commission asking for approval to block a shareholder proposal that it use a third-party auditor to assess “previous customer denial claims, particularly where a death was involved, to determine if denial letters included factually incorrect and insensitive information.” In cases where this outside analyst determined that a coverage claim should not have been denied, the proposal says, those individuals and family members affected are to be sent an apology letter hand-signed by both a UnitedHealth executive and a member of the company’s board of directors.</p>



<p>
	UnitedHealth’s rationale for refusing a vote on such a policy, as its legal team wrote in the letter, is that the proposal was not submitted before “the applicable deadline.”</p>



<p>
	Then, on Jan. 31, the insurer sent a <a rel="nofollow" href="https://www.sec.gov/files/corpfin/no-action/14a-8/durocherunitedhealth13125-14a8inc.pdf" target="_blank">second letter</a> to the SEC, seeking to prevent a shareholder vote on another proposal related to its claim denials. This proposal, if passed by investors, would recommend that UnitedHealth “evaluate how company practices impact access to <a href="https://www.rollingstone.com/t/health-care/" id="auto-tag_health-care" data-tag="health-care">health care</a> and patient outcomes, including analyses of how often prior authorization requirements or denials of coverage lead to delay or abandonment of medical treatment and serious adverse events for patients.” The report produced through this review is also intended to encompass “the public health-related costs and macroeconomic risks created by the company’s practices that limit or delay access to health care.”


</p><section>
			

	<h2 id="section-heading">

	
		Related Content
	
	</h2>

	
	
</section>




<p>
	In their letter, UniteHealth rejected the notion of putting this proposal to a shareholder vote because it is “vague and indefinite,” and, it argued, an attempt to “impermissibly micromanage” the company.</p>



<p>
	The insurance giant’s attempts to police social media chatter about its business practices and its overtures to Trump’s SEC dovetailed earlier this week when hedge fund billionaire <a href="https://www.rollingstone.com/culture/culture-news/bill-ackman-wife-guy-harvard-claudine-gay-1234943020/">Bill Ackman</a> shared his opinion of the company’s future. “If I still shorted stocks, I would short United Healthcare,” he posted to X on Tuesday, adding that the SEC “should do a thorough investigation of the company.” He further mused, “I would not be surprised to find that the company’s profitability is massively overstated due to its denial of medically necessary procedures and patient care.” 

</p>



<p>
	Ackman later deleted the speculation, but UnitedHealth <a href="https://www.ft.com/content/ae98e904-748b-4012-b36f-b5c323de4317" rel="nofollow" target="_blank">flagged his comments to the SEC</a> for potential investigation. The company’s stock price dipped the following day, and ended the week about 2.7 percent lower than it was on Tuesday. “Health insurance has long been subject to significant regulatory oversight and earnings caps,” UnitedHealth said in a statement responding to the outspoken investor, one of many ultra-wealthy figures to back Trump in 2024 and post prolifically on social media about how only the MAGA movement could save the country. “Any claims that health insurers, which typically have low- to mid-single digit margins, can somehow over-earn are grossly uninformed about the structure and strong regulatory oversight of the sector,” the company noted.

	</p>




<p>
	All told, UnitedHealth is mounting a far stronger defense of its reputation than it two months ago, when Thompson’s slaying unleashed a flood of hostility that caught it somewhat off-guard. Now, the company looks like it’s prepared to grind it out as Mangione’s parallel state and federal trials get underway, with heated rhetoric likely to flare up once again.</p>
















</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LIMO: Less Is More for Reasoning (319 pts)]]></title>
            <link>https://arxiv.org/abs/2502.03387</link>
            <guid>42991676</guid>
            <pubDate>Sun, 09 Feb 2025 16:33:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2502.03387">https://arxiv.org/abs/2502.03387</a>, See on <a href="https://news.ycombinator.com/item?id=42991676">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2502.03387">View PDF</a>
    <a href="https://arxiv.org/html/2502.03387v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We present a fundamental discovery that challenges our understanding of how complex reasoning emerges in large language models. While conventional wisdom suggests that sophisticated reasoning tasks demand extensive training data (&gt;100,000 examples), we demonstrate that complex mathematical reasoning abilities can be effectively elicited with surprisingly few examples. Through comprehensive experiments, our proposed model LIMO demonstrates unprecedented performance in mathematical reasoning. With merely 817 curated training samples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving from previous SFT-based models' 6.5% and 59.2% respectively, while only using 1% of the training data required by previous approaches. LIMO demonstrates exceptional out-of-distribution generalization, achieving 40.5% absolute improvement across 10 diverse benchmarks, outperforming models trained on 100x more data, challenging the notion that SFT leads to memorization rather than generalization. Based on these results, we propose the Less-Is-More Reasoning Hypothesis (LIMO Hypothesis): In foundation models where domain knowledge has been comprehensively encoded during pre-training, sophisticated reasoning capabilities can emerge through minimal but precisely orchestrated demonstrations of cognitive processes. This hypothesis posits that the elicitation threshold for complex reasoning is determined by two key factors: (1) the completeness of the model's encoded knowledge foundation during pre-training, and (2) the effectiveness of post-training examples as "cognitive templates" that show the model how to utilize its knowledge base to solve complex reasoning tasks. To facilitate reproducibility and future research in data-efficient reasoning, we release LIMO as a comprehensive open-source suite at <a href="https://github.com/GAIR-NLP/LIMO" rel="external noopener nofollow">this https URL</a>.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Zhen Huang [<a href="https://arxiv.org/show-email/43e4049b/2502.03387" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Wed, 5 Feb 2025 17:23:45 UTC (8,774 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Advanced Magnet Manufacturing Begins in the United States (117 pts)]]></title>
            <link>https://spectrum.ieee.org/advanced-magnet-manufacturing-in-us</link>
            <guid>42991558</guid>
            <pubDate>Sun, 09 Feb 2025 16:17:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/advanced-magnet-manufacturing-in-us">https://spectrum.ieee.org/advanced-magnet-manufacturing-in-us</a>, See on <a href="https://news.ycombinator.com/item?id=42991558">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Advanced Magnet Manufacturing Begins in the United States"><p>In mid-January, a top <a href="https://spectrum.ieee.org/tag/united-states">United States</a> materials company announced that it had started to manufacture rare earth magnets. It was important news—there are no large U.S. makers of the <a href="https://spectrum.ieee.org/tag/neodymium">neodymium</a> magnets that underpin huge and vitally important commercial and defense industries, including <a href="https://spectrum.ieee.org/tag/electric-vehicles">electric vehicles</a>. But it created barely a ripple during a particularly loud and stormy time in U.S. trade relations.</p><p>The press release, from <a href="https://mpmaterials.com/" rel="noopener noreferrer" target="_blank">MP Materials</a>, was light on details. The company disclosed that it had started producing the magnets, called neodymium-iron-boron (NdFeB), on a “trial” basis and that the factory would begin gradually ramping up production before the end of this year. According to MP’s spokesman, Matt Sloustcher, the facility will have an initial capacity of 1,000 tonnes per annum, and has the infrastructure in place to scale up to 2,000 to 3,000 tonnes per year. The release also said that the facility, in Fort Worth, Texas, would supply magnets to <a href="https://spectrum.ieee.org/tag/general-motors">General Motors</a> and other U.S. manufacturers.</p><p><a href="https://spectrum.ieee.org/the-men-who-made-the-magnet-that-made-the-modern-world" target="_blank">NdFeB magnets</a> are the most powerful and valuable type. They are used in <a href="https://spectrum.ieee.org/tag/motors">motors</a> for <a href="https://spectrum.ieee.org/search/?q=electric+vehicles" target="_blank">electric vehicles</a> and for heating, ventilating, and cooling (<a href="https://spectrum.ieee.org/tag/hvac">HVAC</a>) systems, in wind-turbine generators, in tools and <a href="https://spectrum.ieee.org/tag/appliances">appliances</a>, and in audio speakers, among other gear. They are also critical components of countless <a href="https://spectrum.ieee.org/tag/military-systems">military systems</a> and platforms, including fighter and bomber aircraft, <a href="https://spectrum.ieee.org/submarine-stealth" target="_blank">submarines</a>, precision guided <a href="https://spectrum.ieee.org/tag/weapons">weapons</a>, night-vision systems, and radars.</p><h2>A magnet manufacturing surge fueled by Defense dollars</h2><p data-rm-resized-container="25%"><img alt="Front view of a sleek building with several large glass walls." data-rm-shortcode-id="a18794169476bd0ef3148a15c8848fc6" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/front-view-of-a-sleek-building-with-several-large-glass-walls.jpg?id=56224197&amp;width=980" height="3992" id="91f39" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/front-view-of-a-sleek-building-with-several-large-glass-walls.jpg?id=56224197&amp;width=980" width="5323"><small placeholder="Add Photo Caption...">MP Materials’ has named its new, state-of-the-art magnet manufacturing facility Independence.</small><small placeholder="Add Photo Credit...">Business Wire</small></p><p>The Texas facility, which <a data-linked-post="2670490876" href="https://spectrum.ieee.org/rare-earth-elements-2670490876" target="_blank">MP Materials</a> has named Independence, is not the only major rare-earth-magnet project in the U.S. Most notably, Vacuumschmelze GmbH, a magnet maker based in Hanau, <a href="https://spectrum.ieee.org/tag/germany">Germany</a>, has begun constructing a plant in South Carolina through a North American subsidiary, <a href="https://evac-magnetics.com/" rel="noopener noreferrer" target="_blank">e-VAC Magnetics</a>. To build the <a href="https://www.plantservices.com/industry-news/news/33038696/e-vac-to-build-rare-earth-permanent-magnet-manufacturing-plant-in-south-carolina" rel="noopener noreferrer" target="_blank">US $500 million</a> factory, the company secured <a href="https://www.argusmedia.com/en/news-and-insights/latest-market-news/2605425-e-vac-secures-335mn-for-us-permanent-magnet-plant" rel="noopener noreferrer" target="_blank">$335 million</a> in outside funds, including at least $100 million from the U.S. government. (E-VAC, too, has touted a supply agreement with General Motors for its future magnets.)</p><p>In another intriguing U.S. rare-earth magnet project, <a href="https://noveon.co/" rel="noopener noreferrer" target="_blank">Noveon Magnetics</a>, in San Marcos, Texas, is currently producing what it claims are “commercial quantities” of <a href="https://spectrum.ieee.org/the-men-who-made-the-magnet-that-made-the-modern-world" target="_blank">NdFeB magnets</a>. However, the company is not making the magnets in the standard way, starting with metal alloys, but rather in a unique process based on <a href="https://spectrum.ieee.org/tag/recycling">recycling</a> the materials from discarded magnets. <a href="https://www.usare.com/" rel="noopener noreferrer" target="_blank">USA Rare Earth</a>&nbsp;<a href="https://www.mining.com/usa-rare-earth-produces-first-batch-of-magnets-at-oklahoma-plant/" rel="noopener noreferrer" target="_blank">announced on 8 January</a> that it had manufactured a small amount of NdFeB magnets at a plant in Stillwater, Oklahoma.</p><p>Yet another company, Quadrant Magnetics, announced in January, 2022, that it would begin construction on a $100 million NdFeB magnet factory in Louisville, Kentucky. However, 11 months later, U.S. federal agents <a href="http://rnal.com/story/news/local/2023/11/27/quadrant-magnetics-where-things-stand-case-alleges-company-sent-military-data-to-china/71141970007/" rel="noopener noreferrer" target="_blank">arrested three of the company’s top executives</a>, charging them with passing off Chinese-made magnets as locally produced and giving confidential U.S. military data to Chinese agencies.</p><p>The multiple US neodymium-magnet projects are noteworthy but even collectively they won’t make a noticeable dent in China’s dominance. “Let me give you a reality check,” says <a href="https://magmatllc.com/about.html" rel="noopener noreferrer" target="_blank">Steve Constantinides</a>, an IEEE member and magnet-industry consultant based in Honeoye, N.Y. “The total production of neo magnets was somewhere between 220 and 240 thousand tonnes in 2024,” he says, adding that 85 percent of the total, at least, was produced in <a href="https://spectrum.ieee.org/tag/China">China</a>. And “the 15 percent that was not made in China was made in <a href="https://spectrum.ieee.org/tag/japan">Japan</a>, primarily, or in Vietnam.” (Other estimates put China’s share of the neodymium magnet market as high as 90 percent.)</p><p>But look at the figures from a different angle, suggests MP Materials’s Sloustcher. “The U.S. imports just 7,000 tonnes of NdFeB magnets per year,” he points out. “So in total, these [U.S.] facilities can supplant a significant percentage of U.S. imports, help re-start an industry, and scale as the production of motors and other magnet-dependent industries” returns to the United States, he argues.</p><p>And yet, it’s hard not to be a little awed by China’s supremacy. The country has some 300 manufacturers of rare-earth <a href="https://spectrum.ieee.org/tag/permanent-magnets">permanent magnets</a>, according to Constantinides. The largest of these, <a href="https://www.jlmag.com.cn/en/" rel="noopener noreferrer" target="_blank">JL MAG Rare-Earth Co. Ltd</a>., in Ganzhou, produced at least 25,000 tonnes of neodymium magnets last year, Constantinides figures. (The company recently announced that it was building another facility, to begin operating in 2026, that it says will bring its installed capacity to 60,000 tonnes a year.)</p><p>That 25,000 tonnes figure is comparable to the combined output of <em>all</em> of the rare-earth magnet makers that <a href="https://www.fastmarkets.com/insights/rare-earth-magnet-production-outside-asia-gearing-up-2024-preview/" rel="noopener noreferrer" target="_blank">aren’t in China</a>. The $500-million e-VAC plant being built in South Carolina, for example, is reportedly designed to produce around <a href="https://investornews.com/critical-minerals-rare-earths/a-landmark-moment-u-s-dept-of-defense-makes-bold-moves-in-rare-earth-magnet-manufacturing/" rel="noopener noreferrer" target="_blank">1,500 tonnes</a> a year.</p><p>But even those numbers do not fully convey China’s dominance of permanent magnet manufacturing. Where ever a factory is, making neodymium magnets requires supplies of rare-earth metal, and that nearly always leads straight back to China. “Even though they only produce, say, 85 percent of the magnets, they are producing 97 percent of the metal” in the world, says Constantinides. “So the magnet manufacturers in Japan and Europe are highly dependent on the rare-earth metal coming from China.”</p><h2>MP’s Mine-to-Manufacturing stragegy</h2><p>And there, at least, <a href="https://spectrum.ieee.org/tag/mp-materials">MP Materials</a> may have an interesting edge. Hardly any firms, even in China, do what MP is attempting: produce finished magnets starting with ore that the company mines itself. Even large companies typically perform just one or at most two of the four major steps along the path to making a rare-earth magnet: <a href="https://spectrum.ieee.org/tag/mining">mining</a> the ore, refining the ore into rare-earth oxides, reducing the oxides to metals, and then, finally, using the metals to make magnets. Each step is an enormous undertaking requiring entirely different equipment, processes, knowledge, and skill sets.</p><p><img alt="Close-up of stacked bricks of a brownish, slightly iridescent material." data-rm-shortcode-id="28d666110c15828f28899a067ef56942" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/close-up-of-stacked-bricks-of-a-brownish-slightly-iridescent-material.jpg?id=56224494&amp;width=980" height="1875" id="8d421" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/close-up-of-stacked-bricks-of-a-brownish-slightly-iridescent-material.jpg?id=56224494&amp;width=980" width="3000"><small placeholder="Add Photo Caption...">The <a href="https://spectrum.ieee.org/tag/rare-earth-metal">rare earth metal</a> produced at MP Materials’ magnet manufacturing facility in Fort Worth, Texas, consists of mostly neodymium and praseodymium.</small><small placeholder="Add Photo Credit...">Business Wire</small></p><p>“The one advantage they get from [doing it all] is that they get better insights into how different markets are actually growing,” says <a href="https://www.linkedin.com/in/stantrout/" target="_blank">Stan Trout</a>, a magnet industry consultant in Denver, Colorado. “Getting the timing right on any expansion is important,” Trout adds. “And so MP should be getting that information as well as anybody, with the different plants that they have, because they interact with the market in several different ways and can really see what demand is like in real time, rather than as some projection in a forecast.”</p><p>Still, it’s going to be an uphill climb. “There’s are a lot of both hard and soft subsidies in the <a href="https://spectrum.ieee.org/tag/supply-chain">supply chain</a> in China,” says John Ormerod, an industry consultant based in Knoxville, Tenn. “It’s going to be difficult for a US manufacturer to compete with the current price levels of Chinese-made magnets,” he concludes.</p><p>And it’s not going to get better any time soon. China’s rare-earth magnet makers are only using about 60 percent of their production capacity, according to both Constantinides and Ormerod—and yet they are continuing to build new plants. “There’s going to be roughly 500,000 tonnes of capacity by the end of this year,” says Ormerod, citing figures gathered by Singapore-based analyst <a href="https://www.linkedin.com/in/tkruemmer/?originalSubdomain=sg" rel="noopener noreferrer" target="_blank">Thomas Kruemmer</a>. “The demand is only about 50 percent of that.”</p><p>The upshot, all of the analysts agree, will be downward price pressure on <a href="https://spectrum.ieee.org/search/?q=rare+earth+magnets" target="_blank">rare earth magnets</a> in the near future, at least. At the same time, the U.S. <a href="https://spectrum.ieee.org/tag/department-of-defense">Department of Defense</a> has made it a requirement that rare-earth magnets for its systems must be produced entirely, starting with ore, in “friendly” countries—which does not include China. “The DoD will need to pay a premium over cheaper imported magnets to establish a price floor enabling domestic U.S. producers to successfully and continuously supply the DoD,” says Constantinides.</p><p>But is what’s good for America good for General Motors, in this case? We’re all going to find out in a year or two. At the moment, few analysts are bullish on the prospect.</p><p>“The automotive industry has been extremely cost-conscious, demanding supplier price reductions of even fractions of a cent per piece,” notes Constantinides. And even the Trump administration’s tariffs are unlikely to alter the basic math of market economics, he adds. “The application of tariffs to magnets in an attempt to ‘level the playing field’ incentivizes companies to find work-arounds, such as exporting magnets from China to <a href="https://spectrum.ieee.org/tag/malaysia">Malaysia</a> or <a href="https://spectrum.ieee.org/tag/mexico">Mexico</a>, then re-exporting from there to the USA. This is not theoretical, these work-arounds have been used for decades to avoid even the past or existing low tariff rates of about 3.5 percent.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kanata: Cross-platform multi-layer keyboard remapper with advanced customization (133 pts)]]></title>
            <link>https://github.com/jtroo/kanata</link>
            <guid>42991019</guid>
            <pubDate>Sun, 09 Feb 2025 14:52:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jtroo/kanata">https://github.com/jtroo/kanata</a>, See on <a href="https://news.ycombinator.com/item?id=42991019">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Kanata</h2><a id="user-content-kanata" aria-label="Permalink: Kanata" href="#kanata"></a></p>
<div dir="auto"><h3 tabindex="-1" dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/jtroo/kanata/blob/main/assets/kanata-icon.svg"><img alt="Image of a keycap with the letter K on it in pink tones" title="Kanata" height="160" src="https://github.com/jtroo/kanata/raw/main/assets/kanata-icon.svg"></a>
</h3><a id="user-content---" aria-label="Permalink: " href="#--"></a></div>
<p>
  Improve your keyboard comfort
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What does this do?</h2><a id="user-content-what-does-this-do" aria-label="Permalink: What does this do?" href="#what-does-this-do"></a></p>
<p dir="auto">This is a cross-platform software keyboard remapper for Linux, macOS and Windows.
A short summary of the features:</p>
<ul dir="auto">
<li>multiple layers of key functionality</li>
<li>advanced key behaviour customization (e.g. tap-hold, macros, unicode)</li>
</ul>
<p dir="auto">To see all of the features, see the <a href="https://github.com/jtroo/kanata/blob/main/docs/config.adoc">configuration guide</a>.</p>
<p dir="auto">You can find pre-built binaries in the <a href="https://github.com/jtroo/kanata/releases">releases page</a>
or read on for build instructions.</p>
<p dir="auto">You can see a <a href="https://github.com/jtroo/kanata/blob/main/docs/platform-known-issues.adoc">list of known issues here</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Demo</h3><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Demo video</h4><a id="user-content-demo-video" aria-label="Permalink: Demo video" href="#demo-video"></a></p>
<p dir="auto"><a href="https://user-images.githubusercontent.com/6634136/183001314-f64a7e26-4129-4f20-bf26-7165a6e02c38.mp4" rel="nofollow">Showcase of multi-layer functionality (30s, 1.7 MB)</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Online simulator</h4><a id="user-content-online-simulator" aria-label="Permalink: Online simulator" href="#online-simulator"></a></p>
<p dir="auto">You can check out the <a href="https://jtroo.github.io/" rel="nofollow">online simulator</a>
to test configuration validity and test input simulation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why is this useful?</h2><a id="user-content-why-is-this-useful" aria-label="Permalink: Why is this useful?" href="#why-is-this-useful"></a></p>
<p dir="auto">Imagine if, instead of pressing Shift to type uppercase letters, we had giant
keyboards with separate keys for lowercase and uppercase letters. I hope we can
all agree: that would be a terrible user experience!</p>
<p dir="auto">A way to think of how Shift keys work is that they switch your input to another
layer of functionality where you now type uppercase letters and symbols
instead of lowercase letters and numbers.</p>
<p dir="auto">What kanata allows you to do is take this alternate layer concept that Shift
keys have and apply it to any key. You can then customize what those layers do
to suit your exact needs and workflows.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Running kanata currently does not start it in a background process.
You will need to keep the window that starts kanata running to keep kanata active.
Some tips for running kanata in the background:</p>
<ul dir="auto">
<li>Windows: <a data-error-text="Failed to load title" data-id="4579845" data-permission-text="Title is private" data-url="https://github.com/jtroo/kanata/discussions/193" data-hovercard-type="discussion" data-hovercard-url="/jtroo/kanata/discussions/193/hovercard" href="https://github.com/jtroo/kanata/discussions/193">#193</a></li>
<li>Linux: <a data-error-text="Failed to load title" data-id="4373258" data-permission-text="Title is private" data-url="https://github.com/jtroo/kanata/discussions/130" data-hovercard-type="discussion" data-hovercard-url="/jtroo/kanata/discussions/130/hovercard?comment_id=10227272" href="https://github.com/jtroo/kanata/discussions/130#discussioncomment-10227272">#130 (reply in thread)</a></li>
<li>Run from tray icon: <a href="https://github.com/rszyma/kanata-tray">kanata-tray</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pre-built executables</h3><a id="user-content-pre-built-executables" aria-label="Permalink: Pre-built executables" href="#pre-built-executables"></a></p>
<p dir="auto">See the
<a href="https://github.com/jtroo/kanata/releases">releases page</a>
for executables and instructions.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build it yourself</h3><a id="user-content-build-it-yourself" aria-label="Permalink: Build it yourself" href="#build-it-yourself"></a></p>
<p dir="auto">This project uses the latest Rust stable toolchain. If you installed the
Rust toolchain using <code>rustup</code>, e.g. by using the instructions from the
<a href="https://www.rust-lang.org/learn/get-started" rel="nofollow">official website</a>,
you can get the latest stable toolchain with <code>rustup update stable</code>.</p>
<details>
<summary>Instructions</summary>
<p dir="auto">Using <code>cargo install</code>:</p>
<div data-snippet-clipboard-copy-content="cargo install kanata

# On Linux and macOS, this may not work without `sudo`, see below
kanata --cfg <your_configuration_file>"><pre><code>cargo install kanata

# On Linux and macOS, this may not work without `sudo`, see below
kanata --cfg &lt;your_configuration_file&gt;
</code></pre></div>
<p dir="auto">Build and run yourself in Linux:</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/jtroo/kanata &amp;&amp; cd kanata
cargo build   # --release optional, not really perf sensitive

# sudo is used because kanata opens /dev/ files
#
# See below if you want to avoid needing sudo:
# https://github.com/jtroo/kanata/wiki/Avoid-using-sudo-on-Linux
sudo target/debug/kanata --cfg <your_configuration_file>"><pre><code>git clone https://github.com/jtroo/kanata &amp;&amp; cd kanata
cargo build   # --release optional, not really perf sensitive

# sudo is used because kanata opens /dev/ files
#
# See below if you want to avoid needing sudo:
# https://github.com/jtroo/kanata/wiki/Avoid-using-sudo-on-Linux
sudo target/debug/kanata --cfg &lt;your_configuration_file&gt;
</code></pre></div>
<p dir="auto">Build and run yourself in Windows.</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/jtroo/kanata; cd kanata
cargo build   # --release optional, not really perf sensitive
target\debug\kanata --cfg <your_configuration_file>"><pre><code>git clone https://github.com/jtroo/kanata; cd kanata
cargo build   # --release optional, not really perf sensitive
target\debug\kanata --cfg &lt;your_configuration_file&gt;
</code></pre></div>
<p dir="auto">Build and run yourself in macOS:</p>
<p dir="auto">For macOS version 11 and newer: Install the <a href="https://github.com/pqrs-org/Karabiner-DriverKit-VirtualHIDDevice/blob/main/dist/Karabiner-DriverKit-VirtualHIDDevice-5.0.0.pkg">Karabiner VirtualHiDDevice Driver</a>.</p>
<p dir="auto">To activate it:</p>
<p dir="auto"><code>/Applications/.Karabiner-VirtualHIDDevice-Manager.app/Contents/MacOS/Karabiner-VirtualHIDDevice-Manager activate</code></p>
<p dir="auto">For macOS version 10 and older:
Install the <a href="https://github.com/pqrs-org/Karabiner-VirtualHIDDevice">Karabiner kernel extension</a>.</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/jtroo/kanata &amp;&amp; cd kanata
cargo build   # --release optional, not really perf sensitive

# sudo is needed to gain permission to intercept the keyboard

sudo target/debug/kanata --cfg <your_configuration_file>"><pre><code>git clone https://github.com/jtroo/kanata &amp;&amp; cd kanata
cargo build   # --release optional, not really perf sensitive

# sudo is needed to gain permission to intercept the keyboard

sudo target/debug/kanata --cfg &lt;your_configuration_file&gt;
</code></pre></div>
<p dir="auto">The full configuration guide is <a href="https://github.com/jtroo/kanata/blob/main/docs/config.adoc">found here</a>.</p>
<p dir="auto">Sample configuration files are found in <a href="https://github.com/jtroo/kanata/blob/main/cfg_samples">cfg_samples</a>. The
<a href="https://github.com/jtroo/kanata/blob/main/cfg_samples/simple.kbd">simple.kbd</a> file contains a basic configuration file
that is hopefully easy to understand but does not contain all features. The
<code>kanata.kbd</code> contains an example of all features with documentation. The
release assets also have a <code>kanata.kbd</code> file that is tested to work with that
release. All key names can be found in the <a href="https://github.com/jtroo/kanata/blob/main/src/keys/mod.rs">keys module</a>,
and you can also define your own key names.</p>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Feature flags</h3><a id="user-content-feature-flags" aria-label="Permalink: Feature flags" href="#feature-flags"></a></p>
<p dir="auto">When either building yourself or using <code>cargo install</code>,
you can add feature flags that
enable functionality that is turned off by default.</p>
<details>
<summary>Instructions</summary>
<p dir="auto">If you want to enable the <code>cmd</code> actions,
add the flag <code>--features cmd</code>.
For example:</p>
<div data-snippet-clipboard-copy-content="cargo build --release --features cmd
cargo install --features cmd"><pre><code>cargo build --release --features cmd
cargo install --features cmd
</code></pre></div>
<p dir="auto">On Windows,
if you want to compile a binary that uses the Interception driver,
you should add the flag <code>--features interception_driver</code>.
For example:</p>
<div data-snippet-clipboard-copy-content="cargo build --release --features interception_driver
cargo install --features interception_driver"><pre><code>cargo build --release --features interception_driver
cargo install --features interception_driver
</code></pre></div>
<p dir="auto">To combine multiple flags,
use a single <code>--features</code> flag
and use a comma to separate the features.
For example:</p>
<div data-snippet-clipboard-copy-content="cargo build --release --features cmd,interception_driver
cargo install --features cmd,interception_driver"><pre><code>cargo build --release --features cmd,interception_driver
cargo install --features cmd,interception_driver
</code></pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Other installation methods</h2><a id="user-content-other-installation-methods" aria-label="Permalink: Other installation methods" href="#other-installation-methods"></a></p>
<p dir="auto"><a href="https://repology.org/project/kanata/versions" rel="nofollow"><img src="https://camo.githubusercontent.com/aef8ac9aeb0281c0151e86b957de11ecc4d7e8836c58999b8020744f6f22a3bc/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f766572746963616c2d616c6c7265706f732f6b616e6174612e737667" alt="Packaging status" data-canonical-src="https://repology.org/badge/vertical-allrepos/kanata.svg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Notable features</h2><a id="user-content-notable-features" aria-label="Permalink: Notable features" href="#notable-features"></a></p>
<ul dir="auto">
<li>Human-readable configuration file.
<ul dir="auto">
<li><a href="https://github.com/jtroo/kanata/blob/main/cfg_samples/minimal.kbd">Minimal example</a></li>
<li><a href="https://github.com/jtroo/kanata/blob/main/docs/config.adoc">Full guide</a></li>
<li><a href="https://github.com/jtroo/kanata/blob/main/cfg_samples/simple.kbd">Simple example with explanations</a></li>
<li><a href="https://github.com/jtroo/kanata/blob/main/cfg_samples/kanata.kbd">All features showcase</a></li>
</ul>
</li>
<li>Live reloading of the configuration for easy testing of your changes.</li>
<li>Multiple layers of key functionality</li>
<li>Advanced actions such as tap-hold, unicode output, dynamic and static macros</li>
<li>Vim-like leader sequences to execute other actions</li>
<li>Optionally run a TCP server to interact with other programs
<ul dir="auto">
<li>Other programs can respond to <a href="https://github.com/jtroo/kanata/issues/47" data-hovercard-type="issue" data-hovercard-url="/jtroo/kanata/issues/47/hovercard">layer changes or trigger layer changes</a></li>
</ul>
</li>
<li><a href="https://web.archive.org/web/20240209172129/http://www.oblita.com/interception" rel="nofollow">Interception driver</a> support (use <code>kanata_wintercept.exe</code>)
<ul dir="auto">
<li>Note that this issue exists, which is outside the control of this project:
<a data-error-text="Failed to load title" data-id="138779117" data-permission-text="Title is private" data-url="https://github.com/oblitum/Interception/issues/25" data-hovercard-type="issue" data-hovercard-url="/oblitum/Interception/issues/25/hovercard" href="https://github.com/oblitum/Interception/issues/25">oblitum/Interception#25</a></li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions are welcome!</p>
<p dir="auto">Unless explicitly stated otherwise, your contributions to kanata will be made
under the LGPL-3.0-only<a href="https://www.gnu.org/licenses/identify-licenses-clearly.html" rel="nofollow">*</a> license.</p>
<p dir="auto">Some directories are exceptions:</p>
<ul dir="auto">
<li><a href="https://github.com/jtroo/kanata/blob/main/keyberon">keyberon</a>: MIT License</li>
<li><a href="https://github.com/jtroo/kanata/blob/main/interception">interception</a>: MIT or Apache-2.0 Licenses</li>
</ul>
<p dir="auto"><a href="https://github.com/jtroo/kanata/blob/main/docs/design.md">Here's a basic low-effort design doc of kanata</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How you can help</h2><a id="user-content-how-you-can-help" aria-label="Permalink: How you can help" href="#how-you-can-help"></a></p>
<ul dir="auto">
<li>Try it out and let me know what you think. Feel free to file an issue or
start a discussion.</li>
<li>Usability issues and unhelpful error messages are considered bugs that should
be fixed. If you encounter any, I would be thankful if you file an issue.</li>
<li>Browse the open issues and help out if you are able and/or would like to. If
you want to try contributing, feel free to ping jtroo for some pointers.</li>
<li>If you know anything about writing a keyboard driver for Windows, starting an
open-source alternative to the Interception driver would be lovely.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community projects related to kanata</h2><a id="user-content-community-projects-related-to-kanata" aria-label="Permalink: Community projects related to kanata" href="#community-projects-related-to-kanata"></a></p>
<ul dir="auto">
<li><a href="https://github.com/rszyma/vscode-kanata">vscode-kanata</a>: Language support for kanata configuration files in VS Code</li>
<li><a href="https://github.com/LGUG2Z/komokana">komokana</a>: Automatic application-aware layer switching for <a href="https://github.com/LGUG2Z/komorebi"><code>komorebi</code></a> (Windows)</li>
<li><a href="https://github.com/rszyma/kanata-tray">kanata-tray</a>: Control kanata from a tray icon</li>
<li>Application-aware layer switching:
<ul dir="auto">
<li><a href="https://github.com/veyxov/qanata">qanata (Linux)</a></li>
<li><a href="https://github.com/Aqaao/kanawin">kanawin (Windows)</a></li>
<li><a href="https://github.com/reidprichard/window_tools">window_tools (Windows)</a></li>
<li><a href="https://github.com/mdSlash/nata">nata (Linux)</a></li>
<li><a href="https://github.com/devsunb/kanata-vk-agent">kanata-vk-agent (macOS)</a></li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">What does the name mean?</h2><a id="user-content-what-does-the-name-mean" aria-label="Permalink: What does the name mean?" href="#what-does-the-name-mean"></a></p>
<p dir="auto">I wanted a "k" word since this relates to keyboards. According to Wikipedia,
kanata is an indigenous Iroquoian word meaning "village" or "settlement" and is
the origin of Canada's name.</p>
<p dir="auto">There's also PPT✧.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Motivation</h2><a id="user-content-motivation" aria-label="Permalink: Motivation" href="#motivation"></a></p>
<p dir="auto">TLDR: QMK features but for any keyboard, not just fancy mechanical ones.</p>
<details>
  <summary>Long version</summary>
<p dir="auto">I have a few keyboards that run <a href="https://docs.qmk.fm/#/" rel="nofollow">QMK</a>. QMK allows the
user to customize the functionality of their keyboard to their heart's content.</p>
<p dir="auto">One great use case of QMK is its ability map keys so that they overlap with the
home row keys but are accessible on another layer. I won't comment on
productivity, but I find this greatly helps with my keyboard comfort.</p>
<p dir="auto">For example, these keys are on the right side of the keyboard:</p>

<p dir="auto">On one layer I have arrow keys in the same position, and on another layer I
have a numpad.</p>
<div data-snippet-clipboard-copy-content="arrows:       numpad:
- - -         7 8 9
- ↑ -         4 5 6
← ↓ →         1 2 3
- - -         0 * ."><pre><code>arrows:       numpad:
- - -         7 8 9
- ↑ -         4 5 6
← ↓ →         1 2 3
- - -         0 * .
</code></pre></div>
<p dir="auto">One could add as many customizations as one likes to improve comfort, speed,
etc. Personally my main motivator is comfort due to a repetitive strain injury
in the past.</p>
<p dir="auto">However, QMK doesn't run everywhere. In fact, it doesn't run on <strong>most</strong>
hardware you can get. You can't get it to run on a laptop keyboard or any
mainstream office keyboard. I believe that the comfort and empowerment QMK
provides should be available to anyone with a computer on their existing
hardware, instead of having to purchase an enthusiast mechanical keyboard
(which are admittedly very nice — I own a few — but can be costly).</p>
<p dir="auto">The best alternative solution that I found for keyboards that don't run QMK was
<a href="https://github.com/kmonad/kmonad">kmonad</a>. This is an excellent project
and I recommend it if you want to try something similar.</p>
<p dir="auto">The reason for this project's existence is that kmonad is written in Haskell
and I have no idea how to begin contributing to a Haskell project. From an
outsider's perspective I think Haskell is a great language but I really can't
wrap my head around it. And there are a few <a href="https://github.com/jtroo/kanata/blob/main/docs/kmonad_comparison.md">outstanding issues</a>
at the time of writing that make kmonad suboptimal for my personal workflows.</p>
<p dir="auto">This project is written in Rust because Rust is my favourite programming
language and the prior work of the awesome <a href="https://github.com/TeXitoi/keyberon">keyberon crate</a>
exists.</p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Similar Projects</h2><a id="user-content-similar-projects" aria-label="Permalink: Similar Projects" href="#similar-projects"></a></p>
<p dir="auto">The most similar project is <a href="https://github.com/kmonad/kmonad">kmonad</a>,
which served as the inspiration for kanata. <a href="https://github.com/jtroo/kanata/blob/main/docs/kmonad_comparison.md">Here's a comparison document</a>.
Other similar projects:</p>
<ul dir="auto">
<li><a href="https://docs.qmk.fm/#/" rel="nofollow">QMK</a>: Open source keyboard firmware</li>
<li><a href="https://github.com/TeXitoi/keyberon">keyberon</a>: Rust <code>#[no_std]</code> library intended for keyboard firmware</li>
<li><a href="https://github.com/ItayGarin/ktrl">ktrl</a>: Linux-only keyboard customizer with layers, a TCP server, and audio support</li>
<li><a href="https://github.com/timokroeger/kbremap">kbremap</a>: Windows-only keyboard customizer with layers and unicode</li>
<li><a href="https://github.com/alols/xcape">xcape</a>: Linux-only tap-hold modifiers</li>
<li><a href="https://karabiner-elements.pqrs.org/" rel="nofollow">karabiner-elements</a>: Mac-only keyboard customizer</li>
<li><a href="https://github.com/cajhin/capsicain">capsicain</a>: Windows-only key remapper with driver-level key interception</li>
<li><a href="https://github.com/rvaiya/keyd">keyd</a>: Linux-only key remapper very similar to QMK, kmonad, and kanata</li>
<li><a href="https://github.com/k0kubun/xremap">xremap</a>: Linux-only application-aware key remapper inspired more by Emacs key sequences vs. QMK layers/Vim modes</li>
<li><a href="https://github.com/houmain/keymapper">keymapper</a>: Context-aware cross-platform key remapper with a different transformation model (Linux, Windows, Mac)</li>
<li><a href="https://github.com/jbensmann/mouseless">mouseless</a>: Linux-only mouse-focused key remapper that also has layers, key combo and tap-hold capabilities</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why the list?</h3><a id="user-content-why-the-list" aria-label="Permalink: Why the list?" href="#why-the-list"></a></p>
<p dir="auto">While kanata is the best tool for some, it may not be the best tool for
you. I'm happy to introduce you to tools that may better suit your needs. This
list is also useful as reference/inspiration for functionality that could be
added to kanata.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Donations/Support?</h2><a id="user-content-donationssupport" aria-label="Permalink: Donations/Support?" href="#donationssupport"></a></p>
<p dir="auto">The author (jtroo) will not accept monetary donations for work on kanata.
Please instead donate your time and/or money to charity.</p>
<p dir="auto">Some links are below. These links are provided for learning and as interesting
reads. They are <strong>not</strong> an endorsement.</p>
<ul dir="auto">
<li><a href="https://www.effectivealtruism.org/" rel="nofollow">https://www.effectivealtruism.org/</a></li>
<li><a href="https://www.givewell.org/" rel="nofollow">https://www.givewell.org/</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hard disk fraud: long runtimes on new Seagate hard disks (136 pts)]]></title>
            <link>https://www.heise.de/en/news/Hard-disk-fraud-Increasing-evidence-of-origin-in-China-10269059.html</link>
            <guid>42991006</guid>
            <pubDate>Sun, 09 Feb 2025 14:50:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.heise.de/en/news/Hard-disk-fraud-Increasing-evidence-of-origin-in-China-10269059.html">https://www.heise.de/en/news/Hard-disk-fraud-Increasing-evidence-of-origin-in-China-10269059.html</a>, See on <a href="https://news.ycombinator.com/item?id=42991006">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <!-- RSPEAK_STOP -->
          





<a-collapse has-indicator="">
  
  <div data-collapse-target="">
      
  <nav>
    <ol>
        
        <li>

          
            <span aria-current="page">
              Hard disk fraud: Increasing evidence of origin in China
            </span>

            
              <ul>
              
                <li>
                
                  <a href="#nav_cases_from_all__0" title="Cases from all over the world" data-google-interstitial="false">
                    Cases from all over the world
                  </a>
                
                </li>
              
                <li>
                
                  <a href="#nav_slabs_from_chia__1" title="Slabs from chia farms?" data-google-interstitial="false">
                    Slabs from chia farms?
                  </a>
                
                </li>
              
                <li>
                
                  <a href="#nav_warranty_far__2" title="Warranty far too short" data-google-interstitial="false">
                    Warranty far too short
                  </a>
                
                </li>
              
              </ul>
            

          

        </li>
    </ol>

    

    

  </nav>

    </div>
  
</a-collapse>


          <!-- RSPEAK_START -->

        <p>Recently, many online retailers have sent out Seagate hard disks as new that have already been running somewhere <a href="https://www.heise.de/news/Gebrauchte-Seagate-Festplatten-als-Neuware-im-Umlauf-10254276.html?from-en=1">for many</a>, <a href="https://www.heise.de/news/Betrug-mit-Seagate-Festplatten-Dutzende-Leser-melden-Verdachtsfaelle-10258657.html?from-en=1">many</a> <a href="https://www.heise.de/news/Festplatten-Betrug-Weitere-Haendler-betroffen-erste-Ruecknahmen-10264019.html?from-en=1">hours.</a> As yet unknown fraudsters had reset the SMART values of used drives and smuggled them back into distribution via equally unknown channels. Official Seagate dealers are also affected.</p>

    
  

  <!-- RSPEAK_STOP -->
  
  <a-paternoster height="360" media="(min-width: 320px) and (max-width: 767px)">
    

  

  </a-paternoster>
  <!-- RSPEAK_START -->



<p>However, Seagate server hard disks also log their runtimes and other parameters elsewhere: The so-called FARM values cannot (yet?) be reset by the fraudsters (FARM stands for Field Accessible Reliability Metrics). These can also be read out with the <a href="https://www.heise.de/download/product/smartmontools-56954">smartmontools</a> or the <a href="https://www.seagate.com/de/de/support/downloads/seatools/" rel="external noopener" target="_blank">Seagate Seatools</a>. According to the readers, the affected drives have been in operation for an average of around 25,000 hours.</p>
<h3 id="nav_cases_from_all__0">Cases from all over the world</h3>
<p>However, not only German customers are affected. We have received reports from Switzerland, Austria, Luxembourg, the UK, the Czech Republic and the USA. The online retailer East Digital from Hong Kong is also said to be sending out such drives. They have now sold out of the drives, but apparently they often have such “special offers” in their program. We have also seen forum entries from Australian East Digital customers who are now also experiencing long FARM runtimes.</p>
<p>We have also received reports from Japan that the case is being reported there. We are happy to receive further information <a href="mailto:ll@ct.de?subject=Festplatten-Betrug">by e-mail</a> –. If you prefer to remain anonymous, you can do so via our <a href="https://www.heise.de/investigativ/">anonymous mailbox</a>.</p>
<h3 id="nav_slabs_from_chia__1">Slabs from chia farms?</h3>
<p>Where the slabs came from and how they got to Germany is still unclear. However, many such used drives are said to be on sale in China at the moment. These could come from former <a href="https://www.heise.de/news/Kryptowaehrung-Chia-2-Exabyte-ueberschritten-und-erstmalig-handelbar-6037645.html?from-en=1">computing farms for the cryptocurrency Chia</a>, which are now being shut down as farming such coins is no longer profitable: The energy costs are now higher than the expected profit.</p>

  





<p>The available storage space in this network was initially <a href="https://www.heise.de/news/Kryptowaehrung-Chia-verursacht-Lieferprobleme-in-Asien-6045592.html?from-en=1">only a few exabytes</a>, but later rose sharply. Since the summer of 2024, the storage space in the Chia network has been decreasing, from around 34 exabytes at the time to around 19 exabytes now. The loss of around 15 exabytes corresponds to around one million hard disks with a gross capacity of 16 TByte. Not all of these will come from Seagate; however, the manufacturer currently has a share of more than 40 percent of the hard disk market. Roughly speaking, more than 400,000 used Seagate drives with 16 TByte could have been discarded from the Chia farms.</p>


  



  





<p>The message from an affected person in a forum fits in with this. When asked, Seagate stated that his hard disk was originally sold to a Chinese company from Mongolia. Seagate's German representative is not so forthcoming about the origin of the drives, citing data protection and assuring that the company is not involved in the scam.</p>
<h3 id="nav_warranty_far__2">Warranty far too short</h3>
<p>Some of the disks still have a few months of warranty left, but most of them have long since expired. Many were sold as part of a larger system – and therefore as so-called OEM disks, for which the manufacturer provides no warranty. If they were sold in a Dell system, for example, then Dell is responsible for the warranty processing in this system, it is effectively no longer a Seagate disk.</p>


<!-- RSPEAK_STOP -->

<!-- RSPEAK_START -->

<p>Many of our readers have complained, even long before these cases of fraud, about the practice of dealers selling OEM disks without a manufacturer's warranty. We therefore recommend that you visit the warranty inquiries of the dealers immediately after receiving a drive and check the status <a href="https://www.seagate.com/de/de/support/warranty-and-replacements/" rel="external noopener" target="_blank">(Seagate</a>, <a href="https://www.storrepair.com/toshiba_products/" rel="external noopener" target="_blank">Toshiba</a>, <a href="https://support-de.wd.com/app/Warranty_Status" rel="external noopener" target="_blank">Western Digital</a>). The serial number is sometimes already noted on the invoice and can otherwise be read through the anti-static packaging before it is opened; this also allows the production date to be identified. If this is several years in the past, caution is advised and a return is at least worth considering.</p>
<a-opt-in checkbox-text="Preisvergleiche immer laden" type="Preisvergleichinternetservices">
    <div>
      <h2>Empfohlener redaktioneller Inhalt</h2>
      <p>
    Mit Ihrer Zustimmung wird hier ein externer Preisvergleich (heise Preisvergleich) geladen.
  </p>
      <p><label>
            
            Preisvergleiche immer laden
          </label>
        
        
      </p>
      <p>
    Ich bin damit einverstanden, dass mir externe Inhalte angezeigt werden.
    Damit können personenbezogene Daten an Drittplattformen (heise Preisvergleich) übermittelt werden.
    Mehr dazu in unserer
    <a href="https://www.heise.de/Datenschutzerklaerung-der-Heise-Medien-GmbH-Co-KG-4860.html">Datenschutzerklärung</a>.
  </p>
      
    </div>
  </a-opt-in>


<p>

<!-- RSPEAK_STOP -->
<span>(<a href="mailto:ll@ct.de" title="Lutz Labs">ll</a>)</span>
<!-- RSPEAK_START -->
</p>
<div>
    <p>
      Don't miss any news – follow us on
      <a href="https://www.facebook.com/heiseonlineEnglish">Facebook</a>,
      <a href="https://www.linkedin.com/company/104691972">LinkedIn</a> or
      <a href="https://social.heise.de/@heiseonlineenglish">Mastodon</a>.
    </p>
    <p>
      <em>This article was originally published in
      
        <a href="https://www.heise.de/news/Festplatten-Betrug-Hinweise-auf-Ursprung-in-China-verdichten-sich-10268897.html">German</a>.
      
      It was translated with technical assistance and editorially reviewed before publication.</em>
    </p>
  </div>



        
        

        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Baffled by generational garbage collection – wingolog (113 pts)]]></title>
            <link>https://wingolog.org/archives/2025/02/09/baffled-by-generational-garbage-collection</link>
            <guid>42990819</guid>
            <pubDate>Sun, 09 Feb 2025 14:16:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wingolog.org/archives/2025/02/09/baffled-by-generational-garbage-collection">https://wingolog.org/archives/2025/02/09/baffled-by-generational-garbage-collection</a>, See on <a href="https://news.ycombinator.com/item?id=42990819">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Usually in this space I like to share interesting things that I find
out; you might call it a research-epistle-publish loop.  Today, though,
I come not with answers, but with questions, or rather one question, but
with fractal surface area: <i>what is the value proposition of
generational garbage collection?</i></p><h3>hypothesis</h3><p>The conventional wisdom is encapsulated in a 2004 Blackburn, Cheng, and
McKinley paper, <a href="https://www.steveblackburn.org/pubs/papers/mmtk-sigmetrics-2004.pdf">“Myths and Realities:  The Performance Impact of
Garbage
Collection”</a>,
which compares whole-heap mark-sweep and copying collectors to their
generational counterparts, using the Jikes RVM as a test harness.  (It
also examines a generational reference-counting collector, which is an
interesting predecessor to the 2022
<a href="https://www.steveblackburn.org/pubs/papers/lxr-pldi-2022.pdf">LXR</a> work
by Zhao, Blackburn, and McKinley.)</p><p>The paper finds that generational collectors spend less time than their
whole-heap counterparts for a given task.  This is mainly due to less
time spent collecting, because generational collectors avoid
tracing/copying work for older objects that mostly stay in the same
place in the live object graph.</p><p>The paper also notes an improvement for mutator time under generational
GC, but only for the generational mark-sweep collector, which it
attributes to the locality and allocation speed benefit of bump-pointer
allocation in the nursery.  However for copying collectors, generational
GC tends to slow down the mutator, probably because of the write
barrier, but in the end lower collector times still led to lower total
times.</p><p>So, I expected generational collectors to always exhibit lower
wall-clock times than whole-heap collectors.</p><h3>test workbench</h3><p>In <a href="https://github.com/wingo/whippet">whippet</a>, I have a garbage
collector with an abstract API that specializes at compile-time to the
mutator’s object and root-set representation and to the collector’s
allocator, write barrier, and other interfaces.  I embed it in
<a href="https://github.com/wingo/whiffle">whiffle</a>, a simple Scheme-to-C
compiler that can run some small multi-threaded benchmarks, for example
the classic Gabriel benchmarks.  We can then test those benchmarks
against different collectors, mutator (thread) counts, and heap sizes.
I expect that the generational parallel copying collector takes less
time than the whole-heap parallel copying collector.</p><h3>results?</h3><p>So, I ran some benchmarks.  Take the splay-tree benchmark, derived from
Octane’s
<a href="https://github.com/chromium/octane/blob/master/splay.js">splay.js</a>.  I
have a port to Scheme, and the results are... not good!</p><p><img src="https://wingolog.org/pub/splay.scm-generational-scalability-8.png"></p><p>In this graph the “pcc” series is the whole-heap copying collector, and
“generational-pcc” is the generational counterpart, with a nursery sized
such that after each collection, its size is 2 MB times the number of
active mutator threads in the last collector.  So, for this test with
eight threads, on my 8-core Ryzen 7 7840U laptop, the nursery is 16MB
including the copy reserve, which happens to be the same size as the L3
on this CPU.  New objects are kept in the nursery one cycle before being
promoted to the old generation.</p><p>There are also results for <a href="https://github.com/wingo/whippet/blob/main/doc/collector-mmc.md">“mmc” and “generational-mmc”
collectors</a>,
which use an Immix-derived algorithm that allows for bump-pointer
allocation but which doesn’t require a copy reserve.  There, the
generational collectors use a <a href="https://wingolog.org/archives/2022/10/22/the-sticky-mark-bit-algorithm">sticky mark-bit
algorithm</a>,
which has very different performance characteristics as promotion is
in-place, and the nursery is as large as the available heap size.</p><p>The salient point is that at all heap sizes, and for these two very
different configurations (mmc and pcc), generational collection takes
more time than whole-heap collection.  It’s not just the splay benchmark
either; I see the same thing for the very different <a href="https://wingolog.org/pub/nboyer.scm-5-generational-scalability-8.png">nboyer
benchmark</a>.
What is the deal?</p><p>I am honestly quite perplexed by this state of affairs.  I wish I had a
narrative to tie this together, but in lieu of that, voici some
propositions and observations.</p><h3>“generational collection is good because bump-pointer allocation”</h3><p>Sometimes people say that the reason generational collection is good is
because you get bump-pointer allocation, which has better locality and
allocation speed.  This is misattribution: it’s bump-pointer allocators
that have these benefits.  You can have them in whole-heap copying
collectors, or you can have them in whole-heap mark-compact or immix
collectors that bump-pointer allocate into the holes.  Or, true, you can
have them in generational collectors with a copying nursery but a
freelist-based mark-sweep allocator.  But also you can have generational
collectors without bump-pointer allocation, for free-list
sticky-mark-bit collectors.  To simplify this panorama to “generational
collectors have good allocators” is incorrect.</p><h3>“generational collection lowers pause times”</h3><p>It’s true, generational GC does lower median pause times:</p><p><img src="https://wingolog.org/pub/nboyer.scm-5-generational-p50-8.png"></p><p>But because a major collection is usually slightly more work under
generational GC than in a whole-heap system, because of e.g. the need to
reset remembered sets, the maximum pauses are just as big and even a
little bigger:</p><p><img src="https://wingolog.org/pub/nboyer.scm-5-generational-p100-8.png"></p><p>I am not even sure that it is meaningful to compare median pause times
between generational and non-generational collectors, given that the
former perform possibly orders of magnitude more collections than the
latter.</p><p>Doing fewer whole-heap traces is good, though, and in the ideal case,
the less frequent major traces under generational collectors allows time
for concurrent tracing, which is the true mitigation for long pause
times.</p><h3>is it whiffle?</h3><p>Could it be that the test harness I am using is in some way
unrepresentative?  I don’t have more than one test harness for Whippet
yet.  I will start work on a second Whippet embedder within the next few
weeks, so perhaps we will have an answer there.  Still, there is ample
time spent in GC pauses in these benchmarks, so surely as a GC workload
Whiffle has some utility.</p><p>One reasons that Whiffle might be unrepresentative is that it is an
ahead-of-time compiler, whereas nursery addresses are assigned at
run-time.  Whippet exposes the necessary information to allow a
just-in-time compiler to specialize write barriers, for example the
inline check that the field being mutated is not in the nursery, and an
AOT compiler can’t encode this as an immediate.  But it seems a small
detail.</p><p>Also, Whiffle doesn’t do much compiler-side work to elide write
barriers.  Could the cost of write barriers be over-represented in
Whiffle, relative to a production language run-time?</p><p>Relatedly, Whiffle is just a baseline compiler.  It does some partial
evaluation but no CFG-level optimization, no contification, no nice
closure conversion, no specialization, and so on: is it not
representative because it is not an optimizing compiler?</p><h3>is it something about the nursery size?</h3><p>How big should the nursery be?  I have no idea.</p><p>As a thought experiment, consider the case of a 1 kilobyte nursery.  It
is probably too small to allow the time for objects to die young, so the
survival rate at each minor collection would be high.  Above a certain
survival rate, generational GC is probably a lose, because your program
violates the weak generational hypothesis: it introduces a needless copy
for all survivors, and a synchronization for each minor GC.</p><p>On the other hand, a 1 GB nursery is probably not great either.  It is
plenty large enough to allow objects to die young, but the number of
survivor objects in a space that large is such that pause times would
not be very low, which is one of the things you would like in
generational GC.  Also, you lose out on locality: a significant fraction
of the objects you traverse are probably out of cache and might even
incur TLB misses.</p><p>So there is probably a happy medium somewhere.  My instinct is that for
a copying nursery, you want to make it about as big as L3 cache, which
on my 8-core laptop is 16 megabytes.  Systems are different sizes
though; in Whippet my current heuristic is to reserve 2 MB of nursery
per core that was active in the previous cycle, so if only 4 threads are
allocating, you would have a 8 MB nursery.  Is this good?  I don’t know.</p><h3>is it something about the benchmarks?</h3><p>I don’t have a very large set of benchmarks that run on Whiffle, and
they might not be representative.  I mean, they are microbenchmarks.</p><p>One question I had was about heap sizes.  If a benchmark’s maximum heap
size fits in L3, which is the case for some of them, then probably
generational GC is a wash, because whole-heap collection stays in cache.
When I am looking at benchmarks that evaluate generational GC, I make
sure to choose those that exceed L3 size by a good factor, for example
the 8-mutator splay benchmark in which minimum heap size peaks at 300
MB, or the 8-mutator nboyer-5 which peaks at 1.6 GB.</p><p>But then, should nursery size scale with total heap size?  I don’t know!</p><p>Incidentally, the way that I scale these benchmarks to multiple mutators
is a bit odd: they are serial benchmarks, and I just run some number of
threads at a time, and scale the heap size accordingly, assuming that
the minimum size when there are 4 threads is four times the minimum size
when there is just one thread.  However, <a href="https://wingolog.org/archives/2024/07/10/copying-collectors-with-block-structured-heaps-are-unreliable">multithreaded programs are
unreliable</a>,
in the sense that there is no heap size under which they fail and above
which they succeed; I quote:</p><blockquote>
"Consider 10 threads each of which has a local object graph that is
usually 10 MB but briefly 100MB when calculating: usually when GC
happens, total live object size is 10×10MB=100MB, but sometimes as
much as 1 GB; there is a minimum heap size for which the program
sometimes works, but also a minimum heap size at which it always
works."
</blockquote><h3>is it the write barrier?</h3><p>A generational collector partitions objects into old and new sets, and a
minor collection starts by visiting all old-to-new edges, called the
“remembered set”.  As the program runs, mutations to old objects might
introduce new old-to-new edges.  To maintain the remembered set in a
generational collector, the mutator invokes <i>write barriers</i>: little
bits of code that run when you mutate a field in an object.  This is
overhead relative to non-generational configurations, where the mutator
doesn’t have to invoke collector code when it sets fields.</p><p>So, could it be that Whippet’s write barriers or remembered set are
somehow so inefficient that my tests are unrepresentative of the state
of the art?</p><p>I used to use card-marking barriers, but I started to suspect they cause
too much overhead during minor GC and introduced too much cache
contention.  I switched to <a href="https://wingolog.org/archives/2024/10/03/preliminary-notes-on-a-nofl-field-logging-barrier">precise field-logging
barriers</a>
some months back for Whippet’s Immix-derived space, and we use the same
kind of barrier in the generational copying (pcc) collector.  I think
this is state of the art.  I need to see if I can find a configuration
that allows me to measure the overhead of these barriers, independently
of other components of a generational collector.</p><h3>is it something about the generational mechanism?</h3><p>A few months ago, my only generational collector used the <a href="https://wingolog.org/archives/2022/10/22/the-sticky-mark-bit-algorithm">sticky
mark-bit</a>
algorithm, which is an unconventional configuration: its nursery is not
contiguous, non-moving, and can be as large as the heap.  This is part
of the reason that I implemented generational support for the parallel
copying collector, to have a different and more conventional collector
to compare against.  But generational collection loses on some of these
benchmarks in both places!</p><h3>is it something about collecting more often?</h3><p>On one benchmark which repeatedly constructs some trees and then
verifies them, I was seeing terrible results for generational GC, which
I realized were because of cooperative safepoints: generational GC
collects more often, so it requires that all threads reach safepoints
more often, and the non-allocating verification phase wasn’t emitting
any safepoints.  I had to change the compiler to emit safepoints at
regular intervals (in my case, on function entry), and it sped up the
generational collector by a significant amount.</p><p>This is one instance of a general observation, which is that any work
that doesn’t depend on survivor size in a GC pause is more expensive
with a generational collector, which runs more collections.
Synchronization can be a cost.  I had one bug in which tracing
ephemerons did work proportional to the size of the whole heap, instead
of the nursery; I had to specifically add generational support for the
way Whippet deals with ephemerons during a collection to reduce this
cost.</p><h3>is it something about collection frequency?</h3><p>Looking deeper at the data, I have partial answers for the splay benchmark,
and they are annoying :)</p><p>Splay doesn’t actually allocate all that much garbage.  At a 2.5x heap,
the stock parallel MMC collector (in-place, sticky mark bit)
collects... one time.  That’s all.  Same for the generational MMC
collector, because the first collection is always major.  So at 2.5x we
would expect the generational collector to be slightly slower.  The
benchmark is simply not very good – or perhaps the most generous
interpretation is that it represents tasks that allocate 40 MB or so of
long-lived data and not much garbage on top.</p><p>Also at 2.5x heap, the whole-heap copying collector runs 9 times, and
the generational copying collector does 293 minor collections and... 9
major collections.  We are not reducing the number of major GCs.  It
means either the nursery is too small, so objects aren’t dying young
when they could, or the benchmark itself doesn’t conform to the weak
generational hypothesis.</p><p>At a 1.5x heap, the copying collector doesn’t have enough space to run.
For MMC, the non-generational variant collects 7 times, and generational
MMC times out.  Timing out indicates a bug, I think.  Annoying!</p><p>I tend to think that if I get results and there were fewer than, like, 5
major collections for a whole-heap collector, that indicates that the
benchmark is probably inapplicable at that heap size, and I should
somehow surface these anomalies in my analysis scripts.</p><h3>collecting more often redux</h3><p>Doing a similar exercise for nboyer at 2.5x heap with 8 threads (4GB for
1.6GB live data), I see that pcc did 20 major collections, whereas
generational pcc lowered that to 8 major collections and 3471 minor
collections.  Could it be that there are still too many fixed costs
associated with synchronizing for global stop-the-world minor
collections?  I am going to have to add some fine-grained tracing to
find out.</p><h3>conclusion?</h3><p>I just don’t know!  I want to believe that generational collection was an out-and-out win,
but I haven’t yet been able to prove it is true.</p><p>I do have some homework to do.  I need to find a way to test the
overhead of my write barrier – probably using the MMC collector and
making it only do major collections.  I need to fix generational-mmc for
splay and a 1.5x heap.  And I need to do some fine-grained performance
analysis for minor collections in large heaps.</p><p>Enough for today.  Feedback / reactions very welcome.  Thanks for
reading and happy hacking!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don't "optimize" conditional moves in shaders with mix()+step() (339 pts)]]></title>
            <link>https://iquilezles.org/articles/gpuconditionals/</link>
            <guid>42990324</guid>
            <pubDate>Sun, 09 Feb 2025 12:42:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://iquilezles.org/articles/gpuconditionals/">https://iquilezles.org/articles/gpuconditionals/</a>, See on <a href="https://news.ycombinator.com/item?id=42990324">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">



<h3>Intro</h3><hr><p>
In this article I want to correct a popular misconception that's been making the rounds in computer graphics aficionado circles for a long time now. It has to do with branching in the GPUs. Unfortunately there are a couple of educational websites out there that are spreading some misinformation and it would be nice correcting that. I tried contacting the authors without success, so without further ado, here goes my attempt to fix things up:</p><h3>The issue</h3><hr><p>
So, say I have this code, which I actually published the other day:</p><p><span>vec2</span> snap45( <span>in vec2</span> v )
{
    <span>vec2</span> s = <span>sign</span>(v);
    <span>float</span> x = <span>abs</span>(v.x);
    <span>return</span> x&gt;<span>0.923880</span>?<span>vec2</span>(s.x,<span>0.0</span>):
           x&gt;<span>0.382683</span>?s*<span>sqrt</span>(<span>0.5</span>):
                      <span>vec2</span>(<span>0.0</span>,s.y);
}</p>
<p>
The exact details of what it does don't matter for this discussion. All we care about is the two ternary operations, which as you know, implement conditional execution. Indeed, depending on the value of the variable <b>x</b>, the function will return different results. This could be implemented also with regular <b>if</b> statements, and all that I'm going to say stays the same.</p><p>

But here's the problem - when seeing code like this, somebody somewhere will invariably propose the following "optimization", which replaces what they believe (erroneously) are "conditional branches" by arithmetical operations. They will suggest something like this:</p><p><span>vec2</span> snap45( <span>in vec2</span> v )
{
    <span>vec2</span> s = <span>sign</span>(v);
    <span>float</span> x = <span>abs</span>(v.x);

    <span>float</span> w0 = <span>step</span>(<span>0.92387953</span>,x);
    <span>float</span> w1 = <span>step</span>(<span>0.38268343</span>,x)*(<span>1.0</span>-w0);
    <span>float</span> w2 = <span>1.0</span>-w0-w1;

    <span>vec2</span> res0 = <span>vec2</span>(s.x,<span>0.0</span>);
    <span>vec2</span> res1 = <span>vec2</span>(s.x,s.y)*<span>sqrt</span>(<span>0.5</span>);
    <span>vec2</span> res2 = <span>vec2</span>(<span>0.0</span>,s.y);

    <span>return</span> w0*res0 + w1*res1 + w2*res2;
}</p>
<p>
There are two things wrong with this practice. The first one shows an incorrect understanding of how the GPU works. In particular, the original shader code had no conditional branching in it. Selecting between a few registers with a ternary operator or with a plain <b>if</b> statement does not lead to conditional branching; all it involves is a conditional move (a.k.a. "select"), which is a simple instruction to route the correct bits to the destination register. You can think of it as a bitwise AND+NAND+OR on the source registers, which is a simple combinational circuit. Again, there is no branching - the instruction pointer isn't manipulated, there's no branch prediction involved, no instruction cache to invalidation, no nothing.</p><p>

For the record, of course real branches do happen in GPU code, but those are not what's used by the GPU for small moves between registers like we have here. This is true for any GPU made in the last 20+ years. While I'm not an expert in CPUs, I am pretty sure this is true for them as well.</p><p>

The second wrong thing with the supposedly optimizer version is that it actually runs much slower than the original version. The reason is that the <b>step()</b> function is actually implemented like this:</p><p><span>float</span> step( <span>float</span> x, <span>float</span> y )
{
    <span>return</span> x &lt; y ? <span>1.0</span> : <span>0.0</span>;
}</p>
<p>
So people using the step() "optimization" are using the ternary operation anyways, which produces the <b>0.0</b> or <b>1.0</b> which they will use to select the output, only wasting two multiplications and one or two additions. The values could have been conditionally moved directly, which is what the original shader code did.</p><p>

But don't take my word for it, let's look at the generated machine code for the relevant part of the shader I published:</p><div>

<div><p>
GLSL</p><hr>
<p><span>return</span> x&gt;<span>0.923880</span>?<span>vec2</span>(s.x,<span>0.0</span>):
       x&gt;<span>0.382683</span>?s*<span>sqrt</span>(<span>0.5</span>):
                  <span>vec2</span>(<span>0.0</span>,s.y);</p>
</div>
<div><p>
AMD Compiler</p><hr>
<p><span>s_mov_b32</span>     s0, <span>0x3ec3ef15</span>
<span>v_mul_f32</span>     v3, <span>0x3f3504f3</span>, v1
<span>v_mul_f32</span>     v4, <span>0x3f3504f3</span>, v0
<span>s_mov_b32</span>     s1, <span>0x3f6c835e</span>
<span>v_cmp_gt_f32</span>  vcc, <span>abs</span>(v2), s0
<span>v_cndmask_b32</span> v3, 0, v3, vcc
<span>v_cndmask_b32</span> v0, v0, v4, vcc
<span>v_cmp_ngt_f32</span> vcc, <span>abs</span>(v2), s1
<span>v_cndmask_b32</span> v1, v1, v3, vcc
<span>v_cndmask_b32</span> v0, 0, v0, vcc</p>
</div>
<div><p>
Microsoft Compiler</p><hr>
<p><span>lt</span>   r0.xy, l(<span>0</span>, <span>0</span>), v0.xy
<span>lt</span>   r0.zw, v0.xy, l(<span>0</span>, <span>0</span>)
<span>iadd</span> r0.xy, -r0.xyxx, r0.zwzz
<span>itof</span> r0.xy, r0.xyxx
<span>mul</span>  r1.xyzw, r0.xyxy, l4(<span>0.707107</span>)
<span>lt</span>   r2.xy, l(<span>0.923880</span>,<span>0.382683</span>), <span>|</span>v0.xx<span>|</span>
<span>mov</span>  r0.z, l(<span>0</span>)
<span>movc</span> r1.xyzw, r2.yyyy, r1.xyzw, r0.zyzy
<span>movc</span> o0.xyzw, r2.xxxx, r0.xzxz, r1.xyzw</p>
</div>
</div><p>
Here we can see that the GPU is not branching. Instead, according to the AMD compiler, it's performing the required comparisons (<span>v_cmp_gt_f32</span> and <span>v_cmp_ngt_f32</span> - cmp=compare, gt=greater than, ngt=not greated than), and then using the result to mask the results with the bitwise operations mentioned earlier (<span>v_cndmask_b32</span> - cnd=conditional).</p><p>

The Microsoft compiler has expressed the same idea/implementation in a different format, but you can still see the comparison (<span>lt</span> - "lt"=less than) and the masking or conditional move (<span>movc</span> - mov=move, c=conditionally).</p><p>

Not related to the discussion, but also note that the <b>abs()</b> call does not become a GPU instruction and instead becomes an instruction modifier, which is free.</p><h3>Conclusion</h3><hr>
<p>
So, if you ever see somebody proposing this</p><p><span>float</span> a = <span>mix</span>( b, c, <span>step</span>( y, x ) );</p><p>
as an optimization to</p><p><span>float</span> a = x &lt; y ? b : c</p><p>
then please correct them for me. The misinformation has been around for 20 years / 10 GPU generation, and that's more than too long.</p><p>

Thanks!
</p><!-- -------------------------------------------------------------------------------------------- -->

</div></div>]]></description>
        </item>
    </channel>
</rss>