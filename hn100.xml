<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 07 Sep 2023 00:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Ten million a year die from air pollution (2021) (102 pts)]]></title>
            <link>https://www.lrb.co.uk/the-paper/v43/n23/david-wallace-wells/ten-million-a-year</link>
            <guid>37411547</guid>
            <pubDate>Wed, 06 Sep 2023 21:25:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lrb.co.uk/the-paper/v43/n23/david-wallace-wells/ten-million-a-year">https://www.lrb.co.uk/the-paper/v43/n23/david-wallace-wells/ten-million-a-year</a>, See on <a href="https://news.ycombinator.com/item?id=37411547">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!--<div class="article-mask"><div class="copyright-restricted-content"><div class="copyright-restricted-content--notice"><p>Please sign in to read the full article.</p><p><a href="/login" title="Login" class="btn btn-primary">Login</a></p></div></div></div>--><p><span>N</span><span>ot</span>​ all deaths are created equal. In February 2020, the world began to panic about the novel coronavirus, which killed 2714 people that month. This made the news. In the same month, around 800,000 people died from the effects of air pollution. That didn’t. Novelty counts for a lot. At the start of the pandemic, it was considered unseemly to make comparisons like these. But comparing the value of human lives is one thing the machine of modern civilisation does relentlessly, almost invariably to prioritise and absolve the rich – when, for example, the global supply of Covid vaccines is apportioned primarily to the highest-income countries, or when the cost of natural disasters in Bangladesh is measured against the impact of sea-level rise on Miami Beach real estate, or when Joe Biden’s onetime economic adviser Lawrence Summers proposed that Africa, as a whole, was ‘vastly underpolluted’, and suggested that ‘the economic logic behind dumping a whole load of toxic waste in the lowest wage country is impeccable.’</p><p>In its first year, the pandemic did damage according to the opposite logic, with the world’s wealthiest countries the worst hit. When people in those countries tried to diminish the threat of the virus by comparing it to the flu, the disease made a joke of them. But air pollution kills more than ten times as many as the flu every single year, and we hear even less about it. In 2017, a <em>Lancet</em> study put the figure at almost seven million a year, about two-thirds from outside air pollution and one-third from indoor, household pollution. More recent estimates run higher, with as many as 8.7 million deaths every year attributable just to the outdoor particulate matter produced from burning fossil fuels. Add on indoor pollution, and you get an annual toll of more than ten million. That’s more than four times the official worldwide death toll from Covid last year. It’s about twenty times as many as the current annual deaths from war, murder and terrorism combined. Put another way, air pollution kills twenty thousand on an average day, more than have died in the aftermath of all the meltdowns in the history of nuclear power: Chernobyl, Three Mile Island, Fukushima and all the others put together. If the pandemic so terrified us that billions of us retreated into panicked cocoons for months, what can explain or justify our blindness and indifference towards the ten million lives ended each year by the repeated inhalation of smog?</p><p>Ten million deaths a year is a hundred million a decade. The numbers are so large that even the superlatives of disaster fail. They’re so large that they strain credulity, perhaps partly because none of us can picture someone dying in the street from air pollution and partly because it seems pathetically old-fashioned for a doctor to advise a sojourn in healthier air. But the chances are that you can’t picture a death from obesity or cigarette smoking either, and yet you probably don’t doubt estimates of their toll on human wellbeing, or think it wrong to call Louisiana’s River Parishes ‘Cancer Alley’ – the presence of 150 petrochemical plants has made it an incontrovertibly unhealthy place to live, with some communities registering cancer rates fifty times the national average. Such areas are sometimes known as ‘sacrifice zones’.</p><p>A single speck of black carbon, inhaled, won’t stop the heart or poison the lungs, but over time, across populations, the effect is devastating. When we talk about death we always want to see a murderer. When there isn’t one, it’s a lot harder to call it a murder, rather than a tragedy or an act of God. (‘You see one person run over in the street and you’ll never forget it,’ an environmentalist observes in <em>Choked: The Age of Air Pollution and the Fight for a Cleaner Future</em>.<span><a href="https://www.lrb.co.uk/the-paper/v43/n23/footnotes/ten-million-a-year-footnote-2">*</a></span> Thousands dying from the effects of dirty air ‘will never even faze you’.) But the central premise of any mortality model is that everyone dies: the question is when, and whether a certain behaviour or environmental factor hastened that end. And while none of these estimates is meant to suggest a single cause of mortality, such as a gunshot wound or a dose of poison in your morning tea, the calculus for air pollution is the same as for obesity or smoking: take the problem away, and the number of premature deaths will fall by many millions. According to new research, half of these deaths, concentrated in the developing world, are the result of consumption and fossil-fuel burning in the world’s richest countries.</p><p>The environmental historian Stephen Pyne calls our era the ‘pyrocene’, a global regime of burning: coal and oil, agricultural land and forest, bush and wetland, most of it planned. The Anthropocene, Pyne says, implies dominion over nature. He prefers to emphasise the fact that, wherever you look, the earth is in flames. The residue is carbon monoxide, nitrogen dioxide, ozone, black carbon, sulphur dioxide, and the particularly toxic grouping of small particulate matter known as PM2.5. Everything we burn, we breathe.</p><p>Hundreds of millions of people live and breathe in cities permanently clouded by airborne toxic events. In November, the authorities in Delhi closed schools and colleges indefinitely, suspended construction work, and shuttered half of the local coal plants after an episode of ‘toxic smog’ and an order from the Indian Supreme Court to institute emergency measures to combat it. The smog wasn’t new; the response was. Throughout the city, particulate matter hangs around in offices, lobbies and private homes, even those with air purifiers. It often gets so thick that it interferes with air travel. More remarkably, it has interrupted train travel, the smog making it impossible for drivers to see the tracks. Taxi drivers have filtration systems to process the particulates that sneak in. Pedestrians can’t escape it, which is one reason that, on especially smoggy days, living in Delhi is the equivalent of smoking several packets of cigarettes. The city has the highest rates of respiratory illness in the world, and 60 per cent of inhabitants diagnosed with COPD – chronic obstructive pulmonary disease – aren’t even smokers.</p><p>Across India as a whole, where more than a million people die from air pollution each year, exposure to small particulate matter has been estimated at five times the World Health Organisation’s longtime ‘safe’ level – defined as ten micrograms per cubic metre of air. This year the WHO set a new standard, at half the old level. Under the old threshold, 90 per cent of the world’s population were breathing dangerously polluted air; under the new threshold the figure is closer to 99 per cent. Of the world’s fourteen most polluted metropolises, only one (Hotan in China) is outside India. Of the 336 cities that come next on the list, 184 are in China. But this isn’t to say that air pollution is a problem in just two countries. Globally, it causes one death in five.</p><p>Here is just a partial list of the things, short of death rates, we know are affected by air pollution. GDP, with a 10 per cent increase in pollution reducing output by almost a full percentage point, according to an OECD report last year. Cognitive performance, with a study showing that cutting Chinese pollution to the standards required in the US would improve the average student’s ranking in verbal tests by 26 per cent and in maths by 13 per cent. In Los Angeles, after $700 air purifiers were installed in schools, student performance improved almost as much as it would if class sizes were reduced by a third. Heart disease is more common in polluted air, as are many types of cancer, and acute and chronic respiratory diseases like asthma, and strokes. The incidence of Alzheimer’s can triple: in <em>Choked</em>, Beth Gardiner cites a study which found early markers of Alzheimer’s in 40 per cent of autopsies conducted on those in high-pollution areas and in none of those outside them. Rates of other sorts of dementia increase too, as does Parkinson’s. Air pollution has also been linked to mental illness of all kinds – with a recent paper in the <em>British Journal of Psychiatry</em> showing that even small increases in local pollution raise the need for treatment by a third and for hospitalisation by a fifth – and to worse memory, attention and vocabulary, as well as ADHD and autism spectrum disorders. Pollution has been shown to damage the development of neurons in the brain, and proximity to a coal plant can deform a baby’s DNA in the womb. It even accelerates the degeneration of the eyesight.</p><p>A high pollution level in the year a baby is born has been shown to result in reduced earnings and labour force participation at the age of thirty. The relationship of pollution to premature births and low birth weight is so strong that the introduction of the automatic toll system E-ZPass in American cities reduced both problems in areas close to toll plazas (by 10.8 per cent and 11.8 per cent respectively), by cutting down on the exhaust expelled when cars have to queue. Extremely premature births, another study found, were 80 per cent more likely when mothers lived in areas of heavy traffic. Women breathing exhaust fumes during pregnancy gave birth to children with higher rates of paediatric leukaemia, kidney cancer, eye tumours and malignancies in the ovaries and testes. Infant death rates increased in line with pollution levels, as did heart malformations. And those breathing dirtier air in childhood exhibited significantly higher rates of self-harm in adulthood, with an increase of just five micrograms of small particulates a day associated, in 1.4 million people in Denmark, with a 42 per cent rise in violence towards oneself. Depression in teenagers quadruples; suicide becomes more common too.</p><p>Stock market returns are lower on days with higher air pollution, a study found this year. Surgical outcomes are worse. Crime goes up with increased particulate concentrations, especially violent crime: a 10 per cent reduction in pollution, researchers at Colorado State University found, could reduce the cost of crime in the US by $1.4 billion a year. When there’s more smog in the air, chess players make more mistakes, and bigger ones. Politicians speak more simplistically, and baseball umpires make more bad calls.</p><p>In 2019, a comprehensive global review by the Forum of International Respiratory Societies found that air pollution damages every organ, indeed virtually every cell, in the body. Nanoparticles of pollution have been found inside the brainstems of even the very young. But you don’t have to wait until birth to see the effects of breathing particulate matter. The impact begins in the womb, damaging the development of lungs and shortening future lives. In 2019, a small-scale study at Hasselt University found particles of black carbon in every single placenta examined, including those from mothers who lived in areas where the air was thought to be clean, with thousands of particles found in every cubic millimetre. For those who worry about microplastics in the flesh of fish, this is a yet more invasive category of intrusion. Of course, there are also microplastics in the air. They’ve been found in placentas too.</p><p><span>T</span><span>hat</span>​ everything is worse in the presence of pollution means that everything should be better in its absence. And, as best we can tell, it is. According to the National Resources Defence Council, the US Clean Air Act of 1970 is still saving 370,000 American lives every year – more than would have been saved last year had the pandemic never arrived. According to the NRDC, a single piece of legislation delivers annual economic benefits of more than $3 trillion, 32 times the cost of enacting it – benefits distributed disproportionately to the poor and marginalised. The American experience provides the basis for self-justifying indifference to pollution: according to what’s often called the ‘environmental Kuznets curve’, development makes countries dirtier before they get cleaner. This is wishful thinking, implying that pollution is an inevitable consequence of development, which can’t conceivably be achieved cleanly; and that it is in a way consensual, as if taking a job expresses a willingness to choke all the way to work. It also suggests that the effect is temporary, since societies at a certain level of wealth will refuse to put up with heavy pollution. But if more than 90 per cent of the planet’s population have lived for years in places with dangerously polluted air, 90 per cent also live where renewable energy is cheaper than dirty. This one fact renders the ‘economic bargain’ of air pollution, if it could ever be said to be credible, no better than an alibi.</p><p>In London, the gains over a single lifetime have been striking. ‘On Friday, 5 December 1952 my dad left work in South London, stepped out into the darkness and realised this was not going to be an ordinary journey home,’ Gary Fuller writes in <em>The Invisible Killer: The Rising Global Threat of Air Pollution – and How We Can Fight Back</em> (2018). ‘The fog was exceptionally thick. It was as if the world around him had vanished.’ He had to feel his way along the kerb all the way home.’ Throughout the city, visibility was reduced to just a yard, Tim Smedley writes in <em>Clearing the Air: The Beginning and the End of Air Pollution</em>.<span><a href="https://www.lrb.co.uk/the-paper/v43/n23/footnotes/ten-million-a-year-footnote-3">†</a></span> ‘People couldn’t even see their own feet. Blinded commuters stepped off bridges into the icy Thames and from railway platforms into the path of oncoming trains.’ The smoke stuck to windscreens ‘like paint, forcing drivers to abandon their vehicles’. In 1952, the fog was estimated to have killed four thousand people in London, though later estimates tripled the figure; the rate of death was higher than in the cholera epidemic of 1866. The hospitals were overwhelmed. Four years later the Clean Air Act was introduced, and in relatively short order the pea-soupers that had given the city a permanent-seeming identity – reflected in the works of Dickens, Monet and Conan Doyle – came to an end.</p><p>In China, particulate pollution has been cut by a third since 2013, when the state declared ‘war’ on it. In the 1990s, when Mexico City was more polluted than Delhi, 80 per cent of 10 and 11-year-olds asked the colour of the sky responded ‘grey’, Smedley writes; only 10 per cent said ‘blue’. Today the city only just ranks in the list of the world’s thousand most polluted cities, with air as clean as the Northern French town of Roubaix, terminus of the famous cycle race.</p><p>That those gains are so large doesn’t mean there aren’t much bigger ones to reap. In China, more than a million people still die each year from air pollution. In Africa, another million. In London, Gardiner estimates, 9500, about 20 per cent of the city’s total deaths, despite the apparent success of the Ultra Low Emission Zone. The Twitter account @CleanAirLondon has begun to tally deaths attributable to pollution by area in real time. About two-thirds of the population of the UK, Smedley calculates, are living with pollution above the legal limit set by the EU, and millions of British children are going to school in dangerously dirty air.</p><p>The World Bank estimates that as much as 6 per cent of global GDP is lost to pollution and puts the annual loss at $8.1 trillion. Last year, Drew Shindell of Duke University, an expert on pollution impact, appeared before the US House Committee on Oversight and Reform. By further cleaning up America’s air over the next fifty years, Shindell’s research shows, the country could prevent 4.5 million premature deaths, 1.4 million hospitalisations, 1.7 million cases of dementia and 300 million lost work days. The result, he calculated, would be $700 billion a year in net benefits, ‘far more than the cost of the energy transition’. In other words, a total decarbonisation of the US economy would pay for itself through public health gains alone. The American Environmental Protection Agency has an official measure for the value of a single human life: $7 million in 2006 dollars. If you take that number seriously, the annual value of saving the 350,000 lives a year lost to pollution would be $2.45 trillion.</p><p>Globally, air pollution cuts life expectancy by almost two years. The average inhabitant of Delhi would live 9.7 years longer were it not for air pollution. The figure is 8.5 years across the Indo-Gangetic plains, where 500 million people live. Cutting air pollution to the WHO standard would add 5.9 years of life expectancy to 1.38 billion Indians, 5.4 years to 164.7 million Bangladeshis and 3.9 years to 220 million Pakistanis. Annually, 349,000 stillbirths and miscarriages in South Asia can be attributed to air pollution, and 116,000 infants die from its effects in their first month.</p><p>These numbers demand that we reorder our picture of the world we live in, recalculating the brutality of the present. It becomes plain that clean air and clean water and human health should be restored to the centre of the environmental crusade – rather than at the margins, where they’ve been relegated as the movement has coalesced around the necessary project of addressing climate change through decarbonisation. (As a side benefit, clean air and clean water tend to be much more popular with voters than climate-focused environmental policies.) The long timescale of global warming has often made it hard to mobilise a majority against damage that may occur decades, or even generations, in the future. That timescale no longer looks quite so distended, after the last few years of serial disaster – fire, storm and flood – but air pollution provides an even more urgent motive for change: millions are dying, right now, because of it, and because particulate pollution dissipates much more quickly than carbon dioxide in the atmosphere, abating that pollution would save lives swiftly. Carbon hangs in the air for centuries if we don’t remove it; local pollution abates almost as soon as the match is extinguished.</p><p>There’s a further incentive for individual governments to prioritise the addressing of pollution. The benefits of decarbonisation – chiefly that it limits temperature rise – are distributed globally, which in practice means that local actors wait and see how quickly others are moving before moving themselves. Air pollution changes the calculus: for one thing, it’s actually under the control of local and national governments. It’s also a significant burden on public health, which if alleviated offers immediate benefits every government should want to seize.</p><p>A final implication of numbers as large as ten million deaths a year is that, certainly in terms of human mortality and probably in terms of human suffering, over the next few decades the toll of air pollution from the burning of fossil fuels will be greater than all the other impacts of climate change combined, at least as we currently quantify them. Global warming will of course deliver punishing and transformative impacts well below the threshold of mortality: flooding, drought, crop failure; poverty and forced migration and possibly state collapse; hurricanes and wildfire of unprecedented intensity. But as brutal as these may be, they don’t add up to anywhere near ten million deaths a year – or even one million – unless you add to most models the effects of improbable feedback loops (large-scale release of methane from melting permafrost in the northern latitudes, for instance) or widespread civilisational collapse.</p><p>Warming may well destabilise societies: it’s certainly not out of the question. But the damage done by air pollution isn’t hypothetical, and it’s happening at a much bigger scale. According to the WHO, extreme heat killed at least 166,000 people around the world between 1998 and 2017 – 8700 a year. Air pollution killed about a thousand times more. Other estimates are higher, but even the highest – the <em>Lancet</em>’s half a million heat-related deaths per year – is just a twentieth of the toll of air pollution. Earlier this year, Madagascar was said to be on the brink of the world’s first ‘climate famine’, with 30,000 on the verge of starvation. In the same country, Unicef estimates, more than 40,000 already die each year from the effects of air pollution. The Climate Impact Lab recently published a comprehensive accounting of the ‘global mortality consequences for climate change’. The lab, a consortium of environmental scientists and economists from a wide range of US institutions, is known for being at the alarm-raising vanguard of the serious research on the effects of warming. Their highest estimate for the end of this century – assuming an implausibly high emissions scenario called RCP8.5 – was for an annual death toll from climate change of 73 deaths per 100,000 people. Today, air pollution is killing up to 126 per 100,000. In a more plausible scenario, the report projects fewer than 20 deaths per 100,000.</p><p><span>P</span><span>erhaps,</span>​ like me, you have spent the last five years in a state of panic about climate change. Perhaps it has inflamed your politics, and your sense of self. It should. The world is already warmer than it has ever been in the history of human civilisation. We have already exceeded the narrow temperature window which gave rise to everything we know as agriculture and society and politics and culture. The last time there was as much carbon in the atmosphere as there is today, temperatures weren’t 1.2°C warmer than the pre-industrial base level, as they are now, but about 3°C, with forests growing in the Antarctic and sea levels twenty metres higher.</p><p>The climate is changing ten times faster than ever before in a planetary history that includes mass extinctions which wiped out more than 90 per cent of life on Earth. Half of that damage has been done in the last 25 years, since the publication of Al Gore’s first book on global warming and the formation of the UN’s Intergovernmental Panel on Climate Change – in other words, with the full knowledge of the scientific community and the effective consent of global political leaders. A quarter of the change has taken place since Barack Obama was elected president, having hubristically proclaimed that ‘this was the moment when the rise of the oceans began to slow and our planet began to heal.’ Just a few years later, he bragged to an audience in Texas that ‘suddenly, America is the biggest oil producer. That was me, people.’</p><p>In 2018 an IPCC report declared that giving the planet a good chance of staying below 2°C of warming and avoiding the catastrophic effects that would bring – island nations have called it genocide; African climate ambassadors ‘certain death’ for the continent – would require a 45 per cent reduction in emissions this decade. The report suggested that such a rapid timeline would require a global World War Two-scale mobilisation beginning the following year, 2019. Instead, emissions went up, and will be up again, it appears, in 2021, after a brief dip during the pandemic.</p><p>An IPCC report released in August also noted that air pollution has limited the level of warming, to the extent that if it were removed global temperatures would be half a degree higher than they are now. The reason: aerosols reflect sunlight back into space and therefore hold temperature rise below the level our carbon concentrations alone would dictate. Some estimates of the cooling effect run even higher: the climate scientist James Hansen believes the rate of global warming could double as aerosols decline. Cutting air pollution probably won’t produce a sudden temperature spike, because the transition would be gradual, but we would probably already be close to the 2°C threshold if we weren’t also producing enough particulate matter to kill ten million people a year.</p><p>If we fail to keep the rise below 2°C, we may see what used to be once in a century floods happening every single year; major cities in South Asia and the Middle East experiencing ‘lethal’ heat for two hundred or more days a year; the total loss of the planet’s coral reefs, which provide food, income and coastal protection to a half a billion people; and possibly irreversible acceleration of sea-level rise as a result of the melting of the Arctic ice sheets. And the climate may be more sensitive to our carbon perturbations than median estimates predict: a doubling of carbon concentrations from the pre-industrial average produces anything from two degrees of warming to six, depending on the model. At three degrees, a quarter of potential global GDP could be wiped out; in many equatorial regions there would be no hope of economic growth at all. At four degrees, crop yields could drop dramatically, and parts of the world might be hit by up to six climate-driven natural disasters at once.</p><p>All these impacts, even if unleashed, probably won’t surpass present-day air pollution in terms of human mortality for a very long time. Reducing fossil fuel pollution won’t solve the problem. Last year, wildfires accounted for more than half of the air pollution in the western United States – meaning that more particulate matter from burning forests infiltrated the lungs of Americans living in those states than from all other human and industrial activity combined. By the middle of the century, the extent of those fires is expected to double, at the very least, with each tree burned releasing carbon just as coal does, along with particulate matter. The worst air quality in the world is now routinely registered in California, and although these record-setting events typically last only a few days, it is already the case that the smoke from last year’s fires can be held responsible for five thousand additional pre-term births in the state. Globally, the world’s wildfire smoke delivers only a fraction of air pollution, but the fraction is growing. The 2021 fires are still smouldering, and wildfire emissions from this year have reached 4.7 billion tons of carbon, not far off the 5.1 billion produced last year by the US, which is the world’s second biggest emitter.</p><p>Fire is eternal in the American west, of course, but when climate sceptics point to evidence of ancient megafires, they neglect to mention that at the time there weren’t forty million people living in California. In the entire 20th century, there were only five fires that burned more than 100,000 acres. In 2020, there were eleven such fires – one blaze, the August Complex fire in Mendocino, which burned more than a million acres, seemed to demand a new term, ‘gigafire’, to describe it. Each of these fires has produced an unprecedented amount of smoke, so much of it that the fires create their own weather systems – pyrocumulus clouds, fire tornadoes and lightning storms, the lightning sometimes travelling miles from the central point of ignition, and sparking more fire where it lands, producing yet more smoke.</p><p>In some ways fear of smoke is more logical than fear of fire. In many parts of California, you can be confident your house won’t burn down. The chances are that you can evade the flames of even rampant wildfire. But smoke can’t be quarantined. This summer in the resort community of Lake Tahoe – where the Air Quality Index, which describes 51 on its scale as ‘hazardous’, hit 700 – those trapped inside during oppressive weeks of smoke finally fled their vacation homes. Poisoned air reached as far as the East Coast of the US, where more deaths are caused every year by western wildfires than in the west itself, and across the Atlantic to Europe, where around the Mediterranean unprecedented fires were already burning, forcing evacuations from resort hotels.</p><p>The story is global, the world wrapped in smoke. In British Columbia, more carbon is now unleashed each year from forest fires than from all other sources. In Australia, where bushfires are an enduring feature of both landscape and legend, 46 million acres burned in the 2019-20 season – ten times the record-setting California season that would follow, and enough to kill, it was estimated, more than a billion animals. The smoke in Sydney Harbour was so thick ferries couldn’t navigate it, and the particulates so dense that fire alarms were triggered in office buildings, the sensors concluding that there had to be flames nearby. In Siberia, where ‘zombie fires’ now burn regularly through the Arctic winter, carbon released from forests in flames regularly sends heavy smoke across the North Pole to the other side of the planet.</p><p>And then there’s South America, where 30 per cent of the Pantanal, the world’s largest tropical wetland, was lost to fire in a single year – 2020. In the Amazon, so much land is burned to clear trees for farming that the fires release three times as much carbon as all other forms of emission in Brazil – enough to make the rainforest itself, if it were a country, the world’s fifth largest emitter, and to turn the celebrated ‘carbon sink’, which might aid in our fight against warming, into a net source of global carbon. In theory, the burning could be halted, and it may at least be slowed if Lula succeeds Bolsonaro and returns to Brazil’s presidency next year. But the longer-term decline of the rainforest may lie outside the reach of national policy, as current global emissions trajectories suggest an irreversible tipping point for the region by the 2040s: less forest and more grass, less new growth and more new dying, more heat and therefore more fire. The Amazon has long been called ‘the lungs of the planet’. It may soon become a bellows. Everything we burn, we breathe.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Norway rolls back EV incentives while boosting walking and cycling (102 pts)]]></title>
            <link>https://electrek.co/2022/05/17/norway-rolls-back-ev-incentives-while-boosting-walking-and-cycling/</link>
            <guid>37411292</guid>
            <pubDate>Wed, 06 Sep 2023 21:03:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2022/05/17/norway-rolls-back-ev-incentives-while-boosting-walking-and-cycling/">https://electrek.co/2022/05/17/norway-rolls-back-ev-incentives-while-boosting-walking-and-cycling/</a>, See on <a href="https://news.ycombinator.com/item?id=37411292">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
			<img src="https://electrek.co/wp-content/uploads/sites/3/2022/04/Photo-Christian-Huehn-_-Hurtigruten-Norway.jpg?quality=82&amp;strip=all&amp;w=1600" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2022/04/Photo-Christian-Huehn-_-Hurtigruten-Norway.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2022/04/Photo-Christian-Huehn-_-Hurtigruten-Norway.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2022/04/Photo-Christian-Huehn-_-Hurtigruten-Norway.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2022/04/Photo-Christian-Huehn-_-Hurtigruten-Norway.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" width="1600" height="800" alt="" fetchpriority="high">
	
	</figure>

<p>While life may soon start to feel a little less sweet for EV owners in Norway, the country is eyeing its next strategic move toward an even greener future, and that means fewer private cars (even electric varieties) clogging the roads in favor of walking, cycling, and taking the bus. </p>



<div><p>Norway is leading the world in electric car adoption, with more than 65% of new passenger cars sold in the country in 2021 being electric – and generous tax incentives and perks like free parking have played no small role in that. But the government just announced a new plan to roll back VAT exemptions, especially for higher-end vehicles, with an eye toward potentially slashing more benefits. </p><p>First up is the VAT exemption for EVs priced at more than 500,000 kroner (about $51,700)&nbsp;as of January 1, 2023. The new VAT scheme will be dynamic in that the more expensive the electric car, the higher the VAT fee it incurs from next year. </p></div>



<p>Norwegian news outlet <em>The Local </em><a href="https://www.thelocal.no/20220512/norway-to-remove-vat-exemption-for-electric-cars/">postulates</a> that an EV priced at more than 600,000 kroner ($62,000) would be charged a VAT of 25,000 kroner ($2,580) or around 4%. An electric car priced near the 1 million kroner mark ($103,000) could incur up to a 12.5% VAT – which to this France-based reporter seems perfectly reasonable. Note that the standard &nbsp;VAT in Norway is 25%, which is already on the high end compared to the European average of 21%.</p>



<p>Norway already has a goal in place of reducing fossil fuel-burning vehicle sales to zero by 2025 – 10 years earlier than the plan set by the <a href="https://www.reuters.com/business/autos-transportation/eu-lawmakers-back-effective-ban-new-fossil-fuel-cars-2035-2022-05-11/">European Parliament last week</a>. But Norway says it isn’t hoping to simply replace combustion engines with electric counterparts 1:1 but motivate people to get out of their private vehicles and walk, cycle, and take public transport, the latter which was particularly hit hard by the COVID-19 pandemic.</p>



<div><p>EV owners in Norway have long enjoyed a range of <a href="https://elbil.no/english/norwegian-ev-policy/">enticing perks</a> over fossil fuel car owners, from reduced road tolls to driving in bus lanes to free parking, in addition to no purchase or import taxes – and while some of this has already been scaled back due to the huge growth in electric car ownership, the government in taking another hard look in hopes of bumping up public transportation usage and reducing traffic, especially in and around cities. Still, no official plan has been released just yet.</p><p>Norwegian Transport Minister Jon-Ivar Nygard said in the statement:</p></div>



<blockquote><p>Electric cars give us greener transport, but they also have a clear intermodal competition with public transport in urban areas. We must make it more attractive to travel by public transport, cycle, and walk.</p></blockquote>



<p>Of course, the Norwegian Electric Car Association, which represents 110,000&nbsp;EV owners in the country, isn’t happy with the new VAT measures. Christine Bu, the association’s general secretary, told Norwegian media outlet <a href="https://www.nrk.no/norge/revidert-nasjonalbudsjett_-fjernar-momsfritak-for-elbilar-_-innforer-tilskotsordning-1.15964393">NRK</a>:</p>



<blockquote><p> The entire electric car policy is at stake. It’s an incomprehensibly bad idea.</p></blockquote>



<h2 id="h-electrek-s-take">Electrek’s Take</h2>



<p>Norway is well on pace to meet its <a href="https://electrek.co/2022/04/06/norway-keeps-breaking-ev-adoption-records-tesla-model-y-leads/">all-electric goals by 2025,</a> and while that’s exciting, the country looks ready to take the next step in making cities, in particular, more livable, safer, while reducing electricity demands and traffic accidents overall. Fewer cars on the road is the only way forward. While more Norwegians than ever before are driving electric vehicles, they are also driving more miles than ever before. In fact, half of European car journeys are less than three miles – the kind of distance that for a majority of people is doable by bike, bus, or a brisk walk. Plus with Norway offering so many bonus perks, like EVs cruising down bus lanes (which really should be reserved for actual buses) to free parking (which then creates more demand for parking spaces in lieu of urban parks or green spaces), driving becomes an “easy” choice. But cities congested with cars and unrestrained car usage isn’t the utopian future we’re all dreaming of – and Norway is posed once again to lead the charge with a vision of what’s next after a full electric transition takes place. I think we can all agree that the world would be a lot nicer with fewer cars and more bikes, safe walking and cycling paths, and efficient buses.</p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bit by bit microplastics from tyres are polluting our waterways (116 pts)]]></title>
            <link>https://news.griffith.edu.au/2023/09/06/bit-by-bit-microplastics-from-tyres-are-polluting-our-waterways/</link>
            <guid>37411220</guid>
            <pubDate>Wed, 06 Sep 2023 20:58:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.griffith.edu.au/2023/09/06/bit-by-bit-microplastics-from-tyres-are-polluting-our-waterways/">https://news.griffith.edu.au/2023/09/06/bit-by-bit-microplastics-from-tyres-are-polluting-our-waterways/</a>, See on <a href="https://news.ycombinator.com/item?id=37411220">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>In urban stormwater, particles from tyre wear were the most prevalent microplastic a new Griffith-led study has found.</p>
<p>Published in <a href="https://pubs.acs.org/doi/10.1021/acs.est.3c03949"><em>Environmental Science &amp; Technology</em></a>, the study showed that in stormwater runoff during rain approximately 19 out of every 20 microplastics collected were tyre wear particles with anywhere from 2 to 59 particles per litre of water.</p>
<figure id="attachment_79744" aria-describedby="caption-attachment-79744"><img decoding="async" src="https://news.griffith.edu.au/wp-content/uploads/2023/09/microplastics-dr-ziajahromi-1-300x214.jpeg" alt="" width="409" height="292" srcset="https://news.griffith.edu.au/wp-content/uploads/2023/09/microplastics-dr-ziajahromi-1-300x214.jpeg 300w, https://news.griffith.edu.au/wp-content/uploads/2023/09/microplastics-dr-ziajahromi-1-203x145.jpeg 203w, https://news.griffith.edu.au/wp-content/uploads/2023/09/microplastics-dr-ziajahromi-1-400x286.jpeg 400w, https://news.griffith.edu.au/wp-content/uploads/2023/09/microplastics-dr-ziajahromi-1-468x334.jpeg 468w, https://news.griffith.edu.au/wp-content/uploads/2023/09/microplastics-dr-ziajahromi-1-553x395.jpeg 553w, https://news.griffith.edu.au/wp-content/uploads/2023/09/microplastics-dr-ziajahromi-1.jpeg 700w" sizes="(max-width: 409px) 100vw, 409px"><figcaption id="caption-attachment-79744">Lead author Dr Shima Ziajahromi, a research fellow at the Australian Rivers Institute.</figcaption></figure>
<p>“Pollution of our waterways by microplastics is an emerging environmental concern due to their persistence and accumulation in aquatic organisms and ecosystems,” said lead author <a href="https://experts.griffith.edu.au/9419-shima-ziajahromi">Dr Shima Ziajahromi</a>, a research fellow at the <a href="https://www.griffith.edu.au/australian-rivers-institute">Australian Rivers Institute</a>.</p>
<p>“Stormwater runoff which contains a mixture of sediment, chemical, organic and physical pollutants, is a critical pathway for microplastics to washed off from urban environments during rain and into local aquatic habitats.</p>
<p>“But to date, our knowledge of the amount of microplastics in urban stormwater, particularly tyre wear particles, is limited, as is the potential strategies we can use to minimise this source.”</p>
<p>Tyre rubber contains up to 2500 chemicals with the contaminants that leach from tyres considered more toxic to bacteria and microalgae than other plastic polymers.</p>
<p>“Due to the analytical challenges in measuring this source of microplastics in stormwater, research to date often lacks information about the actual number of tyre wear particles water samples,” said Dr Ziajahromi.</p>
<p>Quantitative information of this type is crucial to improve our understanding of the amount of tyre wear particles in stormwater, assess the risk to the environment, and to develop management strategies.</p>
<p><img decoding="async" src="https://news.griffith.edu.au/wp-content/uploads/2023/09/tyre-1714669_1280-300x169.jpg" alt="" width="694" height="391" srcset="https://news.griffith.edu.au/wp-content/uploads/2023/09/tyre-1714669_1280-300x169.jpg 300w, https://news.griffith.edu.au/wp-content/uploads/2023/09/tyre-1714669_1280-1024x575.jpg 1024w, https://news.griffith.edu.au/wp-content/uploads/2023/09/tyre-1714669_1280-210x118.jpg 210w, https://news.griffith.edu.au/wp-content/uploads/2023/09/tyre-1714669_1280-400x225.jpg 400w, https://news.griffith.edu.au/wp-content/uploads/2023/09/tyre-1714669_1280-468x263.jpg 468w, https://news.griffith.edu.au/wp-content/uploads/2023/09/tyre-1714669_1280-553x311.jpg 553w, https://news.griffith.edu.au/wp-content/uploads/2023/09/tyre-1714669_1280.jpg 1280w" sizes="(max-width: 694px) 100vw, 694px"></p>
<p>“Our study quantified and characterize microplastics and tyre wear particles in both stormwater runoff and sediment of stormwater drainage systems in Queensland,” said co-author <a href="https://experts.griffith.edu.au/18672-frederic-leusch">Professor Fred Leusch</a>, who leads the Australian Rivers Institute’s Toxicology Research Program.</p>
<p>“We also assessed the effectiveness of a stormwater treatment device to capture and remove these contaminants from stormwater and evaluated the role of a constructed stormwater wetland for capturing microplastics in the sediment, removing it from stormwater runoff.</p>
<p>“The device is a bag made of 0.2 millimetre mesh which can be retrofitted to stormwater drains. Although originally designed to capture gross pollutants, sediment, litter and oil and grease, it significantly reduced microplastics from raw runoff, with up to 88% less microplastics in treated water which had passed through the device.”</p>
<figure id="attachment_78049" aria-describedby="caption-attachment-78049"><img decoding="async" loading="lazy" src="https://news.griffith.edu.au/wp-content/uploads/2022/09/Fred-300x241.jpg" alt="" width="408" height="328" srcset="https://news.griffith.edu.au/wp-content/uploads/2022/09/Fred-300x241.jpg 300w, https://news.griffith.edu.au/wp-content/uploads/2022/09/Fred-1024x824.jpg 1024w, https://news.griffith.edu.au/wp-content/uploads/2022/09/Fred-768x618.jpg 768w, https://news.griffith.edu.au/wp-content/uploads/2022/09/Fred-180x145.jpg 180w, https://news.griffith.edu.au/wp-content/uploads/2022/09/Fred-400x322.jpg 400w, https://news.griffith.edu.au/wp-content/uploads/2022/09/Fred-468x377.jpg 468w, https://news.griffith.edu.au/wp-content/uploads/2022/09/Fred-553x445.jpg 553w, https://news.griffith.edu.au/wp-content/uploads/2022/09/Fred.jpg 1060w" sizes="(max-width: 408px) 100vw, 408px"><figcaption id="caption-attachment-78049">Professor Frederic Leusch who leads the ARI Toxicology Research Program (ARITOX) at the Australian Rivers Institute</figcaption></figure>
<p>Sediment samples collected from the inlet and outlet of a constructed stormwater wetland contained between 1450 to 4740 particles in every kilogram of sediment, with more microplastics in the sediment at the inlet than the outlet, indicating the wetland’s ability to remove them from stormwater.</p>
<p>“Microplastics that enter constructed wetlands for stormwater drainage systems settle in the sediment and form a biofilm, leading to their accumulation over time, removing them from stormwater runoff,” said Dr Ziajahromi.</p>
<p>“Urban stormwater runoff typically requires treatment for the removal of suspended solids and nutrients such as nitrogen and phosphorus in many jurisdictions in Australia, with some also requiring the removal of gross pollutants. However, regulations are lagging behind when it comes to microplastics and tyre wear particles.”</p>
<p>“Our findings show that both constructed wetlands and the stormwater capture device are strategies that could be potentially used to prevent or at least decrease the amount of microplastics tyre wear particles being transported from stormwater into our waterways.”</p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MS-DOS v1.25 and v2.0 is now open-source (2014) (180 pts)]]></title>
            <link>https://github.com/microsoft/MS-DOS</link>
            <guid>37410803</guid>
            <pubDate>Wed, 06 Sep 2023 20:25:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/microsoft/MS-DOS">https://github.com/microsoft/MS-DOS</a>, See on <a href="https://news.ycombinator.com/item?id=37410803">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Microsoft/MS-DOS/blob/master/msdos-logo.png"><img width="150" height="150" alt="MS-DOS logo" src="https://github.com/Microsoft/MS-DOS/raw/master/msdos-logo.png"></a></p>   
<h2 tabindex="-1" dir="auto">MS-DOS v1.25 and v2.0 Source Code</h2>
<p dir="auto">This repo contains the original source-code and compiled binaries for MS-DOS v1.25 and MS-DOS v2.0.</p>
<p dir="auto">These are the same files <a href="http://www.computerhistory.org/atchm/microsoft-ms-dos-early-source-code/" rel="nofollow">originally shared at the Computer History Museum on March 25th, 2014</a> and are being (re)published in this repo to make them easier to find, reference-to in external writing and works, and to allow exploration and experimentation for those interested in early PC Operating Systems.</p>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto">All files within this repo are released under the <a href="https://en.wikipedia.org/wiki/MIT_License" rel="nofollow">MIT (OSI) License</a> as per the <a href="https://github.com/Microsoft/MS-DOS/blob/master/LICENSE.md">LICENSE file</a> stored in the root of this repo.</p>
<h2 tabindex="-1" dir="auto">Contribute!</h2>
<p dir="auto">The source files in this repo are for historical reference and will be kept static, so please <strong>don’t send</strong> Pull Requests suggesting any modifications to the source files, but feel free to fork this repo and experiment 😊.</p>
<p dir="auto">If, however, you’d like to submit additional non-source content or modifications to non-source files (e.g., this README), please submit via PR, and we’ll review and consider.</p>
<p dir="auto">This project has adopted the <a href="https://opensource.microsoft.com/codeofconduct/" rel="nofollow">Microsoft Open Source Code of Conduct</a>.  For more information see the <a href="https://opensource.microsoft.com/codeofconduct/faq/" rel="nofollow">Code of Conduct FAQ</a> or contact <a href="mailto:opencode@microsoft.com">opencode@microsoft.com</a> with any additional questions or comments.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US broadband grant rules shut out small ISPs and municipalities, advocates say (126 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2023/09/big-isps-will-dominate-42b-grant-fund-if-rules-arent-changed-advocates-say/</link>
            <guid>37410639</guid>
            <pubDate>Wed, 06 Sep 2023 20:12:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2023/09/big-isps-will-dominate-42b-grant-fund-if-rules-arent-changed-advocates-say/">https://arstechnica.com/tech-policy/2023/09/big-isps-will-dominate-42b-grant-fund-if-rules-arent-changed-advocates-say/</a>, See on <a href="https://news.ycombinator.com/item?id=37410639">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2022/09/getty-network-map-800x450.jpg" alt="Illustration of a US map with crisscrossing lines representing a broadband network.">
      <figcaption><p>Getty Images | Andrey Denisyuk</p></figcaption>  </figure>

  




<!-- cache hit 318:single/related:87dbe709f4e3e6ddf2137e0e7a200114 --><!-- empty -->
<p>The biggest Internet service providers will dominate a $42.45 billion broadband grant program unless the Biden administration changes a rule requiring grant recipients to obtain a letter of credit from a bank, according to a joint statement from consumer advocacy groups, local government officials, and advocates for small ISPs.</p>
<p>The <a href="https://connect-humanity.shorthandstories.com/bead-letter-of-credit-alternatives/">letter</a> sent today to US government officials argues that "by establishing capital barriers too steep for all but the best-funded ISPs, the LOC [letter-of-credit requirement] shuts out the vast majority of entities the program claims to prioritize: small and community-centered ISPs, minority and women-owned ISPs, nonprofits, and municipalities."</p>
<p>The rule is part of the Broadband Equity Access and Deployment (BEAD) <a href="https://broadbandusa.ntia.doc.gov/funding-programs/broadband-equity-access-and-deployment-bead-program">program</a> that's being administered by the National Telecommunications and Information Administration (NTIA).</p>
<p>"Rather than demonstrating a provider's ability to construct a broadband network and provide high-speed broadband services to unserved and underserved Americans, the LOC is a measure of whether they can lock up valuable working capital over multiple years," the letter said. "While large incumbents may be able to bear this financial burden, most others can not. And, due to various state and local rules, municipalities are often not allowed to obtain LOCs. Therefore, alternatives to the LOC are critical to ensure these providers can participate in the BEAD program."</p>
<p>The director of the BEAD program, Evan Feinman, responded to letter-of-credit concerns during a <a href="https://www.youtube.com/watch?v=M_ZWWETMaM0&amp;t=21s">webinar</a> in June. He said the NTIA is aiming to "minimize the failure rate, because every project that's undertaken will expend some funds prior to failing and then have to start back at square one with a new provider if it turns out that a provider doesn't have the wherewithal to undertake a project."</p>
<p>"We know that when we narrow [who can get funding], we're going to lose the opportunity to get into partnership with some high-quality small outfits. But we had to err on one side or the other, there was no way to hit it right on the nose," Feinman said. The NTIA will waive the LOC requirement on a case-by-case basis, but waivers will be "tightly controlled," he said.</p>                                            
                                                        
<h2>Biden’s former FCC nominee among 300 letter-signers</h2>
<p>Today's letter objecting to the letter-of-credit rule was signed by "a coalition of 300 broadband experts, ISPs, community leaders, nonprofits, consumer advocates, and business groups," said the <a href="https://www.benton.org/headlines/benton-institute-joins-broadband-experts-isps-and-local-leaders-urge-biden-administration">Benton Institute for Broadband &amp; Society</a>. Local government officials from various parts of the US were among the signers.</p>
<p>One signer is Gigi Sohn, the longtime consumer advocate who was nominated by President Biden to the Federal Communications Commission. After the US Senate <a href="https://arstechnica.com/tech-policy/2023/03/bidens-fcc-pick-withdraws-regrets-that-isps-get-to-choose-their-regulators/">refused to confirm</a> her nomination, Sohn became executive director of the nonprofit <a href="https://aapb.us/">American Association for Public Broadband</a> that lobbies for municipal networks.</p>
<p>The letter was signed by advocates from various other broadband-focused groups, including Public Knowledge; Connect Humanity; the Schools, Health &amp; Libraries Broadband Coalition; the Institute for Local Self-Reliance; Free Press; Next Century Cities; the Multicultural Media, Telecom, and Internet Council; the Coalition for Local Internet Choice; and Consumer Reports.</p>
<p>The letter was sent to Secretary of Commerce Gina Raimondo and NTIA Administrator Alan Davidson. Describing the BEAD program requirements, the letter said that participants must obtain a letter of credit "issued by an FDIC bank with Weiss rating of B- or better for 25 percent of the award amount."</p>
<h2>Rules strike wrong balance, letter says</h2>
<p>Funding rules are intended to ensure that ISPs deliver on commitments to build networks. As we <a href="https://arstechnica.com/tech-policy/2023/08/internet-providers-that-won-fcc-grants-try-to-escape-broadband-commitments/">wrote last month</a>, some ISPs that won grants from a different federal program are trying to escape their broadband-deployment commitments.</p>
<p>But the letter to the NTIA and Commerce Department argued that the letter-of-credit requirement is a bad method of ensuring compliance:</p>
<blockquote><p>Banks providing LOCs require that they be collateralized by cash or cash-equivalent. As a result, awardees will have to lock away vast sums of capital for the full duration of the build, likely several years. With the additional 25 percent match requirement, recipients will have a capital hurdle of more than 60 percent of their grant. We <a href="https://connecthumanity.fund/why-the-letter-of-credit-requirement-could-sink-bead/">estimate</a> a provider seeking a $7.5 million grant for a $10 million project will need at least $4.6 million of their own capital up-front.</p>
<p>While we support the NTIA's intention of ensuring providers are accountable for delivering on grants, far from safeguarding taxpayer dollars, the LOC requirement will prevent the Internet service providers best positioned to connect unserved and underserved Americans from participating.</p></blockquote>
<p>ISPs that signed the letter include Astound Broadband (owner of Grande, RCN, and Wave) and several smaller providers. A lobby group for small providers, the Wireless Internet Service Providers Association, signed as well.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[This page exists only if someone is looking at it (184 pts)]]></title>
            <link>http://ephemeralp2p.durazo.us/2bbbf21959178ef2f935e90fc60e5b6e368d27514fe305ca7dcecc32c0134838</link>
            <guid>37410630</guid>
            <pubDate>Wed, 06 Sep 2023 20:11:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://ephemeralp2p.durazo.us/2bbbf21959178ef2f935e90fc60e5b6e368d27514fe305ca7dcecc32c0134838">http://ephemeralp2p.durazo.us/2bbbf21959178ef2f935e90fc60e5b6e368d27514fe305ca7dcecc32c0134838</a>, See on <a href="https://news.ycombinator.com/item?id=37410630">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div>
      <p>Currently Viewing: <span id="visitor-count">0</span></p>
      <div id="js-console"><ul></ul></div>
      <hr>
      
    </div>
    
    
    
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon Andy Jassy shouldn’t make RTO decisions in echo chamber of CEOs feelings (125 pts)]]></title>
            <link>https://fortune.com/2023/09/05/amazon-andy-jassy-return-to-office-decisions-echo-chamber-ceo-feelings-work-gleb-tsipursky/</link>
            <guid>37408985</guid>
            <pubDate>Wed, 06 Sep 2023 18:20:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fortune.com/2023/09/05/amazon-andy-jassy-return-to-office-decisions-echo-chamber-ceo-feelings-work-gleb-tsipursky/">https://fortune.com/2023/09/05/amazon-andy-jassy-return-to-office-decisions-echo-chamber-ceo-feelings-work-gleb-tsipursky/</a>, See on <a href="https://news.ycombinator.com/item?id=37408985">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Where are CEOs like Amazon’s Andy Jassy getting the data to inform their return-to-office policies? Unfortunately, too many are getting their data from the same place: an echo chamber of like-minded CEOs who use their feelings and intuitions to make these pivotal decisions. By relying on word of mouth and following their gut, rather than the data, these CEOs could be leading their companies into catastrophe.</p><div>



<p>During a recent internal fireside chat that was first reported by Insider and then confirmed by <a href="https://fortune.com/company/amazon-com/" target="_blank" rel="">Amazon</a>, Jassy defended his top-down return-to-office mandate–a drastic shift from a <a href="https://fortune.com/2023/08/29/amazon-ceo-andy-jassy-return-to-office-mandate-or-face-consequences/" target="_self" rel="">flexible</a> policy of teams deciding what to do on their own to an obligation to come to the office three days a week. The company said employees knew all along that office policies would evolve with the pandemic–but it didn’t avert a backlash.</p>



<p>When asked for data to support the move, Jassy lacked a good answer. He said that he spoke to “60 to 80 CEOs of other companies over the last 18 months,” and “virtually all of them” preferred in-office work. He admitted it was a “judgment call” that wasn’t widely supported by data and compared it to another major decision that wasn’t supported by data in the past: the launch of the Amazon Web Services cloud unit.</p>



<h2>Data over feelings</h2>



<p>Is that an apt comparison? There were doubts internally and externally about the launch of AWS because it was an unproven business model. In other words, Amazon was going against the grain and taking a large risk with a huge potential upside if it worked. By contrast, a top-down RTO mandate of three days a week is not at all an “unproven business model.” There’s plenty of evidence around that model, much stronger than the echo chamber of like-minded CEOs. However, Jassy refused to lay out the evidence and relied instead on how he felt–and the validating echo chamber of other CEOs.</p>



<p>Doubling down on the rigid policy, Jassy <a href="https://fortune.com/2023/08/29/amazon-ceo-andy-jassy-return-to-office-mandate-or-face-consequences/" target="_self" rel="">told</a> staff that “it’s probably not going to work out for you” if you don’t come to the office. Amazon is tracking badge swipe data, and in early August sent a <a href="https://www.geekwire.com/2023/amazon-uses-badge-swipe-data-to-tell-employees-they-arent-complying-with-return-to-office-policy/" target="_self" rel="">message</a> to some employees, saying “We are reaching out as you are not currently meeting our expectation of joining your colleagues in the office at least three days a week, even though your assigned building is ready.” Amazon says it shares aggregated and anonymized badge-swipe data with managers to provide an overall view of how many members of a team are coming into the office, but doesn’t give managers data about badge swipes by individual employees.</p>



<p>Of course, Jassy is far from the only CEO to launch a rigid, top-down RTO mandate without relying on data and instead focusing on feelings. Consider <a href="https://fortune.com/company/starbucks/" target="_blank" rel="">Starbucks</a> CEO Howard Schultz’s <a href="https://www.hcamag.com/us/specialization/employee-engagement/starbucks-to-set-stricter-rto-policy/432831" target="_self" rel="">directive</a> for corporate staff to <a href="https://fortune.com/2023/06/16/how-ceo-return-to-office-mandates-can-be-legitimate-but-backfire-rto/" target="_self" rel="">come</a> to the office three days a week this January. According to Schultz, this policy stemmed from his annoyance that corporate employees hadn’t been following a guideline encouraging them to come into the office one or two days a week, as tracked by badge swipes into the building. What a terrible way to make a major RTO policy decision–based on feelings of annoyance about employee badge swipes!</p>



<p>In <a href="https://disasteravoidanceexperts.com/consulting" target="_self" rel="">my discussions</a> with five to 10 corporate leaders each week about best practices for <a href="https://disasteravoidanceexperts.com/hybrid" target="_self" rel="">RTO policies</a>, I hear many similar stories. Most CEOs tell me they decided on their RTO approach based primarily on discussing their intuitions about what works best with other corporate leaders. That’s a textbook example of <a href="https://disasteravoidanceexperts.com/nevergut/" target="_self" rel="">confirmation bias</a>–a <a href="https://www.top10.com/dating/top-10-cognitive-biases-to-avoid-in-dating" target="_self" rel="">cognitive bias</a> where we look for information that confirms our beliefs, and ignore information that doesn’t.</p>



<h2><a href="" target="_self" rel=""></a>Confirmation bias and RTO</h2>



<p>Why didn’t Jassy–or these other leaders–talk to the <a href="https://fortune.com/2023/08/29/atlassian-ceo-scott-farquhar-office-once-a-quarter-remote-work/#:~:text=Farquhar%20himself%20is%20worth%20%2411.7%20billion%2C%20according%20to%20estimates%20from%20Bloomberg." target="_self" rel="">CEO</a> or <a href="https://www.youtube.com/watch?v=6ExwGryS_FY" target="_self" rel="">CHRO</a> of <a href="https://fortune.com/company/atlassian/" target="_blank" rel="">Atlassian</a> about how well their famous remote model works? Because they would have provided data that contradicts these beliefs.</p>



<p>Yet CEOs keep getting surprised by the negative consequences of their echo-chamber-driven RTO decisions. In May, <a href="https://fortune.com/2023/05/31/amazon-employee-walk-protest-climate-rto-policies/" target="_self" rel="">hundreds</a> of Amazon employees walked out on their first RTO day from the company’s Seattle headquarters during the lunch hour, with signs like “Hell no, RTO!” Following the latest announcement, more than 30,000 employees joined a new Slack channel called “remote advocacy” shortly after the announcement and <a href="https://fortune.com/2023/08/29/amazon-ceo-andy-jassy-return-to-office-mandate-or-face-consequences/" target="_self" rel="">organized a petition</a>. In the petition, Amazon employees argued, based on research, that remote work improved productivity, recruitment, work/life balance, inclusion efforts, and reduced corporate expenses.</p>



<p>Andy Jassy’s judgment call rejected this data-driven approach, preferring instead to rely on the CEO echo chamber. That’s despite Amazon’s stock performance, which doubled during the pandemic’s remote work era. The dissonance between stock performance and the leadership’s discontent shows the gap between perceptions and reality around RTO.</p>



<p>We know that the perils of echo-chamber-driven approaches to RTO are not simply evident from case studies like with Amazon. A whopping 80% of bosses reported that they regret their initial return-to-office decisions, according to new research from Envoy, which interviewed more than 1,000 U.S. company executives and workplace managers who work in person at least one day per week.</p>



<p>Leaders said they’d do things differently if they knew more about how often employees actually show up at the office and use the amenities. Some are scratching their heads trying to figure out if their in-office policies are even working. Others are finding it tough to lock in long-term property deals without a clue about how their teams will feel about coming into the office down the road. Larry Gadea, Envoy’s CEO and founder, <a href="https://www.cnbc.com/2023/08/11/80percent-of-bosses-say-they-regret-earlier-return-to-office-plans.html" target="_self" rel="">said </a>“many companies are realizing they could have been a lot more measured in their approach, rather than making big, bold, very controversial decisions based on executives’ opinions rather than employee data.”</p>



<p>Or consider another data point, Unispace’s <em>Returning for Good</em> <a href="https://www.unispace.com/returning-for-good" target="_self" rel="">report</a>. Unispace discovered that a surprising 42% of firms with back-to-office rules saw more people quitting than they’d expected. Additionally, about 29% of these companies are having a hard time hiring new talent. So, while bosses knew pushing folks back into the office would shake things up, they didn’t see the big headaches coming.</p>



<p>Unispace adds a twist: it’s all about options. Their study shows that generally, employees say they’re happy (31%), motivated (30%), and excited (27%) to be back at the desk. But those good vibes dip when going back isn’t optional–dropping to 27%, 26%, and 22% respectively. So, people are more into the office comeback when it’s their call, not a mandate. That benefit of optionality is the same thing I find when gathering data from more than two dozen <a href="https://disasteravoidanceexperts.com/client-list/" target="_self" rel="">organizations</a> that I helped figure out their approach to RTO.</p>



<h2><a href="" target="_self" rel=""></a>Do all RTOs fail to use data?</h2>



<p>Far from all CEOs rely on intuition and the echo chamber in the return to office. In fact, (surprise, surprise) some actually use data. For example, Marc Benioff, the CEO of <a href="https://fortune.com/company/salesforce-com/" target="_blank" rel="">Salesforce</a>, <a href="https://fortune.com/2023/03/07/salesforce-ceo-marc-benioff-remote-work-in-office-mandate-productivity/" target="_self" rel="">said</a> that “for our new employees who are coming in, we know empirically that they do better if they’re in the office, meeting people, being onboarded, being trained. If they are at home and not going through that process, we don’t think they’re as successful.”</p>



<p>Benioff’s comments are supported by the data. A Harvard University working <a href="https://scholar.harvard.edu/pallais/publications/power-proximity-coworkers-training-tomorrow-or-productivity-today" target="_self" rel="">paper</a> studied software engineers at a Fortune 500 company with a main campus spread across two buildings separated by several blocks. The research focused on the impact of physical proximity on feedback, coding output, and retention.</p>



<p>The findings? Engineers who shared a building with all their teammates received 22% more online feedback compared to those who were further apart. However, once the pandemic closed offices, this edge mostly vanished, shrinking to just an 8% advantage in feedback. Interestingly, being in the same location seemed to cut programming output by 24%. This dip was even more pronounced for senior engineers, who saw a 39% drop, largely because they spent more time giving feedback to others. So, while close quarters can boost communication, they may also come with a cost to productivity–especially for the more experienced folks on the team. However, the study found that proximity helped junior folks succeed in the long run. And that’s a fair call for Salesforce to make.</p>



<p>More broadly, Salesforce is adopting a differentiated approach to hybrid work, with different amounts of in-office time not simply for staff with different tenure at the company, but also for different roles. Engineers are looking at just 10 days in the office per quarter, while admin folks need to show up three days a week. Sales and marketing teams need to be in the office four days a week unless they’re out hustling deals. Benioff, won’t even label their setup as a mandate. “I don’t want to force anybody,” he said, warning that pushing the issue too strongly would lead to an outflow of talent. “We don’t want to lose our stars.”</p>



<p>Instead of mandates, Benioff aims to make the office a place people want to be. He’s keeping the door open for employees to negotiate full remote status with their bosses. But he also made it clear that there will always be roles that require some face time.</p>



<p>While that’s not a perfect approach to RTO, it’s much better than most. It hits one of the three required elements of a truly effective RTO: customizing it to your organization’s needs. After all, as Benioff rightly points out, different roles have divergent needs for being in the office. Engineers might only need to come in 10 days a quarter, perhaps at the start and end of a sprint. Admin staff–whose job involves office management–need to cover office duties like helping people with copiers or receiving visitors, so you should make sure there’s always an admin to cover such needs. Accountants can come in a couple of days at the end of the month to close the books and for a week at the end of the quarter.</p>



<p>Just demanding a set number of days per week–as the large majority of major corporate giants have done–is a sign of laziness and conformism. The company’s leaders and HR failed to think through who needs to be in the office and for what purpose. Employees feel a lot of resentment when they come to the office without a good reason to be there, doing the same thing they would do at home.</p>



<h2><a href="" target="_self" rel=""></a>What a data-driven RTO looks like</h2>



<p>Salesforce unfortunately lacked two other key elements of a data-driven RTO: assessing employee opinions and getting their buy-in. Both of these problems are solved with similar tools, killing two birds with one stone.</p>



<p>First, you need to survey your staff on RTO–ideally before the RTO, or after it if you already launched the RTO. At all the companies I <a href="https://disasteravoidanceexperts.com/consulting" target="_self" rel="">worked</a> with to help guide their RTO, whether it’s from the start of the process or to refine it after RTO was already launched, we started with a thorough survey of staff opinions about remote work and the return to office. That survey involves questions around their preferences on RTO, intent to stay with various versions of RTO, whether they would recommend working here to their peers given these versions, their productivity on individual and collaborative tasks at home vs. in the office, and similar questions on well-being, happiness, morale, stress, and so on. The survey is available in the appendix of my best-selling book, <a href="https://disasteravoidanceexperts.com/hybrid/" target="_self" rel=""><em>Returning to the Office and Leading Hybrid and Remote Teams</em></a>.</p>



<p>Next, you’ll want to run focus groups. Choose representative staff from a variety of departments, both rank-and-file and managers at all levels of the organization. Make sure to avoid putting managers together with rank-and-file staff in focus groups, as many employees might be reluctant to be fully transparent when those in managerial roles are in the meeting.</p>



<p>Focus groups offer invaluable qualitative data, diving deeper into the “why” behind survey responses. They let you explore nuanced issues like work-life balance, home office setups, and team dynamics that a survey might not fully capture. This is where you can dig into some of the nuanced issues that a survey might not fully capture. For example, why do some employees prefer hybrid work over fully remote? Is it the office amenities, the team camaraderie, or something else? These sessions should ideally be run by a neutral party to encourage candid conversation and, with participant consent, be recorded for later analysis.</p>



<p>Once you’ve gathered this rich data, the next step is synthesis. Combine the qualitative insights from the focus groups with the quantitative metrics from the surveys. This dual approach not only informs the RTO strategy with a well-rounded perspective but also makes it deeply empathetic to employees’ needs and preferences.</p>



<p>Closing the loop is crucial. Share with employees the actionable steps you’ll take based on these discussions. Even if they don’t fully agree with the final decision, this transparent process makes them feel heard, listened to, and consulted.</p>



<p>The result? A significantly higher level of buy-in and reduced resistance to the RTO plan, as employees will feel that their opinions were genuinely considered in shaping the company’s future. Thus, unlike at Amazon, you won’t have employees leaking recordings of internal company meetings to the media and otherwise getting media involved in your company’s business. You also won’t have employees walking out and publicly protesting or signing mass petitions. None of that happened at any of my clients–because the employees felt listened to, respected, and heard, and because RTO policies were customized to the needs of each team and role.</p>



<p>Amazon illustrates the shortcomings of echo-chamber-driven RTO, characterized by employee resistance and low morale. In contrast, a nuanced, <a href="https://disasteravoidanceexperts.com/hybrid" target="_self" rel="">data-driven RTO approach</a> provides a balanced and empathetic strategy. Given that research on CEO plans for the future by Nick Bloom and other scholars indicates that there will be <a href="https://fortune.com/2023/08/31/remote-work-hybrid-to-grow-despite-return-to-office-push/" target="_self" rel="">more remote work</a>, not less, it seems that many leaders have learned that their initial RTO approach was wrong. Indeed, <a href="https://fortune.com/2023/08/14/bosses-regretting-return-to-office-mandates/" target="_self" rel="">Envoy finds</a> that over 80% of bosses regret their initial RTO plans, saying they wished they gathered more information and made data-driven decisions. By stepping out of the CEO echo chamber and engaging in meaningful dialogue with their workforce, companies can succeed in navigating the complexities of RTO.</p>



<p><em><a href="https://disasteravoidanceexperts.com/glebtsipursky/" target="_blank" rel="noreferrer noopener">Gleb Tsipursky</a>, Ph.D. (a.k.a. “the office whisperer”), helps tech and finance industry executives drive collaboration, innovation, and retention in hybrid work. He serves as the CEO of the boutique future-of-work consultancy<a href="http://disasteravoidanceexperts.com/" target="_blank" rel="noreferrer noopener">&nbsp;Disaster Avoidance Experts</a>. He is the bestselling author of seven books, including</em><a href="https://disasteravoidanceexperts.com/NeverGut/" target="_blank" rel="noreferrer noopener">&nbsp;Never Go With Your Gut</a><em>&nbsp;and<a href="https://disasteravoidanceexperts.com/hybrid/" target="_blank" rel="noreferrer noopener">&nbsp;</a></em><a href="https://disasteravoidanceexperts.com/hybrid/" target="_blank" rel="noreferrer noopener">Leading Hybrid and Remote Teams</a><em>. His expertise comes from over 20 years of<a href="https://disasteravoidanceexperts.com/consulting/" target="_blank" rel="noreferrer noopener">&nbsp;consulting</a>&nbsp;for Fortune 500 companies from&nbsp;<a href="https://fortune.com/company/aflac/" target="_blank" rel="noreferrer noopener">Aflac</a>&nbsp;to&nbsp;<a href="https://fortune.com/company/xerox/" target="_blank" rel="noreferrer noopener">Xerox</a>&nbsp;and<a href="http://disasteravoidanceexperts.com/research" target="_blank" rel="noreferrer noopener">&nbsp;over 15 years</a>&nbsp;in academia as a behavioral scientist at UNC–Chapel Hill and Ohio State.</em></p>



<p><em>The opinions expressed in Fortune.com commentary pieces are solely the views of their authors and do not necessarily reflect the opinions and beliefs of&nbsp;</em>Fortune<em>.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[37signals Introduces "Once" - Buy software one time (212 pts)]]></title>
            <link>https://once.com/</link>
            <guid>37408929</guid>
            <pubDate>Wed, 06 Sep 2023 18:17:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://once.com/">https://once.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37408929">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>

<p>Something happened to business software.</p>

<p>You used to pay for it <strong>once</strong>, install it, and run it. Whether on someone’s computer, or a server for everyone, it felt like you owned it. And you did.</p>

<p>Today, most software is a service. Not owned, but rented. Buying it enters you into a perpetual landlord–tenant agreement. Every month you pay for essentially the same thing you had last month. And if you stop paying, the software stops working. Boom, you’re evicted.</p>

<p>For nearly two decades, the SaaS model benefitted landlords handsomely. With routine prayers — and payers — to the Church of Recurring Revenue, valuations shot to the moon on the backs of businesses subscribed at luxury prices for commodity services they had little control over.</p>

<p>Add up your SaaS subscriptions last year. You should own that shit by now.</p>

<p>SaaS still makes sense for many products, but its grip will slip. Installation and administration used to be hopelessly complicated, but self–hosting tech is simpler now and vastly improved. Plus, IT departments are hungry to run their own IT again, tired of being subservient to Big Tech’s reign clouds.</p>

<p><strong>Once</strong> upon a time you owned what you paid for, you controlled what you depended on, and your privacy and security were your own business. We&nbsp;think it’s that time again.</p>

<p>Introducing <strong>ONCE</strong>, a new line of software products from <a href="https://37signals.com/" aria-label="37signals">37signals</a>.</p>

<ul>
  <li>Pay one time, own forever.</li>
  <li>We write the code, you get to see it.</li>
  <li>We give you the software, you get to host it.</li>
  <li>Simple and straightforward, not enterprisey and bloated.</li>
  <li>For one fixed price. <strong>Once</strong>.</li>
</ul>

<p>We’ll be launching the first product late 2023, with more coming in 2024.</p>

<p>In the early 2000s, we were among the early pioneers leading the industry into the SaaS revolution. Now, 20 years later, we intend to help lead the way out. The post–SaaS era is just around the corner.</p>

<p>Stay tuned.</p>

<figure>
  <svg height="74" viewBox="0 0 206 74" width="206" xmlns="http://www.w3.org/2000/svg"><g><path d="m5.1723 73.9729c.2844-.0225.56854-.0448.83144-.0057.24023-.0168.50201-.0077.7674.0014h.00114c.46196.016.93474.0324 1.32364-.0868.37051-.4298.84537-.4275 1.32046-.4251.08507.0003.17015.0007.25464-.0014.66128.0279 1.28668-.1561 1.91368-.3406.64-.1883 1.2817-.3772 1.9652-.3419 7.925-2.0285 15.5548-5.1628 23.0737-8.5121 12.2271-5.6184 23.9935-12.2231 34.4629-20.7335 10.9951-8.297 20.7221-18.2594 28.456-29.6447.1662-.2269.3357-.4542.5065-.6828.858-1.1507 1.737-2.3304 2.328-3.6373.242-.22925.351-.53381.461-.8385.12-.3324.239-.66505.531-.90003.098-.43311.32-.82471.541-1.21607.192-.33936.384-.67859.496-1.04468.247-.17395.285-.44348.322-.71167.03-.21546.06-.43006.199-.59351.361-.33972.43-.78638.501-1.23951l.011-.06738c.005-.03565.009-.07434.013-.11377.014-.12671.028-.26099.099-.32471.382-.33984.471-.78845.561-1.23499.037-.18811.075-.375854.134-.55481.428-.892337-1.178-.96912-1.227-.170655.011.393068-.188.672605-.388.954475-.101.14257-.203.28576-.278.44458-.021.51685-.304.90344-.586 1.28943-.146.2002-.292.40015-.402.61804-1.402 2.87929-3.263 5.43972-5.1325 8.01146l-.001.0011-.0066.0092-.0016.0022c-.4073.5603-.815 1.1211-1.2183 1.6859-15.676 19.2747-36.9664 33.3626-59.6186 43.0724-1.4535.6087-2.8926 1.2265-4.3289 1.8432l-.0202.0088c-1.6413.7048-3.2791 1.4081-4.9309 2.0945-.552.1517-1.085.3781-1.6199.6055-.5959.2533-1.1942.5076-1.8238.6605-.2401.0969-.4767.2086-.7142.3208-.5949.281-1.1956.5645-1.8712.6243-.1251.0383-.2409.1175-.3585.198-.1711.1172-.3462.2371-.5596.2371-.6616.1178-1.2805.397-1.8959.6746-.6688.3017-1.3335.6015-2.0444.6904-2.5939.9384-5.2663 2.0764-7.86188 3.211-.4756.3259-1.04911.4924-1.61843.6577-.37853.1098-.75521.2192-1.10004.3745-.29426.2655-.65667.3406-1.02161.4162-.30598.0634-.61372.1272-.88455.3039-.5668.3022-1.22365.3204-1.87702.3385-.8515.0237-1.69705.0471-2.329522.6988-1.211629 1.1585-.09727 1.9758 1.006842 2.4296.32342.3701.7578.3845 1.18323.3986.33553.0111.66551.0221.93113.2071.40204.4269.96414.3826 1.52525.3384z"></path><path d="m205.932 39.5745c.019-.0021.037-.0032.056-.0036l.012-2.6787c-.022.0033-.044.0048-.066.0045-.017-.0002-.033-.0013-.049-.0033-.047-.006-.093-.0199-.136-.0414-.077-.0387-.141-.1003-.182-.1765-1.313-1.9143-4.006-2.3119-6.198-2.3886-1.505.0393-3.011-.0032-4.518-.0458-1.631-.046-3.262-.0921-4.892-.0345-5.098.0594-10.194.0595-15.289.0596-5.47.0001-10.939.0003-16.41.0736-.192.0058-.384.0108-.577.0154-.203.005-.407.0095-.611.014h-.002c-1.608.0354-3.219.071-4.816.3118-.175.0257-.367.0529-.425-.1706.017-.368.4-.5519.766-.7272.186-.0889.367-.1756.493-.2829 9.253-5.2567 18.72-10.249 28.519-14.4171 4.279-1.7584 8.648-3.1826 13.029-4.6105l.002-.0007c1.965-.6405 3.932-1.2818 5.894-1.9543 1.685-.7032 3.448-1.3053 5.175-1.8949l.286-.0979v-2.36814c-.364-.03687-.708-.1493-1.051-.26136l-.001-.00036c-.482-.15735-.962-.31409-1.491-.26038-6.826.19287-13.481 2.16175-19.795 4.48904-13.038 5.2482-25.292 12.3459-36.789 20.3581-.367.2845-.75.5515-1.133.8187-.585.4074-1.17.8156-1.703 1.2884-.098.104-.216.1876-.346.2462s-.271.0908-.414.0951c-5.165.0238-10.327.2353-15.486.4862-4.384.2384-8.773.2386-13.163.2389-3.304.0002-6.609.0005-9.912.1023-.888.0153-1.931.2782-2.347 1.1739-.462 1.2096.672 2.3186 1.63 2.3186 4.147-.0509 8.284.1514 12.423.3538l.004.0004c4.172.2039 8.345.4079 12.529.3522.122.0036.244.0066.366.0094.315.0071.63.0118.946.0151.418.0042.838.0061 1.257.0079 1.735.0076 3.47.0151 5.2.198l.027.0026.018.0014c.03.0022.061.0037.093.0052.202.0096.413.0197.489.2398.061.1752-.076.2905-.206.3997-.037.0312-.074.062-.105.0935-.114.1153-.229.2302-.345.3448-.159.1585-.32.3164-.48.4744-.517.5096-1.035 1.0195-1.53 1.549-5.754 5.9818-10.234 13.0689-13.169 20.8323-.064.1812-.101.3717-.138.563-.073.3799-.146.7623-.44 1.0801-.109.3115-.139.6506-.169.9925-.048.5307-.096 1.0683-.437 1.5207-.224.633-.224 1.3017-.223 1.9728.001.8045.002 1.6124-.385 2.3659-.449 1.1535 1.558 1.0016 1.461-.0221.045-.2473.041-.5109.037-.7751-.007-.4556-.014-.9125.231-1.2893.358-.4232.399-.9197.418-1.4469.048-.5327.26-1.0319.471-1.5301.191-.4497.381-.8985.451-1.3704.253-.4028.433-.8531.612-1.2985.129-.3226.257-.6426.411-.94.101-.5041.382-.9487.663-1.3944.242-.3838.485-.7683.614-1.1922 3.198-6.7581 8.263-12.3885 13.799-17.3364.459-.4102.86-.7868 1.224-1.1288l.003-.0029c2.074-1.9492 2.954-2.7754 6.727-2.3097 11.817.3071 23.635.662 35.446 1.1363 5.783.2099 11.572.2576 17.36.2099l.132-.0146c1.991-.2183 4.394-.4819 5.73-2.0942.027-.0386.059-.0736.094-.1045.035-.031.074-.058.116-.0801.025-.0128.05-.024.075-.0334.024-.0087.048-.0158.073-.0214.022-.005.044-.0088.067-.0113z"></path><path d="m86.5189 51.9628c-.0151-.1412-.0216-.3863-.0297-.6904-.0391-1.4768-.115-4.343-1.3986-3.4403-.0791.0611-.1586.1219-.2384.1825-.1633.1241-.3277.247-.492.3701-.5633.4215-1.1267.8431-1.6502 1.3071-1.178.9183-2.4023 1.7471-3.634 2.5808l-.0107.0074c-.5955.403-1.1926.8072-1.7871 1.2235-.0906.0553-.1844.1148-.2808.176-.8882.5632-1.9944 1.2649-2.7687.0781-.0793-.1452-.1729-.2849-.2666-.4248-.2673-.399-.536-.7999-.4792-1.3393.0016-.0307-.0028-.0613-.0131-.0901-.0057-.016-.0132-.0313-.0222-.0456-.0072-.0116-.0155-.0224-.0247-.0326-.0206-.0227-.0455-.041-.0733-.054s-.0579-.0204-.0885-.0218c-.0095-.0009-.0191-.0017-.0286-.002-.01-.0004-.02-.0005-.03-.0003-.0667.0018-.1324.0187-.1921.0497-.0771.04-.1407.1019-.1828.1779-.3008.4333-.6809.7915-1.0608 1.1494-.368.3467-.7358.6932-1.0313 1.1079-.5448.7644-1.296 1.2566-2.0472 1.7488l-.231.1518c-1.1145 1.0545-2.488 1.7956-3.9813 2.1481-1.1946.2423-2.3891-1.0322-2.2185-2.2402.6764-1.2207 1.7506-2.1987 2.818-3.1705.5483-.4991 1.0949-.9968 1.5848-1.5249.3973-.4077.8705-.7066 1.3419-1.0045.6-.379 1.197-.7563 1.6308-1.3534.4818-.191.9396-.4303 1.3915-.6665l.001-.0004c1.2671-.6622 2.4888-1.3006 4.0684-.7902.1225.0179.2335.0819.3103.1789.0768.0972.1135.2199.1027.3432-.0628.4765-.6543.4691-1.185.4622-.3926-.005-.7519-.0095-.839.1828.0086.1705.1707.1262.2884.1211.2415-.0147.4833.0202.7107.1026s.4355.2106.6114.3766c.1759.1659.3159.3662.4114.5884s.1444.4616.1437.7034c.0254.139.0127.3006-.0002.4645-.0243.3084-.0492.6245.1794.8117.8112-.3012 1.5149-.8977 2.2199-1.4952l.0009-.0008c.5286-.448 1.0581-.8966 1.6342-1.2219.4586-.2687.839-.6239 1.2169-.9767.4741-.4426.9442-.8814 1.5596-1.1407.4879-.2175.8884-.5491 1.2862-.8786.4661-.386.9287-.769 1.5244-.9624 3.4355-.6333 3.5014 4.1956 3.5429 7.2403.0076.5563.0144 1.053.0408 1.4459l-.0004.0823c-.0024.3563-.005.7343.3894.9021 1.0549.1442 1.7443-.8755 2.3834-1.8207.2914-.431.5723-.8465.8726-1.1293.4194-.5081.8299-1.0276 1.241-1.5478 1.4757-1.8677 2.9605-3.7469 4.9025-5.1574 1.256-.8053 2.452.5921 2.821 1.7471.49 2.1942 2.43 3.6001 4.577 3.9515.698.4666 1.477.5063 2.256.5459.347.0177.693.0354 1.032.0905.173.0387.346.079.518.1191.845.1973 1.683.3927 2.567.3927 2.554.076 5.106.0808 7.659.0856.658.0012 1.316.0025 1.975.0049 1 0 1.676.4744 1.891 1.2694.274 2.0668-2.122 1.9133-3.889 1.8002-.432-.0276-.825-.0529-1.134-.0429-.834-.0387-1.67-.0531-2.505-.0675-1.412-.0243-2.824-.0486-4.23-.19-.549-.0434-1.09-.1623-1.606-.3532-.445-.1492-.913-.1555-1.379-.1617-.685-.0093-1.363-.0185-1.952-.4816-.273-.1472-.593-.1715-.915-.1959-.424-.0322-.851-.0647-1.177-.379-.028-.0304-.059-.0568-.093-.0788-.052-.0336-.11-.0567-.172-.068-.529-.0149-.976-.2488-1.421-.482-.22-.115-.439-.2298-.668-.3182-.983-.6483-1.827-1.4865-2.483-2.4654-.172-.1437-.297-.4701-.4209-.7973-.2344-.6164-.4697-1.2351-1.0327-.6375-1.159 1.1649-2.213 2.4204-3.2667 3.6756-1.2737 1.5171-2.547 3.0337-4.0047 4.3895-1.3208 1.3017-3.9881.9349-4.7663-.7832-.3374-.8251-.3192-1.7735-.3014-2.7011.0072-.3768.0144-.7503-.0024-1.1105z"></path><path d="m168.834 51.9001c.791.0129 1.549.0252 2.067.1565 3.025-.0341 14.109-1.4963 12.745-5.9562-.355-1.6277-3.035-1.969-2.73.1313.087.7388-.123 1.0117-.831 1.2506-.448.149-.889.3308-1.331.5131-.869.3584-1.741.7183-2.673.8314-3.126.9129-7.32 1.3582-10.442.0597-.244-.0859-.502-.1116-.758-.137-.47-.0466-.932-.0925-1.289-.5113-.792-.1758-1.5-.6091-2.157-1.0647-.329-.2835-.605-.5399-.844-.7623-1.322-1.2292-1.524-1.4172-3.394.6532-.118.0704-.317.2929-.54.5426-.448.5001-.993 1.1091-1.18.8222-.306-.4521-.539-.9897-.774-1.5311-.504-1.1621-1.015-2.342-2.277-2.7343-2.022-1.1056-4.101.7132-5.574 2.0151-.867.514-1.613 1.1892-2.356 1.8623-.559.5063-1.116 1.0114-1.724 1.4459-.475.1896-.847.5081-1.22.8273-.077.0658-.154.1316-.232.1964-1.163 1.1523-2.402 2.217-3.642 3.2819-1.289 1.1075-2.578 2.2152-3.781 3.4217-.366.3406-.711.7005-1.056 1.0604-.388.4046-.776.8091-1.194 1.1866-.083.0754-.172.148-.263.2215-.331.269-.674.5481-.784 1.0104-.308.8308.737.8377 1.131.3685.858-.7519 1.753-1.4521 2.648-2.1523.959-.7504 1.918-1.5006 2.832-2.3145.666-.2895 1.172-.7656 1.68-1.2431.464-.437.93-.8753 1.521-1.1728 1.002-.6223 1.967-1.4524 2.931-2.2821.859-.7399 1.718-1.4792 2.603-2.0704.551-.304 1.174-.815 1.821-1.3457 2.001-1.6411 4.231-3.4703 5.263.0559.174.9178.742 1.6311 1.44 2.1992.513.6563 1.06.3147 1.597-.0203.126-.0787.252-.1571.376-.222.383-.093.732-.2924 1.007-.575l.171-.16c.454-.4247.904-.8459 1.235-1.3857.509-.582 1.132.0031 1.777.6091.454.4264.919.8632 1.363.9111.198.0679.383.1818.57.2976.283.175.573.354.928.3848l.094.0739c.337.2681.663.5272 1.132.4585.327-.012.672-.024.919.2371.58.5124 1.929.5343 3.195.555z"></path></g></svg>
</figure>

<dl>
  <dt>Jason Fried</dt>
  <dd>CEO, 37signals</dd>
  <dd><a href="https://once.com/cdn-cgi/l/email-protection#afc5cedcc0c1ef9c98dcc6c8c1cec3dc81ccc0c2"><span data-cfemail="b3d9d2c0dcddf38084c0dad4ddd2dfc09dd0dcde">[email&nbsp;protected]</span></a></dd>
</dl>


      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Results of technical investigations for Storm-0558 key acquisition (182 pts)]]></title>
            <link>https://msrc.microsoft.com/blog/2023/09/results-of-major-technical-investigations-for-storm-0558-key-acquisition/</link>
            <guid>37408776</guid>
            <pubDate>Wed, 06 Sep 2023 18:07:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://msrc.microsoft.com/blog/2023/09/results-of-major-technical-investigations-for-storm-0558-key-acquisition/">https://msrc.microsoft.com/blog/2023/09/results-of-major-technical-investigations-for-storm-0558-key-acquisition/</a>, See on <a href="https://news.ycombinator.com/item?id=37408776">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					<p>On July 11, 2023, Microsoft published a <a href="https://msrc.microsoft.com/blog/2023/07/microsoft-mitigates-china-based-threat-actor-storm-0558-targeting-of-customer-email/" target="_blank" rel="noopener">blog post</a> which details how the China-Based threat actor, Storm-0558, used an acquired Microsoft account (MSA) consumer key to forge tokens to access OWA and Outlook.com. Upon identifying that the threat actor had acquired the consumer key, Microsoft performed a comprehensive technical investigation into the acquisition of the Microsoft account consumer signing key, including how it was used to access enterprise email. Our technical investigation has concluded. As part of our commitment to transparency and trust, we are releasing our investigation findings.</p>

    <h2 id="key-acquisition">
        Key acquisition&nbsp;&nbsp;
        <a href="#key-acquisition">Key acquisition&nbsp;&nbsp;</a>
    </h2>
<p>Microsoft maintains a highly isolated and restricted production environment. Controls for Microsoft employee access to production infrastructure include background checks, dedicated accounts, secure access workstations, and multi-factor authentication using hardware token devices. Controls in this environment also prevent the use of email, conferencing, web research and other collaboration tools which can lead to common account compromise vectors such as malware infections or phishing, as well as restricting access to systems and data using Just in Time and Just Enough Access policies.</p>
<p>Our corporate environment, which also requires secure authentication and secure devices, allows for email, conferencing, web research and other collaboration tools. While these tools are important, they also make users vulnerable to spear phishing, token stealing malware, and other account compromise vectors. For this reason - by policy and as part of our Zero-Trust and “assume breach” mindset - key material should not leave our production environment.</p>
<p>Our investigation found that a consumer signing system crash in April of 2021 resulted in a snapshot of the crashed process (“crash dump”). The crash dumps, which redact sensitive information, should not include the signing key. In this case, a race condition allowed the key to be present in the crash dump (this issue has been corrected). The key material’s presence in the crash dump was not detected by our systems (this issue has been corrected).</p>
<p>We found that this crash dump, believed at the time not to contain key material, was subsequently moved from the isolated production network into our debugging environment on the internet connected corporate network. This is consistent with our standard debugging processes. Our credential scanning methods did not detect its presence (this issue has been corrected).&nbsp;&nbsp;</p>
<p>After April 2021, when the key was leaked to the corporate environment in the crash dump, the Storm-0558 actor was able to successfully compromise a Microsoft engineer’s corporate account. This account had access to the debugging environment containing the crash dump which incorrectly contained the key. Due to log retention policies, we don’t have logs with specific evidence of this exfiltration by this actor, but this was the most probable mechanism by which the actor acquired the key.</p>

    <h2 id="why-a-consumer-key-was-able-to-access-enterprise-mail">
        Why a consumer key was able to access enterprise mail
        <a href="#why-a-consumer-key-was-able-to-access-enterprise-mail">Why a consumer key was able to access enterprise mail</a>
    </h2>
<p>To meet growing customer demand to support applications which work with both consumer and enterprise applications, Microsoft <a href="https://techcommunity.microsoft.com/t5/microsoft-entra-azure-ad-blog/for-developers-the-first-use-cases-of-the-converged-microsoft/ba-p/244232" target="_blank" rel="noopener">introduced</a> a common key metadata publishing endpoint in September 2018. As part of this converged offering, Microsoft updated documentation to clarify the requirements for key scope validation – which key to use for enterprise accounts, and which to use for consumer accounts.&nbsp;&nbsp;</p>
<p>As part of a pre-existing library of documentation and helper APIs, Microsoft provided an API to help validate the signatures cryptographically but did not update these libraries to perform this scope validation automatically (this issue has been corrected). The mail systems were updated to use the common metadata endpoint in 2022. Developers in the mail system incorrectly assumed libraries performed complete validation and did not add the required issuer/scope validation. Thus, the mail system would accept a request for enterprise email using a security token signed with the consumer key (this issue has been corrected using the updated libraries).&nbsp;&nbsp;</p>

    <h2 id="post-incident-review">
        Post Incident Review
        <a href="#post-incident-review">Post Incident Review</a>
    </h2>
<p>Microsoft is continuously hardening systems as part of our defense in depth strategy. Investments which have been made related to MSA key management are covered in the <a href="https://aka.ms/storm-0558" target="_blank" rel="noopener">https://aka.ms/storm-0558</a> blog. Items detailed in this blog are a subset of these overall investments. We are summarizing the improvements specific to these findings here for clarity:</p>
<ol>
<li>
<p>Identified and resolved race Condition that allowed the signing key to be present in crash dumps</p>
</li>
<li>
<p>Enhanced prevention, detection, and response for key material erroneously included in crash dumps</p>
</li>
<li>
<p>Enhanced credential scanning to better detect presence of signing key in the debugging environment</p>
</li>
<li>
<p>Released enhanced libraries to automate key scope validation in authentication libraries, and clarified related documentation</p>
</li>
</ol>

				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.K. abandons, for now, legislation that would have banned end-to-end encryption (580 pts)]]></title>
            <link>https://daringfireball.net/linked/2023/09/06/uk-encryption-win</link>
            <guid>37408196</guid>
            <pubDate>Wed, 06 Sep 2023 17:28:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daringfireball.net/linked/2023/09/06/uk-encryption-win">https://daringfireball.net/linked/2023/09/06/uk-encryption-win</a>, See on <a href="https://news.ycombinator.com/item?id=37408196">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="Box">


<dl>
<dt><a href="https://www.ft.com/content/770e58b1-a299-4b7b-a129-bded8649a43b">U.K. Abandons, for Now, Legislation That Would Have Banned End-to-End Encryption</a></dt>
<dd>
<p>Cristina Criddle, Anna Gross, and John Aglionby, reporting from London for The Financial Times:</p>

<blockquote>
  <p>The UK government has conceded it will not use controversial
powers in the online safety bill to scan messaging apps for
harmful content until it is “technically feasible” to do so,
postponing measures that critics say threaten users’ privacy.</p>

<p>In a statement to the House of Lords on Wednesday afternoon,
junior arts and heritage minister Lord Stephen Parkinson sought to
mark an eleventh-hour effort to end a stand-off with tech
companies, including WhatsApp, that have threatened to pull their
services from the UK over what they claimed was an intolerable
threat to millions of users’ privacy and security.</p>

<p>Parkinson said that Ofcom, the tech regulator, would only require
companies to scan their networks when a technology is developed
that is capable of doing so. Many security experts believe it
could be years before any such technology is developed, if ever.</p>
</blockquote>

<p><em>No, Thursday’s out. How about never — <a href="https://www.newyorker.com/cartoons/bob-mankoff/the-story-of-how-about-never">is never good for you</a>?</em></p>

<blockquote>
  <p>WhatsApp, owned by Facebook’s parent Meta, and Signal, another
popular encrypted messaging app, are among those that have
threatened to exit the UK market should they be ordered to weaken
encryption, a widely used security technology that allows only
the sender and recipient of messages to view a message’s
contents. [...]</p>

<p>Officials have privately acknowledged to tech companies that there
is no current technology able to scan end-to-end encrypted
messages that would not also undermine users’ privacy, according
to several people briefed on the government’s thinking.</p>
</blockquote>

<p>This isn’t the worst reporting on encryption and lawmakers’ fantasies about “backdoors only accessible by the good guys”, but it’s fundamentally misleading. End-to-end encryption’s meaning is right there in its name. There’s no dial that can be adjusted from “weak” to “strong”. There’s no option for content inspection between end points. It’s not about choosing not to allow eavesdroppers, it’s about implementing protocols where it’s technically impossible to inspect content between sender and receiver.</p>

<p>The actual math is far more complex, but ultimately this boils down to the U.K. acknowledging that 2 + 2 can only equal 4.</p>

<p>★ <em>Wednesday, 6 September 2023</em></p>
</dd>
</dl>




<!-- Google Analytics -->

<!-- 
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-593949-1']);
  _gaq.push (['_gat._anonymizeIp']);
  _gaq.push(['_trackPageview']);
  (function() {
	var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
	ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
	var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
 -->

<!-- Asynchronously load Mint -->
<!-- No, screw mint
<script type="text/javascript">
(function () {
	var ma = document.createElement('script');
	ma.type = 'text/javascript';
	ma.src = '/mint/?js';
	ma.async = true;
	var s = document.getElementsByTagName('script')[0];
	s.parentNode.insertBefore(ma, s);
})();
</script>
-->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Host a Website in the URL (210 pts)]]></title>
            <link>https://smolsite.zip/UEsDBBQAAgAIAMYVIVfaTMb/VQIAANwDAAAKAAAAaW5kZXguaHRtbHVTUW+bMBB+Lr/ilq1i0wo4BGghJA/t9lBpk6Zpm6Y91cEOeAPMbCeEbv3vO0OjZdIK4mTuvvt8+vw5r0xTr5284pStc22Gmq+djWQD/HI2tPhRKrlrmVfIWqoMnm/HZ3laEg0teQY7Vb+cMWpoNiYCvS9fH5r64nxxg0voBTPVyp2HLlRclJXBdeLCXvD+Wh5WLgEC8xBsDrtavXIrY7osCPq+9/uFL1UZhIQQy+ueL94ibUdNBWzlvo/AT9MbjFEUQ4QxQrIYSOHHcWh5sRLbmKb7yCfhTQIxluIxJoB/kBTeBPbmHoJtTNMv+N03CVwVBKtRYpltHsbqE+QFAYv1LBhz3lj5H/mVZXdhK+p65Z6HC3bJYkanhCc7WggzoC5+9JhSu5qvXL7nrWTMDSYNrBy4mr1aOlvZGm9LG1EPGWjaak9zJfCsGqpK0WYo71V3WDoPTsFbwxUe8FlHGRNteVLrFLeFv+eLhx4S+y6ds6MLLol9lyf9IbHtZ4YfzNErU+rByYPJVXkweszJrbus4+brW+NqoKAbWWth+DOEzNeOk3frT5XQ0Fey5mArqIDRIFotGAdTcfj88R2iu0ewhEpqA4PcKY1O1BOmkE1D0aC1aNGf3c4AiqcGU+HEyIUbf7v9YLXlF3BNsSmJgLeFxC2EuQBsBYMy4A/QrRVsZi2p0ZPHgf170QWz7DiIwqvzAjAH3puv33+moGXDjzjckfGDb68bNEMtS+l3bYl4XlTyCeq7gpp/SX7DBifFQT2vV7QDcjdDgced82ASFhfTnXb+AFBLAQIeAxQAAgAIAMYVIVfaTMb/VQIAANwDAAAKAAAAAAAAAAEAAACkgQAAAABpbmRleC5odG1sUEsFBgAAAAABAAEAOAAAAH0CAAAAAA==</link>
            <guid>37408150</guid>
            <pubDate>Wed, 06 Sep 2023 17:24:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://smolsite.zip/UEsDBBQAAgAIAMYVIVfaTMb/VQIAANwDAAAKAAAAaW5kZXguaHRtbHVTUW+bMBB+Lr/ilq1i0wo4BGghJA/t9lBpk6Zpm6Y91cEOeAPMbCeEbv3vO0OjZdIK4mTuvvt8+vw5r0xTr5284pStc22Gmq+djWQD/HI2tPhRKrlrmVfIWqoMnm/HZ3laEg0teQY7Vb+cMWpoNiYCvS9fH5r64nxxg0voBTPVyp2HLlRclJXBdeLCXvD+Wh5WLgEC8xBsDrtavXIrY7osCPq+9/uFL1UZhIQQy+ueL94ibUdNBWzlvo/AT9MbjFEUQ4QxQrIYSOHHcWh5sRLbmKb7yCfhTQIxluIxJoB/kBTeBPbmHoJtTNMv+N03CVwVBKtRYpltHsbqE+QFAYv1LBhz3lj5H/mVZXdhK+p65Z6HC3bJYkanhCc7WggzoC5+9JhSu5qvXL7nrWTMDSYNrBy4mr1aOlvZGm9LG1EPGWjaak9zJfCsGqpK0WYo71V3WDoPTsFbwxUe8FlHGRNteVLrFLeFv+eLhx4S+y6ds6MLLol9lyf9IbHtZ4YfzNErU+rByYPJVXkweszJrbus4+brW+NqoKAbWWth+DOEzNeOk3frT5XQ0Fey5mArqIDRIFotGAdTcfj88R2iu0ewhEpqA4PcKY1O1BOmkE1D0aC1aNGf3c4AiqcGU+HEyIUbf7v9YLXlF3BNsSmJgLeFxC2EuQBsBYMy4A/QrRVsZi2p0ZPHgf170QWz7DiIwqvzAjAH3puv33+moGXDjzjckfGDb68bNEMtS+l3bYl4XlTyCeq7gpp/SX7DBifFQT2vV7QDcjdDgced82ASFhfTnXb+AFBLAQIeAxQAAgAIAMYVIVfaTMb/VQIAANwDAAAKAAAAAAAAAAEAAACkgQAAAABpbmRleC5odG1sUEsFBgAAAAABAAEAOAAAAH0CAAAAAA==">https://smolsite.zip/UEsDBBQAAgAIAMYVIVfaTMb/VQIAANwDAAAKAAAAaW5kZXguaHRtbHVTUW+bMBB+Lr/ilq1i0wo4BGghJA/t9lBpk6Zpm6Y91cEOeAPMbCeEbv3vO0OjZdIK4mTuvvt8+vw5r0xTr5284pStc22Gmq+djWQD/HI2tPhRKrlrmVfIWqoMnm/HZ3laEg0teQY7Vb+cMWpoNiYCvS9fH5r64nxxg0voBTPVyp2HLlRclJXBdeLCXvD+Wh5WLgEC8xBsDrtavXIrY7osCPq+9/uFL1UZhIQQy+ueL94ibUdNBWzlvo/AT9MbjFEUQ4QxQrIYSOHHcWh5sRLbmKb7yCfhTQIxluIxJoB/kBTeBPbmHoJtTNMv+N03CVwVBKtRYpltHsbqE+QFAYv1LBhz3lj5H/mVZXdhK+p65Z6HC3bJYkanhCc7WggzoC5+9JhSu5qvXL7nrWTMDSYNrBy4mr1aOlvZGm9LG1EPGWjaak9zJfCsGqpK0WYo71V3WDoPTsFbwxUe8FlHGRNteVLrFLeFv+eLhx4S+y6ds6MLLol9lyf9IbHtZ4YfzNErU+rByYPJVXkweszJrbus4+brW+NqoKAbWWth+DOEzNeOk3frT5XQ0Fey5mArqIDRIFotGAdTcfj88R2iu0ewhEpqA4PcKY1O1BOmkE1D0aC1aNGf3c4AiqcGU+HEyIUbf7v9YLXlF3BNsSmJgLeFxC2EuQBsBYMy4A/QrRVsZi2p0ZPHgf170QWz7DiIwqvzAjAH3puv33+moGXDjzjckfGDb68bNEMtS+l3bYl4XlTyCeq7gpp/SX7DBifFQT2vV7QDcjdDgced82ASFhfTnXb+AFBLAQIeAxQAAgAIAMYVIVfaTMb/VQIAANwDAAAKAAAAAAAAAAEAAACkgQAAAABpbmRleC5odG1sUEsFBgAAAAABAAEAOAAAAH0CAAAAAA==</a>, See on <a href="https://news.ycombinator.com/item?id=37408150">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
    <p>  Hosted in the URL by 🗜️
      <b>smolsite.zip</b>. Powered by the 
      <a href="https://lwan.ws/">Lwan</a> web server.  
    </p>
    
  
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Socialism? (1949) (182 pts)]]></title>
            <link>https://monthlyreview.org/2009/05/01/why-socialism/</link>
            <guid>37407331</guid>
            <pubDate>Wed, 06 Sep 2023 16:21:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://monthlyreview.org/2009/05/01/why-socialism/">https://monthlyreview.org/2009/05/01/why-socialism/</a>, See on <a href="https://news.ycombinator.com/item?id=37407331">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content">
<p>Dear Reader, we make this and other articles available for free online to serve those unable to afford or access the print edition of <em>Monthly Review</em>. If you read the magazine online and can afford a print subscription, we hope you will consider purchasing one. <a href="https://monthlyreview.org/press/subscriptions/">Please visit the MR store for subscription options</a>. Thank you very much. </p> 
<article>

<header>

</header>

 <div>
<p><a href="https://p4r4f7y4.rocketcdn.me/wp-content/uploads/2009/05/chalk-drawing-of-albert-einstein-e1499809200192.jpeg" rel="lightbox" title="Why Socialism?"><img src="https://p4r4f7y4.rocketcdn.me/wp-content/uploads/2009/05/chalk-drawing-of-albert-einstein-e1499809200192-300x300.jpeg" alt="Albert Einstein (1959), charcoal and watercolor drawing by Alexander Dobkin" width="300" height="300" title="Why Socialism?" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-lazy-src="https://p4r4f7y4.rocketcdn.me/wp-content/uploads/2009/05/chalk-drawing-of-albert-einstein-e1499809200192-300x300.jpeg"></a></p><p><em>Albert Einstein</em> (1959), charcoal and watercolor drawing by Alexander Dobkin. Dobkin (1908–1975) was an important painter of the mid-twentieth century American realist tradition along with other left-wing artists such as Jack Levine, Robert Gwathmey, Philip Evergood, and Raphael and Moses Soyer. A student and collaborator of the Mexican muralist Jose Clemente Orozco, his work is in the permanent collections of the Butler Art Institute, the Museum of Modern Art, the Brooklyn Museum, the Whitney Museum of American Art, the Philadelphia Museum of Art, the Library of Congress, and the Smithsonian Institution. (The preceding caption was written by John J. Simon, "<a href="https://monthlyreview.org/2005/05/01/albert-einstein-radical-a-political-profile/">Albert Einstein, Radical: A Political Profile</a>," <em>Monthly Review</em> vol. 57, no. 1 [2005].)</p>

</div>
<section>
<div>
<p>Albert Einstein is the world-famous physicist. This article was originally published in the first issue of <em>Monthly Review</em> (May 1949). It was subsequently published in May 1998 to commemorate the first issue of <em>MR</em>‘s fiftieth year.</p>
<p>—<span>The Editors</span></p>
</div>
<p>Is it advisable for one who is not an expert on economic and social issues to express views on the subject of socialism? I believe for a number of reasons that it is.</p>
<p>Let us first consider the question from the point of view of scientific knowledge. It might appear that there are no essential methodological differences between astronomy and economics: scientists in both fields attempt to discover laws of general acceptability for a circumscribed group of phenomena in order to make the interconnection of these phenomena as clearly understandable as possible. But in reality such methodological differences do exist. The discovery of general laws in the field of economics is made difficult by the circumstance that observed economic phenomena are often affected by many factors which are very hard to evaluate separately. In addition, the experience which has accumulated since the beginning of the so-called civilized period of human history has—as is well known—been largely influenced and limited by causes which are by no means exclusively economic in nature. For example, most of the major states of history owed their existence to conquest. The conquering peoples established themselves, legally and economically, as the privileged class of the conquered country. They seized for themselves a monopoly of the land ownership and appointed a priesthood from among their own ranks. The priests, in control of education, made the class division of society into a permanent institution and created a system of values by which the people were thenceforth, to a large extent unconsciously, guided in their social behavior.</p>
<p>But historic tradition is, so to speak, of yesterday; nowhere have we really overcome what Thorstein Veblen called “the predatory phase” of human development. The observable economic facts belong to that phase and even such laws as we can derive from them are not applicable to other phases. Since the real purpose of socialism is precisely to overcome and advance beyond the predatory phase of human development, economic science in its present state can throw little light on the socialist society of the future.</p>
<p>Second, socialism is directed towards a social-ethical end. Science, however, cannot create ends and, even less, instill them in human beings; science, at most, can supply the means by which to attain certain ends. But the ends themselves are conceived by personalities with lofty ethical ideals and—if these ends are not stillborn, but vital and vigorous—are adopted and carried forward by those many human beings who, half unconsciously, determine the slow evolution of society.</p>
<p>For these reasons, we should be on our guard not to overestimate science and scientific methods when it is a question of human problems; and we should not assume that experts are the only ones who have a right to express themselves on questions affecting the organization of society.</p>
<p>Innumerable voices have been asserting for some time now that human society is passing through a crisis, that its stability has been gravely shattered. It is characteristic of such a situation that individuals feel indifferent or even hostile toward the group, small or large, to which they belong. In order to illustrate my meaning, let me record here a personal experience. I recently discussed with an intelligent and well-disposed man the threat of another war, which in my opinion would seriously endanger the existence of mankind, and I remarked that only a supra-national organization would offer protection from that danger. Thereupon my visitor, very calmly and coolly, said to me: “Why are you so deeply opposed to the disappearance of the human race?”</p>
<p>I am sure that as little as a century ago no one would have so lightly made a statement of this kind. It is the statement of a man who has striven in vain to attain an equilibrium within himself and has more or less lost hope of succeeding. It is the expression of a painful solitude and isolation from which so many people are suffering in these days. What is the cause? Is there a way out?</p>
<p>It is easy to raise such questions, but difficult to answer them with any degree of assurance. I must try, however, as best I can, although I am very conscious of the fact that our feelings and strivings are often contradictory and obscure and that they cannot be expressed in easy and simple formulas.</p>
<p>Man is, at one and the same time, a solitary being and a social being. As a solitary being, he attempts to protect his own existence and that of those who are closest to him, to satisfy his personal desires, and to develop his innate abilities. As a social being, he seeks to gain the recognition and affection of his fellow human beings, to share in their pleasures, to comfort them in their sorrows, and to improve their conditions of life. Only the existence of these varied, frequently conflicting, strivings accounts for the special character of a man, and their specific combination determines the extent to which an individual can achieve an inner equilibrium and can contribute to the well-being of society. It is quite possible that the relative strength of these two drives is, in the main, fixed by inheritance. But the personality that finally emerges is largely formed by the environment in which a man happens to find himself during his development, by the structure of the society in which he grows up, by the tradition of that society, and by its appraisal of particular types of behavior. The abstract concept “society” means to the individual human being the sum total of his direct and indirect relations to his contemporaries and to all the people of earlier generations. The individual is able to think, feel, strive, and work by himself; but he depends so much upon society—in his physical, intellectual, and emotional existence—that it is impossible to think of him, or to understand him, outside the framework of society. It is “society” which provides man with food, clothing, a home, the tools of work, language, the forms of thought, and most of the content of thought; his life is made possible through the labor and the accomplishments of the many millions past and present who are all hidden behind the small word “society.”</p>
<p>It is evident, therefore, that the dependence of the individual upon society is a fact of nature which cannot be abolished—just as in the case of ants and bees. However, while the whole life process of ants and bees is fixed down to the smallest detail by rigid, hereditary instincts, the social pattern and interrelationships of human beings are very variable and susceptible to change. Memory, the capacity to make new combinations, the gift of oral communication have made possible developments among human being which are not dictated by biological necessities. Such developments manifest themselves in traditions, institutions, and organizations; in literature; in scientific and engineering accomplishments; in works of art. This explains how it happens that, in a certain sense, man can influence his life through his own conduct, and that in this process conscious thinking and wanting can play a part.</p>
<p>Man acquires at birth, through heredity, a biological constitution which we must consider fixed and unalterable, including the natural urges which are characteristic of the human species. In addition, during his lifetime, he acquires a cultural constitution which he adopts from society through communication and through many other types of influences. It is this cultural constitution which, with the passage of time, is subject to change and which determines to a very large extent the relationship between the individual and society. Modern anthropology has taught us, through comparative investigation of so-called primitive cultures, that the social behavior of human beings may differ greatly, depending upon prevailing cultural patterns and the types of organization which predominate in society. It is on this that those who are striving to improve the lot of man may ground their hopes: human beings are not condemned, because of their biological constitution, to annihilate each other or to be at the mercy of a cruel, self-inflicted fate.</p>
<p>If we ask ourselves how the structure of society and the cultural attitude of man should be changed in order to make human life as satisfying as possible, we should constantly be conscious of the fact that there are certain conditions which we are unable to modify. As mentioned before, the biological nature of man is, for all practical purposes, not subject to change. Furthermore, technological and demographic developments of the last few centuries have created conditions which are here to stay. In relatively densely settled populations with the goods which are indispensable to their continued existence, an extreme division of labor and a highly-centralized productive apparatus are absolutely necessary. The time—which, looking back, seems so idyllic—is gone forever when individuals or relatively small groups could be completely self-sufficient. It is only a slight exaggeration to say that mankind constitutes even now a planetary community of production and consumption.</p>
<p>I have now reached the point where I may indicate briefly what to me constitutes the essence of the crisis of our time. It concerns the relationship of the individual to society. The individual has become more conscious than ever of his dependence upon society. But he does not experience this dependence as a positive asset, as an organic tie, as a protective force, but rather as a threat to his natural rights, or even to his economic existence. Moreover, his position in society is such that the egotistical drives of his make-up are constantly being accentuated, while his social drives, which are by nature weaker, progressively deteriorate. All human beings, whatever their position in society, are suffering from this process of deterioration. Unknowingly prisoners of their own egotism, they feel insecure, lonely, and deprived of the naive, simple, and unsophisticated enjoyment of life. Man can find meaning in life, short and perilous as it is, only through devoting himself to society.</p>
<p>The economic anarchy of capitalist society as it exists today is, in my opinion, the real source of the evil. We see before us a huge community of producers the members of which are unceasingly striving to deprive each other of the fruits of their collective labor—not by force, but on the whole in faithful compliance with legally established rules. In this respect, it is important to realize that the means of production—that is to say, the entire productive capacity that is needed for producing consumer goods as well as additional capital goods—may legally be, and for the most part are, the private property of individuals.</p>
<p>For the sake of simplicity, in the discussion that follows I shall call “workers” all those who do not share in the ownership of the means of production—although this does not quite correspond to the customary use of the term. The owner of the means of production is in a position to purchase the labor power of the worker. By using the means of production, the worker produces new goods which become the property of the capitalist. The essential point about this process is the relation between what the worker produces and what he is paid, both measured in terms of real value. Insofar as the labor contract is “free,” what the worker receives is determined not by the real value of the goods he produces, but by his minimum needs and by the capitalists’ requirements for labor power in relation to the number of workers competing for jobs. It is important to understand that even in theory the payment of the worker is not determined by the value of his product.</p>
<p>Private capital tends to become concentrated in few hands, partly because of competition among the capitalists, and partly because technological development and the increasing division of labor encourage the formation of larger units of production at the expense of smaller ones. The result of these developments is an oligarchy of private capital the enormous power of which cannot be effectively checked even by a democratically organized political society. This is true since the members of legislative bodies are selected by political parties, largely financed or otherwise influenced by private capitalists who, for all practical purposes, separate the electorate from the legislature. The consequence is that the representatives of the people do not in fact sufficiently protect the interests of the underprivileged sections of the population. Moreover, under existing conditions, private capitalists inevitably control, directly or indirectly, the main sources of information (press, radio, education). It is thus extremely difficult, and indeed in most cases quite impossible, for the individual citizen to come to objective conclusions and to make intelligent use of his political rights.</p>
<p>The situation prevailing in an economy based on the private ownership of capital is thus characterized by two main principles: first, means of production (capital) are privately owned and the owners dispose of them as they see fit; second, the labor contract is free. Of course, there is no such thing as a <em>pure </em>capitalist society in this sense. In particular, it should be noted that the workers, through long and bitter political struggles, have succeeded in securing a somewhat improved form of the “free labor contract” for certain categories of workers. But taken as a whole, the present day economy does not differ much from “pure” capitalism.</p>
<p>Production is carried on for profit, not for use. There is no provision that all those able and willing to work will always be in a position to find employment; an “army of unemployed” almost always exists. The worker is constantly in fear of losing his job. Since unemployed and poorly paid workers do not provide a profitable market, the production of consumers’ goods is restricted, and great hardship is the consequence. Technological progress frequently results in more unemployment rather than in an easing of the burden of work for all. The profit motive, in conjunction with competition among capitalists, is responsible for an instability in the accumulation and utilization of capital which leads to increasingly severe depressions. Unlimited competition leads to a huge waste of labor, and to that crippling of the social consciousness of individuals which I mentioned before.</p>
<p>This crippling of individuals I consider the worst evil of capitalism. Our whole educational system suffers from this evil. An exaggerated competitive attitude is inculcated into the student, who is trained to worship acquisitive success as a preparation for his future career.</p>
<p>I am convinced there is only <em>one </em>way to eliminate these grave evils, namely through the establishment of a socialist economy, accompanied by an educational system which would be oriented toward social goals. In such an economy, the means of production are owned by society itself and are utilized in a planned fashion. A planned economy, which adjusts production to the needs of the community, would distribute the work to be done among all those able to work and would guarantee a livelihood to every man, woman, and child. The education of the individual, in addition to promoting his own innate abilities, would attempt to develop in him a sense of responsibility for his fellow men in place of the glorification of power and success in our present society.</p>
<p>Nevertheless, it is necessary to remember that a planned economy is not yet socialism. A planned economy as such may be accompanied by the complete enslavement of the individual. The achievement of socialism requires the solution of some extremely difficult socio-political problems: how is it possible, in view of the far-reaching centralization of political and economic power, to prevent bureaucracy from becoming all-powerful and overweening? How can the rights of the individual be protected and therewith a democratic counterweight to the power of bureaucracy be assured?</p>
<p>Clarity about the aims and problems of socialism is of greatest significance in our age of transition. Since, under present circumstances, free and unhindered discussion of these problems has come under a powerful taboo, I consider the foundation of this magazine to be an important public service.</p>
</section>
<span><a href="https://monthlyreview.org/category/2009/" title="View all items in 2009">2009</a>, <a href="https://monthlyreview.org/category/2009/volume-61-issue-01-may-2009/" title="View all items in Volume 61, Issue 01 (May)">Volume 61, Issue 01 (May)</a></span> 


</article>


</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I can tolerate anything except the outgroup (2014) (233 pts)]]></title>
            <link>https://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/</link>
            <guid>37406719</guid>
            <pubDate>Wed, 06 Sep 2023 15:39:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/">https://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/</a>, See on <a href="https://news.ycombinator.com/item?id=37406719">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						<p><i><span size="1">[Content warning: Politics, religion, social justice, spoilers for “The Secret of Father Brown”. This isn’t especially original to me and I don’t claim anything more than to be explaining and rewording things I have heard from a bunch of other people. Unapologetically America-centric because I’m not informed enough to make it otherwise. Try to keep this off Reddit and other similar sorts of things.]</span></i></p>
<p><b>I.</b></p>
<p>In Chesterton’s <i>The Secret of Father Brown</i>, a beloved nobleman who murdered his good-for-nothing brother in a duel thirty years ago returns to his hometown wracked by guilt. All the townspeople want to forgive him immediately, and they mock the titular priest for only being willing to give a measured forgiveness conditional on penance and self-reflection. They lecture the priest on the virtues of charity and compassion.</p>
<p>Later, it comes out that the beloved nobleman did <i>not</i> in fact kill his good-for-nothing brother. The good-for-nothing brother killed the beloved nobleman (and stole his identity). <i>Now</i> the townspeople want to see him lynched or burned alive, and it is only the priest who – consistently – offers a measured forgiveness conditional on penance and self-reflection.</p>
<p>The priest tells them:</p>
<blockquote><p>It seems to me that you only pardon the sins that you don’t really think sinful. You only forgive criminals when they commit what you don’t regard as crimes, but rather as conventions. You forgive a conventional duel just as you forgive a conventional divorce. You forgive because there isn’t anything to be forgiven.</p></blockquote>
<p>He further notes that this is why the townspeople can self-righteously consider themselves more compassionate and forgiving than he is. Actual forgiveness, the kind the priest needs to cultivate to forgive evildoers, is really really hard. The fake forgiveness the townspeople use to forgive the people they like is really easy, so they get to boast not only of their forgiving nature, but of how much nicer they are than those mean old priests who find forgiveness difficult and want penance along with it.</p>
<p>After some thought I agree with Chesterton’s point. There are a lot of people who say “I forgive you” when they mean “No harm done”, and a lot of people who say “That was unforgiveable” when they mean “That was genuinely really bad”. Whether or not forgiveness is <i>right</i> is a complicated topic I do not want to get in here. But since forgiveness is generally considered a virtue, and one that many want credit for having, I think it’s fair to say you only earn the right to call yourself ‘forgiving’ if you forgive things that genuinely hurt you. </p>
<p>To borrow Chesterton’s example, if you think divorce is a-ok, then you don’t get to “forgive” people their divorces, you merely ignore them. Someone who thinks divorce is abhorrent can “forgive” divorce. <i>You</i> can forgive theft, or murder, or tax evasion, or something <i>you</i> find abhorrent.</p>
<p>I mean, from a utilitarian point of view, you are still doing the correct action of not giving people grief because they’re a divorcee. You can have all the Utility Points you want. All I’m saying is that if you “forgive” something you don’t care about, you don’t earn any Virtue Points. </p>
<p>(by way of illustration: a billionaire who gives $100 to charity gets as many Utility Points as an impoverished pensioner who donates the same amount, but the latter gets a lot more Virtue Points)</p>
<p>Tolerance is also considered a virtue, but it suffers the same sort of dimished expectations forgiveness does.</p>
<p>The Emperor <a href="http://poetrychina.net/Story_of_Zen/zenstory3a.htm">summons before him</a> Bodhidharma and asks: “Master, I have been tolerant of innumerable gays, lesbians, bisexuals, asexuals, blacks, Hispanics, Asians, transgender people, and Jews. How many Virtue Points have I earned for my meritorious deeds?”</p>
<p>Bodhidharma answers: “None at all”.</p>
<p>The Emperor, somewhat put out, demands to know why.</p>
<p>Bodhidharma asks: “Well, what do you think of gay people?”</p>
<p>The Emperor answers: “What do you think I am, some kind of homophobic bigot? Of course I have nothing against gay people!”</p>
<p>And Bodhidharma answers: “Thus do you gain no merit by tolerating them!”</p>
<p><b>II.</b></p>
<p>If I had to define “tolerance” it would be something like “respect and kindness toward members of an outgroup”.</p>
<p>And today we have an almost unprecedented situation.</p>
<p>We have a lot of people – like the Emperor – boasting of being able to tolerate everyone from every outgroup they can imagine, loving the outgroup, writing long paeans to how great the outgroup is, staying up at night fretting that somebody else might not like the outgroup enough.</p>
<p>This is really surprising. It’s a total reversal of everything we know about human psychology up to this point. No one did any genetic engineering. No one passed out weird glowing pills in the public schools. And yet suddenly we get an entire group of people who conspicuously promote and defend their outgroups, the outer the better.</p>
<p>What is going on here?</p>
<p>Let’s start by asking what exactly an outgroup is.</p>
<p>There’s a very boring sense in which, assuming the Emperor’s straight, gays are part of his “outgroup” ie a group that he is not a member of. But if the Emperor has curly hair, are straight-haired people part of his outgroup? If the Emperor’s name starts with the letter ‘A’, are people whose names start with the letter ‘B’ part of his outgroup?</p>
<p>Nah. I would differentiate between multiple different meanings of outgroup, where one is “a group you are not a part of” and the other is…something stronger.</p>
<p>I want to avoid a very easy trap, which is saying that outgroups are about how different you are, or how hostile you are. I don’t think that’s quite right.</p>
<p>Compare the Nazis to the German Jews and to the Japanese. The Nazis were very similar to the German Jews: they looked the same, spoke the same language, came from a similar culture. The Nazis were totally different from the Japanese: different race, different language, vast cultural gap. But the Nazis and Japanese mostly got along pretty well. Heck, the Nazis were actually moderately positively disposed to the <i>Chinese</i>, even when they were technically at war. Meanwhile, the conflict between the Nazis and the German Jews – some of whom didn’t even realize they were anything other than German until they checked their grandparents’ birth certificate – is the stuff of history and nightmares. Any theory of outgroupishness that naively assumes the Nazis’ natural outgroup is Japanese or Chinese people will be totally inadequate.</p>
<p>And this isn’t a weird exception. Freud spoke of <a href="http://en.wikipedia.org/wiki/Narcissism_of_small_differences">the narcissism of small differences</a>, saying that “it is precisely communities with adjoining territories, and related to each other in other ways as well, who are engaged in constant feuds and ridiculing each other”. Nazis and German Jews. Northern Irish Protestants and Northern Irish Catholics. Hutus and Tutsis. South African whites and South African blacks. Israeli Jews and Israeli Arabs. Anyone in the former Yugoslavia and anyone else in the former Yugoslavia.</p>
<p>So what makes an outgroup? Proximity plus small differences. If you want to know who someone in former Yugoslavia hates, don’t look at the Indonesians or the Zulus or the Tibetans or anyone else distant and exotic. Find the Yugoslavian ethnicity that lives closely intermingled with them and is most conspicuously similar to them, and chances are you’ll find the one who they have eight hundred years of seething hatred toward.</p>
<p>What makes an unexpected in-group? The answer with Germans and Japanese is obvious – a strategic alliance. In fact, the World Wars forged a lot of unexpected temporary pseudo-friendships. <a href="http://pando.com/2014/02/12/war-nerd-the-long-sleazy-history-behind-a-googlers-nonviolent-militia/">A recent article from War Nerd</a> points out that the British, after spending centuries subjugating and despising the Irish and Sikhs, suddenly needed Irish and Sikh soldiers for World Wars I and II respectively. “Crush them beneath our boots” quickly changed to fawning songs about how “there never was a coward where the shamrock grows” and endless paeans to Sikh military prowess. </p>
<p>Sure, scratch the paeans even a little bit and you find condescension as strong as ever. But eight hundred years of the British committing genocide against the Irish and considering them literally subhuman turned into smiles and songs about shamrocks once the Irish started looking like useful cannon fodder for a larger fight. And the Sikhs, dark-skinned people with turbans and beards who pretty much exemplify the European stereotype of “scary foreigner”, were lauded by everyone from the news media all the way up <a href="https://www.youtube.com/watch?v=--OAScn5NcI">to Winston Churchill</a>.</p>
<p>In other words, outgroups may be the people who look exactly like you, and scary foreigner types can become the in-group on a moment’s notice when it seems convenient.</p>
<p><b>III.</b></p>
<p>There are certain theories of dark matter where it barely interacts with the regular world <i>at all</i>, such that we could have a dark matter planet exactly co-incident with Earth and never know. Maybe dark matter people are walking all around us and through us, maybe my house is in the Times Square of a great dark matter city, maybe a few meters away from me a dark matter blogger is writing on his dark matter computer about how weird it would be if there was a light matter person he couldn’t see right next to him.</p>
<p>This is sort of how I feel about conservatives.</p>
<p>I don’t mean the sort of light-matter conservatives who go around complaining about Big Government and occasionally voting for Romney. I see those guys all the time. What I mean is – well, take creationists. According to <a href="http://www.gallup.com/poll/155003/Hold-Creationist-View-Human-Origins.aspx">Gallup polls</a>, about 46% of Americans are creationists. Not just in the sense of believing God helped guide evolution. I mean they think evolution is a vile atheist lie and God created humans exactly as they exist right now. That’s half the country.</p>
<p>And I don’t have a <i>single one of those people</i> in my social circle. It’s not because I’m deliberately avoiding them; I’m pretty live-and-let-live politically, I wouldn’t ostracize someone just for some weird beliefs. And yet, even though I <a href="http://en.wikipedia.org/wiki/Dunbar%27s_number">probably</a> know about a hundred fifty people, I am pretty confident that not one of them is creationist. Odds of this happening by chance? 1/2^150 = 1/10^45 = approximately the chance of picking a particular atom if you are randomly selecting among all the atoms on Earth.</p>
<p>About forty percent of Americans want to ban gay marriage. I think if I <i>really</i> stretch it, maybe ten of my top hundred fifty friends might fall into this group. This is less astronomically unlikely; the odds are a mere one to one hundred quintillion against.</p>
<p>People like to talk about social bubbles, but that doesn’t even begin to cover one hundred quintillion. The only metaphor that seems really appropriate is the bizarre dark matter world.</p>
<p>I live in a Republican congressional district in a state with a Republican governor. The conservatives are definitely out there. They drive on the same roads as I do, live in the same neighborhoods. But they might as well be made of dark matter. I never meet them.</p>
<p>To be fair, I spend a lot of my time inside on my computer. I’m browsing sites like Reddit.</p>
<p>Recently, there was a thread on Reddit asking – <a href="http://www.reddit.com/r/AskReddit/comments/29uo38/serious_redditors_against_gay_marriage_what_is/">Redditors Against Gay Marriage, What Is Your Best Supporting Argument?</a> A Reddit user who didn’t understand how anybody could be against gay marriage honestly wanted to know how other people who <i>were</i> against it justified their position. He figured he might as well ask one of the largest sites on the Internet, with an estimated user base in the tens of millions.</p>
<p>It soon became clear that nobody there was actually against gay marriage.</p>
<p>There were a bunch of posts saying “I of course support gay marriage but here are some reasons some other people might be against it,” a bunch of others saying “my argument against gay marriage is the government shouldn’t be involved in the marriage business at all”, and several more saying “why would you even ask this question, there’s no possible good argument and you’re wasting your time”. About halfway through the thread someone started saying homosexuality was unnatural and I <i>thought</i> they were going to be the first one to actually answer the question, but at the end they added “But it’s not my place to decide what is or isn’t natural, I’m still pro-gay marriage.”</p>
<p>In a thread with 10,401 comments, a thread <i>specifically</i> asking for people against gay marriage, I was eventually able to find <i>two</i> people who came out and opposed it, way near the bottom. Their posts started with “I know I’m going to be downvoted to hell for this…”</p>
<p>But I’m not only on Reddit. I also hang out on LW.</p>
<p>On last year’s survey, I found that of American LWers who identify with one of the two major political parties, 80% are Democrat and 20% Republican, which actually sounds pretty balanced compared to some of these other examples.</p>
<p>But it doesn’t last. Pretty much all of those “Republicans” are libertarians who consider the GOP the lesser of two evils. When allowed to choose “libertarian” as an alternative, only 4% of visitors continued to identify as conservative. But that’s still…some. Right?</p>
<p>When I broke the numbers down further, 3 percentage points of those are neoreactionaries, a bizarre sect that wants to be ruled by a king. Only <i>one percent</i> of LWers were normal everyday God-‘n-guns-but-not-George-III conservatives of the type that seem to make up about half of the United States.</p>
<p>It gets worse. My formative years were spent at a university which, if it was similar to other elite universities, had <a href="http://www.washingtonpost.com/wp-dyn/articles/A8427-2005Mar28.html">a faculty</a> and <a href="http://www.thecrimson.com/article/2012/11/5/crimson-presidential-poll-2012/">a student body</a> that skewed about 90-10 liberal to conservative – and we can bet that, like LW, even those few token conservatives are Mitt Romney types rather than God-n’-guns types. I get my news from vox.com, an Official Liberal Approved Site. Even when I go out to eat, it turns out my favorite restaurant, California Pizza Kitchen, is <a href="http://blogs.wsj.com/washwire/2014/05/02/liberals-eat-here-conservatives-eat-there/">the most liberal restaurant in the United States</a>.</p>
<p>I inhabit the same geographical area as <i>scores and scores</i> of conservatives. But without meaning to, I have created an <i>outrageously</i> strong bubble, a 10^45 bubble. Conservatives are all around me, yet I am about as likely to have a serious encounter with one as I am a Tibetan lama.</p>
<p>(Less likely, actually. One time a Tibetan lama came to my college and gave a really nice presentation, but if a conservative tried that, people would protest and it would be canceled.)</p>
<p><b>IV.</b></p>
<p>One day I realized that entirely by accident I was fulfilling <i>all</i> the Jewish stereotypes.</p>
<p>I’m nerdy, over-educated, good with words, good with money, weird sense of humor, don’t get outside much, I like deli sandwiches. And I’m a psychiatrist, which is about the most stereotypically Jewish profession short of maybe stand-up comedian or rabbi.</p>
<p>I’m not very religious. And I don’t go to synagogue. But <i>that’s</i> stereotypically Jewish too!</p>
<p>I bring this up because it would be a mistake to think “Well, a Jewish person is by definition someone who is born of a Jewish mother. Or I guess it sort of also means someone who follows the Mosaic Law and goes to synagogue. But I don’t care about Scott’s mother, and I know he doesn’t go to synagogue, so I can’t gain any useful information from knowing Scott is Jewish.”</p>
<p>The defining factors of Judaism – Torah-reading, synagogue-following, mother-having – are the tip of a giant iceberg. Jews sometimes identify as a “tribe”, and even if you don’t attend synagogue, you’re still a member of that tribe and  people can still (in a statistical way) infer things about you by knowing your Jewish identity – like how likely they are to be psychiatrists.</p>
<p>The last section raised a question – if people rarely select their friends and associates and customers explicitly for politics, how do we end up with such intense political segregation?</p>
<p>Well, in the same way “going to synagogue” is merely the iceberg-tip of a Jewish tribe with many distinguishing characteristics, so “voting Republican” or “identifying as conservative” or “believing in creationism” is the iceberg-tip of a conservative tribe with many distinguishing characteristics.</p>
<p>A disproportionate number of my friends are Jewish, because I meet them at psychiatry conferences or something – we self-segregate not based on explicit religion but on implicit tribal characteristics. So in the same way, political tribes self-segregate to an impressive extent – a 1/10^45 extent, I will never tire of hammering in – based on their implicit tribal characteristics.</p>
<p>The people who are actually into this sort of thing sketch out a bunch of speculative tribes and subtribes, but to make it easier, let me stick with two and a half.</p>
<p>The Red Tribe is most classically typified by conservative political beliefs, strong evangelical religious beliefs, creationism, opposing gay marriage, owning guns, eating steak, drinking Coca-Cola, driving SUVs, watching lots of TV, enjoying American football, getting conspicuously upset about terrorists and commies, marrying early, divorcing early, shouting “USA IS NUMBER ONE!!!”, and listening to country music.</p>
<p>The Blue Tribe is most classically typified by liberal political beliefs, vague agnosticism, supporting gay rights, thinking guns are barbaric, eating arugula, drinking fancy bottled water, driving Priuses, reading lots of books, being highly educated, mocking American football, feeling vaguely like they should like soccer but never really being able to get into it, getting conspicuously upset about sexists and bigots, marrying later, constantly pointing out how much more civilized European countries are than America, and listening to “everything except country”.</p>
<p>(There is a partly-formed attempt to spin off a Grey Tribe typified by libertarian political beliefs, Dawkins-style atheism, vague annoyance that the question of gay rights even comes up, eating paleo, drinking Soylent, calling in rides on Uber, reading lots of blogs, calling American football “sportsball”, getting conspicuously upset about the War on Drugs and the NSA, and listening to filk – but for our current purposes this is a distraction and they can safely be considered part of the Blue Tribe most of the time)</p>
<p>I think these “tribes” will turn out to be even stronger categories than politics. Harvard might skew 80-20 in terms of Democrats vs. Republicans, 90-10 in terms of liberals vs. conservatives, but maybe 99-1 in terms of Blues vs. Reds.</p>
<p>It’s the many, many differences between these tribes that explain the strength of the filter bubble – which <i>have I mentioned</i> segregates people at a strength of 1/10^45? Even in something as seemingly politically uncharged as going to California Pizza Kitchen or Sushi House for dinner, I’m restricting myself to the set of people who like cute artisanal pizzas or sophsticated foreign foods, which are classically Blue Tribe characteristics.</p>
<p>Are these tribes based on geography? Are they based on race, ethnic origin, religion, IQ, what TV channels you watched as a kid? I don’t know. </p>
<p>Some of it is certainly genetic – <a href="https://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/%E2%80%9Dhttp://www.matthewckeller.com/16.Hatemi.et.al.2010.Nuc.fam.ajps.pdf%E2%80%9D">estimates</a> <a href="https://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/%E2%80%9Dhttps://www.apsanet.org/imgtest/GeneticsAPSR0505.pdf%E2%80%9D">of</a> the genetic contribution to political association range from 0.4 to 0.6. Heritability of one’s attitudes toward gay rights range from 0.3 to 0.5, which hilariously is a little more heritable than homosexuality itself.</p>
<p>(for an interesting attempt to break these down into more rigorous concepts like “traditionalism”, “authoritarianism”, and “in-group favoritism” and find the genetic loading for each <a href="http://www.midus.wisc.edu/findings/pdfs/1287.pdf">see here</a>. For an attempt to trace the specific genes involved, which mostly turn out to be NMDA receptors, <a href="https://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/%E2%80%9Dhttp://ussc.edu.au/s/media/docs/publications/18_Hatemi_et_al_LinkageGW_JOP.pdf%E2%80%9D">see here</a>)</p>
<p>But I don’t think it’s just genetics. There’s something else going on too. The word “class” seems like the closest analogue, but only if you use it in the sophisticated Paul Fussell <a href="https://www.amazon.com/Class-Through-American-Status-System/dp/0671792253/ref=as_li_ss_tl?_encoding=UTF8&amp;redirect=true&amp;ref_=as_li_tl&amp;linkCode=ll1&amp;tag=slatestarcode-20&amp;linkId=ae89050500c1fcc0f1d2de1ccb5313ab"><i>Guide Through the American Status System</i></a> way instead of the boring “another word for how much money you make” way.</p>
<p>For now we can just accept them as a brute fact – as multiple coexisting societies that might as well be made of dark matter for all of the interaction they have with one another – and move on.</p>
<p><b>V.</b></p>
<p>The worst reaction I’ve ever gotten to a blog post was when <a href="http://squid314.livejournal.com/294986.html">I wrote about</a> the death of Osama bin Laden. I’ve written all sorts of stuff about race and gender and politics and whatever, but that was the worst.</p>
<p>I didn’t come out and say I was happy he was dead. But some people interpreted it that way, and there followed a bunch of comments and emails and Facebook messages about how could I possibly be happy about the death of another human being, even if he was a bad person? Everyone, even Osama, is a human being, and we should never rejoice in the death of a fellow man. One commenter came out and said:</p>
<blockquote><p>I’m surprised at your reaction. As far as people I casually stalk on the internet (ie, LJ and Facebook), you are the first out of the “intelligent, reasoned and thoughtful” group to be uncomplicatedly happy about this development and not to be, say, disgusted at the reactions of the other 90% or so.</p></blockquote>
<p>This commenter was right. Of the “intelligent, reasoned, and thoughtful” people I knew, the overwhelming emotion was conspicuous disgust that other people could be happy about his death. I hastily backtracked and said I wasn’t happy per se, just surprised and relieved that all of this was finally behind us.</p>
<p>And I genuinely believed that day that I had found some unexpected good in people – that everyone I knew was so humane and compassionate that they were unable to rejoice even in the death of someone who hated them and everything they stood for.</p>
<p>Then a few years later, Margaret Thatcher died. And on my Facebook wall – made of these same “intelligent, reasoned, and thoughtful” people – the most common response was to quote some portion of the song “Ding Dong, The Witch Is Dead”. Another popular response was to link the videos of British people spontaneously throwing parties in the street, with comments like “I wish I was there so I could join in”. From this exact same group of people, not a single expression of disgust or a “c’mon, guys, we’re all human beings here.”</p>
<p>I <a href="https://slatestarcodex.com/2013/04/12/if-a-clod-be-washed-away-by-the-sea-europe-is-the-less/">gently pointed this out</a> at the time, and mostly got a bunch of “yeah, so what?”, combined with links to an article claiming that “the demand for respectful silence in the wake of a public figure’s death is not just misguided but dangerous”. </p>
<p>And that was when something clicked for me.</p>
<p>You can talk all you want about Islamophobia, but my friend’s “intelligent, reasoned, and thoughtful people” – her name for the Blue Tribe – can’t get together enough energy to really hate Osama, let alone Muslims in general. We understand that what he did was bad, but it didn’t anger us personally. When he died, we were able to very rationally apply our better nature and our Far Mode beliefs about how it’s never right to be happy about anyone else’s death.</p>
<p>On the other hand, that same group absolutely <i>loathed</i> Thatcher. Most of us (though <a href="https://slatestarcodex.com/2013/04/12/if-a-clod-be-washed-away-by-the-sea-europe-is-the-less/#comment-3355">not all</a>) can agree, if the question is posed explicitly, that Osama was a worse person than Thatcher. But in terms of actual gut feeling? Osama provokes a snap judgment of “flawed human being”, Thatcher a snap judgment of “scum”.</p>
<p>I started this essay by pointing out that, despite what geographical and cultural distance would suggest, the Nazis’ outgroup was not the vastly different Japanese, but the almost-identical German Jews.</p>
<p>And my hypothesis, stated plainly, is that if you’re part of the Blue Tribe, then your outgroup isn’t al-Qaeda, or Muslims, or blacks, or gays, or transpeople, or Jews, or atheists –  it’s the Red Tribe.</p>
<p><b>VI.</b></p>
<p>“But racism and sexism and cissexism and anti-Semitism are these giant all-encompassing social factors that verge upon being human universals! Surely you’re not arguing that mere <i>political</i> differences could ever come close to them!”</p>
<p>One of the ways we <i>know</i> that racism is a giant all-encompassing social factor is the Implicit Association Test. Psychologists ask subjects to quickly identify whether words or photos are members of certain gerrymandered categories, like “either a white person’s face or a positive emotion” or “either a black person’s face and a negative emotion”. Then they compare to a different set of gerrymandered categories, like “either a black person’s face or a positive emotion” or “either a white person’s face or a negative emotion.” If subjects have more trouble (as measured in latency time) connecting white people to negative things than they do white people to positive things, then they probably have subconscious positive associations with white people. You can <a href="https://implicit.harvard.edu/implicit/">try it yourself here</a>.</p>
<p>Of course, what the test famously found was that even white people who claimed to have no racist attitudes at all usually had positive associations with white people and negative associations with black people on the test. There are very many claims and counterclaims about the precise meaning of this, but it ended up being a big part of the evidence in favor of the current consensus that all white people are at least a little racist.</p>
<p>Anyway, three months ago, someone finally had the bright idea of <a href="http://pcl.stanford.edu/research/2014/iyengar-ajps-group-polarization.pdf">doing an Implicit Association Test with political parties</a>, and they found that people’s unconscious partisan biases were <i>half again as strong</i> as their unconscious racial biases (h/t <a href="http://www.bloombergview.com/articles/2014-09-22/partyism-now-trumps-racism">Bloomberg</a>. For example, if you are a white Democrat, your unconscious bias against blacks (as measured by something called a d-score) is 0.16, but your unconscious bias against Republicans will be 0.23. The Cohen’s <i>d</i> for racial bias was 0.61, by <a href="http://en.wikipedia.org/wiki/Effect_size#.22Small.22.2C_.22medium.22.2C_.22large.22_effect_sizes">the book</a> a “moderate” effect size; for party it was 0.95, a “large” effect size.</p>
<p>Okay, fine, but we know race has <i>real world</i> consequences. Like, there have been <a href="https://slatestarcodex.com/2013/04/20/social-justice-for-the-highly-demanding-of-rigor/">several studies</a> where people sent out a bunch of identical resumes except sometimes with a black person’s photo and other times with a white person’s photo, and it was noticed that employers were much more likely to invite the fictional white candidates for interviews. So just some stupid Implicit Association Test results can’t compare to that, right?</p>
<p>Iyengar and Westwood also decided to do the resume test for parties. They asked subjects to decide which of several candidates should get a scholarship (subjects were told this was a genuine decision for the university the researchers were affiliated with). Some resumes had photos of black people, others of white people. And some students listed their experience in Young Democrats of America, others in Young Republicans of America.</p>
<p>Once again, discrimination on the basis of party was much stronger than discrimination on the basis of race. The size of the race effect for white people was only 56-44 (and in the reverse of the expected direction); the size of the party effect was about 80-20 for Democrats and 69-31 for Republicans.</p>
<p>If you want to see their third experiment, which applied <i>yet another</i> classic methodology used to detect racism and <i>once again</i> found partyism to be much stronger, you can read the paper.</p>
<p>I &amp; W did an unusually thorough job, but this sort of thing isn’t new or ground-breaking. People have been studying “belief congruence theory” – the idea that differences in beliefs are more important than demographic factors in forming in-groups and outgroups – for decades. As early as 1967, Smith et al were doing surveys all over the country and <a href="http://psycnet.apa.org/index.cfm?fa=buy.optionToBuy&amp;uid=2005-11098-001">finding that</a> people were more likely to accept friendships across racial lines than across beliefs; in the forty years since then, the observation has been replicated scores of times. Insko, Moe, and Nacoste’s 2006 review <a href="http://onlinelibrary.wiley.com/doi/10.1002/ejsp.2420130206/abstract">Belief Congruence And Racial Discrimination</a> concludes that:</p>
<blockquote><p>. The literature was judged supportive of a weak version of belief congruence theory which states that in those contexts in which social pressure is nonexistent or ineffective, belief is more important than race as a determinant of racial or ethnic discrimination. Evidence for a strong version of belief congruence theory (which states that in those contexts in which social pressure is nonexistent, or ineffective, belief is the only determinant of racial or ethnic discrimination) and was judged much more problematic.</p></blockquote>
<p>One of the best-known examples of racism is the “Guess Who’s Coming To Dinner” scenario where parents are scandalized about their child marrying someone of a different race. Pew has done <a href="http://www.people-press.org/2014/06/12/section-3-political-polarization-and-personal-life/">some good work on this</a> and found that only 23% of conservatives and 1% (!) of liberals admit they would be upset in this situation. But Pew <i>also</i> asked how parents would feel about their child marrying someone of a different <i>political party</i>. Now 30% of conservatives and 23% of liberals would get upset. Average them out, and you go from 12% upsetness rate for race to 27% upsetness rate for party – more than double. Yeah, people do lie to pollsters, but a picture is starting to come together here. </p>
<p>(Harvard, by the way, is a tossup. There are more black students – 11.5% – than conservative students – 10% – but there are more conservative faculty than black faculty.)</p>
<p>Since people will delight in misinterpreting me here, let me overemphasize what I am <i>not</i> saying. I’m not saying people of either party have it “worse” than black people, or that partyism is more of a <i>problem</i> than racism, or any of a number of stupid things along those lines which I am sure I will nevertheless be accused of believing. Racism is worse than partyism because the two parties are at least kind of balanced in numbers and in resources, whereas the brunt of an entire country’s racism falls on a few underprivileged people. I am saying that the <i>underlying attitudes that produce</i> partyism are stronger than the underlying attitudes that produce racism, with no necessary implications on their social effects. </p>
<p>But if we want to look at people’s psychology and motivations, partyism and the particular variant of tribalism that it represents are going to be fertile ground.</p>
<p><b>VII.</b></p>
<p>Every election cycle like clockwork, conservatives accuse liberals of not being sufficiently pro-America. And every election cycle like clockwork, liberals give extremely unconvincing denials of this.</p>
<p>“It’s not that we’re, like, <i>against</i> America per se. It’s just that…well, did you know Europe has much better health care than we do? And much lower crime rates? I mean, come on, how did they get so awesome? And we’re just sitting here, can’t even get the gay marriage thing sorted out, seriously, what’s wrong with a country that can’t…sorry, what were we talking about? Oh yeah, America. They’re okay. Cesar Chavez was really neat. So were some other people outside the mainstream who became famous precisely by criticizing majority society. That’s <i>sort of</i> like America being great, in that I think the parts of it that point out how bad the rest of it are often make excellent points. Vote for me!”</p>
<p>(sorry, I make fun of you because I love you)</p>
<p>There was a big brouhaha a couple of years ago when, as it first became apparent Obama had a good shot at the Presidency, Michelle Obama <a href="http://abcnews.go.com/blogs/politics/2008/02/michelle-obam-1-2">said that</a> “for the first time in my adult life, I am proud of my country.”</p>
<p>Republicans pounced on the comment, asking why she hadn’t felt proud before, and she backtracked saying of course she was proud all the time and she loves America with the burning fury of a million suns and she was just saying that the Obama campaign was <i>particularly</i> inspiring. </p>
<p>As unconvincing denials go, this one was pretty far up there. But no one really held it against her. Probably most Obama voters felt vaguely the same way. <i>I</i> was an Obama voter, and I have proud memories of spending my Fourth of Julys as a kid debunking people’s heartfelt emotions of patriotism. Aaron Sorkin:</p>
<blockquote><p>[What makes America the greatest country in the world?] It’s not the greatest country in the world! We’re seventh in literacy, 27th in math, 22nd in science, 49th in life expectancy, 178th in infant mortality, third in median household income, No. 4 in labor force, and No. 4 in exports. So when you ask what makes us the greatest country in the world, I don’t know what the f*** you’re talking about.</p></blockquote>
<p>(Another <a href="http://www.washingtonpost.com/blogs/wonkblog/wp/2014/07/03/21-maps-and-charts-that-prove-america-is-number-one/">good retort</a> is “We’re number one? Sure – number one in incarceration rates, drone strikes, and making new parents go back to work!”)</p>
<p>All of this is true, of course. But it’s weird that it’s such a classic interest of members of the Blue Tribe, and members of the Red Tribe never seem to bring it up.</p>
<p>(“We’re number one? Sure – number one in levels of sexual degeneracy! Well, I guess probably number two, after the Netherlands, but they’re really small and shouldn’t count.”)</p>
<p>My hunch – both the Red Tribe and the Blue Tribe, for whatever reason, identify “America” with the Red Tribe. Ask people for typically “American” things, and you end up with a very Red list of characteristics – guns, religion, barbecues, American football, NASCAR, cowboys, SUVs, unrestrained capitalism.</p>
<p>That means the Red Tribe feels intensely patriotic about “their” country, and the Blue Tribe feels like they’re living in fortified enclaves deep in hostile territory. </p>
<p>Here is a popular piece published on a major media site called <a href="http://www.huffingtonpost.com/justin-stoneman/post_868_b_720398.html">America: A Big, Fat, Stupid Nation</a>. Another: <a href="http://english.pravda.ru/opinion/columnists/03-07-2008/105678-america-0/">America: A Bunch Of Spoiled, Whiny Brats</a>. Americans <a href="http://matadornetwork.com/life/10-embarrassing-american-stereotypes/">are</a> ignorant, scientifically illiterate religious fanatics whose “patriotism” is actually just narcissism. <a href="http://www.salon.com/2013/11/06/you_will_be_shocked_at_how_ignorant_americans_are_partner/">You Will Be Shocked At How Ignorant Americans Are</a>, and we should <a href="http://www.slate.com/articles/news_and_politics/the_big_idea/2010/02/down_with_the_people.html">Blame The Childish, Ignorant American People</a>.</p>
<p>Needless to say, every single one of these articles was written by an American and read almost entirely by Americans. Those Americans very likely enjoyed the articles very much and did not feel the least bit insulted.</p>
<p>And look at the sources. HuffPo, Salon, Slate. Might those have anything in common?</p>
<p>On both sides, “American” can be either a normal demonym, or a code word for a member of the Red Tribe.</p>
<p><b>VIII.</b></p>
<p>The other day, I logged into OKCupid and found someone who looked cool. I was reading over her profile and found the following sentence:</p>
<blockquote><p>Don’t message me if you’re a sexist white guy</p></blockquote>
<p>And my first thought was “Wait, so a sexist black person would be okay? Why?”</p>
<p>(The girl in question was white as snow)</p>
<p>Around the time the Ferguson riots were first starting, there were a host of articles with titles like <a href="http://mic.com/articles/96554/why-white-people-don-t-seem-to-understand-ferguson-in-one-chart">Why White People Don’t Seem To Understand Ferguson</a>, <a href="http://www.theatlantic.com/politics/archive/2014/08/self-segregation-why-its-hard-for-whites-to-understand-ferguson/378928/">Why It’s So Hard For Whites To Understand Ferguson</a>, and <a href="http://blog.chron.com/texassparkle/2014/08/white-folks-listen-up-and-let-me-tell-you-what-ferguson-is-all-about/">White Folks Listen Up And Let Me Tell You What Ferguson Is All About</a>, this last of which says: </p>
<blockquote><p>Social media is full of people on both sides making presumptions, and believing what they want to believe. But it’s the white folks that don’t understand what this is all about. Let me put it as simply as I can for you […]</p>
<p>No matter how wrong you think Trayvon Martin or Michael Brown were, I think we can all agree they didn’t deserve to die over it. I want you white folks to understand that this is where the anger is coming from. You focused on the looting….”</p></blockquote>
<p>And on a hunch I checked the author photos, and every single one of these articles was written by a white person. </p>
<p><a href="http://robertlindsay.wordpress.com/2011/04/12/who-is-ruining-america/">White People Are Ruining America</a>? White. <a href="http://unvis.it/gawker.com/fifty-years-after-the-march-white-people-are-still-a-d-1216851674">White People Are Still A Disgrace</a>? White. <a href="http://www.huffingtonpost.com/2014/05/05/white-guys-we-suck_n_5269105.html">White Guys: We Suck And We’re Sorry</a>? White. <a href="http://www.realclearpolitics.com/2014/05/08/bye-bye_whiny_white_dudes_331840.html">Bye Bye, Whiny White Dudes</a>? White. <a href="http://unvis.it/makemeasammich.org/2014/04/25/dear-entitled-straight-white-dudes/">Dear Entitled Straight White Dudes, I’m Evicting You From My Life</a>? White. <a href="http://wonkette.com/542874/all-these-white-dudes-need-to-stop-whitesplaining-about-what-slavery-is">White Dudes Need To Stop Whitesplaining</a>? White. <a href="http://whyamericanssuck.blogspot.com/2010/07/1-white-people.html">Reasons Why Americans Suck #1: White People</a>? White. </p>
<p>We’ve all seen articles and comments and articles like this. Some unsavory people try to use them to prove that white people are the <i>real</i> victims or the media is biased against white people or something. Other people who are very nice and optimistic use them to show that some white people have developed some self-awareness and are willing to engage in self-criticism.</p>
<p>But I think the situation with “white” is much the same as the situation with “American” – it can either mean what it says, or be a code word for the Red Tribe.</p>
<p>(except on the blog <a href="http://stuffwhitepeoplelike.com/">Stuff White People Like</a>, where it obviously serves as a code word for the <i>Blue</i> tribe. I don’t know, guys. I didn’t do it.)</p>
<p>I realize that’s making a strong claim, but it would hardly be without precedent. When people say things like “gamers are misogynist”, do they mean <a href="http://www.theguardian.com/commentisfree/2014/sep/18/52-percent-people-playing-games-women-industry-doesnt-know">the 52% of gamers who are women</a>? Do they mean every one of the 59% of Americans from every walk of life who are known to play video or computer games occasionally? No. “Gamer” is a coded reference to the Gray Tribe, the half-branched-off collection of libertarianish tech-savvy nerds, and everyone knows it. As well expect that when people talk about “fedoras”, they mean Indiana Jones. Or when they talk about “urban youth”, they mean freshmen at NYU. Everyone knows exactly who we mean when we say “urban youth”, and them being young people who live in a city has only the most tenuous of relations to the actual concept.</p>
<p>And I’m saying words like “American” and “white” work the same way. Bill Clinton was the <a href="http://www.realclearpolitics.com/video/2014/04/03/bill_clinton_i_loved_being_called_the_first_black_president.html">“first black President”</a>, but if Herman Cain had won in 2012 he’d have been the 43rd white president. And when an angry white person talks at great length about how much he hates “white dudes”, <i>he is not being humble and self-critical</i>.</p>
<p><b>IX.</b></p>
<p>Imagine hearing that a liberal talk show host and comedian was so enraged by the actions of ISIS that he’d recorded and posted a video in which he shouts at them for ten minutes, cursing the “fanatical terrorists” and calling them “utter savages” with “savage values”.</p>
<p>If <i>I</i> heard that, I’d be kind of surprised. It doesn’t fit my model of what liberal talk show hosts do.</p>
<p>But <a href="http://rt.com/usa/168704-russell-brand-fox-news/">the story</a> I’m <i>actually</i> referring to is liberal talk show host / comedian Russell Brand making that same rant against Fox News for <i>supporting war against</i> the Islamic State, adding at the end that “Fox is worse than ISIS”.</p>
<p>That fits my model perfectly. You wouldn’t celebrate Osama’s death, only Thatcher’s. And you wouldn’t call ISIS savages, only Fox News. Fox is the outgroup, ISIS is just some random people off in a desert. You hate the outgroup, you don’t hate random desert people.</p>
<p>I would go further. Not only does Brand not feel much like hating ISIS, he has a strong incentive not to. That incentive is: the Red Tribe is known to hate ISIS loudly and conspicuously. Hating ISIS would signal Red Tribe membership, would be the equivalent of going into Crips territory with a big Bloods gang sign tattooed on your shoulder.</p>
<p>But this might be unfair. What would Russell Brand answer, if we asked him to justify his decision to be much angrier at Fox than ISIS?</p>
<p>He might say something like “Obviously Fox News is not literally worse than ISIS. But here I am, talking to my audience, who are mostly white British people and Americans. These people already know that ISIS is bad; they don’t need to be told that any further. In fact, at this point being angry about how bad ISIS is, is less likely to genuinely change someone’s mind about ISIS, and more likely to promote Islamophobia. The sort of people in my audience are at zero risk of becoming ISIS supporters, but at a very real risk of Islamophobia. So ranting against ISIS would be counterproductive and dangerous. </p>
<p>On the other hand, my audience of white British people and Americans is very likely to contain many Fox News viewers and supporters. And Fox, while not quite as evil as ISIS, is still pretty bad. So here’s somewhere I have a genuine chance to reach people at risk and change minds. Therefore, I think my decision to rant against Fox News, and maybe hyperbolically say they were ‘worse than ISIS’ is justified under the circumstances.”</p>
<p>I have a lot of sympathy to hypothetical-Brand, especially to the part about Islamophobia. It <i>does</i> seem really possible to denounce ISIS’ atrocities to a population that already hates them in order to <a href="https://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/%E2%80%9Dhttps://slatestarcodex.com/2014/05/12/weak-men-are-superweapons/%E2%80%9D">weak-man</a> a couple of already-marginalized Muslims. We need to fight terrorism and atrocities – therefore it’s okay to shout at a poor girl ten thousand miles from home for wearing a headscarf in public. Christians are being executed for their faith in Sudan, therefore let’s picket the people trying to build a mosque next door.</p>
<p>But my sympathy with Brand ends when he acts like his audience is likely to be fans of Fox News.</p>
<p>In a world where a negligible number of Redditors oppose gay marriage and 1% of Less Wrongers identify conservative and I know 0/150 creationists, how many of the people who visit the YouTube channel of a well-known liberal activist with a Che-inspired banner, a channel whose episode names are things like “War: What Is It Good For?” and “Sarah Silverman Talks Feminism” – how many of them do you think are big Fox News fans?</p>
<p>In a way, Russell Brand would have been <i>braver</i> taking a stand against ISIS than against Fox. If he attacked ISIS, his viewers would just be a little confused and uncomfortable. Whereas every moment he’s attacking Fox his viewers are like “HA HA! YEAH! GET ‘EM! SHOW THOSE IGNORANT BIGOTS IN THE OUTGROUP WHO’S BOSS!”</p>
<p>Brand acts as if there are just these countries called “Britain” and “America” who are receiving his material. Wrong. There are two parallel universes, and he’s only broadcasting to one of them.</p>
<p>The result is exactly what we predicted would happen in the case of Islam. Bombard people with images of a far-off land they already hate and tell them to hate it more, and the result is ramping up the intolerance on the couple of dazed and marginalized representatives of that culture who have ended up stuck on your half of the divide. Sure enough, if industry or culture or community gets Blue enough, Red Tribe members start getting harassed, fired from their jobs (Brendan Eich being the obvious example) or otherwise shown the door.</p>
<p>Think of Brendan Eich as a member of a tiny religious minority surrounded by people who hate that minority. Suddenly firing him doesn’t seem very noble.</p>
<p>If you mix together Podunk, Texas and Mosul, Iraq, you can prove that Muslims are scary and very powerful people who are executing Christians all the time – and so we have a great excuse for kicking the one remaining Muslim family, random people who never hurt anyone, out of town. </p>
<p>And if you mix together the open-source tech industry and the parallel universe <a href="http://rmitz.org/freebsd.daemon.html">where</a> you can’t wear a FreeBSD t-shirt without risking someone trying to exorcise you, you can prove that Christians are scary and very powerful people who are persecuting everyone else all the time, and you have a great excuse for kicking one of the few people willing to affiliate with the Red Tribe, a guy who never hurt anyone, out of town.</p>
<p>When a friend of mine heard Eich got fired, she didn’t see anything wrong with it. “I can tolerate anything except intolerance,” she said.</p>
<p>“Intolerance” is starting to look like another one of those words like “white” and “American”.</p>
<p>“I can tolerate anything except the outgroup.” Doesn’t sound quite so noble now, does it?</p>
<p><b>X.</b></p>
<p>We started by asking: millions of people are conspicuously praising every outgroup they can think of, while conspicuously condemning their own in-group. This seems contrary to what we know about social psychology. What’s up?</p>
<p>We noted that outgroups are rarely literally “the group most different from you”, and in fact far more likely to be groups very similar to you sharing <i>almost</i> all your characteristics and living in the same area.</p>
<p>We then noted that although liberals and conservatives live in the same area, they might as well be two totally different countries or universe as far as level of interaction were concerned. </p>
<p>Contra the usual idea of them being marked only by voting behavior, we described them as very different tribes with totally different cultures. You can speak of “American culture” only in the same way you can speak of “Asian culture” – that is, with a lot of interior boundaries being pushed under the rug.</p>
<p>The outgroup of the Red Tribe is occasionally blacks and gays and Muslims, more often the Blue Tribe.</p>
<p>The Blue Tribe has performed some kind of very impressive act of alchemy, and transmuted <i>all</i> of its outgroup hatred to the Red Tribe.</p>
<p>This is not surprising. Ethnic differences have proven quite tractable in the face of shared strategic aims. Even the Nazis, not known for their ethnic tolerance, were able to get all buddy-buddy with the Japanese when they had a common cause.</p>
<p>Research suggests Blue Tribe / Red Tribe prejudice to be much stronger than better-known types of prejudice like racism. Once the Blue Tribe was able to enlist the blacks and gays and Muslims in their ranks, they became allies of convenience who deserve to be rehabilitated with mildly condescending paeans to their virtue. “There never was a coward where the shamrock grows.”</p>
<p>Spending your entire life insulting the other tribe and talking about how terrible they are makes you look, well, tribalistic. It is definitely not high class. So when members of the Blue Tribe decide to dedicate their entire life to yelling about how terrible the Red Tribe is, they make sure that instead of saying “the Red Tribe”, they say “America”, or “white people”, or “straight white men”. That way it’s <i>humble self-criticism</i>. They are <i>so</i> interested in justice that they are willing to critique <i>their own beloved side</i>, much as it pains them to do so. We know they are not exaggerating, because one might exaggerate the flaws of an enemy, but that anyone would exaggerate their <i>own</i> flaws fails <a href="http://en.wikipedia.org/wiki/Criterion_of_embarrassment">the criterion of embarrassment</a>.</p>
<p>The Blue Tribe always has an excuse at hand to persecute and crush any Red Tribers unfortunate enough to fall into its light-matter-universe by defining them as all-powerful domineering oppressors. They appeal to the fact that this is definitely the way it works in the Red Tribe’s dark-matter-universe, and that’s in the same country so it has to be the same community for all intents and purposes. As a result, every Blue Tribe institution is permanently licensed to take whatever emergency measures are necessary against the Red Tribe, however disturbing they might otherwise seem.</p>
<p>And so how virtuous, how noble the Blue Tribe! Perfectly tolerant of all of the different groups that just so happen to be allied with them, never intolerant unless it happen to be against intolerance itself. Never stooping to engage in petty tribal conflict like that awful Red Tribe, but always nobly criticizing their own culture and striving to make it better!</p>
<p>Sorry. But I hope this is at least a <i>little</i> convincing. The weird dynamic of outgroup-philia and ingroup-phobia isn’t anything of the sort. It’s just good old-fashioned in-group-favoritism and outgroup bashing, a little more sophisticated and a little more sneaky.</p>
<p><b>XI.</b></p>
<p>This essay is bad and I should feel bad.</p>
<p>I should feel bad because I made <i>exactly</i> the mistake I am trying to warn everyone else about, and it wasn’t until I was almost done that I noticed.</p>
<p>How virtuous, how noble I must be! Never stooping to engage in petty tribal conflict like that silly Red Tribe, but always nobly criticizing my own tribe and striving to make it better.</p>
<p>Yeah. Once I’ve written a ten thousand word essay savagely attacking the Blue Tribe, either I’m a very special person or they’re my outgroup. And I’m not <i>that</i> special.</p>
<p>Just as you can pull a fast one and look humbly self-critical if you make your audience assume there’s just one American culture, so maybe you can trick people by assuming there’s only one Blue Tribe.</p>
<p>I’m pretty sure I’m not Red, but I did talk about the Grey Tribe above, and I show all the risk factors for being one of them. That means that, although my critique of the Blue Tribe may be right or wrong, in terms of <i>motivation</i> it comes from the same place as a Red Tribe member talking about how much they hate al-Qaeda or a Blue Tribe member talking about how much they hate ignorant bigots. And when I boast of being able to tolerate Christians and Southerners whom the Blue Tribe is mean to, I’m not being tolerant at all, just noticing people so far away from me they wouldn’t make a good outgroup anyway. </p>
<p>I had <i>fun</i> writing this article. People do not have fun writing articles savagely criticizing their in-group. People can criticize their in-group, it’s not <i>humanly impossible</i>, but it takes nerves of steel, it makes your blood boil, you should sweat blood. It shouldn’t be <i>fun</i>.</p>
<p>You can bet some white guy on Gawker who week after week churns out “Why White People Are So Terrible” and “Here’s What Dumb White People Don’t Understand” is having fun and not sweating any blood at all. He’s not criticizing his in-group, he’s never even <i>considered</i> criticizing his in-group. I can’t blame him. Criticizing the in-group is a really difficult project I’ve barely begun to build the mental skills necessary to even consider.</p>
<p>I can think of criticisms of my own tribe. Important criticisms, true ones. But the thought of writing them makes my blood boil.</p>
<p>I imagine might I feel like some liberal US Muslim leader, when he goes on the O’Reilly Show, and O’Reilly ambushes him and demands to know why he and other American Muslims haven’t condemned beheadings by ISIS more, demands that he criticize them right there on live TV. And you can see the wheels in the Muslim leader’s head turning, thinking something like “Okay, obviously beheadings are terrible and I hate them as much as anyone. But you don’t care even <i>the slightest bit</i> about the victims of beheadings. You’re just looking for a way to score points against me so you can embarass all Muslims. And I would rather personally behead every single person in the world than give a smug bigot like you a single microgram more stupid self-satisfaction than you’ve already got.”</p>
<p>That is how I feel when asked to criticize my own tribe, even for correct reasons. If you think you’re criticizing your own tribe, and your blood is not at that temperature, consider the possibility that you aren’t.</p>
<p>But if I want Self-Criticism Virtue Points, criticizing the Grey Tribe is the only honest way to get them. And if I want Tolerance Points, my own personal cross to bear right now is tolerating the Blue Tribe.  I need to remind myself that when they are bad people, they are merely Osama-level bad people instead of Thatcher-level bad people. And when they are good people, they are powerful and necessary crusaders against the evils of the world.</p>
<p>The worst thing that could happen to this post is to have it be used as convenient feces to fling at the Blue Tribe whenever feces are necessary. Which, given what has happened to my last couple of posts along these lines and the obvious biases of my own subconscious, I already expect it will be.</p>
<p>But the best thing that could happen to this post is that it makes a lot of people, especially myself, figure out how to be more tolerant. Not in the “of course I’m tolerant, why shouldn’t I be?” sense of the Emperor in Part I. But in the sense of “being tolerant makes me see red, makes me sweat blood, but darn it <i>I am going to be tolerant anyway</i>.”</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Effectiveness of physical activity for improving depression, anxiety, distress (143 pts)]]></title>
            <link>https://bjsm.bmj.com/content/early/2023/07/11/bjsports-2022-106195</link>
            <guid>37405727</guid>
            <pubDate>Wed, 06 Sep 2023 14:32:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bjsm.bmj.com/content/early/2023/07/11/bjsports-2022-106195">https://bjsm.bmj.com/content/early/2023/07/11/bjsports-2022-106195</a>, See on <a href="https://news.ycombinator.com/item?id=37405727">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[China Bans iPhone Use for Government Officials at Work (119 pts)]]></title>
            <link>https://stocks.apple.com/A01gybx6UQReBj5eQUppe8g</link>
            <guid>37405695</guid>
            <pubDate>Wed, 06 Sep 2023 14:30:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stocks.apple.com/A01gybx6UQReBj5eQUppe8g">https://stocks.apple.com/A01gybx6UQReBj5eQUppe8g</a>, See on <a href="https://news.ycombinator.com/item?id=37405695">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
    
    <p><img src="https://stocks.apple.com/images/Appicon_v1_Stocks.png" alt="Apple News" srcset="https://stocks.apple.com/images/Appicon_v1_Stocks.png 1x, https://stocks.apple.com/images/Appicon_v1_Stocks@2x.png 2x,
         https://stocks.apple.com/images/Appicon_v1_Stocks@3x.png 3x"></p><h2>Opening story…</h2>
    <p><a href="https://www.wsj.com/world/china/china-bans-iphone-use-for-government-officials-at-work-635fe2f8"><span>Click here</span><span>Tap here</span></a> if the story doesn’t open after a few seconds.</p>
    <!-- Only show learn more for News Not Found pages --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[‘Modern cars are a privacy nightmare,’ the worst Mozilla’s seen (176 pts)]]></title>
            <link>https://www.theverge.com/2023/9/6/23861047/car-user-privacy-report-mozilla-foundation-data-collection</link>
            <guid>37405519</guid>
            <pubDate>Wed, 06 Sep 2023 14:17:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2023/9/6/23861047/car-user-privacy-report-mozilla-foundation-data-collection">https://www.theverge.com/2023/9/6/23861047/car-user-privacy-report-mozilla-foundation-data-collection</a>, See on <a href="https://news.ycombinator.com/item?id=37405519">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>If you’re wondering which gadgets have the worst user privacy practices, it turns out the answer may be parked outside. According to a <a href="https://foundation.mozilla.org/en/privacynotincluded/articles/its-official-cars-are-the-worst-product-category-we-have-ever-reviewed-for-privacy/">report published by the Mozilla Foundation</a> on Wednesday, cars are “the official worst category of products for privacy” that it’s ever reviewed. The global nonprofit found that 92 percent of the reviewed automakers provide drivers with little (if any) control over their personal data, with 84 percent sharing user data with outside parties.</p><p>Best known for its open-source Firefox web browser, the Mozilla Foundation claims to “stand up for the health of the internet.” It’s produced several reports and guides under its “Privacy Not Included” series over the years that detail how products and services like <a href="https://www.theverge.com/2022/5/2/23045250/mozilla-mental-health-app-privacy-analysis">mental health apps</a> and <a href="https://www.theverge.com/2023/2/23/23612009/google-play-android-apps-privacy-false-misleading-mozilla-study">app stores</a> handle user data, with advice on how to better protect ourselves.</p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="A graphic showing a car and a shocked emoji that says all 25 cars tested by Mozilla failed the organization’s privacy checks." loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/376x197/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/384x201/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/415x217/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/480x251/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/540x282/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/640x335/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/750x392/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/828x433/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/1080x565/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/1200x628/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/1440x753/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/1920x1004/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/2048x1071/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/2400x1255/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1350x706/2400x1255/filters:focal(675x353:676x354):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24900103/car_PNI_Final_Graphics_OG_Image_Privacy_Nighm.width_1350.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><div><figcaption><em>Kia and Nissan were notably highlighted for including sexual activity in their data collection practices.</em></figcaption> <p><cite>Image: Mozilla</cite></p></div></div><p>All 25 of the car brands that were researched for the report — including <a href="https://foundation.mozilla.org/en/privacynotincluded/ford/">Ford</a>, <a href="https://foundation.mozilla.org/en/privacynotincluded/toyota/">Toyota</a>, <a href="https://foundation.mozilla.org/en/privacynotincluded/volkswagen/">Volkswagen</a>, <a href="https://foundation.mozilla.org/en/privacynotincluded/bmw/">BMW</a>, and <a href="https://foundation.mozilla.org/en/privacynotincluded/tesla/">Tesla</a> — failed to meet the nonprofit organization’s <a href="https://foundation.mozilla.org/en/privacynotincluded/about/methodology/">minimum privacy standards</a> and were found to collect more personal data from customers than necessary. The kind of information collected varies from personal information like medical data to how drivers are using the vehicle itself — such as how fast they drive, where they drive, and even the music they listen to. Both <a href="https://foundation.mozilla.org/en/privacynotincluded/nissan/">Nissan</a> and <a href="https://foundation.mozilla.org/en/privacynotincluded/kia/">Kia</a> are noted to allow the collection of information regarding a user’s sex life. By contrast, Mozilla claims that 37 percent of mental health apps (<a href="https://www.theverge.com/2023/5/4/23710840/mental-health-therapy-apps-mozilla-report-privacy-data-security">which also have a poor reputation for data privacy</a>) had better practices for collecting and using personal data.</p><p>Eighty-four percent of the reviewed car brands share personal user data with service providers, data brokers, and <a href="https://foundation.mozilla.org/privacynotincluded/articles/what-data-does-my-car-collect-about-me-and-where-does-it-go/">potentially sketchy businesses</a>, according to the report, with 76 percent claiming the right to <em>sell</em> that personal data. Fifty-six percent are willing to share user information with the government and / or law enforcement if requested.&nbsp;</p><p>Tesla was the worst-ranked brand in the study, getting flagged in every privacy category — only the second time this happened. Tesla’s AI-powered autopilot was highlighted as “untrustworthy” following its <a href="https://www.theverge.com/2023/7/26/23809183/tesla-autopilot-investigation-false-advertising-california-attorney-general">involvement</a> in <a href="https://www.theverge.com/2022/6/9/23161365/tesla-autopilot-nhtsa-crash-investigation-emergency-vehicle">numerous</a> <a href="https://www.theverge.com/2022/10/26/23425335/tesla-autopilot-justice-department-criminal-investigation">crashes</a> and <a href="https://www.theverge.com/2022/7/27/23280461/tesla-autopilot-crash-motorcyclist-fatal-utah-nhtsa">fatalities</a>. </p><div><p>Mozilla found that numerous car companies collect sensitive user information like photos, immigration status, and even sexual activity</p></div><p>Alongside the report, Mozilla also <a href="https://foundation.mozilla.org/en/privacynotincluded/articles/what-data-does-my-car-collect-about-me-and-where-does-it-go/">published a breakdown</a> explaining how car companies collect and share user data. This can include anything from the user’s name, address, phone number, and email address to more intimate data like photos, calendar information, and even details on the driver’s race, genetic information, and immigration status.</p><p>Mozilla says it also couldn’t confirm that any of the automakers could meet the organization’s minimum security standards regarding data encryption and protection against theft. In fact, it claims dating apps and even sex toys typically provide more detailed security information about their products than cars. </p><p>“While we worried that our doorbells and watches that connect to the internet might be spying on us, car brands quietly entered the data business by turning their vehicles into powerful data-gobbling machines,” says Mozilla in the report.</p><p>Mozilla claims it spent over 600 hours researching the privacy practices of car brands — three times longer per product than it usually spends on these <a href="https://www.theverge.com/2023/2/23/23612009/google-play-android-apps-privacy-false-misleading-mozilla-study">privacy reviews</a>. The report was so scathing that the organization said the advice it typically provides to help customers protect their personal data feels like “tiny drops in a massive bucket.” Instead, the Mozilla Foundation has <a href="https://foundation.mozilla.org/en/privacynotincluded/articles/car-companies-stop-your-huge-data-collection-programs-en/?utm_source=PNI&amp;utm_campaign=23-PNI-Cars&amp;utm_medium=FMO&amp;utm_term=en&amp;utm_content=blog_1">started a petition</a> urging car companies to stop the data collection programs they’re unfairly benefitting from, expressing that “our hope is that increasing awareness will encourage others to hold car companies accountable for their terrible privacy practices.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Now it's PostgreSQL's turn to have a bogus CVE (162 pts)]]></title>
            <link>https://opensourcewatch.beehiiv.com/p/now-postgresqls-turn-bogus-cve</link>
            <guid>37404936</guid>
            <pubDate>Wed, 06 Sep 2023 13:37:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opensourcewatch.beehiiv.com/p/now-postgresqls-turn-bogus-cve">https://opensourcewatch.beehiiv.com/p/now-postgresqls-turn-bogus-cve</a>, See on <a href="https://news.ycombinator.com/item?id=37404936">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-blocks"><p><img alt="" src="https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/7e93734a-d5e4-4467-a5ef-7a9574c5aa64/PostgresSQL_logo.jpg"></p><p> This time, according to the <a href="https://docs.google.com/document/u/0/d/1zb78aBeMwS8wxJvdFbpHcC_tKqo9a1XmqMltQUy3oUY/edit?utm_source=opensourcewatch.beehiiv.com&amp;utm_medium=referral&amp;utm_campaign=now-it-s-postgresql-s-turn-to-have-a-bogus-cve" target="_blank" rel="noopener noreferrer nofollow">PostgreSQL</a> Security Team reports, just like with cURL, whoever the unknown reporter was didn't bother to tell them that was a security problem. Had they done so, the security team would have told them the same thing they told the NVD crew: There was no problem. </p><p> The "issue," <a href="https://www.cve.org/CVERecord?id=CVE-2020-21469&amp;utm_source=opensourcewatch.beehiiv.com&amp;utm_medium=referral&amp;utm_campaign=now-it-s-postgresql-s-turn-to-have-a-bogus-cve" target="_blank" rel="noopener noreferrer nofollow">CVE-2020-21469</a>, claimed that PostgreSQL 12.2 allowed attackers to cause a denial of service by repeatedly sending SIGHUP signals. SIGHUP, which dates back to the days when we connected terminals over serial port connections, is a kill-the-process signal. </p><p> That would be bad news. It would well deserve the 9.8 score it was branded with. </p><p> However, there's one little, itty-bitty problem. Ordinary users can't send SIGHUP signals. In fact, they can't kill PostgreSQL processes, period. SIGHUP can only be sent by a PostgreSQL superuser; a user with pg_reload_conf instructs PostgreSQL to reload its configuration, access, or the root user. In short, anyone who could use this "flaw" to kill PostgreSQL could use any ordinary method to terminate it without this nonsense. </p><p> Or, to quote the PostgreSQL Security Team, "THIS IS NOT A SECURITY VULNERABILITY." </p><p> They've got that right! </p><p> Mind you, as they'll tell you should update from PostgreSQL 12.2 because of <a href="https://www.postgresql.org/support/security/12/?utm_source=opensourcewatch.beehiiv.com&amp;utm_medium=referral&amp;utm_campaign=now-it-s-postgresql-s-turn-to-have-a-bogus-cve" target="_blank" rel="noopener noreferrer nofollow">these actual CVEs</a> and other bug fixes. After all, PostgreSQL 12.2 is over three years old. That makes it a dinosaur of a release. </p><p> But, there's a bigger problem going on. Why are these crap security releases appearing in the first place? And, why are they being blindly passed on to the public without any attempt to see if there is anything to them? In both cURL and PostgreSQL cases, simply asking the developers would have revealed there's "no there, there." </p><p> These aren't technically sophisticated bug reports. They are "Are you kidding me?" bug reports. </p><p> This brings up another point. It's 2023. Usually, a CVE is given the year it's reported as part of its designation. That, combined with over a hundred of them all appearing on the same day, should have raised red flags. </p><p> As to where they all came from, Dan Lorenc, CEO and co-founder of <a href="https://www.chainguard.dev/?utm_source=opensourcewatch.beehiiv.com&amp;utm_medium=referral&amp;utm_campaign=now-it-s-postgresql-s-turn-to-have-a-bogus-cve" target="_blank" rel="noopener noreferrer nofollow">Chainguard</a>, a software supply chain security company, speculated, "The curl commit had 'integer overflow' in the commit message. This Postgres one says 'buffer overflow' in it.<a href="https://twitter.com/lorenc_dan/status/1696669900985827738?utm_source=opensourcewatch.beehiiv.com&amp;utm_medium=referral&amp;utm_campaign=now-it-s-postgresql-s-turn-to-have-a-bogus-cve" target="_blank" rel="noopener noreferrer nofollow"> I'd bet $1,000 this is someone running a script</a> on grepping old commit messages for things like this and auto-filing CVEs." </p><p> No bet. </p><p> In a LinkedIn post, Lorenc expanded on his theme. "All of these CVEs link out to bug or patch entries on repos or mailing lists, <a href="https://www.linkedin.com/feed/update/urn:li:activity:7102609622657548288/?utm_source=opensourcewatch.beehiiv.com&amp;utm_medium=referral&amp;utm_campaign=now-it-s-postgresql-s-turn-to-have-a-bogus-cve" target="_blank" rel="noopener noreferrer nofollow">all were filed without maintainer interaction,</a> and all contain an obvious "vulnerable sounding" string in the commit message or issue. Something like 'use after free,' 'denial of service,' or "buffer overflow.'" </p><p> In short, these are garbage. </p><p> Lorenic said this flood of junk CVE " is literally going to DOS triage teams, the NVD itself, and open source maintainers stuck dealing with the fallout. Stop doing this!" He's correct. </p><p> The CVSS process itself is broken. Of course, we must take security seriously, but taking anonymous, poor complaints as Gospel security truth about critical projects only gets in the way of improving security. What we see with these nonsense reports doesn't help security, it only makes the process harder than ever. </p><p> Stop it! Stop it now! </p><p><span><b>Noteworthy Linux and open-source stories:</b></span></p><div><ul><li><p><a href="https://www.zdnet.com/article/amd-and-intel-cpu-security-bugs-bring-linux-patches/?utm_source=opensourcewatch.beehiiv.com&amp;utm_medium=referral&amp;utm_campaign=now-it-s-postgresql-s-turn-to-have-a-bogus-cve" target="_blank" rel="noopener noreferrer nofollow">AMD and Intel CPU security bugs bring Linux patches</a></p></li><li><p><a href="https://www.techradar.com/news/best-linux-distro-privacy-security?utm_source=opensourcewatch.beehiiv.com&amp;utm_medium=referral&amp;utm_campaign=now-it-s-postgresql-s-turn-to-have-a-bogus-cve" target="_blank" rel="noopener noreferrer nofollow">Best Linux distro for privacy and security of 2023</a></p></li><li><p><a href="https://www.theregister.com/2023/08/25/bodhi_linux_7/?utm_source=opensourcewatch.beehiiv.com&amp;utm_medium=referral&amp;utm_campaign=now-it-s-postgresql-s-turn-to-have-a-bogus-cve" target="_blank" rel="noopener noreferrer nofollow">Bodhi Linux 7 brings Enlightenment to Ubuntu</a></p></li></ul></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Pentagon and CIA have shaped thousands of movies into effective propaganda (105 pts)]]></title>
            <link>https://worldbeyondwar.org/the-pentagon-and-cia-have-shaped-thousands-of-hollywood-movies-into-super-effective-propaganda/</link>
            <guid>37404828</guid>
            <pubDate>Wed, 06 Sep 2023 13:29:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://worldbeyondwar.org/the-pentagon-and-cia-have-shaped-thousands-of-hollywood-movies-into-super-effective-propaganda/">https://worldbeyondwar.org/the-pentagon-and-cia-have-shaped-thousands-of-hollywood-movies-into-super-effective-propaganda/</a>, See on <a href="https://news.ycombinator.com/item?id=37404828">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="26e084c" data-element_type="widget" data-widget_type="theme-post-content.default">
			<p><a href="https://worldbeyondwar.org/wp-content/uploads/2022/01/Theaters_of_War.jpeg"><img decoding="async" src="https://worldbeyondwar.org/wp-content/uploads/2022/01/Theaters_of_War.jpeg" data-src="https://worldbeyondwar.org/wp-content/uploads/2022/01/Theaters_of_War.jpeg" alt="" width="1920" height="1080"></a></p>
<p>By David Swanson, World BEYOND War, January 5, 2022</p>
<p>Propaganda is most impactful when people don’t think it’s propaganda, and most decisive when it’s censorship you never knew happened. When we imagine that the U.S. military only occasionally and slightly influences U.S. movies, we are extremely badly deceived. The actual impact is on thousands of movies made, and thousands of others never made. And television shows of every variety. The military guests and celebrations of the U.S. military on game shows and cooking shows are no more spontaneous or civilian in origin than the ceremonies glorifying members of the U.S. military at professional sports games — ceremonies that have been paid for and choreographed by U.S. tax dollars and the U.S. military. The “entertainment” content carefully shaped by the “entertainment” offices of the Pentagon and the CIA doesn’t just insidiously prepare people to react differently to news about war and peace in the world. To a huge extent it substitutes a different reality for people who learn very little actual news about the world at all.</p>
<p>The U.S. military knows that few people watch boring and non-credible news programs, much less read boring and non-credible newspapers, but that great masses will eagerly watch long movies and TV shows without too much worrying about whether anything makes sense. We know that the Pentagon knows this, and what military officials scheme and plot as a result of knowing this, because of the work of relentless researchers making use of the Freedom of Information Act. These researchers have obtained many thousands of pages of memos, notes, and script re-writes. I don’t know whether they’ve put all of these documents online — I certainly hope they do and that they make the link widely available. I wish such a link were in giant font at the end of a fantastic new film. The film is called <em>Theaters of War: How the Pentagon and CIA Took Hollywood</em>. The Director, Editor, and Narrator is Roger Stahl. The Co-Producers are Matthew Alford, Tom Secker, Sebastian Kaempf. They’ve provided an important public service.</p>
<p>In the film we see copies of and hear quotations from and analysis of much of what has been uncovered, and learn that thousands of pages exist that nobody has yet seen because the military has refused to produce them. Film producers sign contracts with the U.S. military or CIA. They agree to “weave in key talking points.” While unknown quantities of this sort of thing remain unknown, we do know that nearly 3,000 films and many thousands of TV episodes have been given the Pentagon treatment, and many others have been handled by the CIA. In many film productions, the military effectively becomes a co-producer with veto power, in exchange for allowing the use of military bases, weapons, experts, and troops. The alternative is the denial of those things.</p>
<p>But the military is not as passive as this might suggest. It actively pitches new story ideas to movie and TV producers. It seeks out new ideas and new collaborators who might bring them to a theater or laptop near you. <em>Act of Valor</em> actually began life as a recruitment advertisement.</p>
<p>Of course, many movies are made without military assistance. Many of the best never wanted it. Many that wanted it and were denied, managed to get made anyway, sometimes at much greater expense without the U.S. tax dollars paying for the props. But a huge number of movies are made with the military. Sometimes the initial movie in a series is made with the military, and the remaining episodes voluntarily follow the military’s line. Practices are normalized. The military sees huge value in this work, including for recruitment purposes.</p>
<p>The alliance between the military and Hollywood is the main reason that we have lots of big blockbuster movies on certain topics and few if any on others. Studios have written scripts and hired top actors for movies on things like Iran-Contra that have never seen the light of day because of a Pentagon rejection. So, nobody watches Iran-Contra movies for fun the way they might watch a Watergate movie for fun. So, very few people have any notions about Iran-Contra.</p>
<p>But with the reality of what the U.S. military does being so awful, what, you might wonder, are the good topics that do get lots of movies made about them? A lot are fantasy or distortion.<em> Black Hawk Down</em> turned reality (and a book it was “based on”) on its head, as did <em>Clear and Present Danger</em>. Some, like <em>Argo</em>, hunt for small stories within large ones. Scripts explicitly tell audiences that it doesn’t matter who started a war for what, that the only thing that matters is the heroism of troops trying to survive or to rescue a soldier.</p>
<p>Yet, actual U.S. military veterans are often shut out and not consulted They often find movies rejected by the Pentagon as “unrealistic” to be very realistic, and those created with Pentagon collaboration to be highly unrealistic. Of course, a huge number of military-influenced films are made about the U.S. military fighting space aliens and magical creatures — not, clearly, because it’s believable but because it avoids reality. On the other hand, other military-influenced films shape people’s views of targeted nations and dehumanize the humans living in certain places.</p>
<p><em>Don’t Look Up</em> is not mentioned in <em>Theaters of War</em>, and presumably had no military involvement (who knows?, certainly not the movie-watching public), yet it uses a standard military-culture idea (the need to blow up something coming from outerspace, which in reality the U.S. government would simply love to do and you could hardly stop them) as an analogy for the need to stop destroying the planet’s climate (which you cannot easily get the U.S. government to remotely consider) and not one reviewer notices that the film is an equally good or bad analogy for the need to stop building nuclear weapons — because U.S. culture has had that need effectively excised.</p>
<p>The military has written policies on what it approves and disapproves. It disapproves depictions of failures and crimes, which eliminates much of reality. It rejects films about veteran suicide, racism in the military, sexual harassment and assault in the military. But it pretends to refuse to collaborate on films because they’re not “realistic.”</p>
<p>Yet, if you watch enough of what is produced with military involvement you’ll imagine that using and surviving nuclear war is perfectly plausible. This goes back to the <a href="https://davidswanson.org/the-beginning-of-the-end/">original Pentagon-Hollywood invention</a> of myths about Hiroshima and Nagasaki, and runs right up through military influence on <em>The Day After</em>, not to mention the transformation — paid for by people who throw a fit if their tax dollars help prevent someone freezing on the street — of <em>Godzilla</em> from a nuclear warning to the reverse. In the original script for the first <em>Iron Man</em> movie, the hero went up against the evil weapons dealers. The U.S. military rewrote it so that he was a heroic weapons dealer who explicitly argued for more military funding. Sequels stuck with that theme. The U.S. military advertised its weapons of choice in <em>Hulk,</em> <em>Superman, Fast and Furious,</em> and <em>Transformers</em>, the U.S. public effectively paying to push itself to support paying thousands of times more — for weapons it would otherwise have no interest in.</p>
<p>“Documentaries” on the Discovery, History, and National Geographic channels are military-made commercials for weapons. “Inside Combat Rescue” on National Geographic is recruitment propaganda. <em>Captain Marvel</em> exists to sell the Air Force to women. Actress Jennifer Garner has made recruitment ads to accompany movies she’s made that are themselves more effective recruitment ads. A movie called <em>The Recruit</em> was largely written by the head of the CIA’s entertainment office. Shows like NCIS push out the military’s line. But so do shows you wouldn’t expect: “reality” TV shows, game shows, talk shows (with endless reunifications of family members), cooking shows, competition shows, etc.</p>
<p>I’ve <a href="https://davidswanson.org/eye/">written before</a> about how <em>Eye in the Sky</em> was openly and proudly both completely unrealistic nonsense and influenced by the U.S. military to shape people’s ideas about drone murders. A lot of people have some small idea of what goes on. But <em>Theaters of War: How the Pentagon and CIA Took Hollywood </em>helps us to grasp the scale of it. And once we’ve done that, we may gain some possible insights into why polling finds much of the world fearing the U.S. military as a threat to peace, but much of the U.S. public believing that U.S. wars benefit people who are grateful for them. We may begin to form some guesses as to how it is that people in the United States tolerate and even glorify endless mass-killing and destruction, support threatening to use or even using nuclear weapons, and suppose the U.S. to have major enemies out there threatening its “freedoms.” Viewers of <em>Theaters of War</em> may not all immediately react with “Holy shit! The world must think we’re lunatics!” But a few may ask themselves whether it’s possible that wars don’t look like they do in movies — and that would be a great start.</p>
<p><em>Theaters of War</em> ends with a recommendation, that movies be required to disclose at the start any military or CIA collaboration. The film also notes that the United States has laws against propagandizing the U.S. public, which might make such a disclosure a confession of a crime. I would add that<em> s</em>ince 1976, the <a href="https://www.ohchr.org/EN/ProfessionalInterest/Pages/CCPR.aspx">International Covenant on Civil and Political Rights</a> has required that “Any propaganda for war shall be prohibited by law.”</p>
<p>To learn more about this film, view it, or host a screening of it, go <a href="https://shop.mediaed.org/theaters-of-war-p839.aspx">here</a>.</p>
<p><iframe loading="lazy" title="vimeo-player" src="https://player.vimeo.com/video/623566365?h=5560567729" width="640" height="360" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is this Duplo train track under too much tension? (1024 pts)]]></title>
            <link>https://puzzling.stackexchange.com/questions/122232/is-this-duplo-train-track-under-too-much-tension</link>
            <guid>37404740</guid>
            <pubDate>Wed, 06 Sep 2023 13:21:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://puzzling.stackexchange.com/questions/122232/is-this-duplo-train-track-under-too-much-tension">https://puzzling.stackexchange.com/questions/122232/is-this-duplo-train-track-under-too-much-tension</a>, See on <a href="https://news.ycombinator.com/item?id=37404740">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<p>First, we can check that there is no angular misalignment. Since 12 curved pieces are needed to make a full circle, the number of left pieces minus the number of right pieces must be a multiple of 12. Keeping track of the angle, starting at the crossing and going counterclockwise, I think that is satisfied in this setup:</p>
<p><a href="https://i.stack.imgur.com/mrYNQ.jpg" rel="noreferrer"><img src="https://i.stack.imgur.com/mrYNQ.jpg" alt="enter image description here"></a></p>
<p>Second, we look for positional misalignment. What we want to do is add up the vectors from the start to the end of each piece and check that the vector sum is zero. I haven't found a way to do this that ends up neater than just doing the trigonometry. However, things work out nicely in that all the coordinates end up being the sum of a rational number and a rational multiple of <span>$\sqrt{3}$</span> (in math lingo, they are members of <span>$\mathbb{Q}[\sqrt{3}]$</span>). This means that the coordinates sum to zero only if their rational parts sum to zero and the coefficients of <span>$\sqrt{3}$</span> sum to zero independently. This means that we can assign each piece type a list of 4 numbers (2 for the x-coordinate and 2 for the y-coordinate) and the pieces form a loop only if all 4 numbers sum to zero. Those numbers are:</p>
<pre><code>Curves:
0-1:  1    0    2   -1
1-2: -1    1   -1    1
2-3:  2   -1    1    0
3-4: -2    1    1    0
4-5:  1   -1   -1    1
5-6: -1    0    2   -1
Straights:
0-0:  1    0    0    0
1-1:  0    0.5  0.5  0
2-2:  0.5  0    0    0.5
3-3:  0    0    1    0
4-4: -0.5  0    0    0.5
5-5:  0   -0.5  0.5  0
</code></pre>
<p>Note that a 0-to-1 curve and a 1-to-0 curve have the same displacement so we only list the left curve. Also, a 180-degree rotation just negates the coordinates, so we can get away with only calculating the first half of the table.</p>
<p>Adding up the pieces in the layout gives a result of <code>4.5 -3 -2 0.5</code>, i.e. a displacement of <span>$\left(4.5-3\sqrt{3},-2+0.5\sqrt{3}\right)$</span>. This is not zero, so the layout is not free of stress. In fact, if we draw out the path that the shown pieces would ideally take, we get this shape:</p>
<p><a href="https://i.stack.imgur.com/Zetlz.png" rel="noreferrer"><img src="https://i.stack.imgur.com/Zetlz.png" alt="enter image description here"></a></p>
<p>No combination of fewer than 5 pieces will complete the loop, however the following combination of 5 will: <code>3-4 3-4 1-1 8-8 11-11</code>. (There are 3 more combinations of 5 that give the correct displacement, but would add an odd number of curves and therefore cause angular misalignment.)</p>
<p>Note that instead of adding a piece we can remove its 180-degree rotation. Therefore, I would suggest removing <code>10-9-10</code> and <code>5-5</code> and adding a <code>1-1</code> and <code>8-8</code>:</p>
<p><a href="https://i.stack.imgur.com/YsqAA.jpg" rel="noreferrer"><img src="https://i.stack.imgur.com/YsqAA.jpg" alt="enter image description here"></a></p>
<p>That's only if you want an 'exact' solution, for only changing a single piece you'd want to add a <code>2-2</code>, e.g. after the first gray curve, which would yield the following:</p>
<p><a href="https://i.stack.imgur.com/4u6qg.png" rel="noreferrer"><img src="https://i.stack.imgur.com/4u6qg.png" alt="enter image description here"></a></p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Northern summer was hottest on record by a significant margin (114 pts)]]></title>
            <link>https://www.cnn.com/2023/09/06/world/hottest-summer-record-climate-intl/index.html</link>
            <guid>37404433</guid>
            <pubDate>Wed, 06 Sep 2023 12:56:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2023/09/06/world/hottest-summer-record-climate-intl/index.html">https://www.cnn.com/2023/09/06/world/hottest-summer-record-climate-intl/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=37404433">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/lede-2374c5ca94e59acd9d644772a7445542@published" data-name="02 hottest summer climate" data-component-name="image" data-observe-resizes="" data-original-ratio="0.696875" data-original-height="1115" data-original-width="1600" data-url="https://media.cnn.com/api/v1/images/stellar/prod/230906142423-02-hottest-summer-climate.jpg?c=original" data-editable="lede" data-freewheel-lede="true">
       <picture><source height="720" width="1280" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230906142423-02-hottest-summer-climate.jpg?c=16x9&amp;q=h_720,w_1280,c_fill/f_webp" type="image/webp"><source height="540" width="960" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230906142423-02-hottest-summer-climate.jpg?c=16x9&amp;q=h_540,w_960,c_fill/f_webp" type="image/webp"><source height="270" width="480" media="(-webkit-min-device-pixel-ratio: 2)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230906142423-02-hottest-summer-climate.jpg?c=16x9&amp;q=h_270,w_480,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/230906142423-02-hottest-summer-climate.jpg?c=16x9&amp;q=h_720,w_1280,c_fill" alt="People cool off near the Pantheon in Rome, Italy, on Aug. 22, 2023. Italy experienced severe heat waves this summer." onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1115" width="1600"></picture>
    </div><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location"></span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_47571F81-480F-1708-9064-6951844303F5@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      As heat waves continue to bake parts of the world, scientists are reporting that this blistering, deadly summer was the hottest on record – and by a significant margin. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_7DB9D29B-1A31-2545-222B-695184466E66@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      June to August was the planet’s warmest such period since records began in 1940, according to data from the European Union’s Copernicus Climate Change Service.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_B9948F7E-F143-AB56-74D8-69518447F729@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The global average temperature this summer was 16.77 degrees Celsius (62.19 Fahrenheit), according to Copernicus, which is 0.66 degrees Celsius above the 1990 to 2020 average – beating the previous record, set in August 2019, by nearly 0.3 degrees Celsius. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_F955E30B-0CB2-E1B2-1144-695184489485@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Typically these records, which track the average air temperature across the entire world, are broken by hundredths of a degree.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_3659E6A6-B758-61F9-A6D1-6951844854C7@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      This is the first set of scientific data to confirm what many had believed was inevitable. It’s been a<a href="https://www.cnn.com/2023/07/25/world/heat-wave-climate-change-us-china-europe-intl/index.html" target="_blank"> searingly hot summer</a> for swaths of the Northern Hemisphere – including parts of the United States, Europe and <a href="https://www.cnn.com/2023/07/17/asia/climate-extreme-weather-floods-korea-japan-china-india-intl-hnk/index.html" target="_blank">Japan</a> – with record-breaking heat waves and unprecedented ocean temperatures. 
  </p>

  


  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_82328A02-5507-C29D-ABD4-6A3399FACF3D@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The planet experienced its <a href="https://www.cnn.com/2023/07/06/world/warmest-june-global-record-climate/index.html" target="_blank">hottest June on record</a>, followed by the <a href="https://www.cnn.com/2023/07/27/world/july-hottest-month-record-climate/index.html" target="_blank">hottest July</a> – both breaking previous records by large margins.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_396ACBA6-B633-051B-199F-6951844A0789@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      August was also the warmest such month on record, according to the new Copernicus data, and warmer than every other month this year except for July. The global average temperature for the month was 16.82 degrees Celsius – 0.31 degrees warmer than the previous record set in 2016. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_C01935C0-E96D-C148-0589-695CE8E7C1F7@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “The dog days of summer are not just barking, they are biting,” said António Guterres, secretary-general of the United Nations, in a statement about the Copernicus data. “Scientists have long warned what our fossil fuel addiction will unleash. Our climate is imploding faster than we can cope with extreme weather events hitting every corner of the planet”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_9EBA3FBF-7127-E5EF-441E-6951844D4000@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Both July and August are estimated to have been 1.5 degrees warmer than pre-industrial levels, according to Copernicus,<a href="https://www.cnn.com/2023/05/17/world/global-warming-breach-wmo-climate-intl/index.html" target="_blank"> a key threshold</a> scientists have long warned the world must stay under to prevent the most catastrophic impacts of climate change. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_D0DC6093-9AAE-AD8A-22A7-6951844D5D5A@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      While scientists are more focused on long-term global temperature rises, these temporary breaches are an important preview of what the world can expect summers to look like <a href="https://www.cnn.com/2023/08/08/world/july-climate-record-paris-agreement/index.html" target="_blank">at 1.5 degrees of warming</a>.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_AA649A54-E49F-5823-3CFF-69B84C47A965@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “The Northern Hemisphere just had a summer of extremes – with repeated heatwaves <a href="https://www.cnn.com/2023/08/22/americas/canada-wildfires-climate-change-quebec/index.html" target="_blank">fueling devastating wildfires</a>, harming health, disrupting daily lives and wreaking a lasting toll on the environment,”  Petteri Taalas, secretary-general of the World Meteorological Organization, said in a statement. 
  </p>

<div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/image-1b8224b0dcf9d1fc19d9925dc3c728f3@published" data-name="03 hottest summer climate" data-component-name="image" data-observe-resizes="" data-original-ratio="0.666875" data-original-height="1067" data-original-width="1600" data-url="https://media.cnn.com/api/v1/images/stellar/prod/230906142440-03-hottest-summer-climate.jpg?c=original" data-editable="settings">
       <picture><source height="720" width="1280" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230906142440-03-hottest-summer-climate.jpg?c=16x9&amp;q=h_720,w_1280,c_fill/f_webp" type="image/webp"><source height="540" width="960" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230906142440-03-hottest-summer-climate.jpg?c=16x9&amp;q=h_540,w_960,c_fill/f_webp" type="image/webp"><source height="270" width="480" media="(-webkit-min-device-pixel-ratio: 2)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230906142440-03-hottest-summer-climate.jpg?c=16x9&amp;q=h_270,w_480,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/230906142440-03-hottest-summer-climate.jpg?c=16x9&amp;q=h_720,w_1280,c_fill" alt="People seek relief from the heat in Tokyo, on July 30, 2023. Temperatures of 35 degrees Celsius (95F) and above scorched the Japanese capital for weeks." onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1067" width="1600" loading="lazy"></picture>
    </div>

<div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/image-dd7b2bf54cb208c31905f94592e6b787@published" data-name="01 hottest summer climate" data-component-name="image" data-observe-resizes="" data-original-ratio="0.666875" data-original-height="1067" data-original-width="1600" data-url="https://media.cnn.com/api/v1/images/stellar/prod/230906133305-01-hottest-summer-climate.jpg?c=original" data-editable="settings">
       <picture><source height="720" width="1280" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230906133305-01-hottest-summer-climate.jpg?c=16x9&amp;q=h_720,w_1280,c_fill/f_webp" type="image/webp"><source height="540" width="960" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230906133305-01-hottest-summer-climate.jpg?c=16x9&amp;q=h_540,w_960,c_fill/f_webp" type="image/webp"><source height="270" width="480" media="(-webkit-min-device-pixel-ratio: 2)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230906133305-01-hottest-summer-climate.jpg?c=16x9&amp;q=h_270,w_480,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/230906133305-01-hottest-summer-climate.jpg?c=16x9&amp;q=h_720,w_1280,c_fill" alt="A billboard displays a temperature of 118 degrees Fahrenheit (48 degrees Celcius) during a record heat wave in Phoenix, Arizona, on July 18, 2023. " onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1067" width="1600" loading="lazy"></picture>
    </div>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_ABE9672D-5CF7-2684-73F6-69606CEDF2E3@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Countries in the Southern Hemisphere have also experienced startlingly warm winters, with well-above average temperatures recorded in Australia, <a href="https://www.cnn.com/2023/08/04/americas/south-america-winter-heatwave-climate-intl/index.html" target="_blank">several South American countries</a> and Antarctica. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_9A7048DE-5776-BF5F-2D34-6951844FDB67@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Global average ocean temperatures, too, have been <a href="https://www.cnn.com/2023/08/04/world/ocean-heat-temperature-record-climate/index.html" target="_blank">off the charts</a>, helping strengthen<a href="https://www.cnn.com/2023/08/28/us/idalia-rapid-intensification-florida-climate/index.html" target="_blank"> major hurricanes in the Atlantic</a> and typhoons in the Pacific.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_02A6A593-A24D-8750-8E11-69518450ECE3@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In July, a sudden marine heat wave off the coast of Florida saw the ocean reach<a href="https://www.cnn.com/2023/07/12/us/florida-ocean-heat-coral-bleaching-climate/index.html" target="_blank"> “hot tub” temperatures</a>. While in June, parts of the North Atlantic experienced <a href="https://www.cnn.com/2023/06/20/europe/marine-heatwave-north-atlantic-climate-scn-intl/index.html" target="_blank">a “totally unprecedented” marine heat wave</a> with water temperatures up to 5 degrees Celsius (9 degrees Fahrenheit) hotter than usual.    
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_7DC2A536-6403-33A5-DA16-6960F6F731C1@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Every single day from the end of July to the end of August has seen ocean temperatures exceed the previous record set in 2016, according to Copernicus. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_4C444175-4C78-844D-721D-69518451F6D1@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Whether this year will end up being the planet’s warmest on record is not yet clear, but it looks certain to come extremely close. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_9A68525A-50AC-6B49-5829-6951845282B8@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      With four months of the year remaining, 2023 currently ranks as the second warmest on record, according to Copernicus, only 0.01 degrees Celsius below 2016, which is currently the warmest year on record.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_84C077D4-8BD9-F648-4C10-695184538B9E@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Scientists say next year <a href="https://www.cnn.com/2023/07/20/us/2024-hotter-than-2023-el-nino-nasa-climate/index.html" target="_blank">is likely to be even hotter</a>, given the arrival of El Niño, a natural climate fluctuation that brings warmer-than-average sea-surface temperatures and influences weather.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_226F3E5E-6212-2AA5-BEED-699C69B92539@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “This El Niño is developing in a warmer ocean than any previous El Niño so we are watching with interest how this event develops in terms of strength and impact,” Samantha Burgess, deputy director of Copernicus, told CNN
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_F70C02C5-EDE6-BC5C-F192-695184532307@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Burgess said the summer had been one of tumbling records and it would only get worse if the world continues to burn planet-heating fossil fuels.  
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_B3A169E2-139C-0311-D761-695184543944@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “The scientific evidence is overwhelming – we will continue to see more climate records and more intense and frequent extreme weather events impacting society and ecosystems, until we stop emitting greenhouse gases,” she said in a statement.  
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_957BDAA8-DE4C-A3FF-662B-6AC91D9A9392@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The Copernicus data was released the same day as the US National Oceanic and Atmospheric Administration released its State of the Climate report for 2022 – an annual health check-up for the planet.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_26043999-93C8-746B-AEAB-6AC97FBD1B8D@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      It found record ocean heat and global sea levels last year, and unprecedented concentrations of planet-heating pollution in the atmosphere – with carbon pollution reaching the highest levels in at least 800,000 years, according to the<a href="https://www.noaa.gov/news-release/international-report-confirms-record-high-greenhouse-gases-global-sea-levels-in-2022" target="_blank"> report</a>. 
  </p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Falcon 180B (215 pts)]]></title>
            <link>https://huggingface.co/blog/falcon-180b</link>
            <guid>37404424</guid>
            <pubDate>Wed, 06 Sep 2023 12:55:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huggingface.co/blog/falcon-180b">https://huggingface.co/blog/falcon-180b</a>, See on <a href="https://news.ycombinator.com/item?id=37404424">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><a href="https://huggingface.co/blog">
				Back to blog</a></p>
		<!-- HTML_TAG_START -->



<h2>
	<a id="introduction" href="#introduction">
		
	</a>
	<span>
		Introduction
	</span>
</h2>
<p><strong>Today, we're excited to welcome <a href="https://falconllm.tii.ae/">TII's</a> Falcon 180B to HuggingFace!</strong> Falcon 180B sets a new state-of-the-art for open models. It is the largest openly available language model, with 180 billion parameters, and was trained on a massive 3.5 trillion tokens using TII's <a href="https://huggingface.co/datasets/tiiuae/falcon-refinedweb">RefinedWeb</a> dataset. This represents the longest single-epoch pretraining for an open model. </p>
<p>You can find the model on the Hugging Face Hub (<a href="https://huggingface.co/tiiuae/falcon-180B">base</a> and <a href="https://huggingface.co/tiiuae/falcon-180B-chat">chat</a> model) and interact with the model on the <a href="https://huggingface.co/spaces/tiiuae/falcon-180b-chat">Falcon Chat Demo Space</a>.</p>
<p>In terms of capabilities, Falcon 180B achieves state-of-the-art results across natural language tasks. It tops the leaderboard for (pre-trained) open-access models and rivals proprietary models like PaLM-2. While difficult to rank definitively yet, it is considered on par with PaLM-2 Large, making Falcon 180B one of the most capable LLMs publicly known.</p>
<p>In this blog post, we explore what makes Falcon 180B so good by looking at some evaluation results and show how you can use the model.</p>
<ul>
<li><a href="#what-is-falcon-180b">What is Falcon-180B?</a></li>
<li><a href="#how-good-is-falcon-180b">How good is Falcon 180B?</a></li>
<li><a href="#how-to-use-falcon-180b">How to use Falcon 180B?</a><ul>
<li><a href="#demo">Demo</a></li>
<li><a href="#hardware-requirements">Hardware requirements</a></li>
<li><a href="#prompt-format">Prompt format</a></li>
<li><a href="#transformers">Transformers</a></li>
</ul>
</li>
<li><a href="#additional-resources">Additional Resources</a></li>
</ul>
<h2>
	<a id="what-is-falcon-180b" href="#what-is-falcon-180b">
		
	</a>
	<span>
		What is Falcon-180B?
	</span>
</h2>
<p>Falcon 180B is a model released by <a href="https://falconllm.tii.ae/">TII</a> that follows previous releases in the Falcon family.</p>
<p>Architecture-wise, Falcon 180B is a scaled-up version of <a href="https://huggingface.co/tiiuae/falcon-40b">Falcon 40B</a> and builds on its innovations such as multiquery attention for improved scalability. We recommend reviewing the <a href="https://huggingface.co/blog/falcon">initial blog post</a> introducing Falcon to dive into the architecture. Falcon 180B was trained on 3.5 trillion tokens on up to 4096 GPUs simultaneously, using Amazon SageMaker for a total of ~7,000,000 GPU hours. This means Falcon 180B is 2.5 times larger than Llama 2 and was trained with 4x more compute. </p>
<p>The dataset for Falcon 180B consists predominantly of web data from <a href="https://arxiv.org/abs/2306.01116">RefinedWeb</a> (~85%). In addition, it has been trained on a mix of curated data such as conversations, technical papers, and a small fraction of code (~3%). This pretraining dataset is big enough that even 3.5 trillion tokens constitute less than an epoch.</p>
<p>The released <a href="https://huggingface.co/tiiuae/falcon-180B-chat">chat model</a> is fine-tuned on chat and instruction datasets with a mix of several large-scale conversational datasets.</p>
<p>‼️ Commercial use: 
Falcon 180b can be commercially used but under very restrictive conditions, excluding any "hosting use". We recommend to check the <a href="https://huggingface.co/spaces/tiiuae/falcon-180b-license/blob/main/LICENSE.txt">license</a> and consult your legal team if you are interested in using it for commercial purposes.</p>
<h2>
	<a id="how-good-is-falcon-180b" href="#how-good-is-falcon-180b">
		
	</a>
	<span>
		How good is Falcon 180B?
	</span>
</h2>
<p>Falcon 180B is the best openly released LLM today, outperforming Llama 2 70B and OpenAI’s GPT-3.5 on MMLU, and is on par with Google's PaLM 2-Large on HellaSwag, LAMBADA, WebQuestions, Winogrande, PIQA, ARC, BoolQ, CB, COPA, RTE, WiC, WSC, ReCoRD. Falcon 180B typically sits somewhere between GPT 3.5 and GPT4 depending on the evaluation benchmark and further finetuning from the community will be very interesting to follow now that it's openly released.</p>
<p><a href="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/162_falcon_180b/palm2_480.jpg" rel="noopener nofollow"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/162_falcon_180b/palm2_480.jpg" alt="Palm 2 comparison"></a></p>
<p>With 68.74 on the Hugging Face Leaderboard, Falcon 180B is the highest-scoring openly released pre-trained LLM, surpassing Meta’s LLaMA 2 (67.35).</p>
<div>
	<table>
		<thead><tr>
<th>Model</th>
<th>Size</th>
<th>Leaderboard score</th>
<th>Commercial use or license</th>
<th>Pretraining length</th>
</tr>

		</thead><tbody><tr>
<td>Falcon</td>
<td>180B</td>
<td>68.74</td>
<td>🟠</td>
<td>3,500B</td>
</tr>
<tr>
<td>Llama 2</td>
<td>70B</td>
<td>67.35</td>
<td>🟠</td>
<td>2,000B</td>
</tr>
<tr>
<td>LLaMA</td>
<td>65B</td>
<td>64.23</td>
<td>🔴</td>
<td>1,400B</td>
</tr>
<tr>
<td>Falcon</td>
<td>40B</td>
<td>61.48</td>
<td>🟢</td>
<td>1,000B</td>
</tr>
<tr>
<td>MPT</td>
<td>30B</td>
<td>56.15</td>
<td>🟢</td>
<td>1,000B</td>
</tr>
</tbody>
	</table>
</div>
<p><a href="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/162_falcon_180b/open_llm_leaderboard.jpg" rel="noopener nofollow"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/162_falcon_180b/open_llm_leaderboard.jpg" alt="open_llm_leaderboard.png"></a></p>
<p>The quantized Falcon models preserve similar metrics across benchmarks. The results were similar when evaluating <code>torch.float16</code>, <code>8bit</code>, and <code>4bit</code>. See results in the <a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">Open LLM Leaderboard</a>.</p>
<h2>
	<a id="how-to-use-falcon-180b" href="#how-to-use-falcon-180b">
		
	</a>
	<span>
		How to use Falcon 180B?
	</span>
</h2>
<p>Falcon 180B is available in the Hugging Face ecosystem, starting with Transformers version 4.33.</p>
<h3>
	<a id="demo" href="#demo">
		
	</a>
	<span>
		Demo
	</span>
</h3>
<p>You can easily try the Big Falcon Model (180 billion parameters!) in <a href="https://huggingface.co/spaces/tiiuae/falcon-180b-demo">this Space</a> or in the playground embedded below:</p>


<h3>
	<a id="hardware-requirements" href="#hardware-requirements">
		
	</a>
	<span>
		Hardware requirements
	</span>
</h3>
<p>We ran several tests on the hardware needed to run the model for different use cases. Those are not the minimum numbers, but the minimum numbers for the configurations we had access to.</p>
<div>
	<table>
		<thead><tr>
<th></th>
<th>Type</th>
<th>Kind</th>
<th>Memory</th>
<th>Example</th>
</tr>

		</thead><tbody><tr>
<td>Falcon 180B</td>
<td>Training</td>
<td>Full fine-tuning</td>
<td>5120GB</td>
<td>8x 8x A100 80GB</td>
</tr>
<tr>
<td>Falcon 180B</td>
<td>Training</td>
<td>LoRA with ZeRO-3</td>
<td>1280GB</td>
<td>2x 8x A100 80GB</td>
</tr>
<tr>
<td>Falcon 180B</td>
<td>Training</td>
<td>QLoRA</td>
<td>160GB</td>
<td>2x A100 80GB</td>
</tr>
<tr>
<td>Falcon 180B</td>
<td>Inference</td>
<td>BF16/FP16</td>
<td>640GB</td>
<td>8x A100 80GB</td>
</tr>
<tr>
<td>Falcon 180B</td>
<td>Inference</td>
<td>GPTQ/int4</td>
<td>320GB</td>
<td>8x A100 40GB</td>
</tr>
</tbody>
	</table>
</div>
<h3>
	<a id="prompt-format" href="#prompt-format">
		
	</a>
	<span>
		Prompt format
	</span>
</h3>
<p>The base model has no prompt format. Remember that it’s not a conversational model or trained with instructions, so don’t expect it to generate conversational responses—the pretrained model is a great platform for further finetuning, but you probably shouldn’t driectly use it out of the box. The Chat model has a very simple conversation structure.</p>
<pre><code>System: Add an optional system prompt here
User: This is the user input
Falcon: This is what the model generates
User: This might be a second turn input
Falcon: and so on
</code></pre>
<h3>
	<a id="transformers" href="#transformers">
		
	</a>
	<span>
		Transformers
	</span>
</h3>
<p>With the release of Transformers 4.33, you can use Falcon 180B and leverage all the tools in the HF ecosystem, such as:</p>
<ul>
<li>training and inference scripts and examples</li>
<li>safe file format (safetensors)</li>
<li>integrations with tools such as bitsandbytes (4-bit quantization), PEFT (parameter efficient fine-tuning) and GPTQ</li>
<li>assisted generation (also known as “speculative decoding”)</li>
<li>RoPE scaling support for larger context lengths</li>
<li>rich and powerful generation parameters</li>
</ul>
<p>Use of the model requires you to accept its license and terms of use. Please, make sure you are logged into your Hugging Face account and ensure you have the latest version of <code>transformers</code>:</p>
<pre><code>pip install --upgrade transformers
huggingface-cli login
</code></pre>
<h4>
	<a id="bfloat16" href="#bfloat16">
		
	</a>
	<span>
		bfloat16
	</span>
</h4>
<p>This is how you’d use the base model in <code>bfloat16</code>. Falcon 180B is a big model, so please take into account the hardware requirements summarized in the table above.</p>
<pre><code><span>from</span> transformers <span>import</span> AutoTokenizer, AutoModelForCausalLM
<span>import</span> transformers
<span>import</span> torch

model_id = <span>"tiiuae/falcon-180B"</span>

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.bfloat16,
    device_map=<span>"auto"</span>,
)

prompt = <span>"My name is Pedro, I live in"</span>
inputs = tokenizer(prompt, return_tensors=<span>"pt"</span>).to(<span>"cuda"</span>)

output = model.generate(
    input_ids=inputs[<span>"input_ids"</span>],
    attention_mask=inputs[<span>"attention_mask"</span>],
    do_sample=<span>True</span>,
    temperature=<span>0.6</span>,
    top_p=<span>0.9</span>,
    max_new_tokens=<span>50</span>,
)
output = output[<span>0</span>].to(<span>"cpu"</span>)
<span>print</span>(tokenizer.decode(output)
</code></pre>
<p>This could produce an output such as:</p>
<pre><code>My name is Pedro, I live in Portugal and I am 25 years old. I am a graphic designer, but I am also passionate about photography and video.
I love to travel and I am always looking for new adventures. I love to meet new people and explore new places.
</code></pre>
<h4>
	<a id="8-bit-and-4-bit-with-bitsandbytes" href="#8-bit-and-4-bit-with-bitsandbytes">
		
	</a>
	<span>
		8-bit and 4-bit with <code>bitsandbytes</code>
	</span>
</h4>
<p>The 8-bit and 4-bit quantized versions of Falcon 180B show almost no difference in evaluation with respect to the <code>bfloat16</code> reference! This is very good news for inference, as you can confidently use a quantized version to reduce hardware requirements. Keep in mind, though, that 8-bit inference is <em>much faster</em> than running the model in <code>4-bit</code>.</p>
<p>To use quantization, you need to install the <code>bitsandbytes</code> library and simply enable the corresponding flag when loading the model:</p>
<pre><code>model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.bfloat16,
    load_in_8bit=<span>True</span>,
    device_map=<span>"auto"</span>,
)
</code></pre>
<h4>
	<a id="chat-model" href="#chat-model">
		
	</a>
	<span>
		Chat Model
	</span>
</h4>
<p>As mentioned above, the version of the model fine-tuned to follow conversations used a very straightforward training template. We have to follow the same pattern in order to run chat-style inference. For reference, you can take a look at the <a href="https://huggingface.co/spaces/tiiuae/falcon-180b-demo/blob/main/app.py#L28">format_prompt</a> function in the Chat demo, which looks like this:</p>
<pre><code><span>def</span> <span>format_prompt</span>(<span>message, history, system_prompt</span>):
    prompt = <span>""</span>
    <span>if</span> system_prompt:
        prompt += <span>f"System: <span>{system_prompt}</span>\n"</span>
    <span>for</span> user_prompt, bot_response <span>in</span> history:
        prompt += <span>f"User: <span>{user_prompt}</span>\n"</span>
        prompt += <span>f"Falcon: <span>{bot_response}</span>\n"</span>
        prompt += <span>f"User: <span>{message}</span>\nFalcon:"</span>
    <span>return</span> prompt
</code></pre>
<p>As you can see, interactions from the user and responses by the model are preceded by <code>User: </code> and <code>Falcon: </code> separators. We concatenate them together to form a prompt containing the conversation's whole history. We can provide a system prompt to tweak the generation style.</p>
<h2>
	<a id="additional-resources" href="#additional-resources">
		
	</a>
	<span>
		Additional Resources
	</span>
</h2>
<ul>
<li><a href="https://huggingface.co/models?other=falcon&amp;sort=trending&amp;search=180">Models</a></li>
<li><a href="https://huggingface.co/spaces/tiiuae/falcon-180b-chat">Demo</a></li>
<li><a href="https://huggingface.co/blog/falcon">The Falcon has landed in the Hugging Face ecosystem</a></li>
<li><a href="https://falconllm.tii.ae/">Official Announcement</a></li>
</ul>
<h2>
	<a id="acknowledgments" href="#acknowledgments">
		
	</a>
	<span>
		Acknowledgments
	</span>
</h2>
<p>Releasing such a model with support and evaluations in the ecosystem would not be possible without the contributions of many community members, including <a href="https://huggingface.co/clefourrier">Clémentine</a> and <a href="https://github.com/EleutherAI/lm-evaluation-harness">Eleuther Evaluation Harness</a> for LLM evaluations; <a href="https://huggingface.co/loubnabnl">Loubna</a> and <a href="https://huggingface.co/bigcode">BigCode</a> for code evaluations; <a href="https://hf.co/narsil">Nicolas</a> for Inference support; <a href="https://huggingface.co/lysandre">Lysandre</a>, <a href="https://huggingface.co/Rocketknight1">Matt</a>, <a href="https://huggingface.co/DanielHesslow">Daniel</a>, <a href="https://huggingface.co/amyeroberts">Amy</a>, <a href="https://huggingface.co/joaogante">Joao</a>, and <a href="https://huggingface.co/ArthurZ">Arthur</a> for integrating Falcon into transformers. Thanks to <a href="https://huggingface.co/BapBap">Baptiste</a> and <a href="https://huggingface.co/patrickvonplaten">Patrick</a> for the open-source demo. Thanks to <a href="https://huggingface.co/thomwolf">Thom</a>, <a href="https://huggingface.co/lewtun">Lewis</a>, <a href="https://huggingface.co/thebloke">TheBloke</a>, <a href="https://huggingface.co/nouamanetazi">Nouamane</a>, <a href="https://huggingface.co/timdettmers">Tim Dettmers</a> for multiple contributions enabling this to get out. Finally, thanks to the HF Cluster for enabling running LLM evaluations as well as providing inference for a free, open-source demo of the model.</p>
<!-- HTML_TAG_END --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[If You’ve Got a New Car, It’s a Data Privacy Nightmare (536 pts)]]></title>
            <link>https://gizmodo.com/mozilla-new-cars-data-privacy-report-1850805416</link>
            <guid>37404413</guid>
            <pubDate>Wed, 06 Sep 2023 12:54:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/mozilla-new-cars-data-privacy-report-1850805416">https://gizmodo.com/mozilla-new-cars-data-privacy-report-1850805416</a>, See on <a href="https://news.ycombinator.com/item?id=37404413">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Bad news: your car is a spy. If your vehicle was made in the last few years, you’re probably driving around in a data-harvesting machine that may collect personal information as sensitive as your race, weight, and sexual activity. Volkswagen’s cars reportedly know if you’re fastening your seatbelt and how hard you hit the brakes.</p><div data-video-id="193651" data-monetizable="true" data-position="sidebar" data-video-title="The FTC Just Prescribed a Can of Whoop Ass on Health Data" data-video-blog-id="4" data-video-network="gizmodo" data-video-duration="136" data-playlist="193651,195613,195603" data-current="193651"><div><p>The FTC Just Prescribed a Can of Whoop Ass on Health Data</p></div><video disablepictureinpicture="" muted="" playsinline="" width="100%" height="100%" crossorigin="anonymous" preload="none"><source data-src="https://vid.kinja.com/prod/193651/193651_240p.mp4" label="240p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/193651/193651_480p.mp4" label="480p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/193651/193651_720p.mp4" label="720p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/193651/193651_1080p.mp4" label="1080p" type="video/mp4"><track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/19103.vtt" srclang="en"></video><div><ul><li data-label="">Off</li><li data-label="English">English</li></ul></div></div><p>That’s according to new findings from Mozilla’s <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://foundation.mozilla.org/privacynotincluded/categories/cars/&quot;,{&quot;metric25&quot;:1}]]" href="https://foundation.mozilla.org/privacynotincluded/categories/cars/" target="_blank" rel="noopener noreferrer">*Privacy Not Included</a></span> project. The nonprofit found that every major car brand fails to adhere to the most basic privacy and security standards in new internet-connected models, and all 25 of the brands Mozilla examined flunked the organization’s test. Mozilla found brands including BMW, Ford, Toyota, Tesla, and Subaru collect data about drivers including race, facial expressions, weight, health information, and where you drive. Some of the cars tested collected data you wouldn’t expect your car to know about, including details about sexual activity, race, and immigration status, according to Mozilla.</p><p>“Many people think of their car as a private space — somewhere to call your doctor, have a personal conversation with your kid on the way to school, cry your eyes out over a break-up, or drive places you might not want the world to know about,” said Jen Caltrider, program direction of the *Privacy Not Included project, in a press release. “But that perception no longer matches reality. All new cars today are privacy nightmares on wheels that collect huge amounts of personal information.” </p><p>Modern cars use a variety of data harvesting tools including microphones, cameras, and the phones drivers connect to their cars. Manufacturers also collect data through their apps and websites, and can then sell or share that data with third parties. </p><p>The worst offender was Nissan, Mozilla said. The carmaker’s privacy policy suggests the manufacturer collects information including sexual activity, health diagnosis data, and genetic data, though there’s no details about how exactly that data is gathered. Nissan reserves the right to share and sell “preferences, characteristics, psychological trends, predispositions, behavior, attitudes, intelligence, abilities, and aptitudes” to data brokers, law enforcement, and other third parties.</p><p>Other brands didn’t fare much better. Volkswagen, for example, collects your driving behaviors such as your seatbelt and braking habits and pairs that with details such as age and gender for targeted advertising. Kia’s privacy policy reserves the right to monitor your “sex life,” and Mercedes-Benz ships cars with TikTok pre-installed on the infotainment system, an app that has its own <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/tiktok-ban-joe-biden-28000-apps-sdk-data-china-1850174019&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/tiktok-ban-joe-biden-28000-apps-sdk-data-china-1850174019">thicket of privacy problems</a></span>.</p><p>“BMW NA provides our customers with comprehensive data privacy notices regarding the collection of their personal information. For individual control, BMW NA allows vehicle drivers to make granular choices regarding the collection and processing of their personal information,” said Phil DiIanni, a BMW spokesperson. DiIanni said BMW hasn’t reviewed the study, but said “BMW NA does not sell our customer’s in-vehicle personal information,” and the company takes “comprehensive measures to protect our customers’ data.”</p><p>Mercedes-Benz spokesperson  Andrea Berg declined to comment, as the company hasn’t reviewed the study, but Berg said the MercedesMe Connect app gives users privacy settings and the ability to opt-out of certain services. Gizmodo contacted the other manufacturers named in this story, but none immediately provided comments.<br></p><p>The privacy and security problems extend beyond the nature of the data car companies siphon off about you. Mozilla said it was unable to determine whether the brands encrypt any of the data they collect, and only Mercedes-Benz responded to the organization’s questions. </p><p>Mozilla also found that many car brands engage in “privacy washing,” or presenting consumers with information that suggests they don’t have to worry about privacy issues when the exact opposite is true. Many leading<!-- --> manufacturers are signatories to the Alliance for Automotive Innovation’s “<span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.autosinnovate.org/innovation/Automotive%20Privacy/Consumer_Privacy_Principlesfor_VehicleTechnologies_Services-03-21-19.pdf&quot;,{&quot;metric25&quot;:1}]]" href="https://www.autosinnovate.org/innovation/Automotive%20Privacy/Consumer_Privacy_Principlesfor_VehicleTechnologies_Services-03-21-19.pdf" target="_blank" rel="noopener noreferrer">Consumer Privacy Protection Principles</a></span>.” According to Mozilla, these are a non-binding set of vague promises organized by the car manufacturers themselves. <br></p><p>Brian Weiss, a spokesperson for t<!-- -->he Alliance for Automotive<!-- --> Innovation, shared a link to <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.autosinnovate.org/association-update/1-Alliance%20for%20Automotive%20Innovation%20Letter%20on%20Federal%20Privacy%20Legislation.pdf&quot;,{&quot;metric25&quot;:1}]]" href="https://www.autosinnovate.org/association-update/1-Alliance%20for%20Automotive%20Innovation%20Letter%20on%20Federal%20Privacy%20Legislation.pdf" target="_blank" rel="noopener noreferrer">a letter the organization wrote</a></span> to congress about it<!-- -->s Privacy Principles. <!-- -->These principles “<!-- -->are in effect today and enforceable by the Federal Trade Commission,” Weiss said. <br></p><p>Questions around consent are essentially a joke as well. Subaru, for example, says that by being a passenger in the car, you are considered a “user” who has given the company consent to harvest information about you. Mozilla said a number of car brands say it’s the drivers responsibility to let passengers know about their car’s privacy policies—as if the privacy policies are comprehensible to drivers in the first place. Toyota, for example, has a constellation of 12 different privacy policies for your reading pleasure. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bletchley Park codebreaker Margaret Betts has died (182 pts)]]></title>
            <link>https://www.theguardian.com/world/2023/sep/06/she-played-it-down-bletchley-park-codebreaker-dies-at-99</link>
            <guid>37404109</guid>
            <pubDate>Wed, 06 Sep 2023 12:29:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/2023/sep/06/she-played-it-down-bletchley-park-codebreaker-dies-at-99">https://www.theguardian.com/world/2023/sep/06/she-played-it-down-bletchley-park-codebreaker-dies-at-99</a>, See on <a href="https://news.ycombinator.com/item?id=37404109">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>One of the last surviving female Bletchley Park codebreakers, who worked helping to decipher enemy communications during the second world war, has died aged 99.</p><p>Margaret Betts, of Ipswich, Suffolk, was 19 when she was headhunted by “men from the ministry”, having performed well at school, her son Jonathan Betts, 68, said.</p><p>He said she agreed to help, explaining: “She had recently lost her brother because his ship had been sunk by a German U-boat.</p><p>“It was absolutely tragic, he had just married a few weeks before, the whole family was in terrible shock and desperate to do something, to do their bit. She was inspired by this and said ‘absolutely, any way I can help I will’.</p><p>“She wasn’t told what it was, she was just told it would be highly secret work and that eventually she would be told what it was but meanwhile she was to pack her bags and go to a clearing house in north London.”</p><p>He said that she was headhunted in 1942. After a selection process she started work codebreaking in the summer of 1943 and worked through until Victory over Japan (VJ) Day in 1945.</p><p>“Like most of them did, she always played down her role,” said Betts, who lives outside Salisbury, Wiltshire.</p><p>“She said yes, I know it was incredibly important, our part in it, and I know it was highly secret, but please don’t come away with the idea that we’re all Alan Turings, because we’re not.</p><p>“We were there operating the machines, we were obeying orders, we were applying logic to do what we were told to do, and we were doing so efficiently and intelligently, but we didn’t design the machines for decoding.</p><p>She said they programmed machines, called bombes, and set them running to identify encrypted code.</p><p>“When they (the machines) stopped they knew the machine had come up with something,” said Betts. “It may not be anything, but what they then did was take a printout from what the machine had produced. They then took it to an Enigma machine – as they had German Enigma machines that had been captured.</p><p>“They then put the deciphering through the Enigma machine and if it came up with something they then sent it up the line to the senior personnel.”</p><p>Betts said his mother was told at the beginning ‘you must never, never tell anyone about it’.</p><p>“And so she didn’t – for over 40 years she wouldn’t talk about it, all she told us was she worked in an office in the Royal Navy’s service at home.</p><p>“It was only when documentaries started to appear on the TV and books started to be published that eventually she said ‘you know, I was one of those’,” said Betts.</p><p>“We said ‘gosh, why didn’t you tell us before!’ and she said ‘well, I signed the Official Secrets Act, we were told never to tell anyone but it’s obvious now people are all talking about it so I feel it’s OK to mention it’.</p><p>“She was very proud about it, but she played it down.</p><p>“When we said that sounds really exciting, like James Bond spy stuff, she said no, it wasn’t at all like that, it was very humdrum. We were operating machines night and day and it was incredibly boring work most of the time.</p><p>“You just had to stand by the machines, you had to concentrate when you were programming it and make sure it was set up correctly, and the rest of the time you were there watching it, waiting for it to come up with something.”</p><p>Betts said the Navy Wrens of Bletchley Park were invited to parties at local American airbases and “they had proper food, as in Britain there was rationing but the Americans didn’t have it in the same way”.</p><p>“We were all terribly proud to know (of her role),” Betts said.</p><p>“Yes, we heard what she said about it being humdrum but it was vital work they were doing. She was put in a great position of trust and respected that trust and worked hard and along with all the other Wrens in that service she did extremely well.</p><p>“Without their work the war would have lasted longer – some people reckon it would have gone on two years longer if they hadn’t been able to break the German and Japanese codes.</p><p>“She contributed a small part to a very important element in winning the war.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux Network Performance Parameters Explained (320 pts)]]></title>
            <link>https://github.com/leandromoreira/linux-network-performance-parameters</link>
            <guid>37403799</guid>
            <pubDate>Wed, 06 Sep 2023 11:56:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/leandromoreira/linux-network-performance-parameters">https://github.com/leandromoreira/linux-network-performance-parameters</a>, See on <a href="https://news.ycombinator.com/item?id=37403799">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto"><a href="https://github.com/leandromoreira/linux-network-performance-parameters/blob/master/README_RU.md" title="Russian">🇷🇺</a></p>
<h2 tabindex="-1" dir="auto">TOC</h2>
<ul dir="auto">
<li><a href="#introduction">Introduction</a></li>
<li><a href="#linux-network-queues-overview">Linux network queues overview</a></li>
<li><a href="#fitting-the-sysctl-variables-into-the-linux-network-flow">Fitting the sysctl variables into the Linux network flow</a>
<ul dir="auto">
<li>Ingress - they're coming</li>
<li>Egress - they're leaving</li>
<li>How to check - perf</li>
</ul>
</li>
<li><a href="#what-why-and-how---network-and-sysctl-parameters">What, Why and How - network and sysctl parameters</a>
<ul dir="auto">
<li>Ring Buffer - rx,tx</li>
<li>Interrupt Coalescence (IC) - rx-usecs, tx-usecs, rx-frames, tx-frames (hardware IRQ)</li>
<li>Interrupt Coalescing (soft IRQ) and Ingress QDisc</li>
<li>Egress QDisc - txqueuelen and default_qdisc</li>
<li>TCP Read and Write Buffers/Queues</li>
<li>Honorable mentions - TCP FSM and congestion algorithm</li>
</ul>
</li>
<li><a href="#network-tools-for-testing-and-monitoring">Network tools</a></li>
<li><a href="#references">References</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Introduction</h2>
<p dir="auto">Sometimes people are looking for <a href="https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt" rel="nofollow">sysctl</a> cargo cult values that bring high throughput and low latency with no trade-off and that works on every occasion. That's not realistic, although we can say that the <strong>newer kernel versions are very well tuned by default</strong>. In fact, you might <a href="https://medium.com/@duhroach/the-bandwidth-delay-problem-c6a2a578b211" rel="nofollow">hurt performance if you mess with the defaults</a>.</p>
<p dir="auto">This brief tutorial shows <strong>where some of the most used and quoted sysctl/network parameters are located into the Linux network flow</strong>, it was heavily inspired by <a href="https://blog.packagecloud.io/eng/2016/10/11/monitoring-tuning-linux-networking-stack-receiving-data-illustrated/" rel="nofollow">the illustrated guide to Linux networking stack</a> and many of <a href="https://blog.cloudflare.com/how-to-achieve-low-latency/" rel="nofollow">Marek Majkowski's posts</a>.</p>
<blockquote>
<h4 tabindex="-1" dir="auto">Feel free to send corrections and suggestions! :)</h4>
</blockquote>
<h2 tabindex="-1" dir="auto">Linux network queues overview</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/leandromoreira/linux-network-performance-parameters/blob/master/img/linux_network_flow.png"><img src="https://github.com/leandromoreira/linux-network-performance-parameters/raw/master/img/linux_network_flow.png" alt="linux network queues" title="A graphic representation of linux/kernel network main buffer / queues"></a></p>
<h2 tabindex="-1" dir="auto">Fitting the sysctl variables into the Linux network flow</h2>
<h2 tabindex="-1" dir="auto">Ingress - they're coming</h2>
<ol dir="auto">
<li>Packets arrive at the NIC</li>
<li>NIC will verify <code>MAC</code> (if not on promiscuous mode) and <code>FCS</code> and decide to drop or to continue</li>
<li>NIC will <a href="https://en.wikipedia.org/wiki/Direct_memory_access" rel="nofollow">DMA packets at RAM</a>, in a region previously prepared (mapped) by the driver</li>
<li>NIC will enqueue references to the packets at receive <a href="https://en.wikipedia.org/wiki/Circular_buffer" rel="nofollow">ring buffer</a> queue <code>rx</code> until <code>rx-usecs</code> timeout or <code>rx-frames</code></li>
<li>NIC will raise a <code>hard IRQ</code></li>
<li>CPU will run the <code>IRQ handler</code> that runs the driver's code</li>
<li>Driver will <code>schedule a NAPI</code>, clear the <code>hard IRQ</code> and return</li>
<li>Driver raise a <code>soft IRQ (NET_RX_SOFTIRQ)</code></li>
<li>NAPI will poll data from the receive ring buffer until <code>netdev_budget_usecs</code> timeout or <code>netdev_budget</code> and <code>dev_weight</code> packets</li>
<li>Linux will also allocate memory to <code>sk_buff</code></li>
<li>Linux fills the metadata: protocol, interface, setmacheader, removes ethernet</li>
<li>Linux will pass the skb to the kernel stack (<code>netif_receive_skb</code>)</li>
<li>It will set the network header, clone <code>skb</code> to taps (i.e. tcpdump) and pass it to tc ingress</li>
<li>Packets are handled to a qdisc sized <code>netdev_max_backlog</code> with its algorithm defined by <code>default_qdisc</code></li>
<li>It calls <code>ip_rcv</code> and packets are handed to IP</li>
<li>It calls netfilter (<code>PREROUTING</code>)</li>
<li>It looks at the routing table, if forwarding or local</li>
<li>If it's local it calls netfilter (<code>LOCAL_IN</code>)</li>
<li>It calls the L4 protocol (for instance <code>tcp_v4_rcv</code>)</li>
<li>It finds the right socket</li>
<li>It goes to the tcp finite state machine</li>
<li>Enqueue the packet to  the receive buffer and sized as <code>tcp_rmem</code> rules
<ol dir="auto">
<li>If <code>tcp_moderate_rcvbuf</code> is enabled kernel will auto-tune the receive buffer</li>
</ol>
</li>
<li>Kernel will signalize that there is data available to apps (epoll or any polling system)</li>
<li>Application wakes up and reads the data</li>
</ol>
<h2 tabindex="-1" dir="auto">Egress - they're leaving</h2>
<ol dir="auto">
<li>Application sends message (<code>sendmsg</code> or other)</li>
<li>TCP send message allocates skb_buff</li>
<li>It enqueues skb to the socket write buffer of <code>tcp_wmem</code> size</li>
<li>Builds the TCP header (src and dst port, checksum)</li>
<li>Calls L3 handler (in this case <code>ipv4</code> on <code>tcp_write_xmit</code> and <code>tcp_transmit_skb</code>)</li>
<li>L3 (<code>ip_queue_xmit</code>) does its work: build ip header and call netfilter (<code>LOCAL_OUT</code>)</li>
<li>Calls output route action</li>
<li>Calls netfilter (<code>POST_ROUTING</code>)</li>
<li>Fragment the packet (<code>ip_output</code>)</li>
<li>Calls L2 send function (<code>dev_queue_xmit</code>)</li>
<li>Feeds the output (QDisc) queue of <code>txqueuelen</code> length with its algorithm <code>default_qdisc</code></li>
<li>The driver code enqueue the packets at the <code>ring buffer tx</code></li>
<li>The driver will do a <code>soft IRQ (NET_TX_SOFTIRQ)</code> after <code>tx-usecs</code> timeout or <code>tx-frames</code></li>
<li>Re-enable hard IRQ to NIC</li>
<li>Driver will map all the packets (to be sent) to some DMA'ed region</li>
<li>NIC fetches the packets (via DMA) from RAM to transmit</li>
<li>After the transmission NIC will raise a <code>hard IRQ</code> to signal its completion</li>
<li>The driver will handle this IRQ (turn it off)</li>
<li>And schedule (<code>soft IRQ</code>) the NAPI poll system</li>
<li>NAPI will handle the receive packets signaling and free the RAM</li>
</ol>
<h2 tabindex="-1" dir="auto">How to check - perf</h2>
<p dir="auto">If you want to see the network tracing within Linux you can use <a href="https://man7.org/linux/man-pages/man1/perf-trace.1.html" rel="nofollow">perf</a>.</p>
<div data-snippet-clipboard-copy-content="docker run -it --rm --cap-add SYS_ADMIN --entrypoint bash ljishen/perf
apt-get update
apt-get install iputils-ping

# this is going to trace all events (not syscalls) to the subsystem net:* while performing the ping
perf trace --no-syscalls --event 'net:*' ping globo.com -c1 > /dev/null"><pre><code>docker run -it --rm --cap-add SYS_ADMIN --entrypoint bash ljishen/perf
apt-get update
apt-get install iputils-ping

# this is going to trace all events (not syscalls) to the subsystem net:* while performing the ping
perf trace --no-syscalls --event 'net:*' ping globo.com -c1 &gt; /dev/null
</code></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/55913/147019725-69624e67-b3ca-48b4-a823-10521d2bed83.png"><img src="https://user-images.githubusercontent.com/55913/147019725-69624e67-b3ca-48b4-a823-10521d2bed83.png" alt="perf trace network"></a></p>
<h2 tabindex="-1" dir="auto">What, Why and How - network and sysctl parameters</h2>
<h2 tabindex="-1" dir="auto">Ring Buffer - rx,tx</h2>
<ul dir="auto">
<li><strong>What</strong> - the driver receive/send queue a single or multiple queues with a fixed size, usually implemented as FIFO, it is located at RAM</li>
<li><strong>Why</strong> - buffer to smoothly accept bursts of connections without dropping them, you might need to increase these queues when you see drops or overrun, aka there are more packets coming than the kernel is able to consume them, the side effect might be increased latency.</li>
<li><strong>How:</strong>
<ul dir="auto">
<li><strong>Check command:</strong> <code>ethtool -g ethX</code></li>
<li><strong>Change command:</strong> <code>ethtool -G ethX rx value tx value</code></li>
<li><strong>How to monitor:</strong> <code>ethtool -S ethX | grep -e "err" -e "drop" -e "over" -e "miss" -e "timeout" -e "reset" -e "restar" -e "collis" -e "over" | grep -v "\: 0"</code></li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Interrupt Coalescence (IC) - rx-usecs, tx-usecs, rx-frames, tx-frames (hardware IRQ)</h2>
<ul dir="auto">
<li><strong>What</strong> - number of microseconds/frames to wait before raising a hardIRQ, from the NIC perspective it'll DMA data packets until this timeout/number of frames</li>
<li><strong>Why</strong> - reduce CPUs usage, hard IRQ, might increase throughput at cost of latency.</li>
<li><strong>How:</strong>
<ul dir="auto">
<li><strong>Check command:</strong> <code>ethtool -c ethX</code></li>
<li><strong>Change command:</strong> <code>ethtool -C ethX rx-usecs value tx-usecs value</code></li>
<li><strong>How to monitor:</strong> <code>cat /proc/interrupts</code></li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Interrupt Coalescing (soft IRQ) and Ingress QDisc</h2>
<ul dir="auto">
<li><strong>What</strong> - maximum number of microseconds in one <a href="https://en.wikipedia.org/wiki/New_API" rel="nofollow">NAPI</a> polling cycle. Polling will exit when either <code>netdev_budget_usecs</code> have elapsed during the poll cycle or the number of packets processed reaches  <code>netdev_budget</code>.</li>
<li><strong>Why</strong> - instead of reacting to tons of softIRQ, the driver keeps polling data; keep an eye on <code>dropped</code> (# of packets that were dropped because <code>netdev_max_backlog</code> was exceeded) and <code>squeezed</code> (# of times ksoftirq ran out of <code>netdev_budget</code> or time slice with work remaining).</li>
<li><strong>How:</strong>
<ul dir="auto">
<li><strong>Check command:</strong> <code>sysctl net.core.netdev_budget_usecs</code></li>
<li><strong>Change command:</strong> <code>sysctl -w net.core.netdev_budget_usecs value</code></li>
<li><strong>How to monitor:</strong> <code>cat /proc/net/softnet_stat</code>; or a <a href="https://raw.githubusercontent.com/majek/dump/master/how-to-receive-a-packet/softnet.sh" rel="nofollow">better tool</a></li>
</ul>
</li>
<li><strong>What</strong> - <code>netdev_budget</code> is the maximum number of packets taken from all interfaces in one polling cycle (NAPI poll). In one polling cycle interfaces which are registered to polling are probed in a round-robin manner. Also, a polling cycle may not exceed <code>netdev_budget_usecs</code> microseconds, even if <code>netdev_budget</code> has not been exhausted.</li>
<li><strong>How:</strong>
<ul dir="auto">
<li><strong>Check command:</strong> <code>sysctl net.core.netdev_budget</code></li>
<li><strong>Change command:</strong> <code>sysctl -w net.core.netdev_budget value</code></li>
<li><strong>How to monitor:</strong> <code>cat /proc/net/softnet_stat</code>; or a <a href="https://raw.githubusercontent.com/majek/dump/master/how-to-receive-a-packet/softnet.sh" rel="nofollow">better tool</a></li>
</ul>
</li>
<li><strong>What</strong> - <code>dev_weight</code> is the maximum number of packets that kernel can handle on a NAPI interrupt, it's a Per-CPU variable. For drivers that support LRO or GRO_HW, a hardware aggregated packet is counted as one packet in this.</li>
<li><strong>How:</strong>
<ul dir="auto">
<li><strong>Check command:</strong> <code>sysctl net.core.dev_weight</code></li>
<li><strong>Change command:</strong> <code>sysctl -w net.core.dev_weight value</code></li>
<li><strong>How to monitor:</strong> <code>cat /proc/net/softnet_stat</code>; or a <a href="https://raw.githubusercontent.com/majek/dump/master/how-to-receive-a-packet/softnet.sh" rel="nofollow">better tool</a></li>
</ul>
</li>
<li><strong>What</strong> - <code>netdev_max_backlog</code> is the maximum number  of  packets,  queued  on  the  INPUT side (<em>the ingress qdisc</em>), when the interface receives packets faster than kernel can process them.</li>
<li><strong>How:</strong>
<ul dir="auto">
<li><strong>Check command:</strong> <code>sysctl net.core.netdev_max_backlog</code></li>
<li><strong>Change command:</strong> <code>sysctl -w net.core.netdev_max_backlog value</code></li>
<li><strong>How to monitor:</strong> <code>cat /proc/net/softnet_stat</code>; or a <a href="https://raw.githubusercontent.com/majek/dump/master/how-to-receive-a-packet/softnet.sh" rel="nofollow">better tool</a></li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Egress QDisc - txqueuelen and default_qdisc</h2>
<ul dir="auto">
<li><strong>What</strong> - <code>txqueuelen</code> is the maximum number of packets, queued on the OUTPUT side.</li>
<li><strong>Why</strong> - a buffer/queue to face connection burst and also to apply <a href="http://tldp.org/HOWTO/Traffic-Control-HOWTO/intro.html" rel="nofollow">tc (traffic control).</a></li>
<li><strong>How:</strong>
<ul dir="auto">
<li><strong>Check command:</strong> <code>ip link show dev ethX</code></li>
<li><strong>Change command:</strong> <code>ip link set dev ethX txqueuelen N</code></li>
<li><strong>How to monitor:</strong> <code>ip -s link</code></li>
</ul>
</li>
<li><strong>What</strong> - <code>default_qdisc</code> is the default queuing discipline to use for network devices.</li>
<li><strong>Why</strong> - each application has different load and need to traffic control and it is used also to fight against <a href="https://www.bufferbloat.net/projects/codel/wiki/" rel="nofollow">bufferbloat</a></li>
<li><strong>How:</strong>
<ul dir="auto">
<li><strong>Check command:</strong> <code>sysctl net.core.default_qdisc</code></li>
<li><strong>Change command:</strong> <code>sysctl -w net.core.default_qdisc value</code></li>
<li><strong>How to monitor:</strong>   <code>tc -s qdisc ls dev ethX</code></li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">TCP Read and Write Buffers/Queues</h2>
<blockquote>
<p dir="auto">The policy that defines what is <a href="https://wwwx.cs.unc.edu/~sparkst/howto/network_tuning.php" rel="nofollow">memory pressure</a> is specified at tcp_mem and tcp_moderate_rcvbuf.</p>
</blockquote>
<ul dir="auto">
<li><strong>What</strong> - <code>tcp_rmem</code> - min (size used under memory pressure), default (initial size), max (maximum size) - size of receive buffer used by TCP sockets.</li>
<li><strong>Why</strong> - the application buffer/queue to the write/send data, <a href="https://blog.cloudflare.com/the-story-of-one-latency-spike/" rel="nofollow">understand its consequences can help a lot</a>.</li>
<li><strong>How:</strong>
<ul dir="auto">
<li><strong>Check command:</strong> <code>sysctl net.ipv4.tcp_rmem</code></li>
<li><strong>Change command:</strong> <code>sysctl -w net.ipv4.tcp_rmem="min default max"</code>; when changing default value, remember to restart your user space app (i.e. your web server, nginx, etc)</li>
<li><strong>How to monitor:</strong> <code>cat /proc/net/sockstat</code></li>
</ul>
</li>
<li><strong>What</strong> - <code>tcp_wmem</code> - min (size used under memory pressure), default (initial size), max (maximum size) - size of send buffer used by TCP sockets.</li>
<li><strong>How:</strong>
<ul dir="auto">
<li><strong>Check command:</strong> <code>sysctl net.ipv4.tcp_wmem</code></li>
<li><strong>Change command:</strong> <code>sysctl -w net.ipv4.tcp_wmem="min default max"</code>; when changing default value, remember to restart your user space app (i.e. your web server, nginx, etc)</li>
<li><strong>How to monitor:</strong> <code>cat /proc/net/sockstat</code></li>
</ul>
</li>
<li><strong>What</strong> <code>tcp_moderate_rcvbuf</code> - If set, TCP performs receive buffer auto-tuning, attempting to automatically size the buffer.</li>
<li><strong>How:</strong>
<ul dir="auto">
<li><strong>Check command:</strong> <code>sysctl net.ipv4.tcp_moderate_rcvbuf</code></li>
<li><strong>Change command:</strong> <code>sysctl -w net.ipv4.tcp_moderate_rcvbuf value</code></li>
<li><strong>How to monitor:</strong> <code>cat /proc/net/sockstat</code></li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Honorable mentions - TCP FSM and congestion algorithm</h2>
<blockquote>
<p dir="auto">Accept and SYN Queues are governed by net.core.somaxconn and net.ipv4.tcp_max_syn_backlog. <a href="https://blog.cloudflare.com/syn-packet-handling-in-the-wild/#queuesizelimits" rel="nofollow">Nowadays net.core.somaxconn caps both queue sizes.</a></p>
</blockquote>
<ul dir="auto">
<li><code>sysctl net.core.somaxconn</code> - provides an upper limit on the value of the backlog parameter passed to the <a href="https://eklitzke.org/how-tcp-sockets-work" rel="nofollow"><code>listen()</code> function</a>, known in userspace as <code>SOMAXCONN</code>. If you change this value, you should also change your application to a compatible value (i.e. <a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#listen" rel="nofollow">nginx backlog</a>).</li>
<li><code>cat /proc/sys/net/ipv4/tcp_fin_timeout</code> - this specifies the number of seconds to wait for a final FIN packet before the socket is forcibly closed.  This is strictly a violation of the TCP specification but required to prevent denial-of-service attacks.</li>
<li><code>cat /proc/sys/net/ipv4/tcp_available_congestion_control</code> - shows the available congestion control choices that are registered.</li>
<li><code>cat /proc/sys/net/ipv4/tcp_congestion_control</code> - sets the congestion control algorithm to be used for new connections.</li>
<li><code>cat /proc/sys/net/ipv4/tcp_max_syn_backlog</code> - sets the maximum number of queued connection requests which have still not received an acknowledgment from the connecting client; if this number is exceeded, the kernel will begin dropping requests.</li>
<li><code>cat /proc/sys/net/ipv4/tcp_syncookies</code> - enables/disables <a href="https://en.wikipedia.org/wiki/SYN_cookies" rel="nofollow">syn cookies</a>, useful for protecting against <a href="https://www.cloudflare.com/learning/ddos/syn-flood-ddos-attack/" rel="nofollow">syn flood attacks</a>.</li>
<li><code>cat /proc/sys/net/ipv4/tcp_slow_start_after_idle</code> - enables/disables tcp slow start.</li>
</ul>
<p dir="auto"><strong>How to monitor:</strong></p>
<ul dir="auto">
<li><code>netstat -atn | awk '/tcp/ {print $6}' | sort | uniq -c</code> - summary by state</li>
<li><code>ss -neopt state time-wait | wc -l</code> - counters by a specific state: <code>established</code>, <code>syn-sent</code>, <code>syn-recv</code>, <code>fin-wait-1</code>, <code>fin-wait-2</code>, <code>time-wait</code>, <code>closed</code>, <code>close-wait</code>, <code>last-ack</code>, <code>listening</code>, <code>closing</code></li>
<li><code>netstat -st</code> - tcp stats summary</li>
<li><code>nstat -a</code> - human-friendly tcp stats summary</li>
<li><code>cat /proc/net/sockstat</code> - summarized socket stats</li>
<li><code>cat /proc/net/tcp</code> - detailed stats, see each field meaning at the <a href="https://www.kernel.org/doc/Documentation/networking/proc_net_tcp.txt" rel="nofollow">kernel docs</a></li>
<li><code>cat /proc/net/netstat</code> - <code>ListenOverflows</code> and <code>ListenDrops</code> are important fields to keep an eye on
<ul dir="auto">
<li><code>cat /proc/net/netstat | awk '(f==0) { i=1; while ( i&lt;=NF) {n[i] = $i; i++ }; f=1; next} \ (f==1){ i=2; while ( i&lt;=NF){ printf "%s = %d\n", n[i], $i; i++}; f=0} ' | grep -v "= 0</code>; a <a href="https://sa-chernomor.livejournal.com/9858.html" rel="nofollow">human readable <code>/proc/net/netstat</code></a></li>
</ul>
</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/91bdb6f4cc46fa8db6b6e41c712eb1e37c3c598e05c553a889a3d270e7e6a60e/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f612f61322f5463705f73746174655f6469616772616d5f66697865642e737667"><img src="https://camo.githubusercontent.com/91bdb6f4cc46fa8db6b6e41c712eb1e37c3c598e05c553a889a3d270e7e6a60e/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f612f61322f5463705f73746174655f6469616772616d5f66697865642e737667" alt="tcp finite state machine" title="A graphic representation of tcp tcp finite state machine" data-canonical-src="https://upload.wikimedia.org/wikipedia/commons/a/a2/Tcp_state_diagram_fixed.svg"></a>
Source: <a href="https://commons.wikimedia.org/wiki/File:Tcp_state_diagram_fixed_new.svg" rel="nofollow">https://commons.wikimedia.org/wiki/File:Tcp_state_diagram_fixed_new.svg</a></p>
<h2 tabindex="-1" dir="auto">Network tools for testing and monitoring</h2>
<ul dir="auto">
<li><a href="https://iperf.fr/" rel="nofollow">iperf3</a> - network throughput</li>
<li><a href="https://github.com/tsenart/vegeta">vegeta</a> - HTTP load testing tool</li>
<li><a href="https://github.com/firehol/netdata">netdata</a> - system for distributed real-time performance and health monitoring</li>
</ul>
<h2 tabindex="-1" dir="auto">References</h2>
<ul dir="auto">
<li><a href="https://www.kernel.org/doc/Documentation/sysctl/net.txt" rel="nofollow">https://www.kernel.org/doc/Documentation/sysctl/net.txt</a></li>
<li><a href="https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt" rel="nofollow">https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt</a></li>
<li><a href="https://www.kernel.org/doc/Documentation/networking/scaling.txt" rel="nofollow">https://www.kernel.org/doc/Documentation/networking/scaling.txt</a></li>
<li><a href="https://www.kernel.org/doc/Documentation/networking/proc_net_tcp.txt" rel="nofollow">https://www.kernel.org/doc/Documentation/networking/proc_net_tcp.txt</a></li>
<li><a href="https://www.kernel.org/doc/Documentation/networking/multiqueue.txt" rel="nofollow">https://www.kernel.org/doc/Documentation/networking/multiqueue.txt</a></li>
<li><a href="http://man7.org/linux/man-pages/man7/tcp.7.html" rel="nofollow">http://man7.org/linux/man-pages/man7/tcp.7.html</a></li>
<li><a href="http://man7.org/linux/man-pages/man8/tc.8.html" rel="nofollow">http://man7.org/linux/man-pages/man8/tc.8.html</a></li>
<li><a href="http://cseweb.ucsd.edu/classes/fa09/cse124/presentations/TCPlinux_implementation.pdf" rel="nofollow">http://cseweb.ucsd.edu/classes/fa09/cse124/presentations/TCPlinux_implementation.pdf</a></li>
<li><a href="https://netdevconf.org/1.2/papers/bbr-netdev-1.2.new.new.pdf" rel="nofollow">https://netdevconf.org/1.2/papers/bbr-netdev-1.2.new.new.pdf</a></li>
<li><a href="https://blog.cloudflare.com/how-to-receive-a-million-packets/" rel="nofollow">https://blog.cloudflare.com/how-to-receive-a-million-packets/</a></li>
<li><a href="https://blog.cloudflare.com/how-to-achieve-low-latency/" rel="nofollow">https://blog.cloudflare.com/how-to-achieve-low-latency/</a></li>
<li><a href="https://blog.packagecloud.io/eng/2016/06/22/monitoring-tuning-linux-networking-stack-receiving-data/" rel="nofollow">https://blog.packagecloud.io/eng/2016/06/22/monitoring-tuning-linux-networking-stack-receiving-data/</a></li>
<li><a href="https://www.youtube.com/watch?v=6Fl1rsxk4JQ" rel="nofollow">https://www.youtube.com/watch?v=6Fl1rsxk4JQ</a></li>
<li><a href="https://oxnz.github.io/2016/05/03/performance-tuning-networking/" rel="nofollow">https://oxnz.github.io/2016/05/03/performance-tuning-networking/</a></li>
<li><a href="https://www.intel.com/content/dam/www/public/us/en/documents/reference-guides/xl710-x710-performance-tuning-linux-guide.pdf" rel="nofollow">https://www.intel.com/content/dam/www/public/us/en/documents/reference-guides/xl710-x710-performance-tuning-linux-guide.pdf</a></li>
<li><a href="https://access.redhat.com/sites/default/files/attachments/20150325_network_performance_tuning.pdf" rel="nofollow">https://access.redhat.com/sites/default/files/attachments/20150325_network_performance_tuning.pdf</a></li>
<li><a href="https://medium.com/@matteocroce/linux-and-freebsd-networking-cbadcdb15ddd" rel="nofollow">https://medium.com/@matteocroce/linux-and-freebsd-networking-cbadcdb15ddd</a></li>
<li><a href="https://blogs.technet.microsoft.com/networking/2009/08/12/where-do-resets-come-from-no-the-stork-does-not-bring-them/" rel="nofollow">https://blogs.technet.microsoft.com/networking/2009/08/12/where-do-resets-come-from-no-the-stork-does-not-bring-them/</a></li>
<li><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/multi-core-processor-based-linux-paper.pdf" rel="nofollow">https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/multi-core-processor-based-linux-paper.pdf</a></li>
<li><a href="http://syuu.dokukino.com/2013/05/linux-kernel-features-for-high-speed.html" rel="nofollow">http://syuu.dokukino.com/2013/05/linux-kernel-features-for-high-speed.html</a></li>
<li><a href="https://www.bufferbloat.net/projects/codel/wiki/Best_practices_for_benchmarking_Codel_and_FQ_Codel/" rel="nofollow">https://www.bufferbloat.net/projects/codel/wiki/Best_practices_for_benchmarking_Codel_and_FQ_Codel/</a></li>
<li><a href="https://software.intel.com/en-us/articles/setting-up-intel-ethernet-flow-director" rel="nofollow">https://software.intel.com/en-us/articles/setting-up-intel-ethernet-flow-director</a></li>
<li><a href="https://courses.engr.illinois.edu/cs423/sp2014/Lectures/LinuxDriver.pdf" rel="nofollow">https://courses.engr.illinois.edu/cs423/sp2014/Lectures/LinuxDriver.pdf</a></li>
<li><a href="https://www.coverfire.com/articles/queueing-in-the-linux-network-stack/" rel="nofollow">https://www.coverfire.com/articles/queueing-in-the-linux-network-stack/</a></li>
<li><a href="http://vger.kernel.org/~davem/skb.html" rel="nofollow">http://vger.kernel.org/~davem/skb.html</a></li>
<li><a href="https://www.missoulapubliclibrary.org/ftp/LinuxJournal/LJ13-07.pdf" rel="nofollow">https://www.missoulapubliclibrary.org/ftp/LinuxJournal/LJ13-07.pdf</a></li>
<li><a href="https://opensourceforu.com/2016/10/network-performance-monitoring/" rel="nofollow">https://opensourceforu.com/2016/10/network-performance-monitoring/</a></li>
<li><a href="https://www.yumpu.com/en/document/view/55400902/an-adventure-of-analysis-and-optimisation-of-the-linux-networking-stack" rel="nofollow">https://www.yumpu.com/en/document/view/55400902/an-adventure-of-analysis-and-optimisation-of-the-linux-networking-stack</a></li>
<li><a href="https://lwn.net/Articles/616241/" rel="nofollow">https://lwn.net/Articles/616241/</a></li>
<li><a href="https://medium.com/@duhroach/tools-to-profile-networking-performance-3141870d5233" rel="nofollow">https://medium.com/@duhroach/tools-to-profile-networking-performance-3141870d5233</a></li>
<li><a href="https://www.lmax.com/blog/staff-blogs/2016/05/06/navigating-linux-kernel-network-stack-receive-path/" rel="nofollow">https://www.lmax.com/blog/staff-blogs/2016/05/06/navigating-linux-kernel-network-stack-receive-path/</a></li>
<li><a href="https://fasterdata.es.net/host-tuning/linux/100g-tuning/" rel="nofollow">https://fasterdata.es.net/host-tuning/linux/100g-tuning/</a></li>
<li><a href="http://tcpipguide.com/free/t_TCPOperationalOverviewandtheTCPFiniteStateMachineF-2.htm" rel="nofollow">http://tcpipguide.com/free/t_TCPOperationalOverviewandtheTCPFiniteStateMachineF-2.htm</a></li>
<li><a href="http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html" rel="nofollow">http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html</a></li>
<li><a href="https://people.cs.clemson.edu/~westall/853/tcpperf.pdf" rel="nofollow">https://people.cs.clemson.edu/~westall/853/tcpperf.pdf</a></li>
<li><a href="http://tldp.org/HOWTO/Traffic-Control-HOWTO/classless-qdiscs.html" rel="nofollow">http://tldp.org/HOWTO/Traffic-Control-HOWTO/classless-qdiscs.html</a></li>
<li><a href="https://fasterdata.es.net/assets/Papers-and-Publications/100G-Tuning-TechEx2016.tierney.pdf" rel="nofollow">https://fasterdata.es.net/assets/Papers-and-Publications/100G-Tuning-TechEx2016.tierney.pdf</a></li>
<li><a href="https://www.kernel.org/doc/ols/2009/ols2009-pages-169-184.pdf" rel="nofollow">https://www.kernel.org/doc/ols/2009/ols2009-pages-169-184.pdf</a></li>
<li><a href="https://devcentral.f5.com/articles/the-send-buffer-in-depth-21845" rel="nofollow">https://devcentral.f5.com/articles/the-send-buffer-in-depth-21845</a></li>
<li><a href="http://packetbomb.com/understanding-throughput-and-tcp-windows/" rel="nofollow">http://packetbomb.com/understanding-throughput-and-tcp-windows/</a></li>
<li><a href="https://www.speedguide.net/bdp.php" rel="nofollow">https://www.speedguide.net/bdp.php</a></li>
<li><a href="https://www.switch.ch/network/tools/tcp_throughput/" rel="nofollow">https://www.switch.ch/network/tools/tcp_throughput/</a></li>
<li><a href="https://www.ibm.com/support/knowledgecenter/en/SSQPD3_2.6.0/com.ibm.wllm.doc/usingethtoolrates.html" rel="nofollow">https://www.ibm.com/support/knowledgecenter/en/SSQPD3_2.6.0/com.ibm.wllm.doc/usingethtoolrates.html</a></li>
<li><a href="https://blog.tsunanet.net/2011/03/out-of-socket-memory.html" rel="nofollow">https://blog.tsunanet.net/2011/03/out-of-socket-memory.html</a></li>
<li><a href="https://unix.stackexchange.com/questions/12985/how-to-check-rx-ring-max-backlog-and-max-syn-backlog-size" rel="nofollow">https://unix.stackexchange.com/questions/12985/how-to-check-rx-ring-max-backlog-and-max-syn-backlog-size</a></li>
<li><a href="https://serverfault.com/questions/498245/how-to-reduce-number-of-time-wait-processes" rel="nofollow">https://serverfault.com/questions/498245/how-to-reduce-number-of-time-wait-processes</a></li>
<li><a href="https://unix.stackexchange.com/questions/419518/how-to-tell-how-much-memory-tcp-buffers-are-actually-using" rel="nofollow">https://unix.stackexchange.com/questions/419518/how-to-tell-how-much-memory-tcp-buffers-are-actually-using</a></li>
<li><a href="https://eklitzke.org/how-tcp-sockets-work" rel="nofollow">https://eklitzke.org/how-tcp-sockets-work</a></li>
<li><a href="https://www.linux.com/learn/intro-to-linux/2017/7/introduction-ss-command" rel="nofollow">https://www.linux.com/learn/intro-to-linux/2017/7/introduction-ss-command</a></li>
<li><a href="https://staaldraad.github.io/2017/12/20/netstat-without-netstat/" rel="nofollow">https://staaldraad.github.io/2017/12/20/netstat-without-netstat/</a></li>
<li><a href="https://loicpefferkorn.net/2016/03/linux-network-metrics-why-you-should-use-nstat-instead-of-netstat/" rel="nofollow">https://loicpefferkorn.net/2016/03/linux-network-metrics-why-you-should-use-nstat-instead-of-netstat/</a></li>
<li><a href="http://assimilationsystems.com/2015/12/29/bufferbloat-network-best-practice/" rel="nofollow">http://assimilationsystems.com/2015/12/29/bufferbloat-network-best-practice/</a></li>
<li><a href="https://wwwx.cs.unc.edu/~sparkst/howto/network_tuning.php" rel="nofollow">https://wwwx.cs.unc.edu/~sparkst/howto/network_tuning.php</a></li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Norway court rules against Facebook owner Meta in privacy case (143 pts)]]></title>
            <link>https://www.reuters.com/technology/norway-data-regulator-fine-meta-over-privacy-breaches-2023-08-07/</link>
            <guid>37403583</guid>
            <pubDate>Wed, 06 Sep 2023 11:23:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/norway-data-regulator-fine-meta-over-privacy-breaches-2023-08-07/">https://www.reuters.com/technology/norway-data-regulator-fine-meta-over-privacy-breaches-2023-08-07/</a>, See on <a href="https://news.ycombinator.com/item?id=37403583">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="primary-gallery"><p data-testid="Body"><b data-testid="Body">[1/2]</b><span>A smartphone with Meta logo is seen in front of displayed Facebook's new rebrand logo Meta in this illustration taken, October 28, 2021. REUTERS/Dado Ruvic/Illustration/File Photo <a data-testid="Link" href="https://www.reutersagency.com/en/licensereuterscontent/?utm_medium=rcom-article-media&amp;utm_campaign=rcom-rcp-lead" target="_blank"> Acquire Licensing Rights</a></span></p></div><div><div><div><ul role="tablist"><li data-testid="Text" role="tab" aria-selected="true" tabindex="0">Summary</li><li data-testid="Text" role="tab" aria-selected="false" tabindex="-1">Companies</li></ul></div><div><ul><li data-testid="Body">Norwegian data regulator hails 'big victory for privacy'</li><li data-testid="Body">Meta says it is 'disappointed'</li><li data-testid="Body">Fine could be widened to rest of Europe</li></ul></div></div><p data-testid="paragraph-0">OSLO, Sept 6 (Reuters) - Meta Platforms <a data-testid="Link" href="https://www.reuters.com/markets/companies/META.O" target="_blank">(META.O)</a> can be fined for breaching users' privacy, a Norwegian court ruled on Wednesday, stopping an attempt by the owner of Facebook and Instagram to halt a fine imposed by the country's data regulator.</p><p data-testid="paragraph-1">Meta has been fined one million crowns ($93,200) per day since <a data-testid="Link" href="https://www.reuters.com/technology/norway-data-regulator-fine-meta-over-privacy-breaches-2023-08-07/">Aug. 14</a> for harvesting user data and using it to target advertising at them. So-called behavioural advertising is a business model common to Big Tech.</p><p data-testid="paragraph-2">The owner of Facebook and Instagram had sought a temporary injunction against the order from the Norwegian data regulator, Datatilsynet, which imposed a daily fine for three months.</p><p data-testid="paragraph-3">"This is a big victory for privacy," Datatilsynet said in a statement.</p><p data-testid="paragraph-4">The case could have wider European implications as Datatilsynet is considering referring the decision to the European data regulator.</p><p data-testid="paragraph-5">If the European Data Protection Board agrees with Datatilsynet, it could widen the decision's territorial scope to the rest of Europe and make the fine permanent.</p><p data-testid="paragraph-6">The Norwegian agency said on Wednesday it had not yet made a decision on a referral.</p><p data-testid="paragraph-7">Norway is not a member of the European Union but it is a member of the European single market.</p><h2 data-testid="Heading">VERDICT</h2><p data-testid="paragraph-8">Meta argued, among other things, that the authority's decision had been disproportionate, impossible to meet and in violation of other laws, but the court rejected the claims.</p><p data-testid="paragraph-9">"None of these arguments will affect the outcome," Judge Henning Kristiansen said in his ruling, which also orders Meta to pay Datatilsynet's case costs.</p><p data-testid="paragraph-10">Meta declined to say whether it would appeal the verdict.</p><p data-testid="paragraph-11">"We are disappointed by today's decision and will now consider our next steps," a Meta spokesperson said in an emailed statement to Reuters.</p><p data-testid="paragraph-12">Meta told a two-day <a data-testid="Link" href="https://www.reuters.com/technology/facebook-owner-meta-platforms-seeks-stop-privacy-breach-fine-norway-2023-08-22/">court hearing</a> in August it had already committed to ask for consent from users and that Datatilsynet used an "expedited process" that was unnecessary and did not give the company enough time to answer.</p><p data-testid="paragraph-13">The regulator has said it was unclear when, and how, Meta would seek consent from users and that, in the meantime, users' rights were being violated.</p><p data-testid="paragraph-14">($1 = 10.7271 Norwegian crowns)</p><p data-testid="Body">Reporting by Gwladys Fouche, editing by Terje Solsvik and Christina Fincher</p><p data-testid="Body">Our Standards: <a data-testid="Link" href="https://www.thomsonreuters.com/en/about-us/trust-principles.html" target="_blank">The Thomson Reuters Trust Principles.</a></p><div><address><p data-testid="Body">Oversees news coverage from Norway for Reuters and loves flying to Svalbard in the Arctic, oil platforms in the North Sea, and guessing who is going to win the Nobel Peace Prize. Born in France and with Reuters since 2010, she has worked for The Guardian, Agence France-Presse and Al Jazeera English, among others, and speaks four languages.</p></address></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Toyota blames factory shutdown in Japan on ‘insufficient disk space’ (130 pts)]]></title>
            <link>https://www.theguardian.com/business/2023/sep/06/toyota-blames-factory-shutdown-in-japan-on-insufficient-disk-space</link>
            <guid>37403566</guid>
            <pubDate>Wed, 06 Sep 2023 11:19:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/business/2023/sep/06/toyota-blames-factory-shutdown-in-japan-on-insufficient-disk-space">https://www.theguardian.com/business/2023/sep/06/toyota-blames-factory-shutdown-in-japan-on-insufficient-disk-space</a>, See on <a href="https://news.ycombinator.com/item?id=37403566">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><a href="https://www.theguardian.com/business/toyota" data-link-name="in body link">Toyota</a> has blamed a recent shutdown of all of its factories in <a href="https://www.theguardian.com/world/japan" data-link-name="in body link">Japan</a> on a system malfunction caused by “insufficient disk space”.</p><p>The Japanese carmaker said the stoppage on 29 August at all 14 of its domestic plants occurred after servers that process orders for vehicle parts broke down following a maintenance procedure carried out the previous day.</p><p>During this operation, “data that had accumulated in the database was deleted and organised, and an error occurred due to insufficient disk space, causing the system to stop”, <a href="https://www.theguardian.com/business/toyota" data-link-name="in body link" data-component="auto-linked-tag">Toyota</a> said on Wednesday.</p><p>The world’s top-selling automaker reiterated that the incident had not been caused by a cyber-attack. “We would like to apologise once again to our customers, suppliers, and related parties for any inconvenience caused by the suspension of our domestic plants,” it said.</p><p>Toyota said the system had been restored after the data was transferred to a server with a bigger capacity, enabling it to restart production at the plants – which together account for about a third of the automaker’s global production – the following day.</p><p>“We will review our maintenance procedures and strengthen our efforts to prevent a recurrence, so that we can deliver as many vehicles to our customers as soon as possible,” it added.</p><p>Toyota is known for its “just-in-time” production system of providing only small deliveries of necessary parts and other items at various stages of the assembly process.</p><p>This minimises costs and improves efficiency, and is studied by other manufacturers and at business schools around the world. However, as last month’s technical glitch proves, it comes with risks.</p><p>Toyota had to shut down the same 14 factories for a day in February last year when one of its suppliers said one of its file servers had been infected with a virus, raising questions about the cybersecurity of Japan’s supply chains.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How would you say “She said goodbye too many times before.” in Latin? (355 pts)]]></title>
            <link>https://latin.stackexchange.com/a/21492</link>
            <guid>37403136</guid>
            <pubDate>Wed, 06 Sep 2023 09:57:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://latin.stackexchange.com/a/21492">https://latin.stackexchange.com/a/21492</a>, See on <a href="https://news.ycombinator.com/item?id=37403136">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<p>Cicero provides a possibility for "too many times" with <em>nimium saepe</em>:</p>
<blockquote>
<p>Quare "bene et praeclare" quamvis nobis saepe dicatur; "belle et festive" <strong>nimium saepe</strong> nolo (Cicero, <em>De Oratore</em> 3.101.2)</p>
</blockquote>
<p>I think the meaning is even clearer with Seneca's <em>Medea</em>:</p>
<blockquote>
<p>Quodsi <strong>nimium saepe</strong> vocari quereris votis, ignosce, precor:<br>
But if you protest at <strong>too frequent</strong> a summons from my entreaties, forgive me, I pray:</p>
</blockquote>
<p>Cicero uses <em>nimium</em> joined with <em>saepe</em> often, perhaps too often, since it's rarely found in other others (once in Seneca, the above passage, and I think twice in Ovid, but I haven't translated the passages in full to see if they belong together or if <em>nimium</em> goes with another word).</p>
<p>You could also easily just use the comparative or superlative forms of <em>saepe</em>, which would get the point across. In searching the Loeb library, I found several translators who have done that, so it's not just my intuition.</p>
<p>While Draconis is right that you don't need to translate "she", you might consider it if you want to single the subject out. For this, you could use <em>illa</em>, "that woman." For this particular sense of <em>illa</em>, see Lewis &amp; Short:</p>
<blockquote>
<p>C. Opp. to hic, <strong>to indicate that object which is the more remote</strong>, either as regards the position of the word denoting it, or as it is conceived of by the writer; v. hic, I. D.—</p>
</blockquote>
<p>So saying <em>illa valedixit</em> would have the same sense as the English "that woman."</p>
<p>I really only bring this up because the previous line has (and the song is called) "this love," so it provides a nice contrast: <em>hic amor, illa mulier.</em></p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gcsfuse: A user-space file system for interacting with Google Cloud Storage (126 pts)]]></title>
            <link>https://github.com/GoogleCloudPlatform/gcsfuse</link>
            <guid>37403074</guid>
            <pubDate>Wed, 06 Sep 2023 09:48:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/GoogleCloudPlatform/gcsfuse">https://github.com/GoogleCloudPlatform/gcsfuse</a>, See on <a href="https://news.ycombinator.com/item?id=37403074">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Current status</h2>
<p dir="auto">Starting with V1.0, Cloud Storage FUSE is Generally Available and supported by Google, provided that it is used within its documented supported applications, platforms, and limits. Support requests, feature requests, and general questions should be submitted as a support request via Google Cloud support channels or via GitHub&nbsp;<a href="https://github.com/GoogleCloudPlatform/gcsfuse/issues">here</a>.</p>
<p dir="auto">Cloud Storage FUSE is open source software, released under the
<a href="https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/LICENSE">Apache license</a>.</p>
<h2 tabindex="-1" dir="auto">ABOUT</h2>
<h2 tabindex="-1" dir="auto">What is Cloud Storage FUSE?</h2>
<p dir="auto">Cloud Storage FUSE is an open source FUSE adapter that lets you mount and access Cloud Storage buckets as local file systems. For a technical overview of Cloud Storage FUSE, see <a href="https://cloud.google.com/storage/docs/gcs-fuse" rel="nofollow">https://cloud.google.com/storage/docs/gcs-fuse</a>.</p>
<h2 tabindex="-1" dir="auto">Cloud Storage FUSE for machine learning</h2>
<p dir="auto">To learn about the benefits of using Cloud Storage FUSE for machine learning projects, see <a href="https://cloud.google.com/storage/docs/gcsfuse-integrations#machine-learning" rel="nofollow">https://cloud.google.com/storage/docs/gcsfuse-integrations#machine-learning</a>.</p>
<h2 tabindex="-1" dir="auto">Limitations and key differences from POSIX file systems</h2>
<p dir="auto">To learn about limitations and differences between Cloud Storage FUSE and POSIX file systems, see <a href="https://cloud.google.com/storage/docs/gcs-fuse#differences-and-limitations" rel="nofollow">https://cloud.google.com/storage/docs/gcs-fuse#differences-and-limitations</a>.</p>
<h2 tabindex="-1" dir="auto">Pricing for Cloud Storage FUSE</h2>
<p dir="auto">For information about pricing for Cloud Storage FUSE, see <a href="https://cloud.google.com/storage/docs/gcs-fuse#charges" rel="nofollow">https://cloud.google.com/storage/docs/gcs-fuse#charges</a>.</p>
<h2 tabindex="-1" dir="auto">CSI Driver</h2>
<p dir="auto">Using the <a href="https://github.com/GoogleCloudPlatform/gcs-fuse-csi-driver">Cloud Storage FUSE CSI driver</a>, users get the declarative nature of Kubernetes
with all infrastructure fully managed by GKE in combination with Cloud Storage. This CSI
driver relies on Cloud Storage FUSE to mount Cloud storage buckets as file systems on the
GKE nodes, with the Cloud Storage FUSE deployment and management fully handled by GKE,
providing a turn-key experience.</p>
<h2 tabindex="-1" dir="auto">Support</h2>
<h2 tabindex="-1" dir="auto">Supported frameworks and operating systems</h2>
<p dir="auto">To find out which frameworks and operating systems are supported by Cloud Storage FUSE, see <a href="https://cloud.google.com/storage/docs/gcs-fuse#supported-frameworks-os" rel="nofollow">https://cloud.google.com/storage/docs/gcs-fuse#supported-frameworks-os</a>.</p>
<h2 tabindex="-1" dir="auto">Getting support</h2>
<p dir="auto">You can get support, submit general questions, and request new features by <a href="https://github.com/GoogleCloudPlatform/gcsfuse/issues">filing issues in GitHub</a>. You can also get support by using one of <a href="https://cloud.google.com/support-hub" rel="nofollow">Google Cloud's official support channels</a>.</p>
<p dir="auto">See <a href="https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/docs/troubleshooting.md">Troubleshooting</a> for common issue handling.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Remembering Doug Lenat (1950–2023) and His Quest to Capture the World with Logic (131 pts)]]></title>
            <link>https://writings.stephenwolfram.com/2023/09/remembering-doug-lenat-1950-2023-and-his-quest-to-capture-the-world-with-logic/</link>
            <guid>37402925</guid>
            <pubDate>Wed, 06 Sep 2023 09:23:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://writings.stephenwolfram.com/2023/09/remembering-doug-lenat-1950-2023-and-his-quest-to-capture-the-world-with-logic/">https://writings.stephenwolfram.com/2023/09/remembering-doug-lenat-1950-2023-and-his-quest-to-capture-the-world-with-logic/</a>, See on <a href="https://news.ycombinator.com/item?id=37402925">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h2 id="logic,-math-and-ai">Logic, Math and AI</h2>
<p>In many ways the great quest of <a href="https://www.wolframalpha.com/input?i=douglas+lenat">Doug Lenat</a>’s life was an attempt to follow on directly from the work of Aristotle and <a href="https://writings.stephenwolfram.com/2013/05/dropping-in-on-gottfried-leibniz/">Leibniz</a>. For what Doug was fundamentally trying to do over the forty years he spent developing his CYC system was to use the framework of logic—in more or less the same form that Aristotle and Leibniz had it—to capture what happens in the world. It was a noble effort and an impressive example of long-term intellectual tenacity. And while I never managed to actually use CYC myself, I consider it a magnificent experiment—that if nothing else ultimately served to demonstrate the importance of building frameworks beyond logic alone in usefully representing and reasoning about the world.<span id="more-53645"></span></p>
<p>Doug Lenat started working on artificial intelligence at a time when nobody really knew what might be possible—or even easy—to do. Was AI (whatever that might mean) just a clever algorithm—or a new type of computer—away? Or was it all just an “engineering problem” that simply required pulling together a bigger and better “expert system”? There was all sorts of mystery—and quite a lot of hocus pocus—around AI. Did the demo one was seeing actually prove something, or was it really just a trivial (if perhaps unwitting) cheat? </p>
<p>I first met Doug Lenat at the beginning of the 1980s. I had just <a href="https://writings.stephenwolfram.com/2013/06/there-was-a-time-before-mathematica/">developed my SMP (“Symbolic Manipulation Program”) system</a>, that was the forerunner of <a href="https://www.wolfram.com/mathematica/scrapbook/">Mathematica</a> and the modern <a href="https://www.wolfram.com/language/">Wolfram Language</a>. And I had been quite exposed to commercial efforts to “do AI” (and indeed our VCs had even pushed my first company to take on the dubious name “Inference Corporation”, complete with a “=&gt;” logo). And I have to say that when I first met Doug I was quite dismissive. He told me he had a program (that he called <a href="https://en.wikipedia.org/wiki/Automated_Mathematician" target="_blank" rel="noopener">“AM” for “Automated Mathematician”</a>, and that had been the subject of his Stanford CS PhD thesis) that could discover—and in fact had discovered—nontrivial mathematical theorems. </p>
<p>“What theorems?” I asked. “What did you put in? What did you get out?” I suppose to many people the concept of searching for theorems would have seemed like something remarkable, and immediately exciting. But not only had I myself just built a system for systematically representing mathematics in computational form, I had also been <a href="https://www.wolframscience.com/nks/chap-1--the-foundations-for-a-new-kind-of-science#sect-1-4--the-personal-story-of-the-science-in-this-book">enumerating large collections of simple programs</a> like cellular automata. I poked at what Doug said he’d done, and came away unconvinced. Right around the same time I happened to be visiting a leading university AI group, who told me they had a system for translating stories from Spanish into English. “Can I try it?” I asked, suspending for a moment my feeling that this sounded like science fiction. “I don’t really know Spanish”, I said, “Can I start with just a few words?” “No”, they said, “the system works only with stories.” “How long does a story have to be?” I asked. “Actually it has to be a particular kind of story”, they said. “What kind?” I asked. There were a few more iterations, but eventually it came out: the “system” translated one particular story from Spanish into English! I’m not sure if my response included an expletive, but I wondered what kind of science, technology, or anything else this was supposed to be. And when Doug told me about his “Automated Mathematician”, this was the kind of thing I was afraid I was going to find.</p>
<p>Years later, I might say, I think there’s something AM could have been trying to do that’s valid, and interesting, if not obviously possible. Given a particular axiom system it’s easy to mechanically generate infinite collections of “true theorems”—that in effect <a href="https://www.wolframscience.com/metamathematics/">fill metamathematical space</a>. But now the question is: which of these theorems will <a href="https://writings.stephenwolfram.com/2018/11/logic-explainability-and-the-future-of-understanding/">human mathematicians find “interesting”</a>? It’s not clear how much of the answer has to do with the “social history of mathematics”, and how much is more about “abstract principles”. I’ve been <a href="https://www.wolframscience.com/metamathematics/empirical-metamathematics/">studying this quite a bit in recent years</a> (not least because I think it could be useful in practice)—and have some rather deep conclusions about its relation to the nature of mathematics. But I now do wonder to what extent Doug’s work from all those years ago might (or might not) contain heuristics that would be worth trying to pursue even now.</p>
<h2 id="cyc">CYC</h2>
<p>I ran into Doug quite a few times in the early to mid-1980s, both around a company called <a href="https://writings.stephenwolfram.com/2016/04/my-life-in-technology-as-told-at-the-computer-history-museum/">Thinking Machines</a> (to which I was a consultant) and at various events that somehow touched on AI. There was a fairly small and somewhat fragmented AI community in those days, with the academic part in the US concentrated around MIT, Stanford and CMU. I had the impression that Doug was never quite at the center of that community, but was somehow nevertheless a “notable member”, who—particularly with his work being connected to math—was seen as “doing upscale things” around AI. </p>
<p>In 1984 I wrote an article for a special issue of <em>Scientific American</em> on “computer software” (yes, software was trendy then). My article was entitled “<a href="https://content.wolfram.com/uploads/sites/34/2020/07/computer-software-science-mathematics.pdf" target="_blank" rel="noopener">Computer Software in Science and Mathematics</a>”, and the very next article was by Doug, entitled “Computer Software for Intelligent Systems”. The summary at the top of my article read: “Computation offers a new means of describing and investigating scientific and mathematical systems. Simulation by computer may be the only way to predict how certain complicated systems evolve.” And the summary for Doug’s article read: “The key to intelligent problem solving lies in reducing the random search for solutions. To do so intelligent computer programs must tap the same underlying ‘sources of power’ as human beings”. And I suppose in many ways both of us spent most of our next four decades essentially trying to fill out the promise of these summaries.</p>
<p>A key point in Doug’s article—with which I wholeheartedly agree—is that to create something one can usefully identify as “AI”, it’s essential to somehow have lots of knowledge of the world built in. But how should that be done? How should the knowledge be encoded? And how should it be used?</p>
<p>Doug’s article in <em>Scientific American</em> illustrated his basic idea:</p>
<p><a alt="" title="" href="https://content.wolfram.com/uploads/sites/43/2023/09/SA-v2.png"><img loading="lazy" src="https://content.wolfram.com/uploads/sites/43/2023/09/SA-v2.png" alt="Click to enlarge" title="Click to enlarge" width="616" height=""></a></p>
<p>Encode knowledge about the world in the form of statements of logic. Then find ways to piece together these statements to derive conclusions. It was, in a sense, a very classic approach to formalizing the world—and one that would at least in concept be familiar to Aristotle and <a href="https://writings.stephenwolfram.com/2013/05/dropping-in-on-gottfried-leibniz/">Leibniz</a>. Of course it was now using computers—both as a way to store the logical statements, and as a way to find inferences from them.</p>
<p>At first, I think Doug felt the main problem was how to “search for correct inferences”. Given a whole collection of logical statements, he was asking how these could be knitted together to answer some particular question. In essence it was just like <a href="https://www.wolframscience.com/metamathematics/relations-to-automated-theorem-proving/">mathematical theorem proving</a>: how could one knit together axioms to make a proof of a particular theorem? And especially with the computers and algorithms of the time, this seemed like a daunting problem in almost any realistic case. </p>
<p>But then how did humans ever manage to do it? What Doug imagined was that the critical element was heuristics: strategies for guessing how one might “jump ahead” and not have to do the kind of painstaking searches that systematic methods seemed to imply would be needed. Doug developed a system he called <a href="https://en.wikipedia.org/wiki/Eurisko" target="_blank" rel="noopener">EURISKO</a> that implemented a range of heuristics—that Doug expected could be used not only for math, but basically for anything, or at least anything where human-like thinking was effective. And, yes, EURISKO included not only heuristics, but also at least some kinds of heuristics for making new heuristics, etc.</p>
<p>But OK, so Doug imagined that EURISKO could be used to “reason about” anything. So if it had the kind of knowledge humans do, then—Doug believed—it should be able to reason just like humans. In other words, it should be able to deliver some kind of “genuine artificial intelligence” capable of matching human thinking. </p>
<p>There were all sorts of specific domains of knowledge to consider. But Doug particularly wanted to push in what seemed like the most broadly impactful direction—and tackle the problem of commonsense knowledge and commonsense reasoning. And so it was that Doug began what would become a lifelong project to encode as much knowledge as possible in the form of statements of logic.</p>
<p>In 1984 Doug’s project—now named CYC—became a flagship part of <a href="https://en.wikipedia.org/wiki/Microelectronics_and_Computer_Technology_Corporation" target="_blank" rel="noopener">MCC (Microelectronics and Computer Technology Corporation)</a> in Austin, TX—an industry-government consortium that had just been created to counter the perceived threat from the <a href="https://en.wikipedia.org/wiki/Fifth_Generation_Computer_Systems" target="_blank" rel="noopener">Japanese “Fifth Generation Computer Project”</a>, that had shocked the US research establishment by putting immense resources into “solving AI” (and was actually emphasizing many of the same underlying rule-based techniques as Doug). And at MCC Doug had the resources to hire scores of people to embark on what was expected to be a few thousand person-years of effort.</p>
<p>I didn’t hear much about CYC for quite a while, though shortly after Mathematica was released in 1988 <a href="https://writings.stephenwolfram.com/2016/01/farewell-marvin-minsky-19272016/">Marvin Minsky</a> mused to me about how it seemed like we were doing for math-like knowledge what CYC was hoping to do for commonsense knowledge. I think Marvin wasn’t convinced that Doug had the technical parts of CYC right (and, yes, they weren’t using Marvin’s theories as much as they might). But in those years Marvin seemed to feel that CYC was one of the few AI projects going on that actually made any sense. And indeed in my archives I find a rather charming email from Marvin in 1992, attaching a draft of a <a href="https://www.amazon.com/Turing-Option-Questar-Science-Fiction/dp/0446364967" target="_blank" rel="noopener">science fiction novel (entitled </a><em><a href="https://www.amazon.com/Turing-Option-Questar-Science-Fiction/dp/0446364967" target="_blank" rel="noopener">The Turing Option</a></em><a href="https://www.amazon.com/Turing-Option-Questar-Science-Fiction/dp/0446364967" target="_blank" rel="noopener">)</a> that he was writing with <a href="https://www.wolframalpha.com/input?i=harry+harrison">Harry Harrison</a>, which contained mention of CYC:</p>
<blockquote>
<p><em>June 19, 2024</em></p></blockquote>
<blockquote>
<p>When Brian and Ben reached the lab, the computer was running<br>
but the tree-robot was folded and motionless. “Robin,<br>
activate.”</p></blockquote>
<blockquote>
<p>…</p></blockquote>
<blockquote>
<p>“Robin will have to use different concepts of progress for<br>
different kinds of problems. And different kinds of subgoals<br>
for reducing those different kinds of differences.”</p></blockquote>
<blockquote>
<p>“Won’t that require enormous amounts of knowledge?”</p></blockquote>
<blockquote>
<p>“It will indeed—and that’s one reason human education takes<br>
so long. But Robin should already contain a massive amount of<br>
just that kind of information—as part of his CYC-9 knowledge-<br>
base.”</p></blockquote>
<blockquote>
<p>…</p></blockquote>
<blockquote>
<p><span>“There now exists a procedural model for the behavior of a<br>
human individual, based on the prototype human described in<br>
section 6.001 of the CYC-9 knowledge base. Now customizing<br>
parameters on the basis of the example person Brian Delaney<br>
described in the employment, health, and security records of<br>
Megalobe Corporation.”</span></p></blockquote>
<blockquote>
<p>A brief silence ensued. Then the voice continued.</p></blockquote>
<blockquote>
<p><span>“The Delaney model is judged as incomplete as compared to those<br>
of other persons such as President Abraham Lincoln, who has<br>
3596.6 megabytes of descriptive text, or Commander James<br>
Bond, who has 16.9 megabytes.”</span></p></blockquote>
<p>Later, one of the novel’s characters observes: “Even if we started with nothing but the<br>
old Lenat–Haase representation-languages, we’d still be far ahead of what any animal ever evolved.” (<a href="http://www.khaase.com/aboutkh.html" target="_blank" rel="noopener">Ken Haase</a> was a student of Marvin’s who critiqued and extended Doug’s work on heuristics.) </p>
<p>I was exposed to CYC again in 1996 in connection with a book called <em><a href="https://www.amazon.com/HALs-Legacy-2001s-Computer-Reality/dp/0262193787/" target="_blank" rel="noopener">HAL’s Legacy</a></em>—to which both Doug and <a href="https://www.stephenwolfram.com/media/computers-science-extraterrestrials-interview-stephen-wolfram/">I contributed</a>—published in honor of the fictional birthday of the AI <a href="https://writings.stephenwolfram.com/2018/04/learning-about-the-future-from-2001-a-space-odyssey-fifty-years-later/">in the movie <em>2001</em></a>. But mostly AI as a whole was in the doldrums, and almost nobody seemed to be taking it seriously. Sometimes I would hear murmurs about CYC, mostly from government and military contacts. Among academics, Doug would occasionally come up, but rather cruelly he was most notable for his name being used for a <a href="https://en.wikipedia.org/wiki/List_of_humorous_units_of_measurement" target="_blank" rel="noopener">unit of “bogosity”</a>—the lenat—of which it was said that “Like the farad it is considered far too large a unit for practical use, so bogosity is usually expressed in microlenats”.</p>
<h2 id="doug-meets-wolfram|alpha">Doug Meets Wolfram|Alpha</h2>
<p>Many years passed. I certainly hadn’t forgotten Doug, or CYC. And a few times people suggested connecting CYC in some way to our technology. But nothing ever happened. Then in the spring of 2009 we were nearing the first release of <a href="https://www.wolframalpha.com/">Wolfram|Alpha</a>, and it seemed like I finally had something that I might meaningfully be able to talk to Doug about. </p>
<p>I sent a rather tentative email:<br>
</p>
<div>
<div>
<p><span>Subject:</span> something you might find interesting…</p>
<p><span>Date:</span> Thu, 05 Mar 2009 11:15:04 -0500</p>
<p><span>From:</span> Stephen Wolfram</p>
<p><span>To:</span> Doug Lenat</p>
</div>

<div><p>
We’re in the final stages of a rather large project that I think relates to<br>
some of your interests.</p>
<p>I just made a small blog post about it: </p>
<p <pre="">http://blog.wolfram.com/2009/03/05/wolframalpha-is-coming/
</p>
<p>I’d be pleased to give you a webconference demo if you’re interested.</p>
<p>I hope you’ve been well all these years.</p>
<p>— Stephen</p></div>
</div>

<p>Doug quickly responded:<br>
</p>
<div>
<div>
<p><span>Subject:</span> Re: something you might find interesting…</p>
<p><span>Date:</span> Thu, 5 Mar 2009 13:23:31 -0600</p>
<p><span>From:</span> Doug Lenat</p>
<p><span>To:</span> Stephen Wolfram</p>
</div>

<div><p>
Hi, Stephen.</p>
<p>You have become a master of understatement! This certainly<br>
does relate to the 1000 person-years we’ve spent building Cyc’s ontology,<br>
knowledge base, and inference engines, over the last 25 years. I’d very<br>
much like to see a webconference demo, so we identify the opportunities for<br>
synergy.</p>
<p>Regards<br>
Doug</p></div>
</div>

<p>It was definitely a “you’re on my turf” kind of response. And I wasn’t sure what to expect from Doug. But a few days later we had a long call with Doug and some of the senior members of what was now the Cycorp team. And Doug did something that deeply impressed me. Rather than for example nitpicking that Wolfram|Alpha was “not AI” he basically just said “We’ve been trying to do something like this for years, and now you’ve succeeded”. It was a great—and even inspirational—show of intellectual integrity. And whatever I might think of CYC and Doug’s other work (and I’d never formed a terribly clear opinion), this for me put Doug firmly in the category of people to respect.</p>
<p>Doug wrote a blog post entitled “<a href="https://www.dataversity.net/doug-lenat-i-was-positively-impressed-with-wolfram-alpha/" target="_blank" rel="noopener">I was positively impressed with Wolfram Alpha</a>”, and immediately started inviting us to various AI and industry-pooh-bah events to which he was connected. </p>
<p>Doug seemed genuinely pleased that we had made such progress in something so close to his longtime objectives. I talked to him about the comparison between our approaches. He was just working with “pure human-like reasoning”, I said, like one would have had to do in the Middle Ages. But, I said, “In a sense we cheated”. Because we used all the things that got invented in modern times in science and math and so on. If he wanted to work out how some mechanical system would behave, he would have to reason through it: “If you push this down, that pulls up, then this rolls”, etc. But with what we’re doing, we just have to turn everything into math (or something like it), then systematically solve it using equations and so on. </p>
<p>And there was something else too: we weren’t trying to use just logic to represent the world, we were using the full power and richness of computation. In talking about the Solar System, we didn’t just say that “Mars is a planet contained in the Solar System”; we had an algorithm for computing its detailed motion, and so on. </p>
<p>Doug and CYC had also emphasized the scraps of knowledge that seem to appear in our “common sense”. But we were interested in systematic, computable knowledge. We didn’t just want a few scattered “common facts” about animals. We wanted systematic tables of <a href="https://reference.wolfram.com/language/ref/entity/Species.html">properties of millions of species</a>. And we had very general computational ways to represent things: not just words or tags for things, but systematic ways to capture computational structures, whether they were entities, graphs, formulas, images, time series, or geometrical forms, or whatever. </p>
<p>I think Doug viewed CYC as some kind of formalized idealization of how he imagined human minds work: providing a framework into which a large collection of (fairly undifferentiated) knowledge about the world could be “poured”. At some level it was a very “pure AI” concept: set up a generic brain-like thing, then “it’ll just do the rest”. But Doug still felt that the thing had to operate according to logic, and that what was fed into it also had to consist of knowledge packaged up in the form of logic.</p>
<p>But while Doug’s starting points were AI and logic, mine were something different—in effect computation writ large. I always viewed logic as something not terribly special: a particular formal system that described certain kinds of things, but didn’t have any great generality. To me the truly general concept was computation. And that’s what I’ve always used as my foundation. And it’s what’s now led to the modern Wolfram Language, with its character as a <a href="https://writings.stephenwolfram.com/2019/05/what-weve-built-is-a-computational-language-and-thats-very-important/">full-scale computational language</a>. </p>
<p>There is a principled foundation. But it’s not logic. It’s something much more general, and structural: arbitrary symbolic expressions and transformations of them. And I’ve spent much of the past forty years building up coherent computational representations of the whole range of concepts and constructs that we encounter in the world and in our thinking about it. The goal is to have a language—in effect, a notation—that can represent things in a precise, computational way. But then to actually have the built-in capability to compute with that representation. Not to figure out how to string together logical statements, but rather to do whatever computation might need to be done to get an answer. </p>
<p>But beyond their technical visions and architectures, there is a certain parallelism between CYC and the Wolfram Language. Both have been huge projects. Both have been in development for more than forty years. And both have been led by a single person all that time. Yes, the Wolfram Language is certainly the larger of the two. But in the spectrum of technical projects, CYC is still a highly exceptional example of longevity and persistence of vision—and a truly impressive achievement.</p>
<h2 id="later-years">Later Years</h2>
<p>After Wolfram|Alpha came on the scene I started interacting more with Doug, not least because I often <a href="https://writings.stephenwolfram.com/2013/03/talking-about-the-computational-future-at-sxsw-2013/">came to the SXSW conference in Austin</a>, and would usually make a point of reaching out to Doug when I did. Could CYC use Wolfram|Alpha and the Wolfram Language? Could we somehow usefully connect our technology to CYC?</p>
<p>When I talked to Doug he tended to downplay the commonsense aspects of CYC, instead talking about defense, intelligence analysis, healthcare, etc. applications. He’d enthusiastically tell me about particular kinds of knowledge that had been put into CYC. But time and time again I’d have to tell him that actually we already had systematic data and algorithms in those areas. Often I felt a bit bad about it. It was as if he’d been painstakingly planting crops one by one, and we’d come through with a giant industrial machine. </p>
<p>In 2010 we made a big “<a href="https://www.wolframalpha.com/docs/timeline">Timeline of Systematic Data and the Development of Computable Knowledge</a>” poster—and CYC was on it as one of the six entries that began in the 1980s (alongside, for example, the web). Doug and I continued to talk about somehow working together, but nothing ever happened. One problem was the asymmetry: Doug could play with Wolfram|Alpha and Wolfram Language any time. But I’d never once actually been able to try CYC. Several times Doug had promised API keys, but none had ever materialized.</p>
<p>Eventually Doug said to me: “Look, I’m worried you’re going to think it’s bogus”. And particularly knowing Doug’s history with alleged “bogosity” I tried to assure him my goal wasn’t to judge. Or, as I put it in a 2014 email: “Please don’t worry that we’ll think it’s ‘bogus’. I’m interested in finding the good stuff in what you’ve done, not criticizing its flaws.”</p>
<p>But when I was at SXSW the next year Doug had something else he wanted to show me. It was a math education game. And Doug seemed incredibly excited about its videogame setup, complete with 3D spacecraft scenery. My son Christopher was there and politely asked if this was the default Unity scenery. I kept on saying, “Doug, I’ve seen videogames before; show me the AI!” But Doug didn’t seem interested in that anymore, eventually saying that the game wasn’t using CYC—though did still (somewhat) use “rule-based AI”.</p>
<p>I’d already been talking to Doug, though, about what I saw as being an obvious, powerful application of CYC in the context of Wolfram|Alpha: solving math word problems. Given a problem, say, in the form of equations, we could solve pretty much anything thrown at us. But with a word problem like “If Mary has 7 marbles and 3 fall down a drain, how many does she now have?” we didn’t stand a chance. Because to solve this requires commonsense knowledge of the world, which isn’t what Wolfram|Alpha is about. But it is what CYC is supposed to be about. Sadly, though, despite many reminders, we never got to try this out. (And, yes, we built various simple linguistic templates for this kind of thing into Wolfram|Alpha, and <a href="https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/#cracking-some-old-chestnuts">now there are LLMs</a>.)</p>
<p>Independent of anything else, it was impressive that Doug had kept CYC and Cycorp running all those years. But when I saw him in 2015 he was enthusiastically telling me about what I told him seemed to me to be a too-good-to-be-true deal he was making around CYC. A little later there was a strange attempt to sell us the technology of CYC, and I don’t think our teams interacted again after that. </p>
<p>I personally continued to interact with Doug, though. I sent him things I <a href="https://writings.stephenwolfram.com/2014/08/computational-knowledge-and-the-future-of-pure-mathematics/">wrote about the formalization of math</a>. He responded pointing me to <a href="https://www.ijcai.org/Proceedings/77-2/Papers/099.pdf" target="_blank" rel="noopener">things he’d done on AM</a>. On the <a href="https://writings.stephenwolfram.com/2019/05/wolframalpha-at-10/">tenth anniversary of Wolfram|Alpha</a> Doug sent me a nice note, offering that “If you want to team up on, e.g., knocking the Winograd sentence pairs out of the park, let me know.” I have to say I wondered what a “Winograd sentence pair” was. It felt like some kind of challenge from an age of AI long past (apparently it has to do with identifying pronoun reference, which of course has become even more difficult in modern English usage). </p>
<p>And as I write this today, I realize a mistake I made back in 2016. I had for years been thinking about what I’ve come to call “symbolic discourse language”—an extension of computational language that can represent “everyday discourse”. And—stimulated by blockchain and the idea of computational contracts—I finally <a href="https://writings.stephenwolfram.com/2016/10/computational-law-symbolic-discourse-and-the-ai-constitution/">wrote something about this in 2016</a>, and I now realize that I overlooked sending Doug a link to it. Which is a shame, because maybe it would have finally been the thing that got us to connect our systems.</p>
<h2 id="and-now-there-are-llms">And Now There Are LLMs</h2>
<p>Doug was a person who believed in formalism, particularly logic. And I have the impression that he always considered approaches like neural nets not really to have a chance of “solving the problem of AI”. But <a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/">now we have LLMs</a>. So how do they fit in with things like the ideas of CYC? </p>
<p>One of the surprises of LLMs is that they often seem, in effect, to use logic, even though there’s nothing in their setup that explicitly involves logic. But (as I’ve <a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/#semantic-grammar-and-the-power-of-computational-language">described elsewhere</a>) I’m pretty sure what’s happened is that LLMs have “discovered” logic much as Aristotle did—by looking at lots of examples of statements people make and identifying patterns in them. And in a similar way LLMs have “discovered” lots of commonsense knowledge, and reasoning. They’re just following patterns they’ve seen, but—probably in effect organized into what I’ve called a “<a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/#semantic-grammar-and-the-power-of-computational-language">semantic grammar</a>” that determines “<a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/#meaning-space-and-semantic-laws-of-motion">laws of semantic motion</a>”—that’s enough to often achieve some fairly impressive commonsense-like results. </p>
<p>I suspect that a great many of the statements that were fed into CYC could now be generated fairly successfully with LLMs. And perhaps one day there’ll be good enough “LLM science” to be able to identify mechanisms behind what LLMs can do in the commonsense arena—and maybe they’ll even look a bit like what’s in CYC, and how it uses logic. But in a sense the very success of LLMs in the commonsense arena strongly suggests that you don’t fundamentally need deep “structured logic” for that. Though, yes, the LLM may be immensely less efficient—and perhaps less reliable—than a direct symbolic approach.</p>
<p>It’s a very different story, by the way, with computational language and computation. LLMs are through and through based on language and patterns to be found through it. But computation—as it can be accessed through structured computational language—is something very different. It’s about processes that are in a sense thoroughly non-human, and that involve much deeper following of general formal rules, as well as much more structured kinds of data, etc. An LLM might be able to do basic logic, as humans have. But it doesn’t stand a chance on things where humans have had to systematically use formal tools that do serious computation. Insofar as LLMs represent “statistical AI”, CYC represents a certain level of “symbolic AI”. But computational language and computation go much further—to a place where LLMs can’t and shouldn’t follow, and should <a href="https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/">just call them as tools</a>. </p>
<p>Doug always seemed to have a very optimistic view of the promise of AI. In 2013 he wrote to me:<br>
</p>
<div><p>Of course you are coming at this from the opposite end of the Chunnel than<br>
we are, but you’re proceeding, frankly, much more rapidly toward us than we<br>
are toward you. I probably appreciate the significance of what you’ve<br>
accomplished more than almost anyone else: when your and our approaches do<br>
meet up, the combination will be the existence of real AI on Earth. I<br>
think that’s the main motivation in your life, as it is in mine: to live to<br>
see real AI, with the obvious sweeping change in all aspects of life when<br>
there is (i) cradle-to-grave 24×7 Aristotle mentoring and advising for<br>
every human being and, in effect, (ii) a Land of Faerie intelligence<br>
effectively present [e.g., that one can converse with] in every door, floor<br>
tile,…every tangible object above a certain microscopic size.) And to<br>
live to see and be users ourselves in an era of massively amplified human<br>
intelligence …</p>
</div>

<p>The last mail I received from Doug was on January 10, 2023—telling me that he thought it was great that I was <a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/">talking about connecting our tech to ChatGPT</a>. He said, though, that he found it “increasingly worrisome that these models train on CONVINCINGNESS rather than CORRECTNESS”, then gave an example of ChatGPT getting a math word problem wrong.<br>
His email ended:<br>
</p>
<div><p>Yes, let’s chat again at your convenience… it bothers both of us, I<br>
believe, that our systems aren’t leveraging each other! That just bothers<br>
me more and more as I get old (not just older).</p>
</div>

<p>Sadly we never did chat again. We now have a team actively working on symbolic discourse language, and just last week I mentioned CYC to them—and lamented that I’d never been able to try it. And then on Friday I heard that Doug had died. A remarkable pioneer of AI who steadfastly pursued his vision over the whole course of his career, and was taken far too soon.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Chrome pushes browser history-based ad targeting (235 pts)]]></title>
            <link>https://www.theregister.com/2023/09/06/google_privacy_popup_chrome/</link>
            <guid>37401909</guid>
            <pubDate>Wed, 06 Sep 2023 06:31:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/09/06/google_privacy_popup_chrome/">https://www.theregister.com/2023/09/06/google_privacy_popup_chrome/</a>, See on <a href="https://news.ycombinator.com/item?id=37401909">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Google has been gradually rolling out Chrome's "Enhanced Ad Privacy." That's the technology that, unless switched off, allows websites to target the user with adverts tuned to their online activities and interests based on their browser histories.</p>
<p>A popup announcing this functionality has been appearing for some folks since the July release of Chrome 115, which <a target="_blank" href="https://www.theregister.com/2023/06/27/google_tweaks_topics_api_ahead/">included support</a> for Google's Topics API, which is part of the tech titan's <a target="_blank" href="https://www.theregister.com/2023/05/20/google_privacy_sandbox_july/">Privacy Sandbox project</a>.</p>
<p>It would appear more and more people are now seeing this popup as those not keen on Chrome mining their browsing histories to support Google's advertising profits have been speaking up. We understand a small percentage of Chrome's users are being pulled into the Topics API regime at a time, so you may not have noticed or been offered or alerted to anything. And how the Chocolate Factory asks you to agree to or accept the ad targeting depends on where you live, or rather, the laws of where you live.</p>

    

<p>Google next year aims to drop support for third-party cookies, which store browser data that ad companies use for tracking and analytics – to the frequent detriment of user privacy. The US mega-corp has developed a variety of replacement technologies, such as the <a target="_blank" rel="nofollow" href="https://developer.chrome.com/docs/privacy-sandbox/topics/">Topics API</a> that will allow ad targeting to continue without cookie-based tracking and – it's claimed – no privacy consequences.</p>

        


        

<p>Topics essentially works like this: rather than using cookies to track people around the web and figure out their interests from the sites they visit and the apps they use, websites can ask Chrome directly, via its Topics JavaScript API, what sort of things the user is interested in, and then display ads based on that. Chrome picks these topics of interest from studying the user's browser history.</p>
<p>So if you visit lots of financial websites, one of your Chrome-selected topics may be "investing." If a site you visit queries the Topics API, it may learn of this interest from Chrome and decide to serve you an advert about bonds or retirement funds. It also means websites can fetch your online interests straight from your browser.</p>

        

<p>Some people presented with the notification of the new regime complain it's a dark pattern –&nbsp;a term Googlers consider unfairly provocative – as Chrome users may think they're accepting or enabling "enhanced" privacy from ads when in actual fact the Topics API is already enabled, and will remain enabled, and has to be disabled in the browser's settings. That is to say: the popup is a notice that you've been opted in with a little link to your settings to disable the tech if you so wish.</p>
<div><p><a href="https://regmedia.co.uk/2023/09/06/screenshot_chrome_ad_privacy.jpg" target="_blank"><img src="https://regmedia.co.uk/2023/09/06/screenshot_chrome_ad_privacy.jpg?x=648&amp;y=698&amp;infer_y=1" alt="Screenshot of Chrome's ad privacy popup" title="Screenshot of Chrome's ad privacy popup" height="698" width="648"></a></p><p>Screenshot of a 'Got It' variant of Chrome's 'enhanced' ad privacy popup ... Click to enlarge</p>
</div>
<p>Will Dormann, a software vulnerability analyst with the Carnegie Mellon Software Engineering Institute's CERT Coordination Center, <a target="_blank" rel="nofollow" href="https://twitter.com/wdormann/status/1695843146842664997">noted</a> last week that Google's popup provides a default "Got It" button that dismisses the popup pane and does "the exact opposite of what the title text describes" – it leaves Chrome's ad targeting based on browsing history active.</p>
<p>It's worth noting that this popup does explicitly say, "you can make changes in Chrome settings," and that you can switch off the Topics API support using those linked controls. It otherwise doesn't change the status quo. Where third-party cookies were previously used to deliver targeted ads, Chrome users also had to take steps to disable them.</p>
<p>Nonetheless, there's more push back now against the norms preferred by Google and other ad industry firms.</p>
<p>Matthew Green, a cryptography professor at Johns Hopkins University in the US, just encountered the popup and <a target="_blank" rel="nofollow" href="https://twitter.com/matthew_d_green/status/1698813531062185996">expressed his dismay</a>.</p>
<blockquote>

<p>I definitely don’t want my browser sharing any function of my browsing history with every random website I visit</p>
</blockquote>
<p>"I don’t want my browser keeping track of my browsing history to help serve me ads, and I definitely don’t want my browser sharing any function of my browsing history with every random website I visit," he said <a target="_blank" rel="nofollow" href="https://twitter.com/matthew_d_green/status/1699020653196661144?s=20">via Twitter</a>.</p>
<p>And VC Paul Graham has derided ad targeting tech <a target="_blank" rel="nofollow" href="https://twitter.com/paulg/status/1699021936573940154?s=20">as spyware</a>.</p>

        

<p>Google has offered repeated reassurances that its <a target="_blank" rel="nofollow" href="https://github.com/patcg-individual-drafts/topics">Topics API</a> does not allow companies to identify those whose interests inform its ad API. But some developers <a target="_blank" rel="nofollow" href="https://github.com/patcg-individual-drafts/topics/issues/74">claim</a> Topics may be useful for browser fingerprinting and both <a target="_blank" rel="nofollow" href="https://github.com/WebKit/standards-positions/issues/111#issuecomment-1359609317">Apple</a> and <a target="_blank" rel="nofollow" href="https://github.com/mozilla/standards-positions/issues/622">Mozilla</a> have said they won't adopt Topics due to privacy concerns.</p>
<p>Google's popup appears to have regional variations that make the call to action and the button labels clearer and more consistent. One version that's been <a target="_blank" rel="nofollow" href="https://twitter.com/supersat/status/1698826450567323754">reported</a> is titled "Turn on an ad privacy feature" and there's a button that says, "Turn it on."</p>
<ul>

<li><a href="https://www.theregister.com/2023/05/20/google_privacy_sandbox_july/">Privacy Sandbox, Google's answer to third-party cookies, promised within months</a></li>

<li><a href="https://www.theregister.com/2023/02/01/google_cookie_sandbox/">Google ready to kick the cookie habit by Q3 2024, for real this time</a></li>

<li><a href="https://www.theregister.com/2023/06/27/google_tweaks_topics_api_ahead/">Google asks websites to kindly not break its shiny new targeted-advertising API</a></li>

<li><a href="https://www.theregister.com/2023/08/11/chrome_extension_developer_pressure/">Maker of Chrome extension with 300,000+ users tells of constant pressure to sell out</a></li>
</ul>
<p>Unlike the highlighted "Got It" button cited by Dormann and its unadorned "Settings" companion that defers any decision until the linked menu is loaded, "Turn it on" in this variant menu is the same color as the "No thanks" alternative and performs the action suggested by the popup title.</p>
<p>This variation reflects different legal regimes. Unlike America, where opt-out is acceptable and opt-in requirements are broadly opposed by marketers, EU data privacy rules are more demanding in the way data choices are presented.</p>
<p>So if you see a pop-up with "Got It," you've probably been opted-in, based on where you are, and you need to turn off the Topics API support in your Chrome settings if you don't like it; and if you have the option to "Turn it on," you're being asked to opt in or out as you're in a region that requires it.</p>
<p>Depending on what Chrome version you're using, and whether you've been selected to start using Topics API, you can switch this functionality off and on by visiting <code>chrome://settings/adPrivacy</code> and/or <code>chrome://settings/privacySandbox</code> – cut'n'paste these URLs into your address bar to jump straight to the controls.</p>
<div><p><a href="https://regmedia.co.uk/2023/09/06/screenshot_ad_topics_controls.jpg" target="_blank"><img src="https://regmedia.co.uk/2023/09/06/screenshot_ad_topics_controls.jpg?x=648&amp;y=293&amp;infer_y=1" alt="Screenshot of Google Chrome's Topics API settings" title="Screenshot of Google Chrome's Topics API settings" height="293" width="648"></a></p><p>Screenshot of Google Chrome's Topics API settings, via <code>chrome://settings/adPrivacy</code> though yours may be at <code>chrome://settings/privacySandbox</code> ... Click to enlarge</p>
</div>
<p>"Users in the UK, EEA, and Switzerland who have not already opted out of the Chrome trials will be presented with an invitation to participate in Topics, and manage their participation in Measurement and Protected Audience (formerly FLEDGE)," Google explained to <em>The Register</em>.</p>
<p>"All users will have robust controls, and can make individual choices, per API, at any point. Chrome will continue to evolve the user controls carefully and in consultation with regulators, and will have more to share once they've evaluated this initial rollout to a small percentage of users. All users will have robust controls, and can opt out of eligibility for the trials at any point." ®</p>
<div>
<h3>Droidnote</h3>

<p>Meanwhile, Android 14, which is set to be released later this month, is separating <a target="_blank" rel="nofollow" href="https://wiki.mozilla.org/CA">CA certificates</a> from the operating system image so they can be updated remotely without an OS update.</p>

<p>As noted by Tim Perry, creator of the open source HTTP Toolkit, in a <a target="_blank" rel="nofollow" href="https://httptoolkit.com/blog/android-14-breaks-system-certificate-installation/">blog post</a>, while this is a worthwhile defense against untrustworthy Certificate Authorities, its design will make life more difficult for developers and security researchers.</p>

<p>"Unfortunately though, despite those sensible goals, the reality of the implementation has serious consequences: system CA certificates are no longer loaded from /system, and when using root access to either directly modify or mount over the new location on disk, all changes are ignored by all apps on the device," wrote Perry. "Uh oh."</p>

<p><em>The Register</em> asked Perry to elaborate and he explained that this doesn't mean much for alternative Android distributions like LineageOS and GrapheneOS because they can disable this feature if necessary.</p>

<p>"This will most seriously affect security &amp; privacy researchers and reverse engineers, who all need to be able to inspect traffic from third-party apps to fully understand the apps' behavior," he said. "[It] will also cause daily practical problems for the many Android developers &amp; testers who use HTTP debugging tools like HTTP Toolkit and others with their own applications. In the development case, it adds significant friction, but it's possible to work around this for your own single app with more complex setup work."</p>

<p>Perry said the change will be a huge problem for security researchers who will have to rely on alternative versions of Android that don't have this change and which may not behave in the same way. And many apps won't run in these alternative Android builds due to protections like Google's <a target="_blank" rel="nofollow" href="https://developer.android.com/google/play/integrity">Play Integrity API</a>.</p>

<p>Perry said that mobile devices have become increasingly locked down, and even on Linux, restrictions to tools like Flatpak and Snap are moving toward the sandbox model inspired by phones.</p>

<p>"The underlying reasons for locking down like this aren't bad – both desktop computers and mobile phones are huge targets for attackers, and this restriction and others like it will help to protect day to day users from serious risks," he said. "The issue though is that the needs of security and privacy researchers and developers are completely ignored. While it's important to protect devices by default, there need to be practical and officially supported mechanisms for advanced users who know what they're doing to override these protections."</p>
</div>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It’s Official: Cars Are the Worst Category We Have Ever Reviewed for Privacy (122 pts)]]></title>
            <link>https://foundation.mozilla.org/en/privacynotincluded/articles/its-official-cars-are-the-worst-product-category-we-have-ever-reviewed-for-privacy/</link>
            <guid>37401563</guid>
            <pubDate>Wed, 06 Sep 2023 05:16:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://foundation.mozilla.org/en/privacynotincluded/articles/its-official-cars-are-the-worst-product-category-we-have-ever-reviewed-for-privacy/">https://foundation.mozilla.org/en/privacynotincluded/articles/its-official-cars-are-the-worst-product-category-we-have-ever-reviewed-for-privacy/</a>, See on <a href="https://news.ycombinator.com/item?id=37401563">Hacker News</a></p>
Couldn't get https://foundation.mozilla.org/en/privacynotincluded/articles/its-official-cars-are-the-worst-product-category-we-have-ever-reviewed-for-privacy/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Molly Holzschlag has died (295 pts)]]></title>
            <link>https://www.tucsonsentinel.com/local/report/090523_molly_holzschlag/tucsons-molly-holzschlag-known-as-the-fairy-godmother-web-dead-60/</link>
            <guid>37401348</guid>
            <pubDate>Wed, 06 Sep 2023 04:29:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tucsonsentinel.com/local/report/090523_molly_holzschlag/tucsons-molly-holzschlag-known-as-the-fairy-godmother-web-dead-60/">https://www.tucsonsentinel.com/local/report/090523_molly_holzschlag/tucsons-molly-holzschlag-known-as-the-fairy-godmother-web-dead-60/</a>, See on <a href="https://news.ycombinator.com/item?id=37401348">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body-text">
<p>Molly Holzschlag, whose pioneering work in online design standards led to her being dubbed "the fairy godmother of the web," has died at age 60.</p><p>Holzschlag, a longtime Tucson resident, dealt with a series of illnesses over the past decade, including being diagnosed with aplastic anemia. She was found dead Tuesday at her home, family said.</p><p>She was a prolific author and regular speaker about the "open web," advocating for accessible and inclusive online design standards. Also known as "mollydotcom" after her eponymous site that was one of the first blogs, she wrote or co-wrote more than 30 books, and before falling ill she was frequently appearing on Internet conference stages around the world.</p><p>"Molly has changed the world several times over," said the organizers of a 2013 GoFundMe effort that raised more than $70,000 to support Holzschlag while she underwent chemotherapy. </p><p>Holzschlag, who reported on music for the Tucson Weekly in the 1990s, founded Open Web Camp, a Silicon Valley event that ran from 2009-2013, and was a leader of the Web Standards Project in the years before that. That group successfully pushed browser developers, including Microsoft, Opera and Netscape, to adopt web standards. More than once, she challenged Bill Gates face-to-face to fix problems with Internet Explorer.</p><p>She was an "invited expert" on the CSS Working Group of the World Wide Web Consortium, the body that determines the standards that run the Internet. She also served on the W3C HTML and GEO working groups.</p><p>She was steadfast in her insistence that the World Wide Web be usable by people who are differently abled, including sites being able to be parsed by screenreader technology for people with impaired vision.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[On the 10th anniversary of the Snowden revelations (247 pts)]]></title>
            <link>https://www.electrospaces.net/2023/06/on-10th-anniversary-of-snowden.html</link>
            <guid>37400526</guid>
            <pubDate>Wed, 06 Sep 2023 01:57:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.electrospaces.net/2023/06/on-10th-anniversary-of-snowden.html">https://www.electrospaces.net/2023/06/on-10th-anniversary-of-snowden.html</a>, See on <a href="https://news.ycombinator.com/item?id=37400526">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-4344820364338635502" itemprop="description articleBody">
<p><span size="2" color="gray">(Updated: July 4, 2023)</span></p>
<p>
To mark the 10-year anniversary of the start of the Snowden revelations I will look back at some of the most notable disclosures and how they developed, based upon the most recent books and the numerous blog posts I have written here. Still, it should be noted that this overview is not a complete coverage of this wide-ranging topic.</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiyhZ8oMTZBwed-5n7dMj4FYGxNBxrR8NfDPbzx9Te6eeni5ePQDuNKSVPKfGm1TYMJTToHO19ZFzFVvLPJrgJ_yXPPbT06cJrAE7Nr2F5B_NoWy7aHGgdxlD6xqDPf4yy19JIbBk2TfBVZPPoiojdk039bRHMtNCmkzUuznUDeE24c_tEwqEhFaFH7/s800/10yearsnowden-header.jpg" target="_blank"><img alt="" width="620" data-original-height="420" data-original-width="800" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiyhZ8oMTZBwed-5n7dMj4FYGxNBxrR8NfDPbzx9Te6eeni5ePQDuNKSVPKfGm1TYMJTToHO19ZFzFVvLPJrgJ_yXPPbT06cJrAE7Nr2F5B_NoWy7aHGgdxlD6xqDPf4yy19JIbBk2TfBVZPPoiojdk039bRHMtNCmkzUuznUDeE24c_tEwqEhFaFH7/s600/10yearsnowden-header.jpg"></a></p>








<p><span size="+2"><b>Books and archives</b></span></p><p>

Between June 2013 and May 2019, the Snowden revelations resulted in over 200 press reports and more than 1200 classified documents published in full or in part. Additionally, The Intercept published 2148 editions of the NSA's internal newsletter <a href="https://theintercept.com/snowden-sidtoday/" target="_blank">SIDtoday</a>. In total, that may be well over 5000 pages.</p><p>

A collection that allows a useful visual recognition of the documents was found on the private website <a href="https://web.archive.org/web/20230220194734/https://nsa.gov1.info/dni/2020/index.html" target="_blank">IC Off the Record</a>, while text searches are possible at the <a href="https://grid.glendon.yorku.ca/exhibits/show/welcome-to-the-snowden-digital" target="_blank">Snowden Archive</a> which is a collaboration between Canadian Journalists for Free Expression (CJFE) and the University of Toronto. A private collection of the documents is also available at <a href="https://github.com/iamcryptoki/snowden-archive" target="_blank">GitHub</a>.</p><p>

There are also at least 12 <a href="https://www.electrospaces.net/p/books.html#snowden">books about the Snowden revelations</a>. Glenn Greenwald's <i>No Place To Hide</i> from 2014 reads like a pamphlet against perceived mass surveillance. A much more factual overview can be found in <i>Der NSA Komplex</i>, which is also published in 2014 and written by two journalists from Der Spiegel, but unfortunately only available in German.</p><p>

Detailed insights into the political and legal background of the NSA's collection programs are provided in Timothy Edgar's <i>Beyond Snowden</i> from 2017, which is in contrast to Snowden's own memoir <i>Permanent Record</i> from 2019, which leaves more questions than answers.</p><p>

Finally, there's also the long-awaited book <i>Dark Mirror</i> by Washington Post journalist Barton Gellman, which was published in 2020 and offers some important new angles to the initial stories told by Snowden and Greenwald.</p>
<p><a href="https://blogger.googleusercontent.com/img/a/AVvXsEhhtqJPTdbbQy4xiU_ry0G6brToakH7JMt1iDp1_smof7c6BOkXQ17WfJKTCTbT8H9FiCny4qPwqaior9yBUbj0RuI_QiBH0fqdy8cHuKD7IocRbpLR9tpstHvsNxtThbA5kyEhJUJjMeOpqxFQP7OqMLkf2MndGaJFBVEuKdRcCUisXuIJEe47c0Eb=s800" imageanchor="1" target="_blank"><img src="https://blogger.googleusercontent.com/img/a/AVvXsEhhtqJPTdbbQy4xiU_ry0G6brToakH7JMt1iDp1_smof7c6BOkXQ17WfJKTCTbT8H9FiCny4qPwqaior9yBUbj0RuI_QiBH0fqdy8cHuKD7IocRbpLR9tpstHvsNxtThbA5kyEhJUJjMeOpqxFQP7OqMLkf2MndGaJFBVEuKdRcCUisXuIJEe47c0Eb=s800" width="500"></a></p>


<p><span size="+2"><b>Incentives</b></span></p><p>

Some people assume that Snowden is a spy who worked for Russian intelligence, but nowadays, requests for information come from transparency activists as well. Wikileaks' wiki-page titled <a href="https://web.archive.org/web/20090619014040/https://wikileaks.org/wiki/Draft:The_Most_Wanted_Leaks_of_2009" target="_blank">The Most Wanted Leaks of 2009</a> may have inspired Manning to search for information on SIPRNet and to download hundreds of thousands of military and diplomatic reports.</p><p>

Likewise, the incentive for Snowden may have come from the news program <a href="https://en.wikipedia.org/wiki/Democracy_Now!" target="_blank">Democracy Now!</a>, in which on April 20, 2012, former NSA crypto-mathematician Bill Binney, documentary filmmaker Laura Poitras and hacktivist Jacob Appelbaum were interviewed by Amy Goodman (a full transcript can be found <a href="https://www.bibliotecapleyades.net/sociopolitica/sociopol_nsa05.htm" target="_blank">here</a>).</p><p>

In the program, Binney claimed that after 9/11 "all the wraps came off for NSA, and they decided to eliminate the protections on U.S. citizens and collect on domestically". </p><p>

Appelbaum <a href="https://www.democracynow.org/2012/4/20/we_do_not_live_in_a?autostart=true" target="_blank">repeated</a> what he said at the <a href="https://en.wikipedia.org/wiki/Hackers_on_Planet_Earth" target="_blank">HOPE</a> conference in 2010: "I feel that people like Bill need to come forward to talk about what the U.S. government is doing, so that we can make informed choices as a democracy" - which is exactly what Snowden would do: leaking documents because "<i>the public</i> needs to <a href="https://youtu.be/0hLjuVyIIrs?t=300" target="_blank">decide</a> whether these programs and policies are right or wrong."</p><p>

Later that day, Binney and Appelbaum spoke at a "Surveillance Teach-In" in the Whitney Museum, where Appelbaum emphasized that disclosing secret information is also important for privacy and civil liberties organizations: because of a lack of hard evidence and concrete harm it was almost impossible for them to fight NSA surveillance in court.</p><div>
<iframe width="500" height="300" src="https://www.youtube.com/embed/s976iyaO39A" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
  <p><span size="2">
    Binney and Appelbaum at the Surveillance Teach-In on April 20, 2012<br>
  </span>
</p></div>
<p>

Just a month earlier, Snowden had started a <a href="https://www.electrospaces.net/2019/12/review-of-snowdens-book-permanent.html#sysadmin">new job</a> as a SharePoint systems administrator at the NSA's <a href="https://www.electrospaces.net/2019/06/the-nsas-regional-cryptologic-centers.html">regional cryptologic center</a> in the Kunia Tunnel complex in Hawaii. There, he began automating his tasks to free up time for something more interesting, which he describes in <i>Permanent Record</i>:</p><p>
"I want to emphasize this: my active searching out of NSA abuses began not with the copying of documents, but with the reading of them. My initial intention was just to confirm the suspicions that I'd first had back in 2009 in Tokyo. Three years later I was determined to find out if an American system of mass surveillance existed and, if it did, how it functioned." <a nohref="" title="Edward Snowden, Permanent Record, p. 214-215">*</a><br>
</p>
<p>
With this, Snowden basically admits that he isn't a whistleblower: he wasn't confronted with illegal activities or significant abuses and subsequently secured evidence of that, but acted the other way around, by first gathering as much information he could get and then look whether there was something incriminating in it.</p><p>

In his memoir, Snowden doesn't come up with concrete misconducts or other things that could have triggered his decision to hand the files over to journalists. He even omits almost all the disclosures made by the press, which makes that<i> Permanent Record</i> contains hardly anything that justifies his unprecedented data theft.</p><p><a href="https://1.bp.blogspot.com/-WJHs31cb8nw/Xcu8fWiZdJI/AAAAAAAAENY/DVGBGU0tU94MYT-y5TJtdWekkmJmbgc9wCLcBGAsYHQ/s1600/nsa-kunia-pict86.jpg" imageanchor="1" target="_blank"><img src="https://1.bp.blogspot.com/-WJHs31cb8nw/Xcu8fWiZdJI/AAAAAAAAENY/DVGBGU0tU94MYT-y5TJtdWekkmJmbgc9wCLcBGAsYHQ/s1600/nsa-kunia-pict86.jpg" width="500"></a><br>
<span size="2">
The tunnel entrance to the former Kunia Regional Security Operations Center<br>
in Hawaii, where Snowden worked from March 2012 to March 2013<br>
<span color="gray">(photo: NSA - click to enlarge)</span><br>
</span>
</p>

<p><span size="+2"><b>The documents</b></span></p><p>

The actual number of documents which Snowden eventually exfiltrated from the NSA has never been clarified. According to the 2016 <a href="https://fas.org/irp/congress/2016_rpt/hpsci-snowden.pdf" target="_blank">report</a> from the US House Intelligence Committee, Snowden removed more than 1.5 million documents from NSANet and the JWICS intelligence network.</p><p>

Glenn Greenwald repeatedly <a href="https://theintercept.com/2014/05/08/keith-alexander-unplugged-bushobama-matters/" target="_blank">said</a> that number was "pure fabrication" and he could probably agree with former NSA director Keith Alexander who in November 2013 estimated that Snowden had <a href="https://technical.ly/baltimore/2013/11/01/surveillance-necessary-hornets-nest-nsa-director-keith-alexander/" target="_blank">exposed</a> only between 50,000 and 200,000 documents.<a href="https://rumble.com/v2sgyx2-snowden-revelations-10-year-anniversary-glenn-greenwald-speaks-with-snowden.html" target="_blank" title="As of 10:55 Greenwald speaks about hundreds of thousands of documents">*</a></p><p>

According to Barton Gellman, Snowden provided him and Laura Poitras with an encrypted archive of documents called "Pandora" on May 21, 2013. This archive was 8 gigabytes and contained over 50,000 separate documents, all neatly organized in folders.<a nohref="" title="Barton Gellman, Dark Mirror, p. 22-27">*</a></p><p>

Poitras gave Greenwald a copy of the Pandora archive just before they boarded their flight to Hong Kong on June 1. There, Snowden <a href="https://archive.is/Evmoi" target="_blank">gave</a> Ewen MacAskill from The Guardian some 50,000 documents about GCHQ and handed over all the remaining files to Greenwald and Poitras, who are the <a href="https://www.rollingstone.com/culture/culture-news/snowden-and-greenwald-the-men-who-leaked-the-secrets-104970/" target="_blank">only ones</a> with a complete set. Other media outlets only got partial sets of documents.</p><p>

Greenwald's cache eventually ended up at <a href="https://en.wikipedia.org/wiki/The_Intercept" target="_blank">The Intercept</a>, the online news outlet he co-founded with Jeremy Scahill and Laura Poitras in 2014 to report about the Snowden documents. In March 2019, however, The Intercept closed its Snowden archive and <a href="https://mmm.verdi.de/beruf/snowden-und-die-grosse-datenmisshandlung-89797" target="_blank">reportedly</a> destroyed it. </p>
<p><a href="https://2.bp.blogspot.com/-2Mtv0SIBJdk/XJw8vqzmvJI/AAAAAAAAD_k/D-V9GxJYjxUuQf9L-21ecbcgCdh7INBjACLcBGAs/s1600/snowdenfiles-treucrypt.png" imageanchor="1" target="_blank"><img src="https://2.bp.blogspot.com/-2Mtv0SIBJdk/XJw8vqzmvJI/AAAAAAAAD_k/D-V9GxJYjxUuQf9L-21ecbcgCdh7INBjACLcBGAs/s1600/snowdenfiles-treucrypt.png" width="550"></a><br>
<span size="2">
Screenshot from a Brazilian television report, showing some of the Snowden files<br>
opened in a TrueCrypt window on the laptop of Glenn Greenwald.<br>
<span color="gray">(screenshot by koenrh - click to enlarge)</span>
</span>
</p>


<p><span size="+2"><b>Non-Snowden leaks</b></span></p><p>

In a message to Gellman, Snowden said that "he was not resigned to life in prison or worse. He wanted to show other whistleblowers that there could be a happy ending".<a nohref="" title="Barton Gellman, Dark Mirror, p. 129">*</a> Later, whistleblower attorney Jesselyn Radack <a href="https://abcnews.go.com/blogs/headlines/2013/10/more-nsa-leakers-followed-snowdens-footsteps-whistleblower-lawyer-says" target="_blank">hoped</a> that "courage is contagious, and we see more and more people from the NSA coming through our door after Snowden made these revelations."</p><p>

Indeed, other sources started to leak documents to the press. The first one was a so-called tasking record showing that the NSA had targeted the non-secure cell phone of German chancellor Angela Merkel. This was <a href="https://www.spiegel.de/politik/deutschland/nsa-merkel-beschwert-sich-bei-obama-a-929636.html" target="_blank">revealed</a> by Der Spiegel on October 23, 2013, which is less than five months after the start of Snowden's revelations. </p>
<p>
The second leaked document that wasn't attributed to Snowden was just as spectacular: the <a href="https://nsa.gov1.info/dni/nsa-ant-catalog/index.html" target="_blank">ANT product catalog</a> with a range of sophisticated spying gadgets from the NSA's hacking division TAO. This catalog was also published by Der Spiegel and <a href="https://www.youtube.com/watch?v=dy3-QZLTpbQ" target="_blank">discussed</a> by Jacob Appelbaum during the <a href="https://en.wikipedia.org/wiki/Chaos_Communication_Congress" target="_blank">CCC</a> on December 30, 2013.</p><p> 

Initially, hardly anyone noticed that these documents didn't come from Snowden, and so a mysterious "second source" was able to publish files that were sometimes even more embarrassing and damaging than those from the Snowden trove, like intercepted conversations from foreign government leaders.</p><p>

Later, other piggybackers who called themselves <a href="https://en.wikipedia.org/wiki/The_Shadow_Brokers" target="_blank">The Shadow Brokers</a> leaked highly sensitive information about NSA hacking tools. The sources of these leaks have never been identified, although it's often <a href="https://www.schneier.com/blog/archives/2023/06/snowden-ten-years-later.html" target="_blank">assume</a>d that Russian intelligence was behind it. Snowden never addressed these other leaks, nor distanced himself from them.</p>
<p><a href="https://2.bp.blogspot.com/-NE70qy84JJQ/VYoeWkx6HSI/AAAAAAAACiY/uG6vAMItssY/s1600/wikileaks-france-nsa-comint-gamma.jpg" imageanchor="1" target="_blank"><img src="https://2.bp.blogspot.com/-NE70qy84JJQ/VYoeWkx6HSI/AAAAAAAACiY/uG6vAMItssY/s1600/wikileaks-france-nsa-comint-gamma.jpg" title="NSA intelligence report about an intercepted conversation between François Hollande and Jean-Marc Ayrault" width="500"></a><br>
<span size="2">
NSA report about an intercepted conversation of French president Hollande.<br>
Leaked by an unknown source and published by Wikileaks in 2015<br>
<span color="gray">(click to enlarge)</span><br>
</span></p>


<p><span size="+2"><b>The Section 215 program</b></span></p><p>

The very first disclosure of a document that did come from Snowden was the <a href="https://www.theguardian.com/world/interactive/2013/jun/06/verizon-telephone-data-court-order" target="_blank">Verizon order</a> of the Foreign Intelligence Surveillance Court (FISC). This court convenes behind closed doors and is often, but <a href="https://www.emptywheel.net/2017/06/28/confirmed-the-fisa-court-is-less-of-a-rubber-stamp-than-title-iii-courts/" target="_blank">injustly</a> referred to as a "rubber stamp". The order was <a href="https://www.theguardian.com/world/2013/jun/06/nsa-phone-records-verizon-court-order" target="_blank">published</a> by The Guardian on June 6, 2013.</p><p>

The Verizon order showed that the NSA was collecting domestic telephone metadata under the so-called <a href="https://www.electrospaces.net/2015/09/nsas-legal-authorities.html#215">Section 215</a> program. In the US, this became the most controversial issue and initially it seemed to confirm cryptic public warnings by US senators Ron Wyden and Mark Udall, as well as the aforementioned claims by Bill Binney about domestic mass surveillance.</p><p>

In reaction, Director of National Intelligence (DNI) James Clapper started an unprecedented declassification effort and released numerous FISC and NSA documents about the Section 215 program on a newly created Tumblr site called <a href="https://icontherecord.tumblr.com/" target="_blank">IC On the Record</a>. </p><p>

This was meant to clarify a central misunderstanding: the fact that the NSA collects data inside the US doesn't mean they are spying on Americans. The NSA is still focused on foreign targets, but because they are using American internet services, it proved to be fruitful to intercept their data not only abroad, but at telecoms and internet companies inside the US as well (the "home field advantage").</p><p>

Accordingly, the purpose of the Section 215 program was to find out whether foreign terrorists were in contact with unknown conspirators inside the US, which was one of the failures that could have prevented the attacks of 9/11.</p><p>

Therefore, the only thing the domestic telephone records were used for was simple contact chaining: NSA started with a phone number of a foreign terrorist and then the MAINWAY system presented the (foreign and domestic) phone numbers with which that initial number had been in contact with, as well as the numbers they, in their turn had been in contact with, the so-called "second hop":</p><p><img src="https://1.bp.blogspot.com/-FK7jUtlV9IM/VrrfHYPnSjI/AAAAAAAADCg/ji4VHF0HNVw/s1600/contact-chaining-federated2.jpg" width="500" title="Federated contact chaining queries including domestic and foreign phone call records"></p>

<p>

In 2012, the NSA used 288 phone numbers as a "seed" for such a contact chaining query, <a href="https://www.npr.org/templates/transcript/transcript.php?storyId=261079074?storyId=261079074" target="_blank">resulting</a> in 6000 phone numbers that analysts actually looked at. When this led to a suspicious American phone number, the NSA passed it on to the FBI for further investigation.</p><p>

This true purpose of the domestic metadata collection was clearly laid out in a <a href="https://documents.pclob.gov/prod/Documents/OversightReport/cf0ce183-7935-4b06-bb41-007d1f437412/215-Report_on_the_Telephone_Records_Program%20-%20Completed%20508%20-%2011292022.pdf" target="_blank">public report</a> which the independent Privacy and Civil Liberties Oversight Board (PCLOB) published in January 2014. The PCLOB found "no instance in which the program directly contributed to the discovery of a previously unknown terrorist plot", but the program was of some value as it offered additional leads and could show that foreign terrorist plots had <i>no</i> US nexus.</p><p> 

Although these domestic telephone records were not used to spy on Americans, and the FISC limited their retention to 5 years and prohibited the collection of location data, many people would not like to have them in an NSA database because of what Binney and Snowden called the possibility of a "turnkey tyranny".<a nohref="" title="Barton Gellman, Dark Mirror, p. 143">*</a></p><p>

The publication of the Verizon order did not only make the general public aware of the Section 215 program, but also gave civil liberty organizations standing in court, which fulfilled Jacob Appelbaum's wish from the 2012 Surveillance Teach-In.</p><p>

Meanwhile there have been two cases in which a Circuit Court of Appeals ruled about the Section 215 program. They both found that the bulk collection of metadata exceeded the scope of Section 215 of the <a href="https://en.wikipedia.org/wiki/Patriot_Act" target="_blank">Patriot Act</a> (because the actual practice hadn't been foreseen by lawmakers, although they had been briefed about it later). The courts didn't decide on whether the program was constitutional or not.</p>
<p><a href="https://www.theguardian.com/world/interactive/2013/jun/06/verizon-telephone-data-court-order" imageanchor="1" target="_blank"><img src="https://4.bp.blogspot.com/-tHoasJd3Mx8/XjEoogD6LyI/AAAAAAAAEZc/DSNnc_lkC-40lAAs9yCvz0IfrgFJe_YAQCLcBGAsYHQ/s1600/verizon-order.JPG" width="500"></a><br>
<span size="2">
The first page of the Verizon order from April 25, 2013<br>
<span color="gray">(click for the full document)</span><br>
</span>
</p>


<p><span size="+2"><b>The PRISM program</b></span></p><p>

One day after the publication of the Verizon order, The Guardian and The Washington Post revealed the PRISM program, which became 
synonymous for an all encompassing NSA spying system, just like <a href="https://en.wikipedia.org/wiki/ECHELON" target="_blank">ECHELON</a> was before.</p><p>

In his book <i>Dark Mirror</i>, Barton Gellman tells a different story than Greenwald did in <i>No Place to Hide</i>. Greenwald presented himself as the one who was chosen by Snowden to lead the revelations and claimed that he and Laura Poitras were working with Snowden since February 2013, while Gellman only got "some documents" and that Snowden was angry about the fear-driven approach of The Washington Post.<a nohref="" title="Glenn Greenwald, No Place to Hide, p. 54-57">*</a></p><p>

According to Gellman, the opposite was the case: on January 31, 2013, Laura Poitras already asked him for advice and on May 7, they agreed to work together. She introduced Gellman to her source, who still called himself Verax, and they started encrypted chat conversations. On May 20, Snowden sent them the full PRISM presentation, after which they signed a contract with The Washington Post on May 24.<a nohref="" title="Barton Gellman, Dark Mirror, p. 8-11 &amp; 138-139">*</a></p><p>

But Snowden was under severe time pressure and urged Gellman to rapidly publish the full PRISM presentation, which he had signed with a <a href="https://en.wikipedia.org/wiki/Digital_signature" target="_blank">digital signature</a> associated with his Verax alter ego. Only gradually did Gellman realize the implications of this. Snowden's plan was to ask political asylum at a foreign <a href="https://en.wikipedia.org/wiki/Consular_missions_in_Hong_Kong" target="_blank">diplomatic mission</a> in Hong Kong, where he wanted to use the cryptographic signature to identify himself as the source of the PRISM document (and didn't rule out to "provide raw source material to a foreign government").<a nohref="" title="Barton Gellman, Dark Mirror, p. 129">*</a></p><p>

As a journalist, Gellman protected the identity of his source, but publishing the digitally signed PRISM presentation would make him and The Washington Post complicit in Snowden's flight from American law. After consulting Poitras, Gellman decided not to do so. On May 27, Snowden withdrew the exclusive right for the Washington Post and turned to Greenwald, who until that moment didn't know who Snowden was, nor had seen any of the documents.<a nohref="" title="Barton Gellman, Dark Mirror, p. 128-139">*</a></p><p><a href="https://3.bp.blogspot.com/-KVB97E3pnWc/U1SNOMrZqSI/AAAAAAAABj4/hXu1tKvOJm8/s1600/prism-01-combined.jpg" imageanchor="1" target="_blank"><img src="https://3.bp.blogspot.com/-KVB97E3pnWc/U1SNOMrZqSI/AAAAAAAABj4/hXu1tKvOJm8/s1600/prism-01-combined.jpg" width="450"></a></p>
<p>

When Greenwald finally managed to get <a href="https://en.wikipedia.org/wiki/Pretty_Good_Privacy" target="_blank">PGP</a> working, Snowden sent him a zip-file with some 25 documents, including the 41-slide PRISM presentation. Greenwald started writing his own story about PRISM, which was <a href="https://www.theguardian.com/world/2013/jun/06/us-tech-giants-nsa-data" target="_blank">published</a> by The Guardian on June 6, 2013.<a nohref="" title="Glenn Greenwald, No Place To Hide, p. 18-20 &amp; 75-76">*</a> Just an hour earlier, The Washington Post had <a href="http://www.washingtonpost.com/investigations/us-intelligence-mining-data-from-nine-us-internet-companies-in-broad-secret-program/2013/06/06/3a0c0da8-cebf-11e2-8845-d970ccb04497_story.html" target="_blank">released</a> its own PRISM story.</p><p>

The most controversial part of these stories was the claim that "the National Security Agency has obtained direct access to the systems of Google, Facebook, Apple and other US internet giants", which those companies vigorously denied.</p><p>

That "direct access" was taken from one of the slides, but it's unclear why both Gellman and Greenwald stuck to the most simple interpretation of it. Fact is that they had access to the extensive accompanying speaker's notes, which said: "PRISM access is 100% dependent on ISP provisioning".<a nohref="" title="Barton Gellman, Dark Mirror, p. 119 &amp; 124">*</a></p><p>

They also had all the other PRISM slides, including two that were published later on, which clearly show that the FBI is in between the NSA and the internet companies:
</p><p><a href="https://3.bp.blogspot.com/-Ejp2lgqoEok/U3ksoG-pZ1I/AAAAAAAABnA/P2RTtvxQvKA/s1600/prism-14a.jpg" imageanchor="1" target="_blank"><img src="https://3.bp.blogspot.com/-Ejp2lgqoEok/U3ksoG-pZ1I/AAAAAAAABnA/P2RTtvxQvKA/s1600/prism-14a.jpg" width="450"></a></p>
<p><span size="2">
PRISM-slide published by <a href="http://www.lemonde.fr/technologies/article/2013/10/21/france-in-the-nsa-s-crosshair-wanadoo-and-alcatel-targeted_3499739_651865.html" target="_blank">Le Monde</a> on October 22, 2013<br>
  </span>
</p>
<p>

In July 2014, the Privacy and Civil Liberties Oversight Board report (PCLOB) published an extensive <a href="https://documents.pclob.gov/prod/Documents/OversightReport/ba65702c-3541-4125-a67d-92a7f974fc4c/702-Report-2%20-%20Complete%20-%20Nov%2014%202022%201548.pdf" target="_blank">public report</a> about PRISM as well, which confirms that individual selectors (like a target's e-mail address) are sent to internet companies, which are "compelled to give the communications sent to or from that selector to the government." According to the PCLOB, PRISM "has proven valuable in the government’s efforts to combat terrorism as well as in other areas of foreign intelligence."</p>
<p>
In <i>Dark Mirror</i>, Gellman admits: "In retrospect, I do not love the way I wrote the [PRISM] story. I knew a lot less then than I learned later, with more time in the documents and many more interviews". A well-informed source told him that the systems of a company like Facebook are too complex to let the NSA plug in a cable. Only Facebook knows how to pull things out, which they can hand over upon a valid request.<a nohref="" title="Barton Gellman, Dark Mirror, p. 124 &amp; 148">*</a> Google <a href="https://eu.usatoday.com/story/money/business/2013/06/12/google-nsa-servers-secure-ftp/2416181/" target="_blank">did</a> that through secure <a href="https://en.wikipedia.org/wiki/File_Transfer_Protocol" target="_blank">FTP</a> transfers and in person.</p><p>

Another interesting addition provided by Gellman is about the date of the PRISM presentation, April 2013, which is less than one and a half months before Snowden left the NSA:</p><p>
  "Nothing Snowden had seen until now better suited his plan. He had been talking to Poitras for three months, but he still did not feel confident that his disclosures would seize attention from a public that had seldom responded strongly to privacy warnings. Most of the NSA programs that worried him were legally and technically intricate, not easy to explain. He needed examples that ordinary people would recognize. Along came [the PRISM] presentation, festooned at the top of every slide with iconic logos from the best-known Internet companies in the world. "PRISM hits close to people's hearts", he told me."<a nohref="" title="Barton Gellman, Dark Mirror, p. 120">*</a><br>
  </p>


<p><span size="+2"><b>Overcollection</b></span></p><p>

While PRISM is no mass surveillance, but targeted collection against individual foreign targets, it still has a problematic aspect: overcollection. Snowden was eager to draw public attention to this issue and, according to Greenwald, took his last job at NSA Hawaii only in order to get access to the NSA's raw data repositories.<a nohref="" title="Glenn Greenwald, No Place To Hide, p. 48">*</a> Snowden declined to repeat or explain that to Gellman though.<a nohref="" title="Barton Gellman, Dark Mirror, p. 84">*</a></p><p>

He succeeded and was able to exfiltrate a cache of ca. 22,000 collection reports, <a href="https://www.washingtonpost.com/world/national-security/your-questions-answered-about-the-posts-recent-investigation-of-nsa-surveillance/2014/07/11/43d743e6-0908-11e4-8a6a-19355c7e870a_story.html?utm_term=.e6244eb277df" target="_blank">containing</a> 160,000 individual conversations (75% of which instant messages), which the NSA collected via the PRISM program between 2009 and 2012.<a nohref="" title="Barton Gellman, Dark Mirror, p. 340">*</a></p><p>

Snowden handed them over to Barton Gellman who <a href="https://www.washingtonpost.com/world/national-security/in-nsa-intercepted-data-those-not-targeted-far-outnumber-the-foreigners-who-are/2014/07/05/8139adf8-045a-11e4-8572-4b1b969b6322_story.html?utm_term=.676dfdc9ca3a" target="_blank">reported</a> about these files in July 2014. Researchers at The Washington Post found that the intercepted communications contained valuable foreign intelligence information, but also that over 9 out of 10 accountholders were not the intended surveillance targets and that nearly half of the files contained US person identifiers.</p><p>

It's probably technically impossible to prevent such overcollection, but instead of deleting irrelevant personal content, the NSA only "minimizes" it, which means that names of Americans are redacted before they are distributed. Gellman saw that NSA personnel takes these procedures seriously, but when he confronted former NSA deputy director Rick Ledgett with his unease, Ledgett's only reply was that the NSA really doesn't care about ordinary people.<a nohref="" title="Barton Gellman, Dark Mirror, p. 341-345">*</a></p>


<p><span size="+2"><b>The Mission List</b></span></p><p>

Ledgett's answer is confirmed by a comprehensive listing of the tasks of the NSA in the <a href="http://cryptome.org/2014/09/nsa-strategic-mission-list.pdf" target="_blank">Strategic Mission List</a> from January 2007. It was published by The New York Times in November 2013, but got hardly any attention, despite the fact that it clearly contradicts the claims by Snowden and Greenwald that the NSA has just one single goal: collect all digital communications from all over the world.</p><p>

Equally less traction <a href="https://archive.is/KnUS7" target="_blank">gained</a> reports by Ewen MacAskill from The Guardian and Scott Shane from The New York Times, who tried to provide balance and nuance by showing that NSA and GCHQ also did many good things, like monitoring terrorists, the Taliban, hostage takers, human traffickers, and drug cartels.</p><p>

The Mission List says that China, North-Korea, Iraq, Iran, Russia and Venezuela were "Enduring Targets", which means they are of long-term strategic importance and therefore require a holistic approach. Next there were 16 "Topical Missions", which are subject to some change, but can be considered legitimate targets for any large intelligence agency:</p><p>
- Winning the Global War on Terrorism (GWOT)<br>
- Protecting the US homeland<br>
- Combating proliferation of Weapons of Mass Destruction (WMD)<br>
- Protecting US military forces deployed overseas<br>
- Providing warning of impending state instability<br>
- Providing warning of a strategic nuclear missile attack<br>
- Monitoring regional tensions that could escalate<br>
- Preventing an attack on US critical information systems<br>
- Early detection of critical foreign military developments<br>
- Preventing technological surprise<br>
- Ensuring diplomatic advantage for the US<br>
- Ensuring a steady and reliable energy supply for the US<br>
- Countering foreign intelligence threats<br>
- Countering narcotics and transnational criminal networks<br>
- Mapping foreign military and civil communications infrastructure<br>
</p>
<p>
In 2013, terrorism was <a href="https://odnigov.tumblr.com/post/138558113835/dni-clapper-visits-us-naval-academy" target="_blank">replaced</a> by cyber attacks as top threat to American national security. Since then, cyber threats are increasing in frequency, scale, sophistication and severity of impact.</p>

<p><a href="https://1.bp.blogspot.com/-m-T9d8mqNMA/UpJoG-qhJAI/AAAAAAAABBY/qtZemadSakk/s1600/boundless-worldwide-aggregate.jpg" imageanchor="1" target="_blank"><img src="https://1.bp.blogspot.com/-m-T9d8mqNMA/UpJoG-qhJAI/AAAAAAAABBY/qtZemadSakk/s1600/boundless-worldwide-aggregate.jpg" width="550" title="Screenshot of BOUNDLESSINFORMANT"></a><br>
<span size="2">
Screenshot of the BOUNDLESSINFORMANT tool showing where the NSA collected most data<br>
</span>
</p>

<p><span size="+2"><b>Spying among friends</b></span></p><p>

For its mission of "Ensuring Diplomatic Advantage for the U.S.", the NSA intercepts the communications of numerous foreign governments and government leaders. Based upon documents from the Snowden trove, media reported about eavesdropping operations against the Mexican candidate for the presidency, Enrique Peña Nieto, Brazilian president Dilma Rousseff, the <a href="https://www.electrospaces.net/2015/12/how-nsa-targeted-venezuelan-oil-company.html" target="_blank">Venezuelan oil company PdVSA</a> and many others.</p>
<p>
The NSA's interest in Germany's chancellor Angela Merkel had the most far-reaching consequences. Merkel herself made clear to president Obama that "spying on friends is not acceptable" (<i>Ausspähen unter Freunden, das geht gar nicht</i>) and the German parliament started an official investigation into the spying activities of the NSA (<a href="https://de.wikipedia.org/wiki/1._Untersuchungsausschuss_der_18._Wahlperiode_des_Deutschen_Bundestages" target="_blank"><i>NSA-Untersuchungsausschuss</i></a> or <a href="https://twitter.com/hashtag/NSAUA?src=hashtag_click" target="_blank">#NSAUA</a>). This inquiry lasted from March 2014 to June 2017, but soon shifted its focus to Germany's own foreign intelligence agency BND.</p><p>

Extensive hearings of BND employees resulted in unprecedented insights into the details of the cable tapping and satellite interception operations which the BND conducted in cooperation with the NSA. Eventually it became clear that the NSA wasn't spying on German citizens, but did try to collect communications from European governments and companies of interest - just like the BND itself, which was also <a href="http://www.dw.com/en/germany-spies-among-friends-controversy-grows-over-espionage-activities/a-18844401" target="_blank">targeting</a> American and French foreign ministers, the interior departments of EU member states, and many others.</p>
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh67yFyvaSd6MOhzMXsYnQacbFQUvqoTNL9pv-h9DVsc2Keb1WTLEG1E7Avx8Ig3w4C8i5FJL-VCmk4JIuqUooYzYVbKKoVdRwB7VHeOpenv1L5HHTd4iqwScO05Mvq42hPDS66D0Rq9_Y1yClrit3TX2Z5yzChxkeRvbKS0hk6SGJueKo1ZPpdQ9Z0/s800/merkel-cellphone-header.jpg" target="_blank"><img alt="" width="500" data-original-height="420" data-original-width="800" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh67yFyvaSd6MOhzMXsYnQacbFQUvqoTNL9pv-h9DVsc2Keb1WTLEG1E7Avx8Ig3w4C8i5FJL-VCmk4JIuqUooYzYVbKKoVdRwB7VHeOpenv1L5HHTd4iqwScO05Mvq42hPDS66D0Rq9_Y1yClrit3TX2Z5yzChxkeRvbKS0hk6SGJueKo1ZPpdQ9Z0/s600/merkel-cellphone-header.jpg"></a></p>
<p><span size="2">
German chancellor Angela Merkel holding a secure BlackBerry Z10 in 2013<br>
    <span color="gray">(photo: Nicki Demarco/The Fold/The Washington Post)</span><br>
  </span>
</p>


<p><span size="+2"><b>Backdoor tapping Google</b></span></p><p>

A disclosure that caused outrage in Silicon Valley was about MUSCULAR, a collection program in which the NSA cooperates with its British counterpart GCHQ. In October 2013, The Washington Post <a href="https://www.washingtonpost.com/world/national-security/nsa-infiltrates-links-to-yahoo-google-data-centers-worldwide-snowden-documents-say/2013/10/30/e51d661e-4166-11e3-8b74-d89d714ca4dd_story.html" target="_blank">reported</a> that under this program, the NSA had secretly broken into the main communications links between Yahoo and Google data centers around the world.</p><p>

A big question was: why would the NSA do that, given that they already had "front door" access to Google and Yahoo via the PRISM program? Gellman asked Snowden, but his only answer was: "Because it could" and: "I'm speculating, but NSA doesn't ignore low-hanging fruit". Eventually Gellman realized that inside the US, the NSA had to specify individual targets, but abroad it was possible to acquire such data in bulk and to search and analyse it with <a href="https://en.wikipedia.org/wiki/XKeyscore" target="_blank">XKEYSCORE</a>.<a nohref="" title="Barton Gellman, Dark Mirror, p. 285-286">*</a></p><p>

The Post didn't mention the XKEYSCORE system by name and it's also not explained in Gellman's book <i>Dark Mirror</i>. That's unfortunate, because while Greenwald and Snowden presented XKEYSCORE as a global mass surveillance tool, it's actually a smart system to find targets who are communicating anonymously and therefore cannot be traced in the traditional way, via identifiers like phone numbers and e-mail addresses.</p>
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglLBeqt_uSQyOyu2IBstqYg-dq_ODbFpvEab0YTi2EVdQVKw3LU4fohs12nxnMoeIXRmx2YsIV-koifbS1gf5a-4cUivqSDXj8vJtuJVnggBfjCuCVEzpJncsCR3n3jKy1J4_km3zcQe7hDVAPQtvqgyxgm7lUqqOiF_6iIrm1N-AJ1qJBrIHq21pN/s1484/muscular%20google%20cloud.jpg" target="_blank"><img alt="" width="450" data-original-height="1113" data-original-width="1484" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglLBeqt_uSQyOyu2IBstqYg-dq_ODbFpvEab0YTi2EVdQVKw3LU4fohs12nxnMoeIXRmx2YsIV-koifbS1gf5a-4cUivqSDXj8vJtuJVnggBfjCuCVEzpJncsCR3n3jKy1J4_km3zcQe7hDVAPQtvqgyxgm7lUqqOiF_6iIrm1N-AJ1qJBrIHq21pN/s600/muscular%20google%20cloud.jpg"></a></p>
<p><span size="2">
  NSA slide showing where to intercept data from the Google cloud<br>
  </span>
</p>


<p><span size="+2"><b>BOUNDLESSINFORMANT</b></span></p><p>

Where Section 215 was most controversial in the United States, but lesser-known in Europe, the opposite was the case with <a href="https://en.wikipedia.org/wiki/Boundless_Informant" target="_blank">BOUNDLESSINFORMANT</a>, which caused fury in Europe, but is hardly known across the ocean. BOUNDLESSINFORMANT isn't a system to collect data, but an internal visualization tool that counts metadata records to provide insights into the NSA's worldwide data collection.</p><p>

The results are shown in heat maps and charts, for example for countries and collection programs. Such charts for Germany and a few other countries were published on July 29, 2013 by Der Spiegel, but on August 5, the German foreign intelligence agency BND said that they collected these data during military operations abroad and subsequently <a href="https://www.spiegel.de/international/world/german-intelligence-sends-massive-amounts-of-data-to-the-nsa-a-914821.html" target="_blank">shared</a> them with the NSA. </p><p>

Despite this statement, Glenn Greenwald interpreted these charts as evidence of American mass surveillance on European citizens and started publishing them in major European newspapers.</p>
<p><a href="https://1.bp.blogspot.com/-W66ZWknVuLw/VLnJbvaL6QI/AAAAAAAACJ0/PjkJ6dm-4NY/s1600/boundless-germany.jpg" imageanchor="1" target="_blank"><img src="https://1.bp.blogspot.com/-W66ZWknVuLw/VLnJbvaL6QI/AAAAAAAACJ0/PjkJ6dm-4NY/s1600/boundless-germany.jpg" width="550" title="BOUNDLESSINFORMANT screenshot showing metadata related to Germany"></a></p>
<p><span size="2">
  BOUNDLESSINFORMANT chart showing the numbers of<br>
    metadata which German BND shared with the NSA<br>
  </span>
</p>
<p>

On October 21, for example, the French paper Le Monde published a <a href="https://www.lemonde.fr/technologies/article/2013/10/21/france-in-the-nsa-s-crosshair-phone-networks-under-surveillance_3499741_651865.html" target="_blank">story</a> saying that "telephone communications of French citizens are intercepted on a massive scale." After a similar story appeared in Spain, NSA director Keith Alexander came with a remarkable clarification, <a href="https://www.reuters.com/article/us-usa-security-nsa-idUSBRE99S03N20131029" target="_blank">saying</a>: "This is not information that we collected on European citizens. It represents information that we and our NATO allies have collected in defense of our countries and in support of military operations."</p><p>

Greenwald continued his framing in Norwegian and Italian papers. Only in The Netherlands it was <a href="https://tweakers.net/nieuws/92067/nsa-onderschepte-in-maand-metadata-1-komma-8-miljoen-telefoontjes-in-nederland.html" target="_blank">found out</a> that the BOUNDLESSINFORMANT charts were not about content, but about metadata. Dutch interior minister Ronald Plasterk, however, still followed Greenwald's interpretation and assumed the Americans were spying on Dutch citizens. A court case forced the government to admit that Dutch military intelligence had collected the data during operations abroad.</p>
<p>
It was only in May 2019 that <a href="https://theintercept.com/2019/05/29/nsa-data-afghanistan-iraq-mexico-border/" target="_blank">The Intercept</a> put the pieces together and set the record straight: the various BOUNDLESSINFORMANT charts showed cellphone metadata that had been collected by members of the Afghanistan SIGINT Coalition (AFSC, also known as the 9 Eyes) and fed them into the NSA's Real-Time Regional Gateway (RT-RG) big data analysis platform.</p><p>

When The Intercept confronted Greenwald with this new research, he still <a href="https://theintercept.com/2019/05/29/nsa-data-afghanistan-iraq-mexico-border/" target="_blank">tried</a> to blame the NSA: "At the time, Der Spiegel had already reported this interpretation, the NSA wouldn’t answer our questions, and they wouldn’t give us any additional information. I am totally in favor of correcting the record if the reporting was inaccurate."</p><p>

While Greenwald ignored the declaration by general Alexander, he was right when he said that the NSA's internal <a href="https://www.theguardian.com/world/interactive/2013/jun/08/boundless-informant-nsa-full-text" target="_blank">documentation</a> about BOUNDLESSINFORMANT was somewhat confusing. Apparently, Greenwald had to rely on that documentation because Snowden was of little help, just like he was for various other programs that journalists did not fully understand.</p>
<p><a href="https://4.bp.blogspot.com/-4AOOwxorACQ/XX8cgvOthgI/AAAAAAAAEGA/m-OrX8PbqI0YuDbe7hOyftyFroLnlCqNgCLcBGAsYHQ/s1600/afsc-rtrg-datasources.PNG" imageanchor="1" target="_blank"><img src="https://4.bp.blogspot.com/-4AOOwxorACQ/XX8cgvOthgI/AAAAAAAAEGA/m-OrX8PbqI0YuDbe7hOyftyFroLnlCqNgCLcBGAsYHQ/s1600/afsc-rtrg-datasources.PNG" width="500"></a><br>
<span size="2">
Slide showing all the collection systems that fed the RT-RG platform<br> 
<span color="gray">(click to enlarge)</span><br>
</span>
</p>



<p><span size="+2"><b>Truth</b></span></p><p>

Many of the documents that Snowden provided to the press have been misinterpreted or exaggerated, sometimes unintentional, but in other cases maybe deliberately. In <i>Dark Mirror</i>, Barton Gellman writes:</p><div><p>
"There were signs that Snowden was capable of an instrumental approach to truth. In conversations about my work, when I got stuck on a hard reporting problem, he sometimes suggested that I provoke fresh disclosures from government officials by pretending to know more than I did."</p><p>

"Another time he went further, proposing that I actually publish informed speculation as fact. If my story outran the evidence, he said, the government would be forced to respond and thereby reveal more. There would be a net gain for public information either way." </p><p>
  
  "He said misinformation from people like Mike Hayden, supporters of the intelligence establishment, pushed the terms of debate so far off center that only rhetorical counterforce could set the record straight."<a nohref="" title="Barton Gellman, Dark Mirror, p. 324-326">*</a></p></div>
  <p>
Gellman declined this approach because it would make his reporting unreliable and it undermines confidence in the press if it would turn out that certain things weren't true. However, claims made by Greenwald and Snowden himself showed that his "counterforce" method sometimes did work: the government came up with new facts - but those never got the same attention as the original story, which was already stuck in people's minds.</p><p><span size="+1"><b>Conclusion</b></span></p><p>

There's no doubt that the Snowden revelations provided unprecedented insight into modern-day signals intelligence as conducted by the NSA and its Five Eyes partners. </p><p>

In part this was much needed to understand how the legal framework is implemented and where safeguards need improvement. That, however, requires a close examination of the documents, which shows the problems are smaller and more complex than the mythical "global mass surveillance" which Snowden and Greenwald tried to proof.</p><p>

On the other hand, many things have been published that were merely sensational and weakened the US and its signals intelligence system. By revealing its workings and capacity, the Snowden revelations unintentionally set a new standard which other countries <a href="https://blog.erratasec.com/2014/12/snowden-made-things-worse.html" target="_blank">hurried</a> to catch up with.</p><p>



<b>Links </b></p><p><span size="2">
  <br>
- Der Spiegel: <a href="https://archive.is/QZwpB" target="_blank">Das Internet ist heute anders unsicher</a> (June 9, 2023)<br>
- The Atlantic: <a href="https://archive.is/KnUS7" target="_blank">Did the Snowden Revelations Change Anything?</a> (June 7, 2023)<br>
- The Guardian: <a href="https://www.theguardian.com/us-news/2023/jun/07/edward-snowden-mi5-nsa-prism-ghcq" target="_blank">Snowden, MI5 and me: how the leak of the century came to be published</a> (June 7, 2023)<br>
- The Guardian: <a href="https://www.theguardian.com/us-news/2023/jun/07/edward-snowden-10-years-surveillance-revelations" target="_blank">What’s really changed 10 years after the Snowden revelations?</a> (June 7, 2023)<br>
- Schneier on Security: <a href="https://www.schneier.com/blog/archives/2023/06/snowden-ten-years-later.html" target="_blank">Snowden Ten Years Later</a> (June 6, 2023)<br>
- System Update: <a href="https://rumble.com/v2sgyx2-snowden-revelations-10-year-anniversary-glenn-greenwald-speaks-with-snowden.html" target="_blank">SNOWDEN REVELATIONS 10-Year Anniversary: Glenn Greenwald Speaks with Snowden &amp; Laura Poitras on the Past, Present, &amp; Future of Their Historic Reporting</a> (June 6, 2023)<br>
- neues deutschland: <a href="https://www.nd-aktuell.de/artikel/1173743.jahre-snowden-leaks-jahre-snowden-leaks-enthuellungen-nicht-mehr-erwuenscht.html" target="_blank">10 Jahre Snowden-Leaks: Enthüllungen nicht mehr erwünscht</a> (June 6, 2023)<br>
- neues deutschland: <a href="https://www.nd-aktuell.de/artikel/1173746.zehn-jahre-snowden-leaks-snowden-leaks-geheimdokumente-belegen-globale-massenueberwachung.html" target="_blank">Snowden-Leaks: Geheimdokumente belegen globale Massenüberwachung</a> (June 6, 2023)<br>
- Heise: <a href="https://www.heise.de/hintergrund/10-Jahre-Snowden-Enthuellungen-Was-hat-der-NSA-Whistleblower-bewirkt-9060879.html" target="_blank">Edward Snowden: Die Enthüllungen des NSA-Whistleblowers 10 Jahre später</a> (June 5, 2023)<br>
- Der Tagesspiegel: <i>Edward Snowden und die Whistleblower-Frage Feiert die Verräter!</i> (June 2023)<br>
- Netkwesties: <a href="https://www.netkwesties.nl/1472/barton-gellman-herziet-nsa-onthullingen.htm" target="_blank">Barton Gellman herziet NSA-onthullingen</a> (Dec. 7, 2020)<br>
    - See also: <a href="https://web.archive.org/web/20200206094116/https://signpostfilmproductions.com/timeline/" target="_blank">Timeline of Edward Snowden</a><br>
</span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing Small CLI Programs in Common Lisp (2021) (126 pts)]]></title>
            <link>https://stevelosh.com/blog/2021/03/small-common-lisp-cli-programs/</link>
            <guid>37400398</guid>
            <pubDate>Wed, 06 Sep 2023 01:40:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stevelosh.com/blog/2021/03/small-common-lisp-cli-programs/">https://stevelosh.com/blog/2021/03/small-common-lisp-cli-programs/</a>, See on <a href="https://news.ycombinator.com/item?id=37400398">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-blog-entry"><article><p>Posted on March 17th, 2021.</p><p>I write a lot of command-line programs.  For tiny programs I usually go with the
typical UNIX approach: throw together a half-assed shell script and move on.
For large programs I make a full Common Lisp project, with an ASDF system
definition and such.  But there's a middle ground of small<em>ish</em> programs that
don't warrant a full repository on their own, but for which I still want a real
interface with proper <code>--help</code> and error handling.</p>

<p>I've found Common Lisp to be a good language for writing these small command
line programs.  But it can be a little intimidating to get started (especially
for beginners) because Common Lisp is a very flexible language and doesn't lock
you into one way of working.</p>

<p>In this post I'll describe how I write small, stand-alone command line programs
in Common Lisp.  It might work for you, or you might want to modify things to
fit your own needs.</p>

<ol><li><a href="#s1-requirements">Requirements</a></li><li><a href="#s2-solution-skeleton">Solution Skeleton</a><ol><li><a href="#s3-directory-structure">Directory Structure</a></li><li><a href="#s4-lisp-files">Lisp Files</a></li><li><a href="#s5-building-binaries">Building Binaries</a></li><li><a href="#s6-building-man-pages">Building Man Pages</a></li><li><a href="#s7-makefile">Makefile</a></li></ol></li><li><a href="#s8-case-study-a-batch-coloring-utility">Case Study: A Batch Coloring Utility</a><ol><li><a href="#s9-libraries">Libraries</a></li><li><a href="#s10-package">Package</a></li><li><a href="#s11-configuration">Configuration</a></li><li><a href="#s12-errors">Errors</a></li><li><a href="#s13-colorization">Colorization</a></li><li><a href="#s14-not-quite-top-level-interface">Not-Quite-Top-Level Interface</a></li><li><a href="#s15-user-interface">User Interface</a></li><li><a href="#s16-top-level-interface">Top-Level Interface</a></li></ol></li><li><a href="#s17-more-information">More Information</a></li></ol>

<h2 id="s1-requirements"><a href="#s1-requirements">Requirements</a></h2>

<p>When you're writing programs in Common Lisp, you've got a lot of options.
Laying out the requirements I have helped me decide on an approach.</p>

<p>First: each new program should be one single file.  A few other files for the
collection as a whole (e.g. a <code>Makefile</code>) are okay, but once everything is set
up creating a new program should mean adding one single file.  For larger
programs a full project directory and ASDF system are great, but for small
programs having one file per program reduces the mental overhead quite a bit.</p>

<p>The programs need to be able to be developed in the typical Common Lisp
interactive style (in my case: with Swank and VLIME).  Interactive development
is one of the best parts of working in Common Lisp, and I'm not willing to give
it up.  In particular this means that a shell-script style approach, with
<code>#!/path/to/sbcl --script</code> and the top and directly running code at the top
level in the file, doesn't work for two main reasons:</p>

<ul>
<li><code>load</code>ing that file will fail due to the shebang unless you have some ugly
  reader macros in your startup file.</li>
<li>The program will need to do things like parsing command-line arguments and
  exiting with an error code, and calling <code>exit</code> would kill the Swank process.</li>
</ul>

<p>The programs need to be able to use libraries, so Quicklisp will need to be
involved.  Common Lisp has a lot of nice things built-in, but there are some
libraries that are just too useful to pass up.</p>

<p>The programs will need to have proper user interfaces.  Command line arguments
must be robustly parsed (e.g. collapsing <code>-a -b -c foo -d</code> into <code>-abcfoo -d</code>
should work as expected), malformed or unknown options must be caught instead of
dropping them on the floor, error messages should be meaningful, and the
<code>--help</code> should be thoroughly and thoughtfully written so I can remember how to
use the program months later.  A <code>man</code> page is a nice bonus, but not required.</p>

<p>Relying on some basic conventions (e.g. a command <code>foo</code> is always in <code>foo.lisp</code>
and defines a package <code>foo</code> with a function called <code>toplevel</code>) is okay if it
makes my life easier.  These programs are just for me, so I don't have to worry
about people wanting to create executables with spaces in the name or something.</p>

<p>Portability between Common Lisp implementations is nice to have, but not
required.  If using a bit of SBCL-specific grease will let me avoid a bunch of
extra dependencies, that's fine for these small personal programs.</p>

<h2 id="s2-solution-skeleton"><a href="#s2-solution-skeleton">Solution Skeleton</a></h2>

<p>After trying a number of different approaches I've settled on a solution that
I'm pretty happy with.  First I'll describe the general approach, then we'll
look at one actual example program in its entirety.</p>

<h3 id="s3-directory-structure"><a href="#s3-directory-structure">Directory Structure</a></h3>

<p>I keep all my small single-file Common Lisp programs in a <code>lisp</code> directory
inside my dotfiles repository.  Its contents look like this:</p>

<pre><code>…/dotfiles/lisp/
    bin/
        foo
        bar
    man/
        man1/
            foo.1
            bar.1
    build-binary.sh
    build-manual.sh
    Makefile
    foo.lisp
    bar.lisp</code></pre>

<p>The <code>bin</code> directory is where the executable files end up.  I've added it to my
<code>$PATH</code> so I don't have to symlink or copy the binaries anywhere.</p>

<p><code>man</code> contains the generated <code>man</code> pages.  Because it's adjacent to <code>bin</code> (which
is on my path) the <code>man</code> program automatically finds the <code>man</code> pages as
expected.</p>

<p><code>build-binary.sh</code>, <code>build-manual.sh</code>, and <code>Makefile</code> are some glue to make
building programs easier.</p>

<p>The <code>.lisp</code> files are the programs.  Each new program I want to add only
requires adding the <code>&lt;programname&gt;.lisp</code> file in this directory and running
<code>make</code>.</p>

<h3 id="s4-lisp-files"><a href="#s4-lisp-files">Lisp Files</a></h3>

<p>My small Common Lisp programs follow a few conventions that make building them
easier.  Let's look at the skeleton of a <code>foo.lisp</code> file as an example.  I'll
show the entire file here, and then step through it piece by piece.</p>

<pre><code><span><span>(<span><i><span>eval-when</span></i> <span>(<span><span>:compile-toplevel</span> <span>:load-toplevel</span> <span>:execute</span></span>)</span>
  <span>(<span>ql:quickload '<span>(<span><span>:with-user-abort</span> …</span>)</span> <span>:silent</span> t</span>)</span></span>)</span>

<span>(<span><i><span>defpackage</span></i> <span>:foo</span>
  <span>(<span><span>:use</span> <span>:cl</span></span>)</span>
  <span>(<span><span>:export</span> <span>:toplevel</span> <span>*ui*</span></span>)</span></span>)</span>

<span>(<span>in-package <span>:foo</span></span>)</span>

<span>;;;; Configuration -----------------------------------------------
</span><span>(<span><i><span>defparameter</span></i> <span>*whatever*</span> 123</span>)</span>

<span>;;;; Errors ------------------------------------------------------
</span><span>(<span><i><span>define-condition</span></i> user-error <span>(<span>error</span>)</span> <span>(<span></span>)</span></span>)</span>

<span>(<span><i><span>define-condition</span></i> missing-foo <span>(<span>user-error</span>)</span> <span>(<span></span>)</span>
  <span>(<span><span>:report</span> <span>"A foo is required, but none was supplied."</span></span>)</span></span>)</span>

<span>;;;; Functionality -----------------------------------------------
</span><span>(<span><i><span>defun</span></i> foo <span>(<span>string</span>)</span>
  …</span>)</span>

<span>;;;; Run ---------------------------------------------------------
</span><span>(<span><i><span>defun</span></i> run <span>(<span>arguments</span>)</span>
  <span>(<span>map nil #'foo arguments</span>)</span></span>)</span>

<span>;;;; User Interface ----------------------------------------------
</span><span>(<span><i><span>defmacro</span></i> exit-on-ctrl-c <span>(<span>&amp;body body</span>)</span>
  `<span>(<span>handler-case <span>(<span><i><span>with-user-abort:with-user-abort</span></i> <span>(<span><i><span>progn</span></i> ,@body</span>)</span></span>)</span>
     <span>(<span>with-user-abort:user-abort <span>(<span></span>)</span> <span>(<span>sb-ext:exit <span>:code</span> 130</span>)</span></span>)</span></span>)</span></span>)</span>

<span>(<span><i><span>defparameter</span></i> <span>*ui*</span>
  <span>(<span>adopt:make-interface
    <span>:name</span> <span>"foo"</span>
    …</span>)</span></span>)</span>

<span>(<span><i><span>defun</span></i> toplevel <span>(<span></span>)</span>
  <span>(<span>sb-ext:disable-debugger</span>)</span>
  <span>(<span>exit-on-ctrl-c
    <span>(<span>multiple-value-bind <span>(<span>arguments options</span>)</span> <span>(<span>adopt:parse-options-or-exit <span>*ui*</span></span>)</span>
      …       <span>(<span>handler-case <span>(<span>run arguments</span>)</span>
        <span>(<span>user-error <span>(<span>e</span>)</span> <span>(<span>adopt:print-error-and-exit e</span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span></code></pre>

<p>Let's go through each chunk of this.</p>

<pre><code><span><span>(<span><i><span>eval-when</span></i> <span>(<span><span>:compile-toplevel</span> <span>:load-toplevel</span> <span>:execute</span></span>)</span>
  <span>(<span>ql:quickload '<span>(<span><span>:with-user-abort</span> …</span>)</span> <span>:silent</span> t</span>)</span></span>)</span></span></code></pre>

<p>First we <code>quickload</code> any necessary libraries.  We always want to do this, even
when compiling the file, because we need the appropriate packages to exist when
we try to use their symbols later in the file.</p>

<p><a href="https://github.com/compufox/with-user-abort">with-user-abort</a> is a library for easily handling <code>control-c</code>, which all of
these small programs will use.</p>

<pre><code><span><span>(<span><i><span>defpackage</span></i> <span>:foo</span>
  <span>(<span><span>:use</span> <span>:cl</span></span>)</span>
  <span>(<span><span>:export</span> <span>:toplevel</span> <span>*ui*</span></span>)</span></span>)</span>

<span>(<span>in-package <span>:foo</span></span>)</span></span></code></pre>

<p>Next we define a package <code>foo</code> and switch to it.  The package is always named
the same as the resulting binary and the basename of the file, and always
exports the symbols <code>toplevel</code> and <code>*ui*</code>.  These conventions make it easy to
build everything automatically with <code>make</code> later.</p>

<pre><code><span><span>;;;; Configuration -----------------------------------------------
</span><span>(<span><i><span>defparameter</span></i> <span>*whatever*</span> 123</span>)</span></span></code></pre>

<p>Next we define any configuration variables.  These will be set later after
parsing the command line arguments (when we run the command line program) or
at the REPL (when developing interactively).</p>

<pre><code><span><span>;;;; Errors ------------------------------------------------------
</span><span>(<span><i><span>define-condition</span></i> user-error <span>(<span>error</span>)</span> <span>(<span></span>)</span></span>)</span>

<span>(<span><i><span>define-condition</span></i> missing-foo <span>(<span>user-error</span>)</span> <span>(<span></span>)</span>
  <span>(<span><span>:report</span> <span>"A foo is required, but none was supplied."</span></span>)</span></span>)</span></span></code></pre>

<p>We define a <code>user-error</code> condition, and any errors the user might make will
inherit from it.  This will make it easy to treat user errors (e.g. passing
a mangled regular expression like <code>(foo+</code> as an argument) differently from
programming errors (i.e. bugs).  This makes it easier to treat those errors
differently:</p>

<ul>
<li>Bugs should print a backtrace or enter the debugger.</li>
<li>Expected user errors should print a helpful error message with no backtrace or debugger.</li>
</ul>

<pre><code><span><span>;;;; Functionality -----------------------------------------------
</span><span>(<span><i><span>defun</span></i> foo <span>(<span>string</span>)</span>
  …</span>)</span></span></code></pre>

<p>Next we have the actual functionality of the program.</p>

<pre><code><span><span>;;;; Run ---------------------------------------------------------
</span><span>(<span><i><span>defun</span></i> run <span>(<span>arguments</span>)</span>
  <span>(<span>map nil #'foo arguments</span>)</span></span>)</span></span></code></pre>

<p>We define a function <code>run</code> that takes some arguments (as strings) and performs
the main work of the program.</p>

<p>Importantly, <code>run</code> does <em>not</em> handle command line argument parsing, and it does
<em>not</em> exit the program with an error code, which means we can safely call it to
say "run the whole program" when we're developing interactively without worrying
about it killing our Lisp process.</p>

<p>Now we need to define the command line interface.</p>

<pre><code><span><span>;;;; User Interface ----------------------------------------------
</span><span>(<span><i><span>defmacro</span></i> exit-on-ctrl-c <span>(<span>&amp;body body</span>)</span>
  `<span>(<span>handler-case <span>(<span><i><span>with-user-abort:with-user-abort</span></i> <span>(<span><i><span>progn</span></i> ,@body</span>)</span></span>)</span>
     <span>(<span>with-user-abort:user-abort <span>(<span></span>)</span> <span>(<span>adopt:exit 130</span>)</span></span>)</span></span>)</span></span>)</span></span></code></pre>

<p>We'll make a little macro around <code>with-user-abort</code> to make it less wordy.  We'll
<a href="https://tldp.org/LDP/abs/html/exitcodes.html">exit with a status of 130</a> if the
user presses <code>ctrl-c</code>.  Maybe some day I'll pull this into Adopt so I don't have
to copy these three lines everywhere.</p>

<pre><code><span><span>(<span><i><span>defparameter</span></i> <span>*ui*</span>
  <span>(<span>adopt:make-interface
    <span>:name</span> <span>"foo"</span>
    …</span>)</span></span>)</span></span></code></pre>

<p>Here we define the <code>*ui*</code> variable whose symbol we exported above.  <a href="https://docs.stevelosh.com/adopt">Adopt</a> is
a command line argument parsing library I wrote.  If you want to use a different
library, feel free.</p>

<pre><code><span><span>(<span><i><span>defun</span></i> toplevel <span>(<span></span>)</span>
  <span>(<span>sb-ext:disable-debugger</span>)</span>
  <span>(<span>exit-on-ctrl-c
    <span>(<span>multiple-value-bind <span>(<span>arguments options</span>)</span> <span>(<span>adopt:parse-options-or-exit <span>*ui*</span></span>)</span>
      …       <span>(<span>handler-case <span>(<span>run arguments</span>)</span>
        <span>(<span>user-error <span>(<span>e</span>)</span> <span>(<span>adopt:print-error-and-exit e</span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span></code></pre>

<p>And finally we define the <code>toplevel</code> function.  This will only ever be called
when the program is run as a standalone program, never interactively.  It
handles all the work beyond the main guts of the program (which are handled by
the <code>run</code> function), including:</p>

<ul>
<li>Disabling or enabling the debugger.</li>
<li>Exiting the process with an appropriate status code on errors.</li>
<li>Parsing command line arguments.</li>
<li>Setting the values of the configuration parameters.</li>
<li>Calling <code>run</code>.</li>
</ul>

<p>That's it for the structure of the <code>.lisp</code> files.</p>

<h3 id="s5-building-binaries"><a href="#s5-building-binaries">Building Binaries</a></h3>

<p><code>build-binary.sh</code> is a small script to build the executable binaries from the
<code>.lisp</code> files.  <code>./build-binary.sh foo.lisp</code> will build <code>foo</code>:</p>

<pre><code>#!/usr/bin/env bash

set -euo pipefail

LISP=$1
NAME=$(basename "$1" .lisp)
shift

sbcl --load "$LISP" \
     --eval "(sb-ext:save-lisp-and-die \"$NAME\"
               :executable t
               :save-runtime-options t
               :toplevel '$NAME:toplevel)"</code></pre>

<p>Here we see where the naming conventions have become important — we know that
the package is named the same as the binary and that it will have the symbol
<code>toplevel</code> exported, which always names the entry point for the binary.</p>

<h3 id="s6-building-man-pages"><a href="#s6-building-man-pages">Building Man Pages</a></h3>

<p><code>build-manual.sh</code> is similar and builds the <code>man</code> pages using <a href="https://docs.stevelosh.com/adopt">Adopt</a>'s
built-in <code>man</code> page generation.  If you don't care about building <code>man</code> pages
for your personal programs you can ignore this.  I admit that generating <code>man</code>
pages for these programs is a little bit silly because they're only for my own
personal use, but I get it for free with Adopt, so why not?</p>

<pre><code>#!/usr/bin/env bash

set -euo pipefail

LISP=$1
NAME=$(basename "$LISP" .lisp)
OUT="$NAME.1"
shift

sbcl --load "$LISP" \
     --eval "(with-open-file (f \"$OUT\" :direction :output :if-exists :supersede)
               (adopt:print-manual $NAME:*ui* :stream f))" \
     --quit</code></pre>

<p>This is why we always name the Adopt interface variable <code>*ui*</code> and export it
from the package.</p>

<h3 id="s7-makefile"><a href="#s7-makefile">Makefile</a></h3>

<p>Finally we have a simple <code>Makefile</code> so we can run <code>make</code> to regenerate any
out of date binaries and <code>man</code> pages:</p>

<pre><code>files := $(wildcard *.lisp)
names := $(files:.lisp=)

.PHONY: all clean $(names)

all: $(names)

$(names): %: bin/% man/man1/%.1

bin/%: %.lisp build-binary.sh Makefile
    mkdir -p bin
    ./build-binary.sh $&lt;
    mv $(@F) bin/

man/man1/%.1: %.lisp build-manual.sh Makefile
    mkdir -p man/man1
    ./build-manual.sh $&lt;
    mv $(@F) man/man1/

clean:
    rm -rf bin man</code></pre>

<p>We use a <code>wildcard</code> to automatically find the <code>.lisp</code> files so we don't have to
do anything extra after adding a new file when we want to make a new program.</p>

<p>The most notable line here is <code>$(names): %: bin/% man/man1/%.1</code> which uses
a <a href="https://www.gnu.org/software/make/manual/html_node/Static-Pattern.html#Static-Pattern">static pattern rule</a>
to automatically define the phony rules for building each program.  If
<code>$(names)</code> is <code>foo bar</code> this line effectively defines two phony rules:</p>

<pre><code>foo: bin/foo man/man1/foo.1
bar: bin/bar man/man1/bar.1</code></pre>

<p>This lets us run <code>make foo</code> to make both the binary and <code>man</code> page for
<code>foo.lisp</code>.</p>

<h2 id="s8-case-study-a-batch-coloring-utility"><a href="#s8-case-study-a-batch-coloring-utility">Case Study: A Batch Coloring Utility</a></h2>

<p>Now that we've seen the skeleton, let's look at one of my actual programs that
I use all the time.  It's called <code>batchcolor</code> and it's used to highlight regular
expression matches in text (usually log files) with a twist: each unique match
is highlighted in a separate color, which makes it easier to visually parse the
result.</p>

<p>For example: suppose we have some log files with lines of the form <code>&lt;timestamp&gt;
[&lt;request ID&gt;] &lt;level&gt; &lt;message&gt;</code> where request ID is a UUID, and messages might
contain other UUIDs for various things.  Such a log file might look something
like this:</p>

<pre><code>2021-01-02 14:01:45 [f788a624-8dcd-4c5e-b1e8-681d0a68a8d3] INFO Incoming request GET /users/28b2d548-eff1-471c-b807-cc2bcee76b7d/things/7ca6d8d2-5038-42bd-a559-b3ee0c8b7543/
2021-01-02 14:01:45 [f788a624-8dcd-4c5e-b1e8-681d0a68a8d3] INFO Thing 7ca6d8d2-5038-42bd-a559-b3ee0c8b7543 is not cached, retrieving...
2021-01-02 14:01:45 [f788a624-8dcd-4c5e-b1e8-681d0a68a8d3] WARN User 28b2d548-eff1-471c-b807-cc2bcee76b7d does not have access to thing 7ca6d8d2-5038-42bd-a559-b3ee0c8b7543, denying request.
2021-01-02 14:01:46 [f788a624-8dcd-4c5e-b1e8-681d0a68a8d3] INFO Returning HTTP 404.
2021-01-02 14:01:46 [bea6ae06-bd06-4d2a-ae35-3e83fea2edc7] INFO Incoming request GET /users/28b2d548-eff1-471c-b807-cc2bcee76b7d/things/7ca6d8d2-5038-42bd-a559-b3ee0c8d7543/
2021-01-02 14:01:46 [bea6ae06-bd06-4d2a-ae35-3e83fea2edc7] INFO Thing 7ca6d8d2-5038-42bd-a559-b3ee0c8d7543 is not cached, retrieving...
2021-01-02 14:01:46 [b04ced1d-1cfa-4315-aaa9-0e245ff9a8e1] INFO Incoming request POST /users/sign-up/
2021-01-02 14:01:46 [bea6ae06-bd06-4d2a-ae35-3e83fea2edc7] INFO Returning HTTP 200.
2021-01-02 14:01:46 [b04ced1d-1cfa-4315-aaa9-0e245ff9a8e1] ERR Error running SQL query: connection refused.
2021-01-02 14:01:47 [b04ced1d-1cfa-4315-aaa9-0e245ff9a8e1] ERR Returning HTTP 500.</code></pre>

<p>If I try to just read this directly, it's easy for my eyes to glaze over unless
I laboriously walk line-by-line.</p>

<p><a href="https://stevelosh.com/static/images/blog/2021/03/uncolored.png"><img src="https://stevelosh.com/static/images/blog/2021/03/uncolored.png" alt="Screenshot of uncolored log output"></a></p>

<p>I could use <code>grep</code> to highlight the UUIDs:</p>

<pre><code>grep -P \
    '\b[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}\b' \
    example.log
</code></pre>

<p>Unfortunately that doesn't really help too much because all the UUIDs are
highlighted the same color:</p>

<p><a href="https://stevelosh.com/static/images/blog/2021/03/grepcolored.png"><img src="https://stevelosh.com/static/images/blog/2021/03/grepcolored.png" alt="Screenshot of grep-colored log output"></a></p>

<p>To get a more readable version of the log, I use <code>batchcolor</code>:</p>

<pre><code>batchcolor \
    '\b[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}\b' \
    example.log
</code></pre>

<p><code>batchcolor</code> also highlights matches, but it highlights each unique match in its
own color:</p>

<p><a href="https://stevelosh.com/static/images/blog/2021/03/batchcolored.png"><img src="https://stevelosh.com/static/images/blog/2021/03/batchcolored.png" alt="Screenshot of batchcolored log output"></a></p>

<p>This is <em>much</em> easier for me to visually parse.  The interleaving of separate
request logs is now obvious from the colors of the IDs, and it's easy to match
up various user IDs and thing IDs at a glance.  Did you even notice that the two
thing IDs were different before?</p>

<p><code>batchcolor</code> has a few other quality of life features, like picking explicit
colors for specific strings (e.g. red for <code>ERR</code>):</p>

<p><a href="https://stevelosh.com/static/images/blog/2021/03/batchcoloredfull.png"><img src="https://stevelosh.com/static/images/blog/2021/03/batchcoloredfull.png" alt="Screenshot of fully batchcolored log output"></a></p>

<p>I use this particular <code>batchcolor</code> invocation so often I've put it in its own
tiny shell script.  I use it to <code>tail</code> log files when developing locally almost
every day, and it makes visually scanning the log output <em>much</em> easier.  It can
come in handy for other kinds of text too, like highlighting nicknames in an IRC
log.</p>

<p>Let's step through its code piece by piece.</p>

<h3 id="s9-libraries"><a href="#s9-libraries">Libraries</a></h3>

<pre><code><span><span>(<span><i><span>eval-when</span></i> <span>(<span><span>:compile-toplevel</span> <span>:load-toplevel</span> <span>:execute</span></span>)</span>
  <span>(<span>ql:quickload '<span>(<span><span>:adopt</span> <span>:cl-ppcre</span> <span>:with-user-abort</span></span>)</span> <span>:silent</span> t</span>)</span></span>)</span></span></code></pre>

<p>First we <code>quickload</code> libraries.  We'll use <a href="https://docs.stevelosh.com/adopt">Adopt</a> for command line argument
processing, <a href="http://edicl.github.io/cl-ppcre/">cl-ppcre</a> for regular expressions, and the previously-mentioned
<a href="https://github.com/compufox/with-user-abort">with-user-abort</a> to handle <code>control-c</code>.</p>

<h3 id="s10-package"><a href="#s10-package">Package</a></h3>

<pre><code><span><span>(<span><i><span>defpackage</span></i> <span>:batchcolor</span>
  <span>(<span><span>:use</span> <span>:cl</span></span>)</span>
  <span>(<span><span>:export</span> <span>:toplevel</span> <span>:*ui*</span></span>)</span></span>)</span>

<span>(<span>in-package <span>:batchcolor</span></span>)</span></span></code></pre>

<p>We define and switch to the appropriately-named package.  Nothing special here.</p>

<h3 id="s11-configuration"><a href="#s11-configuration">Configuration</a></h3>

<pre><code><span><span>;;;; Configuration ------------------------------------------------------------
</span><span>(<span><i><span>defparameter</span></i> <span>*start*</span> 0</span>)</span>
<span>(<span><i><span>defparameter</span></i> <span>*dark*</span> t</span>)</span></span></code></pre>

<p>Next we <code>defparameter</code> some variables to hold some settings.  <code>*start*</code> will be
used later when randomizing colors, don't worry about it for now.</p>

<h3 id="s12-errors"><a href="#s12-errors">Errors</a></h3>

<pre><code><span><span>;;;; Errors -------------------------------------------------------------------
</span><span>(<span><i><span>define-condition</span></i> user-error <span>(<span>error</span>)</span> <span>(<span></span>)</span></span>)</span>

<span>(<span><i><span>define-condition</span></i> missing-regex <span>(<span>user-error</span>)</span> <span>(<span></span>)</span>
  <span>(<span><span>:report</span> <span>"A regular expression is required."</span></span>)</span></span>)</span>

<span>(<span><i><span>define-condition</span></i> malformed-regex <span>(<span>user-error</span>)</span>
  <span>(<span><span>(<span>underlying-error <span>:initarg</span> <span>:underlying-error</span></span>)</span></span>)</span>
  <span>(<span><span>:report</span> <span>(<span><i><span>lambda</span></i> <span>(<span>c s</span>)</span>
             <span>(<span>format s <span>"Invalid regex: ~A"</span> <span>(<span>slot-value c 'underlying-error</span>)</span></span>)</span></span>)</span></span>)</span></span>)</span>

<span>(<span><i><span>define-condition</span></i> overlapping-groups <span>(<span>user-error</span>)</span> <span>(<span></span>)</span>
  <span>(<span><span>:report</span> <span>"Invalid regex: seems to contain overlapping capturing groups."</span></span>)</span></span>)</span>

<span>(<span><i><span>define-condition</span></i> malformed-explicit <span>(<span>user-error</span>)</span>
  <span>(<span><span>(<span>spec <span>:initarg</span> <span>:spec</span></span>)</span></span>)</span>
  <span>(<span><span>:report</span>
    <span>(<span><i><span>lambda</span></i> <span>(<span>c s</span>)</span>
      <span>(<span>format s <span>"Invalid explicit spec ~S, must be of the form </span><span>\"</span><span>R,G,B:string</span><span>\"</span><span> with colors being 0-5."</span>
              <span>(<span>slot-value c 'spec</span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span></code></pre>

<p>Here we define the user errors.  Some of these are self-explanatory, while
others will make more sense later once we see them in action.  The specific
details aren't as important as the overall idea: for user errors we know might
happen, display a helpful error message instead of just spewing a backtrace at
the user.</p>

<h3 id="s13-colorization"><a href="#s13-colorization">Colorization</a></h3>

<p>Next we have the actual meat of the program.  Obviously this is going to be
completely different for every program, so feel free to skip this if you don't
care about this specific problem.</p>

<pre><code><span><span>;;;; Functionality ------------------------------------------------------------
</span><span>(<span><i><span>defun</span></i> rgb-code <span>(<span>r g b</span>)</span>
  <span>;; The 256 color mode color values are essentially r/g/b in base 6, but
</span>  <span>;; shifted 16 higher to account for the intiial 8+8 colors.
</span>  <span>(<span>+ <span>(<span>* r 36</span>)</span>
     <span>(<span>* g 6</span>)</span>
     <span>(<span>* b 1</span>)</span>
     16</span>)</span></span>)</span></span></code></pre>

<p>We're going to highlight different matches with different colors.  We'll need
a reasonable amount of colors to make this useful, so using the basic 8/16 ANSI
colors isn't enough.  Full 24-bit truecolor is overkill, but the 8-bit ANSI
colors will work nicely.  If we ignore the base colors, we essentially have
6 x 6 x 6 = 216 colors to work with.  <code>rgb-code</code> will take the red, green, and
blue values from <code>0</code> to <code>5</code> and return the color code.  See <a href="https://en.wikipedia.org/wiki/ANSI_escape_code#8-bit">Wikipedia</a>
for more information.</p>

<pre><code><span><span>(<span><i><span>defun</span></i> make-colors <span>(<span>excludep</span>)</span>
  <span>(<span><i><span>let</span></i> <span>(<span><span>(<span>result <span>(<span>make-array 256 <span>:fill-pointer</span> 0</span>)</span></span>)</span></span>)</span>
    <span>(<span>dotimes <span>(<span>r 6</span>)</span>
      <span>(<span>dotimes <span>(<span>g 6</span>)</span>
        <span>(<span>dotimes <span>(<span>b 6</span>)</span>
          <span>(<span>unless <span>(<span>funcall excludep <span>(<span>+ r g b</span>)</span></span>)</span>
            <span>(<span>vector-push-extend <span>(<span>rgb-code r g b</span>)</span> result</span>)</span></span>)</span></span>)</span></span>)</span></span>)</span>
    result</span>)</span></span>)</span>

<span>(<span><i><span>defparameter</span></i> <span>*dark-colors*</span>  <span>(<span>make-colors <span>(<span><i><span>lambda</span></i> <span>(<span>v</span>)</span> <span>(<span>&lt; v 3</span>)</span></span>)</span></span>)</span></span>)</span>
<span>(<span><i><span>defparameter</span></i> <span>*light-colors*</span> <span>(<span>make-colors <span>(<span><i><span>lambda</span></i> <span>(<span>v</span>)</span> <span>(<span>&gt; v 11</span>)</span></span>)</span></span>)</span></span>)</span></span></code></pre>

<p>Now we can build some arrays of colors.  We <em>could</em> use any of the 216 available
colors, but in practice we probably don't want to, because the darkest colors
will be too dark to read on a dark terminal, and vice versa for light terminals.
In a concession to practicality we'll generate two separate arrays of colors,
one that excludes colors whose total value is too dark and one excluding those
that are too light.</p>

<p>(Notice that <code>*dark-colors*</code> is "the array of colors which are suitable for use
on dark terminals" and not "the array of colors which are <em>themselves</em> dark".
Naming things is hard.)</p>

<p>Note that these arrays will be generated when the <code>batchcolor.lisp</code> file is
<code>load</code>ed, which is <em>when we build the binary</em>.  They <em>won't</em> be recomputed every
time you run the resulting binary.  In this case it doesn't really matter (the
arrays are small) but it's worth remembering in case you ever have some data you
want (or don't want) to compute at build time instead of run time.</p>

<pre><code><span><span>(<span><i><span>defparameter</span></i> <span>*explicits*</span> <span>(<span>make-hash-table <span>:test</span> #'equal</span>)</span></span>)</span></span></code></pre>

<p>Here we make a hash table to store the strings and colors for strings we want to
explicitly color (e.g. <code>ERR</code> should be red, <code>INFO</code> cyan).  The keys will be the
strings and values the RGB codes.</p>

<pre><code><span><span>(<span><i><span>defun</span></i> djb2 <span>(<span>string</span>)</span>
  <span>;; http://www.cse.yorku.ca/~oz/hash.html
</span>  <span>(<span>reduce <span>(<span><i><span>lambda</span></i> <span>(<span>hash c</span>)</span>
            <span>(<span>mod <span>(<span>+ <span>(<span>* 33 hash</span>)</span> c</span>)</span> <span>(<span>expt 2 64</span>)</span></span>)</span></span>)</span>
          string
          <span>:initial-value</span> 5381
          <span>:key</span> #'char-code</span>)</span></span>)</span>

<span>(<span><i><span>defun</span></i> find-color <span>(<span>string</span>)</span>
  <span>(<span>gethash string <span>*explicits*</span>
           <span>(<span><i><span>let</span></i> <span>(<span><span>(<span>colors <span>(<span><i><span>if</span></i> <span>*dark*</span> <span>*dark-colors*</span> <span>*light-colors*</span></span>)</span></span>)</span></span>)</span>
             <span>(<span>aref colors
                   <span>(<span>mod <span>(<span>+ <span>(<span>djb2 string</span>)</span> <span>*start*</span></span>)</span>
                        <span>(<span>length colors</span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span></code></pre>

<p>For strings that we want to explicitly color, we just look up the appropriate
code in <code>*explicits*</code> and return it.</p>

<p>Otherwise, we want to highlight unique matches in different colors.  There are
a number of different ways we could do this, for example: we could randomly pick
a color the first time we see a string and store it in a hash table for
subsequent encounters.  But this would mean we'd grow that hash table over time,
and one of the things I often use this utility for is <code>tail -f</code>ing long-running
processes when developing locally, so the memory usage would grow and grow until
the <code>batchcolor</code> process was restarted, which isn't ideal.</p>

<p>Instead, we'll hash each string with a simple <a href="http://www.cse.yorku.ca/~oz/hash.html">DJB hash</a> and use it to
index into the appropriate array of colors.  This ensures that identical matches
get identical colors, and avoids having to store every match we've ever seen.</p>

<p>There will be some collisions, but there's not much we can do about that with
only ~200 colors to work with.  We could have used 16-bit colors like
I mentioned before, but then we'd have to worry about picking colors different
enough for humans to easily tell apart, and for this simple utility I didn't
want to bother.</p>

<p>We'll talk about <code>*start*</code> later, ignore it for now (it's <code>0</code> by default).</p>

<pre><code><span><span>(<span><i><span>defun</span></i> ansi-color-start <span>(<span>color</span>)</span>
  <span>(<span>format nil <span>"~C[38;5;~Dm"</span> <span>#\Escape</span> color</span>)</span></span>)</span>

<span>(<span><i><span>defun</span></i> ansi-color-end <span>(<span></span>)</span>
  <span>(<span>format nil <span>"~C[0m"</span> <span>#\Escape</span></span>)</span></span>)</span>

<span>(<span><i><span>defun</span></i> print-colorized <span>(<span>string</span>)</span>
  <span>(<span>format <span>*standard-output*</span> <span>"~A~A~A"</span>
          <span>(<span>ansi-color-start <span>(<span>find-color string</span>)</span></span>)</span>
          string
          <span>(<span>ansi-color-end</span>)</span></span>)</span></span>)</span></span></code></pre>

<p>Next we have some functions to output the appropriate ANSI escapes to highlight
our matches.  We could use a library for this but it's only two lines.  <a href="http://xn--rpa.cc/irl/term.html">It's
not worth it</a>.</p>

<p>And now we have the beating heart of the program:</p>

<pre><code><span><span>(<span><i><span>defun</span></i> colorize-line <span>(<span>scanner line &amp;aux <span>(<span>start 0</span>)</span></span>)</span>
  <span>(<span>ppcre:do-scans <span>(<span>ms me rs re scanner line</span>)</span>
            <span>(<span><i><span>let*</span></i> <span>(<span><span>(<span>regs? <span>(<span>plusp <span>(<span>length rs</span>)</span></span>)</span></span>)</span>
           <span>(<span>starts <span>(<span><i><span>if</span></i> regs? <span>(<span>remove nil rs</span>)</span> <span>(<span>list ms</span>)</span></span>)</span></span>)</span>
           <span>(<span>ends   <span>(<span><i><span>if</span></i> regs? <span>(<span>remove nil re</span>)</span> <span>(<span>list me</span>)</span></span>)</span></span>)</span></span>)</span>
      <span>(<span>map nil <span>(<span><i><span>lambda</span></i> <span>(<span>word-start word-end</span>)</span>
                 <span>(<span>unless <span>(<span>&lt;= start word-start</span>)</span>
                   <span>(<span>error 'overlapping-groups</span>)</span></span>)</span>
                 <span>(<span>write-string line <span>*standard-output*</span> <span>:start</span> start <span>:end</span> word-start</span>)</span>
                 <span>(<span>print-colorized <span>(<span>subseq line word-start word-end</span>)</span></span>)</span>
                 <span>(<span>setf start word-end</span>)</span></span>)</span>
           starts ends</span>)</span></span>)</span></span>)</span>
  <span>(<span>write-line line <span>*standard-output*</span> <span>:start</span> start</span>)</span></span>)</span></span></code></pre>

<p><code>colorize-line</code> takes a CL-PPCRE scanner and a line, and outputs the line with
any of the desired matches colorized appropriately.  There are a few things to
note here.</p>

<p>First: if the regular expression contains any capturing groups, we'll only
colorize those parts of the match.  For example: if you run <code>batchcolor
'^&lt;(\\w+)&gt; '</code> to colorize the nicks in an IRC log, only the nicknames themselves
will be highlighted, not the surrounding angle brackets.  Otherwise, if there
are no capturing groups in the regular expression, we'll highlight the entire
match (as if there were one big capturing group around the whole thing).</p>

<p>Second: overlapping capturing groups are explicitly disallowed and
a <code>user-error</code> signaled if we notice any.  It's not clear what do to in this
case — if we match <code>((f)oo|(b)oo)</code> against <code>foo</code>, what should the output be?
Highlight <code>f</code> and <code>oo</code> in the same color?  In different colors?  Should the <code>oo</code>
be a different color than the <code>oo</code> in <code>boo</code>?  There's too many options with no
clear winner, so we'll just tell the user to be more clear.</p>

<p>To do the actual work we iterate over each match and print the non-highlighted
text before the match, then print the highlighted match.  Finally we print any
remaining text after the last match.</p>

<h3 id="s14-not-quite-top-level-interface"><a href="#s14-not-quite-top-level-interface">Not-Quite-Top-Level Interface</a></h3>

<pre><code><span><span>;;;; Run ----------------------------------------------------------------------
</span><span>(<span><i><span>defun</span></i> run% <span>(<span>scanner stream</span>)</span>
  <span>(<span><i><span>loop</span></i> <span>:for</span> line = <span>(<span>read-line stream nil</span>)</span>
        <span>:while</span> line
        <span>:do</span> <span>(<span>colorize-line scanner line</span>)</span></span>)</span></span>)</span>

<span>(<span><i><span>defun</span></i> run <span>(<span>pattern paths</span>)</span>
  <span>(<span><i><span>let</span></i> <span>(<span><span>(<span>scanner <span>(<span>handler-case <span>(<span>ppcre:create-scanner pattern</span>)</span>
                   <span>(<span>ppcre:ppcre-syntax-error <span>(<span>c</span>)</span>
                     <span>(<span>error 'malformed-regex <span>:underlying-error</span> c</span>)</span></span>)</span></span>)</span></span>)</span>
        <span>(<span>paths <span>(<span>or paths '<span>(<span><span>"-"</span></span>)</span></span>)</span></span>)</span></span>)</span>
    <span>(<span>dolist <span>(<span>path paths</span>)</span>
      <span>(<span><i><span>if</span></i> <span>(<span>string= <span>"-"</span> path</span>)</span>
        <span>(<span>run% scanner <span>*standard-input*</span></span>)</span>
        <span>(<span><i><span>with-open-file</span></i> <span>(<span>stream path <span>:direction</span> <span>:input</span></span>)</span>
          <span>(<span>run% scanner stream</span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span></code></pre>

<p>Here we have the not-quite-top-level interface to the program.  <code>run</code> takes
a pattern string and a list of paths and runs the colorization on each path.
This is safe to call interactively from the REPL, e.g. <code>(run "&lt;(\\w+)&gt;"
"foo.txt")</code>, so we can test without worrying about killing the Lisp process.</p>

<h3 id="s15-user-interface"><a href="#s15-user-interface">User Interface</a></h3>

<p>In the last chunk of the file we have the user interface.  There are a couple of
things to note here.</p>

<p>I'm using a command line argument parsing library I wrote myself: <a href="https://docs.stevelosh.com/adopt">Adopt</a>.
I won't go over exactly what all the various Adopt functions do.  Most of them
should be fairly easy to understand, but <a href="https://docs.stevelosh.com/adopt/usage/">check out the Adopt
documentation</a> for the full story if you're curious.</p>

<p>If you prefer another library (and there are quite a few around) feel free
to use it — it should be pretty easy to adapt this setup to a different library.
The only things you'd need to change would be the <code>toplevel</code> function and the
<code>build-manual.sh</code> script (if you even care about building <code>man</code> pages at all).</p>

<p>You might also notice that the user interface for the program is almost as much
code as the entire rest of the program.  This may seem strange, but I think it
makes a certain kind of sense.  When you're writing code to interface with an
external system, a messier and more complicated external system will usually
require more code than a cleaner and simpler external system.  A human brain is
probably the messiest and most complicated external system you'll ever have to
deal with, so it's worth taking the extra time and code to be especially careful
when writing an interface to it.</p>

<p>First we'll define a typical <code>-h</code>/<code>--help</code> option:</p>

<pre><code><span><span>(<span><i><span>defparameter</span></i> <span>*option-help*</span>
  <span>(<span>adopt:make-option 'help
    <span>:help</span> <span>"Display help and exit."</span>
    <span>:long</span> <span>"help"</span>
    <span>:short</span> <span>#\h</span>
    <span>:reduce</span> <span>(<span>constantly t</span>)</span></span>)</span></span>)</span></span></code></pre>

<p>Next we'll define a pair of options for enabling/disabling the Lisp debugger:</p>

<pre><code><span><span>(<span><i><span>adopt:defparameters</span></i> <span>(<span><span>*option-debug*</span> <span>*option-no-debug*</span></span>)</span>
  <span>(<span>adopt:make-boolean-options 'debug
    <span>:long</span> <span>"debug"</span>
    <span>:short</span> <span>#\d</span>
    <span>:help</span> <span>"Enable the Lisp debugger."</span>
    <span>:help-no</span> <span>"Disable the Lisp debugger (the default)."</span></span>)</span></span>)</span></span></code></pre>

<p>By default the debugger will be off, so any unexpected error will print
a backtrace to standard error and exit with a nonzero exit code.  This is the
default because if I add a <code>batchcolor</code> somewhere in a shell script, I probably
don't want to suddenly hang the entire script if something breaks.  But we still
want to be <em>able</em> to get into the debugger manually if something goes wrong.
This is Common Lisp — we don't have to settle for a stack trace or core dump, we
can have a real interactive debugger in the final binary.</p>

<p>Note how Adopt's <code>make-boolean-options</code> function creates <em>two</em> options here:</p>

<ul>
<li><code>-d</code>/<code>--debug</code> will enable the debugger.</li>
<li><code>-D</code>/<code>--no-debug</code> will disable the debugger.</li>
</ul>

<p>Even though <em>disabled</em> is the default, it's still important to have both
switches for boolean options like this.  If someone wants the debugger to be
<em>enabled</em> by default instead (along with some other configuration options), they
might have a shell alias like this:</p>

<pre><code>alias bcolor='batchcolor --debug --foo --bar'
</code></pre>

<p>But sometimes they might want to temporarily <em>disable</em> the debugger for a single
run.  Without a <code>--no-debug</code> option, they would have to run the vanilla
<code>batchcolor</code> and retype all the <em>other</em> options.  But having the <code>--no-debug</code>
option allows them to just say:</p>

<pre><code>bcolor --no-debug
</code></pre>

<p>This would expand to:</p>

<pre><code>batchcolor --debug --foo --bar --no-debug
</code></pre>

<p>The later option wins, and the user gets the behavior they expect.</p>

<p>Next we'll define some color-related options.  First an option to randomize the
colors each run, instead of always picking the same color for a particular
string, and then a toggle for choosing colors that work for dark or light
terminals:</p>

<pre><code><span><span>(<span><i><span>adopt:defparameters</span></i> <span>(<span><span>*option-randomize*</span> <span>*option-no-randomize*</span></span>)</span>
  <span>(<span>adopt:make-boolean-options 'randomize
    <span>:help</span> <span>"Randomize the choice of color each run."</span>
    <span>:help-no</span> <span>"Do not randomize the choice of color each run (the default)."</span>
    <span>:long</span> <span>"randomize"</span>
    <span>:short</span> <span>#\r</span></span>)</span></span>)</span>

<span>(<span><i><span>adopt:defparameters</span></i> <span>(<span><span>*option-dark*</span> <span>*option-light*</span></span>)</span>
  <span>(<span>adopt:make-boolean-options 'dark
    <span>:name-no</span> 'light
    <span>:long</span> <span>"dark"</span>
    <span>:long-no</span> <span>"light"</span>
    <span>:help</span> <span>"Optimize for dark terminals (the default)."</span>
    <span>:help-no</span> <span>"Optimize for light terminals."</span>
    <span>:initial-value</span> t</span>)</span></span>)</span></span></code></pre>

<p>The last option we'll define is <code>-e</code>/<code>--explicit</code>, to allow the user to select
an explicit color for a particular string:</p>

<pre><code><span><span>(<span><i><span>defun</span></i> parse-explicit <span>(<span>spec</span>)</span>
  <span>(<span>ppcre:register-groups-bind
      <span>(<span><span>(<span>#'parse-integer r g b</span>)</span> string</span>)</span>
      <span>(<span><span>"^([0-5]),([0-5]),([0-5]):(.+)$"</span> spec</span>)</span>
    <span>(<span><i><span>return-from</span></i> parse-explicit <span>(<span>cons string <span>(<span>rgb-code r g b</span>)</span></span>)</span></span>)</span></span>)</span>
  <span>(<span>error 'malformed-explicit <span>:spec</span> spec</span>)</span></span>)</span>

<span>(<span><i><span>defparameter</span></i> <span>*option-explicit*</span>
  <span>(<span>adopt:make-option 'explicit
    <span>:parameter</span> <span>"R,G,B:STRING"</span>
    <span>:help</span> <span>"Highlight STRING in an explicit color.  May be given multiple times."</span>
    <span>:manual</span> <span>(<span>format nil <span>"~
      Highlight STRING in an explicit color instead of randomly choosing one.  ~
      R, G, and B must be 0-5.  STRING is treated as literal string, not a regex.  ~
      Note that this doesn't automatically add STRING to the overall regex, you ~
      must do that yourself!  This is a known bug that may be fixed in the future."</span></span>)</span>
    <span>:long</span> <span>"explicit"</span>
    <span>:short</span> <span>#\e</span>
    <span>:key</span> #'parse-explicit
    <span>:reduce</span> #'adopt:collect</span>)</span></span>)</span></span></code></pre>

<p>Notice how we signal a <code>malformed-explicit</code> condition if the user gives us
mangled text.  This is a subtype of <code>user-error</code>, so the program will print the
error and exit even if the debugger is enabled.  We also include a slightly more
verbose description in the <code>man</code> page than the terse one in the <code>--help</code> text.</p>

<p>Next we write the main help and manual text, as well as some real-world
examples:</p>

<pre><code><span><span>(<span><i><span>adopt:define-string</span></i> <span>*help-text*</span>
  <span>"batchcolor takes a regular expression and matches it against standard ~
   input one line at a time.  Each unique match is highlighted in its own color.~@
   ~@
   If the regular expression contains any capturing groups, only those parts of ~
   the matches will be highlighted.  Otherwise the entire match will be ~
   highlighted.  Overlapping capturing groups are not supported."</span></span>)</span>

<span>(<span><i><span>adopt:define-string</span></i> <span>*extra-manual-text*</span>
  <span>"If no FILEs are given, standard input will be used.  A file of - stands for ~
   standard input as well.~@
   ~@
   Overlapping capturing groups are not supported because it's not clear what ~
   the result should be.  For example: what should ((f)oo|(b)oo) highlight when ~
   matched against 'foo'?  Should it highlight 'foo' in one color?  The 'f' in ~
   one color and 'oo' in another color?  Should that 'oo' be the same color as ~
   the 'oo' in 'boo' even though the overall match was different?  There are too ~
   many possible behaviors and no clear winner, so batchcolor disallows ~
   overlapping capturing groups entirely."</span></span>)</span>

<span>(<span><i><span>defparameter</span></i> <span>*examples*</span>
  '<span>(<span><span>(<span><span>"Colorize IRC nicknames in a chat log:"</span>
     . <span>"cat channel.log | batchcolor '&lt;(</span><span>\\</span><span>\\</span><span>w+)&gt;'"</span></span>)</span>
    <span>(<span><span>"Colorize UUIDs in a request log:"</span>
     . <span>"tail -f /var/log/foo | batchcolor '[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}'"</span></span>)</span>
    <span>(<span><span>"Colorize some keywords explicitly and IPv4 addresses randomly (note that the keywords have to be in the main regex too, not just in the -e options):"</span>
     . <span>"batchcolor 'WARN|INFO|ERR|(?:[0-9]{1,3}</span><span>\\</span><span>\\</span><span>.){3}[0-9]{1,3}' -e '5,0,0:ERR' -e '5,4,0:WARN' -e '2,2,5:INFO' foo.log"</span></span>)</span>
    <span>(<span><span>"Colorize earmuffed symbols in a Lisp file:"</span>
     . <span>"batchcolor '(?:^|[^*])([*][-a-zA-Z0-9]+[*])(?:$|[^*])' tests/test.lisp"</span></span>)</span></span>)</span></span>)</span></span></code></pre>

<p>Finally we can wire everything together in the main Adopt interface:</p>

<pre><code><span><span>(<span><i><span>defparameter</span></i> <span>*ui*</span>
  <span>(<span>adopt:make-interface
    <span>:name</span> <span>"batchcolor"</span>
    <span>:usage</span> <span>"[OPTIONS] REGEX [FILE...]"</span>
    <span>:summary</span> <span>"colorize regex matches in batches"</span>
    <span>:help</span> <span>*help-text*</span>
    <span>:manual</span> <span>(<span>format nil <span>"~A~2%~A"</span> <span>*help-text*</span> <span>*extra-manual-text*</span></span>)</span>
    <span>:examples</span> <span>*examples*</span>
    <span>:contents</span> <span>(<span>list
                <span>*option-help*</span>
                <span>*option-debug*</span>
                <span>*option-no-debug*</span>
                <span>(<span>adopt:make-group 'color-options
                                  <span>:title</span> <span>"Color Options"</span>
                                  <span>:options</span> <span>(<span>list <span>*option-randomize*</span>
                                                 <span>*option-no-randomize*</span>
                                                 <span>*option-dark*</span>
                                                 <span>*option-light*</span>
                                                 <span>*option-explicit*</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span></code></pre>

<p>All that's left to do is the top-level function that will be called when the
binary is executed.</p>

<h3 id="s16-top-level-interface"><a href="#s16-top-level-interface">Top-Level Interface</a></h3>

<p>Before we write <code>toplevel</code> we've got a couple of helpers:</p>

<pre><code><span><span>(<span><i><span>defmacro</span></i> exit-on-ctrl-c <span>(<span>&amp;body body</span>)</span>
  `<span>(<span>handler-case <span>(<span><i><span>with-user-abort:with-user-abort</span></i> <span>(<span><i><span>progn</span></i> ,@body</span>)</span></span>)</span>
     <span>(<span>with-user-abort:user-abort <span>(<span></span>)</span> <span>(<span>adopt:exit 130</span>)</span></span>)</span></span>)</span></span>)</span>

<span>(<span><i><span>defun</span></i> configure <span>(<span>options</span>)</span>
  <span>(<span><i><span>loop</span></i> <span>:for</span> <span>(<span>string . rgb</span>)</span> <span>:in</span> <span>(<span>gethash 'explicit options</span>)</span>
        <span>:do</span> <span>(<span>setf <span>(<span>gethash string <span>*explicits*</span></span>)</span> rgb</span>)</span></span>)</span>
  <span>(<span>setf <span>*start*</span> <span>(<span><i><span>if</span></i> <span>(<span>gethash 'randomize options</span>)</span>
                  <span>(<span>random 256 <span>(<span>make-random-state t</span>)</span></span>)</span>
                  0</span>)</span>
        <span>*dark*</span> <span>(<span>gethash 'dark options</span>)</span></span>)</span></span>)</span></span></code></pre>

<p>Our <code>toplevel</code> function looks much like the one in the skeleton, but fleshed out
a bit more:</p>

<pre><code><span><span>(<span><i><span>defun</span></i> toplevel <span>(<span></span>)</span>
  <span>(<span>sb-ext:disable-debugger</span>)</span>
  <span>(<span>exit-on-ctrl-c
    <span>(<span>multiple-value-bind <span>(<span>arguments options</span>)</span> <span>(<span>adopt:parse-options-or-exit <span>*ui*</span></span>)</span>
      <span>(<span>when <span>(<span>gethash 'debug options</span>)</span>
        <span>(<span>sb-ext:enable-debugger</span>)</span></span>)</span>
      <span>(<span>handler-case
          <span>(<span><i><span>cond</span></i>
            <span>(<span><span>(<span>gethash 'help options</span>)</span> <span>(<span>adopt:print-help-and-exit <span>*ui*</span></span>)</span></span>)</span>
            <span>(<span><span>(<span>null arguments</span>)</span> <span>(<span>error 'missing-regex</span>)</span></span>)</span>
            <span>(<span>t <span>(<span>destructuring-bind <span>(<span>pattern . files</span>)</span> arguments
                 <span>(<span>configure options</span>)</span>
                 <span>(<span>run pattern files</span>)</span></span>)</span></span>)</span></span>)</span>
        <span>(<span>user-error <span>(<span>e</span>)</span> <span>(<span>adopt:print-error-and-exit e</span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span></code></pre>

<p>This <code>toplevel</code> has a few extra bits beyond the skeletal example.</p>

<p>First, we disable the debugger immediately, and then re-enable it later if the
user asks us to.  We want to keep it disabled until <em>after</em> argument parsing
because we can't know whether the user wants it or not until we parse the
arguments.</p>

<p>Instead of just blindly running <code>run</code>, we check for <code>--help</code> and print it if
desired.  We also validate that the user passes the correct amount of arguments,
signaling a subtype of <code>user-error</code> if they don't.  Assuming everything looks
good we handle the configuration, call <code>run</code>, and that's it!</p>

<p>Running <code>make</code> generates <code>bin/batchcolor</code> and <code>man/man1/batchcolor.1</code>, and we
can view our log files in beautiful color.</p>

<h2 id="s17-more-information"><a href="#s17-more-information">More Information</a></h2>

<p>I hope this overview was helpful.  This has worked for me, but Common Lisp is
a flexible language, so if you want to use this layout as a starting point and
modify it for your own needs, go for it!</p>

<p>If you want to see some more examples you can find them in <a href="https://hg.stevelosh.com/dotfiles/file/tip/lisp">my dotfiles
repository</a>.  Some of the more
fun ones include:</p>

<ul>
<li><code>weather</code> for displaying the weather over the next few hours so I can tell if
  I need a jacket or umbrella before I go out for a walk.</li>
<li><code>retry</code> to retry shell commands if they fail, with options for how many times
  to retry, strategies for waiting/backing off on failure, etc.</li>
<li><code>pick</code> to interactively filter the output of one command into another
  (inspired by the <code>pick</code> program in "The UNIX Programming Environment" but with
  more options).</li>
</ul>

<p>The approach I laid out in this post works well for small, single-file programs.
If you're creating a larger program you'll probably want to move to a full ASDF
system in its own directory/repository.  My friend Ian <a href="http://atomized.org/blog/2020/07/06/common-lisp-in-practice/">wrote a post about
that</a> which you
might find interesting.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fighting API bots with Cloudflare's invisible turnstile (125 pts)]]></title>
            <link>https://www.troyhunt.com/fighting-api-bots-with-cloudflares-invisible-turnstile/</link>
            <guid>37400018</guid>
            <pubDate>Wed, 06 Sep 2023 00:58:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.troyhunt.com/fighting-api-bots-with-cloudflares-invisible-turnstile/">https://www.troyhunt.com/fighting-api-bots-with-cloudflares-invisible-turnstile/</a>, See on <a href="https://news.ycombinator.com/item?id=37400018">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
<p>There's a "hidden" API on HIBP. Well, it's not "hidden" insofar as it's easily discoverable if you watch the network traffic from the client, but it's not meant to be called directly, rather only via the web app. It's called "unified search" and it looks just like this:</p><figure><img src="https://www.troyhunt.com/content/images/2023/03/image-20.png" alt="" loading="lazy" width="1441" height="1031" srcset="https://www.troyhunt.com/content/images/size/w600/2023/03/image-20.png 600w, https://www.troyhunt.com/content/images/size/w1000/2023/03/image-20.png 1000w, https://www.troyhunt.com/content/images/2023/03/image-20.png 1441w" sizes="(min-width: 720px) 720px"></figure><p>It's been there in one form or another since day 1 (so almost a decade now), and it serves a sole purpose: to perform searches from the home page. That is all - <em>only from the home page</em>. It's called asynchronously from the client without needing to post back the entire page and by design, it's super fast and super easy to use. Which is bad. Sometimes.</p><p>To understand why it's bad we need to go back in time all the way to when <a href="https://www.troyhunt.com/have-i-been-pwned-you-can-now-ask-api/">I first launched the API that was intended to be consumed programmatically by other people's services</a>. That was easy, because it was basically just documenting the API that sat behind the home page of the website already, the predecessor to the one you see above. And then, unsurprisingly in retrospect, <a href="https://www.troyhunt.com/the-have-i-been-pwned-api-rate-limiting-and-commercial-use/">it started to be abused so I had to put a rate limit on it</a>. Problem is, that was a very rudimentary IP-based rate limit and it could be circumvented by someone with enough IPs, so fast forward a bit further and <a href="https://www.troyhunt.com/authentication-and-the-have-i-been-pwned-api/">I put auth on the API which required a nominal payment to access it</a>. At the same time, that unified search endpoint was created and home page searches updated to use that rather than the publicly documented API. So, 2 APIs with 2 different purposes.</p><p>The primary objective for putting a price on the public API was to tackle abuse. And it did - it stopped it <em>dead</em>. By attaching a rate limit to a key that required a credit card to purchase it, abusive practices (namely enumerating large numbers of email addresses) disappeared. This wasn't just about putting a <em>financial </em>cost to queries, it was about putting an <em>identity</em> cost to them; people are reluctant to start doing nasty things with a key traceable back to their own payment card! Which is why they turned their attention to the non-authenticated, non-documented unified search API.</p><p>Let's look at a 3 day period of requests to that API earlier this year, keeping in mind this should only ever be requested organically by humans performing searches from the home page:</p><figure><img src="https://www.troyhunt.com/content/images/2023/03/image-12.png" alt="" loading="lazy" width="1200" height="645" srcset="https://www.troyhunt.com/content/images/size/w600/2023/03/image-12.png 600w, https://www.troyhunt.com/content/images/size/w1000/2023/03/image-12.png 1000w, https://www.troyhunt.com/content/images/2023/03/image-12.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>This is far from organic usage with requests peaking at 121.3k in just 5 minutes. Which poses an interesting question: <strong>how do you create an API that should only be consumed asynchronously from a web page and never programmatically via a script?</strong> You could chuck a CAPTCHA on the front page and require that be solved first but let's face it, that's not a pleasant user experience. Rate limit requests by IP? See the earlier problem with that. Block UA strings? Pointless, because they're easily randomised. Rate limit an <a href="https://www.cloudflare.com/learning/network-layer/what-is-an-autonomous-system/?ref=troyhunt.com">ASN</a>? It gets you part way there, but what happens when you get a genuine flood of traffic because the site has hit the mainstream news? <a href="https://www.troyhunt.com/brief-lessons-on-handling-huge-traffic-spikes/">It happens</a>.</p><p>Over the years, I've played with all sorts of combinations of firewall rules based on parameters such as geolocations with incommensurate numbers of requests to their populations, <a href="https://developers.cloudflare.com/bots/concepts/ja3-fingerprint/?ref=troyhunt.com">JA3 fingerprints</a> and, of course, the parameters mentioned above. Based on the chart above these obviously didn't catch all the abusive traffic, but they did catch a significant portion of it:</p><figure><img src="https://www.troyhunt.com/content/images/2023/03/image-13.png" alt="" loading="lazy" width="1075" height="756" srcset="https://www.troyhunt.com/content/images/size/w600/2023/03/image-13.png 600w, https://www.troyhunt.com/content/images/size/w1000/2023/03/image-13.png 1000w, https://www.troyhunt.com/content/images/2023/03/image-13.png 1075w" sizes="(min-width: 720px) 720px"></figure><p>If you combine it with the previous graph, that's about a third of all the bad traffic in that period or in other words, two thirds of the bad traffic was still getting through. There had to be a better way, which brings us to <a href="https://developers.cloudflare.com/turnstile/?ref=troyhunt.com">Cloudflare's Turnstile</a>:</p><blockquote>With Turnstile, we adapt the actual challenge outcome to the individual visitor or browser. First, we run a series of small non-interactive JavaScript challenges gathering more signals about the visitor/browser environment. Those challenges include, proof-of-work, proof-of-space, probing for web APIs, and various other challenges for detecting browser-quirks and human behavior. As a result, we can fine-tune the difficulty of the challenge to the specific request and avoid ever showing a visual puzzle to a user.</blockquote><p>"Avoid ever showing a visual puzzle to a user" is a polite way of saying they avoid the sucky UX of CAPTCHA. Instead, Turnstile offers the ability to issue a "non-interactive challenge" which implements the sorts of clever techniques mentioned above and as it relates to this blog post, that can be <strong>an invisible non-interactive challenge</strong>. This is one of <a href="https://developers.cloudflare.com/turnstile/reference/widget-types/?ref=troyhunt.com">3 different widget types</a> with the others being <strong>a visible non-interactive challenge</strong> and a <strong>non-<em>intrusive</em> interactive challenge</strong>. For my purposes on HIBP, I wanted a zero-friction implementation nobody saw, hence the invisible approach. Here's how it works:</p><figure><img src="https://www.troyhunt.com/content/images/2023/08/turnstile-overview_hu857217e6cfe3055a024af7c1505ed0dc_210985_3757x2700_resize_q75_box_3-3bb896c3.png" alt="" loading="lazy" width="2000" height="1437" srcset="https://www.troyhunt.com/content/images/size/w600/2023/08/turnstile-overview_hu857217e6cfe3055a024af7c1505ed0dc_210985_3757x2700_resize_q75_box_3-3bb896c3.png 600w, https://www.troyhunt.com/content/images/size/w1000/2023/08/turnstile-overview_hu857217e6cfe3055a024af7c1505ed0dc_210985_3757x2700_resize_q75_box_3-3bb896c3.png 1000w, https://www.troyhunt.com/content/images/size/w1600/2023/08/turnstile-overview_hu857217e6cfe3055a024af7c1505ed0dc_210985_3757x2700_resize_q75_box_3-3bb896c3.png 1600w, https://www.troyhunt.com/content/images/size/w2400/2023/08/turnstile-overview_hu857217e6cfe3055a024af7c1505ed0dc_210985_3757x2700_resize_q75_box_3-3bb896c3.png 2400w"></figure><p>Get it? Ok, let's break it down further as it relates to HIBP, starting with when the front page first loads and it embeds the Turnstile widget from Cloudflare:</p><pre><code>&lt;script src="https://challenges.cloudflare.com/turnstile/v0/api.js" async defer&gt;&lt;/script&gt;</code></pre><p>The widget takes responsibility for running the non-interactive challenge and returning a token. This needs to be persisted somewhere on the client side which brings us to <a href="https://developers.cloudflare.com/turnstile/get-started/client-side-rendering/?ref=troyhunt.com">embedding the widget</a>:</p><pre><code>&lt;div&nbsp;ID="turnstileWidget"&nbsp;class="cf-turnstile"&nbsp;data-sitekey="0x4AAAAAAADY3UwkmqCvH8VR"&nbsp;data-callback="turnstileCompleted"&gt;&lt;/div&gt;</code></pre><p>Per the docs in that link, the main thing here is to have an element with the "cf-turnstile" class set on it. If you happen to go take a look at the HIBP HTML source right now, you'll see that element precisely as it appears in the code block above. However, check it out in your browser's dev tools so you can see how it renders in the DOM and it will look more like this:</p><figure><img src="https://www.troyhunt.com/content/images/2023/08/image-4.png" alt="" loading="lazy" width="968" height="204" srcset="https://www.troyhunt.com/content/images/size/w600/2023/08/image-4.png 600w, https://www.troyhunt.com/content/images/2023/08/image-4.png 968w"></figure><p>Expand that DIV tag and you'll find a whole bunch more content set as a result of loading the widget, but that's not relevant right now. What's important is the data-token attribute because that's what's going to prove you're not a bot when you run the search. How you implement this from here is up to you, but what HIBP does is picks up the token and sets it in the "cf-turnstile-response" header then sends it along with the request when that unified search endpoint is called:</p><figure><img src="https://www.troyhunt.com/content/images/2023/08/image-6.png" alt="" loading="lazy" width="948" height="582" srcset="https://www.troyhunt.com/content/images/size/w600/2023/08/image-6.png 600w, https://www.troyhunt.com/content/images/2023/08/image-6.png 948w"></figure><p>So, at this point we've issued a challenge, the browser has solved the challenge and received a token back, now that token has been sent along with the request for the actual resource the user wanted, in this case the unified search endpoint. The final step is to validate the token and for this I'm using a Cloudflare worker. <a href="https://www.troyhunt.com/tag/cloudflare/">I've written a lot about workers in the past</a> so here's the short pitch: it's code that runs in each one of Cloudflare's 300+ edge nodes around the world and can inspect and modify requests and responses on the fly. I already had a worker to do some other processing on unified search requests, so I just added the following:</p><pre><code>const token = request.headers.get('cf-turnstile-response');

if (token === null) {
    return new Response('Missing Turnstile token', { status: 401 });
}

const ip = request.headers.get('CF-Connecting-IP');

let formData = new FormData();
formData.append('secret', '[secret key goes here]');
formData.append('response', token);
formData.append('remoteip', ip);

const turnstileUrl = 'https://challenges.cloudflare.com/turnstile/v0/siteverify';
const result = await fetch(turnstileUrl, {
    body: formData,
    method: 'POST',
});
const outcome = await result.json();

if (!outcome.success) {
    return new Response('Invalid Turnstile token', { status: 401 });
}</code></pre><p>That should be pretty self-explanatory and you can find the docs for this on <a href="https://developers.cloudflare.com/turnstile/get-started/server-side-validation/?ref=troyhunt.com">Cloudflare's server-side validation page</a> which goes into more detail, but in essence, it does the following:</p><ol><li>Gets the token from the request header and rejects the request if it doesn't exist</li><li>Sends the token, your secret key and the user's IP along to Turnstile's "siteverify" endpoint</li><li>If the token is not successfully verified then return 401 "Unauthorised", otherwise continue with the request</li></ol><p>And because this is all done in a Cloudflare worker, any of those 401 responses never even touch the origin. Not only do I not need to process the request in Azure, the person attempting to abuse my API gets a nice speedy response directly from an edge node near them 🙂</p><p>So, what does this mean for bots? If there's no token then they get booted out right away. If there's a token but it's not valid then they get booted out at the end. But can't they just take a previously generated token and use that? Well, yes, but only once:</p><blockquote>If the same response is presented twice, the second and each subsequent request will generate an error stating that the response has already been consumed.</blockquote><p>And remember, a real browser had to generate that token in the first place so it's not like you can just automate the process of token generation then throw it at the API above. (Sidenote: that server-side validation link includes how to handle idempotency, for example when retrying failed requests.) But what if a <em>real human</em> fails the verification? That's entirely up to you but in HIBP's case, that 401 response causes a fallback to a full page post back which then implements other controls, for example an interactive challenge.</p><p>Time for graphs and stats, starting with the one in the hero image of this page where we can see the number of times Turnstile was issued and how many times it was solved over the week prior to publishing this post:</p><figure><img src="https://www.troyhunt.com/content/images/2023/08/2023-08-21_16-38-03.png"></figure><p>That's a 91% hit rate of solved challenges which is great. That remaining 9% is either humans with a false positive or... bots getting rejected 😎 </p><p>More graphs, this time how many requests to the unified search page were rejected by Turnstile:</p><figure><img src="https://www.troyhunt.com/content/images/2023/08/image-9.png" alt="" loading="lazy" width="1110" height="834" srcset="https://www.troyhunt.com/content/images/size/w600/2023/08/image-9.png 600w, https://www.troyhunt.com/content/images/size/w1000/2023/08/image-9.png 1000w, https://www.troyhunt.com/content/images/2023/08/image-9.png 1110w"></figure><p>That 990k number doesn't marry up with the 476k unsolved ones from before because they're 2 different things: the unsolved challenges are when the Turnstile widget is loaded but not solved (hopefully due to it being a bot rather than a false positive), whereas the 401 responses to the API is when a successful (and previously unused) Turnstile token isn't in the header. This could be because the token wasn't present, wasn't solved or had already been used. You get more of a sense of how many of these rejected requests were legit humans when you drill down into attributes like <a href="https://developers.cloudflare.com/bots/concepts/ja3-fingerprint/?ref=troyhunt.com">the JA3 fingerprints</a>:</p><figure><img src="https://www.troyhunt.com/content/images/2023/08/image-10.png" alt="" loading="lazy" width="540" height="238"></figure><p>In other words, of those 990k failed requests, almost 40% of them were from the same 5 clients. Seems legit 🤔</p><p>And about a third were from clients with an identical UA string:</p><figure><img src="https://www.troyhunt.com/content/images/2023/08/image-11.png" alt="" loading="lazy" width="538" height="238"></figure><p>And so on and so forth. The point being that the number of actual legitimate requests from end users that were inconvenienced by Turnstile would be exceptionally small, almost certainly a very low single-digit percentage. I'll never know exactly because bots obviously attempt to emulate legit clients and sometimes legit clients look like bots and if we could easily solve this problem then we wouldn't need Turnstile in the first place! Anecdotally, that very small false positive number stacks up as people tend to complain pretty quickly when something isn't optimal, and I implemented this all the way back in March. Yep, 5 months ago, and I've waited this long to write about it just to be confident it's actually working. Over 100M Turnstile challenges later, I'm confident it is - I've not seen a single instance of abnormal traffic spikes to the unified search endpoint since rolling this out. What I did see initially though is a lot of this sort of thing:</p><figure><img src="https://www.troyhunt.com/content/images/2023/03/image-16.png" alt="" loading="lazy" width="865" height="838" srcset="https://www.troyhunt.com/content/images/size/w600/2023/03/image-16.png 600w, https://www.troyhunt.com/content/images/2023/03/image-16.png 865w" sizes="(min-width: 720px) 720px"></figure><p>By now it should be pretty obvious what's going on here, and it should be equally obvious that it didn't work out real well for them 😊</p><p>The bot problem is a hard one for those of us building services because we're continually torn in different directions. We want to build a slick UX for humans but an obtrusive one for bots. We want services to be easily consumable, but only in the way we intend them to... which might be by the good bots playing by the rules!</p><p>I don't know exactly what Cloudflare is doing in that challenge and I'll be honest, I don't even know what a "proof-of-space" is. But the point of using a service like this is that <em>I don't need to know!</em> What I do know is that Cloudflare sees about 20% of the internet's traffic and because of that, they're in an unrivalled position to look at a request and make a determination on its legitimacy.</p><p>If you're in my shoes, <a href="https://developers.cloudflare.com/turnstile/?ref=troyhunt.com">go and give Turnstile a go</a>. And if you want to consume data from HIBP, go and check out <a href="https://haveibeenpwned.com/API/v3?ref=troyhunt.com">the official API docs</a>, the uh, unified search doesn't work real well for you any more 😎</p>
<section>
<a href="https://www.troyhunt.com/tag/cloudflare/">Cloudflare</a>
<a href="https://www.troyhunt.com/tag/have-i-been-pwned-3f/">Have I Been Pwned</a>
</section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Can LLMs learn from a single example? (385 pts)]]></title>
            <link>https://www.fast.ai/posts/2023-09-04-learning-jumps/</link>
            <guid>37399873</guid>
            <pubDate>Wed, 06 Sep 2023 00:40:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fast.ai/posts/2023-09-04-learning-jumps/">https://www.fast.ai/posts/2023-09-04-learning-jumps/</a>, See on <a href="https://news.ycombinator.com/item?id=37399873">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">




<main id="quarto-document-content">
<blockquote>
<p>Summary: recently while fine-tuning a large language model (LLM) on multiple-choice science exam questions, we observed some highly unusual training loss curves. In particular, it appeared the model was able to rapidly memorize examples from the dataset after seeing them just once. This astonishing feat contradicts most prior wisdom about neural network sample efficiency. Intrigued by this result, we conducted a series of experiments to validate and better understand this phenomenon. It’s early days, but the experiments support the hypothesis that the models are able to rapidly remember inputs. This might mean we have to re-think how we train and use LLMs.</p>
</blockquote>
<section id="how-neural-networks-learn">
<h2 data-anchor-id="how-neural-networks-learn">How neural networks learn</h2>
<p>We train neural network classifiers by showing them examples of inputs and outputs, and they learn to predict outputs based on inputs. For example, we show examples of pictures of dogs and cats, along with the breed of each, and they learn to guess the breed from the image. To be more precise, for a list of possible breeds, they output their guess as to the probability of each breed. If it’s unsure, it will guess a roughly equal probability of each possible breed, and if it’s highly confident, it will guess a nearly 1.0 probability of its predicted breed.</p>
<p>The training process consists of every image in a <em>training set</em> being shown to the network, along with the correct label. A pass through all the input data is called an “epoch”. We have to provide many examples of the training data for the model to learn effectively.</p>
<p>During training the neural network attempts to reduce the <em>loss</em>, which is (roughly speaking) a measure of how often the model is wrong, with highly confident wrong predictions penalised the most, and vise versa. We calculate the loss after each batch for the training set, and from time to time (often at the end of each epoch) we also calculated the loss for a bunch of inputs the model does <em>not</em> get to learn from – this is the “validation set”. Here’s what that looks like in practice when we train for 11 epochs:</p>
<div>
<figure>
<p><img src="https://www.fast.ai/posts/2023-09-04-learning-jumps/2023-09-04-09-00-35.png" width="350"></p>
<figcaption>Loss chart from training on pet breeds</figcaption>
</figure>
</div>
<p>As you see, the training loss gradually (and bumpily) improves relatively quickly, slowing down over time, and the validation loss improves more slowly (and would eventually flatten out entirely, and then eventually get worse, if trained for longer).</p>
<p>You can’t see from the chart where epochs start and stop, because it takes many epochs before a model learns what any particular image looks like. This has been a fundamental constraint of neural networks throughout the decades they’ve been developed – they take an awfully long time to learn anything! It’s actually an <a href="https://www.sciencedirect.com/science/article/pii/S1364661323002036">area of active research</a> about why neural nets are so “sample inefficient”, especially compared to how children learn.</p>
</section>
<section id="a-very-odd-loss-curve">
<h2 data-anchor-id="a-very-odd-loss-curve">A very odd loss curve</h2>
<p>We have recently been working on the <a href="https://www.kaggle.com/competitions/kaggle-llm-science-exam">Kaggle LLM Science Exam</a> competition, which “challenges participants to answer difficult science-based questions written by a Large Language Model”. For instance, here’s the first question:</p>
<div>
<p><em>Which of the following statements accurately describes the impact of Modified Newtonian Dynamics (MOND) on the observed “missing baryonic mass” discrepancy in galaxy clusters?</em></p>
<ol type="A">
<li>MOND is a theory that reduces the observed missing baryonic mass in galaxy clusters by postulating the existence of a new form of matter called “fuzzy dark matter.”</li>
<li>MOND is a theory that increases the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 20.</li>
<li>MOND is a theory that explains the missing baryonic mass in galaxy clusters that was previously considered dark matter by demonstrating that the mass is in the form of neutrinos and axions.</li>
<li>MOND is a theory that reduces the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 2.</li>
<li>MOND is a theory that eliminates the observed missing baryonic mass in galaxy clusters by imposing a new mathematical formulation of gravity that does not require the existence of dark matter.</li>
</ol>
</div>
<p>For those playing along at home, the correct answer, apparently, is D.</p>
<p>Thankfully, we don’t have to rely on our knowledge of Modified Newtonian Dynamics to answer these questions – instead, we are tasked to train a model to answer these questions. When we submit our model to Kaggle, it will be tested against thousands of “held out” questions that we don’t get to see.</p>
<p>We trained our model for 3 epochs on a <a href="https://www.kaggle.com/code/radek1/new-dataset-deberta-v3-large-training">big dataset of questions</a> created by our friend Radek Osmulski, and saw the following most unexpected training loss curve:</p>
<div>
<figure>
<p><img src="https://www.fast.ai/posts/2023-09-04-learning-jumps/2023-09-04-09-33-39.png" width="500"></p>
<figcaption>Loss chart from 3 epoch training on Kaggle comp</figcaption>
</figure>
</div>
<p>The problem here is that you can clearly see the end of each epoch - there’s a sudden downwards jump in loss. We’ve seen similar loss curves before, and they’ve always been due to a bug. For instance, it’s easy to accidentally have the model continue to learn when evaluating the validation set – such that after validation the model suddenly appears much better. So we set out to look for the bug in our training process. We were using Hugging Face’s <code>Trainer</code>, so we guessed there must be a bug in that.</p>
<p>Whilst we began stepping through the code, we also asked fellow open source developers on the <a href="https://discord.gg/k36qjUxyJC">Alignment Lab AI Discord</a> if they’ve seen similar odd training curves, and pretty much everyone said “yes”. But everyone who responded was using Trainer as well, which seemed to support our theory of a bug in that library.</p>
<p>But then <span data-cites="anton">@anton</span> on Discord told us he was seeing this curve with his own simple custom training loop:</p>
<div>
<figure>
<p><img src="https://www.fast.ai/posts/2023-09-04-learning-jumps/2023-09-04-09-39-06.png" width="500"></p>
<figcaption>Anton’s custom loop training loss chart</figcaption>
</figure>
</div>
<p>…and he also showed us this accompanying extremely surprising validation loss curve:</p>
<div>
<figure>
<p><img src="https://www.fast.ai/posts/2023-09-04-learning-jumps/2023-09-04-09-41-02.png" width="500"></p>
<figcaption>Anton’s custom loop validation loss chart</figcaption>
</figure>
</div>
<p>Then we started hearing from more and more Discord friends that they had seen similar strange behavior, including when not using Trainer. We wondered if it was some oddity specific to the <a href="https://arxiv.org/abs/2106.09685v2">LoRA</a> approach we were using, but we heard from folks seeing the same pattern when doing full fine-tuning too. In fact, it was basically common knowledge in the LLM fine-tuning community that this is just how things go when you’re doing this kind of work!…</p>
</section>
<section id="digging-deeper">
<h2 data-anchor-id="digging-deeper">Digging deeper</h2>
<p>The hypothesis that we kept hearing from open source colleagues is that that these training curves were actually showing overfitting. This seemed, at first, quite impossible. It would imply that the model was learning to recognise inputs from just one or two examples. If you look back at that first curve we showed, you can see the loss diving from 0.8 to 0.5 after the first epoch, and then from 0.5 to under 0.2 after the second. Furthermore, <em>during</em> each of the second and third epochs it wasn’t really learning anything new at all. So, other than its initial learning during the beginning of the first epoch, nearly all the apparent learning was (according to this theory) memorization of the training set occurring with only 3 examples per row! Furthermore, for each question, it only gets a tiny amount of signal: how its guess as to the answer compared to the true label.</p>
<p>We tried out an experiment – we trained our Kaggle model for two epochs, using the following learning rate schedule:</p>
<div>
<figure>
<p><img src="https://www.fast.ai/posts/2023-09-04-learning-jumps/2023-09-04-10-05-56.png" width="500"></p>
<figcaption>Learning rate schedule</figcaption>
</figure>
</div>
<p>Nowadays this kind of schedule is not that common, but it’s an approach that saw a lot of success after it was created by Leslie Smith, who discussed it in his 2015 paper <a href="https://arxiv.org/abs/1506.01186">Cyclical Learning Rates for Training Neural Networks</a>.</p>
<p>And here’s the crazy-looking training and validation loss curves we saw as a result:</p>
<div>
<figure>
<p><img src="https://www.fast.ai/posts/2023-09-04-learning-jumps/2023-09-04-10-09-29.png" width="500"></p>
<figcaption>Result of 2-epoch CLR experiment</figcaption>
</figure>
</div>
<p>The only thing that we have come up with (so far!) that fully explains this picture is that the hypothesis is correct: the model is rapidly learning to recognise examples even just seeing them once. Let’s work through each part of the loss curve in turn…</p>
<p>Looking at the first epoch, this looks like a very standard loss curve. We have the learning rate warming up over the first 10% of the epoch, and then gradually decreasing following a cosine schedule. Once the LR comes up to temperature, the training and validation loss rapidly decrease, and then they both slow down as the LR decreases and the “quick wins” are captured.</p>
<p>The second epoch is where it gets interested. We’re not re-shuffling the dataset at the start of the epoch, so those first batches of the second epoch are when the learning rate was still warming up. That’s why we don’t see an immediate step-change like we did from epoch 2 to 3 in the very first loss curve we showed – these batches were only seen when the LR was low, so it couldn’t learn much.</p>
<p>Towards the end of that first 10% of the epoch, the training loss plummets, because the LR was high when these batches were seen during the first epoch, and the model has learned what they look like. The model quickly learns that it can very confidentally guess the correct answer.</p>
<p>But during this time, validation loss suffers. That’s because although the model is getting very confident, it’s not actually getting any better at making predictions. It has simply memorised the dataset, but isn’t improving at generalizing. Over-confident predictions cause validation loss to get worse, because the loss function penalizes more confident errors higher.</p>
<p>The end of the curve is where things get particularly interesting. The training loss starts getting worse – and that really never ought to happen! In fact, neither of us remember ever seeing such a thing before when using a reasonable LR.</p>
<p>But actually, this makes perfect sense under the memorization hypothesis: these are the batches that the model saw at a time when the LR had come back down again, so it wasn’t able to memorize them as effectively. But the model is still over-confident, because it has just got a whole bunch of batches nearly perfectly correct, and hasn’t yet adjusted to the fact that it’s now seeing batches that it didn’t have a chance to learn so well.</p>
<p>It gradually recalibrates to a more reasonable level of confidence, but it takes a while, because the LR is getting lower and lower. As it recalibrates, the validation loss comes back down again.</p>
<p>For our next experiment, we tried <a href="https://arxiv.org/abs/1803.09820">1cycle training</a> over 3 epochs, instead of CLR – that is, we did a single LR warmup for 10% of batches at the start of training, and then decayed the LR over the remaining batches following a cosine schedule. Previously, we did a separate warmup and decay cycle for each epoch. Also, we increased the LoRA rank, resulting in slower learning. Here’s the resulting loss curve:</p>
<div>
<figure>
<p><img src="https://www.fast.ai/posts/2023-09-04-learning-jumps/2023-09-06-06-32-18.png" width="500"></p>
<figcaption>1cycle training over 3 epochs</figcaption>
</figure>
</div>
<p>The shape largely follows what we’d expect, based on the previous discussion, except for one thing: the validation loss does not jump up at epoch 2 – it’s not until epoch 3 that we see that jump. However previously the training loss was around 0.2 by the 2nd epoch, which is only possible when it’s making highly confident predictions. In the 1cycle example it doesn’t make such confident predictions until the third epoch, and we don’t see the jump in validation loss until that happens.</p>
<p>It’s important to note that the validation <em>loss</em> getting worse doesn’t mean that we’re over-fitting in practice. What we generally care about is <em>accuracy</em>, and it’s fine if the model is over-confident. In the Kaggle competition the metric used for the leaderboard is <a href="https://www.fast.ai/posts/2023-09-04-learning-jumps/www.kaggle.com/competitions/kaggle-llm-science-exam/overview/evaluation">Mean Average Precision @ 3 (MAP@3)</a>, which is the accuracy of the ranked top-3 multiple-choice predictions made my the model. Here’s the validation <em>accuracy</em> per batch of the 1cycle training run shown in the previous chart – as you see, it keeps improving, even although the validation <em>loss</em> got worse in the last epoch:</p>
<div>
<figure>
<p><img src="https://www.fast.ai/posts/2023-09-04-learning-jumps/2023-09-06-06-46-17.png" width="500"></p>
<figcaption>MAP@3 for 1cycle training</figcaption>
</figure>
</div>
<p>If you’re interested in diving deeper, take a look at <a href="https://wandb.ai/johnowhitaker/llmemo/reports/Can-LLMs-learn-from-a-single-example---Vmlldzo1MjQ2MDYy">this report</a> where Johno shares logs from some additional examples, along with a notebook for those who’d like to see this effect in action for themselves.</p>
</section>
<section id="how-could-the-memorization-hypothesis-be-true">
<h2 data-anchor-id="how-could-the-memorization-hypothesis-be-true">How could the memorization hypothesis be true?</h2>
<p>There is no fundamental law that says that neural networks can’t learn to recognise inputs from a single example. It’s just what researchers and practitioners have generally found to be the case in practice. It takes a lot of examples because the loss surfaces that we’re trying to navigate using stochastic gradient descent (SGD) are too bumpy to be able to jump far at once. We do know, however, that some things can make loss surfaces smoother, such as using residual connections, as shown in the classic <a href="https://arxiv.org/abs/1712.09913">Visualizing the Loss Landscape of Neural Nets</a> paper (Li et al, 2018).</p>
<div>
<figure>
<p><img src="https://www.fast.ai/posts/2023-09-04-learning-jumps/2023-09-04-12-55-45.png" width="500"></p>
<figcaption>Loss surfaces of a ResNet-56 (Li et al, 2018)</figcaption>
</figure>
</div>
<p>It could well be the case that pre-trained large language models have extremely smooth loss surfaces in areas close to the minimal loss, and that a lot of the fine-tuning work done in the open source community is in this area. This is based on the underlying premise surrounding the original development of fine-tuned universal language models. These models were first documented in the <a href="https://aclanthology.org/P18-1031/">ULMFiT paper</a> back in 2018 by one of us (Jeremy) and Sebastian Ruder. The reason Jeremy originally built the ULMFiT algorithm is because it seemed necessary that any model that could do a good job of language modeling (that is, predicting the next word of a sentence) would have to build a rich hierarchy of abstractions and capabilities internally. Furthermore, Jeremy believed that this hierarchy could then be easily adapted to solve other tasks requiring similar capabilities using a small amount of fine-tuning. The ULMFiT paper demonstrated for the first time that this is indeed exactly what happens.</p>
<p>Large language models, which today are orders of magnitude bigger than those studied in ULMFiT, must have an even richer hierarchy of abstractions. So fine-tuning one of these models to, for instance, answer multiple-choice questions about science, can largely harness capabilities and knowledge that is already available in the model. It’s just a case of surfacing the right pieces in the right way. These should not require many weights to be adjusted very much.</p>
<p>Based on this, it’s perhaps not surprising to think that a pre-trained language model with a small random classification head could be in a part of the weight space where the loss surface smoothly and clearly points exactly in the direction of a good weight configuration. And when using the Adam optimiser (as we did), having a consistent and smooth gradient results in effective dynamic learning rate going up and up, such that steps can get very big.</p>
</section>
<section id="what-now">
<h2 data-anchor-id="what-now">What now?</h2>
<p>Having a model that learns really fast sounds great – but actually it means that a lot of basic ideas around how to train models may be turned on their head! When models train very slowly, we can train them for a long time, using a wide variety of data, for multiple epochs, and we can expect that our model will gradually pull out generalisable information from the data we give it.</p>
<p>But when models learn this fast, the <a href="https://arxiv.org/abs/1312.6211">catastrophic forgetting</a> problem may suddenly become far more pronounced. For instance, if a model sees ten examples of a very common relationship, and then one example of a less common counter-example, it may well remember the counter-example instead of just slightly downweighting its memory of the original ten examples.</p>
<p>It may also be the case now that <a href="https://arxiv.org/abs/1904.12848">data augmentation</a> is now less useful for avoiding over-fitting. Since LLMs are so effective at pulling out representations of the information they’re given, mixing things up by paraphrasing and back-translation may now not make much of a difference. The model would be effectively getting the same information either way.</p>
<p>Perhaps we can mitigate these challenges by greatly increasing our use of techniques such as <a href="https://dl.acm.org/doi/10.5555/2627435.2670313">dropout</a> (which is already used a little in fine-tuning techniques such as LoRA) or <a href="https://arxiv.org/abs/1603.09382">stochastic depth</a> (which does not seem to have been used in NLP to any significant extent yet).</p>
<p>Alternatively, maybe we just need to be careful to use rich mixtures of datasets throughout training, so that our models never have a chance to forget. Although Llama Code, for instance, did suffer from catastrophic forgetting (as it got better at code, it got much worse at everything else), it was fine-tuned with only 10% of non-code data. Perhaps with something closer to a 50/50 mix it would have been possible to get just as good at coding, without losing its existing capabilities.</p>
<p>If you come up with any alternative hypotheses, and are able to test them, or if you find any empirical evidence that the memorization hypothesis is wrong, please do let us know! We’re also keen to hear about other work in this space (and apologies if we failed to reference any prior work here), and any ideas about how (if at all) we should adjust how we train and use these models based on these observations. We’ll be keeping an eye on replies to <a href="https://twitter.com/jeremyphoward/status/1699216721473880425">this twitter thread</a>, so please respond there if you have any thoughts or questions.</p>
</section>
</main> 

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Interoperability can save the open web (192 pts)]]></title>
            <link>https://spectrum.ieee.org/doctorow-interoperability</link>
            <guid>37399799</guid>
            <pubDate>Wed, 06 Sep 2023 00:32:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/doctorow-interoperability">https://spectrum.ieee.org/doctorow-interoperability</a>, See on <a href="https://news.ycombinator.com/item?id=37399799">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-elid="2664563919" data-post-url="https://spectrum.ieee.org/doctorow-interoperability" data-authors="Michael Nolan" data-headline="Cory Doctorow: Interoperability Can Save the Open Web" data-page-title="Cory Doctorow: Interoperability Can Save the Open Web - IEEE Spectrum"><p>In his new book <a href="https://www.versobooks.com/products/3035-the-internet-con" rel="noopener noreferrer" target="_blank"><u><em>The Internet Con: How to Seize the Means of Computation</em></u></a>, author <a href="https://www.eff.org/about/staff/cory-doctorow" rel="noopener noreferrer" target="_blank"><u>Cory Doctorow</u></a> presents a strong case for disrupting Big Tech. While the dominance of Internet platforms like <a href="https://spectrum.ieee.org/tag/twitter">Twitter</a>, <a href="https://spectrum.ieee.org/tag/facebook">Facebook</a>, Instagram, or <a href="https://spectrum.ieee.org/tag/amazon">Amazon</a> is often taken for granted, Doctorow argues that these walled gardens are fenced in by legal structures, not feats of engineering. Doctorow proposes forcing interoperability—any given platform’s ability to interact with another—as a way to break down those walls and to make the Internet freer and more democratic.</p><p><em><a href="https://spectrum.ieee.org/">IEEE Spectrum</a></em> contributor Michael Nolan spoke with Doctorow about his new book and how interoperability could break up monopolies both in tech and beyond.</p><p><strong>Your new book, <em>The Internet Con</em>, as you write in its acknowledgements, “crystallizes two decades’ worth of advocacy writing about and working on issues in digital human rights.” How did that come to take the form of an argument for interoperability as a way to break up Big Tech monopolies?</strong></p><p data-rm-resized-container="25%"><img alt="Black and white portrait of a smiling bespectacled man." data-rm-shortcode-id="083c69fef209bca45afec51763f356bb" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/black-and-white-portrait-of-a-smiling-bespectacled-man.jpg?id=36341066&amp;width=980" height="1240" id="9f28a" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/black-and-white-portrait-of-a-smiling-bespectacled-man.jpg?id=36341066&amp;width=980" width="1240"><small placeholder="Add Photo Caption...">Cory Doctorow</small><small placeholder="Add Photo Credit..."><a href="http://jonathanworth.com/" target="_blank">Jonathan Worth</a></small></p><p><strong>Cory Doctorow:</strong> Over the decades that I’ve been involved in technology, the entities that are on the user’s side have really changed. Sometimes it was tech platforms or companies and sometimes it wasn’t. Sometimes it was governments and sometimes it wasn’t. Having started off defending tech companies that really did have their users’ backs from entertainment companies, I realized that the distinction between them was not that one industry was made up of entertainment executives whose commitment to human rights was very thin and the other was made up of tech executives who had a more good-faith commitment. When a sector is extremely concentrated, the people who are willing to trade the public good and foundational democratic values for incremental increases in their employer’s profitability get a hearing within the company and take over the company’s decision making. When a business doesn’t have to worry about losing its customers due to abusing them, then the people arguing, “We shouldn’t do this because it’s wrong and <em>also</em> it’s bad for business” can only argue, “We shouldn’t do this because it’s wrong.” They have to grudgingly admit that it might be good for business. Any firm in that state eventually becomes a serious hazard to human rights. It’s this “curse of bigness,” as <a href="https://en.wikipedia.org/wiki/Louis_Brandeis" target="_blank">Brandeis</a> called it, that we should really be attuned to and is really pernicious.</p><p><strong>That leads to the main proposal of the book, which is that reaffirming interoperability between systems and platforms can break apart these very large companies. Can you define interoperability?</strong></p><p><strong>Doctorow:</strong> At its root, it’s just the ability to use one thing with something else. Use any ink in your printer with any paper, use any socks with your shoes, anyone’s gasoline in your car, put any lightbulb in your light socket. There’s voluntary, mandatory interoperability, where a group of stakeholders get together and they say, “This is the goal we want all of our products to achieve, and we are going to design a framework so that we can make sure that every lightbulb lights up when you stick it in a light socket.” Then there’s the stuff where they’re indifferent: Car companies don’t stop you from putting a little cigarette-lighter-to-USB adapter into your car. </p><p>Companies can grow very quickly because tech has got these great network effects, but they also have, because of interoperability, really low switching costs.<strong>—Cory Doctorow</strong></p><p>Then there’s the third kind of interop, the kind of chewy, interesting, lots-of-rich-Internet-history interop, which is adversarial interoperability, which in the book we call “comcom,” short for competitive compatibility. It’s the interop that’s done against the wishes of the original equipment manufacturer: scraping, reverse engineering, bots, all of that gnarly stuff done in the face of active hostility. This would be like Apple reverse-engineering <a href="https://spectrum.ieee.org/tag/microsoft">Microsoft</a> Office and making the iWork suite—Pages, Numbers, and Keynote—so that anyone with a Mac could read any Windows-based office file without having to buy any software from Microsoft. </p><p>There are so many examples of this from technology’s history. It’s really the engine of technology. It’s the reason we’ve had this incredible boom-and-bust cycle within tech companies. Companies can grow very quickly because tech has got these great network effects, but they also have, because of interoperability, really low switching costs. Anytime a platform isn’t suited to you or someone has a better idea for it, they can just make a tool [that] kind of greases the skids for you to leave the last one and to jump to the new one. Because of that interoperability, the companies that grow really big become irresistible targets for other companies that want to come in, tempt their users away, and offer them a very easy path to get from the old place to the new one. I think interoperability being interrupted explains “Why are tech companies bad when they used to be good?” It’s because the users can’t leave. If you can’t leave, they don’t have to treat you well.</p><p><strong>So how has tech interoperability become interrupted?</strong></p><p><strong>Doctorow:</strong> There are lots of platforms that have become, effectively, walled gardens. The argument is that the reason that these businesses are so sturdy, that no one has disrupted them or displaced them is that they have such good engineers. I get this from people about iOS all the time, saying “iOS is an impregnable vault, they’ve figured out how to stop people from doing it.” and I say, “wait a second—it’s a felony to try.” If I say I’m the world champion boxer, and no one has ever defeated me, but I can also send you to prison for five years for trying to take my title, how do we know how good a boxer I am? The question of why they use the lawyers and not the engineers, why their go-to is the lawyers and not the engineers, to me the answer is because the lawyers are much more effective at preventing a capitalized, motivated rival from figuring out how to bypass their technical countermeasures.</p><p><strong>So you’re saying it’s not technical dominance or business superiority or network effects that keep these platforms dominant; it’s instead the switching costs imposed by law. <strong>How could those laws be changed to make existing platforms more interoperable?</strong></strong></p><p><strong>Doctorow:</strong> One of the things I’m interested in is how to make a law you can’t cheat on. Facebook often proposes rules only they can follow. Rules for interoperability have two constraints: they have to be administrable and cannot constitute a capital barrier. For example, we can propose two different rules for Twitter [now X]. One would be an end-to-end principle, which is a rule that says: If I follow someone, and they post something, I can see it. That rule makes it really hard for Twitter to overweight content from its preferred suppliers. On top of that we add the Right to Exit. This is the right to leave Twitter without losing your followers and followees. This would be a mandate to stand up an API, and it would be, probably, an <a href="https://www.w3.org/TR/activitypub/" target="_blank">ActivityPub API</a>. It’s a pretty good standard and its deficiencies can be remedied more easily than we can design a new standard. You put those two together, Twitter can’t keep anyone prisoner, and Twitter will have to treat the people who choose to stay well.</p><p><strong>You also argue that requiring interoperability will lead to something of a virtuous antitrust cycle. Is it that breaking down tech monopolies lessens their ability to reinforce the policies that have prevented interoperability in the first place?</strong></p><p><strong>Doctorow: </strong>That’s half of it. To understand the success of an industry in achieving its regulatory goals, you have to understand it needs two things. The first thing is power in the form of excess profits it can maneuver to lobbying. The second is unity.</p><p>Think back to the Napster wars. That was a sector of hundreds of small and medium-sized tech companies that in aggregate had more profit than the whole music industry and the whole movie industry. But the movie industry and the music industry had a smaller number of participants: music was five, movies were seven back then, now it’s three and four. As a result, they were able to agree on what to spend the money on. The tech industry was all over the place. They were knifing each other in the back. The reason the tech industry treats people like the music industry treated them 20 years ago is that unity.</p><p>The two benefits of competition are that it breaks the cash reserves that are used to enact public policy and it introduces the collective action problem that makes the remaining reserves harder to spend.</p><p><strong>How does that virtuous cycle then extend from tech into other sectors?</strong></p><p><strong>Doctorow:</strong> Think about what happened with the breakup of Standard Oil in the first part of the 20th century. Standard Oil was not the only trust. There were trusts for everything: whiskey, railroads, iron, aluminum, cars. Standard Oil’s dominance made people so hopeless about whether or not they could have an accountable government that the toppling of Standard Oil opened up a floodgate of political will that saw all of those other trusts shattered.</p><p>I want to go after tech because it has this characteristic interoperability that makes it a soft target. We start with tech, and that gives us the momentum, the credibility, and the political will to go after everybody else.</p><p><em>Cory Doctorow is an author, activist, journalist, and blogger. His new book, </em><a href="https://www.versobooks.com/products/3035-the-internet-con" rel="noopener noreferrer" target="_blank">The Internet Con: How to Seize the Means of Computation</a>,<em> from Verso Books, is available 5 September 2023. He is special advisor to the </em><a href="http://eff.org/" target="_blank"><em>Electronic Frontier Foundation</em></a><em>.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Experts fear crooks are cracking keys stolen in LastPass breach (155 pts)]]></title>
            <link>https://krebsonsecurity.com/2023/09/experts-fear-crooks-are-cracking-keys-stolen-in-lastpass-breach/</link>
            <guid>37399745</guid>
            <pubDate>Wed, 06 Sep 2023 00:25:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2023/09/experts-fear-crooks-are-cracking-keys-stolen-in-lastpass-breach/">https://krebsonsecurity.com/2023/09/experts-fear-crooks-are-cracking-keys-stolen-in-lastpass-breach/</a>, See on <a href="https://news.ycombinator.com/item?id=37399745">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>In November 2022, the password manager service <strong>LastPass</strong> disclosed a breach in which hackers stole password vaults containing both encrypted and plaintext data for more than 25 million users. Since then, a steady trickle of six-figure cryptocurrency heists targeting security-conscious people throughout the tech industry has led some security experts to conclude that crooks likely have succeeded at cracking open some of the stolen LastPass vaults.</p>
<p><strong>Taylor Monahan</strong> is founder and CEO of <strong>MetaMask</strong>, a popular software cryptocurrency wallet used to interact with the Ethereum blockchain. Since late December 2022, Monahan and other researchers have identified a highly reliable set of clues that they say connect recent thefts targeting more than 150 people, Collectively, these individuals have been robbed of more than $35 million worth of crypto.</p>
<p>Monahan said virtually all of the victims she has assisted were longtime cryptocurrency investors, and security-minded individuals. Importantly, none appeared to have suffered the sorts of attacks that typically preface a high-dollar crypto heist, such as the compromise of one’s email and/or mobile phone accounts.</p>
<p>“The victim profile remains the most striking thing,” Monahan wrote. “They truly all are reasonably secure. They are also deeply integrated into this ecosystem, [including] employees of reputable crypto orgs, VCs [venture capitalists], people who built DeFi protocols, deploy contracts, run full nodes.”</p>
<p>Monahan has been <a href="https://twitter.com/tayvano_/status/1648187031468781568" target="_blank" rel="noopener">documenting the crypto thefts via Twitter/X</a> since March 2023, frequently expressing frustration in the search for a common cause among the victims. Then on Aug. 28, Monahan said she’d concluded that the common thread among nearly every victim was that they’d previously used LastPass to store their “seed phrase,” the private key needed to unlock access to their cryptocurrency investments.</p>
<div id="attachment_64831"><p><img aria-describedby="caption-attachment-64831" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2023/09/tayaug28.png" alt="" width="582" height="844"></p><p id="caption-attachment-64831">MetaMask owner Taylor Monahan on Twitter. Image: twitter.com/tayvano</p></div>
<p>Armed with your secret seed phrase, anyone can instantly access all of the cryptocurrency holdings tied to that cryptographic key, and move the funds to anywhere they like.</p>
<p>Which is why the best practice for many cybersecurity enthusiasts has long been to store their seed phrases either in some type of encrypted container — such as a password manager — or else inside an offline, special-purpose hardware encryption device, such as a Trezor or Ledger wallet.</p>
<p>“The seed phrase is literally the money,” said <strong>Nick Bax</strong>, director of analytics at <a href="https://www.unciphered.com/" target="_blank" rel="noopener">Unciphered</a>, a cryptocurrency wallet recovery company. “If you have my seed phrase, you can copy and paste that into your wallet, and then you can see all my accounts. And you can transfer my funds.”</p>
<p>Bax said he closely reviewed the massive trove of cryptocurrency theft data that Taylor Monahan and others have collected and linked together.</p>
<p>“It’s one of the broadest and most complex cryptocurrency investigations I’ve ever seen,” Bax said. “I ran my own analysis on top of their data and reached the same conclusion that Taylor reported. The threat actor moved stolen funds from multiple victims to the same blockchain addresses, making it possible to strongly link those victims.”</p>
<p>Bax, Monahan and others interviewed for this story say they’ve identified a unique signature that links the theft of more than $35 million in crypto from more than 150 confirmed victims, with roughly two to five high-dollar heists happening each month since December 2022.</p>
<p>KrebsOnSecurity has reviewed this signature but is not publishing it at the request of Monahan and other researchers, who say doing so could cause the attackers to alter their operations in ways that make their criminal activity more difficult to track.</p>
<p>But the researchers have published findings about the dramatic similarities in the ways that victim funds were stolen and laundered through specific cryptocurrency exchanges. They also learned the attackers frequently grouped together victims by sending their cryptocurrencies to the same destination crypto wallet.</p>
<div id="attachment_64829"><p><img aria-describedby="caption-attachment-64829" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2023/09/taygraph.png" alt="" width="250" height="653"></p><p id="caption-attachment-64829">A graphic published by @tayvano on Twitter depicting the movement of stolen cryptocurrencies from victims who used LastPass to store their crypto seed phrases.</p></div>
<p>By identifying points of overlap in these destination addresses, the researchers were then able to track down and interview new victims. For example, the researchers said their methodology identified a recent multi-million dollar crypto heist victim as an employee at <strong>Chainalysis</strong>, a blockchain analysis firm that works closely with law enforcement agencies to help track down cybercriminals and money launderers.</p>
<p>Chainalysis confirmed that the employee had suffered a high-dollar cryptocurrency heist late last month, but otherwise declined to comment for this story.</p>
<p>Bax said the only obvious commonality between the victims who agreed to be interviewed was that they had stored the seed phrases for their cryptocurrency wallets in LastPass.</p>
<p>“On top of the overlapping indicators of compromise, there are more circumstantial behavioral patterns and tradecraft which are also consistent between different thefts and support the conclusion,” Bax told KrebsOnSecuirty. “I’m confident enough that this is a real problem that I’ve been urging my friends and family who use LastPass to change all of their passwords and migrate any crypto that may have been exposed, despite knowing full well how tedious that is.”</p>
<p>LastPass declined to answer questions about the research highlighted in this story, citing an ongoing law enforcement investigation and pending litigation against the company in response to its 2022 data breach.</p>
<p>“Last year’s incident remains the subject of an ongoing investigation by law enforcement and is also the subject of pending litigation,” LastPass said in a written statement provided to KrebsOnSecurity. “Since last year’s attack on LastPass, we have remained in contact with law enforcement and continue to do so.”</p>
<p>Their statement continues:</p>
<p>“We have shared various technical information, Indicators of Compromise (IOCs), and threat actor tactics, techniques, and procedures (TTPs) with our law enforcement contacts as well as our internal and external threat intelligence and forensic partners in an effort to try and help identify the parties responsible. In the meantime, we encourage any security researchers to share any useful information they believe they may have with our Threat Intelligence team by contacting securitydisclosure@lastpass.com.”<span id="more-64785"></span></p>
<h2>THE LASTPASS BREACH(ES)</h2>
<p>On August 25, 2022, <strong>LastPass CEO Karim Toubba</strong> wrote to users that the company had detected unusual activity in its software development environment, and that the intruders stole some source code and proprietary LastPass technical information. On Sept. 15, 2022, LastPass said an investigation into the August breach determined the attacker did not access any customer data or password vaults.</p>
<p>But on Nov. 30, 2022, LastPass notified customers about another, far more serious security incident that the company said leveraged data stolen in the August breach. LastPass disclosed that criminal hackers had compromised encrypted copies of some password vaults, as well as other personal information.</p>
<p>In February 2023, LastPass disclosed that the intrusion involved a highly complex, targeted attack against a DevOps engineer who was one of only four LastPass employees with access to the corporate vault.</p>
<p>“This was accomplished by targeting the DevOps engineer’s home computer and exploiting a vulnerable third-party media software package, which enabled remote code execution capability and allowed the threat actor to implant keylogger malware,” LastPass officials wrote. “The threat actor was able to capture the employee’s master password as it was entered, after the employee authenticated with MFA, and gain access to the DevOps engineer’s LastPass corporate vault.”</p>
<p><strong>Dan Goodin </strong>at Ars Technica&nbsp;<a href="https://arstechnica.com/information-technology/2023/02/lastpass-hackers-infected-employees-home-computer-and-stole-corporate-vault/" target="_blank" rel="noopener">reported</a> and then <a href="https://infosec.exchange/@dangoodin/109950447675626971" target="_blank" rel="noopener">confirmed</a> that the attackers exploited a known vulnerability in a <strong>Plex</strong> media server that the employee was running on his home network, and succeeded in installing malicious software that stole passwords and other authentication credentials. The vulnerability exploited by the intruders was patched back in 2020, but the employee never updated his Plex software.</p>
<p>As it happens, Plex announced its own data breach one day before LastPass disclosed its initial August intrusion. On August 24, 2022, Plex’s security team urged users to reset their passwords, saying an intruder had accessed customer emails, usernames and encrypted passwords.</p>
<h2>OFFLINE ATTACKS</h2>
<p>A basic functionality of LastPass is that it will pick and remember lengthy, complex passwords for each of your websites or online services. To automatically populate the appropriate credentials at any website going forward, you simply authenticate to LastPass using your master password.</p>
<p>LastPass has always emphasized that if you lose this master password, that’s too bad because they don’t store it and their encryption is so strong that even they can’t help you recover it.</p>
<p>But experts say all bets are off when cybercrooks can get their hands on the encrypted vault data itself — as opposed to having to interact with LastPass via its website. These so-called “offline” attacks allow the bad guys to conduct unlimited and unfettered “brute force” password cracking attempts against the encrypted data using powerful computers that can each try millions of password guesses per second.</p>
<p>“It does leave things vulnerable to brute force when the vaults are stolen en masse, especially if info about the vault HOLDER is available,” said <strong>Nicholas Weaver</strong>, a researcher at University of California, Berkeley’s&nbsp;<a href="https://www.icsi.berkeley.edu/icsi/" target="_blank" rel="noopener">International Computer Science Institute</a> (ICSI) and lecturer at UC Davis. “So you just crunch and crunch and crunch with GPUs, with a priority list of vaults you target.”</p>
<p>How hard would it be for well-resourced criminals to crack the master passwords securing LastPass user vaults? Perhaps the best answer to this question comes from <strong>Wladimir Palant</strong>, a security researcher and the original developer behind the <strong>Adblock Plus</strong> browser plugin.</p>
<p>In <a href="https://palant.info/2022/12/28/lastpass-breach-the-significance-of-these-password-iterations/" target="_blank" rel="noopener">a December 2022 blog post</a>, Palant explained that the crackability of the LastPass master passwords depends largely on two things: The complexity of the master password, and the default settings for LastPass users, which appear to have varied quite a bit based on when those users began patronizing the service.</p>
<p>LastPass says that since 2018 it has required a twelve-character minimum for master passwords, which the company said “greatly minimizes the ability for successful brute force password guessing.”</p>
<p>But Palant said while LastPass indeed improved its master password defaults in 2018, it did not force all existing customers who had master passwords of lesser lengths to pick new credentials that would satisfy the 12-character minimum.</p>
<p>“If you are a LastPass customer, chances are that you are completely unaware of this requirement,” Palant wrote. “That’s because LastPass didn’t ask existing customers to change their master password. I had my test account since 2018, and even today I can log in with my eight-character password without any warnings or prompts to change it.”</p>
<p>Palant believes LastPass also failed to upgrade many older, original customers to more secure encryption protections that were offered to newer customers over the years. One important setting in LastPass is the number of “iterations,” or how many times your master password is run through the company’s encryption routines. The more iterations, the longer it takes an offline attacker to crack your master password.</p>
<p>Palant noted last year that for many older LastPass users, the initial default setting for iterations was anywhere from “1” to “500.” By 2013, new LastPass customers were given 5,000 iterations by default. In February 2018, LastPass changed the default to 100,100 iterations. And very recently, it upped that again to 600,000.</p>
<p>Palant said the 2018 change was in response to a security bug report he filed about some users having dangerously low iterations in their LastPass settings.</p>
<p>“Worse yet, for reasons that are beyond me, LastPass didn’t complete this migration,” Palant wrote. “My test account is still at 5,000 iterations, as are the accounts of many other users who checked their LastPass settings. LastPass would know how many users are affected, but they aren’t telling that. In fact, it’s painfully obvious that LastPass never bothered updating users’ security settings. Not when they changed the default from 1 to 500 iterations. Not when they changed it from 500 to 5,000. Only my persistence made them consider it for their latest change. And they still failed implementing it consistently.”</p>
<p>A chart on Palant’s blog post offers an idea of how increasing password iterations dramatically increases the costs and time needed by the attackers to crack someone’s master password. Palant said it would take a single GPU about a year to crack a password of average complexity with 500 iterations, and about 10 years to crack the same password run through 5,000 iterations.</p>
<div id="attachment_64836"><p><img aria-describedby="caption-attachment-64836" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2023/09/gpuguesstime.png" alt="" width="754" height="219" srcset="https://krebsonsecurity.com/wp-content/uploads/2023/09/gpuguesstime.png 850w, https://krebsonsecurity.com/wp-content/uploads/2023/09/gpuguesstime-768x223.png 768w, https://krebsonsecurity.com/wp-content/uploads/2023/09/gpuguesstime-782x227.png 782w" sizes="(max-width: 754px) 100vw, 754px"></p><p id="caption-attachment-64836">Image: palant.info</p></div>
<p>However, these numbers radically come down when a determined adversary also has other large-scale computational assets at their disposal, such as a bitcoin mining operation that can coordinate the password-cracking activity across multiple powerful systems simultaneously.</p>
<p>Weaver said a password or passphrase with average complexity — such as “Correct Horse Battery Staple” is only secure against online attacks, and that its roughly 40 bits of randomness or “<a href="https://www.omnicalculator.com/other/password-entropy" target="_blank" rel="noopener">entropy</a>” means a graphics card can blow through it in no time.</p>
<p>“An Nvidia 3090 can do roughly 4 million [password guesses] per second with 1000 iterations, but that would go down to 8 thousand per second with 500,000 iterations, which is why iteration count matters so much,” Weaver said. “So a combination of ‘not THAT strong of a password’ and ‘old vault’ and ‘low iteration count’ would make it theoretically crackable but real work, but the work is worth it given the targets.”</p>
<p>Reached by KrebsOnSecurity, Palant said he never received a response from LastPass about why the company apparently failed to migrate some number of customers to more secure account settings.</p>
<p>“I know exactly as much as everyone else,” Palant wrote in reply. “LastPass published <a href="https://palant.info/2023/02/28/lastpass-breach-update-the-few-additional-bits-of-information/" target="_blank" rel="noopener">some additional information in March</a>. This finally answered the questions about the timeline of their breach – meaning which users are affected. It also made obvious that business customers are very much at risk here, Federated Login Services being highly compromised in this breach (LastPass downplaying as usual of course).”</p>
<p>Palant said upon logging into his LastPass account a few days ago, he found his master password was still set at 5,000 iterations.</p>
<h2>INTERVIEW WITH A VICTIM</h2>
<p>KrebsOnSecurity interviewed one of the victims tracked down by Monahan, a software engineer and startup founder who recently was robbed of approximately $3.4 million worth of different cryptocurrencies. The victim agreed to tell his story in exchange for anonymity because he is still trying to claw back his losses. We’ll refer to him here as “Connor” (not his real name).</p>
<p>Connor said he began using LastPass roughly a decade ago, and that he also stored the seed phrase for his primary cryptocurrency wallet inside of LastPass. Connor chose to protect his LastPass password vault with an eight character master password that included numbers and symbols (~50 bits of entropy).</p>
<p>“I thought at the time that the bigger risk was losing a piece of paper with my seed phrase on it,” Connor said. “I had it in a bank security deposit box before that, but then I started thinking, ‘Hey, the bank might close or burn down and I could lose my seed phrase.'”</p>
<p>Those seed phrases sat in his LastPass vault for years. Then, early on the morning of Sunday, Aug. 27, 2023, Connor was awoken by a service he’d set up to monitor his cryptocurrency addresses for any unusual activity: Someone was draining funds from his accounts, and fast.</p>
<p>Like other victims interviewed for this story, Connor didn’t suffer the usual indignities that typically presage a cryptocurrency robbery, such as account takeovers of his email inbox or mobile phone number.</p>
<p>Connor said he doesn’t know the number of iterations his master password was given originally, or what it was set at when the LastPass user vault data was stolen last year. But he said he recently logged into his LastPass account and the system forced him to upgrade to the new 600,000 iterations setting.</p>
<p>“Because I set up my LastPass account so early, I’m pretty sure I had whatever weak settings or iterations it originally had,” he said.</p>
<p>Connor said he’s kicking himself because he recently started the process of migrating his cryptocurrency to a new wallet protected by a new seed phrase. But he never finished that migration process. And then he got hacked.</p>
<p>“I’d set up a brand new wallet with new keys,” he said. “I had that ready to go two months ago, but have been procrastinating moving things to the new wallet.”</p>
<p>Connor has been exceedingly lucky in regaining access to some of his stolen millions in cryptocurrency. The Internet is swimming with con artists masquerading as legitimate cryptocurrency recovery experts. To make matters worse, because time is so critical in these crypto heists, many victims turn to the first quasi-believable expert who offers help.</p>
<p>Instead, several friends steered Connor to <a href="https://noteforms.com/forms/flashbots-whitehat-intake-form?notionforms=1&amp;utm_source=notionforms" target="_blank" rel="noopener">Flashbots.net</a>, a cryptocurrency recovery firm that employs several custom techniques to help clients claw back stolen funds — particularly those on the Ethereum blockchain.</p>
<p>According to Connor, Flashbots helped rescue approximately $1.5 million worth of the $3.4 million in cryptocurrency value that was suddenly swept out of his account roughly a week ago. Lucky for him, Connor had some of his assets tied up in a type of digital loan that allowed him to borrow against his various cryptocurrency assets.</p>
<p>Without giving away too many details about how they clawed back the funds, here’s a high level summary: When the crooks who stole Connor’s seed phrase sought to extract value from these loans, they were borrowing the maximum amount of credit that he hadn’t already used. But Connor said that left open an avenue for some of that value to be recaptured, basically by repaying the loan in many small, rapid chunks.</p>
<h2>WHAT SHOULD LASTPASS USERS DO?</h2>
<p>According to MetaMask’s Monahan, users who stored any important passwords with LastPass — particularly those related to cryptocurrency accounts — should change those credentials immediately, and migrate any crypto holdings to new offline hardware wallets.</p>
<p>“Really the ONLY thing you need to read is this,” Monahan pleaded to her 70,000 followers on Twitter/X: “PLEASE DON’T KEEP ALL YOUR ASSETS IN A SINGLE KEY OR SECRET PHRASE FOR YEARS. THE END. Split up your assets. Get a hw [hardware] wallet. Migrate. Now.”</p>
<p>If you also had passwords tied to banking or retirement accounts, or even just important email accounts — now would be a good time to change those credentials as well.</p>
<p>I’ve never been comfortable recommending password managers, because I’ve never seriously used them myself. Something about putting all your eggs in one basket. Heck, I’m so old-fashioned that most of my important passwords are written down and tucked away in safe places.</p>
<p>But I recognize this antiquated approach to password management is not for everyone.&nbsp;Connor says he now uses 1Password, a competing password manager that recently earned the best overall marks from <a href="https://www.wired.com/story/best-password-managers/" target="_blank" rel="noopener">Wired</a> and <a href="https://www.nytimes.com/wirecutter/reviews/1password-review/" target="_blank" rel="noopener">The New York Times</a>.</p>
<p>1Password says that three things are needed to decrypt your information: The encrypted data itself, your account password, and your Secret Key. Only you know your account password, and your Secret Key is generated locally during setup.</p>
<p>“The two are combined on-device to encrypt your vault data and are never sent to 1Password,” explains a 1Password blog post ‘<a href="https://blog.1password.com/what-if-1password-gets-hacked/" target="_blank" rel="noopener">What If 1Password Gets Hacked?</a>‘ “Only the encrypted vault data lives on our servers, so neither 1Password nor an attacker who somehow manages to guess or steal your account password would be able to access your vaults – or what’s inside them.</p>
<p>Weaver said that Secret Key adds an extra level of randomness to all user master passwords that LastPass didn’t have.</p>
<p>“With LastPass, the idea is the user’s password vault is encrypted with a cryptographic hash (H) of the user’s passphrase,” Weaver said. “The problem is a hash of the user’s passphrase is remarkably weak on older LastPass vaults with master passwords that do not have many iterations. 1Password uses H(random-key||password) to generate the password, and it is why you have the QR code business when adding a new device.”</p>
<p>Weaver said LastPass deserves blame for not having upgraded iteration counts for all users a long time ago, and called the latest forced upgrades “a stunning indictment of the negligence on the part of LastPass.”</p>
<p>“That they never even notified all those with iteration counts of less than 100,000 — who are really vulnerable to brute force even with 8-character random passwords or ‘correct horse battery staple’ type passphrases — is outright negligence,” Weaver said. “I would personally advocate that nobody ever uses LastPass again: Not because they were hacked. Not because they had an architecture (unlike 1Password) that makes such hacking a problem. But because of their consistent refusal to address how they screwed up and take proactive efforts to protect their customers.”</p>
<p>Bax and Monahan both acknowledged that their research alone can probably never conclusively tie dozens of high-dollar crypto heists over the past year to the LastPass breach. But Bax says at this point he doesn’t see any other possible explanation.</p>
<p>“Some might say it’s dangerous to assert a strong connection here, but I’d say it’s dangerous to assert there isn’t one,” he said. “I was arguing with my fiance about this last night. She’s waiting for LastPass to tell her to change everything. Meanwhile, I’m telling her to do it now.”</p>
											</div></div>]]></description>
        </item>
    </channel>
</rss>