<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 22 Jun 2024 04:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[My Windows Computer Just Doesn't Feel Like Mine Anymore (188 pts)]]></title>
            <link>https://www.howtogeek.com/my-windows-computer-just-doesnt-feel-like-mine-anymore/</link>
            <guid>40755444</guid>
            <pubDate>Sat, 22 Jun 2024 01:29:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.howtogeek.com/my-windows-computer-just-doesnt-feel-like-mine-anymore/">https://www.howtogeek.com/my-windows-computer-just-doesnt-feel-like-mine-anymore/</a>, See on <a href="https://news.ycombinator.com/item?id=40755444">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body" itemprop="articleBody">

<div id="custom_block_0">

                    <h3>Key Takeaways</h3>
        
            <div>    <ul>
                    <li>
                                        Windows feels more commercial, less personal; past versions were disconnected &amp; resilient.
                        </li>
                    <li>
                                        Advertising integration in Windows makes it feel cheap.
                        </li>
                    <li>
                                        Updates, intrusive changes, settings modifications, and lack of control plague modern Windows systems.
                        </li>
            </ul>
</div>
    
        
    </div><!-- Not injecting Ads due to No-Ads mode. -->
<p>                    An operating system is the most personal part of a "personal" computer, and it used to be that as a Windows user I didn't feel like I was renting my computer from Microsoft, but in recent years that feeling has all but evaporated. To me, Windows feels cheaper and more commercial than ever, and that's not a recipe for a good user experience.
    </p>

    <!-- Not injecting Ads due to No-Ads mode. --><h2 id="the-offline-glory-days-of-windows">
                        The Offline Glory Days of Windows
               </h2>
<p>                    The first version of Windows I ever used, coming from MS-DOS, was Windows 3.1. While Windows 3.1 might look incredibly primitive today, it's hard to explain just how big of a leap this was for a kid who had to memorize the Command Line instructions just to play some games. Things didn't really kick off for me until Windows 95 and our first taste of the internet, but even then, 99% of my Windows time up until Windows 7 was spent disconnected from the net.
    </p>

    
                
    
    
    
                
    
                
        
                                                            
                                                                                                                        
                                                                        
    <div data-img-url="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2014/05/exit-windows-3.1-to-dos.png" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="&quot;&quot;">

            




<figure>
        <picture>
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 1024px)" data-srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2014/05/exit-windows-3.1-to-dos.png?q=70&amp;fit=crop&amp;w=750&amp;dpr=1" srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2014/05/exit-windows-3.1-to-dos.png?q=70&amp;fit=crop&amp;w=750&amp;dpr=1">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 768px)" data-srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2014/05/exit-windows-3.1-to-dos.png?q=70&amp;fit=crop&amp;w=943&amp;dpr=1" srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2014/05/exit-windows-3.1-to-dos.png?q=70&amp;fit=crop&amp;w=943&amp;dpr=1">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 481px)" data-srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2014/05/exit-windows-3.1-to-dos.png?q=70&amp;fit=crop&amp;w=767&amp;dpr=1" srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2014/05/exit-windows-3.1-to-dos.png?q=70&amp;fit=crop&amp;w=767&amp;dpr=1">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 0px)" data-srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2014/05/exit-windows-3.1-to-dos.png?q=70&amp;fit=crop&amp;w=480&amp;dpr=1" srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2014/05/exit-windows-3.1-to-dos.png?q=70&amp;fit=crop&amp;w=480&amp;dpr=1">
                <img width="642" height="482" loading="lazy" decoding="async" alt="exit-windows-3.1-to-dos" data-img-url="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2014/05/exit-windows-3.1-to-dos.png" src="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2014/05/exit-windows-3.1-to-dos.png">
    </picture>
                                    
    </figure>


        </div>

<p>                    In retrospect, this was actually a good thing in some ways, because it meant that Microsoft couldn't remotely mess with my Windows installation. Patches and updates came in the form of Windows service packs, and those were on actual physical floppy disks or CD-ROMs. If my computer worked yesterday, and I didn't change anything myself, it would almost certainly keep working until I inadvertently broke it myself.
    </p>

    
<p>                    Now that Windows is almost always online, my "personal" computer experience is feeling quite a bit less personal.
    </p>

    <h2 id="advertising-sneaking-in">
                        Advertising Sneaking In
               </h2>
                
    
    
    
                
    
                
        
                                                            
                                                                                                                        
                                                                        
    <div>
        <div data-img-url="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/05/windows-start-ads.jpeg" data-img-desc="&quot;Jerome Thomas \/ How-To Geek&quot;" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="&quot;&quot;">

            




<figure>
        <picture>
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 1024px)" data-srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/05/windows-start-ads.jpeg?q=49&amp;fit=crop&amp;w=750&amp;dpr=2" srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/05/windows-start-ads.jpeg?q=49&amp;fit=crop&amp;w=750&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 768px)" data-srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/05/windows-start-ads.jpeg?q=49&amp;fit=crop&amp;w=943&amp;dpr=2" srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/05/windows-start-ads.jpeg?q=49&amp;fit=crop&amp;w=943&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 481px)" data-srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/05/windows-start-ads.jpeg?q=49&amp;fit=crop&amp;w=767&amp;dpr=2" srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/05/windows-start-ads.jpeg?q=49&amp;fit=crop&amp;w=767&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 0px)" data-srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/05/windows-start-ads.jpeg?q=49&amp;fit=crop&amp;w=480&amp;dpr=2" srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/05/windows-start-ads.jpeg?q=49&amp;fit=crop&amp;w=480&amp;dpr=2">
                <img width="2100" height="1400" loading="lazy" decoding="async" alt="The location of the recommended section in the Windows 11 Start menu" data-img-url="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/05/windows-start-ads.jpeg" src="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/05/windows-start-ads.jpeg">
    </picture>
                                    
    </figure>


        </div>
                                    <p>Jerome Thomas / How-To Geek</p>
                        </div>

<p>                    If you bought a laptop or a pre-built computer you probably didn't think much about the price of Windows, but the fact is that Windows has never been an inexpensive operating system. As someone who has almost always built their own computer, I'm keenly aware that this software cost a significant amount of money. Which is why I and many other people were a little irked when Windows started introducing <a href="https://www.howtogeek.com/windows-11-start-menu-ads-how-to-turn-them-off/">advertising</a> and writing guides on <a href="https://www.howtogeek.com/how-to-disable-microsofts-ads-and-recommendations-in-windows-11/">how to turn off advertising in Windows</a> became a popular new pastime for us tech bloggers.
    </p>

    
<p>                    Basically, it now feels like Windows is partly subsidized by advertising, and regular users can't just have the operating system they paid for without being sold more software and services. It's not (yet) the most egregious way to go about it, but for someone who prefers absolute minimilism in their computer interfaces, it's not working for my feng shui.
    </p>

    <h2 id="updates-breaking-my-pc">
                        Updates Breaking My PC
               </h2>
<p>                    At this point, I have lost count of the number of times that I've left my perfectly working Windows computer at the end of my work day, only to return to a completely broken computer that won't boot the next morning. We have numerous articles at How-To Geek on how to <a href="https://www.howtogeek.com/224471/how-to-prevent-windows-10-from-automatically-downloading-updates/">stop Windows from updating</a>, and the mere fact that readers are searching for this information should tell you something.
    </p>

    
<p>                    Forced, automatic Windows updates seem inevitable now, and with every workaround people come up with, the loopholes are closed. Updates can be delayed, but not deferred. Resistance is futile. Which is why I find it hard to even trust Windows to run a Plex server or a NAS, because inevitably it will reboot the computer without asking me first.
    </p>

    <h2 id="leave-my-settings-alone-microsoft">
                        Leave My Settings Alone, Microsoft
               </h2>
<p>                    When I have my computer set up a certain way, I'd like it to stay that way permanently. Yet search the forums on sites like <a href="https://www.reddit.com/r/Windows10/comments/n1hoz0/windows_please_stop_changing_my_settings_with/" rel="noopener noreferrer nofollow" target="_blank">Reddit</a> or Microsoft's own <a href="https://answers.microsoft.com/en-us/windows/forum/all/windows-updates-keeps-changing-my-settings/1870494e-b7be-41a8-84e6-d2e7e55c88d5" rel="noopener noreferrer nofollow" target="_blank">community forums</a>, and you'll find numerous complaints about settings changing after updates. It can be innocuous stuff or more serious or impactful things, such as privacy settings. If anyone is going to flip the switches on my computer to control how it behaves and what's allowed, it should be me.
    </p>

    <h2 id="my-mac-doesn-rsquo-t-feel-subsidized">
                        My Mac Doesn’t Feel Subsidized
               </h2>
                
    
    
    
                
    
                
        
                                                            
                                                                                                                        
                                                                        
    <div data-img-url="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/03/macbook-on-a-desk-showing-a-colorful-wallpaper-with-in-a-dark-room.jpg" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="&quot;Sergio Rodriguez \/ How-To Geek&quot;">

            




<figure>
        <picture>
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 1024px)" data-srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/03/macbook-on-a-desk-showing-a-colorful-wallpaper-with-in-a-dark-room.jpg?q=49&amp;fit=crop&amp;w=750&amp;dpr=2" srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/03/macbook-on-a-desk-showing-a-colorful-wallpaper-with-in-a-dark-room.jpg?q=49&amp;fit=crop&amp;w=750&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 768px)" data-srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/03/macbook-on-a-desk-showing-a-colorful-wallpaper-with-in-a-dark-room.jpg?q=49&amp;fit=crop&amp;w=943&amp;dpr=2" srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/03/macbook-on-a-desk-showing-a-colorful-wallpaper-with-in-a-dark-room.jpg?q=49&amp;fit=crop&amp;w=943&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 481px)" data-srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/03/macbook-on-a-desk-showing-a-colorful-wallpaper-with-in-a-dark-room.jpg?q=49&amp;fit=crop&amp;w=767&amp;dpr=2" srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/03/macbook-on-a-desk-showing-a-colorful-wallpaper-with-in-a-dark-room.jpg?q=49&amp;fit=crop&amp;w=767&amp;dpr=2">
        
                                        
                                    
                                                                                                                                                                            
            
                                                            
            
            
                                        
            <source media="(min-width: 0px)" data-srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/03/macbook-on-a-desk-showing-a-colorful-wallpaper-with-in-a-dark-room.jpg?q=49&amp;fit=crop&amp;w=480&amp;dpr=2" srcset="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/03/macbook-on-a-desk-showing-a-colorful-wallpaper-with-in-a-dark-room.jpg?q=49&amp;fit=crop&amp;w=480&amp;dpr=2">
                <img width="2100" height="1400" loading="lazy" decoding="async" alt="MacBook on a desk showing a colorful wallpaper with in a dark room." data-img-url="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/03/macbook-on-a-desk-showing-a-colorful-wallpaper-with-in-a-dark-room.jpg" src="https://static1.howtogeekimages.com/wordpress/wp-content/uploads/2024/03/macbook-on-a-desk-showing-a-colorful-wallpaper-with-in-a-dark-room.jpg">
    </picture>
                                        <figcaption>Sergio Rodriguez / How-To Geek</figcaption>
                        
    </figure>


        </div>

<p>                    My constant technical issues with Windows 10 updates eventually led me to switch to macOS back in 2019, and the difference in user experience is stark. You won't find bright garish ads for games or apps anywhere except for the actual App Store, which is where they belong. Intrusive "notifications" that are <a href="https://www.howtogeek.com/windows-has-a-new-annoying-popup-for-microsoft-edge/">really just advertising</a>? I haven't encountered that on macOS yet!
    </p>

    
<p>                    Honestly, it might sound weird, but macOS feels like the offline Windows experience of old to me. In fact, the operating system tends to stay classy and out of my way as far as possible. I've been thinking that the common complaint that Macs cost too much for the hardware you get misses the fact that you are <em>also </em>paying for the software. You get macOS and several other full-fat apps, such as the iWork suite, Garageband, and iMovie included in the price of entry. You pay more now, and don't have annoying monetization efforts later.
    </p>

    
<p>                    When I use my Windows 11 laptop (which was more expensive than my Mac, mind you), it feels like those Amazon Kindles that are subsidized by ad money. Except, at least Amazon gave us the choice.
    </p>

    <h2 id="linux-respects-its-users">
                        Linux Respects Its Users
               </h2>
<p>                    The other major player here is of course Linux in all its varied distributions. Here you are literally getting the operating system for free. The closest that a distro of Linux has come to punting ads was when plugs for software showed up in the <a href="https://www.reddit.com/r/linux/comments/hfs4v9/ubuntu_is_putting_ads_in_their_motd_now/" rel="noopener noreferrer nofollow" target="_blank">Ubuntu Message of the Day</a> and more recently a sort-of "ad" for <a href="https://www.omgubuntu.co.uk/2022/10/ubuntu-pro-terminal-ad" rel="noopener noreferrer nofollow" target="_blank">Ubuntu Pro</a> in the terminal. If anyone knows of other examples of native ads in a Linux distro, I'd love to hear about it in the comments.
    </p>

    
<p>                    I've had an on-again-off-again relationship with Linux over the years, and daily drove it during seven years of university, and never did I feel that I was being exploited or not in control. In fact, I was probably in too much control, which is why you can break Linux in so many creative ways just by being a dummy.
    </p>

    <h2 id="can-windows-make-a-comeback">
                        Can Windows Make a Comeback?
               </h2>
<p>                    More and more, I feel like Windows is just becoming a loss-leading front-end for Microsoft to sell its many software-as-a-service products. They don't even do anything if you <a href="https://www.howtogeek.com/how-to-get-windows-11-free/">don't activate Windows</a> other than block wallpaper changes and put a tiny watermark in the corner. You can be sure you can still subscribe to their services even if you didn't pay for Windows!
    </p>

    <hr>
<p>                    I really hope there will be some way in the future to get a version of Windows (that's not for enterprise users) which gives you the choice to have Microsoft butt out of the daily running, appearance, and settings of your computer. I hate to even suggest it, but I might even be willing to pay for an "ad-free" or "hands-off" version of the OS. Will this happen, or will Windows continue to slowly turn into a twisted Black Mirror version of itself? As someone who actually likes Windows, I sure hope it can turn that corner.
    </p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Internet Archive forced to remove 500k books after publishers' court win (316 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/06/internet-archive-forced-to-remove-500000-books-after-publishers-court-win/</link>
            <guid>40754229</guid>
            <pubDate>Fri, 21 Jun 2024 21:53:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/06/internet-archive-forced-to-remove-500000-books-after-publishers-court-win/">https://arstechnica.com/tech-policy/2024/06/internet-archive-forced-to-remove-500000-books-after-publishers-court-win/</a>, See on <a href="https://news.ycombinator.com/item?id=40754229">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/06/GettyImages-119015596-800x609.jpg" alt="Internet Archive forced to remove 500,000 books after publishers’ court win">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 81:single/related:5b8fdf8dace930af74b6311c47e28811 --><!-- empty -->
<p>As a result <a href="https://arstechnica.com/tech-policy/2023/03/publishers-beat-internet-archive-as-judge-rules-e-book-lending-violates-copyright/">of book publishers successfully suing the Internet Archive</a> (IA) last year, the free online library that strives to keep growing online access to books recently shrank by about 500,000 titles.</p>
<p>IA <a href="https://blog.archive.org/2024/06/17/let-readers-read/">reported</a> in a blog post this month that publishers abruptly forcing these takedowns triggered a "devastating loss" for readers who depend on IA to access books that are otherwise impossible or difficult to access.</p>
<p>To restore access, IA is now appealing, hoping to reverse the prior court's decision by convincing the US Court of Appeals in the Second Circuit that IA's <a href="https://archive.org/details/controlled-digital-lending-explained">controlled digital lending</a> of its physical books should be considered fair use under copyright law. An April <a href="https://storage.courtlistener.com/recap/gov.uscourts.ca2.60988/gov.uscourts.ca2.60988.259.0.pdf">court filing</a> shows that IA intends to argue that the publishers have no evidence that the e-book market has been harmed by the open library's lending, and copyright law is better served by allowing IA's lending than by preventing it.</p>
<p>"We use industry-standard technology to prevent our books from being downloaded and redistributed—the same technology used by corporate publishers," Chris Freeland, IA's director of library services, wrote in the blog. "But the publishers suing our library say we shouldn’t be allowed to lend the books we own. They have forced us to remove more than half a million books from our library, and that’s why we are appealing."</p>
<p>IA will have an opportunity to defend its practices when oral arguments start in its appeal on June 28.</p>
<p>"Our position is straightforward; we just want to let our library patrons borrow and read the books we own, like any other library," Freeland wrote, while arguing that the "potential repercussions of this lawsuit extend far beyond the Internet Archive" and publishers should just "let readers read."</p>                                            
                                                        
<p>"This is a fight for the preservation of all libraries and the fundamental right to access information, a cornerstone of any democratic society," Freeland wrote. "We believe in the right of authors to benefit from their work; and we believe that libraries must be permitted to fulfill their mission of providing access to knowledge, regardless of whether it takes physical or digital form. Doing so upholds the principle that knowledge should be equally and equitably accessible to everyone, regardless of where they live or where they learn."</p>
<h2>Internet Archive fans beg publishers to end takedowns</h2>
<p>After publishers won an injunction stopping IA's digital lending, which "limits what we can do with our digitized books," IA's <a href="https://help.archive.org/help/why-are-so-many-books-listed-as-borrow-unavailable-at-the-internet-archive/">help page</a> said, the open library started shrinking. While "removed books are still available to patrons with print disabilities," everyone else has been cut off, causing many books in IA's collection to show up as "Borrow Unavailable."</p>
<p>Ever since, IA has been "inundated" with inquiries from readers all over the world searching for the removed books, Freeland said. And "we get tagged in social media every day where people are like, 'why are there so many books gone from our library'?" Freeland told Ars.</p>
<p>In an <a href="https://www.change.org/p/let-readers-read-an-open-letter-to-the-publishers-in-hachette-v-internet-archive">open letter</a> to publishers signed by nearly 19,000 supporters, IA fans begged publishers to reconsider forcing takedowns and quickly restore access to the lost books.</p>
<p>Among the "far-reaching implications" of the takedowns, IA fans counted the negative educational impact of academics, students, and educators—"particularly in underserved communities where access is limited—who were suddenly cut off from "research materials and literature that support their learning and academic growth."</p>
<p>They also argued that the takedowns dealt "a serious blow to lower-income families, people with disabilities, rural communities, and LGBTQ+ people, among many others," who may not have access to a local library or feel "safe accessing the information they need in public."</p>
<p>"Your removal of these books impedes academic progress and innovation, as well as imperiling the preservation of our cultural and historical knowledge," the letter said.</p>
<p>"This isn't happening in the abstract," Freeland told Ars. "This is real. People no longer have access to a half a million books."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Barcelona will eliminate tourist apartments (223 pts)]]></title>
            <link>https://www.theolivepress.es/spain-news/2024/06/21/breaking-barcelona-will-remove-all-tourist-apartments-in-2028-in-huge-win-for-anti-tourism-activists/</link>
            <guid>40752761</guid>
            <pubDate>Fri, 21 Jun 2024 19:23:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theolivepress.es/spain-news/2024/06/21/breaking-barcelona-will-remove-all-tourist-apartments-in-2028-in-huge-win-for-anti-tourism-activists/">https://www.theolivepress.es/spain-news/2024/06/21/breaking-barcelona-will-remove-all-tourist-apartments-in-2028-in-huge-win-for-anti-tourism-activists/</a>, See on <a href="https://news.ycombinator.com/item?id=40752761">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><strong>BARCELONA’S city council has announced it will revoke all licenses for tourist apartments in the urban area by 2028.</strong></p>
<p>In a major win for anti-tourist activists, Barcelona’s socialist mayor Jaume Collboni announced on Friday that licenses for 10,101 tourist apartments in the city will automatically end in November 2028.</p>
<p>The move represents a crushing blow for Airbnb, Booking.com and other tenants and a triumph for locals who have protested about over-tourism and rising house prices for years.</p>
<p>Announcing the move, Collboni said the rising cost of property in the city – rental and purchase prices have risen by 70% and 40% respectively in the last decade – had forced him to take drastic action.</p>
<p>He said: “We cannot allow it that most young people who leave home are forced to leave Barcelona. The measures we have taken will not change the situation in one day. These things take time. But with these measures we are reaching a turning point”.</p>
<p><strong><em>READ MORE: <a href="https://www.theolivepress.es/spain-news/2024/06/19/exclusive-tourism-has-gone-too-far-hundreds-of-protestors-target-f1-roadshow-in-barcelona-city-centre-ahead-of-spanish-grand-prix/">EXCLUSIVE: ‘Tourism has gone too far’ – hundreds of protestors target F1 roadshow in Barcelona city centre ahead of Spanish Grand Prix</a></em></strong></p>
<div>
<figure><img decoding="async" width="490" height="653" src="https://www.theolivepress.es/wp-content/uploads/2024/06/5-1-490x653.jpg" alt="" srcset="https://www.theolivepress.es/wp-content/uploads/2024/06/5-1-490x653.jpg 490w, https://www.theolivepress.es/wp-content/uploads/2024/06/5-1-225x300.jpg 225w, https://www.theolivepress.es/wp-content/uploads/2024/06/5-1-768x1024.jpg 768w, https://www.theolivepress.es/wp-content/uploads/2024/06/5-1-1152x1536.jpg 1152w, https://www.theolivepress.es/wp-content/uploads/2024/06/5-1-1536x2048.jpg 1536w, https://www.theolivepress.es/wp-content/uploads/2024/06/5-1-60x80.jpg 60w, https://www.theolivepress.es/wp-content/uploads/2024/06/5-1-18x24.jpg 18w, https://www.theolivepress.es/wp-content/uploads/2024/06/5-1-27x36.jpg 27w, https://www.theolivepress.es/wp-content/uploads/2024/06/5-1-36x48.jpg 36w, https://www.theolivepress.es/wp-content/uploads/2024/06/5-1-scaled.jpg 1920w" sizes="(max-width: 490px) 100vw, 490px"><figcaption>The move represents a big win for anti-tourist protestors, who attempted to disrupt an F1 roadshow in the city on Tuesday. Copyright: Ben Pawlowski/Olive Press</figcaption></figure></div>
<p>The deputy mayor for Urban Planning, Laia Bonet, hailed the move as the ‘equivalent of building 10,000 new flats’ which can be used by locals for residential use.</p>
<p>Local officials say that tenants will not be compensated because the move, which will have to be passed with political support, has de-facto compensation by giving owners a four-year window before licences expire. </p>
<p>Alongside the revoking of tourist flat licenses, Collboni announced that new legislation would force building constructors to allocate at least 30% of new homes to social housing.</p>
<p>The measures are designed to alleviate pressure on a housing market which has seen sharp price rises in recent years, forcing many residents to leave the urban area for the suburbs and beyond.</p>
<p>Speaking to the <em>Olive Press </em>at an anti-tourist rally on Tuesday, one Barcelona resident, who gave his name as Alex, said locals were angry at the ‘massification of tourism’ with ‘the cost of living and housing forcing many young people to emigrate from the city centre to the suburbs and nearby towns’.</p>
<p>He added: “The people of Barcelona, like any city in the UK and elsewhere, have the right to live peacefully in their own city. What we need is a better quality of life, decent wages and, above all, an affordable city to live in”. </p>
<p><a href="https://theolivepress.es/register/?level_id=4"><img src="https://www.theolivepress.es/wp-content/uploads/2024/04/paywall-offer-smaller.png" alt="" width="768" height="241"></a></p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Aster shootdown over Sydney in 1955 (162 pts)]]></title>
            <link>https://navyhistory.au/aster-shootdown-over-sydney-in-1955/</link>
            <guid>40751813</guid>
            <pubDate>Fri, 21 Jun 2024 17:33:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://navyhistory.au/aster-shootdown-over-sydney-in-1955/">https://navyhistory.au/aster-shootdown-over-sydney-in-1955/</a>, See on <a href="https://news.ycombinator.com/item?id=40751813">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-label="Aster shootdown over Sydney in 1955"><div><p>FOR more than three hours on a fine, calm August morning in 1955, the eyes of Sydney’s suburbia were fixed skyward, anxiously watching the flight of a pilotless Auster aeroplane as it circled above and headed from Bankstown to the City, pursued by Service aircraft.</p>
<p>It was school holiday time, the alert had gone out over the radio, and the mums had herded in their children, police patrolled areas by car, cycle and foot, firemen stood by their tenders, ambulance men remained on the alert and firefloats stood in readiness in the harbour . . . all eyes still looked up . . . no one knew when or where the plane might suddenly come hurtling down.</p>
<p>The end came – thankfully five miles off the coast – when two Navy Sea Furies opened fire on the Auster. which levelled out pouring smoke, then started down in a slow spiral. The two Navy pilots followed it down, firing two or three more short bursts on the way and with a splash, the errant aircraft, still in one piece, hit the water at 1142 and disappeared. It was all over!</p>
<p>The media had a field day . . with such newspaper headings as “Possible disaster in flight”, and “Thousands watch air drama of flyaway plane”, reaching the overseas press. Politicians asked embarassing questions and crit-icism of the Services followed as did a Department of Civil Aviation enquiry … but how, when and why did it happen?</p>
<p>On the morning of August 30, 1955. Mr Anthony Thrower, aged 30, of Granville, Sydney, rented an Auster from Kingsford Smith Aviation School He had completed only one circuit of his planned one hour practice when the engine failed 10 feet from the ground. Landing the plane in the middle of the strip he climbed out, swung the propellor by hand (there was no self-starter) and the engine immediately roared into life. In a million-to-one chance the brake failed to hold and although pilot Thrower grabbed a wing strut to check the plane he was quickly forced to jump clear, just avoiding the tail. Aided by a favourable south-east wind with well trimmed controls, the pilotless plane sped across the strip and became airborne. It then narrowly missed the control tower, which was subsequently evacuated, and other airport buildings then slowly circled the aerodrome at low altitude After continuing right hand circuits of Bankstown for a further 15 minutes the Auster steadily gained height and began drifting towards the city.</p>
<p>Bankstown Aerodrome officials alerted control personnel at Mascot who broadcast a general alarm to all aircraft as well as the police and other Government organisations. One report stated that a schoolboy might be at the controls. The police radio station at Bourke Street broadcast at almost one minute intervals the plane’s last known whereabouts.</p>
<p>Meanwhile, Commander J. R. W. Groves, RAN, was returning to Schofields aerodrome from exercises, with three other personnel onboard. At 0850 the Navy Auster was alerted by Mascot of the runaway plane. Nearing Bankstown they saw it at 1500ft and climbing in tight circles. Approaching to within 50 yards it was noted to be unoccupied and that the controls were fixed in the one position. The Navy lightplane continued to pursue the unmanned aircraft as it gained height passing over the Sydney suburbs of Punchbowl, Bexley, Hurstville, Rockdale, Mascot, Alexandria, Redfern and finally arriving above the centre of the city about 9.30 am.</p>
<p>In the meantime anxious mothers in suburbs where the plane passed over herded children, who were on school holidays, into their homes. Police patrolled areas by car, cycle and foot. Firemen stood by their trucks and ambulance officers remained on the alert, and firefloats stood in readiness in the harbour. No one knew when or where the plane might suddenly come hurtling down.</p>
<p>By 0953 the Auster was over Vaucluse at 5000 feet. RAAF Wirraway A20-728 departed Richmond at 1010 to join the chase. Onboard was Wing Commander D.R. Beattie and Squadron Leader Tom James. The target was contacted at 1020, 2½ miles offshore and now at an altitude of 7000 ft. Instructions were then received that they were not to open fire until the Auster was five miles offshore and there were no fishing or coastal boats below. The runaway plane continued climbing in tight orbit to 10,300ft and at 1045 hours reached a point estimated at five miles from the coast.</p>
<p><img decoding="async" src="https://navyhistory.au/wp-content/uploads/Wirraway-300x156.jpg" alt="" width="300" height="156" srcset="https://navyhistory.au/wp-content/uploads/Wirraway-300x156.jpg 300w, https://navyhistory.au/wp-content/uploads/Wirraway-150x78.jpg 150w, https://navyhistory.au/wp-content/uploads/Wirraway-120x62.jpg 120w, https://navyhistory.au/wp-content/uploads/Wirraway.jpg 585w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>Two firing passes were then made with the hand held Bren gun from the rear cockpit without any noticeable effect. Before departing the Wirraway rear canopy and fairing had been removed and Squadron Leader James was so cold, it was minus five degrees celcius – that he was unable to change the magazine and his hands were sticking to the gum.</p>
<p>Meanwhile a RAAF Meteor had arrived from Williamtown near Newcastle and after directing it to the target the Wirraway broke off the attack and returned to Richmond. The Navy Auster, which had now been airborne some 3¼ hours, headed for its base at Schofields at about the same time.</p>
<p><img decoding="async" src="https://navyhistory.au/wp-content/uploads/20200914raaf8622332_07-300x200.jpg" alt="" width="300" height="200" srcset="https://navyhistory.au/wp-content/uploads/20200914raaf8622332_07-300x200.jpg 300w, https://navyhistory.au/wp-content/uploads/20200914raaf8622332_07-1500x1000.jpg 1500w, https://navyhistory.au/wp-content/uploads/20200914raaf8622332_07-150x100.jpg 150w, https://navyhistory.au/wp-content/uploads/20200914raaf8622332_07-768x512.jpg 768w, https://navyhistory.au/wp-content/uploads/20200914raaf8622332_07-1536x1024.jpg 1536w, https://navyhistory.au/wp-content/uploads/20200914raaf8622332_07-2048x1365.jpg 2048w, https://navyhistory.au/wp-content/uploads/20200914raaf8622332_07-120x80.jpg 120w, https://navyhistory.au/wp-content/uploads/20200914raaf8622332_07-1000x667.jpg 1000w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>But luck was not with the RAAF that day. Firstly a Meteor piloted by Squadron Leader Holdsworth, had been delayed some 13 minutes on departure when a Sabre preceding his departure, had burst a tyre on landing and obstructed the runway. Then after arriving in the target area, and in the Meteor’s initial firing pass from the rear, both cannons jammed after only a few rounds had been fired. Some strikes were observed on the starboard plane of the Auster.</p>
<p>Squadron Leader Holdsworth then requested that two more Meteors be sent and the reply was received that they were on the way in addition to two Sea Furies from the Naval Air Station at Nowra. While awaiting their arrival A77-80 made four passes directly below the runaway Auster and pulled up sharply in an attempt to dislodge it from its flight path and into a dive. However, the jet wash was not sufficient and the plane continued in the same determined fashion.</p>
<p>Sea Furies from 805 Squadron Nowra appeared on the scene at 1135 and were piloted by Lieutenants J.R. Bluett and Peter McNay (both aged 26), of the Royal Navy, who were on exchange duty in Australia. LEUT McNay lowered his flaps to slow down and approached to within 100 yards of the target to again confirm it was unoccupied. Then, pulling up astern he gave it a short burst from his four cannons. LEUT Bluett followed this with a beam-on attack and after about 15 rounds. a great sheet of flame rose from the cockpit. From the first strikes on the Auster until the time it hit the sea was 1½ minutes.</p>

<figure id="attachment_67775" aria-describedby="caption-attachment-67775"><img decoding="async" src="https://navyhistory.au/wp-content/uploads/HAWKER-SEA-FURY-MK-1-300x158.jpg" alt="" width="300" height="158" srcset="https://navyhistory.au/wp-content/uploads/HAWKER-SEA-FURY-MK-1-300x158.jpg 300w, https://navyhistory.au/wp-content/uploads/HAWKER-SEA-FURY-MK-1-150x79.jpg 150w, https://navyhistory.au/wp-content/uploads/HAWKER-SEA-FURY-MK-1-768x403.jpg 768w, https://navyhistory.au/wp-content/uploads/HAWKER-SEA-FURY-MK-1-120x63.jpg 120w, https://navyhistory.au/wp-content/uploads/HAWKER-SEA-FURY-MK-1.jpg 1000w" sizes="(max-width: 300px) 100vw, 300px"><figcaption id="caption-attachment-67775">Hawker Sea Fury Mark 2</figcaption></figure>


<p><img decoding="async" src="https://navyhistory.au/wp-content/uploads/Astershootdown.jpg" alt="" width="356" height="506" srcset="https://navyhistory.au/wp-content/uploads/Astershootdown.jpg 356w, https://navyhistory.au/wp-content/uploads/Astershootdown-211x300.jpg 211w, https://navyhistory.au/wp-content/uploads/Astershootdown-106x150.jpg 106w, https://navyhistory.au/wp-content/uploads/Astershootdown-120x171.jpg 120w" sizes="(max-width: 356px) 100vw, 356px"></p>
<p>At 1145 a police broadcast announced “the Auster has been shot down. It’s all over.” The barrage of calls from anxious enquirers gradually subsided at the police, newspaper and radio station switchboards throughout Sydney.</p>
<p>When the Navy Sea Furies returned to Nowra, enthusiastic groundstaff quickly painted a small yellow silhouette representing an Auster on the fuselage of LEUT Bluett’s plane. This 26-year-old British pilot had seen eight months’ action in the Korean war from HMS GLORY on ground attack. LEUT McNay had only been in Australia eight months after completing his training in England.</p>
<p>The incident did not quickly subside here. Embarrassing questions were directed in Federal Parliament to. the Government of the day by both Mr C Chambers (Member for Adelaide) and Mr F Daly (Grayndler) during the Budget debate the following month. They asked why was so much money being spent on defence to an Air Force and Navy that took over two hours to shoot down an unarmed light aircraft?</p>
<p>Aviation authorities stated that nearly “dead calm” weather had probably prevented a major disaster as the Auster could have crashed anywhere on its route had it been a windy day. The then Department of Civil Aviation held an enquiry.</p>
<p>The harsh criticism against the Services was unfounded though and despite some initial bad luck the Navy and Air Force had performed creditably on a difficult and elusive “ENEMY”. In addition they were provided with an exciting Tuesday morning over and around Sydney with a free but stubborn target to practise on.</p>
<p>—————————————————————————————————————-</p>

</div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CRIU, a project to implement checkpoint/restore functionality for Linux (140 pts)]]></title>
            <link>https://criu.org/Main_Page</link>
            <guid>40751468</guid>
            <pubDate>Fri, 21 Jun 2024 16:59:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://criu.org/Main_Page">https://criu.org/Main_Page</a>, See on <a href="https://news.ycombinator.com/item?id=40751468">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><div>

<p><a href="https://criu.org/File:3.19.jpg"><img alt="3.19.jpg" src="https://criu.org/w/images/thumb/9/95/3.19.jpg/340px-3.19.jpg" decoding="async" width="340" height="340" srcset="https://criu.org/w/images/thumb/9/95/3.19.jpg/510px-3.19.jpg 1.5x, https://criu.org/w/images/thumb/9/95/3.19.jpg/680px-3.19.jpg 2x"></a></p>
</div>
<p><big>Welcome to CRIU, a project to implement checkpoint/restore functionality for Linux.
</big></p><p><big>Checkpoint/Restore In Userspace, or CRIU (pronounced kree-oo, IPA: /krɪʊ/, Russian: криу), is a Linux software. It can freeze a running container (or an individual application) and checkpoint its state to disk. The data saved can be used to restore the application and run it exactly as it was during the time of the freeze. Using this functionality, application or container live migration, snapshots, remote debugging, and <a href="https://criu.org/Usage_scenarios" title="Usage scenarios">many other things</a> are now possible.
</big></p><p><big>CRIU started as a project of Virtuozzo, and grew with the tremendous help from the <a href="https://criu.org/Community" title="Community">community</a>. It is currently used by (integrated into) OpenVZ, <a href="https://criu.org/LXC" title="LXC">LXC</a>/LXD, <a href="https://criu.org/Docker" title="Docker">Docker</a>, Podman, and <a href="https://criu.org/Integration" title="Integration">other software</a>, and <a href="https://criu.org/Packages" title="Packages">packaged for many Linux distributions</a>.
</big>
</p>
<div><h2></h2>

<h2><span id="CloudNativeSecurityCon_North_America_2024">CloudNativeSecurityCon North America 2024</span></h2>
<p><img alt="CloudNativeSecurityCon.png" src="https://criu.org/w/images/thumb/3/36/CloudNativeSecurityCon.png/200px-CloudNativeSecurityCon.png" decoding="async" width="200" height="67" srcset="https://criu.org/w/images/thumb/3/36/CloudNativeSecurityCon.png/300px-CloudNativeSecurityCon.png 1.5x, https://criu.org/w/images/thumb/3/36/CloudNativeSecurityCon.png/400px-CloudNativeSecurityCon.png 2x"></p>
<p><b>June 27, 2024, Seattle, Washington</b>
</p><p><a rel="nofollow" href="https://sched.co/1dCVs">End-to-End Encryption for Container Checkpointing in Kubernetes</a>
</p>
<h2><span id="Open_Source_Summit_North_America_2024">Open Source Summit North America 2024</span></h2>
<p><img alt="Oss-na.png" src="https://criu.org/w/images/thumb/f/f3/Oss-na.png/200px-Oss-na.png" decoding="async" width="200" height="41" srcset="https://criu.org/w/images/thumb/f/f3/Oss-na.png/300px-Oss-na.png 1.5x, https://criu.org/w/images/thumb/f/f3/Oss-na.png/400px-Oss-na.png 2x"></p>
<p><b>April 17, 2024, Seattle, Washington</b>
</p><p><a rel="nofollow" href="https://sched.co/1aPu9">Investigating Checkpoint and Restore for GPU-Accelerated Containers</a>
</p>
<h2><span id="NVIDIA_GTC_2024">NVIDIA GTC 2024</span></h2>
<p><img alt="Nvidia-gtc.png" src="https://criu.org/w/images/thumb/b/b8/Nvidia-gtc.png/150px-Nvidia-gtc.png" decoding="async" width="150" height="75" srcset="https://criu.org/w/images/thumb/b/b8/Nvidia-gtc.png/225px-Nvidia-gtc.png 1.5x, https://criu.org/w/images/thumb/b/b8/Nvidia-gtc.png/300px-Nvidia-gtc.png 2x"></p>
<p><b>March 21, 2024, San Jose, CA</b>
</p><p><a rel="nofollow" href="https://www.nvidia.com/gtc/posters/#/session/1705106137731001cNAN">Achieving K8S and Public Cloud Operational Efficiency using a New Checkpoint/Restart Feature for GPUs</a>
</p>
<h2><span id="KubeCon_EU_2024">KubeCon EU 2024</span></h2>
<p><img alt="Kubecon.png" src="https://criu.org/w/images/thumb/6/6a/Kubecon.png/150px-Kubecon.png" decoding="async" width="150" height="59" srcset="https://criu.org/w/images/thumb/6/6a/Kubecon.png/225px-Kubecon.png 1.5x, https://criu.org/w/images/thumb/6/6a/Kubecon.png/300px-Kubecon.png 2x"></p>
<p><b>March 22, 2024, Paris, France</b>
</p><p><a rel="nofollow" href="https://sched.co/1YeP3">The Party Must Go on - Resume Pods After Spot Instance Shut Down</a>
</p><p><a rel="nofollow" href="https://sched.co/1YeT4">Enabling Coordinated Checkpointing for Distributed HPC Applications</a>
</p>

</div>
<div>
<h2><span id="Using">Using</span></h2>
<big>
<dl><dt>Getting <a href="https://criu.org/Packages" title="Packages">packages</a> for your distribution</dt>
<dd>Or try manual <a href="https://criu.org/Installation" title="Installation">installation</a> to have CRIU on your system</dd></dl>
</big>
<dl><dt><a href="https://criu.org/CLI" title="CLI">CLI</a>, <a href="https://criu.org/RPC" title="RPC">RPC</a> and <a href="https://criu.org/C_API" title="C API">C API</a></dt>
<dd>Three ways to start using the C/R functionality.  <a href="https://criu.org/Category:API" title="Category:API">More info</a> about APIs.</dd></dl>
<dl><dt><a href="https://criu.org/Usage_scenarios" title="Usage scenarios">Usage scenarios</a></dt>
<dd>Ideas how criu can be used (some are crazy indeed)</dd></dl>
<dl><dt><a href="https://criu.org/Category:HOWTO" title="Category:HOWTO">Category:HOWTO</a></dt>
<dd>Collection of real world examples of how to use CRIU. Some are complex, some are not. HOW TO dump a <a href="https://criu.org/Simple_loop" title="Simple loop">simple loop</a> might be the best one to start with. Also a set of <a href="https://criu.org/Asciinema" title="Asciinema">asciinema</a> records for real-life examples.</dd></dl>
<dl><dt><a rel="nofollow" href="https://www.criu.org/index.php?title=FAQ">FAQ</a> &amp; <a href="https://criu.org/When_C/R_fails" title="When C/R fails">When C/R fails</a></dt>
<dd>A sort of troubleshooting guide</dd></dl>
<dl><dt><a href="https://criu.org/What_can_change_after_C/R" title="What can change after C/R">What can change after C/R</a></dt>
<dd>CRIU cannot (yet) save and restore every single bit of tasks' state. This page describes what bits visible through standard kernel API are such.</dd></dl>
<dl><dt><a href="https://criu.org/What_cannot_be_checkpointed" title="What cannot be checkpointed">What cannot be checkpointed</a></dt>
<dd>What an application could do to make CRIU refuse to dump it.</dd></dl>
<dl><dt><a href="https://criu.org/Contacts" title="Contacts">Contacts</a></dt>
<dd>Ways to communicate with CRIU community</dd></dl>
</div>


<div>
<h2><span id="Under_the_hood">Under the hood</span></h2>
<ul><li><a href="https://criu.org/Checkpoint/Restore" title="Checkpoint/Restore">Checkpoint/Restore</a></li>
<li><a href="https://criu.org/Category:Under_the_hood" title="Category:Under the hood">Category:Under the hood</a></li>
<li><a href="https://criu.org/Category:Network" title="Category:Network">Category:Network</a></li>
<li><a href="https://criu.org/Category:Files" title="Category:Files">Category:Files</a></li>
<li><a href="https://criu.org/Category:Memory" title="Category:Memory">Category:Memory</a></li>
<li><a href="https://criu.org/Pending_signals" title="Pending signals">Pending signals</a></li>
<li><a href="https://criu.org/Stages_of_restoring" title="Stages of restoring">Stages of restoring</a></li>
<li><a href="https://criu.org/Code_blobs" title="Code blobs">Code blobs</a></li>
<li><a href="https://criu.org/Comparison_to_other_CR_projects" title="Comparison to other CR projects">Comparison to other CR projects</a></li></ul>
</div>
<div>
<h2><span id="External_links">External links</span></h2>
<ul><li>2024-04-22, <a rel="nofollow" href="https://dl.acm.org/doi/abs/10.1145/3627703.3650085">Just-In-Time Checkpointing: Low Cost Error Recovery from Deep Learning Training Failures</a></li>
<li>2024-04-22, <a rel="nofollow" href="https://www.dpss.inesc-id.pt/~rbruno/papers/skohli-eurosys24.pdf">Pronghorn: Effective Checkpoint Orchestration for Serverless Hot-Starts</a></li>
<li>2024-01-29, <a rel="nofollow" href="https://www.sciencedirect.com/science/article/pii/S0167739X24000190">Prebaking runtime environments to improve the FaaS cold start latency</a></li>
<li>2023-11-12, <a rel="nofollow" href="https://dl.acm.org/doi/10.1145/3624062.3624254">Checkpoint/Restart for CUDA Kernels</a></li>
<li>2023-10-23, <a rel="nofollow" href="https://dl.acm.org/doi/10.1145/3605181.3626289">Evicting for the greater good: The Case for Reactive Checkpointing in Serverless Computing</a></li>
<li>2023-04-20, <a rel="nofollow" href="https://www.mdpi.com/2504-446X/7/5/286">A Dynamic Checkpoint Interval Decision Algorithm for Live Migration-Based Drone-Recovery System</a></li>
<li>2023-03-10, <a rel="nofollow" href="https://kubernetes.io/blog/2023/03/10/forensic-container-analysis/">Forensic Container Analysis</a></li>
<li>2023-01-14, <a rel="nofollow" href="https://arxiv.org/abs/2301.05861">Async-fork: Mitigating Query Latency Spikes Incurred by the Fork-based Snapshot Mechanism from the OS Level</a></li>
<li>2022-12-05, <a rel="nofollow" href="https://kubernetes.io/blog/2022/12/05/forensic-container-checkpointing-alpha/">Forensic container checkpointing in Kubernetes</a></li></ul>
<dl><dd><b><a href="https://criu.org/Articles" title="Articles">More external articles...</a></b></dd></dl>
</div>
<div>
<h2><span id="Misc">Misc</span></h2>
<ul><li><a href="https://criu.org/Academic_Research" title="Academic Research">Academic Research</a></li>
<li><a href="https://criu.org/Podcasts" title="Podcasts">Podcasts</a> and other audio/video interviews</li>
<li>Project <a href="https://criu.org/History" title="History">history</a></li>
<li><a href="https://criu.org/Logo" title="Logo">Logo</a> description</li>
<li><a href="https://criu.org/Events" title="Events">Events</a></li>
<li><a href="https://criu.org/CRIU_acronym_fun" title="CRIU acronym fun">CRIU acronym fun</a></li></ul>
</div>
<!-- 
NewPP limit report
Cached time: 20240621160420
Cache expiry: 86400
Dynamic content: false
Complications: []
CPU time usage: 0.084 seconds
Real time usage: 0.090 seconds
Preprocessor visited node count: 193/1000000
Post‐expand include size: 6372/2097152 bytes
Template argument size: 98/2097152 bytes
Highest expansion depth: 12/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 0/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%   18.533      1 -total
 62.84%   11.647      1 Template:Download_box
 49.57%    9.187      1 Template:Latest_release
 45.40%    8.414      1 Template:Release
 18.02%    3.339      1 Template:News_block_2
 15.57%    2.886      1 Template:Criu
 14.72%    2.728      1 Template:Dl
 10.86%    2.013      1 Template:Criu_link
  9.54%    1.768      1 Articles
  8.38%    1.553      1 News/events
-->

<!-- Saved in parser cache with key criuwikidb:pcache:idhash:1-0!canonical and timestamp 20240621160420 and revision id 5444
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to prolong lithium based batteries (110 pts)]]></title>
            <link>https://batteryuniversity.com/article/bu-808-how-to-prolong-lithium-based-batteries</link>
            <guid>40751414</guid>
            <pubDate>Fri, 21 Jun 2024 16:55:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://batteryuniversity.com/article/bu-808-how-to-prolong-lithium-based-batteries">https://batteryuniversity.com/article/bu-808-how-to-prolong-lithium-based-batteries</a>, See on <a href="https://news.ycombinator.com/item?id=40751414">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Battery research is focusing on lithium chemistries so much that one could imagine that the battery future lies solely in lithium. There are good reasons to be optimistic as lithium-ion is, in many ways, superior to other chemistries. Applications are growing and are encroaching into markets that previously were solidly held by lead acid, such as standby and load leveling. Many satellites are also powered by Li-ion.</p>
<p>Lithium-ion has not yet fully matured and is still improving. Notable advancements have been made in longevity and safety while the capacity is increasing incrementally. Today, Li-ion meets the expectations of most consumer devices but applications for the EV need further development before this power source will become the accepted norm. <a href="https://batteryuniversity.com/article/bu-104c-the-octagon-battery-what-makes-a-battery-a-battery">BU-104c: The Octagon Battery</a> – What makes a Battery a Battery, describes the stringent requirements a battery must meet.</p>
<p>As battery care-giver, you have choices in how to prolong battery life. Each battery system has unique needs in terms of <a href="https://batteryuniversity.com/article/bu-401a-fast-and-ultra-fast-chargers">charging</a> speed, <a href="https://batteryuniversity.com/article/bu-501-basics-about-discharging">depth of discharge</a>, <a href="https://batteryuniversity.com/article/bu-501a-discharge-characteristics-of-li-ion">loading</a> and exposure to <a href="https://batteryuniversity.com/article/bu-502-discharging-at-high-and-low-temperatures">adverse temperature</a>. Check <a href="https://batteryuniversity.com/article/bu-802-what-causes-capacity-loss">what causes capacity loss</a>, <a href="https://batteryuniversity.com/article/bu-802a-how-does-rising-internal-resistance-affect-performance">how does rising internal resistance affect performance</a>, <a href="https://batteryuniversity.com/article/bu-802b-what-does-elevated-self-discharge-do">what does elevated self-discharge do</a> and <a href="https://batteryuniversity.com/article/bu-802c-how-low-can-a-battery-be-discharged">how low can a battery be discharged?</a> You may also be interested in the <a href="https://batteryuniversity.com/article/bu-901-fundamentals-in-battery-testing">fundamentals of battery testing</a>.</p>
<ul><li><a href="https://batteryuniversity.com/article/bu-415-how-to-charge-and-when-to-charge">BU-415: How to Charge and When to Charge?</a></li><li><a href="https://batteryuniversity.com/article/bu-706-summary-of-dos-and-donts">BU-706: Summary of Do’s and Don’ts</a></li></ul>

<h3><strong>What Causes Lithium-ion to Age?</strong></h3>
<p>The lithium-ion battery works on ion movement between the positive and negative electrodes. In theory such a mechanism should work forever, but cycling, elevated temperature and aging decrease the performance over time. Manufacturers take a conservative approach and specify the life of Li-ion in most consumer products as being between 300 and 500 discharge/charge cycles.</p>
<p>In 2020, small wearable batteries deliver about 300 cycles whereas modern smartphones have a cycle life requirement is 800 cycles and more. The largest advancements are made in <a href="https://batteryuniversity.com/article/bu-1003-electric-vehicle-ev">EV batteries</a> with talk about the one-million-mile battery representing 5,000 cycles.</p>
<p>Evaluating battery life on counting cycles is not conclusive because a discharge may vary in depth and there are no clearly defined standards of what constitutes a cycle(See <a href="https://batteryuniversity.com/article/bu-501-basics-about-discharging">BU-501: Basics About Discharging</a>). In lieu of cycle count, some device manufacturers suggest battery replacement on a date stamp, but this method does not take usage into account. A battery may fail within the allotted time due to heavy use or unfavorable temperature conditions; however, most packs last considerably longer than what the stamp indicates.</p>
<p>The performance of a battery is measured in capacity, a leading health indicator. Internal resistance and self-discharge also play roles, but these are less significant in predicting the end of battery life with modern Li-ion.</p>
<p><strong>F</strong><strong>igure 1</strong> illustrates the capacity drop of 11 Li-polymer batteries that have been cycled at a Cadex laboratory. The 1,500mAh pouch cells for mobile phones were first charged at a current of 1,500mA (1C) to 4.20V/cell and then allowed to saturate to 0.05C (75mA) as part of the full charge saturation. The batteries were then discharged at 1,500mA to 3.0V/cell, and the cycle was repeated. The expected capacity loss of Li-ion batteries was uniform over the delivered 250 cycles and the batteries performed as expected.<strong><br></strong></p>
<figure><strong><img src="https://batteryuniversity.com/img/content/lithium1.jpg" alt="Capacity drop as part of cycling"></strong><figcaption><strong>Figure 1: Capacity drop as part of cycling <sup>[1]</sup></strong></figcaption></figure>
<p>Eleven new Li-ion were tested on a Cadex C7400 battery analyzer. All packs started at a capacity of 88–94% and decreased to 73–84% after 250 full discharge cycles. The 1500mAh pouch packs are used in mobile phones.</p>
<p>Although a battery should deliver 100 percent capacity during the first year of service, it is common to see lower than specified capacities, and shelf life may contribute to this loss. In addition, manufacturers tend to overrate their batteries, knowing that very few users will do spot-checks and complain if low. Not having to match single cells in mobile phones and tablets, as is required in multi-cell packs, opens the floodgates for a much broader performance acceptance. Cells with lower capacities may slip through cracks without the consumer knowing.</p>
<p>Similar to a mechanical device that wears out faster with heavy use, the depth of discharge (DoD) determines the cycle count of the battery. The smaller the discharge (low DoD), the longer the battery will last. If at all possible, avoid full discharges and charge the battery more often between uses. Partial discharge on Li-ion is fine. There is no memory and the battery does not need periodic full discharge cycles to prolong life. The exception may be a periodic calibration of the fuel gauge on a smart battery or intelligent device(See <a href="https://batteryuniversity.com/article/bu-603-how-to-calibrate-a-smart-battery">BU-603: How to Calibrate a “Smart” Battery</a>)</p>
<p>The following tables indicate stress related capacity losses on cobalt-based lithium-ion. The voltages of lithium iron phosphate and lithium titanate are lower and do not apply to the voltage references given.<br></p>
<table><tbody><tr><td><span><strong>Note:</strong></span></td>
			<td><strong>Tables 2, 3 and 4</strong> indicate general aging trends of common cobalt-based Li-ion batteries on depth-of-discharge, temperature and charge levels, Table 6 further looks at capacity loss when operating within given and discharge bandwidths. The tables do not address ultra-fast charging and high load discharges that will shorten battery life. No all batteries behave the same.</td>
		</tr></tbody></table>
<p><strong>Table 2 </strong>estimates the number of discharge/charge cycles Li-ion can deliver at various DoD levels before the battery capacity drops to 70 percent. DoD constitutes a full charge followed by a discharge to the indicated state-of-charge (SoC) level in the table.<br></p>
<table><tbody><tr><th rowspan="2"><p><strong>Depth of Discharge</strong></p></th>
			<th colspan="2"><p><strong>Discharge cycles</strong></p></th>
			
 </tr><tr><th><p>NMC</p></th>
			<th><p>LiPO<sub>4</sub></p></th>

	</tr></tbody><tbody><tr><td><p>100% DoD</p></td>
			<td><p>~300</p></td>
			<td><p>~600</p></td>
			
			
			
		</tr><tr><td><p>80% DoD</p></td>
			<td><p>~400</p></td>
			<td><p>~900</p></td>
			
			
			
		</tr><tr><td><p>60% DoD</p></td>
			<td><p>~600</p></td>
			<td><p>~1,500</p></td>
			
			
			
		</tr><tr><td><p>40% DoD</p></td>
			<td><p>~1,000</p></td>
			<td><p>~3,000</p></td>
			
			
			
		</tr><tr><td><p>20% DoD</p></td>
			<td><p>~2,000</p></td>
			<td><p>~9,000</p></td>
			
			
			
		</tr><tr><td><p>10% DoD</p></td>
			<td><p>~6,000</p></td>
			<td><p>~15,000</p></td>
			
			
			
		</tr></tbody></table>
<figcaption><strong>Table 2: Cycle life as a function ofdepth of discharge*</strong><br>A partial discharge reduces stress and prolongs battery life, so does a partial charge. Elevated temperature and high currents also affect cycle life.</figcaption>
<p><em><strong>*</strong> 100% DoD is a full cycle; 10% is very brief. Cycling in mid-state-of-charge would have best longevity.</em></p>
<p>Lithium-ion suffers from stress when exposed to heat, so does keeping a cell at a high charge voltage. A battery dwelling above 30°C (86°F) is considered <em>elevated temperature</em> and for most Li-ion a voltage above 4.10V/cell is deemed as <em>high voltage</em>. Exposing the battery to high temperature and dwelling in a full state-of-charge for an extended time can be more stressful than cycling. <strong>Table 3</strong> demonstrates capacity loss as a function of temperature and SoC.<br></p>
<table><thead><tr><th scope="col"><strong>Temperature</strong></th>
			<th scope="col"><strong>40% Charge</strong></th>
			<th scope="col"><strong>100% Charge</strong></th>
			
			
			
		</tr></thead><tbody><tr><td>0°C</td>
			<td>98% (after 1 year)</td>
			<td>94% (after 1 year)</td>
			
			
			
		</tr><tr><td>25°C</td>
			<td>96% (after 1 year)</td>
			<td>80% (after 1 year)</td>
			
			
			
		</tr><tr><td>40°C</td>
			<td>85% (after 1 year)</td>
			<td>65% (after 1 year)</td>
			
			
			
		</tr><tr><td>60°C</td>
			<td>75% (after 1 year)</td>
			<td>60% (after 3 months)</td>
			
			
			
		</tr></tbody></table>
<figcaption><strong>Table 3: Estimated recoverable capacity when storing Li-ion for one year at various temperatures</strong><br>Elevated temperature hastens permanent capacity loss. Not all Li-ion systems behave the same.</figcaption>
<p> Most Li-ions charge to 4.20V/cell, and every reduction in peak charge voltage of 0.10V/cell is said to double the cycle life. For example, a lithium-ion cell charged to 4.20V/cell typically delivers 300–500 cycles. If charged to only 4.10V/cell, the life can be prolonged to 600–1,000 cycles; 4.0V/cell should deliver 1,200–2,000 and 3.90V/cell should provide 2,400–4,000 cycles.</p>
<p>On the negative side, a lower peak charge voltage reduces the capacity the battery stores. As a simple guideline, every 70mV reduction in charge voltage lowers the overall capacity by 10 percent. Applying the peak charge voltage on a subsequent charge will restore the full capacity.</p>
<p>In terms of longevity, the optimal charge voltage is 3.92V/cell. Battery experts believe that this threshold eliminates all voltage-related stresses; going lower may not gain further benefits but induce other symptoms(See <a href="https://batteryuniversity.com/article/bu-808b-what-causes-li-ion-to-die">BU-808b: What causes Li-ion to die?</a>) <strong>Table 4</strong> summarizes the capacity as a function of charge levels. (All values are estimated; Energy Cells with higher voltage thresholds may deviate.)<br></p>
<table><thead><tr><th scope="col"><strong>Charge Level* </strong>(V/cell)</th>
			<th scope="col"><strong>Discharge Cycles</strong></th>
			
			
			
			<th scope="col"><strong>Available Stored Energy **</strong></th>
		</tr></thead><tbody><tr><td>[4.30]</td>
			<td>[150–250]</td>
			
			
			
			<td>[110–115%]</td>
		</tr><tr><td>4.25</td>
			<td>200–350</td>
			
			
			
			<td>105–110%</td>
		</tr><tr><td><strong>4.20</strong></td>
			<td><strong>300–500</strong></td>
			
			
			
			<td><strong>100%</strong></td>
		</tr><tr><td>4.13</td>
			<td>400–700</td>
			
			
			
			<td>90%</td>
		</tr><tr><td>4.06</td>
			<td>600–1,000</td>
			
			
			
			<td>81%</td>
		</tr><tr><td>4.00</td>
			<td>850–1,500</td>
			
			
			
			<td>73%</td>
		</tr><tr><td>3.92</td>
			<td>1,200–2,000</td>
			
			
			
			<td>65%</td>
		</tr><tr><td>3.85</td>
			<td>2,400–4,000</td>
			
			
			
	
			
			
			
			<td>60%</td>
		</tr></tbody></table>
<figcaption><strong>Table 4: Discharge cycles and capacity as a function of charge voltage limit</strong><br></figcaption>
<p>Every 0.10V drop below 4.20V/cell doubles the cycle but holds less capacity. Raising the voltage above 4.20V/cell would shorten the life. The readings reflect regular Li-ion charging to 4.20V/cell.</p>
<p><strong>Guideline:</strong> Every 70mV drop in charge voltage lowers the usable capacity by about 10%.<br><strong>Note: </strong>Partial charging negates the benefit of Li-ion in terms of high specific energy.</p>
<p><em><em><strong>*</strong> Similar life cycles apply for batteries with different voltage levels on full charge.</em><strong><br>**</strong> Based on a new battery with 100% capacity when charged to the full voltage.</em></p>
<p><em><strong>Experiment:</strong> Chalmers University of Technology, Sweden, reports that using a reduced charge level of 50% SOC increases the lifetime expectancy of the vehicle Li-ion battery by 44–130%.</em></p>
<p><br>Most chargers for mobile phones, laptops, tablets and digital cameras charge Li-ion to 4.20V/cell. This allows maximum capacity, because the consumer wants nothing less than optimal runtime. Industry, on the other hand, is more concerned about longevity and may choose lower voltage thresholds. Satellites and electric vehicles are such examples.</p>
<p>For safety reasons, many lithium-ions cannot exceed 4.20V/cell. (Some NMC are the exception.) While a higher voltage boosts capacity, exceeding the voltage shortens service life and compromises safety. <strong>Figure 5</strong> demonstrates cycle count as a function of charge voltage. At 4.35V, the cycle count of a regular Li-ion is cut in half.<strong><br></strong></p>
<figure><strong><img src="https://batteryuniversity.com/img/content/lithium2.jpg" alt="Effects on cycle life at elevated charge voltages"></strong><figcaption><strong>Figure 5: Effects on cycle life at elevated charge voltages <sup>[2]</sup></strong><br>Higher charge voltages boost capacity but lowers cycle life and compromises safety.</figcaption></figure>
<p>Besides selecting the best-suited voltage thresholds for a given application, a regular Li-ion should not remain at the high-voltage ceiling of 4.20V/cell for an extended time. The Li-ion charger turns off the charge current and the battery voltage reverts to a more natural level. This is like relaxing the muscles after a strenuous exercise(See <a href="https://batteryuniversity.com/article/charging-lithium-ion-batteries">BU-409: Charging Lithium-ion</a>)</p>
<p><strong>Figure 6</strong> illustrates dynamic stress tests (DST) reflecting capacity loss when cycling Li-ion at various charge and discharge bandwidths. The largest capacity loss occurs when discharging a fully charged Li-ion to 25 percent SoC (black); the loss would be higher if fully discharged. Cycling between 85 and 25 percent (green) provides a longer service life than charging to 100 percent and discharging to 50 percent (dark blue). The smallest capacity loss is attained by charging Li-ion to 75 percent and discharging to 65 percent. This, however, does not fully utilize the battery. High voltages and exposure to elevated temperature is said to degrade the battery quicker than cycling under normal condition. (<a href="https://batteryuniversity.com/article/bu-808b-what-causes-li-ion-to-die">Nissan Leaf case</a>)<br></p>
<figure><strong><img src="https://batteryuniversity.com/img/content/DST-cycles-web2.jpg" alt="Capacity loss as a function of charge and discharge bandwidth"></strong><figcaption><strong>Figure 6: Capacity loss as a function of charge and discharge bandwidth* <sup>[3]</sup></strong><br>Charging and discharging Li-ion only partially prolongs battery life but reduces utilization.</figcaption></figure>
<ul><li><strong>Case 1:</strong> 75–65% SoC offers longest cycle life but delivers only 90,000 energy units (EU). Utilizes 10% of battery.</li><li><strong>Case 2: </strong>75–25% SoC has 3,000 cycles (to 90% capacity) and delivers 150,000 EU. Utilizes 50% of battery. (EV battery, new.)</li><li><strong>Case 3:</strong> 85–25% SoC has 2,000 cycles. Delivers 120,000 EU. Uses 60% of battery.</li><li><strong>Case 4:</strong> 100–25% SoC; long runtime with 75% use of battery. Has short life. (Mobile phone, drone, etc.)</li></ul>
<p><em><span><strong>* </strong></span>Discrepancies exist between <strong>Table 2</strong> and <strong>Figure 6 </strong>on cycle count. No clear explanations are available other than assuming differences in battery quality and test methods. Variances between low-cost consumer and durable industrial grades may also play a role. Capacity retention will decline more rapidly at elevated temperatures than at 20ºC.</em><br></p>
<p>Only a full cycle provides the specified energy of a battery. With a modern <a href="https://batteryuniversity.com/article/discharge-characteristics-li">Energy Cell</a>, this is about 250Wh/kg, but the cycle life will be compromised. All being linear, the life-prolonging mid-range of 85-25 percent reduces the energy to 60 percent and this equates to moderating the specific energy density from 250Wh/kg to 150Wh/kg. Mobile phones are consumer goods that utilize the full energy of a battery. Industrial devices, such as the EV, typically limit the charge to 85% and discharge to 25%, or 60 percent energy usability, to prolong battery life(See <a href="https://batteryuniversity.com/article/why-mobile-phone-batteries-do-not-last-as-long-as-an-ev-battery">Why Mobile Phone Batteries do not last as long as an EV Battery</a>)</p>
<p>Increasing the cycle depth also raises the internal resistance of the Li-ion cell. <strong>Figure 7 </strong>illustrates a sharp rise at a cycle depth of 61 percent measured with the DC resistance method(See also <a href="https://batteryuniversity.com/article/rising-internal-resistance">BU-802a: How does Rising Internal Resistance affect Performance?</a>) The resistance increase is permanent.</p>
<figure><strong><img src="https://batteryuniversity.com/img/content/equivalent_full_cycles.jpg" alt="Sharp rise in internal resistance by increasing cycle depth of Li-ion"></strong><figcaption><strong>Figure 7: Sharp rise in internal resistance by increasing cycle depth of Li-ion <sup>[4]</sup></strong></figcaption></figure>
<p><strong>Note:</strong> DC method delivers different internal resistance readings than with the AC method (green frame). For best results, use the DC method to calculate loading.<br></p>
<p><strong>Figure 8</strong> extrapolates the data from<strong> Figure 6</strong> to expand the predicted cycle life of Li-ion by using an extrapolation program that assumes linear decay of battery capacity with progressive cycling. If this were true, then a Li-ion battery cycled within 75%–25% SoC (blue) would fade to 74% capacity after 14,000 cycles. If this battery were charged to 85% with same depth-of-discharge (green), the capacity would drop to 64% at 14,000 cycles, and with a 100% charge with same DoD (black), the capacity would drop to 48%. For unknown reasons, real-life expectancy tends to be lower than in simulated modeling(See <a href="https://batteryuniversity.com/article/battery-performance-as-a-function-of-cycling">BU-208: Cycling Performance</a>)<strong><br></strong></p>
<figure><strong><img src="https://batteryuniversity.com/img/content/capacity-retention3.jpg" alt="Predictive modeling of battery life by extrapolation"></strong><figcaption><strong>Figure 8: Predictive modeling of battery life by extrapolation <sup>[5]</sup></strong></figcaption></figure>
<p>Li-ion batteries are charged to three different SoC levels and the cycle life modelled. Limiting the charge range prolongs battery life but decreases energy delivered. This reflects in increased weight and higher initial cost.</p>
<p>Battery manufacturers often specify the cycle life of a battery with an 80 DoD. This is practical because batteries should retain some reserve before charge under normal use(See <a href="https://batteryuniversity.com/article/discharge-methods">BU-501: Basics about Discharging</a>, “What Constitutes a Discharge Cycle”) The cycle count on DST (dynamic stress test) differs with battery type, charge time, loading protocol and operating temperature. Lab tests often get numbers that are not attainable in the field. </p>

<h3><strong>What Can the User Do?</strong></h3>
<p>Environmental conditions, not cycling alone, govern the longevity of lithium-ion batteries. The worst situation is keeping a fully charged battery at elevated temperatures. Battery packs do not die suddenly, but the runtime gradually shortens as the capacity fades.</p>
<p>Lower charge voltages prolong battery life and electric vehicles and satellites take advantage of this. Similar provisions could also be made for consumer devices, but these are seldom offered; planned obsolescence takes care of this.</p>
<p>A laptop battery could be prolonged by lowering the charge voltage when connected to the AC grid. To make this feature user-friendly, a device should feature a “Long Life” mode that keeps the battery at 4.05V/cell and offers a SoC of about 80 percent. One hour before traveling, the user requests the “Full Capacity” mode to bring the charge to 4.20V/cell.</p>
<p>The question is asked, “Should I disconnect my laptop from the power grid when not in use?” Under normal circumstances this should not be necessary because charging stops when the Li-ion battery is full. A topping charge is only applied when the battery voltage drops to a certain level. Most users do not remove the AC power, and this practice is safe.</p>
<p>Modern laptops run cooler than older models and reported fires are fewer. Always keep the airflow unobstructed when running electric devices with air-cooling on a bed or pillow. A cool laptop extends battery life and safeguards the internal components. Energy Cells, which most consumer products have, should be charged at 1C or less. Avoid so-called <a href="https://batteryuniversity.com/article/ultra-fast-chargers">ultra-fast chargers</a> that claim to fully charge Li-ion in less than one hour.<br></p>
<hr>
<h3><strong>References</strong></h3>
<p><strong><sup>[1] </sup></strong>Courtesy of Cadex<br><strong><sup>[2] </sup></strong>Source: Choi et al. (2002)<br><strong><sup>[3] </sup></strong>B. Xu, A. Oudalov, A. Ulbig, G. Andersson and D. Kirschen, "Modeling of Lithium-Ion Battery Degradation for Cell Life Assessment," June 2016. [Online]. Available: <a href="https://www.researchgate.net/publication/303890624_Modeling_of_Lithium-Ion_Battery_Degradation_for_Cell_Life_Assessment." target="_blank" rel="noreferrer noopener">https://www.researchgate.net/publication/303890624_Modeling_of_Lithium-Ion_Battery_Degradation_for_Cell_Life_Assessment.</a><br><sup><strong>[4]</strong> </sup>Source: Technische Universität München (TUM)<br><sup><strong>[5]</strong> </sup>With permission to use. Interpolation/extrapolation by OriginLab.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Self-driving Waymos secure final clearance for expansion beyond S.F (183 pts)]]></title>
            <link>https://www.sfchronicle.com/bayarea/article/self-driving-cars-waymo-sf-19523750.php</link>
            <guid>40751108</guid>
            <pubDate>Fri, 21 Jun 2024 16:24:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sfchronicle.com/bayarea/article/self-driving-cars-waymo-sf-19523750.php">https://www.sfchronicle.com/bayarea/article/self-driving-cars-waymo-sf-19523750.php</a>, See on <a href="https://news.ycombinator.com/item?id=40751108">Hacker News</a></p>
Couldn't get https://www.sfchronicle.com/bayarea/article/self-driving-cars-waymo-sf-19523750.php: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Testing Generative AI for Circuit Board Design (271 pts)]]></title>
            <link>https://blog.jitx.com/jitx-corporate-blog/testing-generative-ai-for-circuit-board-design</link>
            <guid>40751020</guid>
            <pubDate>Fri, 21 Jun 2024 16:16:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jitx.com/jitx-corporate-blog/testing-generative-ai-for-circuit-board-design">https://blog.jitx.com/jitx-corporate-blog/testing-generative-ai-for-circuit-board-design</a>, See on <a href="https://news.ycombinator.com/item?id=40751020">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article>
      <time datetime="2024-06-21 16:16:00">
        Jun 21, 2024 9:16:00 AM
      </time>
      
      
      <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><em>TLDR: We test LLMs to figure out how helpful they are for designing a circuit board. We focus on utility of frontier models (GPT4o, Claude 3 Opus, Gemini 1.5) across a set of design tasks, to find where they are and are not useful. They look pretty good for building skills, writing code, and getting useful data out of datasheets.</em></p>
<!--more-->
<p><br><em>TLDRN'T: We do not explore any proprietary copilots, or how to apply a things like a diffusion model to the place and route problem.</em></p>
<h2>Introduction</h2>
<div><p>Can an AI-powered chatbot help with a task as precise as circuit board design? These LLMs (Large Language Models) are famous for hallucinating details, and missing a *single* important detail can sink a design. Determinism is hard but super important for electronics design!&nbsp;</p><p>Today, several shallow product offerings are making AI for electronics design look mostly like hype. But I think there is real utility to be found here, if we can take a better approach.&nbsp;</p><p>In this article, we set LLMs to unfair tasks that expert human circuit board designers handle day to day. We're not looking for basic help, rather pushing on what it takes to help an expert do their job better.</p><p>It would be ridiculous (today) to expect great performance from these general purpose AIs on this expert task, especially because it is probably not well represented in the training data.</p><p>To test performance on difficult design tasks, we work with three of today's leading models:<br>- <a href="https://deepmind.google/technologies/gemini/pro/" rel="noopener">Gemini 1.5 Pro</a>&nbsp;from Google<br>- <a href="https://openai.com/index/hello-gpt-4o/" rel="noopener">GPT-4o</a> from OpenAI<br>- <a href="https://www.anthropic.com/news/claude-3-family" rel="noopener">Claude 3 Opus</a> from Anthropic</p><p>And explore prompting strategies to get the best performance out of all the models on each task. As part of the prompt, we also look for opportunities to improve the performance by asking the LLMs to write code to design circuit boards where possible.</p><p>The best results are reported for each model and for each task. Let's dig in!</p></div>
<h2><span>Asking stupid questions</span></h2>
<p><span>There is a lot to know in circuit board design, and nobody has mastered every relevant domain. Asking an LLM stupid questions is a great way to learn.<p>For example an RF engineer will know their own specialty quite well, but might not be a master of supply chain, power supply design, or how to shape copper reliefs to get high yields at the factory.</p><p>( Some RF engineers will scoff at this, but realistically the world contains people trying to learn things.)</p><p>To simulate someone new to a domain, I avoid prompt engineering, and use of precise expert vocabulary. I asked the LLMs a simple question: </p></span><span><em><span>What is the delay per unit length of a trace on a circuit board?</span></em><p>Claude 3 Opus was the clear winner here. Notice that it brought in the relevant concepts (microstrip, stripline, dielectric), got the answer right, and pointed out critical gotchas:</p></span></p>
<p><span><img src="https://blog.jitx.com/hs-fs/hubfs/Pasted%20image%2020240606134032-png.png?width=734&amp;height=1154&amp;name=Pasted%20image%2020240606134032-png.png" loading="lazy" width="734" height="1154" srcset="https://blog.jitx.com/hs-fs/hubfs/Pasted%20image%2020240606134032-png.png?width=367&amp;height=577&amp;name=Pasted%20image%2020240606134032-png.png 367w, https://blog.jitx.com/hs-fs/hubfs/Pasted%20image%2020240606134032-png.png?width=734&amp;height=1154&amp;name=Pasted%20image%2020240606134032-png.png 734w, https://blog.jitx.com/hs-fs/hubfs/Pasted%20image%2020240606134032-png.png?width=1101&amp;height=1731&amp;name=Pasted%20image%2020240606134032-png.png 1101w, https://blog.jitx.com/hs-fs/hubfs/Pasted%20image%2020240606134032-png.png?width=1468&amp;height=2308&amp;name=Pasted%20image%2020240606134032-png.png 1468w, https://blog.jitx.com/hs-fs/hubfs/Pasted%20image%2020240606134032-png.png?width=1835&amp;height=2885&amp;name=Pasted%20image%2020240606134032-png.png 1835w, https://blog.jitx.com/hs-fs/hubfs/Pasted%20image%2020240606134032-png.png?width=2202&amp;height=3462&amp;name=Pasted%20image%2020240606134032-png.png 2202w" sizes="(max-width: 734px) 100vw, 734px"></span></p>
<p><span>Notice the gotchas here! The speed of a signal changes based on which layer of a circuit board you route it on, and what the materials are.<p>You would never know that looking at a most PCB CAD tools, (e.g. Kicad, Altium) because all of their delay matching is in units of length. e.g. 'both these traces have to be 50 mm long' is a constraint you enter with a GUI. But that's not correct if you want your board to work - delay depends on which layer they are routed on, and what materials are in your board.</p><p>Getting that right: A+ answer for Claude here.&nbsp;</p><p>Google Gemini 1.5 performed the worst on this question. Maybe because it brought in a bunch of sources from the internet, and most of the writing in this discipline is dreck generated by SEO content mills. Incorporating AI summarization of lower quality writing seems to make the answers consistently worse.</p></span></p>
<h2><span>Finding Parts</span></h2>
<div><p>One of the superpowers of an experienced engineer is knowing things like: "A DAC + DSP system good enough for this audio pipeline should be about this big, and cost $1.40 in production". They'll then go do some turbo googling and find it.</p><p>How well can an AI that's been fed the entire internet do?</p><p>For this example I chose find parts for something cool: a robot <a href="https://www.youtube.com/watch?v=EER4pdKw2s4" rel="noopener">motor driver linked by optical ethernet</a> (instead of the usual <a href="https://youtu.be/gsOPZltbvgM" rel="noopener">CAN setups</a>). I want smaller cables, hundreds of possible devices, and compact cables that can survive IRL twisting and jostling.</p></div>
<p>You can see a communication layer like this as the daisy-chained black cabling in this picture from <a href="http://www.hebirobotics.com/" rel="noopener">HEBI</a>:</p>
<p><img src="https://blog.jitx.com/hs-fs/hubfs/image-png-1.png?width=510&amp;height=467&amp;name=image-png-1.png" loading="lazy" width="510" height="467" srcset="https://blog.jitx.com/hs-fs/hubfs/image-png-1.png?width=255&amp;height=234&amp;name=image-png-1.png 255w, https://blog.jitx.com/hs-fs/hubfs/image-png-1.png?width=510&amp;height=467&amp;name=image-png-1.png 510w, https://blog.jitx.com/hs-fs/hubfs/image-png-1.png?width=765&amp;height=701&amp;name=image-png-1.png 765w, https://blog.jitx.com/hs-fs/hubfs/image-png-1.png?width=1020&amp;height=934&amp;name=image-png-1.png 1020w, https://blog.jitx.com/hs-fs/hubfs/image-png-1.png?width=1275&amp;height=1168&amp;name=image-png-1.png 1275w, https://blog.jitx.com/hs-fs/hubfs/image-png-1.png?width=1530&amp;height=1401&amp;name=image-png-1.png 1530w" sizes="(max-width: 510px) 100vw, 510px"></p>
<div><p>Time to use AI to find the parts should I use for the ethernet switch, and the optical transceivers.</p><p>Here's the prompt:</p></div>
<p>I want to design a daisy-chained communications layer for a motor driver, using 100M optical Ethernet. Each motor controller will have a microcontroller that interfaces to the Ethernet network over RGMII. It needs to be compact, robust to mechanical vibration and shock, and handle temperatures up to 60 degrees Celsius. Please help me choose parts for the optical connectors, transceivers, and Ethernet networking device.&nbsp;<br>1. Think step by step as an expert electrical engineer.&nbsp;<br>2. Carefully consider how component choices relate to the requirements.&nbsp;<br>3. I'll give you a digital cookie if you get the answer correct.</p>
<div><p>Here I'm pulling more prompt engineering tricks to boost the performance of the model, and being careful in detailed specifications to really get this to work.</p><p>My initial guess for these parts would be:<br>- Use a small three port ethernet switch to for the daisy chain, hopefully something from Micrel (now Microchip) like the <a href="https://www.microchip.com/en-us/product/ksz8863" rel="noopener">KSZ8863MLL</a>.<br>- For the optical connector/transceiver I would go with the <a href="https://www.firecomms.com/optolock/" rel="noopener">OptoLock part</a> on the example system from Hebi. Very small and robust choice.&nbsp;</p><p>It would be amazing to get new suggestions for parts and architectures here. Something going beyond superficial advice into something practical would have huge impact!</p></div>
<div><p>Instead, performance across all models was uniformly bad and no amount of prompting or follow ups could fix it. It felt a lot like trying to get AI to solve a variant of the <a href="https://chatgpt.com/share/67a305cf-dc5f-45a2-a496-0886116f4659" rel="noopener">wolf, sheep, cabbage problem</a>. It's got the answer locked in, and it's hard to get out of that basin.</p><p>Here's a representative conclusion from Gemini 1.5:</p></div>
<div><p><span>&nbsp;Example Part Selection</span><br><span>- Optical Connectors: LC Duplex connectors (Amphenol or similar)</span><br><span>&nbsp;- Optical Transceivers: 100Base-FX SFP transceivers (Finisar, Cisco, or other reputable brands) with industrial temperature ratings</span><br><span>- Ethernet Networking Device: Microchip LAN8742A or Texas Instruments DP83848</span></p><p><span>Digital Cookie Time! 🍪</span></p><p><span>I hope this detailed breakdown helps you choose the right parts for your daisy-chained motor control system. Please let me know if you have any other questions.</span></p></div>
<p>Grading this:</p>
<p>- All models missed that to get the daisy chain you need a three port ethernet switch. They instead recommend an Ethernet Phy, which isn't going to do it.<br>- All models recommend using a huge SFP transceiver. These are usually found on big datacenter boards, and are not known for being shoved into tiny spaces in a robot joint, and then getting kicked around by Boston Dynamics employees.</p>
<div><p>Overall the generative models don't demonstrate a solid grasp on what the motor controller communication network is, or what application-specific considerations need to be made.&nbsp;</p><p>Without that the part selections are way off. This is a consistent experience. The LLMs will always suggest something, but it will be the 'average' application and miss a lot of the important subtlety. i.e. fiber optic ethernet happens in the mostly in the datacenter, so an average application for fiber optic means a datacenter device.</p><p>Trying to get them to choose an ADC, or sensor, or connector, shows similar 'average' results.</p><p>Maybe this speaks to the difficulty of the domain. If you're not within 10% or so of the global optimal performance in EE, your suggestions have near-zero value.</p></div>
<h2><span>Parsing datasheets</span></h2>
<p><span>Sadly, most of the data you need to design a circuit board is baked away in PDF datasheets, instead of being available via APIs. Directly trying to parse PDFs with python tends to not go well, but LLMs should be pretty good at pulling data from these human-structured documents.<p>I tested three different way of pulling information out:<br>- Copy/paste from the PDF, stuff it into a prompt.<br>- Capture a portion as an image, have the LLM interpret the image<br>- Upload the entire PDF</p></span></p>
<p><span>I'll be using the data available for the <a href="https://docs.nordicsemi.com/bundle/ps_nrf5340/page/keyfeatures_html5.html" rel="noopener">Nordic nRF5340 WLCSP</a> for the experiment. A little 4.0 x 4.4 mm Bluetooth chip, with an 820 page datasheet.&nbsp;</span></p>
<p><span><img src="https://blog.jitx.com/hs-fs/hubfs/image-png-2.png?width=350&amp;height=324&amp;name=image-png-2.png" loading="lazy" width="350" height="324" srcset="https://blog.jitx.com/hs-fs/hubfs/image-png-2.png?width=175&amp;height=162&amp;name=image-png-2.png 175w, https://blog.jitx.com/hs-fs/hubfs/image-png-2.png?width=350&amp;height=324&amp;name=image-png-2.png 350w, https://blog.jitx.com/hs-fs/hubfs/image-png-2.png?width=525&amp;height=486&amp;name=image-png-2.png 525w, https://blog.jitx.com/hs-fs/hubfs/image-png-2.png?width=700&amp;height=648&amp;name=image-png-2.png 700w, https://blog.jitx.com/hs-fs/hubfs/image-png-2.png?width=875&amp;height=810&amp;name=image-png-2.png 875w, https://blog.jitx.com/hs-fs/hubfs/image-png-2.png?width=1050&amp;height=972&amp;name=image-png-2.png 1050w" sizes="(max-width: 350px) 100vw, 350px"></span></p>
<p>Observations on this part: &nbsp;</p>
<ol>
<li>This is by no means the largest datasheet for a electrical component but has many typical features including pin tables, mechanical drawings, application specific notes, graphs, etc</li>
<li>This datasheet has significantly more content than you might expects for simpler components - like OpAmps or digital logic gates. If the LLMs are useful here, they will likely be useful for smaller cases.</li>
<li>This datasheet is about 570k tokens, a little more than half the huge context window available from Gemini.</li>
</ol>
<h3>Make a symbol and footprint</h3>
<div><p>First step is a to make a linked symbol and footprint (landpattern) for our component.&nbsp;</p><p>The most effective method here was to load the entire datasheet into the LLM via the chat file upload mechanism, and then query it interactively to get the details right. Gemini 1.5 was the most reliable for this task.</p><p>Here's the prompt to get the pin table (after uploading the datasheet):</p></div>
<p>Please write the the pin table for the wlcsp version of the nRF5340 as code using the following format:&nbsp;<br>1. One line for each pin&nbsp;<br>2. Each line structured as " [ pin-name | pad-number | direction | bank ]", where pin-name is the name of a pin e.g. GND, pad-number is the number of the pad that maps to that pin, e.g, 28, direction is Left is the pin is an input, and Right otherwise, bank indicates the function, e.g. gpio.&nbsp;<br>3. Wrap numbers following letters in square brackets, e.g. K3 becomes K[3], C1 becomes C[1], F10 becomes F[10]&nbsp;<br>4. Replace periods with square brackets, e.g. P0.20 becomes P0[20]</p>
<p>The AI then returns a block of text with our pin list in a usable format:</p>
<p><code>[ XC1 | A1 | Left | analog_input ]&nbsp;</code><br><code>[ XC2 | A2 | Left | analog_input ]&nbsp;</code><br><code>[ VDD | A3 | Right | power ]&nbsp;</code><br><code>[ VSS | A5 | Left | power ]&nbsp;</code><br><code>[ DECD | A7 | Right | power ]&nbsp;</code><br><code>[ DCCD | A9 | Right | power ]&nbsp;</code><br><code>[ D-| A11 | Left | usb ]&nbsp;</code><br><code>[ D+ | A12 | Left | usb ]&nbsp;</code><br><code>[ DECRF | B1 | Right | power ]&nbsp;</code><br><code>[ VSS | B2 | Left | power ]&nbsp;</code><br><code>[ DECR | B4 | Right | power ]&nbsp;</code><br><code>[ DECN | B5 | Right | power ]</code><br><code>... (continued)</code></p>
<div><p>It got this list exactly correct, impressive for 95 rows of data buried in an 820 page datasheet. Usually I have to get a model to write a little code to reach that level of accuracy, but that was unnecessary here.</p><p>Next I gave it some example code for a BGA footprint and had it generate a new version based on the datasheet information. Here's the resulting code:</p></div>
<div><p><code>; This test is based on the Nordic Semiconductor, nRF5340</code><br><code>&nbsp; ; Datasheet:</code><br><code>&nbsp; ; &nbsp;https://infocenter.nordicsemi.com/pdf/nRF5340_PS_v1.4.pdf</code><br><code>&nbsp; ;</code><br><code>&nbsp; ; Drawing:</code><br><code>&nbsp; ; &nbsp;https://infocenter.nordicsemi.com/pdf/nRF5340_PS_v1.4.pdf</code><br><code>&nbsp; ;</code><br><code>&nbsp; ; NSMD</code><br><code>&nbsp; val rows = 12</code><br><code>&nbsp; val cols = 8</code><br><code>&nbsp; val grid = Grid-Numbering(rows, cols)</code></p><p><code>&nbsp; val missing = to-pad-island(grid, "A[1] B[1] B[3] C[1] C[3] D[3] D[4] D[5] D[6] D[7] D[8] D[9] E[1] E[9] F[4] F[6] F[7] F[9] G[1] G[4] G[9] H[4] H[5] H[6] H[7] H[8] H[9]")</code></p><p><code>&nbsp; val planner = Full-Matrix-Planner(</code><br><code>&nbsp; &nbsp; ; Several pads are not present</code><br><code>&nbsp; &nbsp; inactive = missing,</code><br><code>&nbsp; &nbsp; pad-config = PadConfig-D(</code><br><code>&nbsp; &nbsp; &nbsp; copper-D-adj = ipc-bga-copper(</code><br><code>&nbsp; &nbsp; &nbsp; &nbsp; NonSolderMaskDefined,</code><br><code>&nbsp; &nbsp; &nbsp; &nbsp; density-level = DensityLevelC</code><br><code>&nbsp; &nbsp; &nbsp; &nbsp; ),</code><br><code>&nbsp; &nbsp; &nbsp; mask-D-adj = 0.0,</code><br><code>&nbsp; &nbsp; )</code><br><code>&nbsp; )</code></p><p><code>&nbsp; val body = PackageBody(</code><br><code>&nbsp; &nbsp; width = 4.390 +/- 0.047,</code><br><code>&nbsp; &nbsp; length = 3.994 +/- 0.047,</code><br><code>&nbsp; &nbsp; height = 0.71 +/- [0.06, 0.0]</code><br><code>&nbsp; )</code></p><p><code>&nbsp; val pkg = BGA(</code><br><code>&nbsp; &nbsp; num-leads = 95,</code><br><code>&nbsp; &nbsp; rows = rows,</code><br><code>&nbsp; &nbsp; columns = cols,</code><br><code>&nbsp; &nbsp; lead-diam = 0.35,</code><br><code>&nbsp; &nbsp; pitch = 0.35,</code><br><code>&nbsp; &nbsp; package-body = body,</code><br><code>&nbsp; &nbsp; lead-numbering = grid,</code><br><code>&nbsp; &nbsp; pad-planner = planner,</code><br><code>&nbsp; &nbsp; density-level = DensityLevelB</code><br><code>&nbsp; )</code></p></div>
<div><p>A few more misses here than in the pin table, but close overall. I have to go in and separately prompt for the depopulated balls in the grid, as well as correct the dimensions in the PackageBody.&nbsp;</p><p>(Note that I'm generating JITX code because it has a text-native representation. I bet that you could get the model to emit something like a Kicad symbol/footprint with a little more nudging in the prompt.)</p><p>Running the generated code (which you can find <a href="https://github.com/JITx-Inc/generative-ai-test-cases/blob/main/component-model/nRF5340.stanza" rel="noopener">here</a>), we get our footprint and symbols:</p></div>
<p><img src="https://blog.jitx.com/hs-fs/hubfs/image-png-3.png?width=2682&amp;height=1404&amp;name=image-png-3.png" loading="lazy" width="2682" height="1404" srcset="https://blog.jitx.com/hs-fs/hubfs/image-png-3.png?width=1341&amp;height=702&amp;name=image-png-3.png 1341w, https://blog.jitx.com/hs-fs/hubfs/image-png-3.png?width=2682&amp;height=1404&amp;name=image-png-3.png 2682w, https://blog.jitx.com/hs-fs/hubfs/image-png-3.png?width=4023&amp;height=2106&amp;name=image-png-3.png 4023w, https://blog.jitx.com/hs-fs/hubfs/image-png-3.png?width=5364&amp;height=2808&amp;name=image-png-3.png 5364w, https://blog.jitx.com/hs-fs/hubfs/image-png-3.png?width=6705&amp;height=3510&amp;name=image-png-3.png 6705w, https://blog.jitx.com/hs-fs/hubfs/image-png-3.png?width=8046&amp;height=4212&amp;name=image-png-3.png 8046w" sizes="(max-width: 2682px) 100vw, 2682px"></p>
<div><p>I really like the combination of code and scraped data here because of precision and flexibility.&nbsp;</p><p>I would much rather trust a hand-coded BGA footprint generator for the details, and have the LLM tell me which pads to omit. The backstop of the LLM generating the list of pins <em>and the missing pins</em>, then forcing them both to line up to line up in the code is a nice touch. I can also dig in and edit parameters directly if I want to customize.</p><p>Past the standard component model with a symbol and footprint, the LLM can also pull most of the useful data from the PDF. e.g. here is a generated parameterization for the IO pin levels for checking correctness of connections in a design:</p></div>
<p><code>property(P0[0].digital_io) = DigitalIO(CMOSOutput(VSS + 0.4, VDD - 0.4), 0.3*VDD, 0.7*VDD, "VDD", "VSS", 0)</code></p>
<p>If you don't have the AI return an answer as code, it tends to spread the data you want across multiple paragraphs, and it is easier to get the answer you want by just reading the datasheet instead.</p>
<p>It can even read a bit of the reference schematic and turn it into a netlist:</p>
<p><code><img src="https://blog.jitx.com/hs-fs/hubfs/image-png-4.png?width=1104&amp;height=1426&amp;name=image-png-4.png" loading="lazy" width="1104" height="1426" srcset="https://blog.jitx.com/hs-fs/hubfs/image-png-4.png?width=552&amp;height=713&amp;name=image-png-4.png 552w, https://blog.jitx.com/hs-fs/hubfs/image-png-4.png?width=1104&amp;height=1426&amp;name=image-png-4.png 1104w, https://blog.jitx.com/hs-fs/hubfs/image-png-4.png?width=1656&amp;height=2139&amp;name=image-png-4.png 1656w, https://blog.jitx.com/hs-fs/hubfs/image-png-4.png?width=2208&amp;height=2852&amp;name=image-png-4.png 2208w, https://blog.jitx.com/hs-fs/hubfs/image-png-4.png?width=2760&amp;height=3565&amp;name=image-png-4.png 2760w, https://blog.jitx.com/hs-fs/hubfs/image-png-4.png?width=3312&amp;height=4278&amp;name=image-png-4.png 3312w" sizes="(max-width: 1104px) 100vw, 1104px"></code></p>
<p><code>* Power Supply Nets:</code><br><code>net (nrf.VDD C4.p[1])</code><br><code>net (nrf.VDD C10.p[1])</code><br><code>net (nrf.VDD C11.p[1])</code><br><code>net (nrf.VDD C12.p[1])</code><br><code>net (nrf.VDD C13.p[1])</code><br><code>net (nrf.VDD C15.p[1])</code><br><code>net (nrf.VDD C17.p[1])</code><br><code>.... (continued)</code></p>
<div><p>It hallucinated this task a little bit, inventing resistors here and there.&nbsp;</p><p>Using LLMs to pull data from challenging sources and turn it into useful code was a helpful automation technique (and personally the one I use most). Accuracy can be boosted further by using extraction techniques to cross-reference the data.</p></div>
<h2><span>Designing circuits</span></h2>
<p><span>We've seen that LLMs can understand an image of a schematic well enough to (mostly) turn it into a netlist. Can they take on a much more challenging task and design the circuit itself?<p>As shown earlier, LLMs generated kinda-right, but actually very wrong suggestions for key components. To avoid that dependency, we tested our AIs on an analog circuit design task. This test is more about doing some math, and correctly arranging resistors and capacitors.</p><p>The task is to design an pre-amplifier for an electret microphone -- boosting and filtering an audio signal for sampling by an ADC. We start with a basic architecture exploration. Here's the prompt:</p></span></p>
<p><span>I want to design a microphone pre-amp where I need to bias the electret microphone and create a single-ended signal out to drive the ADC of a microcontroller. Include a bandpass filter with a gain of 20dB, corner frequencies at 100Hz and 20kHz. Help me select an architecture for this amplifier. Propose different filter architectures and describe their pros and cons for this application.&nbsp;<br>1. Think step by step as an expert electrical engineer&nbsp;<br>2. Carefully consider the requirements&nbsp;<br>3. If you get the answer right you get a digital cookie.</span></p>
<p><span>Claude 3 Opus came back with the best answer of the three contenders. I'll analyze it piece by piece.</span></p>
<p><span>Okay, let's think through this step-by-step as an expert electrical engineer:<br>1. Microphone biasing: Electret microphones typically require a DC bias voltage, usually between 1.5V to 10V, applied through a bias resistor. The value of this resistor impacts the microphone's output impedance and noise. A common range is 2.2kΩ to 10kΩ. We'll need to check the microphone's datasheet for specifics.<br>2. Amplifier architecture: For a single-ended output to drive an ADC, we can use a single-supply op-amp configuration. Some good options are:&nbsp;<br>&nbsp; &nbsp; a) Non-inverting amplifier: Simple, high input impedance which is good for the high-impedance mic signal. Gain is set by the feedback resistor ratio.&nbsp;<br>&nbsp; &nbsp; b) Inverting amplifier: Also simple, but lower input impedance. Gain is also set by resistor ratio.&nbsp;<br>&nbsp; &nbsp; c) Push-pull: Combines inverting and non-inverting amps for more output current drive, but more complex. For simplicity and good mic interfacing, a non-inverting amp seems best here.</span></p>
<div><p>Claude did a good job calling out the need to bias the microphone, nice to have that called out explicitly.</p><p>The proposals for non-inverting, and inverting amplifiers are reasonable. The proposal for push-pull configurations is nonsense. A <a href="https://en.wikipedia.org/wiki/Push%E2%80%93pull_output" rel="noopener">Push-Pull configuration</a> describes the transistors inside the op-amp at the output stage. It doesn't have anything to do with the architecture of the op amp circuit.</p><p>Moving on to the filter suggestions:</p></div>
<p><span>3. Bandpass filter: We need a 100Hz to 20kHz passband with 20dB gain. Some filter options:&nbsp;</span><br><span>&nbsp; &nbsp; &nbsp;a) Passive RC: Simple, but requires large component values for low frequencies, and loading affects cutoff frequencies. Gain must come from amp.&nbsp;</span><br><span>&nbsp; &nbsp; &nbsp;b) Active 1st-order: Sallen-Key or Multiple-Feedback topologies. Each is 1st-order, so we'd cascade a low-pass and high-pass for the bandpass response. Easy to integrate gain. Cutoff frequencies affected by component tolerance.&nbsp;</span><br><span>&nbsp; &nbsp; &nbsp;c) Active 2nd-order: Single stage 2nd-order bandpass like a Dual-Amplifier Bandpass (DABP). More complex, but more efficient than cascaded 1st-order. More stable cutoff frequencies.&nbsp;</span><br><span>&nbsp; &nbsp; &nbsp;d) Switched-capacitor: Uses a clock to set cutoff frequencies. Very stable, but requires a clock signal.&nbsp;</span></p>
<p><span>The comments on the Passive RC filter are reasonable.&nbsp;<p>The Sallen-Key analysis is wrong - Sallen-Key is a <a href="https://www.ti.com/lit/an/sboa231/sboa231.pdf?ts=1718092808060&amp;ref_url=https%253A%252F%252Fwww.google.com%252F" rel="noopener">second order filter</a>&nbsp;and can be unstable with this much gain.</p><p>The suggestion for the <a href="https://www.analog.com/media/en/training-seminars/tutorials/MT-209.pdf" rel="noopener">DABP</a> isn't wrong per se, but it is missing some nuance. It doesn't allow for very high gain (limit of 2.0). The complexity of a DABP justified when you need to handle higher frequencies and higher Q levels. This application doesn't require that, so it's a weird choice.</p><p>A switched capacitor filter would be bonkers -- complex, noise-sensitive, and requiring exotic components.</p></span></p>
<p><span>Moving on:</span></p>
<div><p><span>For this application, an active 2nd-order filter like a DABP seems a good balance of simplicity, stability, and easy gain integration. &nbsp;</span><br><span>1. Amplifier gain: The filter will have 20dB gain, which is a factor of 10. We can implement this with a non-inverting amp by setting the feedback resistor ratio to 9. For example, if R1 = 1kΩ, then R2 = 9kΩ.</span><br><span>2. Component values: We'll need to calculate the exact resistor and capacitor values for the DABP filter based on the desired cutoff frequencies and gain. There are online calculators to help with this.</span><br><span>&nbsp;So in summary, I propose a non-inverting op-amp configuration for the microphone, followed by a 2nd-order DABP active filter with 20dB gain. The exact component values will depend on the specific microphone chosen and the filter design equations. &nbsp;</span></p><p><span>How's that? Let me know if you have any other questions!</span></p></div>
<p><span>Here, Claude chooses the DABP and estimates some reasonablish values given that choice. (Usually you would choose values greater than 10k and less than 1M in op amp circuit design, to make assumptions about input and output impedance hold better). The wording is a bit confusing but it could be interpreted as a non-inverting op-amp for the gain stage, followed by a DABP filter with a lower gain. Which can work! Technically!<p>It's making slightly strange decisions across the board, but let's proceed with creating a complete design.&nbsp;</p><p>With a little more prompting, we can get Claude to write some code to do the detailed design and generate the circuit:</p></span></p>
<p><span><code>Great! Let's dive into the calculations and generate the netlists. We'll assume a 3.3V power supply and a microphone bias of 2.5V. We'll use an ideal op-amp model for simplicity.</code><p><code>; Microphone Bias Circuit:</code></p><p><code>; - Let's choose a bias resistor of 2.2kΩ.</code><br><code>; - Assuming negligible current draw from the op-amp, the mic bias will be very <br></code></p></span><span><code>; close to 2.5V.</code><p><code>; Netlist:&nbsp;</code><br><code>inst mic : electret-mic&nbsp;</code><br><code>inst rbias : chip-resistor(2200.0)&nbsp;</code><br><code>inst c1 : ceramic-cap(1.0e-6) ; Decoupling cap, assuming 1uF&nbsp;</code><br><code>net (vdd rbias.p[1])&nbsp;</code><br><code>net (rbias.p[2] mic.vdd c1.p[1])&nbsp;</code><br><code>net (gnd mic.gnd c1.p[2])</code></p></span></p>
<p><span>The decoupling cap in the bias circuit here really hampers the high-frequency performance of the circuit. What the circuit actually needs is a <em>coupling cap</em>, shown in the <code>human.mic</code> circuit here:</span></p>
<p><span><img src="https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-34-17-2563-PM.png?width=1205&amp;height=480&amp;name=image-png-Jun-21-2024-03-34-17-2563-PM.png" loading="lazy" width="1205" height="480" srcset="https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-34-17-2563-PM.png?width=603&amp;height=240&amp;name=image-png-Jun-21-2024-03-34-17-2563-PM.png 603w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-34-17-2563-PM.png?width=1205&amp;height=480&amp;name=image-png-Jun-21-2024-03-34-17-2563-PM.png 1205w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-34-17-2563-PM.png?width=1808&amp;height=720&amp;name=image-png-Jun-21-2024-03-34-17-2563-PM.png 1808w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-34-17-2563-PM.png?width=2410&amp;height=960&amp;name=image-png-Jun-21-2024-03-34-17-2563-PM.png 2410w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-34-17-2563-PM.png?width=3013&amp;height=1200&amp;name=image-png-Jun-21-2024-03-34-17-2563-PM.png 3013w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-34-17-2563-PM.png?width=3615&amp;height=1440&amp;name=image-png-Jun-21-2024-03-34-17-2563-PM.png 3615w" sizes="(max-width: 1205px) 100vw, 1205px"></span></p>
<p><span>Presumably in the training corpus, many articles and datasheets write extensively about decoupling caps. Maybe the "average" recommendation wins out here, and once it sees a positive and negative pin it slaps a capacitor across them right away. In our tests (and most product demos), LLMs <em>loved</em> to give naive advice about decoupling, which usually isn't as actively harmful as it is here.<br></span></p>
<p><span>Moving on to the amplifier:</span></p>
<p><code>; Non-Inverting Amplifier:<p>; - Let's set the gain to 10 (20dB).<br>; - Choose R1 = 1kΩ, then R2 = 9kΩ.</p><p>; Netlist:&nbsp;<br>inst amp : op-amp&nbsp;<br>inst r1 : chip-resistor(1000.0)&nbsp;<br>inst r2 : chip-resistor(9000.0)&nbsp;<br>net (mic.out r1.p[1])&nbsp;<br>net (r1.p[2] amp.v- r2.p[1])&nbsp;<br>net (amp.out r2.p[2])</p></code></p>
<p>The AI describes the amplifier as non-inverting, but then feeds the signal into the inverting input. It's also missing a few other parts and nets that would make for a working circuit. Easier to see in the generated schematic:</p>
<p><img src="https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-38-28-2912-PM.png?width=561&amp;height=349&amp;name=image-png-Jun-21-2024-03-38-28-2912-PM.png" loading="lazy" width="561" height="349" srcset="https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-38-28-2912-PM.png?width=281&amp;height=175&amp;name=image-png-Jun-21-2024-03-38-28-2912-PM.png 281w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-38-28-2912-PM.png?width=561&amp;height=349&amp;name=image-png-Jun-21-2024-03-38-28-2912-PM.png 561w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-38-28-2912-PM.png?width=842&amp;height=524&amp;name=image-png-Jun-21-2024-03-38-28-2912-PM.png 842w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-38-28-2912-PM.png?width=1122&amp;height=698&amp;name=image-png-Jun-21-2024-03-38-28-2912-PM.png 1122w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-38-28-2912-PM.png?width=1403&amp;height=873&amp;name=image-png-Jun-21-2024-03-38-28-2912-PM.png 1403w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-38-28-2912-PM.png?width=1683&amp;height=1047&amp;name=image-png-Jun-21-2024-03-38-28-2912-PM.png 1683w" sizes="(max-width: 561px) 100vw, 561px">(Cue EE eye twitching)</p>
<p>Moving on to the DABP filter implementation:</p>
<p><code>; DABP Bandpass Filter:<p>; - Cutoff frequencies: fl = 100Hz, fh = 20kHz<br>; - Gain at center frequency: G0 = 10 (20dB)<br>; - Quality factor: Let's choose Q = 1 for a fairly wide passband<br>; - Center frequency: f0 = sqrt(fl * fh) ≈ 1.414kHz<br>; - Let's choose C1 = C2 = 10nF<br>; - R1 = R2 = 1 / (2 * pi * f0 * C1) ≈ 11.2kΩ, let's use 11kΩ<br>; - R3 = R1 / (2 * Q * G0) ≈ 550Ω, let's use 560Ω<br>; - R4 = 2 * Q * R1 / G0 ≈ 2.2kΩ</p><p>; Netlist:&nbsp;<br>inst op1 : op-amp&nbsp;<br>inst op2 : op-amp&nbsp;<br>inst r1 : chip-resistor(11000.0)&nbsp;<br>inst r2 : chip-resistor(11000.0)&nbsp;<br>inst r3 : chip-resistor(560.0)&nbsp;<br>inst r4 : chip-resistor(2200.0)&nbsp;<br>inst c1 : ceramic-cap(10.0e-9)&nbsp;<br>inst c2 : ceramic-cap(10.0e-9)&nbsp;<br>net (amp.out op1.v+ r1.p[1] c1.p[1])&nbsp;<br>net (op1.v- op2.out r1.p[2] c1.p[2])&nbsp;<br>net (op1.out r3.p[1])&nbsp;<br>net (r3.p[2] op2.v- r2.p[1] c2.p[1])&nbsp;<br>net (op2.v+ r2.p[2] c2.p[2] r4.p[1])&nbsp;<br>net (r4.p[2] gnd)</p></code></p>
<p><img src="https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-41-30-4263-PM.png?width=934&amp;height=425&amp;name=image-png-Jun-21-2024-03-41-30-4263-PM.png" loading="lazy" width="934" height="425" srcset="https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-41-30-4263-PM.png?width=467&amp;height=213&amp;name=image-png-Jun-21-2024-03-41-30-4263-PM.png 467w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-41-30-4263-PM.png?width=934&amp;height=425&amp;name=image-png-Jun-21-2024-03-41-30-4263-PM.png 934w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-41-30-4263-PM.png?width=1401&amp;height=638&amp;name=image-png-Jun-21-2024-03-41-30-4263-PM.png 1401w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-41-30-4263-PM.png?width=1868&amp;height=850&amp;name=image-png-Jun-21-2024-03-41-30-4263-PM.png 1868w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-41-30-4263-PM.png?width=2335&amp;height=1063&amp;name=image-png-Jun-21-2024-03-41-30-4263-PM.png 2335w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-41-30-4263-PM.png?width=2802&amp;height=1275&amp;name=image-png-Jun-21-2024-03-41-30-4263-PM.png 2802w" sizes="(max-width: 934px) 100vw, 934px">Generated circuit (left), versus reference from ADI (right).</p>
<p>A few more misses on the netlist here, and about as correct as the amplifier (which is to say, not very). We also see the weirdly strong default of attaching capacitors across positive and negative pins. I guess LLMs are high decouplers.</p>
<p>And to round it off, we've got another reminder to add decoupling caps, and a reasonable note about what to watch out for:</p>
<p><span>The output of op2 is the final output of the pre-amp circuit. This should give you a good starting point. Remember to add decoupling capacitors and power supply connections as needed. Also, the actual component values may need to be adjusted based on the real specs of your chosen op-amp and the exact requirements of your ADC. Let me know if you have any other questions!</span></p>
<h3><span>Comparing against ground truth</span></h3>
<p><span>This <a href="https://www.ti.com/lit/ug/tidu765/tidu765.pdf" rel="noopener">reference design</a> from Texas Instruments is a good implementation of the requirements we asked these LLMs to design to. It uses passive RC filters (which the AI considered and avoided), and a single op-amp. I did a quick implementation of this in JITX (<a href="https://github.com/JITx-Inc/generative-ai-test-cases/blob/main/amplifier/reference.stanza" rel="noopener">code here</a>) to compare the AI generated circuit (<a href="https://github.com/JITx-Inc/generative-ai-test-cases/blob/main/amplifier/ai-generated.stanza" rel="noopener">code here</a>) to the TI version.</span></p>
<p><span><img src="https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-49-51-0951-PM.png?width=849&amp;height=547&amp;name=image-png-Jun-21-2024-03-49-51-0951-PM.png" loading="lazy" width="849" height="547" srcset="https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-49-51-0951-PM.png?width=425&amp;height=274&amp;name=image-png-Jun-21-2024-03-49-51-0951-PM.png 425w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-49-51-0951-PM.png?width=849&amp;height=547&amp;name=image-png-Jun-21-2024-03-49-51-0951-PM.png 849w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-49-51-0951-PM.png?width=1274&amp;height=821&amp;name=image-png-Jun-21-2024-03-49-51-0951-PM.png 1274w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-49-51-0951-PM.png?width=1698&amp;height=1094&amp;name=image-png-Jun-21-2024-03-49-51-0951-PM.png 1698w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-49-51-0951-PM.png?width=2123&amp;height=1368&amp;name=image-png-Jun-21-2024-03-49-51-0951-PM.png 2123w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-49-51-0951-PM.png?width=2547&amp;height=1641&amp;name=image-png-Jun-21-2024-03-49-51-0951-PM.png 2547w" sizes="(max-width: 849px) 100vw, 849px"></span></p>
<p><span>The AI generated circuit was three times the cost and size of the design created by that expert engineer at TI. It is also missing many of the necessary connections.&nbsp;<p>I found this breakdown surprising - it had no problems generating code in general, and was able to generate a syntactically correct netlist. The code runs! It's just that the pins are not in the right net statements and the resulting circuit is not correct.</p></span></p>
<h3><span>Testing higher level code</span></h3>
<p><span>In fairness, it's rare to write code like this to design a circuit board. In practice you're primarily calling higher level functions, e.g. selecting an op-amp, configuring a filter with parameters, then using a parametric pre-amp circuit:</span></p>
<p><code>&nbsp; val OpAmpType = components/STMicroelectronics/TS971ILT/component</code><br><code>&nbsp; val bandpass = BandpassConfig(gain = 34.0, low-cut = 100.0, high-pass = 20.0e3)</code><br><code>&nbsp; val preampType = ocdb/modules/amplifiers/microphone-preamp(OpAmpType, bandpass)</code><br><code>&nbsp; inst amp : preampType</code></p>
<div><p>Would LLMs do better if we try to get them to define and use higher-level functions instead?</p><p>Gemini 1.5 did the best here, inventing some reasonable APIs to functions that would exist in a library of helpful circuits:</p></div>
<p><code># Modules</code><br><code>amp = inverting_amplifier("amp1", gain=-20.0)&nbsp;</code><br><code>filt = sallen_key_filter("filt1", low_cutoff=100.0, high_cutoff=20.0e3)&nbsp;</code><br><code># Connections&nbsp;</code><br><code>net (mic.pos r_bias.p[1]) # Microphone to bias resistor&nbsp;</code><br><code>net (r_bias.p[2] c1.p[1] amp.in) # Bias resistor to amp through coupling capacitor</code></p>
<p>(Still misses on the netlist generation though.)</p>
<div><p>Our experiments with code generation reveal an interesting pattern: the LLMs are not great at generating detailed code for a netlist <em>to implement a circuit design</em>. That was a little surprising because as shown in the datasheet parsing section, they can write a 95% correct netlist matching an uploaded image of a schematic. This difference suggests that LLMs excel at information extraction and transformation tasks, but struggle with original design synthesis.</p><p>Having the LLMs generate higher-level code worked better than raw netlist generation, and seems like a promising path forward. This suggests a hybrid approach where human experts create parametric implementations of common circuits, which LLMs can then utilize and adapt, potentially increasing overall reliability.</p></div>
<p>Future research could either explore fine-tuning models specifically for netlist generation tasks, or (this being generative AI) wait a month and see how well the next generation of models does on this problem.</p>
<h2><span>Conclusion</span></h2>
<p><span>Circuit board design requires a lot of precision to get all the details correct -- for unsupervised AI techniques, I think there is a data problem here.&nbsp;<p>The context and meaning of a design -- What does this do? How do you know if it's good? -- are usually absent from schematic and board design data. Maybe there's a little text comment on the schematic with filter calculations, but that's usually it, and the rest lives in the engineer's head.</p><p>An electrical engineer looks at a schematic, understands a portion as a Sallen-Key filter, knows the limitations and function of that circuit, and composes that understanding with the rest of the design. A tremendous amount of context, which is not in any of the design data you can scrape from the internet.</p><p>Our experiments show that generative AI models can be useful for circuit board design, if you use them to write code. With that approach, there were still significant differences across Gemini 1.5, Claude 3 Opus, and GPT-4o for circuit board design.&nbsp;</p><p>Claude 3 was most helpful for answering questions to learn new domains. There's a risk of hallucinations, but those usually fall away if you interrogate the model until it's consistent. Certainly Claude is better and more helpful than the *average* article on circuit board design you would find via web search (there are very good articles, but they can be hard to find).</p><p>Gemini's huge context window was very helpful for pulling component data out of datasheets. It was the one area where the AI 'just worked' and we got way more usability than we expected.</p><p>I'm interested in further testing to find the limits of this technique. Google has done a lot of work on the "Text Haystack" problem to pull tiny pieces of information accurately out of a massive corpus of data, and that's serving them well here.</p></span></p>
<p><span><img src="https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-59-44-3288-PM.png?width=933&amp;height=601&amp;name=image-png-Jun-21-2024-03-59-44-3288-PM.png" loading="lazy" width="933" height="601" srcset="https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-59-44-3288-PM.png?width=467&amp;height=301&amp;name=image-png-Jun-21-2024-03-59-44-3288-PM.png 467w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-59-44-3288-PM.png?width=933&amp;height=601&amp;name=image-png-Jun-21-2024-03-59-44-3288-PM.png 933w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-59-44-3288-PM.png?width=1400&amp;height=902&amp;name=image-png-Jun-21-2024-03-59-44-3288-PM.png 1400w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-59-44-3288-PM.png?width=1866&amp;height=1202&amp;name=image-png-Jun-21-2024-03-59-44-3288-PM.png 1866w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-59-44-3288-PM.png?width=2333&amp;height=1503&amp;name=image-png-Jun-21-2024-03-59-44-3288-PM.png 2333w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-03-59-44-3288-PM.png?width=2799&amp;height=1803&amp;name=image-png-Jun-21-2024-03-59-44-3288-PM.png 2799w" sizes="(max-width: 933px) 100vw, 933px">From the <a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf" rel="noopener">Gemini 1.5 Report</a></span></p>
<p><span>Surprisingly GPT-4o didn't have the most useful answer in any of the categories we tested. It feels wrong to not include any outputs from the model in this summary article, so here's how GPT-4o feels about coming in third:</span></p>
<p><span><img src="https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-04-01-30-3403-PM.png?width=345&amp;height=342&amp;name=image-png-Jun-21-2024-04-01-30-3403-PM.png" loading="lazy" width="345" height="342" srcset="https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-04-01-30-3403-PM.png?width=173&amp;height=171&amp;name=image-png-Jun-21-2024-04-01-30-3403-PM.png 173w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-04-01-30-3403-PM.png?width=345&amp;height=342&amp;name=image-png-Jun-21-2024-04-01-30-3403-PM.png 345w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-04-01-30-3403-PM.png?width=518&amp;height=513&amp;name=image-png-Jun-21-2024-04-01-30-3403-PM.png 518w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-04-01-30-3403-PM.png?width=690&amp;height=684&amp;name=image-png-Jun-21-2024-04-01-30-3403-PM.png 690w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-04-01-30-3403-PM.png?width=863&amp;height=855&amp;name=image-png-Jun-21-2024-04-01-30-3403-PM.png 863w, https://blog.jitx.com/hs-fs/hubfs/image-png-Jun-21-2024-04-01-30-3403-PM.png?width=1035&amp;height=1026&amp;name=image-png-Jun-21-2024-04-01-30-3403-PM.png 1035w" sizes="(max-width: 345px) 100vw, 345px"><br></span></p>
<p><span>Overall we have some promising directions. Using LLMs for circuit board design looks a lot like using them for other complex tasks. They work well for pulling concrete data out of human-shaped data sources, they can do slightly more difficult tasks if they can solve that task by writing code, but eventually their capabilities break down in domains too far out of the training distribution.<p>We only tested the frontier models in this work, but I predict similar results from the open-source Llama or Mistral models. Some fine tuning on netlist creation would likely make the generation capabilities more useful.</p><p>Our work shows both the potential and limitations of current LLMs in specialized fields like circuit design. They're excellent at retrieving information and generating code, but struggle with the nuanced decision-making needed for complex designs. Future LLMs will likely improve here, but for the current model generation, they're best used as tools to assist human experts rather than as standalone designers.</p></span></p>
<p><span>Let me know what you think! You can find me on the JITX discord, and on <a href="https://x.com/DuncanHaldane" rel="noopener">Twitter</a>.</span></p></span>
      </p>
      
        
      
    </article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Acquires Rockset (221 pts)]]></title>
            <link>https://openai.com/index/openai-acquires-rockset/</link>
            <guid>40750391</guid>
            <pubDate>Fri, 21 Jun 2024 15:04:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/openai-acquires-rockset/">https://openai.com/index/openai-acquires-rockset/</a>, See on <a href="https://news.ycombinator.com/item?id=40750391">Hacker News</a></p>
Couldn't get https://openai.com/index/openai-acquires-rockset/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[How the square root of 2 became a number (115 pts)]]></title>
            <link>https://www.quantamagazine.org/how-the-square-root-of-2-became-a-number-20240621/</link>
            <guid>40750230</guid>
            <pubDate>Fri, 21 Jun 2024 14:50:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/how-the-square-root-of-2-became-a-number-20240621/">https://www.quantamagazine.org/how-the-square-root-of-2-became-a-number-20240621/</a>, See on <a href="https://news.ycombinator.com/item?id=40750230">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The ancient Greeks wanted to believe that the universe could be described in its entirety using only whole numbers and the ratios between them — fractions, or what we now call rational numbers. But this aspiration was undermined when they considered a square with sides of length 1, only to find that the length of its diagonal couldn’t possibly be written as a fraction.</p>
<p>The first proof of this (there would be several) is commonly attributed to Pythagoras, a 6th-century BCE philosopher, even though none of his writings survive and little is known about him. Nevertheless, “it was the first crisis in what we call the foundations of mathematics,” said <a href="https://publish.uwo.ca/~jbell/">John Bell</a>, a professor emeritus at Western University in London, Ontario.</p>
<p>That crisis would not be resolved for a long time. Though the ancient Greeks could establish what $latex \sqrt{2}$ was not, they didn’t have a language for explaining what it was.</p>
<p>For millennia, this sufficed. Renaissance mathematicians manipulated what they came to call irrational numbers while trying to solve algebraic equations. The modern notation for square roots came into use in the 16th and 17th centuries. But still, there was something slippery about them. Does $latex \sqrt{2}$ exist in the same way that 2 does? It wasn’t clear.</p>

<p>Mathematicians continued to live with that ambiguity. Then, in the mid-1800s, Richard Dedekind, among others, realized that calculus — which had been developed 200 years earlier by Isaac Newton and Gottfried Leibniz — stood on a shaky foundation. A reserved but gifted mathematician who worked slowly and published relatively little, Dedekind was preparing to teach his students about continuous functions when he realized that he couldn’t give a satisfactory explanation of what it meant for a function to be continuous.</p>
<p>He hadn’t even seen functions properly defined. And that, he argued, required a good understanding of how numbers worked — something mathematicians seemed to have taken for granted. How, he asked, could you know for sure that $latex \sqrt{2}$ multiplied by $latex \sqrt{3}$ equals $latex \sqrt{6}$? He wanted to provide some answers.</p>
<p>And so he introduced a way to define and construct the irrational numbers using only the rationals. Here’s how it works: First, split all the rational numbers into two sets, so that all of the fractions in one set are smaller than those in the other. For instance, in one group, collect all rationals that, when squared, are less than 2; in the other, put all rationals whose squares are greater than 2. Exactly one number plugs the hole between these two sets. Mathematicians give it the label $latex \sqrt{2}$. For Dedekind, then, an irrational number is defined by a pair of infinite sets of rational numbers, which create what he called a cut. “It’s a very lovely idea,” said <a href="https://ianstewartjoat.weebly.com/">Ian Stewart</a> of the University of Warwick. “You can pin down the missing irrational numbers not by describing them, but by describing the gap in which they have to sit.”</p>
<p>Dedekind showed that you can fill in the entire number line this way, rigorously defining for the first time what are now called real numbers (the rationals and the irrationals combined).</p>
<p>At around the same time that Dedekind introduced his cuts, his friend and collaborator Georg Cantor also began to think about irrational numbers. The overlap made their relationship complicated. “They were good friends, and they hated each other. They cooperated, and they ignored each other,” said <a href="https://www.openu.ac.il/en/about/president/pages/default.aspx">Leo Corry</a>, a historian of science who is the president of the Open University of Israel.</p>

<p>Cantor came up with a different definition of irrational numbers. He expressed each in terms of sequences of rational numbers that approached, or “converged” to, a particular irrational value. Though Cantor’s irrational numbers initially looked different from Dedekind’s, later work proved that they are mathematically equivalent.</p>
<p>Cantor’s work led him to ask how many numbers exist. The question might at first seem strange. There are infinitely many whole numbers — you can always keep adding one more. Presumably, that’s as big as a set of numbers can get. But Cantor showed that, paradoxically, though the number of fractions is the same as the number of integers, there are demonstrably more irrational numbers. He was the first to realize that <a href="https://www.quantamagazine.org/how-many-numbers-exist-infinity-proof-moves-math-closer-to-an-answer-20210715/">infinity comes in many sizes</a>.</p>
<p>The number line was more crowded, and weirder, than anyone had imagined. But mathematicians were only able to see that after a change in perspective.</p>

<p>Dedekind’s cuts are arguably the beginning of modern mathematics. “It’s really the first point in the history of mathematics where mathematicians actually know what they’re talking about,” Stewart said. Dedekind and others used his definition to prove major theorems in calculus for the first time — which allowed them not just to strengthen the edifice that Leibniz and Newton had built, but to add to it. Dedekind’s work enabled mathematicians to better understand sequences and functions. Emmy Noether, a prolific mathematician who helped shape the field of abstract algebra in the early 20th century, is said to have <a href="https://core.ac.uk/download/pdf/82253306.pdf">told her students</a> that “everything is already in Dedekind.”</p>
<p>A formal definition of $latex \sqrt{2}$ opened new horizons for exploration beyond the topics in calculus that initially motivated Dedekind. As Stewart put it, “After Dedekind, mathematicians started to realize that you can invent new concepts altogether. … The whole idea of what mathematics is about becomes much broader and more flexible.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Innovation heroes are a sign of a dysfunctional organization (276 pts)]]></title>
            <link>https://steveblank.substack.com/p/why-innovation-heroes-are-a-sign</link>
            <guid>40749754</guid>
            <pubDate>Fri, 21 Jun 2024 14:03:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steveblank.substack.com/p/why-innovation-heroes-are-a-sign">https://steveblank.substack.com/p/why-innovation-heroes-are-a-sign</a>, See on <a href="https://news.ycombinator.com/item?id=40749754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>A week ago I got invited to an “innovation hero” award ceremony at a government agency. I don’t know how many of these I’ve been to in the last couple years, but this one just made my head explode.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbd131c-ff57-4be3-8b28-f714b863e28c_1280x1658.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbd131c-ff57-4be3-8b28-f714b863e28c_1280x1658.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbd131c-ff57-4be3-8b28-f714b863e28c_1280x1658.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbd131c-ff57-4be3-8b28-f714b863e28c_1280x1658.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbd131c-ff57-4be3-8b28-f714b863e28c_1280x1658.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbd131c-ff57-4be3-8b28-f714b863e28c_1280x1658.heic" width="398" height="515.534375" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fdbd131c-ff57-4be3-8b28-f714b863e28c_1280x1658.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1658,&quot;width&quot;:1280,&quot;resizeWidth&quot;:398,&quot;bytes&quot;:317909,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbd131c-ff57-4be3-8b28-f714b863e28c_1280x1658.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbd131c-ff57-4be3-8b28-f714b863e28c_1280x1658.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbd131c-ff57-4be3-8b28-f714b863e28c_1280x1658.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdbd131c-ff57-4be3-8b28-f714b863e28c_1280x1658.heic 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>The award was for an entrepreneur who worked against all odds to buck the system to turn her insight into an application. She had realized it was possible to automate a process that was being done manually – reentering data from one spreadsheet to another and annotating it with additional data from another system. Inspired by her own work problem, she talked to her peers and other stakeholders, built multiple minimum viable products, and figured out how to get engineering, policy, legal, security and everyone else in the enterprise to actually approve it. And then she fought with the acquisition folks to buy the trivial amount of additional hardware needed to connect it. It was a development process that would’ve taken three weeks in a startup, but inside this agency took 10 months (which was considered fast.) At each step she was confronted with “we’re not budgeted for this” or “this isn’t on our schedule” and “this isn’t your job.” Most rational people would’ve given up and said “you can’t fight the system“ but yet she persisted.</p><p>Having seen this scenario play out multiple times at multiple large corporations and government agencies, I could’ve repeated the speech her agency director made at the ceremony verbatim. “Blah blah blah and a $100 bonus.” Everyone politely applauded and went back to work feeling good. I was simply depressed. Never once did anyone ever step back and say that what we just witnessed was leadership rewarding and perpetuating a dysfunctional and broken system.</p><p>I’m constantly puzzled why thoughtful and astute CEOs and Agency Directors never ask, “Why is it that innovations require heroics to occur in our organization? Why don’t we have a repeatable process for innovation? What are the obstacles in the way of delivering needed innovation with speed and urgency in our organization? Why is it that after each one of these awards we don’t go back and fix the parts of the system that made creating something new so difficult?”</p><p>Instead, everyone at this award ceremony just went back to work like it was business as usual. I realized that innovation in this organization was going to continue to happen by heroics and exception rather than by design. As I’ve seen play out way too many times, ultimately the innovators get tired of banging their heads against the wall and leave government service or large companies. Their organizations hemorrhage the very people they need to help them compete against aggressive adversaries or competitors who have them in their sights.</p><p data-attrs="{&quot;url&quot;:&quot;https://steveblank.substack.com/p/why-innovation-heroes-are-a-sign?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://steveblank.substack.com/p/why-innovation-heroes-are-a-sign?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><strong><span>An Organizational Design Problem</span><br></strong><span>Sadly, this wasn’t a single act of bad management or malice. No single individual thought they weren’t doing their job. However, if anyone had taken the time to deconstruct the reason for the roadblocks to innovation, they would have uncovered they weren’t just obstinate middle managers, or a single bad process. Asking a series of “</span><a href="https://en.wikipedia.org/wiki/Five_whys" rel="">five whys</a><span>,” (see </span><a href="https://hbr.org/2010/04/the-five-whys-for-startups" rel="">this HBR article</a><span>) would have discovered that:</span></p><ol><li><p>The agency’s existing processes were not designed for non-standard work. As in most large organizations, they were designed for the repeatable execution of pre-defined tasks.</p></li><li><p>There were no resources available for non-standard work or any parallel organization responsible for innovation.</p></li><li><p>The culture of the organization discouraged experimentation and punished the inevitable failures of a learning and discovery process.</p></li></ol><p><span>Ultimately, the root cause was the entire government agency lacked an Innovation Doctrine. This manifested itself as an organizational design problem. There was simply no permanent place in the organization for unscheduled innovation to happen. And even if there had been, there was </span><em>no way to turn demos into deployment with speed and at scale</em><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55655110-1375-4b9a-80ec-34aed9bd5bd9_714x295.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55655110-1375-4b9a-80ec-34aed9bd5bd9_714x295.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55655110-1375-4b9a-80ec-34aed9bd5bd9_714x295.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55655110-1375-4b9a-80ec-34aed9bd5bd9_714x295.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55655110-1375-4b9a-80ec-34aed9bd5bd9_714x295.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55655110-1375-4b9a-80ec-34aed9bd5bd9_714x295.heic" width="714" height="295" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/55655110-1375-4b9a-80ec-34aed9bd5bd9_714x295.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:295,&quot;width&quot;:714,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:33316,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55655110-1375-4b9a-80ec-34aed9bd5bd9_714x295.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55655110-1375-4b9a-80ec-34aed9bd5bd9_714x295.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55655110-1375-4b9a-80ec-34aed9bd5bd9_714x295.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55655110-1375-4b9a-80ec-34aed9bd5bd9_714x295.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong><span>Innovation Doctrine</span><br></strong><span>In peacetime and/or when you’re the dominant superpower (or a commercial market leader), the emphasis is on process, procedures, and sustainment of existing systems. Deviations from that create chaos and diverge from the predetermined are not welcomed, let alone promoted, and funded. They are eliminated. This works great when the external environment -competitors, adversaries, technologies, threats – is static. However in times of crisis, war or disruption, these unconventional thinkers and innovators are exactly what is needed, and their ideas need to be rapidly deployed.</span></p><p><span>Well-managed organizations realize that they need both innovation and execution. With execution being dominant in peacetime/competitive advantage you have </span><em>managers of process</em><span>. In crisis/wartime innovation is dominant. Instead of mangers of process you need </span><em>innovation leaders</em><span> who shepherd ideas through an </span><a href="https://steveblank.com/2017/09/14/how-companies-strangle-innovation/" rel="">innovation pipeline</a><span>. (see </span><a href="https://steveblank.com/2017/09/14/how-companies-strangle-innovation/" rel="">this HBR article</a><span>.) Successful organizations recognize that innovation isn’t a single activity (incubators, accelerators, hackathons); it is a strategically organized end-to-end&nbsp;process&nbsp;from idea to deployment.</span></p><p><span>While innovation and execution have different processes, people, and culture, they need to respect and depend on each other. This ambidexterity (see </span><a href="https://hbr.org/2004/04/the-ambidextrous-organization" rel="">this HBR article</a><span>) and the innovation processes that go with it require an innovation doctrine – an overall strategy and playbook for the entire organization and enterprise that includes an innovation pipeline and processes intended to drive innovation efforts, and describes the role of innovation leaders in an ambidextrous organization – all focused on rapid deployment of new capabilities.</span></p><p><strong>Lessons Learned</strong></p><ul><li><p>Innovation heroics are a symptom of a lack of an innovation doctrine</p></li><li><p>An innovation doctrine has a playbook, and innovation pipeline and describes the role of innovation leaders in an ambidextrous organization – all focused on rapid deployment of new capabilities</p></li><li><p>All large organizations – both government and corporate—need an innovation doctrine or else risk being outpaced by competitors.</p></li></ul></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How does a computer/calculator compute logarithms? (117 pts)]]></title>
            <link>https://zachartrand.github.io/SoME-3-Living/</link>
            <guid>40749670</guid>
            <pubDate>Fri, 21 Jun 2024 13:54:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zachartrand.github.io/SoME-3-Living/">https://zachartrand.github.io/SoME-3-Living/</a>, See on <a href="https://news.ycombinator.com/item?id=40749670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content" role="main">
      <!---
Summer of Math Exposition 3
How does a computer/calculator compute logarithms?

Author:  Zach Chartrand
Entry created on 2 July 2023
Living version created on 17 Oct 2023
-->

 
 
 


<p><em>Note: This is an updated version of the SoME 3 entry.  See the original
<a href="https://zachartrand.github.io/SoME-3/">here</a>.</em></p>

<h2 id="how-does-a-computercalculator-compute-logarithms">How does a computer/calculator compute logarithms?</h2>

<h2 id="the-curious-students-frustration">The curious student’s frustration</h2>
<p>There are many functions on a scientific or graphing calculator that we are
introduced to as high school students that, we are told, just work.  You select
the function, put in the value that you need to calculate, hit “=” or “ENTER”,
and SHABAM!  You have the correct answer to some arbitrary number of digits that
you are ensured are all 100% accurate.</p>

<p><img src="https://zachartrand.github.io/SoME-3-Living/images/Calculator_ln_2.png" width="50%" title="Pictured:  The natural log of 2 to 32 digits on the built-in Microsoft calculator"></p>

<p><em>Pictured:  The natural log of 2 to (an arbitrary) 32 digits on the built-in Microsoft calculator.</em></p>

<p>This is wonderful!  Necessary, even, for if our calculators and computers calculated
logarithms inaccurately, as well as exponentials, trig functions, and square roots,
to name but a few, a lot of scientific and engineering work would be broken and
end in catastrophe.  But how do we know that the value on the calculator is, in fact,
accurate?  How did the calculator crunch the input number and give us the output?
I remember this question being asked in high school, and the answer being no more than
a handwave.  To be fair to Algebra II teachers (which is where I was first introduced
to logarithms, if memory serves), the answer is beyond the scope of algebra, and lies in
calculus.  But it is an answer worth knowing, and it’s an answer that is very
knowable, even if you don’t have a background in calculus.  Calculus is the method
for deriving the formula used in calculators and computers, but the formula itself
is a pretty simple polynomial.</p>

<h2 id="the-geometric-series">The Geometric Series</h2>
<p>Most of us were introduced to polynomial equations in algebra.  For a quick refresher, a
polynomial is an expression involving at least one variable (usually $x$) and addition,
subtraction, multiplication, division, and integer power operators.  Here are a few examples:</p>

<p><a href="https://www.desmos.com/calculator/ikej8uzn59">Line</a>:  <br> $y = 5 + 2x$</p>

<p><a href="https://www.desmos.com/calculator/9ewvtz1lm6">Parabola</a>:  <br> $y = 1 - x - x^{2}$</p>

<p><a href="https://www.desmos.com/calculator/6dukowuqg0">Quartic</a>:  <br> $y = 4 - 2x - 5x^{2} + \frac{1}{2}x^{3} + x^{4}$</p>

<p><em>Note:  The links lead to Desmos graphs where you can change the parameters to see how it changes the graph.</em></p>

<p>While these equations of polynomials contain a <em>finite</em> number of terms, we can have polynomials
with an <em>infinite</em> number of terms.  These are called <strong>series</strong>, and one of the simplest types of
series is called a <strong>geometric series</strong>.  A geometric series contains an initial term, usually
denoted by the variable $a$, and each successive term is multiplied by a ratio, usually denoted by
the variable $r$.  Here are a couple of examples:</p>

\[\sum_{n=1}^{\infty} \frac{1}{2^n} = \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \ldots \nonumber\]

\[\sum_{n=0}^{\infty} 2 \cdot (-3)^n = 2 - 6 + 18 - 54 + \ldots \nonumber\]

<p>In the first series, the initial value is $\frac{1}{2}$, and each term after it is the
previous term multiplied by $\frac{1}{2}$.  The second series begins with the number 2,
and each term after it is the previous term multiplied by -3.  Because the first series’
terms get smaller in absolute value for each successive term, the sum approaches, or
<strong>converges</strong>, to a value<sup id="fnref:convergence" role="doc-noteref"><a href="#fn:convergence" rel="footnote">1</a></sup>.  The second series’ terms get larger in absolute value
with each successive term, so the series <strong>diverges</strong> without resolving to a defined value.</p>

<p>The general formula for a geometric series is</p>

\[\sum_{n=0}^{\infty} ar^n = a + ar + ar^2 + \ldots + ar^n + \ldots\]

<p>If we set this formula equal to $s$, we can do some rearranging to find a function that
this series is equivalent to:</p>

\[s = a + ar + ar^2 + \ldots + ar^n + \ldots \nonumber\]

<p>By pulling an $r$ out of all the terms after the first one, we get</p>

\[s = a + r(a + ar + ar^2 + \ldots + ar^{n-1} + \ldots) \nonumber\]

<p>Despite the fact that $ar^n$ becomes $ar^{n-1}$, we have an infinite number of terms,
so if we were to expand out the terms in the parentheses, we get the same series as $s$
in the first line; therefore, we can substitute the terms in the parentheses with $s$!<sup id="fnref:notfactorial" role="doc-noteref"><a href="#fn:notfactorial" rel="footnote">2</a></sup></p>

\[s = a + rs \nonumber\]

<p>Move $rs$ to the left side of the equation:</p>

\[s - rs = a, \nonumber\]

<p>combine like-terms:</p>

\[s(1 - r) = a, \nonumber\]

<p>and solve for $s$:</p>

\[s = \frac{a}{1 - r}. \nonumber\]

<p>We can now set both $s$ expressions equal to each other:</p>

\[\frac{a}{1 - r} = \sum_{n=0}^{\infty} ar^n = a + ar + ar^2 + \ldots + ar^n + \ldots\]

<p>Note that this assumes the series converges.  This formula does not hold if the
series diverges.</p>

<p>Regarding the natural logarithm, the geometric series we are interested in is the one where $a = 1$
and $r = -x$:</p>

\[\frac{1}{1-(-x)} = 1 + (-x) + (-x)^2 + (-x)^3 + \ldots + (-x)^n + \ldots \nonumber   \\
  \frac{1}{1+x}    = 1 - x + x^2 - x^3 + x^4 + \ldots + (-x)^n + \ldots\]

<p>This series converges when $|x| &lt; 1$.  Now, you might think that some of the algebraic
manipulation we did earlier was invalid, but we can check our work.  Below, I have a Desmos
graph with both the function $\frac{1}{1+x}$ and the infinite series.  By moving the slider for $N$,
you can add successive terms to the series and see that, as more and more terms are added,
the series graph becomes a better and better approximation to the function graph for $|x| &lt; 1$.</p>

<p><a href="https://www.desmos.com/calculator/t6u3zwhabp">Desmos: Geometric Series</a></p>

<p><img src="https://zachartrand.github.io/SoME-3-Living/images/desmos-geometric-series.png" width="50%" title="Pictured: The 5-term approximation of the geometric series from above (black line) compared to the function 1/(1+x) (green line)."></p>

<p><em>Pictured: The 5-term approximation of the geometric series from above (black line)</em>
<em>compared to the function $\frac{1}{1+x}$ (green line). Note how the series approximation</em>
<em>is only accurate for $|x| &lt; 1$.</em></p>

<h2 id="getting-a-series-for-the-natural-logarithm">Getting a series for the natural logarithm</h2>

<p>“This is all very interesting, but what does this have to do with computing logarithms?”</p>

<p>It turns out that the function $\frac{1}{1+x}$ and the natural logarithm are directly related.
Specifically, the area under the curve $\frac{1}{1+t}$ from $t = 0$ to any value $x$ is the
natural logarithm of $1+x$.  In mathematical symbols, this is rendered as</p>

\[\int_{0}^{x} \frac{1}{1+t} dt = \ln(1+x)\]

<p>While the understanding of the calculus involved is beyond the scope of this article,
I made a <a href="https://www.desmos.com/calculator/czktma6spu">Desmos graph</a> where you can play
with values of $x$ ($a$ in the graph) and see the area under the curve, with its exact
value shown and a 1x1 square area shown as a comparison.</p>

<p><img src="https://zachartrand.github.io/SoME-3-Living/images/desmos-integral.png" width="50%" title="Pictured: The integral of 1/(1+x) from 0 to e-1 (shaded in blue) and a square of Area = 1 (shaded in green). Both shaded areas are equal in size."></p>

<p><em>Pictured: The integral of $\frac{1}{1+x}$ from 0 to $e - 1$ (shaded in blue) and a square of Area = 1 (shaded in green).</em>
<em>Both shaded areas are equal in size.</em></p>

<p>Taking integrals is an inverse problem and for some functions is very difficult, if not impossible, to get the exact solution.
However, for polynomials, it’s actually very easy.  For a given polynomial term, increase the degree
by one, divide the term by the new degree, and take the difference of the function evaluated at the two
integrand values (the values at the top and bottom of the $\int$ ).</p>

<p>We’ll start by setting the natural logarithm equal to the integral of our geometric series:</p>

\[\begin{align*}
    \ln(1+x) &amp; = \int_{0}^{x} \frac{1}{1+t} dt                                                   \\
             &amp; = \int_{0}^{x} (1 - t + t^2 - t^3 + t^4 + \ldots + (-t)^n + \ldots) \space dt
  \end{align*}\]

<p>The integral of a sum is the sum of the integrals of each term, so we can take this one term at a time.
Starting with the first term,</p>

\[\begin{align*}
    \int_{0}^{x} 1 dt &amp; = \int_{0}^{x} 1t^0 dt                     \\
                      &amp; = \frac{t^{0+1}}{0+1} \Big|_{t=0}^{t=x}    \\
                      &amp; = \frac{t^1}{1} \Big|_{t=0}^{t=x}          \\
                      &amp; = t \Big|_{t=0}^{t=x}                      \\
                      &amp; = x - 0 = x  
  \end{align*}\]

<p>Let me explain the symbols above.  We start with taking the integral of 1, a constant, in terms of $t$
(which is a dummy variable to distinguish it from $x$ in the answer).  A constant can be represented as
a zero-degree polynomial term, so we can represent 1 as 1 times $t^0$.  We add one to the degree, so 0
becomes 1, then we divide by the new degree, which is 1 in this case.  Our result is $t$.  We then need to
evaluate this term at $t = x$ and $t = 0$ and subtract them (this is what the vertical bar represents).
The result is $x - 0$, which reduces to $x$.  So the first term of our infinite series for
$\ln(1+x)$ is $x$!  Let’s do the second term:</p>

\[\begin{align*}
    \int_{0}^{x} -t dt &amp; = \int_{0}^{x} -t^1 dt                                                 \\
                       &amp; = -\frac{t^{1+1}}{1+1} \Big|_0^x = -\frac{t^2}{2} \Big|_{t=0}^{t=x}    \\
                       &amp; = -\frac{x^2}{2} - \biggl(-\frac{0^2}{2} \biggr)                       \\
                       &amp; = -\frac{x^2}{2} + 0                                                   \\
                       &amp; = -\frac{x^2}{2}
  \end{align*}\]

<p>Our second term is $-\frac{x^2}{2}$.  You may start to see the overall pattern, but we’ll do one more:</p>

\[\begin{align*}
    \int_{0}^{x} t^2 dt &amp; = \frac{t^{2+1}}{2+1} \Big|_{t=0}^{t=x}    \\
                        &amp; = \frac{t^3}{3} \Big|_{t=0}^{t=x}          \\
                        &amp; = \frac{x^3}{3} - \frac{0^3}{3}            \\
                        &amp; = \frac{x^3}{3}
  \end{align*}\]

<p>With this, the pattern starts to come into focus.  We have a series where each term is a polynomial
divided by its degree, where all of the odd degree polynomial terms are positive and all the even
terms are negative.  Written as a series,</p>

\[\begin{align}
    \ln(1+x) &amp; = \sum_{n=0}^{\infty} (-1)^n \frac{x^{n+1}}{n+1}                \\
    \ln(1+x) &amp; = x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \ldots
  \end{align}\]

<p>In fact, if we were to integrate the general term of the geometric series, this is exactly what we get:</p>

\[\begin{align*}
    \int_0^x \frac{1}{1+t} dt &amp; = \int_0^x \sum_{n=0}^{\infty} (-t)^n dt                                             \\
                              &amp; = \sum_{n=0}^\infty \biggl( \int_0^x (-t)^n dt \biggr)                               \\
                              &amp; = \sum_{n=0}^\infty \biggl( \int_0^x (-1)^n t^n dt \biggr)                           \\
                              &amp; = \Biggl( \sum_{n=0}^\infty (-1)^n \frac{t^{n+1}}{n+1} \Biggr) \Bigg|_{t=0}^{t=x}    \\
                              &amp; = \sum_{n=0}^{\infty} (-1)^n \frac{x^{n+1}}{n+1}
  \end{align*}\]

<p>So, we did it!  We have a polynomial series that calculates the natural logarithm!  Granted, we need to shift our
input by 1, as this series is $\ln(1+x)$, but that’s a simple hurdle to jump!</p>

<p>Except we’re limited.  Very limited.  Remember, the geometric series only applies to the function $\frac{1}{1+x}$ for
$|x| &lt; 1$, otherwise it diverges.  The same limitation exists here.  What’s worse, the series only converges quickly
for $|x| &lt; \frac{1}{2}$; outside this range, the number of terms becomes too much even for a computer to calculate in
a reasonable amount of time. This is fine if all the values you need to calculate a logarithm for are between 0.5 and 1.5,
but most problems involving logarithms tend to have very large values.</p>

<p>Well, we tried.  Pack up, go home, see you next time.</p>

<h2 id="properties-of-logarithms">Properties of logarithms</h2>

<p>Actually, as it turns out, this <em>would</em> be the end if we were dealing with almost any other function.
But we are dealing with logarithms, and logarithms are special.  There are two properties that we
can use to reduce our inputs so that we can calculate the logarithm of any value we want!</p>

<p>The first property is that <em>multiplication in the input is equivalent to addition of the outputs</em>.</p>

<p>This means that if the input is the product of two factors, the logarithm of that product is the same
as the logarithms of each factor taken individually and added together.  For example, if we wanted to
find the natural logarithm of the value 6, we can compute either $\ln(6)$ or $\ln(2) + \ln(3)$, because
$6 = 2 \cdot 3$.</p>

<p>The general form of this property is</p>

\[\log_b(ac) = \log_b(a) + \log_b(c)\]

<p>This also applies to division in the inputs, but instead, you subtract the outputs:</p>

\[\log_b \biggl( \frac{a}{c} \biggr)  = \log_b(a) - \log_b(c)\]

<p>The second property is that <em>the logarithm of a value raised to some power is that power times the
logarithm of the (unraised) value</em>.</p>

<p>This means that exponents in the input of the logarithm can hop out and
become a coefficient in the output. For example, the number 8 can also be written as
$2^3$ $(2 \cdot 2 \cdot 2 = 8)$, so $\ln(8) = \ln(2^3) = 3\ln(2)$.</p>

<p>The general form of this property is</p>

\[\log_b(a^c) = c \log_b(a)\]

<p>Each of these properties allows us to reduce the argument of the logarithm in different ways. Using the
first property, if we have the natural logarithm of a known value (2 and 10 are common choices), we can
reduce the argument by powers of that constant until we get a small enough input. Let’s use 15 as an
example. If we have the natural logarithm of 2 calculated, we can keep dividing 15 by 2 until it is close
to 1 while keeping track of the number of times we divided by 2. After dividing by 2 four times,
we reduce 15 to 0.9375, so $0.9375 \cdot 2^4 = 15$. We can plug this value into our series like this:</p>

\[\begin{align*}
    \ln(15) &amp; = \ln(2^4 \cdot 0.9375)                                                             \\
            &amp; = 4 \ln(2) + \ln(0.9375)                                                            \\
            &amp; = 4 \ln(2) + \ln(1 + (0.9375 - 1))                                                  \\
            &amp; = 4 \ln(2) + \ln(1 + (-0.0625))                                                     \\
            &amp; = 4 \ln(2) + (-0.0625) - \frac{(-0.0625)^2}{2} + \frac{(-0.0625)^3}{3} + \ldots     \\
            &amp; = 2.772588722239781... - 0.0625 - 0.001953125 - 0.000081380208333... + \ldots
  \end{align*}\]

<p>We can see that as terms are added to the series, the approximation gets more and more precise as
each term gets smaller and smaller in magnitude.  In this particular example, the next term is
less than one tenth the absolute value of the previous term. This means that the approximation gains
about one digit of accuracy for each term we add to the series. To see this, here is a list of the
first eight approximations for $\ln(15)$, as well as the accepted value:</p>

\[\begin{align*}
    &amp; \text{0 terms:}        &amp;&amp; 2.772588722239781    \\
    &amp; \text{1 term:}         &amp;&amp; 2.710088722239781    \\
    &amp; \text{2 terms:}        &amp;&amp; 2.708135597239781    \\
    &amp; \text{3 terms:}        &amp;&amp; 2.708054217031448    \\
    &amp; \text{4 terms:}        &amp;&amp; 2.708050402334182    \\
    &amp; \text{5 terms:}        &amp;&amp; 2.708050211599319    \\
    &amp; \text{6 terms:}        &amp;&amp; 2.708050201665211    \\
    &amp; \text{7 terms:}        &amp;&amp; 2.708050201133027    \\
    &amp; \text{8 terms:}        &amp;&amp; 2.708050201103923    \\
    &amp; \                      &amp;&amp;                      \\
    &amp; \text{Accepted value:} &amp;&amp; 2.708050201102210
\end{align*}\]

<p>So now we have a formula for finding the natural logarithm of any number to arbitrary precision
based on the number of terms we use in the series. We did it! I even have a
<a href="https://github.com/zachartrand/SoME-3-Living/blob/main/scripts/log.py">Python script</a>
that implements this formula to return the natural logarithm of any value within 64-bit floating-point
precision using 48 terms.</p>

<p>Now, this formula is perfectly good to use. After all, it’s the formula used in
<a href="https://github.com/python/cpython/blob/main/Lib/_pydecimal.py#L5738">Python’s decimal module</a>
to find the natural logarithm for base-10 number representation. But what if there were a better
formula? One that converged much faster to find the natural logarithm with fewer terms?</p>

<h2 id="the-better-formula">The better formula</h2>

<p>How can an infinite series converge faster? Well, it turns out that for inputs less than 1, series
that have terms that increase by two degrees will converge much faster than series that only increase
by one. For example, if you look at the series for
<a href="https://en.wikipedia.org/wiki/Sine_and_cosine#Series_definitions">sine and cosine</a>,
they increase in degree by 2 for each term and converge very quickly (in fact, if you look at the C
implementations of the
<a href="https://github.com/freemint/fdlibm/blob/master/k_sin.c">sine kernel</a> and
<a href="https://github.com/freemint/fdlibm/blob/master/k_cos.c">cosine kernel</a>, they only use six
polynomial terms to get double floating-point precision, a much quicker convergence than our 48 terms!).
So how do we get this series to skip a degree for each term? Surely, we can’t just get rid of all the
even-degree terms or all of the odd-degree terms and still get an accurate answer, right?</p>

<p>We can if we do it in a clever way. Let’s look at the series again:</p>

\[\ln(1+x) = \sum_{n=0}^{\infty} (-1)^n \frac{x^{n+1}}{n+1} = x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \ldots \nonumber\]

<p>This is the series for $\ln(1+x)$, but what if we could get a series for a slightly different input? For instance,
what would the series be for $\ln(1-x)$? We can rewrite $\ln(1-x)$ as $\ln(1 + (-x))$. To get its series, let’s plug (-x)
into our natural log series:</p>

\[\begin{align}
    \ln(1-x) &amp; = \ln(1 + (-x)) \nonumber                                                             \\
             &amp; = (-x) - \frac{(-x)^2}{2} + \frac{(-x)^3}{3} - \frac{(-x)^4}{4} - \ldots \nonumber    \\
             &amp; = -x - \frac{x^2}{2} - \frac{x^3}{3} - \frac{x^4}{4} + \ldots \nonumber               \\
    \ln(1-x) &amp; = \sum_{n=0}^{\infty} -\frac{x^{n+1}}{n+1}
  \end{align}\]

<p>The difference between this series and our original series is that all the odd terms have become negative
while the even terms remain negative. This is perfect! If you don’t understand why, let me put each series in
expanded form with all the terms lined up:</p>

\[\begin{align*}
    \ln(1+x) &amp;= +x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} \
               + \frac{x^5}{5} - \frac{x^6}{6} + \ldots     \\
    \ln(1-x) &amp;= -x - \frac{x^2}{2} - \frac{x^3}{3} - \frac{x^4}{4} \
               - \frac{x^5}{5} - \frac{x^6}{6} - \ldots
  \end{align*}\]

<p>It should be apparent from this form that if we add the two series together, the odd terms will cancel out,
and if we subtract the second series from the first series, the even terms will cancel out. So, should we add
the series together, or subtract them? This must be determined by seeing how the logarithm function input changes
when we add or subtract the two functions together. If we add the two functions together, we get</p>

\[\ln(1+x) + \ln(1-x) = \ln((1+x)(1-x)) = \ln(1-x^2)\]

<p>And if we subtract the two functions, we get</p>

\[\ln(1+x) - \ln(1-x) = \ln \biggl( \frac{1+x}{1-x} \biggr)\]

<p>using the first property of logarithms.<sup id="fnref:artanh" role="doc-noteref"><a href="#fn:artanh" rel="footnote">3</a></sup> Let’s remind ourselves that $x$ is the value we plug into the
series. If we want the natural logarithm of some value—let’s call it $u$—then we have to find the
value of $x$ to plug into our series that will get us the natural log of $u$. We can find this by
setting $u$ equal to the input of each new, combined logarithm and solve for $x$. For the added
logarithm, set $u$ equal to $1 - x^2$:</p>

\[\begin{gather*}
    u = 1 - x^2      \\
    x^2 = 1 - u        \\
    x = \sqrt{1-u}
  \end{gather*}\]

<p>For the subtracted logarithm, set $u$ equal to $\frac{1+x}{1-x}$:</p>

\[\begin{gather*}
    u = \frac{1+x}{1-x}    \\
    u(1-x) = 1 + x         \\
    u - ux  = 1 + x        \\
    u - 1 = ux + x         \\
    ux + x = u - 1         \\
    x(u + 1) = u - 1       \\
    x = \frac{u-1}{u+1}
  \end{gather*}\]

<p>The addition of the logarithms requires taking a square root—a complicated function in and of itself—to convert
our main input into the series input, while the subtraction of the logarithms only requires the basic operations of
addition, subtraction, and division.<sup id="fnref:radiusofconvergence" role="doc-noteref"><a href="#fn:radiusofconvergence" rel="footnote">4</a></sup> Subtracting the logarithms is the clear winner.
Now we can take our two series and combine them in this manner:</p>

\[\begin{align*}
    \ln(1+x) - \ln(1-x) = \space &amp; x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4}
      + \frac{x^5}{5} - \frac{x^6}{6} + \ldots                                    \\
     - \space (- &amp; x - \frac{x^2}{2} - \frac{x^3}{3} - \frac{x^4}{4}
      - \frac{x^5}{5} - \frac{x^6}{6} - \ldots)
  \end{align*}\]

<p>Distributing the negative sign on the second series, we get</p>

\[\begin{align*}
    \ln(1+x) - \ln(1-x) = \space &amp; x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \frac{x^5}{5}
      - \frac{x^6}{6} + \ldots    \\
    + \space &amp; x + \frac{x^2}{2} + \frac{x^3}{3} + \frac{x^4}{4} + \frac{x^5}{5} + \frac{x^6}{6} + \ldots ,
  \end{align*}\]

<p>and then combining them gives us</p>

\[\begin{align}
    \ln \biggl( \frac{1+x}{1-x} \biggr) &amp; = 2x + \frac{2}{3}x^3 + \frac{2}{5}x^5 + \frac{2}{7}x^7 + \ldots    \\
    &amp; = \sum_{n=0}^{\infty} \frac{2}{2n+1}x^{2n+1} .
  \end{align}\]

<p>Substituting our initial value, $u$, into the input, we get</p>

\[\begin{align}
  \ln(u) &amp; = \sum_{n=0}^{\infty} \frac{2}{2n+1} {\biggl( \frac{u-1}{u+1} \biggr)}^{2n+1}    \\
         &amp; = 2{\biggl( \frac{u-1}{u+1} \biggr)} + \frac{2}{3} {\biggl( \frac{u-1}{u+1} \biggr)}^3
  + \frac{2}{5} {\biggl( \frac{u-1}{u+1} \biggr)}^5 + \frac{2}{7} {\biggl( \frac{u-1}{u+1} \biggr)}^7 + \ldots
  \end{align}\]

<p>We now have a series that increases by two degrees for each new term added! But how much quicker does
this series converge compared to our old series? I have made a
<a href="https://www.desmos.com/calculator/zr1vhmoign">Desmos graph</a> where you can compare the two series.
The first series for $\ln(1+x)$ (shifted right by 1) is in red and our new series is in green.
Slide the value for $N$ to add terms to the series approximations, and note how they converge
both by looking at the graph and by looking at the calculation for the natural log of 2.
(Also, notice the difference in the radius of convergence.) The old series takes 36 terms to reach Desmos’ calculator
accuracy (11 decimal places), but the new series only takes 12! We reduced the number of terms we need
by one third! And when you have the option to reduce the argument like we did with the example to find
the natural log of 15, the number of terms reduces further. In my
<a href="https://github.com/zachartrand/SoME-3-Living/blob/main/scripts/log_fast.py">Python script for the new series</a>,
the code calculates the natural logarithm for any number with 15 terms,
less than one third of the 48 terms needed for my script for the other series!
This series is what is used in the
<a href="https://github.com/freemint/fdlibm/blob/master/e_log.c">logarithm function used in the C library</a>,
which was made during a time where memory was much more limited, so optimization was much more
necessary than it is today; it only uses 8 terms of the series after optimizing the argument
reduction algorithm to get an answer accurate to double floating-point precision.</p>

<p><img src="https://zachartrand.github.io/SoME-3-Living/images/desmos-series-comparison.png" width="50%" title="Pictured: A comparison of the 3-term approximations for the two ln(x) series. Even after only three terms, the latter series is a much better approximation than the former."></p>

<p><em>Pictured: A comparison of the 3-term approximations for the series</em>
<em>$\sum_{n=0}^{\infty} (-1)^n \frac{(x-1)^{n+1}}{n+1}$ (red) and</em>
<em>$\sum_{n=0}^{\infty} \frac{2}{2n+1} {\biggl( \frac{x-1}{x+1} \biggr)}^{2n+1}$</em>
<em>(green) to $\ln(x)$ (dotted black). Even after only three terms, the latter series</em>
<em>is a much better approximation than the former.</em></p>

<p>But regardless of whichever series is used under the hood, you now understand how your computer
and your calculator compute and give you an accurate value to the natural logarithm function. And
with the <a href="https://en.wikipedia.org/wiki/Logarithm#Change_of_base">change of base formula</a>, you can
calculate the logarithm of any base.</p>

<h2 id="final-thoughts">Final thoughts</h2>

<p>As I was learning how to script in Python, I began to get curious about how things worked under the
hood of this programming language. Since Python is open source, I was able to look at its source code
to see how different mathematical functions, particularly in its
<a href="https://docs.python.org/3/library/math.html">math</a> and
<a href="https://docs.python.org/3/library/cmath.html">cmath</a> modules, worked and how their code was structured.
I learned about different techniques of coding mathematical formulae that avoided weird edge cases that
would either create an inaccurate result or throw an error despite a calculable value existing.
However, when it came to the basic complicated math functions, like the logarithm, trigonometric, and
exponential functions, I found that the Python source code didn’t have them written up, because Python
used the functions from the C library. This led me to a new adventure where I looked into
<a href="https://github.com/freemint/fdlibm">the original C code</a>, which, while more difficult to read, is
surprisingly readable once you have learned Python.
The trig functions worked more or less how I expected, but I was surprised that the natural logarithm
used a different series than the one I had learned about in my calculus class. (So does the exponential
function, incidentally. After all, the Taylor series for exp(x) only increases by one degree each term,
and as we’ve learned here, if you can bump that up to two degrees per term, you have better optimization.
If you are curious, go and seek that one out yourself.) Once I worked out how this series was derived,
I gained an appreciation for the cleverness of mathematicians and programmers who sussed out this series
to calculate values for this very useful function. I have always been interested in how things like this
work; when I was younger, I was the curious student who got frustrated when something logical and
grounded in structured patterns was given to us like a magic wand where one push of a button gave you
the answer you sought. I saw logarithm tables that had painstaking calculations for every common logarithm
between 1.000 and 10.000 in 0.001 increments. Where did these values come from, and how do we know they
work for our calculations of radioactive decay, chemical reactions, and population growth? Thanks to this
exercise, now I know, and if you made it this far, so do you! Thank you for joining me on this fun little
math adventure. I hope you found this exercise as interesting and enlightening as I have.</p>

<h3 id="support">Support</h3>
<p>Did you enjoy this article?  Want to help me make more?  Consider making a
<a href="https://www.buymeacoffee.com/zachartrand">donation</a>.</p>

<h3 id="footnotes">Footnotes</h3>



      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spending 3 months investigating a 7-year old bug and fixing it in 1 line of code (245 pts)]]></title>
            <link>https://lemmy.world/post/16763534</link>
            <guid>40749624</guid>
            <pubDate>Fri, 21 Jun 2024 13:49:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lemmy.world/post/16763534">https://lemmy.world/post/16763534</a>, See on <a href="https://news.ycombinator.com/item?id=40749624">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="postContent"><div><p dir="auto">I originally told the story over on the other site, but I thought I’d share it here. With a bonus!</p>
<p dir="auto">I was working on a hardware accessory for the OG iPad. The accessory connected to the iPad over USB and provided MIDI in/out and audio in/out appropriate for a musician trying to lay down some tracks in Garage Band.</p>
<p dir="auto">It was a winner of a product because at its core, it was based on a USB product we had already been making for PCs for almost a decade. All we needed was a little microcontroller to put the iPad into USB host mode (this was in the 30-pin connector days), and then allow it to connect to what was basically a finished product.</p>
<p dir="auto">This product was so old in fact that nobody knew how to compile the source code. When it came time to get it working, someone had to edit the binaries to change the USB descriptors to reflect the new product name and that it drew &lt;10mA from the iPad’s USB port (the original device was port-powered, but the iPad would get angry if you requested more than 10mA even if you were self-powered). This was especially silly because the original product had a 4-character name, but the new product had a 7-character name. We couldn’t make room for the extra bytes, so we had to truncate the name to fit it into the binary without breaking anything.</p>
<p dir="auto">Anyway, product ships and we notice a problem. Every once in a while, a MIDI message is missed. For those of you not familiar, MIDI is used to transmit musical notes that can be later turned into audio by whatever processor/voice you want. A typical message contains the note (A, B, F-sharp, etc), a velocity (how hard you hit the key), and whether it’s a key on or key off. So pressing and releasing a piano key generate two separate messages.</p>
<p dir="auto">Missing the occasional note message wouldn’t typically be a big deal except for instrument voices with infinite sustain like a pipe organ. If you had the pipe organ voice selected when using our device, it’s possible that it would receive a key on, but not a key off. This would result in the iPad assuming that you were holding the key down indefinitely.</p>
<p dir="auto">There isn’t an official spec for what to do if you receive another key-on of the same note without a key-off in between, but Apple handled this in the worst way possible. The iPad would only consider the key released if the number of key-ons and key-offs matched. So the only way to release this pipe organ key was to hope for it to skip a subsequent key-on message for the same key and then finally receive the key-off. The odds of this happening are approximately 0%, so most users had to resort to force quitting the app.</p>
<p dir="auto">Rumors flooded the customer message boards about what could cause this behavior, maybe it was the new iOS update? Maybe you had to close all your other apps? There was a ton of hairbrained theories floating around, but nobody had any definitive explanation.</p>
<p dir="auto">Well I was new to the company and fresh out of college, so I was tasked with figuring this one out.</p>
<p dir="auto">First step was finding a way to generate the bug. I wrote a python script that would hammer scales into our product and just listened for a key to get stuck. I can still recall the cacophony of what amounted to an elephant on cocaine slamming on a keyboard for hours on end.</p>
<p dir="auto">Eventually, I could reproduce the bug about every 10 minutes. One thing I noticed is that it only happened if multiple keys were pressed simultaneously. Pressing one key at a time would never produce the issue.</p>
<p dir="auto">Using a fancy cable that is only available to Apple hardware developers, I was able to interrogate the USB traffic going between our product and the iPad. After a loooot of hunting (the USB debugger could only sample a small portion, so I had to hit the trigger right when I heard the stuck note), I was able to show that the offending note-off event was never making it to the iPad. So Apple was not to blame; our firmware was randomly not passing MIDI messages along.</p>
<p dir="auto">Next step was getting the source to compile. I don’t remember a lot of the details, but it depended on “hex3bin” which I assume was some neckbeard’s version of hex2bin that was “better” for some reasons. I also ended up needing to find a Perl script that was buried deep in some university website. I assume that these tools were widely available when the firmware was written 7 years prior, but they took some digging. I still don’t know anything about Perl, but I got it to run.</p>
<p dir="auto">With firmware compiling, I was able to insert instructions to blink certain LEDs (the device had a few debug LEDs inside that weren’t visible to the user) at certain points in the firmware. There was no live debugger available for the simple 8-bit processor on this thing, so that’s all I had.</p>
<p dir="auto">What it came down to was a timing issue. The processor needed to handle audio traffic as well as MIDI traffic. It would pause whatever it was doing while handling the audio packets.
The MIDI traffic was buffered, so if a key-on or key-off came in while the audio was being handled, it would be addressed immediately after the audio was done.</p>
<p dir="auto">But it was only single buffered. So if a second MIDI message came in while audio was being handled, the second note would overwrite the first, and that first note would be forever lost. There is a limit to how fast MIDI notes can come in over USB, and it was just barely faster than it took to process the audio. So if the first note came in just after the processor cut to handling audio, the next note could potentially come in just before the processor cut back.</p>
<p dir="auto">Now for the solution. Knowing very little about USB audio processing, but having cut my teeth in college on 8-bit 8051 processors, I knew what kind of functions tended to be slow. I did a Ctrl+F for “%” and found a 16-bit modulo right in the audio processing code.</p>
<p dir="auto">This 16-bit modulo was just a final check that the correct number of bytes or bits were being sent (expecting remainder zero), so the denominator was going to be the same every time. The way it was written, the compiler assumed that the denominator could be different every time, so in the background it included an entire function for handling 16-bit modulos on an 8-bit processor.</p>
<p dir="auto">I googled “optimize modulo,” and quickly learned that given a fixed denominator, any 16-bit modulo can be rewritten as three 8-bit modulos.</p>
<p dir="auto">I tried implementing this single-line change, and the audio processor quickly dropped from 90us per packet to like 20us per packet. This 100% fixed the bug.</p>
<p dir="auto">Unfortunately, there was no way to field-upgrade the firmware, so that was still a headache for customer service.</p>
<p dir="auto">As to why this bug never showed up in the preceding 7 years that the USB version of the product was being sold, it was likely because most users only used the device as an audio recorder or MIDI recorder. With only MIDI enabled, no audio is processed, and the bug wouldn’t happen. The iPad however enabled every feature all the time. So the bug was always there. It’s just that nobody noticed it. Edit: also, many MIDI apps don’t do what Apple does and require matching key on/key off events. So if a key gets stuck, pressing it again will unstick it.</p>
<p dir="auto">So three months of listening to Satan banging his fists on a pipe organ lead to a single line change to fix a seven year old bug.</p>
<p dir="auto">TL;DR: 16-bit modulo on an 8-bit processor is slow and caused packets to get dropped.</p>
<p dir="auto">The bonus is at 4:40 in this video <a href="https://youtu.be/DBfojDxpZLY?si=oCUlFY0YrruiUeQq" rel="noopener nofollow">https://youtu.be/DBfojDxpZLY?si=oCUlFY0YrruiUeQq</a></p>
</div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From Infocom to 80 Days: An oral history of text games and interactive fiction (166 pts)]]></title>
            <link>https://arstechnica.com/gaming/2024/06/from-infocom-to-80-days-an-oral-history-of-text-games-and-interactive-fiction/</link>
            <guid>40749426</guid>
            <pubDate>Fri, 21 Jun 2024 13:30:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gaming/2024/06/from-infocom-to-80-days-an-oral-history-of-text-games-and-interactive-fiction/">https://arstechnica.com/gaming/2024/06/from-infocom-to-80-days-an-oral-history-of-text-games-and-interactive-fiction/</a>, See on <a href="https://news.ycombinator.com/item?id=40749426">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/45897016062_e1c52b1dd9_k-800x1199.jpg" alt="Zork running on an Amiga at the Computerspielemuseum in Berlin, Germany.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/11/45897016062_e1c52b1dd9_k.jpg" data-height="2048" data-width="1366">Enlarge</a> <span>/</span> Zork running on an Amiga at the Computerspielemuseum in Berlin, Germany.</p></figcaption>  </figure>

  




<!-- cache hit 60:single/related:5c42246a6933a50d11619419eada3ee5 --><!-- empty -->
<p><em>You are standing at the end of a road before a small brick building.</em></p>
<p>That simple sentence first appeared on a PDP-10 mainframe in the 1970s, and the words marked the beginning of what we now know as interactive fiction.</p>
<p>From the bare-bones text adventures of the 1980s to the heartfelt hypertext works of Twine creators, interactive fiction is an art form that continues to inspire a loyal audience. The community for interactive fiction, or IF, attracts readers and players alongside developers and creators. It champions an open source ethos and a punk-like individuality.</p>
<p>But whatever its production value or artistic merit, at heart, interactive fiction is simply words on a screen. In this time of AAA video games, prestige television, and contemporary novels and poetry, how does interactive fiction continue to endure?
</p><p>To understand the history of IF, the best place to turn for insight is the authors themselves. Not just the authors of notable text games—although many of the people I interviewed for this article do have that claim to fame—but the authors of the communities and the tools that have kept the torch burning. Here's what they had to say about IF and its legacy.</p>
<h2>Examine roots: Adventure and Infocom</h2>
<p>The interactive fiction story began in the 1970s. The first widely played game in the genre was <i>Colossal Cave Adventure</i>, also known simply as <i>Adventure</i>. The text game was made by Will Crowther in 1976, based on his experiences spelunking in Kentucky’s aptly named Mammoth Cave. Descriptions of the different spaces would appear on the terminal, then players would type in two-word commands—a verb followed by a noun—to solve puzzles and navigate the sprawling in-game caverns.</p>                                            
                                                        
<p>During the 1970s, getting the chance to interact with a computer was a rare and special thing for most people.</p>
<p>"My father's office had an open house in about 1978," IF author and tool creator Andrew Plotkin recalled. "We all went in and looked at the computers—computers were very exciting in 1978—and he fired up <i>Adventure</i> on one of the terminals. And I, being eight years old, realized this was the best thing in the universe and immediately wanted to do that forever."</p>
<p>"It is hard to overstate how potent the effect of this game was," said Graham Nelson, creator of the Inform language and author of the landmark IF <i>Curses</i>, of his introduction to the field. "Partly that was because the behemoth-like machine controlling the story was itself beyond ordinary human experience."
</p><p>Perhaps that extraordinary factor is what sparked the curiosity of people like Plotkin and Nelson to play <i>Adventure</i> and the other text games that followed. The roots of interactive fiction are entangled with the roots of the computing industry. "I think it's always been a focus on the written word as an engine for what we consider a game," said software developer and tech entrepreneur Liza Daly. "Originally, that was born out of necessity of primitive computers of the '70s and '80s, but people discovered that there was a lot to mine there."</p>
<p>Home computers were just beginning to gain traction as Stanford University student Don Woods released his own version of <i>Adventure</i> in 1977, based on Crowther’s original Fortran work. Without wider access to comparatively pint-sized machines like the Apple 2 and the Vic-20, Scott Adams might not have found an audience for his own text adventure games, released under his company Adventure International, in another homage to Crowther. As computers spread to more people around the world, interactive fiction was able to reach more and more readers.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Allan McDonald Refused To Approve Challenger Launch, Exposed Cover-Up (2021) (515 pts)]]></title>
            <link>https://www.npr.org/2021/03/07/974534021/remembering-allan-mcdonald-he-refused-to-approve-challenger-launch-exposed-cover</link>
            <guid>40748371</guid>
            <pubDate>Fri, 21 Jun 2024 11:23:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2021/03/07/974534021/remembering-allan-mcdonald-he-refused-to-approve-challenger-launch-exposed-cover">https://www.npr.org/2021/03/07/974534021/remembering-allan-mcdonald-he-refused-to-approve-challenger-launch-exposed-cover</a>, See on <a href="https://news.ycombinator.com/item?id=40748371">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storytext">
      <div id="res974534902">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2021/03/07/mcdonald-with-commemorative-2aa6ac2dbf80eea3029d8d1d7e7d7c60230627d0.jpg?s=1100&amp;c=15&amp;f=jpeg" data-original="https://media.npr.org/assets/img/2021/03/07/mcdonald-with-commemorative-2aa6ac2dbf80eea3029d8d1d7e7d7c60230627d0.jpg?s=1100&amp;c=100&amp;f=jpeg" data-template="https://media.npr.org/assets/img/2021/03/07/mcdonald-with-commemorative-2aa6ac2dbf80eea3029d8d1d7e7d7c60230627d0.jpg?s={width}&amp;c={quality}&amp;f={format}" data-format="webp" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2021/03/07/mcdonald-with-commemorative-2aa6ac2dbf80eea3029d8d1d7e7d7c60230627d0.jpg?s=1100&amp;c=15&amp;f=jpeg" data-original="https://media.npr.org/assets/img/2021/03/07/mcdonald-with-commemorative-2aa6ac2dbf80eea3029d8d1d7e7d7c60230627d0.jpg?s=1100&amp;c=100&amp;f=jpeg" data-template="https://media.npr.org/assets/img/2021/03/07/mcdonald-with-commemorative-2aa6ac2dbf80eea3029d8d1d7e7d7c60230627d0.jpg?s={width}&amp;c={quality}&amp;f={format}" data-format="jpeg" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2021/03/07/mcdonald-with-commemorative-2aa6ac2dbf80eea3029d8d1d7e7d7c60230627d0.jpg?s={width}&amp;c={quality}&amp;f={format}" data-original="https://media.npr.org/assets/img/2021/03/07/mcdonald-with-commemorative-2aa6ac2dbf80eea3029d8d1d7e7d7c60230627d0.jpg?s=1100&amp;c=100&amp;f=jpeg" data-template="https://media.npr.org/assets/img/2021/03/07/mcdonald-with-commemorative-2aa6ac2dbf80eea3029d8d1d7e7d7c60230627d0.jpg?s={width}&amp;c={quality}&amp;f={format}" data-format="jpeg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                Allan McDonald in 2016 holds a commemorative poster honoring the seven astronauts killed aboard the space shuttle Challenger.
                <b aria-label="Image credit">
                    
                    Howard Berkes/NPR
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Howard Berkes/NPR
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2021/03/07/mcdonald-with-commemorative-2aa6ac2dbf80eea3029d8d1d7e7d7c60230627d0.webp?s=2600&amp;c=100&amp;f=webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2021/03/07/mcdonald-with-commemorative-2aa6ac2dbf80eea3029d8d1d7e7d7c60230627d0.jpg?s=2600&amp;c=100&amp;f=jpeg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2021/03/07/mcdonald-with-commemorative-2aa6ac2dbf80eea3029d8d1d7e7d7c60230627d0.jpg?s=2600&amp;c=100&amp;f=jpeg" alt="" src="https://media.npr.org/assets/img/2021/03/07/mcdonald-with-commemorative-2aa6ac2dbf80eea3029d8d1d7e7d7c60230627d0.jpg?s=2600&amp;c=100&amp;f=jpeg">
        </picture>
    </div>
<div>
        <p>Allan McDonald in 2016 holds a commemorative poster honoring the seven astronauts killed aboard the space shuttle Challenger.</p>
        <p><span aria-label="Image credit">
            
            Howard Berkes/NPR
            
        </span>
    </p></div>
   </div>
   <p>On Jan. 27, 1986, Allan McDonald stood on the cusp of history.</p>   <p>McDonald directed the booster rocket project at NASA contractor Morton Thiokol. He was responsible for the two massive rockets, filled with explosive fuel, that lifted space shuttles skyward. He was at the Kennedy Space Center in Florida for the launch of the Challenger "to approve or disapprove a launch if something came up," he told me in 2016, 30 years after Challenger exploded.</p>   <p>His job was to sign and submit an official form. Sign the form, he believed, and he'd risk the lives of the seven astronauts<strong> </strong>set to board the spacecraft the next morning. Refuse to sign, and he'd risk his job, his career and the good life he'd built for his wife and four children.</p>   
   <p>"And I made the smartest decision I ever made in my lifetime," McDonald told me. "I refused to sign it. I just thought we were taking risks we shouldn't be taking."</p>   
   
<!-- END ID="RES974537606" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>McDonald persistently cited three reasons for a delay: freezing overnight temperatures that could compromise the booster rocket joints; ice forming on the launchpad and spacecraft that could damage the orbiter heat tiles at launch; and a forecast of rough seas at the booster rocket recovery site.</p>   <p>He also told NASA officials, "If anything happens to this launch, I wouldn't want to be the person that has to stand in front of a board of inquiry to explain why we launched."</p>   <p>Now, 35 years after the Challenger disaster, McDonald's family reports that he died Saturday in Ogden, Utah, after suffering a fall and brain damage. He was 83 years old.</p>   <p>"There are two ways in which [McDonald's] actions were heroic," recalls Mark Maier, who directs a leadership program at Chapman University and produced a documentary about the Challenger launch decision.</p>   <p>"One was on the night before the launch, refusing to sign off on the launch authorization and continuing to argue against it," Maier says. "And then afterwards in the aftermath, exposing the cover-up that NASA was engaged in."</p>   
   <p>Twelve days after Challenger exploded, McDonald stood up in a closed hearing of a presidential commission investigating the tragedy. He was "in the cheap seats in the back" when he raised his hand and spoke. He had just heard a NASA official completely gloss over a fundamental fact.</p>   <p>McDonald and his team of <a href="https://www.npr.org/2006/01/28/5175151/challenger-reporting-a-disasters-cold-hard-facts">Thiokol engineers had strenuously opposed the launch</a>, arguing that freezing overnight temperatures, as low as 18 degrees F, meant that the O-rings at the booster rocket joints would likely stiffen and fail to contain the explosive fuel burning inside the rockets. They presented data showing that O-rings had lost elasticity at a much warmer temperature, 53 degrees F, during an earlier launch.</p>   
   
<!-- END ID="RES974537681" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>The NASA official simply said that Thiokol had some concerns but approved the launch. He neglected to say that the approval came only after Thiokol executives, under intense pressure from NASA officials, overruled the engineers.</p>   <p>"I was sitting there thinking that's about as deceiving as anything I ever heard," McDonald recalled. "So ... I said I think this presidential commission should know that Morton Thiokol was so concerned, we recommended not launching below 53 degrees Fahrenheit. And we put that in writing and sent that to NASA."</p>   <p>Former Secretary of State William Rogers chaired the commission and stared into the auditorium, squinting in the direction of the voice.</p>   <p>"I'll never forget Chairman Rogers said, 'Would you please come down here on the floor and repeat what I think I heard?' " McDonald said.</p>   <p>The focus of the commission's investigation shifted to the booster rocket O-rings, the efforts of McDonald and his colleagues to stop the launch and the failure of NASA officials to listen.</p>   
   
<!-- END ID="RES974537739" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Morton Thiokol executives were not happy that McDonald spoke up, and they demoted him.</p>   <p>That alarmed members of the presidential commission and members of Congress. Rep. Edward Markey, a Massachusetts Democrat, introduced a <a href="https://www.congress.gov/bill/99th-congress/house-joint-resolution/634/text?r=85&amp;s=1">joint resolution in the House</a> that threatened to forbid Thiokol from getting future NASA contracts given the company's punishment of McDonald and any other Thiokol engineers who spoke freely.</p>   <p>The company relented, and McDonald was promoted to vice president and put in charge of the effort to redesign the booster rocket joints that failed during the Challenger launch.</p>   
   <p>In 1988, the redesigned joints worked successfully as shuttle flights resumed.</p>   <p>McDonald continued to work at Thiokol until 2001 and retired after 42 years. He later co-authored one of the most definitive accounts of the Challenger disaster — <a href="https://upf.com/book.asp?id=MCDON001"><em>Truth, Lies, and O-Rings</em></a><em>: Inside the Space Shuttle </em>Challenger <em>Disaster</em>.</p>   <div id="res974548572">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2021/03/07/mcdonald-at-us-space-command-281b10bcc5e423414b3d65972b8727e0998e0dd9.jpg?s=1100&amp;c=15&amp;f=jpeg" data-original="https://media.npr.org/assets/img/2021/03/07/mcdonald-at-us-space-command-281b10bcc5e423414b3d65972b8727e0998e0dd9.jpg?s=1100&amp;c=100&amp;f=jpeg" data-template="https://media.npr.org/assets/img/2021/03/07/mcdonald-at-us-space-command-281b10bcc5e423414b3d65972b8727e0998e0dd9.jpg?s={width}&amp;c={quality}&amp;f={format}" data-format="webp" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2021/03/07/mcdonald-at-us-space-command-281b10bcc5e423414b3d65972b8727e0998e0dd9.jpg?s=1100&amp;c=15&amp;f=jpeg" data-original="https://media.npr.org/assets/img/2021/03/07/mcdonald-at-us-space-command-281b10bcc5e423414b3d65972b8727e0998e0dd9.jpg?s=1100&amp;c=100&amp;f=jpeg" data-template="https://media.npr.org/assets/img/2021/03/07/mcdonald-at-us-space-command-281b10bcc5e423414b3d65972b8727e0998e0dd9.jpg?s={width}&amp;c={quality}&amp;f={format}" data-format="jpeg" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2021/03/07/mcdonald-at-us-space-command-281b10bcc5e423414b3d65972b8727e0998e0dd9.jpg?s={width}&amp;c={quality}&amp;f={format}" data-original="https://media.npr.org/assets/img/2021/03/07/mcdonald-at-us-space-command-281b10bcc5e423414b3d65972b8727e0998e0dd9.jpg?s=1100&amp;c=100&amp;f=jpeg" data-template="https://media.npr.org/assets/img/2021/03/07/mcdonald-at-us-space-command-281b10bcc5e423414b3d65972b8727e0998e0dd9.jpg?s={width}&amp;c={quality}&amp;f={format}" data-format="jpeg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                In 2018, Allan McDonald reviewed the Challenger launch decision during a series of seminars about leadership and ethical decision-making to managers at U.S. Space Command.
                <b aria-label="Image credit">
                    
                    Mark Maier
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Mark Maier
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2021/03/07/mcdonald-at-us-space-command-281b10bcc5e423414b3d65972b8727e0998e0dd9.webp?s=2600&amp;c=100&amp;f=webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2021/03/07/mcdonald-at-us-space-command-281b10bcc5e423414b3d65972b8727e0998e0dd9.jpg?s=2600&amp;c=100&amp;f=jpeg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2021/03/07/mcdonald-at-us-space-command-281b10bcc5e423414b3d65972b8727e0998e0dd9.jpg?s=2600&amp;c=100&amp;f=jpeg" alt="" src="https://media.npr.org/assets/img/2021/03/07/mcdonald-at-us-space-command-281b10bcc5e423414b3d65972b8727e0998e0dd9.jpg?s=2600&amp;c=100&amp;f=jpeg">
        </picture>
    </div>
<div>
        <p>In 2018, Allan McDonald reviewed the Challenger launch decision during a series of seminars about leadership and ethical decision-making to managers at U.S. Space Command.</p>
        <p><span aria-label="Image credit">
            
            Mark Maier
            
        </span>
    </p></div>
   </div>
   <p>In retirement, McDonald became a fierce advocate of ethical decision-making and spoke to hundreds of engineering students, engineers and managers. He and Chapman University's Maier held leadership and ethics seminars for corporations and government agencies, including U.S. Space Command.</p>   <p>Maier says that one of McDonald's key moments in his talks helps explain his ability to reconcile his brush with history.</p>   <p>"What we should remember about Al McDonald [is] he would often stress his laws of the seven R's," Maier says. "It was always, always do the right thing for the right reason at the right time with the right people. [And] you will have no regrets for the rest of your life."</p>   <p>"It's really that simple if you just keep it focused that way," McDonald told me in 2016.</p>   
   
<!-- END ID="RES974537778" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>He also framed regret another way, paraphrasing a favorite quote from the late journalist Sydney J. Harris.</p>   <p>"Regret for things we did is tempered by time," McDonald said, his expression firm. "But regret for things we did not do is inconsolable." McDonald then paused and added, "That's absolutely true."</p>   <p>He seemed inconsolable immediately after the Challenger explosion in tearful calls home. He recalls the painful conversations in his book. "I feel like it's my fault," he told his daughter Lisa, a nursing student in Boston at the time. "Don't blame yourself, Dad," she said, also crying.</p>   <p>Maier believes McDonald lived out his life with neither blame nor regret. "He died with serenity and equanimity," he says. "I will miss him dearly."</p>   <p>Allan McDonald leaves behind his wife, Linda, and four children — and a legacy of doing the right things at the right times with the right people.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ladybird browser spreads its wings (401 pts)]]></title>
            <link>https://lwn.net/Articles/976822/</link>
            <guid>40746804</guid>
            <pubDate>Fri, 21 Jun 2024 06:35:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/976822/">https://lwn.net/Articles/976822/</a>, See on <a href="https://news.ycombinator.com/item?id=40746804">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<center>
           <div><b>Did you know...?</b><p>LWN.net is a subscriber-supported publication; we rely on subscribers
       to keep the entire operation going.  Please help out by <a href="https://lwn.net/subscribe/">buying a subscription</a> and keeping LWN on the
       net.</p></div>
           </center>
           
<p><a href="https://ladybird.dev/">Ladybird</a> is an open-source
project aimed at building an independent web browser, rather than
yet another browser based on Chrome. It is written in C++ and licensed under a
two-clause BSD license. The effort 
began as part of the <a href="https://www.serenityos.org/">SerenityOS</a> project, but
developer Andreas Kling <a href="https://awesomekling.substack.com/p/forking-ladybird-and-stepping-down-serenityos">announced</a>
on June&nbsp;3 that he was "forking" Ladybird as a separate project and stepping away from
SerenityOS to focus his attention on the browser completely. Ladybird
is not ready to replace Firefox or Chrome for regular use, but it is showing
great promise.</p>

<p>Kling started working on SerenityOS in 2018 as a therapy project
after completing a substance-abuse rehabilitation program. The SerenityOS name is a
nod to the <a href="https://en.wikipedia.org/wiki/Serenity_Prayer">serenity
prayer</a>. Prior to working on the project, he had worked on
WebKit-based browsers at Apple and Nokia. Eventually he <a href="https://awesomekling.github.io/I-quit-my-job-to-focus-on-SerenityOS-full-time/">made
SerenityOS his full-time job</a>, and funded the work through
donations, sales of SerenityOS merchandise, and income from
YouTube. (Kling posts monthly updates to his <a href="https://www.youtube.com/@awesomekling/videos">YouTube
channel</a> about Ladybird, as well as hacking videos where he walks
through working on various components in the browser, such as the <a href="https://www.youtube.com/watch?v=8mxubNQC5O8">JavaScript JIT
compiler</a>.)</p>

<h4>Taking flight</h4>

<p>Kling <a href="https://awesomekling.substack.com/p/ladybird-a-new-cross-platform-browser-project">announced</a>
the Ladybird project in September 2022. He said that the project
started while creating a Qt GUI for SerenityOS's LibWeb browser
engine. He decided to target Linux as well as SerenityOS so it would be easier for
people to work on and debug while in Linux. In the post announcing his
intent to work solely on Ladybird, he noted that he had been focusing
all of his attention on the Linux version of Ladybird. With that
realization, he decided to step down as "benevolent dictator for
life" (BDFL) of SerenityOS so its development would not be held back:</p>

<blockquote>
Before anyone asks, there is no drama behind this change. It's simply
recognizing that there have been two big projects packed uncomfortably
into a single space for too long, and I'm doing what I believe will
make life better for everyone involved.
</blockquote>

<p>Ladybird's governance is similar to SerenityOS. Kling is the
BDFL, with a group of maintainers (currently ten) who can
approve and merge pull requests. The <a href="https://github.com/LadybirdWebBrowser/ladybird/blob/master/CONTRIBUTING.md">contributing</a>
guide notes that maintainership is "<q>by invitation only and does not
correlate with any particular metric</q>". Project development
discussions are held on a <a href="https://discord.com/invite/nvfjVJ4Svh">Discord server</a>
(account required).</p>

<p>Now independent, Ladybird has dropped SerenityOS as a development
target, and has moved to <a href="https://github.com/LadybirdWebBrowser/ladybird">its own GitHub
repository</a>. In addition, Kling has relaxed his self-imposed policy
of excluding "not invented here" (NIH) code that had applied to SerenityOS, which
means that the Ladybird project will be able to make use of existing
libraries rather than writing from scratch.</p>

<p>Comparing the <a href="https://github.com/LadybirdWebBrowser/ladybird/blob/master/README.md">README</a> file in the standalone Ladybird repository
against the <a href="https://github.com/SerenityOS/serenity/blob/master/Ladybird/README.md">README</a>
file in the SerenityOS repository, the goal has
evolved from creating "<q>a standards-compliant, independent web browser with
no third-party dependencies</q>" to developing an independent browser "<q>using a
novel engine based on web standards</q>".</p>

<p>The changes to the section that enumerates the core libraries for Ladybird 
provide some hints about Kling's plans
to use existing libraries rather than continuing to reinvent the
wheel. The core support libraries for the project include homegrown
libraries for cryptography, TLS, 2D-graphics rendering, archive-file
format support, Unicode, as well as audio and video playback.
In the pre-fork documentation, they are described
as alternatives to other software. For example, Ladybird's TLS (LibTLS)
and cryptography (LibCrypto) libraries are "<q>Cryptography primitives
and Transport Layer Security (rather than OpenSSL)</q>". The "rather
than" language has been removed in the journey to the standalone
repository, and the LibSQL library from SerenityOS has <a href="https://github.com/LadybirdWebBrowser/ladybird/commit/8362c073f34f25ef2fbe800780f4b8790b3fffa8">already
been stripped out</a> in favor of sqlite3.</p>

<p>In a discussion in the project's Discord instance on June&nbsp;5, Kling indicated that font rendering
would likely be replaced with a third-party library. A user asked on
June&nbsp;6 what would determine whether a component would be developed in-house versus
using a third-party library. Kling responded that if it implements a web
standard, "i.e DOM, HTML, JavaScript, CSS, Wasm, etc. then we build it
in house." Otherwise, the project would look to alternatives "unless we
believe we can build something better ourselves".</p>

<h4>Status</h4>

<p>Ladybird is still in early development ("pre-alpha") today. It
currently runs on Linux, macOS, and other
UNIX-like operating systems. It's also possible to use on Windows with
Windows Subsystem for Linux (WSL) version&nbsp;2, but there appears to
be no effort to target Windows independently at this time. At the
moment, the project does not provide binaries for any
platform. Interested users will need to grab the source and follow the
<a href="https://github.com/LadybirdWebBrowser/ladybird/blob/master/Documentation/BuildInstructionsLadybird.md">build
instructions</a>. Users will need GCC&nbsp;13+ or Clang&nbsp;17, and Qt6
development packages to play along at home. Ladybird compiles and runs
on, for example, Fedora&nbsp;40 without a problem, but it is a long
way from being suitable for regular use.</p>

<blockquote>
<a href="https://lwn.net/Articles/977492/"><img src="https://static.lwn.net/images/2024/ladybird-sm.png" alt="[Ladybird browser with inspector]" title="Ladybird browser with inspector"></a>
</blockquote>

<p>One might expect that the browser
would be more usable with sites with simpler layouts and little to no JavaScript
(e.g. LWN) than those with complex layouts and a fair amount of
JavaScript (e.g. GitHub). However, this isn't always the case—Ladybird
rendered GitHub and many other sites well, if slowly. Browsing
LWN anonymously worked well, but logging into LWN,
however, consistently proved to be too much for the
application. Each time, it basically froze on the front page and clicking links to
articles did nothing.</p>

<p>Somewhat ironically, it was not possible to log
into Discord using Ladybird. It does a fair
job of rendering pages, but speed and stability are
still wanting. Each Ladybird tab has its own render process, which is
sandboxed as a security measure to prevent any malicious pages from
affecting the rest of the system. However, it doesn't seem to suffice
to keep a single page from crashing the browser entirely. That's to be
expected from a project that's still considered pre-alpha, though.</p>

<p>The current feature set is, not surprisingly, minimal. Ladybird has
a URL/search bar, reload, tabs, can zoom in/out on content, take
screenshots, and (of course) has backward and forward navigation. It
does not, however, have bookmarks, a history display, extensions,
password management, printing, or even the ability to save an
image. WebRTC does not seem to be supported yet. CSS support seems
relatively robust. Ladybird passes 100% of the CSS Selectors tests for
levels 1-3, for example, using <a href="https://css4-selectors.com/browser-selector-test/">this
test</a>. It gets a 53% score for level 4, while Firefox gets 71%, so
not a terrible showing at all. JavaScript support seems solid, but
slow: the <a href="https://www.w3schools.com/js/js_ex_browser.asp">examples
here</a> work, but they load slowly.</p>

<p>On the other hand, Ladybird does have tools for developers, such as
inspectors for the document object model (DOM) tree and accessibility
trees, as well as the ability to create dumps of various things:
the DOM tree and layout tree, computed styles, and so forth. It also
has the ability to spoof the User-Agent sent by the browser so that testers
can try to get around sites that refuse to work with "unknown"
browsers. However, toggling the User-Agent wasn't enough to get
past Google's gatekeeping to sign into Gmail—but it's unclear if
that meant Ladybird wasn't sending the string correctly or if Google
is using other means to fingerprint non-approved browsers.</p>

<p>Suffice it to say, Ladybird is not ready for mainstream use but it
<em>does</em> show potential. In the past month, the project has had
more than 880 commits from 49 authors. If the project maintains that
kind of momentum, or picks up steam, it could become a usable
alternative to mainstream browsers before too long.</p><br clear="all"><hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/976822/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Eidos – Offline alternative to Notion (116 pts)]]></title>
            <link>https://github.com/mayneyao/eidos</link>
            <guid>40746773</guid>
            <pubDate>Fri, 21 Jun 2024 06:30:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mayneyao/eidos">https://github.com/mayneyao/eidos</a>, See on <a href="https://news.ycombinator.com/item?id=40746773">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  





    






  
  

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div id="repo-content-pjax-container">

  

  <include-fragment src="/mayneyao/eidos/spoofed_commit_check/fd2524a74ddaadf322ad6c613dcfdbeea9627a51" data-test-selector="spoofed-commit-check"></include-fragment>

  <div data-view-component="true">
  <div data-view-component="true">        























<react-partial partial-name="repos-overview" data-ssr="true">
  
  
  <div data-hpc="true" data-target="react-partial.reactRoot"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mayneyao/eidos/blob/main/public/show/table-and-doc.webp"><img src="https://github.com/mayneyao/eidos/raw/main/public/show/table-and-doc.webp" alt="eidos"></a></p>
<div dir="auto">
    <p><a href="https://eidos.space/?home=1" rel="nofollow">Home Page</a> |
    <a href="https://discord.gg/bsGMPDR23b" rel="nofollow">Discord</a></p><p dir="auto">
    Eidos is an extensible framework for managing your personal data throughout your lifetime in one place.
    </p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Everything runs inside your browser. PWA support.</p>
</li>
<li>
<p dir="auto">Offline Support: Access your data without an internet connection. Data is stored locally for blazing-fast performance.</p>
</li>
<li>
<p dir="auto">AI Features: Deeply integrated with LLM for AI-powered capabilities. Translate, summarize, and interact with your data within Eidos. AI works even offline.</p>
</li>
<li>
<p dir="auto">Extensible: Customize Eidos to suit your needs.</p>
<ul dir="auto">
<li>Prompt: Speed up your workflow with the Prompt extension. No coding required.</li>
<li>UDF: Use JavaScript to customize Formula functions.</li>
<li>Script: Create powerful data processing logic with TypeScript/JavaScript.</li>
<li>App: Build your own app using any preferred framework.</li>
<li>Block: Extend documents with custom blocks.</li>
<li>Field: Extend tables with custom fields.</li>
</ul>
</li>
<li>
<p dir="auto">Developer Friendly:</p>
<ul dir="auto">
<li>API &amp; SDK</li>
<li>Sqlite Standardization: Every table in Eidos is a SQLite table.</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to develop</h2><a id="user-content-how-to-develop" aria-label="Permalink: How to develop" href="#how-to-develop"></a></p>
<ol dir="auto">
<li>Clone the repository <code>git clone git@github.com:mayneyao/eidos.git</code></li>
<li>Run <code>pnpm install</code> to install dependencies</li>
<li>Run <code>pnpm build</code> (only needed once)</li>
<li>Run <code>pnpm dev</code></li>
<li>You can now access the app in your browser at <a href="http://localhost:5173/" rel="nofollow">http://localhost:5173</a></li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Generate sdk types</h3><a id="user-content-generate-sdk-types" aria-label="Permalink: Generate sdk types" href="#generate-sdk-types"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<p dir="auto">Eidos based on the following open-source projects:</p>
<ul dir="auto">
<li><a href="https://github.com/sqlite/sqlite-wasm">sqlite-wasm</a> - Run SQLite in the browser</li>
<li><a href="https://github.com/shadcn-ui/ui">shadcn-ui</a> - UI components</li>
<li><a href="https://github.com/glideapps/glide-data-grid">glide-data-grid</a> - High performance table</li>
<li><a href="https://github.com/facebook/lexical">lexical</a> - Document editor</li>
<li><a href="https://github.com/mlc-ai/web-llm">web-llm</a> - Run LLM in the browser</li>
<li><a href="https://github.com/teableio/teable">teable</a> &amp; <a href="https://github.com/apitable/apitable">apitable</a> - Teach me how to build an Airtable-like table.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the terms of the AGPL license.</p>
</article></div>
</react-partial>

        </div>
  <div data-pjax="" data-view-component="true">
  <h2>About</h2>

      <p>
        Offline alternative to Notion. Eidos is an extensible framework for managing your personal data throughout your lifetime in one place.
      </p>
      


    <h3>Resources</h3>
    <p>
      <a data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:readme&quot;}" href="#readme-ov-file">
        
        Readme
</a>    </p>

  
    <h3>License</h3>
  <p>
    <a href="#AGPL-3.0-1-ov-file" data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:license&quot;}">
      
     AGPL-3.0 license
    </a>
  </p>




  <include-fragment src="/mayneyao/eidos/hovercards/citation/sidebar_partial?tree_name=main">
  </include-fragment>

  <p>
    <a href="https://github.com/mayneyao/eidos/activity" data-view-component="true">
      
      <span>Activity</span>
</a>  </p>


  <h3>Stars</h3>
  <p>
    <a href="https://github.com/mayneyao/eidos/stargazers" data-view-component="true">
      
      <strong>224</strong>
      stars
</a>  </p>

  <h3>Watchers</h3>
  <p>
    <a href="https://github.com/mayneyao/eidos/watchers" data-view-component="true">
      
      <strong>1</strong>
      watching
</a>  </p>

  <h3>Forks</h3>
  <p>
    <a href="https://github.com/mayneyao/eidos/forks" data-view-component="true">
      
      <strong>5</strong>
      forks
</a>  </p>

    
</div>
  
</div></div>

</turbo-frame>


    </main>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MeshAnything – converts 3D representations into efficient 3D meshes (285 pts)]]></title>
            <link>https://buaacyw.github.io/mesh-anything/</link>
            <guid>40746310</guid>
            <pubDate>Fri, 21 Jun 2024 05:02:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buaacyw.github.io/mesh-anything/">https://buaacyw.github.io/mesh-anything/</a>, See on <a href="https://news.ycombinator.com/item?id=40746310">Hacker News</a></p>
<div id="readability-page-1" class="page">

<div>
          
            <div>
              <p>
              <span>
                <a href="https://tonghe90.github.io/">Tong He</a><sup>2</sup><span>†</span>,</span>
              <span>
                <a href="https://dihuang.me/">Di Huang</a><sup>2</sup>,</span>
              <span>
                <a href="https://ywcmaike.github.io/">Weicai Ye</a><sup>2</sup>,</span>
              <span>
                <a href="https://ch3cook-fdu.github.io/">Sijin Chen</a><sup>3</sup>,</span>
              <span>
                <a href="https://me.kiui.moe/">Jiaxiang Tang</a><sup>4</sup></span>,
              <br>
              <span>
                <a href="https://chenxin.tech/">Xin Chen</a><sup>5</sup>,</span>
              <span>
                <a href="https://caizhongang.github.io/">Zhongang Cai</a><sup>6</sup>,</span>
              <span>
                <a href="https://scholar.google.com.hk/citations?user=jZH2IPYAAAAJ&amp;hl=en">Lei Yang</a><sup>6</sup>,</span>
              <span>
                <a href="https://www.skicyyu.org/">Gang Yu</a><sup>7</sup>,</span>
              <span>
                <a href="https://guosheng.github.io/">Guosheng Lin</a><sup>1</sup><span>†</span>,</span>
              <span>
                <a href="https://icoz69.github.io/">Chi Zhang</a><sup>8</sup><span>†</span></span>

            </p></div>

            <div>
              <p><span><sup>1</sup>S-Lab, Nanyang Technological University,</span>
              <span><sup>2</sup>Shanghai AI Lab</span><br>
              <span><sup>3</sup>Fudan University,</span>
              <span><sup>4</sup>Peking University,</span>
              <span><sup>5</sup>University of Chinese Academy of Sciences</span><br>
              <span><sup>6</sup>SenseTime Research,</span>
              <span><sup>7</sup>Stepfun,</span>
              <span><sup>8</sup>Westlake University</span></p><p><span><sup>*</sup>Work done during a research internship at Shanghai AI Lab.</span>
              </p>
              <p><span><sup>†</sup>Corresponding Authors.</span>
              </p>
            </div>


          
        </div>


<div>
        <p><img src="https://buaacyw.github.io/mesh-anything/demo_video.gif" alt="Demo Video">
        </p>
      </div>

<div>
      <h2>
        <p><span>MeshAnything</span> mimics human artist in extracting meshes from any 3D representations. It can be combined with various 3D asset production pipelines, such as 3D reconstruction and generation, to convert their results into Artist-Created Meshes that can be seamlessly applied in 3D industry.
        </p>
      </h2>
    </div>



<div>
    <div>
      <h4>Comparison with Previous Methods</h4>
      
    </div>
    <div>
          <p><img src="https://buaacyw.github.io/mesh-anything/remesh.png" alt="Remesh Image"></p><p>
            <span>MeshAnything</span> generates meshes with hundreds of times fewer faces, significantly improving storage, rendering, and simulation efficiencies, while achieving precision comparable to previous methods.
          </p>
        </div>
  </div>

<div>
        <h2>Abstract</h2>
        <div>
          <p>
            Recently, 3D assets created via reconstruction and generation have matched the quality of manually crafted assets, highlighting their potential for replacement. However, this potential is largely unrealized because these assets always need to be converted to meshes for 3D industry applications, and the meshes produced by current mesh extraction methods are significantly inferior to Artist-Created Meshes (AMs), i.e., meshes created by human artists.
Specifically, current mesh extraction methods rely on dense faces and ignore geometric features, leading to inefficiencies, complicated post-processing, and lower representation quality.
          </p>
          <p>
            To address these issues, we introduce MeshAnything, a model that treats mesh extraction as a generation problem, producing AMs aligned with specified shapes. By converting 3D assets in any 3D representation into AMs, MeshAnything can be integrated with various 3D asset production methods, thereby enhancing their application across the 3D industry.
          </p>
          <p>
            The architecture of MeshAnything comprises a VQ-VAE and a shape-conditioned decoder-only transformer. We first learn a mesh vocabulary using the VQ-VAE, then train the shape-conditioned decoder-only transformer on this vocabulary for shape-conditioned autoregressive mesh generation. Our extensive experiments show that our method generates AMs with hundreds of times fewer faces, significantly improving storage, rendering, and simulation efficiencies, while achieving precision comparable to previous methods.
          </p>
        </div>
      </div>

<div>
    <div>
      <p>
        <h2>Method</h2>
      </p>
    </div>

    <div>
        <p><img src="https://buaacyw.github.io/mesh-anything/pipline.png" alt="Pipeline Image">
        </p>
      </div>

    <div>
        <p>
           <span>MeshAnything</span> is an autoregressive transformer capable of generating Artist-Created Meshes that adhere to given 3D shapes. We sample point clouds from given 3D assets, encode them into features, and inject them into the decoder-only transformer to achieve shape-conditional mesh generation.
        </p>
        <p>
          Compared to methods like MeshGPT that directly generate Artist-Created Meshes, our approach avoids learning complex 3D shape distributions. Instead, it focuses on efficiently constructing shapes through optimized topology, significantly reducing the training burden and enhancing scalability.
        </p>
      </div>
  </div>


<div>
    <div>
      <p>
        <h2>More Results</h2>
      </p>
    </div>

    <div>
        <p><img src="https://buaacyw.github.io/mesh-anything/teaser.png" alt="Teaser Image">
        </p>
        <p><img src="https://buaacyw.github.io/mesh-anything/add.png" alt="Additional Image">
        </p>
        <p><img src="https://buaacyw.github.io/mesh-anything/gt.png" alt="Ground Truth Image">
        </p>

        <p>
          By integrating with various 3D asset production methods, our approach achieves highly controllable Artist-Created Mesh generation. Besides, we compare our reseults with ground truth in (b) and (c). In (b), MeshAnything generates meshes with better topology and fewer faces than the ground truth. In (c), we produce meshes with a completely different topology while achieving a similar shape, proving that our method does not simply overfit but understands how to construct meshes using efficient topology.
        </p>
      </div>
  </div>



<div id="BibTeX">
    <h2>BibTeX</h2>
    <pre><code>@misc{chen2024meshanything,
      title={MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers},
      author={Yiwen Chen and Tong He and Di Huang and Weicai Ye and Sijin Chen and Jiaxiang Tang and Xin Chen and Zhongang Cai and Lei Yang and Gang Yu and Guosheng Lin and Chi Zhang},
      year={2024},
      eprint={2406.10163},
      archivePrefix={arXiv},
      primaryClass={id='cs.CV' full_name='Computer Vision and Pattern Recognition' is_active=True alt_name=None in_archive='cs' is_general=False description='Covers image processing, computer vision, pattern recognition, and scene understanding. Roughly includes material in ACM Subject Classes I.2.10, I.4, and I.5.'}
}</code></pre>
  </div>






</div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Rant about Front-end Development (115 pts)]]></title>
            <link>https://blog.frankmtaylor.com/2024/06/20/a-rant-about-front-end-development/</link>
            <guid>40746173</guid>
            <pubDate>Fri, 21 Jun 2024 04:31:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.frankmtaylor.com/2024/06/20/a-rant-about-front-end-development/">https://blog.frankmtaylor.com/2024/06/20/a-rant-about-front-end-development/</a>, See on <a href="https://news.ycombinator.com/item?id=40746173">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-3896" itemscope="itemscope" itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
		
		<!-- .entry-header -->

		<div itemprop="articleBody">
			<p><span><span>Reading Time: </span> <span>13</span> <span>minutes</span></span></p><p>I am a front-end developer who is FED up about front-end development. If you write front-end, this isn’t about you <em>personally</em>. It’s about how your choices make me angry. Also this is about how my choices have made me angry. Also this is mostly just about <em>choices</em>, the technologies are incidental. </p>



<p><strong>Note: The views expressed in here are not those of my employer. They are (probably) the views of thousands of people just like me.</strong></p>



<p><strong>Warning: </strong>This article is filled with profanity. Ask your scrummaster if 8 points of profanity is too much to handle today. </p>



<div>
<figure><a href="https://blog.frankmtaylor.com/wp-content/uploads/2024/06/DALL%C2%B7E-2024-06-20-22.40.13-painting-of-a-raven-trying-to-remove-the-keys-from-a-laptop-keyboard.png"><img fetchpriority="high" decoding="async" width="1024" height="1024" src="https://blog.frankmtaylor.com/wp-content/uploads/2024/06/DALL%C2%B7E-2024-06-20-22.40.13-painting-of-a-raven-trying-to-remove-the-keys-from-a-laptop-keyboard.png" alt="Ravens are smart animals, probably much smarter than we really know. If they knew about the stupid shit we were doing to build the internet they'd definitely peck out the keys of every keyboard in existence." srcset="https://blog.frankmtaylor.com/wp-content/uploads/2024/06/DALL%C2%B7E-2024-06-20-22.40.13-painting-of-a-raven-trying-to-remove-the-keys-from-a-laptop-keyboard.png 1024w, https://blog.frankmtaylor.com/wp-content/uploads/2024/06/DALL%C2%B7E-2024-06-20-22.40.13-painting-of-a-raven-trying-to-remove-the-keys-from-a-laptop-keyboard-300x300.png 300w, https://blog.frankmtaylor.com/wp-content/uploads/2024/06/DALL%C2%B7E-2024-06-20-22.40.13-painting-of-a-raven-trying-to-remove-the-keys-from-a-laptop-keyboard-150x150.png 150w, https://blog.frankmtaylor.com/wp-content/uploads/2024/06/DALL%C2%B7E-2024-06-20-22.40.13-painting-of-a-raven-trying-to-remove-the-keys-from-a-laptop-keyboard-768x768.png 768w, https://blog.frankmtaylor.com/wp-content/uploads/2024/06/DALL%C2%B7E-2024-06-20-22.40.13-painting-of-a-raven-trying-to-remove-the-keys-from-a-laptop-keyboard-240x240.png 240w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>Quoth the raven on your merge requests: Nevermore</figcaption></figure></div>


<h2>First, some background</h2>



<p>I have neither a computer science degree nor an engineering degree. But I have worked in web technologies since the second Bush administration. I’ve worked in a variety of roles ranging from business analyst, tester, all the way through developer, consultant, and principal architect.  </p>



<p>I did agency work for 11 years before making the choice to work for a very large tech company. I have worked across sectors like insurance, healthcare, retail, banking, investing, marketing, and manufacturing. I have worked with global brands which are household names. </p>



<p>I have written <em>a lot</em> of front-end code for <em>a lot</em> of companies. I have also dealt with <em>a lot of consequences created by front-end code</em>. My criticisms come from my role as a front-end developer and as someone affected by a front-end developer. </p>



<h2>No one gives a shit about content</h2>



<p>Unless it’s a content-specialized front-end developer who works specifically in the content management space and is specialized in writing front-end for content management system. Did you count how many times I had to write both “front-end” and “content”? Too fucking many. </p>



<p>I have mentored quite a few bootcamp graduates. There are exactly zero graduates of zero bootcamps who have ever been told, “users go to websites for the content.” <strong>Zero</strong>. They all think it’s their moral imperative to make sure every site is built in React.</p>



<p>I have worked with exactly zero computer science graduates who have ever heard the phrase, “content before code”.</p>



<p>Unless the front-end developer has been forced by threat of not-being-able-to-pay-rent to care about content, they don’t fucking care. </p>



<p>This is <strong>wild</strong> to me because HTML5 semantics exist and their whole-ass raison d’être is, in fact, having an understanding of content. </p>



<ul>
<li>You can’t write content-managed HTML if you don’t understand the content.</li>



<li>You can’t write semantic HTML if you don’t understand the content. </li>



<li>You can’t write SEO-ready HTML without understanding the content.</li>



<li>You can’t write accessible HTML without understanding the content.</li>



<li>You can’t write <em>good</em> HTML without understanding the content. </li>
</ul>



<p>Zero SPA developers that I’ve ever met have ever given a shit about using a<code> &lt;header&gt;</code> instead of a <code>&lt;section&gt;</code>. I have found <code>NaN</code> fucks given about using a <code>p</code> over a <code>div</code>. The number of times I’ve seen numbers written inside of a <code>&lt;li&gt;</code> that’s inside of a <code>&lt;ul&gt;</code> — instead of just using an <code>&lt;ol&gt;</code> — <strong>is deeply disturbing.</strong></p>



<p><em>Maybe we should ask the designer or business owner a few questions about what the design means to the end-user before hammering out 18 layers of <code>div</code>s. </em></p>



<h2>CSS is fine; you’re the problem</h2>



<p>If someone gets a ticket for speeding, we don’t blame the car or the road. We definitely blame the idiot who thought it’d be a good idea to race the Dodge Charger camped out in the Dollar General parking lot. </p>



<p>It’s in this very same vein that we don’t blame CSS:</p>



<blockquote>
<p>“The problem with CSS is that the scope is global”<br>“The problem with CSS is the cascade”<br>“The problem with CSS is that it fails silently”</p>
<cite>Every dork who promotes writing styles in JavaScript</cite></blockquote>



<p>Those aren’t problems; they’re <em>features</em>. They are solutions to the very specific problems of, “how do we make content presentable as easily as possible, with as little duplication as possible, and with as few negative impacts to the user as possible.”</p>



<p>Chances are, the things you don’t like about CSS are the things you haven’t bothered to understand about it. </p>



<p>Styles rarely, <em>if ever</em> need to actually be scoped and encapsulated. In fact, the only time you want to prevent styles from being in the global scope is when you didn’t write them <em>and</em> can’t control them. </p>



<p>If duplicated class names are ruining your day, 15-class selectors are crapping in your cereal, and 8 <code>!important</code> are igniting turds in your garage, that’s actually an <em>architecture problem</em>. </p>



<p>Are there <em>real</em> problems in CSS? Of course. But those are problems like, “<code>border-radius</code> should have been called <code>corner-radius</code>,” and “atomic stacking contexts are generated when using <code>opacity</code>,” and “<a href="https://blog.frankmtaylor.com/2012/01/25/css-font-size-an-em-isnt-an-m-but-an-ex-is-an-x/" data-type="link" data-id="https://blog.frankmtaylor.com/2012/01/25/css-font-size-an-em-isnt-an-m-but-an-ex-is-an-x/">an <code>em</code> isn’t really an <code>em</code>.</a>”   Those are problems. </p>



<p>The C of CSS is not a problem. You’re the problem. </p>



<p><em>Put on your big-kid pants and develop a strategy, pick some conventions, write them down, and enforce them through merge requests and peer reviews. </em> </p>



<h2>Server-side rendering does not mean, “rendered with JavaScript”</h2>



<p>There’s a disconcerting number of front-end developers out there who act like it wasn’t possible to generate HTML on a server prior to 2010<a href="#one"><sup>1</sup></a>.  They talk about SSR <em>only</em> in the context of node.js and seem to have no clue that people started working on this problem when season 5 of Seinfeld was on air<a href="#two"><sup>2</sup></a>. </p>



<p>Server-side rendering was not invented with Node. What Node brought to the table was the convenience of writing your shitty <code>div</code> soup in the very same language that was invented in 10 days for the sole purpose of pissing off Java devs everywhere. </p>



<p>Server-side rendering means it’s rendered on the fucking server. You can do that with PHP, ASP, JSP, Ruby, Python, Perl, CGI, and hell, <em>R</em>. You can server-side render a page in <em>Lua</em> if you want. </p>



<p>Just because <em>Node</em> isn’t involved in generating HTML, that doesn’t mean it’s not possible to generate markup at request time.  It is possible. It’s been possible. It will continue to be possible. </p>



<p><em>Stop denying the history, contributions, and value that other technologies bring to solving this exact problem that is definitely not unique to you.</em></p>







<h2>JavaScript is not always the answer</h2>



<p>My brothers and sisters in Christ I want you to know that I care about your souls enough to share these truths with you:</p>



<ul>
<li>You don’t need JavaScript to make a web page. </li>



<li>You don’t need JavaScript to write styles. </li>



<li>You don’t need JavaScript to make an animation. </li>



<li>You don’t need JavaScript just to show content. </li>
</ul>



<p>In 2010 I was a contractor for an organization working with some Very Smart IBM consultants. They could not figure out how our in-house developer made the navigation for the site they were implementing. </p>



<p>It was because our developer used CSS. Our consultants had never considered that CSS could do something as fancy as, “show you a thing when you hover over it.”</p>



<p>That’s a fun “har-har silly ignorant smart consultants,” story except at least it’s about their <em>harmless</em> <em>ignorance</em>.</p>



<p>It’s so much <strong>worse</strong> when they <em>know JavaScript</em>. </p>



<p>Five years ago I was on a project where the perfectly fine .net MVC app was turned into an API for delivering content to a .net core app that used node services to render Vue templates into fully rendered HTML which meant that all of our templates were written in Vue <em>and we still had to write jQuery to make content interactive</em>.  We literally had two layers of JavaScript wrapped in a .net sandwich with JavaScript spread on the top. </p>



<p>I’m seeing architectures being proposed <em>today</em> that do pretty much the same thing I just described but with Drupal on Apache, containerized Node, and Web Components. </p>



<p>If  making a peanut butter and jelly sandwich by spreading the jelly on both sides of the bread is disturbing to you, <em>good</em>. You can still find God. </p>



<p>Do you have any idea how frustrating it is that that in order to explain my sadness to my therapist I must first explain like 5 different technologies and by the time I’m finished <em>she’s sad just hearing it</em>, the session’s over, and I didn’t even get to what was making me upset? Technology has made my anger a recursive function. </p>



<p><em>Can we please stop adding complexity to our systems just so we can do it in JavaScript? If you can do it without JavaScript, you probably should. Tools shouldn’t add complexity. </em></p>



<h2>Sass wasn’t just a mistake but a mistake factory</h2>



<p>10 years ago I thought CSS preprocessors were the coolest thing ever and I was incredibly fucking dumb for thinking that. </p>



<p>The <em>only three good features</em> CSS preprocessors gave were</p>



<ol>
<li>Variables</li>



<li>Mixins</li>



<li>Color transformation</li>
</ol>



<p>Every thing else was a mistake:</p>



<ul>
<li>Nesting</li>



<li>Calc</li>



<li>Functions, including control statements like if and for</li>



<li>Interpolation</li>



<li>Data types of any kind</li>



<li>The entire module thing</li>
</ul>



<h3>Nested CSS obscures complexity</h3>



<p>I hate this feature so much. I hate it more that it’s now native to CSS because not only has it spread, but <em>it’s mutated</em><sup>. <a href="#three">3</a></sup> </p>



<p>Nesting obscures complexity and then makes it impossible to find or fix. </p>



<p>Without using a compiler or psychedelic of any kind, can you tell me what this generates?</p>



<pre data-enlighter-language="scss" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">.feature {
	color: blue;
	&amp;__header {
		p &amp; {
			a {
				&amp;:hover,
				&amp;:focus {
					color: red;
				}
			}
		}
	}
}</pre>



<p>Does this seem reasonable to you?</p>



<pre data-enlighter-language="css" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">.feature {
  color: blue;
}
p .feature__header a:hover, p .feature__header a:focus {
  color: red;
}</pre>



<p>If that’s the output you expected, either you’re one of the Sass spec writers or you did a double-shot of espresso followed by a Ritalin chaser. </p>



<p>Nesting is not good. It hides the specificity that you’re producing and will lend to increasingly fragile code as you try to override a 13 part selector. </p>



<h3>Interpolation, et all</h3>



<p>This was also just a bad idea that we couldn’t have predicted at the time. I’m not mad at the Sass people for this. Hindsight is 20/20 and all. What I want is for it to all stop. </p>



<p>This is fundamentally a bad idea:</p>



<pre data-enlighter-language="scss" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">$sizes: 10px, 20px, 30px, 50px;

@each $size in $sizes {
  .icon-#{$size} {
    font-size: $size;
    height: $size;
    width: $size;
  }
}
</pre>



<p>I know what you’re thinking. </p>



<p>You’re thinking, “But Frank, it saves me on keystrokes! Now I can generate more classes and classnames just based on that list of sizes!”</p>



<p>Bro. </p>



<p><kbd>ctrl</kbd>+<kbd>c</kbd> and <kbd>ctrl</kbd>+<kbd>v</kbd> exist. </p>



<p>Are you a VS Code user? Even easier: Highlight it and press <kbd>alt/opt</kbd> + <kbd>shift</kbd> + <kbd>↓</kbd> , that’ll copy the chunk or line down.  Then, highlight the part that’s repeated a few times (where you’d interpolate), press <kbd>ctrl/cmd</kbd> + <kbd>d</kbd>, and keep pressing until they’re all highlighted. Make your change. Now you’re done.</p>



<p>What did you save? Time and sanity in looking up the Sass syntax? Future time where future you is trying to find where the fuck <code>.icon-80px </code>is living? <a href="https://xkcd.com/1205/">XKCD is not on your side</a> for this automagical icon generator loop that’s going to piss you off with edge cases for the next 5 years. </p>



<p><em>Can we please stop using languages and tech stacks to solve problems that our IDEs are capable of helping us with? </em></p>



<h2>Seriously … forget the Frameworks</h2>



<p>I was blown away when Angular came out. It was an actual <em>thing</em> that could do it all. It could render the markup with fun logicy attributes, respond to data changes, make the AJAX requests, amazing! I wanted to use Angular for <em>all</em> the <strong>interactive web apps</strong>. </p>



<p>Then React came out. That was amazing. It could render the markup and … [incoherent mumbling] components or something… and … <em>wait, that wasn’t even markup; it was JSX. </em> Sure, I had to add a few libraries to really use it, but yay, I used it for <strong>interactive web apps</strong>. </p>



<p>Then there was Vue. Then Preact. Then Ember, Svelte, Backbone, Alpine, Mithril, Solid, Lit, Stencil, Qwik…</p>



<p>Maybe it’s because Angular was no one’s first choice — even though it came first. Maybe that’s why the front-end world lost its damned mind with React. React was so <em>not-angulary</em> that front-end folks were like, “let’s use it client side, server side, native-side, and the 3 other sides of a damned cube”. Folks decided it was a good idea to Reactify All The Things®. </p>



<p>And that’s how React, a framework used to deliver interactive content to a whole 28% of the world’s population, is being used to generate static sites. </p>



<p>I had a client a few years ago that was a <em>household name</em>. Their front-end was written in Gatsby. Gatsby is a <em>static site generator</em> that uses React. This globally-known brand had probably 50 websites in at least as many languages. But the content was very, very, static. </p>



<p>So imagine the horror the front-end dorks felt when they learned that a content author in Bulgaria  updating the terms and conditions didn’t want the whole-ass site rebuilt for every country and language. </p>



<p>This would’ve been a non-problem had the web app been written in .net, Java, or, fuck me for saying it, PHP or Node. </p>



<p>But nah. These goobers got high off npm modules and did shots of JSX in the bathroom at lunch time. They chose a framework <em>used to deliver interactive content  to a significant percentage of the planet</em> for generating non-interactive content on a server. It took them <em>weeks</em> to come up with a solution to the problem they created when they chose a problem as a solution.  </p>



<p>Yes. I am absolutely calling React a problem. I’m calling Angular, Vue, and All the Rest of Them ™ a problem. Because unless you have a <em>specific problem of highly interactive, data-driven content</em>, you don’t need a framework.</p>



<p><em>You don’t need a framework to render static content to the end user.  Stop creating complex solutions to simple problems</em></p>



<h2>Also more generally fuck your complexity</h2>



<p>This, more than anything, is a rant about <em>complexity</em>. </p>



<p>I am mad at how front-end developers create complex solutions to simple problems. I am mad that front-end developers use tools to obscure complexity. I am mad that front-end developers embrace complexity rather than challenge it. </p>



<p>You know what’s great about jQuery? </p>



<p>Everything. </p>



<p>jQuery took several complex problems (browsers do things differently, selecting elements is complex, changing things on elements is tedious, AJAX requests are <em>a lot</em>) and it provided a simple, intuitive, and readable solution:</p>



<pre data-enlighter-language="js" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">$('.getResults').on('click', () =&gt; {
    $.ajax({
       url: '/api/results',
       data: {
         foo: 'bar'
       },
       success: function (result) {
          $('.results').html(result);
       }
    });
});</pre>



<p>Cool your jets for a second and think about how wonderfully <em>simple</em> that is. It handles finding your element in a way that lets you avoid the null checks, shortens your event binding, lets you make an AJAX  request, lets you find the element that the result goes into, and plop it there if it’s successful. </p>



<p>If the problem is, “user clicks on thing, you get data, and show data”, that is a <em>beautiful</em> and simple 11-line solution. It did not need NPM modules and a build system.</p>



<p>And <em>sure</em>, <a href="https://youmightnotneedjquery.com/">maybe you don’t need jQuery</a>, and that’s fine. Will you need more lines of code to do the same thing? Of course. But even without jQuery, your complexity doesn’t grow exponentially like it would if you brought in a framework with its build system, linters, compilers, and 700mb of Node Modules some of which inexplicably require some stupid shit like <a href="https://www.npmjs.com/~jonschlinkert" data-type="link" data-id="https://www.npmjs.com/~jonschlinkert">is-odd</a> or <a href="https://www.npmjs.com/package/is-git-url?activeTab=dependents" data-type="link" data-id="https://www.npmjs.com/package/is-git-url?activeTab=dependents">is-git-url</a> <sup><a href="#four">4</a></sup>.  </p>



<p>Pretend I’m not talking about JavaScript for a second. Let’s pretend it’s just an ordinary, everyday, 3-template web site. Maybe it’s managed by a CMS. Maybe it’s not. Does it really need Tailwind? Bootstrap? <em>Even &lt;gasp class=”from the back of the room”&gt; <strong>Sass</strong></em>? Is writing plain CSS really such a terrible thought?</p>



<p>Let me fill you in on a cool fact about CSS: It doesn’t need a fucking compiler. No <code>npm install -D sass</code>. No <code>npm i gulp</code>. You get to tell WebPack to fuck off good and proper-like, the way the Good Lord Intended. <sup><a href="#five">5</a></sup></p>



<p><em>Simplicity is unsophisticated and lacking in many parts. The simplest solution to a problem is always the best solution. Choose simplicity. I’m begging you. Your future is begging you,.   </em></p>



<h2>Oh, and enough with the new and shiny</h2>



<p>Sure it’s awesome that you can strongly type CSS variables, but that doesn’t mean you should <sup><a href="#six">6</a></sup>. Can you have web components with declarative shadow DOM? d’uh! But, hear me out: Why have three steps to render markup when you could have one?</p>



<p>Yes, the new JS Framework is all the awesomeness. Definitely do a side project with it. Please in the name of her Sweet Saint Fuck of Apathy, don’t use it in your next project. We haven’t learned what our regrets will be, and the regrets are what everyone else has to live with but you. </p>



<p>I don’t care if it’s a new CSS trick, a new JS thing, or a new JS framework: <strong>Give it two years before you take it for a ride in production</strong>. </p>



<p>You know what happens in the next two years?</p>



<p>Two year’s worth of StackOverflow questions. </p>



<p>You do <strong>not</strong> want to be the person taking a new tech or feature for a joy-ride in production and discovering some hemorrhaging-edge bug. </p>



<p>You <strong>also</strong> don’t want to be the person who has to clean up after the person who discovered a bug on a bleeding-edge technology. </p>



<p> Person-Alpha is the asshole. The Alphasshole, if you will. Because they chose to use the bleeding edge thing. </p>



<p>On the scrum-master’s Fibionacci-sequence of suckassness The Alphasshole is a 21. The Alphasshole implemented the new tech and turned your project into a collection of medical-attention-needed polyps on Satan’s butthole. </p>



<p>Person-Beta is the Betasshole. </p>



<p>The Betasshole had to work in real-time with other betassholes on other projects created by other alphassholes that were all equally hemorrhoidal in nature over StackOverflow and Discord to come up with whatever collection of hackery that properly deserves to be called, “Satan’s Self-soothing salve of sour-ass solutions.”</p>



<p>The Betasshole is a 5 on the Satanic-sequence of Suckassness. They’re not nearly as bad as the dickweed who chose new tech. But unfortunately, they made a lot of terrible choices and cannot be free from blame, git-related, or otherwise. </p>



<p>Listen. I’ve been an Alphasshole and a Betasshole before. I regret that. I should not have done that. </p>



<p>I’ve <em>also</em> been gamma waaaaaay more often. Who is not an asshole. That’s a person who’s just had to deal with two years of shit rolling downstream. What’s unfortunate for the gammas is that they often will be <em>accused</em> of being the assholes because they will git-blame, complain, and refrain from touching whatever that new tech was because it’s haunted their nightmares and their daymares. They are simply picking up the pieces. </p>



<p>The new and shiny is fun for side projects. It is not for production.</p>



<p><em>Please put two years between you and any new tech. If for anyone, do it for the gammas who actually have to keep your precious world wide web running. </em></p>



<h2>TL;DR</h2>



<p>Just… grow up and think.</p>



<ul>
<li>Think and care about the content first. Because that’s what the users care about. Assume the users’ interests are more important than your own. </li>



<li>Quit acting like CSS is some giant-ass mistake that needs fixing. A group of people who were collectively smarter than us wrote those specs. They didn’t make mistakes. Assume you are making the mistake, not them. </li>



<li>Server-side rendering was not invented with JavaScript and it doesn’t have to be implemented with JavaScript. There are many ways to render content on a server. Assume non-JavaScript solutions existed first.</li>



<li>JavaScript either is neither the God-send nor the hell-spawn for your project. It is a tool which you can choose to use incorrectly. Learn when JavaScript is the right tool for the job. </li>



<li>Quit doing hard things for simple problems. Quit doing things that are degrees of difficulty <em>harder</em> than the problem. When a problem presents itself, look for multiple solutions, and then choose the simplest one. Assume the simplest solution is the best one. </li>



<li>Quit chasing the new and shiny in your day job. I, too, am excited about the new and shiny. But I put a 2-year buffer between me and prod because I don’t want to be the person to have to discover browser bugs, framework bugs, or even compiler bugs. </li>
</ul>



<p>Or whatever. Don’t do this and continue to be an Alphasshole, Betasshole, or an otherwise generally contemptuous person. I don’t care. At least I can sleep better knowing that you know that I know that you now know that you’re an asshole. </p>



<p><s>Happy</s> apathetic coding!</p>























<div>
<h4>Footnotes, Sources, and Whatnots</h4>
<p id="one"><small>1</small> <a href="https://en.wikipedia.org/wiki/Express.js">Express.js was released in 2010. </a>
</p><p id="two"><small>2</small> <a href="https://www.infoworld.com/article/2609877/believe-the-hype--php-founder-backs-facebook-s-hiphop-technology.html">PHP started development in 1993 and was released in 1995</a> which means that when express.js dropped, PHP was driving to the store and buying clove cigarettes. </p>
<p id="three"><small>3</small> When I say it’s mutated, I mean that nesting jumped from Sass to native CSS. And CSS does it differently. <a href="https://sass-lang.com/blog/sass-and-native-nesting/">So now Sass has to change how it does nesting</a> because of how CSS does it. It’s bad. It will introduce lots of things you don’t want to happen. </p>

<p id="four"><small>4</small> People have been talking about how <a href="https://qz.com/646467/how-one-programmer-broke-the-internet-by-deleting-a-tiny-piece-of-code">left-pad broke the internet</a> and some wise folks have called out that it was pretty silly that such a simple function got to be so ubiquitous that it had the power to “crash the web”. But what’s <em> also dangerous</em> is the person <a href="https://github.com/jonschlinkert/jonschlinkert">actively trying to become ubiquitous</a>. Every PR that involves adding a new dev dependency to any project should require the developer to hand-write the entire dependency tree. That would probably save a lot of future heartache.  </p>

<p id="five"><small>5</small> I do not, in fact, have strong evidence that the Good Lord intended for WebPack to be told to, “fuck off good and proper like.” <em>However</em> <a href="https://www.bibleref.com/Leviticus/19/Leviticus-19-19.html">if the Good Lord had something to say about cotton blends</a>, He’d probably also have something to say about using a JavaScript build utility for building styles.  </p>
<p id="six"><small>6</small> <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@property">Yes, you can have strongly-typed CSS</a>, but it’s insanely tedious because those “types” are not like any types you’d expect from any other language, and the syntax is going to be a huge pain. Also, you have the option to set it to not inherit which is, in fact, the most unCSSy thing ever. So please. Don’t.    </p>
</div>
					</div><!-- .entry-content -->

		<!-- .entry-footer -->
	</article></div>]]></description>
        </item>
    </channel>
</rss>