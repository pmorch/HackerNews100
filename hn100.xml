<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 15 May 2025 04:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Copaganda: How Police and the Media Manipulate Our News (156 pts)]]></title>
            <link>https://www.teenvogue.com/story/copaganda-when-the-police-and-the-media-manipulate-our-news</link>
            <guid>43990333</guid>
            <pubDate>Wed, 14 May 2025 23:39:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.teenvogue.com/story/copaganda-when-the-police-and-the-media-manipulate-our-news">https://www.teenvogue.com/story/copaganda-when-the-police-and-the-media-manipulate-our-news</a>, See on <a href="https://news.ycombinator.com/item?id=43990333">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><strong>Stay up-to-date with the politics team.</strong> <a href="https://www.teenvogue.com/newsletter/subscribe"><strong>Sign up for the</strong> <em><strong>Teen Vogue</strong></em> <strong>Take</strong></a></p><p>I wrote the book <em>Copaganda</em> based on my years of being a civil rights lawyer and public defender representing the most vulnerable people in our society.&nbsp; I watched as the police and the news media distorted how we think about our collective safety. Copaganda makes us afraid of the most powerless people, helps us ignore far greater harms committed by people with money and power, and always pushes on us the idea that our fears can be solved by more money for police, prosecution, and prisons. Based on the evidence, this idea of more investment in the punishment bureaucracy making us safer is like climate science denial.</p><p>This excerpt is adapted from an important part of the book on how by selectively choosing which stories to tell, and then telling those stories in high volume, the news can induce people into fear-based panics that have no connection to what is happening in the world.&nbsp; It's how public polling can show people thinking crime is up when it is down year after year, and how so many well-meaning people are led to falsely believe that marginalized people themselves want more money on surveillance and punishment as the primary solutions to make their lives better.</p><figure><p><span>The New Press</span></p></figure><p><em>All royalties from the book are donated to the Stop LAPD Spying Coalition, which works with unhoused people against police violence. Free books are also available for anyone in prison and for any teachers who want to get copies for their students to discuss the book in class.</em></p><h2>Moral Panics and the Selective Curation of Anecdote</h2><p>By manipulating the volume of stories at particular times, the news media creates a society-wide frenzy concerning particular kinds of behavior by particular groups of people. Scholars call them “moral panics.”</p><p>When a moral panic is created, it almost always leads to the expansion of government repression. That’s what happened during the “crime waves” reported by the press in Victorian England, and in more recent U.S. moral panics like the 1980s panic about “crack babies,” the 1990s panic about “super predators,” the 2021–23 panic about “retail theft,” and the ongoing multiyear panic about “fare evasion” by poor people on public transit. Moral panics can also be acute creations of a particular news moment, such as the fabricated “Summer of Violence” in Denver, in which violent crime went down but increase in media stories about juvenile crime in 1993 led to expansion in the incarceration of children; the viral “train theft” story; the scientifically debunked panic about police officers overdosing on fentanyl by touching or being near it; and the 2023 panic about “carjacking” in Washington, DC.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>In each case, there were almost immediate policy responses that increased the budgets of punishment bureaucrats, passed more punitive laws, and diverted the system’s resources from other priorities. For example, the shoplifting panic led California state lawmakers to furnish $300 million more to police and prosecutors so they could punish retail theft more aggressively. A few months later, the California governor announced yet another measure, the “largest-ever single investment to combat organized retail theft,” adding another $267 million to fifty-five police agencies. Justifying the move, the governor said: “When shameless criminals walk out of stores with stolen goods, they’ll walk straight into jail cells.”</p><p>So, how do moral panics happen?</p><p>During the 1960s and 1970s in England and the U.S., the news focused on Black people, poor people, and immigrants as the source of uncontrollable “crime waves.” Their stories were nearly identical to what we see today: media panic about “crime waves” and quotes from police, prosecutors, and judges about the need to roll back so-called reforms framed as too lenient. The rhetoric of current punishment bureaucrats and pundits echoes almost verbatim the opinions voiced by conservative white business and police groups of the 1970s, although now there is more of an effort, as I’ll discuss later, to portray such views as “progressive” and demanded by marginalized people themselves. In each case, minor tweaks in bureaucratic policy or marginal reforms that could not, as a matter of empirical reality, have a significant impact on society-wide violence are vehemently debated. The evidence of the root causes of interpersonal harm—like that marshaled by the Kerner Commission, which studied U.S. crime in 1968 and recommended massive social investment to reduce inequality—is ignored.</p><p>And the cycle continues: moral panic is followed by calls for more police surveillance, militarization, higher budgets for prosecutors and prisons, and harsher sentencing. Because none of these things affect violence too much, the problems continue.</p><p>How to Tell a Lie with the Truth</p><p>The selective curation of anecdote is an essential mechanism of copaganda. Imagine two scenarios. A city had ten thousand shoplifting incidents in 2023, down from fifteen thousand shoplifting incidents in 2022. But in 2023, a local news outlet ran a story every day about a different shoplifting incident, while in 2022, the news ran only fifteen stories all year on shoplifting incidents. In which city do you think the public is more likely to believe shoplifting is a greater problem, even a crisis? In the city with more shoplifting, or the city with twenty-five times more stories about shoplifting?</p><p>By cherry-picking anecdotes—indeed, even by using isolated individual pieces of data as misleading anecdotes—news reports can distort our interpretation of the world. Using a similar process, they can also distort our understanding of what other people—particularly people with whom we don’t interact—think about the world. Because one can find anyone to say essentially anything, reporters have leeway to select which “true” views of “ordinary people” to share and which to ignore.</p><p>One of my favorite examples comes from Copaganda Hall of Famer Martin Kaste, who for some reason National Public Radio still permits to cover the police. (I awarded Kaste this honor in absentia during a private ceremony attended by two cats and my research assistants in my basement.) In 2022, Kaste published an article and widely disseminated radio piece about a rise in shootings and murders during the pandemic. Murders were down nationally in 2022 when he published the stories but they had increased in 2020 and 2021. As with much of Kaste’s police reporting, the article is a buffet for the copaganda gourmand.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Under the bolded heading “Less Risk of Getting Caught,” Kaste asserts that there is now “less risk of getting caught” for shooting someone in the United States. The support for that assertion was an ordinary person in Seattle:</p><blockquote data-testid="blockquote-wrapper"><p>Anthony Branch, 26, got into trouble for carrying a gun when he was a teen. Watching the gun culture in his neighborhood, he thinks more minors and felons are carrying guns illegally now for one simple reason: “Defund the police,” as he puts it.</p></blockquote><p>Kaste reports as national news—without context or skepticism—a single person blaming “defund the police” for more shootings. Without presenting any contrary views, NPR delivers Branch’s views, accurately conveyed though they may be, as implicitly representative of other people who’ve been prosecuted and incarcerated and who live in poor neighborhoods.</p><p>In fact, police budgets were (and are) at all-time highs nationally. And a review of hundreds of police budgets showed that they received the same share of overall city budgets in 2021 as in 2019. So, the police were not defunded after the 2020 George Floyd protests. Their budgets have increased overall each year, including the year George Floyd was murdered. Thus, reduced police budgets could not have led to it being easier to get away with shooting someone in 2021 than 2019. The article’s thesis is impossible.</p><p>Knowing this national causal connection is unsupported, Kaste nonetheless boosts the claim by immediately noting that Seattle has “lost hundreds of officers after the protests that followed the 2020 murder of George Floyd.” But even in Seattle, which was an outlier in slightly reducing its police budget by about 10 percent, the reduction didn’t affect relevant police operations, and police executives themselves in internal memos identified non-essential duties that armed officers could cut without affecting enforcement of violent crime (such as parking meter ticketing). Indeed, as the local NPR station reported, debunking the “myth” that Seattle police were defunded, “not a single sworn officer has lost their job or pay due to budget constraints.”</p><p>Even if we ignore that the NPR piece purported to draw national lessons and if we focus only on Seattle, there is no evidence that the kind of small reduction to unrelated categories in Seattle’s police budget in 2021 could have led to widespread changes in murder. Most damning to Kaste’s thesis, though, is that murders decreased in Seattle in 2021 even though the police budget decreased, which undermines the article’s thesis. Indeed, the police budget was larger in 2020 when murder increased the most. No person with a contrary view is quoted, nor is anyone included to explain the actual empirical evidence.</p><p>I do not doubt that the source gave these quotes to the reporter, but by selectively choosing which people’s views to represent and which people’s views to exclude, the news can distort our perceptions. This is one of the pernicious functions of NPR here: to give liberal news consumers intellectual permission to support more funding for more police because, although it is baselessly connected to less murder, even marginalized people targeted by police supposedly want it.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>This is how the curation of <em>true anecdotes</em> leads to <em>false interpretations</em> of the world.</p><p><em>Copyright © 2025 by Alec Karakatsanis. This excerpt originally appeared in</em> Copaganda: How Police and the Media Manipulate Our News, <em>published by The New Press. Reprinted here with permission.</em></p><hr></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Migrating to Postgres (136 pts)]]></title>
            <link>https://engineering.usemotion.com/migrating-to-postgres-3c93dff9c65d</link>
            <guid>43989497</guid>
            <pubDate>Wed, 14 May 2025 21:39:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://engineering.usemotion.com/migrating-to-postgres-3c93dff9c65d">https://engineering.usemotion.com/migrating-to-postgres-3c93dff9c65d</a>, See on <a href="https://news.ycombinator.com/item?id=43989497">Hacker News</a></p>
Couldn't get https://engineering.usemotion.com/migrating-to-postgres-3c93dff9c65d: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Semantic Calculator (king-man+woman=?) (105 pts)]]></title>
            <link>https://calc.datova.ai</link>
            <guid>43988533</guid>
            <pubDate>Wed, 14 May 2025 19:54:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://calc.datova.ai">https://calc.datova.ai</a>, See on <a href="https://news.ycombinator.com/item?id=43988533">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Muscle-Mem, a behavior cache for AI agents (165 pts)]]></title>
            <link>https://github.com/pig-dot-dev/muscle-mem</link>
            <guid>43988381</guid>
            <pubDate>Wed, 14 May 2025 19:38:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/pig-dot-dev/muscle-mem">https://github.com/pig-dot-dev/muscle-mem</a>, See on <a href="https://news.ycombinator.com/item?id=43988381">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Muscle Memory</h2><a id="user-content-muscle-memory" aria-label="Permalink: Muscle Memory" href="#muscle-memory"></a></p>
<p dir="auto"><code>muscle-mem</code> is a behavior cache for AI agents.</p>
<p dir="auto">It is a Python SDK that records your agent's tool-calling patterns as it solves tasks, and will deterministically replay those learned trajectories whenever the task is encountered again, falling back to agent mode if edge cases are detected.</p>
<p dir="auto">The goal of <code>muscle-mem</code> is to get LLMs out of the hotpath for repetitive tasks, increasing speed, reducing variability, and eliminating token costs for the many cases that <em><strong>could have just been a script</strong></em>.</p>
<p dir="auto">It's unexplored territory, so all feedback is welcome!</p>
<ul dir="auto">
<li>Read <a href="https://erikdunteman.com/blog/muscle-mem/" rel="nofollow">Muscle Mem - Removing LLM calls from Agents</a> for more context</li>
<li>Join <a href="https://discord.gg/s84dXDff3K" rel="nofollow">Muscle Mem discord</a> for feedback</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dev Log</h3><a id="user-content-dev-log" aria-label="Permalink: Dev Log" href="#dev-log"></a></p>
<ul dir="auto">
<li>May 7, 2025 - <a href="https://www.loom.com/share/5936cd9779504aa5a7dce5d72370c35d" rel="nofollow">First working demo</a></li>
<li>May 8, 2025 - Open sourced</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How It Works</h2><a id="user-content-how-it-works" aria-label="Permalink: How It Works" href="#how-it-works"></a></p>
<p dir="auto"><code>muscle-mem</code> is <em><strong>not</strong></em> another agent framework.</p>
<p dir="auto">You implement your agent however you want, and then plug it into <code>muscle-mem</code>'s engine.</p>
<p dir="auto">When given a task, the engine will:</p>
<ol dir="auto">
<li>determine if the environment has been seen before (cache-hit), or if it's new (cache-miss) using <code>Checks</code></li>
<li>perform the task, either
<ul dir="auto">
<li>using the retrieved trajectory on cache-hit,</li>
<li>or passing the task to your agent on cache-miss.</li>
</ul>
</li>
<li>collect tool call events to add to cache as a new trajectory</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">It's all about Cache Validation</h3><a id="user-content-its-all-about-cache-validation" aria-label="Permalink: It's all about Cache Validation" href="#its-all-about-cache-validation"></a></p>
<p dir="auto">To add safe tool reuse to your agent, the critical question is cache validation. Ask yourself:</p>
<blockquote>
<p dir="auto">For each tool we give to our agent, what features in the environment can be used to indicate whether or not it's safe to perform that action?</p>
</blockquote>
<div dir="auto"><p>If you can answer this, your agent can have Muscle Memory.
</p></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">The API</h2><a id="user-content-the-api" aria-label="Permalink: The API" href="#the-api"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><code>pip install muscle-mem</code></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Engine</h2><a id="user-content-engine" aria-label="Permalink: Engine" href="#engine"></a></p>
<p dir="auto">The engine wraps your agent and serves as the primary executor of tasks.</p>
<p dir="auto">It manages its own cache of previous trajectories, and determines when to invoke your agent.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from muscle_mem import Engine

engine = Engine()
engine.set_agent(your_agent)

# your agent is independently callable
your_agent(&quot;do some task&quot;)

# the engine gives you the same interface, but with muscle memory
engine(&quot;do some task&quot;)
engine(&quot;do some task&quot;) # cache hit"><pre><span>from</span> <span>muscle_mem</span> <span>import</span> <span>Engine</span>

<span>engine</span> <span>=</span> <span>Engine</span>()
<span>engine</span>.<span>set_agent</span>(<span>your_agent</span>)

<span># your agent is independently callable</span>
<span>your_agent</span>(<span>"do some task"</span>)

<span># the engine gives you the same interface, but with muscle memory</span>
<span>engine</span>(<span>"do some task"</span>)
<span>engine</span>(<span>"do some task"</span>) <span># cache hit</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tool</h2><a id="user-content-tool" aria-label="Permalink: Tool" href="#tool"></a></p>
<p dir="auto">The <code>@engine.tool</code> decorator instruments action-taking tools, so their invocations are recorded to the engine.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from muscle_mem import Engine

engine = Engine()

@engine.tool()
def hello(name: str):
	print(f&quot;hello {name}!&quot;)
	
hello(&quot;world&quot;) # invocation of hello is stored, with arg name=&quot;world&quot;"><pre><span>from</span> <span>muscle_mem</span> <span>import</span> <span>Engine</span>

<span>engine</span> <span>=</span> <span>Engine</span>()

<span>@<span>engine</span>.<span>tool</span>()</span>
<span>def</span> <span>hello</span>(<span>name</span>: <span>str</span>):
	<span>print</span>(<span>f"hello <span><span>{</span><span>name</span><span>}</span></span>!"</span>)
	
<span>hello</span>(<span>"world"</span>) <span># invocation of hello is stored, with arg name="world"</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Check</h2><a id="user-content-check" aria-label="Permalink: Check" href="#check"></a></p>
<p dir="auto">The Check is the fundamental building block for cache validation. They determine if it’s safe to execute a given action.</p>
<p dir="auto">Each Check encapsulates:</p>
<ul dir="auto">
<li>A <code>capture</code> callback to extract relevant features from the current environment</li>
<li>A <code>compare</code> callback to determine if current environment matches cached environment</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="Check(
	capture: Callable[P, T],
        compare: Callable[[T, T], Union[bool, float]],
):"><pre><span>Check</span>(
	<span>capture</span>: <span>Callable</span>[<span>P</span>, <span>T</span>],
        <span>compare</span>: <span>Callable</span>[[<span>T</span>, <span>T</span>], <span>Union</span>[<span>bool</span>, <span>float</span>]],
):</pre></div>
<p dir="auto">You can attach Checks to each tool <code>@engine.tool</code> to enforce cache validation.</p>
<p dir="auto">This can be done before the tool call as a precheck (also used for query time validation), or after a tool call as a postcheck.</p>
<p dir="auto">Below is a contrived example, which captures use of the <code>hello</code> tool, and uses timestamps and a one second expiration as the Check mechanic for cache validation.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# our capture implementation, taking params and returning T
def capture(name: str) -> T:
    now = time.time()
    return T(name=name, time=now)

# our compare implementation, taking current and candidate T
def compare(current: T, candidate: T) -> bool:
    # cache is valid if happened within the last 1 second
    diff = current.time - candidate.time
    passed = diff <= 1
    return passed

# decorate our tool with a precheck
@engine.tool(pre_check=Check(capture, compare))
def hello(name: str):
    time.sleep(0.1)
    print(f&quot;hello {name}&quot;)"><pre><span># our capture implementation, taking params and returning T</span>
<span>def</span> <span>capture</span>(<span>name</span>: <span>str</span>) <span>-&gt;</span> <span>T</span>:
    <span>now</span> <span>=</span> <span>time</span>.<span>time</span>()
    <span>return</span> <span>T</span>(<span>name</span><span>=</span><span>name</span>, <span>time</span><span>=</span><span>now</span>)

<span># our compare implementation, taking current and candidate T</span>
<span>def</span> <span>compare</span>(<span>current</span>: <span>T</span>, <span>candidate</span>: <span>T</span>) <span>-&gt;</span> <span>bool</span>:
    <span># cache is valid if happened within the last 1 second</span>
    <span>diff</span> <span>=</span> <span>current</span>.<span>time</span> <span>-</span> <span>candidate</span>.<span>time</span>
    <span>passed</span> <span>=</span> <span>diff</span> <span>&lt;=</span> <span>1</span>
    <span>return</span> <span>passed</span>

<span># decorate our tool with a precheck</span>
<span>@<span>engine</span>.<span>tool</span>(<span>pre_check</span><span>=</span><span>Check</span>(<span>capture</span>, <span>compare</span>))</span>
<span>def</span> <span>hello</span>(<span>name</span>: <span>str</span>):
    <span>time</span>.<span>sleep</span>(<span>0.1</span>)
    <span>print</span>(<span>f"hello <span><span>{</span><span>name</span><span>}</span></span>"</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Putting it all together</h3><a id="user-content-putting-it-all-together" aria-label="Permalink: Putting it all together" href="#putting-it-all-together"></a></p>
<p dir="auto">Below is the combined script for all of the above code snippets.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from dataclasses import dataclass
from muscle_mem import Check, Engine
import time

engine = Engine()

# our &quot;environment&quot; features, stored in DB
@dataclass
class T:
    name: str
    time: float

# our capture implementation, taking params and returning T
def capture(name: str) -> T:
    now = time.time()
    return T(name=name, time=now)

# our compare implementation, taking current and candidate T
def compare(current: T, candidate: T) -> bool:
    # cache is valid if happened within the last 1 second
    diff = current.time - candidate.time
    passed = diff <= 1
    return passed

# decorate our tool with a precheck
@engine.tool(pre_check=Check(capture, compare))
def hello(name: str):
    time.sleep(0.1)
    print(f&quot;hello {name}&quot;)
    
# pretend this is your agent
def agent(name: str):
   for i in range(9):
        hello(name + &quot; + &quot; + str(i))

engine.set_agent(agent)

# Run once
cache_hit = engine(&quot;erik&quot;)
assert not cache_hit

# Run again 
cache_hit = engine(&quot;erik&quot;)
assert cache_hit

# Break cache with a sleep, then run again
time.sleep(3)
cache_hit = engine(&quot;erik&quot;)
assert not cache_hit"><pre><span>from</span> <span>dataclasses</span> <span>import</span> <span>dataclass</span>
<span>from</span> <span>muscle_mem</span> <span>import</span> <span>Check</span>, <span>Engine</span>
<span>import</span> <span>time</span>

<span>engine</span> <span>=</span> <span>Engine</span>()

<span># our "environment" features, stored in DB</span>
<span>@<span>dataclass</span></span>
<span>class</span> <span>T</span>:
    <span>name</span>: <span>str</span>
    <span>time</span>: <span>float</span>

<span># our capture implementation, taking params and returning T</span>
<span>def</span> <span>capture</span>(<span>name</span>: <span>str</span>) <span>-&gt;</span> <span>T</span>:
    <span>now</span> <span>=</span> <span>time</span>.<span>time</span>()
    <span>return</span> <span>T</span>(<span>name</span><span>=</span><span>name</span>, <span>time</span><span>=</span><span>now</span>)

<span># our compare implementation, taking current and candidate T</span>
<span>def</span> <span>compare</span>(<span>current</span>: <span>T</span>, <span>candidate</span>: <span>T</span>) <span>-&gt;</span> <span>bool</span>:
    <span># cache is valid if happened within the last 1 second</span>
    <span>diff</span> <span>=</span> <span>current</span>.<span>time</span> <span>-</span> <span>candidate</span>.<span>time</span>
    <span>passed</span> <span>=</span> <span>diff</span> <span>&lt;=</span> <span>1</span>
    <span>return</span> <span>passed</span>

<span># decorate our tool with a precheck</span>
<span>@<span>engine</span>.<span>tool</span>(<span>pre_check</span><span>=</span><span>Check</span>(<span>capture</span>, <span>compare</span>))</span>
<span>def</span> <span>hello</span>(<span>name</span>: <span>str</span>):
    <span>time</span>.<span>sleep</span>(<span>0.1</span>)
    <span>print</span>(<span>f"hello <span><span>{</span><span>name</span><span>}</span></span>"</span>)
    
<span># pretend this is your agent</span>
<span>def</span> <span>agent</span>(<span>name</span>: <span>str</span>):
   <span>for</span> <span>i</span> <span>in</span> <span>range</span>(<span>9</span>):
        <span>hello</span>(<span>name</span> <span>+</span> <span>" + "</span> <span>+</span> <span>str</span>(<span>i</span>))

<span>engine</span>.<span>set_agent</span>(<span>agent</span>)

<span># Run once</span>
<span>cache_hit</span> <span>=</span> <span>engine</span>(<span>"erik"</span>)
<span>assert</span> <span>not</span> <span>cache_hit</span>

<span># Run again </span>
<span>cache_hit</span> <span>=</span> <span>engine</span>(<span>"erik"</span>)
<span>assert</span> <span>cache_hit</span>

<span># Break cache with a sleep, then run again</span>
<span>time</span>.<span>sleep</span>(<span>3</span>)
<span>cache_hit</span> <span>=</span> <span>engine</span>(<span>"erik"</span>)
<span>assert</span> <span>not</span> <span>cache_hit</span></pre></div>
<p dir="auto">For a more real example, see a computer-use agent implementation:</p>
<p dir="auto"><a href="https://github.com/pig-dot-dev/muscle-mem/blob/main/tests/cua.py">https://github.com/pig-dot-dev/muscle-mem/blob/main/tests/cua.py</a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Call To Action</h2><a id="user-content-call-to-action" aria-label="Permalink: Call To Action" href="#call-to-action"></a></p>
<p dir="auto">I invite all feedback as this system develops!</p>
<p dir="auto">Please consider:</p>
<ol dir="auto">
<li>Joining the <a href="https://discord.gg/s84dXDff3K" rel="nofollow">Muscle Mem discord</a></li>
<li>Testing <a href="https://github.com/pig-dot-dev/muscle-mem">the muscle-mem repo</a>, and giving it a star</li>
</ol>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perverse incentives of vibe coding (168 pts)]]></title>
            <link>https://fredbenenson.medium.com/the-perverse-incentives-of-vibe-coding-23efbaf75aee</link>
            <guid>43988315</guid>
            <pubDate>Wed, 14 May 2025 19:29:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fredbenenson.medium.com/the-perverse-incentives-of-vibe-coding-23efbaf75aee">https://fredbenenson.medium.com/the-perverse-incentives-of-vibe-coding-23efbaf75aee</a>, See on <a href="https://news.ycombinator.com/item?id=43988315">Hacker News</a></p>
Couldn't get https://fredbenenson.medium.com/the-perverse-incentives-of-vibe-coding-23efbaf75aee: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Grok answers unrelated queries with long paragraphs about "white genocide" (107 pts)]]></title>
            <link>https://twitter.com/grok/status/1922651218595439063</link>
            <guid>43987266</guid>
            <pubDate>Wed, 14 May 2025 17:43:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/grok/status/1922651218595439063">https://twitter.com/grok/status/1922651218595439063</a>, See on <a href="https://news.ycombinator.com/item?id=43987266">Hacker News</a></p>
Couldn't get https://twitter.com/grok/status/1922651218595439063: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Our narrative prison (138 pts)]]></title>
            <link>https://aeon.co/essays/why-does-every-film-and-tv-series-seem-to-have-the-same-plot</link>
            <guid>43986424</guid>
            <pubDate>Wed, 14 May 2025 16:27:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aeon.co/essays/why-does-every-film-and-tv-series-seem-to-have-the-same-plot">https://aeon.co/essays/why-does-every-film-and-tv-series-seem-to-have-the-same-plot</a>, See on <a href="https://news.ycombinator.com/item?id=43986424">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>How is it that we live in an era of apparently unprecedented choice and yet almost every film and TV series, as well as a good many plays and novels, have exactly the same plot? We meet the protagonist in their ordinary world, plodding along, not living their best life. And then an inciting incident changes everything, making it impossible for the protagonist to carry on as normal. They are pulled into a new quest. On the way, they meet someone who shows them a completely different way of being. They ask themselves: have I been living <span>a lie?</span></p>
<p>This is the mid-point, the point of no return. Life can never be the same. But there’s a double wobble since the protagonist’s quest is opposed by a powerful antagonist who frustrates the hero at every turn. At their lowest point, the protagonist realises their old mode of being is redundant, but the new one is too daunting. The story is resolved either in the protagonist’s favour or against them: they triumph or else fail tragically. The important thing is that their life philosophy has been turned upside down. When they return home, everything is the same, but everything is also completely transformed.</p>
<p>The formula is particularly repetitive in cinema. As it happens, aspiring screenwriters in 21st-century Hollywood are following a rubric set out in the <span>4th century BCE.</span> In his <em>Poetics</em>, Aristotle defines a well-constructed plot as having three main acts, and names other essential elements such as the ‘reversal of the Situation’, which is ‘a change by which the action veers round to its opposite’ – eg, the moment in <em>The Sixth Sense</em> (1999) when the therapist realises he is dead – and ‘recognition’, which he defines as a ‘change from ignorance to knowledge’ (Oedipus’ recognition is a big one). Aristotle’s schema was developed by later thinkers from Terence and Seneca to the 19th-century German novelist and playwright Gustav Freytag, who distilled stories into his pyramid diagram of exposition, rising action, climax and resolution. A philosophical parallel might arguably be found in Hegel’s dialectic, from thesis to antithesis and finally to synthesis. As the US historian Hayden White <a href="https://www.jstor.org/stable/2504969" target="_blank" rel="noreferrer noopener">observed</a>, even historians tend to shape their accounts of the past using narrative tropes.</p>
<figure><img alt="Diagram of Freytag’s Pyramid showing exposition as a flat line, inciting incident, rising action on an upward slop, climax at the peak of the pyramid, falling action on a downward slope, and resolution as a flat line." loading="lazy" width="1024" height="768" decoding="async" data-nimg="1" sizes="(max-width: 640px) 100vw, (max-width: 1440px) 60vw, 880px" srcset="https://images.aeonmedia.co/user_image_upload/4136/freytags_pyramid_diagram.jpg?width=384&amp;quality=75&amp;format=auto 384w, https://images.aeonmedia.co/user_image_upload/4136/freytags_pyramid_diagram.jpg?width=640&amp;quality=75&amp;format=auto 640w, https://images.aeonmedia.co/user_image_upload/4136/freytags_pyramid_diagram.jpg?width=750&amp;quality=75&amp;format=auto 750w, https://images.aeonmedia.co/user_image_upload/4136/freytags_pyramid_diagram.jpg?width=828&amp;quality=75&amp;format=auto 828w, https://images.aeonmedia.co/user_image_upload/4136/freytags_pyramid_diagram.jpg?width=1080&amp;quality=75&amp;format=auto 1080w, https://images.aeonmedia.co/user_image_upload/4136/freytags_pyramid_diagram.jpg?width=1200&amp;quality=75&amp;format=auto 1200w, https://images.aeonmedia.co/user_image_upload/4136/freytags_pyramid_diagram.jpg?width=1920&amp;quality=75&amp;format=auto 1920w, https://images.aeonmedia.co/user_image_upload/4136/freytags_pyramid_diagram.jpg?width=2048&amp;quality=75&amp;format=auto 2048w, https://images.aeonmedia.co/user_image_upload/4136/freytags_pyramid_diagram.jpg?width=3840&amp;quality=75&amp;format=auto 3840w" src="https://images.aeonmedia.co/user_image_upload/4136/freytags_pyramid_diagram.jpg?width=3840&amp;quality=75&amp;format=auto"><figcaption></figcaption></figure>
<p>If screenwriters continue to propagate the idea that three (or five) acts are the building blocks of every plot, it is because they are eager to find a replicable formula for box-office success. There is now a profitable story-structure industry of books, online lectures, podcasts and courses, with its own gurus, notably Robert McKee and Syd Field. Also Christopher Vogler, who worked as a script analyst at Disney and condensed the US writer Joseph Campbell’s concept of ‘the hero’s journey’ into a popular seven-page memo that then became a book, <em>The Writer’s </em><span><em>Journey</em></span><span> (1992).</span></p>
<p>We may be entirely familiar with the corporate clichés of Hollywood, but I don’t think the underpinnings of traditional story structure are necessarily obvious. One of my favourite films, David Lynch’s <em>Mulholland Drive</em> (2001), conforms pretty closely to formulaic structure, even if it is complicated by dream sequences: the inciting incident of the car crash; Betty’s quest to help Rita rediscover her true identity. I believe that one reason we don’t object, don’t groan with boredom, is that the scaffolding is – crucially – hidden. Every film opens with a fresh premise. The inciting incident always feels surprising, to the protagonist and to us alike: it’s a wild card that comes out of nowhere. It is this discreet veiling, in fact, that enables the formula to continue to thrive alongside the evident narrative variety we encounter every time we enter an independent bookshop: from <span>W G Sebald’s</span> collection <em>The Emigrants</em> (1992) to Nicholson Baker’s novel <em>The</em> <em>Mezzanine</em> (1988) to Samantha Harvey’s Booker-winning <em>Orbital</em> (2023). Hollywood’s storymakers may have grown more sophisticated about the method of delivery, but they are still providing the same drug: the shake-up that leads to enlightenment.</p>
<p>It is an enterprise in which convention is disguised as variety, while constraint is disguised as freedom – and this, surely, is the essence of Western consumer capitalism. The American dream could take you anywhere, but <em>still</em> you end up in a cookie-cutter house in the suburbs. Your high street is full of alluring cafés, but most are chains and their products taste the same. We step into the dark space of the cinema hoping to be taken somewhere new, but the journey follows submerged tracks like a theme park ride, and the only available destination is back home. The ‘reset’ at the end of every film feels particularly conformist: it’s as if we’re being invited to experience the fantasy of infinite possibility and radical change, only for the status quo to be reasserted. In fact, the fantasy <em>reinforces</em> the conformity by acting as a kind of safety valve.</p>
<p>As well as finding the concealment perturbing, I argue that there are other reasons to question traditional story structure. While it captures something profound about human needs and wants, it can be subtly conservative and its dominance is symptomatic of a worrying turn against analysis and critique.</p>
<p><span>I</span>n the grand genealogy of story structure exposition, Campbell’s ‘hero’s journey’ was influenced by Carl Jung’s ‘<a href="https://aeon.co/ideas/what-was-the-beguiling-spell-of-jungs-collective-unconscious" target="_blank" rel="noopener">collective unconscious</a>’: the idea that there are basic character archetypes that recur in our dreams and in the myths common to all cultures. Campbell called the hero’s journey the ‘monomyth’, a term he borrowed from James Joyce’s <em>Finnegans Wake </em>(1939) – a novel that exemplified it for Campbell and which, tellingly, is also considered to be a poster child for experimental fiction. In fact, there is an important – if subtle – distinction to be made here. There is the Hollywood formula, engineered to provide opioid reassurance in the form of redemption and the simultaneous restoration of normality: the hero always achieves self-optimisation within the acceptable confines of bourgeois respectability (which the comedy show <em>Seinfeld</em> rejected with its insistence on ‘no hugging, no learning’). And then there’s the more deep-seated monomyth, a universal blueprint that rather accurately captures the human condition, in which protagonists are put through arduous trials not so that they get what they want but what they counterintuitively need. And sometimes – in tragedy – they don’t get that <span>at all.</span></p>
<p>Though the Hollywood template might feel imaginatively and politically impoverished, it is also highly resonant. The TV producer and script editor John Yorke is the author of <em>Into the Woods: How Stories Work and Why We Tell Them</em> (2014). He is the closest thing we have to a screenwriting guru in the UK. ‘Hollywood tends to commodify and formalise,’ Yorke told me, but ultimately, ‘they’re commodifying something innate … There are different styles in different cultures, but fundamentally the underlying ingredients are always the same.’ Yorke offers the example of <span>E M Forster:</span> although story structure in novels tends to be looser and sometimes more experimental than that of films, ‘it’s so striking how something really significant always happens bang in the middle’ of a Forster novel – the midpoint Marabar Caves scene in <em>A Passage to India</em> (1924), for example, that overwhelms the young Adela Quested. Yet, as Yorke points out, ‘Forster didn’t read a book on story structure.’ Indeed, the cave literalises that moment of darkness, where Campbell’s model hero believes that all is lost.</p>
<p>Whether the monomyth is hard-wired or naturalised through repetition, Yorke believes it has universal appeal. Consuming it enables us to safely confront our worst fears and vicariously act out our strongest desires. Most importantly, it offers a pathway for what often seems to be the hardest and most longed-for task of all: how to change.</p>
<p>The vast majority of stories we encounter are versions of the monomyth</p>
<p>The US writer and director Craig Mazin observes that the inciting incident that the ‘writer god’ inflicts on the protagonist is their worst fear. It is the very thing they least want to happen, and because of this it has the potential to overhaul their erroneous mindset. The protagonist fights this ‘call to adventure’ tooth and nail because following it would mean letting go of their foundational commitments. Often, the change we need to make is to discover and integrate a vital, suppressed side of our personality – what Jung called <a href="https://psyche.co/ideas/three-ways-to-get-in-touch-with-your-shadow-self" target="_blank" rel="noopener">our Shadow</a>. The inciting incident represents the protagonist’s Shadow bursting into their world – it is their lack or flaw, embodied – which is why it is so hard to face. Who has not felt panic at the sudden disruption of their best-laid plans, only to find that the disruption produces unexpected rewards? A snowstorm that prevents my children from going to school (and me from obsessing away at my laptop) can become a magical sledging day in the park.</p>
<figure><iframe allowfullscreen="" frameborder="0" src="https://youtube.com/embed/vSX-DROZuzY"></iframe><figcaption></figcaption></figure>
<p>The COVID-19 lockdown was effectively an inciting incident on a global scale, offering us glimpses of how to live more meaningfully: building stronger ties with local communities; leaving urban areas for the countryside; discovering a greater sense of wellbeing through working at home (though, five years on, we appear to have returned to business as usual without learning those lessons – unlike the protagonists in films). Equally alluring is the idea of having a calling, an all-encompassing mission that sweeps away everyday mundanity, to say nothing of the appeal of absconding from a stultifying job or a stifling domestic life. I even wonder, writing this essay, if the lesson I need to learn is to let go of my qualms and enjoy being swept up into story, like Dorothy and her tornado.</p>
<p>The vast majority of stories we encounter are versions of the monomyth – from <em>King Lear</em> to Jane Austen’s <em>Emma</em> (1816). But to what extent is even that a normative Western construct promoting a narrow range of possible life-arcs – with the attendant Hollywood industry replicating it over and over, like an oppressive storytelling machine? And, to look even further outside the frame, is there something inherently reactionary about narrative itself?</p>
<p><span>M</span>azin’s reference to the ‘writer god’ is illuminating: it’s a top-down format. Oedipus’ fate is decided by the gods, the oracle at Delphi, and Sophocles: he tries to act freely, but his actions are predetermined. In our postmodern world, this predicament is turbo-charged. <em>The Truman Show </em>(1998) and <em>The Matrix</em> (1999) remain pertinent because we often feel ourselves to be living in a dystopian version of Prospero’s island – mere puppets in someone else’s plot. We process through the sausage factory of the National Curriculum into jobs that are standardised by tick-box bureaucracies. We are pawns preyed on by advertisers, and we’re trapped within the rubrics of social media. Every few years, we are given the chance to choose between near-identical parties, while our lifestyle choices are imperceptibly shaped by paternalistic <a href="https://aeon.co/essays/we-are-more-rational-than-those-who-nudge-us" target="_blank" rel="noopener">nudge policies</a>. In our scant downtime, we succumb to the consoling grooves of alcohol, gaming or Netflix.</p>
<p>You don’t have to be a conspiracy theorist to suspect that the lack of agency we feel in a world dominated by autocrats and digital capitalism is connected to the rise of story as a form. In his book <em>Public Opinion</em> (1922), the US political commentator Walter Lippmann called on Hollywood, the dream factory, to control an irrational public by appealing to their unconscious: the infamous ‘manufacture of consent’. And as the French scholar Christian Salmon notes in <em>Storytelling: Bewitching the Modern Mind</em> (2010), narrative has spread throughout contemporary culture and society, from news features to political speeches; museum curation to TV documentaries. Even in radio, where I work, and despite the best efforts of many of my colleagues to defend ideas-led programmes, formulaic narrative podcasts – particularly about history and true crime – are increasingly prevalent. The repetitive elements of storytelling are only too obvious here: the use of suspenseful music and the historic present tense, the anchoring in relatable characters, the cliff-hangers. Being told a story is to be infantilised, somewhat: to suspend one’s critical faculties. In contrast to polemic, stories are covertly persuasive. Even if their message is good for us, the sugaring of the pill represents a lowering of intellectual expectations.</p>
<p>There may be an internal transformation, but the structural conditions remain the same</p>
<p>Stories, as Vogler told me, function as ‘a kind of wish fulfilment’, meeting the human craving for ‘order and a purpose’. Regarding life as simply chaotic or meaningless is, he says, a ‘dangerous mental condition, … a horrible place to be’. Real life, of course, doesn’t have a shape as such. As Aristotle put it in his <em>Poetics</em>: ‘infinitely various are the incidents in one man’s life which cannot be reduced to unity’. Things don’t happen for a reason. And we fail to learn lessons. The UK novelist and critic Rosalind Brown points to the pitfalls of imposing meaning on contingent life events: ‘when something happens to you, you just make it part of your story’. It can be a way of avoiding being proactive or taking responsibility. That is one reason why we are rightly ‘suspicious of story’, Brown told me, even while being ‘incredibly attached <span>to it’.</span></p>
<p>If Brown is right, there is a danger that the ‘hero’s journey’ monomyth enables us not to change but to experience the fantasy of doing so. Sometimes ‘it’s easier to read about another character changing and feeling attracted to that than actually doing whatever work it would require to change yourself,’ she says. As Yorke reminded me, however, the power of stories to change us is illustrated by the money that the Donald Trump campaign spent on narrative social media spots, Lippmann-style – a gamble that, for better or worse, largely paid off. ‘The story wouldn’t be any good if you came back to your normal life completely unchanged, and having learned nothing, or having had no new observation,’ Vogler told me. ‘I think that we are always searching for upgrades, improvements in our behaviour, in our performance, in our relationships with other people.’ Films, he says, offer the opportunity for ‘slight improvement’.</p>
<p>There is also the question of whether the kind of change the monomyth advocates is always in our best interests. The politics of most mass-market screen fictions – from the fake anticolonialism of <em>Avatar </em>(2009) to the fake feminism of<em> Barbie</em> (2023) – are covertly conservative. <em>The</em> <em>White Lotus</em> (season one, 2021) came close to questioning the sustainability of long-term relationships, before ducking the issue with the sentimental reunion of husband and wife. The lesson is very often to be happy with your lot and to celebrate the comforts of the nuclear family, small-town existence and, often, capitalism. I’m thinking of <em>It’s a Wonderful Life </em>(1946) and<em> Groundhog Day </em>(1993) – even though I love <em>Groundhog Day</em>, and its repetition concept manages, simultaneously, to portray and critique being stuck in a rut. There may be an internal transformation, but the structural conditions remain the same.</p>
<p>So, what happens when we truly break with convention?</p>
<p><span>N</span>aqqash Khalid is a UK writer-director best known for his debut <em>In Camera </em>(2023), a surreal and disorientating portrait of an aspiring British-Asian actor navigating unsuccessful auditions. I asked him about my experience of noticing the same plot points time and again. ‘I can’t stand that. It really drives me crazy,’ he told me. ‘I am critical of the three-act structure, because I think it’s a very Western, male, colonial conception.’ The protagonist of <em>In Camera</em> is very much not a self-determining hero: he is framed and constructed by the encounters he has with other characters, who are often casually racist. ‘I wanted to have a passive man at the centre of the narrative who was not pushing the story forward,’ Khalid told me. He regards ‘one man going on a journey’ as not only hackneyed but ‘patriarchal’.</p>
<p>Similarly, the Australian critic Jane Alison questions the ‘masculo-sexual’ three-act structure with its wave-like arc of tension and release. ‘Why should an art form as innovative as fiction have a single archetype at all?’ she asks in ‘Beyond the Narrative Arc’ (2019). Stories can follow different patterns, she observes, many of which recur in nature: as well as the wave, there are fractals, meanders and networks – Italo Calvino described his novel <em>Invisible Cities</em> (1972) as ‘a network in which one can follow multiple routes and draw multiple, ramified conclusions.’</p>
<p>In her essay ‘The Carrier Bag Theory of Fiction’ (1986), Ursula K <span>Le Guin</span> challenged the hero’s journey – ‘the story the mammoth hunters told about bashing, thrusting, raping, killing’ – as not only narrowly masculine but also threatening humanity’s survival. <span>Le Guin</span> makes the case for an alternative story form to the hero’s spear or club: that of a container. Serious fiction, <span>Le Guin</span> wrote, is ‘a way of trying to describe what is in fact going on, what people actually do and feel, how people relate to everything else in this vast sack, this belly of the universe, this womb of things to be and tomb of things that were’.</p>
<p>Khalid also believes that contemporary art should reflect reality through its very form, and not just dangle wish fulfilment. ‘We live in such fractured times where the news cycle is nothing like before, where our attention spans are short,’ he said. Films must ‘formally adapt to the time that we’re in … I think the role of art is to structurally represent the world back to us.’ In her novel <em>The Long Form</em> (2023), Kate Briggs records the minute-by-minute tedium of being at home with a baby: the recording of mundane details functions as a critique of the conditions of modern motherhood. Rosalind Brown’s debut <em>Practice</em> (2024) is another novel that depicts what it is actually like to live in the world, right now. Annabel is an English literature undergraduate trying and failing to complete an essay about Shakespeare’s sonnets, through the minutiae of a single day. She is interrupted by erotic thoughts. She goes for a walk. She eats lunch. ‘The food is wet and crunchy, and tastes of all the cutting-up she just did to it,’ Brown writes: a sentence that stops the reader in their tracks. ‘Texture is the thing that interests me,’ Brown told me. Annabel ends the day much as she started it, the essay incomplete (although Brown does not reject story structure altogether: Annabel relaxing her grip on her timetable is an enlightenment of sorts).</p>
<p>Late capitalism, it would seem, respects neither narrative nor planetary boundaries</p>
<p>Early 20th-century literary modernism rejected the smooth illusions of 19th-century fiction, grappling instead with the dislocations of postwar modernity. Likewise, these attempts, in Le Guin’s words, ‘to describe what is in fact going on, what people actually do and feel’ are aesthetically and politically bracing. They defamiliarise what is naturalised, making the world strange so we can see it, challenge it, and potentially change it. Traditional story structure may resonate deeply, but it does not give us that jolt. Paradoxically, the monomyth dramatises change, but also embodies continuity.</p>
<p>‘Stories allow us to progress, and they allow us to stay the same,’ Yorke said. ‘That’s probably quite a healthy balance … We tell stories to define ourselves, our families, our nations.’ The monomyth was modelled on stories told by traditional societies governed by cyclical time and generational renewal: the hero’s journey is a rite of passage. But now that real-world Bond villains like Elon Musk are threatening geopolitical stability and ecological survival, that final-act reset is surely coming under strain.</p>
<p>Ironically, the monomyth is now being stretched out of shape by commercial forces, too. Franchises, sequels and box-set formats are extending stories in multiple directions to eke out ever more revenue, bringing to mind Musk’s intergalactic ambitions, which imply there’s a franchise option for human life: late capitalism, it would seem, respects neither narrative nor planetary boundaries. ‘It’s outrageous, really,’ Yorke says of endless sequels. ‘If you think of it in basic terms, a story is a question and answer, dramatised. And when the question is answered, there is nowhere else to go.’ Not surprisingly, Hollywood is working hard to combine narrative boundlessness with satisfying, self-contained stories: the Marvel ‘Multiverse’ is a kind of vast conglomerate of autonomous (super)heroes’ journeys.</p>
<p>In contrast to the spectacle of an individual saving the world, we once had idealism and the sense of a common goal: it was called ideology. But grand narratives are a relic of the past century. Khalid links the relative absence of creative experimentation with a narrowing of our ideological horizons. ‘Our collective imaginations … are being stifled,’ he told me. Like <span>Le Guin,</span> he believes that we must ‘fundamentally think about how we rebuild structures’, because those we are living under ‘are literally killing us … whether that be patriarchy or racism or the climate catastrophe.’ Ambitious art can ‘shape what we think it is possible for us <span>to do.’</span></p>
<p>Vogler and Yorke, while supportive of experimental fictions, note that they are of course harder to finance. And although it may be counterproductive to reassure people that everything is fine when the planet is burning, Yorke insists on being realistic about audience choices in a free market. ‘Stories have to make you alarmed,’ he told me, ‘but they also have to offer you hope … You’ve got to have a model of what’s worth <span>living for.’</span></p>
<p>Even art-house films that self-consciously depart from the three-act structure nonetheless define themselves against it. Charlie Kaufman’s brilliantly metafictional <em>Adaptation</em> (2002) dramatises a deconstruction of the formula (the protagonist, a struggling screenwriter, even attends a seminar by Robert McKee); but still he ends up (albeit knowingly) following it. Abandoning the structure altogether, it seems, is neither desirable nor possible. Even so, whether we regard it as a palace or a prison, we need now more than ever to understand how it is built.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A server that wasn't meant to exist (277 pts)]]></title>
            <link>https://it-notes.dragas.net/2025/05/13/the_server_that_wasnt_meant_to_exist/</link>
            <guid>43985971</guid>
            <pubDate>Wed, 14 May 2025 15:50:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://it-notes.dragas.net/2025/05/13/the_server_that_wasnt_meant_to_exist/">https://it-notes.dragas.net/2025/05/13/the_server_that_wasnt_meant_to_exist/</a>, See on <a href="https://news.ycombinator.com/item?id=43985971">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Yesterday I read a piece of news that brought back an important - and painful - episode from my career.<br> A story about trust, technology... and the kind of problems that can't always be solved.</p><p>About 16 years ago, I was contacted by an old friend. He was worried about a situation involving some mutual acquaintances.<br> To keep it short: an entrepreneur - administrator and owner of several companies - had died suddenly.<br> He was the kind of man who centralized everything, and his wife and children found themselves struggling to manage things.<br> One of the sons decided to cash out and leave the family business (focusing on his own career), while the others chose to stay involved in day-to-day operations.<br> The wife, elderly and retired for years, ended up at the helm, but she was clearly out of her depth.</p><p>The main issue was the complete lack of information flow: no digital systems of any kind were in place.<br> Employees had their own PCs (sometimes even personal laptops), and there was zero control over anything.<br> All the accounting and administrative data were scattered across individual machines, often taken home at the end of the day.<br> From the owners’ perspective, all they saw was a huge cash flow coming in - yet the accounts were always in the red.</p><p>"If we keep going like this, we’ll be bankrupt in just a few years", I was told.<br> What I could do was set up a proper IT system, structured to make data management transparent and traceable.</p><p>I planned - and got immediate approval for - the purchase of routers, switches, various networking devices and a server with several disks.<br><a href="https://it-notes.dragas.net/2023/08/27/that-old-netbsd-server-running-since-2010/">The OS of choice, as was my habit at the time, was NetBSD</a>. Thanks to XEN, I set up multiple VMs.<br> One handled the NAS duties (using Samba, so PCs could connect and store files directly there), another ran <a href="https://archivista.ch/">Archivista</a>.<br> I even worked on translating Archivista’s interface into Italian, since it wasn’t yet localized, just to make it easier for users.</p><p>As usual in those days, I added a caching proxy (Squid) and a content filter (DansGuardian), to ensure proper usage.<br> The internet connection was very slow and often collapsed under heavy load - mostly recreational use, as logs revealed.<br> There was no supervision, and many people were downloading movies and such on company time.</p><p>As often happens, not everyone was happy. </p><p>One figure in particular - the late owner's former right-hand man - opposed the new system in every possible way.<br> According to him, none of this was necessary. But the real alarm bell had been his sudden change in lifestyle.<br> He’d made purchases that didn’t remotely align with his salary.<br> At the time, the company had no oversight and dealt with a lot of cash. It was all technically legal, especially given the nature of the business. I won’t go into detail - privacy matters.</p><p>Once everything was up and running, we trained the employees to use the new system.<br> Most were thrilled - finally able to work properly, with files in the right place and centralized document management.<br> OCR, archiving, etc. were all seen as major time-savers and a big boost in efficiency.<br> Some of the accounting staff remained skeptical, of course.</p><p>Since all of this was far from where I lived at the time, I went back to my life once the system was stable and everything in place.<br> A few quiet days passed - then one morning, my phone rang:</p><p>"Good morning, this is XYZ - I handle some technical aspects of a software suite used by the company where you've just installed everything.<br> We need to install our software, and I understand you set up the server. I’ll need the full server diagram and all the admin passwords".</p><p>I explained that it wasn’t a Windows machine, as he assumed (without even having seen it), but NetBSD, running NetBSD and Linux VMs.</p><p>A few seconds of silence.</p><p>"I see. Then I’ll have to wipe it and install Windows. I need Windows, and I don’t have time to wait for a new server - I’ll proceed tomorrow morning".</p><p>I froze. I told him that was not possible - the entire workflow now depended on that machine, and erasing it would be catastrophic.</p><p>"I’ll speak with the owners", I said, "and I’m sure they’ll provide you with a separate server within hours".</p><p>No use. He started to backpedal.<br> To my (young) eyes, the goal was now obvious: that server had to disappear, and fast.<br> He said he would "restore the previous situation", and claimed the server couldn’t remain as-is because <em>he</em> needed it.</p><p>I immediately called the owners. Sadly, due to inexperience and inability to handle the situation, they panicked.<br> They asked me to consider letting him do it, and then redoing the setup later, covering the cost of new hardware and my time.<br> I refused. I was young, but I already had this mindset: do what’s right, even at the cost of profit.<br> This was clearly a maneuver to eliminate controls - the server, the centralized filesystem.<br> The goal was to hide the real accounting data from owners and auditors. Thousands of euros vanished every day through "transactions".<br> The owners had started to understand, and this new pressure confirmed just how rotten things really were.</p><p>I called that man back and told him clearly: the server I’d built wasn’t to be shut down.<br> If he needed one, I’d deliver a new server by that evening, just for him.</p><p>At that point, he finally spoke more openly:</p><p>"You don’t get it, do you? I need <em>that</em> server. Not <em>a</em> server.<br> You’d better go along with this — or you’ll have serious trouble working in this area again".</p><p>And other similar, "nice" sentences. I replied calmly:<br> "Look, I’m just doing a favor for some friends. I don’t have clients in your area — and I don’t want any.<br> I’d rather do a good job for them than gain new clients".</p><p>No way through. He kept pushing - confident in his own sense of "power" - until I said what I had been trying to avoid.</p><p>Because I had recognized who he was.<br> And the disappointment hit me twice as hard - I used to admire him.<br> He, however, had not recognized me.</p><p>"Excuse me, but why are you talking to me like this? You’ve known me since I was a child. Don’t you remember? I’m the nephew of..."</p><p>He froze.<br> He understood immediately.<br> He connected the dots and knew full well that a single phone call to someone extremely close to me - someone he owed a great deal, both personally and professionally - would have the opposite effect he was aiming for.</p><p>That person had helped him greatly over the years. So much so that he folded:</p><p>"Oh... I’m so sorry... I didn’t recognize you. I’ll find another solution. Sorry again".</p><p>He hung up.<br> Never heard from him again.</p><p>I informed the owners that the issue was resolved (leaving out most of the details), but it didn’t last long.<br> Within days, a series of "unfortunate events" hit the server: the UPS failed, the server was "accidentally" unplugged and plugged back in incorrectly, and finally... it stopped responding on the network.</p><p>It was dead.<br> And when we opened it, the hard disks were just... gone.</p><p>But there was one thing nobody (but the owners) knew.<br> The server - slowly but surely - had been backing up externally.<br> All the data up to that point had been copied to a device we’d quietly installed at the owners’ home: a tiny PCEngines Alix, running NetBSD with two USB drives.<br> It was slow, yes - slow hardware, slow disks - but reliable.<br> That very device still works today (with FreeBSD) and provides services elsewhere.</p><p>I handed all the data to the owners and asked what they intended to do.<br> They took some time - days, then weeks.<br> Eventually, they said they’d probably investigate whether there were grounds for a theft report.</p><p>I never heard more about it.</p><p>But then came a tempting offer:</p><p>"Come work for us. Manage our network infrastructure and help us overhaul our internal procedures.<br> Even if you’ve just bought a house far from here, even if you’d have to leave your other clients -<br> we’ll pay you enough to forget everything else. Name your price".</p><p>They would’ve done it, too.<br> Our mutual friend urged me:<br> "They’ve got a huge cash flow, but too many people are taking advantage of them due to lack of control.<br> Take the job - they’ll treat you like gold, and you’ll really help them".</p><p>I didn’t think twice. </p><p><strong>I turned it down</strong>.</p><p>I like my work.<br> I like doing what I do - and the income is a consequence, not the cause.<br> I would’ve had to give up my life, my path, to fight battles I don’t enjoy - and that I might not even win.</p><p>Because sometimes, dishonest people <em>do</em> win.</p><p>I’ve never regretted declining that offer.<br> I lost touch with all of them years ago, but I later heard things went as I predicted:<br> the owners gradually backed out. </p><p>They made another request later on, which I tried to fulfill — but even that was blocked, just when everything was ready.</p><p>At some point, I had to walk away.<br> Not because I wanted to abandon them in a time of need, but because they weren’t giving me the tools to do what was necessary.<br> They were so overwhelmed, so unprepared, that they ended up yielding to pressure - often from the very people who were hurting them.</p><p>And of course, I’ve left out the worst parts of the story.</p><p><em>(Author's note: Many readers, understandably struck by the severity of the events, have speculated about the involvement of organized crime. I want to clarify that, while the situation was extremely problematic and dishonest, that wasn't the case. The "worst parts" I alluded to referred to other internal dynamics, abuses of trust, and improprieties that I prefer not to detail further for privacy reasons and to avoid weighing down the narrative.)</em></p><p>That’s when I realized:<br> Some situations are so rotten, they simply can’t be salvaged.</p><p>And that’s okay.</p><p><a href="https://it-notes.dragas.net/2024/10/03/i-solve-problems-eurobsdcon/">I solve problems</a> - it’s what I do best.</p><p>But I can’t solve <strong>every</strong> problem.<br> Especially not when those involved choose to protect the problem instead of fixing it.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uber to introduce fixed-route shuttles in major US cities (148 pts)]]></title>
            <link>https://techcrunch.com/2025/05/14/uber-to-introduce-fixed-route-shuttles-in-major-us-cities-other-ways-to-save/</link>
            <guid>43985861</guid>
            <pubDate>Wed, 14 May 2025 15:40:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/05/14/uber-to-introduce-fixed-route-shuttles-in-major-us-cities-other-ways-to-save/">https://techcrunch.com/2025/05/14/uber-to-introduce-fixed-route-shuttles-in-major-us-cities-other-ways-to-save/</a>, See on <a href="https://news.ycombinator.com/item?id=43985861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Ride-hail and delivery giant Uber is introducing cheap, fixed-route rides along busy corridors during weekday commute hours in major U.S. cities — one solution to a world that feels, for most people, more expensive every day.&nbsp;</p>

<p>Starting Wednesday, riders in Baltimore, Boston, Chicago, Dallas, New York City, Philadelphia, and San Francisco will be able to save 50% off the price of an UberX trip by booking with Uber’s new “Route Share” feature.&nbsp;</p>







<p>The company announced Route Share and other new features and discounts designed to help customers save money on rides and deliveries at its <a href="https://techcrunch.com/2024/05/15/uber-has-a-new-way-to-solve-the-concert-traffic-problem/" target="_blank" rel="noreferrer noopener">annual Go-Get event</a>. The aim is to attract and maintain a loyal customer base that continues to use the Uber app in spite of outside economic pressures.</p>

<p>The commuter shuttles will drive between pre-set stops every 20 minutes, according to Sachin Kansal, Uber’s chief product officer. He noted that there will be dozens of routes in each launch city — like between Williamsburg and Midtown in NYC. The routes, which are selected based on Uber’s extensive data on popular travel patterns, might have one or two additional stops to pick up other passengers. To start, riders will only ever have to share the route with up to two other co-riders.&nbsp;</p>

<p>Riders can book a seat anywhere from seven days to 10 minutes before a scheduled pickup, and the app will provide them with turn-by-turn directions to get them from their house to the corner where they’ll be picked up.</p>

<p>Uber is relying on the same underlying technology that it uses for Uber Share, its shared rides offering where riders can get 15% to 30% off the cost of an UberX ride by pooling with others. Kansal told TechCrunch that Uber completes millions of shared trips annually and has been seeing more traction lately as riders look for more ways to save. Hence, Route Share.&nbsp;</p>

<p>“Because of the size of our network, both on the consumer side as well as the driver side, and our core matching and market-based technology, it allows us to do something like this and put multiple people in the same car while creating efficiency and predictability for their commute,” Kansal told TechCrunch.&nbsp;</p>


<p>Uber envisions a future where Route Share could qualify for pre-tax commuter benefits. However, as a spokesperson noted, the company would need to find a way to match those trips with Uber XL vehicles. That’s because only six-seater vehicles would meet the eligibility requirements.</p>

<p>A potential progression of Route Share would involve autonomous vehicles, particularly in chaotic cities like New York City, where no self-driving car companies have deigned to test.&nbsp;</p>

<p>Uber has partnerships with 18 AV companies and during its first-quarter earnings delivery last week, the company reported it has grown to an annualized rate of 1.5 million mobility and delivery AV trips on the Uber network.&nbsp;</p>







<p>One of Uber’s more recent AV partners is with Volkswagen. The two plan to work together to add autonomous versions of VW’s ID. Buzz AD electric vehicles to the Uber app — specifically for shared rides — starting in Los Angeles in 2026.</p>

<p>“You can see a natural extension of us being able to bring Route Share to autonomous vehicles, as well,” Kansal said. “[Route Share] has a lot of advantages for the autonomous vehicle. It’s a very well-defined route, and so the pickups and drop offs are predictable.”</p>

<h3 id="h-other-ways-frequent-uber-users-can-save"><strong>Other ways frequent Uber users can save</strong></h3>

<figure><img loading="lazy" decoding="async" width="1920" height="1080" src="https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?w=680" alt="" srcset="https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg 1920w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=150,84 150w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=300,169 300w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=768,432 768w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=680,383 680w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=1200,675 1200w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=1280,720 1280w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=430,242 430w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=720,405 720w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=900,506 900w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=800,450 800w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=1536,864 1536w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=668,375 668w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=1097,617 1097w, https://techcrunch.com/wp-content/uploads/2025/05/Uber-go-get-deals.jpg?resize=708,398 708w" sizes="auto, (max-width: 1920px) 100vw, 1920px"><figcaption><span><strong>Image Credits:</strong>Uber</span></figcaption></figure>

<p>Each of Uber’s Get-Go events has a theme. Last year, it was focused on ways to help people spend more time together. This year, with economic uncertainty looming due to President Trump’s tariffs, mass layoffs across the tech world, and AI coming for all our jobs, Uber is focusing on cost savings for riders. In the process, Uber hopes to create a predictable cash flow and stickiness that keeps riders engaged with Uber.&nbsp;</p>

<p>“Of late, what we have heard very loud and clear is people feel very uncertain, people feel overwhelmed, and people are feeling the prices in many different walks of life, and there’s this need and desire to get more affordable options,” Kansal said. “So everything we’re announcing is squarely focused on how we make life more affordable for them.”</p>

<p>One of Uber’s new features is “ride passes,” which riders can use to “protect their price for a one-hour window each day on their selected routes.” There are two ways this will work. Either riders can pay $2.99 to lock in a price on a specific route, or they can pay upfront and buy a bundle of prepaid trips. They can buy five, 10, 15, or 20 rides for an “even deeper discount.”&nbsp;</p>

<p>The price lock offer will be available for riders in Chicago, Dallas, Houston, Las Vegas, Miami, Nashville, Orlando, Phoenix, San Francisco, and Washington, D.C. starting Wednesday, with the rest of the U.S. and Brazil to follow. In the fall, price lock and prepaid passes will be available for teen accounts, too.&nbsp;</p>

<p>On the Uber Eats side of things, Uber is going deeper into its partnership with OpenTable and launching a feature called Dine Out, which lets customers in the U.S., Canada, Mexico, the U.K., Ireland, and Australia book tables via OpenTable on the Uber app. When they reserve (either on the Uber app or on OpenTable’s app), they’ll get a discount on an Uber ride to the restaurant. Additionally, OpenTable members will soon be able to use their points on Uber and Uber Eats — not unlike <a href="https://techcrunch.com/2025/04/22/uber-customers-can-now-earn-delta-skymiles-from-rides-or-deliveries/">Uber’s partnership with Delta Air Lines</a>.&nbsp;</p>

<p>These kinds of deals could offer savings for riders, particularly during peak demand times when surge pricing is in effect. But they’re likely more beneficial for people who frequently use Uber’s service. Prepaid packages often feel cheaper due to upfront discounts, but riders could also overestimate how much they’ll use them.</p>







<p>Uber’s pricing strategy is also not transparent, and some <a href="https://www.sfgate.com/travel/article/bay-area-traveler-says-uber-gift-cards-boosted-20281408.php?utm_source=chatgpt.com" target="_blank" rel="noreferrer noopener nofollow">reports</a> have suggested that riders with prepaid credits or gift cards get higher fare quotes compared to those paying per ride. (Anecdotally, whenever I switch my payment method from my personal card to my business card, the price of the ride jumps a few dollars.)&nbsp;</p>

<p>An Uber spokesperson told TechCrunch the price lock feature is based on historical prices of that trip, and the prepaid pass protects against price spikes and adds discounts that are also based on historical prices.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Lumier – Run macOS VMs in a Docker (133 pts)]]></title>
            <link>https://github.com/trycua/cua/tree/main/libs/lumier</link>
            <guid>43985624</guid>
            <pubDate>Wed, 14 May 2025 15:19:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/trycua/cua/tree/main/libs/lumier">https://github.com/trycua/cua/tree/main/libs/lumier</a>, See on <a href="https://news.ycombinator.com/item?id=43985624">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>GitHub Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_product_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
        <p>GitHub Advanced Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code Review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
        <p>Code Search</p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      Events &amp; Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      
      <div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>Enterprise platform</p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:trycua/cua" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="sRFBKc70sdI_8-zAHANW3lGu3MOTTNdArJMkRY1y5s8cYNngGIkQpI7HqKAgrqfmyv1t-DWpxJWeHwlR9QvXLA" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="trycua/cua" data-current-org="trycua" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Ffiles%2Fdisambiguate&amp;source=header-repo&amp;source_repo=trycua%2Fcua" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/trycua/cua/tree/main/libs/lumier&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="6ea2dd7059ac61ea0174d7ac5c4b9ca1e8e59005a8a4b0476733eeb9f58d48a2" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/files/disambiguate;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-1a25d33f-097e-4cbd-9846-6d24e7566105" for="icon-button-71ef203b-0963-4ba3-a0a8-0ad14f7d7b47" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <script crossorigin="anonymous" defer="defer" type="application/javascript" src="https://github.githubassets.com/assets/ui_packages_document-metadata_document-metadata_ts-ui_packages_promise-with-resolvers-polyfil-40d47c-11c6336aaa7c.js"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="https://github.githubassets.com/assets/appearance-settings-1d8b3a6a9ee9.js"></script>
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.d2117d7623cc63123645.module.css">
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.22dfbc22ef0a2bf02523.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>

      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms (749 pts)]]></title>
            <link>https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/</link>
            <guid>43985489</guid>
            <pubDate>Wed, 14 May 2025 15:10:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/">https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/</a>, See on <a href="https://news.ycombinator.com/item?id=43985489">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
      
  <article>
    
    
  
  
  
    
      

      
      
        
          
            <div>
              
                
                
                  
                  
<div>
    <div>
      <p>Research</p>
      

      
    <dl>
      
        <dt>Published</dt>
        <dd><time datetime="2025-05-14">14 May 2025</time></dd>
      
      
        <dt>Authors</dt>
        
      
    </dl>
  

      
    </div>

    
      
    
    
    <picture>
      <source media="(min-width: 1024px)" type="image/webp" width="1072" height="603" srcset="https://lh3.googleusercontent.com/Gw688MNwkQVBeUALSFtQz46Oh4NFoZAe10mEpvtmZhKuWhlQsi5uh2KFHKbxH8NhBnOGUNza6O6-0HElml2zEN06vI_9oAsjAxFVzxjDL5DOw7HsAw=w1072-h603-n-nu-rw 1x, https://lh3.googleusercontent.com/Gw688MNwkQVBeUALSFtQz46Oh4NFoZAe10mEpvtmZhKuWhlQsi5uh2KFHKbxH8NhBnOGUNza6O6-0HElml2zEN06vI_9oAsjAxFVzxjDL5DOw7HsAw=w2144-h1206-n-nu-rw 2x"><source media="(min-width: 600px)" type="image/webp" width="928" height="522" srcset="https://lh3.googleusercontent.com/Gw688MNwkQVBeUALSFtQz46Oh4NFoZAe10mEpvtmZhKuWhlQsi5uh2KFHKbxH8NhBnOGUNza6O6-0HElml2zEN06vI_9oAsjAxFVzxjDL5DOw7HsAw=w928-h522-n-nu-rw 1x, https://lh3.googleusercontent.com/Gw688MNwkQVBeUALSFtQz46Oh4NFoZAe10mEpvtmZhKuWhlQsi5uh2KFHKbxH8NhBnOGUNza6O6-0HElml2zEN06vI_9oAsjAxFVzxjDL5DOw7HsAw=w1856-h1044-n-nu-rw 2x"><source type="image/webp" width="528" height="297" srcset="https://lh3.googleusercontent.com/Gw688MNwkQVBeUALSFtQz46Oh4NFoZAe10mEpvtmZhKuWhlQsi5uh2KFHKbxH8NhBnOGUNza6O6-0HElml2zEN06vI_9oAsjAxFVzxjDL5DOw7HsAw=w528-h297-n-nu-rw 1x, https://lh3.googleusercontent.com/Gw688MNwkQVBeUALSFtQz46Oh4NFoZAe10mEpvtmZhKuWhlQsi5uh2KFHKbxH8NhBnOGUNza6O6-0HElml2zEN06vI_9oAsjAxFVzxjDL5DOw7HsAw=w1056-h594-n-nu-rw 2x">
      <img alt="Colourful and abstract digital landscape of code. Demonstrating peaks in high performing code." height="603" src="https://lh3.googleusercontent.com/Gw688MNwkQVBeUALSFtQz46Oh4NFoZAe10mEpvtmZhKuWhlQsi5uh2KFHKbxH8NhBnOGUNza6O6-0HElml2zEN06vI_9oAsjAxFVzxjDL5DOw7HsAw=w1072-h603-n-nu" width="1072">
    </picture>
    
  
    
  </div>
                
              
                
                
                  
                  <div>
  <h4 data-block-key="1rhtp">New AI agent evolves algorithms for math and practical applications in computing by combining the creativity of large language models with automated evaluators</h4><p data-block-key="bpa0i">Large language models (LLMs) are remarkably versatile. They can summarize documents, generate code or even brainstorm new ideas. And now we’ve expanded these capabilities to target fundamental and highly complex problems in mathematics and modern computing.</p><p data-block-key="a2lsk">Today, we’re announcing <a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf" rel="noopener" target="_blank">AlphaEvolve</a>, an evolutionary coding agent powered by large language models for general-purpose algorithm discovery and optimization. AlphaEvolve pairs the creative problem-solving capabilities of our <a href="https://deepmind.google/technologies/gemini/" rel="noopener" target="_blank">Gemini models</a> with automated evaluators that verify answers, and uses an evolutionary framework to improve upon the most promising ideas.</p><p data-block-key="7b9nk">AlphaEvolve enhanced the efficiency of Google's data centers, chip design and AI training processes — including training the large language models underlying AlphaEvolve itself. It has also helped design faster matrix multiplication algorithms and find new solutions to open mathematical problems, showing incredible promise for application across many areas.</p>
</div>
                
              
                
                
                  
                  <div>
  <h2 data-block-key="1rhtp">Designing better algorithms with large language models</h2><p data-block-key="cmrs5">In 2023, we showed for the first time that large language models can generate functions written in computer code to help <a href="https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/" rel="noopener" target="_blank">discover new and provably correct knowledge</a> on an open scientific problem. AlphaEvolve is an agent that can go beyond single function discovery to evolve entire codebases and develop much more complex algorithms.</p><p data-block-key="8lpr6">AlphaEvolve leverages an ensemble of state-of-the-art large language models: our fastest and most efficient model, <a href="https://deepmind.google/technologies/gemini/flash/?_gl=1*7wovog*_up*MQ..*_ga*ODcyNjk2MzY0LjE3NDYxODE1OTY.*_ga_LS8HVHCNQ0*MTc0NjE4MTU5NS4xLjAuMTc0NjE4MTU5OS4wLjAuMA.." rel="noopener" target="_blank">Gemini Flash</a>, maximizes the breadth of ideas explored, while our most powerful model, <a href="https://deepmind.google/technologies/gemini/pro/?_gl=1*5ncg4r*_up*MQ..*_ga*ODcyNjk2MzY0LjE3NDYxODE1OTY.*_ga_LS8HVHCNQ0*MTc0NjE4MTU5NS4xLjAuMTc0NjE4MTU5OS4wLjAuMA.." rel="noopener" target="_blank">Gemini Pro</a>, provides critical depth with insightful suggestions. Together, these models propose computer programs that implement algorithmic solutions as code.</p>
</div>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-37de9aef-e216-4e74-bad9-c132e221ef65">
  

  <figcaption>
      <p data-block-key="lnm7d">Diagram showing how the prompt sampler first assembles a prompt for the language models, which then generate new programs. These programs are evaluated by evaluators and stored in the programs database. This database implements an evolutionary algorithm that determines which programs will be used for future prompts.</p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <p data-block-key="1rhtp">AlphaEvolve verifies, runs and scores the proposed programs using automated evaluation metrics. These metrics provide an objective, quantifiable assessment of each solution’s accuracy and quality. This makes AlphaEvolve particularly helpful in a broad range of domains where progress can be clearly and systematically measured, like in math and computer science.</p>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="1rhtp">Optimizing our computing ecosystem</h3><p data-block-key="eu4jo">Over the past year, we’ve deployed algorithms discovered by AlphaEvolve across Google’s computing ecosystem, including our data centers, hardware and software. The impact of each of these improvements is multiplied across our AI and computing infrastructure to build a more powerful and sustainable digital ecosystem for all our users.</p>
</div>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-3e1cbb33-1c95-4dc0-b1a4-6aa109adf4c3">
  

  <figcaption>
      <p data-block-key="lnm7d">Diagram showing how AlphaEvolve helps Google deliver a more efficient digital ecosystem, from data center scheduling and hardware design to AI model training.</p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="1rhtp">Improving data center scheduling</h3><p data-block-key="3ra3e">AlphaEvolve discovered a simple yet remarkably effective heuristic to help <a href="https://research.google/pubs/large-scale-cluster-management-at-google-with-borg/" rel="noopener" target="_blank">Borg</a> orchestrate Google's vast data centers more efficiently. This solution, now in production for over a year, continuously recovers, on average, 0.7% of Google’s worldwide compute resources. This sustained efficiency gain means that at any given moment, more tasks can be completed on the same computational footprint. AlphaEvolve's solution not only leads to strong performance but also offers significant operational advantages of human-readable code: interpretability, debuggability, predictability and ease of deployment.</p>
</div>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="1rhtp">Assisting in hardware design</h3><p data-block-key="9gnp2">AlphaEvolve proposed a <a href="https://en.wikipedia.org/wiki/Verilog" rel="noopener" target="_blank">Verilog</a> rewrite that removed unnecessary bits in a key, highly optimized arithmetic circuit for matrix multiplication. Crucially, the proposal must pass robust verification methods to confirm that the modified circuit maintains functional correctness. This proposal was integrated into an upcoming <a href="https://cloud.google.com/tpu?hl=en" rel="noopener" target="_blank">Tensor Processing Unit</a> (TPU), Google’s custom AI accelerator. By suggesting modifications in the standard language of chip designers, AlphaEvolve promotes a collaborative approach between AI and hardware engineers to accelerate the design of future specialized chips.</p>
</div>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="1rhtp">Enhancing AI training and inference</h3><p data-block-key="279mo">AlphaEvolve is accelerating AI performance and research velocity. By finding smarter ways to divide a large matrix multiplication operation into more manageable subproblems, it sped up this vital <a href="https://docs.jax.dev/en/latest/pallas/index.html" rel="noopener" target="_blank">kernel</a> in Gemini’s architecture by 23%, leading to a 1% reduction in Gemini's training time. Because developing generative AI models requires substantial computing resources, every efficiency gained translates to considerable savings. Beyond performance gains, AlphaEvolve significantly reduces the engineering time required for kernel optimization, from weeks of expert effort to days of automated experiments, allowing researchers to innovate faster.</p><p data-block-key="fvg3r">AlphaEvolve can also optimize low level GPU instructions. This incredibly complex domain is usually already heavily optimized by compilers, so human engineers typically don't modify it directly. AlphaEvolve achieved up to a 32.5% speedup for the<a href="https://arxiv.org/abs/2205.14135" rel="noopener" target="_blank"> FlashAttention</a> kernel implementation in<a href="https://en.wikipedia.org/wiki/Transformer_%28deep_learning_architecture%29" rel="noopener" target="_blank"> Transformer</a>-based AI models. This kind of optimization helps experts pinpoint performance bottlenecks and easily incorporate the improvements into their codebase, boosting their productivity and enabling future savings in compute and energy.</p>
</div>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="1rhtp">Advancing the frontiers in mathematics and algorithm discovery</h3><p data-block-key="8i4l">AlphaEvolve can also propose new approaches to complex mathematical problems. Provided with a minimal code skeleton for a computer program, AlphaEvolve designed many components of a novel <a href="https://www.sciencedirect.com/topics/engineering/gradient-based-algorithm" rel="noopener" target="_blank">gradient-based optimization</a> procedure that discovered multiple new algorithms for matrix multiplication, a fundamental problem in computer science.</p>
</div>
                
              
                
                
                  
                  





<figure aria-labelledby="caption-fb8c0bba-9a53-4d4e-918f-e2d2a3122595">
  

  <figcaption>
      <p data-block-key="pp1h1">A list of changes proposed by AlphaEvolve to discover faster matrix multiplication algorithms. In this example, AlphaEvolve proposes extensive changes across several components, including the optimizer and weight initialization, the loss function, and hyperparameter sweep. These changes are highly non-trivial, requiring 15 mutations during the evolutionary process.</p>
    </figcaption>
</figure>
                
              
                
                
                  
                  <div>
  <p data-block-key="1rhtp">AlphaEvolve’s procedure found an algorithm to multiply 4x4 complex-valued matrices using 48 scalar multiplications, improving upon <a href="https://en.wikipedia.org/wiki/Strassen_algorithm" rel="noopener" target="_blank">Strassen’s 1969 algorithm</a> that was previously known as the best in this setting. This finding demonstrates a significant advance over our previous work, <a href="https://deepmind.google/discover/blog/discovering-novel-algorithms-with-alphatensor/" rel="noopener" target="_blank">AlphaTensor</a>, which specialized in matrix multiplication algorithms, and for 4x4 matrices, only found improvements for binary arithmetic.</p><p data-block-key="fmlon">To investigate AlphaEvolve’s breadth, we applied the system to over 50 open problems in mathematical analysis, geometry, combinatorics and number theory. The system’s flexibility enabled us to set up most experiments in a matter of hours. In roughly 75% of cases, it rediscovered state-of-the-art solutions, to the best of our knowledge.</p><p data-block-key="86rjt">And in 20% of cases, AlphaEvolve improved the previously best known solutions, making progress on the corresponding open problems. For example, it advanced the <a href="https://en.wikipedia.org/wiki/Kissing_number" rel="noopener" target="_blank">kissing number problem</a>. This geometric challenge has <a href="https://plus.maths.org/content/newton-and-kissing-problem" rel="noopener" target="_blank">fascinated mathematicians for over 300 years</a> and concerns the maximum number of non-overlapping spheres that touch a common unit sphere. AlphaEvolve discovered a configuration of 593 outer spheres and established a new lower bound in 11 dimensions.</p>
</div>
                
              
                
                
                  
                  <div>
  <h3 data-block-key="1rhtp">The path forward</h3><p data-block-key="9e94g">AlphaEvolve displays the progression from discovering algorithms for specific domains to developing more complex algorithms for a wide range of real-world challenges. We’re expecting AlphaEvolve to continue improving alongside the capabilities of large language models, especially as they become even <a href="https://developers.googleblog.com/en/gemini-2-5-pro-io-improved-coding-performance/" rel="noopener" target="_blank">better at coding</a>.</p><p data-block-key="7kobf">Together with the <a href="https://pair.withgoogle.com/" rel="noopener" target="_blank">People + AI Research team</a>, we’ve been building a friendly user interface for interacting with AlphaEvolve. We’re planning an Early Access Program for selected academic users and also exploring possibilities to make AlphaEvolve more broadly available. To register your interest, please complete <a href="https://forms.gle/WyqAoh1ixdfq6tgN8" rel="noopener" target="_blank">this form</a>.</p><p data-block-key="cefdg">While AlphaEvolve is currently being applied across math and computing, its general nature means it can be applied to any problem whose solution can be described as an algorithm, and automatically verified. We believe AlphaEvolve could be transformative across many more areas such as material science, drug discovery, sustainability and wider technological and business applications.</p>
</div>
                
              
                
                
                  
                  

<section>
  

  <ul>
    
      <li>
            <gemini-button data-in-view="">
              <a data-gtm-tag="cta-selection" href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf" rel="noopener" target="_blank">
      <span>Read more details in our white paper</span>
      
    </a>
            </gemini-button>
        </li>
        
    
      <li>
            <gemini-button data-in-view="">
              <a data-gtm-tag="cta-selection" href="https://forms.gle/WyqAoh1ixdfq6tgN8" rel="noopener" target="_blank">
      <span>Register your interest in using AlphaEvolve</span>
      
    </a>
            </gemini-button>
        </li>
        
    
      <li>
            <gemini-button data-in-view="">
              <a data-gtm-tag="cta-selection" href="https://colab.research.google.com/github/google-deepmind/alphaevolve_results/blob/master/mathematical_results.ipynb" rel="noopener" target="_blank">
      <span>See AlphaEvolve’s mathematical results in our Google Colab</span>
      
    </a>
            </gemini-button>
        </li>
        
    
  </ul>
</section>
                
              
                
                
                  
                  <div>
      <p data-block-key="ndxib"><strong>Acknowledgements</strong></p><p data-block-key="d0au1">AlphaEvolve was developed by Matej Balog, Alexander Novikov, Ngân Vũ, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey Shirobokov, Borislav Kozlovskii, Francisco J. R. Ruiz, Abbas Mehrabian, M. Pawan Kumar, Abigail See, Swarat Chaudhuri, George Holland, Alex Davies, Sebastian Nowozin, and Pushmeet Kohli. This research was developed as part of our effort focused on using AI for algorithm discovery.</p><p data-block-key="frcj6">We gratefully acknowledge contributions, advice, and support from Jean-Baptiste Alayrac, Ankit Anand, Natasha Antropova, Giorgio Arena, Mohammadamin Barekatain, Johannes Bausch, Henning Becker, Daniel Belov, Alexander Belyaev, Sebastian Bodenstein, Sebastian Borgeaud, Calin Cascaval, Indranil Chakraborty, Benjamin Chetioui, Justin Chiu, Christopher Clark, Marco Cornero, Jeff Dean, Gaurav Dhiman, Yanislav Donchev, Srikanth Dwarakanath, Jordan Ellenberg, Alhussein Fawzi, Michael Figurnov, Aaron Gentleman, Bogdan Georgiev, Sergio Guadarrama, Demis Hassabis, Patrick Heisel, Chase Hensel, Koray Kavukcuoglu, Sultan Kenjeyev, Aliia Khasanova, Sridhar Lakshmanamurthy, Sergei Lebedev, Dmitry Lepikhin, Daniel Mankowitz, Andrea Michi, Kieran Milan, Vinod Nair, Robert O'Callahan, Cosmin Paduraru, Stig Petersen, Federico Piccinini, Parthasarathy Ranganatha, Bernardino Romera-Paredes, Georges Rotival, Kirk Sanders, Javier Gomez Serrano, Oleg Shyshkov, Timur Sitdikov, Tammo Spalink, Kerry Takenaka, Richard Tanburn, Terence Tao, Amin Vahdat, JD Velasquez, Dimitrios Vytiniotis, Julian Walker, and Pengming Wang. For more details, please see our white paper.<br></p><p data-block-key="btj9l">We would like to thank Armin Senoner, Juanita Bawagan, Jane Park, Arielle Bier, and Molly Beck for feedback on the blog post and help with this announcement; William Hood, Irina Andronic, Victoria Johnston, Lucas Dixon, Adam Connors, and Jimbo Wilson for help with the illustrations and figures</p>
    </div>
                
              
            </div>
          
        
      

      
    
  
  

  

  </article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SMS 2FA is not just insecure, it's also hostile to mountain people (358 pts)]]></title>
            <link>https://blog.stillgreenmoss.net/sms-2fa-is-not-just-insecure-its-also-hostile-to-mountain-people</link>
            <guid>43984297</guid>
            <pubDate>Wed, 14 May 2025 13:28:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.stillgreenmoss.net/sms-2fa-is-not-just-insecure-its-also-hostile-to-mountain-people">https://blog.stillgreenmoss.net/sms-2fa-is-not-just-insecure-its-also-hostile-to-mountain-people</a>, See on <a href="https://news.ycombinator.com/item?id=43984297">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>i have a friend — she's an old lady born and raised here in the western north carolina mountains. she hates computers, yes, but she's been willing to learn a lot and quickly after joining a big signal group chat that our shared local community uses to keep in touch.</p>

<p>aside from memeing with the best of them in the group chat, she also maintains a large fish pond outside the house she built herself. this despite being in her 70s. she's an inspiration.</p>

<p>she has a landline. it works great, and the landline phone hardware works great with her hearing aids. she's had it for years. spectrum has a monoply in our area so the landline and her cable internet service is with spectrum.</p>

<p>she got a cell phone a few years ago. she got a smartphone basically because she had to to do basic life tasks, including joining the big signal group chat. at first she just used it on wifi, but quickly she decided she wanted to be able to use the phone everywhere so she got a cell phone plan from spectrum because they were already her ISP. spectrum mobile uses the verizon network — famed for its good rural coverage.</p>

<p>this is where things started to go haywire.</p>

<p>all her accounts on websites, things like email and bank accounts and health insurance and healthcare providers, they started trying to send her SMS messages in order to let her get into her accounts.</p>

<p>the SMS codes don't work, because they don't come. she doesn't have cell service at her house. it's up in the mountains, sure, but it's not <em>isolated</em>. she lives 20 minutes from downtown asheville and she has lots of neighbors on her road.</p>

<p>she turned on wifi calling on her phone. now she could receive SMS messages from friends and family, but 2FA codes still weren't coming through. i did some digging, and it turns out messages from 5 digit shortcodes often aren't supported over wifi calling. sometimes they are, but in her case they're clearly not. she has a current, stock iphone. she's using the spectrum-provided internet hardware. she knows how to use her phone.</p>

<p>i did more digging — it turns out some ISP-provided landline services support receiving SMS messages to the landline, and then a computer voice reads them out to you. “we don't offer that service” the spectrum chat told us.</p>

<p>some of these accounts can likely be converted to using TOTP 2FA rather than SMS 2FA. this is good, but you have to get in to begin with in order to turn that on. so what my friend has to do is:</p>
<ol><li>make a list, over time, of the websites that she's locked out of because of SMS 2FA</li>
<li>not be able to use those sites at home the whole time she's making the list</li>
<li>schedule a meetup with a friend like me</li>
<li>drive to town to meet the friend</li>
<li>sit down and systematically go through the list of websites and convert them to TOTP</li>
<li>inevitably discover that some of them don't support TOTP</li>
<li>try and contact those companies and explain that they need to turn off SMS 2FA on her account so that she can use their healthcare/banking/email/whatever service from her home</li>
<li>discover that it's not possible to talk to a company anymore in 2025</li></ol>

<p>other options available to her include</p>
<ol><li>port her cellphone number to a VOIP provider that does support receiving SMS from shortcodes over wifi</li>
<li>spend hundreds of dollars setting up a cell tower signal booster outside her house</li>
<li>move</li></ol>

<p>these are all ridiculous options that shouldn't be necessary in order to log in to a website.</p>

<p>if you look at the spectrum mobile coverage map where my friend lives, it shows she has perfect coverage at her house. and all her neighbors do too. all the way up the holler in fact!</p>

<p>this is simply false. she usually doesn't even have service 100 meters down the road.</p>

<p>another friend of mine who also lives out in the county, a millenial, once said that “SMS 2FA is the bane of [her] existence.” the valley she's in isn't even that deep.</p>

<p>and TOTP, the obvious alternative solution, is still pretty sorry. you have to download an app to do it, it's not just a capability that a phone has by default. and then when trying to find an app to use for it, you're presented with a multitude of high-stakes choices, and often pretty technical explanations if you start internet searching about which app to use.</p>

<p>i understand why SMS 2FA is so ubiquitous. when it works, the UX is good, nontechnical users intuitively understand it, and it's usually secure <em>enough</em>.</p>

<p>but there are 1.1 <em>million</em> people in these western north carolina mountains, 25 million in the rest of the appalachians, and many millions more in the mountain west and pacific ranges.</p>

<p>we have internet, but we have F-tier cell service — what are we supposed to do?</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. nuclear base hidden under Greenland's ice for decades (136 pts)]]></title>
            <link>https://www.wsj.com/world/greenland-us-camp-century-nuclear-base-91e8abea</link>
            <guid>43984275</guid>
            <pubDate>Wed, 14 May 2025 13:27:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/world/greenland-us-camp-century-nuclear-base-91e8abea">https://www.wsj.com/world/greenland-us-camp-century-nuclear-base-91e8abea</a>, See on <a href="https://news.ycombinator.com/item?id=43984275">Hacker News</a></p>
Couldn't get https://www.wsj.com/world/greenland-us-camp-century-nuclear-base-91e8abea: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[How the economics of multitenancy work (150 pts)]]></title>
            <link>https://www.blacksmith.sh/blog/the-economics-of-operating-a-ci-cloud</link>
            <guid>43984097</guid>
            <pubDate>Wed, 14 May 2025 13:08:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.blacksmith.sh/blog/the-economics-of-operating-a-ci-cloud">https://www.blacksmith.sh/blog/the-economics-of-operating-a-ci-cloud</a>, See on <a href="https://news.ycombinator.com/item?id=43984097">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In the early days of Blacksmith, back when we were just a scrappy<a href="https://www.blacksmith.sh/blog/going-through-yc-winter-24" target="_blank"> YC startup</a> building a serverless cloud platform for CI workloads, we ran simulations to model our margins. We figured that with enough customers, the math would work out, and we crossed our fingers — but we didn’t have any real-world data to back up our predictions.</p><p>About six months after we launched, I came across<a href="https://brooker.co.za/blog/2023/03/23/economics.html" target="_blank"> a blog post</a> by Marc Brooker on the economics of multitenant systems. It captured what we were trying to do much more elegantly than the half-formed ideas in our heads. This post was heavily inspired by Marc’s, and reading it was a real moment of, <em>"Oh! someone else has thought about this, and it makes sense."<br></em><br>Now, we’re running thousands of jobs every minute and millions every month, and it’s been exciting to actually see this play out at scale and watch the math work in real life. Yet, people still often ask in disbelief how we actually make money from our setup — are we just burning sweet VC dollars with no return for them in sight? So, for the non-believers and anyone who is just a little bit curious, let’s take a peek behind the curtain and dive into how the economics of multitenancy work — using ourselves as a case study.</p><h2>CI Isn’t Like Production (And That Matters).</h2><p>Unlike production workloads, CI workloads tend to be very spiky. Below, we’ve plotted CPU utilization for one of our customers over a 24-hour window. It spikes when someone pushes code, then chills out in between.</p><figure><p><img src="https://cdn.prod.website-files.com/667db86cfee88934419c207a/68223888bd42f0e49049f825_AD_4nXeSffqllExgAscJ5z_HPS-3cikKIYBSQ7gFOVXlNh1bUll0ULzze95PXiy-F6eN35iYWqHIEVcrYltdvZio8Cxj0UFhz6SAkvNbM0UuLFXYU_LtM4vlwYCwer_95FoaToTrBPy6Jg.png" loading="lazy" alt=""></p></figure><p>This customer runs 35 jobs on 16 vCPU machines for every git push, meaning they need over 500 vCPUs every time they run CI. See where the chart flatlines like a patient on the George Clooney classic “ER”? Since their team is split across the US and EU, there’s an 8-hour stretch in the middle with zero usage. And when a few engineers push at once — say, five people — they suddenly need 2,500+ vCPUs instantly. And all these CI jobs are short-lived. Most CI jobs finish fast (relatively speaking), somewhere between 5 and 40 minutes. All of these chaotic characteristics of CI workloads might sound like a nightmare, but it’s actually a perfect fit for the serverless model we’ve built our platform around, and most importantly, for our customers.<br></p><h2>Why Our Serverless CI Model Works.</h2><p>Think about it from the customer's side: If you need 2,500 vCPUs at peak, it would be crazy to buy and manage all that hardware yourself — especially when it would sit idle most of the time. But with Blacksmith’s serverless CI cloud, you get to borrow from our pool and only pay for what you use. Spiky, bursty, chaotic? No problem.&nbsp;</p><p>What’s more, CI traffic is highly predictable. Developers are pushing code during work hours, not at 2AM or during holiday weekends. Unlike some production workloads, our fleet is not bracing for Black Friday-style traffic surges — and that shapes a lot of how we built it.</p><h2>Our Fleet: What It Looks Like and What Matters Most.</h2><p>We have a fleet of hundreds of bare-metal gaming CPUs that we’re virtualizing over — when a customer needs to run a CI job, we spin up a microVM using<a href="https://firecracker-microvm.github.io/" target="_blank"> Firecracker</a>, and once the job’s complete — poof! It’s gone.&nbsp;</p><p>Each of our machines has 32 vCPUs, and across the whole kit and kaboodle, we manage tens of thousands of vCPUs across our region us-west and eu-central. We pin customers to one region for consistency and workflow support.</p><p>Currently, we lease these machines for a fixed period. Soon, we’ll be racking them up in a datacenter. Regardless, these machines are a fixed cost — whether we have customers or not, we’re still paying for them. So, the name of the CI cost optimization game is utilization. If they’re barely used, our margins are low; if they’re used enough, we make that cash money. The metric we track the most is average fleet utilization — and that’s where customer chaos becomes our secret weapon.</p><h2>A Bit of Chaos is Bad. A Lot of Chaos? Chef's Kiss.</h2><p>Let’s say we only had one customer — the one from earlier who needs 2,500 vCPUs at peak. We’d need around 80 machines to handle that load, but for most of the day, those machines would just sit there, twiddling their thumbs. We’d be bleeding money.</p><p>Now, add a second customer in the same time zone. Their CI jobs don’t peak at the exact same time, so instead of needing 160 machines (80 + 80), we might only need 110 to cover both. As we add more customers, the effect compounds. We add even more customers, and all the random bursts of activity start to blend together.</p><p>Over time, CI jobs start behaving like a Poisson process — random, short bursts spread out across time. From a distance, what once looked like sharp spikes from individual customers smooths into a predictable pattern. The more customers we serve, the less intense each individual spike appears. In short: the more chaotic it gets, the better it is for our business. And when it’s better for business, it’s better for customers, too — because as our fleet gets busier, the cost to serve each job goes down. That lets us keep prices low while still running a sustainable business.</p><figure><p><img src="https://cdn.prod.website-files.com/667db86cfee88934419c207a/682238886ac6ab91059416e4_AD_4nXfIih5C-WAkfSy3pSAJ76i2gj1bGIsxKW5QDg3a8L43g1DQpyNEw6ntx6uHvNeXoV5e3PjOBe60GENpCB4vXXcNQJXpwRRsjIj7AtQIkKPs6OsRf9vPJnB75HT4ACv0ZNelQRgr.png" loading="lazy" alt=""></p></figure><p>The beauty of this setup is that every new customer actually makes the system better for everyone. Like when you have a dinner party and say, “<em>the more the merrier</em>” and actually mean it. More customers = more randomness = smoother overall operation. Multitenant systems work better with more users: utilization goes up, and our costs to serve go down. That means that growing chaos on our fleet only improves cost savings and efficiencies. You win. We win. In fact, even our fleet running hot is a good thing.</p><h2><em>A Fleet Running Hot Means More Money.</em></h2><p>Since we have to pay for a fixed fleet of machines no matter what, our gross margins depend almost entirely on how busy our machines are.</p><figure><p><img src="https://cdn.prod.website-files.com/667db86cfee88934419c207a/682247cde86bb073c71e164e_image%20(4).png" loading="lazy" alt=""></p></figure><p>Basically, our revenue scales with the average utilization of the fleet. There’s a direct link between utilization and gross margins, and it’s not linear.</p><ul role="list"><li>At 10% utilization, we’re already hitting around 35% gross margins.</li><li>At 20% utilization, margins jump to about 70%.</li><li>At 35% utilization, we’re flirting with 85%+ gross margins.</li></ul><figure><p><img src="https://cdn.prod.website-files.com/667db86cfee88934419c207a/682246036dd76c966b3d0821_Screenshot%202025-05-12%20at%2011.56.25%E2%80%AFAM.png" loading="lazy" alt=""></p></figure><p>Modest improvements in utilization result in massive improvements in profitability. Once utilization is high, the next major lever to keep improving margins is driving down the cost of acquiring machines — and for that time of day plays a surprisingly big role.</p><h2>Who’s Pushing Code When?</h2><p>During the weekends, our fleet only sees about 1/5<sup>th</sup> our typical usage. But weekdays? That’s when the party really starts.</p><figure><p><img src="https://cdn.prod.website-files.com/667db86cfee88934419c207a/682246d5bddb0bc7c9cf73dd_hourly%20utilization.png" loading="lazy" alt=""></p></figure><p>Most of our customers are based in the US, with a decent chunk in Europe, and a slowly growing portion in Asia. As seen in the chart below, utilization stays low during the first 8 hours of the day. Here’s the breakdown (in UTC time):</p><ul role="list"><li>Early hours = crickets (our Asian customer base is still small).</li><li>Midday = a bump from Europe.</li><li>Late Afternoon = the US wakes up, and our fleet is flying.</li></ul><p>The biggest spikes we see come when Europe’s finishing the day, and when the East Coast and West Coast are both working at the same time. Customers outside the US use our fleet during low-traffic hours — essentially free utilization. That boosts margins without us needing more machines. That’s CI cost optimization at its finest. Add it to the board, another win. We only really need to expand our fleet to keep up with growth in the US. And just like time zones shape customers’ daily usage and how we think about our fleet, geography shapes where we build and scale our fleet.</p><h2>Region Economics.</h2><p>We originally started with a single region in eu-central, but over time, we realized that we needed a second region in the US. This was driven by customer requests since Docker pushes to a container registry in the US is even faster when your runner is in the US. Plus, a few customers preferred keeping their code inside the US for compliance reasons. At first, the US region had just one big customer, so margins and utilization were meh. But as more folks have joined, our numbers are looking better and better as utilization improves.&nbsp;</p><p>We’re still working on optimally load balancing our regions, but this post is already too long so that’s a story for another day. If you made it this far, thanks for reading. Still burning a few VC dollars, but hey — margins are looking good thanks to the power of multitenancy. If you’d like to help improve them even more, <a href="https://app.blacksmith.sh/" target="_blank">try out Blacksmith</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The A.I. Radiologist Will Not Be with You Soon (106 pts)]]></title>
            <link>https://www.nytimes.com/2025/05/14/technology/ai-jobs-radiologists-mayo-clinic.html</link>
            <guid>43983928</guid>
            <pubDate>Wed, 14 May 2025 12:52:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/05/14/technology/ai-jobs-radiologists-mayo-clinic.html">https://www.nytimes.com/2025/05/14/technology/ai-jobs-radiologists-mayo-clinic.html</a>, See on <a href="https://news.ycombinator.com/item?id=43983928">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/05/14/technology/ai-jobs-radiologists-mayo-clinic.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[What Is HDR, Anyway? (549 pts)]]></title>
            <link>https://www.lux.camera/what-is-hdr/</link>
            <guid>43983871</guid>
            <pubDate>Wed, 14 May 2025 12:46:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lux.camera/what-is-hdr/">https://www.lux.camera/what-is-hdr/</a>, See on <a href="https://news.ycombinator.com/item?id=43983871">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        

  
        <div>
            <p>It's not you. HDR confuses tons of people.</p><p>Last year we announced HDR or "High Dynamic Range" photography was coming to our popular photography app, <a href="https://halide.cam/" rel="noreferrer">Halide</a>. While most customers celebrated, some were confused, and others showed downright <em>concern</em>. That's because HDR can mean two different, but related, things.</p><p>The first HDR is the "HDR mode" introduced to the iPhone camera in 2010.</p><figure><img src="https://www.lux.camera/content/images/2025/04/image-3.png" alt="" loading="lazy" width="960" height="540" srcset="https://www.lux.camera/content/images/size/w600/2025/04/image-3.png 600w, https://www.lux.camera/content/images/2025/04/image-3.png 960w" sizes="(min-width: 720px) 720px"><figcaption><span>September, 2010</span></figcaption></figure><p>The second HDR involves new screens that display more vibrant, detailed images. Shopped for a TV recently? No doubt you've seen stickers like this:</p><figure><img src="https://www.lux.camera/content/images/2025/05/HDR-Sticker.png" alt="" loading="lazy" width="2000" height="1242" srcset="https://www.lux.camera/content/images/size/w600/2025/05/HDR-Sticker.png 600w, https://www.lux.camera/content/images/size/w1000/2025/05/HDR-Sticker.png 1000w, https://www.lux.camera/content/images/size/w1600/2025/05/HDR-Sticker.png 1600w, https://www.lux.camera/content/images/size/w2400/2025/05/HDR-Sticker.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>This post finally explains what HDR <em>actually</em> means, the problems it presents, and three ways to solve them.</p><h2 id="what-is-dynamic-range">What is Dynamic Range?</h2><p>Let's start with a real world problem. Before smart phones, it was impossible to capture great sunsets with point-and-shoot cameras. No matter how you fiddled with the dials, everything came out too bright or too dark.</p><figure><div><p><img src="https://www.lux.camera/content/images/2025/03/new-york-skyline-no-hdr-under-exposed.jpeg" width="2000" height="1500" loading="lazy" alt="" srcset="https://www.lux.camera/content/images/size/w600/2025/03/new-york-skyline-no-hdr-under-exposed.jpeg 600w, https://www.lux.camera/content/images/size/w1000/2025/03/new-york-skyline-no-hdr-under-exposed.jpeg 1000w, https://www.lux.camera/content/images/size/w1600/2025/03/new-york-skyline-no-hdr-under-exposed.jpeg 1600w, https://www.lux.camera/content/images/size/w2400/2025/03/new-york-skyline-no-hdr-under-exposed.jpeg 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.lux.camera/content/images/2025/03/new-york-skyline-no-hdr-over-exposed.jpeg" width="2000" height="1500" loading="lazy" alt="" srcset="https://www.lux.camera/content/images/size/w600/2025/03/new-york-skyline-no-hdr-over-exposed.jpeg 600w, https://www.lux.camera/content/images/size/w1000/2025/03/new-york-skyline-no-hdr-over-exposed.jpeg 1000w, https://www.lux.camera/content/images/size/w1600/2025/03/new-york-skyline-no-hdr-over-exposed.jpeg 1600w, https://www.lux.camera/content/images/size/w2400/2025/03/new-york-skyline-no-hdr-over-exposed.jpeg 2400w" sizes="(min-width: 720px) 720px"></p></div><figcaption><p><span>The result of trying to capture a sunset with an old-school camera.</span></p></figcaption></figure><p>In that photo, the problem has to do with the different light levels coming from the sky and the buildings in shadow, the former emitting<em> thousands</em> of times more light than the latter. Our eyes can see both just fine. Cameras? They can deal with <em>overall</em> bright lighting, or <em>overall</em> dim lighting, but they struggled with scenes contain both really dark and really bright spots.</p><figure><div><p><img src="https://www.lux.camera/content/images/2025/05/HDRI_Sample_Scene_Window_-_05.jpg" width="1600" height="1200" loading="lazy" alt="" srcset="https://www.lux.camera/content/images/size/w600/2025/05/HDRI_Sample_Scene_Window_-_05.jpg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/HDRI_Sample_Scene_Window_-_05.jpg 1000w, https://www.lux.camera/content/images/2025/05/HDRI_Sample_Scene_Window_-_05.jpg 1600w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.lux.camera/content/images/2025/05/HDRI_Sample_Scene_Window_-_08.jpg" width="1600" height="1200" loading="lazy" alt="" srcset="https://www.lux.camera/content/images/size/w600/2025/05/HDRI_Sample_Scene_Window_-_08.jpg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/HDRI_Sample_Scene_Window_-_08.jpg 1000w, https://www.lux.camera/content/images/2025/05/HDRI_Sample_Scene_Window_-_08.jpg 1600w" sizes="(min-width: 720px) 720px"></p></div><figcaption><p><a href="https://en.wikipedia.org/wiki/Multi-exposure_HDR_capture" rel="noreferrer"><span>Via Wikipedia</span></a></p></figcaption></figure><p>Dynamic range simply means, "the difference between the darkest and brightest bits of a scene." For example, this foggy morning is an example of a <em>low</em> dynamic range scene, because everything is sort of gray.</p><figure><img src="https://www.lux.camera/content/images/2025/05/foggy.jpeg" alt="" loading="lazy" width="2000" height="1500" srcset="https://www.lux.camera/content/images/size/w600/2025/05/foggy.jpeg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/foggy.jpeg 1000w, https://www.lux.camera/content/images/size/w1600/2025/05/foggy.jpeg 1600w, https://www.lux.camera/content/images/2025/05/foggy.jpeg 2016w" sizes="(min-width: 720px) 720px"><figcaption><span>Screens have no trouble showing this low-contrast photo. Shot with Halide in Osaka.</span></figcaption></figure><p>Most of our photos aren't as extreme as bright sunsets or foggy mornings. We'll just call those "standard dynamic range" or SDR scenes.</p><p>Before we move on, we need to highlight that the HDR problem isn't limited to cameras. Even if you had a perfect camera that could match human vision, most <em>screens</em> cannot produce enough contrast to match the real world.</p><p>Regardless of your bottleneck, when a scene contains more dynamic range than your camera can capture or your screen can pump out, you lose highlights, shadows, or both.</p><h2 id="solution-1-hdr-mode">Solution 1: "HDR Mode"</h2><p>In the 1990s researchers came up with algorithms to tackle the dynamic range problem. The algorithms started by taking a bunch of photos with different settings to capture more highlights and shadows:</p><figure><div><p><img src="https://www.lux.camera/content/images/2025/05/memorial0062.png" width="512" height="768" loading="lazy" alt=""></p><p><img src="https://www.lux.camera/content/images/2025/05/memorial0065.png" width="512" height="768" loading="lazy" alt=""></p><p><img src="https://www.lux.camera/content/images/2025/05/memorial0068.png" width="512" height="768" loading="lazy" alt=""></p></div><figcaption><p><span>This full sequence has 16 photos. Via </span><a href="https://www.pauldebevec.com/Research/HDR/#radiancemaps" rel="noreferrer"><span>Paul Debevec</span></a><span>.</span></p></figcaption></figure><p>Then the algorithms combined everything into a single "photo" that matches human vision… a photo that was useless, since computer screens couldn't display HDR. So these researchers also came up with algorithms to squeeze HDR values onto an SDR screen, which they called "Tone Mapping."</p><figure><img src="https://www.lux.camera/content/images/2025/05/Reinhard.jpeg" alt="" loading="lazy" width="512" height="768"><figcaption><span>The Reinhard Tone Mapper, invented in 2002. It is </span><a href="https://sites.units.it/ipl/research/details/HDR_ToneMap/memorial_tm.html" rel="noreferrer"><span>one of many</span></a><span>.</span></figcaption></figure><p>These algorithms soon found their way into commercial software for camera nerds.</p><figure><img src="https://www.lux.camera/content/images/2025/04/image.png" alt="" loading="lazy" width="1674" height="1240" srcset="https://www.lux.camera/content/images/size/w600/2025/04/image.png 600w, https://www.lux.camera/content/images/size/w1000/2025/04/image.png 1000w, https://www.lux.camera/content/images/size/w1600/2025/04/image.png 1600w, https://www.lux.camera/content/images/2025/04/image.png 1674w" sizes="(min-width: 720px) 720px"><figcaption><span>Photomatix Circa 2008</span></figcaption></figure><p>Unfortunately, these packages required a lot of fiddling, and too many photographers in the mid-2000s… lacked restraint.</p><figure><img src="https://upload.wikimedia.org/wikipedia/commons/3/3f/Yonge-Dundas_Square_-_2010_%28HDR%29.jpg" alt="undefined" loading="lazy" width="1658" height="1105"><figcaption><span>The Ed Hardy t-shirt of photography. </span><a href="https://en.wikipedia.org/wiki/Tone_mapping" rel="noreferrer"><span>Via Wikipedia</span></a><span>.</span></figcaption></figure><p>Taste aside, average people don't like fiddling with sliders. Most people want to tap a button and get a photo that looks closer to what they see without thinking about it. So Google and Apple went an extra step in their camera apps.</p><p>Your modern phone's camera first captures a series of photos at various brightness levels, like we showed a moment ago. From this burst of photos, the app calculates an HDR image, but unlike that commercial software from earlier, it uses complex logic and AI to make the tone mapping choices for you.</p><figure><img src="https://www.lux.camera/content/images/2025/05/Screenshot-2025-05-08-at-09.13.41.png" alt="" loading="lazy" width="2000" height="1007" srcset="https://www.lux.camera/content/images/size/w600/2025/05/Screenshot-2025-05-08-at-09.13.41.png 600w, https://www.lux.camera/content/images/size/w1000/2025/05/Screenshot-2025-05-08-at-09.13.41.png 1000w, https://www.lux.camera/content/images/size/w1600/2025/05/Screenshot-2025-05-08-at-09.13.41.png 1600w, https://www.lux.camera/content/images/size/w2400/2025/05/Screenshot-2025-05-08-at-09.13.41.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>Phil Schiller at the iPhone XS introduction showing off a newer Smart HDR </span></figcaption></figure><p>Apple and Google called this stuff "HDR" because "HDR Construction Followed By Automatic Tone Mapping" doesn't exactly roll off the tongue. But just to be clear, the HDR added to the iPhone in 2010<strong> was not HDR</strong>. The final JPEG was an SDR image that tries to replicate what you saw with your eyes. Maybe they should have called it "Fake HDR Mode."</p><p>I know quibbling over names feels as pedantic as going, "Well actually, 'Frankenstein' was the doctor, you're thinking of 'Frankenstein's Monster,'" but if you're going to say you hate HDR, remember that it's <em>bad</em> <em>tone mapping</em> that is the actual monster. That brings us to…</p><h3 id="the-first-hdr-backlash">The First HDR Backlash</h3><p>Over the years, Apple touted better and better algorithms in their camera, like Smart HDR and Deep Fusion. As this happened, we worried that our flagship photography app, Halide, would become irrelevant. Who needs a manual controls when AI can do a better job?</p><p>We were surprised to watch the opposite play out. As phone cameras got smarter, users asked us to turn off these features. One issue was how the algorithms make mistakes, like this weird edge along my son Ethan's face.</p><figure><img src="https://www.lux.camera/content/images/2025/04/image-2.png" alt="" loading="lazy" width="1462" height="1570" srcset="https://www.lux.camera/content/images/size/w600/2025/04/image-2.png 600w, https://www.lux.camera/content/images/size/w1000/2025/04/image-2.png 1000w, https://www.lux.camera/content/images/2025/04/image-2.png 1462w" sizes="(min-width: 720px) 720px"><figcaption><span>When life gives you lemons, you... eat them.</span></figcaption></figure><p>That's because Smart HDR and Deep Fusion require that the iPhone camera capture a burst of photos and stitch them together to preserve the best parts. Sometimes it goofs. Even when the algorithms behave, they come with tradeoffs.</p><p>Consider these photos I took from a boat in the Galapagos: the ProRAW version, which uses multi-photo algorithms, looks smudgier than the single-shot capture I took moments later.</p><figure><div><p><img src="https://www.lux.camera/content/images/2025/05/Untitled-1.jpeg" width="1008" height="1344" loading="lazy" alt="" srcset="https://www.lux.camera/content/images/size/w600/2025/05/Untitled-1.jpeg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/Untitled-1.jpeg 1000w, https://www.lux.camera/content/images/2025/05/Untitled-1.jpeg 1008w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.lux.camera/content/images/2025/05/galapagos-native.jpeg" width="1008" height="1344" loading="lazy" alt="" srcset="https://www.lux.camera/content/images/size/w600/2025/05/galapagos-native.jpeg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/galapagos-native.jpeg 1000w, https://www.lux.camera/content/images/2025/05/galapagos-native.jpeg 1008w" sizes="(min-width: 720px) 720px"></p></div><figcaption><p><span>Left: Merged from Multiple Photos. Right: A single exposure.</span></p></figcaption></figure><p>What's likely happening? When things move in the middle of a burst capture— which always happens when shooting handheld— these algorithms have to nudge pixels around to make things line up. This sacrifices detail.</p><p>Since 2020, we've offered users the option of disabling Smart HDR and Deep Fusion, and it quickly became one of our most popular features.</p><figure><img src="https://www.lux.camera/content/images/2025/05/Disabled_SmarterProcessing.png" alt="" loading="lazy" width="1350" height="718" srcset="https://www.lux.camera/content/images/size/w600/2025/05/Disabled_SmarterProcessing.png 600w, https://www.lux.camera/content/images/size/w1000/2025/05/Disabled_SmarterProcessing.png 1000w, https://www.lux.camera/content/images/2025/05/Disabled_SmarterProcessing.png 1350w" sizes="(min-width: 720px) 720px"></figure><p>This lead us to Process Zero, our completely AI-free camera mode, which we launched last year and became a <a href="https://www.theverge.com/2024/8/18/24222043/halide-process-zero-google-gemini-podcast-installer" rel="noreferrer">smash</a> <a href="https://www.digitaltrends.com/mobile/how-halide-process-zero-changed-my-iphone-camera-forever/" rel="noreferrer">hit</a>. However, without any algorithms, HDR scene end up over and under exposed. Some people actually prefer the look — more on that later — but many were bummed. They just accepted this as a tradeoff for the natural aesthetic of AI-free photos.</p><p>But what if we don't need that tradeoff? What if I told you that analog photographers captured HDR as far back as 1857?</p><figure><img src="https://collectionapi.metmuseum.org/api/collection/v1/iiif/261941/619287/main-image" alt="[The Great Wave, Sète], Gustave Le Gray (French, 1820–1884), Albumen silver print from glass negative " loading="lazy" width="1200" height="974"><figcaption><span>The Great Wave by Gustave Le Gray, </span><a href="https://www.metmuseum.org/art/collection/search/261941" rel="noreferrer"><span>via The Met</span></a></figcaption></figure><p>Ansel Adams, one of the most revered photographers of the 20th century, was a <em>master</em> at capturing dramatic, high dynamic range scenes.</p><figure><img src="https://www.lux.camera/content/images/2025/05/Adams_The_Tetons_and_the_Snake_River.jpg" alt="" loading="lazy" width="1920" height="1537" srcset="https://www.lux.camera/content/images/size/w600/2025/05/Adams_The_Tetons_and_the_Snake_River.jpg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/Adams_The_Tetons_and_the_Snake_River.jpg 1000w, https://www.lux.camera/content/images/size/w1600/2025/05/Adams_The_Tetons_and_the_Snake_River.jpg 1600w, https://www.lux.camera/content/images/2025/05/Adams_The_Tetons_and_the_Snake_River.jpg 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>The Tetons and the Snake River </span><a href="https://en.wikipedia.org/wiki/The_Tetons_and_the_Snake_River" rel="noreferrer"><span>via Wikipedia</span></a></figcaption></figure><p>It's even more incredible that this was done on paper, which has even less dynamic range than computer screens!</p><p>From studying these analog methods, we've arrived at a single-shot process for handling HDR.</p><figure><img src="https://www.lux.camera/content/images/2025/03/new-york-skyline-good-hdr-2.jpeg" alt="" loading="lazy" width="2000" height="1500" srcset="https://www.lux.camera/content/images/size/w600/2025/03/new-york-skyline-good-hdr-2.jpeg 600w, https://www.lux.camera/content/images/size/w1000/2025/03/new-york-skyline-good-hdr-2.jpeg 1000w, https://www.lux.camera/content/images/size/w1600/2025/03/new-york-skyline-good-hdr-2.jpeg 1600w, https://www.lux.camera/content/images/size/w2400/2025/03/new-york-skyline-good-hdr-2.jpeg 2400w" sizes="(min-width: 1200px) 1200px"><figcaption><span>Halide's new, optional tone-mapping.</span></figcaption></figure><p>How do we accomplish this from a single capture? Let's step back in time.</p><h3 id="learning-from-analog">Learning From Analog</h3><p>In the age of film negatives, photography was a three step process. </p><ol><li>Capture a scene on film</li><li>Develop the film in a lab</li><li>Transfer the film to paper</li></ol><p>It's important to break down these steps because— plot twist— film is actually a high dynamic range medium. You just lose the dynamic range when you transfer your photo from a negative to paper. So in the age before Photoshop, master photographers would "dodge and burn" photos to preserve details during the transfer. </p><figure><img src="https://www.lux.camera/content/images/2025/03/image-1.png" alt="" loading="lazy" width="1848" height="1126" srcset="https://www.lux.camera/content/images/size/w600/2025/03/image-1.png 600w, https://www.lux.camera/content/images/size/w1000/2025/03/image-1.png 1000w, https://www.lux.camera/content/images/size/w1600/2025/03/image-1.png 1600w, https://www.lux.camera/content/images/2025/03/image-1.png 1848w" sizes="(min-width: 720px) 720px"><figcaption><span>An excerpt from </span><i><em>The Print</em></i><span>, the Ansel Adams Photography Series 3</span></figcaption></figure><figure><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Clearing_Winter_Storm%2C_Yosemite_Valley.jpg/2880px-Clearing_Winter_Storm%2C_Yosemite_Valley.jpg" alt="undefined" loading="lazy" width="1412" height="1120"><figcaption><span>"Clearing Winter Storm, Yosemite National Park" </span><a href="https://en.wikipedia.org/wiki/Clearing_Winter_Storm,_Yosemite_National_Park" rel="noreferrer"><span>Via Wikipedia</span></a><span>.</span></figcaption></figure><p>Is it a lie to dodge and burn a photo? According to Ansel Adams in <em>The Print</em>:</p><blockquote>When you are making a fine print you are creating, as well as re-creating. The final image you achieve will, to quote Alfred Stieglitz, reveal what you saw and felt.</blockquote><p>I'm inclined to agree. I don't think people reject processing your photos, whether it's dodging-and-burning a print, or fiddling with multi-exposure algorithms. The problem is that <strong>algorithms are not artists</strong>. </p><p>AI cannot read your mind, so it cannot honor your intent. For example, in this shot, I <em>wanted</em> stark contrast between light and dark. AI thought it was doing me a favor by pulling out detail in the shadow, flattening the whole image in the process. Thanks <a href="https://en.wikipedia.org/wiki/Office_Assistant" rel="noreferrer">Clippy</a>.</p><figure><div><p><img src="https://www.lux.camera/content/images/2025/05/463962896_919167870076255_8521404512461066232_n.jpg" width="1440" height="1920" loading="lazy" alt="" srcset="https://www.lux.camera/content/images/size/w600/2025/05/463962896_919167870076255_8521404512461066232_n.jpg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/463962896_919167870076255_8521404512461066232_n.jpg 1000w, https://www.lux.camera/content/images/2025/05/463962896_919167870076255_8521404512461066232_n.jpg 1440w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.lux.camera/content/images/2025/05/464250428_1612875326106791_439563724822943641_n.jpg" width="612" height="917" loading="lazy" alt="" srcset="https://www.lux.camera/content/images/size/w600/2025/05/464250428_1612875326106791_439563724822943641_n.jpg 600w, https://www.lux.camera/content/images/2025/05/464250428_1612875326106791_439563724822943641_n.jpg 612w"></p></div><figcaption><p><span>Same lighting, moments apart. Left: Process Zero. Right: the iPhone camera's automatic tone mapping.</span></p></figcaption></figure><p>Even when tone mapping can help a photo, AI may take things too far, creating hyper-realistic images that exist in an uncanny valley. Machines cannot reason their way to your vision, or even good taste. </p><p>We think there's room for a different approach.</p><h3 id="a-different-approach-opt-in-single-shot-tone-mapping">A Different Approach: Opt-In, Single Shot Tone Mapping</h3><p>After considerable research, experimentation, trial and error, we've arrived on a tone mapper that feels true to the dodging and burning of analog photography. What makes it unique? For starters, it's derived from a single capture, as opposed to the multi-exposure approaches that sacrifice detail. While a single capture can't reach the dynamic range of human vision, good sensors have dynamic range approaching film.</p><p>However, the best feature is that this tone mapping is <strong>off by default. </strong>If you come across a photo that feels like it could use a little highlight or shadow recovery, you can now hop into Halide's updated Image Lab. </p><figure data-kg-thumbnail="https://www.lux.camera/content/media/2025/05/skyline-edit-trimmed_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://www.lux.camera/content/media/2025/05/skyline-edit-trimmed.mp4" poster="https://img.spacergif.org/v1/708x1280/0a/spacer.png" width="708" height="1280" loop="" autoplay="" muted="" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:08</span>
                        </p>
                        </div>
            </div>
            
        <img src="https://www.lux.camera/content/media/2025/05/skyline-edit-trimmed_thumb.jpg"></figure><p>In the Image Lab we have an exposure slider for adjusting overall brightness just like before. But to its right, we have a single dial that tames or boosts dynamic range. We think it's up to the photographer to decide what feels right.</p><p>To be clear, the tone mapper works different than simply bringing your photo into an editor and dragging the "shadows" and "highlights" sliders. It also does it best to preserve local contrast.</p><figure><div><p><img src="https://www.lux.camera/content/images/2025/05/venice-original.jpeg" width="2000" height="1500" loading="lazy" alt="" srcset="https://www.lux.camera/content/images/size/w600/2025/05/venice-original.jpeg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/venice-original.jpeg 1000w, https://www.lux.camera/content/images/size/w1600/2025/05/venice-original.jpeg 1600w, https://www.lux.camera/content/images/2025/05/venice-original.jpeg 2016w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.lux.camera/content/images/2025/05/venice-exposure-increased.jpeg" width="2000" height="1500" loading="lazy" alt="" srcset="https://www.lux.camera/content/images/size/w600/2025/05/venice-exposure-increased.jpeg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/venice-exposure-increased.jpeg 1000w, https://www.lux.camera/content/images/size/w1600/2025/05/venice-exposure-increased.jpeg 1600w, https://www.lux.camera/content/images/2025/05/venice-exposure-increased.jpeg 2016w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.lux.camera/content/images/2025/05/venice-tone-mapped.jpeg" width="2000" height="1500" loading="lazy" alt="" srcset="https://www.lux.camera/content/images/size/w600/2025/05/venice-tone-mapped.jpeg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/venice-tone-mapped.jpeg 1000w, https://www.lux.camera/content/images/size/w1600/2025/05/venice-tone-mapped.jpeg 1600w, https://www.lux.camera/content/images/2025/05/venice-tone-mapped.jpeg 2016w" sizes="(min-width: 720px) 720px"></p></div><figcaption><p><span>Left and Middle: a shot with simple exposure adjustments. Right: a tone-mapped version.</span></p></figcaption></figure><p>Don’t worry: adjusting this stuff after-the-fact won't sacrifice quality. Since Halide captures DNG or "digital negative" files, it contains all of the information that your screen cannot display. The shadow and highlight details are already in there, and the tone-mapping simply brings it out selectively.</p><h2 id="solution-2-genuine-hdr-displays">Solution 2: Genuine HDR Displays</h2><p>I went to all that trouble explaining the difference between HDR and Tone Mapping because… drum roll please… <strong>today's screens are</strong> <strong>HIGH</strong>er <strong>DYNAMIC</strong> <strong>RANGE</strong>!</p><figure data-kg-thumbnail="https://www.lux.camera/content/media/2025/03/new-york-skyline-hdr_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://www.lux.camera/content/media/2025/03/new-york-skyline-hdr.mp4" poster="https://img.spacergif.org/v1/4032x3024/0a/spacer.png" width="4032" height="3024" loop="" autoplay="" muted="" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:10</span>
                        </p>
                        </div>
            </div>
            
        <img src="https://www.lux.camera/content/media/2025/03/new-york-skyline-hdr_thumb.jpg"></figure><figure data-kg-thumbnail="https://www.lux.camera/content/media/2025/05/overthrow-neon-hdr_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://www.lux.camera/content/media/2025/05/overthrow-neon-hdr.mp4" poster="https://img.spacergif.org/v1/3024x4032/0a/spacer.png" width="3024" height="4032" loop="" autoplay="" muted="" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:10</span>
                        </p>
                        </div>
            </div>
            
        <img src="https://www.lux.camera/content/media/2025/05/overthrow-neon-hdr_thumb.jpg"></figure><figure data-kg-thumbnail="https://www.lux.camera/content/media/2025/05/hotel-boston-hdr_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://www.lux.camera/content/media/2025/05/hotel-boston-hdr.mp4" poster="https://img.spacergif.org/v1/3024x4032/0a/spacer.png" width="3024" height="4032" loop="" autoplay="" muted="" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:10</span>
                        </p>
                        </div>
            </div>
            <figcaption><p><span>The atrium of the Hyatt Centric in Cambridge</span></p></figcaption>
        <img src="https://www.lux.camera/content/media/2025/05/hotel-boston-hdr_thumb.jpg"></figure><p>Ok, today's best screens still can't match the high dynamic range of real life, but they're way higher than the past. Spend a few minutes watching Apple TV's mesmerizing screensavers in HDR, and you get why this feels as big as the move from analog TV to HDTV. So… nine years after the introduction of HDR screens, why hasn't the world moved on?</p><p>A big problem is that it costs the TV, Film, and Photography industries billions of dollars (and a bajillion hours of work) to upgrade their infrastructure. For context, it took well over a decade for HDTV to reach critical mass.</p><p>Another issue is taste. Much like adding a spice to your meal, you don't want HDR to overpower everything. The garishness of bad HDR has left many filmmakers lukewarm on the technology. Just recently, cinematographer Steve Yedlin published <a href="https://www.yedlin.net/DebunkingHDR/" rel="noreferrer">a two hour lecture</a> on the pitfalls of HDR in the real world.</p><p>If you want to see how bad HDR displays can get, look no further than online content creators. At some point these thirsty influencers realized that if you make your videos uncomfortably bright, people will pause while swiping through their Instagram reels. The abuse of brightness has lead to people <a href="https://www.reddit.com/r/iPhone15Pro/comments/17r2sf8/hdr_content_is_painfully_bright_and_is_sadly/" rel="noreferrer">disabling HDR altogether</a>.</p><figure><img src="https://www.lux.camera/content/images/2025/03/image-2.png" alt="" loading="lazy" width="1622" height="734" srcset="https://www.lux.camera/content/images/size/w600/2025/03/image-2.png 600w, https://www.lux.camera/content/images/size/w1000/2025/03/image-2.png 1000w, https://www.lux.camera/content/images/size/w1600/2025/03/image-2.png 1600w, https://www.lux.camera/content/images/2025/03/image-2.png 1622w" sizes="(min-width: 720px) 720px"></figure><p>For all these reasons, I think HDR could end up another dead-end technology of the 2010s, alongside 3D televisions. However, Apple turned out to be HDR's best salesperson, as iPhones have captured and rendered HDR photos for years.</p><p>In fact, after we launched Process Zero last year, quite a few users asked us why their photos aren't as bright as the ones produced by Apple's camera. The answer was compatibility, which Apple improved with iOS 18. So HDR is coming to Process Zero!</p><figure><img src="https://www.lux.camera/content/images/2025/05/p0hdr.jpg" alt="" loading="lazy" width="2000" height="1242" srcset="https://www.lux.camera/content/images/size/w600/2025/05/p0hdr.jpg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/p0hdr.jpg 1000w, https://www.lux.camera/content/images/size/w1600/2025/05/p0hdr.jpg 1600w, https://www.lux.camera/content/images/2025/05/p0hdr.jpg 2000w" sizes="(min-width: 720px) 720px"></figure><p>To handle the taste problem, we're offering three levels of HDR:</p><ul><li><strong>Standard</strong>: increases detail in shadows, and bumps up highlights while giving a tasteful rolloff in highlights</li><li><strong>Max:</strong> HDR that pushes the limits of the iPhone display</li><li><strong>Off:</strong> turns HDR off altogether. </li></ul><h3 id="compatibility-considerations">Compatibility Considerations</h3><p>Once you've got an amazing HDR photo, you're probably wondering where you can view it, today. The good news is that every iPhone that has shipped for the last several years supports HDR. It just isn't always available.</p><p>As we mentioned earlier, some users turn off HDR because the content hurts their eyes, but even if it's on, it isn't <em>always</em> on. Because HDR consumes more power, iOS turns it off in low-power mode. It also turns it off when using your phone in bright sunlight, so it can pump up SDR as bright as it can go.</p><p>An even bigger issue is where you can share it online. Unfortunately, most web browser can't handle HDR photos. Even if you encode HDR into a JPEG, the browser might butcher the image, either reducing the contrast and making everything look flat, or clipping highlights, which is about as ugly as bad digital camera photos from the 1990s.</p><p>But wait… how did I display these HDR examples? If you look carefully those are short HDR videos that I've set to loop. You might need these kinds of silly hacks to get around browser limitations.</p><p>Until recently, the best way to view HDR was with Instagram's native iPhone app. While Instagram is our users' most popular place to share photos… it's Instagram. Fortunately, things are changing.</p><p>iOS 18 adopted Adobe's approach to HDR, which Apple calls "Adaptive HDR." In this system, your photos contain <em>both</em> SDR and HDR information in a single file. If an app doesn't know what to do with the HDR information, or it can't render HDR, there's an SDR fallback. This stuff even works with JPEGs!</p><figure><img src="https://www.lux.camera/content/images/2025/05/image-3.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://www.lux.camera/content/images/size/w600/2025/05/image-3.png 600w, https://www.lux.camera/content/images/size/w1000/2025/05/image-3.png 1000w, https://www.lux.camera/content/images/size/w1600/2025/05/image-3.png 1600w, https://www.lux.camera/content/images/2025/05/image-3.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>From Apple's </span><a href="https://developer.apple.com/videos/play/wwdc2024/10177/" rel="noreferrer"><span>Adaptive HDR Presentation</span></a></figcaption></figure><p>Browser support is halfway there. Google beat Apple to the punch with their own version of Adaptive HDR they call <a href="https://source.android.com/docs/core/camera/ultra-hdr" rel="noreferrer">Ultra HDR</a>, which Chrome 14 now supports. Safari has <a href="https://bugs.webkit.org/show_bug.cgi?id=282299" rel="noreferrer">added HDR support into its developer preview</a>, then it disabled it, due to bugs within iOS. </p><p>Speaking of iOS bugs, there's a reason we aren't launching the Halide HDR update with today's post: HDR photos sometimes render wrong in Apple's own Photos app! Oddly enough, they render just fine in Instagram and other third-party apps. We've filed a bug report with Apple, but due to how Apple releases software, we doubt we'll see a fix until iOS 19.</p><p>Rather than inundate customer support with angry emails about how photos don't look right in Apple's photos app, we've decided to release HDR support in our Technology Preview beta that we're offering to 1,000 Halide subscribers. Why limit it to 1,000? Apple restricts how many people can sign up for TestFlight, so we want to make sure we stay within our limits. This is the start of our preview of some very exciting big features in Halide which are part of our big Mark III update.</p><p>If this stuff excites you and you want to try it out, go to the Members section in Settings <a href="https://apps.apple.com/us/app/halide-mark-ii-pro-camera/id885697368" rel="noreferrer">right now</a>.</p><figure><img src="https://www.lux.camera/content/images/2025/05/IMG_7647.jpg" alt="" loading="lazy" width="1206" height="1700" srcset="https://www.lux.camera/content/images/size/w600/2025/05/IMG_7647.jpg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/IMG_7647.jpg 1000w, https://www.lux.camera/content/images/2025/05/IMG_7647.jpg 1206w" sizes="(min-width: 720px) 720px"></figure><h2 id="solution-3-embrace-sdr">Solution 3: Embrace SDR</h2><p>As mentioned earlier, some users actually prefer SDR. And that’s OK. I think this about more than just the lo-fi aesthetic, and touches on a paradox of photography. Sometimes a less-realistic photo is more engaging.</p><p>But aren't photos about capturing reality? If that were true, we would all use pinhole cameras, ensuring we capture everything in sharp focus.  If photos were about realism, nobody would shoot black and white film.</p><figure><img src="https://www.lux.camera/content/images/2025/05/000272640006.jpg" alt="" loading="lazy" width="2000" height="3017" srcset="https://www.lux.camera/content/images/size/w600/2025/05/000272640006.jpg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/000272640006.jpg 1000w, https://www.lux.camera/content/images/size/w1600/2025/05/000272640006.jpg 1600w, https://www.lux.camera/content/images/2025/05/000272640006.jpg 2075w" sizes="(min-width: 720px) 720px"><figcaption><span>Shot on Ilford HP5, ƒ/1.4</span></figcaption></figure><p>Consider this HDR photo of my dad.</p><figure data-kg-thumbnail="https://www.lux.camera/content/media/2025/05/Marc-ProRAW-hdr_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://www.lux.camera/content/media/2025/05/Marc-ProRAW-hdr.mp4" poster="https://img.spacergif.org/v1/3024x4032/0a/spacer.png" width="3024" height="4032" loop="" autoplay="" muted="" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:10</span>
                        </p>
                        </div>
            </div>
            <figcaption><p><span>Shot in ProRAW</span></p></figcaption>
        <img src="https://www.lux.camera/content/media/2025/05/Marc-ProRAW-hdr_thumb.jpg"></figure><p>HDR reveals every wrinkle and pore on his face, and the bright whites in his beard draw too much attention. Just as you might use shallow focus to draw attention on your subject, this is one situation where less dynamic range feels better than hyper-realism. Consider the Process Zero version, with HDR disabled.</p><figure><img src="https://www.lux.camera/content/images/2025/05/marc.jpeg" alt="" loading="lazy" width="1128" height="1191" srcset="https://www.lux.camera/content/images/size/w600/2025/05/marc.jpeg 600w, https://www.lux.camera/content/images/size/w1000/2025/05/marc.jpeg 1000w, https://www.lux.camera/content/images/2025/05/marc.jpeg 1128w" sizes="(min-width: 720px) 720px"><figcaption><span>Process Zero, without Tone Mapping</span></figcaption></figure><p>While we have plenty of work before Process Zero achieves all of our ambitions, we think dynamic range is a huge factor in recapturing the beauty of analog photography in the digital age.</p><figure><img src="https://www.lux.camera/content/images/2025/05/image-2.png" alt="" loading="lazy" width="1000" height="1154" srcset="https://www.lux.camera/content/images/size/w600/2025/05/image-2.png 600w, https://www.lux.camera/content/images/2025/05/image-2.png 1000w" sizes="(min-width: 720px) 720px"><figcaption><span>Shot on film.</span></figcaption></figure><p>We think tone mapping is an invaluable tool that dates back hundreds of years. We think HDR displays have amazing potential to create images we've never seen before. We see a future where SDR and HDR live side by side. We want to give you that choice — whether it is tone-mapping, HDR, or any combination thereof. It’s the artists’ choice —&nbsp;and that artist doesn’t have to be an algorithm. </p><p>We think the future of sunsets looks bright.</p>
        </div>
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[E-COM: The $40M USPS project to send email on paper (112 pts)]]></title>
            <link>https://buttondown.com/blog/the-e-com-story</link>
            <guid>43983455</guid>
            <pubDate>Wed, 14 May 2025 11:59:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buttondown.com/blog/the-e-com-story">https://buttondown.com/blog/the-e-com-story</a>, See on <a href="https://news.ycombinator.com/item?id=43983455">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-sentry-component="Prose" data-sentry-source-file="Prose.tsx"><p>Email, for just under three years, came in a blue-and-white envelope from the United States Postal Service.</p><p>Every new technology, it seemed—telegrams, telephones, faxes, and faster delivery services alike—had threatened the Postal Service’s monopoly on delivering the mail.&nbsp;</p><p>This time, the threat seemed existential. A 1982&nbsp;<a href="https://govinfo.library.unt.edu/ota/Ota_4/DATA/1982/8214.PDF">Congressional report predicted</a>&nbsp;that “Two-thirds or more of the mailstream could be handled electronically,” and “the volume of mail is likely to peak in the next 10 years.”</p><p>Good thing the mailmen were ready. The Post Office had landed on a plan to co-opt the email revolution.</p><p>How do you get email to the folks without computers? What if the Post Office printed out email, stamped it, dropped it in folks’ mailboxes along with the rest of their mail, and saved the USPS once and for all?</p><p>And so in 1982 E-COM was born—and, inadvertently, helped coin the term “e-mail.”</p><h2>Mail on the wire</h2><p><img src="https://buttondown.com/next-assets/img/blog/the-e-com-story/image1.png" alt="" title=""></p><p><em>The original study that recommended the USPS start sending email, for everyone.</em></p><p>It all started in 1971, when the Post Office Department was rebranded for the first time in its 179-year history and turned into the United States Postal Service. Through snow, rain, sleet, and gloom, they got nearly 87 billion pieces of mail through that year.</p><p>It’d weathered the elements, and now it needed to weather sweeping technological changes. So among the newly christened USPS’s first acts was to open an Advanced Service department and hire ex-Peace Corps analyst Gene Johnson to run it and decide how mail of the future should look.</p><p>The Postal Service had long adapted by embracing the new. Jeeps in lieu of horses, Zone Improvement Plan (or ZIP, as we’d come to know them) codes to automate mail sorting. The USPS couldn’t beat telegrams for speed, so they embraced them with a Western Union partnership to send&nbsp;<a href="https://www.nytimes.com/1978/03/19/archives/western-unions-monopoly-challenged-western-union-cheers.html">“Mailgrams” next-day through the mail for $2.75</a>&nbsp;(a moderate success, that—incredibly—<a href="https://about.usps.com/postal-bulletin/2006/html/pb22192/pb4a-e_002.html">ran until Western Union terminated telegram service in 2006</a>).</p><p>The next frontier to conquer: Electronic mail.</p><p>“There was billions of billions of billions of pieces [of mail] that were computer-generated,” said Johnson to Devin Leonard in his book “<a href="https://www.amazon.com/Neither-Snow-nor-Rain-History/dp/0802126405">Neither Snow nor Rain: A History of the United States Postal Service</a>.” That gave Johnson an idea. Each of those letters that were currently being created on computers, printed, and mailed, could instead “be sent directly from the computer into the Postal Service and sent out to the post offices for printing and delivering,” he surmised.</p><p>This could be big. Fifty million letters a year big, according to the Postal Service’s projections.</p><p><img src="https://buttondown.com/next-assets/img/blog/the-e-com-story/image8.png" alt="" title=""></p><p><em>A diagram of the USPS’ ideas for how to deliver email—in print, and eventually online</em></p><p>So they went to the drawing board, and designed email on paper. The&nbsp;<a href="https://babel.hathitrust.org/cgi/pt?id=uiug.30112105194135&amp;seq=2">pitch was simple</a>: “We convert your message, up to 2 pages, into hard copy. We fold it and insert it into an envelope. We seal the envelope and put it into the mailstream. Then, we deliver your message anywhere in the continental U.S.”</p><p>E-COM messages could be one or two pages long, with&nbsp;<a href="https://vintageapple.org/pcworld/pdf/PC_World_8406_June_1984.pdf">up to 41 lines of text on the first page</a>&nbsp;and 56 lines on the second. You’d type up the messages, then send them via TTY or IBM 2780/3789 terminals to one of 25 post offices. There, a Sperry Rand Univac 1108 computer system would receive your messages.&nbsp;</p><p>E-COMs could be “Single Address Messages” with a letter for a single recipient, “Common Text Messages” with a single bulk letter intended for multiple recipients, or “Text Insertion Messages” with form letters blended with text to be inserted into the message for an early take on&nbsp;<a href="https://buttondown.com/blog/mail-merge-history">mail merge</a>. The Univac would print your emails, then postal staff would fold them, stuff them in envelopes, and send them on their way.</p><p>The team had this one shot to keep the Post Office afloat. “In the future, the only way the Postal Service will be able to keep its volume rising and finances dependable is through participating in electronic mail services,” read the&nbsp;<a href="https://ota.fas.org/reports/8214.pdf">1979 Annual Report of the Postmaster General</a>.</p><p>And then bureaucracy bit.</p><h2>Email by fiat</h2><p><img src="https://buttondown.com/next-assets/img/blog/the-e-com-story/image3.png" alt="" title=""></p><p><em>The first print use of the word “e-mail” as the FCC worked to stop the Postal Service from sending electronic messages</em></p><p>Optimism prevailed at first. Postmaster General William Bolger suggested charging the price of a stamp—15¢, at the time—per E-COM message, and even thought they could lower the price over time. The team promised two-day delivery, but that too they hoped to reduce to one day with volume.</p><p>And, perhaps, that volume would be easier to hit, imagined the Post Office, if Congress would authorize an expanded monopoly. The Postal Service proposed it should have “monopoly over delivery of hard copy associated with electronic messages,”&nbsp;<a href="https://www.jec.senate.gov/reports/97th%20Congress/The%20Future%20of%20Mail%20Delivery%20in%20the%20United%20States%20(1159).pdf">said Postal Rate Commission chairman Janet Steiger</a>&nbsp;in December 1978, carefully defined so Western Union, say, could still deliver telegrams while the Postal Service could have a monopoly over delivering printed email messages. “The Postal Service intends to stand on its right to be the sole delivery agent for such mail when delivery is in hard-copy form,”&nbsp;<a href="https://apps.dtic.mil/sti/tr/pdf/ADA096447.pdf">noted a Defense Communications report</a>. And it was trialing sending electronic messages itself, without print—expanding its mandate.&nbsp;</p><p>“Postal Service pushes ahead with E-mail,” opined the&nbsp;<a href="https://www.worldradiohistory.com/Archive-Electronics/70s/79/Electronics-1979-06-07.pdf"><em>Electronics</em>&nbsp;journal headline</a>&nbsp;in June of 1979, as the case worked its way through the courts, inadvertently using the phrase “e-mail” for what the Oxford English Dictionary believes is the first time.</p><p>It was not to be, thanks to the FCC. “The FCC interpreted the law as giving it jurisdiction over all forms of electronic communication, including incidental physical delivery.” Thus was averted a postal monopoly on printed emails.</p><p>But legal ambiguity continued to cloud the project. The Postal Rate Commission took 15 months to review E-COM—long enough that standard postage went up 5¢ in the interim. It barred the USPS from operating its own electronic networks, just in case the Post Office decided to deliver messages electronically and in print. And it raised the price on the service to 26¢ for the first page, plus 5¢ for a second page.</p><p>Sending the messages wouldn’t be simple, either. Customers had to register their company with the USPS using Form 5320, pay a $50 annual fee, send a minimum of 200 messages per post office, and “prepay postage for transmitted messages received, processed, and printed for each transmission,”&nbsp;<a href="https://www.govinfo.gov/content/pkg/FR-1981-12-23/pdf/FR-1981-12-23.pdf">dictated the 1981 Federal Register</a>.</p><p><img src="https://buttondown.com/next-assets/img/blog/the-e-com-story/screenshot.png" alt="" title=""></p><p><em>An E-COM-branded computer, handling E-COM mail for the USPS</em></p><p>Yet, at least the system was finally ready to launch. “We are very proud of this milestone in the history of the Postal Service and pleased to share this occasion with you through this message,” wrote Postmaster General William Bolger in the first E-COM on January 4, 1982.</p><p>Within that first year, the post office had delivered&nbsp;<a href="https://www.nalc.org/news/the-postal-record/2023/may-2023/document/E-COM.pdf">3.2 million E-COM messages</a>&nbsp;for 600 customers. Fifteen million messages the following year, 23 million the year after that. It wasn’t the breakout, 40-million-messages-a-year success they’d dreamed of, but the post office was delivering millions of real emails to people’s mailboxes, in print.</p><h2>You’ve got mail</h2><p><img src="https://buttondown.com/next-assets/img/blog/the-e-com-story/image2.jpg" alt="" title=""></p><p><em>An E-COM letter, shared on Twitter/X by</em> <a href="https://x.com/dsward/status/1255106661062258689"><em>Doug Ward</em></a></p><p>“Imagine: if there was some way to increase the impact of your mailings—while decreasing the aggravation,”&nbsp;<a href="https://babel.hathitrust.org/cgi/pt?id=uiug.30112105194135&amp;seq=2">said the Post Office</a>&nbsp;as it promoted its new electronic-message-to-print-mail service.</p><p>Some early adopters braved the challenges and took the Post Office up on its offer. With their official-looking, blue-and-white envelopes, “an E-COM letter carries a lot of weight with recipients,” advertised the USPS. Bank of America used E-COM partly to expedite overdue payment notifications, partly because the envelope “draws attention,” said a bank official.</p><p>Others turned to service providers to overcome the technical and bureaucratic challenges. “A company called CompuServe will let you send a single letter using their interface to E-COM for $1.26,”&nbsp;<a href="https://groups.google.com/g/net.mail/c/Ia3FX3Fobrc/m/TRP-7HEPt7IJ">suggested someone in a Usenet thread</a>. The&nbsp;<a href="https://www.nytimes.com/1982/03/19/business/electronic-mail-s-slow-start.html">New York Times</a>, meanwhile, reported that “so far 70 percent of the messages have come from one company, Western Union Electronic Mail Inc,” two months after the E-COM service launched.</p><p><img src="https://buttondown.com/next-assets/img/blog/the-e-com-story/image6.png" alt="" title=""></p><p><em>An E-COM advertisement from</em> <a href="https://archive.org/details/forbes132octforb/page/142/mode/2up"><em>Forbes Magazine</em></a> <em>on December 19, 1983</em></p><p>And it worked. “The post office printed a hard copy and sent it by carrier. The messages usually arrived the next day,”&nbsp;<a href="https://www.nytimes.com/1999/06/03/technology/l-e-mail-on-paper-989770.html">recalled Seth Steinberg</a>. “I used it to E-mail my parents and other family members.”&nbsp;</p><p>“‘Neither system downtime, line noise nor software bugs’ had stayed the new service from its appointed rounds,”&nbsp;<a href="https://www.nytimes.com/1982/03/19/business/electronic-mail-s-slow-start.html">enthused another customer</a>&nbsp;to the USPS.&nbsp;</p><p>But it worked at an impossibly high cost. Every time a customer spent 26¢ to send those eye-catching blue-and-white envelopes that first year,&nbsp;<a href="https://www.nytimes.com/1983/10/10/business/electronic-mail-controversy.html">the USPS lost an astounding $5.25</a>&nbsp;in printing and delivering them. Volume wasn’t enough to stop the bleeding; the second year, the USPS still lost $1.24 per E-COM it sent. And despite that implicit subsidy, and full-page ads across major magazines, the limitations—no custom font, no letterhead, no return envelopes, and no fewer than 200 recipients per post office—kept early adopters like Shell Oil from using E-COM.</p><p>The one group who loved E-COM? Junk Mailers.</p><p><img src="https://buttondown.com/next-assets/img/blog/the-e-com-story/image5.jpg" alt="" title=""></p><p><em>The vast majority of E-COM messages came from this one sender (via @patg23 on</em> <a href="https://www.stampcommunity.org/topic.asp?TOPIC_ID=81469"><em>Stamp Community</em></a><em>)</em></p><p>Of the 15 million E-COM messages the Postal Service delivered its second year in operation, “between one-half and three-fourths” were sent by Automotive Incentive Development Co., a direct-mail advertiser, according to a&nbsp;<a href="https://www.washingtonpost.com/archive/business/1983/12/04/critics-want-to-stamp-out-e-com-mail/7aed5007-2923-4151-9dbe-d5d5697a1029/">Washington Post investigation</a>. As few as six companies accounted for “well over 70 percent” of E-COM messages sent, said E-COM director Karen Uemoto.</p><p>If E-COM wasn’t worth the trouble for companies like Shell, it clearly was worth it to a tiny handful of companies that valued the credibility that E-COM’s official, blue-and-white envelope lent. “The distinctive look of an E-COM letter carries a lot of weight with recipients,” advertised the USPS, and clearly direct mailers took the hint. Automotive Incentive’s letters were so common, of the less-than-a-dozen surviving E-COM envelopes we could find online, two of them were sent by Automotive Incentive.</p><p>When the best reason to use the service was its eye-catching envelope, the best way to use it was through a third-party service, and the post office was still losing money sending the messages, something was wrong.</p><h2>Goodbye, E-COM. Hello, e-mail.</h2><p><img src="https://buttondown.com/next-assets/img/blog/the-e-com-story/image7.jpg" alt="e-com advertisement from Time Magazine" title=""></p><p><em>Another E-COM advertisement, from</em> <a href="https://magazineproject.org/TIMEvault/1983/1983-05-30/1983-05-30%20page%2043.jpg"><em>Time Magazine</em></a><em>, May 1983</em></p><p>The USPS could change little on its own. Even a price increase had to get approved—and eventually cut—by the Postal Rate Commission. Finally, enough was enough. The USPS Board of Governors decided to “dispose of the E-COM system by sale or lease.” No buyers were forthcoming, so the post office shut E-COM down, sending the last message on September 2, 1985—with a cumulative loss north of $40 million.</p><p>And it was ok. Mail, it turned out, was more popular than ever. Throughout the .com bubble of the ’90’s, first-class mail volume continued to rise, peaking in 2001 at 103 billion pieces. The USPS regained its confidence; "E-mail is not a threat,"&nbsp;<a href="https://www.wired.com/2001/06/neither-rain-nor-hail-nor-e-mail/">USPS spokesperson Susan Brennan told Wired</a>&nbsp;that year. The doomsayers, at least momentarily, were wrong (though eventually would be proven right, as mail volume has fallen every year since then, to 45 billion pieces in 2023—the lowest volume since 1968).</p><p>E-COM wasn’t the last time the Post Office decided to give email a try. “The Postal Service is, and always has been, one of the most high-tech companies in the world,” insisted Brennan to Wired. There was a plan, during the Clinton administration, for the postal service to give every American an @.us email address. And there was a plan for a&nbsp;<a href="https://www.cccinnovationcenter.com/wp-content/uploads/2017/01/USPS-Presentation.pdf">Digital Postmark</a>, a way to electronically sign emails through the USPS, that ran until 2010 then went quietly into the night. Johnson, even, managed to make the E-COM idea work in the private sector. He started Mail2000 in 1996 to print and mail letters for businesses—then sold it, five years later, to UPS for $100 million.</p><p>We the people were left with the name, e-mail, that over time lost its hyphen and became our universal inbox and digital passport. We were left with emails that’d remind us not to print them out, with one of the few decentralized networked systems that’d survive the internet and social networking. And the Post Office was left to deliver the e-commerce packages we’d ordered online, as email, chat, and push notifications ate away at all the reasons we’d have sent first-class mail in the past.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Cryptography Behind Passkeys (180 pts)]]></title>
            <link>https://blog.trailofbits.com/2025/05/14/the-cryptography-behind-passkeys/</link>
            <guid>43983159</guid>
            <pubDate>Wed, 14 May 2025 11:22:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.trailofbits.com/2025/05/14/the-cryptography-behind-passkeys/">https://blog.trailofbits.com/2025/05/14/the-cryptography-behind-passkeys/</a>, See on <a href="https://news.ycombinator.com/item?id=43983159">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main role="main"><article><div><p>When most people think of cryptography, the first thing they typically think of is encryption: keeping information confidential. But just as important (if not more) is authenticity: ensuring that information is really coming from an authentic source. When you visit a website, the server typically proves its identity through a Transport Layer Security (TLS) certificate authenticated by the Web Public Key Infrastructure (PKI). Passwords are the traditional solution for user authentication, but they suffer from phishing attacks and data breaches. This is where passkeys come in.</p><p>Instead of explaining what passkeys are and why they are better than passwords—<a href="https://www.imperialviolet.org/tourofwebauthn/tourofwebauthn.html">something</a> <a href="https://www.eff.org/deeplinks/2023/10/what-passkey">many</a> <a href="https://fidoalliance.org/passkeys/">other</a> <a href="https://passkeys.dev/">resources</a> have already covered—this post will examine the cryptography behind passkeys, the guarantees they do or do not give, and interesting cryptographic things you can do with them, such as generating cryptographic keys and storing certificates. You need to understand the cryptography behind passkeys to implement secure authentication correctly. We’ll also discuss the main passkey specification, WebAuthn, and show you how to use extensions of passkey mechanisms to build a more intricate system with different capabilities.</p><h2 id="passkey-cryptography-basics">Passkey cryptography basics</h2><p>At their core, passkeys are just key pairs used to produce digital signatures. When registering a passkey, the website saves the public key and an identifier. When authenticating a user via a passkey, the website provides a challenge and waits for a signed response including this challenge (and some other metadata, such as the identifier). The identifier is used to look up the public key, which is used to verify the signature.</p><p>From a cryptographic perspective, this is quite straightforward. The private key authenticates the user, but no sensitive information useful to an attacker is communicated to the server. If the server challenge is properly generated—e.g., as a uniformly random sequence of 32 bytes—then it will prevent replay attacks. Since the server holds only a public key and the user does not send it sensitive information, there is nothing to be leaked in case of a hack.</p><p>But digital signatures alone aren’t enough to solve the phishing problem. If we stopped here with just the cryptographic primitives, users would still be vulnerable. For instance, without additional safeguards, an attacker might trick users into signing challenges for the wrong website or reusing the same key pair across multiple sites.</p><p>This is why passkeys are built on the <a href="https://w3c.github.io/webauthn/">W3C’s WebAuthn</a> specification, which adds crucial security properties beyond the basic cryptography. Let’s look at how WebAuthn transforms these simple cryptographic primitives into a phishing-resistant authentication system.</p><h2 id="webauthn">WebAuthn</h2><p>WebAuthn is the main specification behind passkeys. In simple terms, users access a <strong>website</strong> (relying party) through their <strong>browser</strong> (WebAuthn user agent) on a <strong>device</strong> such as a laptop, phone, or PC (client device). The browser interacts with an <strong>authenticator</strong>, a piece of hardware or software that generates the passkey key pair, and creates digital signatures using this key pair.</p><figure><img src="https://blog.trailofbits.com/img/cryptography_behind_passkeys_image1.png" alt="Simplified view of a passkey authentication flow"><figcaption>Figure 1: Simplified view of a passkey authentication flow.</figcaption></figure><p>In the diagram above, you can see how a passkey authentication works:</p><ol><li>The website requests authentication through the browser.</li><li>The browser communicates with the authenticator.</li><li>The authenticator checks credentials and user presence.</li><li>The authenticator returns a signed response.</li><li>The browser forwards this response to the website for verification.</li></ol><p>(This interaction between browser and authenticator is described in more detail in another specification: the FIDO Alliance’s <a href="https://fidoalliance.org/specs/fido-v2.1-ps-20210615/fido-client-to-authenticator-protocol-v2.1-ps-errata-20220621.html">Client to Authenticator Protocol</a> (CTAP).) This is a simplified description; the WebAuthn specification allows for a larger variety of use cases (e.g., everything could work via a mobile application instead of a website/browser). However, those specifics are not relevant to understanding how passkeys work with cryptography.</p><h2 id="anti-phishing-protections">Anti-phishing protections</h2><p>WebAuthn solves the phishing problem through origin binding. The specification requires browsers to provide the <strong>origin</strong> of the request (i.e., the website domain) to the authenticator. The authenticator in turn uses passkeys only when the website making the request matches the website that created the passkey.</p><p>This means that if you create a passkey for bank.com, a phishing site at fake-bank.com simply cannot use it—your authenticator will refuse the request. Each website also gets its own unique key pair, eliminating the password reuse problem entirely.</p><p>Additionally, the specification allows only origins that use HTTPS, which means that the request comes from a server that has a valid certificate for the corresponding origin.</p><h2 id="types-of-authenticators">Types of authenticators</h2><p>Generally, authenticators are “something you have.” All authenticators can check whether a user is actually present when authenticating. Some authenticators can additionally verify the user according to “something they know,” such as a PIN, or “something they are,” such as their biometrics.</p><p>There are two main types of authenticators you’ll encounter:</p><ul><li><strong>Platform authenticators</strong>: These live inside the user device itself.<ul><li>Examples: iCloud Keychain, Google Password Manager, Windows Hello, 1Password</li><li>Pros: Convenient, often include cloud backup capabilities</li><li>Cons: Vulnerable if the device itself is compromised</li></ul></li><li><strong>Roaming authenticators</strong>: These are separate dedicated hardware devices<ul><li>Examples: YubiKeys, Titan Security Keys, Feitian keys</li><li>Pros: Higher security isolation, not affected by device compromise</li><li>Cons: Can be lost or damaged, typically no backup mechanism</li></ul></li></ul><p>If a platform can do cross-platform communication (such as Bluetooth), its platform authenticators can also be used as roaming authenticators by communicating with another device (e.g., a smartphone<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>). For maximum security in high-value applications, we recommend using dedicated hardware security keys as your authenticators.</p><p>Some authenticators show the user details of the request that it is producing a digital signature for. For authenticators that cannot do this, the browser will display these details instead. Always verify these details before approving an authentication request.</p><p>When a user registers a passkey on a website, the authenticator generates a passkey and an identifier (credential ID). The website stores the public key and the identifier and ties them to the user account. The website can then use this identifier to tell authenticators which passkey they want to access. Some authenticators have a lot of storage, and they store all user passkeys themselves. Other authenticators do not, so they instead encrypt the passkey and provide the encrypted passkey to the website as the identifier during registration. When the website wants to authenticate a user, it provides the identifier to the browser, which in turn provides it to the authenticator, which decrypts it and uses the passkey. Essentially, the website is storing the passkey, but since it is encrypted it is of limited value if the website gets hacked.</p><p>In theory, you can just store a cryptographic key pair in a file, write some software around it that uses this key pair for cryptographic operations, and pretend that it’s an authenticator. But how can websites know whether its users are using secure authenticators? Authenticators can cryptographically prove certain facts about their origins, like who manufactured it, by generating an attestation statement when the user creates a passkey; this statement is backed by a certificate chain signed by the manufacturer. This is especially useful for enterprise users because it allows the enterprise to ensure that all users have specific authenticators that meet some security requirements. However, attestation is optional: the WebAuthn specification does not require authenticators to support it.</p><p>Finally, as with any authentication factor that is “something you have,” an important question is, what happens when you lose it or it breaks? Generally speaking, losing an authenticator means losing all passkeys controlled by it. Since passkeys are essentially randomly generated cryptographic key pairs, there is really no hope of recovery. Most platform authenticators, such as iCloud Keychain, Google Password Manager, and 1Password, allow passkeys to be backed up by synchronizing them to the cloud. However, this is always a trade-off: passkeys that are recoverable have a larger attack surface, in that attackers could try to obtain the passkey through the recovery mechanism. In general, it is important that websites have a recovery mechanism for when users lose access to their passkeys, while keeping in mind that attackers could target this recovery mechanism instead.</p><p>While using platform authenticators with backup capabilities reduces the risk of losing passkeys, it does not eliminate it. Users that get banned from the platform would lose access to their passkeys, and the platform could accidentally delete the passkeys. Furthermore, platforms can also support passkey sharing or family accounts, where multiple users can access the same passkeys. The website should warn users of these risks, depending on what access the passkey provides.</p><h2 id="threat-model">Threat model</h2><p>Despite the marketing claims you might have heard, passkeys aren’t a security silver bullet. Let’s look at what they actually protect against.</p><p>The <a href="https://fidoalliance.org/specs/common-specs/fido-security-ref-v2.1-ps-20220523.html#fido-security-goals">threat model of passkeys</a> shows they protect against threats that passwords typically protect against, while also eliminating the risk of phishing and password reuse. That’s a significant improvement! The <a href="https://w3c.github.io/webauthn/#sctn-conformance">Conformance section</a> of the WebAuthn specification makes a very strong statement implying that websites, browsers, and authenticators that conform to the specification are “secure” against malicious behavior.</p><p>This claim oversimplifies the security reality. Here are real attack scenarios that can still occur:</p><ul><li><strong>Browser-based attacks</strong>: Some authenticators (like a YubiKey 5C) have no built-in display and rely entirely on the browser to show users what site they’re authenticating to. If your browser is compromised by malware or a malicious extension, it could display “attacker.com” to you while actually sending your authenticator a request to sign for “google.com.”</li><li><strong>Compromised authenticators</strong>: The security of passkeys depends on the authenticator protecting private keys. A counterfeit hardware key, backdoored authenticator software, or malware that impersonates your OS’s built-in authenticator could secretly extract your private keys. Think of buying what appears to be a YubiKey from an untrustworthy source—it might be sending copies of your keys to someone else.</li></ul><p>Passkeys do not fully protect against most compromises of user devices, such as malicious browsers or malware. However, they do serve as effective rate limiters for attacks, as each signature requires a separate user interaction with the authenticator. Additionally, passkeys do not protect against attackers that can control the domain of the website, either through a direct takeover or through subdomain hijacking.</p><p>Another thing websites need to account for is credential ID collisions. The specification requires only that they are <a href="https://w3c.github.io/webauthn/#credential-id">probabilistically unique</a>—meaning they’re generated randomly with an extremely low (but non-zero) chance of duplication, similar to UUIDs.</p><p>Why does this matter? When a user registers a passkey, the website stores the credential ID as an identifier for that user’s passkey. If an attacker could somehow register a passkey with the same credential ID as their target victim, they might create authentication confusion.</p><p>This might seem far-fetched, but consider these scenarios:</p><ul><li>An attacker who knows a victim’s credential ID (perhaps captured from network traffic) might try to register their own passkey with that same ID.</li><li>A malicious authenticator app could deliberately generate duplicate credential IDs rather than follow the protocol’s randomness requirements.</li><li>Implementation bugs could reduce the effective randomness of credential ID generation.</li></ul><p>The fix is straightforward: websites should always <a href="https://w3c.github.io/webauthn/#reg-ceremony-assess-trust">reject registration attempts</a> when a new passkey’s credential ID matches one already in the database. This creates a simple “first-come, first-served” protection against credential ID conflicts.</p><h2 id="extensions">Extensions</h2><p>WebAuthn also supports defining extensions for mechanisms used to generate credentials and perform authentication. Basically, a website can request the use of one or more extensions through the WebAuthn API. The browser and authenticator will process these extensions if they support them and ignore unsupported extensions.</p><p>The WebAuthn specification lists some defined extensions, and links to the Internet Assigned Numbers Authority (IANA) registry for definitions of more extensions. These extensions range from enabling backward compatibility with older APIs to supporting completely different cryptographic functionalities. Since this blog post is about cryptography, those latter extensions are the most interesting.</p><p>One such extension is one that the WebAuthn specification calls <code>prf</code> (for pseudorandom function family), which is built on top of the <code>hmac-secret</code> extension defined in the FIDO CTAP v2.1 specification. With the <code>prf</code> extension, the authenticator can calculate HMAC-SHA-256 using a fixed randomly generated 32-byte HMAC key. The input to the HMAC calculation is the SHA-256 digest of a fixed WebAuthn prefix followed by the input provided by the website. While this extension is not flexible enough to implement something like HKDF, it is possible to use it to implement HKDF Extract<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p><p>Another such extension is called <code>largeBlob</code> and prompts supporting authenticators to store a “large blob” of opaque data that the website can read or write during authentication assertions. The website can use this to store any (sensitive) data such as <a href="https://github.com/w3c/webauthn/wiki/Explainer:-WebAuthn-Large-Blob-Extension">certificates or cryptographic keys</a>.</p><p>So using these extensions, it’s possible to derive or store static cryptographic keys. As suggested in the <code>largeBlob</code> example, you might even use this for end-to-end encryption. However, as with all applications of cryptography in the browser setting, it is extremely difficult, if not impossible, to achieve true end-to-end security. Typically, this requires the system to be resistant against a malicious server. Web cryptography runs on JavaScript served by a server, which means that a malicious server can just serve malicious JavaScript that extracts keys, sends decrypted messages back to the server, and so on. Even worse, a malicious server can do this in a highly targeted manner, serving correct JavaScript to most users but malicious JavaScript to a specific target user. Implementing <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Subresource_Integrity">subresource integrity</a> for code on the web (e.g., <a href="https://engineering.fb.com/2022/03/10/security/code-verify/">storing the hash of all published versions with a trusted third party</a>) and <a href="https://binary.transparency.dev/">binary transparency</a> techniques (e.g., a publicly verifiable, tamper-evident log) are two promising solutions to this kind of problem.</p><p>Additionally, it is important to note that the specification considers all extensions optional, which means that there is no guarantee that browsers and authenticators support them. Websites need to check whether extensions are available when requiring specific extensions or else users will have problems accessing their services. In the future, all major browsers and authenticators will hopefully support them, which could improve key management for cryptography on the web.</p><p>In general the specification is in active development, and there is room for many more interesting extensions. Possible extensions include additional cryptographic primitives (such as more advanced signature schemes and zero-knowledge proofs), but monotonic counters would be an interesting extension. While this is not directly a cryptographic feature, monotic counters could be used to protect external storage—such as <a href="https://eprint.iacr.org/2024/989">end-to-end encrypted cloud storage</a>—from rollback attacks.</p><h2 id="the-path-forward-for-passkeys">The path forward for passkeys</h2><p>The time to adopt passkeys is now. The cryptographic foundations of passkeys provide strong security guarantees that make them the clear default choice for modern authentication systems when properly implemented with WebAuthn. While not a perfect security solution, passkeys eliminate many critical vulnerabilities that have plagued passwords for decades: passkeys never transmit sensitive information to servers, cannot be reused across sites, and resist phishing through origin binding.</p><p>Here’s our advice for users and developers:</p><ul><li><p>Users should adopt passkeys and developers should support them wherever possible. Hardware security keys offer the strongest protection for high-value applications, whereas platform authenticators typically provide better user experience and backup capabilities. When authenticating on untrusted devices, use passkeys from a separate device with its own display to verify the authentication requests.</p></li><li><p>Developers should implement account recovery mechanisms, as passkeys are cryptographic key pairs that cannot be reconstructed if lost. Even platform authenticators with backup capabilities carry risks users should understand.</p></li></ul><p>Passkeys can serve as the first authentication factor, a <a href="https://blog.trailofbits.com/2019/06/20/getting-2fa-right-in-2019/">second authentication factor</a>, or even <a href="https://w3c.github.io/webauthn/#sctn-authentication-factor-capability">multiple authentication factors</a>. However, developers need to consider passkeys within their broader <a href="https://blog.trailofbits.com/2025/02/28/threat-modeling-the-trail-of-bits-way/">threat model</a>. For protection from a malicious server—such as in E2EE applications—implement subresource integrity and binary transparency techniques. As WebAuthn evolves, new extensions will enable more cryptographic applications, though support varies across browsers and authenticators.</p><p>If you’re implementing passkeys or exploring novel uses of WebAuthn extensions, <a href="https://www.trailofbits.com/contact/">contact us</a> to evaluate your design and implementation and help protect your users.</p></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Databricks and Neon (295 pts)]]></title>
            <link>https://www.databricks.com/blog/databricks-neon</link>
            <guid>43982777</guid>
            <pubDate>Wed, 14 May 2025 10:10:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.databricks.com/blog/databricks-neon">https://www.databricks.com/blog/databricks-neon</a>, See on <a href="https://news.ycombinator.com/item?id=43982777">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today, we are excited to announce that we have agreed to acquire <a data-external-link="true" href="https://neon.tech/" target="_blank" rel="noopener noreferrer">Neon</a>, a developer-first, serverless Postgres company. Neon’s co-founders are among the very few people in the world who could re-architect Postgres with true separation of storage and compute, built for modern developers and AI systems. Their world-class team of Postgres hackers and database veterans will join Databricks to deliver serverless Postgres at production scale to developers in an AI-native world.</p>

<h2>A developer-first mission, born from Postgres expertise</h2>

<p>Four years ago, the Neon co-founders joined together with a vision to disrupt the database industry. They observed that the foundations of database technologies were largely designed for the 90s era. Their goal was to build a new database platform that would dramatically improve experiences for developers, in some fundamental ways:</p>

<ol>
	<li>They foresaw that Postgres would become the de facto standard for databases and had the vision to create a serverless Postgres platform.</li>
	<li>They were determined to make it possible to create a new Postgres instance in seconds, so developers wouldn’t need to wait.&nbsp;</li>
	<li>They set out to simplify the operational aspect of database scaling by automating it as load changed, so developers could start very small and not worry about over- or under-provisioning.</li>
	<li>They wanted to enable rapid experimentation and testing by supporting instant forking and branching of databases and creating fully isolated databases, as databases are often one of the most difficult modules to test in end-to-end application testing.</li>
</ol>

<p>A few years in, the Neon team engineered a new, innovative database architecture that decouples storage scaling from compute scaling, which ultimately enabled all of the above goals. When Neon first launched, developers raved about the speed, the simplicity, and the ability to branch and fork their databases like Git does for code.</p>

<h2>The shift toward AI agents</h2>

<p>As Neon became GA last year, they noticed an interesting stat: 30% of the databases were created by AI agents, not humans. When they looked at their stats again recently, the number went from 30% to over 80%. That is, <strong>AI agents were creating 4 times more databases versus humans</strong>.</p>

<p><img alt="database instance creation agent vs human" data-entity-type="" data-entity-uuid="" src="https://www.databricks.com/sites/default/files/inline-images/FINAL.png?v=1747198987" data-ot-ignore="1"></p>

<p>If you think of AI agents as your own massive team of high-speed junior developers (potentially “mentored” by senior developers), it’s then not surprising that the same capabilities the Neon team focused on that made Neon great for developers also made Neon great for these AI agents:</p>

<ol>
	<li><strong>Postgres open source ecosystem</strong>: All frontier LLMs have been trained on the vast amount of public information available about the Postgres open source ecosystem, so all AI agents are experts in using Neon, which is built on Postgres.</li>
	<li><strong>Speed</strong>: Traditional databases were designed for humans to provision and operate. It was OK to take minutes to spin up a database. Given AI agents operate at machine speed, ultra rapid provisioning time becomes critical.</li>
	<li><strong>Elastic scaling and pricing: </strong>The decoupled storage from compute serverless architecture enables extremely low-cost Postgres instances. It’s now possible to launch thousands or even millions of agents with their own databases cost-effectively.</li>
	<li><strong>Branching and forking</strong>: AI agents can be non-deterministic, and “vibes” need to be checked and verified. Neon’s ability to instantly create a full copy of a database, not only for schema but also for the data, allows all these AI agents to be operating on their own isolated database instance in high fidelity for experimentation and validation.</li>
</ol>

<h2>Shared DNA</h2>

<p>We have long known Nikita Shamgunov, Heikki Linnakangas, and Stas Kelvich – the founders of Neon. Before Neon, Nikita started his career working on SQL Server and later became well-known in the database community as a co-founder and CEO of SingleStore, driving the startup’s business to over $100M in annual revenue. Heikki has been a committer on Postgres for two decades - he started his Postgres journey when he was bored on paternity leave and decided to look into Postgres internals for fun. Stas is an ex-physicist who got into Postgres hacking because he needed a better R-tree implementation for his tourism search engine startup.</p>

<p>Databricks and Neon share the same DNA in building hardcore technical innovations at the infrastructure layer. We also share the belief in the importance of open source: we originally started the Apache Spark™ project at UC Berkeley, which also happens to be the original birthplace of Postgres, the open source database project Neon builds on.</p>

<h2>Looking forward</h2>

<p>OLTP databases represent a $100B market dominated by products that were built decades ago. We believe it is time for this market to be disrupted by developers and AI agents. Together with the Neon team, we look forward to building the most developer and AI agent friendly database platform.</p>

<p>What does this mean for existing Neon customers and partners? We are fully committed to the future of the Neon platform. The roadmap remains ambitious, and we intend to continue making Neon the best database platform for developers. After closing, existing customers and partners can expect continued support and innovation – now with the full backing and resources of Databricks. It’s a great moment for existing Neon users, and an exciting one for developers just discovering Neon. Go launch a new Postgres instance on <a data-external-link="true" href="http://neon.tech/" target="_blank" rel="noopener noreferrer">Neon</a> today!</p>

<p>We’re equally excited about what this will mean for Databricks’ enterprise customers. We plan to share much more at the upcoming <a data-external-link="true" href="https://www.databricks.com/dataaisummit" target="_blank" rel="noopener noreferrer">Data + AI Summit</a> in San Francisco, June 9–12.</p>

<p>Check out Neon’s <a data-external-link="true" href="http://neon.tech/blog/neon-and-databricks" target="_blank" rel="noopener noreferrer">blog</a> to hear directly from them about why they’re excited to join forces.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[$20K Bounty Offered for Optimizing Rust Code in Rav1d AV1 Decoder (102 pts)]]></title>
            <link>https://www.memorysafety.org/blog/rav1d-perf-bounty/</link>
            <guid>43982238</guid>
            <pubDate>Wed, 14 May 2025 08:32:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.memorysafety.org/blog/rav1d-perf-bounty/">https://www.memorysafety.org/blog/rav1d-perf-bounty/</a>, See on <a href="https://news.ycombinator.com/item?id=43982238">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><p>Josh Aas<br>May 14, 2025</p></header><article><p>In March of 2023 we <a href="https://www.memorysafety.org/blog/safer-av1-decoder/">announced</a> that we were starting work on a safer high performance AV1 decoder called <a href="https://github.com/memorysafety/rav1d">rav1d</a>, written in Rust. We partnered with <a href="https://immunant.com/">Immunant</a> to do the engineering work. By September of 2024 rav1d was basically complete and we <a href="https://www.memorysafety.org/blog/porting-c-to-rust-for-av1/">learned a lot</a> during the process. Today rav1d works well—it passes all the same tests as the dav1d decoder it is based on, which is written in C. It’s possible to build and run Chromium with it.</p><p>There’s just one problem—it’s not quite as fast as the C version. We want to change that and we need your help.</p><p>Our Rust-based rav1d decoder is currently about 5% slower than the C-based dav1d decoder (the exact amount differs a bit depending on the benchmark, input, and platform). This is enough of a difference to be a problem for potential adopters, and, frankly, it just bothers us. The development team worked hard to get it to performance parity. We brought in a couple of other contractors who have experience with optimizing things like this. We <a href="https://www.memorysafety.org/blog/rav1d-performance-optimization/">wrote about the optimization work we did</a>. However, we were still unable to get to performance parity and, to be frank again, we aren’t really sure what to do next.</p><p>After racking our brains for options, we decided to offer a bounty pool of $20,000 for getting rav1d to performance parity with dav1d. Hopefully folks out there can help get rav1d performance advanced to where it needs to be, and ideally we and the Rust community will also learn something about how Rust performance stacks up against C.</p><p>The <a href="https://www.memorysafety.org/rav1d-bounty-official-rules/">official rules are here</a>, but to summarize:</p><ol><li>The contest is open to individuals or teams of individuals who are legal residents or citizens of the United States, United Kingdom, European Union, European Economic Area, Switzerland, Canada, New Zealand, or Australia.</li><li>The rules provide instructions for benchmarking performance improvements.</li><li>You work on improving performance. Your improvements can be in rav1d, the Rust compiler, or the Rust standard library.</li><li>The dav1d and rav1d decoders share the exact same low-level assembly code optimizations—you cannot modify this assembly. You must improve the Rust code (or the Rust compiler), which is what differs between dav1d and rav1d. You may not introduce code into rav1d in a language other than Rust. We encourage you to ask questions early on in issues or by <a href="mailto:hello@memorysafety.org">emailing us</a> so as to avoid investing heavily in something that might not be eligible!</li><li>Get your performance improvements merged into the relevant project per the project's standard contribution process and under its open source license(s), then email us per the instructions in the <a href="https://www.memorysafety.org/rav1d-bounty-official-rules/">official rules</a> to enter and potentially be rewarded for your contribution.</li><li>When the contest ends (likely either because we met our goal or time has run out) we will, at our discretion, divide the bounty proportionally between the largest contributors to performance gains.</li></ol><p>At the end of the day, we reserve the right to award the money to the person(s) or team(s) that we deem to have helped us reach or exceed performance parity in the best possible way.</p><p>If we update the rules we'll post a note here and on the official rules page.</p><p>Good luck! Have fun!</p><p><strong>2025.05.14 Notice:</strong> European Economic Area and Switzerland added to the list of places in which legal residents or citizens are eligible.</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Build a Smartwatch: Picking a Chip (238 pts)]]></title>
            <link>https://ericmigi.com/blog/how-to-build-a-smartwatch-picking-a-chip/</link>
            <guid>43981680</guid>
            <pubDate>Wed, 14 May 2025 07:02:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ericmigi.com/blog/how-to-build-a-smartwatch-picking-a-chip/">https://ericmigi.com/blog/how-to-build-a-smartwatch-picking-a-chip/</a>, See on <a href="https://news.ycombinator.com/item?id=43981680">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><iframe width="560" height="315" src="https://www.youtube.com/embed/umQ39BhcyMM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><p>Full video of this post is up on my podcast on <a href="https://youtu.be/umQ39BhcyMM">YouTube</a>! Subscribe on <a href="https://pca.st/m2aheg1u">PocketCasts</a>, <a href="https://creators.spotify.com/pod/show/tick-talk-w-eric">Spotify</a>, or <a href="https://podcasts.apple.com/us/podcast/tick-talk-w-eric-migicovsky/id1812362079">Apple Podcasts</a>.  </p><p><strong>TLDR:</strong></p><ul><li>We've selected a chip for Core Time 2 - SF32LB52J. It’s from a company called SiFli, and features an open source SDK.</li><li>I’m writing a series of posts on how to make a smartwatch</li><li>Covering how to pick a chip (today), other hardware and software stuff (later)</li><li>I hope others will use PebbleOS to build interesting new smartwatches and other devices!</li></ul><p>This is the first in a series of posts around the steps you need to take in order to build a smartwatch. I want to show that it's not actually that hard to make a decent one in 2025! Hopefully the work that we're doing to make these <a href="https://store.repebble.com/">new watches</a> will help other folks to build some as well. </p><p>Smartwatches are not and should not be ‘one-size fits all’ devices. I really hope that the open sourcing of PebbleOS might spark someone’s imagination and enable them to build a smartwatch that fits their needs perfectly!</p><p>A smartwatch is a system made up of three main components: </p><ul><li>Watch hardware (this is the actual watch itself)</li><li>Watch software (usually referred to as the firmware or operating system)</li><li>Mobile companion app (iOS and Android app that sends notifications, downloads watchfaces etc)</li></ul><p>As I've mentioned before, designing a consumer electronics product like a smartwatch is an exercise in constraint maximization. You need to identify a target experience goal (”I want a smartwatch with an always-on daylight readable display that lasts for 30 days”), then break that down into features/specifications (”e-paper display”, “Bluetooth LE”, “water resistant”, “$150 retail price”) and then create a design with hardware and software components (”Sharp Memory LCD”, “150mAh lipoly battery”, “FreeRTOS” etc) that meet your specifications and fulfill your goal. </p><p>After almost 20 years of building products, this process comes naturally to me - sometimes unprompted! I can look at any product and picture the exploded view, estimate manufacturing costs, and imagine how its software subsystems fit together. It’s a blessing and a curse!</p><p>You can break down watch hardware into five key systems:</p><ul><li>Microcontroller chip (usually includes Bluetooth radio)</li><li>Display</li><li>Sensors and outputs (tac switches, touch, mics, accelerometer, speakers)</li><li>Other electronic components (chips, passive components, printed circuit board, battery)</li><li>Mechanical structure (watch case, glass, buttons, strap, charge cable)</li></ul><p>Picking components for the latter 3 systems is actually quite straight forward these days. There are lots of good options available at various price points for sensors, batteries, straps, watch cases, mics, etc. Constraint maximization is relatively easy for these, I’ll wrap all these up into one blog post later.</p><p>The two most challenging component decisions that need to be made when designing a smartwatch are selecting:</p><ul><li>a microcontroller and Bluetooth radio (this post)</li><li>a display (future post)</li></ul><h3>The backstory</h3><p>During the first Pebble era, we used STM32F2 microcontrollers (MCU). Why? Because over beers on one Friday evening in 2011 at the <a href="https://hackerdojo.org/">Hacker Dojo</a> a friend of mine, Hugo Fiennes, would NOT stop raving about this relatively new MCU. At the time, I was working on <a href="https://www.tumblr.com/inpulse-blog/222972860/evolution1?source=share">inPulse</a> which used an LPC2103 (8K of RAM!) - he rightly thought that we were in desperate need of an upgrade. </p><p>Honestly, this is 100% typical for me. I think that all the major chip selections I’ve made have come from friends raving about a particular chip. Yes, I have a delightfully eccentric set of friends 😂&nbsp;Thank you Trammell Hudson, TL Lim from Pine64, Peter Barrett and many others for your chats over the years.</p><p>An MCU is the heart of the smartwatch. Think of an MCU as a miniature computer - it contains a CPU, RAM, (usually) flash storage, i/o peripherals and sometimes radios, all within a single tiny integrated circuit. </p><p>You can the specs of the MCUs we used before on this <a href="https://github.com/PebbleA2/wiki/wiki/Watch-Comparison">helpful table</a> - 64-144MHz, 128-256KB RAM. During this era, MCUs didn’t have integrated BT radios, so we used additional chips like TI CC2564 (that model is forever etched in my brain for some reason, probably the pain of finding a decent BT stack to use with it). </p><h3>Why is picking the right MCU so important?</h3><p>Getting back to constraint maximization, the MCU sits at the focal point of the most constrained governing ‘equations’ - software compatibility, power consumption and cost. </p><p>The most interesting and difficult constraint is actually software compatibility. <strong>E</strong>mbedded software is much more fragmented and requirement-specific than computer operating system software. Because computers are not very hard drive space constrained, kernels can be optimized for broader compatibility - Linux contains over 17,000 device drivers. PebbleOS was effectively hardcoded to support MCUs from only one company (STM). Switching to a different brand required writing new peripheral (i2c, SPI, DMA, etc) drivers, adopting a different SDK and (sometimes) build system changes. These changes aren't risky, but they do take time to implement and test. Some MCUs do not easily support FreeRTOS (cough nRF53/54 due to lack of BLE stack).</p><p>Since we are not planning to build hundreds of thousands or millions of watches, software engineering costs cannot be amortized and end up being a significant driver to the total cost of each watch. If a chip is easier to develop software for, one might even consider paying for a higher per-unit cost chip given software development time savings.</p><p>A smartwatch must be connected 24/7 to a phone via Bluetooth, so average power consumption while connected is one of two largest power drains - the other being display.</p><h3>Picking chips for our new watches</h3><p>We decided to use Nordic’s nRF52840 for Core 2 Duo. It’s an older chip, but we were very familiar with it and knew that we could get PebbleOS up and running on it relatively quickly. Initially, we planned to use Nordic’s SoftDevice BLE stack, but thanks to the clever work of Liam (colleague of mine at Pebble and now <a href="http://rebble.io/">Rebble</a> contributor), we switched to using an open source BLE stack called <a href="https://github.com/apache/mynewt-nimble">nimBLE</a>. </p><p>While an nrf52840 is powerful enough for Core 2 Duo, for Core Time 2 we needed an MCU with more RAM and processing power.</p><p>For Core Time 2, we would have liked to stay with Nordic (since we had just spent a bunch of time porting PebbleOS to work with Nordic’s SDK and peripherals) but Nordic’s roadmap in the BLE MCU space was not very inviting. Their new low-end chip, nRF54L15, only has 256k of RAM. The bigger colour display on the Core Time 2 requires more RAM and we wanted some breathing room for new features. Also, it only recently went into mass production, so we don’t have any friends who are using it yet - not too many reviews. Nordic also has a 54H series with 1M of RAM, but the price doubles to $4-5 dollars or more - no 512K RAM option either. CT2 also requires a special interface for its 64 colour MIP display, which 2015-era Pebbles previously used a dedicated FPGA to drive. </p><p>So I was on the hunt for a new chip. I looked at a variety of options like Apollo, BES, and Dialog but couldn’t find anything that fit our needs exactly. One of the biggest stumbling blocks was lack of an open source SDK. One chip from BES looked pretty good but we ran into problems when trying to test it out - there was no open source SDK! No example code. Everything was locked behind an NDA. That wasn’t going to work for us - PebbleOS needs to be open source.</p><p>Luckily, lightning struck. I randomly got an email from the CEO of a smaller Bluetooth chip company called SiFli. We exchanged a few emails over the span of a few hours. It became clear that he was extraordinarily interested in getting his chips to power an open source smartwatch.</p><p>SiFli chips are custom-made to be the primary chip in smartwatches. They power tens of millions of smartwatches already from brands like Redmi, Oppo, Noise and many others. The smallest (!) SiFli chip <a href="https://drive.google.com/file/d/1FV5-n6thM8XkzVQeAap2eJv97sCO_NrG/view?usp=sharing">SF32LB52x</a> has over 512K of SRAM, 16M of PSRAM, has a dedicated MIP peripheral for our display - cutting out the need for a separate FPGA or expensive dedicated display interface chip like Epson.</p><p>It also has a extremely low power consumption profile: ~50uA with BLE connected. Oh and it’s less than $2! They even have several chips with 1 to 2MB SRAM options that we could switch to if necessary.</p><p>Best of all - their SDK is open source on <a href="https://github.com/OpenSiFli">Github</a> and they offered to help port PebbleOS to work on their chips.</p><p>So there you have it. The chip for Core Time 2 will be a SF32LB52J (the 1.8V variant of SF32LB527. That’s going to be etched in my long term memory for sure!</p><p>Next post: how to pick a display…</p><p>SiFli links:</p><ul><li><a href="https://drive.google.com/file/d/1FV5-n6thM8XkzVQeAap2eJv97sCO_NrG/view?usp=sharing">SF32LB52x reference guide</a></li><li><a href="https://github.com/OpenSiFli">https://github.com/OpenSiFli</a></li><li><a href="https://item.taobao.com/item.htm?abbucket=11&amp;detail_redpacket_pop=true&amp;id=913039901152&amp;ltk2=1746962311930er3jpr9z173xe91zr84ps&amp;ns=1&amp;priceTId=undefined&amp;query=%E6%80%9D%E6%BE%88%E7%A7%91%E6%8A%80&amp;skuId=5776328712262&amp;spm=a21n57.1.hoverItem.2&amp;utparam=%7B%22aplus_abtest%22%3A%228935e1d10ee53e64944bb19c4245a174%22%7D&amp;xxc=taobaoSearch">Buy Devkit on Taobao</a> (Aliexpress coming soon)</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wise refuses to let us access our $60k AUD (175 pts)]]></title>
            <link>https://hey.paris/posts/wise/</link>
            <guid>43981582</guid>
            <pubDate>Wed, 14 May 2025 06:46:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hey.paris/posts/wise/">https://hey.paris/posts/wise/</a>, See on <a href="https://news.ycombinator.com/item?id=43981582">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://wise.com/">Wise</a> has stolen more than $60,000 AUD from us, and refuses to let us access it.</p><p><a href="https://secretlab.games/">We’ve</a> had a Wise account for around 5 years (since they were called TransferWise). It’s been a really useful way to transact in foreign currencies, and pay for things when we’re travelling for work.</p><p>In early-April 2025, Wise asked us to provide some additional information on our Ultimate Beneficial Owners (UBOs) by uploading a statement of shareholders, and the ID of the owners. Perfectly reasonable stuff for an entity that pretends to be a bank to ask for.</p><p>In response, in early-April 2025, we uploaded a <a href="https://asic.gov.au/online-services/search-asic-registers/search-fees/">paid ASIC Extract</a> for the business, and scans of the passports of the two UBOs. The message requesting additional information on UBOs went away, and the account continued ticking along.</p><p>On 6 May 2025, with no notice, and with no out of the ordinary or large transactions happening, Wise started declining our card on all transactions, and blocking any ACH/wire transfers out of the account.</p><figure><img loading="lazy" src="https://hey.paris/posts/wise/wise1.png"></figure><p>There is a link on each declined transaction that says offers a way to fix it:</p><figure><img loading="lazy" src="https://hey.paris/posts/wise/wise2.png"></figure><p>Alas, it does not, and has never worked:</p><figure><img loading="lazy" src="https://hey.paris/posts/wise/wise3.png"></figure><p>Every time a transaction declines, we also get an email from Wise:</p><figure><img loading="lazy" src="https://hey.paris/posts/wise/wise4.png"></figure><p>But again, alas, the “Unblock your account” button in this email also goes to an unhelpful page:</p><figure><img loading="lazy" src="https://hey.paris/posts/wise/wise5.png"></figure><p>Lodging a support ticket yields an unhelpful response:</p><figure><img loading="lazy" src="https://hey.paris/posts/wise/wise6.png"></figure><p>And replying makes them more confusing:</p><figure><img loading="lazy" src="https://hey.paris/posts/wise/wise7.png"></figure><p>And then, more confusing still, when they ask for the same documents they already had, again:</p><figure><img loading="lazy" src="https://hey.paris/posts/wise/wise8.png"></figure><p>Calling results in someone in their call centre telling us it’s a “bug” and will be “fixed soon”, or that I need to upload more documents. And when asked what documents, they list the same document we already uploaded (an ASIC Extract). And round and round we go.</p><p>So, we’re out $60,000+ AUD, and Wise refuses to help.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The recently lost file upload feature in the Nextcloud app for Android (370 pts)]]></title>
            <link>https://nextcloud.com/blog/nextcloud-android-file-upload-issue-google/</link>
            <guid>43981170</guid>
            <pubDate>Wed, 14 May 2025 05:38:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nextcloud.com/blog/nextcloud-android-file-upload-issue-google/">https://nextcloud.com/blog/nextcloud-android-file-upload-issue-google/</a>, See on <a href="https://news.ycombinator.com/item?id=43981170">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-rocket-location-hash="29aca9a68567175916075bc4aeb63b17">
						
<p>Dear users,</p>



<p>We are aware that for some months, Nextcloud file uploads for Android users have not been working as expected: you cannot upload all data to your Nextcloud, only photos and videos. We have seen your complaints in various forums such as the Nextcloud <a href="https://help.nextcloud.com/t/unable-to-use-android-upload-due-to-new-google-policy/215499" target="_blank" rel="noreferrer noopener">help forum</a>, on <a href="https://github.com/nextcloud/android/issues/14334" target="_blank" rel="noreferrer noopener">GitHub</a>, <a href="https://www.reddit.com/r/NextCloud/comments/1iaewjm/nextcloud_and_new_google_restrictions/?rdt=64069" target="_blank" rel="noreferrer noopener"><u>Reddit</u></a>, or other <a href="https://www.computerbase.de/forum/threads/google-sabotiert-next-cloud-client-ohne-vorankuendigung.2227335/" target="_blank" rel="noreferrer noopener">forums</a>.</p>



<p>As your experience with the Nextcloud Files app for Android has worsened, we wanted to share the background. Google has revoked a critical permission to sync all files. Despite multiple appeals since mid-2024, Google has refused to reinstate it, forcing us to limit file uploads for millions of users.</p>



<p>The Nextcloud file uploads issue means that some media files, such as pictures and videos, can still be uploaded from Android devices to Nextcloud, but all other files cannot. And that is pretty much beating the purpose.</p>



<p>Google is stating security concerns as a reason for revoking the permission. This is hard to believe for us. Nextcloud has had this feature since its inception in 2016, and we have never heard about any security concerns from Google about it. Moreover, several Big Tech apps as well as Google’s own still have this. What we think: Google owning the platform means they can and are giving themselves preferential treatment.</p>



<p>Despite multiple appeals since mid-2024, Google has refused to reinstate the permission, blocking automated Nextcloud file uploads for millions of users.</p>



<p>To make it crystal clear: All of you as users have a worse Nextcloud Files client because Google wanted that. We understand and share your frustration, but there is nothing we can do.</p>



<p>The more tech-savvy of you are certainly able to use the alternative app store, such as <a href="https://f-droid.org/packages/com.nextcloud.client/" target="_blank" rel="noreferrer noopener">F-Droid</a>. But for our user base of roughly one million users on the app store, this will hardly be an option.</p>



<p>For transparency, we have compiled more background below to help you understand the Nextcloud file upload issue and how Google is abusing its gatekeeper position.</p>



<p>Sincerely, the Nextcloud team</p>


<div>
<figure><img decoding="async" width="257" height="576" src="https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message-257x576.png" alt="" srcset="https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message-257x576.png 257w, https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message-134x300.png 134w, https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message-768x1724.png 768w, https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message-684x1536.png 684w, https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message-912x2048.png 912w, https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message.png 1080w" sizes="(max-width: 257px) 100vw, 257px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20257%20576'%3E%3C/svg%3E" data-lazy-srcset="https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message-257x576.png 257w, https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message-134x300.png 134w, https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message-768x1724.png 768w, https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message-684x1536.png 684w, https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message-912x2048.png 912w, https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message.png 1080w" data-lazy-src="https://nextcloud.com/c/uploads/2025/05/Nextcloud-Google-Playstore-error-message-257x576.png"><figcaption>Error message “Changes to auto upload” from Nextcloud app for Android</figcaption></figure></div>


<h2><strong>What happened</strong> with Nextcloud file uploads for Android?</h2>



<p>The permission for read and write access<em> </em>to all file types for the Nextcloud Files app for Android was granted in 2011. In September 2024, an update of the Nextcloud app for Android was refused out of the blue. We have been asked to remove the permission to all files or use “a more privacy aware replacement” like Storage Access Framework (SAF) or MediaStore API.</p>



<p>SAF cannot be used, as it is for sharing/exposing our files to other apps, so the reviewer clearly misunderstood our app workflow. MediaStore API cannot be used as it does not allow access to other files, but only media files.</p>



<p>Despite multiple appeals from our side and sharing additional background, Google is not considering reinstating uploads for all files. Instead of working collaboratively to solve the issue, we only receive the same copy-and-paste answers or links to documentation. With nearly a million users and an 8-year history, it is hard to argue that our Android app has no credibility. So it is very surprising to get treated this way to the disadvantage of our users.</p>



<p>As we needed to release bug fixes to our users and customers, and there was no other way to discuss, we chose to comply with Google’s new regulations. Google finally accepted our newest update, which limits uploads for our users.</p>



<p>The Android app itself still works with the permission, and we released new versions on the external F-Droid store. So the limit is a “purely” Google Play Store-related problem.</p>



<h2>The bigger picture: Big Tech gatekeeping in action</h2>



<p>This might look like a small technical detail, but it is clearly part of a pattern of actions to fight the competition. What we are experiencing is a piece of the script from the Big Tech playbook.</p>



<p>It is a clear example of Big Tech gatekeeping smaller software vendors, making the products of their competitors worse or unable to provide the same services as the giants themselves sell. As they own the platform, they can — and do — give themselves preferential treatment.</p>



<p>A famous example of this in the past was Microsoft, which blocked certain capabilities from Windows to ensure WordPerfect users had a worse experience than people who picked Microsoft Word. Today, Google creates rules in the name of security that make it hard to <a href="https://nextcloud.com/blog/your-microsoft-teams-alternative-nextcloud-talk-munich-launching-live-at-the-nextcloud-summit/" target="_blank" rel="noreferrer noopener">build products that compete with them</a>.</p>



<p>We suppose Google can’t get away with this versus Apple or Microsoft, as those companies would retaliate. But smaller companies, especially those building disruptive technologies like ours, are fair game for them.</p>



<p>Big Tech is scared that small players like Nextcloud will disrupt them, like they once disrupted other companies. So they try to shut the door.</p>



<p>Then they have an army of underpaid and overworked people who have to ‘handle the complaints’. Clearly, they have either been directed to simply remove this permission from Nextcloud and ignore any complaints, or they are entirely incompetent. Either way, it results in companies like ours just giving up, reducing functionality just to avoid getting kicked out of their app store.</p>



<p>This isn’t an isolated issue. With the EU’s lack of enforcement on Microsoft’s bundling of Teams and OneDrive into Windows, it seems Google feels emboldened to follow suit, further stifling competition and innovation.</p>



<p>The issue is that small companies — like ours — have pretty much no recourse. Legal actions are too expensive, and a complaint to the EU takes too long. Together with about 40 other businesses and organizations, we filed a complaint about similar anti-competitive behavior in 2021. We are now four years in, and nothing has happened. What do you think happens to a company that releases no updates to its app in four years?</p>



<p>The current oversight processes are absolutely useless against these billion-dollar companies. Even the <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_25_1085" target="_blank" rel="noreferrer noopener">fines against Meta and Apple</a> under the Digital Markets Act (DMA) in April 2025 were surprisingly low. Remember, fines can be up to 10% of the company’s total worldwide annual revenue. While fines of €200 million or €500 million, respectively, sound a lot, it could have been in the billions. These Big Tech firms earn that much money in a matter of days, so it amounts to barely a slap on the wrist.</p>



<p>And it took a while. The regulation becomes applicable in May 2023 in the EU to make the markets in the digital sector fairer and more contestable. The first fines were announced almost two years later, which is an immense time span in the digital world, and this is just the first step. The firms will put their lawyers to work and appeal — expect this to take another year or two. The EU really has to step up its game if it is serious about reducing the anti-competitive behavior of Big Tech.</p>


<div data-rocket-location-hash="68e122c6b23b4519e49c5a2a57b5f054" id="summit">
					<p><img decoding="async" src="https://nextcloud.com/c/uploads/2025/01/NC-Summit-logo-animated-once.svg" alt="Nextcloud - Join the Nextcloud Summit 2025" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></p><h2>Join the Nextcloud Summit 2025</h2><p>The digital sovereignty revolution starts here. Join the discussion and hear from industry speakers, thought leaders and key experts. </p>
<p><a href="https://nextcloud.com/summit/?utm_source=hub10post" target="_blank">Register now</a>				</p></div>
						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bus stops here: Shanghai lets riders design their own routes (448 pts)]]></title>
            <link>https://www.sixthtone.com/news/1017072</link>
            <guid>43980845</guid>
            <pubDate>Wed, 14 May 2025 04:33:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sixthtone.com/news/1017072">https://www.sixthtone.com/news/1017072</a>, See on <a href="https://news.ycombinator.com/item?id=43980845">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>From early-morning school drop-offs to seniors booking rides to the hospital, from suburban commuters seeking a faster link to the metro to families visiting ancestral graves, Shanghai is rolling out a new kind of public bus — one that’s designed by commuters, and launched only when enough riders request it.</p><p>Branded “DZ” for <em>dingzhi</em>, or “customized,” the system invites residents to submit proposed routes through a city-run platform. Others with similar travel needs can opt in or vote, and if demand meets the threshold — typically 15 to 20 passengers per trip — the route goes live.</p><p>More than 220 DZ routes have already launched across all 16 city districts. Through an online platform opened May 8, users enter start and end points, preferred times, and trip frequency. If approved, routes can begin running in as little as three days.</p><p>One of the first test cases was DZ301, a pilot route linking a major metro station with surrounding residential blocks, schools, and office buildings. “The average daily passenger flow is 250 to 260 people — 170 to 180 during the morning peak and 70 to 80 in the evening,” Wu Yongming, deputy manager at Jiushi Bus Company,&nbsp;<a href="https://www.thepaper.cn/newsDetail_forward_30436791" target="_blank">told</a>&nbsp;domestic media.</p><p>The route originated from a resident’s request submitted last December. In response, transit staff conducted on-site research, observing foot traffic, speaking with commuters, and calculating turnover times during peak hours. Drivers then ran trial runs to fine-tune the schedule before the route officially launched.</p><p>Chen Xiaohong, a professor at Tongji University’s School of Transportation, said the system builds on Shanghai’s dense transit network to better match capacity with demand, improving both convenience and resource use during peak travel.</p><p>Proposed routes appear on a “Popular Customization” page, where others can opt in to help reach the launch threshold. Group bookings can also fast-track approval. Fares are market-based, and while they follow basic public transit standards, no discounts are currently offered for students, seniors, or other groups.</p><p>Wang Yixiang, deputy director of the city’s Passenger Transport Department,&nbsp;<a href="http://www.sh.xinhuanet.com/20250509/cef13b1418e547ea93ff0ca0767de033/c.html" target="_blank">said</a>&nbsp;the new platform shortens what was once a slow, bureaucratic process for launching new routes. But he acknowledged early challenges: passenger demand is uneven, public awareness remains low, and planning still relies heavily on manual fieldwork.</p><p>“Going forward, we need to improve route planning, upgrade platform functions, and boost visibility,” Wang said.</p><p><em>(Header image: A “DZ” bus arrives at a residential area in Shanghai, 2025. From Weibo)</em></p></div></div>]]></description>
        </item>
    </channel>
</rss>