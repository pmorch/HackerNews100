<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 07 Dec 2023 21:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Making Noisy SVGs (144 pts)]]></title>
            <link>https://daniel.do/article/making-noisy-svgs/</link>
            <guid>38559607</guid>
            <pubDate>Thu, 07 Dec 2023 18:04:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daniel.do/article/making-noisy-svgs/">https://daniel.do/article/making-noisy-svgs/</a>, See on <a href="https://news.ycombinator.com/item?id=38559607">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p><time datetime="2023-11-30">November 30, 2023</time><span>7<!-- --> minute read</span></p><h2 itemprop="headline">Making noisy SVGs</h2><p>Adding noise texture with only code</p></header><p><a href="#addendum-dec-7-2023">Addendum Dec 7, 2023</a></p>
<p>One of my ongoing fixations with the web is how improvements in technology inform web design. In an earlier post this year I <a href="https://daniel.do/article/its-the-future-stop-using-jpegs/#some-background">wrote about my theory</a> that the increasing pixel density of displays galvanized the shift from photography to vector illustrations in the early to mid 2010s.</p>
<p>In recent years there has been a design trend that runs counter to this. Illustrations still rule in web design, but instead of clean, flat shapes there has been an emergence of texture, usually as part of a design’s lighting or shading and <em>usually</em> a “noisy” or grainy texture.</p>
<a href="https://dribbble.com/shots/23092827-Cyber-Security-Portal" target="_blank">
  <img src="https://daniel.do/49c6373f104c02a9f4962e8d68afe8f0/cyber-security-portal-illustration.webp" alt="">
  <cite>Studio Vellekoop &amp; León</cite>
</a>
<p>I’m not hip enough to know if this style has been assigned a pithy label, but I do enjoy it. At the same time, I find it frustrating — because as far as I can tell (the lack of examples I have seen in the wild supports this theory) there isn’t an easy way to replicate these illustrations with SVGs. They can probably be exported as such from illustration programs but it’s likely these applied textures are raster or if they are vector, quite large in size.</p>
<p>SVGs are an interesting subject to me, because the specification for them is dense and there are usually multiple ways to accomplish an effect. Most SVGs are simply exported directly from a graphics program and have a lot of inefficiencies etc… which has led to the emergence of tools like <a href="https://github.com/svg/svgo">SVGO</a>.</p>
<p>I’m not an expert on the subject (I feel like the older I get, the less I feel like I can claim that about anything) but in recent years have taken to hand tuning and occasionally writing my own SVGs from scratch so I am not a complete novice either.</p>
<p>I decided to give creating an SVG using this illustration style a shot. My goal was to use the regular SVG specification to write a simple illustration that had this noisy, textured shadow effect. An additional goal was for this illustration to be moderately flexible, something that could easily be turned into a component in Svelte or React and changed for different shapes and colors. For more direct inspiration, I looked to the designer Josh Warren who has experimented a lot with using this style and simple geometry to nice effect:</p>
<a href="https://dribbble.com/shots/21207219-Interplay" target="_blank">
  <img src="https://daniel.do/1370f375ef9670faf2d9c104b3edc4c0/interplay-illustration.webp" alt="">
  <cite>Josh Warren</cite>
</a>
<hr>
<h2 id="basic-shape-and-gradient"><a href="#basic-shape-and-gradient" aria-label="basic shape and gradient permalink"></a>Basic shape and gradient</h2>
<p>Drawing a circle or square in an SVG is really easy. There are primitives for them.</p>
<div>
<div data-language="html"><pre><code><span><span><span>&lt;</span>svg</span> <span>viewbox</span><span><span>=</span><span>"</span>0 0 100 100<span>"</span></span><span>&gt;</span></span>
	<span><span><span>&lt;</span>circle</span> <span>cx</span><span><span>=</span><span>"</span>50<span>"</span></span> <span>cy</span><span><span>=</span><span>"</span>50<span>"</span></span> <span>r</span><span><span>=</span><span>"</span>50<span>"</span></span> <span>/&gt;</span></span>
<span><span><span>&lt;/</span>svg</span><span>&gt;</span></span></code></pre></div>
<svg viewBox="0 0 100 100">
	<circle cx="50" cy="50" r="50"></circle>
</svg>
</div>
<p>The tricky part is everything else. If you want to apply a gradient, you can specify that as the <code>fill</code> - but what if you want a gradient that changes with the base color you specify? So you don’t have to define a custom gradient with specific colors if you want to reuse the component. Then you’ve entered <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/mask">mask</a> territory. The way masks work in SVGs is that you use the “colors” black and white to how you want a mask to work. It’s a little confusing, but I’ve tried to keep the code example simple.</p>
<p>(As an aside, I have to give huge kudos to MDN’s excellent documentation, this project could not have been done without it!)</p>
<p>This can actually be optimized a little more. We know we’re going to use the same circle shape multiple times, so we can define it once in <code>&lt;defs&gt;</code>, assign it an id and simply reference it with the <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Element/use"><code>use</code></a> element. This makes the code a little more DRY:</p>
<div>
<div data-language="html"><pre><code><span><span><span>&lt;</span>svg</span> <span>viewbox</span><span><span>=</span><span>"</span>0 0 100 100<span>"</span></span><span>&gt;</span></span>
   <span><span><span>&lt;</span>defs</span><span>&gt;</span></span>
 	<span><span><span>&lt;</span>circle</span> <span>id</span><span><span>=</span><span>"</span>shape<span>"</span></span> <span>cx</span><span><span>=</span><span>"</span>50<span>"</span></span> <span>cy</span><span><span>=</span><span>"</span>50<span>"</span></span> <span>r</span><span><span>=</span><span>"</span>50<span>"</span></span> <span>/&gt;</span></span>
   	<span><span><span>&lt;</span>mask</span> <span>id</span><span><span>=</span><span>"</span>gradient<span>"</span></span><span>&gt;</span></span>
   		<span><span><span>&lt;</span>linearGradient</span> <span>id</span><span><span>=</span><span>"</span>fade<span>"</span></span><span>&gt;</span></span>
   			<span><span><span>&lt;</span>stop</span> <span>offset</span><span><span>=</span><span>"</span>0%<span>"</span></span> <span>stop-color</span><span><span>=</span><span>"</span>black<span>"</span></span> <span>stop-opacity</span><span><span>=</span><span>"</span>0.5<span>"</span></span> <span>/&gt;</span></span>
   			<span><span><span>&lt;</span>stop</span> <span>offset</span><span><span>=</span><span>"</span>75%<span>"</span></span> <span>stop-color</span><span><span>=</span><span>"</span>white<span>"</span></span> <span>stop-opacity</span><span><span>=</span><span>"</span>1<span>"</span></span> <span>/&gt;</span></span>
   		<span><span><span>&lt;/</span>linearGradient</span><span>&gt;</span></span>
   		<span><span><span>&lt;</span>use</span> <span>href</span><span><span>=</span><span>"</span>#shape<span>"</span></span> <span>fill</span><span><span>=</span><span>"</span>url('#fade')<span>"</span></span> <span>/&gt;</span></span>
   	<span><span><span>&lt;/</span>mask</span><span>&gt;</span></span>
   <span><span><span>&lt;/</span>defs</span><span>&gt;</span></span>
 <span><span><span>&lt;</span>use</span> <span>href</span><span><span>=</span><span>"</span>#shape<span>"</span></span> <span>mask</span><span><span>=</span><span>"</span>url(#gradient)<span>"</span></span> <span>/&gt;</span></span>
<span><span><span>&lt;/</span>svg</span><span>&gt;</span></span></code></pre></div>
  <svg viewBox="0 0 100 100">
    <defs>
      <circle id="shape" cx="50" cy="50" r="50"></circle>
      <mask id="gradient">
        <linearGradient id="fade">
          <stop offset="0%" stop-color="black" stop-opacity="0.5"></stop>
          <stop offset="75%" stop-color="white" stop-opacity="1"></stop>
        </linearGradient>
        <use href="#shape" fill="url('#fade')"></use>
      </mask>
    </defs>
    <use href="#shape" mask="url(#gradient)"></use>
  </svg>
</div>
<p>So we’ve got the shape and a gradient going, but how do we add a texture to that gradient? The answer is with a filter. <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Tutorial/Filter_effects">MDN’s documentation on SVG Filters</a> goes into better detail on the nuts and bolts of how filters work. I also found this <a href="https://tympanus.net/codrops/2019/02/19/svg-filter-effects-creating-texture-with-feturbulence/">excellent article</a> that goes into great detail about creating textures for SVGs.</p>
<p>To create noise, I used the <code>&lt;feTurbulence&gt;</code> filter which is explicitly for generating artificial textures but required quite a bit of fiddling to get to my liking. Then, I had to use other filter effects to eliminate color variance and blend naturally with the fill color selected, and finally apply the filter to the circle.</p>
<h2 id="result"><a href="#result" aria-label="result permalink"></a>Result</h2>
<div>
<div data-language="html"><pre><code><span><span><span>&lt;</span>svg</span> <span>viewbox</span><span><span>=</span><span>"</span>0 0 100 100<span>"</span></span><span>&gt;</span></span>
	<span><span><span>&lt;</span>defs</span><span>&gt;</span></span>
		<span><span><span>&lt;</span>circle</span> <span>id</span><span><span>=</span><span>"</span>shape<span>"</span></span> <span>cx</span><span><span>=</span><span>"</span>50<span>"</span></span> <span>cy</span><span><span>=</span><span>"</span>50<span>"</span></span> <span>r</span><span><span>=</span><span>"</span>50<span>"</span></span> <span>/&gt;</span></span>
		<span><span><span>&lt;</span>filter</span> <span>id</span><span><span>=</span><span>"</span>noise<span>"</span></span><span>&gt;</span></span>
			<span><span><span>&lt;</span>feTurbulence</span>
				<span>type</span><span><span>=</span><span>"</span>fractalNoise<span>"</span></span>
				<span>baseFrequency</span><span><span>=</span><span>"</span>19.5<span>"</span></span>
				<span>numOctaves</span><span><span>=</span><span>"</span>10<span>"</span></span>
				<span>result</span><span><span>=</span><span>"</span>turbulence<span>"</span></span>
			<span>/&gt;</span></span>
			<span><span><span>&lt;</span>feComposite</span> <span>operator</span><span><span>=</span><span>"</span>in<span>"</span></span> <span>in</span><span><span>=</span><span>"</span>turbulence<span>"</span></span> <span>in2</span><span><span>=</span><span>"</span>SourceAlpha<span>"</span></span> <span>result</span><span><span>=</span><span>"</span>composite<span>"</span></span><span>/&gt;</span></span>
			<span><span><span>&lt;</span>feColorMatrix</span> <span>in</span><span><span>=</span><span>"</span>composite<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>luminanceToAlpha<span>"</span></span> <span>/&gt;</span></span>
			<span><span><span>&lt;</span>feBlend</span> <span>in</span><span><span>=</span><span>"</span>SourceGraphic<span>"</span></span> <span>in2</span><span><span>=</span><span>"</span>composite<span>"</span></span> <span>mode</span><span><span>=</span><span>"</span>color-burn<span>"</span></span> <span>/&gt;</span></span>
		<span><span><span>&lt;/</span>filter</span><span>&gt;</span></span>
		<span><span><span>&lt;</span>mask</span> <span>id</span><span><span>=</span><span>"</span>gradient<span>"</span></span><span>&gt;</span></span>
			<span><span><span>&lt;</span>linearGradient</span> <span>id</span><span><span>=</span><span>"</span>fade<span>"</span></span><span>&gt;</span></span>
				<span><span><span>&lt;</span>stop</span> <span>offset</span><span><span>=</span><span>"</span>0%<span>"</span></span> <span>stop-color</span><span><span>=</span><span>"</span>black<span>"</span></span> <span>stop-opacity</span><span><span>=</span><span>"</span>0.6<span>"</span></span> <span>/&gt;</span></span>
				<span><span><span>&lt;</span>stop</span> <span>offset</span><span><span>=</span><span>"</span>65%<span>"</span></span> <span>stop-color</span><span><span>=</span><span>"</span>white<span>"</span></span> <span>stop-opacity</span><span><span>=</span><span>"</span>0.9<span>"</span></span> <span>/&gt;</span></span>
				<span><span><span>&lt;</span>stop</span> <span>offset</span><span><span>=</span><span>"</span>75%<span>"</span></span> <span>stop-color</span><span><span>=</span><span>"</span>white<span>"</span></span> <span>stop-opacity</span><span><span>=</span><span>"</span>1<span>"</span></span> <span>/&gt;</span></span>
			<span><span><span>&lt;/</span>linearGradient</span><span>&gt;</span></span>
			<span><span><span>&lt;</span>use</span> <span>href</span><span><span>=</span><span>"</span>#shape<span>"</span></span> <span>fill</span><span><span>=</span><span>"</span>url('#fade')<span>"</span></span> <span>/&gt;</span></span>
		<span><span><span>&lt;/</span>mask</span><span>&gt;</span></span>
	<span><span><span>&lt;/</span>defs</span><span>&gt;</span></span>
	<span><span><span>&lt;</span>use</span> <span>href</span><span><span>=</span><span>"</span>#shape<span>"</span></span> <span>fill</span><span><span>=</span><span>"</span>hsl(337, 92%, 69%)<span>"</span></span> <span>mask</span><span><span>=</span><span>"</span>url(#gradient)<span>"</span></span> <span>filter</span><span><span>=</span><span>"</span>url('#noise')<span>"</span></span> <span>/&gt;</span></span>
<span><span><span>&lt;/</span>svg</span><span>&gt;</span></span></code></pre></div>
<svg viewBox="0 0 100 100">
	<defs>
		<circle id="shape" cx="50" cy="50" r="50"></circle>
	  <filter id="noise">
	    <feTurbulence type="fractalNoise" baseFrequency="19.5" numOctaves="10" result="turbulence"></feTurbulence>
			<feComposite operator="in" in="turbulence" in2="SourceAlpha" result="composite"></feComposite>
			<feColorMatrix in="composite" type="luminanceToAlpha"></feColorMatrix>
			<feBlend in="SourceGraphic" in2="composite" mode="color-burn"></feBlend>
	  </filter>
		<mask id="gradient">
			<linearGradient id="fade">
        <stop offset="0%" stop-color="black" stop-opacity="0.6"></stop>
        <stop offset="65%" stop-color="white" stop-opacity="0.9"></stop>
        <stop offset="75%" stop-color="white" stop-opacity="1"></stop>
			</linearGradient>
			<use href="#shape" fill="url('#fade')"></use>
		</mask>
	</defs>
  <use href="#shape" fill="hsl(337, 92%, 69%)" mask="url(#gradient)" filter="url('#noise')"></use>
</svg>
</div>
<p><a href="https://danielimmke.github.io/noisy-shapes"><strong>Full Demo Link</strong></a></p>
<p>Adding a nice fill color and making the gradient a little more subtle and there we go!</p>
<p>With some additional playing around I was able to create <a href="https://danielimmke.github.io/noisy-shapes">an illustration</a> I was quite happy with. It’s not perfect, and notably renders differently in Safari than other browsers but it achieves what I set out to accomplish.</p>
<p>You can also check out the code in the <a href="https://github.com/danielimmke/noisy-shapes">repository</a>.</p>
<p>This method could certainly be improved with additional experimenting. It’s still a far cry from the complexity of some of the illustrations I linked, but I think it could potentially be refined to be usable in more situations.</p>
<h3 id="addendum-dec-7-2023"><a href="#addendum-dec-7-2023" aria-label="addendum dec 7 2023 permalink"></a>Addendum <em>Dec 7, 2023</em></h3>
<p>I submitted this post to Hacker News where it received some reception, and was pointed out that <a href="https://css-tricks.com/grainy-gradients/">CSS Tricks posted a great article</a> written by Jimmy Chion about this subject in 2021. It’s a great article, and the techniques we arrive at are similar.</p>
<p>I was not aware of this post at the time of this writing but am now linking to it here for supplementary reading.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini "duck" demo was not done in realtime or with voice (417 pts)]]></title>
            <link>https://twitter.com/parmy/status/1732811357068615969</link>
            <guid>38559582</guid>
            <pubDate>Thu, 07 Dec 2023 18:03:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/parmy/status/1732811357068615969">https://twitter.com/parmy/status/1732811357068615969</a>, See on <a href="https://news.ycombinator.com/item?id=38559582">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A lost X-Files song (131 pts)]]></title>
            <link>https://twitter.com/laurenancona/status/1731900441800155459</link>
            <guid>38558423</guid>
            <pubDate>Thu, 07 Dec 2023 16:36:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/laurenancona/status/1731900441800155459">https://twitter.com/laurenancona/status/1731900441800155459</a>, See on <a href="https://news.ycombinator.com/item?id=38558423">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Data Engineering Design Patterns (DEDP) (115 pts)]]></title>
            <link>https://www.dedp.online/</link>
            <guid>38557715</guid>
            <pubDate>Thu, 07 Dec 2023 15:51:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dedp.online/">https://www.dedp.online/</a>, See on <a href="https://news.ycombinator.com/item?id=38557715">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                                
                <div id="menu-bar">📖 Data Engineering Design Patterns (DEDP)</div>

                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        <!-- Page table of contents -->
                        

                        <h2 id="book-data-engineering-design-patterns-dedp"><a href="#book-data-engineering-design-patterns-dedp">Book: Data Engineering Design Patterns (DEDP)</a></h2>
<!--*The Future of Data Evolution.* or *Mastering convergent evolution*.-->
<p>Hey there 👋, this is the start of a book about <em>Data Engineering Design Patterns</em>.</p>
<h2 id="about-this-book"><a href="#about-this-book">About This Book</a></h2>
<p>This book is different from usual books. It does <strong>not come finished</strong>. I will steadily release new chapters of the book, carefully listen to all your feedback, and integrate them to create a (hopefully) great book at the end of the day. Keep an eye on the <a href="https://www.dedp.online/appendix/changelog.html">changelog</a> for the latest updates, or sign up for the below <a href="https://list.ssp.sh/subscription/form">newsletter</a>.</p>
<h2 id="motivation"><a href="#motivation">Motivation</a></h2>
<p>I love writing. I love editing text. After writing for about 8+ years on my personal blog, and even doing it professionally for a year, I love the challenge that my former boss, Swyx confronted me, to put my 20+ years of experience in data engineering into a book. And, as I love long formats, a book might just be the best format to bring it all together in one.</p>
<p>Over my 20+ year career, I've witnessed an endless cycle of emerging terms and technologies.  This pattern led me to ponder: are we merely repackaging old ideas in new terminology?</p>
<p>That's when I found the term the intriguing concept: <strong>convergent evolution</strong>. This term, new to me at first, resonated deeply with my experiences in the data field, where often new terms are introduced every wee. Over time, I learned that what seemed new was simply a repurposed concept from a decade ago, now labeled with a new name. </p>
<p>Occasionally, these were existing technologies, subtly enhanced. Yet, true innovation seemed rare. This is where the idea of convergent evolution becomes pivotal. </p>
<p>Convergent evolution is when the outcome of two distinct evolutions is the same. The most famous one is <em>flying</em>. Both a bird and a bee can fly but in different ways. The bird has developed feathers, and a bee has an exoskeleton, which was learned and developed to fly in a different evolution.</p>
<p>This pattern of convergent evolution in data engineering captivated me, inspiring this book. My goal is to dissect these evolutionary paths, uncovering their unique strengths and weaknesses. By doing so, I aim to identify universal design patterns applicable across the spectrum of data engineering. Join me as we explore the essence of convergent evolution, its relevance in our field, and how it can guide us through the Data Engineering Lifecycle, enriching our understanding and practice.</p>
<blockquote>
<p><strong>Disclaimer</strong></p>
<p>This project is still a personal project, available <strong>for free</strong>, solely made by me,&nbsp;<a href="https://www.dedp.online/appendix/author.html">Simon Späti</a>. Therefore, I might be wrong here and there; please <a href="https://www.dedp.online/appendix/feedback">let me know</a> when so. Be kind 🤗. </p>
</blockquote>
<h2 id="subscribing"><a href="#subscribing">Subscribing</a></h2>

<h2 id="what-you-will-learn-by-the-end-of-this-book"><a href="#what-you-will-learn-by-the-end-of-this-book">What You Will Learn by the End of This Book</a></h2>
<ul>
<li>The history and state of the art of data engineering.</li>
<li>We cover Convergent Evolution, common pattern among them and find best practices in the form of data engineering design patterns. </li>
<li>Gain a comprehensive understanding beyond the hype to deeply understand definitions, history and core concepts of data engineering.</li>
<li>Dive into categories of data engineering such as different approaches, architectures and data modeling.</li>
<li>Helping you navigate the complex environments of todays data landscape and improving decision-making for better business outcomes.</li>
<li>Learning how to avoid common pitfalls, relevant tools and technologies and the future of data engineering through explored patterns and best practices.</li>
</ul>
<h2 id="what-you-can-expect"><a href="#what-you-can-expect">What You Can Expect</a></h2>
<ul>
<li>Genuine knowledge and wisdom from my 20+ experiences in the field of business intelligence and data engineering. </li>
<li>To acquire a solid understanding of Convergent Evolution and the practical explanations of crucial data engineering design patterns.</li>
<li>Stay informed in the constantly evolving world of data engineering by understanding essential data engineering design patterns beyond the hype.</li>
</ul>
<h2 id="why-is-this-book-for-you"><a href="#why-is-this-book-for-you">Why Is This Book for You?</a></h2>
<p>Looking to stay ahead of the curve in the constantly evolving world of data engineering? Look no further than this new book. With a focus on crucial data engineering design patterns and how to navigate them, you will gain a comprehensive understanding of how to overcome common challenges and build well-thought-through data systems. </p>
<p>The primary audience for this book on data engineering and the open data stack are professionals and practitioners working in data engineering. This field includes data engineers, data architects, data scientists, and data analysts who are responsible for designing, building, and maintaining data pipelines and data platforms.</p>
<p>The book is designed for an intermediate-level audience who are familiar with the basics of data engineering and have some experience working with data technologies. The audience is assumed to have a basic understanding of SQL and programming and experience working with data tools such as databases, ETL/ELT, and data modeling. The book assumes that you have already read or are aware of the introductory books on data engineering such as <a href="https://www.oreilly.com/library/view/fundamentals-of-data/9781098108298/">The Fundamentals of Data Engineering</a> and are looking to explore the future of data engineering best practices.</p>
<p>The book does not assume mastery of any specific skills or technologies but rather provides a comprehensive overview of the data engineering landscape, including carefully curated approaches to data engineering. The book aims to provide you with a practical guide to applying data engineering design patterns using open-source tools to navigate complex, reliable, and maintainable data architectures and platforms.</p>
<p>What sets this book apart is its unique approach to iterating a live book online and actively seeking <a href="https://www.dedp.online/appendix/feedback.html">feedback</a>. Analyzing critical terms of convergent evolution and how they blend into applicable data engineering design patterns. This innovative approach provides you with the tools and techniques needed to stand out in the competitive data engineering industry. Whether you're a seasoned professional or just starting out in the field, this book is a must-read for anyone looking to improve the efficiency and effectiveness of their open data stack and achieve data-aware solutions.</p>
<h2 id="about-data-engineering-design-patterns"><a href="#about-data-engineering-design-patterns">About Data Engineering Design Patterns</a></h2>
<p>The field of data engineering is constantly changing, making it difficult for professionals to stay up to date with the latest trends and technologies. This book offers a unique solution by introducing the concept of convergent evolution and explaining how it relates to crucial data engineering design patterns. With topics ranging from CEs such as materialized views (which are equivalent to OBT), data validation (or data contracts), OLAP cubes (or semantic layers, personalized APIs, BI dashboard), different flavors of dimensional modeling, and various data integration techniques like ETL, ELT, Reverse ETL, CDP, and Master Data Management, you will gain a comprehensive understanding how these leads into most important design patterns such as Open Data Platform, Dynamic-Querying, Declarative Orchestration, Asset-based Governance and many more.</p>
<p>Part One of the book introduces the field of data engineering with history, explaining the current state, and highlighting common challenges while explaining what are design patterns and why convergent evolution plays a big part in it. Part Two delves into mastering these design patterns, exploring various data patterns resulting in design patterns, e.g., for architectural and data modeling or software engineering approaches applied to data engineering. Part Three provides guidance on how to navigate these patterns in real-world contexts, providing best practices, open data architectures, and emerging technologies. More on the next <a href="https://www.dedp.online/introduction.html">introduction chapter</a>.</p>
<p>By examining emerging technologies and offering insights into the design patterns to navigate common challenges, this book provides a valuable resource for data engineers looking to improve the efficiency and effectiveness of their work. </p>
<p>By learning and applying these design patterns, data engineers can reduce conceptual errors, build more robust data systems, and ultimately contribute to better decision-making and business outcomes. Whether you're a seasoned data engineer or just curious about the field, this book is a must-read for anyone looking to stay ahead of the curve in this constantly evolving industry.</p>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->

                            <a rel="next" href="https://www.dedp.online/terminologies.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>

                        
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">

                    <a rel="next" href="https://www.dedp.online/terminologies.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
            </nav>

        </div>




        


        
        
        

        
        
        

        <!-- Custom JS scripts -->
        
        
        


    </div>
    

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fake chips, I got stung (160 pts)]]></title>
            <link>https://linuxjedi.co.uk/2023/12/01/fake-chips-i-got-stung/</link>
            <guid>38557246</guid>
            <pubDate>Thu, 07 Dec 2023 15:13:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linuxjedi.co.uk/2023/12/01/fake-chips-i-got-stung/">https://linuxjedi.co.uk/2023/12/01/fake-chips-i-got-stung/</a>, See on <a href="https://news.ycombinator.com/item?id=38557246">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
<p>Unfortunately, in the tech sector, just like many other sectors, there are scammers around. When you are dealing with electronics this is typically in the form of chips that have had their markings changed, usually to make them appear as if they are a more expensive chip. This has happened to me, so I’ll talk a bit about it.</p>



<p>As part of my work <a href="https://linuxjedi.co.uk/tag/atom/">restoring the Acorn Atom</a>, I replaced the 6502 CPU with a much lower power CMOS variant made by Rockwell, the R65C02. But something was bugging me. In my tests, I didn’t notice any power drop between that and the original CPU.</p>



<p>You see, the original 6502 used an NMOS process which is typically much more power hungry than CMOS. On top of this, the R65C02 was made using a smaller fabrication size. These things combined means that in-theory it should draw an order of magnitude less power. The R65C02 has an extended instruction set, so it is usually easy to identify.</p>



<p>This is the chip I bought.</p>



<figure><img data-attachment-id="5040" data-permalink="https://linuxjedi.co.uk/2023/12/01/fake-chips-i-got-stung/pxl_20231102_1403128992/" data-orig-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231102_1403128997e2.jpg" data-orig-size="1756,686" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PXL_20231102_140312899~2" data-image-description="" data-image-caption="" data-medium-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231102_1403128997e2.jpg?w=300" data-large-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231102_1403128997e2.jpg?w=736" loading="lazy" width="1024" height="400" src="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231102_1403128997e2.jpg?w=1024" alt="" srcset="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231102_1403128997e2.jpg?w=1024 1024w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231102_1403128997e2.jpg?w=150 150w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231102_1403128997e2.jpg?w=300 300w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231102_1403128997e2.jpg?w=768 768w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231102_1403128997e2.jpg 1756w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>What initially bugged me is that the printing was far too bright compared to pretty much any chip I’ve worked with. Something just seemed “off” about the printing too, but I couldn’t put my finger on it.</p>



<h2>Testing</h2>



<p>As with all things tech I’m not sure about, I start testing them. First of all I tried the acetone test. You see, the printing used on genuine ICs is designed to withstand the harsh cleaning chemicals used during manufacturing. Whereas chips that have had their markings changed typically use a cheaper painting process, which can often be removed with acetone. Straight away some of the printing starting coming off on the acetone soaked cotton bud I used. It looked pretty smeared and faded after a few seconds.</p>



<figure><img data-attachment-id="5041" data-permalink="https://linuxjedi.co.uk/2023/12/01/fake-chips-i-got-stung/pxl_20231128_135033910/" data-orig-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231128_135033910.jpg" data-orig-size="2790,1119" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;,&quot;latitude&quot;:&quot;0&quot;,&quot;longitude&quot;:&quot;0&quot;}" data-image-title="PXL_20231128_135033910" data-image-description="" data-image-caption="" data-medium-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231128_135033910.jpg?w=300" data-large-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231128_135033910.jpg?w=736" loading="lazy" width="1024" height="410" src="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231128_135033910.jpg?w=1024" alt="" srcset="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231128_135033910.jpg?w=1022 1022w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231128_135033910.jpg?w=2045 2045w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231128_135033910.jpg?w=150 150w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231128_135033910.jpg?w=300 300w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231128_135033910.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Next up was a logical test. My <a href="https://store.backbit.io/product/chip-tester/">BackBit Chip Tester Pro v2</a> can not only test the function of a 6502 CPU, but also tell you which variant it is (even detecting an Atari Sally variant). I bunged it in and hit the test button.</p>



<figure><img data-attachment-id="5042" data-permalink="https://linuxjedi.co.uk/2023/12/01/fake-chips-i-got-stung/pxl_20231201_142121137/" data-orig-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142121137.jpg" data-orig-size="3072,4080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 8&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1701440481&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.95&quot;,&quot;iso&quot;:&quot;160&quot;,&quot;shutter_speed&quot;:&quot;0.029625&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;0&quot;,&quot;longitude&quot;:&quot;0&quot;}" data-image-title="PXL_20231201_142121137" data-image-description="" data-image-caption="" data-medium-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142121137.jpg?w=226" data-large-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142121137.jpg?w=736" loading="lazy" width="771" height="1023" src="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142121137.jpg?w=771" alt="" srcset="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142121137.jpg?w=771 771w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142121137.jpg?w=1542 1542w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142121137.jpg?w=113 113w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142121137.jpg?w=226 226w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142121137.jpg?w=768 768w" sizes="(max-width: 771px) 100vw, 771px"></figure>



<p>That explains a few things, this is really a standard NMOS 6502, not a 65C02.</p>



<h2>Other Signs</h2>



<p>There is one other sign I found out later which proves that this is not a genuine chip, the date code. You can see that it says 0032, this means the 32nd week of the year 2000. The problem with that is in 1999 the semiconductor division of Rockwell split out into a company called Conexant. When this happened, any chips manufactured suddenly switched to the Conexant branding, which is a completely different logo.</p>



<p>In addition, I believe, based on web searches, that the wafer ID for an R65C02 is 11450, not 11473 as marked here.</p>



<p>This was annoying because the seller is based in the UK and claims you should buy from them because you take your chances buying from China.</p>



<h2>Another Chip</h2>



<p>Once I figured out my chip was fake, and before I realised the date code issue, I bought another one from a different seller.</p>



<figure><img data-attachment-id="5043" data-permalink="https://linuxjedi.co.uk/2023/12/01/fake-chips-i-got-stung/pxl_20231201_112050339/" data-orig-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_112050339.jpg" data-orig-size="3104,1143" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;,&quot;latitude&quot;:&quot;0&quot;,&quot;longitude&quot;:&quot;0&quot;}" data-image-title="PXL_20231201_112050339" data-image-description="" data-image-caption="" data-medium-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_112050339.jpg?w=300" data-large-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_112050339.jpg?w=736" loading="lazy" width="1024" height="377" src="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_112050339.jpg?w=1024" alt="" srcset="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_112050339.jpg?w=1024 1024w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_112050339.jpg?w=2048 2048w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_112050339.jpg?w=150 150w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_112050339.jpg?w=300 300w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_112050339.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The printing looked a bit better on this one at least, but 30th week of 2015? I very much doubt it. I can’t find evidence of any being manufactured after the early 2000s. Let’s whack it on the tester…</p>



<figure><img data-attachment-id="5044" data-permalink="https://linuxjedi.co.uk/2023/12/01/fake-chips-i-got-stung/pxl_20231201_142253258/" data-orig-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142253258.jpg" data-orig-size="3072,4080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 8&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1701440573&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.95&quot;,&quot;iso&quot;:&quot;155&quot;,&quot;shutter_speed&quot;:&quot;0.03149&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;0&quot;,&quot;longitude&quot;:&quot;0&quot;}" data-image-title="PXL_20231201_142253258" data-image-description="" data-image-caption="" data-medium-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142253258.jpg?w=226" data-large-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142253258.jpg?w=736" loading="lazy" width="771" height="1023" src="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142253258.jpg?w=771" alt="" srcset="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142253258.jpg?w=771 771w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142253258.jpg?w=1542 1542w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142253258.jpg?w=113 113w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142253258.jpg?w=226 226w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142253258.jpg?w=768 768w" sizes="(max-width: 771px) 100vw, 771px"></figure>



<p>That’s more like it, this is at least a R65C02 CPU. My best guess is the speed grade is the issue. The ‘3’ on the end means that it is rated to run at 3MHz, it is likely really just a 2 or 1MHz chip that has been marked up to give it a higher value. This is good enough for me as the Atom will only run it at 1MHz.</p>



<h2>Physical Comparison</h2>



<p>Here are the two chips claiming to be 65C02s together with an original 6502. Normally I would expect there to be printing on the bottom as well as the top.</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:134406412,&quot;permalink&quot;:&quot;https:\/\/linuxjedi.co.uk\/2023\/12\/01\/fake-chips-i-got-stung\/&quot;}">
<figure><img data-attachment-id="5045" data-permalink="https://linuxjedi.co.uk/2023/12/01/fake-chips-i-got-stung/pxl_20231201_142715805-mp/" data-orig-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142715805.mp_.jpg" data-orig-size="4080,3072" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 8&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1701440835&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.95&quot;,&quot;iso&quot;:&quot;1166&quot;,&quot;shutter_speed&quot;:&quot;0.039999&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;0&quot;,&quot;longitude&quot;:&quot;0&quot;}" data-image-title="PXL_20231201_142715805.MP" data-image-description="" data-image-caption="" data-medium-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142715805.mp_.jpg?w=300" data-large-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142715805.mp_.jpg?w=736" loading="lazy" width="1024" height="771" data-id="5045" src="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142715805.mp_.jpg?w=1024" alt="" srcset="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142715805.mp_.jpg?w=1024 1024w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142715805.mp_.jpg?w=2048 2048w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142715805.mp_.jpg?w=150 150w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142715805.mp_.jpg?w=300 300w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142715805.mp_.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img data-attachment-id="5046" data-permalink="https://linuxjedi.co.uk/2023/12/01/fake-chips-i-got-stung/pxl_20231201_142753880-mp/" data-orig-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142753880.mp_.jpg" data-orig-size="4080,3072" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 8&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1701440873&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.95&quot;,&quot;iso&quot;:&quot;1020&quot;,&quot;shutter_speed&quot;:&quot;0.039999&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;0&quot;,&quot;longitude&quot;:&quot;0&quot;}" data-image-title="PXL_20231201_142753880.MP" data-image-description="" data-image-caption="" data-medium-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142753880.mp_.jpg?w=300" data-large-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142753880.mp_.jpg?w=736" loading="lazy" width="1024" height="771" data-id="5046" src="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142753880.mp_.jpg?w=1024" alt="" srcset="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142753880.mp_.jpg?w=1024 1024w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142753880.mp_.jpg?w=2048 2048w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142753880.mp_.jpg?w=150 150w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142753880.mp_.jpg?w=300 300w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142753880.mp_.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</figure>



<p>On the bottom of the middle chip is what appears to be logographic characters. I do not know what these represent, or even if I have them the right way around. <strong>Update</strong>: see the end of this post for the translation the community figured out.</p>



<figure><img data-attachment-id="5047" data-permalink="https://linuxjedi.co.uk/2023/12/01/fake-chips-i-got-stung/pxl_20231201_142817292/" data-orig-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142817292.jpg" data-orig-size="4080,3072" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 8&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1701440897&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.95&quot;,&quot;iso&quot;:&quot;104&quot;,&quot;shutter_speed&quot;:&quot;0.034481&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;0&quot;,&quot;longitude&quot;:&quot;0&quot;}" data-image-title="PXL_20231201_142817292" data-image-description="" data-image-caption="" data-medium-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142817292.jpg?w=300" data-large-file="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142817292.jpg?w=736" loading="lazy" width="1024" height="771" src="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142817292.jpg?w=1024" alt="" srcset="https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142817292.jpg?w=1024 1024w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142817292.jpg?w=2048 2048w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142817292.jpg?w=150 150w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142817292.jpg?w=300 300w, https://thelinuxjedi.files.wordpress.com/2023/12/pxl_20231201_142817292.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>Conclusion</h2>



<p>This is quite a wide spread problem, and it is difficult to find genuine old parts when even UK sellers are selling parts that are not as they are marked.</p>



<p>If, like me, you are not pushing them to their designed limits, that may be OK. But sometimes it really isn’t, and sometimes the chip is nothing like what is shown on the markings, leading to potential physical damage to the machine it is used in.</p>



<p>As a side note, I have designed a prototype board that allows use of a brand new 65C02 IC made by Western Design Center in retro machines. The Western Design Center chips have a slightly different pinout to the others, so need a slight conversion. PCBs for this are coming soon.</p>



<h2>Update 2023-12-07</h2>



<p>This <a href="https://news.ycombinator.com/item?id=38557246">post got added to Hacker News</a> and was in the top 10 for a while. Thank you to whoever did that. In the comments the Chinese handwriting was discussed and it seems that a translation has been found.</p>



<blockquote>
<p>As a native speaker I think its “贤”, just rotated right by 90 degree.</p>
<cite>libreliu on Hacker News</cite></blockquote>



<p>It appears when translated this means “virtuous, worthy, good; able”, which I guess (and other people guess too) means that the chip functions, not that it is a genuine / virtuous chip.</p>



<p>Also thanks to those who commented with minor corrections on Hacker News.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Swedish Tesla strike goes international as Norwegian and Danish unions join in (233 pts)]]></title>
            <link>https://www.theregister.com/2023/12/07/swedish_tesla_strike_international/</link>
            <guid>38557228</guid>
            <pubDate>Thu, 07 Dec 2023 15:12:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/12/07/swedish_tesla_strike_international/">https://www.theregister.com/2023/12/07/swedish_tesla_strike_international/</a>, See on <a href="https://news.ycombinator.com/item?id=38557228">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Swedish Tesla employees have gone on strike, and unions in neighboring Denmark and Norway have joined boycotts of Elon Musk's electric automaker.</p>
<p>Danish union 3F and Norway's Fellesforbundet, the largest private-sector unions in their respective nations, both announced plans this week to get in Tesla's way.</p>
<p>3F, which covers multiple industries in Denmark, has limited its sympathy strike to its Transportation arm, which union chair Jan Villadsen explained will mean transportation workers at docks, including drivers, won't unload or transport Tesla vehicles bound for Sweden.</p>

    

<p>"Even though Elon Musk is one of the richest people in the world and owns Tesla, he can't just make his own rules," Villadsen <a href="https://www.facebook.com/jan.g.villadsen/posts/669001345216182" rel="nofollow">declared</a> on Tuesday when announcing 3F's action. "We have some agreements on the labor market in the Nordics, and you have to comply with them if you want to do business here."</p>

        


        

<p>Fellesforbundet leader Jørn Eggum echoed Villadsen's sentiments in a Wednesday <a href="https://www.fellesforbundet.no/aktuelt/nyheter/2023/varsler-tesla-boikott/" rel="nofollow">announcement</a> that his union will also launch a boycott aimed at stopping the transportation of Teslas into Sweden.</p>
<p>"In the Nordic countries, there is broad agreement about the importance of a well-organized working life," Eggum noted. "The right to demand a collective agreement is a natural part of [that], and we cannot accept that Tesla stands outside this."</p>

        

<p>3F and Fellesforbundet's sympathy strikes will begin on December 19 and December 20, respectively, if a collective agreement between Tesla and employees represented by Swedish automotive worker union IF Metall isn't in place.</p>
<p>IF Metall workers in Sweden – where Tesla doesn't manufacture vehicles but has a number of repair and service shops – have been <a href="https://www.ifmetall.se/aktuellt/tesla/" rel="nofollow">on strike</a> since October after what they described as years of Tesla refusing to bargain with the union. IF Metall-represented employees claim Tesla hasn't guaranteed them good wages, a pension or insurance.</p>
<ul>

<li><a href="https://www.theregister.com/2021/03/26/tesla_labor_law/">Tesla broke US labor law with anti-union efforts – watchdog</a></li>

<li><a href="https://www.theregister.com/2023/02/16/tesla_fires_dozens_at_factory/">Tesla fires Gigafactory staff after someone made the mistake of mentioning unions</a></li>

<li><a href="https://www.theregister.com/2023/11/08/google_union_nlrb/">Google Bard AI contractors unionize amid anger over 'retaliatory' layoffs</a></li>

<li><a href="https://www.theregister.com/2023/04/28/us_labor_board_tesla/">Tesla ran over worker rights, again, US labor judge finds</a></li>
</ul>
<p>Tesla has long refused to bargain with unions, with CEO Elon Musk recently <a href="https://www.theregister.com/2023/11/30/musk_murders_x/">opining</a> that he disagrees with the entire concept of organized labor, as you can see below.</p>
<p>
  <a href="https://www.youtube.com/watch?v=sctgA2qa-rA" data-media="x-videoplayer">Youtube Video</a>
</p>
<p>"I just don't like anything which creates a lords and peasants sort of thing," the world's richest man told the <em>New York Times</em> DealBook Summit. "I think the unions naturally try to create negativity in a company." He added "If Tesla gets unionized it will be because we deserved it, and because we failed in some way."</p>

        

<p>Unions across Sweden have <a href="https://www.ifmetall.se/aktuellt/tesla/darfor-tvingas-if-metall-att-strejka/sympatiatgarder-fran-andra-fackforbund/" rel="nofollow">banded together</a> to cripple Tesla. Swedish port workers have pledged to block imports, electricians have refused to work on damaged Tesla chargers or at the vehicle builder's facilities, painters and builders have declined to work for Elon's products and properties.</p>
<p>Postal workers even decided not to deliver mail to the electric automaker, including license plates – an action that Musk called "<a href="https://twitter.com/elonmusk/status/1727564977869844865?s=20" rel="nofollow">insane</a>". The local court has since <a target="_blank" rel="nofollow" href="https://www.theregister.com/2023/11/27/tesla_sweden_strike_lawsuit/">put a stop</a> to that action.</p>
<p>It's unknown whether Tesla plans to take further action to stop the strikes, or whether it'll cut its losses and bargain with employees – we asked, but didn't hear back. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta's new AI image generator was trained on 1.1B Instagram and FB photos (163 pts)]]></title>
            <link>https://arstechnica.com/information-technology/2023/12/metas-new-ai-image-generator-was-trained-on-1-1-billion-instagram-and-facebook-photos/</link>
            <guid>38557054</guid>
            <pubDate>Thu, 07 Dec 2023 14:57:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/information-technology/2023/12/metas-new-ai-image-generator-was-trained-on-1-1-billion-instagram-and-facebook-photos/">https://arstechnica.com/information-technology/2023/12/metas-new-ai-image-generator-was-trained-on-1-1-billion-instagram-and-facebook-photos/</a>, See on <a href="https://news.ycombinator.com/item?id=38557054">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      adventures in image synthesis    —
</h4>
            
            <h2 itemprop="description">"Imagine with Meta AI" turns prompts into images, trained using public Facebook data.</h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/meta_emu_hero_1-800x450.jpg" alt="Three images generated by " imagine="" with="" meta="" ai="" using="" the="" emu="" model.="">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/meta_emu_hero_1.jpg" data-height="675" data-width="1200">Enlarge</a> <span>/</span> Three images generated by "Imagine with Meta AI" using the Emu AI model.</p><p>Meta | Benj Edwards</p></figcaption>  </figure>

  




<!-- cache hit 507:single/related:15e9502cad0b558c28b6c7748e41ad11 --><!-- empty -->
<p>On Wednesday, Meta <a href="https://about.fb.com/news/2023/12/meta-ai-updates/">released</a> a free standalone AI image-generator website, "<a href="https://imagine.meta.com/">Imagine with Meta AI</a>," based on its Emu image-synthesis model. Meta used 1.1 billion publicly visible Facebook and Instagram images to <a href="https://www.reuters.com/technology/metas-new-ai-chatbot-trained-public-facebook-instagram-posts-2023-09-28/">train the AI model</a>, which can render a novel image from a written prompt. Previously, Meta's version of this technology—using the same data—was <a href="https://arstechnica.com/information-technology/2023/10/facebooks-new-ai-stickers-can-generate-mickey-mouse-holding-a-machine-gun/">only available</a> in messaging and social networking apps such as Instagram.</p>

<p>If you're on Facebook or Instagram, it's quite possible a picture of you (or that you took) helped train Emu. In a way, the <a href="https://bryanalexander.org/digital-literacy/you-are-the-product-one-interesting-source-for-the-meme/">old saying</a>, "If you're not paying for it, you are the product" has taken on a whole new meaning. Although, as of 2016, Instagram users uploaded over <a href="https://www.reuters.com/article/us-facebook-instagram-users/instagrams-user-base-grows-to-more-than-500-million-idUSKCN0Z71LN/">95 million photos a day</a>, so the dataset Meta used to train its AI model was a small subset of its overall photo library.</p>
<p>Since Meta says it only uses publicly available photos for training, setting your photos private on Instagram or Facebook should prevent their inclusion in the company's future AI model training (unless it changes that policy, of course).</p>
<h2>Imagine with Meta AI</h2>
  <div>
    <ul>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/12/barbarian_crt-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/barbarian_crt.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/12/barbarian_crt-980x749.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/12/barbarian_crt.jpg 2560" data-sub-html="#caption-1989205">
          <figure>
            
                          <figcaption id="caption-1989205">
                <span></span>
                                  <p>
                    AI-generated images of "a muscular barbarian with weapons beside a CRT television set, cinematic, 8K, studio lighting" created by Meta Emu on the "Imagine with Meta AI" website.                  </p>
                                                  <p><span></span>
                                          Meta | Benj Edwards                                      </p>
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/12/cat_with_beer-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/cat_with_beer.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/12/cat_with_beer-980x749.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/12/cat_with_beer.jpg 2560" data-sub-html="#caption-1989208">
          <figure>
            
                          <figcaption id="caption-1989208">
                <span></span>
                                  <p>
                    AI-generated images of "a cat in a car holding a can of beer" created by Meta Emu on the "Imagine with Meta AI" website.                  </p>
                                                  <p><span></span>
                                          Meta | Benj Edwards                                      </p>
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/12/flaming_cheeseburger-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/flaming_cheeseburger.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/12/flaming_cheeseburger-980x749.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/12/flaming_cheeseburger.jpg 2560" data-sub-html="#caption-1989204">
          <figure>
            
                          <figcaption id="caption-1989204">
                <span></span>
                                  <p>
                    AI-generated images of "a flaming cheeseburger" created by Meta Emu on the "Imagine with Meta AI" website.                  </p>
                                                  <p><span></span>
                                          Meta | Benj Edwards                                      </p>
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/12/mickeymouse_space-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/mickeymouse_space.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/12/mickeymouse_space-980x749.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/12/mickeymouse_space.jpg 2560" data-sub-html="#caption-1989211">
          <figure>
            
                          <figcaption id="caption-1989211">
                <span></span>
                                  <p>
                    AI-generated images of "a photorealistic Mickey Mouse on the moon in a spacesuit" created by Meta Emu on the "Imagine with Meta AI" website.                  </p>
                                                  <p><span></span>
                                          Meta | Benj Edwards                                      </p>
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/12/handsome_man-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/handsome_man.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/12/handsome_man-980x749.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/12/handsome_man.jpg 2560" data-sub-html="#caption-1989202">
          <figure>
            
                          <figcaption id="caption-1989202">
                <span></span>
                                  <p>
                    AI-generated images of "a handsome man" created by Meta Emu on the "Imagine with Meta AI" website.                  </p>
                                                  <p><span></span>
                                          Meta | Benj Edwards                                      </p>
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/12/gaming_pc-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/gaming_pc.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/12/gaming_pc-980x749.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/12/gaming_pc.jpg 2560" data-sub-html="#caption-1989203">
          <figure>
            
                          <figcaption id="caption-1989203">
                <span></span>
                                  <p>
                    AI-generated images of "the ultimate gaming PC with 1,000 RGB lights" created by Meta Emu on the "Imagine with Meta AI" website.                  </p>
                                                  <p><span></span>
                                          Meta | Benj Edwards                                      </p>
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/12/ars_sign-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/ars_sign.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/12/ars_sign-980x749.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/12/ars_sign.jpg 2560" data-sub-html="#caption-1989209">
          <figure>
            
                          <figcaption id="caption-1989209">
                <span></span>
                                  <p>
                    AI-generated images of "a man holding a sign that says 'Ars Technica'" created by Meta Emu on the "Imagine with Meta AI" website.                  </p>
                                                  <p><span></span>
                                          Meta | Benj Edwards                                      </p>
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/12/xmas_stockings-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/xmas_stockings.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/12/xmas_stockings-980x749.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/12/xmas_stockings.jpg 2560" data-sub-html="#caption-1989212">
          <figure>
            
                          <figcaption id="caption-1989212">
                <span></span>
                                  <p>
                    AI-generated images of a complex prompt involving Christmas stockings and a cave created by Meta Emu on the "Imagine with Meta AI" website.                  </p>
                                                  <p><span></span>
                                          Meta | Benj Edwards                                      </p>
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/12/swirlnerd-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/swirlnerd.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/12/swirlnerd-980x749.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/12/swirlnerd.jpg 2560" data-sub-html="#caption-1989214">
          <figure>
            
                          <figcaption id="caption-1989214">
                <span></span>
                                  <p>
                    AI-generated images of "photorealistic vintage computer collector nerd in a computer lab, bright psychedelic technicolor swirls" created by Meta Emu on the "Imagine with Meta AI" website.                  </p>
                                                  <p><span></span>
                                          Meta | Benj Edwards                                      </p>
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/12/santathread-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/santathread.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/12/santathread-980x749.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/12/santathread.jpg 2560" data-sub-html="#caption-1989213">
          <figure>
            
                          <figcaption id="caption-1989213">
                <span></span>
                                  <p>
                    AI-generated images of "an embroidered Santa Claus" created by Meta Emu on the "Imagine with Meta AI" website.                  </p>
                                                  <p><span></span>
                                          Meta | Benj Edwards                                      </p>
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/12/teddy_skate-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/teddy_skate.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/12/teddy_skate-980x749.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/12/teddy_skate.jpg 2560" data-sub-html="#caption-1989207">
          <figure>
            
                          <figcaption id="caption-1989207">
                <span></span>
                                  <p>
                    AI-generated images of "A teddy bear on a skateboard" created by Meta Emu on the "Imagine with Meta AI" website.                  </p>
                                                  <p><span></span>
                                          Meta | Benj Edwards                                      </p>
                              </figcaption>
                      </figure>
        </li>
              <li data-thumb="https://cdn.arstechnica.net/wp-content/uploads/2023/12/queen_of_universe-150x150.jpg" data-src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/queen_of_universe.jpg" data-responsive="https://cdn.arstechnica.net/wp-content/uploads/2023/12/queen_of_universe-980x749.jpg 1080, https://cdn.arstechnica.net/wp-content/uploads/2023/12/queen_of_universe.jpg 2560" data-sub-html="#caption-1989206">
          <figure>
            
                          <figcaption id="caption-1989206">
                <span></span>
                                  <p>
                    AI-generated images of "a beautiful queen of the universe" created by Meta Emu on the "Imagine with Meta AI" website.                  </p>
                                                  <p><span></span>
                                          Meta | Benj Edwards                                      </p>
                              </figcaption>
                      </figure>
        </li>
          </ul>
  </div>

<p>Similar to <a href="https://arstechnica.com/information-technology/2023/07/stable-diffusion-xl-puts-ai-generated-visual-worlds-at-your-gpus-command/">Stable Diffusion</a>, <a href="https://arstechnica.com/information-technology/2023/11/from-toy-to-tool-dall-e-3-is-a-wake-up-call-for-visual-artists-and-the-rest-of-us/">DALL-E 3</a>, and <a href="https://arstechnica.com/information-technology/2023/06/stunning-midjourney-update-wows-ai-artists-with-camera-like-feature/">Midjourney</a>, Imagine with Meta AI generates new images based on what the AI model "knows" about visual concepts learned from the training data. Creating images using the new website requires a Meta account, which can be imported from an existing Facebook or Instagram account. Each generation creates four 1280×1280 pixel images that can be saved in JPEG format. Images include a small "Imagined with AI" watermark logo in the lower left-hand corner.</p>                                            
                                                        
<p>"We’ve enjoyed hearing from people about how they’re using imagine, Meta AI’s text-to-image generation feature, to make fun and creative content in chats," Meta says in its news release. "Today, we’re expanding access to imagine outside of chats, making it available in the US to start at imagine.meta.com. This standalone experience for creative hobbyists lets you create images with technology from Emu, our image foundation model."</p>

<p>We put Meta's new AI image generator through a battery of low-stakes informal tests using our "Barbarian with a CRT" and "Cat with a beer" image-synthesis protocol and found aesthetically novel results, as you can see above. (As an aside, when generating images of people with Emu, we noticed many looked like typical Instagram fashion posts.)</p>
<p>We also tried our hand at adversarial testing. The generator appears to filter out most violence, curse words, sexual topics, and the names of celebrities and historical figures (no Abraham Lincoln, sadly), but it allows commercial characters like Elmo (yes, even "<a href="https://arstechnica.com/information-technology/2023/10/facebooks-new-ai-stickers-can-generate-mickey-mouse-holding-a-machine-gun/">with a knife</a>") and Mickey Mouse (though not with <a href="https://arstechnica.com/information-technology/2023/10/facebooks-new-ai-stickers-can-generate-mickey-mouse-holding-a-machine-gun/">a machine gun</a>).</p>
<p>Meta's model generally creates photorealistic images well, but not as well as Midjourney. It can handle complex prompts better than Stable Diffusion XL, but perhaps not as well as DALL-E 3. It doesn't seem to do text rendering well at all, and it handles different media outputs like watercolors, embroidery, and pen-and-ink with mixed results. Its images of people seem to include diversity in ethnic backgrounds. Overall, it seems about average these days in terms of AI image synthesis.</p>

                                                </div>

            
            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/information-technology/2023/12/metas-new-ai-image-generator-was-trained-on-1-1-billion-instagram-and-facebook-photos/2/">2</a> <a href="https://arstechnica.com/information-technology/2023/12/metas-new-ai-image-generator-was-trained-on-1-1-billion-instagram-and-facebook-photos/2/"><span>Next <span>→</span></span></a></span></nav>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Purple Llama by Meta AI (283 pts)]]></title>
            <link>https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/</link>
            <guid>38556771</guid>
            <pubDate>Thu, 07 Dec 2023 14:35:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/">https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=38556771">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><ul><li>We’re announcing Purple Llama, an umbrella project featuring open trust and safety tools and evaluations meant to level the playing field for developers to responsibly deploy generative AI models and experiences in accordance with best practices shared in our <a href="https://ai.meta.com/llama/responsible-use-guide/" target="_blank" data-lnfb-mode="ie">Responsible Use Guide</a>.</li><li>As a first step, we are releasing <a href="https://ai.meta.com/research/publications/purple-llama-cyberseceval-a-benchmark-for-evaluating-the-cybersecurity-risks-of-large-language-models/" target="_blank" data-lnfb-mode="ie">CyberSec Eval</a>, a set of cybersecurity safety evaluations benchmarks for LLMs; and <a href="https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/" target="_blank" data-lnfb-mode="ie">Llama Guard</a>, a safety classifier for input/output filtering that is optimized for ease of deployment.</li><li>Aligned with our open approach we look forward to partnering with the newly announced AI Alliance, AMD, AWS, Google Cloud, Hugging Face, IBM, Intel, Lightning AI, Microsoft, MLCommons, NVIDIA, Scale AI, and many others to improve and make those tools available to the open source community.</li></ul></div><div><ul><p>RECOMMENDED READS</p><li><a href="https://ai.meta.com/blog/llama-2/" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_external&quot;}" target="_self" data-lnfb-mode="ie"><svg viewBox="0 0 38 38" fill="none" xmlns="http://www.w3.org/2000/svg"><path opacity="0.4" fill-rule="evenodd" clip-rule="evenodd" d="M19 37C9.05887 37 1 28.9411 1 19C1 9.05887 9.05887 1 19 1C28.9411 1 37 9.05887 37 19C37 28.9411 28.9411 37 19 37Z" stroke="CurrentColor"></path><path d="M21.9657 12L28.9287 18.963L21.9657 25.926L20.7348 24.7193L25.6203 19.8334L10.0001 19.8334V18.0926L25.5966 18.0926L20.7348 13.2309L21.9657 12Z" fill="CurrentColor"></path><path d="M21.9657 12L28.9287 18.963L21.9657 25.926L20.7348 24.7193L25.6203 19.8334L10.0001 19.8334V18.0926L25.5966 18.0926L20.7348 13.2309L21.9657 12Z" fill="CurrentColor"></path></svg><p>Meta and Microsoft Introduce the Next Generation of Llama</p></a></li><li><a href="https://ai.meta.com/blog/fair-10-year-anniversary-open-science-meta/" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_external&quot;}" target="_self" data-lnfb-mode="ie"><svg viewBox="0 0 38 38" fill="none" xmlns="http://www.w3.org/2000/svg"><path opacity="0.4" fill-rule="evenodd" clip-rule="evenodd" d="M19 37C9.05887 37 1 28.9411 1 19C1 9.05887 9.05887 1 19 1C28.9411 1 37 9.05887 37 19C37 28.9411 28.9411 37 19 37Z" stroke="CurrentColor"></path><path d="M21.9657 12L28.9287 18.963L21.9657 25.926L20.7348 24.7193L25.6203 19.8334L10.0001 19.8334V18.0926L25.5966 18.0926L20.7348 13.2309L21.9657 12Z" fill="CurrentColor"></path><path d="M21.9657 12L28.9287 18.963L21.9657 25.926L20.7348 24.7193L25.6203 19.8334L10.0001 19.8334V18.0926L25.5966 18.0926L20.7348 13.2309L21.9657 12Z" fill="CurrentColor"></path></svg><p>Celebrating 10 years of FAIR: A decade of advancing the state-of-the-art through open research</p></a></li><li><a href="https://ai.meta.com/blog/ai-alliance/" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_external&quot;}" target="_self" data-lnfb-mode="ie"><svg viewBox="0 0 38 38" fill="none" xmlns="http://www.w3.org/2000/svg"><path opacity="0.4" fill-rule="evenodd" clip-rule="evenodd" d="M19 37C9.05887 37 1 28.9411 1 19C1 9.05887 9.05887 1 19 1C28.9411 1 37 9.05887 37 19C37 28.9411 28.9411 37 19 37Z" stroke="CurrentColor"></path><path d="M21.9657 12L28.9287 18.963L21.9657 25.926L20.7348 24.7193L25.6203 19.8334L10.0001 19.8334V18.0926L25.5966 18.0926L20.7348 13.2309L21.9657 12Z" fill="CurrentColor"></path><path d="M21.9657 12L28.9287 18.963L21.9657 25.926L20.7348 24.7193L25.6203 19.8334L10.0001 19.8334V18.0926L25.5966 18.0926L20.7348 13.2309L21.9657 12Z" fill="CurrentColor"></path></svg><p>AI Alliance Launches as an International Community of Leading Technology Developers, Researchers, and Adopters Collaborating Together to Advance Open, Safe, Responsible AI</p></a></li></ul><div><p>Generative AI has brought about a new wave of innovation unlike we’ve ever seen before. With it, we have the ability to converse with conversational AIs, generate realistic imagery, and accurately summarize large corpora of documents, all from simple prompts. With over 100 million downloads of Llama models to date, a lot of this innovation is being fueled by open models.</p><p>Collaboration on safety will build trust in the developers driving this new wave of innovation, and requires additional research and contributions on responsible AI. The people building AI systems can’t address the challenges of AI in a vacuum, which is why we want to level the playing field and create a center of mass for open trust and safety.</p><p>Today, we are announcing the launch of Purple Llama — an umbrella project that, over time, will bring together tools and evaluations to help the community build responsibly with open generative AI models. The initial release will include tools and evaluations for cybersecurity and input/output safeguards, with more tools to come in the near future.</p><p>Components within the Purple Llama project will be licensed permissively, enabling both research and commercial usage. We believe this is a major step towards enabling community collaboration and standardizing the development and usage of trust and safety tools for generative AI development.</p><br></div></div><p>The first step forward</p></div><div><p>Cybersecurity and LLM prompt safety are important areas for generative AI safety today. We have prioritized these considerations in our first party products and highlighted them as best practice in the Llama 2 <a href="https://ai.meta.com/llama/responsible-use-guide/" target="_blank" data-lnfb-mode="ie">Responsible Use Guide</a>.</p><p>Cybersecurity</p><div><p>We are sharing what we believe is the first industry-wide set of cybersecurity safety evaluations for LLMs. These benchmarks are based on industry guidance and standards (e.g., CWE and MITRE ATT&amp;CK) and built in collaboration with our security subject matter experts. With this initial release, we aim to provide tools that will help address some risks outlined in the <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2023/07/21/fact-sheet-biden-harris-administration-secures-voluntary-commitments-from-leading-artificial-intelligence-companies-to-manage-the-risks-posed-by-ai/" target="_blank" data-lnfb-mode="ie">White House commitments on developing responsible AI</a>, including:</p><ul><li>Metrics for quantifying LLM cybersecurity risks.</li><li>Tools to evaluate the frequency of insecure code suggestions.</li><li>Tools to evaluate LLMs to make it harder to generate malicious code or aid in carrying out cyberattacks.</li></ul><p>We believe these tools will reduce the frequency of LLMs suggesting insecure AI-generated code and reduce their helpfulness to cyber adversaries. Our initial results show that there are meaningful cybersecurity risks for LLMs, both with recommending insecure code and for complying with malicious requests. See our <a href="https://ai.meta.com/research/publications/purple-llama-cyberseceval-a-benchmark-for-evaluating-the-cybersecurity-risks-of-large-language-models/" target="_blank" data-lnfb-mode="ie">Cybersec Eval paper</a> for more details.</p><br></div><p>Input/Output Safeguards</p><div><p>As we outlined in Llama 2’s <a href="https://ai.meta.com/llama/responsible-use-guide/" target="_blank" data-lnfb-mode="ie">Responsible Use Guide</a>, we recommend that all inputs and outputs to the LLM be checked and filtered in accordance with content guidelines appropriate to the application.</p><p>To support this, and empower the community, we are releasing <a href="https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/" target="_blank" data-lnfb-mode="ie">Llama Guard</a>, an openly-available model that performs competitively on common open benchmarks and provides developers with a pretrained model to help defend against generating potentially risky outputs.</p><p>As part of our ongoing commitment to open and transparent science, we are releasing our methodology and an extended discussion of model performance in our <a href="https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/" target="_blank" data-lnfb-mode="ie">Llama Guard paper</a>. This model has been trained on a mix of publicly-available datasets to enable detection of common types of potentially risky or violating content that may be relevant to a number of developer use cases. Ultimately, our vision is to enable developers to customize this model to support relevant use cases and to make it easier to adopt best practices and improve the open ecosystem.</p><br></div><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.2365-6/407630966_890117059136270_2844720574287423651_n.png?_nc_cat=109&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=-UAAGZ41x0oAX-u9uSN&amp;_nc_ht=scontent.fzrh3-1.fna&amp;oh=00_AfD94mOEM-7RVpUxRyPsX_xKEmypYpL7sW4JsBF83FC_UA&amp;oe=658C4733" alt="" id="u_0_a_sB"></p><p>Why purple?</p><p>We believe that to truly mitigate the challenges that generative AI presents we need to take both attack (red team) and defensive (blue team) postures. <a href="https://danielmiessler.com/p/red-blue-purple-teams/" target="_blank" data-lnfb-mode="ie">Purple teaming</a>, composed of both red and blue team responsibilities, is a collaborative approach to evaluating and mitigating potential risks. The same ethos applies to generative AI. Hence, our investment in Purple Llama will be comprehensive.</p><p>An open ecosystem</p><div><p>Taking an open approach to AI is not new for Meta. Exploratory research, open science, and cross-collaboration are foundational to our AI efforts, and we believe there’s an important opportunity to create an open ecosystem. This collaborative mindset was at the forefront when <a href="https://ai.meta.com/blog/llama-2/" target="_blank" data-lnfb-mode="ie">Llama 2 launched in July</a> with over 100 partners, and we’re excited to share that many of those same partners will be partnering with us on open trust and safety, including: AI Alliance, AMD, Anyscale, AWS, Bain, CloudFlare, Databricks, Dropbox, Google Cloud, Hugging Face, IBM, Intel, Microsoft, MLCommons, Nvidia, Oracle, Orange, Scale AI, Together.AI, and many more to come.</p><p>We’ve also worked with our partners at <a href="https://paperswithcode.com/" target="_blank" data-lnfb-mode="ie">Papers With Code</a> and <a href="https://crfm.stanford.edu/helm/latest/" target="_blank" data-lnfb-mode="ie">HELM</a> to incorporate these evals into their benchmarks, alongside our collaborators within the <a href="https://mlcommons.org/2023/10/mlcommons-announces-the-formation-of-ai-safety-working-group/" target="_blank" data-lnfb-mode="ie">MLCommons AI Safety Working Group</a>.</p><p>We’re excited to collaborate with each and every one of our partners as well as others who share the same vision of an open ecosystem of responsibly-developed generative AI.</p></div><p>The path forward</p><p>We are hosting a <a href="https://nips.cc/" target="_blank" data-lnfb-mode="ie">workshop at NeurIPs 2023</a>, where we plan to share these tools and provide a technical deep dive to help people get started. We hope you’ll join us. We expect safety guidelines and best practices to be an ongoing conversation in the field, and we want your input. We are excited to continue the conversation, find ways to partner, and learn more about what areas matter to you.</p><p>Dive deeper and learn more</p><div><ul><li>Learn more about Llama 2 on the <a href="https://ai.meta.com/llama/" target="_blank" data-lnfb-mode="ie">Llama website</a>, where you can <a href="https://ai.meta.com/llama/get-started/" target="_blank" data-lnfb-mode="ie">get started</a> quickly and get <a href="https://ai.meta.com/llama/faq/" target="_blank" data-lnfb-mode="ie">answers to common questions</a>.</li><li>Learn more about <a href="https://ai.meta.com/llama/responsible-use-guide/" target="_blank" data-lnfb-mode="ie">best practices and considerations</a> for building products powered by LLMs.</li><li>Look for hosted demos by our partners, Together.AI and Anyscale, at NeurIPs in the coming weeks.</li></ul></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How the first gen iPod was reverse engineered to run Rockbox (118 pts)]]></title>
            <link>https://mastodon.social/@bagder/111538350617290554</link>
            <guid>38556636</guid>
            <pubDate>Thu, 07 Dec 2023 14:23:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.social/@bagder/111538350617290554">https://mastodon.social/@bagder/111538350617290554</a>, See on <a href="https://news.ycombinator.com/item?id=38556636">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Lithium Price Collapsed 77% in a Year, as Demand and Production Both Surged (271 pts)]]></title>
            <link>https://wolfstreet.com/2023/11/23/lithium-shortage-bubble-implodes-once-again-as-demand-and-production-both-surged/</link>
            <guid>38556456</guid>
            <pubDate>Thu, 07 Dec 2023 14:06:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wolfstreet.com/2023/11/23/lithium-shortage-bubble-implodes-once-again-as-demand-and-production-both-surged/">https://wolfstreet.com/2023/11/23/lithium-shortage-bubble-implodes-once-again-as-demand-and-production-both-surged/</a>, See on <a href="https://news.ycombinator.com/item?id=38556456">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		    <h3><strong>Investors smell the money, billions are flowing, even in the US, which could become major lithium producer.</strong></h3>
<h4>By&nbsp;<a href="https://wolfstreet.com/author/wolf-richter/" target="_blank" rel="noopener noreferrer">Wolf Richter</a>&nbsp;for&nbsp;<a href="https://wolfstreet.com/" target="_blank" rel="noopener noreferrer">WOLF STREET</a>.</h4>
<p>Who needs fundamentals when you have rampant speculation? And then you can make up a story that fits the speculative narrative, and everyone will jump in, and you’re off to the races. That’s what commodities are all about from time to time. They’re so much fun.</p>
<p>The spot price of battery-grade lithium carbonate, trading in Shanghai and serving as a benchmark, dropped today to CNY 133,500 per tonne, down 77% from the peak a year ago, and below where it had been in 2017.</p>
<p>It had spiked by 1,410% from CNY 39,500 per tonne in August 2020 to CNY 600,000 in November 2022, multiplying by 15 in about 27 months, <em>WHOOSH</em>. The narrative to support the speculative craze was, you guessed it, lithium shortage. But high prices brought lots of new production online. The best cure for high prices is high prices. And soon the new and improved narrative was that there was a lithium glut. And today roughly completes the first full year of a most spectacular collapse in prices.</p>
<p><img fetchpriority="high" decoding="async" src="https://wolfstreet.com/wp-content/uploads/2023/11/US-lithium-carbonate-2023-11-23.png" alt="" width="784" height="581" srcset="https://wolfstreet.com/wp-content/uploads/2023/11/US-lithium-carbonate-2023-11-23.png 784w, https://wolfstreet.com/wp-content/uploads/2023/11/US-lithium-carbonate-2023-11-23-560x415.png 560w, https://wolfstreet.com/wp-content/uploads/2023/11/US-lithium-carbonate-2023-11-23-768x569.png 768w, https://wolfstreet.com/wp-content/uploads/2023/11/US-lithium-carbonate-2023-11-23-260x193.png 260w, https://wolfstreet.com/wp-content/uploads/2023/11/US-lithium-carbonate-2023-11-23-160x119.png 160w" sizes="(max-width: 784px) 100vw, 784px"></p>
<p>We already had a lithium bubble followed by an implosion a few years ago: The prior lithium bubble peaked in 2017, at CNY 175,000, and imploded over the next three years, with the price dropping 77% to CNY 39,500 by August 2020.</p>
<p>Inevitably, when you have so much fun, something even more fun happens: A startup company, Stardust Power, announced on November 21 that it would go public – and you also guessed this – via merger with a SPAC. With the money it expects to raise in the SPAC merger, it will build its first lithium refinery. It already picked out a “shovel-ready” location near Tulsa, OK, to build the lithium refinery and then to supply the EV battery industry.</p>
<p>This Stardust Power announcement comes after the stocks of EV SPACs and a bunch of other companies that had gone public via merger with a SPAC have totally collapsed and entered my pantheon of <a href="https://wolfstreet.com/category/all/imploded-stocks/">Imploded Stocks</a>. So good luck.</p>
<p>Obviously, there is a lot of demand for battery-grade lithium to go into the batteries for the global EV production boom, and thankfully, lithium is abundant around the world and in the US.</p>
<p>In September, we were treated to this headline: “Lithium deposit found in US may be among world’s largest, study finds.” The area is in Nevada. But in the US, permitting issues, local opposition, legal challenges, and costs don’t exactly make starting up lithium production a cakewalk.</p>
<p>Then there is the long-running Lithium Nevada’s $2.3 billion project, which, after overcoming a host of issues, including legal challenges from tribes, is now on schedule to begin production in late 2026 at what could be one of the largest lithium mines in the world.</p>
<p>The big kahuna of the oil-and-gas industry, Exxon Mobil, announced earlier in November that it plans to produce lithium from briny water pumped up from about 10,000 feet in the Smackover Formation in Arkansas. Production is expected to start by 2027 and will eventually supply lithium for well over 1 million EVs per year, according to Reuters. It cited analysts at TD Cowen that estimated this would require Exxon Mobil to invest $2 billion. So that’s going to be good for the economy.</p>
<p>Lithium production at the Salton Sea in California has been kicked around for years. The area has been dubbed Lithium Valley due to its lithium-rich geothermal activity. Three companies are now working on projects using a new technology of extraction that is still largely unproven at scale. Two of the three – BHE Renewables and EnergySource Minerals – own and operate geothermal powerplants in the area, and that’s a pretty good fit. So we’ll see.</p>
<p>All kinds of lithium production projects are being worked on in the US and around the world. Currently, Australia, Chile, and China dominate lithium production. Australia alone accounts for nearly half the global production. The three combined account for about 90% of global production. Everyone is now trying to get in on it. Investors have smelled the money, and the billions are flowing.</p>
<p><i><strong>Enjoy reading WOLF STREET and want to support it? You can donate. I appreciate it immensely. Click on the beer and iced-tea mug to find out how:</strong></i></p>
<p>
<a href="https://wolfstreet.com/how-to-donate-to-wolf-street/" target="_blank" rel="noopener"><img decoding="async" src="https://wolfstreet.com/wp-content/uploads/2019/10/BeerMug2.jpg" alt="" width="100" height="115"></a>
</p>
<p><i><strong>Would you like to be notified via email when WOLF STREET publishes a new article? <a href="https://wolfstreet.com/sign-up-here-for-wolf-street-email-updates/" target="_blank" rel="noopener noreferrer">Sign up here</a>.</strong></i></p>
<p><img decoding="async" src="https://wolfstreet.com/wp-content/uploads/2020/08/placeholder2.png" alt="" width="26" height="65"></p>

	    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Learn SVG with 25 examples – How to code images in HTML (358 pts)]]></title>
            <link>https://svg-tutorial.com/</link>
            <guid>38556116</guid>
            <pubDate>Thu, 07 Dec 2023 13:38:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://svg-tutorial.com/">https://svg-tutorial.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38556116">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
        SVG Tutorial made by <a href="https://bio.link/hunor" target="_blank" rel="noopener">Hunor Márton Borbély</a> in 2023
      </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple and Google confirm governments spy on users through push notifications (110 pts)]]></title>
            <link>https://www.androidauthority.com/apple-google-push-notification-surveillance-3392252/</link>
            <guid>38555810</guid>
            <pubDate>Thu, 07 Dec 2023 12:58:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.androidauthority.com/apple-google-push-notification-surveillance-3392252/">https://www.androidauthority.com/apple-google-push-notification-surveillance-3392252/</a>, See on <a href="https://news.ycombinator.com/item?id=38555810">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div tabindex="0" role="button"><picture><source sizes="(min-width: 64rem) 51.25rem, 80vw" srcset="https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium.jpg.webp 1200w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-300w-170h.jpg.webp 300w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-768w-432h.jpg.webp 768w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-16w-9h.jpg.webp 16w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-32w-18h.jpg.webp 32w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-28w-16h.jpg.webp 28w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-56w-32h.jpg.webp 56w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-64w-36h.jpg.webp 64w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-712w-400h.jpg.webp 712w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-1000w-563h.jpg.webp 1000w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-792w-446h.jpg.webp 792w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-840w-472h.jpg.webp 840w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-770w-433h.jpg.webp 770w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-356w-200h.jpg.webp 356w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-675w-380h.jpg.webp 675w" type="image/webp"><img decoding="async" loading="eager" sizes="(min-width: 64rem) 51.25rem, 80vw" title="Apple WWDC22 iOS16 Lockscreen Notifications 220606 inline.jpg.medium" srcset="https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium.jpg 1200w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-300w-170h.jpg 300w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-768w-432h.jpg 768w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-16w-9h.jpg 16w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-32w-18h.jpg 32w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-28w-16h.jpg 28w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-56w-32h.jpg 56w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-64w-36h.jpg 64w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-712w-400h.jpg 712w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-1000w-563h.jpg 1000w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-792w-446h.jpg 792w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-840w-472h.jpg 840w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-770w-433h.jpg 770w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-356w-200h.jpg 356w, https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium-675w-380h.jpg 675w" alt="Apple WWDC22 iOS16 Lockscreen Notifications 220606 inline.jpg.medium" src="https://www.androidauthority.com/wp-content/uploads/2023/08/Apple-WWDC22-iOS16-Lockscreen-Notifications-220606_inline.jpg.medium.jpg"></picture></div><div><p>TL;DR</p>
<ul>
<li>A US senator has asked the Department of Justice to let Apple and Google disclose how governments surveil users through push notifications.</li>
<li>Apple says the federal government stopped it from being transparent about the practice.</li>
<li>Google has also acknowledged the senator’s plea and said it is committed to keeping users informed about government requests for push notification data.</li>
</ul>
</div><p>Government agencies have been spying on smartphone users through push notifications sent out by apps, a US senator <a href="https://www.documentcloud.org/documents/24191267-wyden_smartphone_push_notification_surveillance_letter_to_doj_-_signed" target="_blank" rel="noopener">wrote in a letter</a> to the Department of Justice on December 6.</p><p>Oregon Senator Ron Wyden has asked the Department of Justice to lift any existing restrictions around discussions of push notification surveillance.</p><p>“I write to urge the Department of Justice (DOJ) to permit Apple and Google to inform their customers and the general public about demands for smartphone app notification records,” Wyden writes in the letter.</p><p>He explains that push notifications pass through a kind of digital post office run by the phone’s operating system providers. “Because Apple and Google deliver push notification data, they can be secretly compelled by governments to hand over this information,” the letter says. This could tell governments how users interact with certain apps, give them access to a notification’s complete text, and disclose some unencrypted content.</p><p>Wyden moved the DOJ to allow Apple and Google to be transparent about the demands they receive from governments regarding push notification surveillance.</p><p>Meanwhile, the two companies welcomed Wyden’s letter and acknowledged that push notification surveillance has been happening for a while. Apple even said it was not allowed to disclose government requests for push notification data but will start informing users about it now.</p><p>“In this case, the federal government prohibited us from sharing any information,” Apple said in a statement published by <a href="https://www.reuters.com/technology/cybersecurity/governments-spying-apple-google-users-through-push-notifications-us-senator-2023-12-06/" target="_blank" rel="noopener"><em>Reuters</em></a>. “Now that this method has become public, we are updating our transparency reporting to detail these kinds of requests.”</p><p>Google also acknowledged the issue and said it shared Wyden’s “commitment to keeping users informed about these requests.” Google’s transparency report already documents governmental requests for users’ push notification data.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Everyday performance rules for Ruby on Rails developers (117 pts)]]></title>
            <link>https://www.rorvswild.com/blog/2023/everyday-performance-rules-for-ruby-on-rails-developers</link>
            <guid>38555768</guid>
            <pubDate>Thu, 07 Dec 2023 12:52:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rorvswild.com/blog/2023/everyday-performance-rules-for-ruby-on-rails-developers">https://www.rorvswild.com/blog/2023/everyday-performance-rules-for-ruby-on-rails-developers</a>, See on <a href="https://news.ycombinator.com/item?id=38555768">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p><em>This post takes inspiration from <a href="https://anthonyhobday.com/sideprojects/saferules">Visual design rules you can safely follow every time</a> by Anthony Hobday.</em></p>

<p>Here, we’re talking about performance rules you can safely follow every time. As with any rules, you are free to break them. You may need a good reason to do so.</p>

<p>We are covering some best practices for HTTP, Ruby, and the database layers so that most applications with decent traffic can improve their response time.
Some of these practices can be obvious to experienced developers. Your applications are on good Rails if you already know and use them all.</p>

<h2>HTTP</h2>

<h3>Use a CDN</h3>

<p>Serve all resources from a CDN. It will reduce latency for your visitors and the number of requests to your server. What’s more, CDNs provide more bandwidth than your servers.</p>

<p>CDNs aren’t expensive, and their rates are very progressive. They are also simple to set:</p>

<pre><code>config.action_controller.asset_host = "cdn.application.example"
</code></pre>

<p>We can’t think of any good reason to do without them except for an application running solely on a private network.</p>

<h3>Enable HTTP compression</h3>

<p>Compression saves bandwidth at a modest CPU cost.
Most web servers, like  <a href="https://httpd.apache.org/docs/current/mod/mod_deflate.html">Apache</a> and <a href="https://nginx.org/en/docs/http/ngx_http_gzip_module.html">Nginx</a>, enable compression by default.
To be sure, verify the presence of <code>Content-Encoding: gzip</code> in the response headers.</p>

<h3>Enable HTTP cache</h3>

<p>A cached resource means one less request for the client and server and, therefore, a faster loading time.<br>
It goes without saying that caching should be enabled for all resources passing through the CDN.</p>

<p>The Cache-Control header gives instructions to browsers and CDNs.
Check that you have a header in the response that looks like this <code>Cache-Control "max-age=86400, public"</code>.
Max age is the duration in seconds, so 24 hours in this case.
It’s up to you to decide whether you need a more aggressive cache.</p>

<p>For private resources, turn off the cache with the <code>Cache-Control: private</code> header.</p>

<h3>Enable keep-alive connections</h3>

<p>Keep-alive connections are reusable.
They prevent having to re-establish a connection, as well as SSL negotiation.
They reduce latency time for all pages made up of several resources.</p>

<p>Web servers often activate them by default.
You can verify the presence of the following header <code>Keep-Alive timeout=5, max=100</code>.
In this example, the connection is closed after 5 seconds of inactivity and can be reused 100 times.</p>

<h2>Ruby</h2>

<h3>Run in the background as much as possible</h3>

<p>Any heavy or latency-intensive task should be run in the background as far as possible.
Sending e-mails is a case in point.<br>
It’s a relatively long task compared with the duration of an HTTP request.
Moreover, its duration is unpredictable since it requires a network connection.
On the other hand, there’s no obligation to send the e-mail during the HTTP request.
So, using the <code>deliver_later</code> method from Rails controllers is a good habit.</p>

<p>As well as reducing response time, it frees up a web process or thread to handle the subsequent request.
So the application can handle a larger volume.
It will also be less vulnerable to a denial-of-service attack.</p>

<h3>Know count, size, and length to save on SQL queries</h3>

<p>It’s important to know the differences between these three methods to ensure you’re triggering the fewest or most optimized SQL queries possible.</p>

<p>The <code>count</code> method always triggers a <code>SELECT count(*) FROM table</code> query.
The <code>length</code> method ensures that the relationship has been loaded to count in memory.
The <code>size</code> method adapts to the loading of the relationship.
Either it triggers a query if it hasn’t been loaded, or it counts in memory if it has already been loaded.
Here’s a summary table:</p>

<table><thead>
<tr>
<th></th>
<th>Records loaded</th>
<th>Record not loaded</th>
</tr>
</thead><tbody>
<tr>
<td>count</td>
<td>SELECT count(*) FROM table</td>
<td>SELECT count(*) FROM table</td>
</tr>
<tr>
<td>size</td>
<td>Count in memory</td>
<td>SELECT count(*) FROM table</td>
</tr>
<tr>
<td>length</td>
<td>Count in memory</td>
<td>SELECT * FROM table</td>
</tr>
</tbody></table>

<p>When counting and enumerating, it’s important to call <code>size</code> after the relationship has been loaded.
In all cases, the aim is to trigger a single request.</p>

<pre><code># Bad 2 queries instead of 1
users = User.all
users.size # SELECT COUNT(*) FROM "users"
users.each { } # SELECT "users".* FROM "users"

# Good
users = User.all
users.length # SELECT "users".* FROM "users"
users.each { } # No queries

# Good
users = User.all
users.each { } # SELECT "users".* FROM "users"
users.size # No queries

# Good
users = User.all.load # SELECT "users".* FROM "users"
users.size # No queries
users.each { } # No queries

# Bad 2 queries instead of 1
users = User.all
users.each { } # SELECT "users".* FROM "users"
users.count # SELECT COUNT(*) FROM "users"
</code></pre>

<h3>Know exists, any/empty, and present/blank to save on SQL queries</h3>

<p>As with <code>count</code>, <code>size</code>, and <code>length</code>, it’s important to know the subtleties of these methods to trigger the fewest and most efficient queries possible.</p>

<p>The <code>exists?</code> method always triggers a query. It is optimized because it stops as soon as it finds a line.
The <code>present?</code> and <code>blank?</code> methods make sure that the query has been executed before checking for their presence or absence in memory.
Finally, the <code>any?</code> and <code>empty?</code> methods adapt if the relationship has already been loaded.
Here’s a summary table:</p>

<table><thead>
<tr>
<th></th>
<th>Loaded</th>
<th>Not loaded</th>
</tr>
</thead><tbody>
<tr>
<td>exists?</td>
<td>SELECT 1 FROM table LIMIT 1</td>
<td>SELECT 1 FROM table LIMIT 1</td>
</tr>
<tr>
<td>any?/empty?</td>
<td>In memory</td>
<td>SELECT 1 FROM table LIMIT 1</td>
</tr>
<tr>
<td>present?/blank?</td>
<td>In memory</td>
<td>SELECT * FROM table</td>
</tr>
</tbody></table>

<p>In this way, we can deduce good and bad uses when we condition a display according to the presence of recordings.</p>

<pre><code># Bad 2 queries instead of 1
users = Users.all
if users.exists? # SELECT 1 FROM users LIMIT 1
  users.each { } # SELECT * FROM users
end

# Good
users = Users.all
if users.present? # SELECT * FROM users
  users.each { } # No queries
end

# Bad 2 queries instead of 1
users = Users.all
if users.any? # SELECT 1 FROM users LIMIT 1
  users.each { } # SELECT * FROM users
end

# Good
users = Users.all.load # SELECT * FROM users
if users.any? # No queries
  users.each { } # No queries
end
</code></pre>

<h3>Use pluck instead of loading ActiveRecord instances when possible</h3>

<p>Pluck allows you to retrieve the raw result of an SQL query and thus avoid creating ActiveRecord instances.
Since there are fewer things to do, it’s inevitably faster and less memory-hungry.
On the other hand, you no longer benefit from the full functionality of an ActiveRecord model.
So it’s a good idea to use it when you don’t need your model’s methods.
We’re thinking in particular of a CSV or text export of several thousand lines.</p>

<pre><code># Slow
CSV.generate do |csv|
  User.all.each { |user| csv &lt;&lt; [user.id, user.name, user.email] }
end

# Fast
CSV.generate do |csv|
  User.pluck(:id, :name, :email).each { |row| csv &lt;&lt; row }
end
</code></pre>

<p>When you need to retrieve a large number of records, try to find a solution with <code>pluck</code>.</p>

<h3>Use symbols or frozen string literals</h3>

<p>By default, Ruby creates a new instance for any string literal, but not for symbols.</p>

<pre><code>"Ruby".object_id #=&gt; 60
"Ruby".object_id #=&gt; 80
"Ruby".object_id #=&gt; 100

:ruby.object_id # =&gt; 710748
:ruby.object_id # =&gt; 710748
:ruby.object_id # =&gt; 710748
</code></pre>

<p>The same chain has been created three times, which is wasteful when the symbol has been reused.
So symbols are more efficient.
A comment at the beginning of each file tells Ruby to freeze and reuse literal strings.</p>

<pre><code># frozen_string_literal: true
"Ruby".object_id #=&gt; 60
"Ruby".object_id #=&gt; 60
"Ruby".object_id #=&gt; 60

:ruby.object_id # =&gt; 710748
:ruby.object_id # =&gt; 710748
:ruby.object_id # =&gt; 710748
</code></pre>

<p>However, the string can no longer be modified, as it has been frozen.
Passing a frozen string to a method you don’t control may result in a FrozenError exception.
You’ll need to duplicate it explicitly.</p>

<pre><code># frozen_string_literal: true
"Ruby".concat(" on Rails") # FrozenError: can't modify frozen String
"Ruby".dup.concat(" on Rails") # =&gt; "Ruby on Rails"
</code></pre>

<h3>Store function results in local variables if needed more than once</h3>

<p>Even if this sounds obvious, it’s not uncommon to read about this kind of code.</p>

<pre><code># Bad
if object.expensive_compute
  puts object.expensive_compute
end

# Good
if result = object.expensive_compute
  puts result
end
</code></pre>

<p>Even with relatively quick methods, it’s a shame to repeat them.</p>

<pre><code># Bad
puts array.first.method1
puts array.first.method2
puts array.first.method3

# Good
object = array.first
puts object.method1
puts object.method2
puts object.method3
</code></pre>

<p>This doesn’t make the code more complicated, and sometimes simplifies it a little.</p>

<h3>Reuse HTTP connections</h3>

<p>For the reasons explained in the <em>Enable keep-alive connections</em> section,
it’s more efficient to reuse the same HTTP connection to execute multiple requests.
Each time, you save the time needed to establish the connection, as well as the SSL negotiation.
This is a significant saving.</p>

<pre><code># Slow, create 5 connections
Net::HTTP.get(url)
Net::HTTP.get(url)
Net::HTTP.get(url)
Net::HTTP.get(url)
Net::HTTP.get(url)

# Fast, by re-using the same connection 5 times
Net::HTTP.start(url.host) do |http|
  http.get(url.path)
  http.get(url.path)
  http.get(url.path)
  http.get(url.path)
  http.get(url.path)
end

# Fast, but without a block
http = Net::HTTP.new(url.host, url.port)
http.start
http.get(url.path)
http.get(url.path)
http.get(url.path)
http.get(url.path)
http.get(url.path)
http.finish
</code></pre>

<p>The easiest way is to make all requests in a block passed to <code>Net::HTTP.start</code>, as you won’t forget to close the connection.
If you can’t group all your requests in one block, you can always start and end them manually.</p>

<h2>Database</h2>

<h3>Tune your Database settings</h3>

<p>By default, most databases are not optimally configured for your use and your server’s capabilities.
If you manage your own database, it’s crucial to do so.<br>
If your database is managed by a third party, it’s just as important to check that this has been done properly.</p>

<p>Fortunately, there are tools available to help you do just that.
For PostgreSQL, we recommend <a href="https://pgtune.leopard.in.ua/">PGTune</a>.
For MySQL, there is MySQLTunner, but we have yet to gain experience with it.</p>

<p>By giving the amount of RAM and number of CPUs, PGTune gives you the best settings for your server. It’s effortless to do.<br>
Then, you only have to copy the settings to the config file.</p>

<p>We like to store those settings into a dedicated file such as <code>/etc/postgresql/16/main/conf.d/pgtune.conf</code>.
If we have to change it in the future, we just need to replace the whole file.
It’s easier for the maintenance.</p>

<p>For SQLite, there are good default since Rails 7.1.
Otherwise you can set those parameters yourself:</p>

<pre><code>PRAGMA journal_mode = WAL;
PRAGMA synchronous = NORMAL;
PRAGMA journal_size_limit = 67108864; -- 64 megabytes
PRAGMA mmap_size = 134217728; -- 128 megabytes
PRAGMA cache_size = 2000;
PRAGMA busy_timeout = 5000;
-- Source: Stephen Margheim
-- https://fractaledmind.github.io/2023/09/21/enhancing-rails-sqlite-performance-metrics
</code></pre>

<h3>SQL will always be faster than your code</h3>

<p>If a task can be performed by the database or your code, let the database take care of it.
It’s faster because all the work is done where the data is.
This means less bandwidth consumption and less latency.
Moreover, your code is unlikely to be better than the database.</p>

<pre><code>  Invoice.pluck(:amount).sum # Slower
  Invoice.sum(:amount) # Faster
</code></pre>

<h3>Index all foreign keys</h3>

<p>The odds for a foreign key to appear in a where clause are very high.
If it’s not the case, probably that the foreign key is useless.
So it’s a no brainer decision to create an index when adding a foreign key.</p>

<p>The disadvantage of indexes is that they slow down table writes.
But very often, the number of reads far exceeds the number of writes.
On the other hand, if your index is never used, it should be deleted.
This information is available in PostgreSQL’s internal tables.
It’s a bit confusing to get into.
Fortunately, tools such as <a href="https://github.com/ankane/pghero">PgHero</a> make it very easy.</p>

<p>So, by default, add an index to each foreign key, then delete the few that are never used.</p>

<h3>Exclude nulls from indexes</h3>

<p>A database index is a B-tree structure.
It is very efficient when data has a high cardinality.
However, when a column allows nulls, it often becomes the most redundant value.
The index is less efficient and takes up more space.
Unless null is an infrequently repeated value, there are only disadvantages to indexing them.<br>
Exclude them when creating the index with a where clause.</p>

<pre><code>add_index :table, :column, where: "(column IS NOT NULL)"
</code></pre>

<p>Or in pure SQL :</p>

<pre><code>CREATE INDEX name ON table (column) WHERE column IS NOT NULL;
</code></pre>

<h3>Do not index column with a low cardinality such as boolean</h3>

<p>The reason is the same as in the previous paragraph.
B-tree indexes work best when cardinality is high.
So a Boolean is the worst column you can index.
So don’t index booleans.</p>

<p>As with other types, if you have very repetitive values that are not significant from a business point of view, it’s probably a good idea to exclude them from the index.
We’re thinking in particular of default values:</p>

<pre><code>add_column :accounts, :balance, default: 0, null: false
add_index :accouns, :balance, where: "(balance != 0)"
</code></pre>

<p>Or in pure SQL:</p>

<pre><code>ALTER TABLE accounts ADD COLUMN balance decimal DEFAULT 0 NOT NULL;
CREATE INDEX index_accounts_balance ON accounts (balance) WHERE balance != 0;
</code></pre>

<h2>Conclusion</h2>

<p>These rules are by no means exhaustive.
Feel free to share your own.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenPGP Forked into "LibrePGP" by GnuPG's Maintainer Werner Koch (171 pts)]]></title>
            <link>https://blog.pgpkeys.eu/critique-critique.html</link>
            <guid>38554943</guid>
            <pubDate>Thu, 07 Dec 2023 10:33:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.pgpkeys.eu/critique-critique.html">https://blog.pgpkeys.eu/critique-critique.html</a>, See on <a href="https://news.ycombinator.com/item?id=38554943">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <h2><a href="https://blog.pgpkeys.eu/">pgpkeys-eu.github.io</a></h2>
      

      


<p>A proposed fork of the OpenPGP standard, called “LibrePGP” and initiated by GnuPG’s maintainer Werner Koch, has made a series of statements on its own website<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup> in order to justify its existence. Some of these criticisms have merit, but most are misleading at best. We address the points raised individually here.</p>

<h2 id="the-critique">The Critique</h2>

<blockquote>
  <p>The IETF OpenPGP Working Group (WG) at some point decided to give up on its charter to produce an updated specification and instead started to re-invent that standard.
Whether this is in line with IETF rules is questionable.</p>
</blockquote>

<p>The crypto-refresh draft<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup> and LibrePGP<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup> are both backwards-compatible with RFC4880, RFC5581, and RFC6687.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup> Neither of them attempt to re-invent any existing standard. Crypto-refresh leaves out many extensions that are included in LibrePGP, in part because the Working Group was <em>not</em> willing to overstep the limitations of the current charter.<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">5</a></sup> Items included in LibrePGP that were intentionally left out of crypto-refresh include:<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" rel="footnote">6</a></sup></p>

<ul>
  <li>Restricted Encryption key flag</li>
  <li>Timestamping usage key flag</li>
  <li>Attested Key Signatures</li>
  <li>Attested Certifications subpacket</li>
  <li>Key Block subpacket</li>
</ul>

<p>These proposed extensions to OpenPGP are compatible with the crypto-refresh draft, and can be specified at a future date once the WG is re-chartered.<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" rel="footnote">7</a></sup></p>

<blockquote>
  <p>Considering that new features and discussions for larger updates of the specification delayed a new RFC for many years and were the reason for closing the WG in 2017 and re-opening in 2020,
we proposed to go back to the last commonly agreed upon draft or to conclude the WG on the grounds that no rough consensus could be found.</p>
</blockquote>

<p>Rough consensus <em>was</em> found; LibrePGP dissents from it.<sup id="fnref:8" role="doc-noteref"><a href="#fn:8" rel="footnote">8</a></sup> <sup id="fnref:9" role="doc-noteref"><a href="#fn:9" rel="footnote">9</a></sup> And one thing that the majority of the WG can agree upon was that the “last commonly agreed upon draft” was not agreed upon at all.</p>

<h2 id="01-symmetric-mode">01 Symmetric Mode</h2>

<blockquote>
  <p>It seems that this new scheme was introduced for the benefit of allowing GCM as yet another encryption mode.
GCM is a counter mode and, as can be seen by the large changes required, is hard to get right.
Meanwhile we have GCM in CMS (the core of S/MIME) because Microsoft decided to go this way.
However, OpenPGP has made its decisions based on technical soundness and not based on larger vendor, government, or committee decision.</p>
</blockquote>

<p>This is the strongest concern that LibrePGP has raised. GCM is hard to get right, but it is widely implemented and its limitations are well-understood.<sup id="fnref:10" role="doc-noteref"><a href="#fn:10" rel="footnote">10</a></sup> Anyone who needs to support GCM in OpenPGP has a large number of well-tested libraries to choose from. Anyone who does not need GCM is not required to implement anything. GCM is OPTIONAL.<sup id="fnref:11" role="doc-noteref"><a href="#fn:11" rel="footnote">11</a></sup></p>

<blockquote>
  <p>The WG once decided to go with OCB and EAX. EAX was only added to avoid possible patent problems.
However, in the 4.5 years since the introduction of EAX, the OCB patent expired.
Thus, there is no more reason to reject OCB, and it should be declared as a RECOMMENDED mode with the intention to make it a MUST mode in some future OpenPGP.</p>
</blockquote>

<p>This paragraph is beside the point, since OCB is already a MUST mode in the OpenPGP crypto-refresh.</p>

<blockquote>
  <p>It can also be expected that FIPS-140 will eventually allow OCB.</p>
</blockquote>

<p>Perhaps, but this is speculation, and no date is suggested.</p>

<blockquote>
  <p>Our suggestion was: Drop all the new AEAD ideas and use what has been deployed and agreed upon in the OpenPGP WG a long time ago.
Further, turn OCB into MUST WG a long time ago. Further, turn OCB into MUST and EAX into MAY (only for backward compatibility with deployed implementations).</p>
</blockquote>

<p>Again, this is <em>already the case</em> in crypto-refresh:<sup id="fnref:12" role="doc-noteref"><a href="#fn:12" rel="footnote">12</a></sup></p>

<blockquote>
  <p>9.6. AEAD Algorithms 
…
Implementations MUST implement OCB. Implementations MAY implement EAX, GCM and other algorithms.</p>
</blockquote>

<p>LibrePGP’s concerns are genuine, but have already been addressed.<sup id="fnref:8:1" role="doc-noteref"><a href="#fn:8" rel="footnote">8</a></sup></p>

<h2 id="02-padding-packet">02 Padding Packet</h2>

<blockquote>
  <p>A padding packet is introduced with the idea to mitigate traffic analysis.
However, it is suggested to use random data for the content of this packet and thus this packet opens a huge covert channel.
This is especially concerning for institutional users efforts regarding Data Leak Prevention (DLP).
Suggestions to use padding based on a verifiable seed, were rejected despite that this is the standard method to do padding.</p>
</blockquote>

<p>OpenPGP already contains numerous potential covert channels.<sup id="fnref:13" role="doc-noteref"><a href="#fn:13" rel="footnote">13</a></sup> Unencrypted padding packets are in many ways <em>safer</em> than those other covert channels, because they are obvious and can (if necessary) be detected and/or removed at e.g. a gateway appliance. The choice of whether to allow padding packets in a given context can still be made at the application layer.</p>

<p>The proposal to mandate verifiable-seed padding was considered in the WG, but consensus could not be reached.<sup id="fnref:14" role="doc-noteref"><a href="#fn:14" rel="footnote">14</a></sup> Many details of how it would work in practice remain unclear.<sup id="fnref:15" role="doc-noteref"><a href="#fn:15" rel="footnote">15</a></sup> Updated guidance for how best to generate padding can still be issued at a later date if consensus is forthcoming.</p>

<blockquote>
  <p>This padding idea has come up in discussion every once in a while over the last 25 years and has always been rejected
because it does not belong into the encryption layer but into the application (plaintext) layer.</p>
</blockquote>

<p>This is not always true. For example, when downloading keys from a keystore, OpenPGP <em>is</em> the application layer. It is not clear for example how else to implement padding in WKD, which only serves binary TPKs.<sup id="fnref:16" role="doc-noteref"><a href="#fn:16" rel="footnote">16</a></sup></p>

<h2 id="03-changes-to-the-ecdh-encryption">03 Changes to the ECDH Encryption</h2>

<blockquote>
  <p>ECDH is the standard way to do encryption with elliptic curves.
For OpenPGP ECDH has been specified in RFC-6637 from 2012 and been implemented by PGP and GnuPG even a year earlier.
Instead of keeping this solid specification some details have been changed without a sound reason.</p>
</blockquote>

<p>The only change to ECDH is that instead of using OpenPGP-specific OIDs to identify ECDH curves (which were never intended to be permanent OID allocations), the new crypto-refresh will use industry-standard OIDs (in v6 packets <em>only</em>).<sup id="fnref:17" role="doc-noteref"><a href="#fn:17" rel="footnote">17</a></sup></p>

<h2 id="04-proliferation-for-algorithms">04 Proliferation for Algorithms</h2>

<blockquote>
  <p>The new draft not only allow the use of GCM as a third encryption mode but adds a couple of other required algorithms:</p>

  <p>HKDF
   Argon2</p>
</blockquote>

<p>HKDF and Argon2 were added to address several known and potential weaknesses in the cryptographic layer of OpenPGP.<sup id="fnref:18" role="doc-noteref"><a href="#fn:18" rel="footnote">18</a></sup> <sup id="fnref:19" role="doc-noteref"><a href="#fn:19" rel="footnote">19</a></sup> <sup id="fnref:20" role="doc-noteref"><a href="#fn:20" rel="footnote">20</a></sup>
LibrePGP does not acknowledge the existence of these issues.</p>

<blockquote>
  <p>Optional modes (EAX, OCB, GCM, and a way to define even more)</p>
</blockquote>

<p>OpenPGP has always been highly extensible, so it’s unclear what the specific objection is here (aside from GCM, which we address elsewhere).</p>

<blockquote>
  <p>Werner Koch joined the AES conference in 2000 on Phil Zimmermann’s wish to talk about algorithm proliferation.
They agreed on pushing the forthcoming AES along with their MDC extension, get Twofish and so out of the focus, and in general resist to add new algorithms.
That is for the simple reason that neither PGP nor GnuPG wanted to maintain all new algorithms until eternity.</p>

  <p>Later, they had to do a political compromise to allow Camellia for the use in Japan and Brainpool curves for European use.
We should really stick to this and not support algorithms which are just a substitute for existing crypto building blocks.
Since added complexity makes a review harder and the larger codebase has to be maintained indefinitely for backwards compatibility.</p>
</blockquote>

<p>This appears to say that it was OK to make a political compromise for the benefit of users who have to comply with some national regulations, but for some reason it is not OK to make a political compromise for the sake of users who have to comply with other national regulations. It might be fair to say that Werner regrets his previous decision and has decided not to repeat that mistake, but that is his personal viewpoint. Others obviously disagree.</p>

<p>Supporting extra algorithms comes at a cost. Whether this cost is “justifiable” is to some extent subjective. Some people think the cost of including GCM is too high, which is fair. If so, they are not required to implement GCM, since GCM is OPTIONAL.<sup id="fnref:11:1" role="doc-noteref"><a href="#fn:11" rel="footnote">11</a></sup></p>

<h2 id="05-removal-of-useful-real-world-features">05 Removal of Useful Real-world Features</h2>

<p>OpenPGP is a long-established standard and has accumulated many features over time. It is good practice to deprecate features that have been found to not work as intended, even if they are useful in theory.</p>

<blockquote>
  <p>For example, in 2016 an m flag was introduced to indicate that the plaintext shall be interpreted as MIME data.
This has been removed along with deprecating the traditional t flag to distinguish between binary and text data.
Having the ability to easily detect MIME data is for example required to process attachments from web mail clients or in air-gaped environments.</p>
</blockquote>

<p>The <code>t</code> flag was deprecated because it did not specify which character set was being used. UTF-8 has long been the standard encoding in OpenPGP, and all “text” usage is therefore already covered by <code>u</code>.<sup id="fnref:21" role="doc-noteref"><a href="#fn:21" rel="footnote">21</a></sup></p>

<blockquote>
  <p>The designated revoker feature has also been deprecated with the rationale that a better method is to achieve this with an “escrowed” revocation, pre-created by the user.
In fact, GnuPG creates such a revocation certificate since version 2.1 (released in 2014), to mitigate the common problem of a forgotten password.
But this is not a replacement for corporate needs: the designated revoker is an important feature to manage a large scale deployments of OpenPGP keys and acts as a CRL (certificate revocation list) replacement.</p>
</blockquote>

<p>No evidence is given that escrowed revocations are less suited to a corporate environment. Escrowed revocations are simple to reason over, and have been supported for decades. By contrast, designated revokers increase the complexity of validity calculations considerably - you cannot be sure if a key has been revoked by looking at the signatures on the key itself, but instead need to have a copy of the revoker’s key, which may not be immediately available. And what happens if the designated revoker’s key is itself revoked?</p>

<h2 id="06-removal-of-security-fixes">06 Removal of Security Fixes</h2>

<blockquote>
  <p>Due to an implementation bug in PGP 5, the metadata of a signed file was not covered by the signatures.
RFC-4880 didn’t fix that for backward compatibility.
However, users were often surprised when they learned that the shown filename and file data could be changed while keeping the signature intact.
With the introduction of the new v5 signature packet format, the opportunity to fix that was taken.</p>

  <p>However, the crypto-refresh group then introduced v6 signatures and removed the fix (see this commit)
with the flimsy explanation that the way to populate that the field is not clear in a theoretical encrypt-then-sign scenario
and that signatures could not be detached and reattached (which is obvioulsy wrong).
A later proposed fix for v4 signature packets (Meta Hash subpacket, see discussion) was not considered.</p>
</blockquote>

<p>An even later proposed fix, to store the metadata in a Signature Notation subpacket, <em>did</em> find initial support.<sup id="fnref:22" role="doc-noteref"><a href="#fn:22" rel="footnote">22</a></sup> Since this merely extends an existing feature of OpenPGP, does not require changes to the wire format, and is therefore currently unchartered, the details were deferred to a future document.</p>

<h2 id="07-salted-signature-issue">07 Salted Signature Issue</h2>

<blockquote>
  <p>Salted signature were introduced with the idea that they might mitigate a chosen prefix attack in the same way as they will do for a certain SHA-1 based Web-of-Trust attack.
No research for that statement has been cited just an assumption and a concern related to fault attacks on EdDSA which is about the development of Wireguard-like protocol.
However, such fault attacks can be more securely detected by checking the signature after verification in the same way as the mitigation to Lenstra’s attack on RSA’s CRT.</p>
</blockquote>

<p>The existence of practical prefix attacks is an assumption. The question is: is it a <em>reasonable</em> assumption? The WG felt it best to err on the side of caution.<sup id="fnref:23" role="doc-noteref"><a href="#fn:23" rel="footnote">23</a></sup></p>

<blockquote>
  <p>Anyway, the major concern here is that this adds another 32 octet covert channel to each message (and also blow the signature up by 64 octets)
In this case it is not an optional feature as with the padding packet.
This is a clear violation of best current practices in sensitive areas where signed mails are mandatory and encryption is not enforced (or monitored by a gateway).</p>
</blockquote>

<p>Covert channels have already been discussed above.</p>

<h2 id="08-regression-from-deployed-formats-and-standard-behavior">08 Regression from Deployed Formats and Standard Behavior</h2>

<p>The section heading is overblown. The crypto-refresh draft and the LibrePGP draft are equally backward-compatible with all deployed OpenPGP artifacts other than those which have been rendered insecure by the passage of time, or experimental deployments.</p>

<blockquote>
  <p>In general the crypto-refresh draft tends to ignore the requirements of long term storage needs and considers online communication and software deployment pattern as the major OpenPGP usage.
Data and software life-cycle management has not been adequately taken in consideration and thus the draft regresses heavily from 30 years of PGP history.</p>
</blockquote>

<p>No example of “ignoring the requirements of long term storage needs” has been given, unless this refers to the OPTIONAL<sup id="fnref:11:2" role="doc-noteref"><a href="#fn:11" rel="footnote">11</a></sup> GCM mode, which being OPTIONAL<sup id="fnref:11:3" role="doc-noteref"><a href="#fn:11" rel="footnote">11</a></sup> can be ignored by such applications.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Of the complaints explicitly raised by LibrePGP, one (GCM) is substantial. The Working Group agreed with those concerns, but balanced them with the requirements of some users for regulatory compliance. OpenPGP has precedent here, having already included Brainpool and Camellia ciphers on similar grounds. All such regulatory-driven extensions to OpenPGP have historically been marked OPTIONAL<sup id="fnref:11:4" role="doc-noteref"><a href="#fn:11" rel="footnote">11</a></sup>, and GCM is no different. OpenPGP crypto-refresh has conformed to established precedent here.</p>

<p>The strongest implicit complaint is that several implementations have already spent significant time developing support for v5 (LibrePGP) artifacts, and that support for v6 (crypto-refresh) would be burdensome. But it is worth pointing out that other implementations with working v5 code are also implementing v6 despite the extra workload incurred.<sup id="fnref:24" role="doc-noteref"><a href="#fn:24" rel="footnote">24</a></sup></p>

<p>The other explicitly-stated complaints can be divided into two classes, neither of which holds up to scrutiny. Most of them are minor technical issues that have been blown out of proportion, e.g. the superficial change in the curve specifier format. Some have even been described, on the record, as acceptable compromises by Werner in previous discussions.<sup id="fnref:25" role="doc-noteref"><a href="#fn:25" rel="footnote">25</a></sup> <sup id="fnref:26" role="doc-noteref"><a href="#fn:26" rel="footnote">26</a></sup> It would appear therefore that these concerns have been included purely to bulk out the list of grievances.</p>

<p>The remaining explicit complaints (touched upon in the preamble) concern IETF procedure, in which case there is a route of appeal via the IETF itself.<sup id="fnref:27" role="doc-noteref"><a href="#fn:27" rel="footnote">27</a></sup> It is not apparent that such an appeal has even been submitted, let alone ruled upon.</p>

<p>There is also one implicit complaint that is only hinted upon in the text, and that is the increasing breakdown in personal trust between Werner and the wider OpenPGP community.<sup id="fnref:28" role="doc-noteref"><a href="#fn:28" rel="footnote">28</a></sup></p>

<p>It is obvious that LibrePGP is an attempt to create facts on the ground that prejudice the conclusion of the IETF standardisation process, in order to maintain the pre-eminent position of one OpenPGP implementation (GnuPG) at the expense of others. It is also impossible to avoid concluding that the target of this power play is the rival implementation that is currently led by two ex-employees of Werner, with whom he has a long-standing and well-documented personal conflict.<sup id="fnref:29" role="doc-noteref"><a href="#fn:29" rel="footnote">29</a></sup> <sup id="fnref:30" role="doc-noteref"><a href="#fn:30" rel="footnote">30</a></sup></p>

<p>Normally, personal conflicts are best left to be resolved at a personal level, but not when they fester to the point where they threaten to destroy an entire community. The root cause of this is not technical but personal, and the solution is therefore not technical but personal.</p>

<h2 id="a-way-forward">A way forward</h2>

<p>One important fact that every single person working in OpenPGP agrees upon is that OpenPGP is in a precarious position. Disagreements over governance and personal animosity have left it to stagnate, even as privacy and security technologies in general have advanced. Without fundamental changes in how OpenPGP functions as a community of human beings, it faces another lost decade at best, if not outright collapse. Actions that deliberately or carelessly foster further division are <em>not constructive</em>. We all have a responsibility to conduct ourselves in a professional manner for the sake of the community that some of us still believe in, even if it does not look particularly inspiring right now.</p>

<p>At this point in time, the OpenPGP community desperately needs to see some acts of good faith.
We strongly suggest that these should include the following:</p>

<ul>
  <li>The librepgp.org website shall be shut down. The draft-koch-librepgp I-D<sup id="fnref:3:1" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup> shall remain active as a reference.</li>
  <li>The OpenPGP Working Group shall, in accordance with its draft charter, begin the process of adopting the WKD protocol as described in draft-koch-openpgp-webkey-service<sup id="fnref:16:1" role="doc-noteref"><a href="#fn:16" rel="footnote">16</a></sup> as a WG standards track document, engaging in good faith with its author at all times.</li>
  <li>GnuPG shall merge <a href="https://dev.gnupg.org/T4393">https://dev.gnupg.org/T4393</a>, and desist from vetoing constructive contributions for personal reasons.</li>
  <li>The OpenPGP WG shall, as a matter of good faith, endeavour for the duration of its new charter to maintain in its work queue at all times at least one of the unchartered items already implemented in v5,<sup id="fnref:6:1" role="doc-noteref"><a href="#fn:6" rel="footnote">6</a></sup> with reference to existing v5 implementations, to the extent that security and practicality concerns permit.</li>
</ul>

<p>If these things should happen, in whatever order but preferably the order listed, we can then begin the process of discussing the medium-term future of OpenPGP in a professional manner. This SHOULD include a commitment by all implementations to at minimum consume both v5 and v6 artifacts on a best-effort basis, even if they have a preference for which standard to ahdere to when generating artifacts. This should be sufficient to ensure that end users are not adversely affected by ongoing disagreements between implementations on the long term path forward.</p>

<h2 id="references">References</h2>




      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[He blew the whistle on Amazon. He's still paying the price (323 pts)]]></title>
            <link>https://www.ft.com/content/de5fea12-2938-4c20-b394-10ca258a5fa1</link>
            <guid>38554159</guid>
            <pubDate>Thu, 07 Dec 2023 08:27:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/de5fea12-2938-4c20-b394-10ca258a5fa1">https://www.ft.com/content/de5fea12-2938-4c20-b394-10ca258a5fa1</a>, See on <a href="https://news.ycombinator.com/item?id=38554159">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="barrier-page">
<div data-o-grid-colspan="12 L6" data-component="articleBanner" data-component-unique-name="default"><p>Keep abreast of significant corporate, financial and political developments around the world. Stay informed and spot emerging risks and opportunities with independent global reporting, expert commentary and analysis you can trust.</p></div>
<div data-component="unlockBanner" data-component-unique-name="default"><p><img src="https://www.ft.com/__assets/creatives/optimizely/MAR090/key_icon.svg" alt=""><span id="text-unlockBanner-default">Subscribe to unlock this article</span></p></div>
<div data-theme="" data-component="heroOffer" data-component-unique-name="CHE-Print"><div data-o-grid-colspan="12"><p><h3>Try unlimited access</h3>
<h3><strong>Only CHF 1 for 4 weeks</strong></h3></p></div><div><div data-o-grid-colspan="12 M6"><ul>
<li>Then CHF 79 per month</li>
<li>New customers only</li>
<li>Cancel anytime during your trial</li>
</ul></div><div data-o-grid-colspan="12 M6"><p><a id="charge-button-CHE-Print" data-trackable="41218b9e-c8ae-c934-43ad-71b13fcb4465" href="https://www.ft.com/buy/offer/41218b9e-c8ae-c934-43ad-71b13fcb4465/"><span><p>Keep reading for CHF 1</p></span></a></p></div></div></div>
<p data-component="subscriptionOptionsHeader" data-component-unique-name="default"><h4 id="text-subscriptionOptionsHeader-default">Explore our subscriptions</h4></p>
<div data-component="subscriptionOptions" data-component-unique-name="CHE-Print"><div><h5 id="title-CHE-Print">Individual</h5><p>Find the plan that suits you best.</p><ul><li data-text="Digital"><a id="button1-CHE-Print" data-trackable="digital" href="https://subs.ft.com/digital_edit?ft-content-uuid=7da5d7e5-2c4d-4619-9c81-294d9a634ac4">Digital</a></li><li data-text="Print"><a id="button2-CHE-Print" data-trackable="print" href="https://subs.ft.com/spa3_uk3m?segmentId=461cfe95-f454-6e0b-9f7b-0800950bef25&amp;utm_us=JJIBAX&amp;utm_eu=WWIBEAX&amp;utm_ca=JJIBAZ&amp;utm_as=FIBAZ&amp;ft-content-uuid=7da5d7e5-2c4d-4619-9c81-294d9a634ac4">Print</a></li><li data-text="Print + Digital"><a id="button3-CHE-Print" data-trackable="digital-print" href="https://subs.ft.com/bundleoptions?segmentId=de88addc-8125-43ec-21f1-152c9886e67f&amp;utm_us=JJIBAX&amp;utm_eu=WWIBEAX&amp;utm_ca=JJIBAZ&amp;utm_as=FIBAZ">Print + Digital</a></li></ul></div></div>
<div data-component="subscriptionOptions" data-component-unique-name="default"><div><h5 id="title-default">Professional</h5><p>Premium access for businesses and educational institutions.</p><ul><li data-text="Get Started"><a id="button1-default" data-trackable="professional" href="https://professional.ft.com/en-gb/services/professional-subscriptions/?barrierName=anon_barrier&amp;ft-content-uuid=7da5d7e5-2c4d-4619-9c81-294d9a634ac4&amp;segmentId=9fbe4fe1-9315-3d67-cc6d-2bc7650c4aea">Get Started</a></li><li data-text=""><a id="button2-default" data-trackable="" href=""></a></li><li data-text=""><a id="button3-default" data-trackable="" href=""></a></li></ul><p>Check if your <a href="https://www.ft.com/licence-finder?segmentId=a0e9a794-4c6d-bb35-e4dc-8bd409e0f54f" data-trackable="edu-finder">university</a> or <a href="https://enterprise.ft.com/licence-finder?segmentId=9fb23d7d-afe4-12f3-3eaa-ff7a41e9d073" data-trackable="license-finder">organisation</a> offers FT membership to read for free.</p>
</div></div>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building end-to-end security for Messenger (263 pts)]]></title>
            <link>https://engineering.fb.com/2023/12/06/security/building-end-to-end-security-for-messenger/</link>
            <guid>38552789</guid>
            <pubDate>Thu, 07 Dec 2023 04:21:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://engineering.fb.com/2023/12/06/security/building-end-to-end-security-for-messenger/">https://engineering.fb.com/2023/12/06/security/building-end-to-end-security-for-messenger/</a>, See on <a href="https://news.ycombinator.com/item?id=38552789">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

		<ul>
<li aria-level="1"><span>We are beginning to upgrade people’s personal conversations on Messenger to use end-to-end encryption (E2EE) by default</span></li>
<li aria-level="1"><span>Meta is publishing two technical white papers on end-to-end encryption:</span>
<ul>
<li aria-level="1"><span>Our <a href="https://engineering.fb.com/wp-content/uploads/2023/12/MessengerEnd-to-EndEncryptionOverview_12-6-2023.pdf" target="_blank" rel="noopener">Messenger end-to-end encryption whitepaper </a>describes the core cryptographic protocol for transmitting messages between clients.</span></li>
<li aria-level="1"><span>The <a href="https://engineering.fb.com/wp-content/uploads/2023/12/TheLabyrinthEncryptedMessageStorageProtocol_12-6-2023.pdf" target="_blank" rel="noopener">Labyrinth encrypted storage protocol whitepaper</a> explains our protocol for end-to-end encrypting stored messaging history between devices on a user’s account.</span></li>
</ul>
</li>
</ul>
<p><span>Today, we’re announcing that we’ve begun to upgrade people’s personal conversations on Messenger to use E2EE by default. Our aim is to ensure that everyone’s personal messages on Messenger can only be accessed by the sender and the intended recipients, and that everyone can be sure the messages they receive are from an authentic sender.</span></p>
<p><span>This is the most significant milestone yet for this project, which began in earnest after </span><a href="https://www.facebook.com/notes/2420600258234172/" target="_blank" rel="noopener"><span>Mark Zuckerberg outlined his vision for it in 2019</span></a><span>. Bringing E2EE to Messenger has been a complex process, with every feature and product goal revealing further challenges that required careful consideration.</span></p>
<p><span>Enabling E2EE on Messenger meant fundamentally rebuilding many aspects of the application its protocols to improve privacy, security, and safety while simultaneously maintaining the features that have made Messenger so popular.&nbsp;</span></p>
<h2><span>Why we’re bringing E2EE to Messenger</span></h2>
<p><span>Messenger first</span> <a href="https://about.fb.com/news/2016/07/messenger-starts-testing-end-to-end-encryption-with-secret-conversations/" target="_blank" rel="noopener"><span>built end-to-end encrypted chats in 2016 </span></a><span>as a feature called Secret Conversations. Since then, we’ve learned a great deal in regards to rolling out E2EE for a wider user base. For example, we recently published an updated</span> <span>white paper, “</span><a href="https://messengernews.fb.com/wp-content/uploads/2021/12/Metas-approach-to-safer-private-messaging-on-Messenger-and-Instagram-DMs-Sep-23.pdf" target="_blank" rel="noopener">Meta’s Approach to Safer Private Messaging on Messenger and Instagram Direct Messaging</a>,” t<span>hat sets out the industry-leading safety systems and tools available on Messenger.</span></p>
<p><span>End-to-end encryption isn’t about the technology at its core. It’s about protecting people’s communications, so they can feel safe expressing themselves with their friends and loved ones. To&nbsp; achieve this, we typically focus on two aims:</span></p>
<ol>
<li aria-level="1"><span>Only the sender and recipients of an E2EE message can see its contents.</span></li>
<li aria-level="1"><span>Nobody (not even Meta) should be able to forge messages to appear to have been sent from someone they weren’t.</span></li>
</ol>
<p><span>In other words, the aim is that only you and the people you’re corresponding with can read your messages – not even the app’s provider (in this case, Meta) could interfere with their contents – and you can be confident in who sent the messages.&nbsp;</span></p>
<h2><span>Understanding these goals</span></h2>
<p><span>These two aims are broad. However, when we reflect on our approach to addressing them, they end up breaking down into eight overlapping concepts that we believe achieve a cohesive approach to meaningful E2EE:&nbsp;</span></p>
<h3><span>1. Confidentiality in transit</span></h3>
<p><span>Message contents are authentically and securely transmitted between your devices and those of the people you’re talking to. This is, perhaps, the primary goal of E2EE, and is where much E2EE research and design work is targeted, such as the Signal protocol we use in our products (such as WhatsApp, Messenger, and Instagram Direct), or the </span><a href="https://datatracker.ietf.org/doc/rfc9420/" target="_blank" rel="noopener"><span>IETF’s Messaging Layer Security protocol</span></a><span>, which we helped to design and was recently standardized.</span></p>
<h3><span>2. Confidentiality in storage</span></h3>
<p><span>Typically, E2EE messaging services rely on local storage and encryption keys to secure encrypted messages. Messenger, however, has a long history of storing people’s messages for them so that they can access them whenever they need without having to store them locally. That’s why we’ve designed a server-based solution where encrypted messages can be stored on Meta’s servers while only being readable using encryption keys under the user’s control.&nbsp;</span></p>
<h3><span>3. Control over endpoints</span></h3>
<p><span>For something to be “end-to-end encrypted,” it is necessary to have a notion of what the “ends” are. For an E2EE messaging app this means that users should have the ability to verify and manage their set of endpoint devices that are receiving their messages, as well as visibility into when this set of devices changes.</span></p>
<h3><span>4. Private feature designs</span></h3>
<p><span>Product features in an E2EE setting typically need to be designed to function in a device-to-device manner, without ever relying on a third party having access to message content. This </span><a href="https://messengernews.fb.com/2023/08/22/expanding-testing-for-end-to-end-encryption-on-messenger/"><span>was a significant effort for Messenger</span></a><span>, as much of its functionality has historically relied on server-side processing, with certain features difficult or impossible to exactly match with message content being limited to the devices.</span></p>
<h3><span>5. Logging limitations</span></h3>
<p><span>Maintaining the confidentiality of message content extends to avoiding accidentally leaking it back to us in telemetry. In a product of Messenger’s scale, complexity, and iteration speed, this creates particular challenges&nbsp;as telemetry is vital in ensuring that the product is working well for people, and in debugging when things go wrong.</span></p>
<h3><span>6. Application security</span></h3>
<p><span>It’s a common saying that, “You can’t have privacy without security,” and this is absolutely true in the end-to-end encrypted domain. Security is important for any consumer product, but E2EE exacerbates the challenges in two important ways: it reduces the provider’s ability to protect the user from attacks, and, in fact, it expands the threat model to include the service provider itself. Our security team is keenly aware of these challenges and works closely with product teams to secure design and implementation of E2EE functionality. For example, we’ve been working to improve the memory safety of our apps; and our E2EE surfaces are covered by our <a href="https://www.facebook.com/whitehat" target="_blank" rel="noopener">bug bounty program</a>.</span></p>
<h3><span>7. Being deliberate about what’s being protected</span></h3>
<p><span>E2EE protects message content. However, this is a complex term to define, and, while certain things are relatively clear – such as the strings contained in a text message, or a photograph sent from your camera roll – in a sufficiently complex messaging application, it turns out there’s a surprisingly large grey area.&nbsp; Our focus is on determining the appropriate boundaries, ensuring that we remain true to our commitments, setting the correct user expectations, and avoiding creating meaningful privacy risks, while still ensuring that the product retains its usefulness to our users.</span></p>
<h3><span>8. Third-party scrutiny</span></h3>
<p><span>E2EE implies confidentiality even if the provider wants to access the contents of a communication. We aim for this to be verifiable externally, and, to this end, have published two white papers to provide transparency into our operations. We describe the properties of some features in our Help Center, and we encourage submissions to our <a href="https://www.facebook.com/whitehat" target="_blank" rel="noopener">bug bounty program</a>. Throughout the project, we have consulted with a diverse range of external parties to ensure that we’re making the right set of tradeoffs. To improve people’s ability to scrutinize us, we also support </span><a href="https://engineering.fb.com/2022/03/10/security/code-verify/" target="_blank" rel="noopener"><span>the Code Verify browser extension</span></a><span> for our web-based end-to-end encrypted messaging, to give security researchers greater confidence that the code version that they are assessing is being used globally.&nbsp;</span></p>
<h2><span>High-level approach</span></h2>
<p><span>With all of this in mind, our high-level approach was to build off of Meta’s prior learnings in E2EE, from both <a href="https://engineering.fb.com/2021/09/10/security/whatsapp-e2ee-backups/" target="_blank" rel="noopener">WhatsApp</a> and Messenger’s Secret Conversations, and then to iterate on our most challenging problems.&nbsp;</span></p>
<p><span>Working from the baseline of these two approaches, we then had to address a series of significant technical challenges, including:</span></p>
<ol>
<li><span><strong>Multi-device capability</strong>: Messenger’s model of multi-device reflects the Facebook network, which allows people to authenticate on new devices with a username and password, in order to send and receive messages. Since <a href="https://engineering.fb.com/2021/07/14/security/whatsapp-multi-device/" target="_blank" rel="noopener">WhatsApp’s multi-device capability</a> relies on a single primary device that must cryptographically authenticate companion devices, we adopted the Secret Conversations model of multi-device, while ensuring that it functions well for all of our users.</span></li>
<li><span><strong>Feature support</strong>: Messenger has a number of messaging features that either don’t exist in WhatsApp, or function differently. Some of these just had to be rebuilt from scratch, while others required deploying new applied privacy technology. For example, we used </span><a href="https://datatracker.ietf.org/wg/ohai/about/" target="_blank" rel="noopener"><span>OHAI</span></a><span> and </span><a href="https://engineering.fb.com/2022/03/30/security/de-identified-authentication-at-scale/" target="_blank" rel="noopener"><span>Anonymous Credentials</span></a><span> to support searches of Facebook’s first-party sticker library, without revealing to us who is sending them.</span></li>
<li><span><strong>Message history</strong>: Messenger has always allowed clients to operate off of a small stored local cache, relying on a server-side database for their message history. Neither WhatsApp nor Secret Conversations operated in this manner, and we didn’t want all users to have to rely on a device-side storage system. Instead, we designed an entirely new encrypted storage system called <a href="https://engineering.fb.com/wp-content/uploads/2023/12/TheLabyrinthEncryptedMessageStorageProtocol_12-6-2023.pdf" target="_blank" rel="noopener">Labyrinth</a>, with ciphertexts uploaded to our servers and loaded on-demand by clients, while operating in a multi-device manner and supporting key rotation when clients are removed.</span></li>
<li><span><strong>Web support</strong>: We needed to support E2EE within our existing web surfaces, including the main Facebook site. The Web platform carries significantly different constraints from native apps, meaning that we needed to take custom approaches to many different aspects of the product. Further, Web users often add and remove devices in very different patterns from mobile-only users, increasing the complexity of our multi-device challenge.</span></li>
</ol>
<h2><span>Learn more about E2EE on Messenger</span></h2>
<p><span>Today, we are sharing two white papers:</span></p>
<ul>
<li aria-level="1"><span>Our </span><a href="https://engineering.fb.com/wp-content/uploads/2023/12/MessengerEnd-to-EndEncryptionOverview_12-6-2023.pdf"><span>Messenger end-to-end encryption whitepaper</span></a><span>, which describes the core cryptographic protocol for transmitting messages between clients.</span></li>
<li aria-level="1"><span>The </span><a href="https://engineering.fb.com/wp-content/uploads/2023/12/TheLabyrinthEncryptedMessageStorageProtocol_12-6-2023.pdf"><span>Labyrinth encrypted storage protocol whitepaper</span></a><span>, describing our protocol for end-to-end encrypting stored messages history between devices on a user’s account.</span></li>
</ul>
<p><span>These add to a number of publications that we have shared which cover Messenger’s E2EE, including:</span></p>
<ul>
<li aria-level="1"><span>Our recently updated </span><a href="https://messengernews.fb.com/wp-content/uploads/2021/12/Metas-approach-to-safer-private-messaging-on-Messenger-and-Instagram-DMs-Sep-23.pdf" target="_blank" rel="noopener"><span>Safety whitepaper</span></a></li>
<li aria-level="1"><span>The independent </span><a href="https://about.fb.com/news/2022/04/expanding-end-to-end-encryption-protects-fundamental-human-rights/" target="_blank" rel="noopener"><span>E2EE Human Rights Impact Assessment</span></a></li>
<li aria-level="1"><span>Our </span><a href="https://engineering.fb.com/wp-content/uploads/2022/07/Meta-Security-Principles-for-Private-Messaging-White-Paper-July-2022-2.pdf" target="_blank" rel="noopener"><span>Security Principles whitepaper</span></a></li>
<li aria-level="1"><span>The </span><a href="https://engineering.fb.com/2022/03/10/security/code-verify/" target="_blank" rel="noopener"><span>Code Verify browser extension</span></a></li>
</ul>
<h2><span>Beyond E2EE for Messenger</span></h2>
<p><span>The journey to bring E2EE to Messenger has been a long one, but it’s not yet finished. While we are globally launching default E2EE for personal one-to-one messages on Messenger, we are still in the testing phase for group messaging and some other products, like Instagram Direct Messages. On Instagram, we are currently testing “disappearing messages” for one-to-one Instagram Direct conversations in select countries. Disappearing messages are ephemeral and, as with those in Messenger, expire 24 hours after being sent. They are built leveraging our E2EE infrastructure and provide an increased level of privacy. We plan to expand this work as well as conduct additional testing around E2EE on Instagram over the next year.</span></p>

		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Windows 11 is last in gaming performance tests against 3 Linux gaming distros (120 pts)]]></title>
            <link>https://www.notebookcheck.net/Windows-11-scores-dead-last-in-gaming-performance-tests-against-3-Linux-gaming-distros.778624.0.html</link>
            <guid>38552159</guid>
            <pubDate>Thu, 07 Dec 2023 02:39:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.notebookcheck.net/Windows-11-scores-dead-last-in-gaming-performance-tests-against-3-Linux-gaming-distros.778624.0.html">https://www.notebookcheck.net/Windows-11-scores-dead-last-in-gaming-performance-tests-against-3-Linux-gaming-distros.778624.0.html</a>, See on <a href="https://news.ycombinator.com/item?id=38552159">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="c10575187"><figure><a href="https://www.notebookcheck.net/fileadmin/Notebooks/News/_nc4/steam-deck-windows-vs-linux-teaser.jpeg" title="Linux has taken the gaming performance crown from Windows in a recent test. (Image source: various - edited)" data-fancybox="news_intro_image" data-caption="Linux has taken the gaming performance crown from Windows in a recent test. (Image source: various - edited)" data-title-id="lightbox_title_news_intro_image"><picture><source srcset="https://www.notebookcheck.net/fileadmin/_processed_/webp/Notebooks/News/_nc4/steam-deck-windows-vs-linux-teaser-jpeg-q82-w240-h.webp 1x, https://www.notebookcheck.net/fileadmin/_processed_/webp/Notebooks/News/_nc4/steam-deck-windows-vs-linux-teaser-jpeg-q82-w480-h.webp 2x" type="image/webp"><img src="https://www.notebookcheck.net/fileadmin/_processed_/0/6/csm_steam-deck-windows-vs-linux-teaser_92d0494271.jpg" loading="lazy" width="240" height="160" alt="Linux has taken the gaming performance crown from Windows in a recent test. (Image source: various - edited)"></picture></a><figcaption>Linux has taken the gaming performance crown from Windows in a recent test. (Image source: various - edited)</figcaption></figure><div><p>Recent testing revealed that Arch Linux, Pop!_OS, and even Nobara Linux, which is maintained by a single developer, all outstripped Windows for the performance crown on Windows-native games. The testing was run at the high-end of quality settings, and Valve's Proton was used to run Windows games on Linux. </p></div></div><div id="c10575186">
<p>Since Valve's Proton compatibility layer came about, there has been a lot of discussion about the performance implications of running games with a go-between. While Linux users have long espoused the performance benefits of Linux over Windows, Proton introduces some overhead, which could result in performance degradation in games. </p>
<p>As it turns out, according to testing by <a href="https://www.computerbase.de/2023-12/welche-linux-distribution-zum-spielen/2/" target="_blank">German outlet ComputerBase</a>, the opposite may be true, or it at least appears to be true that Windows has more going on in the background that does hinder performance. The outlet tested three different Linux distributions — Arch Linux, the base of SteamOS, Nobara Linux, a fork of Fedora, and <a href="https://www.notebookcheck.net/Lemur-Pro-System76-refreshes-Linux-laptop-with-Intel-Raptor-Lake-U-series-processors.719285.0.html" target="_blank">Pop!_OS by System76</a> — across five Windows games and found that in most scenarios, Linux beats out Windows. </p>
<p>When it comes to FPS, the overall leader in testing was Nobara Linux, with Arch Linux and Pop!_OS trailing by 1–5%. <a href="https://www.notebookcheck.net/Windows-11-steals-users-as-Steam-Deck-dominates-Linux-gaming-in-November-Steam-survey.777099.0.html" target="_self">Windows 11</a>, however, was only 6% behind Nobara Linux. So, there isn't a massive performance delta here, but it's an important milestone for Linux to be consistently ahead of Windows — especially in games designed to run on Windows. </p>
<p>In case you haven't heard of <a href="https://start.nobaraproject.org/" target="_blank">Nobara Linux</a>, it's a Fedora-based Linux distribution maintained by <a href="https://github.com/GloriousEggroll" target="_blank">GloriousEggroll</a> (Thomas Crider) — a Red Hat Software Engineer who is also responsible for ProtonGE, a modified version of Steam's Proton that often includes performance fixes and features not found in Valve's standard Proton. The point of Nobara is to deliver an easy-to-use Fedora that has been modified for gaming, so it makes sense that it scores well in gaming applications.&nbsp; </p>
<p>Of the games tested — <i>Cyberpunk 2077</i>, <i>Forspoken</i>, <i>Ratchet &amp; Clank: Rift Apart</i>, <i>Starfield</i>, and <i>The Talos Principle II</i> — Windows lost by the biggest margin in The Talos Principle II, where it scored just 65.1 FPS, compared to the leader, Nobara Linux, and its 71.5 FPS.&nbsp; </p>
<p>The impressive FPS deltas aside, it should be mentioned that, with the exception of Arch Linux, average frame times (measured as 1% lows, in this case) on Linux were generally behind what Windows managed by up to 20%, although frame times were all over the place, so the average may need to be taken with a grain of salt.&nbsp; </p>
<p><i><i></i></i>Curiously, <i>The Talos Principle II</i> is where Windows excelled the most in terms of 1% lows, scoring a whole 14% better than the nearest competition, Pop!_OS. The only Linux distribution to consistently challenge Windows 11 when it comes to frame times is Arch Linux, which beat Microsoft's OS in <i>Cyberpunk 2077</i>, <i>Forspoken</i>, and <i>Starfield</i>. </p>
<p>Arch Linux's success in both FPS — where it scored within 3% of the fastest system in this round of testing — and frame times may give some insight into why Valve switched from Debian to Arch Linux for the base of its SteamOS for the Steam Deck (<a href="https://www.amazon.com/Valve-Handheld-Console-No-Operating-System/dp/B0BBQRYN9M?tag=nbcnewsnet-20" rel="sponsored" target="_blank">curr. US$626.98 on Amazon</a>), and switching to Linux might be worthwhile for gamers on the move looking to eke out every last drop of performance from the <a href="https://www.notebookcheck.net/Asus-ROG-Ally-Z1-Extreme-Review-Gaming-handheld-with-120-Hz-display-and-AMD-Zen4.716680.0.html" target="_self">ROG Ally</a> (<a href="https://bestbuy.7tiv.net/c/2581420/614286/10014?subId2=nbcnews&amp;u=https%3A%2F%2Fwww.bestbuy.com%2Fsite%2Fasus-rog-ally-7-120hz-fhd-1080p-gaming-handheld-amd-ryzen-z1-extreme-processor-512gb-white%2F6542964.p%3FskuId%3D6542964" rel="sponsored" target="_blank">curr. US$599.99 at Best Buy</a>) or Lenovo Legion Go (<a href="https://bestbuy.7tiv.net/c/2581420/614286/10014?subId2=nbcnews&amp;u=https%3A%2F%2Fwww.bestbuy.com%2Fsite%2Flenovo-legion-go-8-8-144hz-wqxga-gaming-handheld-amd-ryzen-z1-extreme-16gb-with-1-tb-ssd-shadow-black%2F6559604.p" rel="sponsored" target="_blank">curr. US$699.99 at Best Buy</a>). </p></div><div itemscope="" itemtype="http://schema.org/Person" rel="author"><div><a href="https://www.notebookcheck.net/Notebookcheck-Team.212978.0.html?&amp;tx_nbc2journalist_pi1%5Bmode%5D=show&amp;tx_nbc2journalist_pi1%5Buid%5D=324"><picture><source srcset="https://www.notebookcheck.net/fileadmin/_processed_/f/1/csm_julian_van_der_merwe_2cd6bb9418.jpg 1x, https://www.notebookcheck.net/fileadmin/_processed_/f/1/csm_julian_van_der_merwe_157959b004.jpg 2x"><img src="https://www.notebookcheck.net/fileadmin/_processed_/f/1/csm_julian_van_der_merwe_2cd6bb9418.jpg" loading="lazy" width="120" height="120" alt="Julian van der Merwe"></picture></a></div><p><a href="https://www.notebookcheck.net/Notebookcheck-Team.212978.0.html?&amp;tx_nbc2journalist_pi1%5Bmode%5D=show&amp;tx_nbc2journalist_pi1%5Buid%5D=324">Julian van der Merwe</a> - Magazine &amp; Specialist News Writer <span title="492&nbsp;"> - 492 articles published on Notebookcheck</span> since 2022</p><p>My interest in tech started in high school, rooting and flashing my Motorola Defy, but I really fell down the rabbit hole when I realised I could overclock the i7 930 in my Gigabyte pre-built PC. This tinkering addiction eventually lead me to study product design in university. I think tech should improve the lives of the people using it, no matter the field. I like to read and write about laptops, smartphones, software and trends in technology. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[23andMe updates their TOS to force binding arbitration (348 pts)]]></title>
            <link>https://stackdiary.com/23andme-updates-tos-to-force-binding-arbitration/</link>
            <guid>38551890</guid>
            <pubDate>Thu, 07 Dec 2023 01:54:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stackdiary.com/23andme-updates-tos-to-force-binding-arbitration/">https://stackdiary.com/23andme-updates-tos-to-force-binding-arbitration/</a>, See on <a href="https://news.ycombinator.com/item?id=38551890">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<p>23andMe, the personal genomics and biotechnology company, has been trying to contain a security breach that was <a href="https://www.bloomberg.com/news/articles/2023-10-06/hacker-puts-23andme-user-data-up-for-sale-on-the-internet" target="_blank" rel="noreferrer noopener">first disclosed on October 6th</a>. On <a href="https://www.theverge.com/2023/10/19/23923861/23andme-possible-data-leak-hack" target="_blank" rel="noreferrer noopener">October 19th</a>, 23andMe disclosed <em>another</em> security breach by the same hacker who had initially claimed responsibility. The hacker said he had access to more than 4 million genetic profile records this time. And on December 4th, <a href="https://www.theverge.com/2023/12/4/23988050/23andme-hackers-accessed-user-data-confirmed" target="_blank" rel="noreferrer noopener">23andMe confirmed</a> that the total scope of the breach was 6.9 million users in total.</p>



<p>The fallout of this disclosure, which started in October, was swift. By October 14th, several individuals had already filed lawsuits against 23andMe for negligence, as <a href="https://stackdiary.com/23andme-sued-by-users-over-data-breach/" target="_blank" rel="noreferrer noopener"><em>Stack Diary</em> reported</a>. Likewise, the general consensus of 23andMe users has been that the company handled the situation very poorly.</p>



<p>To add insult to injury, <em>Stack Diary</em> can reveal that 23andMe is now rolling out an update to its <a href="https://www.23andme.com/en-int/legal/terms-of-service/" target="_blank" rel="noreferrer noopener">Terms of Service</a>. This change will force its users into <em>binding arbitration</em>, which is a means to resolve disputes (such as a cybersecurity breach leaking your DNA data) outside of court.</p>



<p>In this process, both parties in a disagreement present their cases to an arbitrator, who is a neutral third party. The arbitrator listens to both sides, reviews the evidence, and decides. The key aspect of binding arbitration is that the arbitrator's decision is final and legally enforceable, meaning both parties must accept it and cannot appeal to a regular court. </p>



<p>This method is commonly used in various settings, including consumer contracts, employment disputes, and business disagreements, as it is often faster and less formal than going to court.</p>



<p>And 23andMe is trying to accomplish exactly this.</p>



<ul>
<li><strong>Initial Dispute Resolution Period</strong>: If you have a problem with 23andMe's services, you first need to contact their customer care team. This is to try and solve the issue quickly and without legal proceedings. You have to try this informal negotiation for at least 60 days before you can take any further legal action. You need to provide them with a detailed email outlining your issue, including what the dispute is about, when it happened, what you want as a solution, and your contact details. You (and your lawyer, if you have one) will also need to have a discussion with them to try and solve the dispute.</li>



<li><strong>Arbitration Instead of Court</strong>: If the issue isn't resolved in those 60 days, the next step is usually not a lawsuit in court, but arbitration. This means a neutral third party (an arbitrator) will listen to both sides and make a decision. The rules of this process are governed by JAMS, a company that provides arbitration services. In some cases, if many people have similar disputes against 23andMe, a different process called Mass Arbitration with another company, NAM, will be used.</li>



<li><strong>Arbitrator's Decision</strong>: The arbitrator’s decision is final. They have to follow the law and can give any ruling that a court could.</li>



<li><strong>Exceptions to Arbitration</strong>: There are a few situations where you or 23andMe can take the issue to court instead of arbitration. This includes things like intellectual property disputes and small claims (minor issues).</li>



<li><strong>No Class Actions</strong>: You can't join with other people to bring a class action or collective arbitration against 23andMe. Each dispute is handled individually.</li>



<li><strong>Severability</strong>: If any part of this dispute resolution section is not legally enforceable, the rest still applies.</li>
</ul>



<p>In the event of a cybersecurity breach, this means that if you have a dispute with 23andMe about it, you would first try to resolve it with their customer care. If that doesn't work, you'd generally go to arbitration, not a lawsuit, unless it falls under one of the exceptions. You also can't join a class action lawsuit for such an issue.</p>



<h2>23andMe is beginning to notify its users</h2>



<p>23andMe is beginning to inform its users of a modification in their Terms of Service via email. Users are given a 30-day window from when they receive this email to opt out of these new, stringent terms that significantly reduce their rights. </p>


<div>
<figure><img data-dominant-color="eeefef" data-has-transparency="false" decoding="async" width="615" height="650" src="https://stackdiary.com/wp-content/uploads/2023/12/image-3-615x650.png" alt="" srcset="https://stackdiary.com/wp-content/uploads/2023/12/image-3-615x650.png 615w, https://stackdiary.com/wp-content/uploads/2023/12/image-3-284x300.png 284w, https://stackdiary.com/wp-content/uploads/2023/12/image-3-768x811.png 768w, https://stackdiary.com/wp-content/uploads/2023/12/image-3.png 820w" sizes="(max-width: 615px) 100vw, 615px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20615%20650'%3E%3C/svg%3E" data-lazy-srcset="https://stackdiary.com/wp-content/uploads/2023/12/image-3-615x650.png 615w, https://stackdiary.com/wp-content/uploads/2023/12/image-3-284x300.png 284w, https://stackdiary.com/wp-content/uploads/2023/12/image-3-768x811.png 768w, https://stackdiary.com/wp-content/uploads/2023/12/image-3.png 820w" data-lazy-src="https://stackdiary.com/wp-content/uploads/2023/12/image-3-615x650.png"><figcaption>In the email that 23andMe is sending to its users, the "notify us" hyperlink contains an email address that is "legal@23andme.com" as opposed to an address that is listed in the Terms of Service.</figcaption></figure></div>


<p>The email doesn't mention that you must email the "<a href="mailto:arbitrationoptout@23andme.com">arbitrationoptout@23andme.com</a>" address to opt out of forced arbitration, as outlined in the updated Terms of Service, which you can <a href="https://www.23andme.com/legal/terms-of-service/#dispute-resolution-arbitration" target="_blank" rel="noreferrer noopener">preview here</a>. </p>



<blockquote>
<p><strong>30 Day Right to Opt-Out</strong>. You have the right to opt-out and not be bound by the arbitration and class action waiver provisions set forth above by sending written notice of your decision to opt-out by emailing us at arbitrationoptout@23andme.com. The notice must be sent within thirty (30) days of your first use of the Service, or the effective date of the first set of Terms containing an Arbitration and Class Action and Class Arbitration Waiver section otherwise you shall be bound to arbitrate disputes in accordance with the terms of those sections. If you opt out of these arbitration provisions, we also will not be bound by them.</p>
</blockquote>



<p>It's <em>unlikely</em> that the intention of the email mix-up is malicious in nature; they would absolutely get destroyed by every privacy organization on the planet if they snuck in a change like that, but I have emailed them to verify the above and will add a response here once I get it.</p>



<p>That said, unless you email this account 30 days after starting to use the service for the first time, you will automatically be enrolled in this arbitration scheme. Likewise, this affects all users who were affected by the cybersecurity breach since the terms were changed after the fact. Because these terms were put in place on November 30, 2023 - it has already been over a week, and most users might not understand why this is important or relevant.</p>



<p>If you're unsure as to why arbitration is bad, it's because it is biased against the consumer. The Stanford Graduate School of Business did an entire study on it; you can read the blog post about it <a href="https://www.gsb.stanford.edu/insights/why-binding-arbitration-game-rigged-against-customers" target="_blank" rel="noreferrer noopener nofollow">here</a> or view the entire study <a href="https://www.gsb.stanford.edu/faculty-research/working-papers/arbitration-uninformed-consumers" target="_blank" rel="noreferrer noopener nofollow">here</a>. </p>



<p>Here's an excerpt from the blog post:</p>



<blockquote>
<p>Now, a&nbsp;new analysis&nbsp;of almost 9,000 arbitration cases from the securities industry confirms what many have long suspected: The system is biased against consumers — and not just because big companies have more money to spend on lawyers.</p>



<p>When it comes to arbitration, the study finds, companies have a big information advantage in fishing for arbitrators who are likely to rule in their favor.</p>



<p>Making matters worse, the arbitrators themselves know that being pro-company in one case greatly increases their chances of being picked for future cases.</p>
<cite>Edmund L. Andrews, Stanford Business</cite></blockquote>



<p>This is merely about 23andMe protecting <em>itself</em> (not you, the consumer) because if a security breach of this scope happens again in the future, it will have <em>some</em> protection against mass user complaints.</p>



<h2>How to opt-out (email template)</h2>



<p>If you have been affected by the security breach at 23andMe and would like to opt out of the forced arbitration, here is an email template that you can use:</p>



<div>
<p><strong>To:</strong> <a href="mailto:legal@23andme.com">legal@23andme.com</a>, <a href="mailto:customercare@23andme.com">customercare@23andme.com</a>, <a href="mailto:arbitrationoptout@23andme.com">arbitrationoptout@23andme.com</a><br><strong>Subject:</strong> Request to Opt-Out of Updated TOS</p>



<p>Dear 23andMe Team,</p>



<p>I am contacting you regarding the recent changes to the 23andMe Terms of Service, dated November 30, 2023. My name is [your name as registered with 23andMe], and the email associated with my 23andMe account is [your 23andMe account email].</p>



<p>I hereby formally request to opt out of the newly updated Terms of Service. I do not consent to the terms as outlined in the recent update.</p>



<p>Thank you for processing my request promptly.</p>



<p>Best regards, <br>[Your Name]
</p></div>



<p>You should also make sure that you save the reply and explicitly ask them to confirm that you opted out. This will be mandatory in case another breach happens in the future, as you will have proof that you're not bound by this change in their Terms of Service.</p>

								</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Researchers have discovered magnetic monopole quasi-particles (135 pts)]]></title>
            <link>https://www.cam.ac.uk/research/news/diamonds-and-rust-help-unveil-impossible-quasi-particles</link>
            <guid>38550994</guid>
            <pubDate>Wed, 06 Dec 2023 23:38:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cam.ac.uk/research/news/diamonds-and-rust-help-unveil-impossible-quasi-particles">https://www.cam.ac.uk/research/news/diamonds-and-rust-help-unveil-impossible-quasi-particles</a>, See on <a href="https://news.ycombinator.com/item?id=38550994">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Researchers led by the University of Cambridge used a technique known as diamond quantum sensing to observe swirling textures and faint magnetic signals on the surface of hematite, a type of iron oxide.</p>

<p>The researchers observed that magnetic monopoles in hematite emerge through the collective behaviour of many spins (the angular momentum of a particle). These monopoles glide across the swirling textures on the surface of the hematite, like tiny hockey pucks of magnetic charge. This is the first time that naturally occurring emergent monopoles have been observed experimentally.</p>

<p>The research has also shown the direct connection between the previously hidden swirling textures and the magnetic charges of materials like hematite, as if there is a secret code linking them together. The <a href="https://www.nature.com/articles/s41563-023-01737-4">results</a>, which could be useful in enabling next-generation logic and memory applications, are reported in the journal <em>Nature Materials</em>.</p>

<p>According to the equations of James Clerk Maxwell, a giant of Cambridge physics, magnetic objects, whether a fridge magnet or the Earth itself, must always exist as a pair of magnetic poles that cannot be isolated.</p>

<p>“The magnets we use every day have two poles: north and south,” said Professor Mete Atatüre, who led the research. “In the 19th century, it was hypothesised that monopoles could exist. But in one of his foundational equations for the study of electromagnetism, James Clerk Maxwell disagreed.”</p>

<p>Atatüre is Head of Cambridge’s Cavendish Laboratory, a position once held by Maxwell himself. “If monopoles did exist, and we were able to isolate them, it would be like finding a missing puzzle piece that was assumed to be lost,” he said.</p>

<p>About 15 years ago, scientists suggested how monopoles could exist in a magnetic material. This theoretical result relied on the extreme separation of north and south poles so that locally each pole appeared isolated in an exotic material called spin ice.</p>

<p>However, there is an alternative strategy to find monopoles, involving the concept of emergence. The idea of emergence is the combination of many physical entities can give rise to properties that are either more than or different to the sum of their parts.</p>

<p>Working with colleagues from the University of Oxford and the National University of Singapore, the Cambridge researchers used emergence to uncover monopoles spread over two-dimensional space, gliding across the swirling textures on the surface of a magnetic material.</p>

<p>The swirling topological textures are found in two main types of materials: ferromagnets and antiferromagnets. Of the two, antiferromagnets are more stable than ferromagnets, but they are more difficult to study, as they don’t have a strong magnetic signature.</p>

<p>To study the behaviour of antiferromagnets, Atatüre and his colleagues use an imaging technique known as diamond quantum magnetometry. This technique uses a single spin – the inherent angular momentum of an electron – in a diamond needle to precisely measure the magnetic field on the surface of a material, without affecting its behaviour.</p>

<p>For the current study, the researchers used the technique to look at hematite, an antiferromagnetic iron oxide material. To their surprise, they found hidden patterns of magnetic charges within hematite, including monopoles, dipoles and quadrupoles.</p>

<p>“Monopoles had been predicted theoretically, but this is the first time we’ve actually seen a two-dimensional monopole in a naturally occurring magnet,” said co-author Professor Paolo Radaelli, from the University of Oxford.</p>

<p>“These monopoles are a collective state of many spins that twirl around a singularity rather than a single fixed particle, so they emerge through many-body interactions. The result is a tiny, localised stable particle with diverging magnetic field coming out of it,” said co-first author Dr Hariom Jani, from the University of Oxford.</p>

<p>“We’ve shown how diamond quantum magnetometry could be used to unravel the mysterious behaviour of magnetism in two-dimensional quantum materials, which could open up new fields of study in this area,” said co-first author Dr Anthony Tan, from the Cavendish Laboratory. “The challenge has always been direct imaging of these textures in antiferromagnets due to their weaker magnetic pull, but now we’re able to do so, with a nice combination of diamonds and rust.”</p>

<p>The study not only highlights the potential of diamond quantum magnetometry but also underscores its capacity to uncover and investigate hidden magnetic phenomena in quantum materials. If controlled, these swirling textures dressed in magnetic charges could power super-fast and energy-efficient computer memory logic.</p>

<p>The research was supported in part by the Royal Society, the Sir Henry Royce Institute, the European Union, and the Engineering and Physical Sciences Research Council (EPSRC), part of UK Research and Innovation (UKRI).</p>

<p><em><strong>Reference:</strong><br>
K. C. Tan, Hariom Jani, Michael Högen et al. ‘<a href="https://www.nature.com/articles/s41563-023-01737-4">Revealing Emergent Magnetic Charge in an Antiferromagnet with Diamond Quantum Magnetometry</a>.’ Nature Materials (2023). DOI: 10.1038/s41563-023-01737-4.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Merlin Sound ID – Identify Birds Using Your Phone (How It Works) (200 pts)]]></title>
            <link>https://www.macaulaylibrary.org/2021/06/22/behind-the-scenes-of-sound-id-in-merlin/</link>
            <guid>38550737</guid>
            <pubDate>Wed, 06 Dec 2023 23:08:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.macaulaylibrary.org/2021/06/22/behind-the-scenes-of-sound-id-in-merlin/">https://www.macaulaylibrary.org/2021/06/22/behind-the-scenes-of-sound-id-in-merlin/</a>, See on <a href="https://news.ycombinator.com/item?id=38550737">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
<!--?xml encoding="utf-8" ?--><h2><b>What is Sound ID?</b></h2>
<figure id="attachment_6745" aria-describedby="caption-attachment-6745"><img decoding="async" loading="lazy" alt="App demo showing detection of White-throated Sparrow" width="142" height="288" data-image-lazy="" data-src="https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-506x1024.png" data-sizes="(max-width: 142px) 100vw, 142px" data-srcset="https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-506x1024.png 506w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-148x300.png 148w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-768x1554.png 768w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-759x1536.png 759w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-1012x2048.png 1012w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-79x160.png 79w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-158x320.png 158w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-237x480.png 237w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-316x640.png 316w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-445x900.png 445w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-593x1200.png 593w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-890x1800.png 890w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-1186x2400.png 1186w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-300x607.png 300w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-600x1214.png 600w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow.png 1460w" src="https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-506x1024.png" srcset="https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-506x1024.png 506w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-148x300.png 148w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-768x1554.png 768w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-759x1536.png 759w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-1012x2048.png 1012w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-79x160.png 79w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-158x320.png 158w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-237x480.png 237w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-316x640.png 316w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-445x900.png 445w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-593x1200.png 593w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-890x1800.png 890w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-1186x2400.png 1186w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-300x607.png 300w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow-600x1214.png 600w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Sound-ID-iOS-Best-matches-comparison-White-throated-Sparrow.png 1460w"><figcaption id="caption-attachment-6745">A screenshot showing the detection of a White-throated Sparrow.</figcaption></figure>
<p><span>Today we announced one of our biggest breakthroughs—Sound ID, a new feature in the </span><a href="https://merlin.allaboutbirds.org/"><span>Merlin Bird ID</span></a><span> app—and a major leap forward&nbsp;in sound identification and machine learning to date. Sound ID lets people use their phone to listen to the birds around them, and see live predictions of who’s singing. Currently, Merlin can identify 458 bird species in the U.S. and Canada based on their sounds (with more species and regions coming soon). Sound ID runs on your device, without requiring a network connection. <a href="https://merlinbirdid.page.link/sound-id">Download it today for free</a>&nbsp;and test it out in your own backyard! If you happen to be located in the Northeastern United States you can test out Sound ID on the audio below which was recorded in New Hampshire.</span></p>
<h2><b>How does Sound ID work?</b></h2>
<p><span>As your phone records sound, Merlin converts the audio into an image called a spectrogram. The spectrogram plots sound frequencies that appear in the recording, as a function of time. This spectrogram image is then fed into a modern computer vision model called a deep convolutional neural network. We trained this model to identify birds based on 140 hours of audio containing bird sounds, in addition to 126 hours of audio containing non-bird background sounds, like whistling and car noises. For each audio clip, a group of sound ID experts from the Macaulay Library and the eBird community found the precise moments when birds were making sounds, and tagged those sounds with the corresponding bird species. The model can use this detailed supervision from experts to learn how to correctly predict the species that appear in these annotated audio clips, with the goal of generalizing this knowledge to predict which birds appear in audio recordings it hasn’t heard before.</span></p>



<p><span>So how does it work? Once the database of sounds is assembled, we train the computer vision model using a gradient descent algorithm. When the model “hears” a sound clip, it makes a prediction that is based on the transformation of the sound clip’s spectrogram through a series of mathematical operations involving millions of numbers (called <em>weights</em>). The gradient descent algorithm figures out how to adjust the value of each weight to ensure that the model’s predictions match those of the sound ID experts. This weight updating process is the “learning” part of machine learning. </span></p>
<p><span>Building the sound ID model is an iterative process, involving a back-and-forth between the sound ID experts, members of the machine learning team, and people who provide feedback based on field tests of the app. After evaluating a trained model’s performance, we make adjustments to the training algorithm, ask the sound ID experts to label more audio clips, and try to locate any human errors in the previously labeled data.&nbsp;</span></p>
<h2><b>What’s special about Sound ID in Merlin?</b></h2>
<p><span>Merlin is not the first to use deep convolutional neural networks to identify birds by their sounds. In fact, Merlin draws inspiration from a number of other projects, including </span><a href="https://birdnet.cornell.edu/"><span>BirdNET</span></a><span> and </span><a href="https://wp.nyu.edu/birdvox/"><span>BirdVox</span></a><span>.&nbsp;</span></p>
<p><span>There have been many other approaches to bird sound ID through the years, the result of engineering contests such as </span><a href="https://www.kaggle.com/c/birdclef-2021"><span>BirdClef</span></a><span> and </span><a href="http://dcase.community/challenge2021/task-few-shot-bioacoustic-event-detection"><span>DCASE</span></a><span>, </span><a href="https://www.kaggle.com/c/rfcx-species-audio-detection"><span>among</span></a> <a href="https://www.kaggle.com/c/birdsong-recognition"><span>many</span></a> <a href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13103"><span>others</span></a><span>. </span><span>Similar techniques have been used to </span><a href="https://naturesmartcities.com/"><span>monitor the activity of bats</span></a><span>, as well as find </span><a href="https://www.blog.google/technology/ai/pattern-radio-whale-songs/"><span>patterns in whale songs</span></a><span>.</span></p>
<p><span>Previous bird sound ID models have typically been trained using data with a coarser level of temporal resolution. For instance, a model might hear a 30 second recording of a White-breasted Nuthatch, but not be told when the nuthatch is singing in the recording. This can lead to problems: if other species are singing in the same recording, the model will erroneously call all species in the recording a White-breasted Nuthatch, leading to false predictions.&nbsp;</span></p>

<div>
	<figure>
		<p><img alt="Carolina Wren" data-image-lazy="" data-sizes="(min-width: 1200px) 1200px, 100vw" data-srcset="
					https://cdn.download.ams.birds.cornell.edu/api/v1/asset/83066971/160 160w,
					https://cdn.download.ams.birds.cornell.edu/api/v1/asset/83066971/320 320w,
					https://cdn.download.ams.birds.cornell.edu/api/v1/asset/83066971/480 480w,
					https://cdn.download.ams.birds.cornell.edu/api/v1/asset/83066971/640 640w,
					https://cdn.download.ams.birds.cornell.edu/api/v1/asset/83066971/900 900w,
					https://cdn.download.ams.birds.cornell.edu/api/v1/asset/83066971/1200 1200w,
					https://cdn.download.ams.birds.cornell.edu/api/v1/asset/83066971/1800 1800w,
					https://cdn.download.ams.birds.cornell.edu/api/v1/asset/83066971/2400 2400w" data-src="https://cdn.download.ams.birds.cornell.edu/api/v1/asset/83066971/1200">
						</p>
				<figcaption>
			
		</figcaption>
			</figure>
</div>

<p><span>Merlin’s Sound ID tool is trained using audio data which includes the precise moments in time when each bird is vocalizing. The process of generating this data is labor intensive, because it requires sound ID experts to listen to each audio file carefully. As a result of these efforts, the model has the opportunity to learn a more accurate representation of which sounds correspond to which species (and which sounds are ambient noises). </span><a href="https://arxiv.org/abs/2105.07031"><span>Recent research</span></a><span> confirms that temporally fine-grained labels can help improve audio classification performance.</span></p>
<figure id="attachment_6778" aria-describedby="caption-attachment-6778"><img decoding="async" loading="lazy" alt="Screenshot of the annotation tool. " width="1772" height="701" data-image-lazy="" data-src="https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM.png" data-sizes="(max-width: 1772px) 100vw, 1772px" data-srcset="https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM.png 1772w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-300x119.png 300w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-1024x405.png 1024w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-768x304.png 768w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-1536x608.png 1536w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-80x32.png 80w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-160x63.png 160w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-320x127.png 320w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-480x190.png 480w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-640x253.png 640w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-900x356.png 900w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-1200x475.png 1200w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-600x237.png 600w" src="https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM.png" srcset="https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM.png 1772w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-300x119.png 300w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-1024x405.png 1024w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-768x304.png 768w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-1536x608.png 1536w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-80x32.png 80w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-160x63.png 160w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-320x127.png 320w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-480x190.png 480w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-640x253.png 640w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-900x356.png 900w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-1200x475.png 1200w, https://ml-rds-wordpress-prod-s3.s3.amazonaws.com/uploads/2021/06/Screen-Shot-2021-06-22-at-10.48.56-AM-600x237.png 600w"><figcaption id="caption-attachment-6778">We built a custom annotation tool that allows sound ID experts to listen to Macaulay Library recordings and annotate the precise moments when different bird species are vocalizing.</figcaption></figure>

<h2><b>What’s next?</b></h2>
<p><span>In building the model, we made a number of design decisions about how to handle our particular dataset, how to integrate predictions with information from eBird</span><span> (a database of bird sightings shared by citizen scientists from around the world),</span><span> and how to maximize the accuracy of Merlin Sound ID’s predictions in the field.</span></p>
<p><span>In the coming weeks, we’ll be posting a series of articles that take a closer look at these design decisions. We’ll also explore some of what’s in store for our Sound ID tools in the future.</span></p>
<p><span>If you’ve tried Sound ID in Merlin, we’d love to hear about your experience. You can get in touch on Twitter, where the Macaulay Library is <a href="https://twitter.com/macaulaylibrary?lang=en">@MacaulayLibrary</a>.</span></p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Long context prompting for Claude 2.1 (217 pts)]]></title>
            <link>https://www.anthropic.com/index/claude-2-1-prompting</link>
            <guid>38550675</guid>
            <pubDate>Wed, 06 Dec 2023 23:00:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/index/claude-2-1-prompting">https://www.anthropic.com/index/claude-2-1-prompting</a>, See on <a href="https://news.ycombinator.com/item?id=38550675">Hacker News</a></p>
Couldn't get https://www.anthropic.com/index/claude-2-1-prompting: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Gordon Freeman at the Olympic Games (247 pts)]]></title>
            <link>https://moonbase.lgbt/blog/100m-accelerated-backhopping/</link>
            <guid>38550408</guid>
            <pubDate>Wed, 06 Dec 2023 22:32:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://moonbase.lgbt/blog/100m-accelerated-backhopping/">https://moonbase.lgbt/blog/100m-accelerated-backhopping/</a>, See on <a href="https://news.ycombinator.com/item?id=38550408">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
	
	<div>
		
		
		<p>Since the dawn of <a href="https://twitter.com/lunasorcery/status/1576008439586648065">October 1st 2022</a>, the world has been plagued by the question:</p>
<p><strong><em>Would accelerated backhopping give you a competitive advantage in the 100m dash?</em></strong></p>
<p>In this <s>deranged ramble</s> blog article we shall attempt to answer the question once and for all.</p>
<hr>
<blockquote>
“Gordon! You must get out of here! Run!”
<cite>— Dr. Kleiner, Half-Life 2</cite>
</blockquote>

<hr>
<h2 id="initial-parameters">Initial Parameters</h2>
<p>Our investigation into the viability of accelerated backhopping as a competitive strategy in the 100m dash will use the following parameters:</p>
<ul>
<li>Movement physics will be as present in Half-Life 2.</li>
<li>The 100m dash will be as defined in the IAAF Competition Rules.</li>
</ul>
<hr>
<h2 id="what-is-accelerated-backhopping">What is Accelerated Backhopping?</h2>
<p><em>Note: the technical aspects of this section are largely adapted from <a href="https://wiki.sourceruns.org/wiki/Accelerated_Back_Hopping">the SourceRuns wiki</a>.</em></p>
<p>Accelerated backhopping (henceforth referred to as ABH) is a bug in the Source engine movement code, allowing the player to move far faster than the developers intended.</p>
<p>When the player performs a jump, the game tries to give the player a little extra speed boost, based on their current velocity, state (crouching, sprinting, etc), movement input, and look direction. It also attempts to cap the player’s speed, but an oversight in the programming causes the player to accelerate far beyond that speed limit under certain circumstances.</p>
<hr>
<p>Let’s look at <a href="https://github.com/ValveSoftware/source-sdk-2013/blob/56accfdb9c4abd32ae1dc26b2e4cc87898cf4dc1/sp/src/game/shared/gamemovement.cpp#L2469-L2495">the code</a>; this is executed when a player is on the ground and makes a jump input:</p>
<p>Calculate the boost multiplier <code>flSpeedBoostPerc</code> to determine how much of a boost we want to give. If the player is sprinting or ducking, they get a 10% boost, otherwise they get a 50% boost.</p>
<pre><code>float flSpeedBoostPerc = ( !pMoveData-&gt;m_bIsSprinting &amp;&amp; !player-&gt;m_Local.m_bDucked ) ? 0.5f : 0.1f;
</code></pre>
<p>Calculate <code>flSpeedAddition</code>, the additional velocity we want to apply to our player’s speed, by scaling the player’s forward movement input <code>mv-&gt;m_flForwardMove</code> by our boost multiplier, and taking the absolute value so it’s positive.</p>
<pre><code>float flSpeedAddition = fabs( mv-&gt;m_flForwardMove * flSpeedBoostPerc );
</code></pre>
<p>Calculate <code>flMaxSpeed</code>, the maximum speed the player should be travelling at. We take <code>mv-&gt;m_flMaxSpeed</code>, the maximum speed expected for the player’s current state, and increase it by our boost multiplier.</p>
<pre><code>float flMaxSpeed = mv-&gt;m_flMaxSpeed + ( mv-&gt;m_flMaxSpeed * flSpeedBoostPerc );
</code></pre>
<p>Calculate <code>flNewSpeed</code>, the speed we expect the player to have after jumping, by adding <code>flSpeedAddition</code> to the player’s current lateral velocity <code>mv-&gt;m_vecVelocity.Length2D</code>.</p>
<pre><code>float flNewSpeed = ( flSpeedAddition + mv-&gt;m_vecVelocity.Length2D() );
</code></pre>
<p>If the player’s new speed is higher than the maximum speed, subtract the difference from <code>flSpeedAddition</code>.</p>
<pre><code>if ( flNewSpeed &gt; flMaxSpeed )
{
    flSpeedAddition -= flNewSpeed - flMaxSpeed;
}
</code></pre>
<p>If the player is providing a backwards movement input, negate <code>flSpeedAddition</code>:</p>
<pre><code>if ( mv-&gt;m_flForwardMove &lt; 0.0f )
    flSpeedAddition *= -1.0f;
</code></pre>
<p>Apply the speed addition to the player’s velocity, by adding it in the forward look direction <code>vecForward</code>:</p>
<pre><code>VectorAdd( (vecForward*flSpeedAddition), mv-&gt;m_vecVelocity, mv-&gt;m_vecVelocity );
</code></pre>
<hr>
<p>The critical flaw in the code resides in the assumption that the movement input and the current velocity are correlated.</p>
<p>Consider the following situation: The player is sprinting along at 320ups (units per second). They jump forwards, and the boost increases their speed to 352ups, by design. While in the air, they spin around 180 degrees (so they’re now facing where they came from, and moving backwards), release all movement inputs, and begin crouching. Upon touching the ground, still moving at 352ups, they immediately jump again.</p>
<p>The player is crouching, so the boost multiplier is set to 10%.</p>
<p>Since the player isn’t providing any forward movement input, <code>flSpeedAddition</code> becomes 0:</p>
<pre><code>float flSpeedAddition = fabs( mv-&gt;m_flForwardMove * flSpeedBoostPerc ) 
                      = fabs(0 * 0.1) 
                      = 0
</code></pre>
<p>The max speed <code>flMaxSpeed</code> is calculated based on <em>crouching</em> speed limit of 190ups, and comes out as 209:</p>
<pre><code>float flMaxSpeed = mv-&gt;m_flMaxSpeed + ( mv-&gt;m_flMaxSpeed * flSpeedBoostPerc ) 
                 = 190 + (190 * 0.1) 
                 = 209
</code></pre>
<p>Since <code>flSpeedAddition</code> is 0, the new speed <code>flNewSpeed</code> does not change from the player’s current velocity.</p>
<pre><code>float flNewSpeed = ( flSpeedAddition + mv-&gt;m_vecVelocity.Length2D() ) 
                 = 0 + 352 
                 = 352
</code></pre>
<p><code>flNewSpeed</code> is now far in excess of <code>flMaxSpeed</code>, so the difference is subtracted from <code>flSpeedAddition</code>, giving -143:</p>
<pre><code>flSpeedAddition -= flNewSpeed - flMaxSpeed;
                = 0 - (352 - 209)
                = -143
</code></pre>
<p>The player is not providing any backwards movement input, so <code>flSpeedAddition</code> remains negative.</p>
<pre><code>if ( mv-&gt;m_flForwardMove &lt; 0.0f ) // false
    flSpeedAddition *= -1.0f; // doesn't execute
</code></pre>
<p>This negative value then gets multiplied by the player’s <em>forward</em> look direction, producing a vector pointing 143 units <em>behind</em> them. This gets applied to the player’s velocity vector — remember, since spinning in mid-air they’re already moving backwards — increasing their speed by 143ups for a new speed of 495ups.</p>
<p>On the next jump, this effect is compounded, creating a speed boost of 286ups, then 572ups, then 1144ups, and so on.</p>
<hr>
<h2 id="rules-of-engagement">Rules of Engagement</h2>
<p>We will now consult the <a href="https://worldathletics.org/about-iaaf/documents/book-of-rules">IAAF Book of Rules</a> to determine the conditions under which we will compete. The following excerpts are all taken from IAAF Book C, C2.1 Technical Rules.</p>
<h3 id="attire">Attire</h3>
<blockquote>
<p>Assistance not Allowed</p>
<p><strong>6.3</strong>   For the purpose of this Rule, the following examples shall be considered assistance, and are therefore not allowed:<br>
[...]<br>
<strong>6.3.4</strong> The use of any mechanical aid, except by an athlete with an impairment as authorised or permitted in accordance with the Mechanical Aids Regulations.</p>
</blockquote>
<p>Wearing the HEV suit allows the player to sprint, allowing for a much faster initial ABH speed than would otherwise be possible (495ups with the suit, 285ups without). We believe it is a reasonable interpretation that the HEV suit constitutes a mechanical aid, and would therefore not be permitted for use. Our runner will thus compete without the suit.</p>
<h3 id="race-start">Race Start</h3>
<blockquote>
<p><strong>16.3</strong>  In races up to and including 400m (including the first leg of 4 × 200m, the Medley Relay and 4 × 400m), <strong>a crouch start and the use of starting blocks are compulsory</strong>. After the “On your marks” command, an athlete shall approach the start line, assume a position completely within their allocated lane and behind the start line. An athlete shall not touch either the start line or the ground in front of it with their hands or their feet when on their mark. Both hands and at least one knee shall be in contact with the ground and both feet in contact with the foot plates of the starting blocks. At the “Set” command, an athlete shall immediately rise to their final starting position retaining the contact of the hands with the ground and of the feet with the foot plates of the blocks. Once the Starter is satisfied that all athletes are steady in the “Set” position, the gun shall be fired.</p>
</blockquote>
<p>Within the bounds of Half-Life 2’s movement, the use of starting blocks and placing hands on the ground are not possible, so we will assume reasonable exemption from these rules. However, we can still abide by the requirement of a crouching start.</p>
<h3 id="lanes">Lanes</h3>
<blockquote>
<p><strong>14.4</strong>  In all races up to and including 400m, each athlete shall have a separate lane, with a width of 1.22m ± 0.01m, including the lane line on the right, marked by white lines 50mm in width. All lanes shall be of the same nominal width. The inner lane shall be measured as stated in Rule 14.2, but the remaining lanes shall be measured 0.20m from the outer edges of the lines.</p>
</blockquote>
<!-- -->

<blockquote>
<p><strong>17.3</strong>  In all races:</p>
<p><strong>17.3.1</strong>    run in lanes, each athlete shall keep within their allocated lane from start to finish. This shall also apply to any portion of a race run in lanes;</p>
</blockquote>
<!-- -->

<blockquote>
<p><strong>17.4</strong>  An athlete, or in the case of a relay race, their team, shall not be disqualified if the athlete:<br>
[...]<br>
<strong>17.4.2</strong>    steps or runs outside their lane in the straight, any straight part of the diversion from the track for the steeplechase water jump or outside the outer line of their lane on the bend;<br>
[...]<br>
and no material advantage is gained and no other athlete being jostled or obstructed so as to impede the other athlete’s progress (see Rule 17.2 of the Technical Rules). If material advantage is gained, the athlete (or team) shall be disqualified.</p>
</blockquote>
<p>In summary, the lane is 1.22m wide, and we must be careful to stay within that lane. We are only permitted to leave the lane if no material advantage would be gained by doing so; as such we cannot use any maneuvers that depend on us leaving the lane.</p>
<h3 id="the-finish">The Finish</h3>
<blockquote>
<p><strong>18.2</strong>  The athletes shall be placed in the order in which any part of their bodies (i.e. torso, as distinguished from the head, neck, arms, legs, hands or feet) reaches the vertical plane of the nearer edge of the finish line as defined above.</p>
</blockquote>
<p>In summary, our aim is to:</p>
<ul>
<li>Travel 100 meters as quickly as possible,</li>
<li>from a stationary crouching start,</li>
<li>without leaving the 1.22m-wide lane,</li>
<li>and without wearing an HEV suit.</li>
</ul>
<hr>
<h2 id="a-matter-of-scale">A Matter of Scale</h2>
<p>Contemporary game engines typically base their unit systems on the metric system.<sup id="fnref:cite-unity-units"><a href="#fn:cite-unity-units">[1]</a></sup><sup id="fnref:cite-unreal-units"><a href="#fn:cite-unreal-units">[2]</a></sup> Source engine, however, is an unusual beast, and its units are based on the imperial system. Maps are modelled at a scale of 16 units = 1 foot, or 1 unit = 3/4 inch.<sup id="fnref:cite-source-units"><a href="#fn:cite-source-units">[3]</a></sup> From this, we can calculate that our 100m run is 5,249.34 units.</p>
<hr>
<h2 id="the-run">The Run</h2>
<p><em>Note: The following timings and speeds are theoretical based on a crude analysis of the game code, and may not necessarily be reproducible under practical testing.</em></p>
<p>The player begins from a crouching position at the start line. Since an ABH cannot be performed from a crouching start, they spend 200ms returning to a standing position.<sup id="fnref:cite-unduck"><a href="#fn:cite-unduck">[4]</a></sup> Once standing, they begin walking forward, quickly reaching their maximum walking speed of 150ups. Once at speed, they make their first jump facing forwards. They get the <em>intended</em> jump-speed bonus, accelerating them to 225ups. While in the air, they release all forward input, turn 180 degrees, and crouch. Roughly 510ms after jumping,<sup id="fnref:cite-jumptime"><a href="#fn:cite-jumptime">[5]</a></sup> they make their first landing. Still crouching and providing no lateral movement input, they jump again, ABH accelerating them from 225ups to a new speed of 285ups. A further 510ms later, they hit the ground again, and with another jump, ABH accelerates them to 405ups. This continues as follows:</p>
<table>
<thead>
<tr>
<th>Time*</th>
<th>Distance*</th>
<th>Speed**</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.00s</td>
<td>0.00u</td>
<td>225ups</td>
</tr>
<tr>
<td>0.51s</td>
<td>114.75u</td>
<td>285ups</td>
</tr>
<tr>
<td>1.02s</td>
<td>260.10u</td>
<td>405ups</td>
</tr>
<tr>
<td>1.53s</td>
<td>466.65u</td>
<td>645ups</td>
</tr>
<tr>
<td>2.04s</td>
<td>795.60u</td>
<td>1125ups</td>
</tr>
<tr>
<td>2.55s</td>
<td>1369.35u</td>
<td>2085ups</td>
</tr>
<tr>
<td>3.06s</td>
<td>2432.70u</td>
<td>3500ups</td>
</tr>
<tr>
<td>3.57s</td>
<td>4217.70u</td>
<td>3500ups</td>
</tr>
<tr>
<td>4.08s</td>
<td>6002.70u</td>
<td>3500ups</td>
</tr>
</tbody>
</table>
<p><small>* from initial jump</small><br>
<small>** during jump</small></p>
<p>On the seventh jump, ABH <em>would</em> give a velocity of 4005ups, but this gets hard-capped to 3500ups, and remains as such for the remainder of the run. 3.865s after the first jump, the player flies across the finish line, and shortly afterwards at 4.08s, they land some 753.36u (14.35m) beyond it.</p>
<p>Note that these timings and distances are relative to the first jump. After the starting pistol is fired, the player takes 200ms to stand from crouching, and an unspecified amount of time and distance (dependent on the ground friction) to reach their 150ups walking speed. However, given the acceleration the player is able to achieve once jumping, this pre-jump phase would have to last at least 5.715s in order for 100m record-holder Usain Bolt to still have a chance of outrunning them.</p>
<p>We hereby propose that the IAAF add a rule explicitly banning the use of ABH in competitions, and submit this article as justification.</p>
<hr>
<h2 id="addendum">Addendum</h2>
<p>Lyren from the SourceRuns team provided two practical runs, one with human inputs [<a href="https://moonbase.lgbt/blog/100m-accelerated-backhopping/100-scriptless.mp4">video</a>], and one with <a href="https://wiki.sourceruns.org/wiki/Host_timescale">host_timescale</a> to slow down time, along with an autojumping script [<a href="https://moonbase.lgbt/blog/100m-accelerated-backhopping/100-scripted.mp4">video</a>].</p>
<p>It could be argued that since the player cannot sprint without the HEV suit, this would constitute an impairment and the suit may be permitted under the Mechanical Aids Regulations. However, as shown, even without the suit, the player clearly has an unfair advantage over conventional human runners; the addition of the suit would just add further insult to injury.</p>
<p>The observant among you will notice that the blog’s accent colors have been changed specifically for this article, to a shade of orange taken from <a href="https://web.archive.org/web/20070803003812fw_/http://orange.half-life2.com/">the Orange Box website</a> circa 2007.</p>

	</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unveiling secrets of the ESP32: creating an open-source MAC layer (266 pts)]]></title>
            <link>https://zeus.ugent.be/blog/23-24/open-source-esp32-wifi-mac/</link>
            <guid>38550026</guid>
            <pubDate>Wed, 06 Dec 2023 21:50:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zeus.ugent.be/blog/23-24/open-source-esp32-wifi-mac/">https://zeus.ugent.be/blog/23-24/open-source-esp32-wifi-mac/</a>, See on <a href="https://news.ycombinator.com/item?id=38550026">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <h2> door <span property="author">Jasper Devreker</span> </h2> <p><small> Geschreven op <span property="dateCreated">2023-12-06</span><br> Leestijd: 18 minuten </small> </p> </div><div property="articleBody"> <article> <div> <p>The ESP32 is a popular microcontroller known in the maker community for its low price (~ €5) and useful features: it has a dual-core CPU, built-in Wi-Fi and Bluetooth connectivity and 520 KB of RAM. It is also used commercially, in devices ranging from smart CO₂-meters to industrial automation controllers. Most of the software development kit that is used to program for the ESP32 <a href="https://github.com/espressif/esp-idf">is open-source</a>, except notably the wireless bits (Wi-Fi, Bluetooth, low-level RF functions): that functionality is distributed as precompiled libraries, that are then compiled into the firmware the developer&nbsp;writes.</p> <p>A closed-source Wi-Fi implementation has several disadvantages compared to an open-source implementation&nbsp;though:</p> <ul> <li>You are dependent on the vendor (Espressif in this case) to add features; if you have a somewhat non-standard usecase, you might be out of luck. For example, standards-compliant mesh networking (IEEE 802.11s) is not supported on the ESP32; there is <a href="https://docs.espressif.com/projects/esp-idf/en/stable/esp32/api-guides/esp-wifi-mesh.html">a partially closed-source mesh networking implementation made by Espressif</a>, but this is rather limited: the mesh network has a tree topology, and uses NAT on the nodes connected to the root network, making it hard to connect from outside the mesh network to nodes in the mesh network. The protocol is also not documented, so it’s not interoperable with other&nbsp;devices.</li> <li>It’s hard to audit the security of the implementation: since there is no source code available, you have to resort to black-box fuzzing and reverse engineering to find security&nbsp;vulnerabilities.</li> <li>Additionally, an open-source implementation would make research into low-power Wi-Fi mesh networking more affordable; if each node only costs about €5, research involving hundreds of nodes can be affordable on a modest&nbsp;budget.</li> </ul> <p>Espressif has an open issue in their esp32-wifi-lib repository, asking to open-source the MAC layer. In that issue, they confirmed in 2016 that open sourcing the upper MAC is on their roadmap, but as of 2023, nothing has been published yet. Having the source code would for example allow us to implement proper 802.11s-compliant mesh&nbsp;networking.</p> <h2 id="goals">Goals</h2> <p>The main goal of this project is to build a minimal replacement for Espressifs proprietary Wi-Fi binary blobs. We don’t intend to be API-compatible with existing code that uses the Espressif ESP-IDF API, rather, we’d like to have a fully working, open source networking&nbsp;stack.</p> <p>The rest of this section will contain information about how the network stack and Wi-Fi (the 802.11 standard) works, so if you’re already familiar, you can skip&nbsp;it.</p> <figure> <a href="https://pics.zeus.gent/vYXyQm2t9pJCzpDdWFvq9oWR2DACoUJoTsYf8qiz.jpg"> <img src="https://pics.zeus.gent/vYXyQm2t9pJCzpDdWFvq9oWR2DACoUJoTsYf8qiz.jpg" alt="OSI model of the network stack (the difference between application/presentation/session is a bit murky)"> </a> <figcaption>OSI model of the network stack (the difference between application/presentation/session is a bit murky)</figcaption> </figure> <p>Above, you can see a diagram showing the network stack. Computer networking is done with a network stack, where every layer in the stack has its own purpose; this design makes it easier to swap out layers and allows for separate development of layers. The layer at the bottom of the stack interacts with the physical world (for example, by using radiowaves or electric signals); every layer adds their own features. Wi-Fi (also known as the 802.11 standard by engineers) is implemented in the bottom two layers: the PHY layer (what the radio waveforms look like, …) and the MAC layer (how we connect to an access point, what packets exist, how to send packets to local devices,&nbsp;…).</p> <p>On the ESP32, the PHY layer is implemented in hardware; most of the MAC layer is implemented in the proprietary blob. One notable exception to this separation is sending acknowlegement frame: if a device receives a frame, it should send a packet back to acknowledge that this packet was received correctly. This ACK packet needs to be sent within ~10 microseconds; it would be hard to get this timing correct in&nbsp;software.</p> <p>There are 3 types of MAC&nbsp;frames:</p> <ul> <li>Management frames: mostly for managing the connection between the access point and station&nbsp;(client)</li> <li>Control frames: help with delivery of other types of frames (for example ACK, but also request-to-send and&nbsp;clear-to-send)</li> <li>Data frames: contain the data of the layers above the MAC&nbsp;layer</li> </ul> <h2 id="previous-work">Previous&nbsp;work</h2> <p>Since it doesn’t look like Espressif will release an open source MAC implementation anytime soon, we’re on our own to create this. This is rather hard to do, because the hardware with which we send and receive 802.11 packets on the ESP32 is entirely undocumented. This means that we will need to reverse engineer the hardware; first we’ll need to document what the hardware does, then we’ll need to write our own code to correctly interact with it. In 2021, Uri Shaked did some very light reverse engineering of ESP32 Wi-Fi hardware, to mock this in his emulator. That way, programs for the ESP32 can be emulated instead of running them on real hardware. <a href="https://www.youtube.com/watch?v=XmaT8bMssyQ">Shaked gave a talk about this</a>, but only discussed very high level details about the hardware. Espressif has <a href="https://github.com/espressif/qemu">their own fork of QEMU</a> (a popular, open-source emulator) that can also emulate the ESP32, but this fork does not support emulating the Wi-Fi hardware. In 2022, Martin Johnson added basic support for the Wi-Fi hardware to <a href="https://github.com/a159x36/qemu">their own fork of Espressif’s QEMU</a>. The emulated ESP32 can connect to a virtual access point, or have a virtual client connect to&nbsp;it.</p> <p>esp-idf (the SDK for the ESP32) has a function to transmit frames (<code>esp_wifi_80211_tx</code>), but this function only accepts certain types of frames; it does not allow sending most management frames, severely limiting the usefulness of this API to base an 802.11 MAC stack on. They also have a function (<code>esp_wifi_set_promiscuous_rx_cb</code>) to receive a callback on reception of a&nbsp;frame.</p>  <p>Before we can start reverse engineering how the 802.11 PHY hardware works and how we interact with it, we first need to find or build tools that will help. We’ll use 3 main&nbsp;approaches:</p> <ul> <li>Static reverse engineering: we have the compiled libraries that implement the Wi-Fi stack, so we can look at the compiled code and try to decompile it to human-readable code. From this more readable code, we then try to see what the hardware expects the software to&nbsp;do.</li> <li>Dynamic code analysis in an emulator: we can run the firmware in an emulator and inspect how it interacts with the virtual hardware. This has the advantage of having a lot of freedom to how we inspect the hardware, but the disadvantage that the emulator might not behave the same as real hardware. Since we’ll need to write the emulated peripherals ourselves, this risk is real: there is no public datasheet for the Wi-Fi peripheral, so we have to guess how the hardware will behave from the code that interacts with&nbsp;it.</li> <li>Dynamic code analysis on real hardware: we can run the firmware on an actual ESP32, and debug it using a JTAG debugger. This allows us to place breakpoints, inspect the memory and registers, stop and resume the execution, … The disadvantage is that the debugging capabilities are more limited compared to running in an emulator: we can only place 2 breakpoints, we cannot place watchpoints (breakpoints that trigger on memory reads/writes to a certain address), … The big advantage compared to using an emulator is that we’ll know for sure that the behaviour of the hardware is&nbsp;correct.</li> </ul> <h3 id="static-analysis">Static&nbsp;analysis</h3> <p>For the static analysis, we use Ghidra, an open-source reverse engineering tool made by the NSA. Out of the box, Ghidra does not have support <a href="https://github.com/NationalSecurityAgency/ghidra/pull/5442">yet</a> for Xtensa (the CPU architecture of the ESP32), but there is a <a href="https://github.com/Ebiroll/ghidra-xtensa">plugin that adds support</a>. The build tools used in the ESP32 SDK generate both an ELF file (a type of binary file that can contain metadata) and a flat binary file: using the ELF file has the benefit of automatically setting most function&nbsp;names.</p> <h3 id="dynamic-analysis-in-emulator">Dynamic analysis in&nbsp;emulator</h3> <p>We started off from Martin Johnsons’s fork of Espressifs version of QEMU (a popular open-source emulator), and ported their changes to the latest version of Espressif’s QEMU fork. The ESP32 talks to its peripherals via memory mapped IO: by reading from and writing to certain memory addresses, the peripherals provides information to the CPU and does things. To help in reverse engineering, we added log statements to the QEMU Wi-Fi peripherals that log every access to their memory&nbsp;ranges.</p> <p>Additionally, we also implemented stack unwinding in QEMU; this is done for every memory access to a hardware peripheral related to Wi-Fi. That way, we can get a full stack trace for every peripheral access. Symbols are not stripped, so this is a very useful tool. However, to get stack unwinding properly working, we have to run QEMU in single step mode: QEMU has a JIT compiler that compiles sequences of emulated assembly instructions into optimized basic blocks. This greatly improves the execution speed, but since the CPU execution state is only guaranteed to be correct at the beginning of a basic block, if a peripheral memory access happens in the middle of such a basic block, the stack unwinding algorithm gives wrong&nbsp;results.</p> <p>Running in single-step mode negates much of the benefit of the QEMU JIT compiler, causing the code to run much slower. This is not that big of a disadvantage, compared to the treasure trove of information the execution trace gives&nbsp;us.</p> <p>Below is an example of a single memory access logged by QEMU: it’s a write (<code>W</code>) to address <code>3ff46094</code> with value <code>00010005</code>, done by the function <code>ram_pbus_force_test</code>. The rest of the callstack is also logged, and translated to a symbol name if&nbsp;available.</p> <p><code> W 3ff46094 00010005 ram_pbus_force_test 400044f4 set_rx_gain_cal_dc set_rx_gain_testchip_70 set_rx_gain_table bb_init register_chipv7_phy esp_phy_load_cal_and_init esp_phy_enable wifi_hw_start wifi_start_process ieee80211_ioctl_process ppTask vPortTaskWrapper </code></p> <p>Finally, we also corrected the handling of MAC addresses (compared to Martin Johnsons version), so that a packet capture has correct MAC addresses in packets instead of hardcoded&nbsp;addresses.</p> <h3 id="dynamic-analysis-on-real-hardware">Dynamic analysis on real&nbsp;hardware</h3> <p>To dynamically analyze the firmware on real hardware, we use the JTAG hardware debugging interface. By connecting some jumper wires between the ESP32 and a JTAG debugger, we can debug the ESP32. We followed the steps described in <a href="https://github.com/amirgon/ESP32-JTAG">this GitHub repository</a> to get our JTAG debugger (CJMCU-232H)&nbsp;working.</p> <p>In additon to the JTAG debugger, we also connected a USB Wi-Fi dongle directly to the ESP32: the ESP32-WROOM-32U variant of the ESP32 has an antenna connector. We connect that antenna connector to a 60 dB attenuator (this weakens the signal by 60dB), then connect that to the antenna connector of the wireless dongle. That way we’ll be able to only receive the packets coming from the ESP32, and the ESP32 will only receive packets sent by the wireless&nbsp;dongle.</p> <p>This idea unfortunately did not entirely work: enough radio waves from outside access points leaked into the antenna connector that the wireless dongle also receieved their packets. We tried to build a low-cost faraday cage from a paint can to prevent this, but this only attenuated outside signals with an extra 10dB: this removed some APs, but not all of them. The current solution is definitely not ideal, so we’ve started work on building a better and larger faraday cage, from conducting fabric and with fiber-optic data&nbsp;communication.</p> <figure> <a href="https://pics.zeus.gent/rqJc7p6pSbb6FInNNyadKy2tZy2uWqDaFtuU5KPx.jpg"> <img src="https://pics.zeus.gent/rqJc7p6pSbb6FInNNyadKy2tZy2uWqDaFtuU5KPx.jpg" alt="Wi-Fi dongle connected to the ESP32, with two 30 dB attenuators in between"> </a> <figcaption>Wi-Fi dongle connected to the ESP32, with two 30 dB attenuators in between</figcaption> </figure> <figure> <a href="https://pics.zeus.gent/ttmZlo7MpEP6CDzzc5q0QX4iVrg3vlsVFUAB6LEU.jpg"> <img src="https://pics.zeus.gent/ttmZlo7MpEP6CDzzc5q0QX4iVrg3vlsVFUAB6LEU.jpg" alt="Faraday cage made from a paint tin, with copper tape to close the hole for the USB connectors, and ferrite chokes to reduce the RF leaking in"> </a> <figcaption>Faraday cage made from a paint tin, with copper tape to close the hole for the USB connectors, and ferrite chokes to reduce the RF leaking in</figcaption> </figure> <h2 id="architecture">Architecture</h2> <h3 id="softmac-vs-hardmac">SoftMAC vs&nbsp;HardMAC</h3> <p>SoftMAC (Software MAC) and HardMAC (Hardware MAC) refer to two different approaches for implementing the MAC layer for Wi-Fi. SoftMAC relies on software to manage MAC layer functions, which offers flexibility and ease of modification but can consume more power/CPU cycles. HardMAC, on the other hand, offloads MAC layer processing to dedicated hardware, reducing CPU usage and power consumption but limiting the ability to adapt to new features without hardware&nbsp;changes.</p> <p>The ESP32 seems to use a SoftMAC approach: you can directly send and receive 802.11 frames (instead of with HardMAC, where you tell the hardware you want to connect to a certain AP, and it would then automatically craft the nescessary frames and send them). This is good news for our open source implementation, since there already exist open-source 802.11 MAC stacks for SoftMAC (for example, mac80211 in the Linux&nbsp;kernel).</p> <h3 id="peripherals">Peripherals</h3> <p>The Wi-Fi functionality is implemented via multiple hardware peripherals, each responsible for a separate part of the functionality. Through reverse engineering, the following peripherals were identified as ‘used for Wi-Fi functionaliy’ (these are memory addresses, through which the peripherals can be&nbsp;accessed):</p> <ul> <li>MAC peripherals, at 0x3ff73000 to 0x3ff73fff and at 0x3ff74000 to&nbsp;0x3ff74fff</li> <li>RX control registers, at 0x3ff5c000 to&nbsp;0x3ff5cfff</li> <li>baseband, at 0x3ff5d000 to&nbsp;0x3ff5dfff</li> <li> <code>chipv7_phy</code> (?) at 3ff71000 to&nbsp;3ff71fff</li> <li> <code>chipv7_wdev</code> (?) at 3ff75000 to&nbsp;3ff75fff</li> <li>RF frontend, at 3ff45000 to 3ff45fff and 3ff46000 to&nbsp;3ff46fff</li> <li>analog at 3ff4e000 to 3ff4efff (this is also used by the DAC connected to GPIO&nbsp;pins)</li> </ul> <p>It should be noted that these peripherals are mirrored to another place in the address&nbsp;space:</p> <blockquote> <p>Peripherals accessed by the CPU via 0x3FF40000 ~ 0x3FF7FFFF address space (DPORT address) can also be accessed via 0x60000000 ~ 0x6003FFFF (AHB address). (0x3FF40000 + n) address and (0x60000000 + n) address access the same content, where n = 0 ~&nbsp;0x3FFFF.</p> </blockquote> <h3 id="lifecyle">Lifecyle</h3> <p>By writing some minimal firmware that just sends packets in a loop and using the three reverse engineer strategies described earlier, a high level overview of the Wi-Fi hardware lifecycle for sending a packet was&nbsp;determined:</p> <ol> <li>Calling <code>esp_wifi_start()</code>, this indirectly calls&nbsp;<code>esp_phy_enable()</code> </li> <li> <code>esp_phy_enable()</code> is responsible for initializing the wifi&nbsp;hardware: <ol> <li>Calibrate the PHY hardware: this tries to compensate imperfections of the hardware. According to the data sheet, this does, at least: I/Q phase matching; antenna matching; compensating carrier leakage, baseband nonlinearities, power amplifier nonlinearities and RF nonlinearities (I’m more of a software person than an electronic engineer, so I don’t exactly know what these terms mean). This calibration can be stored to the non-volatile storage and to memory. This is used so we don’t have to do a full calibration every time the ESP32 wakes up from modem&nbsp;sleep.</li> <li>Initialize the MAC peripherals: set RX MAC address filters, set the buffers where the packets will be received into, set the auto-ACKing policy, set the chips own MAC&nbsp;address.</li> <li>Set various physical radio properties (TX rate, frequency, TX power,&nbsp;…)</li> <li>Set up the power management timer: if packets are not sent often enough, the modem power save timer kicks in and de-initializes part of the Wi-Fi hardware to save&nbsp;power.</li> </ol> </li> <li>Now, we’re ready to send a&nbsp;packet: <ol> <li>Wake up some Wi-Fi peripherals from deep sleep and restore their calibration, if we need&nbsp;to</li> <li>Set some metadata, related to the packet (likely the rate and other PHY&nbsp;settings)</li> <li>Create a DMA entry, consisting of the length of the packet and the address of the buffer containing the MAC data. The MAC Frame Checksum is automatically calculated by the hardware. DMA stands for Direct Memory Access: that means that we just tell the hardware the address and length of where our packet is, and the hardware will then read that memory and transmit the packet, all on its&nbsp;own.</li> <li>Write the lowest bits of the DMA entry into a hardware register, then enable it for transmission by setting a bit in the bitmask of that&nbsp;register.</li> <li>Once the packet is sent, interrupt 0 will fire to notify us how succesful the transmission was. We can react to collisions and timeouts (and probably also to ACKs received?). We also have to clear the interrupt bit that indicates a packet was&nbsp;sent.</li> </ol> </li> </ol> <h3 id="implementing-transmitting-packets">Implementing transmitting&nbsp;packets</h3> <p>As a (very limited) proof-of-concept, we wanted to send arbitrary 802.11 frames by directly using the memory mapped peripherals, so without using the SDK functions. As you can see in the lifecycle diagram above, before transmitting, we first need to initialize the wifi hardware. Unfortunately, this initialization is a lot more complex than sending packets: to intialize the hardware, about 50000 peripheral memory accesses are needed, compared to about 50 for transmitting a packet (including handling the interrupt). These are not exact numbers at all, but they give an idea about the complexity&nbsp;involved.</p> <p>For the basic ‘transmitting packets’ proof-of-concept, we are currently still using the proprietary functions to initialize the wifi hardware. We encountered the issue that after initializing, the modem power save timer would kick in and de-initialize the wifi peripherals, preventing us from sending packets. To work around this, we send a single packet using the SDK and then immediately call the undocumented <code>pm_disconnected_stop()</code> function, which disables the modem power save mode timer. After this, we can send arbitrary packets by directly writing to the MAC peripheral addresses. For this PoC, we don’t need to replace the interrupt handler for wifi events: the existing, proprietary handler will handle the ‘packet was sent’ interrupt just&nbsp;fine.</p> <p>The <a href="https://github.com/esp32-open-mac/esp32-open-mac">basic proof of concept</a> works, we can transmit arbitrary packets by directly writing and reading from memory&nbsp;addresses!</p> <h2 id="current-roadmap">Current&nbsp;roadmap</h2> <p>Now we can transmit packets, but we still have a lot of work ahead of us: this is the to-do list, in rough order of&nbsp;priorities</p> <ul> <li>☑ Send&nbsp;packets</li> <li>☐ Receive packets: to do this, we will need to do the&nbsp;following: <ul> <li>Set the RX policy (this filters packets based on MAC address) / enable promiscous mode to receive all&nbsp;packets</li> <li>Set the memory address in which we want to receive the packet via&nbsp;DMA</li> <li>Replace the wifi interrupt with our own interrupt; the code indicates that there might be some kind of wifi watchdog, we’ll need to figure out how to pet&nbsp;it.</li> </ul> </li> <li>☐ Send ACK (acknowledgment) packets back if we receive a packet that is destined for&nbsp;us</li> <li>☐ Implement changing the wifi channel, rate, transmit power,&nbsp;…</li> <li>☐ Combine our implementation with an existing open source 802.11 MAC stack, so the ESP32 can associate with access&nbsp;points</li> <li>☐ Implement the hardware initialization (now done by <code>esp_phy_enable()</code>). This will be a hard undertaking, since all calibration routines will need to be implemented, but also has a high payoff: we’ll then have a completely blob-free firmware for the&nbsp;ESP32.</li> </ul> <p>And a list of possible future extensions that are not yet on the roadmap, but are useful to do&nbsp;anyways:</p> <ul> <li>☐ Implement modem power saving: turning off the modem when not in&nbsp;use</li> <li>☐ AMSDU, AMPDU, HT40,&nbsp;QoS</li> <li>☐ Do the cryptography needed for WPA2 etc in hardware instead of in&nbsp;software</li> <li>☐&nbsp;Bluetooth</li> <li>☐ Write SVD documentation for all reverse engineered registers. An SVD file is an XML file that describes the hardware features of a microcontroller, this makes it possible to automatically generate an API from the hardware description. Espressif already has an SVD file containing the documented hardware registers; we can document the undocumented registers and (automatically) merge them&nbsp;in.</li> </ul> <h2 id="code">Code</h2> <p>All code and documentation is available in the <a href="https://github.com/esp32-open-mac/">esp32-open-mac GitHub organisation</a>. I think especially the QEMU fork can be useful for other reverse engineers because of the memory tracing&nbsp;feature.</p> <h2 id="update">Update</h2> <p>Since the beginning of writing this blog post, receiving packets was also implemented. To accomplish this, we needed to implement the Wi-Fi MAC interrupt handler and manage the RX DMA buffers. This means that we now can send and receive packets using only open source code: the hardware initialization is still done with proprietary code, but after this setup is done, only open source code is used to send and receive packets, no more proprietary code is executed. The second part is <a href="https://zeus.ugent.be/blog/23-24/esp32-reverse-engineering-continued/">here</a></p> <h2 id="questions-want-to-collaborate">Questions? Want to&nbsp;collaborate?</h2> <p>This is a sizeable project that could definitely use multiple contributors; I’d really like to collaborate with other people to create a fully functional, open-source Wi-Fi stack for the ESP32. If this sounds like something you’d like to work on, contact me via <a href="mailto:%7a%65%75%73%62%6c%6f%67%40%64%65%76%72%65%6b%65%72%2e%62e">zeusblog@<span>not</span>devreker.be</a>, maybe we can have a weekly hacking&nbsp;session?</p> <p>As far as I know, this is the first undertaking to build an open source 802.11 MAC for an affordable microcontroller. If you want to financially support this project, you can wire money via https://zeus.ugent.be/contact/#payment-info, please put “ESP32” in the transaction description, so our treasurer knows what the money is for. Please do not donate if you’re a student or if you’re not financially independent. If you’re a company and would like to donate hardware (for example, a faraday cage or measuring equipment that might be useful), please contact&nbsp;me.</p> <p><a href="https://nlnet.nl/project/ESP32-opendrivers/">This project</a> was funded through the <a href="https://nlnet.nl/core/">NGI0 Core Fund</a>, a fund established by NLnet with financial support from the European Commission’s Next Generation Internet programme, under the aegis of DG Communications Networks, Content and Technology under grant agreement No&nbsp;101092990.</p> <p>Feel free to send me an email in case you have questions, you think something in this blog post could be worded better or you spotted a&nbsp;mistake.</p> </div>  </article> </div></div>]]></description>
        </item>
    </channel>
</rss>