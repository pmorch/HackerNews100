<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 26 Aug 2024 19:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Using AI to fight insurance claim denials (154 pts)]]></title>
            <link>https://sfstandard.com/2024/08/23/holden-karau-fight-health-insurance-appeal-claims-denials/</link>
            <guid>41358132</guid>
            <pubDate>Mon, 26 Aug 2024 15:31:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sfstandard.com/2024/08/23/holden-karau-fight-health-insurance-appeal-claims-denials/">https://sfstandard.com/2024/08/23/holden-karau-fight-health-insurance-appeal-claims-denials/</a>, See on <a href="https://news.ycombinator.com/item?id=41358132">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>For San Francisco tech worker Holden Karau, paperwork had become a hobby.&nbsp;</p><p>Specifically, the forms and letters required to fight back when her health insurance provider denied a claim for a covered service, surgery, or pharmaceutical.&nbsp;</p><p>As a trans woman who loves motorcycles, she has required gender-affirming care and treatments for an accident in recent years, and received a spate of insurance denials along the way.&nbsp;</p><p>Instead of passively accepting the providers’ decisions, she’d spend hours writing letters and filling out forms to appeal. It usually worked: Out of roughly 40 denials, she won more than 90% of her appeals, she estimates. (She also successfully fought an insurance denial for her dog, Professor Timbit.)&nbsp;</p><p>“Part of that is an unreasonable willingness to take things too far,” Karau said. “There’s an enjoyment in getting a counterparty to follow the rules that they don’t seem to want to have to follow.”</p></div><figure id=""><div><p><span><span></span><img alt="A person wearing a pink shirt and a smartwatch is working on a laptop. They are using their right hand to point at the screen and their left hand is resting on the laptop." loading="lazy" decoding="async" data-nimg="responsive" sizes="(min-width: 1001px) 600px, (min-width: 768px) 700px, 100vw" srcset="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=640&amp;q=75 640w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=750&amp;q=75 750w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=768&amp;q=75 768w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=828&amp;q=75 828w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=1024&amp;q=75 1024w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=1080&amp;q=75 1080w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=1200&amp;q=75 1200w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=1920&amp;q=75 1920w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=2048&amp;q=75 2048w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=3840&amp;q=75 3840w" src="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-09.jpg?w=3840&amp;q=75" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><figcaption>Karau demonstrates the platform, which crafts appeals to health insurance denials. | <span>Source: </span>Emily Steinberger/The Standard</figcaption></figure><div><p>She began helping friends file appeals, too, then asked herself a question that’s typical for engineers: Could she figure out a way to automate the process?&nbsp;</p><p>After a year of tinkering, she just launched her answer: <a href="https://fighthealthinsurance.com/">Fight Health Insurance</a>, an open-source platform that takes advantage of large language models to help users generate health insurance appeals with AI.</p><p>With the slogan “Make your health insurance company cry too,” Karau’s site makes filing appeals faster and easier. <a href="https://www.kff.org/private-insurance/issue-brief/claims-denials-and-appeals-in-aca-marketplace-plans/">A recent study found that</a> Affordable Care Act patients appeal only about 0.1% of rejected claims, and she hopes her platform will encourage more people to fight back.&nbsp;</p></div><figure id=""><div><p><span><span></span><img alt="The image shows a tangle of multicolored cables connected to networking devices in a server rack, with wires coiled around various points and additional equipment nearby." loading="lazy" decoding="async" data-nimg="responsive" sizes="(min-width: 1001px) 600px, (min-width: 768px) 700px, 100vw" srcset="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=640&amp;q=75 640w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=750&amp;q=75 750w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=768&amp;q=75 768w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=828&amp;q=75 828w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=1024&amp;q=75 1024w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=1080&amp;q=75 1080w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=1200&amp;q=75 1200w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=1920&amp;q=75 1920w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=2048&amp;q=75 2048w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=3840&amp;q=75 3840w" src="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-11.jpg?w=3840&amp;q=75" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><figcaption>One of the servers that operates the platform is in Karau's basement office. | <span>Source: </span>Emily Steinberger/The Standard</figcaption></figure><div><p>“Most of the time, my relationship with my health insurance company is more adversarial than collaborative,” she said. “You’re trying to force them to comply with the rules, and they’re trying to spend the <a href="https://www.propublica.org/article/unitedhealth-healthcare-insurance-denial-ulcerative-colitis">least amount of money</a>.”&nbsp;</p><p>A Fight Health Insurance user can scan their insurance denial, and the system will craft several appeal letters to choose from and modify.&nbsp;</p><p>The “dirty secret” of the insurance industry is that most denials can be successfully appealed, according to Dr. Harley Schultz, a patient advocate in the Bay Area.</p><p>“Very few people know about the process, and even fewer take advantage of it, because it’s rather cumbersome, arcane, and confusing, by design,” he said. “But if you fight hard enough and long enough, most denials get overturned.”&nbsp;</p><p>It’s often assumed&nbsp; that only doctors can file appeals, but patients can do it too, he added. <a href="https://www.propublica.org/article/unitedhealth-healthcare-insurance-denial-ulcerative-colitis">Insurers reject about 1 in 7 claims</a> for treatment (Schultz estimates that it could be as high as 25% for some companies), and the reality is that physicians just don’t have time for all that filing.&nbsp;&nbsp;</p><p>“I was in practice for many years, and if I fought every insurance denial, there wouldn’t be any time to do anything else,” Schultz said.&nbsp;</p><p>While some doctors have <a href="https://www.nytimes.com/2024/07/10/health/doctors-insurers-artificial-intelligence.html">turned to artificial intelligence themselves</a> to fight claims, Karau’s service puts the power in the hands of patients, who likely have more time and motivation to dedicate to their claims.&nbsp;</p><p>“In an ideal world, we would have a different system, but we don’t live in an ideal world, so what I’m shooting for here is incremental progress and making the world suck a little less,” she said.&nbsp;</p><p>So far, dozens have used the platform to generate an appeal, and Karau is assessing their feedback to fine-tune the platform and make it more effective and easier to use.&nbsp;</p></div><figure id=""><div><p><span><span></span><img alt="The image shows a computer screen displaying a draft appeal for an insurance company to cover PrEP medication. The document argues for coverage based on medical necessity." loading="lazy" decoding="async" data-nimg="responsive" sizes="(min-width: 1001px) 600px, (min-width: 768px) 700px, 100vw" srcset="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=640&amp;q=75 640w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=750&amp;q=75 750w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=768&amp;q=75 768w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=828&amp;q=75 828w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=1024&amp;q=75 1024w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=1080&amp;q=75 1080w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=1200&amp;q=75 1200w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=1920&amp;q=75 1920w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=2048&amp;q=75 2048w, https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=3840&amp;q=75 3840w" src="https://content.sfstandard.com/wp-content/uploads/2024/08/20240821-techworkerhealthcare-es-10.jpg?w=3840&amp;q=75" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><figcaption>An example of an appeal letter generated by the AI platform. | <span>Source: </span>Emily Steinberger/The Standard</figcaption></figure><div><p>She&nbsp;estimates that she has spent about $10,000 building the platform. It’s free for users, though she might eventually charge for added services like faxing appeals.</p><p>At this point, she’s not planning on leaving her tech job to work on the platform full time (she has held gigs at IBM, Apple, Google, and Netflix, where she currently works) but hopes it can become a self-sustaining business, in addition to a cause about which she’s wildly passionate.&nbsp;</p><p>“The best-case scenario —&nbsp;which is, admittedly, incredibly unlikely —&nbsp;is that this increases the accessibility of appeals to the point that insurance companies stop denying so much tiny bullshit,” she said. “I suspect that they would still try to be dicks about big things, but hopefully we can get them to stop being dicks about small things.”</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dokku: My favorite personal serverless platform (317 pts)]]></title>
            <link>https://hamel.dev/blog/posts/dokku/</link>
            <guid>41358020</guid>
            <pubDate>Mon, 26 Aug 2024 15:21:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hamel.dev/blog/posts/dokku/">https://hamel.dev/blog/posts/dokku/</a>, See on <a href="https://news.ycombinator.com/item?id=41358020">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">




<div>
<figure>
<p><img src="https://hamel.dev/blog/posts/dokku/images/serverless.png"></p>
<figcaption>With Dokku, you can turn a VPS into a powerful serverless platform</figcaption>
</figure>
</div>
<section id="what-is-dokku">
<h2 data-anchor-id="what-is-dokku">What is Dokku?</h2>
<p><a href="https://dokku.com/">Dokku</a> is an open-source Platform as a Service (PaaS) that runs on a single server of your choice. <strong>It’s like <a href="https://www.heroku.com/">Heroku</a>, but you own it.</strong> It is a great way to get the benefits of Heroku without the costs (Heroku can get quite expensive!). I need to deploy many applications for my <a href="https://hamel.dev/hire.html">LLM consulting work</a>. Having a cost-effective, easy-to-use serverless platform is essential for me.</p>
<p><strong>I run a Dokku server on a $7/month VPS on <a href="https://us.ovhcloud.com/">OVHcloud</a></strong> for non-gpu workloads. These applications include things like <a href="https://nbsanity.com/">nbsanity</a> and <a href="https://langfree.parlance-labs.com/tutorials/shiny.html#run-the-shiny-app-locally">data cleaning tools for LLMs</a>.</p>
<p>Some of the features I love about Dokku:</p>
<ul>
<li>Easy to use (like Heroku).</li>
<li>Automatic SSL certificate management via <a href="https://letsencrypt.org/">Let’s Encrypt</a>.</li>
<li>Basic Auth support so I can password-protect sites.</li>
<li>Scale up and down with a single command.</li>
<li>Flexibility to handle any application (Node, Python, etc), including defining a Docker container.</li>
<li>Lots of <a href="https://dokku.com/docs/community/plugins/?h=plugins#official-plugins">official plugins</a> that do almost anything I want.</li>
<li>Easily deploy with git commands.</li>
</ul>
</section>
<section id="minimal-dokku-examples">
<h2>Minimal Dokku Examples</h2>
<p>Make sure you <a href="https://dokku.com/docs/getting-started/installation/">install Dokku</a> on your VPS. As I mentioned, I use <a href="https://us.ovhcloud.com/">OVH</a>.</p>
<section id="deploying-apps-as-a-docker-container">
<h2 data-anchor-id="deploying-apps-as-a-docker-container">Deploying Apps as A Docker Container</h2>
<p>An easy way to deploy applications is with a Docker container.</p>
<p>To deploy a Docker container, I put a Dockerfile in the root of my git repo like this:</p>
<div id="cb1" data-filename="Dockerfile"><pre><code><span id="cb1-1"><span>FROM</span> python:3.10</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span>COPY</span> . /app</span>
<span id="cb1-4"><span>WORKDIR</span> /app</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span># Install the local package</span></span>
<span id="cb1-7"><span>RUN</span> <span>pip</span> install .</span>
<span id="cb1-8"></span>
<span id="cb1-9"><span># This directory contains app.py, a FastApi app</span></span>
<span id="cb1-10"><span>WORKDIR</span> /app/</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span>ENTRYPOINT</span> [<span>"./entrypoint.sh"</span>]</span></code></pre></div>
<div>
<p>The <code>entrypoint.sh</code> script allows me to easily run the app locally or in a Docker container. It looks like this:</p>
<div id="cb2" data-filename="entrypoint.sh"><pre><code><span id="cb2-1"><span>#!/bin/bash</span></span>
<span id="cb2-2"><span>exec</span> uvicorn main:app <span>--port</span> <span>"</span><span>$PORT</span><span>"</span> <span>--host</span> 0.0.0.0</span></code></pre></div>
</div>
<p>On the Dokku host, create the app:</p>

<p><strong>Locally</strong>, set up access to the Dokku host and name it <code>dokku</code> in your <code>~/.ssh/config</code> file. For example, here is mine:</p>
<pre><code>Host dokku
  HostName &lt;The external IP address of your Dokku host&gt;
  User ubuntu
  IdentityFile /Users/hamel/.ssh/dokku</code></pre>
<p>Locally, add the Dokku host as a remote and push to it:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>git</span> remote add dokku dokku@dokku:myapp</span>
<span id="cb5-2"><span>git</span> push dokku main</span></code></pre></div>
<p>That’s it - your app should be running on the Dokku host! Your local logs will print the URL that your application is served on, which by default will be <code>myapp.yourdomain.com</code>. You can also scale it up/down with the following command:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>#scale to two workers</span></span>
<span id="cb6-2"><span>dokku</span> ps:scale myapp web=2</span></code></pre></div>
<p>We are just scratching the surface. For more details, see the <a href="https://dokku.com/docs/">Dokku docs</a>.</p>
</section>
<section id="static-sites">
<h2 data-anchor-id="static-sites">Static Sites</h2>
<p>GitHub Pages is annoying in that you can’t easily deploy private static sites without paying for an expensive Enterprise account. With Dokku, you can easily deploy a static site from a private GitHub Repo and password-protect it.</p>
<p>We will assume that you have a static site in a git repo in a folder named <code>_site</code>.</p>
<p><strong>On the Dokku host</strong>, create an app named <code>mysite</code> and set the <code>NGINX_ROOT</code> environment variable to <code>_site</code>:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>dokku</span> apps:create mysite</span>
<span id="cb7-2"><span>dokku</span> config:set static-site NGINX_ROOT=_site</span></code></pre></div>
<p>Also on the Dokku host, install <a href="https://github.com/dokku/dokku-http-auth">basic auth</a> and <a href="https://github.com/dokku/dokku-http-auth/issues/15#issuecomment-1637058437">set permissions</a> so the plugin can work properly.</p>
<div id="cb8"><pre><code><span id="cb8-1"><span># do setup for the auth plugin that we will use later</span></span>
<span id="cb8-2"><span>sudo</span> dokku plugin:install https://github.com/dokku/dokku-http-auth.git</span>
<span id="cb8-3"><span>sudo</span> chmod +x /home/dokku</span></code></pre></div>
<p>Then execute the following commands from the root of your git repo that contains the static site. :</p>
<div id="annotated-cell-8"><pre><code><a data-target-cell="annotated-cell-8" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-8-1"><span>touch</span> .static</span>
<a data-target-cell="annotated-cell-8" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-8-2"><span>echo</span> BUILDPACK_URL=https://github.com/dokku/buildpack-nginx <span>&gt;</span> .env</span>
<a data-target-cell="annotated-cell-8" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-8-3"><span>git</span> remote add dokku dokku@dokku:mysite</span></code></pre></div>
<dl>
<dt data-target-cell="annotated-cell-8" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="1" data-code-annotation="1">tells <code>dokku</code> that this is a static site</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="2" data-code-annotation="2">tells <code>dokku</code> to use the nginx buildpack for static sites (it will usually automatically detect this, but if you have a project with code and a static site, you need to tell it to use the nginx buildpack so it doesn’t get confused).</span>
</dd>
<dt data-target-cell="annotated-cell-8" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-8" data-code-lines="3" data-code-annotation="3">add the <code>dokku</code> host as a remote. For this to work, make sure <code>dokku</code> is a hostname in your <code>~/.ssh/config</code> file as described <a href="#deploying-apps-as-a-docker-container">in the previous section</a>.</span>
</dd>
</dl>
<p>Finally, deploy your application:</p>

<p>You can now add auth by running the following command on the Dokku host:</p>
<div id="cb10"><pre><code><span id="cb10-1"><span>dokku</span> http-auth:enable mysite <span>&lt;</span>username<span>&gt;</span> <span>&lt;</span>password<span>&gt;</span></span></code></pre></div>
<div>

<p>You can add multiple usernames/passwords and even filter specific IPs. See <a href="https://github.com/dokku/dokku-http-auth">the docs</a>.</p>
</div>
<div>
<p>It’s often desirable to have HTTPS for your site. Dokku makes this easy with the <a href="https://github.com/dokku/dokku-letsencrypt">Let’s Encrypt Plugin</a>, which will even auto-renew for you. I don’t use this, because I’m letting <a href="https://developers.cloudflare.com/dns/manage-dns-records/reference/proxied-dns-records/">Cloudflare handle this with its proxy</a>.</p>
<p>If you are using Cloudflare this way, activating this plugin will mess things up (don’t worry its easy to disable). Honestly, I think it’s easier to let Cloudflare handle it if you are already doing so.</p>
</div>
</section>
</section>
<section id="deploying-with-github-actions">
<h2>Deploying With GitHub Actions</h2>
<p>You can automatically deploy Dokku apps with GitHub Actions, which is helpful if you don’t want to fiddle with pushing to the Dokku host. Here is an example GitHub Action workflow that does this:</p>
<div id="cb11" data-filename="deploy-dokku.yml"><pre><code><span id="cb11-1"><span>name</span><span>:</span><span> CI</span></span>
<span id="cb11-2"><span>on</span><span>:</span></span>
<span id="cb11-3"><span>  </span><span>workflow_dispatch</span><span>:</span></span>
<span id="cb11-4"><span>  </span><span>push</span><span>:</span></span>
<span id="cb11-5"><span>    </span><span>branches</span><span>:</span><span> </span><span>[</span><span>main</span><span>]</span></span>
<span id="cb11-6"></span>
<span id="cb11-7"><span>concurrency</span><span>:</span><span> # Cancel previous jobs to avoid deploy locks on dokku</span></span>
<span id="cb11-8"><span>  </span><span>group</span><span>:</span><span> ${{ github.ref }}</span></span>
<span id="cb11-9"><span>  </span><span>cancel-in-progress</span><span>:</span><span> </span><span>true</span></span>
<span id="cb11-10"></span>
<span id="cb11-11"><span>jobs</span><span>:</span></span>
<span id="cb11-12"><span>  </span><span>deploy-dokku</span><span>:</span></span>
<span id="cb11-13"><span>    </span><span>runs-on</span><span>:</span><span> ubuntu-latest</span></span>
<span id="cb11-14"><span>    </span><span>steps</span><span>:</span></span>
<span id="cb11-15"><span>      </span><span>-</span><span> </span><span>name</span><span>:</span><span> Checkout code</span></span>
<span id="cb11-16"><span>        </span><span>uses</span><span>:</span><span> actions/checkout@v2</span></span>
<span id="cb11-17"><span>        </span><span>with</span><span>:</span></span>
<span id="cb11-18"><span>          </span><span>fetch-depth</span><span>:</span><span> </span><span>0</span></span>
<span id="cb11-19"><span>      </span></span>
<span id="cb11-20"><span>      </span><span>-</span><span> </span><span>name</span><span>:</span><span> Install SSH key</span></span>
<span id="cb11-21"><span>        run</span><span>: </span><span>|</span></span>
<span id="cb11-22">          echo "${{ secrets.DOKKU_SSH_PRIVATE_KEY }}" &gt; private_key.pem</span>
<span id="cb11-23">          chmod 600 private_key.pem</span>
<span id="cb11-24"></span>
<span id="cb11-25"><span>      </span><span>-</span><span> </span><span>name</span><span>:</span><span> Add remote and push</span></span>
<span id="cb11-26"><span>        run</span><span>: </span><span>|</span></span>
<span id="cb11-27">          git remote add dokku dokku@rechat.co:llm-eval</span>
<span id="cb11-28">          GIT_SSH_COMMAND="ssh -i private_key.pem -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no" git push dokku main -f</span></code></pre></div>
</section>
<section id="miscellaneous-tips">
<h2>Miscellaneous Tips</h2>
<p>These are things I often forget, so I’m writing them down here. For these examples, assume my app is named <code>llm-eval</code> and my host is <code>rechat.co</code>.</p>
<section id="run-commands-remotely">
<h2 data-anchor-id="run-commands-remotely">Run commands remotely</h2>
<p>You don’t have to ssh into the Dokku host just to execute commands. You can execute them remotely via the <code>dokku</code> user like this:</p>
<div id="cb12"><pre><code><span id="cb12-1"><span># https://dokku.com/docs/deployment/application-management/</span></span>
<span id="cb12-2"><span>ssh</span> dokku@rechat.co apps:list</span></code></pre></div>
</section>
<section id="docker-cache">
<h2 data-anchor-id="docker-cache">Docker cache</h2>
<p>This is how you can <a href="https://dokku.com/docs/advanced-usage/repository-management/">invalidate the docker cache</a> for a fresh build:</p>
<div id="cb13"><pre><code><span id="cb13-1"><span>ssh</span> dokku@rechat.co repo:purge-cache llm-eval</span></code></pre></div>
</section>
<section id="rebuild-without-pushing">
<h2 data-anchor-id="rebuild-without-pushing">Rebuild without pushing</h2>
<p>Sometimes you want to rebuild without pushing. There are <a href="https://dokku.com/docs/processes/process-management/">many ways to do this</a>, but one way is like this:</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>ssh</span> dokku@rehcat.co ps:rebuild llm-eval</span></code></pre></div>
</section>
</section>
<section id="why-did-i-write-this">
<h2>Why Did I Write This?</h2>
<p>I had to dig up these details whenever I wanted to deploy a new app, so I had to write it up anyway. I hope you find it useful, too!</p>


</section>

</main> <!-- /main -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DOJ Files Antitrust Suit Against RealPage, Maker of Rent-Setting Algorithm (156 pts)]]></title>
            <link>https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm</link>
            <guid>41357557</guid>
            <pubDate>Mon, 26 Aug 2024 14:36:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm">https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm</a>, See on <a href="https://news.ycombinator.com/item?id=41357557">Hacker News</a></p>
Couldn't get https://www.propublica.org/article/realpage-lawsuit-doj-antitrustdoj-files-antitrust-suit-against-maker-of-rent-setting-algorithm: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[NSA releases 1982 Grace Hopper lecture (316 pts)]]></title>
            <link>https://www.nsa.gov/helpful-links/nsa-foia/declassification-transparency-initiatives/historical-releases/view/article/3880193/capt-grace-hopper-on-future-possibilities-data-hardware-software-and-people-1982/</link>
            <guid>41356528</guid>
            <pubDate>Mon, 26 Aug 2024 12:37:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nsa.gov/helpful-links/nsa-foia/declassification-transparency-initiatives/historical-releases/view/article/3880193/capt-grace-hopper-on-future-possibilities-data-hardware-software-and-people-1982/">https://www.nsa.gov/helpful-links/nsa-foia/declassification-transparency-initiatives/historical-releases/view/article/3880193/capt-grace-hopper-on-future-possibilities-data-hardware-software-and-people-1982/</a>, See on <a href="https://news.ycombinator.com/item?id=41356528">Hacker News</a></p>
Couldn't get https://www.nsa.gov/helpful-links/nsa-foia/declassification-transparency-initiatives/historical-releases/view/article/3880193/capt-grace-hopper-on-future-possibilities-data-hardware-software-and-people-1982/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Fixing a Bug in Google Chrome as a First-Time Contributor (373 pts)]]></title>
            <link>https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/</link>
            <guid>41355303</guid>
            <pubDate>Mon, 26 Aug 2024 09:10:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/">https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/</a>, See on <a href="https://news.ycombinator.com/item?id=41355303">Hacker News</a></p>
Couldn't get https://cprimozic.net/blog/fixing-a-bug-in-google-chrome/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Dutch DPA fines Uber 290M euro because of transfers of drivers' data to the US (286 pts)]]></title>
            <link>https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us</link>
            <guid>41355021</guid>
            <pubDate>Mon, 26 Aug 2024 08:15:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us">https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us</a>, See on <a href="https://news.ycombinator.com/item?id=41355021">Hacker News</a></p>
Couldn't get https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-of-290-million-euro-on-uber-because-of-transfers-of-drivers-data-to-the-us: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Avante.nvim: Use Your Neovim Like Using Cursor AI IDE (210 pts)]]></title>
            <link>https://github.com/yetone/avante.nvim</link>
            <guid>41353835</guid>
            <pubDate>Mon, 26 Aug 2024 03:44:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/yetone/avante.nvim">https://github.com/yetone/avante.nvim</a>, See on <a href="https://news.ycombinator.com/item?id=41353835">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">avante.nvim</h2><a id="user-content-avantenvim" aria-label="Permalink: avante.nvim" href="#avantenvim"></a></p>
<p dir="auto"><strong>avante.nvim</strong> is a Neovim plugin designed to emulate the behaviour of the <a href="https://www.cursor.com/" rel="nofollow">Cursor</a> AI IDE. It provides users with AI-driven code suggestions and the ability to apply these recommendations directly to their source files with minimal effort.</p>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto">🥰 This project is undergoing rapid iterations, and many exciting features will be added successively. Stay tuned!</p>
</div>
<details open="">
  <summary>
    
    <span aria-label="Video description avante-2.mp4">avante-2.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/1206493/357962425-510e6270-b6cf-459d-9a2f-15b397d1fe53.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1Nzk2MjQyNS01MTBlNjI3MC1iNmNmLTQ1OWQtOWEyZi0xNWIzOTdkMWZlNTMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZDg4ZTIzYjU1Y2FlNDI5MjFlNDQxMGI1OGRkZTY2MGY0MmM0OTE1YmJiMGRmZTU1ZmRmN2M0N2VlMDIxNmY0NiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.0gv_uhlSjDbCgdHxz524wbNG9AWaIOjET2DF30C7aiM" data-canonical-src="https://private-user-images.githubusercontent.com/1206493/357962425-510e6270-b6cf-459d-9a2f-15b397d1fe53.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1Nzk2MjQyNS01MTBlNjI3MC1iNmNmLTQ1OWQtOWEyZi0xNWIzOTdkMWZlNTMubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZDg4ZTIzYjU1Y2FlNDI5MjFlNDQxMGI1OGRkZTY2MGY0MmM0OTE1YmJiMGRmZTU1ZmRmN2M0N2VlMDIxNmY0NiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.0gv_uhlSjDbCgdHxz524wbNG9AWaIOjET2DF30C7aiM" controls="controls" muted="muted">

  </video>
</details>

<details open="">
  <summary>
    
    <span aria-label="Video description avante-3.mp4">avante-3.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/1206493/358215978-86140bfd-08b4-483d-a887-1b701d9e37dd.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1ODIxNTk3OC04NjE0MGJmZC0wOGI0LTQ4M2QtYTg4Ny0xYjcwMWQ5ZTM3ZGQubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MTdjODAxMGQ5ZDFjMDg2NDBjMGZjZTg0N2FiY2ZiYTY0NWRkMjU5YTgyNTFjYTAyNTllYjNiNzIzMmJjNWMxOCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.imMakzMmOSIjDueTLrg3ZsLKzhV_gb2Ue5zKYjzYSEs" data-canonical-src="https://private-user-images.githubusercontent.com/1206493/358215978-86140bfd-08b4-483d-a887-1b701d9e37dd.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2NzIxMDIsIm5iZiI6MTcyNDY3MTgwMiwicGF0aCI6Ii8xMjA2NDkzLzM1ODIxNTk3OC04NjE0MGJmZC0wOGI0LTQ4M2QtYTg4Ny0xYjcwMWQ5ZTM3ZGQubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDgyNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA4MjZUMTEzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MTdjODAxMGQ5ZDFjMDg2NDBjMGZjZTg0N2FiY2ZiYTY0NWRkMjU5YTgyNTFjYTAyNTllYjNiNzIzMmJjNWMxOCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.imMakzMmOSIjDueTLrg3ZsLKzhV_gb2Ue5zKYjzYSEs" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>AI-Powered Code Assistance</strong>: Interact with AI to ask questions about your current code file and receive intelligent suggestions for improvement or modification.</li>
<li><strong>One-Click Application</strong>: Quickly apply the AI's suggested changes to your source code with a single command, streamlining the editing process and saving time.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Install <code>avante.nvim</code> using <a href="https://github.com/folke/lazy.nvim">lazy.nvim</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;yetone/avante.nvim&quot;,
  event = &quot;VeryLazy&quot;,
  build = &quot;make&quot;,
  opts = {
    -- add any opts here
  },
  dependencies = {
    &quot;nvim-tree/nvim-web-devicons&quot;, -- or echasnovski/mini.icons
    &quot;stevearc/dressing.nvim&quot;,
    &quot;nvim-lua/plenary.nvim&quot;,
    &quot;MunifTanjim/nui.nvim&quot;,
    --- The below is optional, make sure to setup it properly if you have lazy=true
    {
      'MeanderingProgrammer/render-markdown.nvim',
      opts = {
        file_types = { &quot;markdown&quot;, &quot;Avante&quot; },
      },
      ft = { &quot;markdown&quot;, &quot;Avante&quot; },
    },
  },
}"><pre>{
  <span><span>"</span>yetone/avante.nvim<span>"</span></span>,
  <span>event</span> <span>=</span> <span><span>"</span>VeryLazy<span>"</span></span>,
  <span>build</span> <span>=</span> <span><span>"</span>make<span>"</span></span>,
  <span>opts</span> <span>=</span> {
    <span><span>--</span> add any opts here</span>
  },
  <span>dependencies</span> <span>=</span> {
    <span><span>"</span>nvim-tree/nvim-web-devicons<span>"</span></span>, <span><span>--</span> or echasnovski/mini.icons</span>
    <span><span>"</span>stevearc/dressing.nvim<span>"</span></span>,
    <span><span>"</span>nvim-lua/plenary.nvim<span>"</span></span>,
    <span><span>"</span>MunifTanjim/nui.nvim<span>"</span></span>,
    <span><span>---</span> The below is optional, make sure to setup it properly if you have lazy=true</span>
    {
      <span><span>'</span>MeanderingProgrammer/render-markdown.nvim<span>'</span></span>,
      <span>opts</span> <span>=</span> {
        <span>file_types</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
      },
      <span>ft</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
    },
  },
}</pre></div>
<p dir="auto">For Windows users, change the build command to the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;yetone/avante.nvim&quot;,
  event = &quot;VeryLazy&quot;,
  build = &quot;powershell -ExecutionPolicy Bypass -File Build-LuaTiktoken.ps1&quot;,
  -- rest of the config
}"><pre>{
  <span><span>"</span>yetone/avante.nvim<span>"</span></span>,
  <span>event</span> <span>=</span> <span><span>"</span>VeryLazy<span>"</span></span>,
  <span>build</span> <span>=</span> <span><span>"</span>powershell -ExecutionPolicy Bypass -File Build-LuaTiktoken.ps1<span>"</span></span>,
  <span><span>--</span> rest of the config</span>
}</pre></div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto"><code>avante.nvim</code> is currently only compatible with Neovim 0.10.0 or later. Please ensure that your Neovim version meets these requirements before proceeding.</p>
</div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto">If your neovim doesn't use LuaJIT, then change <code>build</code> to <code>make lua51</code>. By default running make will install luajit.
For ARM-based setup, make sure to also install cargo as we will have to build the tiktoken_core from source.</p>
</div>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto">Recommended <strong>Neovim</strong> options:</p>
<div dir="auto" data-snippet-clipboard-copy-content="-- views can only be fully collapsed with the global statusline
vim.opt.laststatus = 3
-- Default splitting will cause your main splits to jump when opening an edgebar.
-- To prevent this, set `splitkeep` to either `screen` or `topline`.
vim.opt.splitkeep = &quot;screen&quot;"><pre><span><span>--</span> views can only be fully collapsed with the global statusline</span>
<span>vim</span>.<span>opt</span>.<span>laststatus</span> <span>=</span> <span>3</span>
<span><span>--</span> Default splitting will cause your main splits to jump when opening an edgebar.</span>
<span><span>--</span> To prevent this, set `splitkeep` to either `screen` or `topline`.</span>
<span>vim</span>.<span>opt</span>.<span>splitkeep</span> <span>=</span> <span><span>"</span>screen<span>"</span></span></pre></div>
</div>
<div dir="auto"><p dir="auto">Note</p>
<p dir="auto"><code>render-markdown.nvim</code> is an optional dependency that is used to render the markdown content of the chat history. Make sure to also include <code>Avante</code> as a filetype
to its setup:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;MeanderingProgrammer/render-markdown.nvim&quot;,
  opts = {
    file_types = { &quot;markdown&quot;, &quot;Avante&quot; },
  },
  ft = { &quot;markdown&quot;, &quot;Avante&quot; },
}"><pre>{
  <span><span>"</span>MeanderingProgrammer/render-markdown.nvim<span>"</span></span>,
  <span>opts</span> <span>=</span> {
    <span>file_types</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
  },
  <span>ft</span> <span>=</span> { <span><span>"</span>markdown<span>"</span></span>, <span><span>"</span>Avante<span>" </span></span>},
}</pre></div>
</div>
<p dir="auto">Default setup configuration:</p>
<p dir="auto"><em>See <a href="https://github.com/yetone/avante.nvim/blob/main/lua/avante/config.lua">config.lua#L9</a> for the full config</em></p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  ---@alias Provider &quot;openai&quot; | &quot;claude&quot; | &quot;azure&quot;  | &quot;copilot&quot; | [string]
  provider = &quot;claude&quot;,
  claude = {
    endpoint = &quot;https://api.anthropic.com&quot;,
    model = &quot;claude-3-5-sonnet-20240620&quot;,
    temperature = 0,
    max_tokens = 4096,
  },
  mappings = {
    ask = &quot;<leader>aa&quot;,
    edit = &quot;<leader>ae&quot;,
    refresh = &quot;<leader>ar&quot;,
    --- @class AvanteConflictMappings
    diff = {
      ours = &quot;co&quot;,
      theirs = &quot;ct&quot;,
      none = &quot;c0&quot;,
      both = &quot;cb&quot;,
      next = &quot;]x&quot;,
      prev = &quot;[x&quot;,
    },
    jump = {
      next = &quot;]]&quot;,
      prev = &quot;[[&quot;,
    },
    submit = {
      normal = &quot;<CR>&quot;,
      insert = &quot;<C-s>&quot;,
    },
    toggle = {
      debug = &quot;<leader>ad&quot;,
      hint = &quot;<leader>ah&quot;,
    },
  },
  hints = { enabled = true },
  windows = {
    wrap = true, -- similar to vim.o.wrap
    width = 30, -- default % based on available width
    sidebar_header = {
      align = &quot;center&quot;, -- left, center, right for title
      rounded = true,
    },
  },
  highlights = {
    ---@type AvanteConflictHighlights
    diff = {
      current = &quot;DiffText&quot;,
      incoming = &quot;DiffAdd&quot;,
    },
  },
  --- @class AvanteConflictUserConfig
  diff = {
    debug = false,
    autojump = true,
    ---@type string | fun(): any
    list_opener = &quot;copen&quot;,
  },
}"><pre>{
  <span><span>---</span><span>@alias</span> <span>Provider</span> <span><span>"</span>openai<span>" </span></span><span>| </span><span><span>"</span>claude<span>" </span></span><span>| </span><span><span>"</span>azure<span>"  </span></span><span>| </span><span><span>"</span>copilot<span>" </span></span><span>| </span><span>[string]</span></span>
  <span>provider</span> <span>=</span> <span><span>"</span>claude<span>"</span></span>,
  <span>claude</span> <span>=</span> {
    <span>endpoint</span> <span>=</span> <span><span>"</span>https://api.anthropic.com<span>"</span></span>,
    <span>model</span> <span>=</span> <span><span>"</span>claude-3-5-sonnet-20240620<span>"</span></span>,
    <span>temperature</span> <span>=</span> <span>0</span>,
    <span>max_tokens</span> <span>=</span> <span>4096</span>,
  },
  <span>mappings</span> <span>=</span> {
    <span>ask</span> <span>=</span> <span><span>"</span>&lt;leader&gt;aa<span>"</span></span>,
    <span>edit</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ae<span>"</span></span>,
    <span>refresh</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ar<span>"</span></span>,
    <span><span>---</span><span> @class</span> <span>AvanteConflictMappings</span></span>
    <span>diff</span> <span>=</span> {
      <span>ours</span> <span>=</span> <span><span>"</span>co<span>"</span></span>,
      <span>theirs</span> <span>=</span> <span><span>"</span>ct<span>"</span></span>,
      <span>none</span> <span>=</span> <span><span>"</span>c0<span>"</span></span>,
      <span>both</span> <span>=</span> <span><span>"</span>cb<span>"</span></span>,
      <span>next</span> <span>=</span> <span><span>"</span>]x<span>"</span></span>,
      <span>prev</span> <span>=</span> <span><span>"</span>[x<span>"</span></span>,
    },
    <span>jump</span> <span>=</span> {
      <span>next</span> <span>=</span> <span><span>"</span>]]<span>"</span></span>,
      <span>prev</span> <span>=</span> <span><span>"</span>[[<span>"</span></span>,
    },
    <span>submit</span> <span>=</span> {
      <span>normal</span> <span>=</span> <span><span>"</span>&lt;CR&gt;<span>"</span></span>,
      <span>insert</span> <span>=</span> <span><span>"</span>&lt;C-s&gt;<span>"</span></span>,
    },
    <span>toggle</span> <span>=</span> {
      <span>debug</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ad<span>"</span></span>,
      <span>hint</span> <span>=</span> <span><span>"</span>&lt;leader&gt;ah<span>"</span></span>,
    },
  },
  <span>hints</span> <span>=</span> { <span>enabled</span> <span>=</span> <span>true</span> },
  <span>windows</span> <span>=</span> {
    <span>wrap</span> <span>=</span> <span>true</span>, <span><span>--</span> similar to vim.o.wrap</span>
    <span>width</span> <span>=</span> <span>30</span>, <span><span>--</span> default % based on available width</span>
    <span>sidebar_header</span> <span>=</span> {
      <span>align</span> <span>=</span> <span><span>"</span>center<span>"</span></span>, <span><span>--</span> left, center, right for title</span>
      <span>rounded</span> <span>=</span> <span>true</span>,
    },
  },
  <span>highlights</span> <span>=</span> {
    <span><span>---</span><span>@type</span> <span>AvanteConflictHighlights</span></span>
    <span>diff</span> <span>=</span> {
      <span>current</span> <span>=</span> <span><span>"</span>DiffText<span>"</span></span>,
      <span>incoming</span> <span>=</span> <span><span>"</span>DiffAdd<span>"</span></span>,
    },
  },
  <span><span>---</span><span> @class</span> <span>AvanteConflictUserConfig</span></span>
  <span>diff</span> <span>=</span> {
    <span>debug</span> <span>=</span> <span>false</span>,
    <span>autojump</span> <span>=</span> <span>true</span>,
    <span><span>---</span><span>@type</span> <span>string </span><span>| </span><span>fun</span><span>(): </span><span>any</span></span>
    <span>list_opener</span> <span>=</span> <span><span>"</span>copen<span>"</span></span>,
  },
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Given its early stage, <code>avante.nvim</code> currently supports the following basic functionalities:</p>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto">Avante will only support OpenAI (and its variants including copilot and azure), and Claude out-of-the-box due to its high code quality generation.
For all OpenAI-compatible providers, see <a href="https://github.com/yetone/avante.nvim/wiki">wiki</a> for more details.</p>
</div>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto">For most consistency between neovim session, it is recommended to set the environment variables in your shell file.
By default, <code>Avante</code> will prompt you at startup to input the API key for the provider you have selected.</p>
<p dir="auto">For Claude:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export ANTHROPIC_API_KEY=your-api-key"><pre><span>export</span> ANTHROPIC_API_KEY=your-api-key</pre></div>
<p dir="auto">For OpenAI:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export OPENAI_API_KEY=your-api-key"><pre><span>export</span> OPENAI_API_KEY=your-api-key</pre></div>
<p dir="auto">For Azure OpenAI:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export AZURE_OPENAI_API_KEY=your-api-key"><pre><span>export</span> AZURE_OPENAI_API_KEY=your-api-key</pre></div>
</div>
<ol dir="auto">
<li>Open a code file in Neovim.</li>
<li>Use the <code>:AvanteAsk</code> command to query the AI about the code.</li>
<li>Review the AI's suggestions.</li>
<li>Apply the recommended changes directly to your code with a simple command or key binding.</li>
</ol>
<p dir="auto"><strong>Note</strong>: The plugin is still under active development, and both its functionality and interface are subject to significant changes. Expect some rough edges and instability as the project evolves.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Bindings</h2><a id="user-content-key-bindings" aria-label="Permalink: Key Bindings" href="#key-bindings"></a></p>
<p dir="auto">The following key bindings are available for use with <code>avante.nvim</code>:</p>
<ul dir="auto">
<li><kbd>Leader</kbd><kbd>a</kbd><kbd>a</kbd> — show sidebar</li>
<li><kbd>Leader</kbd><kbd>a</kbd><kbd>r</kbd> — show sidebar</li>
<li><kbd>c</kbd><kbd>o</kbd> — choose ours</li>
<li><kbd>c</kbd><kbd>t</kbd> — choose theirs</li>
<li><kbd>c</kbd><kbd>b</kbd> — choose both</li>
<li><kbd>c</kbd><kbd>0</kbd> — choose none</li>
<li><kbd>]</kbd><kbd>x</kbd> — move to previous conflict</li>
<li><kbd>[</kbd><kbd>x</kbd> — move to next conflict</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Highlight Groups</h2><a id="user-content-highlight-groups" aria-label="Permalink: Highlight Groups" href="#highlight-groups"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Highlight Group</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>AvanteTitle</td>
<td>Title</td>
</tr>
<tr>
<td>AvanteReversedTitle</td>
<td>Used for rounded border</td>
</tr>
<tr>
<td>AvanteSubtitle</td>
<td>Selected code title</td>
</tr>
<tr>
<td>AvanteReversedSubtitle</td>
<td>Used for rounded border</td>
</tr>
<tr>
<td>AvanteThirdTitle</td>
<td>Prompt title</td>
</tr>
<tr>
<td>AvanteReversedThirdTitle</td>
<td>Used for rounded border</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">TODOs</h2><a id="user-content-todos" aria-label="Permalink: TODOs" href="#todos"></a></p>
<ul>
<li> Chat with current file</li>
<li> Apply diff patch</li>
<li> Chat with the selected block</li>
<li> Slash commands</li>
<li> Edit the selected block</li>
<li> Smart Tab (Cursor Flow)</li>
<li> Chat with project</li>
<li> Chat with selected files</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<ul dir="auto">
<li><strong>Enhanced AI Interactions</strong>: Improve the depth of AI analysis and recommendations for more complex coding scenarios.</li>
<li><strong>LSP + Tree-sitter + LLM Integration</strong>: Integrate with LSP and Tree-sitter and LLM to provide more accurate and powerful code suggestions and analysis.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions to avante.nvim are welcome! If you're interested in helping out, please feel free to submit pull requests or open issues. Before contributing, ensure that your code has been thoroughly tested.</p>
<p dir="auto">See <a href="https://github.com/yetone/avante.nvim/wiki">wiki</a> for more recipes and tricks.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">avante.nvim is licensed under the Apache License. For more details, please refer to the <a href="https://github.com/yetone/avante.nvim/blob/main/LICENSE">LICENSE</a> file.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Removing stuff is never obvious yet often better (421 pts)]]></title>
            <link>https://www.gkogan.co/removing-stuff/</link>
            <guid>41353328</guid>
            <pubDate>Mon, 26 Aug 2024 01:59:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gkogan.co/removing-stuff/">https://www.gkogan.co/removing-stuff/</a>, See on <a href="https://news.ycombinator.com/item?id=41353328">Hacker News</a></p>
Couldn't get https://www.gkogan.co/removing-stuff/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Server Setup Basics for Self Hosting (161 pts)]]></title>
            <link>https://becomesovran.com/blog/server-setup-basics.html</link>
            <guid>41353284</guid>
            <pubDate>Mon, 26 Aug 2024 01:50:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://becomesovran.com/blog/server-setup-basics.html">https://becomesovran.com/blog/server-setup-basics.html</a>, See on <a href="https://news.ycombinator.com/item?id=41353284">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p>This is a post I've been meaning to do for a while. While it's simple to
                explain how to set up an app for self-hosting, it's pointless to host an app on a weak foundation.
                It's a massive pain in my ass to start every how to with a section on server setup, so I'm
                also making this post for myself as a reference on how I like to set up a server for apps I'm
                hosting. I'll start with basic stuff like proper login with SSH and non-root user set up and making
                users for each app. I'll also touch on NGINX setup, some quality of life tools that make server
                management easier, log management and basic network security.<br>‍<br></p>
              <ul role="list">
                <li>
                  <a href="#ssh">SSH</a>
                </li>
                <li>
                  <a href="#users">Users</a>
                </li>
                <li>
                  <a href="#logs">Logs</a>
                </li>
                <li>
                  <a href="#backups">Backups</a>
                </li>
                <li>
                  <a href="#network">Basic Network Safety</a>
                </li>
                <li>
                  <a href="#nginx">NGINX</a>
                </li>
                <li>
                  <a href="#qol">Quality of Life Tools</a>
                </li>
                <li>
                  <a href="#dns">DNS</a>
                </li>
                <li>
                  <a href="#docker">Docker</a>
                </li>
              </ul>
              <h2 id="ssh"><p>SSH</p></h2>
              <p>First is login. You’ll need a way to access your device securely. Don't even
                mess with username and password. You want to use SSH (Secure Shell) and make sure that SSH is the only
                way to log in. To do that, you’ll need an SSH key and a new user account. On a newly provisioned VPS,
                you'll be logged in as root, and you want to protect the root account. First off on the VPS or
                remote machine make a new regular user with and add them to the “sudo” group with:</p>
              <pre contenteditable="false"><code><span>sudo adduser newuser
</span>
sudo usermod -aG sudo newuser</code></pre>
              <p><br>Now on your local machine run:<br></p>
              <pre contenteditable="false"><code><span>ssh-keygen -t ed25519 -C </span><span>"your_email@example.com"</span></code></pre>
              <p><br>Follow the instructions, it should ask you where you want to save the file and
                if you want a password or not. Make sure you set a string one. To copy the public key over to your
                server run on your local machine:</p>
              <pre contenteditable="false"><code><span>ssh-copy-id -i ~/.ssh/id_ed25519.pub newuser@your_server_ip</span></code></pre>
              <p><br>Keep in mind newuser@your-server-ip is the username and the remote device you
                are trying to copy your public key into. When you get prompted for a password, it will be the password
                for the account on the remote device, NOT the password you just made for the SSH key. Once verified, it
                will copy over the public key, and you can now log in Via SSH. To turn off username and password login,
                type in:<br>‍</p>
              <pre contenteditable="false"><code><span>sudo nano /etc/ssh/sshd_config</span></code></pre>
              <p><br>Find these values and set them as you see them here.<br>‍</p>
              <pre contenteditable="false"><code><span>Port 2222     </span><span># Change default port (use a number between 1024 and 65535)</span><span>
</span><span>PermitRootLogin no                 </span><span># Disable root login</span><span>
</span><span>PasswordAuthentication no          </span><span># Disable password authentication</span><span>
</span><span>PubkeyAuthentication yes           </span><span># Enable public key authentication</span><span>
</span><span>AuthorizedKeysFile .ssh/authorized_keys </span><span># Specify authorized_keys file location</span><span>
</span><span>AllowUsers newuser                 </span><span># Only allow specific users to login</span></code></pre>
              <p><br>This disallows every login method besides SSH under the user you copied your
                public key to. Stops login as Root and only allows the user you specify to log in. Hit CTL+S to save and
                CTL+x to get out of the file editor. Restart SSH:<br>‍<br></p>
              <pre contenteditable="false"><code><span>sudo service ssh restart</span></code></pre>
              <p><br>This might boot you out of the session. If it does, this is a good time to test
                the other login methods to see if they are declined before continuing. Also, it should go without
                saying, but you need to keep the private key safe and if you lose it you will not be able to get in
                remotely anymore.You can further lock down your login with: <br>‍</p>
              <pre contenteditable="false"><code><span>Protocol 2                 </span><span># Use only SSH protocol version 2</span><span>
</span><span>MaxAuthTries 3             </span><span># Limit authentication attempts</span><span>
</span><span>ClientAliveInterval 300    </span><span># Client alive interval in seconds</span><span>
</span><span>ClientAliveCountMax 2      </span><span># Maximum client alive count</span></code></pre>
              <p><br>Now, let's dive into users a bit more and see how we can leverage them for
                a bit of organization and security.</p>
              <h2 id="users"><p>Users</p></h2>
              <div><p>Users are important when it comes to managing a Linux server. There
                is an idea in server management called the “Principle of The Least Privilege” this basically means that
                you want to give an app or process the minimum amount of privileges that it needs to do its job. Root
                has unlimited power, and no app really needs this. Making a user for apps that you're running
                accomplishes a few things. It can limit potential damage if an application you are running is
                compromised. It adds isolation when running more than one app, it helps with auditing so you know what
                app is using what system resources. </p><p>In short, users are a great way of helping organize your
                system and helps you troubleshoot if and when things go wrong. To add a new user, run:<br>‍</p></div>
              <pre contenteditable="false"><code><span>sudo useradd -rms /usr/sbin/nologin -c </span><span>"a comment"</span><span> youruser</span></code></pre>
              <p><br>This command makes a user and gives them a home directory for app
                data but does not allow login as the user. The -c flag is optional, but It's nice to know what the
                user is for, like “Running Nextcloud” or whatever. Clone app files into the /opt directory with:<br>‍
              </p>
              <pre contenteditable="false"><code><span>sudo mkdir /opt/myapp</span></code></pre>
              <p><br>This command makes a user and gives them a home directory for app
                data but does not allow login as the user. The -c flag is optional, but It's nice to know what the
                user is for, like “Running Nextcloud” or whatever. Clone app files into the /opt directory with:<br>‍
              </p>
              <pre contenteditable="false"><code><span>sudo chown appuser:appuser /opt/myapp</span></code></pre>
              <p><br>Ok, with this your login is locked down, and you should have a decent
                idea about how to use users. Next is logs.<br>‍</p>
              <h2 id="logs"><strong><p>Logs</p></strong></h2>
              <p><br>Logs are crucial to system administration. They keep track of system
                health, help troubleshoot issues and detect threats. So you want to set up proper log rotation so they
                do not take up too much space on your system, plus are easier to read and manage. To set up proper log
                rotation, you want to edit the logrotate.conf file located in /etc. Individual application
                configurations are typically stored in /etc/logrotate.d/, so an example configuration for NGINX would
                look like:<br>‍<br></p>
              <pre contenteditable="false"><code><span>/var/</span><span>log</span><span>/nginx/*.</span><span>log</span><span> {
</span>    weekly
    missingok
    rotate 52
    compress
    delaycompress
    notifempty
    create 0640 www-data adm
    sharedscripts
    postrotate
<span>        [ -f /var/run/nginx.pid ] &amp;&amp; </span><span>kill</span><span> -USR1 `cat /var/run/nginx.pid`
</span>    endscript
}
</code></pre>
              <p><br>This configuration rotates logs weekly, keeps 52 weeks of logs,
                compresses old logs, makes new logs with the right permissions and then signals NGINX to reopen log
                files after rotation. You can test it with:<br></p>
              <pre contenteditable="false"><code><span>sudo logrotate -d /etc/logrotate.conf</span></code></pre>
              <p><br>This will show what it will do without actually rotating logs. With
                this all set up, you can start to do more advanced stuff like triggering alerts based on log entries.
                Now this is good for a single server but if you manage more than one server it's a good idea to
                look into tools like Grafana Loki, Graylog and Fluentd. I won't go into detail here, but if
                you're looking to up your log game, these a decent place to start.<br>‍<br></p>
              <h2 id="backups"><strong><p>Backups</p></strong></h2>
              <div><p>Backups, and more importantly, testing your backups, are extremely
                important in server management. Remember: a backup is not a backup unless you test it. Untested backups
                are essentially useless.</p><p>

                There are three main types of backups. Full, Differential, Incremental. Full backups are a complete copy
                of all data on a disk. Takes the most resources, but is the easiest to restore from. Differential
                backups back up all the changes since the last full backup, it's a middle ground strategy for backups on
                both space and restoration speed. An incremental backup backs up data that was changed since the last
                backup, this is the fastest backup option but can be the most complex to restore.</p><p>

                I think of it like this. I use incremental backups for things like photos and documents or project files
                and folders that get edited a lot. I'll use a full backup for backing up and entire server or disk.
                Differential backups Ill use for backing up full folders like /etc, /opt and log folders.</p><p>

                Now what about storage? If you follow the 3-2-1 rule, you will be golden. 3 copies of your data, 2
                storage types, and 1 offsite backup. I'd say if this seems like too much, the “offsite” storage is the
                most important and not one to skip. In case of a catastrophic meltdown, having a hard disk with your
                backups is invaluable. Offsite / offline backups can also save your ass from ransomware. So keep that in
                mind. There is a huge amount of backup software out there. <a href="https://github.com/awesome-foss/awesome-sysadmin#backups" target="_blank">This link</a> is for exploring some more
                professional backup tools. <a href="https://github.com/awesome-selfhosted/awesome-selfhosted?tab=readme-ov-file#file-transfer--synchronization" target="_blank">This link</a> has file sync, transfer and could storage solutions. I use a combo
                of sync-thing, Borg backup and good old-fashioned FTP.</p><p>

                Remember, that backup, logs and server monitoring is an evolving process based on your needs. The
                specific strategy you implement should be tailored to your needs and the criticality of your data.</p></div>


              <h2 id="network"><strong><p>Basic Network Safety</p></strong></h2>
              <p><br>The next step in securing a server is to lock down ports that need
                don’t need to be exposed to the internet and banning things that try to log in when they should not. UFW
                and Fail2Ban are two tools that are in widespread use for this. They are simple and easy to use, UFW
                lets you set traffic rules for ports and Fail2Ban will ban and IP address when it knocks on a port they
                should not be or if they fail to log in after some predefined rules. UFW or uncomplicated firewall often
                comes preinstalled on a lot of VPS services, same with Fail2Ban, but if you are on a new machine and
                you're unsure, run:<br>‍</p>
              <pre contenteditable="false"><code><span>sudo apt install ufw
</span>
sudo apt install fail2ban</code></pre>
              <h3 id="ufw"><strong><br>UFW</strong></h3>
              <p><br>We will worry about Fail2Ban later, for now let's focus on UFW
                setup. First run some default policys with:<br></p>
              <pre contenteditable="false"><code><span>sudo ufw default deny incoming
</span> 
sudo ufw allow outgoing</code></pre>
              <p><br>This is considered best practice, as it follows the “the least
                privileges” idea I touched on earlier. It reduces attack surface on your machine and gives you precise
                control over what you do expose. In short, this configuration creates a balance between security and
                functionality. Your server can reach out to the internet as needed, but external entities can only
                connect to your server in ways you've explicitly allowed. Now let's allow some stuff
                in.<br>‍<br></p>
              <pre contenteditable="false"><code><span>sudo ufw allow ssh
</span>sudo ufw allow 80
sudo ufw allow 443</code></pre>
              <p><br>If you are going to be running a web server, you need port 80 and
                port 443 open. 80 is HTTP and 443 is HTTPS. By default, port 22 is SSH, if you changed this you need to
                specify the port instead of using the “allow ssh” command. Here are some other useful commands:
                <br>‍<br>
              </p>
              <pre contenteditable="false"><code><span>#List rules with numbers:</span><span>
</span>sudo ufw status numbered
<span></span><span>#Delete by number:</span><span>
</span>sudo ufw delete NUMBER
<span></span><span>#Delete by rule specification:</span><span>
</span>sudo ufw delete allow 80
<span></span><span>#You can allow connections from specific IP addresses:</span><span>
</span>sudo ufw allow from 192.168.1.100
<span></span><span>#You can also only allow an IP to connect to a specfic port with: </span><span>
</span>sudo ufw allow from 192.168.1.100 to any port 22
<span></span><span>#If you neeed to allow a range of ports: </span><span>
</span>sudo ufw allow 6000:6007/tcp
<span></span><span>#To further protect from brut force attacks you can rate limit specific ports with: </span><span>
</span><span>sudo ufw </span><span>limit</span><span> ssh
</span><span></span><span>#This would limit port 22 to 6 connections in 30 seconds from a single IP. To see the status of the firewall you can use: </span><span>
</span>
<span></span><span>#Adding this goves you more info</span><span>
</span>sudo ufw status verbose
<span></span><span>#and to reset incase you need to start over: </span><span>
</span>sudo ufw reset
<span></span><span>#and to enable and disable: </span><span>
</span><span>sudo ufw </span><span>enable</span><span> 
</span><span>sudo ufw </span><span>disable</span><span> 
</span>
<span></span><span>#finaly to enable logging and adjusting the log level: </span><span>
</span>sudo ufw logging on
<span>sudo ufw logging medium </span><span># levels are low, medium, high, full </span><span>
</span></code></pre>
              <p><br>On to Fail2Ban now. <br></p>
              <h3 id="ban"><strong><br>Fail2Ban</strong></h3>
              <p>‍<br>The main configuration is located in /etc/fail2ban/jail.conf, but
                it's recommended to create a local configuration file:<br>‍<br></p>
              <pre contenteditable="false"><code><span>sudo cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local
</span>
sudo nano /etc/fail2ban/jail.local</code></pre>
              <p>‍<br>There are some basic settings in the [DEFAULT] section of the
                jail.local section those are:<br>‍<br></p>
              <pre contenteditable="false"><code><span>bantime = 10m
</span>findtime = 10m
maxretry = 5</code></pre>
              <p>‍<br>Ban time is how long an IP is banned. Find time is the time frame in
                witch Fail2Ban looks for repeated failure, and max retry is the number of failures before an IP is
                banned. You can tune these as you see fit. There are also custom jails you can set, Fail2Ban also
                supports jails for commonly used services like SSH. There are even more steps you can take, but I think
                this covers the basics.<br></p>
              <h3 id="nginx"><strong><p>NGINX</p></strong></h3>
              <div><p>There are a small mess of web servers out there that you can use.
                Apache, Caddy, nginx, IIS to name a few. I use Nginx. It's what I know, and it works really damn
                well. Nginx (pronounced engine-x) is a web server, reverse proxy, and load balancer. As a web server, it
                excels at serving static content and can handle loads of concurrent connections with fairly low resource
                usage. As a reverse proxy, it can sit in front of your application servers and forward traffic to them
                while enchaining the apps' security. Its load balancing aspects can effectively balance traffic
                between servers, improving reliability and scalability. </p><p>When installed via apt, the default
                location for nginx is /etc/nginx/ the nginx.conf is mostly used for global server configuration and
                includes filed from the /etc/nginx/sites-enabled folder. This modular structure allows for easy
                management of multiple sites. Two folders to be aware of are the sites-enabled folder and the
                sites-available folders. You can think of the sites available as a staging place to test your site
                configurations, while the sites enabled is for live sites and apps. A common practice is to set up and
                test your configuration in the sites in the sites available, then when you're ready to go live and
                get an SSL cert, you link the file to the sites-enabled folder. You do that with:<br>‍</p></div>
              <pre contenteditable="false"><code><span>ln -s /etc/nginx/sites-available/yoursitefile /etc/nginx/sites-enabled</span></code></pre>
              <p><br>Then reload nginx and double check nginx status with:<br>‍<br></p>
              <pre contenteditable="false"><code><span>sudo systemctl reload nginx
</span>
sudo systemctl status nginx</code></pre>
              <div><p>Your site should be live now.</p><p>Below, I’ll show you some
                boilerplate Nginx site configurations. Be sure to look into your app or sites needs as these are just
                starting points.&nbsp;For static sites, this is a decent starting point.&nbsp;</p></div>
              <p><br>Basic Static Website Configuration:<br></p>
              <pre contenteditable="false"><code><span>server {
</span>    listen 80;
    listen [::]:80;
    server_name example.com www.example.com;
    root /var/www/example.com/html;
    index index.html index.htm;
    location / {
<span>        try_files </span><span>$uri</span><span> </span><span>$uri</span><span>/ =404;
</span>    }
<span>    </span><span># Security headers</span><span>
</span><span>    add_header X-Frame-Options </span><span>"SAMEORIGIN"</span><span> always;
</span><span>    add_header X-XSS-Protection </span><span>"1; mode=block"</span><span> always;
</span><span>    add_header X-Content-Type-Options </span><span>"nosniff"</span><span> always;
</span><span>    add_header Referrer-Policy </span><span>"no-referrer-when-downgrade"</span><span> always;
</span><span>    add_header Content-Security-Policy </span><span>"default-src 'self' http: https: data: blob: 'unsafe-inline'"</span><span> always;
</span>
<span>    </span><span># Logging</span><span>
</span><span>    access_log /var/</span><span>log</span><span>/nginx/example.com.access.log;
</span><span>    error_log /var/</span><span>log</span><span>/nginx/example.com.error.log warn;
</span>
<span>    </span><span># SSL configuration (uncomment after running Certbot)</span><span>
</span><span>    </span><span># listen 443 ssl http2;</span><span>
</span><span>    </span><span># listen [::]:443 ssl http2;</span><span>
</span><span>    </span><span># ssl_protocols TLSv1.2 TLSv1.3;</span><span>
</span><span>    </span><span># ssl_prefer_server_ciphers on;</span><span>
</span><span>    </span><span># ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;</span><span>
</span>
<span>    </span><span># Certbot will add its own SSL certificate paths</span><span>
</span><span>    </span><span># ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;</span><span>
</span><span>    </span><span># ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;</span><span>
</span>}</code></pre>
              <p><br>Proxy Pass Configuration:<br></p>
              <pre contenteditable="false"><code><span>server {
</span>    listen 80;
    listen [::]:80;
    server_name app.example.com;
    location / {
        proxy_pass http://localhost:3000;
<span>        proxy_set_header Host </span><span>$host</span><span>;
</span><span>        proxy_set_header X-Real-IP </span><span>$remote_addr</span><span>;
</span><span>        proxy_set_header X-Forwarded-For </span><span>$proxy_add_x_forwarded_for</span><span>;
</span><span>        proxy_set_header X-Forwarded-Proto </span><span>$scheme</span><span>;
</span>    }
<span>    </span><span># Security headers</span><span>
</span><span>    add_header X-Frame-Options </span><span>"SAMEORIGIN"</span><span> always;
</span><span>    add_header X-XSS-Protection </span><span>"1; mode=block"</span><span> always;
</span><span>    add_header X-Content-Type-Options </span><span>"nosniff"</span><span> always;
</span><span>    add_header Referrer-Policy </span><span>"no-referrer-when-downgrade"</span><span> always;
</span><span>    add_header Content-Security-Policy </span><span>"default-src 'self' http: https: data: blob: 'unsafe-inline'"</span><span> always;
</span>
<span>    </span><span># Logging</span><span>
</span><span>    access_log /var/</span><span>log</span><span>/nginx/app.example.com.access.log;
</span><span>    error_log /var/</span><span>log</span><span>/nginx/app.example.com.error.log warn;
</span>
<span>    </span><span># SSL configuration (uncomment after running Certbot)</span><span>
</span><span>    </span><span># listen 443 ssl http2;</span><span>
</span><span>    </span><span># listen [::]:443 ssl http2;</span><span>
</span><span>    </span><span># ssl_protocols TLSv1.2 TLSv1.3;</span><span>
</span><span>    </span><span># ssl_prefer_server_ciphers on;</span><span>
</span><span>    </span><span># ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;</span><span>
</span>
<span>    </span><span># Certbot will add its own SSL certificate paths</span><span>
</span><span>    </span><span># ssl_certificate /etc/letsencrypt/live/app.example.com/fullchain.pem;</span><span>
</span><span>    </span><span># ssl_certificate_key /etc/letsencrypt/live/app.example.com/privkey.pem;</span><span>
</span>}</code></pre>
              <p><br>WebSocket Upgrade Configuration:<br></p>
              <pre contenteditable="false"><code><span>server {
</span>    listen 80;
    listen [::]:80;
    server_name ws.example.com;
    location / {
        proxy_pass http://localhost:8080;
        proxy_http_version 1.1;
<span>        proxy_set_header Upgrade </span><span>$http_upgrade</span><span>;
</span><span>        proxy_set_header Connection </span><span>"upgrade"</span><span>;
</span><span>        proxy_set_header Host </span><span>$host</span><span>;
</span><span>        proxy_set_header X-Real-IP </span><span>$remote_addr</span><span>;
</span><span>        proxy_set_header X-Forwarded-For </span><span>$proxy_add_x_forwarded_for</span><span>;
</span><span>        proxy_set_header X-Forwarded-Proto </span><span>$scheme</span><span>;
</span>    }
<span>    </span><span># Security headers</span><span>
</span><span>    add_header X-Frame-Options </span><span>"SAMEORIGIN"</span><span> always;
</span><span>    add_header X-XSS-Protection </span><span>"1; mode=block"</span><span> always;
</span><span>    add_header X-Content-Type-Options </span><span>"nosniff"</span><span> always;
</span><span>    add_header Referrer-Policy </span><span>"no-referrer-when-downgrade"</span><span> always;
</span><span>    add_header Content-Security-Policy </span><span>"default-src 'self' http: https: data: blob: 'unsafe-inline'"</span><span> always;
</span>
<span>    </span><span># WebSocket timeout settings</span><span>
</span>    proxy_read_timeout 300s;
    proxy_send_timeout 300s;
<span>    </span><span># Logging</span><span>
</span><span>    access_log /var/</span><span>log</span><span>/nginx/ws.example.com.access.log;
</span><span>    error_log /var/</span><span>log</span><span>/nginx/ws.example.com.error.log warn;
</span>
<span>    </span><span># SSL configuration (uncomment after running Certbot)</span><span>
</span><span>    </span><span># listen 443 ssl http2;</span><span>
</span><span>    </span><span># listen [::]:443 ssl http2;</span><span>
</span><span>    </span><span># ssl_protocols TLSv1.2 TLSv1.3;</span><span>
</span><span>    </span><span># ssl_prefer_server_ciphers on;</span><span>
</span><span>    </span><span># ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;</span><span>
</span>
<span>    </span><span># Certbot will add its own SSL certificate paths</span><span>
</span><span>    </span><span># ssl_certificate /etc/letsencrypt/live/ws.example.com/fullchain.pem;</span><span>
</span><span>    </span><span># ssl_certificate_key /etc/letsencrypt/live/ws.example.com/privkey.pem;</span><span>
</span>}</code></pre>
              <div><p>The basic configuration is for serving a simple static site. It
                specifies the domain name, listens on port 80 for both IPv4 and IPv6, sets the root directory for the
                site, configures error handling with try_files, adds some basic headers that protect from common web
                vulnerabilities, sets up logging for access and errors and includes a section for SSL that is commented
                out. Most of the SSL config will be handled by certbot, but there are a few lines in there that add some
                SSL security that can be uncommented after certbot is ran.<br>‍<br>The proxy pass configuration is
                similar to the basic configuration, but instead of serving files directly, it proxies requests to a
                local application (in this case, running on port 3000).</p><p>The third configuration file is geared
                towards apps that need website connections, it's a lot like the proxy pass configuration with some
                changes to allow web sockets. &nbsp;</p><p>Ok, any bit about web servers is not really complete without
                talking about SSL. For casual use, certbot is a pleb's best friend. It's free, it is fast, and
                it fucking works. I use the python version of certbot. You can install that with: &nbsp;<br>‍</p></div>
              <pre contenteditable="false"><code><span>sudo apt install certbot python3-certbot-nginx</span></code></pre>
              <p><br>Once it's installed you can simply run “certbot” in your
                terminal, this will detect the configs in your sites-enabled folder and ask what you want to do (renew,
                reissue, etc…). Follow the walk-through, certbot gives you It's pretty straight forward.<br>‍<br>So
                nowadays certbot when getting a new cert will set up auto-renew for you, so it's a sit-and-forget
                kinda task. But to make sure it worked you can run:<br></p>
              <pre contenteditable="false"><code><span>sudo systemctl status certbot.timer</span></code></pre>
              <p><br>if this is up and running, you should be good to go if you're
                using systemd.<br>‍<br></p>
              <h2 id="qol"><strong><p>Quality Of Life Tools</p></strong></h2>
              <div><p>On the topic of tools that make managing your system easier, I'm
                going to present some tools I use on my servers that I think make management just a bit nicer. Not going
                to do a deep dive on any tool. All of these are optional and in no particular order. A lot of these I
                found on the site <a href="https://terminaltrove.com/" target="_blank">terminal trove</a>, a great site
                to browse if you're a terminal junkie like me.&nbsp;</p><p>First tool, <a href="https://terminaltrove.com/btop/" target="_blank">Btop</a> this is in my personal must haves
                list. Btop is a terminal monitor of resources. It shows you real time visuals of usage stats for your
                box’s CPU, RAM, disks, network and running possesses it's written in C++ and can be installed via
                most package managers.&nbsp;</p><p>For servers that have a lot of outside connections, i.e. a nostr relay, a
                tool like <a href="https://terminaltrove.com/neoss/" target="_blank">Neoss</a> is helpful. Neoss aims to
                replace usual ss command for basic usage. It provides a list of in use TCP and UDP sockets with their
                respective stats. Its main advantage over SS raw output is its clear and simple TUI (terminal user
                interface) that allows you to sort, refresh and navigate what is connected to your machine. It's
                installed Via NPM, meaning you need JavaScript installed.</p><p>
                <a href="https://github.com/allinurl/goaccess" target="_blank">GoAccess</a> is a terminal based log
                analyzer for web servers. It's great for a quick real time look at logs while in the terminal, but
                it can also generate real time HTML, JSON, and CSV reports. GoAccess can be installed via most package
                managers, works on all platforms.&nbsp;</p><p>Next on the list is <a href="https://terminaltrove.com/mc/" target="_blank">MC or “midnight commander”</a> Its a powerful text based file manager with a two panel
                display and lots of features for manipulating files and directories. It's also cross-platform and
                can be installed via most package managers.&nbsp;</p><p>In the same thread of server file management is <a href="https://dev.yorhel.nl/ncdu" target="_blank">NCDU</a>. This one is in my must-have list. It is a
                disk usage analyzer that is designed to find space hogs. It's fast and very simple to use. It can
                be installed on most systems and package managers. Windows will need Linux subsystems installed to use
                it.&nbsp;</p><p>Hopefully you find some use out of these. The last topic I'd like to touch on is DNS
                it's a bit topic, so I'm not going to do a massive deep dive, but if you're self-hosting
                it helps to have some of the basics of DNS down.&nbsp;ing doesn’t work.</p></div>
              <h2 id="dns"><strong><p>DNS</p></strong></h2>
              <div><p>DNS or The Domain Name System is a core part of how the internet as we
                know it works. Love it or hate it, it's what we have to work with If you want to be accessible to
                the wider internet. (I dislike what it currently is it, but I’m not opening that can of worms here.)
                Basically, Think of DNS like a phone book. It’s what allows you to type duckduckgo.com instead of
                “52.250.42.157” every time you need to search the internet. It translates something easy for humans to
                remember into the information needed by computers to actually reach “duckduckgo.com”</p><p>If
                you're hosting on a VPS, the only thing you really need to know is to know how to point an A record
                at your server's IP after you decide on a domain to use. Pretty much all VPS hosts can give you a
                static IP, so that's mostly a set and forget type deal. </p><p>Hosting from home presents some
                challenges. One prominent one is (and a valid question that I often hear) not having a static IP
                address. Nowadays with the number of devices online needing IP addresses we do a lot of juggling, and
                most IP addresses are assigned dynamically unless you pay for it from your ISP.&nbsp; But there is a
                solution. The answer to this is called Dynamic DNS or DDNS. This allows automatic updating of DNS
                servers every time an IP address changes. There are a mess of ways to set up dynamic DNS. You can host
                your own service or use a host. <a href="https://dynamic.domains/dynamic-dns/providers-list/default.aspx" target="_blank">Here is a
                  link</a> with some hosts and projects to check out.</p><p>In a nutshell, it works like so. You chose
                a provider or set up your own. You get a domain, install the client on your home router or server and
                the client periodically checks to see if the IP address has changed, if so it updates your DNS record
                for that domain.&nbsp;</p></div>
              <h2 id="docker"><strong><p>Docker</p></strong></h2>
              <p>I'm not gonna cover how to install docker here. It's best to
                follow <a href="https://docs.docker.com/engine/install/debian/" target="_blank">the official
                  installation</a> guide anyway. But I want to touch on a few things. First off, docker is useful as
                hell for testing new apps. But that's about as far as I take it. I personally do not like using
                docker all that much, and where possible run applications directly. Here are some pros and cons to keep
                in mind.<br></p>
              <h3><strong>Docker Pros</strong></h3>
              <p>Consistency is a big one it can make things more constant between
                development, testing, and deploying if your system can run docker you can run most docker apps. It can
                help with isolation, reducing conflicts between apps. In some cases it can help with efficiency as it
                takes less resources than traditional VM’s. It can help with scaling as it's pretty easy to spin up
                more containers and the microservice architecture can be useful because you can break down an
                application into smaller manageable services, allowing for independent scaling of said services. Lastly
                the community is large, so the documentation is good, and community support is always helpful, plus
                there is a wide range of ready to go docker images for deployment.<br></p>
              <h3><strong>Docker Cons</strong></h3>
              <div><p>I’ll start with overhead. While it's better than a traditional VM,
                it uses more resources than running something directly on the host, and I/O operations can be slower.
                The fact that docker shares the system's kernel means that a compromised app could affect the
                system. Persistent data is doable but adds a layer of complexity that can cause data loss with new
                users, it also makes backups more complex. Networking can also be more complex with docker, making it
                not as straightforward. It's also good to note that if you use UFW or firewalld for a firewall,
                docker bypasses those rules. Docker is only compatible with iptables. Also, while a well managed docker
                container can help manage server resources, an improperly manged on can be detrimental to resources as
                well. Containers can get too large, effecting disk size, and misconfiguration can use too many of your
                servers resources. It also adds extra layers of complexity when monitoring and debugging applications,
                especially across multiple containers.</p><p>At the end of the day, it's your system. But I wanted
                to lay out some pros and cons when it comes to using Docker. Moving on.&nbsp; </p></div>
              <h2><strong><p>Wrap Up</p></strong></h2>
              <p>Well, that about does it for the basics of server setup and tools. There
                is a <a href="https://git.sovbit.dev/Enki/sovran-scripts" target="_blank"> a script that I wrote</a> that will do most of this for you. I wrote it to make my own server setup faster.
                You can get that here, it includes all of my must-haves and does some basic configuration. Tweak it to
                your own needs, and as always stay safe out there and ping me on nostr or simplex if you have questions
                or if I fucked something up in this post.<br></p>
              
              
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Senior Intel CPU architects splinter to develop RISC-V processors (148 pts)]]></title>
            <link>https://www.tomshardware.com/tech-industry/senior-intel-cpu-architects-splinter-to-develop-risc-v-processors-veterans-establish-aheadcomputing</link>
            <guid>41353155</guid>
            <pubDate>Mon, 26 Aug 2024 01:28:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/tech-industry/senior-intel-cpu-architects-splinter-to-develop-risc-v-processors-veterans-establish-aheadcomputing">https://www.tomshardware.com/tech-industry/senior-intel-cpu-architects-splinter-to-develop-risc-v-processors-veterans-establish-aheadcomputing</a>, See on <a href="https://news.ycombinator.com/item?id=41353155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-320-80.jpg" alt="AheadComputing" srcset="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU-888-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/BJ9BSA4XH4du2c87GHUmnU.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: AheadComputing)</span>
</figcaption>
</div>

<div id="article-body">
<p>While Intel is busy laying off thousands of employees some of its most experienced CPU architects, with a combined 80+ years at the firm, have left to form a RISC-V startup. <a data-analytics-id="inline-link" href="https://www.aheadcomputing.com/" data-url="https://www.aheadcomputing.com/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">AheadComputing</a> was co-founded by Debbie Marr, Mark Dechene, Jonathan Pearce, and Srikanth Srinivasan, with the goal of “creating compelling open specification core IP.” This proactive move by the quartet of architects and engineers must be congratulated, as they founded AheadComputing and went public on July 18 – just a couple of weeks before Intel’s harsh <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/intel-to-layoff-more-than-15-of-workforce-almost-20000-employees-encountered-meteor-lake-yield-issues-suspends-dividend" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/intel-to-layoff-more-than-15-of-workforce-almost-20000-employees-encountered-meteor-lake-yield-issues-suspends-dividend">workforce reduction plans</a> were announced.</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-320-80.jpg" alt="AheadComputing" srcset="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/nE5ihyUduHzys7gmQBk2gU.jpg"></picture></p></div><figcaption itemprop="caption description"><span>Everyone deserves a better website </span><span itemprop="copyrightHolder">(Image credit: AheadComputing)</span></figcaption></figure><p>AheadComputing’s website is rather basic and threadbare at the time of writing, but it does contain a mission statement of sorts, some short bios detailing the ex-Intel co-founders, a single blog post (launch announcement), and a call for new recruits with experience in CPU design and verification roles.</p><p>As indicated above, the work of AheadComputing is going to begin with work on the RISC-V architecture. Specifically, the fledgling firm has set out with a plan “dedicated to designing, verifying, and licensing compelling RISC-V core IP.” For any deeper dive into the goings-on behind the doors of the new Oregon-based firm, you will have to chat with them directly or wait for further blogging. However, they will also meet with people during Happy Hour on Tuesdays, between 4 - 5:30 pm, at Cornelius Pass Roadhouse, Hillsboro…</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1200-80.jpg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-320-80.jpg" alt="AheadComputing" srcset="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU-1200-80.jpg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/rASTcahKUtLatdZcwjUWuU.jpg"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: AheadComputing)</span></figcaption></figure><p>The most compelling feature of AheadComputing is, for now, its co-founders, so let’s take a closer look at their resumes.</p><p>Co-founder, CEO, &amp; President, Dr. Debbie Marr was an Intel Fellow and Chief Architect of the Advanced Architecture Development Group (AADG) at Intel and spent 33 years at the chipmaker on products spanning the i386 all up to the present day. A highlight of her career seems to have been bringing Intel Hyperthreading Technology from concept to finished product. Marr also authored over 40 patents in CPU, AI accelerators, and FPGA fields.</p><p>Co-Founder, Mark Dechene was an Intel Principal Engineer and CPU Architect in the Advanced Architecture Development Group. During his 16 years at Intel Dechene worked on architecture development for Intel CPU products including Haswell, Broadwell, Goldmont, Goldmont Plus, Tremont, and Skymont. Dechene has authored over 15 patents, focused on microprocessor performance.</p><p>Co-Founder, Jonathan Pearce was an Intel Principal Engineer, CPU Architect, and a key technologist &amp; strategist in the Advanced Architecture Development Group until recently. Pearce worked for 22 years at Intel. During his career, Pearce has worked in both pre-silicon and post-silicon roles on multiple generations of Intel Core SOCs. He also authored 19 patents in the CPU, AI, and GPU fields.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-k6SrjEwfa6jCtt4TU4Epnh"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div><p>Co-Founder, Dr. Srikanth Srinivasan has over 20 years of technical leadership experience in product R&amp;D. At Intel he taped out some well-known chip designs like Nehalem, Haswell, and Broadwell. However, most recently, Srinivasan led the frontend and backend CPU teams at the Advanced Architecture Development Group at Intel. The highlight of his career / achievements so far is probably the authoring of more than a dozen highly cited papers and over 50 patents.</p><p>With its pedigree, surely we will hear about AheadComputing again, in the not-too-distant future. On the flip side, PC enthusiasts may rightly worry about the future of Intel when it has just instigated the most severe layoff plans in its 56-year history, some of its ambitious construction plans have come into question, and severe brain drain, as evidenced by this new RISC-V startup, could slow any chances of revival.</p>
</div>
<div id="slice-container-authorBio-k6SrjEwfa6jCtt4TU4Epnh"><p>Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.</p></div>



<!-- Drop in a standard article here maybe? -->



</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We found North Korean engineers in our application pile (152 pts)]]></title>
            <link>https://www.cinder.co/blog-posts/north-korean-engineers-in-our-application-pile</link>
            <guid>41353079</guid>
            <pubDate>Mon, 26 Aug 2024 01:18:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cinder.co/blog-posts/north-korean-engineers-in-our-application-pile">https://www.cinder.co/blog-posts/north-korean-engineers-in-our-application-pile</a>, See on <a href="https://news.ycombinator.com/item?id=41353079">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Cinder is part of a growing list of US-based tech companies that encounter engineering applicants who are actually suspected North Korean nationals. These North Koreans almost certainly work on behalf of the North Korean government to <a href="https://apnews.com/article/north-korea-weapons-program-it-workers-f3df7c120522b0581db5c0b9682ebc9b">funnel money back</a> to their government while working remotely via third countries like China. Since at least early 2023, many have applied to US-based remote-first tech companies like Cinder. If you’ve been running into this issue, here are some tips for how you can handle this at your own company.</p><p>It’s important to note that funding the North Korean government could constitute a crime given <a href="https://ofac.treasury.gov/sanctions-programs-and-country-information/north-korea-sanctions">the sanctions</a> the regime is under. And nobody wants that kind of paperwork headache!</p><p>Cinder is unique in our ability to interface with this issue given our co-founders’ backgrounds as ex-CIA operatives, as well as an expert on North Korea. Our prior experience spurred our interest in building internet safety software to begin with, and inspires a particular vigilance to maintain it to the best of our abilities.</p><p>I first learned of North Korea’s practice of sending workers abroad in 2014: I joined the board of a leadership development program for North Korean escapees and learned of North Korea’s government and its use of technology from those who experienced it firsthand. Later, I volunteered for a nonprofit developing information access technology for clandestine use inside closed countries like North Korea. I have spoken with North Korean escapees who have recent knowledge of the latest North Korean tech worker trends. But I never expected I would one day experience them as applicants attempting to join my company.&nbsp;</p><h2>North Koreans are applying to US tech companies?</h2><p>The North Korean government has a <a href="https://www.bloomberg.com/news/features/2018-02-07/inside-kim-jong-un-s-hacker-army">long history</a> of sending workers abroad to earn money for the regime. The workers are sent to countries like China where they must earn a salary quota, most of which will be taken by the government for its own needs. These workers are under close supervision by North Korean officials while abroad. They are often required to leave family members behind as collateral to prevent them from defecting while outside their home country.&nbsp;</p><p>North Koreans have been working undercover as software freelancers for part time contract jobs for years. And recently, they have <a href="https://blog.knowbe4.com/how-a-north-korean-fake-it-worker-tried-to-infiltrate-us">started</a> to apply to American tech companies that offer remote, full time work. This may be exacerbated by the rise of remote work after the COVID pandemic and the fact that working at US tech companies can be so lucrative. Hyun-Seung Lee, a former North Korean businessman and former chair of the Kim Il Sung Socialist Youth League branch in Dalian, China, told us that the earnings quota for a North Korean IT worker based in China is typically $6,000 per month. This quota is more than covered by many US tech salaries.</p><h2>The application process</h2><p>In our experience, North Koreans applying to US tech companies under false pretenses will often use a standard process: they will create profiles on multiple professional networking and job posting sites using a name that is not Korean and sometimes with an AI-edited profile image.&nbsp;</p><p>Once they go through the interview process and have received a job offer, they may ask their new company-provided laptop be <a href="https://www.bleepingcomputer.com/news/security/us-dismantles-laptop-farm-used-by-undercover-north-korean-it-workers/">sent to a US-based partner</a>. According to a Department of Justice <a href="https://www.justice.gov/usao-dc/media/1352191/dl">indictment</a>, the US-based partner may install remote desktop software so that the North Korean engineer can appear to be working from a US location, with a laptop physically located in the US, while remotely controlling the laptop from abroad.</p><p>By demonstrating sufficient technical capability and minimal English language skills, North Korean applicants can meet minimum thresholds for junior software engineer roles. Fast-growing start-ups eager to ship more products might overlook gaps in resume, unreliable or missing education records, or poor command of written or spoken English for an engineer with sufficient skill who is ready to start working soon.&nbsp;</p><p>We suspect if the worker is employed even for just a few months before being terminated, this can still be quite profitable for the regime.</p><h2>Cinder’s approach</h2><p>We have a unique perspective on this problem for a few reasons: our company is in the internet safety industry, two of our co-founders came from the CIA, and I have twelve years of experience working on cybersecurity and human rights issues related to North Korea. So when North Korean IT workers applied to Cinder, they had a different experience than they might have expected.</p><blockquote><em>Pyongyang has a long history of exploiting its people to further the regime’s ambitions and this activity is no exception. Two of Cinder’s founders bring years of CIA experience, so we’re no strangers to creating and running virtual operations, nor detecting and countering those of hostile nation states.<br>‍<br>- Phil Brennan, Cinder co-founder and 10-year CIA veteran</em></blockquote><h3>What tipped us off</h3><p>Fifteen months prior to any <a href="https://www.bleepingcomputer.com/news/security/five-arizona-ukraine-charged-for-cyber-schemes-infiltrating-over-300-companies-to-benefit-north-koreas-weapons-program/">FBI indictments</a>, our COO first noticed a few unusual trends in our applicant pool. Upon further inspection he discovered these candidates either didn't seem to exist on the internet, or were mapped to people who weren't them, who did have an internet presence. Over time, we realized many applicants that had the following characteristics:</p><ol role="list"><li>No online presence outside of professional networking websites; and professional networking profiles were recently created, typically with profile pictures that obscured the individual’s image (in ski goggles, sunglasses), were too zoomed out to be helpful, were AI-generated, or were simply blank.&nbsp;</li><li>Completely fabricated job history including office locations that don’t actually exist.&nbsp;</li><li>Unable to find these applicants online outside of the standard professional networking sites (e.g. no presence on GitHub, social media etc).</li><li>Inability to answer basic questions about the cities in which they allegedly worked (‘What was your Metro stop in Paris?’) or technology on which they worked (‘What org were you in at Uber?’).</li><li>Background noise during their interview that indicated other people speaking in an interview-like setting, implying a crowded room of people on separate professional video calls.</li><li>Highly scripted answers with explicit preference for remote work, and little ability to deviate from the script.</li><li>A mismatch between the name displayed on the resume or networking site, and the candidate’s command of English (e.g. Chris Smith with a B.A. from a large US research university who can barely speak interview-level English is surprising).&nbsp;</li></ol><p>We also noticed vague cover letter language:</p><blockquote><em>Hi, team!<br>I hope you're fine and safe.&nbsp;<br>I am really excited about this potential opportunity with the ambitious project.<br>As a Senior Frontend Developer with 8+ years of experience, I have great experience in working with React.js/Redux, RTK, React Query, Vue, Next.js, Vercel, TypeScript, GraphQL, etc.</em> <em>Please have a look at my previous works.</em></blockquote><p>Another example: </p><blockquote><em>Hi,</em> <br>‍<em>I love what you are doing in your company. With my eight-plus years of development, I'd love to be one of you.</em> <em>As an FE-heavy developer, I have a track record of building successful products. And I am familiar with startup environment.</em> <em>I'd love to use my strong debugging and problem-solving abilities to be a powerful force in the workplace. I can wear multiple hats and adapt to a fast-paced team.</em> <em>I look forward to meeting you to learn more about this role and share my relevant skills.</em> <em>Best,</em></blockquote><p>Taken together, to me these details suggested fake identities. And while I knew North Korea had a history of sending workers abroad to freelance, I didn’t expect that they would apply to full time roles at US-based companies.</p><h3>What we did</h3><p>First, because we come from the Trust and Safety industry, I was able to reach out to our partners at various security companies and confirm these patterns were consistent with North Koreans attempting to pass themselves off as Americans. I also learned a lot from published investigations like the one <a href="https://www.nisos.com/research/dprk-it-worker-scam/">Nisos published last year</a>.</p><p>With more knowledge, we were able to go digging. And we had a lot of material: For applicants from some job sites, roughly 80% of inbound applicants with experience matching our stack were suspected North Koreans.&nbsp;</p><p>We started filtering out suspected North Korean applicants by doing quick internet searches and closer examinations of job history, profile imagery, and a social media screening. However, our process wasn’t perfect, and we still ended up on occasional Zoom calls screening applicants who we would quickly discover, mid-call, had fabricated their career history and only recently created their online presence.</p><p>When we first started receiving North Korean applications, some of our interviewers noted applicants’ strong resistance to travel in their post-interview write ups:</p><blockquote><em>One clarifying question that I neglected to ask about is that on his Linkedin profile he says he is&nbsp; looking for “100% Remote job only without travel”. I did not notice the “without travel” part until after the interview. We should make sure he would be willing to travel sometimes for team offsites as this is an important part of Cinder’s culture.</em></blockquote><p>I started informing candidates that Cinder’s customer base includes companies investigating nation-state espionage and insider threat issues. I added that this is a natural fit for us, because our co-founders came from the US intelligence community including the CIA.&nbsp;</p><p>Upon hearing this, one suspected North Korean applicant immediately dropped from the Zoom call and never contacted us again.</p><h2>What Cinder is doing now</h2><p>We continue to receive dozens of suspected North Korean applicants to Cinder. We take steps to share relevant information with security teams at networking and job listing sites that we work with. If your company is also affected by this growing threat, I encourage you to get in touch with me at <a href="mailto:declan@cndr.io">declan@cndr.io</a> and I’d be happy to share more tips and prevention strategies.&nbsp;</p><p>‍</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uber loses New Zealand appeal, court rules drivers are employees not contractors (111 pts)]]></title>
            <link>https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/</link>
            <guid>41352997</guid>
            <pubDate>Mon, 26 Aug 2024 01:05:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/">https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/</a>, See on <a href="https://news.ycombinator.com/item?id=41352997">Hacker News</a></p>
Couldn't get https://www.nzherald.co.nz/business/uber-loses-landmark-appeal-court-rules-drivers-are-employees-not-contractors/JDXF52QBBBHPJIQJNFNGYC4JOE/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Australian employees now have the right to ignore work emails, calls after hours (445 pts)]]></title>
            <link>https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/</link>
            <guid>41352681</guid>
            <pubDate>Mon, 26 Aug 2024 00:08:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/">https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/</a>, See on <a href="https://news.ycombinator.com/item?id=41352681">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/asia-pacific/australian-employees-now-have-right-ignore-work-emails-calls-after-hours-2024-08-25/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Police Chief Says Cops Have a 5th Amendment Right to Leave Body Cameras Off (209 pts)]]></title>
            <link>https://reason.com/2024/08/23/albuquerques-police-chief-thinks-cops-have-a-5th-amendment-right-to-leave-their-body-cameras-off/</link>
            <guid>41351993</guid>
            <pubDate>Sun, 25 Aug 2024 22:18:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reason.com/2024/08/23/albuquerques-police-chief-thinks-cops-have-a-5th-amendment-right-to-leave-their-body-cameras-off/">https://reason.com/2024/08/23/albuquerques-police-chief-thinks-cops-have-a-5th-amendment-right-to-leave-their-body-cameras-off/</a>, See on <a href="https://news.ycombinator.com/item?id=41351993">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							<p>Albuquerque, New Mexico, Police Chief Harold Medina operated his department-issued pickup truck "in an unsafe manner" on February 17, when he ran a red light and broadsided a car, severely injuring the driver. So concludes a recent <a href="https://s3.documentcloud.org/documents/25056680/i-171-24-medina-martinez-final_redacted.pdf">report</a> from internal investigators who looked into that shocking incident.</p> <p>Duh, you might say if you have seen <a href="https://www.youtube.com/watch?v=DvSVzDimSAk">surveillance camera footage</a> of the crash, which shows Medina crossing Central Avenue, a busy, four-lane street, against the light. He crosses the westbound lanes through a gap between two cars, forcing one of the drivers to brake abruptly, before barreling across the eastbound lanes, where he rams into the side of a gold 1966 Mustang driven by 55-year-old Todd Perchert.</p> <p>Although Medina's recklessness seems obvious, the Albuquerque Police Department's Fleet Crash Review Board (CRB) earlier this year <a href="https://reason.com/2024/04/04/albuquerques-police-chief-ran-a-red-light-and-broadsided-a-car-a-review-board-says-it-was-unavoidable/">concluded</a> that the crash was "non-preventable." How so? Medina, who was on his way to a Saturday press conference with his wife when he took a detour to have a look at a homeless encampment, said he ran the light to escape an altercation between two homeless men that had escalated into gunfire at the intersection of Central and Alvarado Drive.</p> <p>While "the initial decision to enter the intersection is not in question," Lt. James Ortiz says in the Internal Affairs report, "the facts and circumstances do not relieve department personnel of driving safely to ensure no additional harm is done to personnel or to citizens." Medina, Ortiz says, clearly failed to do that: "By definition, driving into a crosswalk, darting between two vehicles driving on a busy street, and crossing through an intersection with vehicles traveling eastbound were unsafe driving practices." In this case, he notes, those unsafe practices "resulted in a vehicle collision with serious physical injuries to the victim, including a broken collarbone and shoulder blade, 8 broken ribs (reconstructed with titanium plates after surgery), collapsed lung, lacerations to left ear and head, multiple gashes to his face, a seven-hour surgery, and hospitalization requiring epidural painkiller and a chest tube for nearly a week."</p> <p>Ortiz not only disagrees with the CRB's conclusion about Medina's crash; he says the board never should have reviewed the incident to begin with, since its mission is limited to accidents "not resulting in a fatality or serious injury." Ortiz says Commander Benito Martinez, who chairs the CRB, violated department policy when he decided the board should pass judgment on Medina's accident.</p> <p>Martinez acknowledged that department policy "prohibited the CRB from hearing serious injury crashes" and that "allowing such a case to be heard would be a policy violation." Why did he allow it anyway? "He explained that his reasoning for permitting the Chief's crash to be reviewed by the CRB was based on his belief that someone wanted the crash to be heard," Ortiz writes. "Cmdr. Martinez clarified that he believed someone from Internal Affairs wanted the case to be heard by the CRB to ensure full transparency. However, he did not consult with anyone in Internal Affairs to verify the accuracy of this assumption."</p> <p>Both the CRB's decision to review the crash and its implicit exoneration of Medina are hard to fathom. But Medina's explanations for the third policy violation identified by Ortiz—the chief's failure to activate his body camera after the crash—are even weirder.</p> <p>"After the collision occurred, the shooting victim approached," Ortiz writes. "The victim informed the Chief that he was okay and had not been shot. Chief Medina asked the victim to remain at the scene, but the victim refused and fled southbound on Alvarado. Another citizen approached the Chief and reported having seen individuals leaving a black truck and fleeing away from the scene. Chief clarified with the witness that no one was outstanding. It is important to note that these interactions were not recorded and are contacts that require mandatory recording."</p> <p>Medina offered two puzzling excuses for leaving his camera off. He&nbsp;"cited intermittent conversations with his wife, who was a passenger in his unmarked patrol vehicle at the time of the collision," Ortiz says. "He claimed there was a right to privileged communication between spouses, which specifically exempted him from mandatory recording requirements." But the relevant policy "does not provide for nonrecording based on spousal privilege."</p> <p>Even more troubling, Medina said he "purposefully did not record because he was invoking his 5th Amendment right not to self-incriminate." Since "he was involved in a traffic collision," he reasoned, he was "subject to 5th Amendment protections."</p> <p>Think about the implications of that argument. Body cameras are supposed to help document (and perhaps deter) police misconduct. But Medina is suggesting that cops have a constitutional right to refrain from recording their interactions with the public whenever that evidence could be used against them. By turning on their cameras in those situations, he argues, police could be incriminating themselves. That is the whole point.</p> <p>Medina received two official <a href="https://www.abqjournal.com/news/albuquerque-police-chief-reprimanded-for-crash-that-injured-man/article_48c6c9de-455d-11ef-a7de-77dd5b86acc9.html">reprimands</a> for the camera violation and the reckless driving that injured Perchert, a casualty of the police chief's desperation to save his own skin. In similar situations, other Albuquerque police officers have been <a href="https://reason.com/2024/04/04/albuquerques-police-chief-ran-a-red-light-and-broadsided-a-car-a-review-board-says-it-was-unavoidable/">fired</a>. But after the crash, Albuquerque Mayor Tim Keller <a href="https://www.koat.com/article/victim-crash-involving-albuquerque-police-chief-medina/60324357">hailed</a> Medina as a hero who is "out on the front line…doing what he can to make our city safe."</p>						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why am I writing a Rust compiler in C? (372 pts)]]></title>
            <link>https://notgull.net/announcing-dozer/</link>
            <guid>41351446</guid>
            <pubDate>Sun, 25 Aug 2024 21:08:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://notgull.net/announcing-dozer/">https://notgull.net/announcing-dozer/</a>, See on <a href="https://news.ycombinator.com/item?id=41351446">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>To bootstrap Rust, no cost is too great.</p>

<p>Perceptive Rustaceans may have noticed my activity has gone down as of late.
There are a handful of different reasons for this. I’ve been the subject of a
truly apocalyptic series of life events, including the death of a relative that
rattled me to my core. I’ve had more responsibilities at work, leaving me with
less time and energy to contribute. Maybe I’ve also lost a little bit of the
college-kid enthusiasm that brought me to open source in the first place.</p>

<p>There’s another reason, too. I’ve been cooking up a project that’s been taking
up most of my time. It’s certainly the largest project I’ve created in the open
source world, and if I complete it, it will certainly be my crowning
achievement.</p>

<p>I am writing a Rust compiler in pure C. No C++. No <a href="https://en.wikipedia.org/wiki/Flex_(lexical_analyser_generator)"><code>flex</code></a> or <a href="https://en.wikipedia.org/wiki/Yacc"><code>yacc</code></a>. Not even a
<a href="https://en.wikipedia.org/wiki/Make_(software)"><code>Makefile</code></a>. Nothing but pure C.</p>

<p>It’s called <a href="https://codeberg.org/notgull/dozer">Dozer</a>.</p>

<h2 id="wait-why">Wait, Why?</h2>

<p>To understand why I’ve followed this path of madness, you first need to
understand bootstrapping and why it is important.</p>

<p>Let’s say that you’ve written some code in Rust. In order to run this code, you
need to <em>compile</em> it. A <em>compiler</em> is a program that parses your code, validates
its correctness, and then transforms it into machine code that the CPU can
understand.</p>

<blockquote>
  <p><img src="https://notgull.net/images/ddog.jpg" alt="Dependency Dog" width="100">
<strong>Dependency Dog:</strong> Yes, it’s significantly more complicated than that. Except when it’s less complicated than that. Compilers are tricky to even describe.</p>
</blockquote>

<p>For Rust, your main compiler is <a href="https://github.com/rust-lang/rust">rustc</a>. If you don’t know, this is the
underlying program that <code>cargo</code> calls when you run <code>cargo build</code>. It’s fantastic
software, and frankly a gem of the open source community. Its code quality is up
there with the Linux kernel and the Quake III source code.</p>

<p>However, <a href="https://github.com/rust-lang/rust">rustc</a> itself is a program. So it needs a compiler to compile it from
its source code to machine code. Say, what language <em>is</em> <a href="https://github.com/rust-lang/rust">rustc</a> written in?</p>

<p><img src="https://notgull.net/images/rustc-in-rust.png" alt="rustc is 97.3 percent rust"></p>

<p>Ah, <a href="https://github.com/rust-lang/rust">rustc</a> is a Rust program. Written in Rust, for the purpose of compiling
Rust code. But, think about this for a second. If <a href="https://github.com/rust-lang/rust">rustc</a> is written in Rust,
and <a href="https://github.com/rust-lang/rust">rustc</a> is needed to compile Rust code, that means you need to use <a href="https://github.com/rust-lang/rust">rustc</a>
to compile <a href="https://github.com/rust-lang/rust">rustc</a>. Which is fine for us users, since we can just download
<a href="https://github.com/rust-lang/rust">rustc</a> from the internet and use it.</p>

<p>But, who compiled the first <a href="https://github.com/rust-lang/rust">rustc</a>? There had to be a chicken before the egg,
right? Where does it start?</p>

<p>…</p>

<p>Actually, that’s fairly simple. Every new version of <a href="https://github.com/rust-lang/rust">rustc</a> was compiled with
the previous version of <a href="https://github.com/rust-lang/rust">rustc</a>. So <a href="https://github.com/rust-lang/rust">rustc</a> version 1.80.0 was compiled with
<a href="https://github.com/rust-lang/rust">rustc</a> version 1.79.0. Which was, in turn, compiled with <a href="https://github.com/rust-lang/rust">rustc</a> version
1.78.0. And so on and so forth, all the way back to <a href="https://github.com/rust-lang/rust/tree/ef75860a0a72f79f97216f8aaa5b388d98da6480">version 0.7</a>
if the compiler. At that point, the compiler was written in <a href="https://en.wikipedia.org/wiki/OCaml">OCaml</a>. So all you
needed was an OCaml compiler to get a fully functioning <a href="https://github.com/rust-lang/rust">rustc</a> program.</p>

<p>There, problem solved! We’ve figured out how to create <a href="https://github.com/rust-lang/rust">rustc</a> from first
principles! All is well, let’s go back to business.</p>

<p>Just one more thing. We still need a version of the <a href="https://en.wikipedia.org/wiki/OCaml">OCaml</a> compiler for all of
this to work. So what language is the <a href="https://en.wikipedia.org/wiki/OCaml">OCaml</a> compiler written in?</p>

<p><img src="https://notgull.net/images/ocaml-in-ocaml.png" alt="OCaml is 84 percent OCaml"></p>

<p><em>faceplant</em></p>

<p>Okay, okay, no worries! There is a <a href="https://github.com/Ekdohibs/camlboot">project</a>
that can successfully compile the <a href="https://en.wikipedia.org/wiki/OCaml">OCaml</a> compiler using <a href="https://en.wikipedia.org/wiki/GNU_Guile">Guile</a>, which is one of the many
variants of <a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)">Scheme</a>, which is one of many variants of <a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)">Lisp</a>. Not to mention,
<a href="https://en.wikipedia.org/wiki/GNU_Guile">Guile</a>’s interpreter is written in C.</p>

<p>So this brings us, as all eventually things do, to the C programming language. We just
compile it using <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a>, and everything works out. So we just need to compile
<a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a>, which is written using… C++?!</p>

<p>Okay, that’s a little unfair. <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a> was written in C until version 5, and it’s
not like there’s a shortage of C compilers written in C out there. For instance,
consider <a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a>, which is written in C and handles not only compiling, but
assembly and linking too.</p>

<p>…but that still doesn’t answer our question. What was the first C compiler
written in? Assembly? Then what was the first assembler written in?</p>

<h2 id="the-descent-principle">The Descent Principle</h2>

<p>This is where we introduce the <a href="https://bootstrappable.org/">Bootstrappable Builds</a>
project. To me, this is one of the most fascinating projects in the open source
community. It’s basically code alchemy.</p>

<p>Their <a href="https://github.com/fosslinux/live-bootstrap">Linux bootstrap process</a>
starts with a 512-byte binary seed. This seed contains what’s possibly the
simplest compiler you can imagine: it takes hexadecimal digits and outputs the
corresponding raw bytes. As an example, here part of the “source code” that’s
compiled with this compiler.</p>

<div><pre><code>31 C0           # xor ax, ax
8E D8           # mov ds, ax
8E C0           # mov es, ax
8E D0           # mov ss, ax
BC 00 77        # mov sp, 0x7700
FC              # cld ; clear direction flag
88 16 15 7C     # mov [boot_drive], dl
</code></pre></div>

<p>Note that everything after the pound sign is a comment, and all whitespace is
stripped. Frankly, I’m not even sure this can be called a programming language.
Still, it is <em>technically</em> analyzable, dissectable source code.</p>

<p>From here, this compiler compiles a very simple operating system, a barebones
shell, and a slightly more advanced compiler. That compiler compiles a slightly
more advanced compiler. A few steps later, you have something that roughly
<em>looks</em> like assembly code.</p>

<div><pre><code>DEFINE cmp_ebx,edx 39D3
DEFINE je 0F84
DEFINE sub_ebx, 81EB

:loop_options
    cmp_ebx,edx                         # Check if we are done
    je %loop_options_done               # We are done
    sub_ebx, %2                         # --options
</code></pre></div>

<p>Man, it’s weird to think of <em>assembly code</em> as being higher-level than anything
else, right?</p>

<p>This is enough to get them to a very basic subset of C. Then they compile a
slightly more advanced C compiler written in this subset. A few steps later they
can compile <a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a>. From there they can bootstrap <a href="https://en.wikipedia.org/wiki/Yacc"><code>yacc</code></a>, basic coreutils,
Bash, autotools, and eventually <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a> and Linux.</p>

<p>I’m not doing this justice, it’s a fascinating process. Every step is listed
<a href="https://github.com/fosslinux/live-bootstrap/blob/master/parts.rst">here</a>.</p>

<p>Anyhow, you’ve essentially gone from “a binary blob small enough to be manually
analyzed” to Linux, GCC, and basically everything else. But let’s start again
from <a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a>.</p>

<p>Right now, Rust shows up very late into this process. They use <a href="https://github.com/thepowersgang/mrustc">mrustc</a>, an
alternative Rust implementation written in C++ that can compile <a href="https://github.com/rust-lang/rust">rustc</a> version
1.56. From here, they then compile up to modern Rust code.</p>

<p>The main issue here is that, by the time C++ is introduced into the bootstrap
chain, the bootstrap is basically over. So if you wanted to use Rust at any
point before C++ is introduced, you’re out of luck.</p>

<p>So, for me, it would be <em>really nice</em> if there was a Rust compiler that could be
bootstrapped from C. Specifically, a Rust compiler that can be bootstrapped from
<a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a>, while assuming that there are no tools on the system yet that could be
potentially useful.</p>

<p>That’s <a href="https://codeberg.org/notgull/dozer">Dozer</a>.</p>

<h2 id="the-plan">The Plan</h2>

<p>I’ve been working on <a href="https://codeberg.org/notgull/dozer">Dozer</a> for the past two months, putting my anemic free
time to work on writing in a language that I kind of hate.</p>

<blockquote>
  <p><img src="https://notgull.net/images/ddog.jpg" alt="Dependency Dog" width="100">
<strong>Dependency Dog:</strong> That’s a little unfair. C has some elegant qualities to it. Reality truly is what you make of it. It’s just that I would not let this code anywhere near production.</p>
</blockquote>

<p>It’s written with no extensions, and so far both <a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TinyCC</a> and <a href="https://sr.ht/~mcf/cproc/">cproc</a> are able
to compile it with no issues. I’m using <a href="https://c9x.me/compile/">QBE</a> as a backend. Other than that, I
assume no tools exist on the system. Just a C compiler, some very basic shell
implementation, and nothing else.</p>

<p>I won’t get into the raw <em>experience</em> of writing a compiler in this blogpost.
But so far, I have the lexer done, as well as a sizable part of the parser.
Macro/module expansion is something I’m putting off as long as possible,
typechecking only supports <code>i32</code>, and codegen is a little bit rough. But it’s a
start.</p>

<p>I can successfully compile this code:</p>

<div><pre><code><span>fn</span> <span>rust_main</span><span>()</span> <span>-&gt;</span> <span>i32</span> <span>{</span>
    <span>(</span><span>2</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>6</span> <span>+</span> <span>3</span>
<span>}</span>
</code></pre></div>

<p>So, where to from here? Here’s my plan.</p>

<ul>
  <li>Slowly advance <a href="https://codeberg.org/notgull/dozer">Dozer</a> until it can compile some basic <code>libc</code>-using samples,
then <code>libcore</code>, then <a href="https://github.com/rust-lang/rust">rustc</a>.
    <ul>
      <li>For the record, I’m planning on compiling <a href="https://github.com/rust-lang/rust">rustc</a>’s <a href="https://github.com/rust-lang/rustc_codegen_cranelift">Cranelift</a>
backend, which is written entirely in Rust. Since we’re assuming we don’t
have C++ yet, we can’t compile LLVM.</li>
    </ul>
  </li>
  <li>Create a <code>cargo</code> equivalent that can use <a href="https://codeberg.org/notgull/dozer">Dozer</a> to compile Rust packages.</li>
  <li>Find out which sources in <a href="https://github.com/rust-lang/rust">rustc</a> are automaticaly generated and then strip
them out. By the Bootstrappable project’s rules, automatically generated code
is not allowed.</li>
  <li>Create a process that can be used to compile <a href="https://github.com/rust-lang/rust">rustc</a> and then <code>cargo</code>, then
use our compiled versions of <a href="https://github.com/rust-lang/rust">rustc</a>/<code>cargo</code> to re-compile canonical versions
of <a href="https://github.com/rust-lang/rust">rustc</a>/<code>cargo</code>.</li>
</ul>

<p>This will definitely be the hardest project I’ve ever undertaken. Part of me
doubts that I will be able to finish it. But you know what? It’s better to have
tried and lost than to never have tried at all.</p>

<p>Stay tuned for more <a href="https://codeberg.org/notgull/dozer">Dozer</a> updates, as well as an explanation of the
architecture I have planned.</p>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pi Pico 2 Extreme Teardown (151 pts)]]></title>
            <link>http://electronupdate.blogspot.com/2024/08/pi-pico-2-extreme-teardown.html</link>
            <guid>41351380</guid>
            <pubDate>Sun, 25 Aug 2024 21:01:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://electronupdate.blogspot.com/2024/08/pi-pico-2-extreme-teardown.html">http://electronupdate.blogspot.com/2024/08/pi-pico-2-extreme-teardown.html</a>, See on <a href="https://news.ycombinator.com/item?id=41351380">Hacker News</a></p>
Couldn't get http://electronupdate.blogspot.com/2024/08/pi-pico-2-extreme-teardown.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Database "sharding" came from Ultima Online? (277 pts)]]></title>
            <link>https://www.raphkoster.com/2009/01/08/database-sharding-came-from-uo/</link>
            <guid>41351219</guid>
            <pubDate>Sun, 25 Aug 2024 20:42:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.raphkoster.com/2009/01/08/database-sharding-came-from-uo/">https://www.raphkoster.com/2009/01/08/database-sharding-came-from-uo/</a>, See on <a href="https://news.ycombinator.com/item?id=41351219">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><a href="https://startuplessonslearned.blogspot.com/2009/01/sharding-for-startups.html#comment-form"><span title="L"><span>L</span></span>essons Learned: Sharding for startups </a>is a technical post about database scalability. What caught my eye was the <em>term</em>. What an odd term — “sharding.” Why would a database be described that way?</p>
<p>So I started reading a bit about it. It basically means running a bunch of parallel databases and looking into the right one, rather than trying to cram everything into one.</p>
<p>Near as I can tell, a quick Google seems to say that the term came about <a href="http://highscalability.com/unorthodox-approach-database-design-coming-shard">because of a guy who worked at Friendster and Flickr, </a>and seems to . Wikipedia has only had <a href="https://en.wikipedia.org/wiki/Shard_(database_architecture)">an article</a> for a little while. In the comment thread at Lessons Learned, there’s mention of the term being used in 2006.</p>
<p>Flickr, of course, was born as an MMO called <a href="https://en.wikipedia.org/wiki/Game_Neverending"><em>Game Neverending</em></a>. In fact, I was quoted in Ludicorp’s business plan, and Stewart Butterfield had asked if I could be an advisor, but I couldn’t do it at the time because of my contract with Sony. Sigh. Anyway, I would be <em>shocked</em> if the term “shard” hadn’t been thrown around those offices… because in MMOs, of course, “shards” has a very specific meaning and history.</p>

<p>It means database partitioning — of worlds. Parallel worlds each running the same static template database source, but evolving different runtime databases. But these were just called “servers” — like, <em>Meridian 59</em> had bunches of them, and they had numbers instead of the common practice of names that is in use today.</p>
<div><p><img decoding="async" title="A snippet from the UO intro movie" src="https://upload.wikimedia.org/wikipedia/en/c/cb/Mondain-uo-intro.jpg" alt="A snippet from the UO intro movie" width="283" height="160"></p><p>A snippet from the UO intro movie</p></div>
<p>No, “shards” came about specifically because when we realized we would need to run multiple whole copies of <em>Ultima Online</em> for users to connect to, we needed to come up with a fiction for it. I went off and read a whole mess of stuff about early Ultima lore and tried to come up with a fictional justification. What I ended up with <a href="https://en.wikipedia.org/wiki/Britannia_(Ultima_Online)">is described here pretty well</a>: that the evil wizard Mondain had attempted to gain control over Sosaria by trapping its essence in a crystal. When the Stranger at the end of Ultima I defeated Mondain and shattered the crystal, the crystal <strong>shards</strong> each held a refracted copy of Sosaria.</p>
<p>It was a very very specific word chosen because, well, it was a piece of a crystal, which was a completely fictional invention. If Mondain had captured Sosaria on a parchment or in a painting, I would have said “a tatter” or a “fragment” or some such. But in the original U1, it specifically said he had used a crystal to gain power. We even talked about terms like “multiverse” and the like at the time and dismissed them as comic-book geeky and not really Ultima-flavored… so “shard” it was.</p>
<p>Now, from there time kept marching forward as each parallel Sosaria evolved in tandem. (UO was supposed to be between U3 and U4, in terms of chronology). The difference is, some of them got the Avatar (sent by the Time Lord) and some didn’t. Some of them were captured by The Guardian, and we invented the notion that Shadowlords were essentially evil beings created from shards he had captured. In fact, the beta test shard eventually was captured in this way — if you read up on it, you’ll find that really, there should be a fourth Shadowlord running around now.</p>
<div><p><a href="http://flickr.com/photos/37996580417@N01/6819311"><img fetchpriority="high" decoding="async" title="Original planned UO map" src="https://i0.wp.com/farm1.static.flickr.com/6/6819311_40cd3d3801.jpg?resize=400%2C300" alt="Original planned UO map, photo by Cory Doctorow, CC BY-SA" width="400" height="300" data-recalc-dims="1"></a></p><p>Original planned UO map, photo by Cory Doctorow, CC BY-SA</p></div>
<p>(Originally, the landmass of <em>Second Age</em> was supposed to be Ambrosia from Ultima III, and there’s actually a spot up north that is where Exodus is supposed to go. We even made the art for the whirlpool that is supposed to go there, and then just never put it in. But that’s a whole other story…)</p>
<p>(Oh… and then why does the Stranger in the original UO intro movie have an Ankh on his chest? Because U9 was in development aready, and nobody had time to make a new model. 🙂 So it’s the same 3d model as was used in U9, which didn’t ship until <em>years</em> later. So expedience led to a fictional glitch.)</p>
<p>In any case, we called parallel servers “shards” and it became a term used occasionally though not universally as a term of art within the field. You’ll hear folks who worked on MMOs in the 90s use server and shard interchangeably — sometimes saying “shard” to reference a parallel server cluster rather than a physical server.</p>
<p>So, did this database term come from a doc that I dashed off one afternoon in 1996? Umm… I am not sure. Seems like an interesting coincidence, if not.</p>
<p>I wonder if I still have that doc…</p>

 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Olivetti Programma 101: At the Origins of the Personal Computer (126 pts)]]></title>
            <link>https://www.inexhibit.com/case-studies/olivetti-programma-101-at-the-origins-of-the-personal-computer/</link>
            <guid>41351009</guid>
            <pubDate>Sun, 25 Aug 2024 20:20:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.inexhibit.com/case-studies/olivetti-programma-101-at-the-origins-of-the-personal-computer/">https://www.inexhibit.com/case-studies/olivetti-programma-101-at-the-origins-of-the-personal-computer/</a>, See on <a href="https://news.ycombinator.com/item?id=41351009">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-768x512.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-423x282.jpg.webp 423w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-624x416.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img fetchpriority="high" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer.jpg" alt="Olivetti Programma 101 computer" width="870" height="580" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-768x512.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-423x282.jpg 423w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-624x416.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>An Olivetti Programma 101, photo courtesy of Museo Nazionale della Scienza e della Tecnologia “Leonardo da Vinci”, Milan (CC BY-SA 4.0).</em></p>
<p><strong>At the origins of the Personal Computer: the&nbsp;Olivetti Programma 101 (1965)</strong></p>
<p>These days, Italy is not particularly renowned for its consumer electronics products; yet, there was a time, in the ’60s, when an Italian company was reputed to be the “European response” to American computer manufacturers; that company was <strong>Olivetti</strong>.</p>
<p>The company was founded in Ivrea, Northern Italy, in the early 20th century as a typewriter maker; but, in the late ’50s, under the direction of <strong>Adriano Olivetti</strong> and his son <strong>Roberto</strong>, it became one of the first European companies to regularly produce electronic calculators and computers, often characterized by innovative design and engineering solutions.</p>
<p><strong>The&nbsp;first human-centered&nbsp;computer</strong><br>
It was in the early Sixties that Olivetti<strong> decided to develop a “desktop” computer</strong>; namely, a computer much smaller than those used at the time, and compact enough to be <em>“a personal object, something that had to live with a person, a person with his chair sitting at a table or desktop”</em> (Roberto Olivetti). This object was the <strong>Programma 101</strong>.</p>
<p>This idea was utterly revolutionary since, at the time, computers were massive mainframes sealed in airtight rooms and operated by an elite of specialized technicians in white coats. Just before revealing the “dream machine”, a Programma 101 advertisement recited: <em>“Welcome to the world of tomorrow. You are about to take a journey out of this world into the world of the future”</em>, another one was showing a businessman and a handsome woman in a swimsuit (his secretary, perhaps) working on a Perottina right at the side of a pool…</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1.jpg" rel="attachment wp-att-39542"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-300x172.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-768x440.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-218x125.jpg.webp 218w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-624x358.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1.jpg" alt="Olivetti Programma 101 computer advertise 1" width="870" height="499" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-300x172.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-768x440.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-218x125.jpg 218w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-computer-advertise-1-624x358.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>A 1960s video advertisement of the Olivetti P101 for the U.S. market.</em></p>
<p><strong>The development stage</strong><br>
The Programma 101 takes its nickname, <em><strong>Perottina</strong></em>, from that of its inventor – Italian electrical engineer <strong>Pier Giorgio Perotto</strong>, then 32 years old – to whom Olivetti assigned the direction of the project in 1962. The computer was developed by an engineering team of five young technicians which included – along with Perotto – Giovanni De Sandre, Giuliano Gaiti, Gastone Garziera, and Giancarlo Toppi.</p>
<p>The early story of the Programma is somewhat romantic. Olivetti had just sold its electronics division to General Electric, which wasn’t interested in an “Italian computer” at all.<br>
Yet, the team didn’t want to give up the project, already in an embryonic stage; therefore, they invented a trick. Overnight, they warily declassified the machine from “computer” to “calculator”, and the calculator division was not part of the agreement with GE. So they could go on developing for some crucial months their “machine of the future”, in a sort of no man’s land between Olivetti and General Electric.</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-Perotto-team.jpg" rel="attachment wp-att-39544"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-Perotto-team.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-Perotto-team-300x212.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-Perotto-team-768x543.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-Perotto-team-624x441.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-Perotto-team.jpg" alt="Olivetti Programma 101 Perotto team" width="870" height="615" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-Perotto-team.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-Perotto-team-300x212.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-Perotto-team-768x543.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-Perotto-team-624x441.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>The technical development team of Programma 101 (except Giuliano Gaiti); left to right and bottom to top: Pier Giorgio Perotto, Giovanni De Sandre, Gastone Garziera, and Giancarlo Toppi; photo courtesy of Laboratorio-museo Tecnologicamente, Ivrea / Wikimedia.</em></p>
<p>When we look at the specifications and capabilities of the machine, today, it is hard to think it was a real computer.<br>
Due to its limited RAM of 1,920 bits, the Programma 101 was mostly a machine conceived to make arithmetic calculations – sums, subtractions, divisions, multiplications, square roots -, yet, like modern computers, it could also perform logical operations, conditional and unconditional jumps, and print the data stored in a register, all through a custom-made alphanumeric programming language. This was, in the early ’60s, what set computers apart from calculators, indeed.<br>
Overall, in today’s terms, Programma 101 can be considered a sort of “transitional fossil” between desktop calculators and personal computers.</p>
<p>The P101 didn’t have a monitor or the like, it used a small paper tape printer as a visualization device, instead. A revolutionary innovation made by Olivetti was to replace the fridge-size magnetic tape mass memory devices typical of coeval mainframes with a <strong>programmable magnetic card reader/recorder</strong>.<br>
Programs were recorded on these plastic strips, about 3 inches wide and one foot long, which could contain only 240 instructions and were very slow but were also small, simple to use, and quite practical overall. The magnetic bands were on one side of the card, so the other could be used to write annotations and the names of the programs they contained.</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2.jpg" rel="attachment wp-att-39546"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2-300x101.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2-768x258.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2-624x209.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2.jpg" alt="Olivetti Programma 101 desktop computer 2" width="870" height="292" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2-300x101.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2-768x258.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-2-624x209.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-magnetic-card.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-magnetic-card.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-magnetic-card-300x98.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-magnetic-card-768x251.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-magnetic-card-624x204.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-magnetic-card.jpg" alt="Olivetti Programma 101 magnetic card" width="870" height="284" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-magnetic-card.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-magnetic-card-300x98.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-magnetic-card-768x251.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-magnetic-card-624x204.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>An image showing how the memory cards were used and a photo of one of the original magnetic cards; images courtesy of Computer Museum / University of Amsterdam and Bech (CC BY-SA 4.0) / Inexhibit.</em></p>
<p>The machine didn’t have a microprocessor or integrated circuits; like most computers of the time, its electronics were exclusively based on transistors, diodes, capacitors, and the like, grouped into larger functional “micro-units” (a patented technology specially developed by Olivetti for the Programma 101).</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open.jpg" rel="attachment wp-att-39554"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-open.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-open-300x164.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-open-768x421.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-open-624x342.jpg.webp 624w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-open-245x135.jpg.webp 245w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open.jpg" alt="Olivetti Programma 101 open" width="870" height="477" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open-300x164.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open-768x421.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open-624x342.jpg 624w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-open-245x135.jpg 245w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>The interior </em><em>of the P101 “Perottina”; photo ICTP Scientific FabLab; the front-right section accommodates the power supply and the electric motor; the front-middle-to-left section contains the keyboard, the printer, and the card reader/recorder; the rear section is reserved for the electronic section, cooled by a fan.</em></p>
<p><strong>The design of the Programma 101 body<br>
</strong>The design of the Programma’s body was conducted by <strong>Mario Bellini</strong>, a then-young architect, who was preferred to other designers who had previously worked for Olivetti, such as Ettore Sottsass, Marco Zanuso, and Marcello Nizzoli. Zanuso was contacted at first, but his proposal was a massive self-standing box, similar to that of a mainframe, which would have nullified all the effort to keep the device as small and lightweight as possible.</p>
<p>The team of&nbsp;Perotto had already created an impromptu wood case for the machine, just to give the P101 some kind of a container, but they were aware they still needed an open-mind architect keen to work on something never seen before. The young Bellini was possibly that man.</p>
<p>For the P101, Bellini conceived a case, mostly made in <strong>cast aluminum</strong>, whose round-edge shape set it apart from other electronics products by Olivetti, such as the mainframe <em>ELEA 9003</em> designed by Sottsass only a few years before.<br>
The decision to make the case of Programma 101 in an unconventional material such as die-cast alloy (most computers of the time were made in sheet metal) was justified by the need to avoid electromagnetic interference in a home/office environment.<br>
The case was 3 mm. thick and relatively lightweight (the whole machine weighed about 65 lbs. / 30 Kg. ).<br>
Bellini would have probably designed it to be made in plastic if synthetic materials were sufficiently developed at the time, which wasn’t the case. For example, in 1964, <strong>Ettore Sottsass</strong> designed a lined housing for the Olivetti Praxis 48 typewriter also to conceal the imperfections and the visually unpleasing shininess in its plastic die.</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1-300x159.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1-768x406.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1-624x330.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1.jpg" alt="Olivetti Praxis 48 typewriter side" width="870" height="460" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1-300x159.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1-768x406.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Praxis-48-typewriter-side-1-624x330.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>The case of the Olivetti Praxis 48 typewriter was designed in 1964 with a lined texture to disguise the imperfection of its innovative plastic body; image Charles Kremenak (CC BY 2.0).</em></p>
<p><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-ELEA-9003.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-ELEA-9003-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-ELEA-9003-768x511.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-ELEA-9003-624x415.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-ELEA-9003.jpg" alt="Olivetti ELEA 9003" width="870" height="579" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-ELEA-9003.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-ELEA-9003-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-ELEA-9003-768x511.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-ELEA-9003-624x415.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></p>
<p><em>The sharp-edged, angular forms of the mainframe Olivetti ELEA 9003 were typical of the late ’50s and early ’60s computers; image Museo Nazionale della Scienza e della Tecnologia “Leonardo da Vinci” (CC BY-SA 4.0).</em></p>
<p>The design of the Perottina is somewhat reminiscent of that (again by Sottsass) of the <strong>Olivetti Logos 27</strong> electromechanical calculator, which was first presented, together with the Programma 101, in October 1965 at the <strong>Bema</strong> (Business Equipment Manufacturer Association) show in New York. &nbsp;Like the 101, the Logos 27 also had a die-cast alloy case; overall, both machines look a bit like big typewriters.<br>
Nevertheless, the case of the Programma is much more futuristic, bright, and “friendly” than the rather serious one of the Logos.</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Logos-27.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Logos-27-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Logos-27-768x512.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Logos-27-423x282.jpg.webp 423w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Logos-27-624x416.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27.jpg" alt="Olivetti Logos 27" width="870" height="580" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27-768x512.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27-423x282.jpg 423w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Logos-27-624x416.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>The electro-mechanic calculator Olivetti Logos 27 (1965), design: Ettore Sottsass; photo&nbsp; Piergiovanna (CC BY-SA 4.0) / Inexhibit.</em></p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5.jpg" rel="attachment wp-att-39560"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5-768x511.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5-624x415.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5.jpg" alt="Olivetti Programma 101 desktop computer 5" width="870" height="579" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5-768x511.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-5-624x415.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>Desk-top computer Olivetti Programma 101 (1965); design: Mario Bellini; photo courtesy of Museo Nazionale della Scienza e della Tecnologia, Milan (CC BY-SA 4.0).</em></p>
<p>I see in it some elements – such as the use of thin lines to make the object appear smaller than it actually was, the playful contrast between the almost-white color case and the vividly-colored logo area, and the uncluttered design of slots and handles – which recall me the <strong>“Snow White” design language</strong> developed for Apple by German designer&nbsp;<em>Hartmut Esslinger</em> twenty years later.</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4.jpg" rel="attachment wp-att-39568"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4-768x511.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4-624x415.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4.jpg" alt="Olivetti Programma 101 desktop computer 4" width="870" height="579" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4-768x511.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-4-624x415.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>Photo courtesy of Museo Nazionale della Scienza e della Tecnologia, Milan (CC BY-SA 4.0).</em></p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6-300x241.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6-768x617.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6-624x501.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6.jpg" alt="Olivetti Programma 101 desktop computer 6" width="870" height="699" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6-300x241.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6-768x617.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-6-624x501.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>Photo by Paolo Monti / BEIC Digital Library (CC BY-SA 4.0)</em><em>.</em></p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-768x512.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-423x282.jpg.webp 423w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-624x416.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up.jpg" alt="Olivetti Programma 101 desktop computer close-up" width="870" height="580" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-768x512.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-423x282.jpg 423w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-close-up-624x416.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>Photo by ☰☵ Michele M. F. / Flickr (CC BY-SA 2.0).</em></p>
<p><strong>The P101 commercial success and legacy</strong><br>
Despite Olivetti initially having modest expectations of the commercial possibilities of Programma 101, the computer was a success.<br>
With a price of $3,200 (about 20,000 in today’s dollars), it was quite cheap if compared to other computers of the time, which were mostly expensive mainframes reserved for big companies, government agencies, and universities. Furthermore, the Perottina was small and you could easily move it from one room to another, plug it into a power socket, and start working in minutes.<br>
In his book&nbsp;on the story of the P101, Perotto&nbsp;reports that some&nbsp;visitors of the <em>Bema Show</em>, when the machine was presented for the first time, believed that it was a sham, and was some sort of a console attached&nbsp;to a mainframe secretly concealed somewhere else.</p>
<p>Olivetti <strong>sold about 44,000 Programma 101 units</strong>, mostly in the United States, including 10 machines that NASA used for the Apollo 11 program.</p>
<p><em>“By Apollo 11 we had a desktop computer, sort of, kind of, called an Olivetti Programma 101. It was kind of a super calculator. (…) It would add, subtract, multiply, and divide, but it would remember a sequence of these things, and it would record that sequence on a magnetic card (…). So you could write a sequence, a programming sequence, and load it in there”</em> David W. Whittle, Johnson Space Center, NASA</p>
<p>What makes the Perottina a quantum leap in computer concept and design was being <strong>the first human-centered computer</strong> ever made.<br>
The company’s leaders and designers shared the same objective: to create for the first time a computer aimed at common people, not technicians and scientists only.<br>
And to achieve that they had to focus on the relationship between humans and machines, besides the pure computational performances of the computer.</p>
<p><em>“Those days, few manufacturers and designers were interested in the user’s perspective and user-friendliness of machines. After all, In the ’60s, the available technology was limited, and the interest of computer designers was entirely focused on technical issues and on making devices work. It was the user who had to adapt to the machine, not the opposite. The electronics had to provide quantitative performances – as much computational power, memory, and printing speed as possible -, there was no room to improve the relationship between computers and their users who, moreover, were all specialized technicians. Despite technology was improving in power, nevertheless, it didn’t leave much to those interested in making machines more friendly and easy to use.” &nbsp;</em>(Pier Giorgio Perotto, Programma 101. The never told, fascinating story of the invention of the Personal Computer, p. 20)</p>
<p>That’s why the Programma was technically and aesthetically conceived as an unintimidating object everyone could use, even at home. In that sense, there is no doubt that the Olivetti Programma 101 truly is <strong>the first Personal Computer</strong> in history.<br>
Furthermore, if industrial design is a discipline aimed at creating relationships between useful objects and their users, the Perottina can be considered possibly the first computer to have been designed.</p>
<p><a href="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7.jpg"><picture><source srcset="https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7.jpg.webp 870w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-300x200.jpg.webp 300w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-768x512.jpg.webp 768w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-423x282.jpg.webp 423w, https://www.inexhibit.com/wp-content/webp-express/webp-images/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-624x416.jpg.webp 624w" sizes="(max-width: 870px) 100vw, 870px" type="image/webp"><img loading="lazy" decoding="async" src="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7.jpg" alt="Olivetti Programma 101 desktop computer 7" width="870" height="580" srcset="https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7.jpg 870w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-300x200.jpg 300w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-768x512.jpg 768w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-423x282.jpg 423w, https://www.inexhibit.com/wp-content/uploads/2017/02/Olivetti-Programma-101-desktop-computer-7-624x416.jpg 624w" sizes="(max-width: 870px) 100vw, 870px"></picture></a></p>
<p><em>Photo by Emanuele / Flickr (CC BY-NC-ND 2.0).</em></p>
<p><strong>References</strong><br>
For images and technical info on the Programma 101 see:<br>
The incredible story of the first PC, from 1965 (http://royal.pingdom.com/2012/08/28/the-first-pc-from-1965/, in English)<br>
Olivetti Programma 1010 (http://www.silab.it/frox/p101/_index.html , in English)<br>
PROGRAMMA 101 – Memory of the Future by Alessandro Bernard and Paolo Ceretto (http://www.101project.eu/the-documentary/, video)<br>
“Alle origini del personal computer: l’Olivetti Programma 101” (http://www.storiaolivetti.it/percorso.asp?idPercorso=630, in Italian)<br>
La Programma 101, il primo personal computer al mondo (http://www.piergiorgioperotto.it/programma101.aspx, in Italian)</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Big Pharma claims lower prices means giving up miracle medications. Ignore them (132 pts)]]></title>
            <link>https://www.vox.com/future-perfect/368538/medicare-drug-prices-pharma-negotiations-innovation</link>
            <guid>41350940</guid>
            <pubDate>Sun, 25 Aug 2024 20:14:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vox.com/future-perfect/368538/medicare-drug-prices-pharma-negotiations-innovation">https://www.vox.com/future-perfect/368538/medicare-drug-prices-pharma-negotiations-innovation</a>, See on <a href="https://news.ycombinator.com/item?id=41350940">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>For the first time, the federal government has <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2024/08/15/fact-sheet-biden-harris-administration-announces-new-lower-prices-for-first-ten-drugs-selected-for-medicare-price-negotiation-to-lower-costs-for-millions-of-americans/">negotiated</a> directly with pharmaceutical companies over the prices for a handful of drugs. The new prices, which were announced mid-August, take effect in January 2026, and they will help the Medicare program cap what individual patients spend out of pocket on their prescriptions in a year at $2,000.</p><p>The historic policy, which has been floating around for decades, was long opposed by “Big Pharma” until Democrats in Congress passed and President Joe Biden signed <a href="https://www.vox.com/policy/2023/8/30/23850979/medicare-drug-price-negotiations-10-prescription-list">the Inflation Reduction Act in 2022</a>.</p><p>Pharma tried to stop the negotiation policy in courts after it became law. Their concerns — namely, that these “price controls” <a href="https://www.vox.com/policy-and-politics/22702855/build-build-better-plan-medicare-negotiate-drug-prices">will stifle innovation</a> — have been echoed by Republicans and policy commentators with the recent finalization of the negotiated prices. With less profit, companies like <a href="https://www.cnbc.com/2023/05/11/pfizer-medicare-could-face-legal-action-over-drug-price-negotiations.html">Pfizer</a> and <a href="https://www.cnn.com/2023/06/06/politics/merck-lawsuit-medicare-drug-price-negotiation/index.html">Merck</a> argue, it will be harder to hire scientists, invest in laboratory space, and set up clinical trials to test the medications of the future.</p><div><p>Sign up <a href="https://www.vox.com/pages/future-perfect-newsletter-signup">here</a> to explore the big, complicated problems the world faces and the most efficient ways to solve them. Sent twice a week.</p></div><p>It is a harrowing proposition: that in trying to control drug prices for 67 million Medicare patients now, we might inadvertently prevent the development of future drugs that could save lives. Implied, if not stated outright, is that we’re putting a cure for cancer or <a href="https://www.vox.com/future-perfect/355108/alzheimers-disease-drug-approval-research-retraction">Alzheimer’s</a> or some other intractable disease in jeopardy.</p><p>But we have good reasons to believe that the current policy won’t have such a trade-off any time soon. For one, pharma is hugely profitable, and these negotiated prices, while potentially chipping away at profit margins, should hardly entirely dampen the incentive to innovate, according to a couple of key studies of the industry. Two, if we are worried about future innovation, we should be focused on <a href="https://www.vox.com/future-perfect/367247/antibiotic-resistance-bacteria-pasteur-act-big-pharma">making it cheaper to develop drugs</a> – and this is actually one area where AI is showing promise. By identifying the best candidates for possible treatments early in the research process, we could speed up development and continue to reduce costs — without losing out on tomorrow’s breakthroughs.</p><div><p id="we-can-afford-to-lower-drug-prices"><h2>We can afford to lower drug prices</h2></p></div><p>The argument against reducing profits usually goes like this: The drug companies spend a lot of money developing drugs, including some drugs that never make it to market because they don’t prove to be effective. When they do have a new, effective drug to sell, they need to make a lot of money to cover their development costs and then some, so they can take the profits and invest more money into research and development for the next generation of medicines. </p><p>Most other wealthy countries, like Australia and the UK, use the government’s central role in their health care system to negotiate lower prices while also <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2866602/">fostering their own medical innovation sectors</a>. But in the US, before the IRA’s provisions became law, prices were left more to the free market and the individual negotiating positions of manufacturers, private insurers, the government, and pharmacy benefit managers. Various rebates, kickbacks, and other financing mechanisms often obfuscated and increased Americans’ drug prices. As a result, the US pays by far the highest costs for medications in the world. </p><p>As a result of how much we pay, Americans generally get first dibs on new cures. But that early access is only useful if patients can afford the drugs. <a href="https://www.kff.org/health-costs/issue-brief/americans-challenges-with-health-care-costs/#:~:text=About%20one%20in%20five%20adults,year%20because%20of%20the%20cost.">Too often, they can’t</a>.</p><p>But here’s the thing: This whole premise is faulty. When the Congressional Budget Office evaluated the bill before it passed, its analysts said they <a href="https://www.cbo.gov/system/files/2023-12/59792-Letter.pdf">did not expect a major effect</a> on future drug development. The need to cover R&amp;D costs does not actually explain, at least not entirely, the high costs for medications charged in America, according to <a href="https://www.healthaffairs.org/content/forefront/r-d-costs-pharmaceutical-companies-do-not-explain-elevated-us-drug-prices">a 2017 analysis published by <em>Health Affairs</em></a>, a health care research journal.</p><p>The research — from Memorial Sloan Kettering Cancer Center’s Nancy Yu, Zachary Helms, and Peter Bach — determined the excess price paid in the US compared to other wealthy nations. They called this price the American R&amp;D “premium.” They then calculated how much revenue said premium generated for the top 15 drug manufacturers in the world and compared it to the companies’ respective R&amp;D spending.</p><div><div><p><a href="https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0,0,100,100" data-pswp-height="1172" data-pswp-width="1240" target="_blank" rel="noreferrer"><img alt="A chart showing how much more Americans pay for prescription drugs than people in other countries do, from 25 percent to 75 percent more, varying by manufacturer." data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px" srcset="https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=256 256w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=376 376w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=384 384w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=415 415w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=480 480w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=540 540w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=640 640w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=750 750w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=828 828w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1080 1080w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1200 1200w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1440 1440w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1920 1920w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2048 2048w, https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400 2400w" src="https://platform.vox.com/wp-content/uploads/sites/2/2024/08/a046W-americans-pay-more-for-prescription-drugs-compared-to-other-countries.png?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div><p><cite>Dylan Scott/Vox</cite></p></div><p>They concluded other countries had average drug list prices that were 41 percent of the net prices paid in the US. Big Pharma reaped $116 billion in revenue in one year from these excess American prices. In the same year, drug makers spent $76 billion on R&amp;D. These numbers suggest drug companies can afford avoiding such a premium. “There are billions of dollars left over even after worldwide research budgets are covered,” the authors wrote.</p><p>At a certain point, the expectation of lower revenues could start to reduce the industry’s willingness to invest in new drugs and make riskier bets with potentially big payoffs. But are we anywhere near that point? Whatever objections these companies might be raising, it may be more telling to examine what they do rather than what they say.</p><p>Last year, Richard Frank and Ro Huang at the Brookings Institution <a href="https://www.brookings.edu/articles/early-claims-and-ma-behavior-following-enactment-of-the-drug-provisions-in-the-ira/">looked</a> at the business decisions drug makers had made since negotiation provisions became law. The researchers specifically considered mergers and acquisitions, the other means by which big drug companies discover new drugs (usually by buying a promising start-up that has already done R&amp;D). </p><p>Frank and Huang detected little evidence that the drug companies were expecting a massive blow to their revenues because of changes to the negotiation process. If anything, they found increased transactions for drugs at both the early and late trial stages. Overall M&amp;A spending was not noticeably altered and some <a href="https://s203.q4cdn.com/636242992/files/doc_financials/2023/q2/JNJ-Q2-2023-Transcript-Final.pdf">recent earnings reports</a> had expressed optimism about the future.</p><p>This makes sense: the IRA stipulated that Medicare’s negotiating authority be limited and gradually phased in. For the first year, Medicare was permitted to pick 10 drugs for negotiations. Next year, the program can add another 15 and another 15 the year after that. </p><div><p id="how-to-make-more-drugs-quickly"><h2>How to make more drugs quickly</h2></p></div><p>We have a sound basis to think we can afford lower prices for more drugs. But still, it would be nice if we could develop drugs more quickly and therefore more cheaply. That could naturally lower prices while still delivering new medicines to people in need. Win-win.</p><p>There may be ways to simplify the approval process and the approval criteria for more drugs. Writer Matt Yglesias <a href="https://www.slowboring.com/p/smarter-ways-to-boost-drug-innovation">covered some options</a> for Congress and the FDA to consider in his newsletter, including being more receptive to data from clinical trials conducted in other countries (where trials can often be done at less expense).</p><p>But science is the most daunting obstacle to new drugs. It can take years for researchers to even figure out how diseases work, their biological basis, and thereby hypothesize possible candidates for interventions. Moving from the basic research that reveals those building blocks to the clinical trials that secure FDA approval can take decades. The FDA only factors in once you’ve figured out something that actually works. That’s why big drug companies do spend so much on acquisitions; even with all their resources, there’s no guarantee the in-house scientists will find a promising treatment candidate before an outside researcher does.</p><p>The best way to maximize our R&amp;D resources, to get the most bang for our buck when we set up expensive human trials, is to identify the most promising candidates at the start. But we are dealing with an enormous amount of information: the library of genetics that every human being carries. This is why drug developers are turning to <a href="https://www.vox.com/future-perfect/23827785/artifical-intelligence-ai-drug-discovery-medicine-pharmaceutical">AI for help in sorting through it</a>.</p><p>Leading researchers on antibiotic resistance <a href="https://www.vox.com/future-perfect/353420/drug-resistant-bacteria-are-killing-more-and-more-humans-we-need-new-weapons">have trained computers</a> to hunt everywhere, even in extinct animal DNA, for molecules that could be promising in treating bacteria that have become difficult for conventional medicines to treat. Longevity proponents <a href="https://www.vox.com/the-highlight/24121932/anti-aging-longevity-science-health-drugs">put a similar faith</a> in artificial intelligence. New start-ups, such as Recursion Pharmaceuticals, <a href="https://www.statnews.com/2024/08/19/recursion-pharmaceuticals-front-runner-ai-in-medicine-new-drug-development/">profiled by STAT</a>, have based their entire business on using AI to find potential drug candidates, including among those sitting on the shelves of Big Pharma that could be repurposed for new conditions.</p><p>Whether those AI aspirations will pay off is still unknown. But they provide another reason for optimism. </p><p>Too often, the drug pricing conversation is framed as an either/or. Either lower prices or new cures, but not both. It’s a false choice.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is Telegram really an encrypted messaging app? (556 pts)]]></title>
            <link>https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/</link>
            <guid>41350530</guid>
            <pubDate>Sun, 25 Aug 2024 19:34:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/">https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/</a>, See on <a href="https://news.ycombinator.com/item?id=41350530">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-7859">
	
	<div>
		
<p>This blog is reserved for more serious things, and ordinarily I wouldn’t spend time on questions like the above. But much as I’d like to spend my time writing about exciting topics, sometimes the world requires a bit of what <a href="https://braddelong.substack.com/">Brad Delong </a>calls “Intellectual Garbage Pickup,” namely: correcting wrong, or mostly-wrong ideas that spread unchecked across the Internet. </p>



<p>This post is inspired by the recent and concerning news that <a href="http://app is accused of failure to cooperate with law enforcement over drug trafficking, child sexual content and fraud.">Telegram’s CEO Pavel Durov has been arrested by French authorities</a> for its failure to sufficiently moderate content. While I don’t know the details, the use of criminal charges to coerce social media companies is a pretty worrying escalation, and I hope there’s more to the story.</p>



<p>But this arrest is not what I want to talk about today.</p>



<p>What I do want to talk about is one specific detail of the reporting. Specifically: the fact that nearly every news report about the arrest refers to Telegram as an “encrypted messaging app.” Here are <a href="https://www.politico.eu/article/telegram-app-ceo-pavel-durov-reportedly-arrested-at-french-airport/">just a</a> <a href="https://abcnews.go.com/Technology/wireStory/french-authorities-arrest-telegram-ceo-pavel-durov-paris-113132319">few</a> <a href="https://www.france24.com/en/live-news/20240825-telegram-chief-pavel-durov-arrested-at-french-airport">examples</a>: </p>


<div>
<figure><a href="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-1.png"><img data-attachment-id="7864" data-permalink="https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/image-34/" data-orig-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-1.png" data-orig-size="1182,274" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-1.png?w=300" data-large-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-1.png?w=700" tabindex="0" role="button" width="1024" height="237" src="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-1.png?w=1024" alt=""></a></figure></div>

<div>
<figure><a href="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-2.png"><img data-attachment-id="7865" data-permalink="https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/image-35/" data-orig-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-2.png" data-orig-size="2466,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-2.png?w=300" data-large-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-2.png?w=700" tabindex="0" role="button" width="1024" height="233" src="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-2.png?w=1024" alt=""></a></figure></div>

<div>
<figure><a href="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-3.png"><img data-attachment-id="7867" data-permalink="https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/image-36/" data-orig-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-3.png" data-orig-size="2040,582" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-3.png?w=300" data-large-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-3.png?w=700" tabindex="0" role="button" width="1024" height="292" src="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-3.png?w=1024" alt=""></a></figure></div>


<p>This phrasing drives me buts because in one a very limited technical sense it’s <em>not wrong.</em> Yet in every sense that matters, it fundamentally misrepresents what Telegram is and how it works in practice. And this misrepresentation is bad for both journalists and particularly for Telegram’s users, many of whom could be badly hurt as a result.</p>



<p>Now to the details. </p>



<h3>Does Telegram have encryption or doesn’t it?</h3>



<p>Many systems use encryption in some way or another. However, when we talk about encryption in the context of modern private messaging services, the word typically has a very specific meaning: it refers to the use of default <a href="https://en.wikipedia.org/wiki/End-to-end_encryption">end-to-end</a> encryption to protect users’ message content. When used in an industry-standard way, this feature ensures that every message will be encrypted using encryption keys that are only known to the communicating parties, and not to the service provider.</p>



<p>From your perspective as a user, an “encrypted messenger” ensures that each time you start a conversation, your messages will only be readable by the folks you intend to speak with. If the operator of a messaging service tries to view the content of your messages, all they’ll see is useless encrypted junk. That same guarantee holds for anyone who might hack into the provider’s servers, and also, for better or for worse, to <a href="https://www.theguardian.com/technology/2023/apr/20/crime-agencies-condemn-facebook-instagram-encryption-plans">law enforcement agencies that serve providers with a subpoena</a>. </p>



<p>Telegram clearly fails to meet this stronger definition for a simple reason: it does not end-to-end encrypt conversations by default. If you want to use end-to-end encryption in Telegram, you must manually activate an <a href="https://core.telegram.org/blackberry/secretchats">optional end-to-end encryption feature</a> called “Secret Chats” for every single private conversation you want to have. The feature is explicitly <span>not turned on</span> for the vast majority of conversations, and is only available for one-on-one conversations, and never for group chats with more than two people in them. </p>



<p>As a kind of a weird bonus, activating end-to-end encryption in Telegram is oddly difficult for non-expert users to actually do.</p>



<p>For one thing, the button that activates Telegram’s encryption feature is not visible from the main conversation pane, or from the home screen. To find it in the iOS app, I had to click at least four times — once to make a hidden menu pop up, and a second time to “confirm” that I wanted to use encryption. And even after this I was not able to actually have an encrypted conversation, since <em>Secret Chats only works if your conversation partner happens to be online </em>when you do this. </p>


<div>
<figure><a href="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-7.png"><img data-attachment-id="7884" data-permalink="https://blog.cryptographyengineering.com/2024/08/25/telegram-is-not-really-an-encrypted-messaging-app/image-40/" data-orig-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-7.png" data-orig-size="2908,658" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-7.png?w=300" data-large-file="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-7.png?w=700" tabindex="0" role="button" loading="lazy" width="1024" height="231" src="https://blog.cryptographyengineering.com/wp-content/uploads/2024/08/image-7.png?w=1024" alt=""></a><figcaption><em>Starting a “secret chat” with my friend Michael on the latest Telegram iOS app. From an ordinary chat screen this option isn’t directly visible. Getting it activated requires four clicks: <strong>(1)</strong> to get to Michael’s profile (left image), <strong>(2)</strong> on the “…” button to display a hidden set of options (center image), <strong>(3)</strong> on “Start Secret Chat”, and <strong>(4)</strong> on the “Are you sure…” confirmation dialog. After that I’m still unable to send Michael any messages, because Telegram’s Secret Chats can only be turned on if the other user is also online. </em></figcaption></figure></div>


<p>Overall this is quite different from the experience of starting a new encrypted chat in an industry-standard modern messaging application, which simply requires you to open a new chat window.</p>



<p>While it might seem like I’m being picky, the difference in adoption between default end-to-end encryption and this experience is likely very significant. The practical impact of these UX decisions is likely to ensure that the vast majority of one-on-one Telegram conversations — and literally <em>every single group chat</em> — allow Telegram’s servers to see and record the content of all messages sent between users. That may or may not be a problem for every Telegram user, but it’s certainly not something we’d advertise as particularly well encrypted.</p>



<p>(If you’re interested in the details, as well as a little bit of further criticism of Telegram’s actual encryption protocols, I’ll get into what we know about that further below.)</p>



<h3>But wait, does default encryption really matter?</h3>



<p>Maybe yes, maybe no! There are two different ways to think about this.</p>



<p>One is that <em>Telegram’s lack of default encryption is just fine</em> <em>for many people</em>. The reality is that many users don’t choose Telegram for encrypted private messaging at all. For plenty of people, Telegram is used more like a social media network than a private messenger. </p>



<p>Getting more specific, Telegram has two popular features that makes it ideal for this use-case. One of those is the ability to create and subscribe to “<a href="https://telegram.org/tour/channels">channels</a>“, each of which works like a broadcast network where one person (or a small number of people) can push content out to millions of readers. When you’re <em>broadcasting</em> messages to thousands of strangers in public, maintaining the secrecy of your chat content isn’t as important. </p>



<p>Telegram also supports large public <a href="https://telegram.org/tour/groups">group chats</a> that can include thousands of users. These groups can be made open for the general public to join, or they can set up as invite-only. While I’ve never personally wanted to share a group chat with thousands of people, I’m told that many people enjoy this feature. In the large and <em>public</em> instantiation, it also doesn’t really matter that Telegram group chats are unencrypted — after all, who cares about confidentiality if you’re talking in the public square?</p>



<p>But Telegram is not limited to just those features, and many users who join for them will also do other things.</p>



<p>Imagine you’re in a “public square” having a large group conversation. In that setting there may be no expectation of strong privacy, and so end-to-end encryption doesn’t really matter to you. But let’s say that you and five friends step out of the square to have a side conversation. Does <em>that</em> conversation deserve strong privacy? It doesn’t really matter what you want, because <em>Telegram won’t provide it</em>, at least not with encryption that protects you from sharing your content with Telegram servers. </p>



<p>Similarly, imagine you use Telegram for its social media-like features, meaning that you mainly consume content rather than producing it. But one day your friend, who also uses Telegram for similar reasons, notices you’re on the platform and decides she wants to send you a private message. Are you concerned about privacy now? And are you each going to manually turn on the “Secret Chat” feature —&nbsp;even though it requires four explicit clicks through hidden menus, and even though it will prevent you from communicating immediately if one of you is offline?</p>



<p>My strong suspicion is that many people who join Telegram for its social media features also end up using it to communicate privately. And I think Telegram knows this, and tends to advertise itself as a “secure messenger” and talk about the platform’s encryption features precisely because they know it makes people feel more comfortable. But in practice, I also suspect that very few of those users are actually <em>using Telegram’s encryption</em>. Many of those users may not even realize they have to turn encryption on manually, and think they’re already using it. </p>



<p>Which brings me to my next point.</p>



<h3>Telegram knows its encryption is difficult to turn on, and they continue to promote their product as a secure messenger</h3>



<p>Telegram’s encryption has <a href="https://threadreaderapp.com/thread/1474067549574688768.html">been subject to</a> <a href="https://grugq.tumblr.com/post/133453305233/operational-telegram">heavy criticism</a> <a href="https://www.dailydot.com/debug/telegram-isis-encryption-cryptography/">since</a> <a href="https://cpj.org/2016/05/why-telegrams-security-flaws-may-put-irans-journal/">at least 2016</a> (and possibly earlier) for many of the reasons I outlined in this post. In fact, many of these criticisms were made by experts including myself, in years-old conversations with Pavel Durov on Twitter.<sup>1</sup></p>



<p>Although the interaction with Durov could sometimes be harsh, I still mostly assumed good faith from Telegram back in those days. I believed that Telegram was busy growing their network and that, in time, they would improve the quality and usability of the platform’s end-to-end encryption: for example, by activating it as a default, providing support for group chats, and making it possible to start encrypted chats with offline users. I assumed that while Telegram might be a follower rather than a leader, it would eventually reach feature parity with the encryption protocols offered by Signal and WhatsApp. Of course, a second possibility was that Telegram would abandon encryption entirely — and just focus on being a social media platform.</p>



<p>What’s actually happened is a lot more confusing to me.</p>



<p>Instead of improving the usability of Telegram’s end-to-end encryption, the owners of Telegram have more or less kept their encryption UX unchanged since 2016. While there have been a <a href="https://core.telegram.org/mtproto">few upgrades to the underlying encryption algorithms</a> used by the platform, the user-facing experience of Secret Chats in 2024 is almost identical to the one <a href="https://grugq.tumblr.com/post/133453305233/operational-telegram">you’d have seen eight years ago</a>. This, despite the fact that the number of Telegram users has grown by 7-9x during the same time period.</p>



<p>At the same time, Telegram CEO Pavel Durov has continued to aggressively market Telegram as a “secure messenger.” Most recently he <a href="https://www.theregister.com/2024/05/14/telegram_ceo_calls_out_rival/">issued a scathing criticism of</a> Signal and WhatsApp on his personal Telegram channel, implying that those systems were backdoored by the US government, and only Telegram’s independent encryption protocols were really trustworthy. </p>



<p>While this might be a reasonable nerd-argument if it was taking place between two platforms that both supported default end-to-end encryption, Telegram really has no legs to stand on in this particular discussion. Indeed, it no longer feels amusing to see the Telegram organization urge people away from default-encrypted messengers, while <em>refusing to implement essential features that would widely encrypt their own users’ messages</em>. In fact, it’s starting to feel a bit malicious.</p>



<h3>What about the boring encryption details? </h3>



<p>This is a cryptography blog and so I’d be remiss if I didn’t spend at least a little bit of time on the boring encryption protocols. I’d also be missing a good opportunity to <em>let my mouth gape open in amazement</em>, which is pretty much what happens every time I look at the internals of Telegram’s encryption. </p>



<p>I’m going to handle this in one paragraph to reduce the pain, and you can feel free to skip past it if you’re not interested.</p>



<p>According to <a href="https://core.telegram.org/api/end-to-end">what I <em>think</em> is the latest encryption spec</a>, Telegram’s Secret Chats feature is based on a custom feature called MTProto 2.0. This system uses 2048-bit* finite-field <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">Diffie-Hellman</a> key agreement, with group parameters (I think) chosen by the server.* (Since the Diffie-Hellman protocol is only executed interactively, this is why Secret Chats cannot be set up when one user is offline.*) MITM protection is handled by the end-users, who must compare key fingerprints. There are some weird random nonces provided by the server, which I don’t fully understands the purpose of* — and that <a href="https://words.filippo.io/dispatches/telegram-ecdh/">in the past used to actively make the key exchange totally insecure against a malicious server</a> (but this has long since been fixed.*) The resulting keys are then used to power the most amazing, <a href="https://eprint.iacr.org/2015/1177.pdf">non-standard</a> authenticated encryption mode ever invented, something called “<a href="https://core.telegram.org/api/end-to-end">Infinite Garble Extension</a>” (IGE) based on AES and with SHA2 handling authentication.*</p>



<p>NB: Every place I put a “*” in the paragraph above is a point where expert cryptographers would, in the context of something like a professional security audit, raise their hands and ask <em>a lot</em> of questions. I’m not going to go further than this. Suffice it to say that Telegram’s encryption is unusual. </p>



<h3>Is there anything else I should know?</h3>



<p>Yes, unfortunately. Even though end-to-end encryption is one of the best tools we’ve developed to prevent data compromise, it is hardly the end of the story. One of the biggest privacy problems in messaging is the availability of loads of meta-data — essentially data about who uses the service, who they talk to, and when they do that talking. </p>



<p>This data is not typically protected by end-to-end encryption. Even in applications that are broadcast-only, such as Telegram’s channels, there is plenty of useful metadata available about <em>who is listening to a broadcast.</em> That information alone is valuable to people, as evidenced by the enormous amounts of money that traditional broadcasters <a href="https://www.komando.com/news/security/stop-smart-tv-tracking/">spend to collect it</a>. Right now all of that information likely exists on Telegram’s servers, where it is available to anyone who wants to collect it.</p>



<p>I am not specifically calling out Telegram for this, since the same problem exists with virtually every other social media network and private messenger. But it should be mentioned, just to avoid leaving you with the conclusion that encryption is all we need. </p>



<p>Notes:</p>



<ol>
<li>I will never find all of these conversations again, thanks to Twitter search being so broken. If anyone can turn them up I’d appreciate it. </li>
</ol>
	</div><!-- .entry-content -->

			<!-- .entry-footer -->
	</article></div>]]></description>
        </item>
    </channel>
</rss>