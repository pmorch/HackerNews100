<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 11 Sep 2023 22:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[uBlock-Origin – 1.52.0 (133 pts)]]></title>
            <link>https://github.com/gorhill/uBlock/releases/tag/1.52.0</link>
            <guid>37472994</guid>
            <pubDate>Mon, 11 Sep 2023 20:13:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/gorhill/uBlock/releases/tag/1.52.0">https://github.com/gorhill/uBlock/releases/tag/1.52.0</a>, See on <a href="https://news.ycombinator.com/item?id=37472994">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:gorhill/uBlock" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="x8C6R9GJSwffziApgP8Nx1Hb5B4IUBkEuexf3bwqIz2-7Feg9FkhJtAX9lTquRZnH9DjGw5zPjEi5JI5gpqigg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="gorhill/uBlock" data-current-org="" data-current-owner="gorhill" data-logged-in="false">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Freleases%2Fshow&amp;source=header-repo&amp;source_repo=gorhill%2FuBlock" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/gorhill/uBlock/releases/tag/1.52.0&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="2f3c5dde8d1530c1097543858fcd6094e612f73a18c39160cb2954947a81a077" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/releases/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Blood pressure should be measured lying down: study (148 pts)]]></title>
            <link>https://newsroom.heart.org/news/high-blood-pressure-while-lying-down-linked-to-higher-risk-of-heart-health-complications</link>
            <guid>37471354</guid>
            <pubDate>Mon, 11 Sep 2023 18:20:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsroom.heart.org/news/high-blood-pressure-while-lying-down-linked-to-higher-risk-of-heart-health-complications">https://newsroom.heart.org/news/high-blood-pressure-while-lying-down-linked-to-higher-risk-of-heart-health-complications</a>, See on <a href="https://news.ycombinator.com/item?id=37471354">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body-container">
          <p>Research Highlights:</p>

<ul>
	<li>An analysis of data from a long-running study of more than 11,000 adults from four diverse communities in the United States has found that adults who had high blood pressure while both seated upright and lying supine (flat on their backs) had a higher risk of heart disease, stroke, heart failure or premature death compared to adults without high blood pressure while upright and supine.&nbsp;</li>
	<li>Adults who had high blood pressure while lying supine but not while seated upright had similar elevated risks of heart attack, stroke, heart failure or premature death as adults who had high blood pressure in both supine and upright positions.</li>
	<li>The increased risk of heart disease, stroke, heart failure or premature death did not differ by the type of blood pressure medication used among participants.</li>
</ul>

<p><strong>Embargoed until 6:30a.m. CT/7:30 a.m. ET Thursday, Sept. 7, 2023</strong></p>

<p>BOSTON, Sept. 7, 2023 — People who had high blood pressure while lying flat on their backs had a higher risk of heart attack, stroke, heart failure or premature death, according to new research to be presented at the American Heart Association’s <a href="https://professional.heart.org/en/meetings/hypertension" rel="" target="_blank" title="">Hypertension Scientific Sessions 2023</a>, to be held Sept. 7-10, 2023, in Boston. The meeting is the premier scientific exchange focused on recent advances in basic and clinical research on high blood pressure and its relationship to cardiac and kidney disease, stroke, obesity and genetics.</p>

<p>The autonomic nervous system regulates blood pressure in different body positions; however, gravity may cause blood to pool when seated or upright, and the body is sometimes unable to properly regulate blood pressure during lying, seated and standing positions, the authors noted.</p>

<p>“If blood pressure is only measured while people are seated upright, cardiovascular disease risk may be missed if not measured also while they are lying supine on their backs,” said lead study author Duc M. Giao, a researcher and a 4<sup>th</sup>-year M.D. student at Harvard Medical School in Boston.</p>

<p>To examine body position, blood pressure and heart health risk, the researchers examined health data for 11,369 adults from the longitudinal Atherosclerosis Risk in Communities (ARIC) study. The data on supine and seated blood pressure was gathered during the enrollment period, ARIC visit 1, which took place between 1987–1989. Participants had their blood pressure taken while briefly lying down at a clinic. The average age of participants at that time was 54 years old; 56% of the group self-identified as female; and 25% of participants self-identified as Black race. Participants in this analysis were followed for an average of 25 to 28 years, up through ARIC visit 5, which includes health data collected from 2011-2013.</p>

<p>The researcher’s findings included:</p>

<ul>
	<li>16% percent of participants who did not have high blood pressure — defined in this study as having top and bottom blood pressure measures greater than or equal to 130/80 mm Hg — while seated had high blood pressure while lying supine (flat on their backs), compared to 74% of those with seated high blood pressure who also had supine high blood pressure.</li>
	<li>In comparison to participants who did not have high blood pressure while seated and supine, participants who had high blood pressure while seated and supine had a 1.6 times higher risk of developing coronary heart disease; a 1.83 times higher risk of developing heart failure; a 1.86 times higher risk of stroke; a 1.43 times higher risk of overall premature death; and a 2.18 times higher risk of dying from coronary heart disease</li>
	<li>Participants who had high blood pressure while supine but not while seated had similar elevated risks as participants who had high blood pressure while both seated and supine.</li>
	<li>Differences in blood pressure medication use did not affect these elevated risks in either group.</li>
</ul>

<p>“Our findings suggest people with known risk factors for heart disease and stroke may benefit from having their blood pressure checked while lying flat on their backs,” Giao said.</p>

<p>“Efforts to manage blood pressure during daily life may help lower blood pressure while sleeping. Future research should compare supine blood pressure measurements in the clinic with overnight measurements.”</p>

<p>The study’s limitations included that it focused on adults who were middle-aged at the time of enrollment, meaning the results might not be as generalizable to older populations, Giao said.</p>

<p><strong>Note: Giao presents <em>Seated And Supine Blood Pressure And Risk Of Cardiovascular Disease And Mortality From The Atherosclerosis Risk In Communities Study </em>at 2:15 p.m. ET on Saturday, Sept. 9, 2023, Presentation #071; Abstract #452</strong></p>

<p>Background:</p>

<ul>
	<li>The Atherosclerosis Risk in Communities (ARIC) study is an ongoing, community-based cohort of 15,792 adults in the United States enrolled from 1987-1989 to investigate the causes for atherosclerotic disease (plaque or fatty buildup in the arteries). ARIC study participants were ages 45–65 years at the start of the study and from rural areas in the U.S. (Forsyth County, North Carolina, and Washington County, Maryland) and urban areas: Minneapolis and Jackson, Mississippi. The research and data from the ARIC clinical visits — including hospital record abstraction, ECG tracings, and physician and coroner questionnaires, as well as death certificate data — have led to discoveries and guidelines surrounding atherosclerosis, heart disease, kidney disease, diabetes, stroke and cognitive decline.</li>
	<li>The <a href="https://www.ahajournals.org/doi/full/10.1161/HYP.0000000000000065" target="_blank">2017 ACC/AHA Guideline for the Prevention, Detection, Evaluation, and Management of High Blood Pressure in Adults</a> classifies hypertension as having top and bottom numbers greater than or equal to 130/80 mm Hg, which was the definition of hypertension used in this study.</li>
</ul>

<p>Co-authors and their disclosures are listed in the abstract. The study was funded by the National Institutes of Health.</p>

<p>Statements and conclusions of studies that are presented at the American Heart Association’s scientific meetings are solely those of the study authors and do not necessarily reflect the Association’s policy or position. The Association makes no representation or guarantee as to their accuracy or reliability. The Association receives funding primarily from individuals; foundations and corporations (including pharmaceutical, device manufacturers and other companies) also make donations and fund specific Association programs and events. The Association has strict policies to prevent these relationships from influencing the science content. Revenues from pharmaceutical and biotech companies, device manufacturers and health insurance providers and the Association’s overall financial information are available <a href="https://www.heart.org/en/about-us/aha-financial-information">here</a>.</p>

<p><strong>Additional Resources:</strong></p>

<ul>
	<li>Available multimedia is on right column of release link&nbsp;<a href="https://newsroom.heart.org/news/high-blood-pressure-while-lying-down-linked-to-higher-risk-of-heart-health-complications?preview=3a007402d06b4cd7cbc3c53acb93b5f5" rel="" target="_blank" title="">https://newsroom.heart.org/news/high-blood-pressure-while-lying-down-linked-to-higher-risk-of-heart-health-complications?preview=3a007402d06b4cd7cbc3c53acb93b5f5</a></li>
	<li><a href="https://www.abstractsonline.com/pp8/?_ga=2.68132181.553845914.1693780001-1860925560.1690312372#!/10947" rel="" target="_blank" title="">Program abstracts online at embargo</a></li>
	<li>AHA news release: <a href="https://newsroom.heart.org/news/if-blood-pressure-rises-upon-standing-so-may-risk-for-heart-attack" target="_blank">If blood pressure rises upon standing, so may risk for heart attack</a> (March 2022)</li>
	<li>AHA&nbsp; news release: <a href="https://newsroom.heart.org/news/blood-pressure-rising-at-night-linked-to-doubling-risk-of-death-in-adults-with-diabetes" target="_blank">Blood pressure rising at night linked to doubling risk of death in adults with diabetes</a> (Sept. 2021)</li>
	<li>AHA news release: <a href="https://newsroom.heart.org/news/abnormal-blood-pressure-levels-while-sleeping-increase-risk-of-heart-disease-stroke" target="_blank">Abnormal blood pressure levels while sleeping increase risk of heart disease</a> (November 2020)</li>
	<li>Follow AHA/ASA news on X (formerly known as Twitter) <a href="https://twitter.com/HeartNews" target="_blank">@HeartNews</a> #Hypertension23</li>
</ul>

<p><strong>###</strong></p>

<p><strong>About the American Heart Association </strong></p>

<p>The American Heart Association is a relentless force for a world of longer, healthier lives. We are dedicated to ensuring equitable health in all communities. Through collaboration with numerous organizations, and powered by millions of volunteers, we fund innovative research, advocate for the public’s health and share lifesaving resources. The Dallas-based organization has been a leading source of health information for nearly a century. Connect with us on <a href="http://www.heart.org/en" target="_blank">heart.org</a>, <a href="http://facebook.com/AmericanHeart" target="_blank">Facebook</a>, <a href="https://twitter.com/American_Heart" rel="" target="_blank" title="">X</a>&nbsp;or by calling 1-800-AHA-USA1.</p>

<p><strong>For Media Inquiries and AHA Expert Perspective: </strong></p>

<p>AHA Communications &amp; Media Relations&nbsp;in Dallas: 214-706-1173; <a href="mailto:ahacommunications@heart.org">ahacommunications@heart.org</a></p>

<p>John Arnst: 214-706-1060; <a href="mailto:John.Arnst@heart.org">John.Arnst@heart.org</a></p>

<p>For Public Inquiries: 1-800-AHA-USA1 (242-8721)</p>

<p><a href="https://www.heart.org/en" target="_blank">heart.org</a> and <a href="https://www.stroke.org/en" target="_blank">stroke.org</a></p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In Germany, 27 are in 'preventive detention' b/c they might do climate protests (236 pts)]]></title>
            <link>https://mastodon.energy/@Sustainable2050/111039159882536261</link>
            <guid>37471048</guid>
            <pubDate>Mon, 11 Sep 2023 18:00:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.energy/@Sustainable2050/111039159882536261">https://mastodon.energy/@Sustainable2050/111039159882536261</a>, See on <a href="https://news.ycombinator.com/item?id=37471048">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Why did Visual Basic die? (186 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37470318</link>
            <guid>37470318</guid>
            <pubDate>Mon, 11 Sep 2023 17:12:56 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37470318">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="37471507"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37471507" href="https://news.ycombinator.com/vote?id=37471507&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Visual Basic (both of them) still exist, but their use has dropped dramatically through some big changes:<p>* "Visual .NET" (aka "Visual Fred" <a href="http://catb.org/jargon/html/V/Visual-Fred.html" rel="nofollow noreferrer">http://catb.org/jargon/html/V/Visual-Fred.html</a> ) was released by Microsoft. This was an incompatible language confusingly <i>also</i> called Visual Basic. I don't think Microsoft realized how angry this made developers and businesses, who were being asked to spend hundreds of billions of dollars (USD) to rewrite code just to keep the same functionality. Before that time, many thought that Visual Basic's wide use gave it a kind of "herd immunity". I don't have numbers with me, but I remember that years later that a study found that some were sticking to the original Visual Basic (even though it was no longer supported), a few had moved to Visual .NET, and many other had abandoned Visual Basic entirely (some to C#, others beyond). In short, the Visual Basic community was split into multiple communities, and anyone using Visual Basic would have to worry about either lack of support or yet another harmful change.</p><p>* The rise of the web and of platforms other than Windows (including Android, iOS, MacOS, Linux). Visual Basic is fine when you send files via sneakernet to another Windows user. Now people want to access through their web browser, smartphone, etc. If you have a website, anything can access it (as long as they have the permissions), and you don't have to worry about synchronizing data changes the way you do if people make changes on their local device. Most of the simple "fill in a form" kinds of applications that Visual Basic was used for are more sensibly web applications (server side or client side).</p><p>Visual Basic is still used. And yes, I think there could be better tools for developing software. But as best as I recall, that's how we ended up here.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472277"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472277" href="https://news.ycombinator.com/vote?id=37472277&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Visual Basic is one of the best arguments for open source and community ownership in the history of computing, IMO. Microsoft's decision to tank it was hugely painful for companies that had made major investments in it -- no company should make that kind of investment in a proprietary platform that can be killed off by a single company and not forked and maintained by others.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37472386"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472386" href="https://news.ycombinator.com/vote?id=37472386&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>As someone who was writing Visual Basic.NET back when it came out, there was no upside to it over writing in C#. VB's original sweet spot was for writing small scripts and apps in Windows, and it was the only language available. When the .NET line came out, you could do the same things in whichever language you wanted. When new tasks came in, I started defaulting to C# for that reason. I don't think anyone actually prefers VB syntax. C# has a pretty robust community around it now.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37472754"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472754" href="https://news.ycombinator.com/vote?id=37472754&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>&gt; When new tasks came in, I started defaulting to C# for that reason. I don't think anyone actually prefers VB syntax. C# has a pretty robust community around it now.<p>Which was your experience because you knew C. VB appealed to people who were not programmers (or not very good ones like me). Microsoft effectively tossed an easy to learn procedural language in the trash and said "go learn all these advanced CS concepts or stop writing stuff" to which most hardcore VB users chose the latter.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37472059"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472059" href="https://news.ycombinator.com/vote?id=37472059&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Lol, my first programming gig as a teenager was performing a VB6 -&gt; VB.NET "upgrade" of a 200K sloc legacy desktop application, which obviously ended up being a total rewrite. Everything in my career since then has seemed easy in comparison.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37472298"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472298" href="https://news.ycombinator.com/vote?id=37472298&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I was a hobby VB developer at this time and I abandoned it shortly after VB.net without really realizing why. I also abandoned Windows completely shortly thereafter.<p>The main thing that killed me was the size of the files that you had to distribute when you used VB.net. No one had the .net runtime early on and it was absolutely massive. I was paying for outgoing data by the gigabyte back then and our connections were much slower.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37472597"><td></td></tr>
            <tr id="37472322"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472322" href="https://news.ycombinator.com/vote?id=37472322&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Yeah, as someone who worked somewhere that had a VB6 project: VB.net was only at all useful as a stop gap between VB and C# and a barely useful one at that.<p>The language as it stands is fine and interop with .NET means it is a decent choice to use, outside of C# just having a bigger user base from a "how easy can I hire devs" standpoint.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37472377"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472377" href="https://news.ycombinator.com/vote?id=37472377&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Great points. And in a tongue in cheek way, having reactive components you can attach handlers to fetch / redraw you UI .. is still there, it's just labelled vue or react ;)</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37472779"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472779" href="https://news.ycombinator.com/vote?id=37472779&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span><i>Yet I can't help wondering what problems it had that caused them to abandon it?</i><p>Tech comes and goes, there’s nothing to vb specifically. As a language it’s pretty limited, tedious and quirky.</p><p><i>Moreover, why hasn't someone come out with a solid replacement?</i></p><p>Because webdev at its core is a community of stubborn smart guys who <i>love</i> the complexity and hate dull business code. They will present absurd arguments like I can do this and that, as if it couldn’t be packed into a vb component and drag-dropped onto a form from a palette without accompanying 1kloc boilerplate and pages of configuration documentation with no sane defaults. VB GUI model may be obsolete, gray and non-responsive, but no one prevents from building responsive interfaces wysiwyg way. My peer web designer does it without bothering with html/css much and it works for her for decades. All the tech is there, it’s just nobody’s collective interest to combine it into a business RAD instead of an intermediate haskell-level mindfuck starter kit. You can’t burn hundreds of millions doing actual work on a platform that everyone could start using solo in just a few days and deliver a working solution next week, even if raw and clumsy as it usually goes with non-pros.</p><p>I’d like to get a better and less bitter explanation, but there is none.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37472327"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472327" href="https://news.ycombinator.com/vote?id=37472327&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>The reason is even bigger than just VB.<p>MS at the time just decide to <i>fully</i> kill the "enthusiast" developer and the "single/truly small" team developer. This is mostly covered under the "RAD" umbrella.</p><p>It kills VB, FoxPro, and now more evidently, Access (more like let it slowly die).</p><p>.NET + Visual Studio + Sql Server are <i>not</i> a substitute in this market. Them are for "professional developer"/"a small cog in a big machine". The worst part is that this move somehow kill the other tools in this space (because somehow others follow suit or whatever) and without somebody leading the charge to see how adapt this tool for the web. MS not getting the Web, Borland doing Hara-kiri and others getting annihilated by "free" open source and all that not helps.</p><p>Ironically, this market have rebound in the myriad of tools like "low code, notebooks, etc" that fill (badly!) the gap.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472473"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472473" href="https://news.ycombinator.com/vote?id=37472473&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Serious question: what is a good alternative to Access? The database design tools and basic forms were incredibly easy to use, and there were very good tutorials for everything else. LibreOffice Base is different and not even close in comprehensiveness, and there seems to be nothing replacing it that isn't a super expensive SaaS.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37472653"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472653" href="https://news.ycombinator.com/vote?id=37472653&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>SQLite. It's not close in terms of ease-of-use of the GUI administration and forms, but as a single-server database solution to embed into a line-of-business app it's fantastic.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37472752"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37472752" href="https://news.ycombinator.com/vote?id=37472752&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>The GUI and forms is what made Access, though. Back in the day I actually made a system with Access that connected to a SQL Server database on the backend rather than Access's file-based engine.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37472728"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472728" href="https://news.ycombinator.com/vote?id=37472728&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Airtable is the closest I have found for ease of use - users that don’t know SQL can put together basic queries and views quickly.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37472748"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472748" href="https://news.ycombinator.com/vote?id=37472748&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Equally serious question: what is the use case for Access?<p>It's been installed on every corp workstation I've had and it's never been useful.  In my experience either Excel can do it or you need a real programming language/database.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37472621"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472621" href="https://news.ycombinator.com/vote?id=37472621&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>The parents point is that there is no alternative, because everyone left the market chasing Microsoft.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37472594"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472594" href="https://news.ycombinator.com/vote?id=37472594&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>For a long time I would have said FileMaker, but considering the strategic moves of Claris in the last few years probably not anymore</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37472615"><td></td></tr>
                        <tr id="37470603"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470603" href="https://news.ycombinator.com/vote?id=37470603&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Does VBA for Excel count? Because if it does then VBA for Excel has reached the"nuclear resistant cockroach" level in finance.<p>You wouldn't believe what sort of processes in very big banks/financial institutions are built using 10 year old VBA macros. In fact, VBA consulting for finance is a very juicy cottage industry at least in Europe to this very day.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37470877"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470877" href="https://news.ycombinator.com/vote?id=37470877&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Excel is literally 2D programming. Us mortal developers who can only put lines below one another are incapable of comprehending it, so we only get to ask the wise finance people how their enigma works.<p>On a serious note, I dread excel. If your PC is set to german, excel will translate the VBA keywords to german. But if you want to type them, you have to do that in english and then have excel translate them.</p><p>I don't want to accept that crap like this is the standard.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472516"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472516" href="https://news.ycombinator.com/vote?id=37472516&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>The 2D aspect is the part of Excel I don't understand.  Why does it have to be a grid?<p>It's great for laying out things meant to print, and making invoices and stuff... But why didn't we have code files and proper fixed layout DB-style tables as "pages" that can go in a workbook?</p><p>Maybe keeping everything as 2D as possible is a necessary compromise for the spatial thinkers out there, and they just wouldn't want it if it was full of boring linear stuff.</p><p>I love the reactivity and the concept that anywhere you put a value, you can put an =expression. But the 2D stuff seems like it's for the people who always have a sense of where things are in space.</p><p>They've done a good job of convincing people that it's not programming and they can do it, I can't really complain, because if Excel didn't exist we might all still have to use paper on a regular basis, or completely unstructured text files.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37471538"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37471538" href="https://news.ycombinator.com/vote?id=37471538&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>&gt; Us mortal developers who can only put lines below one another<p>At least my spaghetti code goes into one direction only...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37472328"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472328" href="https://news.ycombinator.com/vote?id=37472328&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>"2D programming" is normally called array programming, and it's common in scientific computing, ML, and finance. It does require a different mindset, kind of similar to SQL but not exactly. See APL, K, q, NumPy, matlab, Julia, and friends for languages that embrace this paradigm</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37472138"><td></td></tr>
            <tr id="37472216"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472216" href="https://news.ycombinator.com/vote?id=37472216&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>&gt; But if you want to type them, you have to do that in english and then have excel translate them.<p>Huh? At least in the versions I've used I've always needed to type the commands in German.</p><p>There's even an online German - English Excel dictionary...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37471107"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37471107" href="https://news.ycombinator.com/vote?id=37471107&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Healthcare and insurance too! I transform into some glorious magical elf when I volunteer to do the VBA tasks nobody else understands or can lower themselves to do.<p>You can make Excel do some real wacky stuff. I have a spreadsheet that actually calls out to exec() to run a curl POST on commandline and consume REST API endpoints, parse the results, and update the spreadsheet -- why on earth?? because the API was ready but the web app was delayed. I was the fix. :D
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37471164"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37471164" href="https://news.ycombinator.com/vote?id=37471164&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Pretty sure you can access a REST API from VBA without resorting to exec()</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37471214"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37471214" href="https://news.ycombinator.com/vote?id=37471214&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>It only works with toy examples and then stops working. For reasons unknown, as it should work.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37471459"><td></td></tr>
                              <tr id="37472447"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472447" href="https://news.ycombinator.com/vote?id=37472447&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Pre-face: I write a lot of VBA<p>VBA is kind of the result of people only - ONLY - wanting to use Excel for everything. I work with those people. They have mastered excel, but have little to zero interest in learning anything else, and would rather see the world be built around excel.</p><p>So you (like me) get tasked with building applications and forms in VBA.</p><p>I was STOKED when MS announced Python for excel, but alas, turned out to not be what I (and many other) wanted.</p><p>What's the medicine? Dunno, hire analysts that are more open to using other tools . Don't get me wrong, I love using excel for many tasks - but damnit, it's not the only tool.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37470889"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470889" href="https://news.ycombinator.com/vote?id=37470889&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I know of a restaurant franchisee with 170+ locations that uses a home grown ERP system built in VBA on top of Access by an accountant about 20 years ago.<p>I once had to update it to optimize (minimize) front-line staff working hours so the company didn't have to pay health insurance for those employees. A real nightmare of a task in more ways than one!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37471254"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37471254" href="https://news.ycombinator.com/vote?id=37471254&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>My first programming job in the 90s while I was still in college was building systems exactly like you describe (and they were as poorly built as you think hah). I worked for a small IT programming/consulting shop. We did small jobs like this in town in addition to installing networks, IVRs, etc... while working on larger software to sell (which is an entirely different/crazy story that involved burning CD demos and using a hand 'stomper' to label and then mail them out).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37472418"><td></td></tr>
                  <tr id="37470909"><td></td></tr>
                <tr id="37471364"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37471364" href="https://news.ycombinator.com/vote?id=37471364&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>I can confirm this: I know several mechanical engineers that do mission critical-type systems (think "power plants"), and they routinely use Excel VBA for calculations.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37471506"><td></td></tr>
                        <tr id="37472385"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472385" href="https://news.ycombinator.com/vote?id=37472385&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Before VBA for Excel, I wrote numerous macros, including ATAN2(x,y) before there was an ATAN2.<p>Afterwards, forget it. Maybe one.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37470767"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470767" href="https://news.ycombinator.com/vote?id=37470767&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>There is a book called: Professional Excel Development. If you want to get into it. You could probably use that book to build an OS in Excel. I'm not joking.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37471265"><td></td></tr>
                  <tr id="37472520"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472520" href="https://news.ycombinator.com/vote?id=37472520&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I used it as a coding layman in 15-buck-an-hour "admin" (clerk/secretary) roles to automate some processes that my predecessors had done by hand. Mostly just copying entries from a spreadsheet to company Excel/Powerpoint templates and printing them without killing myself copy/pasting or going into the save/print dialog 50 times. It did its work as something any old schmuck could harness to save themselves from carpal tunnel.<p>To that point, I imagine that there are a LOT of admin jobs (or, at least, a lot of tasks) that could be almost completely automated away. It's probably not even a capability issue, but one of job security on the employee side and a lack of *waves hands vaguely* on the employer side.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37470953"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470953" href="https://news.ycombinator.com/vote?id=37470953&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>So true!!! :D :D :D<p>If Excel stops working, financial institutions around the world would collapse.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37470812"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470812" href="https://news.ycombinator.com/vote?id=37470812&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I think for a lot of purposes, the internet kind of took over.<p>VB was great if you needed to do something limited to a single machine.</p><p>These days, we want data to be available across machines which requires using a network, and the default network is the internet.</p><p>If I'm going to be using the internet anyway, I can knock up something in HTML + JS + firebase/whatever data store, and have an application that works on any platform, and is accessible from anywhere in the world. You <i>might</i> need slightly more technical knowledge, but not so much that you can't have a simple CRUD app running in a day or so of work.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472722"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472722" href="https://news.ycombinator.com/vote?id=37472722&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span><i>You might need slightly more technical knowledge, but not so much that you can't have a simple CRUD app running in a day or so of work.</i><p>Well that’s quite a professional bubble you live in. Web dev is truly a frog in a boiling water.</p><p>If my VB/Delphi/Access/PIC buddy who made various apps and hardware back in the day asked me for a platform and I advised him to use what HN praises as “simple”, then pretty sure he’ll never contact me with it again.</p><p>I mean, yeah, <i>CRUD</i> is not hard to do by tutorial. But he will laugh at my CRUD explanation, because he never ever thought about <i>implementing</i> input &lt;&gt; data channels. It’s akin to positioning heads above a cylinder to fetch a database record.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37470920"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470920" href="https://news.ycombinator.com/vote?id=37470920&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I can write HTML/CSS/JS and a few back-end languages like PHP in my sleep but there's no way I could hand-code a web app as fast as I could a desktop app in 1997 using VB.<p>I would LOVE it if I could, though.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472214"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472214" href="https://news.ycombinator.com/vote?id=37472214&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Have you tried <a href="https://anvil.works/" rel="nofollow noreferrer">https://anvil.works</a>? (I'm a founder!)<p>It's quite explicitly VB-esque (only using Python), and having a single paradigm rather than stitching together several different programs speeds things up even for those who can write HTML/JS/CSS in their sleep. (And of course, you can drop out to JS/CSS/HTML if you want.) Overall I think the development speed is comparable to VB6.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472470"><td></td></tr>
                  <tr id="37472543"><td></td></tr>
            <tr id="37472104"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472104" href="https://news.ycombinator.com/vote?id=37472104&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Same. I’m very good at cranking out Tailwind + React UIs, but nothing touches the productivity I had with VB6 or even early C# and Winforms.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37471885"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37471885" href="https://news.ycombinator.com/vote?id=37471885&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I've never written VB, but I can bang out a React UI in jsxstyle like nobody's business.<p>You've piqued my curiosity.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472159"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37472159" href="https://news.ycombinator.com/vote?id=37472159&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Development in VB6 was basically dragging and dropping controls onto a window or dialog box, setting properties on them, and then filling in snippets of code to tie things together.<p>And "control" here means anything from simple labels and buttons up to database connections and embedded COM objects.</p><p>Literally anybody could bang out a simple Windows .exe like nobody's business.</p><p>It would have been really cool if Microsoft included it in the OS like they used to do with QBasic.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37472012"><td></td></tr>
                        <tr id="37471167"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37471167" href="https://news.ycombinator.com/vote?id=37471167&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Yep, this is the right answer. I was there, 23 years ago programming VB6, making apps that were wrapped up in InstallShield, burnt to a CD, and then mailed to our customers. We did do some web things with Apache and some C++ apps interfaced via CGI. But it seemed that overnight Java and Servlets came about and made CGI-bin obsolete and slow as molasses. Add in JSPs and Struts and you had fully functional web apps that were fast and scalable.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37472419"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472419" href="https://news.ycombinator.com/vote?id=37472419&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Does no-one remember VBScript and Active Server Pages (ASP). It was Visual basic as a server-side language, positioned to challenge PHP.<p>VB made it to the web :-)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472759"><td></td></tr>
                  <tr id="37472229"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472229" href="https://news.ycombinator.com/vote?id=37472229&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Yup, that was also my take. I used to write 'on box' and you communicated between components using Com+, and when you switched to http, there was no reason to stick with just VB6.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37470944"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470944" href="https://news.ycombinator.com/vote?id=37470944&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>&gt; VB was great if you needed to do something limited to a single machine.<p>VB6 used to work with oracle across network.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472555"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472555" href="https://news.ycombinator.com/vote?id=37472555&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Same here, we did a VB6 project that allowed the customer to chat with their remote mortgage advisor using a webcam, around '98.<p>The client was supposed to go to a local branch of the bank and then connect to the banks HQ.</p><p>I have also wondered why the software industry with the arrival of Internet went away from all these excellent tools. Not just VB6, but remember all the 4GL and model driven development tools. All gone and never really replaced.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37471108"><td></td></tr>
                <tr id="37472129"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37472129" href="https://news.ycombinator.com/vote?id=37472129&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>More common, in my experience, was the 2 tier app where a (very) fat client directly talked to the db, and all the businesses and data access logic was intermixed with UI event handlers and some stored procedures.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37471386"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37471386" href="https://news.ycombinator.com/vote?id=37471386&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Don't forget that VB.NET was a thing.  I worked on a web-based client management system that used VB.NET on the back-end.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37472245"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472245" href="https://news.ycombinator.com/vote?id=37472245&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>It still is a thing. VB.net is a CLR language just like C#. You can use a tool to translate from one to the other and back.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37471291"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37471291" href="https://news.ycombinator.com/vote?id=37471291&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I think the answer is: because Microsoft let it. I'm a big fan of modern .NET, but my biggest complaint is that Microsoft views, and always has, the CLR as the C# Language Runtime and not the Common Language Runtime.<p>For example, see the relationship between F# and C#. The CLR is constantly getting features that are only to support features in C#, leaving F# in a position where they either don't get the feature, can't add the feature, or begrudgingly add the feature to keep up compatibility with C#, which is something it does take seriously. But this has the effect of "dirtying up" the F# language by either adding features that don't really belong in the language or keeping features out.</p><p>The other thing is that C# consistently adds features to itself that are inspired by F#, since F# already implements these features on the CLR, thus showing their viability. So what happens is that C# continually approaches a more bloated language with a subset of it being a poor copy of F#. But then F# gets dragged along towards having a small subset of C# in it for compatibility purposes. So it's simultaneously making both languages worse.</p><p>Even the iron languages project that lead to IronPython, IronRuby, etc. was a bit of a Trojan horse to test out and exercise the CLR and .NET with no intention of ever providing long-term support for those projects. The DLR, which was implemented to support those, appears to be just maintained by a skeleton crew of people invested in it, probably by those interested in keeping IronPython up and running.</p><p>I do not understand why Microsoft takes this approach. It is myopic, shows a misunderstanding of their own technology in the CLR, and ultimately turns C# into another C++, leave dead languages and projects in the wake.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472399"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472399" href="https://news.ycombinator.com/vote?id=37472399&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>To be fair VB.net originally had dynamic capabilities that C# lacked so at least it possessed features that made its existence justifiable.<p>However the extreme changes required to go from VB6 -&gt; VB.net made it all kind of moot, might as well rewrite.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37472295"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472295" href="https://news.ycombinator.com/vote?id=37472295&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Interestingly enough there are a small handful of things VB.NET and C++/CLI can do which C# can't, which enable the former languages to have better interoperability with COM interfaces.<p>That was with .NET Framework and I'm not sure what the story is today with .NET Core aka .NET 5+.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472371"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37472371" href="https://news.ycombinator.com/vote?id=37472371&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>They eventually added optional names parameters which made the interop problem much better for C# compared to VB.<p>C# wasn't as good still but you no longer had to put earlier params at their default value (which is what made it unusable).</p><p>C++/CLI will probably remain king of interop though being a Frankenstein combination of the .NET runtime and C++.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472493"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37472493" href="https://news.ycombinator.com/vote?id=37472493&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>The other headache was indexed properties, but I don't think that's changed.<p>C++/CLI is no man's land and I tried my best to avoid it; and so far, I've managed; sometimes after-the-fact.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37471934"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37471934" href="https://news.ycombinator.com/vote?id=37471934&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>The F# situation is not comparable to VB.NET.<p>VB.NET was just C# semantics with a VB like syntax. From the beginning it didn't serve any purpose except to make VB Fans feel slightly more at home.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37472734"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472734" href="https://news.ycombinator.com/vote?id=37472734&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Related but off-topic:  Nothing I see today compares to the productivity that I saw with Lotus Notes, Dbase 3 and 4, Paradox, Microsoft Access, and a few other things from that era.  There are some really good SAAS offerings that target this space, but none of them seem as dominant as I would expect.  There was a time that if you wanted a simple application that could be covered with 3-4 tables and 5-6 views, any of the things I mentioned above could handle it.  You could explain the business problem and hand a developer a book on any of the above technologies and expect to have a working product a month later.  Today, this isn't really true.  It does seem we've gone backwards a bit...</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37470852"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470852" href="https://news.ycombinator.com/vote?id=37470852&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I used VB all the way from 1.0 to 6.0.<p>And when VB.NET came out came out in 2002, that was exactly when all the types of GUI-database projects VB6 was used for professionally, started being built in PHP/MySQL/HTML/CSS instead. The switch would have happened anyways, but the fact that VB.NET wasn't backwards-compatible made it really easy to switch since you were going to have to learn/build something new anyway -- otherwise there probably would have been a somewhat longer transition period. Microsoft really shot themselves in the foot (but the web benefited).</p><p>And then on the hobbyist/personal side, that's also basically when casual developers switched from building fun Windows apps to building fun websites.</p><p>So I'd mark it up entirely to web programming replacing it on both sides.</p><p>As for what a replacement might look like, Google had created App Maker (2016-2020) that got replaced by AppSheet (2020-present), which is the closest I've found for the drag-and-drop GUI/database aspect of VB6. But those have been very much geared towards business development, not kids learning programming. Maybe some parents here can chime in on what their kids are learning to program in?</p><p>[1] <a href="https://en.wikipedia.org/wiki/Google_App_Maker" rel="nofollow noreferrer">https://en.wikipedia.org/wiki/Google_App_Maker</a></p><p>[2] <a href="https://en.wikipedia.org/wiki/AppSheet" rel="nofollow noreferrer">https://en.wikipedia.org/wiki/AppSheet</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37471053"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37471053" href="https://news.ycombinator.com/vote?id=37471053&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Good explanation. Hobbiest switched. Because IIS and Asp.net run very well with VB.NET. but who could afford that compared to PHP.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37471209"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37471209" href="https://news.ycombinator.com/vote?id=37471209&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>The bigger pain point, from memory, was having an ODBC-compliant driver so the OS
 could actually talk to your DB. That basically meant MSSQL if you wanted to co-exist happily with early dotnet.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37470764"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470764" href="https://news.ycombinator.com/vote?id=37470764&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Microsoft accidentally killed it moving to .NET and the increasingly stupid GUI libraries they offered up.  Silverlight, 32 bit native, winforms etc and etc.<p>Web development meanwhile went bonkers and VB was a poor cousin to C# very suddenly.</p><p>Its a shame, VB was not for purists but it was very productive.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37471028"><td></td></tr>
                <tr id="37471366"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37471366" href="https://news.ycombinator.com/vote?id=37471366&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>I don't think they did. They said increasingly so. They're just getting at Microsoft continually re-inventing the wheel and then abandoning that wheel when it comes to their GUI libraries. There's WinForms -&gt; WPF -&gt; UDP -&gt; WinUI, Xamarin Forms -&gt; .NET MAUI, and then the evolution of Avalonia and Uno as third-parties trying to step in. And all of those options still exist! You literally have a minimum of 8 GUI options, at least on Windows. There are of course more by external parties.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37471978"><td></td></tr>
                        <tr id="37471790"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37471790" href="https://news.ycombinator.com/vote?id=37471790&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Agreed, .NET (well, C# specifically) was my go to for anything with a GUI until they tried moving on from Winforms/WPF and the way forward seemed to become a large undefined mess.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37471424"><td></td></tr>
                  <tr id="37472685"><td></td></tr>
            <tr id="37472598"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472598" href="https://news.ycombinator.com/vote?id=37472598&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Visual Basic was mostly used for LOB applications.  That stuff mostly migrated to the web.  When businesses decided to move those applications to the web, they had a choice between C# and VB.NET (if they stuck to the MS stack).  C# ultimately won.  Most of the old VB developers that are still around have converted over to being C# developers now.<p>When everything was a desktop app then the choice was C++ or VB and there were a lot of situations where VB "won".  Today C# does everything VB used to do but better on the desktop and non-performance sensitive applications are increasingly using Electron anyway.</p><p>Performance sensitive desktop app = C++
Windows focused non-performace sensitive desktop app = C#
Cross platform non-performace sensitive desktop app = JS/TS in Electron
Web app = anything but VB
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37472350"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472350" href="https://news.ycombinator.com/vote?id=37472350&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>The FOSS community could do SO much better if they wanted to, with reactive web tech, typescript instead of basic, a project file format that's easy to work with in Git, Android support, etc.<p>Despite all this talk about no-code, it seems like all we have now is like, a CMS that lets you embed Google maps, but if you want to do anything more you have to use code.</p><p>Maybe it's just that end users usually don't need to build anything anymore, there's almost always an professionally made app for everything.</p><p>I've tried many times to "Build the app you want to see in the world" and almost every time the result is I decide that living with and working around the imperfections of what's out there is more practical than building and maintaining anything by myself in hopes of the the very small chance people notice and it becomes A Thing.</p><p>Perhaps better dev tools like VB aimed at one off software like that could change the equation, and if the tools existed we'd all find uses for them?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472445"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472445" href="https://news.ycombinator.com/vote?id=37472445&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>&gt;  with reactive web tech, typescript<p>I very much doubt. Actually reactive frameworks such as react and languages that transpile in other languages such as trypescript are the reason they couldn't. These overcomplicated, seemingly well architected, tools are in fact just a fractal of poor design.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37472591"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472591" href="https://news.ycombinator.com/vote?id=37472591&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Not just VB, but also things like Borland Delphi.<p>25 years ago, you could visually compose a UI using standardized components, including advanced concepts like a layout manager. You could do data-binding visually by navigating a linked database. You can write logic/events just by double-clicking a button and the event is created. Here you'd write your code which would typically be pretty easy because all contextual objects are readily available.</p><p>Sure enough, I understand that the above development model also has its limitations and doesn't serve all common modern needs. But still, it's pretty pathetic what we ended up with. Our tool chains are much more complicated and we program at a lower abstraction level whilst requiring a laundry list of skills.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37471664"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37471664" href="https://news.ycombinator.com/vote?id=37471664&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>The web happened. VB was great for builing stand alone desktop applications, possibly with database integration. But they never managed to deliver a similar slick and self-contained solution for building web-based solutions. It didn’t help that the migration from vb6 to vb.net was too painful, but the root cause was the demand for business desktop apps disappeared.<p>The infamous WebForms API was supposed to bring the same gui builder paradigm to the web, but the developer experience was not as great.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37471277"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37471277" href="https://news.ycombinator.com/vote?id=37471277&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I started my career with VB/VBA/Access, but got burned by one of their non-backward compatible upgrades (I don't remember which versions) that derailed an important project.  This was around the time that Java was what the cool kids were using, and I was very amenable to trying open source after that experience, and I never looked back.<p>It was a great experience though, especially for a self-taught beginner long before code academies and YouTube.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37471948"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37471948" href="https://news.ycombinator.com/vote?id=37471948&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>People want more these days. With VB you could write a CRUD application that saved data to a database and ran some reports. But now people want the database to pull in multiple feeds from other businesses via API, people want it to be available on the web, it needs to have a self service component so the customer can also log in, at the back end the database is connected to several other systems with daily feeds coming in and out. Shit is just much more complicated these days.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37472586"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472586" href="https://news.ycombinator.com/vote?id=37472586&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>VB6 could do all these things and more, in the 90's I built just the right small parts in C++ to glue things together, and we could do multi-processing, resilient multi-server setups, and much much more. 
Serving HTTP for some always-limiting browser was an obvious easy sidenote, ie. what your mantra "available on the web" wraps in silver, but leveraging the full power of the desktop and OS was what power users actually wanted, and would still want now if the apps were there.
I think some people at Microsoft realized VB had the potential to canibalize a lot of what they wanted as their proprietary backyard, and they killed the baby before it would grow into more of a mass movement. 
Now they succeeded, many that would have been educated into owning their computers now mindlessly click on "Yes" and are lost in the adds panopticon, but then MS had to non-compete some of the pie off to Google and co...</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37472566"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472566" href="https://news.ycombinator.com/vote?id=37472566&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Microsoft effectively killed VB because they decided everyone should be using .NET. While they created VB .NET in an attempt to make the transition palatable to VB programmers, this was a second-class citizen of the CLR, and more importantly too different from VB, more akin to an inferior C# with VB-like syntax than actual VB. It was widely decried by VB developers [0], and nick-named "Visual Fred" due to really being a different language than VB. Microsoft ignored that, and also didn't bring a VB-like experience to .NET (maybe with the exception of WinForms, I'm not too familiar). It didn't help that mainstream software development started drifting to the web, and later to mobile apps.<p>[0] <a href="https://classicvb.net/vfred/breaks.asp" rel="nofollow noreferrer">https://classicvb.net/vfred/breaks.asp</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37470632"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470632" href="https://news.ycombinator.com/vote?id=37470632&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Are you talking about VB the language, or Visual Studio the IDE with its awesome GUI builder for WinForms (and not so awesome ones for the subsequent Windows GUI layers, forget what they're called).<p>VB is still around but desktop apps in general (and thus VS's GUI builder) largely gave way to web technologies invented outside Microsoft. The dev experience is definitely worse though. Visual Studio was sooooo nice and integrated.</p><p>I don't think this is really VB or NET's fault, Microsoft just kinda missed (or failed the fight against) the web transition. They were busy trying to make it coexist with Windows with seamless downloads like ClickOnce but ultimately simple web pages won out for their reach and ease of use, then mobile app stores came along, and now desktop apps are petty much dead except for niches.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37471390"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37471390" href="https://news.ycombinator.com/vote?id=37471390&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I remember, in some sense, Google (and also a group of anti Microsoft developers) encouraged web development as a strategy to break the Windows software monopoly.<p>So it's not that Microsoft missed it, it is that a big shift happened and it was specifically targeted against them. There's nothing they could have done, except to embrace it, and they did. Visual Basic Script existed and was very popular for a while. IE4 ruled the web.</p><p>The shift to web based technologies is a Google and an open source win. And it is also an inferior experience. That was the price we paid =)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37471522"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37471522" href="https://news.ycombinator.com/vote?id=37471522&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Even in the IE4 days, Microsoft was still very much "we'll only do as much web as necessary, but we can't lose our Windows fort... how can we sabotage this effort?". They were in full-on EEE mode[1] then and wanted to subvert, not join, the web. JScript, ActiveX, ClickOnce, IE's idiosyncracies, etc. were all Microsoft's own efforts to get around the webification of everything. They lost, not just because of Google but also Netscape, Mozilla/Phoenix, eBay, Craigslist, Amazon, Match, MapQuest, etc. Nobody wanted to build desktop apps anymore once they could effortlessly reach everyone via the web without having to be a Microsoft vassal.<p>Even ASP and IIS etc. insisted on having its own stack -- superior in some ways, but way less compatible and more expensive. Again their own doing. Free/cheap won out, I guess :)</p><p>[1] <a href="https://en.wikipedia.org/wiki/Embrace,_extend,_and_extinguish#Examples_by_Microsoft" rel="nofollow noreferrer">https://en.wikipedia.org/wiki/Embrace,_extend,_and_extinguis...</a></p><p>(edit: how the heck do you actually properly make hyperlinks on HN? I always struggle with this)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37470935"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470935" href="https://news.ycombinator.com/vote?id=37470935&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>&gt; web pages won out for their reach and ease of use,<p>Your definition of "ease of use" is amazing. /s
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37471078"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37471078" href="https://news.ycombinator.com/vote?id=37471078&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Heh, point taken. But I'd say overall it's easier for grandma to go to Gmail to check her email than have to figure out what this "Netscrape Communicator" is, install it, set up her "pop three" from her "eyesp" and then deal with a million viruses.<p>Yeah, the web ain't perfect, but it did win... ads got worse, though =/
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37470741"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470741" href="https://news.ycombinator.com/vote?id=37470741&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Visual Basic 6 was very productive - yes.  But it was considered by many to be a toy language (it didn't support class inheritance for one).<p>VB.NET - at least initial versions - was about productive as C#, thus there was no incentive to use VB.</p><p>The thing that made VB6 super productive was it's form designer.  The .NET successor - WinForms designer - wasn't nearly as fast and capable (to this day, really).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37472196"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472196" href="https://news.ycombinator.com/vote?id=37472196&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>From my perspective, Microsoft killed it.  It did not die on its own.  The upgrade path from VB6 to VB.NET was basically unusable.  You either stayed on VB6 or you rewrote the application.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37470684"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470684" href="https://news.ycombinator.com/vote?id=37470684&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>&gt;&gt; I have yet to find a tool that can allow me to be as productive in so short a time as Visual Basic.<p>For me: Delphi or Lazarus
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37472358"><td></td></tr>
                <tr id="37472474"><td></td></tr>
                  <tr id="37470688"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470688" href="https://news.ycombinator.com/vote?id=37470688&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>VB died because of .NET and VB.NET. The syntaxes were similar, but VB.NET was much closer to a "real programming language" in feeling and complexity than VB was, and that's not what anyone who used VB actually wanted.<p>Microsoft was more interested in developing .NET and C# to battle Java, and less interested in developing and promoting VB, their own successful and original product.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                      <tr id="37472465"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472465" href="https://news.ycombinator.com/vote?id=37472465&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>What made VB6 super-productive and quick to get up and running also made it terrible for long-term maintenance, because it hid too much of the details.<p>Then there were language warts like set versus let (strong vs weak pointers), for example, which was way above the paygrade of the average VB6 coders; and having to rely on the Win32 API anyway in order to start doing actual work and work around all of its limitaitons.</p><p>One thing VB6 did do right was forcing interface-based inheritance: Composition over class inheritance was seen as a weakness back then but it was proven as the right concept.</p><p>This is just my opinion!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37471131"><td></td></tr>
            <tr id="37471134"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37471134" href="https://news.ycombinator.com/vote?id=37471134&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span><i>&gt;nothing I have found compares to that development experience today. I would go so far as to say we've gone backwards in a big way.</i><p>I did Visual Basic 3.0 through VB 6.0 corporate development for a few years back in the 1990s.  The closest equivalent today for desktop apps <i>that still has Microsoft's focus on future innovation</i> is C# with Windows Forms.  (I downplay the "obvious" comparison of VB.NET to VB 6.0 because Microsoft already said they will "stop evolving" Visual Basic .NET -- so that's a technology dead end and will fall further and further behind the latest C# as the years go by.)</p><p>I personally don't experience that C#/Winforms has gone backwards from VB 6.0.  Workflow feels much the same as VB6:  Drag some GUI components like text boxes and buttons onto a form, code the controls' event handlers, build the exe.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37471178"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37471178" href="https://news.ycombinator.com/vote?id=37471178&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>I've only done a small amount of VB programming, but from what I remember of it, WinForms + C# is lightyears ahead of VB.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37470665"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470665" href="https://news.ycombinator.com/vote?id=37470665&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>It’s simple: Corporate internal app development (mostly CRUD stuff, as you’d expect) was the bread-and-butter of VB, and it moved wholesale to HTML &amp; JavaScript.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37472149"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472149" href="https://news.ycombinator.com/vote?id=37472149&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I recently wondered:<p>Why is there no VB-Like tool for building Electron - Apps using eg. React-Widgets &amp; Javascript as the scripting - language?</p><p>I'm not married to Electron vs. another similar, possibly more modern / less ressource hungry alternative; or another Frontend Framework.</p><p>But it seems to be it should be possible to do a VB-Style thing using these kinds of tools, Drag+Drop, and Javascript, most of the components should be available already...</p><p>And it could be a fun environment for prototyping, having fun, creating really bad games &amp; greeting card apps again like in the 90s/2000s etc etc.</p><p>It could be a fun learning environment for newbies while a powerful GUI builder for multiple platforms for experts..</p><p>Why isn't there such a thing? Would somebody please build this? :D
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37470873"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470873" href="https://news.ycombinator.com/vote?id=37470873&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>VB (and BASIC in general) has a legacy of being a procedural language. In the late 90’s and early 2000’s, there was a massive push to leverage object oriented programming and design. The births of Java in the 90’s and then C# in the 2000’s were clear catalysts to abandon procedural programming.<p>Of course in .NET VB has nearly all of the OO capabilities that C# has, but I think most developers just decided to go “all-in” on object oriented programming and learn C# and graduate from their procedural past.</p><p>A lot of colleges taught Java and moving to it or C# in the workplace was a much more natural process.</p><p>There are BASIC alternatives and they are fairly strong offerings, but I think OO and functional programming are the standard today.</p><p>That means python, Rust, Golang, Ruby, C#, and Java are the mainstream languages.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37470891"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470891" href="https://news.ycombinator.com/vote?id=37470891&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Honestly, I was never a fan of Basic but I still don't understand why there isn't a GUI app builder as productive as the VB6-era tools were for any language.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37470969"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37470969" href="https://news.ycombinator.com/vote?id=37470969&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Devs don’t design user interfaces anymore. There are separate disciplines for user experience, graphic design, front-end development, API development, and data storage choices.<p>There’s no reason to have a drag and drop UI builder anymore.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472436"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37472436" href="https://news.ycombinator.com/vote?id=37472436&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>not everything is a team effort, and the desire espoused all over this thread for an equivalency clearly demonstrates that there is a 'market' there.<p>when some small developer is making a silly one-off app for a mom&amp;pop local store to facilitate a one-off kind of task they aren't interested in handing off work and splitting meager profits. not every company has the whole "front-end/back-end/devops/ux/design/management" paradigm going on.</p><p>the reality is that microsoft , a fairly litigious group of people, abandoned a concept for their own reasons; and the rest of the market doesn't exactly know where they can step in that minefield of offering equivalent features to a piece of software that is still on life support by a very very large/valuable/litigious company.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="37470421"><td></td></tr>
                <tr id="37470493"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470493" href="https://news.ycombinator.com/vote?id=37470493&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>I think that’s the sense in which it died in that if you were going to switch to .NET you would probably also switch to C#.  The original VB had A GUI builder better than almost anything (even today!) but the UI builders in today’s visual studio support C# as well if not better than VB.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37470752"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37470752" href="https://news.ycombinator.com/vote?id=37470752&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>You bring up a good point, which is that I remember most the GUI builder.  Basic isn't really that great a language, all things considered.  But being able to quickly design and deploy GUI apps with VB was better than anything I've encountered since.<p>There are things like WebFlow and FlutterFlow but those tools feel clunky by comparison.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37470811"><td></td></tr>
                <tr id="37470924"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37470924" href="https://news.ycombinator.com/vote?id=37470924&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Netbeans java gui builder is the only builder I’ve seen come close to the vb gui builder. In fact I was a little disappointed moving from net beans to a “real Java ide” since their gui builders don’t exist or aren’t as good. But vb as a language is a lot better than Java for getting to a productive state for a novice.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37470710"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37470710" href="https://news.ycombinator.com/vote?id=37470710&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>And everything in that IDE was fast and super responsive. Today's IDE are more complex than ever and yet they lack in functionality that was present in VB6.0</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37470868"><td></td></tr>
                  <tr id="37470663"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37470663" href="https://news.ycombinator.com/vote?id=37470663&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>I once had a job offer from a big company that developed exclusively in VB.NET, after transitioning away from VB6. Both for desktop and web. So it's still out there.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37470985"><td></td></tr>
            <tr id="37470848"><td></td></tr>
                <tr id="37470992"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37470992" href="https://news.ycombinator.com/vote?id=37470992&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Well Basic evolved a lot. Comparing 80s Basic on whatever hardware you imagine (think goto + Line Numbers) to 90s Microsoft VisualBasic (think event Händlers for UIs) is a similar jump than VisualBasic to VisualBasic.NET (writing OO code).<p>VB.NET is the same but so much more evolved. Also the runtime below was switched (surely for the better).</p><p>However, like outlined in other comments: VB.NET is a OOP language which handles procedural/functional code as a subset while VB of the 90s was purely procedural.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37471812"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37471812" href="https://news.ycombinator.com/vote?id=37471812&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>With VB.NET, VB basically turned into C# with different syntax. I think a lot of people in that space might as well have been writing C#, so a lot of them switched. Then separately, perhaps almost simultaneously, the Microsoft ecosystem lost relevance.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37470442"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470442" href="https://news.ycombinator.com/vote?id=37470442&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>IMO, it didn't really make a smooth transition to the web. Webforms was the attempt but it was a leaky abstraction (iirc, it kept state for UI components but not variables so things got... weird) and kind of worked against the paradigms at the time (everything was a POST).</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37470795"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470795" href="https://news.ycombinator.com/vote?id=37470795&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>Yeah exactly, VB dying is sort of the CONVERSE of programmers adopting platforms, not languages - <a href="https://old.reddit.com/r/ProgrammingLanguages/comments/sk6w1c/programming_languages_as_biological_strategies/hvkxp4n/" rel="nofollow noreferrer">https://old.reddit.com/r/ProgrammingLanguages/comments/sk6w1...</a><p>- Why is JS popular?  Not because it's the best language, but because it's attached to the browser, and people want to deploy apps to browsers (Figma, etc.)</p><p>- Why is shell the 8th most popular language on Github, and the 6th fastest growing? [1]  Not because it's the best language, but because it's attached to the Unix kernel (specifically Linux, which has a ton of features).  Software in containers and virtual machines must talk to kernels.</p><p>So then the converse is</p><p>- Why is VB no longer popular?  Not because it's a worse language than it used to be (though maybe that's true), but the platform that it supported isn't as popular.</p><p>Like others said, it's probably popular for Excel and app automation, etc.  But today more apps are targeting web and mobile, not Windows desktop.</p><p>- Same answer with  Objective C and Swift -- people are using them to write apps for a platform.  And Kotlin/Android, etc.</p><p>[1] <a href="https://octoverse.github.com/2022/top-programming-languages" rel="nofollow noreferrer">https://octoverse.github.com/2022/top-programming-languages</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37472264"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472264" href="https://news.ycombinator.com/vote?id=37472264&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I used VB 3.0 thru VB 6.0 and I echo the sentiment: those were fun and productive times.  Really solid integrated development environment centered around the desktop UI / form design / UI controls like buttons, textboxes, combo boxes, etc.<p>I also agree that the web changed everything and that is the major reason for the shift away.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37472501"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472501" href="https://news.ycombinator.com/vote?id=37472501&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Popularity of a language is like a popularity of a soda - it's never about the inherent quality or features, but always about the company that stands behind it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37472369"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472369" href="https://news.ycombinator.com/vote?id=37472369&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>I just recently wanted to spin up a simple CRUD UI over a simple DB schema and also thought of Visual Basic for the first time.  It seems so well suited to something like building operational tooling for the endless parade of internal APIs.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37472093"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472093" href="https://news.ycombinator.com/vote?id=37472093&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>&gt; despite all the advances in technology since then, nothing I have found compares to that development experience today<p>You are going to have to qualify this a lot more, because it is absolutely not true. Coding VB was...fine. Language features were primitive, even compared to what was available in the mainstream back then. The tooling was fully proprietary and expensive. Languages and IDEs today are 1000x better in every way.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37472260"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472260" href="https://news.ycombinator.com/vote?id=37472260&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>It's the Python of yesteryear. Nothing about the language was great but the ecosystem was amazing.<p>CRUD app creation was almost completely point and click, VBA was easy and you could take data straight from a document and process it in complex ways, the database integrations were great and easy to use.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37472224"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472224" href="https://news.ycombinator.com/vote?id=37472224&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Honestly it's because Microsoft sucked at marketing. There were so many confusing name choices and unclear development guidelines that people simply stopped using it. Even now developing for windows is a pain and that's because there is like 5 different ways to build an app there.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37471824"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37471824" href="https://news.ycombinator.com/vote?id=37471824&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>You're probably speaking to VB plus Visual Studio RAD (Rapid Application Development aka "drag and drop" GUI programming) and you more or less still have that today with VB.NET and Windows Forms, with minor differences.<p>What killed the older VB6 and it's APIs, whose name I can't recall even though I developed for it in the 1990s, was .net coming along.</p><p>Be warned, it might just be easier to learn C# as it's more well-supported/documented, and VB.net seems like effectively a language dialect of C#.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37472421"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472421" href="https://news.ycombinator.com/vote?id=37472421&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Because you could only use it if you paid for it. If they had released it for free, as in beer, lots of people would have made wi does apps with it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37470966"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470966" href="https://news.ycombinator.com/vote?id=37470966&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>vb didn't die, it evolved into vb.net, but the market place has shifted to C# for the most part.<p>What has died, is the maturity of microsofts tool set, they keep changing their concept/design/platform.</p><p>silverlight/wpf/uwp/winui2|3/etc..</p><p>vb was around for nearly 2 decades and had a very mature tool set, everything since then hasn't gotten nearly that sort of life span or dedication to tool sets.</p><p>Developing in visual studio now, is more like web dev in the 2000s, I can't tell you how often you have to go to the xaml and make correction or adjustments that the UI just can't get right, or just goes bonkers and can't render the UI at all until something is fixed.</p><p>It is really sad, because the power of those old drag and drop builders that just worked meant that prototyping and mocking up applications was much much faster.</p><p>now standing up a UI based project takes ages, I'll usually do a console application now, and are dumping results to a API or console.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37471206"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37471206" href="https://news.ycombinator.com/vote?id=37471206&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>People always worry that Microsoft is silverlighting (that is a verb now) MAUI. I think that would be the end of VisualStudio. The word Visual had a meaning. When they would give up MAUI in favor of React Native (like Office) or Blazor (like the popular opinion), why the hack someone would buy a VS license. And when the think they could again commercialize .NET itself, then .NET would be dead. Modern Java, Flutter and TypeScript would easily swallow their market shares. MAUI, Blazor and .NET are an awesome set of products if they would just put some more concentration in MAUI.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37472396"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472396" href="https://news.ycombinator.com/vote?id=37472396&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>The development paradigm was great. I wish three were something similar for Python, having to switch to TCL/TK for UI stuff is extremely annoying.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37470692"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470692" href="https://news.ycombinator.com/vote?id=37470692&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I wonder the same thing about Apple's HyperCard. I used HyperCard a ton at school and side-projects. Visual Basic was a firmer and better step-up from that imho, less so as VBScript when it came to browsers.<p>As per other comments VBA is alive and well and I did many consulting gigs using that in Ireland in the late 1990s. I hope, in the name of all that is holy, that code isn't running still.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37470763"><td></td></tr>
            <tr id="37470719"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470719" href="https://news.ycombinator.com/vote?id=37470719&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>I wonder about HyperCard as well.  I never used it but, from everything I've ever heard about it, it was also an amazing developer experience.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37470776"><td></td></tr>
                        <tr id="37470872"><td></td></tr>
            <tr id="37472092"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472092" href="https://news.ycombinator.com/vote?id=37472092&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>I started my career with FoxPro for DOS, dabbled a bit with Visual FoxPro and then I found Visual Basic. Spent a lot of fun years with it before moving to ASP and web development in general. Not exactly sure what was the reason for its demise. I guess .NET killed it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37472720"><td></td></tr>
            <tr id="37470777"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470777" href="https://news.ycombinator.com/vote?id=37470777&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>There's still no better GUI toolkit out there than VB6 that I have used. It was amazing.<p>Problem is a lot of apps that would have been traditional LOB apps written in VB/C# have moved to the web so demand isn't there's clear advantages to C# as a language over VB.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37470858"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470858" href="https://news.ycombinator.com/vote?id=37470858&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Netbeans Java Swing GUI builder is far better. That's without factoring in the enormous third party component landscape that is available.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37471325"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37471325" href="https://news.ycombinator.com/vote?id=37471325&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Oh man, I remember building GUI apps with it in college.  My professor only let me use it on the condition that I could fully explain what every component was doing.  I could.  I took the generated swing code and added a <i>massive</i> amount of comments, but even having to do that I was still an order of magnitude faster than every other CS student without.  A lot of my peers were super jealous that I had so much free time, but they weren't willing to invest time in their tools (gdb, perl, regex, sql, etc).  It was quite the force multiplier.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37472378"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472378" href="https://news.ycombinator.com/vote?id=37472378&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>I was a VB6 developer in the 1990s, and I actually wrote a pretty well known product with it (I bet most people didn't know it was VB6 underneath!).<p>When I got my first job in software engineering, it was when .Net was in beta.  Since I only knew VB, I chose to go with VB.Net and Windows Forms.</p><p>Well, that was quite a jarring introduction to actual object oriented programming!</p><p>This is the point when a lot of people surrendered.  The change was too much, there was no path forward for VB, and Microsoft wanted everyone on .Net.</p><p>I eventually switched to C# and we had a hybrid application for a while before it was all ported to C#.  It actually went on to become industry leading software in its space.</p><p>20+ years later, that doesn't seem to have been a bad choice.  Windows Forms is very simple, with a powerful drag-and-drop designer, double-click to hook up events, it's all very similar.  Yes, you have to understand object oriented programming much more than you would have under VB, but that's as close as you are going to get from Microsoft on the desktop.  They try to hide it as best they can.</p><p>I <i>still</i> use Windows Forms if I need to put together something that "just works" on Windows as a desktop app quickly.  It's unmatched for that.</p><p>There are newer technologies, such as WPF, WinUI3, Avalonia and others for .Net but they come with a complexity that would be above your typical use-case for VB6 back in the day.  The VB6 user who just wanted to get stuff done probably doesn't want to have to understand how to implement the MVVM pattern just to get a UI.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37470978"><td></td></tr>
            <tr id="37471197"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37471197" href="https://news.ycombinator.com/vote?id=37471197&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>The web is cross-platform and easier to deploy. The (non-?)existence of RAD tools for it vs VB pales in comparison to that advantage.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37470940"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470940" href="https://news.ycombinator.com/vote?id=37470940&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>We had plenty of amazing paradigms/development environments/holistic experiences which we've regressed from:<p>- LISP environments</p><p>- Smalltalk environments</p><p>- Symbolics genera</p><p>- Mesa and Cedar</p><p>- Apple's Newton</p><p>Besides things like Oberon...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37471828"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37471828" href="https://news.ycombinator.com/vote?id=37471828&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>New version of VB was VB.net.<p>People still used VB.net primarily as they were familiar with VB.</p><p>But the new projects gradually took over C#.net, as it sounded more cool.</p><p>VB.net died after a while.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37471717"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37471717" href="https://news.ycombinator.com/vote?id=37471717&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>How about some love for Quick BASIC? That was my big Christmas present once upon a time when the dinosaurs still roamed the earth.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37472167"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37472167" href="https://news.ycombinator.com/vote?id=37472167&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>Oh you spoiled little children with your integrated development environment and in place editing. Real programmers used GW-Basic with consecutive line numbers.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37472287"><td></td></tr>
            <tr id="37470729"><td></td></tr>
                <tr id="37470922"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470922" href="https://news.ycombinator.com/vote?id=37470922&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>How many incompatible languages called VB-something did Microsoft create? There's at least the classic Visual Basic, VBA, VBScript, and VB.NET.<p>Although to be fair, the distinction between the language and libraries has never been very clear in BASIC variants.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37471884"><td></td></tr>
                <tr id="37472155"><td></td></tr>
                  <tr id="37471150"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37471150" href="https://news.ycombinator.com/vote?id=37471150&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>While I was never a big fan of VB, I agree that the developer experience has been getting worse for most languages since the early 1990s.<p>Do you have a top 3 list of things you miss?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37471958"><td></td></tr>
            <tr id="37471439"><td></td></tr>
            <tr id="37471938"><td></td></tr>
            <tr id="37470717"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470717" href="https://news.ycombinator.com/vote?id=37470717&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>My personal reason, which is probably unique:<p>VB 1.0 was extremely buggy, making it unusable for my use cases.</p><p>VB 1.1, which fixed the bugs I was encountering, was a paid upgrade.</p><p>I switched to Linux and never looked back.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37470644"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470644" href="https://news.ycombinator.com/vote?id=37470644&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>I got the feeling that a lot of the corp/small business apps that used to be developed in VB and deployed to PCs have been replaced by Web-based apps.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37471070"><td></td></tr>
                <tr id="37471317"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37471317" href="https://news.ycombinator.com/vote?id=37471317&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>VB was first released in 1991. If you're certain that you remember it from the late 80's, then you may be thinking of QBASIC. I first learned to write code in QBASIC running on MS-DOS.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37471083"><td></td></tr>
            <tr id="37470859"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470859" href="https://news.ycombinator.com/vote?id=37470859&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>DotNet is meant to be the replacement.  The big problem though is that MS keeps failing to make a GUI framework that is quick-and-easy as VB forms were.  Winforms still exists, and it's only a <i>bit</i> clumsier than VB forms, but it's very old and not modern.  The more modern .NET gui-frameworks are much less user-friendly.<p>Linguistically, I think the successor to VB is Powershell.  It's the same mashup of inconsistent flags that let you swap between "this is a serious language" and "I'm smashing crap together" with tons of unexpected weird behavior, but instead of being a quick-and-dirty GUI app maker, it's a Shell.  Hardcore focus on being easy and productive but unforgivably warty.</p><p>As for VB itself, VB.Net just didn't offer much value distinct from C#, so most people who were coding in VB switched to C#.</p><p>So if you're an old longbearded MS LOB programmer who started before .NET, and you're still working in Microsoft LOB shops, you're probably doing similar stuff but with C#.  But realistically, you've probably also switched to Web.</p><p>And the lack of the VB-level ease-of-use in <i>web</i> technologies is a whole other story.  All the hoary mess of using a document-engine for a cross-platform application server makes it pretty untameable.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37470656"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470656" href="https://news.ycombinator.com/vote?id=37470656&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>VB6 morphed into VB.Net but then the web took over and anything that could be accomplished as a desktop app was replaced by a web page.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37472097"><td></td></tr>
            <tr id="37470372"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37470372" href="https://news.ycombinator.com/vote?id=37470372&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>There's still Visual Basic .NET, is it much different productivity wise? I assume the language has changed enough from classic VB.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37470403"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37470403" href="https://news.ycombinator.com/vote?id=37470403&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><br><div>
                  <p><span>I honestly haven't used it because I thought they had retired it altogether.  The last time I did use it was about 20 years ago and found that they had changed it enough that I wasn't nearly as productive with it as, say, VB6.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37470474"><td></td></tr>
                        <tr id="37472294"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37472294" href="https://news.ycombinator.com/vote?id=37472294&amp;how=up&amp;goto=item%3Fid%3D37470318"></a></center>    </td><td><p><span>&gt;"nothing I have found compares to that development experience today. I would go so far as to say we've gone backwards in a big way"<p>&gt;"I have yet to find a tool that can allow me to be as productive in so short a time as Visual Basic"</p><p>I have and do program in many languages. From my perspective - for type the of applications usually done in VB Delphi / Lazarus would run circles around it. Both productivity and performance wise. It is also possible to do things one simply can not accomplish in VB.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37471211"><td></td></tr>
                <tr id="37472193"><td></td></tr>
                  <tr id="37472114"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Calculate the difference and intersection of any two regexes (175 pts)]]></title>
            <link>http://phylactery.org/antimirov/</link>
            <guid>37470285</guid>
            <pubDate>Mon, 11 Sep 2023 17:10:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://phylactery.org/antimirov/">http://phylactery.org/antimirov/</a>, See on <a href="https://news.ycombinator.com/item?id=37470285">Hacker News</a></p>
<div id="readability-page-1" class="page">
<pre><h2>enter some regular expressions!</h2>
<b>α</b> := 
<b>β</b> := 
<hr>
<b>   ~α</b> = <span id="not-alpha">ϕ</span>
<b>   ~β</b> = <span id="not-beta">ϕ</span>
<b>α &lt; β</b> = <span id="alpha-lt-beta">false</span>
<b>α = β</b> = <span id="alpha-eq-beta">true</span>
<b>α &gt; β</b> = <span id="alpha-gt-beta">false</span>
<b>α &amp; β</b> = <span id="alpha-and-beta">.*</span>
<b>α ^ β</b> = <span id="alpha-xor-beta">ϕ</span>
<b>α - β</b> = <span id="alpha-minus-beta">ϕ</span>
<hr>
<b>s</b> := 

<b>s ∈ α</b> = <span id="str-in-alpha">true</span>
<b>s ∈ β</b> = <span id="str-in-beta">true</span>
<hr>
<b>|α|</b> = <span id="alpha-card">0</span>
<b>|β|</b> = <span id="beta-card">0</span>
<hr>
<b>dfa(α)</b> has <span id="alpha-dfa">0</span> states

<b>dfa(β)</b> has <span id="beta-dfa">0</span> states

<hr>
<b>regex syntax</b>

  <b>.</b>         match any single character
  <b>xy</b>        concatenation: match <b>x</b> and then <b>y</b>
  <b>x|y</b>       alternation: match <b>x</b> or <b>y</b>
  <b>x*</b>        kleene star: match <b>x</b> zero-or-more times
  <b>(xyz)</b>     grouping: treat <b>xyz</b> as a single item (e.g. <b>(xyz)*</b>)
  <b>()</b>        an empty regex matches the empty string
  <b>x+</b>        kleene plus: match <b>x</b> one-or-more times (equivalent to <b>xx*</b>)
  <b>x?</b>        optional: optionally match <b>x</b> (equivalent to <b>(x|)</b>)
  <b>x{n}</b>      exponentiation: concatenate <b>x</b> to itself <b>n</b> times
  <b>x{m,n}</b>    repetition: concatenate <b>x</b> to itself between <b>m</b> and <b>n</b> times
  <b>[a-z0-9]</b>  grouping: match any single character in the group
  <b>[^a-z0-9]</b> negative grouping: match any single character <b>not</b> in the group
  <b>\c</b>        escaping: match the special character <b>c</b>
  <b>\u001a</b>    unicode escaping: match the corresponding UTF-16 character
  a, b, c   all other characters match themselves

<b>unsupported features</b>

  - anchors (e.g. <b>^</b>, <b>$</b>), <i>although <b>^</b> and <b>$</b> must still be escaped!</i>
  - zero-width assertions (e.g. <b>(?=...)</b>, <b>(?&lt;=...)</b>)
  - back references (e.g. <b>\1</b>, <b>\2</b>)
  - subgroup extraction
  - searching or partial matching
  - other flags that change behavior (e.g. case-insensitivity)

see <a href="https://github.com/non/antimirov">https://github.com/non/antimirov</a> for more information

by <a href="http://plastic-idolatry.com/erik/">eiríkr åsheim</a> (@d6 on <a href="https://twitter.com/d6">twitter</a> and <a href="https://mastodon.social/@d6">mastodon</a>)

    </pre>

    
    
    

    

    

    <!-- <script type="text/javascript" src="antimirov-web-fastopt.js"></script> -->

  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[WiFi can read through walls (143 pts)]]></title>
            <link>https://news.ucsb.edu/2023/021198/wifi-can-read-through-walls</link>
            <guid>37469920</guid>
            <pubDate>Mon, 11 Sep 2023 16:45:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.ucsb.edu/2023/021198/wifi-can-read-through-walls">https://news.ucsb.edu/2023/021198/wifi-can-read-through-walls</a>, See on <a href="https://news.ycombinator.com/item?id=37469920">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-history-node-id="21198">
      

    
                    <div><p><span><span><span><span lang="EN" xml:lang="EN"><span><span>Researchers in UC Santa Barbara professor Yasamin Mostofi’s lab have proposed a new foundation that can enable high-quality imaging of still objects with only WiFi signals. Their method uses the Geometrical Theory of Diffraction and the corresponding Keller cones to trace edges of the objects. The technique has also enabled, for the first time, imaging, or reading, the English alphabet through walls with WiFi, a task deemed too difficult for WiFi due to the complex details of the letters.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span></span></span></span></p>
<p><span><span><span><span lang="EN" xml:lang="EN"><span><span>For more details on this technology, check their video at <span><a href="https://www.youtube.com/watch?v=pvqL3gqGDeM">https://www.youtube.com/watch?v=pvqL3gqGDeM</a></span></span></span></span></span></span></span></p>
<p><span><span><span><span lang="EN" xml:lang="EN"><span><span><span>“Imaging still scenery with WiFi is considerably challenging due to the lack of motion,” said Mostofi, a professor of electrical and computer engineering. “We have then taken a completely different approach to tackle this challenging problem by focusing on tracing the edges of the objects instead.”&nbsp; The proposed methodology and experimental results appeared in the Proceedings of the 2023 IEEE </span></span></span></span><span lang="EN" xml:lang="EN"><span><span><span>National Conference on Radar</span></span></span></span><span lang="EN" xml:lang="EN"><span><span><span> (RadarConf) on June 21, 2023.</span></span></span></span></span></span></span></p>
</div>

                  

                  <div><p><span><span><span><span lang="EN" xml:lang="EN"><span><span>This innovation builds on previous work in the Mostofi Lab, which since 2009 has pioneered sensing with everyday radio frequency signals such as WiFi for several different applications, including crowd analytics, person identification, smart health and smart spaces. </span></span></span></span></span></span></p>
<p><span><span><span><span lang="EN" xml:lang="EN"><span><span>“When a given wave is incident on an edge point, a cone of outgoing rays emerges according to the Keller’s Geometrical Theory of Diffraction (GTD), referred to as a Keller cone,” Mostofi explained. The researchers note that this interaction is not limited to visibly sharp edges but applies to a broader set of surfaces with a small enough curvature.</span></span></span></span></span></span></p>
<p><span lang="EN" xml:lang="EN"><span><span>“Depending on the edge orientation, the cone then leaves different footprints (i.e., conic sections) on a given receiver grid. We then develop a mathematical framework that uses these conic footprints as signatures to infer the orientation of the edges, thus creating an edge map of the scene,”&nbsp; Mostofi continued. </span></span></span></p>
</div>

                  <div><p><span><span><span><span lang="EN" xml:lang="EN"><span><span>More specifically, the team proposed a Keller cone-based imaging projection kernel. This kernel is implicitly a function of the edge orientations, a relationship that is then exploited to infer the existence/orientation of the edges via hypothesis testing over a small set of possible edge orientations. In other words, if existence of an edge is determined, the edge orientation that best matches the resulting Keller cone-based signature is chosen for a given point that they are interested in imaging. </span></span></span></span></span></span></p>
<p><span><span><span><span lang="EN" xml:lang="EN"><span><span>“Edges of real-life objects have local dependencies,” said Anurag Pallaprolu, the lead Ph.D. student on the project. “Thus, once we find the high-confidence edge points via the proposed imaging kernel, we then propagate their information to the rest of the points using Bayesian information propagation. This step can further help improve the image, since some of the edges may be in a blind region, or <span>can be </span>overpowered by other edges that are closer to the transmitters.” Finally, once an image is formed, the researchers can further improve the image by using image completion tools from the area of vision.</span></span></span></span></span></span></p>
<p><span><span><span><span lang="EN" xml:lang="EN"><span><span><span>“It is worth noting that traditional imaging techniques result in poor imaging quality when deployed with commodity WiFi transceivers,” added Pallaprolu, “as the surfaces can appear near-specular at lower frequencies, thus not leaving enough signature on the receiver grid.” &nbsp;</span></span></span></span></span></span></span></p>
<p><span><span><span><span lang="EN" xml:lang="EN"><span><span><span>The researchers have also extensively studied the impact of several different parameters, such as curvature of a surface, edge orientation, distance to the receiver grid, and transmitter location on the Keller cones and their proposed edge-based imaging system, thereby developing a foundation for a methodical imaging system design. </span></span></span></span></span></span></span></p>
</div>

                  <div><p><span><span><span><span lang="EN" xml:lang="EN"><span><span><span>In the team’s experiments, three off-the-shelf WiFi transmitters send wireless waves in the area. WiFi receivers are then mounted on an unmanned vehicle that emulates a WiFi receiver grid as it moves.&nbsp; The receiver measures the received signal power which it then uses for imaging, based on the proposed methodology. </span></span></span></span></span></span></span></p>
<p><span lang="EN" xml:lang="EN"><span><span><span>The researchers have extensively tested this technology with several experiments in three different areas, including through-wall scenarios. In one example application, they developed a WiFi Reader to showcase the capabilities of the proposed pipeline. </span></span></span></span></p>
</div>

                  <div><p><span><span><span><span lang="EN" xml:lang="EN"><span><span><span>This application is particularly informative as the English alphabet presents complex details which can be used to test the performance of the imaging system. Along this line, the group has shown how they can successfully image several alphabet-shaped objects. In addition to imaging, they can further classify the letters. Finally, they have shown how their approach enables WiFi to image and read through walls by imaging the details and further reading the letters of the word “BELIEVE” through walls. They have furthermore imaged a number of other objects as well, showing that they can capture details previously not possible with WiFi. </span></span></span></span></span></span></span></p>
<p><span><span><span><span lang="EN" xml:lang="EN"><span><span>Overall, the proposed approach can open up new directions for RF imaging.</span></span></span></span></span></span></p>
</div>

                  

                  

      
  




            
      
            
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK air traffic control meltdown (144 pts)]]></title>
            <link>https://jameshaydon.github.io/nats-fail/</link>
            <guid>37468600</guid>
            <pubDate>Mon, 11 Sep 2023 15:19:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jameshaydon.github.io/nats-fail/">https://jameshaydon.github.io/nats-fail/</a>, See on <a href="https://news.ycombinator.com/item?id=37468600">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Comments on <a href="https://www.reddit.com/r/programming/comments/16fhmuq/a_deep_dive_into_the_bug_that_caused_the_uk_air/?utm_source=share&amp;utm_medium=web2x&amp;context=3">reddit</a></p>
<p>On 28 August 2023 <em>NATS</em>, the UK's air traffic control operator, suffered a
<strong>major</strong> technical incident. The BBC reports that more than <a href="https://www.bbc.com/news/uk-66685349">2000 flights were
cancelled</a> and the cost has been estimated
at over <em>£100 million</em> GBP. The incident probably affected hundreds of thousands
of people.</p>
<p>The press initially reported the cause was a faulty flight plan: <em>UK air traffic
control: inquiry into whether French error caused failure</em> (The Times) and in
typical Mail Online reporting style: <em>"Did blunder by French airline spark air
traffic control issues? Officials probe if a single badly filed travel plan
caused UK's entire flight-control system to collapse in worst outage for a
decade - with 1,000 flights cancelled and chaos set to last DAYS"</em>.</p>
<p>So what happened? These are notes on my reading of the incident report:</p>
<blockquote>
<p>NATS Major Incident Preliminary Report<br>
Flight Plan Reception Suite Automated (FPRSA-R) Sub-system Incident 28th August 2023 <br>
<a href="https://publicapps.caa.co.uk/docs/33/NERL%20Major%20Incident%20Investigation%20Preliminary%20Report.pdf">pdf</a>.</p>
</blockquote>
<p><em>NATS</em> is a "public-private" company in the UK that is responsible for all of
the UK's air traffic control:</p>
<blockquote>
<p>Air Traffic Control (ATC) is the provision and operation of a safe system for
controlling and monitoring aircraft.
[..] <br>
aircraft [..] are required to file a flight plan.
[..] <br>
ATC ensures that aircraft are safely separated laterally and vertically.</p>
</blockquote>
<h2 id="what-went-wrong">What went wrong</h2>
<blockquote>
<p>The start of the sequence of events leading to the incident can be tracked
back to the point at which a flight plan was entered into the flight planning
system.</p>
<p>[Airlines] submit the plan into Eurocontrol’s Integrated Initial Flight Plan
Processing System (IFPS).
[..]</p>
<p>If the submitted flight plan is accepted by IFPS, i.e. it is compliant with
IFPS defined parameters [...] this is sufficient for a flight to depart with
local ATC approval. The flight plan will be sent from IFPS to all relevant
ANSPs who need to manage the flight.
[..]</p>
<p>Within the NATS En-route operations at Swanwick Centre, the data is passed to
FPRSA-R. The FPRSA-R sub-system exists to convert the data received from IFPS
(in a format known as ATS Data Exchange Presentation, ADEXP) into a format
that is compatible with the UK National Airspace System (NAS). NAS is the
flight data processing system which contains all of the relevant airspace and
routings.
[..]</p>
<p>FPRSA-R has a primary and backup system monitored both by dedicated Control
and Monitoring (C&amp;M) systems and also an aggregated central C&amp;M system.
Further resilience is provided by NAS storing 4 hours of previously filed
flight data to allow the operation to continue in the event of the loss of
automatic processing of flight data.
[..]</p>
<p>In addition to the technical resilience provided by backup systems, and the 4
hours of stored flight data, there is operational contingency available to
allow safe service to continue. This is provided through the ability to input
flight data manually, directly into NAS using a manual input system.</p>
</blockquote>
<p>To summarise:</p>
<ul>
<li>Flight plans are first submitted to a European-wide authority <em>IFPS</em>.</li>
<li>If a plan is accepted, the flight is cleared for takeoff.</li>
<li><em>NATS</em> requires the flight plan be transferred to them at least 4 hours before
the aircraft is due to enter UK airspace. This is supposed to give NATS a
4-hour window to be able to fix any problems in processing flight plans.</li>
<li>It seems that there is also probably some process which <em>delays</em> flight plans
until <em>close</em> to the deadline (see below). This might be to avoid congesting
the system with flight plans too early, or lots of plans that may later
change. Still, this results in flight plans being received by NATS sometimes
<em>hours</em> after the flight has taken off.</li>
</ul>
<blockquote>
<p>The NATS ATC System was operating normally.
[..]</p>
<p>[On] 28 August the airline submitted an ICAO4444 compliant flight plan into
Eurocontrol’s flight planning distribution system, IFPS.</p>
</blockquote>
<p>ICAO stands for <a href="https://en.wikipedia.org/wiki/International_Civil_Aviation_Organization" title="wikipedia">International Civil Aviation
Organization</a>, a United Nations agency.
An ICAO4444 flight plan looks like this:</p>
<pre><code><span>(FPL-TTT123-IS
</span><span>-C550/L-SDE1E2GHIJ3J5RWZ/SB1D1
</span><span>-KPWM1225
</span><span>-N0440F310 SSOXS5 SSOXS DCT BUZRD
</span><span>DCT SEY DCT HTO J174 ORF J121
</span><span>CHS EESNT LUNNI1
</span><span>-KJAX0214 KMCO
</span><span>-PBN/A1L1B1C1D1O1T1 NAV/Z1 GBAS
</span><span>DAT/1FANS2PDC SUR/260B RSP180
</span><span>DOF/220501 REG/N123A SEL/BPAM
</span><span>CODE/A05ED7)
</span></code></pre>
<p>Such messages are in a format that is meant to be read by machines, but also by
humans if necessary. The format is spec'd over many many pages of PDF, but is
roughly:</p>
<pre><code><span>( FPL-ACID-Flt Rules Flight Type
</span><span>- AC Type/Wake Cat-
</span><span>Equip.&amp;Capability
</span><span>- Departure EOBT
</span><span>- Speed Altitude [sp] Route
</span><span>- Destination ETE [sp]
</span><span>Alternate(s)
</span><span>- Other Information )
</span></code></pre>
<p>The route part (in this example: <code>N0440F310 SSOXS5 SSOXS DCT BUZRD DCT SEY DCT HTO J174 ORF J121 CHS EESNT LUNNI1</code>) encodes an overall speed (here <code>N0440</code>
meaning <code>440 knots</code>), an overall altitude (here <code>F310</code> which means "Flight
Level 310" which means <code>310 × 100 ft</code> (can also be in <code>km</code>)), and a sequence of
waypoints (referenced by name) separated by a description of how to get from the
previous waypoint to the next one, usually by referencing a "known route" by
name.</p>
<blockquote>
<p>The flight plan was accepted by IFPS
[..] <br>
the aircraft was cleared to depart at 04:00.
[..]</p>
<p>At 08:32 the flight plan was received by NATS’ FPRSA-R sub-system from
Eurocontrol’s IFPS system. This is consistent with the 4 hour rule mentioned
above. The purpose of the FPRSA-R software is to extract the UK portion of the
flight plan [..]</p>
<p>The flight plans delivered to FPRSA-R by IFPS are converted from [..] ICAO4444
to [..] ADEXP. ADEXP is a European-wide flight plan specification that
includes, amongst other data, additional geographical waypoints within the
European region specific to the route of a flight. For flights transiting
through UK airspace, rather than landing in the UK, this will include
additional waypoints outside of UK airspace required for its onward journey.
Following this conversion the ADEXP version of a flight plan includes, amongst
other aspects, the original ICAO4444 flight plan plus an additional list of
waypoints and other data.</p>
</blockquote>
<p>ADEXP looks like this:</p>
<pre><code><span>-TITLE IFPL
</span><span>-BEGIN ADDR
</span><span>  -FAC LIIRZEZX
</span><span>  [...]
</span><span>  -FAC LYZZEBXX
</span><span>-END ADDR
</span><span>-ADEP EDDF
</span><span>-ADES LGTS
</span><span>-ARCID KIM1
</span><span>-ARCTYP B738
</span><span>-CEQPT SDGRWY
</span><span>-EOBD 170729
</span><span>-EOBT 0715
</span><span>-FILTIM 280832
</span><span>-IFPLID AT00441635
</span><span>-ORIGIN -NETWORKTYPE SITA -FAC FRAOXLH
</span><span>-SEQPT C
</span><span>-WKTRC M
</span><span>-PBN B2
</span><span>-REG DABHM
</span><span>-SEL KMGJ
</span><span>-SRC FPL
</span><span>-TTLEET 0210
</span><span>-RFL F330
</span><span>-SPEED N0417
</span><span>-FLTRUL I
</span><span>-FLTTYP S
</span><span>-ROUTE N0417F330 ANEKI8L ANEKI Y163 NATOR UN850 TRA UP131 RESIA Q333
</span><span>BABAG UN606 PEVAL DCT PETAK UL607 PINDO UM603 EDASI
</span><span>-ALTRNT1 LBSF
</span><span>-BEGIN RTEPTS
</span><span>  -PT -PTID EDDF -FL F004 -ETO 170729073000
</span><span>  -PT -PTID RID -FL F100 -ETO 170729073404
</span><span>  -PT -PTID ANEKI -FL F210 -ETO 170729073856
</span><span>  -PT -PTID NEKLO -FL F214 -ETO 170729073911
</span><span>  -PT -PTID BADLI -FL F248 -ETO 170729074118
</span><span>  -PT -PTID PABLA -FL F279 -ETO 170729074348
</span><span>  -PT -PTID HERBI -FL F308 -ETO 170729074624
</span><span>  -PT -PTID NATOR -FL F330 -ETO 170729074911
</span><span>  -PT -PTID TITIX -FL F330 -ETO 170729075154
</span><span>  -PT -PTID TRA -FL F330 -ETO 170729075323
</span><span>  -PT -PTID ARGAX -FL F330 -ETO 170729080055
</span><span>  -PT -PTID RESIA -FL F330 -ETO 170729080731
</span><span>  -PT -PTID UNTAD -FL F330 -ETO 170729081243
</span><span>  -PT -PTID DIKEM -FL F330 -ETO 170729081627
</span><span>  -PT -PTID ROKIB -FL F330 -ETO 170729081824
</span><span>  -PT -PTID BABAG -FL F330 -ETO 170729082816
</span><span>  -PT -PTID PEVAL -FL F330 -ETO 170729082916
</span><span>  -PT -PTID PETAK -FL F330 -ETO 170729091754
</span><span>  -PT -PTID PINDO -FL F330 -ETO 170729093322
</span><span>  -PT -PTID EDASI -FL F165 -ETO 170729094347
</span><span>  -PT -PTID LGTS -FL F000 -ETO 170729095713
</span><span>-END RTEPTS
</span><span>-SID ANEKI8L
</span><span>-ATSRT Y163 ANEKI NATOR
</span><span>-ATSRT UN850 NATOR TRA
</span><span>-ATSRT UP131 TRA RESIA
</span><span>-ATSRT Q333 RESIA BABAG
</span><span>-ATSRT UN606 BABAG PEVAL
</span><span>-DCT PEVAL PETAK
</span><span>-ATSRT UL607 PETAK PINDO
</span><span>n -ATSRT UM603 PINDO EDASI
</span></code></pre>
<p>You can read about ADEXP in the <a href="https://www.eurocontrol.int/sites/default/files/2023-06/eurocontrol-released-specification-adexp-3-4.pdf" title="pdf">official spec</a>.
Some notable fields (page 48):</p>
<table><thead><tr><th>Adexp Primary Field</th><th>Kind</th><th>Syntax</th><th>Semantic</th></tr></thead><tbody>
<tr><td>route</td><td>b</td><td><code>'-' "ROUTE" {LIM_CHAR}</code></td><td>Complete ICAO Field 15 information containing speed, RFL and route (conforming to the syntax given in Ref. [3]).</td></tr>
<tr><td>rtepts</td><td>c</td><td><code>'-' "BEGIN" "RTEPTS" { pt I ad / vec} '-' "END" "RTEPTS"</code></td><td>List of route points. May also contain an aerodrome identifier.</td></tr>
</tbody></table>
<p>In the example, we have the ICAO route:</p>
<pre><code><span>-ROUTE N0417F330 ANEKI8L ANEKI Y163 NATOR UN850 TRA UP131 RESIA Q333 BABAG UN606 PEVAL DCT PETAK UL607 PINDO UM603 EDASI
</span></code></pre>
<p>(9 waypoints, 11 if you add the start and end waypoints)</p>
<p>Visually, routes look like:
<img src="https://jameshaydon.github.io/nats-fail/flight_plan.png" alt="some route" title="A flight plan route"></p>
<p>(You can play around with flight plans at
<a href="https://flightplandatabase.com/">flightplandatabase.com</a>, a website for people
who like playing with flight simulators)</p>
<p>We can indent the "route" parts between the waypoints in the ICAO plan to make
things clearer:</p>
<pre><code><span>N0417F330
</span><span>  ANEKI8L 
</span><span>  ANEKI 
</span><span>    Y163
</span><span>  NATOR
</span><span>    UN850
</span><span>  TRA
</span><span>    UP131
</span><span>  RESIA
</span><span>    Q333
</span><span>  BABAG
</span><span>    UN606
</span><span>  PEVAL
</span><span>    DCT
</span><span>  PETAK
</span><span>    UL607
</span><span>  PINDO
</span><span>    UM603
</span><span>  EDASI
</span></code></pre>
<p>E.g. <code>ANEKI Y163 NATOR</code> means "go from waypoint <code>ANEKI</code> to waypoint <code>NATOR</code> via
the route <code>Y163</code>". <code>DCT</code> means "direct".</p>
<p>The <code>ADEXP</code> format has more waypoints, along with more precision about altitude and estimated time at each waypoint:</p>
<pre><code><span>-BEGIN RTEPTS
</span><span>-PT -PTID EDDF  -FL F004 -ETO 170729073000
</span><span>-PT -PTID RID   -FL F100 -ETO 170729073404
</span><span>-PT -PTID ANEKI -FL F210 -ETO 170729073856
</span><span>-PT -PTID NEKLO -FL F214 -ETO 170729073911
</span><span>-PT -PTID BADLI -FL F248 -ETO 170729074118
</span><span>-PT -PTID PABLA -FL F279 -ETO 170729074348
</span><span>-PT -PTID HERBI -FL F308 -ETO 170729074624
</span><span>-PT -PTID NATOR -FL F330 -ETO 170729074911
</span><span>-PT -PTID TITIX -FL F330 -ETO 170729075154
</span><span>-PT -PTID TRA   -FL F330 -ETO 170729075323
</span><span>-PT -PTID ARGAX -FL F330 -ETO 170729080055
</span><span>-PT -PTID RESIA -FL F330 -ETO 170729080731
</span><span>-PT -PTID UNTAD -FL F330 -ETO 170729081243
</span><span>-PT -PTID DIKEM -FL F330 -ETO 170729081627
</span><span>-PT -PTID ROKIB -FL F330 -ETO 170729081824
</span><span>-PT -PTID BABAG -FL F330 -ETO 170729082816
</span><span>-PT -PTID PEVAL -FL F330 -ETO 170729082916
</span><span>-PT -PTID PETAK -FL F330 -ETO 170729091754
</span><span>-PT -PTID PINDO -FL F330 -ETO 170729093322
</span><span>-PT -PTID EDASI -FL F165 -ETO 170729094347
</span><span>-PT -PTID LGTS  -FL F000 -ETO 170729095713
</span><span>-END RTEPTS
</span></code></pre>
<p>(21 waypoints)</p>
<p>We can mark which of the ADEXP waypoints have a corresponding waypoint in the ICAO plan (with a <code>+</code>) and which are implicit (with a <code>|</code>): </p>
<pre><code><span>EDDF   |
</span><span>RID    |
</span><span>ANEKI  + 
</span><span>NEKLO  |
</span><span>BADLI  |
</span><span>PABLA  |
</span><span>HERBI  |
</span><span>NATOR  +
</span><span>TITIX  |
</span><span>TRA    +
</span><span>ARGAX  |
</span><span>RESIA  +
</span><span>UNTAD  |
</span><span>DIKEM  |
</span><span>ROKIB  |
</span><span>BABAG  +
</span><span>PEVAL  |
</span><span>PETAK  +
</span><span>PINDO  +
</span><span>EDASI  +
</span><span>LGTS   |
</span></code></pre>
<p>Note that the ICAO waypoints do not contain the start and end, since in the
original ICAO format these are specified in other fields (so it would waste
space to list them again in this list).</p>
<blockquote>
<p>The ADEXP waypoints plan included two waypoints along its route that were
geographically distinct but which have the same designator.</p>
</blockquote>
<p>This means there were two lines like:</p>
<pre><code><span>-PT -PTID RESIA -FL F330 -ETO 170729080731
</span></code></pre>
<p>that had the same <code>PTID</code> string like <code>"RESIA"</code>.</p>
<blockquote>
<p>Although there has been work by ICAO and other bodies to eradicate non-unique
waypoint names there are duplicates around the world. In order to avoid
confusion latest standards state that such identical designators should be
geographically widely spaced. In this specific event, both of the waypoints
were located outside of the UK, one towards the beginning of the route and one
towards the end; approximately 4000 nautical miles apart.</p>
</blockquote>
<p>4000 nautical miles is 7408km. Here is an arc of that length on the globe:
<img src="https://jameshaydon.github.io/nats-fail/4000-nautical-miles.png" alt="4000 nautical miles on a globe"></p>
<blockquote>
<p>Once the ADEXP file had been received, the FPRSA-R software commenced
searching for the UK airspace entry point in the waypoint information per the
ADEXP flight plan, commencing at the first line of that waypoint data. FPRSA-R
was able to specifically identify the character string as it appeared in the
ADEXP flight plan text.</p>
</blockquote>
<p>The programming style is very imperative. Furthermore, the description sounds
like the procedure is working directly on the textual representation of the
flight plan, rather than a data structure parsed from the text file. This would
be quite worrying, but it might also just be how it is explained.</p>
<blockquote>
<p>Having correctly identified the entry point, the software moved on to search
for the exit point from UK airspace in the waypoint data.</p>
<p>Having completed those steps,</p>
</blockquote>
<p>This part of the code identified <code>entry</code> and <code>exit</code> waypoints to UK airspace in
the list of <code>ADEXP</code> waypoints.</p>
<blockquote>
<p>FPRSA-R then searches the ICAO4444 section of
the ADEXP file.</p>
</blockquote>
<p>It seems at this point, having identified the entry and exit points from the
list of ADEXP waypoints, it will try to extract the UK portion of the flight plan from the ICAO route.</p>
<blockquote>
<p>It initially searches from the beginning of that data, to find
the identified UK airspace entry point. This was successfully found. Next, it
searches backwards, from the end of that section, to find the UK airspace exit
point. This did not appear in that section of the flight plan so the search
was unsuccessful. As there is no requirement for a flight plan to contain an
exit waypoint from a Flight Information Region (FIR) or a country’s airspace,
the software is designed to cope with this scenario.</p>
<p>Therefore, where there is no UK exit point explicitly included, the software
logic utilises the waypoints as detailed in the ADEXP file to search for the
next nearest point beyond the UK exit point. This was also not present.</p>
<p>The software therefore moved on to the next waypoint.</p>
</blockquote>
<p>OK, so I think this is what is going on, the situation looked something like
this:</p>
<pre><code><span>           4       2        8         5              1           9
</span><span>ICAO:  F------Q--------T--------O-----------P---------------Y--------U
</span><span>
</span><span>ADEXP: F   S  Q    C   T   A    O  E  X     P   W   B   Q   Y        U
</span><span>                       UK  UK   UK UK UK    UK  UK
</span></code></pre>
<p>Here the ICAO route has waypoints (represented by capital letters) separated by
known routes (numbers). On the bottom we have the ADEXP waypoints. The ADEXP
waypoints that are located in the UK airspace are marked with <code>UK</code>.</p>
<ul>
<li>The software has identified:
<ul>
<li><code>entry</code>: waypoint <code>T</code></li>
<li><code>exit</code>: waypoint <code>W</code>
in the ADEXP waypoints.</li>
</ul>
</li>
<li>The software finds waypoint <code>T</code> in the ICAO flight plan.</li>
<li>The software <em>does not</em> find waypoint <code>W</code> in the ICAO flight plan.</li>
<li>The software therefore takes the next waypoint in the ADEXP list, so <code>B</code>, and
tries to find it too, and also does not find it.</li>
<li>So it does this again, taking waypoint <code>Q</code>, and it <em>does</em> find it, but at the
<em>start</em> of the ICAO flight plan, before the plane even enters the UK.</li>
</ul>
<blockquote>
<p>This search was successful as a duplicate identifier appeared in the flight
plan.</p>
</blockquote>
<p>What should the software have done? Well, <code>Q</code> is clearly <em>not</em> the waypoint we
are searching for, we are searching for waypoint <code>Y</code>, since <code>[T, O, P, Y]</code> is
the smallest segment of the ICAO plan that contains all the UK waypoints.</p>
<p>It's important to note here that the original algorithm is buggy; it is perfectly
possible to unambiguously extract the UK portion of this example flight plan;
see <a href="https://jameshaydon.github.io/nats-fail/#how-to-code-this-properly">below</a>. And this is likely the case for the
flight plan that caused the meltdown too.</p>
<blockquote>
<p>Having found an entry and exit point, with the latter being the duplicate and
therefore geographically incorrect, the software could not extract a valid UK
portion of flight plan between these two points. This is the root cause of the
incident. We can therefore rule out any cyber related contribution to this
incident.</p>
</blockquote>
<p>It sounds like the exception was raised in a later portion of the code, which
converts the plan to an internal format for <em>NAS</em>. This part failed because the
identified entry/exit waypoints didn't even specify a valid segment of the ICAO
route.</p>
<blockquote>
<p>Safety critical software systems are designed to always fail safely. This
means that in the event they cannot proceed in a demonstrably safe manner,
they will move into a state that requires manual intervention.</p>
</blockquote>
<p>We are left wondering if, had the misidentified waypoint been in a more
plausible geographic location, the code might not have thrown an exception and
passed along wrong data to ATCOs.</p>
<blockquote>
<p>In this case the software within the FPRSA-R subsystem was unable to establish
a reasonable course of action that would preserve safety and so raised a
critical exception. A critical exception is, broadly speaking, an exception of
last resort after exploring all other handling options. Critical exceptions
can be raised as a result of software logic or hardware faults, but
essentially mark the point at which the affected system cannot continue.</p>
</blockquote>
<p>It sounds like the software was written thinking this exception would never
occur.</p>
<blockquote>
<p>Clearly a better way to handle this specific logic error would be for FPRSA-R
to identify and remove the message and avoid a critical exception. However,
since flight data is safety critical information that is passed to ATCOs the
system must be sure it is correct and could not do so in this case. It
therefore stopped operating, avoiding any opportunity for incorrect data being
passed to a controller. The change to the software will now remove the need
for a critical exception to be raised in these specific circumstances.</p>
<p>Having raised a critical exception the FPRSA-R primary system wrote a log file
into the system log. It then correctly placed itself into maintenance mode and
the C&amp;M system identified that the primary system was no longer available. In
the event of a failure of a primary system the backup system is designed to
take over processing seamlessly. In this instance the backup system took over
processing flight plan messages. As is common in complex real-time systems the
backup system software is located on separate hardware with separate power and
data feeds.</p>
<p>Therefore, on taking over the duties of the primary server, the backup system
applied the same logic to the flight plan with the same result. It
subsequently raised its own critical exception, writing a log file into the
system log and placed itself into maintenance mode.</p>
<p>At this point with both the primary and backup FPRSA-R sub-systems having
failed safely the FPRSA-R was no longer able to automatically process flight
plans. It required restoration to normal service through manual intervention.
The entire process described above, from the point of receipt of the ADEXP
message to both the primary and backup sub-systems moving into maintenance
mode, took less than 20 seconds. 08:32 therefore marks the point at which the
automatic processing of flight plans ceased and the 4 hour buffer to manual
flight plan input commenced. The steps taken to restore the FPRSA-R sub-system
are described in section 5 of this report.</p>
</blockquote>
<p>Then support teams tried to fix things, but unfortunately it took longer than
the 4 hours they had:</p>
<blockquote>
<p>The 1st Line support team were alerted to the incident through the C&amp;M systems
that directly monitor operational systems as well as through direct feedback
from the Operational teams using the FPRSA-R sub-system at the time. The
initial response for the team followed standard recovery processes using the
centralised C&amp;M systems to restart the sub-system. Following multiple attempts
to restore the service, which were unsuccessful, the 2nd Line engineering team
was mobilised and supported the on-site engineers remotely via video link.</p>
</blockquote>
<p><img src="https://jameshaydon.github.io/nats-fail/off-and-on-again.jpg" alt="have you tried turning it off and on again?"></p>
<blockquote>
<p>The on-call teams working remotely with the on-site engineering teams followed
a staged analysis, involving increasingly detailed procedures to attempt to
resolve the issue, none of which were successful. As per standard escalation
procedures, 2nd Line engineers were engaged to provide further access to
advanced diagnostics and logging capabilities.</p>
</blockquote>
<p>It doesn't say how long it took, but the manufacturer of the <code>FPRSA-R</code> system was
eventually called:</p>
<blockquote>
<p>Additional support was then requested from the Technical Design team and
sub-system manufacturer as 1st and 2nd Line support had been unable to restore
the service or identify the precise root cause, which was unusual. The
manufacturer was able to offer further expertise including analysis of
lower-level software logs which led to identification of the likely flight
plan that had caused the software exception. Through understanding which
flight plan had caused the incident the manufacturer was able to provide the
precise sequence of actions necessary to recover the system in a controlled
and safe manner.</p>
</blockquote>
<p>The system was eventually restored, but unfortunately the knock-on effects by
that point were already disastrous.</p>
<p>The manufacturer is an Austrian company, <a href="https://en.wikipedia.org/wiki/Frequentis">Frequentis
AG</a>:</p>
<blockquote>
<p>An FPRSA sub-system has existed in NATS for many years and in 2018 the
previous FPRSA sub- system was replaced with new hardware and software
manufactured by Frequentis AG, one of the leading global ATC System providers.
The manufacturer’s ATC products are operating in approximately 150 countries
and they hold a world-leading position in aeronautical information management
(AIM) and message handling systems.</p>
</blockquote>
<p>The "Nobody ever gets fired for hiring Accenture" defence.</p>
<p>We can find a few job ads related to air traffic control systems at Frequentis
AG on their <a href="https://jobs.frequentis.com/careers/SearchJobs/air?listFilterMode=1">careers
page</a>
Programming languages used: <code>Ada</code>, <code>C++</code>, <code>Java</code>, <code>Python</code>, with <code>Java</code> being
the most common. The code above sounds like it could have been written in any of
these languages, but Ada would at least be safer than the others in other ways.</p>
<h2 id="thoughts">Thoughts</h2>
<p>Things that went wrong:</p>
<ol>
<li>The software that processes flight plans (<code>FPRSA-R</code>) was written in a buggy
way.</li>
<li>The software and system are not properly tested.</li>
<li>The <code>FPRSA-R</code> system has bad <a href="https://en.wikipedia.org/wiki/Failure_mode_and_effects_analysis" title="wikipedia">failure modes</a></li>
</ol>
<h3 id="the-software-was-buggy">The software was buggy</h3>
<p>The software was incapable of extracting the UK portion of the ICAO flight plan,
even though the flight plan was apparently valid (at least according to IFPS).</p>
<ul>
<li>
<p>The procedure was very fiddly and failed for a silly reason.</p>
</li>
<li>
<p>Waypoint markers are not globally unique, but this is a known issue, so NATS
should make sure their systems are robust enough to handle it. <em>All other air
traffic control authorities have to deal with this</em>. NATS says the following
about this in the report:</p>
<blockquote>
<p>Although there has been work by ICAO and other bodies to eradicate
non-unique waypoint names there are duplicates around the world. In order to
avoid confusion latest standards state that such identical designators
should be geographically widely spaced. In this specific event, both of the
waypoints were located outside of the UK, one towards the beginning of the
route and one towards the end; approximately 4000 nautical miles apart.</p>
</blockquote>
<p>When waypoints with the same name are widely spaced, this makes flight plans
unambiguous, because successive waypoints in a flight plan cannot be too far
apart. They also mention possible actions they will take:</p>
<blockquote>
<p>The feasibility of working through the UK state with ICAO to remove the
small number of duplicate waypoint names in the ICAO administered global
dataset that relate to this incident.</p>
</blockquote>
<p>Waypoint names are clearly chosen to be short and snappy. Here's a sequence
from some flight plan I found: <code>KOMAL</code>, <code>ATRAK</code>, <code>SORES</code>, <code>SAKTA</code>, <code>ALMIK</code>,
<code>IGORO</code>, <code>ATMED</code>, etc. It's clear that the system has been designed so these
names can be communicated quickly, e.g. over radio, and that pilots and
air traffic controllers can become familiar with those on the routes they
usually fly. Changing the name of a waypoint can be a scary operation.
Uniqueness is obviously desirable, but it has to be balanced against other
considerations. Including this suggestion in the initial report feels like
NATS is trying to shift the blame onto ICAO.</p>
<p>Furthermore, I don't see why a flight plan can't include the same <em>geographic</em>
waypoint several times; for example for leisure flights or military exercises.
Taking off and landing at the same airport is definitely a thing (called a
"round-robin flight plan"). It doesn't sound like the <code>FPRSA-R</code> algorithm
would be very robust to that.</p>
</li>
</ul>
<p>NATS officials are trying to spin this as:</p>
<blockquote>
<p>An air traffic meltdown in Britain was caused by a "one in 15 million" event,
the boss of traffic control provider NATS said, as initial findings showed how
a single flight plan with two identically labelled markers caused the chaos.</p>
<p>"This was a one in 15 million chance. We've processed 15 million flight plans
with this system up until this point and never seen this before," NATS CEO
Martin Rolfe told the BBC, as airlines stepped up calls for compensation for
the breakdown. <a href="https://www.reuters.com/world/uk/uk-aviation-regulator-review-air-traffic-control-failure-2023-09-06/">Reuters</a></p>
</blockquote>
<p>The system was put in place in 2018, so what Martin Rolfe is saying here is that
this sort of thing only had a chance of occurring "once every 5 years", which is
apparently an acceptable frequency for having a complete air traffic control
meltdown.</p>
<h3 id="the-system-was-poorly-tested">The system was poorly tested</h3>
<p><a href="https://en.wikipedia.org/wiki/Fuzzing">fuzzing</a>, for example, may have
prevented this. By bombarding such a system with randomly generated flight
plans, you can see if any of them cause bad failure modes: a crashed system
where one doesn't know immediately what went wrong. By inspecting which sorts of
flight plans cause problems, it would become apparent that those with duplicate
waypoint identifiers in the ADEXP portion cannot be processed properly.</p>
<h3 id="the-fprsa-r-system-has-bad-failure-modes">The <code>FPRSA-R</code> system has bad failure modes</h3>
<p>All systems can malfunction, so the important thing is that they malfunction <em>in
a good way</em> and that those responsible are <em>prepared</em> for malfunctions.</p>
<p>A single flight plan caused a problem, and the entire <code>FPRSA-R</code> system crashed,
which means no flight plans are being processed at all. If there is a problem
with a single flight plan, it should be moved to a separate slower queue, for
manual processing by humans. NATS acknowledges this in their "actions already
undertaken or in progress":</p>
<blockquote>
<p>The addition of specific message filters into the data flow between IFPS and
FPRSA-R to filter out any flight plans that fit the conditions that caused the
incident.</p>
</blockquote>
<p>When <code>FPRSA-R</code> it did crash, it did so in an obscure way. This is a system
which <em>processes flight plans</em>, yet the relevant flight plan was only found in
"lower-level software logs". If there is an error processing a flight plan,
which brings down the whole system, a notification (including the flight plan)
should immediately be sent to some monitoring team.</p>
<p>NATS was also not prepared for an <code>FPRSA-R</code> system failure. The 1st
and 2nd Line support engineers were not able to locate, or did not think to
check, the low-level log files. This has been fixed:</p>
<blockquote>
<p>An operating instruction has been put in place to allow prompt recovery of the
FPRSA-R sub-system if the same circumstances recur. Each of the technical
operators have been trained to implement the new process. With enhanced
monitoring in place, additional engineering expertise will also be present to
oversee the activity.</p>
</blockquote>
<h3 id="possible-lack-of-formal-verification">Possible lack of formal verification</h3>
<p>As reddit user <code>DontWannaMissAFling</code> <a href="https://www.reddit.com/r/programming/comments/16fhmuq/comment/k02o6n8/?utm_source=share&amp;utm_medium=web2x&amp;context=3">points out</a>:</p>
<blockquote>
<p>But what's wild to me is that something as safety critical as air traffic
control apparently isn't using proven techniques like formal verification,
model checking to eliminate these classes of bugs entirely.</p>
<p>Like as an industry we use TLA+ to stop AWS from having downtime or Xboxes
segfaulting, but not to keep planes in the air?</p>
</blockquote>
<p>I agree that it certainly doesn't sound like any formal verification was used in
this case (for this system), and the report doesn't mention anything. Using
formal verification would certainly have helped here, I might explore this in
subsequent posts.</p>
<p>But it's possible formal verification was used, but faulty code still made its
way into production: end-2-end formal verification for large systems is still in
its infancy. We'll have to wait for the result of the enquiry to know more.</p>
<h2 id="humans-were-kept-safe-at-all-times">Humans were kept safe at all times</h2>
<p>I'd like to note (as does NATS in the report) that despite all the problems
highlighted above, planes in the air over the UK were still safe at all times.
They were being monitored by experienced ATCOs, which monitor planes by their
known flight plan, radio, radar and vision. The consequence of all this was not
that any human lives were put in danger, it's simply that far fewer flights
could take off in the first place, or had to be diverted away from UK airspace.
NATS did the right thing (reducing the number of flights), and kept everybody
safe.</p>
<h2 id="how-to-code-this-properly">How to code this properly</h2>
<p>So, how can we avoid this bug?</p>
<p>Let's recap the problem. There are two sequences of waypoints:</p>
<ul>
<li><code>ADEXP</code>: the full list of waypoints.</li>
<li><code>ICAO</code>: a subsequence of the ADEXP waypoints.</li>
</ul>
<p>Because the ICAO plan doesn't need to include the waypoints at which it
enters/exits an air traffic control region, extracting the segment of the ICAO
flight plan corresponding to the UK portion of the flight is not entirely
trivial. Of course, if we take the entire ICAO flight plan, it already contains
the UK portion, but what we really want is the <em>smallest</em> such segment. It's
interesting to note here that a flight could possibly enter UK airspace, and
then exit it again, and enter it again. We'll ignore this, that is, we will just
find a single contiguous segment that contains all UK portions of the flight,
since this is what the original code seemed to do.</p>
<p>I'm unsure why this task attempts to do this only using the ADEXP data, rather
than consulting a database about how waypoints and flight segments intersect UK
airspace. It seems strange, but let's move on.</p>
<p>Note that it is impossible to achieve this task with the ICAO flight plan alone
(and no knowledge of routes), even if you know for each waypoint if it is in the
UK or not. Indeed you could even be in a situation where <em>none</em> of the waypoints
in the ICAO route are in the UK, for example when the flight plan clips a small
portion of the UK between two of the ICAO waypoints.</p>
<p>So this is why the ADEXP waypoint list is used, and the assumption here, I
assume, is that the ADEXP list contains <em>all</em> the waypoints, and that
furthermore, waypoint granularity is such that if <em>adjacent</em> waypoints both
don't intersect UK airspace, then the segment between them doesn't either.</p>
<p>The mistake of the faulty algorithm described above is to try to work on both
the ICAO data and the ADEXP data as they are, maintaining pointers into each of
them, updating them with vague and wrong invariants in the background of the
programmer's mind. This is a recipe for bugs. Instead, the first thing to do is
to reconcile the data and then carefully extract the UK portion from that.</p>
<p>So we create a data structure for a plan:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>-- A flight plan, with segments between points 'p' via routes 'r'.
</span><span>data </span><span>Plan</span><span> p r
</span><span>  = </span><span>End</span><span> p
</span><span>  | </span><span>Leg</span><span> p r (</span><span>Plan</span><span> p r)
</span></code></pre>
<p>(This is <a href="https://www.haskell.org/">Haskell</a> code, but the ideas apply to most languages.)</p>
<p>This says that a <code>Plan p r</code> has either arrived at its destination <code>End p</code>, or
consists of a segment starting from <code>p</code>, via <code>r</code>, and the <code>rest</code> of the plan:
<code>Leg p r rest</code>.</p>
<p>We can now define all the sorts of flight plan data we will deal with:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>type </span><span>ICAO</span><span>     p r = </span><span>Plan</span><span> p r         </span><span>-- points and routes, no intermediate waypoints
</span><span>type </span><span>ADEXP</span><span>    p   = </span><span>Plan</span><span> p [p]       </span><span>-- points and intermediate waypoints, no route data
</span><span>type </span><span>Combined</span><span> p r = </span><span>Plan</span><span> p (</span><span>Via</span><span> p r) </span><span>-- all the data combined
</span><span>
</span><span>data </span><span>Via</span><span> p r = </span><span>Via
</span><span>  { route   :: r,
</span><span>    </span><span>through </span><span>::</span><span> [</span><span>p</span><span>]
</span><span>  }
</span><span>  </span><span>deriving</span><span> stock (</span><span>Show</span><span>)
</span></code></pre>
<p>Here <code>Combined</code> is our reconciled flight plan, it combined all the information
form ICAO and ADEXP. We can project a <code>Plan</code> back down to <code>ICAO</code> or <code>ADEXP</code>:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>projectICAO </span><span>:: Combined </span><span>p r </span><span>-&gt; ICAO </span><span>p r
</span><span>projectICAO = mapRoutes (.route)
</span><span>
</span><span>projectADEXP </span><span>:: Combined </span><span>p r </span><span>-&gt; ADEXP </span><span>p
</span><span>projectADEXP = mapRoutes (.through)
</span><span>
</span><span>mapRoutes </span><span>::</span><span> (</span><span>r </span><span>-&gt; </span><span>r</span><span>') </span><span>-&gt; Plan </span><span>p r </span><span>-&gt; Plan </span><span>p r</span><span>'
</span><span>mapRoutes _ (</span><span>End</span><span> p) = </span><span>End</span><span> p
</span><span>mapRoutes f (</span><span>Leg</span><span> p r rest) = </span><span>Leg</span><span> p (f r) (mapRoutes f rest)
</span></code></pre>
<p>We'll assume we have already parsed the data into the data structures above.
This is just a matter of reading the spec carefully and turning it into code,
and hopefully something the <code>FPRSA-R</code> did correctly, though as noted previously
it might be working on the text version directly.</p>
<p>Now we write our reconciliation function. For ICAO and ADEXP to reconcile, the
start and end points must match. When reconciling a leg of a flight plan, a
certain amount of waypoints can be skipped in the ICAO plan, and the rest of
them must reconcile with the rest of the flight plan:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>reconcile </span><span>::</span><span> (</span><span>Eq </span><span>p</span><span>) </span><span>=&gt; ICAO </span><span>p r </span><span>-&gt;</span><span> [</span><span>p</span><span>] </span><span>-&gt;</span><span> [</span><span>Combined </span><span>p r</span><span>]
</span><span>reconcile (</span><span>End</span><span> p) [p']             | p == p' = pure (</span><span>End</span><span> p)
</span><span>reconcile (</span><span>Leg</span><span> p r rest) (p' : ps) | p == p' = </span><span>do
</span><span>  (through, restAdexp) &lt;- splits ps
</span><span>  recoRest &lt;- reconcile rest restAdexp
</span><span>  pure (</span><span>Leg</span><span> p </span><span>Via</span><span> {route = r, through} recoRest)
</span><span>reconcile _ _ = </span><span>[]
</span><span>
</span><span>-- | All the ways to snap a list in two.
</span><span>splits </span><span>::</span><span> [</span><span>a</span><span>] </span><span>-&gt;</span><span> [([</span><span>a</span><span>], [</span><span>a</span><span>])]
</span><span>splits </span><span>[] </span><span>= [(</span><span>[]</span><span>, </span><span>[]</span><span>)]
</span><span>splits xs@(x : rest) = (</span><span>[]</span><span>, xs) : (first (x :) &lt;$&gt; splits rest)
</span></code></pre>
<p>Note that the function produces <em>all</em> the possible reconciliations. This is
because reconciliations are not necessarily unique because waypoints can appear
more than once. By calculating all the possible reconciliations, we'll know if
the data is ambiguous, and flag those flight plans for manual processing.</p>
<p>Next, we extract the UK portion of the flight plan. This is done in 3 steps:</p>
<ol>
<li>Remove all legs at the start which don't cross into UK airspace.</li>
<li>Traverse the legs which are in UK airspace.</li>
<li>Once the rest of the flight plan is never again in the UK, cut it short.</li>
</ol>
<p>Each function calls the next step in sequence. Note that we return a
<code>NonUkPlan</code> error when the system reaches the end of the plan without having
found a UK part. By having a compiler which checks that pattern-matches are
covering, the possible failures arise naturally while coding.</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>-- Extract the UK part of the flight.
</span><span>ukSegment </span><span>::</span><span> (</span><span>p </span><span>-&gt; Bool</span><span>) </span><span>-&gt; Combined </span><span>p r </span><span>-&gt; Either Err</span><span> (</span><span>Combined </span><span>p r</span><span>)
</span><span>ukSegment uk (</span><span>End</span><span> p)
</span><span>  | nonUkPlan uk (</span><span>End</span><span> p) = </span><span>Left NonUkPlan
</span><span>  | otherwise = pure (</span><span>End</span><span> p)
</span><span>ukSegment uk plan@(</span><span>Leg</span><span> _ _ rest) =
</span><span>  </span><span>if</span><span> nonUkLeg uk plan
</span><span>    </span><span>then</span><span> ukSegment uk rest
</span><span>    </span><span>else</span><span> pure (flyUK uk plan)
</span><span>
</span><span>-- Fly the UK part of the flight.
</span><span>flyUK </span><span>::</span><span> (</span><span>p </span><span>-&gt; Bool</span><span>) </span><span>-&gt; Combined </span><span>p r </span><span>-&gt; Combined </span><span>p r
</span><span>flyUK _ (</span><span>End</span><span> end) = </span><span>End</span><span> end
</span><span>flyUK uk (</span><span>Leg</span><span> p v rest)
</span><span>  | nonUkPlan uk rest = </span><span>Leg</span><span> p v (afterUK rest)
</span><span>  | otherwise = </span><span>Leg</span><span> p v (flyUK uk rest)
</span><span>
</span><span>-- Skip the rest of the flight.
</span><span>afterUK </span><span>:: Combined </span><span>p r </span><span>-&gt; Combined </span><span>p r
</span><span>afterUK plan = </span><span>End</span><span> (start plan)
</span></code></pre>
<p>These use some small functions:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>-- The next leg of the journey doesn't fly through the UK.
</span><span>nonUkLeg </span><span>::</span><span> (</span><span>p </span><span>-&gt; Bool</span><span>) </span><span>-&gt; Combined </span><span>p r </span><span>-&gt; Bool
</span><span>nonUkLeg uk (</span><span>End</span><span> p) = not (uk p)
</span><span>nonUkLeg uk (</span><span>Leg</span><span> p v _) = not (uk p) &amp;&amp; not (any uk v.through)
</span><span>
</span><span>-- The whole plan isn't in the UK.
</span><span>nonUkPlan </span><span>::</span><span> (</span><span>a </span><span>-&gt; Bool</span><span>) </span><span>-&gt; Combined </span><span>a r </span><span>-&gt; Bool
</span><span>nonUkPlan uk plan = all (nonUkLeg uk) (legs plan)
</span><span>
</span><span>legs </span><span>:: Plan </span><span>p r </span><span>-&gt;</span><span> [</span><span>Plan </span><span>p r</span><span>]
</span><span>legs (</span><span>End</span><span> p) = [</span><span>End</span><span> p]
</span><span>legs plan@(</span><span>Leg</span><span> _ _ rest) = plan : legs rest
</span><span>
</span><span>start </span><span>:: Plan </span><span>p r </span><span>-&gt; </span><span>p
</span><span>start (</span><span>End</span><span> p) = p
</span><span>start (</span><span>Leg</span><span> p _ _) = p
</span></code></pre>
<p>Putting it all together, we get:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>ukPartOfICAO </span><span>::</span><span> (</span><span>Eq </span><span>p</span><span>) </span><span>=&gt;</span><span> (</span><span>p </span><span>-&gt; Bool</span><span>) </span><span>-&gt; ICAO </span><span>p r </span><span>-&gt;</span><span> [</span><span>p</span><span>] </span><span>-&gt; Either Err</span><span> (</span><span>ICAO </span><span>p r</span><span>)
</span><span>ukPartOfICAO uk icao adexp = </span><span>case</span><span> reconcile icao adexp </span><span>of
</span><span>  [plan] -&gt; projectICAO &lt;$&gt; ukSegment uk plan
</span><span>  </span><span>[]     </span><span>-&gt; </span><span>Left CannotReconcileIcaoAdexp
</span><span>  _      -&gt; </span><span>Left AmbiguousReconciliationsOfIcaoAdexp
</span></code></pre>
<p>We collected the following errors while coding:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>data </span><span>Err
</span><span>  = </span><span>NonUkPlan
</span><span>  | </span><span>CannotReconcileIcaoAdexp
</span><span>  | </span><span>AmbiguousReconciliationsOfIcaoAdexp
</span></code></pre>
<p>Let's test it with our example:</p>
<pre><code><span>           4       2        8         5              1           9
</span><span>ICAO:  F------Q--------T--------O-----------P---------------Y--------U
</span><span>
</span><span>ADEXP: F   S  Q    C   T   A    O  E  X     P   W   B   Q   Y        U
</span><span>                       UK  UK   UK UK UK    UK  UK
</span></code></pre>
<pre data-lang="haskell"><code data-lang="haskell"><span>inUK = (</span><span>`</span><span>elem</span><span>`</span><span> ["</span><span>T</span><span>", "</span><span>A</span><span>", "</span><span>O</span><span>", "</span><span>E</span><span>", "</span><span>X</span><span>", "</span><span>P</span><span>", "</span><span>W</span><span>"])
</span><span>icao = ("</span><span>F</span><span>", </span><span>4</span><span>) ~&gt; ("</span><span>Q</span><span>", </span><span>2</span><span>) ~&gt; ("</span><span>T</span><span>", </span><span>8</span><span>) ~&gt; ("</span><span>O</span><span>", </span><span>5</span><span>) ~&gt; ("</span><span>P</span><span>", </span><span>1</span><span>) ~&gt; ("</span><span>Y</span><span>", </span><span>9</span><span>) ~&gt; </span><span>End </span><span>"</span><span>U</span><span>"
</span><span>adexp = ["</span><span>F</span><span>", "</span><span>S</span><span>", "</span><span>Q</span><span>", "</span><span>C</span><span>", "</span><span>T</span><span>", "</span><span>A</span><span>", "</span><span>O</span><span>", "</span><span>E</span><span>", "</span><span>X</span><span>", "</span><span>P</span><span>", "</span><span>W</span><span>", "</span><span>B</span><span>", "</span><span>Q</span><span>", "</span><span>Y</span><span>", "</span><span>U</span><span>"]
</span><span>
</span><span>infixr </span><span>6 </span><span>~&gt;
</span><span>(~&gt;) (p, r) = </span><span>Leg</span><span> p r
</span></code></pre>
<p>And try this at the REPL:</p>
<pre><code><span>λ&gt; ukPortionOfICAO inUK icao adexp
</span><span>Right (Leg "T" 8 (Leg "O" 5 (Leg "P" 1 (End "Y"))))
</span></code></pre>
<p>We can see that this is the correct result:</p>
<pre><code><span>                                 UK portion of ICAO
</span><span>                       ┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┫
</span><span>           4       2        8         5              1           9
</span><span>ICAO:  F------Q--------T--------O-----------P---------------Y--------U
</span><span>
</span><span>ADEXP: F   S  Q    C   T   A    O  E  X     P   W   B   Q   Y        U
</span><span>                       UK  UK   UK UK UK    UK  UK
</span></code></pre>
<p>The waypoint <code>Q</code> is a duplicate in the ADEXP list, but the system still returns
the correct portion of the ICAO flight path. Crisis averted! The fact that there
is a duplicate identifier in this case is immaterial, the ICAO and ADEXP data
still reconcile unambiguously, and the correct sub-route is well-defined.</p>
<p>How large can flight plans get? Well here is a flight plan from London to Sydney
that contains a total of 158 waypoints, and about a third of them appear in the
ICAO route:
<img src="https://jameshaydon.github.io/nats-fail/london-sydney.png" alt="London to Sydney flight plan"> 
<code>ukPortionOfICAO</code> returns practically instantly for such a flight plan.</p>
<p>Comments on <a href="https://www.reddit.com/r/programming/comments/16fhmuq/a_deep_dive_into_the_bug_that_caused_the_uk_air/?utm_source=share&amp;utm_medium=web2x&amp;context=3">reddit</a></p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Webb Discovers Methane, Carbon Dioxide in Atmosphere of K2-18B (166 pts)]]></title>
            <link>https://www.nasa.gov/goddard/2023/webb-discovers-methane-carbon-dioxide-in-atmosphere-of-k2-18b/</link>
            <guid>37468342</guid>
            <pubDate>Mon, 11 Sep 2023 15:04:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nasa.gov/goddard/2023/webb-discovers-methane-carbon-dioxide-in-atmosphere-of-k2-18b/">https://www.nasa.gov/goddard/2023/webb-discovers-methane-carbon-dioxide-in-atmosphere-of-k2-18b/</a>, See on <a href="https://news.ycombinator.com/item?id=37468342">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Develop with Cocoa for Apple devices without using Objective-C (103 pts)]]></title>
            <link>https://felixk15.github.io/posts/c_ocoa/</link>
            <guid>37468031</guid>
            <pubDate>Mon, 11 Sep 2023 14:44:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://felixk15.github.io/posts/c_ocoa/">https://felixk15.github.io/posts/c_ocoa/</a>, See on <a href="https://news.ycombinator.com/item?id=37468031">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2 id="summary">
<span>Summary</span><a href="#summary"><i></i></a>
</h2>
<p>In this post I’ll go into detail about how, during my contracting work for <a href="https://www.shimmerindustries.com/" target="_blank" rel="noopener noreferrer">Shimmer Industries</a> (a company founded by <a href="https://twitter.com/EskilSteenberg" target="_blank" rel="noopener noreferrer">Eskil Steenberg</a> which is focused on developing a real-time lighting designing software), I worked on a piece of software which enabled us to use the MacOS and iOS APIs using a custom C API without having to use ObjC.</p>
<p>This technology (which we decided to call <strong>c-ocoa</strong>) was used to implement support for OSX &amp; iOS for Eskil’s platform abstraction library <a href="https://gamepipeline.org/betray.html" target="_blank" rel="noopener noreferrer">betray</a>. Betray is what’s driving the tools of Shimmer Industries. This allowed us to easily ship existing applications to mobile with only minimal code changes. <a href="https://felixk15.github.io/assets/img/posts/c_ocoa/betray_abstraction.png"><img data-src="/assets/img/posts/c_ocoa/betray_abstraction.png" alt="Betray abstraction layers" data-proofer-ignore="" src="https://felixk15.github.io/assets/img/posts/c_ocoa/betray_abstraction.png"></a> <em>Abstraction layers of betray using c_ocoa for calling native APIs</em></p>
<p>Eskil was generous enough to allow me to write about how this problem was solved. Additionally, we decided to make the <a href="#sourcecode">final project completely open-source!</a>.</p>
<p>The result of the endevaour is effectively a C-API which you can use to interact with the Cocoa API. Since there are C bindings for virtually all programming languages out there, you could even use the generated API with</p>
<ul>
<li><a href="https://www.lua.org/pil/26.html" target="_blank" rel="noopener noreferrer">Lua</a></li>
<li><a href="https://docs.python.org/3/extending/extending.html" target="_blank" rel="noopener noreferrer">Python</a></li>
<li><a href="https://blog.appsignal.com/2018/10/30/ruby-magic-building-a-ruby-c-extension-from-scratch.html" target="_blank" rel="noopener noreferrer">Ruby</a></li>
<li>or even <a href="https://medium.com/jspoint/a-simple-guide-to-load-c-c-code-into-node-js-javascript-applications-3fcccf54fd32" target="_blank" rel="noopener noreferrer">Javascript</a>
</li>
</ul>
<p>Yes, that’s right. Cocoa from the web, y’all!</p>
<p>In the end we have an application that shares 95% of it’s code between platforms and has an identical look and feel. <a href="https://felixk15.github.io/assets/img/posts/c_ocoa/zenith_on_devices.png"><img data-src="/assets/img/posts/c_ocoa/zenith_on_devices.png" alt="Zenith on different devices" data-proofer-ignore="" src="https://felixk15.github.io/assets/img/posts/c_ocoa/zenith_on_devices.png"></a> <em>Application running on Android, Windows 11 and iOS</em></p>
<p>Since this is a code generator, another nice bonus is that you can immediately re-generate the C-API when a new ObjC API becomes available. There’s no waiting for the maintainer of a language bindings library to update the code, just re-run the generator and voila, you have the latest API.</p>
<p>Watched the latest WWDC where a new library got presented and want to try it out in your C-only program? Just re-generate and start tinkering!</p>
<h2 id="why-would-you-do-this-just-use-objective-c11">
<span>“Why would you do this? Just use Objective-C!!!11”</span><a href="#why-would-you-do-this-just-use-objective-c11"><i></i></a>
</h2>
<p>Let me start this post by saying that yes, we could’ve used ObjC to be able to use the MacOS and iOS APIs from within the C codebase that was already in place. We decided against it though, because we wanted to have a pure C codebase without any of the weird ObjC code in there. We didn’t want maintainers (who are all mostly familiar with C) to first learn how to parse ObjC and also thought that this would be a cool thing that might also interesting other developers. It was certainly an interesting experience for me since outside some courses in University, I’ve never touched an OSX or iOS development and was also unfamiliar with ObjC and XCode as an IDE.</p>
<h2 id="introducing-the-objective-c-runtime">
<span>Introducing the Objective-C runtime</span><a href="#introducing-the-objective-c-runtime"><i></i></a>
</h2>
<p>Eskil actually gave me the first hint by pointing me towards the ObjC runtime.</p>
<p>Quoting the official documentation it states that <a href="https://developer.apple.com/documentation/objectivec/objective-c_runtime" target="_blank" rel="noopener noreferrer">“The Objective-C runtime is a runtime library that provides support for the dynamic properties of the Objective-C language”</a>. This sounds interesting, but slighty vague, so after taking a closer look at the documentation and the API itself, to see if there’s stuff in there that could be of use for solving this problem, I was delighted to see that there’s stuff like “give me a list of all classes and methods” and, most importantly “call the function with a given name on this object”. Bingo, this is exactly what I was looking for and seems to be a good foundation to build a C API on. Even better: The ObjC runtime itself is even a pure C API!</p>
<h2 id="the-plan">
<span>The plan</span><a href="#the-plan"><i></i></a>
</h2>
<p>The overall plan is to have a C API which, under the hood, uses the ObjC runtime to call functions that are normally only accessible when programming in ObjC.</p>
<p>In praxis this would mean that ObjC code like this:</p>
<div>

<p><code><table><tbody><tr>
<td><pre>1
2
3
4
5
6
7
8
9
10
11
</pre></td>
<td><pre><span>char</span><span>*</span> <span>getClipboardString</span><span>()</span>
<span>{</span>
  <span>UIPasteboard</span> <span>pasteBoard</span> <span>=</span> <span>[</span><span>UIPasteboard</span> <span>generalPasteboard</span><span>];</span>
  <span>NSString</span> <span>pasteBoardContent</span> <span>=</span> <span>[</span><span>pasteBoard</span> <span>string</span><span>];</span>

  <span>NSUInteger</span> <span>length</span> <span>=</span> <span>[</span><span>pasteBoardContent</span> <span>lengthOfBytesUsingEncoding</span><span>:</span><span>NSUTF8StringEncoding</span><span>];</span>
  <span>char</span><span>*</span> <span>pString</span> <span>=</span> <span>(</span><span>char</span><span>*</span><span>)</span><span>malloc</span><span>(</span><span>length</span><span>);</span>

  <span>[</span><span>pasteBoardContent</span> <span>getCString</span><span>:</span><span>pString</span> <span>maxLength</span><span>:</span><span>length</span> <span>encoding</span><span>:</span><span>NSUTF8StringEncoding</span><span>];</span>
  <span>return</span> <span>pString</span><span>;</span>
<span>}</span>
</pre></td>
</tr></tbody></table></code></p>
</div>
<p>could be written like this in C:</p>
<div>

<p><code><table><tbody><tr>
<td><pre>1
2
3
4
5
6
7
8
9
10
11
</pre></td>
<td><pre><span>char</span><span>*</span> <span>getClipboardString</span><span>()</span>
<span>{</span>
  <span>uipasteboard_t</span> <span>pasteBoard</span> <span>=</span> <span>uipasteboard_generalPasteboard</span><span>();</span>
  <span>nsstring_t</span> <span>pasteBoardContent</span> <span>=</span> <span>uipasteboard_string</span><span>(</span> <span>pasteBoard</span> <span>);</span>

  <span>unsigned</span> <span>long</span> <span>length</span> <span>=</span> <span>nsstring_lengthOfBytesUsingEncoding</span><span>(</span> <span>pasteBoardContent</span><span>,</span> <span>NSUTF8StringEncoding</span> <span>);</span>
  <span>char</span> <span>*</span><span>cStr</span> <span>=</span> <span>(</span><span>char</span> <span>*</span><span>)</span><span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>char</span><span>)</span> <span>*</span> <span>(</span><span>uint</span><span>)</span><span>length</span><span>);</span>
  <span>nsstring_getCString</span><span>(</span><span>pasteBoardContent</span><span>,</span> <span>cStr</span><span>,</span> <span>length</span><span>,</span> <span>NSUTF8StringEncoding</span><span>);</span>

  <span>return</span> <span>cStr</span><span>;</span>
<span>}</span>
</pre></td>
</tr></tbody></table></code></p>
</div>
<p>It was clear pretty early on that we’d need some kind of external code-generation tool that would use the ObjC runtime to parse the ObjC APIs and use the parsed information to generate the C API.</p>
<h2 id="the-code-generator">
<span>The code generator</span><a href="#the-code-generator"><i></i></a>
</h2>
<p>Let’s get right into it and talk about the code generator. From a birds-eye-view the code generator is a command-line tool (written in C) which uses the ObjC runtime API to query various data from ObjC APIs and uses this queried data to generate multiple .c/.h files which can be used in a project to interface with these ObjC APIs using normal C functions.</p>
<p>For each ObjC class that you want to create a C API for, the tool basically does these things in order: <a href="https://felixk15.github.io/assets/img/posts/c_ocoa/code_generator_workflow.png"><img data-src="/assets/img/posts/c_ocoa/code_generator_workflow.png" alt="Code Generator Workflow" data-proofer-ignore="" src="https://felixk15.github.io/assets/img/posts/c_ocoa/code_generator_workflow.png"></a> <em>Code Generator Workflow</em></p>
<h3 id="query-objc-class">
<span>Query ObjC Class</span><a href="#query-objc-class"><i></i></a>
</h3>
<p>The first step is to query metadata about the class that we’re interested in turning into a C API. The code generator works by providing it with one or more ObjC class name(s) (optionally including wildcards). For each class the generator generates a pair of .c/.h files.</p>
<p>This is done by first querying for <em>all</em> (see notes about what <em>all</em> actually means) available classes using <a href="https://developer.apple.com/documentation/objectivec/1418579-objc_getclasslist?language=objc" target="_blank" rel="noopener noreferrer"><code>objc_getClassList()</code></a>. The query results will be returned using an opaque type <code>Class</code> which can be used together with <code>class_</code> prefixed functions to query more metadata about a specific class. So the generator first caches all available classes (I’ll later talk about how classes are made visible for the ObjC runtime API) and then compares the name of each class (by using <a href="https://developer.apple.com/documentation/objectivec/1418635-class_getname?language=objc" target="_blank" rel="noopener noreferrer"><code>class_getName()</code></a>) against the input of the user.</p>
<p>Once one ore more matching classes have been found, we move to the next step.</p>
<blockquote><p><em>Note</em>: <em>All</em> available classes depends on what ObjC frameworks are linked at the time the code generator is run. This also means that you can’t generate code for iOS only classes when running the code generator on OSX since you can’t link the iOS frameworks to the OSX app. For generating code for iOS classes, you have to run the code generator on an iOS simulator.</p></blockquote>
<h3 id="flattening-objc-class-hierarchy">
<span>Flattening ObjC Class Hierarchy</span><a href="#flattening-objc-class-hierarchy"><i></i></a>
</h3>
<p>ObjC is an object oriented language, C is not. So we need some way to map ObjC’s “object orientness” to C functions.</p>
<p>For this problem I decided to flatten the class hierarchy of the class that you want to export to C. This is done by using the <a href="https://developer.apple.com/documentation/objectivec/1418498-class_getsuperclass?language=objc" target="_blank" rel="noopener noreferrer"><code>class_getSuperClass()</code></a> function from the ObjC Runtime API - this also returns an object of type <code>Class</code> - same as <code>objc_getClassList()</code> before.</p>
<p>For each class found during the “Query ObjC Class” step, the program needs to recursively move up the class hierarchy, This is an image illustrating the class hierarchy for the class <a href="https://developer.apple.com/documentation/foundation/nsmutablestring?language=objc" target="_blank" rel="noopener noreferrer"><code>NSMutableString</code></a>: <a href="https://felixk15.github.io/assets/img/posts/c_ocoa/class_hierarchy.png"><img data-src="/assets/img/posts/c_ocoa/class_hierarchy.png" alt="Class Hierarchy of NSMutableString" data-proofer-ignore="" src="https://felixk15.github.io/assets/img/posts/c_ocoa/class_hierarchy.png"></a> <em>Class Hierarchy of NSMutableString (The arrow point upwards the class hierarchy)</em></p>
<p>Unlike C++, ObjC does <em>not</em> support multiple inheritance (thank god!), so this process is rather straight-forward.</p>
<p>By using <code>class_getSuperClass()</code>, we can recursively go up the class hierarchy and query the methods of each individual class. Querying the methods of a class is done using the <a href="https://developer.apple.com/documentation/objectivec/1418490-class_copymethodlist?language=objc" target="_blank" rel="noopener noreferrer"><code>class_copyMethodList()</code></a> API - this returns an array of the opaque type <code>Method</code> which can be used to query metadata about a specific method.</p>
<p>The result of this step is an array of methods from the complete class hierarchy. Spoiler: Since we’ll later call the methods using just their name, we don’t have to worry about methods that have been overriden at this point.</p>
<blockquote><p><em>Note</em>: This works for only for <em>non-static</em> methods. To also get the <em>static</em> methods of a class you have to get what’s called the <code>meta-class</code>. This is done by using the <a href="https://developer.apple.com/documentation/objectivec/1418629-object_getclass?language=objc" target="_blank" rel="noopener noreferrer"><code>object_getClass()</code></a> function with a <code>Class</code> object as it’s argument. This returns another object of type <code>Class</code>. This object can be used together with <code>class_copyMethodList()</code> to get the list of static methods.</p></blockquote>
<p>The result of this step are 2 arrays:</p>
<ol>
<li>Array of all <em>static</em> methods</li>
<li>Array of all <em>non-static</em> methods</li>
</ol>
<h3 id="resolving-objc-runtime-types">
<span>Resolving ObjC Runtime Types</span><a href="#resolving-objc-runtime-types"><i></i></a>
</h3>
<p>Before talking about how the metadata of methods is queried, I have to talk about how types are encoded in the ObjC runtime.</p>
<p>When querying argument and/or return types using the ObjC runtime you “only” get back a string. Naively I though that this is just the name of the return type (eg: <code>int</code>, <code>float</code> or <code>NSString</code>) but things are a bit more complicated than that. Basically we have to differentiate between base types (<code>int</code>, <code>char</code>, <code>float</code> etc), user defined POD(plain-old-data) types (your typical structs), references (pointers) and ids (more on that later). For each of these types, the type name from the ObjC runtime has to be parsed differently.</p>
<h4 id="base-types">
<span>Base Types</span><a href="#base-types"><i></i></a>
</h4>
<p>Let’s start with the most simple - base types. Instead of fully qualified type names (like <code>int</code>), the ObjC runtime returns a string with 1 element. Fortunately, there’s a 1:1 mapping between these “ObjC base types” and “C base types”. The mapping listed below is from the <a href="https://opensource.apple.com/source/objc4/objc4-709/runtime/runtime.h.auto.html" target="_blank" rel="noopener noreferrer"><code>objc/runtime.h</code></a> file</p>
<div>

<p><code><table><tbody><tr>
<td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td>
<td><pre><span>#define _C_CHR      'c'
#define _C_UCHR     'C'
#define _C_SHT      's'
#define _C_USHT     'S'
#define _C_INT      'i'
#define _C_UINT     'I'
#define _C_LNG      'l'
#define _C_ULNG     'L'
#define _C_LNG_LNG  'q'
#define _C_ULNG_LNG 'Q'
#define _C_FLT      'f'
#define _C_DBL      'd'
#define _C_BFLD     'b'
#define _C_BOOL     'B'
#define _C_VOID     'v'
</span></pre></td>
</tr></tbody></table></code></p>
</div>
<h4 id="user-defined-structs">
<span>User defined structs</span><a href="#user-defined-structs"><i></i></a>
</h4>
<p>The next type, user defined POD types (struct XY) are a bit more complex. The ObjC runtime returns the type name and the complete layout of the custom type. To drive home what I mean by this, think of a struct like this:</p>
<div>

<p><code><table><tbody><tr>
<td><pre>1
2
3
4
5
6
</pre></td>
<td><pre><span>struct</span> <span>AwesomeType</span>
<span>{</span>
  <span>char</span> <span>a</span><span>;</span>
  <span>int</span> <span>b</span><span>;</span>
  <span>float</span> <span>c</span><span>;</span>
<span>};</span>
</pre></td>
</tr></tbody></table></code></p>
</div>
<p>This type would be encoded by the ObjC runtime like this: <code>{AwesomeType=cif}</code> With the info on how base types are encoded, the part after the equal sign can be parsed as a list of base types. So this is basically <code>AwesomeType = char int float</code>.</p>
<p>This extends to structs within structs as well. So this struct:</p>
<div>

<p><code><table><tbody><tr>
<td><pre>1
2
3
4
5
6
7
8
9
10
11
12
</pre></td>
<td><pre><span>struct</span> <span>Foo</span>
<span>{</span>
  <span>int</span> <span>a</span><span>;</span>
  <span>unsigned</span> <span>int</span> <span>b</span><span>;</span>
  <span>float</span> <span>c</span><span>;</span>
<span>};</span>

<span>struct</span> <span>Boo</span>
<span>{</span>
  <span>double</span> <span>a</span><span>;</span>
  <span>Foo</span> <span>foo</span><span>;</span>
<span>};</span>
</pre></td>
</tr></tbody></table></code></p>
</div>
<p>Would result in this type name for <code>struct Boo</code>: <code>{Boo=d{Foo=iIf}}</code>.</p>
<blockquote><p><em>Note</em>: The first version of the code generator actually re-created all structs that where used as return and argument types but as you might already have guessed, you loose the member name of each struct member. The current version assumes that you use the actual ObjC struct (which are the same as C structs).</p></blockquote>
<h4 id="references">
<span>References</span><a href="#references"><i></i></a>
</h4>
<p>Following this, we have references which are marked with a <code>^</code> preceeding the encoded type name. This is thankfully quite easy to incorporate into the existing type parsing. Care should be taken with opaque types however since they’ll be returned like this: <code>{OpaqueType=}</code> (For reference: Opaque types are types where the caller doesn’t know the type layout).</p>
<h4 id="id">
<span>ID</span><a href="#id"><i></i></a>
</h4>
<p>Finally, we have id - this is actually a <a href="https://developer.apple.com/documentation/objectivec/id" target="_blank" rel="noopener noreferrer">type from the objc runtime API</a>. This is a reference to an ObjC object, unfortunately for this we don’t get any more type information. Looking at this from C, we basically only know that this is a <code>void*</code> and not what type.</p>
<h3 id="collect-objc-method-metadata">
<span>Collect ObjC Method Metadata</span><a href="#collect-objc-method-metadata"><i></i></a>
</h3>
<p>Now that it is established how the types are encoded, we can continue with querying metadata about each individual method.</p>
<p>After the class hierarchy has been flattened, we have generated a list of all methods of the complete class hierarchy. In this step we use this list to query information about each individual method. Things that we’re interested in include the following:</p>
<ol>
<li>Method Name</li>
<li>Return Type</li>
<li>Number of Parameters</li>
<li>Type of Parameters</li>
</ol>
<p>Since we now operate on objects of type <code>Method</code>, we can use the ObjC runtime functions prefixed with <code>method_</code>. The first function that is being used is <a href="https://developer.apple.com/documentation/objectivec/1418758-method_getname?language=objc" target="_blank" rel="noopener noreferrer"><code>method_getName()</code></a> - this is similar to <code>class_getName()</code> and returns a string.</p>
<p>The next function that we can use is <a href="https://developer.apple.com/documentation/objectivec/1418591-method_getreturntype?language=objc" target="_blank" rel="noopener noreferrer"><code>method_getReturnType()</code></a> this returns an ObjC runtime encoded type string (that we know how to parse thanks to <a href="#resolving-objc-runtime-types">the previous chapter</a>). To get the parameter list, <a href="https://developer.apple.com/documentation/objectivec/1418968-method_getnumberofarguments?language=objc" target="_blank" rel="noopener noreferrer"><code>method_getNumberOfArguments()</code></a> together with <a href="https://developer.apple.com/documentation/objectivec/1418607-method_getargumenttype?language=objc" target="_blank" rel="noopener noreferrer"><code>method_getArgumentType()</code></a> can be used. The returned type is also encoded as an ObjC runtime type.</p>
<blockquote><p><em>Note</em>: Unfortunately the name of the arguments can not be queried - until this is solved, the arguments follow a <code>arg0</code>, <code>arg1</code>, <code>arg2</code>, etc naming-scheme.</p></blockquote>
<p>With these information available, we have a complete function signature and now only need to find out how we can do the actual function call.</p>
<h3 id="calling-objc-methods-using-the-objc-runtime">
<span>Calling ObjC Methods Using The ObjC Runtime</span><a href="#calling-objc-methods-using-the-objc-runtime"><i></i></a>
</h3>
<p>For calling ObjC methods various variations of <code>objc_msgSend</code> can be used. I say “various variations” because there are multiple version depending on what kind of return value you expect (this only applies when targeting i386 hosts).</p>
<ol>
<li>
<a href="https://developer.apple.com/documentation/objectivec/1456712-objc_msgsend" target="_blank" rel="noopener noreferrer"><code>objc_msgSend</code></a> for function that return types &lt;= 16 bytes.</li>
<li>
<a href="https://developer.apple.com/documentation/objectivec/1456697-objc_msgsend_fpret" target="_blank" rel="noopener noreferrer"><code>objc_msgSend_fpret</code></a> for float return types.</li>
<li>
<a href="https://developer.apple.com/documentation/objectivec/1456730-objc_msgsend_stret" target="_blank" rel="noopener noreferrer"><code>objc_msgSend_stret</code></a> for functions that return types &gt; 16 bytes.</li>
</ol>
<p>Calculating the size of the return type can be added as part of the pass where the return type is parsed. During code generation, the size and type of the return value can then be used to select the correct <code>objc_msgSend</code> function.</p>
<p>If you look at the definition of any of these function, you’ll see that the first 2 arguments are always <code>ID self</code> and <code>SEL selector</code>. The first argument <code>ID self</code> is a pointer to the object which we want to call this method on (or, in case of static methods, the meta-class). The <code>SEL selector</code> argument is the name of the method at runtime. This can be retrieved by calling <a href="https://developer.apple.com/documentation/objectivec/1418557-sel_registername?language=objc" target="_blank" rel="noopener noreferrer"><code>sel_registerName()</code></a> with the method name as argument (as given by <code>method_getName()</code>).</p>
<blockquote><p><em>Note</em>: The return value of <code>sel_registerName()</code> is cached internally.</p></blockquote>
<h3 id="generate-c-source-code">
<span>Generate C Source Code</span><a href="#generate-c-source-code"><i></i></a>
</h3>
<p>We’re now perfectly set-up to start generating the C source code, which will become the basis of our API.</p>
<p>If you remember from <a href="#flattening-objc-class-hierarchy">the previous chapter</a> we are left with 2 arrays which contain elements of type <code>Method</code> after the class hierarchy has been flattened. One array for static and one array for non-static methods. These arrays are now used to create matching C functions for each individual method.</p>
<p>We do this by using the method meta-data that we’ve collected <a href="#collect-objc-method-metadata">earlier</a>. The result of this step will be matching .h/.c files for each ObjC class that should be exported.</p>
<p>The first step when writing the C source files is always the file prefix. For .h files the prefix is a header guard and a single typedef for syntactic sugar (example for <code>NSString</code>):</p>
<div>

<p><code><table><tbody><tr>
<td><pre>1
2
3
</pre></td>
<td><pre><span>#ifndef C_OCOA_NSSTRING_HEADER
#define C_OCOA_NSSTRING_HEADER
</span><span>typedef</span> <span>nsstring_t</span> <span>void</span><span>*</span><span>;</span>
</pre></td>
</tr></tbody></table></code></p>
</div>
<p>(for .h files there’s also a postfix needed to add the <code>#endif</code> for the header guard).</p>
<p>For .c files this is a couple of defines that change what variation of <code>objc_msgSend</code> is being called based on the target ABI (since this could theoretically be x86 or ARM). To make the generated C code work on both architectures, these defines are added at the beginning of every .c file:</p>
<div>

<p><code><table><tbody><tr>
<td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td>
<td><pre><span>#ifdef __arm64__
#define abi_objc_msgSend_stret objc_msgSend
#else
#define abi_objc_msgSend_stret objc_msgSend_stret
#endif
#ifdef __i386__
#define abi_objc_msgSend_fpret objc_msgSend_fpret
#else
#define abi_objc_msgSend_fpret objc_msgSend
#endif
</span></pre></td>
</tr></tbody></table></code></p>
</div>
<blockquote><p><em>Note</em>: this means that instead of <code>objc_msgSend_stret</code> and <code>objc_msgSend_fpret</code> we need to use <code>abi_objc_msgSend_stret</code> &amp; <code>abi_objc_msgSend_fpret</code> respectively.</p></blockquote>
<p>For each C function we first call <code>sel_registerName()</code> to get the correct selector for the method that we want to call. After that we have to make the call to <code>objc_msgSend()</code> to perform the actual function call.</p>
<blockquote><p><em>Note</em>: Since all the <code>objc_msgSend</code> function are typless, they need to be cast to the correct function-ptr type to be called with the correct arguments. This will be done using a “synctactic-sugar” helper-macro for better readability and debugability.</p></blockquote>
<h4 id="example">
<span>Example</span><a href="#example"><i></i></a>
</h4>
<p>To give a concrete example let’s focus on the source code generation of the <code>NSString</code> class with one method, <a href="https://developer.apple.com/documentation/foundation/nsstring/1415702-getcstring?language=objc" target="_blank" rel="noopener noreferrer"><code>getCString()</code></a></p>
<p>The function declaration in Objective-C for that function looks like this:</p>
<div>

<p><code><table><tbody><tr>
<td><pre>1
2
3
4
5
6
7
</pre></td>
<td><pre><span>@interface</span> <span>NSString</span> <span>:</span> <span>NSSObject</span>

<span>-</span> <span>(</span><span>BOOL</span><span>)</span><span>getCString</span><span>:(</span><span>char</span> <span>*</span><span>)</span><span>buffer</span> 
        <span>maxLength</span><span>:(</span><span>NSUInteger</span><span>)</span><span>maxBufferCount</span> 
        <span>encoding</span><span>:(</span><span>NSStringEncoding</span><span>)</span><span>encoding</span><span>;</span>

<span>@end</span>
</pre></td>
</tr></tbody></table></code></p>
</div>
<div>

<p><code><table><tbody><tr>
<td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td>
<td><pre><span>// Usage-Code:</span>
<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>**</span> <span>argv</span><span>)</span>
<span>{</span>
  <span>NSString</span><span>*</span> <span>string</span> <span>=</span> <span>[[</span><span>NSString</span> <span>alloc</span><span>]</span> <span>init</span><span>];</span>
  <span>//Fill string with data...</span>
  <span>//..</span>
  <span>char</span> <span>buffer</span><span>[</span><span>512</span><span>];</span>
  <span>[</span><span>string</span> <span>getCstring</span><span>:</span><span>buffer</span> <span>maxLength</span><span>:</span><span>512</span> <span>encoding</span><span>:</span><span>NSUTF8StringEncoding</span><span>]</span>
<span>}</span>

</pre></td>
</tr></tbody></table></code></p>
</div>
<p>Using the information provided earlier, the generated c_ocoa .h/.c file(s) would look like this (including usage-code):</p>
<div>

<p><code><table><tbody><tr>
<td><pre>1
2
3
4
5
6
7
8
</pre></td>
<td><pre><span>// nsstring.h</span>
<span>#ifndef C_OCOA_NSSTRING_HEADER
#define C_OCOA_NSSTRING_HEADER
</span><span>typedef</span> <span>nsstring_t</span> <span>void</span><span>*</span><span>;</span>

<span>bool</span> <span>nsstring_getCString</span><span>(</span> <span>nsstring_t</span> <span>object</span><span>,</span> <span>char</span><span>*</span> <span>arg0</span><span>,</span> <span>unsigned</span> <span>long</span> <span>long</span> <span>arg1</span><span>,</span> <span>unsigned</span> <span>long</span> <span>long</span> <span>arg2</span> <span>);</span>

<span>#endif
</span></pre></td>
</tr></tbody></table></code></p>
</div>
<div>

<p><code><table><tbody><tr>
<td><pre>1
2
3
4
5
6
7
8
9
10
11
</pre></td>
<td><pre><span>// nsstring.c</span>
<span>#include</span> <span>"nsstring.h"</span><span>
</span>
<span>bool</span> <span>nsstring_getCString</span><span>(</span> <span>nsstring_t</span> <span>object</span><span>,</span> <span>char</span><span>*</span> <span>arg0</span><span>,</span> <span>unsigned</span> <span>long</span> <span>long</span> <span>arg1</span><span>,</span> <span>unsigned</span> <span>long</span> <span>long</span> <span>arg2</span> <span>)</span>
<span>{</span>
	<span>SEL</span> <span>methodSelector</span> <span>=</span> <span>sel_registerName</span><span>(</span> <span>"getCString:maxLength:encoding:"</span> <span>);</span>

	<span>#define nsstring_getCString_call( obj, selector, arg0, arg1, arg2 ) ((bool (*)( id, SEL, char*, unsigned long long, unsigned long long ))objc_msgSend) ( obj, selector, arg0, arg1, arg2 )
</span>	<span>return</span> <span>nsstring_getCString_call</span><span>(</span> <span>(</span><span>id</span><span>)</span><span>object</span><span>,</span> <span>methodSelector</span><span>,</span> <span>arg0</span><span>,</span> <span>arg1</span><span>,</span> <span>arg2</span> <span>);</span>
	<span>#undef nsstring_getCString_call
</span><span>}</span>
</pre></td>
</tr></tbody></table></code></p>
</div>
<div>

<p><code><table><tbody><tr>
<td><pre>1
2
3
4
5
6
7
8
9
</pre></td>
<td><pre><span>// Usage-Code:</span>
<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>**</span> <span>argv</span><span>)</span>
<span>{</span>
  <span>nsstring_t</span> <span>string</span> <span>=</span> <span>nsstring_alloc</span><span>(</span> <span>nsstring_init</span><span>()</span> <span>);</span>
  <span>//Fill string with data...</span>
  <span>//..</span>
  <span>char</span> <span>buffer</span><span>[</span><span>512</span><span>];</span>
  <span>nsstring_getCString</span><span>(</span><span>string</span><span>,</span> <span>buffer</span><span>,</span> <span>512</span><span>,</span> <span>NSUTF8StringEncoding</span><span>);</span>
<span>}</span>
</pre></td>
</tr></tbody></table></code></p>
</div>
<h2 id="conclusion">
<span>Conclusion</span><a href="#conclusion"><i></i></a>
</h2>
<p>Generating a pure C API to interface with the OSX/iOS system APIs was a very interesting problem for me personally since it gave me an excuse to work with ObjC and get to know some internals of the language. This was definitely a big undertaking and, to be honest, I expected it to fail at any moment because of some problem(s) that we didn’t foresee. But fortunately everything worked out pretty nicely and it was definitely a scary feeling letting the generator work through the <em>entire</em> class hierarchy of big frameworks like <strong>AppKit</strong>, <strong>Foundation</strong> or <strong>GLKit</strong>. That being said we did hit a couple of problems that we’re actively working on, namely parameter naming and adding auto-generated documentation to the various functions. But all in all the result is pretty cool and we were able to ship an iOS application using the technology.</p>
<h2 id="sourcecode">
<span>Sourcecode</span><a href="#sourcecode"><i></i></a>
</h2>
<p>The entire source code of the code generator has been made open source and can be <a href="https://github.com/FelixK15/c_ocoa" target="_blank" rel="noopener noreferrer">accessed on github</a>. Follow the README in the repository to build the generator locally.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[X sues Calif. to avoid revealing how it makes “controversial” content decisions (173 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2023/09/x-sues-calif-to-avoid-revealing-how-it-makes-controversial-content-decisions/</link>
            <guid>37467607</guid>
            <pubDate>Mon, 11 Sep 2023 14:15:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2023/09/x-sues-calif-to-avoid-revealing-how-it-makes-controversial-content-decisions/">https://arstechnica.com/tech-policy/2023/09/x-sues-calif-to-avoid-revealing-how-it-makes-controversial-content-decisions/</a>, See on <a href="https://news.ycombinator.com/item?id=37467607">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      "Rebranding censorship"    —
</h4>
            
            <h2 itemprop="description">X decried law's "draconian financial penalties," up to $15K per violation per day.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/09/GettyImages-1563274899-800x532.jpg" alt="X sues Calif. to avoid revealing how it makes “controversial” content decisions">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 35:single/related:c4dbb0a9ea6a9aff2f1f0298bc009002 --><!-- empty -->
<p>Today, Elon Musk's X Corp. <a href="https://cdn.arstechnica.net/wp-content/uploads/2023/09/X-Corp-v-Bonta-9-8-2023-Complaint.pdf">sued</a> to block California's content moderation law, AB 587. In its complaint, filed in a US district court in California, X Corp. is seeking a preliminary and permanent injunction stopping California Attorney General Robert Bonta from enforcing the law.</p>
<p>AB 587 passed in September 2022, requiring social media platforms to submit a "terms of service report" semi-annually to California's attorney general, providing "a detailed description of content moderation practices used" and "information about whether, and if so how, the social media company defines and moderates" hate speech or racism, extremism or radicalization, disinformation or misinformation, harassment, and foreign political interference. Under the law, social media platforms must also provide information and statistics on any content moderation actions taken in those categories.</p>
<p>In X's complaint, the company accused California of trying to dictate X's terms of service and compel "controversial disclosures about how X Corp. moderates content on its platform."</p>
<p>The law stipulated that all platforms were required to start collecting data for their first terms of service report covering content moderation during the third quarter of 2023 and submit those reports to Bonta by January 1, 2024.</p>
<p>Platforms could be found violating the law for failing to post terms of service about content moderation, missing a deadline to submit a terms of service report, or materially omitting or misrepresenting information about content moderation. Any platform violating the law risks fines—which X described as "draconian financial penalties"—up to $15,000 per violation per day.</p>
<p>In its complaint, X Corp. argued that AB 587 violates the First Amendment by compelling "companies like X Corp. to engage in speech against their will" and "impermissibly" interfering "with the constitutionally protected editorial judgments of companies." X Corp. said that if the court did not block the law, California could pressure companies "to remove, demonetize, or deprioritize constitutionally protected speech that the state deems undesirable or harmful."</p>
<p>"The State of California touts AB 587 as a mere 'transparency measure' under which certain social media companies must make their content moderation policies and statistics publicly&nbsp;available," X's complaint said. But, X alleged, the state's "true intent" is "to pressure social media platforms to 'eliminate' certain constitutionally protected content viewed by the state as problematic."</p>                                            
                                                        
<p>X Corp. alleged that AB 587 violates other laws, including the Dormant Commerce Clause—"failing to restrict its extensive reporting requirements to information about Californians"—and Section 230 of the Communications Decency Act—which grants platforms immunity from liability for “any action voluntarily taken in good faith to restrict access to or availability of material that the provider or user considers to be obscene, lewd, lascivious, filthy, excessively violent, harassing, or otherwise objectionable, whether or not such material is constitutionally protected.”</p>
<p>"Because AB 587 imposes liability on such actions if they are taken without the required disclosures, AB 587 is preempted by the broad immunity afforded by Section 230," X's complaint said.</p>
<p>Ars could not immediately reach X for comment. Bonta's office said: “While we have not yet been served with the complaint, we will review it and respond in court.”</p>
<p>The author of AB 587, California assemblymember Jesse Gabriel, released a statement saying that the law "is a pure transparency measure that simply requires companies to be upfront about if and how they are moderating content. It in no way requires any specific content moderation policies—which is why it passed with strong, bipartisan support. If Twitter has nothing to hide, then they should have no objection to this bill.”</p>
<p>But tech groups and policy experts echoed X's concerns over AB 587.</p>
<p>Adam Kovacevich, the CEO of the tech industry policy coalition Chamber of Progress, said that "requiring companies to give their content moderation playbook to scammers and conspiracists is a bad idea."</p>
<p>“Even if you don't like anything about Elon Musk’s leadership of X, it’s clear that requiring tech platforms to publish a detailed blueprint of how to work around content moderators will have negative consequences for users online," Kovacevich said. "Letting platforms set their own editorial standards also leaves consumers with more choices about what kind of platforms they spend time on.”</p>
<p>Netchoice, a group representing tech companies and trade associations, has called AB 587 "the Golden State’s new online censorship law." In a statement about X Corp.'s lawsuit, Netchoice said that the law would force companies to submit "intrusive" and "often impossible to comply with" disclosures "about constitutionally protected editorial decisions." Netchoice's director of litigation, Chris Marchese, said that the court should enjoin AB 587 to protect free speech online.</p>
<p>“The First Amendment prohibits the government from regulating lawful speech—directly or indirectly," Marchese said. "States cannot avoid this prohibition by rebranding censorship as ‘transparency’ requirements."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia’s AI supremacy is only temporary (157 pts)]]></title>
            <link>https://petewarden.com/2023/09/10/why-nvidias-ai-supremacy-is-only-temporary/</link>
            <guid>37467585</guid>
            <pubDate>Mon, 11 Sep 2023 14:13:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://petewarden.com/2023/09/10/why-nvidias-ai-supremacy-is-only-temporary/">https://petewarden.com/2023/09/10/why-nvidias-ai-supremacy-is-only-temporary/</a>, See on <a href="https://news.ycombinator.com/item?id=37467585">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						
<figure><a href="https://petewarden.files.wordpress.com/2023/09/dallc2b7e-2023-09-09-18.43.21-computer-chips-running-in-a-foot-race.png"><img data-attachment-id="7833" data-permalink="https://petewarden.com/2023/09/10/why-nvidias-ai-supremacy-is-only-temporary/dallc2b7e-2023-09-09-18-43-21-computer-chips-running-in-a-foot-race/" data-orig-file="https://petewarden.files.wordpress.com/2023/09/dallc2b7e-2023-09-09-18.43.21-computer-chips-running-in-a-foot-race.png" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="dallc2b7e-2023-09-09-18.43.21-computer-chips-running-in-a-foot-race" data-image-description="" data-image-caption="" data-medium-file="https://petewarden.files.wordpress.com/2023/09/dallc2b7e-2023-09-09-18.43.21-computer-chips-running-in-a-foot-race.png?w=300" data-large-file="https://petewarden.files.wordpress.com/2023/09/dallc2b7e-2023-09-09-18.43.21-computer-chips-running-in-a-foot-race.png?w=550" src="https://petewarden.files.wordpress.com/2023/09/dallc2b7e-2023-09-09-18.43.21-computer-chips-running-in-a-foot-race.png?w=1024" alt="" srcset="https://petewarden.files.wordpress.com/2023/09/dallc2b7e-2023-09-09-18.43.21-computer-chips-running-in-a-foot-race.png 1024w, https://petewarden.files.wordpress.com/2023/09/dallc2b7e-2023-09-09-18.43.21-computer-chips-running-in-a-foot-race.png?w=150 150w, https://petewarden.files.wordpress.com/2023/09/dallc2b7e-2023-09-09-18.43.21-computer-chips-running-in-a-foot-race.png?w=300 300w, https://petewarden.files.wordpress.com/2023/09/dallc2b7e-2023-09-09-18.43.21-computer-chips-running-in-a-foot-race.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Nvidia is an amazing company that has executed a contrarian vision for decades, and has rightly become one of the most valuable corporations on the planet thanks to its central role in the AI revolution. I want to explain why I believe it’s top spot in machine learning is far from secure over the next few years. To do that, I’m going to talk about some of the drivers behind Nvidia’s current dominance, and then how they will change in the future.</p>



<h2><span>Currently</span></h2>



<p>Here’s why I think Nvidia is winning so hard right now.</p>



<p><strong>#1 – Almost Nobody is Running Large ML Apps</strong></p>



<p>Outside of a few large tech companies, very few corporations have advanced to actually running large scale AI models in production. They’re still figuring out how to get started with these new capabilities, so the main costs are around dataset collection, hardware for training, and salaries for model authors. This means that machine learning is focused on training, not inference.</p>



<p><strong>#2 – All Nvidia Alternatives Suck</strong></p>



<p>If you’re a developer creating or using ML models, using an Nvidia GPU is a lot easier and less time consuming than an AMD OpenCL card, Google TPU, a Cerebras system, or any other hardware. The software stack is much more mature, there are many more examples, documentation, and other resources, finding engineers experienced with Nvidia is much easier, and integration with all of the major frameworks is better. There is no realistic way for a competitor to beat the platform effect Nvidia has built. It makes sense for the current market to be winner-takes-all, and they’re the winner, full stop.</p>



<p><strong>#3 – Researchers have the Purchasing Power</strong></p>



<p>It’s incredibly hard to hire ML researchers, anyone with experience has their pick of job offers right now. That means they need to be kept happy, and one of the things they demand is use of the Nvidia platform. It’s what they know, they’re productive with it, picking up an alternative would take time and not result in skills the job market values, whereas working on models with the tools they’re comfortable with does. Because researchers are so expensive to hire and retain, their preferences are given a very high priority when purchasing hardware.</p>



<p><strong>#4 – Training Latency Rules</strong></p>



<p>As a rule of thumb models need to be trainable from scratch in about a week. I’ve seen this hold true since the early days of AlexNet, because if the iteration cycle gets any longer it’s very hard to do the empirical testing and prototyping that’s still essential to reach your accuracy goals. As hardware gets faster, people build bigger models up until the point that the training once again takes roughly the same amount of time, and reap the benefits through higher-quality models rather than reduced total training time. This makes buying the latest Nvidia GPUs very attractive, since your existing code will mostly just work, but faster. In theory there’s an opportunity here for competitors to win with lower latency, but the inevitably poor state of their software stack (CUDA has had decades of investment) means it’s mostly an illusion.</p>



<h2><strong>What’s going to change?</strong></h2>



<p>So, hopefully I’ve made a convincing case that there are strong structural reasons behind Nvidia’s success. Here’s how I see those conditions changing over the next few years.</p>



<p><strong>#1 – Inference will Dominate, not Training</strong></p>



<p>Somebody years ago told me “Training costs scale with the number of researchers, inference costs scale with the number of users”. What I took away from this is that there’s some point in the future where the amount of compute any company is using for running models on user requests will exceed the cycles they’re spending on training. Even if the cost of a single training run is massive and running inference is cheap, there are so many potential users in the world with so many different applications that the accumulated total of those inferences will exceed the training total. There are only ever going to be so many researchers.</p>



<p>What this means for hardware is that priorities will shift towards reducing inference costs. A lot of ML researchers see inference as a subset of training, but this is wrong in some fundamental ways. It’s often very hard to assemble a sizable batch of inputs during inference, because that process trades off latency against throughput, and latency is almost always key in user-facing applications. Small or single-input batches change the workload dramatically, and call for very different optimization approaches. There are also a lot of things (like the weights) that remain constant during inference, and so can benefit from pre-processing techniques like weight compression or constant folding.</p>



<p><strong>#2 – CPUs are Competitive for Inference </strong></p>



<p>I didn’t even list CPUs in the Nvidia alternatives above because they’re still laughably slow for training. The main desktop CPUs (x86, Arm, and maybe RISC-V soon) have the benefit of many decades of toolchain investment. They have an even more mature set of development tools and community than Nvidia. They can also be much cheaper per arithmetic op than any GPU.</p>



<p>Old-timers will remember the early days of the internet when most of the cost of setting up a dot-com was millions of dollars for a bunch of high-end web server hardware from someone like Sun. This was because they were the only realistic platform that could serve web pages reliably and with low-latency. They had the fastest hardware money could buy, and that was important when entire sites needed to fit on a single machine. Sun’s market share was rapidly eaten by the introduction of software that could distribute the work across a large number of individually much less capable machines, commodity x86 boxes that were far cheaper.</p>



<p>Training is currently very hard to distribute in a similar way. The workloads make it possible to split work across a few GPUs that are tightly interconnected, but the pattern of continuous updates makes reducing latency by sharding across low-end CPUs unrealistic. This is not true for inference though. The model weights are fixed and can easily be duplicated across a lot of machines at initialization time, so no communication is needed. This makes an army of commodity PCs very appealing for applications relying on ML inference.</p>



<p><strong>#3 – Deployment Engineers gain Power</strong></p>



<p>As inference costs begin to dominate training, there will be a lot of pressure to reduce those costs. Researchers will no longer be the highest priority, so their preferences will carry less weight. They will be asked to do things that are less personally exciting in order to streamline production. There are also going to be a lot more people capable of training models coming into the workforce over the next few years, as the skills involved become more widely understood. This all means researchers’ corporate power will shrink and the needs of the deployment team will be given higher priority.</p>



<p><strong>#4 – Application Costs Rule</strong></p>



<p>When inference dominates the overall AI budget, the hardware and workload requirements are very different. Researchers value the ability to quickly experiment, so they need flexibility to prototype new ideas. Applications usually change their models comparatively infrequently, and may use the same fundamental architecture for years, once the researchers have come up with something that meets their needs. We may almost be heading towards a world where model authors use a specialized tool, like Matlab is for mathematical algorithms, and then hand over the results to deployment engineers who will manually convert the results into something more efficient for an application. This will make sense because any cost savings will be multiplied over a long period of time if the model architecture remains constant (even if the weights change).</p>



<h2>What does this Mean for the Future?</h2>



<p>If you believe my four predictions above, then it’s hard to escape the conclusion that Nvidia’s share of the overall AI market is going to drop. That market is going to grow massively so I wouldn’t be surprised if they continue to grow in absolute unit numbers, but I can’t see how their current margins will be sustainable.</p>



<p>I expect the winners of this shift will be traditional CPU platforms like x86 and Arm. Inference will need to be tightly integrated into traditional business logic to run end user applications, so it’s difficult to see how even hardware specialized for inference can live across a bus, with the latency involved. Instead I expect CPUs to gain much more tightly integrated machine learning support, first as co-processors and eventually as specialized instructions, like the evolution of floating point support.</p>



<p>On a personal level, these beliefs drive my own research and startup focus. The impact of improving inference is going to be so high over the next few years, and it still feels neglected compared to training. There are signs that this is changing though. Communities like <a href="https://www.reddit.com/r/LocalLLaMA/">r/LocalLlama</a> are mostly focused on improving inference, the success of <a href="https://github.com/ggerganov/ggml">GGML</a> shows how much of an appetite there is for inference-focused frameworks, and the spread of a few general-purpose models increases the payoff of inference optimizations. One reason I’m so obsessed with the edge is that it’s the closest environment to the army of commodity PCs that I think will run most cloud AI in the future. Even back in 2013 I originally wrote <a href="https://github.com/jetpacapp/DeepBeliefSDK">the Jetpac SDK</a> to accelerate computer vision on a cluster of 100 m1.small AWS servers, since that was cheaper and faster than a GPU instance for running inference across millions of images. It was only afterwards that I realized what a good fit it was for mobile devices.</p>



<p>I’d love to hear your thoughts on whether inference is going to be as important as I’m predicting! Let me know in the comments if you think I’m onto something, or if I should be stocking up on Nvidia stock.</p>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[9/11 in Realtime (199 pts)]]></title>
            <link>https://911realtime.org:443/</link>
            <guid>37467077</guid>
            <pubDate>Mon, 11 Sep 2023 13:38:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://911realtime.org:443/">https://911realtime.org:443/</a>, See on <a href="https://news.ycombinator.com/item?id=37467077">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <li> <h2>9/11 Realtime</h2> <p><b>Thanks and Open Source Notices</b></p> <h2>Thank you to our backers:</h2> <ul> <li>Will Harris</li> <li>Chris Wooster</li> <li>Robinson Collado</li> <li>Richard Harms</li> <li>Matt MG Herron</li> <li>Adil Majid</li> <li>Alana Malone</li> <li>Kori Stephens</li> <li>Marina Harper</li> <li>James Wendel</li> <li>Jason Smith</li> <li>Adam Garst</li> <li>Andrew Poirier</li> <li>Ty Satrang</li> </ul> <h2>Special thanks to <a href="http://hivelocity.net/">Hivelocity</a></h2> <p><b>Based on Platinum by Robbie Byrd</b></p> <p>A UI framework using native CSS/JS replications of the Mac OS 8.1 interface components. The project is named after the interface theme that came with MacOS 8 and 9, Platinum.</p> <p><a href="https://github.com/robbiebyrd/platinum" target="_blank">Platinum on Github</a></p> <p><b>Based on memento.js by Vijith Assar</b></p> <p><a href="https://github.com/vijithassar/memento" target="_blank">memento.js on Github</a></p> <p> Based on <b><a href="https://github.com/npjg/classic.css" target="_blank">New Dawn</a></b> by <b><a href="https://github.com/npjg" target="_blank">Nathanael Gentry</a></b>. </p><p>Copyright (c) 2019 Nathanael Gentry</p>  <p> Based on <b><a href="https://github.com/ticky/classic-scrollbars" target="_blank">Scrollbars of the Classic Mac OS</a></b> by <b><a href="https://github.com/ticky" target="_blank">Jessica Stokes (@ticky)</a></b>. </p> <hr> <p><b>New Dawn</b> and <b>Platinum</b> License</p> <div><p> MIT License </p><p>  Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: </p></div> <div><p> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. </p><p>  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. </p></div> <p>A huge thanks to Apple, Inc., who maintains the copyright on the Apple Icon, background patterns, interface sounds and interface components.</p>  </li> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unix Domain Sockets vs Loopback TCP Sockets (2014) (112 pts)]]></title>
            <link>https://nicisdigital.wordpress.com/2014/03/03/unix-domain-sockets-vs-loopback-tcp-sockets/</link>
            <guid>37466475</guid>
            <pubDate>Mon, 11 Sep 2023 12:51:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nicisdigital.wordpress.com/2014/03/03/unix-domain-sockets-vs-loopback-tcp-sockets/">https://nicisdigital.wordpress.com/2014/03/03/unix-domain-sockets-vs-loopback-tcp-sockets/</a>, See on <a href="https://news.ycombinator.com/item?id=37466475">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
       <p>Two communicating processes on a single machine have a few options. They can use regular TCP sockets, UDP sockets, unix domain sockets, or shared memory. A recent project I was working on used Node.js with two communicating processes on the same machine. I wanted to know how to reduce the CPU utilization of the machine, so I ran a few experiments to compare the efficiency between unix domain sockets and TCP sockets using the loopback interface. This post covers my experiments and test results.</p>
<p>First off, is a disclaimer. This test is not exhaustive. Both client and server are written in Node.js and can only be as efficient as the Node.js runtime.</p>
<p>All code in this post is available at:&nbsp;<a href="http://github.com/nicmcd/uds_vs_tcp">github.com/nicmcd/uds_vs_tcp</a></p>
<h2>Server Application</h2>
<p>I created a simple Node.js server application that could be connected to via TCP socket or Unix domain socket. It simply echos all received messages. Here is the code:</p>
<pre title="">var assert = require('assert');
assert(process.argv.length == 4, 'node server.js &lt;tcp port&gt; &lt;domain socket path&gt;');

var net = require('net');

var tcpPort = parseInt(process.argv[2]);
assert(!isNaN(tcpPort), 'bad TCP port');
console.log('TCP port: ' + tcpPort);

var udsPath = process.argv[3];
console.log('UDS path: ' + udsPath);

function createServer(name, portPath) {
    var server = net.createServer(function(socket) {
        console.log(name + ' server connected');
        socket.on('end', function() {
            console.log(name + ' server disconnected');
        });
        socket.write('start sending now!');
        socket.pipe(socket);
    });
    server.listen(portPath, function() {
        console.log(name + ' server listening on ' + portPath);
    });
}

var tcpServer = createServer('TCP', tcpPort);
var udsServer = createServer('UDS', udsPath);
</pre>
<h2>Client Application</h2>
<p><span>The client application complements the server application. It connects to the server via TCP or Unix domain sockets. It sends a bunch of randomly generated packets and measures the time it takes to finish. When complete, it prints the time and exits. Here is the code:</span></p>
<pre title="">var assert = require('assert');
assert(process.argv.length == 5, 'node client.js &lt;port or path&gt; &lt;packet size&gt; &lt;packet count&gt;');

var net = require('net');
var crypto = require('crypto');

if (isNaN(parseInt(process.argv[2])) == false)
    var options = {port: parseInt(process.argv[2])};
else
    var options = {path: process.argv[2]};
console.log('options: ' + JSON.stringify(options));

var packetSize = parseInt(process.argv[3]);
assert(!isNaN(packetSize), 'bad packet size');
console.log('packet size: ' + packetSize);

var packetCount = parseInt(process.argv[4]);
assert(!isNaN(packetCount), 'bad packet count');
console.log('packet count: ' + packetCount);

var client = net.connect(options, function() {
    console.log('client connected');
});

var printedFirst = false;
var packet = crypto.randomBytes(packetSize).toString('base64').substring(0,packetSize);
var currPacketCount = 0;
var startTime;
var endTime;
var delta;
client.on('data', function(data) {
    if (printedFirst == false) {
        console.log('client received: ' + data);
        printedFirst = true;
    }
    else {
        currPacketCount += 1;
        if (data.length != packetSize)
            console.log('weird packet size: ' + data.length);
        //console.log('client received a packet: ' + currPacketCount);
    }

    if (currPacketCount &lt; packetCount) {
        if (currPacketCount == 0) {
            startTime = process.hrtime();
        }
        client.write(packet);
    } else {
        client.end();
        endTime = process.hrtime(startTime);
        delta = (endTime[0] * 1e9 + endTime[1]) / 1e6;
        console.log('millis: ' + delta);
    }
});
</pre>
<h2>Running a Single Test</h2>
<p>First start the server application with:</p>
<pre title="">node server.js 5555 /tmp/uds
</pre>
<p>This starts the server using TCP port 5555 and Unix domain socket /tmp/uds.</p>
<p>Now we can run the client application to get some statistics. Let’s first try the TCP socket. Run the client with:</p>
<pre title="">
node client.js 5555 1000 100000

</pre>
<p>This runs the client application using TCP port 5555 and sends 100,000 packets all sized 1000 bytes. This tooks 8006 milliseconds on my machine. We can now try running with the Unix domain socket with:</p>
<pre title="">
node client.js /tmp/uds 1000 100000

</pre>
<p>This runs the client the same as before except it uses the /tmp/uds Unix domain socket instead of the TCP socket. On my machine this took 3570 milliseconds to run. These two runs show that for 1k byte packets, Unix domain sockets are about 2-3x more efficient than TCP sockets.<br>
At this point you might be completely convinced that Unix domain sockets are better and you’ll use them whenever you can. That’s too easy. Let’s run the client application a whole bunch of times and graph the results.<br>
I recently posted about a <a title="taskrun – An easy-to-use python package for running tasks with dependencies and process&nbsp;management" href="https://nicisdigital.wordpress.com/2013/12/13/taskrun/">python package</a> I created for running many tasks and aggregating the data. I thought this socket comparison would make a good example.</p>
<h2>Running the Full Test</h2>
<p>As mentioned, running the full test uses the Taskrun Python package (available at <a title="Taskrun Python Package" href="http://github.com/nicmcd/taskrun">github.com/nicmcd/taskrun</a>). The script I quickly hacked together to run the client application and parse the results is as follows:</p>
<pre title="">
import taskrun
import os

POWER = 15
RUNS = 10
PACKETS_PER_RUN = 100000

manager = taskrun.Task.Manager(
    numProcs = 1,
    showCommands = True,
    runTasks = True,
    showProgress = True)

DIR = "sims"
mkdir = manager.task_new('dir', 'rm -rI ' + DIR + '; mkdir ' + DIR)

def makeName(stype, size, run):
    return stype + '_size' + str(size) + '_run' + str(run)

def makeCommand(port_or_path, size, name):
    return 'node client.js ' + port_or_path + ' ' + str(size) + ' ' + str(PACKETS_PER_RUN) + \
        ' | grep millis | awk \'{printf "%s, ", $2}\' &gt; ' + os.path.join(DIR, name)

barrier1 = manager.task_new('barrier1', 'sleep 0')
for exp in range(0, POWER):
    size = pow(2, exp)
    for run in range(0, RUNS):
        # Unix domain socket test
        name = makeName('uds', size, run)
        task = manager.task_new(name, makeCommand('/tmp/uds', size, name))
        task.dependency_is(mkdir)
        barrier1.dependency_is(task)

        # TCP socket test
        name = makeName('tcp', size, run)
        task = manager.task_new(name, makeCommand('5555', size, name))
        task.dependency_is(mkdir)
        barrier1.dependency_is(task)

# create CSV header
filename = os.path.join(DIR, 'uds_vs_tcp.csv')
header = 'NAME, '
for run in range(0, RUNS):
    header += 'RUN ' + str(run) + ', '
hdr_task = manager.task_new('CSV header', 'echo \'' + header + '\' &gt; ' + filename)
hdr_task.dependency_is(barrier1)

# UDS to CSV
cmd = ''
for exp in range(0,POWER):
    size = pow(2, exp)
    cmd += 'echo -n \'UDS Size ' + str(size) + ', \' &gt;&gt; ' + filename + '; '
    for run in range(0, RUNS):
        name = makeName('uds', size, run)
        cmd += 'cat ' + os.path.join(DIR, name) + ' &gt;&gt; ' + filename + '; '
    cmd += 'echo \'\' &gt;&gt; ' + filename + '; '
uds_task = manager.task_new('UDS to CSV', cmd)
uds_task.dependency_is(hdr_task)

# TCP to CSV
cmd = ''
for exp in range(0,POWER):
    size = pow(2, exp)
    cmd += 'echo -n \'TCP Size ' + str(size) + ', \' &gt;&gt; ' + filename + '; '
    for run in range(0, RUNS):
        name = makeName('tcp', size, run)
        cmd += 'cat ' + os.path.join(DIR, name) + ' &gt;&gt; ' + filename + '; '
    cmd += 'echo \'\' &gt;&gt; ' + filename + '; '
tcp_task = manager.task_new('TCP to CSV', cmd)
tcp_task.dependency_is(uds_task)

manager.run_request_is()

</pre>
<p>Admittedly, this isn’t the prettiest code to look at, but it gets the job done. For both Unix domain socket and TCP socket, it runs the client application for all packet sizes that are a power of 2 from 1 to 16384. Each setup is run 10 times. Each test result is written to its own file. After all the tests have been run, the taskrun script creates a CSV file using all the test results. The CSV file can then be imported into a spreadsheet application for analysis.</p>
<h2>Results</h2>
<p>I ran this on an&nbsp;<a href="http://ark.intel.com/products/75789/">Intel E5-2620 v2</a>&nbsp;processor with 16GB of RAM. I imported the CSV into Excel, averaged the 10 results of each setup, then graphed the results. This first graph shows the execution time compared to packet size on a logarithmic graph.</p>
<p><a href="https://nicisdigital.files.wordpress.com/2014/03/exe-time-vs-pkt-size.png"><img data-attachment-id="604" data-permalink="https://nicisdigital.wordpress.com/2014/03/03/unix-domain-sockets-vs-loopback-tcp-sockets/exe-time-vs-pkt-size/" data-orig-file="https://nicisdigital.files.wordpress.com/2014/03/exe-time-vs-pkt-size.png" data-orig-size="966,611" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Execution Time vs. Packet Size" data-image-description="" data-image-caption="" data-medium-file="https://nicisdigital.files.wordpress.com/2014/03/exe-time-vs-pkt-size.png?w=300" data-large-file="https://nicisdigital.files.wordpress.com/2014/03/exe-time-vs-pkt-size.png?w=510" alt="Execution Time vs. Packet Size" src="https://nicisdigital.files.wordpress.com/2014/03/exe-time-vs-pkt-size.png?w=510&amp;h=322" width="510" height="322" srcset="https://nicisdigital.files.wordpress.com/2014/03/exe-time-vs-pkt-size.png?w=510 510w, https://nicisdigital.files.wordpress.com/2014/03/exe-time-vs-pkt-size.png?w=150 150w, https://nicisdigital.files.wordpress.com/2014/03/exe-time-vs-pkt-size.png?w=300 300w, https://nicisdigital.files.wordpress.com/2014/03/exe-time-vs-pkt-size.png?w=768 768w, https://nicisdigital.files.wordpress.com/2014/03/exe-time-vs-pkt-size.png 966w" sizes="(max-width: 510px) 100vw, 510px"></a></p>
<p>The results shown here are fairly predicable. The Unix domain sockets are always more efficient and the efficiency benefit is in the 2-3x range. After noticing some weird ups and down in the graph, I decided to generate a graph with the execution times normalized to the TCP execution time.</p>
<p><a href="https://nicisdigital.files.wordpress.com/2014/03/rel-exe-time-vs-pkt-size.png"><img data-attachment-id="605" data-permalink="https://nicisdigital.wordpress.com/2014/03/03/unix-domain-sockets-vs-loopback-tcp-sockets/rel-exe-time-vs-pkt-size/" data-orig-file="https://nicisdigital.files.wordpress.com/2014/03/rel-exe-time-vs-pkt-size.png" data-orig-size="964,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Relative Execution Time vs Packet Size" data-image-description="" data-image-caption="" data-medium-file="https://nicisdigital.files.wordpress.com/2014/03/rel-exe-time-vs-pkt-size.png?w=300" data-large-file="https://nicisdigital.files.wordpress.com/2014/03/rel-exe-time-vs-pkt-size.png?w=510" alt="Relative Execution Time vs Packet Size" src="https://nicisdigital.files.wordpress.com/2014/03/rel-exe-time-vs-pkt-size.png?w=510&amp;h=297" width="510" height="297" srcset="https://nicisdigital.files.wordpress.com/2014/03/rel-exe-time-vs-pkt-size.png?w=510 510w, https://nicisdigital.files.wordpress.com/2014/03/rel-exe-time-vs-pkt-size.png?w=150 150w, https://nicisdigital.files.wordpress.com/2014/03/rel-exe-time-vs-pkt-size.png?w=300 300w, https://nicisdigital.files.wordpress.com/2014/03/rel-exe-time-vs-pkt-size.png?w=768 768w, https://nicisdigital.files.wordpress.com/2014/03/rel-exe-time-vs-pkt-size.png 964w" sizes="(max-width: 510px) 100vw, 510px"></a></p>
<p>I’m not exactly sure why the efficiency of Unix domain sockets varies as it does compared to TCP sockets, but it is always better. This is simply because Unix domain sockets don’t traverse the operating system’s network stack. The kernel simply copies the data from the client’s application into the file buffer in the server’s application.</p>

	              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intuitively Understanding Harris Corner Detector (140 pts)]]></title>
            <link>https://comsci.blog/posts/intuitive-harris</link>
            <guid>37466302</guid>
            <pubDate>Mon, 11 Sep 2023 12:35:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://comsci.blog/posts/intuitive-harris">https://comsci.blog/posts/intuitive-harris</a>, See on <a href="https://news.ycombinator.com/item?id=37466302">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>If you ever tried to learn how the Harris corner detection algorithm works, you might have
noticed that the process is not intuitive at all. First, you start with an energy function, approximate it
using Taylor approximation, get a matrix from that, then find the eigenvalues of that matrix, etc.
But when you come to the final implementation, it is rather simple and seems easier.
If you are like me, this is not intuitive at all. But today I will present you a much easier way to understand
how the Harris corner detection algorithm works.</p>

<p>Let’s start with understanding what is a corner. We can simply think of it as a connection of edges. For two edges
to be able to connect, they sure need to be not parallel, so looking at a corner, we should see that
edges moving in different directions (they would be parallel if they moved in the same directions):</p>

<p><img src="https://comsci.blog/assets/intuitive-harris-0.png" alt="" width="400"></p>

<p><em>Figure source: <a href="https://www.cse.psu.edu/~rtc12/CSE486/lecture06.pdf" target="_blank">https://www.cse.psu.edu/~rtc12/CSE486/lecture06.pdf</a></em></p>

<p>So it is obvious that the gradients of the image I<sub>x</sub> and I<sub>y</sub> will both be active in the corner
region. We know that adding I<sub>x</sub><sup>2</sup> and I<sub>y</sub><sup>2</sup> shows the regions with change
in x <strong><em>or</em></strong> y directions (which is the basis of the all edge detection algorithms). So one thing that comes to mind is multiplying the I<sub>x</sub><sup>2</sup>
and I<sub>y</sub><sup>2</sup> so that we will only see regions on the image that have a change in both x <strong><em>and</em></strong> y
directions at the same time, just like corners!</p>

<p>Let’s start implementing this. First, let’s find a pretty basic image that will have lots of corners inside it.</p>

<div><pre><code><span>import</span> <span>cv2</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>

<span># wget https://logowik.com/content/uploads/images/bbc-america9038.jpg -O assets/bbc.jpg
</span>
<span>img</span> <span>=</span> <span>cv2</span><span>.</span><span>imread</span><span>(</span><span>"assets/bbc.jpg"</span><span>,</span> <span>cv2</span><span>.</span><span>IMREAD_GRAYSCALE</span><span>)</span>
<span>plt</span><span>.</span><span>imshow</span><span>(</span><span>img</span><span>,</span> <span>cmap</span><span>=</span><span>"gray"</span><span>)</span>
</code></pre></div>

<p><img src="https://comsci.blog/assets/intuitive-harris_1_1.png" alt="png"></p>

<p>Now we can start finding the gradient of this image using the Sobel operator:</p>

<div><pre><code><span>Ix</span> <span>=</span> <span>cv2</span><span>.</span><span>Sobel</span><span>(</span><span>img</span><span>,</span> <span>ddepth</span><span>=</span><span>cv2</span><span>.</span><span>CV_32F</span><span>,</span> <span>dx</span><span>=</span><span>1</span><span>,</span> <span>dy</span><span>=</span><span>0</span><span>)</span>
<span>Iy</span> <span>=</span> <span>cv2</span><span>.</span><span>Sobel</span><span>(</span><span>img</span><span>,</span> <span>ddepth</span><span>=</span><span>cv2</span><span>.</span><span>CV_32F</span><span>,</span> <span>dx</span><span>=</span><span>0</span><span>,</span> <span>dy</span><span>=</span><span>1</span><span>)</span>
</code></pre></div>

<p>Okay, we are there now. Let’s plot the I<sub>x</sub><sup>2</sup>I<sub>y</sub><sup>2</sup>, we are expecting it to give us regions with both x and y directions:</p>

<div><pre><code><span>plt</span><span>.</span><span>imshow</span><span>(</span><span>Ix</span><span>**</span><span>2</span> <span>*</span> <span>Iy</span><span>**</span><span>2</span><span>,</span> <span>cmap</span><span>=</span><span>'gray'</span><span>)</span>
</code></pre></div>

<p><img src="https://comsci.blog/assets/intuitive-harris_5_1.png" alt="png"></p>

<p>As you can see, we are kind of not successful, because this shows us the both corners and edges that move along in
both x and y directions. But we need to get rid of the edges.</p>

<p>If you carefully look at this resulting image, you will notice that corners are either isolated like the top left
corner of the B logo, or they are at the end of these edges. Maybe we can’t get rid of the edges directly,
but if somehow we can remove the corners from I<sub>x</sub><sup>2</sup>I<sub>y</sub><sup>2</sup>, we can subtract it from the original I<sub>x</sub><sup>2</sup>I<sub>y</sub><sup>2</sup> and
get only the corners. Actually, we can get rid of the corners. Since the corners are isolated in this image,
applying a Gaussian blur will decrease the intensities of the corners a lot!</p>

<p>Let’s see this:</p>

<div><pre><code><span>corners_suppressed</span> <span>=</span> <span>cv2</span><span>.</span><span>GaussianBlur</span><span>(</span><span>Ix</span><span>**</span><span>2</span> <span>*</span> <span>Iy</span><span>**</span><span>2</span><span>,</span> <span>ksize</span><span>=</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>),</span> <span>sigmaX</span><span>=</span><span>1</span><span>)</span>
<span>plt</span><span>.</span><span>imshow</span><span>(</span><span>corners_suppressed</span><span>,</span> <span>cmap</span><span>=</span><span>'gray'</span><span>)</span>
</code></pre></div>

<p><img src="https://comsci.blog/assets/intuitive-harris_7_1.png" alt="png"></p>

<p>We can even do a better job of removing the corners by applying the blur before squaring. Because square will increase
the intensity of isolated corners, making it less affected by the blur. So we can instead do:</p>

<div><pre><code><span>corners_suppressed</span> <span>=</span> <span>cv2</span><span>.</span><span>GaussianBlur</span><span>(</span><span>Ix</span><span>*</span> <span>Iy</span><span>,</span> <span>ksize</span><span>=</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>),</span> <span>sigmaX</span><span>=</span><span>1</span><span>)</span> <span>**</span> <span>2</span>
<span>plt</span><span>.</span><span>imshow</span><span>(</span><span>corners_suppressed</span><span>,</span> <span>cmap</span><span>=</span><span>'gray'</span><span>)</span>
</code></pre></div>

<p><img src="https://comsci.blog/assets/intuitive-harris_9_1.png" alt="png"></p>

<p>Now that we have the corners mostly suppressed image, we can try subtracting this from the I<sub>x</sub><sup>2</sup>I<sub>y</sub><sup>2</sup> and get only the corners. Let’s try it:</p>

<div><pre><code><span>plt</span><span>.</span><span>imshow</span><span>(</span><span>Ix</span><span>**</span><span>2</span> <span>*</span> <span>Iy</span><span>**</span><span>2</span> <span>-</span> <span>corners_suppressed</span><span>,</span> <span>cmap</span><span>=</span><span>'gray'</span><span>)</span>
</code></pre></div>

<p><img src="https://comsci.blog/assets/intuitive-harris_11_1.png" alt="png"></p>

<p>That doesn’t seem to work, but the reason is clear. Edges of the I<sub>x</sub><sup>2</sup>I<sub>y</sub><sup>2</sup>
have different intensity than <code>corners_suppressed</code>, since <code>corners_suppressed</code> has been blurred.
We want them to have the same intensity in edges so that they cancel the edges when they are subtracted.</p>

<p>We can make the edges of I<sub>x</sub><sup>2</sup>I<sub>y</sub><sup>2</sup> similar intensity to edges of <code>corners_suppressed</code>
by applying Gaussian blur to I<sub>x</sub><sup>2</sup> and I<sub>y</sub><sup>2</sup> seperately before multiplying them.
We will apply the blur to squared gradients to make sure the corners are less affected by the blur.</p>

<div><pre><code><span>Ix_squared</span> <span>=</span> <span>cv2</span><span>.</span><span>GaussianBlur</span><span>(</span><span>Ix</span><span>**</span><span>2</span><span>,</span> <span>ksize</span><span>=</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>),</span> <span>sigmaX</span><span>=</span><span>1</span><span>)</span>
<span>Iy_squared</span> <span>=</span> <span>cv2</span><span>.</span><span>GaussianBlur</span><span>(</span><span>Iy</span><span>**</span><span>2</span><span>,</span> <span>ksize</span><span>=</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>),</span> <span>sigmaX</span><span>=</span><span>1</span><span>)</span>

<span>corners</span> <span>=</span> <span>Ix_squared</span> <span>*</span> <span>Iy_squared</span> <span>-</span> <span>corners_suppressed</span>
<span>plt</span><span>.</span><span>imshow</span><span>(</span><span>corners</span><span>,</span> <span>cmap</span><span>=</span><span>'gray'</span><span>)</span>
</code></pre></div>
<p><img src="https://comsci.blog/assets/intuitive-harris_13_1.png" alt="png"></p>

<p>Yes! We successfully get the corners of the image. Now if we look at the data inside the <code>corners</code> matrix, you will notice that
corners have extremely large values and other parts have smaller values. Let’s threshold it:</p>

<div><pre><code><span>corners</span><span>[</span><span>corners</span> <span>&lt;</span> <span>corners</span><span>.</span><span>max</span><span>()</span> <span>/</span> <span>5</span><span>]</span> <span>=</span> <span>0</span>
<span>corners</span><span>[</span><span>corners</span> <span>!=</span> <span>0</span><span>]</span> <span>=</span> <span>255</span>

<span>plt</span><span>.</span><span>imshow</span><span>(</span><span>corners</span><span>,</span> <span>cmap</span><span>=</span><span>"gray"</span><span>)</span>
</code></pre></div>

<p><img src="https://comsci.blog/assets/intuitive-harris_15_1.png" alt="png"></p>

<p>Okay, let’s plot these points as circles in our image:</p>

<div><pre><code><span>new_img</span> <span>=</span> <span>cv2</span><span>.</span><span>cvtColor</span><span>(</span><span>img</span><span>,</span> <span>cv2</span><span>.</span><span>COLOR_GRAY2RGB</span><span>)</span>

<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>img</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]):</span>
    <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>img</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]):</span>
        <span>if</span> <span>corners</span><span>[</span><span>i</span><span>][</span><span>j</span><span>]</span> <span>==</span> <span>255</span><span>:</span>
            <span>cv2</span><span>.</span><span>circle</span><span>(</span><span>new_img</span><span>,</span> <span>(</span><span>j</span><span>,</span> <span>i</span><span>),</span> <span>radius</span><span>=</span><span>2</span><span>,</span> <span>color</span><span>=</span><span>(</span><span>255</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>),</span> <span>thickness</span><span>=-</span><span>1</span><span>)</span>

<span>plt</span><span>.</span><span>imshow</span><span>(</span><span>new_img</span><span>,</span> <span>cmap</span><span>=</span><span>"gray"</span><span>)</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div>

<p><img src="https://comsci.blog/assets/intuitive-harris_17_0.png" alt="png"></p>

<p>And with this, we have implemented the Harris corner detection algorithm and we haven’t talked about things like
fitting ellipses, Taylor series approximation, or any of that stuff. This implementation is equivalent to the
other implementations of this algorithm.</p>

<p>Here is the full code:</p>
<div><pre><code><span>import</span> <span>cv2</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>

<span># wget https://logowik.com/content/uploads/images/bbc-america9038.jpg -O assets/bbc.jpg
</span>
<span>img</span> <span>=</span> <span>cv2</span><span>.</span><span>imread</span><span>(</span><span>"assets/bbc.jpg"</span><span>,</span> <span>cv2</span><span>.</span><span>IMREAD_GRAYSCALE</span><span>)</span>

<span>Ix</span> <span>=</span> <span>cv2</span><span>.</span><span>Sobel</span><span>(</span><span>img</span><span>,</span> <span>ddepth</span><span>=</span><span>cv2</span><span>.</span><span>CV_32F</span><span>,</span> <span>dx</span><span>=</span><span>1</span><span>,</span> <span>dy</span><span>=</span><span>0</span><span>)</span>
<span>Iy</span> <span>=</span> <span>cv2</span><span>.</span><span>Sobel</span><span>(</span><span>img</span><span>,</span> <span>ddepth</span><span>=</span><span>cv2</span><span>.</span><span>CV_32F</span><span>,</span> <span>dx</span><span>=</span><span>0</span><span>,</span> <span>dy</span><span>=</span><span>1</span><span>)</span>

<span>corners_suppressed</span> <span>=</span> <span>cv2</span><span>.</span><span>GaussianBlur</span><span>(</span><span>Ix</span><span>*</span> <span>Iy</span><span>,</span> <span>ksize</span><span>=</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>),</span> <span>sigmaX</span><span>=</span><span>1</span><span>)</span> <span>**</span> <span>2</span>
<span>Ix_squared</span> <span>=</span> <span>cv2</span><span>.</span><span>GaussianBlur</span><span>(</span><span>Ix</span><span>**</span><span>2</span><span>,</span> <span>ksize</span><span>=</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>),</span> <span>sigmaX</span><span>=</span><span>1</span><span>)</span>
<span>Iy_squared</span> <span>=</span> <span>cv2</span><span>.</span><span>GaussianBlur</span><span>(</span><span>Iy</span><span>**</span><span>2</span><span>,</span> <span>ksize</span><span>=</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>),</span> <span>sigmaX</span><span>=</span><span>1</span><span>)</span>

<span>corners</span> <span>=</span> <span>Ix_squared</span> <span>*</span> <span>Iy_squared</span> <span>-</span> <span>corners_suppressed</span>
<span>corners</span><span>[</span><span>corners</span> <span>&lt;</span> <span>corners</span><span>.</span><span>max</span><span>()</span> <span>/</span> <span>5</span><span>]</span> <span>=</span> <span>0</span>
<span>corners</span><span>[</span><span>corners</span> <span>!=</span> <span>0</span><span>]</span> <span>=</span> <span>255</span>

<span>new_img</span> <span>=</span> <span>cv2</span><span>.</span><span>cvtColor</span><span>(</span><span>img</span><span>,</span> <span>cv2</span><span>.</span><span>COLOR_GRAY2RGB</span><span>)</span>

<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>img</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]):</span>
    <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>img</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]):</span>
        <span>if</span> <span>corners</span><span>[</span><span>i</span><span>][</span><span>j</span><span>]</span> <span>==</span> <span>255</span><span>:</span>
            <span>cv2</span><span>.</span><span>circle</span><span>(</span><span>new_img</span><span>,</span> <span>(</span><span>j</span><span>,</span> <span>i</span><span>),</span> <span>radius</span><span>=</span><span>2</span><span>,</span> <span>color</span><span>=</span><span>(</span><span>255</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>),</span> <span>thickness</span><span>=-</span><span>1</span><span>)</span>

<span>plt</span><span>.</span><span>imshow</span><span>(</span><span>new_img</span><span>,</span> <span>cmap</span><span>=</span><span>"gray"</span><span>)</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div>
<p>Hopefully, you now understand how this algorithm works and enjoy the process.</p>

  </div>
</article>



      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Beyond OpenAPI (137 pts)]]></title>
            <link>https://antonz.org/interactive-api-tutorials/</link>
            <guid>37466207</guid>
            <pubDate>Mon, 11 Sep 2023 12:26:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antonz.org/interactive-api-tutorials/">https://antonz.org/interactive-api-tutorials/</a>, See on <a href="https://news.ycombinator.com/item?id=37466207">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><header></header><p>Not all documentation is created equal. According to the popular classification, there are four document types: tutorials, how-to guides, technical references, and explanations.</p><div><p><img alt="Four types of documentation" src="https://antonz.org/interactive-api-tutorials/documentation.png"></p></div><p>OpenAPI, the de facto standard for documenting APIs, is a decent reference-style documentation (and client code generator, of course). But it can't serve as a good how-to or tutorial.</p><p>In this article, I will introduce a concise and readable way to write interactive tutorials and how-tos for any HTTP API (REST, RPC, or other style). And for that (surprise, surprise), we will rely on the HTTP protocol itself.</p><h2 id="a-crash-course-in-http-messages">A crash course in HTTP messages</h2><p>HTTP/1.x is a plain-text protocol that describes the communication between the client and the server. The client sends messages like this:</p><pre tabindex="0"><code>POST /anything/chat HTTP/1.1
host: httpbingo.org
content-type: application/json
user-agent: curl/7.87.0

{
    "message": "Hello!"
}
</code></pre><p>And receives messages like this in response:</p><pre tabindex="0"><code>HTTP/1.1 200 OK
date: Mon, 28 Aug 2023 07:51:49 GMT
content-type: application/json

{
    "message": "Hi!"
}
</code></pre><blockquote><p>HTTP/2, the successor to HTTP/1.1, is a binary protocol. However, all tools (such as the browser devtools or curl) display HTTP/2 messages in plain text (just like HTTP/1.1), so we can safely ignore this fact for our purposes.</p></blockquote><div><figure><img alt="HTTP request and response" src="https://antonz.org/interactive-api-tutorials/http-messages.png"><figcaption>It's easy to read HTTP requests and responses once you get used to it.</figcaption></figure></div><p><strong>HTTP request</strong> consists of three main sections:</p><ol><li>Request line:</li></ol><pre tabindex="0"><code>POST /anything/chat HTTP/1.1
</code></pre><ul><li>The <em>method</em> (<code>POST</code>) defines the operation the client wants to perform.</li><li>The <em>path</em> (<code>/anything/chat</code>) is the URL of the requested resource (without the protocol, domain and port).</li><li>The <em>version</em> (<code>HTTP/1.1</code>) indicates the version of the HTTP protocol.</li></ul><ol start="2"><li>Request headers:</li></ol><pre tabindex="0"><code>host: httpbingo.org
content-type: application/json
user-agent: curl/7.87.0
</code></pre><p>Each header is a key-value pair that tells the server some useful information about the request. In our case it's the hostname of the server (<code>httpbingo.org</code>), the type of the content (<code>application/json</code>) and the client's self-identification (<code>user-agent</code>).</p><ol start="3"><li>Request body:</li></ol><pre tabindex="0"><code>{
    "message": "Hello!"
}
</code></pre><p>The actual data that the client sends to the server.</p><p>The HTTP protocol is stateless, so any state must be contained within the request itself, either in the headers or in the body.</p><p><strong>HTTP response</strong> also consists of three main sections:</p><ol><li>Status line:</li></ol><pre tabindex="0"><code>HTTP/1.1 200 OK
</code></pre><ul><li>The <em>version</em> (<code>HTTP/1.1</code>) indicates the version of the HTTP protocol.</li><li>The <em>status code</em> (<code>200</code>) tells whether the request was successful or not, and why (there are many status codes for <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status">different situations</a>).</li><li>The <em>status message</em> is a human-readable description of the status code. HTTP/2 does not have it.</li></ul><ol start="2"><li>Response headers:</li></ol><pre tabindex="0"><code>date: Mon, 28 Aug 2023 07:51:49 GMT
content-type: application/json
</code></pre><p>Similar to request headers, these provide useful information about the response to the client.</p><ol start="3"><li>Response body:</li></ol><pre tabindex="0"><code>{
    "message": "Hi!"
}
</code></pre><p>The actual data that the server sends to the client.</p><p>There is much more to the HTTP protocol, but this basic knowledge is enough to cover most of API use cases. So let's move on.</p><h2 id="using-http-to-document-api-usage">Using HTTP to document API usage</h2><p>We are going to take an HTTP request:</p><pre tabindex="0"><code>POST /anything/chat HTTP/1.1
host: httpbingo.org
content-type: application/json
user-agent: curl/7.87.0

{
    "message": "Hello!"
}
</code></pre><p>And modify it just a little bit:</p><ul><li>include the full URL in the request line instead of the path;</li><li>remove the protocol version.</li></ul><pre tabindex="0"><code>POST http://httpbingo.org/anything/chat
content-type: application/json

{
    "message": "Hello!"
}
</code></pre><p>This format is perfect for API usage examples. It's concise and readable, yet formal enough to be executed programmatically (directly from the documentation, as we'll see shortly).</p><h2 id="writing-an-interactive-api-guide">Writing an interactive API guide</h2><p>Instead of telling you how to write an interactive API tutorial, I'm going to show you one. We'll use <a href="https://docs.github.com/en/rest/gists/gists">Gists API</a> as an example. It's a compact and useful GitHub service for storing code snippets (called "gists").</p><div><figure><img alt="GitHub Gists" src="https://antonz.org/interactive-api-tutorials/gists.png"><figcaption>Gists are quite handy when a full-blown Git repository is too much.</figcaption></figure></div><p>Even if you are not a GitHub user, you still have access to the Gists API.</p><h3 id="reading-gists">Reading gists</h3><p>Let's take a look at the <strong>public gists</strong> of my pal Redowan (user <code>rednafi</code>). The response can be quite chatty, so we'll only select the 3 most recent (<code>per_page = 3</code>):</p><pre tabindex="0"><code>GET https://api.github.com/users/rednafi/gists?per_page=3
accept: application/json
</code></pre><codapi-snippet sandbox="fetch" editor="basic"></codapi-snippet><p>A family of non-standard <code>x-ratelimit</code> headers tell us how GitHub <strong>limits</strong> our requests:</p><ul><li>There is a total number of <code>x-ratelimit-limit</code> requests available per hour.</li><li>We've already used <code>x-ratelimit-used</code> requests.</li><li>So there are <code>x-ratelimit-remaining</code> requests left.</li></ul><p>We need to keep an eye on these to make sure we don't exceed the quota.</p><p>We can use a combination of <code>page</code> and <code>per_page</code> query parameters to select a <strong>slice of gists</strong>. For example, here are gists 10-15:</p><pre tabindex="0"><code>GET https://api.github.com/users/rednafi/gists?page=3&amp;per_page=5
accept: application/json
</code></pre><codapi-snippet sandbox="fetch" editor="basic"></codapi-snippet><p>Note that GitHub provides navigation links in the <code>link</code> header:</p><pre tabindex="0"><code>link:
    &lt;https://api.github.com/user/30027932/gists?page=2&amp;per_page=5&gt;; rel="prev",
    &lt;https://api.github.com/user/30027932/gists?page=4&amp;per_page=5&gt;; rel="next",
    &lt;https://api.github.com/user/30027932/gists?page=7&amp;per_page=5&gt;; rel="last",
    &lt;https://api.github.com/user/30027932/gists?page=1&amp;per_page=5&gt;; rel="first"
</code></pre><p>That's thoughtful of them!</p><p>Okay, now let's take a look at the <strong>specific gist</strong> with id <code>88242fd822603290255877e396664ba5</code> (this one is mine; let's not bother Redowan anymore):</p><pre tabindex="0"><code>GET https://api.github.com/gists/88242fd822603290255877e396664ba5
accept: application/json
</code></pre><codapi-snippet sandbox="fetch" editor="basic"></codapi-snippet><p>We can see that there is a <code>greet.py</code> file written in the Python <code>language</code> with a certain <code>content</code>:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>Greeter</span>:
</span></span><span><span>    <span>def</span> <span>__init__</span>(<span>self</span>, <span>greeting</span>):
</span></span><span><span>        <span>self</span><span>.</span><span>greeting</span> <span>=</span> <span>greeting</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>greet</span>(<span>self</span>, <span>who</span>):
</span></span><span><span>        <span>print</span>(<span>f</span><span>"</span><span>{</span><span>self</span><span>.</span><span>greeting</span><span>}</span><span>, </span><span>{</span><span>who</span><span>}</span><span>!"</span>)
</span></span><span><span>
</span></span><span><span><span>gr</span> <span>=</span> <span>Greeter</span>(<span>"Hello"</span>)
</span></span><span><span><span>gr</span><span>.</span><span>greet</span>(<span>"world"</span>)
</span></span></code></pre></div><codapi-snippet sandbox="python" editor="basic"></codapi-snippet><p><em>(yep, you can also create interactive Python examples!)</em></p><p>Interestingly, the gist has a <code>history</code>. It appears that every time you edit a gist, GitHub creates a new version, while also keeping previous versions.</p><p>Let's get the <strong>earliest revision</strong>, which has a <code>version</code> = <code>4c10d27cfb163d654745f1d72f2c7ce14225b83b</code> (a bit long, I know):</p><pre tabindex="0"><code>GET https://api.github.com/gists/88242fd822603290255877e396664ba5/4c10d27cfb163d654745f1d72f2c7ce14225b83b
accept: application/json
</code></pre><codapi-snippet sandbox="fetch" editor="basic"></codapi-snippet><p>The code in the gist was much simpler back then:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>msg</span> <span>=</span> <span>"Hello, world!"</span>
</span></span><span><span><span>print</span>(<span>msg</span>)
</span></span></code></pre></div><codapi-snippet sandbox="python" editor="basic"></codapi-snippet><h3 id="modifying-gists">Modifying gists</h3><p>Okay, so we know how to list gists for a user, how to get a specific gist, and even how to get a specific revision. Now let's <strong>create a new gist</strong>!</p><pre tabindex="0"><code>POST https://api.github.com/gists
content-type: application/json
accept: application/json

{
    "description": "Greetings in Markdown",
    "public": true,
    "files":{
        "README.md":{
            "content":"Hello, world!"
        }
    }
}
</code></pre><codapi-snippet sandbox="fetch" editor="basic"></codapi-snippet><p>What's that? We have a <code>401 Unauthorized</code> error. The response body explains: "requires authentication" and even provides a link to the documentation (oh, I just love GitHub APIs).</p><p>Understandably, GitHub does not allow anonymous users to create new gists. We have to authenticate with an API token.</p><blockquote><p>If you want the following examples to work, enter your API token in the field below. You can create one with a 'gist' scope in the <a href="https://github.com/settings/tokens">GitHub settings</a>.</p><p>After you enter the token below, it will be stored locally in the browser and will not be sent anywhere (except to the GitHub API when you click the Run button).</p></blockquote><p>Let's try again, this time with an <code>authorization</code> header.</p><p>Note the <code>public</code> parameter. The service supports "secret" gists (<code>public = false</code>), but it's the "security by obscurity" type of secrecy. Secret gists do not show up in the "GET gists" API method, but they are still accessible by id, even by anonymous users.</p><pre tabindex="0"><code data-lang="authenticated">POST https://api.github.com/gists
content-type: application/json
accept: application/json
authorization: bearer {token}

{
    "description": "Greetings in Markdown",
    "public": true,
    "files":{
        "README.md":{
            "content":"Hello, world!"
        }
    }
}
</code></pre><codapi-snippet sandbox="fetch" editor="basic"></codapi-snippet><details><summary>I don't have a token, just show me the results</summary><pre><code>HTTP/1.1 201 
cache-control: private, max-age=60, s-maxage=60
content-length: 3758
content-type: application/json; charset=utf-8
etag: "819f6b4f728843abcb50ad63da200a4c110245585b3eb1c0f59a5ebe86c8ecf5"
location: https://api.github.com/gists/b17474320a629af38255c0a6efbc72b9
x-accepted-oauth-scopes: 
x-github-media-type: github.v3
x-github-request-id: E8B5:8EDA:511F73:51AC33:64EE0266
x-oauth-scopes: gist
x-ratelimit-limit: 5000
x-ratelimit-remaining: 4997
x-ratelimit-reset: 1693323114
x-ratelimit-resource: core
x-ratelimit-used: 3

{
  "url": "https://api.github.com/gists/b17474320a629af38255c0a6efbc72b9",
  "forks_url": "https://api.github.com/gists/b17474320a629af38255c0a6efbc72b9/forks",
  "commits_url": "https://api.github.com/gists/b17474320a629af38255c0a6efbc72b9/commits",
  "id": "b17474320a629af38255c0a6efbc72b9",
  "node_id": "G_kwDOACz0htoAIGIxNzQ3NDMyMGE2MjlhZjM4MjU1YzBhNmVmYmM3MmI5",
  "git_pull_url": "https://gist.github.com/b17474320a629af38255c0a6efbc72b9.git",
  "git_push_url": "https://gist.github.com/b17474320a629af38255c0a6efbc72b9.git",
  "html_url": "https://gist.github.com/nalgeon/b17474320a629af38255c0a6efbc72b9",
  "files": {
    "README.md": {
      "filename": "README.md",
      "type": "text/markdown",
      "language": "Markdown",
      "raw_url": "https://gist.githubusercontent.com/nalgeon/b17474320a629af38255c0a6efbc72b9/raw/5dd01c177f5d7d1be5346a5bc18a569a7410c2ef/README.md",
      "size": 13,
      "truncated": false,
      "content": "Hello, world!"
    }
  },
  ...
}</code></pre></details><p>HTTP status <code>201 Created</code> means that a new gist has been created as a result of our request.</p><p>Okay, now we can <strong>update a gist</strong> using its <code>id</code> (don't forget to replace the <code>{gist_id}</code> in the request line with the actual <code>id</code> value):</p><pre tabindex="0"><code data-lang="authenticated">PATCH https://api.github.com/gists/{gist_id}
content-type: application/json
accept: application/json
authorization: bearer {token}

{
    "description": "Greetings in Markdown",
    "public": true,
    "files":{
        "README.md":{
            "content":"¡Hola, mundo!"
        }
    }
}
</code></pre><codapi-snippet sandbox="fetch" editor="basic"></codapi-snippet><details><summary>I don't have a token, just show me the results</summary><pre><code>HTTP/1.1 200 
cache-control: private, max-age=60, s-maxage=60
content-type: application/json; charset=utf-8
etag: W/"989eaec7cdb50ba6441e77ea2defba257b98a535f26c2ba6062f152ceffb2d77"
x-accepted-oauth-scopes: 
x-github-media-type: github.v3
x-github-request-id: E8B5:8EDA:5188AA:52163F:64EE027F
x-oauth-scopes: gist
x-ratelimit-limit: 100
x-ratelimit-remaining: 98
x-ratelimit-reset: 1693323129
x-ratelimit-resource: gist_update
x-ratelimit-used: 2

{
  "url": "https://api.github.com/gists/b17474320a629af38255c0a6efbc72b9",
  "forks_url": "https://api.github.com/gists/b17474320a629af38255c0a6efbc72b9/forks",
  "commits_url": "https://api.github.com/gists/b17474320a629af38255c0a6efbc72b9/commits",
  "id": "b17474320a629af38255c0a6efbc72b9",
  "node_id": "G_kwDOACz0htoAIGIxNzQ3NDMyMGE2MjlhZjM4MjU1YzBhNmVmYmM3MmI5",
  "git_pull_url": "https://gist.github.com/b17474320a629af38255c0a6efbc72b9.git",
  "git_push_url": "https://gist.github.com/b17474320a629af38255c0a6efbc72b9.git",
  "html_url": "https://gist.github.com/nalgeon/b17474320a629af38255c0a6efbc72b9",
  "files": {
    "README.md": {
      "filename": "README.md",
      "type": "text/markdown",
      "language": "Markdown",
      "raw_url": "https://gist.githubusercontent.com/nalgeon/b17474320a629af38255c0a6efbc72b9/raw/95975f3d0bac707ce4355dfc4a7955310d212fac/README.md",
      "size": 14,
      "truncated": false,
      "content": "¡Hola, mundo!"
    }
  },
  ...
}</code></pre></details><p>It now greets us in Spanish 🇪🇸</p><p>Very good. Finally, let's <strong>delete a gist</strong>:</p><pre tabindex="0"><code data-lang="authenticated">DELETE https://api.github.com/gists/{gist_id}
accept: application/json
authorization: bearer {token}
</code></pre><codapi-snippet sandbox="fetch" editor="basic"></codapi-snippet><details><summary>I don't have a token, just show me the results</summary><pre><code>HTTP/1.1 204 
x-accepted-oauth-scopes: 
x-github-media-type: github.v3
x-github-request-id: E8B5:8EDA:51E584:5273CC:64EE027F
x-oauth-scopes: gist
x-ratelimit-limit: 5000
x-ratelimit-remaining: 4996
x-ratelimit-reset: 1693323114
x-ratelimit-resource: core
x-ratelimit-used: 4</code></pre></details><p>HTTP status <code>204 No Content</code> means we deleted the gist, so GitHub has nothing more to tell us about it. It's a little sad to see it go, but we can always make another one, right?</p><p>The Gists API has other useful features, but they are beyond the scope of this tutorial. Here are the functions we've covered:</p><ul><li>List user gists.</li><li>Get a specific gist, or a specific revision of a gist.</li><li>Create a new gist.</li><li>Update an existing gist.</li><li>Delete a gist.</li></ul><p>Now try managing your gists! You can always use this article as a playground.</p><h2 id="implementation">Implementation</h2><p>To run the API examples as we did in the previous section, you'll need a bit of JavaScript that does the following:</p><ol><li>Parses the HTTP request example.</li><li>Calls the API.</li><li>Displays the result.</li></ol><div><figure><img alt="Fetch API playground" src="https://antonz.org/interactive-api-tutorials/playground.png"><figcaption>It's always nice when a playground doesn't need a server.</figcaption></figure></div><p>Since we've limited ourselves to a small subset of HTTP request capabilities, parsing is fairly easy:</p><div><pre tabindex="0"><code data-lang="js"><span><span><span>// parse parses the request specification.
</span></span></span><span><span><span></span><span>function</span> <span>parse</span>(<span>text</span>) {
</span></span><span><span>    <span>const</span> <span>lines</span> <span>=</span> <span>text</span>.<span>split</span>(<span>"\n"</span>);
</span></span><span><span>    <span>let</span> <span>lineIdx</span> <span>=</span> <span>0</span>;
</span></span><span><span>
</span></span><span><span>    <span>// parse method and URL
</span></span></span><span><span><span></span>    <span>const</span> <span>methodUrl</span> <span>=</span> <span>lines</span>[<span>0</span>].<span>split</span>(<span>" "</span>).<span>filter</span>((<span>s</span>) =&gt; <span>s</span>);
</span></span><span><span>    <span>const</span> [<span>method</span>, <span>url</span>] <span>=</span>
</span></span><span><span>        <span>methodUrl</span>.<span>length</span> <span>&gt;=</span> <span>2</span> <span>?</span> <span>methodUrl</span> <span>:</span> [<span>"GET"</span>, <span>methodUrl</span>[<span>0</span>]];
</span></span><span><span>    <span>lineIdx</span> <span>+=</span> <span>1</span>;
</span></span><span><span>
</span></span><span><span>    <span>// parse headers
</span></span></span><span><span><span></span>    <span>const</span> <span>headers</span> <span>=</span> {};
</span></span><span><span>    <span>for</span> (<span>let</span> <span>i</span> <span>=</span> <span>lineIdx</span>; <span>i</span> <span>&lt;</span> <span>lines</span>.<span>length</span>; <span>i</span><span>++</span>) {
</span></span><span><span>        <span>const</span> <span>line</span> <span>=</span> <span>lines</span>[<span>i</span>].<span>trim</span>();
</span></span><span><span>        <span>if</span> (<span>line</span> <span>===</span> <span>""</span>) {
</span></span><span><span>            <span>break</span>;
</span></span><span><span>        }
</span></span><span><span>        <span>const</span> [<span>headerName</span>, <span>headerValue</span>] <span>=</span> <span>line</span>.<span>split</span>(<span>":"</span>);
</span></span><span><span>        <span>headers</span>[<span>headerName</span>.<span>trim</span>()] <span>=</span> <span>headerValue</span>.<span>trim</span>();
</span></span><span><span>        <span>lineIdx</span> <span>+=</span> <span>1</span>;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>// parse body
</span></span></span><span><span><span></span>    <span>const</span> <span>body</span> <span>=</span> <span>lines</span>.<span>slice</span>(<span>lineIdx</span> <span>+</span> <span>1</span>).<span>join</span>(<span>"\n"</span>);
</span></span><span><span>
</span></span><span><span>    <span>return</span> { <span>method</span>, <span>url</span>, <span>headers</span>, <span>body</span> };
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>const</span> <span>spec</span> <span>=</span> <span>parse</span>(<span>`GET https://httpbingo.org/uuid`</span>);
</span></span><span><span><span>console</span>.<span>log</span>(<span>JSON</span>.<span>stringify</span>(<span>spec</span>, <span>null</span>, <span>2</span>));
</span></span></code></pre></div><codapi-snippet sandbox="javascript" editor="basic"></codapi-snippet><p>Calling the API and displaying the results is trivial — just use the Fetch API and display the result as plain text:</p><div><pre tabindex="0"><code data-lang="js"><span><span><span>// execCode sends an HTTP request according to the spec
</span></span></span><span><span><span>// and returns the response as text with status, headers and body.
</span></span></span><span><span><span></span><span>async</span> <span>function</span> <span>execCode</span>(<span>spec</span>) {
</span></span><span><span>    <span>const</span> <span>resp</span> <span>=</span> <span>await</span> <span>sendRequest</span>(<span>spec</span>);
</span></span><span><span>    <span>const</span> <span>text</span> <span>=</span> <span>await</span> <span>responseText</span>(<span>resp</span>);
</span></span><span><span>    <span>return</span> <span>text</span>;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>// sendRequest sends an HTTP request according to the spec.
</span></span></span><span><span><span></span><span>async</span> <span>function</span> <span>sendRequest</span>(<span>spec</span>) {
</span></span><span><span>    <span>const</span> <span>options</span> <span>=</span> {
</span></span><span><span>        <span>method</span><span>:</span> <span>spec</span>.<span>method</span>,
</span></span><span><span>        <span>headers</span><span>:</span> <span>spec</span>.<span>headers</span>,
</span></span><span><span>        <span>body</span><span>:</span> <span>spec</span>.<span>body</span> <span>||</span> <span>undefined</span>,
</span></span><span><span>    };
</span></span><span><span>    <span>return</span> <span>await</span> <span>fetch</span>(<span>spec</span>.<span>url</span>, <span>options</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>// responseText returns the response as text
</span></span></span><span><span><span>// with status, headers and body.
</span></span></span><span><span><span></span><span>async</span> <span>function</span> <span>responseText</span>(<span>resp</span>) {
</span></span><span><span>    <span>const</span> <span>version</span> <span>=</span> <span>"HTTP/1.1"</span>;
</span></span><span><span>    <span>const</span> <span>text</span> <span>=</span> <span>await</span> <span>resp</span>.<span>text</span>();
</span></span><span><span>    <span>const</span> <span>messages</span> <span>=</span> [<span>`</span><span>${</span><span>version</span><span>}</span><span> </span><span>${</span><span>resp</span>.<span>status</span><span>}</span><span> </span><span>${</span><span>resp</span>.<span>statusText</span><span>}</span><span>`</span>];
</span></span><span><span>    <span>for</span> (<span>const</span> <span>hdr</span> <span>of</span> <span>resp</span>.<span>headers</span>.<span>entries</span>()) {
</span></span><span><span>        <span>messages</span>.<span>push</span>(<span>`</span><span>${</span><span>hdr</span>[<span>0</span>]<span>}</span><span>: </span><span>${</span><span>hdr</span>[<span>1</span>]<span>}</span><span>`</span>);
</span></span><span><span>    }
</span></span><span><span>    <span>if</span> (<span>text</span>) {
</span></span><span><span>        <span>messages</span>.<span>push</span>(<span>""</span>, <span>text</span>);
</span></span><span><span>    }
</span></span><span><span>    <span>return</span> <span>messages</span>.<span>join</span>(<span>"\n"</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>const</span> <span>spec</span> <span>=</span> {
</span></span><span><span>    <span>method</span><span>:</span> <span>"GET"</span>,
</span></span><span><span>    <span>url</span><span>:</span> <span>"https://httpbingo.org/uuid"</span>,
</span></span><span><span>};
</span></span><span><span>
</span></span><span><span><span>const</span> <span>text</span> <span>=</span> <span>await</span> <span>execCode</span>(<span>spec</span>);
</span></span><span><span><span>console</span>.<span>log</span>(<span>text</span>);
</span></span></code></pre></div><codapi-snippet sandbox="javascript" editor="basic"></codapi-snippet><p>Fetch API works in the browser, so there is no intermediate server involved. The only nuance is that the documentation must either be on the same domain as the API itself, or the API must allow cross-domain requests. But even if that's not the case, you can always proxy the requests — it's not too much work.</p><p>If you want an out-of-the-box solution, I've written a simple library that supports both JavaScript and Fetch API playgrounds:</p><p><a href="https://github.com/nalgeon/codapi-js"><strong><code>codapi-js</code></strong></a></p><p>Ideally, I'd like most documentation to be interactive. Not just API guides, but everything from algorithms (like <a href="https://samwho.dev/hashing/">hashing</a>) to programming languages (like <a href="https://antonz.org/go-1-21-builtins/">Go</a> or <a href="https://antonz.org/trying-odin/">Odin</a>) to databases (like <a href="https://antonz.org/sql-compare-neighbors/">SQLite</a>), frameworks and tools, and even individual packages.</p><p>And (shameless plug here!) I'm building a platform that allows just that — easily embeddable code playgrounds for documentation, online education, and fun. Check it out if you are interested:</p><p><a href="https://codapi.org/"><strong><code>codapi</code></strong></a></p><p>And please try to write an interactive guide the next time you develop an API!</p>

<p><em><a href="https://antonz.org/subscribe/"><i></i>&nbsp;<strong>Subscribe</strong></a>
to keep up with new posts.</em></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A LLM+OLAP Solution (102 pts)]]></title>
            <link>https://doris.apache.org/zh-CN/blog/Tencent-LLM/</link>
            <guid>37466182</guid>
            <pubDate>Mon, 11 Sep 2023 12:23:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://doris.apache.org/zh-CN/blog/Tencent-LLM/">https://doris.apache.org/zh-CN/blog/Tencent-LLM/</a>, See on <a href="https://news.ycombinator.com/item?id=37466182">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container" itemprop="articleBody"><p>Six months ago, I wrote about <a href="https://doris.apache.org/blog/Tencent%20Music/" target="_blank" rel="noopener noreferrer">why we replaced ClickHouse with Apache Doris as an OLAP engine</a> for our data management system. Back then, we were struggling with the auto-generation of SQL statements. As days pass, we have made progresses big enough to be references for you (I think), so here I am again. </p><p>We have adopted Large Language Models (LLM) to empower our Doris-based OLAP services.</p><h2 id="llm--olap">LLM + OLAP<a href="#llm--olap" aria-label="LLM + OLAP的直接链接" title="LLM + OLAP的直接链接">​</a></h2><p>Our incentive was to save our internal staff from the steep learning curve of SQL writing. Thus, we used LLM as an intermediate. It transforms natural language questions into SQL statements and sends the SQLs to the OLAP engine for execution.</p><p><img loading="lazy" src="https://cdnd.selectdb.com/zh-CN/assets/images/Tencent_LLM_1-6672112c0d09d75171d8ed9a749ff196.png" width="1280" height="253"></p><p>Like every AI-related experience, we came across some friction:</p><ol><li>LLM does not understand data jargons, like "fields", "rows", "columns" and "tables". Instead, they can perfectly translate business terms like "corporate income" and "DAU", which are basically what the fields/rows/columns are about. That means it can work well only if the analysts use the exact right word to refer to the metric they need when typing their questions.</li><li>The LLM we are using is slow in inference. It takes over 10 seconds to respond. As it charges fees by token, cost-effectiveness becomes a problem.</li><li>Although the LLM is trained on a large collection of public datasets, it is under-informed of niche knowledge. In our case, the LLM is super unfamiliar with indie songs, so even if the songs are included in our database, the LLM will not able to identify them properly. </li><li>Sometimes our input questions require adequate and latest legal, political, financial, and regulatory information, which is hard to be included in a training dataset or knowledge base. We need to connect the LLM to wider info bases in order to perform more diversified tasks.</li></ol><p>We knock these problems down one by one.</p><h3 id="1-a-semantic-layer">1. A semantic layer<a href="#1-a-semantic-layer" aria-label="1. A semantic layer的直接链接" title="1. A semantic layer的直接链接">​</a></h3><p>For problem No.1, we introduce a semantic layer between the LLM and the OLAP engine. This layer translates business terms into the corresponding data fields. It can identify data filtering conditions from the various natural language wordings, relate them to the metrics involved, and then generate SQL statements. </p><p>Besides that, the semantic layer can optimize the computation logic. When analysts input a question that involves a complicated query, let's say, a multi-table join, the semantic layer can split that into multiple single-table queries to reduce semantic distortion.</p><p><img loading="lazy" src="https://cdnd.selectdb.com/zh-CN/assets/images/Tencent_LLM_2-bb2fdaed64ef15214c0542204dd45832.png" width="1280" height="289"></p><h3 id="2-llm-parsing-rules">2. LLM parsing rules<a href="#2-llm-parsing-rules" aria-label="2. LLM parsing rules的直接链接" title="2. LLM parsing rules的直接链接">​</a></h3><p>To increase cost-effectiveness in using LLM, we evaluate the computation complexity of all scenarios, such as metric computation, detailed record retrieval, and user segmentation. Then, we create rules and dedicate the LLM-parsing step to only complicated tasks. That means for the simple computation tasks, it will skip the parsing. </p><p>For example, when an analyst inputs "tell me the earnings of the major musical platforms", the LLM identifies that this question only entails several metrics or dimensions, so it will not further parse it but send it straight for SQL generation and execution. This can largely shorten query response time and reduce API expenses. </p><p><img loading="lazy" src="https://cdnd.selectdb.com/zh-CN/assets/images/Tencent_LLM_3-3ab023081e1acb069d34a4ce24aef010.png" width="1280" height="406"></p><h3 id="3-schema-mapper-and-external-knowledge-base">3. Schema Mapper and external knowledge base<a href="#3-schema-mapper-and-external-knowledge-base" aria-label="3. Schema Mapper and external knowledge base的直接链接" title="3. Schema Mapper and external knowledge base的直接链接">​</a></h3><p>To empower the LLM with niche knowledge, we added a Schema Mapper upstream from the LLM. The Schema Mapper maps the input question to an external knowledge base, and then the LLM will do parsing.</p><p>We are constantly testing and optimizing the Schema Mapper. We categorize and rate content in the external knowledge base, and do various levels of mapping (full-text mapping and fuzzy mapping) to enable better semantic parsing.</p><p><img loading="lazy" src="https://cdnd.selectdb.com/zh-CN/assets/images/Tencent_LLM_4-261ee680cf77335b25f32e41d7a4924b.png" width="2001" height="647"></p><h3 id="4-plugins">4. Plugins<a href="#4-plugins" aria-label="4. Plugins的直接链接" title="4. Plugins的直接链接">​</a></h3><p>We used plugins to connect the LLM to more fields of information, and we have different integration methods for different types of plugins:</p><ul><li><strong>Embedding local files</strong>: This is especially useful when we need to "teach" the LLM the latest regulatory policies, which are often text files. Firstly, the system vectorizes the local text file, executes semantic searches to find matching or similar terms in the local file, extracts the relevant contents and puts them into the LLM parsing window to generate output. </li><li><strong>Third-party plugins</strong>: The marketplace is full of third-party plugins that are designed for all kinds of sectors. With them, the LLM is able to deal with wide-ranging topics. Each plugin has its own prompts and calling function. Once the input question hits a prompt, the relevant plugin will be called.</li></ul><p><img loading="lazy" src="https://cdnd.selectdb.com/zh-CN/assets/images/Tencent_LLM_5-70a170e771dd9eadcc1488b94d892478.png" width="2001" height="645"></p><p>After we are done with above four optimizations, the SuperSonic framework comes into being.</p><h2 id="the-supersonic-framework">The SuperSonic framework<a href="#the-supersonic-framework" aria-label="The SuperSonic framework的直接链接" title="The SuperSonic framework的直接链接">​</a></h2><p>Now let me walk you through this <a href="https://github.com/tencentmusic/supersonic" target="_blank" rel="noopener noreferrer">framework</a>:</p><p><img loading="lazy" src="https://cdnd.selectdb.com/zh-CN/assets/images/Tencent_LLM_6-cbbbb25041c807376b2b9d14609e82c8.png" width="1280" height="1117"></p><ul><li>An analyst inputs a question.</li><li>The Schema Mapper maps the question to an external knowledge base.</li><li>If there are matching fields in the external knowledge base, the question will not be parsed by the LLM. Instead, a metric computation formula will trigger the OLAP engine to start querying. If there is no matching field, the question will enter the LLM.</li><li>Based on the pre-defined rules, the LLM rates the complexity level of the question. If it is a simple query, it will go directly to the OLAP engine; if it is a complicated query, it will be semantically parsed and converted to a DSL statement.</li><li>At the Semantic Layer, the DSL statement will be split based on its query scenario. For example, if it is a multi-table join query, this layer will generate multiple single-table query SQL statements.</li><li>If the question involves external knowledge, the LLM will call a third-party plugin.</li></ul><p><strong>Example</strong></p><p><img loading="lazy" src="https://cdnd.selectdb.com/zh-CN/assets/images/Tencent_LLM_7-c20b3cc2b0b00b32bc2825c1d62b1d5d.png" width="2001" height="1126"></p><p>To answer whether a certain song can be performed on variety shows, the system retrieves the OLAP data warehouse for details about the song, and presents it with results from the Commercial Use Query third-party plugin.</p><h2 id="olap-architecture">OLAP Architecture<a href="#olap-architecture" aria-label="OLAP Architecture的直接链接" title="OLAP Architecture的直接链接">​</a></h2><p>As for the OLAP part of this framework, after several rounds of architectural evolution, this is what our current OLAP pipeline looks like. </p><p>Raw data is sorted into tags and metrics, which are custom-defined by the analysts. The tags and metrics are under unified management in order to avoid inconsistent definitions. Then, they are combined into various tagsets and metricsets for various queries. </p><p><img loading="lazy" src="https://cdnd.selectdb.com/zh-CN/assets/images/Tencent_LLM_8-6d517a787c782510bf3869176730ce3a.png" width="1709" height="1119"></p><p>We have drawn two main takeaways for you from our architectural optimization experience.</p><p><strong>1. Streamline the links</strong></p><p>Before we adopted Apache Doris, we used to have ClickHouse to accelerate the computation of tags and metrics, and Elasticsearch to process dimensional data. That's two analytic engines and requires us to adapt the query statements to both of them. It was high-maintenance.</p><p>Thus, we replaced ClickHouse with Apache Doris, and utilized the <a href="https://doris.apache.org/docs/dev/lakehouse/multi-catalog/es" target="_blank" rel="noopener noreferrer">Elasticsearch Catalog</a> functionality to connect Elasticsearch data to Doris. In this way, we make Doris our unified query gateway. </p><p><strong>2. Split the flat tables</strong></p><p>In early versions of our OLAP architecture, we used to put data into flat tables, which made things tricky. For one thing, flat tables absorbed all the writing latency from upstreams, and that added up to considerable loss in data realtimeliness. For another, 50% of data in a flat table was dimensional data, which was rarely updated. With every new flat table came some bulky dimensional data that consumed lots of storage space. </p><p>Therefore, we split the flat tables into metric tables and dimension tables. As they are updated in different paces, we put them into different data models.</p><ul><li><strong>Metric tables</strong>: We arrange metric data in the Aggregate Key model of Apache Doris, which means new data will be merged with the old data by way of SUM, MAX, MIN, etc.</li><li><strong>Dimension tables</strong>: These tables are in the Unique Key model of Apache Doris, which means new data record will replace the old. This can greatly increase performance in our query scenarios.</li></ul><p>You might ask, does this cause trouble in queries, since most queries require data from both types of tables? Don't worry, we address that with the Rollup feature of Doris. On the basis of the base tables, we can select the dimensions we need to create Rollup views, which will automatically execute <code>GROUP BY</code>. This relieves us of the need to define tags for each Rollup view and largely speed up queries.</p><h2 id="other-tricks">Other Tricks<a href="#other-tricks" aria-label="Other Tricks的直接链接" title="Other Tricks的直接链接">​</a></h2><p>In our experience with Apache Doris, we also find some other functionalities handy, so I list them here for you, too:</p><p><strong>1. Materialized View</strong></p><p>A Materialized View is a pre-computed dataset. It is a way to accelerate queries when you frequently need to access data of certain dimensions. In these scenarios, we define derived tags and metrics based on the original ones. For example, we create a derived metric by combining Metric 1, Metric 2, and Metric 3: <code>sum(m1+m2+m3)</code>. Then, we can create a Materialized View for it. According to the Doris release schedule, version 2.1 will support multi-table Materialized Views, and we look forward to that.</p><p><strong>2. Flink-Doris-Connector</strong></p><p>This is for Exactly-Once guarantee in data ingestion. The Flink-Doris-Connector implements a checkpoint mechanism and two-stage commit, and allows for auto data synchronization from relational databases to Doris.</p><p><strong>3. Compaction</strong></p><p>When the number of aggregation tasks or data volume becomes overwhelming for Flink, there might be huge latency in data compaction. We solve that with Vertical Compaction and Segment Compaction. Vertical Compaction supports loading of only part of the columns, so it can reduce storage consumption when compacting flat tables. Segment Compaction can avoid generating too much segments during data writing, and allows for compaction while writing simultaneously.   </p><h2 id="whats-next">What's Next<a href="#whats-next" aria-label="What's Next的直接链接" title="What's Next的直接链接">​</a></h2><p>With an aim to reduce costs and increase service availability, we plan to test the newly released Storage-Compute Separation and Cross-Cluster Replication of Doris, and we embrace any ideas and inputs about the SuperSonic framework and the Apache Doris project.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Networking for introverts (139 pts)]]></title>
            <link>https://www.economist.com/business/2023/09/07/networking-for-introverts-a-how-to-guide</link>
            <guid>37466147</guid>
            <pubDate>Mon, 11 Sep 2023 12:20:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/business/2023/09/07/networking-for-introverts-a-how-to-guide">https://www.economist.com/business/2023/09/07/networking-for-introverts-a-how-to-guide</a>, See on <a href="https://news.ycombinator.com/item?id=37466147">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><h2>Making the business of meeting strangers marginally less awful</h2></section><div><div data-body-id="cp2"><div><figure><div><figcaption>Listen to this story.</figcaption> <p><span>Enjoy more audio and podcasts on<!-- --> <a id="audio-ios-cta" href="https://economist-app.onelink.me/d2eC/bed1b25" target="_blank" rel="noreferrer">iOS</a> <!-- -->or<!-- --> <a id="audio-android-cta" href="https://economist-app.onelink.me/d2eC/7f3c199" target="_blank" rel="noreferrer">Android</a>.</span></p></div><audio controls="" id="audio-player" preload="none" src="https://www.economist.com/media-assets/audio/060%20Business%20-%20Bartleby%20copy-452e13ecc2cba8a5207cbc25654ef43a.mp3" title="Networking for introverts: a how-to guide " controlslist="nodownload"><p>Your browser does not support the &lt;audio&gt; element.</p></audio></figure></div><p data-component="paragraph"><span data-caps="initial">C</span><small>orporate life</small> throws up some stressful moments. Bringing bad news to your boss; facing an interview panel; making a big presentation. But few things are worse than networking if you are an introvert.</p><p data-component="paragraph">You arrive at an event to find that everyone there apparently knows each other already. And then you look more closely and spot the fellow-sufferers. They are the people who are actually reading the conference blurb. They look at email on their phones with greater intensity than ever happens at the office. They endlessly circulate the room, like bits of plastic in the ocean waiting to be snagged on something. They take a seat in the main hall while the sound engineers are still testing the microphones.</p><p data-component="paragraph">Fortunately, there is advice out there on how to break the ice with strangers. Unfortunately, it’s abysmal. One sage counsels making contact in queues, because it is easier to talk to the person in front of you and behind you. You are meant to ambush people on the escalator, in the toilets and in the queue to get your name tag. In the line for coffee, open the door to jobs and sales by saying six incomprehensible words: “Juicing up for the big keynote?”</p><p data-component="paragraph">On it goes. Don’t be afraid to laugh, because nothing drains the tension from a room like someone who cannot stop chuckling. Bring personal information into the conversation, lest people think you are at a conference on treasury-management software only for commercial gain. Use the other person’s name twice, to appear truly engaged. And take notes on conversations afterwards so you can follow up with them.</p><p data-component="paragraph">Add these ingredients together, and you have the recipe for success:</p><p data-component="paragraph">“Juicing up for the big keynote?”</p><p data-component="paragraph">“What?”</p><p data-component="paragraph">“Juicing up for the big keynote?”</p><p data-component="paragraph">“I don’t know what that means.”</p><p data-component="paragraph">[Scan name badge] “Keith, is it?”</p><p data-component="paragraph">“Er, yes.”</p><p data-component="paragraph">[Laughing] “I’m having a baby, Keith.”</p><p data-component="paragraph">“Keith?”</p><p data-component="paragraph">[Take out notepad]</p><p data-component="paragraph">If this is how to network, no wonder people go to the main hall early.</p><p data-component="paragraph">Making contacts on a site like LinkedIn is a lot less stressful. There is no eye contact, after all, and the rules of the road are agreed. And all those connection requests do appear to help with careers. A paper published last year by Karthik Rajkumar of LinkedIn and co-authors from academia found empirical evidence for the insight that underpins all kinds of networking—that, because they bring you new information, more infrequent and distant relationships (or “weak ties”) are more useful than close contacts.</p><p data-component="paragraph">The researchers randomly changed the “People You May Know” recommendations algorithm that LinkedIn shows its users, so that the prevalence of weaker and stronger connections varied among people on the site. The experiment showed that weaker ties (where a pair of users had only one mutual friend, say) were more likely to lead to job applications and job moves than those where people had 25 mutual friends or more.</p><p data-component="paragraph">This sounds like nirvana for introverts: start spamming everyone with connection requests, close the office door and wait for job offers. But it is not that easy. Even weak ties need tending. Even online, interacting with people is easier if you find it energising; a survey-based study of LinkedIn, by Joanna Davis of Augustana College and her co-authors, found that extroversion was a predictor of networking ability.</p><p data-component="paragraph">There isn’t a genuinely painless way for introverts to network. Still, methods to do it exist that are wiser than standing in a queue and hoping the guy who doesn’t know how to get coffee out of the machine is your ticket to career success.</p><p data-component="paragraph">The real secret is to save your energy for the people who are most likely to be interesting to you. In the online realm, for instance, Dr Rajkumar’s study does not find that the weaker the tie, the better. The sweet spot in networking on LinkedIn is someone with moderately weak ties to you: connecting with a person with ten mutual friends markedly increases the probability of changing jobs compared with someone with just one shared friend.</p><p data-component="paragraph">In other words, networking pays off if you can identify people who can bring you new information but are close enough to your world that this information is useful. In the offline world, a tool like Chat<small>GPT</small> should make it easier to find useful prospects in a list of event attendees. But you still need to overcome all your instincts and approach them.<span>■</span></p><p data-component="paragraph"><b>Read more from Bartleby, our columnist on management and work:<br></b><i><a href="https://www.economist.com/business/2023/08/31/the-best-bosses-know-how-to-subtract-work">The best bosses know how to subtract work</a> (Aug 31st)<br></i><i><a href="https://www.economist.com/business/2023/08/24/the-benefits-of-a-good-workplace-mentoring-scheme-are-undeniable">How to get the most out of mentoring</a> (Aug 24th)<br></i><i><a href="https://www.economist.com/business/article66888-prod.ece" target="_blank">A retiring consultant’s advice on consultants</a> (Jul 17th)</i></p><p data-component="paragraph"><i>Also: How the Bartleby column <a href="https://www.economist.com/column-names">got its name</a></i></p></div><p>This article appeared in the Business section of the print edition under the headline "Stranger things"</p><div data-tracking-id="content-well-chapter-list"><h2><a href="https://www.economist.com/business/">Business</a> <span>September 9th 2023</span></h2><ul><li><a href="https://www.economist.com/business/2023/09/03/meet-ernie-chinas-answer-to-chatgpt"><span>Meet Ernie, China’s answer to ChatGPT</span></a></li><li><a href="https://www.economist.com/business/2023/09/07/german-builders-are-on-the-brink-of-collapse"><span>German builders are on the brink of collapse</span></a></li><li><a href="https://www.economist.com/business/2023/09/07/tiktok-is-wading-into-south-east-asias-e-commerce-wars"><span>TikTok is wading into South-East Asia’s e-commerce wars</span></a></li><li><a href="https://www.economist.com/business/2023/09/07/a-strike-at-chevron-shows-a-reinvigorated-union-movement"><span>A strike at Chevron shows a reinvigorated union movement</span></a></li><li><a href="https://www.economist.com/business/2023/09/07/meet-the-worlds-most-enduring-product"><span>Meet the world’s most enduring product</span></a></li><li><a href="https://www.economist.com/business/2023/09/07/networking-for-introverts-a-how-to-guide"><span>Networking for introverts: a how-to guide</span></a></li><li><a href="https://www.economist.com/business/2023/09/04/americas-bosses-just-wont-quit-that-could-spell-trouble"><span>America’s bosses just won’t quit. That could spell trouble</span></a></li></ul></div><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img alt="The new Middle East: The promise and the perils" loading="lazy" width="1280" height="1684" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/img/b/16/21/90/media-assets/image/20230909_DE_EU.jpg 16w, https://www.economist.com/img/b/32/42/90/media-assets/image/20230909_DE_EU.jpg 32w, https://www.economist.com/img/b/48/63/90/media-assets/image/20230909_DE_EU.jpg 48w, https://www.economist.com/img/b/64/84/90/media-assets/image/20230909_DE_EU.jpg 64w, https://www.economist.com/img/b/96/126/90/media-assets/image/20230909_DE_EU.jpg 96w, https://www.economist.com/img/b/128/168/90/media-assets/image/20230909_DE_EU.jpg 128w, https://www.economist.com/img/b/256/336/90/media-assets/image/20230909_DE_EU.jpg 256w, https://www.economist.com/img/b/360/473/90/media-assets/image/20230909_DE_EU.jpg 360w, https://www.economist.com/img/b/384/505/90/media-assets/image/20230909_DE_EU.jpg 384w, https://www.economist.com/img/b/480/631/90/media-assets/image/20230909_DE_EU.jpg 480w, https://www.economist.com/img/b/600/789/90/media-assets/image/20230909_DE_EU.jpg 600w, https://www.economist.com/img/b/834/1097/90/media-assets/image/20230909_DE_EU.jpg 834w, https://www.economist.com/img/b/960/1263/90/media-assets/image/20230909_DE_EU.jpg 960w, https://www.economist.com/img/b/1096/1441/90/media-assets/image/20230909_DE_EU.jpg 1096w, https://www.economist.com/img/b/1280/1684/90/media-assets/image/20230909_DE_EU.jpg 1280w, https://www.economist.com/img/b/1424/1873/90/media-assets/image/20230909_DE_EU.jpg 1424w" src="https://www.economist.com/img/b/1424/1873/90/media-assets/image/20230909_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the September 9th 2023 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents </p><a href="https://www.economist.com/printedition/2023-09-09" data-analytics="sidebar:weekly_edition"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1zm.142 4.5l-1.008 1.062c3.33 3.276 4.194 4.14 4.608 4.5-1.602-.018-3.168-.018-10.242-.018v1.584c7.074 0 8.73 0 10.242-.018-.432.36-1.314 1.206-4.608 4.536l1.008 1.044 6.354-6.354L12.142 5.5z" fill="#2E45B8" fill-rule="nonzero"></path></g></svg><span>Explore the edition</span></a></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Project Gutenberg Open Audiobook Collection (283 pts)]]></title>
            <link>https://marhamilresearch4.blob.core.windows.net/gutenberg-public/Website/index.html</link>
            <guid>37466027</guid>
            <pubDate>Mon, 11 Sep 2023 12:06:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marhamilresearch4.blob.core.windows.net/gutenberg-public/Website/index.html">https://marhamilresearch4.blob.core.windows.net/gutenberg-public/Website/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=37466027">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="particles">
        
        <p><strong>Thousands of free and open audiobooks powered by Microsoft AI</strong></p>
      </div><div id="Paper">
    <h2>Paper</h2>
    <div>
      <p>
        <h2>For more technical information on the code used to generate these audiobooks please see our IEEE Big Data paper: <a href="https://arxiv.org/abs/2009.08044">Large Scale Intelligent Microservices</a>‍<br></h2>
        
      </p>
      <p>@article{hamilton2020large,<br> &nbsp;title={Large-Scale Intelligent Microservices},<br> &nbsp;author={Hamilton, Mark and Gonsalves, Nick and Lee, Christina <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and Raman, Anand and Walsh, Brendan and Prasad, Siddhartha<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and Banda, Dalitso and Zhang, Lucy and Zhang, Lei and Freeman, William T},<br> &nbsp;journal={arXiv preprint arXiv:2009.08044},<br> &nbsp;year={2020}}</p>
    </div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The right to data ownership is the only way to take on Big Tech (221 pts)]]></title>
            <link>https://www.telegraph.co.uk/business/2023/09/11/right-data-ownership-big-tech-google-meta-competition/</link>
            <guid>37465972</guid>
            <pubDate>Mon, 11 Sep 2023 12:02:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.telegraph.co.uk/business/2023/09/11/right-data-ownership-big-tech-google-meta-competition/">https://www.telegraph.co.uk/business/2023/09/11/right-data-ownership-big-tech-google-meta-competition/</a>, See on <a href="https://news.ycombinator.com/item?id=37465972">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-test="article-body-text">
  
  

	

	
	

	
	



  
  
    <p>Today, giant technology companies are more powerful than any nation state. Their whims set the political agenda.&nbsp;</p><p>Ian Bremmer calls this “technopolarity”, describing how digital power defines politics and reshapes the world. For example, consider their enthusiasm for AI regulation: laws which could in theory be written and enforced by them.&nbsp;</p><p>This does not seem healthy for either the economy or our democracy – so can anything on Earth stop Big Tech?</p><p>One argument is that we should not worry. As sure as eggs are eggs, we are told, a period of market dominance will be followed by hubris, in a self-correcting cycle.&nbsp;</p><p>Just look at Microsoft, they say. Twenty-five years ago this month, the software company surpassed General Electric to become the most valuable on the planet.&nbsp;</p><p>The same month, a tiny new company with an odd name was formally incorporated. It called itself Google. By 2012, it had overtaken Microsoft’s market capitalisation, although Microsoft has subsequently caught up.&nbsp;</p><p>This week, <a href="https://www.telegraph.co.uk/business/2023/09/10/google-monopoly-lawsuit-antitrust-trial-doj-kent-walker/" target="_blank" rel="noopener noreferrer">the biggest antitrust trial</a> since the American government took on Microsoft begins – and this time it is Google who is in the dock. So don’t worry about monopolies: it seems the system takes care of itself. Everything is for the best in all possible worlds, as Voltaire’s Dr Pangloss assured us.</p>
  
</div><div data-test="article-body-text">
  
  

	

	
	

	
	



  
  
    <p>How neat this is – perhaps too neat. For a start, monopoly profits ought to see private capital flooding into startups and would-be rivals, to grab their market share.&nbsp;</p><p>Startups like Neeva, for example, the search engine I wrote about last year, founded by top ex-Google executives and engineers. Its search results were so good, compared to Google’s, <a href="https://www.telegraph.co.uk/technology/2022/05/30/seen-google-free-future-like-breathing-clean-air/" target="_blank" rel="noopener noreferrer">they were like a breath of fresh&nbsp;air</a>. More fool me, though.</p><p>Neeva announced it was closing down for good in May, unable to make a business out of its superior product. In fact, there has not been a major new platform to challenge the incumbents for well over a decade. Capital keeps finding other things to fund, even some very silly things, like lab grown meat.</p><p>But advocates of strong competition law also have a problem. Very often, <a href="https://www.telegraph.co.uk/news/2023/06/15/the-eu-might-just-break-the-internet/" target="_blank" rel="noopener noreferrer">the authorities are all bark</a>, and no bite – and the European Union is one of the worst offenders in this regard.&nbsp;</p><p>The top Silicon Valley lawyer behind the Microsoft antitrust case, Gary Reback conceded as much when he also advised us not to worry. The mere act of competition scrutiny benefits the market: “the trial is the remedy”, he has said.</p><p>But very often the competition watchdog’s intervention seems to have no impact at all, and has only made the dominant player stronger. Google has run rings around competition authorities by appearing to take it on the chin, then offering up a less onerous behavioural remedy.&nbsp;</p><p>This is accepted and life carries on much as before. Structural remedies do not necessarily improve things much either. When in 2000, a Microsoft breakup was privately shopped around its computer rivals, it seemed nobody wanted to take any of the chopped up pieces of the company.</p><p>So if doing nothing is not an option and doing something is ineffective, what else is left to do?&nbsp;</p>
  
</div><div data-test="article-body-text">
  
  

	

	
	

	
	



  
  
    <p>Something needs to change, for just as advocates of the theory of network effects predicted, online markets are winner-takes all markets. Big Tech only ever seems to get bigger.</p><p>But do not despair – the answer may be a very old one.</p><p>Today, Google is no more about web search or maps than those American candy shops on Oxford Street are in the business of selling sweets. That is what we see when we walk past, but it is not really what they do.&nbsp;</p><p>Google and Meta, Facebook’s parent company, are giant personal data processing companies. But because of a peculiar loophole, they get that data for free – it doesn’t “belong” to anyone.&nbsp;</p><p>If only we were allowed to assert ownership of our data, in the form of a strong property right, we could start to do some interesting things with it.&nbsp;</p><p>We could demand its destruction, because it would be ours, giving us much stronger privacy protection than we enjoy today. We would also be able to trade it and do the one thing we cannot currently – help determine its value.&nbsp;</p><p>Our decisions would help set the price for this data. This is not a popular idea with everyone. Academics and the digital NGOs, a familiar looking blob, hate the prospect, in part because it leaves them with a diminished political role, if any at all.</p><p>The computer scientist Jaron Lanier, the best-known advocate of the idea of stronger property rights, says “some people are horrified by the idea of capitalism online, but this would be a more honest capitalism. The familiar ‘free’ arrangement has been a disaster.” He calls it “Data Dignity”.</p><p>I am not suggesting property rights are a panacea, or a replacement for careful and enlightened competition enforcement by nation states. But in the spirit of experimentation, should we not try the one thing we have not actually tried online yet – capitalism?</p>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Removing Garbage Collection from the Rust Language (2013) (163 pts)]]></title>
            <link>http://pcwalton.github.io/_posts/2013-06-02-removing-garbage-collection-from-the-rust-language.html</link>
            <guid>37465185</guid>
            <pubDate>Mon, 11 Sep 2023 10:23:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://pcwalton.github.io/_posts/2013-06-02-removing-garbage-collection-from-the-rust-language.html">http://pcwalton.github.io/_posts/2013-06-02-removing-garbage-collection-from-the-rust-language.html</a>, See on <a href="https://news.ycombinator.com/item?id=37465185">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>I've been floating ways to simplify the memory management story in Rust around the core team lately. Memory management is a contentious topic, since we've worked hard to get to the current state of things, and with the push toward stability lately, there is a (quite reasonable!) resistance to any changes at this state. Still, I think the current memory management story in Rust is worth revisiting, as the current state of things may cause us problems down the line. Working with Dave Herman and Niko Matsakis, I've formulated a fairly concrete proposal at this point. The basic idea is to <em>remove garbage collection from the core language and relegate it to the standard library</em>, with a minimal set of language hooks in place to allow for flexible, pluggable automatic memory management.</p>
<p>This post is designed to explain the "why", not the "how"—I'm leaving the concrete details of the proposed system to a future blog post or mailing list discussion. Rather, this explains the issue that I see with the current system. I think that the garbage collection story as it stands in Rust is not quite ideal, for three reasons: <em>familiarity</em>, <em>simplicity</em>, and <em>flexibility</em>. I'll cover each in turn.</p>
<h2>Familiarity</h2>
<p>One of the most common questions almost every Rust beginner asks is "when do I use managed pointers, and when do I use owned pointers?" Or, more simply, "what are all these <code>~</code> and <code>@</code> symbols everywhere?" Having worked on Rust for many years now, I've seen several reasons for the difficulty. Chief among them are:</p>
<ol>
<li>
<p><em>The difference between the stack and the heap is a difficult concept to grasp for many programmers used to languages like Java that don't make such a distinction.</em> This is, unfortunately, a fundamental difficulty of working in a systems language. There's little that can be done about this without taking control of allocation out of the hands of the programmer. Doing that, however, would compromise the goals of the language—in low-level, performance-critical programming, being able to precisely control whether allocations occur on the stack or on the heap is crucial.</p>
</li>
<li>
<p><em>The sigils make the code unfamiliar before the concepts are learned.</em> Unlike the rest of the punctuation in Rust, <code>~</code> and <code>@</code> are not part of the standard repertoire of punctuation in C-like languages, and as a result the language can seem intimidating. One of the benefits of keywords is that they are self-documenting in a way that punctuation is not. This could be fixed by switching to keywords, which I prefer for this reason; however, syntactic beauty is in the eye of the beholder and so I won't lose sleep over this not changing if the community prefers the current syntax.</p>
</li>
<li>
<p><em>There are two heaps, not just one, so beginners are confused as to which one to allocate into.</em> This is a result of the "minimize sharing by default" philosophy of the concurrency system. However, the concurrency system has been part of the <em>library</em> rather than the language for several years now, so this seems somewhat out of place.</p>
</li>
<li>
<p><em>Programmers don't know which to use, since some operations are available with <code>~</code> and some operations are available with <code>@</code></em>. Actually, we were confused on this point for a long time as well—it wasn't clear whether <code>~</code> or <code>@</code> would become dominant. We debated for a long time which to present first, <code>~</code> or <code>@</code>. However, as the language and community evolved, and coding standards became more settled, a clear winner emerged: the owning pointer <code>~</code>. In practice, the rule has been that <em>programmers should use <code>~</code> to allocate in all circumstances except when they have no way of knowing precisely when the object in question should be freed.</em></p>
</li>
</ol>
<p>Point (4), to me, is the most critical. The rule that emerged—<code>~</code> over <code>@</code>—should not be surprising, in retrospect, as it is how systems software has been developed for decades. The key insight that was missing is that <em>the owning pointer <code>~</code> is just the Rust equivalent of <code>malloc</code> and <code>free</code>.</em> For many, probably most C programs, <code>malloc</code> and <code>free</code> are just fine (assuming you use them correctly, of course); each heap allocation is allocated in just one place and destroyed in just one place. Only when the lifetimes of objects become very complex do C and C++ programmers resort to manual reference counting to determine when an object should be freed (and many, perhaps most, C programs never get there). <em>This</em> is the role that has emerged for <code>@</code> in Rust programs: <code>@</code> is a replacement for manual reference counting in C programs. The <code>kobject</code> system in the Linux kernel, the <code>GObject</code> system in <code>glib</code>, and so forth, are the C equivalents of <code>@</code> in Rust.</p>
<p>The key point here is that these are very specialized use cases in C, and <code>@</code> has been relegated to a similarly marginal role in idiomatic Rust code. We thought for a while that many Rust programs would use <code>@</code> extensively and that it would ease the learning curve for those not used to destructor-based memory management and references. This has not, however, been the case in practice. In reality, since the libraries all use owning pointers (<code>~</code>), Rust programmers have to learn them quickly anyhow. And once Rust programmers learn how to use <code>~</code> effectively, they quickly find <code>@</code> relegated to a marginal role, if it's used at all. <code>~</code> has so many advantages: deterministic allocation and destruction, interaction with the standard library, freedom from GC marking pauses, simpler semantics, appendability where vectors and strings are concerned, and sendability across tasks.</p>
<p>I think we're better off teaching <code>~</code> as the go-to solution for most programs and relegating <code>@</code> to a specialized role. <code>@</code> has its use cases, to be sure; large, event-driven C++ programs use reference counting for a reason. But those use cases are specialized. Beginners should not be asking "should I use <code>~</code> or <code>@</code>?" The answer is almost always <code>~</code>.</p>
<p>In this regard relegating <code>@</code> to a library is just the natural conclusion of this approach. I feel that what beginners should be taught is that <code>~</code> is the way to allocate in Rust, and letting an <code>~</code> owning pointer go out of scope is the way you free in Rust. This is what we should be teaching in the <em>language</em> tutorial. As beginners become more comfortable with this and explore the libraries, they will learn about ways to achieve more dynamic memory management: tracing garbage collection with the <code>Gc</code> type, reference counting with the <code>Rc</code> type, and thread-safe reference counting with the <code>Arc</code> type. But by building only <code>~</code> into the language, we can reduce confusion by, in effect, making the language more opinionated.</p>
<h2>Simplicity</h2>
<p>Although Rust didn't start out that way, one of the most interesting applications of Rust has been very low-level programming, even down to the level of kernels. The interest in this application of Rust was something of a surprise to us, but in hindsight it makes perfect sense. Low-level control over memory management isn't something that most applications software, especially on the server side, wants; most of that software has migrated over to languages like Java, Ruby, and JavaScript that trade control and performance for convenience by making memory management automatically, and dynamically, managed by the runtime. The remaining class of software, most of which is written in C and C++, is software that must manage memory manually in order to achieve some combination of performance, simplicity, and/or the ability to self-host. The prospect of using a new language for <em>this</em> class of software, which includes OS kernels, game engines, and browser engines among others, is what is fueling the growth of the nascent Rust community.</p>
<p>It might be possible to create a language that presents only a simple, fully automatic memory management system at first, and which surfaces the machinery of safe manual memory management* only when the programmer requires it for maximum performance. This would ease the learning curve, as programmers would be able to write many, perhaps most programs without ever learning how to manage memory at all. However, at this point I don't think that this language exists yet, and in particular I don't think Rust is that language. There are basically two problems here: (1) <code>~</code> owning pointers are everywhere in Rust, from the standard library to the built-in macros, making learning about them a necessity from the get-go; and (2) it is basically impossible to program Rust without at least a cursory understanding of references (a.k.a. <code>&amp;</code> pointers) and their lifetime semantics; even <code>vec::each()</code> uses references.</p>
<p>Despite the fact that this might seem like a negative result, I actually think it's quite positive for the project. It helps to define the project's scope. I don't think automatic memory management in Rust is ever going to be as convenient as memory management in, say, Ruby or Java, and that's OK! <em>The same level of control that adds cognitive overhead to memory management in Rust compared to other languages also makes Rust able to go where few other industry languages have.</em> This space, I think, is where Rust can really shine.</p>
<p>In short, I think that Rust as a <em>language</em> should focus on roughly the same application domain as C++ does.†</p>
<p>Important to this effort is to have as small of a runtime as possible, just as C++ does, leaving higher-level abstractions to libraries. And, in fact, we are almost there already. The only runtime support that compiled Rust programs require are a small set of "language items", which are magic functions or traits written <em>in Rust</em> that are known to the compiler. Looking at the set of language items, and disqualifying legacy items that will be removed soon such as <code>annihilate</code> and <code>log_type</code>, there are just a few categories:</p>
<ol>
<li>
<p>Operator traits, like <code>Add</code> and <code>Sub</code>. These are analogous to <code>operator+</code>, <code>operator-</code>, and so forth in C++.</p>
</li>
<li>
<p>Memory primitives, like <code>str_eq</code>. These are somewhat legacy at this point and probably could be converted to LLVM intrinsics like <code>memcmp</code> without much trouble, especially after dynamically sized types happens. In any case, in most C++ compilers <code>memcmp</code> and friends are builtins.</p>
</li>
<li>
<p>Failure: <code>fail</code> and <code>fail_bounds_check</code>. This is analogous to <code>throw</code> in C++, although a Rust program that doesn't want to use stack unwinding might want to use <code>abort</code> instead (which would be like <code>-fno-exceptions</code>) or do something more elaborate like the Linux kernel's "oops" functionality.</p>
</li>
<li>
<p>Allocation primitives <code>malloc</code> and <code>free</code>. These have direct C++ equivalents: <code>operator new</code> and <code>operator delete</code>.</p>
</li>
<li>
<p>Garbage collection primitives.</p>
</li>
</ol>
<p>Of these, the only language items that don't have direct C++ equivalents are the garbage collection primitives. If those were eliminated, then Rust as a language would be every bit as freestanding as C++ is. In terms of suitability for kernel and embedded development, Rust would be on truly equal footing.</p>
<p>In summary: (1) all Rust programmers have to know how <code>~</code> and <code>&amp;</code> work, despite the presence of <code>@</code>; (2) the only additional runtime primitives that Rust exposes and C++ doesn't are those related to <code>@</code>.</p>
<h2>Flexibility</h2>
<p>When it comes to memory management, there are obviously many different strategies: stack allocation, heap allocation with <code>malloc</code> and <code>free</code>, arena allocation, and garbage collection. What's less well known is that even among garbage collection, there are many different approaches, each with advantages and disadvantages. There's thread-local GC, thread-safe GC, incremental GC, generational GC, reference counting, thread-safe reference counting, deferred reference counting, ulterior reference counting—the list goes on and on. (For a good survey of automatic memory management techniques and how they relate to one another, check out <a href="http://www.cs.virginia.edu/~cs415/reading/bacon-garbage.pdf">"A Unified Theory of Garbage Collection" by Bacon et al.</a>) A program that wants to maximize performance among some axis (latency versus throughput) and remain safe with objects with complex lifetimes may have reasons to choose one or the other.</p>
<p>Specifically, there's the perennial debate between reference counting and tracing garbage collection. Many applications are better with tracing GC because of the increased throughput it provides and straightforward handling of cycles, and many applications are better with reference counting because of implementation simplicity, cache behavior, mostly-incremental operation, and promptness of deallocation. It makes sense for applications to be able to choose between the two. Even more important is the tradeoff between thread-safe and thread-local garbage collection: concurrent garbage collection is practically always more expensive than thread-local garbage collection, so it makes sense for programs to restrict concurrent GC (including atomic reference counting) to be used only when needed.</p>
<p>Integrating multiple tracing garbage collectors or cycle collectors into one system is a hard problem, and I don't think Rust is going to really solve it. However, integrating reference counting into a garbage collected system is straightforward, as long as cycles are not created (and in Rust we can forbid the creation of such cycles through clever use of the type system). In practice this seems to work well: we typically use thread-local tracing GC for data with complex lifetimes within one task, and we use thread-safe reference counting for data that must be shared between tasks.</p>
<p>Equally important is the ability to integrate with <em>external</em> garbage collection systems (usually reference counted ones). This is a problem that is often overlooked, but is terribly important for client software such as mobile apps and browser engines. On Windows, apps must integrate with the reference-counted COM system in order to use DirectX and other APIs. On the Mac and on iOS, apps have to integrate with Objective-C and the closely-related Core Foundation, also reference-counted systems. On Linux, GNOME apps have to integrate with GObject, again a reference-counted system. On Android, apps have to integrate with the garbage-collected Dalvik subsystem via the JNI. All of this requires that the memory management system in the language be deeply flexible.</p>
<p>Because of this, I'm suspect of blessing any particular form of automatic memory management in the core language. In Rust, the <code>@</code> type is not only blessed with special syntax, but is eligible for borrowing and other operations in a way that user-defined types aren't. Although Rust provides the facilities needed to build practically all the other forms of garbage collection, as well as those needed to integrate with external GC systems in a safe way, the resulting smart pointers feel second-class compared to <code>@</code>. A systems language designed to work in a diverse set of environments should have the flexibility to create memory management abstractions that feel first-class.</p>
<h2>Conclusion</h2>
<p>For these three reasons—familiarity, simplicity, and flexibility—I'd like to propose removing <code>@</code> pointers from the language and replacing them with a small set of hooks allowing the same functionality to be implemented as a library and on user-defined types. We would ship tracing GC as part of the standard library and make it just as powerful and convenient as it is today (except for the <code>@</code> syntax). We'd gain a flexible set of abstractions, make the language easier to learn, and make Rust into a truly freestanding language environment.</p>
<p>* Note that the <em>safe</em> qualifier here disqualifies manually-built free lists in garbage-collected languages, as these manually-built free lists provide no protection against errors like double "frees", leaks, and danging pointers. (They're significantly worse than true manual memory management anyhow; the GC still has to trace through objects in arenas at mark time, copy the objects within out into the tenured generation when they survive a minor collection, write barrier the objects, and so forth.)</p>
<p>† Note that I don't mean you shouldn't write Web frameworks and Web sites in Rust: in fact, I think Rust would be a fantastic language for many classes of Web server software, especially that which must scale to the highest loads and squeeze every ounce of performance out of the servers on the racks.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The SHA256 for this sentence begins with: one, eight, two, a, seven, c and nine. (157 pts)]]></title>
            <link>https://twitter.com/lauriewired/status/1700982575291142594</link>
            <guid>37465086</guid>
            <pubDate>Mon, 11 Sep 2023 10:08:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/lauriewired/status/1700982575291142594">https://twitter.com/lauriewired/status/1700982575291142594</a>, See on <a href="https://news.ycombinator.com/item?id=37465086">Hacker News</a></p>
Couldn't get https://twitter.com/lauriewired/status/1700982575291142594: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[30 years of The X-Files (103 pts)]]></title>
            <link>https://arstechnica.com/culture/2023/09/the-truth-is-out-there-celebrate-30-years-of-the-x-files-with-our-30-favorite-episodes/</link>
            <guid>37464576</guid>
            <pubDate>Mon, 11 Sep 2023 08:51:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/culture/2023/09/the-truth-is-out-there-celebrate-30-years-of-the-x-files-with-our-30-favorite-episodes/">https://arstechnica.com/culture/2023/09/the-truth-is-out-there-celebrate-30-years-of-the-x-files-with-our-30-favorite-episodes/</a>, See on <a href="https://news.ycombinator.com/item?id=37464576">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/pilot-800x535.jpg" alt="Mulder sitting at his desk, Scully sitting on top of it, with " i="" want="" to="" believe="" poster="" in="" the="">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/08/pilot.jpg" data-height="802" data-width="1200">Enlarge</a> <span>/</span> FBI agents Fox Mulder (David Duchovny) and Dana Scully (Gillian Anderson) were the heart and soul of <em>The X-Files</em>.</p><p>20th Century Fox</p></figcaption>  </figure>

  




<!-- cache hit 60:single/related:c9f3407209fffb29899b23a2484a42b2 --><!-- empty -->
<p>In September 1993, fictional FBI Special Agents <a href="https://en.wikipedia.org/wiki/Fox_Mulder">Fox Mulder</a> (David Duchovny) and <a href="https://en.wikipedia.org/wiki/Dana_Scully">Dana Scully</a> (Gillian Anderson) made their broadcast TV debut on <a href="https://en.wikipedia.org/wiki/The_X-Files"><em>The X-Files</em></a> and went on to investigate alien abductions and all manner of strange phenomena for nine full seasons and <a href="https://en.wikipedia.org/wiki/The_X-Files_(film)">two</a> feature <a href="https://en.wikipedia.org/wiki/The_X-Files:_I_Want_to_Believe">films</a>, followed by two additional limited-run seasons in 2016 and 2018. This hugely popular and influential series celebrates its 30th anniversary this month, giving us a prime opportunity to pay homage to our favorite episodes and characters.</p>
<p><strong>(Spoilers for <em>The X-Files</em> below.)</strong></p>
    <div>
            <p>(Ars Technica may earn compensation for sales from links on this post through <a href="https://arstechnica.com/affiliate-link-policy/">affiliate programs</a>.)</p>
        </div>

<p><em>The X-Files</em> was created by <a href="https://en.wikipedia.org/wiki/Chris_Carter_(screenwriter)">Chris Carter</a>, who was a fan of the 1970s horror series <a href="https://en.wikipedia.org/wiki/Kolchak:_The_Night_Stalker"><em>Kolchak: The Night Stalker</em></a>, featuring a wire service reporter (Darren McGavin) investigating mysterious crimes with a supernatural or science fiction element. Other cited influences included <em>The Twilight Zone, Night Gallery, Twin Peaks</em> (in which Duchovny played a transgender DEA agent), and Jonathan Demme's 1988 Oscar-winning film <em>The Silence of the Lambs</em>.</p>
<p>Carter liked the idea of a TV series featuring FBI agents investigating the paranormal. He deliberately made Mulder (nicknamed "Spooky") the true believer and Scully the science-based skeptic—a gender swap to counter broad cultural stereotypes. Carter described the pair as a dichotomy, representing his desire to believe in something versus an inability to believe—the age-old tension between skepticism and faith.</p>
<p>As the characters developed over subsequent seasons, we saw them internalize that tension, with Mulder sometimes getting discouraged and questioning his longing to believe and Scully being forced to confront how her science sometimes conflicted with her devout Catholic faith. They each had deep personal journeys as well; both lost family members, for instance, and Mulder's obsession with alien abductions was fueled by the disappearance of his sister Samantha when he was a kid. And while Carter was adamant early on that this would be a purely platonic relationship—<em>à&nbsp;la</em> Emma Peel and John Steed in <em>The Avengers</em> British TV series—that changed as the friendship between Mulder and Scully deepened, with increasingly romantic overtones. But the series never openly acknowledged the two having sex until season 11's "<a href="https://en.wikipedia.org/wiki/Plus_One_(The_X-Files)">Plus One</a>."</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/08/lonegunmen1.jpg" data-height="798" data-width="1200" alt="The Lone Gunmen were introduced in the S1 episode &quot;E.B.E.&quot; and soon became fan favorites."><img alt="The Lone Gunmen were introduced in the S1 episode &quot;E.B.E.&quot; and soon became fan favorites." src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/lonegunmen1-640x426.jpg" width="640" height="426" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/08/lonegunmen1.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/08/lonegunmen1.jpg" data-height="798" data-width="1200">Enlarge</a> <span>/</span> The Lone Gunmen were introduced in the S1 episode "E.B.E." and soon became fan favorites.</p><p>20th Century Fox</p></figcaption></figure>
<p><em>The X-Files</em> quickly blossomed from a cult series into a bona fide pop culture phenomenon throughout its first seven seasons, racking up a lot of Emmy and Golden Globe awards. Scully is often credited with encouraging young women to pursue careers in medicine, science, or the FBI, a phenomenon dubbed the "<a href="https://en.wikipedia.org/wiki/Dana_Scully#%22The_Scully_Effect%22">Scully effect</a>."</p>                                            
                                                        
<p>While it started out dealing with UFOs and alien abduction, Carter and his writing team realized early on that it would be difficult to sustain that momentum over multiple seasons. So there were essentially two kinds of episodes: those advancing the over-arching "<a href="https://en.wikipedia.org/wiki/Mythology_of_The_X-Files">mytharc</a>" of the series canon—often featuring appearances by William B. Davis as the iconic <a href="https://en.wikipedia.org/wiki/Cigarette_Smoking_Man">Cigarette Smoking Man</a> (CSM)—and standalone "Monster of the Week" (MOW) episodes unrelated to the series mythology. From horror to humor, shadowy conspiracies to arcane folklore, the series offered something for everyone, a key factor in its broad popular appeal.</p>
<h2>“The Seasons That Shall Not Be Named”</h2>
<p>For the first five seasons, <em>The X-Files</em> filmed in Vancouver, British Columbia, but it moved to Los Angeles starting with the sixth season so that Duchovny could be closer to his then-wife Tea Leoni. When Duchovny's contract expired after the seventh season, he effectively quit the series, though he returned occasionally as Mulder during S8 and S9—or, as I like to call them, "The Seasons That Shall Not Be Named."</p>
<p>This was unquestionably the low point of the series, especially with Anderson also winding down her involvement. Carter apparently convinced himself that he could simply find new leads—in this case, Robert Patrick as <a href="https://en.wikipedia.org/wiki/John_Doggett">John Doggett</a> and Annabeth Gish as <a href="https://en.wikipedia.org/wiki/Monica_Reyes">Monica Reyes</a>—and the show would run indefinitely. But there is simply no <em>X-Files</em> without Mulder and Scully. Add in the deaths of fan favorites <a href="https://en.wikipedia.org/wiki/The_Lone_Gunmen">the Lone Gunmen</a> in "<a href="https://en.wikipedia.org/wiki/Jump_the_Shark_(The_X-Files)">Jump the Shark</a>" (S9), and no wonder ratings steeply declined.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/08/doggettandreyes.jpg" data-height="800" data-width="1200" alt="The series introduced Monica Reyes (Annabeth Gish) and John Doggett (Robert Patrick) as new leads for the eighth and ninth seasons. But there is no <em>X-Files</em> without Mulder and Scully, and ratings sharply declined."><img alt="The series introduced Monica Reyes (Annabeth Gish) and John Doggett (Robert Patrick) as new leads for the eighth and ninth seasons. But there is no <em>X-Files</em> without Mulder and Scully, and ratings sharply declined." src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/doggettandreyes-640x427.jpg" width="640" height="427" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/08/doggettandreyes.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/08/doggettandreyes.jpg" data-height="800" data-width="1200">Enlarge</a> <span>/</span> The series introduced Monica Reyes (Annabeth Gish) and John Doggett (Robert Patrick) as new leads for the eighth and ninth seasons. But there is no <em>X-Files</em> without Mulder and Scully, and ratings sharply declined.</p><p>20th Century Fox</p></figcaption></figure>
<p>The show's original run ended with that ninth season. But <em>The X-Files</em> lived on via DVD and (more recently) streaming platforms, and its hardcore fan base remained fiercely loyal. The 2008 film <a href="https://en.wikipedia.org/wiki/The_X-Files:_I_Want_to_Believe"><em>The X-Files: I Want to Believe</em></a> (with a standalone MOW plot) received mixed reviews and didn't exactly light up the box office, but it grossed $68 million against its $30 million budget. That was enough to spark rumors of a possible third film; both Duchovny and Anderson expressed a willingness to co-star.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Chrome just rolled out a new way to track you and serve ads (477 pts)]]></title>
            <link>https://theconversation.com/google-chrome-just-rolled-out-a-new-way-to-track-you-and-serve-ads-heres-what-you-need-to-know-213150</link>
            <guid>37464574</guid>
            <pubDate>Mon, 11 Sep 2023 08:50:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/google-chrome-just-rolled-out-a-new-way-to-track-you-and-serve-ads-heres-what-you-need-to-know-213150">https://theconversation.com/google-chrome-just-rolled-out-a-new-way-to-track-you-and-serve-ads-heres-what-you-need-to-know-213150</a>, See on <a href="https://news.ycombinator.com/item?id=37464574">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Late last week, Google announced something called the Privacy Sandbox has been rolled out <a href="https://privacysandbox.com/intl/en_us/news/privacy-sandbox-for-the-web-reaches-general-availability">to a “majority” of Chrome users</a>, and will reach 100% of users in the coming months. But what is it, exactly? </p>

<p>The new suite of features represents a fundamental shift in how Chrome will track user data for the benefit of advertisers. Instead of third-party cookies, Chrome can now tap directly into your browsing history to gather information on advertising “topics” (more on that later).</p>

<p>In development since 2019, this change has attracted <a href="https://gizmodo.com/google-privacy-sandbox-now-on-every-chrome-browser-1850812404">a great deal of controversy</a>, as some commentators have deemed it <a href="https://arstechnica.com/gadgets/2023/09/googles-widely-opposed-ad-platform-the-privacy-sandbox-launches-in-chrome/">invasive in terms of privacy</a>.</p>

<p>Understanding how it works – and whether you want to opt in or out – is important, since Chrome remains the most widely used browser in the world, with a 63% market share <a href="https://www.statista.com/statistics/268254/market-share-of-internet-browsers-worldwide-since-2009/">as of May 2023</a> (Safari is in second place with 13%).</p>

<h2>Wait, what is a cookie?</h2>

<p>In 1994, computer engineer Lou Montulli at Netscape revolutionised the way we browsed the internet with his <a href="https://montulli.blogspot.com/2013/05/the-reasoning-behind-web-cookies.html">invention of the “cookie</a>”. For the first time, web pages could remember our passwords, preferences, language settings and even shopping carts.</p>

<p>This method was supposed to be a private exchange of information just between a user and a website – what’s known as a first-party cookie. But within two years, advertisers worked out how to “hack” cookies <a href="https://qz.com/2000350/the-inventor-of-the-digital-cookie-has-some-regrets">to track users</a>. These are third-party cookies.</p>

<p>You can think of a first-party cookie like a shop assistant who listens to your preferences and is happy to hold your bags or clothes while you make your selection – but only while you are inside their store.</p>

<p>A third-party cookie is like a bug from an old spy movie. It listens to everything in your room, but only shares the info with its allies. The “spy” can place this cookie on other people’s sites, to record what you visit and what data you enter. If you’ve ever wondered how Facebook has served you an ad about something related to a news story you just read, chances are it’s because you have third-party cookies enabled.</p>

<p>Unregulated online tracking and surveillance via cookies were the default until 2018, when the European Union’s <a href="https://gdpr.eu/what-is-gdpr/">General Data Protection Regulations</a> (GDPR) and the <a href="https://oag.ca.gov/privacy/ccpa">California Consumer Privacy Act</a> (CCPA) were introduced. If you have noticed more pop-ups notifying you of cookies and asking for your informed consent, you have the GDPR and CCPA to thank.</p>

<hr>
<p>
  <em>
    <strong>
      Read more:
      <a href="https://theconversation.com/cookies-i-looked-at-50-well-known-websites-and-most-are-gathering-our-data-illegally-176203">Cookies: I looked at 50 well-known websites and most are gathering our data illegally</a>
    </strong>
  </em>
</p>
<hr>


<p>The <a href="https://clearcode.cc/blog/third-party-cookies-demise/#safari-and-firefox-turn-off-support-for-third-party-cookies">first browsers</a> to turn off support for third-party cookies were Apple’s Safari in 2017 and Mozilla’s Firefox in 2019.</p>

<p>But Google is also a major online advertising company, with ads <a href="https://www.doofinder.com/en/statistics/google-revenue-breakdown">making up 57.8% of Google’s revenue</a> as of 2023. They <a href="https://www.forbes.com/sites/theyec/2022/09/12/the-slow-death-of-third-party-cookies">have been slowest off the mark</a> in turning off third-party cookies in Chrome. With the introduction of the Privacy Sandbox, they now hope to start turning cookies off sometime in 2024.</p>

<h2>How is the Privacy Sandbox different from cookies?</h2>

<p>The details on how the Privacy Sandbox collection of features works <a href="https://developer.chrome.com/en/blog/shipping-privacy-sandbox/#whats-shipping">are rather technical</a>. But here are a few of the most important aspects.</p>

<p>Instead of using third-party cookies to serve you ads across the internet, Chrome will provide something called advertising Topics. These are high-level summaries of your browsing behaviour, tracked locally (such as in your browsing history), that companies can access on request to serve you ads on particular subjects.</p>

<p>Additionally, there are features such as <a href="https://developer.chrome.com/docs/privacy-sandbox/protected-audience/">Protected Audience</a> that can serve you ads for “remarketing” (for example, Chrome tracked you visiting a listing for a toaster, so now you will get ads for toasters elsewhere), and <a href="https://developer.chrome.com/docs/privacy-sandbox/attribution-reporting/">Attribution Reporting</a>, that gathers data on ad clicks.</p>

<p>In short, instead of third-party cookies doing the spying, the features these cookies enable will be available directly within Chrome.</p>



<h2>Is user tracking necessarily bad?</h2>

<p>While Google pitches the Privacy Sandbox as something that will improve user privacy, <a href="https://movementforanopenweb.com/googles-privacy-sandbox-a-closer-look-at-claims-and-contradictions/">not everyone agrees</a>.</p>

<p>If these features are switched on, Google – one of the world’s biggest advertising companies – is essentially able to listen to you everywhere on the web.</p>

<p>Tracking technology can arguably benefit us as well. For example, it could be helpful if an online store reminds you every three months you need a new toothbrush, or that this time last year you bought a birthday card for your mum.</p>

<p>Offloading cognitive effort, such as reminders like these, is a great way automation can assist humanity. When used in situations where pinpoint accuracy is required, it can make our lives easier and more pleasant.</p>

<p>However, if you are not comfortable with surveillance, the alternative to third-party cookies may not necessarily be the new Privacy Sandbox in Chrome.</p>

<p>The alternative is to completely disable tracking altogether.</p>

<h2>What can you do?</h2>

<p>If you don’t want your online activities to be tracked for advertising purposes, there are a few straightforward choices.</p>

<p>By far the most private browsers are specialist non-tracking browsers that prioritise no tracking, such as <a href="https://duckduckgo.com/">DuckDuckGo</a> and <a href="https://brave.com/">Brave</a>. But if you don’t want to get that nerdy, Safari and Firefox already have third-party cookies blocked by default.</p>

<figure>
            <a href="https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="A screenshot of a Chrome settings page listing Ad topics, Site-suggested ads and Ad measurement" data-src="https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=324&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=324&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=324&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=407&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=407&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=407&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/547410/original/file-20230911-19-1eiqz9.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>The tools found in Google Chrome are nestled under Settings - Ads privacy. You can toggle each section on or off individually, and click on them to look at more details.</span>
              <span><span>Screenshot via The Conversation</span></span>
            </figcaption>
          </figure>

<p>If you don’t mind some useful targeted advertising, you can leave the Chrome Privacy Sandbox settings on.</p>

<p>If you want to adjust these settings or switch them off, click the three dots in the upper-right corner and go to <em>Settings &gt; Privacy and Security &gt; Ad privacy</em>. It’s unclear if toggling these features off will stop Chrome from collecting these data altogether, or if it just won’t share the data with advertisers. You can find out more details about each feature on <a href="https://support.google.com/chrome/answer/13355898">the Google Chrome Help page</a>.</p>

<p>Lastly, it’s good to remember nothing truly comes for free. Software costs money to develop. If you’re not paying towards that, then it’s likely you – or your data – are the product. We need to revolutionise how we think about our own data and what value it truly holds.</p>

<hr>
<p>
  <em>
    <strong>
      Read more:
      <a href="https://theconversation.com/the-ugly-truth-tech-companies-are-tracking-and-misusing-our-data-and-theres-little-we-can-do-127444">The ugly truth: tech companies are tracking and misusing our data, and there's little we can do</a>
    </strong>
  </em>
</p>
<hr>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta deletes Al Jazeera presenter’s profile after show criticising Israel (162 pts)]]></title>
            <link>https://www.aljazeera.com/news/2023/9/10/meta-deletes-al-jazeera-presenters-profile-after-show-criticising-israel</link>
            <guid>37464482</guid>
            <pubDate>Mon, 11 Sep 2023 08:36:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aljazeera.com/news/2023/9/10/meta-deletes-al-jazeera-presenters-profile-after-show-criticising-israel">https://www.aljazeera.com/news/2023/9/10/meta-deletes-al-jazeera-presenters-profile-after-show-criticising-israel</a>, See on <a href="https://news.ycombinator.com/item?id=37464482">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>Tip of the Iceberg episode investigated how Facebook targets Palestinian content related to Israel.</em></p></div><div aria-live="polite" aria-atomic="true"><p>Al Jazeera Arabic presenter Tamer Almisshal has had his Facebook profile deleted by Meta 24 hours after&nbsp;the programme Tip of the Iceberg aired an investigation into Meta’s censorship of Palestinian content titled <a href="https://www.youtube.com/watch?v=cnj0rmnsAdI" target="_blank">The Locked Space</a>.</p>
<p>The programme’s investigation, which aired on Friday, included admissions by Eric Barbing, former head of Israel’s cybersecurity apparatus, about his organisation’s effort to track Palestinian content according to criteria that included “liking” a photo of a Palestinian killed by Israeli forces.</p>
<p>Then the agency would approach Facebook and argue that the content should be taken down.</p>
<p>According to Barbing, Facebook usually complies with the requests and Israel’s security apparatus follows up cases, including bringing court cases if need be.</p>
<p>The investigation followed up on Barbing’s admissions by interviewing a number of human and digital rights experts who agreed that there was a distinct imbalance in how Palestinian content is restricted.</p>
<p>The programme also interviewed Julie Owono, a member of Facebook’s oversight board, who admitted there is a discrepancy in how rules are interpreted and applied to Palestinian content and added that recommendations had been sent to Facebook to correct this.</p>
<p>Al Jazeera has asked Facebook about why Almisshal’s profile was shut down with no prior warning or explanation. It had not received a response by the time of publication.</p>
<h2 id="targeting-a-journalist">‘Targeting a journalist’</h2>
<p>Almisshal said the profile that was deleted is his personal page, set up by him in 2006 and verified. He had at least 700,000 followers on it.</p>
<p>“After the huge success of the episode, I discovered that my personal Facebook profile had been deleted with no explanations given,” he told Al Jazeera. “It really does seem like some kind of revenge for the programme. We haven’t received any response from Facebook yet.”</p>
<p>The programme’s team had set out to investigate how wide the gap was between how Palestinian and Israeli posts and material are treated by Facebook.</p>
<p>To do that, it set up an experiment in which it built two different pages, one with a pro-Palestinian perspective and the other a pro-Israeli one, and ran trials on them. The team concluded that there was indeed a big discrepancy in how much scrutiny there is and how rules are applied to posts on either page.</p>
<blockquote data-width="550" data-dnt="true">
<p lang="en" dir="ltr">A day after Tamer Almisshal, a Palestinian <a href="https://twitter.com/hashtag/journalist?src=hash&amp;ref_src=twsrc%5Etfw">#journalist</a> with <a href="https://twitter.com/hashtag/Jazeera?src=hash&amp;ref_src=twsrc%5Etfw">#Jazeera</a>, presented shocking evidence of Meta's censorship of Palestinian content on its platforms during his "Tip of the Iceberg" TV show, Facebook has taken down his page.<a href="https://twitter.com/hashtag/IsraeliCrimes?src=hash&amp;ref_src=twsrc%5Etfw">#IsraeliCrimes</a> <a href="https://twitter.com/hashtag/Palestine?src=hash&amp;ref_src=twsrc%5Etfw">#Palestine</a> <a href="https://t.co/RGQm8sUuzQ">pic.twitter.com/RGQm8sUuzQ</a></p>
<p>— Hadeel Abo Aita (@aita_hadeel) <a href="https://twitter.com/aita_hadeel/status/1700858011084857400?ref_src=twsrc%5Etfw">September 10, 2023</a></p></blockquote>

<p>It is not clear why Facebook would choose to delete an individual’s page in response to a programme.</p>
<p>“There was no explanation, no warning,” Almisshal said. “There had been no issues with any of the content on my page before. No message saying I had violated any rules.”</p>
<p>Almisshal stands by his programme.</p>
<p>“Last March, Facebook restricted my account, and it has happened other times, but usually the situation is resolved,” he said. “This was a journalistically sound project, and we communicated with Meta for it, giving them the opportunity to speak during the investigation.</p>
<p>“But to target a journalist individually instead – I would never have expected that.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A group of open source Android apps without ads and unnecessary permissions (354 pts)]]></title>
            <link>https://www.simplemobiletools.com</link>
            <guid>37463662</guid>
            <pubDate>Mon, 11 Sep 2023 06:33:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.simplemobiletools.com">https://www.simplemobiletools.com</a>, See on <a href="https://news.ycombinator.com/item?id=37463662">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <div>
                <p>
                    <h2>Let’s stay in touch!</h2>
                </p>

                <div>
                    <form action="https://www.simplemobiletools.com/newsletter" method="POST" novalidate="">
                        
                        <div>
                            <p>

                            <label>
                                <span>Your email address…</span>
                            </label></p><p>Fill in the email address field with a valid email.</p>
                        </div>

                        
                    </form>
                </div>
            </div>

            <p><span>Replacing your Android apps one by one since 2016.</span>

                <span>Copyright © 2023, All Rights Reserved.</span></p>
            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HDMI ISA graphics card for vintage PCs by improving the Graphics Gremlin (239 pts)]]></title>
            <link>https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/</link>
            <guid>37462947</guid>
            <pubDate>Mon, 11 Sep 2023 04:38:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/">https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/</a>, See on <a href="https://news.ycombinator.com/item?id=37462947">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>HDMI is a relatively modern video connector we take for granted on modern PCs and monitors. Now vintage PCs can join in the fun too with a native connection to modern HDMI monitors without any additional adapter.</p>
<h2 id="background">Background</h2>
<p>2 years ago, I learned of an open-source project called Graphics Gremlin (GG) by <a href="https://www.linkedin.com/in/eric-schlaepfer-5ab72315/">Eric Schlaepfer</a> who runs the website <a href="https://tubetime.us/">Tubetime.us</a>. It is an 8-bit ISA graphics card that supports display standards like <a href="https://en.wikipedia.org/wiki/Color_Graphics_Adapter">Color Graphics Adapter (CGA)</a> and <a href="https://en.wikipedia.org/wiki/IBM_Monochrome_Display_Adapter">Monochrome Display Adapter (MDA)</a>. CGA and MDA are display standards used by older IBM(-compatible) PCs in the 1980s.</p>
<p>The frequencies and connectors used by CGA and MDA are no longer supported by modern monitors hence it is difficult for older PCs of the 1980s era to have modern displays connected to them without external adapters. GG addresses this problem by using techniques like scan doubling (for CGA) and increasing the vertical refresh rate (for MDA) then outputing to a relatively newer but still old VGA port.</p>
<p>I fabricated and assembled the design then installed it into my <a href="https://github.com/yeokm1/retro-configs/tree/master/desktops/ibm-5155">IBM5155</a>.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-original.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-original.jpg" width="600"></a></p><p>GG provides outputs in VGA, Composite and DB9 RGBI.</p>
<p>However 2 issues bugged me about this card:</p>
<ol>
<li>
<p>The Composite video and VGA port cannot be used at the same time due to pin sharing between both ports. Switching between them is possible by flipping physical switches on the card. However on my IBM5155, the internal CRT monitor runs on Composite hence if I want to use an external monitor, the internal CRT becomes unusable.</p>
</li>
<li>
<p>Modern monitors have long started to omit the analog VGA inputs in favour of modern digital ports like HDMI or Displayport. This requires a VGA-to-HDMI adapter. This analog-to-digital conversion will also lead to an inevitable loss in video quality. Such adapters also require an external power source such as USB. Vintage PCs usually don’t have USB outputs so supplying power with an additional USB power adapter leads to more setup hassles.</p>
</li>
</ol>
<p>I decided to modify the GG design so it can connect natively to an external HDMI monitor and service the internal Composite-based CRT at the same time.</p>
<h2 id="how-does-the-graphics-gremlin-work">How does the Graphics Gremlin work?</h2>
<p>The core of the GG is the Lattice iCE40HX4K FPGA. It is responsible for handling instructions from the ISA bus and generating the appropriate video signals.</p>
<p>512KiB video RAM is provided by ISSI IS61WV5128BLL. 3 bitstreams are stored in a 8Mbit Microchip SST26VF080A SPI flash. These bitstreams are:</p>
<ol>
<li>MDA output using a VGA compatible 70Hz refresh rate</li>
<li>MDA output to RGBI port at 50Hz refresh rate (incompatible with VGA monitors)</li>
<li>CGA output. RGBI connector will output at 320x200 60Hz while VGA will be scan doubled to 640x400 60Hz.</li>
</ol>
<p>RGBI output is driven directly from the FPGA since it is just a TTL signal. Analog VGA signal is generated using a DAC resistor ladder. Composite is driven from the green VGA pin hence why Composite and VGA cannot be used at the same time.</p>
<p>The code is written in Verilog HDL and uses the open source <a href="https://clifford.at/icestorm">Project Icestorm</a> toolchain.</p>
<p>One interesting thing that the GG design has is it will display a blinking test pattern if it is powered on but the host PC has yet to command it to display anything.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-test-pattern.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-test-pattern.jpg" width="800"></a></p><p>The left is the test pattern for CGA and the right is MDA.</p>
<p>This test pattern proved very useful for me as it means I don’t need the card to be plugged into a PC while I’m testing any code changes.</p>
<h2 id="my-modifications">My Modifications</h2>
<h2 id="summary">Summary</h2>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-top-both.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-top-both.jpg" width="800"></a></p><p>Left is the original GG, right is my modified design.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-board-ports.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-board-ports.jpg" width="800"></a></p><p>View from the ports side.</p>

<p>
  <iframe src="https://www.youtube.com/embed/xLy6on_o4YM" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>This is the demo video using the updated GG card in my IBM5155 outputing HDMI to my 5:4 Dell P1917S monitor and Composite to my small LCD screen.</p>
<p>This video shows the bootup process from a cold start to the DOS 6.22 command line. After that I run <a href="https://github.com/MobyGamer/CGACompatibilityTester">CGA Compatibility tester</a> to check the output.</p>
<p>The entire updated PCB design and Verilog code has been open-sourced here: <a href="https://github.com/yeokm1/graphics-gremlin-hdmi">https://github.com/yeokm1/graphics-gremlin-hdmi</a></p>
<p>Here is a summary of changes I made some which I will cover further down this post.</p>
<ul>
<li>Hardware changes
<ul>
<li>Added HDMI port by removing the RGBI DB9 port. Port positions adjusted to ease trace routing.</li>
<li>Added <a href="https://www.ti.com/product/TFP410">TI TFP410</a> DVI transmitter (HDMI is compatible with DVI). HDMI is independent of the VGA/Composite output.</li>
<li>Test points for inputs to DVI transmitter</li>
<li>Replaced the 3.3VDC 1A linear regulator with 3A as TFP410 is power hungry at up to 1A.</li>
<li>Added pin headers for power.</li>
<li>Added LED power indicators for 5V and 3.3V.</li>
</ul>
</li>
<li>HDL code changes
<ul>
<li>Selectable MDA colours</li>
<li>Removed normal MDA bitstream as there is no more RGBI port.</li>
<li>Added CGA 70Hz mode.</li>
<li>Modified Scandoubler code to support Display Enable signal as required by DVI chip but not VGA</li>
</ul>
</li>
</ul>
<h2 id="hardware-changes">Hardware changes</h2>
<h2 id="hdmi-support-through-dvi-transmitter-ic">HDMI support through DVI transmitter IC</h2>
<p>HDMI (and DVI) use Transition-Minimized Differential Signaling (TMDS) lines. The ICE40 FPGA however does not have that. Online searches garnered that some people have <a href="https://hackaday.io/page/5702-dvi-hdmi-pmod-for-an-ice40-fpga">used workarounds</a> to generate the differential signals however I’m not sure how compatible or spec-compliant those are.</p>
<p>I decided to go for more reliable option by using a dedicated DVI transmitter TI TFP410. I referred to an <a href="https://blackmesalabs.wordpress.com/2017/12/15/bml-hdmi-video-for-fpgas-over-pmod/">open-source PMOD schematic from Black Mesa Labs</a> to integrate this chip into the Graphics Gremlin.</p>
<p>The TFP410 accepts a 24-bit RGB colour data input. Ideally, we should connect all 24 pins to the FPGA directly but there are not many spare pins left in the ICE40HX. The only FPGA pins available are those meant for the external RGBI port which I dropped. These pins include the 4 colour signals, red, green, blue and intensity are thus repurposed to talk to the TFP410.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-tfp410-sch-snippet.png"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-tfp410-sch-snippet.png" width="250"></a></p><p>To simulate an RGBI monitor, the 3 base colour signals are connected to the MSB of the colour input with the intensity bit shared among all as the second-most significant bit.</p>
<p>The TFP410 will also handle the appropriate 8b/10b encoding to ensure a proper TMDS data signal for DVI. Since a HDMI connector is electrically similar to DVI, the DVI transmitter output can be directly wired to the HDMI port.</p>
<h2 id="test-points">Test points</h2>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-board.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-board.jpg" width="800"></a></p><p>Various test points were added to the board. The data inputs from the FPGA to the TFP410 are as follows:</p>
<ul>
<li>Red, Green, Blue, Intensity</li>
<li>Horizontal Sync (HS)</li>
<li>Vertical Sync (VS)</li>
<li>Display Enable (DE)</li>
<li>Clock (CLK)</li>
</ul>
<p>These inputs with 3.3V and GND are broken out as standard 2.54mm pin headers in the style of a PMOD.</p>
<p>I also added power LEDs and pin headers to the left of the board so I can monitor power state and power the board without having to connect to an actual vintage machine with ISA bus and displaying something.</p>
<h2 id="hdl-code-changes">HDL code changes</h2>
<h2 id="supporting-the-dvi-transmitter-chip">Supporting the DVI transmitter chip</h2>
<p>The Verilog code has to be modified to send data in an appropriate format to the DVI chip.</p>
<p>Most of the original RGBI lines meant for the DB9 monitor connector, RGBI, HS, VS lines are similar. However the CLK and DE lines are not used before and hence has to be provided. CLK was relatively easy to get and wire out to the DVI chip. However DE was slightly more problematic.</p>
<p>In the original IBM CGA/MDA graphics card, there exists a chip called a <a href="https://en.wikipedia.org/wiki/Motorola_6845">Motorola 6845</a> which generates the Cathode Ray Tube (CRT) control signals. It is also known as a CRTC6845 and the DE line is also generated here.</p>
<p>In the code, the behaviour of this chip is emulated in <a href="https://github.com/schlae/graphics-gremlin/blob/main/verilog/crtc6845.v">crtc6845.v</a>. The DE line output of this module has to be pulled out and wired to the DVI chip.</p>
<p>In CGA mode, the code contains a <a href="https://github.com/schlae/graphics-gremlin/blob/main/verilog/cga_scandoubler.v">cga_scandoubler.v</a> to double the number of horizontal lines and frequency to change the number of viewable vertical lines from 640x200 to 640x400 to make it more compatible for modern displays. It does this by doing double buffering with 2 arrays. One array is read out twice for each line using twice the usual pixel clock while the other array is being written to by the host PC then both arrays are swapped at the end of line.</p>
<p>I modified this Scandoubler to cache the DE bit as well.</p>
<h2 id="selectable-mda-colours">Selectable MDA colours</h2>
<p>In the original GG, the MDA output is a constant amber (see photo in an earlier section). I didn’t particularly like amber. I wanted to have a customisable colour option depending on my needs. Since 2 of the physical switches are unused in MDA mode, I programmed the ability to change the colours depending on what switch is selected.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-mda-display.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-mda-display.jpg" width="800"></a></p><p>Depending on switch state, colours like green, yellow, white and red are selectable on-the-fly.</p>
<h2 id="additional-cga-70hz-mode">Additional CGA 70Hz mode</h2>
<p>According to page 18 of the <a href="https://www.cs.unc.edu/Research/stc/FAQs/Video/dvi_spec-V1_0.pdf">DVI 1.0 specification</a>, the minimum acceptable for DVI is a pixel clock of 25.175Mhz for 640x480 60Hz.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-dvi-lowest.png"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-dvi-lowest.png" width="600"></a></p><p>Even after scandoubling, the current resolution of 640x400 60Hz is technically below the minimum acceptable. I have tested with the monitors I have up to a modern Dell S2721QS 4K monitor and Sony TV and all can accept 640x400 60Hz with no problems.</p>
<p>Nevertheless to adhere to the specification, I decided to provide another selectable CGA bitstream to drive the pixel clock higher so as to produce 640x400 at 70Hz in case some displays cannot accept a lower pixel clock.</p>
<p>At this mode though, the IBM5155 internal CRT and external composite display will no longer work.</p>

<p>During the design process, I used several tools to help me.</p>
<p>As I would find out, if one sends an improper display signal to the monitor, most monitors will tell you the signal is out of specification and not elaborate more otherwise nothing is shown at all.</p>
<p>This makes it extremely difficult to troubleshoot what went wrong.</p>
<h2 id="digilent-digital-discovery">Digilent Digital Discovery</h2>
<p>The Digilent Digital Discovery (DDD) is a relatively low-cost USB logic analyzer for the specifications/features.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-ddd.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-ddd.jpg" width="600"></a></p><p>It can sample up to 800 MS/s depending on the number of channels active at one time. Compared to most osilloscopes, it has 2 GBit of RAM which allows me to store plenty of samples. This is especially required given the data samples I was working with and I need to capture at least several frames.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-waveforms.png"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-waveforms.png" width="800"></a></p><p>This is a sample capture of the Clock, Display Enable, Vertical Sync and Horizontal Sync signals on the Digilent Waveforms software.</p>
<h2 id="testing-with-mimas-a7-xilinx-artix-7">Testing with Mimas A7 (Xilinx Artix 7)</h2>
<p>As part of my testing, I also made a small FPGA test project using another FPGA board Mimas A7 based on the Xilinx Artix 7.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-with-mimas-a7.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-with-mimas-a7.jpg" width="600"></a></p><p>The FPGA test board reads the raw signals that are given to the DVI transmitter and displays the output using its own HDMI output. Visualising the signals makes it easier to literally see and troubleshoot what the problem could be instead of just looking at the raw logic levels from the logic analyser output.</p>
<p>The code is heavily based on the <a href="https://github.com/dominic-meads/HDMI_FPGA/">HDMI_FPGA</a> project by Dominic Meads and runs on Vivado 2023.</p>
<h2 id="486-pc">486 PC</h2>
<p>Instead of going to my precious IBM5155 directly, I used my <a href="https://yeokhengmeng.com/2021/05/setting-up-a-486-retro-pc/">486 PC</a> for intermediate testing.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-486-cga.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-486-cga.jpg" width="400"></a></p><p>The BIOS of my 486 motherboard has the ability to change to the different CGA and MDA modes on top of its more period correct VGA mode. This helped me in my testing as I can more easily switch between the video modes compared to my <a href="https://www.minuszerodegrees.net/5160/misc/5160_motherboard_switch_settings.htm">IBM5155 which uses physical switch settings</a>.</p>
<h2 id="install-in-my-ibm5155">Install in my IBM5155</h2>
<p>After I was more confident on the card’s functionality, final tests were done in my IBM5155.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-ibm5155-top.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-ibm5155-top.jpg" width="400"></a></p><p>The card installed in the slot closest to the CRT monitor with the internal composite cable connected.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-ibm5155-back.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-ibm5155-back.jpg" width="400"></a></p><p>The rear of my IBM5155 shows the HDMI connector, probably the first to have one?</p>
<p>I didn’t design a new card bracket so I used a twist tie to secure the card to the enclosure.</p>
<h2 id="known-issue-with-brown">Known issue with brown</h2>
<p>This palette value “I:0 R:1 G:1 B:0” is not handled correctly by this card and is displayed as dark yellow instead of brown as per how the <a href="https://www.aceinnova.com/en/electronics/cga-and-the-brown-color-in-ibm-5153-color-display/">IBM5153 Colour Display Monitor does it</a>. When an IBM5153 monitor sees this signal “I:0 R:1 G:1 B:0”, the green component is halved producing a brown colour.</p>
<p>In order to emulate this behaviour for modern displays, the FPGA itself will have to halve the green colour component which means I will need more signal lines to the DVI transmitter. However I lack the pins on the FPGA to provide more than a 4-bit RGBI output.</p>
<p><a href="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-cga-test.jpg"><img src="https://yeokhengmeng.com/2023/09/hdmi-isa-graphics-card-for-vintage-pcs/images/gg-hdmi-cga-test.jpg" width="600"></a></p><p>My IBM 5155 running the <a href="https://github.com/MobyGamer/CGACompatibilityTester">CGA Compatibility Tester</a> displaying the colour palatte. One can see the brown colour is displayed incorrectly as dark yellow.</p>
<p>The original GG does not suffer from this problem as the brown colour can be easily generated with the existing FPGA pins to the VGA resistor DAC.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This project was a long journey for me. If you look at the silkscreen date on the PCB, it shows 9 August 2021. At that time, I designed the PCB without the skills to code in Verilog. Even though the number of changes I made are small, it took me quite a bit of time on the side to finally pick up the skills to work on my first FPGA project with all development and testing work this project entails.</p>
<p>Not forgetting I’m actually standing on the shoulders of giants like Eric Schlaepfer who designed the original Graphics Gremlin. I’m just building on a small increment on top of his work.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How could the early Unix OS comprise so few lines of code? (198 pts)]]></title>
            <link>https://retrocomputing.stackexchange.com/questions/26083/how-could-early-unix-os-comprise-so-few-lines-of-code</link>
            <guid>37462806</guid>
            <pubDate>Mon, 11 Sep 2023 04:14:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://retrocomputing.stackexchange.com/questions/26083/how-could-early-unix-os-comprise-so-few-lines-of-code">https://retrocomputing.stackexchange.com/questions/26083/how-could-early-unix-os-comprise-so-few-lines-of-code</a>, See on <a href="https://news.ycombinator.com/item?id=37462806">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<p>If you look at the code in the modern Linux kernel, you will find that most of the code is in the device drivers.  There are tens of millions of lines of code to support everything imaginable -- the networking cards in 1990s DEC Alpha workstations, the soundcards in late 1980s ISA IBM PC-compatibles, modern 64-bit ARM tablets, all the USB devices, and so on.</p>
<p>On top of that, we have dozens of file systems, support for many different kinds of networking protocols.  There are multiple different schedulers -- not just for processes, but block IO and network transfers.  And so on.  In fact, the feature variety and hardware drivers make up the great majority of Linux code.  Linux, before all these features and bloat were added, as originally released as a crude kernel for 386 machines, was also measured in tens of thousands of lines of code.</p>
<p>I've written a small multitasking kernel, for an embedded application, so I feel qualified to say: it really isn't that big of a job.  The basic UNIX design of processes and file system is a structure that has several interworking parts, so it's delicate and finnicky.  But it's not ultimately that complex.</p>
<p>Basic memory management takes a few hundred lines.  Implementing basic processes takes a few hundred lines.  A basic file system takes a few thousand lines of C code.  Device drivers depend on the complexity of the device, but can be quite small.  You just need drivers for a terminal of some kind, and a disk of some kind.</p>
<p>That will give you the core to load binaries, execute them, and give them some system calls for reading/writing files.  That's about all the original UNIX provided.  But then you will want networking and fast algorithms for disk caching.  It rapidly starts adding up.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Japan launches rocket carrying lunar lander and X-ray telescope (228 pts)]]></title>
            <link>https://phys.org/news/2023-09-japan-rocket-lunar-lander-x-ray.html</link>
            <guid>37462351</guid>
            <pubDate>Mon, 11 Sep 2023 03:00:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2023-09-japan-rocket-lunar-lander-x-ray.html">https://phys.org/news/2023-09-japan-rocket-lunar-lander-x-ray.html</a>, See on <a href="https://news.ycombinator.com/item?id=37462351">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket.jpg" data-sub-html="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/japan-launches-rocket.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe" title="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP" width="800" height="510">
             <figcaption>
                An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
            </figcaption>        </figure>
    </div>
<p>Japan launched a rocket Thursday carrying an X-ray telescope that will explore the origins of the universe as well as a small lunar lander.

										 											      </p>
										 
										 											  
<p>The launch of the HII-A rocket from Tanegashima Space Center in southwestern Japan was shown on <a href="https://phys.org/tags/live+video/" rel="tag">live video</a> by the Japan Aerospace Exploration Agency, known as JAXA.
</p><p>"We have a liftoff," the narrator at JAXA said as the rocket flew up in a burst of smoke then flew over the Pacific.
</p><p>Thirteen minutes after the launch, the rocket put into orbit around Earth a satellite called the X-Ray Imaging and Spectroscopy Mission, or XRISM, which will measure the speed and makeup of what lies between galaxies.
</p><p>That information helps in studying how <a href="https://phys.org/tags/celestial+objects/" rel="tag">celestial objects</a> were formed, and hopefully can lead to solving the mystery of how the universe was created, JAXA says.
</p><p>In cooperation with NASA, JAXA will look at the strength of light at different wavelengths, the temperature of things in space and their shapes and brightness.
</p><div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japans-moon-sniper-mis.jpg" data-src="https://scx2.b-cdn.net/gfx/news/2023/japans-moon-sniper-mis.jpg" data-sub-html="Graphic on Japan's Smart Lander for Investigating Moon (SLIM), or 'Moon Sniper', which aims to land within 100 meters of a specific lunar target.">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/japans-moon-sniper-mis.jpg" alt="Japan's 'Moon Sniper' mission" title="Graphic on Japan's Smart Lander for Investigating Moon (SLIM), or 'Moon Sniper', which aims to land within 100 meters of a specific lunar target.">
             <figcaption>
                Graphic on Japan's Smart Lander for Investigating Moon (SLIM), or 'Moon Sniper', which aims to land within 100 meters of a specific lunar target.
            </figcaption>        </figure>
    </div>

<p>David Alexander, director of the Rice Space Institute at Rice University, believes the mission is significant for delivering insight into the properties of hot plasma, or the superheated matter that makes up much of the universe.
</p><p>Plasmas have the potential to be used in various ways, including healing wounds, making computer chips and cleaning the environment.
</p><p>"Understanding the distribution of this hot plasma in space and time, as well as its dynamical motion, will shed light on diverse phenomena such as <a href="https://phys.org/tags/black+holes/" rel="tag">black holes</a>, the evolution of chemical elements in the universe and the formation of galactic clusters," Alexander said.
</p><div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-1.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-1.jpg" data-sub-html="An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/japan-launches-rocket-1.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe" title="An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
             <figcaption>
                An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
            </figcaption>        </figure>
    </div>

<p>Also aboard the latest Japanese rocket is the Smart Lander for Investigating Moon, or SLIM, a lightweight lunar <a href="https://phys.org/tags/lander/" rel="tag">lander</a>. The Smart Lander won't make <a href="https://phys.org/tags/lunar+orbit/" rel="tag">lunar orbit</a> for three or four months after the launch and would likely attempt a landing early next year, according to the space agency.
</p><p>The lander successfully separated from the rocket about 45 minutes after the launch and proceeded on its proper track to eventually land on the <a href="https://phys.org/tags/moon/" rel="tag">moon</a>. JAXA workers applauded and bowed with each other from their observation facility.
</p><div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-2.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-2.jpg" data-sub-html="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/japan-launches-rocket-2.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe" title="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
             <figcaption>
                An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
            </figcaption>        </figure>
    </div>



											  													    
											  
											  <p>JAXA is developing "pinpoint landing technology" to prepare for future lunar probes and landing on other planets. While landings now tend to be off by about 10 kilometers (6 miles) or more, the Smart Lander is designed to be more precise, within about 100 meters (330 feet) of the intended target, JAXA official Shinichiro Sakai told reporters ahead of the launch.
</p><p>That allows the box-shaped gadgetry to find a safer place to land.
</p><p>The move comes at a time when the world is again turning to the challenge of going to the moon. Only four nations have successfully landed on the moon, the U.S., Russia, China and India.
</p><p>Last month, <a href="https://phys.org/news/2023-08-india-moon-rover-sulfur-elements.html">India landed a spacecraft</a> near the moon's south pole. That came just days after Russia failed in its attempt to return to the moon for the first time in nearly a half century. A Japanese private company, called ispace, crashed a lander in trying to land on the moon in April.
</p><ul>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-3.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-3.jpg" data-sub-html="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-3.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-5.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-5.jpg" data-sub-html="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-5.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-6.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-6.jpg" data-sub-html="An H2A rocket sits at launch pad at Tanegashima Space Center in Kagoshima, southern Japan Monday, Aug. 28, 2023. The rocket was to blast off Monday morning, but the lift-off was postponed due to strong winds, according to Kyodo News. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-6.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An H2A rocket sits at launch pad at Tanegashima Space Center in Kagoshima, southern Japan Monday, Aug. 28, 2023. The rocket was to blast off Monday morning, but the lift-off was postponed due to strong winds, according to Kyodo News. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-4.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-4.jpg" data-sub-html="An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-4.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An HII-A rocket blasts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-7.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-7.jpg" data-sub-html="An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-7.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-8.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-8.jpg" data-sub-html="An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-8.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
            <li data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/japan-launches-rocket-9.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2023/japan-launches-rocket-9.jpg" data-sub-html="An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP">
            <figure>
                <img src="https://scx1.b-cdn.net/csz/news/800/2023/japan-launches-rocket-9.jpg" alt="Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe">
                 <figcaption>
                    An HII-A rocket lifts off from the launch pad at Tanegashima Space Center in Kagoshima, southern Japan Thursday, Sept. 7, 2023. Credit: Kyodo News via AP
                </figcaption>            </figure>
        </li>
    </ul>

<p>Japan's space program has been marred by recent failures. In February, the H3 <a href="https://phys.org/tags/rocket+launch/" rel="tag">rocket launch</a> was aborted for a glitch. Liftoff a month later succeeded, but the <a href="https://phys.org/tags/rocket/" rel="tag">rocket</a> had to be destroyed after its second stage failed to ignite properly.
</p><p>Japan has started recruiting astronaut candidates for the first time in 13 years, making clear its ambitions to send a Japanese to the moon.
</p><p>Going to the moon has fascinated humankind for decades. Under the U.S. Apollo program, astronauts Neil Armstrong and Buzz Aldrin walked on the moon in 1969.
</p><p>The last NASA human mission to the moon was in 1972, and the focus on sending humans to the moon appeared to wane, with missions being relegated to robots.
										 																				
																					
																															 </p><p>
												  © 2023 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed without permission.
											 </p>
										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												Japan launches rocket carrying lunar lander and X-ray telescope to explore origins of universe (2023, September 7)
												retrieved 11 September 2023
												from https://phys.org/news/2023-09-japan-rocket-lunar-lander-x-ray.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chronic fatigue syndrome may have a post-viral infection origin (165 pts)]]></title>
            <link>https://medicalxpress.com/news/2023-09-chronic-fatigue-syndrome-post-viral-infection.html</link>
            <guid>37462208</guid>
            <pubDate>Mon, 11 Sep 2023 02:38:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2023-09-chronic-fatigue-syndrome-post-viral-infection.html">https://medicalxpress.com/news/2023-09-chronic-fatigue-syndrome-post-viral-infection.html</a>, See on <a href="https://news.ycombinator.com/item?id=37462208">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/chronic-fatigue-syndro-2.jpg" data-src="https://scx2.b-cdn.net/gfx/news/2023/chronic-fatigue-syndro-2.jpg" data-sub-html="Credit: <i>PLOS Pathogens</i> (2023). DOI: 10.1371/journal.ppat.1011523">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/chronic-fatigue-syndro-2.jpg" alt="Chronic fatigue syndrome may have a post-viral infection origin" title="Credit: PLOS Pathogens (2023). DOI: 10.1371/journal.ppat.1011523" width="800" height="530">
             <figcaption>
                Credit: <i>PLOS Pathogens</i> (2023). DOI: 10.1371/journal.ppat.1011523
            </figcaption>        </figure>
    </div>
<p>Professor Maureen R. Hanson of the Department of Molecular Biology and Genetics, Cornell University, Ithaca, New York, has looked into historical outbreaks of myalgic encephalomyelitis (ME), also known as chronic fatigue syndrome (CFS), and their association with enteroviruses and other pathogens.
                                                </p>                                                                                
<p>In a paper, "The viral origin of myalgic encephalomyelitis/<a href="https://medicalxpress.com/tags/chronic+fatigue+syndrome/" rel="tag">chronic fatigue syndrome</a>," published in <i>PLOS Pathogens</i>, professor Hanson explores several hypotheses related to the causes of ME/CFS, including a likely culprit in viral infections, particularly those from the enterovirus family.
</p><p>The exact causes of ME/CFS are not fully understood, and it is considered a complex and multifactorial condition. Several theories and factors have been proposed as potential contributors to ME/CFS, but no single cause has been definitively identified.
</p><p>Hanson makes the case that some causes are more likely than others, including:
</p><ul><li>Infections with the enterovirus family of viruses. This hypothesis is based on historical outbreaks of ME/CFS coinciding with outbreaks of diseases caused by enteroviruses, as well as evidence of chronic viral infection in some ME/CFS patients. While this could be causal to many more cases, identifying the specific virus that was infecting an individual who later acquired ME/CFS is not possible.</li><li>Human herpesviruses (HHVs), such as Epstein-Barr virus and HHV-6. In ME/CFS, these are a potential source. Some ME/CFS patients report an acute infection with HHVs at the onset of their illness, and reactivation of these viruses may contribute to the condition.</li><li>Post-viral syndromes, including post-acute sequelae of COVID-19 (PASC). These are included in an emerging area of clinical understanding. Some individuals with mild or asymptomatic COVID-19 later experience a post-viral illness that shares symptoms with ME/CFS. This raises questions about the relationship between other lesser-known or less apparent infections and their potential to cause post-viral syndromes and ME/CFS.</li></ul>
<p>In the light of a major viral pandemic with lingering ME/CFS conditions, Hanson compiled information on historical ME/CFS outbreaks with studies on infections like Epstein-Barr virus, Q fever, Ross River virus, influenza and previous ME/CFS patient research, and interrogated varying criteria used by research groups and clinicians to define ME/CFS.
</p><p>Focusing on <a href="https://medicalxpress.com/tags/viral+infections/" rel="tag">viral infections</a> is an intriguing investigative path, as there are already many conditions associated with ME/CFS, almost as if a researcher could pick anywhere to start pulling at the connecting threads of the condition.
</p><p>There are immune system abnormalities linked to ME/CFS; genetic factors may play a role in susceptibility. The central nervous system has associations with many of the symptoms. A host of potential environmental factors, such as toxins, stress, and trauma may be implicated. Recent research indicates issues with cellular energy metabolism, particularly involving mitochondria, leading to the fatigue and reduced stamina. Hormonal dysregulation and/or gut microbiota could play a role, and the list goes on.
</p><p>Hanson argues that there is no proof that multiple pathogens can cause ME/CFS. She suggests that the hypothesis persists due to the overinterpretation of data from previous studies where the initial infection type was either missed, inferred but not verified, or where the symptom survey did not include ME/CFS defining criteria.
</p><p>Currently, there is no specific diagnostic test or universally effective treatment for ME/CFS, which makes it a challenging condition to manage. Treatment typically focuses on symptom management by attempting to improve the quality of life for individuals through traditional, good doctorly advice of "Exercise regularly, eat right, get plenty of sleep." The condition can be frustrating for patients who follow such advice and yet find no relief.
</p><p>Before the SARS-CoV-2 pandemic, the ability of RNA viruses to persist in tissues for long periods was largely ignored, according to Hanson. Recognizing that EVs are prime candidates for causing ME/CFS suggests the importance of pursuing a relevant inquiry into this diverse virus family.

                                            <!-- Google middle Adsense block -->
    </p>                                        <h2>The global laboratory</h2>
<p>Sixty-five million long COVID sufferers worldwide have prompted the US government to devise PASC to describe a post-acute illness syndrome. Most relevant to ME/CFS is that some people who suffered mild or asymptomatic cases of COVID-19 later began experiencing a post-viral illness that fulfills most or even all of the criteria for ME/CFS.
</p><p>Increasingly, these people are told by their doctors that they have ME/CFS, but the diagnostic criteria were created six years before SARS-CoV-2 emerged. Those who acquired ME/CFS before the SARS-CoV-2 outbreak also number in the tens of millions, and the source of their initial infection often remains a mystery.
</p><p>Hanson suggests that the overlap in symptoms between some forms of post-COVID illness and ME/CFS suggests that disruptions in the same pathways may be occurring in both diseases, but to conclude that the two syndromes are identical without more data, especially at the molecular level, is currently unwarranted. Any SARS-specific antiviral treatments will not be effective for ME/CFS patients.
</p><p>If it were not for COVID-19 hitting everywhere all at once, ME/CFS caused by SARS-CoV-2 might also be flying under the radar of the clinical and research communities. Now that the link between a viral <a href="https://medicalxpress.com/tags/infection/" rel="tag">infection</a> and ME/CFS has been firmly detected, Hanson is urging an inquiry into the prime candidate for previously existing ME/CFS cases.
                                                                                
                                        											</p><div>
												                                                    <p><strong>More information:</strong>
                                                    Maureen R. Hanson et al, The viral origin of myalgic encephalomyelitis/chronic fatigue syndrome, <i>PLOS Pathogens</i> (2023).  <a data-doi="1" href="https://dx.doi.org/10.1371/journal.ppat.1011523" target="_blank">DOI: 10.1371/journal.ppat.1011523</a>
																								
																								</p>
																							</div>
                                        											
										                                                                                    <p>
                                                © 2023 Science X Network
                                            </p>
                                                                                
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Chronic fatigue syndrome may have a post-viral infection origin (2023, September 6)
                                                 retrieved 11 September 2023
                                                 from https://medicalxpress.com/news/2023-09-chronic-fatigue-syndrome-post-viral-infection.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RestGPT (210 pts)]]></title>
            <link>https://github.com/Yifan-Song793/RestGPT</link>
            <guid>37462125</guid>
            <pubDate>Mon, 11 Sep 2023 02:22:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Yifan-Song793/RestGPT">https://github.com/Yifan-Song793/RestGPT</a>, See on <a href="https://news.ycombinator.com/item?id=37462125">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">RestGPT</h2>
<p dir="auto">This is the code for the paper <a href="https://arxiv.org/abs/2306.06624" rel="nofollow">RestGPT: Connecting Large Language Models with Real-World RESTful APIs</a>.</p>
<p dir="auto">This work aims to construct a <strong>large language model based autonomous agent, RestGPT, to control real-world applications</strong>, such as movie database and music player. To achieve this, we connect LLMs with <strong>RESTful APIs</strong> and tackle the practical challenges of planning, API calling, and response parsing. To fully evaluate the performance of RestGPT, we propose <strong>RestBench</strong>, a high-quality test set which consists of two real-world scenarios and human-annotated instructions with gold solution paths.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Yifan-Song793/RestGPT/blob/main/imgs/intro.png"><img src="https://github.com/Yifan-Song793/RestGPT/raw/main/imgs/intro.png" alt="intro"></a></p>
<h2 tabindex="-1" dir="auto">What's New</h2>
<ul dir="auto">
<li><strong>[Next]</strong> The demo is under-construction.</li>
<li><strong>[2023/8/29]</strong> Code for RestGPT is released.</li>
<li><strong>[2023/8/28]</strong> The second version of our <a href="https://arxiv.org/abs/2306.06624" rel="nofollow">paper</a> is released.</li>
<li><strong>[2023/6/13]</strong> Our <a href="https://arxiv.org/abs/2306.06624" rel="nofollow">paper</a> is released.</li>
</ul>
<h2 tabindex="-1" dir="auto">RestGPT</h2>
<p dir="auto">RestGPT adopts an iterative coarse-to-fine online planning framework and uses an executor to call RESTful APIs. Here is an overview of RestGPT.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Yifan-Song793/RestGPT/blob/main/imgs/model.png"><img src="https://github.com/Yifan-Song793/RestGPT/raw/main/imgs/model.png" alt="model"></a></p>
<p dir="auto">Modules:</p>
<ul dir="auto">
<li>Planner: generating natural language sub-task for current step.</li>
<li>API selector: mapping the coarse high-level sub-task to finer API calling plan.</li>
<li>Executor: executing the API calling plan.
<ul dir="auto">
<li>Caller: organizing API parameters based on the API plan and API documentation.</li>
<li>Parser: generating Python code to parse the API response based on the response schema.</li>
</ul>
</li>
</ul>
<p dir="auto">Here is an example of using TMDB movie database to search for the number of movies directed by Sofia Coppola.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Yifan-Song793/RestGPT/blob/main/imgs/example.gif"><img src="https://github.com/Yifan-Song793/RestGPT/raw/main/imgs/example.gif" alt="example" data-animated-image=""></a></p>
<h2 tabindex="-1" dir="auto">Data</h2>
<p dir="auto">We also introduce RestBench to evaluate the performance of RestGPT. RestBench is a high-quality test set consisting of TMDB movie database and Spotify music player scenarios. We collect realistic user instructions with human-annotated gold solution paths. Here are examples of RestBench:</p>
<p dir="auto">TMDB example:</p>
<ul dir="auto">
<li>Instruction: Who is the director of today's most trending movie?</li>
<li>Gold solution path
<ul dir="auto">
<li>GET /trending/{media_type}/{time_window}</li>
<li>GET /movie/{movie_id}/credits</li>
</ul>
</li>
</ul>
<p dir="auto">Spotify example:</p>
<ul dir="auto">
<li>Instruction: Make me a playlist containing three songs of Mariah Carey and name it 'Love Mariah'.</li>
<li>Gold solution path
<ul dir="auto">
<li>GET /search</li>
<li>GET /me</li>
<li>POST /usres/{user_id}/playlists</li>
<li>POST /playlists/{playlist_id}/tracks</li>
</ul>
</li>
</ul>
<p dir="auto">Below is the statistics of the data. We report the number of instructions with different lengths of solution path:</p>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>#APIs</th>
<th>Len-1</th>
<th>Len-2</th>
<th>Len-3</th>
<th>Len-4</th>
<th>Avg. Len.</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr>
<td>TMDB</td>
<td>54</td>
<td>5</td>
<td>66</td>
<td>27</td>
<td>2</td>
<td>2.3</td>
<td>100</td>
</tr>
<tr>
<td>Spotify</td>
<td>40</td>
<td>8</td>
<td>18</td>
<td>22</td>
<td>9</td>
<td>2.6</td>
<td>57</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Setup</h2>
<div dir="auto" data-snippet-clipboard-copy-content="pip install langchain colorama tiktoken spotipy openai"><pre>pip install langchain colorama tiktoken spotipy openai</pre></div>
<p dir="auto">create <code>logs</code> folder</p>
<p dir="auto">Get OpenAI key from OpenAI, TMDB key from <a href="https://developer.themoviedb.org/docs/getting-started" rel="nofollow">https://developer.themoviedb.org/docs/getting-started</a>, and Spotify key from <a href="https://developer.spotify.com/documentation/web-api" rel="nofollow">https://developer.spotify.com/documentation/web-api</a></p>
<p dir="auto">Fill in your own key in <code>config.yaml</code></p>
<h2 tabindex="-1" dir="auto">(Optional) Initialize the Spotify Environment</h2>
<p dir="auto"><strong>WARNING: this will remove all your data from spotify!</strong></p>

<h2 tabindex="-1" dir="auto">Run</h2>
<p dir="auto">The code can be run using the following command:</p>

<p dir="auto">Then Input the scenario (TMDB/Spotify) and instruction.</p>
<p dir="auto">We also provide two scripts to run RestGPT on RestBench:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# TMDB
python run_tmdb.py

# Spotify, please open Spotify on your device
python run_spotify.py"><pre><span><span>#</span> TMDB</span>
python run_tmdb.py

<span><span>#</span> Spotify, please open Spotify on your device</span>
python run_spotify.py</pre></div>
<p dir="auto"><code>run_tmdb.py</code> will sequentially execute all instructions of RestBench-TMDB. Regarding RestBench-Spotify, you should manually modify the <code>query_idx</code> before executing the instructions.</p>
<h2 tabindex="-1" dir="auto">Citation</h2>
<p dir="auto">If you find this repo useful, please cite us.</p>
<div dir="auto" data-snippet-clipboard-copy-content="@misc{song2023restgpt,
      title={RestGPT: Connecting Large Language Models with Real-World RESTful APIs}, 
      author={Yifan Song and Weimin Xiong and Dawei Zhu and Wenhao Wu and Han Qian and Mingbo Song and Hailiang Huang and Cheng Li and Ke Wang and Rong Yao and Ye Tian and Sujian Li},
      year={2023},
      eprint={2306.06624},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}"><pre><span>@misc</span>{<span>song2023restgpt</span>,
      <span>title</span>=<span><span>{</span>RestGPT: Connecting Large Language Models with Real-World RESTful APIs<span>}</span></span>, 
      <span>author</span>=<span><span>{</span>Yifan Song and Weimin Xiong and Dawei Zhu and Wenhao Wu and Han Qian and Mingbo Song and Hailiang Huang and Cheng Li and Ke Wang and Rong Yao and Ye Tian and Sujian Li<span>}</span></span>,
      <span>year</span>=<span><span>{</span>2023<span>}</span></span>,
      <span>eprint</span>=<span><span>{</span>2306.06624<span>}</span></span>,
      <span>archivePrefix</span>=<span><span>{</span>arXiv<span>}</span></span>,
      <span>primaryClass</span>=<span><span>{</span>cs.CL<span>}</span></span>
}</pre></div>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK air traffic control meltdown (210 pts)]]></title>
            <link>https://jameshaydon.github.io/nats-fail/</link>
            <guid>37461695</guid>
            <pubDate>Mon, 11 Sep 2023 01:08:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jameshaydon.github.io/nats-fail/">https://jameshaydon.github.io/nats-fail/</a>, See on <a href="https://news.ycombinator.com/item?id=37461695">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Comments on <a href="https://www.reddit.com/r/programming/comments/16fhmuq/a_deep_dive_into_the_bug_that_caused_the_uk_air/?utm_source=share&amp;utm_medium=web2x&amp;context=3">reddit</a></p>
<p>On 28 August 2023 <em>NATS</em>, the UK's air traffic control operator, suffered a
<strong>major</strong> technical incident. The BBC reports that more than <a href="https://www.bbc.com/news/uk-66685349">2000 flights were
cancelled</a> and the cost has been estimated
at over <em>£100 million</em> GBP. The incident probably affected hundreds of thousands
of people.</p>
<p>The press initially reported the cause was a faulty flight plan: <em>UK air traffic
control: inquiry into whether French error caused failure</em> (The Times) and in
typical Mail Online reporting style: <em>"Did blunder by French airline spark air
traffic control issues? Officials probe if a single badly filed travel plan
caused UK's entire flight-control system to collapse in worst outage for a
decade - with 1,000 flights cancelled and chaos set to last DAYS"</em>.</p>
<p>So what happened? These are notes on my reading of the incident report:</p>
<blockquote>
<p>NATS Major Incident Preliminary Report<br>
Flight Plan Reception Suite Automated (FPRSA-R) Sub-system Incident 28th August 2023 <br>
<a href="https://publicapps.caa.co.uk/docs/33/NERL%20Major%20Incident%20Investigation%20Preliminary%20Report.pdf">pdf</a>.</p>
</blockquote>
<p><em>NATS</em> is a "public-private" company in the UK that is responsible for all of
the UK's air traffic control:</p>
<blockquote>
<p>Air Traffic Control (ATC) is the provision and operation of a safe system for
controlling and monitoring aircraft.
[..] <br>
aircraft [..] are required to file a flight plan.
[..] <br>
ATC ensures that aircraft are safely separated laterally and vertically.</p>
</blockquote>
<h2 id="what-went-wrong">What went wrong</h2>
<blockquote>
<p>The start of the sequence of events leading to the incident can be tracked
back to the point at which a flight plan was entered into the flight planning
system.</p>
<p>[Airlines] submit the plan into Eurocontrol’s Integrated Initial Flight Plan
Processing System (IFPS).
[..]</p>
<p>If the submitted flight plan is accepted by IFPS, i.e. it is compliant with
IFPS defined parameters [...] this is sufficient for a flight to depart with
local ATC approval. The flight plan will be sent from IFPS to all relevant
ANSPs who need to manage the flight.
[..]</p>
<p>Within the NATS En-route operations at Swanwick Centre, the data is passed to
FPRSA-R. The FPRSA-R sub-system exists to convert the data received from IFPS
(in a format known as ATS Data Exchange Presentation, ADEXP) into a format
that is compatible with the UK National Airspace System (NAS). NAS is the
flight data processing system which contains all of the relevant airspace and
routings.
[..]</p>
<p>FPRSA-R has a primary and backup system monitored both by dedicated Control
and Monitoring (C&amp;M) systems and also an aggregated central C&amp;M system.
Further resilience is provided by NAS storing 4 hours of previously filed
flight data to allow the operation to continue in the event of the loss of
automatic processing of flight data.
[..]</p>
<p>In addition to the technical resilience provided by backup systems, and the 4
hours of stored flight data, there is operational contingency available to
allow safe service to continue. This is provided through the ability to input
flight data manually, directly into NAS using a manual input system.</p>
</blockquote>
<p>To summarise:</p>
<ul>
<li>Flight plans are first submitted to a European-wide authority <em>IFPS</em>.</li>
<li>If a plan is accepted, the flight is cleared for takeoff.</li>
<li><em>NATS</em> requires the flight plan be transferred to them at least 4 hours before
the aircraft is due to enter UK airspace. This is supposed to give NATS a
4-hour window to be able to fix any problems in processing flight plans.</li>
<li>It seems that there is also probably some process which <em>delays</em> flight plans
until <em>close</em> to the deadline (see below). This might be to avoid congesting
the system with flight plans too early, or lots of plans that may later
change. Still, this results in flight plans being received by NATS sometimes
<em>hours</em> after the flight has taken off.</li>
</ul>
<blockquote>
<p>The NATS ATC System was operating normally.
[..]</p>
<p>[On] 28 August the airline submitted an ICAO4444 compliant flight plan into
Eurocontrol’s flight planning distribution system, IFPS.</p>
</blockquote>
<p>ICAO stands for <a href="https://en.wikipedia.org/wiki/International_Civil_Aviation_Organization" title="wikipedia">International Civil Aviation
Organization</a>, a United Nations agency.
An ICAO4444 flight plan looks like this:</p>
<pre><code><span>(FPL-TTT123-IS
</span><span>-C550/L-SDE1E2GHIJ3J5RWZ/SB1D1
</span><span>-KPWM1225
</span><span>-N0440F310 SSOXS5 SSOXS DCT BUZRD
</span><span>DCT SEY DCT HTO J174 ORF J121
</span><span>CHS EESNT LUNNI1
</span><span>-KJAX0214 KMCO
</span><span>-PBN/A1L1B1C1D1O1T1 NAV/Z1 GBAS
</span><span>DAT/1FANS2PDC SUR/260B RSP180
</span><span>DOF/220501 REG/N123A SEL/BPAM
</span><span>CODE/A05ED7)
</span></code></pre>
<p>Such messages are in a format that is meant to be read by machines, but also by
humans if necessary. The format is spec'd over many many pages of PDF, but is
roughly:</p>
<pre><code><span>( FPL-ACID-Flt Rules Flight Type
</span><span>- AC Type/Wake Cat-
</span><span>Equip.&amp;Capability
</span><span>- Departure EOBT
</span><span>- Speed Altitude [sp] Route
</span><span>- Destination ETE [sp]
</span><span>Alternate(s)
</span><span>- Other Information )
</span></code></pre>
<p>The route part (in this example: <code>N0440F310 SSOXS5 SSOXS DCT BUZRD DCT SEY DCT HTO J174 ORF J121 CHS EESNT LUNNI1</code>) encodes an overall speed (here <code>N0440</code>
meaning <code>440 knots</code>), an overall altitude (here <code>F310</code> which means "Flight
Level 310" which means <code>310 × 100 ft</code> (can also be in <code>km</code>)), and a sequence of
waypoints (referenced by name) separated by a description of how to get from the
previous waypoint to the next one, usually by referencing a "known route" by
name.</p>
<blockquote>
<p>The flight plan was accepted by IFPS
[..] <br>
the aircraft was cleared to depart at 04:00.
[..]</p>
<p>At 08:32 the flight plan was received by NATS’ FPRSA-R sub-system from
Eurocontrol’s IFPS system. This is consistent with the 4 hour rule mentioned
above. The purpose of the FPRSA-R software is to extract the UK portion of the
flight plan [..]</p>
<p>The flight plans delivered to FPRSA-R by IFPS are converted from [..] ICAO4444
to [..] ADEXP. ADEXP is a European-wide flight plan specification that
includes, amongst other data, additional geographical waypoints within the
European region specific to the route of a flight. For flights transiting
through UK airspace, rather than landing in the UK, this will include
additional waypoints outside of UK airspace required for its onward journey.
Following this conversion the ADEXP version of a flight plan includes, amongst
other aspects, the original ICAO4444 flight plan plus an additional list of
waypoints and other data.</p>
</blockquote>
<p>ADEXP looks like this:</p>
<pre><code><span>-TITLE IFPL
</span><span>-BEGIN ADDR
</span><span>  -FAC LIIRZEZX
</span><span>  [...]
</span><span>  -FAC LYZZEBXX
</span><span>-END ADDR
</span><span>-ADEP EDDF
</span><span>-ADES LGTS
</span><span>-ARCID KIM1
</span><span>-ARCTYP B738
</span><span>-CEQPT SDGRWY
</span><span>-EOBD 170729
</span><span>-EOBT 0715
</span><span>-FILTIM 280832
</span><span>-IFPLID AT00441635
</span><span>-ORIGIN -NETWORKTYPE SITA -FAC FRAOXLH
</span><span>-SEQPT C
</span><span>-WKTRC M
</span><span>-PBN B2
</span><span>-REG DABHM
</span><span>-SEL KMGJ
</span><span>-SRC FPL
</span><span>-TTLEET 0210
</span><span>-RFL F330
</span><span>-SPEED N0417
</span><span>-FLTRUL I
</span><span>-FLTTYP S
</span><span>-ROUTE N0417F330 ANEKI8L ANEKI Y163 NATOR UN850 TRA UP131 RESIA Q333
</span><span>BABAG UN606 PEVAL DCT PETAK UL607 PINDO UM603 EDASI
</span><span>-ALTRNT1 LBSF
</span><span>-BEGIN RTEPTS
</span><span>  -PT -PTID EDDF -FL F004 -ETO 170729073000
</span><span>  -PT -PTID RID -FL F100 -ETO 170729073404
</span><span>  -PT -PTID ANEKI -FL F210 -ETO 170729073856
</span><span>  -PT -PTID NEKLO -FL F214 -ETO 170729073911
</span><span>  -PT -PTID BADLI -FL F248 -ETO 170729074118
</span><span>  -PT -PTID PABLA -FL F279 -ETO 170729074348
</span><span>  -PT -PTID HERBI -FL F308 -ETO 170729074624
</span><span>  -PT -PTID NATOR -FL F330 -ETO 170729074911
</span><span>  -PT -PTID TITIX -FL F330 -ETO 170729075154
</span><span>  -PT -PTID TRA -FL F330 -ETO 170729075323
</span><span>  -PT -PTID ARGAX -FL F330 -ETO 170729080055
</span><span>  -PT -PTID RESIA -FL F330 -ETO 170729080731
</span><span>  -PT -PTID UNTAD -FL F330 -ETO 170729081243
</span><span>  -PT -PTID DIKEM -FL F330 -ETO 170729081627
</span><span>  -PT -PTID ROKIB -FL F330 -ETO 170729081824
</span><span>  -PT -PTID BABAG -FL F330 -ETO 170729082816
</span><span>  -PT -PTID PEVAL -FL F330 -ETO 170729082916
</span><span>  -PT -PTID PETAK -FL F330 -ETO 170729091754
</span><span>  -PT -PTID PINDO -FL F330 -ETO 170729093322
</span><span>  -PT -PTID EDASI -FL F165 -ETO 170729094347
</span><span>  -PT -PTID LGTS -FL F000 -ETO 170729095713
</span><span>-END RTEPTS
</span><span>-SID ANEKI8L
</span><span>-ATSRT Y163 ANEKI NATOR
</span><span>-ATSRT UN850 NATOR TRA
</span><span>-ATSRT UP131 TRA RESIA
</span><span>-ATSRT Q333 RESIA BABAG
</span><span>-ATSRT UN606 BABAG PEVAL
</span><span>-DCT PEVAL PETAK
</span><span>-ATSRT UL607 PETAK PINDO
</span><span>n -ATSRT UM603 PINDO EDASI
</span></code></pre>
<p>You can read about ADEXP in the <a href="https://www.eurocontrol.int/sites/default/files/2023-06/eurocontrol-released-specification-adexp-3-4.pdf" title="pdf">official spec</a>.
Some notable fields (page 48):</p>
<table><thead><tr><th>Adexp Primary Field</th><th>Kind</th><th>Syntax</th><th>Semantic</th></tr></thead><tbody>
<tr><td>route</td><td>b</td><td><code>'-' "ROUTE" {LIM_CHAR}</code></td><td>Complete ICAO Field 15 information containing speed, RFL and route (conforming to the syntax given in Ref. [3]).</td></tr>
<tr><td>rtepts</td><td>c</td><td><code>'-' "BEGIN" "RTEPTS" { pt I ad / vec} '-' "END" "RTEPTS"</code></td><td>List of route points. May also contain an aerodrome identifier.</td></tr>
</tbody></table>
<p>In the example, we have the ICAO route:</p>
<pre><code><span>-ROUTE N0417F330 ANEKI8L ANEKI Y163 NATOR UN850 TRA UP131 RESIA Q333 BABAG UN606 PEVAL DCT PETAK UL607 PINDO UM603 EDASI
</span></code></pre>
<p>(9 waypoints, 11 if you add the start and end waypoints)</p>
<p>Visually, routes look like:
<img src="https://jameshaydon.github.io/nats-fail/flight_plan.png" alt="some route" title="A flight plan route"></p>
<p>(You can play around with flight plans at
<a href="https://flightplandatabase.com/">flightplandatabase.com</a>, a website for people
who like playing with flight simulators)</p>
<p>We can indent the "route" parts between the waypoints in the ICAO plan to make
things clearer:</p>
<pre><code><span>N0417F330
</span><span>  ANEKI8L 
</span><span>  ANEKI 
</span><span>    Y163
</span><span>  NATOR
</span><span>    UN850
</span><span>  TRA
</span><span>    UP131
</span><span>  RESIA
</span><span>    Q333
</span><span>  BABAG
</span><span>    UN606
</span><span>  PEVAL
</span><span>    DCT
</span><span>  PETAK
</span><span>    UL607
</span><span>  PINDO
</span><span>    UM603
</span><span>  EDASI
</span></code></pre>
<p>E.g. <code>ANEKI Y163 NATOR</code> means "go from waypoint <code>ANEKI</code> to waypoint <code>NATOR</code> via
the route <code>Y163</code>". <code>DCT</code> means "direct".</p>
<p>The <code>ADEXP</code> format has more waypoints, along with more precision about altitude and estimated time at each waypoint:</p>
<pre><code><span>-BEGIN RTEPTS
</span><span>-PT -PTID EDDF  -FL F004 -ETO 170729073000
</span><span>-PT -PTID RID   -FL F100 -ETO 170729073404
</span><span>-PT -PTID ANEKI -FL F210 -ETO 170729073856
</span><span>-PT -PTID NEKLO -FL F214 -ETO 170729073911
</span><span>-PT -PTID BADLI -FL F248 -ETO 170729074118
</span><span>-PT -PTID PABLA -FL F279 -ETO 170729074348
</span><span>-PT -PTID HERBI -FL F308 -ETO 170729074624
</span><span>-PT -PTID NATOR -FL F330 -ETO 170729074911
</span><span>-PT -PTID TITIX -FL F330 -ETO 170729075154
</span><span>-PT -PTID TRA   -FL F330 -ETO 170729075323
</span><span>-PT -PTID ARGAX -FL F330 -ETO 170729080055
</span><span>-PT -PTID RESIA -FL F330 -ETO 170729080731
</span><span>-PT -PTID UNTAD -FL F330 -ETO 170729081243
</span><span>-PT -PTID DIKEM -FL F330 -ETO 170729081627
</span><span>-PT -PTID ROKIB -FL F330 -ETO 170729081824
</span><span>-PT -PTID BABAG -FL F330 -ETO 170729082816
</span><span>-PT -PTID PEVAL -FL F330 -ETO 170729082916
</span><span>-PT -PTID PETAK -FL F330 -ETO 170729091754
</span><span>-PT -PTID PINDO -FL F330 -ETO 170729093322
</span><span>-PT -PTID EDASI -FL F165 -ETO 170729094347
</span><span>-PT -PTID LGTS  -FL F000 -ETO 170729095713
</span><span>-END RTEPTS
</span></code></pre>
<p>(21 waypoints)</p>
<p>We can mark which of the ADEXP waypoints have a corresponding waypoint in the ICAO plan (with a <code>+</code>) and which are implicit (with a <code>|</code>): </p>
<pre><code><span>EDDF   |
</span><span>RID    |
</span><span>ANEKI  + 
</span><span>NEKLO  |
</span><span>BADLI  |
</span><span>PABLA  |
</span><span>HERBI  |
</span><span>NATOR  +
</span><span>TITIX  |
</span><span>TRA    +
</span><span>ARGAX  |
</span><span>RESIA  +
</span><span>UNTAD  |
</span><span>DIKEM  |
</span><span>ROKIB  |
</span><span>BABAG  +
</span><span>PEVAL  |
</span><span>PETAK  +
</span><span>PINDO  +
</span><span>EDASI  +
</span><span>LGTS   |
</span></code></pre>
<p>Note that the ICAO waypoints do not contain the start and end, since in the
original ICAO format these are specified in other fields (so it would waste
space to list them again in this list).</p>
<blockquote>
<p>The ADEXP waypoints plan included two waypoints along its route that were
geographically distinct but which have the same designator.</p>
</blockquote>
<p>This means there were two lines like:</p>
<pre><code><span>-PT -PTID RESIA -FL F330 -ETO 170729080731
</span></code></pre>
<p>that had the same <code>PTID</code> string like <code>"RESIA"</code>.</p>
<blockquote>
<p>Although there has been work by ICAO and other bodies to eradicate non-unique
waypoint names there are duplicates around the world. In order to avoid
confusion latest standards state that such identical designators should be
geographically widely spaced. In this specific event, both of the waypoints
were located outside of the UK, one towards the beginning of the route and one
towards the end; approximately 4000 nautical miles apart.</p>
</blockquote>
<p>4000 nautical miles is 7408km. Here is an arc of that length on the globe:
<img src="https://jameshaydon.github.io/nats-fail/4000-nautical-miles.png" alt="4000 nautical miles on a globe"></p>
<blockquote>
<p>Once the ADEXP file had been received, the FPRSA-R software commenced
searching for the UK airspace entry point in the waypoint information per the
ADEXP flight plan, commencing at the first line of that waypoint data. FPRSA-R
was able to specifically identify the character string as it appeared in the
ADEXP flight plan text.</p>
</blockquote>
<p>The programming style is very imperative. Furthermore, the description sounds
like the procedure is working directly on the textual representation of the
flight plan, rather than a data structure parsed from the text file. This would
be quite worrying, but it might also just be how it is explained.</p>
<blockquote>
<p>Having correctly identified the entry point, the software moved on to search
for the exit point from UK airspace in the waypoint data.</p>
<p>Having completed those steps,</p>
</blockquote>
<p>This part of the code identified <code>entry</code> and <code>exit</code> waypoints to UK airspace in
the list of <code>ADEXP</code> waypoints.</p>
<blockquote>
<p>FPRSA-R then searches the ICAO4444 section of
the ADEXP file.</p>
</blockquote>
<p>It seems at this point, having identified the entry and exit points from the
list of ADEXP waypoints, it will try to extract the UK portion of the flight plan from the ICAO route.</p>
<blockquote>
<p>It initially searches from the beginning of that data, to find
the identified UK airspace entry point. This was successfully found. Next, it
searches backwards, from the end of that section, to find the UK airspace exit
point. This did not appear in that section of the flight plan so the search
was unsuccessful. As there is no requirement for a flight plan to contain an
exit waypoint from a Flight Information Region (FIR) or a country’s airspace,
the software is designed to cope with this scenario.</p>
<p>Therefore, where there is no UK exit point explicitly included, the software
logic utilises the waypoints as detailed in the ADEXP file to search for the
next nearest point beyond the UK exit point. This was also not present.</p>
<p>The software therefore moved on to the next waypoint.</p>
</blockquote>
<p>OK, so I think this is what is going on, the situation looked something like
this:</p>
<pre><code><span>           4       2        8         5              1           9
</span><span>ICAO:  F------Q--------T--------O-----------P---------------Y--------U
</span><span>
</span><span>ADEXP: F   S  Q    C   T   A    O  E  X     P   W   B   Q   Y        U
</span><span>                       UK  UK   UK UK UK    UK  UK
</span></code></pre>
<p>Here the ICAO route has waypoints (represented by capital letters) separated by
known routes (numbers). On the bottom we have the ADEXP waypoints. The ADEXP
waypoints that are located in the UK airspace are marked with <code>UK</code>.</p>
<ul>
<li>The software has identified:
<ul>
<li><code>entry</code>: waypoint <code>T</code></li>
<li><code>exit</code>: waypoint <code>W</code>
in the ADEXP waypoints.</li>
</ul>
</li>
<li>The software finds waypoint <code>T</code> in the ICAO flight plan.</li>
<li>The software <em>does not</em> find waypoint <code>W</code> in the ICAO flight plan.</li>
<li>The software therefore takes the next waypoint in the ADEXP list, so <code>B</code>, and
tries to find it too, and also does not find it.</li>
<li>So it does this again, taking waypoint <code>Q</code>, and it <em>does</em> find it, but at the
<em>start</em> of the ICAO flight plan, before the plane even enters the UK.</li>
</ul>
<blockquote>
<p>This search was successful as a duplicate identifier appeared in the flight
plan.</p>
</blockquote>
<p>What should the software have done? Well, <code>Q</code> is clearly <em>not</em> the waypoint we
are searching for, we are searching for waypoint <code>Y</code>, since <code>[T, O, P, Y]</code> is
the smallest segment of the ICAO plan that contains all the UK waypoints.</p>
<p>It's important to note here that the original algorithm is buggy; it is perfectly
possible to unambiguously extract the UK portion of this example flight plan;
see <a href="https://jameshaydon.github.io/nats-fail/#how-to-code-this-properly">below</a>. And this is likely the case for the
flight plan that caused the meltdown too.</p>
<blockquote>
<p>Having found an entry and exit point, with the latter being the duplicate and
therefore geographically incorrect, the software could not extract a valid UK
portion of flight plan between these two points. This is the root cause of the
incident. We can therefore rule out any cyber related contribution to this
incident.</p>
</blockquote>
<p>It sounds like the exception was raised in a later portion of the code, which
converts the plan to an internal format for <em>NAS</em>. This part failed because the
identified entry/exit waypoints didn't even specify a valid segment of the ICAO
route.</p>
<blockquote>
<p>Safety critical software systems are designed to always fail safely. This
means that in the event they cannot proceed in a demonstrably safe manner,
they will move into a state that requires manual intervention.</p>
</blockquote>
<p>We are left wondering if, had the misidentified waypoint been in a more
plausible geographic location, the code might not have thrown an exception and
passed along wrong data to ATCOs.</p>
<blockquote>
<p>In this case the software within the FPRSA-R subsystem was unable to establish
a reasonable course of action that would preserve safety and so raised a
critical exception. A critical exception is, broadly speaking, an exception of
last resort after exploring all other handling options. Critical exceptions
can be raised as a result of software logic or hardware faults, but
essentially mark the point at which the affected system cannot continue.</p>
</blockquote>
<p>It sounds like the software was written thinking this exception would never
occur.</p>
<blockquote>
<p>Clearly a better way to handle this specific logic error would be for FPRSA-R
to identify and remove the message and avoid a critical exception. However,
since flight data is safety critical information that is passed to ATCOs the
system must be sure it is correct and could not do so in this case. It
therefore stopped operating, avoiding any opportunity for incorrect data being
passed to a controller. The change to the software will now remove the need
for a critical exception to be raised in these specific circumstances.</p>
<p>Having raised a critical exception the FPRSA-R primary system wrote a log file
into the system log. It then correctly placed itself into maintenance mode and
the C&amp;M system identified that the primary system was no longer available. In
the event of a failure of a primary system the backup system is designed to
take over processing seamlessly. In this instance the backup system took over
processing flight plan messages. As is common in complex real-time systems the
backup system software is located on separate hardware with separate power and
data feeds.</p>
<p>Therefore, on taking over the duties of the primary server, the backup system
applied the same logic to the flight plan with the same result. It
subsequently raised its own critical exception, writing a log file into the
system log and placed itself into maintenance mode.</p>
<p>At this point with both the primary and backup FPRSA-R sub-systems having
failed safely the FPRSA-R was no longer able to automatically process flight
plans. It required restoration to normal service through manual intervention.
The entire process described above, from the point of receipt of the ADEXP
message to both the primary and backup sub-systems moving into maintenance
mode, took less than 20 seconds. 08:32 therefore marks the point at which the
automatic processing of flight plans ceased and the 4 hour buffer to manual
flight plan input commenced. The steps taken to restore the FPRSA-R sub-system
are described in section 5 of this report.</p>
</blockquote>
<p>Then support teams tried to fix things, but unfortunately it took longer than
the 4 hours they had:</p>
<blockquote>
<p>The 1st Line support team were alerted to the incident through the C&amp;M systems
that directly monitor operational systems as well as through direct feedback
from the Operational teams using the FPRSA-R sub-system at the time. The
initial response for the team followed standard recovery processes using the
centralised C&amp;M systems to restart the sub-system. Following multiple attempts
to restore the service, which were unsuccessful, the 2nd Line engineering team
was mobilised and supported the on-site engineers remotely via video link.</p>
</blockquote>
<p><img src="https://jameshaydon.github.io/nats-fail/off-and-on-again.jpg" alt="have you tried turning it off and on again?"></p>
<blockquote>
<p>The on-call teams working remotely with the on-site engineering teams followed
a staged analysis, involving increasingly detailed procedures to attempt to
resolve the issue, none of which were successful. As per standard escalation
procedures, 2nd Line engineers were engaged to provide further access to
advanced diagnostics and logging capabilities.</p>
</blockquote>
<p>It doesn't say how long it took, but the manufacturer of the <code>FPRSA-R</code> system was
eventually called:</p>
<blockquote>
<p>Additional support was then requested from the Technical Design team and
sub-system manufacturer as 1st and 2nd Line support had been unable to restore
the service or identify the precise root cause, which was unusual. The
manufacturer was able to offer further expertise including analysis of
lower-level software logs which led to identification of the likely flight
plan that had caused the software exception. Through understanding which
flight plan had caused the incident the manufacturer was able to provide the
precise sequence of actions necessary to recover the system in a controlled
and safe manner.</p>
</blockquote>
<p>The system was eventually restored, but unfortunately the knock-on effects by
that point were already disastrous.</p>
<p>The manufacturer is an Austrian company, <a href="https://en.wikipedia.org/wiki/Frequentis">Frequentis
AG</a>:</p>
<blockquote>
<p>An FPRSA sub-system has existed in NATS for many years and in 2018 the
previous FPRSA sub- system was replaced with new hardware and software
manufactured by Frequentis AG, one of the leading global ATC System providers.
The manufacturer’s ATC products are operating in approximately 150 countries
and they hold a world-leading position in aeronautical information management
(AIM) and message handling systems.</p>
</blockquote>
<p>The "Nobody ever gets fired for hiring Accenture" defence.</p>
<p>We can find a few job ads related to air traffic control systems at Frequentis
AG on their <a href="https://jobs.frequentis.com/careers/SearchJobs/air?listFilterMode=1">careers
page</a>
Programming languages used: <code>Ada</code>, <code>C++</code>, <code>Java</code>, <code>Python</code>, with <code>Java</code> being
the most common. The code above sounds like it could have been written in any of
these languages, but Ada would at least be safer than the others in other ways.</p>
<h2 id="thoughts">Thoughts</h2>
<p>Things that went wrong:</p>
<ol>
<li>The software that processes flight plans (<code>FPRSA-R</code>) was written in a buggy
way.</li>
<li>The software and system are not properly tested.</li>
<li>The <code>FPRSA-R</code> system has bad <a href="https://en.wikipedia.org/wiki/Failure_mode_and_effects_analysis" title="wikipedia">failure modes</a></li>
</ol>
<h3 id="the-software-was-buggy">The software was buggy</h3>
<p>The software was incapable of extracting the UK portion of the ICAO flight plan,
even though the flight plan was apparently valid (at least according to IFPS).</p>
<ul>
<li>
<p>The procedure was very fiddly and failed for a silly reason.</p>
</li>
<li>
<p>Waypoint markers are not globally unique, but this is a known issue, so NATS
should make sure their systems are robust enough to handle it. <em>All other air
traffic control authorities have to deal with this</em>. NATS says the following
about this in the report:</p>
<blockquote>
<p>Although there has been work by ICAO and other bodies to eradicate
non-unique waypoint names there are duplicates around the world. In order to
avoid confusion latest standards state that such identical designators
should be geographically widely spaced. In this specific event, both of the
waypoints were located outside of the UK, one towards the beginning of the
route and one towards the end; approximately 4000 nautical miles apart.</p>
</blockquote>
<p>When waypoints with the same name are widely spaced, this makes flight plans
unambiguous, because successive waypoints in a flight plan cannot be too far
apart. They also mention possible actions they will take:</p>
<blockquote>
<p>The feasibility of working through the UK state with ICAO to remove the
small number of duplicate waypoint names in the ICAO administered global
dataset that relate to this incident.</p>
</blockquote>
<p>Waypoint names are clearly chosen to be short and snappy. Here's a sequence
from some flight plan I found: <code>KOMAL</code>, <code>ATRAK</code>, <code>SORES</code>, <code>SAKTA</code>, <code>ALMIK</code>,
<code>IGORO</code>, <code>ATMED</code>, etc. It's clear that the system has been designed so these
names can be communicated quickly, e.g. over radio, and that pilots and
air traffic controllers can become familiar with those on the routes they
usually fly. Changing the name of a waypoint can be a scary operation.
Uniqueness is obviously desirable, but it has to be balanced against other
considerations. Including this suggestion in the initial report feels like
NATS is trying to shift the blame onto ICAO.</p>
<p>Furthermore, I don't see why a flight plan can't include the same <em>geographic</em>
waypoint several times; for example for leisure flights or military exercises.
Taking off and landing at the same airport is definitely a thing (called a
"round-robin flight plan"). It doesn't sound like the <code>FPRSA-R</code> algorithm
would be very robust to that.</p>
</li>
</ul>
<p>NATS officials are trying to spin this as:</p>
<blockquote>
<p>An air traffic meltdown in Britain was caused by a "one in 15 million" event,
the boss of traffic control provider NATS said, as initial findings showed how
a single flight plan with two identically labelled markers caused the chaos.</p>
<p>"This was a one in 15 million chance. We've processed 15 million flight plans
with this system up until this point and never seen this before," NATS CEO
Martin Rolfe told the BBC, as airlines stepped up calls for compensation for
the breakdown. <a href="https://www.reuters.com/world/uk/uk-aviation-regulator-review-air-traffic-control-failure-2023-09-06/">Reuters</a></p>
</blockquote>
<p>The system was put in place in 2018, so what Martin Rolfe is saying here is that
this sort of thing only had a chance of occurring "once every 5 years", which is
apparently an acceptable frequency for having a complete air traffic control
meltdown.</p>
<h3 id="the-system-was-poorly-tested">The system was poorly tested</h3>
<p><a href="https://en.wikipedia.org/wiki/Fuzzing">fuzzing</a>, for example, may have
prevented this. By bombarding such a system with randomly generated flight
plans, you can see if any of them cause bad failure modes: a crashed system
where one doesn't know immediately what went wrong. By inspecting which sorts of
flight plans cause problems, it would become apparent that those with duplicate
waypoint identifiers in the ADEXP portion cannot be processed properly.</p>
<h3 id="the-fprsa-r-system-has-bad-failure-modes">The <code>FPRSA-R</code> system has bad failure modes</h3>
<p>All systems can malfunction, so the important thing is that they malfunction <em>in
a good way</em> and that those responsible are <em>prepared</em> for malfunctions.</p>
<p>A single flight plan caused a problem, and the entire <code>FPRSA-R</code> system crashed,
which means no flight plans are being processed at all. If there is a problem
with a single flight plan, it should be moved to a separate slower queue, for
manual processing by humans. NATS acknowledges this in their "actions already
undertaken or in progress":</p>
<blockquote>
<p>The addition of specific message filters into the data flow between IFPS and
FPRSA-R to filter out any flight plans that fit the conditions that caused the
incident.</p>
</blockquote>
<p>When <code>FPRSA-R</code> it did crash, it did so in an obscure way. This is a system
which <em>processes flight plans</em>, yet the relevant flight plan was only found in
"lower-level software logs". If there is an error processing a flight plan,
which brings down the whole system, a notification (including the flight plan)
should immediately be sent to some monitoring team.</p>
<p>NATS was also not prepared for an <code>FPRSA-R</code> system failure. The 1st
and 2nd Line support engineers were not able to locate, or did not think to
check, the low-level log files. This has been fixed:</p>
<blockquote>
<p>An operating instruction has been put in place to allow prompt recovery of the
FPRSA-R sub-system if the same circumstances recur. Each of the technical
operators have been trained to implement the new process. With enhanced
monitoring in place, additional engineering expertise will also be present to
oversee the activity.</p>
</blockquote>
<h3 id="possible-lack-of-formal-verification">Possible lack of formal verification</h3>
<p>As reddit user <code>DontWannaMissAFling</code> <a href="https://www.reddit.com/r/programming/comments/16fhmuq/comment/k02o6n8/?utm_source=share&amp;utm_medium=web2x&amp;context=3">points out</a>:</p>
<blockquote>
<p>But what's wild to me is that something as safety critical as air traffic
control apparently isn't using proven techniques like formal verification,
model checking to eliminate these classes of bugs entirely.</p>
<p>Like as an industry we use TLA+ to stop AWS from having downtime or Xboxes
segfaulting, but not to keep planes in the air?</p>
</blockquote>
<p>I agree that it certainly doesn't sound like any formal verification was used in
this case (for this system), and the report doesn't mention anything. Using
formal verification would certainly have helped here, I might explore this in
subsequent posts.</p>
<p>But it's possible formal verification was used, but faulty code still made its
way into production: end-2-end formal verification for large systems is still in
its infancy. We'll have to wait for the result of the enquiry to know more.</p>
<h2 id="humans-were-kept-safe-at-all-times">Humans were kept safe at all times</h2>
<p>I'd like to note (as does NATS in the report) that despite all the problems
highlighted above, planes in the air over the UK were still safe at all times.
They were being monitored by experienced ATCOs, which monitor planes by their
known flight plan, radio, radar and vision. The consequence of all this was not
that any human lives were put in danger, it's simply that far fewer flights
could take off in the first place, or had to be diverted away from UK airspace.
NATS did the right thing (reducing the number of flights), and kept everybody
safe.</p>
<h2 id="how-to-code-this-properly">How to code this properly</h2>
<p>So, how can we avoid this bug?</p>
<p>Let's recap the problem. There are two sequences of waypoints:</p>
<ul>
<li><code>ADEXP</code>: the full list of waypoints.</li>
<li><code>ICAO</code>: a subsequence of the ADEXP waypoints.</li>
</ul>
<p>Because the ICAO plan doesn't need to include the waypoints at which it
enters/exits an air traffic control region, extracting the segment of the ICAO
flight plan corresponding to the UK portion of the flight is not entirely
trivial. Of course, if we take the entire ICAO flight plan, it already contains
the UK portion, but what we really want is the <em>smallest</em> such segment. It's
interesting to note here that a flight could possibly enter UK airspace, and
then exit it again, and enter it again. We'll ignore this, that is, we will just
find a single contiguous segment that contains all UK portions of the flight,
since this is what the original code seemed to do.</p>
<p>I'm unsure why this task attempts to do this only using the ADEXP data, rather
than consulting a database about how waypoints and flight segments intersect UK
airspace. It seems strange, but let's move on.</p>
<p>Note that it is impossible to achieve this task with the ICAO flight plan alone
(and no knowledge of routes), even if you know for each waypoint if it is in the
UK or not. Indeed you could even be in a situation where <em>none</em> of the waypoints
in the ICAO route are in the UK, for example when the flight plan clips a small
portion of the UK between two of the ICAO waypoints.</p>
<p>So this is why the ADEXP waypoint list is used, and the assumption here, I
assume, is that the ADEXP list contains <em>all</em> the waypoints, and that
furthermore, waypoint granularity is such that if <em>adjacent</em> waypoints both
don't intersect UK airspace, then the segment between them doesn't either.</p>
<p>The mistake of the faulty algorithm described above is to try to work on both
the ICAO data and the ADEXP data as they are, maintaining pointers into each of
them, updating them with vague and wrong invariants in the background of the
programmer's mind. This is a recipe for bugs. Instead, the first thing to do is
to reconcile the data and then carefully extract the UK portion from that.</p>
<p>So we create a data structure for a plan:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>-- A flight plan, with segments between points 'p' via routes 'r'.
</span><span>data </span><span>Plan</span><span> p r
</span><span>  = </span><span>End</span><span> p
</span><span>  | </span><span>Leg</span><span> p r (</span><span>Plan</span><span> p r)
</span></code></pre>
<p>(This is <a href="https://www.haskell.org/">Haskell</a> code, but the ideas apply to most languages.)</p>
<p>This says that a <code>Plan p r</code> has either arrived at its destination <code>End p</code>, or
consists of a segment starting from <code>p</code>, via <code>r</code>, and the <code>rest</code> of the plan:
<code>Leg p r rest</code>.</p>
<p>We can now define all the sorts of flight plan data we will deal with:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>type </span><span>ICAO</span><span>     p r = </span><span>Plan</span><span> p r         </span><span>-- points and routes, no intermediate waypoints
</span><span>type </span><span>ADEXP</span><span>    p   = </span><span>Plan</span><span> p [p]       </span><span>-- points and intermediate waypoints, no route data
</span><span>type </span><span>Combined</span><span> p r = </span><span>Plan</span><span> p (</span><span>Via</span><span> p r) </span><span>-- all the data combined
</span><span>
</span><span>data </span><span>Via</span><span> p r = </span><span>Via
</span><span>  { route   :: r,
</span><span>    </span><span>through </span><span>::</span><span> [</span><span>p</span><span>]
</span><span>  }
</span><span>  </span><span>deriving</span><span> stock (</span><span>Show</span><span>)
</span></code></pre>
<p>Here <code>Combined</code> is our reconciled flight plan, it combined all the information
form ICAO and ADEXP. We can project a <code>Plan</code> back down to <code>ICAO</code> or <code>ADEXP</code>:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>projectICAO </span><span>:: Combined </span><span>p r </span><span>-&gt; ICAO </span><span>p r
</span><span>projectICAO = mapRoutes (.route)
</span><span>
</span><span>projectADEXP </span><span>:: Combined </span><span>p r </span><span>-&gt; ADEXP </span><span>p
</span><span>projectADEXP = mapRoutes (.through)
</span><span>
</span><span>mapRoutes </span><span>::</span><span> (</span><span>r </span><span>-&gt; </span><span>r</span><span>') </span><span>-&gt; Plan </span><span>p r </span><span>-&gt; Plan </span><span>p r</span><span>'
</span><span>mapRoutes _ (</span><span>End</span><span> p) = </span><span>End</span><span> p
</span><span>mapRoutes f (</span><span>Leg</span><span> p r rest) = </span><span>Leg</span><span> p (f r) (mapRoutes f rest)
</span></code></pre>
<p>We'll assume we have already parsed the data into the data structures above.
This is just a matter of reading the spec carefully and turning it into code,
and hopefully something the <code>FPRSA-R</code> did correctly, though as noted previously
it might be working on the text version directly.</p>
<p>Now we write our reconciliation function. For ICAO and ADEXP to reconcile, the
start and end points must match. When reconciling a leg of a flight plan, a
certain amount of waypoints can be skipped in the ICAO plan, and the rest of
them must reconcile with the rest of the flight plan:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>reconcile </span><span>::</span><span> (</span><span>Eq </span><span>p</span><span>) </span><span>=&gt; ICAO </span><span>p r </span><span>-&gt;</span><span> [</span><span>p</span><span>] </span><span>-&gt;</span><span> [</span><span>Combined </span><span>p r</span><span>]
</span><span>reconcile (</span><span>End</span><span> p) [p']             | p == p' = pure (</span><span>End</span><span> p)
</span><span>reconcile (</span><span>Leg</span><span> p r rest) (p' : ps) | p == p' = </span><span>do
</span><span>  (through, restAdexp) &lt;- splits ps
</span><span>  recoRest &lt;- reconcile rest restAdexp
</span><span>  pure (</span><span>Leg</span><span> p </span><span>Via</span><span> {route = r, through} recoRest)
</span><span>reconcile _ _ = </span><span>[]
</span><span>
</span><span>-- | All the ways to snap a list in two.
</span><span>splits </span><span>::</span><span> [</span><span>a</span><span>] </span><span>-&gt;</span><span> [([</span><span>a</span><span>], [</span><span>a</span><span>])]
</span><span>splits </span><span>[] </span><span>= [(</span><span>[]</span><span>, </span><span>[]</span><span>)]
</span><span>splits xs@(x : rest) = (</span><span>[]</span><span>, xs) : (first (x :) &lt;$&gt; splits rest)
</span></code></pre>
<p>Note that the function produces <em>all</em> the possible reconciliations. This is
because reconciliations are not necessarily unique because waypoints can appear
more than once. By calculating all the possible reconciliations, we'll know if
the data is ambiguous, and flag those flight plans for manual processing.</p>
<p>Next, we extract the UK portion of the flight plan. This is done in 3 steps:</p>
<ol>
<li>Remove all legs at the start which don't cross into UK airspace.</li>
<li>Traverse the legs which are in UK airspace.</li>
<li>Once the rest of the flight plan is never again in the UK, cut it short.</li>
</ol>
<p>Each function calls the next step in sequence. Note that we return a
<code>NonUkPlan</code> error when the system reaches the end of the plan without having
found a UK part. By having a compiler which checks that pattern-matches are
covering, the possible failures arise naturally while coding.</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>-- Extract the UK part of the flight.
</span><span>ukSegment </span><span>::</span><span> (</span><span>p </span><span>-&gt; Bool</span><span>) </span><span>-&gt; Combined </span><span>p r </span><span>-&gt; Either Err</span><span> (</span><span>Combined </span><span>p r</span><span>)
</span><span>ukSegment uk (</span><span>End</span><span> p)
</span><span>  | nonUkPlan uk (</span><span>End</span><span> p) = </span><span>Left NonUkPlan
</span><span>  | otherwise = pure (</span><span>End</span><span> p)
</span><span>ukSegment uk plan@(</span><span>Leg</span><span> _ _ rest) =
</span><span>  </span><span>if</span><span> nonUkLeg uk plan
</span><span>    </span><span>then</span><span> ukSegment uk rest
</span><span>    </span><span>else</span><span> pure (flyUK uk plan)
</span><span>
</span><span>-- Fly the UK part of the flight.
</span><span>flyUK </span><span>::</span><span> (</span><span>p </span><span>-&gt; Bool</span><span>) </span><span>-&gt; Combined </span><span>p r </span><span>-&gt; Combined </span><span>p r
</span><span>flyUK _ (</span><span>End</span><span> end) = </span><span>End</span><span> end
</span><span>flyUK uk (</span><span>Leg</span><span> p v rest)
</span><span>  | nonUkPlan uk rest = </span><span>Leg</span><span> p v (afterUK rest)
</span><span>  | otherwise = </span><span>Leg</span><span> p v (flyUK uk rest)
</span><span>
</span><span>-- Skip the rest of the flight.
</span><span>afterUK </span><span>:: Combined </span><span>p r </span><span>-&gt; Combined </span><span>p r
</span><span>afterUK plan = </span><span>End</span><span> (start plan)
</span></code></pre>
<p>These use some small functions:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>-- The next leg of the journey doesn't fly through the UK.
</span><span>nonUkLeg </span><span>::</span><span> (</span><span>p </span><span>-&gt; Bool</span><span>) </span><span>-&gt; Combined </span><span>p r </span><span>-&gt; Bool
</span><span>nonUkLeg uk (</span><span>End</span><span> p) = not (uk p)
</span><span>nonUkLeg uk (</span><span>Leg</span><span> p v _) = not (uk p) &amp;&amp; not (any uk v.through)
</span><span>
</span><span>-- The whole plan isn't in the UK.
</span><span>nonUkPlan </span><span>::</span><span> (</span><span>a </span><span>-&gt; Bool</span><span>) </span><span>-&gt; Combined </span><span>a r </span><span>-&gt; Bool
</span><span>nonUkPlan uk plan = all (nonUkLeg uk) (legs plan)
</span><span>
</span><span>legs </span><span>:: Plan </span><span>p r </span><span>-&gt;</span><span> [</span><span>Plan </span><span>p r</span><span>]
</span><span>legs (</span><span>End</span><span> p) = [</span><span>End</span><span> p]
</span><span>legs plan@(</span><span>Leg</span><span> _ _ rest) = plan : legs rest
</span><span>
</span><span>start </span><span>:: Plan </span><span>p r </span><span>-&gt; </span><span>p
</span><span>start (</span><span>End</span><span> p) = p
</span><span>start (</span><span>Leg</span><span> p _ _) = p
</span></code></pre>
<p>Putting it all together, we get:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>ukPartOfICAO </span><span>::</span><span> (</span><span>Eq </span><span>p</span><span>) </span><span>=&gt;</span><span> (</span><span>p </span><span>-&gt; Bool</span><span>) </span><span>-&gt; ICAO </span><span>p r </span><span>-&gt;</span><span> [</span><span>p</span><span>] </span><span>-&gt; Either Err</span><span> (</span><span>ICAO </span><span>p r</span><span>)
</span><span>ukPartOfICAO uk icao adexp = </span><span>case</span><span> reconcile icao adexp </span><span>of
</span><span>  [plan] -&gt; projectICAO &lt;$&gt; ukSegment uk plan
</span><span>  </span><span>[]     </span><span>-&gt; </span><span>Left CannotReconcileIcaoAdexp
</span><span>  _      -&gt; </span><span>Left AmbiguousReconciliationsOfIcaoAdexp
</span></code></pre>
<p>We collected the following errors while coding:</p>
<pre data-lang="haskell"><code data-lang="haskell"><span>data </span><span>Err
</span><span>  = </span><span>NonUkPlan
</span><span>  | </span><span>CannotReconcileIcaoAdexp
</span><span>  | </span><span>AmbiguousReconciliationsOfIcaoAdexp
</span></code></pre>
<p>Let's test it with our example:</p>
<pre><code><span>           4       2        8         5              1           9
</span><span>ICAO:  F------Q--------T--------O-----------P---------------Y--------U
</span><span>
</span><span>ADEXP: F   S  Q    C   T   A    O  E  X     P   W   B   Q   Y        U
</span><span>                       UK  UK   UK UK UK    UK  UK
</span></code></pre>
<pre data-lang="haskell"><code data-lang="haskell"><span>inUK = (</span><span>`</span><span>elem</span><span>`</span><span> ["</span><span>T</span><span>", "</span><span>A</span><span>", "</span><span>O</span><span>", "</span><span>E</span><span>", "</span><span>X</span><span>", "</span><span>P</span><span>", "</span><span>W</span><span>"])
</span><span>icao = ("</span><span>F</span><span>", </span><span>4</span><span>) ~&gt; ("</span><span>Q</span><span>", </span><span>2</span><span>) ~&gt; ("</span><span>T</span><span>", </span><span>8</span><span>) ~&gt; ("</span><span>O</span><span>", </span><span>5</span><span>) ~&gt; ("</span><span>P</span><span>", </span><span>1</span><span>) ~&gt; ("</span><span>Y</span><span>", </span><span>9</span><span>) ~&gt; </span><span>End </span><span>"</span><span>U</span><span>"
</span><span>adexp = ["</span><span>F</span><span>", "</span><span>S</span><span>", "</span><span>Q</span><span>", "</span><span>C</span><span>", "</span><span>T</span><span>", "</span><span>A</span><span>", "</span><span>O</span><span>", "</span><span>E</span><span>", "</span><span>X</span><span>", "</span><span>P</span><span>", "</span><span>W</span><span>", "</span><span>B</span><span>", "</span><span>Q</span><span>", "</span><span>Y</span><span>", "</span><span>U</span><span>"]
</span><span>
</span><span>infixr </span><span>6 </span><span>~&gt;
</span><span>(~&gt;) (p, r) = </span><span>Leg</span><span> p r
</span></code></pre>
<p>And try this at the REPL:</p>
<pre><code><span>λ&gt; ukPortionOfICAO inUK icao adexp
</span><span>Right (Leg "T" 8 (Leg "O" 5 (Leg "P" 1 (End "Y"))))
</span></code></pre>
<p>We can see that this is the correct result:</p>
<pre><code><span>                                 UK portion of ICAO
</span><span>                       ┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┫
</span><span>           4       2        8         5              1           9
</span><span>ICAO:  F------Q--------T--------O-----------P---------------Y--------U
</span><span>
</span><span>ADEXP: F   S  Q    C   T   A    O  E  X     P   W   B   Q   Y        U
</span><span>                       UK  UK   UK UK UK    UK  UK
</span></code></pre>
<p>The waypoint <code>Q</code> is a duplicate in the ADEXP list, but the system still returns
the correct portion of the ICAO flight path. Crisis averted! The fact that there
is a duplicate identifier in this case is immaterial, the ICAO and ADEXP data
still reconcile unambiguously, and the correct sub-route is well-defined.</p>
<p>How large can flight plans get? Well here is a flight plan from London to Sydney
that contains a total of 158 waypoints, and about a third of them appear in the
ICAO route:
<img src="https://jameshaydon.github.io/nats-fail/london-sydney.png" alt="London to Sydney flight plan"> 
<code>ukPortionOfICAO</code> returns practically instantly for such a flight plan.</p>
<p>Comments on <a href="https://www.reddit.com/r/programming/comments/16fhmuq/a_deep_dive_into_the_bug_that_caused_the_uk_air/?utm_source=share&amp;utm_medium=web2x&amp;context=3">reddit</a></p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft has not stopped forcing Edge on Windows 11 users (686 pts)]]></title>
            <link>https://www.ctrl.blog/entry/windows-system-components-default-edge.html</link>
            <guid>37461449</guid>
            <pubDate>Mon, 11 Sep 2023 00:25:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ctrl.blog/entry/windows-system-components-default-edge.html">https://www.ctrl.blog/entry/windows-system-components-default-edge.html</a>, See on <a href="https://news.ycombinator.com/item?id=37461449">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="https://schema.org/articleBody">
        <p>Microsoft published <a href="https://blogs.windows.com/windows-insider/2023/08/25/announcing-windows-11-insider-preview-build-23531-dev-channel/" rel="external" title="“Announcing Windows 11 Insider Preview Build 23531 (Dev Channel)”">a blog post on the <cite>Windows Insider Blog</cite></a> in <time datetime="2023-08-25">late August</time> with a vague statement saying that “Windows system components“ were to begin respecting the default web browser setting. Windows 10 and 11 regularly bypass this setting and force-open links in Microsoft Edge instead. In my extensive testing, I haven’t found any changes in the new Windows Insider version.</p>
        <p>You may have read stories in the tech media celebrating that Windows will finally respect the default browser setting. This reporting seems to have been done completely without verification and based entirely on a misunderstanding. The source of the confusion is this one highlighted but vague entry in the changelog for a recent Windows 11 Insider preview build:</p>
        <figure>
          <blockquote cite="https://blogs.windows.com/windows-insider/2023/08/25/announcing-windows-11-insider-preview-build-23531-dev-channel/">
            <p>In the European Economic Area (<abbr>EEA</abbr>), Windows system components use the default browser to open links.</p>
          </blockquote>
          <figcaption>
            <p><a href="https://blogs.windows.com/windows-insider/2023/08/25/announcing-windows-11-insider-preview-build-23531-dev-channel/" rel="external" title="“Announcing Windows 11 Insider Preview Build 23531 (Dev Channel)”"><cite>Announcing Windows 11 Insider Preview Build 23531 (Dev Channel)</cite></a>, Amanda Langowski Brandon LeBlanc</p>
          </figcaption>
        </figure>
        <p>The highlight makes it sound like Microsoft has finally caved to regulatory pressure from the European Union (<abbr>EU</abbr>). The software powerhouse has abused the dominant market position of its Windows operating system to promote its Edge web browser and services for too long.</p>
        <p>I’ve followed this developing story closely over the years. I even developed the popular open-source <a href="https://www.ctrl.blog/entry/edgedeflector-default-browser.html" title="“EdgeDeflector enforces your default browser setting in Windows”">EdgeDeflector program</a> that hijacked web links destined for Microsoft Edge and directed them back to your default web browser. Microsoft finally reacted and <a href="https://www.ctrl.blog/entry/microsoft-edge-protocol-competition.html" title="“Windows now blocks Edge browser competitors from opening links”">blocked EdgeDeflector from working</a> once the Mozilla Firefox and Brave browsers began <a href="https://www.ctrl.blog/entry/anti-competitive-browser-edges.html" title="“Brave and Firefox to intercept links that force-open in Microsoft Edge”">building the functionality into their web browsers</a>.</p>
        <p>Excitedly, I installed the new Windows Insider build and began testing the changes to see them in action. At first, I didn’t believe my findings. <em>Nothing</em> had changed from the current version of Windows 11.</p>
        <ul>
          <li>The new Windows version still strongly discourages changing the default browser away from Microsoft Edge.</li>
          <li>After system updates, the new version still aggressively prompts you with a captive full-screen experience on start-up to reset your default web browser to Microsoft Edge.</li>
          <li>Web links in primary surfaces still force-open Microsoft Edge — including links in the new Copilot, Start menu, Search on the taskbar and desktop, Windows Spotlight, first-party apps (Outlook, Teams, News, Weather, and more), and Widgets on the taskbar (formerly called News and Weather).</li>
        </ul>
        <p>I’ve verified my findings in the Home and Professional editions of Windows and even the <abbr title="European Union">EU</abbr>-specific “N” variants of each edition. I’ve tested in two configurations for Norway (<abbr title="European Economic Area">EEA</abbr> member) and Germany (<abbr title="European Economic Area">EEA</abbr> and <abbr title="European Union">EU</abbr> member). For both tests, I installed devices with region and locale settings matching the desired country with <abbr title="Internet Protocol">IP</abbr> addresses and geolocation sensor data to match.</p>
        <p>I’ve checked, double-, and triple-checked my findings. <em>Nothing has changed.</em> Web links still force-open in Microsoft Edge instead of your default web browser.</p>
        <p>Microsoft first announced the changes for Windows Insider build 23531 (Developer channel). I waited for two more releases and retested with builds 23536 and 23541, both from the Developer channel. I also retested with the Canary channel, which is even further ahead on the development tree than the Developer channel.</p>
        <p>Microsoft sometimes gradually rolls out changes in the Windows Insider program to a limited set of users. It does not document publicly which new changes are gradually rolled out. However, there were only two new experiments in build 23531. None of them are related to default browser settings or Microsoft Edge. The new changes to default browser handling may be a gradual rollout, though.</p>
        <p>Microsoft was vague about the change, and neither its customers nor the tech media verified their assumptions before running with the story. Despite not having implemented the changes everyone assumed it had, it has received lots of positive press attention for doing the right thing.</p>
        <p>I have not found anyone commenting on whether this change worked for them in the many and extensive discussions on Hacker News, Reddit, and other social media. I’ve also not found any traces of confirmation or checks in the hundreds of news sites that ran the story nor in their comment sections. There has also been no mention of it in the Insider Feedback Hub or any subsequent Windows Insider build announcements or changelogs.</p>
        <p>I have <em>not</em> reached out to Microsoft for a comment on this story. Frankly, at this point, I rather assume they hate me personally more than they hate their average customers. Microsoft has also refused to make statements to <a href="https://www.theregister.com/2023/08/30/microsoft_windows_11_bing/" rel="external" title="“After injecting pop-up ads for Bing into Windows, Microsoft now bends to Europe on links”">The Register</a> and <a href="https://www.theverge.com/2023/9/5/23859537/microsoft-windows-11-default-browser-links-eu-eea-changes" rel="external" title="”Microsoft to stop forcing Windows 11 users into Edge in EU countries“">The Verge</a> for their stories on the vague changes.</p>
        <p><small>Disclaimer: I am an employee of <em>Vivaldi Technologies</em>, a competitor to Microsoft Edge. This website is my personal blog, and the views and findings expressed here do not represent my employer. I’m also the developer of EdgeDeflector, the circumvention program described in the article.</small></p>
      </div><div>
        <h3>Abbreviations</h3>
        <dl>
          <p>
            <dt><dfn><abbr>EEA</abbr></dfn></dt>
            <dd>European Economic Area</dd>
          </p>
          <p>
            <dt><dfn><abbr>EU</abbr></dfn></dt>
            <dd>European Union</dd>
          </p>
          <p>
            <dt><dfn><abbr>IP</abbr></dfn></dt>
            <dd>Internet Protocol</dd>
          </p>
        </dl>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[To make dishwashers great again? (2020) (123 pts)]]></title>
            <link>https://www.greenbuildinglawupdate.com/2020/11/articles/environmental/to-make-dishwashers-great-again/</link>
            <guid>37460941</guid>
            <pubDate>Sun, 10 Sep 2023 22:57:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.greenbuildinglawupdate.com/2020/11/articles/environmental/to-make-dishwashers-great-again/">https://www.greenbuildinglawupdate.com/2020/11/articles/environmental/to-make-dishwashers-great-again/</a>, See on <a href="https://news.ycombinator.com/item?id=37460941">Hacker News</a></p>
Couldn't get https://www.greenbuildinglawupdate.com/2020/11/articles/environmental/to-make-dishwashers-great-again/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The Awk book’s 60-line version of Make (232 pts)]]></title>
            <link>https://benhoyt.com/writings/awk-make/</link>
            <guid>37460815</guid>
            <pubDate>Sun, 10 Sep 2023 22:36:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://benhoyt.com/writings/awk-make/">https://benhoyt.com/writings/awk-make/</a>, See on <a href="https://news.ycombinator.com/item?id=37460815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="container">

<p>September 2023</p>

<blockquote>
  <p><strong>Go to:</strong> <a href="#original-awk-version">AWK Make</a> | <a href="#how-it-works">How it works</a> | <a href="#python-version">Python Make</a> | <a href="#conclusion">Conclusion</a></p>
</blockquote>

<p>In the wonderful book <em>The AWK Programming Language</em> by Aho, Weinberger, and Kernighan, there are a few pages at the end of chapter 7 that present a simplified version of the Make utility – written in a single page of AWK code.</p>

<p>Before we look at that, I want to mention that the <a href="https://awk.dev/">second edition</a> of the AWK book is coming out next month. Brian Kernighan’s done a great job of updating it, most notably with a new chapter on <a href="https://en.wikipedia.org/wiki/Exploratory_data_analysis">exploratory data analysis</a>, and adding proper CSV support to AWK to enable this. I was honoured to be asked to review a draft of the second edition.</p>

<p>AWK still shines for exploring data in 2023, especially with the new <code>--csv</code> option. CSV mode has also been <a href="https://git.savannah.gnu.org/cgit/gawk.git/tree/NEWS">added to Gawk</a> (GNU AWK), the most widely-installed version of AWK. My own <a href="https://github.com/benhoyt/goawk">GoAWK</a> implementation has had <a href="https://benhoyt.com/writings/goawk-csv/">proper CSV support</a> for some time, and I’ve added the <code>--csv</code> option to match the others.</p>

<p>The second edition of the book still includes the Make program, though it’s been made more readable with the <a href="https://github.com/benhoyt/awkmake/commit/a5793b2b55168959f3f2e976d1e409401cd8aac4">addition</a> of some “spacing and bracing” – this took it from 50 lines to 62 lines.</p>

<p>This article presents the Make program, to show how AWK is not just great for one-liners, but <a href="https://maximullaris.com/awk.html">can be used</a> as a scripting language too – though whether you <em>should</em> or not is another question.</p>

<p>I’m then going to compare what the same program would look like in Python, and briefly discuss when you’d choose AWK or Python for this kind of thing.</p>

<p>It should go without saying, but I intend this purely as a learning exercise (for me and my readers), not a program I’d recommend you use to build your projects!</p>

<h2 id="original-awk-version">Original AWK version</h2>

<p>The second edition of the book introduces the Make program as follows. (For what it’s worth, I find the term “target” confusing here – I think “source” or “dependency” would fit better.)</p>

<blockquote>
  <p>This section develops a
rudimentary updating program, patterned after the Unix <code>make</code> command, that
is based on the depth-first search technique of the previous section.</p>

  <p>To use the updater, one must explicitly describe what the components of the
system are, how they depend upon one another, and what commands are needed
to construct them. We’ll assume these dependencies and commands are stored
in a file, called a <code>makefile</code>, that contains a sequence of rules of the form</p>

  <div><pre><code>name:   t1 t2 ... tn
        commands
</code></pre></div>

  <p>The first line of a rule is a dependency relation that states that the program or
file <em>name</em> depends on the targets <em>t1</em>, <em>t2</em>, …, <em>tn</em> where each <em>ti</em> is a filename or
another <em>name</em>. Following each dependency relation may be one or more lines of
<em>commands</em> that list the commands necessary to generate <em>name</em>. Here is an
example of a <code>makefile</code> for a small program with two C files called <code>a.c</code> and <code>b.c</code>, and a <code>yacc</code>
grammar file <code>c.y</code>, a typical program-development application.</p>

  <div><pre><code>prog:   a.o b.o c.o
        gcc a.o b.o c.o -ly -o prog
a.o:    prog.h a.c
        gcc -c prog.h a.c
b.o:    prog.h b.c
        gcc -c prog.h b.c
c.o:    c.c
        gcc -c c.c
c.c:    c.y
        yacc c.y
        mv y.tab.c c.c
print:
        pr prog.h a.c b.c c.y
</code></pre></div>

  <p>The first line states that <code>prog</code> depends on the target files <code>a.o</code>, <code>b.o</code>, and <code>c.o</code>.
The second line says that <code>prog</code> is generated by using the C compiler command
<code>gcc</code> to link <code>a.o</code>, <code>b.o</code>, <code>c.o</code>, and a <code>yacc</code> library <code>y</code> into the file <code>prog</code>. The next rule
(third line) states that <code>a.o</code> depends on the targets <code>prog.h</code> and <code>a.c</code> and is
created by compiling these targets; <code>b.o</code> is the same. The file <code>c.o</code> depends on
<code>c.c</code>, which in turn depends on <code>c.y</code>, which has to be processed by the <code>yacc</code>
parser generator. Finally, the name <code>print</code> does not depend on any target; by
convention, for targetless names <code>make</code> will always perform the associated action,
in this case printing all the source files with the command <code>pr</code>.</p>

  <p>The dependency relations in the <code>makefile</code> can be represented by a graph
in which there is an edge from node <em>x</em> to node <em>y</em> whenever there is a dependency
rule with <em>x</em> on the left side and <em>y</em> one of the targets on the right. For a rule
with no targets, a successorless node with the name on the left is created. For
the <code>makefile</code> above, we have the following dependency graph:</p>

  <div><pre><code>                  prog                 print
                /   |   \
               /    |    \
            a.o    b.o    c.o
           /   \  /   \      \
          /     \/     \      \
        a.c   prog.h   b.c     c.c
                                |
                               c.y
</code></pre></div>
</blockquote>

<p>It’s a highly-simplified version of Make, of course, but still has the core concepts of outputs, dependencies, and build commands.</p>

<p>Before we look at how it works, I’ve included the full source code below, as it appears in the second edition of the AWK book. Click on the bold text to expand it, or skip down to “How it works” to see the code explained in detail.</p>

<details>
  <summary><strong>The AWK book’s Make program (full source code).</strong></summary>

  <div><pre><code><span>BEGIN</span> <span>{</span>
    <span>while</span> <span>(</span><span>getline</span> <span>&lt;</span><span>"makefile"</span> <span>&gt;</span> <span>0</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>$0</span> <span>~</span> <span>/^</span><span>[</span><span>A-Za-z</span><span>]</span><span>/</span><span>)</span> <span>{</span>  <span>#  $1: $2 $3 ...</span>
            <span>sub</span><span>(</span><span>/:/</span><span>,</span> <span>""</span><span>)</span>
            <span>if</span> <span>(</span><span>++</span><span>names</span><span>[</span><span>nm</span> <span>=</span> <span>$1</span><span>]</span> <span>&gt;</span> <span>1</span><span>)</span>
                <span>error</span><span>(</span><span>nm</span> <span>" is multiply defined"</span><span>)</span>
            <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>2</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>NF</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span># remember targets</span>
                <span>slist</span><span>[</span><span>nm</span><span>,</span> <span>++</span><span>scnt</span><span>[</span><span>nm</span><span>]]</span> <span>=</span> <span>$i</span>
        <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>$0</span> <span>~</span> <span>/^</span><span>\t</span><span>/</span><span>)</span> <span>{</span>      <span># remember cmd for</span>
            <span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>=</span> <span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>$0</span> <span>"\n"</span> <span>#   current name</span>
        <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>NF</span> <span>&gt;</span> <span>0</span><span>)</span> <span>{</span>
            <span>error</span><span>(</span><span>"illegal line in makefile: "</span> <span>$0</span><span>)</span>
        <span>}</span>
    <span>}</span>

    <span>ages</span><span>()</span>      <span># compute initial ages</span>

    <span>if</span> <span>(</span><span>ARGV</span><span>[</span><span>1</span><span>]</span> <span>in</span> <span>names</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>update</span><span>(</span><span>ARGV</span><span>[</span><span>1</span><span>])</span> <span>==</span> <span>0</span><span>)</span>
            <span>print</span> <span>ARGV</span><span>[</span><span>1</span><span>]</span> <span>" is up to date"</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>error</span><span>(</span><span>ARGV</span><span>[</span><span>1</span><span>]</span> <span>" is not in makefile"</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>function</span> <span>ages</span><span>(</span>      <span>f</span><span>,</span><span>n</span><span>,</span><span>t</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>t</span> <span>=</span> <span>1</span><span>;</span> <span>(</span><span>"ls -t"</span> <span>|</span> <span>getline</span> <span>f</span><span>)</span> <span>&gt;</span> <span>0</span><span>;</span> <span>t</span><span>++</span><span>)</span>
        <span>age</span><span>[</span><span>f</span><span>]</span> <span>=</span> <span>t</span>         <span># all existing files get an age</span>
    <span>close</span><span>(</span><span>"ls -t"</span><span>)</span>

    <span>for</span> <span>(</span><span>n</span> <span>in</span> <span>names</span><span>)</span>
        <span>if</span> <span>(</span><span>!</span><span>(</span><span>n</span> <span>in</span> <span>age</span><span>))</span>   <span># if n has not been created</span>
            <span>age</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>9999</span>  <span># make n really old</span>
<span>}</span>

<span>function</span> <span>update</span><span>(</span><span>n</span><span>,</span>   <span>changed</span><span>,</span><span>i</span><span>,</span><span>s</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span><span>(</span><span>n</span> <span>in</span> <span>age</span><span>))</span>
        <span>error</span><span>(</span><span>n</span> <span>" does not exist"</span><span>)</span>
    <span>if</span> <span>(</span><span>!</span><span>(</span><span>n</span> <span>in</span> <span>names</span><span>))</span>
        <span>return</span> <span>0</span>
    <span>changed</span> <span>=</span> <span>0</span>
    <span>visited</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>1</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>scnt</span><span>[</span><span>n</span><span>];</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>visited</span><span>[</span><span>s</span> <span>=</span> <span>slist</span><span>[</span><span>n</span><span>,</span> <span>i</span><span>]]</span> <span>==</span> <span>0</span><span>)</span>
            <span>update</span><span>(</span><span>s</span><span>)</span>
        <span>else</span> <span>if</span> <span>(</span><span>visited</span><span>[</span><span>s</span><span>]</span> <span>==</span> <span>1</span><span>)</span>
            <span>error</span><span>(</span><span>s</span> <span>" and "</span> <span>n</span> <span>" are circularly defined"</span><span>)</span>
        <span>if</span> <span>(</span><span>age</span><span>[</span><span>s</span><span>]</span> <span>&lt;=</span> <span>age</span><span>[</span><span>n</span><span>])</span>
            <span>changed</span><span>++</span>
    <span>}</span>
    <span>visited</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>2</span>
    <span>if</span> <span>(</span><span>changed</span> <span>||</span> <span>scnt</span><span>[</span><span>n</span><span>]</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"%s"</span><span>,</span> <span>cmd</span><span>[</span><span>n</span><span>])</span>
        <span>system</span><span>(</span><span>cmd</span><span>[</span><span>n</span><span>])</span>  <span># execute cmd associated with n</span>
        <span>ages</span><span>()</span>          <span># recompute all ages</span>
        <span>age</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>0</span>      <span># make n very new</span>
        <span>return</span> <span>1</span>
    <span>}</span>
    <span>return</span> <span>0</span>
<span>}</span>

<span>function</span> <span>error</span><span>(</span><span>s</span><span>)</span> <span>{</span> <span>print</span> <span>"error: "</span> <span>s</span><span>;</span> <span>exit</span> <span>}</span>
</code></pre></div>
</details>

<h2 id="how-it-works">How it works</h2>

<p>There’s an explanation of how the program works in the book, but I’ll explain it in my own words here, focussing on the aspects I find interesting.</p>

<p>The <code>BEGIN</code> block is the main entry point for a program like this. Unlike most AWK programs which implicitly read lines from standard input, this one uses an explicit loop with <code>getline</code> to read the <code>makefile</code>:</p>

<div><pre><code><span>BEGIN</span> <span>{</span>
    <span>while</span> <span>(</span><span>getline</span> <span>&lt;</span><span>"makefile"</span> <span>&gt;</span> <span>0</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>$0</span> <span>~</span> <span>/^</span><span>[</span><span>A-Za-z</span><span>]</span><span>/</span><span>)</span> <span>{</span>  <span>#  $1: $2 $3 ...</span>
            <span>sub</span><span>(</span><span>/:/</span><span>,</span> <span>""</span><span>)</span>
            <span>if</span> <span>(</span><span>++</span><span>names</span><span>[</span><span>nm</span> <span>=</span> <span>$1</span><span>]</span> <span>&gt;</span> <span>1</span><span>)</span>
                <span>error</span><span>(</span><span>nm</span> <span>" is multiply defined"</span><span>)</span>
            <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>2</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>NF</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span># remember targets</span>
                <span>slist</span><span>[</span><span>nm</span><span>,</span> <span>++</span><span>scnt</span><span>[</span><span>nm</span><span>]]</span> <span>=</span> <span>$i</span>
        <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>$0</span> <span>~</span> <span>/^</span><span>\t</span><span>/</span><span>)</span> <span>{</span>      <span># remember cmd for</span>
            <span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>=</span> <span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>$0</span> <span>"\n"</span> <span>#   current name</span>
        <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>NF</span> <span>&gt;</span> <span>0</span><span>)</span> <span>{</span>
            <span>error</span><span>(</span><span>"illegal line in makefile: "</span> <span>$0</span><span>)</span>
        <span>}</span>
    <span>}</span>
    <span>...</span>
<span>}</span>
</code></pre></div>

<p>The <code>getline &lt;filename</code> is a redirect clause that opens <code>makefile</code> (the first time) and reads it line-by-line until the end. If the line (<code>$0</code>) starts with a letter (<code>/^[A-Za-z]/</code>), it’s considered a <code>name: targets</code> rule.</p>

<p>The <code>sub(/:/, "")</code> call removes the colon from the current line (the <code>$0</code> is implicit in the two-argument form of <code>sub</code>).</p>

<p>We then ensure that this rule hasn’t already been defined by checking the <code>names</code> array. An AWK array is actually an <em>associative array</em>, an old-school term for a key-value map.</p>

<p>The inner <code>for</code> loop adds each target (or dependency) to the <code>slist</code> / <code>scnt</code> data structure. This is really a map of lists, but it’s flattened to work around the fact that AWK doesn’t support nested collections. The body of the loop is very terse:</p>

<div><pre><code><span>for</span> <span>(</span><span>i</span> <span>=</span> <span>2</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>NF</span><span>;</span> <span>i</span><span>++</span><span>)</span>
    <span>slist</span><span>[</span><span>nm</span><span>,</span> <span>++</span><span>scnt</span><span>[</span><span>nm</span><span>]]</span> <span>=</span> <span>$i</span>
</code></pre></div>

<p>This loops through each dependency: every field <code>$i</code> from field 2 to <code>NF</code> (the number of fields in the line).</p>

<p>For each dependency, it increments <code>scnt[nm]</code>, the count of sources for the current rule (<code>nm</code>). Then, store the dependency <code>$i</code> in <code>slist</code>, indexed by the multi-key name and count. AWK simulates multi-dimensional or multi-key arrays by creating a concatenated key where each key is separated by the <code>SUBSEP</code> separator (which defaults to <code>"\x1c"</code>).</p>

<p>After the loop, in the <code>prog</code> example we’d end up with <code>slist</code> and <code>scnt</code> looking like this:</p>

<div><pre><code>slist
    a.o,1:  prog.h
    a.o,2:  a.c
    b.o,1:  prog.h
    b.o,2:  b.c
    c.c,1:  c.y
    c.o,1:  c.c
    prog,1: a.o
    prog,2: b.o
    prog,3: c.o

scnt
    a.o:  2
    b.o:  2
    c.c:  1
    c.o:  1
    prog: 3
</code></pre></div>

<p>Coming back up, if the line starts with a tab, it’s a command, so we append it to the name’s command string:</p>

<div><pre><code><span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>=</span> <span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>$0</span> <span>"\n"</span>
</code></pre></div>

<p>Otherwise, if the line is not a blank line (<code>NF &gt; 0</code>), it’s a <code>makefile</code> error.</p>

<p>Finally, after reading the <code>makefile</code> in the <code>while</code> loop, we uses <code>ages()</code> to compute the ages of all files in the current directory, and then call <code>update(ARGV[1])</code> to update the rule passed on the command line:</p>

<div><pre><code><span>BEGIN</span> <span>{</span>
    <span>...</span>
    <span>ages</span><span>()</span>      <span># compute initial ages</span>

    <span>if</span> <span>(</span><span>ARGV</span><span>[</span><span>1</span><span>]</span> <span>in</span> <span>names</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>update</span><span>(</span><span>ARGV</span><span>[</span><span>1</span><span>])</span> <span>==</span> <span>0</span><span>)</span>
            <span>print</span> <span>ARGV</span><span>[</span><span>1</span><span>]</span> <span>" is up to date"</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>error</span><span>(</span><span>ARGV</span><span>[</span><span>1</span><span>]</span> <span>" is not in makefile"</span><span>)</span>
    <span>}</span>
<span>}</span>
</code></pre></div>

<p>The <code>ages</code> function is where things start to get interesting:</p>

<div><pre><code><span>function</span> <span>ages</span><span>(</span>      <span>f</span><span>,</span><span>n</span><span>,</span><span>t</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>t</span> <span>=</span> <span>1</span><span>;</span> <span>(</span><span>"ls -t"</span> <span>|</span> <span>getline</span> <span>f</span><span>)</span> <span>&gt;</span> <span>0</span><span>;</span> <span>t</span><span>++</span><span>)</span>
        <span>age</span><span>[</span><span>f</span><span>]</span> <span>=</span> <span>t</span>         <span># all existing files get an age</span>
    <span>close</span><span>(</span><span>"ls -t"</span><span>)</span>

    <span>for</span> <span>(</span><span>n</span> <span>in</span> <span>names</span><span>)</span>
        <span>if</span> <span>(</span><span>!</span><span>(</span><span>n</span> <span>in</span> <span>age</span><span>))</span>   <span># if n has not been created</span>
            <span>age</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>9999</span>  <span># make n really old</span>
<span>}</span>
</code></pre></div>

<p>The parameter names <code>f</code>, <code>n</code>, and <code>t</code> are prefixed with a bunch of spaces to show they’re actually local variables, and not expected as arguments. This is an AWK quirk (which Kernighan regrets): the only way to define local variables is as function parameters, and if a function is called with fewer arguments than it has parameters, the extras take on the default value (0 for numbers, <code>""</code> for strings). So you’ll see these extra spaces a lot in AWK function definitions.</p>

<p>The next thing is quite neat: AWK supports shell-like <code>|</code> syntax to pipe the output of a program, one <code>getline</code> at a time, to a variable (in this case <code>f</code>). The <code>ls -t</code> command lists files in the current directory ordered by modification time, newest first.</p>

<p>After the loop that’s assigned each file’s age to <code>age[f]</code>, we call <code>close</code> to close the <code>ls -t</code> pipe and avoid too many open file handles.</p>

<p>Finally, we loop through the rule names and assign an arbitrary large number to <code>age[n]</code> to pretend that files that haven’t been created are really old and need to be updated.</p>

<p>Next is the recursive <code>update</code> function, where the meat of the algorithm lives:</p>

<div><pre><code><span>function</span> <span>update</span><span>(</span><span>n</span><span>,</span>   <span>changed</span><span>,</span><span>i</span><span>,</span><span>s</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span><span>(</span><span>n</span> <span>in</span> <span>age</span><span>))</span>
        <span>error</span><span>(</span><span>n</span> <span>" does not exist"</span><span>)</span>
    <span>if</span> <span>(</span><span>!</span><span>(</span><span>n</span> <span>in</span> <span>names</span><span>))</span>
        <span>return</span> <span>0</span>
    <span>changed</span> <span>=</span> <span>0</span>
    <span>visited</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>1</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>scnt</span><span>[</span><span>n</span><span>];</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>visited</span><span>[</span><span>s</span> <span>=</span> <span>slist</span><span>[</span><span>n</span><span>,</span> <span>i</span><span>]]</span> <span>==</span> <span>0</span><span>)</span>
            <span>update</span><span>(</span><span>s</span><span>)</span>
        <span>else</span> <span>if</span> <span>(</span><span>visited</span><span>[</span><span>s</span><span>]</span> <span>==</span> <span>1</span><span>)</span>
            <span>error</span><span>(</span><span>s</span> <span>" and "</span> <span>n</span> <span>" are circularly defined"</span><span>)</span>
        <span>if</span> <span>(</span><span>age</span><span>[</span><span>s</span><span>]</span> <span>&lt;=</span> <span>age</span><span>[</span><span>n</span><span>])</span>
            <span>changed</span><span>++</span>
    <span>}</span>
    <span>visited</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>2</span>
    <span>if</span> <span>(</span><span>changed</span> <span>||</span> <span>scnt</span><span>[</span><span>n</span><span>]</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"%s"</span><span>,</span> <span>cmd</span><span>[</span><span>n</span><span>])</span>
        <span>system</span><span>(</span><span>cmd</span><span>[</span><span>n</span><span>])</span>  <span># execute cmd associated with n</span>
        <span>ages</span><span>()</span>          <span># recompute all ages</span>
        <span>age</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>0</span>      <span># make n very new</span>
        <span>return</span> <span>1</span>
    <span>}</span>
    <span>return</span> <span>0</span>
<span>}</span>
</code></pre></div>

<p>Once again you’ll note the parameter list: <code>n</code> is an expected argument (the name to update), and <code>changed,i,s</code> are the locals.</p>

<p>After initial checks, we loop through the list of dependencies by iterating from <code>slist[n, 1]</code> to <code>slist[n, scnt[n]]</code>. If we haven’t visited this dependency yet, we perform a depth-first traversal of the dependency graph by recursively calling <code>update</code> to see if we need to update that dependency first:</p>

<div><pre><code><span>if</span> <span>(</span><span>visited</span><span>[</span><span>s</span> <span>=</span> <span>slist</span><span>[</span><span>n</span><span>,</span> <span>i</span><span>]]</span> <span>==</span> <span>0</span><span>)</span>
    <span>update</span><span>(</span><span>s</span><span>)</span>
</code></pre></div>

<p>The recursion is terminated by the <code>if (!(n in names)) return 0</code> block near the top. We stop when the file being updated isn’t in the list of rule names – which is a leaf node in the dependency graph.</p>

<p>The block <code>if (age[s] &lt;= age[n]) changed++</code> increments the <code>changed</code> count if any dependency is newer than the age of the current file being updated.</p>

<p>After the traversal loop, if any of the dependencies or sub-dependencies had changed, we run the associated command using <code>system()</code>, recompute the ages of all files, and <code>return 1</code> to the caller to indicate we did make an update.</p>

<p>The <code>scnt[n] == 0</code> clause handles the case where the rule being updated doesn’t have any dependencies specified, like the <code>print</code> rule in the example. In that case, always re-run its command.</p>

<p>And there you have it! A minimalist Make in one page of AWK.</p>

<h2 id="python-version">Python version</h2>

<p>For interest, I ported the book’s AWK Make to Python, and have included it below. Once again, click the bold text to expand the program.</p>

<details>
  <summary><strong>My Python port of the Make program (full source code).</strong></summary>

  <div><pre><code><span>import</span> <span>os</span><span>,</span> <span>re</span><span>,</span> <span>sys</span>

<span>slist</span> <span>=</span> <span>{}</span>  <span># slist[name] is list of rule's sources
</span><span>cmd</span> <span>=</span> <span>{}</span>    <span># cmd[name] is shell command to run for rule
</span>
<span>def</span> <span>main</span><span>():</span>
    <span>for</span> <span>line</span> <span>in</span> <span>open</span><span>(</span><span>'makefile'</span><span>):</span>
        <span>if</span> <span>re</span><span>.</span><span>match</span><span>(</span><span>'[A-Za-z]'</span><span>,</span> <span>line</span><span>):</span>
            <span>line</span> <span>=</span> <span>line</span><span>.</span><span>replace</span><span>(</span><span>':'</span><span>,</span> <span>''</span><span>)</span>
            <span>fields</span> <span>=</span> <span>line</span><span>.</span><span>split</span><span>()</span>
            <span>nm</span> <span>=</span> <span>fields</span><span>[</span><span>0</span><span>]</span>
            <span>if</span> <span>nm</span> <span>in</span> <span>slist</span><span>:</span>
                <span>error</span><span>(</span><span>f</span><span>'</span><span>{</span><span>nm</span><span>}</span><span> is multiply defined'</span><span>)</span>
            <span>slist</span><span>[</span><span>nm</span><span>]</span> <span>=</span> <span>fields</span><span>[</span><span>1</span><span>:]</span>    <span># remember targets
</span>        <span>elif</span> <span>line</span><span>.</span><span>startswith</span><span>(</span><span>'</span><span>\t</span><span>'</span><span>):</span>   <span># remember cmd for current name
</span>            <span>cmd</span><span>[</span><span>nm</span><span>]</span> <span>=</span> <span>cmd</span><span>.</span><span>get</span><span>(</span><span>nm</span><span>,</span> <span>''</span><span>)</span> <span>+</span> <span>line</span>
        <span>elif</span> <span>line</span><span>.</span><span>strip</span><span>():</span>
            <span>error</span><span>(</span><span>f</span><span>'illegal line in makefile: </span><span>{</span><span>line</span><span>}</span><span>'</span><span>)</span>
    <span>if</span> <span>sys</span><span>.</span><span>argv</span><span>[</span><span>1</span><span>]</span> <span>in</span> <span>slist</span><span>:</span>
        <span>if</span> <span>not</span> <span>update</span><span>(</span><span>sys</span><span>.</span><span>argv</span><span>[</span><span>1</span><span>]):</span>
            <span>print</span><span>(</span><span>sys</span><span>.</span><span>argv</span><span>[</span><span>1</span><span>],</span> <span>'is up to date'</span><span>)</span>
    <span>else</span><span>:</span>
        <span>error</span><span>(</span><span>f</span><span>'</span><span>{</span><span>sys</span><span>.</span><span>argv</span><span>[</span><span>1</span><span>]</span><span>}</span><span> is not in makefile'</span><span>)</span>

<span>def</span> <span>mtime</span><span>(</span><span>n</span><span>):</span>
    <span>try</span><span>:</span>
        <span>return</span> <span>os</span><span>.</span><span>stat</span><span>(</span><span>n</span><span>).</span><span>st_mtime</span>
    <span>except</span> <span>FileNotFoundError</span><span>:</span>
        <span>return</span> <span>0</span>  <span># mark as old if it doesn't exist
</span>
<span>def</span> <span>update</span><span>(</span><span>n</span><span>,</span> <span>visited</span><span>=</span><span>{}):</span>
    <span>ntime</span> <span>=</span> <span>mtime</span><span>(</span><span>n</span><span>)</span>
    <span>if</span> <span>n</span> <span>not</span> <span>in</span> <span>slist</span> <span>and</span> <span>ntime</span> <span>==</span> <span>0</span><span>:</span>
        <span>error</span><span>(</span><span>f</span><span>'</span><span>{</span><span>n</span><span>}</span><span> does not exist'</span><span>)</span>
    <span>if</span> <span>n</span> <span>not</span> <span>in</span> <span>slist</span><span>:</span>
        <span>return</span> <span>0</span>
    <span>changed</span> <span>=</span> <span>False</span>
    <span>visited</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>1</span>
    <span>for</span> <span>s</span> <span>in</span> <span>slist</span><span>.</span><span>get</span><span>(</span><span>n</span><span>,</span> <span>[]):</span>
        <span>if</span> <span>s</span> <span>not</span> <span>in</span> <span>visited</span><span>:</span>
            <span>update</span><span>(</span><span>s</span><span>)</span>
        <span>elif</span> <span>visited</span><span>[</span><span>s</span><span>]</span> <span>==</span> <span>1</span><span>:</span>
            <span>error</span><span>(</span><span>f</span><span>'</span><span>{</span><span>s</span><span>}</span><span> and </span><span>{</span><span>n</span><span>}</span><span> are circularly defined'</span><span>)</span>
        <span>if</span> <span>mtime</span><span>(</span><span>s</span><span>)</span> <span>&gt;</span> <span>ntime</span><span>:</span>
            <span>changed</span> <span>=</span> <span>True</span>
    <span>visited</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>2</span>
    <span>if</span> <span>changed</span> <span>or</span> <span>len</span><span>(</span><span>slist</span><span>.</span><span>get</span><span>(</span><span>n</span><span>,</span> <span>[]))</span> <span>==</span> <span>0</span><span>:</span>
        <span>print</span><span>(</span><span>cmd</span><span>[</span><span>n</span><span>],</span> <span>end</span><span>=</span><span>''</span><span>)</span>
        <span>os</span><span>.</span><span>system</span><span>(</span><span>cmd</span><span>[</span><span>n</span><span>])</span>  <span># execute cmd associated with n
</span>        <span>return</span> <span>1</span>
    <span>return</span> <span>0</span>

<span>def</span> <span>error</span><span>(</span><span>msg</span><span>):</span>
    <span>print</span><span>(</span><span>'error:'</span><span>,</span> <span>msg</span><span>,</span> <span>file</span><span>=</span><span>sys</span><span>.</span><span>stderr</span><span>)</span>
    <span>sys</span><span>.</span><span>exit</span><span>(</span><span>1</span><span>)</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>
    <span>main</span><span>()</span>
</code></pre></div>
</details>

<p>It’s very similar in structure to the original AWK version, though I made two simplifications which I think make it somewhat easier to understand:</p>

<ol>
  <li>Simpler data structures to avoid the <code>slist</code> / <code>scnt</code> quirkiness – in Python we can just use a dictionary of lists. (<a href="https://github.com/benhoyt/awkmake/commit/490e5d210bdd4a7ce61292c73f1ec3f06da090eb">See diff.</a>)</li>
  <li>Determine ages more directly using <code>os.stat()</code> to fetch file modification times (mtimes), rather than using the <code>ls -t</code> trick. This also removes the need for the <code>age</code> map and the <code>ages</code> function. (<a href="https://github.com/benhoyt/awkmake/commit/7bb6a6de06a329551678fb90073a268342baf049">See diff.</a>)</li>
</ol>

<p>I didn’t plan for this, but even if you include the <code>import</code> line and the <code>if __name__ == '__main__'</code> dance, it’s 58 lines of code – basically the same length as the AWK program.</p>

<p>When making the Python version, I realized we could simplify the AWK version in a similar way:</p>

<ol>
  <li>It’s conceptually simpler to store the <code>slist</code> directly as an AWK array: a key-value map where the key is the rule name and the value is the list of dependencies as a space-separated string (just like in the <code>makefile</code>). We can use <code>split</code> as needed to turn the dependencies string into a list (an array from 1 to the number of dependencies). This avoids the need for <code>scnt</code> and <code>names</code> altogether. (<a href="https://github.com/benhoyt/awkmake/pull/2/commits/45b5c4de5ec4c5b09830fdf06b00f4e0c7f7886e">See diff.</a>)</li>
  <li>Similar to the Python version, we can get the mtime directly by shelling out to <code>stat</code>, instead of listing all files in age order with <code>ls -t</code>. I’ve used <code>stat --format %y</code> to do this. I believe this is a GNU extension, so it’s not as portable as <code>ls -t</code>, but it’s simpler and avoids the need for recomputing the <code>age</code> array. (<a href="https://github.com/benhoyt/awkmake/pull/2/commits/d5cd8cc3cdeebce953dc2b15c9fedca3eef5ceca">See diff.</a>)</li>
</ol>

<p>For what it’s worth, the modified version is four lines shorter than the original. I think the simpler <code>slist</code> is clearer, and I like the more direct approach to fetching mtimes, though I realize the lack of portability of <code>stat --format</code> is a downside (macOS’s <code>stat</code> looks <a href="https://ss64.com/osx/stat.html">quite different</a>).</p>

<h2 id="conclusion">Conclusion</h2>

<p>The AWK Make program is a neat little piece of code that shows how useful a language AWK is, even for medium-sized scripts.</p>

<p>However, Python is definitely a nicer language for this kind of thing: it has much richer data types, better tools like <code>os.stat</code>, and local variables without quirky syntax.</p>

<p>I consider AWK amazing, but I think it should remain where it excels: for exploratory data analysis and for one-liner data extraction scripts.</p>

<p>As the author of GoAWK, which has had native CSV support for a while, I’m especially pleased to see both Kernighan’s “one true AWK” and Gawk gain proper CSV support in the form of the <code>--csv</code> option. Kernighan’s <a href="https://github.com/onetrueawk/awk/commit/c76017e59eb71b5403d44fb974a83bf71462eb39#diff-b335630551682c19a781afebcf4d07bf978fb1f8ac04c6bf87428ed5106870f5">AWK updates</a> will be merged soon, and Gawk will <a href="http://git.savannah.gnu.org/cgit/gawk.git/tree/NEWS">include this feature in version 5.3.0</a>, which is coming out soon.</p>

<p>You can also view my <a href="https://github.com/benhoyt/awkmake">awkmake</a> repo on GitHub, which contains the full source for both the AWK book’s Make program and my Python version, as well as a runnable example project based on the example in the AWK book.</p>

<p>I’d love it if you <a href="https://github.com/sponsors/benhoyt/">sponsored me on GitHub</a> – it will motivate me to work on my open source projects and write more good content. Thanks!</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RISC-V SBI and the full boot process (109 pts)]]></title>
            <link>https://popovicu.com/posts/risc-v-sbi-and-full-boot-process/</link>
            <guid>37460614</guid>
            <pubDate>Sun, 10 Sep 2023 22:10:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://popovicu.com/posts/risc-v-sbi-and-full-boot-process/">https://popovicu.com/posts/risc-v-sbi-and-full-boot-process/</a>, See on <a href="https://news.ycombinator.com/item?id=37460614">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article" role="article">
      <p>In the last article, we covered <a href="https://popovicu.com/posts/bare-metal-programming-risc-v">bare metal programming on RISC-V</a>. Please familiarize yourself with that material before proceeding with the rest of this article, as this article is a direct continuation of the aforementioned one.</p>
<p>This time we are talking about RISC-V <strong>SBI (Supervisor Binary Interface)</strong>, with <strong>OpenSBI</strong> as the example. We’ll look at how SBI can assist us with implementing operating system kernel primitives and we’ll end the article with a practical example using <code>riscv64 virt</code> machine.</p>
<h2 id="table-of-contents">Table of contents</h2>
<details><summary>Open Table of contents</summary>
<ul>
<li>
<p><a href="#risc-v-and-bios">RISC-V and “BIOS”</a></p>
<ul>
<li><a href="#machine-modes">Machine modes</a></li>
<li><a href="#sbi">SBI</a></li>
<li><a href="#fancy-abstractions">Fancy abstractions</a></li>
<li><a href="#binary-interface">Binary interface</a></li>
</ul>
</li>
<li>
<p><a href="#practical-example-with-opensbi">Practical example with OpenSBI</a></p>
</li>
<li>
<p><a href="#booting-the-os-kernel-after-sbi-and-calling-into-opensbi">Booting the OS kernel after SBI and calling into OpenSBI</a></p>
<ul>
<li>
<p><a href="#what-really-happens-in-the-zsbl">What really happens in the ZSBL?</a></p>
</li>
<li>
<p><a href="#3-flavors-of-opensbi">3 flavors of OpenSBI</a></p>
<ul>
<li><a href="#fw_payload"><code>FW_PAYLOAD</code></a></li>
<li><a href="#fw_jump"><code>FW_JUMP</code></a></li>
<li><a href="#fw_dynamic"><code>FW_DYNAMIC</code></a></li>
<li><a href="#exploring-the-fw_dynamic_info-struct">Exploring the <code>fw_dynamic_info</code> struct</a></li>
<li><a href="#building-an-infinite-loop-fake-kernel">Building an “infinite-loop fake kernel”</a></li>
<li><a href="#intentionally-skipped-details">Intentionally skipped details</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#hello-world-fake-kernel">Hello world fake kernel</a></p>
</li>
<li>
<p><a href="#conclusion">Conclusion</a></p>
</li>
<li>
<p><a href="#code-pointers">Code pointers</a></p>
</li>
</ul>
</details>
<h2 id="risc-v-and-bios">RISC-V and “BIOS”</h2>
<p>In the article mentioned above, we talked extensively about the very first stages of the RISC-V bootup process. We mentioned that first the ZSBL (Zero Stage Bootloader) runs, initializes a few registers and jumps directly to some address hardcoded by ZSBL. In the case of QEMU’s <code>riscv64 virt</code>, the hardcoded address is <code>0x80000000</code>. This is where the first user-provided code runs, and if left to default, QEMU will load <code>OpenSBI</code> there.</p>
<h3 id="machine-modes">Machine modes</h3>
<p>So far we have avoided talking about different machine modes, and now is the perfect time to introduce them. The concept with machines modes is that not every piece of software should be able to access just about any memory address on the machine, or even execute just about any instructions available with the CPU. Traditionally, in a textbook example, the two main divisions are made here:</p>
<ol>
<li>Privileged mode</li>
<li>Unprivileged mode</li>
</ol>
<p>The <em>privileged mode</em> is where the machine starts at the boot time. Any instruction is permitted and no address access is considered an access violation. Once the operating system takes over the control of the system and starts launching the user code (aka userspace code), the modes start switching. When the user code is running on the CPU core, it is running within the <em>unprivileged mode</em> where not everything is accessible. Going back to the kernel mode means switching back to the privilged mode.</p>
<p>This is a very textbook and simplistic view at the permissions of operations and the question arises: why only 2 modes?</p>
<p>In systems, more than 2 modes typically exist, forming a <a href="https://en.wikipedia.org/wiki/Protection_ring">protection ring</a> with multiple access modes. RISC-V specification does not necessarily prescribe exactly which modes must be implemented for a core, except the <strong>M (Machine)</strong> mode. This is the most privileged mode.</p>
<p>Typically, the processors with M mode only are simple embedded systems, moving over more secure systems (M and S modes), all the way to full systems that can run Unix-like operating systems (M, S and U modes).</p>
<h3 id="sbi">SBI</h3>
<p>The <a href="https://github.com/riscv-non-isa/riscv-sbi-doc">official docs</a> provide a formal definition, and I will try to water it down here with the goals of making it more intuitive.</p>
<p>RISC-V’s SBI spec defines the layer of software that sits at the bottom of the RISC-V software stack. This is very similar to BIOS, which is traditionally the first bit of software that runs on a machine. You might have seen some of the guides for developing a simple kernel from scratch, and they typically involve something similar to what we did in the <a href="https://popovicu.com/posts/bare-metal-programming-risc-v">initial guide</a> for bare metal programming on RISC-V, with a small twist — they are very often actually depending on the pre-existing software to do some I/O. The similarity to our previous guide is that they also carefully align the first instructions to the correct address to ensure that the processor’s execution flow goes as intended and the simple kernel takes over at the right time, however, what I have typically observed in those short guides is that the goal is typically to print something like ‘Hello world’ to <strong>the VGA screen</strong>. This last bit sounds like a fairly complex operation, and it really is.</p>
<p>How is printing to the VGA then done easily then? The answer is that BIOS is here to assist with the most basic I/O operations such as printing some characters to the screen, hence its name — <strong>B</strong>asic <strong>I</strong>nput <strong>O</strong>utput <strong>S</strong>ystem! Please pay attention to the opening section of the bare metal programming guide: we were achieving interaction with the user <em>without</em> depending on <em>any</em> existing software on the machine (well, almost true, we still went through the Zero Stage Bootloader, but we didn’t depend on any outcome from it, nor we really had any control over it; it’s simply hardcoded into the system). If we were to print something on the VGA screen, instead of sending characters out through UART, we would have to do a lot more than send an ASCII code to a single address. VGA involves setting up the display device into the right mode, by sending multiple values over, setting up different parameters, etc. It’s a fairly ellaborate operation.</p>
<p>So how does BIOS traditionally help with tasks like these? The main concept is that whatever operating system ends up installed on the machine, it would anyway need some basic functionality, such as printing some information to the VGA screen. Thus, the machine can have these standard operations simply baked into it and ready to consume by whatever operating system ends up on the machine. Conceptually, we can think of these procedures as an everyday library we write our applications against.</p>
<p>Additionally, if an operating system is written against such a “library”, it automatically becomes more portable. The “library” should have all the low level details, such as “outputting to UART means writing to <code>0x10000000</code>” (as is the case with QEMU’s <code>riscv64 virt</code> VM), vs. “outputting to UART means writing to <code>0x12345678</code>”, and the operating system simply needs to invoke “outputting to UART” procedure, while this “library” will know exactly how to interact with the hardware.</p>
<h3 id="fancy-abstractions">Fancy abstractions</h3>
<p>This is all just a lot of talk for a very simple concept we have been using in programming since day 1: we apply <strong>layers of abstractions</strong> in our coding. Think of something like a Python function that does something like “sending a local file to an email address”. From a high level perspective, we simply call a function <code>send_file_to_email(file, email)</code> and the underlying library opens up the network connection and starts pumping the bytes. This could be just another Python library. At some point, that will likely move down the software stack, and the Python library will depend on the Python runtime written in something like C to make a system call to the operating system (for example, to perform a core operation such as opening a network socket). The operating system has a network driver somewhere deep down, which knows to which address in the address space does it need to send the individual bytes in order to send the bytes over the wire to the network and so on. The main concept here is that we have an established way of hiding the complexity of operations by delegating them to the lower layers of the software stack. We built the larger system not from the atomic parts, but out of “molecules”.</p>
<p>If we’re delegating the complexity to the underlying library, it probably just means a function call. However, once it’s time to delegate the complexity to the operating system and lower, this happens through a <strong>binary interface</strong>.</p>
<h3 id="binary-interface">Binary interface</h3>
<p>Since basically forever, the <code>x86</code> has been the dominant architecture for the computers we use, be it desktops or laptops. Things have been changing a lot lately, and other architectures are entering the picture, but let’s focus on just <code>x86</code>. What then, makes an application built for Linux incompatible with the application for Windows? If it’s written for <code>x86</code>, and both Linux and Windows run on <code>x86</code>, what could possibly be the differentiator here? The CPU instructions are not different from one platform and the other, so what could it be? The answer is the <strong>interface between the application and the operating system</strong>. This particular link between the user software and the operating system is called the <strong>application binary interface (ABI)</strong>. ABI is just a definition that says how the services from the operating system are invoked from the user application.</p>
<p>Therefore, when we say something like “this software is written for platform X”, it’s not enough to just say that X is <code>x86</code> or <code>RISC-V</code>, we must say <code>x86/Linux</code> or <code>x86/Windows</code> or <code>RISC-V Linux</code> etc. The platform definition may be even more complex than that if things like dynamic linking are involved, but let us not go there for now.</p>
<p>Let’s take a quick example at a program written in assembly for <code>x86/Linux</code> that just prints a ‘Hello’ string to the standard output.</p>
<pre is:raw="" tabindex="0"><code><span><span>.global _start</span></span>
<span></span>
<span><span>.</span><span>section .text</span></span>
<span></span>
<span><span>_start:</span><span> </span><span>mov</span><span> </span><span>$4</span><span>, %</span><span>eax</span><span> </span><span>; 4 is the code for the 'write' system call</span></span>
<span><span>        </span><span>mov</span><span> </span><span>$1</span><span>, %</span><span>ebx</span><span> </span><span>; We are writing to file 1, i.e. the 'standard output'</span></span>
<span><span>        </span><span>mov</span><span> </span><span>$message</span><span>, %</span><span>ecx</span><span> </span><span>; The data we want to print is at the address defined by the symbol message</span></span>
<span><span>        </span><span>mov</span><span> </span><span>$5</span><span>, %</span><span>edx</span><span> </span><span>; The length of the data we want to print is 5</span></span>
<span><span>        </span><span>int</span><span> </span><span>$0x80</span><span> </span><span>; Invoke the system call, i.e. ask kernel to print the data to the standard output</span></span>
<span></span>
<span><span>        </span><span>mov</span><span> </span><span>$1</span><span>, %</span><span>eax</span><span> </span><span>; 1 is the code for the 'exit' system call</span></span>
<span><span>        </span><span>mov</span><span> </span><span>$0</span><span>, %</span><span>ebx</span><span> </span><span>; 0 is the process return code</span></span>
<span><span>        </span><span>int</span><span> </span><span>$0x80</span><span>  </span><span>; Invoke the system call, i.e. ask the the kernel to close this process</span></span>
<span></span>
<span><span>.</span><span>section .data</span></span>
<span><span>message:</span><span> .ascii "Hello"</span></span></code></pre>
<p>Assemble this program with:</p>
<pre is:raw="" tabindex="0"><code><span><span>as -o syscall.o syscall.s</span></span></code></pre>
<p>Link it with:</p>
<pre is:raw="" tabindex="0"><code><span><span>ld -o syscall syscall.o</span></span></code></pre>
<p>Run with:</p>
<pre is:raw="" tabindex="0"><code><span><span>./syscall</span></span></code></pre>
<p>You should see the output “Hello”. If you’re on Bash and you also want to double check the process return code, simply run:</p>
<pre is:raw="" tabindex="0"><code><span><span>echo $?</span></span></code></pre>
<p>And you should see <code>0</code>.</p>
<p><em>Tip: If you want to try out this example from above, but you do not have access to an x86/Linux machine, you can do this through a JavaScript VM that emulates an x86 system in-browser <a href="https://bellard.org/jslinux/">here</a>; that’s a really cool website!</em></p>
<p>And there we have it: a program which prints a message to the standard output when run on an <code>x86</code> machine with a Linux kernel. C standard library <strong>was not used</strong>. The final <code>ELF</code> binary should run on Linux with no dependencies other than it is run on the correct platform.</p>
<p>Now back to the question, what makes this binary incompatible with Windows (potentially)? <strong>Another operating system encodes the system calls differently (e.g. writing isn’t code 4, but code 123, or the parameters are passed through different CPU registers).</strong> And now you have a good idea of how to directly interface with the kernel, without the assistance of the standard library (although you probably almost never want to do it). This means you have uncovered the layer at which software does things like opening files, allocates memory, sends signals, etc. The C standard library can be thought of as a wrapper which hides this complexity of invoking software interrupts through the <code>int</code> instruction to communicate with the kernel, and instead makes it look like a normal call to a C function, and then under the hood, this is what it is. To be fair, the library does a lot more than that, but for the purposes of this article, it can be thought of simply as a wrapper.</p>
<p>And now in the RISC-V world, we have the same thing: the user application interfaces with the kernel through software interrupt CPU instructions, and passing the parameters through the CPU registers. And the kernel basically does <strong>the same thing</strong> with the SBI in order to invoke its services! It’s just that this final layer of logic invocation is called the <strong>SBI</strong>, not the <strong>ABI</strong>. A way to think about it is that it is not the <strong>application</strong> that works in the lower layer, but rather the <strong>supervisor</strong> of the applications. The difference, however, is in the name only, and the concept remains absolutely the same.</p>
<h2 id="practical-example-with-opensbi">Practical example with OpenSBI</h2>
<p>At this point we have established that SBI, much like ABI, is just a way of invoking a functionality in the lower layers of the software stack. Furthermore, we also established the SBI sits at the bottom of the software stack on a RISC-V machine, and runs in the most privileged M mode. Let’s add some more details to this picture.</p>
<p>It should also make sense at this point why the QEMU developers chose the <code>-bios</code> flag in order to accept the SBI software image (because the functionality is basically the same as BIOS). As a reminder, the <code>-bios</code> flag should point to an <code>ELF</code> file that will lay out the SBI software out in memory starting from address <code>0x80000000</code>.</p>
<p>Let’s start the QEMU’s VM with just OpenSBI loaded, and see what happens. We shouldn’t really have to pass anything to QEMU since it defaults to loading OpenSBI at <code>0x80000000</code>.</p>
<pre is:raw="" tabindex="0"><code><span><span>qemu-system-riscv64 -machine virt</span></span></code></pre>
<p>This is the output (on the serial port, not VGA):</p>
<pre is:raw="" tabindex="0"><code><span><span>OpenSBI v0.8</span></span>
<span><span>   ____                    _____ ____ _____</span></span>
<span><span>  / __ \                  / ____|  _ \_   _|</span></span>
<span><span> | |  | |_ __   ___ _ __ | (___ | |_) || |</span></span>
<span><span> | |  | | '_ \ / _ \ '_ \ \___ \|  _ &lt; | |</span></span>
<span><span> | |__| | |_) |  __/ | | |____) | |_) || |_</span></span>
<span><span>  \____/| .__/ \___|_| |_|_____/|____/_____|</span></span>
<span><span>        | |</span></span>
<span><span>        |_|</span></span>
<span><span></span></span>
<span><span>Platform Name       : riscv-virtio,qemu</span></span>
<span><span>Platform Features   : timer,mfdeleg</span></span>
<span><span>Platform HART Count : 1</span></span>
<span><span>Boot HART ID        : 0</span></span>
<span><span>Boot HART ISA       : rv64imafdcsu</span></span>
<span><span>BOOT HART Features  : pmp,scounteren,mcounteren,time</span></span>
<span><span>BOOT HART PMP Count : 16</span></span>
<span><span>Firmware Base       : 0x80000000</span></span>
<span><span>Firmware Size       : 96 KB</span></span>
<span><span>Runtime SBI Version : 0.2</span></span>
<span><span></span></span>
<span><span>MIDELEG : 0x0000000000000222</span></span>
<span><span>MEDELEG : 0x000000000000b109</span></span>
<span><span>PMP0    : 0x0000000080000000-0x000000008001ffff (A)</span></span>
<span><span>PMP1    : 0x0000000000000000-0xffffffffffffffff (A,R,W,X)</span></span></code></pre>
<p>The machine keeps spinning in place, presumably because it is set up to do so by default since there is no other piece of software passed to QEMU to take over the control after OpenSBI. At this point, things look good, it seems like OpenSBI has been set up properly (and its output confirms that it sits right at <code>0x80000000</code>).</p>
<p>How do we keep going up the software stack, how do we add a new layer? The new layer could be something like an operating system kernel, so similarly to how we have previously built an <code>ELF</code> file containing instructions to be placed at <code>0x80000000</code>, we will build another <code>ELF</code> file for QEMU to load into its memory, but this time the instructions will come to another address, since the portion starting at <code>0x80000000</code> has already been taken over by OpenSBI.</p>
<p>Which address should we load our fake “kernel” at, then?</p>
<h2 id="booting-the-os-kernel-after-sbi-and-calling-into-opensbi">Booting the OS kernel after SBI and calling into OpenSBI</h2>
<p>When we loaded the BIOS/SBI/whatever you want to call it, the address was basically burnt into the machine’s logic. The first few instructions were Zero Stage Bootloader (ZSBL) and the final instruction from there was jumping to the hardcoded address <code>0x80000000</code>. As we previously mentioned, this is an immutable fact of the platform we’re working with, it’s just simply what it does. However, that’s all it really hardcodes at this point: it just hardcodes that you will have to start from <code>0x80000000</code>, and now we have OpenSBI placed there, so where does OpenSBI take us next?</p>
<p>Now enters the importance of the <strong>ZSBL</strong> again and now it really matters how it initializes those registers before performing that hardcoded jump to <code>0x80000000</code>. What ZSBL really does is two things:</p>
<ol>
<li>Ensures that the software running <strong>after</strong> OpenSBI’s initialization can run, and this is basically the OS kernel bootloader, or it could be the kernel itself directly (which is what you typically see in QEMU guides where you launch Linux, bootloader is skipped and the memory is immediately loaded with the kernel).</li>
<li>Jumps to the OpenSBI.</li>
</ol>
<p>We have covered the second point in great detail so far, so let’s now dig deeper into how does it accomplish point #1.</p>
<h3 id="what-really-happens-in-the-zsbl">What really happens in the ZSBL?</h3>
<p>We have mentioned before that ZSBL execution starts at the address <code>0x1000</code>. Let’s trace the execution through QEMU and see what’s going on. To do that, we’ll add 2 flags to the QEMU CLI command: <code>-s</code> and <code>-S</code>. These flags ensure that QEMU exposes a <code>gdb</code> debug port, and additionally, the VM pauses immediately upon creation, waiting for us to drive it manually (which we will do through <code>gdb</code>).</p>
<p>Let’s begin this reverse engineering process. We’re starting QEMU as so:</p>
<pre is:raw="" tabindex="0"><code><span><span>qemu-system-riscv64 -machine virt -s -S</span></span></code></pre>
<p>In another terminal, we connect to the <code>gdb</code> server nested in QEMU, so we can drive the VM forward. I am doing this on an <code>x86</code> machine, so I will use <code>gdb-multiarch</code> so I can do a cross-platform debug for <code>riscv</code>. So in this new terminal, I just run:</p>
<pre is:raw="" tabindex="0"><code><span><span>gdb-multiarch</span></span></code></pre>
<p>I want to set up a few things before I connect into the VM to drive it forward:</p>
<pre is:raw="" tabindex="0"><code><span><span>set architecture riscv:rv64</span></span></code></pre>
<p>It should be obvious what the line above does. Next, I want to get the actual running instruction printed to my terminal each time I move one instruction:</p>
<pre is:raw="" tabindex="0"><code><span><span>set disassemble-next-line on</span></span></code></pre>
<p>It’s time to connect to the QEMU <code>gdb</code> server (port <code>1234</code> is I believe hardcoded by QEMU, though it <em>may</em> be configurable by the <code>-s</code> flag somehow; I never tried it and I don’t think you’ll need to change this behavior)</p>
<pre is:raw="" tabindex="0"><code><span><span>target remote :1234</span></span></code></pre>
<p>And right there, <code>gdb</code> is waiting for us at <code>0x1000</code>, exactly where the very first instruction after power on happens. We will use <code>si</code> a few times to step through instructions one by one, until we get to the jump to SBI at <code>0x80000000</code>.</p>
<pre is:raw="" tabindex="0"><code><span><span>(gdb) target remote:1234</span></span>
<span><span>Remote debugging using :1234</span></span>
<span><span>warning: No executable has been specified and target does not support</span></span>
<span><span>determining executable automatically.  Try using the "file" command.</span></span>
<span><span>0x0000000000001000 in ?? ()</span></span>
<span><span>=&gt; 0x0000000000001000:	97 02 00 00	auipc	t0,0x0</span></span>
<span><span>(gdb) si</span></span>
<span><span>0x0000000000001004 in ?? ()</span></span>
<span><span>=&gt; 0x0000000000001004:	13 86 82 02	addi	a2,t0,40</span></span>
<span><span>(gdb) si</span></span>
<span><span>0x0000000000001008 in ?? ()</span></span>
<span><span>=&gt; 0x0000000000001008:	73 25 40 f1	csrr	a0,mhartid</span></span>
<span><span>(gdb) si</span></span>
<span><span>0x000000000000100c in ?? ()</span></span>
<span><span>=&gt; 0x000000000000100c:	83 b5 02 02	ld	a1,32(t0)</span></span>
<span><span>(gdb) si</span></span>
<span><span>0x0000000000001010 in ?? ()</span></span>
<span><span>=&gt; 0x0000000000001010:	83 b2 82 01	ld	t0,24(t0)</span></span>
<span><span>(gdb) si</span></span>
<span><span>0x0000000000001014 in ?? ()</span></span>
<span><span>=&gt; 0x0000000000001014:	67 80 02 00	jr	t0</span></span>
<span><span>(gdb) si</span></span>
<span><span>0x0000000080000000 in ?? ()</span></span>
<span><span>=&gt; 0x0000000080000000:	33 04 05 00	add	s0,a0,zero</span></span></code></pre>
<p>There were only 6 instructions in ZSBL before handing the control over to the OpenSBI, including the jump itself. However, what are these few instructions that happened, what is their significance?</p>
<p>It turns out that all this is part of the SBI specification too, it’s a part of the boot sequence. However, with OpenSBI, there are 3 different flavors of this dance, and let’s look at those flavors first before getting into a lot of details on what happens after the ZSBL.</p>
<h3 id="3-flavors-of-opensbi">3 flavors of OpenSBI</h3>
<p>You can build OpenSBI in 3 different ways:</p>
<ol>
<li><code>FW_PAYLOAD</code> (<a href="https://github.com/riscv-software-src/opensbi/blob/master/docs/firmware/fw_payload.md">official docs</a>)</li>
<li><code>FW_JUMP</code> (<a href="https://github.com/riscv-software-src/opensbi/blob/master/docs/firmware/fw_jump.md">official docs</a>)</li>
<li><code>FW_DYNAMIC</code> (<a href="https://github.com/riscv-software-src/opensbi/blob/master/docs/firmware/fw_dynamic.md">official docs</a>)</li>
</ol>
<h4 id="fw_payload"><code>FW_PAYLOAD</code></h4>
<p>This one is probably the easiest to understand conceptually. When building this flavor of OpenSBI, you will literally point the <code>make</code> tool to your kernel/“whatever you want to run after OpenSBI” image and you will get a single binary payload that you can directly load wherever you first CPU instructions start from (in QEMU’s VM case, <code>0x80000000</code>). As I understand, it is possible to tweak the exact location of your software in relation to the OpenSBI blob in the memory, but for simplicity, the mental model we can apply here is that OpenSBI and your software blob are spliced together into a single blob and once the OpenSBI initialization finishes, the very next instruction is your software (you basically slide right into your software after OpenSBI).</p>
<p>The way to achieve this is:</p>
<ol>
<li>Make sure <code>FW_PAYLOAD=y</code> is set in the <code>make</code> process, this will ensure a file called <code>fw_payload</code> is generated.</li>
<li>Point <code>FW_PAYLOAD_PATH</code> in your <code>make</code> process to the software you want to run after OpenSBI.</li>
</ol>
<p>Per the docs linked aboved, if you skip the second flag, a very simple piece of software will be spliced with OpenSBI: a blank infinite loop. That explains why when we just launched QEMU with no flags, basically with OpenSBI only, the machine kept spinning in place — OpenSBI was likely built this way (since you can’t just keep executing random contents of the memory) and it was just busy waiting in place.</p>
<p>The upside of this approach is that now you have a single, spliced, monolithic software image to load into your machine. You don’t have to deal with multiple floating pieces, just one monolith. If your build process for the software is straightforward, you may even end up with a really easy way to manage all the software on the target machine, while getting all the upside of having OpenSBI do some work for you.</p>
<p>The downside is that you are now responsible for building everything together, including OpenSBI. What’s worse, if the machine already had OpenSBI, let’s imagine, burnt into some ROM, it already has OpenSBI to boot up, having it twice on a machine likely won’t cut it.</p>
<h4 id="fw_jump"><code>FW_JUMP</code></h4>
<p>This one is fairly simple too: you basically hardcode the address of your software that comes after OpenSBI. Similarly to above, 2 steps are needed.</p>
<ol>
<li>Make sure <code>FW_JUMP=y</code> is set in the <code>make</code> process, this will ensure a file called <code>fw_jump</code> is generated.</li>
<li>Set <code>FW_JUMP_ADDR</code> in the <code>make</code> process to the address where OpenSBI should jump once its done.</li>
</ol>
<p>This is quite similar to what we had in the previous scenario, only the jump address is hardcoded. It seems like in this case you are still necessarily responsible for building the OpenSBI image, but it’s easy to rebuild it and point to different addresses for different machines (let’s say different machines with varying memory layouts).</p>
<h4 id="fw_dynamic"><code>FW_DYNAMIC</code></h4>
<p>This one is the most generalized flavor and that’s why we leave it for last. This is where the importance of the register set up in ZSLB shines.</p>
<p>In this flavor, the boot stage that happens before OpenSBI is in charge of passing a few pointers to OpenSBI. In this case, we’re of course talking about the ZSBL. If we play close attention, we see that it touches the register <code>a2</code>.</p>
<p>At this point, I would like to encourage the reader to also read the section on ZSBL from <a href="https://embeddedinn.xyz/articles/tutorial/RISCV-Uncovering-the-Mysteries-of-Linux-Boot-on-RISC-V-QEMU-Machines/#the-zero-stage-bootloader-zsbl">this article</a>. The whole article is great, I just initially found it a little tough to go through, so consider this article a warmup for understanding that article, it’s really worth going through.</p>
<p>Anyway, keeping this article watered down still — what is the significance of setting up the register <code>a2</code> in ZSBL? <strong>It points to a struct <code>struct fw_dynamic_info</code></strong> which gives the dynamic OpenSBI flavor a way to continue going through the boot process! In fact, one of the piece of data in this struct is the address of the next piece of software running after OpenSBI! A good question to ask is: on a real machine, who populates this struct? Based on what we’ll see below, it’s obvious that QEMU hardcodes this content into the memory, and that logic is not part a of the ZSBL, but I can definitely imagine a device where ZSBL actually populates this struct and passes it on to OpenSBI.</p>
<p>Slide 17 of <a href="https://riscv.org/wp-content/uploads/2019/06/13.30-RISCV_OpenSBI_Deep_Dive_v5.pdf">this presentation</a> by an engineer from Western Digital (presumably a core contributor to OpenSBI) outlines the contents of this <code>struct</code>:</p>
<ol>
<li>Magic number</li>
<li>Version</li>
<li>Next address</li>
<li>Next mode</li>
<li>Options</li>
</ol>
<p>All of these are unsigned longs (I guess that means 64 bit, 8 bytes?).</p>
<h4 id="exploring-the-fw_dynamic_info-struct">Exploring the <code>fw_dynamic_info</code> struct</h4>
<p>At this point, let’s take a quick detour to make sure we’re on the same page. Let’s quickly make sure we’re all looking at the same version of the OpenSBI because different systems have different version of QEMU which may come with a different version of OpenSBI. Building OpenSBI from source is really straightforward, so let’s quickly do it. First, we need to clone the Git repo (time of writing of this article is 10th Sept 2023; if you want to achieve full reproducibility, build at a commit at this date):</p>
<pre is:raw="" tabindex="0"><code><span><span>git clone https://github.com/riscv-software-src/opensbi.git</span></span>
<span><span>cd opensbi</span></span>
<span><span>make ARCH=riscv CROSS_COMPILE=riscv64-linux-gnu- PLATFORM=generic</span></span></code></pre>
<p>The build should be fairly fast and lightweight. The output file we’re interested in is <code>build/platform/generic/firmware/fw_dynamic.bin</code>. We’ll pass this through the <code>-bios</code> flag to QEMU. Starting QEMU with (from the <code>opensbi</code> folder we just cloned with Git):</p>
<pre is:raw="" tabindex="0"><code><span><span>qemu-system-riscv64 -machine virt -s -S -bios build/platform/generic/firmware/fw_dynamic.bin</span></span></code></pre>
<p>After a few <code>si</code>s in <code>gdb</code>, we get back to where we were before. Let’s poke QEMU’s memory to see what’s going on there at the end of ZSBL. At the last instruction of ZSBL, we look at the register dump (we use <code>i r</code> for this).</p>
<pre is:raw="" tabindex="0"><code><span><span>=&gt; 0x0000000080000000:	33 04 05 00	add	s0,a0,zero</span></span>
<span><span>(gdb) i r</span></span>
<span><span>ra             0x0	0x0</span></span>
<span><span>sp             0x0	0x0</span></span>
<span><span>gp             0x0	0x0</span></span>
<span><span>tp             0x0	0x0</span></span>
<span><span>t0             0x80000000	2147483648</span></span>
<span><span>t1             0x0	0</span></span>
<span><span>t2             0x0	0</span></span>
<span><span>fp             0x0	0x0</span></span>
<span><span>s1             0x0	0</span></span>
<span><span>a0             0x0	0</span></span>
<span><span>a1             0x87e00000	2279604224</span></span>
<span><span>a2             0x1028	4136</span></span>
<span><span>a3             0x0	0</span></span>
<span><span>a4             0x0	0</span></span>
<span><span>a5             0x0	0</span></span>
<span><span>a6             0x0	0</span></span>
<span><span>a7             0x0	0</span></span>
<span><span>s2             0x0	0</span></span>
<span><span>s3             0x0	0</span></span>
<span><span>s4             0x0	0</span></span>
<span><span>s5             0x0	0</span></span>
<span><span>s6             0x0	0</span></span>
<span><span>s7             0x0	0</span></span>
<span><span>s8             0x0	0</span></span>
<span><span>s9             0x0	0</span></span>
<span><span>s10            0x0	0</span></span>
<span><span>s11            0x0	0</span></span>
<span><span>t3             0x0	0</span></span>
<span><span>t4             0x0	0</span></span>
<span><span>t5             0x0	0</span></span>
<span><span>t6             0x0	0</span></span>
<span><span>pc             0x80000000	0x80000000</span></span></code></pre>
<p><code>a2</code> is therefore pointing to <code>0x1028</code>. As we said, let’s poke that memory with <code>gdb</code>. We’ll ask it to read 10 successive 8-byte values starting from <code>0x1028</code>, and display them in hex format.</p>
<pre is:raw="" tabindex="0"><code><span><span>(gdb) x/10xg 0x1028</span></span></code></pre>
<p>The <code>g</code> flag prints out the memory contents in 8-byte (giant) chunks.</p>
<pre is:raw="" tabindex="0"><code><span><span>(gdb) x/10xg 0x1028</span></span>
<span><span>0x1028:	0x000000004942534f	0x0000000000000002</span></span>
<span><span>0x1038:	0x0000000000000000	0x0000000000000001</span></span>
<span><span>0x1048:	0x0000000000000000	0x0000000000000000</span></span>
<span><span>0x1058:	0x0000000000000000	0x0000000000000000</span></span>
<span><span>0x1068:	0x0000000000000000	0x0000000000000000</span></span></code></pre>
<p>This roughly seems to match <a href="https://embeddedinn.xyz/articles/tutorial/RISCV-Uncovering-the-Mysteries-of-Linux-Boot-on-RISC-V-QEMU-Machines/#the-zero-stage-bootloader-zsbl">Vysakh’s article</a>. We definitely see the magic described in that article, followed by the <code>0x02</code> info version. Next should be the address for the next jump, but there are all zeroes… This is strange, but let’s keep looking. Next value is <code>0x01</code> which again, according to the article, should correspond to the next mode of execution which is <code>S</code>. This is correct, we’re going from <code>M</code> mode running SBI to the <code>S</code> mode running the OS kernel bootloader, or the kernel itself, whatever we want. Why is the address of the next jump all zeroes though? At this point, I’ll just let QEMU run without interference from <code>gdb</code>. I run the following in <code>gdb</code>:</p>
<pre is:raw="" tabindex="0"><code><span><span>continue</span></span></code></pre>
<p>Everything is sort of hanging, but I got a newer OpenSBI output on UART since I am now running a newer version of OpenSBI:</p>
<pre is:raw="" tabindex="0"><code><span><span>OpenSBI v1.3-54-g901d3d7</span></span>
<span><span>   ____                    _____ ____ _____</span></span>
<span><span>  / __ \                  / ____|  _ \_   _|</span></span>
<span><span> | |  | |_ __   ___ _ __ | (___ | |_) || |</span></span>
<span><span> | |  | | '_ \ / _ \ '_ \ \___ \|  _ &lt; | |</span></span>
<span><span> | |__| | |_) |  __/ | | |____) | |_) || |_</span></span>
<span><span>  \____/| .__/ \___|_| |_|_____/|____/_____|</span></span>
<span><span>        | |</span></span>
<span><span>        |_|</span></span>
<span><span></span></span>
<span><span>Platform Name             : riscv-virtio,qemu</span></span>
<span><span>Platform Features         : medeleg</span></span>
<span><span>Platform HART Count       : 1</span></span>
<span><span>Platform IPI Device       : aclint-mswi</span></span>
<span><span>Platform Timer Device     : aclint-mtimer @ 10000000Hz</span></span>
<span><span>Platform Console Device   : uart8250</span></span>
<span><span>Platform HSM Device       : ---</span></span>
<span><span>Platform PMU Device       : ---</span></span>
<span><span>Platform Reboot Device    : syscon-reboot</span></span>
<span><span>Platform Shutdown Device  : syscon-poweroff</span></span>
<span><span>Platform Suspend Device   : ---</span></span>
<span><span>Platform CPPC Device      : ---</span></span>
<span><span>Firmware Base             : 0x80000000</span></span>
<span><span>Firmware Size             : 322 KB</span></span>
<span><span>Firmware RW Offset        : 0x40000</span></span>
<span><span>Firmware RW Size          : 66 KB</span></span>
<span><span>Firmware Heap Offset      : 0x48000</span></span>
<span><span>Firmware Heap Size        : 34 KB (total), 2 KB (reserved), 9 KB (used), 22 KB (free)</span></span>
<span><span>Firmware Scratch Size     : 4096 B (total), 768 B (used), 3328 B (free)</span></span>
<span><span>Runtime SBI Version       : 1.0</span></span>
<span><span></span></span>
<span><span>Domain0 Name              : root</span></span>
<span><span>Domain0 Boot HART         : 0</span></span>
<span><span>Domain0 HARTs             : 0*</span></span>
<span><span>Domain0 Region00          : 0x0000000002000000-0x000000000200ffff M: (I,R,W) S/U: ()</span></span>
<span><span>Domain0 Region01          : 0x0000000080040000-0x000000008005ffff M: (R,W) S/U: ()</span></span>
<span><span>Domain0 Region02          : 0x0000000080000000-0x000000008003ffff M: (R,X) S/U: ()</span></span>
<span><span>Domain0 Region03          : 0x0000000000000000-0xffffffffffffffff M: () S/U: (R,W,X)</span></span>
<span><span>Domain0 Next Address      : 0x0000000000000000</span></span>
<span><span>Domain0 Next Arg1         : 0x0000000087e00000</span></span>
<span><span>Domain0 Next Mode         : S-mode</span></span>
<span><span>Domain0 SysReset          : yes</span></span>
<span><span>Domain0 SysSuspend        : yes</span></span>
<span><span></span></span>
<span><span>Boot HART ID              : 0</span></span>
<span><span>Boot HART Domain          : root</span></span>
<span><span>Boot HART Priv Version    : v1.10</span></span>
<span><span>Boot HART Base ISA        : rv64imafdc</span></span>
<span><span>Boot HART ISA Extensions  : zicntr</span></span>
<span><span>Boot HART PMP Count       : 16</span></span>
<span><span>Boot HART PMP Granularity : 4</span></span>
<span><span>Boot HART PMP Address Bits: 54</span></span>
<span><span>Boot HART MHPM Info       : 0 (0x00000000)</span></span>
<span><span>Boot HART MIDELEG         : 0x0000000000000222</span></span>
<span><span>Boot HART MEDELEG         : 0x000000000000b109</span></span></code></pre>
<p>This matches what we saw above, the next address is all zeroes… This is strange, there’s no way that could be true. I now ran QEMU without the initial pause, just letting it run and connecting with <code>gdb</code> asynchronously. I’ll spare you the details, but inspecting the registers on that “live run” definitely showed to me that nothing is executing in the <code>0x0000000000000000</code> area. The CPU seems to be spinning around some other address.</p>
<p>This likely has something to do with the fact that I actually didn’t pass any software to QEMU to load other than OpenSBI, so that’s probably what’s throwing it off. QEMU likely populated the struct in memory with all zeroes, and OpenSBI identifies it as an illegal edge case, so it just keeps spinning in OpenSBI forever — this is my educated guess.</p>
<p>How do we pass some software to run other than OpenSBI? <strong>The same way we passed OpenSBI, just a diferent flag name!</strong> This time, we’re using the <code>-kernel</code> QEMU flag. And how are we going to build this software? The same way we built the “fake BIOS” in our previous article, we’ll just map it to a different memory location. Let’s give it a shot at <code>0x80200000</code>.</p>
<h4 id="building-an-infinite-loop-fake-kernel">Building an “infinite-loop fake kernel”</h4>
<p>Our OS kernel will just spin in place. It will be a single jump instruction at <code>0x80200000</code> that just stays there infinitely. Here’s the assembly source code:</p>
<pre is:raw="" tabindex="0"><code><span><span>	.global _start</span></span>
<span><span>	.</span><span>section .text</span><span>.kernel</span></span>
<span></span>
<span><span>_start:</span><span>	j _start</span></span></code></pre>
<p>The linker script is the following:</p>
<pre is:raw="" tabindex="0"><code><span><span>MEMORY {</span></span>
<span><span>  kernel_space (rwx) : ORIGIN = 0x80200000, LENGTH = 128</span></span>
<span><span>}</span></span>
<span><span></span></span>
<span><span>SECTIONS {</span></span>
<span><span>  .text : {</span></span>
<span><span>    infinite_loop.o(.text.kernel)</span></span>
<span><span>  } &gt; kernel_space</span></span>
<span><span>}</span></span></code></pre>
<p><em>For details on how to use these files to build an <code>ELF</code> image that can be loaded into QEMU, please see the original bare metal programming article.</em></p>
<p>Once we build it, we end up with the <code>infinte_loop</code> <code>ELF</code> file that can serve as our fake kernel. We now run QEMU</p>
<pre is:raw="" tabindex="0"><code><span><span>qemu-system-riscv64 -machine virt -s -S -bios build/platform/generic/firmware/fw_dynamic.bin -kernel ~/work/github_demo/risc-v-bare-metal-fake-kernel/infinite_loop</span></span></code></pre>
<p>Again, I connect <code>gdb</code> and <code>si</code> my way to the end of ZSBL. Now when I read the infamous struct at <code>0x1028</code>, things look a lot better, which confirms the theory that QEMU was populating that struct weirdly.</p>
<pre is:raw="" tabindex="0"><code><span><span>=&gt; 0x0000000080000000:	33 04 05 00	add	s0,a0,zero</span></span>
<span><span>(gdb) x/10xg 0x1028</span></span>
<span><span>0x1028:	0x000000004942534f	0x0000000000000002</span></span>
<span><span>0x1038:	0x0000000080200000	0x0000000000000001</span></span>
<span><span>0x1048:	0x0000000000000000	0x0000000000000000</span></span>
<span><span>0x1058:	0x0000000000000000	0x0000000000000000</span></span>
<span><span>0x1068:	0x0000000000000000	0x0000000000000000</span></span></code></pre>
<p>We now see that the new address is populated in this struct, as is expected. This is also reflected in the OpenSBI output on UART. Let’s continue to our fake kernel with <code>gdb</code> and see if everything is OK there.</p>
<pre is:raw="" tabindex="0"><code><span><span>(gdb) break *0x080200000</span></span>
<span><span>Breakpoint 1 at 0x80200000</span></span>
<span><span>(gdb) continue</span></span>
<span><span>Continuing.</span></span>
<span><span></span></span>
<span><span>Breakpoint 1, 0x0000000080200000 in ?? ()</span></span>
<span><span>=&gt; 0x0000000080200000:	6f 00 00 00	j	0x80200000</span></span></code></pre>
<p>Everything looks good here. Let’s recap:</p>
<ol>
<li>ZSBL is the first thing that runs after the power-on. It initializes a few registers. The key register is <code>a2</code>, which points to a <code>fw_dynamic_info</code> struct containing the crucial info for the <code>FW_DYNAMIC</code> flavor of OpenSBI to operate. In QEMU case, this struct is somehow populated during the power-on, magically by the virutalization engine, but in reality, this is <strong>likely</strong> the job of the ZSBL. Either way, OpenSBI now knows what to do after it’s done.</li>
<li>OpenSBI provides an interrupt-based interface for the software up on the stack (presumably OS kernel bootloader and kernel itself) to invoke it. This interface is called SBI and it’s conceptually the same as ABI for the application software on top of an operating system.</li>
<li>We pass the kernel image to QEMU as yet another ELF which just populated another section of the memory. QEMU populates the struct in such way that OpenSBI can pass the control to there, and before it switches there, it enters the <code>S</code> mode of execution.</li>
</ol>
<h4 id="intentionally-skipped-details">Intentionally skipped details</h4>
<p>ZSBL also touched the <code>a0</code> and <code>a1</code> registers.</p>
<p><code>a0</code> has something to do with RISC-V <code>hart</code>s, but let’s not get into those details, they are not relevant for the rest of this article. Besides, this particular step in the boot process doesn’t seem to be particularly relevant, per <a href="https://github.com/riscv-software-src/opensbi/issues/170#issuecomment-642679348">comments from Github</a>.</p>
<p><code>a1</code> is an interesting pointer because it points to the <strong>device tree</strong> data structure in memory. For the rest of this article, this data structure is not relevant, so we can disregard this piece of information. However, the device tree is really useful for real kernels like Linux. Linux is able to scan the device tree from memory and understand the structure of the machine it’s running on, rather than having to run a lot of <code>if/else</code> branches in its programming for every hardware combination. <a href="https://en.wikipedia.org/wiki/Devicetree#Linux">The Wikipedia article</a> should give a decent idea of how this is used in Linux. As mentioned, however, we won’t be concerned with the details of device tree in the rest of this article.</p>
<h2 id="hello-world-fake-kernel">Hello world fake kernel</h2>
<p>Now we have all the knowledge we need to code a fake OS kernel that just prints “Hello world” to the UART device. The functionality is not at all different from the bare metal program we looked at in the previous guide, but the way we’ll get there is significantly different. We’ll be using an SBI call to print to UART, instead of directly interacting with the UART device (we’re using a more privileged lower layer of software to do this work for us). This could have serious consequences, even on a trivial example such as a “hello world” one: <strong>we delegate the responsibility of interacting with the UART hardware to the SBI layer, thus achieving portability across different machines that conform to this SBI interface</strong>.</p>
<p>How do we call into RISC-V SBI layer? Conceptually, it’s exactly the same as invoking a print to standard output in x86 Linux — we’ll populate some registers and invoke a software interrupt/trap to pass the control down the software stack to OpenSBI. OpenSBI offers a lot of services in the SBI layer, and many of them can be extremely useful for developing a portable operating system kernel, such as interaction with the timers (relevant for time slicing and enabling multiple threads to share the same CPU core). For the full list of functionality exposed through the SBI layer, please take a look <a href="https://github.com/riscv-non-isa/riscv-sbi-doc/blob/master/riscv-sbi.adoc">here</a>.</p>
<p>In this guide, we’ll be focusing on the <a href="https://github.com/riscv-non-isa/riscv-sbi-doc/blob/master/src/ext-debug-console.adoc">debug console</a> functionality, i.e. we’ll be writing out to UART through SBI. Let’s code!</p>
<p>First, we need to know how do we encode the functionality we want OpenSBI to execute through registers. This is well documented <a href="https://github.com/riscv-non-isa/riscv-sbi-doc/blob/master/src/binary-encoding.adoc">here</a>. tl;dr is that SBI functionality is grouped into “extensions”. Register <code>a7</code> contains the extension ID (EID), while <code>a6</code> encodes the individual function ID (FID) within that extension. The parameters are then passed through <code>a0</code>, <code>a1</code>, <code>a2</code>, …</p>
<p>For printing to the console, the EID we are looking for is <code>0x4442434E</code> (a rather interesting value) and the FID is simply <code>0x00</code>.</p>
<p>This time, instead of printing one by one character as we did in the initial bare metal programming guide, we’ll invoke the printing as a single operation. After all, we should be benefiting from the high level functionality that the SBI layer offers. Therefore, our binary should store the output string somewhere in the memory, and ideally we want to do something like invoking the SBI to print from that address. We’ll do just that:</p>
<pre is:raw="" tabindex="0"><code><span><span>        .global _start</span></span>
<span><span>        .</span><span>section .text</span><span>.kernel</span></span>
<span></span>
<span><span>_start:</span><span> li a7, </span><span>0x4442434E</span></span>
<span><span>        li a6, </span><span>0x00</span></span>
<span><span>1</span><span>:      auipc a3, %pcrel_hi(debug_string)</span></span>
<span><span>        addi a3, a3, %pcrel_lo(</span><span>1b</span><span>)</span></span>
<span><span>        li a4, </span><span>0x00000000FFFFFFFF</span></span>
<span><span>        li a5, </span><span>0xFFFFFFFF00000000</span></span>
<span><span>        li a0, </span><span>12</span></span>
<span><span>        </span><span>and</span><span> a1, a3, a4</span></span>
<span><span>        </span><span>and</span><span> a2, a3, a5</span></span>
<span><span>        ecall</span></span>
<span></span>
<span><span>        li a7, </span><span>0x01</span></span>
<span><span>        mv a6, a0</span></span>
<span><span>        ecall</span></span>
<span></span>
<span><span>loop</span><span>:   j </span><span>loop</span></span>
<span></span>
<span><span>        .</span><span>section .rodata</span></span>
<span><span>debug_string:</span></span>
<span><span>        .string "Hello world\n"</span></span></code></pre>
<p>A couple of things to note here:</p>
<ol>
<li>We use PC-relative addressing here for the output string. As a reminder, the kernel is stored at an address represented by a very large unsigned integer. This value is too high to be encoded within any RISC-V 32-bit instruction word. That’s not a problem, we simply use a short sequence of <code>AUIPC</code> and <code>ADDI</code> instructions to get there (check out <a href="https://michaeljclark.github.io/asm.html">this article</a> for more information on this). If you do not understand what this point is all about, please make sure to revise different memory addressing modes and the differences between them: this is crucial for any sort of bare metal programming.</li>
<li>There is some bit-masking happening as well for registers <code>a1</code> and <code>a2</code>. SBI for some reason asks for the pointer to the string to be printed to be broken down into two 32-bit pieces.</li>
</ol>
<p>So our SBI call is defined by several registers:</p>
<ol>
<li><code>a7</code> identifies the SBI extension</li>
<li><code>a6</code> identifies the function within the extension (in this case, debug console extension)</li>
<li><code>a0</code> contains the length of the string that needs to go to the debug console output</li>
<li><code>a1</code> and <code>a2</code>, when joined together, contain the 64-bit pointer to the address of the stirng that needs to be printed</li>
</ol>
<p>The SBI call is now invoked through an <code>ecall</code> instruction, which activates a CPU trap. At this point, OpenSBI takes over and writes to UART, in exactly the same way as we did in the initial bare metal programming guide. If you are wondering how a simple <code>ecall</code> invocation takes us to OpenSBI, that is because OpenSBI set up the trap handling mechanism in such way that when our kernel gets into a trap, the program counter will jump into the OpenSBI software section. The details of this are way outside the scope of this article, but we may cover this in some other article.</p>
<p>For now, just check out the QEMU serial port and confirm that “Hello world” is printed properly:</p>
<pre is:raw="" tabindex="0"><code><span><span>qemu-system-riscv64 -machine virt -s -S -bios build/platform/generic/firmware/fw_dynamic.bin -kernel ~/work/github_demo/risc-v-bare-metal-fake-kernel/hello_world_kernel</span></span></code></pre>
<pre is:raw="" tabindex="0"><code><span><span>OpenSBI v1.3-54-g901d3d7</span></span>
<span><span>   ____                    _____ ____ _____</span></span>
<span><span>  / __ \                  / ____|  _ \_   _|</span></span>
<span><span> | |  | |_ __   ___ _ __ | (___ | |_) || |</span></span>
<span><span> | |  | | '_ \ / _ \ '_ \ \___ \|  _ &lt; | |</span></span>
<span><span> | |__| | |_) |  __/ | | |____) | |_) || |_</span></span>
<span><span>  \____/| .__/ \___|_| |_|_____/|____/_____|</span></span>
<span><span>        | |</span></span>
<span><span>        |_|</span></span>
<span><span></span></span>
<span><span>Platform Name             : riscv-virtio,qemu</span></span>
<span><span>Platform Features         : medeleg</span></span>
<span><span>Platform HART Count       : 1</span></span>
<span><span>Platform IPI Device       : aclint-mswi</span></span>
<span><span>Platform Timer Device     : aclint-mtimer @ 10000000Hz</span></span>
<span><span>Platform Console Device   : uart8250</span></span>
<span><span>Platform HSM Device       : ---</span></span>
<span><span>Platform PMU Device       : ---</span></span>
<span><span>Platform Reboot Device    : syscon-reboot</span></span>
<span><span>Platform Shutdown Device  : syscon-poweroff</span></span>
<span><span>Platform Suspend Device   : ---</span></span>
<span><span>Platform CPPC Device      : ---</span></span>
<span><span>Firmware Base             : 0x80000000</span></span>
<span><span>Firmware Size             : 322 KB</span></span>
<span><span>Firmware RW Offset        : 0x40000</span></span>
<span><span>Firmware RW Size          : 66 KB</span></span>
<span><span>Firmware Heap Offset      : 0x48000</span></span>
<span><span>Firmware Heap Size        : 34 KB (total), 2 KB (reserved), 9 KB (used), 22 KB (free)</span></span>
<span><span>Firmware Scratch Size     : 4096 B (total), 768 B (used), 3328 B (free)</span></span>
<span><span>Runtime SBI Version       : 1.0</span></span>
<span><span></span></span>
<span><span>Domain0 Name              : root</span></span>
<span><span>Domain0 Boot HART         : 0</span></span>
<span><span>Domain0 HARTs             : 0*</span></span>
<span><span>Domain0 Region00          : 0x0000000002000000-0x000000000200ffff M: (I,R,W) S/U: ()</span></span>
<span><span>Domain0 Region01          : 0x0000000080040000-0x000000008005ffff M: (R,W) S/U: ()</span></span>
<span><span>Domain0 Region02          : 0x0000000080000000-0x000000008003ffff M: (R,X) S/U: ()</span></span>
<span><span>Domain0 Region03          : 0x0000000000000000-0xffffffffffffffff M: () S/U: (R,W,X)</span></span>
<span><span>Domain0 Next Address      : 0x0000000080200000</span></span>
<span><span>Domain0 Next Arg1         : 0x0000000087e00000</span></span>
<span><span>Domain0 Next Mode         : S-mode</span></span>
<span><span>Domain0 SysReset          : yes</span></span>
<span><span>Domain0 SysSuspend        : yes</span></span>
<span><span></span></span>
<span><span>Boot HART ID              : 0</span></span>
<span><span>Boot HART Domain          : root</span></span>
<span><span>Boot HART Priv Version    : v1.10</span></span>
<span><span>Boot HART Base ISA        : rv64imafdc</span></span>
<span><span>Boot HART ISA Extensions  : zicntr</span></span>
<span><span>Boot HART PMP Count       : 16</span></span>
<span><span>Boot HART PMP Granularity : 4</span></span>
<span><span>Boot HART PMP Address Bits: 54</span></span>
<span><span>Boot HART MHPM Info       : 0 (0x00000000)</span></span>
<span><span>Boot HART MIDELEG         : 0x0000000000000222</span></span>
<span><span>Boot HART MEDELEG         : 0x000000000000b109</span></span>
<span><span>Hello world</span></span></code></pre>
<p>As an exercise, I suggest probing the <a href="https://github.com/riscv-non-isa/riscv-sbi-doc/blob/master/src/ext-base.adoc">base extension (<code>0x10</code>)</a> with <code>gdb</code> to investigate what the QEMU machine + OpenSBI you build are capable of offering.</p>
<h2 id="conclusion">Conclusion</h2>
<p>We ended up with an entirely portable fake kernel that prints “Hello world” to UART! This may seem like nothing special, but the concept here is very powerful. Without rebuilding, you can drop the same kernel image on a different RISC-V 64-bit machine with OpenSBI that supports the debug console extension.</p>
<p>In fact, I played a little trick here. :) One of the main reasons I suggested building OpenSBI from source is that some QEMU versions provided by the Linux distro package managers do not support the debug console extension (they’re simply old). This was the case with my default OpenSBI which came with Debian’s version of QEMU.</p>
<p>Finally, I would like to remind the reader that we have extensively focused on the QEMU <code>virt</code> machine with a RISC-V core and all the fine details of this article are related to it. That said, my hope is that the reader has learned enough about the boot sequence concepts and bare metal programming that adapting this knowledge to a particular real-world scenario becomes easy.</p>
<p>In the next posts, we’ll talk about taking this further and booting up a full blown Linux kernel. We’ll expand that step by step until we reach a Linux deployment that can handle I/O with keyboard, mouse, screen and Ethernet network.</p>
<p>I hope you enjoyed this lengthy writeup!</p>
<h2 id="code-pointers">Code pointers</h2>
<p>If you prefer not to copy/paste, the code is available on <a href="https://github.com/popovicu/risc-v-bare-metal-fake-kernel">this GitHub repo</a>.</p>
    </article></div>]]></description>
        </item>
    </channel>
</rss>