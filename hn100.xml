<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 20 Dec 2023 18:00:09 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Volkswagen, Porsche, and Audi finally say they will use Tesla's EV charging plug (121 pts)]]></title>
            <link>https://www.theverge.com/2023/12/19/24008426/volkswagen-audi-porsche-tesla-nacs-ev-charging-plug</link>
            <guid>38709319</guid>
            <pubDate>Wed, 20 Dec 2023 14:56:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2023/12/19/24008426/volkswagen-audi-porsche-tesla-nacs-ev-charging-plug">https://www.theverge.com/2023/12/19/24008426/volkswagen-audi-porsche-tesla-nacs-ev-charging-plug</a>, See on <a href="https://news.ycombinator.com/item?id=38709319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Volkswagen Group, which also owns Audi, Porsche, and Scout Motors, is finally doing what nearly every other automaker has already done: announce its intention to adopt Tesla‚Äôs electric vehicle charging standard. </p><p>VW said it is ‚Äúexploring adapter solutions‚Äù so that its current EV owners can access Tesla‚Äôs Supercharger network and expects to have something to roll out by 2025. That same year, you‚Äôll start to see new VW electric vehicles rolling off the assembly line with Tesla‚Äôs charging port natively installed. All told, VW says the deal will give its customers access to 15,000 Supercharger locations in North America. </p><div><p>VW said it is ‚Äúexploring adapter solutions‚Äù</p></div><p>Of course, VW is incredibly late to this parade. Things started rolling in November 2022, when <a href="https://www.theverge.com/2022/11/11/23453587/tesla-connector-north-american-standard-ccs-combo">Tesla announced</a> that it was renaming its charging technology to the North American Charging Standard (NACS) and would be opening it up to other automakers. <a href="https://www.theverge.com/2023/5/25/23737896/ford-tesla-ev-fast-charging-elon-musk-twitter-space">Ford came first</a>, <a href="https://www.theverge.com/2023/6/8/23754470/gm-tesla-ev-supercharger-nacs-elon-musk">then GM</a>, and then, well, <a href="https://www.theverge.com/2023/6/9/23755184/tesla-ev-charging-standard-nacs-ccs-gm-ford">everyone else</a>. </p><p>Volkswagen Group, one of the world‚Äôs largest automakers, with brands like Audi, Bentley, Bugatti, Porsche, and Lamborghini under its umbrella, stayed mum throughout. All we got was some reporting that <a href="https://www.theverge.com/2023/7/5/23784541/vw-toyota-tesla-nacs-ev-charging-plug-standard">the company was ‚Äúin talks‚Äù with Tesla</a>. That story followed the news that Electrify America, VW‚Äôs EV charging subsidiary,&nbsp;<a href="https://www.theverge.com/2023/6/29/23778599/electrify-america-tesla-nacs-connector-2025-ev">would begin adding Tesla charging plugs</a> itself. The rest of Germany‚Äôs auto industry soon followed, including <a href="https://www.theverge.com/2023/10/17/23921374/bmw-mini-rolls-royce-tesla-nacs-ev-charging-standard">BMW, Mini</a>, and <a href="https://www.theverge.com/2023/7/7/23787186/mercedes-benz-tesla-nacs-ev-charging-standard">Mercedes-Benz</a>. </p><p>Until recently, Tesla Superchargers were exclusive to Tesla owners. In fact, it was one of Tesla‚Äôs main selling points: consistent, exclusive, and abundant EV charging. But that began to change several years ago when the company started offering access to non-Tesla EVs ‚Äîfirst in Europe and then in the US after the Biden administration said it would be a <a href="https://www.theverge.com/2023/2/15/23600859/tesla-supercharger-non-tesla-ev-number-biden">prerequisite to tap into some of the $7.5 billion</a> for EV charging in the Bipartisan Infrastructure Law.</p><p>Tesla‚Äôs Supercharger network is widely recognized as superior to many of the third-party EV charging stations, most of which feature CCS plugs and the less utilized CHAdeMO charging standard. The company says it has 45,000 Superchargers worldwide, 12,000 of which are located in the US.</p><p>And while other EV charging stations struggle with software glitches and faulty chargers, Tesla says its Superchargers are nearly perfect in their reliability. The company says that the average uptime of Supercharger sites last year amounted to 99.95 percent, down marginally from&nbsp;99.96 percent in 2021.</p><p>Now, with VW out of the way, Tesla can train all of its attention on the last real holdout: Stellantis, which owns brands like Jeep, Chrysler, Ram, Dodge, Peugeot, Fiat, and many more. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Podman Desktop 1.6 released: Even more Kubernetes and Containers features (126 pts)]]></title>
            <link>https://podman-desktop.io/blog/podman-desktop-release-1.6</link>
            <guid>38709121</guid>
            <pubDate>Wed, 20 Dec 2023 14:36:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://podman-desktop.io/blog/podman-desktop-release-1.6">https://podman-desktop.io/blog/podman-desktop-release-1.6</a>, See on <a href="https://news.ycombinator.com/item?id=38709121">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container" itemprop="articleBody"><p>Podman Desktop 1.6 Release! üéâ</p>
<p><img loading="lazy" alt="Podman-desktop-1-6-hero" src="https://podman-desktop.io/assets/images/santaseal-53d399f20690910707cb93295dd700ce.png" width="1920" height="1080"></p>
<p>This release introduces:</p>
<ul>
<li><strong>Minikube Featured Extension</strong>: Minikube extension to create local Kubernetes clusters in containers.</li>
<li><strong>Podman 4.8.2</strong>: <a href="https://github.com/containers/podman/releases" target="_blank" rel="noopener noreferrer">Podman 4.8.2</a> is now included in Windows and Mac installers.</li>
<li><strong>Setting Page for Command-Line Tools</strong>: Manage and update your CLI tools.</li>
<li><strong>Kubernetes Contexts Manager</strong>: Browse all your kubernetes contexts, set default and remove unused ones.</li>
<li><strong>Editable Podman Machine for MacOS</strong>: Easy resize and reconfiguration of the Podman runtime environment.</li>
<li><strong>Filters for Containers and Pods Lists</strong>: Focus on the containers and Pods you are working with.</li>
<li><strong>Sorting on Volumes and Images List</strong>: Sort volumes or images with your prefered criterias.</li>
<li><strong>Environment Colums on Containers and Pods lists</strong>: Easy catch of the environment on which a container or a pod is running on.</li>
<li><strong>Extension API Improvements</strong>: Another set of improvements to the extension API enabling more goodness for ü¶≠ Podman Desktop's extensions.</li>
</ul>
<p>Podman Desktop 1.6 is now available. <a href="https://podman-desktop.io/downloads">Click here to download it</a>!</p>
<hr>
<h2 id="release-details">Release Details<a href="#release-details" aria-label="Direct link to Release Details" title="Direct link to Release Details">‚Äã</a></h2>
<h3 id="minikube-featured-extension">Minikube featured extension<a href="#minikube-featured-extension" aria-label="Direct link to Minikube featured extension" title="Direct link to Minikube featured extension">‚Äã</a></h3>
<p>For developers who need to run Kubernetes locally and reproduce an environment close to production for development and experimentation purposes, Podman Desktop allows users to easily set up that environment on a local machine. There are two extensions providing the capability to configure a open source Kubernetes cluster locally, you can either choose between <a href="https://kind.sigs.k8s.io/" target="_blank" rel="noopener noreferrer">Kind</a> or <a href="https://minikube.sigs.k8s.io/docs/" target="_blank" rel="noopener noreferrer">Minikube</a>.</p>
<p>The Minikube extension allows you to install Minikube on your workstation and also to setup a Kubernetes cluster locally running in a container! Yes, you read that correctly - in a container similar to how Kind works. The advantage is that it's lighter and faster to start. With Minikube, one of the advantage, is that you can build your images locally with Podman and get them automatically available in your local Kubernetes cluster - which will speed up your turnarounds when you want to test your application. If you want to learn more this, read the <a href="https://podman-desktop.io/blog/sharing-podman-images-with-kubernetes-cluster" target="_blank" rel="noopener noreferrer">following blog post</a>.</p>
<p><img loading="lazy" alt="Minikube-feature-extension" src="https://podman-desktop.io/assets/images/minikube-feature-extension-dedb97b4b55350d997e49986f88e230f.png" width="1906" height="1038"></p>
<h3 id="command-line-tools-configuration-compose-and-kubectl">Command-Line Tools Configuration: Compose and Kubectl<a href="#command-line-tools-configuration-compose-and-kubectl" aria-label="Direct link to Command-Line Tools Configuration: Compose and Kubectl" title="Direct link to Command-Line Tools Configuration: Compose and Kubectl">‚Äã</a></h3>
<p>Configuring and managing your setup is getting easier with the addition of a new section in the Settings to manage command-line tools. In Podman Desktop, extensions can list command-line tools that are helpful to their users or required to make use of the installed extensions.</p>
<p>There are two command-line tools within Podman Desktop that allows you to view whether they are installed or require an update:</p>
<ul>
<li>Compose binary for running 'podman compose' commands.</li>
<li>kubectl for interacting with Kubernetes clusters.</li>
</ul>
<p><img loading="lazy" alt="cli-tools" src="https://podman-desktop.io/assets/images/cli-tools-40a9ec75b14a04433ec9a13e0aab1049.png" width="1162" height="812"></p>
<p>From the settings you can see the command-line tools that are installed, and you can see the version - and when a new version is available, you'll get a small notification to allow you easily update to that version.</p>
<p><img loading="lazy" alt="Compose-Update" src="https://podman-desktop.io/assets/images/compose-update-20a782e079045b424da69bd6b3959d37.png" width="2078" height="1132"></p>
<h3 id="kubernetes-contexts-manager">Kubernetes Contexts Manager<a href="#kubernetes-contexts-manager" aria-label="Direct link to Kubernetes Contexts Manager" title="Direct link to Kubernetes Contexts Manager">‚Äã</a></h3>
<p>We are introducing a new screen available from the Settings which allows you to easily manage your Kubernetes contexts. Podman Desktop was already providing the handy context switcher available from the status bar, but when you get to work with multiple Kubernetes environments, it's not uncommon to end with a big and long list of Kubernetes contexts.</p>
<p>The new Kubernetes Contexts screen allows you to easily see all your registered Kubernetes contexts. You can use the screen to clean up your registered contexts, or set the current (default) context.</p>
<p><img loading="lazy" alt="Kubernetes Contexts List" src="https://podman-desktop.io/assets/images/kubernetes-contexts-026a8394a1cdb3f8130a8e7b7a1695f5.png" width="2864" height="2284"></p>
<h3 id="editable-podman-machine">Editable Podman Machine<a href="#editable-podman-machine" aria-label="Direct link to Editable Podman Machine" title="Direct link to Editable Podman Machine">‚Äã</a></h3>
<p>A Podman machine is a virtual environment specifically designed to run Podman containers on Mac and Windows. It allows users to manage and operate containerized applications in an isolated and controlled setting. When creating a Podman machine, you configure its settings: memory, CPU(s) and disk size.</p>
<p>We've received the feedback regarding the ability to reconfigure your Podman machine on the go. This is now possible for macOS users, and particularly useful when you start with an environment and need to scale it up based on new needs and containers you would like to run in your Podman environment.</p>
<p><img loading="lazy" src="https://github.com/containers/podman-desktop/assets/1636769/91150767-58a9-47b5-abbc-58d2d50f4fca" alt="Editable podman machine"></p>
<p>You'll notice we improved the sliders to configure the Podman machine's options - and also introduced a way to enter numeric values directly.</p>
<h3 id="tabsfilters-for-containers-and-pods">Tabs/Filters for Containers and Pods<a href="#tabsfilters-for-containers-and-pods" aria-label="Direct link to Tabs/Filters for Containers and Pods" title="Direct link to Tabs/Filters for Containers and Pods">‚Äã</a></h3>
<p>Being able to quickly identify the containers and the pods you are working with is critical when you are iterating on the development of your application. For this reason, we added filters at the top of the lists of Containers and Pods that allow you to easily view all the containers/pods, only those that are running, or only those that are stopped.</p>
<p><img loading="lazy" src="https://github.com/containers/podman-desktop/assets/1636769/37190c74-7fa5-485e-81a4-bd970f606286" alt="Filters for containers and pods"></p>
<h3 id="sorting-for-volumes-and-images-lists">Sorting for Volumes and Images lists<a href="#sorting-for-volumes-and-images-lists" aria-label="Direct link to Sorting for Volumes and Images lists" title="Direct link to Sorting for Volumes and Images lists">‚Äã</a></h3>
<p>The lists of Volumes and Images have improved and are now have the ability to be sorted by the criteria of your choice. You can for example filter images by their size - which can be convenient when you want to clean up your environment.</p>
<p><img loading="lazy" src="https://github.com/containers/podman-desktop/assets/1636769/0d20b5c2-517c-4ccc-8992-b8df275bcc30" alt="Sorting for Volumes and Images"></p>
<h3 id="environment-columns-on-containers-and-pods-lists">Environment columns on Containers and Pods lists<a href="#environment-columns-on-containers-and-pods-lists" aria-label="Direct link to Environment columns on Containers and Pods lists" title="Direct link to Environment columns on Containers and Pods lists">‚Äã</a></h3>
<p>Podman Desktop is able to work with multiple providers: it could work with multiple container engines and multiple Kubernetes environments too. In order to make it easier to identify the containers and the pods and differentiate them depending on which environment they are running onto, we are introducing a new environment column in the list of Containers and Pods to display a badge.</p>
<p><img loading="lazy" alt="Environment Column" src="https://podman-desktop.io/assets/images/environment-column-f9c0eeca8f5d810da054529ea466bfc4.png" width="3708" height="1906"></p>
<h4 id="better-visibility-to-the-containers-running-in-pods">Better visibility to the containers running in Pods<a href="#better-visibility-to-the-containers-running-in-pods" aria-label="Direct link to Better visibility to the containers running in Pods" title="Direct link to Better visibility to the containers running in Pods">‚Äã</a></h4>
<p>The list of Pods has been refined to provide easier visibility and access to the containers running within each of them. Each of the containers now have one dot and you can hover each dot to display the info about the container - and if you click on it you'll be able to access the details of the container.</p>
<p><img loading="lazy" src="https://github.com/containers/podman-desktop/assets/1636769/0e88a88e-9a17-4261-b60f-b4d09ca19127" alt="Visibility for containers in Pods"></p>
<h3 id="extension-api-improvements">Extension API improvements<a href="#extension-api-improvements" aria-label="Direct link to Extension API improvements" title="Direct link to Extension API improvements">‚Äã</a></h3>
<p>The ü¶≠ Podman Desktop extension API received many improvements, including:</p>
<ul>
<li>Documentation explaining how to create an onboarding workflow for an extension <a href="https://github.com/containers/podman-desktop/pull/4837" target="_blank" rel="noopener noreferrer">#4837</a></li>
<li>Documented how extensions hook into UI <a href="https://github.com/containers/podman-desktop/pull/4633" target="_blank" rel="noopener noreferrer">#4633</a></li>
<li>Documented how to implement api client <a href="https://github.com/containers/podman-desktop/pull/4636" target="_blank" rel="noopener noreferrer">#4636</a></li>
<li>Image checker extension API <a href="https://github.com/containers/podman-desktop/pull/4662" target="_blank" rel="noopener noreferrer">#4662</a></li>
<li>Added api to register cli updater <a href="https://github.com/containers/podman-desktop/pull/5064" target="_blank" rel="noopener noreferrer">#5064</a></li>
</ul>
<hr>
<h2 id="other-notable-enhancements">Other Notable Enhancements<a href="#other-notable-enhancements" aria-label="Direct link to Other Notable Enhancements" title="Direct link to Other Notable Enhancements">‚Äã</a></h2>
<ul>
<li>Show container connection type and endpoint <a href="https://github.com/containers/podman-desktop/pull/5098" target="_blank" rel="noopener noreferrer">#5098</a></li>
<li>Environment column to pods/containers <a href="https://github.com/containers/podman-desktop/pull/4583" target="_blank" rel="noopener noreferrer">#4583</a></li>
<li>Displaying extension icons in the list of extensions <a href="https://github.com/containers/podman-desktop/pull/5101" target="_blank" rel="noopener noreferrer">#5101</a></li>
<li>Introduced UI icon image component <a href="https://github.com/containers/podman-desktop/pull/5117" target="_blank" rel="noopener noreferrer">#5117</a></li>
<li>Added icon to extensionInfo <a href="https://github.com/containers/podman-desktop/pull/5089" target="_blank" rel="noopener noreferrer">#5089</a></li>
<li>Added encoding option on RunOptions <a href="https://github.com/containers/podman-desktop/pull/4942" target="_blank" rel="noopener noreferrer">#4942</a></li>
<li>Introduced property for appearance but for now only dark is supported <a href="https://github.com/containers/podman-desktop/pull/4887" target="_blank" rel="noopener noreferrer">#4887</a></li>
<li>Default table sorting <a href="https://github.com/containers/podman-desktop/pull/4860" target="_blank" rel="noopener noreferrer">#4860</a></li>
<li>Display notification for completed onboarding in task manager <a href="https://github.com/containers/podman-desktop/pull/4811" target="_blank" rel="noopener noreferrer">#4811</a></li>
<li>Added purple dot when new content is available in dashboard <a href="https://github.com/containers/podman-desktop/pull/4782" target="_blank" rel="noopener noreferrer">#4782</a></li>
<li>Argos CI: Introduce Argos CI to track and detect visual regressions on the website</li>
<li>Added command palette: add enablement property <a href="https://github.com/containers/podman-desktop/pull/4630" target="_blank" rel="noopener noreferrer">#4630</a></li>
<li>Added documentation for telemetry and usage data <a href="https://github.com/containers/podman-desktop/pull/4619" target="_blank" rel="noopener noreferrer">#4618</a></li>
<li>Introduced table component <a href="https://github.com/containers/podman-desktop/pull/4545" target="_blank" rel="noopener noreferrer">#4545</a></li>
<li>Added ability to abort build image <a href="https://github.com/containers/podman-desktop/pull/4538" target="_blank" rel="noopener noreferrer">#4538</a></li>
<li>Added support in command palette for category <a href="https://github.com/containers/podman-desktop/pull/4531" target="_blank" rel="noopener noreferrer">#4531</a></li>
<li>Upgraded flatpak to org.freedesktop.Platform version 23.08 <a href="https://github.com/containers/podman-desktop/pull/3968" target="_blank" rel="noopener noreferrer">#3968</a></li>
<li>Added open exposed url to pod details <a href="https://github.com/containers/podman-desktop/pull/3762" target="_blank" rel="noopener noreferrer">#3762</a></li>
</ul>
<hr>
<h2 id="notable-bug-fixes">Notable Bug Fixes<a href="#notable-bug-fixes" aria-label="Direct link to Notable Bug Fixes" title="Direct link to Notable Bug Fixes">‚Äã</a></h2>
<ul>
<li>Fix reconnect to <code>/events</code> if disconnected <a href="https://github.com/containers/podman-desktop/pull/4809" target="_blank" rel="noopener noreferrer">#4809</a></li>
<li>fix: reset loggerhandlerKey after restarting machine <a href="https://github.com/containers/podman-desktop/pull/5168" target="_blank" rel="noopener noreferrer">#5168</a></li>
<li>fix: fix: podman machine created with wrong flags <a href="https://github.com/containers/podman-desktop/pull/5178" target="_blank" rel="noopener noreferrer">#5178</a></li>
<li>fix: avoid to crash if configuration is invalid <a href="https://github.com/containers/podman-desktop/pull/5182" target="_blank" rel="noopener noreferrer">#5182</a></li>
<li>fix: extension installation checks architecture and os <a href="https://github.com/containers/podman-desktop/pull/5191" target="_blank" rel="noopener noreferrer">#5191</a></li>
<li>fix: use URL for proxy specification and add validation <a href="https://github.com/containers/podman-desktop/pull/4825" target="_blank" rel="noopener noreferrer">#4825</a></li>
<li>fix: do not change color and underline of markdown buttons <a href="https://github.com/containers/podman-desktop/pull/5138" target="_blank" rel="noopener noreferrer">#5138</a></li>
<li>fix: do not reconnect when connection is removed <a href="https://github.com/containers/podman-desktop/pull/5131" target="_blank" rel="noopener noreferrer">#5131</a></li>
<li>fix: table headers shouldn't allow text selection <a href="https://github.com/containers/podman-desktop/pull/5118" target="_blank" rel="noopener noreferrer">#5118</a></li>
<li>fix: add style to link <a href="https://github.com/containers/podman-desktop/pull/5108" target="_blank" rel="noopener noreferrer">#5108</a></li>
<li>fix: launch.json references wrong script <a href="https://github.com/containers/podman-desktop/pull/5094" target="_blank" rel="noopener noreferrer">#5094</a></li>
<li>fix: don't link to k8s cluster server <a href="https://github.com/containers/podman-desktop/pull/5087" target="_blank" rel="noopener noreferrer">5087</a></li>
<li>fix: pass the complete imageInfo to the check function <a href="https://github.com/containers/podman-desktop/pull/5069" target="_blank" rel="noopener noreferrer">#5069</a></li>
<li>fix: container tabs should match pods <a href="https://github.com/containers/podman-desktop/pull/5057" target="_blank" rel="noopener noreferrer">#5057</a></li>
<li>fix: revert styling of disabled buttons <a href="https://github.com/containers/podman-desktop/pull/5056" target="_blank" rel="noopener noreferrer">#5056</a></li>
<li>fix: update current context reactively <a href="https://github.com/containers/podman-desktop/pull/5055" target="_blank" rel="noopener noreferrer">#5055</a></li>
<li>fix: make ProviderResultPage do not change input values <a href="https://github.com/containers/podman-desktop/pull/5030" target="_blank" rel="noopener noreferrer">#5030</a></li>
<li>fix: add rowgroup to tables <a href="https://github.com/containers/podman-desktop/pull/5005" target="_blank" rel="noopener noreferrer">#5005</a></li>
<li>fix: add path prop for route object <a href="https://github.com/containers/podman-desktop/pull/4981" target="_blank" rel="noopener noreferrer">#4981</a></li>
<li>fix: remove errant hash mark <a href="https://github.com/containers/podman-desktop/pull/4971" target="_blank" rel="noopener noreferrer">#4971</a></li>
<li>fix: check extension folder contains package.json <a href="https://github.com/containers/podman-desktop/pull/4964" target="_blank" rel="noopener noreferrer">#4964</a></li>
<li>fix: refactor List UI components <a href="https://github.com/containers/podman-desktop/pull/4953" target="_blank" rel="noopener noreferrer">#4953</a></li>
<li>fix: succeeded/completed state for Compose onboarding <a href="https://github.com/containers/podman-desktop/pull/4947" target="_blank" rel="noopener noreferrer">#4947</a></li>
<li>fix: remove flex class from markdown button rendering <a href="https://github.com/containers/podman-desktop/pull/4934" target="_blank" rel="noopener noreferrer">#4934</a></li>
<li>fix: unable to read wsl version when using chinese as syslang on Windows <a href="https://github.com/containers/podman-desktop/pull/4918" target="_blank" rel="noopener noreferrer">#4918</a></li>
<li>fix: retain autostart setting <a href="https://github.com/containers/podman-desktop/pull/4879" target="_blank" rel="noopener noreferrer">#4879</a></li>
<li>fix: use vi.waitUtnil instead of cycles with awaiting promises <a href="https://github.com/containers/podman-desktop/pull/4861" target="_blank" rel="noopener noreferrer">#4861</a></li>
<li>fix: docker host on windows when executing compose command <a href="https://github.com/containers/podman-desktop/pull/4855" target="_blank" rel="noopener noreferrer">#4855</a></li>
<li>fix: merged compose deploy to kube page in UI <a href="https://github.com/containers/podman-desktop/pull/4827" target="_blank" rel="noopener noreferrer">#4827</a></li>
<li>fix: use URL for proxy specification and add validation <a href="https://github.com/containers/podman-desktop/pull/4825" target="_blank" rel="noopener noreferrer">#4825</a></li>
<li>fix: reconnect to /events if disconnected <a href="https://github.com/containers/podman-desktop/pull/4809" target="_blank" rel="noopener noreferrer">#4809</a></li>
<li>fix: remove fixed height after patternfly removal <a href="https://github.com/containers/podman-desktop/pull/4804" target="_blank" rel="noopener noreferrer">#4804</a></li>
<li>fix background colours after patternfly removal <a href="https://github.com/containers/podman-desktop/pull/4803" target="_blank" rel="noopener noreferrer">#4803</a></li>
<li>fix: report metrics for stopped machines <a href="https://github.com/containers/podman-desktop/pull/4787" target="_blank" rel="noopener noreferrer">#4787</a></li>
<li>chore: update to docusaurus v3.0.0 <a href="https://github.com/containers/podman-desktop/pull/4764" target="_blank" rel="noopener noreferrer">#4764</a></li>
<li>chore: drop patternfly <a href="https://github.com/containers/podman-desktop/pull/4762" target="_blank" rel="noopener noreferrer">#4762</a></li>
<li>fix: avoid to send telemetry usage as this method is called every 5s <a href="https://github.com/containers/podman-desktop/pull/4692" target="_blank" rel="noopener noreferrer">#4692</a></li>
<li>fix: location of roots.exe in devmode <a href="https://github.com/containers/podman-desktop/pull/4654" target="_blank" rel="noopener noreferrer">#4654</a></li>
<li>fix: disable create/start container if any port is busy <a href="https://github.com/containers/podman-desktop/pull/4637" target="_blank" rel="noopener noreferrer">#4637</a></li>
<li>fix: fix setup in build image tests <a href="https://github.com/containers/podman-desktop/pull/4625" target="_blank" rel="noopener noreferrer">#4625</a></li>
<li>fix: find a free port <a href="https://github.com/containers/podman-desktop/pull/4616" target="_blank" rel="noopener noreferrer">#4616</a></li>
<li>fix: reduce size of provider cards on the dashboard <a href="https://github.com/containers/podman-desktop/pull/4615" target="_blank" rel="noopener noreferrer">#4615</a></li>
<li>fix: shorter doc nav section titles <a href="https://github.com/containers/podman-desktop/pull/4613" target="_blank" rel="noopener noreferrer">#4613</a></li>
<li>fix: report error if container engine action fails in details page <a href="https://github.com/containers/podman-desktop/pull/4556" target="_blank" rel="noopener noreferrer">#4556</a></li>
<li>fix: remove prev/next bar <a href="https://github.com/containers/podman-desktop/pull/4548" target="_blank" rel="noopener noreferrer">#4548</a></li>
<li>fix: reduce website footer <a href="https://github.com/containers/podman-desktop/pull/4546" target="_blank" rel="noopener noreferrer">#4546</a></li>
<li>fix: handle compose format json that is no longer a JSON array object <a href="https://github.com/containers/podman-desktop/pull/4540" target="_blank" rel="noopener noreferrer">#4540</a></li>
<li>fix: disable push to kind menu item if pushing is in progress <a href="https://github.com/containers/podman-desktop/pull/4530" target="_blank" rel="noopener noreferrer">#4530</a></li>
<li>fix: check for self signed cert message and use insecure param when editing registry password <a href="https://github.com/containers/podman-desktop/pull/4523" target="_blank" rel="noopener noreferrer">#4523</a></li>
<li>fix: add autoscroll to summary pages <a href="https://github.com/containers/podman-desktop/pull/4504" target="_blank" rel="noopener noreferrer">#4504</a></li>
<li>fix: report errors when analyzing extensions <a href="https://github.com/containers/podman-desktop/pull/4380" target="_blank" rel="noopener noreferrer">#4380</a></li>
<li>fix: allow editing of build containerfile <a href="https://github.com/containers/podman-desktop/pull/4471" target="_blank" rel="noopener noreferrer">#4471</a></li>
<li>refactor: updated compose onboarding installation <a href="https://github.com/containers/podman-desktop/pull/4479" target="_blank" rel="noopener noreferrer">#4479</a></li>
<li>refactor: remove compose from the status bar <a href="https://github.com/containers/podman-desktop/pull/4492" target="_blank" rel="noopener noreferrer">#4492</a></li>
</ul>
<hr>
<h2 id="documentation">Documentation<a href="#documentation" aria-label="Direct link to Documentation" title="Direct link to Documentation">‚Äã</a></h2>
<p>Coming with this new version of ü¶≠ Podman Desktop, the documentation has been getting the following improvements:</p>
<ul>
<li>Reorganize doc navigation by provider <a href="https://github.com/containers/podman-desktop/pull/4558" target="_blank" rel="noopener noreferrer">#4558</a></li>
<li>Added vsc runtime dependency for Windows development <a href="https://github.com/containers/podman-desktop/pull/5091" target="_blank" rel="noopener noreferrer">#5091</a></li>
<li>Show location of lima podman socket <a href="https://github.com/containers/podman-desktop/pull/5090" target="_blank" rel="noopener noreferrer">#5090</a></li>
<li>Fixed typo in URI for releases <a href="https://github.com/containers/podman-desktop/pull/4909" target="_blank" rel="noopener noreferrer">#4909</a></li>
<li>Explain how to create an onboarding workflow for an extension <a href="https://github.com/containers/podman-desktop/pull/4837" target="_blank" rel="noopener noreferrer">#4837</a></li>
<li>Make it possible for lima to provide both <a href="https://github.com/containers/podman-desktop/pull/4789" target="_blank" rel="noopener noreferrer">#4789</a></li>
<li>Blog post about minikube/sharing images <a href="https://github.com/containers/podman-desktop/pull/4735" target="_blank" rel="noopener noreferrer">#4735</a></li>
<li>Remove duplicate text from windows troubleshooting <a href="https://github.com/containers/podman-desktop/pull/4652" target="_blank" rel="noopener noreferrer">#4652</a></li>
<li>Add step to implement api client <a href="https://github.com/containers/podman-desktop/pull/4636" target="_blank" rel="noopener noreferrer">#4636</a></li>
<li>Fixed the main lima command for limactl <a href="https://github.com/containers/podman-desktop/pull/4623" target="_blank" rel="noopener noreferrer">#4623</a></li>
<li>Lima provider cleanup after the improvements in the implementation <a href="https://github.com/containers/podman-desktop/pull/4622" target="_blank" rel="noopener noreferrer">#4622</a></li>
<li>Update documentation regarding auto merge <a href="https://github.com/containers/podman-desktop/pull/4519" target="_blank" rel="noopener noreferrer">#4519</a></li>
<li>Using standard OS tabs for registries docs <a href="https://github.com/containers/podman-desktop/pull/4497" target="_blank" rel="noopener noreferrer">#4497</a></li>
<li>Fixed mahine -&gt; machine <a href="https://github.com/containers/podman-desktop/pull/4495" target="_blank" rel="noopener noreferrer">#4495</a></li>
<li>Added screenshots and fixed formatting to the registries section <a href="https://github.com/containers/podman-desktop/pull/4472" target="_blank" rel="noopener noreferrer">#4472</a></li>
</ul>
<hr>

<p>üéâ We‚Äôd like to say a big thank you to everyone who helped to make ü¶≠ Podman Desktop even better. In this
release we received pull requests from the following people:</p>
<ul>
<li>
<p><a href="https://github.com/afbjorklund" target="_blank" rel="noopener noreferrer">afbjorklund</a> in <a href="https://github.com/containers/podman-desktop/pull/4547" target="_blank" rel="noopener noreferrer">fix: add website target for running vale </a>, <a href="https://github.com/containers/podman-desktop/pull/4623" target="_blank" rel="noopener noreferrer">docs: the main lima command is limactl</a>, <a href="https://github.com/containers/podman-desktop/pull/4622" target="_blank" rel="noopener noreferrer"> docs: lima provider cleanup after the merge</a>, <a href="https://github.com/containers/podman-desktop/pull/4789" target="_blank" rel="noopener noreferrer">docs: make it possible for lima to provide both</a>, <a href="https://github.com/containers/podman-desktop/pull/5087" target="_blank" rel="noopener noreferrer">fix: don't link to k8s cluster server</a>, <a href="https://github.com/containers/podman-desktop/pull/5088" target="_blank" rel="noopener noreferrer">feat: show the k8s namespace</a>, <a href="https://github.com/containers/podman-desktop/pull/5090" target="_blank" rel="noopener noreferrer">docs: show location of lima podman socket</a></p>
</li>
<li>
<p><a href="https://github.com/axel7083" target="_blank" rel="noopener noreferrer">axel7083</a> in <a href="https://github.com/containers/podman-desktop/pull/3728" target="_blank" rel="noopener noreferrer">refactoring: item formats from renderer/preferences in separate files</a>, <a href="https://github.com/containers/podman-desktop/pull/4364" target="_blank" rel="noopener noreferrer">feat: adding optional abort controller to dockerode api</a></p>
</li>
<li>
<p><a href="https://github.com/ReadingShades" target="_blank" rel="noopener noreferrer">ReadingShades</a> in <a href="https://github.com/containers/podman-desktop/pull/4245" target="_blank" rel="noopener noreferrer">docs: Added the environment variable set commands of the common windows terminal emulators</a></p>
</li>
<li>
<p><a href="https://github.com/jannikbertram" target="_blank" rel="noopener noreferrer">jannikbertram</a> in <a href="https://github.com/containers/podman-desktop/pull/4457" target="_blank" rel="noopener noreferrer">chore: add close button to troubleshooting and help page</a></p>
</li>
<li>
<p><a href="https://github.com/singodiyashubham87" target="_blank" rel="noopener noreferrer">singodiyashubham87</a> in <a href="https://github.com/containers/podman-desktop/pull/4494" target="_blank" rel="noopener noreferrer">fix: header line height issue on website</a></p>
</li>
<li>
<p><a href="https://github.com/edvardsanta" target="_blank" rel="noopener noreferrer">edvardsanta</a> in <a href="https://github.com/containers/podman-desktop/pull/4518" target="_blank" rel="noopener noreferrer">feat: remove redundant naming in buttons</a></p>
</li>
<li>
<p><a href="https://github.com/Mayureshd-18" target="_blank" rel="noopener noreferrer">Mayureshd-18</a> in <a href="https://github.com/containers/podman-desktop/pull/4551" target="_blank" rel="noopener noreferrer">fix typos</a></p>
</li>
<li>
<p><a href="https://github.com/jgelens" target="_blank" rel="noopener noreferrer">jgelens</a> in <a href="https://github.com/containers/podman-desktop/pull/4609" target="_blank" rel="noopener noreferrer">Fix rootless command</a></p>
</li>
<li>
<p><a href="https://github.com/itecompro" target="_blank" rel="noopener noreferrer">itecompro</a> in <a href="https://github.com/containers/podman-desktop/pull/4652" target="_blank" rel="noopener noreferrer">docs: remove duplicate text from windows troubleshooting</a></p>
</li>
<li>
<p><a href="https://github.com/EricSmekens" target="_blank" rel="noopener noreferrer">EricSmekens</a> in <a href="https://github.com/containers/podman-desktop/pull/4909" target="_blank" rel="noopener noreferrer">docs: Fixed typo in URI for releases</a></p>
</li>
<li>
<p><a href="https://github.com/ecrookshanks-rh" target="_blank" rel="noopener noreferrer">ecrookshanks-rh</a> in <a href="https://github.com/containers/podman-desktop/pull/5095" target="_blank" rel="noopener noreferrer">fix: added text beside icon for create pods </a></p>
</li>
</ul>
<hr>
<h2 id="final-notes">Final notes<a href="#final-notes" aria-label="Direct link to Final notes" title="Direct link to Final notes">‚Äã</a></h2>
<h3 id="fixed-issues">Fixed Issues<a href="#fixed-issues" aria-label="Direct link to Fixed Issues" title="Direct link to Fixed Issues">‚Äã</a></h3>
<p>The complete list of issues fixed in this release is available <a href="https://github.com/containers/podman-desktop/issues?q=is%3Aclosed+milestone%3A1.6.0" target="_blank" rel="noopener noreferrer">here</a>.</p>
<h3 id="where-to-download">Where to Download<a href="#where-to-download" aria-label="Direct link to Where to Download" title="Direct link to Where to Download">‚Äã</a></h3>
<p>Get the latest release from the <a href="https://podman-desktop.io/downloads">Downloads</a> section of the website and boost your development journey with Podman Desktop. Additionally, visit the <a href="https://github.com/containers/podman-desktop" target="_blank" rel="noopener noreferrer">GitHub repository</a> and see how you can help us make Podman Desktop better.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Minimal implementation of Mamba, the new LLM architecture, in 1 file of PyTorch (177 pts)]]></title>
            <link>https://github.com/johnma2006/mamba-minimal</link>
            <guid>38708730</guid>
            <pubDate>Wed, 20 Dec 2023 13:58:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/johnma2006/mamba-minimal">https://github.com/johnma2006/mamba-minimal</a>, See on <a href="https://news.ycombinator.com/item?id=38708730">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">mamba-minimal</h2>
<p dir="auto">Simple, minimal implementation of Mamba in one file of PyTorch.</p>
<p dir="auto">Featuring:</p>
<ul dir="auto">
<li>Equivalent numerical output as official implementation for both forward and backward pass</li>
<li>Simplified, readable, annotated code</li>
</ul>
<p dir="auto">Does NOT include:</p>
<ul dir="auto">
<li>Speed. The official implementation is heavily optimized, and these optimizations are core contributions of the Mamba paper. I kept most implementations simple for readability.</li>
<li>Proper parameter initialization (though this could be added without sacrificing readability)</li>
</ul>
<h2 tabindex="-1" dir="auto">Demo</h2>
<p dir="auto">See <a href="https://github.com/johnma2006/mamba-minimal/blob/master/demo.ipynb">demo.ipynb</a> for examples of prompt completions.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from model import Mamba
from transformers import AutoTokenizer

model = Mamba.from_pretrained('state-spaces/mamba-370m')
tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neox-20b')

generate(model, tokenizer, 'Mamba is the')"><pre><span>from</span> <span>model</span> <span>import</span> <span>Mamba</span>
<span>from</span> <span>transformers</span> <span>import</span> <span>AutoTokenizer</span>

<span>model</span> <span>=</span> <span>Mamba</span>.<span>from_pretrained</span>(<span>'state-spaces/mamba-370m'</span>)
<span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span>.<span>from_pretrained</span>(<span>'EleutherAI/gpt-neox-20b'</span>)

<span>generate</span>(<span>model</span>, <span>tokenizer</span>, <span>'Mamba is the'</span>)</pre></div>
<blockquote>
<p dir="auto">Mamba is the world's longest venomous snake with an estimated length of over 150 m. With such a large size and a venomous bite, Mamba kills by stabbing the victim (which is more painful and less effective than a single stab of the bite)</p>
</blockquote>
<p dir="auto">150 meters... ü´¢ scary!</p>
<h2 tabindex="-1" dir="auto">References</h2>
<p dir="auto">The Mamba architecture was introduced in <a href="https://arxiv.org/abs/2312.00752" rel="nofollow">Mamba: Linear-Time Sequence Modeling with Selective State Spaces</a> by <a href="https://twitter.com/_albertgu?lang=en" rel="nofollow">Albert Gu</a> and <a href="https://twitter.com/tri_dao?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor" rel="nofollow">Tri Dao</a>.</p>
<p dir="auto">The official implementation is here: <a href="https://github.com/state-spaces/mamba/tree/main">https://github.com/state-spaces/mamba/tree/main</a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[High-Speed Large Language Model Serving on PCs with Consumer-Grade GPUs (130 pts)]]></title>
            <link>https://github.com/SJTU-IPADS/PowerInfer</link>
            <guid>38708585</guid>
            <pubDate>Wed, 20 Dec 2023 13:46:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/SJTU-IPADS/PowerInfer">https://github.com/SJTU-IPADS/PowerInfer</a>, See on <a href="https://news.ycombinator.com/item?id=38708585">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU</h2>
<h2 tabindex="-1" dir="auto">TL;DR</h2>
<p dir="auto">PowerInfer is a CPU/GPU LLM inference engine leveraging <strong>activation locality</strong> for your device.</p>
<h2 tabindex="-1" dir="auto">Demo üî•</h2>
<details open="">
  <summary>
    
    <span aria-label="Video description powerinfer-live-demo.mp4">powerinfer-live-demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/34213478/291527562-fe441a42-5fce-448b-a3e5-ea4abb43ba23.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDMwOTU1MDUsIm5iZiI6MTcwMzA5NTIwNSwicGF0aCI6Ii8zNDIxMzQ3OC8yOTE1Mjc1NjItZmU0NDFhNDItNWZjZS00NDhiLWEzZTUtZWE0YWJiNDNiYTIzLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjIwVDE4MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0ZGExMWM0NmZkNTgwZmFkMTY2OWZjOTU3MzA5NzE5MDIwYTczZjcyN2Q1YjViMWNjMDY0N2VhODI2Zjk2ZWUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.RAEralHzdI9AUwAumXhsGyezEKButqUlZSWeoE4S_TE" data-canonical-src="https://private-user-images.githubusercontent.com/34213478/291527562-fe441a42-5fce-448b-a3e5-ea4abb43ba23.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDMwOTU1MDUsIm5iZiI6MTcwMzA5NTIwNSwicGF0aCI6Ii8zNDIxMzQ3OC8yOTE1Mjc1NjItZmU0NDFhNDItNWZjZS00NDhiLWEzZTUtZWE0YWJiNDNiYTIzLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjIwVDE4MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0ZGExMWM0NmZkNTgwZmFkMTY2OWZjOTU3MzA5NzE5MDIwYTczZjcyN2Q1YjViMWNjMDY0N2VhODI2Zjk2ZWUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.RAEralHzdI9AUwAumXhsGyezEKButqUlZSWeoE4S_TE" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">PowerInfer v.s. llama.cpp on a single RTX 4090(24G) running Falcon(ReLU)-40B-FP16 with a 11x speedup!</p>
<p dir="auto"><sub>Both PowerInfer and llama.cpp were running on the same hardware and fully utilized VRAM on RTX 4090.</sub></p>
<h2 tabindex="-1" dir="auto">Abstract</h2>
<p dir="auto">We introduce PowerInfer, a high-speed Large Language Model (LLM) inference engine on a personal computer (PC)
equipped with a single consumer-grade GPU. The key underlying the design of PowerInfer is exploiting the high <strong>locality</strong>
inherent in LLM inference, characterized by a power-law distribution in neuron activation.</p>
<p dir="auto">This distribution indicates that a small subset of neurons, termed hot neurons, are consistently activated
across inputs, while the majority, cold neurons, vary based on specific inputs.
PowerInfer exploits such an insight to design a GPU-CPU hybrid inference engine:
hot-activated neurons are preloaded onto the GPU for fast access, while cold-activated neurons are computed
on the CPU, thus significantly reducing GPU memory demands and CPU-GPU data transfers.
PowerInfer further integrates adaptive predictors and neuron-aware sparse operators,
optimizing the efficiency of neuron activation and computational sparsity.</p>
<p dir="auto">Evaluation shows that PowerInfer attains an average token generation rate of 13.20 tokens/s, with a peak of 29.08 tokens/s, across various LLMs (including OPT-175B) on a single NVIDIA RTX 4090 GPU,
only 18% lower than that achieved by a top-tier server-grade A100 GPU.
This significantly outperforms llama.cpp by up to 11.69x while retaining model accuracy.</p>
<h2 tabindex="-1" dir="auto">Features</h2>
<p dir="auto">PowerInfer is a high-speed and easy-to-use inference engine for deploying LLMs locally.</p>
<p dir="auto">PowerInfer is fast with:</p>
<ul dir="auto">
<li><strong>Locality-centric design</strong>: Utilizes sparse activation and 'hot'/'cold' neuron concept for efficient LLM inference, ensuring high speed with lower resource demands.</li>
<li><strong>Hybrid CPU/GPU Utilization</strong>: Seamlessly integrates memory/computation capabilities of CPU and GPU for a balanced workload and faster processing.</li>
</ul>
<p dir="auto">PowerInfer is flexible and easy to use with:</p>
<ul dir="auto">
<li><strong>Easy Integration</strong>: Compatible with popular <a href="https://huggingface.co/SparseLLM" rel="nofollow">ReLU-sparse models</a>.</li>
<li><strong>Local Deployment Ease</strong>: Designed and deeply optimized for local deployment on consumer-grade hardware, enabling low-latency LLM inference and serving on a single GPU.</li>
<li><strong>Backward Compatibility</strong>: While distinct from llama.cpp, you can make use of most of <code>examples/</code> the same way as llama.cpp such as server and batched generation. PowerInfer also supports inference with llama.cpp's model weights for compatibility purposes, but there will be no performance gain.</li>
</ul>
<p dir="auto">You can use these models with PowerInfer today:</p>
<ul dir="auto">
<li>Falcon-40B</li>
<li>Llama2 family</li>
</ul>
<p dir="auto">We have tested PowerInfer on the following platforms:</p>
<ul dir="auto">
<li>x86-64 CPU (with AVX2 instructions) on Linux</li>
<li>x86-64 CPU and NVIDIA GPU on Linux</li>
<li>Apple M Chips on macOS (As we do not optimize for Mac, the performance improvement is not significant now.)</li>
</ul>
<p dir="auto">And new features coming soon:</p>
<ul dir="auto">
<li>Mistral-7B model</li>
<li>Metal backend for sparse inference on macOS</li>
</ul>
<h2 tabindex="-1" dir="auto">Getting Started</h2>
<ul dir="auto">
<li><a href="#setup-and-installation">Installation</a></li>
<li><a href="#model-weights">Model Weights</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Setup and Installation</h2>
<h3 tabindex="-1" dir="auto">Get the Code</h3>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/SJTU-IPADS/PowerInfer
cd PowerInfer
pip install -r requirements.txt # install Python helpers' dependencies"><pre>git clone https://github.com/SJTU-IPADS/PowerInfer
<span>cd</span> PowerInfer
pip install -r requirements.txt <span><span>#</span> install Python helpers' dependencies</span></pre></div>
<h3 tabindex="-1" dir="auto">Build</h3>
<p dir="auto">In order to build PowerInfer you have two different options. These commands are supposed to be run from the root directory of the project.</p>
<p dir="auto">Using <code>CMake</code>(3.13+) on Linux or macOS:</p>
<ul dir="auto">
<li>If you have an NVIDIA GPU:</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="cmake -S . -B build -DLLAMA_CUBLAS=ON
cmake --build build --config Release"><pre>cmake -S <span>.</span> -B build -DLLAMA_CUBLAS=ON
cmake --build build --config Release</pre></div>
<ul dir="auto">
<li>If you just CPU:</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="cmake -S . -B build
cmake --build build --config Release"><pre>cmake -S <span>.</span> -B build
cmake --build build --config Release</pre></div>
<h2 tabindex="-1" dir="auto">Model Weights</h2>
<p dir="auto">PowerInfer models are stored in a special format called <em>PowerInfer GGUF</em> based on GGUF format, consisting of both LLM weights and predictor weights.</p>
<h3 tabindex="-1" dir="auto">Download PowerInfer GGUF via Hugging Face</h3>
<p dir="auto">You can obtain PowerInfer GGUF weights at <code>*.powerinfer.gguf</code> as well as profiled model activation statistics for 'hot'-neuron offloading from each Hugging Face repo below.</p>
<table>
<thead>
<tr>
<th>Base Model</th>
<th>PowerInfer GGUF</th>
</tr>
</thead>
<tbody>
<tr>
<td>LLaMA(ReLU)-2-7B</td>
<td><a href="https://huggingface.co/PowerInfer/ReluLLaMA-7B-PowerInfer-GGUF" rel="nofollow">PowerInfer/ReluLLaMA-7B-PowerInfer-GGUF</a></td>
</tr>
<tr>
<td>LLaMA(ReLU)-2-13B</td>
<td><a href="https://huggingface.co/PowerInfer/ReluLLaMA-13B-PowerInfer-GGUF" rel="nofollow">PowerInfer/ReluLLaMA-13B-PowerInfer-GGUF</a></td>
</tr>
<tr>
<td>Falcon(ReLU)-40B</td>
<td><a href="https://huggingface.co/PowerInfer/ReluFalcon-40B-PowerInfer-GGUF" rel="nofollow">PowerInfer/ReluFalcon-40B-PowerInfer-GGUF</a></td>
</tr>
<tr>
<td>LLaMA(ReLU)-2-70B</td>
<td><a href="https://huggingface.co/PowerInfer/ReluLLaMA-70B-PowerInfer-GGUF" rel="nofollow">PowerInfer/ReluLLaMA-70B-PowerInfer-GGUF</a></td>
</tr>
</tbody>
</table>
<p dir="auto">We suggest downloading/cloning the whole repo so PowerInfer can automatically make use of such directory structure for feature-complete model offloading:</p>
<div data-snippet-clipboard-copy-content=".
‚îú‚îÄ‚îÄ *.powerinfer.gguf (Unquantized PowerInfer model)
‚îú‚îÄ‚îÄ *.q4.powerinfer.gguf (INT4 quantized PowerInfer model, if available)
‚îú‚îÄ‚îÄ activation (Profiled activation statistics for fine-grained FFN offloading)
‚îÇ   ‚îú‚îÄ‚îÄ activation_x.pt (Profiled activation statistics for layer x)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ *.[q4].powerinfer.gguf.generated.gpuidx (Generated GPU index at runtime for corresponding model)"><pre><code>.
‚îú‚îÄ‚îÄ *.powerinfer.gguf (Unquantized PowerInfer model)
‚îú‚îÄ‚îÄ *.q4.powerinfer.gguf (INT4 quantized PowerInfer model, if available)
‚îú‚îÄ‚îÄ activation (Profiled activation statistics for fine-grained FFN offloading)
‚îÇ   ‚îú‚îÄ‚îÄ activation_x.pt (Profiled activation statistics for layer x)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ *.[q4].powerinfer.gguf.generated.gpuidx (Generated GPU index at runtime for corresponding model)
</code></pre></div>
<h3 tabindex="-1" dir="auto">Convert from Original Model Weights + Predictor Weights</h3>
<p dir="auto">Hugging Face limits single model weight to 50GiB. For unquantized models &gt;= 40B, you can convert PowerInfer GGUF from the original model weights and predictor weights obtained from Hugging Face.</p>
<table>
<thead>
<tr>
<th>Base Model</th>
<th>Original Model</th>
<th>Predictor</th>
</tr>
</thead>
<tbody>
<tr>
<td>LLaMA(ReLU)-2-7B</td>
<td><a href="https://huggingface.co/SparseLLM/ReluLLaMA-7B" rel="nofollow">SparseLLM/ReluLLaMA-7B</a></td>
<td><a href="https://huggingface.co/PowerInfer/ReluLLaMA-7B-Predictor" rel="nofollow">PowerInfer/ReluLLaMA-7B-Predictor</a></td>
</tr>
<tr>
<td>LLaMA(ReLU)-2-13B</td>
<td><a href="https://huggingface.co/SparseLLM/ReluLLaMA-13B" rel="nofollow">SparseLLM/ReluLLaMA-13B</a></td>
<td><a href="https://huggingface.co/PowerInfer/ReluLLaMA-13B-Predictor" rel="nofollow">PowerInfer/ReluLLaMA-13B-Predictor</a></td>
</tr>
<tr>
<td>Falcon(ReLU)-40B</td>
<td><a href="https://huggingface.co/SparseLLM/ReluFalcon-40B" rel="nofollow">SparseLLM/ReluFalcon-40B</a></td>
<td><a href="https://huggingface.co/PowerInfer/ReluFalcon-40B-Predictor" rel="nofollow">PowerInfer/ReluFalcon-40B-Predictor</a></td>
</tr>
<tr>
<td>LLaMA(ReLU)-2-70B</td>
<td><a href="https://huggingface.co/SparseLLM/ReluLLaMA-70B" rel="nofollow">SparseLLM/ReluLLaMA-70B</a></td>
<td><a href="https://huggingface.co/PowerInfer/ReluLLaMA-70B-Predictor" rel="nofollow">PowerInfer/ReluLLaMA-70B-Predictor</a></td>
</tr>
</tbody>
</table>
<p dir="auto">You can use the following command to convert the original model weights and predictor weights to PowerInfer GGUF:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# make sure that you have done `pip install -r requirements.txt`
python convert.py --outfile /PATH/TO/POWERINFER/GGUF/REPO/MODELNAME.powerinfer.gguf /PATH/TO/ORIGINAL/MODEL /PATH/TO/PREDICTOR
# python convert.py --outfile ./ReluLLaMA-70B-PowerInfer-GGUF/llama-70b-relu.powerinfer.gguf ./SparseLLM/ReluLLaMA-70B ./PowerInfer/ReluLLaMA-70B-Predictor"><pre><span><span>#</span> make sure that you have done `pip install -r requirements.txt`</span>
python convert.py --outfile /PATH/TO/POWERINFER/GGUF/REPO/MODELNAME.powerinfer.gguf /PATH/TO/ORIGINAL/MODEL /PATH/TO/PREDICTOR
<span><span>#</span> python convert.py --outfile ./ReluLLaMA-70B-PowerInfer-GGUF/llama-70b-relu.powerinfer.gguf ./SparseLLM/ReluLLaMA-70B ./PowerInfer/ReluLLaMA-70B-Predictor</span></pre></div>
<p dir="auto">For the same reason, we suggest keeping the same directory structure as PowerInfer GGUF repos after conversion.</p>
<h2 tabindex="-1" dir="auto">Inference</h2>
<p dir="auto">For CPU-only and CPU-GPU hybrid inference with all available VRAM, you can use the following instructions to run PowerInfer:</p>
<div dir="auto" data-snippet-clipboard-copy-content="./build/bin/main -m /PATH/TO/MODEL -n $output_token_count -t $thread_num -p $prompt
# ./build/bin/main -m ./ReluFalcon-40B-PowerInfer-GGUF/falcon-40b-relu.q4.powerinfer.gguf -n 128 -t 8 -p &quot;Once upon a time&quot;"><pre>./build/bin/main -m /PATH/TO/MODEL -n <span>$output_token_count</span> -t <span>$thread_num</span> -p <span>$prompt</span>
<span><span>#</span> ./build/bin/main -m ./ReluFalcon-40B-PowerInfer-GGUF/falcon-40b-relu.q4.powerinfer.gguf -n 128 -t 8 -p "Once upon a time"</span></pre></div>
<p dir="auto">If you want to limit the VRAM usage of GPU:</p>
<div dir="auto" data-snippet-clipboard-copy-content="./build/bin/main -m /PATH/TO/MODEL -n $output_token_count -t $thread_num -p $prompt --vram-budget $vram_gb
# ./build/bin/main -m ./ReluLLaMA-7B-PowerInfer-GGUF/llama-7b-relu.powerinfer.gguf -n 128 -t 8 -p &quot;Once upon a time&quot; --vram-budget 8"><pre>./build/bin/main -m /PATH/TO/MODEL -n <span>$output_token_count</span> -t <span>$thread_num</span> -p <span>$prompt</span> --vram-budget <span>$vram_gb</span>
<span><span>#</span> ./build/bin/main -m ./ReluLLaMA-7B-PowerInfer-GGUF/llama-7b-relu.powerinfer.gguf -n 128 -t 8 -p "Once upon a time" --vram-budget 8</span></pre></div>
<p dir="auto">Under CPU-GPU hybrid inference, PowerInfer will automatically offload all dense activation blocks to GPU and split FFN on GPU if possible.</p>
<h2 tabindex="-1" dir="auto">Quantization</h2>
<p dir="auto">PowerInfer has optimized quantization support for INT4(<code>Q4_0</code>) models. You can use the following instructions to quantize PowerInfer GGUF model:</p>
<div dir="auto" data-snippet-clipboard-copy-content="./build/bin/quantize /PATH/TO/MODEL /PATH/TO/OUTPUT/QUANTIZED/MODEL Q4_0
# ./build/bin/quantize ./ReluFalcon-40B-PowerInfer-GGUF/falcon-40b-relu.powerinfer.gguf ./ReluFalcon-40B-PowerInfer-GGUF/falcon-40b-relu.q4.powerinfer.gguf Q4_0"><pre>./build/bin/quantize /PATH/TO/MODEL /PATH/TO/OUTPUT/QUANTIZED/MODEL Q4_0
<span><span>#</span> ./build/bin/quantize ./ReluFalcon-40B-PowerInfer-GGUF/falcon-40b-relu.powerinfer.gguf ./ReluFalcon-40B-PowerInfer-GGUF/falcon-40b-relu.q4.powerinfer.gguf Q4_0</span></pre></div>
<p dir="auto">Then you can use the quantized model for inference with PowerInfer with the same instructions as above.</p>
<h2 tabindex="-1" dir="auto">Evaluation</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/34213478/290874852-d700fa6c-77ba-462f-a2fc-3fd21c898f33.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDMwOTU1MDUsIm5iZiI6MTcwMzA5NTIwNSwicGF0aCI6Ii8zNDIxMzQ3OC8yOTA4NzQ4NTItZDcwMGZhNmMtNzdiYS00NjJmLWEyZmMtM2ZkMjFjODk4ZjMzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjIwVDE4MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE4OGJmMzRmMjE0MDU0ZTAzMzI5NDIwNzczMjk5ZjY0MjY4Mzk4ODA1ODZjOTk5YjM0M2IzNTliY2Y3OGMxMzEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.yrPVIWOJp317-QUWBGHnMhPSpvnlCb4nvBUgNcNtfx4"><img src="https://private-user-images.githubusercontent.com/34213478/290874852-d700fa6c-77ba-462f-a2fc-3fd21c898f33.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDMwOTU1MDUsIm5iZiI6MTcwMzA5NTIwNSwicGF0aCI6Ii8zNDIxMzQ3OC8yOTA4NzQ4NTItZDcwMGZhNmMtNzdiYS00NjJmLWEyZmMtM2ZkMjFjODk4ZjMzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjIwVDE4MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE4OGJmMzRmMjE0MDU0ZTAzMzI5NDIwNzczMjk5ZjY0MjY4Mzk4ODA1ODZjOTk5YjM0M2IzNTliY2Y3OGMxMzEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.yrPVIWOJp317-QUWBGHnMhPSpvnlCb4nvBUgNcNtfx4" alt="github-eval-4090"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/34213478/290875021-0fc1bfc4-aafc-4e82-a865-bec0143aff1a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDMwOTU1MDUsIm5iZiI6MTcwMzA5NTIwNSwicGF0aCI6Ii8zNDIxMzQ3OC8yOTA4NzUwMjEtMGZjMWJmYzQtYWFmYy00ZTgyLWE4NjUtYmVjMDE0M2FmZjFhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjIwVDE4MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTI3Mjk4NGI1NmMyYmQ0YjQzN2IyMjJhOGQ3NTE0NWNmODkwNDdmZTYxMmZmZjdjMzYwYjhkNTY3NTEyNTY3YTYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.Xr8HPuQ7rUCSyG6fYxXg9NHfhu-pQmFosFc1jJu_N7s"><img src="https://private-user-images.githubusercontent.com/34213478/290875021-0fc1bfc4-aafc-4e82-a865-bec0143aff1a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDMwOTU1MDUsIm5iZiI6MTcwMzA5NTIwNSwicGF0aCI6Ii8zNDIxMzQ3OC8yOTA4NzUwMjEtMGZjMWJmYzQtYWFmYy00ZTgyLWE4NjUtYmVjMDE0M2FmZjFhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMjAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjIwVDE4MDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTI3Mjk4NGI1NmMyYmQ0YjQzN2IyMjJhOGQ3NTE0NWNmODkwNDdmZTYxMmZmZjdjMzYwYjhkNTY3NTEyNTY3YTYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.Xr8HPuQ7rUCSyG6fYxXg9NHfhu-pQmFosFc1jJu_N7s" alt="github-eval-2080ti-q4"></a></p>
<p dir="auto">PowerInfer achieves up to 11x and 8x speedup for FP16 and INT4 models!</p>
<h2 tabindex="-1" dir="auto">FAQs</h2>
<ol dir="auto">
<li>What if I encountered <code>CUDA_ERROR_OUT_OF_MEMORY</code>?
<ul dir="auto">
<li>You can try to run with <code>--reset-gpu-index</code> argument to rebuild the GPU index for this model to avoid any stale cache.</li>
<li>Due to our current implementation, model offloading might not be as accurate as expected. You can try with <code>--vram-budget</code> with a slightly lower value or <code>--disable-gpu-index</code> to disable FFN offloading.</li>
</ul>
</li>
<li>What if...
<ul dir="auto">
<li>Issues are welcomed! Please feel free to open an issue and attach your running environment and running parameters. We will try our best to help you.</li>
</ul>
</li>
</ol>
<h2 tabindex="-1" dir="auto">TODOs</h2>
<p dir="auto">We will release the code and data in the following order, please stay tuned!</p>
<ul>
<li> Release core code of PowerInfer, supporting Llama-2, Falcon-40B.</li>
<li> Support Mistral-7B</li>
<li> Support Windows</li>
<li> Support text-generation-webui</li>
<li> Release perplexity evaluation code</li>
<li> Support Metal for Mac</li>
<li> Release code for OPT models</li>
<li> Release predictor training code</li>
<li> Support online split for FFN network</li>
<li> Support Multi-GPU</li>
</ul>
<h2 tabindex="-1" dir="auto">Paper and Citation</h2>
<p dir="auto">More technical details can be found in our <a href="https://ipads.se.sjtu.edu.cn/_media/publications/powerinfer-20231219.pdf" rel="nofollow">paper</a>.</p>
<p dir="auto">If you find PowerInfer useful or relevant to your project and research, please kindly cite our paper:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@techreport{song2023powerinfer,
  author      = {Yixin Song and Zeyu Mi and Haotong Xie and Haibo Chen},
  title       = {PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU},
  institution = {Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University},
  year        = {2023}
}"><pre><span>@techreport</span>{<span>song2023powerinfer</span>,
  <span>author</span>      = <span><span>{</span>Yixin Song and Zeyu Mi and Haotong Xie and Haibo Chen<span>}</span></span>,
  <span>title</span>       = <span><span>{</span>PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU<span>}</span></span>,
  <span>institution</span> = <span><span>{</span>Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University<span>}</span></span>,
  <span>year</span>        = <span><span>{</span>2023<span>}</span></span>
}</pre></div>
<h2 tabindex="-1" dir="auto">Acknowledgement</h2>
<p dir="auto">We are thankful for the easily modifiable operator library <a href="https://github.com/ggerganov/ggml">ggml</a> and execution runtime provided by <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>. We also extend our gratitude to <a href="https://nlp.csai.tsinghua.edu.cn/" rel="nofollow">THUNLP</a> for their support of ReLU-based sparse models. We also appreciate the research of <a href="https://proceedings.mlr.press/v202/liu23am.html" rel="nofollow">Deja Vu</a>, which inspires PowerInfer.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trying chDB, an embeddable ClickHouse engine (118 pts)]]></title>
            <link>https://antonz.org/trying-chdb/</link>
            <guid>38708436</guid>
            <pubDate>Wed, 20 Dec 2023 13:31:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antonz.org/trying-chdb/">https://antonz.org/trying-chdb/</a>, See on <a href="https://news.ycombinator.com/item?id=38708436">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><header></header><p><a href="https://github.com/chdb-io/chdb">chDB</a> is an embeddable, in-process SQL OLAP engine powered by ClickHouse. It's as if SQLite and ClickHouse had an offspring (no offence to either party). chDB takes up ‚âà100mb of disk space, runs on smaller machines (even on a 64mb RAM container), and provides language bindings for Python, Node.js, Go, Rust and C/C++.</p><p>Let's get a taste of chDB with some interactive examples (you can run/edit them without leaving the browser or installing anything).</p><p><a href="#using-chdb">Using chDB</a> ‚Ä¢
<a href="#sql-dialect">SQL dialect</a> ‚Ä¢
<a href="#reading-data">Reading data</a> ‚Ä¢
<a href="#writing-data">Writing data</a> ‚Ä¢
<a href="#user-defined-functions">User-defined functions</a> ‚Ä¢
<a href="#python-database-api">Python DB API</a> ‚Ä¢
<a href="#current-status">Current status</a></p><h2 id="using-chdb">Using chDB</h2><p>It's as simple as <code>pip install chdb</code> and then:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> <span>chdb</span>
</span></span><span><span>
</span></span><span><span><span>res</span> <span>=</span> <span>chdb</span><span>.</span><span>query</span>(<span>"select 42"</span>)
</span></span><span><span><span>print</span>(<span>res</span>, <span>end</span><span>=</span><span>""</span>)
</span></span></code></pre></div><codapi-snippet sandbox="chdb-python" editor="basic"></codapi-snippet><p>Using a database engine to select the number <code>42</code> is probably not very exciting, but bear with me.</p><h2 id="sql-dialect">SQL dialect</h2><p>chDB is a wrapper around ClickHouse, so it supports exactly the same <a href="https://clickhouse.com/docs/en/sql-reference/syntax">SQL syntax</a>, including joins, CTEs, set operations, aggregations and window functions.</p><p>For example, let's create a sampled table of 10000 random numbers and calculate the mean and 95th percentile:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>chdb.session</span> <span>import</span> <span>Session</span>
</span></span><span><span>
</span></span><span><span><span>db</span> <span>=</span> <span>Session</span>()
</span></span><span><span><span>db</span><span>.</span><span>query</span>(<span>"create database db"</span>)
</span></span><span><span><span>db</span><span>.</span><span>query</span>(<span>"use db"</span>)
</span></span><span><span>
</span></span><span><span><span>db</span><span>.</span><span>query</span>(<span>"""
</span></span></span><span><span><span>create table data (id UInt32, x UInt32)
</span></span></span><span><span><span>engine MergeTree order by id sample by id
</span></span></span><span><span><span>as
</span></span></span><span><span><span>select number+1 as id, randUniform(1, 100) as x
</span></span></span><span><span><span>from numbers(10000);
</span></span></span><span><span><span>"""</span>)
</span></span><span><span>
</span></span><span><span><span>query_sql</span> <span>=</span> <span>"""
</span></span></span><span><span><span>select
</span></span></span><span><span><span>  avg(x) as "avg",
</span></span></span><span><span><span>  round(quantile(0.95)(x), 2) as p95
</span></span></span><span><span><span>from data
</span></span></span><span><span><span>sample 0.1;
</span></span></span><span><span><span>"""</span>
</span></span><span><span>
</span></span><span><span><span>res</span> <span>=</span> <span>db</span><span>.</span><span>query</span>(<span>query_sql</span>, <span>"PrettyCompactNoEscapes"</span>)
</span></span><span><span><span>print</span>(<span>res</span>, <span>end</span><span>=</span><span>""</span>)
</span></span></code></pre></div><codapi-snippet sandbox="chdb-python" editor="basic"></codapi-snippet><p>Note a couple of things here:</p><ul><li><code>Session</code> provides a stateful database connection (the data is stored in the temporary folder and discarded when the connection is closed).</li><li>The second argument to the <code>query</code> method specifies the output format. There are many <a href="https://doc.chdb.io/#/formats">supported formats</a> such as <code>CSV</code>, <code>SQLInsert</code>, <code>JSON</code> and <code>XML</code> (try changing the format in the above example and re-running the code). The default one is <code>CSV</code>.</li></ul><h2 id="reading-data">Reading data</h2><p>As with output formats, chDB supports any input format supported by ClickHouse.</p><p>For example, we can read a dataset from CSV:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>query_sql</span> <span>=</span> <span>"select * from 'employees.csv'"</span>
</span></span><span><span><span>res</span> <span>=</span> <span>chdb</span><span>.</span><span>query</span>(<span>query_sql</span>, <span>"PrettyCompactNoEscapes"</span>)
</span></span><span><span><span>print</span>(
</span></span><span><span>    <span>f</span><span>"</span><span>{</span><span>res</span><span>.</span><span>rows_read</span>()<span>}</span><span> rows | "</span>
</span></span><span><span>    <span>f</span><span>"</span><span>{</span><span>res</span><span>.</span><span>bytes_read</span>()<span>}</span><span> bytes | "</span>
</span></span><span><span>    <span>f</span><span>"</span><span>{</span><span>res</span><span>.</span><span>elapsed</span>()<span>}</span><span> seconds"</span>
</span></span><span><span>)
</span></span></code></pre></div><codapi-snippet sandbox="chdb-python" editor="basic" template="main.py" files="employees.csv"></codapi-snippet><p>Or work with an external dataset as if it were a database table:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>query_sql</span> <span>=</span> <span>"""
</span></span></span><span><span><span>select distinct city
</span></span></span><span><span><span>from 'employees.csv'
</span></span></span><span><span><span>"""</span>
</span></span><span><span>
</span></span><span><span><span>res</span> <span>=</span> <span>chdb</span><span>.</span><span>query</span>(<span>query_sql</span>, <span>"CSV"</span>)
</span></span><span><span><span>print</span>(<span>res</span>, <span>end</span><span>=</span><span>""</span>)
</span></span></code></pre></div><codapi-snippet sandbox="chdb-python" editor="basic" template="main.py" files="employees.csv"></codapi-snippet><p>We can even query Pandas dataframes as if they were tables:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>import</span> <span>chdb.dataframe</span> <span>as</span> <span>cdf</span>
</span></span><span><span><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
</span></span><span><span>
</span></span><span><span><span>employees</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span>(<span>"employees.csv"</span>)
</span></span><span><span><span>departments</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span>(<span>"departments.csv"</span>)
</span></span><span><span>
</span></span><span><span><span>query_sql</span> <span>=</span> <span>"""
</span></span></span><span><span><span>select
</span></span></span><span><span><span>  emp_id, first_name,
</span></span></span><span><span><span>  dep.name as dep_name,
</span></span></span><span><span><span>  salary
</span></span></span><span><span><span>from __emp__ as emp
</span></span></span><span><span><span>    join __dep__ as dep using(dep_id)
</span></span></span><span><span><span>order by salary desc;
</span></span></span><span><span><span>"""</span>
</span></span><span><span>
</span></span><span><span><span>res</span> <span>=</span> <span>cdf</span><span>.</span><span>query</span>(<span>sql</span><span>=</span><span>query_sql</span>, <span>emp</span><span>=</span><span>employees</span>, <span>dep</span><span>=</span><span>departments</span>)
</span></span><span><span><span>print</span>(<span>res</span>, <span>end</span><span>=</span><span>""</span>)
</span></span></code></pre></div><codapi-snippet sandbox="chdb-python" editor="basic" files="employees.csv departments.csv"></codapi-snippet><h2 id="writing-data">Writing data</h2><p>The easiest way to export data is to use the output format (the second parameter in the <code>query</code> method), and then write the data to disk:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>pathlib</span> <span>import</span> <span>Path</span>
</span></span><span><span>
</span></span><span><span><span>query_sql</span> <span>=</span> <span>"select * from 'employees.csv'"</span>
</span></span><span><span><span>res</span> <span>=</span> <span>chdb</span><span>.</span><span>query</span>(<span>query_sql</span>, <span>"Parquet"</span>)
</span></span><span><span>
</span></span><span><span><span># export to Parquet</span>
</span></span><span><span><span>path</span> <span>=</span> <span>Path</span>(<span>"/tmp/employees.parquet"</span>)
</span></span><span><span><span>path</span><span>.</span><span>write_bytes</span>(<span>res</span><span>.</span><span>bytes</span>())
</span></span><span><span>
</span></span><span><span><span># import from Parquet</span>
</span></span><span><span><span>query_sql</span> <span>=</span> <span>"select * from '/tmp/employees.parquet' limit 5"</span>
</span></span><span><span><span>res</span> <span>=</span> <span>chdb</span><span>.</span><span>query</span>(<span>query_sql</span>, <span>"PrettyCompactNoEscapes"</span>)
</span></span><span><span><span>print</span>(<span>res</span>, <span>end</span><span>=</span><span>""</span>)
</span></span></code></pre></div><codapi-snippet sandbox="chdb-python" editor="basic" template="main.py" files="employees.csv"></codapi-snippet><p>We can also easily convert the chDB result object into a PyArrow table:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>query_sql</span> <span>=</span> <span>"select * from 'employees.csv'"</span>
</span></span><span><span><span>res</span> <span>=</span> <span>chdb</span><span>.</span><span>query</span>(<span>query_sql</span>, <span>"Arrow"</span>)
</span></span><span><span>
</span></span><span><span><span>table</span> <span>=</span> <span>chdb</span><span>.</span><span>to_arrowTable</span>(<span>res</span>)
</span></span><span><span><span>print</span>(<span>table</span><span>.</span><span>schema</span>)
</span></span></code></pre></div><codapi-snippet sandbox="chdb-python" editor="basic" template="main.py" files="employees.csv"></codapi-snippet><p>Or Pandas dataframe:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>query_sql</span> <span>=</span> <span>"select * from 'employees.csv'"</span>
</span></span><span><span><span>res</span> <span>=</span> <span>chdb</span><span>.</span><span>query</span>(<span>query_sql</span>, <span>"Arrow"</span>)
</span></span><span><span>
</span></span><span><span><span>frame</span> <span>=</span> <span>chdb</span><span>.</span><span>to_df</span>(<span>res</span>)
</span></span><span><span><span>frame</span><span>.</span><span>info</span>()
</span></span></code></pre></div><codapi-snippet sandbox="chdb-python" editor="basic" template="main.py" files="employees.csv"></codapi-snippet><p>To persist a chDB session to a specific folder on disk, use the <code>path</code> constructor parameter. This way you can restore the session later:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>chdb.session</span> <span>import</span> <span>Session</span>
</span></span><span><span>
</span></span><span><span><span># create a persistent session</span>
</span></span><span><span><span>db</span> <span>=</span> <span>Session</span>(<span>path</span><span>=</span><span>"/tmp/employees"</span>)
</span></span><span><span>
</span></span><span><span><span># create a database and a table</span>
</span></span><span><span><span>db</span><span>.</span><span>query</span>(<span>"create database db"</span>)
</span></span><span><span><span>db</span><span>.</span><span>query</span>(<span>"""
</span></span></span><span><span><span>create table db.employees (
</span></span></span><span><span><span>  emp_id UInt32 primary key,
</span></span></span><span><span><span>  first_name String, last_name String,
</span></span></span><span><span><span>  birth_dt Date, hire_dt Date,
</span></span></span><span><span><span>  dep_id String, city String,
</span></span></span><span><span><span>  salary UInt32,
</span></span></span><span><span><span>) engine MergeTree;
</span></span></span><span><span><span>"""</span>)
</span></span><span><span>
</span></span><span><span><span># load data into the table</span>
</span></span><span><span><span>db</span><span>.</span><span>query</span>(<span>"""
</span></span></span><span><span><span>insert into db.employees
</span></span></span><span><span><span>select * from 'employees.csv'
</span></span></span><span><span><span>"""</span>)
</span></span><span><span>
</span></span><span><span><span># ...</span>
</span></span><span><span><span># restore the session later</span>
</span></span><span><span><span>db</span> <span>=</span> <span>Session</span>(<span>path</span><span>=</span><span>"/tmp/employees"</span>)
</span></span><span><span>
</span></span><span><span><span># query the data</span>
</span></span><span><span><span>res</span> <span>=</span> <span>db</span><span>.</span><span>query</span>(<span>"select count(*) from db.employees"</span>)
</span></span><span><span><span>print</span>(<span>res</span>, <span>end</span><span>=</span><span>""</span>)
</span></span></code></pre></div><codapi-snippet sandbox="chdb-python" editor="basic" files="employees.csv"></codapi-snippet><h2 id="user-defined-functions">User-defined functions</h2><p>We can define a function in Python and use it in chDB SQL queries.</p><p>Here is a <code>split_part</code> function that splits a string on the given separator and returns the resulting field with the given index (counting from one):</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>chdb.udf</span> <span>import</span> <span>chdb_udf</span>
</span></span><span><span>
</span></span><span><span><span>@chdb_udf</span>()
</span></span><span><span><span>def</span> <span>split_part</span>(<span>s</span>, <span>sep</span>, <span>idx</span>):
</span></span><span><span>    <span>idx</span> <span>=</span> <span>int</span>(<span>idx</span>)<span>-</span><span>1</span>
</span></span><span><span>    <span>return</span> <span>s</span><span>.</span><span>split</span>(<span>sep</span>)[<span>idx</span>]
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>second</span> <span>=</span> <span>chdb</span><span>.</span><span>query</span>(<span>"select split_part('a;b;c', ';', 2)"</span>)
</span></span><span><span><span>print</span>(<span>second</span>, <span>end</span><span>=</span><span>""</span>)
</span></span></code></pre></div><codapi-snippet sandbox="chdb-python" editor="basic" template="main.py"></codapi-snippet><p>And here is a <code>sumn</code> function that calculates a sum from 1 to N:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>chdb.udf</span> <span>import</span> <span>chdb_udf</span>
</span></span><span><span>
</span></span><span><span><span>@chdb_udf</span>(<span>return_type</span><span>=</span><span>"Int32"</span>)
</span></span><span><span><span>def</span> <span>sumn</span>(<span>n</span>):
</span></span><span><span>    <span>n</span> <span>=</span> <span>int</span>(<span>n</span>)
</span></span><span><span>    <span>return</span> <span>n</span><span>*</span>(<span>n</span><span>+</span><span>1</span>)<span>//</span><span>2</span>
</span></span><span><span>
</span></span><span><span>
</span></span><span><span><span>sum20</span> <span>=</span> <span>chdb</span><span>.</span><span>query</span>(<span>"select sumn(20)"</span>)
</span></span><span><span><span>print</span>(<span>sum20</span>, <span>end</span><span>=</span><span>""</span>)
</span></span></code></pre></div><codapi-snippet sandbox="chdb-python" editor="basic" template="main.py"></codapi-snippet><p>Currently chDB only supports scalar functions that take strings as parameters. If the function returns a type other than string, we should pass it as <code>return_type</code> to the <code>chdb_udf</code> decorator.</p><h2 id="python-database-api">Python Database API</h2><p>The chDB Python package adheres to the Python DB API (<a href="https://peps.python.org/pep-0249/">PEP 249</a>), so you can use it just like you'd use stdlib's <code>sqlite3</code> module:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>contextlib</span> <span>import</span> <span>closing</span>
</span></span><span><span><span>from</span> <span>chdb</span> <span>import</span> <span>dbapi</span>
</span></span><span><span>
</span></span><span><span><span>print</span>(<span>f</span><span>"chdb version: </span><span>{</span><span>dbapi</span><span>.</span><span>get_client_info</span>()<span>}</span><span>"</span>)
</span></span><span><span>
</span></span><span><span><span>with</span> <span>closing</span>(<span>dbapi</span><span>.</span><span>connect</span>()) <span>as</span> <span>conn</span>:
</span></span><span><span>    <span>with</span> <span>closing</span>(<span>conn</span><span>.</span><span>cursor</span>()) <span>as</span> <span>cur</span>:
</span></span><span><span>        <span>cur</span><span>.</span><span>execute</span>(<span>"select version()"</span>)
</span></span><span><span>        <span>print</span>(<span>"description:"</span>, <span>cur</span><span>.</span><span>description</span>)
</span></span><span><span>        <span>print</span>(<span>"data:"</span>, <span>cur</span><span>.</span><span>fetchone</span>())
</span></span></code></pre></div><codapi-snippet sandbox="chdb-python" editor="basic"></codapi-snippet><h2 id="current-status">Current status</h2><p>chDB reached 1.0 in December 2023. It has the full power of ClickHouse under the hood, a team of passionate maintainers and a growing user base. The future looks bright and I wish chDB all the best!</p><p>‚îÄ‚îÄ</p><p>P.S. <mark>Interactive examples in this post</mark> are powered by <a href="https://codapi.org/"><strong>codapi</strong></a> ‚Äî an open source tool I'm building. Use it to embed live code snippets into your product docs, online course or blog.</p><p><em><a href="https://antonz.org/subscribe/"><i></i>&nbsp;<strong>Subscribe</strong></a>
to keep up with new posts.</em></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SSH protects the most sensitive networks. It just got a lot weaker (107 pts)]]></title>
            <link>https://arstechnica.com/security/2023/12/hackers-can-break-ssh-channel-integrity-using-novel-data-corruption-attack/</link>
            <guid>38708215</guid>
            <pubDate>Wed, 20 Dec 2023 13:09:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/security/2023/12/hackers-can-break-ssh-channel-integrity-using-novel-data-corruption-attack/">https://arstechnica.com/security/2023/12/hackers-can-break-ssh-channel-integrity-using-novel-data-corruption-attack/</a>, See on <a href="https://news.ycombinator.com/item?id=38708215">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      MESSING WITH SSH DATA STREAMS    ‚Äî
</h4>
            
            <h2 itemprop="description">Novel Terrapin attack uses prefix truncation to downgrade the security of SSH channels.</h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/terrapin-data-attack-800x450.jpg" alt="Terrapin is coming for your data.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/terrapin-data-attack.jpg" data-height="1440" data-width="2560">Enlarge</a> <span>/</span> Terrapin is coming for your data.</p><p>Aurich Lawson | Getty Images</p></figcaption>  </figure>

  




<!-- cache hit 216:single/related:09b2b1ce1005fdee05d0fb775004de6c --><!-- empty -->
<p>Sometime around the start of 1995, an unknown person planted a password sniffer on the network backbone of Finland‚Äôs Helsinki University of Technology (now known as Aalto University). Once in place, this piece of dedicated hardware surreptitiously inhaled thousands of user names and passwords before it was finally discovered. Some of the credentials belonged to employees of a company run by Tatu Yl√∂nen, who was also a database researcher at the university.</p>
<p>The event proved to be seminal, not just for Yl√∂nen's company but for the entire world. Until that point, people like Yl√∂nen connected to networks using tools which implemented protocols such as Telnet, rlogin, rcp, and rsh. All of these transmitted passwords (and all other data) as plaintext, providing an endless stream of valuable information to sniffers. Yl√∂nen, who at the time knew little about implementing strong cryptography in code, set out to develop the <a href="https://en.wikipedia.org/wiki/Secure_Shell">Secure Shell Protocol (SSH)</a> in early 1995, about three months after the discovery of the password sniffer.</p>
<p>As one of the first network tools to route traffic through an impregnable tunnel fortified with a still-esoteric feature known as "public key encryption," SSH quickly caught on around the world. Besides its unprecedented security guarantees, SSH was easy to install on a wide array of operating systems, including the myriad ones that powered the devices administrators used‚Äîand the servers those devices connected to remotely. SSH also supported <a href="https://goteleport.com/blog/x11-forwarding/">X11 forwarding</a>, which allowed users to run graphical applications on a remote server.</p>
<p>Yl√∂nen submitted SSH to the Internet Engineering Taskforce in 1996, and it quickly became an almost ubiquitous tool for remotely connecting computers. Today, it‚Äôs hard to overstate the importance of the protocol, which underpins the security of apps used inside millions of organizations, including cloud environments crucial to Google, Amazon, Facebook, and other large companies.</p>                                            
                                                        
<p>‚ÄúPassword sniffing attacks were very common at that time, with new incidents reported almost weekly, and arguably it was the biggest security problem on the Internet at the time,‚Äù Yl√∂nen wrote in an online interview. ‚ÄúI did intend SSH to become as widely used as possible. It was critically needed for securing networks and computing systems, and it for the most part solved the password sniffing problem.‚Äù</p>
<p>Now, nearly 30 years later, researchers have devised an attack with the potential to undermine, if not cripple, cryptographic SSH protections that the networking world takes for granted.</p>
<h2>Meet Terrapin</h2>
<p>Named Terrapin, the new hack works only when an attacker has an active adversary-in-the middle position on the connection between the admins and the network they remotely connect to. Also known as a man-in-the-middle or MitM attack, this occurs when an attacker secretly positioned between two parties intercepts communications and assumes the identity of both the recipient and the sender. This provides the ability to both intercept and to alter communications. While this position can be difficult for an attacker to achieve, it‚Äôs one of the scenarios from which SSH was thought to have immunity.</p>
<p>For Terrapin to be viable, the connection it interferes with also must be secured by either "ChaCha20-Poly1305" or "CBC with Encrypt-then-MAC," both of which are cipher modes added to the SSH protocol (in 2013 and 2012, respectively). A scan performed by the researchers found that 77 percent of SSH servers exposed to the Internet support at least one of the vulnerable encryption modes, while 57 percent of them list a vulnerable encryption mode as the preferred choice.</p>
<p>At its core, Terrapin works by altering or corrupting information transmitted in the SSH data stream during the handshake‚Äîthe earliest stage of a connection, when the two parties negotiate the encryption parameters they will use to establish a secure connection. The attack targets the BPP, short for <a href="https://www.scribd.com/document/59627915/Ssh-Security">Binary Packet Protocol</a>, which is designed to ensure that adversaries with an active position can't add or drop messages exchanged during the handshake. Terrapin relies on prefix truncation, a class of attack that removes specific messages at the very beginning of a data stream.</p>

                                                </div>

            
            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/security/2023/12/hackers-can-break-ssh-channel-integrity-using-novel-data-corruption-attack/2/">2</a> <a href="https://arstechnica.com/security/2023/12/hackers-can-break-ssh-channel-integrity-using-novel-data-corruption-attack/3/">3</a> <a href="https://arstechnica.com/security/2023/12/hackers-can-break-ssh-channel-integrity-using-novel-data-corruption-attack/4/">4</a> <a href="https://arstechnica.com/security/2023/12/hackers-can-break-ssh-channel-integrity-using-novel-data-corruption-attack/2/"><span>Next <span>‚Üí</span></span></a></span></nav>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rite Aid banned from using face recognition software after false ID shoplifters (116 pts)]]></title>
            <link>https://techcrunch.com/2023/12/20/rite-aid-facial-recognition/</link>
            <guid>38708065</guid>
            <pubDate>Wed, 20 Dec 2023 12:52:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2023/12/20/rite-aid-facial-recognition/">https://techcrunch.com/2023/12/20/rite-aid-facial-recognition/</a>, See on <a href="https://news.ycombinator.com/item?id=38708065">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary"><a href="https://en.wikipedia.org/wiki/Rite_Aid">Rite Aid</a> has been <a href="https://www.ftc.gov/news-events/news/press-releases/2023/12/rite-aid-banned-using-ai-facial-recognition-after-ftc-says-retailer-deployed-technology-without">banned</a> from using facial recognition software for five years, after the Federal Trade Commission (FTC) found that the U.S. drugstore giant‚Äôs ‚Äúreckless use of facial surveillance systems‚Äù left customers humiliated and put their ‚Äúsensitive information at risk.‚Äù</p>
<p>The FTC‚Äôs <a href="https://www.ftc.gov/system/files/ftc_gov/pdf/2023190_riteaid_stipulated_order_filed.pdf">Order</a>, which is subject to approval from the U.S. Bankruptcy Court after Rite Aid <a href="https://apnews.com/article/rite-pharmacy-bankruptcy-f80c3d231946d675b03e4e797f627fa6">filed for Chapter 11 bankruptcy protection</a> in October, also instructs Rite Aid to delete any images it collected as part of its facial recognition system rollout, as well as any products that were built from those images. The company must also implement a robust data security program to safeguard any personal data it collects.</p>
<p>A Reuters <a href="https://www.reuters.com/investigates/special-report/usa-riteaid-software/">report from 2020</a> detailed how the drugstore chain had secretly introduced facial recognition systems across some 200 U.S. stores over an eight-year period starting in 2012, with ‚Äúlargely lower-income, non-white neighborhoods‚Äù serving as the technology testbed.</p>
<p>With the FTC‚Äôs increasing <a href="https://www.ftc.gov/news-events/news/press-releases/2023/05/ftc-warns-about-misuses-biometric-information-harm-consumers">focus on the misuse of biometric surveillance</a>, Rite Aid fell firmly in the government agency‚Äôs crosshairs. Among its&nbsp;allegations are that Rite Aid ‚Äî in partnership with two contracted companies ‚Äî created a ‚Äúwatchlist database‚Äù containing images of customers that the company said had engaged in criminal activity at one of its stores. These images, which were often poor quality, were captured from CCTV or employees‚Äô mobile phone cameras.</p>
<p>When a customer entered a store who supposedly matched an existing image on its database, employees would receive an automatic alert instructing them to take action ‚Äî and the majority of the time this instruction was to ‚Äúapproach and identify,‚Äù meaning verifying the customer‚Äôs identity and asking them to leave. Often, these ‚Äúmatches‚Äù were false positives that led to employees incorrectly accusing customers of wrongdoing, creating ‚Äúembarrassment, harassment, and other harm,‚Äù according to the FTC.</p>
<p>‚ÄúEmployees, acting on false positive alerts, followed consumers around its stores, searched them, ordered them to leave, called the police to confront or remove consumers, and publicly accused them, sometimes in front of friends or family, of shoplifting or other wrongdoing,‚Äù the complaint reads.</p>
<p>Additionally, the FTC said that Rite Aid failed to inform customers that facial recognition technology was in use, while also instructing employees to specifically <em>not</em> reveal this information to customers.</p>
<h2>Face-off</h2>
<p>Facial recognition software has emerged as one of most controversial facets of the AI-powered surveillance era. In the past few years we‚Äôve seen cities issue <a href="https://techcrunch.com/2020/09/09/facial-recognition-ban-portland-oregon/" target="_blank" rel="noopener">expansive bans on the technology</a>, while politicians have fought to <a href="https://techcrunch.com/2022/09/29/house-democrats-facial-recognition-act/" target="_blank" rel="noopener">regulate how police utilize it</a>. And companies such as Clearview AI, meanwhile, have been <a href="https://techcrunch.com/2022/05/09/clearview-settlement-bipa/" target="_blank" rel="noopener">hit with lawsuits</a> and <a href="https://techcrunch.com/2022/07/13/clearview-greek-ban-order/" target="_blank" rel="noopener">fines</a> around the world for major <a href="https://techcrunch.com/2022/05/23/clearview-uk-ico-fine/" target="_blank" rel="noopener">data privacy breaches</a> around facial recognition technology.</p>
<p>The FTC‚Äôs latest findings regarding Rite Aid also shines a light on inherent biases in AI systems. For instance, the FTC says that Rite Aid failed to mitigate risks to certain consumers due to their race ‚Äî its technology was ‚Äúmore likely to generate false positives in stores located in plurality-Black and Asian communities than in plurality-White communities,‚Äù the findings note.</p>
<p>Additionally, the FTC said that Rite Aid failed to test or measure the accuracy or their facial recognition system prior to, or after, deployment.</p>
<p>In a <a href="https://news.riteaid.com/press-releases/press-release-details/2023/Rite-Aid-Reaches-Settlement-with-FTC/default.aspx">press release</a>, Rite Aid said that it was ‚Äúpleased to reach an agreement with the FTC,‚Äù but that it disagreed with the crux of the allegations.</p>
<p>‚ÄúThe allegations relate to a facial recognition technology pilot program the Company deployed in a limited number of stores,‚Äù Rite Aid said in its statement. ‚ÄúRite Aid stopped using the technology in this small group of stores more than three years ago, before the FTC‚Äôs investigation regarding the Company‚Äôs use of the technology began.‚Äù</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[There's a Concorde Engine Complete with Afterburner for Sale on eBay (120 pts)]]></title>
            <link>https://simpleflying.com/concorde-engine-for-sale-ebay/</link>
            <guid>38707995</guid>
            <pubDate>Wed, 20 Dec 2023 12:45:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simpleflying.com/concorde-engine-for-sale-ebay/">https://simpleflying.com/concorde-engine-for-sale-ebay/</a>, See on <a href="https://news.ycombinator.com/item?id=38707995">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                                       <div>
                    


        

                        <nav>
                <ul>
                    <li><a href="https://simpleflying.com/">Home</a></li>
                                                                                            <li><a href="https://simpleflying.com/category/aviation-news/">Aviation News</a></li>
                                                                                                                                                            </ul>
            </nav>
            
                </div>
                            

    
            
    
        
            
    
    
    
        
    
                            






            
            

    
    
        
    
            
    
            
    
        
            
    
    
    
        
    
                                
    <p>It was the only engine sold by British Airways with its serial number plate attached. </p>

            
            

    
    
        
    
            
    
            
    
        
            
    
    
    
        
    
                                
                                    
                                                                                                                        
                                                <div data-img-url="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/312564454_486271333535864_7770349111757162724_n-1.jpg" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="&quot;Photo: The Museum of Flight&quot;">

        <figure>
            <picture>
                <!--[if IE 9]>
                <video style="display: none;"><![endif]-->
                                    <source media="(min-width: 1024px)" sizes="1140px" srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/312564454_486271333535864_7770349111757162724_n-1.jpg?q=50&amp;fit=contain&amp;w=1140&amp;h=&amp;dpr=1.5">
                                    <source media="(min-width: 768px)" sizes="943px" srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/312564454_486271333535864_7770349111757162724_n-1.jpg?q=50&amp;fit=contain&amp;w=943&amp;h=&amp;dpr=1.5">
                                    <source media="(min-width: 481px)" sizes="767px" srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/312564454_486271333535864_7770349111757162724_n-1.jpg?q=50&amp;fit=contain&amp;w=767&amp;h=&amp;dpr=1.5">
                                    <source media="(min-width: 0px)" sizes="480px" srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/312564454_486271333535864_7770349111757162724_n-1.jpg?q=50&amp;fit=contain&amp;w=480&amp;h=&amp;dpr=1.5">
                                <!--[if IE 9]></video><![endif]-->
                                    <img width="1546" height="870" alt="British Airways Concorde G-BOAG preparing to land." data-img-url="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/312564454_486271333535864_7770349111757162724_n-1.jpg" src="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/312564454_486271333535864_7770349111757162724_n-1.jpg">
                            </picture>
            <figcaption>Photo: The Museum of Flight</figcaption>
        </figure>
    </div>

    
            <!-- No winning ad found for zone: below main pic! -->
    
            
            

    
    
        
    
            
                    </div><div id="article-body" itemprop="articleBody"><div id="custom_block_0">
<h3>Summary</h3>
<div> 
<ul> <li> A turbo-jet engine from a British Airways Concorde is being sold to the public on eBay. </li> <li> The engine is not operational and can only be used for static display or repurposed as furniture or art. </li> <li> The engine is unique as it is the only one sold by British Airways with the afterburner and original log book. </li> </ul>
</div>
 </div>

<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":0,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":0,"nbrPlacementsScanned":1,"ruleCount":10,"degradationStartingPoint":2,"actualCount":0} -->
<!-- Zone: below first paragraph. -->
<!-- No ads allowed! -->
<p>A turbo-jet engine formerly operated on a <a href="https://simpleflying.com/tag/british-airways/">British Airways (BA)</a> <a href="https://simpleflying.com/tag/concorde/">Concorde</a> is on sale to the general public. Complete with an afterburner, the nearly 50-year-old engine is being sold for over $700,000.</p>
<!-- Repeatable debug data: {"injection":"before","adPosition":0,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":0,"nbrPlacementsScanned":1,"ruleCount":10,"degradationStartingPoint":2,"actualCount":198} --><!-- Zone: character count repeatable. --><!-- No ads allowed! --><!-- Repeatable debug data: {"injection":"after","adPosition":1,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":1,"nbrPlacementsScanned":1,"ruleCount":10,"degradationStartingPoint":2,"actualCount":0} -->
<p>The aircraft, once powered by the turbo engine, can be visited at the Museum of Flight in Seattle, Washington. It is one of three Concorde aircraft that remain intact, preserving the history of the iconic supersonic jet.</p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":1,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":1,"nbrPlacementsScanned":2,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":220} -->
<!-- No winning ad found for zone: native in content! -->

<p>The Rolls-Royce Olympus 593-610, fitted with fans and an afterburner, is available for $716,927.94 (¬£565,000.00) by <a href="http://www.ebay.co.uk/itm/116001533010?mkcid=16&amp;mkevt=1&amp;mkrid=711-127632-2357-0&amp;ssspo=3X5IDjxbSpS&amp;sssrc=4429486&amp;ssuid=guVqnn7EQqq&amp;var=&amp;widget_ver=artemis&amp;media=COPY" rel="noopener noreferrer" target="_blank">eBay</a> user ny10uk20. According to the seller, the engine is <em>‚Äúnot able to fly‚Äù </em>and <em>‚Äúmust only be used for static display.‚Äù </em></p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":1,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":1,"nbrPlacementsScanned":2,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":487} -->
<div><div data-img-url="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600-1.jpg" data-img-desc="&quot;Photo:&amp;nbsp;ny10uk20 | eBay&quot;" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="null"> <figure> <picture><!--[if IE 9]> <video style="display: none;"><![endif]--> <source media="(min-width: 1024px)" sizes="1500px" data-srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600-1.jpg?q=50&amp;fit=crop&amp;w=1500&amp;dpr=1.5"> <source media="(min-width: 768px)" sizes="943px" data-srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600-1.jpg?q=50&amp;fit=crop&amp;w=943&amp;dpr=1.5"> <source media="(min-width: 481px)" sizes="767px" data-srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600-1.jpg?q=50&amp;fit=crop&amp;w=767&amp;dpr=1.5"> <source media="(min-width: 0px)" sizes="480px" data-srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600-1.jpg?q=50&amp;fit=crop&amp;w=480&amp;dpr=1.5"><!--[if IE 9]></video><![endif]--><img width="1600" height="1200" alt="A Concorde turbo-jet engine on sale. " data-img-url="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600-1.jpg" src="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600-1.jpg"> </picture> </figure> </div><p>Photo:&nbsp;ny10uk20 | eBay</p> </div>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":1,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":1,"nbrPlacementsScanned":2,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":727} -->
<p>However, the seller also noted that the engine is<em> ‚Äúperfect‚Äù </em>for dismantling and repurposing<em> ‚Äúinto collectable pieces of furniture or art.‚Äù</em> The engine is approximately 18 feet long and five feet high (5.5 meters by 1.5 meters). It weighs three and a half tons, while its stand is another two tons, making the combined weight five and a half tons.</p>
<!-- Repeatable debug data: {"injection":"before","adPosition":1,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":1,"nbrPlacementsScanned":2,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":1096} --><!-- Zone: character count repeatable. --><!-- No ads allowed! --><!-- Repeatable debug data: {"injection":"after","adPosition":2,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":2,"nbrPlacementsScanned":2,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":0} -->
<div><div data-img-url="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600.jpg" data-img-desc="&quot;Photo:&amp;nbsp;ny10uk20 | eBay&quot;" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="null"> <figure> <picture><!--[if IE 9]> <video style="display: none;"><![endif]--> <source media="(min-width: 1024px)" sizes="1500px" data-srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600.jpg?q=50&amp;fit=crop&amp;w=1500&amp;dpr=1.5"> <source media="(min-width: 768px)" sizes="943px" data-srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600.jpg?q=50&amp;fit=crop&amp;w=943&amp;dpr=1.5"> <source media="(min-width: 481px)" sizes="767px" data-srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600.jpg?q=50&amp;fit=crop&amp;w=767&amp;dpr=1.5"> <source media="(min-width: 0px)" sizes="480px" data-srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600.jpg?q=50&amp;fit=crop&amp;w=480&amp;dpr=1.5"><!--[if IE 9]></video><![endif]--><img width="699" height="290" alt="A Concorde turbo-jet engine on display." data-img-url="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600.jpg" src="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/s-l1600.jpg"> </picture> </figure> </div><p>Photo:&nbsp;ny10uk20 | eBay</p> </div>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":2,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":2,"nbrPlacementsScanned":3,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":240} -->
<p>The seller commented on how the engine, initially sold from BA, is one of a kind.</p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":2,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":2,"nbrPlacementsScanned":3,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":321} -->
<blockquote>
<p>‚ÄúThis was the only engine BA sold which had the afterburner fitted and the engine serial number plate attached. In addition, the only one for which the original Log Book for delivery has been released.‚Äù</p>
 </blockquote>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":2,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":2,"nbrPlacementsScanned":3,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":545} -->

<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":2,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":2,"nbrPlacementsScanned":3,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":545} -->
<h2 id="the-history-of-g-boag"> The history of G-BOAG </h2>
<p>The engine was installed on the aircraft initially registered as G-BFKW. This would be the aircraft‚Äôs third engine. According to Heritage Concorde, the plane was built in 1977 and was delivered to British Aerospace (BAe), an aircraft, ammunition, and defense systems manufacturer, on January 27, 1978. Having a less-than-glamorous beginning to its life with no buyer, the jet was loaned for a sixth-month period to BA via a sale or return agreement, as the airline was awaiting the repair of another Concorde at a maintenance facility at Filton Airfield.</p>
<!-- Repeatable debug data: {"injection":"before","adPosition":2,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":2,"nbrPlacementsScanned":3,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":1105} --><!-- Zone: character count repeatable. --><!-- No ads allowed! --><!-- Repeatable debug data: {"injection":"after","adPosition":3,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":3,"nbrPlacementsScanned":3,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":0} -->

<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":3,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":3,"nbrPlacementsScanned":4,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":53} -->
<p>G-BFKW was grounded after an aborted flight to New York on April 26, 1980, due to water contaminating the hydraulic system. The issues led to an intake failure at a speed of Mach 2, which later reportedly resulted in engine surges. After remaining on the ground for several months, $1.2 million (¬£1,000,000) was spent to return the aircraft to flying condition. On February 9, 1981, BA re-registered the Concorde as G-BOAG. Under these letters, the aircraft would continue to fly for the better part of 22 years, according to Heritage Concorde.</p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":3,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":3,"nbrPlacementsScanned":4,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":603} -->
<p>In 1982, the aircraft suffered another grounding as it was utilized as the primary source of spares for the remainder of BA‚Äôs Concorde fleet. This lasted for a few years until the airline acquired another Concorde, G-BBDG, to be utilized as the source for spares. G-BOAG returned to service in 1984. One year later, the plane was the first Concorde to unveil BA‚Äôs new ‚ÄúLandor‚Äù livery and new interior.</p>
<!-- Repeatable debug data: {"injection":"before","adPosition":3,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":3,"nbrPlacementsScanned":4,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":1028} --><!-- Zone: character count repeatable. --><!-- No ads allowed! --><!-- Repeatable debug data: {"injection":"after","adPosition":4,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":4,"nbrPlacementsScanned":4,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":0} -->
<p>In 1996, the jet underwent refurbishment and became the last Concorde to be repainted in BA‚Äôs new Chatham livery. Following the Paris crash modification program in 2001, G-BOAG was the third BA Concorde to return to the skies on October 19 of that year. Just two years later, it flew to Toronto to begin its North American farewell tour. On October 14, 2003, the jet visited Washington Dulles International Airport to conclude its North American farewell tour and flew back over the pond to begin its UK farewell tour.</p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":4,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":4,"nbrPlacementsScanned":5,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":524} -->

<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":4,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":4,"nbrPlacementsScanned":5,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":524} -->
<h2 id="flying-into-retirement"> Flying into retirement </h2>
<p>G-BOAG operated its final flight from New York to London on October 24, 2003, and joined two other Concordes, G-BOAE and G-BOAF, at Heathrow Airport to mark the last day of Concorde commercial flights. On November 3, 2003, the aircraft flew to its retirement home at the Museum of Flight in Seattle, where it can still be visited today.</p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":4,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":4,"nbrPlacementsScanned":5,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":860} -->
<div><div data-img-url="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/354858765_653859173443745_7410047939404106111_n.jpg" data-img-desc="&quot;Photo: The Museum of Flight&quot;" data-modal-id="single-image-modal" data-modal-container-id="single-image-modal-container" data-img-caption="null"> <figure> <picture><!--[if IE 9]> <video style="display: none;"><![endif]--> <source media="(min-width: 1024px)" sizes="1500px" data-srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/354858765_653859173443745_7410047939404106111_n.jpg?q=50&amp;fit=crop&amp;w=1500&amp;dpr=1.5"> <source media="(min-width: 768px)" sizes="943px" data-srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/354858765_653859173443745_7410047939404106111_n.jpg?q=50&amp;fit=crop&amp;w=943&amp;dpr=1.5"> <source media="(min-width: 481px)" sizes="767px" data-srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/354858765_653859173443745_7410047939404106111_n.jpg?q=50&amp;fit=crop&amp;w=767&amp;dpr=1.5"> <source media="(min-width: 0px)" sizes="480px" data-srcset="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/354858765_653859173443745_7410047939404106111_n.jpg?q=50&amp;fit=crop&amp;w=480&amp;dpr=1.5"><!--[if IE 9]></video><![endif]--><img width="2048" height="1073" alt="G-BOAG resting at the Museum of Flight in Seattle, Washington." data-img-url="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/354858765_653859173443745_7410047939404106111_n.jpg" src="https://static1.simpleflyingimages.com/wordpress/wp-content/uploads/2023/12/354858765_653859173443745_7410047939404106111_n.jpg"> </picture> </figure> </div><p>Photo: The Museum of Flight</p> </div>
<!-- Repeatable debug data: {"injection":"before","adPosition":4,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":4,"nbrPlacementsScanned":5,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":1100} --><!-- Zone: character count repeatable. --><!-- No ads allowed! --><!-- Repeatable debug data: {"injection":"after","adPosition":5,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":5,"nbrPlacementsScanned":5,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":0} -->

<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":5,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":5,"nbrPlacementsScanned":6,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":79} -->
<p>Throughout its life, G-BOAG recorded 16,239 flight hours, 5,633 landings, and 5,066 supersonic flights. The engine is located in Farnborough, England, and is not for sale in the US, according to eBay.</p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":5,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":5,"nbrPlacementsScanned":6,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":279} -->
<p><em>Sources: <a href="https://www.heritageconcorde.com/g-boag-214" rel="noopener noreferrer" target="_blank">Heritage Concorde</a></em></p>
<!-- No repeatable ad for zone: character count repeatable. --><!-- Repeatable debug data: {"injection":"none","adPosition":5,"startingPoint":1,"skipEvery":null,"nbrPlacementFilledEachSkip":5,"nbrPlacementsScanned":6,"ruleCount":1000,"degradationStartingPoint":2,"actualCount":305} -->
 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla blamed drivers for failures of parts it long knew were defective (215 pts)]]></title>
            <link>https://www.reuters.com/investigates/special-report/tesla-musk-steering-suspension/</link>
            <guid>38707589</guid>
            <pubDate>Wed, 20 Dec 2023 11:46:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/investigates/special-report/tesla-musk-steering-suspension/">https://www.reuters.com/investigates/special-report/tesla-musk-steering-suspension/</a>, See on <a href="https://news.ycombinator.com/item?id=38707589">Hacker News</a></p>
Couldn't get https://www.reuters.com/investigates/special-report/tesla-musk-steering-suspension/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Notesnook ‚Äì open-source and zero knowledge private note taking app (118 pts)]]></title>
            <link>https://notesnook.com/</link>
            <guid>38707156</guid>
            <pubDate>Wed, 20 Dec 2023 10:28:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://notesnook.com/">https://notesnook.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38707156">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><div><p><span>Privacy for everyone ‚Äî not just the privileged few</span><span>Your privacy matters to us, no matter who you are. In a world where everyone is trying to spy on you, Notesnook encrypts all your data before it leaves your device. Join Notesnook so that no one<!-- --> <del>will</del>can ever sell your data again.</span></p><a href="https://app.notesnook.com/signup"><span>Join our mission</span><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" color="var(--theme-ui-colors-white)" style="color:var(--theme-ui-colors-white);margin-left:15px" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M1 8a.5.5 0 0 1 .5-.5h11.793l-3.147-3.146a.5.5 0 0 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 0 1-.708-.708L13.293 8.5H1.5A.5.5 0 0 1 1 8z"></path></svg></a></div><div><p><span>NOTES</span></p><div><p><span><span>qughTEA M XTHPgt2m</span></span><span><span> k50Gk c1Q0 FU Wc4A gmF8ep</span></span><span><span>K ZHTn HEvUNbOZ e5q5sK86i8R PdD Ps8 xI6dwfL q6qub EoDczigIm UcAo iBi o3m hcJuD fyO fhJ Vdn5bikZ BTwqu</span></span></p></div><div><p><span><span>9NkNQAj e TTj2g7RH</span></span><span><span> Z JZHrVfIjQVV MPjo 2R 9Yw PThul1Q Ac o0RZ</span></span><span><span>UW PPX1Xu AM chvPZhCU 8 zc nFPoy5a o6Ig 9YsMSG 2Q IDlgsQGFxPiJSwvz 7q 2ugqTE 2O LcGSbI3r i 1qsaY Wsp kBZa6Jm4d oc YArP ZZagx44wIC0MI</span></span></p></div><p><span>NOTEBOOKS</span></p><div><p><span>Journal &amp; Thoughts</span><span>Trying to find meaning through journaling everyday.</span></p><p><span><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M17 3H7c-1.1 0-2 .9-2 2v16l7-3 7 3V5c0-1.1-.9-2-2-2z"></path></svg> <!-- -->Thoughts</span></p><p><span>7d ago</span></p></div></div></div><div><p><span>End-to-end encrypted note syncing</span><span>Whether it's your mobile, desktop, or browser, you can access your notes from anywhere, anytime.</span></p><div><p><span>The Meaning of Life</span></p><p><span>1<!-- --> words</span><span>Mon, Dec 11, 2023, 5:28 AM</span><span>Saved</span></p></div><div><div><p><span>The Meaning Of Life</span><span>Add a tag...</span><span></span></p></div><div><p><span>The Meaning of Life</span></p><p><span>1<!-- --> words</span><span>Mon, Dec 11, 2023, 5:28 AM</span><span>Saved</span></p></div></div></div><div><h2>Get Notesnook on all your devices</h2><p><span>Whether you are on mobile or desktop, Notesnook works everywhere.</span></p><a href="https://notesnook.com/downloads"><span>Download now</span><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" color="var(--theme-ui-colors-white)" style="color:var(--theme-ui-colors-white);margin-left:15px" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M1 8a.5.5 0 0 1 .5-.5h11.793l-3.147-3.146a.5.5 0 0 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 0 1-.708-.708L13.293 8.5H1.5A.5.5 0 0 1 1 8z"></path></svg></a></div><div><p><span>Open source and transparent</span></p><p><span>On 9th of August, 2022, we open sourced all Notesnook client apps on Github. Today our importer, web clipper &amp; sync server are all open source under GPLv3. We want Notesnook to be a piece of software that'll live on even if we decide to shut it down. Independent from decisions of a single party.</span></p><a href="https://blog.notesnook.com/notesnook-is-going-open-source/"><span>Read the blog</span><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" color="var(--theme-ui-colors-white)" style="color:var(--theme-ui-colors-white);margin-left:15px" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M1 8a.5.5 0 0 1 .5-.5h11.793l-3.147-3.146a.5.5 0 0 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 0 1-.708-.708L13.293 8.5H1.5A.5.5 0 0 1 1 8z"></path></svg></a></div><div><p><span>Edit your notes the way you want</span><span>Do everything in one place, from tables, tasks, embeds to every little detail in our rich text editor.</span></p></div><div><div><p><span>Extra privacy with notes vault</span><span>Password protect your most important notes and store them encrypted even on your device.</span></p></div><div><p><span>It's easy to forget things, be reminded</span><span>No one should know what you are up to today, tomorrow or a week later. It's easy to forget things though. Keep track of your tasks &amp; reminders in Notesnook.</span></p><div><p><span>Train at the gym</span><span>Make sure to go left and right</span></p></div><div><p><span>Pay bills</span><span>Electricity, gas, water and other bills</span></p></div><div><p><span>Book reservation at resturaunt</span><span>Call to make a reservation for dinner</span></p></div></div></div><div><div><p><span>Learn how your <span>notes</span> are<!-- --> <span>encrypted</span></span><span>To verify that your notes are actually encrypted, you can use our open source tool, Vericrypt. Vericrypt uses real data from your account &amp; works 100% offline.</span></p><a href="https://vericrypt.notesnook.com/"><span>Try Vericrypt</span><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" color="var(--theme-ui-colors-white)" style="color:var(--theme-ui-colors-white);margin-left:15px" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M1 8a.5.5 0 0 1 .5-.5h11.793l-3.147-3.146a.5.5 0 0 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 0 1-.708-.708L13.293 8.5H1.5A.5.5 0 0 1 1 8z"></path></svg></a></div><div><p><span id="encryptionResult"><span>Ciphertext: <!-- -->FxUxP-YaWBXnXPJS0EFJaY8</span><br><span>IV: <!-- -->FowXCLWJtyXG__i8MdIdM_DNDPBJvX9r</span><br><span>Salt: <!-- -->Zsaa5jNYhaXdjywLjkA2Sg</span><br><span>Password:<!-- --> <span>my-password</span></span></span><span>Encrypted with XChaCha20 &amp; Aragon2</span></p></div></div><div><div><p><span>See what people are saying</span><span>We aren't just making this up. Over 60,000 people use Notesnook every day.</span></p><div><a href="https://twitter.com/jasonbereklewis/status/1438635808727044098" target="_blank"><p><img src="https://api.dicebear.com/5.x/avataaars/svg?seed=jasonbereklewis"><span><b>@<!-- -->jasonbereklewis</b></span></p><span>I work in content writing and communications. My day starts and ends in Notesnook. My Chrome app is always open; it's where I take all my notes. The clean design, Focus mode, the tagging and color coding are all features that help keep my work organised every day.</span></a><a href="https://www.reddit.com/r/SideProject/comments/mj11wp/comment/hd3qx8l/" target="_blank"><p><img src="https://api.dicebear.com/5.x/avataaars/svg?seed=jacks_hell"><span><b>@<!-- -->jacks_hell</b></span></p><span>This app is really great so far! (using the android version currently) looking forward to maximizing the **** out of this. Also i think you should mention off the bat that unlimited storage in the pro version means file upload (pics, etc).</span></a><a href="https://twitter.com/akshitchawla04/status/1642146617385189376" target="_blank"><p><img src="https://api.dicebear.com/5.x/avataaars/svg?seed=akshitchawla04"><span><b>@<!-- -->akshitchawla04</b></span></p><span>Have been using @notesnook for some days now and loving it. Notesnook says they can't read my notes and that was enough to convince me to use it. Will mostly buy a subscription after my free trial ends. Do check it out!</span></a><a href="https://twitter.com/andrewsayer/status/1637817220113002503" target="_blank"><p><img src="https://api.dicebear.com/5.x/avataaars/svg?seed=andrewsayer"><span><b>@<!-- -->andrewsayer</b></span></p><span>You simply cannot get any better of a note taking app than @notesnook. The UI is clean and slick, it is feature rich, encrypted, reasonably priced (esp. for students &amp; educators) &amp; open source.</span></a><a href="https://twitter.com/HolensteinDan/status/1439728355935342592" target="_blank"><p><img src="https://api.dicebear.com/5.x/avataaars/svg?seed=HolensteinDan"><span><b>@<!-- -->HolensteinDan</b></span></p><span>Notesnook app is what Evernote should have become long ago. And they're still improving.</span></a><a href="https://alternativeto.net/software/notesnook/about/#post-110802" target="_blank"><p><img src="https://api.dicebear.com/5.x/avataaars/svg?seed=LeslieP"><span><b>@<!-- -->LeslieP</b></span></p><span>Recommended by privacytools.io - if I'm going to change apps in 2022, I'm going TOWARDS privacy respecting apps and AWAY FROM AdTech. These guys get it, and are working hard to develop this app, very responsive. It's already replaced Google Keep for me. Look forward to the continuous improvement.</span></a><a href="https://alternativeto.net/software/notesnook/about/#post-105405" target="_blank"><p><img src="https://api.dicebear.com/5.x/avataaars/svg?seed=candroid_man"><span><b>@<!-- -->candroid_man</b></span></p><span>Notesnook is the best notes app I have ever used. I have watched the development closely for about a year now. It started out pretty rough, but now I can confidently recommend this to other users. The UI is great, syncing works perfectly, and the devs are doing a fantastic job listening to the community and adding amazing features.</span></a><a href="https://twitter.com/youshisune/status/1637005544631197697" target="_blank"><p><img src="https://api.dicebear.com/5.x/avataaars/svg?seed=youshisune"><span><b>@<!-- -->youshisune</b></span></p><span>Today, I migrated from StandardNotes to @notesnook, for mainly better privacy and their interface that looks like evernote #MigrateToNotesnook</span></a></div></div><div><div><h2>Community driven open development</h2><p><span>We value your feedback so join us and share your experiences and ideas. Let's build the best note taking app together.</span></p><p><a href="https://discord.com/invite/zQBK97EE22" target="_blank"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" color="var(--theme-ui-colors-white)" style="color:var(--theme-ui-colors-white);margin-right:5px" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg><span>Join our community</span></a><a href="https://notesnook.com/roadmap"><span>See full roadmap</span><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" color="var(--theme-ui-colors-info)" style="color:var(--theme-ui-colors-info);margin-left:15px" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M1 8a.5.5 0 0 1 .5-.5h11.793l-3.147-3.146a.5.5 0 0 1 .708-.708l4 4a.5.5 0 0 1 0 .708l-4 4a.5.5 0 0 1-.708-.708L13.293 8.5H1.5A.5.5 0 0 1 1 8z"></path></svg></a></p></div><div><div><div><div><p><span>Publish on more app stores (7/9)<!-- --> </span></p><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="15" width="15" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708z"></path></svg></div><p><span>Expand to see which stores Notesnook is coming to.</span></p></div><p><a target="_blank">In progress</a></p></div><div><div><p><span>User profile<!-- --> </span></p><p><span>This will include username, name, profile picture etc. all fully encrypted, of course.</span></p></div><p><a target="_blank">In progress</a></p></div><div><div><p><span>Self hosting sync server (0/4)<!-- --> </span></p><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="15" width="15" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708z"></path></svg></div><p><a target="_blank">Planned</a></p></div></div></div></div><div><p><img width="150px" height="150px" src="https://notesnook.com/logo.svg"></p><div><h2>Privacy for everyone</h2><p><span>Get ready for an open source &amp; private note taking experience.</span><a href="https://app.notesnook.com/"><span>Get started for free</span></a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Elite: "The game that couldn't be written" [video] (106 pts)]]></title>
            <link>https://www.youtube.com/watch?v=lC4YLMLar5I</link>
            <guid>38707095</guid>
            <pubDate>Wed, 20 Dec 2023 10:18:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=lC4YLMLar5I">https://www.youtube.com/watch?v=lC4YLMLar5I</a>, See on <a href="https://news.ycombinator.com/item?id=38707095">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Advice for new software devs who've read all those other advice essays (260 pts)]]></title>
            <link>https://buttondown.email/hillelwayne/archive/advice-for-new-software-devs-whove-read-all-those/</link>
            <guid>38706697</guid>
            <pubDate>Wed, 20 Dec 2023 09:01:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buttondown.email/hillelwayne/archive/advice-for-new-software-devs-whove-read-all-those/">https://buttondown.email/hillelwayne/archive/advice-for-new-software-devs-whove-read-all-those/</a>, See on <a href="https://news.ycombinator.com/item?id=38706697">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                

                
                    
                        <p>Someone recently asked me if I had advice for early-career programmers. At first I thought this was a silly question. I only entered the workforce ten years ago; many of my newsletter subscribers have been programming for longer than I've been alive! </p>
<p>Then I went and read some "advice for starting programmer" essays and thought of some things they missed. So here's thirteen bits of advice for early-career programmers. Some of it is contradictory.</p>
<ol>
<li>
<p>People don't listen to me because I'm a good programmer, they listen to me because I'm a good writer. The same is true of pretty much <em>everybody</em> you'll read. This doesn't mean you should automatically reject everything, but it means you should carefully think about it and evaluate how it applies to your situation. And take any argument about "objective truth" with a grain of salt: there is <em>very</em> little about software that's been scientifically studied, and most of the research is inconclusive. </p>
</li>
<li>
<p>But also don't worry too hard about getting "tricked" or learning "the wrong thing". If you like someone's ideas, try them out! As long as you're not actively sabotaging your coworkers then it'll probably work out in the end, even if you look back and think "I should have done that different." That's what learning is all about!</p>
</li>
<li>
<p>Read the book <a href="https://debuggingrules.com/" target="_blank">Debugging: The 9 Rules</a>. Borrow it from the library or ask your company to buy a copy, whatever. It's a real easy read and teaches an important skill all the other "beginner programmer" books barely cover.</p>
</li>
<li>
<p>At some point you will discover the Right Way to program, the thing which makes this all <em>make sense</em>, and you'll be convinced that the whole field would be so much better off if everybody else programmed the Right Way, too. For me the Right Way was test-driven development; for you it might be functional programming, lisp, formal methods or one of a million other things. </p>
<p>I'm not going to tell you to <em>not</em>  get swept up in the Right Way, because that's pretty much impossible. And honestly it feels really great to discover the Right Way and life's too short to not feel good. Just be <em>mindful</em> of the fact you're getting swept up and try not to make your identity the Right Way Guy. Eventually the honeymoon will end and you'll learn that programming is frustrating and messy regardless of which Right Way people use, and that you can also make great software without doing it the Right Way. Over time you'll learn fifty other Right Ways and learn to mix and match them to the problem at hand.</p>
</li>
<li>
<p>When you first encounter the Right Way, it will <em>likely</em> be from someone who went full Right Way Guy. Try not to hold it against them later. And try not to conflate the actual technique with how the RWG <em>pitches</em> the technique. Most ideas need some modification from their purest form to integrate well with other ideas.</p>
</li>
<li>
<p><a href="https://jvns.ca/" target="_blank">Julia Evans</a> once <a href="https://www.youtube.com/watch?v=30YWsGDr8mA" target="_blank">said</a> "behind every best practice is a horror story." If you don't understand a Best Practice, look for the horror story that inspired it. It might make the best practice make sense. It might turn out to be something that's completely irrelevant to you, and then you can feel comfortable doing a different practice instead.</p>
</li>
<li>
<p>Building on the last tip: a lot of best practices and conventions are "path dependent", arising from a mix of historical and cultural factors. There are things we do because our mentors do it, who do it because <em>their</em> mentors did it, who did it to address issues that aren't as relevant anymore. If something sounds like a <a href="https://en.wikipedia.org/wiki/Just-so_story" target="_blank">just-so story</a>, it very well might be. You can often retrace the whole path if you're willing to look.</p>
</li>
<li>
<p>Take walks.</p>
</li>
<li>
<p>Almost every tool you use has some form of hidden depth, from your programming language to git to JIRA. Don't feel like you have to become an expert in every single one, but do consider spending 5-10 minutes learning a bit more about what it can do. </p>
</li>
<li>
<p>Talk to people in other parts of the company: support, business domain, sales, etc. Consider shadowing them if you have the time (and feel comfortable asking). You'll be surprised by what you learn! </p>
</li>
<li>
<p>If possible, try to do a few different types of programming earlier in your career. This doesn't have to mean switching jobs: most companies are doing several different kinds of programming at once. So like if you're starting in a webdev company, try some frontend, some backend, some operations, some database stuff, and so forth. This helps you learn, but <em>far more importantly</em> increases your chances of finding a kind of software work that you really really like. My first job was as a frontend dev and I was <em>miserable</em>. Later I moved to backend and was much happier, as were the people who wanted to spent more time doing frontend! </p>
</li>
<li>
<p>You've probably heard the advice that software as a field is changing <em>all the time</em>, and that you shouldn't get swept up in the framework treadmill, just focus on learning fundamental skills. This is a true, but doesn't explain the "why". For structural reasons, <em>information</em> in software propagates really quickly. This is due to a lot of factors (internet, open source, <a href="https://www.hillelwayne.com/post/what-we-can-learn/" target="_blank">conferences</a>) but overall there's a lower barrier to sharing ideas in software. So it's really easy to get a lot of people to <em>know about</em> someone's pet project, even if only one person uses it. </p>
<p>The upshot of this is that a lot of the technologies you hear about have very small userbases and will never get wide adoption, but it won't <em>seem</em> that way from how you hear about it. That's why it makes sense to be conservative. If you hear about something that gets you excited, go ahead and be an early adopter, otherwise it's okay to wait a couple years to see if it has legs.</p>
</li>
<li>
<p>Ultimately none of us can predict the future, just as none of us could have predicted the present. Just try to do the best you can, live according to your values, and enjoy the ride.</p>
</li>
</ol>
<p>That's all from me for the year; new workshop dates when I get back. See you in 2024! </p>
                    
                

                
                    <p><em>If you're reading this on the web, you can subscribe <a href="https://buttondown.email/hillelwayne" target="_blank">here</a>. Updates are 6x a month. My main website is <a href="https://www.hillelwayne.com/" target="_blank">here</a>.</em></p>
                
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built an open source AI video search engine to learn more about AI (110 pts)]]></title>
            <link>https://avse.vercel.app</link>
            <guid>38705535</guid>
            <pubDate>Wed, 20 Dec 2023 04:44:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://avse.vercel.app">https://avse.vercel.app</a>, See on <a href="https://news.ycombinator.com/item?id=38705535">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[LLM in a Flash: Efficient LLM Inference with Limited Memory (226 pts)]]></title>
            <link>https://huggingface.co/papers/2312.11514</link>
            <guid>38704982</guid>
            <pubDate>Wed, 20 Dec 2023 03:02:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huggingface.co/papers/2312.11514">https://huggingface.co/papers/2312.11514</a>, See on <a href="https://news.ycombinator.com/item?id=38704982">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div data-props="{&quot;comments&quot;:[{&quot;id&quot;:&quot;65825e287cec0a2080cbaf0b&quot;,&quot;author&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/88bb4c4a67dc8958069e9014f5e73a0b.svg&quot;,&quot;fullname&quot;:&quot;Michael Barry&quot;,&quot;name&quot;:&quot;MichaelBarryUK&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false},&quot;createdAt&quot;:&quot;2023-12-20T03:23:20.000Z&quot;,&quot;type&quot;:&quot;comment&quot;,&quot;data&quot;:{&quot;edited&quot;:false,&quot;hidden&quot;:false,&quot;latest&quot;:{&quot;raw&quot;:&quot;üí©&quot;,&quot;html&quot;:&quot;<p>üí©</p>\n&quot;,&quot;updatedAt&quot;:&quot;2023-12-20T03:23:20.638Z&quot;,&quot;author&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/88bb4c4a67dc8958069e9014f5e73a0b.svg&quot;,&quot;fullname&quot;:&quot;Michael Barry&quot;,&quot;name&quot;:&quot;MichaelBarryUK&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false}},&quot;numEdits&quot;:0,&quot;editors&quot;:[&quot;MichaelBarryUK&quot;],&quot;reactions&quot;:[{&quot;reaction&quot;:&quot;üòî&quot;,&quot;users&quot;:[&quot;nlpguy&quot;,&quot;10100101j&quot;,&quot;IsoSpandy&quot;,&quot;hyper88&quot;,&quot;saidattax&quot;],&quot;count&quot;:5}],&quot;identifiedLanguage&quot;:{&quot;language&quot;:&quot;en&quot;,&quot;probability&quot;:0.7121967673301697},&quot;isReport&quot;:false}}],&quot;primaryEmailConfirmed&quot;:false,&quot;paper&quot;:{&quot;id&quot;:&quot;2312.11514&quot;,&quot;authors&quot;:[{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af2&quot;,&quot;name&quot;:&quot;Keivan Alizadeh&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af3&quot;,&quot;name&quot;:&quot;Iman Mirzadeh&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af4&quot;,&quot;user&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/8e440bdf6241be32ea45f72d3f00e05b.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Dmitry Belenko&quot;,&quot;user&quot;:&quot;depthwise&quot;,&quot;type&quot;:&quot;user&quot;},&quot;name&quot;:&quot;Dmitry Belenko&quot;,&quot;status&quot;:&quot;admin_assigned&quot;,&quot;statusLastChangedAt&quot;:&quot;2023-12-20T08:59:28.800Z&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af5&quot;,&quot;name&quot;:&quot;Karen Khatamifard&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af6&quot;,&quot;name&quot;:&quot;Minsik Cho&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af7&quot;,&quot;name&quot;:&quot;Carlo C Del Mundo&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af8&quot;,&quot;name&quot;:&quot;Mohammad Rastegari&quot;,&quot;hidden&quot;:false},{&quot;_id&quot;:&quot;6582524a5f6d8343825e4af9&quot;,&quot;user&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/fc3d149a27bc8396010a2a02148e8ca0.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Mehrdad Farajtabar&quot;,&quot;user&quot;:&quot;mfarajtabar&quot;,&quot;type&quot;:&quot;user&quot;},&quot;name&quot;:&quot;Mehrdad Farajtabar&quot;,&quot;status&quot;:&quot;admin_assigned&quot;,&quot;statusLastChangedAt&quot;:&quot;2023-12-20T08:21:56.790Z&quot;,&quot;hidden&quot;:false}],&quot;publishedAt&quot;:&quot;2023-12-12T18:57:08.000Z&quot;,&quot;title&quot;:&quot;LLM in a flash: Efficient Large Language Model Inference with Limited\n  Memory&quot;,&quot;summary&quot;:&quot;Large language models (LLMs) are central to modern natural language\nprocessing, delivering exceptional performance in various tasks. However, their\nintensive computational and memory requirements present challenges, especially\nfor devices with limited DRAM capacity. This paper tackles the challenge of\nefficiently running LLMs that exceed the available DRAM capacity by storing the\nmodel parameters on flash memory but bringing them on demand to DRAM. Our\nmethod involves constructing an inference cost model that harmonizes with the\nflash memory behavior, guiding us to optimize in two critical areas: reducing\nthe volume of data transferred from flash and reading data in larger, more\ncontiguous chunks. Within this flash memory-informed framework, we introduce\ntwo principal techniques. First, \&quot;windowing'\&quot; strategically reduces data\ntransfer by reusing previously activated neurons, and second, \&quot;row-column\nbundling\&quot;, tailored to the sequential data access strengths of flash memory,\nincreases the size of data chunks read from flash memory. These methods\ncollectively enable running models up to twice the size of the available DRAM,\nwith a 4-5x and 20-25x increase in inference speed compared to naive loading\napproaches in CPU and GPU, respectively. Our integration of sparsity awareness,\ncontext-adaptive loading, and a hardware-oriented design paves the way for\neffective inference of LLMs on devices with limited memory.&quot;,&quot;upvotes&quot;:33},&quot;canReadDatabase&quot;:false,&quot;canManageCommunity&quot;:false,&quot;hasHfLevelAccess&quot;:false,&quot;publishedOnDailyAt&quot;:&quot;2023-12-20T02:32:43.361Z&quot;,&quot;upvoted&quot;:false,&quot;upvoters&quot;:[{&quot;avatarUrl&quot;:&quot;/avatars/2e476fce12c4d48bb1f0ac3e68ddc209.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Kaio Ken&quot;,&quot;user&quot;:&quot;kaiokendev&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/1b4c9afab0c4b10ac50fca0c738bb61a.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;lbn&quot;,&quot;user&quot;:&quot;llbn&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1637711517996-6039478ab3ecf716b1a5fd4d.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:true,&quot;fullname&quot;:&quot;taesiri&quot;,&quot;user&quot;:&quot;taesiri&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/358503a958bacff790c5830f24946378.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Xin&quot;,&quot;user&quot;:&quot;Nuclear6&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1649899774659-6254f8e5d21e4cc386b881ad.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Somshubra Majumdar&quot;,&quot;user&quot;:&quot;smajumdar94&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/62ce50353529c21a228ab2d8/153N-GZ0Vj5YXWMW3noQe.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Se June Joo&quot;,&quot;user&quot;:&quot;Joocjun&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/d44dee29d7aae9e545cb7847d835bae7.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Aiden Shihadeh&quot;,&quot;user&quot;:&quot;sdkv2&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/1e9617311b04bbf296f061a9a85b12cc.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Ai Studio Lab&quot;,&quot;user&quot;:&quot;aistudiolab&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/1674683851722-62441cb7456803e95009a08f.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Arthur Zucker&quot;,&quot;user&quot;:&quot;ArthurZ&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/d6f733991b3011ce53c9055f3083332f.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Erland Hilman Fuadi&quot;,&quot;user&quot;:&quot;Masa-Erland&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;https://aeiljuispo.cloudimg.io/v7/https://cdn-uploads.huggingface.co/production/uploads/637b53a7a2460cde612b127b/urzriWZ00OvHgESYnBlKX.jpeg?w=200&amp;h=200&amp;f=face&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Krinal Joshi&quot;,&quot;user&quot;:&quot;krinal&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;avatarUrl&quot;:&quot;/avatars/8860b175ae0d292bb5ad8502a97b9b9f.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Mous&quot;,&quot;user&quot;:&quot;Anony&quot;,&quot;type&quot;:&quot;user&quot;}],&quot;acceptLanguages&quot;:[&quot;*&quot;]}" data-target="PaperContent">

<div><h2>Abstract</h2>
	<p>Large language models (LLMs) are central to modern natural language
processing, delivering exceptional performance in various tasks. However, their
intensive computational and memory requirements present challenges, especially
for devices with limited DRAM capacity. This paper tackles the challenge of
efficiently running LLMs that exceed the available DRAM capacity by storing the
model parameters on flash memory but bringing them on demand to DRAM. Our
method involves constructing an inference cost model that harmonizes with the
flash memory behavior, guiding us to optimize in two critical areas: reducing
the volume of data transferred from flash and reading data in larger, more
contiguous chunks. Within this flash memory-informed framework, we introduce
two principal techniques. First, "windowing'" strategically reduces data
transfer by reusing previously activated neurons, and second, "row-column
bundling", tailored to the sequential data access strengths of flash memory,
increases the size of data chunks read from flash memory. These methods
collectively enable running models up to twice the size of the available DRAM,
with a 4-5x and 20-25x increase in inference speed compared to naive loading
approaches in CPU and GPU, respectively. Our integration of sparsity awareness,
context-adaptive loading, and a hardware-oriented design paves the way for
effective inference of LLMs on devices with limited memory.</p></div>

<p><a href="https://arxiv.org/abs/2312.11514" target="_blank" rel="noreferrer">View arXiv page</a>
	<a href="https://arxiv.org/pdf/2312.11514" target="_blank" rel="noreferrer">View PDF</a>
	<a href="https://huggingface.co/login?next=%2Fpapers%2F2312.11514">
			Add to collection
		</a></p>



<div><h3>Community</h3>

	


</div>

</div>
		<section>

			<h2>
				Models citing this paper
				<span>0</span></h2>
			<p>No model linking this paper</p>
				<p>Cite arxiv.org/abs/2312.11514 in a model README.md to link it from this page.
				</p>

			<h2>
				Datasets citing this paper
				<span>0</span></h2>
			<p>No dataset linking this paper</p>
				<p>Cite arxiv.org/abs/2312.11514 in a dataset README.md to link it from this page.
				</p>

			<h3>
				Spaces citing this paper
				<span>0</span></h3>

			<p>No Space linking this paper</p>
				<p>Cite arxiv.org/abs/2312.11514 in a Space README.md to link it from this page.
				</p>

			<h2>
				Collections including this paper
				<span>5</span></h2>
			<nav>








					<a href="https://huggingface.co/collections?paper=2312.11514">Browse 5 collections that include this paper
						</a></nav></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rite Aid banned from using AI facial recognition for five years (220 pts)]]></title>
            <link>https://www.ftc.gov/news-events/news/press-releases/2023/12/rite-aid-banned-using-ai-facial-recognition-after-ftc-says-retailer-deployed-technology-without</link>
            <guid>38704830</guid>
            <pubDate>Wed, 20 Dec 2023 02:38:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ftc.gov/news-events/news/press-releases/2023/12/rite-aid-banned-using-ai-facial-recognition-after-ftc-says-retailer-deployed-technology-without">https://www.ftc.gov/news-events/news/press-releases/2023/12/rite-aid-banned-using-ai-facial-recognition-after-ftc-says-retailer-deployed-technology-without</a>, See on <a href="https://news.ycombinator.com/item?id=38704830">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span><span><span>Rite Aid will be prohibited from using facial recognition technology for surveillance purposes for five years to settle Federal Trade Commission charges that the retailer failed to implement reasonable procedures and prevent harm to consumers in its use of facial recognition technology in hundreds of stores. </span></span></span></p>



<p><span><span>‚Äú<span><span>Rite Aid's reckless use of facial surveillance systems left its customers facing humiliation and other harms, and its order violations put consumers‚Äô sensitive information at risk," </span></span>said Samuel Levine, Director of the FTC‚Äôs Bureau of Consumer Protection. <span>‚ÄúToday‚Äôs groundbreaking order makes clear that the Commission will be vigilant in protecting the public from unfair biometric surveillance and unfair data security practices.‚Äù </span></span></span></p>



<p><span><span><span><span><span><span>The <a href="https://www.ftc.gov/system/files/ftc_gov/pdf/2023190_riteaid_stipulated_order_filed.pdf">proposed order</a>&nbsp;will require Rite Aid to implement comprehensive safeguards to prevent these types of harm to consumers when deploying automated systems that use biometric information to track them or flag them as security risks. It also will require Rite Aid to discontinue using any such technology if it cannot control potential risks to consumers.</span></span> To settle charges it violated a <a href="https://www.ftc.gov/news-events/news/press-releases/2010/07/rite-aid-settles-ftc-charges-it-failed-protect-medical-financial-privacy-customers-employees">2010 Commission data security order</a> by failing to adequately oversee its service providers, Rite Aid will also be required to implement a robust information security program, which must be overseen by the company‚Äôs top executives.</span></span></span></span></p>



<p><span><span><span>In a <a href="https://www.ftc.gov/system/files/ftc_gov/pdf/2023190_riteaid_complaint_filed.pdf">complaint</a><b>&nbsp;</b>filed in federal court<b>,</b> the FTC says that from 2012 to 2020, Rite Aid deployed artificial intelligence-based facial recognition technology in order to identify customers who may have been engaged in shoplifting or other problematic behavior. The complaint, however, charges that the company failed to take reasonable measures to prevent harm to consumers, who, as a result, were erroneously accused by employees of wrongdoing because facial recognition technology falsely flagged the consumers as matching someone who had previously been identified as a shoplifter or other troublemaker. </span></span></span></p>



<p><span><span><span><span><span>Preventing the misuse of biometric information is a high priority for the FTC, </span><a href="https://www.ftc.gov/news-events/news/press-releases/2023/05/ftc-warns-about-misuses-biometric-information-harm-consumers"><span>which issued a warning earlier this year</span></a><span> that the agency would be closely monitoring this sector. Rite Aid‚Äôs actions subjected consumers to embarrassment, harassment, and other harm, according to the complaint. </span>The company did not inform consumers that it was using the technology in its stores and employees were discouraged from revealing such information. <span>Employees, acting on false positive alerts, followed consumers around its stores, searched them, ordered them to leave, called the police to confront or remove consumers, and </span><span>publicly accused them, sometimes in front of friends or family, of shoplifting or other wrongdoing, according to the complaint. In addition, the FTC says Rite Aid‚Äôs actions disproportionately impacted people of color.</span></span></span></span></span></p>



<p><span><span><span>According to the complaint, Rite Aid contracted with two companies to help create a database of images of individuals‚Äîconsidered to be<span> ‚Äúpersons of interest‚Äù because Rite Aid believed they engaged in or attempted to engage in criminal activity at one of its retail locations‚Äîalong with their names and other information such as any criminal background data. The company collected tens of thousands of images of individuals, many of which were low-quality and came from Rite Aid‚Äôs security cameras, employee phone cameras and even news stories, according to the complaint.</span></span></span></span></p>



<p><span><span><span><span><span>The system generated thousands of false-positive matches, the FTC says. For example, the technology sometimes matched customers with people who had originally been enrolled in the database based on activity thousands of miles away, or flagged the same person at dozens of different stores all across the United States, according to the complaint. Specifically, the complaint says Rite Aid failed to: </span></span></span></span></span></p>



<ul><li><span><span><span><span><span>Consider and mitigate potential risks to consumers from misidentifying them, including heightened risks to certain consumers because of their race or gender. For example, Rite Aid‚Äôs facial recognition technology was more likely to generate false positives in stores located in plurality-Black and Asian communities than in plurality-White communities;</span></span></span></span></span></li>
<li><span><span><span><span>Test, assess, measure, document, or inquire about the accuracy of its facial recognition technology before deploying it, including failing to seek any information from either vendor it used to provide the facial recognition technology about the extent to which the technology had been tested for accuracy;</span></span></span></span></li>
<li><span><span><span><span>Prevent the use of low-quality images in connection with its facial recognition technology, increasing the likelihood of false-positive match alerts; </span></span></span></span></li>
</ul><ul><li><span><span><span><span><span>Regularly monitor or test the accuracy of the technology after it was deployed, including by failing to implement or enforce any procedure for tracking the rate of false positive matches or actions that were taken based on those false positive matches; and </span></span></span></span></span></li>
<li><span><span><span><span><span>Adequately train employees tasked with operating facial recognition technology in its stores and flag that the technology could generate false positives. Even after Rite Aid switched to a technology that enabled employees to report a ‚Äúbad match‚Äù and required employees to use it, the company did not take action to ensure employees followed this policy.</span></span></span></span></span></li>
</ul>

<p><span><span><span><span>In its complaint, the FTC also says Rite Aid violated its </span><span>2010 data security order</span><span> with the Commission by failing to adequately implement a comprehensive information security program. Among other things, the 2010 order required Rite Aid to ensure its third-party service providers had appropriate safeguards to protect consumers‚Äô personal data. For example, the complaint alleges the company conducted many security assessments of service providers orally, and that it failed to obtain or possess backup documentation of such assessments, including for service providers Rite Aid deemed to be ‚Äúhigh risk.‚Äù </span></span></span></span></p>



<p><span><span><span><span><span>In addition to the ban and required safeguards for automated biometric security or surveillance systems, other provisions of the proposed order prohibit Rite Aid from misrepresenting its data security and privacy practices and also require the company to: </span></span></span></span></span></p>



<ul><li><span><span><span><span><b><span>Delete, and direct third parties to delete</span></b><span>, any images or photos they collected because of Rite Aid‚Äôs facial recognition system as well as any algorithms or other products that were developed using those images and photos;</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Notify consumers</span></b><span> when their biometric information is enrolled in a database used in connection with a biometric security or surveillance system and when Rite Aid takes some kind of action against them based on an output generated by such a system;</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Investigate and respond</span></b><span> in writing to consumer complaints about actions taken against consumers related to an automated biometric security or surveillance system;</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Provide clear and conspicuous notice</span></b><span> to consumers about the use of facial recognition or other biometric surveillance technology in its stores;</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Delete any biometric information</span></b><span> it collects within five years; </span></span></span></span></span></li>
<li><span><span><span><span><b><span>Implement a data security program</span></b><span> to protect and secure personal information it collects, stores, and shares with its vendors; </span></span></span></span></span></li>
<li><span><span><span><span><b><span>Obtain independent third-party assessments</span></b><span> of its information security program; and</span></span></span></span></span></li>
<li><span><span><span><span><b><span>Provide the Commission with an annual certification</span></b><span> from its CEO documenting Rite Aid‚Äôs adherence to the order‚Äôs provisions.</span></span></span></span></span></li>
</ul>

<p><span><span><span><span>The Commission voted 3-0 to<span><span> authorize staff&nbsp;to file the complaint and the proposed stipulated order against Rite Aid</span></span>. Commissioner Alvaro Bedoya <a href="https://www.ftc.gov/legal-library/browse/cases-proceedings/public-statements/statement-commissioner-alvaro-m-bedoya-ftc-v-rite-aid-corporation">released a statement</a>. </span></span></span></span></p>



<p><span><span><span><span>The complaint and order were filed in the Eastern District of Pennsylvania. Rite Aid is currently going through bankruptcy proceedings and the order will go into effect after approval from the bankruptcy court and the federal district court as well as modification of the 2010 order by the Commission.</span></span></span></span></p>



<p><span><span><span><span><span>The principal attorneys on these matters are </span></span><span>Robin Wetherill, Leah Frazier, Diana Chang, Christopher Erickson, and Brian Welke in the FTC‚Äôs Bureau of Consumer Protection.</span><span><span></span></span></span></span></span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build a search engine, not a vector DB (203 pts)]]></title>
            <link>https://blog.elicit.com/search-vs-vector-db/</link>
            <guid>38703943</guid>
            <pubDate>Wed, 20 Dec 2023 00:27:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.elicit.com/search-vs-vector-db/">https://blog.elicit.com/search-vs-vector-db/</a>, See on <a href="https://news.ycombinator.com/item?id=38703943">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <p>In the last 12 months there has been a proliferation of vector DB startups. I‚Äôm not here to debate the specific design tradeoffs of any of them. Instead, I want to push back on several common approaches to what a vector database is, what it‚Äôs for, and how you should use one to solve problems.</p><h3 id="vector-databases-aren%E2%80%99t-memory">Vector databases aren‚Äôt memory</h3><p>Many vector databases frame their basic utility as solving the problem of language models lacking long term memory, or the fact that you can‚Äôt place all of the context for a question into your prompt.</p><figure><a href="https://www.trychroma.com/blog/seed?ref=blog.elicit.com"><img src="https://blog.elicit.com/content/images/2023/12/Search-Engine.png" alt="" loading="lazy" width="653" height="581" srcset="https://blog.elicit.com/content/images/size/w600/2023/12/Search-Engine.png 600w, https://blog.elicit.com/content/images/2023/12/Search-Engine.png 653w"></a><figcaption><span>https://trychroma.com/blog/seed</span></figcaption></figure><p>However, vector search is ultimately just a particular kind of search<em>.</em> Giving your LLM access to a database it can write to and search across is very useful, but it‚Äôs ultimately best conceptualized as giving an agent access to a search engine, versus actually ‚Äúhaving more memory‚Äù.</p><p>Imagine you‚Äôre a company that wants to build an LLM-powered documentation experience. If you think of a vector database as just providing an expanded memory to your language model, you might just embed all of your company‚Äôs product docs, and then let users ask questions to your bot. When a user hits enter, you do a vector search for their query, find all of the chunks, load them into context, and then have your language model try to answer the question. In fact, that‚Äôs the approach we initially took at Stripe when I worked on their <a href="https://stripe.com/newsroom/news/stripe-and-openai?ref=blog.elicit.com">AI docs product</a>.</p><p>Ultimately though, I found that approach to be a dead-end. The crux is that while vector search is better along some axes than traditional search, it's not magic. Just like regular search, you'll end up with irrelevant or missing documents in your results. Language models, just like humans, can only work with what they have and <a href="https://arxiv.org/abs/2302.00093?ref=blog.elicit.com" rel="noreferrer">those irrelevant documents will likely mislead them</a>. </p><p>If you want to make a good RAG tool that uses your documentation, you should start by making a search engine over those documents that would be good enough for a human to use themselves. This likely something your organization has considered before, and if it doesn‚Äôt exist it‚Äôs because building a good search engine has traditionally been a significant undertaking.</p><h3 id="the-good-news">The good news</h3><p>You‚Äôve sat down and decided to build good search, how do you actually do it? It turns out that in this case LLMs can actually save the day.</p><p>Embeddings, for all that they aren‚Äôt a magic wand, are still pretty amazing. High-quality embedding search will have a lower false negative rate than keyword search, and combining the two results in much better performance than any pure fulltext search (Google has been doing this for years with <a href="https://blog.google/products/search/search-language-understanding-bert/?ref=blog.elicit.com">BERT</a>). However, both embeddings themselves and the tools needed to use them in large-scale search, have improved by leaps and bounds. There are plenty of battle-tested databases that let you combine keyword and vector search, and I highly recommend using one of these (at Elicit we use <a href="https://vespa.ai/?ref=blog.elicit.com">Vespa</a>, but vector databases like Chroma now often support this as well).</p><p>Once you‚Äôve improved your overall search by blending embeddings with more traditional methods, you get to the fun stuff. A savvy human trying to find information via a search engine knows how to structure their query in order to ensure they find relevant information (<a href="https://supple.com.au/tools/google-advance-search-operators/?ref=blog.elicit.com">Google-fu used to be a powerful art form</a>), language models can do the same. If your model wants to find ‚Äúwhat‚Äôs the latest news on malaria vaccines,‚Äù you could have a language model construct a query that includes a date filter. There is a ton of low hanging fruit here, and after that an almost endless amount of tweaking that can be done to result in incredible quality search. Like in many other cases, similar things were <strong>possible</strong> in the world before LLMs, but they took a lot of specialized skill and effort. Now you can get competitive performance with a few hours of your time and some compute.</p><p>The final stage in the traditional search pipeline is re-ranking. It used to be the case that to do re-ranking you would <a href="https://www.kdd.org/kdd2016/papers/files/adf0361-yinA.pdf?ref=blog.elicit.com">train a relevancy model</a> on signals like which items a user clicks on for a given search results page, and then use that model to sort your top results. If you‚Äôre not a whole team structured around building a search engine, this isn‚Äôt a viable problem to tackle. Now with language models, you can provide some details on a query:result pair to a model and get a relevancy score that will <a href="https://arxiv.org/abs/2311.07994?ref=blog.elicit.com" rel="noreferrer">beat out all but the best purpose-built systems</a>.</p><p>Ultimately, recent advancements in AI make it much easier to build cutting-edge search, using orders of magnitude less effort than once required. Because of that, the return on sitting down and seriously building good search is extremely high.</p><p>If you want to build a RAG-based tool, first build search.</p><h3 id="postscript-the-bad-news"><em>Postscript (The bad news)</em></h3><p>You‚Äôve built a nice search engine using the above techniques, now it‚Äôs time to deploy it. Unfortunately, language models don‚Äôt let you avoid the other half of building a search engine: evaluating it.</p><p>Specifically, this means being able to answer questions like:</p><ul><li>‚ÄúWhen is doing a search appropriate?‚Äù</li><li>‚ÄúWhen you do a search, what content are you actually trying to locate?‚Äù</li><li>‚ÄúHow high does that content rank in your results?‚Äù</li></ul><p>Answering any of those questions requires building evaluation and monitoring infrastructure that you can use to iterate on your search pipeline and know whether the changes you make are improvements. For a followup on evaluating search engines, I recommend this excellent <a href="https://dtunkelang.medium.com/evaluating-good-search-part-i-measure-it-5507b2dbf4f6?ref=blog.elicit.com">series of posts</a>.</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: Microsoft.com added 192.168.1.1 to their DNS record (453 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38702783</link>
            <guid>38702783</guid>
            <pubDate>Tue, 19 Dec 2023 22:30:52 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38702783">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38703553"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703553" href="https://news.ycombinator.com/vote?id=38703553&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Through a series of connections I know a guy that knows a guy that works at Microsoft that was made aware and the changes have been reverted. Give 'er 30 minutes TTL ;)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38703993"><td></td></tr>
            <tr id="38703779"><td></td></tr>
            <tr id="38703891"><td></td></tr>
                <tr id="38703982"><td></td></tr>
                  <tr id="38703940"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703940" href="https://news.ycombinator.com/vote?id=38703940&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>TTL appears to be set to an hour. But either way, its been 45 min and the primary ns1-39.azure-dns.com is still offering up 0.1</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38704070"><td></td></tr>
            <tr id="38703929"><td></td></tr>
            <tr id="38703720"><td></td></tr>
            <tr id="38703905"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703905" href="https://news.ycombinator.com/vote?id=38703905&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>This isn‚Äôt something that I think should be diluted.<p>If it‚Äôs that simple for a stray record to be included in the dns round robin it could have been bad if it was an external ip with a machine setup by a phisherman especially since control of a domain is all you need to get an ssl cert now.</p><p>Couple this with the fact that it‚Äôs Microsoft, one of the most relied on companies in our computer world, this is pretty darn horrible.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38704042"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38704042" href="https://news.ycombinator.com/vote?id=38704042&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>For all this to work you need to control the domain.
Is that easier than simply breaking into their systems and owning their servers?</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38704217"><td></td></tr>
            <tr id="38703917"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703917" href="https://news.ycombinator.com/vote?id=38703917&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Wait wait wait wait. Bunny.net accidentally changed their DNS to 127.0.0.1 and took a bunch of their CDN users down today too. Coincidence? Weird day.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38704225"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38704225" href="https://news.ycombinator.com/vote?id=38704225&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>Wait... Can DNS resolvers be configured so that RFC1918 is respected?<p>I mean: I don't expect anything less from Microsoft than doing stuff like that and it cannot affect me for I nullroute microsoft.com from my <i>unbound</i> server (<i>unboud</i> takes wildcard when nullrouting or NXDOMAINing crap domains like microsoft.com or meta.com etc., which is sweet).</p><p>However I'd expect my trusty DNS resolver to also prevent me from <i>anyone</i> not on my private LANs to impersonate addresses reserved for private uses.</p><p>Does anyone know here if it's easily doable?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38704159"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38704159" href="https://news.ycombinator.com/vote?id=38704159&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>microsoft.com is currently IPv6-only on my network, because OpenWrt's DNS rebinding protection filters out the A records:<pre><code>  $ ping -4 microsoft.com
  ping: microsoft.com: Address family for hostname not supported

  $ ping -6 microsoft.com
  PING microsoft.com(2603:1030:c02:8::14 (2603:1030:c02:8::14)) 56 data bytes
  64 bytes from 2603:1030:c02:8::14 (2603:1030:c02:8::14): icmp_seq=1 ttl=112 time=68.4 ms</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703344"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703344" href="https://news.ycombinator.com/vote?id=38703344&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>I'm trying to figure out how this could have happened, but I control so few IP addresses that many of my DNS entries are manually assigned. And you'd have to be incompetent if you have access to set DNS records and you set them to RFC 1918 addresses.<p>Anyone have any theories on how this could happen?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38703876"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703876" href="https://news.ycombinator.com/vote?id=38703876&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>I'll go with Joseph Conrad on this one.<p>"It's only those who do nothing that make no mistakes, I suppose."</p><p>Now the persons that did it have some proof that they did something.</p><p>They will surely put some check in place because there should be another adage somewhere that says that you only learn to use the handrails after you fell in the stairs.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38703738"><td></td></tr>
                <tr id="38704144"><td></td></tr>
                  <tr id="38703375"><td></td></tr>
                <tr id="38703870"><td></td></tr>
                        <tr id="38703523"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703523" href="https://news.ycombinator.com/vote?id=38703523&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>that's what happens when you buy address space from the back of a van in the parking lot ;)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38702845"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38702845" href="https://news.ycombinator.com/vote?id=38702845&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>I get it too, with .1.0 as well<pre><code>    Name: microsoft.com
    Address: 192.168.1.1

    Name: microsoft.com
    Address: 192.168.1.0
</code></pre>
"ooopsie!"</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38703802"><td></td></tr>
                <tr id="38703895"><td></td></tr>
                        <tr id="38703179"><td></td></tr>
                <tr id="38703239"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703239" href="https://news.ycombinator.com/vote?id=38703239&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>Potential timeouts for clients/workstations trying to reach microsoft.com.<p>Which entry is picked for use is generally random depending on the client.</p><p>Most systems will retry using another entry though on issues connecting through. That said, if you are on a network that is 192.168 based, trying to get to Microsoft.com may just send you to your local router!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38703419"><td></td></tr>
                  <tr id="38703525"><td></td></tr>
            <tr id="38703773"><td></td></tr>
            <tr id="38703953"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703953" href="https://news.ycombinator.com/vote?id=38703953&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>So let me see if I understand. With this DNS record, if me or Windows tries to hit ‚Äúmicrosoft.com‚Äù there‚Äôs a 1/7 chance it hit my router instead?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38703965"><td></td></tr>
                  <tr id="38703705"><td></td></tr>
                <tr id="38703756"><td></td></tr>
                <tr id="38703834"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38703834" href="https://news.ycombinator.com/vote?id=38703834&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Do most DNS forwarders not block addresses that resolve to a local IP these days? I know dnsmasq does, and NextDNS too I think.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38704185"><td></td></tr>
            <tr id="38703969"><td></td></tr>
                <tr id="38704067"><td></td></tr>
                        <tr id="38704109"><td></td></tr>
                <tr id="38704149"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38704149" href="https://news.ycombinator.com/vote?id=38704149&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>They do: the updates are signed so our hypothetical spies would need to have a zero day in Authenticode or to have compromised the signing keys.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38703031"><td></td></tr>
            <tr id="38703826"><td></td></tr>
                <tr id="38703893"><td></td></tr>
                <tr id="38704064"><td></td></tr>
                <tr id="38704130"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38704130" href="https://news.ycombinator.com/vote?id=38704130&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Even if that is the case, if it is random, some section of DNS would send traffic to it. Maybe it was OK because most resolvers would ignore the local address on the list??</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38703958"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703958" href="https://news.ycombinator.com/vote?id=38703958&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>How the hell did that pass any sort of responsible review process at Microsoft?<p>Now Microsoft owns all your home networks, only like the default address on every home router out there...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38704063"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38704063" href="https://news.ycombinator.com/vote?id=38704063&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>You have the danger of this backwards: this is a very bad security problem <i>for Microsoft</i>, and not a problem for people outside of MS (except to the extent that we're all indirectly reliant on MS being secure). Pointing a domain at an IP address does not give you any power over than IP address, and you can point a domain at anything you want.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38704016"><td></td></tr>
            <tr id="38704040"><td></td></tr>
            <tr id="38704138"><td></td></tr>
            <tr id="38704039"><td></td></tr>
                  <tr id="38704015"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38704015" href="https://news.ycombinator.com/vote?id=38704015&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>Y'all, instead of the constant confirmed here. Just do an authoritative lookup.<p>dig +trace +short microsoft.com</p><p>NS a.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS b.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS c.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS d.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS e.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS f.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS g.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS h.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS i.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS j.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS k.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS l.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>NS m.root-servers.net. from server 100.100.100.100 in 10 ms.</p><p>RRSIG NS 8 0 518400 20240101050000 20231219040000 46780 . fG/YHtUJu3YMAm9Mlzzvp3xG4UCPG01aYNnlyF1HfAHdZpR+L88CVUcz NFHq9M45KjB7ZTlSFt2JvEyK/8FcavZLOthkXRREbJQswjLCbhiPQCbq tQLF+tKaNYUihqawCfjgZy1i5YwYjmphbjfzwoKo1POtepf0YCIcuLBi nQFw4Lr79O6cjyg6qlYnqaK6z4Xi5qt6ocohJafjs86LuuRo2WvmJ1IK k0ZUoAC6Qyjz4MVhqHMvQGdp7EnzjoL8Y9PTXeUuD6Ixp/Aklj2psLjD TZDPYN1q+zDd1giFyuwNRX9DG1zrxzN2lzQiLWmGKrzP3DvFWL1L2Ts1 FWjy/Q== from server 100.100.100.100 in 10 ms.</p><p>;; UDP setup with 2001:502:7094::30#53(2001:502:7094::30) for microsoft.com failed: network unreachable.</p><p>;; UDP setup with 2001:502:7094::30#53(2001:502:7094::30) for microsoft.com failed: network unreachable.</p><p>;; UDP setup with 2001:502:7094::30#53(2001:502:7094::30) for microsoft.com failed: network unreachable.</p><p>A 20.112.250.133 from server 150.171.10.39 in 20 ms.</p><p>A 20.231.239.246 from server 150.171.10.39 in 20 ms.</p><p>A 20.76.201.171 from server 150.171.10.39 in 20 ms.</p><p>A 20.70.246.20 from server 150.171.10.39 in 20 ms.</p><p>A 20.236.44.162 from server 150.171.10.39 in 20 ms.</p><p>A 192.168.1.0 from server 150.171.10.39 in 20 ms.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38704190"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38704190" href="https://news.ycombinator.com/vote?id=38704190&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Or from a bunch of dnses:<pre><code>  $ export srch="192.168.1.0"; echo "as of $(date '+%s';):"; for dns in 1.1.1.1 8.8.8.8 76.76.2.0 9.9.9.9 208.67.222.222 185.228.168.9 76.76.19.19 94.140.14.14; do dig @${dns} microsoft.com +short | grep "${srch}" &gt; /dev/null; if [  $? == 0  ]; then echo "${dns} still has ${srch} for microsoft.com"; else echo "${dns} no longer has ${srch} for microsoft.com"; fi; done
  as of 1703033639:
  1.1.1.1 still has 192.168.1.0 for microsoft.com
  8.8.8.8 still has 192.168.1.0 for microsoft.com
  76.76.2.0 still has 192.168.1.0 for microsoft.com
  9.9.9.9 still has 192.168.1.0 for microsoft.com
  208.67.222.222 still has 192.168.1.0 for microsoft.com
  185.228.168.9 still has 192.168.1.0 for microsoft.com
  76.76.19.19 still has 192.168.1.0 for microsoft.com
  94.140.14.14 still has 192.168.1.0 for microsoft.com
  $ pbpaste | sed 's;^;  ;' | pbcopy</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38703687"><td></td></tr>
                <tr id="38703952"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703952" href="https://news.ycombinator.com/vote?id=38703952&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><p><span>Well in my case (and a lot of other people), 192.168.1.1 is the local address of my home router. So if I go to microsoft.com I have a 1 in 7 chance of getting my home router instead (if I ignore the certificate warning). Other random breakage will happen depending on what that local address is assigned to for you.<p>In theory this could be leveraged for hacking, but I think that would require setup in advance.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38703740"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703740" href="https://news.ycombinator.com/vote?id=38703740&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Since 2 out of the 7 IPs are 192.168 (private ips), 2/7 visitors to microsoft.com will load the private ones assumign equal weight and not get the page to load.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703696"><td></td></tr>
                  <tr id="38703761"><td></td></tr>
                <tr id="38703793"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703793" href="https://news.ycombinator.com/vote?id=38703793&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>Nah, if it's already reverted, they're good to go. A post-mortem with how something like that got through will definitely be on the table though.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703964"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703964" href="https://news.ycombinator.com/vote?id=38703964&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>I'm wondering how such a change would get "merged" in to begin with. I imagine even non-network engineers would get this huge itch having a large corporate contain a private IP in the changelist (I'm the non network engineer and can't really explain why it's bad. But it FEELS wrong and sometimes you at least need to use instinct to get another pair of eyes on something).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703975"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703975" href="https://news.ycombinator.com/vote?id=38703975&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>I hope not. Failures are on a spectrum and this was unfortunate but probably not malicious. All things considered this should be a lesson learned. There should be more failsafe mechanisms in place so juniors can fail safely and learn from them. The absolute worst thing we can do is shame an individual so they don‚Äôt attempt to try new things in fear of ridicule.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38703830"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38703830" href="https://news.ycombinator.com/vote?id=38703830&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>The seniors all go on leave and the interns are left to run the place. If they fired the juniors the seniors would have to come back from holiday!</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38703730"><td></td></tr>
            <tr id="38703118"><td></td></tr>
            <tr id="38702823"><td></td></tr>
            <tr id="38703700"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38703700" href="https://news.ycombinator.com/vote?id=38703700&amp;how=up&amp;goto=item%3Fid%3D38702783"></a></center>    </td><td><br><div>
                  <p><span>I don‚Äôt know man, putting microsoft.com on your router sounds like a massive reduction in latency. Congrats on the achievement.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38702903"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Closing of the Bulgarian Frontier (125 pts)]]></title>
            <link>https://www.switchyardmag.com/issue-1/bulgarianfrontier</link>
            <guid>38702276</guid>
            <pubDate>Tue, 19 Dec 2023 21:59:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.switchyardmag.com/issue-1/bulgarianfrontier">https://www.switchyardmag.com/issue-1/bulgarianfrontier</a>, See on <a href="https://news.ycombinator.com/item?id=38702276">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">
        
          
<article id="sections" data-page-sections="6529e1a1ecc7e60d996474cc">
  
  
    
    


  


<div data-content-field="main-content" data-item-id="" data-test="page-section" data-section-theme="light" data-section-id="6529e1a1ecc7e60d996474ce" data-controller="SectionWrapperController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;sectionTheme&quot;: &quot;light&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-current-context="{
&quot;video&quot;: {
&quot;playbackSpeed&quot;: 0.5,
&quot;filter&quot;: 1,
&quot;filterStrength&quot;: 0,
&quot;zoom&quot;: 0,
&quot;videoSourceProvider&quot;: &quot;none&quot;
},
&quot;backgroundImageId&quot;: null,
&quot;backgroundMediaEffect&quot;: null,
&quot;divider&quot;: null,
&quot;typeName&quot;: &quot;blog-basic-grid&quot;
}" data-animation="none">
  <article id="article-">
  
    <div data-layout-label="Post Body" data-type="item" id="item-652e0d3fd11d3d0e62042dcc"><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-a7d7db2923ae332d9afa">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg" data-image-dimensions="2400x1600" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg" width="2400" height="1600" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6a15015-4c8d-4ee3-81cd-810400d239e8/7545AA018.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-2244ed8deedcf9bff2db">
  <p><strong>Essay by Dimiter Kenarov</strong></p><h4><em>All illustrations featured in this essay are part of the Bulgarian Visual Archive, a digital project that curates thousands of found and donated photographs. BVA aims to narrate the history of 20th-century Bulgaria through the visual record of both private and public events that have usually been pushed to the margins of official narratives. As part of its mission, BVA offers all of its photographs for download free of charge, for both personal and commercial purposes.</em></h4>
</div><div data-block-type="2" id="block-5d1f1296bc3b4679c365">
  <p><span data-text-attribute-id="af3819f5-11a4-463c-bba6-a306b093c33a">As the plane began its final approach to the Sofia airport, I leaned to look out the porthole. Gray fields and mangy patches of overgrown post-industrial wasteland lay scattered outside the city.</span></p><h4>Next came the monolithic mazes of Communist-era apartment blocks‚Äîblocks I had grown up in‚Äîfollowed by older jumbles of red-tiled roofs and, scattered in between, free-standing clusters of freshly built condos and office towers. Downtown, along Sofia‚Äôs famed yellow cobblestones (‚Äúthe yellow-brick road,‚Äù as English-language tour guides jauntily refer to it) rested the triangular Stalinist behemoth of ‚ÄúThe Party House,‚Äù the former headquarters of the Bulgarian Communist Party, now topped by the country‚Äôs tricolor instead of its original red star. The spot nearby, where the cube-shaped mausoleum of Georgi Dimitrov (‚Äúthe Great Leader and Teacher of the Bulgarian people‚Äù) had once stood, was now a flat, empty lot, an oversize Malevich square. Tsarigradsko shose, previously known as Lenin Boulevard, was choked with traffic. Though everything appeared disorderly from above, it was exactly what I was looking for: a sense of things happening, a sense of time changing, a new frontier.</h4><h4>It was the end of 2010, and I had decided to move back to my native Bulgaria. I‚Äôd spent more than a decade in the United States, getting an education and putting a life together, and had never imagined I‚Äôd be retracing my steps eastward someday, like a criminal revisiting a crime scene. Some people considered you a failure if you came back; they said you lacked ambition and inner resources to stick it out. If you were lucky enough to get away, why throw your luck to the dogs? Wasn‚Äôt it better to settle down in a ‚Äúnormal‚Äù place, where buses ran on time and you didn‚Äôt need to bribe every traffic cop who pulled you over? It was perfectly fine to visit your relatives for a week over Christmas or to sprawl during the summer on the beaches of the Black Sea, splurging hard-earned cash to make the neighbors envious, but to return home for good, unforced by circumstances, bordered on madness. It was irrational, irresponsible, and possibly suicidal. The imp of the perverse. You never looked over your shoulder, lest you turn into a pillar of salt.</h4><h4>It was, admittedly, a strange decision on my part. I wasn‚Äôt unhappy abroad or nostalgic for home. I didn‚Äôt have trouble adjusting to the trappings of my adopted country. I was neither a desperate war refugee with only the clothes on my back, nor a political exile constantly complaining about the tastelessness of local cuisine. The concept of ‚Äúculture shock‚Äù that people tended to talk so much about was foreign to me. I‚Äôd gone to the States after graduating high school in Sofia to attend on a scholarship a small liberal arts college in Vermont and, later, a graduate program in California, and had never had issues fitting in. Mine was the American dream, I suppose, the one that promised you could be nobody and thus anybody. Like Huck Finn, I felt free to ‚Äúlight out for the Territory,‚Äù unburdened by my history and culture, even by my language, and by all the parochial concepts of identity I had been raised on.&nbsp;</h4>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-5c5b934440d252ce549a">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg" data-image-dimensions="1600x2400" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg" width="1600" height="2400" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/f5cb6737-7ff5-4b5f-b6be-cfd33ceb7c69/7581AA011.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-485d8bfe18377d7385f7">

<p>
  <h4>As the years wore on, however, I came to make another discovery: I was late to the party. I had traveled to the westernmost frontier of the Western world, but the frontier had long since ceased being one. My dream was dated, even clich√©d. The States felt like an old place, weirdly older than Europe, a place where, for all its breathless movement, time seemed to have stopped. There was too much of everything: rules, work, wealth, poverty, guns, art. Somehow, over the years, the machine had become overly complex, the foundations slowly but inexorably sinking under the weight of its ever-growing bulk. Even the road to self-renewal and originality, the road less traveled by, was now well-trodden, part of a tired discourse endlessly advertised and monetized and absorbed within a system of capital. The celebrated American self had become another commodity on the shelf of the cultural supermarket. To go to the woods ‚Äúto live deliberately,‚Äù like Henry David Thoreau had done, now required submitting a twenty-page application for a research grant and at least three recommendations.</h4><h4>That was when an idea occurred to me: What if I moved back? Wasn‚Äôt Bulgaria, in all of its dinginess and provincialism and unpredictability, exactly the kind of frontier I was looking to explore, where the clock was still ticking forward toward some unknown horizon? After all, the world is round and if you travel west of ‚Äúthe West‚Äù you‚Äôd eventually bump into ‚Äúthe East.‚Äù To abandon my peaceful but mostly prospectless academic life in the States in order to plunge into the cesspool of my homeland was a bit of a gamble, but also, I thought, the most American thing I could do. I liked what the poet T. S. Eliot had written: ‚Äúthe end of all our exploring / Will be to arrive where we started / And know the place for the first time.‚Äù It was the classic narrative arc of journeys at least since <em>The Odyssey</em>. Could it be, I mused, that real freedom resided not in the freedom to leave but in the freedom to return?</h4><h4><strong>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢</strong></h4><h4>I was born<strong> </strong>in Sofia, the capital of what was still then the People‚Äôs Republic of Bulgaria, in 1981‚Äîeight years before the collapse of the country‚Äôs Communist regime. My childhood memories of that period are fragmentary and uneventful, nothing outlandishly totalitarian to titillate the imagination. Maybe I wasn‚Äôt old enough to serve as a witness or maybe the system was already too exhausted to care about propagating its genes in my generation, the last one to grow up under its tutelage, and my brush with the ideology of the day was rather innocuous, bland even. When I started school, I received my Young Pioneer‚Äôs blue neckerchief (the red one was reserved for older kids) and publicly swore allegiance to the organization‚Äôs flag; I had to learn a poem by heart about the first cosmonaut Yuri Gagarin (‚ÄúYuri Gagarin, how did you fly? / Was it fast, your rocket ship white?‚Äù); I read a celebrated Soviet novel <em>Timur and His Squad</em> about a gang of children secretly doing good deeds and another, a Bulgarian one, about Mitko Palaluzov, a young boy in the country‚Äôs Communist underground (the partisans) during the Second World War who died tragically. Other than that, nobody cared much about my proper political education. We did visit once on a school field trip the mausoleum of Georgi Dimitrov, where the mummified body of Bulgaria‚Äôs first Communist prime minister was laid out in a funeral chamber, yet that seemed more like an adventure than pilgrimage. Lit up by ghostly lights in his glass sarcophagus, Comrade Dimitrov was lying peacefully there, his head slightly propped up on a pillow, like Snow White. Even the idols of the past were now nothing more than characters in a cheap, fairytale diorama.&nbsp;</h4><h4>At that time, in the 1980s, my family and I were residing in a tower block in Student Town, a neighborhood on the outskirts of Sofia designed to function as a large, centralized campus. My parents had arrived in the capital from the provinces to attend university and, after graduating, had married and decided to stay on: my father working as an anesthesiologist at a large hospital and my mother as a computer programmer in Bulgaria‚Äôs nascent IT sector. Since neither of them had official Sofia residency yet (a prerequisite to remain in the city), living in a dormitory was their only available option.&nbsp;</h4>
</p>




















  
  



</div><div data-block-type="2" id="block-105c9347a29ffdced4ec">

<p>
  <h4>Student Town was still in the early stages of development, and its few academic and residential buildings were surrounded by wild fields, where one could still occasionally encounter flocks of sheep. Yet this seemingly pastoral, marginal corner of Sofia was its most cosmopolitan: young men and women from all over the post-colonial socialist world‚ÄîVietnam, Syria, Cuba, Egypt, Ethiopia, Mozambique, Congo-Brazzaville‚Äîhad relocated to Bulgaria to get their university degrees and strengthen the bonds of internationalism. Some had brought their kids along, who played with us Bulgarians. It was a glorious time, the way childhood is often glorious, regardless of skin color or political systems. Most days we were busy exploring the meandering footpaths branching out of our respective dorms or doodling in student notebooks left unguarded in one of the common reading rooms. Our favorite activity, however, was sailing on a makeshift raft of Styrofoam in an enormous ditch filled with rainwater close to the Karl Marx Institute of Economics. &nbsp;</h4><h4>We kids had no idea how or when or why that ditch had been dug, but its size‚Äîroughly 500 meters long and 20 meters across, if memory serves me right‚Äîfascinated us, like the mysterious remnants of a lost civilization. Years later, I found out that we‚Äôd actually played in what had been part of a defunct Communist-era mega-project informally known as ‚Äúthe Sofia Sea,‚Äù which had envisioned a network of navigable canals, connecting to the Danube, 150 kilometers to the north, and from there to the Black Sea and the rest of the world. The plan had been first conceived by Party bureaucrats in the early 1950s, probably drawing inspiration from Stalin‚Äôs famous call for ‚Äúthe great transformation of nature,‚Äù which encouraged radical human interventions in the form of land management and waterworks construction. Sofia was landlocked and hemmed on all sides by mountains, but so what? Shouldn‚Äôt Communism dream big? If Moscow had its Moscow River, why couldn‚Äôt Sofia have its Sofia Sea?&nbsp;</h4><h4>With neither sufficient labor force nor adequate machinery for an undertaking on this scale, the Bulgarian regime had decided to look for ‚Äúvolunteers‚Äù among Sofia‚Äôs own residents. Equipped with only shovels and pickaxes, factory workers and secretaries and doctors and engineers toiled on weekends and holidays in the canals over a period of several years. Jokes abounded about breeding crocodiles there some day and repurposing shovels as oars. If somebody was late to work, they‚Äôd explain to their boss with a smile that they had waited for the ship, but it had never arrived and they‚Äôd been forced to walk. Finally, in the mid-1960s, a few level-headed experts determined that completing the project could cause mass flooding in the city. A decision was made to discontinue digging‚Ä¶ and commence burying. The latter job had never been properly completed either and that was how, two decades later, a few kids from all over the world got to sail on a makeshift raft of Styrofoam in an enormous ditch filled with rainwater. Without ever intending to‚Äîstrange are the ways of history‚Äîwe had realized the unfulfilled Communist dream of ‚Äúthe Sofia Sea.‚Äù</h4>
</p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-c06dc45a8033dd58a4bd">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg" data-image-dimensions="1600x1067" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg" width="1600" height="1067" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/e6137290-68c2-4244-a8b0-d69687cfdeec/7660AA010.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-0a7e132aa5fee0506960">

<p>
  <h4>Seen in retrospect, that dug-and-buried network of canals was perhaps something of a metaphor for the general state of affairs at the time, of what had happened to the system. Like elsewhere in Eastern and Central Europe, the Communists had taken over the government of my home country in a Soviet-backed coup at the end of the Second World War with the professed idea of radically transforming society and politics on Marxist terms, but following the initial ‚Äúrevolutionary‚Äù period, the regime‚Äôs grand ambitions had to be methodically scaled down. Certainly, there were still endless bromides about building ‚Äúthe bright future,‚Äù when bread would be free (supposedly by the year 2000) and social class would disappear and the means of production would have no single owner (Engels‚Äôs ‚Äúwithering away of the state‚Äù). There were monumental Party congresses full of mind-numbing speeches about fulfilling in four years the next five-year economic plan, about the higher (always higher) production of wheat and eggs and pork, about the ever-better material conditions of the people and their improving access to consumer goods, but even the staunchest believers were already aware all of that was just a charade, going through the motions. Sailing in Sofia would never be possible, and it was wiser to bury the evidence of the effort.&nbsp;</h4><h4>By the early 1970s, Bulgaria, like Brezhnev‚Äôs Soviet Union and the rest of the Soviet Bloc, was stuck in ‚Äústagnation‚Äù‚Äîor ‚Äúreal socialism,‚Äù as local ideologues preferred to call it euphemistically. Gradually, the country was transforming into a quiet and somewhat boring totalitarian backwater, drab but not poor, politically oppressive but not excessively bloodthirsty, not anymore. The vast majority of citizens went to work, shopped for whatever scarce items were available at the stores, got married, raised kids, saved money to furnish their modest apartments and houses, went to restaurants on special occasions, to the movies or the theater on weekends, took annual vacations at one of Black Sea resorts or somewhere in the mountains. Marxism continued to be the state religion, and you went along with its rituals, the way people in the West still went to church, but nobody had any faith left. Worse, nobody could see a future, a social horizon, especially after the violent suppression of the Prague Spring, the last genuine revolution in the region. Communism had always relied on teleology for its existence, but now the frontier had been closed. It was as if time itself had stopped moving forward and had entered a cyclical almost medieval agricultural pattern: winter, spring, summer, autumn; winter, spring, summer, autumn; 10th Congress of the Party, 11th Congress of the Party, 12th Congress of the Party, 13th Congress of the Party.&nbsp;</h4><h4>Perhaps that was why the Communist regimes all across Eastern and Central Europe collapsed in the final run. Not so much because of their beleaguered economies, although that was an important factor, but because no one believed anymore. Life is always transitory, a ceaseless metamorphosis, and when the possibility of change disappears, when the frontiers disappear and times turns cyclical, a process of decay inevitably sets in.</h4><h4><strong>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢</strong></h4><h4>It was the<strong> </strong>best of times, it was the worst of times, a feast in a time of plague, a carnival ride amid carnage. Even to this day, more than thirty years later, it‚Äôs hard for me to explain coherently what happened in Bulgaria immediately after ‚Äúthe changes‚Äù of 1989. It seems like something out of a dream, scraps of images and phrases and music and emotions jumbled together, a kind of bottled up energy suddenly released into the open. This wasn‚Äôt the end of history, as Francis Fukuyama had suggested, but its opposite, the rusty arms of the clock grinding into gear once again, the train departing its rural station after years of delay. Time sped up so abruptly‚Äîa bullet train‚Äîit made many of the passengers on board dizzy.&nbsp;</h4>
</p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-492ba006d29df9fe5028">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg" data-image-dimensions="1600x1067" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg" width="1600" height="1067" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/32a66d87-43a2-4d63-a5e0-501fb5827ecf/191110AA015.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-f1d30bfd24c50801aa73">

<p>
  <h4>‚ÄúDe-mo-cra-cy,‚Äù shouted people everywhere in the squares, waving flags and holding up placards. <br> I remember the initial joy and hope that the nightmare of the past was over and better times awaited ahead. No more single-party rule with dimwitted men at the helm, no more Soviet control, no more mass surveillance and secret files, no more political prisoners, no more censorship, no more mindless ideological garbage, no more planned and wasteful economy, no more Party privileges and corruption, no more one type of everything (or nothing) in the stores, no more waiting for ten years to buy a car, no more denied passports and closed borders, no more grayness, no more human indignities. It was a naive and idealistic vision perhaps, but no less real for that. For 45 years, Bulgarians had been kept in a huge high-security prison, the size of a country, only occasionally allowed a glimpse through the iron bars, and isolation of that length tends to inflame the imagination. When the mind is not allowed to wander out, it naturally goes in, deeper into fantasy. Overheard stories of life on the other side, in ‚Äúthe free world,‚Äù take on the quality of fairy tales, of myth‚Äîand myth is always bound to prove a disappointment at the end.</h4><h4>What happened in Bulgaria during the 1990s was what happened in so many other places across Eastern and Central Europe. Prepared and well-positioned, members of the former Communist Party elite managed the whole transformation of the system from the inside, privatizing, so to speak, their own state power. Behind the suave rhetoric of democracy and freedom, they were busily transferring public funds into their personal accounts, creating companies and mafia conglomerates. The highly repressive functions of the totalitarian machinery disappeared, but money was no worse an instrument of control, perhaps even a better one because more refined and insidious.&nbsp;</h4><h4>At the same time, the sudden shift to a market economy tanked the country‚Äôs long-suffering industries. Obsolete factories churning out obsolete commodities couldn‚Äôt survive the global competition for long, and many of them had to shut down for good, leaving thousands of workers unemployed and unemployable. A large portion of Bulgaria‚Äôs residents lost their life savings to hyperinflation or were cheated out of them by pyramid schemes. It was not uncommon to see engineers driving taxis or pensioners with doctorates sifting through battered dumpsters. At night, Sofia was shrouded in sepulchral darkness and the few street lamps that glowed appeared to absorb, rather than give off light. Store shelves were often empty‚Äîeven emptier than before‚Äîand for a while the government had to introduce ration cards for food staples, just like in wartime. I remember how my father would get up at four in the morning to stand in line for bread and milk or how my mother blacked out once waiting to buy a half-pack of detergent. There were constant electric outages, and we‚Äôd have dinner by the flicker of candlelight in our new prefab apartment in Sofia‚Äôs Nadezhda quarter. We had no central heating installed yet, so in the winter all of us slept with our clothes on.&nbsp;</h4>
</p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-3e90d945f39836f2b8f3">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg" data-image-dimensions="1600x1102" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg" width="1600" height="1102" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/bc995fde-5e71-4d5f-bd1e-8ed7971f486f/0037127.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-8c30390d270fedd5f0b4">

<p>
  <h4>In spite of all the economic hardship and rampant crime, in my memory the 1990s stand out as a glorious, sublime era. In the immediate wake of ‚Äúthe changes,‚Äù Bulgarians felt a rush of excitement for the future: participating in politics, publishing independent newspapers, creating provocative art, starting private businesses. My mother left her state job (she‚Äôd had a leading role in developing Bulgaria‚Äôs first information system for traffic control) to run the risk-assessment and anti-fraud management system of a large French bank; my father was promoted, at age 38, to medical director of his hospital. My paternal grandparents transformed their garage in a provincial town into a general store, while my maternal ones started a rabbit farm on the premises of their village property. Almost everybody, regardless of age, wanted to do something bold with their newfound freedom, to risk and experiment. It was like living in a frontier settlement, but where the frontier was not defined by the movement across physical borders, but across social and personal ones. There was, to quote the classic theoretician of the American frontier Frederick Jackson Turner, ‚Äúcoarseness and strength combined with acuteness and inquisitiveness; that practical, inventive turn of mind, quick to find expedients; that masterful grasp of material things, lacking in the artistic but powerful to effect great ends; that restless, nervous energy; that dominant individualism, working for good and for evil, and withal that buoyancy and exuberance which comes with freedom.‚Äù</h4><h4>As I entered my teenage years, I came to encounter everything that had been previously censored or just in scarce supply: loud music, experimental art, porn, drugs. There were no rules to adhere to anymore. Nobody made boys cut their hair if it was too long or rubber-stamped girls‚Äô thighs if their skirts were too short, as had been common practice in schools. I didn‚Äôt care much about long hair, but I dyed mine green, then blue, then purple. I got into freestyle snowboarding and punk rock. You could wear anything you fancied, tight or baggy or skimpy, and get as many piercings and tattoos as your body could possibly hold. Listening to the Beatles‚Äîtame, unoffending Beatles‚Äîhad once been semi-illicit, akin to dissidence, and passing their records around had gotten not a few hot heads into trouble. Under the new system, record stores began to openly pirate and sell any music available, from the Sex Pistols to Cannibal Corpse. Theaters, shaking off the conservative, parochial mores of the Party, would put on radical performances by Beckett and Ionesco, Jean Genet and Heiner M√ºller, Sarah Kane and Eve Ensler, naked actors sometimes roaming the stage or just ranting in a delirium. Literature followed suit, plunging into postmodern irony and games, throwing off the bondage of the past. It was marvelous.&nbsp;</h4><h4>Even the mausoleum of Georgi Dimitrov, the mummy now removed and safely cremated, took on a life of its own: explicit graffiti covered the limestone walls, the doors swung wide open for staggering drunks who needed a place to relieve themselves; skateboarders rode around, doing kickflips and nose grinds on the decorative curbs; an American evangelical pastor, intent on saving the souls of former commies, organized a revival meeting in the square facing the relic, with thousands of people crowding the viewing stands where members of the Politburo had once greeted the parading masses‚Äî‚ÄúGod is healing you now! In the name of Jesus! Hallelujah!‚Äù he shouted while laying hands on the faithful to cast out their demons, perhaps the demons of the past; in 1996, when the movie&nbsp;<em>101 Dalmatians</em>&nbsp;came out, some PR brain made the brilliant decision to rent the mausoleum as advertising space and cover its white exterior in huge black spots; the next year, an impressive production of Verdi‚Äôs&nbsp;<em>Aida</em>&nbsp;used the edifice as a set. The mausoleum was eventually‚Äîand sadly‚Äîremoved in 1999 by anti-Communist political crusaders, but even its act of demolition became a sort of artistic performance: it took several attempts to blow it up, spectators laughing and cracking jokes at each unsuccessful blast, until a decision was made to take it apart bit by bit.</h4>
</p>




















  
  



</div><div data-block-type="2" id="block-e2e073f3966ba54c0938">

<p>
  <h4>Meanwhile, the party (non-Communist) scene exploded as well. Hundreds of bars and nightclubs set up shop in recently privatized facilities‚Äîcommunity centers, abandoned swimming pools, movie theaters‚Äîwhere cheap booze flowed to the sound of pop-folk beats and the eye-popping beams of strobe lights and glitter balls. Bacchanalian crowds, dressed up in the most outrageous fashion, danced to rave beats through the night. The first gay establishments gingerly tested the ground too, hidden away in dingy, smoke-filled basements, where one had to press a secret doorbell to gain entry‚Äîstill secretive but no longer illegal. There were even ‚Äúchildren‚Äôs discotheques,‚Äù ostensibly safe party spaces for the underage, but which frequently turned raucous, with 14-year-olds downing vodkas and throwing up in the toilets. As for marijuana, it was available to anybody who wanted it. It was so cheap you could buy whole bags for a pittance, as my friends and I did. When that proved insufficient, there was Ecstasy and benzos, uppers and downers, as well as grandma‚Äôs Parkinson‚Äôs medication that gave you amazing hallucinations. The most reckless turned to heroin, but that was a whole different game, where many tragically lost their footing.&nbsp;</h4><h4>This newfangled liberty could be dangerous of course, deadly even, yet danger also made up part of the excitement. As Hunter S. Thompson wrote about the counterculture moment in San Francisco, ‚ÄúNo explanation, no mix of words or music or memories can touch that sense of knowing that you were there and alive in that corner of time and the world.‚Äù The 1990s were truly Bulgaria‚Äôs 1960s, the period when the frontiers opened and time started moving forward again. A belated revolution.&nbsp;</h4><h4><strong>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢</strong>	</h4><h4>When I returned<strong> </strong>to Bulgaria in 2010, the country was already officially part of the European Union. The chaos of those early post-Communist years had subsided quite a bit, crime rates had gone down, and Sofia looked dapper, the parks spruced up and the streets cleaner. There was a huge range of restaurants and bars with exotic menus, name-brand stores and shopping malls, where one could hit the gym or the ice-skating rink after watching a blockbuster movie. The local IT sector was booming, co-working spaces were popular, hipsters roamed the art galleries and fancy cafes, and budget flights landed several times a day from all over Europe. Outside of the city center, the old Communist-era apartment blocks looked as bleak as always and, if you traveled a short distance beyond the capital, you immediately encountered poverty and desperation, but at least among a certain urban class of Bulgarians (to which I also belong), the promises of market liberalism and democracy were bearing fruit. &nbsp;</h4><h4>In the years that followed, I dived into the local scene with enthusiasm, without any regret for having left the States. I had never really believed in the idea of home, I had always been something of a vagrant‚Äî‚Äúa rootless cosmopolitan,‚Äù in the dismissive phrase of Stalin‚Äîyet returning to my native place, seeing it afresh, gave me enormous pleasure. Plus, there was so much still to be done, so much open space. I had already started working as a freelance journalist for US media, writing long-form features from the region, and I had a whole list of interesting topics I began to tackle as both an insider and outsider: hot political and cultural issues, social and environmental problems, the burden of the totalitarian past.&nbsp;</h4>
</p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-71cfa9276acea6ff2ea4">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg" data-image-dimensions="1600x1067" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg" width="1600" height="1067" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/4c85f055-4624-4408-970e-251109c6a316/7735AA030.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-49252d08bca699a921fe">

<p>
  <h4>Even so, the longer I remained in Bulgaria and the region, the more I was haunted by the uncomfortable feeling that a frontier was closing once again. Residual energy from the 1990s still hung in the air, a desire for experimentation still bubbled on the fringes, as the influx of EU capital had not completely smothered creative disorder‚Äîthe most essential of life conditions‚Äîbut I could already see clouds gathering somewhere in the distance. A lot of Bulgarians were certainly better off since ‚Äúthe changes,‚Äù or at least they could afford to buy more commodities and travel abroad as they wished, but they had become tired, more apathetic, less imaginative, their dreams smaller. Maybe that was the fate of any revolution: after the initial bang, there‚Äôs a natural period of calm, a dust-settling. The body can‚Äôt always live on the edge, in a whirlwind of adrenalin‚Äîit‚Äôs much too exhausting. There is a time for everything, as the prophet tells us: a time to scatter stones and a time to gather them, a time to tear and a time to mend, a time for war and a time for peace.&nbsp;</h4><h4>There was an uncomfortable paradox though: the more life organized, the more it settled into a routine; the more affluent and peaceful society became, the better paved the roads and the fancier the cars, the more normal and orderly the days‚ÄîI suppose the public ideals journalism indirectly fights for‚Äîthe fewer possibilities glimmered on the horizon. As civilization tamed the wilderness‚Äîto use an antiquated and controversial but in this case perhaps not wholly irrelevant metaphor‚Äîsomething intangible was lost: a spirit, perhaps, or an aspiration it‚Äôs difficult to put my finger on. For all its numerous faults, the 1990s had sparked one of those utopian visions of building a new world atop the ashes of the old, as Communism had once done.&nbsp;</h4><h4>Next came the bureaucratic goal of joining the European Union‚Äî‚Äúthe civilized world,‚Äù in the lingo of politicians‚Äîwhich a vast majority of Bulgarians felt enthusiastic about. When that was finally achieved, however, grand, inspirational ideas for the future seemed to gradually peter out. Occasional crises like migration, environmental issues, the need for judicial reform, and the rampant political corruption kept Facebook filled with outrage and the media pundits occupied, but those usually melted into oblivion with the next news cycle. What should Bulgarians strive for next? What should they look forward to? Consumer society offered one solution, of course‚Äîa new TV, a new smartphone, a new car, a new apartment‚Äîbut that could be only a temporary fix, for even the acquisition of new objects grows old in the end.</h4><h4>&nbsp;<strong>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢</strong></h4><h4>Have I been<strong> </strong>late again, I often ask myself when I think about my return to Bulgaria a decade ago, the frontier more or less tamed by the time I had arrived? Or is this just the way of the world, the order of things? Or is it my constant craving for novelty and excitement, the specific chemistry of my brain that has distorted my expectations and made me project my unresolved psychological drives onto the social and political canvas? Or is there, indeed, some general malaise that imbues our current moment, a common feeling of a dead end?&nbsp;</h4><h4>It‚Äôs a conundrum impossible to resolve. Yet, faced with it, I recall Thomas Mann‚Äôs <em>The Magic Mountain</em>, one of the greatest novels on the subject of time. Its protagonist Hans Castorp goes to pay what is supposed to be just a short visit to his ailing cousin at a TB sanatorium in the mountains of Switzerland, but for a variety of reasons (illness, love, love as illness) he ends up staying for seven years. Initially, everything is new to him, so packed with remarkable encounters and incidents, thoughts and impressions, that the duration of time stretches out and each day feels like weeks. As the weeks turn into months and the months into years, however, as his mind becomes habituated to its environment, as routine sets in and morphs into endless repetition, time quickens its pace and blurs to such a degree that its passing becomes almost imperceptible to the senses and, for all intents and purposes, it ceases to exist. And here is Mann himself on the issue:</h4><h4>For the moment we need to recall the swift flight of time‚Äîeven of a quite considerable period of time‚Äîwhich we spend in bed when we are ill. All the days are nothing but the same day repeating itself‚Äîor rather, since it is always the same day, it is incorrect to speak of repetition; a continuous present, an identity, an everlastingness‚Äîsuch words as these would better convey the idea. They bring you your midday broth as they brought it yesterday and will bring it tomorrow; and it comes over you‚Äîbut whence or how you do not know, it makes you quite giddy to see the broth coming in‚Äîthat you‚Äôre losing a sense of the demarcation of time, that its units are running together, disappearing; and what is being revealed to you as the true content of time is merely a dimensionless present in which they eternally bring you the broth.</h4><h4>Ay, there‚Äôs the rub: the broth. Maybe I‚Äôm imagining this, but it seems that all of us‚Äîin Bulgaria, in the rest of Europe, in the United States‚Äîare lying sick in our beds while somebody is bringing us the same broth over and over again. For the closing of frontiers is not simply a spatial issue, but a temporal one as well, as space and time are, of course, interrelated. Like Communism, capitalism is a teleological system at its root, relying on a narrative of progress, on a forward-moving vector of time, but when that time turns cyclical, repetitive, without a clear direction, the system begins to disintegrate, not under the weight of its own contradictions, as Marx would tell us, but under the weight of its own uniformity. The recent coronavirus epidemic, which measured itself in seasons‚Äîwinter spikes followed by summer lows‚Äîonly made that condition legible. But social media too, with the essentially cyclical nature of its feeds, with its intermittent flows of information that blur into non-information, has deepened the sensation that one is wasting away in the prison of timelessness. We‚Äôre often told that we live in the most dynamic period in human history, where change‚Äîpolitical, economic, technological‚Äîhappens on a nearly daily basis. That is true on the physical level, of course, but the psychological optics are rather different. Like a wheel that spins so fast that its spokes appear stationary or moving backwards even (the so-called wagon-wheel effect), the fast rate of transformation has come to feel like stasis. Hurtling toward a black hole, we seem to be endlessly stuck, horizonless, in the event horizon.&nbsp;</h4>
</p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-ea50f4110486adad3f50">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg" data-image="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg" data-image-dimensions="1600x1067" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg" width="1600" height="1067" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/65203ed8bebd9d456c1ad651/d6243ab7-9a2c-4087-871b-0f9b75024f71/1696409.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-b9e71e23da5a8285e73a">

<p>
  <h4>Today, we have become citizens of a global, Brezhnevian capitalist state, which, in its failure to provide an inspiring frontier‚Äîgone are the days of Kennedy‚Äôs ‚ÄúNew Frontiers‚Äù or Obama‚Äôs ‚ÄúChange We Can Believe In‚Äù‚Äîhas slowly ossified and wrapped back upon itself. My feeling is that all the troubles we‚Äôve been witnessing over the last decade‚ÄîTrumpism, Brexit, the rise of nationalism all over Europe, Russia‚Äôs virulent imperialism‚Äîare attempts to disrupt not just the dominant political systems, but the zone of eternal repetition. In most cases, these attempts are ridiculous, ersatz, misguided imitations of ideologies borrowed from the past, exposing their own imaginative shortages‚Äîthey aspire to move the hands of the clock, even if backwards‚Äîbut it‚Äôs hard to deny they represent dissatisfaction and resentment with the way things are. There is, it seems to me, a subconscious craving to be taken out of the boredom of timelessness and be thrown back into the flux of time, even if that means violence or war‚Äîanything but the broth! When even travel to exotic places (or to a sanatorium in Switzerland) fails to rejuvenate the perception of time and becomes just one more lifeless landscape on Instagram, desperation takes hold of the mind. Or perhaps it‚Äôs an irrational impulse, the old human perversity in action, which Dostoyevsky describes so terrifyingly well in his <em>Notes from the Underground</em>: ‚ÄúShower upon him every earthly blessing‚Ä¶ give him economic prosperity, such that he should have nothing else to do but sleep, eat cakes and busy himself with the continuation of his species, and even then out of sheer ingratitude, sheer spite, man would play you some nasty trick. He would even risk his cakes and would deliberately desire the most fatal rubbish‚Ä¶ simply to introduce into all this positive good sense his fatal fantastic element.‚Äù</h4><h4>A few months before Russia attacked Ukraine, I was at a residence in Vienna, where a Ukrainian friend told me that his country was the only one in Europe that still unreservedly believed in the European Union and the Western liberal-democratic project, that, if the EU took Ukraine on board, it would expand not only its geographic frontiers but renew its sense of purpose as well. I think the war, for all its terrible human toll, or because of it, has largely proven him right. Ukraine has turned into a rallying call for much of Europe, a vicarious way (dangerous, but not too dangerous) to experience once again the forward vector of time. How long that momentum is going to last, however, is impossible to know‚Äîjust as it‚Äôs impossible to know what the future holds for Bulgaria, or for myself for that matter. Perhaps it‚Äôs artificial intelligence that would help us glimpse that new frontier, though I‚Äôm afraid it will only deepen our current problems: vision requires more than a large language model, more than the expert recombination of the knowledge we already have. For vision is something that I believe only humans possess: a dream of that sea there, beyond the horizon. A belief.</h4>
</p>




















  
  



</div></div>
  
</article>

</div>

  
</article>


          

          
            
              

            
          
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Linux graphics stack in a nutshell (244 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/955376/b3fba3bbfabbc411/</link>
            <guid>38702271</guid>
            <pubDate>Tue, 19 Dec 2023 21:59:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/955376/b3fba3bbfabbc411/">https://lwn.net/SubscriberLink/955376/b3fba3bbfabbc411/</a>, See on <a href="https://news.ycombinator.com/item?id=38702271">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<!-- $Id: slink-none,v 1.2 2005-11-04 22:11:18 corbet Exp $ -->
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>

<p>
Linux graphics developers often speak of <em>modern</em> Linux graphics
when they refer to  a number of individual software components and how they
interact 
with each other.
Among other things, it's a mix of kernel-managed display resources, 
Wayland for compositing, accelerated 3D rendering, and decidedly not X11.
In a two-part series, we will take a fast-paced journey
through the graphics code to see how it converts application data
to pixel data and displays it on the screen. In this installment, we look
at application rendering, Mesa internals, and the
necessary kernel features.
</p>

<h4>
Application rendering
</h4>

<p>
Graphics output starts in the application, which processes and
stores formatted data that is to be visualized.
The common data structure for visualization is the
<a href="https://en.wikipedia.org/wiki/Scene_graph">scene graph</a>, which
is 
a tree where each node stores either a model in 3D space or its
attributes. Model nodes contain the data to be visualized, such as a
game's scenery or elements of a scientific simulation. Attribute
nodes set the orientation or location of the models. Each attribute
node applies to the nodes below. To render its scene graph into an
on-screen image, an application walks the tree from top to
bottom and left to right, sets or clears the attributes and renders
the 3D models accordingly.
</p>

<p>
In the example scene graph shown below, rendering starts at the root node,
which prepares the renderer and sets the output location. The application
first takes the branch to the left and renders "Rectangle&nbsp;1" at
position (0,&nbsp;0) with the surface pattern stored in texture&nbsp;1.
The application then moves back to the root node 
and takes the branch to the right where it enters the attribute node named
"Transform". Applications describe transformations, 
such as positioning or scaling, in&nbsp;4x4 matrices that the algorithm
applies during 
the rendering process. In the example, the transform node
scales all of its child nodes by a factor of&nbsp;0.5. So rendering
"Rectangle&nbsp;2" 
and "Rectangle&nbsp;3" displays them at half their original sizes, with their
positions adjusted to (10,&nbsp;10) and (15,&nbsp;15), respectively. Both
rectangles
use different textures:&nbsp;2 and&nbsp;3, respectively.
</p>

<blockquote>
<img src="https://static.lwn.net/images/2023/scenegraph.png" alt="[Scene graph]" title="Scene graph">
</blockquote>


<p>
To simplify rendering and make use of hardware acceleration, most
applications utilize one of the standard APIs, such as
<a href="https://opengl.org/">OpenGL</a>
or
<a href="https://vulkan.org/">Vulkan</a>.
Details vary among the individual APIs, but each provides interfaces
to manage graphics memory, fill it with data, and render the
stored information. The result is an image that the application can
either display as-is or use as input data to further processing.
</p>

<p>
All graphics data is held in buffer objects, each of which is a
range of graphics memory with a handle or ID attached. For example,
each 3D model is stored in a
<a href="https://en.wikipedia.org/wiki/Vertex_buffer_object">vertex-buffer object</a>,
each texture is stored in a <a href="https://www.khronos.org/opengl/wiki/Texture">texture-buffer object</a>, each object's <a href="https://en.wikipedia.org/wiki/Normal_(geometry)">surface
normals</a> are stored in a buffer object, and so on. The output image
is itself <a href="https://www.khronos.org/opengl/wiki/Framebuffer_Object">stored in a buffer object</a>. So graphics rendering is, in large
part, an exercise in memory management.
</p>

<p>
The application can provide input data in any format, as long as
the graphics shader can process it. A
<a href="https://en.wikipedia.org/wiki/Shader">shader</a>
is a program that contains the instructions to transform the input
data into an output image. It is provided by the application and executed by the
graphics card.
</p>

<p>
Real-world shader programs can implement
complex, multi-pass algorithms, but for this example we break it
down to the minimum required. Probably the two most common operations
in shaders are vertex transformations and texture lookups. We can think
of a vertex as a corner of a polygon. Written in
<a href="https://www.khronos.org/opengl/wiki/OpenGL_Shading_Language">OpenGL
Shading Language</a> (GLSL),
transforming a vertex looks like this:
</p>

<pre>    uniform mat4 Matrix; // same for all of a rectangles's vertices
    in vec4 inVertexCoord; // contains a different vertex coordinate on each invocation

    gl_Position = Matrix * inVertexCoord;
</pre>


<p>
The variable <tt>inVertexCoord</tt> is an input coordinate coming from the
application's scene graph. The variable <tt>gl_Position</tt>
is the coordinate within the application's output buffer. In broad terms,
the former coordinate is within the displayed scenery, while the latter is
within the application window.
<tt>Matrix</tt> is the&nbsp;4x4 matrix that describes the transformation between
the two coordinate systems. This shader operation runs for each vertex in
the scene graph. In the example of the application's scene graph of
rectangles above, <tt>inVertexCoord</tt> contains each vertex of each rectangle
at least once. The matrix <tt>Matrix</tt> then contains that vertex's
transformation, such as moving it to the correct position or scaling it by
the factor of&nbsp;0.5 as specified in the transform node.
</p>

<p>
Once the vertices are transformed to the output coordinate system, the
shader program computes the values of the covered "fragments",
which is graphics jargon for an output pixel with a depth value along the Z
axis and
maybe other information. Each fragment requires a color. In GLSL, the
shader's <tt>texture()</tt> function retrieves the color from a texture
like this:
</p>

<pre>    uniform sampler2D Tex; // the texture object of the current rectangle
    in vec2 vsTexCoord; // interpolated texture coordinate for the fragment

    Color = texture(Tex, vsTexCoord);
</pre>


<p>
Here, <tt>Tex</tt> represents a texture buffer. The value <tt>vsTexCoord</tt>
is the texture coordinate; the position where to read within the texture.
Using both values, <tt>texture()</tt> returns a
color value. Assigning it to <tt>Color</tt> writes a colored pixel to the
output buffer. To fill the output buffer with pixel data, this shader code runs
for each individual fragment. The texture buffer is designated by the model
that is being drawn, the texture coordinate is provided by OpenGL's
internal computation. For the example scene graph, the application invokes
this code for each of the rectangles using that rectangle's texture buffer.
</p>

<p>
Running these shader instructions on the whole scene graph generates the
complete output image for the application.
</p>

<h4>
Mesa
</h4>

<p>
Nothing we have discussed so far is specific to Linux, but it gives us the
framework to look at how it's all implemented. On Linux, the
<a href="https://mesa3d.org/">Mesa&nbsp;3D</a>
library, Mesa for short, implements 3D rendering interfaces and support
for various graphics hardware. To applications, it provides OpenGL or
Vulkan for desktop graphics,
<a href="https://www.khronos.org/opengles/">OpenGL ES</a>
for mobile systems, and
<a href="https://www.khronos.org/opencl/">OpenCL</a>
for computation. On the hardware side, Mesa implements drivers for most
of today's graphics hardware.
</p>

<p>
Mesa drivers generally do not implement these application interfaces by
themselves as Mesa contains plenty of helpers and abstractions.
For stateful interfaces, such as OpenGL, Mesa's
<a href="https://www.freedesktop.org/wiki/Software/gallium/">Gallium3D</a>
framework connects interfaces and drivers
with each other. This is called a state tracker. Mesa contains
state trackers for various versions of OpenGL, OpenGL ES, and OpenCL. When the
application uses 
the API, it modifies the state tracker for the given interface.
</p>

<p>
A hardware driver within Mesa further converts the state-tracker information
to hardware state and rendering instructions.
For example, calling OpenGL's
<a href="https://registry.khronos.org/OpenGL-Refpages/gl4/html/glBindTexture.xhtml"><tt>glBindTexture()</tt></a>
selects the current texture buffer within the OpenGL
state tracker. The hardware driver then installs the texture-buffer
object in graphics memory and links the active shader program to
refer to the buffer object as its texture. In our example above, the
texture becomes available as <tt>Tex</tt> in the
shader program.
</p>

<p>
Vulkan is a stateless interface, so Gallium3D is not useful
for those drivers; Mesa instead offers the <a href="https://docs.mesa3d.org/vulkan/index.html">Vulkan runtime</a> to help
with their 
implementation. If there is a Vulkan driver available, though, there
might not be a need for Gallium3D-based OpenGL support at all for
that hardware.
<a href="https://docs.mesa3d.org/drivers/zink.html">Zink</a>
is a Mesa driver that maps Gallium3D to Vulkan. With Zink, OpenGL state
turns into Gallium3D state, which is then forwarded to hardware via standard
Vulkan interfaces. In principle, this works with any hardware's Vulkan
driver. One can imagine that future drivers within Mesa only implement
Vulkan and rely on Zink for OpenGL compatibility.
</p>

<p>
Besides Gallium3D, Mesa provides more helpers, such as winsys or GBM, to
its hardware 
drivers. Winsys wraps the details of the
window system. GBM, the Generic Buffer Manager, simplifies buffer-object
allocation.
There are also a number of shader languages, such as
GLSL
or
<a href="https://www.khronos.org/spir/">SPIR-V</a>,
available to the application.  Mesa compiles the
application-provided shader code to the "New Interface Representation" or
NIR, which Mesa drivers turn into 
hardware instructions. To get the shader instructions and the associated
data processed by Mesa's hardware acceleration, their buffer objects have
to be stored in memory locations accessible to the graphics card.
</p>

<h4>
Kernel memory management
</h4>

<p>
Any memory accessible to the graphics hardware is commonly subsumed under
the umbrella term of graphics memory; it is the graphics
stack's central resource, as all of the stack's components interact with
it. On the hardware side, graphics memory comes in a variety of
configurations that range from dedicated memory on discrete graphics
adapters to regular system memory of system-on-chip (SoC) boards. In between are
graphics chips with DMA-able or 
<a href="https://en.wikipedia.org/wiki/Shared_graphics_memory">shared graphics memory</a>,
<a href="https://en.wikipedia.org/wiki/Graphics_address_remapping_table">graphics
address remapping table</a> (GART) memory
of discrete devices, or the so-called stolen graphics memory
of on-board graphics.
</p>

<p>
Being a system-wide resource, graphics memory is maintained by the kernel's
<a href="https://en.wikipedia.org/wiki/Direct_Rendering_Manager">Direct
Rendering Manager</a> (DRM)
subsystem. To access DRM functionality, Mesa opens
the graphics card's device file under <tt>/dev/dri</tt>, such as
<tt>/dev/dri/renderD128</tt>. As required by its
user-space counterparts, DRM exposes graphics memory in the form
of buffer objects, where each buffer object represents a slice of the
available memory.
</p>

<p>
The DRM framework provides a number of memory managers for the most
common cases. The DRM drivers for the discrete graphics cards
from AMD, NVIDIA, and (soon) Intel use the <a href="https://docs.kernel.org/gpu/drm-mm.html">Translation Table Manager</a>
(TTM). It supports discrete graphics memory, GART memory, and system memory.
TTM can move buffer objects between these areas, so if the device's
discrete memory fills up, unused buffer objects can be swapped out to
system memory.
</p>

<p>
Drivers for simple framebuffer devices often use the
SHMEM helpers, which allocate buffer objects in shared memory. Here,
regular system memory acts as a shadow buffer for the device's
limited resources. The graphics driver maintains the device's
graphics memory internally, but exposes buffer objects in system memory
to the outside. This also makes it
possible to memory-map buffer objects of devices on the USB or I2C bus,
even though these buses do not support page mappings of
device memory;  the shadow buffer can be mapped instead.
</p>

<p>
The other common
allocator, the DMA helper, manages buffer
objects in DMA-able areas of the physical memory. This design is often used
in SoC boards, where graphics chips fetch and store data via DMA operations.
Of course, DRM drivers with additional requirements have the option of extending
one of the existing memory managers or implementing their own.
</p>

<p>
The <tt>ioctl()</tt> interface for managing buffer objects is called the <a href="https://docs.kernel.org/gpu/drm-mm.html#the-graphics-execution-manager-gem">Graphics 
Execution Manager</a> (GEM). Each DRM driver implements GEM according to its
hardware's 
features and requirements.
The GEM interface allows mapping a buffer object's memory pages to user-space
or kernel address space, allows pinning the pages at a certain location, or
exporting them to other drivers. For example, an application in user space
can get access to a buffer object's memory pages by invoking <tt>mmap()</tt>
with the
correct offset on the DRM device file's file descriptor. The call will eventually
end up in the DRM driver's GEM code, which sets up the mapping. As we will see
below, it's a useful feature for software rendering.
</p>

<p>
The one common operation that GEM does not provide is buffer allocation.
Each buffer object has a specific use case, which affects and is affected by
the object's allocation parameters, memory location, or hardware constraints.
Hence, each DRM driver offers a dedicated <tt>ioctl()</tt> operation for buffer-object
allocation that captures these hardware-specific settings. The DRM driver's
counterpart in Mesa invokes said <tt>ioctl()</tt> operation accordingly.
</p>

<h4>
Rendering operations
</h4>

<p>
Just having buffer objects for storing the output image, the input data, and
the shader programs is not enough. To start rendering, Mesa instructs DRM to
put all necessary buffer objects in graphics memory and invokes the
active shader program. It's again all specific to the hardware and provided
as <tt>ioctl()</tt> operations by each DRM driver individually. As with buffer allocation,
the hardware driver within Mesa invokes the DRM driver's <tt>ioctl()</tt> operations.
For Mesa drivers based on Gallium3D, this happens when the driver converts the
state tracker information into hardware state.
</p>

<p>
The graphics driver ideally acts only as a proxy between the application
in user space and the hardware. The hardware renderer runs asynchronously to
the rest of the graphics stack and reports back to the driver only in
case of an error or on successful completion; much like the system CPU
informs the operating system on page faults or illegal instructions. As long
as there's nothing to report, driver overhead is minimal. There are
exceptions; for example, older models of Intel graphics chips do not
support 
vertex transformations, so the driver within Mesa has to implement them in
software. On the Raspberry Pi, the kernel's DRM driver has to validate each
shader's memory access, as the VideoCore&nbsp;4 chip does not contain
an I/O MMU to isolate the shader from the system.
</p>

<h4>
Software rendering
</h4>

<p>
So far, we have assumed hardware support for graphics rendering. What if
there's no such support or the user-space application cannot use it? For
example, a user-space GUI toolkit might prefer rendering in
software because hardware-centric interfaces like OpenGL do not fit its needs.
And there's Plymouth, the program that displays the boot-up logo and prompts
for disk-encryption passwords during boot, which usually does not have a full
graphics stack available. For these scenarios, DRM offers the dumb-buffer
<tt>ioctl()</tt> interface.
</p>

<p>
By utilizing dumb buffers, an application allocates
buffer objects in graphics memory, but without support for hardware
acceleration. So any returned buffer object is only usable with software
rendering. The application in user space, such as a GUI
toolkit or Plymouth, maps the buffer object's pages into its address space
and copies over the output image. Mesa's software renderer works similarly:
the input buffer objects all live in system memory and the system CPU
processes the shader instructions. The output buffer is a dumb-buffer
object that stores the rendered image. While that's neither fast nor fancy,
it's good enough to run a modern desktop environment on simple hardware that
does not support accelerated rendering.
</p>

<p>
We have now gone through the application's graphics stack for rendering. After
having completed the traversal of the scene graph, the application's output
buffer object contains the visualized scenery or data that it wants to
display. But the buffer is not 
yet on the screen. Whether accelerated or dumb, putting the buffer on the
screen requires compositing and mode setting, which form the other half of
the graphics stack. In part&nbsp;2, we will look at Wayland
compositing, setting display modes with DRM, and a few other features of the
graphics stack.
</p><br clear="all"><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Device_drivers-Graphics">Device drivers/Graphics</a></td></tr>
            <tr><td><a href="https://lwn.net/Archives/GuestIndex/">GuestArticles</a></td><td><a href="https://lwn.net/Archives/GuestIndex/#Zimmermann_Thomas">Zimmermann, Thomas</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/955376/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VideoPoet A large language model for zero-shot video generation (120 pts)]]></title>
            <link>https://sites.research.google/videopoet/</link>
            <guid>38702141</guid>
            <pubDate>Tue, 19 Dec 2023 21:47:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sites.research.google/videopoet/">https://sites.research.google/videopoet/</a>, See on <a href="https://news.ycombinator.com/item?id=38702141">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<h3 size="3">
<p>Quick Links</p>
</h3>
<p>To view additional results, please also visit our other pages:</p>
<p><a target="_blank" href="http://sites.research.google/videopoet/text-to-video">Text-to-Video</a> - <a target="_blank" href="http://sites.research.google/videopoet/image-to-video">Image-to-Video</a> - <a target="_blank" href="http://sites.research.google/videopoet/video-editing">Video Editing</a> - <a target="_blank" href="http://sites.research.google/videopoet/stylization">Stylization</a> - <a target="_blank" href="http://sites.research.google/videopoet/inpainting">Inpainting</a></p>

<h3 size="3">
<p>Authors</p>
</h3>
<p>Dan Kondratyuk*, Lijun Yu*, Xiuye Gu*, Jos√© Lezama*, Jonathan Huang, Rachel Hornung, Hartwig Adam, Hassan Akbari, Yair Alon, Vighnesh Birodkar, Yong Cheng, Ming-Chang Chiu,&nbsp;Josh Dillon, Irfan Essa, Agrim Gupta, Meera Hahn, Anja Hauth, David Hendon, Alonso Martinez, David Minnen, David Ross, Grant Schindler, Mikhail Sirotenko, Kihyuk Sohn, Krishna Somandepalli, Huisheng Wang, Jimmy Yan, Ming-Hsuan Yang, Xuan Yang, Bryan Seybold*, Lu Jiang*</p>
<hr>
<p>*Equal technical contribution</p>
<h3 size="3">
<p>Acknowledgements</p>
</h3>
<p><i>We give special thanks to Alex Siegman and Victor Gomes for managing computing resources. We also give thanks to Aren Jansen, Marco Tagliasacchi, Neil Zeghidour, John Hershey for audio tokenization and processing, Angad Singh for storyboarding in ‚ÄúRookie the Raccoon‚Äù, Cordelia Schmid for research discussions, Alonso Martinez for graphic design, David Salesin, Tomas Izo, and Rahul Sukthankar for their support, and Jay Yagnik as architect of the initial concept.</i></p>
<hr>
<p><i>**Referenced works:</i></p>
<ul>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Bierstadt_Albert_Old_Faithful.jpg">Old Faithful</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Pillars_of_creation_2014_HST_WFC3-UVIS_full-res.jpg">Pillars of Creation</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://www.artic.edu/artworks/120885/milk-drop-coronet">Milk Drop Coronet</a>, <a target="_blank" href="https://creativecommons.org/publicdomain/zero/1.0/">CC0 1.0</a>.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Rembrandt_Christ_in_the_Storm_on_the_Lake_of_Galilee.jpg">The Storm on the Sea of Galilee</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:George_III_Statue.jpg">George III Statue</a>, <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">CC BY-SA 4.0</a>.</p>
</li>
<li>
<p><a target="_blank" href="https://en.wikipedia.org/wiki/File:Raising_the_Flag_on_Iwo_Jima,_larger_-_edit1.jpg">Raising the Flag on Iwo Jima</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Caspar_David_Friedrich_-_Wanderer_above_the_Sea_of_Fog.jpeg">Wanderer above the Sea of Fog</a>, public domain.</p>
</li>
<li>
<p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:Mona_Lisa,_by_Leonardo_da_Vinci,_from_C2RMF_retouched.jpg">Mona Lisa</a>, public domain.</p>
</li>
</ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vulkan video extensions for accelerated H.264 and H.265 encode (224 pts)]]></title>
            <link>https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-encode</link>
            <guid>38701780</guid>
            <pubDate>Tue, 19 Dec 2023 21:21:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-encode">https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-encode</a>, See on <a href="https://news.ycombinator.com/item?id=38701780">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><time itemprop="dateCreated" datetime="2023-12-19T06:00:00-08:00"><i></i> December 19, 2023</time>
        by <span itemprop="author">Lynne Iribarren, Khronos Member of the Vulkan Video TSG and Ahmed Abdelkhalek, AMD, Vulkan Video TSG Chair</span>
        <span itemtype="keywords"><i></i>
        
            <a href="https://www.khronos.org/news/tags/tag/vulkan" title="vulkan">vulkan</a>, 
            <a href="https://www.khronos.org/news/tags/tag/video" title="video">video</a>
        </span>
    </p><div itemprop="description">
    <p>In April 2021, the Vulkan¬Æ Working Group at Khronos¬Æ <a href="https://www.khronos.org/blog/an-introduction-to-vulkan-video">released a set of provisional extensions</a>, collectively referred to as ‚ÄòVulkan Video‚Äô which provide seamless encoding and decoding of video streams using a variety of video coding standards. The December 2022 release of Vulkan 1.3.238 saw the <a href="https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-decode">finalization of the extensions to decode H.264 and H.265</a>, and today, with the release of Vulkan <strong>1.3.274</strong>, Khronos has finalized their counterpart: the extensions to enable <strong>encoding</strong> of H.264 and H.265 video streams. Leveraging the Vulkan framework, they provide a standardized, seamless, low-overhead, and highly controllable way to produce H.264 and H.265 video via hardware accelerators, with applications ranging from real-time, low-latency streaming to offline server-scale transcoding.</p>
<p>Incorporating industry feedback, the extensions saw many improvements since their introduction, from a bidirectional interface (overrides) to help with coding and exposing advanced hardware capabilities, to rate control configuration parameters and an interface to aid with quality vs. performance trade-offs. This feedback also prompted the release of the first video maintenance extension. In addition, given the high industry demand for AV1 codec support, an AV1 decode extension release is imminent, with an AV1 encode extension development also underway. Figure 1 depicts Vulkan Video extensions along with their status and relations.</p>


<figure><img src="https://www.khronos.org/assets/uploads/blogs/2023-blog-vulkan-video-1.jpg">Figure 1. Vulkan Video extensions</figure>


<p>The encode extensions grant low-level control over much of the encoding process, while still keeping the efficiency and performance of hardware encoding acceleration. Implementers have the freedom to tweak details such as quantization index, per-slice bit allocation, arithmetic coder, deblocking, and more. Given this flexibility and complexity, a balanced programming interface for rate control gives users a choice between more automated operation and low-level tweaking of frame parameters.</p>
<h2>So, What Changed?</h2>
<p>This section briefly summarizes the changes included in this release relative to <a href="https://www.khronos.org/blog/khronos-finalizes-vulkan-video-extensions-for-accelerated-h.264-and-h.265-decode">prior descriptions</a> of the Vulkan Video extensions.</p>
<h3>Changes to Video Encode</h3>
<h4>Encoder Rate Control</h4>
<p>Often the most important aspect of encoder configuration for applications, the encoder rate control API was given special attention in Vulkan Video. From exposing parameters for standard rate control modes (e.g. CBR/VBR), to allowing applications to provide hints about other intended stream encoding parameters (e.g. picture/reference patterns), to providing the ability to configure per-layer rate control parameters (e.g. for streams with multiple temporal layers), the rate control API offers a rich set of features for various use cases and lays a solid foundation for future extensions. Encoder rate control configuration is performed using the <strong><em>vkCmdControlVideoCodingKHR</em></strong> command.</p>
<h4>Encoder Quality Levels</h4>
<p>Video encoder implementations often fine tune the use of various encoding tools and rate control parameters depending on the desired quality versus performance/latency trade-offs of different use cases. Now implementations report the number of quality levels supported for a given video profile and usage. A new API <strong><em>vkGetPhysicalDeviceVideoEncodeQualityLevelPropertiesKHR </em></strong>may be used to retrieve implementation recommendations for various encoding parameters and configurations (e.g. rate control).</p>
<h4>Implementation Overrides</h4>
<p>Due to the complex nature of video encoding, and the ever-changing nature of hardware encoders and their capabilities, an interface, known as <strong>overrides</strong>, permits bidirectional communication that <strong>guarantees</strong> that the output video stream will be compliant. In addition, applications may opt-in for optimization overrides to allow implementations more flexibility to optimize for the specified usage and hints. Full disclosure about the occurrence of overrides for video session parameters or frame parameters is also reported for developers interested in more detailed analysis of such overrides.</p>
<h4>Retrieval of encoded video session parameters bitstream segments</h4>
<p>To facilitate implementation overrides for bitstream compliance and optimizations, applications are expected to retrieve the encoded video session parameter bitstream segments (e.g. H.264 SPS/PPS) from the implementation using the new API call <strong><em>vkGetEncodedVideoSessionParametersKHR</em></strong> against the given <strong><em>VkVideoSessionParametersKHR</em></strong> object.</p>
<h4>Encoder Feedback Query</h4>
<p>To allow future extension of encoder feedback statistics in a manner similar to pipeline statistics, the new <strong><em>VK_QUERY_TYPE_VIDEO_ENCODE_FEEDBACK_KHR</em></strong> is now used to retrieve the video bitstream offset and size.</p>
<p>Figure 2 depicts the Vulkan Video encoding process, which remains largely unchanged compared to previous descriptions.</p>


<figure><img src="https://www.khronos.org/assets/uploads/blogs/2023-blog-vulkan-video-2.jpg">Figure 2. Vulkan Video Encode Process</figure>


<h3>Changes to Video Decode &amp; Encode</h3>
<h4>VK_KHR_video_maintenance1</h4>
<p>Along with the video encoding extensions, Khronos is releasing a maintenance extension incorporating community and industry feedback, which improves flexibility for both decoding and encoding. This extension permits decoding implementations to create images usable with video decoding without the need to explicitly specify the video profiles they will be used with. The same applies for encoding, where an attached per-image video profile limits usability with large and complex transcoding frameworks.</p>
<p>In addition to flexibility improvements, a new, simpler interface for specifying video queries <strong>inline with video decode and encode operation commands</strong> has been added, known as inline queries.</p>
<h4>Requiring pSetupReferenceSlotKHR for non-reference pictures</h4>
<p>When the Vulkan Video decode extensions were finalized applications were required to provide a reconstructed picture resource and DPB slot (via <strong><em>VkVideoDecodeInfoKHR::pSetupReferenceSlot</em></strong>) only if the picture being decoded will become a reference. However, no shipping implementation actually supported specifying <strong><em>NULL</em></strong>for <strong><em>pSetupReferenceSlot</em></strong>, and further some implementations discovered cases that require the use of the reconstructed picture resource and/or DPB slot for transient storage during decoding a non-reference picture. A similar situation applies to encoding non-reference pictures. As a result, the vulkan video extensions were updated to require providing <strong><em>pSetupReferenceSlotKHR</em></strong> for non-reference pictures.</p>
<h2>I Want All The Details!</h2>
<p>The following <strong>proposal documents</strong> provide a much more detailed and thorough review of all finalized Vulkan Video extensions, including the rationale behind the chosen design approach, various issues encountered during the development of Vulkan Video and how they were resolved, as well as code samples to aid in application development:</p>
<ul>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_queue.adoc"><strong><em>VK_KHR_video_queue</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_decode_queue.adoc"><strong><em>VK_KHR_video_decode_queue</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_decode_h264.adoc"><strong><em>VK_KHR_video_decode_h264</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_decode_h265.adoc"><strong><em>VK_KHR_video_decode_h265</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_encode_queue.adoc"><strong><em>VK_KHR_video_encode_queue</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_encode_h264.adoc"><strong><em>VK_KHR_video_encode_h264</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_encode_h265.adoc"><strong><em>VK_KHR_video_encode_h265</em></strong></a></li>
<li><a href="https://github.com/KhronosGroup/Vulkan-Docs/blob/main/proposals/VK_KHR_video_maintenance1.adoc"><strong><em>VK_KHR_video_maintenance1</em></strong></a></li>
</ul>
<p>Developers interested in using Vulkan Video are strongly encouraged to read the above proposal documents - they really give you a good head start!</p>
<p>All details about the Vulkan Video API are available in the final extensions <strong>specification</strong> links:</p>
<ul>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_queue.html"><strong><em>VK_KHR_video_queue</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_decode_queue.html"><strong><em>VK_KHR_video_decode_queue</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_decode_h264.html"><strong><em>VK_KHR_video_decode_h264</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_decode_h265.html"><strong><em>VK_KHR_video_decode_h265</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_encode_queue.html"><strong><em>VK_KHR_video_encode_queue</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_encode_h264.html"><strong><em>VK_KHR_video_encode_h264</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_encode_h265.html"><strong><em>VK_KHR_video_encode_h265</em></strong></a></li>
<li><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_video_maintenance1.html"><strong><em>VK_KHR_video_maintenance1</em></strong></a></li>
</ul>
<h2>Call for Action, Feedback &amp; Support!</h2>
<p>The finalization and release of these Vulkan Video extensions marks a significant milestone in the Vulkan ecosystem roadmap, adding fully accelerated H.264 and H.265 encode to this widely available cross-platform GPU API. We encourage developers to utilize these extensions to bring new levels of performance and functionality to their video applications on Windows and Linux.</p>
<p>We welcome you to join <a href="https://vulkan.org/events/vulkanised-2024">Vulkanised 2024</a> (February 5-7 in MountainView CA.), which will include a presentation &amp; live demo about Vulkan Video and much more!</p>
<p>NVIDIA, Intel &amp; AMD are the first IHVs implementing support for these extensions:</p>
<ul>
<li>NVIDIA: Windows and Linux <a href="https://developer.nvidia.com/vulkan-driver">BETA drivers</a> available now</li>
<li>Intel: Coming soon</li>
<li>AMD: Coming soon</li>
</ul>
<p>Additionally, the open-source drivers <a href="https://airlied.blogspot.com/2023/12/radv-vulkan-video-encode-status.html">RADV</a> and <a href="https://gitlab.freedesktop.org/zzoon/mesa/-/tree/h264enc_anv_4?ref_type=heads">ANV</a> are adding support for the finalized Vulkan Video encode extensions, in addition to already supporting the Vulkan Video decode extensions.</p>
<p>Strong ecosystem adoption continues for Vulkan Video, and there are several implementers of the spec:</p>
<ul>
<li>The <a href="https://github.com/nvpro-samples/vk_video_samples">reference app</a> part of the Vulkan Video samples repository with encoding support is coming soon in 1Q24.</li>
<li>FFmpeg, in a <a href="http://lynne.ee/vulkan-video-encoding.html">branch</a> currently under development, soon to be merged into the <a href="https://git.videolan.org/?p=ffmpeg.git;a=log;h=HEAD">main repository</a>.</li>
<li>Gstreamer, in a <a href="https://gitlab.freedesktop.org/gstreamer/gstreamer/-/merge_requests/5739">branch</a> currently under development and a description of the journey can be found <a href="https://blogs.igalia.com/scerveau/vulkan-video-encoder-in-gstreamer/">here</a>.</li>
</ul>
<p>Those interested in testing the code should follow their guidelines and are welcome to submit feedback.</p>
<p>An upcoming release of Vulkan SDK will include updated Vulkan headers and Validation Layer support for the newly released video extensions. In the meantime, you can find the Vulkan headers <a href="https://github.com/KhronosGroup/Vulkan-Headers">here</a>.</p>
<p>We look forward to your use and feedback on Vulkan Video! Please share your experience and thoughts through the <a href="https://github.com/KhronosGroup/Vulkan-Docs/issues/2284">Vulkan Video Encode Release GitHub Issue</a>. This issue will also be updated to provide links to Vulkan Video-related resources as they become available.</p>
<p>We also encourage your participation in extending Vulkan Video to support more codecs and features. See <a href="https://www.khronos.org/members/">khronos.org/members</a> for information about how to join Khronos and participate in the definition of any of our standards.</p>
<p>Thank you for your interest and support of Vulkan Video. We hope you find it effective for your use cases and applications, and we look forward to supporting your needs with more codecs and features!</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CUDA vs. ROCm: A case study (148 pts)]]></title>
            <link>https://shihab-shahriar.github.io//blog/2023/Cuda-vs-Rocm-A-Case-Study-Through-Random-Number-Libraries/</link>
            <guid>38700060</guid>
            <pubDate>Tue, 19 Dec 2023 19:09:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shihab-shahriar.github.io//blog/2023/Cuda-vs-Rocm-A-Case-Study-Through-Random-Number-Libraries/">https://shihab-shahriar.github.io//blog/2023/Cuda-vs-Rocm-A-Case-Study-Through-Random-Number-Libraries/</a>, See on <a href="https://news.ycombinator.com/item?id=38700060">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <div id="markdown-content"> <p>How far along is AMD‚Äôs ROCm in catching up to Cuda? AMD has been on this race for a while now, with ROCm debuting 7 years ago. Answering this question is a bit tricky though. CUDA isn‚Äôt a single piece of software‚Äîit‚Äôs an entire ecosystem spanning compilers, libraries, tools, documentation, Stack Overflow/forum answers, etc. Today, I‚Äôm going to zoom in on a particular slice of these vast ecosystems, the random number generation libraries: cuRAND and rocRAND, part of the suite of around ten libraries that come standard on both systems. Hopefully, this sheds some light on the current state-of-affairs of the broader landscape.</p> <p>Most of these observations grew out of my work on a research project a few months ago. As I worked, I realized I was forming some pretty strong takes that I can‚Äôt really put in an academic paper. So here I am.</p> <p>One of the key advantages of rocRAND is it is open-source. So let‚Äôs start at their <a href="https://github.com/ROCm/rocRAND" rel="external nofollow noopener" target="_blank">GitHub repo</a> first.</p> <h2 id="design">Design</h2> <p>Going through the README, one of the first things you notice is AMD actually offers two random number libraries: rocRAND and hipRAND, the latter being a thin client that chooses cuRAND or rocRAND depending on the platform. So, for today‚Äôs discussion, we‚Äôll set aside hipRAND.</p> <p>Next comes a list of random number generators implemented in the library. You won‚Äôt find a discussion about them here (or anywhere else for that matter), Just a list of names. Moving on, in the Requirements section, ROCm is listed as a dependency for AMD platforms, as expected. However, clicking on the ROCm link leads to the first 404 error on this page. To run this library on CPU, you need something referred to as ‚ÄúHIP-CPU‚Äù. This link thankfully works, and the tagline of its Github repo reads- ‚ÄúAn implementation of HIP that works on CPUs, across OSes.‚Äù</p> <p>Let‚Äôs pause for a moment. We‚Äôre not even halfway through the README and we have already seen 3 different platforms from AMD- ROCm, HIP, HIP-CPU. I really wonder about the necessity or the wisdom behind this fragmentation- splitting HIP in particular. A single standard or library like SYCL or Kokkos seems to support multiple hardware platforms just fine under one codebase. To me this felt like a half-hearted attempt to tick one more box in a head-to-head battle with (intel-supported) SYCL. And I say half-hearted because HIP-CPU has been under development for more than 3 years, last commit pushed 3 months ago, and this is the first paragraph of its README: ‚ÄúPlease note the library is being actively developed, and is known to be incomplet; it might also be incorrekt and there could be a few bad bugs lurking.‚Äù Let‚Äôs return to our focus on rocRAND.</p> <p>One of the key challenges in developing a parallel, reproducible random number library is ensuring statistical robustness. This might not matter for most users, but for applications like Brownian simulations, a weak generator can silently wreak havoc. Rigorous testing with standard, widely accepted statistical frameworks is crucial - something cuRAND of course does. However, I couldn‚Äôt find any discussion on this for rocRAND, aside from two self-written simple tests. There‚Äôs mention of a statistical test suite in the README, but again, that link leads to a 404 error.</p> <p>It‚Äôs not looking great, but at this point, I found a feature that cuRAND doesn‚Äôt have, a Python API! It‚Äôs an interesting choice: to attach such a high-level language interface for such a low-level library. So let‚Äôs go to the documentation and see what‚Äôs it for, shall we?</p> <h2 id="documentation">Documentation</h2> <figure> <picture> <source media="(max-width: 480px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/py-480.webp"> <source media="(max-width: 800px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/py-800.webp"> <source media="(max-width: 1400px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/py-1400.webp"> <img src="https://shihab-shahriar.github.io/assets/img/rocm/py.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption>Figure 1: rocRAND's Python API.</figcaption> </figure> <p>That‚Äôs it! That‚Äôs the entirety of the Python API documentation ‚Äì and no, those headers aren‚Äôt clickable. <a href="https://rocm.docs.amd.com/projects/rocRAND/en/latest/python_api.html" rel="external nofollow noopener" target="_blank">This is it</a>!</p> <p>So, that was a bonus feature. What about the C++ API documentation? well, it exists, but it‚Äôs hardly any different. The API reference is almost entirely just a dump of function docstrings, with same comment copy/pasted for all the functions. And this mindless copy/pasting has predictable result- you‚Äôll find, for example, the ‚Äúdocumentation‚Äù mention 64 bit int return type for a function while it actually returns 32-bit.</p> <p>The Programming Guide again starts (and ends) with the list of generators, with only one piece of extra information here, whether a generator is for pseudo-random or quasi-random number generation. The next (and final) section is titled ‚ÄúOrdering‚Äù, and the very first sentence starts talking about ‚Äúhow results are ordered in global memory.‚Äù If you just thought- wait, what results? that‚Äôs a very valid response. You <em>might</em> eventually figure out they are talking about the host-side API that generates a buffer of random numbers on device. Being GPU, it uses multiple threads behind the scene, and ordering here refers to how to order the numbers coming out of each thread in the output buffer. They list 5 ways of doing it, after commenting how this choice impacts performance and reproducibility. Go on, <a href="https://rocm.docs.amd.com/projects/rocRAND/en/latest/programmers_guide.html#" rel="external nofollow noopener" target="_blank">read about them a little bit</a>, you‚Äôll soon discover a pretty interesting relationship between them. For the lazy among you, here‚Äôs a clue:</p> <figure> <picture> <source media="(max-width: 480px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/Spiderman-480.webp"> <source media="(max-width: 800px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/Spiderman-800.webp"> <source media="(max-width: 1400px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/Spiderman-1400.webp"> <img src="https://shihab-shahriar.github.io/assets/img/rocm/Spiderman.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption></figcaption> </figure> <p>They are all the same! Of course, they don‚Äôt say that directly, it‚Äôs another little thing for you to figure out. (well, technically I can‚Äôt say ‚Äúall‚Äù are same, becuase they don‚Äôt mention the fifth one anywhere else in the page.)</p> <p>Frankly, this isn‚Äôt just bad documentation; this is horrendous. There is no attempt anywhere to introduce or explain anything: just data dumps and lists. You get the sense, once again, that this ‚Äúdocumentation work‚Äù was another box for someone to tick, without any consideration paid to a potential user of the software.</p> <p>But the code follows the same API as cuRAND. So someone familar with cuRAND will be able to manage eventually. Let‚Äôs look at how that code fares against cuRAND next.</p> <h2 id="performance">Performance</h2> <p>I‚Äôll start with a real-world benchmark, using a classic example of GPGPU programming: Ray tracing in one weekend in cuda (<a href="https://github.com/rogerallen/raytracinginoneweekendincuda" rel="external nofollow noopener" target="_blank">Github</a>). For meaningful performance comparison of random number libraries, we need a program that uses random numbers beyond just the initialization phase. Ray tracer is a good example of that. Both libraries offer a variety of generators; for this test, I chose Philox.</p> <figure> <picture> <source media="(max-width: 480px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/comb-480.webp"> <source media="(max-width: 800px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/comb-800.webp"> <source media="(max-width: 1400px)" srcset="https://shihab-shahriar.github.io/assets/img/rocm/comb-1400.webp"> <img src="https://shihab-shahriar.github.io/assets/img/rocm/comb.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture><figcaption>Figure 2: Time taken to render the image on the right by cuRAND and rocRAND libraries (left)</figcaption> </figure> <p>4.03 seconds vs 5.5s- the raytracer with the rocRAND version is 37% slower. Remember this isn‚Äôt a micro-benchmark of just random number generation part, the timings are for whole program. With that in mind, I think this is a pretty substantial slowdown.</p> <p>The benchmark was performed on an Nvidia V100 GPU. Is that fair? I think yes, especially since rocRAND‚Äôs developers <a href="https://streamhpc.com/blog/2017-11-29/learn-amds-prng-library-developed-rocRAND/" rel="external nofollow noopener" target="_blank">claimed</a> to have performance parity with cuRAND on Nvidia GPUs. But maybe cuRAND has some hardware-specific optimizations? I really don‚Äôt think that‚Äôs the case. Philox algorithm isn‚Äôt that complicated, it doesn‚Äôt really need any advanced GPU primitives. But don‚Äôt take just my word for it: our lab made a pretty simple implementation of Philox, (you can find it <a href="https://github.com/msu-sparta/OpenRAND/blob/main/include/openrand/philox.h" rel="external nofollow noopener" target="_blank">here</a>), it is orders of magnitude smaller than rocRAND‚Äôs implementation in terms of LOC, yet it performs on par with CuRAND (4.09 seconds).</p> <p>Still, it‚Äôs just one benchmark. I‚Äôm sure there are other hardware-software combinations where this performance gap disappears. But, just to ensure that the ray tracer isn‚Äôt some outlier, I wrote a pretty basic 2D brownian dynamics simulation code. The story is even worse here for rocRAND, 6.30 seconds vs cuRAND‚Äôs 4.23- a 48% slowdown.</p> <h2 id="final-thoughts">Final Thoughts</h2> <p>After the ChatGPT phenomenon, there has recently been lots of focus on Nvidia‚Äôs ‚ÄúCUDA moat‚Äù. As we all watched the vast AI riches going almost exclusively to Nvidia thanks mostly to that moat, many assumed this will be a big wake-up call for AMD, their <a href="https://www.vanityfair.com/news/2016/06/how-mark-zuckerberg-led-facebooks-war-to-crush-google-plus" rel="external nofollow noopener" target="_blank">Carthage must be destroyed</a> moment that radically alters their well-known laid-back attitude to software. There are hints of this shift in their recent events and press releases, and I hope this trend continues.</p> <p>But in my little corner of HPC world, I‚Äôm yet to see any meaningful movement in that regard. And AMD needs to hurry up- as I wrote this article, I took a cursory glance at Intel‚Äôs <a href="https://spec.oneapi.io/versions/1.2-rev-1/elements/oneMKL/source/domains/rng/onemkl-rng-overview.html" rel="external nofollow noopener" target="_blank">documentation</a> for SYCL (a competitor of HIP) on this topic- a clean, well-organized, professional site- as you‚Äôd expect.</p> <p>Like many, I‚Äôm looking forward to a real showdown in the GPGPU space someday- I‚Äôm just not sure that will necessarily be between Nvidia and AMD.</p> </div> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[At Least 15% of Reddit Content Is Corporate Trolls Manipulating Public Opinion (146 pts)]]></title>
            <link>https://medium.com/collapsenews/new-study-at-least-15-of-all-reddit-content-is-corporate-trolls-trying-to-manipulate-public-b249bd42ab42</link>
            <guid>38700038</guid>
            <pubDate>Tue, 19 Dec 2023 19:07:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/collapsenews/new-study-at-least-15-of-all-reddit-content-is-corporate-trolls-trying-to-manipulate-public-b249bd42ab42">https://medium.com/collapsenews/new-study-at-least-15-of-all-reddit-content-is-corporate-trolls-trying-to-manipulate-public-b249bd42ab42</a>, See on <a href="https://news.ycombinator.com/item?id=38700038">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://medium.com/@chrisjeffrieshomelessromantic?source=post_page-----b249bd42ab42--------------------------------"><div aria-hidden="false"><p><img alt="Homeless Romantic" src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*P3NFVEPEgZp88pjg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a><a href="https://medium.com/collapsenews?source=post_page-----b249bd42ab42--------------------------------" rel="noopener follow"><div aria-hidden="false"><p><img alt="Collapse News" src="https://miro.medium.com/v2/resize:fill:48:48/1*U7BJY5ZImQnK_eaz_2oTMg.jpeg" width="24" height="24" loading="lazy" data-testid="publicationPhoto"></p></div></a></div><figure><figcaption>Photo by <a href="https://unsplash.com/@brett_jordan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Brett Jordan</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b680"><a href="https://www.journals.elsevier.com/computers-in-human-behavior%0A" rel="noopener ugc nofollow" target="_blank">https://www.journals.elsevier.com/computers-in-human-behavior%0A</a></p><h2 id="9f33">The Impact of Corporate Trolls on Reddit: A Growing Problem</h2><p id="36a2">The rise of social media has brought about a new battleground for the spread of misinformation, manipulation of public opinion, and promotion of products and services. Reddit, one of the most popular social media platforms, has not been immune to this phenomenon.</p><p id="b57c">Two significant studies, <strong>the Pew Research Center study conducted in 2018 and the Computers in Human Behavior study published in 2020, have shed light on the prevalence and impact of corporate trolls on Reddit.</strong></p><h2 id="c308">Pew Research Center Study: Unveiling the Reach of Corporate Trolls</h2><p id="c3b6">The Pew Research Center study, conducted in 2018, delved into the experiences of 2,505 adult Americans who use Reddit.</p><p id="03b9">The findings were alarming, revealing that a considerable portion of Reddit users had directly encountered the influence of corporate trolls.</p><p id="5911"><strong>The study found that 11% of the respondents had been contacted by a bot or troll attempting to promote a product or service</strong>. Even more concerning was the discovery that 13% of the respondents had witnessed a company manipulate public opinion on the platform.</p><p id="2b6f">The study‚Äôs demographic analysis further highlighted the targeted nature of corporate trolling. Younger users, particularly those aged 18‚Äì29, were significantly more likely to be contacted by corporate trolls, with 17% of them reporting such experiences, compared to only 7% of users aged 65 and over. This age-based discrepancy underscores the strategic approach of corporate trolls in engaging with a demographic that is often more susceptible to their influence.</p></div><div><p><h2 id="5841">Computers in Human Behavior Study: Uncovering Strategic‚Ä¶</h2></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Lufthansa A350's frustrating Oakland diversion (239 pts)]]></title>
            <link>https://onemileatatime.com/news/lufthansa-a350-oakland-diversion/</link>
            <guid>38699343</guid>
            <pubDate>Tue, 19 Dec 2023 18:19:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://onemileatatime.com/news/lufthansa-a350-oakland-diversion/">https://onemileatatime.com/news/lufthansa-a350-oakland-diversion/</a>, See on <a href="https://news.ycombinator.com/item?id=38699343">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>A San Francisco-bound Lufthansa jet recently had to divert to Oakland due to a company policy, even though the weather was nice, and all other planes were having no issues landing in San Francisco. Were air traffic controller just being petty, is Lufthansa‚Äôs policy unnecessary, or is this just the price you pay when you err on the side of extreme caution?</p>
<div id="ez-toc-container">

<nav><ul><li><a href="#lufthansa_pilots_cant_do_visual_approaches_at_night" title="Lufthansa pilots can‚Äôt do visual approaches at night">Lufthansa pilots can‚Äôt do visual approaches at night</a></li><li><a href="#who_was_in_the_wrong_here" title="Who was in the wrong here?">Who was in the wrong here?</a></li><li><a href="#bottom_line" title="Bottom line">Bottom line</a></li></ul></nav></div>
<h2 id="h-lufthansa-pilots-can-t-do-visual-approaches-at-night"><span id="lufthansa_pilots_cant_do_visual_approaches_at_night"></span>Lufthansa pilots can‚Äôt do visual approaches at night<span></span></h2>
<p>This incident happened on Monday, October 16, 2023, and involves Lufthansa flight LH458 from Munich (MUC) to San Francisco (SFO). The flight was operated by a six-year-old Airbus A350-900 with the registration code D-AIXC. VASAviation did a great job creating a video that has both a visualization of the flight path, plus the audio between the Lufthansa pilots and the air traffic controller. </p>
<p>This incident revolves around how Lufthansa reportedly has a company policy whereby pilots can‚Äôt do visual approaches at night, but rather require instrument landing system&nbsp;(ILS) approaches. I wasn‚Äôt aware of this restriction, and I‚Äôm not sure if it only applies on certain flights (like long hauls), or what. I assume the intent is that this is an extra operational safety layer.</p>
<p>Why does it matter that Lufthansa doesn‚Äôt allow visual approaches? Well, air traffic controllers have to space planes out a bit more for instrument approaches rather than visual approaches, especially at airports like SFO, where parallel landings are performed.</p>
<p>When visual approaches are allowed, controllers can tell pilots to maintain visual separation from other aircraft, so they don‚Äôt have to leave as much of a buffer as with an instrument landing (where it‚Äôs entirely on the controllers to provide proper spacing). And that brings us to the issue here‚Ä¶ </p>
<p>Here‚Äôs what happens between the Lufthansa pilots and the approach controllers:</p>
<ul>
<li>The controller clears the Lufthansa jet to make a visual approach, and the Lufthansa pilot advises ‚Äúdue to company procedures, we are unable visual approach at nighttime‚Äù</li>
<li>The controller then advises that ‚Äúif that‚Äôs the case, then it will be extended delays‚Äù</li>
<li>The Lufthansa pilot responds ‚Äúif that‚Äôs the case, that‚Äôs the case,‚Äù at which point the controller puts the Lufthansa jet into an extended holding pattern</li>
<li>After some time, the Lufthansa pilot advises ‚Äúif we are not set up for base soon, we will have to declare fuel emergency and that would really **** up your sequence‚Äù (I can‚Äôt tell if he says s*ck or f*ck)</li>
<li>At this point the controller asks ‚Äúwhat is your divert field?‚Äù suggesting that rather than letting the Lufthansa jet declare a fuel emergency at SFO, the plane will just have to fly to its diversion point</li>
<li>The Lufthansa pilot says ‚Äúit would be Oakland,‚Äù to which the controller responds ‚Äúyou need vectors to Oakland?‚Äù</li>
<li>The Lufthansa pilot responds ‚Äúno, but I just don‚Äôt understand why everybody is taking‚Ä¶ my company forbids visual separation at night, so what is the problem here?‚Äù</li>
<li>The controller responds ‚ÄúI can‚Äôt have this conversation with you, you either divert to Oakland or you can continue to hold, it‚Äôs up to you‚Äù</li>
<li>The Lufthansa pilot responds ‚Äúokay, you promised me 10 minutes, that ran out four minutes ago, so how many more minutes?‚Äù</li>
<li>The controller responds ‚Äúconversation is over,‚Äù and then says ‚Äúwhat are your intentions, you want to divert or you want to continue with the delay?‚Äù</li>
<li>When the controller advises that it will be an additional 10-15 minute delay, the Lufthansa pilot requests to divert to Oakland</li>
</ul>
<figure></figure>
<p>Unfortunately this turned into quite the messy delay for Lufthansa:</p>
<ul>
<li>The flight was initially supposed to leave Munich at 4:20PM, but only departed at 6:30PM</li>
<li>The flight was supposed to arrive in San Francisco at 7PM, but ended up landing in Oakland at 9:43PM, after a 12hr13min flight</li>
<li>Then at 11:30PM the plane departed Oakland for San Francisco, where it landed at 11:55PM</li>
</ul>
<h2 id="h-who-was-in-the-wrong-here"><span id="who_was_in_the_wrong_here"></span>Who was in the wrong here?<span></span></h2>
<p>Usually in these interactions between pilots and air traffic controllers, there‚Äôs one party that‚Äôs clearly acting out of line.</p>

<p>In this case, the Lufthansa pilots are doing nothing wrong. They‚Äôre following company procedures, and there‚Äôs no flexibility when it comes to that. It‚Äôs a pretty black and white matter. I am curious how the pilots announced this diversion to passengers. ‚ÄúJa, so unfortunately even though the weather is nice in San Francisco, we will be diverting to Oakland because of a specific company procedure that only we follow, when all other planes are landing just fine?‚Äù</p>
<p>The rest of this is totally beyond my area of expertise, but I‚Äôd be curious to know what any OMAAT readers who are pilots or air traffic controllers think. A few thoughts and questions:</p>
<ul>
<li>Are there any other airlines that require instrument landings at night? And is this Lufthansa policy specific to long haul flights where fatigue could be more of an issue, or all flights?</li>
<li>If this is Lufthansa‚Äôs company policy, you‚Äôd think that this wouldn‚Äôt be the first time that this has come up at SFO, and that this is something that air traffic controllers would have dealt with before</li>
<li>To the credit of air traffic controllers, they may have very well had a consistent traffic flow, and allowing in an instrument approach could have messed up the spacing a bit, and could have caused problems for other planes</li>
<li>At the same time, it seems like the air traffic controllers aren‚Äôt exactly trying to go above and beyond to accommodate the Lufthansa jet, and even seem to have quite an attitude with the Lufthansa pilots, and almost get joy out of their diversion; at least that‚Äôs the tone that I sense</li>
</ul>
<figure><img fetchpriority="high" decoding="async" width="1200" height="753" src="https://cdn.onemileatatime.com/wp-content/uploads/2020/07/Lufthansa-A350.jpg" alt="" srcset="https://cdn.onemileatatime.com/wp-content/uploads/2020/07/Lufthansa-A350.jpg?width=360&amp;auto_optimize=low&amp;quality=75 360w, https://cdn.onemileatatime.com/wp-content/uploads/2020/07/Lufthansa-A350.jpg?width=1200&amp;auto_optimize=low&amp;quality=75 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>A Lufthansa Airbus A350 had to divert to Oakland</figcaption></figure>
<h2 id="h-bottom-line"><span id="bottom_line"></span>Bottom line<span></span></h2>
<p>A San Francisco-bound Lufthansa Airbus A350 had to divert to Oakland, due to a company policy whereby Lufthansa pilots apparently can‚Äôt make visual approaches at night. Air traffic controllers were unwilling or unable to help the Lufthansa pilots, and that caused a bit of a spat between the two parties.</p>
<p>This is an interesting situation, and it seemed like the circumstances were the perfect storm for this to happen, given that SFO often has parallel approaches and is consistently busy, so there‚Äôs not much room for extra spacing.</p>
<p><strong>What do you make of this Lufthansa situation?</strong></p>





 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[C++ Should Be C++ (124 pts)]]></title>
            <link>https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p3023r1.html</link>
            <guid>38699223</guid>
            <pubDate>Tue, 19 Dec 2023 18:11:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p3023r1.html">https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p3023r1.html</a>, See on <a href="https://news.ycombinator.com/item?id=38699223">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="doc" data-hard-breaks="true"><p><strong><span>Document number</span></strong><span>: P3023R1</span><br>
<strong><span>Date</span></strong><span>: 2023-10-31</span><br>
<strong><span>Authors</span></strong><span>: David Sankel &lt;</span><a href="mailto:dsankel@adobe.com" target="_blank" rel="noopener"><span>dsankel@adobe.com</span></a><span>&gt;</span><br>
<strong><span>Audience</span></strong><span>: Evolution, Library Evolution</span></p><h2 id="Abstract" data-id="Abstract"><a href="#Abstract" title="Abstract"><span></span></a><span>Abstract</span></h2><p><span>Over the past few years, the C++ community has coped with challenging social media situations, calls for a so-called successor, and signs of upcoming anti-C++ safety regulations. This piles on top of the ordinary committee stress of competing designs and prioritization difficulties. In a time like this it‚Äôs easy to dwell on troubles or adopt fiercely defensive positions.</span></p><p><span>This paper attempts to reframe unconstructive narratives and argue that the committee‚Äôs real opportunity is to improve people‚Äôs lives. We‚Äôll show how this outlook leads to guidance on committee participation, direction, and responsibilities.</span></p><h2 id="Introduction" data-id="Introduction"><a href="#Introduction" title="Introduction"><span></span></a><span>Introduction</span></h2><p><span>The C++ community has been through a lot over the past few years. This paper makes no attempt to recount this history (God forbid!), but instead acknowledges that present circumstances have led committee members to question ‚ÄúWhy are we here?‚Äù, ‚ÄúIs participation in C++ standardization still worthwhile?‚Äù, ‚ÄúWhat does the future hold for C++?‚Äù, and ‚ÄúWhere should I invest my efforts?‚Äù. Today‚Äôs answers to these questions will define C++ for years to come.</span></p><p><span>This document makes the case for my personal perspective and the technical directions that flow from it. My opinions are formed from 23 years of industry C++ experience and 8 years of active committee participation. Equally contributing are countless conversations with engineers flowing from participation in the Boost Foundation, the Bloomberg C++ Guild, C++ conferences, and #include&lt;C++&gt;. However, I don‚Äôt pretend to have all the answers and maintain the right to change my mind when new information presents itself.</span></p><p><span>This document is split into the three parts. The first considers different ideas for a C++ Standardization Committee mission and argues that the most compelling one is to improve people‚Äôs lives. The second discusses some social patterns and temptations that lead to counter-productive decisions. The final part focuses on technical biases and considers some of the immediate choices the committee faces.</span></p><h3 id="Acknowledgements" data-id="Acknowledgements"><a href="#Acknowledgements" title="Acknowledgements"><span></span></a><span>Acknowledgements</span></h3><p><span>Some of what I say here has been more eloquently said elsewhere. I refer the reader especially to </span><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2000r4.pdf" target="_blank" rel="noopener"><em><span>Direction for ISO C++</span></em><span> (P2000R4)</span></a><span> from the direction group and </span><a href="https://dl.acm.org/doi/pdf/10.1145/3386320" target="_blank" rel="noopener"><em><span>Thriving in a Crowded and Changing World</span></em></a><span> from Bjarne Stroustrup. I‚Äôll be quoting extensively from these documents. </span><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1962r0.pdf" target="_blank" rel="noopener"><em><span>How can you be so certain?</span></em><span> (P1962R0)</span></a><span> and </span><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0559r0.pdf" target="_blank" rel="noopener"><em><span>Operating principles for evolving C++</span></em><span> (P0559R0)</span></a><span> also cover similar topics.</span></p><p><span>I‚Äôd be remiss if I did not also credit Niall Douglas, Inbal Levi, Bjarne Stroustrup, and Herb Sutter for providing valuable feedback that substantially improved this document.</span></p><h2 id="Mission" data-id="Mission"><a href="#Mission" title="Mission"><span></span></a><span>Mission</span></h2><h3 id="The-biggest-threat" data-id="The-biggest-threat"><a href="#The-biggest-threat" title="The-biggest-threat"><span></span></a><span>The biggest threat</span></h3><p><em><span>How can you be so certain?</span></em><span> states ‚Äúif we are not careful, C++ can still fail‚Äù. </span><em><span>Operating principles for evolving C++</span></em><span> suggests principles ‚Äúin order to keep C++ alive, healthy and progressing‚Äù. These statements, representing a wider community outlook, imply C++ is an entity that has acquired something valuable that can be lost. What does this mean, exactly?</span></p><p><span>It is easy to see that C++ is fit as a general-purpose programming language‚Äìadoption by millions is a testament to that. Engineers gain proficiency in a reasonable amount of time and use it to solve their problems. C++'s usefulness it what matters.</span></p><p><span>Many think other programming languages ‚Äúthreaten‚Äù C++ or have the potential to ‚Äútake away‚Äù what it has. A closer look reveals that the presence of a new tool doesn‚Äôt make an existing tool less capable, but potentially more capable.</span></p><p><span>What about regulatory legislation? It cannot change C++'s capabilities any more than those of my hammer. C++ does what it does and is useful where it is used. Unlike my hammer, however, there </span><em><span>is</span></em><span> an entity with the power to degrade C++'s fitness: the C++ standardization committee.</span></p><p><span>The surest way to make a standard irrelevant is to say yes to everything. It is easy to see why: standardizing a complex mess of incoherent ideas quickly becomes ‚Äúinsanity to the point of endangering the future of C++‚Äù</span><sup><a href="#fn1" id="fnref1">[1]</a></sup><span>. If my hammer is replaced with a complex gadget requiring thousands of pages of instructions, it is no longer useful for me. Yet, this is exactly our tendency with C++.</span></p><p><span>If C++'s biggest threat is the standardization committee then that begs the question of how to mitigate its risk and align it to a greater good.</span></p><h3 id="Mission1" data-id="Mission"><a href="#Mission1" title="Mission1"><span></span></a><span>Mission</span></h3><p><span>A body comprised of hundreds of individuals cannot function without a unifying mission. There are many ideas of what this should be for WG21, but here are a few strawmen worth considering:</span></p><ol>
<li><span>Make/keep C++ the best language in the world.</span></li>
<li><span>Make C++ the only language people use.</span></li>
<li><span>Make C++ the most popular language.</span></li>
</ol><p><span>The ideas of a ‚Äúbest‚Äù, ‚Äúsole‚Äù, or ‚Äúmost popular‚Äù language are questionable, but more concerning is their impact. First, this outlook leads to an aversion of other languages both from pride and fear that those other languages might be ‚Äúbetter‚Äù. Consider, for example, that 40% of C++ developers want to use Rust and 22% already do; ignorance of Rust is ignorance of our users.</span><sup><a href="#fn2" id="fnref2">[2]</a></sup><span> Second, positioning C++ as the ‚Äúbest‚Äù language leads to grafting features of other languages at the expense of complexity and consistency. Finally, a lot of energy is expended in useless arguments claiming the benefits of ‚Äúcompeting‚Äù languages are overblown and that the drawbacks of C++ are exaggerated.</span></p><p><span>We need a more constructive mission and I think there is one: to improve people‚Äôs lives. When the range-based for loop reached compilers, millions of developers smiled and said ‚ÄúAh, that‚Äôs nice.‚Äù It may have even made their day. This is the kind of massive good within WG21‚Äôs control and aligning ourselves to it is incredibly rewarding.</span></p><p><span>An altruistic mindset eliminates the idea of ‚Äúcompetitor‚Äù. Would Habitat for Humanity morn if the Peace Corps reached a distressed area first? Of course not! They would celebrate the arrival of help. It should be the same with us when our users solve their problem using a different tool. Other language communities helping our users are our allies. We must not forget that. Turf wars don‚Äôt serve our users‚Äô interests.</span></p><p><span>Some patterns of thought frustrate a mission of improving people‚Äôs lives. Awareness of these is important as they undoubtedly crop up.</span></p><h3 id="C-as-personal-and-group-identity" data-id="C-as-personal-and-group-identity"><a href="#C-as-personal-and-group-identity" title="C-as-personal-and-group-identity"><span></span></a><span>C++ as personal and group identity</span></h3><p><span>One of the first questions programmers ask each other in a social setting is ‚ÄúWhat language do you program in?‚Äù. This frequently sets the stage for unfortunate stereotypes. ‚ÄúOh, a Java programmer who writes slow code‚Äù. ‚ÄúOh, a Python programmer who cannot program in a ‚Äòreal‚Äô language‚Äù. ‚ÄúOh, a Go programmer who ‚Ä¶‚Äù. When we think of C++ we may find pride in mastery of a difficult language, the ability to write high performance code, and a relationship to the world‚Äôs greatest C++ works.</span></p><p><span>While there are benefits to identification with C++ as a source of greatness and purpose, this comes at a cost. First, being primarily an emotional transference, it clouds reason. At my first committee meeting I was advised to avoid mentioning functional programming lest people dismiss my arguments upon hearing the words. Second, deep identification with C++ can create deep seated fears that C++ will become a ‚Äúlegacy‚Äù language making one‚Äôs skillset (and person even!) obsolete.</span></p><p><span>I mention these things because they frequently compromise a standardization mission to improve people‚Äôs lives. We need to assess the programming language world without tribalism tempting us to ignore or overcompensate for issues.</span></p><h3 id="Counterproductive-rhetoric" data-id="Counterproductive-rhetoric"><a href="#Counterproductive-rhetoric" title="Counterproductive-rhetoric"><span></span></a><span>Counterproductive rhetoric</span></h3><p><span>C++ is frequently written and talked about as if it were a living thing. Words like ‚Äúfatal‚Äù</span><sup><a href="#fn3" id="fnref3">[3]</a></sup><span>, ‚Äúfail‚Äù</span><sup><a href="#fn4" id="fnref4">[4]</a></sup><span>, ‚Äúdead‚Äù</span><sup><a href="#fn5" id="fnref5">[5]</a></sup><span>, and ‚Äúdeath‚Äù</span><sup><a href="#fn6" id="fnref6">[6]</a></sup><span> are common in our literature. When we imagine C++ as a living thing, we naturally associate finite resources (active users), competition (other languages), and death (obsolescence). This thinking is fundamentally inaccurate. C++ is not alive, cannot die, and isn‚Äôt competing against anything. It is a merely a tool that is sometimes useful.</span></p><p><span>We must move away from this thinking. In combination with the transference previously discussed, it generates fear and encourages the idea of enemies. The current lack of cooperation and credit between different language communities is quite unfortunate. At its worst people are put down because of the programming language they associate with.</span></p><p><span>Let us remember that a) languages don‚Äôt battle, people do, b) smearing other languages doesn‚Äôt improve people‚Äôs lives, and c) C++ living forever is not our goal.</span></p><h3 id="Standardization-as-personal-opportunity-vs-stewardship" data-id="Standardization-as-personal-opportunity-vs-stewardship"><a href="#Standardization-as-personal-opportunity-vs-stewardship" title="Standardization-as-personal-opportunity-vs-stewardship"><span></span></a><span>Standardization as personal opportunity vs. stewardship</span></h3><p><span>When first joining the committee, it is easy to see participation as primarily a personal opportunity to gain C++ expertise, rub shoulders with celebrities, and, worse of all, leave a mark on the world by getting a proposal accepted. While all these things do indeed happen, there is something much larger at play here.</span></p><p><span>The direction group warns ‚Äúwe are writing a standard for millions of programmers to rely on for decades, a bit of humility is in order.‚Äù</span><sup><a href="#fn7" id="fnref7">[7]</a></sup><span> This is not an earnable privilege and none of us are really qualified to make these decisions, but here we are. Our heavy responsibility outweighs the personal opportunities.</span></p><p><span>What does that responsibility entail? It means rejecting proposals without an understandable value proposition. It means resisting social pressure when you are against something. It means building an informed opinion by reading the paper, testing the feature, and collaborating with others. It means saying ‚Äúyes‚Äù only when there is minimal risk. Above all, it means stewardship: you are a caretaker and guardian of something beyond yourself.</span></p><p><span>If you do write a proposal, save time and frustration by enlisting the help of experienced designers and wording experts. They want to help! Also, carefully consider if the problem you‚Äôre solving justifies the additional complexity and risk. C++ is a language that is ‚Äútrying to do too much too fast‚Äù</span><sup><a href="#fn8" id="fnref8">[8]</a></sup><span> and needs ‚Äúto become more restrained and selective‚Äù</span><sup><a href="#fn9" id="fnref9">[9]</a></sup><span>.</span></p><h2 id="The-technical-aspect" data-id="The-technical-aspect"><a href="#The-technical-aspect" title="The-technical-aspect"><span></span></a><span>The technical aspect</span></h2><p><span>Equally important to our social tendencies are the technical tendencies that work against us. This section calls out several anti-patterns, none of which are new </span><sup><a href="#fn10" id="fnref10">[10]</a></sup><span>.</span></p><h3 id="Neophilia" data-id="Neophilia"><a href="#Neophilia" title="Neophilia"><span></span></a><span>Neophilia</span></h3><p><span>Bjarne succinctly stated ‚ÄúEnthusiasm favors the new‚Äù</span><sup><a href="#fn11" id="fnref11">[11]</a></sup><span>. Technological innovations and fads follow a familiar hype curve </span><sup><a href="#fn12" id="fnref12">[12]</a></sup><span> that begins with a peak of inflated expectations. We risk getting caught up in enthusiasm and standardizing features that, in retrospect, don‚Äôt deliver on their promise, poorly integrate with the rest of the language, and increase learning costs.</span></p><p><span>Consider Rust traits which solve similar problems to those of C++ concepts. Traits‚Äôs explicit opt-in semantics offers several advantages including separately type-checked generics. Should we add traits to C++? If we do so, we‚Äôll end up with two ways to solve the same problem with millions of lines of code using the old way. Moreover, most developers will need to be familiar with both to be effective in a large, existing codebase, compounding C++'s learning costs.</span></p><p><span>Just because another language has something potentially better than C++ doesn‚Äôt mean we should incorporate it. ‚ÄúKeeping up with the Joneses‚Äù is a disservice. We should ask ourselves how non-experts, making up most of our users, will react when seeing a feature for the first time in someone else‚Äôs code. Frequently it is frustration from having to spend time learning something with marginal benefit over what it replaces.</span></p><h3 id="Features-and-prioritization-bias-towards-experts" data-id="Features-and-prioritization-bias-towards-experts"><a href="#Features-and-prioritization-bias-towards-experts" title="Features-and-prioritization-bias-towards-experts"><span></span></a><span>Features and prioritization bias towards experts</span></h3><p><span>The C++ committee, predominantly comprised of experts, leaves average programmers ‚Äúseriously underrepresented‚Äù</span><sup><a href="#fn13" id="fnref13">[13]</a></sup><span>. This ‚Äúbiases the committee towards language lawyering, advanced features, and implementation issues, rather than directly addressing the needs of the mass of C++ developers, which many committee members know only indirectly‚Äù</span><sup><a href="#fn14" id="fnref14">[14]</a></sup><span>.</span></p><p><span>Time spent on expert features squanders opportunities to improve lives at scale. When we prioritize a proposal, we should ask ‚Äúis this solving a problem for experts or for the average developer?‚Äù. If it‚Äôs the former, we should seriously consider moving on.</span></p><p><span>Our expert imbalance also results in over-complicated solutions that require advanced proficiencies for simple tasks. Consider the hoops one needs to jump through to make </span><code>std::print</code><span> work with a custom type when compared to the old stream operators. It is too easy for experts to lose touch with novices and professional engineers who don‚Äôt spend their free time learning advanced C++ complexities, especially when surrounded by other experts.</span></p><p><span>One of the most valuable things committee members can do is discuss proposals with application engineers. ‚ÄúIs this something you would use?‚Äù. ‚ÄúIs this ergonomic?‚Äù. ‚ÄúHow hard is this to learn?‚Äù. ‚ÄúIs this worth another chapter in the C++ book?‚Äù. This kind of feedback should weigh more heavily than abstract theories on what an ideal developer should want.</span></p><h3 id="Complexity" data-id="Complexity"><a href="#Complexity" title="Complexity"><span></span></a><span>Complexity</span></h3><p><span>The direction group sees ‚ÄúC++ in danger of losing coherency due to proposals based on differing and sometimes mutually contradictory design philosophies and differing stylistic tastes.‚Äù </span><sup><a href="#fn15" id="fnref15">[15]</a></sup><span> Bjarne suspects this is due to a combination of committee growth, an influx of new people, specialization of membership, and a decrease of knowledge of C++'s history among the members.</span><sup><a href="#fn16" id="fnref16">[16]</a></sup></p><p><span>Changes reducing coherence increase complexity and this elevates training costs. Hiring C++ developers is much more challenging than hiring other developers not because of demand, but because the barrier to entry is too high. Fewer people want to learn C++ and fewer schools want to teach it. One of the important ways we can improve people‚Äôs lives is to help our users find colleagues.</span></p><p><span>The direction group recalls Alex Stepanov rescuing C++ from disaster by bringing consistency and coherence to the standard library</span><sup><a href="#fn17" id="fnref17">[17]</a></sup><span>, yet we actively debate breaking these same rules for a relatively niche library addition. We recently replaced a simple </span><code>std::function</code><span> template with no less than three alternatives: </span><code>std::copyable_function</code><span>, </span><code>std::function_ref</code><span>, and </span><code>std::move_only_function</code><span>. This isn‚Äôt helping our complexity problems!</span></p><p><span>I agree with the design group that we must ‚Äúaim for coherence‚Äù</span><sup><a href="#fn18" id="fnref18">[18]</a></sup><span>. Here are three concrete suggestions for doing so:</span></p><ol>
<li><span>Curb the tendency to focus proposal discussions on a narrow problem domain by asking how it fits within the entire C++ offering. ‚ÄúIs this in the common C++ style?‚Äù. ‚ÄúIs this increasing C++'s barrier to entry?‚Äù. ‚ÄúHow would this impact the hypothetical ‚ÄòC++ book‚Äô?‚Äù</span></li>
<li><span>Encourage study groups to get early feedback from the evolution groups (EWG and LEWG) on the desirability of features.</span><sup><a href="#fn19" id="fnref19">[19]</a></sup><span> Evolution groups are responsible for considering the bigger picture. Getting this feedback before extensive study group iteration can prevent undesirable features gaining difficult-to-stop momentum.</span></li>
<li><span>Overcome reluctance to say, ‚ÄúI don‚Äôt think this belongs in C++.‚Äù We don‚Äôt do authors any favors by providing improvement feedback on proposals that are ultimately undesirable.</span></li>
</ol><h3 id="Niche-problems-getting-more-than-niche-effort" data-id="Niche-problems-getting-more-than-niche-effort"><a href="#Niche-problems-getting-more-than-niche-effort" title="Niche-problems-getting-more-than-niche-effort"><span></span></a><span>Niche problems getting more than niche effort</span></h3><blockquote>
<p><span>[I]t is hard for a committee to remember that a language cannot be all things to all people. It is even harder to accept that it cannot solve even the most urgent problems of every member.</span></p>
<p><span>Bjarne Stroustrup, </span><em><span>Thriving in a Crowded and Changing World</span></em></p>
</blockquote><p><span>In committee, we frequently spend time on things that only a small number of people care about. It‚Äôs difficult to say ‚Äúno‚Äù when someone, somewhere would benefit. There‚Äôs also a tendency to mentally check-out during these discussions which results in proposals not getting an appropriate rigor.</span></p><p><span>When we fall into these traps, we 1) deny the greater number of users time spent on proposals that can improve their lives, 2) needlessly increase the complexity of the language and library, and 3) encourage more niche proposals.</span></p><p><span>Solving these problems boils down to saying ‚Äúno‚Äù more often and, if needed, repeatedly. Bug fixes aside, the committee should spend its time on a fewer number of proposals that have a bigger impact. Effort spent writing papers solving pet peeves in C++ is better spent writing up analyses and experience reports on higher-impact proposals. We should be doing more to acknowledge such work.</span></p><h2 id="Moving-ahead" data-id="Moving-ahead"><a href="#Moving-ahead" title="Moving-ahead"><span></span></a><span>Moving ahead</span></h2><p><span>This section considers a memory safety and a major C++ overhaul in light this paper‚Äôs principles.</span></p><h3 id="Memory-safety" data-id="Memory-safety"><a href="#Memory-safety" title="Memory-safety"><span></span></a><span>Memory safety</span></h3><p><span>Official documents discussing legislation against C++ due its ‚Äúmemory unsafety‚Äù have caused community uproar. We‚Äôve seen gigantic email threads, a new study group dedicated to safety, and numerous talks at C++ conferences. What is much less prevalent is a demand from average C++ users for memory safety features; they‚Äôre much more concerned about compilation speed. When most C++ developers haven‚Äôt adopted tools like Coverity and C++ core guidelines checkers, it is hard to claim that memory safety features substantially improve their lives at least from their point of view.</span></p><p><span>Where memory safety </span><em><span>is</span></em><span> a serious concern, we see the adoption of Rust for critical components. Yet we see little demand from even these developers for C++ safety features. Their problem is already solved.</span></p><p><span>The direction group states ‚Äúno language can be everything for everybody‚Äù</span><sup><a href="#fn20" id="fnref20">[20]</a></sup><span> and I cannot agree more. Rust and other languages are successfully filling engineering needs for memory safety guarantees in critical components. This is not a space our users are demanding us to go into and doing so risks both failure and, yes, even more complexity.</span></p><h3 id="Major-C-overhaul" data-id="Major-C-overhaul"><a href="#Major-C-overhaul" title="Major-C-overhaul"><span></span></a><span>Major C++ overhaul</span></h3><p><span>Over the past two years it‚Äôs become in vogue to talk about ‚ÄúC++ successors‚Äù which range from dramatic syntax changes to replacing the C++ committee with another organization. What should the committee‚Äôs response be to this phenomenon?</span></p><p><span>For groups attempting a new language outside of the committee, I think our response should be support. If these initiatives don‚Äôt confuse or otherwise harm our users, they share our goal of improving people‚Äôs lives. When they succeed, that‚Äôs a good thing. Even if they fail, the ideas they generate might help our users in the end.</span></p><p><span>What about the option to drastically change the face of C++ in the context of WG21? A C++ 2.0, perhaps? If you ask a typical C++ developer how we can improve their lives, a modern and snazzy new syntax will not top their list. Yes, </span><code>template</code><span> and </span><code>typename</code><span> are tedious to read and type, but it‚Äôs what they know and they‚Äôd rather it not be mucked with. This is more than reluctance to change‚Äìour users want coherence in their C++ code base as much as we want coherence in the standard.</span></p><p><span>If a C++ successor ever gains traction, our users would want it to be the best it can be. The committee composition doesn‚Äôt have a magical quality that makes it more suited to build a successor than any other entity. The inertia from C++ 1.0‚Äôs adoption may even lead to a C++ 2.0 getting adopted when other successor attempts are more fit for purpose. That wouldn‚Äôt be good for our users.</span></p><p><span>In summary, the C++ committee‚Äôs biggest opportunity to improve people‚Äôs lives is to focus on C++ as it is today to serve us better in a few years time under the constraints of compatibility. Let‚Äôs leave speculative successor projects to external entities. We‚Äôre distracted enough as it is.</span></p><h3 id="What-should-we-do" data-id="What-should-we-do"><a href="#What-should-we-do" title="What-should-we-do"><span></span></a><span>What should we do?</span></h3><p><span>I‚Äôve said a lot about what we should not do. That‚Äôs intentional‚Äìwe need to do less. However, I don‚Äôt want to give the impression we should say no to </span><em><span>all</span></em><span> proposals. There are plenty of opportunities to improve our user‚Äôs lives through proposals. Here are a few concrete examples:</span></p><ul>
<li>
<p><strong><span>Faster hashing and hash combiners</span></strong><span>. The standard library‚Äôs hash map and hash set interfaces are now decades old. Over that time, we‚Äôve seen an explosion in their utility and many algorithmic advancements, advancements that require an interface change. By adding more modern hashing data structures to the standard, we can substantially improve the performance, and environmental impact, of newly written code. Our users also desperately need a standardized way to combine hashes in their own hash functions.</span></p>
</li>
<li>
<p><strong><span>JSON parsing</span></strong><span>. A simple, ergonomic, standardized JSON parsing and serialization library will save many users from searching libraries or, worse, writing custom formats. A non-goal is to be the world‚Äôs fastest JSON parser.</span></p>
</li>
<li>
<p><strong><span>Command-line parsing</span></strong><span>. A simple, standardized library for command-line parsing will also improve the lives of the 99% by replacing the common </span><code>argv[1]</code><span> parsing in small applications.</span></p>
</li>
</ul><p><span>There are many more ideas like these. The goal is to give as many people as possible the ‚Äúah, that‚Äôs nice‚Äù reaction.</span></p><h2 id="Conclusion" data-id="Conclusion"><a href="#Conclusion" title="Conclusion"><span></span></a><span>Conclusion</span></h2><p><span>This paper advocates for a C++ standardization mission: improving people‚Äôs lives. It also identified the social and technical biases that obstruct this mission. Finally, it considered major ongoing WG21 discussions and suggested ideas for future work.</span></p><p><span>In the end, when I say ‚ÄúC++ should be C++‚Äù I mean that C++ is a useful tool as it is‚Äìdrastic changes aren‚Äôt helpful. To avoid it becoming what it is not, we need to say ‚Äúno‚Äù more often, recognize our biases, and, above all, put our users first.</span></p><h2 id="References" data-id="References"><a href="#References" title="References"><span></span></a><span>References</span></h2><p><span>‚Äú2023 Developer Survey.‚Äù </span><em><span>Stack Overflow</span></em><span>, 2023, </span><a href="https://survey.stackoverflow.co/2023/" target="_blank" rel="noopener"><span>https://survey.stackoverflow.co/2023/</span></a><span>.</span></p><p><span>Hinnant, Howard et al. ‚ÄúDirection for ISO C++.‚Äù 15 October 2022, </span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>https://wg21.link/P2000R4</span></a><span>.</span></p><p><span>Stroustrup, Bjarne. ‚ÄúHow can you be so certain?‚Äù 18 November 2019, </span><a href="https://wg21.link/P1962R0" target="_blank" rel="noopener"><span>https://wg21.link/P1962R0</span></a><span>.</span></p><p><span>Stroustrup, Bjarne. ‚ÄúRemember the Vasa!‚Äù 6 March 2018, </span><a href="https://wg21.link/P0977R0%5D" target="_blank" rel="noopener"><span>https://wg21.link/P0977R0</span></a><span>.</span></p><p><span>Stroustrup, Bjarne. ‚ÄúThriving in a Crowded and Changing World: C++ 2006-2020.‚Äù </span><em><span>Proc. ACM Program. Lang.</span></em><span>, vol. 4, HOPL, June 2020, Article 70, pp. 1-167,  </span><a href="https://doi.org/10.1145/3386320" target="_blank" rel="noopener"><span>https://doi.org/10.1145/3386320</span></a><span>.</span></p><p><span>van Winkel, J.C. et al. ‚ÄúOperating principles for evolving C++‚Äù 31 Janurary 2017, </span><a href="https://wg21.link/P0559R0" target="_blank" rel="noopener"><span>https://wg21.link/P0559R0</span></a><span>.</span></p><hr><section>
<ol>
<li id="fn1"><p><em><span>Remember the Vasa!</span></em><span> (</span><a href="https://wg21.link/P0977R0" target="_blank" rel="noopener"><span>P0977R0</span></a><span>)</span> <a href="#fnref1">‚Ü©Ô∏é</a></p>
</li>
<li id="fn2"><p><span>The Stack Overflow 2023 survey had 89,184 respondents. 19,634 indicated they did "extensive development work" C++ over the past year and 4,269 claimed extensive development work in both Rust and C++ over the past year. Of those who used C++, 7,918 indicated a desire to work in Rust over the next year.</span> <a href="#fnref2">‚Ü©Ô∏é</a></p>
</li>
<li id="fn3"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a> <a href="#fnref3">‚Ü©Ô∏é</a></p>
</li>
<li id="fn4"><p><em><span>How can you be so certain</span></em><span> (</span><a href="https://wg21.link/P1962R0" target="_blank" rel="noopener"><span>P1962R0</span></a><span>)</span> <a href="#fnref4">‚Ü©Ô∏é</a></p>
</li>
<li id="fn5"><p><em><span>Operating principles for evolving C++</span></em><span> (</span><a href="https://wg21.link/P0559R0" target="_blank" rel="noopener"><span>P0559R0</span></a><span>)</span> <a href="#fnref5">‚Ü©Ô∏é</a></p>
</li>
<li id="fn6"><p><span>ibid.</span> <a href="#fnref6">‚Ü©Ô∏é</a></p>
</li>
<li id="fn7"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref7">‚Ü©Ô∏é</a></p>
</li>
<li id="fn8"><p><em><span>How can you be so certain?</span></em><span> (</span><a href="https://wg21.link/P1962R0" target="_blank" rel="noopener"><span>P1962R0</span></a><span>)</span> <a href="#fnref8">‚Ü©Ô∏é</a></p>
</li>
<li id="fn9"><p><span>ibid.</span> <a href="#fnref9">‚Ü©Ô∏é</a></p>
</li>
<li id="fn10"><p><span> See </span><em><span>Thriving in a Crowded and Changing World</span></em><span> and </span><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref10">‚Ü©Ô∏é</a></p>
</li>
<li id="fn11"><p><span> </span><em><span>Thriving in a Crowded and Changing World</span></em><span> </span> <a href="#fnref11">‚Ü©Ô∏é</a></p>
</li>
<li id="fn12"><p><span> https://en.wikipedia.org/wiki/Gartner_hype_cycle </span> <a href="#fnref12">‚Ü©Ô∏é</a></p>
</li>
<li id="fn13"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref13">‚Ü©Ô∏é</a></p>
</li>
<li id="fn14"><p><em><span>Thriving in a Crowded and Changing World</span></em> <a href="#fnref14">‚Ü©Ô∏é</a></p>
</li>
<li id="fn15"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref15">‚Ü©Ô∏é</a></p>
</li>
<li id="fn16"><p><em><span>Thriving in a Crowded and Changing World</span></em> <a href="#fnref16">‚Ü©Ô∏é</a></p>
</li>
<li id="fn17"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref17">‚Ü©Ô∏é</a></p>
</li>
<li id="fn18"><p><span>ibid.</span> <a href="#fnref18">‚Ü©Ô∏é</a></p>
</li>
<li id="fn19"><p><span>Credit to Niall Douglas for this idea</span> <a href="#fnref19">‚Ü©Ô∏é</a></p>
</li>
<li id="fn20"><p><em><span>Direction for ISO C++</span></em><span> (</span><a href="https://wg21.link/P2000R4" target="_blank" rel="noopener"><span>P2000R4</span></a><span>)</span> <a href="#fnref20">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bit banging a 3.5" floppy drive (208 pts)]]></title>
            <link>https://floppy.cafe/</link>
            <guid>38699201</guid>
            <pubDate>Tue, 19 Dec 2023 18:09:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://floppy.cafe/">https://floppy.cafe/</a>, See on <a href="https://news.ycombinator.com/item?id=38699201">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <h2>Bit Banging a 3.5" Floppy Drive</h2>
      
      <p>
        Welcome to the <b>floppy cafe</b>! These pages are the lost and sacred
        texts you've been looking for if you happen to be writing a driver for
        a 3.5" floppy. To learn these mysteries, I bit-banged a floppy drive
        using a
        <a href="https://www.pjrc.com/store/teensy40.html" target="_blank" rel="noreferrer">teensy4.0</a>
        and managed to write a full driver for it. My project code is hosted
        <a href="https://github.com/SharpCoder/floppy-driver-rs" target="_blank" rel="noreferrer">here on github</a>
        in case you'd like to learn more. Continue reading for an extremely
        detailed overview of the project and all my findings on this adventure.
        <b>Although the information is largely common for any floppy drive,
          floppy.cafe is dedicated specifically to 3.5" media.
        </b>
      </p>
      <h2>Table of Contents</h2>
      
        
        
        
        
        
        
      
      <h2>
        <a id="how-do-floppy-disks-work" href="#how-do-floppy-disks-work"><img src="https://floppy.cafe/media/link.png"></a>How do Floppy Disks
        Work?
      </h2>
      <p>
        This
        <a href="http://philipstorr.id.au/pcbook/book4/floppyd.htm" target="_blank">website</a>
        has a good overview and some nice pictures. Fundamentally, your floppy
        houses a magnetized disk that spins at about 300rpm. For 3.5" media,
        that disk contains 80 tracks. Each track has 18 sectors. Each sector has
        512 bytes of user-space data (and some more bytes used for metadata).
        Most "modern" floppies are double-sided, so you can multiply all that by
        2 in order to find the total amount of usable space per disk.
        <code>1,474,560 bytes</code> in all.
      </p>
      <p>
        <b>Fun fact!</b> floppy disks actually contain a lot more surface area
        than 1.44mb. By my calculation, you'll get closer to 1.70mb but a lot of
        that extra space is earmarked for
        <a href="#synchronization-barriers">synchronization barriers</a> and
        sector / track metadata.
      </p>
      <h2>
        <a id="wiring-guide" href="#wiring-guide"><img src="https://floppy.cafe/media/link.png"></a>
        Wiring Guide
      </h2>
      <p>
        Here's the cool thing about floppy drives: they have no communication
        protocol! It's just a bunch of gpio pins. For most of them, pulling the
        pin <code>HIGH</code> means it is in the "disabled" or "off" state.
        Pulling a pin <code>LOW</code> will activate it. You can read about the
        very detailed specifications for the
        <a href="https://floppy.cafe/resources/SAMSUNG-SFD321B-070103.pdf" target="_blank">SAMSUNG-SFD321B</a>
        floppy drive. The top row of pins are the functions, the bottom row of
        pins are all <b>LOGIC GROUND</b>. Logic. Did you get that? LOGIC! Not
        motor ground. I had them wired up wrong for weeks and wondered why
        nothing worked. And, yes, there's like a million ground pins but you
        only need 1 to get it working.
      </p>
      <p>
        <b>An important note!</b> the logic-level pins are rated for 5v,
        however, you can use 3v3 in a pinch! Why is that? All these data pins
        are <i>open drain</i> and should be hooked up to a
        <i>pull-up resistor</i>. That means the only way these floppy drives
        communciate back is by sinking the voltage. So 3v3, 5v, it doesn't
        matter. The floppy drive will happily pull it down.
      </p>
      <p>
        <b>Protip!</b> Some of the bottom row of pins are
        <b>not connected internally!</b> So if you are plugging in just 1 ground
        wire and it's not working, chances are the ground pin you selected is
        disconnected. Try another one.
      </p>
      <img alt="A page from a guide showing what each pin on the back of a floppy drive does." src="https://floppy.cafe/media/pins.png">
      <p>
        You'll notice the power section only needs two wires. 5v+ and another
        ground. For your sanity, I suggest using a separate power bus than
        whatever your microcontroller is on.
      </p>
      <p>
        Please do not connect the 5v+ to an arduino or a GPIO! It can draw
        upwards of 1A during really feisty operations and it will
        <b>fry your microcontroller!</b>
      </p>
      <h2>
        <a id="sending-commands" href="#sending-commands"><img src="https://floppy.cafe/media/link.png"></a>Sending Commands
      </h2>
      <p>
        There are a number of commands and proceedures you will need to
        implement in order to assume control of the floppy drive. In general,
        commands are issued by pulling a given pin <code>LOW</code>.
      </p>

      <p>
        <b>A word of warning:</b> I've read online the Arduino internal pull-ups
        aren't great. They'll work for most of these pins
        <i>except the data line</i>. You may want to add a 4.5k pull-up to the
        <code>DATA</code> line instead of relying on the built-in pull-ups.
      </p>
      <p>Alright! Let's explore each function you have access to.</p>

      <h3>Index</h3>
      <p>
        The floppy drive doesn't really know <i>where</i> you are at any given
        time. You can suss this out with various mechanisms, and one of those
        mechanisms is the <b>INDEX</b> pin. The index pin is the first usable
        pin on the top row (pin 8). When this pin is <code>LOW</code>, the disk
        has made one complete revolution and is currently at the start of the
        data stream.
      </p>
      <p>
        In my driver, I would often look for <code>HIGH</code> to
        <code>LOW</code> transitions and use this to increment an error counter.
        If I can't complete some task after 10 revolutions or so, I consider the
        drive in a bad state.
      </p>

      <h3>Drive Select</h3>
      <p>
        There are a few different drive select pins (often for drive 0, 1, and
        2) but the main one we're interested in is
        <code>PIN 12</code> also known as <code>DRIVE SELECT 1</code>. The other
        ones are reserved for controlling multiple floppy drives at once. This
        function is used to enable the floppy drive. Pulling it
        <code>LOW</code>
        will provide you access to all the other I/O functions except
        <code>MOTOR ON</code>. That one is agnostic of drive select.
      </p>
      <h3>Motor On</h3>
      <p>
        As the name suggests, this pin is dedicated to controlling the motor. To
        enable the motor, pull this pin
        <code>LOW</code> and then wait 500ms. It's good practice to monitor the
        <code>INDEX</code> line as well for a <code>HIGH</code> to
        <code>LOW</code> transition, indicating that the spindle has made a
        complete revolution.
      </p>
      <h3>Direction Select</h3>
      <p>
        This pin controls the direction that the track <b>stepper motor</b> pin
        will move in, when you pulse the <code>STEP</code> pin. Pulling this pin
        <code>LOW</code> will orient the track stepper motor to move towards the
        center of the magnetic disk (increasing the track number). Pulling this
        pin <code>HIGH</code> will orient the track stepper to move towards the
        outside of the magnetic disk (decreasing the track number).
      </p>
      <h3>Step</h3>
      <p>
        There are 80 tracks on your average 3.5" floppy drive. You can select a
        given track by pulsing the <code>STEP</code> pin and combining it with
        the <b>direction select</b> pin.
      </p>
      <p>
        Pulsing this pin will charge and actuate a stepper motor. As such, there
        are some specific timing requirements. I like to pull it
        <code>LOW</code> for <code>3ms</code> and then pull it
        <code>HIGH</code> for an additional <code>3ms</code> and leave it in the
        high state until the next pulse. The documentation states it can be low
        for as short as <code>0.15us</code> but that didn't work for me
        consistently across other drives.
      </p>
      <h3>Write Data</h3>
      <p>
        If you want to know a lot more about this pin, head on over to the
        <a href="https://floppy.cafe/mfm.html">MFM ENCODING</a> page for a primer on how to use it.
        From a technical perspective, pulsing this pin will reverse the flux
        direction on the magnetized disk. In general, you will hold the pin
        <code>LOW</code> for about <code>0.15us to 1.1us</code> and then bring
        it back to a <code>HIGH</code> state. How long it remains in the high
        state determines the encoded value according to the MFM rules.
      </p>
      <h3>Write Gate</h3>
      <p>
        Pusling the write data pin will do nothing if the gate is closed. To
        begin writing data, you must pull this pin <code>LOW</code> and keep it
        low during your write operation.
      </p>
      <p>
        <b>You cannot read and write at the same time.</b>
      </p>
      <p>
        <b>Fun fact!</b> While I was developing my driver, I ruined many entire
        tracks by leaving this open for too long. If you aren't careful, it'll
        wreck the sector metadata and synchronization barriers and totally
        destroy your floppy disk. Reformatting the disk should restore balance
        to the force, so this won't be a total loss.
      </p>
      <h3>Track 00</h3>
      <p>
        The floppy drive controls this pin, and when it gets pulled
        <code>LOW</code> that means the read/write head is positioned on
         the first track  (<b>track 0</b>).
      </p>
      <h3>Write Protect</h3>
      <p>
        When a write-protected media is insertted, this pin will be pulled
        <code>LOW</code> by the floppy drive and the data on the disk is
        protected from mis-erasing. When the pin is <code>HIGH</code> the
        floppy drive can be written.
      </p>
      <p>
        This only seems to work if the <b>drive select</b> pin has been pulled
        low.
      </p>
      <h3>Read Data</h3>
      <p>
        A <code>HIGH</code> to <code>LOW</code> transition on this line
        indicates the flux direction has changed on the underlying magnetic
        disk. Once you encouter this transition, count all the clock cyles
        between the <i>leading edge</i> of the <code>LOW</code> signal to the
        <i>trailing edge</i> of the <code>HIGH</code> signal.
      </p>
      <h3>Side Select</h3>
      <p>
        These 3.5" floppy disks have 2 sides. Pulling this pin
        <code>HIGH</code> selects the lower side (side 0). Pulling this pin
        <code>LOW</code> selects the upper side (side 1).
      </p>
      <h3>Ready/Disk Change</h3>
      <p>
        I never got this to work, but the spec says it will either tell you if
        the drive is in a ready state or not. When the floppy drive pulls this
        pin <code>LOW</code>, the drive is ready for operation. Otherwise, the
        pin will be left in a <code>HIGH</code> state.
      </p>
      <h2>
        <a id="synchronization-barriers" href="#synchronization-barriers"><img src="https://floppy.cafe/media/link.png"></a>Synchronization
        Barriers
      </h2>
      <p>
        Between each track is a synchronization barrier. This barrier is
        surprisingly easy to find because it is just 12 <code>0x0</code> bytes
        followed by 3 <code>0xA1</code> bytes. In terms of pulses, it amounts to
        to 96 short pulses followed by the sequence of pulses <code>MLMLMSLMLMSLMLM</code>.
        You may have trouble reading all 96 pulses because of timing. A common
        practice is to seek for at least 80 pulses instead.
        This will give you a bit more resilience.
      </p>
      <h2>
        <a id="sector-metadata" href="#sector-metadata"><img src="https://floppy.cafe/media/link.png"></a>Sector Metadata
      </h2>
      <p>
        Each sector is comprised of some metadata to describe it. The metadata
        is formatted like so:
        </p><ul>
          <li>12 bytes of <b>0x0</b></li>
          <li>3 bytes of <b>0xA1</b></li>
          <li>One byte of <b>0xFE</b></li>
          <li>One byte to indicate the track number</li>
          <li>One byte to indicate the side (or head)</li>
          <li>One byte to indicate thes sector number</li>
          <li>One byte to indicate the sector size</li>
          <li>2 bytes of CRC (cyclic redundancy code) computed from the sector
            metadata</li>
          <li>22 bytes of <b>0x4E</b></li>
          <li>12 bytes of <b>0x0</b></li>
          <li>3 bytes of <b>0xA1</b></li>
          <li>1 byte of either <b>0xFA</b> or <b>0xFB</b></li>
          <li>512 bytes of user data</li>
          <li>2 bytes of CRC computed from the user data</li>
          <li>Unspecified amount of <b>0x4E</b> bytes filling in the remaining
            space between sectors</li>
        </ul>
      
      <p>
        Upon careful inspection, we can see there are actually two
        synchronization barriers. One to find the sector metadata, and another
        to find the userspace data.
        The only difference is the byte that follows. For sectors, the immediate
        byte after the barrier is <b>0xFE</b>. For userspace data, it's either
        <b>0xFA</b> or <b>0xFB</b>.
        This is how we can determine which kind of barrier we've run into.
      </p>
      <h2>
        <a id="track-metadata" href="#track-metadata"><img src="https://floppy.cafe/media/link.png"></a>Track Metadata
      </h2>
      <p>
        Each track also has its own set of metadata which is formatted like so:
        </p><ul>
          <li>80 bytes of <b>0x4E</b></li>
          <li>12 bytes of <b>0x00</b></li>
          <li>3 bytes of <b>0xC3</b></li>
          <li>One byte of <b>0xFC</b></li>
          <li>50 bytes of <b>0x4E</b></li>
        </ul>
      
      <h2>
        <a id="further-reading" href="#further-reading"><img src="https://floppy.cafe/media/link.png"></a>Further Reading
      </h2>
      <p>
        Here is a comprehensive list of additional resources:
        </p><ul>
          <li><a href="https://floppy.cafe/resources/SAMSUNG-SFD321B-070103.pdf" target="_blank" rel="noreferrer">SFD321B-070103.pdf</a></li>
          <li><a href="http://philipstorr.id.au/pcbook/book4/floppyd.htm" target="_blank" rel="noreferrer">Floppy Disk Formats</a></li>
          <li><a href="http://www.interfacebus.com/PC_Floppy_Drive_PinOut.html" target="_blank" rel="noreferrer">Floppy Drive PinOut</a></li>
          <li><a href="https://www.5volts.ch/posts/mfmreader/" target="_blank" rel="noreferrer">MFM Reader</a></li>
          <li><a href="https://github.com/SharpCoder/floppy-driver-rs" target="_blank" rel="noreferrer">(github) Floppy Driver RS</a></li>
          <li><a href="https://github.com/adafruit/Adafruit_Floppy/tree/main" target="_blank" rel="noreferrer">(github) Adafruit Floppy Reader</a></li>
          <li><a href="https://github.com/dhansel/ArduinoFDC" target="_blank" rel="noreferrer">(github) Arduino FDC</a></li>
        </ul>
      
      <p>
        Next, let's check out <a href="https://floppy.cafe/mfm.html">MFM ENCODING</a> to learn more
        about how data is stored.
      </p>
    </div></div>]]></description>
        </item>
    </channel>
</rss>