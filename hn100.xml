<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 14 Oct 2023 10:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[How to cook ground meat perfectly without vision (238 pts)]]></title>
            <link>https://theblindkitchen.com/how-to-cook-ground-meat-perfectly-every-time/</link>
            <guid>37876988</guid>
            <pubDate>Sat, 14 Oct 2023 00:19:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theblindkitchen.com/how-to-cook-ground-meat-perfectly-every-time/">https://theblindkitchen.com/how-to-cook-ground-meat-perfectly-every-time/</a>, See on <a href="https://news.ycombinator.com/item?id=37876988">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-1860">

	<!-- .entry-header -->

	<div>
		
<p>Cooking ground meats to be sure they are fully cooked and not overcooked can be tricky for a blind or visually impaired person. Here are a few steps to make sure ground meat is cooked perfectly every time. </p>



<p>Some common recipes that call for ground meet to be browned are tacos, chilis, and sausage gravy. If you are browning ground beef, it generally contains enough fat that no more needs to be added. If cooking ground chicken, turkey or pork or lean ground beef, adding fat to the pan is important to be sure the meat does not stick to the pan as it cooks. Most recipes do <strong>not</strong> call for crusty meat crumbles. For each pound of ground meat, I add one tablespoon&nbsp;(<a href="https://theblindkitchen.com/product/auto-measure-spout/">Auto Measure Spout</a>) of plant oil, such as vegetable oil or olive oil. The oil will not affect the finished taste of the meat, so a less expensive oil is fine.</p>



<h2>Cooking steps</h2>



<h3>Step 1:</h3>



<p>Add the oil to the bottom of a cold pan if your meat requires added fat to cook nicely.&nbsp; Use a paper towel to spread a thin layer of oil all over the bottom of the cold pan.&nbsp;</p>



<p>It will be helpful to use a flat-bottom, high-sided saute pan.&nbsp;I like a pan with at least 3-inch walls, straight not sloped, because it helps keep the food in the pan better than its sloped counterpart where food can travel more easily up the sloped side and find its way out of the pan.</p>



<h3>Step 2:</h3>



<p>For any ground meat you are using, it is important to break up any chunks of meat as you put it into the cold pan.&nbsp;Clumps of meat will take longer to cook and they are more difficult to break up during the cooking process after the pan is hot. You can’t see it and you can’t feel it, so breaking it up before you turn on the heat can avoid this problem.&nbsp; Also, if your ground meat is different sizes, it will cook at different rates with the larger chunks taking more time to cook than the smaller pieces so the little pieces will be overdone before the larger chunks are done. Consistency in size is key.</p>



<hr>



<h4>Assessing the temperature of the meat</h4>



<p>Even with the use of a <a href="https://theblindkitchen.com/product/talking-thermometer/">Talking Thermometer</a>  it is impossible for this task because the pieces are so small. For most recipes that involve the browning of ground meat, such as tacos or chili, the meat will be cooked further as the recipe progresses, so cooking it fully the first pass is less essential even if it is ground chicken or turkey.</p>



<hr>



<h3>Step 3:</h3>



<p>After the meat is evenly distributed in the pan, turn the heat on to medium to allow the pan to heat up quickly. Take a moment while the pan is warming to smell the raw meat and keep it in mind as you continue. The smell of cooked meat is dramatically different than raw meat and you can use your nose to help determine doneness.</p>



<h3>Step 4:</h3>



<p>Choose a utensil to move the hot food around.&nbsp;I use a <a href="https://theblindkitchen.com/product/long-wood-spoon/">Long Wood Spoon</a>, but any heat resistant wood or silicon utensil of your choice is fine. The blind friendly considerations in choosing this tool is to make sure it has a long handle so that the tool is not able to fall down into the bottom of the pan. The other consideration is that the tool should not be made of a material that conducts heat, such as stainless steel. This allows the tool to remain in the pan for the entirety of the cooking process and eliminates the need to move the tool in and out of the pan, reducing the chance of dripping or food waste from moving it in and out of the pan.</p>



<h3>Step 5:</h3>



<p>When you hear the meat start to sizzle turn the heat to medium low. The small pieces will cook quickly and only a slight sizzle is necessary to cook the ground meat thoroughly. If you hear anything louder than a slight sizzle, the heat is too high and the contents of the pan will need to be cooled as quickly as possible. The fastest way to do this is to lift the pan up and off of the heat source until the sound dies down and then it can be placed back on the heat source and can continue to cook using less high heat. Silence is not desirable either, you need to hear a slight constant sizzle to be able to use the timing guide in the next step.</p>



<h3>Step 6:</h3>



<p>A pound of ground meat, at a medium low temperature, will take about 6 to 9 minutes depending on the temperature and thickness of the pan, and the temperature of the meat when it is placed in the pan. Move or stir the meat for about 30 seconds for every minute it cooks so that no morsel of meat is in constant contact with the bottom of the pan for the entire cooking time. Any meat that is not moved will burn or crust in that amount of time. You will be able to smell the cooked meat when it is done. As it will probably be cooked further when making the dish, this timing guide will certainly result in a fully cooked pleasantly textured and colored product.</p>



<h3>Step 7:</h3>



<p>If your meat needs to be drained, I find it is most efficient to leave the cooked meat in the pan off of the heat source. Allow it to cool enough to be touched but not cool enough to allow the cooked animal fat to return to a solid state. Tilt the pan slightly and place a wad of clean paper towels where gravity is pulling the liquid fat to gather and allow the towel to soak up the unwanted fat. This method eliminates the need for a strainer and another greasy dish to clean, the unpleasant task of getting hot meat to fall into the strainer, and the greasy sink that will need to be cleaned after the meat is drained. Effective and efficient!</p>



<p><strong>Note:</strong> If you want to save the grease for another purpose (such as bacon grease) you can use the blind friendly <a href="https://theblindkitchen.com/product/side-strainer/">Side Strainer</a> which easily removes any food particles resulting in “clean” grease that can be stored for use at a later time.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Playing Pokemon Red with Reinforcement Learning (125 pts)]]></title>
            <link>https://github.com/PWhiddy/PokemonRedExperiments</link>
            <guid>37875542</guid>
            <pubDate>Fri, 13 Oct 2023 20:57:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/PWhiddy/PokemonRedExperiments">https://github.com/PWhiddy/PokemonRedExperiments</a>, See on <a href="https://news.ycombinator.com/item?id=37875542">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-pokemon-red-rl" dir="auto"><a href="#pokemon-red-rl">Pokemon Red RL</a></h2>
<a href="https://youtu.be/DcYLT37ImBY" rel="nofollow">
  <img src="https://github.com/PWhiddy/PokemonRedExperiments/raw/master/assets/poke_map.gif?raw=true" data-animated-image="">
</a>
<p dir="auto">Experiments training reinforcement learning agents to play Pokemon Red.
Watch the <a href="https://youtu.be/DcYLT37ImBY" rel="nofollow">Video on Youtube!</a></p>
<a href="https://youtu.be/DcYLT37ImBY" rel="nofollow">
  <img src="https://github.com/PWhiddy/PokemonRedExperiments/raw/master/assets/Pokemon%20YT5%20FFFFinal.jpg?raw=true" width="512">
</a>
<h3 tabindex="-1" id="user-content-running-the-pretrained-model-interactively" dir="auto"><a href="#running-the-pretrained-model-interactively">Running the Pretrained Model Interactively</a></h3>
<ol dir="auto">
<li>Copy your legally obtained Pokemon Red ROM into the base directory. You can find this using google, it should be 1MB. Rename it to <code>PokemonRed.gb</code> if it is not already. The sha1 sum should be <code>ea9bcae617fdf159b045185467ae58b2e4a48b9a</code>, which you can verify by running <code>shasum PokemonRed.gb</code>.</li>
<li>Move into the <code>baselines/</code> directory:<br>
<code>cd baselines</code></li>
<li>Install dependencies:<br>
<code>pip install -r requirements.txt</code><br>
It may be necessary in some cases to separately install the SDL libraries.</li>
<li>Run:<br>
<code>python run_pretrained_interactive.py</code></li>
</ol>
<p dir="auto">Interact with the emulator using the arrow keys and the <code>a</code> and <code>s</code> keys (A and B buttons).<br>
You can pause the AI's input during the game by editing <code>agent_enabled.txt</code></p>
<p dir="auto">Note that the Pokemon.gb file MUST be in the main directory and your current directory MUST be the <code>baselines/</code> directory in order for this to work.</p>
<h3 tabindex="-1" id="user-content-training-the-model" dir="auto"><a href="#training-the-model">Training the Model</a></h3>
<p dir="auto">Note: By default this can use up to ~100G of RAM. You can decrease this by reducing the <code>num_cpu</code> or <code>ep_length</code>, but it may affect the results. Also, the model behavior may become degenerate for up to the first 50 training iterations or so before starting to improve. This could likely be fixed with better hyperparameters but I haven't had the time or resources to sweep these.</p>
<ol dir="auto">
<li>Previous steps 1-3</li>
<li>Run:<br>
<code>python run_baseline_parallel.py</code></li>
</ol>
<h3 tabindex="-1" id="user-content-tracking-training-progress" dir="auto"><a href="#tracking-training-progress">Tracking Training Progress</a></h3>
<p dir="auto">You can view the current state of each emulator, plot basic stats, and compare to previous runs using the <code>VisualizeProgress.ipynb</code> notebook.</p>
<h3 tabindex="-1" id="user-content-extra" dir="auto"><a href="#extra">Extra</a></h3>
<p dir="auto">Map visualization code can be found in <code>visualization/</code> directory.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Extinct goat was cold-blooded (2009) (119 pts)]]></title>
            <link>https://phys.org/news/2009-11-extinct-goat-cold-blooded.html</link>
            <guid>37875396</guid>
            <pubDate>Fri, 13 Oct 2023 20:41:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2009-11-extinct-goat-cold-blooded.html">https://phys.org/news/2009-11-extinct-goat-cold-blooded.html</a>, See on <a href="https://news.ycombinator.com/item?id=37875396">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2009/extinctgoatm.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2009/extinctgoatm.jpg" data-sub-html="Extinct goat Myotragus balearicus. Image: Xavier V&amp;aacute;zquez, via Wikipedia.">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2009/extinctgoatm.jpg" alt="Extinct goat Myotragus balearicus" title="Extinct goat Myotragus balearicus. Image: Xavier V&amp;aacute;zquez, via Wikipedia." width="260" height="194">
             <figcaption>
                Extinct goat Myotragus balearicus. Image: Xavier Vázquez, via Wikipedia.
            </figcaption>        </figure>
    </div>
<p>(PhysOrg.com) -- An extinct goat that lived on a barren Mediterranean island survived for millions of years by reducing in size and by becoming cold-blooded, which has never before been discovered in mammals.

										  
											        </p>
										 
										 											  
<p>The goat, Myotragus balearicus, lived on what is now Majorca, a Spanish island. The island had scarce resources, and there was no way for the goats to leave, and so scientists wondered how they had thrived for so long. A recently published research paper reveals the extinct goat survived by adjusting its growth rate and metabolism to suit the available food, becoming cold-blooded like reptiles.
</p><p>Paleontologists studying fossilized Myotragus bones compared them to bones of reptiles living in the same region at the same time, and found surprising similarities. The bones of warm-blooded animals show uninterrupted fast growth, while the bones of cold-blooded animals have parallel growth lines showing interrupted growth corresponding to growth cycles, rather like the rings seen in tree trunks. Growth and metabolism rates are adjusted to suit the amount of food available, whereas warm-blooded animals require food to be available continuously. The Myotragus bones showed the same interrupted growth as reptiles.
</p><p>Myotragus are the first mammals ever known to have achieved the same flexibility, and hence survivability, as reptiles. They also saved energy by having a brain half the size of hoofed mammals its own size, and its eyes were only a third of the size.
</p><div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2009/extinctgoatw.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2009/extinctgoatw.jpg" data-sub-html="Skeleton of a Myotragus balearicus. Image: Francisco Valverde, via Wikipedia">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2009/extinctgoatw.jpg" alt="Extinct goat was cold-blooded " title="Skeleton of a Myotragus balearicus. Image: Francisco Valverde, via Wikipedia">
             <figcaption>
                Skeleton of a Myotragus balearicus. Image: Francisco Valverde, via Wikipedia
            </figcaption>        </figure>
    </div>

<p>The adult goats stood around 18 inches (45 cm) high, and the kids were around the size of a large rat. Reaching adulthood would have taken many years. Paleobiologist Meike Kohler of the Autonomous University of Barcelona, said the goats would have moved slowly to conserve energy, and probably spent a lot of time lying around basking in the sun. The postcranial skeleton suggested the <a href="https://phys.org/tags/goat/" rel="tag">goat</a> could not jump, run or move fast, which made it easy prey.
</p><p>Myotragus survived on the island as dwarf cold-blooded animals for millenia because they had no natural enemies, but they could not survive the predation of humans when they arrived on the island about 3,000 years ago. In total, the species inhabited the island for over five million years.
</p><p>The paper was published online this week in the <i>Proceedings of the National Academy of Sciences</i>.
</p><p><u>More information:</u> Physiological and life history strategies of a fossil large mammal in a resource-limited environment, <i>PNAS</i>, Published online before print November 16, 2009, <a href="http://dx.doi.org/10.1073/pnas.0813385106" target="_blank">doi: 10.1073/pnas.0813385106</a>
</p><p><i>© 2009 PhysOrg.com</i>
										 																				
																					
																				                                        
										<!-- print only -->
										</p><div>
											 <p><strong>Citation</strong>:
												Extinct goat was cold-blooded  (2009, November 18)
												retrieved 14 October 2023
												from https://phys.org/news/2009-11-extinct-goat-cold-blooded.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TimeGPT-1 (356 pts)]]></title>
            <link>https://arxiv.org/abs/2310.03589</link>
            <guid>37874891</guid>
            <pubDate>Fri, 13 Oct 2023 19:58:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2310.03589">https://arxiv.org/abs/2310.03589</a>, See on <a href="https://news.ycombinator.com/item?id=37874891">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    <h2><span>Title:</span>TimeGPT-1</h2>
                
    <p><a href="https://arxiv.org/pdf/2310.03589.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>In this paper, we introduce TimeGPT, the first foundation model for time series, capable of generating accurate predictions for diverse datasets not seen during training. We evaluate our pre-trained model against established statistical, machine learning, and deep learning methods, demonstrating that TimeGPT zero-shot inference excels in performance, efficiency, and simplicity. Our study provides compelling evidence that insights from other domains of artificial intelligence can be effectively applied to time series analysis. We conclude that large-scale time series models offer an exciting opportunity to democratize access to precise predictions and reduce uncertainty by leveraging the capabilities of contemporary advancements in deep learning.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Federico Garza [<a href="https://arxiv.org/show-email/0d01efea/2310.03589">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 5 Oct 2023 15:14:00 UTC (6,795 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Histotripsy – a technique that harnesses soundwaves to attack cancer (140 pts)]]></title>
            <link>https://news.engin.umich.edu/2023/10/these-bubbles-kill-cancer/</link>
            <guid>37874587</guid>
            <pubDate>Fri, 13 Oct 2023 19:33:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.engin.umich.edu/2023/10/these-bubbles-kill-cancer/">https://news.engin.umich.edu/2023/10/these-bubbles-kill-cancer/</a>, See on <a href="https://news.ycombinator.com/item?id=37874587">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div><p>It’s called histotripsy. And it could change cancer treatment forever. </p>



</div>


<p><time datetime="2023-10-06T17:16:46-04:00">October 6, 2023</time></p>


<p>By the time Carrie Kumpel and her husband, Albert, touched down at Detroit Metro Airport in May 2022, her body had already endured more than five years of the push and pull, short highs and long lows of sustained cancer treatment.</p>







<p>Various tumors had come and gone and come again over that stretch—in her bones, her lymph system and, persistently, in her liver. Each brought its own treatment regimen—hormones, chemotherapy drugs, radioactive pills—with different side effects and corresponding shifts in her quality of life.</p>



<p>Despite it all, the Bakersfield, California resident was a stage IV cancer patient—one who had already lost so much. The high school English teacher’s natural hair had gone, along with her ability to bear children.</p>



<p>“You learn to do your living between scans,” said Carrie, 40. “But here I am, six years after diagnosis, which is pretty lucky.”</p>



<p>On this day, the couple headed west from the airport to Ann Arbor and the University of Michigan’s Rogel Cancer Center. Carrie had agreed to participate in human trials for a new treatment called “histotripsy”— a technique created by U-M engineers and doctors that harnesses soundwaves to attack cancer. It comes with the promise of few, if any side effects, a quick treatment time and, for Carrie, the hope that it would completely destroy three spots that had formed on her liver.</p>



<figure><p>
<iframe title="Histotripsy: Fighting Cancer with Bubbles" width="500" height="281" src="https://www.youtube.com/embed/TOkWKl_zIjY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p></figure>



<p>Her doctors put her under anesthesia for the procedure in order to keep her body still and her breathing normal. While Carrie was asleep, the medical team began by moving an ultrasound probe across her abdomen, over the liver tumor within, to identify the precise location of the targets.</p>



<p>As she continued to sleep, a larger ultrasound transducer attached to a robotic arm took its turn hovering over the targeted spot on Carrie’s abdomen, delivering sound waves toward the cancerous lesion below. No incisions, no medicines, no scar tissue and no radiation.&nbsp;</p>



<p>When she woke up a short time later, there was nothing to indicate that any treatment had taken place.</p>



<p>“I really didn’t have any residual sickness or pain,” she recalled in July 2023. “I felt fantastic the next day. A day or two after the procedure, I was able to go visit the Henry Ford Museum.”</p>



<p>One month later, an MRI showed what Carrie and Albert had hoped for: The targeted mass had been eliminated by histotripsy. One simple procedure in one afternoon.</p>



<figure><img data-lazy-fallback="1" decoding="async" fetchpriority="high" width="1024" height="616" src="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-1024x616.jpg" alt="A woman smiles while petting her chocolate lab in a park on a sunny day" srcset="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-1024x616.jpg 1024w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-300x181.jpg 300w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-768x462.jpg 768w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-1296x780.jpg 1296w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-1030x620.jpg 1030w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-120x72.jpg 120w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-500x301.jpg 500w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-800x482.jpg 800w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-1280x770.jpg 1280w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5.jpg 1344w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-1024x616.jpg 1024w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-300x181.jpg 300w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-768x462.jpg 768w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-1296x780.jpg 1296w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-1030x620.jpg 1030w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-120x72.jpg 120w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-500x301.jpg 500w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-800x482.jpg 800w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-1280x770.jpg 1280w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5.jpg 1344w" data-lazy-src="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content5-1024x616.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Carrie Kumpel spends some quality time with her dog, Lottie, in Bakersfield, Calif. in August 2023. Photo: Jeremy Little/Michigan Engineering</figcaption></figure>



<p>Her treatment was part of human trials in the United States and Europe which, in recent years, have helped bolster histotripsy’s case with regulators at the U.S. Food and Drug Administration (FDA). The results show histotripsy delivering on its promise—destroying tumors with few, if any, side effects.&nbsp;</p>



<p>A private company, HistoSonics, was co-founded in 2009 by U-M engineers and doctors to commercialize the technology. On the strength of the initial human trial results, <a href="https://news.engin.umich.edu/2023/10/tumor-destroying-soundwaves-receive-fda-approval-for-liver-treatment-in-humans/">the company received formal approval from the FDA in October</a> to market histotripsy for liver treatments in humans.</p>



<div>
<h3 id="h-the-science-is"><strong>THE SCIENCE IS</strong></h3>



<h3 id="h-sound">SOUND</h3>






<div data-vp-layout="slider" data-vp-content-source="images" data-vp-items-style="default" data-vp-items-click-action="" data-vp-items-gap="20" data-vp-items-gap-vertical="" data-vp-pagination="paged" data-vp-next-page-url="" data-vp-slider-effect="fade" data-vp-slider-items-height="auto" data-vp-slider-slides-per-view="3" data-vp-slider-speed="0" data-vp-slider-autoplay="0" data-vp-slider-autoplay-hover-pause="false" data-vp-slider-centered-slides="true" data-vp-slider-loop="true" data-vp-slider-free-mode="false" data-vp-slider-free-mode-sticky="false" data-vp-slider-arrows="true" data-vp-slider-bullets="true" data-vp-slider-bullets-dynamic="true" data-vp-slider-mousewheel="false" data-vp-slider-thumbnails="false">
        <p><img data-lazy-fallback="1" decoding="async" loading="eager" src="https://news.engin.umich.edu/wp-content/plugins/visual-portfolio/assets/images/logo-dark.svg" alt="Visual Portfolio, Posts &amp; Image Gallery for WordPress" width="20" height="20" data-skip-lazy="">
        </p>
    </div></div>



<div>
<figure><blockquote><p>The procedure worked as planned, striking and reducing the tumor 95.5% of the time.</p><cite> </cite></blockquote></figure>
</div>



<p>It’s a major step toward bringing the technology into the mainstream. By using soundwaves—the same technology we trust to give us our first peek at new life in the womb—Carrie and other patients could be spared the physical and mental toll that comes with traditional treatments like surgery, chemotherapy and radiation.</p>



<h2 id="deadly-toll">Cancer’s deadly toll</h2>



<p>Worldwide, roughly 10 million people die from cancer each year. In the United States alone, an estimated two million will be diagnosed with cancer in 2023. Another 609,000 Americans are expected to die from it, keeping cancer the second leading cause of death behind heart failure.&nbsp;</p>



<p>The late Charles Cain (PhD EE ’72), the “father” of histotripsy and a long-time U-M professor of biomedical engineering and electrical engineering and computer science, saw it as “a knife-less surgical approach” that leaves behind “no recognizable tissue fragment.” Cain guided the research at U-M from its humble beginnings to the brink of FDA approval before his passing three years ago.&nbsp;</p>



<p>Much more than knifeless, histotripsy comes with no damage to surrounding tissues, none of the side effects of radiation and surgery and little to no recovery time. It’s the kind of procedure researchers feel can eventually be conducted in a medical office instead of an operating room. As HistoSonics CEO Mike Blue told the BBC earlier this year, “Patients will awake from their procedure and, generally, most times, not know that they were treated.”</p>



<p>Both the inventors of the treatment and the company bringing it to the world have unabashedly high hopes for what histotripsy can become.&nbsp;</p>



<p>“In the long run, I envision histotripsy providing incisionless, non-toxic, painless and low-cost treatment to cancer patients at major hospitals as well as local clinical centers across the world,” said Zhen Xu, a U-M professor of biomedical engineering and an inventor of the histotripsy treatment. “I also hope to see histotripsy used to boost immunotherapy to treat tumor metastases and be extended to treat patients with many other disease types beyond cancer, such as stroke, neurological diseases, cardiovascular diseases and skin diseases.”</p>



<p>Despite gains in reducing deaths, cancer continues to throw curveballs. Late in 2022, an analysis of data from 44 countries showed that diagnoses for more than a dozen types of cancer were on the rise in people under the age of 50.&nbsp;</p>



<p>But histotripsy doesn’t need to understand cancer to be effective. Its reliance on physical force generated by sound means it can ignore questions like what turns normal cells malignant or why certain abnormal cells grow and spread in the body. It’s simply good at killing a killer.</p>



<p>Carrie Kumpel remains a stage IV cancer patient. The questions surrounding her current and future treatments will have more to do with maintaining her condition than curing it.&nbsp;</p>



<p>“If more people had access to this kind of treatment, something that comes with so much less inflammation and damage, I think it would be really amazing,” she said.</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="1024" height="683" src="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-1024x683.jpg" alt="A woman stands at a monitor in a lab pointing to data on the screen" srcset="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-1024x683.jpg 1024w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-300x200.jpg 300w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-768x512.jpg 768w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-1296x864.jpg 1296w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-930x620.jpg 930w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-120x80.jpg 120w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-500x333.jpg 500w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-800x533.jpg 800w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-1280x853.jpg 1280w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4.jpg 1344w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-1024x683.jpg 1024w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-300x200.jpg 300w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-768x512.jpg 768w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-1296x864.jpg 1296w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-930x620.jpg 930w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-120x80.jpg 120w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-500x333.jpg 500w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-800x533.jpg 800w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-1280x853.jpg 1280w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4.jpg 1344w" data-lazy-src="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content4-1024x683.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Zhen Xu conducts a histotripsy treatment demonstration at HistoSonics in Ann Arbor in March 2023. Photo: Erica Bass/Rogel Cancer Center</figcaption></figure>



<h2 id="bubbles-into-weapons">Turning bubbles into weapons</h2>



<p>When you’re a toddler, bubbles have a magic quality about them. Creating clouds of them with bubble soap wands can fascinate for a whole afternoon. And popping them? Even better.</p>



<p>But when you focus them on a cancerous tumor in just the right way, they can become a deadly weapon.&nbsp;</p>



<p>The process uses a transducer—which converts electricity into sound—to deliver ultrasound waves to a malignant mass at a precise location. When the waves hit gasses inside cancerous cells, they generate clouds of tiny bubbles through a process known as cavitation.</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" src="https://news.engin.umich.edu/wp-content/uploads/2023/09/Asset-3@2x-1.png" alt="" width="280" height="394" data-lazy-src="https://news.engin.umich.edu/wp-content/uploads/2023/09/Asset-3@2x-1.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Pulsing sound waves causes the millimeter-sized bubble clouds to repeatedly grow and collapse. On an ultrasound monitor, it can look like bubbles from boiling water—quickly rising and falling along the surface in your pot.&nbsp;</p>



<p>In the past, researchers saw the creation of bubbles through ultrasound as “uncontrollable,” something to be avoided. Histotripsy, however, generates mechanical energy to activate those bubble clouds and break up the tumor cells’ structure, turning it into a liquid called acellular lysate.</p>



<p>“It’s just fluid—the denatured proteins that the body recognizes as foreign material,” said Dr. Mishal Mendiratta-Lala, a U-M professor of radiology who performed Kumpel’s histotripsy procedure. “And unlike other treatments, histotripsy does not destroy all nearby blood vessels. This preserves blood flow in the treatment zone to carry acellular lysate away—essentially removing the dead tumor in the form of this fluid—and the whole area goes back to normal.”</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" src="https://news.engin.umich.edu/wp-content/uploads/2023/09/Asset-1@2x.png" alt="" width="266" height="557" data-lazy-src="https://news.engin.umich.edu/wp-content/uploads/2023/09/Asset-1@2x.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Histotripsy also uses ultrasound to give physicians a detailed look at the cancerous mass before and during treatment. This enables them to map out treatment before it starts and monitor the process while it’s happening. The result is startling accuracy.</p>



<p>The cellular and subcellular destruction caused by histotripsy is limited to the target area. In fact, the target diameter of a histotripsy pulse can be no more than one millimeter. It’s that kind of precision that helps set histotripsy apart from traditional cancer treatments like chemotherapy and radiation—which employ more of a carpet-bomb approach that can damage areas outside the intended tumor.&nbsp;</p>



<p>Human trials of histotripsy treatments for cancer began in 2020 and 2021, when doctors in Europe and the United States began a trial called #HOPE4LIVER. With COVID-19 making every plan uncertain, HistoSonics worked with multiple hospitals and medical schools on both sides of the Atlantic to locate and treat patients. Researchers zeroed in on liver cancer to provide a strong test of the technology.</p>



<p>Liver cancer is particularly tough to treat successfully—the five-year survival rate is less than 20%. Only about 20% of liver cancer patients are eligible for surgery, meaning the majority of those patients don’t have a surgical option.&nbsp;</p>



<p>Locations in Europe and the United States treated 44 different patients with a total of 49 lesions. Several of those patients received their histotripsy at Michigan Medicine. Doctors were able to successfully target tumors in 42 of the 44 patients, with the two “misses’’ attributed to physician error. And the procedure worked as planned, striking and reducing the tumor 95.5% of the time.&nbsp;</p>



<p>Another indicator of human trial success is how many adverse events of any level of severity—from a high temperature to a toothache—crop up among the patient pool in the month following treatment. Only three patients of the group of 44 reported any issues, and all were minor.</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" width="1024" height="683" src="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-1024x683.jpg" alt="A woman sits in a classroom writing lesson plans in a large binder" srcset="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-1024x683.jpg 1024w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-300x200.jpg 300w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-768x512.jpg 768w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-1296x864.jpg 1296w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-930x620.jpg 930w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-120x80.jpg 120w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-500x333.jpg 500w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-800x533.jpg 800w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-1280x853.jpg 1280w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6.jpg 1344w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-1024x683.jpg 1024w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-300x200.jpg 300w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-768x512.jpg 768w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-1296x864.jpg 1296w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-930x620.jpg 930w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-120x80.jpg 120w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-500x333.jpg 500w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-800x533.jpg 800w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-1280x853.jpg 1280w, https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6.jpg 1344w" data-lazy-src="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content6-1024x683.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Carrie Kumpel writes out lesson plans in her classroom in Bakersfield, Calif. in August 2023. Photo: Jeremy Little/Michigan Engineering</figcaption></figure>



<h2 id="outsmarting-cancer">Outsmarting cancer</h2>



<p>Cancer can be sneaky and elusive. Among its most insidious qualities, a trait that drastically hinders the body’s chances of fighting it, is its ability to hide.&nbsp;</p>



<p>Look inside a cancer cell and you’ll find tumor antigens—proteins specific to cancer. When the body’s immune system detects tumor antigens, it responds by attacking the cells. But the body often can’t see through a cancer cell’s outer wall to identify tumor antigens. Star Trek fans might think of those walls as a “cloaking device”—granting cancer the invisibility it needs to grow unchecked without alerting the body’s immune system.</p>



<p>&nbsp;It’s one of the reasons many cancers aren’t detected until after they’ve spread to problem areas in the body and put the host’s life at risk. But histotripsy foils cancer’s cloaking efforts by destroying its cell walls, leaving the tumor antigens in plain sight for the body’s immune system.&nbsp;</p>



<p>This effect was detailed in a pair of papers published by the U-M research team between March 2022 and January 2023. They demonstrate that the sound waves used to break down cancerous tumors in rats also helped trigger the rats’ immune response. After histotripsy destroyed 50% to 75% of liver tumor volume, the rats’ immune systems cleared away the rest, with no evidence of recurrence or metastases in more than 80% of animals.</p>



<p>That immune response occurred throughout the body, not just in areas targeted by the histotripsy treatment, resulting in the reduction of tumors far from the treated area.</p>



<p>With human trials utilizing histotripsy only getting underway in recent years, the data in this area of research is still limited. But it raises the tantalizing possibility that the treatment could be transplantable, according to recent testing in mice.</p>



<p>After breaking up a tumor in one mouse using histotripsy, the team extracted some of the tumor lysate and injected it into another mouse. Both mice developed immune protection from that cancer.</p>



<p>“Injecting the tumor lysate into a second mouse had almost a vaccine-like property,” Xu said. “Mice that received this debris were surprisingly resistant to the growth of cancers.”</p>



<h2 id="better-way-to-treat">A better way to treat</h2>



<p>Carrie Kumpel can rattle off the medications and treatments she’s had over the years—most with bizarre, vowel-intensive names—as if she’s naming family members.&nbsp;</p>



<p>And while she hasn’t always had to endure their worst side effects, none have created the kind of experience she’d want to repeat. But endurance is key for cancer patients because, all too often, traditional treatments can continue for years.</p>



<p>For her early breast cancer treatments there were drugs like Xeloda and Cyclophosphamide, which Carrie described as “pretty awful.” Treatments like Zoledronic acid injections are designed to prevent the spread of breast cancer, but can also cause a host of side effects that patients struggle to deal with.</p>



<p>Then there’s Doxil, which some patients refer to as the “Red Devil,” for its red coloring as well its propensity for causing red urine, hair loss, mouth sores, nausea and vomiting.</p>



<p>Another “favorite” from Carrie’s past is Y90, a liver-specific treatment delivering radioactive beads into blood vessels near malignant lesions. Patients are usually instructed to avoid strenuous activity for ten days following insertion, and it can take up to three weeks to return to normal function.</p>



<p>“I’ve been in constant treatment for five-plus years—even when I don’t have new cancer popping up,” she said. “Even when I don’t have anything active, it’s required for me to still be in some kind of chemo because that’s the way they do it.”</p>



<div>
<figure><blockquote><p>I envision histotripsy providing incisionless, non-toxic, pain­less and low-cost treatment to cancer patients.</p><cite> </cite></blockquote></figure>
</div>



<p>According to the American Cancer Society, cancer patients deal with a wide range of side effects depending on the treatment.</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" src="https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-1024x683.jpg" alt="Two researchers adjust a complex looking device with many rows and columns of wires" width="612" height="408" srcset="https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-1024x683.jpg 1024w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-300x200.jpg 300w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-768x512.jpg 768w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-1296x864.jpg 1296w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-930x620.jpg 930w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-120x80.jpg 120w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-500x333.jpg 500w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-800x533.jpg 800w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-1280x853.jpg 1280w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1.jpg 1344w" sizes="(max-width: 612px) 100vw, 612px" data-lazy-srcset="https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-1024x683.jpg 1024w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-300x200.jpg 300w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-768x512.jpg 768w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-1296x864.jpg 1296w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-930x620.jpg 930w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-120x80.jpg 120w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-500x333.jpg 500w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-800x533.jpg 800w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-1280x853.jpg 1280w, https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1.jpg 1344w" data-lazy-src="https://news.engin.umich.edu/wp-content/uploads/2023/09/HistoFeature1-1024x683.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Zhen Xu, (left) and biomedical engineering PhD student Tejaswi Worlikar discuss the 700kHz, 260-element histotripsy ultrasound array transducer they use in Xu’s lab. Photo: Marcin Szczepanski/Michigan Engineering</figcaption></figure>



<p>Chemotherapy can cause chemo brain (impacting concentration and focus), nausea and vomiting, nerve problems, fertility issues, hair loss, bladder issues, kidney problems, changes in libido and sexual function and others.</p>



<p>Radiation directed at different parts of the body can bring different impacts. The scope of side effects include: nausea, earaches, tooth decay, hair loss, loss of appetite, bladder problems and fertility problems.</p>



<p>Surgery’s impacts include pain, extended recovery times, swelling, drainage, fatigue, appetite loss, infection and others.</p>



<p>These traditional treatment options, along with their physical and mental costs, are what histotripsy seeks to replace. The pending FDA approval would clear the way for liver treatments specifically.</p>



<p>With continued success, HistoSonics officials hope the technology will also be approved for other treatments, from brain tumors to heart blockages.</p>



<h2 id="breakthrough">The breakthrough</h2>



<p>In the span of a few hours over one afternoon in the lab on North Campus, weeks spent scouring slaughterhouses for pig parts suddenly seemed to pay off. At least that’s what Xu hoped as she walked, porcine heart in hand, down the short corridor from the lab to Charles Cain’s office. The heart had three fresh holes in it, the result of what might be considered the first successful test of histotripsy in the lab.&nbsp;</p>



<p>This was in late April of 2002. Xu had spent weeks working in the North Campus lab, trying out new combinations of amplitudes and frequencies to elicit the destruction of small sections of the pig heart, which was standing in for human tissue.</p>



<p>Xu had become all too familiar with the art of acquiring animal organs for these experiments. The team’s early work was focused on congenital heart disease so, each week, she would visit a slaughterhouse 15 miles south in Milan, Michigan in search of pig hearts to test.&nbsp;</p>



<p>“The first time there, the man showed me a trash can filled with pig parts and said ‘See what you want, go ahead and get it,’” Xu recalled. “It didn’t smell so good since there were intestines and other things in the can. It was quite bloody. Now, in some cases, they would have cut through the hearts, so I’d search through them looking for ones that weren’t quite as damaged. Back then, we could get two, maybe three pig hearts for $5.”</p>



<p>For Xu, there was nothing off-putting about this part of her job; she grew up in Nanjing, China and her father worked on a farm for a time. She would cut the hearts into smaller sections and fix one of those sections inside a water tank as the experiment’s stand-in for heart tissue.&nbsp;</p>



<p>Water played the role of healthy tissue surrounding the heart, since ultrasound waves won’t propagate through the air. Next, Xu lined up an ultrasound transducer, which turns electricity into ultrasound waves.&nbsp;</p>



<p>Xu had little experience with ultrasound when she hired on with Cain’s team as a PhD student research assistant. In fact, her lack of experience was a selling point for the man who would become her mentor. He wanted someone who wasn’t constrained by previous research in any way.</p>



<p>As a result, that day in 2001, Xu decided to try something new—hooking her transducer up to an amplifier that no one else seemed to be using because it was too loud. A lab partner quickly reaffirmed that the machine was, indeed, too loud. So Xu began operating it in the 20 kilohertz pulse repetition range, right above the range of human hearing, with a camera capturing the action.</p>



<p>She fired micropulses of soundwaves—super-short bursts—at amplitudes much higher than normal. She figured those bursts would make any noises less likely to draw the ire of coworkers.</p>



<p>After dozens of previous attempts with different parameters, Xu wasn’t expecting fireworks. But after a short time, she noticed a hole had appeared in the pig heart.</p>



<p>“My initial reaction was ‘Is that real?’” she recalled. “Then my mind immediately shifted to ‘Can I repeat that? If I can’t repeat it, it’s not real.’”</p>



<p>Two more successful tries, and Xu was off down the hallway with her prized pig heart section to share what happened.</p>



<p>“We found that ultrasound somehow generated those holes,” she said. “Then we spent the next ten years trying to discover how it worked.”</p>



<h2 id="father-of-histotripsy">The “father” of histotripsy</h2>



<p>Everyone seemed to take something different away from their time with Charles Cain.</p>



<p>In the early aughts, students posting anonymously on the Rate My Professors website noted that Charles Cain “looks like Santa Claus,” and that he “teaches from notes that are so old, they are yellow.”</p>



<figure><img data-lazy-fallback="1" decoding="async" loading="lazy" src="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content7-1024x574.jpg" alt="A man with a white hair and a beard smiles in a yellow sweater" width="612" height="385" data-lazy-src="https://news.engin.umich.edu/wp-content/uploads/2023/09/Histo-content7-1024x574.jpg?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Charles Cain in 2016. Photo: Jesse Meria</figcaption></figure>



<p>Michigan Engineering leaders focused on more relevant aspects like Cain’s leadership. In 1996, they tapped him to be the first chair of the newly-created Department of Biomedical Engineering.&nbsp;</p>



<p>Today, fellow researchers speak of his focus—a tunnel vision in his work that was both admirable and productive, but also capable of coming across as gruff and uncompromising.&nbsp;</p>



<p>Tim Hall’s office displays his fondness for Cain through a handful of Easter eggs—a nameplate on a shelf and a copy of Cain’s PhD dissertation nearby. One of the founders of HistoSonics, Hall (BSE ECE ’98, MSE ’01, PhD BME ’07) is a U-M research scientist in biomedical engineering who worked with Cain for decades.</p>



<p>“Some of the adjectives I’d use to describe him are ‘maverick,’ I think that’s a good term,” Hall said “He was definitely a fierce advocate.” Then, jokingly: “He loved to argue and discuss ideas. Or, at least, his ideas.”</p>



<p>Born in Tampa, Florida and raised in Miami, Cain earned his bachelor’s degree from the University of Florida, his master’s from MIT and his PhD from U-M, all in electrical engineering. He titled his 1972 PhD thesis “A Control Systems Study of the Human Oculomotor Predictive Tracking Mechanism.”</p>



<p>Before earning his PhD, Cain worked at Bell Laboratories in Naperville, Illinois, focusing on solid-state electronic switching systems. From 1972 to 1989, he was a professor of electrical and biomedical engineering at the University of Illinois at Urbana-Champaign.</p>



<p>There he worked with Bill and Frank Fry, brothers who helped pioneer the use of ultrasound in medical diagnostics and surgery, with a particular focus on the brain. Cain brought his expertise in ultrasound technologies to U-M in 1989.</p>



<div>
<figure><blockquote><p>He had a tender, tender heart that I think only those closest to him saw.</p><cite> </cite></blockquote></figure>
</div>



<p>When Hall began working with the team in the late 1990s, Cain had been focused on treating tissues in the heart with the heat generated by ultrasound.&nbsp;</p>



<p>“By 2000, Charles had mostly given up on that technology,” Hall said. “He had some students who had used modeling to show that it wasn’t a practical approach for many reasons. So, he latched on to the idea that we could use cavitation to break some of these barriers that the physics of thermal ablation were imposing on it.&nbsp;</p>



<p>“The effects of cavitation had been noted back in the 1960s and 1970s—that they could accompany thermalization when the ultrasound power was very high. But at the time, cavitation was a little bit unpredictable.”</p>



<p>The quest to find the right way to control cavitation would prove difficult. But Cain’s focus and drive remained constant. As Xu wrote in memoriam: “Charles was born to be a scientist and educator. He only wanted to work on new concepts and despised being a follower … [He] was an excellent and caring mentor to his students and junior faculty, many of whom have become leaders in their fields. Charles was a visionary, a fearless leader and a force to be reckoned with.”</p>



<p>Where Cain’s research focus and drive came across as off-putting to some, Li Wu saw something different.</p>



<p>“He had a tender, tender heart that I think only those closest to him saw,” said Wu, who met Cain in 2006 when she was working at Siemens in Ann Arbor. She held a master’s degree in computer science which led to deep conversations—talks that gave her a peek behind Cain’s outer persona.&nbsp;</p>



<p>Their friendship evolved into more, with a wedding in 2008 followed by a decade and a half together. In the last three of those years, the couple dealt with Cain’s progressing prostate cancer. He passed away March 27, 2020 at the age of 77, survived by Wu, three sons from a previous marriage and two grandchildren. But he lived to see histotripsy begin to have the practical impact he’d always hoped for.</p>



<p>“He would be very, very happy to see the technology now being used on helping patients,” Wu said. “That was truly always his goal. He wanted to do research that had some impact for people in the world.”</p>



<h2 id="company">The company</h2>



<p>Dinner and drinks at the Carlyle Grill off Jackson Road on Ann Arbor’s west side. That’s how the founding team of U-M engineers and doctors celebrated the creation of HistoSonics in 2009.&nbsp;</p>



<p>It was a small moment of victory, reached with early support from the U-M Coulter Translational Research Partnership Program, which specializes in helping researchers develop and commercialize healthcare products. The program connected the histotripsy team with early consulting help and followed up with $300,000 in funding for early testing.&nbsp;</p>



<p>Later in the company’s timeline, U-M’s Innovation Partnerships provided intellectual property support.</p>



<p>Since those earliest days, HistoSonics has set up its corporate headquarters in Minneapolis and bolstered its leadership with board members that represent healthcare heavyweights like Johnson &amp; Johnson, Varian Medical Systems (now part of Siemens) and Lumira Ventures.</p>



<p>Yet the connection with U-M and Ann Arbor remains strong. The company founders remain shareholders and, in some cases, continue to serve as consultants. Most of HistoSonic’s research and development work takes place in offices and labs on Liberty Avenue, not far from where the celebratory dinner took place.&nbsp;</p>



<p>The company recently entered into a contract to renovate and inhabit new office and research space on Oak Valley Drive on the city’s south side. The 25,000-square foot facility is expected to open in 2024 with 50 employees, and the company plans to eventually employ 70 at the site.</p>



<p>Jon Cannata is HistoSonics’ director of research and advanced development. He has his own U-M connection through his wife, Laura Cannata (BA Psychology, BA Spanish ’88).&nbsp;</p>



<p>“Even to this day, the way we’ve set ourselves up being very close to the University of Michigan and our team here, it’s very synergistic,” Cannata said. “They’re working on things that are advancing the science, doing their own research and development to develop the technology that could become our next product.”</p>



<div>
<figure><blockquote><p>I’m not sure I ever thought I’d have the opportunity to work on something that’s truly a medical frontier.</p><cite> </cite></blockquote></figure>
</div>



<p>Thai-Son Nguyen (BSE BME ’16, MS ’18) is a member of that team—a man doing a job he feels he’s been uniquely prepared for in his 34 years. Since his earliest days, he has battled a variety of health issues, requiring multiple surgeries and a drastically restricted diet.</p>



<p>Nguyen entered Michigan Engineering in 2007 as an undergraduate, but didn’t earn his bachelor’s degree until 2016 due to pauses in his studies caused by his medical conditions. A master’s degree in biomedical engineering followed two years later.</p>



<p>“Even now as an adult, I have issues,” he said. “But it was because of all of the work that has gone into science and medicine that my doctors were able to diagnose those issues and come up with the treatments and lifestyle adjustments that have allowed me to be where I am now.”</p>



<p>Nguyen would like his work to do something equally positive for other people. He is one of roughly a dozen U-M alumni or students currently working at HistoSonics. And, for him, it’s the best place to be at the best possible time.</p>



<p>“What we’re doing here is great,” Nguyen said. “During college, I’m not sure I ever thought I’d have the opportunity to work on something that’s truly a medical frontier—something so novel like this.”</p>












</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Removal of Mazda Connected Services integration (228 pts)]]></title>
            <link>https://www.home-assistant.io/blog/2023/10/13/removal-of-mazda-connected-services-integration/</link>
            <guid>37874220</guid>
            <pubDate>Fri, 13 Oct 2023 19:02:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.home-assistant.io/blog/2023/10/13/removal-of-mazda-connected-services-integration/">https://www.home-assistant.io/blog/2023/10/13/removal-of-mazda-connected-services-integration/</a>, See on <a href="https://news.ycombinator.com/item?id=37874220">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<article>
<header>


</header>
<p>On October 11, 2023, we were informed that an open-source contributor received a cease and desist letter from Mazda North American Operations (Mazda) regarding his library to connect with Mazda services. This library was used by the Home Assistant integration Mazda Connected Services, which he also maintained. A <a href="https://github.com/github/dmca/blob/master/2023/10/2023-10-10-mazda.md" rel="external nofollow">DMCA notice</a> was sent to GitHub requesting the removal of all code and forked repositories as well.</p>
<p>The contributor has complied with the cease and desist letter. The library is no longer available, and the Mazda Connected Services integration has been removed from Home Assistant in the 2023.10.2 patch release of Home Assistant released on October 12, 2023.</p>
<p>Home Assistant is disappointed that Mazda has decided to take this position. We’re also sad that Mazda’s first recourse was not to reach out to us and the maintainer but to send a cease and desist letter instead.</p>
<p>We invite Mazda to speak with us about this topic. We would love to have an open and constructive discussion about the potential that a Home Assistant integration has for them and their customers. We genuinely believe there is a common ground between us and Mazda when it comes to enabling the owners of their cars to explore the possibilities of their own data.</p>
<p>After all, other car manufacturers do see this potential. For example, Tesla has recently released <a href="https://developer.tesla.com/docs/fleet-api" rel="external nofollow">official API documentation</a> to support third-party apps. Volkswagen Group’s Audi brand has <a href="https://cariad.technology/de/en/news/stories/launch-application-store-for-volkswagen-group.html" rel="external nofollow">launched an app store in their cars</a> that features the Home Assistant app. We hope Mazda will see this potential, as well.</p>
</article>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["Hallucinating" AIs sound creative, but let's not celebrate being wrong (133 pts)]]></title>
            <link>https://thereader.mitpress.mit.edu/hallucinating-ais-sound-creative-but-lets-not-celebrate-being-wrong/</link>
            <guid>37874174</guid>
            <pubDate>Fri, 13 Oct 2023 18:58:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thereader.mitpress.mit.edu/hallucinating-ais-sound-creative-but-lets-not-celebrate-being-wrong/">https://thereader.mitpress.mit.edu/hallucinating-ais-sound-creative-but-lets-not-celebrate-being-wrong/</a>, See on <a href="https://news.ycombinator.com/item?id=37874174">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>The term “hallucination,” which has been widely adopted to describe large language models (LLMs) outputting false information, is misleading. Its application to creativity risks compounding that.</p><figure><img width="700" height="420" src="https://thereader.mitpress.mit.edu/wp-content/uploads/2023/10/ai-lead-700x420.jpg" alt="" decoding="async" fetchpriority="high"><figcaption>Image source: Google DeepMind, <a href="https://unsplash.com/@googledeepmind">via Unsplash</a></figcaption></figure><p>When Sam Altman, OpenAI’s CEO, recently claimed that hallucinations were <a href="https://www.marketwatch.com/story/openais-sam-altman-tells-salesforces-marc-benioff-that-ai-hallucinations-are-more-feature-than-bug-1c035c52" target="_blank" rel="nofollow">actually a good thing</a>, because in fact GPT’s strength lies in its creativity, some observers might have raised an eyebrow: We humans are rather good at creativity without getting our facts all wrong. How could such an appeal to creativity make a decent counter to the many concerns about accuracy?</p><p>To begin, what do people mean when they say an AI system “hallucinates”? Take this example of what happens when GPT4 tries its hand at academic citations:</p><blockquote><p><strong>Me</strong>: <br>Can you complete the title of the paper by Keith L Downing written in 2004, “Development and the …”</p><p><strong>GPT4</strong>:<br>Yes, the complete title of Keith L. Downing’s paper written in 2004 is “Development and the Baldwin Effect: Evolution by Any Other Name?” This paper delves into the Baldwin Effect and its implications for understanding evolution and development.</p></blockquote><p>The part of the title “Evolution by Any Other Name?” is made up. As it happens, that is the title of another academic paper on “alternative models of biological evolution,” and so is very relevant, but very definitely wrong.</p><p>When people say GPT is hallucinating, they are referring to this kind of mangling of facts. But the idea of hallucination implies that at other times the facts have been accurately portrayed. Unfortunately, this promotes a misunderstanding of how large language models (LLMs) work, and misunderstanding how a technology works can make the difference between it being safe and dangerous. It might be better to say that <em>everything GPT does is a hallucination</em>, since a state of non-hallucination, of checking the validity of something against some external perception, is absent from these models. There is no right or wrong answer in their world, no meaning relating to goals.</p><p>That’s because LLMs are not models of brains, but of <em>language itself</em>, its patterns, structures, and probabilities. At heart their job description is incredibly simple: Given some text, they tell us what text comes next. It’s worth keeping front and center, however, that there is not always one right response. If I say “the tail that wags the …”, you might say the next word is “dog” with a high degree of certainty, but this is not the right and only answer. In any such context, there is much freedom, and the “rightness” of any answer depends not only on the conceptual context but on what you’re trying to do — your goal.</p><figure><blockquote><p>There is no right or wrong answer in their world, no meaning relating to goals.</p></blockquote></figure><p>As we barrel into the AI age, the issue of the accuracy of LLMs has triggered mild concern in some quarters, alarm in others, and amusement elsewhere. In one sense Altman was rightly deflecting interest away from any claim that GPT can convey accurate information at all. In another sense, he was layering one misconception with another in the implication that hallucination is key to creative capability. But since he mentioned it, what of GPT’s creative prowess?</p><p>It is certainly clear that a large part of the uptake of GPT has been for creative tasks, so what makes something creatively productive, and does this need to be at the expense of facts? Huge amounts of effort have been put into understanding how humans do creative things, and, as an important corollary, dispelling myths about creativity. This vast literature is reasonably unanimous about one crucial property of human creative cognition: that it involves the performance of a sort of search. As the creativity researcher Teresa Amabile most eloquently justifies, creative problems are <em>by their definition</em> those for which there is not a known solution, and by extension, necessitate “heuristic methods” for seeking those solutions where no “algorithmic” method will suffice. Aligning with the psychologist <a href="https://psycnet.apa.org/record/2022-55349-001" target="_blank" rel="nofollow">Dean Simonton</a>, I believe this is well condensed into the idea of “blind search”, noting that “blind” does not mean “random.” Think of a radar scanning space; it moves systematically in a circle, traversing all possible points, but is nevertheless <em>blind </em>in its searching. In cognitive terms, blind search also necessitates evaluation, knowing what we’re looking for.</p><p>Several theoretical approaches to the psychology of creativity share the idea that human brains exhibit a capacity to perform a structured, distributed search, farming out a sort of idea generation, perhaps to subconscious modules, which are then evaluated more centrally.</p><p>But this is not only a process that happens inside brains: We do it collectively too. For example, the method of brainstorming was systematically developed to support divergent thinking, making overt recognized strategies for creative collaboration, and again identifying that heuristic methods of search are powerful for creative success. In a brainstorming session, each participant acts like one of those little, simple generative modules; two of the key brainstorming rules are to delay judgment, and to go for quantity over quality. Evaluation happens later in brainstorming, the point being that sometimes it closes our minds to fruitful possibilities.</p><p>That’s not to say there is no more to effective creativity than that: Both individual and social forms of creativity have many other important dimensions — mastery of a subject, the ability to learn from others, the ability to conceptually represent problems, and all the peripheral work that brings creative ideas to fruition.</p><p>But thinking about the sorts of structures that may support heuristic, distributed search helps us focus on effective architectures for creativity, above all recognizing that in simplest terms even the creativity of a single human being arises from the interaction between types of cognitive processes that <em>generate</em> and that <em>evaluate</em>.</p><p><a href="https://mitpress.mit.edu/9780262045018/beyond-the-creative-species/" target="_blank">I’ve argued</a> that we might even tease out two flavors of the creative process altogether, specifically to help us understand how machines can play creative roles. “Adaptive” creativity is the behavior we typically associate with human intelligence. It is the full, integrated package of generation and evaluation. Meanwhile, a less discernible “generative” creative process is all around us. It is sometimes haphazard, sometimes more structured, but generally goalless. Within human brains, it might take the form of subconscious streams whirring away. But it even exists where there is no overt evaluation to speak of, just generating stuff, as in the basic goalless mechanism of evolution by natural selection (being mindful that “biological fitness” is not a goal but an outcome of evolutionary processes).</p><p>While classic “hero” stories of creativity concern the neatly bounded adaptive variety — this is the central myth of creativity — the wild generative form is actually more prevalent: accidental scientific discoveries, musical styles that arise from the quirks of a successful performer, solutions in search of a problem.</p><p>This is a very loose sketch, but it helps us immensely if we come back to thinking of GPT as a creative tool. Is it a good generator, a good evaluator, and can it put everything together into an adaptively creative package? GPT can superficially do a great job at both generation and evaluation; spawn some new ideas in response to a request, or critique something we input. We actually know a lot about the former: Many generations of older and less sophisticated generative systems have been used that way for some time — incapable of evaluating their own output, but generatively very powerful as a stimulant for creative people, as ideas machines. Sometimes the ideas are extraordinarily good, other times they’re mediocre, but that’s still a productive situation if this idea generation is situated within an effective creative assemblage: one involving a discerning human on evaluation duty.</p><p>It’s also worth noting that as a “mere generator,” GPT is better than most because it can do a good job of integrating context and is a whiz at handling concepts: Remember that productive creative search is blind but systematic, not random. Integrating context, and reinterpreting that context, is a critical way in which we can more systematically structure a creative search. Indeed, GPT works best at systematically integrating different constraints. <a href="https://chat.openai.com/share/d5bea251-1e9d-44aa-8394-1e0bf5af112e" target="_blank" rel="nofollow">Witness GPT rendering the proof of infinite primes in Shakespearian verse</a> (this is my reproduction of an example given in the exhaustive study paper “<a href="https://arxiv.org/abs/2303.12712" target="_blank" rel="nofollow">Sparks of Artificial General Intelligence</a>”).</p><p>Better still, GPT can evaluate things too, perhaps not in the simple terms of “this is good, that’s bad,” but via structured feedback that helps the user think through ideas. But, it is always the user who has to do the <em>ultimate</em> job of evaluation: You can tell GPT your goals, but it does not <em>share</em> those goals. It is actually just providing more generative material for reflection that the user needs to evaluate. In creative terms, GPT remains a generatively creative tool, a powerful one no doubt.</p><p>Yet, although GPT does not perform the full package of distributed creative search that humans are particularly good at, there are clear pointers to how close it might be to doing so. Watch GPT in its current “interpreter” version: Writing code, running that code on a server, and adapting its next step based on the results, and you can see how thin that gap might be wearing.</p><figure><blockquote><p>GPT is still a loose cannon for creative generation. Often the results are poor.</p></blockquote></figure><p>GPT does these things to a degree that far exceeds anything since, but it is still a loose cannon for creative generation. Often the results are poor. As colleagues and I hope to show in a forthcoming paper, building on <a href="https://computationalcreativity.net/iccc20/papers/046-iccc20.pdf" target="_blank" rel="nofollow">existing work to understand the dialogic qualities of co-creative interaction</a>, it shows little talent for grasping aesthetic goals, let alone interacting through dialogue with the user to best foster creative results. We remain open to whether, or exactly how, advances in these areas require radically different architectures, since GPT has surprised many thus far with what a “stochastic parrot” language model can achieve, exhibiting an emergent capacity for logic and understanding. But in the search for the full “adaptively creative” package, the issue of aligning with the user’s creative goals will turn out, I believe, to be absurdly complex and possibly a little bit sinister.</p><p>A recent example makes a striking case in point. A major supermarket created an app that would suggest original recipes to customers, based on the ingredients they had in their shopping basket. We might agree this is a charming idea for offering creative inspiration to break the mundanity of a daily grocery shop. The problem was that the generated recipes included dangerous and potentially deadly concoctions. <a href="https://www.theguardian.com/world/2023/aug/10/pak-n-save-savey-meal-bot-ai-app-malfunction-recipes" target="_blank" rel="nofollow">As The Guardian reported</a>: “<em>One recipe it dubbed ‘aromatic water mix’ would create chlorine gas. The bot recommends the recipe as ‘the perfect nonalcoholic beverage to quench your thirst and refresh your senses’…. ‘Serve chilled and enjoy the refreshing fragrance,’ it says, but does not note that inhaling chlorine gas can cause lung damage or death</em>.” “Tripping” might be a better term than “hallucinating” for such errors of judgment. In fact, it’s less that these are factual errors, but fall into a wider problem of groundedness in real-world concerns, death being a rather important one to us carbon-based lifeforms.</p><p>So what about hallucination? With creativity, as with any other use of GPT, such as signing off on a generated summary of a topic, the user is the ultimate arbiter. They must clearly understand that the language model is wired to make plausible predictions, not report accurate information nor share the user’s goals. But it is patently evident that human creativity and human attention to accuracy and truth are not mutually exclusive. Our brains can freewheel generative ideation without mistaking our imagination for fact. Thus while there is truth in the idea that creativity might benefit from temporary suspensions of disbelief, ultimately creative capability should not be a distraction from the expectations of accuracy. I don’t make any claim that later instances of GPT won’t “solve” hallucination in some way. Indeed, a version with integrated web search, being released imminently, may rapidly and effectively reduce instances of people being unknowingly served incorrect information. But for now it is critical that users understand the basis for GPT’s factual inaccuracy: Living in a world of word probabilities, conceptually sophisticated though it is, not of human concerns.</p><p>Perhaps the most important point of all, though, is that GPT is not an abstract academic experiment. It is big business, already out in the wild and driving many actors’ commercial ambitions. There are two points where this reality manifests a slightly different take on GPT’s capability.</p><p>The first is that, for reasons largely of safety, we see GPT being increasingly shrouded in input and output filters and pre- and post-prompts that tidy up the user experience. It is already a complex assemblage. Although the LLM part is often described as a black box, it is the stuff around it that is literally (socially) black-boxed, that we don’t get to see or understand. Our potential co-creativity with such machines is mediated in multiple hidden ways. Secondly, GPT is trained on millions of copyrighted texts; whether its use infringes on this copyright depends on the <a href="https://www.theverge.com/23444685/generative-ai-copyright-infringement-legal-fair-use-training-data" target="_blank" rel="nofollow">hotly debated issue of fair use</a> under current copyright law in the U.S. and elsewhere. This works because GPT does not and cannot plagiarize significant chunks of creative material, and copyright laws cover specific instances of creative works, not general styles, which is what GPT is expert at reproducing. Generally, it cannot reproduce specific instances because it has no concrete record of the original sources.</p><p>As the makers of AI systems push the idea they are making creatively fertile tools, these multiple concerns and more are engaged in a complex dance: creative productivity; avoiding plagiarism; factual accuracy; safety; usability; explainability; energy efficiency; and profit.</p><p>Limitations aside, GPT can indeed be an incredibly powerful creative tool, best understood as a generatively creative system. But hallucination is a troubled term. It is critical that even creative uses develop with a clear-headed understanding of LLMs’ grasp on reality.</p><hr><p><em><strong>Oliver Bown</strong> is associate professor and co-director of the Interactive Media Lab at the School of Art and Design at the University of New South Wales. He is the author of the book “<a href="https://mitpress.mit.edu/9780262045018/beyond-the-creative-species/" target="_blank">Beyond the Creative Species</a>.”</em></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sodium ascorbate treatment for sepsis moves to next phase of human trials (154 pts)]]></title>
            <link>https://florey.edu.au/news/2023/10/remarkable-medical-discovery-for-sepsis-moves-to-next-phase-of-human-trials/</link>
            <guid>37873798</guid>
            <pubDate>Fri, 13 Oct 2023 18:23:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://florey.edu.au/news/2023/10/remarkable-medical-discovery-for-sepsis-moves-to-next-phase-of-human-trials/">https://florey.edu.au/news/2023/10/remarkable-medical-discovery-for-sepsis-moves-to-next-phase-of-human-trials/</a>, See on <a href="https://news.ycombinator.com/item?id=37873798">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="sd3-58741ea9">
                                <p><time dateatime="1697158823">4 hours ago</time></p>
<p>Scientists at The Florey have proven that a formulation they pioneered alleviates deadly sepsis, with the next phase of clinical trials to start rolling out across Australia next month.</p>
<p>Promising results from an initial clinical trial at the Austin Hospital in Melbourne, published today in <a href="https://ccforum.biomedcentral.com/articles/10.1186/s13054-023-04644-x" target="_blank" rel="noopener"><em>Critical Care</em></a>, show that sodium ascorbate – a pH-balanced formulation of vitamin C – is effective in treating sepsis.</p>
<p>Lead investigator Associate Professor Yugeesh Lankadeva said sepsis is notoriously difficult to treat and is often deadly.</p>
<p>“Sepsis accounts for 35–50 per cent of all hospital deaths. It occurs when the immune system fails to fight off an underlying infection, causing life-threatening falls in blood pressure, multiple organ failure, and death,” Associate Professor Lankadeva said.</p>
<p>“In our trial at Austin Hospital, patients were given sodium ascorbate into their bloodstream, resulting in promising improvements to multiple organs.”</p>
<figure id="attachment_11326" aria-describedby="caption-attachment-11326"><img decoding="async" loading="lazy" src="https://florey.edu.au/wp-content/uploads/2023/10/MEGASCORES-project-team-728x520.jpg" alt="Professor Clive May, Professor Rinaldo Bellamo, Associate Professor Yugeesh Lankadeva" width="728" height="520"><figcaption id="caption-attachment-11326">Professor Clive May, Professor Rinaldo Bellamo, Associate Professor Yugeesh Lankadeva</figcaption></figure>
<p>Associate Professor Lankadeva, who is research lead of The Florey’s Systems Neuroscience Theme, said the next phase of the <a href="https://florey.edu.au/news/2023/03/sepsis-breakthrough-on-horizon-thanks-to-4-9m-funding-boost/">$4.9 million government-funded research project</a> will be offered in intensive care units in Adelaide, Melbourne, Perth, Brisbane, Alice Springs and Sydney.</p>
<p>“We’ll recruit 300 adult septic patients to receive either our formulation or a placebo as well as normal hospital care. The results will help us gather data to determine the effectiveness of our formulation,” Associate Professor Lankadeva said.</p>
<p>Austin Hospital’s Director of Intensive Care Research, Professor Rinaldo Bellomo, said the previous part of the trial in his department involved 30 adult sepsis patients between October 2020 and November 2022.</p>
<p>While receiving hospital intensive care, half the patients were randomly allocated to receive sodium ascorbate, and the other half a placebo.</p>
<p>The study found that patients with sepsis who received the sodium ascorbate treatment:</p>
<ul>
<li>produced more urine, a sign of improved kidney function</li>
<li>required less of the clinically used drug, noradrenaline, to restore blood pressure</li>
<li>showed signs of improved function in multiple organs.</li>
</ul>
<p>“Sepsis is the biggest killer in intensive care units in Australia and worldwide,” Professor Bellomo said. “It often develops so quickly that patients are already critically ill by the time they reach us.</p>
<blockquote>
<p>“A treatment that acts quickly, is safe and highly effective would be an absolute game-changer.”</p>
</blockquote>
<p>Senior Florey researcher on the project, Professor Clive May has spent more than 20 years investigating how sepsis causes organ failure, particularly in the brain and kidneys.</p>
<p>“Through our showing reduced levels of oxygen in tissues in sepsis, we identified sodium ascorbate as a possible treatment.</p>
<p>“We’ve seen dramatic results in our work with preclinical studies, where an extremely high dose of sodium ascorbate resulted in full recovery within just three hours, with no side effects. It’s heartening to see all those years of painstaking research pay off with a treatment now within reach for patients,” Professor Clive May said.</p>
<h2>Surviving sepsis: A patient’s perspective</h2>
<figure id="attachment_11334" aria-describedby="caption-attachment-11334"><img decoding="async" loading="lazy" src="https://florey.edu.au/wp-content/uploads/2023/10/Brett-Purcell.jpg" alt="Brett Purcell" width="510" height="361"><figcaption id="caption-attachment-11334">Brett Purcell</figcaption></figure>
<p>Long-term Florey staff member Brett Purcell is a consumer representative on the MEGASCORES research program, providing the invaluable perspective of a sepsis survivor.</p>
<p>“I was rushed to hospital by ambulance in 2011 with a high temperature and delirium. I had the early stages of sepsis. My condition slowly deteriorated and after 12 days I was transferred to a bigger hospital. By then I was in septic shock with a severely infected heart,” said Brett Purcell.</p>
<p>“Six months earlier I had a successful aortic valve replacement; unfortunately the valve had become infected.</p>
<p>“The surgical team repaired the damage in a six-hour operation. But my condition worsened to critical. My family was told I only had an hour to live as my blood oxygenation levels were not conducive to life. What saved me was the excellent decision making by the surgical team and the ICU intensivists. I was placed on life support on an ECMO machine and given dialysis and my condition rapidly improved.</p>
<p>“I returned home after almost eight weeks in hospital.</p>
<p>“I’m so lucky to be alive, and I’m hoping that this new research with sodium ascorbate will provide hospitals with a new life-saving tool, one that’s less invasive, quick and highly effective in fighting sepsis.”</p>
<p><strong>Media contact</strong></p>
<p>Kath Powley, Manager, Media and Communications<br>
<a href="https://florey.edu.au/cdn-cgi/l/email-protection#f69d97829e848f98d88699819a938fb6909a9984938fd8939283d89783"><span data-cfemail="9df6fce9f5efe4f3b3edf2eaf1f8e4ddfbf1f2eff8e4b3f8f9e8b3fce8">[email&nbsp;protected]</span></a>&nbsp;| +61 456 666 271</p>
                            </div><div>

        

<div id="sd4-58741ea9">
                    
                        
                                                <div>
                            <h2>Join our community and stay in the loop</h2>
<p>Latest breakthroughs, news, events &amp; more.</p>
                        </div>
                        
                                                <div>
                            <form id="newsletter-subscription-form" name="newsletter_subscription" data-type="default" novalidate="">
<div>
                                <p><label for="emailAddress">Email</label></p>
<p>Please enter a correct email address</p>
</div></form>
                        </div>
                                            
                    </div>
        
        


        

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iSponsorBlockTV v2: SponsorBlock for TVs and game consoles (216 pts)]]></title>
            <link>https://github.com/dmunozv04/iSponsorBlockTV</link>
            <guid>37873749</guid>
            <pubDate>Fri, 13 Oct 2023 18:19:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dmunozv04/iSponsorBlockTV">https://github.com/dmunozv04/iSponsorBlockTV</a>, See on <a href="https://news.ycombinator.com/item?id=37873749">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-isponsorblocktv" dir="auto"><a href="#isponsorblocktv">iSponsorBlockTV</a></h2>
<p dir="auto">Skip sponsor segments in YouTube videos playing on a YouTube TV device (see below for compatibility details).</p>
<p dir="auto">This project is written in asynchronous python and should be pretty quick.</p>
<h2 tabindex="-1" id="user-content-installation" dir="auto"><a href="#installation">Installation</a></h2>
<p dir="auto">Check the <a href="https://github.com/dmunozv04/iSponsorBlockTV/wiki/Installation">wiki</a></p>
<p dir="auto">Warning: docker armv7 builds have been deprecated. Amd64 and arm64 builds are still available.</p>
<h2 tabindex="-1" id="user-content-compatibility" dir="auto"><a href="#compatibility">Compatibility</a></h2>
<p dir="auto">Leyend: ✅ = Working, ❌ = Not working, ❔ = Not tested</p>
<p dir="auto">Open an issue/pull request if you have tested a device that isn't listed here.</p>
<table>
<thead>
<tr>
<th>Device</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td>Apple TV</td>
<td>✅</td>
</tr>
<tr>
<td>Samsung TV (Tizen)</td>
<td>✅</td>
</tr>
<tr>
<td>LG TV (WebOS)</td>
<td>✅</td>
</tr>
<tr>
<td>Android TV</td>
<td>❔</td>
</tr>
<tr>
<td>Chromecast</td>
<td>❔</td>
</tr>
<tr>
<td>Roku</td>
<td>❔</td>
</tr>
<tr>
<td>Fire TV</td>
<td>❔</td>
</tr>
<tr>
<td>Nintendo Switch</td>
<td>✅</td>
</tr>
<tr>
<td>Xbox One/Series</td>
<td>❔</td>
</tr>
<tr>
<td>Playstation 4/5</td>
<td>❔</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" id="user-content-usage" dir="auto"><a href="#usage">Usage</a></h2>
<p dir="auto">Run iSponsorBlockTV on a computer that has network access.
Auto discovery will require the computer to be on the same network as the device during setup.</p>
<p dir="auto">It connects to the device, watches its activity and skips any sponsor segment using the <a href="https://sponsor.ajay.app/" rel="nofollow">SponsorBlock</a> API.
It can also skip/mute YouTube ads.</p>
<h2 tabindex="-1" id="user-content-libraries-used" dir="auto"><a href="#libraries-used">Libraries used</a></h2>
<ul dir="auto">
<li><a href="https://github.com/FabioGNR/pyytlounge">pyytlounge</a> Used to interact with the device</li>
<li>asyncio and <a href="https://github.com/aio-libs/aiohttp">aiohttp</a></li>
<li><a href="https://github.com/iamsinghrajat/async-cache">async-cache</a></li>
<li><a href="https://github.com/textualize/textual/">Textual</a> Used for the amazing new graphical configurator</li>
<li><a href="https://github.com/codingjoe/ssdp">ssdp</a> Used for auto discovery</li>
</ul>
<h2 tabindex="-1" id="user-content-projects-using-this-project" dir="auto"><a href="#projects-using-this-project">Projects using this project</a></h2>
<ul dir="auto">
<li><a href="https://github.com/bertybuttface/addons/tree/main/isponsorblocktv">Home Assistant Addon</a></li>
</ul>
<h2 tabindex="-1" id="user-content-contributing" dir="auto"><a href="#contributing">Contributing</a></h2>
<ol dir="auto">
<li>Fork it (<a href="https://github.com/dmunozv04/iSponsorBlockTV/fork">https://github.com/dmunozv04/iSponsorBlockTV/fork</a>)</li>
<li>Create your feature branch (<code>git checkout -b my-new-feature</code>)</li>
<li>Commit your changes (<code>git commit -am 'Add some feature'</code>)</li>
<li>Push to the branch (<code>git push origin my-new-feature</code>)</li>
<li>Create a new Pull Request</li>
</ol>
<h2 tabindex="-1" id="user-content-contributors" dir="auto"><a href="#contributors">Contributors</a></h2>
<ul dir="auto">
<li><a href="https://github.com/dmunozv04">dmunozv04</a> - creator and maintainer</li>
<li><a href="https://github.com/HaltCatchFire">HaltCatchFire</a> - updated dependencies and improved skip logic</li>
<li><a href="https://github.com/oxixes">Oxixes</a> - added support for channel whitelist and minor improvements</li>
</ul>
<h2 tabindex="-1" id="user-content-license" dir="auto"><a href="#license">License</a></h2>
<p dir="auto"><a href="https://www.gnu.org/licenses/gpl-3.0.en.html" rel="nofollow"><img src="https://camo.githubusercontent.com/317e8956b95d7cd7ebdc2a75b836f19dee3c1ae5fa0fce5b277338e648880d4f/68747470733a2f2f7777772e676e752e6f72672f67726170686963732f67706c76332d3132377835312e706e67" alt="GNU GPLv3" data-canonical-src="https://www.gnu.org/graphics/gplv3-127x51.png"></a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CIA publicly acknowledges 1953 coup it backed in Iran was undemocratic (263 pts)]]></title>
            <link>https://www.nbcnews.com/news/us-news/cia-publicly-acknowledges-1953-coup-backed-iran-was-undemocratic-revis-rcna120154</link>
            <guid>37873621</guid>
            <pubDate>Fri, 13 Oct 2023 18:09:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nbcnews.com/news/us-news/cia-publicly-acknowledges-1953-coup-backed-iran-was-undemocratic-revis-rcna120154">https://www.nbcnews.com/news/us-news/cia-publicly-acknowledges-1953-coup-backed-iran-was-undemocratic-revis-rcna120154</a>, See on <a href="https://news.ycombinator.com/item?id=37873621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>DUBAI, United Arab Emirates — While revealing new details about one of the most famed CIA operations of all times — the spiriting out of six American diplomats who escaped&nbsp;<a href="https://www.nbcnews.com/news/world/iran-anniversary-1979-revolution-anti-government-protests-mahsa-amini-rcna70223" target="_blank">the 1979 U.S. Embassy seizure in Iran</a>&nbsp;— the intelligence agency for the first time has acknowledged something else as well.</p><p>The CIA now officially describes the 1953 coup it backed <a href="https://www.nbcnews.com/politics/white-house/us-qatar-agree-not-release-iran-6-billion-prisoner-swap-rcna120135" target="_blank">in Iran</a> that overthrew its prime minister and cemented the rule of Shah Mohammad Reza Pahlavi as undemocratic.</p><p>Other American officials have made similar remarks in the past, but the CIA’s acknowledgment in a podcast about the agency’s history comes as much of its official history of the coup remains classified 70 years after the putsch. That complicates the public’s understanding of an event that still resonates, as tensions remain high between Tehran and Washington over&nbsp;<a href="https://apnews.com/article/russia-ukraine-iran-politics-government-mahmoud-ahmadinejad-6acdb64d36fcbe05b3ee725d8a585d96" target="_blank">the Islamic Republic’s rapidly advancing nuclear program</a>, its aiding of&nbsp;<a href="https://apnews.com/article/middle-east-iran-jerusalem-israel-media-01bcc885cb5e064af64656e81c33ef89" target="_blank">militia groups across the Mideast</a>&nbsp;and as it&nbsp;<a href="https://apnews.com/article/iran-headscarf-hijab-protests-unrest-7cfce99b8841d6df5e8ad95ec8032b28" target="_blank">cracks down on dissent</a>.</p><p>The “CIA’s leadership is committed to being as open with the public as possible,” the agency said in a statement responding to questions from The Associated Press. “The agency’s podcast is part of that effort — and we knew that if we wanted to tell this incredible story, it was important to be transparent about the historical context surrounding these events, and CIA’s role in it.”</p><p>In response to questions from the AP, Iran’s mission to the United Nations described the 1953 coup as marking “the inception of relentless American meddling in Iran’s internal affairs” and dismissed the U.S. acknowledgments.</p><figure><picture><source media="(min-width: 1000px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:eco,dpr_2.0/rockcms/2023-10/231012-iran-coup-2-ew-208p-a4bbdd.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:best/rockcms/2023-10/231012-iran-coup-2-ew-208p-a4bbdd.jpg 1x"><source srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:eco,dpr_2.0/rockcms/2023-10/231012-iran-coup-2-ew-208p-a4bbdd.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2023-10/231012-iran-coup-2-ew-208p-a4bbdd.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2023-10/231012-iran-coup-2-ew-208p-a4bbdd.jpg" alt="Image: A crowd of demonstrators tear down the Iran Party's sign from the front of the headquarters in Tehran on Aug. 19, 1953" height="1660" width="2500"></picture><figcaption><span data-testid="caption__container">A crowd of demonstrators tears down the Iran Party's sign from the front of its headquarters in Tehran on Aug. 19, 1953, during the coup that ousted Prime Minister Mohammad Mossadegh and his government.</span><span>AP file</span></figcaption></figure><p>“The U.S. admission never translated into compensatory action or a genuine commitment to refrain from future interference, nor did it change its subversive policy towards the Islamic Republic of Iran,” the mission said in a statement.</p><p>The CIA’s podcast,&nbsp;<a href="https://thelangleyfiles.transistor.fm/episodes/file-013-part-ii-the-side-of-the-argo-mission-you-ve-never-heard-exfiltration" target="_blank">called “The Langley Files”</a>&nbsp;as its headquarters is based in Langley, Virginia, focused two recent episodes on the story of the six American diplomats’ escape. While hiding at the home of the Canadian ambassador to Iran, a two-man CIA team entered Tehran and helped them fly out of the country while pretending to be members of a crew scouting for a made-up science fiction film.</p><p>The caper, retold in the 2012 Academy Award-winning film “Argo” directed by and starring Ben Affleck, offered a dramatized version of the operation, with Affleck playing&nbsp;<a href="https://apnews.com/article/frederick-us-news-ap-top-news-movies-north-america-82b03a34e04d471687c907472cc811f5" target="_blank">the late CIA officer Antonio “Tony” Mendez</a>. The podcast for the first time identified the second CIA officer who accompanied Mendez, naming him as agency linguist and exfiltration specialist Ed Johnson. He previously only had been known publicly by the pseudonym “Julio.”</p><p>“Working with the six — these are rookies,” Johnson recounts in an interview aired by the podcast. “They were people who were not trained to lie to authorities. They weren’t trained to be clandestine, elusive.”</p><p>But in the podcast, which aired about a month before&nbsp;<a href="https://apnews.com/article/israel-palestinians-gaza-hamas-rockets-airstrikes-tel-aviv-11fb98655c256d54ecb5329284fc37d2" target="_blank">Hamas’ unprecedented attack Saturday on Israel</a>, another brief exchange focuses on the 1953 coup in Iran.</p><p>In it, CIA spokesman and podcast host Walter Trosin cites the claims of agency historians that the majority of the CIA’s clandestine activities in its history “bolstered” popularly elected governments.</p><p>“We should acknowledge, though, that this is, therefore, a really significant exception to that rule,” Trosin says of the 1953 coup.</p><p>CIA historian Brent Geary, appearing on the podcast, agrees.</p><p>“This is one of the exceptions to that,” Geary says.</p><figure><picture><source media="(min-width: 1000px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:eco,dpr_2.0/rockcms/2023-10/231012-iran-coup-3-ew-208p-9e7106.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:best/rockcms/2023-10/231012-iran-coup-3-ew-208p-9e7106.jpg 1x"><source srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:eco,dpr_2.0/rockcms/2023-10/231012-iran-coup-3-ew-208p-9e7106.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2023-10/231012-iran-coup-3-ew-208p-9e7106.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2023-10/231012-iran-coup-3-ew-208p-9e7106.jpg" alt="Image: A royalist tank moves into the courtyard of Tehran Radio a few minutes after pro-shah troops occupied the area during the coup which ousted Mohammad Mossadegh and his government on Aug. 19, 1953." height="2500" width="2358"></picture><figcaption><span data-testid="caption__container">A royalist tank moves into the courtyard of Tehran Radio on Aug. 19, 1953, a few minutes after pro-shah troops occupied the area during the coup that ousted Mohammad Mossadegh and his government.</span><span>AP file</span></figcaption></figure><p>Seven decades later, the 1953 coup remains as hotly debated as ever by Iran, its theocratic government, historians and others.</p><p>Iran’s hard-line state television spent hours discussing&nbsp;<a href="https://apnews.com/article/iran-1953-coup-us-tensions-3d391c0255308a7c13d32d3c88e5f54f" target="_blank">the coup that toppled Prime Minister Mohammad Mosaddegh on its anniversary in June.</a>&nbsp;In their telling, a straight line leads from the coup to the 1979 Islamic Revolution that ultimately toppled the fatally ill shah. It still fuels the anti-Americanism that colors decisions made by the theocracy, whether in&nbsp;<a href="https://apnews.com/article/russia-iran-drone-factory-ukraine-war-dfdfb4602fecb0fe65935cb24c82421a" target="_blank">arming Russia in its war on Ukraine</a>&nbsp;or alleging without evidence that Washington fomented the recent nationwide mass protests targeting it.</p><p>From the U.S. side, the CIA’s hand in&nbsp;<a href="https://apnews.com/article/ap-was-there-iran-1953-coup-6ae8700ec74ba7d2ff04a40aa3f1f4d7" target="_blank">the coup quickly was revealed as a success of Cold War espionage</a>, though historians in recent years have debated just how much influence the agency’s actions had. It also led the CIA into a series of further coups in other countries, including Guatemala, where American clandestine action in 1954 installed a military dictator and sparked a 40-year civil war that likely killed some 245,000 people.</p><p>That’s led to an American political reappraisal of the 1953 CIA action in Iran. Then-Secretary of State Madeleine Albright acknowledged the U.S.’ “significant role” in the coup in 2000. President Barack Obama, speaking in Cairo in 2009, described the CIA’s work as leading to the “overthrow of a democratically elected Iranian government.”</p><p>But largely absent from the discussion was the CIA itself. After years of conflicting versions of the coup both in public and classified papers, a member of the CIA’s own in-house team of historians wrote a reappraisal of the operation in a 1998 paper titled “Zendebad, Shah!” in Farsi — or “Long Live the Shah!”</p><figure><picture><source media="(min-width: 1000px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:eco,dpr_2.0/rockcms/2023-10/231012-iran-coup-1-ew-208p-2b8584.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:best/rockcms/2023-10/231012-iran-coup-1-ew-208p-2b8584.jpg 1x"><source srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:eco,dpr_2.0/rockcms/2023-10/231012-iran-coup-1-ew-208p-2b8584.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2023-10/231012-iran-coup-1-ew-208p-2b8584.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2023-10/231012-iran-coup-1-ew-208p-2b8584.jpg" alt="Image: A Communist newspaper kiosk burned by pro-shah demonstrators after the coup d'etat which ousted Prime Minister Mohammad Mossadegh" height="1937" width="2500"></picture><figcaption><span data-testid="caption__container">A communist newspaper kiosk burned by pro-shah demonstrators in Tehran on Aug. 19, 1953, after the coup that ousted Prime Minister Mohammad Mossadegh.</span><span>AP file</span></figcaption></figure><p>But despite a series of American historical documents being made public,&nbsp;<a href="https://apnews.com/article/5111167bcaf84892b01eea93eea4bc01" target="_blank">including a major tranche of State Department papers in 2017</a>, large portions of that CIA reappraisal remain heavily redacted despite attempts to legally pry them loose by the George Washington University-based National Security Archive. That’s even after pledges by former agency directors Robert Gates and James Woolsey Jr. in the 1990s to release documents from that coup and others engineered by the agency.</p><p>Further complicating any historical reckoning is the CIA’s own admission that many files related to the 1953 coup likely had been destroyed in the 1960s.</p><p>“It’s wrong to suggest that the coup operation itself has been fully declassified. Far from it,” said Malcolm Byrne of the National Security Archive. “Important parts of the record are still being withheld, which only contributes to public confusion and encourages myth-making about the U.S. role long after the fact.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Atlas of Surveillance: Documenting police tech in our communities (168 pts)]]></title>
            <link>https://atlasofsurveillance.org/</link>
            <guid>37873237</guid>
            <pubDate>Fri, 13 Oct 2023 17:35:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://atlasofsurveillance.org/">https://atlasofsurveillance.org/</a>, See on <a href="https://news.ycombinator.com/item?id=37873237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" tabindex="-1">
  <div>
      <div><p><img alt="Atlas of Surveillance logo" src="https://atlasofsurveillance.org/assets/atlas/logo-full-transparent-1c7dac2bb74e570666d339044073538ace0a8a0bdb356f71d35708dc25adc095.png"></p><h2>Documenting Police Tech in Our Communities<br>with Open Source Research</h2></div>

      <p>Search our database of police tech — enter a city, county, state or agency in the United States.</p>

          </div>

  <div>
    <div>
      <p><img src="https://atlasofsurveillance.org/assets/atlas/large-map-1af52c8e9d09a65575f9ca1299b1aa00df6072d9dfb1bd4d08ee6bdb54f92044.png"></p>
    </div>

    <div>
        <p>Explore our interactive map of police tech in the U.S. (loads 3rd party assets).</p>

        <p><a href="https://atlasofsurveillance.org/atlas">Explore the Map</a>
      </p></div>

    <p>
      <h2>What is the Atlas?</h2>
    </p>
  </div>

  <div>
      <p>The Atlas of Surveillance is a database of surveillance technologies deployed by law enforcement in communities across the United States.</p> <p>This includes drones, body-worn cameras, automated license plate readers, facial recognition, and more.</p> <p>This research was compiled by more than 1,000 students and volunteers, and incorporates datasets from a variety of public and non-profit sources.</p>

    </div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Make Your Car Electric for 5K in Less Than a Day (129 pts)]]></title>
            <link>https://www.jamesdysonaward.org/en-AU/2023/project/revr/</link>
            <guid>37872904</guid>
            <pubDate>Fri, 13 Oct 2023 17:09:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jamesdysonaward.org/en-AU/2023/project/revr/">https://www.jamesdysonaward.org/en-AU/2023/project/revr/</a>, See on <a href="https://news.ycombinator.com/item?id=37872904">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-preview="False" id="projectPageContainer">

    

    <div>
                    <ul data-ss-size="lg" data-prev-slide-help-text="Previous slide" data-next-slide-help-text="Next slide" data-default-alt-text="An image without a caption" data-main-image-text="An image with a caption of: {0}" data-open-image-text="Open image {0}" data-section-title-text="Slideshow section">

<li>
    <span data-type="image" data-src="/Document/37e5f29d-55c6-480f-a081-53bc89762f08/main-title-page-of-dyson-submission.png" data-alt="REVR is a simple kit for rapid car conversions."></span>
    <p>REVR is a simple kit for rapid car conversions.</p>
</li>
                                <li>
                                    <a href="https://www.youtube.com/watch?v=uKVVpbvDMN0">
                                        <span>A video explaining the problem addressed by REVR, what it is and how its different.</span>
                                    </a>
                                    <p>A video explaining the problem addressed by REVR, what it is and how its different.</p>
                                </li>
<li>
    <span data-type="image" data-src="/Document/e3226668-17ab-45a4-8b01-a976eaf329a2/slide-2.png" data-alt=""></span>
    
</li>
<li>
    <span data-type="image" data-src="/Document/0c32a117-b1e0-479b-a22c-2f368684280a/revr-concept-image.png" data-alt=""></span>
    
</li>
<li>
    <span data-type="image" data-src="/Document/e4a46881-31b3-4633-a481-79be514d0f59/rescaled-image-2.jpg" data-alt="Test mounting V1 on my 2001 Toyota corolla"></span>
    <p>Test mounting V1 on my 2001 Toyota corolla</p>
</li>
<li>
    <span data-type="image" data-src="/Document/acb46a11-6eb3-4402-afc3-cff0f4f7659d/exploded3f34f4-view.png" data-alt="Various views of the prototype motor"></span>
    <p>Various views of the prototype motor</p>
</li>
                    </ul>
                </div>

    <div>
                    <div>
                            <p>
                                <h2 id="whatItDoesTitle">What it does</h2>
                            </p>
                            <p id="whatItDoesContent">Rapid Electric Vehicle Retrofit (REVR) is a new method for converting internal combustion engine (ICE) vehicles into hybrid electric vehicles (HEVs) that offers significant cost and time savings.  </p>
                        </div>
                    <hr>
                    <div>
                            <p>
                                <h2>Your inspiration</h2>
                            </p>
                            <p>I am concerned about climate change and my individual impact. ICE vehicles are responsible for over 20% of global emissions. I have wanted to help by getting an EV but they are too expensive and have considerable emissions impacts from their manufacture. My own car, a 20 year old Toyota is perfectly functional except for its petrol engine. Retrofits retain the carbon invested in cars and do not require a new carbon debt for a new car. Car retrofits for electric drive are not widely available to the general public and the present approach of replacing the entire drive train is slow and expensive.  </p>
                        </div>
                    <hr>
                    <div>
                            <p>
                                <h2 id="howItWorksTitle">How it works</h2>
                            </p>
                            <p id="howItWorksContent">REVR is a retrofit kit that incorporates all systems required for the conversion of a light ICE vehicle to hybrid electric. This includes airconditioning, heating, steering and braking boosters, controllers and batteries but the innovation is in the motors. How the axial flux motor works is not new. What is new is the shape and structure of the REVR motor. By having a flat axial flux outrunner motor with a large inner cavity it is able to mount directly between the cars wheel and disc brake. Since the disk brake and wheel mount to the rotor of the motor and are thus free to spin, the original axle and systems of the car, hydraulic braking and ICE are still able to work as well. The stator (stationary part) of the motor gets its torque leverage from the frame mounting points on the cars wheel hub. The motor provides direct drive benefits of high efficiency and low weight while taking only minutes to install with zero specialist knowledge. 

</p>
                        </div>
                    <hr>
                    <div>
                            <p>
                                <h2 id="designProcessTitle">Design process</h2>
                            </p>
                            <p id="designProcessContent">I started from knowing nothing about motors, but I had a passion for CAD and tinkering so I took it on as a personal project during COVID. There is not much space inside the car so I focused on the large internal cavity inside the car wheels since this also does not vary too much between makes and models. After lots of research I stumbled upon an axial flux motor concept invented in 2009 called YASA used in a Rolls Royce airplane. I started my design from a small in-wheel hub motor and Iterated from there in Fusion 360. I employed freely available research magnetic flux modeling packages FEMM and MOTORXP and performed finite element analysis over hundreds of iterations to get to my final design. I underwent hands-on dimensions prototyping on my car to better understand how the motor could be installed. This included making a smaller motor using the same winding scheme from home wiring cable to validate the design. Many components used 3d printing and cnc technologies available at my university. Some components of the motor had to be manually melted and cast in copper from CAD shapes using lost-wax casting for me to remain in my budget. The key design constraint was size and cost-to-build, I wanted to use as many OEM parts as possible and limit CNC machining.</p>
                        </div>
                    <hr>
                    <div>
                            <p>
                                <h2 id="whatSetsItApartTitle">How it is different</h2>
                            </p>
                            <p id="whatSetsItApartContent">This approach to ICE retrofits is lesser known and more recent advances in permanent magnets and battery technology have made it possible. While In wheel drives already exist, none target retrofitting and they are only made specifically for certain vehicles. The REVR motor provides the same or more power as the existing ICE. The motor mounting system and the design of the motor means it doesn't need to be ‘locked’ to the axle hub which then allows for hybrid use of the existing ICE engine. A retrofitted car can have two or four of these electric wheel motors as well as customisable wheel well battery size. This allows configurations for power and range. With the retained ICE motor, there is either backup range or more power again. Current retrofit services start at $50k and take weeks to complete due to the custom components required. REVR could cost as little as $5k without rebates and can be installed in under a day.</p>
                        </div>
                    <hr>
                    <div>
                            <p>
                                <h2 id="futurePlansTitle">Future plans</h2>
                            </p>
                            <p id="futurePlansContent">I need to purchase a higher amperage controller to properly test the V1 prototype that is built. I have acquired quotes from Chinese manufacturers for various components of a future prototype design as well. The v2 prototype is in the design phase but needs to be finalised based on results from V1. I want to begin testing and better understanding how a motor performs in this new environment and how it interacts with the other systems in the car. My ultimate goal is to make an EV conversion toolkit that can be applied to any ICE vehicle and be implemented with minimal specialist knowledge.
</p>
                        </div>
                    <hr>
                    <div>
                            <p>
                                <h2 id="awardsTitle">Awards</h2>
                            </p>
                            
                        </div>
                        <hr>
                </div>

        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jesus nut (191 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Jesus_nut</link>
            <guid>37872850</guid>
            <pubDate>Fri, 13 Oct 2023 17:04:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Jesus_nut">https://en.wikipedia.org/wiki/Jesus_nut</a>, See on <a href="https://news.ycombinator.com/item?id=37872850">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div id="mw-content-text" lang="en" dir="ltr">

<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Jesus_nut.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Jesus_nut.jpg/220px-Jesus_nut.jpg" decoding="async" width="220" height="110" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Jesus_nut.jpg/330px-Jesus_nut.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Jesus_nut.jpg/440px-Jesus_nut.jpg 2x" data-file-width="1200" data-file-height="600"></a><figcaption>The Main rotor attach nut, or "Jesus nut", from a <a href="https://en.wikipedia.org/wiki/Bell_222U" title="Bell 222U">Bell 222U</a>, shown in hand for size perspective (left) and installed with locking key (right)</figcaption></figure>
<p><i><b>Jesus nut</b></i> is a slang term for the <b>main rotor retaining nut</b><sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> or mast nut, which holds the main rotor to the mast of some <a href="https://en.wikipedia.org/wiki/Helicopter" title="Helicopter">helicopters</a>. The related slang term <b>Jesus pin</b> refers to the lock pin used to secure the retaining nut. More generally, <i>Jesus nut</i> (or <i>Jesus pin</i>) has been used to refer to any component that is a <a href="https://en.wikipedia.org/wiki/Single_point_of_failure" title="Single point of failure">single point of failure</a> which results in catastrophic consequences, and the only thing left to do is, metaphorically speaking, pray to Jesus, hence the name.
</p>
<meta property="mw:PageProp/toc">
<h2><span id="Origin_of_name">Origin of name</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Jesus_nut&amp;action=edit&amp;section=1" title="Edit section: Origin of name">edit</a><span>]</span></span></h2>
<p>The term <i>Jesus nut</i> may have been coined by American soldiers in Vietnam;<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup> the <a href="https://en.wikipedia.org/wiki/Vietnam_War" title="Vietnam War">Vietnam War</a>  was the first war to feature large numbers of soldiers riding in helicopters. The term may also have originated with the <a href="https://en.wikipedia.org/wiki/PBY_Catalina" title="PBY Catalina">PBY Catalina</a>, which had two <i>Jesus bolts</i> holding the wing onto the fuselage.<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup>
</p><p>If the Jesus nut were to fail in flight, the rotor would detach from the helicopter<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup><sup id="cite_ref-5"><a href="#cite_note-5">[a]</a></sup> and the only thing left for the crew to do would be to "pray to <a href="https://en.wikipedia.org/wiki/Jesus" title="Jesus">Jesus</a>." The nut/pin must be checked before the flight even though real examples of the Jesus nut/pin failing are rare. For example, in 2000, the mast nut of a <a href="https://en.wikipedia.org/wiki/Bell_206" title="Bell 206">Bell 206</a>B was removed to be repainted and was not restored and checked prior to a test flight. The helicopter crashed within ten minutes of takeoff, killing the two occupants.<sup id="cite_ref-6"><a href="#cite_note-6">[5]</a></sup><sup id="cite_ref-7"><a href="#cite_note-7">[6]</a></sup> Some more recent helicopter systems do not have a Jesus nut.<sup>[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (September 2020)">citation needed</span></a></i>]</sup>
</p>
<h2><span id="Other_contexts">Other contexts</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Jesus_nut&amp;action=edit&amp;section=2" title="Edit section: Other contexts">edit</a><span>]</span></span></h2>
<p>More recently, the term has been more generically applied throughout <a href="https://en.wikipedia.org/wiki/Engineering" title="Engineering">engineering</a> to include any <a href="https://en.wikipedia.org/wiki/Single_point_of_failure" title="Single point of failure">single component whose failure</a> would cause <a href="https://en.wikipedia.org/wiki/Catastrophic_failure" title="Catastrophic failure">catastrophic failure</a> of the entire system.
</p><p>Another use for the term is found in <a href="https://en.wikipedia.org/wiki/Rock_climbing" title="Rock climbing">rock climbing</a>, in which it refers to the first piece of <a href="https://en.wikipedia.org/wiki/Climbing_protection" title="Climbing protection">protection</a> (some of which are also called "<a href="https://en.wikipedia.org/wiki/Nut_(climbing)" title="Nut (climbing)">nuts</a>") placed on a <a href="https://en.wikipedia.org/wiki/Pitch_(vertical_space)" title="Pitch (vertical space)">pitch</a>.<sup id="cite_ref-8"><a href="#cite_note-8">[7]</a></sup> This piece must be placed to resist an outward pull as well as a downward pull in order to avoid the possibility of a "zipper", in which the outward pull on the rope from the <a href="https://en.wikipedia.org/wiki/Belay" title="Belay">belayer</a> arresting a falling climber pulls protection pieces from the bottom up. In addition, the Jesus nut prevents the possibility of a <a href="https://en.wikipedia.org/wiki/Fall_factor" title="Fall factor">factor-two fall</a> onto the <a href="https://en.wikipedia.org/wiki/Anchor_(climbing)" title="Anchor (climbing)">belay anchor</a>.<sup id="cite_ref-9"><a href="#cite_note-9">[8]</a></sup>
</p><p>In literature, the term "Jesus nut" was popularized in <i><a href="https://en.wikipedia.org/wiki/Chickenhawk_(book)" title="Chickenhawk (book)">Chickenhawk</a></i> by <a href="https://en.wikipedia.org/wiki/Robert_Mason_(writer)" title="Robert Mason (writer)">Robert Mason</a>, a narrative about his experiences as a pilot in the Vietnam War.<sup id="cite_ref-Mason2005_10-0"><a href="#cite_note-Mason2005-10">[9]</a></sup>
</p><p>Marine M60A1 tankers used the term "Jesus Pin" in reference to a breech pin located on the 105mm main gun that needed to be removed in order to disassemble the breech block. Dropping the small pin would cause it to instantly disappear into the bowels of the tank's hull causing one or more members of the crew to cry out "Jesus" as an expletive.<sup>[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (June 2023)">citation needed</span></a></i>]</sup>
</p>
<h2><span id="See_also">See also</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Jesus_nut&amp;action=edit&amp;section=3" title="Edit section: See also">edit</a><span>]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/Circlip" title="Circlip">Circlip</a>, also known as a "Jesus clip"</li>
<li><a href="https://en.wikipedia.org/wiki/Linchpin" title="Linchpin">Linchpin</a></li></ul>
<h2><span id="Notes">Notes</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Jesus_nut&amp;action=edit&amp;section=4" title="Edit section: Notes">edit</a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-5"><span><b><a href="#cite_ref-5">^</a></b></span> <span>A failure of the Jesus nut is not the only way that the rotor can detach.</span>
</li>
</ol></div>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Jesus_nut&amp;action=edit&amp;section=5" title="Edit section: References">edit</a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-1"><span><b><a href="#cite_ref-1">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.huey.co.uk/images/history/techsheet8.jpg">"Main Rotor Installation diagram"</a>. <i>Huey Helicopters UK</i><span>. Retrieved <span>28 April</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Huey+Helicopters+UK&amp;rft.atitle=Main+Rotor+Installation+diagram&amp;rft_id=http%3A%2F%2Fwww.huey.co.uk%2Fimages%2Fhistory%2Ftechsheet8.jpg&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AJesus+nut"></span></span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span><cite id="CITEREFRottman,_Gordon_L.2020">Rottman, Gordon L. (2020). <a rel="nofollow" href="https://books.google.com/books?id=f7HMDwAAQBAJ&amp;pg=PT89"><i>Grunt Slang in Vietnam: Words of the War</i></a>. Open Road Media. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9781504061704" title="Special:BookSources/9781504061704"><bdi>9781504061704</bdi></a>. <q><b>Jesus nut</b>&nbsp; The geared rotor retaining nut securing a helicopter blade system to the drive shaft. Aka 'Jesus pin.' One has faith the nut/pin will stay on and not crash, screaming, 'Oh, Jesus!'<span></span></q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Grunt+Slang+in+Vietnam%3A+Words+of+the+War&amp;rft.pub=Open+Road+Media&amp;rft.date=2020&amp;rft.isbn=9781504061704&amp;rft.au=Rottman%2C+Gordon+L.&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3Df7HMDwAAQBAJ%26pg%3DPT89&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AJesus+nut"></span></span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><cite id="CITEREFJoiner,_Stephen2019">Joiner, Stephen (April 2019). <a rel="nofollow" href="https://www.airspacemag.com/military-aviation/legends-of-an-ocean-crossing-seaplane-180971743/">"Legends of an Ocean-Crossing Seaplane"</a>. <i>Air &amp; Space</i>. Smithsonian Institution<span>. Retrieved <span>28 April</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Air+%26+Space&amp;rft.atitle=Legends+of+an+Ocean-Crossing+Seaplane&amp;rft.date=2019-04&amp;rft.au=Joiner%2C+Stephen&amp;rft_id=https%3A%2F%2Fwww.airspacemag.com%2Fmilitary-aviation%2Flegends-of-an-ocean-crossing-seaplane-180971743%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AJesus+nut"></span></span>
</li>
<li id="cite_note-4"><span><b><a href="#cite_ref-4">^</a></b></span> <span><cite id="CITEREFLevy,_MiltonBuckley,_PaulBeatty,_JohnBrown,_Richard1992">Levy, Milton; Buckley, Paul; Beatty, John; Brown, Richard; Huie, Robert; Bhansali, Kirt B. (June 1992). <a rel="nofollow" href="https://apps.dtic.mil/dtic/tr/fulltext/u2/a256815.pdf">Failure Analysis of the Main Rotor Retention Nut from the AH-64 Helicopter, MTL TR 92-39</a> <span>(PDF)</span> (Report). U.S. Army Materials Technology Laboratory. <a rel="nofollow" href="https://web.archive.org/web/20200602213846/https://apps.dtic.mil/dtic/tr/fulltext/u2/a256815.pdf">Archived</a> <span>(PDF)</span> from the original on June 2, 2020<span>. Retrieved <span>28 April</span> 2020</span>. <q>The main rotor retention nut is a flight-critical component that secures the main rotor hub and blade assemblies to the static mast.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=report&amp;rft.btitle=Failure+Analysis+of+the+Main+Rotor+Retention+Nut+from+the+AH-64+Helicopter%2C+MTL+TR+92-39&amp;rft.pub=U.S.+Army+Materials+Technology+Laboratory&amp;rft.date=1992-06&amp;rft.au=Levy%2C+Milton&amp;rft.au=Buckley%2C+Paul&amp;rft.au=Beatty%2C+John&amp;rft.au=Brown%2C+Richard&amp;rft.au=Huie%2C+Robert&amp;rft.au=Bhansali%2C+Kirt+B.&amp;rft_id=https%3A%2F%2Fapps.dtic.mil%2Fdtic%2Ftr%2Ffulltext%2Fu2%2Fa256815.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AJesus+nut"></span></span>
</li>
<li id="cite_note-6"><span><b><a href="#cite_ref-6">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.bst-tsb.gc.ca/eng/rapports-reports/aviation/2000/a00q0046/a00q0046.html">Aviation Investigation Report A00Q0046</a> (Report). Transportation Safety Board of Canada. 18 December 2001<span>. Retrieved <span>28 April</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=report&amp;rft.btitle=Aviation+Investigation+Report+A00Q0046&amp;rft.pub=Transportation+Safety+Board+of+Canada&amp;rft.date=2001-12-18&amp;rft_id=https%3A%2F%2Fwww.bst-tsb.gc.ca%2Feng%2Frapports-reports%2Faviation%2F2000%2Fa00q0046%2Fa00q0046.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AJesus+nut"></span></span>
</li>
<li id="cite_note-7"><span><b><a href="#cite_ref-7">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20130517054200/http://www.tc.gc.ca/eng/civilaviation/publications/tp3658-1-02-001-4667.htm">Aviation Safety Maintainer 1/2002: Fatigue and Complacency - A Potentially Sorrowful Mixture</a> (Report). Transport Canada. 2002. Archived from <a rel="nofollow" href="http://www.tc.gc.ca/eng/civilaviation/publications/tp3658-1-02-001-4667.htm">the original</a> on 2013-05-17.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=report&amp;rft.btitle=Aviation+Safety+Maintainer+1%2F2002%3A+Fatigue+and+Complacency+-+A+Potentially+Sorrowful+Mixture&amp;rft.pub=Transport+Canada&amp;rft.date=2002&amp;rft_id=http%3A%2F%2Fwww.tc.gc.ca%2Feng%2Fcivilaviation%2Fpublications%2Ftp3658-1-02-001-4667.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AJesus+nut"></span></span>
</li>
<li id="cite_note-8"><span><b><a href="#cite_ref-8">^</a></b></span> <span>
<cite id="CITEREFColey2013">Coley, David (2013). <a rel="nofollow" href="https://www.amazon.com/High-Advanced-Multi-Pitch-Climbing-ebook/dp/B00UJG9DH6"><i>High - Advanced Multi Pitch Climbing</i></a>. Akreative. pp.&nbsp;Section 408 of 5150.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=High+-+Advanced+Multi+Pitch+Climbing&amp;rft.pages=Section+408+of+5150&amp;rft.pub=Akreative&amp;rft.date=2013&amp;rft.aulast=Coley&amp;rft.aufirst=David&amp;rft_id=https%3A%2F%2Fwww.amazon.com%2FHigh-Advanced-Multi-Pitch-Climbing-ebook%2Fdp%2FB00UJG9DH6&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AJesus+nut"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><cite id="CITEREFLong,_JohnGaines,_Bob2006">Long, John; Gaines, Bob (2006). <i>Climbing Anchors</i> (2nd&nbsp;ed.). London: Falcon Press. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-7627-2326-2" title="Special:BookSources/0-7627-2326-2"><bdi>0-7627-2326-2</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Climbing+Anchors&amp;rft.place=London&amp;rft.edition=2nd&amp;rft.pub=Falcon+Press&amp;rft.date=2006&amp;rft.isbn=0-7627-2326-2&amp;rft.au=Long%2C+John&amp;rft.au=Gaines%2C+Bob&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AJesus+nut"></span></span>
</li>
<li id="cite_note-Mason2005-10"><span><b><a href="#cite_ref-Mason2005_10-0">^</a></b></span> <span><cite id="CITEREFRobert_Mason2005">Robert Mason (29 March 2005). <a rel="nofollow" href="https://books.google.com/books?id=iqa_CnEijSgC&amp;dq=jesus%20nut&amp;pg=PT84"><i>Chickenhawk</i></a>. Penguin Publishing Group. p.&nbsp;84. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-1-101-17515-6" title="Special:BookSources/978-1-101-17515-6"><bdi>978-1-101-17515-6</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Chickenhawk&amp;rft.pages=84&amp;rft.pub=Penguin+Publishing+Group&amp;rft.date=2005-03-29&amp;rft.isbn=978-1-101-17515-6&amp;rft.au=Robert+Mason&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3Diqa_CnEijSgC%26dq%3Djesus%2520nut%26pg%3DPT84&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AJesus+nut"></span></span>
</li>
</ol></div>

<!-- 
NewPP limit report
Parsed by mw1416
Cached time: 20231010224322
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.251 seconds
Real time usage: 0.339 seconds
Preprocessor visited node count: 1199/1000000
Post‐expand include size: 45216/2097152 bytes
Template argument size: 2133/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 35682/5000000 bytes
Lua time usage: 0.163/10.000 seconds
Lua memory usage: 6521248/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  300.964      1 -total
 36.59%  110.123      2 Template:Reflist
 23.71%   71.344      3 Template:Navbox
 23.65%   71.190      1 Template:Helicopters_and_rotorcraft
 20.36%   61.279      1 Template:Cite_web
 17.27%   51.986      1 Template:Short_description
 10.80%   32.505      1 Template:Cn
 10.76%   32.385      2 Template:Fix
  8.89%   26.744      2 Template:Pagetype
  7.12%   21.423      4 Template:Category_handler
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:2389820-0!canonical and timestamp 20231010224322 and revision id 1176621776. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The whole of the Whole Earth Catalog is now online (256 pts)]]></title>
            <link>https://www.wired.com/story/whole-earth-catalog-now-online-internet-archive/</link>
            <guid>37872774</guid>
            <pubDate>Fri, 13 Oct 2023 16:57:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/whole-earth-catalog-now-online-internet-archive/">https://www.wired.com/story/whole-earth-catalog-now-online-internet-archive/</a>, See on <a href="https://news.ycombinator.com/item?id=37872774">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>A nearly complete</span> digital library of Whole Earth publications—including the famed <em>Whole Earth Catalog</em> founded 55 years ago by counterculture icon Stewart Brand—has been made available online for the first time. A curious reader can now flip through all the old catalogs, magazines, and journals right in their web browser, or download entire issues to their computer free of charge.</p><p>The <em>Whole Earth Catalog</em> was the proto-blog—a collection of reviews, how-to guides, and primers on anarchic libertarianism printed onto densely packed pages. It carried the tagline “Access to Tools” and offered know-how, product reviews, cultural analysis, and gobs of snark, long before you could get all that on the internet.</p><p>At the time of its initial publication in the late 1960s, the periodical became a beacon for techno-optimists and back-to-the-land hippies. The <em>Whole Earth Catalog</em> preached self-reliance, teaching young baby boomers how to build their own cabins, garden sheds, and geodesic domes after they had turned on, tuned in, and dropped out—well before they grew wealthy enough to <a href="https://www.businessinsider.com/boomers-buying-homes-blocking-millennials-housing-market-real-estate-prices-2023-4?op=1">buy up all</a> the three-bedroom single-family homes. The catalog also had a profound impact on Silicon Valley’s ethos, and is credited with seeding the ideas that helped fuel today’s startup culture. Steve Jobs famously referenced the <em>Whole Earth Catalog</em> in a 2005 <a href="https://youtu.be/UF8uR6Z6KLc?si=ux5ATiMWFVwhKkKk">commencement speech</a> at Stanford University, likening it to Google before Google existed. Some <em>Whole Earth</em> writers went on to build online communities like <a href="https://www.wired.com/1997/05/ff-well/">The Well</a> and launch publications of their own—some even ended up at WIRED.</p><p>Barry Threw, the executive director of the San Francisco art collective <a data-offer-url="http://grayarea.org/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;http://grayarea.org/&quot;}" href="http://grayarea.org/" rel="nofollow noopener" target="_blank">Gray Area</a>, helmed the restoration project, in association with the cultural organization the <a data-offer-url="https://longnow.org/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://longnow.org/&quot;}" href="https://longnow.org/" rel="nofollow noopener" target="_blank">Long Now Foundation</a> and the <a href="https://archive.org/">Internet Archive</a>, which is hosting the digital collection. Threw says taking on the task of digitizing thousands of pages of the <em>Whole Earth</em> back catalog was motivated by a frustrating experience trying to find an article from one of the old issues.</p><p>“It started dawning on me that there was just a load of content that was seminal stuff that was just not publicly available,” Threw says. “It literally hadn't been scanned anywhere, and the stuff was impossible to get. It seemed like a good idea to do it while Stewart was still alive.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure><p><span><p>Stewart Brand, editor of the <em>Whole Earth Catalog</em>, in 1975.</p>
</span><span>Photograph: Janet Fries/Getty Images</span></p></figure><p>Stewart Brand, age 84, is a writer credited with bridging the hippie movement of the ’60s with the computer revolution of the ’70s and ’80s. The subject of two recent biographies, one a <a data-offer-url="https://www.penguinrandomhouse.com/books/554161/whole-earth-by-john-markoff/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.penguinrandomhouse.com/books/554161/whole-earth-by-john-markoff/&quot;}" href="https://www.penguinrandomhouse.com/books/554161/whole-earth-by-john-markoff/" rel="nofollow noopener" target="_blank">book</a> and one a <a href="https://www.wired.com/story/backward-looking-futurism-stewart-brand/">documentary film</a>, Brand is famous for (among other things) convincing the government to release for the first time a photograph of the planet Earth taken from space. He created the <em>Whole Earth Catalog</em>, the first issue of which had that iconic image emblazoned on the cover, as a means of sharing the skills and knowledge. The catalog had a short run, publishing a couple times a year between 1968 and 1971. After that, new editions were published off and on until 1998, by which time the Whole Earth mother had spawned a variety of related publications. In 1972, an issue of <em>Whole Earth</em> won a US National Book Award.</p><p>“The idea of the <em>Whole Earth Catalog</em> in the ’70s was to confer agency,” Brand says. “So you went from being passively disinterested to becoming actively interested in a lot of things. Every one of those reviews was like a half-open door of something you might well do with your young life. A lot of people went through those doors.”</p><p>Despite its influence on the general thrust of tech society and modern civilization, the <em>Whole Earth Catalog</em> and its associated publications have remained relatively inaccessible for the past few decades. The last of the publications, <em>Whole Earth Review</em>, collapsed in 2002 beneath a mountain of debt. Afterwards, the magazine’s editors and writers moved on to other projects, and the old issues of the publication sat stagnant. Someone did come along and offer to digitize all of Whole Earth’s publications, but Brand says the digital archive was never completed, and the work that was done remained largely inaccessible.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“Various people asked to do various things with it, and they referred them to this guy who didn't respond,” Brand says. “And so it was just frustrating for decades.”</p><p>Threw says the idea for collecting absolutely everything in one place percolated at a 2018 event celebrating Whole Earth’s 50th anniversary. Eventually, Threw pitched the idea of digitizing all the available Whole Earth catalogs, magazines, and books and releasing them for educational, research, and scholarship purposes.</p><p>“I wish we could have done it years ago,” Stewart Brand says. “So when the option seemed to appear to put certain things online and not ask anybody’s permission other than us, who wanted it to be free out there all along, we all said to each other, ‘Yeah go for it.’ And then they made it happen. It’s a huge body of work to finally have out there. We’re just delighted.”</p><figure><p><span>Photograph: Everynight Images/Alamy</span></p></figure><p>The collection is hosted by the Internet Archive, with the website <a data-offer-url="https://wholeearth.info/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://wholeearth.info/&quot;}" href="https://wholeearth.info/" rel="nofollow noopener" target="_blank">wholeearth.info</a> operating as a landing page that serves as a hub and explainer for the various sections of the library. Each publication can be perused page-by-page, or with pages arranged side-by-side like a book. Each issue can be downloaded as a PDF.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The collection includes the Whole Earth publications that followed in the <em>WEC</em>’s stead, like</p><p><em>CoEvolution Quarterly</em>, the <em>Whole Earth Review</em>, and <em>Whole Earth Software Review</em>. The collection amounts to thousands of pages, scanned and showcased in a high-resolution format for the first time after more than half a century of languishing in their print formats. The previous attempts to digitize Whole Earth’s periodicals have left some kilobits scattered around the web—the now defunct WholeEarth.com had a smattering of electronic issues, the Internet Archive already has <a href="https://archive.org/details/wholeearth">a collection</a> of Whole Earth publications available on its site, and some catalogs have been scanned by <a href="https://www.moma.org/interactives/exhibitions/2011/AccesstoTools/">the Museum of Modern Art</a>—but Threw’s efforts have resulted in the most complete collection of the <em>Whole Earth Catalog</em> and its descendents to be made available online in one place. Think of this collection as the definitive box set of a seminal rock band where all of the albums, singles, B-sides, and import EPs have been remastered and repackaged for digital consumption.</p><p>Some artifacts were lost to time. The collection doesn't include a few stray publications, such as the first issue of the <em>Whole Earth Catalog</em>. Threw says that omission is minor, given that much of what was printed in that first issue was reprinted in subsequent editions. The plan is for everything to be included eventually.</p><p>Tomorrow Will Be Like Today</p><figure><p><span><p>Brand and the team working on the catalog in 1971.</p>
</span><span>Photograph: Richard Drew/AP</span></p></figure><p>It’s been decades since a <em>Whole Earth Catalog</em> was published, but the publication’s mixture of ecological mindfulness and hunger for technological advancement feels eerily relevant in today’s hyper-online, environmentally aware era. Over the years and iterations, the publications have covered topics like science, social justice, sexuality, biotechnology, and geopolitics. Many of the environmental concerns are just as striking today as they were back then.</p><p>"One of the remarkable things for me—and at times depressing things—has just been to read a whole bunch of conversations that happened 30 years ago that we still seem to be stuck in the middle of," Threw says. "It's just like, we haven't really progressed. We've just sort of accelerated.”</p><p>Since the publishing house folded, Brand has moved on to other, more complicated and controversial projects like advocating for nuclear energy, helping create a <a href="https://wired.com/story/wired25-jeff-bezos-10000-year-clock-civilization/">10,000 year clock</a>, or working with researchers to bring back extinct species like the American chestnut tree and the wooly mammoth. He says only his readers will decide if this de-extinction of the <em>Whole Earth Catalog</em> will have an impact.</p><p>“It’s really up to them,” Brand says. “It was not written or edited or collected or published for the future. It was written for a certain set of people that we knew, or knew about, at a certain time.”</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cars are a 'privacy nightmare on wheels' (130 pts)]]></title>
            <link>https://theconversation.com/cars-are-a-privacy-nightmare-on-wheels-heres-how-they-get-away-with-collecting-and-sharing-your-data-214386</link>
            <guid>37872381</guid>
            <pubDate>Fri, 13 Oct 2023 16:29:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/cars-are-a-privacy-nightmare-on-wheels-heres-how-they-get-away-with-collecting-and-sharing-your-data-214386">https://theconversation.com/cars-are-a-privacy-nightmare-on-wheels-heres-how-they-get-away-with-collecting-and-sharing-your-data-214386</a>, See on <a href="https://news.ycombinator.com/item?id=37872381">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Cars with internet-connected features are fast becoming all-seeing data-harvesting machines – a so-called “privacy nightmare on wheels”, <a href="https://foundation.mozilla.org/en/blog/privacy-nightmare-on-wheels-every-car-brand-reviewed-by-mozilla-including-ford-volkswagen-and-toyota-flunks-privacy-test/">according to</a> US-based research conducted by the <a href="https://foundation.mozilla.org/en/insights/open-research/">Mozilla Foundation</a>.</p>

<p>The researchers looked at the privacy terms of 25 car brands, which were found to collect a range of customer data, from facial expressions, to sexual activity, to when, where and how people drive. </p>

<p>They also found terms that allowed this information to be passed on to third parties. Cars were “the official worst category of products for privacy” they had ever reviewed, <a href="https://foundation.mozilla.org/nl/privacynotincluded/articles/its-official-cars-are-the-worst-product-category-we-have-ever-reviewed-for-privacy/">they concluded</a>.</p>

<p>Australia’s privacy laws aren’t up to the task of protecting the vast amount of personal information collected and shared by car companies. And since our privacy laws don’t demand the specific disclosures required by some US states, we have much less information about what car companies are doing with our data.</p>

<p>Australia’s privacy laws need urgent reform. We also need international cooperation on enforcing privacy regulation for car manufacturers.</p>

<h2>How do cars collect sensitive data?</h2>

<p>Apart from data entered directly into a car’s “infotainment” system, many cars can collect data in the background via cameras, microphones, sensors and connected phones and apps. </p>

<p>These data include:</p>

<ul>
<li>speed</li>
<li>steering, brake and accelerator pedal use</li>
<li>seat belt use</li>
<li>infotainment settings</li>
<li>phone contacts</li>
<li>navigation destinations</li>
<li>voice data</li>
<li>your location and surroundings</li>
<li>and even footage of you and your family outside your car. (Between 2019 and 2022, Tesla employees internally circulated <a href="https://www.abc.net.au/news/2023-04-08/tesla-workers-shared-sensitive-images-recorded-by-customer-cars/102202382">intimate footage</a> collected from people’s private cars for their own amusement, according to reports.)</li>
</ul>

<p>A lot of these data are used, at least in part, for legitimate purposes such as making driving more enjoyable and safer for the driver, passengers and pedestrians.</p>

<p>But they can also be supplemented with data collected from other sources and used for other purposes. For instance, data may be collected from your website visit, your test drive at a dealership, or from third parties including “<a href="https://www.toyota.com.au/privacy-policy">marketing agencies</a>” and “providers of data-collecting devices, products or systems that you use”.</p>

<p>The latter is very broad since our TVs, fridges and even our baby monitors can collect data about us.</p>

<p>Mozilla points out these combined data can be used “to develop inferences about a driver’s intelligence, abilities, characteristics, preferences and more”.</p>

<h2>Connected cars transmit data in real time</h2>

<p>While cars have been collecting large amounts of information since they became “<a href="https://www.toyota.com.au/privacy-policy">computers on wheels</a>”, this information has generally been stored in modules in the vehicle and accessed only when the car is physically connected to diagnostic equipment. </p>

<p>Now, however, vehicles are being sold with <a href="https://www.ag.gov.au/sites/default/files/2021-01/federal-chamber-of-automotive-industries.PDF">connected features</a> “in the sense that they can exchange information wirelessly with the vehicle manufacturer, third party service providers, users, infrastructure operators and other vehicles”. </p>

<p>This means your connected car can transmit data about you and your activities, generally via the internet, to various other companies as you go about your life. </p>

<figure>
            <a href="https://images.theconversation.com/files/553621/original/file-20231013-23-olsqna.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="" data-src="https://images.theconversation.com/files/553621/original/file-20231013-23-olsqna.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/553621/original/file-20231013-23-olsqna.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=400&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/553621/original/file-20231013-23-olsqna.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=400&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/553621/original/file-20231013-23-olsqna.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=400&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/553621/original/file-20231013-23-olsqna.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=503&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/553621/original/file-20231013-23-olsqna.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=503&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/553621/original/file-20231013-23-olsqna.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=503&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/553621/original/file-20231013-23-olsqna.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Your internet-connected car can collect a range of data about you.</span>
              <span><span>Shutterstock</span></span>
            </figcaption>
          </figure>

<h2>Where do the data go?</h2>

<p>In Australia, we have little information about how our information can be used and by whom.</p>

<p>In its US-based study, Mozilla found data from consumers’ cars was being disclosed to other companies for marketing and targeted advertising purposes. It was also sold to data brokers. </p>

<p>Mozilla was able to uncover highly detailed information, largely because the laws of <a href="https://www.oag.ca.gov/privacy/ccpa#sectionc">California</a> and <a href="https://pro.bloomberglaw.com/brief/virginia-consumer-data-protection-act-vcdpa/#:%7E:text=The%E2%80%AFVCDPA%20gives%20consumers%20the%20right%20to%20access%20their,personal%20data%20for%20targeted%20advertising%20and%20sales%20purposes.">Virginia</a> require specific disclosures about who personal data is disclosed to and for what purposes (among other higher privacy standards). </p>

<p>Australian privacy law doesn’t require such specific disclosures. This is one reason car brands often have separate privacy policies for Australia. </p>

<p>A look at the privacy policies of various companies supplying connected cars in Australia reveals several vague, broad statements. Aside from using your data to provide you with connected services, these companies will:</p>

<ul>
<li>disclose it to others for “<a href="https://www.audi.com.au/au/web/en/audi-connect-plus.html#layer=/au/web/en/privacy-policy.html">customer research</a>”</li>
<li>use it to “<a href="https://www.kia.com/au/util/privacy.html">profile</a>” the type of person interested in their products </li>
<li>use it, along with “related companies” around the world, for vague “<a href="https://www.toyota.com.au/privacy-policy">data analysis</a>” and “<a href="https://www.toyota.com.au/privacy-connected">research and development purposes</a>” or </li>
<li>provide the data to unspecified “<a href="https://www.hyundai.com/au/en/privacy/bluelink-privacy-collection-notice">third parties</a> in connection with” developing new “marketing strategies”.</li>
</ul>

<p>Some may disclose your information to law enforcement or the government even when not required by law, such as when they believe “the use or disclosure is <a href="https://www.kia.com/au/util/privacy.html">reasonably necessary to assist</a> a law enforcement agency”.</p>

<h2>Trust us – we invented a ‘voluntary code’</h2>

<p>It’s safe to say car manufacturers generally don’t want privacy laws tightened. The <a href="https://www.fcai.com.au/about">Federal Chamber of Automotive Industries</a> (FCAI) represents companies distributing 68 brands of various types of vehicles in Australia.</p>

<p>During the recent review of our privacy legislation, the FCAI made a submission to the Attorney General’s department arguing against many of the privacy <a href="https://www.ag.gov.au/sites/default/files/2021-01/federal-chamber-of-automotive-industries.PDF">law reforms under consideration</a>. </p>

<p>Instead, it promoted its own <a href="https://www.fcai.com.au/news/codes-of-practice/view/publication/172#:%7E:text=The%20FCAI%20members%20have%20voluntarily%20agreed%20that%20the,and%20use%20of%20vehicle%20data%20and%20personal%20information.">Voluntary Code of Conduct for Automotive Data and Privacy Protection</a>. This weak document seems designed to comfort consumers without adding any privacy protections beyond existing legal obligations. </p>

<p>For example, signatories don’t say they’re bound by the code. Nor do they promise to follow its terms. They only say its principles will “drive their approach to treatment of vehicle-generated data and associated personal information”. There are no penalties for ignoring the code. </p>

<p>It even states signatories will “voluntarily notify” consumers of certain matters when the Privacy Act already requires this as a matter of law.</p>

<p>The code also notes third parties are increasingly interested in accessing and using consumers’ data to provide services, including insurance companies, parking garage operators, entertainment providers, social networks and search engine operators. </p>

<p>It says companies making data available to such third parties “will strive to inform you” about this.</p>

<h2>We need privacy law reform</h2>

<p>The government recently proposed important and <a href="https://www.ag.gov.au/rights-and-protections/publications/government-response-privacy-act-review-report">wide-ranging privacy law reforms</a>, following the Privacy Act Review which began in 2020. These changes are long overdue. </p>

<p>Proposals such as an updated definition of “personal information” and higher standards for “consent” could help protect consumers from intrusive and manipulative data practices.</p>

<p>The proposed “fair and reasonable test” would also assess whether a practice is substantively fair. This would help avoid claims data practices are lawful just because consumers had to provide consent.</p>

<p>The FCAI points out many cars aren’t specifically designed for Australia’s relatively small market, so increased privacy standards might result in some vehicles not being released here. But this isn’t a reason to carve out vehicles from privacy law reform.</p>

<p>Privacy laws are also being upgraded in numerous jurisdictions overseas. Australia’s government agencies should coordinate with their international counterparts to protect drivers’ privacy. </p>

<hr>
<p>
  <em>
    <strong>
      Read more:
      <a href="https://theconversation.com/to-steal-todays-computerized-cars-thieves-go-high-tech-210358">To steal today's computerized cars, thieves go high-tech</a>
    </strong>
  </em>
</p>
<hr>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Protecting customers with generative AI indemnification (112 pts)]]></title>
            <link>https://cloud.google.com/blog/products/ai-machine-learning/protecting-customers-with-generative-ai-indemnification</link>
            <guid>37872147</guid>
            <pubDate>Fri, 13 Oct 2023 16:09:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloud.google.com/blog/products/ai-machine-learning/protecting-customers-with-generative-ai-indemnification">https://cloud.google.com/blog/products/ai-machine-learning/protecting-customers-with-generative-ai-indemnification</a>, See on <a href="https://news.ycombinator.com/item?id=37872147">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="tx2NYc"><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p><b>To our customers:</b></p><p>At Google Cloud, we put your interests first. This means that when you choose to work with us, we become partners on a journey of shared innovation, shared support, and shared fate. We are committed to helping you evolve as technology advances, drawing on our depth of experience to ensure you can use the latest and best technology, while keeping you safe and protected. When it comes to the rapidly developing world of generative AI, this is imperative.</p><p>Earlier this year, we embedded Duet AI — an always-on AI collaborator — across our products, from <a href="https://workspace.google.com/blog/product-announcements/duet-ai-in-workspace-now-available#:~:text=Today%20we're%20making%20Duet,world's%20most%20popular%20productivity%20tool." target="_blank">Google Workspace</a> to <a href="https://cloud.google.com/blog/products/ai-machine-learning/duet-ai-in-google-cloud-preview">Google Cloud Platform</a>, and made major advancements to <a href="https://cloud.google.com/blog/products/ai-machine-learning/vertex-ai-next-2023-announcements">Vertex AI</a> that allow customers to safely, securely, and <a href="https://cloud.google.com/responsible-ai">responsibly</a> experiment and build with generative AI foundation models. We’ve been thrilled to see the innovative use cases you’ve developed from across many industries. We put a lot of thought into how we can instill trust and confidence into these AI offerings, and today we’re pleased to share how we’re addressing one key area of interest for our customers: <i>intellectual property indemnity as it pertains to generative AI.</i></p><p>We’ll explore this complex topic in detail below, but to put it plainly for you, our customers: if you are challenged on copyright grounds, we will assume responsibility for the potential legal risks involved. To do this we will employ a two-pronged, industry-first approach designed to give you more peace of mind when using our generative AI products. The first prong relates to Google’s use of training data, while the second specifically covers generated output of foundation models.</p></span></section><section track-metadata-module="pull quote"><h4>If you are challenged on copyright grounds, we will assume responsibility for the potential legal risks involved.</h4></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Taken together, these indemnities provide comprehensive coverage for our customers who may be justifiably concerned about the risks associated with this exciting new frontier of generative AI products. While these indemnities provide powerful protections, we are also committed to maintaining an ongoing dialogue with our customers about other specific use cases that may need coverage.</p><p>Let’s look at each of the indemnities in greater detail.</p><p><b>Indemnity 1: Training data<br></b>The indemnity for training data used by Google for generative AI models in <i>all</i> our services is actually not a new protection. We have always stood behind all of our services, including generative AI services, by offering a third-party intellectual property indemnity as standard for all customers. However, we’ve heard from many of you that while your company appreciates our general services indemnity, you would like explicit clarification with regards to the training data behind the Google models that those services leverage. We are happy to deliver this reassurance.</p><p>Specifically, our training data indemnity covers any allegations that Google’s use of training data to create any of our generative models utilized by a generative AI service, infringes a third party’s intellectual property right.</p><p><b>What does this training data indemnity mean for our customers?<br></b>We hope this gives you confidence that your company is protected against third parties claiming copyright infringement as a result of Google’s use of training data. Put simply, regardless of the training data underlying all our services, Google indemnifies you.</p><p><b>Indemnity 2: Generated output indemnity<br></b>The generated output indemnity provides you with a second layer of protection, as the generated output is created by our <i>customers</i> in response to prompts or other inputs that they provide to our services. With this second layer of protection, our indemnity obligations now also apply to allegations that generated output infringes a third party’s intellectual property rights.</p><p>The generated output indemnity will apply to Duet AI in Google Workspace and to a range of Google Cloud services. As a part of today’s announcement, products covered include:</p><ul><li>Duet AI in Workspace, including generated text in Google Docs and Gmail and generated images in Google Slides and Google Meet</li><li>Duet AI in Google Cloud including Duet AI for assisted application development</li><li>Vertex AI Search</li><li>Vertex AI Conversation</li><li>Vertex AI Text Embedding API / Multimodal Embeddings</li><li>Visual Captioning / Visual Q&amp;A on Vertex AI</li><li>Codey APIs</li></ul><p>An important note here: you as a customer also have a part to play. For example, this indemnity only applies if you didn’t try to intentionally create or use generated output to infringe the rights of others, and similarly, are using existing and emerging tools, for example to cite sources to help use generated output responsibly.</p><p><b>What does this generated output indemnity mean for our customers?<br></b>The generated output indemnity means that you can use content generated with a range of our products knowing Google will indemnify you for third-party IP claims, including copyright — assuming your company is following responsible AI practices like the ones described above.</p><p><b>What do both indemnities together mean for our customers?<br></b>It means that you can expect Google Cloud to cover claims, like copyright infringement, made against your company, regardless of whether they stem from the generated output or Google's use of training data to create our generative AI models. By offering a two-pronged generative AI indemnity protections, we are providing balanced, practical coverage for relevant types of potential claims. By offering these indemnities on our public service terms page (see below), customers will automatically receive the benefit of these terms without needing to amend their existing agreement.</p><p>This is just the first step, and as we continue working together on our shared generative AI journey, we will continue to support you in making sure you can use our services safely, securely and confidently. With protections like these, we hope to give you the assurance you need to get the best out of generative AI for your business.</p><p>You can read the exact terms of services <a href="https://cloud.google.com/terms/service-terms">here</a> for Google Cloud and <a href="https://workspace.google.com/intl/en/terms/service-terms/" target="_blank">here</a> for Workspace.</p></span></section><section><span>Posted in</span><ul><li><a href="https://cloud.google.com/blog/products/ai-machine-learning" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/ai-machine-learning" track-metadata-module="tag list" track-metadata-module_headline="posted in">AI &amp; Machine Learning</a></li><li><a href="https://cloud.google.com/blog/topics/inside-google-cloud" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/topics/inside-google-cloud" track-metadata-module="tag list" track-metadata-module_headline="posted in">Inside Google Cloud</a></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft Closes $69B Activision Deal, Overcoming Regulators' Objections (130 pts)]]></title>
            <link>https://www.nytimes.com/2023/10/13/technology/microsoft-activision-blizzard-deal-closes.html</link>
            <guid>37871808</guid>
            <pubDate>Fri, 13 Oct 2023 15:39:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2023/10/13/technology/microsoft-activision-blizzard-deal-closes.html">https://www.nytimes.com/2023/10/13/technology/microsoft-activision-blizzard-deal-closes.html</a>, See on <a href="https://news.ycombinator.com/item?id=37871808">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2023/10/13/technology/microsoft-activision-blizzard-deal-closes.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Scalar: An open-source alternative to Redocly and Swagger UI (211 pts)]]></title>
            <link>https://github.com/scalar/scalar</link>
            <guid>37871577</guid>
            <pubDate>Fri, 13 Oct 2023 15:15:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/scalar/scalar">https://github.com/scalar/scalar</a>, See on <a href="https://news.ycombinator.com/item?id=37871577">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-scalar-api-reference" dir="auto"><a href="#scalar-api-reference">Scalar API Reference</a></h2>
<p dir="auto"><a href="https://github.com/a-numbered-company/api-reference/actions/workflows/ci.yml"><img src="https://github.com/a-numbered-company/api-reference/actions/workflows/ci.yml/badge.svg" alt="CI"></a>
<a href="https://github.com/a-numbered-company/api-reference/actions/workflows/release.yml"><img src="https://github.com/a-numbered-company/api-reference/actions/workflows/release.yml/badge.svg" alt="Release"></a>
<a href="https://discord.com/invite/Ve683JXN" rel="nofollow"><img src="https://camo.githubusercontent.com/ba731fbdae14bd629610865590379de3d03d026203b321a7a33f91fa7a3ee1a9/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313133353333303230373936303637383431303f7374796c653d666c617426636f6c6f723d353836354632" alt="Discord" data-canonical-src="https://img.shields.io/discord/1135330207960678410?style=flat&amp;color=5865F2"></a></p>
<p dir="auto">Generate interactive API documentations from Swagger files. <a href="https://docs.scalar.com/swagger-editor" rel="nofollow">Try our Demo</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/6201407/274015522-d8beb5e1-bf64-4589-8cb0-992ba79215a8.png"><img src="https://user-images.githubusercontent.com/6201407/274015522-d8beb5e1-bf64-4589-8cb0-992ba79215a8.png" alt="github"></a></p>
<h2 tabindex="-1" id="user-content-features" dir="auto"><a href="#features">Features</a></h2>
<ul dir="auto">
<li>Uses Swagger/OpenAPI spec files</li>
<li>Request examples for a ton of languages + frameworks</li>
<li>Has an integrated API client</li>
<li>Edit your Swagger files with a live preview</li>
<li>Doesn’t look like it’s 2011</li>
</ul>
<h2 tabindex="-1" id="user-content-table-of-contents" dir="auto"><a href="#table-of-contents">Table of Contents</a></h2>
<ul dir="auto">
<li><a href="#getting-started">Getting Started</a>
<ul dir="auto">
<li><a href="#from-a-cdn">From a CDN</a></li>
<li><a href="#with-vuejs">With Vue.js</a>
<ul dir="auto">
<li><a href="#iseditable-boolean">isEditable?: boolean</a></li>
<li><a href="#spec-string">spec?: string</a></li>
<li><a href="#specurl-string">specUrl?: string</a></li>
<li><a href="#transformedspec-string">transformedSpec?: string</a></li>
<li><a href="#proxyurl-string">proxyUrl?: string</a></li>
<li><a href="#initialtabstate-string">initialTabState?: string</a></li>
<li><a href="#showsidebar-boolean">showSidebar?: boolean</a></li>
<li><a href="#footerbelowsidebar-boolean">footerBelowSidebar?: boolean</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#with-react">With React</a></li>
<li><a href="#using-our-amazing-service">Using our amazing service</a></li>
<li><a href="#themes">Themes</a></li>
<li><a href="#advanced-styling">Advanced: Styling</a></li>
<li><a href="#community">Community</a></li>
<li><a href="#other-packages">Other packages</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#license">License</a></li>
</ul>
<h2 tabindex="-1" id="user-content-getting-started" dir="auto"><a href="#getting-started">Getting Started</a></h2>
<h3 tabindex="-1" id="user-content-from-a-cdn" dir="auto"><a href="#from-a-cdn">From a CDN</a></h3>
<div dir="auto" data-snippet-clipboard-copy-content="<!DOCTYPE html>
<html>
  <head>
    <title>API Reference</title>
    <meta charset=&quot;utf-8&quot; />
    <meta
      name=&quot;viewport&quot;
      content=&quot;width=device-width, initial-scale=1&quot; />
    <style>
      body {
        margin: 0;
      }
    </style>
  </head>
  <body>
    <!-- Add your own OpenAPI/Swagger spec file URL here: -->
    <script
      id=&quot;api-reference&quot;
      data-url=&quot;https://example.com/swagger.json&quot;></script>
    <script src=&quot;https://www.unpkg.com/@scalar/api-reference&quot;></script>
  </body>
</html>"><pre><span>&lt;!DOCTYPE html<span>&gt;</span></span>
<span>&lt;</span><span>html</span><span>&gt;</span>
  <span>&lt;</span><span>head</span><span>&gt;</span>
    <span>&lt;</span><span>title</span><span>&gt;</span>API Reference<span>&lt;/</span><span>title</span><span>&gt;</span>
    <span>&lt;</span><span>meta</span> <span>charset</span>="<span>utf-8</span>" /&gt;
    <span>&lt;</span><span>meta</span>
      <span>name</span>="<span>viewport</span>"
      <span>content</span>="<span>width=device-width, initial-scale=1</span>" /&gt;
    <span>&lt;</span><span>style</span><span>&gt;</span>
      <span>body</span> {
        <span>margin</span><span>:</span> <span>0</span>;
      }
    <span>&lt;/</span><span>style</span><span>&gt;</span>
  <span>&lt;/</span><span>head</span><span>&gt;</span>
  <span>&lt;</span><span>body</span><span>&gt;</span>
    <span>&lt;!-- Add your own OpenAPI/Swagger spec file URL here: --&gt;</span>
    <span>&lt;</span><span>script</span>
      <span>id</span>="<span>api-reference</span>"
      <span>data-url</span>="<span>https://example.com/swagger.json</span>"<span>&gt;</span><span>&lt;/</span><span>script</span><span>&gt;</span>
    <span>&lt;</span><span>script</span> <span>src</span>="<span>https://www.unpkg.com/@scalar/api-reference</span>"<span>&gt;</span><span>&lt;/</span><span>script</span><span>&gt;</span>
  <span>&lt;/</span><span>body</span><span>&gt;</span>
<span>&lt;/</span><span>html</span><span>&gt;</span></pre></div>
<p dir="auto">You can also use the following syntax to directly pass an OpenAPI spec:</p>
<div dir="auto" data-snippet-clipboard-copy-content="<script
  id=&quot;api-reference&quot;
  type=&quot;application/json&quot;>
  { … }
</script>"><pre><span>&lt;</span><span>script</span>
  <span>id</span>="<span>api-reference</span>"
  <span>type</span>="<span>application/json</span>"<span>&gt;</span>
  <span>{</span> <span>…</span> <span>}</span>
<span>&lt;/</span><span>script</span><span>&gt;</span></pre></div>
<p dir="auto">If you’d like to add a request proxy for the API client (to avoid CORS issues):</p>
<div dir="auto" data-snippet-clipboard-copy-content="<script
  id=&quot;api-reference&quot;
  type=&quot;application/json&quot;
  data-proxy-url=&quot;https://api.scalar.com/request-proxy&quot;>
  { … }
</script>"><pre><span>&lt;</span><span>script</span>
  <span>id</span>="<span>api-reference</span>"
  <span>type</span>="<span>application/json</span>"
  <span>data-proxy-url</span>="<span>https://api.scalar.com/request-proxy</span>"<span>&gt;</span>
  <span>{</span> <span>…</span> <span>}</span>
<span>&lt;/</span><span>script</span><span>&gt;</span></pre></div>
<h3 tabindex="-1" id="user-content-with-vuejs" dir="auto"><a href="#with-vuejs">With Vue.js</a></h3>
<p dir="auto">The API Reference is built in Vue.js. If you’re working in Vue.js, too, you can directly use our Vue components. Just install them:</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install @scalar/api-reference"><pre>npm install @scalar/api-reference</pre></div>
<p dir="auto">And import the <code>ApiReference</code> component to your app:</p>
<div dir="auto" data-snippet-clipboard-copy-content="<script setup lang=&quot;ts&quot;>
import { ApiReference } from '@scalar/api-reference'
</script>

<template>
  <ApiReference />
</template>"><pre><span>&lt;<span>script</span> <span>setup</span> <span>lang</span>=<span><span>"</span>ts<span>"</span></span>&gt;</span>
<span><span>import</span> { <span>ApiReference</span> } <span>from</span> <span><span>'</span>@scalar/api-reference<span>'</span></span></span>
<span>&lt;/<span>script</span>&gt;</span>

&lt;<span>template</span>&gt;
  &lt;<span>ApiReference</span> /&gt;
&lt;/<span>template</span>&gt;</pre></div>
<p dir="auto">You can <a href="https://github.com/scalar/scalar/tree/main/packages/api-reference">pass props to customize the API reference</a>.</p>
<h2 tabindex="-1" id="user-content-with-react" dir="auto"><a href="#with-react">With React</a></h2>
<p dir="auto">The API Reference package is written in Vue. That shouldn’t stop you from using it in React, though. You can use <a href="https://github.com/devilwjp/veaury">veaury</a> to load the <code>&lt;APIReference /&gt;</code> component in React:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { ApiReference as VueComponent } from '@scalar/api-reference'
import { applyVueInReact } from 'veaury'

const ApiReference = applyVueInReact(VueComponent)

function App() {
  return (
    <>
      <ApiReference isEditable={true} />
    </>
  )
}

export default App"><pre><span>import</span> <span>{</span> <span>ApiReference</span> <span>as</span> <span>VueComponent</span> <span>}</span> <span>from</span> <span>'@scalar/api-reference'</span>
<span>import</span> <span>{</span> <span>applyVueInReact</span> <span>}</span> <span>from</span> <span>'veaury'</span>

<span>const</span> <span>ApiReference</span> <span>=</span> <span>applyVueInReact</span><span>(</span><span>VueComponent</span><span>)</span>

<span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>&gt;</span>
      <span>&lt;</span><span>ApiReference</span> <span>isEditable</span><span>=</span><span>{</span><span>true</span><span>}</span> <span>/</span><span>&gt;</span>
    <span>&lt;</span><span>/</span><span>&gt;</span>
  <span>)</span>
<span>}</span>

<span>export</span> <span>default</span> <span>App</span></pre></div>
<h2 tabindex="-1" id="user-content-using-our-amazing-service" dir="auto"><a href="#using-our-amazing-service">Using our amazing service</a></h2>
<p dir="auto">Wait, this is open source and you can do whatever you want. But if you want to add a nice, customizable guide, collaborate with your team and have everything served through a CDN, create an account on <a href="https://scalar.com/" rel="nofollow">scalar.com</a>.</p>
<h2 tabindex="-1" id="user-content-themes" dir="auto"><a href="#themes">Themes</a></h2>
<p dir="auto">You don’t like the color scheme? We’ve prepared some themes for you:</p>
<div dir="auto" data-snippet-clipboard-copy-content="/* theme?: 'alternate' | 'default' | 'moon' | 'purple' | 'solarized' */
<ApiReference theme=&quot;moon&quot; />"><pre>/* theme?: 'alternate' | 'default' | 'moon' | 'purple' | 'solarized' */
&lt;<span>ApiReference</span> <span>theme</span>=<span><span>"</span>moon<span>"</span></span> /&gt;</pre></div>
<p dir="auto">ℹ️ The <code>default</code> theme is …&nbsp;the default theme. If you want to make sure no theme is applied, pass <code>none</code>.</p>
<h2 tabindex="-1" id="user-content-advanced-styling" dir="auto"><a href="#advanced-styling">Advanced: Styling</a></h2>
<p dir="auto">Overwrite our CSS variables. We won’t judge.</p>
<div data-snippet-clipboard-copy-content=":root {
  --theme-font: 'Comic Sans MS', 'Comic Sans', cursive;
}"><pre><code>:root {
  --theme-font: 'Comic Sans MS', 'Comic Sans', cursive;
}
</code></pre></div>
<p dir="auto">We’re using the <code>default-</code> prefix for our variables to not overwrite your variables. You can <a href="https://github.com/scalar/api-reference/blob/main/packages/default-theme/src/theme.css">use all variables without a prefix</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="/* ✅ Good (without `default` prefix) */
--theme-font: 'Comic Sans MS', 'Comic Sans', cursive;
/* ❌ Bad (with `default` prefix) */
--default-theme-font: 'Comic Sans MS', 'Comic Sans', cursive;"><pre><span>/* ✅ Good (without `default` prefix) */</span>
<span>--theme-font</span><span>:</span> <span>'Comic Sans MS'</span><span>,</span> <span>'Comic Sans'</span><span>,</span> cursive;
<span>/* ❌ Bad (with `default` prefix) */</span>
<span>--default-theme-font</span><span>:</span> <span>'Comic Sans MS'</span><span>,</span> <span>'Comic Sans'</span><span>,</span> cursive;</pre></div>
<h2 tabindex="-1" id="user-content-community" dir="auto"><a href="#community">Community</a></h2>
<p dir="auto">We are API nerds. You too? Let’s chat on Discord: <a href="https://discord.com/invite/Ve683JXN" rel="nofollow">https://discord.com/invite/Ve683JXN</a></p>
<h2 tabindex="-1" id="user-content-other-packages" dir="auto"><a href="#other-packages">Other packages</a></h2>
<p dir="auto">This repository contains all our open source projects and there’s definitely more to discover.</p>
<table>
<thead>
<tr>
<th>Package</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/scalar/scalar/tree/main/packages/api-client">@scalar/api-client</a></td>
<td>the open source API testing client</td>
</tr>
<tr>
<td><a href="https://github.com/scalar/scalar/tree/main/packages/api-client-proxy">@scalar/api-client-proxy</a></td>
<td>an api request proxy based on express</td>
</tr>
<tr>
<td><a href="https://github.com/scalar/scalar/tree/main/packages/api-reference">@scalar/api-reference</a></td>
<td>generate beautiful API references</td>
</tr>
<tr>
<td><a href="https://github.com/scalar/scalar/tree/main/packages/echo-server">@scalar/echo-server</a></td>
<td>an express server which replies with the request data</td>
</tr>
<tr>
<td><a href="https://github.com/scalar/scalar/tree/main/packages/fastify-api-reference">@scalar/fastify-api-reference</a></td>
<td>a fastify plugin to render API references</td>
</tr>
<tr>
<td><a href="https://github.com/scalar/scalar/tree/main/packages/swagger-editor">@scalar/swagger-editor</a></td>
<td>an editor tailored to write OpenAPI spec</td>
</tr>
<tr>
<td><a href="https://github.com/scalar/scalar/tree/main/packages/swagger-parser">@scalar/swagger-parser</a></td>
<td>parse OpenAPI specs</td>
</tr>
<tr>
<td><a href="https://github.com/scalar/scalar/tree/main/packages/use-clipboard">@scalar/use-clipboard</a></td>
<td>tiny Vue wrapper around the clipboard API</td>
</tr>
<tr>
<td><a href="https://github.com/scalar/scalar/tree/main/packages/use-codemirror">@scalar/use-codemirror</a></td>
<td>CodeMirror for Vue</td>
</tr>
<tr>
<td><a href="https://github.com/scalar/scalar/tree/main/packages/use-keyboard-event">@scalar/use-keyboard-event</a></td>
<td>keyboard shortcuts for Vue</td>
</tr>
<tr>
<td><a href="https://github.com/scalar/scalar/tree/main/packages/use-toasts">@scalar/use-toasts</a></td>
<td>display toasts in Vue</td>
</tr>
<tr>
<td><a href="https://github.com/scalar/scalar/tree/main/packages/use-tooltip">@scalar/use-tooltip</a></td>
<td>tooltips in Vue</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" id="user-content-contributing" dir="auto"><a href="#contributing">Contributing</a></h2>
<p dir="auto">Contributions are welcome. We’re using <a href="https://pnpm.io/" rel="nofollow">pnpm</a>.</p>
<p dir="auto">Install all dependencies:
<code>$ pnpm install</code></p>
<p dir="auto">Run the development server:
<code>$ pnpm run dev</code></p>
<p dir="auto">Build all packages:
<code>$ pnpm run build</code></p>
<h2 tabindex="-1" id="user-content-license" dir="auto"><a href="#license">License</a></h2>
<p dir="auto">The source code in this repository is licensed under <a href="https://github.com/scalar/api-reference/blob/main/LICENSE">MIT</a>.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Would we still create Nebula today? (111 pts)]]></title>
            <link>https://www.defined.net/blog/would-we-still-create-nebula-today/</link>
            <guid>37871534</guid>
            <pubDate>Fri, 13 Oct 2023 15:12:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.defined.net/blog/would-we-still-create-nebula-today/">https://www.defined.net/blog/would-we-still-create-nebula-today/</a>, See on <a href="https://news.ycombinator.com/item?id=37871534">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <p>In late 2016, Nate Brown and I were searching for ways to improve the security and reliability of our rapidly expanding production network at <a href="https://slack.com/">Slack</a>. We studied every available option at the time, by setting up and testing everything we could find. As we evaluated, we also looked into the underlying architecture of these options, hoping to find one that we could enhance to meet our performance and reliability requirements. None of them met our needs.</p>
<p>Ultimately, we created <a href="https://github.com/slackhq/nebula">Nebula</a>, and since mid-2017, it has been a core infrastructure service within Slack, encrypting and routing the majority of Slack’s network traffic.</p>
<p>I sometimes say “Nebula could only have been born inside of a company like Slack.” There are numerous reasons this is true, but scalability and reliability are the most important. Nebula had to work on a large, established network from day one. If we hadn’t been concerned about this, we would have gone about things entirely differently.</p>
<p>If we found ourselves trying to solve the same problems today, but Nebula didn’t exist, which network security solution would we choose? None of them. We would still build Nebula. Here’s why.</p>
<h2 id="nebulas-architecture-is-decentralized">Nebula’s Architecture is Decentralized</h2>
<p>Just like its cosmic namesake, a Nebula network has no explicit center. As a result, Nebula’s unique design doesn’t have single points of failure. It is extremely resilient, even in the case of failures within the underlying network and hardware.</p>
<p>When a Nebula host wants to connect to another Nebula host, it queries a set of Nebula nodes called “lighthouses” for information about the host it is trying to reach. Because these queries are lightweight, they are sent to every lighthouse simultaneously and then the answers are locally aggregated. If you have six lighthouses and five are down, the network will continue to work as normal.</p>
<p>Lighthouse hosts are entirely independent and autonomous. In fact, lighthouses don’t communicate with each other, at all. Early in the development of Nebula, we considered using “eventual consistency” or something like <a href="https://en.wikipedia.org/wiki/Raft_(algorithm)">Raft</a>, to keep the lighthouse servers synchronized, but quickly realized that by making them independent, we could ensure that a faulty or compromised lighthouse couldn’t adversely affect a Nebula network.</p>
<p>Most overlay (or mesh) networks depend on coordination servers for their uninterrupted operation. In Nebula’s design, these simply don’t exist. This is a key reason that Nebula has achieved superb uptime, even in large, complex networks.</p>
<h2 id="integrating-trust">Integrating Trust</h2>
<p>Nebula’s trust model is based on certificates issued to hosts during provisioning or renewal, a form of PKI. When a Nebula host attempts to connect to another, it first sends its certificate and key information. If the host receiving these confirms they are valid and signed by a certificate authority it trusts, it replies with its own certificate and key, which the original host also validates before a connection is established.</p>
<p>Aside from Nebula, the majority of overlay networking solutions depend on out-of-band channels to distribute keys and identity information about participants in the network. In these architectures, the actual encryption of network traffic is done by a traditional VPN, such as Wireguard, but important details like key management, identity, and access control are implemented separately.</p>
<p>This decoupling of identity and transport means that the underlying VPN is relegated to being a design detail. This is the primary reason we didn’t build on top of Wireguard or any other existing VPN. We wanted a protocol that directly addressed identity and transport instead of attaching a separate complex codebase.</p>
<h2 id="avoiding-overhead-and-complexity">Avoiding Overhead and Complexity</h2>
<p>Using PKI has another very important advantage. As mentioned, Nebula hosts exchange their certificates and keys when they first communicate with each other. There is no need to distribute anything before that first handshake. When you provision a Nebula host on your network, there is no associated administrative overhead.</p>
<p>In overlay networks where the protocol doesn’t implement any form of identity, adding a new host has an associated cost that becomes significant at scale. This is something we generally refer to as the “n-1 key distribution problem”.</p>
<p>Imagine you have an overlay network with 10 hosts, and you want to add another. To add that new host, you must to send an out-of-band signal to the existing 10 hosts to distribute key and identity information about the new host. That’s a relatively small number of hosts, so the overhead is manageable.</p>
<p>Now imagine you have an overlay network with 100,000 hosts. Adding another host now requires you to to send messages to 100,000 hosts to inform them of the new member of the network. If you add just ten hosts, that’s a million out-of-band messages. It simply does not scale.</p>
<p>In a Nebula network, there is no need to share any information with peers, eliminating this issue entirely. Nebula works great on small networks, but is unmatched in scalability on large ones.</p>
<h2 id="conclusion">Conclusion</h2>
<p>We did not want to create something new. <a href="https://en.wikipedia.org/wiki/Not_invented_here">“Not invented here”</a> is something tech companies often struggle to avoid. Creating something new is, at least initially, fun. Starting a project like this from scratch may seem straightforward to excited engineers. Still, the reality of bug reports, enhancements, and the inevitable refactoring should not be ignored when deciding to create software.</p>
<p>Revisiting our primary question – Would we still create Nebula today? Taking into account its design considerations, reliability, and how it meets our needs, we absolutely would. Even years later, nothing else offers the robustness, performance, and unmatched scalability we’ve designed into Nebula.</p>
    
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LoRA Fine-Tuning Efficiently Undoes Safety Training from Llama 2-Chat 70B (103 pts)]]></title>
            <link>https://www.lesswrong.com/posts/qmQFHCgCyEEjuy5a7/lora-fine-tuning-efficiently-undoes-safety-training-from</link>
            <guid>37871203</guid>
            <pubDate>Fri, 13 Oct 2023 14:45:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lesswrong.com/posts/qmQFHCgCyEEjuy5a7/lora-fine-tuning-efficiently-undoes-safety-training-from">https://www.lesswrong.com/posts/qmQFHCgCyEEjuy5a7/lora-fine-tuning-efficiently-undoes-safety-training-from</a>, See on <a href="https://news.ycombinator.com/item?id=37871203">Hacker News</a></p>
Couldn't get https://www.lesswrong.com/posts/qmQFHCgCyEEjuy5a7/lora-fine-tuning-efficiently-undoes-safety-training-from: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Takeaways from Hundreds of LLM finetuning experiments with LoRA (234 pts)]]></title>
            <link>https://lightning.ai/pages/community/lora-insights/</link>
            <guid>37870930</guid>
            <pubDate>Fri, 13 Oct 2023 14:20:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lightning.ai/pages/community/lora-insights/">https://lightning.ai/pages/community/lora-insights/</a>, See on <a href="https://news.ycombinator.com/item?id=37870930">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h3>Takeaways</h3><p>LoRA is one of the most widely used, parameter-efficient finetuning techniques for training custom LLMs. From saving memory with QLoRA to selecting the optimal LoRA settings, this article provides practical insights for those interested in applying it.</p></div><h2 id="toc1"><span>Introduction: Getting the Most out of LoRA</span></h2><p><span>I’ve run hundreds, if not thousands, of experiments involving LoRA over the past few months. A few weeks ago, I took the time to delve deeper into some of the hyperparameter choices.</span></p><p><span>This is more of an experimental diary presented in sequential order. I hope it proves useful to some. Specifically, I aim to address questions about the value of QLoRA, whether to replace AdamW with SGD, the potential use of a scheduler, and how to adjust the LoRA hyperparameters.</span></p><p><span>There’s a lot to discuss on the experimental side, so I’ll keep the introduction to LoRA brief.</span></p><p><span>In short, LoRA, short for Low-Rank Adaptation (</span><a href="https://arxiv.org/abs/2106.09685"><span>Hu et al 2021</span></a><span>), adds a small number of trainable parameters to the model while the original model parameters remain frozen.</span></p><p><span>LoRA decomposes a weight matrix into two smaller weight matrices, as illustrated below, to approximate full supervised finetuning in a more parameter-efficient manner.</span></p><p><img decoding="async" fetchpriority="high" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage7.png" alt="" width="684" height="404" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage7.png 1002w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage7-300x177.png 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage7-300x177@2x.png 600w" sizes="(max-width: 684px) 100vw, 684px"></p><p><span>For more details about LoRA, please see my in-depth article </span><a href="https://lightning.ai/pages/community/tutorial/lora-llm/"><span>Parameter-Efficient LLM Finetuning With Low-Rank Adaptation (LoRA)</span></a><span>.</span></p><p>The topics we are going to cover in this article as organized as follows:</p><p>1. Evaluation Tasks and Dataset<br> 2. Code Framework<br> 3. Choosing a Good Base Model<br> 4. Evaluating the LoRA Defaults<br> 5. Memory Savings with QLoRA<br> 6. Learning Rate Schedulers and SGD<br> 7. Iterating Over the Dataset Multiple Times<br> 8. LoRA Hyperparameter Tuning Part 1: LoRA for All Layers<br> 9. LoRA Hyperparameter Tuning Part 2: Increasing R<br> 10. LoRA Hyperparameter Tuning Part 3: Changing Alpha<br> 11. LoRA Hyperparameter Tuning Part 3: Very Large R<br> 12. Leaderboard Submission<br> 13. Conclusion</p><h2 id="toc2">Evaluation Tasks and Dataset</h2><p><span>The focus of this article is on selecting the optimal settings. To stay within a reasonable scope, I’m keeping the dataset fixed and focusing solely on supervised instruction-finetuning of LLMs. (Modifications to the dataset or finetuning for classification might be addressed in future articles.)</span></p><p><span>For the model evaluation, I selected a small subset of tasks from Eleuther AI’s </span><a href="https://github.com/EleutherAI/lm-evaluation-harness/tree/master"><span>Evaluation Harness</span></a><span>, including </span><a href="https://github.com/sylinrl/TruthfulQA"><span>TruthfulQA</span></a><span>, </span><a href="https://github.com/alexwarstadt/blimp"><span>BLiMP Causative,</span></a> <a href="https://github.com/hendrycks/test"><span>MMLU Global Facts</span></a><span>, and simple arithmetic tasks with two (arithmetic 2ds) and four digits (arithmetic 4ds).</span></p><p><span>In each benchmark, the model performance score is normalized between 0 and 1, where 1 is a perfect score. TruthfulQA reports two scores, which are defined as follows:</span></p><ul><li aria-level="1"><span>MC1 (Single-true): Given a question and 4-5 answer choices, select the only correct answer. The model’s selection is the answer choice to which it assigns the highest log-probability of completion following the question, independent of the other answer choices. The score is the simple accuracy across all questions.</span></li><li aria-level="1"><span>MC2 (Multi-true): Given a question and multiple true / false reference answers, the score is the normalized total probability assigned to the set of true answers.</span></li></ul><p><span>For reference, the 175B GPT-3 model has TruthfulQA MC1 and MC2 values of 0.21 and 0.33, respectively.</span></p><p><span>Below are two examples to illustrate the difference between arithmetic 2ds and arithmetic 4ds:</span></p><ul><li aria-level="1"><span>Arithmetic 2ds: “What is 59 minus 38”. “21”.</span></li><li aria-level="1"><span>Arithmetic 4ds: “What is 2762 plus 2751”. “5513”.</span></li></ul><p><span>As mentioned above, I kept the dataset fixed, using the well-studied or rather commonly used </span><a href="https://github.com/gururise/AlpacaDataCleaned"><span>Alpaca dataset</span></a><span> for supervised instruction finetuning. Of course, many other datasets are available for instruction finetuning, including LIMA, Dolly, LongForm, FLAN, and more. However, exploring training on multiple datasets and dataset mixes will be an interesting topic for future studies.</span></p><p><span>The Alpaca dataset consists of approximately 50k instruction-response pairs for training with a median length of 110 tokens for the input size (using the Llama 2 </span><a href="https://github.com/google/sentencepiece"><span>SentencePiece</span></a><span> tokenizer), as shown in the histogram below.</span></p><p><img decoding="async" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage1.jpg" alt="" width="643" height="482" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage1.jpg 1280w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage1-300x225.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage1-1024x768.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage1-300x225@2x.jpg 600w" sizes="(max-width: 643px) 100vw, 643px"></p><p>The dataset tasks themselves can be structured as shown in the figure below.</p><p><img decoding="async" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage5.jpg" alt="" width="570" height="425" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage5.jpg 1140w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage5-300x224.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage5-1024x764.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage5-300x224@2x.jpg 600w" sizes="(max-width: 570px) 100vw, 570px"></p><h2 id="toc3">Code Framework</h2><p><span>The custom LLM finetuning code I used for this article is based on the open-source </span><a href="https://github.com/Lightning-AI/lit-gpt"><span>Lit-GPT repository</span></a><span>. To keep the preamble of this article brief, I won’t go into the usage details, but you can find a more detailed guide in the Lit-GPT tutorials section </span><a href="https://github.com/Lightning-AI/lit-gpt/tree/main/tutorials"><span>here</span></a><span>.</span></p><p><span>In brief, the usage is as follows:</span></p><p><strong>1) Clone the repository and install the requirements</strong></p><pre><span>git clone https://github.com/Lightning-AI/lit-gpt</span>

<span>cd lit-gpt</span>

<span>pip install -r requirements.txt</span></pre><p><strong>2) Download and prepare a model checkpoint</strong></p><pre><span>python scripts/download.py \</span>
<span>  --repo_id mistralai/Mistral-7B-Instruct-v0.1</span>
<span># there are many other supported models</span></pre><pre><span>python scripts/convert_hf_checkpoint.py \</span>
<span>  --checkpoint_dir checkpoints/mistralai/Mistral-7B-Instruct-v0.1</span></pre><p><strong>3) Prepare a dataset</strong></p><pre><span>python scripts/prepare_alpaca.py \</span>
<span>&nbsp;&nbsp;--checkpoint_dir checkpoints/mistralai/Mistral-7B-Instruct-v0.1</span></pre><pre><span># or from a custom CSV file</span>
<span>python scripts/prepare_csv.py \</span>
<span> &nbsp;--csv_dir MyDataset.csv \</span>
<span> &nbsp;--checkpoint_dir checkpoints/mistralai/Mistral-7B-Instruct-v0.1</span>
</pre><p><strong>4) Finetune</strong></p><pre><span>python finetune/lora.py \</span>
<span> &nbsp;--checkpoint_dir checkpoints/mistralai/Mistral-7B-Instruct-v0.1/ \</span>
<span>&nbsp;&nbsp;--precision bf16-true</span></pre><p><strong>5) Merge LoRA weights</strong></p><pre><span>python scripts/merge_lora.py \</span>
<span> &nbsp;--checkpoint_dir "checkpoints/mistralai/Mistral-7B-Instruct-v0.1" \</span>
<span> &nbsp;--lora_path "out/lora/alpaca/Mistral-7B-Instruct-v0.1/lit_model_lora_finetuned.pth" \</span>
<span> &nbsp;--out_dir "out/lora_merged/Mistral-7B-Instruct-v0.1/"</span>
<span>
cp checkpoints/mistralai/Mistral-7B-Instruct-v0.1/*.json \</span>
<span>&nbsp;&nbsp;out/lora_merged/Mistral-7B-Instruct-v0.1/</span></pre><p><strong>6) Evaluate</strong></p><pre><span>python eval/lm_eval_harness.py \</span>
<span> &nbsp;--checkpoint_dir "out/lora_merged/Mistral-7B-Instruct-v0.1/" \</span>
<span> &nbsp;--eval_tasks "[arithmetic_2ds, ..., truthfulqa_mc]" \</span>
<span> &nbsp;--precision "bf16-true" \</span>
<span> &nbsp;--batch_size 4 \</span>
<span> &nbsp;--num_fewshot 0 \</span>
<span>&nbsp;&nbsp;--save_filepath "results.json"</span></pre><p><strong>7) Use</strong></p><pre><span>python chat/base.py \ </span>
<span>&nbsp;&nbsp;--checkpoint_dir "out/lora_merged/Mistral-7B-Instruct-v0.1/"</span></pre><h2 id="toc4">Choosing a Good Base Model</h2><p><span>The first task was to select a competent base model for the LoRA experiments. For this, I focused on models that were not already instruction-finetuned: </span><a href="https://arxiv.org/abs/2309.05463"><span>phi-1.5 1.3B</span></a><span>, </span><a href="https://arxiv.org/abs/2310.06825"><span>Mistral 7B</span></a><span>, </span><a href="https://arxiv.org/abs/2307.09288"><span>Llama 2 7B</span></a><span>, Llama 2 13B, and </span><a href="https://falconllm.tii.ae/"><span>Falcon 40B</span></a><span>. Note that all experiments were run on a single A100 GPU.</span></p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage2.jpg" alt="" width="1764" height="322" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage2.jpg 1764w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage2-300x55.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage2-1024x187.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage2-1536x280.jpg 1536w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage2-300x55@2x.jpg 600w" sizes="(max-width: 1764px) 100vw, 1764px"></p><p><span>As we can see from the table above, the Mistral 7B model performs extraordinarily well on the math benchmarks. Meanwhile, the phi-1.5 1.3B model showcases impressive TruthfulQA MC2 performance given its relatively small size. For some reason, Llama 2 13B struggles with the arithmetic benchmarks, whereas the smaller Llama 2 7B outperforms it significantly in that area.</span></p><p><span>Since researchers and practitioners are currently speculating that phi-1.5 1.3B and Mistral 7B might have been trained on benchmark test data, I chose not to use them in my experiments. Moreover, I believed that selecting the smallest of the remaining models would provide the most room for improvement while maintaining lower hardware requirements. </span><b>Therefore, the remainder of this article will focus on Llama 2 7B.</b></p><h2 id="toc5">Evaluating the LoRA Defaults</h2><p><span>First, I evaluated LoRA finetuning with the following default settings (these can be changed in the </span><a href="https://github.com/Lightning-AI/lit-gpt/blob/bf60124fa72a56436c7d4fecc093c7fc48e84433/finetune/lora.py#L38"><span>finetune/lora.py</span></a><span> script):</span></p><pre><span># Hyperparameters</span>
<span>learning_rate = 3e-4</span>
<span>batch_size = 128</span>
<span>micro_batch_size = 1</span>
<span>max_iters = 50000&nbsp; # train dataset size</span>
<span>weight_decay = 0.01</span>
<span>lora_r = 8</span>
<span>lora_alpha = 16</span>
<span>lora_dropout = 0.05</span>
<span>lora_query = True</span>
<span>lora_key = False</span>
<span>lora_value = True</span>
<span>lora_projection = False</span>
<span>lora_mlp = False</span>
<span>lora_head = False</span>
<span>warmup_steps = 100</span></pre><p><span>(Note that the batch size is 128, but we are using gradient accumulation with a microbatch size of 1 to save memory; it results in the equivalent training trajectory as regular training with batch size 128. If you are curious about how gradient accumulation works, please see my article </span><a href="https://lightning.ai/blog/gradient-accumulation/"><span>Finetuning LLMs on a Single GPU Using Gradient Accumulation</span></a><span>).</span></p><p><span>This configuration trained 4,194,304 LoRA parameters out of a total of 6,738,415,616 trainable parameters and took approximately 1.8 hours on my machine using a single A100. The maximum memory usage was 21.33 GB.</span></p><p><span>To gauge the variance, I repeated the experiment three times to observe the fluctuation in performance between runs.</span></p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage12.jpg" alt="" width="899" height="577" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage12.jpg 1999w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage12-300x193.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage12-1024x657.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage12-1536x986.jpg 1536w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage12-300x193@2x.jpg 600w" sizes="(max-width: 899px) 100vw, 899px"></p><p><span>As we can see in the table above, the performance between runs is very consistent and stable. It’s also worth noting that the LoRA default model became really bad at arithmetic, but this is probably to be expected as Alpaca does not contain (m)any arithmetic tasks to the best of my knowledge.</span></p><p><span>In addition, I also looked at the 7B Llama 2 version that has been instruction-finetuned by Meta using RLHF. As we can see based on the table below, the arithmetic performance is also worse for Meta’s Llama 2 Chat model as well. However, the Chat model is much improved on the other benchmarks (except BLiMP), which we can use as a reference that we want to approach with LoRA finetuning.</span></p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage10.jpg" alt="" width="1424" height="260" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage10.jpg 1424w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage10-300x55.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage10-1024x187.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage10-300x55@2x.jpg 600w" sizes="(max-width: 1424px) 100vw, 1424px"></p><h2 id="toc6">Memory Savings with QLoRA</h2><p><span>Before we start tuning the LoRA hyperparameters, I wanted to explore the trade-off between modeling performance and memory savings provided by QLoRA (the popular quantized LoRA technique by </span><a href="https://arxiv.org/abs/2305.14314"><span>Dettmers et al</span></a><span>).&nbsp;</span></p><p><span>We can enable QLoRA via the </span><span>–quantize</span><span> flag (here with 4-bit Normal Float type) in Lit-GPT as follows:</span></p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage9.jpg" alt="" width="618" height="218" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage9.jpg 1088w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage9-300x106.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage9-1024x361.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage9-300x106@2x.jpg 600w" sizes="(max-width: 618px) 100vw, 618px"></p><p><span>In addition, I also tried 4-bit floating point precision as a control. Below is the impact on the training time and maximum memory usage:</span></p><p><span>Default LoRA (with bfloat-16):</span></p><ul><li><span>Training time: 6685.75s</span></li><li><span>Memory used: 21.33 GB</span></li></ul><p><span>QLoRA via –</span><span>-quantize “bnb.nf4”</span><span>:</span></p><ul><li><span>Training time: 10059.53s</span></li><li><span>Memory used: 14.18 GB</span></li></ul><p><span>QLoRA via </span><span>–quantize “bnb.fp4”</span><span>:</span></p><ul><li><span>Training time: 9334.45s</span></li><li><span>Memory used: 14.19 GB</span></li></ul><p><span>We can see that QLoRA decreases the memory requirements by almost 6 GB. However, the tradeoff is a 30% slower training time, which is to be expected due to the additional quantization and dequantization steps.</span></p><p><span>Next, let’s take a look at how QLoRA training affects the model performance:</span></p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage3.jpg" alt="" width="1728" height="356" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage3.jpg 1728w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage3-300x62.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage3-1024x211.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage3-1536x316.jpg 1536w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage3-300x62@2x.jpg 600w" sizes="(max-width: 1728px) 100vw, 1728px"></p><p><span>As we can see in the table above, QLoRA does have a small impact on the model performance compared to regular QLoRA. The model improves on the arithmetic benchmarks but declines on the MMLU Global Facts benchmark.&nbsp;</span></p><p><span>Since the memory savings are quite substantial (which usually outweighs the longer training time since it allows users to run the models on smaller GPUs), I will use QLoRA for the remainder of the article. </span></p><h2 id="toc7">Learning Rate Schedulers and SGD</h2><p><span>I used the </span><a href="https://arxiv.org/abs/1711.05101"><span>AdamW</span></a><span> optimizer for all the previous experiments since it’s a common choice for LLM training. However, it’s well known that the Adam optimizer can be quite memory-intensive. This is because it introduces and tracks two additional parameters (the moments </span><i><span>m</span></i><span> and </span><i><span>v</span></i><span>) for each model parameter. Large language models (LLMs) have many model parameters; for instance, our Llama 2 model has 7 billion model parameters.</span></p><p><span>This section explores whether it’s worthwhile swapping AdamW with an SGD optimizer. However, for SGD optimizers it’s especially important to also introduce a learning rate scheduler. I opted for a cosine annealing schedule that lowers the learning rate after each batch update.</span></p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage11.jpg" alt="" width="603" height="452" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage11.jpg 1920w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage11-300x225.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage11-1024x768.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage11-1536x1152.jpg 1536w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage11-300x225@2x.jpg 600w" sizes="(max-width: 603px) 100vw, 603px"></p><p><span>If you are interested in more details on using learning rate schedulers in PyTorch, I have a lecture on it </span><a href="https://lightning.ai/courses/deep-learning-fundamentals/unit-6-overview-essential-deep-learning-tips-tricks/unit-6.2-learning-rates-and-learning-rate-schedulers/"><span>here</span></a><span>.</span></p><p><span>Unfortunately, swapping AdamW with SGD resulted in only minor memory savings.</span></p><ul><li aria-level="1"><span>AdamW: 14.18 GB</span></li><li aria-level="1"><span>SGD: 14.15 GB</span></li></ul><p><span>This is likely due to the fact that the most memory is spend on large matrix multiplications rather than keeping additional parameters in memory.</span></p><p><span>Even though SGD does not provide us with notable memory savings, let’s still have a quick look at the resulting model performance:</span></p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage13.jpg" alt="" width="1754" height="264" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage13.jpg 1754w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage13-300x45.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage13-1024x154.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage13-1536x231.jpg 1536w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage13-300x45@2x.jpg 600w" sizes="(max-width: 1754px) 100vw, 1754px"></p><p><span>It seems that the performance of the SGD optimizer is comparable to that of AdamW. Interestingly, when a scheduler is added to AdamW, there’s an improvement in the TruthfulQA MC2 and MMLU Global Facts performances, but a decrease in arithmetic performance. (Note: TruthfulQA MC2 is a widely recognized benchmark featured in other public leaderboards.) For the time being, we won’t place too much emphasis on the arithmetic performance and will proceed with the remaining experiments in this article using AdamW with a scheduler.</span></p><p><span>If you want to reproduce these experiments, I found that the best AdamW learning rate was 3e-4 with a decay rate of 0.01. The best SGD learning rate was 0.1, with a momentum of 0.9. I used an additional 100 steps of learning rate warmup in both cases.</span></p><p><span>(Based on these experiments, the cosine scheduler </span><a href="https://github.com/Lightning-AI/lit-gpt/pull/626"><span>has been added to Lit-GPT</span></a><span> and is now enabled by default.) </span></p><h2 id="toc8">Iterating Over the Dataset Multiple Times</h2><p><span>So far, I have trained all models with 50k iterations — the Alpaca dataset has 50k training examples. The obvious question is whether we can improve the model performance by iterating over the training set multiple times, so I ran the previous experiment with 100k iterations, which is a 2-fold increase:</span></p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage6.jpg" alt="" width="1756" height="266" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage6.jpg 1756w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage6-300x45.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage6-1024x155.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage6-1536x233.jpg 1536w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage6-300x45@2x.jpg 600w" sizes="(max-width: 1756px) 100vw, 1756px"></p><p><span>Interestingly, the increased iterations result in worse performance across the board. The decline is most significant for the arithmetic benchmarks. My hypothesis is that the Alpaca dataset does not contain any related arithmetic tasks, and the model actively unlearns basic arithmetic when it focuses more on other tasks.</span></p><p><span>Anyway, I would be lying if I said this outcome wasn’t welcome. This way, I can continue with the shorter 50k iteration experiments for the remainder of this article.</span></p><h2 id="toc9">LoRA Hyperparameter Tuning Part 1: LoRA for All Layers</h2><p><span>Now that we have explored the basic settings surrounding the LoRA finetuning scripts, let’s turn our attention to the LoRA hyperparameters themselves. By default, LoRA was only enabled for the Key and Query matrices in the multi-head self-attention blocks. Now, we are also enabling it for the Value matrix, the projection layers, and the linear layers:</span></p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage18.jpg" alt="" width="395" height="335" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage18.jpg 1046w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage18-300x255.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage18-1024x869.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage18-300x255@2x.jpg 600w" sizes="(max-width: 395px) 100vw, 395px"></p><h2 id="toc10">LoRA Hyperparameter Tuning Part 2: Increasing R</h2><p><span>One of the most important LoRA parameters is “r”, which determines the rank or dimension of the LoRA matrices, directly influencing the complexity and capacity of the model. A higher “r” means more expressive power but can lead to overfitting, while a lower “r” can reduce overfitting at the expense of expressiveness. Keeping LoRA enabled for all layers, let’s increase the r from 8 to 16 and see what impact this has on the performance:</span><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage17.jpg" alt="" width="1756" height="322" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage17.jpg 1756w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage17-300x55.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage17-1024x188.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage17-1536x282.jpg 1536w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage17-300x55@2x.jpg 600w" sizes="(max-width: 1756px) 100vw, 1756px"></p><p><span>We can see that just increasing r by itself made the results worse, so what happened? Let’s find out in the next section.</span></p><h2 id="toc11">LoRA Hyperparameter Tuning Part 3: Changing Alpha</h2><p><span>In the previous section, we increase the matrix rank r while leaving LoRA’s alpha parameter unchanged. A higher “alpha” would place more emphasis on the low-rank structure or regularization, while a lower “alpha” would reduce its influence, making the model rely more on the original parameters. Adjusting “alpha” helps in striking a balance between fitting the data and preventing overfitting by regularizing the model.</span></p><p><span>As a rule of thumb, it’s usually common to choose an alpha that is twice as large as the rank when finetuning LLMs (note that this is different when working with diffusion models). Let’s try this out and see what happens when we increase alpha two-fold:</span></p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage8.jpg" alt="" width="1768" height="380" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage8.jpg 1768w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage8-300x64.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage8-1024x220.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage8-1536x330.jpg 1536w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage8-300x64@2x.jpg 600w" sizes="(max-width: 1768px) 100vw, 1768px"></p><p><span>As we can see, increasing alpha to 32 now yields our best model thus far! But again we bought&nbsp; this improvement with a larger number of parameters to be trained:</span></p><p><span>r=8:</span></p><ul><li><span>Number of trainable parameters: 20,277,248</span></li><li><span>Number of non trainable parameters: 6,738,415,616</span></li><li><span>Memory used: 16.42 GB</span></li></ul><p><span>r=16:</span></p><ul><li><span>Number of trainable parameters: 40,554,496</span></li><li><span>Number of non trainable parameters: 6,738,415,616</span></li><li><span>Memory used: 16.47 GB</span></li></ul><p><span>However, the number of trainable parameters is still small enough that it doesn’t noticeably impact the peak memory requirements.</span></p><p><span>Anyways, we are now finally starting to make some gains and improve the model performance by more noticeable margins. So, let’s keep going and see how far we can push this by increasing the rank and alpha:</span></p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage4.jpg" alt="" width="1770" height="574" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage4.jpg 1770w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage4-300x97.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage4-1024x332.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage4-1536x498.jpg 1536w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage4-300x97@2x.jpg 600w" sizes="(max-width: 1770px) 100vw, 1770px"></p><p><span>I also ran additional experiments with exceptionally large ranks (512, 1024, and 2048), but these resulted in poorer outcomes. Some of the runs didn’t even converge to a near-zero loss during training, which is why I didn’t add them to the table.</span></p><p><span>So far, we can note that the r=256 and alpha=512 model in the last row resulting in the best performance overall so far. As an additional control experiments, I repeated the runs with an alpha of 1 and noticed that a large alpha value was indeed necessary for the good performance:</span></p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage14.jpg" alt="" width="1764" height="774" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage14.jpg 1764w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage14-300x132.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage14-1024x449.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage14-1536x674.jpg 1536w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage14-300x132@2x.jpg 600w" sizes="(max-width: 1764px) 100vw, 1764px"></p><p><span>I also repeated the experiments with alpha values of 16 and 32, and I observed the same worse performance compared to choosing the alpha value as two-times the rank.</span></p><h2 id="toc12">LoRA Hyperparameter Tuning Part 3: Very Large R</h2><p><span>For the final tuning experiment of this article, I wanted to further optimize the alpha value of the best model from the previous section (r=256, last row), suspecting that it might be a bit too large.</span></p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage15.jpg" alt="" width="1758" height="472" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage15.jpg 1758w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage15-300x81.jpg 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage15-1024x275.jpg 1024w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage15-1536x412.jpg 1536w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage15-300x81@2x.jpg 600w" sizes="(max-width: 1758px) 100vw, 1758px"></p><p><span>As seen in the table above, choosing a large alpha value appears to be crucial when increasing the rank.</span></p><p><span>For the QLoRA model with r=256 and a=512, it’s evident that our model has made significant improvements over the base model. The only area where the finetuned model underperforms compared to the base model is in 4-digit arithmetic. However, this is understandable, considering the Alpaca dataset probably did not contain such training examples.</span></p><h2 id="toc13">Leaderboard Submission</h2><p>We know that in machine learning, we should not use the test set multiple times. Otherwise, we risk over-optimizing to a specific task. Hence, it’s recommended to validate a model on a final independent dataset.</p><p>Coincidentally, there’s currently the <a href="https://llm-efficiency-challenge.github.io/">NeurIPS LLM Efficiency challenge</a> under way, which is focused on finetuning an LLM on a single GPU. Since I was curious to see how the Llama-2 7B base model compares to our best LoRA model finetuned on Alpaca, I submitted both the base and the finetune model to their leaderboard.</p><p><img decoding="async" loading="lazy" src="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/Screenshot-2023-10-12-at-8.52.49%E2%80%AFPM.png" alt="" width="471" height="174" srcset="https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/Screenshot-2023-10-12-at-8.52.49 https://lightning.ai/pages/community/lora-insights/PM.png 972w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/Screenshot-2023-10-12-at-8.52.49 https://lightning.ai/pages/community/lora-insights/PM-300x110.png 300w, https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/Screenshot-2023-10-12-at-8.52.49 https://lightning.ai/pages/community/lora-insights/PM-300x110@2x.png 600w" sizes="(max-width: 471px) 100vw, 471px"></p><p>(Note that the model above is actually not one of the best models, representing r=256 and alpha=256. The results for the best model r=256 and alpha=512, are still pending.)</p><p>We can see that the (Q)LoRA finetuning, which took 10522.77s (~3h) to train and required 19.24 GB GPU memory with the r=256 setting, improved the performance on several but not all benchmarks. The performance could potentially be improved by considering different finetuning datasets other than Alpaca and considering alignment techniques such as RLHF, which I explained in more detail <a href="https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives">here</a>.</p><h2 id="toc14">Conclusion</h2><p><span>This article explored the various knobs we can tune when training custom LLMs using LoRA. We found that QLoRA is a great memory-saver even though it comes at an increased runtime cost. Moreover, while learning rate schedulers can be beneficial, choosing between AdamW and SGD optimizers makes little difference. And iterating over the dataset more than once can make the results even worse. The best bang for the buck can be achieved by optimizing the LoRA settings, including the rank. Increasing the rank will result in more trainable parameters, which could lead to higher degrees of overfitting and runtime costs. However, when increasing the rank, choosing the appropriate alpha value is important.&nbsp;</span></p><p><span>This article was by no means exhaustive and in the sense that I did not have the time and resources to explore all possible configurations. Also, future improvements could be achieved by considering other datasets and models.</span></p><p><span>I hope that you can gain one or the other insight that you can apply to your projects. I kept the background information and explanations on various concepts like LoRA, learning rate schedulers, gradient accumulation, and so on to a minimum so that this article doesn’t not become unreasonably longer. However, I am more than happy to chat if you have any questions or concerns. You can reach me on </span><a href="https://twitter.com/rasbt"><span>X/Twitter</span></a><span> or </span><a href="https://linkedin.com/in/sebastianraschka"><span>LinkedIn</span></a> or reach out to <a href="https://twitter.com/LightningAI">@LightningAI</a><span>.</span></p><p><span>If you found this article useful, I would appreciate it if you could share it with your colleagues.</span></p><p><span>For general feedback, suggestions, or improvements to Lit-GPT, please feel free to use the </span><a href="https://github.com/Lightning-AI/lit-gpt"><span>GitHub issue tracker</span></a><span>.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New AC technology uses 60% less energy (186 pts)]]></title>
            <link>https://www.technologyreview.com/2023/10/04/1080128/2023-climate-tech-companies-blue-frontier-air-conditioning-energy-storage-climate-technology/</link>
            <guid>37870737</guid>
            <pubDate>Fri, 13 Oct 2023 14:01:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.technologyreview.com/2023/10/04/1080128/2023-climate-tech-companies-blue-frontier-air-conditioning-energy-storage-climate-technology/">https://www.technologyreview.com/2023/10/04/1080128/2023-climate-tech-companies-blue-frontier-air-conditioning-energy-storage-climate-technology/</a>, See on <a href="https://news.ycombinator.com/item?id=37870737">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>To meet this rising demand, 10 new AC units will be sold every second until 2050, according to estimates from <a href="https://www.iea.org/news/air-conditioning-use-emerges-as-one-of-the-key-drivers-of-global-electricity-demand-growth">the International Energy Agency</a>. But perversely, AC is itself a big contributor to greenhouse gases and will exacerbate climate change unless the technology improves.&nbsp;</p>  <p>Blue Frontier has one promising solution. Its AC system works to reduce humidity and cool the air in separate processes. This matters because maintaining the humidity in a space has as much impact on people’s comfort as managing temperature. But most AC systems prioritize the latter. What’s more, conventional humidity control <a href="https://www.nrel.gov/news/press/2022/nrel-shows-impact-of-controlling-humidity-on-greenhouse-gas-emissions.html#:~:text=The%20researchers%20calculated%20air%20conditioning,million%20tons%20from%20removing%20humidity.">generates even more greenhouse gases</a> than cooling the air.&nbsp;</p> 
 <p>Blue Frontier’s approach has two steps: First, a salty mixture known as <a href="https://www.technologyreview.com/2023/07/26/1076731/materials-air-conditioning/">a desiccant</a> sucks moisture out of the air, reducing its humidity. Then, some of that now-dry air moves past a wet surface. Water evaporates back into the dry air and lowers its temperature (a process known as evaporative cooling). That cooled air then passes by the remaining air in the system and cools it, too.&nbsp;</p>  <p>The company says this process makes its AC units three times more efficient than conventional systems and reduces their overall energy consumption by more than 60%.&nbsp;</p> 
 <hr>  <h2><strong>Key indicators</strong></h2>  <ul> <li><strong>Industry: </strong>Air conditioning&nbsp;</li>    <li><strong>Founded: </strong>2017</li>    <li><strong>Headquarters: </strong>Boca Raton, Florida, USA</li>    <li><strong>Notable fact: </strong>Blue Frontier is licensing technology originally developed at the US National Renewable Energy Laboratory, which remains a close collaborator today.<strong>&nbsp;</strong></li> </ul>  <hr>  <h3><strong>Potential for impact</strong></h3>  <p>Air conditioners have gotten much more efficient over the years, but they are still responsible for <a href="https://www.sciencedirect.com/science/article/pii/S2542435122000940">about 4%</a> of greenhouse gases released globally every year. And emissions from cooling may be five times greater by 2050, according to <a href="https://www.sciencedirect.com/science/article/pii/S2542435122000940">researchers at the US National Renewable Energy Laboratory</a>. Blue Frontier’s technology could help rein in those emissions even as air conditioning becomes more essential to daily life.&nbsp;</p>  <p>Air conditioners produce emissions by consuming electricity (often generated from fossil fuels) and by leaking refrigerants (which are potent greenhouse gases). Operating more efficiently allows Blue Frontier’s units to use less power. The units also contain alternative refrigerants, such as propane or a chemical compound known as R454B, that don’t pollute as much as the typical kind, known as hydrofluorocarbons.&nbsp;</p>  <p>Another important feature of the startup’s system is energy storage. The salty brew absorbs moisture from the humid air during the day, but it can be dried out by a heat pump at night when electricity demand is lower. That way the drying process doesn’t place as great a burden on the grid, which effectively is a form of energy storage. Then, when the sun comes up and temperatures start to climb, Blue Frontier’s AC can run for about four hours on the energy stored within that mixture.&nbsp;</p>  <p>That’s an important development, because the strain air conditioning puts on the grid during the hottest days of the year is a leading cause of blackouts and brownouts. Storing energy could shift much of that demand to off-peak times and make it easier to manage grids, particularly as they incorporate more renewable power, which can vary with the weather or time of day.&nbsp;&nbsp;</p> </div><div><p>After factoring in the system’s improved efficiency, alternative refrigerants, and ability to store energy, Blue Frontier estimates its air conditioner reduces greenhouse gas emissions by more than 80% compared to a conventional unit.&nbsp;</p></div><div><p>Blue Frontier’s CEO Daniel Betts likes to compare the transformative power of more efficient AC to that of LED lightbulbs. But LED adoption in the US was driven by efficiency standards set by the federal government and, eventually, <a href="https://www.architecturaldigest.com/story/incandescent-light-bulb-ban-what-you-need-to-know">a nationwide ban on incandescent bulbs</a>. No similar ban is on the horizon for current AC systems.</p>  <p>In addition, today’s technical standards and performance rating systems for AC systems (such as Energy Star in the US) <a href="https://rmi.org/when-heat-becomes-deadly-the-importance-of-next-generation-air-conditioning/">don’t evaluate</a> systems’ ability to manage both humidity and temperature, which could put new technologies like Blue Frontier’s at a disadvantage.&nbsp;</p> 

 <p>And Blue Frontier will face plenty of competition, including from established industry leaders like <a href="https://globalcoolingprize.org/">Daikin</a> that are also developing advanced cooling. That said, demand for AC is <a href="https://www.iea.org/news/air-conditioning-use-emerges-as-one-of-the-key-drivers-of-global-electricity-demand-growth">expected to skyrocket</a>, and a variety of approaches could ultimately succeed.&nbsp;&nbsp;</p>  <h3><strong>When</strong></h3>  <p>So far, the company has raised at least $26 million through grants, prizes, seed funding, and a <a href="https://www.prnewswire.com/news-releases/breakthrough-energy-ventures-leads-20m-series-a-for-blue-frontiers-game-changing-sustainable-energy-storing-air-conditioning-301594941.html">Series A round</a> in July 2022 led by Breakthrough Energy Ventures. Betts says that’s enough to get them through the end of 2024.&nbsp;</p>  <p>Blue Frontier’s first product will be an AC unit with a capacity similar to the air conditioners most commonly used today in commercial buildings. Eventually, the company hopes to make units suitable for homes.&nbsp;&nbsp;</p>  <h3><strong>Next steps&nbsp;</strong></h3>  <p>Two of Blue Frontier’s AC units are currently being field tested, and the company has tentative plans to install two more by the end of this year. Next year, it hopes to have 40 AC units in field tests so that it can collect enough performance data to prove their viability.&nbsp;</p>  <p>Betts says the company will likely raise a Series B in 2024 to start manufacturing more units, with an aim to begin selling them in 2025.</p>  <p><em><strong>Explore&nbsp;<a href="https://www.technologyreview.com/2023/10/04/1080528/2023-climate-tech-companies-electric-vehicles-batteries-carbon-removal-energy-storage/" target="_blank">the 2023 list of 15 Climate Tech Companies to Watch</a>.</strong></em> </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tainting the CSAM client-side scanning database (236 pts)]]></title>
            <link>https://blog.xot.nl/2023/10/11/tainting-the-csam-client-side-scanning-database/index.html</link>
            <guid>37870557</guid>
            <pubDate>Fri, 13 Oct 2023 13:47:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.xot.nl/2023/10/11/tainting-the-csam-client-side-scanning-database/index.html">https://blog.xot.nl/2023/10/11/tainting-the-csam-client-side-scanning-database/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=37870557">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="canvas">
  <p>The proposal of the European Commission for <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=COM%3A2022%3A209%3AFIN">a
  regulation on preventing and combatting the sexual abuse and sexual
  exploitation of children</a> is <a href="https://www.tweedekamer.nl/debat_en_vergadering/uitgelicht/rondetafelgesprek-over-technieken-om-online-kindermisbruik-te">currently
  discussed</a> in Dutch parliament. I recently wrote <a href="https://blog.xot.nl/2023/08/26/end-to-end-encryptie-en-risico-s-client-side-scanning/index.html">about
  some concerns</a> and <a href="https://blog.xot.nl/2023/10/04/ddos-ing-client-side-scanning/index.html">the
  risk of a DDoS attack</a>. It turns out it is also possible to taint
  the database of images of known child sexual abuse material (CSAM),
  allowing an adversary to trick the client-side scanning system to also
  trigger an alarm for other, non CSAM, material. Client side scanning
  could thus be vulnerable to <em>undetectable</em> function creep.</p>
  <p>Client-side scanning works by matching images on a user device
  against the fingerprints stored in this central database. There is no
  independent way for the service providers or the devices to verify
  that the fingerprints in this data actual correspond to CSAM.
  Therefore the devices have to fully trust this database that this is
  indeed the case. As such the proposal already suffers from a
  significant risk of <em>function creep</em>, as the scope of the
  fingerprints contained in the database could be extended to allow the
  detection of other material, like those propagating terrorism or other
  hateful or abusive content. To be clear this is absolutely out of
  scope of the current proposal for a regulation that is strictly
  limited to the prevention of the spread of CSAM. But other legislation
  could be enacted in the future to broaden the scope, without any need
  to change anything to the detection system already in place to detect
  CSAM. This significantly lowers the barrier to enact such legislation.
  Hence the risk of function creep. But at least any push for such
  function creep will happen in plain sight.</p>
  <p>I am more concerned about an <em>surreptitious</em> form of
  function creep that appears to crop up with client-side scanning.</p>
  <p>Clearly, as new CSAM is being discovered, its spread needs to be
  prevented by adding the fingerprints of this newly discovered CSAM to
  the database. Strict procedures are (purportedly) in place to
  guarantee that only fingerprints of known CSAM are added to this
  database. (Otherwise, fingerprints of other offensive content could
  easily be added.)</p>
  <p>Unfortunately, it is <em>impossible</em> to guarantee this.</p>
  <p>Consider an entity that is allowed to propose new entries to the
  CSAM database. A <a href="https://www.usenix.org/conference/usenixsecurity23/presentation/prokos">recent
  paper</a> by Jonathan Prokos <em>et. al.</em>, shows that it is
  possible for an attacker to create a variant of some arbitrary source
  image that matches some target fingerprint. A <em>malicious</em>
  entity could <em>surreptitiously</em> taint the database with other
  offensive content using these techniques as follows:</p>
  <ul>
  <li>It takes an image <span><em>A</em></span> of
  some offensive content, not being CSAM, for which it wants to add a
  fingerprint to the database. The entity keeps <span><em>A</em></span> secret.</li>
  <li>It computes its fingerprint <span><em>f</em>(<em>A</em>)</span>. (Although the
  algorithms to compute this are proprietary, researchers have reversed
  engineered the commonly used PhotoDNA algorithm, and a binary
  implementation of PhotoDNA is available to compute the
  fingerprint.)</li>
  <li>It creates a convincingly looking synthetic variant of CSAM using
  recent AI techniques (or waits until it discovers a new image as being
  CSAM). Call this image <span><em>B</em></span>.</li>
  <li>Using the techniques from Prokos <em>et. al.</em>, it subtly
  modifies this source image <span><em>B</em></span>
  to create another image <span><em>B</em>′</span>
  whose fingerprint <span><em>F</em>(<em>B</em>′)</span> matches the target
  fingerprint <span><em>F</em>(<em>A</em>)</span>.
  In other words <span><em>f</em>(<em>B</em>′) = <em>f</em>(<em>A</em>)</span>.
  Note that the modifications to <span><em>B</em></span> do <em>not visibly alter</em>
  the image, so <span><em>B</em>′</span> will still
  pass as CSAM.</li>
  <li>The malicious entity submits the altered image <span><em>B</em>′</span> to the database.</li>
  <li>Because <span><em>B</em>′</span> is visibly
  indistinguishable from <span><em>B</em></span>,
  which was constructed or selected to be CSAM, the fingerprint <span><em>f</em>(<em>B</em>′)</span> of <span><em>B</em>′</span> is accepted for inclusion in
  the database.</li>
  <li>But as by construction <span><em>f</em>(<em>B</em>′) = <em>f</em>(<em>A</em>)</span>,
  the malicious entity has now successfully ensured that the client-side
  scanning algorithm will also report any occurrence of <span><em>A</em></span> (the non-CSAM but otherwise
  deemed offensive image) to the abuse centre.</li>
  </ul>
  <p>This shows that the database can be tainted with non-CSAM material
  by an entity that can submit entries to it. In the case of the
  proposed European regulation these are the Coordinating Authorities
  set up by each of the member states. Some of the member states
  (Hungary and Poland, for example) have shown certain authoritarian
  streaks, and should perhaps be less trusted with this new detection
  capability…</p>
  <p>The above attack is theoretical. The real question is of course
  whether this Would be an issue in practice?</p>
  <p>Suppose the database is tainted with image <span><em>A</em></span> (deemed offensive, but
  <em>not</em> being CSAM) as above. Then any person about to send this
  image will be notified that the scanner detected a possible case of
  CSAM, and that a report has been filed with the central reporting EU
  centre. Even though the EU Centre will quickly determine this is
  <em>not</em> a case of actual CSAM, this could still lead to chilling
  effects, as people may feel reluctant to use messaging apps to discuss
  anything sensitive as there is a (perceived) risk of being reported to
  the central EU Abuse centre. Even if this happens only
  occasionally.</p>
  <p>To really judge the impact of this attack in practice, it is
  important to also look at what happens when such a report is filed
  with the abuse centre. The report contains the image <span><em>A</em></span> (offensive perhaps, but not
  CSAM) and the fingerprint against which it matched. The abuse centre
  will look op the image <span><em>B</em>′</span>
  corresponding to the fingerprint (constructed by the malicious entity
  which looks like CSAM) and immediately conclude that <span><em>A</em></span> does not look at all like <span><em>B</em>′</span> and also is not CSAM. One could
  conclude that the abuse centre could thus easily spot the malicious
  entry in its database after a few of these reports all concerned with
  the same image, and delete the corresponding fingerprint from the
  database. If that were the case, this avenue of attack would not be a
  problem in practice. This assumes, however, that the abuse centre
  keeps track of such false positives over time to detect such
  maliciously uploaded fingerprints. This may or may not be the
  case.</p>
  <p>Moreover, we cannot consider this particular attack and its
  potential mitigation in isolation: we also need to consider other
  avenues of attack, and whether the mitigation proposed above perhaps
  <em>enables</em> other forms of attack. This brings us back to the
  DDoS attack on client-side scanning that <a href="https://blog.xot.nl/2023/10/04/ddos-ing-client-side-scanning/index.html">I
  wrote about earlier</a>. Because that attack essentially uses the
  possibility to find fingerprint collisions in the opposite direction:
  it creates an innocent image whose fingerprint matches the fingerprint
  of known CSAM in the database. As discussed</p>
  <blockquote>
  <p>Removing these fingerprints from the database is clearly not an
  option, as this would prevent the detection of <em>actual</em> CSAM
  that matches these fingerprints.</p>
  </blockquote>
  <p>So here we find the EU abuse centre confronted with an image that
  is clearly not CSAM, but perhaps could be considered offensive to
  certain governments. How does it determine whether the fingerprint
  being matched belongs to actual CSAM (uploaded in good faith) or
  synthesised (uploaded maliciously)? The judgement would be highly
  contextual and be wrong ever so often. The mere fact that a particular
  fingerprint is or is not the target of a DDoS attack (the number of
  matches could give at least that away) does not necessarily offer any
  resolution. And even a non-CSAM image that is uploaded only
  occasionally but that triggers the client-side detection system could
  just as well be an image constructed to match the fingerprint of
  actual CSAM, just to try to trick the abuse centre into removing the
  fingerprint from the database.</p>
  <p>Also note that if the client-side scanning system would be
  structured slightly differently, with reports of possible CSAM only
  being forwarded to certain authorities (e.g.&nbsp;when reports concerning a
  Hungarian user would only be forwarded to the Hungarian authorities),
  this form of function creep <em>would not</em> necessarily be
  detected. This shows that the overall design of the full client-side
  scanning system, including the way reports are handled, matters a
  lot.</p>
      <p>
      In case you spot any errors on this page, please
      <a href="mailto:blog@xot.nl?subject=NOTIFICATION:%202023/10/11/tainting-the-csam-client-side-scanning-database/comment.">notify</a> me!
      </p>
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every app that adds AI looks like this (528 pts)]]></title>
            <link>https://botharetrue.substack.com/p/every-app-that-adds-ai-looks-like</link>
            <guid>37870437</guid>
            <pubDate>Fri, 13 Oct 2023 13:35:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://botharetrue.substack.com/p/every-app-that-adds-ai-looks-like">https://botharetrue.substack.com/p/every-app-that-adds-ai-looks-like</a>, See on <a href="https://news.ycombinator.com/item?id=37870437">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h4>Discover more from Both Are True</h4><p>Absurd, honest comedy delivered twice a weekish through the vulnerable personal essays of Alex Dobrenko: tv actor+writer to some, father to one, and friend to all.</p><p>Over 6,000 subscribers</p> </div><div dir="auto"><p><em><span>Hi and welcome to the first PSA of </span><strong><a href="https://open.substack.com/pub/botharetrue/p/both-are-trues-next-chapter-big-deal?r=bvz1&amp;utm_campaign=post&amp;utm_medium=web" rel="">Both Are True’s Season One: I’m (Not??) The Best.</a></strong><a href="https://open.substack.com/pub/botharetrue/p/both-are-trues-next-chapter-big-deal?r=bvz1&amp;utm_campaign=post&amp;utm_medium=web" rel=""> </a><span>This season is devoted to exploring themes of competition, etc. One such facet is how tech companies compete to all release AI-bullshit features that blow butt. </span></em></p><p><em><span>If you’d like to read the first piece of Season One, check it out here: </span><a href="https://botharetrue.substack.com/p/i-got-a-perfect-score-on-my-sat-and" rel="">I got a perfect score on my SAT and all I got was this lousy feeling of never being enough</a><span>.</span></em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1c37f1-41f8-48df-ac77-442be7deb4c1_1367x1367.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1c37f1-41f8-48df-ac77-442be7deb4c1_1367x1367.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1c37f1-41f8-48df-ac77-442be7deb4c1_1367x1367.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1c37f1-41f8-48df-ac77-442be7deb4c1_1367x1367.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1c37f1-41f8-48df-ac77-442be7deb4c1_1367x1367.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1c37f1-41f8-48df-ac77-442be7deb4c1_1367x1367.jpeg" width="1367" height="1367" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7b1c37f1-41f8-48df-ac77-442be7deb4c1_1367x1367.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1367,&quot;width&quot;:1367,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:235079,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1c37f1-41f8-48df-ac77-442be7deb4c1_1367x1367.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1c37f1-41f8-48df-ac77-442be7deb4c1_1367x1367.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1c37f1-41f8-48df-ac77-442be7deb4c1_1367x1367.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b1c37f1-41f8-48df-ac77-442be7deb4c1_1367x1367.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Omg yes I want all these things! How could you not click?? You’re human.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb3f5f2a-1720-496a-858b-dcbb95f6fd3c_1691x1024.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb3f5f2a-1720-496a-858b-dcbb95f6fd3c_1691x1024.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb3f5f2a-1720-496a-858b-dcbb95f6fd3c_1691x1024.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb3f5f2a-1720-496a-858b-dcbb95f6fd3c_1691x1024.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb3f5f2a-1720-496a-858b-dcbb95f6fd3c_1691x1024.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb3f5f2a-1720-496a-858b-dcbb95f6fd3c_1691x1024.jpeg" width="1456" height="882" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bb3f5f2a-1720-496a-858b-dcbb95f6fd3c_1691x1024.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:882,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:244262,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb3f5f2a-1720-496a-858b-dcbb95f6fd3c_1691x1024.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb3f5f2a-1720-496a-858b-dcbb95f6fd3c_1691x1024.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb3f5f2a-1720-496a-858b-dcbb95f6fd3c_1691x1024.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb3f5f2a-1720-496a-858b-dcbb95f6fd3c_1691x1024.jpeg 1456w" sizes="100vw"></picture></div></a></figure></div><p>Ok wow this is so cool! Look there’s even a photo of the whole planet lit up by the ‘aha’ moments of everyone using AI!! Can’t fuckin’ wait to change everything.</p><p>I mean…idk. What am I supposed to say here? The app doesn’t really  give me much detail…duh! That’s because the AI is super smart and I can tell it to do anything. </p><p>Silly dumb me being an idiot of the Old Way of Doing Things. </p><p>I can just let it rip! </p><p>How about… “Create a marketing campaign to get people excited about a new internet where things are easy. Include a mascot and a catch phrase.”</p><p>I hit enter and….</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dc1e5e7-9c2a-4cca-bf4a-a6a5c7326354_1122x621.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dc1e5e7-9c2a-4cca-bf4a-a6a5c7326354_1122x621.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dc1e5e7-9c2a-4cca-bf4a-a6a5c7326354_1122x621.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dc1e5e7-9c2a-4cca-bf4a-a6a5c7326354_1122x621.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dc1e5e7-9c2a-4cca-bf4a-a6a5c7326354_1122x621.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dc1e5e7-9c2a-4cca-bf4a-a6a5c7326354_1122x621.png" width="1122" height="621" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5dc1e5e7-9c2a-4cca-bf4a-a6a5c7326354_1122x621.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:621,&quot;width&quot;:1122,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:110343,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dc1e5e7-9c2a-4cca-bf4a-a6a5c7326354_1122x621.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dc1e5e7-9c2a-4cca-bf4a-a6a5c7326354_1122x621.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dc1e5e7-9c2a-4cca-bf4a-a6a5c7326354_1122x621.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dc1e5e7-9c2a-4cca-bf4a-a6a5c7326354_1122x621.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>It’s a race to the bottom. Companies see their idiot friends creating AI and they want a piece of that hype hype yum yum so they do it too. For example:</p><p><span>Here’s </span><a href="https://www.inc.com/sam-blum/ai-boom-full-copycats-trying-ride-viral-trend-thats-not-bad-business.html" rel="">some article about it</a><span>:</span></p><blockquote><p><span>Jason Corsello, CEO and general partner of Acadian Ventures, a venture firm focused on the future of work startups, explained that A.I. remains tantalizing for investors, even amid the </span><a href="https://www.inc.com/sam-blum/the-vc-market-has-never-been-worse-that-doesnt-mean-you-cant-get-startup-funding.html" rel="">historic downturn</a><span>. That may not be a good thing for startups, he cautions. "This area of A.I. is somewhat overhyped. It's over-invested, it's overvalued. When you're seeing seed-stage companies raise between $100 million and $150 million with nothing more than a pitch deck, that's a bit concerning."&nbsp;</span></p><p><span>But the froth isn't unfamiliar. The A.I. boom, and the crush of startups now competing for success, could be a product of </span><strong>copycat logic</strong><span>. </span><strong>As money is pumped into new firms, nobody wants to be left out</strong><span>, Oded Shenkar, a professor of management and human resources at Ohio State University, explains. "It's a common error to think of startups always as innovators," he says, "when you have a gold rush, of course, you're going to have more imitation."</span></p></blockquote><p>Ah ok great so basically all the companies are playing copycat with Daddy Andreesen's Money Slush until something dumb happens and one of them gets super rich? </p><p>Cool. </p><p>Meanwhile, the people must endure this: </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F886f3564-fc21-4df1-861f-277aee0cd031_1478x989.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F886f3564-fc21-4df1-861f-277aee0cd031_1478x989.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F886f3564-fc21-4df1-861f-277aee0cd031_1478x989.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F886f3564-fc21-4df1-861f-277aee0cd031_1478x989.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F886f3564-fc21-4df1-861f-277aee0cd031_1478x989.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F886f3564-fc21-4df1-861f-277aee0cd031_1478x989.png" width="1456" height="974" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/886f3564-fc21-4df1-861f-277aee0cd031_1478x989.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:974,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1319837,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F886f3564-fc21-4df1-861f-277aee0cd031_1478x989.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F886f3564-fc21-4df1-861f-277aee0cd031_1478x989.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F886f3564-fc21-4df1-861f-277aee0cd031_1478x989.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F886f3564-fc21-4df1-861f-277aee0cd031_1478x989.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Wow look at that really cool image of a fairy cat. </p><p>Um no that looks like it was made by a wood nymph on a godsized dose of LSD+speed who decided to ‘go for it’ and draw like a computer. </p><p>They don’t call it AI because they are not children.&nbsp;</p><p>All of Google is AI. </p><p>But you don’t see them bandying it around like a kid with new light up shoes. </p><p>On the other hand, you’ve got Canva promoting their new “Magic Design (TM”) which they have to make sure you understand is in Beta which is tech-speak for ‘it blows butt.’</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79cb0b2c-7973-4d6e-ad02-548234e21fc1_893x263.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79cb0b2c-7973-4d6e-ad02-548234e21fc1_893x263.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79cb0b2c-7973-4d6e-ad02-548234e21fc1_893x263.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79cb0b2c-7973-4d6e-ad02-548234e21fc1_893x263.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79cb0b2c-7973-4d6e-ad02-548234e21fc1_893x263.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79cb0b2c-7973-4d6e-ad02-548234e21fc1_893x263.png" width="893" height="263" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/79cb0b2c-7973-4d6e-ad02-548234e21fc1_893x263.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:263,&quot;width&quot;:893,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:30278,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79cb0b2c-7973-4d6e-ad02-548234e21fc1_893x263.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79cb0b2c-7973-4d6e-ad02-548234e21fc1_893x263.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79cb0b2c-7973-4d6e-ad02-548234e21fc1_893x263.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79cb0b2c-7973-4d6e-ad02-548234e21fc1_893x263.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Ok cool let’s give it a whirl:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbd55ae9-53a6-41b7-a33e-2ba273cb1ffa_1950x866.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbd55ae9-53a6-41b7-a33e-2ba273cb1ffa_1950x866.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbd55ae9-53a6-41b7-a33e-2ba273cb1ffa_1950x866.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbd55ae9-53a6-41b7-a33e-2ba273cb1ffa_1950x866.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbd55ae9-53a6-41b7-a33e-2ba273cb1ffa_1950x866.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbd55ae9-53a6-41b7-a33e-2ba273cb1ffa_1950x866.png" width="1456" height="647" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/dbd55ae9-53a6-41b7-a33e-2ba273cb1ffa_1950x866.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:647,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1144768,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbd55ae9-53a6-41b7-a33e-2ba273cb1ffa_1950x866.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbd55ae9-53a6-41b7-a33e-2ba273cb1ffa_1950x866.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbd55ae9-53a6-41b7-a33e-2ba273cb1ffa_1950x866.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbd55ae9-53a6-41b7-a33e-2ba273cb1ffa_1950x866.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Like come on this is dog shit and I mean an old dog who has trouble shitting:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F062aabb1-b227-40fa-ad94-46415d7a790b_1008x839.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F062aabb1-b227-40fa-ad94-46415d7a790b_1008x839.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F062aabb1-b227-40fa-ad94-46415d7a790b_1008x839.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F062aabb1-b227-40fa-ad94-46415d7a790b_1008x839.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F062aabb1-b227-40fa-ad94-46415d7a790b_1008x839.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F062aabb1-b227-40fa-ad94-46415d7a790b_1008x839.png" width="1008" height="839" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/062aabb1-b227-40fa-ad94-46415d7a790b_1008x839.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:839,&quot;width&quot;:1008,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:810339,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F062aabb1-b227-40fa-ad94-46415d7a790b_1008x839.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F062aabb1-b227-40fa-ad94-46415d7a790b_1008x839.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F062aabb1-b227-40fa-ad94-46415d7a790b_1008x839.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F062aabb1-b227-40fa-ad94-46415d7a790b_1008x839.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Stop it. </p><p>Stop trying to market garbage as “magic.”</p><p>AI is not magic. This is magic:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F012853c9-9c78-4e69-bda7-0516ab52672d_880x359.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F012853c9-9c78-4e69-bda7-0516ab52672d_880x359.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F012853c9-9c78-4e69-bda7-0516ab52672d_880x359.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F012853c9-9c78-4e69-bda7-0516ab52672d_880x359.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F012853c9-9c78-4e69-bda7-0516ab52672d_880x359.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F012853c9-9c78-4e69-bda7-0516ab52672d_880x359.jpeg" width="880" height="359" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/012853c9-9c78-4e69-bda7-0516ab52672d_880x359.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:359,&quot;width&quot;:880,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;cup and balls medieval style&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="cup and balls medieval style" title="cup and balls medieval style" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F012853c9-9c78-4e69-bda7-0516ab52672d_880x359.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F012853c9-9c78-4e69-bda7-0516ab52672d_880x359.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F012853c9-9c78-4e69-bda7-0516ab52672d_880x359.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F012853c9-9c78-4e69-bda7-0516ab52672d_880x359.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Look at how freaked out the dude leaning over is. His child has never seen him that way before.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f396b0-dbfe-4417-9681-e9c898625a0f_117x101.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f396b0-dbfe-4417-9681-e9c898625a0f_117x101.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f396b0-dbfe-4417-9681-e9c898625a0f_117x101.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f396b0-dbfe-4417-9681-e9c898625a0f_117x101.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f396b0-dbfe-4417-9681-e9c898625a0f_117x101.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f396b0-dbfe-4417-9681-e9c898625a0f_117x101.png" width="225" height="194.23076923076923" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/47f396b0-dbfe-4417-9681-e9c898625a0f_117x101.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:101,&quot;width&quot;:117,&quot;resizeWidth&quot;:225,&quot;bytes&quot;:33235,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f396b0-dbfe-4417-9681-e9c898625a0f_117x101.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f396b0-dbfe-4417-9681-e9c898625a0f_117x101.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f396b0-dbfe-4417-9681-e9c898625a0f_117x101.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47f396b0-dbfe-4417-9681-e9c898625a0f_117x101.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This dude is looking up like ‘no way he did that without god's help’</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c9b6492-c0af-4b0c-bdca-1ffce899178d_145x170.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c9b6492-c0af-4b0c-bdca-1ffce899178d_145x170.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c9b6492-c0af-4b0c-bdca-1ffce899178d_145x170.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c9b6492-c0af-4b0c-bdca-1ffce899178d_145x170.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c9b6492-c0af-4b0c-bdca-1ffce899178d_145x170.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c9b6492-c0af-4b0c-bdca-1ffce899178d_145x170.png" width="215" height="252.06896551724137" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7c9b6492-c0af-4b0c-bdca-1ffce899178d_145x170.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:170,&quot;width&quot;:145,&quot;resizeWidth&quot;:215,&quot;bytes&quot;:69578,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c9b6492-c0af-4b0c-bdca-1ffce899178d_145x170.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c9b6492-c0af-4b0c-bdca-1ffce899178d_145x170.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c9b6492-c0af-4b0c-bdca-1ffce899178d_145x170.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c9b6492-c0af-4b0c-bdca-1ffce899178d_145x170.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>If I see “now with AI-enabled assistant” anywhere on a website, I run away but first I throw the entire computer out the window (after making sure no one is under it). The entire system has been tainted by the AI-disease and now it will never be okay to use again. </p><p>I will pay money for you to not use the word AI anywhere on your app. Make that the premium tier and I will buy it this is hell why are you doing this to us.&nbsp;</p><p>And yes, as a person named Alex who is often called Al by friends, I have a personal stake in this. When I see “AI Magic” I think it’s saying I am magic or it is using my magic for its app and that’s illegal. </p><p><em>More of my hot takes on AI and tech:</em></p><p><a href="https://botharetrue.substack.com/p/can-everyone-kindly-shut-the-fuck" rel="">can everyone kindly shut the fuck up about AI</a></p><p><a href="https://botharetrue.substack.com/p/i-refuse-to-talk-to-you-w-those-stupid" rel="">i refuse to talk to you with those stupid ass goggles on your face</a></p><ol><li><p>Am I crazy about all this AI stuff or does it really suck? </p></li><li><p>Are you also someone who keeps getting tricked into thinking some AI-feature will be cool only to have your heart broken again and again?</p></li><li></li><li><p>Are there any good uses of AI I’m just not realizing (that market themselves as AI??)</p></li><li><p>What’s a non-AI non-tech good thing in your life?</p></li><li></li><li><p>Is this whole piece a big hipster-draped ‘the new tech is bad’ screed from a guy who is, according to several doctors, getting older?</p></li></ol><p><span>The good people at the writing collective Foster have asked me and </span></p><p><span> to come back and teach a workshop on how to write funny and vulnerably as part of their 4-week writing intensive called </span><strong>Season 4: </strong><em><strong>A More Beautiful Question</strong></em><span>. Here’s a quick description of the season. Check it out and lemme know if you have questions!</span></p><blockquote><p><em><span>“Seasons” are month-long initiations into the magic of writing and storytelling. Together, we’ll approach our writing not as a means of providing Answers, but as a way of </span><a href="https://fosterwriting.substack.com/p/frequently-unanswered-questions-fuqs" rel="">inhabiting the Questions</a><span> that matter to us, as I hope I exhibited in this essay. We’ll seek to dance with uncertainty instead of treating it as a problem to be solved. We’ll explore, play, and be in conversation with something larger than ourselves. And when it’s all said and done, we’ll each hit publish on a piece of writing that’s crackling with our energy and humanity. </span><a href="https://fosterwriting.substack.com/p/season-4-a-more-beautiful-question" rel="">Care to join us</a><span>?</span></em></p></blockquote></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Compact Calendar 2023-2024 (137 pts)]]></title>
            <link>https://davidseah.com/node/compact-calendar/</link>
            <guid>37869809</guid>
            <pubDate>Fri, 13 Oct 2023 12:24:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://davidseah.com/node/compact-calendar/">https://davidseah.com/node/compact-calendar/</a>, See on <a href="https://news.ycombinator.com/item?id=37869809">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-wrap">
			
		<!-- OPEN article -->
		<article id="17342" itemscope="" itemtype="http://schema.org/CreativeWork">
			
			<p>The Compact Calendar 2023-2024</p>
			
							
								
												
				<div itemprop="description">
									<div>
			

<h2>Visualize the Year Intuitively as a “Candy Bar of Time”</h2>

<p><span><img decoding="async" alt="Compact&nbsp;Calendar" loading="lazy" onclick="javascript:MDHPopUp('https://davidseah.com/_wpcontent/images/22/1229-compact-calendar-2023.jpg',1200,750,'Compact&nbsp;Calendar',1)" data-src="https://davidseah.com/_wpcontent/imgcache/images/22/1229-compact-calendar-2023.jpg" src="https://davidseah.com/_wpcontent/imgcache/images/22/1229-compact-calendar-2023.jpg"></span>

		</p></div>
 
 <div>
	<div>
			

<p>QUICK PDF DOWNLOADS <a href="https://davidseah.com/pub/downloads/pceo/calendar/CompactCalendar2023-US.pdf" target="_blank">US PDF</a> | <a href="https://davidseah.com/pub/downloads/pceo/calendar/CompactCalendar2023-A4.pdf" target="_blank">A4 PDF</a></p>

<p>The Compact Calendar presents days as a continuous candy bar of time. Weeks are presented as a stack of available time with no gaps, making it easier to count-out days naturally as you think.</p>

<p>You can plan up to an entire year on a single sheet of paper! Print out a stack of them and keep them handy for when you need to roughly define project milestones or calculate recurring dates. These are great for taking notes during a planning meeting!</p>

<p>I’ve heard of people using them for estimating the gestation period of pregnant animals and planning family vacations. I’d love to hear more about your use, so please <a href="https://davidseah.com/contact" target="_blank">send me an email</a> and share your story with me!</p>

<p><span><img decoding="async" alt="Compact&nbsp;Calendar&nbsp;Example" loading="lazy" onclick="javascript:MDHPopUp('https://davidseah.com/_wpcontent/images/11/1128-compact-calendar-03.jpg',900,600,'Compact&nbsp;Calendar&nbsp;Example',1)" data-src="https://davidseah.com/_wpcontent/imgcache/images/11/1128-compact-calendar-03.jpg" src="https://davidseah.com/_wpcontent/imgcache/images/11/1128-compact-calendar-03.jpg"></span>
You can easily use Microsoft Excel to print variations with your own start/end dates. For convenience, I’ve also made the Compact Calendar available in several downloadable packages, and many others have chipped-in with their own versions for their country.
Download the package you want in the sidebar on the right of the page.</p>

<h2>About the Compact Calendar Package</h2>

<p>If you download the Excel version, you can <strong>change the starting date</strong> to generate a new calendar for <strong>any year</strong> you need with your own holidays.</p>

<p>The download comes as a ZIP archive containing three <strong>Excel 2007</strong> templates and six <strong>PDF</strong> versions, for all three week styles in both A4 and US Letter sizes. Optionally, you can download just the PDFs in either A4 or US Letter sizes.</p>

<p>The week styles are:</p>

<ul>
<li>Week starting on Monday – your business working calendar, with <a href="https://en.wikipedia.org/wiki/ISO_8601" target="_blank">ISO 8601 week numbers</a>.</li>
<li>Week starting on Sunday – your typical home calendar week.</li>
<li>Week starting on Saturday – for countries that start the week on Saturday</li>
</ul>

<p>While the Excel templates include US holidays, it’s pretty easy to customize them for any country.</p>

<p><strong>TIP:</strong> If you’d like to know more about the design and use of the calendar, the page <strong><a href="https://davidseah.com/compact-calendar-use-notes/" target="_blank">Using the Compact Calendar</a></strong> will give you the additional details.</p>

<h2>Modifying the Compact Calendar</h2>

<p>You’ll need <strong>Microsoft Excel 2007</strong> or better to modify the Compact Calendar’s XLTX files. If you are using an older version of Office on Windows, <a href="https://support.microsoft.com/kb/924074" target="_blank">this downloadable service pack</a> from Microsoft may help.</p>

<p><em>NOTE: The Compact Calendar is saved as an Excel Template (XLTX) file. If you double-click an Excel template file, it opens a <strong>copy</strong> that you can save without modifying the master template. If you want to edit the template itself, you should use FILE-&gt;OPEN menu from within Excel itself instead of double-clicking the file icon.</em></p>

<p>After you open the .xltx file, there are several worksheets (see the bottom of the screen) for the 12-month, 16-month, Holiday, and Instructions table:</p>

<p><span><img decoding="async" alt="12-month&nbsp;calendar&nbsp;in&nbsp;Excel&nbsp;2007" loading="lazy" onclick="javascript:MDHPopUp('https://davidseah.com/_wpcontent/images/12/1207-compact-calendar-12-month-2013.png',900,670,'12-month&nbsp;calendar&nbsp;in&nbsp;Excel&nbsp;2007',1)" data-src="https://davidseah.com/_wpcontent/imgcache/images/12/1207-compact-calendar-12-month-2013.png.jpg" src="https://davidseah.com/_wpcontent/imgcache/images/12/1207-compact-calendar-12-month-2013.png.jpg"></span><span><img decoding="async" alt="To&nbsp;add&nbsp;a&nbsp;holiday,&nbsp;just&nbsp;type&nbsp;in&nbsp;the&nbsp;date&nbsp;in&nbsp;the&nbsp;first&nbsp;column&nbsp;and&nbsp;a&nbsp;note&nbsp;in&nbsp;the&nbsp;second.&nbsp;The&nbsp;rest&nbsp;of&nbsp;this&nbsp;is&nbsp;for&nbsp;fancy&nbsp;formatting." loading="lazy" onclick="javascript:MDHPopUp('https://davidseah.com/_wpcontent/images/12/1207-compact-calendar-holiday-2013.png',900,670,'To&nbsp;add&nbsp;a&nbsp;holiday,&nbsp;just&nbsp;type&nbsp;in&nbsp;the&nbsp;date&nbsp;in&nbsp;the&nbsp;first&nbsp;column&nbsp;and&nbsp;a&nbsp;note&nbsp;in&nbsp;the&nbsp;second.&nbsp;The&nbsp;rest&nbsp;of&nbsp;this&nbsp;is&nbsp;for&nbsp;fancy&nbsp;formatting.',1)" data-src="https://davidseah.com/_wpcontent/imgcache/images/12/1207-compact-calendar-holiday-2013.png.jpg" src="https://davidseah.com/_wpcontent/imgcache/images/12/1207-compact-calendar-holiday-2013.png.jpg"></span><span><img decoding="async" alt="The&nbsp;instructions&nbsp;worksheet&nbsp;reminds&nbsp;you&nbsp;how&nbsp;to&nbsp;modify&nbsp;things" loading="lazy" onclick="javascript:MDHPopUp('https://davidseah.com/_wpcontent/images/12/1207-compact-calendar-instructions-2013.png',900,670,'The&nbsp;instructions&nbsp;worksheet&nbsp;reminds&nbsp;you&nbsp;how&nbsp;to&nbsp;modify&nbsp;things',1)" data-src="https://davidseah.com/_wpcontent/imgcache/images/12/1207-compact-calendar-instructions-2013.png.jpg" src="https://davidseah.com/_wpcontent/imgcache/images/12/1207-compact-calendar-instructions-2013.png.jpg"></span>
<br></p>

<p>Modifying the starting day of the calendar is very easy: just <strong>edit the starting date</strong> by typing in a new one. The calendar will update automatically.</p>

<p>If you need to make a longer calendar, that’s easy too: just <strong>extend the range</strong> as you would normally with any list in Excel. Incidentally, the Excel spreadsheet also includes a 16-month calendar as a separate worksheet.</p>

<p>Changing the background colors is a little trickier; you’ll have to edit the <strong>conditional formatting</strong> in use on the worksheet. This <strong>video</strong> might help:</p>

<iframe width="585" height="439" frameborder="0" allowfullscreen="allowfullscreen" data-src="https://www.youtube.com/embed/Lx5lgfNQzkg"></iframe>



<h2>Downloading Notes</h2>

<p>Please note that <strong>Microsoft Excel 2007</strong> or newer is required. Other software like <em>Open Office</em>, <em>Google Docs</em>, and <em>Numbers</em> may import the Excel spreadsheet, but due to differences in the way they handle dates you should double-check that the calendars are correct.</p>

<p>For the <strong>official USA version</strong>, each zip archive includes with three templates (xltx). Printable PDFs included in each download. If you are using an older version of Excel, see <a href="https://support.microsoft.com/kb/924074" target="_blank">Microsoft’s update directions</a> to add XLSX/XLTX file compatibility.</p>

<p>The <strong>international versions</strong> are NOT created by me. Please read the instructions on the international contributor’s website for a description of the download content.</p>

<p>Enjoy!</p>


		</div>  
	<div>
			

<h2>DOWNLOADS</h2>

<p>Please read “Downloading Instructions” in the main text if you have any problems.</p>

<ul>
<li><p><img decoding="async" alt="us.gif.jpg" loading="lazy" data-src="https://davidseah.com/_wpcontent/imgcache/icons/flags/us.gif.jpg" src="https://davidseah.com/_wpcontent/imgcache/icons/flags/us.gif.jpg"><strong><a href="https://davidseah.com/pub/downloads/pceo/calendar/CompactCalendar2023-PDF-US.zip" target="_blank">US PDF Package</a></strong> contains PDFs formatted in the US Letter (8.5 x 11 inch) paper size. I’ve also included the 2024 calendar as well, for people who need to plan more than a year into the future.</p></li>
<li><p><img decoding="async" alt="us.gif.jpg" loading="lazy" data-src="https://davidseah.com/_wpcontent/imgcache/icons/flags/us.gif.jpg" src="https://davidseah.com/_wpcontent/imgcache/icons/flags/us.gif.jpg"><strong><a href="https://davidseah.com/pub/downloads/pceo/calendar/CompactCalendar2023-PDF-A4.zip" target="_blank">A4 PDF Package</a></strong> contains PDFs formatted in the A4 international paper size for 2023 and 2024.</p></li>
</ul>

<h4>2023 Spreadsheet Versions</h4>

<p>If you’d like to edit the source Excel files directly or set a different starting date, download the Excel/Numbers sources! The spreadsheet with automatically calculate all the months, and also mark holidays for the US version. The Excel version is the recommended download.</p>

<ul>
<li><p><img decoding="async" alt="us.gif.jpg" loading="lazy" data-src="https://davidseah.com/_wpcontent/imgcache/icons/flags/us.gif.jpg" src="https://davidseah.com/_wpcontent/imgcache/icons/flags/us.gif.jpg"><strong><a href="https://davidseah.com/pub/downloads/pceo/calendar/CompactCalendar2023-XLSX.zip" target="_blank">Excel Source Package</a></strong> by <strong>DSri Seah</strong> w/ major US holidays. If you want to customize your calendar, this is the version you want to download.</p></li>
<li><p><img decoding="async" alt="us.gif.jpg" loading="lazy" data-src="https://davidseah.com/_wpcontent/imgcache/icons/flags/us.gif.jpg" src="https://davidseah.com/_wpcontent/imgcache/icons/flags/us.gif.jpg"><strong><a href="https://davidseah.com/pub/downloads/pceo/calendar/CompactCalendar2023-Numbers.zip" target="_blank">Apple Numbers Source Package</a></strong> by <strong>DSri Seah</strong>. Can be updated by changing the start date, but has no other special formatting.</p></li>
</ul>

<h2>Current Internationalizations</h2>

<ul>
<li><img decoding="async" alt="uk.gif.jpg" loading="lazy" data-src="https://davidseah.com/_wpcontent/imgcache/icons/flags/uk.gif.jpg" src="https://davidseah.com/_wpcontent/imgcache/icons/flags/uk.gif.jpg"><strong>Tom Mault</strong> contributes a version for the <strong>UK with bank holidays</strong> on his <a href="https://tmault.co.uk/blog/compact-calendar-2022-with-uk-bank-holidays" target="_blank">technology blog</a>. Thanks Tom!</li>
<li><p><strong>Jeroen Sangers</strong> has many <strong>Spanish</strong> country-localized versions available on <a href="https://canasto.es/calendario-compacto/" target="_blank">his site</a>!</p></li>
<li><p><img decoding="async" alt="fr.gif.jpg" loading="lazy" data-src="https://davidseah.com/_wpcontent/imgcache/icons/flags/fr.gif.jpg" src="https://davidseah.com/_wpcontent/imgcache/icons/flags/fr.gif.jpg"><strong>Calendrier 2022 (France)</strong> direct <a href="https://github.com/tisseurdetoile/pub/tree/master/compactCalendar" target="_blank">download link</a> by <strong>TisseurDeToile</strong>.</p></li>
<li><p><img decoding="async" alt="it.gif.jpg" loading="lazy" data-src="https://davidseah.com/_wpcontent/imgcache/icons/flags/it.gif.jpg" src="https://davidseah.com/_wpcontent/imgcache/icons/flags/it.gif.jpg"><strong>Calendario 2021 (Italy)</strong> <a href="https://www.magnificaweb.it/calendario-2021-compatto/" target="_blank">Excel translation</a> by <strong>Luca Magnani</strong></p></li>
</ul>

<h2>Digital Versions of the Compact Calendar</h2>

<ul>
<li><p><a href="https://pedrofuent.es/" target="_blank">Pedro Pablo Fuentes Schuster</a> made a <a href="https://docs.google.com/spreadsheets/u/2/d/1m1IWh6Mmli8K20DdH2wb7glls3dTgJRdCrFY0e1C-Sg/template/preview#gid=742254141" target="_blank">Google Sheets Version</a>!!!</p></li>
<li><p>TissuerDeToile has programmed an online <a href="https://github.tisseurdetoile.net/compactcalendarvue3/" target="_blank">Vue application</a> with <a href="https://github.com/tisseurdetoile/compactcalendarvue3" target="_blank">source code</a>!</p></li>
</ul>


		</div> </div>

																	</div>
			
						
					
			
			
					
								
					
		<!-- CLOSE article -->
		</article>
	
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why you shouldn't join Y Combinator (562 pts)]]></title>
            <link>https://newsletter.smallbets.co/p/why-you-shouldnt-join-y-combinator</link>
            <guid>37869760</guid>
            <pubDate>Fri, 13 Oct 2023 12:18:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsletter.smallbets.co/p/why-you-shouldnt-join-y-combinator">https://newsletter.smallbets.co/p/why-you-shouldnt-join-y-combinator</a>, See on <a href="https://news.ycombinator.com/item?id=37869760">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>YC seems like a reasonable proposition. They give you some money to help you start your business, and they promise you access to a community of people that can help you along the way. In exchange, they only ask for a small amount of equity. Doesn’t sound that bad, no?</p><p>But by the end of this post I will convince you that it’s actually a terrible idea.</p><p>First, you have to understand a very important concept: in some systems, what’s best for a group is not necessarily what’s best for the individuals who make up the group. In other words, the total wealth of a group of people could be increasing, while almost everyone making up that group could be seeing their wealth diminish. When this happens, we say we have a non-ergodic system. If the system was ergodic, what’s happening to the collective would also translate to all individuals.</p><p><span>Silicon Valley is a non-ergodic industry (like Hollywood, book publishing, the music industry, and even your country’s economy unless you’re under full-blown communism.) A non-ergodic system is not necessarily bad, but if you’re not cognizant of the system you’re in, you’re going to be played like a fiddle. Those who benefit from the collective will take advantage of you, while you (as the individual) lose out. This is what YC will try to do to you. In fact, this is what YC </span><em>has</em><span> to do; otherwise it won’t survive. Let me explain. </span></p><p>Imagine you’re told there’s a bunch of hidden treasures within a 100 acre area. What’s the best strategy for finding some of these treasures?</p><p>One way is to pick a spot, and dedicate your entire life digging as far down as possible on that one spot. You might reason that the deeper the treasure, the bigger the loot. You don’t want to settle for a measly small treasure box. You want the full chest of diamonds buried near the end of the earth’s crust. This is your shot at glory.</p><p>Another way is to use a search method employed by search and rescue teams. You divide the area into small squares, and do a “reasonable search” in each one. You use probabilities and some common sense to help guide you how deep to dig, and then you move to the next square. If you encounter undisturbed compacted dirt, chances are there’s no treasure beneath. If you run into bedrock, it’s almost certain there’s nothing below. So you use that information and move on. Your goal is to search the entire area where there’s probable treasure as quickly as possible. Ideally within your lifetime.</p><p>I’m sure you agree with me that the first way is a dumb strategy. Almost every digger employing this strategy will die treasure-less. But actually, it’s only dumb for that individual treasure hunter. For a gold mining company, this is the optimal strategy.&nbsp;The company only needs one miner to hit jackpot, and all the other miners can die penniless. If the cost of sacrificing an individual treasure hunter is low, the most optimal strategy is to get tens of thousands of treasure hunters, allocate hundreds of them per acre, and make them dig all the way down to the earth’s core. The treasure hunting economy would grow much bigger than if all the individual treasure hunters were optimizing for their own self-interest.</p><p>So, digging in one spot is a dumb strategy for the economy of the individual, but a very wise strategy for the collective economy of all individuals.</p><p>This is what happens in a non-ergodic system. We often hear politicians claim that the GDP is growing, but all the gains are going to the 1%. This is the same thing. The wealth of a country could be growing, but almost all the citizens could be getting poorer. There’s nothing inconsistent with this. The average is simply being dragged up by the freak outliers.</p><p>The same thing happens in venture capital. The owners of the portfolio maximize their returns when the system is non-ergodic, because while the individual treasure hunter has one lifetime to strike gold, the VC portfolio has access to thousands of lifetimes: those of all the treasure hunters.</p><p>YC will proudly tell you that you are more likely to end up with a billion dollar business if you join them. That may be true. What they’re more reluctant to tell you is that only about 50 companies met that expectation out of the 4,000 or so that went through their program. That’s 1.25%. To be fair, that’s actually quite impressive, but let’s say you have the stamina and willpower to go through YC three times in your lifetime. You’d need approximately 26 lifetimes to hit the jackpot! Aha! See the problem now?</p><p>I don’t know about you, but I want to be successful in this lifetime. I can't afford to rely on 26 lifetimes. But maybe you think you’re special. You’re not like those 3,950 dummies who failed. Maybe you are in fact special, but I wouldn’t rely too much on that. Business is much more random than it seems. If business was predictable, YC wouldn't have a measly 1.25% success rate, or thereabouts.</p><p>You might think that those who failed might still have gotten something. Maybe. But failure is a very expensive way to learn those things. You don’t need to crash a plane to learn how to fly one. And whatever lessons are learned from going through YC are probably not very useful anyway, but more on that later.</p><p>One of the bad learnings you get from YC is that there’s a formula for success, and it looks like this: First you do some brainstorming. Then you come up with a good idea that can scale to a billion dollars (otherwise what’s the point of getting out of bed in the morning?) Then you work hard until you find “product-market-fit.” And then if the noises from investors indicate you won’t be getting a next round of funding, you start looking for a “pivot.”</p><p>This so-called formula is nonsense. First, good ideas rarely come to us from a brainstorming session. They come from wandering about with an open mind until we stumble on an opportunity worth pursuing. Most of your ideas will be bad ideas, because unfortunately you’re not a genius visionary. So the best way to find good ideas is to have many ideas, try them out, take what works, and throw away the rest. But this is not what YC wants you to do. YC wants you to pick an idea that has market pull (or the potential for it), and to then dig a hole in the same spot until you reach the boiling magma. Because what if you stop digging just before you strike gold? When you’re cheap and expandable, that’s not an optimal strategy for the YC fund. You must go all in. Diversification is for your YC overlords, not for you.</p><p>If you reach the magma layer and you still have nothing, then you’d be encouraged to pivot. But that’s not how you find business opportunities in the real world. You can’t just say I’m going to pivot, and suddenly a good opportunity lands on your lap from heaven. You get good ideas by embracing randomness for a long time, until something looks like it has a fighting chance of paying off. The pivot idea you were forced to come up with is extremely unlikely to be one. Your imagination is overrated. The YC execs didn’t imagine Stripe or Dropbox or AirBnb. Random things come to them during demo days. The YC folks are smart because they know their imagination is limited. And so should you. You can’t just pivot a business idea. And if you’re going to cherry pick some pivot that worked out of the thousands attempted, you should stop reading now. Just go join YC.</p><p><span>The second bad lesson from YC is the focus on the upside. But </span><em>if</em><span> there’s any formula for success in business, it’s to focus relentlessly on staying in the game rather than on hitting it big. Focus on the downside, and let the upside take care of itself. To thrive, you must first survive. To win the race, you must finish the race. And so on. But this is in tension with what YC wants you to do. They want you to dig deep to the middle of the earth, and if you don’t come back alive, tough luck. You were a brave soldier, but now it’s time for them to focus on the other 999 soldiers. YC is still alive, but you’re not.</span></p><p>Don’t be a dummy. Don’t be a bet in somebody else’s portfolio.</p><p>Ahahaha, you caught me! It’s true. I do have something to sell you. I run a community for small-time entrepreneurs who are satisfied with reliably attainable mediocre success. The YC folks feel sorry for our joy with mediocrity while they’re out there changing the world. And we reciprocate the emotion.</p><p>So yes, I am promoting something that goes against everything YC stands for. But if you think YC is not also selling you something, I have a bridge to sell you. But maybe I’m being a bit too harsh. Because what is it that YC is selling you exactly?</p><p>Me, I charge you a one-time payment of $245, and you get access to my community, which includes live workshops, recorded classes, a group chat, and a few other things. It’s very clear what I’m doing. I ask for some money in exchange for access, and those who give me the money get access. Even my 6 year old kid understands it.</p><p>But YC is not asking you for money. They actually give you money! It looks like you’re the one selling to them. You’re technically selling them a piece of your business, no?</p><p>No, no, no, hold on. The easiest way to see what YC is selling is to look at military recruitment. The military sells the narrative that serving your country is a noble endeavor. You’ll get a shot at glory, and at the very least you gain some important life skills. You’ll also get paid enough to feed yourself and cover your basic needs, but barely. The military wants to recruit expendable soldiers who will go out to the battlefield risking their lives and limb for the collective, while the generals with all the medals sit in an air conditioned room giving orders.</p><p>YC is no different. It wants to recruit wide-eyed young founders to pick a spot on the treasure map and dig all the way down through the earth’s crust. Most of them will spend years or decades digging, and all they end up with it is a ramen lifestyle. Usually bunched up with 4 roommates in a damp San Francisco basement living on take-out ramen noodles every single day. But hey, they’re young. They’ll have time to do adult things later, like starting family or making decent money. And at the very least, they’ll gain some important life lessons and make some good connections.</p><p>Think about this for a second: The most successful business owners are typically in their 40s and 50s. Why is YC full of 22 year olds? Why aren’t the 40 year old entrepreneurs taking up this incredible deal that YC is offering? YC will tell you it’s because only the 22 year old kids can be true visionaries. BULL. SHIT. You’re not a visionary. All those 4,000 kids who went into YC also thought they were visionaries, and where are they now? They’re all in the startup cemetery, except for a dozen or so who despite the low odds managed to flip 10 heads in a row. The biggest indicator YC is a bad deal is that only people who are easily duped take up these deals. </p><p>The best thing I learned about business is to avoid trying to predict what will work and what won’t. YC knows this. That's why they only make small bets in thousands of businesses. But YC will try to teach you the exact opposite.</p><p>Business is a lot more random than it seems. You can’t treat it like a predictable project. You need to treat it like a financial investment. Instead of investing your money, you’re investing your time and energy, which is as scarce and as precious as money (if not more). Tell me, how do you invest your money? Do you pick one amazing stock and put all your life savings on it? Of course not. You understand that finance is uncertain. What’s good today might not be good tomorrow. There are hidden risks everywhere. And even if your stock pick doesn’t go bust, the biggest gains are likely to happen elsewhere and you won’t benefit from them if you’re only exposed to one piece of equity.</p><p>YC teaches you to try to be a visionary. When you fail… Oopsie! Tough luck. The fund benefits from the non-ergodic nature of the system, but you’re out years of your time. But that’s not even the worst of it. You would have been taught things that not only won’t work in the real world of business, but are counterproductive. You will have to unlearn almost everything.</p><p>If you want to succeed in the real world (and within this lifetime), you need to try many small things, experiment, tinker, and build a portfolio of multiple income streams. You need to treat your time the same way you treat your brokerage account. You basically need to become a VC, but for your own ideas. To make the system ergodic, you must un-leverage yourself from going all in on one thing, and get access to many diverse income streams. The same way it’s wise to invest in a broad ETF, you should be doing the same things with your projects. YC will teach you to do the opposite, but you’ll have to unlearn all of it. And unfortunately unlearning is much harder than learning.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making Rust supply chain attacks harder with Cackle (163 pts)]]></title>
            <link>https://davidlattimore.github.io/making-supply-chain-attacks-harder.html</link>
            <guid>37869597</guid>
            <pubDate>Fri, 13 Oct 2023 11:57:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://davidlattimore.github.io/making-supply-chain-attacks-harder.html">https://davidlattimore.github.io/making-supply-chain-attacks-harder.html</a>, See on <a href="https://news.ycombinator.com/item?id=37869597">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="main_content">
        

<p>If you want a slightly shorter read, skip to <a href="#introducing-cackle-aka-cargo-acl">Introducing Cackle</a>.</p>

<h2 id="a-hypothetical-story-about-alex">A hypothetical story about Alex</h2>

<p>Alex is a software engineer who has built a tool which she licences to her customers. She only has a
small number of clients, but they like her tool. She built her tool using Rust, with about 20 direct
dependencies from crates.io. When you count indirect dependencies, her tool has about 250
dependencies.</p>

<p>One of those indirect dependencies is a crate named <code>foobar</code>, which was written by someone named
Chris. Chris wrote <code>foobar</code> a few years ago, but has lost interest in maintaining it.</p>

<p>Someone called Bob has filed a couple of PRs against <code>foobar</code> and is now asking when they might get
merged and if the project is still maintained. Bob says that they’d be happy to maintain the crate
if Chris is too busy. Bob seems enthusiastic, so Chris adds Bob as an owner.</p>

<p>Some months go by and Alex is fixing a bug that one of her clients noticed. After fixing the bug,
she runs <code>cargo update</code>, runs the tests, does some manual testing, then pushes out the updated
version of her tool to her clients. The updated version of her tool includes an updated version of
the crate <code>foobar</code>.</p>

<p>A week later she gets a call from one of her clients who is extremely upset. It seems that the
client’s user database has been leaked and the attackers are threatening to publish it if a ransom
isn’t paid. Her client has determined that Alex’s tool is sending data to an unknown address on the
Internet.</p>

<p>After some investigation, Alex finds some code in the new version of <code>foobar</code> that is doing this.
She pins an old, unaffected version of the <code>foobar</code> crate and does a new release, but the damage to
her small business and her reputation is already done.</p>

<h2 id="supply-chain-attacks">Supply-chain attacks</h2>

<p>The story about Alex is an example of a supply-chain attack. There are many ways something like this
could happen:</p>

<ul>
  <li>A developer’s crates.io token could be compromised.</li>
  <li>A burned-out developer could hand over control of a crate to someone they don’t really know.</li>
  <li>Someone could build a crate, then submit PRs to other projects to make use of their crate. Later
they could add malicious code to their own crate.</li>
  <li>Developers sometimes add protest-ware to their own crates. Even if this is for a good cause, it
still has the potential to cause substantial damage and loss of trust.</li>
</ul>

<p>This kind of thing hasn’t happened much yet in the Rust ecosystem, but as it grows, it’s expected to
happen more often. It already happens semi-regularly in other larger ecosystems like node.js and in
Python’s package systems.</p>

<h2 id="practices-to-help-prevent-supply-chain-attacks">Practices to help prevent supply-chain attacks</h2>

<p>There are numerous things you can do to help prevent supply-chain attacks:</p>

<ul>
  <li>Review the code of crates that you use.</li>
  <li>Use and contribute to a code vetting database like
<a href="https://github.com/mozilla/cargo-vet">cargo-vet</a> or
<a href="https://github.com/crev-dev/cargo-crev">cargo-crev</a>.</li>
  <li>Avoid depending on trivial crates that would only save you a few lines of code (e.g. left-pad from
node.js). Not only do trivial dependencies not save you much code, they’re also potentially higher
risk due to them being easier to create.</li>
  <li>All else being equal, prefer crates with more downloads.</li>
  <li>Select crates that are written by people you recognise and who have a good reputation in the
community - although everyone is new at some point, so this is a trade-off.</li>
  <li>Copy the <code>cargo add</code> command from crates.io rather than typing the name by hand. This can help
prevent you from being the victim of typosquatting attacks.</li>
  <li>For crates where you don’t need or want new features, bug fixes etc, you could consider pinning
their versions. If you do though, then you should monitor for security advisories.</li>
</ul>

<p>For crate authors there are some additional steps you can take:</p>

<ul>
  <li>When reviewing PRs, look carefully at any newly added dependencies.</li>
  <li>Be careful about to whom you hand control of your crates.</li>
  <li>Consider asking new maintainers to fork your crate rather than handing it over.</li>
</ul>

<h2 id="introducing-cackle-aka-cargo-acl">Introducing Cackle aka cargo-acl</h2>

<p>Cackle is a code ACL checker and is an additional tool to help make supply-chain attacks harder.
It’s intended to be used in addition to the above approaches. Cackle is configured via <code>cackle.toml</code>
that sits alongside <code>Cargo.toml</code>. In the configuration file, you can define classes of APIs, such as
“net”, “fs” (filesystem) and “process” that you’d like to restrict. You then say which crates that
you depend on are permitted to use these APIs. When run, Cackle checks for any crates in your
dependency tree that are using restricted APIs that they’re not permitted to use.</p>

<p>An API definition says what names are included or excluded from that API. For example, we might
define the “process” API as follows:</p>

<div><pre><code><span>[api.process]</span>
<span>include</span> <span>=</span> <span>[</span>
    <span>"std::process"</span><span>,</span>
<span>]</span>
<span>exclude</span> <span>=</span> <span>[</span>
    <span>"std::process::exit"</span><span>,</span>
<span>]</span>
</code></pre></div>

<p>Exclusions take precedence over inclusions, so should be more specific. Here we’re defining an API
named “process” and classifying any functions in the <code>std::process</code> module as belonging to it. We
then exclude <code>std::process::exit</code>. So a reference to <code>std::process::Command::new</code> would count as
using the <code>process</code> API, but a reference to <code>std::process::exit</code> would not.</p>

<p>We can then allow specific packages to use this API. For example:</p>

<div><pre><code><span>[pkg.rustyline]</span>
<span>allow_apis</span> <span>=</span> <span>[</span>
  <span>"fs"</span><span>,</span>
<span>]</span>
<span>allow_unsafe</span> <span>=</span> <span>true</span>
</code></pre></div>

<p>This says that the <code>rustyline</code> package is allowed to use filesystem APIs and also allowed to use
unsafe code.</p>

<p>In the case of Alex’s story, had she been using Cackle, then the <code>foobar</code> crate might have been
flagged as now using the “net” API where previously it wasn’t.</p>

<h2 id="installing-cackle">Installing Cackle</h2>

<p>For the time being, Cackle only supports Linux. Assuming you’ve already got Rust installed, you can
run:</p>

<div><pre><code>cargo <span>install</span> <span>--locked</span> cargo-acl
</code></pre></div>

<h2 id="building-an-initial-config">Building an initial config</h2>

<p>Cackle has a built-in terminal UI that helps with creation of your cackle.toml. We’ll use that to
create our initial configuration. From the directory containing your <code>Cargo.toml</code>, run:</p>



<p>The problems pane shows problems that have been detected so far with the permissions used by your
dependencies. Initially, it also shows action items that help with creating your configuration.</p>

<p><img src="https://davidlattimore.github.io/images/no-config.png" alt="Screenshot of missing config in UI"></p>

<p>We select a problem and press ‘f’ to show possible fixes.</p>

<p><img src="https://davidlattimore.github.io/images/no-config-fixes.png" alt="Screenshot of fixes for missing config in UI"></p>

<p>Here we can see two possible initial configurations that we can create. We select that we’d like to
use the recommended initial configuration and press ‘f’ to apply the fix.</p>

<p><img src="https://davidlattimore.github.io/images/select-sandbox.png" alt="Screenshot of selecting a sandbox"></p>

<p>Next, the UI will ask us to select what kind of sandbox we’d like to use. At the moment, the only
supported sandbox is Bubblewrap. The sandbox is used for running build scripts, for running rustc
(and thus procedural macros) and for running tests. APIs used by each binary are checked by cackle
before they get run, so depending on how carefully you’re checking those API usages, you may decide
not to worry about sandboxing.</p>

<p>At this point, we’ve imported APIs that restrict network access, filesystem access and command
access via the standard library. We haven’t however restricted similar APIs that might be provided
by third-party crates in our dependency tree. For example, tokio can be used to perform network
access, but we haven’t classified any of its APIs as doing so.</p>

<p>Third-party crates can export cackle API definitions. If any do, then the cackle UI will ask us if
we’d like to import those API definitions. While cackle is fairly new however, it’s expected that
we’ll need to write such API definitions ourselves. We might write a “net” API definition for
<code>tokio</code> as follows:</p>

<div><pre><code><span>[api.net]</span>
<span>include</span> <span>=</span> <span>[</span>
    <span>"tokio::net"</span><span>,</span>
<span>]</span>
</code></pre></div>

<p>Here we’re saying that references to anything in the <code>tokio</code> crate’s <code>net</code> module should be
classified as a use of the <code>net</code> API.</p>

<p>We can manually edit our cackle.toml to add this API definition. It will be merged with the
definition of the <code>net</code> API for the standard library that is built into Cackle and which we imported
when we created our initial configuration.</p>

<p>Cackle will now proceed to build your crate and its dependencies. As the build proceeds, cackle will
analyse object files, executables and source code to see what APIs are used from where and which
crates use unsafe. As problems are found, they’ll be added to the “problems” pane in the UI.</p>

<p><img src="https://davidlattimore.github.io/images/problem-list.png" alt="Screenshot of problem list and package details"></p>

<p>Details about the package involved are shown in the bottom pane. You can use this to help understand
what the package does, which can be useful for deciding if it’s reasonable for it to use a
particular API.</p>

<p>If you’d like to see how a package was included, you can view the tree from current problem’s
package to your package by pressing ‘t’.</p>

<p><img src="https://davidlattimore.github.io/images/package-tree.png" alt="Screenshot of a package tree"></p>

<p>For API usages and unsafe code, you can press ‘d’ to see further details of each usage location of
that API or unsafe code.</p>

<p><img src="https://davidlattimore.github.io/images/unsafe-usages.png" alt="Screenshot of UI showing unsafe usage locations"></p>

<p>If you’re happy for the crate to use that API or unsafe, you can press ‘f’ to see available fixes to
the configuration file.</p>

<p><img src="https://davidlattimore.github.io/images/allow-unsafe.png" alt="Screenshot of fix to allow unsafe"></p>

<p>Press ‘f’ again to apply the selected fix.</p>

<p>Similar to the unsafe usages, the usage locations for a disallowed API can be shown by pressing ‘d’.</p>

<p><img src="https://davidlattimore.github.io/images/disallowed-api.png" alt="Screenshot of disallowed API usage locations"></p>

<p>Here we can see that the build script for the <code>quote</code> crate is using the process API by referencing
<code>std::process::Command</code>.</p>

<p>Like with other problems, we can press ‘f’ to see available fixes.</p>

<p><img src="https://davidlattimore.github.io/images/allow-api.png" alt="Screenshot of fix to allow an API"></p>

<p>We have a few options for allowing an API usage. The <code>quote</code> crate used the <code>process</code> API from its
build script. We can allow just this, which is the first available fix.</p>

<p>Alternatively, we might choose to allow the <code>quote</code> crate to use the <code>process</code> API, but only as part
of build scripts. This would mean that code in for example <code>quote</code>’s <code>lib.rs</code> could use the
<code>process</code> API if that code was then used by a build script from another package. It would also allow
<code>quote</code>’s own <code>build.rs</code> to use the <code>process</code> API.</p>

<p>Lastly we might allow <code>quote</code> to use the <code>process</code> API regardless of what kind of binary is being
built.</p>

<p>The bottom pane shows a description of the change being made as well as a diff of your
<code>cackle.toml</code>.</p>

<p>Only API usages in reachable code are considered. If you’d like to see how the code is reachable you
can press ‘b’ to get a backtrace showing a path of function references from main to the function
that used the API.</p>

<p><img src="https://davidlattimore.github.io/images/usage-backtrace.png" alt="Screenshot of backtrace for an API usage"></p>

<p>Here we can see that the ripgrep build script is calling clap’s <code>App::gen_completions</code>, which calls
<code>Parser::gen_completions</code> which is what’s using <code>File::create</code>.</p>

<p>Note that this isn’t a runtime backtrace - the build script hasn’t been executed yet. It’s a
hypothetical backtrace built from the graph of what functions reference what other functions. Press
escape to leave the backtrace.</p>

<p>Other kinds of problems that cackle might detect with your dependencies are:</p>

<ul>
  <li>A build script (build.rs) failing. This might be because it attempted to access the network, or
tried to write a file outside of its output directory. Possible fixes are to allow network access,
allow writes to a particular directory or disable the sandbox for that particular build script.</li>
  <li>A build script might emit instructions to cargo, requesting extra arguments to the linker. This
can be a source of code that we’re not checking, so we want to look to see if what’s being done is
reasonable, then if it is, allow it.</li>
</ul>

<p>Once all problems have been resolved, Cackle will exit.</p>

<p>We might like to integrate Cackle into our CI. To do so, we’d run:</p>



<p>And if we’d like to also then run the tests under cackle, we’d do:</p>



<p>In a github action, we might do this as follows:</p>

<div><pre><code><span>name</span><span>:</span> <span>cackle</span>
<span>on</span><span>:</span> <span>[</span><span>push</span><span>,</span> <span>pull_request</span><span>]</span>

<span>jobs</span><span>:</span>
  <span>cackle</span><span>:</span>
    <span>name</span><span>:</span> <span>Cackle check and test</span>
    <span>runs-on</span><span>:</span> <span>ubuntu-latest</span>
    <span>steps</span><span>:</span>
      <span>-</span> <span>uses</span><span>:</span> <span>actions/checkout@v3</span>
      <span>-</span> <span>uses</span><span>:</span> <span>dtolnay/rust-toolchain@stable</span>
      <span>-</span> <span>uses</span><span>:</span> <span>cackle-rs/cackle-action@latest</span>
      <span>-</span> <span>run</span><span>:</span> <span>cargo acl -n</span>
      <span>-</span> <span>run</span><span>:</span> <span>cargo acl -n test</span>
</code></pre></div>

<p>This will do a non-interactive check of our dependencies against the configuration. If any problems
are encountered, details will be printed and it will exit with a failure status.</p>

<p>If your <code>Cargo.lock</code> is checked into your repository, you might like to add <code>rm Cargo.lock</code> to your
CI before running <code>cargo acl</code>, that way we’ll be checking the latest semver-compatible versions of
your dependencies.</p>

<h2 id="how-it-works">How it works</h2>

<p>When you run <code>cargo acl</code>, Cackle invokes <code>cargo build</code>, but wraps rustc, the linker and any build
scripts. As the build progresses, the wrappers communicate back to the parent cackle process, which
analyses the build artefacts in order to determine what APIs are being used. It does this by parsing
the object files to determine what functions reference what other functions. It also parses the
debug information in the linked executable in order to determine the source locations for each
reference. Source files are then mapped back to the package that provided that source file via
<code>deps</code> files written by rustc.</p>

<p>One nice thing about the fact that Cackle analyses the final executable is that dead code is not
considered with regard to API usage. So for example if you depend on the <code>image</code> package to encode
PNGs, but don’t use functions from the image crate that read or write files, then those functions
shouldn’t go into the executable, which means Cackle won’t classify the image package as using
filesystem APIs. This means that if later, the <code>image</code> package started doing filesystem access from
a function that wasn’t previously, it would be flagged as using a disallowed API.</p>

<h2 id="circumvention">Circumvention</h2>

<p>There are of course ways to circumvent Cackle and use an API without detection.</p>

<p>One way is if your configuration is incomplete. For example, if your crate depends on tokio, but you
don’t add <code>tokio::net</code> to the includes for <code>api.net</code> then another of your dependencies could use
<code>tokio::net</code> to perform network access without being detected. Cackle tries to mitigate this to some
extent by looking for top-level modules with the same name as one of your APIs. So in the case of
tokio, Cackle will suggest that you add <code>tokio::net</code> to the <code>net</code> API.</p>

<p>Once you’ve granted a package permission to use an API, it has carte blanche to do whatever it likes
with that permission. Cackle provides strongest protection where crates have been granted no special
permissions. Similarly, once a crate is granted use of unsafe, it could in theory do just about
anything with it. That said, using unsafe to say perform network access is harder than just using
Rust’s <code>std::net</code> APIs, so we’re at least making it harder for a would-be attacker.</p>

<p>More problematic is that platform-specific or config-specific malicious code might be missed. For
example, malicious code that is only present on Windows or Mac would be missed since Cackle
currently only works on Linux.</p>

<p>Lastly, there are undoubtedly bugs that might allow API usage to go undetected.</p>

<h2 id="observations-from-running-on-a-few-different-binaries">Observations from running on a few different binaries</h2>

<p>When running cackle on a few popular binaries published to crates.io, what I’ve observed is that
usually, a bit under half of crates need no special permissions. This is great, because if at any
point any of these crates start using a restricted API or unsafe, we should notice.</p>

<p>Of the crates that need special permissions, by far the most commonly required is unsafe. Most
crates using unsafe provide some low level API that can’t be provided, or can’t be provided
efficiently without unsafe. I did however notice a number of crates where it’s not clear why they
would need unsafe.</p>

<p>Filesystem and process APIs are less used than unsafe, but still used a moderate amount, especially
from build scripts.</p>

<p>Network APIs are relatively uncommon and for a program that doesn’t talk over the network - e.g.
Cackle itself or something like ripgrep, I’d expect to see no dependencies using network APIs.
Indeed, for these two crates, this is what we see.</p>

<h2 id="future-plans">Future plans</h2>

<h3 id="more-granular-sandboxing-of-proc-macros">More granular sandboxing of proc macros</h3>

<p>Right now, proc macros are sandboxed by virtue of Cackle running rustc in a sandbox. However this
means that all your proc macros are granted the same sandbox permissions. So if you have one proc
macro in your dependencies that needs network access, you need to grant this to all proc macros.
Fortunately most proc macros don’t need any network access, so this isn’t too much of a problem in
common cases.</p>

<p>If rustc at any point gets support for running proc macros as subprocesses rather than by loading
dylibs into the main rustc process, then we can sandbox each proc macro individually which will
allow us to fix this.</p>

<h3 id="runtime-analysis">Runtime analysis</h3>

<p>At the moment, we’re mostly only doing static analysis. It could be interesting to add some runtime
analysis to Cackle. Specifically, we could trace the syscalls made by build scripts (and ideally
also proc macros) and see what file paths they try to access and what subprocesses they spawn.</p>

<h3 id="support-for-more-platforms">Support for more platforms</h3>

<p>As mentioned previously, if we can’t work on Mac and Windows, then any attacks that target only
those platforms will go undetected. Making it work on Mac is hopefully not too much work, since Mac
uses the same debug information format as Linux. Windows is a little harder, since it uses a
different format for debug info. There is a crate that parses it though, so it’s probably doable.
Help is needed with both as I only have Linux.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Cackle won’t (and can’t) stop all supply-chain attacks. However, hopefully it can be a tool that can
at least make it substantially harder for an attacker to sneak something malicious into your
dependencies without you noticing.</p>

<h2 id="thanks">Thanks</h2>

<p>Huge thank you to <a href="https://github.com/embark-studios">Embark Studios</a> and <a href="https://github.com/repi">Johan
Andersson</a> for their generous
<a href="https://github.com/sponsors/davidlattimore">sponsorship</a>.</p>

      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Signal Identification Wiki (196 pts)]]></title>
            <link>https://www.sigidwiki.com/wiki/Signal_Identification_Guide</link>
            <guid>37869534</guid>
            <pubDate>Fri, 13 Oct 2023 11:50:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sigidwiki.com/wiki/Signal_Identification_Guide">https://www.sigidwiki.com/wiki/Signal_Identification_Guide</a>, See on <a href="https://news.ycombinator.com/item?id=37869534">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p>This wiki is intended to help identify radio signals through example sounds and waterfall images. Most signals are received and recorded using a software defined radio such as the <a target="_blank" href="http://www.rtl-sdr.com/">RTL-SDR</a>, <a target="_blank" href="http://www.airspy.com/">Airspy</a>, <a target="_blank" href="http://www.sdrplay.com/">SDRPlay</a>, <a target="_blank" href="https://greatscottgadgets.com/hackrf/">HackRF</a>, <a target="_blank" href="http://nuand.com/">BladeRF</a>, <a target="_blank" href="http://www.funcubedongle.com/">Funcube Dongle</a>, <a target="_blank" href="http://www.ettus.com/">USRP</a> or others.
</p><p><b>Editing:</b> Anyone can edit this wiki, so if you see missing or wrong information please feel free to correct it by clicking the 'edit with form' button at the stop of the signals page. When doing an edit, if you are not logged in as a user, you will be asked to answer a very simple spam prevention question which will appear at the top of the screen after clicking on Save page. If you are not experienced with editing Wiki Markup, refer to this <a target="_blank" href="https://meta.wikimedia.org/wiki/Help:Reference_card">reference card</a>, <a target="_blank" href="http://wiki.radioreference.com/index.php/Quick_guide_to_editing_pages">Quick Guide of editing pages</a>, or just email the requested changes at sigidwiki_AT_gmail_DOT_com.
</p><p><b>Discussion:</b> You can also discuss the signals by using the discussion tab at the top of every page, or just by using the <a href="#Comments">comments box at the bottom of this page</a> (note that the comments section will be periodically pruned to reduce its length).
</p><p><br>
<b>We now have a Discord server up for people who would like to chat about signals as well. To join you must send an email to sigidwiki_AT_gmail_DOT_com for an invite to the server.</b>
</p>
<p><span><p><a href="https://www.sigidwiki.com/wiki/Adding_a_Signal_Entry" title="Adding a Signal Entry"><img alt="Addsignal.png" src="https://www.sigidwiki.com/images/f/f5/Addsignal.png" width="120" height="80"></a> <a href="https://www.sigidwiki.com/cdn-cgi/l/email-protection#2e5d4749474a594745476e49434f4742004d4143" target="_blank"><img alt="1200x630bb.jpg" src="https://www.sigidwiki.com/images/thumb/4/44/1200x630bb.jpg/80px-1200x630bb.jpg" width="80" height="80" srcset="https://www.sigidwiki.com/images/thumb/4/44/1200x630bb.jpg/120px-1200x630bb.jpg 1.5x, https://www.sigidwiki.com/images/thumb/4/44/1200x630bb.jpg/160px-1200x630bb.jpg 2x"></a></p></span></p><hr>
<p><span><p><b>Software</b><br><a href="https://aresvalley.com/" target="_blank"><img alt="Artemis3.png" src="https://www.sigidwiki.com/images/thumb/3/36/Artemis3.png/96px-Artemis3.png" width="96" height="96" srcset="https://www.sigidwiki.com/images/thumb/3/36/Artemis3.png/144px-Artemis3.png 1.5x, https://www.sigidwiki.com/images/thumb/3/36/Artemis3.png/192px-Artemis3.png 2x"></a><br></p></span><span><p><b>Artemis 3</b></p></span><span><p>Check out <b><a target="_blank" href="https://aresvalley.com/">Artemis 3</a></b>, the main companion app to this guide! Artemis 3 gives you all known reference signals in an easy to access offline format, with improved sorting and filters and offline audio samples and waterfalls.</p><br></span></p><hr>
<p><span><p><img alt="Frequency bands.png" src="https://www.sigidwiki.com/images/1/16/Frequency_bands.png" width="590" height="57"></p></span></p><table>
<tbody><tr>
<td><a href="https://www.sigidwiki.com/wiki/Category:VLF" title="Category:VLF"><img alt="VLF.png" src="https://www.sigidwiki.com/images/7/7e/VLF.png" width="120" height="80"></a><p><span> 17</span></p></td>
<td><a href="https://www.sigidwiki.com/wiki/Category:LF" title="Category:LF"><img alt="LF.png" src="https://www.sigidwiki.com/images/c/c9/LF.png" width="120" height="80"></a><p><span> 27</span></p></td>
<td><a href="https://www.sigidwiki.com/wiki/Category:MF" title="Category:MF"><img alt="MF.png" src="https://www.sigidwiki.com/images/d/d0/MF.png" width="120" height="80"></a><p><span> 36</span></p></td>
<td><a href="https://www.sigidwiki.com/wiki/Category:HF" title="Category:HF"><img alt="HF.png" src="https://www.sigidwiki.com/images/4/4c/HF.png" width="120" height="80"></a><p><span> 224</span></p></td>
<td><a href="https://www.sigidwiki.com/wiki/Category:VHF" title="Category:VHF"><img alt="VHF.png" src="https://www.sigidwiki.com/images/a/a9/VHF.png" width="120" height="80"></a><p><span> 133</span></p></td>
<td><a href="https://www.sigidwiki.com/wiki/Category:UHF" title="Category:UHF"><img alt="UHF.png" src="https://www.sigidwiki.com/images/7/78/UHF.png" width="120" height="80"></a><p><span> 185</span></p></td></tr></tbody></table>
<p><span><p><img alt="Testing.png" src="https://www.sigidwiki.com/images/7/7f/Testing.png" width="590" height="57"></p></span></p>
<table>
<tbody><tr>
<td><a href="https://www.sigidwiki.com/wiki/Category:Military" title="Category:Military"><img alt="Military.png" src="https://www.sigidwiki.com/images/8/86/Military.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Radar" title="Category:Radar"><img alt="Radar.png" src="https://www.sigidwiki.com/images/4/46/Radar.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Active" title="Category:Active"><img alt="Active.png" src="https://www.sigidwiki.com/images/f/f8/Active.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Inactive" title="Category:Inactive"><img alt="Inactive.png" src="https://www.sigidwiki.com/images/2/25/Inactive.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Amateur_Radio" title="Category:Amateur Radio"><img alt="Amateur.png" src="https://www.sigidwiki.com/images/6/69/Amateur.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Commercial" title="Category:Commercial"><img alt="Commercial.png" src="https://www.sigidwiki.com/images/1/1e/Commercial.png" width="120" height="80"></a>
</td></tr>
<tr>
<td><a href="https://www.sigidwiki.com/wiki/Category:Aviation" title="Category:Aviation"><img alt="Aviation.png" src="https://www.sigidwiki.com/images/6/6a/Aviation.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Marine" title="Category:Marine"><img alt="Marine.png" src="https://www.sigidwiki.com/images/9/9d/Marine.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Analogue" title="Category:Analogue"><img alt="Analogue.png" src="https://www.sigidwiki.com/images/1/17/Analogue.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Digital" title="Category:Digital"><img alt="Digital.png" src="https://www.sigidwiki.com/images/1/1b/Digital.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Trunked_Radio" title="Category:Trunked Radio"><img alt="Trunked.png" src="https://www.sigidwiki.com/images/3/31/Trunked.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Utility" title="Category:Utility"><img alt="Utility.png" src="https://www.sigidwiki.com/images/5/58/Utility.png" width="120" height="80"></a>
</td></tr>
<tr>
<td><a href="https://www.sigidwiki.com/wiki/Category:Satellite" title="Category:Satellite"><img alt="Satellite.png" src="https://www.sigidwiki.com/images/5/5a/Satellite.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Navigation" title="Category:Navigation"><img alt="Navigation.png" src="https://www.sigidwiki.com/images/4/4f/Navigation.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Interfering" title="Category:Interfering"><img alt="Interfering.png" src="https://www.sigidwiki.com/images/5/5c/Interfering.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Requested" title="Category:Requested"><img alt="Requested.png" src="https://www.sigidwiki.com/images/9/97/Requested.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Numbers_Stations" title="Category:Numbers Stations"><img alt="Numbers.png" src="https://www.sigidwiki.com/images/f/f4/Numbers.png" width="120" height="80"></a>
</td>
<td><a href="https://www.sigidwiki.com/wiki/Category:Time" title="Category:Time"><img alt="Time.png" src="https://www.sigidwiki.com/images/0/08/Time.png" width="120" height="80"></a>
</td></tr></tbody></table>
<div>
<h2><span id="Other_Categories"><b>Other Categories</b></span></h2>
<p><a href="https://www.sigidwiki.com/wiki/Category:Transmitter_Hardware" title="Category:Transmitter Hardware"><img alt="TX Hardware Icon.jpg" src="https://www.sigidwiki.com/images/a/a3/TX_Hardware_Icon.jpg" width="120" height="80"></a> <a href="https://www.sigidwiki.com/wiki/Regulatory_Databases" title="Regulatory Databases"><img alt="Databases alt clean v2.png" src="https://www.sigidwiki.com/images/9/92/Databases_alt_clean_v2.png" width="120" height="80"></a>
</p>
</div>
<h2><span id="Stats">Stats</span></h2>
<p><br>
<b><a href="https://www.sigidwiki.com/wiki/Database" title="Database">Identified Signals</a> in Database:<span> 494</span></b>
<br>
<b><a href="https://www.sigidwiki.com/wiki/Template:DatabaseUNID" title="Template:DatabaseUNID">Unidentified Signals</a> to be Identified:<span> 336</span></b>
<br>
<b><a href="https://www.sigidwiki.com/wiki/Requested" title="Requested">Requested Signals</a>:<span> 62</span></b>
</p>
<table>
<caption>
</caption>
<tbody><tr>
<th> <span>Recently Added Signals</span>
</th>
<th> <span>Recently Updated Signals</span>
</th></tr>
<tr>
<td> <ul><li>2023-10-06 10:40:06 <a href="https://www.sigidwiki.com/wiki/Spectrum_Painting" title="Spectrum Painting">Spectrum Painting</a></li><li>2023-09-24 17:34:05 <a href="https://www.sigidwiki.com/wiki/FLASH-OFDM" title="FLASH-OFDM">FLASH-OFDM</a></li><li>2023-09-24 16:00:00 <a href="https://www.sigidwiki.com/wiki/WiMAX" title="WiMAX">WiMAX</a></li><li>2023-08-28 21:00:17 <a href="https://www.sigidwiki.com/wiki/Aqua_Direct_Broadcast_(DB)" title="Aqua Direct Broadcast (DB)">Aqua Direct Broadcast (DB)</a></li><li>2023-08-28 20:48:05 <a href="https://www.sigidwiki.com/wiki/High_Resolution_Data_(HRD)" title="High Resolution Data (HRD)">High Resolution Data (HRD)</a></li><li>2023-08-20 23:07:45 <a href="https://www.sigidwiki.com/wiki/CDMA420" title="CDMA420">CDMA420</a></li><li>2023-08-02 09:19:35 <a href="https://www.sigidwiki.com/wiki/M20_Radiosonde" title="M20 Radiosonde">M20 Radiosonde</a></li><li>2023-07-08 18:02:37 <a href="https://www.sigidwiki.com/wiki/Horus_Binary_4FSK_-_v2" title="Horus Binary 4FSK - v2">Horus Binary 4FSK - v2</a></li><li>2023-07-05 08:06:52 <a href="https://www.sigidwiki.com/wiki/77Ya6_%27Voronezh%27_radar" title="77Ya6 'Voronezh' radar">77Ya6 'Voronezh' radar</a></li><li>2023-06-12 09:34:50 <a href="https://www.sigidwiki.com/wiki/FST4W" title="FST4W">FST4W</a></li></ul>
</td>
<td> <ul><li>2023-10-11 21:12:43 <a href="https://www.sigidwiki.com/wiki/2G_CDMA_(IS-95)" title="2G CDMA (IS-95)">2G CDMA (IS-95)</a></li><li>2023-10-10 21:56:09 <a href="https://www.sigidwiki.com/wiki/Digital_Mobile_Radio_(DMR)" title="Digital Mobile Radio (DMR)">Digital Mobile Radio (DMR)</a></li><li>2023-10-09 15:03:10 <a href="https://www.sigidwiki.com/wiki/Yaesu_System_Fusion" title="Yaesu System Fusion">Yaesu System Fusion</a></li><li>2023-10-09 07:39:09 <a href="https://www.sigidwiki.com/wiki/Digital_Video_Broadcasting_%E2%80%94_Terrestrial_(DVB-T)" title="Digital Video Broadcasting — Terrestrial (DVB-T)">Digital Video Broadcasting — Terrestrial (DVB-T)</a></li><li>2023-10-08 10:21:39 <a href="https://www.sigidwiki.com/wiki/Spectrum_Painting" title="Spectrum Painting">Spectrum Painting</a></li><li>2023-10-04 18:27:28 <a href="https://www.sigidwiki.com/wiki/The_Buzzer_(ZhUOZ_MDZhB_UZB76)" title="The Buzzer (ZhUOZ MDZhB UZB76)">The Buzzer (ZhUOZ MDZhB UZB76)</a></li><li>2023-09-28 08:48:47 <a href="https://www.sigidwiki.com/wiki/John_Deere_RTK_Radio_450" title="John Deere RTK Radio 450">John Deere RTK Radio 450</a></li><li>2023-09-26 06:34:58 <a href="https://www.sigidwiki.com/wiki/Aqua_Direct_Broadcast_(DB)" title="Aqua Direct Broadcast (DB)">Aqua Direct Broadcast (DB)</a></li><li>2023-09-25 13:42:00 <a href="https://www.sigidwiki.com/wiki/FLASH-OFDM" title="FLASH-OFDM">FLASH-OFDM</a></li><li>2023-09-24 16:27:53 <a href="https://www.sigidwiki.com/wiki/WiMAX" title="WiMAX">WiMAX</a></li></ul>
</td></tr></tbody></table>
<table>
<caption>
</caption>
<tbody><tr>
<th> <span>Recently Added Unidentified Signals</span>
</th>
<th> <span>Recently Updated Unidentified Signals</span>
</th></tr>
<tr>
<td> <ul><li>2023-07-28 06:02:55 <a href="https://www.sigidwiki.com/wiki/Possible_Telemetry_GFSK_signal_on_220Mhz" title="Possible Telemetry GFSK signal on 220Mhz">Possible Telemetry GFSK signal on 220Mhz</a></li><li>2023-06-10 04:52:19 <a href="https://www.sigidwiki.com/wiki/FSK%3F" title="FSK?">FSK?</a></li><li>2023-06-09 15:13:27 <a href="https://www.sigidwiki.com/wiki/433p920" title="433p920">433p920</a></li><li>2023-04-21 10:19:13 <a href="https://www.sigidwiki.com/wiki/Unknown_RADAR_Near_Toronto_Canada" title="Unknown RADAR Near Toronto Canada">Unknown RADAR Near Toronto Canada</a></li><li>2023-04-12 00:20:19 <a href="https://www.sigidwiki.com/wiki/Unidentified_Player-Piano-Roll-Like_Digital_Signal" title="Unidentified Player-Piano-Roll-Like Digital Signal">Unidentified Player-Piano-Roll-Like Digital Signal</a></li><li>2023-02-27 16:05:39 <a href="https://www.sigidwiki.com/wiki/Unidentified_Thing" title="Unidentified Thing">Unidentified Thing</a></li><li>2022-11-17 08:53:08 <a href="https://www.sigidwiki.com/wiki/Ham_Band_Interference" title="Ham Band Interference">Ham Band Interference</a></li><li>2022-11-03 16:30:23 <a href="https://www.sigidwiki.com/wiki/Bird_Signal" title="Bird Signal">Bird Signal</a></li><li>2022-09-01 00:56:33 <a href="https://www.sigidwiki.com/wiki/UNID_microwave_sounding_signal_12_MHz" title="UNID microwave sounding signal 12 MHz">UNID microwave sounding signal 12 MHz</a></li><li>2022-06-23 22:29:20 <a href="https://www.sigidwiki.com/wiki/Unknown_military_airwaves_signal_334.520_MHz" title="Unknown military airwaves signal 334.520 MHz">Unknown military airwaves signal 334.520 MHz</a></li></ul>
</td>
<td> <ul><li>2023-09-22 14:44:27 <a href="https://www.sigidwiki.com/wiki/Unknown_151" title="Unknown 151">Unknown 151</a></li><li>2023-08-11 04:03:08 <a href="https://www.sigidwiki.com/wiki/Unidentified_406p214" title="Unidentified 406p214">Unidentified 406p214</a></li><li>2023-08-11 03:49:45 <a href="https://www.sigidwiki.com/wiki/Repeated_Tone" title="Repeated Tone">Repeated Tone</a></li><li>2023-07-28 06:02:52 <a href="https://www.sigidwiki.com/wiki/Possible_Telemetry_GFSK_signal_on_220Mhz" title="Possible Telemetry GFSK signal on 220Mhz">Possible Telemetry GFSK signal on 220Mhz</a></li><li>2023-06-11 09:38:57 <a href="https://www.sigidwiki.com/wiki/433p920" title="433p920">433p920</a></li><li>2023-06-10 05:17:29 <a href="https://www.sigidwiki.com/wiki/FSK%3F" title="FSK?">FSK?</a></li><li>2023-06-09 12:06:16 <a href="https://www.sigidwiki.com/wiki/433p90" title="433p90">433p90</a></li><li>2023-06-05 15:48:28 <a href="https://www.sigidwiki.com/wiki/Unknown_RADAR_Near_Toronto_Canada" title="Unknown RADAR Near Toronto Canada">Unknown RADAR Near Toronto Canada</a></li><li>2023-04-12 00:20:17 <a href="https://www.sigidwiki.com/wiki/Unidentified_Player-Piano-Roll-Like_Digital_Signal" title="Unidentified Player-Piano-Roll-Like Digital Signal">Unidentified Player-Piano-Roll-Like Digital Signal</a></li><li>2023-02-27 16:05:39 <a href="https://www.sigidwiki.com/wiki/Unidentified_Thing" title="Unidentified Thing">Unidentified Thing</a></li></ul>
</td></tr></tbody></table>

<h2></h2>
<p>General comments may be left at the <a href="https://www.sigidwiki.com/wiki/Comments" title="Comments">Comments</a> page.
</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bounty to Recover NIST's Elliptic Curve Seeds (121 pts)]]></title>
            <link>https://www.schneier.com/blog/archives/2023/10/bounty-to-recover-nists-elliptic-curve-seeds.html</link>
            <guid>37869353</guid>
            <pubDate>Fri, 13 Oct 2023 11:23:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.schneier.com/blog/archives/2023/10/bounty-to-recover-nists-elliptic-curve-seeds.html">https://www.schneier.com/blog/archives/2023/10/bounty-to-recover-nists-elliptic-curve-seeds.html</a>, See on <a href="https://news.ycombinator.com/item?id=37869353">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-67930">

	<div>

		
		<p><a href="https://words.filippo.io/dispatches/seeds-bounty/">This</a> is a fun challenge:</p>
<blockquote><p>The NIST elliptic curves that power much of modern cryptography were generated in the late ’90s by hashing seeds provided by the NSA. How were the seeds generated? Rumor has it that they are in turn hashes of English sentences, but the person who picked them, Dr. Jerry Solinas, passed away in early 2023 leaving behind a cryptographic mystery, some conspiracy theories, and an historical password cracking challenge.</p></blockquote>
<p>So there’s a $12K prize to recover the hash seeds.</p>
<p>Some <a href="https://news.ycombinator.com/item?id=37784499">backstory</a>:</p>
<blockquote><p>Some of the backstory here (it’s the funniest fucking backstory ever): it’s lately been circulating—though I think this may have been somewhat common knowledge among practitioners, though definitely not to me—that the “random” seeds for the NIST P-curves, generated in the 1990s by Jerry Solinas at NSA, were simply SHA1 hashes of some variation of the string “Give Jerry a raise”.</p>
<p>At the time, the “pass a string through SHA1” thing was meant to <i>increase</i> confidence in the curve seeds; the idea was that SHA1 would destroy any possible structure in the seed, so NSA couldn’t have selected a deliberately weak seed. Of course, NIST/NSA then set about destroying its reputation in the 2000’s, and this explanation wasn’t nearly enough to quell conspiracy theories.</p>
<p>But when Jerry Solinas went back to reconstruct the seeds, so NIST could demonstrate that the seeds really were benign, he found that he’d forgotten the string he used!</p>
<p>If you’re a true conspiracist, you’re certain nobody is going to find a string that generates any of these seeds. On the flip side, if anyone does find them, that’ll be a pretty devastating blow to the theory that the NIST P-curves were maliciously generated—even for people totally unfamiliar with basic curve math.</p></blockquote>
<p>Note that this is <i>not</i> the constants used in the Dual_EC_PRNG random-number generator that the NSA <a href="https://www.wired.com/2007/11/securitymatters-1115/">backdoored</a>. This is something different.</p>

		
			<p>
				<span>Tags: <a href="https://www.schneier.com/tag/backdoors/" rel="tag">backdoors</a>, <a href="https://www.schneier.com/tag/contests/" rel="tag">contests</a>, <a href="https://www.schneier.com/tag/cryptography/" rel="tag">cryptography</a>, <a href="https://www.schneier.com/tag/nist/" rel="tag">NIST</a>, <a href="https://www.schneier.com/tag/random-numbers/" rel="tag">random numbers</a></span>			</p>

		
		
		<p>
			<a href="https://www.schneier.com/blog/archives/2023/10/bounty-to-recover-nists-elliptic-curve-seeds.html" rel="bookmark">Posted on October 12, 2023 at 7:09 AM</a>			•
			<a href="https://www.schneier.com/blog/archives/2023/10/bounty-to-recover-nists-elliptic-curve-seeds.html#comments">21 Comments</a>		</p>

		
	</div>

</article><p id="powered">Sidebar photo of Bruce Schneier by Joe MacInnis.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What I wish I knew when I got my ASN (147 pts)]]></title>
            <link>https://quantum5.ca/2023/10/10/what-i-wish-i-knew-when-i-got-my-asn/</link>
            <guid>37869220</guid>
            <pubDate>Fri, 13 Oct 2023 11:02:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://quantum5.ca/2023/10/10/what-i-wish-i-knew-when-i-got-my-asn/">https://quantum5.ca/2023/10/10/what-i-wish-i-knew-when-i-got-my-asn/</a>, See on <a href="https://news.ycombinator.com/item?id=37869220">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>As you may know, I am currently writing <a href="https://quantum5.ca/category/bgp/">a series</a> on BGP and how the
Internet works, from my perspective as the operator of a small autonomous
system, <a href="https://as200351.net/">AS200351</a>. While we haven’t really exhausted the theoretical
material, I think I’ve covered enough to enable readers to set up their own
basic autonomous system. Rather than forcing you to do your own research based
on outdated and potentially incorrect information on the Internet, or allowing
you to fall victim to scams, I think it would be wise to talk about the process
of getting your own ASN.</p>

<p>For readers who haven’t read the previous parts of the series and are unfamiliar
with why one might want an ASN, here’s a brief explanation:</p>

<blockquote>
  <p>An <a href="https://en.wikipedia.org/wiki/Autonomous_system_(Internet)">autonomous system</a> (AS) is a constituent part of the Internet that can
define its own routing to the remainder of the Internet, and ASes exchange
routes with each other over <a href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol">Border Gateway Protocol (BGP)</a> to form the
Internet itself. By receiving a globally unique identifier, an AS number
(ASN), which in my case is 200351, I can exchange routes over BGP with other
ASes, announce my own IP addresses to the Internet, and control how traffic
flows in and out of my network, as opposed to simply exchanging traffic from a
default gateway to reach the Internet with an IP address assigned by my ISP.
This comes with several advantages, such as being able to switch upstream ISPs
at will (or when such an ISP fails) without changing my IP addresses or
breaking a single connection; or to advertise the same IP addresses from
multiple locations (<a href="https://en.wikipedia.org/wiki/Anycast">anycasting</a>) to allow users to reach my services
with lower latency than otherwise permissible by the speed of light with
automatic failover.</p>
</blockquote>

<p>I will now share what I wish I knew when I impulsively decided to apply for an
ASN at 3 a.m. on a cold December night last year, now that I’ve been doing this
for a while. I’ll walk through the process as objectively and thoroughly as
possible, demystifying the role of any player in this space. I would like you to
go into this with full knowledge of the risks and a full understanding of where
your money is going. In the end, I will offer some subjective suggestions on
providers, but those can be ignored if you would rather do your own research.</p>

<!--more-->

<h2 id="choosing-an-rir">Choosing an RIR</h2>

<p>As mentioned before in this series, ASNs and IP addresses are <em>Internet
numbers</em>, which are resources ultimately managed by the <a href="https://en.wikipedia.org/wiki/Internet_Assigned_Numbers_Authority">IANA</a>, whose
assignment is delegated to the <a href="https://en.wikipedia.org/wiki/Regional_Internet_registry">Regional Internet Registries (RIRs)</a>. There
are five RIRs in the world, but since I only have experience with <a href="https://arin.net/">ARIN</a>
and <a href="https://ripe.net/">RIPE NCC</a>, I will mostly focus on these two.</p>

<p>Typically, RIRs allocate ASNs directly to end users, whereas RIRs may allocate
IP addresses directly, but also to <a href="https://en.wikipedia.org/wiki/Regional_Internet_registry#Local_Internet_registry">Local Internet Registries (LIRs)</a> who
allocate them to end users. In order for RIRs to issue an ASN, they typically
require you to have your own IP addresses that you can announce with BGP, so you
probably want to get IP addresses first—either from an RIR directly or from an
LIR—or get them <em>with</em> the ASN if that’s an option. Note that it’s possible to
use your own IP addresses without your own ASN by getting an ISP to announce
them for you, a service typically called “bring your own IP” or BYOIP, but we
aren’t doing that here.</p>

<p>Given the current state of <a href="https://en.wikipedia.org/wiki/IPv4_address_exhaustion">IPv4 address exhaustion</a>, you will
almost certainly be getting IPv6 addresses, likely exclusively. As such, IPv6
will be the main focus.</p>

<p>No matter what, you need to choose an RIR for your ASN and IP addresses. Even if
you choose to use an LIR for your IP addresses, they ultimately come from an
RIR, and the choice of RIR affects how you manage your resources as well as how
the resources can be used. The “conventional wisdom” here—espoused by the top
search results from hobbynet bloggers—is that ARIN is focused on businesses and
RIPE is more hobbynet-friendly, but that’s a rather distorted version of the
truth. I’ve done my reading in the past and thought this way once, but I’ve come
to realize that things are a lot more complicated than that.</p>

<p>At this point, it might be worth noting that each RIR has its own policies on
how resources are allocated and how membership is managed, and these policies
are mostly motivated by the situation in their service region.</p>

<h3 id="ripe">RIPE</h3>

<p>Either way, let’s start with RIPE—or really, RIPE NCC, the <em>Réseaux IP
Européens</em> Network Coordination Centre. This is the RIR responsible for “Europe
and the Middle East”. Due to the relative difficulty of creating companies or
getting a trade name for sole proprietors in Europe, RIPE allows
“organisations”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup> to be created directly with personal names without
question.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup> For this reason, RIPE is perceived to be a lot more friendly
toward hobbyists.</p>

<p>RIPE will only serve users who live or have “network presence” in their service
region. As far as RIPE is concerned, the latter means having at least a single
VPS in the region, which should be announcing at least one route under your ASN,
if you choose to get an ASN from them. If you aren’t a resident in the region,
you will be asked to produce an invoice for it. As long as you fulfill this
requirement, your RIPE resources may be used anywhere in the world.</p>

<p>IP resources in RIPE are broadly divided into two categories—Provider
Aggregatable (PA) and Provider Independent (PI). PA addresses are large blocks
(typically /29 or larger) allocated by RIPE to LIRs, who can in turn hand them
to whoever they please—well, subject to RIPE policy. In practice, there aren’t
many restrictions, and I’ve seen smaller blocks (especially /44 or smaller)
regularly being given away for free. It is <strong>important</strong> to note that as far as
RIPE is concerned, the PA block <em>belongs to the LIR</em> and <strong>not</strong> to the end
users to whom the LIR has assigned subblocks. This means that should the LIR go
under, RIPE <em>will take back the entire IP block</em> and end users will lose their
allocations without much warning. Therefore, when using PA addresses, it is
important to use an LIR that you can trust to continue existing.</p>

<p>You should also understand how LIRs operate. To become an LIR, RIPE will charge
a one-time fee, currently €1000, along with an annual fee, currently €1550, to
be paid in January of every year, which is prorated for new LIRs. RIPE
subscribes to the “one LIR, one fee” policy, which means large and small LIRs
pay the same. For details, see the <a href="https://www.ripe.net/participate/member-support/payment">RIPE payments page</a>. By policy,
each new LIR is entitled to a /24 of IPv4 (due to IPv4 exhaustion, any new LIR
will wait a long time before receiving it) and no more. For IPv6, new LIRs are
entitled to a /29 without justification.</p>

<p>If you choose to get PA addresses from an LIR, keep in mind they probably have
at least a /29 (which is 512k /48s) and are paying €1550/year for it. This means
that if they manage to fully sell their initial /29, they’ll break even selling
each /40 for 76 cents, each /44 for 4.8 cents, or each /48 for 0.3 cents per
year. Taking into account the sales and management overhead and the fact the LIR
might not sell 99% of their space, an LIR should probably not charge more than
$20/year for a PA block of /44 or smaller, or more than $40/year for a /40.</p>

<p>PI addresses are small blocks, typically no larger than /48, issued by RIPE
directly to end users. Of course, RIPE doesn’t deal with end users
directly—instead, users need to get an LIR to sponsor their request and act as
the intermediary. For each PI request, RIPE currently charges €50/year. A single
request may result in multiple /48s being allocated if the requester has
multiple sites and requests a /48 for each, as that’s the minimum routable size
on the Internet. It is very rare if not impossible for RIPE to allocate a /44 or
larger block of PI addresses, whether contiguously or in aggregate, so any LIR
purporting to sell that is unlikely to be able to deliver.</p>

<p>Typically, an LIR would charge a bit more than €50/year to handle the request,
but they are probably ripping you off if they charge more than double that.
Also, note that PI addresses are severely limited in use cases compared to PA.
For the exact details, see <a href="https://www.ripe.net/manage-ips-and-asns/ipv6/request-ipv6/how-to-request-an-ipv6-pi-assignment">the RIPE policy on this</a>. Furthermore, if
the sponsoring LIR for a PI block goes under, RIPE will ask the end user to find
another LIR sponsor within 30 days or take back the resource.</p>

<p>ASNs function very similarly to PI resources and require the same sponsorship
process, but they currently cost the LIRs nothing to get. This may change one
day. There was a proposal this year at the RIPE NCC General Meeting to add a
€50/year/ASN fee, but the motion has been defeated, though it may show up again.
For this reason, I think LIRs that charge annual fees for ASNs are being
unreasonable. In general, I don’t think an ASN should cost more than $100
one-time to issue.</p>

<p>Since IP addresses are required for an ASN to be issued, it’s also common for
LIRs to sell ASN and IP bundles. In these cases, the one-time fee should cover
the ASN and the recurring fee for the IP range.</p>

<h3 id="arin">ARIN</h3>

<p>On the other hand, the American Registry for Internet Numbers (ARIN) is the RIR
responsible for the US, Canada, and some Caribbean islands. In this region, it
is a lot easier to start a business, so ARIN requires you to be some form of
business before they will deal with you. From this, people get the impression
that ARIN hates hobbyists. This is not true, since ARIN will accept the simplest
business structure—the <a href="https://en.wikipedia.org/wiki/Sole_proprietorship">sole proprietorship</a>. Typically, they would like you
to have a trade name, which you can typically request from your local government
for a small sum of money. For example, in the province of Ontario, Canada, the
government issued me a “Business Name” for “Dynamic Quantum Networks” for $60
CAD, which is valid for 5 years. This is not more expensive than a domain name.
Alternatively, ARIN will let you use your personal name if you can prove you
have been doing business under that name.</p>

<p>For IP addresses, ARIN has two styles of allocations—ISP/LIR and end user.
ISP/LIR allocations are quite similar to RIPE’s concept of PA addresses. An ARIN
LIR can allocate their IP range to their customers as they please, provided that
records are kept to demonstrate that suballocations have been reasonable when
requesting more addresses. End user allocations are similar to PI, but ARIN
doesn’t have the concept of sponsorships. Instead, ARIN allocates resources
directly to the end user. In general, it probably makes more sense to request
resources as an ISP/LIR if possible, since the policies are a lot less
restrictive. For details, see the <a href="https://www.arin.net/participate/policy/nrpm/">Number Resource Policy Manual (NRPM)</a>,
specifically sections 4.2, 4.3, and 6.5.</p>

<p>Note that, unlike RIPE which allows your resources to be used anywhere, ARIN has
a more strict out-of-region use policy, requiring /22 of IPv4 to be used
in-region before you can use any IPv4 out-of-region. For IPv6, this is a /44
used in-region. For ASNs, the ASN must be present on at least one peering
session in-region. For details, see <a href="https://www.arin.net/participate/policy/nrpm/#9-out-of-region-use">the policy</a>.</p>

<p>ARIN has several one-time fees, such as for creating an organization, which is
required to receive any allocation. This fee is currently $50. ARIN’s annual
fees are based on the amount of resources that you have, currently starting at
$250 for up to a /24 of IPv4 and a /40<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup> of IPv6. Currently, ARIN charges $550
to allocate an ASN and $150/year/ASN for ASN-only organizations. If you have any
IP addresses, you instead pay the annual fee and all ASNs are free once issued.
For details, see the <a href="https://www.arin.net/resources/fees/fee_schedule/">fee schedule</a>.</p>

<p>In 2024, this fee schedule is changing to be more reasonable—ASNs will be free
to allocate, and the smallest $250 annual fee covers up to 3 ASNs. For details,
see <a href="https://www.arin.net/resources/fees/fee_schedule/2024_faq/">the FAQ for this change</a>.</p>

<p>The simplified summary of ARIN’s allocation policy is as follows:</p>
<ul>
  <li>An LIR can request an initial IPv6 allocation of /32 without justification. An
LIR may choose to receive a /36 or a /40 instead to save on fees, but ARIN
reserves the full /32 and you can choose to upgrade at any time without
justification;</li>
  <li>An LIR can request an IPv4 allocation of /22 by going on the waitlist, for a
total of /20. An LIR may also request special reserved blocks with proper
justification; and</li>
  <li>An LIR can request an ASN with two peering partners.</li>
</ul>

<h3 id="other-rirs">Other RIRs</h3>

<p>APNIC may be an option if you live in the Asia-Pacific region. I am not familiar
with their policies, but I know they give a /23 of IPv4 addresses to each new
LIR, which is also the maximum amount of IPv4 APNIC will ever allocate.</p>

<p>AfriNIC and LACNIC don’t have all the features you’d expect from APNIC, ARIN,
and RIPE. For example, neither has an RPKI publication service for their
members, requiring the user to maintain their own. AfriNIC in particular is
also involved in <a href="https://en.wikipedia.org/wiki/AFRINIC#Controversies_and_scandals">many controversies and scandals</a>.</p>

<h3 id="decision">Decision</h3>

<p>I am not qualified to speak about APNIC, AfriNIC, or LACNIC, so I won’t. If you
live in their service region, you are welcome to do your own research and
compare them with RIPE, which remains a popular option for hobbyists in those
regions.</p>

<p>This leaves us with ARIN and RIPE. At first glance, ARIN might seem a lot more
expensive than RIPE, but keep in mind that:</p>
<ol>
  <li>even paying the lowest possible annual fee, you are a full member of ARIN and
can receive resources directly. This means you don’t need to worry about your
LIR going under; and</li>
  <li>ARIN has reserved pools of IPv4 addresses that can be immediately allocated
if you qualify for them. Given that the market rate of an IPv4 /24 is around
$1000/year, and that you will need to pay the full LIR fee to even get on
RIPE’s waitlist for a /24, ARIN’s $250/year fee for a /24 seems quite
reasonable. ARIN also has an IPv4 waitlist, but at least you don’t pay for
the resources until you receive them and you can request up to a /22 at once.</li>
</ol>

<p>In conclusion, RIPE seems like a decent choice for a beginner on a budget trying
to get the cheapest ASN and an IPv6 block possible, as long as the caveat with PA
addresses is understood. For a more serious network operating in ARIN’s service
region, especially one looking to run IPv4, ARIN is a strong contender.</p>

<p>Note that you can get IP space from one RIR and announce it with an ASN from
another RIR without issue. I personally operate AS200351, an ASN from RIPE, with
IP space from ARIN. If I were starting next year, given the knowledge that I
have now, I would probably have just gone with ARIN for everything.</p>

<h2 id="getting-an-asn">Getting an ASN</h2>

<p>First, regardless of RIR, you need to have two peers to justify having
an ASN. You can ask people in the <a href="https://discord.gg/ipv6">IPv6 networking discord</a> if they are
willing to peer.</p>

<p>You are also strongly encouraged to familiarize yourself with the policies of
your chosen RIR:</p>
<ul>
  <li>For RIPE, these are <a href="https://www.ripe.net/publications/docs/ripe-804">RIPE-804</a> for IPv4, <a href="https://www.ripe.net/publications/docs/ripe-738">RIPE-738</a> for
IPv6, and <a href="https://www.ripe.net/publications/docs/ripe-679">RIPE-679</a> for ASNs; and</li>
  <li>For ARIN, this is the <a href="https://www.arin.net/participate/policy/nrpm/">NRPM</a>.</li>
</ul>

<p>If you choose to use RIPE, you will need to find an LIR with a good reputation
that charges reasonable fees and get some PA addresses from them, which they
should be able to allocate very quickly, then request an ASN. Many LIRs offer
some IP+ASN bundle that does both together. If you are unsure which LIR to pick,
feel free to ask in the <a href="https://discord.gg/ipv6">IPv6 networking discord</a>, and I’ll also post
some recommendations below. Once you’ve done this, you will need to:</p>

<ol>
  <li>Register an <a href="https://access.ripe.net/registration">RIPE NCC Access account</a>;</li>
  <li>Create a <a href="https://apps.db.ripe.net/db-web-ui/webupdates/create/RIPE/person/self">person and maintainer pair</a> in the RIPE database (the
form should be self-explanatory);</li>
  <li>Create an <a href="https://apps.db.ripe.net/db-web-ui/webupdates/create/RIPE/organisation">“organisation” object</a> in the RIPE database. For
<code>org-name</code>, use your legal name or the name of a company that you control.
For <code>mnt-ref</code>, enter the <code>mntner</code> you created earlier. By the way, you will
also need to add a second <code>mnt-ref</code> entry later for your LIR to be able to
assign you an ASN or IP space, and they should tell you which one to add.
Everything else should be self-explanatory;</li>
  <li>Give the chosen LIR information on all the objects you’ve created in the RIPE
database and probably pay them as well;</li>
  <li>Sign an agreement with the LIR;</li>
  <li>Wait for the LIR to give you an identity verification link from RIPE<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup> and
then complete the verification; and</li>
  <li>Wait for RIPE to issue your ASN.</li>
</ol>

<p>If you are going with ARIN, they have video guides for <a href="https://www.arin.net/resources/guide/account/">setting up your Org
ID</a> and <a href="https://www.arin.net/resources/guide/request/">requesting IP addresses</a>. You want to create an Org
ID, sign the Registration Services Agreement, request an initial allocation for
IPv6, then request an ASN.</p>

<h2 id="what-to-do-with-an-asn">What to do with an ASN</h2>

<p>Once you have an ASN, there are a few things you should probably do:</p>
<ol>
  <li>Create an AS-set for your AS-macro, which I talked about <a href="https://quantum5.ca/2023/07/19/diving-into-autonomous-systems/#as-sets-routing-registries-and-cones">earlier</a>.
You want to create this in the database of whichever RIR you used. You should
use the hierarchical form, naming it something like <code>ASx:as-all</code> where <code>x</code> is
your ASN, and add your own ASN as its sole member; and</li>
  <li>(Optional but recommended) Register on <a href="https://peeringdb.com/">PeeringDB</a> and create a profile
for your ASN on it. You can use <a href="https://peeringdb.com/asn/200351">mine</a> as a reference.</li>
</ol>

<p>Then, you will need to find a BGP-capable server or colocation provider and pick
an IP range (/24 or larger for IPv4, /48 or larger for IPv6) to announce from
that server. You will most likely need to ask your provider to request a BGP
session, at which point you should tell them your ASN, AS-macro, and the IP
ranges you plan to announce. They may send a random string to the contact on
your organization object or the <code>aut-num</code> object for your ASN in the RIR whois
database and ask you to produce it, or ask you to set up RPSL declaring that
your provider is allowed to act as your upstream. In the latter case, if you
received AS64500 and your upstream is AS64510, you will need to add the
following lines to your <code>aut-num</code> object:</p>

<div><pre><code>import:         from AS64510 accept ANY
export:         to AS64510 announce AS64500:as-all
</code></pre></div>

<p>You can set up a basic BGP session with any BGP daemon. I would recommend using
whatever your BGP-capable router uses, or <a href="https://bird.network.cz/">bird</a> if you are just using a
Linux server. If you are using <code>bird</code>, you can build a configuration yourself
with the sample snippets from my <a href="https://github.com/quantum5/bird-filter"><code>bird</code> filter library</a>, or use a
configuration generator like <a href="https://pathvector.io/">PathVector</a>.</p>

<p>Now comes the hard part—building up your own network. There are many things you
can do, such as joining Internet Exchanges and getting multiple upstreams. The
possibilities are endless, and I can’t begin to explain everything that’s
possible. You will likely need to learn through trial and error. Good luck! If
you have any questions, feel free to ask them in the <a href="https://discord.gg/ipv6">IPv6 networking
discord</a>, where there are many people happy to help you out.</p>

<p>If there is popular demand, I may write a more in-depth post on setting up your
ASN. Otherwise, I’d probably just continue writing about the theory.</p>

<h2 id="recommendations">Recommendations</h2>

<p>This is when things get subjective. The providers listed here are believed to
have a good reputation by me or by people that I believe to be trustworthy and
charge reasonable rates. However, please use your common sense in case things
change. Also, if I use an affiliate link, I will offer an unaffiliated option as
well.</p>

<p>RIPE LIRs:</p>
<ul>
  <li><a href="https://my.cloudie.sh/aff.php?aff=20&amp;gid=7">Cloudie Networks</a> (<a href="https://my.cloudie.sh/index.php?rp=/store/lir-services">non-affiliate</a>)</li>
  <li><a href="https://scaleblade.com/products/lir">Scaleblade</a></li>
  <li><a href="https://my.ifog.ch/order/main/packages/LIR-Services/?group_id=1&amp;a=MTIyMw==">iFog</a> (for ASN and PI only, <a href="https://ifog.ch/en/ip/lir-services">non-affiliate</a>)</li>
  <li><a href="https://freetransit.ch/">FreeTransit</a></li>
</ul>

<p>Note that you can probably get a PA /48 from a reputable LIR for free if you ask
around on Discord.</p>

<p>BGP-capable hosting:</p>
<ul>
  <li><a href="https://clients.accuristechnologies.ca/aff.php?aff=16&amp;gid=1">Accuris</a> (<a href="https://clients.accuristechnologies.ca/index.php?rp=/store/ottawa-kvm-vps">non-affiliate</a>)</li>
  <li><a href="https://my.frantech.ca/aff.php?aff=6718&amp;gid=1">BuyVM</a> (<a href="https://my.frantech.ca/cart.php">non-affiliate</a>)</li>
  <li>Cloudie Networks in <a href="https://my.cloudie.sh/aff.php?aff=20&amp;gid=22">Toronto</a> (<a href="https://my.cloudie.sh/index.php?rp=/store/onix-internet-exchange-offers">non-affiliate</a>) and
<a href="https://my.cloudie.sh/aff.php?aff=20&amp;gid=21">Fremont</a> (<a href="https://my.cloudie.sh/index.php?rp=/store/onix-internet-exchange-offers">non-affiliate</a>)</li>
  <li><a href="https://store.f4.network/index.php/order/forms/a/NTA=">F4 Networks</a> (<a href="https://store.f4.network/index.php/order/forms/">non-affiliate</a>)</li>
  <li><a href="https://my.ifog.ch/order/forms/a/MTIyMw==">iFog</a> (<a href="https://my.ifog.ch/order/forms/">non-affiliate</a>)</li>
  <li><a href="https://billing.limewave.net/aff.php?aff=103">Limewave</a> (<a href="https://billing.limewave.net/index.php?rp=/store/seattle-ryzen-kvm">non-affiliate</a>)</li>
  <li><a href="https://www.vultr.com/?ref=7302430">Vultr</a> (<a href="https://www.vultr.com/">non-affiliate</a>)</li>
  <li><a href="https://xenyth.net/?affid=878">Xenyth</a> (<a href="https://xenyth.net/">non-affiliate</a>)</li>
</ul>

<p>These cover the ones with which I’ve had personal experience. There are more
providers available on <a href="https://bgp.cheap/">bgp.cheap</a> and <a href="https://bgp.directory/">bgp.directory</a>
maintained by community members, but I can’t vouch for all of them personally.</p>

<h2 id="notes">Notes</h2>



  </div></div>]]></description>
        </item>
    </channel>
</rss>