<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 16 Feb 2024 13:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Alexei Navalny has died – authorities (337 pts)]]></title>
            <link>https://www.reuters.com/world/europe/jailed-russian-opposition-leader-navalny-dead-prison-service-2024-02-16/</link>
            <guid>39395631</guid>
            <pubDate>Fri, 16 Feb 2024 11:34:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/europe/jailed-russian-opposition-leader-navalny-dead-prison-service-2024-02-16/">https://www.reuters.com/world/europe/jailed-russian-opposition-leader-navalny-dead-prison-service-2024-02-16/</a>, See on <a href="https://news.ycombinator.com/item?id=39395631">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/europe/jailed-russian-opposition-leader-navalny-dead-prison-service-2024-02-16/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Kagi Changelog 2/13: Faster and more accurate instant answers and Wikipedia page (153 pts)]]></title>
            <link>https://kagi.com/changelog#3179</link>
            <guid>39394060</guid>
            <pubDate>Fri, 16 Feb 2024 06:59:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kagi.com/changelog#3179">https://kagi.com/changelog#3179</a>, See on <a href="https://news.ycombinator.com/item?id=39394060">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mainContent"><div id="3179"><h2><span>Feb 13, 2024 - Faster and more accurate instant answers. And we got a Wikipedia page!</span><a href="https://kagi.com/changelog#3179"> #</a></h2><div><h3>Features</h3><ul><li><p>We added <strong>Wolfram|Alpha to enhance our capabilities in calculations, unit conversions, and time</strong> queries for better results. This solves a huge number of issues reported for these kind of queries as the results now come from a computational knowledge authorithy.</p> <p>(Wolfram Alpha integration for fact based queries <a href="https://kagifeedback.org/d/1271" data-id="1271"><span></span></a><a href="https://kagifeedback.org/d/1271">#1271</a> <a href="https://kagifeedback.org/u/Recast">@Recast</a>)</p></li></ul><p><img src="https://kagifeedback.org/assets/files/2024-02-13/1707850630-598677-screenshot-2024-02-13-at-105705.png" title="" alt=""></p><p><img src="https://kagifeedback.org/assets/files/2024-02-13/1707852556-300223-image.png" title="" alt=""></p><ul><li>In the same spirit of <strong>getting answers faster</strong>, now simply starting your query with an interrogative word (what, where, who, which, when, how) or just ending it with a question mark (?) will <strong>automatically trigger Quick Answer</strong>:</li></ul><p><img src="https://kagifeedback.org/assets/files/2024-02-13/1707851550-889014-screenshot-2024-02-13-at-111224.png" title="" alt=""></p><p><img src="https://kagifeedback.org/assets/files/2024-02-13/1707851590-997746-screenshot-2024-02-13-at-111305.png" title="" alt=""></p><ul><li><p>Video results will now feature <strong>duration, channel name and timestamp</strong>  <a href="https://kagifeedback.org/d/2970" data-id="2970"><span></span></a><a href="https://kagifeedback.org/d/2970">#2970</a> <a href="https://kagifeedback.org/u/blosh">@blosh</a>)<br><img src="https://kagifeedback.org/assets/files/2024-02-13/1707850745-196425-screenshot-2024-02-13-at-105856.png" title="" alt=""></p></li><li><p>You can now <strong>hear how words are pronounced</strong> directly in our dictionary results, <a href="https://kagifeedback.org/d/321" data-id="321"><span></span></a><a href="https://kagifeedback.org/d/321">#321</a> <a href="https://kagifeedback.org/u/Yuu">@Yuu</a> <br><img src="https://kagifeedback.org/assets/files/2024-02-13/1707849305-551491-image.png" title="" alt=""></p></li><li><p>We've introduced a new feature in Research Assistant that allows you to <strong>use your lenses to narrow down the scope of search results in Assistant</strong>   <a href="https://kagifeedback.org/d/2147" data-id="2147"><span></span></a><a href="https://kagifeedback.org/d/2147">#2147</a> <a href="https://kagifeedback.org/u/truethomas">@truethomas</a>)<br><img src="https://kagifeedback.org/assets/files/2024-02-13/1707840034-526042-image.png" title="" alt=""></p></li></ul><h3>Improvements &amp; Bug fixes</h3><ul><li>Switch between search and assistant mode without clearing the search <a href="https://kagifeedback.org/d/2390" data-id="2390"><span></span></a><a href="https://kagifeedback.org/d/2390">#2390</a> <a href="https://kagifeedback.org/u/mackid1993">@mackid1993</a></li><li>Time Ascending/Descending should contextually change to facilitate understanding <a href="https://kagifeedback.org/d/1387" data-id="1387"><span></span></a><a href="https://kagifeedback.org/d/1387">#1387</a> <a href="https://kagifeedback.org/u/kf">@kf</a> </li><li>Ctrl+V for assistant upload <a href="https://kagifeedback.org/d/3024" data-id="3024"><span></span></a><a href="https://kagifeedback.org/d/3024">#3024</a> <a href="https://kagifeedback.org/u/Value7609">@Value7609</a></li><li>Billing page does not have a way to show detailed consumption statistics on Trial plan <a href="https://kagifeedback.org/d/3052" data-id="3052"><span></span></a><a href="https://kagifeedback.org/d/3052">#3052</a> <a href="https://kagifeedback.org/u/aochagavia">@aochagavia</a></li><li>Turn Off Search Suggestions for Kids Accounts <a href="https://kagifeedback.org/d/3070" data-id="3070"><span></span></a><a href="https://kagifeedback.org/d/3070">#3070</a> <a href="https://kagifeedback.org/u/keen_dog">@keen_dog</a></li><li>Searching for a unicode sequence always opens first result <a href="https://kagifeedback.org/d/3078" data-id="3078"><span></span></a><a href="https://kagifeedback.org/d/3078">#3078</a> <a href="https://kagifeedback.org/u/cvzakharchenko">@cvzakharchenko</a> </li><li>Video search timestamps incorrect <a href="https://kagifeedback.org/d/3117" data-id="3117"><span></span></a><a href="https://kagifeedback.org/d/3117">#3117</a> <a href="https://kagifeedback.org/u/Amino4873">@Amino4873</a></li><li>Bang completion in browser search bar <a href="https://kagifeedback.org/d/1967" data-id="1967"><span></span></a><a href="https://kagifeedback.org/d/1967">#1967</a> <a href="https://kagifeedback.org/u/Value7609">@Value7609</a> </li><li>Semicolons aren't properly handled in the search results page <a href="https://kagifeedback.org/d/2365" data-id="2365"><span></span></a><a href="https://kagifeedback.org/d/2365">#2365</a> <a href="https://kagifeedback.org/u/laiz">@laiz</a></li><li>Markup sneaking into calculation responses <a href="https://kagifeedback.org/d/3053" data-id="3053"><span></span></a><a href="https://kagifeedback.org/d/3053">#3053</a> <a href="https://kagifeedback.org/u/anotherhue">@anotherhue</a></li><li>Quick Answer on iOS erroneously enables horizontal scroll <a href="https://kagifeedback.org/d/3166" data-id="3166"><span></span></a><a href="https://kagifeedback.org/d/3166">#3166</a> <a href="https://kagifeedback.org/u/equalidea">@equalidea</a> </li><li>Flight widget “show more” does not work on mobile <a href="https://kagifeedback.org/d/3136" data-id="3136"><span></span></a><a href="https://kagifeedback.org/d/3136">#3136</a> <a href="https://kagifeedback.org/u/stoyle">@stoyle</a></li><li>Copying from Assistant while it is writing it's answer doesn't work <a href="https://kagifeedback.org/d/2596" data-id="2596"><span></span></a><a href="https://kagifeedback.org/d/2596">#2596</a> <a href="https://kagifeedback.org/u/Grooty">@Grooty</a></li><li>[UI] popover for paid sites does not display on Mobile <a href="https://kagifeedback.org/d/3076" data-id="3076"><span></span></a><a href="https://kagifeedback.org/d/3076">#3076</a> <a href="https://kagifeedback.org/u/heliostatic">@heliostatic</a></li><li>Assistant answer format  <a href="https://kagifeedback.org/d/3068" data-id="3068"><span></span></a><a href="https://kagifeedback.org/d/3068">#3068</a> <a href="https://kagifeedback.org/u/cardinal086">@cardinal086</a></li><li>Pressing <code>c</code> while renaming a family will open the menu <a href="https://kagifeedback.org/d/3105" data-id="3105"><span></span></a><a href="https://kagifeedback.org/d/3105">#3105</a> <a href="https://kagifeedback.org/u/catgirlinspace">@catgirlinspace</a></li><li>Quick answer gives no answer <a href="https://kagifeedback.org/d/3108" data-id="3108"><span></span></a><a href="https://kagifeedback.org/d/3108">#3108</a> <a href="https://kagifeedback.org/u/X145678908765">@X145678908765</a></li><li>Assistant citation quotation do nothing on mobile <a href="https://kagifeedback.org/d/3085" data-id="3085"><span></span></a><a href="https://kagifeedback.org/d/3085">#3085</a> <a href="https://kagifeedback.org/u/stoyle">@stoyle</a></li></ul><h3>Fixed with Wolfram|Alpha computation integration</h3> <ul><li>Incorrect timezone conversion <a href="https://kagifeedback.org/d/2342" data-id="2342"><span></span></a><a href="https://kagifeedback.org/d/2342">#2342</a> <a href="https://kagifeedback.org/u/Crafty9853">@Crafty9853</a></li><li>Crypto to fiat conversation, increase floating point precision for cryptocurrency <a href="https://kagifeedback.org/d/2348" data-id="2348"><span></span></a><a href="https://kagifeedback.org/d/2348">#2348</a> <a href="https://kagifeedback.org/u/mccowen">@mccowen</a></li><li>Calculator struggling with percentages <a href="https://kagifeedback.org/d/2566" data-id="2566"><span></span></a><a href="https://kagifeedback.org/d/2566">#2566</a> <a href="https://kagifeedback.org/u/Krmloo">@Krmloo</a></li><li>Time conversion using city/region/country names and current location <a href="https://kagifeedback.org/d/756" data-id="756"><span></span></a><a href="https://kagifeedback.org/d/756">#756</a> <a href="https://kagifeedback.org/u/tychoregter">@tychoregter</a></li><li>Improve calculator widget <a href="https://kagifeedback.org/d/2505" data-id="2505"><span></span></a><a href="https://kagifeedback.org/d/2505">#2505</a> <a href="https://kagifeedback.org/u/EvacuatedTerminal">@EvacuatedTerminal</a></li><li>"time argentina" uses wrong timezone <a href="https://kagifeedback.org/d/2482" data-id="2482"><span></span></a><a href="https://kagifeedback.org/d/2482">#2482</a> <a href="https://kagifeedback.org/u/bwkagi">@bwkagi</a></li><li>Can't convert "bytes to MB" <a href="https://kagifeedback.org/d/2481" data-id="2481"><span></span></a><a href="https://kagifeedback.org/d/2481">#2481</a> <a href="https://kagifeedback.org/u/jesus">@jesus</a></li><li>Wrong time <a href="https://kagifeedback.org/d/2377" data-id="2377"><span></span></a><a href="https://kagifeedback.org/d/2377">#2377</a> <a href="https://kagifeedback.org/u/Edweis">@Edweis</a></li><li>Speed conversion widget <a href="https://kagifeedback.org/d/2362" data-id="2362"><span></span></a><a href="https://kagifeedback.org/d/2362">#2362</a> <a href="https://kagifeedback.org/u/lumpycustard">@lumpycustard</a></li><li>Asking from Cyprus time gives wrong answer <a href="https://kagifeedback.org/d/2032" data-id="2032"><span></span></a><a href="https://kagifeedback.org/d/2032">#2032</a> <a href="https://kagifeedback.org/u/asolovyov">@asolovyov</a></li><li>Calculator widget appears to be haunted (wrong results for MANY things) <a href="https://kagifeedback.org/d/2289" data-id="2289"><span></span></a><a href="https://kagifeedback.org/d/2289">#2289</a> <a href="https://kagifeedback.org/u/puppy">@puppy</a></li><li>Gallon to oz - unknown  <a href="https://kagifeedback.org/d/2212" data-id="2212"><span></span></a><a href="https://kagifeedback.org/d/2212">#2212</a> <a href="https://kagifeedback.org/u/partlycloudy">@partlycloudy</a></li><li>Conversion to minutes fails if using <code>min</code> <a href="https://kagifeedback.org/d/2082" data-id="2082"><span></span></a><a href="https://kagifeedback.org/d/2082">#2082</a> <a href="https://kagifeedback.org/u/xeophon">@xeophon</a></li><li>Add natural language maths to calculator <a href="https://kagifeedback.org/d/2061" data-id="2061"><span></span></a><a href="https://kagifeedback.org/d/2061">#2061</a> <a href="https://kagifeedback.org/u/StarMaze">@StarMaze</a></li><li>Calculator gives wrong answer for 2<sup>63 <a href="https://kagifeedback.org/d/1953" data-id="1953"><span></span></a><a href="https://kagifeedback.org/d/1953">#1953</a></sup> <a href="https://kagifeedback.org/u/rookwood101">@rookwood101</a></li><li>Unit converter can't handle small numbers <a href="https://kagifeedback.org/d/1995" data-id="1995"><span></span></a><a href="https://kagifeedback.org/d/1995">#1995</a> <a href="https://kagifeedback.org/u/ThreePointsShort">@ThreePointsShort</a></li><li>Recognize comma as decimal separator <a href="https://kagifeedback.org/d/2743" data-id="2743"><span></span></a><a href="https://kagifeedback.org/d/2743">#2743</a> <a href="https://kagifeedback.org/u/jstolarek">@jstolarek</a></li><li>A search for 'Eastern Time' brings up the wrong time zone <a href="https://kagifeedback.org/d/243" data-id="243"><span></span></a><a href="https://kagifeedback.org/d/243">#243</a> <a href="https://kagifeedback.org/u/CorlinP">@CorlinP</a></li><li>"Current time in ___" does not bring up time zone widget <a href="https://kagifeedback.org/d/99" data-id="99"><span></span></a><a href="https://kagifeedback.org/d/99">#99</a> <a href="https://kagifeedback.org/u/lacikawiz">@lacikawiz</a></li><li>Time zone conversion uses wrong time zone <a href="https://kagifeedback.org/d/1075" data-id="1075"><span></span></a><a href="https://kagifeedback.org/d/1075">#1075</a> <a href="https://kagifeedback.org/u/Jake-Moss">@Jake-Moss</a></li><li>Time Converter widget doesn't account for summer time <a href="https://kagifeedback.org/d/1031" data-id="1031"><span></span></a><a href="https://kagifeedback.org/d/1031">#1031</a> <a href="https://kagifeedback.org/u/Kai">@Kai</a></li><li>Time widget is broken <a href="https://kagifeedback.org/d/1053" data-id="1053"><span></span></a><a href="https://kagifeedback.org/d/1053">#1053</a> <a href="https://kagifeedback.org/u/test41">@test41</a></li><li>Time conversion is incorrect <a href="https://kagifeedback.org/d/1386" data-id="1386"><span></span></a><a href="https://kagifeedback.org/d/1386">#1386</a> <a href="https://kagifeedback.org/u/alanb">@alanb</a></li><li>Time widget thinks Palestine is five hours ahead of Israel <a href="https://kagifeedback.org/d/2985" data-id="2985"><span></span></a><a href="https://kagifeedback.org/d/2985">#2985</a> <a href="https://kagifeedback.org/u/cybiko123">@cybiko123</a></li><li>"Time in argentina" is incorrect <a href="https://kagifeedback.org/d/1379" data-id="1379"><span></span></a><a href="https://kagifeedback.org/d/1379">#1379</a> <a href="https://kagifeedback.org/u/kagiar">@kagiar</a></li><li>3pm PT is about pacific time <a href="https://kagifeedback.org/d/355" data-id="355"><span></span></a><a href="https://kagifeedback.org/d/355">#355</a> <a href="https://kagifeedback.org/u/matkoniecz">@matkoniecz</a></li><li>'Time in Equador' returns incorrect offset <a href="https://kagifeedback.org/d/1212" data-id="1212"><span></span></a><a href="https://kagifeedback.org/d/1212">#1212</a> <a href="https://kagifeedback.org/u/SamSkjord">@SamSkjord</a></li><li>Clock Widget - No/Odd results for some european microstates <a href="https://kagifeedback.org/d/25" data-id="25"><span></span></a><a href="https://kagifeedback.org/d/25">#25</a> <a href="https://kagifeedback.org/u/Deucalion">@Deucalion</a></li><li>Wrong timezone conversion for IST to CEST and wrong usage of CET/CEST <a href="https://kagifeedback.org/d/1669" data-id="1669"><span></span></a><a href="https://kagifeedback.org/d/1669">#1669</a> <a href="https://kagifeedback.org/u/Nankeru">@Nankeru</a></li><li>Widget for time span (e.g.  "38 days from now", "38 days from today") <a href="https://kagifeedback.org/d/119" data-id="119"><span></span></a><a href="https://kagifeedback.org/d/119">#119</a> <a href="https://kagifeedback.org/u/yokoffing">@yokoffing</a></li><li>Nautical miles unit conversion <a href="https://kagifeedback.org/d/1117" data-id="1117"><span></span></a><a href="https://kagifeedback.org/d/1117">#1117</a> <a href="https://kagifeedback.org/u/dharmab">@dharmab</a></li><li>Currency conversion search too slow <a href="https://kagifeedback.org/d/1116" data-id="1116"><span></span></a><a href="https://kagifeedback.org/d/1116">#1116</a> <a href="https://kagifeedback.org/u/Tomotake">@Tomotake</a></li><li>Fl oz conversion does not work in all regions <a href="https://kagifeedback.org/d/1883" data-id="1883"><span></span></a><a href="https://kagifeedback.org/d/1883">#1883</a> <a href="https://kagifeedback.org/u/mon">@mon</a></li><li>Convert kJ to Calories <a href="https://kagifeedback.org/d/2775" data-id="2775"><span></span></a><a href="https://kagifeedback.org/d/2775">#2775</a> <a href="https://kagifeedback.org/u/gateway">@gateway</a></li><li>Weird behavior when converting temperature <a href="https://kagifeedback.org/d/557" data-id="557"><span></span></a><a href="https://kagifeedback.org/d/557">#557</a> <a href="https://kagifeedback.org/u/trekt">@trekt</a></li><li>Incorrect decimal separator for calculation results <a href="https://kagifeedback.org/d/1336" data-id="1336"><span></span></a><a href="https://kagifeedback.org/d/1336">#1336</a> <a href="https://kagifeedback.org/u/hmnd">@hmnd</a></li><li>Allow commas for large numbers in calculator <a href="https://kagifeedback.org/d/136" data-id="136"><span></span></a><a href="https://kagifeedback.org/d/136">#136</a> <a href="https://kagifeedback.org/u/lacikawiz">@lacikawiz</a></li><li>Time conversion doesn't use daylight savings <a href="https://kagifeedback.org/d/344" data-id="344"><span></span></a><a href="https://kagifeedback.org/d/344">#344</a> <a href="https://kagifeedback.org/u/rozbb">@rozbb</a></li><li>Need more decimal places in USD-BTC conversion <a href="https://kagifeedback.org/d/1256" data-id="1256"><span></span></a><a href="https://kagifeedback.org/d/1256">#1256</a> <a href="https://kagifeedback.org/u/SK">@SK</a></li><li>Time conversion to daylight time <a href="https://kagifeedback.org/d/1433" data-id="1433"><span></span></a><a href="https://kagifeedback.org/d/1433">#1433</a> <a href="https://kagifeedback.org/u/matkam">@matkam</a></li><li>Currency Conversion Error <a href="https://kagifeedback.org/d/2910" data-id="2910"><span></span></a><a href="https://kagifeedback.org/d/2910">#2910</a> <a href="https://kagifeedback.org/u/cempack">@cempack</a></li><li>Calculator widget doesn't support shortenings of storage units (GB vs gigabyte) <a href="https://kagifeedback.org/d/1642" data-id="1642"><span></span></a><a href="https://kagifeedback.org/d/1642">#1642</a> <a href="https://kagifeedback.org/u/Grooty">@Grooty</a></li><li>Wrong calculator results when region set to Singapore <a href="https://kagifeedback.org/d/1216" data-id="1216"><span></span></a><a href="https://kagifeedback.org/d/1216">#1216</a> <a href="https://kagifeedback.org/u/bh">@bh</a></li><li>Math calculations round to 0 after e8 <a href="https://kagifeedback.org/d/2767" data-id="2767"><span></span></a><a href="https://kagifeedback.org/d/2767">#2767</a> <a href="https://kagifeedback.org/u/rudyfink">@rudyfink</a></li><li>Calculator ignores commas. <a href="https://kagifeedback.org/d/2323" data-id="2323"><span></span></a><a href="https://kagifeedback.org/d/2323">#2323</a> <a href="https://kagifeedback.org/u/guissmo">@guissmo</a></li></ul><h2>In other news</h2><p>Kagi got a <a href="https://en.wikipedia.org/wiki/Kagi_%28search_engine%29" rel="ugc nofollow">Wikipedia page</a>!</p></div></div><div id="3122"><h2><span>Feb 8, 2024 - Ultimate features available for Family / Duo plans</span><a href="https://kagi.com/changelog#3122"> #</a></h2><div><h3>Features</h3><ul><li>We're happy to announce that Family and Duo plan members can now upgrade to Ultimate plan features for just $15 per month. per family member upgraded. The Ultimate plan includes access to the latest AI models, such as GPT-4/GPT-4-Turbo, Claude 2.1 (100k) and soon Gemini Ultra. To upgrade your account or that of another member, simply visit the "Members" section under <a href="https://www.kagi.com/settings?p=account_members" rel="ugc nofollow">Family Settings</a>.</li></ul><p> <a href="https://kagifeedback.org/d/2024" data-id="2024"><span></span></a><a href="https://kagifeedback.org/d/2024">#2024</a> <a href="https://kagifeedback.org/u/nucleardog">@nucleardog</a></p><p><img src="https://kagifeedback.org/assets/files/2024-02-08/1707408105-538813-image.png" title="" alt=""></p><ul><li><a href="https://apps.apple.com/us/app/kagi-for-safari/id1622835804" rel="ugc nofollow">Kagi for Safari 2.2.0</a> is released, fixing many previous issues reported by the users.</li></ul><p><img src="https://kagifeedback.org/assets/files/2024-02-08/1707412278-840815-image.png" title="" alt=""></p><ul><li>We've improved the mobile experience for Assistant users. Now, Now, when composing your prompt, you can effortlessly access settings for Assistant, including options for Research mode and Chat mode. Additionally, the entire prompt is now fully visible.<br><img src="https://kagifeedback.org/assets/files/2024-02-08/1707415219-743952-image.png" title="" alt=""></li></ul><h3>Improvements &amp; Bug fixes</h3><ul><li>Kagi search on Firefox ESR 78 give JS error (previously fixed but happening again) <a href="https://kagifeedback.org/d/3055" data-id="3055"><span></span></a><a href="https://kagifeedback.org/d/3055">#3055</a> <a href="https://kagifeedback.org/u/kagi-not-working">@kagi-not-working</a> </li><li>Weather Widget Doesn't Display when Asking for Temperature <a href="https://kagifeedback.org/d/3046" data-id="3046"><span></span></a><a href="https://kagifeedback.org/d/3046">#3046</a> <a href="https://kagifeedback.org/u/bhagwad">@bhagwad</a></li><li>/ (slash) keyboard shortcut doesn't scroll to top in safari <a href="https://kagifeedback.org/d/2989" data-id="2989"><span></span></a><a href="https://kagifeedback.org/d/2989">#2989</a> <a href="https://kagifeedback.org/u/nullable">@nullable</a></li><li>Quick answer does not always show up on results page <a href="https://kagifeedback.org/d/3035" data-id="3035"><span></span></a><a href="https://kagifeedback.org/d/3035">#3035</a> <a href="https://kagifeedback.org/u/stoyle">@stoyle</a></li> </ul></div></div><div id="3106"><h2><span>Feb 6, 2024 - Two-factor authentication</span><a href="https://kagi.com/changelog#3106"> #</a></h2><div><h3>Features</h3><ul><li><p>Two-factor authentication (2FA) is now possible to further secure your Kagi account . This was the most upvoted feature on kagifeedback.org and we are glad to (finally) deliver it. You can <a href="https://kagi.com/settings?p=2fa_setup" rel="ugc nofollow">set it up</a> on your Settings page under the "Account" section. <a href="https://kagifeedback.org/u/Kai">@Kai</a> in <a href="https://kagifeedback.org/d/14" data-id="14"><span></span></a><a href="https://kagifeedback.org/d/14">#14</a></p> <p><img src="https://kagifeedback.org/assets/files/2024-02-06/1707252573-299972-screenshot-2024-02-06-at-124926.png" title="" alt=""></p></li></ul><ul><li><p>We added indication of results coming from Kagi's own index. Look for doggo graphics in results information popup.</p>  <p><img src="https://kagifeedback.org/assets/files/2024-02-06/1707236132-683351-screenshot-2024-02-06-at-081525.png" title="" alt=""></p></li></ul><ul><li>We've introduced the possibility to customise how hours are displayed in your account—choose between the 12 and 24-hour formats. To access this option, simply navigate to "General" under your account settings.<br><img src="https://kagifeedback.org/assets/files/2024-02-06/1707230712-907319-image.png" title="" alt=""></li></ul><h3>Improvements &amp; Bug fixes</h3><ul><li>Issues with how Quick Answer refers to search result items <a href="https://kagifeedback.org/d/3000" data-id="3000"><span></span></a><a href="https://kagifeedback.org/d/3000">#3000</a> <a href="https://kagifeedback.org/u/leftium">@leftium</a> </li><li>We continued tacking accessibility issues reported in <a href="https://kagifeedback.org/d/2923" data-id="2923"><span></span></a><a href="https://kagifeedback.org/d/2923">#2923</a> <a href="https://kagifeedback.org/u/darekkay">@darekkay</a> </li><li>Additional features for news and other articles <a href="https://kagifeedback.org/d/2932" data-id="2932"><span></span></a><a href="https://kagifeedback.org/d/2932">#2932</a> <a href="https://kagifeedback.org/u/Dumb">@Dumb</a></li><li>Calculator broken for basic mathematics <a href="https://kagifeedback.org/d/3087" data-id="3087"><span></span></a><a href="https://kagifeedback.org/d/3087">#3087</a> <a href="https://kagifeedback.org/u/bgeron">@bgeron</a> </li><li>Wrong title for search result <a href="https://kagifeedback.org/d/2984" data-id="2984"><span></span></a><a href="https://kagifeedback.org/d/2984">#2984</a> <a href="https://kagifeedback.org/u/strager">@strager</a></li><li>Translation/Localization on "Phone" button and "Opens soon X PM/AM" <a href="https://kagifeedback.org/d/2976" data-id="2976"><span></span></a><a href="https://kagifeedback.org/d/2976">#2976</a> <a href="https://kagifeedback.org/u/TheLastEnvoy">@TheLastEnvoy</a></li><li>Relaxed password restrictions to meet most <a href="https://pages.nist.gov/800-63-3/sp800-63b.html" rel="ugc nofollow">recent standards</a></li><li>Redirect rules do not trim white space <a href="https://kagifeedback.org/d/3064" data-id="3064"><span></span></a><a href="https://kagifeedback.org/d/3064">#3064</a> <a href="https://kagifeedback.org/u/gunslingerfry">@gunslingerfry</a></li><li>Safari for iOS Results Page Too Wide <a href="https://kagifeedback.org/d/3026" data-id="3026"><span></span></a><a href="https://kagifeedback.org/d/3026">#3026</a> <a href="https://kagifeedback.org/u/TVPaulD">@TVPaulD</a> </li><li>Site details can be dismissed before it finishes appearing <a href="https://kagifeedback.org/d/1798" data-id="1798"><span></span></a><a href="https://kagifeedback.org/d/1798">#1798</a> <a href="https://kagifeedback.org/u/tuesday">@tuesday</a></li><li>Switch between search and assistant mode without clearing the search <a href="https://kagifeedback.org/d/2390" data-id="2390"><span></span></a><a href="https://kagifeedback.org/d/2390">#2390</a> <a href="https://kagifeedback.org/u/mackid1993">@mackid1993</a></li><li>Inline LaTeX response in quick answer not rendering properly <a href="https://kagifeedback.org/d/3008" data-id="3008"><span></span></a><a href="https://kagifeedback.org/d/3008">#3008</a> <a href="https://kagifeedback.org/u/gladiator2339">@gladiator2339</a> <ul><li>$_latex_inline in AI output <a href="https://kagifeedback.org/d/3073" data-id="3073"><span></span></a><a href="https://kagifeedback.org/d/3073">#3073</a> <a href="https://kagifeedback.org/u/MightyPork">@MightyPork</a> </li> <li>Quick Answer renders "$" as "$_latex_inline" <a href="https://kagifeedback.org/d/3032" data-id="3032"><span></span></a><a href="https://kagifeedback.org/d/3032">#3032</a> <a href="https://kagifeedback.org/u/arinazari">@arinazari</a></li></ul></li><li>Maps:   <ul><li>Improve the UI-layout of the Inline-Maps Component on the Main Page</li>  <li>Fix rendering bug in Directions</li>  <li>Improvements to UI layout of POI Infobox</li></ul></li></ul>  <br></div></div><div id="3051"><h2><span>Jan 30, 2024 - Misc improvements and bug fixes</span><a href="https://kagi.com/changelog#3051"> #</a></h2><div><h3>Improvements &amp; Bug fixes</h3><ul><li>The weather widget now features a location button for users to set their precise location</li><li>Region search doesn't work when a lens is active <a href="https://kagifeedback.org/d/2933" data-id="2933"><span></span></a><a href="https://kagifeedback.org/d/2933">#2933</a> <a href="https://kagifeedback.org/u/Vapid">@Vapid</a></li><li>Inconsistent enrichment API results <a href="https://kagifeedback.org/d/2888" data-id="2888"><span></span></a><a href="https://kagifeedback.org/d/2888">#2888</a> <a href="https://kagifeedback.org/u/Value7609">@Value7609</a> </li><li>!m Maps Bang doesn't search <a href="https://kagifeedback.org/d/2945" data-id="2945"><span></span></a><a href="https://kagifeedback.org/d/2945">#2945</a> <a href="https://kagifeedback.org/u/andyrew1">@andyrew1</a></li><li>Search param dropdowns stay open <a href="https://kagifeedback.org/d/2902" data-id="2902"><span></span></a><a href="https://kagifeedback.org/d/2902">#2902</a> <a href="https://kagifeedback.org/u/jrileyh">@jrileyh</a></li><li>Blank page after signup <a href="https://kagifeedback.org/d/2939" data-id="2939"><span></span></a><a href="https://kagifeedback.org/d/2939">#2939</a> <a href="https://kagifeedback.org/u/petiole">@petiole</a> </li><li>Time Ascending/Descending should contextually change to facilitate understanding <a href="https://kagifeedback.org/d/1387" data-id="1387"><span></span></a><a href="https://kagifeedback.org/d/1387">#1387</a> <a href="https://kagifeedback.org/u/kf">@kf</a></li><li>Search input field initially scrolled out of view on mobile <a href="https://kagifeedback.org/d/2958" data-id="2958"><span></span></a><a href="https://kagifeedback.org/d/2958">#2958</a> <a href="https://kagifeedback.org/u/tacocat">@tacocat</a></li><li>Increased number of image search results <a href="https://kagifeedback.org/d/2785" data-id="2785"><span></span></a><a href="https://kagifeedback.org/d/2785">#2785</a> <a href="https://kagifeedback.org/u/KimLaughton">@KimLaughton</a></li><li>Maps search is broken; just returns local area <a href="https://kagifeedback.org/d/3015" data-id="3015"><span></span></a><a href="https://kagifeedback.org/d/3015">#3015</a> <a href="https://kagifeedback.org/u/jamescridland">@jamescridland</a></li></ul><h3>Assistant</h3><p>Research Assistant now displays the uploaded reference photo on the right side during chat conversations for easy reference<br><img src="https://kagifeedback.org/assets/files/2024-01-30/1706616058-706586-image.png" title="" alt=""></p><ul><li>Universal Summarizer now shows the reading time "saved" by summarizing a web page</li><li>Make Kagi Assistant's sources respect regex redirects <a href="https://kagifeedback.org/d/2602" data-id="2602"><span></span></a><a href="https://kagifeedback.org/d/2602">#2602</a> <a href="https://kagifeedback.org/u/Kel">@Kel</a></li><li>Research is not being given full context of the conversation <a href="https://kagifeedback.org/d/2950" data-id="2950"><span></span></a><a href="https://kagifeedback.org/d/2950">#2950</a> <a href="https://kagifeedback.org/u/httpjames">@httpjames</a></li><li>Assistant input form doesn't allow newlines on mobile <a href="https://kagifeedback.org/d/2731" data-id="2731"><span></span></a><a href="https://kagifeedback.org/d/2731">#2731</a> <a href="https://kagifeedback.org/u/EvacuatedTerminal">@EvacuatedTerminal</a></li><li>Assistant switching language during conversation <a href="https://kagifeedback.org/d/2982" data-id="2982"><span></span></a><a href="https://kagifeedback.org/d/2982">#2982</a> <a href="https://kagifeedback.org/u/lou">@lou</a></li></ul><h3>In other news</h3><ul><li><a href="https://teclis.com/" rel="ugc nofollow">Teclis</a> is live again. Teclis surfaces most of Kagi's own index (non-commercial content) in a public way. Teclis is a hobby project by Kagi founder,  maintained on a best effort single person basis, just to set the right expectations.</li></ul></div></div><div id="3005"><h2><span>Jan 24, 2024 - Celebrating 20k members</span><a href="https://kagi.com/changelog#3005"> #</a></h2><div><h3>Announcements</h3><p>Today, we’re happy and proud to have reached <strong>20,000 members</strong>.</p>  <p>We have a special surprise for our community. Read everything about it in our <a href="https://blog.kagi.com/celebrating-20k" rel="ugc nofollow">blog post</a>.</p><p><img src="https://kagifeedback.org/assets/files/2024-01-23/1706048250-795569-kagi-stickers.png" title="" alt=""></p><h3>Features</h3><ul><li>Kagi search extension for <a href="https://chromewebstore.google.com/detail/kagi-search-for-chrome/cdglnehniifkbagbbombnjghhcihifij?hl=en-Us" rel="ugc nofollow">Chrome</a> and <a href="https://addons.mozilla.org/en-US/firefox/addon/kagi-search-for-firefox/" rel="ugc nofollow">Firefox</a> 0.5.0 released  <ul><li>Added support for FastGPT</li>  <li>Fix: Kagi Extension API Key Not Persistent in Firefox ESR on Kali Linux <a href="https://kagifeedback.org/d/2234" data-id="2234"><span></span></a><a href="https://kagifeedback.org/d/2234">#2234</a> @Maxpl01Z</li>  <li>Fix: Kagi keeps saying invalid session token in firefox on linux after setting up successfully and working fine for a while. <a href="https://kagifeedback.org/d/2090" data-id="2090"><span></span></a><a href="https://kagifeedback.org/d/2090">#2090</a> @bkw777a</li>  <li>Fix: Firefox default search engine keeps resetting <a href="https://kagifeedback.org/d/2748" data-id="2748"><span></span></a><a href="https://kagifeedback.org/d/2748">#2748</a> <a href="https://kagifeedback.org/u/Tulip">@Tulip</a></li> </ul></li></ul><p><img src="https://kagifeedback.org/assets/files/2024-01-24/1706110928-788953-screenshot-2024-01-24-at-074142.png" title="" alt=""></p><ul><li>We've introduced an option to disable all personalizations (like blocked or raised domains) for your current search. Just click on "Options" — found at the top of the search results — and deselect "Personalized". Suggested by  <a href="https://kagifeedback.org/d/1943" data-id="1943"><span></span></a><a href="https://kagifeedback.org/d/1943">#1943</a> <a href="https://kagifeedback.org/u/stoyle">@stoyle</a><br><img src="https://kagifeedback.org/assets/files/2024-01-24/1706136800-302539-image.png" title="" alt=""></li></ul><ul><li>New, automated <a href="https://status.kagi.com/" rel="ugc nofollow">status page</a> following the learnings from the <a href="https://status.kagi.com/clrnl9zwl97290beoine8zlvzx" rel="ugc nofollow">post-mortem</a> last week</li></ul><p><img src="https://kagifeedback.org/assets/files/2024-01-24/1706111630-443135-screenshot-2024-01-24-at-075345.png" title="" alt=""></p><h3>Improvements &amp; Bug fixes</h3><ul><li>Accessibility improvements <a href="https://kagifeedback.org/d/2923" data-id="2923"><span></span></a><a href="https://kagifeedback.org/d/2923">#2923</a> <a href="https://kagifeedback.org/u/darekkay">@darekkay</a></li><li>Perform a reverse image search with Kagi by pasting any image directly from your clipboard into the search bar. Suggested by <a href="https://kagifeedback.org/d/1704" data-id="1704"><span></span></a><a href="https://kagifeedback.org/d/1704">#1704</a> <a href="https://kagifeedback.org/u/VIEWVIEWVIEW">@VIEWVIEWVIEW</a></li><li>Search yields no results <a href="https://kagifeedback.org/d/2953" data-id="2953"><span></span></a><a href="https://kagifeedback.org/d/2953">#2953</a> <a href="https://kagifeedback.org/u/flat_reward">@flat_reward</a></li><li>"Time in Japan" shows the Wikipedia page for "suicide in Japan" <a href="https://kagifeedback.org/d/2877" data-id="2877"><span></span></a><a href="https://kagifeedback.org/d/2877">#2877</a> <a href="https://kagifeedback.org/u/fexii">@fexii</a></li><li>Image search not respecting minus / negative operator <a href="https://kagifeedback.org/d/2884" data-id="2884"><span></span></a><a href="https://kagifeedback.org/d/2884">#2884</a> <a href="https://kagifeedback.org/u/Tiny_Beetle">@Tiny_Beetle</a></li><li>Bangs have become case sensitive <a href="https://kagifeedback.org/d/2946" data-id="2946"><span></span></a><a href="https://kagifeedback.org/d/2946">#2946</a> <a href="https://kagifeedback.org/u/httpjames">@httpjames</a></li><li>Lens descriptions in settings are all truncated <a href="https://kagifeedback.org/d/2916" data-id="2916"><span></span></a><a href="https://kagifeedback.org/d/2916">#2916</a> <a href="https://kagifeedback.org/u/ValPolyakh">@ValPolyakh</a></li><li>Issues with iOS keyboard cursor swipe gesture <a href="https://kagifeedback.org/d/1759" data-id="1759"><span></span></a><a href="https://kagifeedback.org/d/1759">#1759</a> <a href="https://kagifeedback.org/u/TyPell91">@TyPell91</a> </li><li>Weather Widget Location Issue. <a href="https://kagifeedback.org/d/2852" data-id="2852"><span></span></a><a href="https://kagifeedback.org/d/2852">#2852</a> <a href="https://kagifeedback.org/u/cempack">@cempack</a></li><li>News and Web Search Returns Out of Date Results vs. Google <a href="https://kagifeedback.org/d/2764" data-id="2764"><span></span></a><a href="https://kagifeedback.org/d/2764">#2764</a> <a href="https://kagifeedback.org/u/CrunchyFritos">@CrunchyFritos</a></li><li>Add a feedback button to the mobile menu <a href="https://kagifeedback.org/d/1616" data-id="1616"><span></span></a><a href="https://kagifeedback.org/d/1616">#1616</a> <a href="https://kagifeedback.org/u/thislooksfun">@thislooksfun</a></li><li>Redirect rule does not seem to be applied to "Interesting Finds" <a href="https://kagifeedback.org/d/2967" data-id="2967"><span></span></a><a href="https://kagifeedback.org/d/2967">#2967</a> <a href="https://kagifeedback.org/u/frereit">@frereit</a></li><li>Some links in the wikipedia article preview do not work <a href="https://kagifeedback.org/d/2977" data-id="2977"><span></span></a><a href="https://kagifeedback.org/d/2977">#2977</a> <a href="https://kagifeedback.org/u/tdf">@tdf</a></li><li>"Show more" button when there's nothing more to show <a href="https://kagifeedback.org/d/2980" data-id="2980"><span></span></a><a href="https://kagifeedback.org/d/2980">#2980</a> <a href="https://kagifeedback.org/u/eikowagenknecht">@eikowagenknecht</a></li></ul><h3>Assistant</h3><ul><li>We've added Mistral Medium to our Assistant, available to Ultimate subscribers<br><img src="https://kagifeedback.org/assets/files/2024-01-24/1706106465-144740-image.png" title="" alt=""></li></ul><ul><li>Research Assistant now respects your preferences for domain rankings when gathering information. It recognizes the websites you've pinned, promoted, demoted, or blocked, ensuring tailored search results. Inspired by <a href="https://kagifeedback.org/d/2533" data-id="2533"><span></span></a><a href="https://kagifeedback.org/d/2533">#2533</a> <a href="https://kagifeedback.org/u/Zambyte">@Zambyte</a></li><li>When invoking chat in assistant wrong model is selected <a href="https://kagifeedback.org/d/2909" data-id="2909"><span></span></a><a href="https://kagifeedback.org/d/2909">#2909</a> <a href="https://kagifeedback.org/u/stoyle">@stoyle</a></li><li>Assistant Chat GPT4 truncates Input on Mobile <a href="https://kagifeedback.org/d/2882" data-id="2882"><span></span></a><a href="https://kagifeedback.org/d/2882">#2882</a> <a href="https://kagifeedback.org/u/jhkmnl">@jhkmnl</a></li><li>FastGPT should autofocus on the prompt field on load <a href="https://kagifeedback.org/d/2676" data-id="2676"><span></span></a><a href="https://kagifeedback.org/d/2676">#2676</a> <a href="https://kagifeedback.org/u/mhitza">@mhitza</a> </li><li>Support for research assistant math results with latex <a href="https://kagifeedback.org/d/2925" data-id="2925"><span></span></a><a href="https://kagifeedback.org/d/2925">#2925</a> <a href="https://kagifeedback.org/u/Mg432">@Mg432</a></li><li>Code examples show "$_latex_inline" in place of any $ character <a href="https://kagifeedback.org/d/2966" data-id="2966"><span></span></a><a href="https://kagifeedback.org/d/2966">#2966</a> <a href="https://kagifeedback.org/u/mhersh">@mhersh</a></li></ul></div></div><div id="2931"><h2><span>Jan 16, 2024 - Quick Peek, Enhanced Local Business search, Usenet lens, GPT4-vision in Assistant, and Outage Post-Mortem</span><a href="https://kagi.com/changelog#2931"> #</a></h2><div><h2>Announcements</h2> <ul><li>We added "<strong>Quick Peek</strong>" widget to our results. With this addition you will find additional relevant results about the query you are searching. This feature can be easily enabled / disabled in the <a href="https://kagi.com/settings?p=search" rel="ugc nofollow">Search Settings</a>.</li></ul><p><img src="https://kagifeedback.org/assets/files/2024-01-16/1705427357-987277-screenshot-2024-01-16-at-094910.png" title="" alt=""></p>  <br> <ul><li>We added <strong>additional sources for local businesses</strong> to our inline maps search results. Inline maps should be more responsive now when searching for specific local businesses. More improvements to come. Related issue: Local business / open hours <a href="https://kagifeedback.org/d/2477" data-id="2477"><span></span></a><a href="https://kagifeedback.org/d/2477">#2477</a> <a href="https://kagifeedback.org/u/partlycloudy">@partlycloudy</a></li></ul><p><img src="https://kagifeedback.org/assets/files/2024-01-16/1705427049-489431-screenshot-2024-01-16-at-094320.png" title="" alt=""></p><ul><li>Find hidden treasures from the early days of the web through the new <strong>Usenet / Archive search lens</strong></li> </ul><p><img src="https://kagifeedback.org/assets/files/2024-01-16/1705428002-248272-screenshot-2024-01-16-at-095955.png" title="" alt=""></p> <ul><li><p>Kagi Assistant (available as open beta for Ultimate members) now leverages <strong>GPT4-vision model</strong> to better understand and describe images. You can test this improved functionality by uploading images or providing image URLs for the Kagi Assistant to analyse.</p>  <p>Edit: A member just emailed saying "the example you have is wrong about 7 of the 10 "Key Points" (only the restaurant name, VAT amount, and amount tendered are correct)." Yes that can be the case with LLMs, we are not trying to present this as grounbreaking, we just integrated a model and the example is as good as the underlying model. This is clearly demonstrating its limitations and it is what it is. We are currently using the best commercially available vision model on the market and it is our desire to emphasize that access to this and other world's cutting edge LLM's are all included in the Assistant with one Kagi subscription. No doubt they will get better in the future.</p></li></ul><p><img src="https://kagifeedback.org/assets/files/2024-01-16/1705427862-716303-screenshot-2024-01-16-at-095718.png" title="" alt=""></p><h3>Outage post-mortem</h3> <ul><li>We've dissected last Thursday's events and the steps we're taking in response in a detailed <a href="https://status.kagi.com/issues/2024-01-12-kagi-down-on-some-regions/" rel="ugc nofollow">post-mortem report</a>. Thank you for bearing with us, and please look forward to a more robust service as we continue to improve.</li></ul><h2>Improvements &amp; Bug fixes</h2><ul><li>Some summarized results display wrong language <a href="https://kagifeedback.org/d/2907" data-id="2907"><span></span></a><a href="https://kagifeedback.org/d/2907">#2907</a> <a href="https://kagifeedback.org/u/Dustin">@Dustin</a> </li><li>Clear search button doesn’t work (Mobile Orion) <a href="https://kagifeedback.org/d/2870" data-id="2870"><span></span></a><a href="https://kagifeedback.org/d/2870">#2870</a> <a href="https://kagifeedback.org/u/jeffdaley">@jeffdaley</a></li><li>Long filename text overflows in Assistant <a href="https://kagifeedback.org/d/2631" data-id="2631"><span></span></a><a href="https://kagifeedback.org/d/2631">#2631</a> <a href="https://kagifeedback.org/u/sw">@sw</a></li><li>Research Assistant incorrectly citing sources as "Item X"  <a href="https://kagifeedback.org/d/2908" data-id="2908"><span></span></a><a href="https://kagifeedback.org/d/2908">#2908</a> <a href="https://kagifeedback.org/u/Buffalo_Tree">@Buffalo_Tree</a></li><li>Assistant responses rendering real HTML elements <a href="https://kagifeedback.org/d/2650" data-id="2650"><span></span></a><a href="https://kagifeedback.org/d/2650">#2650</a> <a href="https://kagifeedback.org/u/httpjames">@httpjames</a></li><li>Fail to apply redirection rule to widget (e.g. wikipedia widget) in search result <a href="https://kagifeedback.org/d/2801" data-id="2801"><span></span></a><a href="https://kagifeedback.org/d/2801">#2801</a> <a href="https://kagifeedback.org/u/Fernandez">@Fernandez</a></li><li>Lens excluded words not working <a href="https://kagifeedback.org/d/2643" data-id="2643"><span></span></a><a href="https://kagifeedback.org/d/2643">#2643</a> <a href="https://kagifeedback.org/u/Recast">@Recast</a> </li><li>Setting theme-color meta attribute doesn't work <a href="https://kagifeedback.org/d/2868" data-id="2868"><span></span></a><a href="https://kagifeedback.org/d/2868">#2868</a> <a href="https://kagifeedback.org/u/Holger">@Holger</a></li><li>Short terms &amp; quick answers add horizontal scrolling on mobile <a href="https://kagifeedback.org/d/2865" data-id="2865"><span></span></a><a href="https://kagifeedback.org/d/2865">#2865</a> <a href="https://kagifeedback.org/u/Vapid">@Vapid</a></li><li>Rendring markdown code snippets etc, is wrong in lists <a href="https://kagifeedback.org/d/2724" data-id="2724"><span></span></a><a href="https://kagifeedback.org/d/2724">#2724</a> <a href="https://kagifeedback.org/u/stoyle">@stoyle</a></li><li>Sending two different questions to FastGPT causes responses to glitch <a href="https://kagifeedback.org/d/2480" data-id="2480"><span></span></a><a href="https://kagifeedback.org/d/2480">#2480</a> <a href="https://kagifeedback.org/u/DeltAndy">@DeltAndy</a></li><li>Transparent image filters not working <a href="https://kagifeedback.org/d/2402" data-id="2402"><span></span></a><a href="https://kagifeedback.org/d/2402">#2402</a> <a href="https://kagifeedback.org/u/jesus">@jesus</a></li><li>Kagi search personalised results bug <a href="https://kagifeedback.org/d/2867" data-id="2867"><span></span></a><a href="https://kagifeedback.org/d/2867">#2867</a> <a href="https://kagifeedback.org/u/Repacking6528">@Repacking6528</a></li><li>Country Codes should work when searching in Country Menu <a href="https://kagifeedback.org/d/998" data-id="998"><span></span></a><a href="https://kagifeedback.org/d/998">#998</a> <a href="https://kagifeedback.org/u/Imperator_of_all">@Imperator_of_all</a></li><li>Shield icon and popup panel metric are unclear how they relate <a href="https://kagifeedback.org/d/2668" data-id="2668"><span></span></a><a href="https://kagifeedback.org/d/2668">#2668</a> <a href="https://kagifeedback.org/u/laserdinosaur">@laserdinosaur</a></li><li>[Discuss Document] SyntaxError: Unexpected token <a href="https://kagifeedback.org/d/2843" data-id="2843"><span></span></a><a href="https://kagifeedback.org/d/2843">#2843</a> <a href="https://kagifeedback.org/u/RMcCurdyDOTcom">@RMcCurdyDOTcom</a></li><li>Universal Summarizer Hallucination <a href="https://kagifeedback.org/d/2652" data-id="2652"><span></span></a><a href="https://kagifeedback.org/d/2652">#2652</a> <a href="https://kagifeedback.org/u/CrunchyFritos">@CrunchyFritos</a></li><li>Universal summarizer doesn't show in Korean <a href="https://kagifeedback.org/d/2891" data-id="2891"><span></span></a><a href="https://kagifeedback.org/d/2891">#2891</a> <a href="https://kagifeedback.org/u/HanbyulKimLuke">@HanbyulKimLuke</a></li><li>Quick answer messes up viewport on mobile <a href="https://kagifeedback.org/d/2924" data-id="2924"><span></span></a><a href="https://kagifeedback.org/d/2924">#2924</a> <a href="https://kagifeedback.org/u/stoyle">@stoyle</a></li><li>Lowering the ranking of gov.cn doesn't work <a href="https://kagifeedback.org/d/2681" data-id="2681"><span></span></a><a href="https://kagifeedback.org/d/2681">#2681</a> <a href="https://kagifeedback.org/u/Peter">@Peter</a></li><li>Images from text results show missing image for a few seconds after clicking <a href="https://kagifeedback.org/d/2844" data-id="2844"><span></span></a><a href="https://kagifeedback.org/d/2844">#2844</a> <a href="https://kagifeedback.org/u/olly_kf">@olly_kf</a></li><li>Metacritic bang command (!mc) gives a 404, new URL needed <a href="https://kagifeedback.org/d/2920" data-id="2920"><span></span></a><a href="https://kagifeedback.org/d/2920">#2920</a> <a href="https://kagifeedback.org/u/pdm">@pdm</a></li></ul></div></div><div id="2856"><h2><span>Jan 5, 2024 - Lemmy search lens and Safari extension update</span><a href="https://kagi.com/changelog#2856"> #</a></h2><div><h3>📢 Announcements</h3><ul><li><p>We have rolled back Kagi Search for Safari extension because of issues reported by users. The URL to download the rolled back version is the same <a href="https://apps.apple.com/us/app/kagi-search-for-safari/id1622835804" rel="ugc nofollow">apps.apple.com/us/app/kagi-search-for-safari/id1622835804</a>. We are continuing the development of the 2.0 branch which is open source and you can follow the discussion <a href="https://github.com/kagisearch/browser_extensions/pull/59" rel="ugc nofollow">here</a>.</p> </li><li><p>Kagi is popular on Lemmy and a lot of Lemmy users are using Kagi. We have released the first version of a Lemmy/Kbin search lens.  <a href="https://kagifeedback.org/d/1659" data-id="1659"><span></span></a><a href="https://kagifeedback.org/d/1659">#1659</a> <a href="https://kagifeedback.org/u/Nankeru">@Nankeru</a></p></li></ul><p><img src="https://kagifeedback.org/assets/files/2024-01-05/1704485218-274688-screenshot-2024-01-05-at-120649.png" title="" alt=""></p><ul><li>Quick answer and Summarize page are quicker and using streaming responses</li></ul><h3>🪲 Bug fixes &amp; Improvements</h3><ul><li>Improvements to quality of results in user lenses</li><li>We are showing less subresults for single domain (it was sometimes overwhelming)</li><li>Inline news widget shows more news stories when available</li><li>Weather widget should be displayed when searching for "temperature", "humidity" etc <a href="https://kagifeedback.org/d/2704" data-id="2704"><span></span></a><a href="https://kagifeedback.org/d/2704">#2704</a> <a href="https://kagifeedback.org/u/montag2k">@montag2k</a> </li><li>Cannot highlight search input without risking clearing the entire thing I typed <a href="https://kagifeedback.org/d/2779" data-id="2779"><span></span></a><a href="https://kagifeedback.org/d/2779">#2779</a> <a href="https://kagifeedback.org/u/guissmo">@guissmo</a> </li><li>Irrelevant adult results for Chinese query <a href="https://kagifeedback.org/d/2633" data-id="2633"><span></span></a><a href="https://kagifeedback.org/d/2633">#2633</a> <a href="https://kagifeedback.org/u/energize_detonator">@energize_detonator</a> </li><li>Autosuggest frequently recommends appending 'fnaf' to searches <a href="https://kagifeedback.org/d/2713" data-id="2713"><span></span></a><a href="https://kagifeedback.org/d/2713">#2713</a> <a href="https://kagifeedback.org/u/Ryologic">@Ryologic</a></li><li>Search suggestion box showing &lt;i&gt;-tags <a href="https://kagifeedback.org/d/2820" data-id="2820"><span></span></a><a href="https://kagifeedback.org/d/2820">#2820</a> <a href="https://kagifeedback.org/u/BeNice">@BeNice</a> </li><li>Spurious NSFW result <a href="https://kagifeedback.org/d/2824" data-id="2824"><span></span></a><a href="https://kagifeedback.org/d/2824">#2824</a> <a href="https://kagifeedback.org/u/grrr">@grrr</a> </li><li>Empty Footnotes without References in Discuss Doc <a href="https://kagifeedback.org/d/2805" data-id="2805"><span></span></a><a href="https://kagifeedback.org/d/2805">#2805</a> <a href="https://kagifeedback.org/u/CrunchyFritos">@CrunchyFritos</a></li><li>Landscape mode on iOS does not render search/assistant widgets correctly <a href="https://kagifeedback.org/d/2778" data-id="2778"><span></span></a><a href="https://kagifeedback.org/d/2778">#2778</a> <a href="https://kagifeedback.org/u/stoyle">@stoyle</a></li><li>Fix URL normalization/validation for summarizer</li><li>Random number in quick answer response <a href="https://kagifeedback.org/d/2800" data-id="2800"><span></span></a><a href="https://kagifeedback.org/d/2800">#2800</a> <a href="https://kagifeedback.org/u/bert">@bert</a></li><li>RegEx matching bug in redirect rules for your search results. <a href="https://kagifeedback.org/d/2840" data-id="2840"><span></span></a><a href="https://kagifeedback.org/d/2840">#2840</a> <a href="https://kagifeedback.org/u/Fernandez">@Fernandez</a> </li><li>Maps Search Doesn't Load Android <a href="https://kagifeedback.org/d/2831" data-id="2831"><span></span></a><a href="https://kagifeedback.org/d/2831">#2831</a> <a href="https://kagifeedback.org/u/purpledingo">@purpledingo</a></li><li>"enterprise movie" gives back result with Cyrillic spelling <a href="https://kagifeedback.org/d/2850" data-id="2850"><span></span></a><a href="https://kagifeedback.org/d/2850">#2850</a> <a href="https://kagifeedback.org/u/inesicio">@inesicio</a> </li><li>Info card top is cut off <a href="https://kagifeedback.org/d/2811" data-id="2811"><span></span></a><a href="https://kagifeedback.org/d/2811">#2811</a> <a href="https://kagifeedback.org/u/Kai">@Kai</a></li><li>Timer and stopwatch are broken <a href="https://kagifeedback.org/d/2771" data-id="2771"><span></span></a><a href="https://kagifeedback.org/d/2771">#2771</a> <a href="https://kagifeedback.org/u/drdaeman">@drdaeman</a></li></ul></div></div><div id="2793"><h2><span>Dec 28, 2023 - Improved search results and new extension for Safari</span><a href="https://kagi.com/changelog#2793"> #</a></h2><div><h3>📢 Announcements</h3><ul><li><p>We have added Brave Search API as an additional source of results. With this, Brave API joins the growing list of <a href="https://help.kagi.com/kagi/search-details/search-sources.html" rel="ugc nofollow">Kagi's search sources</a>, ensuring that if you can not find something on Kagi, it does not exist on the web. This will come at no additional cost to you.</p></li><li><p><a href="https://help.kagi.com/kagi/ai/assistant.html" rel="ugc nofollow">Kagi Assistant</a> usage stats are now on the <a href="https://kagi.com/stats" rel="ugc nofollow">stats page</a>. Assistant is still in beta and currently available to Ultimate plan users. We plan to roll it out to all members in January.  <a href="https://kagifeedback.org/d/2141" data-id="2141"><span></span></a><a href="https://kagifeedback.org/d/2141">#2141</a> <a href="https://kagifeedback.org/u/Grooty">@Grooty</a></p></li><li><p>We vastly improved Image search results. Check them <a href="https://kagi.com/images?q=captain+america" rel="ugc nofollow">here</a> including all the powerful filters.<br><img src="https://kagifeedback.org/assets/files/2023-12-28/1703786798-699687-screenshot-2023-12-28-at-100607.png" title="" alt=""></p></li></ul><ul><li><p><a href="https://apps.apple.com/us/app/kagi-search-for-safari/id1622835804?mt=12" rel="ugc nofollow">Kagi Search for Safari Extension 2.0</a> has just launched! We've updated the extension to be cross-platform and rewrote it from scratch for improved reliability, as well as a simpler way to get your Kagi searches going across your macOS and iOS devices, with Apple’s automatic extension state syncing.</p>  <p>Existing users of the iOS Kagi Search for Safari Extension are encouraged to <a href="https://apps.apple.com/us/app/kagi-search-for-safari/id1622835804?mt=12" rel="ugc nofollow">install the cross-platform version</a> from the App Store to continue receiving updates after the iOS-only extension is delisted (in July 2024). Until that time, the iOS-only extension will continue to receive the same updates and run the same underlying code as the cross-platform extension.</p>  <p>The migration to the Safari Web Extensions framework will require you to grant access to the Extension on the search engine during your first run. See the instructions in the app for details.</p>  <p>Release notes for extension:</p>  <p>[Fixed] Redirects should not experience intermittent failures<br>  [Changed] You can override which search engine redirects to Kagi manually. The first time you install/upgrade to this version, the extension will attempt to detect your current Safari search engine<br>  [Changed] You only need to provide extension access to urls on the search engine you are overriding.</p></li></ul><h3>🪲 Bug fixes &amp; Improvements</h3><ul><li>Clickable anchors in changelog for easy sharing of changelog posts</li><li>Added new regional bangs !be_fr, !ca_fr, !ch_fr, !es_ca</li><li>Query suggestions are too "greedy" <a href="https://kagifeedback.org/d/2750" data-id="2750"><span></span></a><a href="https://kagifeedback.org/d/2750">#2750</a> <a href="https://kagifeedback.org/u/dcoates">@dcoates</a> </li><li>Custom CSS does not apply to the Assistant page. <a href="https://kagifeedback.org/d/2534" data-id="2534"><span></span></a><a href="https://kagifeedback.org/d/2534">#2534</a> <a href="https://kagifeedback.org/u/Zambyte">@Zambyte</a> </li><li>Semicolons aren't properly handled in the search results page <a href="https://kagifeedback.org/d/2365" data-id="2365"><span></span></a><a href="https://kagifeedback.org/d/2365">#2365</a> <a href="https://kagifeedback.org/u/laiz">@laiz</a></li><li>Kagi search interface no longer works on Firefox ESR <a href="https://kagifeedback.org/d/2766" data-id="2766"><span></span></a><a href="https://kagifeedback.org/d/2766">#2766</a> <a href="https://kagifeedback.org/u/kagi-not-working">@kagi-not-working</a></li><li>This screen needs to be available on Localazy to be localized <a href="https://kagifeedback.org/d/2714" data-id="2714"><span></span></a><a href="https://kagifeedback.org/d/2714">#2714</a> <a href="https://kagifeedback.org/u/TheLastEnvoy">@TheLastEnvoy</a></li><li>!staples search is broken <a href="https://kagifeedback.org/d/2772" data-id="2772"><span></span></a><a href="https://kagifeedback.org/d/2772">#2772</a> <a href="https://kagifeedback.org/u/sidwolf6583">@sidwolf6583</a></li><li>"Are you finding this answer useful" overlay hard to close <a href="https://kagifeedback.org/d/2195" data-id="2195"><span></span></a><a href="https://kagifeedback.org/d/2195">#2195</a> <a href="https://kagifeedback.org/u/timo">@timo</a></li><li>Opening Quick Answer links in another tab <a href="https://kagifeedback.org/d/2556" data-id="2556"><span></span></a><a href="https://kagifeedback.org/d/2556">#2556</a> <a href="https://kagifeedback.org/u/X145678908765">@X145678908765</a></li><li>Paywall indicator in the news tab <a href="https://kagifeedback.org/d/2663" data-id="2663"><span></span></a><a href="https://kagifeedback.org/d/2663">#2663</a> <a href="https://kagifeedback.org/u/Dumb">@Dumb</a></li><li>Making prorating clearer on the Pricing page <a href="https://kagifeedback.org/d/2736" data-id="2736"><span></span></a><a href="https://kagifeedback.org/d/2736">#2736</a> <a href="https://kagifeedback.org/u/GrygrFlzr">@GrygrFlzr</a></li><li>Page redirects / regexes don't get applied to quick answer citations <a href="https://kagifeedback.org/d/2389" data-id="2389"><span></span></a><a href="https://kagifeedback.org/d/2389">#2389</a> <a href="https://kagifeedback.org/u/xhat">@xhat</a> </li><li>Allow Quick Bangs at end of query <a href="https://kagifeedback.org/d/1434" data-id="1434"><span></span></a><a href="https://kagifeedback.org/d/1434">#1434</a> <a href="https://kagifeedback.org/u/macro">@macro</a> </li><li>Improved forgot password &amp; reset password errors</li><li>Fixed missing HN and Reddit comments on posts</li></ul><p><img src="https://kagifeedback.org/assets/files/2023-12-28/1703789237-596032-screenshot-2023-12-28-at-104712.png" title="" alt=""></p><h3>Assistant</h3><ul><li><p>Faster assistant responses (<strong>over 100 tok/sec for gpt-3.5-turbo</strong>)<br><video controls="" src="https://kagifeedback.org/assets/files/2023-12-28/1703791944-576645-screen-recording-2023-12-28-at-113035.mov"></video></p></li><li><p>Improvements to Fast Research assistant</p></li><li><p>Assistant on iOS and iPadOS, safari or orion, requires reload after question is posed <a href="https://kagifeedback.org/d/2776" data-id="2776"><span></span></a><a href="https://kagifeedback.org/d/2776">#2776</a> <a href="https://kagifeedback.org/u/stoyle">@stoyle</a></p></li></ul><h3>Happy holidays from the Kagi team!</h3><p>Thank you for supporting us in this amazing year. Consider <a href="https://kagi.com/settings?p=gift" rel="ugc nofollow">gifting Kagi </a> to your friends and family and bring the joy of great web search to their homes. See you all in 2024!</p><p><img src="https://kagifeedback.org/assets/files/2023-12-28/1703788045-128686-image.png" title="" alt=""></p></div></div><div id="2762"><h2><span>Dec 21, 2023 - Kagi Search community event and new language regions</span><a href="https://kagi.com/changelog#2762"> #</a></h2><div><h3>📢 Announcements</h3><p>We held our end-of-the-year Kagi Search community event featuring business update, year in review and questions and answers session. You can watch the recording here:</p><p><span data-s9e-mediaembed="youtube"><span><iframe allowfullscreen="" loading="lazy" scrolling="no" src="https://www.youtube.com/embed/DRVY-74lkBA"></iframe></span></span></p><p>If you want to check out only the slide deck of the  business update, click <a href="https://docs.google.com/presentation/d/10DY-qrg6kQ-SKlbbiF9kaE2M_K8_6xrV9JDs5D_wNFk/edit?usp=sharing" rel="ugc nofollow">here</a>.</p><p><img src="https://kagifeedback.org/assets/files/2023-12-21/1703200863-701810-screenshot-2023-12-21-at-152035.png" title="" alt=""></p><p>One of the most requested features from the community was improved language/region support. In this update, we added support for Belgium (fr), Belgium (nl), Canada (en), Canada (fr), Spain (es), Spain (ca), Switzerland (de), Switzerland (fr) regions/languages <a href="https://kagifeedback.org/d/89" data-id="89"><span></span></a><a href="https://kagifeedback.org/d/89">#89</a> <a href="https://kagifeedback.org/u/tom">@tom</a></p><h3>🪲 Bug fixes &amp; Improvements</h3><ul><li>Podcast results don't link to the episodes <a href="https://kagifeedback.org/d/2268" data-id="2268"><span></span></a><a href="https://kagifeedback.org/d/2268">#2268</a> <a href="https://kagifeedback.org/u/jamescridland">@jamescridland</a></li><li>A quick way to block a result domain <a href="https://kagifeedback.org/d/2711" data-id="2711"><span></span></a><a href="https://kagifeedback.org/d/2711">#2711</a> <a href="https://kagifeedback.org/u/truist">@truist</a></li><li>Layout issue when switching plans on mobile <a href="https://kagifeedback.org/d/2721" data-id="2721"><span></span></a><a href="https://kagifeedback.org/d/2721">#2721</a> <a href="https://kagifeedback.org/u/ForumNinja404">@ForumNinja404</a></li><li>PDF tag cut off for long paths <a href="https://kagifeedback.org/d/2710" data-id="2710"><span></span></a><a href="https://kagifeedback.org/d/2710">#2710</a> <a href="https://kagifeedback.org/u/kevin51jiang">@kevin51jiang</a> </li><li>Signup does not validate password <a href="https://kagifeedback.org/d/2696" data-id="2696"><span></span></a><a href="https://kagifeedback.org/d/2696">#2696</a> <a href="https://kagifeedback.org/u/jimbo">@jimbo</a> </li><li>The Summarizer "Discuss further" doesn't seem to work <a href="https://kagifeedback.org/d/2712" data-id="2712"><span></span></a><a href="https://kagifeedback.org/d/2712">#2712</a> <a href="https://kagifeedback.org/u/JanPieter">@JanPieter</a></li><li>Attempting to mouse over Quick Answer feedback window dismisses feedback window <a href="https://kagifeedback.org/d/2664" data-id="2664"><span></span></a><a href="https://kagifeedback.org/d/2664">#2664</a> <a href="https://kagifeedback.org/u/bert">@bert</a></li><li>Stopwatch resets on hour mark <a href="https://kagifeedback.org/d/2500" data-id="2500"><span></span></a><a href="https://kagifeedback.org/d/2500">#2500</a> <a href="https://kagifeedback.org/u/abb128">@abb128</a> </li><li>!answer bang asks me to login when using a Private Session Link search URL in a new private browsing session <a href="https://kagifeedback.org/d/2401" data-id="2401"><span></span></a><a href="https://kagifeedback.org/d/2401">#2401</a> <a href="https://kagifeedback.org/u/fawkesley">@fawkesley</a></li><li>Visit links within location searches slightly off. <a href="https://kagifeedback.org/d/2716" data-id="2716"><span></span></a><a href="https://kagifeedback.org/d/2716">#2716</a> <a href="https://kagifeedback.org/u/gabeio">@gabeio</a></li><li>Redirect user to sign-in instead of sign-up on invalid OAuth2 login</li><li>Proper www to non-www redirection <a href="https://kagifeedback.org/d/2703" data-id="2703"><span></span></a><a href="https://kagifeedback.org/d/2703">#2703</a> <a href="https://kagifeedback.org/u/maddy">@maddy</a> </li><li>Wrong time <a href="https://kagifeedback.org/d/2730" data-id="2730"><span></span></a><a href="https://kagifeedback.org/d/2730">#2730</a> <a href="https://kagifeedback.org/u/AntonMakiievskyi">@AntonMakiievskyi</a></li><li>Russian Wikipedia !bang is broken <a href="https://kagifeedback.org/d/2734" data-id="2734"><span></span></a><a href="https://kagifeedback.org/d/2734">#2734</a> <a href="https://kagifeedback.org/u/fxgn">@fxgn</a></li><li>Update !mcwiki to minecraft.wiki <a href="https://kagifeedback.org/d/2449" data-id="2449"><span></span></a><a href="https://kagifeedback.org/d/2449">#2449</a> <a href="https://kagifeedback.org/u/sbrl">@sbrl</a></li><li>Give more specific user API error when token is malformed</li><li>Clicking on any gift amount on the 'Gift Kagi subscription' page redirects to the main page <a href="https://kagifeedback.org/d/2756" data-id="2756"><span></span></a><a href="https://kagifeedback.org/d/2756">#2756</a> <a href="https://kagifeedback.org/u/vankusss">@vankusss</a></li><li>No custom CSS in Video and News tabs <a href="https://kagifeedback.org/d/2706" data-id="2706"><span></span></a><a href="https://kagifeedback.org/d/2706">#2706</a> <a href="https://kagifeedback.org/u/sw">@sw</a></li><li>Stackoverflow title copied from query rather than site <a href="https://kagifeedback.org/d/1064" data-id="1064"><span></span></a><a href="https://kagifeedback.org/d/1064">#1064</a> <a href="https://kagifeedback.org/u/nicstella">@nicstella</a></li><li>Search suggestions must not disappear if I just keep typing what is already suggested <a href="https://kagifeedback.org/d/1893" data-id="1893"><span></span></a><a href="https://kagifeedback.org/d/1893">#1893</a> <a href="https://kagifeedback.org/u/rs387">@rs387</a></li></ul><h2>Assistant</h2><p>📢 Announcements</p><ul><li>We have implemented a new system allowing for longer input. All modes currently have a max of 6k characters per user query, this will be adjusted (upward) in the future</li></ul><p>✨ Features</p><ul><li>New citation snippet design</li><li>Improved robustness of attachment extraction</li></ul><p>🪲 Bugfixes</p><ul><li>Long inputs with non-alphabetical characters may sometimes result in a 414 error</li><li>Citation snippet double HTML-escaping</li></ul></div></div><div id="2702"><h2><span>Dec 14th, 2023</span><a href="https://kagi.com/changelog#2702"> #</a></h2><div><h3>🪲 Bug fixes &amp; Improvements</h3><ul><li>Image Search Returns NSFW Results/Porn With Safe Search Enabled <a href="https://kagifeedback.org/d/2490" data-id="2490"><span></span></a><a href="https://kagifeedback.org/d/2490">#2490</a> <a href="https://kagifeedback.org/u/Kurtis02">@Kurtis02</a></li><li>Login button for Universal Summarizer <a href="https://kagifeedback.org/d/2628" data-id="2628"><span></span></a><a href="https://kagifeedback.org/d/2628">#2628</a> <a href="https://kagifeedback.org/u/Wrought5154">@Wrought5154</a></li><li>Support to output Traditional Chinese in Universal Summarizer <a href="https://kagifeedback.org/d/2606" data-id="2606"><span></span></a><a href="https://kagifeedback.org/d/2606">#2606</a> <a href="https://kagifeedback.org/u/PeterDaveHello">@PeterDaveHello</a></li><li>Unformatted bold tags in summarizer output <a href="https://kagifeedback.org/d/2694" data-id="2694"><span></span></a><a href="https://kagifeedback.org/d/2694">#2694</a> @moretnfyhn</li><li>Better error messages when changing email doesn't work</li><li>Translate doesn't translate to specified language <a href="https://kagifeedback.org/d/1842" data-id="1842"><span></span></a><a href="https://kagifeedback.org/d/1842">#1842</a> <a href="https://kagifeedback.org/u/GiorgiShalvashvili">@GiorgiShalvashvili</a></li><li>New domain information popup shows previous favicon briefly <a href="https://kagifeedback.org/d/2655" data-id="2655"><span></span></a><a href="https://kagifeedback.org/d/2655">#2655</a> <a href="https://kagifeedback.org/u/Jake-Moss">@Jake-Moss</a></li><li>Kagi doesn't supply bold Lufga font, requiring the browser to synthesize it <a href="https://kagifeedback.org/d/2656" data-id="2656"><span></span></a><a href="https://kagifeedback.org/d/2656">#2656</a> <a href="https://kagifeedback.org/u/bert">@bert</a></li><li>Signin with Google: Access blocked: kagi.com has not completed the Google verification process <a href="https://kagifeedback.org/d/2666" data-id="2666"><span></span></a><a href="https://kagifeedback.org/d/2666">#2666</a> <a href="https://kagifeedback.org/u/tjpnz">@tjpnz</a></li><li>A search for "esc pos protocol" shows a preview of Wikipedia's page about the "P" letter <a href="https://kagifeedback.org/d/2494" data-id="2494"><span></span></a><a href="https://kagifeedback.org/d/2494">#2494</a> <a href="https://kagifeedback.org/u/neysofu">@neysofu</a></li><li>Hackernews icons don't show up correctly <a href="https://kagifeedback.org/d/2599" data-id="2599"><span></span></a><a href="https://kagifeedback.org/d/2599">#2599</a> <a href="https://kagifeedback.org/u/Value7609">@Value7609</a></li><li>Weather showing incorrect temperature <a href="https://kagifeedback.org/d/2680" data-id="2680"><span></span></a><a href="https://kagifeedback.org/d/2680">#2680</a> <a href="https://kagifeedback.org/u/dmelcer9">@dmelcer9</a></li><li>Search term gets cut after hashtag <a href="https://kagifeedback.org/d/2422" data-id="2422"><span></span></a><a href="https://kagifeedback.org/d/2422">#2422</a> <a href="https://kagifeedback.org/u/Jak">@Jak</a></li><li>Some regional bangs clash with existing ones <a href="https://kagifeedback.org/d/2229" data-id="2229"><span></span></a><a href="https://kagifeedback.org/d/2229">#2229</a> <a href="https://kagifeedback.org/u/matmat">@matmat</a></li><li>Display phone number on search page <a href="https://kagifeedback.org/d/2647" data-id="2647"><span></span></a><a href="https://kagifeedback.org/d/2647">#2647</a> <a href="https://kagifeedback.org/u/champs777">@champs777</a></li><li>Websites in inline maps results now have a button for copying</li><li>Inline maps results now feature reviews</li></ul><p><img src="https://kagifeedback.org/assets/files/2023-12-15/1702600516-924304-2023-12-14-19-20.png" title="" alt=""></p><h3>Assistant</h3><p>✨ Features</p><ul><li>Research modes are less likely to respond "Unfortunately, I do not have enough information…" or similar. Where possible, we will take some extra time to re-search and try again</li><li>Snippets won't be shown from sources (Wolfram Alpha) whose API structures responses in a different manner than the website</li></ul><p>🪲 Bugfixes</p><ul><li>Regression in citations when using Wolfram Alpha as a source</li><li>Allow code to be copied while assistant is still typing <a href="https://kagifeedback.org/d/2219" data-id="2219"><span></span></a><a href="https://kagifeedback.org/d/2219">#2219</a> <a href="https://kagifeedback.org/u/Reroute5183">@Reroute5183</a></li><li>Assistant doesn't render nested bullet points properly <a href="https://kagifeedback.org/d/2673" data-id="2673"><span></span></a><a href="https://kagifeedback.org/d/2673">#2673</a> <a href="https://kagifeedback.org/u/httpjames">@httpjames</a></li><li>Summarizer &amp; Kagi Assistant unable to summarize/process www.3m.com links. <a href="https://kagifeedback.org/d/2619" data-id="2619"><span></span></a><a href="https://kagifeedback.org/d/2619">#2619</a> <a href="https://kagifeedback.org/u/EvacuatedTerminal">@EvacuatedTerminal</a></li><li>Assistant hangs forever instead of timing out on unsuccessful attachment retrieval</li></ul><p>⚠️ Known Issues</p><ul><li>Long inputs may sometimes result in a 414 error. We are working on a new system to allow much larger input sizes that should be rolled out very soon.</li></ul></div></div><div id="2654"><h2><span>Dec 7, 2023 - Paywalled articles indicator and improved weather widget</span><a href="https://kagi.com/changelog#2654"> #</a></h2><div><h3>📢 Announcements</h3><ul><li><p>We are now indicating (potentially) paywalled articles in search results  <a href="https://kagifeedback.org/d/459" data-id="459"><span></span></a><a href="https://kagifeedback.org/d/459">#459</a> <a href="https://kagifeedback.org/u/Kai">@Kai</a><br><img src="https://kagifeedback.org/assets/files/2023-12-08/1701997361-791733-screenshot-2023-12-07-at-170237.png" title="" alt=""></p></li><li><p>New, beautiful domain information popup!<br><img src="https://kagifeedback.org/assets/files/2023-12-08/1702016622-708427-screenshot-2023-12-07-at-222317.png" title="" alt=""></p></li></ul><ul><li><p>Setting that lets set your default preferred units  <a href="https://kagifeedback.org/d/862" data-id="862"><span></span></a><a href="https://kagifeedback.org/d/862">#862</a> <a href="https://kagifeedback.org/u/jared-07">@jared-07</a> <img src="https://kagifeedback.org/assets/files/2023-12-08/1701997763-521160-screenshot-2023-12-07-at-170917.png" title="" alt=""></p></li><li><p>Improved weather widget to go with the previous<br><img src="https://kagifeedback.org/assets/files/2023-12-08/1701997307-745116-screenshot-2023-12-07-at-170144.png" title="" alt=""></p></li></ul><h3>🪲 Bug fixes &amp; Improvements</h3><ul><li>Kagi Search extension for Firefox and Chrome (0.4.3)   <ul><li>Kagi extension for Firefox on Android <a href="https://kagifeedback.org/d/2209" data-id="2209"><span></span></a><a href="https://kagifeedback.org/d/2209">#2209</a> <a href="https://kagifeedback.org/u/UndarkAido">@UndarkAido</a></li>  <li>Text formatting and copy button for summarizer <a href="https://kagifeedback.org/d/2464" data-id="2464"><span></span></a><a href="https://kagifeedback.org/d/2464">#2464</a> <a href="https://kagifeedback.org/u/dds2d">@dds2d</a></li>  <li>Summarizer doesn't work when firefox reader mode is active <a href="https://kagifeedback.org/d/2558" data-id="2558"><span></span></a><a href="https://kagifeedback.org/d/2558">#2558</a> <a href="https://kagifeedback.org/u/okwhatever">@okwhatever</a></li> </ul></li><li>Option to expand Wikipedia preview in right content box by default. <a href="https://kagifeedback.org/d/1904" data-id="1904"><span></span></a><a href="https://kagifeedback.org/d/1904">#1904</a> <a href="https://kagifeedback.org/u/chris_20017">@chris_20017</a></li><li>Add Google Maps and Apple Maps Links to Search Results</li><li>Bang for Universal Summarizer Summary vs. Key Moments <a href="https://kagifeedback.org/d/2386" data-id="2386"><span></span></a><a href="https://kagifeedback.org/d/2386">#2386</a> <a href="https://kagifeedback.org/u/CrunchyFritos">@CrunchyFritos</a></li><li>Published Date incorrect <a href="https://kagifeedback.org/d/2033" data-id="2033"><span></span></a><a href="https://kagifeedback.org/d/2033">#2033</a> <a href="https://kagifeedback.org/u/hmnd">@hmnd</a></li><li>Favicon not showing on safari tabs <a href="https://kagifeedback.org/d/2532" data-id="2532"><span></span></a><a href="https://kagifeedback.org/d/2532">#2532</a> <a href="https://kagifeedback.org/u/gwynforthewyn">@gwynforthewyn</a></li><li>Unexpected translate widget “switch sides” behavior when detecting language <a href="https://kagifeedback.org/d/2415" data-id="2415"><span></span></a><a href="https://kagifeedback.org/d/2415">#2415</a> <a href="https://kagifeedback.org/u/bert">@bert</a></li><li>!fast inoperable on Team Plan <a href="https://kagifeedback.org/d/2607" data-id="2607"><span></span></a><a href="https://kagifeedback.org/d/2607">#2607</a> <a href="https://kagifeedback.org/u/pbronez">@pbronez</a></li><li>Unable to restore theme color to default <a href="https://kagifeedback.org/d/1614" data-id="1614"><span></span></a><a href="https://kagifeedback.org/d/1614">#1614</a> <a href="https://kagifeedback.org/u/umar">@umar</a></li></ul></div></div><div id="2629"><h2><span>Nov 30, 2023 - Quality of life improvements</span><a href="https://kagi.com/changelog#2629"> #</a></h2><div><h3>Kagi Search</h3><h3>🪲 Bug fixes &amp; Improvements</h3><ul><li>Cursor will not scroll to end of search for long queries on Android  <a href="https://kagifeedback.org/d/2302" data-id="2302"><span></span></a><a href="https://kagifeedback.org/d/2302">#2302</a> <a href="https://kagifeedback.org/u/zam">@zam</a></li><li>Japanese input appears twice when using Hiragana/Katakana/Kanji input <a href="https://kagifeedback.org/d/2029" data-id="2029"><span></span></a><a href="https://kagifeedback.org/d/2029">#2029</a> <a href="https://kagifeedback.org/u/nikke1234">@nikke1234</a> </li><li>Keyboard navigation doesn't highlight instant answer <a href="https://kagifeedback.org/d/2396" data-id="2396"><span></span></a><a href="https://kagifeedback.org/d/2396">#2396</a> <a href="https://kagifeedback.org/u/danbulant">@danbulant</a> </li><li>Lens not scoping correcty <a href="https://kagifeedback.org/d/2250" data-id="2250"><span></span></a><a href="https://kagifeedback.org/d/2250">#2250</a> <a href="https://kagifeedback.org/u/Rediwed">@Rediwed</a></li><li>Mobile - Responsive issues. <a href="https://kagifeedback.org/d/2509" data-id="2509"><span></span></a><a href="https://kagifeedback.org/d/2509">#2509</a> <a href="https://kagifeedback.org/u/cempack">@cempack</a></li><li>Wikipedia widget empty pane <a href="https://kagifeedback.org/d/2423" data-id="2423"><span></span></a><a href="https://kagifeedback.org/d/2423">#2423</a> <a href="https://kagifeedback.org/u/Value7609">@Value7609</a></li><li>Kagi bangs without query should take you to the corresponding Kagi search page <a href="https://kagifeedback.org/d/2316" data-id="2316"><span></span></a><a href="https://kagifeedback.org/d/2316">#2316</a> <a href="https://kagifeedback.org/u/bert">@bert</a></li><li>Reverse image search: search bar text overlap with thumbnail <a href="https://kagifeedback.org/d/2278" data-id="2278"><span></span></a><a href="https://kagifeedback.org/d/2278">#2278</a> <a href="https://kagifeedback.org/u/FrederickZh">@FrederickZh</a></li><li>Ability to navigate to Kagi Assistant when advanced search is enabled <a href="https://kagifeedback.org/d/2298" data-id="2298"><span></span></a><a href="https://kagifeedback.org/d/2298">#2298</a> <a href="https://kagifeedback.org/u/Nezteb">@Nezteb</a></li><li>Laptop screen - responsive issues. <a href="https://kagifeedback.org/d/2508" data-id="2508"><span></span></a><a href="https://kagifeedback.org/d/2508">#2508</a> <a href="https://kagifeedback.org/u/cempack">@cempack</a> </li><li>Add upload date for YouTube video results <a href="https://kagifeedback.org/d/2526" data-id="2526"><span></span></a><a href="https://kagifeedback.org/d/2526">#2526</a> <a href="https://kagifeedback.org/u/Yiin">@Yiin</a> </li><li>Show a message when trying to search in an incognito window while not logged in <a href="https://kagifeedback.org/d/1830" data-id="1830"><span></span></a><a href="https://kagifeedback.org/d/1830">#1830</a> <a href="https://kagifeedback.org/u/ThomasS">@ThomasS</a></li><li>StackOverflow widget formatting is broken <a href="https://kagifeedback.org/d/2452" data-id="2452"><span></span></a><a href="https://kagifeedback.org/d/2452">#2452</a> <a href="https://kagifeedback.org/u/fxgn">@fxgn</a></li><li>Higher quality results for "News" </li><li>Further improved latency for Australia region (after launching the new DC Sydney two weeks ago)</li><li>Missing attribution in map <a href="https://kagifeedback.org/d/2041" data-id="2041"><span></span></a><a href="https://kagifeedback.org/d/2041">#2041</a> <a href="https://kagifeedback.org/u/02JanDal">@02JanDal</a> </li><li>Content-Security-Policy missing on Summarizer <a href="https://kagifeedback.org/d/2527" data-id="2527"><span></span></a><a href="https://kagifeedback.org/d/2527">#2527</a> <a href="https://kagifeedback.org/u/promenaden">@promenaden</a></li><li>YouTube link not encoded properly on clicking the “discuss further” button on the summarization page <a href="https://kagifeedback.org/d/2564" data-id="2564"><span></span></a><a href="https://kagifeedback.org/d/2564">#2564</a> <a href="https://kagifeedback.org/u/platyhsu">@platyhsu</a></li><li>Fixed reported XSS in Universal Summarizer and FastGPT</li><li>Searching for "the boys" triggers shopping widget <a href="https://kagifeedback.org/d/2595" data-id="2595"><span></span></a><a href="https://kagifeedback.org/d/2595">#2595</a> <a href="https://kagifeedback.org/u/terminalnode">@terminalnode</a></li><li>Summerizer no longer works with direct link <a href="https://kagifeedback.org/d/2570" data-id="2570"><span></span></a><a href="https://kagifeedback.org/d/2570">#2570</a> <a href="https://kagifeedback.org/u/inesicio">@inesicio</a></li><li>Summarizer unable to summarize bugs.chromium.org <a href="https://kagifeedback.org/d/2562" data-id="2562"><span></span></a><a href="https://kagifeedback.org/d/2562">#2562</a> <a href="https://kagifeedback.org/u/EvacuatedTerminal">@EvacuatedTerminal</a></li> </ul><h3>Kagi Assistant</h3><p>✨ Features</p><ul><li>Citation snippets:</li><li>- Hover or click an inline citation and review the source text</li><li>- Where possible, clicking the inline citation link directly to the relevant part of the webpage</li><li>Show Assistant on landing page with Advanced Search open</li><li>Improved LLM speed and reliability</li></ul><p>🪲 Bugfixes</p><ul><li>Incorrect formatting in Fast mode <a href="https://kagifeedback.org/d/2567" data-id="2567"><span></span></a><a href="https://kagifeedback.org/d/2567">#2567</a> <a href="https://kagifeedback.org/u/NevevrAlak">@NevevrAlak</a></li><li>Research assistant upload file modal squished on mobile <a href="https://kagifeedback.org/d/2552" data-id="2552"><span></span></a><a href="https://kagifeedback.org/d/2552">#2552</a> <a href="https://kagifeedback.org/u/EvacuatedTerminal">@EvacuatedTerminal</a></li><li>Custom assistant settings use the wrong model <a href="https://kagifeedback.org/d/2510" data-id="2510"><span></span></a><a href="https://kagifeedback.org/d/2510">#2510</a> <a href="https://kagifeedback.org/u/houston">@houston</a></li><li>Chat glitches when scrolling up <a href="https://kagifeedback.org/d/2435" data-id="2435"><span></span></a><a href="https://kagifeedback.org/d/2435">#2435</a> <a href="https://kagifeedback.org/u/feedbackhax">@feedbackhax</a></li><li>Various small UX fixes</li></ul><p>⚠️ Known Issues</p><ul><li>Low contrast citation snippets in dark mode. Bugfix should be out within a couple days</li><li>Long inputs with non-alphabetical characters may sometimes result in a 414 error. We are working on a new system to allow much larger input sizes</li></ul></div></div><div id="2540"><h2><span>Nov 16, 2023 - GPT 4 Turbo, Australia region, Sales Tax</span><a href="https://kagi.com/changelog#2540"> #</a></h2><div><h3>📢 Announcements</h3><ul><li><p>We are making <strong>GPT 4 Turbo</strong> available in Kagi Assistant (<em>Kagi Assistant is currently in closed beta and available to Ultimate members</em>)</p></li><li><p><strong>Summarize any page on the web</strong> with Kagi Search extensions for <a href="https://chromewebstore.google.com/detail/kagi-search-for-chrome/cdglnehniifkbagbbombnjghhcihifij" rel="ugc nofollow">Chrome</a> and <a href="https://addons.mozilla.org/en-US/firefox/addon/kagi-search-for-firefox/" rel="ugc nofollow">Firefox</a> (0.4.2). We added support for Summarizer language setting and summary type. This feature is free for all Kagi members, try it out!</p></li><li><p>We are <strong>now deployed in Australia</strong> (Sydney), yay! This will reduce latency for our members in this part of the world. We <a href="https://help.kagi.com/kagi/search-details/search-speed.html" rel="ugc nofollow">care about speed a lot</a>!</p></li></ul><p>Here is a map of all <strong>Kagi data center locations</strong> currently.<br><img src="https://kagifeedback.org/assets/files/2023-11-16/1700178524-889329-image.png" title="" alt=""></p><ul><li><p>Kagi is <a href="https://kagi.com/stats" rel="ugc nofollow">growing up</a>! You've all seen and participated in the incredible growth of the past few months, thank you. It also means we'll need to start looking at where <strong>we need to start charging sales tax/VAT</strong> on behalf of your state/government. We're in the process of looking at the details, and we will do our best to make this as seamless as possible. Expect more information soon.</p></li><li><p>Our tech lead <strong>Zac Nowicki recently gave a talk</strong> at Crystal Conf. Zac shares a summary of lessons, technology, ideas, and challenges after building a search engine product from the ground up in Crystal for the past three years. <a href="https://www.youtube.com/watch?v=r7t9xPajjTM&amp;list=PLt-CsM4G1WoadONHl3zPN_Ts5PqH8TgMZ&amp;index=8" rel="ugc nofollow">Watch the presentation</a>.</p></li><li><p>We have a great <a href="https://discord.com/channels/849884108750061568/1171909248507191326/1172609911021121600" rel="ugc nofollow">discussion</a> about <strong>Kagi Email</strong> in ⁠our Discord. <a href="https://kagi.com/discord" rel="ugc nofollow">Join us</a>!</p></li> </ul><h3>🪲 Bug fixes &amp; Improvements</h3><ul><li>Fixed Inline discussions not showing actual discussions</li><li>No search bang for no_region, only for regions <a href="https://kagifeedback.org/d/2475" data-id="2475"><span></span></a><a href="https://kagifeedback.org/d/2475">#2475</a> <a href="https://kagifeedback.org/u/bgeron">@bgeron</a></li><li>Keyboard shortcuts are difficult to find <a href="https://kagifeedback.org/d/2252" data-id="2252"><span></span></a><a href="https://kagifeedback.org/d/2252">#2252</a> <a href="https://kagifeedback.org/u/janfoeh">@janfoeh</a></li><li>Unsanitized square brackets in FastGPT <a href="https://kagifeedback.org/d/2470" data-id="2470"><span></span></a><a href="https://kagifeedback.org/d/2470">#2470</a> <a href="https://kagifeedback.org/u/felkr">@felkr</a></li><li>Information icon next to Total searches this period on billing page does not provide information <a href="https://kagifeedback.org/d/2495" data-id="2495"><span></span></a><a href="https://kagifeedback.org/d/2495">#2495</a> <a href="https://kagifeedback.org/u/bebowilson">@bebowilson</a> </li><li>GTA 6 returns “reviews” for game that doesn’t exist <a href="https://kagifeedback.org/d/2488" data-id="2488"><span></span></a><a href="https://kagifeedback.org/d/2488">#2488</a> <a href="https://kagifeedback.org/u/lolrepeatlol">@lolrepeatlol</a></li><li>FastGPT API results are different (and much worse) than kagi.com/fastgpt <a href="https://kagifeedback.org/d/2504" data-id="2504"><span></span></a><a href="https://kagifeedback.org/d/2504">#2504</a> <a href="https://kagifeedback.org/u/estheruary">@estheruary</a></li><li>FastGPT web version and API doesn't provide the same result <a href="https://kagifeedback.org/d/1690" data-id="1690"><span></span></a><a href="https://kagifeedback.org/d/1690">#1690</a> <a href="https://kagifeedback.org/u/doom">@doom</a></li><li>Universal Summarizer reports that multi-page PDF files are too short to summarize <a href="https://kagifeedback.org/d/1962" data-id="1962"><span></span></a><a href="https://kagifeedback.org/d/1962">#1962</a> <a href="https://kagifeedback.org/u/scottharris">@scottharris</a></li><li>Album of The Year bang !aoty with a search redirects to the wrong URL <a href="https://kagifeedback.org/d/2485" data-id="2485"><span></span></a><a href="https://kagifeedback.org/d/2485">#2485</a> <a href="https://kagifeedback.org/u/haakon">@haakon</a> </li><li>Bang !cron is broken <a href="https://kagifeedback.org/d/2459" data-id="2459"><span></span></a><a href="https://kagifeedback.org/d/2459">#2459</a> <a href="https://kagifeedback.org/u/loloriz">@loloriz</a></li><li>!gog bang not working correctly <a href="https://kagifeedback.org/d/2287" data-id="2287"><span></span></a><a href="https://kagifeedback.org/d/2287">#2287</a> <a href="https://kagifeedback.org/u/Xamrica">@Xamrica</a> </li><li>Fun fact on stats page has wrong text <a href="https://kagifeedback.org/d/2442" data-id="2442"><span></span></a><a href="https://kagifeedback.org/d/2442">#2442</a> <a href="https://kagifeedback.org/u/Jake-Moss">@Jake-Moss</a> </li><li>Gift activation links overflow <a href="https://kagifeedback.org/d/2420" data-id="2420"><span></span></a><a href="https://kagifeedback.org/d/2420">#2420</a> <a href="https://kagifeedback.org/u/httpjames">@httpjames</a></li><li>Lens name truncated in settings <a href="https://kagifeedback.org/d/2397" data-id="2397"><span></span></a><a href="https://kagifeedback.org/d/2397">#2397</a> <a href="https://kagifeedback.org/u/timmm">@timmm</a></li><li>The Summarizer extension language option <a href="https://kagifeedback.org/d/2507" data-id="2507"><span></span></a><a href="https://kagifeedback.org/d/2507">#2507</a> <a href="https://kagifeedback.org/u/cempack">@cempack</a></li><li>[Chrome Extension] [Summarizer] Extension always uses Summary, instead of Key Moments <a href="https://kagifeedback.org/d/2321" data-id="2321"><span></span></a><a href="https://kagifeedback.org/d/2321">#2321</a> <a href="https://kagifeedback.org/u/rswerve">@rswerve</a></li></ul><h2>Kagi Assistant</h2><h3>📢 Announcements</h3><ul><li>GPT-4 Turbo now available to Ultimate members</li><li>Increased custom Assistant prompt length (1500 chars) <a href="https://kagifeedback.org/d/2150" data-id="2150"><span></span></a><a href="https://kagifeedback.org/d/2150">#2150</a> <a href="https://kagifeedback.org/u/AndroidKitKat">@AndroidKitKat</a></li></ul><h3>🪲 Bugfixes</h3><ul><li>Show custom mode name in settings <a href="https://kagifeedback.org/d/2294" data-id="2294"><span></span></a><a href="https://kagifeedback.org/d/2294">#2294</a> <a href="https://kagifeedback.org/u/TheLastEnvoy">@TheLastEnvoy</a></li></ul><h3>⚠️ Known Issues</h3><ul><li>Long inputs with non-alphabetical characters may sometimes result in a 414 error. We are working on a new system to allow much larger input sizes</li></ul></div></div><div id="2445"><h2><span>Nov 3, 2023 - New region and mysterious Kagi surprise</span><a href="https://kagi.com/changelog#2445"> #</a></h2><div><h3>📢 Announcements</h3><ul><li>We launched a new deployment in South America (São Paulo) datacenter region to reduce latency for our members there. Next week we plan to also expand datacenter operations to Australia (Sydney) region.</li><li>Starter plan Annual plan changed to 3600 searches/year (vs 300 month) to make it more flexible</li><li>New live <a href="https://kagi.com/stats" rel="ugc nofollow">Kagi Stats</a> page. Have a go at guessing the mysterious surprise <a href="https://kagifeedback.org/d/2444-what-is-kagi-surprise-20k" rel="ugc nofollow">here</a></li></ul><h3>✨ Features</h3><ul><li>General settings (including language preference) now available for Kids accounts in the Family Plan  <a href="https://kagifeedback.org/d/2306" data-id="2306"><span></span></a><a href="https://kagifeedback.org/d/2306">#2306</a> <a href="https://kagifeedback.org/u/ploum">@ploum</a></li></ul><h3>🪲 Bug fixes &amp; Improvements</h3><ul><li>Blocked domain still appears in "confident answer" <a href="https://kagifeedback.org/d/2405" data-id="2405"><span></span></a><a href="https://kagifeedback.org/d/2405">#2405</a> <a href="https://kagifeedback.org/u/erandebl">@erandebl</a> </li><li>Icons in the search bar overlap with text <a href="https://kagifeedback.org/d/2074" data-id="2074"><span></span></a><a href="https://kagifeedback.org/d/2074">#2074</a> <a href="https://kagifeedback.org/u/Michele144">@Michele144</a></li><li>"Search with" query URL encoding <a href="https://kagifeedback.org/d/2222" data-id="2222"><span></span></a><a href="https://kagifeedback.org/d/2222">#2222</a> <a href="https://kagifeedback.org/u/feedbackhax">@feedbackhax</a> </li><li>Adding a search engine shortcut broken: TypeError <a href="https://kagifeedback.org/d/2218" data-id="2218"><span></span></a><a href="https://kagifeedback.org/d/2218">#2218</a> <a href="https://kagifeedback.org/u/ni_something">@ni_something</a></li><li>Nixopt bang does not work <a href="https://kagifeedback.org/d/2352" data-id="2352"><span></span></a><a href="https://kagifeedback.org/d/2352">#2352</a> <a href="https://kagifeedback.org/u/niclasoverby">@niclasoverby</a> </li><li>According to docs bang !si should be regional, but it is used elsewhere <a href="https://kagifeedback.org/d/2216" data-id="2216"><span></span></a><a href="https://kagifeedback.org/d/2216">#2216</a> <a href="https://kagifeedback.org/u/hook">@hook</a> </li><li>FastGPT should not automatically open the keyboard on mobile after it is finished writing the response. <a href="https://kagifeedback.org/d/2085" data-id="2085"><span></span></a><a href="https://kagifeedback.org/d/2085">#2085</a> <a href="https://kagifeedback.org/u/Protech">@Protech</a> </li><li>Adding a search engine shortcut broken: TypeError <a href="https://kagifeedback.org/d/2218" data-id="2218"><span></span></a><a href="https://kagifeedback.org/d/2218">#2218</a> <a href="https://kagifeedback.org/u/ni_something">@ni_something</a></li><li>More results resets country <a href="https://kagifeedback.org/d/1277" data-id="1277"><span></span></a><a href="https://kagifeedback.org/d/1277">#1277</a> <a href="https://kagifeedback.org/u/benelgar">@benelgar</a> </li><li>Incorrect "what is my IP" response <a href="https://kagifeedback.org/d/2412" data-id="2412"><span></span></a><a href="https://kagifeedback.org/d/2412">#2412</a> <a href="https://kagifeedback.org/u/Vex">@Vex</a></li><li>Alternatives to pay per use search for Standard/Starter plan <a href="https://kagifeedback.org/d/2018" data-id="2018"><span></span></a><a href="https://kagifeedback.org/d/2018">#2018</a> <a href="https://kagifeedback.org/u/KagiForMe">@KagiForMe</a> </li><li>Images widget always shows images in portrait boxes on mobile <a href="https://kagifeedback.org/d/2178" data-id="2178"><span></span></a><a href="https://kagifeedback.org/d/2178">#2178</a> <a href="https://kagifeedback.org/u/Michele144">@Michele144</a></li><li>When accessing Kagi News from a smartphone, display 2 rows of text for each item inside the Interesting News section <a href="https://kagifeedback.org/d/1625" data-id="1625"><span></span></a><a href="https://kagifeedback.org/d/1625">#1625</a> <a href="https://kagifeedback.org/u/David">@David</a></li><li>Safari-pinned-tab.svg redirects to 404 <a href="https://kagifeedback.org/d/2009" data-id="2009"><span></span></a><a href="https://kagifeedback.org/d/2009">#2009</a> <a href="https://kagifeedback.org/u/cyann">@cyann</a> </li><li>Universal Summarizer does not summarize podcasts <a href="https://kagifeedback.org/d/2109" data-id="2109"><span></span></a><a href="https://kagifeedback.org/d/2109">#2109</a> <a href="https://kagifeedback.org/u/nbanks">@nbanks</a></li><li>Cloud animations on Kagi start page use excessive CPU resources <a href="https://kagifeedback.org/d/300" data-id="300"><span></span></a><a href="https://kagifeedback.org/d/300">#300</a> <a href="https://kagifeedback.org/u/slartoff">@slartoff</a> </li><li>Tapping on the empty suggestion region should close it <a href="https://kagifeedback.org/d/2233" data-id="2233"><span></span></a><a href="https://kagifeedback.org/d/2233">#2233</a> <a href="https://kagifeedback.org/u/Browsing6853">@Browsing6853</a> </li><li>Show the number of ranked domains  <a href="https://kagifeedback.org/d/2246" data-id="2246"><span></span></a><a href="https://kagifeedback.org/d/2246">#2246</a> <a href="https://kagifeedback.org/u/chris_20017">@chris_20017</a></li><li>Summmarizer does not work for some websites <a href="https://kagifeedback.org/d/2334" data-id="2334"><span></span></a><a href="https://kagifeedback.org/d/2334">#2334</a> <a href="https://kagifeedback.org/u/Roovesta">@Roovesta</a> </li><li>Search button under the reverse image search is not aligned in the centre <a href="https://kagifeedback.org/d/2179" data-id="2179"><span></span></a><a href="https://kagifeedback.org/d/2179">#2179</a> <a href="https://kagifeedback.org/u/Repacking6528">@Repacking6528</a> </li><li>"Open in Web Archive" doesn't honor "Open Links in a New Tab" setting <a href="https://kagifeedback.org/d/2123" data-id="2123"><span></span></a><a href="https://kagifeedback.org/d/2123">#2123</a> <a href="https://kagifeedback.org/u/securemepls">@securemepls</a></li><li>Flash caused by meta theme color <a href="https://kagifeedback.org/d/2165" data-id="2165"><span></span></a><a href="https://kagifeedback.org/d/2165">#2165</a> <a href="https://kagifeedback.org/u/ysun">@ysun</a></li><li>Fun fact on stats page has wrong text <a href="https://kagifeedback.org/d/2442" data-id="2442"><span></span></a><a href="https://kagifeedback.org/d/2442">#2442</a> <a href="https://kagifeedback.org/u/Jake-Moss">@Jake-Moss</a> </li><li>Gift activation links overflow <a href="https://kagifeedback.org/d/2420" data-id="2420"><span></span></a><a href="https://kagifeedback.org/d/2420">#2420</a> <a href="https://kagifeedback.org/u/httpjames">@httpjames</a></li><li>Lens name truncated in settings <a href="https://kagifeedback.org/d/2397" data-id="2397"><span></span></a><a href="https://kagifeedback.org/d/2397">#2397</a> <a href="https://kagifeedback.org/u/timmm">@timmm</a></li><li>Unable to summarize Paul Graham essay <a href="https://kagifeedback.org/d/2413" data-id="2413"><span></span></a><a href="https://kagifeedback.org/d/2413">#2413</a> <a href="https://kagifeedback.org/u/CrunchyFritos">@CrunchyFritos</a></li><li>Custom bangs URL should not get URL encoded - i.e. &amp;amp; <a href="https://kagifeedback.org/d/2259" data-id="2259"><span></span></a><a href="https://kagifeedback.org/d/2259">#2259</a> <a href="https://kagifeedback.org/u/Value7609">@Value7609</a></li><li>Currency conversion, i.e., "100 usd to sek", should display widget <a href="https://kagifeedback.org/d/2031" data-id="2031"><span></span></a><a href="https://kagifeedback.org/d/2031">#2031</a> <a href="https://kagifeedback.org/u/Vapid">@Vapid</a></li><li>Lens "Kagi Help and Feedback" includes other domains <a href="https://kagifeedback.org/d/2301" data-id="2301"><span></span></a><a href="https://kagifeedback.org/d/2301">#2301</a> <a href="https://kagifeedback.org/u/oogl6fhk6">@oogl6fhk6</a></li><li>"ask questions about document" uses default mode instead of the modes which are capable of accessing the internet <a href="https://kagifeedback.org/d/2153" data-id="2153"><span></span></a><a href="https://kagifeedback.org/d/2153">#2153</a> <a href="https://kagifeedback.org/u/Value7609">@Value7609</a> </li><li>Info icon for summarize overlaps with the "more" menu <a href="https://kagifeedback.org/d/2340" data-id="2340"><span></span></a><a href="https://kagifeedback.org/d/2340">#2340</a> <a href="https://kagifeedback.org/u/ocharles">@ocharles</a></li></ul><h2>Kagi Assistant</h2><h3>📢 Announcements</h3><ul><li>Starting next Thursday (1 week from today) non-ultimate users will no longer have access to ultimate features. We appreciate your help testing Assistant, and you will continue to have beta access prior to public launch.</li><li>Known issue: Long inputs with non-alphabetical characters may sometimes result in a 414 error. We are working on a new system to allow much larger input sizes.</li></ul><h3>✨ Features</h3><ul><li>Significantly improved streaming speed for OpenAI models</li><li>Switching back and forth between Assistant and Web Search clears the query</li><li>Navigating to the landing page from Assistant opens Assistant mode</li><li>Assistant bangs without input redirect to the expected location</li></ul><h3>🪲 Bug fixes</h3><ul><li>Accidentally triggering bangs within Assistant  <a href="https://kagifeedback.org/d/2320" data-id="2320"><span></span></a><a href="https://kagifeedback.org/d/2320">#2320</a> <a href="https://kagifeedback.org/u/Whoops">@Whoops</a>]</li><li>Regenerate response errors  <a href="https://kagifeedback.org/d/2374" data-id="2374"><span></span></a><a href="https://kagifeedback.org/d/2374">#2374</a> <a href="https://kagifeedback.org/u/Value7609">@Value7609</a>]</li><li>XSS vulnerabilities</li><li>Hallucination of links in Research mode  <a href="https://kagifeedback.org/d/2358" data-id="2358"><span></span></a><a href="https://kagifeedback.org/d/2358">#2358</a> <a href="https://kagifeedback.org/u/nissa">@nissa</a>]</li><li>Loss of context</li><li>Research mode follow-up edge cases</li><li>No search edge cases</li><li>Text wrapping of messages  <a href="https://kagifeedback.org/d/2154" data-id="2154"><span></span></a><a href="https://kagifeedback.org/d/2154">#2154</a> <a href="https://kagifeedback.org/u/Value7609">@Value7609</a>]</li><li>Unexpected scrolling  <a href="https://kagifeedback.org/d/2155" data-id="2155"><span></span></a><a href="https://kagifeedback.org/d/2155">#2155</a> <a href="https://kagifeedback.org/u/Reroute5183">@Reroute5183</a>]</li><li>No summary of document</li><li>Answer stops streaming midway</li><li>Error on long conversations in Code mode  <a href="https://kagifeedback.org/d/2225" data-id="2225"><span></span></a><a href="https://kagifeedback.org/d/2225">#2225</a> <a href="https://kagifeedback.org/u/whee">@whee</a>]</li></ul></div></div><div id="2284"><h2><span>Oct 10, 2023 - Misc fixes</span><a href="https://kagi.com/changelog#2284"> #</a></h2><div><p><strong>New</strong><br>Kagi Search extension for <a href="https://chrome.google.com/webstore/detail/kagi-search-for-chrome/cdglnehniifkbagbbombnjghhcihifij" rel="ugc nofollow">Chrome</a> and <a href="https://addons.mozilla.org/en-US/firefox/addon/kagi-search-for-firefox/" rel="ugc nofollow">Firefox</a> 0.4.0:</p><ul><li>Right click on the page to summarize the page</li><li>Right-clicking an image to search Kagi by image <a href="https://kagifeedback.org/d/2105" data-id="2105"><span></span></a><a href="https://kagifeedback.org/d/2105">#2105</a> <a href="https://kagifeedback.org/u/Nankeru">@Nankeru</a></li></ul><p><strong>Improved</strong></p><ul><li>Site footer enhanced with useful navigation links</li></ul><p><strong>Fixed</strong></p><ul><li>Icons in the search bar overlap with text <a href="https://kagifeedback.org/d/2074" data-id="2074"><span></span></a><a href="https://kagifeedback.org/d/2074">#2074</a> <a href="https://kagifeedback.org/u/Michele144">@Michele144</a> </li><li>Login does not work without JS <a href="https://kagifeedback.org/d/2045" data-id="2045"><span></span></a><a href="https://kagifeedback.org/d/2045">#2045</a> <a href="https://kagifeedback.org/u/eiangarsaowrfutarfgfarg">@eiangarsaowrfutarfgfarg</a></li><li>Search cannot be triggered by return key without the JS <a href="https://kagifeedback.org/d/2065" data-id="2065"><span></span></a><a href="https://kagifeedback.org/d/2065">#2065</a> <a href="https://kagifeedback.org/u/eiangarsaowrfutarfgfarg">@eiangarsaowrfutarfgfarg</a></li><li>Custom bangs URL should not get URL encoded - i.e. &amp;amp; <a href="https://kagifeedback.org/d/2259" data-id="2259"><span></span></a><a href="https://kagifeedback.org/d/2259">#2259</a> <a href="https://kagifeedback.org/u/Value7609">@Value7609</a> </li><li>Z-index incorrect for keyboard shortcuts overlay <a href="https://kagifeedback.org/d/2143" data-id="2143"><span></span></a><a href="https://kagifeedback.org/d/2143">#2143</a> <a href="https://kagifeedback.org/u/theperiscope">@theperiscope</a></li><li>The video in <a href="https://kagi.com/changelog" rel="ugc nofollow">https://kagi.com/changelog</a> is blocked by CSP <a href="https://kagifeedback.org/d/2139" data-id="2139"><span></span></a><a href="https://kagifeedback.org/d/2139">#2139</a> <a href="https://kagifeedback.org/u/FrederickZh">@FrederickZh</a> </li><li>Wikipedia-mode.el is always at the top of an Emacs search <a href="https://kagifeedback.org/d/1923" data-id="1923"><span></span></a><a href="https://kagifeedback.org/d/1923">#1923</a> <a href="https://kagifeedback.org/u/gthomsen">@gthomsen</a> </li><li>Quick answer info tooltip z-index issue <a href="https://kagifeedback.org/d/2049" data-id="2049"><span></span></a><a href="https://kagifeedback.org/d/2049">#2049</a> <a href="https://kagifeedback.org/u/sdgluck">@sdgluck</a></li><li>Kagi Summary API now returns numbered list summaries <a href="https://kagifeedback.org/d/2149" data-id="2149"><span></span></a><a href="https://kagifeedback.org/d/2149">#2149</a> <a href="https://kagifeedback.org/u/bitjammer">@bitjammer</a></li><li>Unsanitized HTML output <a href="https://kagifeedback.org/d/2088" data-id="2088"><span></span></a><a href="https://kagifeedback.org/d/2088">#2088</a> <a href="https://kagifeedback.org/u/jurassicpeak">@jurassicpeak</a> </li><li>Family plan page overflows on mobile <a href="https://kagifeedback.org/d/2011" data-id="2011"><span></span></a><a href="https://kagifeedback.org/d/2011">#2011</a> <a href="https://kagifeedback.org/u/ForumNinja404">@ForumNinja404</a> </li><li>Advanced search options show above keyboard shortcuts <a href="https://kagifeedback.org/d/2017" data-id="2017"><span></span></a><a href="https://kagifeedback.org/d/2017">#2017</a> <a href="https://kagifeedback.org/u/KoboldMage">@KoboldMage</a></li></ul><p><strong>Assistant beta</strong> (currently available to Ultimate plan members, general availability planned for November)</p><p>✨ Features</p><ul><li>Significantly improved logic driving follow-ups in Research mode</li><li>Better use of previous searches</li><li>New logic to derive additional searches when needed</li><li>Better detection of when additional searches are not needed (and would degrade the output)</li></ul><p>🪲 Bugfixes</p><ul><li>Assistant response caching doesn't account for the entirety of a multiline primp <a href="https://kagifeedback.org/d/2170" data-id="2170"><span></span></a><a href="https://kagifeedback.org/d/2170">#2170</a> <a href="https://kagifeedback.org/u/httpjames">@httpjames</a></li><li>Assistant: Weird layout while code assistent writes unfinished fenced code blocks <a href="https://kagifeedback.org/d/2115" data-id="2115"><span></span></a><a href="https://kagifeedback.org/d/2115">#2115</a> <a href="https://kagifeedback.org/u/warpspin">@warpspin</a> </li><li>Security fixes (XSS) - many thanks to the users who have been flagging these</li><li>Images are more consistently displayed when available</li><li>Better filtering of input so multiple distinct people/places are less likely to be confused</li><li>Assistant-related bangs should now display in the UI for all beta users</li><li>!fast and !expert are fixed</li><li>Better responses for edge cases</li><li>Another input limit bug</li><li>Formatting fixes for summaries</li><li>Various backend bugfixes</li></ul></div></div><div id="2136"><h2><span>Sep 28, 2023 - Assistant beta and enhanced accessibility</span><a href="https://kagi.com/changelog#2136"> #</a></h2><div><p>We are rolling <strong>Kagi Assistant beta</strong> for all our current Ultimate plan members (new Ultimate plan users will be onboarded daily). Assistant includes four dynamic AI modes - Research, Code, Chat, and Custom - powered by cutting-edge language models like GPT-4 and Claude-2 (on the Ultimate plan), all in one package. Stay tuned, as we plan to make the Assistant available to all members in the coming weeks.</p><p><img src="https://kagifeedback.org/assets/files/2023-09-29/1695962516-11471-image.png" title="" alt=""></p><p>We're committed to making our platform more accessible. We already made a number of changes to <strong>improve accessibility</strong> in our search experience and our latest update enhances the screen reader experience in Maps, making it more user-friendly for visually impaired users. We are at the beginning of the road and if we're committed to making our platform more accessible.  If you or someone you know can provide valuable feedback, please contact us at <a href="mailto:dylan@kagi.com">dylan@kagi.com</a>. Your input will help us better serve the needs of these members of our community.</p><p><strong>New:</strong></p><ul><li>Show the "More" menu on the front page <a href="https://kagifeedback.org/d/1579" data-id="1579"><span></span></a><a href="https://kagifeedback.org/d/1579">#1579</a> <a href="https://kagifeedback.org/u/Nankeru">@Nankeru</a> </li><li>Added $300 option for the gift card (so you can gift Ultimate plan for a year to someone)</li><li>New Kagi status page <a href="https://status.kagi.com/" rel="ugc nofollow">https://status.kagi.com</a></li></ul><p><strong>Improved:</strong></p><ul><li>Universal Summarizer unable to process transcript <a href="https://kagifeedback.org/d/1999" data-id="1999"><span></span></a><a href="https://kagifeedback.org/d/1999">#1999</a> <a href="https://kagifeedback.org/u/seligman">@seligman</a> </li><li>Make Universal Summarizer default to Key Moments</li><li>Kids account: Search Entire Web off + Lens not working as expected  <a href="https://kagifeedback.org/d/2081" data-id="2081"><span></span></a><a href="https://kagifeedback.org/d/2081">#2081</a> <a href="https://kagifeedback.org/u/spicytuna">@spicytuna</a></li><li>Kids account: use of email as username does not allow login <a href="https://kagifeedback.org/d/1828" data-id="1828"><span></span></a><a href="https://kagifeedback.org/d/1828">#1828</a> <a href="https://kagifeedback.org/u/Nils">@Nils</a></li><li>Small Values Calculations Search Suggestions <a href="https://kagifeedback.org/d/1969" data-id="1969"><span></span></a><a href="https://kagifeedback.org/d/1969">#1969</a> <a href="https://kagifeedback.org/u/Reroute5183">@Reroute5183</a> </li><li>The example searchs on the landing page do not respect system theme setting</li><li>Show wrong company stock price for apple inc keyword <a href="https://kagifeedback.org/d/1039" data-id="1039"><span></span></a><a href="https://kagifeedback.org/d/1039">#1039</a> <a href="https://kagifeedback.org/u/SukinoVerse">@SukinoVerse</a></li><li>Searching for "Vladimir Prelovac" in "Videos" gives results only about Putin <a href="https://kagifeedback.org/d/2069" data-id="2069"><span></span></a><a href="https://kagifeedback.org/d/2069">#2069</a> <a href="https://kagifeedback.org/u/ASeeker">@ASeeker</a></li></ul><p><strong>Fixed:</strong></p><ul><li>Misc billing/Stripe related issues</li><li>Trial searches were sometimes not properly updated</li><li>Case-sensitive matching for family/team invites</li><li>Safari extension Private Browsing Redirect <a href="https://kagifeedback.org/d/2084" data-id="2084"><span></span></a><a href="https://kagifeedback.org/d/2084">#2084</a> <a href="https://kagifeedback.org/u/kevrodg">@kevrodg</a> </li><li>Redirect Rules don't apply when using the “I feel lucky” (!) operator <a href="https://kagifeedback.org/d/1110" data-id="1110"><span></span></a><a href="https://kagifeedback.org/d/1110">#1110</a> <a href="https://kagifeedback.org/u/quinncom">@quinncom</a></li><li>Login does not work without JS <a href="https://kagifeedback.org/d/2045" data-id="2045"><span></span></a><a href="https://kagifeedback.org/d/2045">#2045</a> <a href="https://kagifeedback.org/u/eiangarsaowrfutarfgfarg">@eiangarsaowrfutarfgfarg</a> </li><li>XSS vulnerability when handling dates</li><li>Can only pay $10 with Paypal <a href="https://kagifeedback.org/d/2060" data-id="2060"><span></span></a><a href="https://kagifeedback.org/d/2060">#2060</a> <a href="https://kagifeedback.org/u/erikvanoosten">@erikvanoosten</a></li><li>Verbatim 'search without quotes' button not working. <a href="https://kagifeedback.org/d/1986" data-id="1986"><span></span></a><a href="https://kagifeedback.org/d/1986">#1986</a> <a href="https://kagifeedback.org/u/Value7609">@Value7609</a> </li><li>Search bar is broken, does not search anything <a href="https://kagifeedback.org/d/1975" data-id="1975"><span></span></a><a href="https://kagifeedback.org/d/1975">#1975</a> <a href="https://kagifeedback.org/u/ASeeker">@ASeeker</a></li><li>Duplicate videos in search results <a href="https://kagifeedback.org/d/1968" data-id="1968"><span></span></a><a href="https://kagifeedback.org/d/1968">#1968</a> <a href="https://kagifeedback.org/u/xjc">@xjc</a></li><li>The first result of the conversion widget adds unnecessary spaces before and after the output. <a href="https://kagifeedback.org/d/2078" data-id="2078"><span></span></a><a href="https://kagifeedback.org/d/2078">#2078</a> <a href="https://kagifeedback.org/u/loloriz">@loloriz</a> </li><li>Currency conversion, i.e., "100 usd to sek", should display widget <a href="https://kagifeedback.org/d/2031" data-id="2031"><span></span></a><a href="https://kagifeedback.org/d/2031">#2031</a> <a href="https://kagifeedback.org/u/Vapid">@Vapid</a></li><li>News widget is linking to msn.com news instead of original source. <a href="https://kagifeedback.org/d/2006" data-id="2006"><span></span></a><a href="https://kagifeedback.org/d/2006">#2006</a> <a href="https://kagifeedback.org/u/yellow">@yellow</a></li><li>Clicking "save" after adjusting soft/hard limit in billing leads to "We haven’t found anything." page <a href="https://kagifeedback.org/d/1947" data-id="1947"><span></span></a><a href="https://kagifeedback.org/d/1947">#1947</a> <a href="https://kagifeedback.org/u/chris_20017">@chris_20017</a></li><li>Empty li on billing page <a href="https://kagifeedback.org/d/2019" data-id="2019"><span></span></a><a href="https://kagifeedback.org/d/2019">#2019</a> <a href="https://kagifeedback.org/u/jonathon">@jonathon</a></li></ul><p><strong>Assistant beta:</strong></p><p>✨ Features</p><ul><li>All new mode selector (now with color!)</li><li>Info boxes for each mode, shown when clicking the ? icon</li><li>Summaries will be given in bullets</li><li>Input limits raised (for real this time) to 8k chars</li></ul><p>🪲 Bugfixes</p><ul><li>No longer re-summarize documents and delay answers</li><li>Citations will be shown with regenerated queries (and other edge cases)</li><li>Various internal AI improvements</li><li>Encoding of characters fixed</li><li>Threads won't change modes anymore</li><li>Uploading documents works no matter what mode is selected as default</li><li>More robust mode selection on landing page</li><li>No longer downgrading followups to gpt-3.5</li></ul></div></div><div id="2012"><h2><span>Sep 21, 2023 - Unlimited searches for $10/month</span><a href="https://kagi.com/changelog#2012"> #</a></h2><div><p>We're thrilled to bring you the news you've all been eagerly awaiting -  Kagi is now available with unlimited searches for just $10/month!</p><p>More in our announcement <a href="https://blog.kagi.com/unlimited-searches-for-10" rel="ugc nofollow">blog post</a>.</p><p><img src="https://kagifeedback.org/assets/files/2023-09-21/1695325178-755236-doggo-2-2.png" title="" alt=""></p></div></div><div id="1970"><h2><span>Sep 14, 2023 - Share lenses with other users</span><a href="https://kagi.com/changelog#1970"> #</a></h2><div><p>You can now share lenses with other Kagi users.</p><p>Enable lens sharing in your lens settings:</p><p><img src="https://kagifeedback.org/assets/files/2023-09-15/1694748322-861944-screenshot-2023-09-14-at-202519.png" title="" alt=""></p><p>The lens will now have the share icon which will allow you to copy a sharable link:<br><img src="https://kagifeedback.org/assets/files/2023-09-15/1694748395-602520-screenshot-2023-09-14-at-202631.png" title="" alt=""></p><p>Other users can now import the lens, using the link.</p><p>Try importing this demo lens by clicking this <a href="https://kagi.com/lenses/lw70zLGD2VksUiNe5dSFTTm90toUCp9y" rel="ugc nofollow">link</a> (it will create a lens that will allow you to search on Hacker News).</p><p><strong>New</strong></p><ul><li>Share custom lenses with other users <a href="https://kagifeedback.org/d/127" data-id="127"><span></span></a><a href="https://kagifeedback.org/d/127">#127</a> <a href="https://kagifeedback.org/u/riddley">@riddley</a> </li><li>Add darkmode support for inline map</li></ul><p><strong>Improvements</strong></p><ul><li>Results filters borders have ugly padding <a href="https://kagifeedback.org/d/1960" data-id="1960"><span></span></a><a href="https://kagifeedback.org/d/1960">#1960</a> <a href="https://kagifeedback.org/u/bln">@bln</a> </li><li>Dropdown menus should close on selection of item</li><li>Switch plan page should display your current plan <a href="https://kagifeedback.org/d/1729" data-id="1729"><span></span></a><a href="https://kagifeedback.org/d/1729">#1729</a> <a href="https://kagifeedback.org/u/Jake-Moss">@Jake-Moss</a></li><li>Apple touch icon and favicon-32x32/16x16 don't match favicon <a href="https://kagifeedback.org/d/1877" data-id="1877"><span></span></a><a href="https://kagifeedback.org/d/1877">#1877</a> <a href="https://kagifeedback.org/u/Value7609">@Value7609</a> </li><li>Show phone number in maps results not just a call button <a href="https://kagifeedback.org/d/1630" data-id="1630"><span></span></a><a href="https://kagifeedback.org/d/1630">#1630</a> <a href="https://kagifeedback.org/u/zannzen">@zannzen</a></li></ul><p><strong>Fixed</strong></p><ul><li>Escaping issues in autosuggest subtext</li><li>Can't save quick bangs <a href="https://kagifeedback.org/d/1922" data-id="1922"><span></span></a><a href="https://kagifeedback.org/d/1922">#1922</a> <a href="https://kagifeedback.org/u/Reroute5183">@Reroute5183</a></li><li>Duplicate results with different domain capitalization <a href="https://kagifeedback.org/d/1860" data-id="1860"><span></span></a><a href="https://kagifeedback.org/d/1860">#1860</a> <a href="https://kagifeedback.org/u/dan">@dan</a> </li><li><code>"business.site" -site:business.site</code> still gave *.business.site results <a href="https://kagifeedback.org/d/1818" data-id="1818"><span></span></a><a href="https://kagifeedback.org/d/1818">#1818</a> <a href="https://kagifeedback.org/u/gslin">@gslin</a></li><li>-site operator not working properly <a href="https://kagifeedback.org/d/1661" data-id="1661"><span></span></a><a href="https://kagifeedback.org/d/1661">#1661</a> <a href="https://kagifeedback.org/u/vicky">@vicky</a> </li><li>Custom bang leads to wrong bang suggestion <a href="https://kagifeedback.org/d/1168" data-id="1168"><span></span></a><a href="https://kagifeedback.org/d/1168">#1168</a> <a href="https://kagifeedback.org/u/Browsing6853">@Browsing6853</a></li><li>Local language version is ignored in Wikipedia preview <a href="https://kagifeedback.org/d/1925" data-id="1925"><span></span></a><a href="https://kagifeedback.org/d/1925">#1925</a> <a href="https://kagifeedback.org/u/chris_20017">@chris_20017</a> </li><li>Directions component become irresponsible when Kagi maps is toggled <a href="https://kagifeedback.org/d/1907" data-id="1907"><span></span></a><a href="https://kagifeedback.org/d/1907">#1907</a> <a href="https://kagifeedback.org/u/Zayon">@Zayon</a></li><li>Place search map image link leads to unexpected map result <a href="https://kagifeedback.org/d/1662" data-id="1662"><span></span></a><a href="https://kagifeedback.org/d/1662">#1662</a> <a href="https://kagifeedback.org/u/cbirdsong">@cbirdsong</a></li><li>Map thumbnail takes me to the wrong location <a href="https://kagifeedback.org/d/1410" data-id="1410"><span></span></a><a href="https://kagifeedback.org/d/1410">#1410</a> <a href="https://kagifeedback.org/u/jrdmcgr">@jrdmcgr</a></li><li>Map widget showing wrong location <a href="https://kagifeedback.org/d/1530" data-id="1530"><span></span></a><a href="https://kagifeedback.org/d/1530">#1530</a> <a href="https://kagifeedback.org/u/yeri">@yeri</a></li><li>Map preview shows different location than rest of info box <a href="https://kagifeedback.org/d/1666" data-id="1666"><span></span></a><a href="https://kagifeedback.org/d/1666">#1666</a> <a href="https://kagifeedback.org/u/sw">@sw</a></li><li>When performing local search on VPN it does not use location permission  <a href="https://kagifeedback.org/d/1564" data-id="1564"><span></span></a><a href="https://kagifeedback.org/d/1564">#1564</a> <a href="https://kagifeedback.org/u/cakeboss">@cakeboss</a></li><li>Using a capital character when blocking a domain causes the domain to not be blocked <a href="https://kagifeedback.org/d/1915" data-id="1915"><span></span></a><a href="https://kagifeedback.org/d/1915">#1915</a> <a href="https://kagifeedback.org/u/laiz">@laiz</a></li><li>Default query for !gt is "{{{s}}}" <a href="https://kagifeedback.org/d/1903" data-id="1903"><span></span></a><a href="https://kagifeedback.org/d/1903">#1903</a> <a href="https://kagifeedback.org/u/nwoeanhinnogaehr">@nwoeanhinnogaehr</a></li><li>Searching for "translated books" attempts to translate the string "d book" <a href="https://kagifeedback.org/d/1862" data-id="1862"><span></span></a><a href="https://kagifeedback.org/d/1862">#1862</a> <a href="https://kagifeedback.org/u/XMPPwocky">@XMPPwocky</a> </li><li>AND search operator description identical to OR <a href="https://kagifeedback.org/d/1930" data-id="1930"><span></span></a><a href="https://kagifeedback.org/d/1930">#1930</a> <a href="https://kagifeedback.org/u/Siemova">@Siemova</a></li></ul><p><strong>AI</strong></p><ul><li>FastGPT moved to <a href="https://kagi.com/fastgpt" rel="ugc nofollow">https://kagi.com/fastgpt</a></li><li>FastGPT: Removed blinking cursor</li><li>FastGPT: Add an X to the query input box to delete the whole query <a href="https://kagifeedback.org/d/1950" data-id="1950"><span></span></a><a href="https://kagifeedback.org/d/1950">#1950</a> <a href="https://kagifeedback.org/u/Reroute5183">@Reroute5183</a></li><li>Universal Summarizer ignoring language <a href="https://kagifeedback.org/d/1902" data-id="1902"><span></span></a><a href="https://kagifeedback.org/d/1902">#1902</a> <a href="https://kagifeedback.org/u/Heeroo">@Heeroo</a> </li><li>When summarising Tildes.net it should take into account the comments as well <a href="https://kagifeedback.org/d/1879" data-id="1879"><span></span></a><a href="https://kagifeedback.org/d/1879">#1879</a> <a href="https://kagifeedback.org/u/hook">@hook</a></li><li>The ' character in a code snippet in Discuss Document is displayed as it's unicode hex code: &amp;#x27; <a href="https://kagifeedback.org/d/1678" data-id="1678"><span></span></a><a href="https://kagifeedback.org/d/1678">#1678</a> <a href="https://kagifeedback.org/u/Grooty">@Grooty</a></li></ul></div></div><div id="1933"><h2><span>Sep 7, 2023 - Kagi Small Web</span><a href="https://kagi.com/changelog#1933"> #</a></h2><div><p>As a part of our ongoing mission to humanize the web, we're thrilled to announce the launch of Kagi Small Web initiative.</p><p>Learn more in our latest <a href="https://blog.kagi.com/small-web" rel="ugc nofollow">blog post</a>.</p><p><img src="https://kagifeedback.org/assets/files/2023-09-07/1694099345-602123-image.png" title="" alt=""></p> </div></div><div id="1909"><h2><span>Aug 31, 2023 - New payment methods</span><a href="https://kagi.com/changelog#1909"> #</a></h2><div><p>We are happy to announce that Kagi now accepts payments through PayPal and Venmo, as well as EUR payments via iDEAL and Giropay. In addition we accept Bitcoin and Bitcoin Lightning through OpenNode.</p><p>Read more in the <a href="https://blog.kagi.com/accepting-paypal-bitcoin" rel="ugc nofollow">blog post</a>.</p><p><img src="https://kagifeedback.org/assets/files/2023-08-31/1693524705-575549-screenshot-2023-08-31-at-163128.png" title="" alt=""></p><p>In addition Kagi now has support for OpenNode which closes one of the most upvotes feature suggestions on our feedback forum.</p><ul><li>Enable anonymous payments  <a href="https://kagifeedback.org/d/493" data-id="493"><span></span></a><a href="https://kagifeedback.org/d/493">#493</a> <a href="https://kagifeedback.org/u/PrivateLiberty">@PrivateLiberty</a></li></ul><p><img src="https://kagifeedback.org/assets/files/2023-08-31/1693522014-802416-screenshot-2023-08-31-at-154646.png" title="" alt=""></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Think Python, 3rd Edition (226 pts)]]></title>
            <link>https://allendowney.github.io/ThinkPython/</link>
            <guid>39392881</guid>
            <pubDate>Fri, 16 Feb 2024 03:32:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://allendowney.github.io/ThinkPython/">https://allendowney.github.io/ThinkPython/</a>, See on <a href="https://news.ycombinator.com/item?id=39392881">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      
      
      <main id="main-content">
        
        



          <div>
              
              
              
              

<div id="jb-print-docs-body">
            
            <p>
                <h2> Contents </h2>
            </p>
            <nav aria-label="Page">
                <ul>
<li><a href="#the-notebooks">The notebooks</a><ul>
<li><a href="#chapter-1-programming-as-a-way-of-thinking">Chapter 1: Programming as a way of thinking</a></li>
</ul>
</li>
<li><a href="#resources-for-teachers">Resources for teachers</a></li>
</ul>
            </nav>
        </div>

              
                

                <article role="main">
                  
  <section id="think-python-3rd-edition">
<h2>Think Python, 3rd edition<a href="#think-python-3rd-edition" title="Permalink to this heading">#</a></h2>
<p><em>Think Python</em> is an introduction to Python for people who have never programmed before – or for people who have tried and had a hard time.</p>
<p><a href="https://greenteapress.com/wp/think-python-3rd-edition/">Here is the landing page for the book at Green Tea Press</a>.</p>
<p>For the third edition, the biggest changes are:</p>
<ul>
<li><p>The book is now entirely in Jupyter notebooks, so you can read the text, run the code, and work on the exercises, all in one place. Using the links below, you can run the notebooks on Colab, so you don’t have to install anything to get started.</p></li>
<li><p>The text is substantially revised and a few chapters have been reordered. There are more exercises now, and I think a lot of them are better.</p></li>
<li><p>At the end of every chapter, there are suggestions for using tools like ChatGPT and Colab AI to learn more and to get help with the exercises.</p></li>
</ul>
<p>The book is scheduled to be published by O’Reilly Media in July 2024, so it is a work in progress.
Starting in February 2024, I plan to release new chapters here, about one per week.</p>
<p><a href="https://www.oreilly.com/library/view/think-python/9781098155421/">You can read the early release at O’Reilly Media</a></p>
<p><a href="https://www.amazon.com/_/dp/1098155432?smid=ATVPDKIKX0DER&amp;_encoding=UTF8&amp;tag=oreilly20-20&amp;_encoding=UTF8&amp;tag=greenteapre01-20&amp;linkCode=ur2&amp;linkId=e2a529f94920295d27ec8a06e757dc7c&amp;camp=1789&amp;creative=9325">You can preorder the third edition on Amazon</a></p>
<section id="the-notebooks">
<h2>The notebooks<a href="#the-notebooks" title="Permalink to this heading">#</a></h2>
<section id="chapter-1-programming-as-a-way-of-thinking">
<h3>Chapter 1: Programming as a way of thinking<a href="#chapter-1-programming-as-a-way-of-thinking" title="Permalink to this heading">#</a></h3>
<ul>
<li><p><a href="https://colab.research.google.com/github/AllenDowney/ThinkPython/blob/v3/chapters/chap01.ipynb">Click here to run Chapter 1 on Colab</a></p></li>
</ul>
</section>
</section>
<section id="resources-for-teachers">
<h2>Resources for teachers<a href="#resources-for-teachers" title="Permalink to this heading">#</a></h2>
<p>If you are teaching with this book, here are some resources you might find useful.</p>
<ul>
<li><p>You can download notebooks with solutions [COMING SOON]</p></li>
<li><p>Quizzes for each chapter, and a summative quiz for the whole book, are available [COMING SOON]</p></li>
<li><p><em>Teaching and Learning with Jupyter</em> is an online book with suggestions for using Jupyter effectively in the classroom. You can <a href="https://jupyter4edu.github.io/jupyter-edu-book">read the book here</a>.</p></li>
<li><p>One of the best ways to use notebooks in the classroom is live coding, where an instructor writes code and students follow along in their own notebooks. To learn about live coding – and a lot of other great advice about teaching programming – I recommend the teacher training provided by The Carpentries, <a href="https://carpentries.github.io/instructor-training">which you can read here</a>.</p></li>
</ul>
</section>

</section>

    
    

                </article>
              

              
              
                
              
            </div>
          
        

      </main>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefly III: A free and open source personal finance manager (124 pts)]]></title>
            <link>https://www.firefly-iii.org/</link>
            <guid>39392428</guid>
            <pubDate>Fri, 16 Feb 2024 02:34:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.firefly-iii.org/">https://www.firefly-iii.org/</a>, See on <a href="https://news.ycombinator.com/item?id=39392428">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2>Budgets, categories and tags</h2>
<p>Name your poison. Do you like to work with tags? Need to budget your expenses? Want to categorize all of your hobby expenses? Look no further. Firefly III supports all kinds. Budgets can be expanded with limits in multiple currencies, so you can budget both your daily household expenses and what you spend in Imperial Credits when visiting Tatooine.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Magika: AI powered fast and efficient file type identification (425 pts)]]></title>
            <link>https://opensource.googleblog.com/2024/02/magika-ai-powered-fast-and-efficient-file-type-identification.html</link>
            <guid>39391688</guid>
            <pubDate>Fri, 16 Feb 2024 01:02:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opensource.googleblog.com/2024/02/magika-ai-powered-fast-and-efficient-file-type-identification.html">https://opensource.googleblog.com/2024/02/magika-ai-powered-fast-and-efficient-file-type-identification.html</a>, See on <a href="https://news.ycombinator.com/item?id=39391688">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-824803887080674909" itemprop="articleBody">
<meta content="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbkRgYqDxKQrhyphenhyphenl-sNYpZJ08Oo5TqD08Yk5tcbCYzFatO-cDjDRlDH96vDiO0ylvYN-TZoKSfR4LBln1wSFJLixBRiuVeuzaF0UQ3wGUMt14VKugPHuk7q0CwSgeg0V7OVS_yxaUXbFus2yVXrLmRdB88QQyXagMFE6Axs91iDgdq1hUkS4hsS4ECMuf4/s1600/OSS-Majika-Social-V5.png" name="twitter:image">
<p>

<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxNXxbDvO9U0sI1_Vh0b_iePDZZDhr-XzvjOQTrAFBHEnaFSoohzbNR36Op83b8Hj7L1JOiex5JWEyQFVzC5jWBtLRULhMDmbu_Z4Cs3094FwQVmI8H2uOYKIu_ozG4luPhxeJIQiH_GjV7zAP4K-o-B6RnTZptdhH3nhUfatSurWEmn2x9vdp0vitAk4/s1600/OSS-Magika-Banner-V5%20%281%29.png"><img data-original-height="800" data-original-width="1058" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhxNXxbDvO9U0sI1_Vh0b_iePDZZDhr-XzvjOQTrAFBHEnaFSoohzbNR36Op83b8Hj7L1JOiex5JWEyQFVzC5jWBtLRULhMDmbu_Z4Cs3094FwQVmI8H2uOYKIu_ozG4luPhxeJIQiH_GjV7zAP4K-o-B6RnTZptdhH3nhUfatSurWEmn2x9vdp0vitAk4/s1600/OSS-Magika-Banner-V5%20%281%29.png"></a></p><p>Today we are <a href="https://google.github.io/magika/" target="_blank">open-sourcing Magika</a>, Google’s AI-powered file-type identification system, to help others accurately detect binary and textual file types. Under the hood, Magika employs a custom, highly optimized deep-learning model, enabling precise file identification within milliseconds, even when running on a CPU. </p>

<div><table><tbody><tr><td><center><img alt="Magika command line tool used to recognize a identify the type of a diverse set of files" data-original-height="1504" data-original-width="720" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiPjf8Rag2sUXJw_aUJcqEBo_RPNRG0PyFSJI8FXuyeaCYT195znXw4DW235ZHVihlUfZ744MFeZBlfhG_xdq8jjnQN5ICFjMO-rphRjt9BfO1gfyupghgAPWxNsivP9l362AcNXWnFSj_CzaJ1Con6ZMfJ1RcFExjhCDRMUs59qcQAxulIlkhBn-uhNDU/s1600/image1.png" td=""></center></td></tr><tr><td><i>Magika command line tool used to recognize a identify the type of a diverse set of files</i></td></tr></tbody></table></div>

<p>You can <a href="https://google.github.io/magika/" target="_blank">try the Magika web demo today</a>, or install it as a Python library and standalone command line tool (output is showcased above) by  using the standard command line  <span>pip install magika</span>.</p>

<h2>Why identifying file type is difficult</h2>

<p>Since the early days of computing, accurately detecting file types has been crucial in determining how to process files. Linux comes equipped with <a href="https://github.com/file/file" target="_blank"><span>libmagic</span> and the <span>file utility</span></a>, which have served as the de facto standard for file type identification for over 50 years. Today web browsers, code editors, and countless other software rely on file-type detection to decide how to properly render a file. For example, modern code editors use file-type detection to choose which syntax coloring scheme to use as the developer starts typing in a new file. </p>

<p>Accurate file-type detection is a notoriously difficult problem because each file format has a different structure, or no structure at all. This is particularly challenging for textual formats and programming languages as they have very similar constructs. So far, <span>libmagic</span> and most other file-type-identification software have been relying on a handcrafted collection of heuristics and custom rules to detect each file format.</p> 

<p>This manual approach is both time consuming and error prone as it is hard for humans to create generalized rules by hand. In particular for security applications, creating dependable detection is especially challenging as attackers are constantly attempting to confuse detection with adversarially-crafted payloads.</p>

<p>To address this issue and provide fast and accurate file-type detection we researched and developed Magika, a new AI powered file type detector. Under the hood, Magika uses a custom, highly optimized deep-learning model designed and trained using <a href="https://keras.io/" target="_blank">Keras</a> that only weighs about 1MB.  At inference time Magika uses  <a href="https://onnx.ai/" target="_blank">Onnx</a> as an inference engine to ensure files are identified in a matter of milliseconds, almost as fast as a non-AI tool even on CPU.</p>

<h2>Magika Performance</h2>

<div><table><tbody><tr><td><center><img alt="Magika detection quality compared to other tools on our 1M files benchmark" data-original-height="1504" data-original-width="720" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuz_BUIEGw6FQfhzA1lr4EQ1SLO_O0S8TIlGrnYY5Kh0BRngFTboPD4_DTCYsbKkO9c51xUKaulCu8ivEdyQlGIhEfvRzleArV9XpatHdvgSf62F1kt3DMwSOwOOan6gL2kaaangCIzQBv1ZVGIXInx-9jpO9N_OkYR8LeJvl6A-Ba3Qdfq441i9QBxvY/s1600/image2.png" td=""></center></td></tr><tr><td><i>Magika detection quality compared to other tools on our 1M files benchmark</i></td></tr></tbody></table></div>

<p>Performance wise, Magika, thanks to its AI model and large training dataset, is able to  outperform other existing tools by about 20% when evaluated on a 1M files benchmark that encompasses over 100 file types.  Breaking down by file type, as reported in the table below, we see even greater performance gains on textual files, including code files  and configuration files that other tools can struggle with.</p>

<div><table><tbody><tr><td><center><img alt="Table showing various file type identification tools performance for a selection of the file types included in our benchmark" data-original-height="1504" data-original-width="720" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhYHJfKw3xp2yBY_qdS8RcamEPn5oWhK2jbbkSgztnC_icqV7IFqh3lcAOWEzEu20TI2zMwBsdBp6YauRRc-ouVZTqLpxbkW5PMoBfuZLgSJKwfYIBVjGrrbM8Ob2P5iuJvQXE2eQ5mGe0WFXT4ilZbciPwasz8h-6AKx-sk7CH_klLRwrYbC3VqDPqlng/s1600/Screenshot%202024-02-15%20at%2011.24.40%E2%80%AFAM.png" td=""></center></td></tr><tr><td><i>Various file type identification tools performance for a selection of the file types included in our benchmark - n/a indicates the tool doesn’t detect the given file type.</i></td></tr></tbody></table></div><br>

<h2>Magika at Google</h2>

<p>Internally, Magika is used at scale to help improve Google users’ safety by routing Gmail, Drive, and Safe Browsing files to the proper security and content policy scanners.
Looking at a weekly average of hundreds of billions of files reveals that Magika improves file type identification accuracy by 50% compared to our previous system that relied on handcrafted rules. In particular, this increase in accuracy allows us to scan 11% more files with our <a href="https://security.googleblog.com/2020/02/improving-malicious-document-detection.html" target="_blank">specialized malicious AI document scanners</a> and reduce the number of unidentified files to 3%.</p>

<p>The upcoming integration of Magika with VirusTotal will complement the platform's existing Code Insight functionality, which employs Google's generative AI to analyze and detect malicious code. Magika will act as a pre-filter before files are analyzed by <a href="https://blog.virustotal.com/2023/04/introducing-virustotal-code-insight.html" target="_blank">Code Insight</a>, improving the platform’s efficiency and accuracy. This integration, due to VirusTotal’s collaborative nature, directly contributes to the global cybersecurity ecosystem, fostering a safer digital environment.</p>

<h2>Open Sourcing Magika</h2>

<p>By <a href="https://google.github.io/magika/" target="_blank">open-sourcing Magika</a>, we aim to help other software improve their file identification accuracy and offer researchers a reliable method for identifying file types at scale. </p>

<p><a href="https://github.com/google/magika" target="_blank">Magika code and model</a> are freely available starting today in Github under the Apache2 License. Magika  can also quickly be installed as a standalone utility and python library via the <a href="https://pypi.org/project/magika/" target="_blank">pypi package manager</a> by simply typing <span>pip install</span> magika with no GPU required. We also have an experimental <a href="https://www.npmjs.com/package/magika" target="_blank">npm package</a> if you would like to use the TFJS version.</p>

<p>To learn more about how to use it, please refer to <a href="https://www.npmjs.com/package/magika" target="_blank">Magika documentation site</a>.</p><br>

<h4><span>Acknowledgements </span></h4>
  
<p>Magika would not have been possible without the help of many people including: Ange Albertini, Loua Farah, Francois Galilee, Giancarlo Metitieri, Luca Invernizzi, Young Maeng, Alex Petit-Bianco, David Tao, Kurt Thomas, Amanda Walker, and Zhixun Tan.</p>

<p><em>By Elie Bursztein – Cybersecurity AI Technical and Research Lead and Yanick Fratantonio – Cybersecurity Research Scientist</em></p>







</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Video generation models as world simulators (265 pts)]]></title>
            <link>https://openai.com/research/video-generation-models-as-world-simulators</link>
            <guid>39391458</guid>
            <pubDate>Fri, 16 Feb 2024 00:38:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/research/video-generation-models-as-world-simulators">https://openai.com/research/video-generation-models-as-world-simulators</a>, See on <a href="https://news.ycombinator.com/item?id=39391458">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><!--[--><!--[--><!--]--><!--[--><div><p>This technical report focuses on (1) our method for turning visual data of all types into a unified representation that enables large-scale training of generative models, and (2) qualitative evaluation of Sora’s capabilities and limitations. Model and implementation details are not included in this report.</p><p>Much prior work has studied generative modeling of video data using a variety of methods, including recurrent networks,<span><sup><span>[^1]</span></sup><!----></span><span><sup><span>[^2]</span></sup><!----></span><span><sup><span>[^3]</span></sup><!----></span> generative adversarial networks,<span><sup><span>[^4]</span></sup><!----></span><span><sup><span>[^5]</span></sup><!----></span><span><sup><span>[^6]</span></sup><!----></span><span><sup><span>[^7]</span></sup><!----></span> autoregressive transformers,<span><sup><span>[^8]</span></sup><!----></span><span><sup><span>[^9]</span></sup><!----></span> and diffusion models.<span><sup><span>[^10]</span></sup><!----></span><span><sup><span>[^11]</span></sup><!----></span><span><sup><span>[^12]</span></sup><!----></span> These works often focus on a narrow category of visual data, on shorter videos, or on videos of a fixed size. Sora is a generalist model of visual data—it can generate videos and images spanning diverse durations, aspect ratios and resolutions, up to a full minute of high definition video.<br></p></div><!--]--><!--[--><div id="turning-visual-data-into-patches" data-heading=""><p><h2>Turning visual data into patches</h2></p></div><!--]--><!--[--><div><p>We take inspiration from large language models which acquire generalist capabilities by training on internet-scale data.<span><sup><span>[^13]</span></sup><!----></span><span><sup><span>[^14]</span></sup><!----></span> The success of the LLM paradigm is enabled in part by the use of tokens<em> </em>that elegantly unify diverse modalities of text—code, math and various natural languages. In this work, we consider how generative models of visual data can inherit such benefits. Whereas LLMs have text tokens, Sora has visual <em>patches</em>. Patches have previously been shown to be an effective representation for models of visual data.<span><sup><span>[^15]</span></sup><!----></span><span><sup><span>[^16]</span></sup><!----></span><span><sup><span>[^17]</span></sup><!----></span><span><sup><span>[^18]</span></sup><!----></span> We find that patches are a highly-scalable and effective representation for training generative models on diverse types of videos and images.<br></p></div><!--]--><!--[--><div><figure><p><img src="https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=10&amp;height=10&amp;quality=50" width="2031" height="378" alt="Figure Patches" loading="lazy" data-nuxt-img="" sizes="(max-width: 744px) 100vw, (max-width: 1280px) 100vw, (max-width: 1440px) 100vw, 100vw" srcset="https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=400 400w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=800 800w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=1000 1000w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=1400 1400w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=2000 2000w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=2600 2600w, https://images.openai.com/blob/1d2955dd-9d05-4f33-b346-be531d2a7737/figure-patches.png?trim=0,0,0,0&amp;width=3200 3200w" aria-hidden="false"></p><figcaption><!--[--><!--]--></figcaption></figure></div><!--]--><!--[--><div><p>At a high level, we turn videos into patches by first compressing videos into a lower-dimensional latent space,<span><sup><span>[^19]</span></sup><!----></span> and subsequently decomposing the representation into spacetime patches.<br></p></div><!--]--><!--[--><div id="video-compression-network" data-heading=""><p><h2>Video compression network</h2></p></div><!--]--><!--[--><div><p>We train a network that reduces the dimensionality of visual data.<span><sup><span>[^20]</span></sup><!----></span> This network takes raw video as input and outputs a latent representation that is compressed both temporally and spatially. Sora is trained on and subsequently generates videos within this compressed latent space. We also train a corresponding decoder model that maps generated latents back to pixel space.</p></div><!--]--><!--[--><div id="spacetime-latent-patches" data-heading=""><p><h2>Spacetime Latent Patches</h2></p></div><!--]--><!--[--><div><p>Given a compressed input video, we extract a sequence of spacetime patches which act as transformer tokens. This scheme works for images too since images are just videos with a single frame. Our patch-based representation enables Sora to train on videos and images of variable resolutions, durations and aspect ratios. At inference time, we can control the size of generated videos by arranging randomly-initialized patches in an appropriately-sized grid.<br></p></div><!--]--><!--[--><div id="scaling-transformers-for-video-generation" data-heading=""><p><h2>Scaling transformers for video generation</h2></p></div><!--]--><!--[--><div><p>Sora is a diffusion model<span><sup><span>[^21]</span></sup><!----></span><span><sup><span>[^22]</span></sup><!----></span><span><sup><span>[^23]</span></sup><!----></span><span><sup><span>[^24]</span></sup><!----></span><span><sup><span>[^25]</span></sup><!----></span>; given input noisy patches (and conditioning information like text prompts), it’s trained to predict the original “clean” patches. Importantly, Sora is a diffusion <em>transformer</em>.<span><sup><span>[^26]</span></sup><!----></span> Transformers have demonstrated remarkable scaling properties across a variety of domains, including language modeling,<span><sup><span>[^13]</span></sup><!----></span><span><sup><span>[^14]</span></sup><!----></span> computer vision,<span><sup><span>[^15]</span></sup><!----></span><span><sup><span>[^16]</span></sup><!----></span><span><sup><span>[^17]</span></sup><!----></span><span><sup><span>[^18]</span></sup><!----></span> and image generation.<span><sup><span>[^27]</span></sup><!----></span><span><sup><span>[^28]</span></sup><!----></span><span><sup><span>[^29]</span></sup><!----></span><br></p></div><!--]--><!--[--><div><figure><p><img src="https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=10&amp;height=10&amp;quality=50" width="1261" height="312" alt="Figure Diffusion" loading="lazy" data-nuxt-img="" sizes="(max-width: 744px) 100vw, (max-width: 1280px) 100vw, (max-width: 1440px) 100vw, 100vw" srcset="https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=400 400w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=800 800w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=1000 1000w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=1400 1400w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=2000 2000w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=2600 2600w, https://images.openai.com/blob/aa8b687c-bee5-4d72-a1c8-1350d33c80d3/figure-diffusion.png?trim=0,0,0,0&amp;width=3200 3200w" aria-hidden="false"></p><figcaption><!--[--><!--]--></figcaption></figure></div><!--]--><!--[--><div><p>In this work, we find that diffusion transformers scale effectively as video models as well. Below, we show a comparison of video samples with fixed seeds and inputs as training progresses. Sample quality improves markedly as training compute increases.<br></p></div><!--]--><!--[--><!--]--><!--[--><div id="variable-durations-resolutions-aspect-ratios" data-heading=""><p><h2>Variable durations, resolutions, aspect ratios</h2></p></div><!--]--><!--[--><div><p>Past approaches to image and video generation typically resize, crop or trim videos to a standard size – e.g., 4 second videos at 256x256 resolution. We find that instead training on data at its native size provides several benefits.<br></p></div><!--]--><!--[--><div id="sampling-flexibility" data-heading=""><p><h3>Sampling flexibility</h3></p></div><!--]--><!--[--><div><p>Sora can sample widescreen 1920x1080p videos, vertical 1080x1920 videos and everything inbetween. This lets Sora create content for different devices directly at their native aspect ratios. It also lets us quickly prototype content at lower sizes before generating at full resolution—all with the same model.<br></p></div><!--]--><!--[--><!--]--><!--[--><div id="improved-framing-and-composition" data-heading=""><p><h3>Improved framing and composition</h3></p></div><!--]--><!--[--><div><p>We empirically find that training on videos at their native aspect ratios improves composition and framing. We compare Sora against a version of our model that crops all training videos to be square, which is common practice when training generative models. The model&nbsp; trained on square crops (left) sometimes generates videos where the subject is only partially in view. In comparison, videos from Sora (right)s have improved framing.<br></p></div><!--]--><!--[--><!--]--><!--[--><div id="language-understanding" data-heading=""><p><h2>Language understanding</h2></p></div><!--]--><!--[--><div><p>Training text-to-video generation systems requires a large amount of videos with corresponding text captions. We apply the re-captioning technique introduced in DALL·E 3<span><sup><span>[^30]</span></sup><!----></span> to videos. We first train a highly descriptive captioner model and then use it to produce text captions for all videos in our training set. We find that training on highly descriptive video captions improves text fidelity as well as the overall quality of videos.</p><p>Similar to DALL·E 3, we also leverage GPT to turn short user prompts into longer detailed captions that are sent to the video model. This enables Sora to generate high quality videos that accurately follow user prompts.<br></p></div><!--]--><!--[--><div layout="full-bleed" id="SoraMadlib-25"><p> taking a pleasant stroll in </p></div><!--]--><!--[--><div id="prompting-with-images-and-videos" data-heading=""><p><h2>Prompting with images and videos</h2></p></div><!--]--><!--[--><div><p>All of the results above and in our <a href="https://openai.com/sora" rel="noopener noreferrer">landing page</a> show text-to-video samples. But Sora can also be prompted with other inputs, such as pre-existing images or video. This capability enables Sora to perform a wide range of image and video editing tasks—creating perfectly looping video, animating static images, extending videos forwards or backwards in time, etc.<br></p></div><!--]--><!--[--><div id="animating-dall-e-images" data-heading=""><p><h3>Animating DALL·E images</h3></p></div><!--]--><!--[--><div><p>Sora is capable of generating videos provided an image and prompt as input. Below we show example videos generated based on DALL·E 2<span><sup><span>[^31]</span></sup><!----></span> and DALL·E 3<span><sup><span>[^30]</span></sup><!----></span> images.<br></p></div><!--]--><!--[--><div layout="auto" id="SoraVideoGrid-30"><!--[--><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/prompting_0.png"></p></div><!--]--><p>A Shiba Inu dog wearing a beret and black turtleneck.</p></div><!--]--><!--[--><div layout="auto" id="SoraVideoGrid-31"><!--[--><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/prompting_2.png"></p></div><!--]--><p>Monster Illustration in flat design style of a diverse family of monsters. The group includes a furry brown monster, a sleek black monster with antennas, a spotted green monster, and a tiny polka-dotted monster, all interacting in a playful environment.</p></div><!--]--><!--[--><div layout="auto" id="SoraVideoGrid-32"><!--[--><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/prompting_4.png"></p></div><!--]--><p>An image of a realistic cloud that spells “SORA”.</p></div><!--]--><!--[--><div layout="auto" id="SoraVideoGrid-33"><!--[--><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/prompting_6.png"></p></div><!--]--><p>In an ornate, historical hall, a massive tidal wave peaks and begins to crash. Two surfers, seizing the moment, skillfully navigate the face of the wave.</p></div><!--]--><!--[--><div id="extending-generated-videos" data-heading=""><p><h3>Extending generated videos</h3></p></div><!--]--><!--[--><div><p>Sora is also capable of extending videos, either forward or backward in time. Below are four videos that were all extended backward in time starting from a segment of a generated video. As a result, each of the four videos starts different from the others, yet all four videos lead to the same ending.<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p>We can use this method to extend a video both forward and backward to produce a seamless infinite loop.<br></p></div><!--]--><!--[--><!--]--><!--[--><div id="video-to-video-editing" data-heading=""><p><h3>Video-to-video editing</h3></p></div><!--]--><!--[--><div><p>Diffusion models have enabled a plethora of methods for editing images and videos from text prompts. Below we apply one of these methods, SDEdit,<span><sup><span>[^32]</span></sup><!----></span> to Sora. This technique enables Sora to transform&nbsp; the styles and environments of input videos zero-shot.<br></p></div><!--]--><!--[--><!--]--><!--[--><div id="connecting-videos" data-heading=""><p><h3>Connecting videos</h3></p></div><!--]--><!--[--><div><p>We can also use Sora to gradually interpolate between two input videos, creating seamless transitions between videos with entirely different subjects and scene compositions. In the examples below, the videos in the center interpolate between the corresponding videos on the left and right.<br></p></div><!--]--><!--[--><!--]--><!--[--><div id="image-generation-capabilities" data-heading=""><p><h2>Image generation capabilities</h2></p></div><!--]--><!--[--><div><p>Sora is also capable of generating images. We do this by arranging patches of Gaussian noise in a spatial grid with a temporal extent of one frame. The model can generate images of variable sizes—up to 2048x2048 resolution.<br></p></div><!--]--><!--[--><div layout="auto" id="SoraVideoGrid-47"><!--[--><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/image_0.png"><span>Close-up portrait shot of a woman in autumn, extreme detail, shallow depth of field</span></p></div><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/image_1.png"><span>Vibrant coral reef teeming with colorful fish and sea creatures</span></p></div><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/image_2.png"><span>Digital art of a young tiger under an apple tree in a matte painting style with gorgeous details</span></p></div><div><p><img loading="lazy" src="https://cdn.openai.com/tmp/s/image_3.png"><span>A snowy mountain village with cozy cabins and a northern lights display, high detail and photorealistic dslr, 50mm f/1.2</span></p></div><!--]--><!----></div><!--]--><!--[--><div id="emerging-simulation-capabilities" data-heading=""><p><h2>Emerging simulation capabilities</h2></p></div><!--]--><!--[--><div><p>We find that video models exhibit a number of interesting emergent capabilities when trained at scale. These capabilities enable Sora to simulate some aspects of people, animals and environments from the physical world. These properties emerge without any explicit inductive biases for 3D, objects, etc.—they are purely phenomena of scale.</p><p><strong>3D consistency.</strong> Sora can generate videos with dynamic camera motion. As the camera shifts and rotates, people and scene elements move consistently through three-dimensional space.<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p><strong>Long-range coherence and object permanence. </strong>A significant challenge for video generation systems has been maintaining temporal consistency when sampling long videos. We find that Sora is often, though not always, able to effectively model both short- and long-range dependencies. For example, our model can persist people, animals and objects even when they are occluded or leave the frame. Likewise, it can generate multiple shots of the same character in a single sample, maintaining their appearance throughout the video.<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p><strong>Interacting with the world.</strong> Sora can sometimes simulate actions that affect the state of the world in simple ways. For example, a painter can leave new strokes along a canvas that persist over time, or a man can eat a burger and leave bite marks.<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p><strong>Simulating digital worlds.</strong> Sora is also able to simulate artificial processes–one example is video games. Sora can simultaneously control the player in Minecraft with a basic policy while also rendering the world and its dynamics in high fidelity. These capabilities can be elicited zero-shot by prompting Sora with captions mentioning “Minecraft.”<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p>These capabilities suggest that continued scaling of video models is a promising path towards the development of highly-capable simulators of the physical and digital world, and the objects, animals and people that live within them.<br></p></div><!--]--><!--[--><div id="discussion" data-heading=""><p><h2>Discussion</h2></p></div><!--]--><!--[--><!--]--><!--[--><div><p>Sora currently exhibits numerous limitations as a simulator. For example, it does not accurately model the physics of many basic interactions, like glass shattering. Other interactions, like eating food, do not always yield correct changes in object state. We enumerate other common failure modes of the model—such as incoherencies that develop in long duration samples or spontaneous appearances of objects—in our <a href="https://openai.com/sora" rel="noopener noreferrer">landing page</a>.<br></p></div><!--]--><!--[--><!--]--><!--[--><div><p>We believe the capabilities Sora has today demonstrate that continued scaling of video models is a promising path towards the development of capable simulators of the physical and digital world, and the objects, animals and people that live within them.<br></p></div><!--]--><!--]--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It Was 33 Years Ago Today: Happy Birthday Lemmings (349 pts)]]></title>
            <link>https://scottishgames.net/2024/02/14/it-was-33-years-ago-today-happy-birthday-lemmings/</link>
            <guid>39390965</guid>
            <pubDate>Thu, 15 Feb 2024 23:48:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scottishgames.net/2024/02/14/it-was-33-years-ago-today-happy-birthday-lemmings/">https://scottishgames.net/2024/02/14/it-was-33-years-ago-today-happy-birthday-lemmings/</a>, See on <a href="https://news.ycombinator.com/item?id=39390965">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-37461">
		<!-- .entry-header -->

	
	<div>
		
<p>Today, February 14th, 2024, marks the 33rd anniversary of <em><a href="https://en.wikipedia.org/wiki/Lemmings_(video_game)">Lemmings</a></em>, the game that transcended mere entertainment to become a cultural icon and a catalyst for Scotland’s thriving game development industry. But before the green-haired hordes invaded screens worldwide, let’s rewind to 1991 and trace its remarkable journey.</p>



<p>Born from the minds of DMA Design (now of course Rockstar North), a small Dundee studio, Lemmings was a revolutionary concept. Instead of blowing things you, you were tasked with saving the plummeting rodents’ lives. </p>



<p>However, DMA’s genius lay in its execution. With charming character design (at an astonishingly small scale), addictive puzzle mechanics, and more than a touch of what would become DMA’s slapstick humour, they transformed a complex concept into a game anyone could pick up and play.</p>


<div>
<figure><a href="https://i0.wp.com/scottishgames.net/wp-content/uploads/2012/11/lemmings-8bit.jpg?ssl=1"><img loading="lazy" decoding="async" width="580" height="363" data-attachment-id="4108" data-permalink="https://scottishgames.net/2012/11/06/steve-hammonds-manual-override-realit/lemmings-8bit/" data-orig-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2012/11/lemmings-8bit.jpg?fit=580%2C363&amp;ssl=1" data-orig-size="580,363" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="lemmings 8bit" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2012/11/lemmings-8bit.jpg?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2012/11/lemmings-8bit.jpg?fit=580%2C363&amp;ssl=1" src="https://i0.wp.com/scottishgames.net/wp-content/uploads/2012/11/lemmings-8bit.jpg?resize=580%2C363&amp;ssl=1" alt="Lemming. 8 Bit." data-recalc-dims="1"></a></figure></div>


<p><em>Lemmings</em> offered a simple premise: guide a predetermined number of lemmings to an exit by assigning them roles like blocker, climber, builder, and floater. But simplicity masks depth. Each level presented a unique challenge, requiring strategic thinking, quick reflexes, and a touch of trial-and-error gory death.</p>



<p>Success was immediate. <em>Lemmings</em> conquered consoles and computers, selling over 15 million copies and becoming the UK’s best-selling game of 1991. Awards and accolades rained down, but perhaps the most significant impact was on Scottish gaming itself. Lemmings put DMA Design on the map, attracting talent and investment and inspiring the world’s first games degree.</p>



<p>The Scottish Games Network spoke to several of the original team members to ask for their thoughts on the impact of the game:</p>



<h4>Mike Dailly, the creator of the original animation of tiny things being splattered, said:</h4>



<blockquote>
<p>I’m constantly amazed at the legacy of Lemmings. Where ever I go, there are fans, old and new who love the game. With the style, and accessibility of it, it not only entertained, but brought families closer together as kids played with their non-game playing parents and grandparents. I get people getting in touch all the time telling me of their happy memories of playing it with their relatives who never had an interest in games before, and being able to share their hobby with them, meant the world to them.</p>



<p>Even now at shows, some 33 years later, you’ll still see the odd person dressed up as a Lemming and expressing love for the game, the music, the sound effects, the characters – or how they were useless at it, but loved to just nuke them!</p>



<p>Lemmings is still the game I’m most proud to have been a part of, in a world of first person shooters, it’s as popular now as it ever was with young and old alike</p>
</blockquote>



<h4>Russell Kay, told us his dream is to bring the games to a new generation:</h4>



<blockquote>
<p>33 years ago we released a game that is still loved today that is very gratifying and I don’t think any of us would have believed you if we were told at the time. Over the years we have fallen in and out of love with the franchise but it holds a special place in our hearts, personally I would love to be able to update the characters and franchise but Sony hold onto the rights jealously, it would be fantastic to get a chance to see what the Lemmings would make of the modern gaming world!</p>
</blockquote>



<p>Lemmings’ influence resonated far beyond Scotland. It can be said to have popularised puzzle games, inspiring titles like <em>The Incredible Machine</em>. Its emphasis on physics and user-generated content laid the groundwork for future sandbox games (possibly even <em>Minecraft</em>…?)</p>



<p>Moreover, its humour and memorable characters solidified DMA Design’s reputation for innovative, surprising and engaging gameplay, paving the way for future classics like <em>Grand Theft Auto</em>, the often overlooked (and far more bonkers) <em>Tanktics</em>, cult-classic <em>Body Harvest</em> and the underrated <em>Wild Metal Country</em>.</p>



<p>Today, Lemmings remains a beloved puzzle classic, enjoying re-releases on various platforms and inspiring new generations of designers. But its legacy extends far beyond nostalgic pixelated memories. Dundee’s city centre plays host to a beloved <a href="https://scottishgames.net/2013/10/14/lets-go-lemmings-in-the-real-world/">series of statues of Lemmings</a>, hard at work, climbing and bridging a garden gateway overlooking the river Tay.</p>


<div>
<figure><a href="https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?ssl=1"><img loading="lazy" decoding="async" width="740" height="448" data-attachment-id="37472" data-permalink="https://scottishgames.net/2024/02/14/it-was-33-years-ago-today-happy-birthday-lemmings/screenshot-2024-02-14-at-14-08-29/" data-orig-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?fit=1398%2C846&amp;ssl=1" data-orig-size="1398,846" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2024-02-14 at 14.08.29" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?fit=300%2C182&amp;ssl=1" data-large-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?fit=740%2C448&amp;ssl=1" src="https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?resize=740%2C448&amp;ssl=1" alt="Lemmings statue, Perth Road, Dundee" srcset="https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?resize=1024%2C620&amp;ssl=1 1024w, https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?resize=300%2C182&amp;ssl=1 300w, https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?resize=768%2C465&amp;ssl=1 768w, https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?resize=1200%2C726&amp;ssl=1 1200w, https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?resize=500%2C303&amp;ssl=1 500w, https://i0.wp.com/scottishgames.net/wp-content/uploads/2024/02/Screenshot-2024-02-14-at-14.08.29.png?w=1398&amp;ssl=1 1398w" sizes="(max-width: 706px) 89vw, (max-width: 767px) 82vw, 740px" data-recalc-dims="1"></a></figure></div>


<p>On the 20th anniversary in 2011 <a href="https://scottishgames.net/2021/02/15/happy-birthday-lemmings-30-today/">a plaque was unveiled</a> at the bottom of Perth Road in the city, commemorating DMA’s first office, where the game was originally born.</p>


<div>
<figure><a href="https://i0.wp.com/scottishgames.net/wp-content/uploads/2011/02/cropped-bb-lemmings.jpg?ssl=1"><img loading="lazy" decoding="async" width="700" height="200" data-attachment-id="881" data-permalink="https://scottishgames.net/cropped-bb-lemmings-jpg/" data-orig-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2011/02/cropped-bb-lemmings.jpg?fit=700%2C200&amp;ssl=1" data-orig-size="700,200" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="cropped-bb-lemmings.jpg" data-image-description="<p>http://scottishgames.net/wp-content/uploads/2011/02/cropped-bb-lemmings.jpg</p>
" data-image-caption="" data-medium-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2011/02/cropped-bb-lemmings.jpg?fit=300%2C86&amp;ssl=1" data-large-file="https://i0.wp.com/scottishgames.net/wp-content/uploads/2011/02/cropped-bb-lemmings.jpg?fit=700%2C200&amp;ssl=1" src="https://i0.wp.com/scottishgames.net/wp-content/uploads/2011/02/cropped-bb-lemmings.jpg?resize=700%2C200&amp;ssl=1" alt="" data-recalc-dims="1"></a></figure></div>


<p>In 2022 <em><a href="https://scottishgames.net/2022/02/15/lemmings-can-you-dig-it-youtube/" target="_blank" rel="noreferrer noopener">Lemmings: Can You Dig It?</a></em> a feature-length documentary was released, which charted the design and development of the original game and its impact upon gamers today. You can watch it here:</p>



<figure><p><span><iframe loading="lazy" width="740" height="417" src="https://www.youtube.com/embed/RbAVNKdk9gA?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-GB&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox"></iframe></span>
</p></figure>



<p>Happy birthday <em>Lemmings</em>!</p>
		
		
		
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Galactic Compass – an app that points to the galactic center (141 pts)]]></title>
            <link>https://interconnected.org/home/2024/02/15/galactic-compass</link>
            <guid>39389858</guid>
            <pubDate>Thu, 15 Feb 2024 22:12:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://interconnected.org/home/2024/02/15/galactic-compass">https://interconnected.org/home/2024/02/15/galactic-compass</a>, See on <a href="https://news.ycombinator.com/item?id=39389858">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="social-select-root" data-highlights="">
  <p>Hey I made an app! It’s a green floating arrow that always points to the middle of the Milky Way.</p>
<p>i.e. 26,000 light years towards the supermassive central black hole, Sagittarius A*.</p>
<p>You can have it too!</p>
<p><strong><a href="https://apps.apple.com/gb/app/galactic-compass/id6451314440">Download Galactic Compass from the App Store.</a></strong></p>
<p>BUT: I don’t know how to write apps.</p>
<p>And yet here we are!</p>
<p>Let me explain.</p>
<p><img alt="" src="https://interconnected.org/home/static/content/2024/02/15/galactic-compass.jpg"></p>
<h3>Cultivating a sense of the galactic centre</h3>
<p>It’s remarkably grounding?</p>
<p>Once upon a time I trained myself to always know where to look, and the centre of the galaxy moves of course over the day and the year: <q>So I would end up pointing through the pavement, or down a street, and thinking, huh, that’s where it is.</q></p>
<p>It is a worthwhile super-sense:</p>
<blockquote>
<p>Eventually then I had this picture of myself, and the Earth, and the solar system, and the centre of the galaxy which had initially been whirling round me, and now it had flipped, <u>I was turning around it.</u></p>
<p>It was wildly situating.</p>
</blockquote>
<p>I’ve lost the intuition now, sadly.</p>
<p>The above description is from <a href="https://interconnected.org/home/2021/06/30/galaxy">my 2021 writeup</a> which I conclude by saying:</p>
<blockquote>
<p>In my imagination I see an iPhone app which displays a 3D model, connected to the gyroscope and the compass and the GPS. …</p>
<p><u>But there are slightly too many things I would need to learn</u></p>
</blockquote>
<p>So I couldn’t built it.</p>
<p>EXCEPT.</p>
<p><em>Now there is ChatGPT.</em></p>
<hr>
<h3>Developing an app with ChatGPT</h3>
<p>I can’t write Swift (the language used to code iOS apps).</p>
<p>But what I am able to do is break up large problems into smaller, expressible problems, and then sequence them.</p>
<p><strong>I’ll be detailed about this.</strong> When I’ve walking folks through this, they’re often interested so it is (perhaps) non-obvious?</p>
<p><em>If you’re not interested in the detail, skip to the next section.</em></p>
<p>I started by installing Xcode and setting up a git repo. I know how to do that. (GitHub Copilot doesn’t work in Xcode by the way.)</p>
<p>To get going, I said to ChatGPT 4 something like:</p>
<ul>
<li>I’m building an iPhone app using SwiftUI. I have installed Xcode version X. Please walk me through creating a new iOS app with a single screen. The screen should be blank except for a line of text in the middle that says “Hello, World!”</li>
</ul>
<p>Then I followed the instructions.</p>
<p>There was lots of interaction like: <em>okay I’ve done step 1. I’m on step 2 but I can’t see the X, or I have the error Y, what should I do?</em></p>
<p>I know, from other coding, that I want to have my build working as early as possible.</p>
<p>My next question to ChatGPT was something like:</p>
<ul>
<li>Now I want to see my development app running on my phone as I work. Please walk me through that.</li>
</ul>
<p>Ok, now I’ve got a setup which means I can develop and I can test.</p>
<p>Now putting together the app itself is <em>not</em> about describing the overall app. I don’t want ChatGPT to be overfaced.</p>
<p>I worked in steps at this kind of resolution, making sure each step was complete before moving to the next:</p>
<ul>
<li>Okay now add two tabs at the bottom. The tabs are called Compass and Debug. Each has an icon. The first tab show should the Hello World screen, and the second tab should have the word “Debug” in the middle</li>
<li>We’ll work on the Debug screen. Add a section of text rows that simply say A, B, and C. Use standard iOS components. Ok, now add a label at the top. Make the text smaller. Make it capitalised.</li>
<li>Add two rows, latitude and longitude, based on the device location. Add the device heading.</li>
<li>Track the device motion and add rows for pitch, roll, and yaw.</li>
</ul>
<p>Then I found a Swift-compatible library to translate between galactic coordinates and relative coordinates. (Ultimately I need altitude and azimuth, a way of pointing at a position in the sky, based on the current time and location.) I’m using <a href="https://github.com/onekiloparsec/SwiftAA">SwiftAA</a>.</p>
<ul>
<li>I’m using SwiftAA. Please make a new Swift object that takes the current date and device location, and provides the azimuth and altitude of the galactic centre (I looked up the coordinates of the central black hole as a proxy)</li>
<li>Using the new GalacticCenter object, display azimuth and altitude in a new section on the debug screen.</li>
</ul>
<p>I retained the Debug tab in the shipped app so you can see.</p>
<p>So that’s all the astronomical stuff done.</p>
<p>You never want to give ChatGPT big goals where it has to figure out the way on its own. Then both of you will be confused. Intermediate stepping stones and being sure of your boots with each stride, that’s the way.</p>
<p>Now we build the rotating arrow:</p>
<ul>
<li>Ok now we’re on the Compass screen. Make a SceneKit view with a cube in the middle over the whole screen</li>
<li><em>(There was a whole lot of back and forth here to fix scrolling issues, ensuring the tabs were tappable, positioning some text over the bottom, and so on.)</em></li>
<li>Now let’s make a green arrow from an extruded rectangle and squashed pyramid. The arrow should point to the top of the screen</li>
<li>Break out the data from the Debug screen into a separate object so both tabs can use it</li>
<li>Assuming the phone is lying flat. Make the arrow point north</li>
<li>Rotate the arrow in 3D in real-time in response to the device orientation so that it always points north</li>
<li>Instead of pointing north, point the arrow at the altitude and azimuth of the galactic centre</li>
</ul>
<p>This now became pretty tricky because I had to learn about how to combine rotations. I barely know anything about quaternions, so there was a bunch to learn here.</p>
<p>ChatGPT, being a large language model but lacking embodiment, is awful at 3D maths and reference frames.</p>
<p>Finally I…</p>
<ul>
<li>Asked ChatGPT to walk me through the process of building the app using Xcode Cloud and distributing it on TestFlight</li>
<li>Shared the test app with friends to ask for their help with rotations.</li>
</ul>
<p>Galactic Compass is still pretty janky, to be sure.</p>
<p>But it ain’t bad for a collaboration between someone who can’t build apps and an AI that is barely a year old.</p>
<hr>
<h3>“An app can be a home-cooked meal”</h3>
<p>Ethan Mollick and a team of social scientists studied a group of management consultants using AI.</p>
<p><a href="https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged">The headline is that, yes, AI results in better work.</a></p>
<p>The fascinating buried result is that the biggest effect is felt by the <em>bottom-half skilled participants.</em></p>
<p>i.e. if you’re sub-skilled then you can use AI to drag you up to median.</p>
<p>Now, none of us have just one skill. Like most people, I have a mix.</p>
<p>But now I’m a reasonable engineer, an amateur designer, an ok systems thinker, ok at having ideas, and now a midwit <em>everything</em> when it comes to all the actual skilled tasks.</p>
<p>And the combination means I can bring ideas to life that simply wouldn’t be possible if I had to persuade a designer or engineer buddy to help me out. Being able to bring ideas to life means I can scaffold up to other ideas… and others…</p>
<p>Like this galactic compass.</p>
<p>Back in 2020, Robin Sloan said that <a href="https://www.robinsloan.com/notes/home-cooked-app/">an app can be a home-cooked meal</a>. It’s such a memorable perspective, and what we should aspire to from our software.</p>
<p>Now I’ve cooked a meal that anyone with an iPhone can download. Probably only a couple dozen people will want it, but I want it in my pocket, and I want to share it with my friends, and here we are.</p>
<p>And I can’t even cook!</p>
<p>But I know where the centre of the galaxy is, even so.</p>
<hr>
<p>Galactic Compass links:</p>
<p><a href="https://apps.apple.com/gb/app/galactic-compass/id6451314440">Download from the App Store.</a></p>
<p><a href="https://www.actsnotfacts.com/made/galactic-compass">Project page on Acts Not Facts.</a></p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build your own 3D printed Hexapod (110 pts)]]></title>
            <link>https://github.com/MakeYourPet/hexapod</link>
            <guid>39388269</guid>
            <pubDate>Thu, 15 Feb 2024 20:25:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/MakeYourPet/hexapod">https://github.com/MakeYourPet/hexapod</a>, See on <a href="https://news.ycombinator.com/item?id=39388269">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/MakeYourPet/hexapod/blob/main/Illustrations/yellow2.png"><img src="https://github.com/MakeYourPet/hexapod/raw/main/Illustrations/yellow2.png" height="300"></a></p>
<h2 tabindex="-1" dir="auto">Some quick links to get you started</h2>
<ul dir="auto">
<li>Watch the step by step build videos on my <a href="https://www.youtube.com/makeyourpet" rel="nofollow">YouTube channel</a>.<br></li>
<li>For build questions and to connect with the community join my <a href="https://discord.gg/vb8YWMfBuk" rel="nofollow">Discord server</a>.<br></li>
<li>A <a href="https://github.com/MakeYourPet/hexapod/blob/main/wiring-diagram-servo2040.png">wiring diagram</a> that you may find useful.<br></li>
<li>A fan-made <a href="https://docs.google.com/spreadsheets/d/1jLi3IdmLERsBDhjaqHxFGQgZul_3uq9oj55M1rFG8mY/edit#gid=0" rel="nofollow">parts list</a>. Also another fan-made <a href="https://docs.google.com/spreadsheets/d/1y--z7EeejWcb-8ooPaIFn3Hulu9dJOcoKyGoxGq8KI8/edit?usp=drivesdk" rel="nofollow">parts list</a>. And here is a <a href="https://github.com/LonelyGhost6/Public/blob/main/part-list.pdf">third one</a>. These are not meant to be a complete list of EVERYTHING that you need, but they cover most of the important and pricier stuff.<br></li>
<li>If you decide to use the Servo2040 board (highly recommended), find the <a href="https://github.com/EddieCarrera/chica-servo2040-simpleDriver/releases/download/v0.0.1/chica-servo2040_release.uf2">firmware</a> and the <a href="https://github.com/EddieCarrera/chica-servo2040-simpleDriver#loading-the-firmware-image">instructions on how to flash it</a> from Eddie's repository.<br></li>
</ul>
<h2 tabindex="-1" dir="auto">Illustrations</h2>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/MakeYourPet/hexapod/blob/main/Illustrations/front-view.png"><img src="https://github.com/MakeYourPet/hexapod/raw/main/Illustrations/front-view.png" height="200"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/MakeYourPet/hexapod/blob/main/Illustrations/back-view.png"><img src="https://github.com/MakeYourPet/hexapod/raw/main/Illustrations/back-view.png" height="200"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/MakeYourPet/hexapod/blob/main/Illustrations/leg-components.png"><img src="https://github.com/MakeYourPet/hexapod/raw/main/Illustrations/leg-components.png" height="200"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/MakeYourPet/hexapod/blob/main/Illustrations/tibia-components.png"><img src="https://github.com/MakeYourPet/hexapod/raw/main/Illustrations/tibia-components.png" height="200"></a>
</p>
<h2 tabindex="-1" dir="auto">About the STL files in this repository</h2>
<p dir="auto">Some of the parts have multiple versions with slight differences. But all of them are compatible and should work.<br>
Make sure to check all of them to pick the one that works for you before committing to the print.<br>
I use the latest version of each part in my own hexapod, which is the one with the higher number at the end of its name.</p>
<h2 tabindex="-1" dir="auto">Compatible fan-made 3D printable parts</h2>
<p dir="auto">Check out <a href="https://github.com/almelnz2005/hexapod">this</a> repository which contains modified (but compatible) versions of the original parts which uses metal horns, M3 screws and seperated components to make the parts more 3D printer friendly. This is especially helpful if you are printing with material other than PLA and have issues with supports or shrinking.</p>
<h2 tabindex="-1" dir="auto">Wiring Diagram</h2>
<ul dir="auto">
<li>Pimoroni Servo2040 (The newer, simpler, cheaper and recommended option):<br></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/MakeYourPet/hexapod/blob/main/wiring-diagram-servo2040.png"><img src="https://github.com/MakeYourPet/hexapod/raw/main/wiring-diagram-servo2040.png" height="300"></a></p>
<ul dir="auto">
<li>Pololu Maestro (The original, complicated, expensive and legacy option):<br></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/MakeYourPet/hexapod/blob/main/wiring-diagram-pololu.png"><img src="https://github.com/MakeYourPet/hexapod/raw/main/wiring-diagram-pololu.png" height="300"></a></p>
<h2 tabindex="-1" dir="auto">Electronic Component Layout</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/MakeYourPet/hexapod/blob/main/component-layout.jpg"><img src="https://github.com/MakeYourPet/hexapod/raw/main/component-layout.jpg" height="400"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple confirms it's breaking iPhone web apps in the EU on purpose (733 pts)]]></title>
            <link>https://techcrunch.com/2024/02/15/apple-confirms-its-breaking-iphone-web-apps-in-the-eu-on-purpose/</link>
            <guid>39388218</guid>
            <pubDate>Thu, 15 Feb 2024 20:22:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/02/15/apple-confirms-its-breaking-iphone-web-apps-in-the-eu-on-purpose/">https://techcrunch.com/2024/02/15/apple-confirms-its-breaking-iphone-web-apps-in-the-eu-on-purpose/</a>, See on <a href="https://news.ycombinator.com/item?id=39388218">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">Well, it turns out it’s not a bug that broke iPhone web apps, also known as Progressive Web Apps (PWAs), in the EU. Following developer complaints and press reports about how PWAs were no longer functional in the EU after installing the most recent iOS betas, Apple has updated its website to explain why. No surprise, the tech giant is blaming the new EU regulation, the Digital Markets Act, for the change, saying that the complexities involved with the DMA’s requirement to allow different browser engines is the root cause.</p>
<p>To catch you up, security researcher <a href="https://x.com/mysk_co/status/1753401847044288847?s=20">Tommy Mysk</a> and <a href="https://open-web-advocacy.org/blog/did-apple-just-break-web-apps-in-ios17.4-beta-eu/">Open Web Advocacy</a>, first noticed that PWAs <a href="https://www.macrumors.com/2024/02/08/ios-17-4-nerfs-web-apps-in-the-eu">had been demoted</a> to website shortcuts with the release of the second beta of iOS 17.4. Initially, it was unclear if this was a beta bug — stranger things have happened — or it was intended to undermine the functionality of PWAs in the E.U., a market where Apple is now being forced to allow alternative app stores, third-party payments, and alternative browser engines, among other things. In the betas, PWAs, which typically allow web apps to function and feel more like native iOS apps, were no longer working.&nbsp;Developers noticed that these web apps would open like a bookmark saved to your Home Screen, instead.</p>
<p>As <a href="https://www.macrumors.com/2024/02/08/ios-17-4-nerfs-web-apps-in-the-eu">MacRumors</a> pointed out at the time, that meant no “dedicated windowing, notifications, or long-term local storage.” iOS <a href="https://9to5mac.com/2023/02/16/iphone-web-app-new-features-ios-16-4/">16.4 also allowed PWAs to badge their icons</a> with notifications, as native apps could. iOS 17.4 beta users reported that when they opened a web app while running the iOS beta, the system would ask them if they wanted to open the app in Safari or cancel. The message indicates that the web app will “open in your default browser from now on,” it said. Afterward, users said they experienced issues with data loss, as a Safari website shortcut doesn’t offer local storage. Notifications also no longer worked.</p>
<p>Still, there was reason to be cautious about whether or not the change was intentional. Multiple staff at TechCrunch repeatedly asked Apple for comment but received no reply. (We had wanted to know if the comapny would confirm if this was a beta bug or an intentional change, and if the latter, what Apple’s reasoning for it was.) After the next beta release emerged, <a href="https://www.theverge.com/2024/2/14/24072764/apple-progressive-web-apps-eu-ios-17-4">The Verge</a>&nbsp;ran a report indicating that Apple <em>“appears to be”</em> breaking PWAs in the E.U., after also not likely getting a formal response from the tech giant.</p>
<p>Now, Apple has responded, in its way. Today, it updated its <a href="https://developer.apple.com/support/dma-and-apps-in-the-eu/">website detailing its DMA-related changes in the EU</a> to address the matter. In a new update, the company explains how it’s had to make so many changes to iOS to comply with the EU guidelines, that continued support for PWAs was simply off the table.</p>
<p>Traditionally, the iOS system provided support for Home Screen web apps by building directly on WebKit (Safari’s browser engine), and its security architecture, Apple said. That allowed web apps to align with the same security and privacy models as found in other native apps. But with the DMA, Apple is being forced to allow alternative browser engines. It argues that without the isolation and enforcement of the rules applied to WebKit-based web apps, malicious apps could be installed that could do things like read data from other web apps, or “gain access to a user’s camera, microphone or location without a user’s consent,” Apple said.</p>
<p>“Addressing the complex security and privacy concerns associated with web apps using alternative browser engines would require building an entirely new integration architecture that does not currently exist in iOS and was not practical to undertake given the other demands of the DMA and the very low user adoption of Home Screen web apps. And so, to comply with the DMA’s requirements, we had to remove the Home Screen web apps feature in the EU,” the website reads.</p>
<p>The company informs EU users they will be able to access websites from their Home Screen through bookmarks as a result of the change, confirming developers’ concerns that PWAs were effectively being disabled in the EU.</p>
<p>“We expect this change to affect a small number of users. Still, we regret any impact this change — that was made as part of the work to comply with the DMA — may have on developers of Home Screen web apps and our users,” Apple says.</p>
<p><a href="https://twitter.com/OpenWebAdvocacy/status/1757929731071373447">Critics</a> <a href="https://twitter.com/douglascamata/status/1755967835371716975">have</a> <a href="https://twitter.com/MyDaebakCafe/status/1755538810287350259">argued</a> that Apple’s desire to hold onto its power in the iOS app ecosystem was so strong that it would break web app functionality for users of its devices. Apple’s defenders, meanwhile, will probably argue that the company’s explanation is reasonable and aligns with Apple’s desire to keep iOS safe for its users. The truth, as it often is, is likely lies more in the middle.</p>
<p>Apple still has not responded to requests for comment.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Solar and battery to make up 81% of new US electric-generating capacity in 2024 (135 pts)]]></title>
            <link>https://www.eia.gov/todayinenergy/detail.php?id=61424</link>
            <guid>39387862</guid>
            <pubDate>Thu, 15 Feb 2024 20:02:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eia.gov/todayinenergy/detail.php?id=61424">https://www.eia.gov/todayinenergy/detail.php?id=61424</a>, See on <a href="https://news.ycombinator.com/item?id=39387862">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-type="inbrief">
													<p>
								In-brief analysis							</p>
											<p><span>February 15, 2024</span></p>
					
										












<p><img src="https://www.eia.gov/todayinenergy/images/2024.02.15/main.svg" alt="U.S. planned utility-scale electric-generating capacity additions"></p>
<hr>

<p>Developers and power plant owners plan to add 62.8 gigawatts (GW) of new utility-scale electric-generating capacity in 2024, according to our latest <a href="https://www.eia.gov/electricity/data/eia860m/"><em>Preliminary Monthly Electric Generator Inventory</em></a>. This addition would be 55% more added capacity than the 40.4 GW added in 2023 (the most since 2003) and points to a continued rise in industry activity. We expect solar to account for the largest share of new capacity in 2024, at 58%, followed by battery storage, at 23%.  </p>

     


<p><strong>Solar. </strong>We expect a record addition of utility-scale solar in 2024 if the scheduled 36.4 GW are added to the grid. This growth would almost double last year’s 18.4 GW increase, which was itself a record for annual utility-scale solar installation in the United States. As the effects of supply chain challenges and trade restrictions ease, solar continues to outpace capacity additions from other generating resources.</p>
  
<p>More than half of the new utility-scale solar capacity is planned for three states: Texas (35%), California (10%), and Florida (6%). Outside of these states, the Gemini solar facility in Nevada plans to begin operating in 2024.  With a planned photovoltaic capacity of 690 megawatts (MW) and battery storage of 380 MW, it is <a href="https://www.usgs.gov/centers/southwest-biological-science-center/science/gemini-solar-project">expected to be the largest solar project</a> in the United States when fully operational.  </p>

<p><strong>Battery storage. </strong>We also expect battery storage to set a record for annual capacity additions in 2024. We expect <a href="https://www.eia.gov/todayinenergy/detail.php?id=61202">U.S. battery storage capacity to nearly double in 2024</a> as developers report plans to add 14.3 GW of battery storage to the existing 15.5 GW this year. In 2023, 6.4 GW of new battery storage capacity was added to the U.S. grid, a 70% annual increase.</p>

<p>Texas, with an expected 6.4 GW, and California, with an expected 5.2 GW, will account for 82% of the new U.S. battery storage capacity. Developers have scheduled the Menifee Power Bank (460.0 MW) at the site of the former Inland Empire Energy Center natural gas-fired power plant in Riverside, California, to come on line in 2024. With the rise of solar and wind capacity in the United States, the demand for battery storage continues to increase. The Inflation Reduction Act (IRA) has also accelerated the development of energy storage by introducing investment tax credits (ITCs) for stand-alone storage. Prior to the IRA, batteries qualified for federal tax credits only if they were co-located with solar.  </p>

<p><strong>Wind. </strong>Operators report another 8.2 GW of wind capacity is scheduled to come on line in 2024. Following the record additions of more than 14.0 GW in both 2020 and 2021, wind capacity additions have slowed in the last two years.  </p>

<p>Two large offshore wind plants scheduled to come on line this year are the 800-MW Vineyard Wind 1 off the coast of Massachusetts and the 130-MW South Fork Wind off the coast of New York. South Fork Wind, which developers expected to begin commercial operation last year, is now scheduled to come on line in March 2024. </p>

<p><strong>Natural gas. </strong>For 2024, developers report 2.5 GW in planned natural gas capacity additions, the least new natural gas capacity in 25 years. Notably, in 2024, 79% of the natural gas capacity added is to come from simple-cycle, natural gas turbine (SCGT) plants. This year will be the first time since 2001 that combined-cycle capacity was not the predominant natural gas-fired technology. <a href="https://www.eia.gov/todayinenergy/detail.php?id=55680">SCGT power plants provide effective grid support</a> because they can start up, ramp up, and ramp down relatively quickly.  </p>

<p><strong>Nuclear. </strong>Start-up of the fourth reactor (1.1 GW) at Georgia’s Vogtle nuclear power plant, originally scheduled for last year, has moved to March 2024. Vogtle Unit 3 began commercial operation at the end of July last year.</p>

<p><img src="https://www.eia.gov/todayinenergy/images/2024.02.15/chart2.svg" alt="planned 2023 U.S. utility-scale electric generator additions"></p>
<hr>

<p><strong>Principal contributor: </strong>Suparna Ray<br><strong>Data visualization: </strong>Suparna Ray, Kristen Tsai</p>






										
										
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building an LLM from Scratch: Automatic Differentiation (290 pts)]]></title>
            <link>https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/post.html</link>
            <guid>39387850</guid>
            <pubDate>Thu, 15 Feb 2024 20:01:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/post.html">https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/post.html</a>, See on <a href="https://news.ycombinator.com/item?id=39387850">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">





<div id="faa21911" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="1">
<details>
<summary>Setup</summary>
<div id="cb1"><pre><code><span id="cb1-1"><span>from</span> typing <span>import</span> Any, Optional, List</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span>import</span> networkx <span>as</span> nx</span></code></pre></div>
</details>
</div>
<section id="llm-from-scratch-automatic-differentiation">
<h2 data-anchor-id="llm-from-scratch-automatic-differentiation">LLM from scratch: Automatic Differentiation</h2>
<p>I’m building a modern language model with all the bells and whistles completely from scratch: from vanilla python to functional coding assistant. Borrowing (shamelessly stealing) from computer games, I’ve built a tech tree of everything that I think I’ll need to implement to get a fully functional language model. If you think anything is missing, <a href="mailto:bclarkson-code@proton.me">please let me know</a>:</p>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/tech_tree_post_1.png" alt="The LLM from scratch tech tree" width="700"></p>
<figcaption>The LLM from scratch tech tree</figcaption>
</figure>
</div>
<p>Before we can move onto building modern features like <a href="https://arxiv.org/abs/2104.09864">Rotary Positional Encodings</a>, we first need to figure out how to differentiate with a computer. The backpropagation algorithm that underpins the entire field of Deep Learning requires the ability to differentiate the outputs of neural networks with respect to (wrt) their inputs. In this post, we’ll go from nothing to an (admittedly very limited) automatic differentiation library that can differentiate arbitrary functions of scalar values.</p>
<p>This one algorithm will form the core of our deep learning library that, eventually, will include everything we need to train a language model.</p>
</section>
<section id="creating-a-tensor">
<h2 data-anchor-id="creating-a-tensor">Creating a tensor</h2>
<p>We can’t do any differentiation if we don’t have any numbers to differentiate. We’ll want to add some extra functionality that is in standard <code>float</code> types so we’ll need to create our own. Let’s call it a <code>Tensor</code>.</p>
<div id="3c2dc0d6" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="2"><pre><code><span id="cb2-1"><span>class</span> Tensor:</span>
<span id="cb2-2">    <span>"""</span></span>
<span id="cb2-3"><span>    Just a number (for now)</span></span>
<span id="cb2-4"><span>    """</span></span>
<span id="cb2-5"></span>
<span id="cb2-6">    value: <span>float</span></span>
<span id="cb2-7"></span>
<span id="cb2-8">    <span>def</span> <span>__init__</span>(<span>self</span>, value: <span>float</span>):</span>
<span id="cb2-9">        <span>self</span>.value <span>=</span> value</span>
<span id="cb2-10"></span>
<span id="cb2-11">    <span>def</span> <span>__repr__</span>(<span>self</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb2-12">        <span>"""</span></span>
<span id="cb2-13"><span>        Create a printable string representation of this</span></span>
<span id="cb2-14"><span>        object</span></span>
<span id="cb2-15"></span>
<span id="cb2-16"><span>        This function gets called when you pass a Tensor to print</span></span>
<span id="cb2-17"></span>
<span id="cb2-18"><span>        Without this function:</span></span>
<span id="cb2-19"><span>        &gt;&gt;&gt; print(Tensor(5))</span></span>
<span id="cb2-20"><span>        &lt;__main__.Tensor at 0x104fd1950&gt;</span></span>
<span id="cb2-21"></span>
<span id="cb2-22"><span>        With this function:</span></span>
<span id="cb2-23"><span>        &gt;&gt;&gt; print(Tensor(5))</span></span>
<span id="cb2-24"><span>        Tensor(5)</span></span>
<span id="cb2-25"><span>        """</span></span>
<span id="cb2-26">        <span>return</span> <span>f"Tensor(</span><span>{</span><span>self</span><span>.</span>value<span>}</span><span>)"</span></span>
<span id="cb2-27"></span>
<span id="cb2-28"></span>
<span id="cb2-29"><span># try it out</span></span>
<span id="cb2-30">Tensor(<span>5</span>)</span></code></pre></div>
<p>Next we’ll need some simple operations we want to perform: addition, subtraction and multiplication.</p>
<div id="69ba409d" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="3"><pre><code><span id="cb4-1"><span>def</span> _add(a: Tensor, b: Tensor):</span>
<span id="cb4-2">    <span>"""</span></span>
<span id="cb4-3"><span>    Add two tensors</span></span>
<span id="cb4-4"><span>    """</span></span>
<span id="cb4-5">    <span>return</span> Tensor(a.value <span>+</span> b.value)</span>
<span id="cb4-6"></span>
<span id="cb4-7"></span>
<span id="cb4-8"><span>def</span> _sub(a: Tensor, b: Tensor):</span>
<span id="cb4-9">    <span>"""</span></span>
<span id="cb4-10"><span>    Subtract tensor b from tensor a</span></span>
<span id="cb4-11"><span>    """</span></span>
<span id="cb4-12">    <span>return</span> Tensor(a.value <span>-</span> b.value)</span>
<span id="cb4-13"></span>
<span id="cb4-14"></span>
<span id="cb4-15"><span>def</span> _mul(a: Tensor, b: Tensor):</span>
<span id="cb4-16">    <span>"""</span></span>
<span id="cb4-17"><span>    Multiply two tensors</span></span>
<span id="cb4-18"><span>    """</span></span>
<span id="cb4-19">    <span>return</span> Tensor(a.value <span>*</span> b.value)</span></code></pre></div>
<p>We can use use our operations as follows:</p>
<div id="55858d5d" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="4">
<div id="cb5"><pre><code><span id="cb5-1"><span>def</span> test(got: Any, want: Any):</span>
<span id="cb5-2">    <span>"""</span></span>
<span id="cb5-3"><span>    Check that two objects are equal to each other</span></span>
<span id="cb5-4"><span>    """</span></span>
<span id="cb5-5">    indicator <span>=</span> <span>"✅"</span> <span>if</span> want <span>==</span> got <span>else</span> <span>"❌"</span></span>
<span id="cb5-6">    <span>print</span>(<span>f"</span><span>{</span>indicator<span>}</span><span> - Want: </span><span>{</span>want<span>}</span><span>, Got: </span><span>{</span>got<span>}</span><span>"</span>)</span>
<span id="cb5-7"></span>
<span id="cb5-8"></span>
<span id="cb5-9">a <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb5-10">b <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb5-11"></span>
<span id="cb5-12"></span>
<span id="cb5-13">test(_add(a, b).value, <span>7</span>)</span>
<span id="cb5-14">test(_sub(a, b).value, <span>-</span><span>1</span>)</span>
<span id="cb5-15">test(_mul(a, b).value, <span>12</span>)</span></code></pre></div>
<div>
<pre><code>✅ - Want: 7, Got: 7
✅ - Want: -1, Got: -1
✅ - Want: 12, Got: 12</code></pre>
</div>
</div>
</section>
<section id="scalar-derivatives">
<h2 data-anchor-id="scalar-derivatives">Scalar derivatives</h2>
<p>Diving straight into differentiating matrices sounds too hard so let’s start with something simpler: differentiating scalars. The simplest scalar derivative I can think of is differentiating a tensor with respect to itself: <span>\[\frac{dx}{dx} = 1\]</span></p>
<p>A more interesting case is the derivative of two tensors added together (note we are using partial derivatives because our function has multiple inputs): <span>\[f(x, y) = x + y\]</span> <span>\[\frac{\partial f}{\partial x} = 1\]</span> <span>\[\frac{\partial f}{\partial y} = 1\]</span></p>
<p>We can do a similar thing for multiplication and subtraction</p>
<table>
<colgroup>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th><span>\(f(x, y)\)</span></th>
<th><span>\(\frac{\partial f}{\partial x}\)</span></th>
<th><span>\(\frac{\partial f}{\partial y}\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td><span>\(x + y\)</span></td>
<td><span>\(1\)</span></td>
<td><span>\(1\)</span></td>
</tr>
<tr>
<td><span>\(x - y\)</span></td>
<td><span>\(1\)</span></td>
<td><span>\(-1\)</span></td>
</tr>
<tr>
<td><span>\(x \times y\)</span></td>
<td><span>\(y\)</span></td>
<td><span>\(x\)</span></td>
</tr>
</tbody>
</table>
<p>Now that we’ve worked out these derivatives mathematically, the next step is to convert them into code. In the table above, when we make a tensor by combining two tensors with an operation, the derivative only ever depends on the inputs and the operation. There is no “hidden state”.</p>
<p>This means that the only information we need to store is the inputs to an operation and a function to calculate the derivative wrt each input. With this, we should be able to differentiate any binary function wrt its inputs. A good place to store this information is in the tensor that is produced by the operation.</p>
<p>We’ll add some new attributes to our <code>Tensor</code>: <code>args</code> and <code>local_derivatives</code>. If the tensor is the output of an operation, then <code>args</code> will store the arguments to the operation and <code>local_derivatives</code> will store the derivatives wrt each input. We’re calling it <code>local_derivatives</code> to avoid confusion when we start nesting functions.</p>
<p>Once we’ve calculated the derivative (from our <code>args</code> and <code>local_derivatives</code>) we’ll need to store it. It turns out that the neatest place to put this is in the tensor that the output is being differentiated wrt. We’ll call this <code>derivative</code>.</p>
<div id="2df2b7ce" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="5"><pre><code><span id="cb7-1"><span>class</span> Tensor:</span>
<span id="cb7-2">    <span>"""</span></span>
<span id="cb7-3"><span>    A number that can be differentiated</span></span>
<span id="cb7-4"><span>    """</span></span>
<span id="cb7-5"></span>
<span id="cb7-6">    <span># If the tensor was made by an operation, the operation arguments</span></span>
<span id="cb7-7">    <span># are stored in args</span></span>
<span id="cb7-8">    args: <span>tuple</span>[<span>"Tensor"</span>] <span>=</span> ()</span>
<span id="cb7-9">    <span># If the tensor was made by an operation, the derivatives wrt</span></span>
<span id="cb7-10">    <span># operation inputs are stored in derivatives</span></span>
<span id="cb7-11">    local_derivatives: <span>tuple</span>[<span>"Tensor"</span>] <span>=</span> ()</span>
<span id="cb7-12">    <span># The derivative we have calculated</span></span>
<span id="cb7-13">    derivative: Optional[<span>"Tensor"</span>] <span>=</span> <span>None</span></span>
<span id="cb7-14"></span>
<span id="cb7-15">    <span>def</span> <span>__init__</span>(<span>self</span>, value: <span>float</span>):</span>
<span id="cb7-16">        <span>self</span>.value <span>=</span> value</span>
<span id="cb7-17"></span>
<span id="cb7-18">    <span>def</span> <span>__repr__</span>(<span>self</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb7-19">        <span>"""</span></span>
<span id="cb7-20"><span>        Create a printable string representation of this</span></span>
<span id="cb7-21"><span>        object</span></span>
<span id="cb7-22"></span>
<span id="cb7-23"><span>        This function gets called when you pass a Tensor to print</span></span>
<span id="cb7-24"></span>
<span id="cb7-25"><span>        Without this function:</span></span>
<span id="cb7-26"><span>        &gt;&gt;&gt; print(Tensor(5))</span></span>
<span id="cb7-27"><span>        &lt;__main__.Tensor at 0x104fd1950&gt;</span></span>
<span id="cb7-28"></span>
<span id="cb7-29"><span>        With this function:</span></span>
<span id="cb7-30"><span>        &gt;&gt;&gt; print(Tensor(5))</span></span>
<span id="cb7-31"><span>        Tensor(5)</span></span>
<span id="cb7-32"><span>        """</span></span>
<span id="cb7-33">        <span>return</span> <span>f"Tensor(</span><span>{</span><span>self</span><span>.</span>value<span>}</span><span>)"</span></span></code></pre></div>
<p>For example, if we have</p>
<div id="16c996f7" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="6"><pre><code><span id="cb8-1">a <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb8-2">b <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb8-3"></span>
<span id="cb8-4">output <span>=</span> _mul(a, b)</span></code></pre></div>
<p>Then <code>output.args</code> and <code>output.local_derivatives</code> should be set to:</p>
<div id="cb9"><pre><code><span id="cb9-1">output.args <span>==</span> (Tensor(<span>3</span>), Tensor(<span>4</span>))</span>
<span id="cb9-2">output.derivatives <span>==</span> (</span>
<span id="cb9-3">    b,  <span># derivative of output wrt a is b</span></span>
<span id="cb9-4">    a,  <span># derivative of output wrt b is a</span></span>
<span id="cb9-5">)</span></code></pre></div>
<p>Once we have actually computed the derivatives, then the derivative of <code>output</code> wrt <code>a</code> will be stored in <code>a.derivative</code> and should be equal to <code>b</code> (which is 4 in this case).</p>
<p>We know that we’ve done everything right once these tests pass:</p>
<div id="615dc0ba" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="7">
<div id="cb10"><pre><code><span id="cb10-1">a <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb10-2">b <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb10-3"></span>
<span id="cb10-4">output <span>=</span> _mul(a, b)</span>
<span id="cb10-5"></span>
<span id="cb10-6"><span># </span><span>TODO</span><span>: differentiate here</span></span>
<span id="cb10-7"></span>
<span id="cb10-8">test(got<span>=</span>output.args, want<span>=</span>(a, b))</span>
<span id="cb10-9">test(got<span>=</span>output.local_derivatives, want<span>=</span>(b, a))</span>
<span id="cb10-10">test(got<span>=</span>a.derivative, want<span>=</span>b)</span>
<span id="cb10-11">test(got<span>=</span>b.derivative, want<span>=</span>a)</span></code></pre></div>
<div>
<pre><code>❌ - Want: (Tensor(3), Tensor(4)), Got: ()
❌ - Want: (Tensor(4), Tensor(3)), Got: ()
❌ - Want: Tensor(4), Got: None
❌ - Want: Tensor(3), Got: None</code></pre>
</div>
</div>
<p>First, let’s add a function to our <code>Tensor</code> that will actually calculate the derivatives for each of the function arguments. Pytorch calls this function <code>backward</code> so we’ll do the same.</p>
<div id="18dcfc02" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="8"><pre><code><span id="cb12-1"><span>class</span> Tensor:</span>
<span id="cb12-2">    <span>"""</span></span>
<span id="cb12-3"><span>    A number that can be differentiated</span></span>
<span id="cb12-4"><span>    """</span></span>
<span id="cb12-5"></span>
<span id="cb12-6">    <span># If the tensor was made by an operation, the operation arguments</span></span>
<span id="cb12-7">    <span># are stored in args</span></span>
<span id="cb12-8">    args: <span>tuple</span>[<span>"Tensor"</span>] <span>=</span> ()</span>
<span id="cb12-9">    <span># If the tensor was made by an operation, the derivatives wrt</span></span>
<span id="cb12-10">    <span># operation inputs are stored in</span></span>
<span id="cb12-11">    local_derivatives: <span>tuple</span>[<span>"Tensor"</span>] <span>=</span> ()</span>
<span id="cb12-12">    <span># The derivative we have calculated</span></span>
<span id="cb12-13">    derivative: Optional[<span>"Tensor"</span>] <span>=</span> <span>None</span></span>
<span id="cb12-14"></span>
<span id="cb12-15">    <span># optionally give this tensor a name</span></span>
<span id="cb12-16">    name: Optional[<span>str</span>] <span>=</span> <span>None</span></span>
<span id="cb12-17">    <span># Later, we'll want to record the path we followed to get</span></span>
<span id="cb12-18">    <span># to this tensor and some operations we did along the way</span></span>
<span id="cb12-19">    <span># don't worry about these for now</span></span>
<span id="cb12-20">    paths: List[Tensor] <span>=</span> <span>None</span></span>
<span id="cb12-21">    chains: List[Tensor] <span>=</span> <span>None</span></span>
<span id="cb12-22"></span>
<span id="cb12-23">    <span>def</span> <span>__init__</span>(<span>self</span>, value: <span>float</span>):</span>
<span id="cb12-24">        <span>self</span>.value <span>=</span> value</span>
<span id="cb12-25"></span>
<span id="cb12-26">    <span>def</span> backward(<span>self</span>):</span>
<span id="cb12-27">        <span>if</span> <span>self</span>.args <span>is</span> <span>None</span> <span>or</span> <span>self</span>.local_derivatives <span>is</span> <span>None</span>:</span>
<span id="cb12-28">            <span>raise</span> <span>ValueError</span>(</span>
<span id="cb12-29">                <span>"Cannot differentiate a Tensor that is not a function of other Tensors"</span></span>
<span id="cb12-30">            )</span>
<span id="cb12-31"></span>
<span id="cb12-32">        <span>for</span> arg, derivative <span>in</span> <span>zip</span>(<span>self</span>.args, <span>self</span>.local_derivatives):</span>
<span id="cb12-33">            arg.derivative <span>=</span> derivative</span>
<span id="cb12-34"></span>
<span id="cb12-35">    <span>def</span> <span>__repr__</span>(<span>self</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb12-36">        <span>"""</span></span>
<span id="cb12-37"><span>        Create a printable string representation of this</span></span>
<span id="cb12-38"><span>        object</span></span>
<span id="cb12-39"></span>
<span id="cb12-40"><span>        This function gets called when you pass a Tensor to print</span></span>
<span id="cb12-41"></span>
<span id="cb12-42"><span>        Without this function:</span></span>
<span id="cb12-43"><span>        &gt;&gt;&gt; print(Tensor(5))</span></span>
<span id="cb12-44"><span>        &lt;__main__.Tensor at 0x104fd1950&gt;</span></span>
<span id="cb12-45"></span>
<span id="cb12-46"><span>        With this function:</span></span>
<span id="cb12-47"><span>        &gt;&gt;&gt; print(Tensor(5))</span></span>
<span id="cb12-48"><span>        Tensor(5)</span></span>
<span id="cb12-49"><span>        """</span></span>
<span id="cb12-50">        <span>return</span> <span>f"Tensor(</span><span>{</span><span>self</span><span>.</span>value<span>}</span><span>)"</span></span></code></pre></div>
<p>This only works if we also store the arguments and derivatives in the output tensors of operations</p>
<div id="0f77b5c2" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="9"><pre><code><span id="cb13-1"><span>def</span> _add(a: Tensor, b: Tensor):</span>
<span id="cb13-2">    <span>"""</span></span>
<span id="cb13-3"><span>    Add two tensors</span></span>
<span id="cb13-4"><span>    """</span></span>
<span id="cb13-5">    result <span>=</span> Tensor(a.value <span>+</span> b.value)</span>
<span id="cb13-6">    result.local_derivatives <span>=</span> (Tensor(<span>1</span>), Tensor(<span>1</span>))</span>
<span id="cb13-7">    result.args <span>=</span> (a, b)</span>
<span id="cb13-8">    <span>return</span> result</span>
<span id="cb13-9"></span>
<span id="cb13-10"></span>
<span id="cb13-11"><span>def</span> _sub(a: Tensor, b: Tensor):</span>
<span id="cb13-12">    <span>"""</span></span>
<span id="cb13-13"><span>    Subtract tensor b from a</span></span>
<span id="cb13-14"><span>    """</span></span>
<span id="cb13-15">    result <span>=</span> Tensor(a.value <span>-</span> b.value)</span>
<span id="cb13-16">    result.local_derivatives <span>=</span> (Tensor(<span>1</span>), Tensor(<span>-</span><span>1</span>))</span>
<span id="cb13-17">    result.args <span>=</span> (a, b)</span>
<span id="cb13-18">    <span>return</span> result</span>
<span id="cb13-19"></span>
<span id="cb13-20"></span>
<span id="cb13-21"><span>def</span> _mul(a: Tensor, b: Tensor):</span>
<span id="cb13-22">    <span>"""</span></span>
<span id="cb13-23"><span>    Multiply two tensors</span></span>
<span id="cb13-24"><span>    """</span></span>
<span id="cb13-25">    result <span>=</span> Tensor(a.value <span>*</span> b.value)</span>
<span id="cb13-26">    result.local_derivatives <span>=</span> (b, a)</span>
<span id="cb13-27">    result.args <span>=</span> (a, b)</span>
<span id="cb13-28">    <span>return</span> result</span></code></pre></div>
<p>Let’s re-run our tests and see if it works</p>
<div id="426bc097" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="10">
<div id="cb14"><pre><code><span id="cb14-1">a <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb14-2">b <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb14-3"></span>
<span id="cb14-4">output <span>=</span> _mul(a, b)</span>
<span id="cb14-5"></span>
<span id="cb14-6">output.backward()</span>
<span id="cb14-7"></span>
<span id="cb14-8">test(got<span>=</span>output.args, want<span>=</span>(a, b))</span>
<span id="cb14-9">test(got<span>=</span>output.local_derivatives, want<span>=</span>(b, a))</span>
<span id="cb14-10">test(a.derivative, b)</span>
<span id="cb14-11">test(b.derivative, a)</span></code></pre></div>
<div>
<pre><code>✅ - Want: (Tensor(3), Tensor(4)), Got: (Tensor(3), Tensor(4))
✅ - Want: (Tensor(4), Tensor(3)), Got: (Tensor(4), Tensor(3))
✅ - Want: Tensor(4), Got: Tensor(4)
✅ - Want: Tensor(3), Got: Tensor(3)</code></pre>
</div>
</div>
<p>So far so good, let’s try nesting operations.</p>
<div id="e14634fb" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="11">
<div id="cb16"><pre><code><span id="cb16-1">a <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb16-2">b <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb16-3"></span>
<span id="cb16-4">output_1 <span>=</span> _mul(a, b)</span>
<span id="cb16-5"><span># z = a + (a * b)</span></span>
<span id="cb16-6">output_2 <span>=</span> _add(a, output_1)</span>
<span id="cb16-7"></span>
<span id="cb16-8">output_2.backward()</span>
<span id="cb16-9"></span>
<span id="cb16-10"><span># should get</span></span>
<span id="cb16-11"><span># dz/db = 0 + a = a</span></span>
<span id="cb16-12">test(b.derivative, a)</span></code></pre></div>
<div>
<pre><code>❌ - Want: Tensor(3), Got: None</code></pre>
</div>
</div>
<p>Something has gone wrong.</p>
<p>We should have got <code>a</code> as the derivative for <code>b</code> but we got <code>0</code> instead. Looking through the <code>.backward()</code> function, the issue is pretty clear: we haven’t thought about nested functions. To get this example working, we’ll need to figure out how to calculate derivatives through multiple functions instead of just one.</p>
</section>
<section id="chaining-functions-together">
<h2 data-anchor-id="chaining-functions-together">Chaining Functions Together</h2>
<p>To calculate derivatives of nested functions, we can use a rule from calculus: The Chain Rule.</p>
<p>For a variable <span>\(z\)</span> generated by nested functions <span>\(f\)</span> and <span>\(g\)</span> such that <span>\[z = f(g(x))\]</span></p>
<p>Then the derivative of <span>\(z\)</span> wrt <span>\(x\)</span> is: <span>\[\frac{\partial z}{\partial x} = \frac{\partial f(u)}{\partial u} \frac{\partial g(x)}{\partial x}\]</span></p>
<p>Here, <span>\(u\)</span> is a dummy variable. <span>\(\frac{\partial f(u)}{\partial u}\)</span> means the derivative of <span>\(f\)</span> wrt its input.</p>
<p>For example, if</p>
<p><span>\[f(x) = g(x)^2\]</span> Then we can define <span>\(u=g(x)\)</span> and rewrite <span>\(f\)</span> in terms of u <span>\[f(u) = u^2 \implies \frac{\partial f(u)}{\partial u} = 2u = 2 g(x)\]</span></p>
<section id="multiple-variables">
<h3 data-anchor-id="multiple-variables">Multiple Variables</h3>
<p>The chain rule works as you might expect for functions of multiple variables. When differentiating wrt a variable, we can treat the other variables as constant and differentiate as normal <span>\[z = f(g(x), h(y))\]</span></p>
<p><span>\[\frac{\partial z}{\partial x} = \frac{\partial f(u)}{\partial u} \frac{\partial g(x)}{\partial x}\]</span> <span>\[\frac{\partial z}{\partial y} = \frac{\partial f(u)}{\partial u} \frac{\partial h(y)}{\partial y}\]</span></p>
<p>If we have different functions that take the same input, we differentiate each of them individually and then add them together</p>
<p><span>\[z = f(g(x), h(x))\]</span></p>
<p>We get <span>\[\frac{\partial z}{\partial x} = \frac{\partial f(u)}{\partial u}\frac{\partial g(x)}{\partial x} + \frac{\partial f(u)}{\partial u}\frac{\partial h(x)}{\partial x}\]</span></p>
</section>
<section id="more-than-2-functions">
<h3 data-anchor-id="more-than-2-functions">More than 2 functions</h3>
<p>If we chain 3 functions together, we still just multiply the derivatives for each function together:</p>
<p><span>\[\frac{\partial z}{\partial x} = \frac{\partial f(u)}{\partial u} \frac{\partial g(x)}{\partial x} = \frac{\partial f(u)}{\partial u} \frac{\partial g(u)}{\partial u}\frac{\partial h(x)}{\partial x}\]</span></p>
<p>And this generalises to any amount of nesting</p>
<p><span>\[z = f_1(f_2(....f_{n-1}(f_n(x))...)) \]</span> <span>\(\implies \frac{\partial z}{\partial x} = \frac{\partial f_1(u)}{\partial u}\frac{\partial f_2(u)}{\partial u}...\frac{\partial f_{n-1}(u)}{\partial u}\frac{\partial f_{n}(x)}{\partial x}\)</span>$</p>
</section>
<section id="a-picture-is-worth-a-thousand-equations">
<h3 data-anchor-id="a-picture-is-worth-a-thousand-equations">A picture is worth a thousand equations</h3>
<p>As you probably noticed, the maths is starting to get quite dense. When we start working with neural networks, we can easily get 100s or 1000s of functions deep so to get a handle on things, we’ll need a different strategy. Helpfully, there is one: turning it into a graph.</p>
<p>We can start with some rules:</p>
<blockquote>
<p>Variables are represented with circles and operations are represented with boxes</p>
</blockquote>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/variable_and_box.png" alt="A variable as a circle and an operation as a box"></p>
</figure>
</div>
<blockquote>
<p>Inputs to an operation are represented with arrows that point to the operation box. Outputs point away.</p>
</blockquote>
<p>For example, here is the diagram for <span>\(z = mx\)</span></p>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/z_eq_mx.png" alt="The operation z = mx"></p>
</figure>
</div>
<p>And that’s it! All of the equations we’ll be working with can be represented graphically using these simple rules. To try it out, let’s draw the diagram for a more complex formula:</p>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/square_error.png" alt="A diagram of the square error of a linear regression"></p>
</figure>
</div>
<p>This is an example of a structure called a graph (also called a network). A lot of problem in computer science get much easier if you can represent them with a graph and this is no exception.</p>
<p>The real power of these diagrams is that they can also help us with our derivatives. Take <span>\[y = mx + p = \texttt{add}(p, \texttt{mul}(m ,x)).\]</span></p>
<p>From before, we can find its derivatives by differentiating each operation wrt its inputs and multiplying the results together. In this case, we get: <span>\[\frac{\partial y}{\partial p} = \frac{\partial \texttt{add}(u_1, u_2)}{\partial u_1} = 1\]</span> <span>\[\frac{\partial y}{\partial m} = \frac{\partial \texttt{add}(u_1, u_2)}{\partial u_2}\frac{\partial \texttt{mul}(u_1, u_2)}{\partial u_2} = 1 \times x = x\]</span> <span>\[\frac{\partial y}{\partial x} = \frac{\partial \texttt{add}(u_1, u_2)}{\partial u_2}\frac{\partial \texttt{mul}(u_1, u_2)}{\partial u_1} = 1 \times m = m\]</span></p>
<p>We can also graph it like this:</p>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/y_eq_mx_plus_p_labelled.png" alt="a graph of y = mx + p"></p>
</figure>
</div>
<p>If you imagine walking from <span>\(y\)</span> to each of the inputs, you might notice a similarity between the edges you pass through and the equations above. If you walk from <span>\(y\)</span> to <span>\(x\)</span>, you’ll pass through <code>a-&gt;c-&gt;d</code>. Similarly, if you walk from <span>\(y\)</span> to <span>\(m\)</span>, you’ll pass through <code>a-&gt;d-&gt;e</code>. Notice that both paths go through <code>c</code>, the edge coming out of <code>add</code> that corresponds to the input <span>\(u_2\)</span>. Also, both equations include the term <span>\(\frac{\partial \texttt{add}(u_1, u_2)}{\partial u_2}\)</span>.</p>
<p>If I rename the edges as follows:</p>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/y_eq_mx_plus_p_deriv.png" alt="y = mx + p with each edge given a letter"></p>
</figure>
</div>
<p>We can see that going from <span>\(y\)</span> to <span>\(x\)</span>, we pass through <span>\(1\)</span>, <span>\(\frac{\partial \texttt{add}(u_1, u_2)}{\partial u_2}\)</span> and <span>\(\frac{\partial \texttt{mul}(u_1, u_2)}{\partial u_1}\)</span>. If we multiply these together, we get exactly <span>\(\frac{\partial \texttt{add}(u_1, u_2)}{\partial u_2}\frac{\partial \texttt{mul}(u_1, u_2)}{\partial u_1} = \frac{\partial y}{\partial x}\)</span>!</p>
<p>It turns out that this rule works in general:</p>
<blockquote>
<p>If we have some operation <span>\(\texttt{op}(u_1, u_2, ..., u_n)\)</span>, we should label the edge corresponding to input <span>\(u_i\)</span> with <span>\(\frac{\partial \texttt{op}(u_1, u_2, ..., u_n)}{\partial u_i}\)</span></p>
</blockquote>
<p>Then, if we want to find the derivative of the output node wrt any of the inputs,</p>
<blockquote>
<p>The derivative of an output variable wrt one of the input variables can be found by traversing the graph from the output to the input and multiplying together the derivatives for every edge on the path</p>
</blockquote>
<p>To cover every edge case, there are some extra details</p>
<blockquote>
<p>If a graph contains multiple paths from the output to an input, then the derivative is the sum of the products for each path</p>
</blockquote>
<p>This comes from the case we saw earlier where when we have different functions that have the same input we have to add their derivative chains together.</p>
<blockquote>
<p>If an edge is not the input to any function, its derivative is 1</p>
</blockquote>
<p>This covers the edge that leads from the final operation to the output. You can think of the edge having the derivative <span>\(\frac{\partial y}{\partial y}=1\)</span></p>
<p>And that’s it! Let’s try it out with <span>\(z = (x + c)x\)</span>:</p>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/images/z_eq_xx_plus_xc.png" alt="A graph of z = (x+c)x with edges annotated with derivatives"></p>
</figure>
</div>
<p>Here, instead of writing the formulae for each derivative, I have gone ahead and calculated their actual values. Instead of just figuring out the formulae for a derivative, we want to calculate its value when we plug in our input parameters.</p>
<p>All that remains is to multiply the local derivatives together along each path. We’ll call the product of derivatives along a single path a chain (after the chain rule)</p>
<p>We can get from <span>\(z\)</span> to <span>\(x\)</span> via the green path and the red path. Following these paths, we get: <span>\[\text{red path} = 1 \times (x + c) = x + c\]</span> Along the green path we get: <span>\[\text{green path} = 1 \times x \times 1 = x\]</span></p>
<p>Adding these together, we get <span>\((x+c) + x = 2x + c\)</span></p>
<p>If we work out the derivative algebraically:</p>
<p><span>\[\frac{\partial z}{\partial x} = \frac{\partial}{\partial x}((x+c)x) = \frac{\partial}{\partial x}(x^2 + cx) = \frac{\partial x^2}{\partial x} + c\frac{\partial x}{\partial x} = 2x + c\]</span></p>
<p>We can see that it seems to work! Calculating <span>\(\frac{\partial z}{\partial c}\)</span> is left as an exercise for the reader (I’ve always wanted to say that).</p>
<p>To summarise, we have invented the following algorithm for calculating of a variable wrt its inputs:</p>
<ol type="1">
<li>Turn the equation into a graph</li>
<li>Label each edge with the appropriate derivative</li>
<li>Find every path from the output to the input variable you care about</li>
<li>Follow each path and multiply the derivatives you pass through</li>
<li>Add together the results for each path</li>
</ol>
<p>Now that we have an algorithm in pictures and words, let’s turn it into code.</p>
</section>
<section id="the-algorithm">
<h3 data-anchor-id="the-algorithm">The Algorithm™</h3>
<p>Surprisingly, we have actually already converted our functions into graphs. If you recall, when we generate a tensor from an operation, we record the inputs to the operation in the output tensor (in <code>.args</code>). We also stored the functions to calculate derivatives for each of the inputs in <code>.local_derivatives</code> which means that we know both the destination and derivative for every edge that points to a given node. This means that we’ve already completed steps 1 and 2.</p>
<p>The next challenge is to find all paths from the tensor we want to differentiate to the input tensors that created it. Because none of our operations are self referential (outputs are never fed back in as inputs), and all of our edges have a direction, our graph of operations is a directed acyclic graph or DAG. The property of the graph having no cycles means that we can find all paths to every parameter pretty easily with a Breadth First Search (or Depth First Search but BFS makes some optimisations easier as we’ll see in part 2).</p>
<p>To try it out, let’s recreate that giant graph we made earlier. We can do this by first calculating <span>\(L\)</span> from the inputs</p>
<div id="4c65eba1" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="12"><pre><code><span id="cb18-1">y <span>=</span> Tensor(<span>1</span>)</span>
<span id="cb18-2">m <span>=</span> Tensor(<span>2</span>)</span>
<span id="cb18-3">x <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb18-4">c <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb18-5"></span>
<span id="cb18-6"><span># L = (y - (mx + c))^2</span></span>
<span id="cb18-7">left <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb18-8">right <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb18-9"></span>
<span id="cb18-10">L <span>=</span> _mul(left, right)</span>
<span id="cb18-11"></span>
<span id="cb18-12"><span># Attaching names to tensors will make our</span></span>
<span id="cb18-13"><span># diagram look nicer</span></span>
<span id="cb18-14">y.name <span>=</span> <span>"y"</span></span>
<span id="cb18-15">m.name <span>=</span> <span>"m"</span></span>
<span id="cb18-16">x.name <span>=</span> <span>"x"</span></span>
<span id="cb18-17">c.name <span>=</span> <span>"c"</span></span>
<span id="cb18-18">L.name <span>=</span> <span>"L"</span></span></code></pre></div>
<p>And then using Breadth First Search to do 3 things:</p>
<ul>
<li>Find all nodes</li>
<li>Find all edges</li>
<li>Find all paths from <span>\(L\)</span> to our parameters</li>
</ul>
<p>We haven’t implemented a simple way to check whether two tensors are identical so we’ll need to compare hashes.</p>
<div id="6f90fd88" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="13"><pre><code><span id="cb19-1">edges <span>=</span> []</span>
<span id="cb19-2"></span>
<span id="cb19-3">stack <span>=</span> [(L, [L])]</span>
<span id="cb19-4"></span>
<span id="cb19-5">nodes <span>=</span> []</span>
<span id="cb19-6">edges <span>=</span> []</span>
<span id="cb19-7"><span>while</span> stack:</span>
<span id="cb19-8">    node, current_path <span>=</span> stack.pop()</span>
<span id="cb19-9">    <span># Record nodes we haven't seen before</span></span>
<span id="cb19-10">    <span>if</span> <span>hash</span>(node) <span>not</span> <span>in</span> [<span>hash</span>(n) <span>for</span> n <span>in</span> nodes]:</span>
<span id="cb19-11">        nodes.append(node)</span>
<span id="cb19-12"></span>
<span id="cb19-13">    <span># If we have reached a parameter (it has no arguments</span></span>
<span id="cb19-14">    <span># because it wasn't created by an operation) then</span></span>
<span id="cb19-15">    <span># record the path taken to get here</span></span>
<span id="cb19-16">    <span>if</span> <span>not</span> node.args:</span>
<span id="cb19-17">        <span>if</span> node.paths <span>is</span> <span>None</span>:</span>
<span id="cb19-18">            node.paths <span>=</span> []</span>
<span id="cb19-19">        node.paths.append(current_path)</span>
<span id="cb19-20">        <span>continue</span></span>
<span id="cb19-21"></span>
<span id="cb19-22">    <span>for</span> arg <span>in</span> node.args:</span>
<span id="cb19-23">        stack.append((arg, current_path <span>+</span> [arg]))</span>
<span id="cb19-24">        <span># Record every new edge</span></span>
<span id="cb19-25">        edges.append((<span>hash</span>(node), <span>hash</span>(arg)))</span></code></pre></div>
<p>Now we’ve got all of the edges and nodes, we have complete knowledge of our computational graph. Let’s use networkx to plot it</p>
<div id="8fd42378" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="14">
<div id="cb20"><pre><code><span id="cb20-1"><span># Assign a unique integer to each</span></span>
<span id="cb20-2"><span># unnamed node so we know which</span></span>
<span id="cb20-3"><span># node is which in the picture</span></span>
<span id="cb20-4">labels <span>=</span> {}</span>
<span id="cb20-5"><span>for</span> i, node <span>in</span> <span>enumerate</span>(nodes):</span>
<span id="cb20-6">    <span>if</span> node.name <span>is</span> <span>None</span>:</span>
<span id="cb20-7">        labels[<span>hash</span>(node)] <span>=</span> <span>str</span>(i)</span>
<span id="cb20-8">    <span>else</span>:</span>
<span id="cb20-9">        labels[<span>hash</span>(node)] <span>=</span> node.name</span>
<span id="cb20-10"></span>
<span id="cb20-11">graph <span>=</span> nx.DiGraph()</span>
<span id="cb20-12">graph.add_edges_from(edges)</span>
<span id="cb20-13">pos <span>=</span> nx.nx_agraph.pygraphviz_layout(graph, prog<span>=</span><span>"dot"</span>)</span>
<span id="cb20-14">nx.draw(graph, pos<span>=</span>pos, labels<span>=</span>labels)</span></code></pre></div>
<div>
<figure>
<p><img src="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/post_files/figure-html/cell-15-output-1.png" width="691" height="499"></p>
</figure>
</div>
</div>
<p>If you squint a bit, you can see that this looks like the graph we made earlier! Let’s take a look at the paths the algorithm found from <span>\(L\)</span> to <span>\(x\)</span>.</p>
<div id="7cf96dca" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="15">
<div id="cb21"><pre><code><span id="cb21-1"><span>for</span> path <span>in</span> x.paths:</span>
<span id="cb21-2">    steps <span>=</span> []</span>
<span id="cb21-3">    <span>for</span> step <span>in</span> path:</span>
<span id="cb21-4">        steps.append(labels[<span>hash</span>(step)])</span>
<span id="cb21-5">    <span>print</span>(<span>"-&gt;"</span>.join(steps))</span></code></pre></div>
<div>
<pre><code>L-&gt;1-&gt;2-&gt;4-&gt;x
L-&gt;8-&gt;9-&gt;10-&gt;x</code></pre>
</div>
</div>
<p>The paths look correct! All we need to do now is to modify the algorithm a bit to keep track of the chain of derivatives along each path.</p>
<div id="386e7fdf" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="16"><pre><code><span id="cb23-1">y <span>=</span> Tensor(<span>1</span>)</span>
<span id="cb23-2">m <span>=</span> Tensor(<span>2</span>)</span>
<span id="cb23-3">x <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb23-4">c <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb23-5"></span>
<span id="cb23-6"><span># L = (y - (mx + c))^2</span></span>
<span id="cb23-7">left <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb23-8">right <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb23-9"></span>
<span id="cb23-10">L <span>=</span> _mul(left, right)</span>
<span id="cb23-11"></span>
<span id="cb23-12">y.name <span>=</span> <span>"y"</span></span>
<span id="cb23-13">m.name <span>=</span> <span>"m"</span></span>
<span id="cb23-14">x.name <span>=</span> <span>"x"</span></span>
<span id="cb23-15">c.name <span>=</span> <span>"c"</span></span>
<span id="cb23-16">L.name <span>=</span> <span>"L"</span></span></code></pre></div>
<div id="28e3b011" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="17"><pre><code><span id="cb24-1">stack <span>=</span> [(L, [L], [])]</span>
<span id="cb24-2"></span>
<span id="cb24-3">nodes <span>=</span> []</span>
<span id="cb24-4">edges <span>=</span> []</span>
<span id="cb24-5"><span>while</span> stack:</span>
<span id="cb24-6">    node, current_path, current_chain <span>=</span> stack.pop()</span>
<span id="cb24-7">    <span># Record nodes we haven't seen before</span></span>
<span id="cb24-8">    <span>if</span> <span>hash</span>(node) <span>not</span> <span>in</span> [<span>hash</span>(n) <span>for</span> n <span>in</span> nodes]:</span>
<span id="cb24-9">        nodes.append(node)</span>
<span id="cb24-10"></span>
<span id="cb24-11">    <span># If we have reached a parameter (it has no arguments</span></span>
<span id="cb24-12">    <span># because it wasn't created by an operation) then</span></span>
<span id="cb24-13">    <span># record the path taken to get here</span></span>
<span id="cb24-14">    <span>if</span> <span>not</span> node.args:</span>
<span id="cb24-15">        <span>if</span> node.paths <span>is</span> <span>None</span>:</span>
<span id="cb24-16">            node.paths <span>=</span> []</span>
<span id="cb24-17">        <span>if</span> node.chains <span>is</span> <span>None</span>:</span>
<span id="cb24-18">            node.chains <span>=</span> []</span>
<span id="cb24-19">        node.paths.append(current_path)</span>
<span id="cb24-20">        node.chains.append(current_chain)</span>
<span id="cb24-21">        <span>continue</span></span>
<span id="cb24-22"></span>
<span id="cb24-23">    <span>for</span> arg, op <span>in</span> <span>zip</span>(node.args, node.local_derivatives):</span>
<span id="cb24-24">        next_node <span>=</span> arg</span>
<span id="cb24-25">        next_path <span>=</span> current_path <span>+</span> [arg]</span>
<span id="cb24-26">        next_chain <span>=</span> current_chain <span>+</span> [op]</span>
<span id="cb24-27"></span>
<span id="cb24-28">        stack.append((arg, next_path, next_chain))</span>
<span id="cb24-29"></span>
<span id="cb24-30">        <span># Record every new edge</span></span>
<span id="cb24-31">        edges.append((<span>hash</span>(node), <span>hash</span>(arg)))</span></code></pre></div>
<p>Let’s check if the derivatives were recorded correctly.</p>
<div id="95ea9947" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="18">
<div id="cb25"><pre><code><span id="cb25-1"><span>print</span>(<span>f"Number of chains: </span><span>{</span><span>len</span>(x.chains)<span>}</span><span>"</span>)</span>
<span id="cb25-2"><span>for</span> chain <span>in</span> x.chains:</span>
<span id="cb25-3">    <span>print</span>(chain)</span></code></pre></div>
<div>
<pre><code>Number of chains: 2
[Tensor(-9), Tensor(-1), Tensor(1), Tensor(2)]
[Tensor(-9), Tensor(-1), Tensor(1), Tensor(2)]</code></pre>
</div>
</div>
<p>Looks reasonable so far. We have 2 identical paths, each with 4 derivatives (one for each edge in the path) as expected.</p>
<p>Let’s multiply the derivatives together along each path and add the total for each path together and see if we get the right answer.</p>
<p>According my calculations (and <a href="https://www.wolframalpha.com/">Wolfram Alpha</a>) the derivative of <span>\(L\)</span> wrt <span>\(x\)</span> is: <span>\[\frac{\partial L}{\partial x} = 2m (c + mx - y)\]</span> Plugging the values for our tensors in, we get <span>\[2\times2 (4 + (2\times3) - 1) = 36\]</span></p>
<div id="71c45972" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="19"><pre><code><span id="cb27-1">total_derivative <span>=</span> Tensor(<span>0</span>)</span>
<span id="cb27-2"><span>for</span> chain <span>in</span> x.chains:</span>
<span id="cb27-3">    chain_total <span>=</span> Tensor(<span>1</span>)</span>
<span id="cb27-4">    <span>for</span> step <span>in</span> chain:</span>
<span id="cb27-5">        chain_total <span>=</span> _mul(chain_total, step)</span>
<span id="cb27-6">    total_derivative <span>=</span> _add(total_derivative, chain_total)</span>
<span id="cb27-7"></span>
<span id="cb27-8">total_derivative</span></code></pre></div>
<p>The correct answer! It looks like our algorithm works. All that remains is to put all the pieces together.</p>
</section>
</section>
<section id="putting-it-all-together">
<h2 data-anchor-id="putting-it-all-together">Putting it all together</h2>
<p>When dreaming up the algorithm, we kept a record of the nodes, edges and paths which made plotting and debugging easier. Now that we know that it works, we can remove these and simplify things a bit.</p>
<div id="5c3a5852" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="20"><pre><code><span id="cb29-1"><span>def</span> backward(root_node: Tensor) <span>-&gt;</span> <span>None</span>:</span>
<span id="cb29-2">    stack <span>=</span> [(root_node, [])]</span>
<span id="cb29-3"></span>
<span id="cb29-4">    <span>while</span> stack:</span>
<span id="cb29-5">        node, current_derivative <span>=</span> stack.pop()</span>
<span id="cb29-6"></span>
<span id="cb29-7">        <span># if we have reached a parameter (it has no arguments</span></span>
<span id="cb29-8">        <span># because it wasn't created by an operation) then</span></span>
<span id="cb29-9">        <span># record the path taken to get here</span></span>
<span id="cb29-10">        <span>if</span> <span>not</span> node.args:</span>
<span id="cb29-11">            <span>if</span> node.chains <span>is</span> <span>None</span>:</span>
<span id="cb29-12">                node.chains <span>=</span> []</span>
<span id="cb29-13">            node.chain.append(current_derivative)</span>
<span id="cb29-14">            <span>continue</span></span>
<span id="cb29-15"></span>
<span id="cb29-16">        <span>for</span> arg, op <span>in</span> <span>zip</span>(node.args, node.local_derivatives):</span>
<span id="cb29-17">            stack.append((arg, current_derivative <span>+</span> [op]))</span></code></pre></div>
<p>There is also no need (for now) to store the derivatives and calculate them separately. Instead, we can avoid a bunch of repeated calculations by multiplying the derivatives as we go.</p>
<div id="c4000db8" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="21"><pre><code><span id="cb30-1"><span>def</span> backward(root_node: Tensor) <span>-&gt;</span> <span>None</span>:</span>
<span id="cb30-2">    stack <span>=</span> [(root_node, Tensor(<span>1</span>))]</span>
<span id="cb30-3"></span>
<span id="cb30-4">    <span>while</span> stack:</span>
<span id="cb30-5">        node, current_derivative <span>=</span> stack.pop()</span>
<span id="cb30-6"></span>
<span id="cb30-7">        <span># if we have reached a parameter (it has no arguments</span></span>
<span id="cb30-8">        <span># because it wasn't created by an operation) then add the</span></span>
<span id="cb30-9">        <span># derivative</span></span>
<span id="cb30-10">        <span>if</span> <span>not</span> node.args:</span>
<span id="cb30-11">            <span>if</span> node.derivative <span>is</span> <span>None</span>:</span>
<span id="cb30-12">                node.derivative <span>=</span> current_derivative</span>
<span id="cb30-13">            <span>else</span>:</span>
<span id="cb30-14">                node.derivative <span>=</span> _add(node.derivative, current_derivative)</span>
<span id="cb30-15">            <span>continue</span></span>
<span id="cb30-16"></span>
<span id="cb30-17">        <span>for</span> arg, derivative <span>in</span> <span>zip</span>(node.args, node.local_derivatives):</span>
<span id="cb30-18">            stack.append((arg, _mul(current_derivative, derivative)))</span></code></pre></div>
<p>Let’s make sure we didn’t break anything</p>
<div id="6bc39eac" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="22">
<div id="cb31"><pre><code><span id="cb31-1">y <span>=</span> Tensor(<span>1</span>)</span>
<span id="cb31-2">m <span>=</span> Tensor(<span>2</span>)</span>
<span id="cb31-3">x <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb31-4">c <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb31-5"></span>
<span id="cb31-6">left <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb31-7">right <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb31-8"></span>
<span id="cb31-9">L <span>=</span> _mul(left, right)</span>
<span id="cb31-10">backward(L)</span>
<span id="cb31-11"></span>
<span id="cb31-12"><span>print</span>(<span>f"</span><span>{</span>x<span>.</span>derivative <span>=</span> <span>}</span><span>\n</span><span>"</span>)</span>
<span id="cb31-13">test(got<span>=</span>x.derivative.value, want<span>=</span><span>36</span>)</span></code></pre></div>
<div>
<pre><code>x.derivative = Tensor(36)

✅ - Want: 36, Got: 36</code></pre>
</div>
</div>
<p>Let’s put this algorithm into our Tensor object</p>
<div id="208fa522" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="23"><pre><code><span id="cb33-1"><span>class</span> Tensor:</span>
<span id="cb33-2">    <span>"""</span></span>
<span id="cb33-3"><span>    A float that can be differentiated</span></span>
<span id="cb33-4"><span>    """</span></span>
<span id="cb33-5"></span>
<span id="cb33-6">    args: <span>tuple</span>[Tensor] <span>=</span> ()</span>
<span id="cb33-7">    local_derivatives: <span>tuple</span>[Tensor] <span>=</span> ()</span>
<span id="cb33-8">    <span># The derivative (once we've calculated it).  This is None if the derivative</span></span>
<span id="cb33-9">    <span># has not been computed yet</span></span>
<span id="cb33-10">    derivative: Tensor <span>|</span> <span>None</span> <span>=</span> <span>None</span></span>
<span id="cb33-11"></span>
<span id="cb33-12">    <span>def</span> <span>__init__</span>(<span>self</span>, value: <span>float</span>):</span>
<span id="cb33-13">        <span>self</span>.value <span>=</span> value</span>
<span id="cb33-14"></span>
<span id="cb33-15">    <span>def</span> <span>__repr__</span>(<span>self</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb33-16">        <span>return</span> <span>f"Tensor(</span><span>{</span><span>self</span><span>.</span>value<span>.</span><span>__repr__</span>()<span>}</span><span>)"</span></span>
<span id="cb33-17"></span>
<span id="cb33-18">    <span>def</span> backward(<span>self</span>):</span>
<span id="cb33-19">        <span>if</span> <span>self</span>.args <span>is</span> <span>None</span> <span>or</span> <span>self</span>.local_derivatives <span>is</span> <span>None</span>:</span>
<span id="cb33-20">            <span>raise</span> <span>ValueError</span>(</span>
<span id="cb33-21">                <span>"Cannot differentiate a Tensor that is not a function of other Tensors"</span></span>
<span id="cb33-22">            )</span>
<span id="cb33-23"></span>
<span id="cb33-24">        stack <span>=</span> [(<span>self</span>, Tensor(<span>1</span>))]</span>
<span id="cb33-25"></span>
<span id="cb33-26">        <span>while</span> stack:</span>
<span id="cb33-27">            node, current_derivative <span>=</span> stack.pop()</span>
<span id="cb33-28"></span>
<span id="cb33-29">            <span># if we have reached a parameter (it has no arguments</span></span>
<span id="cb33-30">            <span># because it wasn't created by an operation) then add the</span></span>
<span id="cb33-31">            <span># derivative</span></span>
<span id="cb33-32">            <span>if</span> <span>not</span> node.args:</span>
<span id="cb33-33">                <span>if</span> node.derivative <span>is</span> <span>None</span>:</span>
<span id="cb33-34">                    node.derivative <span>=</span> Tensor(<span>0</span>)</span>
<span id="cb33-35">                node.derivative <span>=</span> _add(node.derivative, current_derivative)</span>
<span id="cb33-36">                <span>continue</span></span>
<span id="cb33-37"></span>
<span id="cb33-38">            <span>for</span> arg, derivative <span>in</span> <span>zip</span>(node.args, node.local_derivatives):</span>
<span id="cb33-39">                new_derivative <span>=</span> _mul(current_derivative, derivative)</span>
<span id="cb33-40">                stack.append((arg, new_derivative))</span></code></pre></div>
<p>Let’s try it out</p>
<div id="59db14e7" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="24">
<div id="cb34"><pre><code><span id="cb34-1">y <span>=</span> Tensor(<span>1</span>)</span>
<span id="cb34-2">m <span>=</span> Tensor(<span>2</span>)</span>
<span id="cb34-3">x <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb34-4">c <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb34-5"></span>
<span id="cb34-6">left <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb34-7">right <span>=</span> _sub(y, _add(_mul(m, x), c))</span>
<span id="cb34-8"></span>
<span id="cb34-9">L <span>=</span> _mul(left, right)</span>
<span id="cb34-10">L.backward()</span>
<span id="cb34-11"></span>
<span id="cb34-12">test(x.derivative, Tensor(<span>36</span>))</span></code></pre></div>
<div>
<pre><code>❌ - Want: Tensor(36), Got: Tensor(36)</code></pre>
</div>
</div>
<p>Huh?</p>
<p>By default, if you compare two objects in python with <code>==</code>, python will check whether the object on the left has the same reference as the object as the one on the right. Because <code>Tensor(36)</code> is a different object (that just happens to have the same value) to <code>x.derivative</code>, <code>x.derivative == Tensor(36)</code> returns <code>False</code>.</p>
<p>It makes a lot more sense to compare two tensors based upon their <code>.value</code>. To achieve this, we can add the <code>__eq__</code> special method to <code>Tensor</code> which will change the behaviour of the <code>==</code> operator for <code>Tensor</code> objects</p>
<div id="00be4f8d" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="25"><pre><code><span id="cb36-1"><span>def</span> <span>__eq__</span>(<span>self</span>, other) <span>-&gt;</span> <span>bool</span>:</span>
<span id="cb36-2">    <span>"""</span></span>
<span id="cb36-3"><span>    Tells python to compare .value when applying the `==`</span></span>
<span id="cb36-4"><span>    operation to two tensors instead of comparing references</span></span>
<span id="cb36-5"><span>    """</span></span>
<span id="cb36-6">    <span>if</span> <span>not</span> <span>isinstance</span>(other, <span>"Tensor"</span>):</span>
<span id="cb36-7">        <span>raise</span> <span>TypeError</span>(<span>f"Cannot compare a Tensor with a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb36-8"></span>
<span id="cb36-9">    <span>return</span> <span>self</span>.value <span>==</span> other.value</span></code></pre></div>
<p>Similarly, if we try to use <code>+</code>, <code>-</code> or <code>*</code> on our tensors, we’ll get an error. We can tell python how to do these operations on our tensors by defining the following special functions:</p>
<ul>
<li><code>__add__</code> let’s us use <code>+</code></li>
<li><code>__sub__</code> let’s us use <code>-</code></li>
<li><code>__mul__</code> let’s us use <code>*</code></li>
</ul>
<div id="20dbaf3a" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="26"><pre><code><span id="cb37-1"><span>def</span> <span>__add__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb37-2">    <span>if</span> <span>not</span> <span>isinstance</span>(other, <span>"Tensor"</span>):</span>
<span id="cb37-3">        <span>raise</span> <span>TypeError</span>(<span>f"Cannot add a Tensor to a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb37-4"></span>
<span id="cb37-5">    <span>return</span> _add(<span>self</span>, other)</span>
<span id="cb37-6"></span>
<span id="cb37-7"></span>
<span id="cb37-8"><span>def</span> <span>__sub__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb37-9">    <span>if</span> <span>not</span> <span>isinstance</span>(other, <span>"Tensor"</span>):</span>
<span id="cb37-10">        <span>raise</span> <span>TypeError</span>(<span>f"Cannot subtract a Tensor from a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb37-11"></span>
<span id="cb37-12">    <span>return</span> _sub(<span>self</span>, other)</span>
<span id="cb37-13"></span>
<span id="cb37-14"></span>
<span id="cb37-15"><span>def</span> <span>__mul__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb37-16">    <span>if</span> <span>not</span> <span>isinstance</span>(other, <span>"Tensor"</span>):</span>
<span id="cb37-17">        <span>raise</span> <span>TypeError</span>(<span>f"Cannot multiply a Tensor with a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb37-18">    <span>return</span> _mul(<span>self</span>, other)</span></code></pre></div>
<p>Finally, we can add the <code>__iadd__</code>, <code>__isub__</code> and <code>__imul__</code> methods to allow us to use <code>+=</code>, <code>-=</code> and <code>*=</code>.</p>
<div id="7f0b2199" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="27"><pre><code><span id="cb38-1"><span>def</span> <span>__iadd__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb38-2">    <span>self</span> <span>=</span> <span>self</span>.<span>__add__</span>(<span>self</span>, other)</span>
<span id="cb38-3">    <span>return</span> <span>self</span></span>
<span id="cb38-4"></span>
<span id="cb38-5"></span>
<span id="cb38-6"><span>def</span> <span>__isub__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb38-7">    <span>self</span> <span>=</span> <span>self</span>.<span>__sub__</span>(<span>self</span>, other)</span>
<span id="cb38-8">    <span>return</span> <span>self</span></span>
<span id="cb38-9"></span>
<span id="cb38-10"></span>
<span id="cb38-11"><span>def</span> <span>__imul__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb38-12">    <span>self</span> <span>=</span> <span>self</span>.<span>__mul__</span>(<span>self</span>, other)</span>
<span id="cb38-13">    <span>return</span> <span>self</span></span></code></pre></div>
<p>While we’re here, let’s clean up our backward function a bit by replacing the ugly <code>_add</code> and <code>_mul</code> operations with <code>+</code> and <code>*</code>.</p>
<div id="aee373de" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="28"><pre><code><span id="cb39-1"><span>def</span> backward(<span>self</span>):</span>
<span id="cb39-2">    <span>if</span> <span>self</span>.args <span>is</span> <span>None</span> <span>or</span> <span>self</span>.local_derivatives <span>is</span> <span>None</span>:</span>
<span id="cb39-3">        <span>raise</span> <span>ValueError</span>(</span>
<span id="cb39-4">            <span>"Cannot differentiate a Tensor that is not a function of other Tensors"</span></span>
<span id="cb39-5">        )</span>
<span id="cb39-6"></span>
<span id="cb39-7">    stack <span>=</span> [(<span>self</span>, Tensor(<span>1</span>))]</span>
<span id="cb39-8"></span>
<span id="cb39-9">    <span>while</span> stack:</span>
<span id="cb39-10">        node, current_derivative <span>=</span> stack.pop()</span>
<span id="cb39-11"></span>
<span id="cb39-12">        <span># if we have reached a parameter (it has no arguments</span></span>
<span id="cb39-13">        <span># because it wasn't created by an operation) then add the</span></span>
<span id="cb39-14">        <span># derivative</span></span>
<span id="cb39-15">        <span>if</span> <span>not</span> node.args:</span>
<span id="cb39-16">            <span>if</span> node.derivative <span>is</span> <span>None</span>:</span>
<span id="cb39-17">                node.derivative <span>+=</span> current_derivative</span>
<span id="cb39-18">            <span>else</span>:</span>
<span id="cb39-19">                node.derivative <span>+=</span> current_derivative</span>
<span id="cb39-20">            <span>continue</span></span>
<span id="cb39-21"></span>
<span id="cb39-22">        <span>for</span> arg, derivative <span>in</span> <span>zip</span>(node.args, node.local_derivatives):</span>
<span id="cb39-23">            stack.append((arg, current_derivative <span>*</span> derivative))</span></code></pre></div>
<p>Putting all of these improvements together, we get a final <code>Tensor</code> object as follows:</p>
<div id="2eae868b" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="29"><pre><code><span id="cb40-1"><span>class</span> Tensor:</span>
<span id="cb40-2">    <span>"""</span></span>
<span id="cb40-3"><span>    A float that can be differentiated</span></span>
<span id="cb40-4"><span>    """</span></span>
<span id="cb40-5"></span>
<span id="cb40-6">    args: <span>tuple</span>[Tensor] <span>=</span> ()</span>
<span id="cb40-7">    local_derivatives: <span>tuple</span>[Tensor] <span>=</span> ()</span>
<span id="cb40-8">    <span># The derivative (once we've calculated it).  This is None if the derivative</span></span>
<span id="cb40-9">    <span># has not been computed yet</span></span>
<span id="cb40-10">    derivative: Tensor <span>|</span> <span>None</span> <span>=</span> <span>None</span></span>
<span id="cb40-11"></span>
<span id="cb40-12">    <span>def</span> <span>__init__</span>(<span>self</span>, value: <span>float</span>):</span>
<span id="cb40-13">        <span>self</span>.value <span>=</span> value</span>
<span id="cb40-14"></span>
<span id="cb40-15">    <span>def</span> <span>__repr__</span>(<span>self</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb40-16">        <span>return</span> <span>f"Tensor(</span><span>{</span><span>self</span><span>.</span>value<span>.</span><span>__repr__</span>()<span>}</span><span>)"</span></span>
<span id="cb40-17"></span>
<span id="cb40-18">    <span>def</span> <span>__eq__</span>(<span>self</span>, other) <span>-&gt;</span> <span>bool</span>:</span>
<span id="cb40-19">        <span>if</span> <span>not</span> <span>isinstance</span>(other, Tensor):</span>
<span id="cb40-20">            <span>raise</span> <span>TypeError</span>(<span>f"Cannot compare a Tensor with a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb40-21">        <span>return</span> <span>self</span>.value <span>==</span> other.value</span>
<span id="cb40-22"></span>
<span id="cb40-23">    <span>def</span> <span>__add__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb40-24">        <span>if</span> <span>not</span> <span>isinstance</span>(other, Tensor):</span>
<span id="cb40-25">            <span>raise</span> <span>TypeError</span>(<span>f"Cannot add a Tensor to a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb40-26">        <span>return</span> _add(<span>self</span>, other)</span>
<span id="cb40-27"></span>
<span id="cb40-28">    <span>def</span> <span>__sub__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb40-29">        <span>if</span> <span>not</span> <span>isinstance</span>(other, Tensor):</span>
<span id="cb40-30">            <span>raise</span> <span>TypeError</span>(<span>f"Cannot subtract a Tensor from a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb40-31">        <span>return</span> _sub(<span>self</span>, other)</span>
<span id="cb40-32"></span>
<span id="cb40-33">    <span>def</span> <span>__mul__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb40-34">        <span>if</span> <span>not</span> <span>isinstance</span>(other, Tensor):</span>
<span id="cb40-35">            <span>raise</span> <span>TypeError</span>(<span>f"Cannot multiply a Tensor with a </span><span>{</span><span>type</span>(other)<span>}</span><span>"</span>)</span>
<span id="cb40-36">        <span>return</span> _mul(<span>self</span>, other)</span>
<span id="cb40-37"></span>
<span id="cb40-38">    <span>def</span> <span>__iadd__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb40-39">        <span>return</span> <span>self</span>.<span>__add__</span>(other)</span>
<span id="cb40-40"></span>
<span id="cb40-41">    <span>def</span> <span>__isub__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb40-42">        <span>return</span> <span>self</span>.<span>__sub__</span>(other)</span>
<span id="cb40-43"></span>
<span id="cb40-44">    <span>def</span> <span>__imul__</span>(<span>self</span>, other) <span>-&gt;</span> Tensor:</span>
<span id="cb40-45">        <span>return</span> <span>self</span>.<span>__mul__</span>(other)</span>
<span id="cb40-46"></span>
<span id="cb40-47">    <span>def</span> <span>__repr__</span>(<span>self</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb40-48">        <span>return</span> <span>f"Tensor(</span><span>{</span><span>self</span><span>.</span>value<span>}</span><span>)"</span></span>
<span id="cb40-49"></span>
<span id="cb40-50">    <span>def</span> backward(<span>self</span>):</span>
<span id="cb40-51">        <span>if</span> <span>self</span>.args <span>is</span> <span>None</span> <span>or</span> <span>self</span>.local_derivatives <span>is</span> <span>None</span>:</span>
<span id="cb40-52">            <span>raise</span> <span>ValueError</span>(</span>
<span id="cb40-53">                <span>"Cannot differentiate a Tensor that is not a function of other Tensors"</span></span>
<span id="cb40-54">            )</span>
<span id="cb40-55"></span>
<span id="cb40-56">        stack <span>=</span> [(<span>self</span>, Tensor(<span>1</span>))]</span>
<span id="cb40-57"></span>
<span id="cb40-58">        <span>while</span> stack:</span>
<span id="cb40-59">            node, current_derivative <span>=</span> stack.pop()</span>
<span id="cb40-60"></span>
<span id="cb40-61">            <span># if we have reached a parameter (it has no arguments</span></span>
<span id="cb40-62">            <span># because it wasn't created by an operation) then add the</span></span>
<span id="cb40-63">            <span># current_derivative to derivative</span></span>
<span id="cb40-64">            <span>if</span> <span>not</span> node.args:</span>
<span id="cb40-65">                <span>if</span> node.derivative <span>is</span> <span>None</span>:</span>
<span id="cb40-66">                    node.derivative <span>=</span> current_derivative</span>
<span id="cb40-67">                <span>else</span>:</span>
<span id="cb40-68">                    node.derivative <span>+=</span> current_derivative</span>
<span id="cb40-69">                <span>continue</span></span>
<span id="cb40-70"></span>
<span id="cb40-71">            <span>for</span> arg, derivative <span>in</span> <span>zip</span>(node.args, node.local_derivatives):</span>
<span id="cb40-72">                stack.append((arg, current_derivative <span>*</span> derivative))</span></code></pre></div>
<p>Let’s take it for a spin. We’ll try calculating <span>\(L\)</span> again</p>
<div id="db25982d" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="30">
<div id="cb41"><pre><code><span id="cb41-1">y <span>=</span> Tensor(<span>1</span>)</span>
<span id="cb41-2">m <span>=</span> Tensor(<span>2</span>)</span>
<span id="cb41-3">x <span>=</span> Tensor(<span>3</span>)</span>
<span id="cb41-4">c <span>=</span> Tensor(<span>4</span>)</span>
<span id="cb41-5"></span>
<span id="cb41-6">diff <span>=</span> y <span>-</span> ((m <span>*</span> x) <span>+</span> c)</span>
<span id="cb41-7">L <span>=</span> diff <span>*</span> diff</span>
<span id="cb41-8">L.backward()</span>
<span id="cb41-9"></span>
<span id="cb41-10">test(got<span>=</span>x.derivative, want<span>=</span>Tensor(<span>36</span>))</span></code></pre></div>
<div>
<pre><code>✅ - Want: Tensor(36), Got: Tensor(36)</code></pre>
</div>
</div>
<p>Much easier!</p>
<p>To really see what this baby can do, I asked a language model for the most complicated expression it could think of and it gave me this:</p>
<p><span>\[f(x) = (2x^3 + 4x^2 - 5x) \times (3x^2 - 2x + 7) - (6x^4 + 2x^3 - 8x^2) + (5x^2 - 3x)\]</span> According to <a href="https://www.wolframalpha.com/">Wolfram Alpha</a>, the derivative of this expression is: <span>\[\frac{d f(x)}{dx} = -38 + 102 x - 33 x^2 + 8 x^3 + 30 x^4\]</span></p>
<p>If we plug 2 into this equation, the answer is apparently 578 (again, thanks to <a href="https://www.wolframalpha.com/">Wolfram Alpha</a>).</p>
<p>Let’s try it with our algorithm</p>
<div id="0fd9b01f" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="31">
<div id="cb43"><pre><code><span id="cb43-1">x <span>=</span> Tensor(<span>2</span>)</span>
<span id="cb43-2"></span>
<span id="cb43-3">y <span>=</span> (</span>
<span id="cb43-4">    (Tensor(<span>2</span>) <span>*</span> x <span>*</span> x <span>*</span> x <span>+</span> Tensor(<span>4</span>) <span>*</span> x <span>*</span> x <span>-</span> Tensor(<span>5</span>) <span>*</span> x)</span>
<span id="cb43-5">    <span>*</span> (Tensor(<span>3</span>) <span>*</span> x <span>*</span> x <span>-</span> Tensor(<span>2</span>) <span>*</span> x <span>+</span> Tensor(<span>7</span>))</span>
<span id="cb43-6">    <span>-</span> (Tensor(<span>6</span>) <span>*</span> x <span>*</span> x <span>*</span> x <span>*</span> x <span>+</span> Tensor(<span>2</span>) <span>*</span> x <span>*</span> x <span>*</span> x <span>-</span> Tensor(<span>8</span>) <span>*</span> x <span>*</span> x)</span>
<span id="cb43-7">    <span>+</span> (Tensor(<span>5</span>) <span>*</span> x <span>*</span> x <span>-</span> Tensor(<span>3</span>) <span>*</span> x)</span>
<span id="cb43-8">)</span>
<span id="cb43-9"></span>
<span id="cb43-10">y.backward()</span>
<span id="cb43-11"></span>
<span id="cb43-12">test(got<span>=</span>x.derivative, want<span>=</span>Tensor(<span>578</span>))</span></code></pre></div>
<div>
<pre><code>✅ - Want: Tensor(578), Got: Tensor(578)</code></pre>
</div>
</div>
<p>Once again, we got the right answer!</p>
</section>
<section id="conclusion">
<h2>Conclusion</h2>
<p>From nothing, we have now written an algorithm that will let us differentiate any mathematical expression (provided it only involves addition, subtraction and multiplication). We did this by converting our expression into a graph and re-imagining partial derivatives as operations on the edges of that graph. Then we found that we could apply Breadth First Search to combine all the derivatives together to get a final answer.</p>
<p>Differentiating scalars is (I hope you agree) interesting, but it isn’t exactly GPT-4. That said, with a few small modifications to our algorithm, we can extend our algorithm to handle multi-dimensional tensors like matrices and vectors. Once you can do that, you can build up to backpropagation and, eventually, to a fully functional language model.</p>
<p>Next time, we’ll extend our algorithm to vectors and matrices and build up from there to a working neural network. If you want to peek ahead, you can check out the repo for <a href="https://github.com/bclarkson-code/Tricycle">Tricycle</a> which is the name for the deep learning framework we’re building.</p>


</section>

</main> <!-- /main -->


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uv: Python packaging in Rust (570 pts)]]></title>
            <link>https://astral.sh/blog/uv</link>
            <guid>39387641</guid>
            <pubDate>Thu, 15 Feb 2024 19:50:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://astral.sh/blog/uv">https://astral.sh/blog/uv</a>, See on <a href="https://news.ycombinator.com/item?id=39387641">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p><strong>TL;DR:</strong> <a href="https://github.com/astral-sh/uv">uv</a> is an <strong>extremely fast Python package
installer and resolver</strong>, written in Rust, and designed as a drop-in replacement for <code>pip</code> and
<code>pip-tools</code> workflows.</p>
<p><a href="https://github.com/astral-sh/uv">uv</a> represents a milestone in our pursuit of a <a href="https://blog.rust-lang.org/2016/05/05/cargo-pillars.html#pillars-of-cargo">"Cargo for Python"</a>:
a comprehensive Python project and package manager that's fast, reliable, and easy to use.</p>
<p>As part of this release, we're also taking stewardship of <a href="https://github.com/mitsuhiko/rye">Rye</a>,
an experimental Python packaging tool from <a href="https://github.com/mitsuhiko">Armin Ronacher</a>. We'll
maintain <a href="https://github.com/mitsuhiko/rye">Rye</a> as we expand <a href="https://github.com/astral-sh/uv">uv</a> into a unified successor
project, to fulfill our <a href="https://rye-up.com/philosophy/">shared vision</a> for Python packaging.</p>
<hr>
<p>At Astral, we build high-performance developer tools for the Python ecosystem. We're best known
for <a href="https://github.com/astral-sh/ruff">Ruff</a>, an extremely fast
Python <a href="https://notes.crmarsh.com/python-tooling-could-be-much-much-faster">linter</a>
and <a href="https://astral.sh/blog/the-ruff-formatter">formatter</a>.</p>
<p>Today, we're releasing the next tool in the Astral toolchain: <strong><a href="https://github.com/astral-sh/uv">uv</a>, an extremely fast Python
package resolver and installer, written in Rust</strong>.</p>
<div><p><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 422 250"><g aria-roledescription="group mark container" fill="none" stroke-miterlimit="10"><g aria-roledescription="group mark container"><g aria-roledescription="axis" aria-label="X-axis for a linear scale with values from 0.0 to 3.5"><g pointer-events="none"><path stroke="rgba(127,127,127,0.25)" d="M347.5 90.5"></path></g><g pointer-events="none"><text text-anchor="middle" transform="translate(90.5 105.5)" font-family="Roboto Mono,monospace" font-size="12">0s
                        </text><text text-anchor="middle" transform="translate(176.214 105.5)" font-family="Roboto Mono,monospace" font-size="12">1s
                        </text><text text-anchor="middle" transform="translate(261.929 105.5)" font-family="Roboto Mono,monospace" font-size="12">2s
                        </text><text text-anchor="middle" transform="translate(347.643 105.5)" font-family="Roboto Mono,monospace" font-size="12">3s
                        </text></g></g><g aria-roledescription="axis" aria-label="Y-axis for a discrete scale with 4 values: uv, poetry, pip-compile, pdm"><g pointer-events="none"><text text-anchor="end" transform="translate(80.5 15.25)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">uv
                        </text><text text-anchor="end" transform="translate(80.5 37.75)" font-family="Roboto Mono,monospace" font-size="12">poetry
                        </text><text text-anchor="end" transform="translate(80.5 60.25)" font-family="Roboto Mono,monospace" font-size="12">pip-compile
                        </text><text text-anchor="end" transform="translate(80.5 82.75)" font-family="Roboto Mono,monospace" font-size="12">pdm
                        </text></g></g><g aria-roledescription="rect mark container"><path aria-label="Sum of time: 0.0134756369786; tool: uv" aria-roledescription="bar" d="M90 4.75h1.155v13H90Z"></path><path aria-label="Sum of time: 0.60278702674; tool: poetry" aria-roledescription="bar" d="M90 27.25h51.667v13H90Z"></path><path aria-label="Sum of time: 1.55616658094; tool: pip-compile" aria-roledescription="bar" d="M90 49.75h133.386v13H90Z"></path><path aria-label="Sum of time: 3.37404433084; tool: pdm" aria-roledescription="bar" d="M90 72.25h289.204v13H90Z"></path></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.60278702674; tool: poetry; timeFormat: 0.60s" aria-roledescription="text mark" transform="translate(147.667 37.75)" font-family="Roboto Mono,monospace" font-size="12">0.60s
                  </text><text aria-label="Sum of time: 1.55616658094; tool: pip-compile; timeFormat: 1.56s" aria-roledescription="text mark" transform="translate(229.386 60.25)" font-family="Roboto Mono,monospace" font-size="12">1.56s
                  </text><text aria-label="Sum of time: 3.37404433084; tool: pdm; timeFormat: 3.37s" aria-roledescription="text mark" transform="translate(385.204 82.75)" font-family="Roboto Mono,monospace" font-size="12">3.37s
                  </text></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.0134756369786; tool: uv; timeFormat: 0.01s" aria-roledescription="text mark" transform="translate(97.155 15.25)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">0.01s
                  </text></g><g aria-roledescription="axis" aria-label="X-axis for a linear scale with values from 0 to 5"><g pointer-events="none"><path stroke="rgba(127,127,127,0.25)" d="M330.5 233.5"></path></g><g pointer-events="none"><text text-anchor="middle" transform="translate(90.5 248.5)" font-family="Roboto Mono,monospace" font-size="12">0s
                        </text><text text-anchor="middle" transform="translate(210.5 248.5)" font-family="Roboto Mono,monospace" font-size="12">2s
                        </text><text text-anchor="middle" transform="translate(330.5 248.5)" font-family="Roboto Mono,monospace" font-size="12">4s
                        </text></g></g><g aria-roledescription="axis" aria-label="Y-axis for a discrete scale with 4 values: uv, poetry, pdm, pip-sync"><g pointer-events="none"><text text-anchor="end" transform="translate(80.5 158.25)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">uv
                        </text><text text-anchor="end" transform="translate(80.5 180.75)" font-family="Roboto Mono,monospace" font-size="12">poetry
                        </text><text text-anchor="end" transform="translate(80.5 203.25)" font-family="Roboto Mono,monospace" font-size="12">pdm
                        </text><text text-anchor="end" transform="translate(80.5 225.75)" font-family="Roboto Mono,monospace" font-size="12">pip-sync
                        </text></g></g><g aria-roledescription="rect mark container"><path aria-label="Sum of time: 0.0576289908; tool: uv" aria-roledescription="bar" d="M90 147.75h3.458v13H90Z"></path><path aria-label="Sum of time: 0.9872183659; tool: poetry" aria-roledescription="bar" d="M90 170.25h59.233v13H90Z"></path><path aria-label="Sum of time: 1.8969612492; tool: pdm" aria-roledescription="bar" d="M90 192.75h113.818v13H90Z"></path><path aria-label="Sum of time: 4.6313483826; tool: pip-sync" aria-roledescription="bar" d="M90 215.25h277.88v13H90Z"></path></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.9872183659; tool: poetry; timeFormat: 0.99s" aria-roledescription="text mark" transform="translate(155.233 180.75)" font-family="Roboto Mono,monospace" font-size="12">0.99s
                  </text><text aria-label="Sum of time: 1.8969612492; tool: pdm; timeFormat: 1.90s" aria-roledescription="text mark" transform="translate(209.818 203.25)" font-family="Roboto Mono,monospace" font-size="12">1.90s
                  </text><text aria-label="Sum of time: 4.6313483826; tool: pip-sync; timeFormat: 4.63s" aria-roledescription="text mark" transform="translate(373.88 225.75)" font-family="Roboto Mono,monospace" font-size="12">4.63s
                  </text></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.0576289908; tool: uv; timeFormat: 0.06s" aria-roledescription="text mark" transform="translate(99.458 158.25)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">0.06s
                  </text></g></g></g></svg></p><div><p><span>Resolving (left) and installing (right) the<!-- --> <a target="_blank" rel="noreferrer" href="https://github.com/python-trio/trio">Trio</a> <!-- -->dependencies with a<!-- --> </span><a aria-label="Toggle cache" tabindex="0" type="button">warm</a> <span>cache, to simulate<!-- --> <!-- -->recreating a virtual environment or adding a dependency to an existing project<!-- --> <!-- -->(<a href="https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md" target="_blank" rel="noreferrer">source</a>).</span></p><p><span>Resolving (top) and installing (bottom) the<!-- --> <a target="_blank" rel="noreferrer" href="https://github.com/python-trio/trio">Trio</a> <!-- -->dependencies with a<!-- --> </span><a aria-label="Toggle cache" tabindex="0" type="button">warm</a> <span>cache, to simulate<!-- --> <!-- -->recreating a virtual environment or adding a dependency to an existing project<!-- --> <!-- -->(<a href="https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md" target="_blank" rel="noreferrer">source</a>).</span></p></div></div>
<p><a href="https://github.com/astral-sh/uv">uv</a> is designed as a drop-in replacement for <code>pip</code> and <code>pip-tools</code>,
and is ready for production use today in projects built around those workflows.</p>
<p>Like <a href="https://github.com/astral-sh/ruff">Ruff</a>, uv's implementation was grounded in our core
product principles:</p>
<ol>
<li><strong>An obsessive focus on performance.</strong> In the above <a href="https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md">benchmarks</a>,
uv is <strong>8-10x faster</strong> than <code>pip</code> and <code>pip-tools</code> without caching, and <strong>80-115x faster</strong>
when running with a warm cache (e.g., recreating a virtual environment or updating a dependency).
uv uses a global module cache to avoid re-downloading and re-building dependencies, and
leverages Copy-on-Write and hardlinks on supported filesystems to minimize disk space usage.</li>
<li><strong>Optimized for adoption.</strong> While we have big aspirations for the future of Python packaging,
uv's initial release is centered on supporting the <code>pip</code> and <code>pip-tools</code> APIs behind
our <code>uv pip</code> interface, making it usable by existing projects with zero configuration.
Similarly, uv can be used as "just" a resolver (<code>uv pip compile</code> to lock your
dependencies), "just" a virtual environment creator (<code>uv venv</code>), "just" a package
installer (<code>uv pip sync</code>), and so on. It's both unified and modular.</li>
<li><strong>A simplified toolchain.</strong> uv ships as a single static binary capable of
replacing <code>pip</code>, <code>pip-tools</code>, and <code>virtualenv</code>. uv has no direct Python dependency, so you
can install it separately from Python itself, avoiding the need to manage <code>pip</code> installations
across multiple Python versions (e.g., <code>pip</code> vs. <code>pip3</code> vs. <code>pip3.7</code>).</li>
</ol>
<p>While uv will evolve into a <strong>complete Python project and package manager</strong> (a <a href="https://blog.rust-lang.org/2016/05/05/cargo-pillars.html#pillars-of-cargo">"Cargo for Python"</a>),
the narrower <code>pip-tools</code> scope allows us to solve the low-level problems involved in building such
a tool (like package installation) while shipping something immediately useful with minimal barrier
to adoption.</p>
<p>You can install <a href="https://github.com/astral-sh/uv">uv</a> today via our standalone installers,
or from <a href="https://pypi.org/project/uv/">PyPI</a>.</p>

<p><a href="https://github.com/astral-sh/uv">uv</a> supports everything you'd expect from a modern Python
packaging tool: editable installs, Git dependencies, URL dependencies, local dependencies,
constraint files, source distributions, custom indexes, and more, all designed around drop-in
compatibility with your existing tools.</p>
<p><a href="https://github.com/astral-sh/uv">uv</a> supports <strong>Linux</strong>, <strong>Windows</strong>, and <strong>macOS</strong>, and
has been tested at-scale against the public PyPI index.</p>
<h3><span id="a-drop-in-compatible-api"></span>A drop-in compatible API<!-- --> <a href="#a-drop-in-compatible-api">#</a></h3>
<p>This initial release centers on what we refer to as uv's <code>pip</code> API. It'll be familiar to those
that have used <code>pip</code> and <code>pip-tools</code> in the past:</p>
<ul>
<li>Instead of <code>pip install</code>, run <code>uv pip install</code> to install Python dependencies from the command
line, a requirements file, or a <code>pyproject.toml</code>.</li>
<li>Instead of <code>pip-compile</code>, run <code>uv pip compile</code> to generate a locked <code>requirements.txt</code>.</li>
<li>Instead of <code>pip-sync</code>, run <code>uv pip sync</code> to sync a virtual environment with a locked <code>requirements.txt</code>.</li>
</ul>
<p>By scoping these "lower-level" commands under <code>uv pip</code>, we retain space in the CLI for the more
"opinionated" project management API we intend to ship in the future, which will look more like
<a href="https://github.com/mitsuhiko/rye">Rye</a>, or <a href="https://github.com/rust-lang/cargo">Cargo</a>, or
<a href="https://github.com/python-poetry/poetry">Poetry</a>. (Imagine <code>uv run</code>, <code>uv build</code>, and so on.)</p>
<p>uv can also be used as a virtual environment manager via <code>uv venv</code>. It's about 80x
faster than <code>python -m venv</code> and 7x faster than <code>virtualenv</code>, with no dependency on Python.</p>
<div><p><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 454 282"><g aria-roledescription="group mark container" fill="none" stroke-miterlimit="10"><g aria-roledescription="group mark container"><g aria-roledescription="axis" aria-label="Y-axis for a discrete scale with 3 values: uv, virtualenv, venv"><g pointer-events="none"><text text-anchor="end" transform="translate(89.5 35)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">uv
                        </text><text text-anchor="end" transform="translate(89.5 65)" font-family="Roboto Mono,monospace" font-size="12">virtualenv
                        </text><text text-anchor="end" transform="translate(89.5 95)" font-family="Roboto Mono,monospace" font-size="12">venv
                        </text></g></g><g aria-roledescription="axis" aria-label="Y-axis for a discrete scale with 3 values: uv, virtualenv, venv"><g pointer-events="none"><text text-anchor="end" transform="translate(89.5 178)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">uv
                        </text><text text-anchor="end" transform="translate(89.5 208)" font-family="Roboto Mono,monospace" font-size="12">virtualenv
                        </text><text text-anchor="end" transform="translate(89.5 238)" font-family="Roboto Mono,monospace" font-size="12">venv
                        </text></g></g></g><g aria-roledescription="group mark container"><g aria-roledescription="axis" aria-label="X-axis for a linear scale with values from 0.00 to 0.08"><g pointer-events="none"><path stroke="rgba(127,127,127,0.25)" d="M407.5 106.5"></path></g><g pointer-events="none"><text text-anchor="middle" transform="translate(107.5 121.5)" font-family="Roboto Mono,monospace" font-size="12">0s
                        </text><text text-anchor="middle" transform="translate(182.5 121.5)" font-family="Roboto Mono,monospace" font-size="12">0.02s
                        </text><text text-anchor="middle" transform="translate(257.5 121.5)" font-family="Roboto Mono,monospace" font-size="12">0.04s
                        </text><text text-anchor="middle" transform="translate(332.5 121.5)" font-family="Roboto Mono,monospace" font-size="12">0.06s
                        </text><text text-anchor="middle" transform="translate(407.5 121.5)" font-family="Roboto Mono,monospace" font-size="12">0.08s
                        </text></g></g><g aria-roledescription="rect mark container"><path aria-label="Sum of time: 0.0041; tool: uv" aria-roledescription="bar" d="M107 24.5h15.375v13H107Z"></path><path aria-label="Sum of time: 0.0744; tool: virtualenv" aria-roledescription="bar" d="M107 54.5h279v13H107Z"></path><path aria-label="Sum of time: 0.0241; tool: venv" aria-roledescription="bar" d="M107 84.5h90.375v13H107Z"></path></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.0744; tool: virtualenv; timeFormat: 74.4ms" aria-roledescription="text mark" transform="translate(392 65)" font-family="Roboto Mono,monospace" font-size="12">74.4ms
                  </text><text aria-label="Sum of time: 0.0241; tool: venv; timeFormat: 24.1ms" aria-roledescription="text mark" transform="translate(203.375 95)" font-family="Roboto Mono,monospace" font-size="12">24.1ms
                  </text></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.0041; tool: uv; timeFormat: 4.1ms" aria-roledescription="text mark" transform="translate(128.375 35)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">4.1ms
                  </text></g><g aria-roledescription="axis" aria-label="X-axis for a linear scale with values from 0.0 to 1.6"><g pointer-events="none"><path stroke="rgba(127,127,127,0.25)" d="M388.5 249.5"></path></g><g pointer-events="none"><text text-anchor="middle" transform="translate(107.5 264.5)" font-family="Roboto Mono,monospace" font-size="12">0s
                        </text><text text-anchor="middle" transform="translate(201.25 264.5)" font-family="Roboto Mono,monospace" font-size="12">0.5s
                        </text><text text-anchor="middle" transform="translate(295 264.5)" font-family="Roboto Mono,monospace" font-size="12">1s
                        </text><text text-anchor="middle" transform="translate(388.75 264.5)" font-family="Roboto Mono,monospace" font-size="12">1.5s
                        </text></g></g><g aria-roledescription="rect mark container"><path aria-label="Sum of time: 0.0182; tool: uv" aria-roledescription="bar" d="M107 167.5h3.413v13H107Z"></path><path aria-label="Sum of time: 0.1414; tool: virtualenv" aria-roledescription="bar" d="M107 197.5h26.512v13H107Z"></path><path aria-label="Sum of time: 1.54; tool: venv" aria-roledescription="bar" d="M107 227.5h288.75v13H107Z"></path></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.1414; tool: virtualenv; timeFormat: 141.4ms" aria-roledescription="text mark" transform="translate(139.512 208)" font-family="Roboto Mono,monospace" font-size="12">141.4ms
                  </text><text aria-label="Sum of time: 1.54; tool: venv; timeFormat: 1.54s" aria-roledescription="text mark" transform="translate(401.75 238)" font-family="Roboto Mono,monospace" font-size="12">1.54s
                  </text></g><g aria-roledescription="text mark container"><text aria-label="Sum of time: 0.0182; tool: uv; timeFormat: 18.2ms" aria-roledescription="text mark" transform="translate(116.412 178)" font-family="Roboto Mono,monospace" font-size="12" font-weight="bold">18.2ms
                  </text></g></g></g></svg></p><div><p>Creating a virtual environment, with (top) and without (bottom) seed packages like pip and setuptools (<a href="https://github.com/astral-sh/uv/blob/ea13d94c57149a8fc6ebfcef46149252e869269f/scripts/benchmarks/venv.sh" target="_blank" rel="noreferrer">source</a>).</p><p>Creating a virtual environment, with (left) and without (right) seed packages like pip and setuptools (<a href="https://github.com/astral-sh/uv/blob/ea13d94c57149a8fc6ebfcef46149252e869269f/scripts/benchmarks/venv.sh" target="_blank" rel="noreferrer">source</a>).</p></div></div>
<p>uv's virtual environments are standards-compliant and work interchangeably with other tools —
there's no lock-in or customization.</p>
<p>Building our own package management stack from scratch also opened up room for new capabilities.
For example:</p>
<ul>
<li><strong>uv supports alternate resolution strategies.</strong> By default, uv follows the standard
Python dependency resolution strategy of preferring the latest compatible version of each package.
But by passing <code>--resolution=lowest</code>, library authors can test their packages against the lowest-compatible version of their dependencies. (This is similar to Go's
<a href="https://go.dev/ref/mod#minimal-version-selection">Minimal version selection</a>.)</li>
<li><strong>uv allows for resolutions against arbitrary target Python versions.</strong> While <code>pip</code>
and <code>pip-tools</code> always resolve against the currently-installed Python version (generating, e.g., a
Python 3.12-compatible resolution when running under Python 3.12), uv accepts
a <code>--python-version</code> parameter, enabling you to generate, e.g., Python 3.7-compatible resolutions
even when running under newer versions.</li>
<li><strong>uv allows for dependency “overrides”.</strong> uv takes pip's “constraints” concepts a step
further via overrides (<code>-o overrides.txt</code>), which allow the user to guide the resolver by
overriding the declared dependencies of a package. Overrides give the user an escape hatch for
working around erroneous upper bounds and other incorrectly-declared dependencies.</li>
</ul>
<p>In its current form, uv won't be the right fit for all projects. <code>pip</code> is a mature and stable
tool, with extensive support for an extremely wide range of use cases and a focus on compatibility.
While uv supports a large fraction of the <code>pip</code> interface, it lacks support for some of its
legacy features, like <code>.egg</code> distributions.</p>
<p>Similarly, uv does not yet generate a platform-agnostic lockfile. This matches <code>pip-tools</code>, but
differs from Poetry and PDM, making uv a better fit for projects built around the <code>pip</code> and
<code>pip-tools</code> workflows.</p>
<p>For those deep in the packaging ecosystem, uv also includes standards-compliant Rust
implementations of <a href="https://peps.python.org/pep-0440/">PEP 440</a> (version identifiers),
<a href="https://peps.python.org/pep-0508/">PEP 508</a> (dependency specifiers),
<a href="https://peps.python.org/pep-0517/">PEP 517</a> (a build-system independent build frontend),
<a href="https://peps.python.org/pep-0405/">PEP 405</a> (virtual environments), and more.</p>
<h3><span id="a-cargo-for-python-uv-and-rye"></span>A "Cargo for Python": uv and Rye<!-- --> <a href="#a-cargo-for-python-uv-and-rye">#</a></h3>
<p>uv represents an intermediary milestone in our pursuit of a <a href="https://blog.rust-lang.org/2016/05/05/cargo-pillars.html#pillars-of-cargo">"Cargo for Python"</a>: a unified Python
package and project manager that is extremely fast, reliable, and easy to use.</p>
<p>Think: a single binary that bootstraps your Python installation and gives you everything you need to
be productive with Python, bundling not only <code>pip</code>, <code>pip-tools</code>, and <code>virtualenv</code>, but also <code>pipx</code>,
<code>tox</code>, <code>poetry</code>, <code>pyenv</code>, <code>ruff</code>, and more.</p>
<p>Python tooling can be a low-confidence experience: it's a significant amount of work to stand up a
new or existing project, and commands fail in confusing ways. In contrast, when working in the Rust
ecosystem, you trust the tools to succeed. The Astral toolchain is about bringing Python from a
low-confidence to a high-confidence experience.</p>
<p>This vision for Python packaging is not far off from that put forward by <a href="https://github.com/mitsuhiko/rye">Rye</a>,
an experimental project and package management tool from <a href="https://github.com/mitsuhiko">Armin Ronacher</a>.</p>
<p>In talking with Armin, it was clear that our visions were closely aligned, but that fulfilling
them would require a significant investment in foundational tooling. For example: building such a
tool requires an extremely fast, end-to-end integrated, cross-platform resolver and installer. <strong>In
uv, we've built that foundational tooling.</strong></p>
<p>We saw this as a rare opportunity to team up, and to avoid fragmenting the Python ecosystem.
<strong>As such, in collaboration with Armin, we're excited to be taking over <a href="https://github.com/mitsuhiko/rye">Rye</a>.</strong>
Our goal is to evolve uv into a production-ready <a href="https://blog.rust-lang.org/2016/05/05/cargo-pillars.html#pillars-of-cargo">"Cargo for Python"</a>, and to provide a smooth
migration path from Rye to uv when the time is right.</p>
<p>Until then, we'll be maintaining Rye, migrating it to use uv under-the-hood, and, more
generally, treating it as an experimental testbed for the end-user experience we're building
towards.</p>
<p>While merging projects comes with its own challenges, we're committed to building a single, unified
tool under the Astral banner, and to supporting existing Rye users as we evolve uv into a
suitable and comprehensive successor project.</p>
<h3><span id="our-roadmap"></span>Our Roadmap<!-- --> <a href="#our-roadmap">#</a></h3>
<p>Following this release, our first priority is to support users as they consider <a href="https://github.com/astral-sh/uv">uv</a>,
with a focus on improving compatibility, performance, and stability across platforms.</p>
<p>From there, we'll look towards expanding uv into a complete Python project and package manager:
a single binary that gives you everything you need to be productive with Python.</p>
<p>We have an ambitious roadmap for uv. But even in its current form, I think it will
feel like a very different experience for Python. I hope you'll give it a try.</p>
<h3><span id="acknowledgements"></span>Acknowledgements<!-- --> <a href="#acknowledgements">#</a></h3>
<p>Finally, we'd like to thank all those that contributed directly or indirectly to the development of
uv. Foremost among them are <a href="https://github.com/Eh2406">Jacob Finkelman</a>
and <a href="https://github.com/mpizenberg">Matthieu Pizenberg</a>, the maintainers
of <a href="https://github.com/pubgrub-rs/pubgrub">pubgrub-rs</a>. uv uses PubGrub as its underlying
version solver, and we're grateful to Jacob and Matthieu for the work they put into PubGrub in the
past, and for the way they've engaged with us as collaborators throughout the project.</p>
<p>We'd also like to thank those projects in the packaging space that've inspired us,
especially <a href="https://github.com/rust-lang/cargo">Cargo</a>, along with <a href="https://github.com/oven-sh/bun">Bun</a>, <a href="https://github.com/orogene/orogene">Orogene</a>,
and <a href="https://github.com/pnpm/pnpm">pnpm</a> from the JavaScript ecosystem,
and <a href="https://github.com/njsmith/posy">Posy</a>, <a href="https://github.com/konstin/monotrail-resolve">Monotrail</a>,
and <a href="https://github.com/mitsuhiko/rye">Rye</a> from the Python ecosystem. In particular, thanks
to <a href="https://github.com/mitsuhiko">Armin Ronacher</a> for collaborating with us on this effort.</p>
<p>Finally, we'd like to thank the maintainers of <a href="https://github.com/pypa/pip">pip</a> and the members of
the PyPA more broadly for all the work they do to make Python packaging possible.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sam Altman owns OpenAI's venture capital fund (243 pts)]]></title>
            <link>https://www.axios.com/2024/02/15/sam-altman-openai-startup-fund</link>
            <guid>39387578</guid>
            <pubDate>Thu, 15 Feb 2024 19:45:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.axios.com/2024/02/15/sam-altman-openai-startup-fund">https://www.axios.com/2024/02/15/sam-altman-openai-startup-fund</a>, See on <a href="https://news.ycombinator.com/item?id=39387578">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-theme="core" id="main-content"><div data-vars-content-id="89f40cb7-4531-4c6b-85c8-c199765f13ff" data-vars-headline="Sam Altman owns OpenAI's venture capital fund" data-vars-category="story" data-vars-sub-category="story"><div><div><p><img alt="headshot" loading="lazy" width="52" height="52" decoding="async" data-nimg="1" srcset="https://www.axios.com/_next/image?url=https%3A%2F%2Fimages.axios.com%2FcUYY6Rl2xaPB8AWGASzP3EWlsDQ%3D%2F0x0%3A328x328%2F52x0%2F2020%2F05%2F01%2F1588371030543.jpg&amp;w=320&amp;q=75 1x" src="https://www.axios.com/_next/image?url=https%3A%2F%2Fimages.axios.com%2FcUYY6Rl2xaPB8AWGASzP3EWlsDQ%3D%2F0x0%3A328x328%2F52x0%2F2020%2F05%2F01%2F1588371030543.jpg&amp;w=320&amp;q=75"></p></div><div><ul><li data-cy="byline-author"><a href="https://www.axios.com/authors/danprimack"><span>Dan Primack</span></a><p>, author of  </p><a href="https://www.axios.com/newsletters/axios-pro-rata">Axios Pro Rata</a></li></ul></div></div><figure data-cy="au-image"><img data-cy="StoryImage" alt="Photo illustration of Sam Altman waving in front of a pile of money." fetchpriority="high" width="1920" height="1080" decoding="async" data-nimg="1" sizes="100vw" srcset="https://images.axios.com/GDQgvSXrjaTnHVNOCxYUj2XUtJQ=/0x0:1920x1080/320x180/2024/02/15/1708018368446.jpg?w=320 320w, https://images.axios.com/GDQgvSXrjaTnHVNOCxYUj2XUtJQ=/0x0:1920x1080/320x180/2024/02/15/1708018368446.jpg?w=320 320w, https://images.axios.com/XQFxVifpfo8p2VsNz37-hfOiyS0=/0x0:1920x1080/640x360/2024/02/15/1708018368446.jpg?w=640 640w, https://images.axios.com/XQFxVifpfo8p2VsNz37-hfOiyS0=/0x0:1920x1080/640x360/2024/02/15/1708018368446.jpg?w=640 640w, https://images.axios.com/i27RdSyJupBNc81EE1MowR8wsWY=/0x0:1920x1080/768x432/2024/02/15/1708018368446.jpg?w=768 768w, https://images.axios.com/i27RdSyJupBNc81EE1MowR8wsWY=/0x0:1920x1080/768x432/2024/02/15/1708018368446.jpg?w=768 768w, https://images.axios.com/IDowc7V9ZUYqv5KeTV8Ra1-X-20=/0x0:1920x1080/1024x576/2024/02/15/1708018368446.jpg?w=1024 1024w, https://images.axios.com/IDowc7V9ZUYqv5KeTV8Ra1-X-20=/0x0:1920x1080/1024x576/2024/02/15/1708018368446.jpg?w=1024 1024w, https://images.axios.com/o8FshlR8oMZ76w2gNQAh6FkTZV4=/0x0:1920x1080/1366x768/2024/02/15/1708018368446.jpg?w=1366 1366w, https://images.axios.com/o8FshlR8oMZ76w2gNQAh6FkTZV4=/0x0:1920x1080/1366x768/2024/02/15/1708018368446.jpg?w=1366 1366w, https://images.axios.com/PfEiA3uwp9fWdaDzrLY7JoJTu-w=/0x0:1920x1080/1600x900/2024/02/15/1708018368446.jpg?w=1600 1600w, https://images.axios.com/PfEiA3uwp9fWdaDzrLY7JoJTu-w=/0x0:1920x1080/1600x900/2024/02/15/1708018368446.jpg?w=1600 1600w, https://images.axios.com/ut-S-jEgmNSG0cpCRmG9tiH27jM=/0x0:1920x1080/1920x1080/2024/02/15/1708018368446.jpg?w=1920 1920w, https://images.axios.com/ut-S-jEgmNSG0cpCRmG9tiH27jM=/0x0:1920x1080/1920x1080/2024/02/15/1708018368446.jpg?w=1920 1920w" src="https://images.axios.com/ut-S-jEgmNSG0cpCRmG9tiH27jM=/0x0:1920x1080/1920x1080/2024/02/15/1708018368446.jpg?w=1920"><figcaption><p>Rebecca Zisser / Axios</p></figcaption></figure><div><p><span data-schema="smart-brevity"><p>Sam Altman isn't just the CEO of ChatGPT maker OpenAI. He's also the owner of OpenAI Startup Fund, which Altman once <a data-vars-link-text="called" data-vars-click-url="https://www.openai.fund/about" data-vars-content-id="89f40cb7-4531-4c6b-85c8-c199765f13ff" data-vars-headline="Sam Altman owns OpenAI's venture capital fund" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.openai.fund/about" target="_blank">called</a> a "corporate venture fund," according to federal securities filings.</p><p><strong>Why it matters:</strong> OpenAI's structural strangeness permeates all aspects of the business.</p></span></p><p><strong>Background:</strong> OpenAI Startup Fund was launched in late 2021 to invest in other AI startups and projects.</p><ul><li>By last May it reported $175 million in total commitments, and a portfolio that included video editor Descript and legal tool Harvey.</li><li>It always had outside limited partners, including major OpenAI partner Microsoft, which is unusual for corporate VC funds but not unique.</li><li>What set OpenAI Startup Fund apart, however, was that it wasn't (and isn't) owned by OpenAI. Nor even by its affiliated <a data-vars-link-text="nonprofit foundation" data-vars-click-url="https://www.axios.com/2023/01/10/how-a-silicon-valley-nonprofit-became-worth-billions" data-vars-content-id="89f40cb7-4531-4c6b-85c8-c199765f13ff" data-vars-headline="Sam Altman owns OpenAI's venture capital fund" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2023/01/10/how-a-silicon-valley-nonprofit-became-worth-billions" target="_self">nonprofit foundation</a>. Instead, it's legally owned by Altman.</li></ul><p><strong>Behind the scenes: </strong>"We wanted to get started quickly and the easiest way to do that due to our structure was to put it in Sam's name," an OpenAI spokesperson tells Axios. "We have always intended for this to be temporary."</p><ul><li>"Temporary" has been well over a year and it's a significant risk. For example, what might have happened had Altman <a data-vars-link-text="remained fired" data-vars-click-url="https://www.axios.com/2023/11/22/sam-altman-return-open-ai" data-vars-content-id="89f40cb7-4531-4c6b-85c8-c199765f13ff" data-vars-headline="Sam Altman owns OpenAI's venture capital fund" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2023/11/22/sam-altman-return-open-ai" target="_self">remained fired</a> by OpenAI. Could he have kept the fund? Was there anything contractual to prevent it?</li><li>No answer to that last question, but the company does add: "We now know that we may need to re-examine our governance structure, which should precede any changes to the fund, but our priority is to establish a new board first."</li></ul></div></div><h5>Go deeper</h5></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Plastics producers deceived public about recycling, report reveals (124 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2024/feb/15/recycling-plastics-producers-report</link>
            <guid>39387387</guid>
            <pubDate>Thu, 15 Feb 2024 19:32:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2024/feb/15/recycling-plastics-producers-report">https://www.theguardian.com/us-news/2024/feb/15/recycling-plastics-producers-report</a>, See on <a href="https://news.ycombinator.com/item?id=39387387">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Plastic producers have known for more than 30 years that recycling is not an economically or technically feasible plastic waste management solution. That has not stopped them from promoting it, according to a new report.</p><p>“The companies lied,” said Richard Wiles, president of fossil-fuel accountability advocacy group the Center for Climate Integrity (CCI), which published the report. “It’s time to hold them accountable for the damage they’ve caused.”</p><figure id="a1b80ff2-5ffb-49c5-94cf-04e08c7a3648" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:2,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;What a waste: New York City budget cuts eviscerate community composting groups&quot;,&quot;elementId&quot;:&quot;a1b80ff2-5ffb-49c5-94cf-04e08c7a3648&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/environment/2024/feb/11/new-york-city-community-composting-groups-budget-cuts&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>Plastic, which is made from oil and gas, is notoriously difficult to recycle. Doing so requires meticulous sorting, since most of the thousands of chemically distinct varieties of plastic cannot be recycled together. That renders an already pricey process even more expensive. Another challenge: the material degrades each time it is reused, meaning it can generally only be reused once or twice.</p><p>The industry has known for decades about these existential challenges, but obscured that information in its marketing campaigns, <a href="https://climateintegrity.org/plastics-fraud" data-link-name="in body link">the report shows</a>.</p><p>The research draws on previous <a href="https://www.pbs.org/wgbh/frontline/documentary/plastic-wars/?" data-link-name="in body link">investigations</a> as well as newly revealed internal documents illustrating the extent of this decades-long campaign.</p><p>Industry insiders over the past several decades have variously referred to plastic recycling as “uneconomical”, said it “cannot be considered a permanent solid waste solution”, and said it “cannot go on indefinitely”, the revelations show.</p><p>The authors say the evidence demonstrates that oil and petrochemical companies, as well as their trade associations, may have broken laws designed to protect the public from misleading marketing and pollution.</p><h2 id="single-use-plastics">Single-use plastics</h2><p>In the 1950s, plastic producers came up with an idea to ensure a continually growing market for their products: disposability.</p><p>“They knew if they focused on single-use [plastics] people would buy and buy and buy,” said Davis Allen, investigative researcher at the CCI and the report’s lead author.</p><p>At a 1956 industry conference, the Society of the Plastics Industry, a trade group, told producers to focus on “low cost, big volume” and “expendability” and to aim for materials to end up “in the garbage wagon”. (Society of Plastics is <a href="https://www.plasticstoday.com/business/spi-no-more-rebrands-as-plastics-industry-association-aka-plastics" data-link-name="in body link">now</a> known as the Plastics Industry Association. Plastics Industry Association was not immediately available for comment.)</p><p>Over the following decades, the industry told the public that plastics can easily be tossed into landfills or burned in garbage incinerators. But in the 1980s, as<strong> </strong>municipalities began considering bans on grocery bags and other plastic products<strong>, </strong>the industry began promoting a new solution: recycling.</p><h2 id="recycling-campaigns">Recycling campaigns</h2><p>The industry has long known that plastics recycling is not economically or practically viable, the report shows. An internal 1986 report from the trade association the Vinyl Institute noted that “recycling cannot be considered a permanent solid waste solution [to plastics], as it merely prolongs the time until an item is disposed of”.</p><p>In 1989, the founding director of the Vinyl Institute told attendees of a trade conference: “Recycling cannot go on indefinitely, and does not solve the solid waste problem.”</p><p>Despite this knowledge, the Society of the Plastics Industry established the Plastics Recycling Foundation in 1984, bringing together petrochemical companies and bottlers, and launched a campaign focused on the sector’s <a href="https://www.toxicdocs.org/d/rpQVOR8obVNLbN5R69K0EJ5pJ?lightbox=1" data-link-name="in body link">commitment</a> to recycling.</p><p>In 1988, the trade group rolled out the “chasing arrows” – the widely recognized symbol for recyclable plastic – and began using it on packaging. Experts have long said the symbol is highly misleading, and recently federal regulators have <a href="https://www.nytimes.com/2023/08/07/climate/chasing-arrows-recycling-symbol-epa.html" data-link-name="in body link">echoed</a> their concerns.</p><p>The Society of the Plastics Industry also established a plastics recycling research center at Rutgers University in New Jersey in 1985, one year after state lawmakers passed<strong> </strong>a mandatory recycling law. In 1988, industry group the Council for Solid <a href="https://www.theguardian.com/environment/waste" data-link-name="in body link" data-component="auto-linked-tag">Waste</a> Solutions set up a recycling pilot project in St Paul, Minnesota, where the city council had just voted to ban the plastic polystyrene, or styrofoam.</p><p>And in the early 1990s, another industry group ran ads in Ladies’ Home Journal proclaiming: “A bottle can come back as a bottle, over and over again.”</p><p>All the while, behind closed doors, industry leaders maintained that recycling was not a real solution.</p><p>In 1994, a representative of Eastman Chemical spoke at an industry conference about the need for proper plastic recycling infrastructure. “While some day this may be a reality,” he said, “it is more likely that we will wake up and realize that we are not going to recycle our way out of the solid waste issue.” That same year, an Exxon employee told staffers at the American Plastics Council: “We are committed to the activities [of plastics recycling], but not committed to the results.”</p><p>“It’s clearly fraud they’re engaged in,” said Wiles.</p><p>The report does not allege that the companies broke specific laws. But Alyssa Johl, report co-author and attorney, said she suspects they violated public-nuisance, racketeering and consumer-fraud protections.</p><p>The industry’s misconduct continues today, the report alleges. Over the past several years, industry lobbying groups have <a href="https://cen.acs.org/environment/recycling/plastic-recycling-chemical-advanced-fuel-pyrolysis-state-laws/100/i17" data-link-name="in body link">promoted</a> so-called<strong> </strong>chemical recycling, which <a href="https://www.theguardian.com/us-news/2023/apr/10/exxon-advanced-recycling-plastic-environment" data-link-name="in body link">breaks plastic polymers down</a> into tiny molecules in order to make new plastics, synthetic fuels and other products. But the process creates pollution and is even more energy intensive than traditional plastic recycling.</p><p>The plastics sector has long known chemical recycling is also not a true solution to plastic waste, the report says. In a 1994 trade meeting, Exxon Chemical vice-president Irwin Levowitz called one common form of chemical recycling a “fundamentally uneconomical process”. And in 2003, a longtime trade consultant criticized the industry for promoting chemical recycling, calling it “another example of how non-science got into the minds of industry and environmental activists alike”.</p><p>“This is just another example, a new version, of the deception we saw before,” said Allen.</p><h2 id="legal-ramifications">Legal ramifications</h2><p>The report comes as the plastic industry and recycling are facing growing<strong> </strong>public scrutiny. Two years ago, California’s attorney general, Rob Bonta, publicly launched an <a href="https://oag.ca.gov/news/press-releases/attorney-general-bonta-announces-investigation-fossil-fuel-and-petrochemical" data-link-name="in body link">investigation</a> into fossil fuel and petrochemical producers “for their role in causing and exacerbating the global plastics pollution crisis”.</p><p>A toxic train derailment in East Palestine, Ohio, last February also catalyzed a movement demanding a ban on vinyl chloride, a carcinogen used to make plastic. Last month, the EPA announced a health review of the chemical – the first step toward a <a href="https://apnews.com/article/vinyl-chloride-ohio-train-derailment-toxic-chemicals-54bb0a943f4f4af0e4f68cc60ce4edb4" data-link-name="in body link">potential ban</a>.</p><p>In 2023, New York state also filed a lawsuit against PepsiCo, saying its single-use plastics violate public nuisance laws, and that the company misled consumers about the effectiveness of recycling.</p><figure id="662870ea-aad7-4537-a257-dab131a2a311" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:31,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Certified natural gas is ‘dangerous greenwashing scheme’, US senators say&quot;,&quot;elementId&quot;:&quot;662870ea-aad7-4537-a257-dab131a2a311&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/us-news/2024/feb/12/natural-gas-greenwashing-democrats&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>The public is also increasingly concerned about the climate impact of plastic production and disposal, which account for <a href="https://rmi.org/clean-energy-101-reducing-climate-pollution-from-the-plastics-industry/#:~:text=In%20fact%2C%20about%2012%20percent,to%20manage%20plastics'%20climate%20risks." data-link-name="in body link">3.4% of all global greenhouse-gas emissions.</a> In recent years, two dozen cities and states have <a href="https://www.theguardian.com/us-news/2023/jun/07/climate-crisis-big-oil-lawsuits-constitution" data-link-name="in body link">sued the oil industry</a> for covering up the dangers of the climate crisis. Similarly taking the oil and petrochemical industries to court for “knowingly deceiving” the public, said Wiles, could force them to change their business models.</p><p>“I think the first step in solving the problem is holding the companies accountable,” he said.</p><p>Judith Enck, a former regional administrator for the Environmental Protection Agency and founder of the advocacy group Beyond Plastics, called the analysis “very solid”.</p><p>“The report should be read by every attorney general in the nation and the Federal Trade Commission,” she said.</p><p>Brian Frosh, the former attorney general for the state of Maryland, said the report includes the kind of evidence he would not normally expect to see until a lawsuit has already gone through a process of discovery.</p><p>“If I were attorney general, based on what I read in CCI’s report, I’d feel comfortable pressing for an investigation and a lawsuit,” he said.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PWAs wont replace native iOS apps (180 pts)]]></title>
            <link>https://app.campsite.co/campsite/p/notes/rengvq2txami</link>
            <guid>39387304</guid>
            <pubDate>Thu, 15 Feb 2024 19:28:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://app.campsite.co/campsite/p/notes/rengvq2txami">https://app.campsite.co/campsite/p/notes/rengvq2txami</a>, See on <a href="https://news.ycombinator.com/item?id=39387304">Hacker News</a></p>
<div id="readability-page-1" class="page"><a href="#main">Skip to content</a><div id="__next"><nav><a href="https://www.campsite.co/"><svg width="26" height="14" viewBox="0 0 34 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0.140151 16.4649L9.5715 0.490928C9.75112 0.186693 10.0782 0 10.4316 0H25.7959C26.569 0 27.049 0.840284 26.6561 1.50582L17.2247 17.4798C17.0451 17.7841 16.718 17.9708 16.3646 17.9708H1.00028C0.227176 17.9708 -0.252794 17.1305 0.140151 16.4649Z" fill="currentColor"></path><path d="M22.2255 17.9707H32.9577C33.7108 17.9707 34.193 17.1691 33.8398 16.5042L28.7719 6.96112C28.4064 6.27298 27.4284 6.24978 27.0307 6.91981L21.3666 16.4628C20.9715 17.1284 21.4514 17.9707 22.2255 17.9707Z" fill="currentColor"></path></svg></a><a data-state="closed" href="https://www.campsite.co/"><span><span>Made with Campsite</span></span></a></nav><main><div><p>Ryan Nystrom</p></div></main><!--$--><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple confirms iOS 17.4 removes Home Screen web apps in the EU (106 pts)]]></title>
            <link>https://9to5mac.com/2024/02/15/ios-17-4-web-apps-european-union/</link>
            <guid>39386244</guid>
            <pubDate>Thu, 15 Feb 2024 18:20:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5mac.com/2024/02/15/ios-17-4-web-apps-european-union/">https://9to5mac.com/2024/02/15/ios-17-4-web-apps-european-union/</a>, See on <a href="https://news.ycombinator.com/item?id=39386244">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="800" src="https://9to5mac.com/wp-content/uploads/sites/6/2024/01/app-store-security.webp?w=1600" alt="App Store security" srcset="https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/01/app-store-security.webp?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/01/app-store-security.webp?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/01/app-store-security.webp?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2024/01/app-store-security.webp?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>iOS 17.4 offers a number of changes for the App Store and iPhone in the European Union. This includes things <a href="https://9to5mac.com/2024/01/25/third-party-default-browsers-engines/" target="_blank" rel="noreferrer noopener">like third-party app marketplaces</a> and <a href="https://9to5mac.com/2024/01/25/third-party-default-browsers-engines/">support for alternative browser engines</a>. One byproduct of these changes, however, is that iOS 17.4 removes support for Home Screen web apps in the EU. </p>



<p>Apple has now offered an explanation for this decision, confirming that the omission was not a bug. Instead, it’s because of requirements under the Digital Markets Act. </p>



<h2 id="h-web-apps-on-ios-17-4-in-the-eu">Web apps on iOS 17.4 in the EU</h2>



<p>Last week, iPhone users in the European Union noticed that they were no longer able to install and run web apps on their iPhone’s Home Screen in iOS 17.4. Apple has added a number of features over the years to improve support for progressive web apps on iPhone. For example,&nbsp;<a href="https://9to5mac.com/2023/02/16/iphone-web-app-new-features-ios-16-4/" target="_blank" rel="noreferrer noopener">iOS 16.4 allowed PWAs to deliver push notifications with icon badges</a>.</p>



<p>One change in iOS 17.4 is that the iPhone now supports alternative browser engines in the EU. This allows companies to build browsers that don’t use Apple’s WebKit engine for the first time. Apple says that this change, required by the Digital Markets Act, is why it has been forced to remove Home Screen web apps support in the European Union. </p>



<p>Apple explains that it would have to build an “entirely new integration architecture that does not currently exist in iOS” to address the “complex security and privacy concerns associated with web apps using alternative browser engines.” </p>



<p>This work “was not practical to undertake given the other demands of the DMA and the very low user adoption of Home Screen web apps,” Apple explains. “And so, to comply with the DMA’s requirements, we had to remove the Home Screen web apps feature in the EU.” </p>



<p>“EU users will be able to continue accessing websites directly from their Home Screen through a bookmark with minimal impact to their functionality,” Apple continues. </p>



<p>It’s understandable that Apple wouldn’t offer support for Home Screen web apps for third-party browsers. But why did it also remove support for Home Screen web apps for Safari? Unfortunately, that’s another side effect of the Digital Markets Act. </p>



<p>The DMA requires that all browsers have equality, meaning that Apple can’t favor Safari and WebKit over third-party browser engines. Therefore, because it can’t offer Home Screen web apps support for third-party browsers, it also can’t offer support via Safari. </p>



<p>Apple’s full explanation follows, which was published on <a href="https://developer.apple.com/support/dma-and-apps-in-the-eu#dev-qaa">Apple’s developer website today</a>: </p>



<blockquote>
<p>To comply with the Digital Markets Act, Apple has done an enormous amount of engineering work to add new functionality and capabilities for developers and users in the European Union – including more than 600 new APls and a wide range of developer tools. </p>



<p>The iOS system has traditionally provided support for Home Screen web apps by building directly on WebKit and its security architecture. That integration means Home Screen web apps are managed to align with the security and privacy model for native apps on iOS, including isolation of storage and enforcement of system prompts to access privacy impacting capabilities on a per-site basis.</p>



<p>Without this type of isolation and enforcement, malicious web apps could read data from other web apps and recapture their permissions to gain access to a user’s camera, microphone or location without a user’s consent. Browsers also could install web apps on the system without a user’s awareness and consent. Addressing the complex security and privacy concerns associated with web apps using alternative browser engines would require building an entirely new integration architecture that does not currently exist in iOS and was not practical to undertake given the other demands of the DMA and the very low user adoption of Home Screen web apps. And so, to comply with the DMA’s requirements, we had to remove the Home Screen web apps feature in the EU.</p>



<p>EU users will be able to continue accessing websites directly from their Home Screen through a bookmark with minimal impact to their functionality. We expect this change to affect a small number of users. Still, we regret any impact this change — that was made as part of the work to comply with the DMA — may have on developers of Home Screen web apps and our</p>
</blockquote>



<p>iOS 17.4 is currently available to developers and public beta testers, and is slated for a release in early March. </p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Mac to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sora: Creating video from text (3135 pts)]]></title>
            <link>https://openai.com/sora</link>
            <guid>39386156</guid>
            <pubDate>Thu, 15 Feb 2024 18:14:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/sora">https://openai.com/sora</a>, See on <a href="https://news.ycombinator.com/item?id=39386156">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="capabilities"><div><p>We’re teaching AI to understand and simulate the physical world in motion, with the goal of training models that help people solve problems that require real-world interaction.</p><p>Introducing Sora, our text-to-video model. Sora can generate videos up to a minute long while maintaining visual quality and adherence to the user’s prompt.</p></div><div><p>Today, Sora is becoming available to red teamers to assess critical areas for harms or risks. We are also granting access to a number of visual artists, designers, and filmmakers to gain feedback on how to advance the model to be most helpful for creative professionals.</p><p>We’re sharing our research progress early to start working with and getting feedback from people outside of OpenAI and to give the public a sense of what AI capabilities are on the horizon.</p></div><div><!----><p>Sora is able to generate complex scenes with multiple characters, specific types of motion, and accurate details of the subject and background. The model understands not only what the user has asked for in the prompt, but also how those things exist in the physical world.</p></div><div><!----><p>The model has a deep understanding of language, enabling it to accurately interpret prompts and generate compelling characters that express vibrant emotions. Sora can also create multiple shots within a single generated video that accurately persist characters and visual style.</p></div><div><p>The current model has weaknesses. It may struggle with accurately simulating the physics of a complex scene, and may not understand specific instances of cause and effect. For example, a person might take a bite out of a cookie, but afterward, the cookie may not have a bite mark.</p><p>The model may also confuse spatial details of a prompt, for example, mixing up left and right, and may struggle with precise descriptions of events that take place over time, like following a specific camera trajectory.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unreal Engine 5 ported to WebGPU (139 pts)]]></title>
            <link>https://twitter.com/spatialweeb/status/1757581115609817236</link>
            <guid>39385739</guid>
            <pubDate>Thu, 15 Feb 2024 17:45:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/spatialweeb/status/1757581115609817236">https://twitter.com/spatialweeb/status/1757581115609817236</a>, See on <a href="https://news.ycombinator.com/item?id=39385739">Hacker News</a></p>
Couldn't get https://twitter.com/spatialweeb/status/1757581115609817236: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Fitness trackers find new symptom of depression: body temperature (139 pts)]]></title>
            <link>https://www.sacbee.com/news/nation-world/national/article285256032.html</link>
            <guid>39385683</guid>
            <pubDate>Thu, 15 Feb 2024 17:41:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sacbee.com/news/nation-world/national/article285256032.html">https://www.sacbee.com/news/nation-world/national/article285256032.html</a>, See on <a href="https://news.ycombinator.com/item?id=39385683">Hacker News</a></p>
Couldn't get https://www.sacbee.com/news/nation-world/national/article285256032.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Feds want to ban the Flipper Zero – Experts say it's a scapegoat (250 pts)]]></title>
            <link>https://www.vice.com/en/article/4a388g/flipper-zero-ban-canada-hacking-car-thefts</link>
            <guid>39385301</guid>
            <pubDate>Thu, 15 Feb 2024 17:15:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vice.com/en/article/4a388g/flipper-zero-ban-canada-hacking-car-thefts">https://www.vice.com/en/article/4a388g/flipper-zero-ban-canada-hacking-car-thefts</a>, See on <a href="https://news.ycombinator.com/item?id=39385301">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="BodyComponentRenderer"><p><span data-component="TextBlock"><p>The government of Canada has its sights set on banning the Flipper Zero, an adorable handheld hacking device that is cherished by security researchers and hobbyist hackers and has gained <a href="https://www.wired.com/story/what-is-flipper-zero-tiktok/" target="_blank"><span>a sizable following on TikTok</span></a>.&nbsp;</p></span><span data-component="TextBlock"><p>The device is modeled and named after the virtual dolphin from the movie <em>Johnny Mnemonic</em>, and it’s essentially <a href="https://www.vice.com/en/article/bvxyjm/meet-flipper-the-tamagotchi-you-feed-by-hacking-stuff"><span>a Tamagotchi you can use to hack stuff</span></a>. Flipper can scan radio frequencies and clone key fobs, control infrared-based devices, and is generally a kind of Swiss Army knife for security researchers, who actually <a href="https://www.packetlabs.net/posts/flipper-zero/" target="_blank"><span>use it to improve device security</span></a>. It’s also used by hobbyists who like playing around with computers,&nbsp; and more generally it’s just really adorable. But there's a lot of <a href="https://www.zdnet.com/home-and-office/flipper-zero-can-you-really-hack-wi-fi-networks-and-other-questions-answered/" target="_blank"><span>misinformation floating around</span></a> about its capabilities due to bombastic—and often staged—videos on TikTok and other social media platforms.</p></span><span></span><span data-component="TextBlock"><p>Flipper’s popularity has resulted in the device being named as a target in an upcoming National Summit on Combating Auto Theft, where the Canadian government claims, without any evidence, that the device is being used to steal cars.&nbsp;</p></span><span data-component="TextBlock"><p>“Criminals have been using sophisticated tools to steal cars. And Canadians are rightfully worried,” wrote François-Philippe Champagne, the Canadian Minister of Innovation, Science and Industry, in a tweet. “Today, I announced we are banning the importation, sale and use of consumer hacking devices, like flippers, used to commit these crimes.”</p></span><span data-component="TextBlock"><p>Canada <a href="https://www.vice.com/en/article/7kxdmx/one-regulation-could-have-stopped-a-nationwide-car-theft-wave-why-dont-we-have-it"><span>does have a problem with car thefts</span></a> at the moment tied to organized crime networks, but there's no evidence that Flipper Zero is playing a major role in these thefts. The Flipper Zero scans frequencies and records signals that can be replayed. While the Flipper Zero can do this for a car key fob, allowing a user to open a car with the device, it only works once due to the rolling codes that have been implemented by car makers for 30 years, and only if the key fob is first activated out of range of the car. <a href="https://www.youtube.com/watch?v=CGpMF_H0bUg" target="_blank"><span>More effective approaches</span></a> used by criminals involve actually plugging a device into a car with a cable or employing a "relay" (not replay) attack that involves two devices—one by the car and one near the fob, which tricks the car into thinking the owner is nearby.&nbsp;</p></span><span></span><span data-component="TextBlock"><p>Champagne linked a <a href="https://www.canada.ca/en/public-safety-canada/news/2024/02/government-of-canada-hosts-national-summit-on-combatting-auto-theft.html" target="_blank"><span>press release for an upcoming national summit</span></a> where government will be “Pursuing all avenues to ban devices used to steal vehicles by copying the wireless signals for remote keyless entry, such as the Flipper Zero, which would allow for the removal of those devices from the Canadian marketplace through collaboration with law enforcement agencies,” according to one the conference’s agenda items. The press release does not include any evidence that the device is being used for auto theft.</p></span></p><p><span data-component="TextBlock"><p>Naturally, this has riled digital rights groups and sections of the hacker and cybersecurity community, who are both upset and unsurprised that the Canadian government has their beloved Flipper in its crosshairs.&nbsp;</p></span><span data-component="TextBlock"><p>"We shouldn't be blaming manufacturers of radio transmitters for security lapses in the wireless unlock mechanisms of cars," Bill Budington, Senior Staff Technologist at the Electronic Frontier Foundation, said in a statement to Motherboard. "Flipper Zero devices, because of their ease of use, are convenient scapegoats to blame for gaping security holes in fob implementations by car manufacturers. Banning Flipper Zero devices is tantamount to banning a multi-tool because it can be used for vandalism, or banning markers because they can be used for graffiti. Moreover, tools like the Flipper Zero are used by security researchers involved in researching and hardening the security of systems like car fobs—banning them will result in tangible harms."</p></span><span></span><span data-component="TextBlock"><p>Canadian digital rights group OpenMedia concurred that banning the Flipper Zero would do more harm than good.&nbsp;</p></span><span data-component="TextBlock"><p>"A ban on sale of general purpose tools like the Flipper Zero will do more to hurt than help Canadian cybersecurity," said OpenMedia Executive Director Matt Hatfield. "The core problem here is the vulnerability of the keyless entry systems cars are using, not the fact that ordinary technology can reveal this vulnerability. By blocking the lawful sale of these devices, Canada will make it harder for cybersecurity researchers to do their work of testing vulnerabilities and informing the Canadian public, while doing little to prevent motivated car thieves from acquiring tools and exploiting these vulnerabilities."</p></span><span data-component="TextBlock"><p>When reached for comment, Flipper Devices COO Alex Kugalin reiterated that modern cars are largely protected from the simple attacks the device is capable of. “Flipper Zero can’t be used to hijack any car, specifically the ones produced after the 1990s, since their security systems have rolling codes. Also, it’d require actively blocking the signal from the owner to catch the original signal, which Flipper Zero’s hardware is incapable of doing”, said Alex Kulagin, COO of Flipper Devices. “Flipper Zero is intended for security testing and development and we have taken necessary precautions to ensure the device can’t be used for nefarious purposes."</p></span><span></span></p><p><span data-component="TextBlock"><p>The company pointed Motherboard to <a href="https://www.cyber.nj.gov/alerts-advisories/flipper-zero" target="_blank"><span>a January 2023 alert</span></a> from the New Jersey Cybersecurity &amp; Communications Integration Cell, a state organization. The alert stated that "most modern wireless devices are not vulnerable to simple replay attacks" and added that the Flipper Zero is unable to make purchases using signals captured from contactless credit cards. The alert also pointed to <a href="https://www.wired.com/story/what-is-flipper-zero-tiktok/" target="_blank"><span>reporting from Wired</span></a> that stated most of the dramatic videos on TikTok showing a Flipper Zero being used to steal a car are likely staged.&nbsp;</p></span><span data-component="TextBlock"><p>The proposed ban prompted bemused reactions from cybersecurity professionals on social media. “The only thing that can stop a bad guy with a Flipper Zero is a good guy with a Flipper Zero. I have a right to protect my family and community,” wrote security researcher Wesley McGrew, in a cheeky tweet referencing the frequently-used pro-gun rhetoric. McGrew also responded to Champagne’s post with a “Come And Take It” meme spinning off the popular <a href="https://en.wikipedia.org/wiki/Come_and_take_it" target="_blank"><span>libertarian slogan</span></a>.</p></span><span data-component="TextBlock"><p>Security experts lined up to lambaste the Canadian government and its insistence that the device is enabling crime. “Instant reactive thought… Isn’t stealing a car already a crime - that the criminal is ok breaking?” wrote security consultant Josh Corman.</p></span><span data-component="TextBlock"><p>Others mocked the government’s belief that devices like Flipper Zero are dangerous and all-powerful hacking tools. “I don’t find the Flipper to be that useful. Its built-in radio frequency support is barely more than you get from a good rooted phone. And I was unable to purchase the RF frequency modules because they were sold out. But imagine that *this* is considered a threat!” <a href="https://twitter.com/matthew_d_green/status/1755984810915385545" target="_blank"><span>wrote Matthew Green</span></a>, a professor of cryptography at Johns Hopkins University.</p></span><span data-component="TextBlock"><p><em>Jordan Pearson contributed reporting to this article.&nbsp;</em></p></span></p></div><div><p><h3>ORIGINAL REPORTING ON EVERYTHING THAT MATTERS IN YOUR INBOX.</h3></p><p>By signing up, you agree to the<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/terms-of-use.html">Terms of Use</a> <!-- -->and<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/privacy-policy.html">Privacy Policy</a> <!-- -->&amp; to receive electronic communications from Vice Media Group, which may include marketing promotions, advertisements and sponsored content.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Three Virtues of a Great Programmer (280 pts)]]></title>
            <link>https://thethreevirtues.com/</link>
            <guid>39385228</guid>
            <pubDate>Thu, 15 Feb 2024 17:10:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thethreevirtues.com/">https://thethreevirtues.com/</a>, See on <a href="https://news.ycombinator.com/item?id=39385228">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="85%">
	<tbody><tr>
	<td>
		<br><hr>
		<p>According to Larry Wall<sup>(1)</sup>, the original author of the Perl
		programming language, there are <b>three great virtues of a programmer</b>; Laziness, Impatience and Hubris</p>
		<ol>
			<li> <b>Laziness</b>: The quality that makes you go to great effort to
			reduce overall energy expenditure.  It makes you write labor-saving
			programs that other people will find useful and document what you
			wrote so you don't have to answer so many questions about it.</li>
			<li> <b>Impatience</b>: The anger you feel when the computer is being
			lazy.  This makes you write programs that don't just react to your
			needs, but actually anticipate them.  Or at least pretend to.</li>
			<li> <b>Hubris</b>: The quality that makes you write (and maintain)
			programs that other people won't want to say bad things about.</li>
		</ol>
		<hr>
	</td>
	</tr>
	</tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every Default macOS Wallpaper (460 pts)]]></title>
            <link>https://512pixels.net/projects/default-mac-wallpapers-in-5k/</link>
            <guid>39384731</guid>
            <pubDate>Thu, 15 Feb 2024 16:29:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://512pixels.net/projects/default-mac-wallpapers-in-5k/">https://512pixels.net/projects/default-mac-wallpapers-in-5k/</a>, See on <a href="https://news.ycombinator.com/item?id=39384731">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primary">
		<main id="main">

		
<article id="post-14130" class="page">
	<!-- .entry-header -->

	
<!--			<div class="post-thumbnail">-->
<!--				--><!--			</div>-->

		
	<div>
		<p>Every major version of <del>Mac OS X</del> macOS has come with a new default wallpaper. As you can see, I have collected them all here.</p>
<p>While great in their day, the early wallpapers are now quite small in the world of 5K and 6K displays.</p>
<p>If you want to see detailed screenshots of every release of OS X, <a href="https://512pixels.net/projects/aqua-screenshot-library/"><strong>click here.</strong></a></p>
<p>If you are looking for Mac OS 9 wallpapers, <a href="https://512pixels.net/projects/mac-os-9-5k-wallpapers/"><strong>this page is for you.</strong></a></p>
<h2>Sponsored by Rogue Amoeba</h2>

<p><a href="https://rogueamoeba.com/sentBy.php?512LIBRARY-2024"><img decoding="async" src="https://512pixels.net/wp-content/uploads/2023/12/512-banner-larger@2x.png"> </a></p>
<p>Rogue Amoeba is proud to continue our sponsorship of the 512 Pixels Mac Wallpaper Archive. We’ve been making amazing macOS audio software Aqua was the hot new thing.</p>
<p>From recording anything with Audio Hijack to getting superior control over all the sound on your Mac with SoundSource, we have tools for all your audio needs. Visit <a href="https://rogueamoeba.com/sentBy.php?512LIBRARY-2024">rogueamoeba.com</a> to learn about all our great utilities.</p>
<hr>
<h2>10.0 Cheetah &amp; 10.1 Puma</h2>
<p>The first two releases of Mac OS X shared the same wallpaper. The sweeping blue arcs and curves helped set the tone of the new Aqua interface.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-0_10.1--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-0_10.1.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-0_10-1-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.2 Jaguar</h2>
<p>Jaguar took the same Aqua-inspired theme but added some depth and motion to things. In my head, the trails streaking across the screen were from a set of comets.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-2--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-2.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-2-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.3 Panther</h2>
<p>While Panther inflicted Macs everywhere with <a href="https://512pixels.net/wp-content/uploads/2018/08/10-3-Panther-Command-Tab.png">Brushed Metal,</a> its wallpaper stayed on brand, refreshing the original 10.0 image.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-3--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-3.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-3-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.4 Tiger</h2>
<p>Many consider Tiger to be the best “classic” version of Mac OS X. While that may or may not be true, it is my favorite Aqua-inspired wallpaper.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-4--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-4.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-4-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.5 Leopard</h2>
<p>Complete with a revised, unified user interface and shiny new Dock, 10.5 broke the Aqua mold. As such, Leopard was the first version of OS X to break from the Aqua-themed wallpaper. It ushered in the “space era” of OS X wallpapers, which was used heavily in the new Time Machine interface as well.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-5--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-5.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-5-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.5 Leopard Server</h2>
<p>The server version of Leopard server came with its own unique wallpaper that is a real treat:</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-5-Server-thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-5-Server.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-5-Server-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.6 Snow Leopard</h2>
<p>The “no new features” mantra for Snow Leopard didn’t ban a new wallpaper, thankfully. This starscape is still one of my favorites. The Server version isn’t bad either!</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-6--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-6.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-6-6k.jpg"><strong>Download 6K version.</strong></a></p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-6-Server-thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-6-Server.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-6-Server-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.7 Lion</h2>
<p>Lion kept up the space theme, this time showing off the Andromeda galaxy. The space nerd in me likes the idea, but the execution of this one leaves dead-last on my list of favorites.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-7--thumb.png" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-7.png"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-7-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.8 Mountain Lion</h2>
<p>Just like Snow Leopard before it, with Mountain Lion, Apple opted to clean up and revise the existing theme as opposed to changing directions for what would be a less-impactful release of OS X.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-8--thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-8.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-8-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.9 Mavericks</h2>
<p>Mavericks marked the beginning of Apple’s “California location” naming scheme for Mac releases. The wave depicted looks as intimidating as the ones in the famous surfing location.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-9--thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-9.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-9-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.10 Yosemite</h2>
<p>Yosemite brought another UI refresh to the Mac, making things flatter and more modern. The wallpaper ushered in a new era based on … well … mountains.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-10--thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-10.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-10-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.11 El Capitan</h2>
<p>Named after a breathtaking spot in Yosemite National Park, El Capitan was a clean-up year after 10.10.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-11--thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-11.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-11-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.12 Sierra</h2>
<p>More mountains.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-12--thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-12.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-12-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.13 High Sierra</h2>
<p>Even more mountains.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-13--thumb.jpg" alt=""></p>
<p><a href="https://512pixels.net/downloads/macos-wallpapers/10-13.jpg"><strong>Download 5K version.</strong></a><br>
<a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-13-6k.jpg"><strong>Download 6K version.</strong></a></p>
<h2>10.14 Mojave</h2>
<p>No more mountains! Mojave brought a new system-wide Dark Mode, and the OS shipped with two versions of its default wallpaper to match. Users could even have macOS slowly fade between the two background images over the course of the day.</p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-14-Day-Thumb.jpg" alt=""></p>
<p><img decoding="async" src="https://512pixels.net/downloads/macos-wallpapers-thumbs/10-14-Night-Thumb.jpg" alt=""></p>
<p><strong>Download 5K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/10-14-Day.jpg">Mojave Day</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/10-14-Night.jpg">Mojave Night</a></li>
</ul>
<p><strong>Download 6K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-14-Day-6k.jpg">Mojave Day</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/10-14-Night-6k.jpg">Mojave Night</a></li>
</ul>
<h2>10.15 Catalina</h2>
<p>macOS Catalina brought big changes to the Mac, including the ability to run iPad apps natively, opening the platform up to a much larger number of developers than ever before. Catalina shipped with multiple variants of its default wallpaper, and the ability to shift between them as time progresses throughout the day:</p>
<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/512pixels.net\/projects\/default-mac-wallpapers-in-5k\/&quot;}" id="gallery-1"><figure>
			<p><img fetchpriority="high" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb.jpg 1400w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="19699" data-permalink="https://512pixels.net/projects/default-mac-wallpapers-in-5k/10-15-day-thumb/" data-orig-file="https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb.jpg" data-orig-size="1400,1400" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="10-15-Day-thumb" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2020/06/10-15-Day-thumb.jpg">
			</p></figure><figure>
			<p><img decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb.jpg 1400w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="19700" data-permalink="https://512pixels.net/projects/default-mac-wallpapers-in-5k/10-15-night-thumb/" data-orig-file="https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb.jpg" data-orig-size="1400,1400" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="10-15-Night-thumb" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2020/06/10-15-Night-thumb.jpg">
			</p></figure>
		</div>

<p><strong>Download 6K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/10-15-Day.jpg">Catalina Day</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/10-15-Night.jpg">Catalina Night</a></li>
</ul>
<h2>macOS Big Sur</h2>
<p>This version of macOS is such a big deal, Apple changed the version number to 11.0. It will be the OS that brings support for Apple Silicon-powered Macs, and features a brand new design.</p>


<p><strong>Download 6K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/11-0-Color-Day.jpg">Big Sur Colorful Day</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/11-0-Big-Sur-Color-Night.jpg">Big Sur Colorful Night</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/11-0-Day.jpg">Big Sur Day</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers/11-0-Night.jpg">Big Sur Night</a></li>
</ul>
<h2>macOS Monterey</h2>
<p>This version of macOS builds on Big Sur, bringing Shortcuts and a range of features that are also part of iOS and iPadOS 15. As of the first beta, Monterey does not include any new nature wallpapers as previous releases has.</p>
<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/512pixels.net\/projects\/default-mac-wallpapers-in-5k\/&quot;}" id="gallery-3"><figure>
			<p><img loading="lazy" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail.jpg 1400w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="22538" data-permalink="https://512pixels.net/12-light-thumbnail/" data-orig-file="https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail.jpg" data-orig-size="1400,1400" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="12-Light-thumbnail" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2021/06/12-Light-thumbnail.jpg">
			</p></figure><figure>
			<p><img loading="lazy" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail.jpg 1400w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="22537" data-permalink="https://512pixels.net/12-dark-thumbnail/" data-orig-file="https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail.jpg" data-orig-size="1400,1400" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="12-Dark-thumbnail" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2021/06/12-Dark-thumbnail.jpg">
			</p></figure>
		</div>

<p><strong>Download 6K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/12-Light.jpg">Monterey Light</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/12-Dark.jpg">Monterey Dark</a></li>
</ul>
<h2>macOS Ventura</h2>
<p>macOS 13 brings big changes to system apps like Mail and Messages, as well as a new multitasking user interface named Stage Manager.</p>
<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/512pixels.net\/projects\/default-mac-wallpapers-in-5k\/&quot;}" id="gallery-4"><figure>
			<p><img loading="lazy" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-1500x1500.jpg 1500w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb.jpg 2000w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-1536x1536.jpg 1536w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="24717" data-permalink="https://512pixels.net/projects/default-mac-wallpapers-in-5k/13-ventura-light-thumb/" data-orig-file="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb.jpg" data-orig-size="2000,2000" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="13-Ventura-Light-thumb" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-1500x1500.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Light-thumb-2000x2000.jpg">
			</p></figure><figure>
			<p><img loading="lazy" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-1500x1500.jpg 1500w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb.jpg 2000w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-1536x1536.jpg 1536w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="24716" data-permalink="https://512pixels.net/projects/default-mac-wallpapers-in-5k/13-ventura-dark-thumb/" data-orig-file="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb.jpg" data-orig-size="2000,2000" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="13-Ventura-Dark-thumb" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-1500x1500.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2022/06/13-Ventura-Dark-thumb-2000x2000.jpg">
			</p></figure>
		</div>

<p><strong>Download 6K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/13-Ventura-Light.jpg">Ventura Light</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/13-Ventura-Dark.jpg">Ventura Dark</a></li>
</ul>
<h2>macOS Sonoma</h2>
<p>macOS Sonoma brings several goodies, including the ability to use interactive widgets on the Desktop, enhanced video conferencing, updates to many core apps and the inclusion of stickers … for some reason.</p>
<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/512pixels.net\/projects\/default-mac-wallpapers-in-5k\/&quot;}" id="gallery-5"><figure>
			<p><img loading="lazy" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb-1500x1500.jpg 1500w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb-1536x1536.jpg 1536w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb.jpg 2000w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="27117" data-permalink="https://512pixels.net/projects/default-mac-wallpapers-in-5k/14-sonoma-light-thumb/" data-orig-file="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb.jpg" data-orig-size="2000,2000" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="14-Sonoma-Light-thumb" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb-1500x1500.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Light-thumb.jpg">
			</p></figure><figure>
			<p><img loading="lazy" decoding="async" width="500" height="500" src="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb-500x500.jpg" alt="" srcset="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb-500x500.jpg 500w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb-1500x1500.jpg 1500w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb-768x768.jpg 768w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb-1536x1536.jpg 1536w, https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb.jpg 2000w" sizes="(max-width: 500px) 100vw, 500px" data-attachment-id="27116" data-permalink="https://512pixels.net/projects/default-mac-wallpapers-in-5k/14-sonoma-dark-thumb/" data-orig-file="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb.jpg" data-orig-size="2000,2000" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="14-Sonoma-Dark-thumb" data-image-description="" data-image-caption="" data-medium-file="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb-1500x1500.jpg" data-large-file="https://512pixels.net/wp-content/uploads/2023/06/14-Sonoma-Dark-thumb.jpg">
			</p></figure>
		</div>

<p><strong>Download 6K versions:</strong></p>
<ul>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/14-Sonoma-Light.jpg">Sonoma Light</a></li>
<li><a href="https://512pixels.net/downloads/macos-wallpapers-6k/14-Sonoma-Dark.jpg">Sonoma Dark</a></li>
</ul>
<p><strong><a href="https://512pixels.net/membership/">Become a member of 512 Pixels.</a></strong> Support projects like these, receive exclusive content in the monthly newsletter and enjoy advanced screenings of my YouTube videos.</p>
	</div><!-- .entry-content -->

	</article><!-- #post-14130 -->

		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The existence of a new kind of magnetism has been confirmed (195 pts)]]></title>
            <link>https://www.newscientist.com/article/2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed/</link>
            <guid>39384458</guid>
            <pubDate>Thu, 15 Feb 2024 16:12:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newscientist.com/article/2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed/">https://www.newscientist.com/article/2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed/</a>, See on <a href="https://news.ycombinator.com/item?id=39384458">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        <header>
                                                            <h4>
                                                                        <a href="https://www.newscientist.com/subject/physics/" data-analytics-hook="article-header-subject-link">Physics</a>
                                </h4>
                                                        
                            

                            
                                                            <p>Altermagnets, theorised to exist but never before seen, have been measured for the first time and they could help us make new types of magnetic computers</p>
                            
                            
                            
                            <p>
        
<a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.newscientist.com%2Farticle%2F2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed%2F" target="_blank" rel="nofollow" data-social-platform="facebook" aria-label="Link to Facebook / Meta">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" version="1.1" role="img" fill="rgb(0, 0, 0)">
    <title>Facebook / Meta</title>
    <g>
        <path d="M22 5.16c-.406-.054-1.806-.16-3.43-.16-3.4 0-5.733 1.825-5.733 5.17v2.882H9v3.913h3.837V27h4.604V16.965h3.823l.587-3.913h-4.41v-2.5c0-1.123.347-1.903 2.198-1.903H22V5.16z" fill-rule="evenodd"></path>
    </g>
    </svg>
</a>
        
<a href="https://twitter.com/share?url=https%3A%2F%2Fwww.newscientist.com%2Farticle%2F2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed%2F" target="_blank" rel="nofollow" data-social-platform="twitter" aria-label="Link to Twitter / X">
    <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="none" viewBox="0 0 22 22">
        <title>Twitter / X icon</title>
        <path fill="#000" d="m12.21 9.814 5.644-6.556h-1.338l-4.9 5.692L7.7 3.258H3.185l5.92 8.608-5.92 6.875h1.338L9.7 12.73l4.134 6.011h4.515L12.21 9.814Zm-1.833 2.128-.6-.857-4.772-6.821H7.06l3.851 5.505.6.857 5.006 7.155h-2.055l-4.085-5.839Z"></path>
    </svg>
</a>
    <a href="whatsapp://send?text=The%20existence%20of%20a%20new%20kind%20of%20magnetism%20has%20been%20confirmed%20https://www.newscientist.com/article/2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed/" data-action="share/whatsapp/share" target="_blank" rel="nofollow" data-social-platform="whatsapp">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" version="1.1" role="img" style="fill: rgb(0, 0, 0);">
        <g>
            <path d="M19.11 17.205c-.372 0-1.088 1.39-1.518 1.39a.63.63 0 0 1-.315-.1c-.802-.402-1.504-.817-2.163-1.447-.545-.516-1.146-1.29-1.46-1.963a.426.426 0 0 1-.073-.215c0-.33.99-.945.99-1.49 0-.143-.73-2.09-.832-2.335-.143-.372-.214-.487-.6-.487-.187 0-.36-.043-.53-.043-.302 0-.53.115-.746.315-.688.645-1.032 1.318-1.06 2.264v.114c-.015.99.472 1.977 1.017 2.78 1.23 1.82 2.506 3.41 4.554 4.34.616.287 2.035.888 2.722.888.817 0 2.15-.515 2.478-1.318.13-.33.244-.73.244-1.088 0-.058 0-.144-.03-.215-.1-.172-2.434-1.39-2.678-1.39zm-2.908 7.593c-1.747 0-3.48-.53-4.942-1.49L7.793 24.41l1.132-3.337a8.955 8.955 0 0 1-1.72-5.272c0-4.955 4.04-8.995 8.997-8.995S25.2 10.845 25.2 15.8c0 4.958-4.04 8.998-8.998 8.998zm0-19.798c-5.96 0-10.8 4.842-10.8 10.8 0 1.964.53 3.898 1.546 5.574L5 27.176l5.974-1.92a10.807 10.807 0 0 0 16.03-9.455c0-5.958-4.842-10.8-10.802-10.8z" fill-rule="evenodd"></path>
        </g>
    </svg>
</a>
        
<a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fwww.newscientist.com%2Farticle%2F2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed%2F" target="_blank" rel="nofollow" data-social-platform="linkedin" aria-label="Link to Linkedin">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" version="1.1" role="img" style="fill: rgb(0, 0, 0);">
    <title>Linkedin</title>
    <g>
        <path d="M26 25.963h-4.185v-6.55c0-1.56-.027-3.57-2.175-3.57-2.18 0-2.51 1.7-2.51 3.46v6.66h-4.182V12.495h4.012v1.84h.058c.558-1.058 1.924-2.174 3.96-2.174 4.24 0 5.022 2.79 5.022 6.417v7.386zM8.23 10.655a2.426 2.426 0 0 1 0-4.855 2.427 2.427 0 0 1 0 4.855zm-2.098 1.84h4.19v13.468h-4.19V12.495z" fill-rule="evenodd"></path>
    </g>
    </svg>
</a>
        
<a href="https://reddit.com/submit?url=https%3A%2F%2Fwww.newscientist.com%2Farticle%2F2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed%2F&amp;title=The%20existence%20of%20a%20new%20kind%20of%20magnetism%20has%20been%20confirmed" target="_blank" rel="nofollow" data-social-platform="reddit">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" version="1.1" role="img" style="fill: rgb(0, 0, 0);">
        <g>
            <path d="M27 15.5a2.452 2.452 0 0 1-1.338 2.21c.098.38.147.777.147 1.19 0 1.283-.437 2.47-1.308 3.563-.872 1.092-2.06 1.955-3.567 2.588-1.506.634-3.143.95-4.91.95-1.768 0-3.403-.316-4.905-.95-1.502-.632-2.69-1.495-3.56-2.587-.872-1.092-1.308-2.28-1.308-3.562 0-.388.045-.777.135-1.166a2.47 2.47 0 0 1-1.006-.912c-.253-.4-.38-.842-.38-1.322 0-.678.237-1.26.712-1.744a2.334 2.334 0 0 1 1.73-.726c.697 0 1.29.26 1.78.782 1.785-1.258 3.893-1.928 6.324-2.01l1.424-6.467a.42.42 0 0 1 .184-.26.4.4 0 0 1 .32-.063l4.53 1.006c.147-.306.368-.553.662-.74a1.78 1.78 0 0 1 .97-.278c.508 0 .94.18 1.302.54.36.36.54.796.54 1.31 0 .512-.18.95-.54 1.315-.36.364-.794.546-1.302.546-.507 0-.94-.18-1.295-.54a1.793 1.793 0 0 1-.533-1.308l-4.1-.92-1.277 5.86c2.455.074 4.58.736 6.37 1.985a2.315 2.315 0 0 1 1.757-.757c.68 0 1.256.242 1.73.726.476.484.713 1.066.713 1.744zm-16.868 2.47c0 .513.178.95.534 1.315.356.365.787.547 1.295.547.508 0 .942-.182 1.302-.547.36-.364.54-.802.54-1.315 0-.513-.18-.95-.54-1.31-.36-.36-.794-.54-1.3-.54-.5 0-.93.183-1.29.547a1.79 1.79 0 0 0-.54 1.303zm9.944 4.406c.09-.09.135-.2.135-.323a.444.444 0 0 0-.44-.447c-.124 0-.23.042-.32.124-.336.348-.83.605-1.486.77a7.99 7.99 0 0 1-1.964.248 7.99 7.99 0 0 1-1.964-.248c-.655-.165-1.15-.422-1.486-.77a.456.456 0 0 0-.32-.124.414.414 0 0 0-.306.124.41.41 0 0 0-.135.317.45.45 0 0 0 .134.33c.352.355.837.636 1.455.843.617.207 1.118.33 1.503.366a11.6 11.6 0 0 0 1.117.056c.36 0 .733-.02 1.117-.056.385-.037.886-.16 1.504-.366.62-.207 1.104-.488 1.456-.844zm-.037-2.544c.507 0 .938-.182 1.294-.547.356-.364.534-.802.534-1.315 0-.505-.18-.94-.54-1.303a1.75 1.75 0 0 0-1.29-.546c-.506 0-.94.18-1.3.54-.36.36-.54.797-.54 1.31s.18.95.54 1.315c.36.365.794.547 1.3.547z" fill-rule="evenodd"></path>
        </g>
    </svg>
</a>
    <a href="mailto:?subject=The%20existence%20of%20a%20new%20kind%20of%20magnetism%20has%20been%20confirmed&amp;body=Altermagnets%2C%20theorised%20to%20exist%20but%20never%20before%20seen%2C%20have%20been%20measured%20for%20the%20first%20time%20and%20they%20could%20help%20us%20make%20new%20types%20of%20magnetic%20computers%0D%0Aread%20more:%20https%3A%2F%2Fwww.newscientist.com%2Farticle%2F2417255-the-existence-of-a-new-kind-of-magnetism-has-been-confirmed%2F" target="_blank" rel="nofollow" data-social-platform="email">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" version="1.1" role="img" style="fill: rgb(0, 0, 0);">
        <g>
            <g fill-rule="evenodd"></g>
            <path d="M27 22.757c0 1.24-.988 2.243-2.19 2.243H7.19C5.98 25 5 23.994 5 22.757V13.67c0-.556.39-.773.855-.496l8.78 5.238c.782.467 1.95.467 2.73 0l8.78-5.238c.472-.28.855-.063.855.495v9.087z"></path><path d="M27 9.243C27 8.006 26.02 7 24.81 7H7.19C5.988 7 5 8.004 5 9.243v.465c0 .554.385 1.232.857 1.514l9.61 5.733c.267.16.8.16 1.067 0l9.61-5.733c.473-.283.856-.96.856-1.514v-.465z"></path>
        </g>
    </svg>
</a>
    <a rel="nofollow" tabindex="0">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32" version="1.1" role="img" style="fill: rgb(0, 0, 0);">
        <g>
            <path d="M24.67 10.62h-2.86V7.49H10.82v3.12H7.95c-.5 0-.9.4-.9.9v7.66h3.77v1.31L15 24.66h6.81v-5.44h3.77v-7.7c-.01-.5-.41-.9-.91-.9zM11.88 8.56h8.86v2.06h-8.86V8.56zm10.98 9.18h-1.05v-2.1h-1.06v7.96H16.4c-1.58 0-.82-3.74-.82-3.74s-3.65.89-3.69-.78v-3.43h-1.06v2.06H9.77v-3.58h13.09v3.61zm.75-4.91c-.4 0-.72-.32-.72-.72s.32-.72.72-.72c.4 0 .72.32.72.72s-.32.72-.72.72zm-4.12 2.96h-6.1v1.06h6.1v-1.06zm-6.11 3.15h6.1v-1.06h-6.1v1.06z"></path>
        </g>
    </svg>
</a></p>                        </header>
                    </div><section>
                    <figure data-method="caption-shortcode"><p><img src="https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=1200" data-src="https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=1200" srcset="https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=100 100w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=200 200w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=249 249w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=300 300w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=400 400w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=500 500w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=600 600w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=700 700w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=800 800w, https://images.newscientist.com/wp-content/uploads/2024/02/14153321/SEI_191483493.jpg?width=900 900w" sizes="(min-width: 1130px) 900px, (min-width: 1025px) 900, (min-width: 768px) calc(100vw - 30px), calc(100vw - 30px)" alt="Illustration of altermagnetism in a chemical compound" width="1348" height="900" data-credit="Libor Šmejkal and Anna Birk Hellenes" data-caption="Altermagnetism works differently from standard magnetism"></p><figcaption><div><p>Altermagnetism works differently from standard magnetism</p><p>Libor Šmejkal and Anna Birk Hellenes</p></div></figcaption></figure>
<p>A new kind of magnetism has been measured for the first time. Altermagnets, which contain a blend of properties from different classes of existing magnets, could be used to make high capacity and fast memory devices or new kinds of magnetic computers.</p>
<p>Until the 20th century, there was thought to be only one kind of <a href="https://www.newscientist.com/article/mg24432580-500-exotic-super-magnets-could-shake-up-medicine-cosmology-and-computing/">permanent magnet</a>, a ferromagnet, the effects of which can be seen in objects with relatively strong external magnetic fields like fridge magnets or compass needles.</p>

    
<p>These fields are caused by the magnetic spins of the magnets’ electrons lining up in one direction.</p>
<p>But, in the 1930s, French physicist Louis Néel discovered another kind of magnetism, <a href="https://www.newscientist.com/article/weird-magnets-make-computers-work-1000-times-faster/">called antiferromagnetism</a>, where the electrons’ spins are alternately up and down. Although antiferromagnets lack the external fields of ferromagnets, they do show interesting internal magnetic properties because of the alternating spins.</p>
<p>Then in 2019, <a href="https://arxiv.org/abs/1901.00445">researchers predicted a perplexing electric current in the crystal structure of certain antiferromagnets, called the anomalous Hall effect</a>, which couldn’t be explained by the conventional theory of alternating spins. The current was moving without any external magnetic field.</p>
<span></span><p>It seemed, when looking at a crystal in terms of sheets of spins, that <a href="https://arxiv.org/abs/2105.05820">a third kind of permanent magnetism might be responsible, which has been called altermagnetism.</a> Altermagnets would look like antiferromagnets, but the sheets of spins would look the same when rotated from any angle. This would explain the Hall effect, but no one had seen the electronic signature of this structure itself, so scientists were unsure whether it was definitely a new kind of magnetism.</p>
<p>Now, <a href="https://www.psi.ch/en/lno/people/juraj-krempasky">Juraj Krempasky</a> at the Paul Scherrer Institute in Villigen, Switzerland, and his colleagues have confirmed the existence of an altermagnet by measuring the electron structure in a crystal, manganese telluride, that was previously thought to be antiferromagnetic.</p>
    
<p>To do this, they gauged how light bounced off manganese telluride to find the energies and speeds of the electrons inside the crystal. After mapping out these electrons, they were found to almost exactly match the predictions given by simulations for an altermagnetic material.</p>
<p>The electrons seemed to be split into two groups, which allows them more movement inside the crystal and is the source of the unusual altermagnetic properties. “This gave direct evidence that we can talk about altermagnets and that they behave exactly as predicted by theory,” says Krempasky.</p>

    
<p>This electron grouping seems to come from the atoms of tellurium, which is non-magnetic, in the crystal structure, which separate the magnetic charges of the manganese into their own planes and allow the unusual rotational symmetry.</p>
<p>“It’s really nice verification that these materials do exist,” says <a href="https://www.york.ac.uk/physics-engineering-technology/people/physics-staff-richard-evans/">Richard Evans</a> at the University of York, UK. As well as the electrons in altermagnets being freer to move than those in antiferromagnets, this new type of magnet also doesn’t have external magnetic fields like in ferromagnets, says Evans, so you can use them to make magnetic devices that don’t interfere with each other.</p>
<p>The property could boost the storage on computer hard drives, because commercial devices contain ferromagnetic material that is so tightly packed that the material’s external magnetic fields start to see interference – altermagnets could be packed more densely.</p>
<p>The magnets could even lead to spintronic computers that use magnetic spin instead of current to perform their measurements and calculations, says <a href="https://eps.leeds.ac.uk/physics/staff/5729/dr-joseph-barker">Joseph Barker</a> at the University of Leeds, UK, combining memory and computer chips into one device. “It maybe gives more hope to the idea that we could make spintronic devices become a reality,” says Barker.</p>


                    <div><h4>Article amended on 15 February 2024</h4><p>We have corrected when Louis Néel discovered antiferromagnetism and the name of the crystal studied to confirm the existence of altermagnetism.</p></div><section><p>Topics:</p></section>                </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Asahi Linux project's OpenGL support on Apple Silicon officially surpasses Apple (358 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/02/asahi-linux-projects-opengl-support-on-apple-silicon-officially-surpasses-apples/</link>
            <guid>39383798</guid>
            <pubDate>Thu, 15 Feb 2024 15:26:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/02/asahi-linux-projects-opengl-support-on-apple-silicon-officially-surpasses-apples/">https://arstechnica.com/gadgets/2024/02/asahi-linux-projects-opengl-support-on-apple-silicon-officially-surpasses-apples/</a>, See on <a href="https://news.ycombinator.com/item?id=39383798">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      who needs metal?    —
</h4>
            
            <h2 itemprop="description">Newest driver supports the latest versions of OpenGL and OpenGL ES.</h2>
                    </header>
        <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2022/03/asahi-macbook-800x450.jpg" alt="Slowly but surely, the Asahi Linux team is getting Linux up and running on Apple Silicon Macs.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2022/03/asahi-macbook.jpg" data-height="1080" data-width="1920">Enlarge</a> <span>/</span> Slowly but surely, the Asahi Linux team is getting Linux up and running on Apple Silicon Macs.</p><p>Apple/Asahi Linux</p></figcaption>  </figure>

  




<!-- cache hit 2:single/related:356a9a52863033d61adc4d1aa1b1cbb1 --><!-- empty -->
<p>For around three years now, the team of independent developers behind the Asahi Linux project has worked to support Linux on Apple Silicon Macs, despite Apple's total lack of involvement. Over the years, the project has gone from a "highly unstable experiment" to a "surprisingly functional and usable desktop operating system." Even Linus Torvalds has used it to run Linux on Apple's hardware.</p>
<p>The team has been steadily improving its open source, standards-conformant GPU driver for the M1 and M2 since releasing them <a href="https://rosenzweig.io/blog/asahi-gpu-part-7.html">in December 2022</a>, and today, the team crossed an important symbolic milestone: The Asahi driver's support for the OpenGL and OpenGL ES graphics have officially passed what Apple offers in macOS. The team's latest graphics driver fully conforms with OpenGL version 4.6 and OpenGL ES version 3.2, the most recent version of either API. Apple's support in macOS tops out at OpenGL 4.1, announced in July 2010.</p>
<p>Developer Alyssa Rosenzweig wrote <a href="https://rosenzweig.io/blog/conformant-gl46-on-the-m1.html">a detailed blog post</a> that announced the new driver, which had to pass "over 100,000 tests" to be deemed officially conformant. The team achieved this milestone despite the fact that Apple's GPUs don't support some features that would have made implementing these APIs more straightforward.</p>
<p>"Regrettably, the M1 doesn’t map well to any graphics standard newer than OpenGL ES 3.1," writes Rosenzweig. "While Vulkan makes some of these features optional, the missing features are required to layer DirectX and OpenGL on top. No existing solution on M1 gets past the OpenGL 4.1 feature set... Without hardware support, new features need new tricks. Geometry shaders, tessellation, and transform feedback become compute shaders. Cull distance becomes a transformed interpolated value. Clip control becomes a vertex shader epilogue. The list goes on."</p>                                            
                                                        

<p>Now that the Asahi GPU driver supports the latest OpenGL and OpenGL ES standards—released in 2017 and 2015, respectively—the work turns to supporting the low-overhead Vulkan API on Apple's hardware. Vulkan support in macOS is limited to translation layers like MoltenVK, which translates Vulkan API calls to Metal ones that the hardware and OS can understand.</p>
<p>Apple's OpenGL support has been stuck at the 4.1 level since macOS 10.9 Mavericks was released in 2013. Since then, the company has shifted its focus to its proprietary Metal graphics API, which, like DirectX 12 and Vulkan, is a "low-overhead" API meant to reduce the performance overhead sometimes associated with older APIs like OpenGL. But despite declaring OpenGL <a href="https://arstechnica.com/gadgets/2018/06/the-end-of-opengl-support-other-updates-apple-didnt-share-at-the-keynote/">officially deprecated</a> in 2018, Apple has left its existing OpenGL implementation alone since then, never updating it but also maintaining support even as it has transitioned from Intel's processors to its own CPUs and GPUs.</p>
<p>Rosenzweig's blog post didn't give any specific updates on Vulkan except to say that the team was "well on the road" to supporting it. In addition to supporting native Linux apps, supporting more graphics APIs in Asahi will allow the operating system to take better advantage of software like <a href="https://arstechnica.com/gaming/2023/04/proton-update-gets-18-more-windows-games-running-on-linux-including-chex-quest-hd/">Valve's Proton</a>, which already has a few games written for x86-based Windows PCs running on Arm-based Apple hardware.</p>
<p>Though there are still things that don't work, Fedora Asahi Remix is surprisingly polished and supports a lot of the hardware available in most M1 and M2 Macs—including the webcam, speakers, Wi-Fi and Bluetooth, and graphics acceleration. Other features, like Thunderbolt, running displays over USB-C, the system's built-in microphone, and the Touch ID fingerprint sensors, remain non-functional. Asahi's most recent update blog post, <a href="https://asahilinux.org/2024/01/fedora-asahi-new/">published in mid-January</a>, highlighted HDMI support, support for DRM-protected websites via Google's proprietary Widevine package, Touchbar support for the handful of Apple Silicon Macs that use one, and more.</p>
<p>As for the newest wave of M3 Macs, Asahi developer Hector Martin said in October 2023 that basic support for the newest chips would take "at least six months." Among other things, the team will need time to support the M3 GPU in their drivers; the team also relies primarily on Mac mini models for development, and the M3 Mac mini doesn't exist yet.</p>

                                                </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini 1.5 Pro (152 pts)]]></title>
            <link>https://twitter.com/JeffDean/status/1758146022726041615</link>
            <guid>39383593</guid>
            <pubDate>Thu, 15 Feb 2024 15:12:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/JeffDean/status/1758146022726041615">https://twitter.com/JeffDean/status/1758146022726041615</a>, See on <a href="https://news.ycombinator.com/item?id=39383593">Hacker News</a></p>
Couldn't get https://twitter.com/JeffDean/status/1758146022726041615: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Our next-generation model: Gemini 1.5 (988 pts)]]></title>
            <link>https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/</link>
            <guid>39383446</guid>
            <pubDate>Thu, 15 Feb 2024 15:02:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/">https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/</a>, See on <a href="https://news.ycombinator.com/item?id=39383446">Hacker News</a></p>
<div id="readability-page-1" class="page"><article ng-init="drawerToggle = {'open': true}">

    
    





    

    
      

<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
  }">
      
      
        <p>
          The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.
        </p>
      
    </div>

    

    
      







<div>
    <figure>
      <div>
  <p><img srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/final_gemini_1.5_blog_header_2096x1182-1.gif 600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/final_gemini_1.5_blog_header_2096x1182-1.gif 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/final_gemini_1.5_blog_header_2096x1182-1.gif 1600w" sizes="(max-width: 599px) 100vw, (max-width: 1023px) 600px, 1024px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/final_gemini_1.5_blog_header_2096x1182-1.gif" fetchpriority="high" alt="The word “Gemini 1.5” appears in a blue gradient against a black background.">
  </p>
</div>

      
    </figure>
  </div>


    

    
    <div>
        
          
            <div data-component="uni-article-jumplinks" data-analytics-module="{
    &quot;module_name&quot;: &quot;Article Jumplinks&quot;,
    &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
  }">
  <nav aria-label="Article Jumplinks">
    <p><span>In this story</span>
    </p>
    
    
    <div>
      <ul id="article-jumplinks__list">
        
        <li>
          <a aria-label="link to Note from Sundar" href="#sundar-note" id="sundar-note-anchor">Note from Sundar</a>
        </li>
        
        <li>
          <a aria-label="link to Introducing Gemini 1.5" href="#gemini-15" id="gemini-15-anchor">Introducing Gemini 1.5</a>
        </li>
        
        <li>
          <a aria-label="link to Efficient architecture" href="#architecture" id="architecture-anchor">Efficient architecture</a>
        </li>
        
        <li>
          <a aria-label="link to Long context window" href="#context-window" id="context-window-anchor">Long context window</a>
        </li>
        
        <li>
          <a aria-label="link to Enhanced performance" href="#performance" id="performance-anchor">Enhanced performance</a>
        </li>
        
        <li>
          <a aria-label="link to Ethics and safety testing" href="#ethics-safety" id="ethics-safety-anchor">Ethics and safety testing</a>
        </li>
        
        <li>
          <a aria-label="link to Build with Gemini" href="#build-experiment" id="build-experiment-anchor">Build with Gemini</a>
        </li>
        
      </ul>
    </div>
    
  </nav>
</div>
          
          
          <div data-reading-time="true" data-component="uni-drop-cap|uni-tombstone">

            
              


<google-read-aloud-player data-analytics-module="{
        &quot;event&quot;: &quot;module_impression&quot;,
        &quot;module_name&quot;: &quot;ai_audio&quot;,
        &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
    }" data-date-modified="2024-02-15T15:43:59.395802+00:00" data-progress-bar-style="half-wave" data-api-key="AIzaSyBLT6VkYe-x7sWLZI2Ep26-fNkBKgND-Ac" data-article-style="style9" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-layout-style="style1" data-highlight-mode="word-over-paragraph" data-highlight-text-color="#000000" data-highlight-word-background="#8AB4F8" data-highlight-paragraph-background="#D2E3FC" data-background="linear-gradient(180deg, #F1F3F4 0%, #F8F9FA 100%)" data-foreground-color="#202124" data-font="600 16px Google Sans, sans-serif" data-box-shadow="0px 1px 3px 1px rgba(60, 64, 67, 0.15)">
</google-read-aloud-player>




            

            
            
<!--article text-->

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><p data-block-key="k1g9k"><i>A note from Google and Alphabet CEO Sundar Pichai:</i></p><p data-block-key="43i75">Last week, we rolled out our most capable model, Gemini 1.0 Ultra, and took a significant step forward in making Google products more helpful, starting with <a href="https://blog.google/technology/ai/google-gemini-update-sundar-pichai-2024/" rt-link-type="external">Gemini Advanced</a>. Today, developers and Cloud customers can begin building with 1.0 Ultra too — with our Gemini API in <a href="https://aistudio.google.com/" rt-link-type="external">AI Studio</a> and in <a href="https://cloud.google.com/vertex-ai" rt-link-type="external">Vertex AI</a>.</p><p data-block-key="ebks5">Our teams continue pushing the frontiers of our latest models with safety at the core. They are making rapid progress. In fact, we’re ready to introduce the next generation: Gemini 1.5. It shows dramatic improvements across a number of dimensions and 1.5 Pro achieves comparable quality to 1.0 Ultra, while using less compute.</p><p data-block-key="aa73f">This new generation also delivers a breakthrough in long-context understanding. We’ve been able to significantly increase the amount of information our models can process — running up to 1 million tokens consistently, achieving the longest context window of any large-scale foundation model yet.</p><p data-block-key="31sii">Longer context windows show us the promise of what is possible. They will enable entirely new capabilities and help developers build much more useful models and applications. We’re excited to offer a limited preview of this experimental feature to developers and enterprise customers. Demis shares more on capabilities, safety and availability below.</p><p data-block-key="5ecmf">— Sundar</p></div>
  

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h2 data-block-key="k1g9k">Introducing Gemini 1.5</h2><p data-block-key="f3142"><i>By Demis Hassabis, CEO of Google DeepMind, on behalf of the Gemini team</i></p><p data-block-key="chshj">This is an exciting time for AI. New advances in the field have the potential to make AI more helpful for billions of people over the coming years. Since <a href="https://blog.google/technology/ai/google-gemini-ai/" rt-link-type="external">introducing Gemini 1.0</a>, we’ve been testing, refining and enhancing its capabilities.</p><p data-block-key="bpk1l">Today, we’re announcing our next-generation model: Gemini 1.5.</p><p data-block-key="cq31g">Gemini 1.5 delivers dramatically enhanced performance. It represents a step change in our approach, building upon research and engineering innovations across nearly every part of our foundation model development and infrastructure. This includes making Gemini 1.5 more efficient to train and serve, with a new <a href="https://arxiv.org/abs/1701.06538" rt-link-type="external">Mixture-of-Experts</a> (MoE) architecture.</p><p data-block-key="ei3s7">The first Gemini 1.5 model we’re releasing for early testing is Gemini 1.5 Pro. It’s a mid-size multimodal model, optimized for scaling across a wide-range of tasks, and <a href="https://goo.gle/GeminiV1-5" rt-link-type="external">performs at a similar level to 1.0 Ultra</a>, our largest model to date. It also introduces a breakthrough experimental feature in long-context understanding.</p><p data-block-key="73fdi">Gemini 1.5 Pro comes with a standard 128,000 token context window. But starting today, a limited group of developers and enterprise customers can try it with a context window of up to 1 million tokens via <a href="https://aistudio.google.com/" rt-link-type="external">AI Studio</a> and <a href="https://cloud.google.com/vertex-ai" rt-link-type="external">Vertex AI</a> in private preview.</p><p data-block-key="2n70l">As we roll out the full 1 million token context window, we’re actively working on optimizations to improve latency, reduce computational requirements and enhance the user experience. We’re excited for people to try this breakthrough capability, and we share more details on future availability below.</p><p data-block-key="3k946">These continued advances in our next-generation models will open up new possibilities for people, developers and enterprises to create, discover and build using AI.</p></div>
  

  
    







  
      <div data-analytics-module="{
          &quot;module_name&quot;: &quot;Inline Images&quot;,
          &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
        }">
  

  <p>

      
      
        
          <video tabindex="0" autoplay="" loop="" muted="" playsinline="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/final_tokens_scale_animated_3840x2300.mp4" type="video/mp4" title="Animation comparing the context lengths of leading foundation models, listing Gemini 1.0 Pro at 32,000 tokens, GPT-4 Turbo at 128,000 tokens, Claude 2.1 at 200,000 tokens, and Gemini 1.5 Pro at 1 million tokens and up to 10 million tokens tested in research." alt="final tokens animation">
            Video format not supported
          </video>
        
      
    
    </p>
    
      <figcaption><p data-block-key="vi55e">Context lengths of leading foundation models</p></figcaption>
    
  
    </div>
  



  

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h2 data-block-key="k1g9k">Highly efficient architecture</h2><p data-block-key="5l1m">Gemini 1.5 is built upon our leading research on <a href="https://blog.research.google/2017/08/transformer-novel-neural-network.html" rt-link-type="external">Transformer</a> and <a href="https://arxiv.org/abs/1701.06538" rt-link-type="external">MoE</a> architecture. While a traditional Transformer functions as one large neural network, MoE models are divided into smaller "expert” neural networks.</p><p data-block-key="bofgb">Depending on the type of input given, MoE models learn to selectively activate only the most relevant expert pathways in its neural network. This specialization massively enhances the model’s efficiency. Google has been an early adopter and pioneer of the MoE technique for deep learning through research such as <a href="https://arxiv.org/abs/1701.06538" rt-link-type="external">Sparsely-Gated MoE</a>, <a href="https://arxiv.org/abs/2006.16668" rt-link-type="external">GShard-Transformer</a>, <a href="https://arxiv.org/abs/2101.03961" rt-link-type="external">Switch-Transformer,</a> <a href="https://blog.research.google/2019/10/exploring-massively-multilingual.html" rt-link-type="external">M4</a> and more.</p><p data-block-key="829je">Our latest innovations in model architecture allow Gemini 1.5 to learn complex tasks more quickly and maintain quality, while being more efficient to train and serve. These efficiencies are helping our teams iterate, train and deliver more advanced versions of Gemini faster than ever before, and we’re working on further optimizations.</p></div>
  

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h2 data-block-key="k1g9k">Greater context, more helpful capabilities</h2><p data-block-key="4m4dc">An AI model’s “context window” is made up of tokens, which are the building blocks used for processing information. Tokens can be entire parts or subsections of words, images, videos, audio or code. The bigger a model’s context window, the more information it can take in and process in a given prompt — making its output more consistent, relevant and useful.</p><p data-block-key="7l6jt">Through a series of machine learning innovations, we’ve increased 1.5 Pro’s context window capacity far beyond the original 32,000 tokens for Gemini 1.0. We can now run up to 1 million tokens in production.</p><p data-block-key="djuni">This means 1.5 Pro can process vast amounts of information in one go — including 1 hour of video, 11 hours of audio, codebases with over 30,000 lines of code or over 700,000 words. In our research, we’ve also successfully tested up to 10 million tokens.</p><h3 data-block-key="9id65">Complex reasoning about vast amounts of information</h3><p data-block-key="572lb">1.5 Pro can seamlessly analyze, classify and summarize large amounts of content within a given prompt. For example, when given the 402-page transcripts from Apollo 11’s mission to the moon, it can reason about conversations, events and details found across the document.</p></div>
  

  
    
  
    


<div data-component="uni-article-yt-player" data-page-title="Our next-generation model: Gemini 1.5" data-video-id="LHKL_210CcU" data-index-id="10" data-analytics-module="{
    &quot;module_name&quot;: &quot;Youtube Video&quot;,
    &quot;section_header&quot;: &quot;undefined&quot;
  }">

    

    <a role="video" tabindex="0">
      <div>
        
          
          <p><img alt="Reasoning across a 402-page transcript: Gemini 1.5 Pro Demo" src="https://i.ytimg.com/vi_webp/LHKL_210CcU/default.webp" loading="lazy" data-loading="{
                &quot;mobile&quot;: &quot;//i.ytimg.com/vi_webp/LHKL_210CcU/sddefault.webp&quot;,
                &quot;desktop&quot;: &quot;//i.ytimg.com/vi_webp/LHKL_210CcU/maxresdefault.webp&quot;
              }"></p>

        
        <svg role="presentation">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button_no_hole"></use>
          
        </svg>
        <svg role="img">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button"></use>
          
        </svg>

        
        
        
        
      </div>
    </a>

    
      <p>Gemini 1.5 Pro can understand, reason about and identify curious details in the 402-page transcripts from Apollo 11’s mission to the moon.</p>
    

    
  </div>

  


  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h3 data-block-key="k1g9k">Better understanding and reasoning across modalities</h3><p data-block-key="6atnh">1.5 Pro can perform highly-sophisticated understanding and reasoning tasks for different modalities, including video. For instance, when given a 44-minute silent <a href="https://www.youtube.com/watch?v=rOVtjJkqtiA" rt-link-type="external">Buster Keaton movie</a>, the model can accurately analyze various plot points and events, and even reason about small details in the movie that could easily be missed.</p></div>
  

  
    
  
    


<div data-component="uni-article-yt-player" data-page-title="Our next-generation model: Gemini 1.5" data-video-id="wa0MT8OwHuk" data-index-id="12" data-analytics-module="{
    &quot;module_name&quot;: &quot;Youtube Video&quot;,
    &quot;section_header&quot;: &quot;undefined&quot;
  }">

    

    <a role="video" tabindex="0">
      <div>
        
          
          <p><img alt="Multimodal prompting with a 44-minute movie: Gemini 1.5 Pro Demo" src="https://i.ytimg.com/vi_webp/wa0MT8OwHuk/default.webp" loading="lazy" data-loading="{
                &quot;mobile&quot;: &quot;//i.ytimg.com/vi_webp/wa0MT8OwHuk/sddefault.webp&quot;,
                &quot;desktop&quot;: &quot;//i.ytimg.com/vi_webp/wa0MT8OwHuk/maxresdefault.webp&quot;
              }"></p>

        
        <svg role="presentation">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button_no_hole"></use>
          
        </svg>
        <svg role="img">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button"></use>
          
        </svg>

        
        
        
        
      </div>
    </a>

    
      <p>Gemini 1.5 Pro can identify a scene in a 44-minute silent Buster Keaton movie when given a simple line drawing as reference material for a real-life object.</p>
    

    
  </div>

  


  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h3 data-block-key="l4f5z">Relevant problem-solving with longer blocks of code</h3><p data-block-key="6p94l">1.5 Pro can perform more relevant problem-solving tasks across longer blocks of code. When given a prompt with more than 100,000 lines of code, it can better reason across examples, suggest helpful modifications and give explanations about how different parts of the code works.</p></div>
  

  
    
  
    


<div data-component="uni-article-yt-player" data-page-title="Our next-generation model: Gemini 1.5" data-video-id="SSnsmqIj1MI" data-index-id="14" data-analytics-module="{
    &quot;module_name&quot;: &quot;Youtube Video&quot;,
    &quot;section_header&quot;: &quot;undefined&quot;
  }">

    

    <a role="video" tabindex="0">
      <div>
        
          
          <p><img alt="Problem solving across 100,633 lines of code | Gemini 1.5 Pro Demo" src="https://i.ytimg.com/vi_webp/SSnsmqIj1MI/default.webp" loading="lazy" data-loading="{
                &quot;mobile&quot;: &quot;//i.ytimg.com/vi_webp/SSnsmqIj1MI/sddefault.webp&quot;,
                &quot;desktop&quot;: &quot;//i.ytimg.com/vi_webp/SSnsmqIj1MI/maxresdefault.webp&quot;
              }"></p>

        
        <svg role="presentation">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button_no_hole"></use>
          
        </svg>
        <svg role="img">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button"></use>
          
        </svg>

        
        
        
        
      </div>
    </a>

    
      <p>Gemini 1.5 Pro can reason across 100,000 lines of code giving helpful solutions, modifications and explanations.</p>
    

    
  </div>

  


  

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h2 data-block-key="k1g9k">Enhanced performance</h2><p data-block-key="6peis">When tested on a comprehensive panel of text, code, image, audio and video evaluations, 1.5 Pro outperforms 1.0 Pro on 87% of the benchmarks used for developing our large language models (LLMs). And when compared to 1.0 Ultra on the same benchmarks, it performs at a broadly similar level.</p><p data-block-key="2m8o3">Gemini 1.5 Pro maintains high levels of performance even as its context window increases. In the <a href="https://github.com/gkamradt/LLMTest_NeedleInAHaystack" rt-link-type="external">Needle In A Haystack</a> (NIAH) evaluation, where a small piece of text containing a particular fact or statement is purposely placed within a long block of text, 1.5 Pro found the embedded text 99% of the time, in blocks of data as long as 1 million tokens.</p><p data-block-key="cq31">Gemini 1.5 Pro also shows impressive “in-context learning” skills, meaning that it can learn a new skill from information given in a long prompt, without needing additional fine-tuning. We tested this skill on the <a href="https://arxiv.org/abs/2309.16575" rt-link-type="external">Machine Translation from One Book</a> (MTOB) benchmark, which shows how well the model learns from information it’s never seen before. When given a <a href="https://langsci-press.org/catalog/book/344" rt-link-type="external">grammar manual</a> for <a href="https://endangeredlanguages.com/lang/1891?hl=en" rt-link-type="external">Kalamang</a>, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person learning from the same content.<br></p><p data-block-key="7op9s">As 1.5 Pro’s long context window is the first of its kind among large-scale models, we’re continuously developing new evaluations and benchmarks for testing its novel capabilities.</p><p data-block-key="b6eqt">For more details, see our <a href="https://goo.gle/GeminiV1-5" rt-link-type="external">Gemini 1.5 Pro technical report</a>.</p></div>
  

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h2 data-block-key="k1g9k">Extensive ethics and safety testing</h2><p data-block-key="a3s4a">In line with our <a href="https://ai.google/responsibility/principles/" rt-link-type="external">AI Principles</a> and robust safety policies, we’re ensuring our models undergo extensive ethics and safety tests. We then integrate these research learnings into our governance processes and model development and evaluations to continuously improve our AI systems.</p><p data-block-key="3r93h">Since introducing 1.0 Ultra in December, our teams have continued refining the model, making it safer for a wider release. We’ve also conducted <a href="https://goo.gle/GeminiPaper" rt-link-type="external">novel research on safety risks</a> and developed red-teaming techniques to test for a range of potential harms.</p><p data-block-key="2pmdm">In advance of releasing 1.5 Pro, we've taken the same approach to responsible deployment as we did for our Gemini 1.0 models, <a href="https://goo.gle/GeminiV1-5" rt-link-type="external">conducting extensive evaluations</a> across areas including content safety and representational harms, and will continue to expand this testing. Beyond this, we’re developing further tests that account for the novel long-context capabilities of 1.5 Pro.</p></div>
  

  
    

  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Our next\u002Dgeneration model: Gemini 1.5&quot;
         }"><h2 data-block-key="k1g9k">Build and experiment with Gemini models</h2><p data-block-key="94van">We’re committed to bringing each new generation of Gemini models to billions of people, developers and enterprises around the world responsibly.</p><p data-block-key="9uot9">Starting today, we’re offering a limited preview of 1.5 Pro to developers and enterprise customers via <a href="https://aistudio.google.com/" rt-link-type="external">AI Studio</a> and <a href="https://cloud.google.com/vertex-ai" rt-link-type="external">Vertex AI</a>. Read more about this on our <a href="https://developers.googleblog.com/2024/02/gemini-15-available-for-private-preview-in-google-ai-studio.html" rt-link-type="external">Google for Developers blog</a> and <a href="https://cloud.google.com/blog/products/ai-machine-learning/gemini-on-vertex-ai-expands" rt-link-type="external">Google Cloud blog</a>.</p><p data-block-key="55ddh">We’ll introduce 1.5 Pro with a standard 128,000 token context window when the model is ready for a wider release. Coming soon, we plan to introduce pricing tiers that start at the standard 128,000 context window and scale up to 1 million tokens, as we improve the model.</p><p data-block-key="3h3jn">Early testers can try the 1 million token context window at no cost during the testing period, though they should expect longer latency times with this experimental feature. Significant improvements in speed are also on the horizon.</p><p data-block-key="e52dh">Developers interested in testing 1.5 Pro can <a href="https://aistudio.google.com/app/waitlist/97445851" rt-link-type="external">sign up now</a> in AI Studio, while enterprise customers can reach out to their Vertex AI account team.</p><p data-block-key="bpauc">Learn more about <a href="https://deepmind.google/technologies/gemini" rt-link-type="external">Gemini’s capabilities and see how it works</a>.</p></div>
  

  
    

  
    






<div role="form" aria-label="Sign up to receive weekly news and stories from Google." data-component="uni-subscribe" data-analytics-module="{
    &quot;module_name&quot;: &quot;Newsletter&quot;,
    &quot;section_header&quot;: &quot;Get more stories from Google in your inbox.&quot;
  }">
        
        
        <p>You are already subscribed to our newsletter.</p>
      </div>

  

  


            
            

            
              




            
          </div>
        
      </div>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Observable 2.0, a static site generator for data apps (478 pts)]]></title>
            <link>https://observablehq.com/blog/observable-2-0</link>
            <guid>39383386</guid>
            <pubDate>Thu, 15 Feb 2024 14:57:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://observablehq.com/blog/observable-2-0">https://observablehq.com/blog/observable-2-0</a>, See on <a href="https://news.ycombinator.com/item?id=39383386">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today we’re launching <a href="https://observablehq.com/product">Observable 2.0</a> with a bold new vision: an open-source static site generator for building fast, beautiful data apps, dashboards, and reports.</p><p>Our mission is to help teams communicate more effectively with data. Effective presentation of data is critical for deep insight, nuanced understanding, and informed decisions. Observable notebooks are great for ephemeral, <i>ad hoc</i> data exploration. But notebooks aren’t well-suited for polished dashboards and apps.</p><p>Enter <a href="https://observablehq.com/framework/">Observable Framework</a>.</p><div><figure><img src="https://images.ctfassets.net/uklh5xrq1p2j/26cJydaf6IQXGPmS7i13Gr/d4db342f8088003c3a4f004c13990940/1_-_Framework_Preview__1_.png" alt="Framework preview"></figure></div><p>With Framework, you can build the best data apps your team has ever seen. Framework combines the power of <b>JavaScript on the front-end</b> for interactive graphics, with <b>any language on the back-end</b> for data preparation and analysis. SQL, Python, R, Rust, Go… you name it. It’s the polyglot programmer’s dream. Everything you need is at your fingertips: interactive charts and inputs, responsive grids, themes, dark mode, keyboard-friendly navigation, and more. And because it’s code, there’s no limit to customization!</p><p>Framework is free and <a href="https://github.com/observablehq/framework">open-source</a>. Projects are just local files. Use your favorite editor, preview locally, check it all into git, write unit tests, add CI/CD, even work offline. You can host projects anywhere or deploy instantly to Observable to share them securely with your team.</p><p>Observable Framework solves the “last mile” problem of data apps: loading data. Conventional dashboards are slow because they run queries on view while the user waits; Framework’s data loaders run <i>on build</i> so that pages load instantly. And because data loaders run on your servers, you control privacy and security.
If you’re ready to dive in, visit our <a href="https://observablehq.com/framework/getting-started">Getting started tutorial</a>, or open a terminal and run:
</p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;npm init @observablehq</span>
</p><p>If you’d like to hear more about why we built Framework, please read on.</p><h3>Beyond notebooks <b>📓</b></h3><p>This moment — Observable 2.0 — reflects lessons learned over many years.</p><p>We believe the lightweight, collaborative nature of computational notebooks makes them ideal for exploring data and answering <i>ad hoc</i> questions. We founded Observable in 2016, pioneering a <a href="https://medium.com/@mbostock/a-better-way-to-code-2b1d2876a3a0">reactive, web-first approach</a> to notebooks and seeking to make data visualization easier, more practicable, and more social. We dreamed that notebooks might be the “one ring to rule them all” — powering not just notes, but apps, dashboards, and reports.</p><p>Yet no single interface can excel at every task. As cool as reactive notebooks are, a notebook can’t compete with a custom web app in terms of user experience. Notebooks are constrained by:</p><ul><li><p>A single-column, narrow layout</p></li><li><p>Low visual information density</p></li><li><p>Always-visible editor chrome</p></li></ul><p>These same limitations make notebooks great for tinkering and learning — the code is always at your fingertips, adjacent to the output — but not so great for presentation. To fill that latter role, we need better data apps.</p><p>A good data app embodies an empirical perspective; it fosters a shared understanding. Whereas notebooks tend to be for individuals, data apps are more often for a team. And whereas notebooks tend to be transient byproducts of point-in-time exploration, data apps often sustain value over time as people return to see how things change.</p><p>The differences between notebooks and data apps extend to development. A notebook editor desires speed: jotting down thoughts, running a query, sketching a chart. A data app developer prioritizes correctness, performance, and maintainability: making careful, deliberate changes that others depend on, favoring code review and testing before publishing.</p><p>We had three goals in mind when we set out to reimagine data app development:</p><ol><li><p><b>A better developer workflow</b> — meeting the needs of developers</p></li><li><p><b>A better user experience</b> — the “proof is in the pudding”</p></li><li><p><b>A better data architecture</b> — solving the “last mile” problem</p></li></ol><div><figure><img src="https://images.ctfassets.net/uklh5xrq1p2j/5D9MHFW8goDgB7Fuczy9s4/28dec57555f601daaaee374d2d2c5347/2_-_Workflow.png" alt="Workflow"></figure></div><h3>A better developer workflow <b>👩‍💻</b></h3><p>Modern development is built on <a href="https://stephango.com/file-over-app">files</a>. Files have myriad strengths, but the strongest is interoperability. When every tool uses files, it’s far easier to incorporate a new tool — and now Observable — into your workflow.</p><p>This isn’t just about using your preferred text editor. Now you can bring your own source control and code review system, too. You can write unit tests and run linters. You can automate builds with continuous integration or deployment. You can work offline. You can self-host. You can generate or edit content programmatically, say to format code or to find-and-replace across files.</p><p>As we break new ground with Observable Framework, we’re further improving interoperability by adopting vanilla JavaScript syntax. And we’re deprecating <span>require</span> in favor of modern ES <span>import</span>. These changes make Observable easier to learn, and to share code with other applications. (We’ll port these improvements back to Observable notebooks in the future.)</p><div><figure><a href="https://github.com/observablehq/framework/tree/main/examples"><img src="https://images.ctfassets.net/uklh5xrq1p2j/7EKYLd7vJn0TRcBoQZWRvV/d4976632216f1e072746e4910d827cc1/3_-_Examples.png" alt="Examples"></a><figcaption></figcaption></figure></div><h3><b>A better user experience 😍</b></h3><p>A toolmaker can’t care only about the developer experience — what does the developer experience matter if the resulting app is not demonstrably better? The merit of a creative tool should be judged by the quality of its creations, not its process. Or: “the proof of the pudding is in the eating.”</p><p>We believe that well-designed tools help developers build more efficiently by focusing their efforts on high-value work. We favor opinionated tools, with defaults and conveniences that foster a good user experience. We nudge you into <a href="https://blog.codinghorror.com/falling-into-the-pit-of-success/">the pit of success</a>.</p><p>Framework’s lightweight Markdown syntax — with light and dark mode, thoughtful colors, responsive grids, and built-in navigation — gives you beautiful pages from the start. It’s highly customizable if you need it, but it’s quick to get started with batteries included.</p><p>Most importantly, Framework’s data architecture practically forces your app to be <i>fast</i> because data is precomputed. Performance is critical for dashboards: users don’t like to wait, and dashboards only create value if users look at them. Slow dashboards waste time. (And you certainly don’t want your database and dashboard falling over under load!)</p><div><figure><img src="https://images.ctfassets.net/uklh5xrq1p2j/6ATQajSu9ZLRVmgR0YIiYs/12f2da04080e37ef88f82f001c566107/4_-_Architecture.png" alt="Architecture"></figure></div><h3>A better data architecture</h3><p>Every data visualization requires data. Obviously. But less obviously, each data visualization requires highly-specific data prepared with that visualization in mind. In fact, most of the work of visualization isn’t choosing visual encodings or laying out axes or visualizing <i>per se</i> — it’s preparing data. As I wrote <a href="https://observablehq.com/@mbostock/10-years-of-open-source-visualization">previously</a>,</p><div><figure><blockquote><p>working with data should be 80% of the work of visualization. Visualization is the end result of analysis — the visible manifestation of data, to be seen, shared, and appreciated by experts and non-experts alike — and as such it sometimes gets too much credit. To produce a visualization, one must first find data, clean it, transform, join, model, etc. Working with data is sometimes needlessly denigrated as “janitorial” when it represents the critical step of understanding the data as it is, warts and all.</p></blockquote></figure></div><p>Given how much work goes into preparing data, it follows that developers want</p><ul><li><p>to use any language (say Python or R or SQL),</p></li><li><p>to use any library (say NumPy or dplyr),</p></li><li><p>to use any data source (database, data warehouse, API, files, <i>etc</i>.), and</p></li><li><p>to crunch data ahead of time (offline)</p></li></ul><p>while still leveraging JavaScript in the browser for interactive graphics.</p><p>Framework’s data loaders solve this “last mile” problem by computing static data snapshots at build time. These snapshots can be highly-optimized (and aggregated and anonymized), minimizing the data you send to the client. And since a data loader is just a fancy way of generating a file on-demand (with clever caching and routing), loaders can be written in any language and use any library. This flexibility is not unlike <a href="https://en.wikipedia.org/wiki/Common_Gateway_Interface">CGI</a> from 30 years ago, and <a href="https://en.wikipedia.org/wiki/Pipeline_(Unix)">Unix pipes</a>. And since data loaders run on your servers, viewers don’t need direct access to the underlying data sources, and your dashboards are more secure and robust.</p><p>The speed of modern data warehouses is astonishing. But far too often something is missing for new analysis — some untapped data source, some not-yet-materialized view for a query to run at interactive speeds. Framework’s data loaders let you bypass these hurdles and produce a fast dashboard without “heavy lifting” in your data warehouse. And once your analysis demonstrates value, you can shift work to your data warehouse and simplify your data loaders. Framework lets you build faster and quickly validate your ideas.</p><p>We believe Framework will change how you think about data, and effect a better user experience. And by securely hosting apps alongside notebooks, Observable now offers an end-to-end solution for data analysis and presentation.</p><h3>Thank you <b>🙏</b></h3><p>We wouldn’t be here without the support, feedback, and encouragement from you — our community. Thank you for using Observable notebooks, Observable Plot, and D3. We’re thrilled to share Observable Framework with you now, and can’t wait to hear what you think.</p><p>To learn more about Framework, <a href="https://observablehq.com/framework/">read the docs</a>.</p><p>To share your questions or feedback, please <a href="https://talk.observablehq.com/latest">visit our forum</a>.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I got scammed out of $50k (101 pts)]]></title>
            <link>https://www.thecut.com/article/amazon-scam-call-ftc-arrest-warrants.html</link>
            <guid>39382981</guid>
            <pubDate>Thu, 15 Feb 2024 14:19:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thecut.com/article/amazon-scam-call-ftc-arrest-warrants.html">https://www.thecut.com/article/amazon-scam-call-ftc-arrest-warrants.html</a>, See on <a href="https://news.ycombinator.com/item?id=39382981">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-editable="main" data-track-zone="main">  <article role="main" data-track-type="article-detail" data-uri="www.thecut.com/_components/article/instances/cls9hkvh6000k0ifm6jiftoxi@published" data-content-channel="Career &amp; Money" data-crosspost="" data-type="Vertical Enterprise" data-syndication="original" data-headline="The Day I Put $50,000 in a Shoe Box and Handed It to a Stranger" data-authors="Charlotte Cowles" data-publish-date="2024-02-15" data-tags="style, fashion, spring fashion, spring 2024 fashion issue, best of the cut, new york magazine, remove interruptions, scams, money, personal finance, self, first person, audio article" data-issue-date="2024-02-12" data-components-count="91" data-canonical-url="http://www.thecut.com/article/amazon-scam-call-ftc-arrest-warrants.html">
    


  
  
  
  <header>
    <div>
          <h2 data-editable="overrideHeadline">The Day I Put $50,000 in a Shoe Box and Handed It to a Stranger</h2>
            <h2 data-editable="displayTeaser">I never thought I was the kind of person to fall for a scam.</h2>
            

            <p><span>
                  <a href="https://www.thecut.com/author/charlotte-cowles/" rel="author">
                    <img src="https://pyxis.nymag.com/v1/imgs/a2e/291/896a7f58b1dd99a9677575f693b0c399a5-charlotte-cowles.2x.rsquare.w168.jpg" alt="Portrait of Charlotte Cowles">
                  </a>
                </span>
            <span data-editable="bylines">
            <p><span>By</span> <span>
        ,
          <span>the Cut’s financial-advice columnist.</span><span>&nbsp;</span>
          <span>In addition to “My Two Cents,” she writes about work and parenting for the site. Previously, she was the senior features editor at Harper's Bazaar and a senior editor at the Cut. She was also the editorial director for MM.LaFleur. Her work has also been published in Glamour, Art in America, Politico, and other places.</span>
      </span></p>

              </span>
          </p>
        </div>
      <div data-editable="lede">
          <picture> <source media="(min-resolution: 192dpi) and (min-width: 1180px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 1180px)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.2x.rvertical.w570.jpg 2x" width="570" height="712"> <source media="(min-width: 1180px) " srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.rvertical.w570.jpg" width="570" height="712"> <source media="(min-resolution: 192dpi) and (min-width: 768px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.2x.rvertical.w570.jpg 2x" width="570" height="712"> <source media="(min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.rvertical.w570.jpg" width="570" height="712"> <source media="(min-resolution: 192dpi), (-webkit-min-device-pixel-ratio: 2)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.2x.rvertical.w570.jpg" width="570" height="712"> <img src="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.rvertical.w570.jpg" data-content-img="" width="570" height="712" fetchpriority="high"> </picture>
          </div>
        <p><span>Illustration: Nicole Rifkin</span>
        </p>
  </header>
  <section>
    <div data-editable="content">
      <div>
          <div>
            <picture> <source media="(min-resolution: 192dpi) and (min-width: 1180px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 1180px)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.2x.rvertical.w570.jpg 2x" width="570" height="712"> <source media="(min-width: 1180px) " srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.rvertical.w570.jpg" width="570" height="712"> <source media="(min-resolution: 192dpi) and (min-width: 768px), (-webkit-min-device-pixel-ratio: 2) and (min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.2x.rvertical.w570.jpg 2x" width="570" height="712"> <source media="(min-width: 768px)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.rvertical.w570.jpg" width="570" height="712"> <source media="(min-resolution: 192dpi), (-webkit-min-device-pixel-ratio: 2)" srcset="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.2x.rvertical.w570.jpg" width="570" height="712"> <img src="https://pyxis.nymag.com/v1/imgs/c04/eae/e6f771ada50b6d775dd8e83976829d96b9-scammer-lede.rvertical.w570.jpg" data-content-img="" width="570" height="712" fetchpriority="high"> </picture>
          </div>
            <div>
              <p><span>Illustration: Nicole Rifkin</span>
              </p>
            </div>
              </div>
        

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/cls9hkvh6000i0ifmigzoeac8@published" data-word-count="52">On a Tuesday evening this past October, I put $50,000 in cash in a shoe box, taped it shut as instructed, and carried it to the sidewalk in front of my apartment, my phone clasped to my ear. “Don’t let anyone hurt me,” I told the man on the line, feeling pathetic.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq600343b7yhj2gog97@published" data-word-count="13">“You won’t be hurt,” he answered. “Just keep doing exactly as I say.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq600353b7y3k8a1sbw@published" data-word-count="46">Three minutes later, a white Mercedes SUV pulled up to the curb. “The back window will open,” said the man on the phone. “Do not look at the driver or talk to him. Put the box through the window, say ‘thank you,’ and go back inside.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq600363b7yegwwp80f@published" data-word-count="83">The man on the phone knew my home address, my Social Security number, the names of my family members, and that my 2-year-old son was playing in our living room. He told me my home was being watched, my laptop had been hacked, and we were in imminent danger. “I can help you, but only if you cooperate,” he said. His first orders: I could not tell anyone about our conversation, not even my spouse, or talk to the police or a lawyer.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq600373b7yfjnsrlka@published" data-word-count="90">Now I know this was all a scam — a cruel and violating one but painfully obvious in retrospect. Here’s what I can’t figure out: Why didn’t I just hang up and call 911? Why didn’t I text my husband, or my brother (a lawyer), or my best friend (also a lawyer), or my parents, or one of the many other people who would have helped me? Why did I hand over all that money — the contents of my savings account, strictly for emergencies — without a bigger fight?</p>

  <section data-uri="www.thecut.com/_components/package-table-of-contents/instances/clsm5tjmv008a3b7yyxnsuna1@published" data-editable="settings">
  

  <div>
    
      <p><a href="https://www.thecut.com/tags/spring-2024-fashion-issue/">
          <img src="https://pyxis.nymag.com/v1/imgs/72f/fc2/f5515b8e4e53c4a19503e81e27dcddd54b-0424CUTCov-4x5-moore-rev.2x.rvertical.w330.jpg" alt="package-table-of-contents-photo">
        </a>
      </p>
  </div>


    
  
  <span>
    <a href="https://www.thecut.com/tags/spring-2024-fashion-issue/">See All</a>&nbsp;
    <!--?xml version="1.0" encoding="utf-8"?-->
<!-- Generator: Adobe Illustrator 26.5.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 11 11" style="enable-background:new 0 0 11 11;" xml:space="preserve">

<path d="M5.1,11l3-5.6L5.1,0L11,5.4L5.1,11z"></path>
<path d="M0,11l3-5.6L0,0l5.9,5.4L0,11z"></path>
</svg>

  </span>
</section>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq700383b7yfe719uee@published" data-word-count="100">When I’ve told people this story, most of them say the same thing: You don’t seem like the type of person this would happen to. What they mean is that I’m not senile, or hysterical, or a rube. But these stereotypes are actually false. Younger adults — Gen Z, millennials, and Gen X — are 34 percent <em>more</em> likely to report losing money to fraud compared with those over 60, according to a recent report from the Federal Trade Commission. Another study found that well-educated people or those with good jobs were just as vulnerable to scams as everyone else.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq700393b7yu0ezqflh@published" data-word-count="88">Still, how could I have been such easy prey? Scam victims tend to be single, lonely, and economically insecure with low financial literacy. I am none of those things. I’m closer to the opposite. I’m a journalist who had a weekly column in the “Business” section of the New York <em>Times.</em> I’ve written a personal-finance column for this magazine for the past seven years. I interview money experts all the time and take their advice seriously. I’m married and talk to my friends, family, and colleagues every day.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq7003a3b7ywx18621n@published" data-word-count="88">And while this is harder to quantify — how do I even put it? — I’m not someone who loses her head. My mother-in-law has described me as even-keeled; my own mom has called me “maddeningly rational.” I am listed as an emergency contact for several friends — and their kids. I vote, floss, cook, and exercise. In other words, I’m not a person who panics under pressure and falls for a conspiracy involving drug smuggling, money laundering, and CIA officers at my door. Until, suddenly, I was.</p>

  

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq8003c3b7y102y9bcg@published" data-word-count="86">That morning — it was October 31 — I dressed my toddler in a pizza costume for Halloween and kissed him good-bye before school. I wrote some work emails. At about 12:30 p.m., my phone buzzed. The caller ID said it was Amazon. I answered. A polite woman with a vague accent told me she was calling from Amazon customer service to check some unusual activity on my account. The call was being recorded for quality assurance. Had I recently spent $8,000 on MacBooks and iPads?</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq8003d3b7yif1zqfle@published" data-word-count="54">I had not. I checked my Amazon account. My order history showed diapers and groceries, no iPads. The woman, who said her name was Krista, told me the purchases had been made under my business account. “I don’t have a business account,” I said. “Hmm,” she said. “Our system shows that you have two.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq8003e3b7yq1vyhvc2@published" data-word-count="55">Krista and I concurred that I was the victim of identity theft, and she said she would flag the fraudulent accounts and freeze their activity. She provided me with a case-ID number for future reference and recommended that I check my credit cards. I did, and everything looked normal. I thanked her for her help.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq8003f3b7ytfg2ultv@published" data-word-count="48">Then Krista explained that Amazon had been having a lot of problems with identity theft and false accounts lately. It had become so pervasive that the company was working with a liaison at the Federal Trade Commission and was referring defrauded customers to him. Could she connect me?</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq9003g3b7yzsqivi3g@published" data-word-count="4">“Um, sure?” I said.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq9003h3b7y84fa7z0i@published" data-word-count="105">Krista transferred the call to a man who identified himself as Calvin Mitchell. He said he was an investigator with the FTC, gave me his badge number, and had me write down his direct phone line in case I needed to contact him again. He also told me our call was being recorded. He asked me to verify the spelling of my name. Then he read me the last four digits of my Social Security number, my home address, and my date of birth to confirm that they were correct. The fact that he had my Social Security number threw me. I was getting nervous.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq9003i3b7y86hkgepm@published" data-word-count="27">“I’m glad we’re speaking,” said Calvin. “Your personal information is linked to a case that we’ve been working on for a while now, and it’s quite serious.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jq9003j3b7yhwz59x0m@published" data-word-count="169">He told me that 22 bank accounts, nine vehicles, and four properties were registered to my name. The bank accounts had wired more than $3 million overseas, mostly to Jamaica and Iraq. Did I know anything about this? “No,” I said. Did I know someone named Stella Suk-Yee Kwong? “I don’t think so,” I said. He texted me a photo of her ID, which he claimed had been found in a car rented under my name that was abandoned on the southern border of Texas with blood and drugs in the trunk. A home in New Mexico affiliated with the car rental had subsequently been raided, he added, and authorities found more drugs, cash, and bank statements registered to my name and Social Security number. He texted me a drug-bust photo of bags of pills and money stacked on a table. He told me that there were warrants out for my arrest in Maryland and Texas and that I was being charged with cybercrimes, money laundering, and drug trafficking.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqa003k3b7y6c7g49zr@published" data-word-count="54">My head swam. I Googled my name along with “warrant” and “money laundering,” but nothing came up. Were arrest warrants public? I wasn’t sure. Google led me to truthfinder.com, which asked for my credit-card information — nope. “I’m in deep shit,” I texted my husband. “My identity was stolen and it seems really bad.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqb003l3b7yadezzz8j@published" data-word-count="66">Calvin wanted to know if I knew anyone who might be the culprit or if I had any connections to Iraq or Jamaica. “No,” I said. “This is the first I’m hearing about any of this, and it’s a lot to take in.” He asked if I had ever used public or unsecured Wi-Fi. “I don’t know. Maybe?” I said. “I used the airport Wi-Fi recently.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqb003m3b7yhdb1b9vd@published" data-word-count="37">“Ah,” he said. “That’s unfortunate. It’s how many of these breaches start.” I was embarrassed, like I’d left my fly unzipped. How could I have been so thoughtless? But also — didn’t everyone use the airport Wi-Fi?</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqb003n3b7yhcfbg1z2@published" data-word-count="26">Calvin told me to listen carefully. “The first thing you must do is not tell anyone what is going on. Everyone around you is a suspect.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqb003o3b7ykt9gabaz@published" data-word-count="97">I almost laughed. I told him I was quite sure that my husband, who works for an affordable-housing nonprofit and makes meticulous spreadsheets for our child-care expenses, was not a secret drug smuggler. “I believe you, but even so, your communications are probably under surveillance,” Calvin said. “You cannot talk to him about this.” I quickly deleted the text messages I had sent my husband a few minutes earlier. “These are sophisticated criminals with a lot of money at stake,” he continued. “You should assume you are in danger and being watched. You cannot take any chances.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqc003p3b7y7ajyixfd@published" data-word-count="130">I felt suspended between two worlds — the one I knew and the one this man was describing. If I had nothing to do with any of these allegations, how much could they truly affect me? I thought of an old <em>This American Life </em>episode about a woman whose Social Security card was stolen. No matter how many times she closed her bank accounts and opened new ones, her identity thief kept draining them, destroying her credit and her sanity. (It turned out to be her boyfriend.) I remembered another story about a man who got stuck on a no-fly list after his personal information was used by a terrorist group. It dawned on me that being connected to major federal offenses, even falsely, could really fuck up my life.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqd003q3b7ys5ku7xfp@published" data-word-count="71">Calvin wanted to know how much money I currently had in my bank accounts. I told him that I had two — checking and savings — with a combined balance of a little over $80,000. As a freelancer in a volatile industry, I keep a sizable emergency fund, and I also set aside cash to pay my taxes at the end of the year, since they aren’t withheld from my paychecks.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqd003r3b7ypzo0jor6@published" data-word-count="92">His voice took on a more urgent tone. “You must have worked very hard to save all that money,” he said. “Do not share your bank-account information with anyone. I am going to help you keep your money safe.” He said that he would transfer me to his colleague at the CIA who was the lead investigator on my case and gave me a nine-digit case number for my records. (I Googled the number. Nothing.) He said the CIA agent would tell me what to do next, and he wished me luck.</p>

  

  <div data-uri="www.thecut.com/_components/image/instances/clsm5q4ef007n3b7ywzbg2pix@published" data-editable="settings">
    
    <p><span>Illustration: Nicole Rifkin</span>
    </p>
</div>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqe003t3b7yi1li3dza@published" data-word-count="70">If it was a scam<strong><em>,</em></strong> I couldn’t see the angle. It had occurred to me that the whole story might be made up or an elaborate mistake. But no one had asked me for money or told me to buy crypto; they’d only encouraged me <em>not</em> to share my banking information. They hadn’t asked for my personal details; they already knew them. I hadn’t been told to click on anything.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqe003u3b7yddqewies@published" data-word-count="104">Still, I had not seen a shred of evidence. I checked my bank accounts, credit cards, and credit score; nothing looked out of the ordinary. I knew I should probably talk to a lawyer or maybe call the police, though I was doubtful that they would help. What was I going to say — “My identity was stolen, and I think I’m somehow in danger”? I had no proof. I was also annoyed that my workday had been hijacked. It was 2 p.m., and I had already pushed back one deadline and postponed two work calls. I had to get myself out of this.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqe003v3b7yrnt1flog@published" data-word-count="72">The next man who got on the line had a deeper voice and a slight British accent flecked with something I couldn’t identify. He told me his name was Michael Sarano and that he worked for the CIA on cases involving the FTC. He gave me his badge number. “I’m going to need more than that,” I said. “I have no reason to believe that any of what you’re saying is real.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqf003w3b7y2hsfkucg@published" data-word-count="65">“I completely understand,” he said calmly. He told me to go to the FTC home page and look up the main phone number. “Now hang up the phone, and I will call you from that number right now.” I did as he said. The FTC number flashed on my screen, and I picked up. “How do I know you’re not just spoofing this?” I asked.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqf003x3b7yl86nymmn@published" data-word-count="65">“It’s a government number,” he said, almost indignant. “It cannot be spoofed.” I wasn’t sure if this was true and tried Googling it, but Michael was already onto his next point. He told me the call was being recorded, so I put him on speaker and began recording on my end, too. He wanted to know if I had told anyone what was going on.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqf003y3b7yhyvkjcqy@published" data-word-count="56">I admitted that I had texted my husband. “You must reassure him that everything is fine,” Michael said. “In many cases like this, we have to investigate the spouse as well, and the less he knows, the less he is implicated. From now on, you have to follow protocol if you want us to help you.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqf003z3b7y723ufrvh@published" data-word-count="13">“I don’t think I should lie to my husband,” I said, feeling stupid.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqf00403b7yn23en1za@published" data-word-count="46">“You are being investigated for major federal crimes,” he said. “By keeping your husband out of this, you are <em>protecting </em>him.” He then repeated the point Calvin had made about my phone and computer being hacked and monitored by the criminals who had stolen my identity.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqg00413b7y8sah3cnt@published" data-word-count="32">By that point, my husband had sent me a series of concerned texts. “Don’t worry. It will be okay,” I wrote back. It felt gross to imagine a third party reading along.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqg00423b7y76ckd0r4@published" data-word-count="89">Michael snowed me with the same stories Calvin had. They were consistent: the car on the Texas border, the property in New Mexico, the drugs, the bank accounts. He asked if I shared my residence with anyone besides my husband and son. Then he asked more questions about my family members, including my parents, my brother, and my sister-in-law. He knew their names and where they lived. I told him they had nothing to do with this. In fact, I was now sure I wanted to consult a lawyer.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqg00433b7yp9kd3bvx@published" data-word-count="62">“If you talk to an attorney, I cannot help you anymore,” Michael said sternly. “You will be considered noncooperative. Your home will be raided, and your assets will be seized. You may be arrested. It’s your choice.” This seemed ludicrous. I pictured officers tramping in, taking my laptop, going through our bookshelves, questioning our neighbors, scaring my son. It was a nonstarter.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqg00443b7ykbykct9w@published" data-word-count="27">“Can I just come to your office and sort this out in person?” I said. “It’s getting late, and I need to take my son trick-or-treating soon.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqg00453b7y45u3ulxn@published" data-word-count="44">“My office is in Langley,” he said. “We don’t have enough time. We need to act immediately. I’m going to talk you through the process. It’s going to sound crazy, but we must follow protocol if we’re going to catch the people behind this.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqg00463b7yf3zwjmo1@published" data-word-count="98">He explained that the CIA would need to freeze all the assets in my name, including my actual bank accounts. In the eyes of the law, there was no difference between the “real” and the fraudulent ones, he said. They would also deactivate my compromised Social Security number and get me a new one. Then, by monitoring any activity under my old Social Security number and accounts, they would catch the criminals who were using my identity and I would get my life back. But until then, I would need to use only cash for my day-to-day expenses.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqh00473b7ye8s8a9cv@published" data-word-count="22">It was far-fetched. Ridiculous. But also not completely out of the realm of possibility. “Do I have any other options?” I asked.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqh00483b7ym4f7nzng@published" data-word-count="17">“Unfortunately, no,” he said. “You must follow my directions very carefully. We do not have much time.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqh00493b7yfw5vsv3v@published" data-word-count="93">He asked me how much cash I thought I would need to support myself for a year if necessary. My assets could be frozen for up to two years if the investigation dragged on, he added. There could be a trial; I might need to testify. These things take time. “I don’t know, $50,000?” I said. I wondered how I would receive paychecks without a bank account. Would I have to take time off from work? I did some mental calculations of how much my husband could float us and for how long.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqh004a3b7yijy19l69@published" data-word-count="40">“Okay,” he said. “You need to go to the bank and get that cash out now. You cannot tell them what it is for. In one of my last cases, the identity thief was someone who worked at the bank.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqi004b3b7yzb2xsoca@published" data-word-count="64">Michael told me to keep the phone on speaker so we would remain in contact. “It’s important that I monitor where this money goes from now on. Remember, all of your assets are part of this investigation,” he said. Then he told me that one of his colleagues would meet me at my apartment at 5 p.m. to guide me through the next steps.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqi004c3b7yrupgha8w@published" data-word-count="20">“You can’t send a complete stranger to my home,” I said, my voice rising. “My 2-year-old son will be here.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqi004d3b7y7g21n626@published" data-word-count="24">“Let me worry about that,” he said. “It’s my job. But if you don’t cooperate, I cannot keep you safe. It is your choice.”</p>

  

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqi004f3b7y4vno8t8h@published" data-word-count="55">It’s impossible to explain why I accepted this logic. But I had been given marching orders and a deadline. My son would be home soon, and I had to fix this mess. I put on sneakers in case I needed to run. I brought a backpack for the cash. I felt both terrified and absurd.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqi004g3b7yrshp1wcp@published" data-word-count="66">It was jarring to see trick-or-treaters in my Brooklyn neighborhood, people going about their lives. The air was crisp, and dead leaves swirled on the ground. I was on high alert for anyone who might be following me. At one point, a man in sunglasses and a hoodie trailed me for a few blocks. At Michael’s suggestion, I ducked into a parking garage until he passed.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqi004h3b7yoikaw79j@published" data-word-count="92">When I reached the bank, I told the guard I needed to make a large cash withdrawal and she sent me upstairs. Michael was on speakerphone in my pocket. I asked the teller for $50,000. The woman behind the thick glass window raised her eyebrows, disappeared into a back room, came back with a large metal box of $100 bills, and counted them out with a machine. Then she pushed the stacks of bills through the slot along with a sheet of paper warning me against scams. I thanked her and left.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqj004i3b7ymftctv9l@published" data-word-count="67">Michael was bursting with praise. “You did a great job,” he said. “I have to go for a moment to see about the details of your case; I’m going to have you speak to my colleague if you have any questions.” He put a woman on the line. She was younger, with an accent I couldn’t identify. She told me to go home and await further instructions.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqj004j3b7yqresl85o@published" data-word-count="67">As I walked back to my apartment, something jolted me out of my trance, and I became furious. No government agency would establish this as “protocol.” It was preposterous. “I need to speak with Michael,” I told the woman on the phone. He got on right away. “I don’t even believe that you’re a CIA agent,” I said. “What you’re asking me to do is completely unreasonable.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqj004k3b7yq269p2md@published" data-word-count="56">He sighed. “I’m sending you a photo of my badge right now,” he said. “I don’t know what else to tell you. You can trust me, and I will help you. Or you can hang up and put yourself and your family in danger. Do you really want to take that risk with a young child?”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqj004l3b7y2dko06mh@published" data-word-count="73">I waited for a stoplight at a busy intersection. I could see my apartment window from where I stood. My son was playing inside with a neighbor’s daughter and their nanny. A picture of Michael’s badge appeared on my phone. I had no way of verifying it; it could easily have been Photoshopped. “I don’t trust you at all,” I said to Michael. “But it doesn’t seem like I have any other choice.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqk004m3b7yvxhoxilj@published" data-word-count="92">When I got home, Michael told me to get a box, put the cash in it, take a picture of it, then tape it shut. I found a floral-printed shoe box that had once contained a pair of slippers I’d bought for myself — a frivolous purchase that now seemed mortifying. Michael told me to label it with my name, my case number, my address, a locker number he read to me, and my signature. Then he directed me to take another picture of the labeled box and text it to him.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqk004n3b7ytb8vhmdk@published" data-word-count="101">“My colleague will be there soon. He is an undercover CIA agent, and he will secure the money for you,” he said. What exactly would that entail? I asked. “Tonight, we will close down your Social Security number, and you will lose access to your bank accounts,” he explained. “Tomorrow, you’ll need to go to the Social Security office and get a new Social Security number. We’ll secure this money for you in a government locker and hand-deliver a Treasury check for the same amount. You can cash the check and use it for your expenses until the investigation is over.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jql004o3b7y9t8l4o3m@published" data-word-count="21">“Why can’t I just use this cash?” I asked. “Why do you have to take it and give me a check?”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jql004p3b7ype733hsn@published" data-word-count="47">“Because all of your assets under your current identity are part of the investigation,” he said. “You are being charged with money laundering. If we secure this cash and then issue you a government check under your new Social Security number, that will be considered clean money.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jql004q3b7ygfsusup4@published" data-word-count="24">“I’ll need to see your colleague’s badge,” I said. “I’m not just going to give $50,000 of my money to someone I don’t know.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jql004r3b7y2rr34nol@published" data-word-count="37">“Undercover agents don’t carry badges,” he said, as if I’d asked the CIA to bring me a Happy Meal. “They’re undercover. Remember, you are probably being watched. The criminals cannot know that a CIA agent is there.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jql004s3b7yuxp9bqgz@published" data-word-count="116">In a twisted way, this made some amount of sense to me. Or maybe I had lost my grip on reality so completely that I was willing to resign myself to this new version of it. Most important, I didn’t know what else to do. Even if Michael wasn’t working for the CIA (which struck me as more and more likely), he was sending a man to our address. I felt a sickening dread that he might ask to come inside. If giving him this money would make him go away, I was ready to do it. I’d been on the phone for nearly five hours. I wanted to take my son trick-or-treating. I was exhausted.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqm004t3b7ytyfonk7i@published" data-word-count="104">Michael seemed to sense that I was flagging and asked if I’d had lunch. I hadn’t. He told me to eat something but keep him on the line; his agent was on the way to my address but running late. “You can meet him outside if that would make you more comfortable,” Michael said, and I felt relieved. While I gnawed on a granola bar at my desk, he got chatty and asked about my job. I told him I was going to Washington, D.C., later that week. “Oh, great. You could come to my office in Langley,” he said. “Where are you staying?”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqm004u3b7yce6w8hea@published" data-word-count="86">A little after 6 p.m., Michael told me to go downstairs. His colleague was arriving. My husband had just come home from work and was reading to our son. “What’s going on? Is everything okay?” he asked as I put my coat on. I motioned to the phone and shushed him. Then I whispered, “I have to go downstairs and meet a guy who’s helping with the identity-theft case. I’ll explain more later.” He frowned and silently mouthed, “What?” I told him I had to go.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqn004v3b7yes2iy6q4@published" data-word-count="64">I met the SUV at the curb and put the money in the back seat. It was 6:06 p.m. Even if I’d tried to see who was driving, the windows were tinted and it was dusk. He maybe wore a baseball cap. When I turned around, I could see the backlit faces of my husband and son watching from our apartment nine stories above.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqn004w3b7y5o1uxhoy@published" data-word-count="83">As I walked back inside, Michael texted me a photo of a Treasury check made out to me for $50,000 and told me a hard copy would be hand-delivered to me in the morning. He was working on setting up my appointment with the Social Security office. “You will receive a confirmation text shortly,” he said. “Stay on the line until you do.” I felt oddly comforted by this. An appointment would give me something legitimate, an actual connection to a government agency.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqn004x3b7yqj9is4rf@published" data-word-count="83">I took my son trick-or-treating, my phone on speaker in my pocket. I felt numb, almost in a fugue state, smiling and chatting with my neighbors and their kids. At one point, I checked to see if Michael was still there; his female colleague answered and said he’d be back soon. Then, when we got home and I checked again, the line was dead. I panicked and called back. The woman answered. “Michael is busy,” she said. “He’ll call you in the morning.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqn004y3b7y6u0vk6dd@published" data-word-count="33">I was confused. Did this mean I didn’t have a Social Security number at all anymore? I pictured myself floating, identity-less. “Do I have an appointment at the Social Security office?” I asked.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqo004z3b7yvn61f93v@published" data-word-count="23">“Michael will call you tomorrow,” she repeated. “He hasn’t been able to secure your appointment yet. The Social Security office is closed now.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqo00503b7yc8awyvou@published" data-word-count="122">I went into my bedroom and shut the door, feeling my face grow hot. I had a physical sensation of scales falling from my eyes; the room shimmered around me, spots raining from the ceiling. I saw the whole day peel away, like the layers of an onion — Michael, the FTC officer, the Amazon call — revealing my real life, raw and exposed, at the center. “Oh my God,” I said, my hands tingling. “You are lying to me. Michael was lying. You just took my money and I’m never getting it back.” That wasn’t true, the woman said. She understood that I was upset. She was sorry. Everything would be fine. “You’re a fucking liar,” I hissed, and hung up.</p>

  

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqo00523b7yo9fzzz2y@published" data-word-count="104">Through choking sobs, I told my husband what had happened. “Why didn’t you tell me?” he asked, incredulous. “I would have stopped you.” That I’d been trying to protect him suddenly seemed so idiotic I couldn’t even say it out loud. Our son looked on, confused. “Mama’s sad,” he announced, clinging to my leg. We put him to bed and then I called my parents and my brother. At their urging, I called 911. Around 10:30 p.m., three police officers came over and took my statement. I struggled to recount what I’d done; it seemed like a bad dream. I felt like a fool.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqp00533b7yo7aj70ax@published" data-word-count="37">“No government agency will ever ask you for money,” one cop informed me, as if I’d never heard it before. I wanted to scream, “I <em>know.</em>” Instead, I said, “It didn’t really feel like he was asking.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqp00543b7yo0ykysz5@published" data-word-count="49">The police told me not to worry; the scammers wouldn’t be back. “They got what they wanted,” another officer said, as though it would reassure me. I gave them the photos and recordings I had. They promised to check traffic cameras for the car that had taken the money.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqp00553b7yqqlxr1h2@published" data-word-count="107">When I woke up the next morning, a few seconds passed before I remembered the previous day. I was my old self, in my old bed, milky dawn light on the walls. Then it all came crashing back, a fresh humiliation, and I curled into the fetal position. I felt violated, unreliable; I couldn’t trust myself. Were my tendencies toward people-pleasing, rule following, and conflict aversion far worse than I’d ever thought, even pathological? I imagined other people’s reactions. <em>She’s always been a little careless.</em> <em>She seems unhinged.</em> I considered keeping the whole thing a secret. I worried it would harm my professional reputation. I still do.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqp00563b7ykfck9oy6@published" data-word-count="171">In the days that followed, I kept revisiting the fake world of that afternoon, slipping through a portal into an alternate life. I would get paranoid that someone was reading my texts, watching me as I took my son to school, or using my Social Security number to wire money and rent cars. It was a relief that I wasn’t actually in trouble with the law, but then again — I’d lost $50,000 and I wasn’t getting it back. I checked my accounts and credit cards obsessively. I called my bank. They gave me instructions to freeze my credit, file reports with the FBI and FTC, and run anti-virus software on my laptop to check for malware, which I did. I cried a lot. My husband felt helpless; he still doesn’t like to talk about it. Instead, he researched new locks for our doors and looked into security cameras. One night I shook him awake, convinced that someone was trying to break in. “It’s only the wind,” he said. “We’re safe.”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqq00573b7ybm56xl83@published" data-word-count="121">Fifty thousand dollars is a lot of money. It took me years to save, stashing away a few thousand every time I got paid for a big project. Part of it was money I had received from my grandfather, an inheritance he took great pains to set up for his grandchildren before his death. Sometimes I imagine how I would have spent it if I had to get rid of it in a day. I could have paid for over a year’s worth of child care up front. I could have put it toward the master’s degree I’ve always wanted. I could have housed multiple families for months. Perhaps, inadvertently, I am; I occasionally wonder what the scammers did with it.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqr00583b7ytma4vvdj@published" data-word-count="76">Because I had set it aside for emergencies and taxes, it was money I tried to pretend I didn’t have — it wasn’t for spending. Initially, I was afraid that I wouldn’t be able to afford my taxes this year, but then my accountant told me I could write off losses due to theft. So from a financial standpoint, I’ll survive, as long as I don’t have another emergency — a real one — anytime soon.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqr00593b7y74yx14d8@published" data-word-count="72">When I did tell friends what had happened, it seemed like everyone had a horror story. One friend’s dad, a criminal-defense attorney, had been scammed out of $1.2 million. Another person I know, a real-estate developer, was duped into wiring $450,000 to someone posing as one of his contractors. Someone else knew a Wall Street executive who had been conned into draining her 401(k) by some guy she met at a bar.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqr005a3b7yu08ktzpz@published" data-word-count="120">I felt a guilty sense of consolation whenever I heard about a scam involving someone I respected. If this could happen to them, maybe I wasn’t such a moron. As a journalist, it’s my instinct to research and talk to experts, so I dove into books and podcasts about scams, desperate to make sense of my own. I had known that fraud was on the rise but was shocked to learn the numbers — financial losses ballooned by more than 30 percent in 2022. I read that self-laceration is typical; half of victims blame themselves for being gullible, and most experience serious anxiety, depression, or other stress-related health problems afterward. I heard about victim support groups. I went to therapy.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqs005b3b7yaj2zdefi@published" data-word-count="59">When I discovered that Katie Gatti Tassin, a personal-finance expert who writes the popular <em>Money With Katie </em>newsletter, lost $8,000 five years ago to a grandmotherly-sounding woman pretending to call from Tassin’s credit union, I called her to ask how she’d coped. “Everyone was so patronizing,” she told me. “The response was basically ‘It’s your fault that this happened.’”</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqs005c3b7yeyxbd5sh@published" data-word-count="75">If I had to pinpoint a moment that made me think my scammers were legitimate, it was probably when they read me my Social Security number. Now I know that all kinds of personal information — your email address, your kids’ names and birthdays, even your pets’ names — are commonly sold on the dark web. Of course, the scammers could also have learned about my son from a 30-second perusal of my Instagram feed.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqs005d3b7yi3kdpybt@published" data-word-count="194">It was my brother, the lawyer, who pointed out that what I had experienced sounded a lot like a coerced confession. “I read enough transcripts of bad interrogations in law school to understand that anyone can be convinced that they have a very narrow set of terrible options,” he said. When I posed this theory to Saul Kassin, a psychology professor at John Jay College of Criminal Justice who studies coerced confessions, he agreed. “If someone is trying to get you to be compliant, they do it incrementally, in a series of small steps that take you farther and farther from what you know to be true,” he said. “It’s not about breaking the will. They were altering the sense of reality.” And when you haven’t done anything wrong, the risk of cooperating feels minimal, he added. An innocent person thinks everything will get sorted out. It also mattered that I was kept on the phone for so long. People start to break down cognitively after a few hours of interrogation. “At that point, they’re not thinking straight. They feel the need to put an end to the situation at all costs,” Kassin said.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqu005e3b7y07dv8lkh@published" data-word-count="49">I wondered how often scammers are caught and about the guy who’d driven the car to my apartment. But when I asked experts, they doubted he’d be a meaningful lead. One pointed out that he might have been a courier who was told to come pick up a box.</p>

  <p data-editable="text" data-uri="www.thecut.com/_components/clay-paragraph/instances/clsm54jqu005f3b7yoixur5gq@published" data-word-count="82">I still don’t believe that what happened to me could happen to anyone, but I’m starting to realize that I’m not uniquely fallible. Several friends felt strongly that if the scammers hadn’t mentioned my son, I would never have fallen for this. They’re right that I’d be willing to do — or pay — anything to protect him. Either way, I have to accept that someone waged psychological warfare on me, and I lost. For now, I just don’t answer my phone.</p>

  






  

  <section data-uri="www.thecut.com/_components/package-list/instances/cls9hxrti000l3b80029g93f4@published" data-track-type="article-list">
  
    <ul>
        <li data-track-type="article-link" data-track-component-name="package-list" data-track-page-uri="www.thecut.com/_pages/cls9i46y900000ik7rxitcouj@published" data-track-headline="Paloma Elsesser on the Price of Being ‘First’" data-track-index="0" data-track-component-title="">
          <span>
            <svg viewBox="0 0 7 12" xmlns="http://www.w3.org/2000/svg"><path d="M.66 11.28L3.6 5.85.66.6l5.76 5.25z" fill="#D0011B" fill-rule="evenodd"></path></svg>

          </span>
          <a href="https://www.thecut.com/article/paloma-elsesser-model-of-the-year-essay.html">
            <span>
              Paloma Elsesser on the Price of Being ‘First’
            </span>
          </a>
        </li>
        <li data-track-type="article-link" data-track-component-name="package-list" data-track-page-uri="www.thecut.com/_pages/clsktvimz00000iipm0b8mvnn@published" data-track-headline="Would You Spend $860 on These Stretchy Pants?" data-track-index="1" data-track-component-title="">
          <span>
            <svg viewBox="0 0 7 12" xmlns="http://www.w3.org/2000/svg"><path d="M.66 11.28L3.6 5.85.66.6l5.76 5.25z" fill="#D0011B" fill-rule="evenodd"></path></svg>

          </span>
          <a href="https://www.thecut.com/article/high-sport-kick-flare-pants-review.html">
            <span>
              Would You Spend $860 on These Stretchy Pants?
            </span>
          </a>
        </li>
        <li data-track-type="article-link" data-track-component-name="package-list" data-track-page-uri="www.thecut.com/_pages/clsks7xlk002l0ikmupy5xx6u@published" data-track-headline="The Lure of Divorce" data-track-index="2" data-track-component-title="">
          <span>
            <svg viewBox="0 0 7 12" xmlns="http://www.w3.org/2000/svg"><path d="M.66 11.28L3.6 5.85.66.6l5.76 5.25z" fill="#D0011B" fill-rule="evenodd"></path></svg>

          </span>
          <a href="https://www.thecut.com/article/marriage-divorce-should-i-leave-my-husband-emily-gould.html">
            <span>
              The Lure of Divorce<!---->&nbsp;<span></span>
            </span>
          </a>
        </li>
    </ul>
      
      <a href="https://www.thecut.com/tags/spring-2024-fashion-issue" aria-label="See All from More From the spring 2024 fashion issue">
        <span>See All</span>
        <span>
          <svg viewBox="0 0 7 12" xmlns="http://www.w3.org/2000/svg"><path d="M.66 11.28L3.6 5.85.66.6l5.76 5.25z" fill="#D0011B" fill-rule="evenodd"></path></svg>

        </span>
      </a>
</section>


    </div>

    


          



      <span>How I Got Scammed Out of $50,000</span>



  </section>
  
</article>

  

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Nitter officially declared "over" today – alternatives? (208 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=39382590</link>
            <guid>39382590</guid>
            <pubDate>Thu, 15 Feb 2024 13:45:02 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=39382590">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="39389151"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39389151" href="https://news.ycombinator.com/vote?id=39389151&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>I mostly have the same attitude to this as I do to sites with ridiculously aggressive cookie popups… I don’t need to see the content, I can just go for a walk in the sun instead.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39389179"><td></td></tr>
                  <tr id="39388989"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39388989" href="https://news.ycombinator.com/vote?id=39388989&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Public-facing tweets are a huge part of Twitter's value proposition. Between this, removal of verification, and publish.twitter.com being broken, I wonder how many of the biggest outlets and organizations will continue to abide Twitter's decline.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39383208"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383208" href="https://news.ycombinator.com/vote?id=39383208&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>There's two distinct Nitter use cases I need to replace.<p>1. Someone drops a link to Twitter. Twitter hides threads and throws items in some weird non-chronological order—assuming I don't get a login wall. I need an unfucked UI.</p><p>2. There are some content I can't get anywhere else that I follow through RSS. I wish these people would move elsewhere, but if they haven't by now, they probably won't ever.</p><p>I may just run a local instance with an account created for the purpose if that remains viable, but associating all that with a single login/IP address is something I'd like to avoid.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389366"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39389366" href="https://news.ycombinator.com/vote?id=39389366&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>1) Ask people to send screenshots of the tweets instead of links. I think this has naturally been happening a lot more over the years anyway and people will just get used to do that.<p>2) I guess those people will slowly realize they have lost most of their audience anyway.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389494"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39389494" href="https://news.ycombinator.com/vote?id=39389494&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Right? (#2), I can't be so far in the minority to just not be willing to bother with Twitter. There is really very little content that will compel me to have a bad time consuming it. Is it 1 out of 10? 2 out of 10? More? Even if it's just 10% that's still significant. Just my $0.02 of course.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39388549"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39388549" href="https://news.ycombinator.com/vote?id=39388549&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>In addition to a chronological feed, Nitter provided pagination and link de-obfuscation. Would be nice to get that back somehow.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39383350"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383350" href="https://news.ycombinator.com/vote?id=39383350&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Right, all the "just don't use it" comments miss the point. I used Nitter specifically because I don't use twitter, so I could see the contents of a link that was being posted or discussed. I suppose a solution could be "ignore a large swath of posts and links and discussions" which is basically what I do, but sometimes it's nice to have the option to look at them. Same as if you don't use MS Word, someone might still occasionally send you a word document and it's nice to have a way to open it without having to install Word.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383398"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39383398" href="https://news.ycombinator.com/vote?id=39383398&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>+1. Need something like archive.today/.is for Twitter so you can rip and archive the content that might not live elsewhere. Grab it, stick it in Wayback Machine, return a Wayback url.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383512"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383512" href="https://news.ycombinator.com/vote?id=39383512&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>+1 on Reddit as well.<p>Reddit doesn't have login walls yet but it has way too much information stored within their walls to not have a backup / non-social-media way of extracting it. It's infeasible to have Reddit blocked because it's UI is intended to be addictive like all social media but also be able to extract information from it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39388801"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39388801" href="https://news.ycombinator.com/vote?id=39388801&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>There are 18+ age walls that just force you to login, often in unnecessary places.<p>Plus mobile sometimes refuses to show some things.</p><p>old.reddit still works though.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39383542"><td></td></tr>
                <tr id="39389225"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39389225" href="https://news.ycombinator.com/vote?id=39389225&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>It’s dying a slow death through neglect. Image posts don’t work correctly, image comments don’t show up, and the dirent comment links generated from www don’t work on old</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39389533"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_39389533" href="https://news.ycombinator.com/vote?id=39389533&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Still better than logging in, using the new web app or downloading the app.<p>It's not like 95% of the content is any good anyway. You have to dig deep into a niche to really get any value, and the last few years, less and less. Of course, I haven't logged in for 3-4 years so maybe I'm missing something. Doubt it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39388786"><td></td></tr>
                <tr id="39389450"><td></td></tr>
                        <tr id="39383923"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383923" href="https://news.ycombinator.com/vote?id=39383923&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>The EFF just recently wrote an article with instructions on how to persevere &amp; archive your own tweets on the Wayback Machine, but it involves exporting your own backup and uploading it to them. Since the API is completely cut off from Twitter, there is no official way to backup other people's accounts.<p>But archive.today uses scraping and all sorts of tricky methods to bypass paywalls. I honestly don't understand why Nitter can't just stay logged out and rotate IPs. Although I'm sure that gets pricey when other people are accessing it constantly.</p><p><a href="https://www.eff.org/deeplinks/2024/01/save-your-twitter-account" rel="nofollow">https://www.eff.org/deeplinks/2024/01/save-your-twitter-acco...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39384026"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39384026" href="https://news.ycombinator.com/vote?id=39384026&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>If the scraping model is impaired due to aggressive countermeasures, end game are browser extensions that scrape as users view the site and ship scraped data back to a processor, similar to recap the law (uses an extension to scrape the PACER legal database and ship digital artifacts to the Internet Archive). Care will need to be taken around potentially sensitive data that could be shipped if users are logged in.<p><a href="https://free.law/recap" rel="nofollow">https://free.law/recap</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39387356"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39387356" href="https://news.ycombinator.com/vote?id=39387356&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Oh, that's a very cool project! How successful has it been? If it wasn't for Sci-hub that would be a great idea for the scientific publishing world as well.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39388410"><td></td></tr>
                  <tr id="39388603"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39388603" href="https://news.ycombinator.com/vote?id=39388603&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>This model also works well for deep web content archiving.<p>There was a gaming message board where someone wrote a browser extension that would back up all topics someone visited in the background while they were reading them.  It became important for archiving as much content from those forums as possible as the forum was in the process of shutting down.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="39384714"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39384714" href="https://news.ycombinator.com/vote?id=39384714&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Why don't you make a twitter account and install a duplicate web browser that you only use to open twitter links (and other crap that you don't want polluting your normal browser)?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39386202"><td></td></tr>
                <tr id="39386651"><td></td></tr>
                <tr id="39388570"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39388570" href="https://news.ycombinator.com/vote?id=39388570&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>You also need a burner phone number. Otherwise it will be difficult to get an account.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39383412"><td></td></tr>
                <tr id="39383489"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383489" href="https://news.ycombinator.com/vote?id=39383489&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>If the content we wanted was on Mastodon, we would not be having this conversation. Your comment is deeply unhelpful.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383838"><td></td></tr>
                <tr id="39384216"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39384216" href="https://news.ycombinator.com/vote?id=39384216&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>You're looking at a vase and seeing two faces side-on.<p>"Twitter won't let me read content people post on it"</p><p>"Try posting it on Mastodon"</p><p>"If it was on Mastodon we wouldn't be having this conversation"</p><p>"Whatever, you don't share anything from Twitter anyway"</p><p>Can you see the vase yet?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39384929"><td></td></tr>
                  <tr id="39384218"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39384218" href="https://news.ycombinator.com/vote?id=39384218&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>The issue isn't me posting Twitter links here or elsewhere. It's what to do when others do.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39387819"><td></td></tr>
                <tr id="39389341"><td><table>  <tbody><tr>    <td indent="7"><img src="https://news.ycombinator.com/s.gif" height="1" width="280"></td><td>
      <center><a id="up_39389341" href="https://news.ycombinator.com/vote?id=39389341&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Much as I dislike login walls, Mastodon still doesn't respect `:prefers-color-scheme`, so they're not my friends either.</span></p></div></td></tr>
        </tbody></table></td></tr>
                                    <tr id="39383527"><td></td></tr>
                        <tr id="39383482"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383482" href="https://news.ycombinator.com/vote?id=39383482&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>I’d also vote for 3) the user interface is fast, responsive, and not total garbage inflicted with man boy ego whim randomly mutating a decade of questionable product management decisions</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39384052"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39384052" href="https://news.ycombinator.com/vote?id=39384052&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>It's over.<p>It isn't just Twitter, it's every single website that's turned themselves into a login-walled "application".</p><p>Twitter's relative openness lasted a long time. It was open by default because it is a product built in 2006, when the idea of coralling people into walled gardens to show them ads didn't exist.</p><p>Apps built later take the concept of "walled garden" as a default feature. Slack , Discord, Snapchat, Tiktok, Telegram .... all largely closed off platforms. You can't see anything unless you're logged in.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389638"><td></td></tr>
            <tr id="39386562"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39386562" href="https://news.ycombinator.com/vote?id=39386562&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>But Twitter is an ad-driven platform. Most of those other ones are not. It's ALL about the exposure to eyeballs. But now that Elon chewed on some wires and killed whole colocations, they are not able to serve all that traffic that is supposed to view the ads - for all the talk about how "Twitter is still running like it used to" after being gutted like a fish. It is definitely not.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383621"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383621" href="https://news.ycombinator.com/vote?id=39383621&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>For the same reason given for Nitter stopping, it is unlikely that you'll find a public service like that. There are nitter-like options, including forks of nitter itself, that you can self-host to give a better UX, but with those you have to have a twitter⁰ account for it to login with.<p>Another option (that also requires an account) is to use twitter⁰ itself with a browser extension that tweaks the UI.</p><p>My solution is the one I've been using for a _long_ time: simply don't go there. It has never been more than a novelty-gone-wrong, unless you count “a cesspool of humanity” as more, and as far as I know I've not missed out on anything significant. If you want me not to know what you have to say, say it on twitter⁰! Though I acknowledge that this is not an acceptable solution for all.</p><p>--</p><p>[0] The site desperately trying to be known as Χ
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383833"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383833" href="https://news.ycombinator.com/vote?id=39383833&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>In terms of a browser extension for Twitter, I highly recommend Control Panel for Twitter. It works as a browser extension as well as on some mobile browsers. It is highly customizable to filter out who/what you don't want to see and is fully open source if you feel the need to tweak.<p>It's updated regularly and the creator is highly active on Twitter to provide updates and answer questions - @ControlPanelFT</p><p>If you decide to use it, drop the guy a donation, they work hard on it!</p><p><a href="https://github.com/insin/control-panel-for-twitter">https://github.com/insin/control-panel-for-twitter</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39384413"><td></td></tr>
                <tr id="39387460"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39387460" href="https://news.ycombinator.com/vote?id=39387460&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>That looks interesting in theory, but unfortunately it was last updated in Feb 2022 so I would doubt highly it still works. There were a great deal of 3rd party tools to reduce abuse, bots and known bad actors on Twitter, but Elon took that all away when he restricted access to the API to only those paying $42k/month.<p>I haven't actively been on Twitter since July, but after he essentially removed the majority of moderation staff after he bought the place, reporting people is basically a non-working feature anyway. I remember getting a notice on someone I reported 3 months after the fact.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="39383505"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383505" href="https://news.ycombinator.com/vote?id=39383505&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Twitter became the defacto public square, so it's understandable that there's inertia for society to keep visiting.<p>This particular public square has been bought and fenced off. Ostensibly this is to drive more traffic to it.</p><p>Passively standing outside the fence trying to peek in is a lost cause. Find a new public square and convince as many people as you can to move. To do that, engage with those who moved, and create compelling reasons to go to the new public square.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389519"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39389519" href="https://news.ycombinator.com/vote?id=39389519&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Was twitter ever really a defacto public square? The fact that some notable people used it doesn't make it a public square. I've seen stats that show only something like 1-3% of the US population has a twitter account. Facebook is much more of a "public square" than twitter ever was.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39388192"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39388192" href="https://news.ycombinator.com/vote?id=39388192&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>There is enough decent resources on Twitter to warrant signing up IMO.  I just avoid installing the app so I don't end up browsing it.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39384024"><td></td></tr>
                <tr id="39385644"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39385644" href="https://news.ycombinator.com/vote?id=39385644&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>They work only for a few more days, till their account expires (30 days after creation). After that no more guest account creation is possible: each instance will go red one by one.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39386344"><td></td></tr>
                        <tr id="39383410"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383410" href="https://news.ycombinator.com/vote?id=39383410&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>"I don't like twitter, I don't want to have an account on twitter, yet I <i>demand</i> to be able to read content posted on twitter" Honestly, I cannot understand the point of view of some commenters here.<p>Don't like the platform? Then don't use it! It's not mandatory. You can find content elsewhere online. You can block submissions on HN that link to twitter. Or you can just create an account with fake info and be done with it.</p><p>I don't actively use Twitter myself (as I'm not based in the US), but I have an account that I use solely for reading. The overwhelming number of similar comments actually makes me want to use it more.</p><p>/rant (and now feel free to downvote instead of replying)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389208"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39389208" href="https://news.ycombinator.com/vote?id=39389208&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt;Don't like the platform? Then don't use it! It's not mandatory.<p>Sorry, my public officials seem to be using it as an official communications platform. For many people, it is in fact mandatory.</p><p>&gt;You can find content elsewhere online.</p><p>Not if someone sends you a link to a twitter thread and you can only see the first tweet without logging in. You can only see that content right there.</p><p>&gt; I have an account that I use solely for reading. The overwhelming number of similar comments actually makes me want to use it more.</p><p>This attitude will make you fit right in there.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389431"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39389431" href="https://news.ycombinator.com/vote?id=39389431&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>As an example, local police here sent out urgent missing person reports and the "more information" link was a twitter link (behind a bit.ly shortener if you can believe it)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39389347"><td></td></tr>
            <tr id="39389425"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39389425" href="https://news.ycombinator.com/vote?id=39389425&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt;Sorry, my public officials seem to be using it as an official communications platform. For many people, it is in fact mandatory.<p>I don't believe that anyone but Elon Musk use twitter as its only communicatuon platform.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39389510"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39389510" href="https://news.ycombinator.com/vote?id=39389510&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>I agree. It's not hard to make an account to "lurk". I'm sure most of those complaining have accounts at various other social media websites. It may cost some privacy, but I find the content more than worthwhile.<p>There is content on Twitter that is not available anywhere else. It frequently breaks news faster than any other source, and there are many high profile posters who use it as their only broadcast source. Some memorable examples include the FTX and OpenAI fiascos.</p><p>The website isn't stellar, but it is functional. Lists are a great feature to separate content into custom feeds.</p><p>Maybe there will be something in the future that can serve as an alternative, but there is none currently.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39389422"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39389422" href="https://news.ycombinator.com/vote?id=39389422&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; "I don't like twitter, I don't want to have an account on twitter, yet I demand to be able to read content posted on twitter" Honestly, I cannot understand the point of view of some commenters here.<p>Why is it surprizing? What's there to understand? It's web. Twitter used to be a decent web citizen, and allowed you to read its posts like you would read web pages. I don't want an account on Mastodon; yet I can read content posted to Mastodon. I don't want an account on Bluesky; yet I can read content posted to Bluesky. Twitter used to be like that, and we got used to it, and now it's not, and it's infuriating.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39386616"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39386616" href="https://news.ycombinator.com/vote?id=39386616&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>I'll do both.<p>People that create twitter accounts do so because they want reach. They want to be able to publish freely, to the internet, to share ideas, information they have, memes, whatever. But now, their reach is limited to other twitter accounts. Their voice is no longer public on the internet.</p><p>Twitter has some inertia that will carry this new model for now, there's a lot of twitter accounts, so many that most people won't know the difference at first. But as time goes on and people want to make things public and people slowly stop posting twitter links everywhere because they're useless (only useful to people with twitter accounts, so why share them outside of twitter in the first place) and every reference to something on twitter becomes a screenshot, people will look for alternatives to broadcast their thoughts.</p><p>Twitter is supposed to be a website where people can share ideas. You need an account to share ofc, but it's still supposed to be a website, you go there and read things. That's not possible anymore. Reading what someone has to say is only "using it" in the most tenuous sense. Using twitter is posting to it. People being able to read what you say is the whole point. They think they're forcing the whole world to get twitter accounts, but what they're really doing is forcing twitter users to share their ideas in more than one place, it's not going to turn out good for the company in the long run.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39388925"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39388925" href="https://news.ycombinator.com/vote?id=39388925&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; They want to be able to publish freely, to the internet, to share ideas, information they have, memes, whatever.<p>Is this necessarily true? At this point, I would figure that people who continue to publish on Twitter are aware of its restrictions and continue to communicate there with that knowledge. If anything, one could argue that trying to access Twitter content without an account is what's actually inappropriate here, as posters can no longer trust the guarantees of the platform.</p><p>&gt; Twitter is supposed to be a website where people can share ideas.</p><p>Twitter <i>used</i> to be a website where people can share ideas. Twitter currently is a website where people can share ideas <i>with other Twitter users</i>. If you post on Twitter now with the intention of being truly public on the internet, I'd say you're using the wrong tool for the job. Whether that's a good business decision or not is irrelevant; the fact is that Twitter has changed its purpose, and users should update their expectations accordingly, however they see fit.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383549"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383549" href="https://news.ycombinator.com/vote?id=39383549&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>It's a change in behavior for Twitter, which was built with content and threads in the open.<p>It's ok for people to say, "I like how it was before."
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39387330"><td></td></tr>
            <tr id="39383480"><td></td></tr>
                  <tr id="39388545"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39388545" href="https://news.ycombinator.com/vote?id=39388545&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>libreddit is suffering the same problem. Some instances are still working but they're probably switching outgoing IPs often to evade the ban hammer.<p>As others have noted, I think this is part of a larger trend. All websites have realized that data is power, data is money, and they don't want to share anymore.</p><p>I used to host both nitter and libreddit, now I host neither of them. I've simply given up on reading that data.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39388661"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39388661" href="https://news.ycombinator.com/vote?id=39388661&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Host it your self. I'm doing that with libreddit. Gives me much better performance than the highly used public instances.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39388939"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39388939" href="https://news.ycombinator.com/vote?id=39388939&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>I was self hosting Reddit, which now seems entirely dead, and need to switch over to libreddit. Hopefully that lasts longer...</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39389567"><td></td></tr>
                        <tr id="39382884"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39382884" href="https://news.ycombinator.com/vote?id=39382884&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>What are you looking for? If you want to be anonymous, your are SOL unfortunately. If you are looking for a less crappy browsing experience than Twitter, and Nitter filled that void, you can find forks which fetch content with your Twitter account. Setting up for local self hosting doesn't take a lot of minutes.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383248"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383248" href="https://news.ycombinator.com/vote?id=39383248&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>I used to use Nitter to view content without logging in, as I do not have a twitter account  nor do I want one.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39383988"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383988" href="https://news.ycombinator.com/vote?id=39383988&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>The question is whether or not they'll continue to develop Nitter just for people who want to run it locally. Twitter's page layout &amp; functions get updated and changed CONSTANTLY. If someone isn't updating Nitter regularly it will become depreciated very quickly.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39382707"><td></td></tr>
            <tr id="39383336"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383336" href="https://news.ycombinator.com/vote?id=39383336&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>I have Tampermonkey scripts that delete Twitter entries from HN and anywhere else on the web. Seems to work well for me.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383372"><td></td></tr>
                  <tr id="39389348"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39389348" href="https://news.ycombinator.com/vote?id=39389348&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>When nitter.poast.org announces it is going offline, I will believe "Nitter is over".  (Unless I find another instance that works.)  But this one still works fine.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39388775"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39388775" href="https://news.ycombinator.com/vote?id=39388775&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Why do you need one? It takes a few minutes to make a Twitter account and keep browsing. You probably spent more time writing this post.<p>I'm glad I won't have to deal with people posting these off-brand Twitter links anymore.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39388855"><td></td></tr>
                  <tr id="39383390"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383390" href="https://news.ycombinator.com/vote?id=39383390&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>For the past few weeks I've been using<p><a href="https://twiiit.com/" rel="nofollow">https://twiiit.com/</a></p><p>to find independent nitter servers that can show tweets of the few academics I still want to follow.</p><p>Now Twitter might soon break also these small third party servers but for the moment, they still work.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39384985"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39384985" href="https://news.ycombinator.com/vote?id=39384985&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Started using Twitter in 2006. [Long story] Quit around 2017. Privacy Badger extension blocks embeds. Used to allow occasionally until I noticed it was never worth it and finally stopped reading "news" sites that were sentence|tweet|s|t etc.<p>Used Nitter for a while for the reason many do: to see that 1 tweet or thread that sounds interesting.  Realized it either wasn't or was a little FOMO.</p><p>When I was a kid if you missed a good movie in theaters you had to wait years to see it on TV. I've started returning to that mentality.  If it's genuinely good enough and interesting enough it will turn up somewhere eventually or I'll just miss out.</p><p>I can't number the people who have told me I <i>must</i> subscribe to AppleTV to watch some Ted show no one talks about any more. I always said: "No. It will turn up on some platform I use or come out on Blu-ray or I'll just never see it." For all I know it's on Blu-ray already. I forgot about it until just now it's been so long since I <i>must</i> watch.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39383330"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383330" href="https://news.ycombinator.com/vote?id=39383330&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>I thought that the official instance (nitter.net) works and that it works but visited it now, and it seems it doesn't have a valid certificate since Jan24th.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383707"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383707" href="https://news.ycombinator.com/vote?id=39383707&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>If you're in Chrome it likes to give you a full screen "oh no you can't go to this website!" with no visible override, but if you type in "thisisunsafe" it'll fly by it.<p>I wish Chrome would just let me have the damn button. I'm not a five year old.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389308"><td></td></tr>
                        <tr id="39383862"><td></td></tr>
            <tr id="39383397"><td></td></tr>
                <tr id="39386680"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39386680" href="https://news.ycombinator.com/vote?id=39386680&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>My personal concern is, if I have to sign up for an account to see what you have to say, I don't care what you have to say. If you want reach pick a platform that let's people easily read your thoughts. This is no different than "download the app to continue reading." People on twitter are irrelevant as far as I'm concerned, and they just don't know it yet. They will.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383328"><td></td></tr>
            <tr id="39383131"><td></td></tr>
            <tr id="39383396"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383396" href="https://news.ycombinator.com/vote?id=39383396&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Use a completely different platform. Find users providing content you like. Follow them and interact.<p>Either Twitter opens back up or segments trickle off the platform.</p><p>I used nitter only because it loaded faster and displyed raw cronological order.</p><p>Life existed before Twitter was created. You can do it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383579"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383579" href="https://news.ycombinator.com/vote?id=39383579&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>I think this misses the point that a lot of nitter users aren’t looking for a social media platform to interact with people on, but to access information only available on twitter.  “Use a completely different platform” is useful to people consuming the social media product, but not useful for people who are uninterested in “content you like” but in very specific content they’re interested in.<p>I’m not saying there’s a solution that’s good either or there needs to be a good solution.  It’s a private business and there are all sorts of shitburger private businesses building golden walls around important content only available on their crappy platform and there’s no alternatives other than submit to their exploitation or remain ignorant in the world of subjects that are important to you.</p><p>But it would be nice if there were alternatives between brutal exploitation and unrequited ignorance. But heading over to mastodon or whatever doesn’t help you read “important thread about X discovery” or whatever since the content is singular and only exists on twitter.</p><p>Personally HN is the only social media like platform I use, and I have no interest in maintaining the energy levels to participate in the others. I’m just a passive observer of specific pieces of content in those platforms.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383763"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39383763" href="https://news.ycombinator.com/vote?id=39383763&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span><i>&gt; but to access information only available on twitter</i><p>I see this being said a lot, even by some of my own contacts who insist on occasionally sending me links to things on twitter¹, but I'm not convinced there is really much of worth on there that isn't available elsewhere. What is uniquely on there that I might possibly care about isn't, IMO, worth being associated with or exposed to the rest.</p><p>--</p><p>[1] I used to use nitter to view such things, but stopped that many moons ago and ask if they have any other source, or if it is a joke maybe download/screenshot and forward that way.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383925"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383925" href="https://news.ycombinator.com/vote?id=39383925&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>You may feel the subject is inane, but an example that sticks out in my mind was the Varda replication thread of LK99. It was really only on twitter, I found it entertaining to read occasionally, but I wasn’t really going to invest energy in asking for screenshots etc. But I agree with you regarding being associated with it exposed to the rest. That’s the value nitter brought !  It’s a sad day that it’s gone. End of the world? No. But the world has become slightly less good.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39384984"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39384984" href="https://news.ycombinator.com/vote?id=39384984&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Twitter at least used to be the best place to find official statements from local government, local cops, etc. They would put stuff out on their official accounts, other people would post video of news conferences, and so on. I am not sure there is a replacement.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="39383378"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383378" href="https://news.ycombinator.com/vote?id=39383378&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>I think you have 3 alternatives:<p>1. Create a Twitter account.</p><p>2. Stop using Twitter.</p><p>3. Use Facebook, Tumblr, or Mastodon for microblogging.</p><p>Twitter started requiring a login screen to view posts, but it's not the first website to do so. Pinterest and Instagram have done this for ages. We all hate it, but it's business.</p><p>I wonder why Tumblr isn't more successful than it is. It used to be a pretty well-known platform, and it's almost identical to Twitter, but while every celebrity seems to have a Twitter account, nobody seems to have a Tumblr account. Perhaps they do, they just don't tell anybody about it?</p><p>I wish Mastodon wasn't a thing. I believe federation is a terrible idea for normal computer users due to its non-obvious dangers, specially as more people will begin using Mastodon as if it were Facebook. I saw on Reddit that someone is building an open source, non-federated Reddit clone. That's what I think would have been better: an open-source, non-federated Twitter clone. Does anybody know of something like that, by the way?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383890"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383890" href="https://news.ycombinator.com/vote?id=39383890&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span><i>&gt; I wonder why Tumblr isn't more successful than it is. It used to be a pretty well-known platform, and it's almost identical to Twitter,</i><p>Twitter won over that and a number of other options on novelty, inertia, and notoriety, essentially. A mix of right-place-right-time, further luck, and network effects.</p><p>Tumblr did better than many alternatives, but eventually shot itself in the foot (well, was shot in the foot by its parent) when it alienated a chunk of the audience it did have by deleting a lot of content in order to appease potential advertisers.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39386553"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39386553" href="https://news.ycombinator.com/vote?id=39386553&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; in order to appease potential advertisers.<p>It wasn't advertisers, it was apple, they'd been delisted from the app store, and getting rid of the NSFW material was part of the deal that apple would allow them back with.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383418"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383418" href="https://news.ycombinator.com/vote?id=39383418&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Tumblr used to be a lot more popular, but its collapse is usually attributed to them banning NSFW content. Not everyone was posting or viewing NSFW of course, but there was enough overlap in audiences to cause a cascade which ended with nearly everyone, NSFW or not, moving to Twitter.<p>It's a classic Yahoo acquisition fumble, they bought it for $1.1 billion and ended up selling it on to Automattic for just $3 million post-exodus.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389379"><td></td></tr>
                  <tr id="39383500"><td></td></tr>
                <tr id="39383565"><td></td></tr>
                <tr id="39389543"><td></td></tr>
            <tr id="39389505"><td></td></tr>
            <tr id="39383759"><td></td></tr>
                                        <tr id="39383182"><td></td></tr>
            <tr id="39383187"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383187" href="https://news.ycombinator.com/vote?id=39383187&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>nitter.cz is one of many mirrors. The official site was nitter.net (which is down as well).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39385919"><td></td></tr>
            <tr id="39383320"><td></td></tr>
                <tr id="39385751"><td></td></tr>
                <tr id="39389441"><td></td></tr>
            <tr id="39385972"><td></td></tr>
                  <tr id="39383535"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383535" href="https://news.ycombinator.com/vote?id=39383535&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Too few people who care, too many that are happy to be fed what the twitter algo decides they should see. Dopamine takes care of the rest.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383697"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39383697" href="https://news.ycombinator.com/vote?id=39383697&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Too few people care for what to happen?<p>Maybe I am misreading your post, but why does it matter if people behave in a certain way en masse, when the majority of the personal impact is based on personal behavior.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383648"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383648" href="https://news.ycombinator.com/vote?id=39383648&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>This is the actual answer... but social networks are super sticky, and trap people in with the threat of cutting other people off who also cant/wont leave.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="39383519"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383519" href="https://news.ycombinator.com/vote?id=39383519&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Despite the outrage, I think only a minority of users think this.<p>Most twitter users like it, and didn't even attempt to move to another platform.</p><p>I personally tried substack notes, mastodon and bluesky, and none of them bring 0.1% of the activity and interesting things that used to happen on twitter.</p><p>Now twitter is less interesting than before, but it still the only candidate that is worth my time. Even reddit is slowly becoming meh.</p><p>I'm certain that the new generation, however, is creating their own wonderland in a place I'm not active in. That's how we got twitter started, it's usually the young that stir those things.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383183"><td></td></tr>
                <tr id="39386649"><td></td></tr>
                  <tr id="39383309"><td></td></tr>
                <tr id="39383563"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383563" href="https://news.ycombinator.com/vote?id=39383563&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>There is no such thing as "one twitter", it's way too big.<p>I assume your activity mean you must be filtered in a bucket that shows you those things, because I never encounter such tweets in my timeline.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39383338"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383338" href="https://news.ycombinator.com/vote?id=39383338&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>So does Google, Facebook, Tumblr, Cloudflare, GoDaddy, and Dreamhost.<p>Should we stop linking to all information on all of these platforms because some of the information is undesirable to some people?</p><p>Do you allow others to poison your well like that?  If so, that strikes me as easily exploitable.</p><p>Also, the idea that this sort of content is inherently dangerous doesn’t hold water. I’m not going to become a white supremacist because Twitter showed me a racist tweet.  Information and ideology is not inherently dangerous.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39385006"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39385006" href="https://news.ycombinator.com/vote?id=39385006&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; So does Google, Facebook, Tumblr, Cloudflare, GoDaddy, and Dreamhost.<p>That is intentionally and maliciously obfuscating the issue by equating social media (Google, Facebook, Tumblr) with infrastructure hosting (Cloudflare, GoDaddy, and Dreamhost).</p><p>Those two types of companies are <i>very</i> different and should be regulated very differently.</p><p>&gt; Should we stop linking to all information on all of these platforms because some of the information is undesirable to some people?</p><p>Um, yes?</p><p>Links to social media vaporize regularly.  If it isn't worth the effort to pull and host onto a less ephemeral medium, was it really worth sharing at all?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39383591"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39383591" href="https://news.ycombinator.com/vote?id=39383591&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; So does Google, Facebook, Tumblr, Cloudflare, GoDaddy, and Dreamhost.<p>Those are all very different things. Only Facebook is somewhat similar in that it has an algorithm that surfaces emotionally engaging content.</p><p>&gt; I’m not going to become a white supremacist because Twitter showed me a racist tweet.</p><p>How about if it showed you 50 racist tweets? If repetition and exposure didn't have any effect on our behaviour then there would be no advertising market and no one would bother to spend vast sums on political campaigning.</p><p>&gt; Information and ideology is not inherently dangerous.</p><p>How about misinformation? As an example, I'd say the rise in anti-vaccination activity is an example of inherently dangerous information that has been spread primarily through social media.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383605"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383605" href="https://news.ycombinator.com/vote?id=39383605&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Neither is misinformation inherently dangerous.  There are 400,000 churches in the US and every year fewer people identify as religious.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383415"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39383415" href="https://news.ycombinator.com/vote?id=39383415&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; Also, the idea that this sort of content is inherently dangerous doesn’t hold water. I’m not going to become a white supremacist because Twitter showed me a racist tweet. Information and ideology is not inherently dangerous.<p>There's been enough work that suggests a close link between exposure to propaganda and getting funneled in to increasingly more radical material, e.g. [1].</p><p>Particularly regarding Twitter, it's noticeable that it's not just <i>one</i> racist tweet that gets shown to you when you deliberately click on one - the space below will be filled with similar kind of content, and you can see a marked increase of far-right crap on your algorithmic timeline as well, with every little interaction you have with far-right content.</p><p>It was bad before Musk, but since his takeover it's gotten really really bad.</p><p>[1] <a href="https://www.technologyreview.com/2020/01/29/276000/a-study-of-youtube-comments-shows-how-its-turning-people-onto-the-alt-right/" rel="nofollow">https://www.technologyreview.com/2020/01/29/276000/a-study-o...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39383729"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383729" href="https://news.ycombinator.com/vote?id=39383729&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; you can see a marked increase of far-right crap on your algorithmic timeline as well, with every little interaction you have with far-right content.<p>And?</p><p>I trust people to be intelligent enough to make their own decisions. If seeing an incredibly (or even mildly) racist tweet suddenly makes them proverbially goose-step around their home, they already were going to. One, ten, or hundred posts won't make them racist unless they were already predisposed to those ideas. In a healthy mind, viewing alternative views may broaden their view which might include disagreeing with their previous opinions.</p><p>If viewing a gay marriage doesn't make you gay, neither does seeing someone complain about other races or LGBT people. I am on 'your' side politically but the opinion that all conservative opinion should be extinguished or somehow that it is inherently harmful because you disagree with is just as bad as conservatives saying the same about your opinion.</p><p>There is no harm in reading and understanding other's opinions. All sides need to understand that. It only crosses into the need for 'deplatforming' when they are making implicit or explicit threats against a person or a group of people.</p><p>"I think &lt;x&gt; race is less likely to be successful due to &lt;x, y, z&gt;" is not a bad opinion. It may be wrong, but it isn't hurtful beyond maybe to someone who is too sensitive. "I think &lt;x&gt; race should be exterminated" is beyond the line and shouldn't be allowed to be posted publicly.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39385922"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39385922" href="https://news.ycombinator.com/vote?id=39385922&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; If viewing a gay marriage doesn't make you gay, neither does seeing someone complain about other races or LGBT people.<p>This is a great line that probably pisses off almost everybody. Love it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383562"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383562" href="https://news.ycombinator.com/vote?id=39383562&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Your link mentions YouTube. Under your logic, should we also stop using YouTube because its recommendations will radicalize us?<p>This line of thinking doesn’t make sense to me.  Furthermore, bad ideology and its ideologues won’t go away simply because we individually stop looking at them.</p><p>I quit Twitter after 12 years when they started censoring the site search.  I was trying to research QAnon wackos and it turns out that the search box had been neutered.</p><p>It’s one thing to tell people what they can post, it’s another to tell me what I’m not allowed to read (that is allowed to be posted).</p><p>Fuck censorship.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="39383416"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383416" href="https://news.ycombinator.com/vote?id=39383416&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>What one individual might view as transphobia another would view as radical feminism. The world's not as black and white as you make it out to be.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383495"><td></td></tr>
                <tr id="39383598"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39383598" href="https://news.ycombinator.com/vote?id=39383598&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>The initialism "TERF" means "trans-exclusionary radical feminism"; I'm sure those who hold these views see themselves as being "just" radical feminists — the way the discussions go, it seems to me people with these views are unable to comprehend that the model they have of what gender is, is one of several, or that there is any value in the models they do not themselves have.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39385756"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_39385756" href="https://news.ycombinator.com/vote?id=39385756&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>There's only room for one model when it comes to deciding who gets to use which space though.<p>For example, should a male convict who identifies as a woman be incarcerated in the female prison estate or the male one? There's not really room for several models of sex and gender in answering that question, as there's a single choice to be made with two mutually exclusive options.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39385938"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_39385938" href="https://news.ycombinator.com/vote?id=39385938&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>&gt; There's only room for one model when it comes to deciding who gets to use which space though.<p>One model <i>per space</i>. For example, the answer to "given how much testosterone is now in their body, which gender sports team should this F2M person be on?" is different to "which do we need to screen them for, testicular cancer or cervical cancer?"</p><p>&gt; For example, should a male convict who identifies as a woman be incarcerated in the female prison estate or the male one? There's not really room for several models of sex and gender in answering that question, as there's a single choice to be made with two mutually exclusive options.</p><p>Four[0] options, if you think outside the box.</p><p>Ideally, I would have my prisons set up with enough guards that this doesn't matter. As I don't live in the ideal world, I would also have a[0] trans estate for those who have begun but not yet completed transitioning, and those who have completed a transition would be in whatever the new gender is.</p><p>[0] or +1, if M2F != F2M while transitioning
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                                          <tr id="39388245"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39388245" href="https://news.ycombinator.com/vote?id=39388245&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>Twitter, oh sorry X, died on the day everything went completely batshit insane, politicized and radicalized anyway. To the point people got (and still are!) permanently suspended for no good reason at all.<p>Such a shame, ~10 years ago it used to be tons of fun with some really good discussions in the mix.</p><p>But times are really changing I guess. And not for the better.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="39383129"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383129" href="https://news.ycombinator.com/vote?id=39383129&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>If you don't like twitter, why not just not use it? I guess it sucks that you can't click twitter links, but honestly, you're not missing anything. Whenever I jump through some hoop to view a tweet linked here, it's not worth it.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383265"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383265" href="https://news.ycombinator.com/vote?id=39383265&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>There are sometimes newsworthy things on Twitter. I have the domain blocked at the Pihole to break the "check Twitter" loop I get into; having to do the Nitter thing helped enormously in breaking the bad habit.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383954"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39383954" href="https://news.ycombinator.com/vote?id=39383954&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span><i>&gt; There are sometimes newsworthy things on Twitter.</i><p>If something is particularly newsworthy, it'll appear elsewhere in pretty short order IME, often it originated elsewhere in fact.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39388274"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39388274" href="https://news.ycombinator.com/vote?id=39388274&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Sometimes the tweets themselves <i>are</i> newsworthy, or the news articles cite a tweet. Some local governments use Twitter for announcements you can't easily get elsewhere, especially during a disaster like a big snowstorm.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="39383423"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_39383423" href="https://news.ycombinator.com/vote?id=39383423&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>There are people doing things of interest to me where I can either read it on Twitter (currently using Nitter's RSS feeds) or see the misleading blogspam or fluff-filled YouTube video about it a few days later. I'd rather get the information from the source.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="39383788"><td></td></tr>
            <tr id="39383239"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_39383239" href="https://news.ycombinator.com/vote?id=39383239&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Farcaster has been a nice refreshment for me. Currently a lot of developer types are present on the platform and I've seen lots of insightful conversations there.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="39383317"><td></td></tr>
                <tr id="39384768"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_39384768" href="https://news.ycombinator.com/vote?id=39384768&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><p><span>I looked it up and apparently there is a "$5 sign-up fee", and posts/reactions are not free too:<p>&gt;To sign up, users must pay a $5 sign-up fee, meant to prevent the creation of spam accounts. Further, users can only post a limited number of “casts” on Farcaster apps, which are tied to packages called storage units. Storage units, which go for $5 a piece, grant a user 5,000 casts, 2,500 reactions, and 2,500 links or photo posts within a one-year period.</p><p>(some shady website)</p><p>Yeah, that will surely make millions of users to sign up /s
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="39389166"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_39389166" href="https://news.ycombinator.com/vote?id=39389166&amp;how=up&amp;goto=item%3Fid%3D39382590"></a></center>    </td><td><br><div>
                  <p><span>Yeah, I don't get it. Social media sites thrive on interaction. Giving users a reason to hesitate before interacting is going to snuff out a lot of the casual interactions that make a site feel "alive".</span></p></div></td></tr>
        </tbody></table></td></tr>
                              </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub now officially supports polar.sh as a funding platform (122 pts)]]></title>
            <link>https://twitter.com/birk/status/1758087210211909649</link>
            <guid>39382281</guid>
            <pubDate>Thu, 15 Feb 2024 13:15:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/birk/status/1758087210211909649">https://twitter.com/birk/status/1758087210211909649</a>, See on <a href="https://news.ycombinator.com/item?id=39382281">Hacker News</a></p>
Couldn't get https://twitter.com/birk/status/1758087210211909649: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[How deceptive design is used to compromise your privacy and how to fight back (158 pts)]]></title>
            <link>https://consciousdigital.org/deceptive-design-patterns/</link>
            <guid>39382264</guid>
            <pubDate>Thu, 15 Feb 2024 13:14:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://consciousdigital.org/deceptive-design-patterns/">https://consciousdigital.org/deceptive-design-patterns/</a>, See on <a href="https://news.ycombinator.com/item?id=39382264">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-6826">
  
  <div data-hide-featured-media="1">
<p>Today, we’re releasing a new <a href="https://consciousdigital.org/deceptive-patterns/">guide</a> explaining how to compel companies employing deceptive design to dodge data protection requests—like those for data deletion or access—to comply. It encapsulates five years of experience from operating <a href="http://yourdigitalrights.org/">YourDigitalRights.org</a> and <a href="http://databrokerswatch.org/">DataBrokersWatch.org</a>, alongside a unique experiment and extensive research. Here’s the story behind it.</p>



<p>Deceptive design, also known as deceptive patterns or dark patterns, refers to the tactics companies employ through design to manipulate individuals into actions they wouldn’t normally take. For example, websites sometimes use deceptive patterns to manipulate people to purchase expensive products or subscriptions by concealing free or more affordable alternatives:</p>



<div>




<p>For a cheaper Google Workspaces subscription, first subscribe to the expensive option and then downgrade (Source: <a href="http://deceptive.design/">deceptive.design</a>)</p>
</div>



<p>Similarly, companies employ deceptive tactics to avoid complying with data protection requests. These are legal rights that allow individuals to ask a company to delete or share a copy of their personal data. The encouraging news is that more than five years since the GDPR—the legal framework in the EU that gives individuals the right to access or delete their data—was introduced, most companies now adhere to these data protection requests.</p>



<p>The downside, however, is that some companies continue to resist compliance. Specifically, data-centric enterprises, whose business models hinge on gathering personal data—like data brokers and social networks—resort to deceptive design practices to skirt data protection requests. This is particularly concerning because these entities hold vast amounts of personal data and often use it in the most objectionable ways. As a result, they are the primary targets from whom we seek to erase our data.</p>



<p>In 2022, we embarked on an unconventional experiment. We sent a data deletion request to each of the 600 data brokers listed on <a href="http://databrokerswatch.org/">DataBrokersWatch.org</a> to observe their reactions. This experiment allowed us to uncover numerous deceptive patterns and formulate effective countermeasures – strategies to bypass these dark patterns. Often, our countermeasures persuaded the companies to honor our deletion requests. When they didn’t, we escalated the issue to a government regulator (a process <a href="http://yourdigitalrights.org/">YourDigitalRights.org</a> can handle for you). Looking back, the effort was worthwhile. We’ve noticed a trend towards better compliance among data-centric businesses. We detailed our findings in a <a href="https://www.youtube.com/watch?v=SY_YAZEJPjc&amp;t=1s">presentation</a> at the 2022 Good Tech Fest for those interested in learning more.</p>



<p>We hope you find the guide useful and would appreciate your feedback.</p>


<p><a href="https://consciousdigital.org/wp-content/uploads/2023/04/deceptive-patterns.pdf" data-width="max" data-height="max" data-toolbar="bottom" data-toolbar-fixed="off">deceptive-patterns<br></a></p>

<p id="jp-relatedposts">
	<h3><em>Related</em></h3>
</p></div><!--/inner-wrap-->
    
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Managing mutable data in Elixir with Rust (126 pts)]]></title>
            <link>https://www.lambdafunctions.com/articles/elixir-and-rust</link>
            <guid>39382227</guid>
            <pubDate>Thu, 15 Feb 2024 13:09:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lambdafunctions.com/articles/elixir-and-rust">https://www.lambdafunctions.com/articles/elixir-and-rust</a>, See on <a href="https://news.ycombinator.com/item?id=39382227">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
<h2>
Managing mutable data in Elixir with Rust</h2>
<p>
One of Elixir’s core benefits, and the secret to its robustness and scalability,
is its foundation on immutable data.  Sometimes, though, immutability is just
not a great fit for a particular task—but that task is only one part of a large
project.  Is it possible to enjoy the benefits of Elixir’s data model everywhere
else, but carve out a little mutable exception for one area?</p>
<p>
Yes!</p>
<p>
A long-running Elixir project I’m involved in has just this problem.  The
project is delivered over the web, so moving away from Elixir as a whole is not
on the cards because <a href="https://www.phoenixframework.org/">Phoenix</a> is quite
simply a cheat code for web development.  We <em>could</em> hive off the mutable
section into a microservice, but that would require significant architectural
and management overhead.  All we really need is a little escape hatch for a
limited chunk of code, while still being within the same VM and able to interact
normally with the rest of the service.</p>
<p>
This is just what <a href="https://github.com/rusterlium/rustler">Rustler</a> offers.</p>
<p>
Rustler is “a library for writing Erlang NIFs in safe Rust code”—in other
words, you can write code that looks like standard Elixir functions, but behind
the scenes is actually implemented in Rust.</p>
<p>
<a href="https://www.erlang.org/docs/17/tutorial/nif">NIFs</a> have been a feature of the
Erlang VM since long before either Elixir or Rust arrived on the scene.  What
Rust and Rustler add is:</p>
<ul>
  <li>
    <p>
safety—this is critical since a crash in a NIF will bring down the
whole VM    </p>
  </li>
  <li>
    <p>
a lot of polish and interface glue that makes it feasible to write
more ambitious integrations that you might be inclined to attempt with
C and Erlang’s standard NIF support    </p>
  </li>
  <li>
    <p>
access to all of Rust’s libraries    </p>
  </li>
</ul>
<p>
Unfortunately, most of the Rustler examples on the web focus on the speed
benefits and show the implementation of a trivial <code>add</code> function and then stop
there.  While that’s fine for demonstrating the bare minimum integration
required, for me the interesting part of Rustler is the chance to escape in a
controlled way from the immutable world—I want to explore how to manage a
little mutable chunk of memory in a safe way.  Although Rustler is certainly
capable of this, there’s very little available in the way of tutorials or
examples.</p>
<p>
Hopefully this article will help.</p>
<h2>
Goal</h2>
<p>
As mentioned above, I want to explore memory management.  More specifically, I
want to be able to hold a chunk of data in the Rust world that persists between
multiple calls to different “Elixir” (Rustler) functions.  These functions
should allow the Elixir world to pass data into the Rust world, mutate the data
held there, and then retrieve results.</p>
<p>
To give us something substantial to play with and avoid having to implement our
own data store for this demo, I’ll use Oxigraph.</p>
<p>
<a href="https://github.com/oxigraph">Oxigraph</a> is a Rust graph database library
implementing the SPARQL standard.  Let’s suppose that we want to wrap it, so
that we can have access to a fast graph database from within Elixir.  We’ll call
our wrapper <code>FeGraph</code>.</p>
<p>
We want to be able to:</p>
<ol>
  <li>
    <p>
Make a new in-memory database    </p>
    <pre><code>db = FeGraph.new()</code></pre>
  </li>
  <li>
    <p>
Add data to it    </p>
    <pre><code>FeGraph.set(db, "http://foo.bar.com")
FeGraph.set(db, "http://foo.baz.com")</code></pre>
  </li>
  <li>
    <p>
Export the database as a
<a href="https://en.wikipedia.org/wiki/Turtle_(syntax)">Turtle</a> string:    </p>
    <pre><code>FeGraph.dump_db(db) |&gt; IO.puts()</code></pre>
  </li>
</ol>
<p>
To keep this to a reasonable length, we’re not going to implement everything
that would be required to expose all the capabilities of Oxigraph; just enough
to demonstrate holding data on the Rust side and acting on it from Elixir.</p>
<h2>
Implementation</h2>
<p>
(If you want to follow along, I recommend working through one of the many
Rustler <code>add</code> tutorials I mentioned before getting into the code, so that you
have a basic project up and running and have worked through how Rust and Elixir
functions link together.  Everything below here assumes you’re already at that
point.)</p>
<p>
The key to this whole approach is the ability to pass a
<a href="https://erlang.org/doc/man/erl_nif.html#resource_objects">Resource</a> between the
two worlds.  This acts as a handle to a piece of memory; it can be returned from
a NIF and then passed back into another call.  Exactly what we need.</p>
<p>
A BEAM <code>Resource</code> is represented in Rustler by a
<code>rustler::resource::ResourceArc&lt;T&gt;</code> struct.  To get started with our
implementation, let’s define a new type that we can use as a handle to represent
the state of our graph store.</p>
<p>
In a production scenario we’re likely to want to manage more state than this,
but for now it will suffice to define a <code>MyGraph</code> struct that just contains (via
a mutex) the Oxigraph data store; this represents the mutable data we want to
manage outside Elixir.  In the future, more fields could be added to <code>MyGraph</code>
as necessary.</p>
<p>
To turn this into something that can be passed back and forth between Elixir and
Rust, we need to wrap it in a <code>ResourceArc</code>.  In order to make our function
signatures a bit more readable we’ll define a new type of <code>GraphArc</code> to
represent a <code>MyGraph</code> struct in a <code>ResourceArc</code>.</p>
<p>
In <code>lib.rs</code>:</p>
<pre><code>use std::sync::Mutex;
use oxigraph::store::Store;
use rustler::resource::ResourceArc;
use rustler::OwnedBinary;
use rustler::{Env, Term};

struct MyGraph { store: Mutex&lt;Store&gt; }

type GraphArc = ResourceArc&lt;MyGraph&gt;;</code></pre>
<p>
A bit of additional plumbing is required to tell Rustler that a <code>MyGraph</code> is
something that can be used as a <code>Resource</code>:</p>
<pre><code>fn on_load(env: Env, _info: Term) -&gt; bool {
    rustler::resource!(MyGraph, env);
    true
}</code></pre>
<p>
With these definitions in place, we can write a <code>new</code> function that allocates a
new data store and returns a handle to it:</p>
<pre><code>#[rustler::nif]
fn new() -&gt; GraphArc {
    ResourceArc::new(
        MyGraph {
            store: Mutex::new(Store::new().unwrap()),
        }
    )
}</code></pre>
<p>
And on the Elixir side, in <code>fe_graph.ex</code>:</p>
<pre><code>defmodule FeGraph do
  use Rustler, otp_app: :myapp, crate: "fegraph"

  def new(), do: :erlang.nif_error(:nif_not_loaded)
end</code></pre>
<p>
At this point we can test in <code>iex</code>, and see that the Elixir stub above has been
replaced by the Rust NIF we defined, which we can run and which gives us back a
reference:</p>
<pre><code>iex(1)&gt; FeGraph.new
#Reference&lt;0.2659174309.2607677441.115195&gt;</code></pre>
<p>
Granted we can’t yet <em>do</em> anything with it, but we’re already defining a data
store in Rust and seeing evidence of it in Elixir; and behind the scenes the
BEAM and Rustler are taking care of all of the heavy lifting for us.</p>
<p>
How about a simple function to add some data to our new store?  In a way that
will feel very familiar to Elixir code, it will need to both take and return a
<code>GraphArc</code> handle.  We’ll also have it accept a single string to use for all
three parts of the triple to store (normally of course we’d take different
strings for the subject, predicate, and object parts of the triple, but our
focus here isn’t on SPARQL—we just want some data to store.)</p>
<pre><code>#[rustler::nif]
fn set(state: GraphArc, iri: &amp;str) -&gt; GraphArc {
    let store = state.store.lock().unwrap();

    let ex = NamedNode::new(iri).unwrap();
    let quad =
        Quad::new(ex.clone(), ex.clone(), ex.clone(), GraphName::DefaultGraph);
    (*store).insert(&amp;quad).unwrap();

    drop(store);

    state
}</code></pre>
<p>
Within the function we can use our <code>GraphArc</code> state argument to get a hold of
the Oxigraph store that we created back in the <code>new</code> function.  Once we’ve got
it we can add some test data to the graph as normal, then return the unchanged
<code>state</code>.</p>
<p>
The final piece of the puzzle is to retrieve some data from our store.  Rather
than running a query (which would require getting into more SPARQL) we’ll just
dump the whole database and return it as a string.  As before, our new function
will need to accept a <code>GraphArc</code>, but this time we’ll return an <code>OwnedBinary</code>,
which allows us to send a binary back to the BEAM and then wash our hands of it.</p>
<pre><code>#[rustler::nif]
fn dump_db(state: GraphArc) -&gt; OwnedBinary {
    let store = state.store.lock().unwrap();

    let mut buffer = Vec::new();
    (*store)
        .dump_graph(
            &amp;mut buffer,
            GraphFormat::Turtle,
            GraphNameRef::DefaultGraph,
        )
        .unwrap();

    let mut result = OwnedBinary::new(buffer.len()).unwrap();
    result.as_mut_slice().copy_from_slice(&amp;buffer);

    result
}</code></pre>
<p>
The majority of this function turns out to be messing around getting the data
out of Oxigraph into a buffer, and then from the buffer into the <code>OwnedBinary</code>;
the Rustler wrapper has become mostly invisible which is what I was originally
hoping for.</p>
<p>
With this in place we can now demonstrate allocating some memory in Rust,
returning a handle to that memory, then using it to store data outside the BEAM
memory model and finally fetch the data back into the Elixir world:</p>
<pre><code>iex(1)&gt; db = FeGraph.new
#Reference&lt;0.2749498138.3684302852.140448&gt;
iex(2)&gt; FeGraph.set(db, "http://foo.com")
#Reference&lt;0.2749498138.3684302852.140448&gt;
iex(3)&gt; FeGraph.dump_db(db)
"&lt;http://foo.com&gt; &lt;http://foo.com&gt; &lt;http://foo.com&gt; .\n"</code></pre>
<p>
Note the important part; the reference is the same both times despite the data
changing and we are <em>not</em> storing it after the <code>set</code> call; normally we’d need to
do something like <code>db = FeGraph.set(db, "http://foo.com")</code> instead.  The only
reason <code>set</code> returns the reference is for convenient use with the pipe operator
or similar.</p>
<h2>
Conclusion</h2>
<p>
While the code shown above does skip past most of the error handling, hopefully
it’s clear just how accessible Rustler makes it to link Rust code into Elixir
projects in a way that allows you to combine the strengths of both.</p>
<p>
Rustler is a tremendous addition to the Elixir ecosystem, and it opens up far
more opportunities than just calculating things more quickly.  Being able to opt
out of the standard BEAM memory model for specific sections of code can open the
doors to custom data stores and other features that would not generally be a
good fit for Elixir, while still allowing you to use the power of Phoenix for
the majority of your application… all with virtually seamless integration.</p>

        </section></div>]]></description>
        </item>
    </channel>
</rss>