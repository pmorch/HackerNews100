<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 29 Jun 2024 13:30:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[It's not just you, Next.js is getting harder to use (104 pts)]]></title>
            <link>https://www.propelauth.com/post/nextjs-challenges</link>
            <guid>40828610</guid>
            <pubDate>Sat, 29 Jun 2024 08:00:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.propelauth.com/post/nextjs-challenges">https://www.propelauth.com/post/nextjs-challenges</a>, See on <a href="https://news.ycombinator.com/item?id=40828610">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        <p>I wrote a blog post the other day about how Next.js Middleware can be useful for working around some of the <a href="https://www.propelauth.com/post/getting-url-in-next-server-components?ref=propelauth.com">restrictions imposed by server components</a>. This led to some fun discussions in the world about whether this was a reasonable approach or if Next.js DX was just... <a href="https://github.com/vercel/next.js/discussions/65385?ref=propelauth.com">bad</a>.</p><figure><img src="https://cdn.getmidnight.com/a1241f0fcb8d83a4c0387f234e241914/2024/05/Screen-Shot-2024-05-14-at-9.02.53-AM.png" alt="" loading="lazy" width="916" height="498"></figure><p>From my perspective, Next.js’ App Router has two major problems that make it difficult to adopt:</p><ul><li>You need to understand a lot about the internals to do seemingly basic tasks.</li><li>There are many ways to shoot yourself in the foot that are opt-out instead of opt-in.</li></ul><p>To understand this better, let’s look at its predecessor, the Pages Router.</p><h2 id="a-quick-look-at-the-pages-router">A quick look at the Pages Router</h2><p>When I first learned about Next.js, the main “competitor” was Create React App (CRA). I was using CRA for all my projects, but I switched to Next.js for two reasons:</p><ul><li>I liked file-based routing because it allowed me to write less boilerplate code.</li><li>Whenever I ran the dev server, CRA would open <a href="http://localhost:3000/?ref=propelauth.com">http://localhost:3000</a> (which gets annoying fast), and Next.js didn’t.</li></ul><p>The second one is maybe a little silly, but to me, Next.js was:</p><p><strong>React with better defaults.</strong></p><p>And that’s all I really wanted. It wasn’t until later that I discovered the other features Next.js had. API routes were exciting as they gave me a serverless function without setting up any extra infra - super handy for things like “Contact Us” forms on a marketing site. <code>getServerSideProps</code> allowed me to run basic functions on the server before the page loaded.</p><p>Those concepts were powerful, but they were also <strong>simple</strong>.</p><p>An API route looked and acted a lot like every other route handler. If you had used Express or Cloudflare Workers, you can squint at a route handler and all the concepts you already knew translated. <code>getServerSideProps</code> was a little different, but once you understood how to get a <code>request</code> and the format of the response, it turned out to be pretty straightforward too.</p><h2 id="the-app-router-release">The App Router release</h2><p>The Next 13 release introduced the <a href="https://nextjs.org/docs/app?ref=propelauth.com">App Router</a>, adding many new features. You had <a href="https://nextjs.org/docs/app/building-your-application/rendering/server-components?ref=propelauth.com">Server Components</a> which allowed you to render your React components on the server and reduce the amount of data you needed to send to your client.</p><p>You had&nbsp;<a href="https://nextjs.org/docs/app/building-your-application/routing/layouts-and-templates?ref=propelauth.com">Layouts</a>, which allowed you to define aspects of your UI shared by multiple routes and didn’t need to be re-rendered on every navigation.</p><p>Caching got… <a href="https://nextjs.org/docs/app/building-your-application/caching?ref=propelauth.com">more sophisticated</a>.</p><p>And while these features were interesting, the biggest loss was <strong>simplicity</strong>.</p><h2 id="when-a-framework-doesn%E2%80%99t-do-what-you-think-it-will-do">When a framework doesn’t do what you think it will do</h2><p>A fairly universal experience as a developer is banging your head against the wall and yelling, “Why does this not work?”</p><p>Everyone’s been there, and it always sucks. For me, it’s even more painful if it feels like it’s not a bug in my code but a misunderstanding of how things are supposed to work.</p><p>You are no longer yelling, “Why does this not work?” but rather, “Why does this work… like <em>that</em>?”</p><p>The App Router, unfortunately, is full of these kinds of subtleties.</p><p>Let’s look back at my original issue: I just want to get the URL in a Server Component. <a href="https://github.com/vercel/next.js/issues/43704?ref=propelauth.com#issuecomment-2090798307">Here’s an answer</a> to a popular Github issue about the topic, and I’ll post part of it here:</p><blockquote>If we take a step back, the question "Why can't I access&nbsp;<code>pathname</code>&nbsp;or current URL?" is part of a bigger question: "Why can't I access the complete&nbsp;<strong>request and response objects</strong>?"<p>Next.js is both a&nbsp;<strong>static</strong>&nbsp;and&nbsp;<strong>dynamic</strong>&nbsp;rendering framework that splits work into route segments. While exposing the request/response is very powerful, these objects are inherently&nbsp;<strong>dynamic</strong>&nbsp;and affect the entire route. This limits the framework's ability to implement current (caching and streaming) and future (Partial Prerendering) optimizations.</p><p>To address this challenge, we considered exposing the request object and tracking where it's being accessed (e.g. using a proxy). But this would make it harder to track how the methods were being used in your code base, and could lead developers to unintentionally opting into dynamic rendering.</p><p>Instead, we exposed specific methods from the Web Request API, unifying and optimizing each for usage in different contexts: Components, Server Actions, Route Handlers, and Middleware. These APIs allow the developer to explicitly opt into framework heuristics like dynamic rendering, and makes it easier for Next.js to track usage, breaking the work, and optimizing as much as possible.</p><p>For example, when using&nbsp;<a href="https://nextjs.org/docs/app/api-reference/functions/headers?ref=propelauth.com"><code>headers</code></a>, the framework knows to opt into dynamic rendering to handle the request. Or, in the case of&nbsp;<a href="https://nextjs.org/docs/app/api-reference/functions/cookies?ref=propelauth.com">cookies</a>, you can read cookies in the React render context, but only set cookies in a mutation context (e.g. Server Actions and Route Handlers) because cookies cannot be set once streaming starts.</p></blockquote><p>For what it’s worth, this response is incredible. It’s well written, it helps me understand a lot of the underlying issues, and it gives me insight into the tradeoffs associated with different approaches that I absolutely didn’t think about.</p><p>That being said, if you are a developer and all you are trying to do is get the URL in a Server Component, you probably read this and left with 5 more things to Google before realizing you probably have to restructure your code.</p><p>This post summarizes my feelings about it:</p><figure><img src="https://cdn.getmidnight.com/a1241f0fcb8d83a4c0387f234e241914/2024/05/Screen-Shot-2024-05-14-at-1.42.51-AM.png" alt="" loading="lazy" width="860" height="124"></figure><p>It’s not that it’s necessarily incorrect - it’s unexpected.</p><p>That original post also mentioned a few other subtleties. One common footgun is in how <a href="https://www.propelauth.com/post/cookies-in-next-js?ref=propelauth.com">cookies are handled</a>. You can call <code>cookies().set("key", "value")</code> anywhere and it will type-check, but in some cases it will fail at runtime.</p><p>Compare these to the “old” way of doing things where you got a big <code>request</code> object and could do anything you wanted on the server, and it’s fair to say that there’s been a jump in complexity.</p><p>I also need to point out that the “on-by-default” aggressive caching is a rough experience. I’d argue that way more people expect to opt-in to caching rather than dig through a lot of documentation to figure out how to opt-out.</p><p>I’m sure other companies had similar issues to us, but at <a href="https://www.propelauth.com/?ref=propelauth.com">PropelAuth</a> we often got bug reports that weren’t bugs but amounted to “You thought you made an API call, but you didn’t, and you are just reading a cached result.”</p><p>And all of this begs the question, who are these features and optimizations for?</p><h2 id="it%E2%80%99s-very-hard-to-build-a-one-size-fits-all-product">It’s very hard to build a one-size-fits-all product</h2><p>All of these features that I’m painting as overly complex do matter for some people. If you are building an e-commerce platform, for example, there are some great features here.</p><p>Your pages load faster because you send less data to the client. Your pages load faster because everything is aggressively cached. Your pages load faster because only parts of the page need to re-render when the user navigates to a new page. And in the e-commerce world, faster page loads means more money, so you would absolutely take the tradeoff of a more complex framework for them.</p><p>But if I’m building a dashboard for my SaaS application… I don’t really care about any of that. I care way more about the speed at which I ship features, and all that complexity becomes a burden on my dev team.</p><p>My personal experience and frustrations with the App Router will be different than another person’s because we have different products, different use cases, and different resources. Speaking specifically as a person who spends a lot of time writing and helping other people write B2B SaaS applications, the App Router DX is a big step down from the Pages Router.</p><h2 id="is-this-inevitable-for-frameworks-as-they-grow">Is this inevitable for frameworks as they grow?</h2><p>As products/frameworks grow, they tend to get more complicated. Customers ask for more things. Bigger customers ask for more specific things. Bigger customers pay more so you prioritize and build those more specific things.</p><p>Customers who previously loved the simplicity of it all get annoyed at how complicated things feel and… oh, look at that, a new framework has popped up that’s way simpler. We should all switch to that!</p><p>It’s challenging to avoid this, but one way to mitigate it is to not make everyone deal with the complexity that only some people need.</p><h2 id="just-because-something-is-recommended-doesn%E2%80%99t-mean-it%E2%80%99s-right-for-you">Just because something is recommended, doesn’t mean it’s right for you</h2><p>One of my biggest issues with the App Router was just this:</p><figure><img src="https://cdn.getmidnight.com/a1241f0fcb8d83a4c0387f234e241914/2024/05/Untitled-design--15---1-.png" alt="" loading="lazy" width="598" height="148"></figure><p>Next.js has officially recommended that you use the App Router since before it was honestly ready for production use. Next.js doesn’t have a recommendation on whether TypeScript, ESLint, or Tailwind are right for your project (despite providing defaults of Yes on TS/ESLint, No to Tailwind - sorry Tailwind fans), but absolutely believes you should be using the App Router.</p><p>The <a href="https://react.dev/learn/start-a-new-react-project?ref=propelauth.com">official React docs</a> don’t share the same sentiment. They currently recommend the Pages Router and describe the App Router as a “Bleeding-edge React Framework.”</p><p>When you look at the App Router through that lens, it makes way more sense. Instead of thinking of it as the recommended default for React, you can think of it more <a href="https://twitter.com/dan_abramov2/status/1752721357614301690?ref=propelauth.com">like a beta release</a>. The experience is more complicated and <a href="https://github.com/vercel/next.js/discussions/41934?ref=propelauth.com">some things that were easy are now hard/impossible</a>, but what else would you expect from something that’s still “Bleeding-edge?”</p><p>So when you are picking a framework for your next project, it’s worth recognizing that there are still many rough edges in the App Router. You might have better luck reaching for a different tool that’s more suited to your use case.</p>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[All web "content" is freeware (110 pts)]]></title>
            <link>https://rubenerd.com/all-web-content-is-freeware/</link>
            <guid>40828441</guid>
            <pubDate>Sat, 29 Jun 2024 07:09:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rubenerd.com/all-web-content-is-freeware/">https://rubenerd.com/all-web-content-is-freeware/</a>, See on <a href="https://news.ycombinator.com/item?id=40828441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Sean Endicott <a href="https://www.windowscentral.com/software-apps/ever-put-content-on-the-web-microsoft-says-that-its-okay-for-them-to-steal-it-because-its-freeware">quoted a CNBC interview</a> with Microsoft’s CEO of AI, and it’s nothing if not entertaining!</p>
<blockquote>
<p>“With respect to content that is already on the open web, the social contract of that content since the 90s has been that it is fair use. Anyone can copy it, recreate with it, reproduce with it. That has been freeware, if you like. That’s been the understanding,” said Suleyman.</p>
</blockquote>
<p>This is the same company behind <a href="https://en.wikipedia.org/wiki/An_Open_Letter_to_Hobbyists">this famous letter in 1976</a>. Perhaps that’s why he bookended his claims with “since the 90s”. But that means torrents of Windows are freeware! Maybe he should have run this by legal first.</p>
<p>Easy gotchas aside, this rambling, incoherent interview was a fascinating and <em>deeply</em> revealing perspective into how managers are thinking. It’s dawning on them that they’ve lost the financial argument, because these models are unsustainable to anyone not <a href="https://quoteinvestigator.com/2021/04/20/gold-shovel/">selling the shovels</a>. Model decay has revealed the emperor has no clothes when it comes to tools “learning” or “being inspired” as artists are. The general public are beginning to equate “AI generated” with low effort and low quality, coining a <a href="https://www.thestar.com.my/tech/tech-news/2024/06/21/slop-is-the-dubious-online-content-churned-out-by-ai" title="‘Slop’ is the dubious online content churned out by AI">new term in the process</a>. There are also indications that <a href="https://omny.fm/shows/better-offline/are-we-at-peak-ai" title="Better Offline: Are We At Peak AI?">peak AI</a> may already soon be upon us, given they’re rapidly exhausting their supply of organic material to train against.</p>
<p>Backed into an ethical, financial, mathematical, and legal corner, generative AI vendors are now resorting to arguing everything is fair game, because it always was. Don’t blame us, the <a href="https://knowyourmeme.com/memes/torment-nexus" title="Know Your Meme: The Torment Nexus">Torment Nexus</a> is established practice!</p>
<p>This gives me the opportunity to address a point a lot of tech pundits are now making: a chatbot is no different from a search engine. The “social contract” here is that search engines could crawl our pages, create indexes, data mine them based on secret algorithms, and present processed results based on a query. A generative AI chatbox is no different, right?</p>
<p>Except, and I know this may come as a shock: <em>search engines link to their sources!</em> Chatbots don’t. That’s what makes their “hallucinations” so dangerous; there’s no audit trail. Search engines deliver traffic, generative AI tools train against data to avoid doing that. The “social contract” here is completely upside down, as though a tool was asked to generate an image of it.</p>
<p>This is the surest sign to me that we’re in a bubble again: the talking heads are beginning to believe their own nonsense. That’s another form of model decay, now that I think about it.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to waste bandwidth, battery power, and annoy sysadmins (218 pts)]]></title>
            <link>https://rachelbythebay.com/w/2024/06/28/fxios/</link>
            <guid>40828203</guid>
            <pubDate>Sat, 29 Jun 2024 06:07:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachelbythebay.com/w/2024/06/28/fxios/">https://rachelbythebay.com/w/2024/06/28/fxios/</a>, See on <a href="https://news.ycombinator.com/item?id=40828203">Hacker News</a></p>
Couldn't get https://rachelbythebay.com/w/2024/06/28/fxios/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The 'pay phone bandit' who baffled the FBI in the '80s (102 pts)]]></title>
            <link>https://www.mentalfloss.com/posts/pay-phone-bandit-baffled-fbi</link>
            <guid>40827650</guid>
            <pubDate>Sat, 29 Jun 2024 03:19:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mentalfloss.com/posts/pay-phone-bandit-baffled-fbi">https://www.mentalfloss.com/posts/pay-phone-bandit-baffled-fbi</a>, See on <a href="https://news.ycombinator.com/item?id=40827650">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure></figure><p data-mm-id="_k4ztttvkp">Most of the sightings were the same. Standing in front of the motel clerk or convenience store worker was a man, roughly 5 feet, 9 inches tall, <a href="https://www.washingtonpost.com/archive/politics/1988/08/30/fbi-agents-arrest-suspect-in-legendary-500000-pay-phone-theft-case/bca70245-b2d9-4cb6-899f-2304d7057979/" target="_blank">wearing</a> a baseball cap pulled low and almost touching a pair of gold-rimmed eyeglasses. A ponytail stuck out from the back of the hat. A button-down shirt was left untucked. Cowboy boots protruded from under his pant cuffs.</p><p data-mm-id="_mhcj1fl4t">Most importantly, the man liked to pay for his food or his room in quarters—rolls and rolls of quarters.</p><p data-mm-id="_7dp103nc1">In the 1980s, police in Ohio as well as the FBI spent years <a href="https://www.latimes.com/archives/la-xpm-1988-08-28-me-1808-story.html" target="_blank">chasing</a> the man with the ponytail. Unlike a lot of criminals, he didn’t brandish a gun, resort to violence, or put innocent people in his crosshairs. What he did instead was become the most prolific safecracker in modern times, able to breach what was once <a href="https://www.latimes.com/archives/la-xpm-1987-12-08-me-27444-story.html" target="_blank">believed</a> to be the impenetrable, unbreakable strongbox housed in the country’s 1.8 million pay phones. Using means that baffled even security experts, the “pay phone bandit” or “telephone bandit” eluded capture. Quarter by quarter and year after year, he collected an estimated $500,000 to <a href="https://www.newspapers.com/image/641914911/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%22%20%22Ohio%22" target="_blank">$1 million</a> from these tiny safes. The question was how anyone was ever going to find him.</p><p data-mm-id="_9gir4pvh1">“Unless somebody gets lucky, he’ll probably never get caught,” Ohio Bell Telephone security official Robert Cooperider told <em>The Los Angeles Times</em> in 1987. “He’s well-organized, he’s smart, and he’s not greedy. He only hits a few widely spaced spots each day. He’s always looking over his shoulder, to see if there is a police car, or a telephone company vehicle.”</p><p data-mm-id="_mry61xe1z">Though it’s hard to imagine today, there was once a time when making a telephone call meant going home, asking to use someone’s phone, or plunking a quarter into a freestanding pay phone. (Or more than one, depending on where you were calling and for how long.) </p><p data-mm-id="_psu909emr">The first public pay-to-use coin-operated phone <a href="https://time.com/4425102/public-telephone-booth-history/" target="_blank">debuted</a> in Hartford, Connecticut, in 1889. It relied on the honor system, with users depositing coins owed after their call was done. Over the next century, they appeared everywhere, from convenience stores to diners to bus stations. Some were freestanding; others were located inside of a booth to give callers some privacy.</p><p data-mm-id="_4o23p6aao">While the phones varied somewhat in design, virtually all of them took care to make the coin box virtually impregnable. Bell, then the world’s largest phone carrier, <a href="https://www.newspapers.com/image/295427269/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%20bandit%22" target="_blank">reportedly</a> spent years refining a lock on their box that was thought to be unpickable. If a would-be thief wanted to even have a shot at getting into the box, they’d have to try smashing it open with a sledge hammer or knock it out of the ground with a tractor. Given that the boxes only held about $150 when full, few criminals thought it was worth the effort.</p><div data-mm-id="_izkflqdbd"><figure data-id="_izkflqdbd" data-mm-type="image"><canvas></canvas><picture><source><source><source></picture></figure><p><figcaption>A typical pay phone inside of a phone booth. / Marie Hickman/Stone via Getty Images</figcaption></p></div><p data-mm-id="_6eeeowg0c">James Clark wasn’t one of those people. The Akron, Ohio, native was a machinist by trade, but he had a nebulous history. According to the Associated Press, in 1968 he was arrested for <a href="https://www.newspapers.com/image/296810671/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%22%20%22Ohio%22" target="_blank">attempting</a> to arrange a massive counterfeit money deal with contacts in Europe that would have put $50 million phony bills into circulation. He was caught and sentenced to three years in prison.</p><p data-mm-id="_b7xtffq05">Roughly a decade later, in the early 1980s, Clark devised a new scheme. According to authorities, Clark obtained locks like the ones found on pay phones and created a set of specialized locksmith tools that allowed him to pick the lock. Though different operators had somewhat different lock configurations, Clark zeroed in on specific designs to breach. (His exact tool set and technique has never been publicly disclosed, likely due to security concerns.)</p><p data-mm-id="_x3miqn5vk">Clark’s strategy was simple. Upon arriving at a pay phone, he <a href="https://www.oklahoman.com/story/news/1988/02/14/phone-companies-seek-coin-thief/62661920007/" target="_blank">used</a> a custom tool that he could slip into the margins of the coin box to gauge how much money was inside and whether it was worth pursuing. If it was full, he’d pick up the receiver and pretend to be deep in a conversation. While hunched over the phone, he’d grab his lockpicking tools—which he concealed with an untucked shirttail—and get to work on the lock. Picking one took about 15 minutes. When he got it, the faceplate in front of the coin receptacle came off. Clark would take the box full of change and then replace the faceplate.</p><p data-mm-id="_jl1kf3ska">This last step was key: The phone would <a href="https://www.newspapers.com/image/153864107/?terms=%22James%20Clark%22%20%22pay%20phone%22%20%22Ohio%22" target="_blank">continue</a> to operate without the box, giving no physical or mechanical clue it had been tampered with. No one would realize the box was missing until a phone company employee came to retrieve the money—in some cases a week or so later. By that point, Clark would be long gone.</p><p data-mm-id="_g4dz6n2bv">Clark ransacked pay phones in Ohio, but he soon branched out to other states. By one estimate, he hit phones in 30 of them, mostly in the South and West. He preferred to stick to phones near the interstate so he could leave in a hurry if he had to. He also seemed to favor phones near country and Western bars, either because he liked the entertainment or because he knew businesses would have profitable phones nearby. He stopped off for lodging and food using his stolen quarters as payment, though he was also known to exchange the coins for bills at banks. He was also seemingly cocky. He used the name <em>James Bell</em> when registering for rooms, a nod to the phone giant he was ripping off on a regular basis.</p><p data-mm-id="_35rf0dhs9">Bell was wise to Clark’s scheme early on. As his spree grew, there was a question of whether he was acting alone or whether the phone thefts were part of some interstate crime ring.</p><p data-mm-id="_slth57s83">But closer inspection of the locks revealed a clue. In picking them, Clark left behind a telltale series of scratches that authorities considered almost as good as a fingerprint. It was the one piece of evidence officials had to go on, though there was nothing to compare it to—no national database of lockpicking marks.</p><p data-mm-id="_cguhe9w7j">It wasn’t until 1985 that investigators in Ohio and the FBI got their first real break in the case. A person that news media described as an “informer” told them<strong> </strong>to look closely at Clark,<strong> </strong>the Akron native who had once been embroiled in the counterfeit ring of the late 1960s. Clark’s family—his wife and a grown daughter—were still in the Akron area, but Clark himself was nowhere to be found. He had apparently broken off ties with his relatives.</p><p data-mm-id="_lju6vg5jm">Armed with a search warrant, police searched a trailer belonging to Clark and found a smoking gun of sorts: parts of a Bell lock, which they inferred had been used as a practice lock.</p><div data-mm-id="_24byqll5g"><figure data-id="_24byqll5g" data-mm-type="image"><canvas></canvas><picture><source><source><source></picture></figure><p><figcaption>The lock box on a pay phone can be seen on the lower right. / Carlos E. Serrano/Moment via Getty Images</figcaption></p></div><p data-mm-id="_knefnje51">While there was no sign of Clark, at least they could put a face to their suspect’s name. A sketch artist <a href="https://www.newspapers.com/image/919421370/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%20bandit%22" target="_blank">developed</a> a likeness that was used for wanted posters; police approached convenience store workers and motel workers asking if they had seen him. Some had, including one witness who <a href="https://www.newspapers.com/image/289405984/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%22%20%22Ohio%22" target="_blank">believed</a> they had seen Clark working a phone while being obscured from view by a blue van. The phone’s contents were believed to have been stolen around the time of the sighting. One Bell employee even related a story of confronting Clark while he was in the middle of a heist; Clark, in a rare moment of animus, warned the worker off. Though he apparently never brandished it, Clark was known to carry a .38 revolver. He was seemingly prepared for a confrontation.</p><p data-mm-id="_cfnewbet9">A warrant was issued for Clark’s arrest in Ohio as well as nationally: The FBI sought him in conjunction with unlawful flight from the state. Bell and other phone operators offered a $25,000 reward for information leading to his arrest. Tips continued to come in, though Clark, sticking close to the interstate, was always a day or so ahead of the law. Not even two appearances on <em>America’s Most Wanted</em> resulted in any meaningful leads. Some officials doubted he would ever be caught. If he wasn’t, there really wasn’t anything Bell or other operators could practically do. Even if he were costing them $70,000 annually, that was still cheaper than trying to replace locks on 1.8 million phones.</p><p data-mm-id="_je9hbnwwa">But in August 1988, Clark’s run came to an end. Acting on another tip, the FBI arrested him in Buena Park, California. True to Clark’s subversive style, there was no protracted struggle: He surrendered without incident; unique lockpicking tools were found in his apartment. Though law enforcement didn’t divulge who or what led them to Buena Park, they indicated Clark’s decision to stay in one place may have helped them catch up to him.</p><p data-mm-id="_w04u5a26t">Speaking with the press, his attorney, Paul Potter, said Clark had admitted to being the man police had been searching for in 1985 and characterized his client as “an American tinkerer.”</p><p data-mm-id="_z2tct38og">Bell’s national spree was a logistically messy one for the criminal justice system. Any one of dozens of states could bring charges. Initially, he was <a href="https://www.upi.com/Archives/1988/09/02/Coin-box-bandit-agrees-to-extradition/9461589176000/" target="_blank">extradited</a> back to Ohio, where he pled guilty in Summit County to five counts of grand theft and another five counts of tampering with coin machines, crimes with a loss valued at just $500. In consideration for the plea, the judge <a href="https://www.newspapers.com/image/296810671/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%22%20%22Ohio%22" target="_blank">dropped</a> other charges and took a potential 10-year prison sentence off the table. Clark got three years.</p><p data-mm-id="_npkl89t1h">In 1990, Clark got another <a href="https://www.newspapers.com/image/641914911/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%22%20%22Ohio%22" target="_blank">sentence</a> in Ohio, this one in Columbus after pleading to one count of theft and two counts of tampering. He got a three-year sentence. Whether he received additional time in other states is unclear. </p><p data-mm-id="_1q3915wgl">Clark was roughly 50 years old when he was caught. He died in 2012. In a guestbook marking his passing, a commenter <a href="https://www.legacy.com/us/obituaries/ohio/name/james-clark-obituary?id=23748114" target="_blank">observed</a> that Clark was a “thinker and a doer,” which is probably as fitting a eulogy as he could hope for. It’s also unlikely the FBI’s fears of a copycat will ever materialize: As of 2018, there were <a href="https://money.cnn.com/2018/03/19/news/companies/pay-phones/index.html" target="_blank">less </a>than 100,000 pay phones in the country and likely even fewer today.</p><p data-mm-id="_nz7je012e"><strong>Read More About True Crime:</strong></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The XAES-256-GCM extended-nonce AEAD (143 pts)]]></title>
            <link>https://words.filippo.io/dispatches/xaes-256-gcm/</link>
            <guid>40826683</guid>
            <pubDate>Sat, 29 Jun 2024 00:01:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://words.filippo.io/dispatches/xaes-256-gcm/">https://words.filippo.io/dispatches/xaes-256-gcm/</a>, See on <a href="https://news.ycombinator.com/item?id=40826683">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            <p>About a year ago <a href="https://words.filippo.io/dispatches/xaes-256-gcm-11/">I wrote</a> that “I want to use XAES-256-GCM/11, which has a number of nice properties and only the annoying defect of not existing.” Well, there is now <a href="https://c2sp.org/XAES-256-GCM?ref=words.filippo.io">an XAES-256-GCM specification</a>. (Had to give up on the /11 part, but that was just a performance optimization.)</p>
<p>XAES-256-GCM is an <em>authenticated encryption with additional data</em> (AEAD) algorithm with 256-bit keys and <strong>192-bit nonces</strong>. It was designed with the following goals:</p>
<ol>
<li>supporting a nonce large enough to be safe to generate randomly for a virtually unlimited number of messages (2⁸⁰ messages with collision risk 2⁻³²);</li>
<li>full, straightforward FIPS 140 compliance; and</li>
<li>trivial implementation on top of common cryptographic libraries.</li>
</ol>
<p>The large nonce enables safer and more friendly APIs that automatically read a fresh nonce from the operating system’s CSPRNG for every message, without burdening the user with any <a href="https://en.wikipedia.org/wiki/Birthday_attack?ref=words.filippo.io">birthday bound</a> calculations. Compliance and compatibility make it available anywhere an AEAD might be needed, including in settings where alternative large-nonce AEADs are not an option.</p>
<p>Like XChaCha20Poly1305, XAES-256-GCM is an extended-nonce construction on top of AES-256-GCM. That is, it uses the key and the large nonce to compute a derived key for the underlying AEAD.</p>
<p>It’s simple enough to fit inline in this newsletter. Here we go. <em>K</em> and <em>N</em> are the input key and nonce, <em>Kₓ</em> and <em>Nₓ</em> are the derived AES-256-GCM key and nonce.</p>
<ol>
<li><em>L</em> = AES-256ₖ(0¹²⁸)</li>
<li>If MSB₁(<em>L</em>) = 0, then <em>K1</em> = <em>L</em> &lt;&lt; 1;<br>
Else <em>K1</em> = (<em>L</em> &lt;&lt; 1) ⊕ 0¹²⁰10000111</li>
<li><em>M1</em> = 0x00 || 0x01 || <code>X</code> || 0x00 || <em>N</em>[:12]</li>
<li><em>M2</em> = 0x00 || 0x02 || <code>X</code> || 0x00 || <em>N</em>[:12]</li>
<li><em>Kₓ</em> = AES-256ₖ(<em>M1</em> ⊕ <em>K1</em>) || AES-256ₖ(<em>M2</em> ⊕ <em>K1</em>)</li>
<li><em>Nₓ</em> = <em>N</em>[12:]</li>
</ol>
<p>As you can see, it costs three AES-256ₖ calls per message, although one can be precomputed for a given key, and the other two can reuse its key schedule.</p>
<p>The <a href="https://github.com/C2SP/C2SP/blob/main/XAES-256-GCM/go/XAES-256-GCM.go?ref=words.filippo.io">Go reference implementation</a> fits in less than 100 lines of mostly boilerplate, including the precomputation optimization, and only uses the standard library’s crypto/cipher and crypto/aes.</p>
<p>Importantly, you could also describe XAES-256-GCM entirely in terms of a standard <a href="https://csrc.nist.gov/publications/detail/sp/800-108/rev-1/final?ref=words.filippo.io">NIST SP 800-108r1</a> KDF and the standard NIST AES-256-GCM AEAD (<a href="https://csrc.nist.gov/pubs/sp/800/38/d/final?ref=words.filippo.io">NIST SP 800-38D</a>, <a href="https://csrc.nist.gov/pubs/fips/197/final?ref=words.filippo.io">FIPS 197</a>).</p>
<blockquote>
<p>Instantiate a counter-based KDF (<a href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-108r1.pdf?ref=words.filippo.io#%5B%7B%22num%22%3A79%2C%22gen%22%3A0%7D%2C%7B%22name%22%3A%22XYZ%22%7D%2C70%2C300%2C0%5D">NIST SP 800-108r1, Section 4.1</a>) with CMAC-AES256 (<a href="https://csrc.nist.gov/publications/detail/sp/800-38b/final?ref=words.filippo.io">NIST SP 800-38B</a>) and the input key as <em>Kin</em>, the ASCII letter <code>X</code> (0x58) as <em>Label</em>, the first 96 bits of the input nonce as <em>Context</em> (as recommended by <a href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-108r1.pdf?ref=words.filippo.io#%5B%7B%22num%22%3A71%2C%22gen%22%3A0%7D%2C%7B%22name%22%3A%22XYZ%22%7D%2C70%2C720%2C0%5D">NIST SP 800-108r1, Section 4</a>, point 4), a counter (<em>i</em>) size of 16 bits, and omitting the optional <em>L</em> field, and produce a 256-bit derived key. Use that derived key and the last 96 bits of the input nonce with AES-256-GCM.</p>
</blockquote>
<p>Thanks to the choice of parameters, if we peel off the KDF and CMAC abstractions, the result is barely slower and more complex than straightforwardly invoking AES-256 on a counter. In exchange, we get a vetted and compliant solution. The parameters <a href="https://github.com/C2SP/C2SP/blob/main/XAES-256-GCM/openssl/openssl.c?ref=words.filippo.io">are supported by the high-level OpenSSL API</a>, too.</p>
<p>Why no more “/11”? Well, half the point of using AES-GCM is FIPS 140 compliance. (The other half being hardware acceleration.) If we mucked with the rounds number the design wouldn’t be compliant.</p>
<p>Indeed, if compliance is not a goal there are a number of alternatives, from AES-GCM-SIV to modern AEAD constructions based on the AES core. The specification has <a href="https://c2sp.org/XAES-256-GCM?ref=words.filippo.io#alternatives">an extensive Alternatives section</a> that compares each of them to XAES-256-GCM.</p>
<p>Also included in the specification are <a href="https://c2sp.org/XAES-256-GCM?ref=words.filippo.io#test-vectors">test vectors</a> for the two main code paths (MSB₁(<em>L</em>) = 0 and 1), and <a href="https://c2sp.org/XAES-256-GCM?ref=words.filippo.io#accumulated-randomized-tests">accumulated test vectors</a> that compress 10 000 or 1 000 000 random iterations.</p>
<p>To sum up, XAES-256-GCM is designed to be a safe, boring, compliant, and interoperable AEAD that can fit high-level APIs, the kind we’d like to add to Go. It’s designed to complement XChaCha20Poly1305 and AES-GCM-SIV as implementations of a hypothetical <a href="https://github.com/golang/go/issues/54364?ref=words.filippo.io#issuecomment-1642676993">nonce-less AEAD API</a>. If other cryptography library maintainers like it (or don’t), I would love to hear about it, because we are not big fans of adding Go-specific constructions to the standard library.</p>
<p>By the way, I have an exciting update about my professional open source maintainer effort coming in less than two weeks! Make sure to subscribe to <a href="https://filippo.io/newsletter?ref=words.filippo.io">Maintainer Dispatches</a> or to follow me on Bluesky at <a href="https://bsky.app/profile/filippo.abyssdomain.expert?ref=words.filippo.io">@filippo.abyssdomain.expert</a> or on Mastodon at <a href="https://abyssdomain.expert/@filippo?ref=words.filippo.io">@filippo@abyssdomain.expert</a>. (Or, see you at <a href="https://www.gophercon.com/?ref=words.filippo.io">GopherCon</a> in Chicago!)</p>
<h2 id="the-picture">The picture</h2>
<p>Earlier this year I ran in the <a href="https://www.centopassi.net/?ref=words.filippo.io">Centopassi</a> motorcycle competition. It involves driving more than 1600km on mountain roads, through one hundred GPS coordinates you select in advance from a long list, in three days and a half. It’s been fantastic. It took me to corners of Italy I would have never seen, and I had a lot of fun. This picture is taken at our 100th location, after a couple kilometers of unpaved hairpins on the side of the hill. The finish line was at the lake you can see in the distance. I was ecstatic.</p>
<p>That’s my 2014 KTM Duke 690, a single-cylinder “naked” from before KTM knew how to make larger street bikes. It’s weird and I love it.</p>
<p><img src="https://words.filippo.io/content/images/2024/06/IMG_1921.jpeg" alt="A black motorcycle with saddlebags and a race plate, parked on a dirt road overlooking a vast, scenic valley with green hills, a lake in the distance, and mountains under a bright blue sky with scattered white clouds." loading="lazy"></p>
<p>My awesome clients—<a href="https://www.sigsum.org/?ref=words.filippo.io">Sigsum</a>, <a href="https://www.latacora.com/?ref=words.filippo.io">Latacora</a>, <a href="https://interchain.io/?ref=words.filippo.io">Interchain</a>, <a href="https://smallstep.com/?ref=words.filippo.io">Smallstep</a>, <a href="https://www.avalabs.org/?ref=words.filippo.io">Ava Labs</a>, <a href="https://goteleport.com/?ref=words.filippo.io">Teleport</a>, <a href="https://www.sandboxaq.com/?ref=words.filippo.io">SandboxAQ</a>, <a href="https://charm.sh/?ref=words.filippo.io">Charm</a>, and <a href="https://tailscale.com/?ref=words.filippo.io">Tailscale</a>—are funding all my work for the community and through our retainer contracts they get face time and unlimited access to advice on Go and cryptography.</p>
<p>Here are a few words from some of them!</p>
<p>Latacora — <a href="https://www.latacora.com/?ref=words.filippo.io">Latacora</a> bootstraps security practices for startups. Instead of wasting your time trying to hire a security person who is good at everything from Android security to AWS IAM strategies to SOC2 and apparently has the time to answer all your security questionnaires plus never gets sick or takes a day off, you hire us. We provide a crack team of professionals prepped with processes and power tools, coupling individual security capabilities with strategic program management and tactical project management.</p>
<p>Teleport — For the past five years, attacks and compromises have been shifting from traditional malware and security breaches to identifying and compromising valid user accounts and credentials with social engineering, credential theft, or phishing. <a href="https://goteleport.com/identity-governance-security/?utm=filippo&amp;ref=words.filippo.io">Teleport Identity Governance &amp; Security</a> is designed to eliminate weak access patterns through access monitoring, minimize attack surface with access requests, and purge unused permissions via mandatory access reviews.</p>
<p>Ava Labs — We at <a href="https://www.avalabs.org/?ref=words.filippo.io">Ava Labs</a>, maintainer of <a href="https://github.com/ava-labs/avalanchego?ref=words.filippo.io">AvalancheGo</a> (the most widely used client for interacting with the <a href="https://www.avax.network/?ref=words.filippo.io">Avalanche Network</a>), believe the sustainable maintenance and development of open source cryptographic protocols is critical to the broad adoption of blockchain technology. We are proud to support this necessary and impactful work through our ongoing sponsorship of Filippo and his team.</p>
<p>SandboxAQ — <a href="https://www.sandboxaq.com/?ref=words.filippo.io">SandboxAQ</a>’s <a href="https://www.sandboxaq.com/solutions/aqtive-guard?ref=words.filippo.io">AQtive Guard</a> is a unified cryptographic management software platform that helps protect sensitive data and ensures compliance with authorities and customers. It provides a full range of capabilities to achieve cryptographic agility, acting as an essential cryptography inventory and data aggregation platform that applies current and future standardization organizations mandates. AQtive Guard automatically analyzes and reports on your cryptographic security posture and policy management, enabling your team to deploy and enforce new protocols, including quantum-resistant cryptography, without re-writing code or modifying your IT infrastructure.</p>

        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Eulogy for DevOps (197 pts)]]></title>
            <link>https://matduggan.com/a-eulogy-for-devops/</link>
            <guid>40826236</guid>
            <pubDate>Fri, 28 Jun 2024 22:59:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matduggan.com/a-eulogy-for-devops/">https://matduggan.com/a-eulogy-for-devops/</a>, See on <a href="https://news.ycombinator.com/item?id=40826236">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
<p>We hardly knew ye. </p><p>DevOps, like many trendy technology terms, has gone from the peak of optimism to the depths of exhaustion. While many of the fundamental ideas behind the concept have become second-nature for organizations, proving it did in fact have a measurable outcome, the difference between the initial intent and where we ended up is vast. For most organizations this didn't result in a wave of safer, easier to use software but instead encouraged new patterns of work that centralized risk and introduced delays and irritations that didn't exist before. We can move faster than before, but that didn't magically fix all our problems. </p><p>The cause of its death was a critical misunderstanding over what was causing software to be hard to write. The belief was by removing barriers to deployment, more software would get deployed and things would be easier and better. Effectively that the issue was that developers and operations teams were being held back by ridiculous process and coordination. In reality these "soft problems" of communication and coordination are much more difficult to solve than the technical problems around pushing more code out into the world more often. </p><h3 id="what-is-devops">What is DevOps?</h3><p>DevOps, when it was introduced around 2007, was a pretty radical concept of removing the divisions between people who ran the hardware and people who wrote the software. Organizations still had giant silos between teams, with myself experiencing a lot of that workflow. </p><p>Since all computer nerds also love space, it was basically us cosplaying as NASA. Copying a lot of the procedures and ideas from NASA to try and increase the safety around pushing code out into the world. Different organizations would copy and paste different parts, but the basic premise was every release was as close to bug free as time allowed. You were typically shooting for zero exceptions.</p><p>When I worked for a legacy company around that time, the flow for releasing software looked as follows. </p><ul><li>Development team would cut a release of the server software with a release number in conjunction with the frontend team typically packaged together as a full entity. They would test this locally on their machines, then it would go to dev for QA to test, then finally out to customers once the QA checks were cleared. </li><li>Operations teams would receive a playbook of effectively what the software was changing and what to do if it broke. This would include how it was supposed to be installed, if it did anything to the database, it was a whole living document. The idea was the people managing the servers, networking equipment and SANs had no idea what the software did or how to fix it so they needed what were effectively step by step instructions. Sometimes you would even get this as a paper document. </li><li>Since these happened often inside of your datacenter, you didn't have unlimited elasticity for growth. So, if possible, you would slowly roll out the update and stop to monitor at intervals. But you couldn't do what people see now as a blue/green deployment because rarely did you have enough excess server capacity to run two versions at the same time for all users. Some orgs did do different datacenters at different times and cut between them (which was considered to be sort of the highest tier of safety). </li><li>You'd pick a deployment day, typically middle of the week around 10 AM local time and then would monitor whatever metrics you had to see if the release was successful or not. These were often pretty basic metrics of success, including some real eyebrow raising stuff like "is support getting more tickets" and "are we getting more hits to our uptime website". Effectively "is the load balancer happy" and "are customers actively screaming at us". </li><li>You'd finish the deployment and then the on-call team would monitor the progress as you went. </li></ul><h3 id="why-didnt-this-work">Why Didn't This Work</h3><p>Part of the issue was this design was very labor-intensive. You needed enough developers coordinating together to put together a release. Then you needed a staffed QA team to actually take that software and ensure, on top of automated testing which was jusssttttt starting to become a thing, that the software actually worked. Finally you needed a technical writer working with the development team to walk through what does a release playbook look like and then finally have the Operations team receive, review the book and then implement the plan. </p><p>It was also slow. Features would often be pushed for months even when they were done just because a more important feature had to go out first. Or this update was making major changes to the database and we didn't want to bundle in six things with the one possibly catastrophic change. It's effectively the Agile vs Waterfall design broken out to practical steps. </p><figure><img src="https://kruschecompany.com/wp-content/uploads/2021/09/Waterfall-vs-Agile-in-software-development-infographic.jpg" alt="Waterfall vs Agile in software development infographic" loading="lazy" width="1000" height="2000"></figure><p>A lot of the lip service around this time that was given as to why organizations were changing was, frankly, bullshit. The real reason companies were so desperate to change was the following:</p><ul><li>Having lots of mandatory technical employees they couldn't easily replace was a bummer</li><li>Recruitment was hard and expensive. </li><li>Sales couldn't easily inject whatever last-minute deal requirement they had into the release cycle since that was often set it stone. </li><li>It provided an amazing opportunity for SaaS vendors to inject themselves into the process by offloading complexity into their stack so they pushed it hard.</li><li>The change also emphasized the strengths of cloud platforms at the time when they were starting to gobble market share. You didn't need lots of discipline, just allocate more servers. </li><li>Money was (effectively) free so it was better to increase speed regardless of monthly bills. </li><li>Developers were understandably frustrated that minor changes could take weeks to get out the door while they were being blamed for customer complaints.</li></ul><p>So executives went to a few conferences and someone asked them if they were "doing DevOps" and so we all changed our entire lives so they didn't feel like they weren't part of the cool club. </p><h3 id="what-was-devops">What Was DevOps?</h3><p>Often this image is used to sum it up:</p><figure><img src="https://wac-cdn.atlassian.com/dam/jcr:ef9fe684-c6dc-4ba0-a636-4ef7bcfa11f1/New%20DevOps%20Loop%20image.png?cdnVersion=1833" alt="DevOps Infinity Wheel" loading="lazy" width="2240" height="1090"></figure><p>In a nutshell, the basic premise was that development teams and operations teams were now one team. QA was fired and replaced with this idea that because you could very quickly deploy new releases and get feedback on those releases, you didn't need a lengthy internal test period where every piece of functionality was retested and determined to still be relevant. </p><p>Often this is <em>conflated</em> with the concept of SRE from Google, which I will argue until I die is a giant mistake. SRE is in the same genre but a very different tune, with a much more disciplined and structured approach to this problem. DevOps instead is about the simplification of the stack such that any developer on your team can deploy to production as many times in a day as they wish with only the minimal amounts of control on that deployment to ensure it had a reasonably high chance of working. </p><p>In reality DevOps as a practice looks much more like how Facebook operated, with employees committing to production on their first day and relying extensively on real-world signals to determine success or failure vs QA and tightly controlled releases. </p><p>In practice it looks like this:</p><ul><li>Development makes a branch in git and adds a feature, fix, change, etc. </li><li>They open up a PR and then someone else on that team looks at it, sees it passes their internal tests, approves it and then it gets merged into main. This is effectively the only safety step, relying on the reviewer to have perfect knowledge of all systems. </li><li>This triggers a webhook to the CI/CD system which starts the build (often of an entire container with this code inside) and then once the container is built, it's pushed to a container registry. </li><li>The CD system tells the servers that the new release exists, often through a Kubernetes deployment or pushing a new version of an internal package or using the internal CLI of the cloud providers specific "run a container as a service" platform. It then monitors and tells you about the success or failure of that deployment. </li><li>Finally there are release-aware metrics which allow that same team, who is on-call for their application, to see if something has changed since they released it. Is latency up, error count up, etc. This is often just a line in a graph saying this was old and this is new. </li><li>Depending on the system, this can either be something where every time the container is deployed it is on brand-new VMs or it is using some system like Kubernetes to deploy "the right number" of containers. </li></ul><p>The sales pitch was simple. Everyone can do everything so teams no longer need as many specialized people. Frameworks like Rails made database operations less dangerous, so we don't need a team of DBAs. Hell, use something like Mongo and you never need a DBA! </p><p>DevOps combined with Agile ended up with a very different philosophy of programming which had the following conceits:</p><ul><li>The User is the Tester</li><li>Every System Is Your Specialization </li><li>Speed Of Shipping Above All</li><li>Catch It In Metrics</li><li>Uptime Is Free, SSO Costs Money (free features were premium, expensive availability wasn't charged for)</li><li>Logs Are Business Intelligence</li></ul><h3 id="what-didnt-work">What Didn't Work</h3><p>The first cracks in this model emerged pretty early on. Developers were testing on their local Mac and Windows machines and then deploying code to Linux servers configured from Ansible playbooks and left running for months, sometimes years. Inevitably small differences in the running fleet of production servers emerged, either from package upgrades for security reasons or just from random configuration events. This could be mitigated by frequently rotating the running servers by destroying and rebuilding them as fresh VMs, but in practice this wasn't done as often as it should have been. </p><p>Soon you would see things like "it's running fine on box 1,2, 4, 5, but 3 seems to be having problems". It wasn't clear in the DevOps model <em>who</em> exactly was supposed to go figure out what was happening or how. In the previous design someone who worked with Linux for years and with these specific servers would be monitoring the release, but now those team members often wouldn't even know a deployment was happening. Telling someone who is amazing at writing great Javascript to go "find the problem with a Linux box" turned out to be easier said than done. </p><p>Quickly feedback from developers started to pile up. They didn't want to have to spend all this time figuring out what Debian package they wanted for this or that dependency. It wasn't what they were interested in doing and also they weren't being rewarded for that work, since they were almost exclusively being measured for promotions by the software they shipped. This left the Operations folks in charge of "smoothing out" this process, which in practice often meant really wasteful practices. </p><p>You'd see really strange workflows around this time of doubling the number of production servers you were paying for by the hour during a deployment and then slowly scaling them down, all relying on the same AMI (server image) to ensure some baseline level of consistency. However since any update to the AMI required a full dev-stage-prod check, things like security upgrades took <em>a very long time</em>. </p><p>Soon you had just a pile of issues that became difficult to assign. Who "owned" platform errors that didn't result in problems for users? When a build worked locally but failed inside of Jenkins, what team needed to check that? The idea of we're all working on the same team broke down when it came to assigning ownership of annoying issues because <em>someone</em> had to own them or they'd just sit there forever untouched. </p><h3 id="enter-containers">Enter Containers</h3><p>DevOps got a real shot in the arm with the popularization of containers, which allowed the movement to progress past its awkward teenage years. Not only did this (mostly) solve the "it worked on my machine" thing but it also allowed for a massive simplification of the Linux server component part. Now servers were effectively dumb boxes running containers, either on their own with Docker compose or as part of a fleet with Kubernetes/ECS/App Engine/Nomad/whatever new thing that has been invented in the last two weeks. </p><p>Combined with you could move almost everything that might previous be a networking team problem or a SAN problem to configuration inside of the cloud provider through tools like Terraform and you saw a real flattening of the skill curve. This greatly reduced the expertise required to operate these platforms and allowed for more automation. Soon you started to see what we now recognize as the current standard for development which is "I push out a bajillion changes a day to production". </p><h3 id="what-containers-didnt-fix">What Containers Didn't Fix</h3><p>So there's a lot of other shit in that DevOps model we haven't talked about. </p><figure><img src="https://matduggan.com/content/images/2024/06/New-DevOps-Loop-image.png" alt="" loading="lazy" width="2000" height="973" srcset="https://matduggan.com/content/images/size/w600/2024/06/New-DevOps-Loop-image.png 600w, https://matduggan.com/content/images/size/w1000/2024/06/New-DevOps-Loop-image.png 1000w, https://matduggan.com/content/images/size/w1600/2024/06/New-DevOps-Loop-image.png 1600w, https://matduggan.com/content/images/2024/06/New-DevOps-Loop-image.png 2240w" sizes="(min-width: 720px) 720px"></figure><p>So far teams had improved the "build, test and deploy" parts. However operating the crap was still very hard. Observability was <em>really really</em> hard and expensive. Discoverability was actually harder than ever because stuff was constantly changing beneath your feet and finally the Planning part immediately collapsed into the ocean because now teams could do whatever they wanted all the time. </p><p><strong>Operate</strong></p><p>This meant someone going through and doing all the boring stuff. Upgrading Kubernetes, upgrading the host operating system, making firewall rules, setting up service meshes, enforcing network policies, running the bastion host, configuring the SSH keys, etc. What organizations quickly discovered was that this stuff was very time consuming to do and often required <em>more</em> specialization than the roles they had previously gotten rid of. </p><p>Before you needed a DBA, a sysadmin, a network engineer and some general Operations folks. Now you needed someone who not only understood databases but understood <em>your specific cloud providers</em> version of that database. You still needed someone with the sysadmin skills, but in addition they needed to be experts in your cloud platform in order to ensure you weren't exposing your database to the internet. Networking was still critical but now it all existed at a level outside of your control, meaning weird issues would sometimes have to get explained as "well that sometimes happens". </p><p>Often teams would delay maintenance tasks out of a fear of breaking something like k8s or their hosted database, but that resulted in delaying the pain and making their lives more difficult. This was the era where every startup I interviewed with basically just wanted someone to update all the stuff in their stack "safely". Every system was well past EOL and nobody knew how to Jenga it all together. </p><p><strong>Observe</strong></p><p>As applications shipped more often, knowing they worked became more important so you could roll back if it blew up in your face. However replacing simple uptime checks with detailed traces, metrics and logs was hard. These technologies are specialized and require detailed understanding of what they do and how they work. A syslog centralized box lasts <em>to a point</em> and then it doesn't. Prometheus scales to x amount of metrics and then no longer works on a single box. You needed someone who had a detailed understanding of how metrics, logs and traces worked and how to work with development teams in getting them sending the correct signal to the right places at the right amount of fidelity. </p><p>Or you could pay a SaaS a <em>shocking amount</em> to do it for you. The rise of companies like Datadog and the eye-watering bills that followed was proof that they understood how important what they were providing was. You quickly saw Observability bills exceed CPU and networking costs for organizations as one team would misconfigure their application logs and suddenly you have blown through your monthly quota in a week. </p><p>Developers were being expected to monitor with detailed precision what was happening with their applications without a full understanding of what they were seeing. How many metrics and logs were being dropped on the floor or sampled away, how did the platform work in displaying these logs to them, how do you write an query for terabytes of logs so that you can surface what you need quickly, all of this was being passed around in Confluence pages being written by desperate developers who were learning as they were getting paged at 2AM how all this shit works together. </p><p><strong>Continuous Feedback</strong></p><p>This to me is the same problem as Observe. It's about whether your deployment worked or not and whether you had signal from internal tests if it was likely to work. It's also about feedback from the team on what in this process worked and what didn't, but because nobody ever did anything with that internal feedback we can just throw that one directly in the trash. </p><p>I guess in theory this would be retros where we all complain about the same six things every sprint and then continue with our lives. I'm not an Agile Karate Master so you'll need to talk to the experts. </p><p><strong>Discover</strong></p><p>A big pitch of combining these teams was the idea of more knowledge sharing. Development teams and Operation teams would be able to cross-share more about what things did and how they worked. Again it's an interesting idea and there was some improvement to discoverability, but in practice that isn't how the incentives were aligned. </p><p>Developers weren't rewarded for discovering more about how the platform operated and Operations didn't have any incentive to sit down and figure out how the frontend was built. It's not a lack of intellectual curiosity by either party, just the finite amount of time we all have before we die and what we get rewarded for doing. Being surprised that this didn't work is like being surprised a mouse didn't go down the tunnel with no cheese just for the experience. </p><p>In practice I "discovered" that if NPM was down nothing worked and the frontend team "discovered" that troubleshooting Kubernetes was a bit like Warhammer 40k Adeptus Mechanicus waving incense in front of machines they didn't understand in the hopes that it would make the problem go away. </p><figure><img src="https://warhammeruniverse.com/wp-content/uploads/2023/12/00007-2552221792-1024x569.png" alt="The Adeptus Mechanicus - Warhammer Universe (2024)" loading="lazy" width="1024" height="569"><figcaption><span>Try restarting the Holy Deployment</span></figcaption></figure><p><strong>Plan</strong></p><p>Maybe more than anything else, this lack of centralization impacted planning. Since teams weren't syncing on a regular basis anymore, things could continue in crazy directions unchecked. In theory PMs were syncing with each other to try and ensure there were railroad tracks in front of the train before it plowed into the ground at 100 MPH, but that was a lot to put on a small cadre of people. </p><p>We see this especially in large orgs with microservices where it is easier to write a new microservice to do something rather than figure out which existing microservice does the thing you are trying to do. This model was sustainable when money was free and cloud budgets were unlimited, but once that gravy train crashed into the mountain of "businesses need to be profitable and pay taxes" that stopped making sense. </p><h3 id="the-part-where-we-all-gave-up">The Part Where We All Gave Up</h3><p>A lot of orgs solved the problems above by simply throwing bodies into the mix. More developers meant it was possible for teams to have someone (anyone) learn more about the systems and how to fix them. Adding more levels of PMs and overall planning staff meant even with the frantic pace of change it was...more possible to keep an eye on what was happening. While cloud bills continued to go unbounded, for the most part these services worked and allowed people to do the things they wanted to do. </p><p>Then layoffs started and budget cuts. Suddenly it wasn't acceptable to spend unlimited money with your logging platform and your cloud provider as well as having a full team. Almost instantly I saw the shift as organizations started talking about "going back to basics". Among this was a hard turn in the narrative around Kubernetes where it went from an amazing technology that lets you grow to Google-scale to a weight around an organizations neck nobody understood. </p><p><strong>Platform Engineering</strong></p><p>Since there are no new ideas, just new terms, a successor to the throne has emerged. No longer are development teams expected to understand and troubleshoot the platforms that run their software, instead the idea is that the entire process is completely abstracted away from them. They provide the container and that is the end of the relationship. </p><p>From a certain perspective this makes more sense since it places the ownership for the operation of the platform with the people who should have owned it from the beginning. It also removes some of the ambiguity over what is whose problem. The development teams are still on-call for their specific application errors, but platform teams are allowed to enforce more global rules. </p><p>Well at least in theory. In practice this is another expansion of roles. You went from needing to be a Linux sysadmin to being a cloud-certified Linux sysadmin to being a Kubernetes-certified multicloud Linux sysadmin to finally being an application developer who can create a useful webUI for deploying applications on top of a multicloud stack that runs on Kubernetes in multiple regions with perfect uptime and observability that doesn't blow the budget. I guess at some point between learning the difference between AWS and GCP we were all supposed to go out and learn how to make useful websites. </p><figure><img src="https://cdn.prod.website-files.com/622b2fcc29fc56492b771cb8/637d1841fc5e9a6a942d5a02_1.png" alt="" loading="lazy" width="1600" height="683"></figure><p>This division of labor makes no sense but at least it's something I guess. Feels like somehow Developers got stuck with a lot more work and Operation teams now need to learn 600 technologies a week. Surprisingly tech executives didn't get any additional work with this system. I'm sure the next reorg they'll chip in more. </p><h3 id="conclusion">Conclusion</h3><p>We are now seeing a massive contraction of the Infrastructure space. Teams are increasingly looking for simple, less platform specific tooling. In my own personal circles it feels like a real return to basics, as small and medium organizations abandon technology like Kubernetes and adopt much more simple and easy-to-troubleshoot workflows like "a bash script that pulls a new container". </p><p>In some respects it's a positive change, as organizations stop pretending they needed a "global scale" and can focus on actually servicing the users and developers they have. In reality a lot of this technology was adopted by organizations who weren't ready for it and didn't have a great plan for how to use it. </p><p>However Platform Engineering is not a magical solution to the problem. It is instead another fabrication of an industry desperate to show monthly growth in cloud providers who know teams lack the expertise to create the kinds of tooling described by such practices. In reality organizations need to be more brutally honest about what they <em>actually need</em> vs what bullshit they've been led to believe they need. </p><p>My hope is that we keep the gains from the DevOps approach and focus on simplification and stability over rapid transformation in the Infrastructure space. I think we desperately need a return to basics ideology that encourages teams to stop designing with the expectation that endless growth is the only possible outcome of every product launch. </p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open source 'Eclipse Theia IDE' exits beta to challenge Visual Studio Code (167 pts)]]></title>
            <link>https://visualstudiomagazine.com/Articles/2024/06/27/eclipse-theia-ide.aspx</link>
            <guid>40825146</guid>
            <pubDate>Fri, 28 Jun 2024 20:49:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://visualstudiomagazine.com/Articles/2024/06/27/eclipse-theia-ide.aspx">https://visualstudiomagazine.com/Articles/2024/06/27/eclipse-theia-ide.aspx</a>, See on <a href="https://news.ycombinator.com/item?id=40825146">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="level0"> 
        
        <p id="ph_pcontent2_0_KickerText"><a href="https://visualstudiomagazine.com/Articles/List/News.aspx">News</a></p>
        
        <h3 id="ph_pcontent2_0_MainHeading">Open Source 'Eclipse Theia IDE' Exits Beta to Challenge Visual Studio Code</h3>
        
        
        

        <p>
  Some seven years in the making, the Eclipse Foundation's Theia IDE project is now generally available, emerging from beta to challenge Microsoft's similar Visual Studio Code editor, with which it shares much tech.
  
</p>



<p>
   The <a href="https://theia-ide.org/#theiaide" target="_blank">Eclipse Theia IDE</a>, part of the <a href="https://ecdtools.eclipse.org/" target="_blank">Eclipse Cloud DevTools ecosystem</a>, primarily differs from VS Code in licensing and governance. Open-source champion Eclipse Foundation calls it a "true open-source alternative" to VS Code, which Microsoft has <a href="https://code.visualstudio.com/docs/supporting/faq" target="_blank">described</a> as being "built" on open source but with proprietary elements like default telemetry with which usage data is collected.
 
</p>



<div><figure> <a href="https://visualstudiomagazine.com/Articles/2024/06/27/~/media/ECG/visualstudiomagazine/Images/2024/06/theia_desktop.ashx" target="_blank">
<img alt="Eclipse Theia IDE in on Windows" src="https://visualstudiomagazine.com/Articles/2024/06/27/~/media/ECG/visualstudiomagazine/Images/2024/06/theia_desktop_s.ashx" height="160" width="300"> </a>
<figcaption> <b>[Click on image for larger view.]</b> Eclipse Theia IDE in on Windows <em>(source: Screenshot).</em></figcaption>
</figure></div>




<p>
  Note that Eclipse Theia IDE is a separate component from the overall Theia project's related <a href="https://projects.eclipse.org/projects/ecd.theia" target="_blank">Eclipse Theia Platform</a>, used to build IDEs and tools based on modern web technologies.
  
</p>






<p>
  As far as the similarities with VS Code, Theia is built on the same <a href="https://microsoft.github.io/monaco-editor/" target="_blank">Monaco editor</a> that powers VS Code, and it supports the same Language Server Protocol (LSP) and Debug Adapter Protocol (DAP) that provide IntelliSense code completions, error checking and other features.
  
</p>



<p>
  Eclipse Theia IDE also supports the same extensions as VS Code (via the <a href="https://open-vsx.org/" target="_blank">Open VSX Registry</a> instead of Microsoft's Visual Studio Code Marketplace), which are typically written in TypeScript and JavaScript. There are many, many more extensions available for VS Code in Microsoft's marketplace, while "Extensions for VS Code Compatible Editors" in the Open VSX Registry number 3,784 at the time of this writing. 
</p>

    

<br>



<div><figure> <a href="https://visualstudiomagazine.com/Articles/2024/06/27/~/media/ECG/visualstudiomagazine/Images/2024/06/open_vsx.ashx" target="_blank">
<img alt="Open VSX Registry" src="https://visualstudiomagazine.com/Articles/2024/06/27/~/media/ECG/visualstudiomagazine/Images/2024/06/open_vsx_s.ashx" height="159" width="300"> </a>
<figcaption> <b>[Click on image for larger view.]</b> Open VSX Registry <em>(source: Open VSX Registry).</em></figcaption>
</figure></div>




<p>
Eclipse Foundation <a href="https://eclipsesource.com/blogs/2019/12/06/the-eclipse-theia-ide-vs-vs-code/" target="_blank">compared the two tools</a> in 2019, when it said to make a good decision between using VS Code or Eclipse Theia as a platform for a tool, an organization will need to evaluate custom project requirements, noting that as a general direction:
</p>




<ul>
<li>If you want to provide some tooling, which is focussed on code and want as many developers as possible to use it in their existing IDE, providing an extension for VS Code seems like a valid choice.
</li>
<li>If you want to provide a white-labeled product for customers or your own developers, which is tailored to a specific use case and possibly contains more features than code editing, you might be better served with Eclipse Theia.</li>
</ul>




<p>
  A somewhat more recent <a href="https://blogs.eclipse.org/post/mike-milinkovich/eclipse-theia-and-vs-code-differences-explained" target="_blank">post</a> from 2020 exploring the differences between the Eclipse Theia Platform (not IDE) and VS Code noted two primary ways in which the projects' architectures differ:
  
</p>



<ul>
<li>Eclipse Theia allows developers to create desktop and cloud IDEs using a single, open source technology stack. Microsoft now offers VS Online for cloud development environments, but like VS Code, it cannot be used in open source initiatives such as Gitpod.
</li>
<li>Eclipse Theia allows developers to customize every aspect of the IDE without forking or patching the code. This means they can easily use Theia as a base to develop desktop and cloud IDEs that are fully tailored for the needs of internal company projects or for commercial resale as a branded product. VS Code is a developer IDE only. It was never intended to be used as the base for other IDEs, extended, or further distributed.</li>
</ul>




<p>
  For developers just wanting to pick a tool to write apps with, an Eclipse Foundation blog <a href="https://eclipsesource.com/blogs/2024/06/27/introducing-the-theia-ide/" target="_blank">post</a> today said: "For developers in search of an IDE that combines flexibility, openness, and cutting-edge technology, the Theia IDE is a compelling choice. Distinctive features like an adaptable toolbar, detachable views, remote development support, and the forthcoming live collaboration mode set Theia apart from other open-source IDEs. Moreover, its commitment to privacy and its stance against incorporating telemetry by default reflect its respect for user preferences."
</p>






<p>
  Eclipse Foundation today emphasized another difference between its Theia IDE and VS Code: the surrounding ecosystem/community.
</p>




<div><figure> <a href="https://visualstudiomagazine.com/Articles/2024/06/27/~/media/ECG/visualstudiomagazine/Images/2024/06/theia_community.ashx" target="_blank">
<img alt="Eclipse Theia Community" src="https://visualstudiomagazine.com/Articles/2024/06/27/~/media/ECG/visualstudiomagazine/Images/2024/06/theia_community_s.ashx" height="220" width="300"> </a>
<figcaption> <b>[Click on image for larger view.]</b> Eclipse Theia Community <em>(source: Eclipse).</em></figcaption>
</figure></div>




<p>
  "At the core of Theia IDE is its vibrant open source community hosted by the Eclipse Foundation," the organization <a href="https://newsroom.eclipse.org/news/announcements/eclipse-foundation-introduces-theia-ide-elevate-modern-developer-experience" target="_blank">said</a> in a news release. "This ensures freedom for commercial use without proprietary constraints and fosters innovation and reliability through contributions from companies like Ericsson, EclipseSource, STMicroelectronics, TypeFox, and more. The community-driven model encourages participation and adaptation according to user needs and feedback."
</p>




<p>
  Indeed, the list of contributors to and adopters of the platform is extensive, also featuring Broadcom, Arm, IBM, Red Hat, SAP, Samsung, Google, Gitpod, Huawei and many others.
</p>




<p>
  "The Theia IDE's open-source foundation, supported by a vibrant community and underpinned by a license that champions commercial use, sets the stage for a development environment that is not only powerful and flexible but also inclusive and forward-looking," Eclipse Foundation concluded in its announcement today. "By choosing the Theia IDE, developers and organizations are not just adopting an IDE; they are joining a movement that values collaboration, freedom, and the collective pursuit of excellence in software development."
</p>
<br>
        
        
        
        
        
        
        
        <!-- pager start -->
        
        <!-- pager end -->
        
        
            
        

        
                <div>
                    <p id="ph_pcontent2_0_AuthorInfo_AboutAuthor">About the Author</p>
                    
                <p>
                    <strong></strong>
                    David Ramel is an editor and writer for Converge360.
                    <br>
                    
                    <a id="ph_pcontent2_0_AuthorInfo_AuthorEmail_0"></a>
                </p>
            
                </div>
            
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The story, as best I can remember, of the origin of Mosaic and Netscape [video] (265 pts)]]></title>
            <link>https://pmarca.substack.com/p/the-true-story-as-best-i-can-remember</link>
            <guid>40825033</guid>
            <pubDate>Fri, 28 Jun 2024 20:39:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pmarca.substack.com/p/the-true-story-as-best-i-can-remember">https://pmarca.substack.com/p/the-true-story-as-best-i-can-remember</a>, See on <a href="https://news.ycombinator.com/item?id=40825033">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main"><div data-testid="navbar"><p><a href="https://pmarca.substack.com/" native=""><img src="https://substackcdn.com/image/fetch/w_96,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg"></a></p><h2><a href="https://pmarca.substack.com/" native="">Marc Andreessen Substack</a></h2></div><div><div><article><div><div><div><div><div><div><div><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="m12 14 4-4"></path><path d="M3.34 19a10 10 0 1 1 17.32 0"></path></svg><p>Playback speed</p></div><div><p>×</p></div></div><div><div><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 12v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2v-8"></path><polyline points="16 6 12 2 8 6"></polyline><line x1="12" x2="12" y1="2" y2="15"></line></svg><p>Share post</p></div></div><div><div><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 12v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2v-8"></path><polyline points="16 6 12 2 8 6"></polyline><line x1="12" x2="12" y1="2" y2="15"></line></svg><p>Share post at current time</p></div></div></div><div><div><div><div id="trigger27149" aria-expanded="false" aria-haspopup="dialog" aria-controls="dialog27150" arialabel="View more"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 12v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2v-8"></path><polyline points="16 6 12 2 8 6"></polyline><line x1="12" x2="12" y1="2" y2="15"></line></svg><p>Share from 0:00</p></div></div></div><div><div><p>0:00</p><p>/</p><p>0:00</p></div></div></div></div><div><div><p>Transcript</p></div></div></div></div><div><div><div><div><p>Enjoy!</p></div><div><div><a href="https://substack.com/profile/22353-marc-andreessen" target="_blank" rel="noopener"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_80,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg"><img src="https://substackcdn.com/image/fetch/w_80,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg" sizes="100vw" alt="" width="80"></picture></a></div><div><div><p><a href="https://substack.com/@pmarca">Marc Andreessen</a></p></div><div><p>Jun 28, 2024</p></div></div></div><div><span><p>Share</p></span><a role="button"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="var(--color-secondary-themed)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="21" x2="3" y1="6" y2="6"></line><line x1="15" x2="3" y1="12" y2="12"></line><line x1="17" x2="3" y1="18" y2="18"></line></svg><p>Transcript</p></a></div></div></div><div><div><div><div><a href="https://pmarca.substack.com/" native=""><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_48,h_48,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg 48w, https://substackcdn.com/image/fetch/w_96,h_96,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg 96w, https://substackcdn.com/image/fetch/w_144,h_144,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg 144w" sizes="48px"><img src="https://substackcdn.com/image/fetch/w_48,h_48,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg" sizes="48px" alt="Marc Andreessen Substack" srcset="https://substackcdn.com/image/fetch/w_48,h_48,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg 48w, https://substackcdn.com/image/fetch/w_96,h_96,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg 96w, https://substackcdn.com/image/fetch/w_144,h_144,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg 144w" width="48" height="48"></picture></a></div><p>Marc Andreessen Substack</p></div><div data-component-name="SubscribeWidget"><form action="/api/v1/free?nojs=true" method="post" novalidate=""></form></div></div><div><div><p>Authors</p><div><div><a href="https://substack.com/profile/22353-marc-andreessen?utm_source=author-byline-face-podcast" target="_blank" rel="noopener"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_64,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg"><img src="https://substackcdn.com/image/fetch/w_64,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg" sizes="100vw" alt="" width="64"></picture></a></div><div><p>Marc Andreessen</p></div></div></div><div><p>Recent Posts</p><div><div><p><img type="image/gif" src="https://pmarca.substack.com/api/v1/video/upload/b33e4bc3-2428-4b56-8367-cd1d85a680cc/preview.gif?height=480"></p><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_150,h_150,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-video.s3.amazonaws.com%2Fvideo_upload%2Fpost%2F143254349%2Fb33e4bc3-2428-4b56-8367-cd1d85a680cc%2Ftranscoded-00001.png"><img src="https://substackcdn.com/image/fetch/w_150,h_150,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-video.s3.amazonaws.com%2Fvideo_upload%2Fpost%2F143254349%2Fb33e4bc3-2428-4b56-8367-cd1d85a680cc%2Ftranscoded-00001.png" sizes="(min-width:768px) 50vw, 100vw" alt="" width="150" height="150"></picture></div><div><div><p><a href="https://pmarca.substack.com/p/on-tech-politicspolicy-2-hour-video" data-testid="post-preview-title">On Tech Politics/Policy -- 2 hour video discussion</a></p></div><div><p><time datetime="2024-04-04T05:37:52.095Z">Apr 4</time>&nbsp;<span>•</span>&nbsp;<span><a href="https://substack.com/@pmarca">Marc Andreessen</a></span></p></div></div></div></div></div></div></div></div></article></div><div><p>Ready for more?</p><div><form action="/api/v1/free?nojs=true" method="post" novalidate=""></form></div></div></div><div><div><p>© 2024 Marc Andreessen</p><div><p><a href="https://substack.com/privacy" target="_blank" rel="noopener noreferrer">Privacy</a><span> ∙ </span><a href="https://substack.com/tos" target="_blank" rel="noopener noreferrer">Terms</a><span> ∙ </span><a href="https://substack.com/ccpa#personal-data-collected" target="_blank" rel="noopener noreferrer">Collection notice</a></p></div></div><div><a native="" href="https://substack.com/signup?utm_source=substack&amp;utm_medium=web&amp;utm_content=footer"><svg role="img" width="1000" height="1000" viewBox="0 0 1000 1000" fill="#FF6719" stroke-width="1.8" stroke="none" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M764.166 348.371H236.319V419.402H764.166V348.371Z"></path><path d="M236.319 483.752V813.999L500.231 666.512L764.19 813.999V483.752H236.319Z"></path><path d="M764.166 213H236.319V284.019H764.166V213Z"></path></g></svg> Start Writing</a><p><a native="" href="https://substack.com/app/app-store-redirect?utm_campaign=app-marketing&amp;utm_content=web-footer-button">Get the app</a></p></div><p><a href="https://substack.com/" native="">Substack</a> is the home for great culture</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US Supreme Court allows cities to ban homeless camps (112 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cj774nxrpy7o</link>
            <guid>40823850</guid>
            <pubDate>Fri, 28 Jun 2024 18:54:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cj774nxrpy7o">https://www.bbc.com/news/articles/cj774nxrpy7o</a>, See on <a href="https://news.ycombinator.com/item?id=40823850">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="byline" data-component="byline-block"><p><time>10 hours ago</time></p><div><p><span data-testid="byline-name">By&nbsp;<!-- -->Samantha Granville<!-- -->,&nbsp;<!-- --></span><span>BBC News, Los Angeles</span></p></div></div><div data-component="text-block"><p>The US Supreme Court has ruled in a 6-3 vote along ideological lines that cities can ban homeless people from sleeping rough.<!-- --></p><p>It is the court's most significant decision on homelessness since at least the 1980s, when many experts say the modern US homeless crisis began.<!-- --></p><p>The ruling says that local governments can enforce laws against people sleeping in public places without being in violation of the US constitution's limits on cruel and unusual punishment.<!-- --></p><p>The case started in the small city of Grants Pass, Oregon, where three homeless people sued after receiving citations for sleeping and camping outside.<!-- --></p><p>At a Supreme Court hearing in April, the city argued that criminal penalties were necessary to enforce local laws banning homeless people from public spaces for "reasons of cleanliness and safety".<!-- --></p><p>The homeless residents said those penalties violated the Eighth Amendment of the US Constitution because the city did not have any public shelters.<!-- --></p><p>Writing for the conservative majority in an opinion issued on Friday, Justice Neil Gorsuch wrote that the city's regulations on camping do not inflict “terror, pain or disgrace”.<!-- --></p><p>He added that the law does not criminalise the “mere status” of being homeless, and that the ban focuses more on the actions taken by individuals rather than their status alone.<!-- --></p><p>“Under the city’s laws, it makes no difference whether the charged defendant is homeless, a backpacker on vacation passing through town, or a student who abandons his dorm room to camp out in protest on the lawn of a municipal building,” Justice Gorsuch wrote.<!-- --></p><p>Justice Sonia Sotomayor, writing on behalf of the three dissenting liberal justices, wrote: “Sleep is a biological necessity, not a crime. Homelessness is a reality for so many Americans.”<!-- --></p><p>Several cities issued statements welcoming the ruling. San Francisco said it would help cities "manage our public spaces more effectively and efficiently," and the city of Grants Pass, the centre of the legal dispute, said that city leaders would meet with their lawyers to discuss next steps. <!-- --></p><p>Homelessness is on the rise in the US, fuelled in part by chronic shortages of affordable housing. Around 653,000 people did not have homes in 2023, the largest number since tracking began in 2007, according to US government figures. <!-- --></p><p>There were also an estimated 256,000 people living without shelter on a given night across the country last year, according to the <!-- --><a target="_blank" href="https://www.huduser.gov/portal/sites/default/files/pdf/2023-AHAR-Part-1.pdf">Department of Housing and Urban Development.<!-- --></a></p><p>Reacting to the ruling, the National Alliance to End Homelessness said it "sets a dangerous precedent that will cause undue harm to people experiencing homelessness and give free reign to local officials who prefer pointless and expensive arrests and imprisonment, rather than real solutions".<!-- --></p><p>Grants Pass's population has doubled to 40,000 in the last 20 years, but its supply of affordable or public housing has not.<!-- --></p><p>Soaring housing costs led to a sizeable number of people losing their homes.<!-- --></p><p>Town officials responded by passing laws that fined people for sleeping or camping in public. Over time, those fines stacked up, reaching thousands of dollars for some.<!-- --></p><p>Unable to pay for multiple citations, three homeless people sued the city.<!-- --></p><p>Their lawsuit reached the 9th Circuit Court of Appeals, which decided in 2022 that the restrictions in Grants Pass were so tight that they amounted to an effective ban on being homeless within city limits.<!-- --></p><p>The court had determined four years earlier in a similar case in Idaho that the constitution “bars a city from prosecuting people criminally for sleeping outside on public property when those people have no home or other shelter to go to".<!-- --></p></div><div data-component="text-block"><p>Meanwhile, the homeless crisis has continued to worsen.<!-- --></p><p>Jennifer Friedenbach, of the Coalition on Homelessness in San Francisco, said that money and resources should "go towards getting folks off the streets".<!-- --></p><p>“What we know is that arresting and fining people for being homeless doesn't work," she said. "It doesn't get anybody off the streets. It wastes municipal resources, and it exacerbates homelessness."<!-- --></p><p>The Supreme Court's Grants Pass decision will now allow cities to take more severe measures without the fear of legal recourse.<!-- --></p><p>The first problem with putting homeless people in jail is that it is extremely expensive, and when they get out, the person is still homeless and now even less apt to finding employment with a criminal record, says Elizabeth Funk, founder of DignityMoves, a nonprofit dedicated to ending unsheltered homelessness.<!-- --></p><p>“We need to be thinking about how to get this problem solved," she says. "It's not going to be fining people for doing something they can't avoid. It's helping them.”<!-- --></p><p>Some of the highest concentrations of homeless are on the West Coast. <!-- --></p><p>California, with its moderate temperatures, accounts for nearly half of all homeless people who live outside and has a total of 123,423 homeless, according to data from the US Department of Housing and Urban Development.<!-- --></p><p>Cities across the country have been wrestling with how to combat the growing crisis. <!-- --></p><p>The issue has been at the heart of recent election cycles in West Coast cities, including Los Angeles, where officials have poured record amounts of money into creating shelters and affordable housing while homelessness has still increased.<!-- --></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama-agents: an async-first framework for building production ready agents (103 pts)]]></title>
            <link>https://github.com/run-llama/llama-agents</link>
            <guid>40822512</guid>
            <pubDate>Fri, 28 Jun 2024 16:54:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/run-llama/llama-agents">https://github.com/run-llama/llama-agents</a>, See on <a href="https://news.ycombinator.com/item?id=40822512">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">🦙 <code>llama-agents</code> 🤖</h2><a id="user-content--llama-agents-" aria-label="Permalink: 🦙 llama-agents 🤖" href="#-llama-agents-"></a></p>
<p dir="auto"><code>llama-agents</code> is an async-first framework for building, iterating, and productionizing multi-agent systems, including multi-agent communication, distributed tool execution, human-in-the-loop, and more!</p>
<p dir="auto">In <code>llama-agents</code>, each agent is seen as a <code>service</code>, endlessly processing incoming tasks. Each agent pulls and publishes messages from a <code>message queue</code>.</p>
<p dir="auto">At the top of a <code>llama-agents</code> system is the <code>control plane</code>. The control plane keeps track of ongoing tasks, which services are in the network, and also decides which service should handle the next step of a task using an <code>orchestrator</code>.</p>
<p dir="auto">The overall system layout is pictured below.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/run-llama/llama-agents/blob/main/system_diagram.png"><img src="https://github.com/run-llama/llama-agents/raw/main/system_diagram.png" alt="A basic system in llama-agents"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><code>llama-agents</code> can be installed with pip, and relies mainly on <code>llama-index-core</code>:</p>

<p dir="auto">If you don't already have llama-index installed, to follow these examples, you'll also need</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install llama-index-agent-openai"><pre>pip install llama-index-agent-openai</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">The quickest way to get started is with an existing agent (or agents) and wrapping into launcher.</p>
<p dir="auto">The example below shows a trivial example with two agents from <code>llama-index</code>.</p>
<p dir="auto">First, lets setup some agents and initial components for our <code>llama-agents</code> system:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from llama_agents import (
    AgentService,
    AgentOrchestrator,
    ControlPlaneServer,
    SimpleMessageQueue,
)

from llama_index.core.agent import ReActAgent
from llama_index.core.tools import FunctionTool
from llama_index.llms.openai import OpenAI


# create an agent
def get_the_secret_fact() -> str:
    &quot;&quot;&quot;Returns the secret fact.&quot;&quot;&quot;
    return &quot;The secret fact is: A baby llama is called a 'Cria'.&quot;


tool = FunctionTool.from_defaults(fn=get_the_secret_fact)

agent1 = ReActAgent.from_tools([tool], llm=OpenAI())
agent2 = ReActAgent.from_tools([], llm=OpenAI())

# create our multi-agent framework components
message_queue = SimpleMessageQueue(port=8000)
control_plane = ControlPlaneServer(
    message_queue=message_queue,
    orchestrator=AgentOrchestrator(llm=OpenAI(model=&quot;gpt-4-turbo&quot;)),
    port=8001,
)
agent_server_1 = AgentService(
    agent=agent1,
    message_queue=message_queue,
    description=&quot;Useful for getting the secret fact.&quot;,
    service_name=&quot;secret_fact_agent&quot;,
    port=8002,
)
agent_server_2 = AgentService(
    agent=agent2,
    message_queue=message_queue,
    description=&quot;Useful for getting random dumb facts.&quot;,
    service_name=&quot;dumb_fact_agent&quot;,
    port=8003,
)"><pre><span>from</span> <span>llama_agents</span> <span>import</span> (
    <span>AgentService</span>,
    <span>AgentOrchestrator</span>,
    <span>ControlPlaneServer</span>,
    <span>SimpleMessageQueue</span>,
)

<span>from</span> <span>llama_index</span>.<span>core</span>.<span>agent</span> <span>import</span> <span>ReActAgent</span>
<span>from</span> <span>llama_index</span>.<span>core</span>.<span>tools</span> <span>import</span> <span>FunctionTool</span>
<span>from</span> <span>llama_index</span>.<span>llms</span>.<span>openai</span> <span>import</span> <span>OpenAI</span>


<span># create an agent</span>
<span>def</span> <span>get_the_secret_fact</span>() <span>-&gt;</span> <span>str</span>:
    <span>"""Returns the secret fact."""</span>
    <span>return</span> <span>"The secret fact is: A baby llama is called a 'Cria'."</span>


<span>tool</span> <span>=</span> <span>FunctionTool</span>.<span>from_defaults</span>(<span>fn</span><span>=</span><span>get_the_secret_fact</span>)

<span>agent1</span> <span>=</span> <span>ReActAgent</span>.<span>from_tools</span>([<span>tool</span>], <span>llm</span><span>=</span><span>OpenAI</span>())
<span>agent2</span> <span>=</span> <span>ReActAgent</span>.<span>from_tools</span>([], <span>llm</span><span>=</span><span>OpenAI</span>())

<span># create our multi-agent framework components</span>
<span>message_queue</span> <span>=</span> <span>SimpleMessageQueue</span>(<span>port</span><span>=</span><span>8000</span>)
<span>control_plane</span> <span>=</span> <span>ControlPlaneServer</span>(
    <span>message_queue</span><span>=</span><span>message_queue</span>,
    <span>orchestrator</span><span>=</span><span>AgentOrchestrator</span>(<span>llm</span><span>=</span><span>OpenAI</span>(<span>model</span><span>=</span><span>"gpt-4-turbo"</span>)),
    <span>port</span><span>=</span><span>8001</span>,
)
<span>agent_server_1</span> <span>=</span> <span>AgentService</span>(
    <span>agent</span><span>=</span><span>agent1</span>,
    <span>message_queue</span><span>=</span><span>message_queue</span>,
    <span>description</span><span>=</span><span>"Useful for getting the secret fact."</span>,
    <span>service_name</span><span>=</span><span>"secret_fact_agent"</span>,
    <span>port</span><span>=</span><span>8002</span>,
)
<span>agent_server_2</span> <span>=</span> <span>AgentService</span>(
    <span>agent</span><span>=</span><span>agent2</span>,
    <span>message_queue</span><span>=</span><span>message_queue</span>,
    <span>description</span><span>=</span><span>"Useful for getting random dumb facts."</span>,
    <span>service_name</span><span>=</span><span>"dumb_fact_agent"</span>,
    <span>port</span><span>=</span><span>8003</span>,
)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Local / Notebook Flow</h3><a id="user-content-local--notebook-flow" aria-label="Permalink: Local / Notebook Flow" href="#local--notebook-flow"></a></p>
<p dir="auto">Next, when working in a notebook or for faster iteration, we can launch our <code>llama-agents</code> system in a single-run setting, where one message is propagated through the network and returned.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from llama_agents import LocalLauncher

# launch it
launcher = LocalLauncher(
    [agent_server_1, agent_server_2],
    control_plane,
    message_queue,
)
result = launcher.launch_single(&quot;What is the secret fact?&quot;)

print(f&quot;Result: {result}&quot;)"><pre><span>from</span> <span>llama_agents</span> <span>import</span> <span>LocalLauncher</span>

<span># launch it</span>
<span>launcher</span> <span>=</span> <span>LocalLauncher</span>(
    [<span>agent_server_1</span>, <span>agent_server_2</span>],
    <span>control_plane</span>,
    <span>message_queue</span>,
)
<span>result</span> <span>=</span> <span>launcher</span>.<span>launch_single</span>(<span>"What is the secret fact?"</span>)

<span>print</span>(<span>f"Result: <span><span>{</span><span>result</span><span>}</span></span>"</span>)</pre></div>
<p dir="auto">As with any agentic system, its important to consider how reliable the LLM is that you are using. In general, APIs that support function calling (OpenAI, Anthropic, Mistral, etc.) are the most reliable.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Server Flow</h3><a id="user-content-server-flow" aria-label="Permalink: Server Flow" href="#server-flow"></a></p>
<p dir="auto">Once you are happy with your system, we can launch all our services as independent processes, allowing for higher throughput and scalability.</p>
<p dir="auto">By default, all task results are published to a specific "human" queue, so we also define a consumer to handle this result as it comes in. (In the future, this final queue will be configurable!)</p>
<p dir="auto">To test this, you can use the server launcher in a script:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from llama_agents import ServerLauncher, CallableMessageConsumer


# Additional human consumer
def handle_result(message) -> None:
    print(f&quot;Got result:&quot;, message.data)


human_consumer = CallableMessageConsumer(
    handler=handle_result, message_type=&quot;human&quot;
)

# Define Launcher
launcher = ServerLauncher(
    [agent_server_1, agent_server_2],
    control_plane,
    message_queue,
    additional_consumers=[human_consumer],
)

# Launch it!
launcher.launch_servers()"><pre><span>from</span> <span>llama_agents</span> <span>import</span> <span>ServerLauncher</span>, <span>CallableMessageConsumer</span>


<span># Additional human consumer</span>
<span>def</span> <span>handle_result</span>(<span>message</span>) <span>-&gt;</span> <span>None</span>:
    <span>print</span>(<span>f"Got result:"</span>, <span>message</span>.<span>data</span>)


<span>human_consumer</span> <span>=</span> <span>CallableMessageConsumer</span>(
    <span>handler</span><span>=</span><span>handle_result</span>, <span>message_type</span><span>=</span><span>"human"</span>
)

<span># Define Launcher</span>
<span>launcher</span> <span>=</span> <span>ServerLauncher</span>(
    [<span>agent_server_1</span>, <span>agent_server_2</span>],
    <span>control_plane</span>,
    <span>message_queue</span>,
    <span>additional_consumers</span><span>=</span>[<span>human_consumer</span>],
)

<span># Launch it!</span>
<span>launcher</span>.<span>launch_servers</span>()</pre></div>
<p dir="auto">Now, since everything is a server, you need API requests to interact with it. The easiest way is to use our client and the control plane URL:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from llama_agents import LlamaAgentsClient, AsyncLlamaAgentsClient

client = LlamaAgentsClient(&quot;<control plane URL>&quot;)  # i.e. http://127.0.0.1:8001
task_id = client.create_task(&quot;What is the secret fact?&quot;)
# <Wait a few seconds>
# returns TaskResult or None if not finished
result = client.get_task_result(task_id)"><pre><span>from</span> <span>llama_agents</span> <span>import</span> <span>LlamaAgentsClient</span>, <span>AsyncLlamaAgentsClient</span>

<span>client</span> <span>=</span> <span>LlamaAgentsClient</span>(<span>"&lt;control plane URL&gt;"</span>)  <span># i.e. http://127.0.0.1:8001</span>
<span>task_id</span> <span>=</span> <span>client</span>.<span>create_task</span>(<span>"What is the secret fact?"</span>)
<span># &lt;Wait a few seconds&gt;</span>
<span># returns TaskResult or None if not finished</span>
<span>result</span> <span>=</span> <span>client</span>.<span>get_task_result</span>(<span>task_id</span>)</pre></div>
<p dir="auto">Rather than using a client or raw <code>curl</code> requests, you can also use a built-in CLI tool to monitor and interact with your services.</p>
<p dir="auto">In another terminal, you can run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="llama-agents monitor --control-plane-url http://127.0.0.1:8000"><pre>llama-agents monitor --control-plane-url http://127.0.0.1:8000</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/run-llama/llama-agents/blob/main/llama_agents_monitor.png"><img src="https://github.com/run-llama/llama-agents/raw/main/llama_agents_monitor.png" alt="The llama-agents monitor app"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">You can find a host of examples in our examples folder:</p>
<ul dir="auto">
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/agentic_rag_toolservice.ipynb">Agentic RAG + Tool Service</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/agentic_local_single.py">Agentic Orchestrator w/ Local Launcher</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/agentic_server.py">Agentic Orchestrator w/ Server Launcher</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/agentic_human_local_single.py">Agentic Orchestrator w/ Human in the Loop</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/agentic_toolservice_local_single.py">Agentic Orchestrator w/ Tool Service</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/pipeline_local_single.py">Pipeline Orchestrator w/ Local Launcher</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/pipeline_human_local_single.py">Pipeline Orchestrator w/ Human in the Loop</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/pipeline_agent_service_tool_local_single.py">Pipeline Orchestrator w/ Agent Server As Tool</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/query_rewrite_rag.ipynb">Pipeline Orchestrator w/ Query Rewrite RAG</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Components of a <code>llama-agents</code> System</h2><a id="user-content-components-of-a-llama-agents-system" aria-label="Permalink: Components of a llama-agents System" href="#components-of-a-llama-agents-system"></a></p>
<p dir="auto">In <code>llama-agents</code>, there are several key components that make up the overall system</p>
<ul dir="auto">
<li><code>message queue</code> -- the message queue acts as a queue for all services and the <code>control plane</code>. It has methods for publishing methods to named queues, and delegates messages to consumers.</li>
<li><code>control plane</code> -- the control plane is a the central gateway to the <code>llama-agents</code> system. It keeps track of current tasks, as well as the services that are registered to the system. It also holds the <code>orchestrator</code>.</li>
<li><code>orchestrator</code> -- The module handles incoming tasks and decides what service to send it to, as well as how to handle results from services. An orchestrator can be agentic (with an LLM making decisions), explicit (with a query pipeline defining a flow), a mix of both, or something completely custom.</li>
<li><code>services</code> -- Services are where the actual work happens. A services accepts some incoming task and context, processes it, and publishes a result
<ul dir="auto">
<li>A <code>tool service</code> is a special service used to off-load the compution of agent tools. Agents can instead be equipped with a meta-tool that calls the tool service.</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Low-Level API in <code>llama-agents</code></h2><a id="user-content-low-level-api-in-llama-agents" aria-label="Permalink: Low-Level API in llama-agents" href="#low-level-api-in-llama-agents"></a></p>
<p dir="auto">So far, you've seen how to define components and how to launch them. However in most production use-cases, you will need to launch services manually, as well as define your own consumers!</p>
<p dir="auto">So, here is a quick guide on exactly that!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Launching</h3><a id="user-content-launching" aria-label="Permalink: Launching" href="#launching"></a></p>
<p dir="auto">First, you will want to launch everything. This can be done in a single script, or you can launch things with multiple scripts per service, or on different machines, or even in docker images.</p>
<p dir="auto">In this example, we will assume launching from a single script.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import asyncio

# launch the message queue
queue_task = asyncio.create_task(message_queue.launch_server())

# wait for the message queue to be ready
await asyncio.sleep(1)

# launch the control plane
control_plane_task = asyncio.create_task(self.control_plane.launch_server())

# wait for the control plane to be ready
await asyncio.sleep(1)

# register the control plane as a consumer
await self.message_queue.client.register_consumer(
    self.control_plane.as_consumer(remote=True)
)

# register the services
control_plane_url = (
    f&quot;http://{self.control_plane.host}:{self.control_plane.port}&quot;
)
service_tasks = []
for service in self.services:
    # first launch the service
    service_tasks.append(asyncio.create_task(service.launch_server()))

    # register the service to the message queue
    await service.register_to_message_queue()

    # register the service to the control plane
    await service.register_to_control_plane(control_plane_url)"><pre><span>import</span> <span>asyncio</span>

<span># launch the message queue</span>
<span>queue_task</span> <span>=</span> <span>asyncio</span>.<span>create_task</span>(<span>message_queue</span>.<span>launch_server</span>())

<span># wait for the message queue to be ready</span>
<span>await</span> <span>asyncio</span>.<span>sleep</span>(<span>1</span>)

<span># launch the control plane</span>
<span>control_plane_task</span> <span>=</span> <span>asyncio</span>.<span>create_task</span>(<span>self</span>.<span>control_plane</span>.<span>launch_server</span>())

<span># wait for the control plane to be ready</span>
<span>await</span> <span>asyncio</span>.<span>sleep</span>(<span>1</span>)

<span># register the control plane as a consumer</span>
<span>await</span> <span>self</span>.<span>message_queue</span>.<span>client</span>.<span>register_consumer</span>(
    <span>self</span>.<span>control_plane</span>.<span>as_consumer</span>(<span>remote</span><span>=</span><span>True</span>)
)

<span># register the services</span>
<span>control_plane_url</span> <span>=</span> (
    <span>f"http://<span><span>{</span><span>self</span>.<span>control_plane</span>.<span>host</span><span>}</span></span>:<span><span>{</span><span>self</span>.<span>control_plane</span>.<span>port</span><span>}</span></span>"</span>
)
<span>service_tasks</span> <span>=</span> []
<span>for</span> <span>service</span> <span>in</span> <span>self</span>.<span>services</span>:
    <span># first launch the service</span>
    <span>service_tasks</span>.<span>append</span>(<span>asyncio</span>.<span>create_task</span>(<span>service</span>.<span>launch_server</span>()))

    <span># register the service to the message queue</span>
    <span>await</span> <span>service</span>.<span>register_to_message_queue</span>()

    <span># register the service to the control plane</span>
    <span>await</span> <span>service</span>.<span>register_to_control_plane</span>(<span>control_plane_url</span>)</pre></div>
<p dir="auto">With that done, you may want to define a consumer for the results of tasks.</p>
<p dir="auto">By default, the results of tasks get published to a <code>human</code> message queue.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from llama_agents import (
    CallableMessageConsumer,
    RemoteMessageConsumer,
    QueueMessage,
)


def handle_result(message: QueueMessage) -> None:
    print(message.data)


human_consumer = CallableMessageConsumer(
    handler=handle_result, message_type=&quot;human&quot;
)

message_queue.register_consumer(human_consumer)

# or, you can send the message to any URL
# human_consumer = RemoteMessageConsumer(url=&quot;some destination url&quot;)
# message_queue.register_consumer(human_consumer)"><pre><span>from</span> <span>llama_agents</span> <span>import</span> (
    <span>CallableMessageConsumer</span>,
    <span>RemoteMessageConsumer</span>,
    <span>QueueMessage</span>,
)


<span>def</span> <span>handle_result</span>(<span>message</span>: <span>QueueMessage</span>) <span>-&gt;</span> <span>None</span>:
    <span>print</span>(<span>message</span>.<span>data</span>)


<span>human_consumer</span> <span>=</span> <span>CallableMessageConsumer</span>(
    <span>handler</span><span>=</span><span>handle_result</span>, <span>message_type</span><span>=</span><span>"human"</span>
)

<span>message_queue</span>.<span>register_consumer</span>(<span>human_consumer</span>)

<span># or, you can send the message to any URL</span>
<span># human_consumer = RemoteMessageConsumer(url="some destination url")</span>
<span># message_queue.register_consumer(human_consumer)</span></pre></div>
<p dir="auto">Or, if you don't want to define a consumer, you can just use the <code>monitor</code> to observe your system results</p>
<div dir="auto" data-snippet-clipboard-copy-content="llama-agents monitor --control-plane-url http://127.0.0.1:8000"><pre>llama-agents monitor --control-plane-url http://127.0.0.1:8000</pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft informs customers that Russian hackers spied on emails (107 pts)]]></title>
            <link>https://www.reuters.com/technology/cybersecurity/microsoft-tells-clients-russian-hackers-viewed-emails-bloomberg-news-reports-2024-06-27/</link>
            <guid>40821994</guid>
            <pubDate>Fri, 28 Jun 2024 16:01:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/cybersecurity/microsoft-tells-clients-russian-hackers-viewed-emails-bloomberg-news-reports-2024-06-27/">https://www.reuters.com/technology/cybersecurity/microsoft-tells-clients-russian-hackers-viewed-emails-bloomberg-news-reports-2024-06-27/</a>, See on <a href="https://news.ycombinator.com/item?id=40821994">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/cybersecurity/microsoft-tells-clients-russian-hackers-viewed-emails-bloomberg-news-reports-2024-06-27/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Supreme Court overrules Chevron deference [pdf] (111 pts)]]></title>
            <link>https://www.supremecourt.gov/opinions/23pdf/22-451_7m58.pdf</link>
            <guid>40821007</guid>
            <pubDate>Fri, 28 Jun 2024 14:36:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.supremecourt.gov/opinions/23pdf/22-451_7m58.pdf">https://www.supremecourt.gov/opinions/23pdf/22-451_7m58.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=40821007">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Supreme Court overturns 40-year-old "Chevron deference" doctrine (668 pts)]]></title>
            <link>https://www.axios.com/2024/06/28/supreme-court-chevron-doctrine-ruling</link>
            <guid>40820949</guid>
            <pubDate>Fri, 28 Jun 2024 14:31:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.axios.com/2024/06/28/supreme-court-chevron-doctrine-ruling">https://www.axios.com/2024/06/28/supreme-court-chevron-doctrine-ruling</a>, See on <a href="https://news.ycombinator.com/item?id=40820949">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-cy="au-image" data-chromatic="ignore"><img data-cy="StoryImage" alt="The U.S. Supreme Court in April 2024." fetchpriority="high" width="1920" height="1080" decoding="async" data-nimg="1" sizes="100vw" srcset="https://images.axios.com/0HWtMwcrXgCb_5lFNMsNTUU6Yy8=/0x900:8640x5760/320x180/2024/05/16/1715879188297.jpg?w=320 320w, https://images.axios.com/0HWtMwcrXgCb_5lFNMsNTUU6Yy8=/0x900:8640x5760/320x180/2024/05/16/1715879188297.jpg?w=320 320w, https://images.axios.com/7ZxL6bKpkNxWL6ubjcOmQOyctKo=/0x900:8640x5760/640x360/2024/05/16/1715879188297.jpg?w=640 640w, https://images.axios.com/7ZxL6bKpkNxWL6ubjcOmQOyctKo=/0x900:8640x5760/640x360/2024/05/16/1715879188297.jpg?w=640 640w, https://images.axios.com/lSDvbXXvNLIXeF2xPC0G-oouy-c=/0x900:8640x5760/768x432/2024/05/16/1715879188297.jpg?w=768 768w, https://images.axios.com/lSDvbXXvNLIXeF2xPC0G-oouy-c=/0x900:8640x5760/768x432/2024/05/16/1715879188297.jpg?w=768 768w, https://images.axios.com/hXC9UdkVp4dGz5KhHQvsDxPQfXw=/0x900:8640x5760/1024x576/2024/05/16/1715879188297.jpg?w=1024 1024w, https://images.axios.com/hXC9UdkVp4dGz5KhHQvsDxPQfXw=/0x900:8640x5760/1024x576/2024/05/16/1715879188297.jpg?w=1024 1024w, https://images.axios.com/Fqe49_mapPRZ-bwhEVixaLwVxSg=/0x900:8640x5760/1366x768/2024/05/16/1715879188297.jpg?w=1366 1366w, https://images.axios.com/Fqe49_mapPRZ-bwhEVixaLwVxSg=/0x900:8640x5760/1366x768/2024/05/16/1715879188297.jpg?w=1366 1366w, https://images.axios.com/99g12vnypLK_H6s5a3GwwpWuoss=/0x900:8640x5760/1600x900/2024/05/16/1715879188297.jpg?w=1600 1600w, https://images.axios.com/99g12vnypLK_H6s5a3GwwpWuoss=/0x900:8640x5760/1600x900/2024/05/16/1715879188297.jpg?w=1600 1600w, https://images.axios.com/9RMqkLL-qeuwtkEPKrMjkj_KObk=/0x900:8640x5760/1920x1080/2024/05/16/1715879188297.jpg?w=1920 1920w, https://images.axios.com/9RMqkLL-qeuwtkEPKrMjkj_KObk=/0x900:8640x5760/1920x1080/2024/05/16/1715879188297.jpg?w=1920 1920w" src="https://images.axios.com/9RMqkLL-qeuwtkEPKrMjkj_KObk=/0x900:8640x5760/1920x1080/2024/05/16/1715879188297.jpg?w=1920"><figcaption><p>The U.S. Supreme Court in April 2024. Photo; Bill Clark/CQ-Roll Call, Inc via Getty Images</p></figcaption></div><div data-chromatic="ignore"><p><span data-schema="smart-brevity"><p>The <a data-vars-link-text="Supreme Court" data-vars-click-url="https://www.axios.com/2024/06/20/supreme-court-rulings-trump-abortion" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2024/06/20/supreme-court-rulings-trump-abortion" target="_self">Supreme Court</a> on Friday curtailed the executive branch's ability to interpret laws it's charged with implementing, giving the judiciary more say in what federal agencies can do.</p><p><strong>Why it matters:</strong> The<strong> </strong><a data-vars-link-text="landmark 6-3 ruling" data-vars-click-url="https://www.supremecourt.gov/opinions/23pdf/22-451_7m58.pdf" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.supremecourt.gov/opinions/23pdf/22-451_7m58.pdf" target="_blank">landmark 6-3 ruling</a> along ideological lines overturns<strong> </strong>the court's 40-year-old "Chevron deference" doctrine. It could make it harder for executive agencies to tackle<strong> </strong>a wide array of policy areas, including <a data-vars-link-text="environmental" data-vars-click-url="https://www.axios.com/2024/01/17/supreme-court-chevron-environment" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2024/01/17/supreme-court-chevron-environment" target="_self">environmental</a> and <a data-vars-link-text="health" data-vars-click-url="https://www.axios.com/2024/01/17/supreme-court-chevron-deference-medicare-medicaid" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2024/01/17/supreme-court-chevron-deference-medicare-medicaid" target="_self">health</a> regulations and <a data-vars-link-text="labor and employment laws" data-vars-click-url="https://www.bloomberglaw.com/external/document/X1N1TE8K000000/labor-relations-professional-perspective-apres-moi-le-deluge-big" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.bloomberglaw.com/external/document/X1N1TE8K000000/labor-relations-professional-perspective-apres-moi-le-deluge-big" target="_blank">labor and employment laws</a>.</p></span></p><p><strong>Driving the news:</strong> Chief Justice John Roberts, writing the opinion of the court, argued Chevron "defies the command of" the Administrative Procedure Act, which governs federal administrative agencies.</p><ul><li>He said it "requires a court to ignore, not follow, 'the reading the court would have reached had it exercised its independent judgment as required by the APA.'"</li><li>Further, he said it "is misguided" because "agencies have no special competence in resolving statutory ambiguities. Courts do."</li></ul><p><strong>Roberts noted </strong>the court's decision did not call into question prior cases that relied on Chevron, including holdings pertaining to the Clean Air Act, because they "are still subject to statutory stare decisis despite our change in interpretive methodology."</p><ul><li>"Mere reliance on Chevron cannot constitute a 'special justification' for overruling such a holding," he said.</li></ul><p><strong>Justice Elena Kagan,</strong> in a dissenting opinion, wrote that the ruling Friday was "yet another example of the Court's resolve to roll back agency authority, despite congressional direction to the contrary."</p><ul><li>"Congress knows that it does not — in fact cannot — write perfectly complete regulatory statutes," she wrote. "It knows that those statutes will inevitably contain ambiguities that some other actor will have to resolve, and gaps that some other actor will have to fill. And it would usually prefer that actor to be the responsible agency, not a court.<strong>"</strong></li><li>She warned the decision "is likely to produce large-scale disruption." </li><li>"In one fell swoop, the majority today gives itself exclusive power over every open issue — no matter how expertise-driven or policy-laden — involving the meaning of regulatory law."</li><li>"The majority disdains restraint, and grasps for power."</li></ul><p><strong>Context: </strong>The ruling <a data-vars-link-text="marks another major victory" data-vars-click-url="https://www.axios.com/2023/05/25/supreme-court-epa-wetlands-clean-water-act" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2023/05/25/supreme-court-epa-wetlands-clean-water-act" target="_self">marks another major victory</a> for conservatives, who for decades have sought to limit the federal government's ability to regulate businesses.</p><ul><li>In the wake of the court's ruling, it's expected that more federal rules will be challenged in the courts and judges will have greater discretion to invalidate agency actions.</li><li>The decision comes one day after the Supreme Court <a data-vars-link-text="curtailed federal agencies' use of administrative law judges" data-vars-click-url="https://www.axios.com/2024/06/27/scotus-sec-jarkesy-decision" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2024/06/27/scotus-sec-jarkesy-decision" target="_self">curtailed federal agencies' use of administrative law judges</a> in another blow to the administrative state.</li></ul><p><strong>How it works:</strong> <a data-vars-link-text="The doctrine" data-vars-click-url="https://sgp.fas.org/crs/misc/R44954.pdf" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://sgp.fas.org/crs/misc/R44954.pdf" target="_blank">The doctrine</a> was created by the Reagan-era Supreme Court in Chevron U.S.A. v. Natural Resources Defense Council in 1984 and has since become <a data-vars-link-text="the most cited" data-vars-click-url="https://www.yalejreg.com/nc/most-cited-supreme-court-administrative-law-decisions-by-chris-walker/" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.yalejreg.com/nc/most-cited-supreme-court-administrative-law-decisions-by-chris-walker/" target="_blank">the most cited</a> Supreme Court decision in administrative law.</p><ul><li>Under Chevron deference, courts would defer to how to expert federal agencies interpret the laws they are charged with implementing provided their reading is reasonable — even if it's not the only way the law can be interpreted.</li><li>It allowed Congress to rely on the expertise within the federal government when implementing everything from health and safety regulations to environmental and financial laws.</li></ul><p><strong>Zoom in: </strong>However, Chevron was challenged in two separate cases over a National Marine Fisheries Service regulation meant to prevent overfishing on commercial fishing vessels.</p><ul><li>Fishing companies challenging the regulation claimed the doctrine violated Article III of the Constitution by shifting the authority to interpret federal law from the courts to the executive branch.</li><li> They also claimed it violated Article I by allowing agencies to formulate policy when only Congress should have lawmaking power.</li></ul><p><strong>The other side:</strong> The government argued that the doctrine had  safeguards within it that prevented agencies from usurping Congress's lawmaking authority.</p><ul><li>It noted that Chevron only applied to ambiguous text in laws passed by Congress and instances in which lawmakers had given interpretive authority to an agency.</li><li>The doctrine was also necessary to limit federal judges' abilities to make public policy when they may not have the expertise to do so and aren't subject to democratic accountability, the government said.</li></ul><p><strong>Between the lines: </strong>Lawyers who worked pro bono to represent fishing companies involved in the cases are also staff attorneys for Americans for Prosperity, a libertarian political advocacy group funded by billionaire Charles Koch, the <a data-vars-link-text="New York Times" data-vars-click-url="https://www.nytimes.com/2024/01/16/climate/koch-chevron-deference-supreme-court.html" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.nytimes.com/2024/01/16/climate/koch-chevron-deference-supreme-court.html" target="_blank">New York Times</a> reported earlier this year.</p><ul><li>The political network associated with Charles Koch and his late brother, David Koch, have long championed efforts to get cases before the Supreme Court that, if decided in their favor, would roll back the federal government's regulatory powers.</li><li>The Koch network also successfully attracted Supreme Court Justice Clarence Thomas, who voted against the doctrine, to speak at at least one of its <a data-vars-link-text="donor events" data-vars-click-url="https://www.axios.com/2023/09/22/clarence-thomas-koch-brothers-donor-events" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2023/09/22/clarence-thomas-koch-brothers-donor-events" target="_self">donor events</a> in 2018, <a data-vars-link-text="ProPublica" data-vars-click-url="https://www.propublica.org/article/clarence-thomas-secretly-attended-koch-brothers-donor-events-scotus" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.propublica.org/article/clarence-thomas-secretly-attended-koch-brothers-donor-events-scotus" target="_blank">ProPublica</a> reported last year.</li><li>It's unclear who purchased Thomas' flight to the 2018 event, as he never  reported it in his annual financial disclosure form. Thomas has attended at least two of such events in past years.</li></ul><p><strong>The big picture: </strong>In recent years, Chevron had fallen out of favor of the <a data-vars-link-text="conservative-majority Supreme Court" data-vars-click-url="https://crsreports.congress.gov/product/pdf/LSB/LSB11061" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://crsreports.congress.gov/product/pdf/LSB/LSB11061" target="_blank">conservative-majority Supreme Court</a>, which had declined to apply it or cite it in cases which it may once have applied.</p><ul><li>The ruling comes as some federal judges have taken a more active role in overruling agency expertise.</li><li>For example, Texas District Judge Matthew Kacsmaryk last April <a data-vars-link-text="paused" data-vars-click-url="https://www.axios.com/2024/03/23/abortion-pill-access-supreme-court-mifepristone-fda" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2024/03/23/abortion-pill-access-supreme-court-mifepristone-fda" target="_self">paused</a> the FDA's original 23-year-old approval of the abortion pill mifepristone in a case that's now to be decided by the Supreme Court.</li></ul><p><strong>Go deeper: </strong><a data-vars-link-text="Supreme Court brushes off payday lenders' challenge to consumer watchdog's funding" data-vars-click-url="https://www.axios.com/2024/05/16/supreme-court-cfpb-funding" data-vars-content-id="319f7ddc-f588-4484-955d-818b37e93d50" data-vars-headline="Supreme Court guts agency power in seismic Chevron ruling" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2024/05/16/supreme-court-cfpb-funding" target="_self">Supreme Court brushes off payday lenders' challenge to consumer watchdog's funding</a></p><p><em>Editor's note: This story was updated with details from the court's ruling.</em></p></div></div>]]></description>
        </item>
    </channel>
</rss>