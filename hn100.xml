<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 20 May 2024 03:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The Lunacy of Artemis (127 pts)]]></title>
            <link>https://idlewords.com/2024/5/the_lunacy_of_artemis.htm</link>
            <guid>40410404</guid>
            <pubDate>Sun, 19 May 2024 23:02:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://idlewords.com/2024/5/the_lunacy_of_artemis.htm">https://idlewords.com/2024/5/the_lunacy_of_artemis.htm</a>, See on <a href="https://news.ycombinator.com/item?id=40410404">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><b>1.1.<a href="https://idlewords.com/2020/">2023</a></b></p><p><a href="https://idlewords.com/2024/5/the_lunacy_of_artemis.htm">The Lunacy of Artemis</a></p>
   
   


<p><img src="https://idlewords.com/images/artemis_cloud.jpg" width="100%" alt="distant photo of Artemis rocket on launch pad"></p>


<p>A little over 51 years ago, a rocket lifted off from Cape Canaveral carrying three astronauts and a space car.  After a three day journey to the moon, two of the astronauts climbed into a spindly lander and made the short trip down to the surface, where for another three days they collected rocks and did donuts in the space car. Then they climbed back into the lander,  rejoined their colleague in orbit, and departed for Earth. Their capsule splashed down in the South Pacific on December 19, 1972.  This mission, Apollo 17, would be the last time human beings ventured beyond low Earth orbit. 

</p><p>If you believe NASA, late in 2026 Americans will walk on the moon again. That proposed mission is called Artemis 3, and its lunar segment looks a lot like Apollo 17 without the space car. Two astronauts will land on the moon, collect rocks, take selfies, and about a week after landing rejoin their orbiting colleagues to go back to Earth. 

</p><p>But where Apollo 17 launched on a single rocket and cost $3.3 billion (in 2023 dollars), the first Artemis landing involves a dozen or two heavy rocket launches and costs so much that NASA refuses to give a figure (one veteran of NASA budgeting estimates it at $7-10 billion).<a id="fn_cost"></a><a href="#cost"><span><sup>[1]</sup></span></a>  The single-use lander for the mission will be the heaviest spacecraft ever flown, and yet the mission's scientific return—a small box of rocks—is less than what came home on Apollo 17. And the whole plan hinges on technologies that haven't been invented yet becoming reliable and practical within the next eighteen months. 

</p><p>You don’t have to be a rocket scientist to wonder what’s going on here. If we can put a man on the moon,  then why can't we just go do it again?  The moon hasn’t changed since the 1960’s, while every technology we used to get there  has seen staggering advances.  It took NASA eight years to go from nothing to a moon landing at the dawn of the Space Age. But today, twenty years and $93 billion after the space agency announced our return to the moon, the goal seems as far out of reach as ever.<a id="fn_nasatime"></a><a href="#nasatime"><span><sup>[2]</sup></span></a> 

</p><p>Articles about Artemis often give the program’s tangled backstory.   But I want to talk about Artemis as a technical design, because there’s just so much to drink in. While NASA is no stranger to complex mission architectures, Artemis goes beyond complex to the just plain incoherent. None of the puzzle pieces seem to come from the  same box. Half the program requires breakthrough technologies that make the other half unnecessary.  The rocket and spacecraft NASA spent two decades building can’t even reach the moon.  And for reasons no one understands, there’s a new space station in the mix.

</p><p>In the past, whatever oddball project NASA came up with, we at least knew they could build the hardware. But Artemis calls the agency’s competence as an engineering organization into question.  For the first time since the early 1960's, it's unclear whether the US space agency is even <i>capable</i> of putting astronauts on the Moon. 

<br>



</p><p><img src="https://idlewords.com/images/apollo_flight_path.jpg" width="100%" alt="Photograph of SLS rocket"></p>

<p><b><a name="apollo">A Note on Apollo</a></b></p> 


<p>In this essay I make a lot of comparisons to Project Apollo. This is not because I think other mission architectures are inferior, but because the early success of that program sets such a useful baseline.  At the dawn of the Space Age, using rudimentary technology, American astronauts landed on the moon six times in seven attempts.  The moon landings were NASA’s greatest achievement and should set a floor for what a modern mission, flying modern hardware, might achieve.

</p><p>Advocates for Artemis insist that the program is more than Apollo 2.0. But as we’ll see, Artemis can't even measure up to Apollo 1.0. It costs more, does less, flies less frequently, and exposes crews to risks that the steely-eyed missile men of the Apollo era found unacceptable.   It's as if Ford in 2024 released a new model car that was slower,  more accident-prone, and ten times more expensive than the Model T.  

</p><p>When a next-generation lunar program can’t meet the cost, performance, or safety standards set three generations earlier, something has gone seriously awry. 

<br>



</p><p><img src="https://idlewords.com/images/sls_image.jpg" width="100%" alt="Photograph of SLS rocket"></p>

<p><a name="sls"><b>I. The Rocket</b></a></p> 

<p>The jewel of Artemis is a big orange rocket with a flavorless name, the Space Launch System (SLS).  SLS looks like someone started building a Space Shuttle and ran out of legos for the orbiter. There is the familiar orange tank, a big white pair of solid rocket boosters, but then the rocket just peters out in a 1960’s style stack of cones and cylinders. 

</p><p>The best way to think of SLS is as a balding guy with a mullet: there are fireworks down below that are meant to distract you from a sad situation up top.  In the case of the rocket, those fireworks are a first stage with more thrust than the Saturn V, enough thrust that the boosted core stage can nearly put itself into orbit.  But on top of this monster sits a second stage so anemic that even its name (the Interim Cryogenic Propulsion Stage) is a kind of apology. For eight minutes SLS roars into the sky on a pillar of fire.  And then, like a cork popping out of a bottle, the tiny ICPS emerges and drifts vaguely moonwards on a wisp of flame. 

</p><p>With this design, the minds behind SLS achieved a first in space flight, creating a rocket that is at the same time more powerful and less capable than the Saturn V.  While the 1960’s giant could send 49 metric tons to the Moon,  SLS only manages 27 tons—not enough to fly an Apollo-style landing, not enough to even put a crew in orbit around the Moon without a lander. The best SLS can do is slingshot the Orion spacecraft once around the moon and back, a mission that will fly under the name Artemis 2.  

</p><p>NASA wants to replace ICPS with an ‘Exploration Upper Stage’  (the project has been held up, among other things, by a <a href="https://oig.nasa.gov/wp-content/uploads/2024/02/IG-22-012.pdf">near-billion dollar cost overrun on a launch pad</a>). But even that upgrade won’t give SLS the power of the Saturn V.  For whatever reason, NASA designed its first heavy launcher in forty years to be unable to fly the simple, proven architecture of the Apollo missions.

</p><p>Of course, plenty of rockets go on to enjoy rewarding, productive careers without being as powerful as the Saturn V.   And if SLS rockets were piling up at the Michoud Assembly Facility like cordwood, or if NASA were willing to let its astronauts fly commercial, it would be a simple matter to split Artemis missions across multiple launches. 

</p><p>But NASA insists that astronauts fly SLS. And SLS is a “one and done” rocket, artisanally hand-crafted by a workforce that likes to get home before traffic gets bad. The rocket can only launch once every two years at a cost of about four billion dollars<a id="fn_slscost"></a><a href="#slscost"><span><sup>[3]</sup></span></a>—about twice what it would cost to light the rocket’s weight in dollar bills on fire<a id="fn_dollarbills"></a><a href="#dollarbills"><span><sup>[4]</sup></span></a>. 

</p><p>Early on, SLS designers made the catastrophic decision to reuse Shuttle hardware, which is like using Fabergé eggs to save money on an omelette.  The SLS core stage recycles Space Shuttle main engines, actual veterans of old Shuttle flights called out of retirement for one last job.  Refurbishing a single such engine to work on SLS costs NASA $40 million, or a bit more than SpaceX spends on all 33 engines on its Superheavy booster.<a id="fn_refurb"></a><a href="#refurb"><span><sup>[5]</sup></span></a> And though the Shuttle engines are designed to be fully reusable (the main reason they're so expensive), every SLS launch throws four of them away. Once all the junkyards are picked clean, NASA will pay Aerojet Rocketdyne to restart production of the classic engine at a cool unit cost of $145 million<a id="fn_rs25restart"></a><a href="#rs25restart"><span><sup>[6]</sup></span></a>. 

</p><p>The story is no better with the solid rocket boosters, the other piece of Shuttle hardware SLS reuses.  Originally a stopgap measure introduced to save the Shuttle budget, these heavy rockets now attach themselves like barnacles to every new NASA launcher design. To no one’s surprise, retrofitting a bunch of heavy steel casings left over from Shuttle days has saved the program nothing. Each SLS booster is now projected to cost $266 million, or about twice the launch cost of a Falcon Heavy.<a id="fn_fheavy"></a><a href="#fheavy"><span><sup>[7]</sup></span></a>  Just replacing the asbestos lining in the boosters with a greener material, a project budgeted at $4.4M, has now cost NASA a quarter of a billion dollars.  And once the leftover segments run out seven rockets from now,  SLS will need a brand new booster design, opening up fertile new vistas of overspending. 

</p><p>Costs on SLS have reached the point where private industry is now able to develop, test, and launch an entire rocket <i>program</i> for less than NASA spends on a single engine<a id="fn_electron"></a><a href="#electron"><span><sup>[8]</sup></span></a>.  Flying SLS is like owning a classic car—everything is hand built, the components cost a fortune, and when you finally get the thing out of the shop, you find yourself constantly overtaken by younger rivals. 

</p><p>But the cost of SLS to NASA goes beyond money.   The agency has committed to an antiquated frankenrocket just as the space industry is entering a period of unprecedented innovation. While other space programs get to romp and play with technologies like reusable stages and exotic alloys, NASA is stuck for years wasting a massive, skilled workforce on a dead-end design. 

</p><p>The SLS program's slow pace also affects safety. Back in the Shuttle era, NASA managers argued that it took three to four launches a year to keep workers proficient enough to build and launch the vehicles safely.  A boutique approach where workers hand-craft one rocket every two years  means having to re-learn processes and procedures with every launch.

</p><p>It also leaves no room in Artemis for test flights. The program simply assumes success, flying all its important 'firsts' with astronauts on board. When there are unanticipated failures, like the extensive heat shield spalling and near burn-through observed in Artemis 1,<a id="fn_heatshield"></a><a href="#heatshield"><span><sup>[9]</sup></span></a> the agency has no way to test a proposed fix without a multi-year delay to the program. So they end up using indirect means to convince themselves that a new design is safe to fly, a process ripe for error and self-delusion.




</p><p><img src="https://idlewords.com/images/orion_oversize.jpg" width="100%" alt="Orion space capsule with OVERSIZE LOAD banner"></p>

<p><b><a name="Orion">II. The Spacecraft</a></b></p> 


<p>Orion, the capsule that launches on top of SLS, is a relaxed-fit reimagining of the Apollo command module suitable for today’s larger astronaut. It boasts modern computers, half again as much volume as the 1960’s design, and a few creature comforts (like not having to poop in a baggie) that would have pleased the Apollo pioneers.

</p><p>The capsule’s official name is the Orion Multipurpose Crew Vehicle, but finding even a single purpose for Orion has greatly challenged NASA.  For twenty years the spacecraft has mostly sat on the ground, chewing through a $1.2 billion annual budget. In 2014, the first Orion flew a brief test flight. Eight short years later, Orion launched again, carrying a crew of instrumented mannequins around the Moon on Artemis 1.  In 2025 the capsule (by then old enough to drink) is supposed to fly  human passengers on Artemis 2. 

</p><p>Orion goes to space attached to a basket of amenities called the European Service Module. The ESM provides Orion with solar panels, breathing gas, batteries, and a small rocket that is the capsule’s principal means of propulsion. But because the ESM was never designed to go to the moon, it carries very little propellant—far too little to get the hefty capsule in and out of lunar orbit.<a id="fn_oriondeltav"></a><a href="#oriondeltav"><span><sup>[10]</sup></span></a>   

</p><p>And Orion is hefty. Originally designed to hold six astronauts, the capsule was never resized when the crew requirement shrank to four.  Like an empty nester’s minivan, Orion now hauls around a bunch of mass and volume that it doesn’t need. Even with all the savings that come from replacing Apollo-era avionics, the capsule weighs almost twice as much as the Apollo Command Module. 

</p><p>This extra mass has knock-on effects across the entire Artemis design. Since a large capsule needs a large abort rocket, SLS has to haul Orion's massive Launch Abort System—seven tons of dead weight—nearly all the way into orbit. And reinforcing the capsule so that abort system won't shake the astronauts into jelly means making it heavier, which puts more demand on the parachutes and heat shield,<a id="fn_heatshield"></a><a href="#heatshield"><span><sup>[11]</sup></span></a> and around and around we go. 

</p><p><img src="https://idlewords.com/images/csm_orion_esm.jpg" width="100%" alt="Orion space capsule with OVERSIZE LOAD banner"></p>

<p>Size comparison of the Apollo command and service module (left) and Orion + European Service Module (right)</p>

<div><p>What’s particularly frustrating is that Orion and ESM together have nearly the same mass as the Apollo command and service modules, which had no trouble reaching the Moon.  The difference is all in the proportions. Where Apollo was built like a roadster, with a small crew compartment bolted onto an oversized engine, Orion is the Dodge Journey of spacecraft—a chunky, underpowered six-seater that advertises to the world that you're terrible at managing money.

</p></div><p><img src="https://idlewords.com/images/nrho.jpg" width="100%" alt="diagram of near-rectilinear halo orbit"></p>

<p><b><a name="orbit">III. The Orbit</a></b></p> 

<p>The fact that neither its rocket or spaceship can get to the Moon creates difficulties for NASA’s lunar program.  So, like an aging crooner transposing old hits into an easier key, the agency has worked to find a ‘lunar-adjacent’ destination that its hardware can get to.

</p><p>Their solution is a bit of celestial arcana called Near Rectilinear Halo Orbit, or NRHO.  A spacecraft in this orbit circles the moon every 6.5 days, passing 1,000 kilometers above the lunar north pole at closest approach, then drifting out about 70,000 kilometers (a fifth of the Earth/Moon distance) at its furthest point.  Getting to NRHO from Earth requires significantly less energy than entering a  useful lunar orbit, putting it just within reach for SLS and Orion.<a id="fn_nrho"></a><a href="#nrho"><span><sup>[12]</sup></span></a>


</p><p>To hear NASA tell it, NRHO is so full of advantages that it’s a wonder we stay on Earth.  Spacecraft in the orbit always have a sightline to Earth and never pass through its shadow. The orbit is relatively stable, so a spacecraft can loiter there for months using only ion thrusters. And the deep space environment is the perfect place to practice going to Mars. 

</p><p>But NRHO is terrible for getting to the moon. The orbit is like one of those European budget airports that leaves you out in a field somewhere, requiring an expensive taxi.  In Artemis, this taxi takes the form of a whole other spaceship—the lunar lander—which launches without a crew a month or two before Orion and is supposed to be waiting in NRHO when the capsule arrives. 

 </p><p>Once these two spacecraft dock together, two astronauts climb into the lander from Orion and begin a day-long descent to the lunar surface. The other two astronauts wait for them in NRHO, playing hearts and quietly absorbing radiation.

</p><p>Apollo landings also divided the crew between lander and orbiter. But those missions kept the command module in a low lunar orbit that brought it over the landing site every two hours.  This proximity between orbiter and lander had enormous implications for safety. At any point in the surface mission, the astronauts on the moon could climb into the ascent rocket, hit the big red button, and be back sipping Tang with the command module pilot by bedtime.  The short orbital period also gave the combined crew a dozen opportunities a day to return directly to Earth. <a id="fn_abort"></a><a href="#abort"><span><sup>[13]</sup></span></a>

</p><p>Sitting in NRHO makes abort scenarios much harder. Depending on when in the mission it happens, a stricken lander might need three or more days to catch up with the orbiting Orion. In the worst case, the crew might find themselves stuck on the lunar surface for hours after an abort is called, forced to wait for Orion to reach a more favorable point in its orbit. And once everyone is back on Orion, more days might pass before the crew can depart for Earth. These long and variable abort times significantly increase risk to the crew, making many scenarios that were survivable on Apollo (like Apollo 13!) lethal on Artemis. <a id="fn_abortnrho"></a><a href="#abortnrho"><span><sup>[14]</sup></span></a>

</p><p>The abort issue is just one example of  NRHO making missions slower.  NASA likes to boast that Orion can stay in space far longer than Apollo, but this is like bragging that you’re in the best shape of your life after the bank repossessed your car.  It's an oddly positive spin to put on bad life choices. The reason Orion needs all that endurance is because transit times from Earth to NRHO are long, and the crew has to waste additional time in NRHO waiting for orbits to line up.  The Artemis 3 mission, for example, will spend 24 days in transit, compared to just 6 days on Apollo 11. 

</p><p>NRHO even dictates how long astronauts stay on the Moon—surface time has to be a multiple of the 6.5 day orbital period. This lack of flexibility means that even early flag-and-footprints missions like Artemis 3 have to spend at least a week on the moon, a constraint that adds considerable risk to the initial landing.  <a id="fn_landingrisk"></a><a href="#landingrisk"><span><sup>[15]</sup></span></a>

</p><p>In spaceflight, brevity is safety. There's no better way to protect astronauts  from the risks of solar storms, mechanical failure, and other mishaps than by minimizing slack time in space. Moreover, a safe architecture should allow for a rapid return to Earth at any point in the mission.   There’s no question astronauts on the first Artemis missions would be better off with Orion in low lunar orbit. The decision to stage from NRHO is an excellent example of NASA designing its lunar program in the wrong direction—letting deficiencies in the hardware dictate the level of mission risk. 

￼




</p><p><img src="https://idlewords.com/images/gateway_diagram.jpg" width="100%" alt="diagram of Gateway"></p>
<p>Early diagram of Gateway. Note that the segment marked 'human lander system' now dwarfs the space station.</p>

<p><b><a name="gateway">IV. Gateway</a></b></p> 

<p>I suppose at some point we have to talk about Gateway.  Gateway is a small modular space station that NASA wants to build in NRHO.  It has been showing up across various missions like a bad smell since before 2012.  

</p><p>Early in the Artemis program, NASA described Gateway as a kind of celestial truck stop, a safe place for the lander to park and for the crew to grab a cup of coffee on their way to the moon.  But when it became clear that Gateway would not be ready in time for Artemis 3, NASA re-evaluated.  Reasoning that two spacecraft could meet up in NRHO just as easily as three, the agency gave permission for the first moon landing to proceed without a space station.

</p><p>Despite this open admission that Gateway is unnecessary, building the space station remains the core activity of the Artemis program. The three missions that follow that first landing are devoted chiefly to Gateway assembly.  In fact, initial plans for Artemis 4 left out a lunar landing entirely, as if it were an inconvenience to the real work being done up in orbit.

</p><p>This is a remarkable situation. It’s like if you hired someone to redo your kitchen and they started building a boat in your driveway. Sure, the boat gives the builders a place to relax, lets them practice tricky plumbing and finishing work, and is a safe place to store their tools. But all those arguments will fail to satisfy. You still want to know what building a boat has to do with kitchen repair, and why you’re the one footing the bill. 

</p><p>NASA has struggled to lay out a technical rationale for Gateway. The space station adds both cost and complexity to Artemis, a program not particularly lacking in either.  Requiring moon-bound astronauts to stop at Gateway also makes missions riskier (by adding docking operations) while imposing a big propellant tax. Aerospace engineer and pundit Robert Zubrin has aptly called the station a tollbooth in space.  

</p><p>Even Gateway defenders struggle to hype up the station. A common argument is that Gateway may not ideal for any one thing, but is good for a whole lot of things. But that is the same line of thinking that got us SLS and Orion, both vehicles designed before anyone knew what to do with them. The truth is that all-purpose designs don't exist in human space flight. The best you can do is build a spacecraft that is equally bad at everything. 
 
</p><p>But to search for technical grounds is to misunderstand the purpose of Gateway.  The station is not being built to shelter astronauts in the harsh environment of space, but to protect Artemis in the harsh environment of Congress. NASA needs Gateway to navigate an uncertain political landscape in the 2030’s. Without a station, Artemis will just be a series of infrequent multibillion dollar moon landings, a red cape waved in the face of the Office of Management and Budget.  Gateway armors Artemis by bringing in international partners, each of whom contributes expensive hardware. As NASA learned building the International Space Station, this combination of sunk costs and international entanglement is a powerful talisman against program death.   

</p><p>Gateway also solves some other problems for NASA.  It gives SLS a destination to fly to, stimulates private industry (by handing out public money to supply Gateway), creates a job for the astronaut corps, and guarantees the continuity of human space flight once the ISS becomes uninhabitable sometime in the 2030’s. <a id="fn_iss"></a><a href="#iss"><span><sup>[16]</sup></span></a>


</p><p>That last goal may sound odd if you don’t see human space flight as an end in itself.  But NASA is a faith-based organization, dedicated to the principle that taxpayers should always keep an American or two in orbit.  it’s a little bit as if the National Oceanic Atmospheric Administration insisted on keeping bathyscapes full of sailors at the bottom of the sea, irrespective of cost or merit, and kneecapped programs that might threaten the continuous human benthic presence. You can’t argue with faith.

</p><p>From a bureaucrat’s perspective, Gateway is NASA’s ticket back to a golden era in the early 2000's when the Space Station and Space Shuttle formed an uncancellable whole, each program justifying the existence of the other.  Recreating this dynamic with Gateway and SLS/Orion would mean predictable budgets and program stability for NASA well into the 2050’s.  

</p><p>But Artemis was supposed to take us back to a different golden age, the golden age of Apollo.  And so there’s an unresolved tension in the program between building Gateway and  doing interesting things on the moon. With Artemis missions two or more years apart, it’s inevitable that Gateway assembly will push aspirational projects like a surface habitat or pressurized rover out into the 2040’s. But those same projects are on the critical path to Mars, where NASA still insists we’re going in the late 2030’s. The situation is awkward.

</p><p>So that is the story of Gateway—unloved, ineradicable, and as we’ll see, likely to become the sole legacy of the Artemis program.


￼


</p><p><img src="https://idlewords.com/images/pointy_rocket.jpg" width="100%" alt="artist's rendering of human landing system'"></p>

<p><b><a name="lander">V. The Lander</a></b></p> 

<p>The lunar lander is the most technically ambitious part of Artemis.  Where SLS, Orion, and Gateway are mostly a compilation of NASA's greatest hits, the lander requires breakthrough technologies with the potential to revolutionize space travel. 

</p><p>Of course, you can’t just call it a lander.  In Artemis speak, this spacecraft is the Human Landing System, or HLS. NASA has delegated its design to two private companies, Blue Origin and SpaceX.  SpaceX is responsible for landing astronauts on Artemis 3 and 4, while Blue Origin is on the hook for Artemis 5 (notionally scheduled for 2030).  After that, the agency will take competitive bids for subsequent missions. 

</p><p>The SpaceX HLS design is based on their experimental Starship spacecraft, an enormous rocket that takes off on and lands on its tail, like 1950’s sci-fi.   There is a strong “emperor’s new clothes” vibe to this design.  On the one hand, it is the brainchild of brilliant SpaceX engineers and passed NASA technical review. On the other hand, the lander seems to go out of its way to create problems for itself to solve with technology. 

</p><p><img src="https://idlewords.com/images/hls_lem.jpg" width="100%" alt="artist's rendering of human landing system'"></p>
<p>An early SpaceX rendering of the Human Landing System, with the Apollo Lunar Module added for scale.</p> 


<p>To start with the obvious, HLS looks more likely to tip over than the last two spacecraft to land on the moon, which <a href="https://www.space.com/intuitive-machines-odysseus-moon-lander-tipped-over">tipped</a> <a href="https://www.cbsnews.com/news/japanese-moon-lander-reaches-surface-but-fate-uncertain/">over</a>.   It is a fifteen story tower that must land on its ass in terrible lighting conditions, on rubble of unknown composition, over a light-second from Earth.  The crew are left suspended so high above the surface that they need a folding space elevator (not the cool kind) to get down.  And yet in the end this single-use lander carries less payload (both up and down) than the tiny Lunar Module on Apollo 17. Using Starship to land two astronauts on the moon is like delivering a pizza with an aircraft carrier. 

</p><p>Amusingly, the sheer size of the SpaceX design leaves it with little room for cargo.  The spacecraft arrives on the Moon laden with something like 200 tons of cryogenic propellant,<a id="fn_hlsprop"></a><a href="#hlsprop"><span><sup>[14]</sup></span></a> and like a fat man leaving an armchair, it needs every drop of that energy to get its bulk back off the surface.  Nor does it help matters that all this cryogenic propellant has to cook for a week in direct sunlight.

</p><p>Other, less daring lander designs reduce their appetite for propellant by using a detachable landing stage. This arrangement also shields the ascent rocket from hypervelocity debris that gets kicked up during landing.  But HLS is a one-piece rocket; the same engines that get sandblasted on their way down to the moon must relight without fail a week later. 

 </p><p>Given this fact, it’s remarkable that NASA’s contract with SpaceX doesn’t require them to demonstrate a lunar takeoff. All SpaceX has to do to satisfy NASA requirements is land an HLS prototype on the Moon.  Questions about ascent can then presumably wait until the actual mission, when we all find out together with the crew whether HLS can take off again.<a id="fn_ascent"></a><a href="#ascent"><span><sup>[15]</sup></span></a>

</p><p>This fearlessness in design is part of a pattern with Starship HLS.  Problems that other landers avoid in the design phase are solved with engineering.  And it’s kind of understandable why SpaceX does it this way. Starship is meant to fly to Mars, a much bigger challenge than landing two people on the Moon. If the basic Starship design can’t handle a lunar landing, it would throw the company’s whole Mars plan into question. SpaceX is committed to making Starship work, which is different from making the best possible lunar lander.

</p><p>Less obvious is why NASA tolerates all this complexity in the most hazardous phase of its first moon mission. Why land a rocket the size of a building packed with moving parts?  It’s hard to look at the HLS design and not think back to other times when a room full of smart NASA people talked themselves into taking major risks because the alternative was not getting to fly at all. 

</p><p>It’s instructive to compare the HLS approach to the design philosophy on Apollo. Engineers on that progam were motivated by terror; no one wanted to make the mistake that would leave astronauts stranded on the moon.  The weapon they used to knock down risk was simplicity. The Lunar Module was a small metal box with a wide stance, built low enough so that the astronauts only needed to climb down a short ladder. The bottom half of the LM was a descent stage that completely covered the ascent rocket (a design that showed its value on Apollo 15, when one of the descent engines got <a href="https://en.wikipedia.org/wiki/Descent_propulsion_system#/media/File:Apollo_15_Engine_Bell.jpg">smushed by a rock</a>).   And that ascent rocket, the most important piece of hardware in the lander, was a caveman design intentionally made so primitive that it  would struggle to find ways to fail.  

</p><p>On Artemis, it's the other way around: the more hazardous the mission phase, the more complex the hardware. It's hard to look at all this lunar machinery and feel reassured, especially when NASA's own Aerospace Safety Advisory Panel estimates that the Orion/SLS portion of a moon mission alone (not including anything to do with HLS) already <a href="https://oiir.hq.nasa.gov/asap/documents/2014_ASAP_Annual_Report.pdf">has a 1:75 chance</a> of killing the crew. 



</p><p><img src="https://idlewords.com/images/fuel_fight.jpg" width="100%" alt="artist's rendering of human landing system'"></p>

<p><b><a name="refueling">VI. Refueling</a></b></p> 



<p>Since NASA’s biggest rocket struggles to get Orion into distant lunar orbit, and HLS weighs fifty times as much as Orion, the curious reader might wonder how the unmanned lander is supposed to get up there.

</p><p>NASA’s answer is, very sensibly, “not our problem”. They are paying Blue Origin and SpaceX the big bucks to figure this out on their own. And as a practical matter, the only way to put such a massive spacecraft into NRHO is to first refuel it in low Earth orbit. 

</p><p>Like a lot of space technology, orbital refueling sounds simple, has never been attempted, and can’t be adequately simulated on Earth.<a id="fn_refuel"></a><a href="#refuel"><span><sup>[18]</sup></span></a>  The crux of the problem is that liquid and gas phases in microgravity jumble up into a three-dimensional mess, so that even measuring the quantity of propellant in a tank becomes difficult.  To make matters harder, Starship uses cryogenic propellants that boil at temperatures about a hundred degrees colder than the plumbing they need to move through.  Imagine trying to pour water from a thermos into a red-hot skillet while falling off a cliff and you get some idea of the difficulties. 

</p><p>To get refueling working, SpaceX will first have to demonstrate propellant transfer between rockets as a proof of concept, and then get the process working reliably and efficiently at a scale of hundreds of tons. (These are two distinct challenges).  Once they can routinely move liquid oxygen and methane from Starship A to Starship B, they’ll be ready to set up the infrastructure they need to launch HLS. 


</p><p><img src="https://idlewords.com/images/fueling_conops.jpg" width="100%" alt="artist's rendering of human landing system'"></p>

<p>The plan for getting HLS to the moon looks like this: a few months before the landing date, SpaceX will launch a special variant of their Starship rocket configured to serve as a propellant depot. Then they'll start launching Starships one by one to fill it up. Each Starship arrives in low Earth orbit with some residual propellant; it will need to dock with the depot rocket and transfer over this remnant fuel.   Once the depot is full, SpaceX will launch HLS, have it fill its tanks at the depot rocket, and send it up to NRHO in advance of Orion. When Orion arrives, HLS will hopefully have enough propellant left on board to take on astronauts and make a single round trip from NRHO to the lunar surface.

</p><p>Getting this plan to work requires solving a second engineering problem, how to keep cryogenic propellants cold in space.  Low earth orbit is a toasty place, and without special measures, the cryogenic propellants Starship uses will quickly vent off into space.  The problem is easy to solve in deep space (use a sunshade), but becomes tricky in low Earth orbit, where a warm rock covers a third of the sky.  (Boil-off is also a big issue for HLS on the moon.)


</p><p> It’s not clear how many Starship launches it will take to refuel HLS.  Elon Musk has said four launches might be enough; NASA Assistant Deputy Associate Administrator Lakiesha Hawkins says the number is in the “high teens”.  Last week, SpaceX's Kathy Lueders <a href="https://youtu.be/vOg49BVhU40?si=6q8R2qvkmEDPGy0V&amp;t=2381">gave a figure of fifteen launches</a>.

</p><p>The real number is unknown and will come down to four factors:

</p><ol>
<li>How much propellant a Starship can carry to low Earth orbit.</li>

<li>What fraction of that can be usably pumped out of the rocket. </li>

<li>How quickly cryogenic propellant boils away from the orbiting depot.</li>

<li>How rapidly SpaceX can launch Starships.</li>
</ol>

<p>SpaceX probably knows the answer to (1), but isn’t talking.  Data for (2) and (3) will have to wait for flight tests that are planned for 2025.  And obviously a lot is riding on (4), also called launch cadence.  

</p><p>The record for heavy rocket launch cadence belongs to Saturn V, which launched three times during a four month period in 1968.  Second place belongs to the Space Shuttle, which flew nine times in the calendar year before the Challenger disaster. In third place is Falcon Heavy, which flew six times in a 13 month period beginning in November 2022. 

</p><p>For the refueling plan to work, Starship will have to break this record by a factor of ten, launching every six days or so across multiple launch facilities. <a id="fn_cadence"></a><a href="#cadence"><span><sup>[1]</sup></span></a>  The refueling program can tolerate a few launch failures, as long as none of them damages a launch pad. 

</p><p>There’s no company better prepared to meet this challenge than SpaceX. Their Falcon 9 rocket has shattered records for both reliability and cadence, and now launches about once every three days.  But it took SpaceX ten years to get from the first orbital Falcon 9 flight to a weekly cadence, and Starship is vastly bigger and more complicated than the Falcon 9. <a id="fn_falcon9"></a><a href="#falcon9"><span><sup>[20]</sup></span></a>

</p><p>Working backwards from the official schedule allows us to appreciate the time pressure facing SpaceX. To make the official Artemis landing date, SpaceX has to land an unmanned HLS prototype on the moon in early 2026. That means tanker flights to fill an orbiting depot would start in late 2025.  This doesn’t leave a lot of time for the company to invent orbital refueling, get it working at scale, make it efficient, deal with boil-off, get Starship launching reliably, begin recovering booster stages,<a id="fn_recovery"></a><a href="#recovery"><span><sup>[21]</sup></span></a> set up additional launch facilities, achieve a weekly cadence,  and at the same time design and test all the other systems that need to go into HLS. 

</p><p>Lest anyone think I’m picking on SpaceX, the development schedule for Blue Origin’s 2029 lander is even more fantastical. That design requires pumping tons of liquid hydrogen between spacecraft in lunar orbit, a challenge perhaps an order of magnitude harder than what SpaceX is attempting. Liquid hydrogen is bulky, boils near absolute zero, and is infamous for its ability to leak through anything (the Shuttle program couldn't get a handle on hydrogen leaks on Earth even after a hundred some launches).  And the rocket Blue Origin needs to test all this technology has never left the ground. 

</p><p>The upshot is that NASA has put a pair of last-minute long-shot technology development programs between itself and the moon.  Particularly striking is the contrast between the ambition of the HLS designs and the extreme conservatism and glacial pace of SLS/Orion.  The same organization that spent 23 years and 20 billion dollars building the world's most vanilla spacecraft demands that SpaceX darken the sky with Starships within four years of signing the initial HLS contract. While thrilling for SpaceX fans, this is pretty unserious behavior from the nation’s space agency, which had several decades' warning that going to the moon would require a lander. 

</p><p>All this to say, it's universally understood that there won’t be a moon landing in 2026. At some point NASA will have to officially slip the schedule, as it did in 2021, 2023, and at the start of this year.  If this accelerating pattern of delays continues, by year’s end we might reach a state of continuous postponement, a kind of scheduling singularity where the landing date for Artemis 3 recedes smoothly and continuously into the future. 

</p><p>Otherwise, it's hard to imagine a manned lunar landing before 2030, if the Artemis program survives that long.


</p><p><img src="https://idlewords.com/images/artemis_cart.jpg" width="100%" alt="Interior of Skylab"></p>

<p><b><a name="conclusion">VII. Conclusion</a></b></p>

<p>I want to stress that there’s nothing wrong with NASA making big bets on technology.  Quite the contrary, the audacious HLS contracts may be the healthiest thing about Artemis. Visionaries at NASA identified a futuristic new energy source (space billionaire egos) and found a way to tap it on a fixed-cost basis.  If SpaceX or Blue Origin figure out how to make cryogenic refueling practical, it will mean a big step forward for space exploration, exactly the thing NASA should be encouraging. And if the technology doesn’t pan out, we’ll have found that out mostly by spending Musk’s and Bezos’s money.  

</p><p>The real problem with Artemis is that it doesn’t think through the consequences of its own success.  A working infrastructure for orbital refueling would make SLS and Orion superfluous.  Instead of waiting two years to go up on a $4 billion rocket, crews and cargo could launch every weekend on cheap commercial rockets, refueling in low Earth orbit on their way to the Moon. A similar logic holds for Gateway.  Why assemble a space station out of habitrail pieces out in lunar orbit, like an animal, when you can build one on Earth and launch it in one piece? Better yet, just spraypaint “<b>GATEWAY</b>” on the side of the nearest Starship, send it out to NRHO, and save NASA and its international partners billions.  Having a working gas station in low Earth orbit fundamentally changes what is possible, in a way the SLS/Orion arm of Artemis doesn't seem to recognize.

</p><p>Conversely, if SpaceX and Blue Origin can’t make cryogenic refueling work, then NASA has no plan B for landing on the moon. All the Artemis program will be able to do is assemble Gateway.  Promising taxpayers the moon only to deliver ISS Jr. does not broadcast a message of national greatness, and is unlikely to get Congress excited about going to Mars.  The hurtful comparisons between American dynamism in the 1960’s and whatever it is we have now will practically write themselves. 

</p><p>What NASA is doing is like an office worker blowing half their salary on lottery tickets while putting the other half in a pension fund.  If the lottery money comes through, then there was really no need for the pension fund. But without the lottery win, there’s not enough money in the pension account to retire on. The two strategies don't make sense together.

</p><p>There’s a ‘realist’ school of space flight that concedes all this but asks us to look at the bigger picture. We’re never going to have the perfect space program, the argument goes, but the important thing is forward progress. And Artemis is the first program in years to survive a presidential transition and have a shot at getting us beyond low Earth orbit.  With Artemis still funded, and Starship making rapid progress, at some point we’ll finally see American astronauts back on the moon.

</p><p>But this argument has two flaws. The first is that it feeds a cycle of dysfunction at NASA that is rapidly making it impossible for us to go anywhere.    Holding human space flight to a different standard than NASA’s science missions has been a disaster for space exploration.  Right now the Exploration Systems Development Mission Directorate (the entity responsible for manned space flight) couldn’t build a toaster for less than a billion dollars.  Incompetence, self-dealing, and mismanagement that end careers on the science side of NASA are not just tolerated but rewarded on the human space flight side.  Before we let the agency build out its third white elephant project in forty years,  it’s worth reflecting on what we're getting in return for half our exploration budget.

</p><p>The second, more serious flaw in the “realist” approach is that it enables a culture of institutional mendacity that must ultimately be fatal at an engineering organization. We've reached a point where NASA lies constantly, to both itself and to the public. It lies about schedules and capabilities. It lies about the costs and the benefits of its human spaceflight program. And above all, it lies about risk. All the institutional pathologies identified in the Rogers Report and the Columbia Accident Investigation Board are alive and well in Artemis—groupthink, management bloat, intense pressure to meet impossible deadlines, and a willingness to manufacture engineering rationales to justify flying unsafe hardware.

</p><div><p>Do we really have to wait for another tragedy, and another beautifully produced Presidential Commission report, to see that Artemis is broken? 

</p></div><p><b><a name="notes">Notes</a></b></p>



<p><a id="cost"></a><a href="#fn_cost">[1]</a>  Without NASA's help, it's hard to put a dollar figure on a mission without making somewhat arbitrary decisions about what to include and exclude. The $7-10 billion estimate comes from a Bush-era official in the Office of Management and Budget commenting <a href="https://forum.nasaspaceflight.com/index.php?topic=60228.msg2559545#msg2559545">on the NASA Spaceflight Forum</a>

</p><blockquote>
And that $7.2B assumes Artemis III stays on schedule.  Based on the FY24 budget request, each additional year between Artemis II and Artemis III adds another $3.5B to $4.0B in Common Exploration to Artemis III.  If Artemis III goes off in 2027, then it will be $10.8B total.  If 2028, then $14.3B.
</blockquote>

 <p>In other words, it's hard to break out an actual cost while the launch dates for both Artemis II and III keep slipping.
 
 </p><p>NASA's own Inspector General estimates the cost of <a href="https://oig.nasa.gov/wp-content/uploads/2024/02/IG-22-003.pdf">just the SLS/Orion portion</a> of a moon landing at $4.1 billion. 


</p><p><a id="nasatime"></a><a href="#fn_nasatime">[2]</a>  The first US suborbital flight, Friendship 7, launched on May 15, 1961. Armstrong and Aldrin landed on the moon eight years and two months later, on July 21, 1969.  President Bush announced the goal of returning to the Moon in a January 2004 speech, setting the target date for the first landing "as early as 2015", and no later than 2020.

</p><p><a id="slscost"></a><a href="#fn_slscost">[3]</a> NASA refuses to track the per-launch cost of SLS, so it's easy to get into nerdfights. Since the main cost driver on SLS is the gigantic workforce employed on the project, something like two or three times the headcount of SpaceX, the cost per launch depends a lot on cadence.    If you assume a yearly launch rate (the official line), then the rocket costs $2.1 billion a launch. If like me you think one launch every two years is optimistic, the cost climbs up into the $4-5 billion range.   


</p><p><a id="dollarbills"></a><a href="#fn_dollarbills">[4]</a> The SLS weighs 2,600 metric tons fully fueled, and conveniently enough a dollar bill weighs about 1 gram. 

</p><p><a id="refurb"></a><a href="#fn_refurb">[5]</a> SpaceX does not disclose the cost, but it's widely assumed the Raptor engine used on Superheavy costs $1 million.   



</p><p><a id="rs25restart"></a><a href="#fn_rs25restart">[6]</a>  The $145 million figure comes from <a href="https://spacenews.com/aerojet-rocketdyne-defends-sls-engine-contract-costs/">dividing the contract cost by the number of engines</a>, caveman style. Others have reached a figure of $100 million for the unit cost of these engines. The important point is not who is right but the fact that NASA is paying vastly more than anyone else for engines of this class.


</p><p><a id="fheavy"></a><a href="#fn_fheavy">[7]</a> $250M is the figure you get by dividing the $3.2 billion Booster Production and Operations contract to Northrop Grumman by the number of boosters (12) in the contract.  Source:  <a href="https://oig.nasa.gov/wp-content/uploads/2024/02/IG-23-015.pdf">Office of the Inspector General</a>. For cost overruns replacing asbestos, see the OIG report on <a href="https://oig.nasa.gov/wp-content/uploads/2024/02/IG-23-015.pdf">NASA’s Management of the Space Launch
System Booster and Engine Contracts</a>.  The Department of Defense paid <a href"https:="" www.nasaspaceflight.com="" 2023="" 12="" otv-7="" "="">$130 million</a> for a Falcon Heavy launch in 2023. 

</p><p><a id="electron"></a><a href="#fn_electron">[8]</a>  Rocket Lab developed, tested, and flew its Electron rocket for a total program cost of <a href="https://twitter.com/Peter_J_Beck/status/1302692025297379328">$100 million</a>. 

</p><p><a id="heatshield"></a><a href="#fn_heatshield">[9]</a> In particular, the separation bolts embedded in the Orion heat shield were built based on a flawed thermal model, and need to be redesigned to safely fly a crew. From <a href="https://oig.nasa.gov/office-of-inspector-general-oig/audit-reports/nasas-readiness-for-the-artemis-ii-crewed-mission-to-lunar-orbit/">the OIG report</a>:

</p><blockquote>
Separation bolt melt beyond the thermal barrier during reentry can expose the vehicle to hot gas ingestion behind the heat shield, exceeding Orion’s structural limits and resulting in the breakup of the vehicle and loss of crew. Post-flight inspections determined there was a discrepancy in the thermal model used to predict the bolts’ performance pre-flight. Current predictions using the correct information suggest the bolt melt exceeds the design capability of Orion.
</blockquote>

<p>The current plan is to work around these problems on Artemis 2, and then redesign the components for Artemis 3. That means astronauts have to fly at least twice with an untested heat shield design. 




</p><p><a id="oriondeltav"></a><a href="#fn_oriondeltav">[10]</a> 
Orion/ESM has a delta V budget of 1340 m/s. Getting into and out of an equatorial low lunar orbit takes about 1800 m/s, more for a polar orbit.  (See <a href="https://www.nasa.gov/wp-content/uploads/2023/10/nrho-artemis-orbit.pdf">source</a>.)

</p><p><a id="nrho"></a><a href="#fn_nrho">[11]</a> 
It takes about 900 m/s of total delta V to get in and out of NHRO, comfortably within Orion/ESM's 1340 m/s budget.  (See <a href="https://www.nasa.gov/wp-content/uploads/2023/10/nrho-artemis-orbit.pdf">source</a>.)

</p><p><a id="abort"></a><a href="#fn_abort">[12]</a> 
In <i>Carrying the Fire</i>, Apollo 11 astronaut Michael Collins recalls carrying a small notebook covering 18 lunar rendezvous scenarios he might be called on to fly in various contingencies. If the Lunar Module could get itself off the surface, there was probably a way to dock with it.

</p><p>For those too young to remember, Tang is a powdered orange drink <a href="https://www.foodandwine.com/lifestyle/how-nasa-made-tang-cool">closely associated</a> with the American space program. 


</p><p><a id="abortnrho"></a><a href="#fn_abortnrho">[13]</a> For a detailed (if somewhat cryptic) discussion of possible Artemis abort modes to NRHO, see <a href="https://ntrs.nasa.gov/api/citations/20230002566/downloads/HLS%20NRHO%20to%20Lunar%20Surface%20and%20Back%20Mission%20Design_STRIVES.pptx.pdf">HLS NRHO to Lunar Surface and
Back Mission Design</a>, NASA 2022.

</p><p><a id="hlsprop"></a><a href="#fn_hlsprop">[14]</a> This is my own speculative guess; the answer is very sensitive to the dry weight of HLS and the boil-off rate of its cryogenic propellants. Delta V from the lunar surface to NRHO is 2,610 m/sec.  Assuming HLS weighs 120 tons unfueled, it would need about 150 metric tons of propellant to get into NRHO from the lunar surface. Adding safety margin, fuel for docking operations, and allowing for a week of boiloff gets me to about 200 tons. 

</p><p><a id="landingrisk"></a><a href="#fn_landingrisk">[15]</a>
The main safety issue is the difficult thermal environment at the landing site, where the Sun sits just above the horizon, heating half the lander. If it weren't for the NRHO constraint, it's very unlikely Artemis 3 would spend more than a day or two on the lunar surface. 

</p><p><a id="iss"></a><a href="#fn_iss">[16]</a>
The ISS program has been repeatedly extended, but the station is coming up against physical limiting factors (like metal fatigue) that will soon make it too dangerous to use.

</p><p><a id="ascent"></a><a href="#fn_ascent">[17]</a>
Recent comments by NASA suggest SpaceX has <a href="https://twitter.com/jeff_foust/status/1783877352432263175">voluntarily added an ascent phase</a> to its landing demo, ending a pretty untenable situation. However, there's still no requirement that the unmanned landing/ascent demo be performed using the same lander design that will fly on the actual mission, another oddity in the HLS contract.


</p><p><a id="refuel"></a><a href="#fn_refuel">[18]</a>
To be precise, I'm talking about moving bulk propellant between rockets in orbit. There are resupply flights to the International Space Station that deliver about 850 kilograms of non-cryogenic propellant to boost the station in its orbit, and there have been small-scale experiments in refueling satellites. But no one has attempted refueling a flown rocket stage in space, cryogenic or otherwise. 



</p><p><a id="cadence"></a><a href="#fn_cadence">[19]</a>

Both SpaceX's <a href="https://youtu.be/vOg49BVhU40?si=6q8R2qvkmEDPGy0V&amp;t=2381" "="">Kathy Lueders</a> and NASA confirm Starship needs to launch from multiple sites.  Here's an excerpt from <a href="https://www.nasa.gov/wp-content/uploads/2024/01/heoc-november-2023-final-v2.pdf">the minutes</a> of the NASA Advisory Council Human Exploration and Operations Committee meeting on November 17 and 20, 2023:

</p><blockquote>
Mr. [Wayne] Hale asked where Artemis III will launch from. [Assistant Deputy AA for Moon to Mars Lakiesha] Hawkins said that launch pads will be used in Florida and potentially Texas. The missions will need quite a number of tankers; in order to meet the schedule, there will need to be a rapid succession of launches of fuel, requiring more than one site for launches on a 6-day rotation schedule, and multiples of launches. 
</blockquote>


<p><a id="falcon9"></a><a href="#fn_falcon9">[20]</a> Falcon 9 first flew in June of 2010 and achieved a weekly launch cadence over a span of six launches starting in November 2020. 


</p><p><a id="recovery"></a><a href="#fn_recovery">[21]</a> Recovering Superheavy stages is not a NASA requirement for HLS, but it's a huge cost driver for SpaceX given the number of launches involved. 


</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hertz Charging a Tesla Renter for Gas Was Not an Isolated Incident (137 pts)]]></title>
            <link>https://www.thedrive.com/news/hertz-charging-a-tesla-renter-for-gas-was-not-an-isolated-incident</link>
            <guid>40410341</guid>
            <pubDate>Sun, 19 May 2024 22:52:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thedrive.com/news/hertz-charging-a-tesla-renter-for-gas-was-not-an-isolated-incident">https://www.thedrive.com/news/hertz-charging-a-tesla-renter-for-gas-was-not-an-isolated-incident</a>, See on <a href="https://news.ycombinator.com/item?id=40410341">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-id="page-content" data-og-area="article-blocks" id="incArticle"><p>Hertz's foray into renting EVs hasn't been a runaway success. The rental agency is <a href="https://www.thedrive.com/news/ex-hertz-tesla-model-3s-cost-as-little-as-14000-would-you-buy-one" target="_blank" rel="noreferrer noopener">liquidating its excess Teslas</a> due to limited demand and tanking values, while those who have rented its EVs haven't always had a good experience. Last week, we reported on a customer who was <a href="https://www.thedrive.com/news/hertz-is-charging-tesla-model-3-renter-277-fee-for-gas-wont-back-down" target="_blank" rel="noreferrer noopener">charged $277 for gasoline his rented Tesla couldn't have possibly used</a>—and now, we've heard from other Hertz customers who say they've been charged even more.</p><p>Hertz caught attention last week for how it handled a customer whom it had charged a "Skip the Pump" fee, which allows renters to pay a premium for Hertz to refill the tank for them. But of course, this customer's rented <a href="https://www.thedrive.com/news/2024-tesla-model-3-with-new-face-and-interior-finally-arrives-in-us" target="_blank" rel="noreferrer noopener">Tesla Model 3</a> didn't use gas—it draws power from a battery—and Hertz has a separate, flat fee for EV recharges. Nevertheless, the customer was charged $277.39 despite returning the car with the exact same charge they left with, and Hertz refused to refund it until after our story ran.</p><p>It's no isolated incident either, as other customers have written in to inform us that it happened to them, too.</p><figure data-og-block-area="article-blocks" data-og-block-nth="1" data-og-block-type="core/image"><span data-rawhtml="1">A lineup of Hertz Polestar 2 EVs. <em>Hertz</em> </span></figure><p>Evan Froehlich told us that when he booked a Tesla Model 3 Long Range, his problems began well before it came time to return the car. On pickup, he was told the Long Range model he'd reserved was unavailable, and that he'd been downgraded to a standard-range model. He had to go to a manager to get any recourse, which ended up being just a $22 discount.</p><p>Froehlich returned the rental at 21 percent charge, expecting to pay a flat $25 recharge fee. (It's ordinarily $35, but Hertz's loyalty program discounts it.) To Froehlich's surprise, he was hit with a $340.97 "Skip the Pump" fee, which can be applied after returning a car if it's not requested beforehand. He says Hertz's customer service was difficult to reach, and that it took making a ruckus on social media to get Hertz's attention.</p><p>In the end, a Hertz representative was able to review the charge and have it reversed. But Froelich was told it could take five to seven business days for the money to transfer, and for his troubles, he was offered just one free day of renting an EV (to be redeemed this calendar year, no less).</p><div data-og-block-area="article-blocks" data-og-block-nth="1" data-og-block-type="core/gallery"><figcaption data-rawhtml="1">Some of Evan Froehlich's interactions with Hertz customer service regarding his fuel charges. <em>Evan Froehlich</em></figcaption></div><p>Fellow Hertz customer Toan Le reported an even worse experience with their Tesla rental earlier this month. They told us they prepaid $329.83 for a week with a Model 3, and returned the car expecting to pay only $25 for Hertz to charge it. Le was then apparently billed $690.32, some of which was redundant billing for the rental they say they'd already paid for.</p><p>To add insult to injury, their invoice (shown here) indicates more than two thirds of that, $475.19, was a fuel charge, which was applied in addition to the $25 charging fee. They also faced a $125.01 "rebill" for using <a href="https://www.thedrive.com/news/oops-tesla-is-re-hiring-some-charging-personnel-musk-laid-off" target="_blank" rel="noreferrer noopener">the Supercharger network</a> during their rental, which <a href="https://www.yellowbullet.com/threads/rented-a-tesla.2679591/" target="_blank" rel="noreferrer noopener">other Hertz customers have expressed surprise and frustration with</a>. Charging costs can vary, but a 75-percent charge from a Supercharger will often cost in the region of just $15.</p><div data-og-block-area="article-blocks" data-og-block-nth="2" data-og-block-type="core/gallery"><figcaption data-rawhtml="1">Toan Le's invoices for their Tesla Model 3 rental, plus an email from Hertz's customer service. <em>Toan Le</em></figcaption></div><p>Le was able to get the fuel charge waived, but was still dissatisfied to see such a large followup bill. Despite reaching the top tier of Hertz's loyalty program, they told us they "might reconsider renting another vehicle from Hertz." How many other Hertz customers have been inappropriately billed is unclear, though <a href="https://www.facebook.com/david.kreeger.9/posts/pfbid0866bUEYfvxJ3vYS2dxDFU7Eyf9uQidgYPvLw7rS7VeVtrrYoApJtAQZgzEXteGCkl" target="_blank" rel="noreferrer noopener">a March 2023 Facebook post</a> documenting a similar case indicates this has been happening for more than a year.</p><p><em>Got a tip or question for the author? You can reach them here: james@thedrive.com</em></p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meteor Just Seen in Portugal (172 pts)]]></title>
            <link>https://old.reddit.com/r/interestingasfuck/comments/1cva6j6/meteor_just_seen_in_portugal_23h45/</link>
            <guid>40409710</guid>
            <pubDate>Sun, 19 May 2024 21:01:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/interestingasfuck/comments/1cva6j6/meteor_just_seen_in_portugal_23h45/">https://old.reddit.com/r/interestingasfuck/comments/1cva6j6/meteor_just_seen_in_portugal_23h45/</a>, See on <a href="https://news.ycombinator.com/item?id=40409710">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><hr>

<p>A place to share (almost) anything and everything interesting as fuck.</p>

<hr>

<h2><a href="https://www.reddit.com/r/interestingasfuck/wiki/index#wiki_rules.3A">Please read our rules</a></h2>

<ol>
<li><p><strong>Posts MUST be INTERESTING AS FUCK.</strong> <a href="https://www.reddit.com/r/interestingasfuck/wiki/index#wiki_rule_1_-_posts_must_be_interesting_as_fuck">more&gt;&gt;</a></p></li>
<li><p>Titles must be descriptive and directly related to the content <a href="https://www.reddit.com/r/interestingasfuck/wiki/index#wiki_rule_2_-_titles_must_be_descriptive_and_directly_related_to_the_content">more&gt;&gt;</a></p></li>
<li><p>No porn or gore. <a href="https://www.reddit.com/r/interestingasfuck/wiki/index#wiki_rule_3_-_no_porn.2Fgore">more&gt;&gt;</a></p></li>
<li><p>No personal information, doxing, witch hunt, brigading, or <strong>any subreddit-related meta-drama</strong>. <a href="https://www.reddit.com/r/interestingasfuck/wiki/index#wiki_rule_4_-_no_doxing.2Fwitch_hunts">more&gt;&gt;</a></p></li>
<li><p>Source your claims. <a href="https://www.reddit.com/r/interestingasfuck/wiki/index#wiki_rule_5_-_provide_a_source_when_the_title_is_in_doubt">more&gt;&gt;</a></p></li>
<li><p>No FCoO/flooding. <a href="https://www.reddit.com/r/interestingasfuck/wiki/index#wiki_rule_6_-_no_fcoo.2Fflooding">more&gt;&gt;</a> </p></li>
<li><p>No self-promotion, bots or any kind of spam. <a href="https://www.reddit.com/r/interestingasfuck/wiki/index#wiki_rule_7_-_no_self-promotion">more&gt;&gt;</a></p></li>
<li><p>Comments must be civil. Any racism, bigotry, or any other kind of hate speech is strictly prohibited and will result in a ban. <a href="https://www.reddit.com/r/interestingasfuck/wiki/index#wiki_rule_8_-_civility">more&gt;&gt;</a></p></li>
<li><p>Reposts of images on the front page, or within the set limit of <a href="https://old.reddit.com/r/interestingasfuck/top">/r/interestingasfuck/top</a>, will be removed <a href="https://www.reddit.com/r/interestingasfuck/wiki/index#wiki_rule_9_-_repost_limitations">more&gt;&gt;</a></p></li>
<li><p>No gossip or tabloid-type material <a href="https://www.reddit.com/r/interestingasfuck/wiki/index#wiki_rule_10_-_no_gossip_or_tabloid-type_material">more&gt;&gt;</a></p></li>
</ol>

<hr>

<p><a href="https://www.reddit.com/r/interestingasfuck/wiki/index#wiki_additional.2Ftemporary_rules">Additional Rules</a></p>

<ul>
<li><p>Serial reposters may be filtered or banned.</p></li>
<li><p>Established accounts will get escalating bans if they willfully ignore the posting rules</p></li>
<li><p>We require new users to post original content, not lazy reposts. Reposting as a very new account might get you banned</p></li>
<li><p>All posts by new users require mod approval in order to weed out spammers.</p></li>
<li><p>Please mark spoilers like this:  <code>&gt;!text here!&lt;</code> Click/tap to <span>read</span>.</p></li>
<li><p>All posts concerning the Palestine/Israel conflict will be locked for comments.  Such posts are still subject to all rules above.</p></li>
</ul>

<hr>

<p>If you want a piece of content that belongs to you to be removed from <a href="https://old.reddit.com/r/interestingasfuck">/r/interestingasfuck</a> then please file a copyright notice <a href="https://reddit.zendesk.com/hc/en-us/requests/new?ticket_form_id=73465">here</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Operation CHARM: Car repair manuals for everyone (161 pts)]]></title>
            <link>https://charm.li/</link>
            <guid>40409588</guid>
            <pubDate>Sun, 19 May 2024 20:39:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://charm.li/">https://charm.li/</a>, See on <a href="https://news.ycombinator.com/item?id=40409588">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p><b>Operation CHARM</b>: Car repair manuals for everyone.</p>
<div><p><a href="https://charm.li/">Home</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama3 implemented from scratch (419 pts)]]></title>
            <link>https://github.com/naklecha/llama3-from-scratch</link>
            <guid>40408880</guid>
            <pubDate>Sun, 19 May 2024 18:42:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/naklecha/llama3-from-scratch">https://github.com/naklecha/llama3-from-scratch</a>, See on <a href="https://news.ycombinator.com/item?id=40408880">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">llama3 implemented from scratch</h2><a id="user-content-llama3-implemented-from-scratch" aria-label="Permalink: llama3 implemented from scratch" href="#llama3-implemented-from-scratch"></a></p>
<p dir="auto">in this file, i implemented llama3 from scratch, one tensor and matrix multiplication at a time.
<br>
also, im going to load tensors directly from the model file that meta provided for llama3, you need to download the weights before running this file.
here is the offical link to download the weights: <a href="https://llama.meta.com/llama-downloads/" rel="nofollow">https://llama.meta.com/llama-downloads/</a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/archi.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/archi.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">tokenizer</h2><a id="user-content-tokenizer" aria-label="Permalink: tokenizer" href="#tokenizer"></a></p>
<p dir="auto">im not going to implement a bpe tokenizer (but andrej karpathy has a really clean implementation)
<br>
link to his implementation: <a href="https://github.com/karpathy/minbpe">https://github.com/karpathy/minbpe</a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/karpathyminbpe.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/karpathyminbpe.png" width="600"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="from pathlib import Path
import tiktoken
from tiktoken.load import load_tiktoken_bpe
import torch
import json
import matplotlib.pyplot as plt

tokenizer_path = &quot;Meta-Llama-3-8B/tokenizer.model&quot;
special_tokens = [
            &quot;<|begin_of_text|>&quot;,
            &quot;<|end_of_text|>&quot;,
            &quot;<|reserved_special_token_0|>&quot;,
            &quot;<|reserved_special_token_1|>&quot;,
            &quot;<|reserved_special_token_2|>&quot;,
            &quot;<|reserved_special_token_3|>&quot;,
            &quot;<|start_header_id|>&quot;,
            &quot;<|end_header_id|>&quot;,
            &quot;<|reserved_special_token_4|>&quot;,
            &quot;<|eot_id|>&quot;,  # end of turn
        ] + [f&quot;<|reserved_special_token_{i}|>&quot; for i in range(5, 256 - 5)]
mergeable_ranks = load_tiktoken_bpe(tokenizer_path)
tokenizer = tiktoken.Encoding(
    name=Path(tokenizer_path).name,
    pat_str=r&quot;(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\r\n\p{L}\p{N}]?\p{L}+|\p{N}{1,3}| ?[^\s\p{L}\p{N}]+[\r\n]*|\s*[\r\n]+|\s+(?!\S)|\s+&quot;,
    mergeable_ranks=mergeable_ranks,
    special_tokens={token: len(mergeable_ranks) + i for i, token in enumerate(special_tokens)},
)

tokenizer.decode(tokenizer.encode(&quot;hello world!&quot;))"><pre><span>from</span> <span>pathlib</span> <span>import</span> <span>Path</span>
<span>import</span> <span>tiktoken</span>
<span>from</span> <span>tiktoken</span>.<span>load</span> <span>import</span> <span>load_tiktoken_bpe</span>
<span>import</span> <span>torch</span>
<span>import</span> <span>json</span>
<span>import</span> <span>matplotlib</span>.<span>pyplot</span> <span>as</span> <span>plt</span>

<span>tokenizer_path</span> <span>=</span> <span>"Meta-Llama-3-8B/tokenizer.model"</span>
<span>special_tokens</span> <span>=</span> [
            <span>"&lt;|begin_of_text|&gt;"</span>,
            <span>"&lt;|end_of_text|&gt;"</span>,
            <span>"&lt;|reserved_special_token_0|&gt;"</span>,
            <span>"&lt;|reserved_special_token_1|&gt;"</span>,
            <span>"&lt;|reserved_special_token_2|&gt;"</span>,
            <span>"&lt;|reserved_special_token_3|&gt;"</span>,
            <span>"&lt;|start_header_id|&gt;"</span>,
            <span>"&lt;|end_header_id|&gt;"</span>,
            <span>"&lt;|reserved_special_token_4|&gt;"</span>,
            <span>"&lt;|eot_id|&gt;"</span>,  <span># end of turn</span>
        ] <span>+</span> [<span>f"&lt;|reserved_special_token_<span><span>{</span><span>i</span><span>}</span></span>|&gt;"</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span>(<span>5</span>, <span>256</span> <span>-</span> <span>5</span>)]
<span>mergeable_ranks</span> <span>=</span> <span>load_tiktoken_bpe</span>(<span>tokenizer_path</span>)
<span>tokenizer</span> <span>=</span> <span>tiktoken</span>.<span>Encoding</span>(
    <span>name</span><span>=</span><span>Path</span>(<span>tokenizer_path</span>).<span>name</span>,
    <span>pat_str</span><span>=</span><span>r"(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\r\n\p{L}\p{N}]?\p{L}+|\p{N}{1,3}| ?[^\s\p{L}\p{N}]+[\r\n]*|\s*[\r\n]+|\s+(?!\S)|\s+"</span>,
    <span>mergeable_ranks</span><span>=</span><span>mergeable_ranks</span>,
    <span>special_tokens</span><span>=</span>{<span>token</span>: <span>len</span>(<span>mergeable_ranks</span>) <span>+</span> <span>i</span> <span>for</span> <span>i</span>, <span>token</span> <span>in</span> <span>enumerate</span>(<span>special_tokens</span>)},
)

<span>tokenizer</span>.<span>decode</span>(<span>tokenizer</span>.<span>encode</span>(<span>"hello world!"</span>))</pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">reading the model file</h2><a id="user-content-reading-the-model-file" aria-label="Permalink: reading the model file" href="#reading-the-model-file"></a></p>
<p dir="auto">normally, reading this depends on how the model classes are written and the variable names inside them.
<br>
but since we are implementing llama3 from scratch we will read the file one tensor at a time.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/model.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/model.png" width="600"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="model = torch.load(&quot;Meta-Llama-3-8B/consolidated.00.pth&quot;)
print(json.dumps(list(model.keys())[:20], indent=4))"><pre><span>model</span> <span>=</span> <span>torch</span>.<span>load</span>(<span>"Meta-Llama-3-8B/consolidated.00.pth"</span>)
<span>print</span>(<span>json</span>.<span>dumps</span>(<span>list</span>(<span>model</span>.<span>keys</span>())[:<span>20</span>], <span>indent</span><span>=</span><span>4</span>))</pre></div>
<div data-snippet-clipboard-copy-content="[
    &quot;tok_embeddings.weight&quot;,
    &quot;layers.0.attention.wq.weight&quot;,
    &quot;layers.0.attention.wk.weight&quot;,
    &quot;layers.0.attention.wv.weight&quot;,
    &quot;layers.0.attention.wo.weight&quot;,
    &quot;layers.0.feed_forward.w1.weight&quot;,
    &quot;layers.0.feed_forward.w3.weight&quot;,
    &quot;layers.0.feed_forward.w2.weight&quot;,
    &quot;layers.0.attention_norm.weight&quot;,
    &quot;layers.0.ffn_norm.weight&quot;,
    &quot;layers.1.attention.wq.weight&quot;,
    &quot;layers.1.attention.wk.weight&quot;,
    &quot;layers.1.attention.wv.weight&quot;,
    &quot;layers.1.attention.wo.weight&quot;,
    &quot;layers.1.feed_forward.w1.weight&quot;,
    &quot;layers.1.feed_forward.w3.weight&quot;,
    &quot;layers.1.feed_forward.w2.weight&quot;,
    &quot;layers.1.attention_norm.weight&quot;,
    &quot;layers.1.ffn_norm.weight&quot;,
    &quot;layers.2.attention.wq.weight&quot;
]"><pre><code>[
    "tok_embeddings.weight",
    "layers.0.attention.wq.weight",
    "layers.0.attention.wk.weight",
    "layers.0.attention.wv.weight",
    "layers.0.attention.wo.weight",
    "layers.0.feed_forward.w1.weight",
    "layers.0.feed_forward.w3.weight",
    "layers.0.feed_forward.w2.weight",
    "layers.0.attention_norm.weight",
    "layers.0.ffn_norm.weight",
    "layers.1.attention.wq.weight",
    "layers.1.attention.wk.weight",
    "layers.1.attention.wv.weight",
    "layers.1.attention.wo.weight",
    "layers.1.feed_forward.w1.weight",
    "layers.1.feed_forward.w3.weight",
    "layers.1.feed_forward.w2.weight",
    "layers.1.attention_norm.weight",
    "layers.1.ffn_norm.weight",
    "layers.2.attention.wq.weight"
]
</code></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="with open(&quot;Meta-Llama-3-8B/params.json&quot;, &quot;r&quot;) as f:
    config = json.load(f)
config"><pre><span>with</span> <span>open</span>(<span>"Meta-Llama-3-8B/params.json"</span>, <span>"r"</span>) <span>as</span> <span>f</span>:
    <span>config</span> <span>=</span> <span>json</span>.<span>load</span>(<span>f</span>)
<span>config</span></pre></div>
<div data-snippet-clipboard-copy-content="{'dim': 4096,
 'n_layers': 32,
 'n_heads': 32,
 'n_kv_heads': 8,
 'vocab_size': 128256,
 'multiple_of': 1024,
 'ffn_dim_multiplier': 1.3,
 'norm_eps': 1e-05,
 'rope_theta': 500000.0}"><pre><code>{'dim': 4096,
 'n_layers': 32,
 'n_heads': 32,
 'n_kv_heads': 8,
 'vocab_size': 128256,
 'multiple_of': 1024,
 'ffn_dim_multiplier': 1.3,
 'norm_eps': 1e-05,
 'rope_theta': 500000.0}
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">we use this config to infer details about the model like</h2><a id="user-content-we-use-this-config-to-infer-details-about-the-model-like" aria-label="Permalink: we use this config to infer details about the model like" href="#we-use-this-config-to-infer-details-about-the-model-like"></a></p>
<ol dir="auto">
<li>the model has 32 transformer layers</li>
<li>each multi-head attention block has 32 heads</li>
<li>the vocab size and so on</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="dim = config[&quot;dim&quot;]
n_layers = config[&quot;n_layers&quot;]
n_heads = config[&quot;n_heads&quot;]
n_kv_heads = config[&quot;n_kv_heads&quot;]
vocab_size = config[&quot;vocab_size&quot;]
multiple_of = config[&quot;multiple_of&quot;]
ffn_dim_multiplier = config[&quot;ffn_dim_multiplier&quot;]
norm_eps = config[&quot;norm_eps&quot;]
rope_theta = torch.tensor(config[&quot;rope_theta&quot;])"><pre><span>dim</span> <span>=</span> <span>config</span>[<span>"dim"</span>]
<span>n_layers</span> <span>=</span> <span>config</span>[<span>"n_layers"</span>]
<span>n_heads</span> <span>=</span> <span>config</span>[<span>"n_heads"</span>]
<span>n_kv_heads</span> <span>=</span> <span>config</span>[<span>"n_kv_heads"</span>]
<span>vocab_size</span> <span>=</span> <span>config</span>[<span>"vocab_size"</span>]
<span>multiple_of</span> <span>=</span> <span>config</span>[<span>"multiple_of"</span>]
<span>ffn_dim_multiplier</span> <span>=</span> <span>config</span>[<span>"ffn_dim_multiplier"</span>]
<span>norm_eps</span> <span>=</span> <span>config</span>[<span>"norm_eps"</span>]
<span>rope_theta</span> <span>=</span> <span>torch</span>.<span>tensor</span>(<span>config</span>[<span>"rope_theta"</span>])</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">converting text to tokens</h2><a id="user-content-converting-text-to-tokens" aria-label="Permalink: converting text to tokens" href="#converting-text-to-tokens"></a></p>
<p dir="auto">here we use tiktoken (i think an openai library) as the tokenizer</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/tokens.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/tokens.png" width="600"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="prompt = &quot;the answer to the ultimate question of life, the universe, and everything is &quot;
tokens = [128000] + tokenizer.encode(prompt)
print(tokens)
tokens = torch.tensor(tokens)
prompt_split_as_tokens = [tokenizer.decode([token.item()]) for token in tokens]
print(prompt_split_as_tokens)"><pre><span>prompt</span> <span>=</span> <span>"the answer to the ultimate question of life, the universe, and everything is "</span>
<span>tokens</span> <span>=</span> [<span>128000</span>] <span>+</span> <span>tokenizer</span>.<span>encode</span>(<span>prompt</span>)
<span>print</span>(<span>tokens</span>)
<span>tokens</span> <span>=</span> <span>torch</span>.<span>tensor</span>(<span>tokens</span>)
<span>prompt_split_as_tokens</span> <span>=</span> [<span>tokenizer</span>.<span>decode</span>([<span>token</span>.<span>item</span>()]) <span>for</span> <span>token</span> <span>in</span> <span>tokens</span>]
<span>print</span>(<span>prompt_split_as_tokens</span>)</pre></div>
<div data-snippet-clipboard-copy-content="[128000, 1820, 4320, 311, 279, 17139, 3488, 315, 2324, 11, 279, 15861, 11, 323, 4395, 374, 220]
['<|begin_of_text|>', 'the', ' answer', ' to', ' the', ' ultimate', ' question', ' of', ' life', ',', ' the', ' universe', ',', ' and', ' everything', ' is', ' ']"><pre><code>[128000, 1820, 4320, 311, 279, 17139, 3488, 315, 2324, 11, 279, 15861, 11, 323, 4395, 374, 220]
['&lt;|begin_of_text|&gt;', 'the', ' answer', ' to', ' the', ' ultimate', ' question', ' of', ' life', ',', ' the', ' universe', ',', ' and', ' everything', ' is', ' ']
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">converting tokens to their embedding</h2><a id="user-content-converting-tokens-to-their-embedding" aria-label="Permalink: converting tokens to their embedding" href="#converting-tokens-to-their-embedding"></a></p>
<div dir="auto"><p>IM SORRY but this is the only part of the codebase where i use an inbuilt neural network module
<br>
anyway, so our [17x1] tokens are now [17x4096], i.e. 17 embeddings (one for each token) of length 4096
</p><p>

note: keep track of the shapes, it makes it much easier to understand everything</p></div>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/embeddings.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/embeddings.png" width="600"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="embedding_layer = torch.nn.Embedding(vocab_size, dim)
embedding_layer.weight.data.copy_(model[&quot;tok_embeddings.weight&quot;])
token_embeddings_unnormalized = embedding_layer(tokens).to(torch.bfloat16)
token_embeddings_unnormalized.shape"><pre><span>embedding_layer</span> <span>=</span> <span>torch</span>.<span>nn</span>.<span>Embedding</span>(<span>vocab_size</span>, <span>dim</span>)
<span>embedding_layer</span>.<span>weight</span>.<span>data</span>.<span>copy_</span>(<span>model</span>[<span>"tok_embeddings.weight"</span>])
<span>token_embeddings_unnormalized</span> <span>=</span> <span>embedding_layer</span>(<span>tokens</span>).<span>to</span>(<span>torch</span>.<span>bfloat16</span>)
<span>token_embeddings_unnormalized</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">we then normalize the embedding using rms normalization</h2><a id="user-content-we-then-normalize-the-embedding-using-rms-normalization" aria-label="Permalink: we then normalize the embedding using rms normalization" href="#we-then-normalize-the-embedding-using-rms-normalization"></a></p>
<p dir="auto">please, note after this step the shapes dont change, the values are just normalized
<br>
things to keep in mind, we need a norm_eps (from config) because we dont want to accidently set rms to 0 and divide by 0
<br>
here is the formula:</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/rms.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/rms.png" width="600"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="# def rms_norm(tensor, norm_weights):
#     rms = (tensor.pow(2).mean(-1, keepdim=True) + norm_eps)**0.5
#     return tensor * (norm_weights / rms)
def rms_norm(tensor, norm_weights):
    return (tensor * torch.rsqrt(tensor.pow(2).mean(-1, keepdim=True) + norm_eps)) * norm_weights"><pre><span># def rms_norm(tensor, norm_weights):</span>
<span>#     rms = (tensor.pow(2).mean(-1, keepdim=True) + norm_eps)**0.5</span>
<span>#     return tensor * (norm_weights / rms)</span>
<span>def</span> <span>rms_norm</span>(<span>tensor</span>, <span>norm_weights</span>):
    <span>return</span> (<span>tensor</span> <span>*</span> <span>torch</span>.<span>rsqrt</span>(<span>tensor</span>.<span>pow</span>(<span>2</span>).<span>mean</span>(<span>-</span><span>1</span>, <span>keepdim</span><span>=</span><span>True</span>) <span>+</span> <span>norm_eps</span>)) <span>*</span> <span>norm_weights</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">building the first first layer of the transformer</h2><a id="user-content-building-the-first-first-layer-of-the-transformer" aria-label="Permalink: building the first first layer of the transformer" href="#building-the-first-first-layer-of-the-transformer"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">normalization</h3><a id="user-content-normalization" aria-label="Permalink: normalization" href="#normalization"></a></p>
<p dir="auto">you will see me accessing layer.0 from the model dict (this is the first layer)
<br>
anyway, so after normalizing our shapes are still [17x4096] same as embedding but normalized</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/norm.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/norm.png" width="600"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="token_embeddings = rms_norm(token_embeddings_unnormalized, model[&quot;layers.0.attention_norm.weight&quot;])
token_embeddings.shape"><pre><span>token_embeddings</span> <span>=</span> <span>rms_norm</span>(<span>token_embeddings_unnormalized</span>, <span>model</span>[<span>"layers.0.attention_norm.weight"</span>])
<span>token_embeddings</span>.<span>shape</span></pre></div>

<p dir="auto"><h3 tabindex="-1" dir="auto">attention implemented from scratch</h3><a id="user-content-attention-implemented-from-scratch" aria-label="Permalink: attention implemented from scratch" href="#attention-implemented-from-scratch"></a></p>
<p dir="auto">let's load the attention heads of the first layer of the transformer</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/qkv.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/qkv.png" width="600"></a>
</p>

<p dir="auto">&gt; when we load the query, key, value and output vectors from the model we notice the shapes to be [4096x4096], [1024x4096], [1024x4096], [4096x4096]
<br>
&gt; at first glance this is weird because ideally we want each q,k,v and o for each head individually
<br>
&gt; the authors of the code bundled them togeather because its easy it helps parallize attention head multiplication.
<br>
&gt; im going to unwrap everything...</p>
<div dir="auto" data-snippet-clipboard-copy-content="print(
    model[&quot;layers.0.attention.wq.weight&quot;].shape,
    model[&quot;layers.0.attention.wk.weight&quot;].shape,
    model[&quot;layers.0.attention.wv.weight&quot;].shape,
    model[&quot;layers.0.attention.wo.weight&quot;].shape
)"><pre><span>print</span>(
    <span>model</span>[<span>"layers.0.attention.wq.weight"</span>].<span>shape</span>,
    <span>model</span>[<span>"layers.0.attention.wk.weight"</span>].<span>shape</span>,
    <span>model</span>[<span>"layers.0.attention.wv.weight"</span>].<span>shape</span>,
    <span>model</span>[<span>"layers.0.attention.wo.weight"</span>].<span>shape</span>
)</pre></div>
<div data-snippet-clipboard-copy-content="torch.Size([4096, 4096]) torch.Size([1024, 4096]) torch.Size([1024, 4096]) torch.Size([4096, 4096])"><pre><code>torch.Size([4096, 4096]) torch.Size([1024, 4096]) torch.Size([1024, 4096]) torch.Size([4096, 4096])
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">unwrapping query</h3><a id="user-content-unwrapping-query" aria-label="Permalink: unwrapping query" href="#unwrapping-query"></a></p>
<div dir="auto"><p>in the next section we will unwrap the queries from multiple attention heads, the resulting shape is [32x128x4096]
</p><p>
here, 32 is the number of attention heads in llama3, 128 is the size of the query vector and 4096 is the size of the token embedding</p></div>
<div dir="auto" data-snippet-clipboard-copy-content="q_layer0 = model[&quot;layers.0.attention.wq.weight&quot;]
head_dim = q_layer0.shape[0] // n_heads
q_layer0 = q_layer0.view(n_heads, head_dim, dim)
q_layer0.shape"><pre><span>q_layer0</span> <span>=</span> <span>model</span>[<span>"layers.0.attention.wq.weight"</span>]
<span>head_dim</span> <span>=</span> <span>q_layer0</span>.<span>shape</span>[<span>0</span>] <span>//</span> <span>n_heads</span>
<span>q_layer0</span> <span>=</span> <span>q_layer0</span>.<span>view</span>(<span>n_heads</span>, <span>head_dim</span>, <span>dim</span>)
<span>q_layer0</span>.<span>shape</span></pre></div>
<div data-snippet-clipboard-copy-content="torch.Size([32, 128, 4096])"><pre><code>torch.Size([32, 128, 4096])
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">im going to implement the first head of the first layer</h3><a id="user-content-im-going-to-implement-the-first-head-of-the-first-layer" aria-label="Permalink: im going to implement the first head of the first layer" href="#im-going-to-implement-the-first-head-of-the-first-layer"></a></p>
<p dir="auto">here i access the query weight matrix first head of the first layer, the size of this query weight matrix is [128x4096]</p>
<div dir="auto" data-snippet-clipboard-copy-content="q_layer0_head0 = q_layer0[0]
q_layer0_head0.shape"><pre><span>q_layer0_head0</span> <span>=</span> <span>q_layer0</span>[<span>0</span>]
<span>q_layer0_head0</span>.<span>shape</span></pre></div>

<p dir="auto"><h3 tabindex="-1" dir="auto">we now multiply the query weights with the token embedding, to recive a query for the token</h3><a id="user-content-we-now-multiply-the-query-weights-with-the-token-embedding-to-recive-a-query-for-the-token" aria-label="Permalink: we now multiply the query weights with the token embedding, to recive a query for the token" href="#we-now-multiply-the-query-weights-with-the-token-embedding-to-recive-a-query-for-the-token"></a></p>
<p dir="auto">here you can see the resulting shape is [17x128], this is because we have 17 tokens and for each token there is a 128 length query.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/q_per_token.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/q_per_token.png" width="600"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="q_per_token = torch.matmul(token_embeddings, q_layer0_head0.T)
q_per_token.shape"><pre><span>q_per_token</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>token_embeddings</span>, <span>q_layer0_head0</span>.<span>T</span>)
<span>q_per_token</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">positioning encoding</h2><a id="user-content-positioning-encoding" aria-label="Permalink: positioning encoding" href="#positioning-encoding"></a></p>
<div dir="auto"><p>we are now at a stage where we have a query vector for each token in our prompt, but if you think about it -- the indivitually query vector has no idea about the position in the prompt.
</p><p>
query: "the answer to the ultimate question of life, the universe, and everything is "
</p><p>
in our prompt we have used "the" three times, we need the query vectors of all 3 "the" tokens to have different query vectors (each of size [1x128]) based on their positions in the query. we perform these rotations using RoPE (rotory positional embedding).
</p></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">RoPE</h3><a id="user-content-rope" aria-label="Permalink: RoPE" href="#rope"></a></p>
<p dir="auto">watch this video (this is what i watched) to understand the math.
<a href="https://www.youtube.com/watch?v=o29P0Kpobz0&amp;t=530s" rel="nofollow">https://www.youtube.com/watch?v=o29P0Kpobz0&amp;t=530s</a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/rope.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/rope.png" width="600"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="q_per_token_split_into_pairs = q_per_token.float().view(q_per_token.shape[0], -1, 2)
q_per_token_split_into_pairs.shape"><pre><span>q_per_token_split_into_pairs</span> <span>=</span> <span>q_per_token</span>.<span>float</span>().<span>view</span>(<span>q_per_token</span>.<span>shape</span>[<span>0</span>], <span>-</span><span>1</span>, <span>2</span>)
<span>q_per_token_split_into_pairs</span>.<span>shape</span></pre></div>

<div dir="auto"><p>in the above step, we split the query vectors into pairs, we apply a rotational angle shift to each pair!
</p><p>
we now have a vector of size [17x64x2], this is the 128 length queries split into 64 pairs for each token in the prompt! each of those 64 pairs will be rotated by m*(theta) where m is the position of the token for which we are rotating the query!</p></div>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/qsplit.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/qsplit.png" width="600"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">using dot product of complex numbers to rotate a vector</h2><a id="user-content-using-dot-product-of-complex-numbers-to-rotate-a-vector" aria-label="Permalink: using dot product of complex numbers to rotate a vector" href="#using-dot-product-of-complex-numbers-to-rotate-a-vector"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/freq_cis.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/freq_cis.png" width="600"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="zero_to_one_split_into_64_parts = torch.tensor(range(64))/64
zero_to_one_split_into_64_parts"><pre><span>zero_to_one_split_into_64_parts</span> <span>=</span> <span>torch</span>.<span>tensor</span>(<span>range</span>(<span>64</span>))<span>/</span><span>64</span>
<span>zero_to_one_split_into_64_parts</span></pre></div>
<div data-snippet-clipboard-copy-content="tensor([0.0000, 0.0156, 0.0312, 0.0469, 0.0625, 0.0781, 0.0938, 0.1094, 0.1250,
        0.1406, 0.1562, 0.1719, 0.1875, 0.2031, 0.2188, 0.2344, 0.2500, 0.2656,
        0.2812, 0.2969, 0.3125, 0.3281, 0.3438, 0.3594, 0.3750, 0.3906, 0.4062,
        0.4219, 0.4375, 0.4531, 0.4688, 0.4844, 0.5000, 0.5156, 0.5312, 0.5469,
        0.5625, 0.5781, 0.5938, 0.6094, 0.6250, 0.6406, 0.6562, 0.6719, 0.6875,
        0.7031, 0.7188, 0.7344, 0.7500, 0.7656, 0.7812, 0.7969, 0.8125, 0.8281,
        0.8438, 0.8594, 0.8750, 0.8906, 0.9062, 0.9219, 0.9375, 0.9531, 0.9688,
        0.9844])"><pre><code>tensor([0.0000, 0.0156, 0.0312, 0.0469, 0.0625, 0.0781, 0.0938, 0.1094, 0.1250,
        0.1406, 0.1562, 0.1719, 0.1875, 0.2031, 0.2188, 0.2344, 0.2500, 0.2656,
        0.2812, 0.2969, 0.3125, 0.3281, 0.3438, 0.3594, 0.3750, 0.3906, 0.4062,
        0.4219, 0.4375, 0.4531, 0.4688, 0.4844, 0.5000, 0.5156, 0.5312, 0.5469,
        0.5625, 0.5781, 0.5938, 0.6094, 0.6250, 0.6406, 0.6562, 0.6719, 0.6875,
        0.7031, 0.7188, 0.7344, 0.7500, 0.7656, 0.7812, 0.7969, 0.8125, 0.8281,
        0.8438, 0.8594, 0.8750, 0.8906, 0.9062, 0.9219, 0.9375, 0.9531, 0.9688,
        0.9844])
</code></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="freqs = 1.0 / (rope_theta ** zero_to_one_split_into_64_parts)
freqs"><pre><span>freqs</span> <span>=</span> <span>1.0</span> <span>/</span> (<span>rope_theta</span> <span>**</span> <span>zero_to_one_split_into_64_parts</span>)
<span>freqs</span></pre></div>
<div data-snippet-clipboard-copy-content="tensor([1.0000e+00, 8.1462e-01, 6.6360e-01, 5.4058e-01, 4.4037e-01, 3.5873e-01,
        2.9223e-01, 2.3805e-01, 1.9392e-01, 1.5797e-01, 1.2869e-01, 1.0483e-01,
        8.5397e-02, 6.9566e-02, 5.6670e-02, 4.6164e-02, 3.7606e-02, 3.0635e-02,
        2.4955e-02, 2.0329e-02, 1.6560e-02, 1.3490e-02, 1.0990e-02, 8.9523e-03,
        7.2927e-03, 5.9407e-03, 4.8394e-03, 3.9423e-03, 3.2114e-03, 2.6161e-03,
        2.1311e-03, 1.7360e-03, 1.4142e-03, 1.1520e-03, 9.3847e-04, 7.6450e-04,
        6.2277e-04, 5.0732e-04, 4.1327e-04, 3.3666e-04, 2.7425e-04, 2.2341e-04,
        1.8199e-04, 1.4825e-04, 1.2077e-04, 9.8381e-05, 8.0143e-05, 6.5286e-05,
        5.3183e-05, 4.3324e-05, 3.5292e-05, 2.8750e-05, 2.3420e-05, 1.9078e-05,
        1.5542e-05, 1.2660e-05, 1.0313e-05, 8.4015e-06, 6.8440e-06, 5.5752e-06,
        4.5417e-06, 3.6997e-06, 3.0139e-06, 2.4551e-06])"><pre><code>tensor([1.0000e+00, 8.1462e-01, 6.6360e-01, 5.4058e-01, 4.4037e-01, 3.5873e-01,
        2.9223e-01, 2.3805e-01, 1.9392e-01, 1.5797e-01, 1.2869e-01, 1.0483e-01,
        8.5397e-02, 6.9566e-02, 5.6670e-02, 4.6164e-02, 3.7606e-02, 3.0635e-02,
        2.4955e-02, 2.0329e-02, 1.6560e-02, 1.3490e-02, 1.0990e-02, 8.9523e-03,
        7.2927e-03, 5.9407e-03, 4.8394e-03, 3.9423e-03, 3.2114e-03, 2.6161e-03,
        2.1311e-03, 1.7360e-03, 1.4142e-03, 1.1520e-03, 9.3847e-04, 7.6450e-04,
        6.2277e-04, 5.0732e-04, 4.1327e-04, 3.3666e-04, 2.7425e-04, 2.2341e-04,
        1.8199e-04, 1.4825e-04, 1.2077e-04, 9.8381e-05, 8.0143e-05, 6.5286e-05,
        5.3183e-05, 4.3324e-05, 3.5292e-05, 2.8750e-05, 2.3420e-05, 1.9078e-05,
        1.5542e-05, 1.2660e-05, 1.0313e-05, 8.4015e-06, 6.8440e-06, 5.5752e-06,
        4.5417e-06, 3.6997e-06, 3.0139e-06, 2.4551e-06])
</code></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="freqs_for_each_token = torch.outer(torch.arange(17), freqs)
freqs_cis = torch.polar(torch.ones_like(freqs_for_each_token), freqs_for_each_token)
freqs_cis.shape

# viewing tjhe third row of freqs_cis
value = freqs_cis[3]
plt.figure()
for i, element in enumerate(value[:17]):
    plt.plot([0, element.real], [0, element.imag], color='blue', linewidth=1, label=f&quot;Index: {i}&quot;)
    plt.annotate(f&quot;{i}&quot;, xy=(element.real, element.imag), color='red')
plt.xlabel('Real')
plt.ylabel('Imaginary')
plt.title('Plot of one row of freqs_cis')
plt.show()"><pre><span>freqs_for_each_token</span> <span>=</span> <span>torch</span>.<span>outer</span>(<span>torch</span>.<span>arange</span>(<span>17</span>), <span>freqs</span>)
<span>freqs_cis</span> <span>=</span> <span>torch</span>.<span>polar</span>(<span>torch</span>.<span>ones_like</span>(<span>freqs_for_each_token</span>), <span>freqs_for_each_token</span>)
<span>freqs_cis</span>.<span>shape</span>

<span># viewing tjhe third row of freqs_cis</span>
<span>value</span> <span>=</span> <span>freqs_cis</span>[<span>3</span>]
<span>plt</span>.<span>figure</span>()
<span>for</span> <span>i</span>, <span>element</span> <span>in</span> <span>enumerate</span>(<span>value</span>[:<span>17</span>]):
    <span>plt</span>.<span>plot</span>([<span>0</span>, <span>element</span>.<span>real</span>], [<span>0</span>, <span>element</span>.<span>imag</span>], <span>color</span><span>=</span><span>'blue'</span>, <span>linewidth</span><span>=</span><span>1</span>, <span>label</span><span>=</span><span>f"Index: <span><span>{</span><span>i</span><span>}</span></span>"</span>)
    <span>plt</span>.<span>annotate</span>(<span>f"<span><span>{</span><span>i</span><span>}</span></span>"</span>, <span>xy</span><span>=</span>(<span>element</span>.<span>real</span>, <span>element</span>.<span>imag</span>), <span>color</span><span>=</span><span>'red'</span>)
<span>plt</span>.<span>xlabel</span>(<span>'Real'</span>)
<span>plt</span>.<span>ylabel</span>(<span>'Imaginary'</span>)
<span>plt</span>.<span>title</span>(<span>'Plot of one row of freqs_cis'</span>)
<span>plt</span>.<span>show</span>()</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/implllama3_30_0.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/implllama3_30_0.png" alt="png"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">now that we have a complex number (the angle change vector) for every token's query element</h3><a id="user-content-now-that-we-have-a-complex-number-the-angle-change-vector-for-every-tokens-query-element" aria-label="Permalink: now that we have a complex number (the angle change vector) for every token's query element" href="#now-that-we-have-a-complex-number-the-angle-change-vector-for-every-tokens-query-element"></a></p>
<p dir="auto">we can convert our queries (the one we split into pairs) as complex numbers and then dot product to rotate the query based on the position
<br>
honeslty this is beautiful to think about :)</p>
<div dir="auto" data-snippet-clipboard-copy-content="q_per_token_as_complex_numbers = torch.view_as_complex(q_per_token_split_into_pairs)
q_per_token_as_complex_numbers.shape"><pre><span>q_per_token_as_complex_numbers</span> <span>=</span> <span>torch</span>.<span>view_as_complex</span>(<span>q_per_token_split_into_pairs</span>)
<span>q_per_token_as_complex_numbers</span>.<span>shape</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="q_per_token_as_complex_numbers_rotated = q_per_token_as_complex_numbers * freqs_cis
q_per_token_as_complex_numbers_rotated.shape"><pre><span>q_per_token_as_complex_numbers_rotated</span> <span>=</span> <span>q_per_token_as_complex_numbers</span> <span>*</span> <span>freqs_cis</span>
<span>q_per_token_as_complex_numbers_rotated</span>.<span>shape</span></pre></div>

<p dir="auto"><h3 tabindex="-1" dir="auto">after rotated vector is obtained</h3><a id="user-content-after-rotated-vector-is-obtained" aria-label="Permalink: after rotated vector is obtained" href="#after-rotated-vector-is-obtained"></a></p>
<p dir="auto">we can get back our the queries as pairs by viewing the complex numbers as real numbers again</p>
<div dir="auto" data-snippet-clipboard-copy-content="q_per_token_split_into_pairs_rotated = torch.view_as_real(q_per_token_as_complex_numbers_rotated)
q_per_token_split_into_pairs_rotated.shape"><pre><span>q_per_token_split_into_pairs_rotated</span> <span>=</span> <span>torch</span>.<span>view_as_real</span>(<span>q_per_token_as_complex_numbers_rotated</span>)
<span>q_per_token_split_into_pairs_rotated</span>.<span>shape</span></pre></div>

<p dir="auto">the rotated pairs are now merged, we now have a new query vector (rotated query vector) that is of the shape [17x128] where 17 is the number of tokens and the 128 is the dim of the query vector</p>
<div dir="auto" data-snippet-clipboard-copy-content="q_per_token_rotated = q_per_token_split_into_pairs_rotated.view(q_per_token.shape)
q_per_token_rotated.shape"><pre><span>q_per_token_rotated</span> <span>=</span> <span>q_per_token_split_into_pairs_rotated</span>.<span>view</span>(<span>q_per_token</span>.<span>shape</span>)
<span>q_per_token_rotated</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">keys (almost the same as queries)</h2><a id="user-content-keys-almost-the-same-as-queries" aria-label="Permalink: keys (almost the same as queries)" href="#keys-almost-the-same-as-queries"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/keys.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/keys.png" width="600px"></a>
</p>
im lazy as fuck, so im not going to go through the math for keys, the only things you need to keep in mind are:
<br>
&gt; keys generate key vectors also of dimention 128
<br>
&gt; keys have only 1/4th the number of the weights as queries, this is because the weights for keys are shared across 4 heads at a time, to reduce the number of computations need
<br>
&gt; keys are also rotated to add positional info, just like queries because of the same reasons 
<div dir="auto" data-snippet-clipboard-copy-content="k_layer0 = model[&quot;layers.0.attention.wk.weight&quot;]
k_layer0 = k_layer0.view(n_kv_heads, k_layer0.shape[0] // n_kv_heads, dim)
k_layer0.shape"><pre><span>k_layer0</span> <span>=</span> <span>model</span>[<span>"layers.0.attention.wk.weight"</span>]
<span>k_layer0</span> <span>=</span> <span>k_layer0</span>.<span>view</span>(<span>n_kv_heads</span>, <span>k_layer0</span>.<span>shape</span>[<span>0</span>] <span>//</span> <span>n_kv_heads</span>, <span>dim</span>)
<span>k_layer0</span>.<span>shape</span></pre></div>
<div data-snippet-clipboard-copy-content="torch.Size([8, 128, 4096])"><pre><code>torch.Size([8, 128, 4096])
</code></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="k_layer0_head0 = k_layer0[0]
k_layer0_head0.shape"><pre><span>k_layer0_head0</span> <span>=</span> <span>k_layer0</span>[<span>0</span>]
<span>k_layer0_head0</span>.<span>shape</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="k_per_token = torch.matmul(token_embeddings, k_layer0_head0.T)
k_per_token.shape"><pre><span>k_per_token</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>token_embeddings</span>, <span>k_layer0_head0</span>.<span>T</span>)
<span>k_per_token</span>.<span>shape</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="k_per_token_split_into_pairs = k_per_token.float().view(k_per_token.shape[0], -1, 2)
k_per_token_split_into_pairs.shape"><pre><span>k_per_token_split_into_pairs</span> <span>=</span> <span>k_per_token</span>.<span>float</span>().<span>view</span>(<span>k_per_token</span>.<span>shape</span>[<span>0</span>], <span>-</span><span>1</span>, <span>2</span>)
<span>k_per_token_split_into_pairs</span>.<span>shape</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="k_per_token_as_complex_numbers = torch.view_as_complex(k_per_token_split_into_pairs)
k_per_token_as_complex_numbers.shape"><pre><span>k_per_token_as_complex_numbers</span> <span>=</span> <span>torch</span>.<span>view_as_complex</span>(<span>k_per_token_split_into_pairs</span>)
<span>k_per_token_as_complex_numbers</span>.<span>shape</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="k_per_token_split_into_pairs_rotated = torch.view_as_real(k_per_token_as_complex_numbers * freqs_cis)
k_per_token_split_into_pairs_rotated.shape"><pre><span>k_per_token_split_into_pairs_rotated</span> <span>=</span> <span>torch</span>.<span>view_as_real</span>(<span>k_per_token_as_complex_numbers</span> <span>*</span> <span>freqs_cis</span>)
<span>k_per_token_split_into_pairs_rotated</span>.<span>shape</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="k_per_token_rotated = k_per_token_split_into_pairs_rotated.view(k_per_token.shape)
k_per_token_rotated.shape"><pre><span>k_per_token_rotated</span> <span>=</span> <span>k_per_token_split_into_pairs_rotated</span>.<span>view</span>(<span>k_per_token</span>.<span>shape</span>)
<span>k_per_token_rotated</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">at this stage now have both the rotated values of queries and keys, for each token.</h2><a id="user-content-at-this-stage-now-have-both-the-rotated-values-of-queries-and-keys-for-each-token" aria-label="Permalink: at this stage now have both the rotated values of queries and keys, for each token." href="#at-this-stage-now-have-both-the-rotated-values-of-queries-and-keys-for-each-token"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/keys0.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/keys0.png" width="600px"></a>
</p>
each of the queries and keys are now of shape [17x128]. 
<p dir="auto"><h2 tabindex="-1" dir="auto">in the next step we will multiply the queries and key matrices</h2><a id="user-content-in-the-next-step-we-will-multiply-the-queries-and-key-matrices" aria-label="Permalink: in the next step we will multiply the queries and key matrices" href="#in-the-next-step-we-will-multiply-the-queries-and-key-matrices"></a></p>
<p dir="auto">doing this will give us a score mapping each token with one another
<br>
this score describes how well each token's query relates to the each tokens's key.
THIS IS SELF ATTENTION :)
<br>
the shape of the attention score matrix (qk_per_token) is [17x17] where 17 is the number of tokens in the prompt</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/qkmatmul.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/qkmatmul.png" width="600px"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="qk_per_token = torch.matmul(q_per_token_rotated, k_per_token_rotated.T)/(head_dim)**0.5
qk_per_token.shape"><pre><span>qk_per_token</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>q_per_token_rotated</span>, <span>k_per_token_rotated</span>.<span>T</span>)<span>/</span>(<span>head_dim</span>)<span>**</span><span>0.5</span>
<span>qk_per_token</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">we now have to mask query key scores</h2><a id="user-content-we-now-have-to-mask-query-key-scores" aria-label="Permalink: we now have to mask query key scores" href="#we-now-have-to-mask-query-key-scores"></a></p>
<p dir="auto">during the training process of llama3, the future token qk scores are masked.
<br>
why? because during training we only learn to predict tokens using past tokens.
<br>
as a result, during inference we set the future tokens to zero.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/mask.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/mask.png" width="600px"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="def display_qk_heatmap(qk_per_token):
    _, ax = plt.subplots()
    im = ax.imshow(qk_per_token.to(float).detach(), cmap='viridis')
    ax.set_xticks(range(len(prompt_split_as_tokens)))
    ax.set_yticks(range(len(prompt_split_as_tokens)))
    ax.set_xticklabels(prompt_split_as_tokens)
    ax.set_yticklabels(prompt_split_as_tokens)
    ax.figure.colorbar(im, ax=ax)
    
display_qk_heatmap(qk_per_token)"><pre><span>def</span> <span>display_qk_heatmap</span>(<span>qk_per_token</span>):
    <span>_</span>, <span>ax</span> <span>=</span> <span>plt</span>.<span>subplots</span>()
    <span>im</span> <span>=</span> <span>ax</span>.<span>imshow</span>(<span>qk_per_token</span>.<span>to</span>(<span>float</span>).<span>detach</span>(), <span>cmap</span><span>=</span><span>'viridis'</span>)
    <span>ax</span>.<span>set_xticks</span>(<span>range</span>(<span>len</span>(<span>prompt_split_as_tokens</span>)))
    <span>ax</span>.<span>set_yticks</span>(<span>range</span>(<span>len</span>(<span>prompt_split_as_tokens</span>)))
    <span>ax</span>.<span>set_xticklabels</span>(<span>prompt_split_as_tokens</span>)
    <span>ax</span>.<span>set_yticklabels</span>(<span>prompt_split_as_tokens</span>)
    <span>ax</span>.<span>figure</span>.<span>colorbar</span>(<span>im</span>, <span>ax</span><span>=</span><span>ax</span>)
    
<span>display_qk_heatmap</span>(<span>qk_per_token</span>)</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/implllama3_50_0.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/implllama3_50_0.png" alt="png"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="mask = torch.full((len(tokens), len(tokens)), float(&quot;-inf&quot;), device=tokens.device)
mask = torch.triu(mask, diagonal=1)
mask"><pre><span>mask</span> <span>=</span> <span>torch</span>.<span>full</span>((<span>len</span>(<span>tokens</span>), <span>len</span>(<span>tokens</span>)), <span>float</span>(<span>"-inf"</span>), <span>device</span><span>=</span><span>tokens</span>.<span>device</span>)
<span>mask</span> <span>=</span> <span>torch</span>.<span>triu</span>(<span>mask</span>, <span>diagonal</span><span>=</span><span>1</span>)
<span>mask</span></pre></div>
<div data-snippet-clipboard-copy-content="tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"><pre><code>tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
</code></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="qk_per_token_after_masking = qk_per_token + mask
display_qk_heatmap(qk_per_token_after_masking)"><pre><span>qk_per_token_after_masking</span> <span>=</span> <span>qk_per_token</span> <span>+</span> <span>mask</span>
<span>display_qk_heatmap</span>(<span>qk_per_token_after_masking</span>)</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/implllama3_52_0.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/implllama3_52_0.png" alt="png"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/softmax.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/softmax.png" width="600px"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="qk_per_token_after_masking_after_softmax = torch.nn.functional.softmax(qk_per_token_after_masking, dim=1).to(torch.bfloat16)
display_qk_heatmap(qk_per_token_after_masking_after_softmax)"><pre><span>qk_per_token_after_masking_after_softmax</span> <span>=</span> <span>torch</span>.<span>nn</span>.<span>functional</span>.<span>softmax</span>(<span>qk_per_token_after_masking</span>, <span>dim</span><span>=</span><span>1</span>).<span>to</span>(<span>torch</span>.<span>bfloat16</span>)
<span>display_qk_heatmap</span>(<span>qk_per_token_after_masking_after_softmax</span>)</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/implllama3_54_0.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/implllama3_54_0.png" alt="png"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">values (almost the end of attention)</h2><a id="user-content-values-almost-the-end-of-attention" aria-label="Permalink: values (almost the end of attention)" href="#values-almost-the-end-of-attention"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/value.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/value.png" width="600px"></a>
</p>
these scores (0-1) are used to determine how much of value matrix is used per token
<br>
&gt; just like keys, value weights are also shared acorss every 4 attention heads (to save computation)
<br>
&gt; as a result, the shape of the value weight matrix below is [8x128x4096]
<div dir="auto" data-snippet-clipboard-copy-content="v_layer0 = model[&quot;layers.0.attention.wv.weight&quot;]
v_layer0 = v_layer0.view(n_kv_heads, v_layer0.shape[0] // n_kv_heads, dim)
v_layer0.shape"><pre><span>v_layer0</span> <span>=</span> <span>model</span>[<span>"layers.0.attention.wv.weight"</span>]
<span>v_layer0</span> <span>=</span> <span>v_layer0</span>.<span>view</span>(<span>n_kv_heads</span>, <span>v_layer0</span>.<span>shape</span>[<span>0</span>] <span>//</span> <span>n_kv_heads</span>, <span>dim</span>)
<span>v_layer0</span>.<span>shape</span></pre></div>
<div data-snippet-clipboard-copy-content="torch.Size([8, 128, 4096])"><pre><code>torch.Size([8, 128, 4096])
</code></pre></div>
<p dir="auto">the first layer, first head value weight matrix is given below</p>
<div dir="auto" data-snippet-clipboard-copy-content="v_layer0_head0 = v_layer0[0]
v_layer0_head0.shape"><pre><span>v_layer0_head0</span> <span>=</span> <span>v_layer0</span>[<span>0</span>]
<span>v_layer0_head0</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">value vectors</h2><a id="user-content-value-vectors" aria-label="Permalink: value vectors" href="#value-vectors"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/v0.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/v0.png" width="600px"></a>
</p>
we now use the value weghts to get the attention values per token, this is of size [17x128] where 17 is the number of tokens in the prompt and 128 is the dim of the value vector per token
<div dir="auto" data-snippet-clipboard-copy-content="v_per_token = torch.matmul(token_embeddings, v_layer0_head0.T)
v_per_token.shape"><pre><span>v_per_token</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>token_embeddings</span>, <span>v_layer0_head0</span>.<span>T</span>)
<span>v_per_token</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">attention</h2><a id="user-content-attention" aria-label="Permalink: attention" href="#attention"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/attention.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/attention.png" width="600px"></a>
</p>
the resultant attention vector after multipying with the values per token is of shape [17*128]
<div dir="auto" data-snippet-clipboard-copy-content="qkv_attention = torch.matmul(qk_per_token_after_masking_after_softmax, v_per_token)
qkv_attention.shape"><pre><span>qkv_attention</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>qk_per_token_after_masking_after_softmax</span>, <span>v_per_token</span>)
<span>qkv_attention</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">multi head attention</h2><a id="user-content-multi-head-attention" aria-label="Permalink: multi head attention" href="#multi-head-attention"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/heads.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/heads.png" width="600px"></a>
</p>
WE NOW HAVE THE ATTENTION VALUE OF THE FIRST LAYER AND FIRST HEAD
<br>
now im going to run a loop and perform the exact same math as the cells above but for every head in the first layer
<div dir="auto" data-snippet-clipboard-copy-content="qkv_attention_store = []

for head in range(n_heads):
    q_layer0_head = q_layer0[head]
    k_layer0_head = k_layer0[head//4] # key weights are shared across 4 heads
    v_layer0_head = v_layer0[head//4] # value weights are shared across 4 heads
    q_per_token = torch.matmul(token_embeddings, q_layer0_head.T)
    k_per_token = torch.matmul(token_embeddings, k_layer0_head.T)
    v_per_token = torch.matmul(token_embeddings, v_layer0_head.T)

    q_per_token_split_into_pairs = q_per_token.float().view(q_per_token.shape[0], -1, 2)
    q_per_token_as_complex_numbers = torch.view_as_complex(q_per_token_split_into_pairs)
    q_per_token_split_into_pairs_rotated = torch.view_as_real(q_per_token_as_complex_numbers * freqs_cis[:len(tokens)])
    q_per_token_rotated = q_per_token_split_into_pairs_rotated.view(q_per_token.shape)

    k_per_token_split_into_pairs = k_per_token.float().view(k_per_token.shape[0], -1, 2)
    k_per_token_as_complex_numbers = torch.view_as_complex(k_per_token_split_into_pairs)
    k_per_token_split_into_pairs_rotated = torch.view_as_real(k_per_token_as_complex_numbers * freqs_cis[:len(tokens)])
    k_per_token_rotated = k_per_token_split_into_pairs_rotated.view(k_per_token.shape)

    qk_per_token = torch.matmul(q_per_token_rotated, k_per_token_rotated.T)/(128)**0.5
    mask = torch.full((len(tokens), len(tokens)), float(&quot;-inf&quot;), device=tokens.device)
    mask = torch.triu(mask, diagonal=1)
    qk_per_token_after_masking = qk_per_token + mask
    qk_per_token_after_masking_after_softmax = torch.nn.functional.softmax(qk_per_token_after_masking, dim=1).to(torch.bfloat16)
    qkv_attention = torch.matmul(qk_per_token_after_masking_after_softmax, v_per_token)
    qkv_attention = torch.matmul(qk_per_token_after_masking_after_softmax, v_per_token)
    qkv_attention_store.append(qkv_attention)

len(qkv_attention_store)"><pre><span>qkv_attention_store</span> <span>=</span> []

<span>for</span> <span>head</span> <span>in</span> <span>range</span>(<span>n_heads</span>):
    <span>q_layer0_head</span> <span>=</span> <span>q_layer0</span>[<span>head</span>]
    <span>k_layer0_head</span> <span>=</span> <span>k_layer0</span>[<span>head</span><span>//</span><span>4</span>] <span># key weights are shared across 4 heads</span>
    <span>v_layer0_head</span> <span>=</span> <span>v_layer0</span>[<span>head</span><span>//</span><span>4</span>] <span># value weights are shared across 4 heads</span>
    <span>q_per_token</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>token_embeddings</span>, <span>q_layer0_head</span>.<span>T</span>)
    <span>k_per_token</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>token_embeddings</span>, <span>k_layer0_head</span>.<span>T</span>)
    <span>v_per_token</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>token_embeddings</span>, <span>v_layer0_head</span>.<span>T</span>)

    <span>q_per_token_split_into_pairs</span> <span>=</span> <span>q_per_token</span>.<span>float</span>().<span>view</span>(<span>q_per_token</span>.<span>shape</span>[<span>0</span>], <span>-</span><span>1</span>, <span>2</span>)
    <span>q_per_token_as_complex_numbers</span> <span>=</span> <span>torch</span>.<span>view_as_complex</span>(<span>q_per_token_split_into_pairs</span>)
    <span>q_per_token_split_into_pairs_rotated</span> <span>=</span> <span>torch</span>.<span>view_as_real</span>(<span>q_per_token_as_complex_numbers</span> <span>*</span> <span>freqs_cis</span>[:<span>len</span>(<span>tokens</span>)])
    <span>q_per_token_rotated</span> <span>=</span> <span>q_per_token_split_into_pairs_rotated</span>.<span>view</span>(<span>q_per_token</span>.<span>shape</span>)

    <span>k_per_token_split_into_pairs</span> <span>=</span> <span>k_per_token</span>.<span>float</span>().<span>view</span>(<span>k_per_token</span>.<span>shape</span>[<span>0</span>], <span>-</span><span>1</span>, <span>2</span>)
    <span>k_per_token_as_complex_numbers</span> <span>=</span> <span>torch</span>.<span>view_as_complex</span>(<span>k_per_token_split_into_pairs</span>)
    <span>k_per_token_split_into_pairs_rotated</span> <span>=</span> <span>torch</span>.<span>view_as_real</span>(<span>k_per_token_as_complex_numbers</span> <span>*</span> <span>freqs_cis</span>[:<span>len</span>(<span>tokens</span>)])
    <span>k_per_token_rotated</span> <span>=</span> <span>k_per_token_split_into_pairs_rotated</span>.<span>view</span>(<span>k_per_token</span>.<span>shape</span>)

    <span>qk_per_token</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>q_per_token_rotated</span>, <span>k_per_token_rotated</span>.<span>T</span>)<span>/</span>(<span>128</span>)<span>**</span><span>0.5</span>
    <span>mask</span> <span>=</span> <span>torch</span>.<span>full</span>((<span>len</span>(<span>tokens</span>), <span>len</span>(<span>tokens</span>)), <span>float</span>(<span>"-inf"</span>), <span>device</span><span>=</span><span>tokens</span>.<span>device</span>)
    <span>mask</span> <span>=</span> <span>torch</span>.<span>triu</span>(<span>mask</span>, <span>diagonal</span><span>=</span><span>1</span>)
    <span>qk_per_token_after_masking</span> <span>=</span> <span>qk_per_token</span> <span>+</span> <span>mask</span>
    <span>qk_per_token_after_masking_after_softmax</span> <span>=</span> <span>torch</span>.<span>nn</span>.<span>functional</span>.<span>softmax</span>(<span>qk_per_token_after_masking</span>, <span>dim</span><span>=</span><span>1</span>).<span>to</span>(<span>torch</span>.<span>bfloat16</span>)
    <span>qkv_attention</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>qk_per_token_after_masking_after_softmax</span>, <span>v_per_token</span>)
    <span>qkv_attention</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>qk_per_token_after_masking_after_softmax</span>, <span>v_per_token</span>)
    <span>qkv_attention_store</span>.<span>append</span>(<span>qkv_attention</span>)

<span>len</span>(<span>qkv_attention_store</span>)</pre></div>

<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/stacked.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/stacked.png" width="600px"></a>
</p>
we now have a the qkv_attention matrix for all 32 heads on the first layer, next im going to merge all attention scores into one large matrix of size [17x4096]
<br>
we are almost at the end :)
<div dir="auto" data-snippet-clipboard-copy-content="stacked_qkv_attention = torch.cat(qkv_attention_store, dim=-1)
stacked_qkv_attention.shape"><pre><span>stacked_qkv_attention</span> <span>=</span> <span>torch</span>.<span>cat</span>(<span>qkv_attention_store</span>, <span>dim</span><span>=</span><span>-</span><span>1</span>)
<span>stacked_qkv_attention</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">weight matrix, one of the final steps</h2><a id="user-content-weight-matrix-one-of-the-final-steps" aria-label="Permalink: weight matrix, one of the final steps" href="#weight-matrix-one-of-the-final-steps"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/weightmatrix.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/weightmatrix.png" width="600px"></a>
</p>
one of the last things to do for a layer 0 attention is, is to multiply the weight matrix of the 
<div dir="auto" data-snippet-clipboard-copy-content="w_layer0 = model[&quot;layers.0.attention.wo.weight&quot;]
w_layer0.shape"><pre><span>w_layer0</span> <span>=</span> <span>model</span>[<span>"layers.0.attention.wo.weight"</span>]
<span>w_layer0</span>.<span>shape</span></pre></div>

<p dir="auto"><h3 tabindex="-1" dir="auto">this is a simple linear layer, so we just matmul</h3><a id="user-content-this-is-a-simple-linear-layer-so-we-just-matmul" aria-label="Permalink: this is a simple linear layer, so we just matmul" href="#this-is-a-simple-linear-layer-so-we-just-matmul"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="embedding_delta = torch.matmul(stacked_qkv_attention, w_layer0.T)
embedding_delta.shape"><pre><span>embedding_delta</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>stacked_qkv_attention</span>, <span>w_layer0</span>.<span>T</span>)
<span>embedding_delta</span>.<span>shape</span></pre></div>

<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/afterattention.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/afterattention.png" width="600px"></a>
</p>
we now have the change in the embedding value after attention, that should be adding to the original token embeddings
<div dir="auto" data-snippet-clipboard-copy-content="embedding_after_edit = token_embeddings_unnormalized + embedding_delta
embedding_after_edit.shape"><pre><span>embedding_after_edit</span> <span>=</span> <span>token_embeddings_unnormalized</span> <span>+</span> <span>embedding_delta</span>
<span>embedding_after_edit</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">we normalize and then run a feed forward neural network through the embedding delta</h2><a id="user-content-we-normalize-and-then-run-a-feed-forward-neural-network-through-the-embedding-delta" aria-label="Permalink: we normalize and then run a feed forward neural network through the embedding delta" href="#we-normalize-and-then-run-a-feed-forward-neural-network-through-the-embedding-delta"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/norm_after.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/norm_after.png" width="600px"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="embedding_after_edit_normalized = rms_norm(embedding_after_edit, model[&quot;layers.0.ffn_norm.weight&quot;])
embedding_after_edit_normalized.shape"><pre><span>embedding_after_edit_normalized</span> <span>=</span> <span>rms_norm</span>(<span>embedding_after_edit</span>, <span>model</span>[<span>"layers.0.ffn_norm.weight"</span>])
<span>embedding_after_edit_normalized</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">loading the ff weights and implementing the feed forward network</h2><a id="user-content-loading-the-ff-weights-and-implementing-the-feed-forward-network" aria-label="Permalink: loading the ff weights and implementing the feed forward network" href="#loading-the-ff-weights-and-implementing-the-feed-forward-network"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/swiglu.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/swiglu.png" width="600px"></a>
</p>
in llama3, they used a SwiGLU feedforward network, this network architecture is really good at adding non linearity when needed by the model.
<br>
its pretty standard to use this feed forward network architecture in llms these days
<div dir="auto" data-snippet-clipboard-copy-content="w1 = model[&quot;layers.0.feed_forward.w1.weight&quot;]
w2 = model[&quot;layers.0.feed_forward.w2.weight&quot;]
w3 = model[&quot;layers.0.feed_forward.w3.weight&quot;]
output_after_feedforward = torch.matmul(torch.functional.F.silu(torch.matmul(embedding_after_edit_normalized, w1.T)) * torch.matmul(embedding_after_edit_normalized, w3.T), w2.T)
output_after_feedforward.shape"><pre><span>w1</span> <span>=</span> <span>model</span>[<span>"layers.0.feed_forward.w1.weight"</span>]
<span>w2</span> <span>=</span> <span>model</span>[<span>"layers.0.feed_forward.w2.weight"</span>]
<span>w3</span> <span>=</span> <span>model</span>[<span>"layers.0.feed_forward.w3.weight"</span>]
<span>output_after_feedforward</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>torch</span>.<span>functional</span>.<span>F</span>.<span>silu</span>(<span>torch</span>.<span>matmul</span>(<span>embedding_after_edit_normalized</span>, <span>w1</span>.<span>T</span>)) <span>*</span> <span>torch</span>.<span>matmul</span>(<span>embedding_after_edit_normalized</span>, <span>w3</span>.<span>T</span>), <span>w2</span>.<span>T</span>)
<span>output_after_feedforward</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">WE FINALLY HAVE NEW EDITED EMBEDDINGS FOR EACH TOKEN AFTER THE FIRST LAYER</h2><a id="user-content-we-finally-have-new-edited-embeddings-for-each-token-after-the-first-layer" aria-label="Permalink: WE FINALLY HAVE NEW EDITED EMBEDDINGS FOR EACH TOKEN AFTER THE FIRST LAYER" href="#we-finally-have-new-edited-embeddings-for-each-token-after-the-first-layer"></a></p>
<p dir="auto">just 31 more layers to go before we are done (one for loop away)
<br>
you can imagine this edited embedding as having information about all queries asked on the first layer
<br>
now each layer will encode more and more complex queries on the quesions asked, until we have an embedding that knows everything about the next token that we need.</p>
<div dir="auto" data-snippet-clipboard-copy-content="layer_0_embedding = embedding_after_edit+output_after_feedforward
layer_0_embedding.shape"><pre><span>layer_0_embedding</span> <span>=</span> <span>embedding_after_edit</span><span>+</span><span>output_after_feedforward</span>
<span>layer_0_embedding</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">god, everything all at once</h2><a id="user-content-god-everything-all-at-once" aria-label="Permalink: god, everything all at once" href="#god-everything-all-at-once"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/god.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/god.png" width="600px"></a>
</p>
yep, this is it. everything we did before, all at once, for every single layer.

<p dir="auto"><h2 tabindex="-1" dir="auto">have fun reading :)</h2><a id="user-content-have-fun-reading-" aria-label="Permalink: have fun reading :)" href="#have-fun-reading-"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="final_embedding = token_embeddings_unnormalized
for layer in range(n_layers):
    qkv_attention_store = []
    layer_embedding_norm = rms_norm(final_embedding, model[f&quot;layers.{layer}.attention_norm.weight&quot;])
    q_layer = model[f&quot;layers.{layer}.attention.wq.weight&quot;]
    q_layer = q_layer.view(n_heads, q_layer.shape[0] // n_heads, dim)
    k_layer = model[f&quot;layers.{layer}.attention.wk.weight&quot;]
    k_layer = k_layer.view(n_kv_heads, k_layer.shape[0] // n_kv_heads, dim)
    v_layer = model[f&quot;layers.{layer}.attention.wv.weight&quot;]
    v_layer = v_layer.view(n_kv_heads, v_layer.shape[0] // n_kv_heads, dim)
    w_layer = model[f&quot;layers.{layer}.attention.wo.weight&quot;]
    for head in range(n_heads):
        q_layer_head = q_layer[head]
        k_layer_head = k_layer[head//4]
        v_layer_head = v_layer[head//4]
        q_per_token = torch.matmul(layer_embedding_norm, q_layer_head.T)
        k_per_token = torch.matmul(layer_embedding_norm, k_layer_head.T)
        v_per_token = torch.matmul(layer_embedding_norm, v_layer_head.T)
        q_per_token_split_into_pairs = q_per_token.float().view(q_per_token.shape[0], -1, 2)
        q_per_token_as_complex_numbers = torch.view_as_complex(q_per_token_split_into_pairs)
        q_per_token_split_into_pairs_rotated = torch.view_as_real(q_per_token_as_complex_numbers * freqs_cis)
        q_per_token_rotated = q_per_token_split_into_pairs_rotated.view(q_per_token.shape)
        k_per_token_split_into_pairs = k_per_token.float().view(k_per_token.shape[0], -1, 2)
        k_per_token_as_complex_numbers = torch.view_as_complex(k_per_token_split_into_pairs)
        k_per_token_split_into_pairs_rotated = torch.view_as_real(k_per_token_as_complex_numbers * freqs_cis)
        k_per_token_rotated = k_per_token_split_into_pairs_rotated.view(k_per_token.shape)
        qk_per_token = torch.matmul(q_per_token_rotated, k_per_token_rotated.T)/(128)**0.5
        mask = torch.full((len(token_embeddings_unnormalized), len(token_embeddings_unnormalized)), float(&quot;-inf&quot;))
        mask = torch.triu(mask, diagonal=1)
        qk_per_token_after_masking = qk_per_token + mask
        qk_per_token_after_masking_after_softmax = torch.nn.functional.softmax(qk_per_token_after_masking, dim=1).to(torch.bfloat16)
        qkv_attention = torch.matmul(qk_per_token_after_masking_after_softmax, v_per_token)
        qkv_attention_store.append(qkv_attention)

    stacked_qkv_attention = torch.cat(qkv_attention_store, dim=-1)
    w_layer = model[f&quot;layers.{layer}.attention.wo.weight&quot;]
    embedding_delta = torch.matmul(stacked_qkv_attention, w_layer.T)
    embedding_after_edit = final_embedding + embedding_delta
    embedding_after_edit_normalized = rms_norm(embedding_after_edit, model[f&quot;layers.{layer}.ffn_norm.weight&quot;])
    w1 = model[f&quot;layers.{layer}.feed_forward.w1.weight&quot;]
    w2 = model[f&quot;layers.{layer}.feed_forward.w2.weight&quot;]
    w3 = model[f&quot;layers.{layer}.feed_forward.w3.weight&quot;]
    output_after_feedforward = torch.matmul(torch.functional.F.silu(torch.matmul(embedding_after_edit_normalized, w1.T)) * torch.matmul(embedding_after_edit_normalized, w3.T), w2.T)
    final_embedding = embedding_after_edit+output_after_feedforward"><pre><span>final_embedding</span> <span>=</span> <span>token_embeddings_unnormalized</span>
<span>for</span> <span>layer</span> <span>in</span> <span>range</span>(<span>n_layers</span>):
    <span>qkv_attention_store</span> <span>=</span> []
    <span>layer_embedding_norm</span> <span>=</span> <span>rms_norm</span>(<span>final_embedding</span>, <span>model</span>[<span>f"layers.<span><span>{</span><span>layer</span><span>}</span></span>.attention_norm.weight"</span>])
    <span>q_layer</span> <span>=</span> <span>model</span>[<span>f"layers.<span><span>{</span><span>layer</span><span>}</span></span>.attention.wq.weight"</span>]
    <span>q_layer</span> <span>=</span> <span>q_layer</span>.<span>view</span>(<span>n_heads</span>, <span>q_layer</span>.<span>shape</span>[<span>0</span>] <span>//</span> <span>n_heads</span>, <span>dim</span>)
    <span>k_layer</span> <span>=</span> <span>model</span>[<span>f"layers.<span><span>{</span><span>layer</span><span>}</span></span>.attention.wk.weight"</span>]
    <span>k_layer</span> <span>=</span> <span>k_layer</span>.<span>view</span>(<span>n_kv_heads</span>, <span>k_layer</span>.<span>shape</span>[<span>0</span>] <span>//</span> <span>n_kv_heads</span>, <span>dim</span>)
    <span>v_layer</span> <span>=</span> <span>model</span>[<span>f"layers.<span><span>{</span><span>layer</span><span>}</span></span>.attention.wv.weight"</span>]
    <span>v_layer</span> <span>=</span> <span>v_layer</span>.<span>view</span>(<span>n_kv_heads</span>, <span>v_layer</span>.<span>shape</span>[<span>0</span>] <span>//</span> <span>n_kv_heads</span>, <span>dim</span>)
    <span>w_layer</span> <span>=</span> <span>model</span>[<span>f"layers.<span><span>{</span><span>layer</span><span>}</span></span>.attention.wo.weight"</span>]
    <span>for</span> <span>head</span> <span>in</span> <span>range</span>(<span>n_heads</span>):
        <span>q_layer_head</span> <span>=</span> <span>q_layer</span>[<span>head</span>]
        <span>k_layer_head</span> <span>=</span> <span>k_layer</span>[<span>head</span><span>//</span><span>4</span>]
        <span>v_layer_head</span> <span>=</span> <span>v_layer</span>[<span>head</span><span>//</span><span>4</span>]
        <span>q_per_token</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>layer_embedding_norm</span>, <span>q_layer_head</span>.<span>T</span>)
        <span>k_per_token</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>layer_embedding_norm</span>, <span>k_layer_head</span>.<span>T</span>)
        <span>v_per_token</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>layer_embedding_norm</span>, <span>v_layer_head</span>.<span>T</span>)
        <span>q_per_token_split_into_pairs</span> <span>=</span> <span>q_per_token</span>.<span>float</span>().<span>view</span>(<span>q_per_token</span>.<span>shape</span>[<span>0</span>], <span>-</span><span>1</span>, <span>2</span>)
        <span>q_per_token_as_complex_numbers</span> <span>=</span> <span>torch</span>.<span>view_as_complex</span>(<span>q_per_token_split_into_pairs</span>)
        <span>q_per_token_split_into_pairs_rotated</span> <span>=</span> <span>torch</span>.<span>view_as_real</span>(<span>q_per_token_as_complex_numbers</span> <span>*</span> <span>freqs_cis</span>)
        <span>q_per_token_rotated</span> <span>=</span> <span>q_per_token_split_into_pairs_rotated</span>.<span>view</span>(<span>q_per_token</span>.<span>shape</span>)
        <span>k_per_token_split_into_pairs</span> <span>=</span> <span>k_per_token</span>.<span>float</span>().<span>view</span>(<span>k_per_token</span>.<span>shape</span>[<span>0</span>], <span>-</span><span>1</span>, <span>2</span>)
        <span>k_per_token_as_complex_numbers</span> <span>=</span> <span>torch</span>.<span>view_as_complex</span>(<span>k_per_token_split_into_pairs</span>)
        <span>k_per_token_split_into_pairs_rotated</span> <span>=</span> <span>torch</span>.<span>view_as_real</span>(<span>k_per_token_as_complex_numbers</span> <span>*</span> <span>freqs_cis</span>)
        <span>k_per_token_rotated</span> <span>=</span> <span>k_per_token_split_into_pairs_rotated</span>.<span>view</span>(<span>k_per_token</span>.<span>shape</span>)
        <span>qk_per_token</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>q_per_token_rotated</span>, <span>k_per_token_rotated</span>.<span>T</span>)<span>/</span>(<span>128</span>)<span>**</span><span>0.5</span>
        <span>mask</span> <span>=</span> <span>torch</span>.<span>full</span>((<span>len</span>(<span>token_embeddings_unnormalized</span>), <span>len</span>(<span>token_embeddings_unnormalized</span>)), <span>float</span>(<span>"-inf"</span>))
        <span>mask</span> <span>=</span> <span>torch</span>.<span>triu</span>(<span>mask</span>, <span>diagonal</span><span>=</span><span>1</span>)
        <span>qk_per_token_after_masking</span> <span>=</span> <span>qk_per_token</span> <span>+</span> <span>mask</span>
        <span>qk_per_token_after_masking_after_softmax</span> <span>=</span> <span>torch</span>.<span>nn</span>.<span>functional</span>.<span>softmax</span>(<span>qk_per_token_after_masking</span>, <span>dim</span><span>=</span><span>1</span>).<span>to</span>(<span>torch</span>.<span>bfloat16</span>)
        <span>qkv_attention</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>qk_per_token_after_masking_after_softmax</span>, <span>v_per_token</span>)
        <span>qkv_attention_store</span>.<span>append</span>(<span>qkv_attention</span>)

    <span>stacked_qkv_attention</span> <span>=</span> <span>torch</span>.<span>cat</span>(<span>qkv_attention_store</span>, <span>dim</span><span>=</span><span>-</span><span>1</span>)
    <span>w_layer</span> <span>=</span> <span>model</span>[<span>f"layers.<span><span>{</span><span>layer</span><span>}</span></span>.attention.wo.weight"</span>]
    <span>embedding_delta</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>stacked_qkv_attention</span>, <span>w_layer</span>.<span>T</span>)
    <span>embedding_after_edit</span> <span>=</span> <span>final_embedding</span> <span>+</span> <span>embedding_delta</span>
    <span>embedding_after_edit_normalized</span> <span>=</span> <span>rms_norm</span>(<span>embedding_after_edit</span>, <span>model</span>[<span>f"layers.<span><span>{</span><span>layer</span><span>}</span></span>.ffn_norm.weight"</span>])
    <span>w1</span> <span>=</span> <span>model</span>[<span>f"layers.<span><span>{</span><span>layer</span><span>}</span></span>.feed_forward.w1.weight"</span>]
    <span>w2</span> <span>=</span> <span>model</span>[<span>f"layers.<span><span>{</span><span>layer</span><span>}</span></span>.feed_forward.w2.weight"</span>]
    <span>w3</span> <span>=</span> <span>model</span>[<span>f"layers.<span><span>{</span><span>layer</span><span>}</span></span>.feed_forward.w3.weight"</span>]
    <span>output_after_feedforward</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>torch</span>.<span>functional</span>.<span>F</span>.<span>silu</span>(<span>torch</span>.<span>matmul</span>(<span>embedding_after_edit_normalized</span>, <span>w1</span>.<span>T</span>)) <span>*</span> <span>torch</span>.<span>matmul</span>(<span>embedding_after_edit_normalized</span>, <span>w3</span>.<span>T</span>), <span>w2</span>.<span>T</span>)
    <span>final_embedding</span> <span>=</span> <span>embedding_after_edit</span><span>+</span><span>output_after_feedforward</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">we now have the final embedding, the best guess the model could make about the next token</h2><a id="user-content-we-now-have-the-final-embedding-the-best-guess-the-model-could-make-about-the-next-token" aria-label="Permalink: we now have the final embedding, the best guess the model could make about the next token" href="#we-now-have-the-final-embedding-the-best-guess-the-model-could-make-about-the-next-token"></a></p>
<p dir="auto">the shape of the embedding is the same as regular token embeddings [17x4096] where 17 is the number of tokens and 4096 is the embedding dim</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/last_norm.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/last_norm.png" width="600px"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="final_embedding = rms_norm(final_embedding, model[&quot;norm.weight&quot;])
final_embedding.shape"><pre><span>final_embedding</span> <span>=</span> <span>rms_norm</span>(<span>final_embedding</span>, <span>model</span>[<span>"norm.weight"</span>])
<span>final_embedding</span>.<span>shape</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">finally, lets decode the embedding into the token value</h2><a id="user-content-finally-lets-decode-the-embedding-into-the-token-value" aria-label="Permalink: finally, lets decode the embedding into the token value" href="#finally-lets-decode-the-embedding-into-the-token-value"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/finallayer.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/finallayer.png" width="600px"></a>
</p>
we will use the output decoder to convert the final embedding into a token
<div dir="auto" data-snippet-clipboard-copy-content="model[&quot;output.weight&quot;].shape"><pre><span>model</span>[<span>"output.weight"</span>].<span>shape</span></pre></div>
<div data-snippet-clipboard-copy-content="torch.Size([128256, 4096])"><pre><code>torch.Size([128256, 4096])
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">we use the embedding of the last token to predict the next value</h2><a id="user-content-we-use-the-embedding-of-the-last-token-to-predict-the-next-value" aria-label="Permalink: we use the embedding of the last token to predict the next value" href="#we-use-the-embedding-of-the-last-token-to-predict-the-next-value"></a></p>
<p dir="auto">hopefully in our case, 42 :)
note: 42 is the answer to "the answer to the ultimate question of life, the universe, and everything is ", according to the book "hitchhiker's guide to the galaxy", most mordern llms would answer with 42 here, which should validate our entire code! wish me luck :)</p>
<div dir="auto" data-snippet-clipboard-copy-content="logits = torch.matmul(final_embedding[-1], model[&quot;output.weight&quot;].T)
logits.shape"><pre><span>logits</span> <span>=</span> <span>torch</span>.<span>matmul</span>(<span>final_embedding</span>[<span>-</span><span>1</span>], <span>model</span>[<span>"output.weight"</span>].<span>T</span>)
<span>logits</span>.<span>shape</span></pre></div>

<p dir="auto"><h3 tabindex="-1" dir="auto">the model predicted token number 2983 as the next token, is this the token number for 42?</h3><a id="user-content-the-model-predicted-token-number-2983-as-the-next-token-is-this-the-token-number-for-42" aria-label="Permalink: the model predicted token number 2983 as the next token, is this the token number for 42?" href="#the-model-predicted-token-number-2983-as-the-next-token-is-this-the-token-number-for-42"></a></p>
<p dir="auto">IM HYPING YOU UP, this is the last cell of code, hopefully you had fun :)</p>
<div dir="auto" data-snippet-clipboard-copy-content="next_token = torch.argmax(logits, dim=-1)
next_token"><pre><span>next_token</span> <span>=</span> <span>torch</span>.<span>argmax</span>(<span>logits</span>, <span>dim</span><span>=</span><span>-</span><span>1</span>)
<span>next_token</span></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">lets fucking go</h2><a id="user-content-lets-fucking-go" aria-label="Permalink: lets fucking go" href="#lets-fucking-go"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/42.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/42.png" width="600px"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="tokenizer.decode([next_token.item()])"><pre><span>tokenizer</span>.<span>decode</span>([<span>next_token</span>.<span>item</span>()])</pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">thank you, i love you :)</h2><a id="user-content-thank-you-i-love-you-" aria-label="Permalink: thank you, i love you :)" href="#thank-you-i-love-you-"></a></p>
<p dir="auto">This is the end. Hopefully you enjoyed reading it!</p>
<p dir="auto">If you want to support my work</p>
<ol dir="auto">
<li>follow me on twitter <a href="https://twitter.com/naklecha" rel="nofollow">https://twitter.com/naklecha</a></li>
<li>or, buy me a coffee <a href="https://www.buymeacoffee.com/naklecha" rel="nofollow">https://www.buymeacoffee.com/naklecha</a></li>
</ol>
<p dir="auto">Honestly, if you made it this far you already made my day :)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">what motivates me?</h2><a id="user-content-what-motivates-me" aria-label="Permalink: what motivates me?" href="#what-motivates-me"></a></p>
<p dir="auto">My friends and I are on a mission - to make research more accessible!
We created a research lab called A10 - <a href="http://aaaaaaaaaa.org/" rel="nofollow">AAAAAAAAAA.org</a></p>
<p dir="auto">A10 twitter - <a href="https://twitter.com/aaaaaaaaaaorg" rel="nofollow">https://twitter.com/aaaaaaaaaaorg</a></p>
<p dir="auto">our thesis:</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/naklecha/llama3-from-scratch/blob/main/images/a10.png"><img src="https://github.com/naklecha/llama3-from-scratch/raw/main/images/a10.png" width="600px"></a>
</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Video streaming is expensive yet YouTube "seems" to do it for free. How? (156 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40408515</link>
            <guid>40408515</guid>
            <pubDate>Sun, 19 May 2024 17:51:41 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40408515">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="40411040"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40411040" href="https://news.ycombinator.com/vote?id=40411040&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>The economics fundamentally changed a couple of years ago when cloudflare released R2. I don't know if anyone has built a streaming client for it yet, but R2 takes the largest expense (outgoing bandwidth) and zeroes it out.<p>Yor business would be wholly dependent on cloudflare. But if you don't have to pay for bandwidth, the economics aren't that bad.</p><p>(I ran a large porn site a lifetime ago, long before cdns were ubiquitous. If I was in the business today, I would absolutely put everything on R2 and make it work no matter how much client development it took)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40409320"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409320" href="https://news.ycombinator.com/vote?id=40409320&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Disclaimer: I used to work at a live video streaming company as a financial analyst so quite familiar with this<p>The biggest cost is as you imagine the streaming - getting the video to the viewer.  It was a large part of our variable cost and we had a (literal) mad genius dev ops person holed up in his own office cave that managed the whole operation.</p><p>Ive long forgotten the special optimizations he did but he would keep finding ways to improve margin / efficiency.</p><p>Encoding is a cost but I don’t recall it being significant</p><p>Storage isnt generally expensive. Think about how cheap you as a consumer can go get 2 TB of storage, and extrapolate.</p><p>The other big expense - people!  All those engineers to build back and front end systems. That’s what ruined us - too many people were needed and not enough money coming in so we were burning cash.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40409451"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40409451" href="https://news.ycombinator.com/vote?id=40409451&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>I'm guessing live video looks a lot different from a more static video site. I think encoding and storage are both quite expensive. You want to encode videos that are likely to be watched in the most efficient ways possible to reduce network bandwidth usage, and every video needs at least some encoding.<p>Based on some power laws etc., I would guess most videos have only a handful of views, so storing them forever and the cost to encode them initially is probably significant.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410469"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40410469" href="https://news.ycombinator.com/vote?id=40410469&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Encoding and storage aren't significant, relative to the bandwidth costs. Bandwidth is the high order bit.<p>The primary difference between live and static video is the bursts -- get to a certain scale as a static video provider, and you can roughly estimate your bandwidth 95th percentiles. But one big live event can blow you out of the water, and push you over into very expensive tiers that will kill your economics.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410696"><td></td></tr>
                <tr id="40410737"><td></td></tr>
            <tr id="40410960"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40410960" href="https://news.ycombinator.com/vote?id=40410960&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>AFAICT, the answer to "why does Google do X" is basically always "because someone needed a launch to point at when they're up for promotion".</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40410739"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40410739" href="https://news.ycombinator.com/vote?id=40410739&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Because significance varies, as does optimisation. At YouTube scale it might matter more, or the benefits might be bigger, even if just to save some energy or carbon footprint (and even that might be just for a compliance or marketing line).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40410735"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40410735" href="https://news.ycombinator.com/vote?id=40410735&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Because when you are Youtube, even relatively marginal cost improvements can be huge in absolute. There is also the UX of having to wait X minutes for an uploaded video to be ready that is improved by this.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="40410638"><td></td></tr>
            <tr id="40409586"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40409586" href="https://news.ycombinator.com/vote?id=40409586&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Interesting background. I worked twice in digital video, once ~2000-2001 (ancient history - early IP, ISDN, the dead-end of H.323, bonded GSM channels, etc.) and once ~2009-2010. The second episode was fascinating, we specialised in mobile video at a time when it was just appearing on the consumer market. <i>Most</i> of the global mobile device manufacturers were clients. It got to the point where they would build the hardware and we would get airdropped in to their R&amp;D to make it work - they had no idea how performant the architecture was going to be, because they'd never tried it. We also built the server side, the billing architecture with revenue share, carrier billing support (only possible with device preloaded apps due to <i>Google Play</i> (then "Google Apps"?) store restrictions on third party payment mechanisms), etc.<p>Encoding, scaling and transcoding are relatively cheap for stored content, and relatively expensive if you want real or near-real time.</p><p>If you want DRM (digital rights management = ~ineffective copy protection) then you need to add a bit more overhead for that, both in terms of processing and latency. If you need multi-DRM (different DRM systems for different devices the consumer owns) and a good cross-device experience (like pause and resume across devices), it gets real hard real fast.</p><p>It helps to be targeting a standard platform, for example a modern widescreen TV with H.265 support and solid 4K decoding. Otherwise you need a different version for every resolution, a different version for every CODEC, a different version for every bitrate, etc. We had great experience adjusting bitrates and encoding parameters for different device categories, for example if you had a certain phone and you ran it at max spec it might look great but if you were looking to preserve battery and were running on battery save mode the decode would fail and you'd get choppy performance and stuttering audio. This sort of thing was rife then.</p><p>As a series of specialist video providers emerged, ~all the cloud providers went and added these services, basically 95% of which are frontends to ffmpeg and some internal cloud storage scheme or similar.</p><p>Finally, billing is hard. Users have an expectation of free content now.</p><p>No experience with real time stream economics, but saw the inside of LA's stadium video control center one day. Didn't look inexpensive, I'll tell you that much. Probably for events with multiple cameras you're mostly paying site fees, ie. reliable bandwidth, humans, mixing desk if required. For studio broadcast these costs will be reduced. Both will have a slight real time encoding tax vs. stored content. If you want to figure out how to do it cheaply, look at the porn industry.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410306"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40410306" href="https://news.ycombinator.com/vote?id=40410306&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>&gt; basically 95% of which are frontends to ffmpeg<p>I wonder what the approximate net global economic benefit of ffmpeg is to this point?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410496"><td></td></tr>
                        <tr id="40409336"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40409336" href="https://news.ycombinator.com/vote?id=40409336&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Curious: was your distribution client-server or peer-to-peer?<p>Or both, similar to Skype's supernode model?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40409612"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40409612" href="https://news.ycombinator.com/vote?id=40409612&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>The overwhelming majority of "legitimate" video streaming sites operate on a client-server model, which allows videos to be watched in web browsers, and on mobile devices (which don't generally do well in P2P as they find uploading difficult).<p>And generally torrent-based streamers don't hire financial analysts :)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="40409790"><td></td></tr>
            <tr id="40410183"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40410183" href="https://news.ycombinator.com/vote?id=40410183&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>It’s not that expensive at YouTube scale. We are talking fractions of a penny per GiB transferred.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40410264"><td></td></tr>
                <tr id="40410289"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40410289" href="https://news.ycombinator.com/vote?id=40410289&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Yup! This is the reason why its so cheap for them. Other companies in similar positions have cache nodes in the ISPs and this dramatically lowers the cost</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40410442"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40410442" href="https://news.ycombinator.com/vote?id=40410442&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Which would help for the crazy popular meme videos, but I bet the long tail on YouTube is insanely big, even if you did have the “watch next” engine getting in on the game steering you toward content already present in your nearby caches.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40410330"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40410330" href="https://news.ycombinator.com/vote?id=40410330&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>"not that expensive" is relative; it's still a lot of money.  Sure, it's not trillions of dollars, but it's still billions of dollars.  YouTube has historically not returned a net profit (and I haven't heard of that situation changing).</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40410433"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40410433" href="https://news.ycombinator.com/vote?id=40410433&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Do you have a public source for that? From what I’ve heard YouTube has been profitable year years at this point.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40410530"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40410530" href="https://news.ycombinator.com/vote?id=40410530&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>&gt; Do you have a public source for that?<p>YT financials and P&amp;L were not broken out in audited financial statements back in the day.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                                    <tr id="40409260"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409260" href="https://news.ycombinator.com/vote?id=40409260&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>For the streaming factor specifically, I can at least offer something resembling an answer: Google. In the early 2000s they bought up a bunch of dark fiber and peered with all the major US ISPs, and they were able to do this because no ISP wants to be the one that blocks or degrades Google. As a result they were able to host video streaming on their network without immediately being shut down by Comcast and co. Instead they had to go after Netflix.<p>Google has a lot of custom encoding silicon, too, AFAIK.</p><p>Storage is the biggest question of the three. Linus Sebastian specifically called this out when YouTube started really pushing to make the non-Premium experience <i>dreadful</i>. There isn't really some secret special sauce you can buy or make for storage. Literally everything is being stored with the same hard drives, SSDs, discs, or tapes you can just go out and buy. The only specialization you can do is build or buy equipment to handle extreme numbers of them. Google <i>does</i> buy these in bulk, so they probably get a discount on storage, but it's not something that would make storage costs just go away.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40409418"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40409418" href="https://news.ycombinator.com/vote?id=40409418&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>The bandwidth costs are the key. Good luck getting rates anywhere near what Google’s effectively are. Spoiler: you can’t. You probably can’t realistically get to 5x their costs, byte-for-byte.<p>Which makes competing with them effectively impossible except for a very-few other megacorps.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40409516"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40409516" href="https://news.ycombinator.com/vote?id=40409516&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Bandwidth costs are actually free, so this isn't exactly accurate.<p>Most bandwidth is via settlement-free peering with thousands of ISPs around the world. At least that's how we did it at Twitch, and how we did it when I worked at a large CDN before that. There are still costs for backhaul, interconnect, colocation space, dark fiber, network hardware, and transit to fill the gaps. But this talk about how "Google can magically do it 5x cheaper" is nonsense.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410663"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40410663" href="https://news.ycombinator.com/vote?id=40410663&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>&gt; There are still costs for backhaul, interconnect, colocation space, dark fiber, network hardware, and transit to fill the gaps.<p>Genuine question - aren't those gaps essentially what make a video streaming service operate at scale though? It'd be like saying "ya this bus can get everyone from NYC to Philly at $10 but doesn't stop anywhere in between", or am I missing something about all of those gap filling components?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40409640"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40409640" href="https://news.ycombinator.com/vote?id=40409640&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Don't Comcast and friends throttle any peering points you use, until you hand over $x per subscriber per month for them to stop doing so?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40410835"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40410835" href="https://news.ycombinator.com/vote?id=40410835&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>That isn't free. For every terabit of bandwidth, you have to physically build out a terabit of network. Not even remotely free. Having already built the network, and being already paying to run it, you can then use it for free, yes.<p>This is the model for all networks, indeed, most businesses - they pay a big upfront and moderate recurring cost to make a fast network (or restaurant or widget factory) and then sell it in slices with a large freedom to choose a pricing model. Pay per terabyte is a pretty reasonable way to pass on the network's fixed cost to consumers, just like part of the cost of the restaurant meal covers the interior decorations, even though the decorations don't actually cost more the more people eat, until the restaurant gets so busy it needs to expand.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="40409525"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40409525" href="https://news.ycombinator.com/vote?id=40409525&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Bandwidth costs are really not that bad.<p>95th billing, adaptive, progressive playing and just cap buffer to the minimum to keep playing. Equals ~$1M/month for +10 tbit/s egress.</p><p>Source: Worked at one of the largest bandwidth consumers in the world.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410080"><td></td></tr>
                <tr id="40411015"><td></td></tr>
            <tr id="40411014"><td></td></tr>
                  <tr id="40409610"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40409610" href="https://news.ycombinator.com/vote?id=40409610&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>My home connection uploads at 681mbit/s (just did the test over wifi) for 40 euros/months.
At that price, I'd get 13tbit/s for 800k euros.<p>It's a bit surprising that you were not getting significantly better prices than individuals.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410056"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40410056" href="https://news.ycombinator.com/vote?id=40410056&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Price business pipes where they won’t cut you off for saturating that 24/7.<p>[edit] and that have good deliverability worldwide, no weird paths to other consumer IPs that intermittently fail to route or inexplicably have dial-up transfer speeds. And have anything like a real SLA.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="40409568"><td></td></tr>
                <tr id="40410065"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40410065" href="https://news.ycombinator.com/vote?id=40410065&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>I am so confused here. Either I’ve been doing high-bandwidth bit slinging extremely wrong for quite a while or a lot of HN has never done it at all and is opining on it anyway. It’s real money, IME.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40409600"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40409600" href="https://news.ycombinator.com/vote?id=40409600&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Anyone who says "bandwidth costs are not really that bad" should spend 2 minutes playing with the AWS cost calculator.<p>You would think the VMs are the expensive part, but no, egress is easily multiple times the cost of the compute.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410286"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40410286" href="https://news.ycombinator.com/vote?id=40410286&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Cloud bandwidth pricing has nothing with do with costs and everything to do with lock in .<p>You can get 100x cheaper and unmetered at a low cost provider like OVH or hetzner or similar bare metal data centers .</p><p>It doesn’t even need significant monthly commits to get that pricing if you are running video streaming at scale you are not running on AWS or even tier 2 like OVH for sure
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410865"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_40410865" href="https://news.ycombinator.com/vote?id=40410865&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>But anyone doing things at great scale, isn’t going with OVH. You could use it as an origin I goes but you’d still need CDN for decent content delivery.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40410717"><td></td></tr>
                <tr id="40410894"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_40410894" href="https://news.ycombinator.com/vote?id=40410894&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>It's unmetered*<p>* if our upstream is saturated we're going to look at our biggest users and if the number is really big we'll send them a polite email to please reduce it or pay more.</p><p>There are reports of people getting emails from Hetzner after sending  multiple Gbps continuously for several months. That's the level you have to reach before the * kicks in. Only 1Gbps servers are unmetered, so you'd have to have several.</p><p>If you want to know a better approximation of their true cost just look at their non-unlimited plans: 20TB/month included for free; 1€/TB (excl VAT) after that.</p><p>I have one more interesting data point to add: I was quoted 950€/month for a dedicated 10Gbps between Berlin and Amsterdam (about 600km) plus peering at AMS-IX, or 300€ for 1Gbps. (They're not secretive and you can just ask for a quote using their sales contact form). Extrapolating, it seems that 1€ is worth about 2.5 petabyte-kilometers, at least within the dense interconnections of continental Europe. About twice the price of shipping a petabyte of hard drives the same distance.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="40409778"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40409778" href="https://news.ycombinator.com/vote?id=40409778&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>To be fair, that is the penalty of being in a shared cloud. They are incetivized to keep their customers from using everything, everywhere, all at once.<p>Jump into a 'bare metal' datacenter and things can get much different.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40410049"><td></td></tr>
                  <tr id="40409634"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40409634" href="https://news.ycombinator.com/vote?id=40409634&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Assuming 10 Mbit/s per stream that would serve 1 million concurrent streams 24/7. If we assume people watch 2.4 hours per day on average, it could support 10 million active users. Or a cost to serve for bandwidth alone of 1 USD/user per year.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40409310"><td></td></tr>
                <tr id="40409338"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40409338" href="https://news.ycombinator.com/vote?id=40409338&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>So long as storage costs decrease exponentially I think they'll keep everything.<p>Especially if the amount of content uploaded keeps going up, so the relative benefit of deleting old stuff is small.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40409368"><td></td></tr>
                  <tr id="40409535"><td></td></tr>
                <tr id="40409704"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40409704" href="https://news.ycombinator.com/vote?id=40409704&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Exactly! This was my go-to approach for reducing storage costs. Customers don't get spooked when they get an extra 1s delay for something they search once in a month. However, an extra 30ms delay in "everyday content" is a sure way to loose your users.<p>However, implementing this in practice is non-trivial. Knowing what is "everyday content" versus what is "once a month content".</p><p>To add more complexity -- you have these semi-predictable hype-waves especially two peaks in case of most YT videos where a "once-a-month" content becomes an "everyday" content before again becoming a "once-a-month" content. It feels you could specifically optimise for this -- reduce storage costs without sacrificing UX.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40409583"><td></td></tr>
                <tr id="40409721"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40409721" href="https://news.ycombinator.com/vote?id=40409721&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Think about what you actually need to start a video. Maybe a dozen MB?<p>After that, you can plunge into colder storages and warm things up as you stream. Additionally, if you need longer to 'defrost' things, just cache a few more MB at the front. Cheat a bit by assuming 480p to start with if you need to; even less to store.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410249"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_40410249" href="https://news.ycombinator.com/vote?id=40410249&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>There is also location location location.<p>Maybe Google holds your content in 7 data centers round the world (~1 per continent for planned maintenance + latency + reduced oceanic fiber usage).</p><p>But with old rarely streamed content they might cut that down to just 3.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="40409648"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40409648" href="https://news.ycombinator.com/vote?id=40409648&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Speed/latency doesn't tell you much, because it's all on a hard drive <i>somewhere</i>.<p>The question is whether YT is serving up the <i>one</i> (redundantly-backed storage) copy they have of your almost-never-watched video, or whether it's serving it up from one of 1,000+ copies it's made across the globe for currently popular videos.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40409608"><td></td></tr>
                        <tr id="40409539"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40409539" href="https://news.ycombinator.com/vote?id=40409539&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Old content has value for training AI models even if there are no human viewers anymore.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40409639"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40409639" href="https://news.ycombinator.com/vote?id=40409639&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Yes, it's inevitable.<p>My guess is that the first step will be to re-encode all the non-popular videos with severe lossy compression.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410266"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40410266" href="https://news.ycombinator.com/vote?id=40410266&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>They still keep the original uploaded files.<p>You know that because when they release a new format (eg. HDR or a different resolution), they re-encode from the original.   Various people have tested that with moire patterns and various other ways to demonstrate if something was encoded more than once.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="40408644"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40408644" href="https://news.ycombinator.com/vote?id=40408644&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>YouTube generated <i>$31.5 billion</i> in advertising revenue in 2023.<p><a href="https://www.businessofapps.com/data/youtube-statistics/#:~:text=YouTube%20improved%20its%20percentage%20revenue,generated%20%2431.5%20billion%20in%202023" rel="nofollow">https://www.businessofapps.com/data/youtube-statistics/#:~:t...</a>.</p><p>That's... a lot! Plenty of historical precedent for fully advertising-supported media with high expenses, from OTA network television and radio to free weekly newspapers... or inexpensive subscriptions to daily newspapers subsidized by advertising. Advertising has been paying the bills for electronic media for a century now.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410248"><td></td></tr>
                <tr id="40410322"><td></td></tr>
            <tr id="40410297"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40410297" href="https://news.ycombinator.com/vote?id=40410297&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Netflix spends over 50% of it's revenue on content production and licensing ($17B out of $30B), and they made $6B net profit in the past year.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40410354"><td></td></tr>
                <tr id="40410503"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40410503" href="https://news.ycombinator.com/vote?id=40410503&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Netflix serves a slightly larger portion of internet traffic than YouTube on the same amount of revenue. So whatever subsidization youtube is providing for those videos, is clearly outweighed by the monetization of the remaining videos. YouTube has higher revenue per GB of bandwidth served than Netflix.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="40410241"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40410241" href="https://news.ycombinator.com/vote?id=40410241&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Yes. For comparison, Netflix has about $30B in revenue... paid up front for all of its content (something youtube doesnt) and accounts for a larger percentage of internet traffic (likely because of higher quality streams)... and they still made $6B net profit.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40410275"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40410275" href="https://news.ycombinator.com/vote?id=40410275&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Netflix content is highly coachable (tiny library Vs YouTube), which dramatically reduces the cost of serving the data to users.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40409531"><td></td></tr>
                <tr id="40409596"><td></td></tr>
                        <tr id="40410516"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40410516" href="https://news.ycombinator.com/vote?id=40410516&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>It's purely a scale problem.<p>On the "Revenue" side you will quite probably need to have enough eyeballs that advertisers come to you directly to display ads and do so in volume.</p><p>On the "Costs" side you'd want to be big enough that you can just store your content in ~3 of your own datacentres, cache the "hot content" in a site or two per country then give away caches to ISPs (who will gladly host them in their own network for free).</p><p>Biggest cost will be bandwidth/streaming servers. Encoding/storage is comparatively cheap. If you were small you would likely start to do this from a few 100Gbps dedicated servers per continent. <a href="https://www.fdcservers.net/configurator?fixedFilter=15&amp;fixedFilterType=bandwidth_option" rel="nofollow">https://www.fdcservers.net/configurator?fixedFilter=15&amp;fixed...</a> If we set an average of 3-4Mbps per stream you're looking at each server handling 20,000 videos served and the hourly cost of the server would be around say $4/hour so you're looking at around $0.20 per 1000 video hours in theory, in practice it will be higher. Worst case closer to $0.50 per 1000 video hours due to utilisation rates.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410994"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40410994" href="https://news.ycombinator.com/vote?id=40410994&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Aren't big players colocating their CDNs at internet exchanges? Bandwidth should be essentially free for content delivery.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40410587"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40410587" href="https://news.ycombinator.com/vote?id=40410587&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>It may be different at this scale, but in my experience fast-ish redundant file storage has always been extremely expensive even at lower storage sizes, while getting a 100 Gbps line is relatively cheap.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40410665"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40410665" href="https://news.ycombinator.com/vote?id=40410665&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>it's different at scale, and you mostly don't need SSDs since you have cache boxes, most your storage is videos that are very rarely used. You're looking at probably a rack of SSDs for every 5-10 racks of spinning disks X 3 datacentres. Even that would give you approx 50-90PB of usable storage (replicated so it's in all three sites) for a few tens of thousands a month.<p>Even if you just put it all on S3 infrequent, which would be one of the most expensive ways of doing it, it's still not really expensive compared to serving the content.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="40410648"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40410648" href="https://news.ycombinator.com/vote?id=40410648&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>For most players streaming are not profitable.  Youtube is likely profitable, but since Google doesn’t report separate income, we don’t know how much.<p>Netflix is.</p><p>Disney, peacock, Paramount, Max , etc are not profitable with the hope they can capture future monopoly standing.</p><p>Prime Video is likely also not profitable or break even given their studio investments (e.g. MGM, first party content).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410676"><td></td></tr>
                  <tr id="40409573"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409573" href="https://news.ycombinator.com/vote?id=40409573&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Disclaimer: I worked at Google and occasionally did things for YT, but it was 2015 and before. I did look at their P&amp;L, <i>somewhat</i>.<p>egress costs were enormous and YT was not profitable. I don't know if it is now, but I wouldn't be surprised to find it is. They sure have enough ads.</p><p>As several people say below, caching content around the world is key, so that not all requests are serviced in NoCal.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40409589"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40409589" href="https://news.ycombinator.com/vote?id=40409589&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Bingo, YT has always been a loss leader for Google dominance. Only recently have they squeezed the ads knob to maybe generate a profit but I’d bet it’s nothing like the high margin AdWords cash cow.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40410362"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40410362" href="https://news.ycombinator.com/vote?id=40410362&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>It's so wild to see people so confidently being wrong in a comment. YouTube has seen profit since 2013, with margins growing each year.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40410890"><td></td></tr>
            <tr id="40410520"><td></td></tr>
                <tr id="40410577"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40410577" href="https://news.ycombinator.com/vote?id=40410577&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>I was there as well, and Youtube was wildly profitable.<p>See how easy it is to make random statements on the internet.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410692"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_40410692" href="https://news.ycombinator.com/vote?id=40410692&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>&gt; random statements<p>Yep. I'd be happy to stand in front of an arbiter who knows the facts and let him/her judge which one of us knows what he's talking about.</p><p>or we can ask ChatGPT:  "was YouTube profitable prior to 2017"</p><p>Before 2017, YouTube's profitability status was not officially disclosed by its parent company, Google (now Alphabet Inc.). While Google acquired YouTube in 2006 for $1.65 billion, the platform's journey to profitability was complex and prolonged due to the high costs associated with its massive data storage, bandwidth, and content licensing needs. Despite its immense popularity and growing user base, these operational costs made turning a profit challenging.</p><p>Revenue Growth and Challenges:</p><p>Revenue Generation: YouTube generated significant revenue through advertising. By 2015, its ad revenue was estimated to be over $4 billion annually. Despite this, high operational costs offset these revenues.</p><p>Content and Infrastructure Costs: The expenses for server maintenance, bandwidth, and licensing for music and other content were substantial. YouTube also invested heavily in developing new features and expanding its global reach.
Monetization Strategies: YouTube introduced various monetization strategies over the years, including TrueView ads, channel memberships, Super Chat, and YouTube Premium (previously YouTube Red). These aimed to diversify revenue streams beyond traditional advertising.</p><p>Estimates and Market Analysts:</p><p>While exact profitability figures were not publicly available, market analysts and industry insiders speculated about YouTube's financial health. For instance:</p><p>In 2015, The Wall Street Journal reported that despite generating substantial revenue, YouTube barely broke even due to high costs.
Analysts suggested that YouTube's profitability improved gradually as its revenue grew and operational efficiencies increased.</p><p>Official Confirmation of Profitability:</p><p>It wasn't until 2017 that there were stronger indications of YouTube's profitability. During an earnings call in 2017, Alphabet's CFO Ruth Porat hinted at YouTube being a significant contributor to the company's revenue growth, suggesting improved profitability.</p><p>In summary, while YouTube likely faced profitability challenges for much of its early existence, it was making significant strides towards profitability by the mid-2010s, achieving a more stable financial status around 2017.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410880"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_40410880" href="https://news.ycombinator.com/vote?id=40410880&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>I don't know why you're getting downvoted.  Efficiency projects like the transcoding ASIC are a big part of pushing YouTube to profitability, as well as the alternate revenue streams and heavy increases in monetization.  Video serving is extremely expensive and difficult compared to everything else Google does.<p>Ruth Porat has been on record many times indicating that YouTube wasn't profitable in the 2010's.  I think her public statements have only indicated that YouTube was free cash flow positive as of the 2020's, but I haven't found exactly where that happened - Google has experimented with a lot of different kinds of breakdowns of its finances.  I assume that hiding the economics of YouTube is part of this (as well as protection against a zealous DOJ saying that Google's businesses are separable).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410998"><td><table>  <tbody><tr>    <td indent="7"><img src="https://news.ycombinator.com/s.gif" height="1" width="280"></td><td>
      <center><a id="up_40410998" href="https://news.ycombinator.com/vote?id=40410998&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>&gt; I don't know why you're getting downvoted.<p>Because I'm not here to read a wall of text generated by ChatGPT.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                                    <tr id="40410499"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40410499" href="https://news.ycombinator.com/vote?id=40410499&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>No. 2013? See GP, see Google financial statements, etc. I do think it started turning a profit over the last 3 years, but can't confirm that.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="40409205"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409205" href="https://news.ycombinator.com/vote?id=40409205&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>For streaming, google have caches in like every ISP network. Also majority of the people watches the latest and same type of content that is mainly served from the homepage, which is easier to cache and serve.<p>If you have the ipvfoo extension, you can see it in action. (its easier to see with IPv6)</p><p><a href="https://github.com/pmarks-net/ipvfoo">https://github.com/pmarks-net/ipvfoo</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40409275"><td></td></tr>
                <tr id="40409355"><td></td></tr>
                <tr id="40409829"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40409829" href="https://news.ycombinator.com/vote?id=40409829&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Although note the map is only city addresses. For example the "London" pin is on the notional point where "London" is, ie Charing Cross. There is no giant network interchange at Charing Cross, it's just a convenient place co-ordinate for "London".</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40409253"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40409253" href="https://news.ycombinator.com/vote?id=40409253&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>I wonder if that's part of the reason for their algorithms to push the same videos to everyone, they're already cached at the edge so it costs them nothing?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40409282"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40409282" href="https://news.ycombinator.com/vote?id=40409282&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>More popular works are more likely to be enjoyable to more people. There is no really objective measure of quality for any creative work, and taste doesn't scale, so publishers bias for popularity as it's one of the few things they can understand.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40409670"><td></td></tr>
            <tr id="40410355"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40410355" href="https://news.ycombinator.com/vote?id=40410355&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>The majority will enjoy and like whatever is pushed on them. Decades of radio and TV should be enough evidence for this. Music or video is not popular because people like it, but because somebody decided to make it popular by pushing it on people.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40409402"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40409402" href="https://news.ycombinator.com/vote?id=40409402&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>I would imagine that's too insignificant to factor into that particular calculation.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40410108"><td></td></tr>
                      <tr id="40409279"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40409279" href="https://news.ycombinator.com/vote?id=40409279&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>I would imagine it's an unintended side effect of the "people recently watched this so it's relevant" part of the algorithm.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40409174"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409174" href="https://news.ycombinator.com/vote?id=40409174&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Encoding is largely super-linear for a single stream, so you just need enough cores for the intake * formats.  Streaming is mostly chunking and a smart player that loads the right chunks at the right time.  Storage is bottom dollar, use whatever the cheapest disks you've got that you can attach to fiber, then cache the hell out of everything.<p>So in short, the only "on-demand" component is encoding, and if you don't have an 'available in an instant' promise, you can do it on spot instances on the cheapest cloud you can find;  The rest is just storage and distribution - if you own a world-wide network of datacenters for your successful advertising service, that's kinda an already solved problem for you - just allocate a few racks to a new service.</p><p>I of course downplay everything and simplify massively - but at a high level, it's just a lot of ffmpeg -&gt; S3 -&gt; html5 player.  The harder problems are in the long tail - high latency, content licensing &amp; geo fencing, etc.</p><p>Source: used to SRE for a video streaming provider (not YT), also former GG
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40410531"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40410531" href="https://news.ycombinator.com/vote?id=40410531&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Video streaming is getting cheaper all the time. Bandwidth costs are dropping every year (substantially in most cases) and bitrates aren't keeping up (the few exceptions probably being AppleTV+ and BBC iPlayer which do 30-50mbit/sec 4K HDR streams).<p>You can do this for so much cheaper than AWS etc price for bandwidth. You can get 100gigE transit from he.net for list price $4500/month. Add probably the same again for colo + hardware (don't need much hardware these days to saturate 100gigE) and you can probably stream videos to 20,000 concurrent users at 5mbit/sec for ~$10k/month.</p><p>Another way would be to use someone like OVH who offers dedicated servers with 10gigE (supposedly 'guaranteed') for about $800/month each list price, without having to bother with colo and ip transit setup.</p><p>Obviously this is highly simplified as you will require encoding resource and storage, but again with someone like OVH you'd be able to spin up a lot of cheap boxes to do this. How much this will cost will depend on how many videos you get and how many views per video etc.</p><p>So IMO the actual bandwidth is a bit of a non issue. The far bigger issue is getting users to use your platform (marketing is MUCH more expensive than IP transit) and then having advertisers on your site. This is a much harder problem to solve and where the real barrier to entry is.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40410558"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40410558" href="https://news.ycombinator.com/vote?id=40410558&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>I worked on YouTube transcoding about 12 years ago. First, the scale is mostly reused - what’s doing transcoding now is doing a different compute job later. Transcoding was also done for most videos only on idle compute. Second, Google had 300k+ caches around the world, in many surprising places (buses, cruise ships) as well as many thousands of other larger but not full data center locations; get the content as close as possible to the user. (I imagine now all transcoding from the mezzanine format is done in real time on an edge GPU for all but the most popular platforms and content). Tl;dr: build out a huge amount of infrastructure to serve ads very quickly and you can piggyback video serving on that at little marginal cost.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40410982"><td></td></tr>
            <tr id="40409214"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409214" href="https://news.ycombinator.com/vote?id=40409214&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>It probably costs them a ton of money, but they probably make a ton more so that’s OK.<p>Also: bandwidth gets a lot cheaper when you own the pipes.</p><p>And one that is less obvious: despite having hundreds of millions of videos available, a large contingent of people are watching the same ultra-popular ones. There are some economies of scale to be had there.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40409334"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409334" href="https://news.ycombinator.com/vote?id=40409334&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>DIY (instead of the cloud) is the answer. If you're pushing terabytes+ from day 1 on a shoestring, you're going to want your own CDN. If you can manage a queueing system and the occasional wait, run your own (or rented physical) hardware for transcoding at as high a utilisation as you can.<p>Build vs buy pushes you to "build" early on when your margins are slim and your volume is huge.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40409603"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409603" href="https://news.ycombinator.com/vote?id=40409603&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>The economics are simple:<p>&gt; <i>I know advertisements are a thing for YT, but is it enough?</i></p><p>Yes, it is -- virtually certainly. We can assume YouTube is profitable. It's not broken out directly in quarterly reports, but it doesn't make any sense that Google would still be running it after all these years (almost 20) if it weren't.</p><p>But obviously YouTube didn't <i>start out</i> as profitable. You need scale, which provides two things:</p><p>1) Marginal storage and streaming costs go down (Google is big enough to save huge amounts of money by running its own data centers, peering agreements, caching near customers, etc.)</p><p>2) More advertisers running more ads that can be targeted to more users whose preferences you know more about</p><p>So no, <i>you</i> can't run it profitably.</p><p>This is a classic example of a business that is only profitable at scale, that needs to lose a lot of money at first as it grows until it achieves scale. And it's not just scale on the traditional tech/users side, it's scale on the advertising side as well -- advertisers aren't going to bother running ads on your platform until you have enough users for them to care.</p><p>It's also pretty strongly a "winner-takes-all" network effects situation, where video publishers want to put up their videos where the viewers are, and viewers want to visit the site where all the content is. So if you wanted to create a YT competitor, I don't know how you'd convince content creators to post their videos to your site in addition to YT, or how to convince consumers to watch said videos on your site instead of YT.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40410048"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40410048" href="https://news.ycombinator.com/vote?id=40410048&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Also scale on the supply side. It took time to get to a place where obviously the video should be on Youtube, and that's hard to replicate.<p>This applies to the content which would exist anyway, and then doubly to content created for Youtube. Grand Pooh Bear would be on Twitch anyway, but it doesn't really make sense for a Tom Scott, let alone "Corrections" which is a Youtube-only addition to Seth Myers "Late Night" show.</p><p>Likewise until it gets fairly "big" it doesn't make sense to <i>officially</i> put your music videos on Youtube. Today that's basically the main way they're getting seen.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="40409297"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409297" href="https://news.ycombinator.com/vote?id=40409297&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>The value of YouTube isn't purely monetary. Controlling YouTube is extremely advantageous for Google, even if it isn't particularly profitable.<p>Besides the general advantage of having control over such a massive platform, which definitely plays an important part in the lives of hundreds of millions of people, Google likely views YouTube as important to control.
If YouTube were a separate entity, it could e.g. freely choose their ad providers or even provides ads themselves, essentially creating competition for Google. Google also has trivial access to the data there and therefore the easiest access if they want to train AI on that data. Last but not least I think Google sees YouTube as vital for their corporate image and their social mission presented in Google Jigsaw.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40410585"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40410585" href="https://news.ycombinator.com/vote?id=40410585&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Yes it costs a lot, and YouTube also makes a lot of money via ads, subscriptions, partnerships. Whether it is ultimately profitable or not is anyone's guess, since they don't report the numbers publicly.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40409157"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409157" href="https://news.ycombinator.com/vote?id=40409157&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>&gt; especially at scale<p>The marginal costs go down a bit if your scale is truly immense. Google can afford to design/manufacture/deploy hyper-efficient custom silicon ASICs for encoding. Also because their critical mass of users provide valuable network effects, they can get away with particularly poor quality encoding (IMHO) and the vast majority of users still won't switch to other platforms with higher visual quality - but other (non-pornographic) video platforms generally don't have that luxury.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40410012"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40410012" href="https://news.ycombinator.com/vote?id=40410012&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Is there any way that I can pay YouTube so that the videos I post do not have ads when people view them for free?  I think there is a clear answer to this question for video, and it’s ~$60/month.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40410790"><td></td></tr>
                  <tr id="40409443"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409443" href="https://news.ycombinator.com/vote?id=40409443&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Storage, transcoding/encoding, and any other compute operations (rendering, etc) are small compared to data transfer costs.<p>At the scale of the largest streaming apps (Disney, Netflix, YouTube, etc) you are moving petabytes of data PER DAY. At that size, you have access to significant savings on CDNs, backbone providers, etc. in many cases the discounts will be 90% - I have seen as high as 99% - or higher off the “list” price (which are usually never paid by anyone anyway).</p><p>You also tend to own your own backbone and can link in whichever ISP wherever you want for the “final mile.”</p><p>Final note, when you have been doing this long enough, you can start shaping the traffic based off previous patterns. I remember an eBay listing years ago for a Netflix local storage device that was meant to store shows at an ISP’s data center.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40409775"><td></td></tr>
                  <tr id="40409269"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409269" href="https://news.ycombinator.com/vote?id=40409269&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>Bandwidth/Transport costs for live streaming, especially in group conference call scenarios (where N streams needs to be broadcasted to N-1 participants) become prohibitively expensive after about 8 or so participants unless you can offload those bandwidth requirements to other places (e.g., like in a peer-to-peer architecture).<p>How Zoom manages to do this in a client-server fashion and is still financially solvent is also a question I've had for a while, but like others say, discounts on the transport and peering arrangements will be a key part in making those economics work, as compression and storage are relatively solved problems here.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40409664"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409664" href="https://news.ycombinator.com/vote?id=40409664&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>&gt; Streaming, encoding, and storage demands enormous costs -- especially at scale<p>When you look at costs per unit, then it gets cheaper at scale, not more expensive.</p><p>For streaming, at scale you can afford to do peering yourself, instead of buying bandwidth.</p><p>For encoding, at scale you can afford special purpose encoding hardware, instead of using general purpose hardware.</p><p>For storage, at scale you can get cheap bulk deals with drive manufacturers.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40409065"><td></td></tr>
                <tr id="40409248"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40409248" href="https://news.ycombinator.com/vote?id=40409248&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>I realized this as I saw many of my favorite gaming Youtubers chase the algorithm and change their content to stay relevant. It all eventually converges on content that children would find entertaining. They're the biggest demographic spending the most time looking at ads. That's where following the algorithm leads.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40409192"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409192" href="https://news.ycombinator.com/vote?id=40409192&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><br><div>
                  <p><span>Video streaming is expensive <i>for you</i>. Google is incredible at making things cheap that we all thought were expensive.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40409734"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40409734" href="https://news.ycombinator.com/vote?id=40409734&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>&gt;Google is incredible at making things cheap<p>As Curly would say, "Eh, a big cheapskate, nyuk nyuk !" ;)</p><p>It's true they do have a "cheapening" effect, especially over time, but Curly's a knucklehead, I wouldn't want to compete with them on their own terms.  That's a big gorilla.</p><p>&gt;If tomorrow I want to start a platform</p><p>Seems like one approach would be to start out with what you can easily afford to begin with.</p><p>Which brings me exactly to the bare bones of storing, encoding, streaming and nothing else.</p><p>If nothing else to minimize complexity and cost of getting started.</p><p>And to possibly obviate the need for monetization up to a point.</p><p>To launch, just pick one fairly popular &amp; accessible format/bit-rate and encode all your raw content (or a test portion of content) the exact same way in advance.  Afterward, you're done with that phase and free of any need for real-time encoding.  You still need to store and subsequently "outstream" your ready-to-deliver content.</p><p>It may actually cost you nothing to store a working copy of your encoded content "library" on your own private server on your own designated premises, especially if you already own the storage devices and there is plenty of unused storage space.  There are also alternatives that are not without cost, only you could decide if it was worth money or not.</p><p>Naturally you will be limited by the bandwidth and infrastructure at each storage location, as to how many viewers at what resolution you can directly serve at one time, and whether or not the ISP/router can be configured to allow outside access to your server.</p><p>If you're going to use 100Mbps of surplus upload bandwidth from a business internet account for instance, and your content was encoded at 1.5Mbps (don't even think about 4K), it may be no additional cost to start serving viewers directly from that server, but you would not be able to serve more than about 50 viewers at one time.</p><p>That might get you started (at an appropriate scale) with no cash outlay whatsoever, and if the demand was there beyond a few dozen viewers then you could decide to pass your stream along to a more capable content delivery network of some kind, at various incremental cost.</p><p>Alternatively, the whole thing could be outsourced and hosted for world-wide access in a turnkey operation where all you do is supply the content.  Cost may be a prohibiting factor, it does seem like there are hosting plans with a free tier but not with enough bandwidth to serve a meaningful number of viewers compared to YT.</p><p>Fortunately for YT, when they got started they didn't have competition already showing 4K stuff to compare to.</p><p>But if the action you take, has cost within the range of what you can <i>easily</i> bear, you could then afford to deliver a completely superior, ad-free experience for your fortunate few viewers.  If you wanted to.  Something a multi-billion-dollar company seems to be less and less able to afford.  What a position to be in.  If the whole thing actually was costing you no cash at all you'd be free to make it seem as free and frictionless as YT, probably more so because it was free from the ground up.</p><p>&gt;a platform that is supported with Advert revenues</p><p>If you did decide to go this route and were sustainable without ads to begin with, you could very judiciously choose your sponsors to be ones that did not conflict with any feature that is more meaningful to the visitors.  You would also be financially ahead beginning with the first ad you decided to run.  And you could decide to stop at any time.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="40409590"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409590" href="https://news.ycombinator.com/vote?id=40409590&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>It sure doesn’t feel free. YouTube has cranked the ads up so frickin’ high that I swear they’re quietly in panic mode about profitability.<p>Every month I notice the temperature of the pot is up a few degrees. This month it’s unskippable 15 second ads before most videos. Last month it was the first search result now being an ad.  Before that it was how 5 second ads are now 7 seconds.</p><p>If I thought to write them all down I’d have a dozen more steps to share.</p><p>My kids now call it “the Bad YouTube” vs. YouTube Kids because the former is flooded with ads.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40410479"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40410479" href="https://news.ycombinator.com/vote?id=40410479&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>As someone who works in a large cloud company, there is a lot going on to create a data center. By data center I mean compute and storage. These large companies have perfected the economics and engineering needed to create a data center. They spend billions on R&amp;D. They basically own everything in their supply chain. Smaller companies can't compete.<p>Additionally, they don't pay the same electricity and water bill that others pay for their data center. They get a discount because they are creating jobs.</p><p>Getting streaming to be cost effective starts from decades of R&amp;D investment + getting low cost electricity and water + owning supply chain.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40410283"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40410283" href="https://news.ycombinator.com/vote?id=40410283&amp;how=up&amp;goto=item%3Fid%3D40408515"></a></center>    </td><td><p><span>YouTube is vertically integrated.<p>They're not paying a margin to advertising companies because they are the advertising company, they're not paying a margin to datacenters because they are the datacenter.</p><p>The data gleaned from YT views helps them to run search and vice versa.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40410317"><td></td></tr>
            <tr id="40409428"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coding My Handwriting (290 pts)]]></title>
            <link>https://www.amygoodchild.com/blog/cursive-handwriting-in-javascript</link>
            <guid>40408291</guid>
            <pubDate>Sun, 19 May 2024 17:15:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.amygoodchild.com/blog/cursive-handwriting-in-javascript">https://www.amygoodchild.com/blog/cursive-handwriting-in-javascript</a>, See on <a href="https://news.ycombinator.com/item?id=40408291">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">
        
          
<article id="sections" data-page-sections="5f37d09b551f154577577f0a">
  
  
    
    


  


<div data-content-field="main-content" data-item-id="" data-test="page-section" data-section-theme="white" data-section-id="5f37d09b551f154577577f0c" data-controller="SectionWrapperController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;sectionTheme&quot;: &quot;white&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-current-context="{
&quot;video&quot;: {
&quot;playbackSpeed&quot;: 0.5,
&quot;filter&quot;: 1,
&quot;filterStrength&quot;: 0,
&quot;zoom&quot;: 0,
&quot;videoSourceProvider&quot;: &quot;none&quot;
},
&quot;backgroundImageId&quot;: null,
&quot;backgroundMediaEffect&quot;: null,
&quot;divider&quot;: null,
&quot;typeName&quot;: &quot;blog-basic-grid&quot;
}" data-animation="none">
  <article id="article-">
  
    
    
    
    <div data-layout-label="Post Body" data-type="item" id="item-6642095b62643354c29c66e0"><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-8156bbeef2534803659c">
  <p>A familiar theme for me is dismissing an idea as being too much work and then later finding myself doing it anyway. That’s what happened here.</p><p>A little while ago I created a block script in JavaScript, thinking that cursive would be too complex. But here I am, two months later, ready to talk about the cursive handwriting I’ve created. There is perhaps a lesson in that but let’s not dwell on it.  </p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715603804147_8094">
  <h3>Block script</h3><p><a href="https://www.amygoodchild.com/blog/generating-the-alphabet" target="_blank">This previous article</a> is about my block printed version of the alphabet. As a summary, I created it by: </p><ul data-rte-list="default"><li><p>Writing code to define key points in each letter’s paths (~10 points per letter).</p></li><li><p>Smoothing those paths using Chaikin’s curve algorithm.</p></li><li><p>Turning the path into a shape for variable thickness along the length.</p></li><li><p>Draw the shape paths using p5js.</p></li></ul><p>It looked like this: </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715603804147_5236">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/eba9ea4a-a805-4c1d-8630-c2bcf0772453/printed+handwriting.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/eba9ea4a-a805-4c1d-8630-c2bcf0772453/printed+handwriting.png" data-image-dimensions="777x1010" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/eba9ea4a-a805-4c1d-8630-c2bcf0772453/printed+handwriting.png" width="777" height="1010" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/eba9ea4a-a805-4c1d-8630-c2bcf0772453/printed+handwriting.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/eba9ea4a-a805-4c1d-8630-c2bcf0772453/printed+handwriting.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/eba9ea4a-a805-4c1d-8630-c2bcf0772453/printed+handwriting.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/eba9ea4a-a805-4c1d-8630-c2bcf0772453/printed+handwriting.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/eba9ea4a-a805-4c1d-8630-c2bcf0772453/printed+handwriting.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/eba9ea4a-a805-4c1d-8630-c2bcf0772453/printed+handwriting.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/eba9ea4a-a805-4c1d-8630-c2bcf0772453/printed+handwriting.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715603804147_6047">

<p>By the way, an article about my system for generating these sentences is coming soon, sign up to my newsletter to hear about it.</p>




















  
  



</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715603804147_7576">

<p>Defining the original paths for those letters was a very manual process of writing their positions into the code and then nudging the points back and forth until the letters looked right. When it came to coding cursive, I streamlined the process. </p>




















  
  



</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715603804147_12260">
  <h3>Designing Letters</h3><p>In the p5js editor, for easy access, I <a href="https://editor.p5js.org/amygoodchild/sketches/GZzkh4cWt" target="_blank">created a tool</a> to define and output the key points in the paths. </p><p>It displays a sample letter (for scale and context) next to an area in which to design the new letter with these steps:</p><ul data-rte-list="default"><li><p>Click to place key points for the path - the resultant Chaikin-curved path is shown.</p></li><li><p>Tap ‘p’ to switch to editing mode.</p></li><li><p>Select points and drag them into position. </p></li><li><p>Tap ‘enter’ to output the path to the console. </p></li></ul><p>I created 2-3 options for each letter. </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715608887114_6458">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/b22794d7-33d0-4a7e-b5f8-ce4b8b2aa363/letter+designer.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/b22794d7-33d0-4a7e-b5f8-ce4b8b2aa363/letter+designer.gif" data-image-dimensions="600x353" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/b22794d7-33d0-4a7e-b5f8-ce4b8b2aa363/letter+designer.gif" width="600" height="353" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/b22794d7-33d0-4a7e-b5f8-ce4b8b2aa363/letter+designer.gif?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/b22794d7-33d0-4a7e-b5f8-ce4b8b2aa363/letter+designer.gif?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/b22794d7-33d0-4a7e-b5f8-ce4b8b2aa363/letter+designer.gif?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/b22794d7-33d0-4a7e-b5f8-ce4b8b2aa363/letter+designer.gif?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/b22794d7-33d0-4a7e-b5f8-ce4b8b2aa363/letter+designer.gif?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/b22794d7-33d0-4a7e-b5f8-ce4b8b2aa363/letter+designer.gif?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/b22794d7-33d0-4a7e-b5f8-ce4b8b2aa363/letter+designer.gif?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715608887114_11164">

<p>The path that results looks like this: </p>




















  
  



</div><div data-block-type="23" id="block-yui_3_17_2_1_1715608887114_11555">
<pre><code>[{x:0.7,y:22.5},{x:8.2,y:18.1},{x:8.9,y:11.2},{x:3.7,y:11.4},{x:1.7,y:18.9},{x:8.4,y:22.4},{x:17.7,y:22.0}] </code></pre></div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715610756359_6768">
  <p>I wanted to use my own handwriting as a guide, so I wrote out a range of examples of lower and uppercase letters and loaded the image directly into my letter building tool for tracing.</p><p>The w/a/s/d keys are used to place the image in the right spot and r/e zooms the image in and out. The blurry ‘e’ you see in the gif above is the sample image. </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715610756359_8038">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/93889136-57d1-4f0a-a508-7aa8ce5209b2/handwritingsample.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/93889136-57d1-4f0a-a508-7aa8ce5209b2/handwritingsample.jpg" data-image-dimensions="2904x2148" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/93889136-57d1-4f0a-a508-7aa8ce5209b2/handwritingsample.jpg" width="2904" height="2148" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/93889136-57d1-4f0a-a508-7aa8ce5209b2/handwritingsample.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/93889136-57d1-4f0a-a508-7aa8ce5209b2/handwritingsample.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/93889136-57d1-4f0a-a508-7aa8ce5209b2/handwritingsample.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/93889136-57d1-4f0a-a508-7aa8ce5209b2/handwritingsample.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/93889136-57d1-4f0a-a508-7aa8ce5209b2/handwritingsample.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/93889136-57d1-4f0a-a508-7aa8ce5209b2/handwritingsample.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/93889136-57d1-4f0a-a508-7aa8ce5209b2/handwritingsample.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715610756359_13825">

<p>The numbers noted on the paper are the x y coordinates to get that area to be in the letter creation window.</p>




















  
  



</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715610756359_11950">

<p>After creating all the paths, curving them and turning them into shapes with variable width,  (check the <a href="https://www.amygoodchild.com/blog/generating-the-alphabet" target="_blank">previous article</a> for more detail), here’s how the characters look individually. </p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715610756359_12692">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/5e99bed5-e27f-40bb-b95b-4c76d198e2ea/cursive+letters+individual.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/5e99bed5-e27f-40bb-b95b-4c76d198e2ea/cursive+letters+individual.png" data-image-dimensions="1208x337" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/5e99bed5-e27f-40bb-b95b-4c76d198e2ea/cursive+letters+individual.png" width="1208" height="337" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/5e99bed5-e27f-40bb-b95b-4c76d198e2ea/cursive+letters+individual.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/5e99bed5-e27f-40bb-b95b-4c76d198e2ea/cursive+letters+individual.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/5e99bed5-e27f-40bb-b95b-4c76d198e2ea/cursive+letters+individual.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/5e99bed5-e27f-40bb-b95b-4c76d198e2ea/cursive+letters+individual.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/5e99bed5-e27f-40bb-b95b-4c76d198e2ea/cursive+letters+individual.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/5e99bed5-e27f-40bb-b95b-4c76d198e2ea/cursive+letters+individual.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/5e99bed5-e27f-40bb-b95b-4c76d198e2ea/cursive+letters+individual.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715610756359_11339">
  <h3>Cursive-ifying, Cursifying (?) </h3><p>Sometimes joining letters is easy, you just go straight from one path of key points to the next before Chaikin curving them all in one go. But some letter pairs do not work nicely together.</p><p>Consider the letter pair <strong>na</strong>. In red we can see the last point of the letter <strong>n</strong>, which is low, and in green, the first point of the letter <strong>a</strong>, which is high. This causes the joining path to go diagonally through the <strong>a</strong>, making it look a bit like an <strong>e</strong>. </p><p>Meanwhile in the pair <strong>ti</strong>, the <strong>t</strong> ends just above the baseline and the <strong>i</strong> starts on it, causing an unnatural ridge. </p>
</div><div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715610756359_14483">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/7984a9cc-0079-4dc4-94e6-d323f25c05fb/na+-+1.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/7984a9cc-0079-4dc4-94e6-d323f25c05fb/na+-+1.png" data-image-dimensions="500x500" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/7984a9cc-0079-4dc4-94e6-d323f25c05fb/na+-+1.png" width="500" height="500" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/7984a9cc-0079-4dc4-94e6-d323f25c05fb/na+-+1.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/7984a9cc-0079-4dc4-94e6-d323f25c05fb/na+-+1.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/7984a9cc-0079-4dc4-94e6-d323f25c05fb/na+-+1.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/7984a9cc-0079-4dc4-94e6-d323f25c05fb/na+-+1.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/7984a9cc-0079-4dc4-94e6-d323f25c05fb/na+-+1.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/7984a9cc-0079-4dc4-94e6-d323f25c05fb/na+-+1.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/7984a9cc-0079-4dc4-94e6-d323f25c05fb/na+-+1.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715610756359_32131">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/f333ede0-cb98-4db3-99e3-feadcdcbda39/ti.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/f333ede0-cb98-4db3-99e3-feadcdcbda39/ti.png" data-image-dimensions="500x500" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/f333ede0-cb98-4db3-99e3-feadcdcbda39/ti.png" width="500" height="500" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/f333ede0-cb98-4db3-99e3-feadcdcbda39/ti.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/f333ede0-cb98-4db3-99e3-feadcdcbda39/ti.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/f333ede0-cb98-4db3-99e3-feadcdcbda39/ti.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/f333ede0-cb98-4db3-99e3-feadcdcbda39/ti.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/f333ede0-cb98-4db3-99e3-feadcdcbda39/ti.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/f333ede0-cb98-4db3-99e3-feadcdcbda39/ti.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/f333ede0-cb98-4db3-99e3-feadcdcbda39/ti.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div></div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715610756359_19361">

<p>To fix these issues we can add an extra point to the start of the <strong>a</strong>, and delete the last two points on the <strong>t</strong>. </p>




















  
  



</div><div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715610756359_20290">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/e3456092-c6ba-4ade-b4a8-2e925de89e90/na+-+2.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/e3456092-c6ba-4ade-b4a8-2e925de89e90/na+-+2.png" data-image-dimensions="500x500" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/e3456092-c6ba-4ade-b4a8-2e925de89e90/na+-+2.png" width="500" height="500" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/e3456092-c6ba-4ade-b4a8-2e925de89e90/na+-+2.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/e3456092-c6ba-4ade-b4a8-2e925de89e90/na+-+2.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/e3456092-c6ba-4ade-b4a8-2e925de89e90/na+-+2.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/e3456092-c6ba-4ade-b4a8-2e925de89e90/na+-+2.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/e3456092-c6ba-4ade-b4a8-2e925de89e90/na+-+2.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/e3456092-c6ba-4ade-b4a8-2e925de89e90/na+-+2.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/e3456092-c6ba-4ade-b4a8-2e925de89e90/na+-+2.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715610756359_60784">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/edec8a82-c9eb-4467-b731-ec4cc27afb80/ti+-+2.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/edec8a82-c9eb-4467-b731-ec4cc27afb80/ti+-+2.png" data-image-dimensions="500x500" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/edec8a82-c9eb-4467-b731-ec4cc27afb80/ti+-+2.png" width="500" height="500" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/edec8a82-c9eb-4467-b731-ec4cc27afb80/ti+-+2.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/edec8a82-c9eb-4467-b731-ec4cc27afb80/ti+-+2.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/edec8a82-c9eb-4467-b731-ec4cc27afb80/ti+-+2.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/edec8a82-c9eb-4467-b731-ec4cc27afb80/ti+-+2.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/edec8a82-c9eb-4467-b731-ec4cc27afb80/ti+-+2.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/edec8a82-c9eb-4467-b731-ec4cc27afb80/ti+-+2.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/edec8a82-c9eb-4467-b731-ec4cc27afb80/ti+-+2.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div></div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715610756359_23305">
  <p>But we can’t just change the letters like that for all scenarios. </p><p>For example, if the <strong>a</strong> is at the start of a word, the additional point will be out of place and if the <strong>a</strong> preceded by a letter like <strong>w</strong>, it creates a line that crosses through the <strong>a </strong>in a different way. If the <strong>t</strong> is paired with a <strong>k</strong>, it becomes deformed. </p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715610756359_28307">
  <p>The points at the beginning and ends of letter paths need to vary depending on which other letters they are next to. </p><p>At first I tried calling out particular “problem” pairs and writing rules for them specifically but, in the end, I added a single number to the beginning and end of each path which states if it: </p><ul data-rte-list="default"><li><p>Cannot join another letter (0)</p></li><li><p>Joins another letter around the base line (1)</p></li><li><p>Joins another letter just above the base line (2)</p></li><li><p>Joins another letter around the x-height (3)</p></li></ul><p>Here are some examples:</p>
</div><div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715610756359_86058">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4c290819-b063-4d0a-b083-804b7036d783/join+heights+-+0.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4c290819-b063-4d0a-b083-804b7036d783/join+heights+-+0.png" data-image-dimensions="693x470" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4c290819-b063-4d0a-b083-804b7036d783/join+heights+-+0.png" width="693" height="470" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4c290819-b063-4d0a-b083-804b7036d783/join+heights+-+0.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4c290819-b063-4d0a-b083-804b7036d783/join+heights+-+0.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4c290819-b063-4d0a-b083-804b7036d783/join+heights+-+0.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4c290819-b063-4d0a-b083-804b7036d783/join+heights+-+0.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4c290819-b063-4d0a-b083-804b7036d783/join+heights+-+0.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4c290819-b063-4d0a-b083-804b7036d783/join+heights+-+0.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4c290819-b063-4d0a-b083-804b7036d783/join+heights+-+0.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715610756359_87117">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/daa228f1-48f9-4594-88b9-8e696cf0d176/join+heights+-+1.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/daa228f1-48f9-4594-88b9-8e696cf0d176/join+heights+-+1.png" data-image-dimensions="693x470" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/daa228f1-48f9-4594-88b9-8e696cf0d176/join+heights+-+1.png" width="693" height="470" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/daa228f1-48f9-4594-88b9-8e696cf0d176/join+heights+-+1.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/daa228f1-48f9-4594-88b9-8e696cf0d176/join+heights+-+1.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/daa228f1-48f9-4594-88b9-8e696cf0d176/join+heights+-+1.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/daa228f1-48f9-4594-88b9-8e696cf0d176/join+heights+-+1.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/daa228f1-48f9-4594-88b9-8e696cf0d176/join+heights+-+1.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/daa228f1-48f9-4594-88b9-8e696cf0d176/join+heights+-+1.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/daa228f1-48f9-4594-88b9-8e696cf0d176/join+heights+-+1.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div></div><div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715610756359_91110">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/962005c8-c702-417a-9d26-7d0ed69ad611/join+heights+-+2.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/962005c8-c702-417a-9d26-7d0ed69ad611/join+heights+-+2.png" data-image-dimensions="693x448" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/962005c8-c702-417a-9d26-7d0ed69ad611/join+heights+-+2.png" width="693" height="448" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/962005c8-c702-417a-9d26-7d0ed69ad611/join+heights+-+2.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/962005c8-c702-417a-9d26-7d0ed69ad611/join+heights+-+2.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/962005c8-c702-417a-9d26-7d0ed69ad611/join+heights+-+2.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/962005c8-c702-417a-9d26-7d0ed69ad611/join+heights+-+2.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/962005c8-c702-417a-9d26-7d0ed69ad611/join+heights+-+2.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/962005c8-c702-417a-9d26-7d0ed69ad611/join+heights+-+2.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/962005c8-c702-417a-9d26-7d0ed69ad611/join+heights+-+2.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715610756359_92175">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/9b0091c0-e647-4800-83e7-33c6419eb13e/join+heights+-+3.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/9b0091c0-e647-4800-83e7-33c6419eb13e/join+heights+-+3.png" data-image-dimensions="693x448" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/9b0091c0-e647-4800-83e7-33c6419eb13e/join+heights+-+3.png" width="693" height="448" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/9b0091c0-e647-4800-83e7-33c6419eb13e/join+heights+-+3.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/9b0091c0-e647-4800-83e7-33c6419eb13e/join+heights+-+3.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/9b0091c0-e647-4800-83e7-33c6419eb13e/join+heights+-+3.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/9b0091c0-e647-4800-83e7-33c6419eb13e/join+heights+-+3.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/9b0091c0-e647-4800-83e7-33c6419eb13e/join+heights+-+3.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/9b0091c0-e647-4800-83e7-33c6419eb13e/join+heights+-+3.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/9b0091c0-e647-4800-83e7-33c6419eb13e/join+heights+-+3.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div></div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715610756359_83859">

<p>Each letter path now looks something like this, note the single digits at the beginning and end:</p>




















  
  



</div><div data-block-type="23" id="block-yui_3_17_2_1_1715610756359_82950">
<pre><code>[0,{x:12.2,y:13.2},{x:13.5,y:11.0},{x:6.2,y:8.4},{x:1.1,y:13.0},{x:1.8,y:19.0},{x:7.0,y:23.4},{x:15.2,y:23.6},{x:18.4,y:22.1},1],</code></pre></div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715752260728_99684">

<p>I tested all of the letter pairs, like so:</p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715752260728_104149">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/8e7c8f57-54e5-4aae-8d94-41c9826d11de/letterpairs.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/8e7c8f57-54e5-4aae-8d94-41c9826d11de/letterpairs.png" data-image-dimensions="3164x3165" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/8e7c8f57-54e5-4aae-8d94-41c9826d11de/letterpairs.png" width="3164" height="3165" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/8e7c8f57-54e5-4aae-8d94-41c9826d11de/letterpairs.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/8e7c8f57-54e5-4aae-8d94-41c9826d11de/letterpairs.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/8e7c8f57-54e5-4aae-8d94-41c9826d11de/letterpairs.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/8e7c8f57-54e5-4aae-8d94-41c9826d11de/letterpairs.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/8e7c8f57-54e5-4aae-8d94-41c9826d11de/letterpairs.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/8e7c8f57-54e5-4aae-8d94-41c9826d11de/letterpairs.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/8e7c8f57-54e5-4aae-8d94-41c9826d11de/letterpairs.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715752260728_106462">

<p>Here you can also see some of the variation, created by having multiple paths for each letter and also by editing the letters depending on what letter they are next to. Ideally I would have at least 5 or 6 options of paths for each letter but there is a balance to be drawn against file size. </p>




















  
  



</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715610756359_99517">
  <h3>Creating words</h3><p>When a word is created: </p><ul data-rte-list="default"><li><p>a basic path is chosen for each letter from the 2-3 different options for that character.</p></li><li><p>the information about the ends of the paths are passed to the adjacent letters<br>(the letter paths all have to be chosen first as, in some cases, different path options for the same letter have different end points)</p></li><li><p>The basic paths are adjusted in response to their neighbours. <br>E.g. if the previous letter’s end height is 2, remove 1 point from the start of this path, or if the next letter’s start height is 1, add an additional point in a certain location. </p></li></ul><p>The adjustment functions can get a bit complicated, for example here is the one for the letter q:</p>
</div><div data-block-type="23" id="block-yui_3_17_2_1_1715610756359_131824">
<pre><code>// ip = path 
// pc = previous char's end info 
// nc = next char's start info 
// n = index of path that was chosen for this letter
adjust: (ip, pc, nc, n) =&gt; {
  // randomly adds in a break at the end for 70% of this letter
  if (rand() &lt; 0.7 ) ip.splice(-1, 1, 0);

   // if [2] was chosen for this path from the 4 options, 
   if (n &lt; 2) {

     // Swap out first two points for a different point if the previous char ends at 3
     if (pc == 3) ip.splice(1, 2, {x:10,y:12});

     // Otherwise, as long as it's not a 0, add a point at the beginning
     else if (pc &gt; 0) ip.splice(1, 0, {x:10,y:20});
  }

  // If there's no break (0) between this character and the next
  if (nc &gt; 0 &amp;&amp; ip[ip.length-1] != 0){
    // Swap out the last two points for a different one 
    ip.splice(-3, 2, {x:16,y:34})
  }
}</code></pre></div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715610756359_133889">

<p>But often they are fairly short, here is the one for the letter n:</p>




















  
  



</div><div data-block-type="23" id="block-yui_3_17_2_1_1715610756359_138034">
<pre><code>adjust: (ip, pc, nc) =&gt; {
  // If the next letter starts at a 3, randomly either create a break or move the last point 
  if (nc == 3) rand() &lt; 0.3 ? ip.splice(-1, 1, 0) : ip.splice(-2, 1, {x:17,y:23.8})
}</code></pre></div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715610756359_140399">

<p>Next the basic paths for all the letters are joined together. While doing this, it ignores 1, 2 and 3’s in the letter paths but whenever there is a 0 it creates a break by starting a new path. </p>




















  
  



</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715610756359_152142">

<p>After curving those paths, turning them into varied width shapes, and adding some jittering around using Perlin noise, here’s what the cursive writing looks like.</p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715610756359_153981">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4555438f-8f38-4571-8fc5-fd1baafcf559/Cursive+text.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4555438f-8f38-4571-8fc5-fd1baafcf559/Cursive+text.png" data-image-dimensions="1274x1284" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4555438f-8f38-4571-8fc5-fd1baafcf559/Cursive+text.png" width="1274" height="1284" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4555438f-8f38-4571-8fc5-fd1baafcf559/Cursive+text.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4555438f-8f38-4571-8fc5-fd1baafcf559/Cursive+text.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4555438f-8f38-4571-8fc5-fd1baafcf559/Cursive+text.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4555438f-8f38-4571-8fc5-fd1baafcf559/Cursive+text.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4555438f-8f38-4571-8fc5-fd1baafcf559/Cursive+text.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4555438f-8f38-4571-8fc5-fd1baafcf559/Cursive+text.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4555438f-8f38-4571-8fc5-fd1baafcf559/Cursive+text.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715610756359_155793">

<p>An article about generating these sentences will be coming soon, you can sign up to my newsletter to get a heads up when it’s out. </p>




















  
  



</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715688327725_64868">

<p>For fun, here’s a side by side comparison of the coded handwriting run through my plotter, next to my actual handwriting. </p>




















  
  



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715610756359_159523">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/fc2b53c5-879a-4dd0-b568-6957eff56693/handwriting+comparison.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/fc2b53c5-879a-4dd0-b568-6957eff56693/handwriting+comparison.jpg" data-image-dimensions="2794x1946" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/fc2b53c5-879a-4dd0-b568-6957eff56693/handwriting+comparison.jpg" width="2794" height="1946" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/fc2b53c5-879a-4dd0-b568-6957eff56693/handwriting+comparison.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/fc2b53c5-879a-4dd0-b568-6957eff56693/handwriting+comparison.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/fc2b53c5-879a-4dd0-b568-6957eff56693/handwriting+comparison.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/fc2b53c5-879a-4dd0-b568-6957eff56693/handwriting+comparison.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/fc2b53c5-879a-4dd0-b568-6957eff56693/handwriting+comparison.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/fc2b53c5-879a-4dd0-b568-6957eff56693/handwriting+comparison.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/fc2b53c5-879a-4dd0-b568-6957eff56693/handwriting+comparison.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715688327725_67491">
  <h3>WHAT DOES IT WEIGH?</h3><p>The letter class for the block print was 9.7kb. The letter class for the cursive handwriting (after being run through a minifier) is currently 26.1kb. </p><p>This one is larger because there are multiple paths for each letter as well as the function for adjust the points to meet the letter’s neighbours, but I have made some other savings. I’m sure further savings could be made - I am not a code golf wizard but I have a few ideas. </p><p>For example, currently the letters are designed around a default font size of 20 and then resized, meaning lots of the points are defined as e.g. x: 14.5, but if I switch this to a default size of 200, the point could be defined as 145, removing one character (the decimal place). I need to make this change carefully, so it’s on the To Do list for later. </p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715752260728_44848">
  <h3>How I’m Using it</h3><p>The main purpose for this handwriting is for the titles, labels and scribbled notes on these <a href="https://x.com/amygoodchild/status/1770433357777973273" target="_blank">diagrams</a> I’ve been working on. But I’m also have a lot of fun playing around with the text itself. </p><p>One of the best things about having encoded paths instead of using a font is that I can mess around with those paths. Changing the position of letters and changing the thickness across an individual letter and so on. </p>
</div><div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715752260728_54208">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/0ffc0b11-4c4f-4fa1-be64-2d8f1f43878b/handwriting-text-1.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/0ffc0b11-4c4f-4fa1-be64-2d8f1f43878b/handwriting-text-1.png" data-image-dimensions="2352x2352" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/0ffc0b11-4c4f-4fa1-be64-2d8f1f43878b/handwriting-text-1.png" width="2352" height="2352" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/0ffc0b11-4c4f-4fa1-be64-2d8f1f43878b/handwriting-text-1.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/0ffc0b11-4c4f-4fa1-be64-2d8f1f43878b/handwriting-text-1.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/0ffc0b11-4c4f-4fa1-be64-2d8f1f43878b/handwriting-text-1.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/0ffc0b11-4c4f-4fa1-be64-2d8f1f43878b/handwriting-text-1.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/0ffc0b11-4c4f-4fa1-be64-2d8f1f43878b/handwriting-text-1.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/0ffc0b11-4c4f-4fa1-be64-2d8f1f43878b/handwriting-text-1.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/0ffc0b11-4c4f-4fa1-be64-2d8f1f43878b/handwriting-text-1.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715752260728_56521">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/18f126d9-96c3-4835-9fbe-d1f80a328d89/handwriting-text-3.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/18f126d9-96c3-4835-9fbe-d1f80a328d89/handwriting-text-3.png" data-image-dimensions="2352x2352" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/18f126d9-96c3-4835-9fbe-d1f80a328d89/handwriting-text-3.png" width="2352" height="2352" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/18f126d9-96c3-4835-9fbe-d1f80a328d89/handwriting-text-3.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/18f126d9-96c3-4835-9fbe-d1f80a328d89/handwriting-text-3.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/18f126d9-96c3-4835-9fbe-d1f80a328d89/handwriting-text-3.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/18f126d9-96c3-4835-9fbe-d1f80a328d89/handwriting-text-3.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/18f126d9-96c3-4835-9fbe-d1f80a328d89/handwriting-text-3.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/18f126d9-96c3-4835-9fbe-d1f80a328d89/handwriting-text-3.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/18f126d9-96c3-4835-9fbe-d1f80a328d89/handwriting-text-3.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div></div><div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715752260728_61966">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4ef17597-1b2d-4d59-8ee3-eb412188c50f/handwriting-text-6.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4ef17597-1b2d-4d59-8ee3-eb412188c50f/handwriting-text-6.png" data-image-dimensions="2352x2352" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4ef17597-1b2d-4d59-8ee3-eb412188c50f/handwriting-text-6.png" width="2352" height="2352" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4ef17597-1b2d-4d59-8ee3-eb412188c50f/handwriting-text-6.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4ef17597-1b2d-4d59-8ee3-eb412188c50f/handwriting-text-6.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4ef17597-1b2d-4d59-8ee3-eb412188c50f/handwriting-text-6.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4ef17597-1b2d-4d59-8ee3-eb412188c50f/handwriting-text-6.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4ef17597-1b2d-4d59-8ee3-eb412188c50f/handwriting-text-6.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4ef17597-1b2d-4d59-8ee3-eb412188c50f/handwriting-text-6.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/4ef17597-1b2d-4d59-8ee3-eb412188c50f/handwriting-text-6.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715752260728_67735">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/1289f9d9-f244-4e4f-9a86-a72dd2ab4339/handwriting-text-5.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/1289f9d9-f244-4e4f-9a86-a72dd2ab4339/handwriting-text-5.png" data-image-dimensions="2352x2352" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/1289f9d9-f244-4e4f-9a86-a72dd2ab4339/handwriting-text-5.png" width="2352" height="2352" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/1289f9d9-f244-4e4f-9a86-a72dd2ab4339/handwriting-text-5.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/1289f9d9-f244-4e4f-9a86-a72dd2ab4339/handwriting-text-5.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/1289f9d9-f244-4e4f-9a86-a72dd2ab4339/handwriting-text-5.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/1289f9d9-f244-4e4f-9a86-a72dd2ab4339/handwriting-text-5.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/1289f9d9-f244-4e4f-9a86-a72dd2ab4339/handwriting-text-5.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/1289f9d9-f244-4e4f-9a86-a72dd2ab4339/handwriting-text-5.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/1289f9d9-f244-4e4f-9a86-a72dd2ab4339/handwriting-text-5.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div></div><div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715752260728_69016">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/72f0234a-05dc-44d5-aa0e-cfe012d6e4e2/handwriting-text-4.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/72f0234a-05dc-44d5-aa0e-cfe012d6e4e2/handwriting-text-4.png" data-image-dimensions="2352x2352" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/72f0234a-05dc-44d5-aa0e-cfe012d6e4e2/handwriting-text-4.png" width="2352" height="2352" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/72f0234a-05dc-44d5-aa0e-cfe012d6e4e2/handwriting-text-4.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/72f0234a-05dc-44d5-aa0e-cfe012d6e4e2/handwriting-text-4.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/72f0234a-05dc-44d5-aa0e-cfe012d6e4e2/handwriting-text-4.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/72f0234a-05dc-44d5-aa0e-cfe012d6e4e2/handwriting-text-4.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/72f0234a-05dc-44d5-aa0e-cfe012d6e4e2/handwriting-text-4.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/72f0234a-05dc-44d5-aa0e-cfe012d6e4e2/handwriting-text-4.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/72f0234a-05dc-44d5-aa0e-cfe012d6e4e2/handwriting-text-4.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715752260728_55380">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/30b1f065-edb6-4cfe-ae9c-4eb898256c42/handwriting-text-2.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/30b1f065-edb6-4cfe-ae9c-4eb898256c42/handwriting-text-2.png" data-image-dimensions="2352x2352" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/30b1f065-edb6-4cfe-ae9c-4eb898256c42/handwriting-text-2.png" width="2352" height="2352" sizes="(max-width: 640px) 100vw, (max-width: 767px) 50vw, 50vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/30b1f065-edb6-4cfe-ae9c-4eb898256c42/handwriting-text-2.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/30b1f065-edb6-4cfe-ae9c-4eb898256c42/handwriting-text-2.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/30b1f065-edb6-4cfe-ae9c-4eb898256c42/handwriting-text-2.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/30b1f065-edb6-4cfe-ae9c-4eb898256c42/handwriting-text-2.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/30b1f065-edb6-4cfe-ae9c-4eb898256c42/handwriting-text-2.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/30b1f065-edb6-4cfe-ae9c-4eb898256c42/handwriting-text-2.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/30b1f065-edb6-4cfe-ae9c-4eb898256c42/handwriting-text-2.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div></div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1715951246919_69251">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/de2fe388-555d-49b2-84ac-c06d3e3002cf/handwriting-text-10.png" data-image="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/de2fe388-555d-49b2-84ac-c06d3e3002cf/handwriting-text-10.png" data-image-dimensions="2352x2352" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/de2fe388-555d-49b2-84ac-c06d3e3002cf/handwriting-text-10.png" width="2352" height="2352" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/de2fe388-555d-49b2-84ac-c06d3e3002cf/handwriting-text-10.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/de2fe388-555d-49b2-84ac-c06d3e3002cf/handwriting-text-10.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/de2fe388-555d-49b2-84ac-c06d3e3002cf/handwriting-text-10.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/de2fe388-555d-49b2-84ac-c06d3e3002cf/handwriting-text-10.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/de2fe388-555d-49b2-84ac-c06d3e3002cf/handwriting-text-10.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/de2fe388-555d-49b2-84ac-c06d3e3002cf/handwriting-text-10.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5f33cddd6aff255aabb0c6cd/de2fe388-555d-49b2-84ac-c06d3e3002cf/handwriting-text-10.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715951246919_82022">

<p>Next up I’m going to be incorporating the handwriting into those diagrams, but I’m definitely intending to come back and create something focused on the text itself as well, as I’m finding it super beautiful and there’s a lot of possibility there!</p>




















  
  



</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-yui_3_17_2_1_1715752260728_120438">
  <p>😍 Enjoyed this article? I’d love it if you could <a href="https://x.com/amygoodchild/status/1791475650190102834" target="_blank">give a boost on Twitter</a>, thanks!</p><p>✨ And don’t forget to sign up for my weekly newsletter, filled with updates. </p>
</div></div>
  
</article>

</div>

  
</article>


          

          
            
              

            
          
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI doppelgänger experiment – Part 1: The training (149 pts)]]></title>
            <link>https://julienposture.substack.com/p/the-ai-doppelganger-experiment-part</link>
            <guid>40407927</guid>
            <pubDate>Sun, 19 May 2024 16:19:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://julienposture.substack.com/p/the-ai-doppelganger-experiment-part">https://julienposture.substack.com/p/the-ai-doppelganger-experiment-part</a>, See on <a href="https://news.ycombinator.com/item?id=40407927">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em>&nbsp;‘And only&nbsp;one&nbsp;for birthday presents, you know.&nbsp;There’s glory for you!’&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</em></p><p><em>&nbsp;‘I don’t know what you mean by “glory”,’ Alice said.</em></p><p><em>&nbsp;‘Humpty Dumpty smiled contemptuously. ‘Of course, you don’t–till I tell you.&nbsp;I meant “there’s a nice knock-down argument for you!”’</em></p><p><em>&nbsp;‘But “glory” doesn’t mean “a nice knock-down argument”, Alice objected.</em></p><p><em>&nbsp;‘When&nbsp;I&nbsp;use a word,’ Humpty Dumpty said in rather a scornful tone, ‘it means just what I choose it to mean–neither more nor less.’</em></p><p><em>&nbsp;‘The question is,’ said Alice, ‘whether you&nbsp;can&nbsp;make words mean different things–that’s all.’</em></p><p><em>‘The question is,’ said Humpty Dumpty, ‘which is to be master–that’s all’</em></p><p>This passage of Alice Through the Looking Glass is often cited in philosophy of language classes to introduce the idea of language as a social activity that rely on shared meaning. If the same word means different things every time we use it, or different things for different speakers, how could we communicate at all? As I’m researching the social life of images through the fields of illustration, design, law, machine learning, and so on, I’m often reminded of Humpty Dumpty. While illustrators, designers, lawyers, and computer scientists might all use the same words —images, style, art— they rarely share the same meaning. But unlike Alice and Humpty Dumpty, instead of having a conversation about what they mean when they use a word, the people talking about AI and art continue to yap at each other endlessly in mutual misunderstanding. The goal of course, is not mutual understanding, but power, or as Humpty Dumpty puts it, to decide “which is to be master”. Without ever addressing the linguistic nature of the debate, proponents and opponents of generative AI are indeed fighting for the power to define what “image”, “style”, “art” mean.</p><p><span>Communication relies on shared language, and when this communication is about what we see, it also relies on shared ways of seeing. Yet, different people learn to see the same things differently and these ways of seeing, as </span><a href="https://www.youtube.com/watch?v=0pDE4VX_9Kk" rel="">John Berger pointed out</a><span>, are socially constructed. What does an artist see when they look at their style? How does it differ from the ways machine learning models see styles? And which way of seeing has more power?</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ab196f5-1f2c-41a5-b45a-906a99c0e667_500x357.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ab196f5-1f2c-41a5-b45a-906a99c0e667_500x357.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ab196f5-1f2c-41a5-b45a-906a99c0e667_500x357.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ab196f5-1f2c-41a5-b45a-906a99c0e667_500x357.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ab196f5-1f2c-41a5-b45a-906a99c0e667_500x357.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ab196f5-1f2c-41a5-b45a-906a99c0e667_500x357.png" width="48" height="34.272" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5ab196f5-1f2c-41a5-b45a-906a99c0e667_500x357.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:357,&quot;width&quot;:500,&quot;resizeWidth&quot;:48,&quot;bytes&quot;:6882,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ab196f5-1f2c-41a5-b45a-906a99c0e667_500x357.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ab196f5-1f2c-41a5-b45a-906a99c0e667_500x357.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ab196f5-1f2c-41a5-b45a-906a99c0e667_500x357.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ab196f5-1f2c-41a5-b45a-906a99c0e667_500x357.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>To start answering these questions, I interviewed computer scientists working on generative AI about “style transfer”, the process of extracting the stylistic features of an image to apply them to another. Both as an illustrator and an anthropologist, I was fascinated by the idea. When I ask illustrators to describe their style, they usually go on long narrative tangents about what they love, how they grew up, who they know, etc. Style is a deeply lived category, a repository of experiences and influences that resists simple definitions. I wondered how computer scientists could create systems that translated this in mathematical vectors that could be extracted from a mere image. How they defined “style”, how they trained a model to pick up on it, and how much of our own perception and the ways we learn to look at images, are all very exciting questions to me.</p><p><span>The main takeaway of these (ongoing) interviews so far has been that computer scientists are interested in style not in itself, but for the challenges that it confronts machine learning models with. Training a model to transfer the style of an image to another involves for that model to take a whole entity, the image, and divides it in layers that are not pre-given in the data itself. In this case, the layers are the </span><em>denotational</em><span> content of the image, what it represents, and its </span><em>stylistic</em><span>, or formal treatment. This is an impressive feat for a machine learning model to be able to achieve this. But the very notion that artworks can be separated in these two aspects, denotational and stylistic, is itself an old idea that can be traced to early twentieth century </span><a href="http://arthistoryresources.net/baroque-art-theory-2013/wolfflin-renaissance-baroque.html" rel="">art historian Heinrich Wölfflin (1864-1945)</a><span> work on formalism. For him, it was important to study artwork from a formal point of view, without considering their subject.</span></p><p><span>We rarely hear about the historical ideas that shape the thinking of technologists, that’s the whole point. Technology is meant to be innovative, disruptive, and the lobbying of AI company is in part of cultural lobbying to erase the historicity of their ideas in order to </span><a href="https://www.effectivealtruism.org/articles/cause-profile-long-run-future" rel="">constantly situate their work in the future.</a><span> So how does an early twentieth century idea about art shows up in AI work today?</span></p><p>As often, it shows up in the unquestioned parts of the process of training a model. Computer scientists have often told me how none of them really has a working definition of style they consciously encode in a model:</p><blockquote><p><em>“It's not very easy to define exactly what style is. But then you have these papers that say ‘Okay, what we're doing is, without defining exactly what style means we're showing you a method that can take an image, which we'll say we'll copy the style from, and we can transplant this style onto another image’. And you get a result that you look at and intuitively you say, ‘Okay, it's another object in the same style’ even if you don't know how to define its parts.”</em></p></blockquote><p>The success or failure of style transfer relies not only on an algorithm, but on the “intuitive” perception of a beholder. This means both machine and human ways of seeing are co-constitutive of the resulting model. Another computer scientist shared that when training their own model, they worked with a designer whose job was to evaluate the quality of the output of a style transfer. The success of the model here became entangled with the taste of the perceiver parsing through outputs, selecting the best, i.e. the output that fit best our culturally specific idea of style. Far from an emergent inexplicable feature of the model, separating content from style is most often the result of tinkering, subjective perception, selection, and more tinkering, all steeped in very human ideas about what images are made of. So, how can I study this very subjective perception?</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4499739e-b13c-4d83-ac0f-8fb0da4e3a51_500x357.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4499739e-b13c-4d83-ac0f-8fb0da4e3a51_500x357.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4499739e-b13c-4d83-ac0f-8fb0da4e3a51_500x357.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4499739e-b13c-4d83-ac0f-8fb0da4e3a51_500x357.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4499739e-b13c-4d83-ac0f-8fb0da4e3a51_500x357.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4499739e-b13c-4d83-ac0f-8fb0da4e3a51_500x357.png" width="48" height="34.272" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4499739e-b13c-4d83-ac0f-8fb0da4e3a51_500x357.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:357,&quot;width&quot;:500,&quot;resizeWidth&quot;:48,&quot;bytes&quot;:6882,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4499739e-b13c-4d83-ac0f-8fb0da4e3a51_500x357.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4499739e-b13c-4d83-ac0f-8fb0da4e3a51_500x357.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4499739e-b13c-4d83-ac0f-8fb0da4e3a51_500x357.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4499739e-b13c-4d83-ac0f-8fb0da4e3a51_500x357.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Ways of seeing are a slippery object of study. Unlike the linguistic anthropologists who trained me to study language, I (realistically) cannot record and transcribe “looks” like I would with words. Instead, I’m chasing ways of seeing in various corners of multiple meaning-making practices, from the moodboard designers create to the feedback illustrators get from art directors, from the captioning of a dataset to the prompting of a model. As AI companies are </span><a href="https://www.theatlantic.com/technology/archive/2024/01/ai-transparency-meta-microsoft/677022/" rel="">not exactly as open as they promised to be</a><span>, I’ve decided that instead of spending months negotiating access to secret spaces protected by NDAs, I might as well take the experimental road, and train a model myself. &nbsp;</span></p><p><span>To do this, I contacted an amazing PhD researcher in Human-Computer Interaction at the University of Columbia, Sitong, to work together on this. Working with another researcher was not only a way for me to ensure I would have someone who can explain to me what’s going on, but also to work with someone with the same ethical concerns I have about working with machine learning and people. Together we created an experimental protocol that would allow illustrators to participate and train the model on their own work in a safe environment, and get the opportunity to generate images themselves, thus placing human and machine in interaction to answer the question: </span><em>What is generated in the encounter between human and machine ways of seeing?</em></p><p>Here's how we went about setting up a Human-Computer Interaction (HCI) experiment, within the larger context of my ongoing ethnographic fieldwork with New York creatives, and some insights we gathered along the way.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03c1617a-df51-4751-b6bf-19e0a89ed3ca_500x357.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03c1617a-df51-4751-b6bf-19e0a89ed3ca_500x357.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03c1617a-df51-4751-b6bf-19e0a89ed3ca_500x357.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03c1617a-df51-4751-b6bf-19e0a89ed3ca_500x357.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03c1617a-df51-4751-b6bf-19e0a89ed3ca_500x357.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03c1617a-df51-4751-b6bf-19e0a89ed3ca_500x357.png" width="48" height="34.272" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/03c1617a-df51-4751-b6bf-19e0a89ed3ca_500x357.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:357,&quot;width&quot;:500,&quot;resizeWidth&quot;:48,&quot;bytes&quot;:6882,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03c1617a-df51-4751-b6bf-19e0a89ed3ca_500x357.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03c1617a-df51-4751-b6bf-19e0a89ed3ca_500x357.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03c1617a-df51-4751-b6bf-19e0a89ed3ca_500x357.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03c1617a-df51-4751-b6bf-19e0a89ed3ca_500x357.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Firstly, Sitong found the simplest and safest way to fine-tune a model and ended up choosing to do so with a </span><a href="https://www.youtube.com/watch?app=desktop&amp;v=7m522D01mh0&amp;ab_channel=kasukanra" rel="">LoRa, or Low Rank Adaptation</a><span>. One of the main limitations of regular models like Stable Diffusion or MidJourney is that one cannot maintain a subject through several generations. This means that the description of a character would lead to wildly different results from one output to the next. LoRa was initially created to teach a model to learn a concept, for example a given character, that could then be generated consistently through many images. Interestingly, the model has been since then widely used to teach models not to recognize the subject of an image, but its style, leading to the now infamous case of </span><a href="https://waxy.org/2022/11/invasive-diffusion-how-one-unwilling-illustrator-found-herself-turned-into-an-ai-model/" rel="">Hollie Mengert’s work getting ripped off</a><span>.</span></p><p><span>Once the LoRa was installed and set up, we had to feed it our first dataset, a.k.a 30 of my own precious illustrations. But the images alone are not enough for the model to learn to see their style, I had to caption each illustration describing </span><em>what</em><span> it was showing, leaving unwritten </span><em>how</em><span> it looked. Captioning a dataset is a process fraught with arbitrary choices that while seemingly “intuitive”, was for me a very complex task to wrap my mind around. The goal of captioning is to teach the model that everything described in the caption will be the replaceable features of a dataset, what will be flexibly generated by prompting it later. This means that everything else, that is not described in captions, must be retained as something to apply to all output. As one Youtuber explains it, captioning is therefore a powerful semiotic action:</span></p><blockquote><p><em>“[…] because the more details you input the more precise the model is going to be. […]If you have only 20 images it is going to be pretty fast but if you have more images that's really gonna take a while. I really wish that we had some sort of software that could do it automatically but as of right now the best tool is human eyes.”</em></p></blockquote><p>So much for an automation.</p><p>My favourite way to think about this problem of captioning is Gregory Bateson’s boot. Bateson was a famous anthropologist, known for his interdisciplinary work spanning biology, psychiatry and social sciences and his founding role in the field of cybernetics in the 1950s. He was interested in the patterns that govern our lives, and the relation between parts and whole. To teach this to his student, he would use this figure:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febafd4d9-cdd6-4a06-bea9-c116b2b4e80c_690x652.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febafd4d9-cdd6-4a06-bea9-c116b2b4e80c_690x652.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febafd4d9-cdd6-4a06-bea9-c116b2b4e80c_690x652.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febafd4d9-cdd6-4a06-bea9-c116b2b4e80c_690x652.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febafd4d9-cdd6-4a06-bea9-c116b2b4e80c_690x652.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febafd4d9-cdd6-4a06-bea9-c116b2b4e80c_690x652.png" width="322" height="304.26666666666665" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ebafd4d9-cdd6-4a06-bea9-c116b2b4e80c_690x652.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:652,&quot;width&quot;:690,&quot;resizeWidth&quot;:322,&quot;bytes&quot;:36357,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febafd4d9-cdd6-4a06-bea9-c116b2b4e80c_690x652.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febafd4d9-cdd6-4a06-bea9-c116b2b4e80c_690x652.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febafd4d9-cdd6-4a06-bea9-c116b2b4e80c_690x652.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febafd4d9-cdd6-4a06-bea9-c116b2b4e80c_690x652.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Bateson Boot, reproduced from Mind and Nature, 1979</figcaption></figure></div><p>He would ask the students to describe it, and then compare the results. I’m not going to describe all the answers as you can watch a short video focusing on the exercise here: </p><div id="youtube2-bM5N9RDfPco" data-attrs="{&quot;videoId&quot;:&quot;bM5N9RDfPco&quot;,&quot;startTime&quot;:&quot;389s&quot;,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/bM5N9RDfPco?start=389s&amp;rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p>As different students describe the figure using different strategies (the way it looks, the way it can be broken into parts, etc.), Bateson tells us that “we can get a certain amount of agreement about what's really there but we cannot get an agreement about ways of describing it and we use in the description a whole mess of concepts of intervening variables and mentionables to get our stuff across.” In other words, when using words and concepts to “describe” something we see, we inevitably impose on this object the limitations that come with description.</p><p>A dataset is like a massive Bateson boot, full of complex images (expressed as numerical vectors) tied to simple words (expressed as numerical vectors). In this pairing between the sprawling complexity of our visual world and its neat description by words, much is lost. As I’m sitting at my laptop trying to come up for a caption for each of my illustration, I panic. My brain can’t seem to be able to precisely locate where meaning happens in my work, nor can it separate in neat layers the images I’ve made between style and content. The message is the medium. I try to think about how I work, my relationship to a brief, the process of sketching and the role of language in it, maybe there’s in the process of making an image the key to understand why it’s so hard to describe it.</p><p>I realize that, despite working with texts (briefs, articles, etc.), there’s always a moment when I let go of language. I usually read the text once, and then work with whatever afterimage I have left of its meaning. Part of that meaning gets transferred in the things I draw, maybe a corpse and a bookshelf because the text is about corpses in literature.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bd5685-50ca-4388-a86d-1d4458e1d749_4018x1563.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bd5685-50ca-4388-a86d-1d4458e1d749_4018x1563.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bd5685-50ca-4388-a86d-1d4458e1d749_4018x1563.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bd5685-50ca-4388-a86d-1d4458e1d749_4018x1563.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bd5685-50ca-4388-a86d-1d4458e1d749_4018x1563.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bd5685-50ca-4388-a86d-1d4458e1d749_4018x1563.png" width="1456" height="566" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/18bd5685-50ca-4388-a86d-1d4458e1d749_4018x1563.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:566,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:809437,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bd5685-50ca-4388-a86d-1d4458e1d749_4018x1563.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bd5685-50ca-4388-a86d-1d4458e1d749_4018x1563.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bd5685-50ca-4388-a86d-1d4458e1d749_4018x1563.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18bd5685-50ca-4388-a86d-1d4458e1d749_4018x1563.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The long suffering cadaver - The New York Times Book Review</figcaption></figure></div><p><span>But also, the way I choose to depict this corpse is a cut out, which I only realize as I’m sketching, because the art director suggested a two-image layout which allows for a sense of time, a sequence. Suddenly the corpse is not represented </span><em>in</em><span> the image but cut out </span><em>from</em><span> it, and only becomes the subject of the second image. All of this happens silently, keeping language at bay, to allow visual meaning-making to happen on its own. We’ll return to language later, as I get feedback from the art director and we fine tune the final image, but that process of making images from text is in large part non-linguistic, and therefore hardly contained by the linearity of neither captioning nor prompting.</span></p><p>In taking the relationship between words and images as a simple 1:1 ratio, machine learning models sacrifice much of what illustration is really about, i.e. the space between text and image. This is not to say they do a bad job, they just do a very different one than illustrators do. They see images in a very different ways illustrators see them. The division between words and images is not the only one that is being flattened in most discussions of generative AI, another crucial one is that between images and people.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf0ee00f-2cb6-4002-b6da-bc13863b6b6f_500x357.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf0ee00f-2cb6-4002-b6da-bc13863b6b6f_500x357.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf0ee00f-2cb6-4002-b6da-bc13863b6b6f_500x357.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf0ee00f-2cb6-4002-b6da-bc13863b6b6f_500x357.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf0ee00f-2cb6-4002-b6da-bc13863b6b6f_500x357.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf0ee00f-2cb6-4002-b6da-bc13863b6b6f_500x357.png" width="48" height="34.272" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/af0ee00f-2cb6-4002-b6da-bc13863b6b6f_500x357.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:357,&quot;width&quot;:500,&quot;resizeWidth&quot;:48,&quot;bytes&quot;:6882,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf0ee00f-2cb6-4002-b6da-bc13863b6b6f_500x357.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf0ee00f-2cb6-4002-b6da-bc13863b6b6f_500x357.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf0ee00f-2cb6-4002-b6da-bc13863b6b6f_500x357.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf0ee00f-2cb6-4002-b6da-bc13863b6b6f_500x357.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Once she trained the model on my work, Sitong and I meet up on Zoom. She shares her screen and shows me a series of 10 images of a woman wearing a cap. Put together on a spectrum, the images shows how the original image (a photorealistic AI image of the woman) gradually turns into a Julien Posture version of itself.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8132c89-0b0f-4c69-9d3e-78a6c9a9c9cf_4000x678.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8132c89-0b0f-4c69-9d3e-78a6c9a9c9cf_4000x678.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8132c89-0b0f-4c69-9d3e-78a6c9a9c9cf_4000x678.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8132c89-0b0f-4c69-9d3e-78a6c9a9c9cf_4000x678.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8132c89-0b0f-4c69-9d3e-78a6c9a9c9cf_4000x678.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8132c89-0b0f-4c69-9d3e-78a6c9a9c9cf_4000x678.png" width="1456" height="247" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b8132c89-0b0f-4c69-9d3e-78a6c9a9c9cf_4000x678.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:247,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2670033,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8132c89-0b0f-4c69-9d3e-78a6c9a9c9cf_4000x678.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8132c89-0b0f-4c69-9d3e-78a6c9a9c9cf_4000x678.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8132c89-0b0f-4c69-9d3e-78a6c9a9c9cf_4000x678.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8132c89-0b0f-4c69-9d3e-78a6c9a9c9cf_4000x678.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Progression of the model learning my style</figcaption></figure></div><p><span>As I’m contemplating this Cronenberg-like transformation of the image, I can’t help to be struck by the triviality of my own work. There’s something confronting in facing a computational doppelgänger, something akin to the uncanny valley. I’m surprised at how much this affects me, even though my whole schtick is to be reflexive and critical about style, what surprises me the most is that even though the output if “objectively” a failure</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-144663529" href="https://julienposture.substack.com/p/the-ai-doppelganger-experiment-part#footnote-1-144663529" target="_self" rel="">1</a></span><span>, I see myself in it. But maybe what I see in the generation, what I find actually disturbing, is the part of my work that has already been objectified and commodified, the parts of my style I spent years making digestible for clients, consistent for social media, and reproducible for easy production.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7cdd15c-99c4-4ab6-9f60-e8e8b22867f6_512x768.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7cdd15c-99c4-4ab6-9f60-e8e8b22867f6_512x768.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7cdd15c-99c4-4ab6-9f60-e8e8b22867f6_512x768.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7cdd15c-99c4-4ab6-9f60-e8e8b22867f6_512x768.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7cdd15c-99c4-4ab6-9f60-e8e8b22867f6_512x768.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7cdd15c-99c4-4ab6-9f60-e8e8b22867f6_512x768.png" width="324" height="486" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d7cdd15c-99c4-4ab6-9f60-e8e8b22867f6_512x768.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:768,&quot;width&quot;:512,&quot;resizeWidth&quot;:324,&quot;bytes&quot;:488606,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7cdd15c-99c4-4ab6-9f60-e8e8b22867f6_512x768.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7cdd15c-99c4-4ab6-9f60-e8e8b22867f6_512x768.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7cdd15c-99c4-4ab6-9f60-e8e8b22867f6_512x768.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7cdd15c-99c4-4ab6-9f60-e8e8b22867f6_512x768.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Early result from the model</figcaption></figure></div><p>As I extend the invitations to various illustrators, some categorically refuse, seeing one’s life work so easily reproduced would be too challenging they tell me. I understand. I went in this experiment confident about the distance I have with my own style, only to be shaken by the uncanniness of existing in a computational form. Is this the way people see my work? A mere surface, a bundle of shapes and colours slapped onto any idea.</p><p><span>On April 30</span><sup>th</sup><span>, </span><a href="https://www.youtube.com/watch?v=-C0dU2OV5F4&amp;ab_channel=PBSNewsHour" rel="">British artist FKA Twigs testified in front of US senate</a><span> about her experience and thoughts about AI. Her testimony weaves in the same breath issues of personhood and economic livelihood, identity and intellectual property, essence and superficiality:</span></p><blockquote><p>“I am here because my music, my dancing, my acting, the way that my body moves in front of a camera and the way that my voice resonates through a microphone is not by chance; they are essential reflections of who I am. My art is the canvas on which I paint my identity and the sustaining foundation of my livelihood. It is the essence of my being.”</p></blockquote><p>As many artists navigating the AI waters, Twigs must negotiate a delicate balance. On the one hand she mobilizes deeply emotional registers showing the inherent entanglement of her identity with her work, the “essence of [her] being”, on the other hand, she must clarify she’s not a luddite, and that her argument is mostly a rational, economic one. In fact, later she reveals having trained her own model in her likeness “to extend my reach and handle my online social media interactions, whilst I continue to focus on my art from the comfort and solace of my studio.”</p><p><a href="https://julienposture.substack.com/p/phd-journal-1" rel="">As I’ve written before</a><span>, illustration is a practice that turns artists into sort of hybrids between people and images. Illustrators style is both a very personal thing and a valuable commodity, and as illustrators’ images circulate online, fragments of themselves do too. Returning to the court, this ambiguity is best captured by Adobe’s proposition of the FAIR act (Federal Anti-Impersonation Right) which is a blend of copyright and right of publicity, conceptualizing style mimicry as a form of impersonation (see what I mean by hybrid between people and image?).</span></p><p>In lawsuits between AI companies and artists, these differences become flattened in the supposedly neutral gaze of the law. Machine learning models are constantly personified, the processes in their black box likened to that of artistic inspiration, meanwhile, artistic processes are mechanized, made simple and linear. The AI doppelgänger experiment is a way to zoom in on these tensions and ask, with artists, what is the difference between a person-created image, and a machine-generated one? And can we qualify this difference in ways that are productive for technological, legal, and social conversations about AI and creativity?</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b27f482-dec3-4ece-bddb-b8e88b6416d3_500x357.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b27f482-dec3-4ece-bddb-b8e88b6416d3_500x357.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b27f482-dec3-4ece-bddb-b8e88b6416d3_500x357.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b27f482-dec3-4ece-bddb-b8e88b6416d3_500x357.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b27f482-dec3-4ece-bddb-b8e88b6416d3_500x357.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b27f482-dec3-4ece-bddb-b8e88b6416d3_500x357.png" width="48" height="34.272" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2b27f482-dec3-4ece-bddb-b8e88b6416d3_500x357.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:357,&quot;width&quot;:500,&quot;resizeWidth&quot;:48,&quot;bytes&quot;:6882,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b27f482-dec3-4ece-bddb-b8e88b6416d3_500x357.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b27f482-dec3-4ece-bddb-b8e88b6416d3_500x357.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b27f482-dec3-4ece-bddb-b8e88b6416d3_500x357.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b27f482-dec3-4ece-bddb-b8e88b6416d3_500x357.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>A notification chimes on my phone, it’s D., an illustrator who will be testing the model soon, “when are you finally gonna copy my art — Can’t wait to see it”. The model has now been trained enough times, it’s ready to be used with prompts. D. will be the first one to try it. I’m looking forward to it. I’m also a bit worried. Will this be a triggering experience for the illustrators I work with? Or will this be vindicating? What will be generated in the encounter between human and machine ways of seeing?</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Make timelapses easily using FFmpeg (198 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40407526</link>
            <guid>40407526</guid>
            <pubDate>Sun, 19 May 2024 15:24:12 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40407526">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="40408852"><td></td></tr>
            <tr id="40408345"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40408345" href="https://news.ycombinator.com/vote?id=40408345&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>Nice, thanks! I tried using ffmpeg for a minor video editing task I had a few months ago - just a cut, crop, rescale, and volume adjust. I've tried a few of the mainstream GUI video editing tools, and IMO, they all have incomprehensible UIs, are way too bloated, and usually far too expensive for what I'm trying to do. FFmpeg may not be dead simple, but I find it much easier to skim the command line flag list to figure out how to do what I want. And once I do, I can save down a handful of useful sets of flags and refer to them next time. Cheers to ffmpeg, one of the kings of FOSS! If you ever feel the need to do any kind of video conversion or editing, definitely try to do it in ffmpeg first.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40408757"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40408757" href="https://news.ycombinator.com/vote?id=40408757&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>Indeed. I find it baffling how hard it is to just make lightweight edits to videos on Windows. At a bare minimum I would like to clip a video, or crop or change audio tracks. My cheat sheet of ffmpeg commands still remains to be the easiest way for me to do this.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40409236"><td></td></tr>
            <tr id="40408744"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40408744" href="https://news.ycombinator.com/vote?id=40408744&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><p><span>To be fair, pulling out a professional video editor for small changes is like learning emacs to edit some config files. You don't need 99% of the features.<p>Also as an FYI to everyone, FFmpeg does support nVidia GPU acceleration but it might not be enabled in your build. So check if you use it a lot.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40409152"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40409152" href="https://news.ycombinator.com/vote?id=40409152&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>Probably true, but ffmpeg seems to have a ton of features too. It seems to me that CLI apps are inherently better at not distracting you with things you don't need. A CLI flag that you don't use is invisible outside of the man pages, not so for a menu or toolbar of a zillion options with names and icons you don't understand.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40408620"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40408620" href="https://news.ycombinator.com/vote?id=40408620&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>Davinci Resolve has a free (as in beer) version that is quite capable and easy to use, even as someone who'd only used iMovie before. The only problem is that "how to do X in Davinci Resolve" has been taken over by slop.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40409138"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40409138" href="https://news.ycombinator.com/vote?id=40409138&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>Davinci Resolve is actually the first thing that came to mind on the subject of, okay it's free, that's nice, but I can't for the life of me figure out how to do anything in it. I suppose it's not necessarily their fault that the search results for how to do basic things are garbage, but I guess an advantage of CLI apps is how-to results for them don't seem to attract nearly as much SEOified clickbait.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40409019"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409019" href="https://news.ycombinator.com/vote?id=40409019&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>back when computers were hard, tips like this were gold. but these days,
for for a well trod/documented thing like ffmpeg,
asking ChatGPT to make the ffmpeg command you want works really well, eg "give me ffmpeg to make a video from a series of jpegs" and iterate from there.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40409249"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40409249" href="https://news.ycombinator.com/vote?id=40409249&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>Please don't let this line of thinking put you (the reader) off sharing tips. Here we now have a thread containing other information we may not have thought to ask anyone/thing about, discussion, history, etc.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40408878"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40408878" href="https://news.ycombinator.com/vote?id=40408878&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><p><span>Where FFMPEG really shines is stabilising video.<p>Unfortunately not all versions have "vidstab".</p><p>ffmpeg -i "$1" -vf vidstabdetect=shakiness=5:show=1  dummy.avi</p><p>ffmpeg -i "$1" -vf yadif, format=yuv420p, vidstabtransform=zoom=2:optzoom=0:crop=black -c:v libx264 -b:a 32k  stabilized264.mp4</p><p>Yesterweek's shaky video shot from a kayak: <a href="https://youtu.be/4pM0VeH4NE0?si=H2qTJfcvis3QmFlj" rel="nofollow">https://youtu.be/4pM0VeH4NE0?si=H2qTJfcvis3QmFlj</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40409023"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40409023" href="https://news.ycombinator.com/vote?id=40409023&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><p><span>If you really wish to install all the available options, you can run:<p>brew install homebrew-ffmpeg/ffmpeg/ffmpeg $(brew options homebrew-ffmpeg/ffmpeg/ffmpeg --compact)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="40409221"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409221" href="https://news.ycombinator.com/vote?id=40409221&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><p><span>Is there a variant that encodes ProRes lossless?<p>I usually open them up in a new project just to create a lossless input video to work with in After Effects, and use that (if I use image sequence directly, DaVinci Resolve acts in weird ways).</p><p>ffmpeg might ease that AE part.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40409183"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40409183" href="https://news.ycombinator.com/vote?id=40409183&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>Maybe someone should collect all those commands and create a website or a gist that list them with search possible. They are gems !</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40407826"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40407826" href="https://news.ycombinator.com/vote?id=40407826&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><p><span>ffmpeg is such a great tool!<p>Be aware that <i>-pattern_type glob</i> is not supported on Windows, though, iirc. A workaround is to name your jpegs with consecutive numbers (not necessarily starting at 0) and use a pattern with a counter placeholder in it instead.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40408208"><td></td></tr>
                <tr id="40408566"><td></td></tr>
                  <tr id="40408025"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40408025" href="https://news.ycombinator.com/vote?id=40408025&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><p><span>Obligatory humor: <a href="https://youtu.be/9kaIXkImCAM" rel="nofollow">https://youtu.be/9kaIXkImCAM</a><p>Note of support: ffmpeg supported many of the transcoding needs of my former employer back in 2007, being a "friendly" tool to the team. Yes it had/s issue. Being open source gave us a lifeline, to be able to fix our own stuff, and build up our video and audio live streaming and video watching white label service.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40408317"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40408317" href="https://news.ycombinator.com/vote?id=40408317&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>wsl --cd=%cd% ffmpeg -framerate 30 -pattern_type glob -i '*.JPG' -c:v libx264 -r 30 -pix_fmt yuv420p timelapse.mp4</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40407905"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40407905" href="https://news.ycombinator.com/vote?id=40407905&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>Hmm, I wonder why `-pattern_type glob` doesn't work on Windows. Perhaps it is something that could easily be programmed into the source code?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40408151"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40408151" href="https://news.ycombinator.com/vote?id=40408151&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>If I were yo guess, it might be using the GNU libc (or compatible) glob functionality under the hood.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40408421"><td></td></tr>
                  <tr id="40408813"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40408813" href="https://news.ycombinator.com/vote?id=40408813&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>Does this add any interframe blur or are you controlling that based on exposure time ? Very important for quality Timelapse's</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40408023"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40408023" href="https://news.ycombinator.com/vote?id=40408023&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><p><span>I recently wrote a blog post about doing this to create timelapses of Rimworld colonies. I didn’t realize -pattern_type glob didn’t work on windows though… I’ll have to update it.<p>Also, an assumption in your command is that all the images are the same aspect ratio. If they’re not, you can use this to dynamically pad it out with black bars on either size:</p><p>‘-vf "scale=1920:1080:force_original_aspect_ratio=decrease:eval=frame,pad=1920:1080:-1:-1:eval=frame"’</p><p><a href="https://mpeyton.com/posts/rimworld_timelapse_ffmpeg/" rel="nofollow">https://mpeyton.com/posts/rimworld_timelapse_ffmpeg/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40408529"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40408529" href="https://news.ycombinator.com/vote?id=40408529&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>I'd recommend Da Vinci Resolve for making timelapses. It performs really well and let's you scrub through before rendering anything which lets you clip just the part that you need. Plus you get the benefit of high export quality which can be fiddly with ffmpeg.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40409303"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40409303" href="https://news.ycombinator.com/vote?id=40409303&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>Resolve is insanely heavyweight for such a simple task. Those video editor UIs are incredibly hard to understand for people not using them every day.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40408723"><td></td></tr>
                <tr id="40409033"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40409033" href="https://news.ycombinator.com/vote?id=40409033&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>there are a bunch of flags to get exactly right in order to get it to give you a high quality image out. there are wrappers to do this more easily for you, ffmpeg is a low level tool.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40408972"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40408972" href="https://news.ycombinator.com/vote?id=40408972&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>I looked into using ffmpeg to “compress” video podcasts by lowering the framerate a lot, but it didn’t seem to do as much as I thought (about 50% size reduction). The theory was that a video podcast is mostly talking heads with an occasional chart on the screen, so you really only need a frame every second, or five seconds.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40409006"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40409006" href="https://news.ycombinator.com/vote?id=40409006&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>AV1 exceeds at these type of videos. It's why so many anime people use it.<p>Try encoding the video to AV1 with OPUS audio. You'll get ridiculous gainz!</p><p>My command is:</p><pre><code>    $ffmpegPath -i $_.FullName -r 23.976 -vf scale=1280:720 -c:v libsvtav1 -pix_fmt yuv420p10le -crf 30 -preset 10 -g 300 -c:a libopus -b:a 96k -ac 2 -c:s copy -map 0 $destPath</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40409059"><td></td></tr>
                        <tr id="40408801"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40408801" href="https://news.ycombinator.com/vote?id=40408801&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><p><span>I wanted to print out one of those flipbooks I had as a kid, where the frames are printed and as the pages are flipped it looks like a movie.<p>Is that something ffmpeg could do?</p><p>Is there any good resource for recipes like these?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40408995"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40408995" href="https://news.ycombinator.com/vote?id=40408995&amp;how=up&amp;goto=item%3Fid%3D40407526"></a></center>    </td><td><br><div>
                  <p><span>try<pre><code>    ffmpeg -ss 00:01:00 -i input.avi -t 30 -vf "fps=1,scale=320:-1:flags=lanczos" output_%04d.jpg
</code></pre>
00:01:00 is where to start the flip book, 30 is thirty seconds worth, and 1 fps is how many frames per second. this'll make output_XX.jpg from the Avi which you can then print</span></p></div></td></tr>
        </tbody></table></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Swarming Proxima Centauri: Picospacecraft Swarms over Interstellar Distances (169 pts)]]></title>
            <link>https://astrobiology.com/2024/05/swarming-proxima-centauri-coherent-picospacecraft-swarms-over-interstellar-distances.html</link>
            <guid>40407228</guid>
            <pubDate>Sun, 19 May 2024 14:33:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://astrobiology.com/2024/05/swarming-proxima-centauri-coherent-picospacecraft-swarms-over-interstellar-distances.html">https://astrobiology.com/2024/05/swarming-proxima-centauri-coherent-picospacecraft-swarms-over-interstellar-distances.html</a>, See on <a href="https://news.ycombinator.com/item?id=40407228">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                                            <figure>
                                    <img src="https://astrobiology.com/wp-content/uploads/2024/05/Swarming-Proxima-Centauri.png" alt="Swarming Proxima Centauri: Coherent Picospacecraft Swarms Over Interstellar Distances">
                                                                            <figcaption>
                                            <div>
                                                <p>
                                                                                                            Graphic depiction of Swarming Proxima Centauri: Coherent Picospacecraft Swarms Over Interstellar Distances
Thomas Eubanks                                                                                                    </p>
                                                                                            </div>
                                        </figcaption>
                                                                    </figure>
                                                        
<p>Tiny gram-scale interstellar probes pushed by laser light are likely to be the only technology capable of reaching another star this century. We presuppose availability by mid-century of a laser beamer powerful enough (~100-GW) to boost a few grams to relativistic speed, lasersails robust enough to survive launch, and terrestrial light buckets (~1-sq.km) big enough to catch our optical signals. Then our proposed representative mission, around the third quarter of this century, is to fly by our nearest neighbor, the potentially habitable world Proxima b, with a large autonomous swarm of 1000s of tiny probes.</p>



<p>Given extreme constraints on launch mass (grams), onboard power (milliwatts), and coms aperture (centimeters to meters), our team determined in our work over the last 3 years that only a large swarm of many probes acting in unison can generate an optical signal strong enough to cross the immense distance back to Earth. The 8-year round-trip time lag eliminates any practical control by Earth, therefore the swarm must possess an extraordinary degree of autonomy, for example, in order to prioritize which data is returned to Earth. Thus, the reader will see that coordinating the swarming of individuals into an effective whole is the dominant challenge for our representative mission to Proxima Centauri b. Coordination in turn rests on establishing a mesh network via low-power optical links and synchronizing probes’ on-board clocks with Earth and with each other to support accurate position-navigation-timing (PNT).</p>



<p>Our representative mission begins with a long string of probes launched one at a time to ~0.2c. After launch, the drive laser is used for signaling and clock synchronization, providing a continual time signal like a metronome. Initial boost is modulated so the tail of the string catches up with the head (“time on target”). Exploiting drag imparted by the interstellar medium (“velocity on target”) over the 20-year cruise keeps the group together once assembled. An initial string 100s to 1000s of AU long dynamically coalesces itself over time into a lens-shaped mesh network #100,000 km across, sufficient to account for ephemeris errors at Proxima, ensuring at least some probes pass close to the target.</p>



<p>A swarm whose members are in known spatial positions relative to each other, having state-of-the-art microminiaturized clocks to keep synchrony, can utilize its entire population to communicate with Earth, periodically building up a single short but extremely bright contemporaneous laser pulse from all of them. Operational coherence means each probe sends the same data but adjusts its emission time according to its relative position, such that all pulses arrive simultaneously at the receiving arrays on Earth. This effectively multiplies the power from any one probe by the number N of probes in the swarm, providing orders of magnitude greater data return.</p>



<p>A swarm would tolerate significant attrition en route, mitigating the risk of “putting all your eggs in one basket,” and enabling close observation of Proxima b from multiple vantage points. Fortunately, we don’t have to wait until mid-century to make practical progress – we can explore and test swarming techniques now in a simulated environment, which is what we propose to do in this work. We anticipate our innovations would have a profound effect on space exploration, complementing existing techniques and enabling entirely new types of missions, for example picospacecraft swarms covering all of cislunar space, or instrumenting an entire planetary magnetosphere. Well before mid-century we foresee a number of such missions, starting in Earth or lunar orbit, but in time extending deep into the outer Solar system. For example, such a swarm could explore the rapidly receding interstellar object 1I/’Oumuamua or the solar gravitational lens. These would both be precursors to the ultimate interstellar mission, but also scientifically valuable in their own right.</p>



<p>— Thomas Eubanks Space Initiatives, Inc.:</p>



<p><em><strong><a href="https://www.nasa.gov/general/niac-2024-selections/" target="_blank" rel="noreferrer noopener">2024 NIAC Phase I Selection</a>, NASA</strong></em></p>



<p>Astrobiology, Interstellar,</p>
                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Compilers for free with weval (165 pts)]]></title>
            <link>https://bernsteinbear.com/blog/weval/</link>
            <guid>40406194</guid>
            <pubDate>Sun, 19 May 2024 11:33:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bernsteinbear.com/blog/weval/">https://bernsteinbear.com/blog/weval/</a>, See on <a href="https://news.ycombinator.com/item?id=40406194">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p><a href="https://cfallin.org/">Chris Fallin</a> came and gave a talk to the Northeastern
<a href="https://prl.khoury.northeastern.edu/">Programming Research Laboratory</a>
last month. He talked about his work on a new project called
<a href="https://github.com/cfallin/weval">weval</a>, a WebAssembly partial evaluator (and
then helped me write this post!).</p>

<p>Partial evaluation is neat. In short, it’s all about taking an existing
program, modifying it to hold some of its inputs as constants, and then letting
the compiler/optimizer go hog wild on it. The result is still a program—not a
value—and it’s usually faster than the original program.</p>

<p>The usual small example is the power function. If you have a function that takes
two arguments, <code>x</code> and <code>y</code>, and returns <code>x^y</code>:</p>

<div><pre><code><span>int</span> <span>power</span><span>(</span><span>int</span> <span>x</span><span>,</span> <span>int</span> <span>y</span><span>)</span> <span>{</span>
  <span>int</span> <span>result</span> <span>=</span> <span>1</span><span>;</span>
  <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>y</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>result</span> <span>*=</span> <span>x</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>If you partially evaluate this function with respect to <code>y</code> at <code>y = 5</code>, you get
a new function that takes one argument, <code>x</code>, and returns <code>x^5</code>:</p>

<div><pre><code><span>int</span> <span>power_5</span><span>(</span><span>int</span> <span>x</span><span>)</span> <span>{</span>
  <span>int</span> <span>result</span> <span>=</span> <span>1</span><span>;</span>
  <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>result</span> <span>*=</span> <span>x</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Now, to you, this might not look that different from the original function. But
to an optimizer, it is a new world of opportunity. The optimizer can unroll the
loop and remove the conditional:</p>

<div><pre><code><span>int</span> <span>power_5</span><span>(</span><span>int</span> <span>x</span><span>)</span> <span>{</span>
  <span>return</span> <span>x</span> <span>*</span> <span>x</span> <span>*</span> <span>x</span> <span>*</span> <span>x</span> <span>*</span> <span>x</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>weval does that for entire WebAssembly modules. WebAssembly modules that are
normally much bigger than a small <code>power</code> function. You might want to use it
if, for example, your WebAssembly module is an interpreter. Imagine a world
where you have compiled a runtime such as SpiderMonkey or CPython to
WebAssembly. You could then run your Python or JavaScript programs on the
WebAssembly runtime, but they would be slower than if you had compiled them
directly to WebAssembly. And even if you compiled the JS/Python directly to
Wasm, it would probably be slow unless your compiler did some fancy static
analysis. This is where weval comes in.</p>

<h2 id="enter-weval">Enter weval</h2>

<p>SpiderMonkey and CPython are both huge. Instead, we’re going to do a little
demo of a tiny interpreter that I wrote with Chris. Our interpreter doesn’t do
much—local variables, an accumulator, arithmetic, and branching. But it’s
enough to show off the performance boosts that come with weval.</p>

<div><pre><code><span>#define FOR_EACH_INSTRUCTION(V)                                                \
  V(LOAD_IMMEDIATE)                                                            \
  V(STORE_LOCAL)                                                               \
  V(LOAD_LOCAL)                                                                \
  V(PRINT)                                                                     \
  V(PRINTI)                                                                    \
  V(JMPNZ)                                                                     \
  V(INC)                                                                       \
  V(DEC)                                                                       \
  V(ADD)                                                                       \
  V(HALT)
</span></code></pre></div>

<p>It’s designed as a little loop that reads the next instructions and dispatches
with a <code>switch</code>. It’s not the fastest design<sup id="fnref:computed-goto" role="doc-noteref"><a href="#fn:computed-goto" rel="footnote">1</a></sup>, but that’s okay.</p>

<div><pre><code><span>uword</span> <span>Execute</span><span>(</span><span>uword</span> <span>*</span><span>program</span><span>)</span> <span>{</span>
  <span>// ...</span>
  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
    <span>Instruction</span> <span>op</span> <span>=</span> <span>(</span><span>Instruction</span><span>)</span><span>program</span><span>[</span><span>pc</span><span>++</span><span>];</span>
    <span>switch</span> <span>(</span><span>op</span><span>)</span> <span>{</span>
    <span>case</span> <span>LOAD_IMMEDIATE</span><span>:</span> <span>{</span>
      <span>uword</span> <span>value</span> <span>=</span> <span>program</span><span>[</span><span>pc</span><span>++</span><span>];</span>
      <span>accumulator</span> <span>=</span> <span>(</span><span>Object</span><span>)</span><span>value</span><span>;</span>
      <span>break</span><span>;</span>
    <span>}</span>
    <span>case</span> <span>STORE_LOCAL</span><span>:</span> <span>{</span>
      <span>uword</span> <span>idx</span> <span>=</span> <span>program</span><span>[</span><span>pc</span><span>++</span><span>];</span>
      <span>LOCAL_AT_PUT</span><span>(</span><span>idx</span><span>,</span> <span>accumulator</span><span>);</span>
      <span>break</span><span>;</span>
    <span>}</span>
    <span>case</span> <span>LOAD_LOCAL</span><span>:</span> <span>{</span>
      <span>uword</span> <span>idx</span> <span>=</span> <span>program</span><span>[</span><span>pc</span><span>++</span><span>];</span>
      <span>accumulator</span> <span>=</span> <span>LOCAL_AT</span><span>(</span><span>idx</span><span>);</span>
      <span>break</span><span>;</span>
    <span>}</span>
    <span>case</span> <span>PRINT</span><span>:</span> <span>{</span>
      <span>const</span> <span>char</span> <span>*</span><span>msg</span> <span>=</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>)</span><span>program</span><span>[</span><span>pc</span><span>++</span><span>];</span>
      <span>printf</span><span>(</span><span>"%s"</span><span>,</span> <span>msg</span><span>);</span>
      <span>break</span><span>;</span>
    <span>}</span>
    <span>case</span> <span>PRINTI</span><span>:</span> <span>{</span>
      <span>printf</span><span>(</span><span>"%"</span> <span>PRIu64</span><span>,</span> <span>accumulator</span><span>);</span>
      <span>break</span><span>;</span>
    <span>}</span>
    <span>case</span> <span>HALT</span><span>:</span> <span>{</span>
      <span>return</span> <span>accumulator</span><span>;</span>
    <span>}</span>
    <span>case</span> <span>JMPNZ</span><span>:</span> <span>{</span>
      <span>uword</span> <span>offset</span> <span>=</span> <span>program</span><span>[</span><span>pc</span><span>++</span><span>];</span>
      <span>if</span> <span>(</span><span>accumulator</span> <span>!=</span> <span>0</span><span>)</span> <span>{</span>
        <span>pc</span> <span>=</span> <span>offset</span><span>;</span>
      <span>}</span>
      <span>break</span><span>;</span>
    <span>}</span>
    <span>case</span> <span>INC</span><span>:</span> <span>{</span>
      <span>accumulator</span><span>++</span><span>;</span>
      <span>break</span><span>;</span>
    <span>}</span>
    <span>case</span> <span>DEC</span><span>:</span> <span>{</span>
      <span>accumulator</span><span>--</span><span>;</span>
      <span>break</span><span>;</span>
    <span>}</span>
    <span>case</span> <span>ADD</span><span>:</span> <span>{</span>
      <span>uword</span> <span>idx1</span> <span>=</span> <span>program</span><span>[</span><span>pc</span><span>++</span><span>];</span>
      <span>uword</span> <span>idx2</span> <span>=</span> <span>program</span><span>[</span><span>pc</span><span>++</span><span>];</span>
      <span>accumulator</span> <span>=</span> <span>LOCAL_AT</span><span>(</span><span>idx1</span><span>)</span> <span>+</span> <span>LOCAL_AT</span><span>(</span><span>idx2</span><span>);</span>
      <span>break</span><span>;</span>
    <span>}</span>
    <span>// ...</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div>

<p>Using this bytecode, we can write a simple program that adds up all the numbers
from 1 to 100 million:</p>

<div><pre><code><span>enum</span> <span>{</span>
  <span>result</span> <span>=</span> <span>0</span><span>,</span>
  <span>loopc</span> <span>=</span> <span>1</span><span>,</span>
<span>};</span>
<span>uword</span> <span>program</span><span>[]</span> <span>=</span> <span>{</span>
  <span>// result = 0</span>
  <span>LOAD_IMMEDIATE</span><span>,</span> <span>0</span><span>,</span>
  <span>STORE_LOCAL</span><span>,</span> <span>result</span><span>,</span>
  <span>// loopc = 100_000_000</span>
  <span>LOAD_IMMEDIATE</span><span>,</span> <span>100000000</span><span>,</span>
  <span>STORE_LOCAL</span><span>,</span> <span>loopc</span><span>,</span>

  <span>// loop:</span>
  <span>// result += loopc</span>
  <span>ADD</span><span>,</span> <span>result</span><span>,</span> <span>loopc</span><span>,</span>
  <span>STORE_LOCAL</span><span>,</span> <span>result</span><span>,</span>
  <span>// loopc--</span>
  <span>LOAD_LOCAL</span><span>,</span> <span>loopc</span><span>,</span>
  <span>DEC</span><span>,</span>
  <span>STORE_LOCAL</span><span>,</span> <span>loopc</span><span>,</span>
  <span>// if loopc != 0, jump to loop</span>
  <span>JMPNZ</span><span>,</span> <span>8</span><span>,</span>

  <span>// print result</span>
  <span>PRINT</span><span>,</span> <span>(</span><span>uword</span><span>)</span><span>"Result: "</span><span>,</span>
  <span>LOAD_LOCAL</span><span>,</span> <span>result</span><span>,</span>
  <span>PRINTI</span><span>,</span>
  <span>PRINT</span><span>,</span> <span>(</span><span>uword</span><span>)</span><span>"</span><span>\n</span><span>"</span><span>,</span>
  <span>HALT</span><span>,</span>
<span>};</span>
</code></pre></div>

<p>We can compile this interpreter program with any C or C++ compiler, feed the
interpreter the bytecode, and it will print the result after about 350ms:</p>

<div><pre><code><span>$</span><span> </span>c++ <span>-O2</span> peval.cc <span>-o</span> peval.out
<span>$</span><span> </span>./peval.out
<span>Result: 5000000050000000
</span><span>$</span><span>
</span></code></pre></div>

<p>But let’s assume you want to sandbox this program with WebAssembly. Thankfully,
there’s this project called <a href="https://github.com/webAssembly/wasi-sdk">wasi-sdk</a>
that provides near drop-in replacements for Clang that target WebAssembly. We
can compile the interpreter with wasi-sdk and run it with <code>wasmtime</code> or any
other WebAssembly runtime that provides a WASI polyfill<sup id="fnref:polyfill" role="doc-noteref"><a href="#fn:polyfill" rel="footnote">2</a></sup>. This runs
in about 530ms:</p>

<div><pre><code><span>$</span><span> </span>/opt/wasi-sdk/bin/clang++ <span>-O2</span> peval.cc <span>-o</span> peval.normal.wasm
<span>$</span><span> </span>wasmtime peval.normal.wasm
<span>Result: 5000000050000000
</span><span>$</span><span>
</span></code></pre></div>

<p>But really what we wanted all along was to deploy the program—not the
interpreter too, <em>just</em> the program—in the sandbox. We can do that by
smushing the bytecode and the interpreter together with weval. This runs in
about 40ms:</p>

<div><pre><code><span>$</span><span> </span>/opt/wasi-sdk/bin/clang++ <span>-O2</span> <span>-DDO_WEVAL</span> <span>-I</span> include peval.cc <span>-o</span> peval.wasm
<span>$</span><span> </span>weval weval <span>-i</span> peval.wasm <span>-o</span> peval.wevaled.wasm <span>-w</span>
<span>$</span><span> </span>wasmtime peval.wevaled.wasm
<span>Result: 5000000050000000
</span><span>$</span><span>
</span></code></pre></div>

<p>First of all: let’s step back. We had an interpreter written in C++ that took
350ms to run. We made it a little slower (530ms) by compiling it to
WebAssembly. Then we got a <strong>8.5x speedup</strong> by using weval. That’s nuts. That’s
probably close to what we would get if we hand-wrote a little compiler for our
bytecode machine, but I did not have to write a compiler.</p>

<table>
  <thead>
    <tr>
      <th>Method</th>
      <th>Time (ms)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>C++</td>
      <td>350</td>
    </tr>
    <tr>
      <td>WASI</td>
      <td>530</td>
    </tr>
    <tr>
      <td>WASI+weval</td>
      <td><strong>40</strong>  (!!)</td>
    </tr>
  </tbody>
</table>

<p>Check out an <a href="https://asciinema.org/a/EesYdO0GFxkTKyAJu2vuVXjTS">asciicast</a> if
you want to feel that difference.</p>

<p>You might notice that I added some sneaky flags like <code>-DDO_WEVAL</code> and <code>-I
include</code> in there. What’s going on?</p>

<h2 id="specializing-the-interpreter">Specializing the interpreter</h2>

<p><strong>Big picture:</strong> give the interpreter function access to constant bytecode.</p>

<p>Well, while weval works <em>correctly</em> on any combination of WebAssembly module
and its input, it works <em>best</em> when you give it a little help and tell it what
data is constant. In order to do that, we pre-initialize the WebAssembly module
using a project called <a href="https://github.com/bytecodealliance/wizer">wizer</a>. It
gives you, the programmer, hooks to set up some memory before turning the
running state back into a WebAssembly module. Let’s look at a diagram of the
situation as it is right now:</p>

<figure>

<figcaption>This is too many levels of nesting</figcaption>
</figure>

<p>Right now, at run-time, the interpreter loads the bytecode and runs it. The
bytecode is not known ahead of time, so the interpreter has to be general.</p>

<p>In order to specialize the interpreter, we do three steps <em>at WebAssembly
module initialization time</em>:</p>

<ol>
  <li>Load the bytecode</li>
  <li>Create a specialized version of the interpreter function with constant
arguments</li>
  <li>Run constant propagation and other compiler passes on the function</li>
</ol>

<p>In this example, we know the bytecode is constant. We can tell weval this by
using one of its helper intrinsics. In this case, we create a copy of the
<code>Execute</code> function with constant arguments (the <code>program</code>). Now we have two
functions: <code>Execute</code> and <code>ExecuteSpecialized</code>. All of this happens in the
<code>init</code> function:</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>bool</span> <span>IsSpecialized</span><span>&gt;</span>
<span>uword</span> <span>Execute</span><span>(</span><span>uword</span> <span>*</span><span>program</span><span>)</span> <span>{</span>
    <span>// ...</span>
<span>}</span>

<span>#ifdef DO_WEVAL
</span><span>Object</span> <span>(</span><span>*</span><span>ExecuteSpecialized</span><span>)(</span><span>uword</span> <span>*</span><span>)</span> <span>=</span> <span>0</span><span>;</span>

<span>void</span> <span>init</span><span>()</span> <span>{</span>
  <span>uword</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>uword</span> <span>loopc</span> <span>=</span> <span>1</span><span>;</span>
  <span>weval</span><span>::</span><span>weval</span><span>(</span><span>&amp;</span><span>ExecuteSpecialized</span><span>,</span> <span>&amp;</span><span>Execute</span><span>&lt;</span><span>true</span><span>&gt;</span><span>,</span> <span>/*func_id=*/</span><span>123</span><span>,</span>
               <span>weval</span><span>::</span><span>SpecializeMemory</span><span>&lt;</span><span>uword</span> <span>*&gt;</span><span>(</span><span>program</span><span>,</span> <span>sizeof</span> <span>program</span><span>));</span>
<span>}</span>

<span>WIZER_INIT</span><span>(</span><span>init</span><span>);</span>
<span>WEVAL_DEFINE_GLOBALS</span><span>();</span>
<span>#endif
</span>
<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span> <span>**</span><span>argv</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>ExecuteSpecialized</span><span>)</span> <span>{</span>
    <span>ExecuteSpecialized</span><span>(</span><span>nullptr</span><span>);</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>Execute</span><span>&lt;</span><span>false</span><span>&gt;</span><span>(</span><span>program</span><span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div>

<p>Now that the code has been loaded and marked constant, the picture looks more
like this:</p>

<figure>

</figure>

<p>While the code is constant, weval isn’t magic. It won’t modify control flow, by
default, except simplifying branches that become constant (it doesn’t even know
what an interpreter is!).</p>

<p>In order to start making <code>ExecuteSpecialized</code> faster, we have to drop little
hints into the interpreter for weval to pick up. We want to actually specialize
the control flow—make the control flow in the bytecode become control flow in
the new function itself—so we tell weval about the PC to let it expand out
the code.</p>

<h2 id="modifying-the-interpreter">Modifying the interpreter</h2>

<p><strong>Big picture:</strong> unroll the loop by specializing on the program counter.</p>

<p>We can start off by telling weval what variable to use as a <em>specialization
context</em>. In this case, since we know that the bytecode is constant, we can
specialize on the <code>pc</code>—the program counter. This lets weval completely unroll
the interpreter loop.</p>

<div><pre><code><span>uword</span> <span>Execute</span><span>(</span><span>uword</span> <span>*</span><span>program</span><span>)</span> <span>{</span>
  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
    <span>// ...</span>
    <span>switch</span> <span>(</span><span>op</span><span>)</span> <span>{</span>
      <span>// ...</span>
    <span>}</span>
    <span>weval</span><span>::</span><span>update_context</span><span>(</span><span>pc</span><span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div>

<p>After running weval on the bundled module, and letting weval unroll the loop,
the picture looks like this:</p>

<figure>

</figure>

<p>This means that from this point forward, we have used weval to turn our
interpreter into a compiler. There are only two optimizations so
far—unrolling the loop and constant propagation—but they are very
effective. The result is a fully WebAssembly module with no interpreter and no
bytecode.</p>

<p>Weval’s compiler passes are not magic. They are the same passes that any
compiler would run on your code. They can unroll the interpreter loop and turn
bytecode into straight-line WebAssembly code. But that code still has local
variable writes push and local variable reads and all the other overhead of the
interpreter. So there’s more to be done…</p>

<h2 id="but-what-if-we-modified-it-more">But what if we modified it more?</h2>

<p><strong>Big picture:</strong> unroll interpreter local variables into WebAssembly local
variables by telling weval where they are.</p>

<p>Memory can be hard to reason about in a compiler. Weval isn’t a whole program
optimizing compiler and might not be able to prove that a memory location (in
this case, the locals array) never escapes or aliases something else. But we,
the interpreter authors, know that. So we can add more hints.</p>

<p>Right now, <code>LOCAL_AT</code> and <code>LOCAL_AT_PUT</code> are macros that read and write to the
locals array:</p>

<div><pre><code><span>#define LOCAL_AT(idx) (locals[idx])
#define LOCAL_AT_PUT(idx, val) (locals[idx] = val)
</span></code></pre></div>

<p>That’s all well and good for the interpreter, but it’s not great for the
compiled code. What we really want is to give weval the ability to reason about
each memory location—each local index—separately as an SSA value.</p>

<p>In order to do that, we use weval intrinsics: <code>weval_read_reg</code> and
<code>weval_write_reg</code>. For maximum flexibility, we have a couple of macros that
switch between the two:</p>

<div><pre><code><span>#ifdef DO_WEVAL
#define LOCAL_AT(idx) (IsSpecialized ? weval_read_reg(idx) : locals[idx])
#define LOCAL_AT_PUT(idx, val)                                                 \
  if (IsSpecialized) {                                                         \
    weval_write_reg(idx, val);                                                 \
  } else {                                                                     \
    locals[idx] = val;                                                         \
  }
#else
#define LOCAL_AT(idx) (locals[idx])
#define LOCAL_AT_PUT(idx, val) (locals[idx] = val)
#endif
</span></code></pre></div>

<p>Now, weval can reason about each local variable separately and they get
eventually compiled to normal WebAssembly locals.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p>The big idea here is that it’s possible to incrementally unravel an interpreter
into a compiler by specializing on constant data and then doing normal compiler
passes. The more you can specialize at build-time, the faster the resulting
generated code will be.</p>

<p>Check out the code in my <a href="https://github.com/tekknolagi/weval">already old fork of
weval</a>. It includes surprise benchmarks of
Wasm JITs in different JS runtimes, too!</p>

<h2 id="looking-forward">Looking forward</h2>

<p>Chris gave some more detail about how weval works in <a href="https://bernsteinbear.com/assets/img/weval_slides.pdf">this
talk</a> (PDF), including a description of how the
interpreter function is actually combined with the bytecode. The main idea is
to use the PC values as a “context” in a context-sensitive dataflow analysis,
so regular constant propagation will see the PC value and opcode for just one
interpreter loop iteration, rather than the union of all of them (as a static
analysis normally would). There are a bunch of fiddly details to make it work
well, and Chris also plans to write a blog post covering weval and its
application to SpiderMonkey soon.</p>

<p>Also, our interpreter is tiny and not very interesting on its own. It’s only
useful to explain some weval concepts to you. But the same principles apply to
much larger interpreters, too! There’s SpiderMonkey, yes, and the same could
also probably be done for CPython, the main Python runtime. CPython even has
support for being compiled to WebAssembly already!</p>

<p>Imagine compiling Python directly down to WebAssembly… maybe coming soon?</p>

<h2 id="wilder-ideas">Wilder ideas</h2>

<p>CPython already has support for vectorcall function pointers. This is a way to
add a JIT compiler in a portable way. We could also maybe use this to turn
weval into a Wasm JIT for CPython.</p>

<h2 id="similar-projects">Similar projects</h2>

<p><a href="https://github.com/BuildIt-lang/buildit">BuildIt</a> is a similar project for C++
that takes a library approach.</p>


        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Transforming a QLC SSD into an SLC SSD (226 pts)]]></title>
            <link>https://theoverclockingpage.com/2024/05/13/tutorial-transforming-a-qlc-ssd-into-an-slc-ssd-dramatically-increasing-the-drives-endurance/?lang=en</link>
            <guid>40405578</guid>
            <pubDate>Sun, 19 May 2024 09:30:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theoverclockingpage.com/2024/05/13/tutorial-transforming-a-qlc-ssd-into-an-slc-ssd-dramatically-increasing-the-drives-endurance/?lang=en">https://theoverclockingpage.com/2024/05/13/tutorial-transforming-a-qlc-ssd-into-an-slc-ssd-dramatically-increasing-the-drives-endurance/?lang=en</a>, See on <a href="https://news.ycombinator.com/item?id=40405578">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wtr-content" data-bg="transparent" data-fg="#dd1616" data-width="8" data-mute="" data-fgopacity="0.85" data-mutedopacity="0.5" data-placement="top" data-placement-offset="0" data-content-offset="0" data-placement-touch="top" data-placement-offset-touch="0" data-transparent="1" data-shadow="1" data-touch="0" data-non-touch="1" data-comments="0" data-commentsbg="#dd1616" data-location="page" data-mutedfg="#dd1616" data-endfg="#dd1616" data-rtl="0">
<p>In today’s article, we’re embarking on something unprecedented! We’ll guide you step by step through the process of transforming an SSD equipped with QLC NANDs into an SLC SSD, significantly enhancing its durability and overall performance!</p>
<h3 id="especificacoes-do-ssd">Especification of the DUT SSD:</h3>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/SSD-Lineup-US.png?ssl=1"><img decoding="async" width="499" height="578" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/SSD-Lineup-US.png?resize=499%2C578&amp;ssl=1" alt="SSD Lineup US" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 2" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/SSD-Lineup-US.png?w=499&amp;ssl=1 499w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/SSD-Lineup-US.png?resize=259%2C300&amp;ssl=1 259w" sizes="(max-width: 499px) 100vw, 499px" data-recalc-dims="1"></a></figure></div>
<p>The SSD I chose is a <strong>Crucial BX500</strong>, which we’ve tested numerous times both on our website and on my YouTube channel.</p>
<h3 id="softwares-do-ssd"><strong>ATENTION: BEFORE YOU CONTINUE READING</strong>!!!</h3>
<p>Firstly, this procedure is safer than overclocking, but it still requires caution. Only proceed if you are genuinely interested, as I cannot be held responsible if any steps are executed incorrectly. I will explain as clearly as possible to minimize any misunderstandings.</p>
<p>This voids the warranty of any SSD. <strong>AND REMEMBER, WHEN FLASHING THE FIRMWARE TO THE SSD, ALL DATA WILL BE ERASED</strong>, so be sure to back up your devices before proceeding with anything.</p>
<h3 id="unboxing"><strong>NECESSARY TOOLS</strong></h3>
<p>To perform this procedure, it was necessary to use an adapter SATA to USB 3.0 adapter with the<strong> Jmicron JMS578 Bridge Chip</strong> model.</p>
<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/theoverclockingpage.com\/2024\/05\/13\/tutorial-transforming-a-qlc-ssd-into-an-slc-ssd-dramatically-increasing-the-drives-endurance\/?lang=en&quot;}">
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2023/06/Ferramenta-SSD-Card-Opener-4.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="540" data-id="32602" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2023/06/Ferramenta-SSD-Card-Opener-4.jpg?resize=720%2C540&amp;ssl=1" alt="Ferramenta SSD Card Opener 4" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 3" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2023/06/Ferramenta-SSD-Card-Opener-4.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2023/06/Ferramenta-SSD-Card-Opener-4.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2023/06/Ferramenta-SSD-Card-Opener-4.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2023/06/Ferramenta-SSD-Card-Opener-4.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2023/06/Ferramenta-SSD-Card-Opener-4.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2023/06/Ferramenta-SSD-Card-Opener-4.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2023/06/Ferramenta-SSD-Card-Opener-4.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2023/06/Ferramenta-SSD-Card-Opener-4.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/01/image-2.png?ssl=1"><img loading="lazy" decoding="async" width="720" height="720" data-id="53404" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/01/image-2.png?resize=720%2C720&amp;ssl=1" alt="image 2" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 4" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/01/image-2.png?w=1000&amp;ssl=1 1000w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/01/image-2.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/01/image-2.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/01/image-2.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/01/image-2.png?resize=1200%2C1200&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/01/image-2.png?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/01/image-2.png?resize=600%2C600&amp;ssl=1 600w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/01/image-2.png?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/01/image-2.png?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/01/image-2.png?resize=160%2C160&amp;ssl=1 160w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
</figure>
<p>In addition to, we also need a clamp to perform the short on the ROM/Safe Mode terminals on the SSD’s PCB.</p>
<h3 id="unboxing">Technical Specs</h3>
<p>Before we move on to the tutorial, let’s analyze this SSD a little further.</p>
<p><strong>Controller</strong><br></p>
<p>The SSD controller is responsible for handling all data management tasks, including over-provisioning and garbage collection, among other background functions. Naturally, this contributes to the SSD’s overall performance.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2022/11/ssd-crucial-bx500-500gb-controlador.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="332" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2022/11/ssd-crucial-bx500-500gb-controlador.jpg?resize=720%2C332&amp;ssl=1" alt="ssd crucial bx500 500gb controlador" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 5" data-recalc-dims="1"></a></figure></div>
<p>In this project, the SSD utilizes the <strong>Silicon Motion</strong> controller model <strong>SM2259XT2</strong>, which is a new variant of the <strong>SM2259XT</strong>.</p>
<p>In this case, it’s a <strong>single-core</strong> controller, meaning it has one main core responsible for managing the NANDs, with a <strong>32-bit ARC</strong> architecture, not <strong>ARM </strong>as we’re accustomed to. This controller has an operating frequency up to <strong>550 MHz</strong>, but as we’ll see in the following image, in this project, it was operating at <strong>437.5 MHz</strong>.</p>
<p>This controller also supports up to <strong>2 communication channels</strong> with a bus speed of up to <strong>800 MT/s</strong>, where each of these channels supports up to <strong>8 Chip Enable</strong> commands, allowing the controller to communicate with up to <strong>16 Dies</strong> simultaneously using the <strong>interleaving</strong> technique.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-02-111225.png?ssl=1"><img loading="lazy" decoding="async" width="720" height="496" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-02-111225.png?resize=720%2C496&amp;ssl=1" alt="Screenshot 2024 03 02 111225" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 6" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-02-111225.png?w=844&amp;ssl=1 844w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-02-111225.png?resize=300%2C207&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-02-111225.png?resize=768%2C530&amp;ssl=1 768w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>What was different from its predecessor, the <strong>SM2259XT</strong>, which had <strong>4 channels</strong> and <strong>4 C.E</strong>. supporting a maximum of <strong>16 dies</strong>.</p>
<p><strong>DRAM&nbsp;Cache or H.M.B.</strong><br></p>
<p>Every top-of-the-line SSD aiming to deliver consistent high performance requires a buffer to store its mapping tables (<em><strong>Flash Translation Layer</strong></em> or <em><strong>Look-up table</strong></em>). This enables better random performance and responsiveness.</p>
<p>Being a DRAM-Less SATA SSD, it doesn’t support Host Memory Buffer (HMB) technology.</p>
<p><strong>NAND Flash</strong><br></p>
<p>Regarding its storage integrated circuits, the 500GB SSD has 2 NAND flash chips labeled “<strong>NY240</strong>,” which when decoded yield the NANDs “<strong>MT29F2T08GELCEJ4-QU:C</strong>” from the American manufacturer <strong>Micron</strong>, model <strong>N48R Media Grade</strong>. In this case, they are 1Tb (128GiB) dies containing 176 layers of data and a total of 195 gates, resulting in an array efficiency of 90.2%.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2022/11/ssd-crucial-bx500-500gb-nand-flash.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="332" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2022/11/ssd-crucial-bx500-500gb-nand-flash.jpg?resize=720%2C332&amp;ssl=1" alt="ssd crucial bx500 500gb nand flash" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 7" data-recalc-dims="1"></a></figure></div>
<p>In this SSD, each NAND Flash contains 2 dies with 1Tb of density, totaling 256GB per NAND, resulting in a total of 500GB. They communicate with the controller using a bus speed of <strong>262.5 MHz</strong> (<strong>525 MT/s</strong>), which is considerably below what the NANDs are capable of. These <strong>N48R </strong>dies are capable of operating at <strong>800 MHz</strong> (<strong>1600 MT/s</strong>).</p>
<p>There are several reasons why they might be running so low, such as the manufacturer opting to reduce power consumption and heat. Or even this batch of NAND Flash not being able to pass Micron’s Quality Control at higher frequencies and ends up being sold cheaper or perhaps has a lower endurance as well, which generally results in lower NAND costs, enabling SSDs like this to have a very low price.</p>
<p><strong>SOFTWARE UTILIZED FOR THIS PROJECT</strong></p>
<p>As this is a <strong>Silicon Motion</strong> controller, we will be using a mass production tool from them, known as <strong>MPTools</strong>. It’s worth noting that these softwares are <strong>NOT</strong> provided by the manufacturers but are LEAKED by individuals with access, and posted on Russian or Chinese forums.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-1.png?ssl=1"><img loading="lazy" decoding="async" width="720" height="190" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-1.png?resize=720%2C190&amp;ssl=1" alt="image 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 8" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-1.png?w=1017&amp;ssl=1 1017w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-1.png?resize=300%2C79&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-1.png?resize=768%2C203&amp;ssl=1 768w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>For this project, we will use the “<strong>SMI SM2259XT2 MPTool FIMN48 V0304A FWV0303B0</strong>“, which needs to be compatible with both the controller and the NAND Flash, and this tool allows us to do that.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-2.png?ssl=1"><img loading="lazy" decoding="async" width="720" height="379" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-2.png?resize=720%2C379&amp;ssl=1" alt="image 2" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 9" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-2.png?resize=1024%2C539&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-2.png?resize=300%2C158&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-2.png?resize=768%2C404&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-2.png?resize=1200%2C632&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-2.png?w=1366&amp;ssl=1 1366w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>Before making any modifications, we need to retrieve certain parameters from the SSD to preserve them. These values in the software are a preset from another SSD that may have different parameters. We need to obtain the following parameters:</p>
<ul>
<li>Flash IO Driving with it’s subivisons</li>
<li>Flash Control Driving</li>
<li>Flash DQS/Data Driving</li>
</ul>
<p>These parameters use hexadecimal values and must be changed according to the desired speed that we will configure for the SSD.</p>
<p>We also have many more parameters such as:</p>
<ul>
<li>Control ODT (On-die Termination)</li>
<li>Flash ODT (On-die Termination)</li>
<li>Schmitt Window Trigger</li>
</ul>
<p>To get these parameters, we need to go to the main screen of <strong>MPTools </strong>as shown below:</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-3.png?ssl=1"><img loading="lazy" decoding="async" width="720" height="456" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-3.png?resize=720%2C456&amp;ssl=1" alt="image 3" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 10" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-3.png?w=1014&amp;ssl=1 1014w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-3.png?resize=300%2C190&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-3.png?resize=768%2C486&amp;ssl=1 768w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>And then we’ll click on “Scan,” which will scan all compatible disks in the system:</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-4.png?ssl=1"><img loading="lazy" decoding="async" width="259" height="245" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-4.png?resize=259%2C245&amp;ssl=1" alt="image 4" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 11" data-recalc-dims="1"></a></figure></div>
<p>After this, the SSD will be shown on port 1 if everything has gone smoothly so far, remembering that it’s not necessary to put the SSD in <strong>Safe Mode/ROM Mode</strong> yet.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-5.png?ssl=1"><img loading="lazy" decoding="async" width="720" height="216" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-5.png?resize=720%2C216&amp;ssl=1" alt="image 5" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 12" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-5.png?w=1009&amp;ssl=1 1009w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-5.png?resize=300%2C90&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-5.png?resize=768%2C230&amp;ssl=1 768w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>Now we double-click on this Blue Name “<strong>Ready (FW: M6CR061, MN48R)</strong>“, which, when clicked twice, will open this new screen with SSD information.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-6.png?ssl=1"><img loading="lazy" decoding="async" width="720" height="495" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-6.png?resize=720%2C495&amp;ssl=1" alt="image 6" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 13" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-6.png?w=843&amp;ssl=1 843w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-6.png?resize=300%2C206&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-6.png?resize=768%2C527&amp;ssl=1 768w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>Then we should click on both Card mode and CID Settings to see all the parameters that the SSD comes with from the factory.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-7.png?ssl=1"><img loading="lazy" decoding="async" width="720" height="495" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-7.png?resize=720%2C495&amp;ssl=1" alt="image 7" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 14" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-7.png?w=843&amp;ssl=1 843w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-7.png?resize=300%2C206&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-7.png?resize=768%2C527&amp;ssl=1 768w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>After noting these parameters, we also see here the speed of the controller and the NAND, which for the sake of a fair comparison, we will leave at these same frequencies.</p>
<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/theoverclockingpage.com\/2024\/05\/13\/tutorial-transforming-a-qlc-ssd-into-an-slc-ssd-dramatically-increasing-the-drives-endurance\/?lang=en&quot;}">
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-02-111225-Copy-1.png?ssl=1"><img loading="lazy" decoding="async" width="330" height="273" data-id="55104" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-02-111225-Copy-1.png?resize=330%2C273&amp;ssl=1" alt="Screenshot 2024 03 02 111225 Copy 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 15" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-02-111225-Copy-1.png?w=330&amp;ssl=1 330w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-02-111225-Copy-1.png?resize=300%2C248&amp;ssl=1 300w" sizes="(max-width: 330px) 100vw, 330px" data-recalc-dims="1"></a></figure>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-02-111303-Copy-1.png?ssl=1"><img loading="lazy" decoding="async" width="325" height="268" data-id="55102" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-02-111303-Copy-1.png?resize=325%2C268&amp;ssl=1" alt="Screenshot 2024 03 02 111303 Copy 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 16" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-02-111303-Copy-1.png?w=325&amp;ssl=1 325w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-02-111303-Copy-1.png?resize=300%2C247&amp;ssl=1 300w" sizes="(max-width: 325px) 100vw, 325px" data-recalc-dims="1"></a></figure>
</figure>
<p><strong>Applying Configurations</strong></p>
<p>Initially, we should click on the “Edit Config” button in the top right corner, and the default password is “space 2x,” which is literally ” “.</p>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-06-142821.png?ssl=1"><img loading="lazy" decoding="async" width="720" height="517" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-06-142821.png?resize=720%2C517&amp;ssl=1" alt="Screenshot 2024 03 06 142821" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 17" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-06-142821.png?w=997&amp;ssl=1 997w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-06-142821.png?resize=300%2C215&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/Screenshot-2024-03-06-142821.png?resize=768%2C552&amp;ssl=1 768w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
<p>After enabling the options to configure the SSD, let’s start by giving a name to this project. In the “<strong>Model Name:</strong>” field, we’ll enter the name that the SSD will have. This one was named “<strong>SSD SLC Test</strong>.”</p>
<p>Next, we’ll add a <strong>tag </strong>to this new firmware. In the red rectangle number 3, we’ll go to the “<strong>Firmware Version:</strong>” field and enter whatever we desire. I used “<strong>SSD-SLC</strong>” as an example.</p>
<p>Next, we arrive at one of the most crucial parts, the section on signal integrity, as all these other parameters are sensitive and must be adjusted precisely.</p>
<p>Let’s start with the top 2 parameters, “<strong>Flash Control Driving (hex)</strong>” and “<strong>Flash DQS/Data Driving (Hex)</strong>“. As we saw in the previous images, these parameters come with values of 66 in hexadecimal, so we will keep them. These 2 parameters can be found in the images below:</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-8.png?ssl=1"><img loading="lazy" decoding="async" width="329" height="270" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-8.png?resize=329%2C270&amp;ssl=1" alt="image 8" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 18" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-8.png?w=329&amp;ssl=1 329w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-8.png?resize=300%2C246&amp;ssl=1 300w" sizes="(max-width: 329px) 100vw, 329px" data-recalc-dims="1"></a></figure></div>
<p>After configuring these 2, let’s move on to the frequencies. As we can see in the image below, we take these 2 values and set them. The CPU in this software came by default at 500 MHz while the NAND at 250 MHz. The NAND will increase the clock slightly and the CPU will decrease, I will not overclock here for a fair comparison. Next, we’ll leave the Output driving at 03H, which is the signal closest to 04H that the SSD had.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-10.png?ssl=1"><img loading="lazy" decoding="async" width="327" height="269" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-10.png?resize=327%2C269&amp;ssl=1" alt="image 10" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 19" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-10.png?w=327&amp;ssl=1 327w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-10.png?resize=300%2C247&amp;ssl=1 300w" sizes="(max-width: 327px) 100vw, 327px" data-recalc-dims="1"></a></figure></div>
<p>Next, we have the last 3 settings to resolve: <strong>Flash ODT</strong>, <strong>Control ODT</strong>, and <strong>Schmitt Window.</strong> In this case, we apply the values circled in red in each of these parameters in their respective fields.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-16.png?ssl=1"><img loading="lazy" decoding="async" width="327" height="271" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-16.png?resize=327%2C271&amp;ssl=1" alt="image 16" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 20" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-16.png?w=327&amp;ssl=1 327w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-16.png?resize=300%2C249&amp;ssl=1 300w" sizes="(max-width: 327px) 100vw, 327px" data-recalc-dims="1"></a></figure></div>
<p>Good, here we have reached the end of another stage of this procedure. And we begin the next following step, which is the modification of the software. Because by default, this version of MPTools would not support this modification.</p>
<p>Initially, we need to go to the directory of this program in the “<strong>UFD_MP</strong>” folder located in the root directory.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-19.png?ssl=1"><img loading="lazy" decoding="async" width="661" height="499" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-19.png?resize=661%2C499&amp;ssl=1" alt="image 19" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 21" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-19.png?w=661&amp;ssl=1 661w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-19.png?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-19.png?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 661px) 100vw, 661px" data-recalc-dims="1"></a></figure></div>
<p>Inside this folder, we should look for the file named “<strong>Setting.set</strong>,” which is a configuration file of <strong>MPTools</strong>. Let’s open it using the Windows Notepad.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-20.png?ssl=1"><img loading="lazy" decoding="async" width="636" height="341" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-20.png?resize=636%2C341&amp;ssl=1" alt="image 20" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 22" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-20.png?w=636&amp;ssl=1 636w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-20.png?resize=300%2C161&amp;ssl=1 300w" sizes="(max-width: 636px) 100vw, 636px" data-recalc-dims="1"></a></figure></div>
<p>With the file open, we’ll make 2 modifications, the first one being in the section “<strong>[Function]</strong>“, where we have the configuration named “<strong>ENFWTAG=1</strong>,” which we should change its logical level from <strong>1</strong> to <strong>0</strong>.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-22.png?ssl=1"><img loading="lazy" decoding="async" width="720" height="560" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-22.png?resize=720%2C560&amp;ssl=1" alt="image 22" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 23" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-22.png?w=948&amp;ssl=1 948w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-22.png?resize=300%2C233&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-22.png?resize=768%2C597&amp;ssl=1 768w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>The other configuration is in the category “<strong>[Option]</strong>“, where we will add one more extra command line. This command is as follows: “<strong>EnSLCMode=1</strong>“. So after that, we save the file and reopen the MPTools.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-23.png?ssl=1"><img loading="lazy" decoding="async" width="456" height="240" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-23.png?resize=456%2C240&amp;ssl=1" alt="image 23" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 24" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-23.png?w=456&amp;ssl=1 456w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-23.png?resize=300%2C158&amp;ssl=1 300w" sizes="(max-width: 456px) 100vw, 456px" data-recalc-dims="1"></a></figure></div>
<p>With MPTools open, we can see that in the “<strong>Select Procedure</strong>” section, there is now an option called “<strong>Force SLC Mode</strong>“, which we should check. But let’s take it easy because we haven’t finished the modifications yet. There’s no point in trying to write this new firmware to the SSD if it’s still going to operate in its native mode, whether it’s TLC or QLC.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-24.png?ssl=1"><img loading="lazy" decoding="async" width="371" height="208" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-24.png?resize=371%2C208&amp;ssl=1" alt="image 24" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 25" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-24.png?w=371&amp;ssl=1 371w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-24.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-24.png?resize=520%2C292&amp;ssl=1 520w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-24.png?resize=1000%2C562&amp;ssl=1 1000w" sizes="(max-width: 371px) 100vw, 371px" data-recalc-dims="1"></a></figure></div>
<p>Now we’ve reached the crucial part that enables all these modifications we’ve made to become possible. We need to take the boot and firmware initialization files from a folder within MPTools and place these files in another directory of the program.</p>
<p>First, we return to the default directory of MPTools and open the “<strong>Firmware</strong>” folder within the software.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-25.png?ssl=1"><img loading="lazy" decoding="async" width="648" height="502" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-25.png?resize=648%2C502&amp;ssl=1" alt="image 25" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 26" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-25.png?w=648&amp;ssl=1 648w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-25.png?resize=300%2C232&amp;ssl=1 300w" sizes="(max-width: 648px) 100vw, 648px" data-recalc-dims="1"></a></figure></div>
<p>Inside this folder, we will find one named “<strong>2259</strong>,” which refers to the <strong>SM2259XT2 </strong>controller of this SSD. Within this folder, there should be another folder named “<strong>IMN48</strong>” along with a configuration file and parameters file.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-27.png?ssl=1"><img loading="lazy" decoding="async" width="424" height="120" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-27.png?resize=424%2C120&amp;ssl=1" alt="image 27" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 27" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-27.png?w=424&amp;ssl=1 424w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-27.png?resize=300%2C85&amp;ssl=1 300w" sizes="(max-width: 424px) 100vw, 424px" data-recalc-dims="1"></a></figure></div>
<p>Once again, we enter this <strong>IMN48 </strong>folder, where we will encounter numerous files and folders.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-29.png?ssl=1"><img loading="lazy" decoding="async" width="636" height="163" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-29.png?resize=636%2C163&amp;ssl=1" alt="image 29" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 28" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-29.png?w=636&amp;ssl=1 636w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-29.png?resize=300%2C77&amp;ssl=1 300w" sizes="(max-width: 636px) 100vw, 636px" data-recalc-dims="1"></a></figure></div>
<p>Let’s move forward and open the “<strong>00</strong>” folder, then select all the files and folders within the “<strong>00</strong>” folder.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-31.png?ssl=1"><img loading="lazy" decoding="async" width="641" height="238" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-31.png?resize=641%2C238&amp;ssl=1" alt="image 31" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 29" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-31.png?w=641&amp;ssl=1 641w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-31.png?resize=300%2C111&amp;ssl=1 300w" sizes="(max-width: 641px) 100vw, 641px" data-recalc-dims="1"></a></figure></div>
<p>We will “<strong>copy</strong>” (not cut) to the previous folder, the “<strong>00</strong>” folder, which should look like the following image:</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-33.png?ssl=1"><img loading="lazy" decoding="async" width="648" height="351" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-33.png?resize=648%2C351&amp;ssl=1" alt="image 33" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 30" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-33.png?w=648&amp;ssl=1 648w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-33.png?resize=300%2C163&amp;ssl=1 300w" sizes="(max-width: 648px) 100vw, 648px" data-recalc-dims="1"></a></figure></div>
<p>And then we should enter the “<strong>XT2</strong>” folder and copy this single file inside it called “<strong>BootISP2259.bin</strong>” to this “<strong>00</strong>” directory as shown in the next image.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-35.png?ssl=1"><img loading="lazy" decoding="async" width="644" height="381" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-35.png?resize=644%2C381&amp;ssl=1" alt="image 35" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 31" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-35.png?w=644&amp;ssl=1 644w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-35.png?resize=300%2C177&amp;ssl=1 300w" sizes="(max-width: 644px) 100vw, 644px" data-recalc-dims="1"></a></figure></div>
<p>Next, we’ll copy all these files from the folder and paste them into the previous “<strong>2259</strong>” directory as shown in the following image:</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-39.png?ssl=1"><img loading="lazy" decoding="async" width="672" height="576" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-39.png?resize=672%2C576&amp;ssl=1" alt="image 39" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 32" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-39.png?w=672&amp;ssl=1 672w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-39.png?resize=300%2C257&amp;ssl=1 300w" sizes="(max-width: 672px) 100vw, 672px" data-recalc-dims="1"></a></figure></div>
<p><strong>IT IS IMPORTANT TO NOTE THAT THIS PROCEDURE WITH THESE FILES IS FOR THIS KIT OF SM2259XT2 + NANDS N48R.</strong></p>
<p><strong>OTHER SSDS WITH DIFFERENT NANDS FOLLOW THE SAME PROCEDURE, BUT WITH DIFFERENT FOLDER NAMES. THE N48 FOLDERS WILL BE NAMED ACCORDING TO THE NAND MANUFACTURER, AS SHOWN IN THE EXAMPLE BELOW OF AN SSD WITH SM2259XT2 CONTROLLER + KIOXIA BiCS5 NANDs.</strong></p>
<p>P.S.: Some NAND models may not be 100% compatible. So far, I’ve only tested with Intel and Micron NANDs.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/04-1.png?ssl=1"><img loading="lazy" decoding="async" width="720" height="161" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/04-1.png?resize=720%2C161&amp;ssl=1" alt="04 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 33" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/04-1.png?resize=1024%2C229&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/04-1.png?resize=300%2C67&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/04-1.png?resize=768%2C172&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/04-1.png?resize=1200%2C269&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/04-1.png?w=1468&amp;ssl=1 1468w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>Tendo deixado isto claro, agora sim voltamos ao programa <strong>MPTools</strong>, vamos em <strong>Parameter </strong>novamente e vamos checar todas as configurações anteriores para ver se ainda estão aplicadas.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-37.png?ssl=1"><img loading="lazy" decoding="async" width="720" height="514" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-37.png?resize=720%2C514&amp;ssl=1" alt="image 37" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 34" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-37.png?w=1006&amp;ssl=1 1006w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-37.png?resize=300%2C214&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-37.png?resize=768%2C548&amp;ssl=1 768w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>If everything is correct, let’s go to the “<strong>Test</strong>” section next to “<strong>Parameter</strong>,” which is the program’s main screen. Now we should put the SSD into ROM mode. Let’s close the software again.</p>
<h3 id="softwares-do-ssd"><strong>HOW MUCH DID THE ENDURANCE INCREASED?</strong></h3>
<p>To calculate durability precisely, we need the following information:</p>
<p><strong>Write Amplification Factor</strong></p>
<p><strong>NAND: Program/Erase Cycle</strong></p>
<p><strong>SSD’s Capacity</strong></p>
<p>With these 3 parameters, we can have a basic understanding of TBW (Terabytes Written), but remember that it’s an approximate value. For a more precise calculation, following the <strong>JEDEC JESD218A</strong> parameters would be necessary, which includes more complicated parameters like <strong>Wear-Leveling Efficiency</strong> (<strong>W.L.E.</strong>).</p>
<p>Using this basic calculation with the SSD in its default mode, we see that it has a <strong>TBW</strong> of <strong>120TB</strong>, with a <strong>Program/Erase Cycle</strong> of these <strong>Media Grade N48R</strong> NANDs around <strong>900 P.E.C</strong>. And how do I know this? I managed to access the datasheet of the NANDs. Taking this into consideration, we can reach the conclusion below, considering the calculation:</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-41.png?ssl=1"><img loading="lazy" decoding="async" width="720" height="193" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-41.png?resize=720%2C193&amp;ssl=1" alt="image 41" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 35" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-41.png?w=1003&amp;ssl=1 1003w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-41.png?resize=300%2C80&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-41.png?resize=768%2C206&amp;ssl=1 768w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p> <strong>120 TB (TBW) = (900 P.E.C. x 0.5 TB)</strong> <br> ———————- <br> <strong> X (W.A.F)</strong> </p>
<p> <strong>X = 3.75 W.A.F.</strong></p>
<p>We see that based on this, the SSD’s WAF in its native form would be quite high, in the range of 3.75, when tested in practical scenarios it was close to 3.8 WAF.</p>
<p>Now, in pSLC mode, the parameters change. The NAND from this Die can withstand up to <strong>60,000 P/E</strong> <strong>cycles</strong> according to the datasheet, and its capacity drops to 0.12TB (120GB). When I randomly tested the SSD, I noticed that its WAF was below 2, which improved significantly.</p>
<p><strong> </strong> <strong>X TB (TBW) = (60.000 P.E.C. x 0.12 TB)</strong> <br> ———————- <br> <strong>1.8 (W.A.F)</strong></p>
<p><strong>X = 4000 TB (TBW)</strong></p>
<p>We see that the TBW has increased drastically, from <strong>120TB</strong>(500GB QLC) to <strong>4,000TB</strong> (120GB pSLC), which is an increase of over 3333%, more than 3000 percent.</p>
<p><strong>TEST BENCH</strong><br>– OS: Windows 11 Pro 64-bit (Build: 23H2)<br>– CPU: Intel Core i7 13700K (5.7GHz all core) (E-cores e Hyper-threading desabled)<br>– RAM: 2&nbsp;×&nbsp;16 GB DDR4-3200MHz CL-16 Netac&nbsp;(c/ XMP)<br>– Motherboard: MSI Z790-P PRO WIFI D4&nbsp;(Bios Ver.:&nbsp;<strong>7E06v18</strong>)<br>– GPU: RTX 4060 Galax 1-Click OC (Drivers: 537.xx)<br>– (OS Drive): SSD Solidigm P44 Pro 2TB (Firmware:&nbsp;<strong>001C</strong>)<br>– DUT SSD: SSD BX500 “SLC-Test” 2TB (Firmware:&nbsp;<strong><strong>My custom firmware</strong></strong>)<br>– Chipset Driver Intel Z790:&nbsp;<strong>10.1.19376.8374</strong>.<br>– Windows: Indexing disabled to avoid affecting test results.<br>– Windows: Windows updates disabled to avoid affecting test results<br>– Windows: Most Windows applications disabled from running in the background.<br>– Boot Windows: Clean Image with only Drivers<br>– Test pSLC Cache: The SSD is cooled by fans to prevent thermal throttling, ensuring it doesn’t interfere with the test results.<br>– Windows: Antivirus disabled to minimize variation in each round.<br>– DUT SSDs: Used as a secondary drive, with 0% of space being utilized, and other tests conducted with 50% of space utilized to represent a realistic scenario.<br>– Quarch PPM QTL1999 – Power consumption test: conducted with three parameters—idle, where the drive is left as a secondary, and after a period of idle, a one-hour write test is performed, and the average power consumption is recorded</p>
<p><strong>CONTRIBUTIONS TO PROJECT LIKE THIS IN THE FUTURE</strong></p>
<p>If you enjoyed this article and would like to see more articles like this, I’ll be leaving a link below where you can contribute directly. In the future, I plan to bring a comparison showing the difference in SLC cache sizes, transforming a QLC or TLC SSD into SLC, among many other topics.</p>
<p><strong>Paypal – <a href="https://theoverclockingpage.com/cdn-cgi/l/email-protection" data-cfemail="511630332338343d323023383e323021372b11393e253c30383d7f323e3c">[email&nbsp;protected]</a></strong></p>
<p><strong>CRYSTALDISKMARK</strong><br></p>
<p>We conducted synthetic sequential and random tests with the following configurations:</p>
<p>Sequential: 2x 1 GiB (Blocks 1 MiB) 8 Queues 1 Thread</p>
<p>Random: 2x 1 GiB (Blocks 4 KiB) 1 Queue 1/2/4/8/16 Threads</p>
<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/theoverclockingpage.com\/2024\/05\/13\/tutorial-transforming-a-qlc-ssd-into-an-slc-ssd-dramatically-increasing-the-drives-endurance\/?lang=en&quot;}">
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image001-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="508" data-id="56927" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image001-1.jpg?resize=720%2C508&amp;ssl=1" alt="image001 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 36" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image001-1.jpg?resize=1024%2C722&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image001-1.jpg?resize=300%2C212&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image001-1.jpg?resize=768%2C542&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image001-1.jpg?resize=1200%2C847&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image001-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image003-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="508" data-id="56929" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image003-1.jpg?resize=720%2C508&amp;ssl=1" alt="image003 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 37" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image003-1.jpg?resize=1024%2C722&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image003-1.jpg?resize=300%2C212&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image003-1.jpg?resize=768%2C542&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image003-1.jpg?resize=1200%2C847&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image003-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
</figure>
<p>In these sequential scenarios, the difference is basically nonexistent because even with the pSLC Cache, the SSD already reaches its maximum bandwidth and the manufacturer’s sequential speeds. Not to mention that this is a quick test; in a more extensive and heavy benchmark, we will see that there will indeed be a difference.</p>
<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/theoverclockingpage.com\/2024\/05\/13\/tutorial-transforming-a-qlc-ssd-into-an-slc-ssd-dramatically-increasing-the-drives-endurance\/?lang=en&quot;}">
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image005-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="508" data-id="56931" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image005-1.jpg?resize=720%2C508&amp;ssl=1" alt="image005 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 38" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image005-1.jpg?resize=1024%2C722&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image005-1.jpg?resize=300%2C212&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image005-1.jpg?resize=768%2C542&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image005-1.jpg?resize=1200%2C847&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image005-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image007-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="508" data-id="56933" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image007-1.jpg?resize=720%2C508&amp;ssl=1" alt="image007 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 39" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image007-1.jpg?resize=1024%2C722&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image007-1.jpg?resize=300%2C212&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image007-1.jpg?resize=768%2C542&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image007-1.jpg?resize=1200%2C847&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image007-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
</figure>
<p>In terms of latency, there was indeed a considerable drop because when the SSD is in Idle, its NANDs, when they start to write or “read,” are in native mode, which would be QLC, and until they are reprogrammed to SLC, they have a certain latency. However, with the SSD in full pSLC mode, this latency is much lower because it always stays in pSLC mode.</p>
<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/theoverclockingpage.com\/2024\/05\/13\/tutorial-transforming-a-qlc-ssd-into-an-slc-ssd-dramatically-increasing-the-drives-endurance\/?lang=en&quot;}">
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image009-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="508" data-id="56935" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image009-1.jpg?resize=720%2C508&amp;ssl=1" alt="image009 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 40" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image009-1.jpg?resize=1024%2C722&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image009-1.jpg?resize=300%2C212&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image009-1.jpg?resize=768%2C542&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image009-1.jpg?resize=1200%2C847&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image009-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image011-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="508" data-id="56937" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image011-1.jpg?resize=720%2C508&amp;ssl=1" alt="image011 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 41" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image011-1.jpg?w=1280&amp;ssl=1 1280w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image011-1.jpg?resize=300%2C212&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image011-1.jpg?resize=1024%2C722&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image011-1.jpg?resize=768%2C542&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image011-1.jpg?resize=1200%2C847&amp;ssl=1 1200w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
</figure>
<p>The same happens with its random speeds; we can see that there was a greater difference in these benchmarks compared to sequential speed, where the difference was almost negligible.</p>
<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/theoverclockingpage.com\/2024\/05\/13\/tutorial-transforming-a-qlc-ssd-into-an-slc-ssd-dramatically-increasing-the-drives-endurance\/?lang=en&quot;}">
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image013-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="508" data-id="56939" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image013-1.jpg?resize=720%2C508&amp;ssl=1" alt="image013 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 42" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image013-1.jpg?resize=1024%2C722&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image013-1.jpg?resize=300%2C212&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image013-1.jpg?resize=768%2C542&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image013-1.jpg?resize=1200%2C847&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image013-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image015-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="508" data-id="56941" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image015-1.jpg?resize=720%2C508&amp;ssl=1" alt="image015 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 43" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image015-1.jpg?w=1280&amp;ssl=1 1280w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image015-1.jpg?resize=300%2C212&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image015-1.jpg?resize=1024%2C722&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image015-1.jpg?resize=768%2C542&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image015-1.jpg?resize=1200%2C847&amp;ssl=1 1200w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
</figure>
<p>The same happens at QD1; we can see that in reading, the SSD had an increase of over 16% in its speeds, while in writing, there was a much larger increase of over 30%.</p>
<p><strong>ATTO Disk Benchmark QD1 and QD4</strong></p>
<p>We conducted a test using ATTO to observe the speed of SSDs at various block sizes. In this benchmark, it was configured as follows:</p>
<p>Block sizes: from 512 Bytes to 8 MiB</p>
<p>File size: 256MB</p>
<p>Queue Depth: 1 and 4.</p>
<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/theoverclockingpage.com\/2024\/05\/13\/tutorial-transforming-a-qlc-ssd-into-an-slc-ssd-dramatically-increasing-the-drives-endurance\/?lang=en&quot;}">
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image017-2.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="510" data-id="56943" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image017-2.jpg?resize=720%2C510&amp;ssl=1" alt="image017 2" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 44" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image017-2.jpg?resize=1024%2C726&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image017-2.jpg?resize=300%2C213&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image017-2.jpg?resize=768%2C544&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image017-2.jpg?resize=1200%2C850&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image017-2.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image019-2.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="508" data-id="56945" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image019-2.jpg?resize=720%2C508&amp;ssl=1" alt="image019 2" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 45" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image019-2.jpg?resize=1024%2C723&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image019-2.jpg?resize=300%2C212&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image019-2.jpg?resize=768%2C542&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image019-2.jpg?resize=1200%2C848&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image019-2.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
</figure>
<p>The ATTO Disk Benchmark is a software that performs a sequential speed test with compressed files. Therefore, for a simulation under a data transfer load like in Windows, we typically see block sizes ranging from 128KB to 1MB. Now, we observe that the SSD in pSLC mode outperforms the SSD in its factory mode across all block sizes, which is impressive once again.</p>
<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/theoverclockingpage.com\/2024\/05\/13\/tutorial-transforming-a-qlc-ssd-into-an-slc-ssd-dramatically-increasing-the-drives-endurance\/?lang=en&quot;}">
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image021-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="508" data-id="56947" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image021-1.jpg?resize=720%2C508&amp;ssl=1" alt="image021 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 46" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image021-1.jpg?resize=1024%2C723&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image021-1.jpg?resize=300%2C212&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image021-1.jpg?resize=768%2C542&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image021-1.jpg?resize=1200%2C848&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image021-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image023-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="510" data-id="56949" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image023-1.jpg?resize=720%2C510&amp;ssl=1" alt="image023 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 47" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image023-1.jpg?resize=1024%2C726&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image023-1.jpg?resize=300%2C213&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image023-1.jpg?resize=768%2C544&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image023-1.jpg?resize=1200%2C850&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image023-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
</figure>
<p>The same pattern repeated at queue depth 1, although the difference in some block sizes was slightly lower compared to a queue depth of 4.</p>
<p><strong>3DMark – Storage Benchmark</strong></p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2022/04/capsule_616x353.jpg?ssl=1"><img loading="lazy" decoding="async" width="616" height="353" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2022/04/capsule_616x353.jpg?resize=616%2C353&amp;ssl=1" alt="" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 48" data-recalc-dims="1"></a></figure></div>
<p>In this benchmark, various storage-related tests are conducted, including game loading tests for games like Call of Duty Black Ops 4, Overwatch, recording and streaming with OBS of a gameplay at 1080p 60 FPS, game installations, and file transfers of game folders.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image027-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image027-1.jpg?resize=720%2C503&amp;ssl=1" alt="image027 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 49" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image027-1.jpg?resize=1024%2C715&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image027-1.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image027-1.jpg?resize=768%2C536&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image027-1.jpg?resize=1200%2C838&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image027-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/theoverclockingpage.com\/2024\/05\/13\/tutorial-transforming-a-qlc-ssd-into-an-slc-ssd-dramatically-increasing-the-drives-endurance\/?lang=en&quot;}">
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image029-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" data-id="56953" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image029-1.jpg?resize=720%2C503&amp;ssl=1" alt="image029 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 50" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image029-1.jpg?resize=1024%2C715&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image029-1.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image029-1.jpg?resize=768%2C536&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image029-1.jpg?resize=1200%2C838&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image029-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image031-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" data-id="56955" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image031-1.jpg?resize=720%2C503&amp;ssl=1" alt="image031 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 51" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image031-1.jpg?resize=1024%2C715&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image031-1.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image031-1.jpg?resize=768%2C536&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image031-1.jpg?resize=1200%2C838&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image031-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure>
</figure>
<p>In this benchmark focusing more on casual environments, we can see that even here, in a scenario fully representative of reality, there is indeed a performance difference, especially in latency. Although it may not be something entirely noticeable in everyday use in these “lighter” scenarios.</p>
<p><strong>PCMARK 10 – FULL SYSTEM DRIVE BENCHMARK</strong></p>
<p>In this test, the Storage Test tool was used along with the “Full System Drive Benchmark,” which performs light and heavy evaluations on the SSD.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2022/04/pcmark10-fb-og.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="378" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2022/04/pcmark10-fb-og.jpg?resize=720%2C378&amp;ssl=1" alt="pcmark10 fb og" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 52" data-recalc-dims="1"></a></figure></div>
<p><br>Among these traces, we can observe tests such as:</p>
<ul>
<li>Boot Windows 10</li>
<li>Adobe After Effects: Launching the application until it’s ready for use</li>
<li>Adobe Illustrator: Launching the application until it’s ready for use</li>
<li>Adobe Premiere Pro: Launching the application until it’s ready for use</li>
<li>Adobe Lightroom: Launching the application until it’s ready for use</li>
<li>Adobe Photoshop: Launching the application until it’s ready for use</li>
<li>Battlefield V: Loading time until the start menu</li>
<li>Call of Duty Black Ops 4: Loading time until the start menu</li>
<li>Overwatch: Loading time until the start menu</li>
<li>Using Adobe After Effects</li>
<li>Using Microsoft Excel</li>
<li>Using Adobe Illustrator</li>
<li>Using Adobe InDesign</li>
<li>Using Microsoft PowerPoint</li>
<li>Using Adobe Photoshop (Intensive use)</li>
<li>Using Adobe Photoshop (Lighter use)</li>
<li>Copying 4 ISO files, totaling 20GB, to a secondary disk (Write test)</li>
<li>Performing the ISO file copy (Read-write test)</li>
<li>Copying the ISO file to a secondary disk (Read)</li>
<li>Copying 339 JPEG files (Photos) to the tested disk (Write)</li>
<li>Creating copies of these JPEG files (Read-write)</li>
<li>Copying 339 JPEG files (Photos) to another disk (Read)</li>
</ul>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image034-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image034-1.jpg?resize=720%2C503&amp;ssl=1" alt="image034 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 53" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image034-1.jpg?resize=1024%2C715&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image034-1.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image034-1.jpg?resize=768%2C536&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image034-1.jpg?resize=1200%2C838&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image034-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>In this scenario, which is a practical benchmark with a slightly greater focus on writing than 3DMark, as it is more productivity-oriented, it’s possible to notice the practical difference in day-to-day use. The difference was striking, almost twice the performance.</p>
<p><strong>Adobe Premiere Pro 2021</strong></p>
<p>Next, we used Adobe Premiere to measure the average time it takes to open a project of about 16.5GB with 4K resolution, 120Mbps bitrate, and full of effects until it was ready for editing. It’s worth noting that the tested SSD is always used as a secondary drive without the operating system installed, as this could affect the results, leading to inconsistencies.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image037-1.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image037-1.jpg?resize=720%2C503&amp;ssl=1" alt="image037 1" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 54" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image037-1.jpg?resize=1024%2C715&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image037-1.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image037-1.jpg?resize=768%2C536&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image037-1.jpg?resize=1200%2C838&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image037-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>Here we can see that, as it is more of a scenario of sequential data reading from the project, the difference was almost negligible, just a variation between runs.</p>
<p><strong>WINDOWS BOOT TIME AND GAME LOADING TIME</strong></p>
<p>We compared the SSD with pSLC Cache and in pSLC Mode using the Final Fantasy XIV benchmark.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image038.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image038.jpg?resize=720%2C503&amp;ssl=1" alt="image038" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 55" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image038.jpg?resize=1024%2C716&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image038.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image038.jpg?resize=768%2C537&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image038.jpg?resize=1200%2C839&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image038.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>The same happens with game loading times because the limitation lies in the game’s API, which differs from <strong>DirectStorage</strong>. This API is not optimized for us to feel a significant difference.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image042.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image042.jpg?resize=720%2C503&amp;ssl=1" alt="image042" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 56" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image042.jpg?resize=1024%2C715&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image042.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image042.jpg?resize=768%2C536&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image042.jpg?resize=1200%2C838&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image042.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>The same can be said for Windows, as although it is a completely new system, it cannot take advantage of features like the one we applied to the SSD.</p>
<p><strong>SLC CACHING</strong></p>
<p>A large part of SSDs on the market currently utilize SLC Caching technology, where a certain percentage of their storage capacity, whether it’s MLC (2 bits per cell), TLC (3 bits per cell), or QLC (4 bits per cell), is used to store only 1 bit per cell. In this case, it’s used as a write and read buffer, where the controller starts writing, and when the buffer is depleted, it writes to the native NAND Flash (MLC/TLC/QLC).</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-40.png?ssl=1"><img loading="lazy" decoding="async" width="567" height="319" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-40.png?resize=567%2C319&amp;ssl=1" alt="image 40" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 57" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-40.png?w=567&amp;ssl=1 567w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-40.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-40.png?resize=520%2C292&amp;ssl=1 520w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/03/image-40.png?resize=1000%2C562&amp;ssl=1 1000w" sizes="(max-width: 567px) 100vw, 567px" data-recalc-dims="1"></a></figure></div>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image043.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="391" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image043.jpg?resize=720%2C391&amp;ssl=1" alt="image043" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 58" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image043.jpg?resize=1024%2C556&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image043.jpg?resize=300%2C163&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image043.jpg?resize=768%2C417&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image043.jpg?resize=1200%2C652&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image043.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>Through IOmeter, we can get an idea of the SLC cache volume of this SSD, as manufacturers often do not provide this information. Based on the tests we conducted, it was found that it has a pSLC cache volume that appears to be dynamic, relatively small, around <strong>45GB</strong>. It managed to maintain an average speed of approximately <strong>493MB/s </strong>until the end of the buffer, which is a good speed considering it is a SATA SSD.</p>
<p>However, after writing <strong>45GB</strong>, it begins to enter the folding process because it allocated all its capacity to work as pSLC. So now we see the true Achilles’ heel of QLC SSDs. Its sustained speed was quite low, averaging around <strong>50 MB/s</strong>.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image045.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="391" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image045.jpg?resize=720%2C391&amp;ssl=1" alt="image045" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 59" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image045.jpg?resize=1024%2C556&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image045.jpg?resize=300%2C163&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image045.jpg?resize=768%2C417&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image045.jpg?resize=1200%2C652&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image045.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>Now, when we transform this SSD into <strong>pSLC</strong>, we see that it writes to its full capacity of 120GB at an average of <strong>498 MB/s</strong>. And to confirm, we wrote up to 500GB to the SSD, and even then, it continued rewriting its capacity more than 4 times at almost <strong>500 MB/s</strong>.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image047.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image047.jpg?resize=720%2C503&amp;ssl=1" alt="image047" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 60" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image047.jpg?resize=1024%2C716&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image047.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image047.jpg?resize=768%2C537&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image047.jpg?resize=1200%2C839&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image047.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>As we can see in the graph above, we averaged the SSD’s write speed, combining the speed within the pSLC Cache + Folding + Native. Taking this into account, we see that the difference was striking, almost 10 times higher.</p>
<p><strong>FILE COPY TEST</strong></p>
<p>In this test, the ISO files and CSGO were copied from a RAM Disk to the SSD to see how it performs. The Windows 10 21H1 ISO of 6.25GB (1 file) and the CSGO installation folder of 25.2GB were used.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image049.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image049.jpg?resize=720%2C503&amp;ssl=1" alt="image049" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 61" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image049.jpg?resize=1024%2C716&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image049.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image049.jpg?resize=768%2C537&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image049.jpg?resize=1200%2C839&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image049.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>In a more realistic test like this, we can see that there is no difference because the SLC cache volume of the SSD natively is larger than the size of the tested file.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image051.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image051.jpg?resize=720%2C503&amp;ssl=1" alt="image051" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 62" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image051.jpg?w=1280&amp;ssl=1 1280w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image051.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image051.jpg?resize=1024%2C716&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image051.jpg?resize=768%2C537&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image051.jpg?resize=1200%2C839&amp;ssl=1 1200w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>And even when using a larger folder, it is still smaller than the volume of the SSD’s SLC cache. I don’t test with larger files because I use a RAM Disk, and since I only have “<strong>32GB</strong>” to make a larger RAM Disk, I would need more RAM.</p>
<p><strong>TEMPERATURE TEST</strong></p>
<p>In this part of the analysis, we will observe the temperature of the SSD during a stress test, where the SSD receives files continuously, to determine if there was any <strong><em>thermal throttling</em></strong> with its internal components that could cause a bottleneck or loss of performance.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image053.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image053.jpg?resize=720%2C503&amp;ssl=1" alt="image053" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 63" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image053.jpg?resize=1024%2C716&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image053.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image053.jpg?resize=768%2C537&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image053.jpg?resize=1200%2C839&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image053.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>The SSD doesn’t even heat up because it’s a low-power consumption SSD, as we’ll see throughout the analysis, and I believe this sensor to be the NAND Flash sensor.</p>
<p><strong>POWER CONSUMPTION AND EFFICIENCY</strong></p>
<p>SSDs, like many other components in our system, have a certain power consumption. The most efficient ones can perform tasks quickly with relatively low power consumption, allowing them to transition back to idle power states where they consume less energy.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2022/08/quarch-programmable-power-module.png?ssl=1"><img loading="lazy" decoding="async" width="690" height="400" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2022/08/quarch-programmable-power-module.png?resize=690%2C400&amp;ssl=1" alt="quarch programmable power module" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 64" data-recalc-dims="1"></a><figcaption><strong>SPECIAL THANKS FOR QUARCH FOR SENDING THIS UNIT</strong></figcaption></figure></div>
<p>In this section of the analysis, we will use the Quarch Programmable Power Module provided by Quarch Solutions (pictured above) to conduct tests and determine how efficient the SSD is. This methodology involves conducting three tests: measuring the maximum power consumption of the SSD, calculating an average power consumption in practical and casual scenarios, and measuring power consumption during idle periods.</p>
<p>This set of tests, especially those related to efficiency and idle power consumption, is important for users who intend to use SSDs in laptops. SSDs spend the vast majority of their time in low-power states (idle), so understanding their power consumption characteristics can significantly impact battery life and overall energy efficiency.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image061.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image061.jpg?resize=720%2C503&amp;ssl=1" alt="image061" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 65" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image061.jpg?resize=1024%2C716&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image061.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image061.jpg?resize=768%2C537&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image061.jpg?resize=1200%2C839&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image061.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>We can see that thanks to this modification, its efficiency has increased dramatically. This occurred because, although the difference in power consumption was not as significant as we will see shortly, the speed in MB/s was extremely high. </p>
<p>Due to the benchmark exceeding the SSD’s <strong>45GB </strong>cache by a large margin, it spent a significant portion of the test at a very low speed of less than<strong> 55 MB/s</strong>, resulting in low efficiency. In pSLC mode, it was able to write twice its capacity at even lower power consumption than in QLC mode, and its bandwidth did not drop at any point. This led to the significant difference in power consumption.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image055.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image055.jpg?resize=720%2C503&amp;ssl=1" alt="image055" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 66" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image055.jpg?resize=1024%2C716&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image055.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image055.jpg?resize=768%2C537&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image055.jpg?resize=1200%2C839&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image055.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>Although this SSD naturally has low power consumption, we do observe a decrease when transforming it into pSLC mode. This occurs because SLC NANDs have only 2 logical levels, meaning the <strong>threshold voltage </strong>required to allow electrons to flow in the gate channel of each cell is lower since there are fewer levels needed to represent binary 1 or 0. In contrast, QLC NANDs have 16 logical levels, requiring a higher <strong>threshold voltage</strong>. This explains the reduction in power consumption.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image057.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image057.jpg?resize=720%2C503&amp;ssl=1" alt="image057" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 67" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image057.jpg?resize=1024%2C716&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image057.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image057.jpg?resize=768%2C537&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image057.jpg?resize=1200%2C839&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image057.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>Once again, we see this in the average of both SSDs.</p>
<div>
<figure><a href="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image059.jpg?ssl=1"><img loading="lazy" decoding="async" width="720" height="503" src="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image059.jpg?resize=720%2C503&amp;ssl=1" alt="image059" title="Tutorial: Transforming a QLC SSD into an SLC SSD - Dramatically increasing the drive's endurance! 68" srcset="https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image059.jpg?resize=1024%2C716&amp;ssl=1 1024w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image059.jpg?resize=300%2C210&amp;ssl=1 300w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image059.jpg?resize=768%2C537&amp;ssl=1 768w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image059.jpg?resize=1200%2C839&amp;ssl=1 1200w, https://i0.wp.com/theoverclockingpage.com/wp-content/uploads/2024/05/image059.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"></a></figure></div>
<p>Last but not least, the Idle test, which represents the scenario where the vast majority of SSDs are in everyday use. Here we can see that it had even lower consumption in Idle. Another positive point.</p>
<p>What can we conclude from this?</p>
<p>Once again, I stress the importance of caution with this procedure as it can indeed go wrong if not done correctly. However, we see that the differences are significant in some scenarios while more subtle in others. But now, in terms of durability, the difference is immense!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Iberian lynx doubles its population in just three years (114 pts)]]></title>
            <link>https://english.elpais.com/science-tech/2024-05-17/the-iberian-lynx-doubles-its-population-in-just-three-years-and-reaches-2000-individuals.html</link>
            <guid>40404488</guid>
            <pubDate>Sun, 19 May 2024 05:31:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://english.elpais.com/science-tech/2024-05-17/the-iberian-lynx-doubles-its-population-in-just-three-years-and-reaches-2000-individuals.html">https://english.elpais.com/science-tech/2024-05-17/the-iberian-lynx-doubles-its-population-in-just-three-years-and-reaches-2000-individuals.html</a>, See on <a href="https://news.ycombinator.com/item?id=40404488">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-dtm-region="articulo_cuerpo"><figure><span><img alt="Lince" decoding="auto" height="276" srcset="https://imagenes.elpais.com/resizer/v2/CORSXHDDE5BOXHHVQCPKWO2NAI.jpg?auth=a02ef151f5a683352c10eb8697d95f7fdccaf03d0ae648de7517f6f7c4d192b5&amp;width=414 414w,https://imagenes.elpais.com/resizer/v2/CORSXHDDE5BOXHHVQCPKWO2NAI.jpg?auth=a02ef151f5a683352c10eb8697d95f7fdccaf03d0ae648de7517f6f7c4d192b5&amp;width=828 640w,https://imagenes.elpais.com/resizer/v2/CORSXHDDE5BOXHHVQCPKWO2NAI.jpg?auth=a02ef151f5a683352c10eb8697d95f7fdccaf03d0ae648de7517f6f7c4d192b5&amp;width=980 1000w,https://imagenes.elpais.com/resizer/v2/CORSXHDDE5BOXHHVQCPKWO2NAI.jpg?auth=a02ef151f5a683352c10eb8697d95f7fdccaf03d0ae648de7517f6f7c4d192b5&amp;width=1200 1200w" width="414" sizes="(min-width: 1199px) 760px,(min-width: 1001px) cal(100vw - 62vw),(min-width: 768px) 767px, 100vw" src="https://imagenes.elpais.com/resizer/v2/CORSXHDDE5BOXHHVQCPKWO2NAI.jpg?auth=a02ef151f5a683352c10eb8697d95f7fdccaf03d0ae648de7517f6f7c4d192b5&amp;width=414" loading="eager"></span><figcaption><span>A litter of Iberian lynxes from Ciudad Real.</span><span>Alexandra Surkova-WWF</span></figcaption></figure><p>The Iberian lynx (<i>Lynx pardinus</i>) continues <a href="https://english.elpais.com/society/2021-05-31/spains-iberian-lynx-population-soars-to-1000-but-species-remains-endangered.html">along its upward path</a>, although it is still at risk of extinction. The last census in 2023 shows that the species has doubled its population in the last three years and has reached 2,021 individuals, with 1,299 adults or subadults and 722 cubs. Despite the good data, 750 breeding females would be needed to classify the species in a favorable conservation status, and in this latest count only 406 have been detected. According to Spain’s Ministry for the Ecological Transition, they are “gradually” getting closer to the necessary number, but are still falling short.</p><p>Captive breeding centers have played an essential role in this recovery. From 2011 to 2023, 372 lynxes born in the four existing centers have been released. The population has been expanding, and last year the reproduction of the species was verified in 14 population centers, in addition to the stable presence in new areas of the Spanish region of Murcia, and the provinces of Albacete, Badajoz, Toledo and Ciudad Real. Most of the specimens, 1,731 or 85% of the total, live in Spain and the rest, 291, are <a href="https://english.elpais.com/economy-and-business/2024-05-13/portugal-is-no-longer-a-problem-for-europe.html">in Portugal</a>. The stable populations are located in four Spanish regions: Andalusia with 755 specimens (43.6% of the Spanish population), closely followed by Castilla-La Mancha with 715 lynxes (41.3%), Extremadura where 253 specimens were located, and Murcia with seven.</p><figure><span><img alt="Expansion of the Iberian lynx, in a graph provided by the Ministry for the Ecological Transition" decoding="auto" height="267" srcset="https://imagenes.elpais.com/resizer/v2/WC3H7XTTMFGAZFP2WT3UTHFISA.jpeg?auth=92ad55f27e3b48911d12e71428c404b0f2d41b969870ecc89f325342a8872e3c&amp;width=414 414w,https://imagenes.elpais.com/resizer/v2/WC3H7XTTMFGAZFP2WT3UTHFISA.jpeg?auth=92ad55f27e3b48911d12e71428c404b0f2d41b969870ecc89f325342a8872e3c&amp;width=828 640w,https://imagenes.elpais.com/resizer/v2/WC3H7XTTMFGAZFP2WT3UTHFISA.jpeg?auth=92ad55f27e3b48911d12e71428c404b0f2d41b969870ecc89f325342a8872e3c&amp;width=980 1000w,https://imagenes.elpais.com/resizer/v2/WC3H7XTTMFGAZFP2WT3UTHFISA.jpeg?auth=92ad55f27e3b48911d12e71428c404b0f2d41b969870ecc89f325342a8872e3c&amp;width=1960 1960w" width="414" sizes="(min-width:1199px) 1155px,(min-width:1001px) calc(100vw - 44px),(min-width:768px) 767px, 100vw" src="https://imagenes.elpais.com/resizer/v2/WC3H7XTTMFGAZFP2WT3UTHFISA.jpeg?auth=92ad55f27e3b48911d12e71428c404b0f2d41b969870ecc89f325342a8872e3c&amp;width=414" loading="lazy"></span><figcaption><span>Expansion of the Iberian lynx, in a graph provided by the Ministry for the Ecological Transition</span><span>Ministerio para la Transición Ecológica</span></figcaption></figure><p>The ministry believes that the data allow for a degree of optimism, because the feline’s trend is positive and has continued on an upward trend since 2015, the year in which the International Union for Conservation of Nature (IUCN) lowered its threat level. The species went from being “critically endangered” to simply “endangered.” It was a fundamental step for the survival of an animal that was close to extinction in 2002, when only 94 specimens remained in Andalusia. Captive breeding programs with significant European investment have allowed the creation of different nuclei, and have managed to reverse the situation. This increase now means that lynxes are approaching inhabited places, as happened in late March, when a rancher found <a href="https://english.elpais.com/international/2024-03-26/a-rancher-finds-three-newborn-lynxes-in-his-haystack-in-toledo.html">four lynxes born in his haystack</a> in Menasalbas, municipality of Toledo.</p><p>“We are at an average growth of 20%, a trend that has been maintained due to the creation of three new nuclei,” says Ramón Pérez de Ayala, a member of World Wildlife Fund (WWF) and a specialist in the species. To obtain the number of breeding females, it is necessary, according to their calculations, to create another five new areas with lynxes. “There were populations that grew a lot, up to 30%, but then they stabilized,” he explains. This occurred in the mountains of Toledo, one of the biggest success stories of reintroduction. “There, the first place where they became active was practically saturated, but the lynxes have moved to a neighboring area, which has kept up the growth,” he notes. The same situation has taken place in other areas such as Guarrizas (Jaén) and in Portugal, in the Guadiana valley area.</p><p>A reproductive female needs a territory of about 500 hectares, although it all depends on the amount of food available: the more food there is, the less space is needed. <a href="https://english.elpais.com/society/2022-09-29/it-was-a-perfect-storm-how-13-rabbits-caused-the-largest-biological-invasion-in-history.html">The rabbit </a>is the main component of their diet and there are places where the rabbit population cannot recover, affected mainly by a deadly hemorrhagic disease. Depending on the areas, the drop is between 30% and 87% in a decade, indicates Pérez de Ayala. In this boom situation, the feline’s biggest enemy is road accidents, which has become its main cause of mortality. “In 2023 there were 144 deaths due to this cause, 7.1% of the population, and we cannot forget poaching, which goes unnoticed.”</p><p><i>Sign up for </i><a href="https://plus.elpais.com/newsletters/lnp/1/333/?lang=en"><i><u>our weekly newsletter</u></i></a> <i>to get more English-language news coverage from EL PAÍS USA Edition</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Classic Usenet posts on computer architecture, operating systems and languages (255 pts)]]></title>
            <link>https://yarchive.net/comp/index.html</link>
            <guid>40404440</guid>
            <pubDate>Sun, 19 May 2024 05:16:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yarchive.net/comp/index.html">https://yarchive.net/comp/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=40404440">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="100%">
<tbody><tr>
<td>

	<h2> Computer Architecture </h2>

<br><a href="https://yarchive.net/comp/128bit.html">The prospects for 128 bit processors</a> (John R. Mashey) [8913 bytes]
<br><a href="https://yarchive.net/comp/64bit.html">64 bit processors: history and rationale</a> (John R. Mashey) [32401 bytes]
<br><a href="https://yarchive.net/comp/amd64.html">AMD64 </a> (Linus Torvalds; Terje Mathisen) [12514 bytes]
<br><a href="https://yarchive.net/comp/asynchronous_logic.html">Asynchronous logic </a> (Mitch Alsup) [3766 bytes]
<br><a href="https://yarchive.net/comp/atomic_transactions.html">Atomic transactions </a> (Mitch Alsup; Terje Mathisen) [86188 bytes]
<br><a href="https://yarchive.net/comp/bcd_instructions.html">BCD instructions: RISC and CISC</a> (John R. Mashey) [3624 bytes]
<br><a href="https://yarchive.net/comp/big_data.html">Big Data</a> (John R. Mashey, Larry McVoy) [30027 bytes]
<br><a href="https://yarchive.net/comp/byte_addressing.html">Byte_addressing</a> (John R. Mashey) [2819 bytes]
<br><a href="https://yarchive.net/comp/caches.html">Caches </a> (John R. Mashey; John D. McCalpin) [7821 bytes]
<br><a href="https://yarchive.net/comp/cache_parity.html">Parity and ECC use in caches</a> (John R. Mashey) [1549 bytes]
<br><a href="https://yarchive.net/comp/cache_thrashing.html">Cache thrashing </a> (Andy Glew; Linus Torvalds; Terje Mathisen) [9422 bytes]
<br><a href="https://yarchive.net/comp/carry_bit.html">Carry bits; The Architect's Trap</a> (John R. Mashey) [8038 bytes]
<br><a href="https://yarchive.net/comp/cmos_logic_speed.html">CMOS logic speeds </a> (Mitch Alsup) [9317 bytes]
<br><a href="https://yarchive.net/comp/cmov.html">CMOV </a> (Terje Mathisen) [2341 bytes]
<br><a href="https://yarchive.net/comp/cpu_features.html">CPU feature economics </a> (John R. Mashey) [3860 bytes]
<br><a href="https://yarchive.net/comp/cpu_power.html">CPU power usage </a> (Mitch Alsup) [2795 bytes]
<br><a href="https://yarchive.net/comp/debugging_hardware.html">Hardware to aid debugging</a> (John R. Mashey) [10408 bytes]
<br><a href="https://yarchive.net/comp/dram_cache.html">DRAM cache </a> (Mitch Alsup; Terje Mathisen) [8807 bytes]
<br><a href="https://yarchive.net/comp/dram_latencies.html">DRAM latencies </a> (Mitch Alsup) [3056 bytes]
<br><a href="https://yarchive.net/comp/endian.html">Endian </a> (John R. Mashey) [2053 bytes]
<br><a href="https://yarchive.net/comp/fp_registers.html">Separate floating point registers</a> (John R. Mashey) [14584 bytes]
<br><a href="https://yarchive.net/comp/fp_fixup.html">Floating-point exception fixup </a> (John Mashey; Terje Mathisen) [6750 bytes]
<br><a href="https://yarchive.net/comp/fault_tolerant.html">Fault tolerant </a> (John R. Mashey) [4384 bytes]
<br><a href="https://yarchive.net/comp/h264_cabac.html">H264 CABAC </a> (Maynard Handley; Terje Mathisen) [19556 bytes]
<br><a href="https://yarchive.net/comp/ia64.html">Merced/IA64</a> (John R. Mashey) [23688 bytes]
<br><a href="https://yarchive.net/comp/instr_per_clock.html">Instructions per clock </a> (John R. Mashey) [7624 bytes]
<br><a href="https://yarchive.net/comp/ibm_801.html">IBM 801 </a> (Greg Pfister) [5308 bytes]
<br><a href="https://yarchive.net/comp/ibm_pc_8088.html">Why the IBM PC used the 8088 </a> (Bill Katz; John R. Mashey) [4264 bytes]
<br><a href="https://yarchive.net/comp/interval_arithmetic.html">Interval arithmetic </a> (James B. Shearer) [47593 bytes]
<br><a href="https://yarchive.net/comp/lisp_support.html">Lisp support </a> (Eliot Miranda; John Mashey) [27352 bytes]
<br><a href="https://yarchive.net/comp/ll_sc.html">LL/SC </a> (John Mashey; Terje Mathisen) [26317 bytes]
<br><a href="https://yarchive.net/comp/memory_layouts.html">Message passing versus shared memory; the SGI Origin machines</a> (John R. Mashey, John McCalpin) [73943 bytes]
<br><a href="https://yarchive.net/comp/mips16.html">MIPS16 </a> (John R. Mashey) [3489 bytes]
<br><a href="https://yarchive.net/comp/mips_interrupts.html">Interrupts on the MIPS processors</a> (John R. Mashey) [7035 bytes]
<br><a href="https://yarchive.net/comp/mips_exceptions.html">MIPS exceptions </a> (John Mashey) [11018 bytes]
<br><a href="https://yarchive.net/comp/misalignment.html">Misalignment </a> (John Levine; Mitch Alsup; Terje Mathisen) [14100 bytes]
<br><a href="https://yarchive.net/comp/multiprocessor_terminology.html">Multiprocessor machine terminology </a> (John R. Mashey) [8226 bytes]
<br><a href="https://yarchive.net/comp/mvc_instruction.html">The MVC instruction</a> (John R. Mashey, Allen J. Baum) [15584 bytes]
<br><a href="https://yarchive.net/comp/n_bit_cpu.html">The definition of an N bit cpu</a> (John R. Mashey) [4027 bytes]
<br><a href="https://yarchive.net/comp/opteron_stream.html">Opteron STREAM benchmark optimizations </a> (Terje Mathisen) [2030 bytes]
<br><a href="https://yarchive.net/comp/page_size.html">Page size </a> (Linus Torvalds) [2775 bytes]
<br><a href="https://yarchive.net/comp/pentium_4.html">The Pentium 4 </a> (Linus Torvalds; Terje Mathisen) [4681 bytes]
<br><a href="https://yarchive.net/comp/powerof2.html">Why word sizes are powers of 2</a> (John R. Mashey) [5185 bytes]
<br><a href="https://yarchive.net/comp/powerpc_page_tables.html">PowerPC page tables </a> (Greg Pfister; Linus Torvalds) [22229 bytes]
<br><a href="https://yarchive.net/comp/prefetch.html">Prefetch </a> (Terje Mathisen) [3788 bytes]
<br><a href="https://yarchive.net/comp/quad_precision.html">Quad precision </a> (Robert Corbett) [989 bytes]
<br><a href="https://yarchive.net/comp/register_windows.html">Register windows</a> (John Mashey) [8389 bytes]
<br><a href="https://yarchive.net/comp/register_file_size.html">Register file size </a> (Mitch Alsup) [5876 bytes]
<br><a href="https://yarchive.net/comp/rep_movs.html">REP MOVS </a> (Terje Mathisen) [1160 bytes]
<br><a href="https://yarchive.net/comp/renaming.html">Register renaming</a> (John R. Mashey) [4955 bytes]
<br><a href="https://yarchive.net/comp/result_forwarding.html">Result forwarding </a> (Terje Mathisen) [1524 bytes]
<br><a href="https://yarchive.net/comp/risc_definition.html">RISC vs CISC</a> (John R. Mashey) [43955 bytes]
<br><a href="https://yarchive.net/comp/rom_speeds.html">ROM speeds </a> (Mitch Alsup) [1835 bytes]
<br><a href="https://yarchive.net/comp/self_modify.html">Self-modifying code</a> (John R. Mashey, John Reiser, Dennis Ritchie) [24900 bytes]
<br><a href="https://yarchive.net/comp/set_associative.html">Direct Mapped vs. Set Associative caches</a> (John R. Mashey) [2260 bytes]
<br><a href="https://yarchive.net/comp/signed_division.html">Signed division </a> (Robert Corbett) [1273 bytes]
<br><a href="https://yarchive.net/comp/slow_memory_effects.html">Algorithm Analyses *Must Change* to Model Current Processors</a> (John R. Mashey) [10337 bytes]
<br><a href="https://yarchive.net/comp/software_pipelining.html">Software pipelining </a> (Linus Torvalds) [23736 bytes]
<br><a href="https://yarchive.net/comp/software_tlb.html">Software-refilled TLBs</a> (John R. Mashey, John F Carr) [76259 bytes]
<br><a href="https://yarchive.net/comp/spec.html">The SPEC benchmark suite</a> (John R. Mashey) [55015 bytes]
<br><a href="https://yarchive.net/comp/specfp2000.html">SpecFP2000 </a> (Greg Lindahl; John D. McCalpin; Wesley Jones) [19554 bytes]
<br><a href="https://yarchive.net/comp/specfp_bandwidth.html">SpecFP bandwidth </a> (John D. McCalpin) [8570 bytes]
<br><a href="https://yarchive.net/comp/specfp_time_skewing.html">SpecFP and time-skewing optimizations </a> (Greg Lindahl; John D. McCalpin) [24362 bytes]
<br><a href="https://yarchive.net/comp/sram_main_mem.html">SRAM main memories</a> (John R. Mashey) [3130 bytes]
<br><a href="https://yarchive.net/comp/stack_machines.html">Stack machines</a> (John R. Mashey) [34138 bytes]
<br><a href="https://yarchive.net/comp/streaming_data.html">Streaming data</a> (John R. Mashey) [4655 bytes]
<br><a href="https://yarchive.net/comp/tera.html">The Tera multithreaded architecture </a> (Preston Briggs, John R. Mashey) [27972 bytes]
<br><a href="https://yarchive.net/comp/threaded_cpu.html">Multithreaded CPUs</a> (John R. Mashey) [11759 bytes]
<br><a href="https://yarchive.net/comp/tlbs.html">TLBs </a> (John Mashey) [9415 bytes]
<br><a href="https://yarchive.net/comp/transmission_gates.html">Transmission gates </a> (Mitch Alsup) [1686 bytes]
<br><a href="https://yarchive.net/comp/vax.html">The VAX </a> (John Mashey) [89376 bytes]
<br><a href="https://yarchive.net/comp/vectored_interrupts.html">Vectored interrupts </a> (John Mashey) [4607 bytes]
<br><a href="https://yarchive.net/comp/virtual_machine.html">Virtual machines</a> (John R. Mashey) [4749 bytes]
<br><a href="https://yarchive.net/comp/wiz.html">Wiz </a> (John Mashey) [106300 bytes]
<br><a href="https://yarchive.net/comp/zero_register.html">Zero registers</a> (John R. Mashey) [32828 bytes]

	<h2> Programming Languages </h2>

<br><a href="https://yarchive.net/comp/ada.html">Ada </a> (Henry Spencer) [3755 bytes]
<br><a href="https://yarchive.net/comp/aliasing.html">Aliasing </a> (Terje Mathisen) [1060 bytes]
<br><a href="https://yarchive.net/comp/alloca.html">Alloca </a> (Dennis Ritchie) [2383 bytes]
<br><a href="https://yarchive.net/comp/ansic_broken_unsigned.html">The ANSI C unsigned mess </a> (Chris Torek) [4523 bytes]
<br><a href="https://yarchive.net/comp/array_bounds_check.html">Array bounds checking </a> (Henry Spencer) [4905 bytes]
<br><a href="https://yarchive.net/comp/linux/bad_macros.html">Bad C macros </a> (Jamie Lokier) [1768 bytes]
<br><a href="https://yarchive.net/comp/caching_multidimensional_arrays.html">Caching multidimensional arrays </a> (Terje Mathisen) [2469 bytes]
<br><a href="https://yarchive.net/comp/call_by_name.html">Call by name</a> (John R. Mashey; Dennis Ritchie; Robert Corbett; William B. Clodius) [11927 bytes]
<br><a href="https://yarchive.net/comp/calling_conventions.html">Binary calling conventions </a> (Chris Torek) [17341 bytes]
<br><a href="https://yarchive.net/comp/c.html">C </a> (Dennis Ritchie; Douglas A. Gwyn; John A. Gregor, Jr.; Linus Torvalds) [15080 bytes]
<br><a href="https://yarchive.net/comp/c_main.html">C calling conventions for main() </a> (Dennis Ritchie) [1765 bytes]
<br><a href="https://yarchive.net/comp/c_extern.html">C "extern" </a> (Dennis Ritchie) [1659 bytes]
<br><a href="https://yarchive.net/comp/c_prototypes.html">C prototypes </a> (Chris Torek) [2396 bytes]
<br><a href="https://yarchive.net/comp/c_shifts.html">C shifts </a> (Dennis Ritchie) [1428 bytes]
<br><a href="https://yarchive.net/comp/linux/c99_preprocessor.html">The C99 preprocessor </a> (Al Viro) [2001 bytes]
<br><a href="https://yarchive.net/comp/linux/c_==.html">C's == operator</a> (Linus Torvalds) [2566 bytes]
<br><a href="https://yarchive.net/comp/cobol.html">COBOL </a> (Henry Spencer; Morten Reistad; Terje Mathisen) [17966 bytes]
<br><a href="https://yarchive.net/comp/compiler.html">Compiler design </a> (Henry Spencer) [13873 bytes]
<br><a href="https://yarchive.net/comp/compiler_optimizations.html">Compiler optimizations </a> (Andy Glew; Greg Lindahl; Linus Torvalds; Terje Mathisen) [13634 bytes]
<br><a href="https://yarchive.net/comp/come_from.html">COME FROM </a> (Robert Corbett) [1738 bytes]
<br><a href="https://yarchive.net/comp/const.html">The "const" qualifier in C </a> (Chris Torek; Linus Torvalds) [15452 bytes]
<br><a href="https://yarchive.net/comp/contravariance.html">Contravariance </a> (Henry Spencer) [4621 bytes]
<br><a href="https://yarchive.net/comp/cray_integers.html">Cray integers </a> (Dennis Ritchie) [1695 bytes]
<br><a href="https://yarchive.net/comp/debugger.html">Debuggers </a> (Douglas A. Gwyn) [1555 bytes]
<br><a href="https://yarchive.net/comp/decimal_fp.html">Decimal FP </a> (Glen Herrmannsfeldt; Mitch Alsup; Terje Mathisen; Wilco Dijkstra; hack@watson.ibm.com) [22994 bytes]
<br><a href="https://yarchive.net/comp/denormals.html">Denormals </a> (Terje Mathisen) [1672 bytes]
<br><a href="https://yarchive.net/comp/dereferencing_null.html">Dereferencing null </a> (John R. Mashey) [1254 bytes]
<br><a href="https://yarchive.net/comp/linux/empty_statement_macro.html">empty_statement macro </a> (Linus Torvalds) [2636 bytes]
<br><a href="https://yarchive.net/comp/fortran_operator_precedence.html">Fortran operator precedence weirdness </a> (Robert Corbett) [1735 bytes]
<br><a href="https://yarchive.net/comp/f2k_allocatable.html">F2K allocatable </a> (Jos R Bergervoet; Richard Maine) [10487 bytes]
<br><a href="https://yarchive.net/comp/f2k_optional_arguments.html">F2K optional arguments </a> (Robert Corbett) [2801 bytes]
<br><a href="https://yarchive.net/comp/f90_arrays.html">F90 arrays </a> (James Van Buskirk; Richard Maine; Robert Corbett) [18144 bytes]
<br><a href="https://yarchive.net/comp/f90.html">F90 </a> (Richard Maine) [7143 bytes]
<br><a href="https://yarchive.net/comp/f95.html">F95 </a> (Robert Corbett) [6536 bytes]
<br><a href="https://yarchive.net/comp/fast_division.html">Fast division </a> (Terje Mathisen) [3397 bytes]
<br><a href="https://yarchive.net/comp/floor_function.html">Floor function </a> (Chris Torek) [3372 bytes]
<br><a href="https://yarchive.net/comp/fortran_abi.html">Fortran ABI </a> (Robert Corbett) [3899 bytes]
<br><a href="https://yarchive.net/comp/fortran_aliasing.html">Fortran aliasing </a> (James Van Buskirk; Jos Bergervoet; Richard Maine; Robert Corbett) [9377 bytes]
<br><a href="https://yarchive.net/comp/fortran_carriage_control.html">Fortran carriage control </a> (Richard Maine) [5791 bytes]
<br><a href="https://yarchive.net/comp/fortran_extensions.html">Fortran extensions </a> (Robert Corbett) [3265 bytes]
<br><a href="https://yarchive.net/comp/fortran_functions.html">Fortran functions </a> (Robert Corbett) [7644 bytes]
<br><a href="https://yarchive.net/comp/fortran_intent.html">Fortran intent </a> (Richard Maine; Robert Corbett) [9394 bytes]
<br><a href="https://yarchive.net/comp/fortran_parse.html">Fortran parse </a> (Robert Corbett) [2731 bytes]
<br><a href="https://yarchive.net/comp/fortran_pointers.html">Fortran pointers </a> (Robert Corbett) [6712 bytes]
<br><a href="https://yarchive.net/comp/fortran_real*8.html">Fortran real*8 </a> (Richard Maine; Robert Corbett) [3769 bytes]
<br><a href="https://yarchive.net/comp/fortran_standard.html">Fortran standard </a> (Charles Russell; Robert Corbett) [28776 bytes]
<br><a href="https://yarchive.net/comp/fortran_tabs.html">Fortran tabs </a> (Robert Corbett) [1560 bytes]
<br><a href="https://yarchive.net/comp/gcc_optim.html">GCC optimization </a> (Chris Torek) [9693 bytes]
<br><a href="https://yarchive.net/comp/gpl_linking.html">The GPL and linking </a> (Theodore Y. Ts'o) [6738 bytes]
<br><a href="https://yarchive.net/comp/handwritten_parse_tables.html">Handwritten parse tables </a> (David R Tribble; Dennis Ritchie) [5340 bytes]
<br><a href="https://yarchive.net/comp/int_lexing.html">Integer lexing </a> (Henry Spencer) [1249 bytes]
<br><a href="https://yarchive.net/comp/java_bytecode_verification.html">Java bytecode verification </a> (David Chase) [2044 bytes]
<br><a href="https://yarchive.net/comp/latency.html">Latency </a> (John Mashey; Terje Mathisen) [4808 bytes]
<br><a href="https://yarchive.net/comp/ll_parsing.html">LL parsing </a> (Henry Spencer) [1525 bytes]
<br><a href="https://yarchive.net/comp/logical_xor.html">Logical XOR </a> (Dennis Ritchie) [3288 bytes]
<br><a href="https://yarchive.net/comp/longlong.html">The 64-bit integer type "long long": arguments and history.</a> (John R. Mashey) [77321 bytes]
<br><a href="https://yarchive.net/comp/longjmp.html">longjmp() </a> (Dennis Ritchie; Larry Jones) [6562 bytes]
<br><a href="https://yarchive.net/comp/malloc.html">malloc() </a> (Chris Torek; David Chase) [8046 bytes]
<br><a href="https://yarchive.net/comp/matrix_multiply.html">Matrix multiplication </a> (James B. Shearer) [1290 bytes]
<br><a href="https://yarchive.net/comp/norestrict.html">Norestrict </a> (Linus Torvalds) [18019 bytes]
<br><a href="https://yarchive.net/comp/parsers.html">Parsers </a> (Henry Spencer) [8805 bytes]
<br><a href="https://yarchive.net/comp/pl_i.html">Pl/I </a> (John R. Levine) [5521 bytes]
<br><a href="https://yarchive.net/comp/polyglot.html">Polyglot program </a> (Peter Lisle) [6103 bytes]
<br><a href="https://yarchive.net/comp/power_of_two.html">Power-of-two detection </a> (Bruce Hoult; John D. McCalpin) [2402 bytes]
<br><a href="https://yarchive.net/comp/sequence_points.html">Sequence points </a> (Dennis Ritchie) [2365 bytes]
<br><a href="https://yarchive.net/comp/shift_instruction.html">Shift instructions and the C language</a> (John R. Mashey) [43881 bytes]
<br><a href="https://yarchive.net/comp/signal_handlers.html">Signal handlers and errno </a> (Chris Torek) [3571 bytes]
<br><a href="https://yarchive.net/comp/sqrtm.html">Square root of a matrix </a> (Cleve Moler) [7489 bytes]
<br><a href="https://yarchive.net/comp/standard_readability.html">Standard readability </a> (Henry Spencer) [6581 bytes]
<br><a href="https://yarchive.net/comp/string_literals.html">String literals </a> (Dennis Ritchie; Douglas A. Gwyn) [7264 bytes]
<br><a href="https://yarchive.net/comp/strtok.html">strtok </a> (Chris Torek) [6787 bytes]
<br><a href="https://yarchive.net/comp/struct_return.html">Struct return </a> (Chris Torek) [7699 bytes]
<br><a href="https://yarchive.net/comp/stupid_pointer_tricks.html">Stupid pointer tricks </a> (David E. Wallace) [5150 bytes]
<br><a href="https://yarchive.net/comp/volatile.html">The C "volatile" qualifier</a> (John R. Mashey; Linus Torvalds; Theodore Tso) [92228 bytes]

	<h2> The Computer Business; Miscellaneous </h2>

<br><a href="https://yarchive.net/comp/chip_make.html">The chip making business</a> (John R. Mashey) [30676 bytes]
<br><a href="https://yarchive.net/comp/computer_spending.html">Computer spending </a> (John R. Mashey) [3943 bytes]
<br><a href="https://yarchive.net/comp/copy_protection.html">Copy protection </a> (John De Armond) [4974 bytes]
<br><a href="https://yarchive.net/comp/danish.html">Danish </a> (Terje Mathisen) [1106 bytes]
<br><a href="https://yarchive.net/comp/english.html">English </a> (Henry Spencer) [2154 bytes]
<br><a href="https://yarchive.net/comp/eta_peglar.html">The ETA Saga </a> (Rob Peglar) [38619 bytes]
<br><a href="https://yarchive.net/comp/evolution.html">Evolution </a> (Linus Torvalds; Larry McVoy) [23087 bytes]
<br><a href="https://yarchive.net/comp/gulf_stream.html">The Gulf Stream </a> (Norman Yarvin) [10575 bytes]
<br><a href="https://yarchive.net/comp/high_tech_stocks.html">High tech stocks </a> (John R. Mashey) [19025 bytes]
<br><a href="https://yarchive.net/comp/highways.html">Highways </a> (John F. Carr) [2490 bytes]
<br><a href="https://yarchive.net/comp/hospitals.html">Hospitals </a> (del cecchi) [1955 bytes]
<br><a href="https://yarchive.net/comp/insider.html">Insider Trading</a> (John R. Mashey) [14009 bytes]
<br><a href="https://yarchive.net/comp/media_reports.html">Media reports </a> (John R. Mashey) [6087 bytes]
<br><a href="https://yarchive.net/comp/mips_prospects.html">MIPS prospects (old) </a> (John R. Mashey) [40572 bytes]
<br><a href="https://yarchive.net/comp/mips_stock_glitch.html">The MIPS stock glitch</a> (John R. Mashey) [5395 bytes]
<br><a href="https://yarchive.net/comp/mimeograph.html">Mimeograph </a> (Dennis Ritchie) [1818 bytes]
<br><a href="https://yarchive.net/comp/norway.html">Norway </a> (Terje Mathisen) [5549 bytes]
<br><a href="https://yarchive.net/comp/oceanography.html">Oceanography </a> (John D. McCalpin) [2423 bytes]
<br><a href="https://yarchive.net/comp/out_of_print.html">Out-of-print books and tax law </a> (Henry Spencer) [1478 bytes]
<br><a href="https://yarchive.net/comp/patents.html">Patents </a> (John R. Mashey) [3195 bytes]
<br><a href="https://yarchive.net/comp/sgi_cray_acquisition.html">SGI Cray acquisition </a> (John R. Mashey; John D. McCalpin) [14327 bytes]
<br><a href="https://yarchive.net/comp/sgi_graphics.html">SGI and high-end graphics</a> (John R. Mashey, John F Carr) [18963 bytes]
<br><a href="https://yarchive.net/comp/sgi_market.html">SGI's customers</a> (John R. Mashey) [24248 bytes]
<br><a href="https://yarchive.net/comp/sgi_movies.html">SGI and the movies</a> (John R. Mashey) [18218 bytes]
<br><a href="https://yarchive.net/comp/sgi_nt.html">SGI and Windows NT</a> (John R. Mashey) [8183 bytes]
<br><a href="https://yarchive.net/comp/software_patents.html">Software patents </a> (Dennis Ritchie) [2127 bytes]
<br><a href="https://yarchive.net/comp/startups.html">High-tech innovation</a> (John Mashey) [15334 bytes]
<br><a href="https://yarchive.net/comp/stupid_lawsuits.html">Bell Labs and stupid lawsuits</a> (John R. Mashey) [2106 bytes]

	<h2> Hardware </h2>

<br><a href="https://yarchive.net/comp/linux/bad_blocks.html">Bad blocks </a> (Theodore Y. Ts'o) [20421 bytes]
<br><a href="https://yarchive.net/comp/board_reseat.html">Reseating circuit boards </a> (Henry Spencer) [782 bytes]
<br><a href="https://yarchive.net/comp/copper_chip_wires.html">Copper chip wires </a> (Mitch Alsup) [1604 bytes]
<br><a href="https://yarchive.net/comp/ethernet_crossover.html">Ethernet crossover cables </a> (H. Peter Anvin) [1381 bytes]
<br><a href="https://yarchive.net/comp/ethernet_encoding.html">Ethernet encoding </a> (Henry Spencer) [1647 bytes]
<br><a href="https://yarchive.net/comp/ethernet_grounding.html">Ethernet grounding </a> (Henry Spencer) [1064 bytes]
<br><a href="https://yarchive.net/comp/ethernet_patent.html">The Ethernet patent </a> (Henry Spencer) [1148 bytes]
<br><a href="https://yarchive.net/comp/ic_desolder.html">IC desoldering </a> (John De Armond) [1219 bytes]
<br><a href="https://yarchive.net/comp/no_parity.html">Non-parity memory </a> (Henry Spencer) [3248 bytes]
<br><a href="https://yarchive.net/comp/optical_fiber.html">Optical fiber </a> (Morten Reistad; Terje Mathisen) [37097 bytes]
<br><a href="https://yarchive.net/comp/rs232.html">RS232 signals </a> (anon) [8585 bytes]
<br><a href="https://yarchive.net/comp/rs232_rtscts.html">RS232 RTS/CTS lines </a> (Henry Spencer) [2000 bytes]
<br><a href="https://yarchive.net/comp/tales.html">Tales </a> (anon) [2483 bytes]

</td>
<td>

	<h2> Operating Systems </h2>

<br><a href="https://yarchive.net/comp/bourne_shell.html">The Bourne shell</a> (John R. Mashey) [11148 bytes]
<br><a href="https://yarchive.net/comp/bsd.html">BSD </a> (Dennis Ritchie) [2329 bytes]
<br><a href="https://yarchive.net/comp/deadlock.html">Deadlock </a> (John Mashey) [5305 bytes]
<br><a href="https://yarchive.net/comp/eio.html">EIO </a> (Douglas A. Gwyn) [1170 bytes]
<br><a href="https://yarchive.net/comp/ethernet_checksums.html">Ethernet checksums </a> (Jonathan Stone; Linus Torvalds; Terje Mathisen) [28032 bytes]
<br><a href="https://yarchive.net/comp/ftp_attack.html">An FTP security hole </a> (*Hobbit*) [10500 bytes]
<br><a href="https://yarchive.net/comp/large_pages.html">Large pages </a> (John Mashey) [6866 bytes]
<br><a href="https://yarchive.net/comp/microkernels.html">Microkernels </a> (Linus Torvalds) [69856 bytes]
<br><a href="https://yarchive.net/comp/minix.html">Minix </a> (Linus Torvalds) [3597 bytes]
<br><a href="https://yarchive.net/comp/mmap.html">Memory mapping</a> (John R. Mashey; Linus Torvalds) [14030 bytes]
<br><a href="https://yarchive.net/comp/real_time.html">Real time systems</a> (John R. Mashey) [7952 bytes]
<br><a href="https://yarchive.net/comp/sandboxes.html">Sandboxes </a> (Theodore Y. Ts'o) [3611 bytes]
<br><a href="https://yarchive.net/comp/setuid_mess.html">Setuid mess </a> (Casper H.S. Dik; Chris Torek) [14468 bytes]
<br><a href="https://yarchive.net/comp/synchronous_metadata.html">Synchronous metadata </a> (Linus Torvalds) [4283 bytes]
<br><a href="https://yarchive.net/comp/unix_command_names.html">Unix command names </a> (Henry Spencer) [2201 bytes]
<br><a href="https://yarchive.net/comp/zombie_process.html">Zombie processes </a> (Douglas A. Gwyn) [1430 bytes]

	<h3> Linux </h3>

<br><a href="https://yarchive.net/comp/linux/64bit_divide.html">64-bit divide </a> (Jamie Lokier; Linus Torvalds) [5581 bytes]
<br><a href="https://yarchive.net/comp/linux/abi_documentation.html">ABI documentation </a> (Linus Torvalds) [4882 bytes]
<br><a href="https://yarchive.net/comp/linux/ACCESS_ONCE.html">ACCESS_ONCE </a> (Linus Torvalds) [6081 bytes]
<br><a href="https://yarchive.net/comp/linux/acks.html">ACKs </a> (Linus Torvalds) [3634 bytes]
<br><a href="https://yarchive.net/comp/linux/acpi.html">ACPI </a> (Linus Torvalds) [2729 bytes]
<br><a href="https://yarchive.net/comp/linux/address_zero.html">Address zero </a> (Linus Torvalds) [5707 bytes]
<br><a href="https://yarchive.net/comp/linux/antivirus.html">Antivirus software </a> (Al Viro; Theodore Tso) [34379 bytes]
<br><a href="https://yarchive.net/comp/linux/assert.html">Assert </a> (Linus Torvalds) [1716 bytes]
<br><a href="https://yarchive.net/comp/linux/async_resume.html">Asynchronous resume </a> (Linus Torvalds) [82056 bytes]
<br><a href="https://yarchive.net/comp/linux/bayes_spam_filters.html">Bayes spam filters </a> (Linus Torvalds) [5412 bytes]
<br><a href="https://yarchive.net/comp/linux/benchmarks.html">Benchmarks </a> (Linus Torvalds) [7639 bytes]
<br><a href="https://yarchive.net/comp/linux/binary_modules.html">Binary modules </a> (Theodore Ts'o) [6344 bytes]
<br><a href="https://yarchive.net/comp/linux/bind_mounts.html">Bind mounts </a> (Al Viro) [1094 bytes]
<br><a href="https://yarchive.net/comp/linux/bios.html">Dealing with the BIOS </a> (Linus Torvalds) [16864 bytes]
<br><a href="https://yarchive.net/comp/linux/bios_boot_order.html">BIOS boot order </a> (H. Peter Anvin) [1316 bytes]
<br><a href="https://yarchive.net/comp/linux/bitfields.html">Bitfields </a> (Linus Torvalds; Al Viro) [7167 bytes]
<br><a href="https://yarchive.net/comp/linux/block_device_error_handling.html">Block device error handling </a> (Theodore Ts'o) [9824 bytes]
<br><a href="https://yarchive.net/comp/linux/block_layer.html">Block layer </a> (Linus Torvalds) [7000 bytes]
<br><a href="https://yarchive.net/comp/linux/bool.html">Bool </a> (H. Peter Anvin; Linus Torvalds) [10186 bytes]
<br><a href="https://yarchive.net/comp/linux/branch_hints.html">Branch hints </a> (Linus Torvalds) [10588 bytes]
<br><a href="https://yarchive.net/comp/linux/buffer_heads.html">Buffer heads </a> (Linus Torvalds; Theodore Tso) [24461 bytes]
<br><a href="https://yarchive.net/comp/linux/BUG.html">BUG() </a> (Linus Torvalds) [19318 bytes]
<br><a href="https://yarchive.net/comp/linux/bug_tracking.html">Bug tracking </a> (Linus Torvalds; Theodore Tso) [37198 bytes]
<br><a href="https://yarchive.net/comp/linux/build_log_diffs.html">Build log diffs </a> (Al Viro) [3477 bytes]
<br><a href="https://yarchive.net/comp/linux/bundling.html">Bundling </a> (Al Viro; Linus Torvalds) [15012 bytes]
<br><a href="https://yarchive.net/comp/linux/bytes_left_in_page_macro.html">Bytes-left-in-page macro </a> (Linus Torvalds) [2343 bytes]
<br><a href="https://yarchive.net/comp/linux/cache_coloring.html">Cache coloring </a> (Linus Torvalds) [12148 bytes]
<br><a href="https://yarchive.net/comp/linux/cache_games.html">Cache games </a> (Linus Torvalds) [4809 bytes]
<br><a href="https://yarchive.net/comp/linux/caches_read_ahead.html">Caches and read-ahead </a> (Daniel Phillips; H. Peter Anvin; Linus Torvalds) [33801 bytes]
<br><a href="https://yarchive.net/comp/linux/callback_type_safety.html">Callback type safety </a> (Al Viro) [10717 bytes]
<br><a href="https://yarchive.net/comp/linux/case_insensitive_filenames.html">Case insensitive filenames </a> (H. Peter Anvin; Ingo Molnar; Linus Torvalds; Theodore Ts'o; Al Viro) [80356 bytes]
<br><a href="https://yarchive.net/comp/linux/c++.html">C++ </a> (Al Viro; Linus Torvalds; Theodore Ts'o) [14772 bytes]
<br><a href="https://yarchive.net/comp/linux/c_concurrency.html">C support for concurrency </a> (Linus Torvalds) [2164 bytes]
<br><a href="https://yarchive.net/comp/linux/checkpointing.html">Checkpointing </a> (Linus Torvalds) [3294 bytes]
<br><a href="https://yarchive.net/comp/linux/child-runs-first.html">Child-runs-first </a> (Linus Torvalds) [2217 bytes]
<br><a href="https://yarchive.net/comp/linux/chroot.html">chroot </a> (Al Viro; Theodore Tso) [6538 bytes]
<br><a href="https://yarchive.net/comp/linux/cli_sti.html">CLI/STI </a> (Linus Torvalds) [1533 bytes]
<br><a href="https://yarchive.net/comp/linux/close_return_value.html">close()'s return value </a> (Linus Torvalds) [3174 bytes]
<br><a href="https://yarchive.net/comp/linux/cmov.html">CMOV </a> (Linus Torvalds) [11509 bytes]
<br><a href="https://yarchive.net/comp/linux/cmpxchg_ll_sc_portability.html">cmpxchg, LL/SC, and portability </a> (Al Viro; Linus Torvalds) [17064 bytes]
<br><a href="https://yarchive.net/comp/linux/code_complexity.html">Code complexity </a> (Linus Torvalds) [3470 bytes]
<br><a href="https://yarchive.net/comp/linux/code_size.html">Code size </a> (Linus Torvalds) [4288 bytes]
<br><a href="https://yarchive.net/comp/linux/coding_style.html">Coding style </a> (Al Viro; Larry McVoy; Linus Torvalds; Theodore Tso) [64473 bytes]
<br><a href="https://yarchive.net/comp/linux/collective_work_copyright.html">Collective work copyright </a> (Linus Torvalds) [9886 bytes]
<br><a href="https://yarchive.net/comp/linux/commit_messages.html">Commit messages </a> (Linus Torvalds) [3263 bytes]
<br><a href="https://yarchive.net/comp/linux/compatibility.html">Compatibility </a> (Al Viro; Linus Torvalds; Theodore Ts'o) [36511 bytes]
<br><a href="https://yarchive.net/comp/linux/compatibility_wrappers.html">Compatibility wrappers </a> (Linus Torvalds) [4398 bytes]
<br><a href="https://yarchive.net/comp/linux/compiler_barriers.html">Compiler barriers </a> (Linus Torvalds) [4393 bytes]
<br><a href="https://yarchive.net/comp/linux/conditional_assignments.html">Conditional assignments </a> (Linus Torvalds) [2996 bytes]
<br><a href="https://yarchive.net/comp/linux/CONFIG_LOCALVERSION_AUTO.html">CONFIG_LOCALVERSION_AUTO </a> (Linus Torvalds) [2688 bytes]
<br><a href="https://yarchive.net/comp/linux/config_pm_trace.html">CONFIG_PM_TRACE </a> (Linus Torvalds) [2269 bytes]
<br><a href="https://yarchive.net/comp/linux/constant_expressions.html">Constant expressions </a> (Al Viro; Linus Torvalds) [6373 bytes]
<br><a href="https://yarchive.net/comp/linux/cpu_reliability.html">CPU reliability </a> (Linus Torvalds) [1814 bytes]
<br><a href="https://yarchive.net/comp/linux/crash_dumps.html">Crash dumps </a> (Linus Torvalds) [10477 bytes]
<br><a href="https://yarchive.net/comp/linux/dd_rescue.html">dd_rescue </a> (Theodore Tso) [3060 bytes]
<br><a href="https://yarchive.net/comp/linux/deadlock.html">Deadlock </a> (Greg KH; Linus Torvalds; Al Viro) [17432 bytes]
<br><a href="https://yarchive.net/comp/linux/debuggers.html">Debuggers </a> (Al Viro; Larry McVoy; Linus Torvalds; Theodore Y. Ts'o) [28184 bytes]
<br><a href="https://yarchive.net/comp/linux/development_speed.html">Development speed </a> (Al Viro; Linus Torvalds; Theodore Tso) [36071 bytes]
<br><a href="https://yarchive.net/comp/linux/devfs.html">devfs </a> (Al Viro; Theodore Ts'o) [23268 bytes]
<br><a href="https://yarchive.net/comp/linux/device_numbers.html">Device numbers </a> (H. Peter Anvin; Linus Torvalds; Theodore Ts'o; Al Viro) [45554 bytes]
<br><a href="https://yarchive.net/comp/linux/device_probing.html">Device probing </a> (Linus Torvalds) [12511 bytes]
<br><a href="https://yarchive.net/comp/linux/dev_permissions.html">/dev permissions </a> (Linus Torvalds) [1901 bytes]
<br><a href="https://yarchive.net/comp/linux/dev_random.html">/dev/random </a> (H. Peter Anvin; Theodore Y. Ts'o) [85163 bytes]
<br><a href="https://yarchive.net/comp/linux/dirty_limits.html">Dirty limits </a> (Linus Torvalds) [11525 bytes]
<br><a href="https://yarchive.net/comp/linux/disable_irq_races.html">disable_irq races </a> (Linus Torvalds; Al Viro) [26415 bytes]
<br><a href="https://yarchive.net/comp/linux/disk_corruption.html">Disk corruption </a> (Theodore Ts'o;) [14162 bytes]
<br><a href="https://yarchive.net/comp/linux/disk_snapshot.html">Disk snapshots </a> (Theodore Tso) [1895 bytes]
<br><a href="https://yarchive.net/comp/linux/documentation.html">Documentation </a> (Linus Torvalds) [1406 bytes]
<br><a href="https://yarchive.net/comp/linux/dram_power_savings.html">DRAM power savings </a> (Linus Torvalds) [8571 bytes]
<br><a href="https://yarchive.net/comp/linux/drive_caches.html">Drive caches </a> (Linus Torvalds) [16400 bytes]
<br><a href="https://yarchive.net/comp/linux/drm.html">DRM </a> (Linus Torvalds) [21104 bytes]
<br><a href="https://yarchive.net/comp/linux/dual_license_bsd_gpl.html">Dual license BSD/GPL </a> (Linus Torvalds; Theodore Tso) [19263 bytes]
<br><a href="https://yarchive.net/comp/linux/dump.html">dump </a> (Linus Torvalds) [11522 bytes]
<br><a href="https://yarchive.net/comp/linux/e2image.html">e2image </a> (Theodore Ts'o) [2631 bytes]
<br><a href="https://yarchive.net/comp/linux/edge_triggered_interrupts.html">Edge-triggered interrupts </a> (Linus Torvalds) [35208 bytes]
<br><a href="https://yarchive.net/comp/linux/efi.html">EFI </a> (Linus Torvalds) [4192 bytes]
<br><a href="https://yarchive.net/comp/linux/empty_function_calls.html">Empty function calls' cost </a> (Linus Torvalds) [4194 bytes]
<br><a href="https://yarchive.net/comp/linux/errno.html">errno </a> (Linus Torvalds) [2011 bytes]
<br><a href="https://yarchive.net/comp/linux/error_jumps.html">Error jumps </a> (Linus Torvalds) [2463 bytes]
<br><a href="https://yarchive.net/comp/linux/event_queues.html">Event queues </a> (Linus Torvalds) [32863 bytes]
<br><a href="https://yarchive.net/comp/linux/everything_is_file.html">The everything-is-a-file principle </a> (Linus Torvalds) [21195 bytes]
<br><a href="https://yarchive.net/comp/linux/execute-only.html">Execute-only </a> (Linus Torvalds) [3927 bytes]
<br><a href="https://yarchive.net/comp/linux/export_symbol_gpl.html">EXPORT_SYMBOL_GPL </a> (Linus Torvalds) [1655 bytes]
<br><a href="https://yarchive.net/comp/linux/extreme_system_recovery.html">Extreme system recovery </a> (Al Viro) [6470 bytes]
<br><a href="https://yarchive.net/comp/linux/fairness.html">Fairness </a> (Ingo Molnar; Linus Torvalds; Ulrich Drepper) [24826 bytes]
<br><a href="https://yarchive.net/comp/linux/file_hole_caching.html">File hole caching </a> (Linus Torvalds) [1554 bytes]
<br><a href="https://yarchive.net/comp/linux/files_as_directories.html">Files as directories </a> (Linus Torvalds; Theodore Ts'o; Al Viro) [118379 bytes]
<br><a href="https://yarchive.net/comp/linux/filesystem_compatibility.html">Filesystem compatibility </a> (Theodore Tso) [2204 bytes]
<br><a href="https://yarchive.net/comp/linux/flash_card_errors.html">Flash card errors </a> (H. Peter Anvin; Theodore Tso) [8266 bytes]
<br><a href="https://yarchive.net/comp/linux/fork_race.html">Fork race </a> (Linus Torvalds) [2197 bytes]
<br><a href="https://yarchive.net/comp/linux/fp_state_save.html">Saving the floating-point state </a> (Linus Torvalds) [10863 bytes]
<br><a href="https://yarchive.net/comp/linux/fragmentation_avoidance.html">Fragmentation avoidance </a> (Linus Torvalds) [48733 bytes]
<br><a href="https://yarchive.net/comp/linux/framebuffer.html">The framebuffer code </a> (Linus Torvalds) [1931 bytes]
<br><a href="https://yarchive.net/comp/linux/frequency_scaling.html">Frequency scaling </a> (Linus Torvalds) [18171 bytes]
<br><a href="https://yarchive.net/comp/linux/function_pointers.html">Function pointers </a> (Linus Torvalds) [1056 bytes]
<br><a href="https://yarchive.net/comp/linux/gcc_asm.html">gcc assembly </a> (Linus Torvalds) [13771 bytes]
<br><a href="https://yarchive.net/comp/linux/gcc_attributes.html">gcc attributes </a> (Al Viro; Linus Torvalds) [29806 bytes]
<br><a href="https://yarchive.net/comp/linux/gcc.html">gcc </a> (Al Viro; H. Peter Anvin; Linus Torvalds; Theodore Y. Ts'o) [139556 bytes]
<br><a href="https://yarchive.net/comp/linux/gcc_inline.html">gcc "inline" </a> (H. Peter Anvin; Linus Torvalds; Theodore Tso) [86941 bytes]
<br><a href="https://yarchive.net/comp/linux/gcc_vs_kernel_stability.html">gcc and kernel stability </a> (Linus Torvalds) [15853 bytes]
<br><a href="https://yarchive.net/comp/linux/generic.html">Generic mechanisms </a> (Linus Torvalds) [8581 bytes]
<br><a href="https://yarchive.net/comp/linux/getpid_caching.html">getpid() caching </a> (Linus Torvalds) [15203 bytes]
<br><a href="https://yarchive.net/comp/linux/get_unaligned.html">get_unaligned() </a> (Linus Torvalds) [4548 bytes]
<br><a href="https://yarchive.net/comp/linux/git_basic.html">git basic usage </a> (Linus Torvalds) [8284 bytes]
<br><a href="https://yarchive.net/comp/linux/git_bisect.html">git bisect </a> (Linus Torvalds) [32500 bytes]
<br><a href="https://yarchive.net/comp/linux/git_branches.html">git branches </a> (Linus Torvalds) [12910 bytes]
<br><a href="https://yarchive.net/comp/linux/git_btrfs_history.html">git btrfs history </a> (Linus Torvalds) [3514 bytes]
<br><a href="https://yarchive.net/comp/linux/git.html">git </a> (Linus Torvalds; Theodore Ts'o) [87731 bytes]
<br><a href="https://yarchive.net/comp/linux/git_merges_from_upstream.html">Git merges from upstream </a> (Linus Torvalds) [18183 bytes]
<br><a href="https://yarchive.net/comp/linux/git_rebase.html">git rebase </a> (Al Viro; Linus Torvalds; Theodore Tso) [101693 bytes]
<br><a href="https://yarchive.net/comp/linux/global_variables.html">Global variables </a> (Theodore Tso) [1600 bytes]
<br><a href="https://yarchive.net/comp/linux/gpl3.html">The GPL3 </a> (Al Viro; Linus Torvalds) [13983 bytes]
<br><a href="https://yarchive.net/comp/linux/gpl.html">The GPL </a> (Al Viro; Larry McVoy; Linus Torvalds; Theodore Ts'o) [150693 bytes]
<br><a href="https://yarchive.net/comp/linux/gpl_modules.html">The GPL and modules </a> (Linus Torvalds; Theodore Ts'o; Al Viro) [94008 bytes]
<br><a href="https://yarchive.net/comp/linux/hardware_glitches.html">Hardware glitches </a> (Linus Torvalds) [9670 bytes]
<br><a href="https://yarchive.net/comp/linux/hibernation.html">Hibernation </a> (Linus Torvalds) [110016 bytes]
<br><a href="https://yarchive.net/comp/linux/highmem.html">Highmem </a> (H. Peter Anvin; Linus Torvalds) [15703 bytes]
<br><a href="https://yarchive.net/comp/linux/hurd.html">Hurd </a> (Larry McVoy; Theodore Ts'o) [7205 bytes]
<br><a href="https://yarchive.net/comp/linux/HZ.html">HZ </a> (Linus Torvalds) [30583 bytes]
<br><a href="https://yarchive.net/comp/linux/ifdefs.html">ifdefs </a> (Linus Torvalds) [3225 bytes]
<br><a href="https://yarchive.net/comp/linux/in_interrupt.html">in_interrupt() </a> (Linus Torvalds; Theodore Y. Ts'o) [3302 bytes]
<br><a href="https://yarchive.net/comp/linux/initramfs.html">Initramfs </a> (Al Viro; Linus Torvalds) [5854 bytes]
<br><a href="https://yarchive.net/comp/linux/inline_assembly.html">Inline assembly </a> (H. Peter Anvin; Linus Torvalds) [19062 bytes]
<br><a href="https://yarchive.net/comp/linux/inline.html">Inlining functions </a> (Linus Torvalds) [17099 bytes]
<br><a href="https://yarchive.net/comp/linux/innovation.html">Innovation </a> (Al Viro) [3185 bytes]
<br><a href="https://yarchive.net/comp/linux/int_types.html">Integer types in the kernel </a> (Linus Torvalds; Al Viro) [5546 bytes]
<br><a href="https://yarchive.net/comp/linux/ioctl.html">ioctl() </a> (Al Viro; Linus Torvalds) [27092 bytes]
<br><a href="https://yarchive.net/comp/linux/io_space_accesses.html">I/O space accesses </a> (Linus Torvalds) [16057 bytes]
<br><a href="https://yarchive.net/comp/linux/irq_routing.html">IRQ routing </a> (Linus Torvalds) [6371 bytes]
<br><a href="https://yarchive.net/comp/linux/journaling_filesystems.html">Journaling filesystems </a> (Theodore Y. Ts'o) [5336 bytes]
<br><a href="https://yarchive.net/comp/linux/kernel_configuration.html">Kernel configuration </a> (Linus Torvalds; Theodore Tso) [29836 bytes]
<br><a href="https://yarchive.net/comp/linux/kernel_deadlock_debug.html">Kernel deadlock debugging </a> (Linus Torvalds) [4953 bytes]
<br><a href="https://yarchive.net/comp/linux/kernel_dumps.html">Kernel dumps </a> (Linus Torvalds; Theodore Tso) [5484 bytes]
<br><a href="https://yarchive.net/comp/linux/kernel_fp.html">Kernel floating-point </a> (Linus Torvalds) [3517 bytes]
<br><a href="https://yarchive.net/comp/linux/kernel_headers.html">Kernel headers </a> (Al Viro; H. Peter Anvin; Linus Torvalds) [41700 bytes]
<br><a href="https://yarchive.net/comp/linux/kernel.html">The kernel's role </a> (Linus Torvalds) [9704 bytes]
<br><a href="https://yarchive.net/comp/linux/kinit.html">kinit </a> (Al Viro; H. Peter Anvin; Linus Torvalds; Theodore Tso) [20839 bytes]
<br><a href="https://yarchive.net/comp/linux/large_pages.html">Large pages </a> (Linus Torvalds) [16018 bytes]
<br><a href="https://yarchive.net/comp/linux/latency.html">Latency </a> (Linus Torvalds) [2746 bytes]
<br><a href="https://yarchive.net/comp/linux/libgcc.html">libgcc </a> (Linus Torvalds) [7604 bytes]
<br><a href="https://yarchive.net/comp/linux/light_weight_processes.html">Light-weight processes </a> (David S. Miller; Larry McVoy; Zack Weinberg) [31949 bytes]
<br><a href="https://yarchive.net/comp/linux/linus.html">Linus Torvalds </a> (Linus Torvalds) [2335 bytes]
<br><a href="https://yarchive.net/comp/linux/linux_dev_policy.html">Linux development policy </a> (Linus Torvalds) [2805 bytes]
<br><a href="https://yarchive.net/comp/linux/linux_speed.html">Linux's speed </a> (Linus Torvalds) [2297 bytes]
<br><a href="https://yarchive.net/comp/linux/linux_trademark.html">The Linux trademark </a> (Linus Torvalds) [6140 bytes]
<br><a href="https://yarchive.net/comp/linux/lists.html">Lists </a> (Linus Torvalds) [2515 bytes]
<br><a href="https://yarchive.net/comp/linux/lock_costs.html">Lock costs </a> (Linus Torvalds) [4814 bytes]
<br><a href="https://yarchive.net/comp/linux/locking.html">Locking </a> (Linus Torvalds) [21406 bytes]
<br><a href="https://yarchive.net/comp/linux/lock_ordering.html">Lock ordering </a> (Linus Torvalds) [3915 bytes]
<br><a href="https://yarchive.net/comp/linux/log_structured_filesystems.html">Log structured filesystems </a> (Theodore Tso) [7269 bytes]
<br><a href="https://yarchive.net/comp/linux/log_timestamp_ordering.html">Log timestamp ordering </a> (Linus Torvalds) [12127 bytes]
<br><a href="https://yarchive.net/comp/linux/lookup_tables.html">Lookup tables </a> (Linus Torvalds) [2508 bytes]
<br><a href="https://yarchive.net/comp/linux/lost+found.html">lost+found </a> (Theodore Y. Ts'o) [2064 bytes]
<br><a href="https://yarchive.net/comp/linux/maintainers.html">Maintainers </a> (Linus Torvalds) [39113 bytes]
<br><a href="https://yarchive.net/comp/linux/malloc_0.html">malloc(0) </a> (Linus Torvalds) [7643 bytes]
<br><a href="https://yarchive.net/comp/linux/map_copy.html">MAP_COPY </a> (Linus Torvalds) [9843 bytes]
<br><a href="https://yarchive.net/comp/linux/massive_cross-builds.html">Massive cross-builds </a> (Al Viro) [10643 bytes]
<br><a href="https://yarchive.net/comp/linux/memcpy.html">memcpy </a> (Linus Torvalds) [1707 bytes]
<br><a href="https://yarchive.net/comp/linux/memory_barriers.html">Memory barriers </a> (Linus Torvalds) [24459 bytes]
<br><a href="https://yarchive.net/comp/linux/memory_pressure_code.html">Memory pressure code </a> (Linus Torvalds) [14078 bytes]
<br><a href="https://yarchive.net/comp/linux/merge_window.html">The merge window </a> (Linus Torvalds) [18914 bytes]
<br><a href="https://yarchive.net/comp/linux/micro-optimizations.html">Micro-optimizations </a> (Linus Torvalds) [2426 bytes]
<br><a href="https://yarchive.net/comp/linux/minixfs.html">minixfs </a> (Al Viro; Linus Torvalds) [12580 bytes]
<br><a href="https://yarchive.net/comp/linux/mmap_portability.html">mmap() portability </a> (Linus Torvalds) [7131 bytes]
<br><a href="https://yarchive.net/comp/linux/modversions.html">MODVERSIONS </a> (Linus Torvalds) [7285 bytes]
<br><a href="https://yarchive.net/comp/linux/more_evil_than.html">More evil than... </a> (Larry McVoy) [1254 bytes]
<br><a href="https://yarchive.net/comp/linux/mounts.html">Mounts </a> (Al Viro; Linus Torvalds) [9919 bytes]
<br><a href="https://yarchive.net/comp/linux/mtime_mmap.html">mtime changes with mmap() </a> (Linus Torvalds) [3649 bytes]
<br><a href="https://yarchive.net/comp/linux/mtu_discovery.html">MTU discovery </a> (Theodore Y. Ts'o) [11101 bytes]
<br><a href="https://yarchive.net/comp/linux/multiple_includes.html">Multiple includes </a> (Linus Torvalds) [1304 bytes]
<br><a href="https://yarchive.net/comp/linux/must_check.html">must_check </a> (Linus Torvalds) [13071 bytes]
<br><a href="https://yarchive.net/comp/linux/negative_dentries.html">Negative dentries </a> (Linus Torvalds) [2379 bytes]
<br><a href="https://yarchive.net/comp/linux/network_filesystems.html">Network filesystems </a> (Al Viro) [2907 bytes]
<br><a href="https://yarchive.net/comp/linux/nfs.html">NFS </a> (Linus Torvalds) [4352 bytes]
<br><a href="https://yarchive.net/comp/linux/no_irq.html">NO_IRQ </a> (Linus Torvalds) [7379 bytes]
<br><a href="https://yarchive.net/comp/linux/nop.html">NOP </a> (Linus Torvalds) [2329 bytes]
<br><a href="https://yarchive.net/comp/linux/o_direct.html">O_DIRECT </a> (Larry McVoy; Linus Torvalds) [52865 bytes]
<br><a href="https://yarchive.net/comp/linux/oops_decoding.html">Oops decoding </a> (Al Viro; Linus Torvalds) [34176 bytes]
<br><a href="https://yarchive.net/comp/linux/Os.html">-Os </a> (Linus Torvalds) [3063 bytes]
<br><a href="https://yarchive.net/comp/linux/page_cache.html">The page cache </a> (Linus Torvalds) [5480 bytes]
<br><a href="https://yarchive.net/comp/linux/page_coloring.html">Page coloring </a> (Larry McVoy; Linus Torvalds) [6901 bytes]
<br><a href="https://yarchive.net/comp/linux/page_sizes.html">Page sizes </a> (Linus Torvalds) [29511 bytes]
<br><a href="https://yarchive.net/comp/linux/page_tables.html">Page tables </a> (Linus Torvalds; Paul Mackerras) [43972 bytes]
<br><a href="https://yarchive.net/comp/linux/page_zeroing_strategy.html">Page zeroing strategy </a> (Linus Torvalds) [12354 bytes]
<br><a href="https://yarchive.net/comp/linux/partial_reads_writes.html">Partial reads and writes </a> (Larry McVoy; Linus Torvalds) [12604 bytes]
<br><a href="https://yarchive.net/comp/linux/patches.html">Patches </a> (Al Viro; Kirill Korotaev; Linus Torvalds; Theodore Tso) [34010 bytes]
<br><a href="https://yarchive.net/comp/linux/patch_tracking.html">Patch tracking </a> (Linus Torvalds) [19166 bytes]
<br><a href="https://yarchive.net/comp/linux/patents.html">Patents </a> (Al Viro; Larry McVoy; Linus Torvalds; Theodore Tso) [14147 bytes]
<br><a href="https://yarchive.net/comp/linux/pc_clocks.html">PC clocks </a> (H. Peter Anvin) [3857 bytes]
<br><a href="https://yarchive.net/comp/linux/penguin.html">The penguin logo </a> (Linus Torvalds) [1043 bytes]
<br><a href="https://yarchive.net/comp/linux/pipe_packetize.html">Using pipes to send a packet stream </a> (Linus Torvalds) [1395 bytes]
<br><a href="https://yarchive.net/comp/linux/pivot_root.html">pivot_root() </a> (Linus Torvalds) [3382 bytes]
<br><a href="https://yarchive.net/comp/linux/plugging.html">I/O plugging </a> (Jens Axboe; Linus Torvalds) [22911 bytes]
<br><a href="https://yarchive.net/comp/linux/pointer_overlap.html">Pointer overlap </a> (Linus Torvalds) [3848 bytes]
<br><a href="https://yarchive.net/comp/linux/pointer_subtraction.html">Pointer subtraction </a> (Al Viro; Linus Torvalds) [4764 bytes]
<br><a href="https://yarchive.net/comp/linux/point_to_point_links.html">Point-to-point links </a> (Linus Torvalds) [4504 bytes]
<br><a href="https://yarchive.net/comp/linux/pop_instruction_speed.html">POP instruction speed </a> (Jeff Garzik; Linus Torvalds) [21275 bytes]
<br><a href="https://yarchive.net/comp/linux/priority_inheritance.html">Priority inheritance </a> (Linus Torvalds) [3952 bytes]
<br><a href="https://yarchive.net/comp/linux/process_wakeup.html">Process wakeup </a> (Linus Torvalds) [2725 bytes]
<br><a href="https://yarchive.net/comp/linux/proc_self_fd.html">/proc/self/fd </a> (Theodore Tso) [2043 bytes]
<br><a href="https://yarchive.net/comp/linux/ptrace_mmap.html">ptrace and mmap </a> (Linus Torvalds) [7146 bytes]
<br><a href="https://yarchive.net/comp/linux/ptrace_self_attach.html">ptrace() self-attach </a> (Linus Torvalds) [4480 bytes]
<br><a href="https://yarchive.net/comp/linux/ptrace_signals.html">ptrace() and signals </a> (Linus Torvalds) [17993 bytes]
<br><a href="https://yarchive.net/comp/linux/put_user.html">put_user() </a> (Linus Torvalds) [4292 bytes]
<br><a href="https://yarchive.net/comp/linux/quirks.html">Quirks </a> (Linus Torvalds) [6629 bytes]
<br><a href="https://yarchive.net/comp/linux/raid0.html">RAID0 </a> (Linus Torvalds) [8803 bytes]
<br><a href="https://yarchive.net/comp/linux/readahead.html">Readahead </a> (Linus Torvalds) [1903 bytes]
<br><a href="https://yarchive.net/comp/linux/readdir_nonatomicity.html">readdir() nonatomicity </a> (Theodore Ts'o) [5534 bytes]
<br><a href="https://yarchive.net/comp/linux/recursive_locks.html">Recursive locks </a> (Linus Torvalds) [8847 bytes]
<br><a href="https://yarchive.net/comp/linux/reference_counting.html">Reference counting </a> (Linus Torvalds) [4766 bytes]
<br><a href="https://yarchive.net/comp/linux/regression_tracking.html">Regression tracking </a> (Linus Torvalds) [26622 bytes]
<br><a href="https://yarchive.net/comp/linux/reiser4.html">Reiser4 </a> (Christoph Hellwig; Linus Torvalds; Theodore Ts'o; Al Viro) [26551 bytes]
<br><a href="https://yarchive.net/comp/linux/resource_forks.html">Resource forks </a> (Linus Torvalds; Theodore Y. Ts'o) [26100 bytes]
<br><a href="https://yarchive.net/comp/linux/restrict.html">C99's 'restrict' keyword </a> (Linus Torvalds) [3372 bytes]
<br><a href="https://yarchive.net/comp/linux/revision_control_filesystem.html">Revision-control filesystem </a> (Linus Torvalds) [1970 bytes]
<br><a href="https://yarchive.net/comp/linux/rtlinux.html">RTLinux </a> (Linus Torvalds) [10020 bytes]
<br><a href="https://yarchive.net/comp/linux/rwlocks.html">rwlocks </a> (Linus Torvalds) [14504 bytes]
<br><a href="https://yarchive.net/comp/linux/scheduler.html">The scheduler </a> (Linus Torvalds) [7765 bytes]
<br><a href="https://yarchive.net/comp/linux/scsi_ids.html">SCSI ids </a> (Linus Torvalds) [7915 bytes]
<br><a href="https://yarchive.net/comp/linux/scsi_layer.html">The SCSI layer </a> (Theodore Tso) [11473 bytes]
<br><a href="https://yarchive.net/comp/linux/security_bugs.html">Security bugs </a> (Al Viro; Linus Torvalds; Theodore Tso) [36711 bytes]
<br><a href="https://yarchive.net/comp/linux/security_lists.html">Security mailing lists </a> (Alan Cox; Linus Torvalds; Theodore Ts'o) [59846 bytes]
<br><a href="https://yarchive.net/comp/linux/security.html">Security </a> (Linus Torvalds; Theodore Tso) [37230 bytes]
<br><a href="https://yarchive.net/comp/linux/select.html">select() </a> (Linus Torvalds) [4180 bytes]
<br><a href="https://yarchive.net/comp/linux/selinux.html">SELinux </a> (Al Viro; Ingo Molnar; Linus Torvalds; Theodore Tso) [17087 bytes]
<br><a href="https://yarchive.net/comp/linux/semaphores.html">Semaphores </a> (Linus Torvalds) [54756 bytes]
<br><a href="https://yarchive.net/comp/linux/sendfile.html">sendfile() </a> (Linus Torvalds) [38139 bytes]
<br><a href="https://yarchive.net/comp/linux/serial.html">The serial port driver </a> (Theodore Tso) [4737 bytes]
<br><a href="https://yarchive.net/comp/linux/shift_by_32.html">32-bit shifts </a> (Linus Torvalds) [2540 bytes]
<br><a href="https://yarchive.net/comp/linux/signal_safe.html">Signal-safe </a> (Linus Torvalds) [1395 bytes]
<br><a href="https://yarchive.net/comp/linux/signals_restart.html">Signals and system call restarting </a> (Theodore Y. Ts'o) [2419 bytes]
<br><a href="https://yarchive.net/comp/linux/signal_struct.html">signal_struct </a> (Linus Torvalds) [2894 bytes]
<br><a href="https://yarchive.net/comp/linux/signed_divisions.html">Signed divisions </a> (Al Viro; Linus Torvalds) [8195 bytes]
<br><a href="https://yarchive.net/comp/linux/signed_pointers.html">Signed pointers </a> (Linus Torvalds) [1398 bytes]
<br><a href="https://yarchive.net/comp/linux/signed_unsigned_casts.html">Signed&lt;-&gt;unsigned casts </a> (Linus Torvalds) [3023 bytes]
<br><a href="https://yarchive.net/comp/linux/slab.html">The slab allocator </a> (Linus Torvalds) [7349 bytes]
<br><a href="https://yarchive.net/comp/linux/small_static_binaries.html">Small static binaries </a> (Ulrich Drepper; Zack Weinberg) [6824 bytes]
<br><a href="https://yarchive.net/comp/linux/smp_costs.html">SMP costs </a> (Linus Torvalds) [2184 bytes]
<br><a href="https://yarchive.net/comp/linux/socklen_t.html">socklen_t </a> (Linus Torvalds) [1905 bytes]
<br><a href="https://yarchive.net/comp/linux/soft_update.html">Soft Update filesystems </a> (Theodore Ts'o) [7906 bytes]
<br><a href="https://yarchive.net/comp/linux/software_prefetching.html">Software prefetching from memory </a> (Linus Torvalds) [4011 bytes]
<br><a href="https://yarchive.net/comp/linux/software_quality.html">Software quality </a> (Al Viro) [4574 bytes]
<br><a href="https://yarchive.net/comp/linux/sparse.html">Sparse </a> (Linus Torvalds; Al Viro) [34099 bytes]
<br><a href="https://yarchive.net/comp/linux/specs.html">Specs </a> (Al Viro; Linus Torvalds; Theodore Ts'o) [14055 bytes]
<br><a href="https://yarchive.net/comp/linux/spinlocks.html">Spinlocks </a> (Ingo Molnar; Linus Torvalds; Paul E. McKenney) [59161 bytes]
<br><a href="https://yarchive.net/comp/linux/splice.html">splice() </a> (Linus Torvalds) [35592 bytes]
<br><a href="https://yarchive.net/comp/linux/stallman.html">Richard Stallman </a> (Al Viro) [1266 bytes]
<br><a href="https://yarchive.net/comp/linux/stat_size.html">stat() sizes of pipes/sockets </a> (Linus Torvalds) [1789 bytes]
<br><a href="https://yarchive.net/comp/linux/store_buffer.html">CPU store buffers </a> (Linus Torvalds) [8142 bytes]
<br><a href="https://yarchive.net/comp/linux/strncpy.html">strncpy() </a> (Linus Torvalds) [1519 bytes]
<br><a href="https://yarchive.net/comp/linux/struct_declarations.html">Struct declarations </a> (Linus Torvalds) [2683 bytes]
<br><a href="https://yarchive.net/comp/linux/struct_init.html">Struct initialization </a> (Al Viro; Linus Torvalds) [13396 bytes]
<br><a href="https://yarchive.net/comp/linux/stupid_mail_clients.html">Stupid mail clients </a> (Linus Torvalds) [5129 bytes]
<br><a href="https://yarchive.net/comp/linux/sun.html">Sun </a> (Linus Torvalds) [4940 bytes]
<br><a href="https://yarchive.net/comp/linux/suspend.html">Suspend </a> (Linus Torvalds; Theodore Tso) [16757 bytes]
<br><a href="https://yarchive.net/comp/linux/symbolic_links_git.html">Symbolic links and git </a> (Linus Torvalds) [1437 bytes]
<br><a href="https://yarchive.net/comp/linux/symbol_printing.html">Symbol printing </a> (Linus Torvalds) [4754 bytes]
<br><a href="https://yarchive.net/comp/linux/sysfs.html">Sysfs </a> (Al Viro; Theodore Tso) [19319 bytes]
<br><a href="https://yarchive.net/comp/linux/syslog_clogs.html">Syslog clogs </a> (Linus Torvalds) [1436 bytes]
<br><a href="https://yarchive.net/comp/linux/system_clock_localtime.html">Hardware clock on localtime, and fsck </a> (Martin Schwidefsky; Michal Schmidt; Theodore Tso) [8467 bytes]
<br><a href="https://yarchive.net/comp/linux/thread_synchronous_signals.html">Thread-synchronous signals </a> (Linus Torvalds) [4482 bytes]
<br><a href="https://yarchive.net/comp/linux/timer_wrapping_c.html">Timer wrapping-around in C </a> (Johannes Stezenbach; Linus Torvalds) [8575 bytes]
<br><a href="https://yarchive.net/comp/linux/tla.html">TLAs </a> (Linus Torvalds) [2938 bytes]
<br><a href="https://yarchive.net/comp/linux/tool_bundling.html">Tool bundling </a> (Al Viro; Linus Torvalds) [16966 bytes]
<br><a href="https://yarchive.net/comp/linux/triple_faults.html">Triple faults </a> (Linus Torvalds) [1090 bytes]
<br><a href="https://yarchive.net/comp/linux/tsc.html">TSC </a> (Linus Torvalds) [4476 bytes]
<br><a href="https://yarchive.net/comp/linux/tty_access_times.html">tty access times </a> (Linus Torvalds) [3767 bytes]
<br><a href="https://yarchive.net/comp/linux/tuning_parameters.html">Tuning parameters </a> (Linus Torvalds) [2271 bytes]
<br><a href="https://yarchive.net/comp/linux/TXT.html">TXT </a> (Theodore Tso) [10849 bytes]
<br><a href="https://yarchive.net/comp/linux/typedefs.html">Typedefs </a> (Linus Torvalds) [14694 bytes]
<br><a href="https://yarchive.net/comp/linux/unsigned_arithmetic.html">Unsigned arithmetic </a> (Linus Torvalds) [3232 bytes]
<br><a href="https://yarchive.net/comp/linux/user_kernel_splits.html">User / kernel splits </a> (Linus Torvalds) [9634 bytes]
<br><a href="https://yarchive.net/comp/linux/user_pointers.html">User pointers </a> (Linus Torvalds) [2653 bytes]
<br><a href="https://yarchive.net/comp/linux/user_space_filesystems.html">User-space filesystems </a> (Linus Torvalds) [10500 bytes]
<br><a href="https://yarchive.net/comp/linux/userspace_io.html">User-space I/O </a> (Linus Torvalds) [11647 bytes]
<br><a href="https://yarchive.net/comp/linux/utf8.html">UTF-8 </a> (H. Peter Anvin; Jamie Lokier; Linus Torvalds; Theodore Ts'o; Al Viro) [69577 bytes]
<br><a href="https://yarchive.net/comp/linux/utrace.html">utrace </a> (Linus Torvalds; Theodore Ts'o) [33682 bytes]
<br><a href="https://yarchive.net/comp/linux/vendor_driven.html">Vendor-driven </a> (Linus Torvalds) [8492 bytes]
<br><a href="https://yarchive.net/comp/linux/vmalloc.html">vmalloc() </a> (Jens Axboe; Linus Torvalds; Theodore Ts'o) [10819 bytes]
<br><a href="https://yarchive.net/comp/linux/VMAs.html">VMAs </a> (Linus Torvalds) [4351 bytes]
<br><a href="https://yarchive.net/comp/linux/vm_dirty_ratio.html">vm_dirty_ratio </a> (Linus Torvalds) [7775 bytes]
<br><a href="https://yarchive.net/comp/linux/wakekill.html">Wakekill </a> (Linus Torvalds) [16695 bytes]
<br><a href="https://yarchive.net/comp/linux/work_on_cpu.html">work_on_cpu() </a> (Linus Torvalds) [1627 bytes]
<br><a href="https://yarchive.net/comp/linux/write_barriers.html">Write barriers </a> (Linus Torvalds) [26514 bytes]
<br><a href="https://yarchive.net/comp/linux/write_combining.html">Write combining </a> (Linus Torvalds) [2749 bytes]
<br><a href="https://yarchive.net/comp/linux/write_error_return.html">write() error return </a> (Linus Torvalds) [2777 bytes]
<br><a href="https://yarchive.net/comp/linux/x86-64.html">x86-64 </a> (Linus Torvalds) [4881 bytes]
<br><a href="https://yarchive.net/comp/linux/x86_rings.html">x86 rings </a> (H. Peter Anvin; Linus Torvalds) [4518 bytes]
<br><a href="https://yarchive.net/comp/linux/x86_tlb.html">The x86 TLB </a> (Linus Torvalds) [9941 bytes]
<br><a href="https://yarchive.net/comp/linux/x86.html">x86 versus other architectures</a> (Linus Torvalds) [22123 bytes]
<br><a href="https://yarchive.net/comp/linux/xen.html">Xen </a> (Linus Torvalds) [3920 bytes]
<br><a href="https://yarchive.net/comp/linux/xfs.html">XFS </a> (Al Viro) [1740 bytes]
<br><a href="https://yarchive.net/comp/linux/zero-copy.html">Zero-copy </a> (Linus Torvalds) [28652 bytes]
<br><a href="https://yarchive.net/comp/linux/ZERO_PAGE.html">ZERO_PAGE </a> (Linus Torvalds) [11084 bytes]
<br><a href="https://yarchive.net/comp/linux/zero.html">Zero as a special value </a> (Linus Torvalds) [27396 bytes]
<br><a href="https://yarchive.net/comp/linux/zfs.html">ZFS </a> (Theodore Tso) [5759 bytes]

</td>
</tr>
</tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Katy – 68000 Linux on a Solderless Breadboard (2014) (183 pts)]]></title>
            <link>https://www.bigmessowires.com/2014/11/17/68-katy-68000-linux-on-a-solderless-breadboard/</link>
            <guid>40404423</guid>
            <pubDate>Sun, 19 May 2024 05:12:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bigmessowires.com/2014/11/17/68-katy-68000-linux-on-a-solderless-breadboard/">https://www.bigmessowires.com/2014/11/17/68-katy-68000-linux-on-a-solderless-breadboard/</a>, See on <a href="https://news.ycombinator.com/item?id=40404423">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p><iframe width="500" height="375" src="https://www.youtube.com/embed/SRdLlaUmmpM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>What does it take to build a little 68000-based protoboard computer, and get it running Linux? In my case, about three weeks of spare time, plenty of coffee, and a strong dose of stubborness. After banging my head against the wall with problems ranging from the inductance of pushbutton switches to memory leaks in the C standard library, it finally works! I’ve built several other DIY computer systems before, but never took their software beyond simple assembly language programs. Having a full-fledged multitasking OS running on this ugly pile of chips and wires is a thrill, and opens up all kinds of interesting new possibilities. I’ve named this plucky little machine <strong>68 Katy</strong>.</p>
<p>&nbsp;<br>
<strong>Hardware</strong></p>
<p><img src="https://www.bigmessowires.com/wp-content/uploads/2014/11/68-katy-protoboard-final.jpg" alt="68-katy-protoboard-final" width="600" height="651" srcset="https://www.bigmessowires.com/wp-content/uploads/2014/11/68-katy-protoboard-final.jpg 600w, https://www.bigmessowires.com/wp-content/uploads/2014/11/68-katy-protoboard-final-276x300.jpg 276w" sizes="(max-width: 600px) 100vw, 600px"></p>
<p>Here’s a look at the final version of the hardware. It took about a week to assemble and wire up all the parts on a solderless breadboard. The heart of the system is a Motorola 68008 CPU, a low-cost variant of the more common 68000, with fewer address pins and an 8-bit data bus. The CPU has 20 address pins, allowing for 1 MB of total address space. It’s paired with a 512K 8-bit SRAM, and a 512K Flash ROM (of which 480K is addressable – the remaining 32K is memory-mapped I/O devices). </p>
<p>The standard 68000 CPU has a 16-bit data bus, so it normally requires at least two 8-bit RAM chips and two 8-bit ROM chips. The 68008 requires fewer memory chips thanks to its 8-bit data bus, but the trade-off is that memory bandwidth is only half that of the 68000. Neither chip has any on-board cache, so half the memory bandwidth leads to roughly half the performance. My 68008 runs at 2 MHz (it was unstable when tested at 4 MHz), providing similar performance to a 1 MHz 68000. That’s pretty slow, even in comparison to 68000 systems from the early 1980’s, which were typically 8 MHz or faster.</p>
<p>An FT245 USB-to-FIFO module provides a communication link to another computer. On the external PC, it appears as a virtual serial port. Windows Hyperterm or another similar terminal program can be used to communicate with it, like an old VT100 terminal. On the 68 Katy side, the FT245 appears as a byte-wide I/O register mapped into the CPU’s address space. Reading from its address fetches the next incoming byte from the PC, and writing to the address sends a byte out to the PC. The FT245 has an internal 256-byte buffer, which helps smooth out the communication. When there’s an incoming byte waiting in the buffer, it triggers a CPU interrupt.</p>
<p>A 555 timer provides the only other interrupt source, generating a regular series of CPU interrupts at roughly 100 Hz. The initial version of the hardware had no timer interrupt, but I later discovered it was essential in order to get Linux working correctly.</p>
<p>The protoboard has eight LEDs for debugging, which are driven from a memory-mapped 74LS377 register. The rest of the protoboard is filled with assorted 7400 series parts and one PAL, which are used for address decoding, interrupt arbitration, and other basic glue logic.</p>
<p>Schematics? Forget it. Everything was built incrementally, one wire at a time, while staring at chip datasheets. It’s an organic creation.</p>
<p>&nbsp;<br>
<strong>Software</strong></p>
<p>Once the hardware build was done, I began writing some simple test programs in 68K assembly language. Wichit Sirichote’s <a href="http://chaokhun.kmitl.ac.th/~kswichit/68k/68k.html">zBug monitor</a> provided a good starting point for my own ROM-based monitor/bootloader. Using the monitor program, I was able to load other programs in binary or Motorola S-record format over the FT245 link, store them in RAM, and execute them. I was even able to get Lee Davison’s <a href="http://www.easy68k.com/applications.htm">ehBASIC for 68000</a> working, which provided a few hours of fun.</p>
<p>One feature I could have added to the monitor program, but didn’t, was the ability to reprogram the Flash ROM. The ROM chip has a read/write input pin just like an SRAM, but writing to the Flash ROM is more complicated. The CPU needs to first write a magic sequence of bytes in order to unlock the ROM. Then it needs to write more magic bytes to tell the ROM which blocks to erase, followed by the new bytes to be written. Finally, it must poll the output of the ROM to learn when the erase and reprogram sequence is complete. </p>
<p>The monitor program could have updated itself, or any other data stored in ROM, by copying itself to RAM, then running from RAM while saving new data to Flash ROM. But I was lazy and never implemented that feature, so I had to physically pull the ROM chip from the protoboard and place it in an external EPROM programmer whenever I made a change – about 100 times over the course of the project. Ugh.</p>
<p>&nbsp;<br>
<strong>Linux</strong></p>
<p>Inspired by a <a href="http://mc68k.blogspot.com/2012/03/uclinux-part-i.html">similar project</a>, I decided that a simple monitor program and BASIC weren’t interesting enough, and I needed to run Linux on this hardware. It sounded interesting and exciting, but I really had no idea where to begin. I had plenty of experience as a Linux user (as well as other UNIX versions), but I knew nothing about how the kernel worked, or how to build it from source code, or to port it to new hardware. So the real adventure began there.</p>
<p>The first challenge was to learn how to build a Linux image for an existing machine. It seemed simple enough in theory – just download the source code from kernel.org or some other distribution tree, and compile it. Reality was more complicated, and there were many details that confused me, and build problems I was powerless to solve. It wasn’t easy, and I discussed the process in much more detail in this <a href="https://www.bigmessowires.com/2014/11/06/building-uclinux-for-a-68000-target/">earlier post</a>. </p>
<p>I chose to use uClinux, a Linux distribution designed for microcontrollers and other low-end hardware, particularly CPUs without an MMU and that can’t support virtual memory. Then I chose a very old version of uClinux, based on kernel 2.0.39, that dates all the way back to 2001! I configured it to disable nearly every single optional feature, including all networking support. This ancient code was my best hope for getting a Linux that would actually run in 512K of ROM and 512K of RAM.</p>
<p>Starting with the uClinux configuration for another 68000-based system, I updated the code to reflect the 68 Katy memory map, changed the system initialization code, and added a driver for the FT245. Describing those steps makes them sound simple, and they might have been for someone more experienced with Linux, but for me it was a challenge just to identify which files and functions needed to modified. Google wasn’t very helpful, since I was working with such an old version of the kernel, and the resources I found on building/porting Linux mostly weren’t applicable. I primarily relied on the Linux <i>grep</i> command to search through the thousands of kernel source files for strings of interest, then stared at the code until I could understand how it worked.</p>
<p>After about a week, I had something I was <a href="https://www.bigmessowires.com/2014/11/10/baby-steps-with-uclinux/">ready to test</a>. And it worked, at least a little bit! It showed the first few lines of kernel output, but hung at “calibrating delay loop”. Aha, I needed a timer interrupt. Of course! I added a 555 timer and some extra interrupt logic, and was ready to try again.</p>
<p>The <a href="https://www.bigmessowires.com/2014/11/12/inching-forward/">second attempt</a> got further into the boot process, but failed to mount the memory-resident root filesystem. I was stumped for a while. After looking more carefully, I discovered that my linker script was mapping the root filesystem and BSS to the same address in RAM, and the earily initialization code was overwriting the filesystem with zeroes. And more fundamentally, I discovered that it wasn’t possible to fit all of Linux in 512K RAM, including the kernel code, static data, root filesystem, and dynamically allocated memory. Something had to be moved to ROM, or it was never going to work.</p>
<p>In the <a href="https://www.bigmessowires.com/2014/11/13/banging-my-head-against-the-wall/">third attempt</a>, I moved the root filesystem image to ROM, freeing up about 150K of RAM. And this kind of, almost worked! It booted, mounted the filesystem, and seemed to be working OK, but then suddenly it would land back at the monitor program prompt. Huh? I eventually tracked this one to the FT245 driver I’d written. I only implemented the minimal set of required driver functions, and the other optional functions were NULL entries in a function table somewhere. One of the functions I thought was optional proved to be required. When the kernel called it, it used a NULL function pointer, causing a jump to address 0, restarting my monitor program.</p>
<p>The fourth attempt was better. It spawned the init process, and ran the startup script, but died with out-of-memory errors before it completed. At the time, 68 Katy’s memory map was 256K ROM, 256K I/O devices, and 512K RAM. By shrinking the I/O space to 32K, I was able to increase the usable ROM to 480K, providing enough space to store the root filesystem image <em>and </em>the kernel code itself! This freed up another 251K of RAM.</p>
<p>The fifth attempt actually booted to a shell prompt! Now it was executing the kernel code directly from ROM. I was able to run a few commands, like <em>ls </em>and <em>cat</em>, but then the system would run out of memory and die. As I investigated, it looked like memory allocated from <em>malloc()</em> and <em>do_mmap()</em> was never beeing freed. Was this some kind of free list allocator I didn’t understand? No. It turns out I’d made a typo in a function called <em>is_in_rom()</em>, adding too many zeroes, causing the memory allocator to think all addresses were in ROM and so didn’t need to be freed. Then after fixing that, I discovered a small memory leak in the C library <em>setenv()</em> function. I never did solve that one, but instead just modified the programs that used it to avoid calling it.</p>
<p>My debugging method was primitive: lots of <em>printk </em>and <em>printf </em>statements sprinkled everywhere. Then pull the ROM chip, reprogram it in an external EPROM programmer, replace it in the protoboard, and try again.</p>
<p>The sixth attempt finally worked. Two weeks after beginning my experiments with Linux, I had a working system! Here’s a screenshot of the boot sequence:</p>
<p><img src="https://www.bigmessowires.com/wp-content/uploads/2014/11/linux-2.0.39-boot.png" alt="linux-2.0.39-boot" width="677" height="686" srcset="https://www.bigmessowires.com/wp-content/uploads/2014/11/linux-2.0.39-boot.png 677w, https://www.bigmessowires.com/wp-content/uploads/2014/11/linux-2.0.39-boot-296x300.png 296w" sizes="(max-width: 677px) 100vw, 677px"></p>
<p>Watch the video for more details. I’m using a shell called sash, which has a few dozen common shell commands (like <em>ls </em>and <em>cat</em>) built directly into it. The root filesystem in ROM is read-only, and a small read-write filesystem is created in a RAM disk. The system supports multitasking, so it can run an LED blinker program in the background while still working in the Linux shell. It even has vi, and Colossal Cave Adventure!</p>
<p>It was an interesting journey. The Linux kernel still seems big and unwiedly to me, but no longer seems so scary as it did initially. It’s just an especially big program, and most of its pieces aren’t too difficult to understand if you open up the relevant source files and start reading.</p>
<p>&nbsp;<br>
<strong>Memory Requirements</strong></p>
<p>So how much memory does it require to run a super-minimal uClinux system, with an old 2.0 kernel? If you follow my example and put as much as possible in ROM, it needs about 343K of ROM and 312K of RAM, or just 628K of RAM if you’ve got a bootloader that can fill RAM from some external source. My 68 Katy system is slightly heavier than that due to including vi and Adventure, but not by much. Here’s the breakdown:</p>
<p>ROM</p>
<ul>
<li>kernel code and read-only data (.text and .rodata segments) – 251K</li>
<li>kernel initialized static data (.data segment) – 27K</li>
<li>root filesystem – 189K</li>
</ul>
<p>RAM</p>
<ul>
<li>kernel static data (.data and .bss segments) – 84K</li>
<li>kernel dynamic allocations during boot-up – 104K</li>
<li>RAM disk – 64K</li>
<li>init and shell process allocations – 58K</li>
<li>stack and exception vectors – 2K</li>
</ul>
<p>&nbsp;<br>
<strong>Problems</strong></p>
<p>The kernel always measures the CPU at 0.81 bogomips, regardless of the clock crystal I use. The 555 timer interrupt is independent of the CPU clock, so with a faster clock the bogomips calculation should measure more executions of the busy loop per timer interrupt. I’m not sure why it doesn’t, but it means any real-time calculations will be off.</p>
<p>The display in vi acts weird. Some lines appear prefixed with a capital H, and stray Unicode characters appear here and there. At first I thought this was a hardware bug, and I’m still not certain it isn’t. But I think it’s probably an issue with the way my terminal program (Tera Term) handles the ANSI escape sequences sent by vi. I tried all the different terminal settings available in Tera Term, and also tried a different terminal program, all with the same result. </p>
<p>&nbsp;<br>
<strong>What’s Next?</strong></p>
<p>This 68008 system on a protoboard was intended to be only an experiment and proof-of-concept for the <em>real </em>68 Katy, which I had planned to build on a custom PCB with a full 68000 CPU, a CPLD for glue logic, more RAM, an SD card, and ethernet. But this experiment was perhaps a bit too successful, and now I’m wondering if it really makes sense to go to the effort of building the “real” system if it’s going to be essentially the same thing, only faster. Of course the SD card and ethernet will add some interesting new elements, so maybe it’s fine. I probably need to sleep on the question for a few days.</p>
<p>One way of adding more spice to the next iteration of 68 Katy would be to include video output, so it could directly drive a monitor instead of being controlled through a serial terminal. I’ve done that once before, with BMOW 1, which had VGA output. It mostly worked, although the arbitration for video memory between the display hardware and the CPU was clunky and produced visible display artifacts. To take things further, I could even aim for DVI or HDMI video output, since VGA is a slowly dying standard. </p>
<p>The smart move is probably to stick with my original plan. Lots of extra features are cool, but also have a way of killing a project. I’d rather have something with 10 features and that works, than something with 20 features that I never finished or that collapsed under the weight of its complexity. But until then, excuse me while I go play some more Colossal Cave…</p>
<p>&nbsp;<br>
<strong>Files</strong><br>
The source code for my 68 Katy port of uClinux is available for download, as well as the toolchain I used to build it, the monitor/bootloader source, and a preconfigured VirtualBox machine image of Ubuntu 12.04 to host it all. Grab the files <a href="https://www.bigmessowires.com/68-katy/">here</a>. Have fun!</p>
      
<p><a href="https://www.bigmessowires.com/2014/11/17/68-katy-68000-linux-on-a-solderless-breadboard/#comments">Read 53 comments and join the conversation</a>&nbsp;      
    </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Big Tech to EU: "Drop Dead" (282 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2024/05/big-tech-eu-drop-dead</link>
            <guid>40404296</guid>
            <pubDate>Sun, 19 May 2024 04:31:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2024/05/big-tech-eu-drop-dead">https://www.eff.org/deeplinks/2024/05/big-tech-eu-drop-dead</a>, See on <a href="https://news.ycombinator.com/item?id=40404296">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span data-contrast="none">The European Union’s new Digital Markets Act (DMA) is a complex, many-legged beast, but at root, it is a regulation that aims to make it easier for the public to control the technology they use and rely on.&nbsp;</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">One DMA rule forces </span><span>the powerful “gatekeeper” </span><span data-contrast="none">tech companies to allow third-party app stores. That means that you, the owner of a device, can decide who you trust to provide you with software for it.&nbsp;</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">Another rule requires those tech gatekeepers to offer interoperable gateways that other platforms can plug into - so you can quit using a chat client, switch to a rival, and still connect with the people you left behind (similar measures may come to social media in the future).</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">There’s a rule banning “self-preferencing.” That’s when platforms push their often inferior, in-house products and hide superior products made by their rivals.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">And perhaps best of all, there’s a privacy rule, reinforcing the eight-year-old General Data Protection Regulation, a strong</span><span>,</span><span data-contrast="none"> privacy law that has been flouted</span><span>&nbsp;</span><span data-contrast="none"> for too long, </span><i><span data-contrast="none">especially </span></i><span data-contrast="none">by the largest tech giants.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">In other words, the DMA is meant to push us toward a world where you decide which software runs on your devices,</span><span>&nbsp;</span><span data-contrast="none"> where it’s easy to find the best products and services, where you can leave a platform for a better one without forfeiting your social relationships</span> <span data-contrast="none">,</span> <span data-contrast="none">and where you can do all of this without getting spied on.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span>If it </span><span>works,</span> <span data-contrast="none">this will get dangerously close to </span><a href="https://www.eff.org/how-to-fix-the-internet-podcast"><span data-contrast="none">better future</span></a><span data-contrast="none"> we’ve spent the past thirty years fighting for.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">There’s just one wrinkle: the Big Tech companies don’t want that future, and they’re trying their damndest to strangle it in its cradle.</span><span data-ccp-props="0}"></span></p>

<p><span data-ccp-props="0}">&nbsp;Right from the start, it was obvious that the tech giants were going to war against the DMA, and the freedom it promised to their users. Take Apple, whose tight control over which software its customers can install was a major concern of the DMA from its inception.</span><span data-ccp-props="0}"> <br></span></p>
<p><span data-contrast="none">Apple didn’t invent the idea of a “curated computer” that could only run software that was blessed by its manufacturer, but they certainly perfected it. iOS devices will refuse to run software unless it comes from Apple’s App Store, and that control over Apple’s customers means that Apple can exert tremendous control over app vendors, too.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-ccp-props="{}">&nbsp;Apple charges app vendors a whopping 30 percent commission on most transactions, both the initial price of the app and everything you buy from it thereafter. This is a remarkably high transaction fee —compare it to the credit-card sector, itself the subject of sharp criticism for its high </span><i><span data-contrast="none">3-5</span></i><span data-contrast="none"> percent fees. To maintain those high commissions, Apple also restricts its vendors from informing their customers about the existence of other ways of paying (say, via their website) and at various times has also banned its vendors from offering discounts to customers who complete their purchases without using the app.&nbsp;</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-ccp-props="{}">Apple is adamant that it needs this control to keep its customers safe, but </span><a href="https://www.eff.org/document/letter-bruce-schneier-senate-judiciary-regarding-app-store-security"><span data-contrast="none">in theory</span></a><span data-contrast="none"> and </span><a href="https://gizmodo.com/apple-iphone-analytics-tracking-even-when-off-app-store-1849757558"><span data-contrast="none">in practice</span></a><span data-contrast="none">, Apple has shown that </span><a href="https://www.eff.org/document/letter-bruce-schneier-senate-judiciary-regarding-app-store-security"><span data-contrast="none">it can protect you without maintaining this degree of control</span></a><span data-contrast="none">, and that </span><a href="https://gizmodo.com/apple-iphone-analytics-tracking-even-when-off-app-store-1849757558"><span data-contrast="none">it uses this control to </span><i><span data-contrast="none">take away</span></i><span data-contrast="none"> your security when it serves the company’s profits to do so</span></a><span data-contrast="none">.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-ccp-props="{}">Apple </span><a href="https://companiesmarketcap.com/apple/marketcap/"><span data-contrast="none">is worth between two and three trillion dollars</span></a><span data-contrast="none">. Investors prize Apple’s stock in large part due to </span><a href="https://www.nytimes.com/2021/03/18/opinion/apple-google-app-monopoly.html"><span data-contrast="none">the tens of billions of dollars it extracts from other businesses</span></a><span data-contrast="none"> that want to reach its customers.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">The DMA is aimed squarely at these practices. It requires the largest app store companies to grant their customers the freedom to choose other app stores. Companies like Apple were given over a year to prepare for the DMA, and were told to produce compliance plans by March of this year.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">But </span><a href="https://proton.me/blog/apple-dma-compliance-plan-trap"><span data-contrast="none">Apple’s compliance plan falls </span><i><span data-contrast="none">very</span></i><span data-contrast="none"> short of the mark</span></a><span data-contrast="none">: between a blizzard of confusing junk fees (like the €0.50 per use “Core Technology Fee” that the most popular apps will have to pay Apple even if their apps are sold through a rival store) and onerous conditions (app makers who try </span><span>to sell through </span><span data-contrast="none">a rival app store </span><span>are </span><span>have their offerings </span><span data-contrast="none">removed from Apple’s store, and are permanently&nbsp;</span><span> banned </span><span data-contrast="none">from it), the plan in no way satisfies the EU’s goal of fostering competition in app stores.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">That’s just scratching the surface of Apple’s absurd proposal: Apple’s customers will have to successfully navigate a maze of deeply buried settings just to try another app store (</span><a href="https://9to5mac.com/2024/04/01/altstore-iphone-apps-patreon-eu/"><span data-contrast="none">and there’s some pretty cool-sounding app stores in the wings</span></a><span data-contrast="none">!), and </span><a href="https://www.theverge.com/2024/3/7/24093437/apple-iphone-third-party-app-store-dma-eu"><span data-contrast="none">Apple will disable all your third-party apps if you take your phone out of the EU for 30 days</span></a><span data-contrast="none">.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">Apple appears to be playing a high-stakes game of chicken with EU regulators, effectively saying, “Yes, you have 500 million citizens, but we have three trillion dollars, so why should we listen to you?” Apple inaugurated this performance of noncompliance by banning Epic, the company most closely associated with the EU’s decision to require third party app stores, from operating an app store and terminating its developer account (</span><a href="https://www.epicgames.com/site/en-US/news/apple-terminated-epic-s-developer-account"><span data-contrast="none">Epic’s account was later reinstated</span></a><span data-contrast="none"> after the EU registered its disapproval).</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">It’s not just Apple, of course.&nbsp;</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">The DMA includes new enforcement tools to finally apply the General Data Privacy Regulation (GDPR) to US tech giants. The GDPR is Europe’s landmark privacy law, but in the eight years since its passage, Europeans have struggled to use it to reform the terrible privacy practices of the largest tech companies.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">Meta is one of the worst on privacy, and no wonder: its entire business is grounded in the nonconsensual extraction and mining of billions of dollars’ worth of private information from billions of people all over the world. The GDPR should be requiring Meta to actually secure our willing, informed (and revocable) consent to carry on all this surveillance, and there’s </span><a href="https://www.cnbc.com/2022/02/02/facebook-says-apple-ios-privacy-change-will-cost-10-billion-this-year.html"><span data-contrast="none">good evidence that more than 95 percent of us would block Facebook spying if we could</span></a><span data-contrast="none">.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">Meta’s answer to this is a “</span><a href="https://noyb.eu/en/pay-or-okay-1500-eu-year-your-online-privacy"><span data-contrast="none">Pay or Okay</span></a><span data-contrast="none">” system, in which users who do not consent to Meta’s surveillance will have to pay to use the service, or be blocked from it. Unfortunately for Meta, this is prohibited (privacy is not a luxury good that only the wealthiest should be afforded).&nbsp;</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">Just like Apple, Meta is behaving as though the DMA permits it to carry on its worst behavior, with minor cosmetic tweaks around the margins. Just like Apple, Meta is daring the EU to enforce its democratically enacted laws, implicitly promising to pit its billions against Europe’s institutions to preserve its right to spy on us.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">These are high-stakes clashes. </span><a href="https://www.ft.com/content/6fb1602d-a08b-4a8c-bac0-047b7d64aba5"><span data-contrast="none">As the tech sector grew more concentrated, it also grew less accountable</span></a><span data-contrast="none">, able to substitute lock-in and regulatory capture for making good products and </span><a href="https://www.eff.org/wp/who-has-your-back-2019"><span data-contrast="none">having their users’ backs</span></a><span data-contrast="none">. Tech has found new ways to compromise our </span><a href="https://www.eff.org/issues/privacy"><span data-contrast="none">privacy rights</span></a><span data-contrast="none">, our </span><a href="https://www.eff.org/deeplinks/2021/08/tech-rights-are-workers-rights-doordash-edition"><span data-contrast="none">labor rights</span></a><span data-contrast="none">, and our </span><a href="https://scholarship.law.bu.edu/faculty_scholarship/3645/"><span data-contrast="none">consumer rights</span></a><span data-contrast="none"> - at scale.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-ccp-props="{}">After decades of regulatory indifference to tech monopolization, competition authorities all over the world are taking on Big Tech. The DMA is by far the most muscular and ambitious salvo we’ve seen.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-ccp-props="{}">Seen in that light, it’s no surprise that Big Tech is refusing to comply with the rules. If the EU successfully forces tech to play fair, it will serve as a starting gun for a global race to the top, in which tech’s ill-gotten gains - of data, power and money - will be returned to the users and workers from whom that treasure came.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-ccp-props="{}">The architects of the DMA and DSA foresaw this, of course. </span><a href="https://open-web-advocacy.org/blog/eu-opens-dma-investigations/"><span data-contrast="none">They’ve announced investigations into Apple, Google and Meta</span></a><span data-contrast="none">, threatening </span><a href="https://www.techrepublic.com/article/european-commission-antitrust-investigation-apple-meta-alphabet/"><span data-contrast="none">fines of 10 percent of the companies’ global income, which will </span><i><span data-contrast="none">double</span></i><span data-contrast="none"> to 20 percent</span></a><span data-contrast="none"> if the companies don’t toe the line.</span><span data-ccp-props="0}">&nbsp;</span></p>
<p><span data-contrast="none">It’s not just Big Tech that’s playing for all the marbles - it’s also the systems of democratic control and accountability. If Apple can sabotage the DMA’s insistence on taking away its veto over its customers’ software choices, that will spill over into </span><a href="https://www.justice.gov/opa/media/1344546/dl?inline"><span data-contrast="none">the US Department of Justice’s case over the same issue</span></a><span data-contrast="none">, as well as the cases in </span><a href="https://asia.nikkei.com/Business/Technology/Japan-to-crack-down-on-Apple-and-Google-app-store-monopolies"><span data-contrast="none">Japan</span></a><span data-contrast="none"> and </span><a href="https://www.reuters.com/technology/skorea-considers-505-mln-fine-against-google-apple-over-app-market-practices-2023-10-06/"><span data-contrast="none">South Korea</span></a><span data-contrast="none">, and the </span><a href="https://www.gov.uk/government/news/cma-wins-appeal-in-apple-case"><span data-contrast="none">pending enforcement action in the UK</span></a><span data-contrast="none">.</span><span data-ccp-props="0}">&nbsp;</span></p>



</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Riven (478 pts)]]></title>
            <link>https://www.filfre.net/2024/05/riven/</link>
            <guid>40404054</guid>
            <pubDate>Sun, 19 May 2024 03:34:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.filfre.net/2024/05/riven/">https://www.filfre.net/2024/05/riven/</a>, See on <a href="https://news.ycombinator.com/item?id=40404054">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
														<div id="attachment_5919"><p><a href="https://www.filfre.net/2024/05/riven/millers/" rel="attachment wp-att-5919"><img fetchpriority="high" decoding="async" aria-describedby="caption-attachment-5919" src="https://www.filfre.net/wp-content/uploads/2024/05/millers-300x262.jpg" alt="" width="515" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/05/millers-300x262.jpg 300w, https://www.filfre.net/wp-content/uploads/2024/05/millers-1024x896.jpg 1024w, https://www.filfre.net/wp-content/uploads/2024/05/millers-768x672.jpg 768w, https://www.filfre.net/wp-content/uploads/2024/05/millers-1536x1343.jpg 1536w, https://www.filfre.net/wp-content/uploads/2024/05/millers.jpg 1546w" sizes="(max-width: 515px) 100vw, 515px"></a></p><p id="caption-attachment-5919">Robyn and Rand Miller.</p></div>
<p>Sometimes success smacks you right in the face. More often, it sneaks up on you from behind.</p>
<p>In September of 1993, <a href="https://www.filfre.net/2016/10/the-manhole">the brothers Rand and Robyn Miller</a> and the few other employees of Cyan, Inc., were prototypical starving artists, living on “rice and beans and government cheese.” That month they saw Brøderbund publish their esoteric Apple Macintosh puzzle game <a href="https://www.filfre.net/2020/02/myst-or-the-drawbacks-to-success"><em>Myst</em></a>, which they and everyone else regarded as a niche product for a niche platform. There would go another year before it became abundantly clear that <em>Myst</em>, now available in a version for Microsoft Windows as well as for the Mac, was a genuine mass-market hit. It would turn into the gift that kept on giving, a game with more legs than your average millipede. It wouldn’t enjoy its best single month until December of 1996, when it would set a record for the most copies one game had <em>ever</em> sold in one month.</p>
<p>All of this — not just the sales figures themselves but the dozens of awards, the write-ups in glossy magazines like <em>Rolling Stone</em> and <em>Newsweek</em>, the fawningly overwritten profiles in <em>Wired</em>, the comparisons with Steven Spielberg’s <em>Jurassic Park</em> and Michael Jackson’s <em>Thriller</em> — happened just gradually enough that it seemed almost natural. <em>Almost</em> natural. “It took a while for it to hit me that millions of people were buying this game,” says Robyn Miller. “The most I could really wrap my head around would be to go to a huge concert and see all of the people there and think, ‘Okay, this is not even a portion of the people who are playing <em>Myst</em>.'”</p>
<p>The Miller brothers could have retired and lived very comfortably for the rest of their lives on the fortune they earned from <em>Myst</em>. They didn’t choose this path. “We took salaries that were fairly modest and just put the company’s money back into [a] new project,” says Rand.</p>
<p>Brøderbund was more than eager for a sequel to <em>Myst</em>, something that many far smaller hits than it got as a matter of course within a year. But the Miller brothers refused to be hurried, and did not need to be, a rare luxury indeed in their industry. Although they enjoyed a very good relationship with Brøderbund, whose marketing acumen had been essential to getting the <em>Myst</em> ball rolling, they did not wish to be beholden to their publisher in any way. Rather than accepting the traditional publisher advance, they decided that they would fund the sequel entirely on their own out of the royalties of the first game. This meant that, as <em>Myst</em> blew up bigger and bigger, their ambitions for the game they intended to call <em>Riven</em> were inflated in tandem. They refused to give Brøderbund a firm release date; it will be done when it’s done, they said. They took to talking about <em>Myst</em> as their <em>Hobbit</em>, <em>Riven</em> as their <em>Lord of the Rings</em>. It had taken J.R.R. Tolkien seventeen years to bridge the gap between his children’s adventure story and the most important fantasy epic in modern literary history. Surely Brøderbund could accept having to wait just a few years for <em>Riven</em>, especially with the sales figures <em>Myst</em> was still putting up.</p>
<p>Cyan’s digs reflected their rising status. They hadn’t even had a proper office when they were making <em>Myst</em>; everybody worked out of their separate homes in and around Spokane, Washington, sharing their output with one another using the “car net”: put it on a disk, get into your car, and drive it over to the other person. In the immediate aftermath of <em>Myst’</em>s release and promising early sales, they all piled into a drafty, unheated garage owned by their sound specialist Chris Brandkamp. Then, as the sales numbers continued to tick upward, they moved into an anonymous-looking former Comfort World Mattress storefront. Finally, in January of 1995, they broke ground on a grandiosely named “Cyan World Headquarters,” whose real-world architecture was to be modeled on the virtual architecture of <em>Myst</em> and <em>Riven</em>. While they were waiting for that building to be completed — the construction would take eighteen months — they junked the consumer-grade Macs which had slowly and laboriously done all of the 3D modeling necessary to create <em>Myst’</em>s environments in favor of Silicon Graphics workstations that cost $40,000 a pop.</p>
<hr>
<div id="attachment_5921"><p><a href="https://www.filfre.net/2024/05/riven/ground/" rel="attachment wp-att-5921"><img decoding="async" aria-describedby="caption-attachment-5921" src="https://www.filfre.net/wp-content/uploads/2024/05/ground-300x195.jpg" alt="" width="600" height="389" srcset="https://www.filfre.net/wp-content/uploads/2024/05/ground-300x195.jpg 300w, https://www.filfre.net/wp-content/uploads/2024/05/ground-1024x664.jpg 1024w, https://www.filfre.net/wp-content/uploads/2024/05/ground-768x498.jpg 768w, https://www.filfre.net/wp-content/uploads/2024/05/ground.jpg 1386w" sizes="(max-width: 600px) 100vw, 600px"></a></p><p id="caption-attachment-5921">Cyan breaks ground on their new “world headquarters.”</p></div>
<div id="attachment_5922"><p><a href="https://www.filfre.net/2024/05/riven/offices1/" rel="attachment wp-att-5922"><img decoding="async" aria-describedby="caption-attachment-5922" src="https://www.filfre.net/wp-content/uploads/2024/05/offices1-300x116.jpg" alt="" width="600" height="231" srcset="https://www.filfre.net/wp-content/uploads/2024/05/offices1-300x116.jpg 300w, https://www.filfre.net/wp-content/uploads/2024/05/offices1-1024x395.jpg 1024w, https://www.filfre.net/wp-content/uploads/2024/05/offices1-768x296.jpg 768w, https://www.filfre.net/wp-content/uploads/2024/05/offices1-1536x592.jpg 1536w, https://www.filfre.net/wp-content/uploads/2024/05/offices1-2048x790.jpg 2048w" sizes="(max-width: 600px) 100vw, 600px"></a></p><p id="caption-attachment-5922">The completed building looked very much apiece with their games, both outside…</p></div>
<div id="attachment_5923"><p><a href="https://www.filfre.net/2024/05/riven/offices2/" rel="attachment wp-att-5923"><img decoding="async" aria-describedby="caption-attachment-5923" src="https://www.filfre.net/wp-content/uploads/2024/05/offices2-300x234.jpg" alt="" width="577" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/05/offices2-300x234.jpg 300w, https://www.filfre.net/wp-content/uploads/2024/05/offices2-1024x798.jpg 1024w, https://www.filfre.net/wp-content/uploads/2024/05/offices2-768x599.jpg 768w, https://www.filfre.net/wp-content/uploads/2024/05/offices2.jpg 1235w" sizes="(max-width: 577px) 100vw, 577px"></a></p><p id="caption-attachment-5923">…and inside.</p></div>
<div id="attachment_5924"><p><a href="https://www.filfre.net/2024/05/riven/sgi/" rel="attachment wp-att-5924"><img decoding="async" aria-describedby="caption-attachment-5924" src="https://www.filfre.net/wp-content/uploads/2024/05/SGI-300x249.jpg" alt="" width="542" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/05/SGI-300x249.jpg 300w, https://www.filfre.net/wp-content/uploads/2024/05/SGI-1024x850.jpg 1024w, https://www.filfre.net/wp-content/uploads/2024/05/SGI-768x637.jpg 768w, https://www.filfre.net/wp-content/uploads/2024/05/SGI-1536x1275.jpg 1536w, https://www.filfre.net/wp-content/uploads/2024/05/SGI.jpg 1682w" sizes="(max-width: 542px) 100vw, 542px"></a></p><p id="caption-attachment-5924">The machines that made <em>Riven</em>. Its imagery was rendered using $1 million worth of <a href="https://www.filfre.net/2023/05/the-next-generation-in-graphics-part-2-three-dimensions-in-hardware">Silicon Graphics</a> hardware: a dozen or so workstations connected to these four high-end servers that did the grunt work of the ray-tracing. It was a far cry from <em>Myst</em>, which had been made with ordinary consumer-grade Macs running off-the-shelf software.</p></div>
<div id="attachment_5938"><p><a href="https://www.filfre.net/2024/05/riven/cyan/" rel="attachment wp-att-5938"><img decoding="async" aria-describedby="caption-attachment-5938" src="https://www.filfre.net/wp-content/uploads/2024/05/cyan-300x255.jpg" alt="" width="529" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/05/cyan-300x255.jpg 300w, https://www.filfre.net/wp-content/uploads/2024/05/cyan-1024x872.jpg 1024w, https://www.filfre.net/wp-content/uploads/2024/05/cyan-768x654.jpg 768w, https://www.filfre.net/wp-content/uploads/2024/05/cyan-1536x1307.jpg 1536w, https://www.filfre.net/wp-content/uploads/2024/05/cyan-2048x1743.jpg 2048w" sizes="(max-width: 529px) 100vw, 529px"></a></p><p id="caption-attachment-5938">And the people who made <em>Riven</em>…</p></div>
<hr>

<p>There were attempts to drum up controversies in the press, especially after <em>Riven</em> missed a tentative Christmas 1996 target date which Brøderbund had (prematurely) announced, a delay that caused the publisher’s stock price to drop by 25 percent. The journalists who always seemed to be hovering around the perimeter of Cyan’s offices claimed to sniff trouble in the air, an aroma of overstretched budgets and creative tensions. But, although there were certainly arguments — what project of this magnitude doesn’t cause arguments? — there was in truth no juicy decadence or discord going on at Cyan. The Miller brothers, sons of a preacher and still devout Christians, never lost their Heartland groundedness. They never let their fluke success go to their heads in the way of, say, the minds behind <a href="https://www.filfre.net/2020/04/the-7th-guests-new-clothes">Trilobyte of <em>The 7th Guest</em> fame</a>, were never even seriously tempted to move their operation to some more glamorous city than Spokane. For them, it was all about the work. And luckily for them, plenty of people were more than willing to move to Spokane for a chance to work at The House That <em>Myst</em> Built, which by the end of 1995 had replaced Trilobyte as the most feted single games studio in the mainstream American press, the necessary contrast to all those other unscrupulous operators who were <a href="https://www.filfre.net/2021/04/the-ratings-game-part-1-a-likely-and-an-unlikely-suspect">filling their games and the minds of the nation’s youth with indiscriminate sex and violence</a>.</p>
<p>The most important of all the people who were suddenly willing to come to Spokane would prove to be Richard Vander Wende, a former Disney production designer — his fingerprints were all over the recent film <em>Aladdin</em> — who first bumped into the Miller brothers at a Digital World Expo in Los Angeles. Wende’s conceptual contribution to <em>Riven</em> would be as massive as that of either of the Miller brothers, such that he would be given a richly deserved co-equal billing with them at the very top of the credits listing.</p>
<div id="attachment_5920"><p><a href="https://www.filfre.net/2024/05/riven/wende/" rel="attachment wp-att-5920"><img decoding="async" aria-describedby="caption-attachment-5920" src="https://www.filfre.net/wp-content/uploads/2024/05/wende-290x300.jpg" alt="" width="436" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/05/wende-290x300.jpg 290w, https://www.filfre.net/wp-content/uploads/2024/05/wende-768x793.jpg 768w, https://www.filfre.net/wp-content/uploads/2024/05/wende.jpg 825w" sizes="(max-width: 436px) 100vw, 436px"></a></p><p id="caption-attachment-5920">Richard Vander Wende.</p></div>
<p>Needless to say, though, there were many others who contributed as well. By the time Cyan moved into their new world headquarters in the summer of 1996, more than twenty people were actively working on <em>Riven</em> every day. The sequel would wind up costing ten times to fifteen times as much to make as its predecessor, filling five CDs to <em>Myst’</em>s lone silver platter.</p>
<p>Given the Millers’ artistic temperament and given the rare privilege they enjoyed of being able to make exactly the game they wished to make, one might be tempted to assume that <em>Riven</em> was to be some radical departure from what had come before. In reality, though, this was not the case at all. <em>Riven</em> was to be <em>Myst</em>, only more so; call it <em>Myst</em> perfected. Once again you would be left to wander around inside a beautiful pre-rendered 3D environment, which you would view from a first-person perspective. And once again you would be expected to solve intricate puzzles there — or not, as you chose.</p>
<p>Cyan had long since realized that players of <em>Myst</em> broke down into two broad categories. There were those they called the gamers, who engaged seriously with it as a series of logical challenges to be overcome through research, experimentation, and deduction. And then there was the other group of players — a far, far larger one, if we’re being honest — whom Cyan called the tourists, who just wanted to poke around a little inside the virtual world and take in some of the sights and sounds. These were folks like the residents of a retirement home who wrote to Cyan to say that they had been playing and enjoying <em>Myst</em> for two years and two months, and wanted to hear if the rumors that there were locations to explore beyond the first island — an island which constitutes about 20 percent of the full game — were in fact true.</p>
<p><em>Riven</em> was meant to cater to both groups, by giving the gamers a much deeper, richer, more complex tapestry of puzzles to unravel, whilst simultaneously being kept as deliberately “open” as possible in terms of its geography, so that you could see most of its locations without ever having to solve a single conundrum. “The two complaints about <em>Myst</em>,” said Rand Miller, “were that it was too hard and too easy. We’re trying to make <em>Riven</em> better for both kinds of players.” Whereas <em>Myst</em> allowed you to visit four separate “ages” — basically, alternative dimensions — after solving those early puzzles which had so stymied the retirees, <em>Riven</em> was to take place all in the same dimension, on a single archipelago of five islands. You would be able to travel between the islands right from the start, using vehicles whose operation should be quite straightforward even for the most puzzle-averse players. If all you wanted to do was wander around the world of <em>Riven</em>, it would give you a lot more spaces in which to do so than <em>Myst</em>.</p>
<p>Of course, while the world of <em>Riven</em> was slowly coming together, the real world wasn’t sitting still. <em>Myst</em> had been followed by an inevitable flood of “<em>Myst</em> clones” from other publishers and studios, which, in lieu of a proper sequel from Cyan, did their best to pick up the slack by offering up their own deserted, 3D-rendered environments to explore. Few of them were more than modestly successful; <a href="https://www.mobygames.com/game/560/zork-nemesis-the-forbidden-lands/">Activision’s <em>Zork Nemesis</em></a>, which may have done the best of them all, sold about 450,000 copies, an order of magnitude and a half less than the final numbers that <em>Myst</em> would put up. Meanwhile the genre of adventure games in general had peaked in the immediate aftermath of <em>Myst</em> and would be well into an increasingly precipitous decline by the time <em>Riven</em> shipped in October of 1997. <a href="https://www.filfre.net/2023/10/the-last-express"><em>The Last Express</em></a>, the only other adventure that Brøderbund published that year, stiffed badly in the spring, despite sporting prominently on its box the name of <a href="https://www.filfre.net/2016/10/how-jordan-mechner-made-a-different-sort-of-interactive-movie-or-the-virtues-of-restraint">Jordan Mechner</a>, one of the few videogame auteurs with a reputation to rival that of the Miller brothers.</p>
<p>Yet Cyan’s own games still seemed weirdly proof against the marketplace pressures that were driving so many other game makers in the direction of real-time strategy and first-person shooters. In June of 1997, the nearly four-year-old <em>Myst</em> was propelled back to the top of the sales charts by the excitement over the approaching debut of <em>Riven</em>. And when it did appear, <em>Riven</em> didn’t disappoint the bean counters. It and <em>Myst</em> tag-teamed one another in the top two chart positions right through the Christmas buying season. <em>Myst</em> would return to number one a few more times in the course of 1998, while an entire industry continued to scratch its collective head, wondering why this particular game — a game that was now approaching its fifth birthday, making it roughly as aged as the plays of Shakespeare as the industry reckoned time — should continue to sell in such numbers. Even today, it’s hard to say precisely why <em>Myst</em> just kept selling and selling, defying all the usual gravities of its market. It seems that non-violent, non-hardcore gaming simply needed a standard bearer, and so it found one for itself.</p>
<p><em>Riven</em> wasn’t quite as successful as <em>Myst</em>, but this doesn’t mean it didn’t do very well indeed by all of the standard metrics. Its biggest failing in comparison to its older sibling was ironically its very cutting-edge nature; whereas just about any computer that was capable of running other everyday software could run <em>Myst</em> by 1997, you needed a fairly recent, powerful machine to run <em>Riven</em>. Despite this, and despite the usual skepticism from the hardcore-gaming press — “With its familiar, lever-yanking gameplay, <em>Riven</em> emerges as the ultimate <em>Myst</em> clone,” scoffed <em>Computer Gaming World</em> magazine — <em>Riven’</em>s sales surpassed 1 million units in its first year, numbers of which any other adventure game could scarcely have dreamed.<span><a role="button" tabindex="0" onclick="footnote_moveToReference_5916_1('footnote_plugin_reference_5916_1_1');" onkeypress="footnote_moveToReference_5916_1('footnote_plugin_reference_5916_1_1');"><sup id="footnote_plugin_tooltip_5916_1_1">[1]</sup></a><span id="footnote_plugin_tooltip_text_5916_1_1">An article in the May 17 2001 edition of the <em>Los Angeles Times</em> claimed that <em>Riven</em> had sold 4.5 million copies by that point, three and a half years after its release. This number has since been repeated in numerous places, including Wikipedia. I’ll eat my hat if it’s correct; this game would have left a much wider vapor trail behind it if it was. Read in context in the original article, the figure actually comes across as a typo.<p>
<em>Riven</em> was a huge hit by any conventional standard, but it didn’t have the legs of <em>Myst</em>. Already for long stretches during 1998, it was once again being comfortably outsold by <em>Myst</em>. Lifetime retail sales of around 1.5 million strike me as the most likely figure — still more than enough to place <em>Riven</em> in the upper echelon of late 1990s computer games.</p></span></span></p>
<p>Fans and boosters of the genre naturally wanted to see a broader trend in <em>Riven’</em>s sales, a proof that adventures in general could still bring home the bacon with the best of them. The hard truth that the games of Cyan were always uniquely uncoupled from what was going on around them was never harder to accept than in this case. In the end, though, <em>Riven</em> would have no impact whatsoever on the overall trajectory of the adventure genre.</p>
<hr>
<p><a href="https://www.filfre.net/2024/05/riven/5287113-riven-the-sequel-to-myst-windows-front-cover/" rel="attachment wp-att-5925"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2024/05/5287113-riven-the-sequel-to-myst-windows-front-cover-239x300.jpg" alt="" width="359" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/05/5287113-riven-the-sequel-to-myst-windows-front-cover-239x300.jpg 239w, https://www.filfre.net/wp-content/uploads/2024/05/5287113-riven-the-sequel-to-myst-windows-front-cover.jpg 638w" sizes="(max-width: 359px) 100vw, 359px"></a></p>
<p>Because <em>Riven</em> is a sequel in such a pure sense — a game that aims to do exactly what its predecessor did, only bigger and better — your reaction to it is doomed to be dictated to a large extent by your reaction to said predecessor. It’s almost impossible for me to imagine anyone liking or loving <em>Riven</em> who didn’t at least like <em>Myst</em>.</p>
<p>The defining quality of both games is their thoroughgoing sense of restraint. When <em>Myst</em> first started to attract sales and attention, naysayers saw its minimalism through the lens of technical affordance, or rather the Miller brothers’ lack thereof: having only off-the-shelf middleware like <a href="https://www.filfre.net/2016/09/the-freedom-to-associate">HyperCard</a> to work with, lacking the skill set that might have let them create better tools of their own, they just had to do the best they could with what they had. In this reading, <em>Myst</em>‘s static world, its almost nonexistent user interface, its lack of even such niceties as a player inventory, stemmed not so much from aesthetic intent as from the fact that it had been created with a hypertext editor that had never been meant for making games. The alternative reading is that the Miller brothers were among the few game developers who knew the value of restraint from the start, that they were by nature and inclination minimalists in an industry inclined to maximalism in all things, and this quality was their greatest strength rather than a weakness. The truth probably lies somewhere between the two extremes, as it usually does. Regardless, there’s no denying that the brothers leaned hard into the same spirit of minimalism that had defined <em>Myst </em>when the time came to make <em>Riven</em>, even though they were now no longer technologically constrained into doing so. One camp reads this as a colossal failure of vision; the other reads it as merely staying true to the unique vision that had gotten them this far.</p>
<p>While I don’t want to plant myself too firmly in either corner, I must say that I am surprised by some of the things that Cyan <em>didn’t</em> do with twice the time and ten or fifteen times the budget. The fact that <em>Riven</em> still relies on static, pre-rendered scenery and node-based movement isn’t the source of my surprise; that compromise was necessary in order to achieve the visual fidelity that Cyan demanded. I’m rather surprised by how little Cyan innovated even within that basic framework. Well before <em>Riven</em> appeared, the makers of other <em>Myst</em> successors had begun to experiment with ways of creating a slightly more fluid, natural-feeling experience. <em>Zork Nemesis</em>, for example, stores each of its nodes as a 360-degree panorama instead of a set of fixed views, letting you smoothly turn in place through a complete circle. <em>Riven</em>, by contrast, confines its innovations in this area to displaying a little transition animation as you rotate between its rigidly fixed views. As a result, switching from view to view does become a little less jarring than it is in <em>Myst</em>, but the approach is far from even the <em>Myst</em>-clone state of the art.</p>
<p>Cyan was likewise disinterested in pursuing other solutions that would have been even easier to implement than panning rotation, but that could have made their game less awkward to play. The extent of your rotation when you click on the left or right side of the screen remains inconsistent, just as it was in <em>Myst</em>; sometimes it’s 90 degrees, sometimes it’s less or more. This can make simple navigation much more confusing than it needs to be, introducing a layer of fake difficulty — i.e., difficulties that you would <em>not</em> have if you were really <em>in</em> this world — which seems at odd with Cyan’s stated determination to create as immersive an experience as possible. Even a compass with which to tell which way you’re facing at any given time would have helped enormously, but no such concessions to player convenience are to hand.</p>
<p>Again, these are solutions that the other makers of <em>Myst</em> clones — not a group overly celebrated for its spirit of innovation — had long since deployed. Cyan was always a strangely self-contained entity, showing little awareness of what others were doing around them, making a virtue of their complete ignorance of the competition. In cases like these, it was perhaps not so much a virtue as a failure of simple due diligence. Building upon the work of others is the way that gaming as a whole progresses.</p>
<p>When it comes to storytelling as well, <em>Riven’</em>s differences from <em>Myst</em> are more a matter of execution than kind. As in <em>Myst</em>, there is very little story at all here, if by that we mean a foreground plot driving things along. A brief bit of exposition at the beginning picks up right where <em>Myst</em> ended, providing an excuse for dumping you into another open-ended environment. Whereas <em>Myst</em> took place entirely in deserted ages, here you’re ostensibly surrounded by the Rivenese, the vaguely Native-American-like inhabitants of the archipelago. Rather conveniently for Cyan, however, the Rivenese are terrified of strangers, and scurry away into hiding whenever you enter a scene. The few named characters you meet, including the principal villain, are likewise forever just leaving when you come upon them, or showing up, giving speeches, and then going away again before you can interact with them. By 1997, this sort of thing was feeling more tired than clever.</p>
<div id="attachment_5927"><p><a href="https://www.filfre.net/2024/05/riven/riven1/" rel="attachment wp-att-5927"><img decoding="async" aria-describedby="caption-attachment-5927" src="https://www.filfre.net/wp-content/uploads/2024/05/riven1-300x225.jpg" alt="" width="600" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/05/riven1-300x225.jpg 300w, https://www.filfre.net/wp-content/uploads/2024/05/riven1.jpg 640w" sizes="(max-width: 600px) 100vw, 600px"></a></p><p id="caption-attachment-5927">Rand Miller, returning in the role of the patriarch Atrus from <em>Myst</em>, gives you your marching orders and sends you on your way in the introductory movie. <em>Riven</em> makes more extensive use of such scenes involving real actors than <em>Myst</em>, but it’s done well, and never overdone. The end result is about as un-cheesy as these techniques can possibly look to modern eyes.</p></div>
<p>The real story, in both <em>Myst</em> and <em>Riven</em>, is the backstory that caused these spaces to become the places they are, a backstory which you uncover as you explore them. And in this area, I’m happy to say, <em>Riven</em> actually does outdo its predecessor. Almost everything there is to find out about how the ages of <em>Myst</em> became as they are is conveyed in one astonishingly clumsy infodump, a set of books which you find in a library on that first island after solving the first couple of puzzles. These stop your progress dead for an hour or so as you read through them, after which you’re back to exploring, never to be troubled by much of any exposition again.</p>
<p>By the time of <em>Riven</em>, however, the Miller brothers had learned about the existence of something called dramatic pacing. Here, too, most of the real story comes in the form of books and journals, but these are scattered around the islands, providing an enticement to solve puzzles in order to acquire and read them. The <em>Myst</em> “universe” grew considerably in depth and coherency between <em>Myst</em> and <em>Riven</em>, thanks to a trilogy of novels written by the British science-fiction author David Wingrove in close collaboration with the Miller brothers during that interim. In <em>Riven</em>, then, you get some of the same sense that you get in <em>The Lord of the Rings</em>, that you are only scraping the surface of a world that goes much deeper than its foreground sights and sounds. “<em>The Lord of the Rings</em> is so satisfying because of the details,” said Rand Miller at the time. “You get the feeling that the world you’re reading about is real. Different but real. That’s how we go about designing.” Like Tolkien, the Miller brothers went so far as to make up the beginnings at least of a coherent language for their land’s inhabitants. This sense of established lore, combined with the improved pacing and better writing, makes <em>Riven’</em>s backstory more compelling than that of <em>Myst</em>, makes uncovering more of it feel like a worthwhile goal in itself. Instead of providing a mere excuse for the gameplay, as in <em>Myst</em>, <em>Riven’</em>s backstory comes to fuel its gameplay to a large extent.</p>
<p>And this starts to take us into the territory of the first of the two things that <em>Riven</em> does really, really well, does so well in fact that you might just be willing to discount all of the failings I’ve been belaboring up to this point. The archipelago is a truly intriguing, even awe-inspiring place to explore, thank not just to the cutting-edge 3D-rendering technology that was used to bring it to life, but — and even more so — the <em>thought</em> that went into the place.</p>
<div id="attachment_5926"><p><a href="https://www.filfre.net/2024/05/riven/riven0/" rel="attachment wp-att-5926"><img decoding="async" aria-describedby="caption-attachment-5926" src="https://www.filfre.net/wp-content/uploads/2024/05/riven0-300x225.jpg" alt="" width="600" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/05/riven0-300x225.jpg 300w, https://www.filfre.net/wp-content/uploads/2024/05/riven0.jpg 640w" sizes="(max-width: 600px) 100vw, 600px"></a></p><p id="caption-attachment-5926"><em>Riven</em> makes its priorities clear from the beginning, when it asks you to set up your screen and your speakers to provide the immersive audiovisual experience it intends for you to have.</p></div>
<p>The adjective “surreal” seems unavoidable when discussing <em>Myst</em>, so much so that Brøderbund built it right into their advertising tagline. (“The Surrealistic Adventure That Will Become Your World.”) Looking back on it now, though, I realize that the surrealism of <em>Myst</em> was as much a product of process as intention. The 3D-modeling software that was used to create the scenery of <em>Myst</em> couldn’t render genuinely realistic scenes; everything it churned out was too geometrical, too stiff, too uniform in color to look in any sense <em>real</em>. The result was surrealism, that forlorn, otherworldly, even vaguely disturbing stripe of beauty that became the hallmark of <em>Myst</em> and its many imitators.</p>
<p>But I would not call <em>Riven</em> surreal. The improved technology that enabled it, on both the rendering side — meaning all those Silicon Graphics servers and workstations, with their complex ray-tracing algorithms — and the consumer-facing side — meaning the latest home computers, with their capability of displaying millions of nuanced shades of color onscreen at once — led to a more believable world. The key to it all is in the textures, the patterns that are overlaid onto the frame of a 3D model in lieu of blocks of solid color to make it look like a real object made out of wood, metal, or dirt. Cyan traveled to Santa Fe, New Mexico, to capture thousands of textures. The same visual qualities that led to that state being dubbed the “Land of Enchantment” and drew artists like Georgia O’Keeffe to its high deserts suffuses the game, from the pueblo walls of the Rivenese homes to the pebbly cliff-side paths, from <a href="https://www.filfre.net/2015/02/t-plus-0-the-fulcrum-of-history">an old iron tower rusting in the sun</a> to the ragged vegetation huddling around it. You can almost feel the sun on your back and the sweat on your skin.</p>
<p>My wife and I are inveterate hikers these days, planning most of our holidays around where we can get out and walk. <em>Riven</em> made me want to climb through the screen and roam its landscapes for myself. <em>Myst</em> has its charms, but they are nothing like this. When I compare the two games, I think about what a revelation the battered, weathered world of Tatooine was when <em>Star Wars</em> hit cinemas in 1977, how at odds it was with the antiseptic sleekness of the science-fiction films that preceded it. <em>Riven</em> is almost as much of a revelation when set beside <em>Myst</em> and its many clones.</p>
<hr>
<p><a href="https://www.filfre.net/2024/05/riven/riven7/" rel="attachment wp-att-5935"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2024/05/riven7-300x225.jpg" alt="" width="600" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/05/riven7-300x225.jpg 300w, https://www.filfre.net/wp-content/uploads/2024/05/riven7.jpg 640w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p><a href="https://www.filfre.net/2024/05/riven/riven5-2/" rel="attachment wp-att-5936"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2024/05/riven5-1-300x225.jpg" alt="" width="600" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/05/riven5-1-300x225.jpg 300w, https://www.filfre.net/wp-content/uploads/2024/05/riven5-1.jpg 640w" sizes="(max-width: 600px) 100vw, 600px"></a><a href="https://www.filfre.net/2024/05/riven/riven8/" rel="attachment wp-att-5937"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2024/05/riven8-300x225.jpg" alt="" width="600" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/05/riven8-300x225.jpg 300w, https://www.filfre.net/wp-content/uploads/2024/05/riven8.jpg 640w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<hr>

<p>The visuals both feed and are fed by the backstory and the world-building. The islands are replete with little details that have nothing to do with solving the game, that exist simply as natural, necessary parts of this place you’re exploring. In <a href="https://www.youtube.com/watch?v=aa-JMzTBH00&amp;t=2s">a perceptive video essay</a>, YouTube creator VZedshows notes how “the lived-in world of <em>Riven</em> lets us look at a house and say, ‘Okay, that’s a house.’ And that’s it. A totally different thought than seeing a log cabin on Myst Island and saying, ‘Okay, that’s a house. But what is it <em>for</em>?’ The puzzles in <em>Riven</em> melt into the world around them.”</p>
<p>Which brings us neatly to the other thing that <em>Riven</em> does remarkably well, the one aimed at the gamers rather than the tourists. Quite simply, <em>Riven</em> is one of the most elegantly sophisticated puzzle games ever created. This facet of it is not for everyone. (I’m not even sure it’s for me, about which more in a moment.) But it does what it sets out to do uncompromisingly well. <em>Riven</em> is a puzzle game that doesn’t feel like a puzzle game. It rather feels like you really have been dropped onto this archipelago, with its foreign civilization and all of its foreign artifacts, and then left to your own devices to make sense of it all.</p>
<div id="attachment_5929"><p><a href="https://www.filfre.net/2024/05/riven/riven3/" rel="attachment wp-att-5929"><img decoding="async" aria-describedby="caption-attachment-5929" src="https://www.filfre.net/wp-content/uploads/2024/05/riven3-300x225.jpg" alt="" width="600" height="450" srcset="https://www.filfre.net/wp-content/uploads/2024/05/riven3-300x225.jpg 300w, https://www.filfre.net/wp-content/uploads/2024/05/riven3.jpg 640w" sizes="(max-width: 600px) 100vw, 600px"></a></p><p id="caption-attachment-5929">Many of <em>Riven’</em>s puzzles are as much anthropological as mechanical. For example, you have to learn to translate the different symbols of a foreign number system.</p></div>
<p>This is undoubtedly more realistic than the ages of <em>Myst</em>, whose puzzles stand out from their environs so plainly that they might as well be circled with a bright red Sharpie. But does it lead to a better game? As usual, the answer is in the eye of the beholder. Ironically, almost everything that can be said about <em>Riven’</em>s puzzles can be cast as either a positive or a negative. If you’re looking for an adventure game that’s nails-hard and yet scrupulously fair — a combination that’s rarer than it ought to be — <em>Riven</em> will not disappoint you. If not, however, it will put you right off just as soon as you grow bored with idle wandering and begin to ask yourself what the game expects you to actually be <em>doing</em>. <em>Myst</em> was widely perceived in the 1990s as being more difficult than it really was; <em>Riven</em>, by contrast, well and truly earns its reputation.</p>
<p>Each of <em>Myst’</em>s ages is a little game unto itself when it comes to its puzzles; you never need to use tools or information from one age to overcome a problem in another one. For better or for worse, <em>Riven</em> is not like that — not at all. Puzzles and clues are scattered willy-nilly all over the five islands; you might be expected to connect a symbol you’re looking at now to a gadget you last poked at hours and hours ago. Careful, copious note-taking is the only practical way to proceed. I daresay you might end up spending more time poring over your real-world journal, looking for ways to combine and thereby to make sense of the data therein, than you do looking at the monitor screen. Because most of the geography is open to you from the very beginning — this is arguably <em>Riven’</em>s one real concession to the needs of the marketplace, being the one that allows it to cater to the tourists as well as the gamers — there isn’t the gated progress you get in so many other puzzly adventure games, with new areas and new problems being introduced gradually as you solve the earlier ones. No, <em>Riven</em> throws it all at you from the start, in one big lump. You just have to keep plugging away at it when even your apparently successful deductions don’t seem to be yielding much in the way of concrete rewards, trusting that it will all come together in one big whoosh at the end.</p>
<p>All of which is to say that <em>Riven</em> is a <em>slow</em> game, the polar opposite of the instant gratification that defines the videogame medium in the eyes of so many. There are few shortcuts for moving through its sprawling, fragmented geography — something you’ll need to do a lot of, thanks to its refusal to contain its puzzles within smaller areas as <em>Myst</em> does. Just double-checking some observation you think you made earlier or confirming that some effect took place as expected represents a significant investment in time. Back in the day, when everyone was playing directly from CD, <em>Riven</em> was even slower than it is today, requiring you to swap discs every time you traveled to a different island.<span><a role="button" tabindex="0" onclick="footnote_moveToReference_5916_1('footnote_plugin_reference_5916_1_2');" onkeypress="footnote_moveToReference_5916_1('footnote_plugin_reference_5916_1_2');"><sup id="footnote_plugin_tooltip_5916_1_2">[2]</sup></a><span id="footnote_plugin_tooltip_text_5916_1_2">Some months after its original release, <em>Riven</em> became one of the first games ever to be made available on DVD-ROM. No game benefited more from the switch in storage technology; not only were DVD drives faster than CD drives, but a single DVD disc was capacious enough to contain the whole of <em>Riven</em>.</span></span> In <a href="https://eblong.com/zarf/gamerev/riven.html">his vintage 1997 review</a>, Andrew Plotkin — a fellow who is without a doubt much, much smarter than I am, at least when it comes to stuff like this — said that he was able to solve <em>Riven</em> in about twenty hours, using just one hint. It will probably take more mortal intelligences some multiple of one or both of those figures.</p>
<p>Your reaction to <em>Riven</em> when approached in “gamer” mode will depend on whether you think this kind of intensive intellectual challenge is fun or not, as well as whether you have the excess intellectual and temporal bandwidth in your current life to go all-in on such a major undertaking. I must sheepishly confess that my answer to the first question is more prevaricating than definitive, while my answer to the second one is a pretty solid no. In the abstract, I do understand the appeal of what <em>Riven</em> is offering, understand how <em>awesome</em> it must feel to put all of these disparate pieces together without help. Nevertheless, when I approached the game for this article, I couldn’t quite find the motivation to persevere down that road. <em>Riven</em> wants you to work a little harder for your fun than the current version of myself is willing to do. I don’t futz around with my notebook too long before I start looking out the window and thinking about how nice it would be to take a walk in <em>real</em> nature. I take enough notes doing research for the articles I write; I’m not sure I want to do so much research <em>inside</em> a game.</p>
<p>Prompted partially by my experience with <em>Riven</em>, I’ve been musing a fair amount lately about the way we receive games, and especially how the commentary you read on this site and others similar to it can be out of step with the way the games in question existed for their players in their heyday. I’m subject to the tyranny of my editorial calendar, to the need to just <em>finish</em> things, one way or another, and move on. <em>Riven</em> is not well-suited to such a mindset. In my travels around the Internet, I’ve noticed that those who remember the game most fondly often took months or years to finish it, or never finished it at all. It existed for them as a tempting curiosity, to be picked up from time to time and poked at, just to see if a little more progress was possible here or there, or whether the brainstorm that came to them unbidden while driving home from work that day might bear some sort of fruit. It’s an open question whether even folks who don’t have an editorial schedule to keep can recapture that mindset here and now, in the third decade (!) of the 21st century, when more entertainment of every conceivable type than any of us could possibly consume in a lifetime is constantly luring us away from any such hard nut as <em>Riven</em>. As of this writing, Cyan is preparing a remake of <em>Riven</em>. It will be interesting to see what concessions, if any, they chose to make to our new reality.</p>
<p>Even in the late 1990s, there was the palpable sense that <em>Riven</em> represented the end of an era, that even Cyan would not be able to catch lightning in a bottle a third time with yet another cerebral, contemplative, zeitgeist-stamping single-player puzzle game. Both Richard Vander Wende and Robyn Miller quit the company as soon as the obligatory rounds of promotional interviews had been completed, leaving the <em>Myst</em> franchise’s future solely in the hands of Rand Miller. Robyn’s stated reason for departing brings to the fore some of the frustrations I have with Cyan’s work. He said that he was most interested in telling stories, and had concluded that computer games just weren’t any good at that: “I felt like, you know what? It’s not working. This whole story thing is not happening, and one of the reasons it’s not happening is because of the medium. It’s not what this medium is good at.” So, he said, he wanted to work in film instead.</p>
<p>The obvious response is that Cyan had never actually tried to tell an engaging foreground story, had rather been content to leave you always picking up the breadcrumbs of backstory. Cyan’s stubborn conservatism in terms of form and their slightly snooty insistence on living in their own hermetically sealed bubble, blissfully unaware of the innovations going on around them in their industry in both storytelling and other aspects of game making, strike me as this unquestionably talented group’s least attractive qualities by far. When asked once what his favorite games were, Richard Vander Wende said he didn’t have any: “Robyn and I are not really interested in games of any kind. We’re more interested in building worlds. To us, <em>Myst</em> and <em>Riven</em> are not ‘games’ at all.” Such scare-quoted condescension does no one any favors.</p>
<p>Then again, that’s only one way of looking at it. Another way is to recognize that <em>Riven</em> is exactly the game — okay, if you like, the world — that its creators wanted to make. It’s worth acknowledging, even celebrating, as the brave artistic statement it is. Love it or hate it, <em>Riven</em> knows what it wants to be, and succeeds in being exactly that — no more, no less. Rather than <em>The Lord of the Rings</em>, call it the <a href="https://www.goodreads.com/book/show/338798.Ulysses"><em>Ulysses</em></a> of gaming: a daunting creation by any standard, but one that can be very rewarding to those willing and able to meet it where it lives. That a game like this outsold dozens of its more visceral, immediate rivals on the store shelves of the late 1990s is surely one of the wonders of the age.</p>
<hr>
<p><code> </code><br>
<strong>Did you enjoy this article? If so, please think about pitching in to help me make many more like it. You can pledge any amount you like.</strong></p>
<p><a href="https://www.patreon.com/DigitalAntiquarian" rel="attachment wp-att-5598"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2023/04/Patreon-300x133-1.png" alt="" width="300" height="133"></a></p>
<hr>

<p><strong>Sources:</strong> The books <em>The Secret History of Mac Gaming</em> (Expanded Edition) by Richard Moss, <em>From Myst to Riven: The Creations &amp; Inspirations</em> by Richard Kadrey, and <em>Riven: The Sequel to Myst: The Official Strategy Guide</em> by Rick Barba; <em>Computer Gaming World</em> of January 1998; <em>Retro Gamer</em> 208; <em>Wired</em> of September 1997; <em>Game Developer</em> of March 1998. Plus the “making of” documentary that was included on the original <em>Riven</em> CDs. The sales figures for <em>Zork Nemesis</em> come from the Jordan Mechner archive at the <a href="https://www.museumofplay.org/">Strong Museum of Play</a>.</p>
<p>Online sources include&nbsp;<a href="https://web.archive.org/web/20060515224603/http://www.gamespot.com/features/riven/"><em>GameSpot’</em>s old preview</a> of <em>Riven</em>, <a href="https://web.archive.org/web/20010913083729/http://images.salon.com/21st/feature/1998/03/02feature.html"><em>Salon’</em>s profile of the Miller brothers</a> on the occasion of Robyn’s departure from Cyan, <a href="https://www.youtube.com/watch?v=aa-JMzTBH00&amp;t=2s">VZedshows’s video essay</a> on <em>Myst</em> and <em>Riven</em>, and <a href="https://eblong.com/zarf/gamerev/riven.html">Andrew Plotkin’s old review</a> of <em>Riven</em>.</p>
<p>The original version of <em>Riven</em> is currently <a href="https://www.gog.com/en/game/riven_the_sequel_to_myst">available as a digital purchase on GOG.com</a>. As noted in the article above, a remake is in the works at Cyan.</p>
							
							
														
													</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is artificial consciousness achievable? Lessons from the human brain (181 pts)]]></title>
            <link>https://arxiv.org/abs/2405.04540</link>
            <guid>40403962</guid>
            <pubDate>Sun, 19 May 2024 03:18:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2405.04540">https://arxiv.org/abs/2405.04540</a>, See on <a href="https://news.ycombinator.com/item?id=40403962">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2405.04540">View PDF</a></p><blockquote>
            <span>Abstract:</span>We here analyse the question of developing artificial consciousness from an evolutionary perspective, taking the evolution of the human brain and its relation with consciousness as a reference model. This kind of analysis reveals several structural and functional features of the human brain that appear to be key for reaching human-like complex conscious experience and that current research on Artificial Intelligence (AI) should take into account in its attempt to develop systems capable of conscious processing. We argue that, even if AI is limited in its ability to emulate human consciousness for both intrinsic (structural and architectural) and extrinsic (related to the current stage of scientific and technological knowledge) reasons, taking inspiration from those characteristics of the brain that make conscious processing possible and/or modulate it, is a potentially promising strategy towards developing conscious AI. Also, it is theoretically possible that AI research can develop partial or potentially alternative forms of consciousness that is qualitatively different from the human, and that may be either more or less sophisticated depending on the perspectives. Therefore, we recommend neuroscience-inspired caution in talking about artificial consciousness: since the use of the same word consciousness for humans and AI becomes ambiguous and potentially misleading, we propose to clearly specify what is common and what differs in AI conscious processing from full human conscious experience.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Michele Farisco [<a href="https://arxiv.org/show-email/9efab11f/2405.04540">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 18 Apr 2024 12:59:44 UTC (1,337 KB)<br>
</p></div></div>]]></description>
        </item>
    </channel>
</rss>