<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 11 Dec 2025 04:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Apple Services Experiencing Outage (114 pts)]]></title>
            <link>https://www.apple.com/support/systemstatus/</link>
            <guid>46223577</guid>
            <pubDate>Wed, 10 Dec 2025 20:47:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/support/systemstatus/">https://www.apple.com/support/systemstatus/</a>, See on <a href="https://news.ycombinator.com/item?id=46223577">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ac-globalfooter" lang="en-US" data-analytics-region="global footer" role="contentinfo" aria-labelledby="ac-gf-label">
		        <h2 id="ac-gf-label">Apple Footer</h2>
		        <nav aria-label="Breadcrumbs" role="navigation">
		            <a href="https://www.apple.com/">
		                
		                <span>Apple</span>
		                <span></span>
		                <span></span>
		            </a>
		            <div>
		                <ol vocab="http://schema.org/" typeof="BreadcrumbList">
		                    <li property="itemListElement" typeof="ListItem">
		                        <span property="name">System Status</span>
		                        <meta property="position" content="1">
		                    </li>
		                </ol>
		            </div>
		        </nav>
		        <section>
					<div x-ms-format-detection="none"><p>
						More ways to shop: <a href="https://www.apple.com/retail/" onclick="sendAnalytics(this), trackFooterLinkClick(this)" data-analytics-title="find an apple store">Find an Apple Store</a> or <a href="https://locate.apple.com/" onclick="sendAnalytics(this), trackFooterLinkClick(this)" data-analytics-title="other retailers or resellers" data-analytics-exit-link="">other retailer</a> near you. <span>Or call 1-800-MY-APPLE.</span>
					</p></div>
					<div>
						<p><a href="https://www.apple.com/choose-country-region/" title="Choose your country or region" aria-label="United States. Choose your country or region" onclick="sendAnalyticsInnerHtml(this), trackCountrySelectorLinkClick(this)" data-analytics-title="choose your country">United States</a>
					</p></div>
					<div>
						<p>Copyright ¬©
							<span id="footer_msg_year"></span> Apple Inc. All rights reserved.</p>
						<div>
							<p><a href="https://www.apple.com/legal/privacy/" onclick="sendAnalytics(this), trackFooterSuperLinkClick(this)" data-analytics-title="privacy policy">Privacy Policy</a>
							<a href="https://www.apple.com/legal/internet-services/terms/site.html" onclick="sendAnalytics(this), trackFooterSuperLinkClick(this)" data-analytics-title="terms of use">Terms of Use</a>
							<a href="https://www.apple.com/us/shop/goto/help/sales_refunds" onclick="sendAnalytics(this), trackFooterSuperLinkClick(this)" data-analytics-title="sales and refunds">Sales and Refunds</a>
							<a href="https://www.apple.com/legal/" onclick="sendAnalytics(this), trackFooterSuperLinkClick(this)" data-analytics-title="legal">Legal</a>
							<a href="https://www.apple.com/sitemap/" onclick="sendAnalytics(this), trackFooterSuperLinkClick(this)" data-analytics-title="site map">Site Map</a>
						</p></div>
					</div>
				</section>				
		    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Getting a Gemini API key is an exercise in frustration (334 pts)]]></title>
            <link>https://ankursethi.com/blog/gemini-api-key-frustration/</link>
            <guid>46223311</guid>
            <pubDate>Wed, 10 Dec 2025 20:29:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ankursethi.com/blog/gemini-api-key-frustration/">https://ankursethi.com/blog/gemini-api-key-frustration/</a>, See on <a href="https://news.ycombinator.com/item?id=46223311">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <article>   <section>  <p>Last week, I started working on a new side-project. It‚Äôs a standard React app partly made up of run-of-the-mill CRUD views‚Äîa perfect fit for LLM-assisted programming. I reasoned that if I could get an LLM to quickly write the boring code for me, I‚Äôd have more time to focus on the interesting problems I wanted to solve.</p>
<p>I‚Äôve pretty much settled on Claude Code as my coding assistant of choice, but I‚Äôd been hearing great things about Google‚Äôs Gemini 3 Pro. Despite my aversion to Google products, I decided to try it out on my new codebase.</p>
<p>I already had <a href="https://github.com/google-gemini/gemini-cli">Gemini CLI</a> installed, but that only gave me access to Gemini 2.5 with rate limits. I wanted to try out Gemini 3 Pro, and I wanted to avoid being rate limited. I had some spare cash to burn on this experiment, so I went looking for ways to pay for a Gemini Pro plan, if such a thing existed.</p>
<p>Thus began my grand adventure in trying to give Google my money.</p>
<h2 id="what-is-a-gemini-really">What is a Gemini, really?</h2>
<p>The name ‚ÄúGemini‚Äù is so overloaded that it barely means anything. Based on the context, Gemini could refer to:</p>
<ul>
<li>The chatbot available at <a href="https://gemini.google.com/">gemini.google.com</a>.</li>
<li>The mobile app that lets you use the same Gemini chatbot on your <a href="https://apps.apple.com/us/app/google-gemini/id6477489729">iPhone</a> or <a href="https://play.google.com/store/apps/details?id=com.google.android.apps.bard&amp;hl=en_US">Android</a>.</li>
<li>The <a href="https://gemini.google/us/assistant/">voice assistant</a> on Android phones.</li>
<li>The AI features <a href="https://workspace.google.com/resources/ai/">built into Google Workspace</a>, Firebase, Colab, BigQuery, and other Google products.</li>
<li>Gemini CLI, an agentic coding tool for your terminal that works the same way as Claude Code or OpenAI Codex.</li>
<li>The <a href="https://codeassist.google/">Gemini Code Assist</a> suite of products, which includes extensions for various IDEs, a GitHub app, and Gemini CLI.</li>
<li>The <a href="https://en.wikipedia.org/wiki/Gemini_(language_model)">underlying LLM</a> powering all these products.</li>
<li>Probably three more products by the time I finish writing this blog post.</li>
</ul>
<p>To make things even more confusing, Google has at least three different products just for agentic coding: Gemini Code Assist (Gemini CLI is a part of this suite of products), <a href="https://jules.google/">Jules</a>, and <a href="https://antigravity.google/">Antigravity</a>.</p>
<p>And then there‚Äôs a bunch of other GenAI stuff that is powered by Gemini but doesn‚Äôt have the word Gemini in the name: <a href="https://cloud.google.com/vertex-ai?hl=en">Vertex AI Platform</a>, <a href="https://aistudio.google.com/api-keys">Google AI Studio</a>, <a href="https://notebooklm.google/">NotebookLM</a>, and who knows what else.</p>
<p>I just wanted to plug my credit card information into a form and get access to a coding assistant. Instead, I was dunked into an alphabet soup of products that all seemed to do similar things and, crucially, didn‚Äôt have any giant ‚ÄúBuy Now!‚Äù buttons for me to click.</p>
<p>In contrast, both Anthropic and OpenAI have two primary ways you can access their products: via their consumer offerings at <a href="https://claude.ai/">claude.ai</a> and <a href="https://chatgpt.com/">chatgpt.com</a> respectively, or via API credits that you can buy through their respective <a href="https://platform.claude.com/">developer</a> <a href="https://platform.openai.com/">consoles</a>. In each case, there is a form field where you can plug in your credit card details, and a big, friendly ‚ÄúBuy Now!‚Äù button to click.</p>
<p>After half an hour of searching the web, I did the obvious thing and asked the free version of Gemini (the chatbot, not one of those other Geminis) what to do:</p>
<blockquote>
<p>How do I pay for the pro version of Gemini so i can use it in the terminal for writing code? I specifically want to use the Gemini 3 Pro model.</p>
</blockquote>
<p>It thought for a suspiciously long time and told me that Gemini 3 Pro required a developer API key to use. Since the new model is still in preview, it‚Äôs not yet available on any of the consumer plans. When I asked follow up questions about pricing, it told me that ‚ÄúSomething went wrong‚Äù. Which translates to: we broke something, but we won‚Äôt tell you how to fix it.</p>
<p>So I asked Claude for help. Between the two LLMs, I was able to figure out how to create an API key for the Gemini I wanted.</p>
<h2 id="creating-an-api-key-is-easy">Creating an API key is easy</h2>
<p>Google AI Studio is supposed to be the all-in-one dashboard for Google‚Äôs generative AI models. This is where you can experiment with model parameters, manage API keys, view logs, and manage billing for your projects.</p>
<p>I logged into Google AI Studio and <a href="https://aistudio.google.com/api-keys">created a new API key</a>. This part was pretty straightforward: I followed the on-screen instructions and had a fresh new key housed under a project in a few seconds. I then verified that my key was working with Gemini CLI.</p>
<p>It worked! Now all that was left to do was to purchase some API credits. Back in Google AI Studio, I saw a link titled ‚ÄúSet up billing‚Äù next to my key. It looked promising, so I clicked it.</p>
<p>That‚Äôs where the fun <em>really</em> began.</p>
<h2 id="google-doesnt-want-my-money">Google doesn‚Äôt want my money</h2>
<p>The ‚ÄúSet up billing‚Äù link kicked me out of Google AI Studio and into Google Cloud Console, and my heart sank. Every time I‚Äôve logged into Google Cloud Console or AWS, I‚Äôve wasted hours upon hours reading outdated documentation, gazing in despair at graphs that make no sense, going around in circles from dashboard to dashboard, and feeling a strong desire to attain freedom from this mortal coil.</p>
<p>Turns out I can‚Äôt just put $100 into my Gemini account. Instead, I must first create a Billing Account. After I‚Äôve done that, I must associate it with a project. <em>Then</em> I‚Äôm allowed to add a payment method to the Billing Account. And <em>then</em>, if I‚Äôm lucky, my API key will turn into a paid API key with Gemini Pro privileges.</p>
<p>So I did the thing. The whole song and dance. Including the mandatory two-factor OTP verification that every Indian credit card requires. At the end of the process, I was greeted with a popup telling me I had to verify my payment method before I‚Äôd be allowed to use it.</p>
<p>Wait. Didn‚Äôt I <em>just</em> verify my payment method? When I entered the OTP from my bank?</p>
<p>Nope, turns out Google hungers for more data. Who‚Äôd have thunk it?</p>
<p>To verify my payment method <em>for reals</em>, I had to send Google a picture of my government-issued ID and the credit card I‚Äôd just associated with my Billing Account. I had to ensure all the numbers on my credit card were redacted by manually placing black bars on top of them in an image editor, leaving only my name and the last four digits of the credit card number visible.</p>
<p>This felt unnecessarily intrusive. But by this point, I was too deep in the process to quit. I was invested. I needed my Gemini 3 Pro, and I was willing to pay any price.</p>
<p>The upload form for the government ID rejected my upload twice before it finally accepted it. It was the same exact ID every single time, just in different file formats. It wanted a PNG file. Not a JPG file, nor a PDF file, but a PNG file. Did the upload form mention that in the instructions? Of course not.</p>
<p>After jumping through all these hoops, I received an email from Google telling me that my verification will be completed in a few days.</p>
<p>A <em>few days</em>? Nothing to do but wait, I suppose.</p>
<h2 id="403-forbidden">403 Forbidden</h2>
<p>At this point, I closed all my open Cloud Console tabs and went back to work. But when I was fifteen minutes into writing some code by hand like a Neanderthal, I received a second email from Google telling me that my verification was complete.</p>
<p>So for the tenth time that day, I navigated to AI Studio. For the tenth time I clicked ‚ÄúSet up billing‚Äù on the page listing my API keys. For the tenth time I was told that my project wasn‚Äôt associated with a billing account. For the tenth time I associated the project with my new billing account. And finally, after doing all of this, the ‚ÄúQuota tier‚Äù column on the page listing my API keys said ‚ÄúTier 1‚Äù instead of ‚ÄúSet up billing‚Äù.</p>
<p>Wait, Tier 1? Did that mean there were other tiers? What were tiers, anyway? Was I already on the best tier? Or maybe I was on the worst one? Not important. The important part was that I had my API key and I‚Äôd managed to convince Google to charge me for it.</p>
<p>I went back to the Gemini CLI, ran the <code>/settings</code> command, and turned on the ‚ÄúEnable experimental features‚Äù option. I ran the <code>/models</code> command, which told me that Gemini 3 Pro was now available.</p>
<p>Success? Not yet.</p>
<p>When I tried sending a message to the LLM, it failed with this 403 error:</p>
<pre tabindex="0" data-language="json"><code><span><span>{</span></span>
<span><span>  "error"</span><span>: {</span></span>
<span><span>    "message"</span><span>: </span><span>"{</span><span>\n</span><span>  \"</span><span>error</span><span>\"</span><span>: {</span><span>\n</span><span>    \"</span><span>code</span><span>\"</span><span>: 403,</span><span>\n</span><span>    \"</span><span>message</span><span>\"</span><span>: </span><span>\"</span><span>The caller does not have permission</span><span>\"</span><span>,</span><span>\n</span><span>    \"</span><span>status</span><span>\"</span><span>:</span><span>\"</span><span>PERMISSION_DENIED</span><span>\"\n</span><span>  }</span><span>\n</span><span>}</span><span>\n</span><span>"</span><span>,</span></span>
<span><span>    "code"</span><span>: </span><span>403</span><span>,</span></span>
<span><span>    "status"</span><span>: </span><span>"Forbidden"</span></span>
<span><span>  }</span></span>
<span><span>}</span></span></code></pre>
<p>Is that JSON inside a string inside JSON? Yes. Yes it is.</p>
<p>To figure out if my key was even working, I tried calling the Gemini API from JavaScript, reproducing the basic example from <a href="https://ai.google.dev/gemini-api/docs#javascript">Google‚Äôs own documentation</a>.</p>
<p>No dice. I ran into the exact same error.</p>
<p>I then tried talking to Gemini 3 Pro using the <a href="https://aistudio.google.com/prompts/new_chat">Playground</a> inside Google AI Studio. It showed me a toast message saying <code>Failed to generate content. Please try again.</code> The chat transcript said <code>An internal error has occurred.</code></p>
<p>At this point I gave up and walked away from my computer. It was already 8pm. I‚Äôd been trying to get things to work since 5pm. I needed to eat dinner, play <em>Clair Obscur</em>, and go to bed. I had no more time to waste and no more fucks to give.</p>
<h2 id="your-account-is-in-good-standing-at-this-time">Your account is in good standing at this time</h2>
<p>Just as I was getting into bed, I received an email from Google with this subject line:</p>
<blockquote>
<p>Your Google Cloud and APIs billing account XXXXXX-XXXXXX-XXXXXX is in good standing at this time.</p>
</blockquote>
<p>With the message inside saying:</p>
<blockquote>
<p>Based on the information you provided and further analysis by Google, we have reinstated your billing account XXXXXX-XXXXXX-XXXXXX. Your account is in good standing, and you should now have full access to your account and related Project(s) and Service(s).</p>
</blockquote>
<p>I have no idea what any of this means, but Gemini 3 Pro started working correctly after I received this email. It worked in the Playground, directly by calling the API from JavaScript, and with Gemini CLI.</p>
<p>Problem solved, I guess. Until Google mysteriously decides that my account is no longer in good standing.</p>
<h2 id="this-was-a-waste-of-time">This was a waste of time</h2>
<p>This was such a frustrating experience that I still haven‚Äôt tried using Gemini with my new codebase, nearly a week after I made all those sacrifices to the Gods of Billing Account.</p>
<p>I understand why the process for getting a Gemini API key is so convoluted. It‚Äôs designed for large organizations, not an individual developers trying to get work done; it serves the bureaucracy, not the people doing the work; it‚Äôs designed for maximum compliance with government regulations, not for efficiency or productivity.</p>
<p>Google doesn‚Äôt want my money unless I‚Äôm an organization that employs ten thousand people.</p>
<p>In contrast to Google, Anthropic and OpenAI are much smaller and much more nimble. They‚Äôre able to make the process of setting up a developer account quick and easy for those of us who just want to get things done. Unlike Google, they haven‚Äôt yet become complacent. They need to compete for developer mindshare if they are to survive a decade into the future. Maybe they‚Äôll add the same level of bureaucracy to their processes as they become larger, but for now they‚Äôre fairly easy to deal with.</p>
<p>I‚Äôm still going to try using Gemini 3 Pro with Gemini CLI as my coding assistant, but I‚Äôll probably cap the experiment to a month. Unless Gemini 3 Pro is a massive improvement over its competitors, I‚Äôll stick to using tools built by organizations that want me as a customer.</p>  </section>   </article>    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I got an Nvidia GH200 server for ‚Ç¨7.5k on Reddit and converted it to a desktop (244 pts)]]></title>
            <link>https://dnhkng.github.io/posts/hopper/</link>
            <guid>46222237</guid>
            <pubDate>Wed, 10 Dec 2025 19:19:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dnhkng.github.io/posts/hopper/">https://dnhkng.github.io/posts/hopper/</a>, See on <a href="https://news.ycombinator.com/item?id=46222237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://dnhkng.github.io/assets/img/main.jpg"><img src="https://dnhkng.github.io/assets/img/main.jpg" alt="Grace Hopper Desktop" loading="lazy"></a></p><h2 id="introduction"><span>Introduction</span><a href="#introduction"><i></i></a></h2><p>Running large language models locally has always been a game of compromise. You either spend \$10,000+ on consumer GPUs that can barely handle 70 B parameter models, or you dream about enterprise hardware you‚Äôll never afford. The Grace-Hopper platform‚ÄîNvidia‚Äôs unified CPU-GPU superchip architecture‚Äîrepresents the kind of dream-rig AI infrastructure LocalLlama drools over, with systems typically costing well over \$100,000 and exclusively available to data centers and research institutions.</p><p>So when I stumbled across a Grace-Hopper system being sold for 10K euro on Reddit, my first thought was ‚Äúobviously fake.‚Äù My second thought was ‚ÄúI wonder if he‚Äôll take 7.5K euro?‚Äù.</p><p>This is the story of how I bought enterprise-grade AI hardware designed for liquid-cooled server racks, converted it to air cooling, survived multiple near-disasters (including GPUs reporting temperatures of 16 million degrees), and ended up with a desktop that can run 235B parameter models at home. It‚Äôs a tale of questionable decisions, creative problem-solving, and what happens when you try to turn datacenter equipment into a daily driver.</p><p>If you‚Äôve ever wondered what it takes to run truly large models locally, or if you‚Äôre just here to watch someone disassemble $80,000 worth of hardware with nothing but hope and isopropanol, you‚Äôre in the right place.</p><h2 id="the-deal"><span>The Deal</span><a href="#the-deal"><i></i></a></h2><p>Early this year, while browsing r/LocalLLaMA/new, I came across a <a href="https://www.reddit.com/r/LocalLLaMA/comments/1m65iga/frankenserver_for_sale_at_a_steep_discount_2x96gb/"><em>ridiculously good deal</em></a>. How good? These were the specs for the server offered for 10K euro, and a serious upgrade to my 4x RTX 4090 rig:</p><h3 id="specs"><span>Specs:</span><a href="#specs"><i></i></a></h3><ul><li>2x Nvidia Grace-Hopper Superchip</li><li>2x 72-core Nvidia Grace CPU</li><li>2x Nvidia Hopper H100 Tensor Core GPU</li><li>2x 480GB of LPDDR5X memory with error-correction code (ECC)</li><li>2x 96GB of HBM3 memory</li><li>1152GB of total fast-access memory</li><li>NVLink-C2C: 900 GB/s of bandwidth</li><li>Programmable from 1000W to 2000W TDP (CPU + GPU + memory)</li><li>1x High-efficiency 3000W PSU 230V to 48V</li><li>2x PCIe Gen4 M.2 22110/2280 slots on board</li><li>4x FHFL PCIe Gen5 x16</li></ul><blockquote><p><strong>UPDATE</strong>:Since I bought this, DDR5 RAM prices have become insane. 960GB of fast DDR5 now costs more than what I paid for the whole Grace-Hopper system ü§Ø</p></blockquote><p><em>Obviously fake</em> I thought, because</p><ol><li>H100s cost about <strong>30-40,000 euro each</strong>, and this system has <em>two of them</em></li><li>Grace-Hopper NVL2 systems are basically not for sale for consumers anyway!</li></ol><p>The Reddit thread explained the reason the system was being sold cheap:</p><blockquote><p>The main reason why is that it is a Frankensystem converted from liquid-cooled to aircooled. Also it is not very pretty and not rackable, because it has a 48V power supply attached. It is originally directly from Nvidia.</p></blockquote><p>I immediately offered to buy it, because why not? If it was a scam, I could always back out, but I wanted to be first in line!</p><p>It turns out I live near the seller, and he runs an online shop that <a href="https://gptshop.ai/">sells modified Nvidia server equipment as desktops</a>. It still seemed pretty risky, so I did some research and <a href="https://www.youtube.com/watch?v=YBIpJhN5YsE">found a video review</a> of one of his Desktops on Youtube. With the deal now seeming at least plausible, and the seller only a two-hour drive away and agreeing to take cash, it was time to take a Bavarian road trip.</p><p>I arrived at a farmhouse in a small forest, and met Bernhard the proprietor of <a href="https://gptshop.ai/">GPTshop.ai</a>. He showed me a nice workshop (plasma cutters, an electronics lab, etc.) from which he fabricates custom cases for the high-end H100 desktops he builds. These desktops seem pretty damn nice, so it‚Äôs unfortunate that his webshop gives off shady vibes; the business registration in the Cayman Islands definitely doesn‚Äôt help. What I can say though is that this item was <em>heavily</em> discounted, and not what he usually sells.</p><blockquote><p><strong>Disclaimer</strong>: I have zero affiliation with GPTshop.ai beyond handing them a stack of cash and receiving a dust-covered server in return. If this were a sponsored post, they probably wouldn‚Äôt let me mention the 16 million degree GPU temperatures or the part where I had to free-solder components while praying to the electronics gods.</p></blockquote><h2 id="disassembling-the-grace-hopper-server"><span>Disassembling the Grace Hopper server</span><a href="#disassembling-the-grace-hopper-server"><i></i></a></h2><p><a href="https://dnhkng.github.io/assets/img/open.jpeg"><img src="https://dnhkng.github.io/assets/img/open.jpeg" alt="Arrival" loading="lazy"></a></p><p>The server itself was not in great condition. These things run <em>extremely</em> loud and high-throughput fans, and these had sucked in a lot of dust, coating the mainboard so heavily I couldn‚Äôt tell the color of the PCB. However, it booted up and ran OK, so I handed over a wad of cash, strapped it into the backseat of my car with the seatbelt (it weighed ~20 kg), and drove it home.</p><p>Did I mention it‚Äôs loud? Firing up the system is physically painful. There are 8x Sunon dual-fan modules, and each is as loud as a powerful vacuum cleaner, but with a much higher and more annoying pitch. With all 8 running at full power, hearing protection is necessary - I could hear the system running in my basement with the windows closed from 50 meters away! My wife immediately (and quite fairly), banned its use at home. We both work home-office and it was simply too loud for online meetings. But I had other plans anyway‚Ä¶</p><p>First things first, I of course quickly decided and then proceeded to strip down the server, after first photo-documenting the various connectors between the various PCBs, modules and mainboard.</p><h2 id="cleaning-the-server"><span>Cleaning the Server</span><a href="#cleaning-the-server"><i></i></a></h2><p><a href="https://dnhkng.github.io/assets/img/cleaning.jpg"><img src="https://dnhkng.github.io/assets/img/cleaning.jpg" alt="Cleaning" loading="lazy"></a></p><p>The majority of the dust was vacuumed off during disassembly, but there was clearly a lot more under the Grace-Hopper modules. After removing those as well, I decided to go with a full washdown of the mainboard.</p><p>I purchased a few litres of Isopropanol, and with a soft brush I went over the whole board a few times to get the remaining fine dust from inside connectors and between SMD-component pins.</p><p>I suspected there might also be dust <em>inside</em> the Grace-Hopper modules, but actually, I really just wanted to pop them open to poke around.</p><p>The mainboard went on my heated floor to dry for a week, while I moved on to replacing the cooling system.</p><h2 id="a-new-water-cooling-system"><span>A new Water Cooling system</span><a href="#a-new-water-cooling-system"><i></i></a></h2><p><a href="https://dnhkng.github.io/assets/img/adapter_plate.jpg"><img src="https://dnhkng.github.io/assets/img/adapter_plate.jpg" alt="Adapter Plate" loading="lazy"></a></p><p>I had looked into building a custom water-cooling block, but I was worried about leaks, when I found cheap <a href="https://www.arctic.de/en/Liquid-Freezer-III-420/ACFRE00137A">all-in-one water cooling systems</a> for ~40 euro each on sale. Two per GH200 module would be sufficient, so I carefully measured the dimensions of the GPU die and CPU, as well as screw locations, and threw those into Fusion 360 to model up an adapter block.</p><p>I have a Bambu X1, which came in very handy for prototyping the adapter blocks. The tolerances have to be very tight, so I printed several cut-away versions to make sure there was solid contact to the bare GPU die, and a safe margin from contact to fragile parts.</p><p>The parts were then sent for CNC milling, and were delivered as the mainboard was finished drying. After using yet more isopropanol to clean off the machining oil, they were mounted without much fuss.</p><h2 id="assembling-the-desktop"><span>Assembling the Desktop</span><a href="#assembling-the-desktop"><i></i></a></h2><p><a href="https://dnhkng.github.io/assets/img/assembly.jpg"><img src="https://dnhkng.github.io/assets/img/assembly.jpg" alt="Assembly" loading="lazy"></a></p><p>My go-to material for this kind of project is ProfilAlu from eBay. It‚Äôs cheap, stiff, and delivered pre-cut for assembly. I put together a design in Fusion 360, and had the parts in a few days. The various mounts however were much more work. I needed to design a few dozen custom mounts for the various PCBs and air-filter fixings; this used up a few kilos of filament to get things just right.</p><h2 id="disasters"><span>Disaster(s)</span><a href="#disasters"><i></i></a></h2><h3 id="critical-fan-errors"><span>Critical Fan Errors</span><a href="#critical-fan-errors"><i></i></a></h3><p>The system didn‚Äôt start to boot anymore. Checking the logs, I saw 16 critical errors, one for each fan in the 8 pairs:</p><blockquote><div><table><tbody><tr><td>4</td><td>08/06/25</td><td>19:24:08 CEST</td><td>Fan FAN_5_F</td><td>Lower Critical going low</td><td>Asserted</td><td>Reading 0 &lt; Threshold 2156 RPM</td></tr><tr><td>5</td><td>08/06/25</td><td>19:24:08 CEST</td><td>Fan FAN_6_R</td><td>Lower Critical going low</td><td>Asserted</td><td>Reading 0 &lt; Threshold 2156 RPM</td></tr><tr><td>6</td><td>08/06/25</td><td>19:24:08 CEST</td><td>Fan FAN_8_F</td><td>Lower Critical going low</td><td>Asserted</td><td>Reading 0 &lt; Threshold 2156 RPM</td></tr><tr><td>7</td><td>08/06/25</td><td>19:24:08 CEST</td><td>Fan FAN_5_R</td><td>Lower Critical going low</td><td>Asserted</td><td>Reading 0 &lt; Threshold 2156 RPM</td></tr><tr><td>8</td><td>08/06/25</td><td>19:24:08 CEST</td><td>Fan FAN_7_F</td><td>Lower Critical going low</td><td>Asserted</td><td>Reading 0 &lt; Threshold 2156 RPM</td></tr><tr><td>9</td><td>08/06/25</td><td>19:24:08 CEST</td><td>Fan FAN_8_R</td><td>Lower Critical going low</td><td>Asserted</td><td>Reading 0 &lt; Threshold 2156 RPM‚Ä¶</td></tr></tbody></table></div></blockquote><p>With the fans removed, the <a href="https://en.wikipedia.org/wiki/Intelligent_Platform_Management_Interface#Baseboard_management_controller">BMC (Baseboard Management Controller)</a> immediately panicked, and shut down the mainboard to prevent thermal damage, even with the water coolers in place. So, I disabled the fan-check subsystem.</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre># stops the service for the current session
systemctl stop phosphor-sensor-monitor.service

# prevents the service from starting on the next boot
systemctl disable phosphor-sensor-monitor.service
</pre></td></tr></tbody></table></code></p></div><p>Who needs hardware monitoring? ¬Ø\_(„ÉÑ)_/¬Ø</p><h3 id="nuclear-fusion"><span>Nuclear Fusion?</span><a href="#nuclear-fusion"><i></i></a></h3><p>Great! I could start the boot process, and even reach login! But only about 1 time in 4‚Ä¶ Not optimal. And even logged in, the server would crash within 2 minutes.</p><p>Looking into the BMC logs, I saw:</p><div><table><tbody><tr><td>Sep 23 08:20:18</td><td>oberon-bmc</td><td>shutdown_ok_mon[1478]</td><td>event: FALLING EDGE offset: 26 timestamp: [571.615238550]</td></tr><tr><td>Sep 23 08:20:18</td><td>oberon-bmc</td><td>power-status[1493]</td><td>event: FALLING EDGE offset: 18 timestamp: [571.632491062]</td></tr><tr><td>Sep 23 08:20:18</td><td><strong>oberon-bmc</strong></td><td><strong>shutdown_ok_mon[545]</strong></td><td><strong>SHDN_OK_L-I = 0</strong></td></tr><tr><td>Sep 23 08:20:18</td><td>oberon-bmc</td><td>shutdown_ok_mon[545]</td><td>Asserting SYS_RST_IN_L-O to hold host in reset</td></tr><tr><td>Sep 23 08:20:18</td><td>oberon-bmc</td><td>shutdown_ok_mon[545]</td><td>gpioset SYS_RST_IN_L-O = 0</td></tr><tr><td>Sep 23 08:20:18</td><td>oberon-bmc</td><td>power-status[697]</td><td>gpioset SYS_RST_IN_L-O = 0</td></tr><tr><td>Sep 23 08:20:18</td><td>oberon-bmc</td><td>power-status[697]</td><td>Set SYS_RST_IN_L-O=0</td></tr></tbody></table></div><p>So, a Critical Failure at 08:20:18:</p><ul><li>SHDN_OK_L-I signal goes low (falling edge detected)</li><li>This immediately triggers a shutdown sequence</li><li>System powers off within ~30 seconds of successful boot</li></ul><p>But why?!!? I had shut down the hardware monitoring.</p><p>Diving deeper into the logs:</p><div><table><tbody><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>ipmid[520]</td><td>thresholdChanged: Assert</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>ipmid[520]</td><td>thresholdChanged: Assert</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>ipmid[520]</td><td>thresholdChanged: Assert</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>satellitesensor[2351]</td><td>Sensor HGX_GPU_1_TEMP_1 high threshold 92 assert: value 1.67772e+07 raw data nan</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>satellitesensor[2351]</td><td>Sensor HGX_GPU_1_TEMP_1 high threshold 89 assert: value 1.67772e+07 raw data nan</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>satellitesensor[2351]</td><td>Sensor HGX_GPU_1_TEMP_1 high threshold 87 assert: value 1.67772e+07 raw data nan</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>phosphor-fru-fault-monitor[524]</td><td>/xyz/openbmc_project/logging/entry/496 created</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>phosphor-fru-fault-monitor[524]</td><td>/xyz/openbmc_project/logging/entry/497 created</td></tr><tr><td>Oct 05 10:15:00</td><td>oberon-bmc</td><td>sensor-monitor[499]</td><td>Starting 1000ms HardShutdownAlarmHigh shutdown timer due to sensor /xyz/openbmc_project/sensors/temperature/HGX_GPU_0_TEMP_1 value 16777214</td></tr></tbody></table></div><blockquote><p><strong>Warning:</strong> Your GPU should not reach 16,777,214 Celsius during boot. Imagine what would happen under load!</p></blockquote><p>This took some time to debug, as I was quite sure the sensors could not physically handle reading temperatures over 16 million Celsius‚Ä¶ But then I noticed something interesting about that specific number:</p><div><table><thead><tr><th>Decimal</th><th>Binary</th><th>Hex</th></tr></thead><tbody><tr><td>16,777,214</td><td>1111 1111 1111 1111 1111 1110</td><td>0xFFFFFE</td></tr></tbody></table></div><p>This is <code>2¬≤‚Å¥ - 2</code>, which is suspiciously close to the maximum value of a 24-bit unsigned integer. In the hardware world, this is the equivalent of a sensor throwing up its hands and screaming ‚ÄúI have no idea what‚Äôs happening!‚Äù When hardware can‚Äôt read a value properly‚Äîwhether due to a loose connection, damaged circuit, or initialization failure‚Äîit often returns the maximum (or near-maximum) representable value. It‚Äôs like the digital version of a shrug.</p><p>The logs confirmed this theory: seeing <code>1.67772e+07</code> (16,777,214) wasn‚Äôt evidence that my GPU had achieved nuclear fusion temperatures üî•‚Äîit was evidence that the temperature sensor had simply stopped working. And if a sensor error is intermittent, the most likely culprit is a loose connection or physical damage.</p><p>After spending way too long pursuing software solutions (because who wants to disassemble everything <em>again</em>?), I finally accepted the inevitable and broke out the screwdrivers.</p><p><a href="https://dnhkng.github.io/assets/img/fix.jpg"><img src="https://dnhkng.github.io/assets/img/fix.jpg" alt="Fix" loading="lazy"></a></p><p>I happened to have bought a new microscope earlier this year, and it turned out to be the perfect tool for diagnosing and fixing the issue. Near one of the modules, I found some damaged surface mount components. The damage must have happened after cleaning, probably during the reassembly of the modules with the copper adapters. They weigh over 2 kg, so a slight bump would have easily caused this damage. Amazingly, the tiny components were still attached to the traces, and so I could measure them easily: a 100 nF capacitor, and 4.7k resistor (both of which I had on-hand, as they are standard values for decoupling circuits). The bad news? I had huge ‚Äú0805‚Äù sized parts (2mm long), these were tiny ‚Äú0402‚Äù (1mm long). And one of the traces was just gone.</p><p>With some very fiddly soldering, and scratching off the solder mask on the PCB to expose more trace, I was able to ‚Äòfree solder‚Äô the parts into a wonderful 3D sculpture which was then liberally coated in UV-curing mask resin, set, and then held in place with sticky tape. Very professional. After reassembly, the system booted smoothly.</p><h2 id="final-touches"><span>Final Touches</span><a href="#final-touches"><i></i></a></h2><p><a href="https://dnhkng.github.io/assets/img/touches.jpg"><img src="https://dnhkng.github.io/assets/img/touches.jpg" alt="Fix" loading="lazy"></a></p><p>I 3D printed a few extra parts:</p><ul><li>Mounts for the E1.S 8TB SSD I found cheap online</li><li>A full rear-panel, that mounts the 3KW 48V power supply</li><li>Cool-looking mesh to protect the water-cooling radiators and dust filters</li></ul><p>Getting the actual GPU working was also painful, so I‚Äôll leave the details here for future adventurers:</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td><pre># Data Center/HGX-Series/HGX H100/Linux aarch64/12.8 seem to work!
wget https://us.download.nvidia.com/tesla/570.195.03/NVIDIA-Linux-aarch64-570.195.03.run

# Tell the driver to completely ignore the NVLINK and it should allow the GPUs to initialise independently over PCIe !!!!   This took a week of work to find, thanks Reddit!

# create a modprobe config file:
sudo nano /etc/modprobe.d/nvidia-disable-nvlink.conf

# add the driver option
options nvidia NVreg_NvLinkDisable=1

# update the boot files:
sudo update-initramfs -u

# reboot
sudo reboot
</pre></td></tr></tbody></table></code></p></div><h2 id="benchmarks"><span>Benchmarks</span><a href="#benchmarks"><i></i></a></h2><p>That‚Äôs what you‚Äôre here for, maybe? I have only just started, but after compiling the latest Llama.cpp version using 144 cores in 90 seconds, here‚Äôs some benchmarks on larger LLMs:</p><p><a href="https://dnhkng.github.io/assets/img/benchmarks.jpg"><img src="https://dnhkng.github.io/assets/img/benchmarks.jpg" alt="Benchmarks" loading="lazy"></a></p><div><table><thead><tr><th>Model</th><th>Prompt Processing</th><th>Token Generation</th></tr></thead><tbody><tr><td>gpt-oss-120b-Q4_K_M</td><td>2974.79</td><td>195.84</td></tr><tr><td>GLM-4.5-Air-Q4_K_M</td><td>1936.65</td><td>100.71</td></tr><tr><td>Qwen3-235B-A22B-Instruct-2507-Q4_K</td><td>1022.79</td><td>65.90</td></tr></tbody></table></div><p>This is pretty unoptimized, but it‚Äôs looking promising so far! During the LLM tests I hit around 300W per GPU, far from the 900W max.</p><h2 id="cost-breakdown"><span>Cost Breakdown</span><a href="#cost-breakdown"><i></i></a></h2><p>Here‚Äôs what the entire build actually cost me, from the initial purchase to the final touches:</p><div><table><thead><tr><th>Component</th><th>Description</th><th>Cost (EUR)</th></tr></thead><tbody><tr><td>Grace-Hopper Server</td><td>2x GH200 superchips with H100 GPUs (the Frankenstein special)</td><td>‚Ç¨7,500</td></tr><tr><td>Storage</td><td>‚Äòlike-new‚Äô used 8TB E1.S NVMe SSD</td><td>‚Ç¨250</td></tr><tr><td>Custom Water Cooling Adapters</td><td>2x CNC-milled copper mounting plates for AIO coolers</td><td>‚Ç¨700</td></tr><tr><td>AIO Water Coolers</td><td>4x Arctic Liquid Freezer III 420 (B-Ware)</td><td>‚Ç¨180</td></tr><tr><td>Structural Frame</td><td>Extruded aluminum profiles, pre-cut and delivered</td><td>‚Ç¨200</td></tr><tr><td>3D Printing Filament</td><td>1kg black PLA for custom mounts and brackets</td><td>‚Ç¨20</td></tr><tr><td>Hardware</td><td>Nuts, bolts, and mounting hardware</td><td>‚Ç¨50</td></tr><tr><td>Cleaning Supplies</td><td>5 liters of 99.9% isopropanol (used liberally throughout)</td><td>‚Ç¨20</td></tr><tr><td>Aesthetics</td><td>LED lighting strip (because RGB makes it faster)</td><td>‚Ç¨10</td></tr><tr><td><strong>Total</strong></td><td>&nbsp;</td><td><strong>‚Ç¨8,930</strong></td></tr></tbody></table></div><p>Not included: hearing protection (absolutely necessary), the microscope I already owned (but proved essential), several failed 3D prints, and the emotional cost of seeing ‚Äú16,777,214¬∞C‚Äù in system logs.</p><h2 id="conclusion"><span>Conclusion</span><a href="#conclusion"><i></i></a></h2><p>So, was it worth it? I now have a desktop that can run 235B parameter models at home for less than the cost of a single H100. It required disassembling $80,000 worth of enterprise hardware, debugging sensors that reported temperatures approaching the surface of the sun, and free-soldering components under a microscope. Your mileage may vary. Literally: I had to drive two hours to pick this thing up.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Super Mario 64 for the PS1 (189 pts)]]></title>
            <link>https://github.com/malucard/sm64-psx</link>
            <guid>46221925</guid>
            <pubDate>Wed, 10 Dec 2025 18:58:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/malucard/sm64-psx">https://github.com/malucard/sm64-psx</a>, See on <a href="https://news.ycombinator.com/item?id=46221925">Hacker News</a></p>
<div id="readability-page-1" class="page"><p dir="auto">This repo does not include all assets necessary for compiling the game.
An original copy of the game is required to extract the assets.</p><div data-snippet-clipboard-copy-content="sm64
‚îú‚îÄ‚îÄ actors: object behaviors, geo layout, and display lists
‚îú‚îÄ‚îÄ assets: animation and demo data
‚îÇ   ‚îú‚îÄ‚îÄ anims: animation data
‚îÇ   ‚îî‚îÄ‚îÄ demos: demo data
‚îú‚îÄ‚îÄ bin: C files for ordering display lists and textures
‚îú‚îÄ‚îÄ build: output directory
‚îú‚îÄ‚îÄ data: behavior scripts, misc. data
‚îú‚îÄ‚îÄ doxygen: documentation infrastructure
‚îú‚îÄ‚îÄ enhancements: example source modifications
‚îú‚îÄ‚îÄ include: header files
‚îú‚îÄ‚îÄ levels: level scripts, geo layout, and display lists
‚îú‚îÄ‚îÄ lib: N64 SDK code
‚îú‚îÄ‚îÄ sound: sequences, sound samples, and sound banks
‚îú‚îÄ‚îÄ src: C source code for game
‚îÇ   ‚îú‚îÄ‚îÄ audio: audio code
‚îÇ   ‚îú‚îÄ‚îÄ buffers: stacks, heaps, and task buffers
‚îÇ   ‚îú‚îÄ‚îÄ engine: script processing engines and utils
‚îÇ   ‚îú‚îÄ‚îÄ game: behaviors and rest of game source
‚îÇ   ‚îú‚îÄ‚îÄ goddard: rewritten Mario intro screen
‚îÇ   ‚îú‚îÄ‚îÄ goddard_og: backup of original Mario intro screen
‚îÇ   ‚îú‚îÄ‚îÄ menu: title screen and file, act, and debug level selection menus
‚îÇ   ‚îî‚îÄ‚îÄ port: port code, audio and video renderer
‚îú‚îÄ‚îÄ text: dialog, level names, act names
‚îú‚îÄ‚îÄ textures: skybox and generic texture data
‚îî‚îÄ‚îÄ tools: build tools"><pre><code>sm64
‚îú‚îÄ‚îÄ actors: object behaviors, geo layout, and display lists
‚îú‚îÄ‚îÄ assets: animation and demo data
‚îÇ   ‚îú‚îÄ‚îÄ anims: animation data
‚îÇ   ‚îî‚îÄ‚îÄ demos: demo data
‚îú‚îÄ‚îÄ bin: C files for ordering display lists and textures
‚îú‚îÄ‚îÄ build: output directory
‚îú‚îÄ‚îÄ data: behavior scripts, misc. data
‚îú‚îÄ‚îÄ doxygen: documentation infrastructure
‚îú‚îÄ‚îÄ enhancements: example source modifications
‚îú‚îÄ‚îÄ include: header files
‚îú‚îÄ‚îÄ levels: level scripts, geo layout, and display lists
‚îú‚îÄ‚îÄ lib: N64 SDK code
‚îú‚îÄ‚îÄ sound: sequences, sound samples, and sound banks
‚îú‚îÄ‚îÄ src: C source code for game
‚îÇ   ‚îú‚îÄ‚îÄ audio: audio code
‚îÇ   ‚îú‚îÄ‚îÄ buffers: stacks, heaps, and task buffers
‚îÇ   ‚îú‚îÄ‚îÄ engine: script processing engines and utils
‚îÇ   ‚îú‚îÄ‚îÄ game: behaviors and rest of game source
‚îÇ   ‚îú‚îÄ‚îÄ goddard: rewritten Mario intro screen
‚îÇ   ‚îú‚îÄ‚îÄ goddard_og: backup of original Mario intro screen
‚îÇ   ‚îú‚îÄ‚îÄ menu: title screen and file, act, and debug level selection menus
‚îÇ   ‚îî‚îÄ‚îÄ port: port code, audio and video renderer
‚îú‚îÄ‚îÄ text: dialog, level names, act names
‚îú‚îÄ‚îÄ textures: skybox and generic texture data
‚îî‚îÄ‚îÄ tools: build tools
</code></pre></div><p dir="auto">Pull requests are welcome. For major changes, please open an issue first to
discuss what you would like to change.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise (108 pts)]]></title>
            <link>https://arxiv.org/abs/2512.08309</link>
            <guid>46221594</guid>
            <pubDate>Wed, 10 Dec 2025 18:37:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2512.08309">https://arxiv.org/abs/2512.08309</a>, See on <a href="https://news.ycombinator.com/item?id=46221594">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2512.08309">View PDF</a>
    <a href="https://arxiv.org/html/2512.08309v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>For decades, procedural worlds have been built on procedural noise functions such as Perlin noise, which are fast and infinite, yet fundamentally limited in realism and large-scale coherence. We introduce Terrain Diffusion, an AI-era successor to Perlin noise that bridges the fidelity of diffusion models with the properties that made procedural noise indispensable: seamless infinite extent, seed-consistency, and constant-time random access. At its core is InfiniteDiffusion, a novel algorithm for infinite generation, enabling seamless, real-time synthesis of boundless landscapes. A hierarchical stack of diffusion models couples planetary context with local detail, while a compact Laplacian encoding stabilizes outputs across Earth-scale dynamic ranges. An open-source infinite-tensor framework supports constant-memory manipulation of unbounded tensors, and few-step consistency distillation enables efficient generation. Together, these components establish diffusion models as a practical foundation for procedural world generation, capable of synthesizing entire planets coherently, controllably, and without limits.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Alexander Goslin [<a href="https://arxiv.org/show-email/c780ef89/2512.08309" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 9 Dec 2025 07:10:35 UTC (12,075 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Automated license plate reader coverage in the USA (139 pts)]]></title>
            <link>https://alpranalysis.com</link>
            <guid>46220794</guid>
            <pubDate>Wed, 10 Dec 2025 17:42:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alpranalysis.com">https://alpranalysis.com</a>, See on <a href="https://news.ycombinator.com/item?id=46220794">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Is it a bubble? (175 pts)]]></title>
            <link>https://www.oaktreecapital.com/insights/memo/is-it-a-bubble</link>
            <guid>46220640</guid>
            <pubDate>Wed, 10 Dec 2025 17:30:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.oaktreecapital.com/insights/memo/is-it-a-bubble">https://www.oaktreecapital.com/insights/memo/is-it-a-bubble</a>, See on <a href="https://news.ycombinator.com/item?id=46220640">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							
							<!-- Text to Speech Conditional Wrapper -->
							<!-- End -->
							<p>Ours is a remarkable moment in world history.  A transformative technology is ascending, and its supporters claim it will forever change the world.  To build it requires companies to invest a sum of money unlike anything in living memory.  News reports are filled with widespread fears that America‚Äôs biggest corporations are propping up a bubble that will soon pop.  </p><p>During my visits to clients in Asia and the Middle East last month, I was often asked about the possibility of a bubble surrounding artificial intelligence, and my discussions gave rise to this memo.  I want to start off with my usual caveats: I‚Äôm not active in the stock market; I merely watch it as the best barometer of investor psychology.  I‚Äôm also no techie, and I don‚Äôt know any more about AI than most generalist investors.  But I‚Äôll do my best.</p><p>One of the most interesting aspects of bubbles is their regularity, not in terms of timing, but rather the progression they follow.  Something new and seemingly revolutionary appears and worms its way into people‚Äôs minds.  It captures their imagination, and the excitement is overwhelming.  The early participants enjoy huge gains.  Those who merely look on feel incredible envy and regret and ‚Äì motivated by the fear of continuing to miss out ‚Äì pile in.  They do this without knowledge of what the future will bring or concern about whether the price they‚Äôre paying can possibly be expected to produce a reasonable return with a tolerable amount of risk.  The end result for investors is inevitably painful in the short to medium term, although it‚Äôs possible to end up ahead after enough years have passed.</p><p>I‚Äôve lived through several bubbles and read about others, and they‚Äôve all hewed to this description.  One might think the losses experienced when past bubbles popped would discourage the next one from forming.  But that hasn‚Äôt happened yet, and I‚Äôm sure it never will.  <strong>Memories are short, and prudence and natural risk aversion are no match for the dream of getting rich on the back of a revolutionary technology that ‚Äúeveryone knows‚Äù will change the world. </strong></p><p>I took the quote that opens this memo from Derek Thompson‚Äôs November 4 newsletter entitled ‚ÄúAI Could Be the Railroad of the 21<sup>st</sup> Century.  Brace Yourself,‚Äù about parallels between what‚Äôs going on today in AI and the railroad boom of the 1860s.  Its word-for-word applicability to both shows clearly what‚Äôs meant by the phrase widely attributed to Mark Twain: ‚Äúhistory rhymes.‚Äù</p><p><span>Understanding Bubbles</span></p><p>Before diving into the subject at hand ‚Äì and having read a great deal about it in preparation ‚Äì <strong>I want to start with a point of clarification.  Everyone asks, ‚ÄúIs there a bubble in AI?‚Äù  I think there‚Äôs ambiguity even in the question.  I‚Äôve concluded there are two different but interrelated bubble possibilities to think about: one in the behavior of companies <span>within</span> the industry, and the other in how investors are behaving <span>with regard to</span> the industry.</strong> I have absolutely no ability to judge whether the AI companies‚Äô aggressive behavior is justified, so I‚Äôll try to stick primarily to the question of whether there‚Äôs a bubble around AI in the financial world.</p><p>The main job of an investment analyst ‚Äì especially in the so-called ‚Äúvalue‚Äù school to which I subscribe ‚Äì is to (a) study companies and other assets and assess the level of and outlook for their intrinsic value and (b) make investment decisions on the basis of that value.  Most of the change the analyst encounters in the short to medium term surrounds the asset‚Äôs price and its relationship to underlying value.  That relationship, in turn, is essentially the result of investor psychology.</p><p>Market bubbles aren‚Äôt caused directly by technological or financial developments.  Rather, they result from the application of excessive optimism to those developments.  As I wrote in my January memo <a href="https://www.oaktreecapital.com/insights/memo/on-bubble-watch" data-sf-ec-immutable=""><em>On Bubble Watch</em></a>, bubbles are temporary manias in which developments in those areas become the subject of what former U.S. Federal Reserve Chairman Alan Greenspan called ‚Äúirrational exuberance.‚Äô‚Äô</p><p>Bubbles usually coalesce around new financial developments (e.g., the South Sea Company of the early 1700s or sub-prime residential mortgage-backed securities in 2005-06) or technological progress (optical fiber in the late 1990s and the internet in 1998-2000).  <strong>Newness plays a huge part in this.  Because there‚Äôs no history to restrain the imagination, the future can appear limitless for the new thing.  And futures that are perceived to be limitless can justify valuations that go well beyond past norms ‚Äì leading to asset prices that aren‚Äôt justified on the basis of predictable earning power.</strong></p><p>The role of newness is well described in my favorite passage from a book that greatly influenced me, <em>A Short History of Financial Euphoria</em> by John Kenneth Galbraith.  Galbraith wrote about what he called ‚Äúthe extreme brevity of the financial memory‚Äù and pointed out that in the financial markets, ‚Äúpast experience, to the extent that it is part of memory at all, is dismissed as the primitive refuge of those who do not have the insight to appreciate the incredible wonders of the present.‚Äù  In other words, history can impose limits on awe regarding the present and imagination regarding the future.  In the absence of history, on the other hand, all things seem possible.</p><p><strong>The key thing to note here is that the new thing understandably inspires great enthusiasm, but bubbles are what happen when the enthusiasm reaches irrational proportions.  </strong>Who can identify the boundary of rationality?  Who can say when an optimistic market has become a bubble?  It‚Äôs just a matter of judgment.  </p><p>Something that occurred to me this past month is that two of my best ‚Äúcalls‚Äù came in 2000, when I cautioned about what was going on in the market for tech and internet stocks, and in 2005-07, when I cited the dearth of risk aversion and the resulting ease of doing crazy deals in the pre-Global Financial Crisis world.  </p><ul><li data-list="2" data-level="1"><p>First, in neither case did I possess any expertise regarding the things that turned out to be the subjects of the bubbles: the internet and sub-prime mortgage-backed securities.  All I did was render observations regarding the behavior taking place around me.  </p></li><li data-list="2" data-level="1"><p>And second, the value in my calls consisted mostly of describing the folly in that behavior, not in insisting that it had brought on a bubble.  </p></li></ul><p><strong>Struggling with whether to apply the ‚Äúbubble‚Äù label can bog you down and interfere with proper judgment; we can accomplish a great deal by merely assessing what‚Äôs going on around us and drawing inferences with regard to proper behavior.</strong></p><p><span>What‚Äôs Good About Bubbles?</span></p><p>Before going on to discuss AI and whether it‚Äôs presently in a bubble, I want to spend a little time on a subject that may seem somewhat academic from the standpoint of investors: the upside of bubbles.  You may find the attention I devote to this topic excessive, but I do so because I find it fascinating.</p><p>The November 5 <em>Stratechery</em> newsletter was entitled ‚ÄúThe Benefits of Bubbles.‚Äù  In it, Ben Thompson (no relation to Derek) cites a book titled <em>Boom: Bubbles and the End of Stagnation</em>. It was written by Byrne Hobart and Tobias Huber, who propose that there are two kinds of bubbles:</p><p>. . . ‚ÄúInflection Bubbles‚Äù ‚Äì the good kind of bubbles, as opposed to the much more damaging ‚ÄúMean-reversion Bubbles‚Äù like the 2000‚Äôs subprime mortgage bubble. </p><p>I find this a useful dichotomy.  </p><ul><li data-list="2" data-level="1"><p>The financial fads I‚Äôve read about or witnessed ‚Äì the South Sea Company, portfolio insurance, and sub-prime mortgage-backed securities ‚Äì stirred the imagination based on the promise of returns without risk, but there was no expectation that they would represent overall progress for mankind.  There was, for example, no thought that housing would be revolutionized by the sub-prime mortgage movement, merely a feeling that there was money to be made from backing new buyers.  Hobart and Huber call these ‚Äúmean-reverting bubbles,‚Äù presumably because there‚Äôs no expectation that the underlying developments would move the world forward.  Fads merely rise and fall.</p></li><li data-list="2" data-level="1"><p>On the other hand, Hobart and Huber call bubbles based on technological progress ‚Äì as in the case of the railroads and the internet ‚Äì ‚Äúinflection bubbles.‚Äù  After an inflection-driven bubble, the world will not revert to its prior state.  In such a bubble, ‚Äúinvestors decide that the future will be meaningfully different from the past and trade accordingly.‚Äù  As Thompson tells us:</p></li></ul><p>The definitive book on bubbles has long been Carlota Perez‚Äôs <em>Technological Revolutions and Financial Capital</em>. Bubbles were ‚Äì are ‚Äì thought to be something negative and to be avoided, particularly at the time Perez published her book.  The year was 2002 and much of the world was in a recession coming off the puncturing of the dot-com bubble.</p><p>Perez didn‚Äôt deny the pain: in fact, she noted that similar crashes marked previous revolutions, including the Industrial Revolution, railways, electricity, and the automobile.  In each case the bubbles were not regrettable, but necessary: <strong>the speculative mania enabled what Perez called the ‚ÄúInstallation Phase,‚Äù where necessary but not necessarily financially wise investments laid the groundwork for the ‚ÄúDeployment Period.‚Äù  What marked the shift to the deployment period was the popping of the bubble; <span>what enabled the deployment period were the money-losing investments.</span></strong> (All emphasis added)</p><p>This distinction is very meaningful for Hobart and Huber, and I agree.  They say, ‚Äúnot all bubbles destroy wealth and value.  Some can be understood as important catalysts for techno-scientific progress.‚Äù  </p><p>But I would restate as follows: ‚ÄúMean-reversion bubbles‚Äù ‚Äì in which markets soar on the basis of some new financial miracle and then collapse ‚Äì destroy wealth.  On the other hand, ‚Äúinflection bubbles‚Äù based on revolutionary developments accelerate technological progress and create the foundation for a more prosperous future, <strong>and they destroy wealth</strong>. The key is to not be one of the investors whose wealth is destroyed in the process of bringing on progress.</p><p>Hobart and Huber go on to describe in greater depth the process through which bubbles finance the building of the infrastructure required by the new technology and thus accelerate its adoption:</p><p>Most novel technology doesn‚Äôt just appear <em>ex nihilo</em> [i.e., from nothing], entering the world fully formed and all at once.  Rather, it builds on previous false starts, failures, iterations, and historical path dependencies.  Bubbles create opportunities to deploy the capital necessary to fund and speed up such large-scale experimentation ‚Äì which includes lots of trial and error done in parallel ‚Äì thereby accelerating the rate of potentially disruptive technologies and breakthroughs. </p><p>By generating positive feedback cycles of enthusiasm and investment, bubbles can be net beneficial.  Optimism can be a self-fulfilling prophecy.  Speculation provides the massive financing needed to fund highly risky and exploratory projects; what appears in the short term to be excessive enthusiasm or just bad investing turns out to be essential for bootstrapping social and technological innovations . . .  A bubble can be a collective delusion, but it can also be an expression of collective vision.  That vision becomes a site of coordination for people and capital and for the parallelization of innovation.  Instead of happening over time, bursts of progress happen simultaneously across different domains.  And with mounting enthusiasm . . . comes increased risk tolerance and strong network effects.  The fear of missing out, or FOMO, attracts even more participants, entrepreneurs, and speculators, further reinforcing this positive feedback loop.  Like bubbles, FOMO tends to have a bad reputation, but it‚Äôs sometimes a healthy instinct.  After all, none of us wants to miss out on a once-in-a-lifetime chance to build the future.</p><p>In other words, bubbles based on technological progress are good because they excite investors into pouring in money ‚Äì a good bit of which is thrown away ‚Äì to carpet-bomb a new area of opportunity and thus jump-start its exploitation.  </p><p><strong>The key realization seems to be that if people remained patient, prudent, analytical, and value-insistent, novel technologies would take many years and perhaps decades to be built out.  Instead, the hysteria of the bubble causes the process to be compressed into a very short period ‚Äì with some of the money going into life-changing investment in the winners but a lot of it being incinerated. </strong></p><p><strong>A bubble has aspects that are both technological and financial, but the above citations are from the standpoint of people who crave technological progress and are perfectly happy to see investors lose money in its interest.  ‚ÄúWe,‚Äù on the other hand, would like to see technological progress but have no desire to throw away money to help bring it about.</strong></p><p>Ben Thompson ends this discussion by saying, ‚ÄúThis is why I‚Äôm excited to talk about new technologies, the prospect for which <em>I don‚Äôt know</em>.‚Äù I love the fact that he‚Äôs excited by future possibilities and at the same time admits that the shape of the future is unknown (in our world, we might say ‚Äúvery risky‚Äù).</p><p><span>Assessing the Current Landscape</span></p><p>Now let‚Äôs get down to what we used to call ‚Äúbrass tacks.‚Äù  What do we know?  First, I haven‚Äôt met anyone who doesn‚Äôt believe artificial intelligence has the potential to be one of the biggest technological developments of all time, reshaping both daily life and the global economy.</p><p>We also know that in recent years, economies and markets have become increasingly dependent on AI:</p><ul><li data-list="3" data-level="1"><p>AI is responsible for a very large portion of companies‚Äô total capital expenditures.</p></li><li data-list="3" data-level="1"><p>Capital expenditures on AI capacity account for a large share of the growth in U.S. GDP.</p></li><li data-list="3" data-level="1"><p>AI stocks have been the source of the vast majority of the gains of the S&amp;P 500.</p></li></ul><p>As a <em>Fortune</em> headline put it on October 7: </p><p>75% of gains, 80% of profits, 90% of capex ‚Äì AI‚Äôs grip on the S&amp;P is total and Morgan Stanley‚Äôs top analyst is ‚Äòvery concerned‚Äô</p><p>Further, I think it‚Äôs important to note that whereas the gains in AI-related stocks account for a disproportionate percentage of the total gains in all stocks, the excitement AI injects into the market must have added a lot to the appreciation of non-AI stocks as well.</p><p>AI-related stocks have shown astronomical performance, led by Nvidia, the leading developer of computer chips for AI.  From its formation in 1993 and its initial public offering in 1999, when its estimated market value was $626 million, Nvidia briefly became the world‚Äôs first company worth $5 trillion.  That‚Äôs appreciation of around 8,000x, or roughly 40% a year for 26+ years.  No wonder imaginations have been fired.  </p><p><span>What Are the Areas of Uncertainty?</span></p><p>I think it‚Äôs fair to say that while we know AI will be a source of incredible change, most of us have no idea exactly what it will be able to do, how it will be applied commercially, or what the timing will be.  </p><p><strong>Who will be the winners, and what will they be worth?</strong> If a new technology is assumed to be a world changer, it‚Äôs invariably assumed that the leading companies possessing that technology will be of great value.  But how accurate will that assumption prove to be?  As Warren Buffett pointed out in 1999, ‚Äú[The automobile was] the most important invention, probably, of the first half of the 20<sup>th</sup> century. . . .  If you had seen at the time of the first cars how this country would develop in connection with autos, you would have said, ‚ÄòThis is the place I must be.‚Äô  But of the 2,000 companies, as of a few years ago, only three car companies survived.  So autos had an enormous impact on America but the opposite direction on investors.‚Äù (<em>Time</em>, January 23, 2012)</p><p>In AI, there are some very strong leaders at present, including some of the world‚Äôs strongest and richest companies.  But new technology is notoriously disruptive.  Will today‚Äôs leaders prevail or give way to upstarts?  How much will the arms race cost, and who will win?</p><p><strong>Similarly, what‚Äôs a share in an upstart worth?</strong> Unlike front runners worth trillions, it‚Äôs possible to invest in some would-be challengers at enterprise values in mere billions or even ‚Äì might I say? ‚Äì millions.  On June 25, 2024, CNBC reported as follows:  </p><p>A team founded by college dropouts has raised $120 million from investors led by Primary Venture Partners to build a new AI chip to take on Nvidia.  Etched CEO Gavin Uberti said the startup is betting that as AI develops, most of the technology‚Äôs power-hungry computing requirements will be filled by customized, hard-wired chips called ASICs.  ‚ÄúIf transformers go away, we‚Äôll die,‚Äù Uberti told CNBC. ‚ÄúBut if they stick around, we‚Äôre the biggest company of all time.‚Äù</p><p>Even granting the possibility that Etched won‚Äôt become the biggest company of all time, if success could give them a valuation just one-fifth of Nvidia‚Äôs peak ‚Äì a mere $1 trillion ‚Äì what probability of success would be required to justify an investment of $120 million?  Assuming for simplicity‚Äôs sake that the investment was for a 100% ownership stake, all you need is a belief that achieving the trillion-dollar value has a probability of one-tenth of a percent for an expected return of over eight times your money.  Who‚Äôs to say Etched doesn‚Äôt have that chance?  And in that case, why would anyone not play?  The foregoing is what I call ‚Äúlottery-ticket thinking,‚Äù in which the dream of an enormous payoff justifies ‚Äì no, compels ‚Äì participation in an endeavor with an overwhelming probability of failing.  </p><p>There‚Äôs nothing wrong with calculating expected values this way.  Leading venture capitalists engage in it every day to great effect.  But assumptions regarding the possible payoffs and their probabilities must be reasonable.  Thinking about a trillion-dollar payout will override reasonableness in any calculation.</p><p><strong>Will AI produce profits, and for whom?  Two things</strong> we know little or nothing about are the profits AI will produce for vendors and its impact on non-AI companies, primarily meaning those who employ it.  </p><p>Will AI be a monopoly or duopoly, in which one or two leading companies are able to charge dearly for the capabilities?  Or will it be a highly competitive free-for-all in which a number of firms compete on price for users‚Äô spending on AI services, making it a commodity?  Or, perhaps most likely, will it be a mix of leading companies and specialized players, some of whom compete on price and others through proprietary advantages.  It‚Äôs said that the services currently responding to AI queries, such as ChatGPT and Gemini, lose money on every query they answer (of course, it‚Äôs not unusual for participants in a new industry to offer ‚Äúloss leaders‚Äù for a while).  Will the leading tech firms ‚Äì used to success in winner-take-all markets ‚Äì be content to experience losses in their AI businesses for years in order to gain share?  Hundreds of billions of dollars are being committed to the race for AI leadership.  Who will win, and what will be the result?</p><p>Likewise, what will be AI‚Äôs impact on the companies that use it?  Clearly, AI will be a great tool for enhancing users‚Äô productivity by, among other things, replacing workers with computer-sourced labor and intelligence.  But will this ability to cut costs add to the profit margins of the companies that employ it?  Or will it simply enable price wars among those companies in the pursuit of customers?  In that case, the savings might be passed on to the customers rather than garnered by the companies.  In other words, is it possible AI will increase the efficiency of businesses without increasing their profitability?</p><p><strong>Should we worry about so-called ‚Äúcircular deals‚Äù?</strong> In the telecom boom of the late 1990s, in which optical fiber became overbuilt, fiber-owning companies engaged in transactions with each other that permitted them to report profits.  If two companies own fiber, they just have an asset on their books.  But if each buys capacity from the other, they can both report profits . . . so they did.  In other cases, manufacturers loaned network operators money to buy equipment from them, before the operators had customers to justify the buildout.  All this resulted in profits that were illusory.</p><p>Nowadays, deals are being announced in which money appears to be round-tripped between AI players.  People who believe there‚Äôs an AI bubble find it easy to view these transactions with suspicion.  Is the purpose to achieve legitimate business goals or to exaggerate progress?</p><p>Adding to worries, critics say, some of the deals that OpenAI has made with chipmakers, cloud computing companies and others are oddly circular.  OpenAI is set to receive billions from tech companies but also sends billions back to the same companies to pay for computing power and other services. . . .</p><p>Nvidia has also made some deals that have raised questions about whether the company is paying itself.  It announced that it would invest $100 billion in OpenAI.  The start-up receives that money as it buys or leases Nvidia‚Äôs chips. . . .</p><p>Goldman Sachs has estimated that Nvidia will make 15 percent of its sales next year from what critics also call circular deals.  (<em>The New York Times</em>, November 20)</p><p>Noteworthily, OpenAI has made investment commitments to industry counterparties totaling $1.4 trillion, even though it has yet to turn a profit.  The company makes clear that the investments are to be paid out of revenues received from the same parties and that it has ways to back out of these commitments.  But all this raises the question of whether the AI industry has developed a perpetual motion machine.  </p><p>(On this subject, I‚Äôve been enjoying articles questioning the ability of people to relate to the word ‚Äútrillion,‚Äù and I think this idea is spot on.  A million dollars is a dollar a second for 11.6 days.  A billion dollars is a dollar a second for 31.7 years.  We get that.  But a trillion dollars is a dollar a second for 31,700 years.  Who can get their head around the significance of 31,700 years?)</p><p><strong>What will be the useful life of AI assets?</strong> We have to wonder whether the topic of obsolescence is being handled correctly in AI-land.  What will be the lifespan of AI chips?  How many years of earnings growth should be counted on in assigning p/e ratios for AI-related stocks?  Will chips and other aspects of AI infrastructure last long enough to repay the debt undertaken to buy them?  Will artificial general intelligence (a machine capable of doing anything the human brain can do) be achieved?  Will that be the end of progress, or might there be further revolutions, and what firms will win them?  Will firms reach a position where technology is stable and they can extract economic value from it?  Or will new technologies continually threaten to supplant older ones as the route to success?  </p><p>In this connection, a single issue of an FT newsletter briefly mentioned two developments that suggest the fluid nature of the competitive landscape:</p><ul><li data-list="2" data-level="1"><p>A study by the Massachusetts Institute of Technology and open-source AI start-up Hugging Face found that the total share of downloads of new Chinese-made open models rose to 17 per cent in the past year.  The figure surpasses the 15.8 per cent share of downloads from American developers such as Google, Meta and OpenAI ‚Äì the first time Chinese groups have beaten their American counterparts. . . .</p></li><li data-list="2" data-level="1"><p>Nvidia shares fell sharply yesterday on fears that Google is gaining ground in artificial intelligence, erasing $115bn in market value from the AI chipmaker.  (<em>FirstFT Americas</em>, November 26)</p></li></ul><p><strong>Dynamic change creates the opportunity for incredible new technologies, but that same dynamism can threaten the leading companies‚Äô reign.</strong> Amid all these uncertainties, investors must ask whether the assumption of continued success incorporated in the prices they‚Äôre paying is fully warranted.</p><p><strong>Is exuberance leading to speculative behavior?</strong> For an extreme example, I‚Äôll cite the trend toward venture capital investments in startups via $1 billion ‚Äúseed rounds.‚Äù  Here‚Äôs one vignette:</p><p>Thinking Machines, an AI startup helmed by former Open AI executive Mira Murati, just raised the largest seed round in history: $2 billion in funding at a $10 billion valuation.  The company has not released a product and has refused to tell investors what they‚Äôre even trying to build.  ‚ÄúIt was the most absurd pitch meeting,‚Äù one investor who met with Murati said.  ‚ÄúShe was like, ‚ÄòSo we're doing an AI company with the best AI people, but we can‚Äôt answer any questions.‚Äô ‚Äù  (‚ÄúThe Is How the AI Bubble Will Pop,‚Äù Derek Thompson Substack, October 2)</p><p>But that‚Äôs ancient history. . . already two months old.  Here‚Äôs an update:</p><p>Thinking Machines Lab, the artificial intelligence startup founded by former Open AI executive Mira Murati, is in early talks to raise a new funding round at a roughly $50 billion valuation, <em>Bloomberg News</em> reported on Thursday.  The startup was last valued at $12 billion in July, after it raised about $2 billion.  (<em>Reuters</em>, November 13)</p><p>And Thinking Machines Lab isn‚Äôt alone:</p><p>In one of the boldest bets yet in the AI arms race, Safe Superintelligence (SSI), the stealth startup founded by former OpenAI chief scientist Ilya Sutskever, has raised $2 billion in a round that values the company at $32 billion ‚Äì despite having no publicly released product or service.  (<em>CTech by Calcalist</em>, April 13)</p><p><strong>What‚Äôs the end state?</strong> Part of the issue with AI includes the unusual nature of this newest thing.  This isn‚Äôt like a business that designs and sells a product, making money if the selling price exceeds the cost of the inputs.  Rather, it‚Äôs companies building an airplane while it‚Äôs in flight, and once it‚Äôs built, they‚Äôll know what it can do and whether anyone will pay for its services.</p><p>Many companies justify their spending because <strong>they‚Äôre not just building a product, they‚Äôre creating something that will change the world</strong>: artificial general intelligence, or A.G.I. . . .  The rub is that none of them quite know how to do it.</p><p>But Anton Korinek, an economist at the University of Virginia, said the spending would all be justified if Silicon Valley reached its goal.  He is optimistic it can be done.</p><p>‚ÄúIt‚Äôs a bet on A.G.I. or bust,‚Äù Dr. Korinek said.  (<em>The New York Times</em>, November 20 ‚Äì emphasis added)</p><p>The yet-to-be-determined nature of the industry under construction is best captured in remarks from Sam Altman, the CEO of OpenAI, that have been paraphrased as follows: ‚Äúwe‚Äôll build this sort of generally intelligent system and then ask it to figure out a way to generate an investment return from it.‚Äù</p><p>This should be a source of pause for people who heretofore fully comprehended the nature of the businesses they invested in.  Clearly, the value of a technology that equals or surpasses the human brain should be pretty big, but isn‚Äôt it well beyond calculation?  </p><p><span>A Word About the Use of Debt</span></p><p>To date, much of the investment in AI and the supporting infrastructure has consisted of equity capital derived from operating cash flow.  But now, companies are committing amounts that require debt financing, and for some of those companies, the investments and leverage have to be described as aggressive.</p><p>The AI data centre boom was never going to be financed with cash alone.  The project is too big to be paid for out of pocket.  JPMorgan analysts have done some sums on the back of a napkin, or possibly a tablecloth, and estimated the bill for the infrastructure build-out would come to $5tn (not including a tip).  Who knows if that‚Äôs right, but we have good reason to expect close to half a trillion in spending next year.  Meanwhile, the biggest spenders (Microsoft, Alphabet, Amazon, Meta and Oracle) had only about $350bn in the bank, collectively, as of the end of the third quarter.  (‚ÄúUnhedged,‚Äù <em>Financial Times</em>, November 13)</p><p>The firms mentioned above derive healthy cash flows from their very strong non-AI businesses.  But the massive, winner-take-all arms race in AI is requiring some to take on debt.  <strong>In fact, it‚Äôs reasonable to think one of the reasons they‚Äôre spending vast sums is to make it hard for lesser firms to keep up.</strong> </p><p>Oracle, Meta, and Alphabet have issued 30-year bonds to finance AI investments.  In the case of the latter two, the yields on the bonds exceed those on Treasurys of like maturity by 100 basis points or less.  Is it prudent to accept 30 years of technological uncertainty to make a fixed-income investment that yields little more than riskless debt?  And will the investments funded with debt ‚Äì in chips and data centers ‚Äì maintain their level of productivity long enough for these 30-year obligations to be repaid?</p><p>On November 14, Alex Kantrowitz‚Äôs <em>Big Technology Podcast</em> carried a conversation with Gil Luria, Head of Technology Research at financial services firm D.A. Davidson, primarily regarding the use of debt in the AI sector.  Here‚Äôs some of what Luria had to say:</p><ul><li data-list="4" data-level="1"><p>Healthy behavior is being practiced by ‚Äú. . . reasonable, thoughtful business leaders, like the ones at Microsoft, Amazon, and Google that are making sound investments in growing the capacity to deliver AI. And the reason they can make sound investments is that they have all the customers. . .  And so, when they make investments, they‚Äôre using cash on their balance sheets; they have tremendous cash flow to back it up; they understand that it‚Äôs a risky investment; and they balance it out.‚Äù  </p></li><li data-list="4" data-level="1"><p>Unhealthy behavior ‚Äì Here he describes ‚Äú. . . a startup that is borrowing money to build data centers for another startup.  They‚Äôre both losing tremendous amounts of cash, and yet they‚Äôre somehow being able to raise this debt capital in order to fund this buildout, again without having the customers or the visibility into those investments paying off.‚Äù</p></li><li data-list="4" data-level="1"><p>‚ÄúSo there‚Äôs a whole range of behaviors between healthy and unhealthy, and we just need to sort that out so we don‚Äôt make the mistakes of the past.‚Äù</p></li><li data-list="4" data-level="1"><p>‚ÄúThere are certain things we finance through equity, through ownership, and there are certain things we finance through debt, through an obligation to pay down interest over time.  And as a society, for the longest time, we‚Äôve had those two pieces in their right place.  Debt is when I have a predictable cash flow and/or an asset that can back that loan, and then it makes sense for me to exchange capital now for future cash flows to the lender. . . .  We use equity for investing in more speculative things, for when we want to grow and we want to own that growth, but we‚Äôre not sure about what the cash flow is going to be.  That‚Äôs how a normal economy functions.  When you start confusing the two you get yourself in trouble.‚Äù</p></li></ul><p>Among potentially worrisome factors, Luria cites these:</p><ul><li data-list="5" data-level="1"><p>‚ÄúA speculative asset . . . we don‚Äôt know how much of it we‚Äôre really going to need in two to five years.‚Äù</p></li><li data-list="5" data-level="1"><p>Lender personnel with incentives to make loans but no exposure to long-term consequences </p></li><li data-list="5" data-level="1"><p>The possibility that the supply of AI capacity catches up with or surpasses the demand</p></li><li data-list="5" data-level="1"><p>The chance that future generations of AI chips will be more powerful, obsoleting existing ones or reducing their value as backing for debt</p></li><li data-list="5" data-level="1"><p>Powerful competitors who vie for market share by cutting rental rates and running losses</p></li></ul><p>Here are some important paragraphs from Azeem Azhar‚Äôs <em>Exponential View</em> of October 18:</p><p>When does an AI boom tip into a bubble?  [Investor and engineer] Paul Kedrosky points to the Minsky moment ‚Äì the inflection point when credit expansion exhausts its good projects and starts chasing bad ones, funding marginal deals with vendor financing and questionable coverage ratios.  For AI infrastructure, that shift may already be underway; the telltale signs include hyperscalers‚Äô capex outpacing revenue momentum and lenders sweetening terms to keep the party alive.</p><p>Paul makes a compelling case.  We‚Äôve entered speculative finance territory ‚Äì arguably past the tentative stage ‚Äì and recent deals will set dangerous precedents.  As Paul warns, this financing will ‚Äúcreate templates for future such transactions,‚Äù spurring rapid expansion in junk issuance and SPV proliferation among hyperscalers chasing dominance at any cost. . . . </p><p><strong>For AI infrastructure, the warning signs are flashing: vendor financing proliferates, coverage ratios thin, and hyperscalers leverage balance sheets to maintain capex velocity even as revenue momentum lags.  We see both sides ‚Äì genuine infrastructure expansion alongside financing gymnastics that recall the 2000 telecom bust.  The boom may yet prove productive, but only if revenue catches up before credit tightens.</strong> When does healthy strain become systemic risk?  That‚Äôs the question we must answer before the market does.  (Emphasis added)</p><p>Azhar references the use of off-balance sheet financing via special-purpose vehicles, or SPVs, which were among the biggest contributors to Enron‚Äôs precariousness and eventual collapse.  A company and its partners set up an SPV for some specific purpose(s) and supply the equity capital.  The parent company may have operating control, but because it doesn‚Äôt have majority ownership, it doesn‚Äôt consolidate the SPV on its financial statements.  The SPV takes on debt, but that debt doesn‚Äôt appear on the parent‚Äôs books.  The parent may be an investment grade borrower, but likewise, the debt isn‚Äôt an obligation of the parent or guaranteed by it.  Today‚Äôs debt may be backed by promised rent from a data center tenant ‚Äì sometimes an equity partner ‚Äì but the debt isn‚Äôt a direct obligation of the equity partner either.  Essentially, an SPV is a way to make it look like a company isn‚Äôt doing the things the SPV is doing and doesn‚Äôt have the debt the SPV does.  (Private equity funds and private credit funds are highly likely to be found among the partners and lenders in these entities.)  </p><p>As I quoted earlier, according to Perez (who wrote on the heels of the dot-com bubble), ‚Äúwhat enabled the deployment period were the money-losing investments.‚Äù  Early investment is lost in the ‚ÄúMinsky moment,‚Äù in which unwise commitments made in an extended up-cycle encounters value destruction in a correction.  And there are three things we know for sure about the use of debt:</p><ul><li data-list="3" data-level="1"><p>it magnifies losses if there are losses (just as it magnifies the hoped-for gains if they materialize), </p></li><li data-list="3" data-level="1"><p>it increases the probability of a venture failing if it encounters a difficult moment, and</p></li><li data-list="3" data-level="1"><p>despite the layer of equity beneath it, it puts lenders‚Äô capital at risk if the difficult moment is bad enough.</p></li></ul><p>One key risk to consider is the possibility that the boom in data center construction will result in a glut.  Some data centers may be rendered uneconomic, and some owners may go bankrupt.  In that case, a new generation of owners might buy up centers at pennies on the dollar from lenders who foreclosed on them, reaping profits when the industry stabilizes.  This is a process through which ‚Äúcreative destruction‚Äù brings markets into equilibrium and reduces costs to levels that make future business profitable.</p><p><strong>Debt is neither a good thing nor a bad thing <em>per se</em>. Likewise, the use of leverage in the AI industry shouldn‚Äôt be applauded or feared.  It all comes down to the proportion of debt in the capital structure; the quality of the assets or cash flows you‚Äôre lending against; the borrowers‚Äô alternative sources of liquidity for repayment; and the adequacy of the safety margin obtained by lenders.  We‚Äôll see which lenders maintain discipline in today‚Äôs heady environment.</strong></p><p>It‚Äôs worth noting in this connection that Oaktree has made a few investments in data centers, and our parent, Brookfield, is raising a $10 billion fund for investment in AI infrastructure.  Brookfield is putting up its own money and has equity commitments from sovereign wealth funds and Nvidia, to which it intends to apply ‚Äúprudent‚Äù debt.  Brookfield‚Äôs investments seem likely to go largely into geographies that are less saturated with data centers and for infrastructure to supply the vast amounts of electric power that data centers will require.  Of course, we‚Äôre both doing these things on the basis of what we think are prudent decisions.  </p><p><strong>I know I don‚Äôt know enough to opine on AI.  But I do know something about debt, and it‚Äôs this:  </strong></p><ul><li data-list="3" data-level="1"><p><strong>It‚Äôs okay to supply debt financing for a venture where the outcome is uncertain.</strong> </p></li><li data-list="3" data-level="1"><p><strong>It‚Äôs not okay where the outcome is purely a matter of conjecture.</strong> </p></li><li data-list="3" data-level="1"><p><strong>Those who understand the difference still have to make the distinction correctly.</strong></p></li></ul><p>The FT‚Äôs <em>Unhedged</em> quotes Chong Sin, lead analyst for CMBS research at JPMorgan, as saying, ‚Äú. . . in our conversations with investment grade ABS and CMBS investors, one often-cited concern is whether they want to take on the residual value risk of data centers when the bonds mature.‚Äù  I‚Äôm glad potential lenders are asking the kind of questions they should.  </p><p>Here‚Äôs how to think about the intersection of debt and AI according to Bob O‚ÄôLeary, Oaktree‚Äôs co-CEO and co-portfolio manager of our Opportunities Funds:</p><p><strong>Most technological advances develop into winner-takes-all or winner-takes-most competitions.  The ‚Äúright‚Äù way to play this dynamic is through equity, not debt.</strong> Assuming you can diversify your equity exposures so as to include the eventual winner, the massive gain from the winner will more than compensate for the capital impairment on the losers.  That‚Äôs the venture capitalist‚Äôs time-honored formula for success.</p><p>The precise opposite is true of a diversified pool of debt exposures.  You‚Äôll only make your coupon on the winner, and that will be grossly insufficient to compensate for the impairments you‚Äôll experience on the debt of the losers.  </p><p><strong>Of course, if you can‚Äôt identify the pool of companies from which the winner will emerge, the difference between debt and equity is irrelevant ‚Äì you‚Äôre a zero either way.</strong> I mention this because that‚Äôs precisely what happened in search and social media: early leaders (Lycos in search and MySpace in social media) lost out spectacularly to companies that emerged later (Google in search and Facebook in social media).</p><p><span>Trying to Get to a Conclusion</span></p><p>There can be no doubt that today‚Äôs behavior is ‚Äúspeculative,‚Äù defined as based on speculation regarding the future.  There‚Äôs also no doubt that no one knows what the future holds, but investors are betting huge sums on that future.</p><p>In that connection, I want to say a little about the unique nature of AI.  The AI revolution is different from the technological revolutions that preceded it in ways that are both <span>wonderful</span> and <span>worrisome</span>. It feels to me like a genie has been released from a bottle, and it isn‚Äôt going back in:</p><p><strong>AI may not be a tool for mankind, but rather something of a replacement.</strong> It may be capable of taking over cognition, on which humans have thus far had a monopoly.  Because of this, it‚Äôs likely to be different in kind from prior developments, not just in degree.  (More on this in my postscript.)</p><p><strong>AI technology is progressing at an incredibly rapid clip</strong>, possibly leaving scant time for mankind to adjust.  I‚Äôll provide two examples:</p><br><ul><li data-list="2" data-level="1"><p>Coding, which we called ‚Äúcomputer programming‚Äù 60 years ago, is the canary in the coal mine in terms of the impact of AI.  In many advanced software teams, developers no longer write the code; they type in what they want, and AI systems generate the code for them.  Coding performed by AI is at a world-class level, something that wasn‚Äôt so just a year ago.  According to my guide here, ‚ÄúThere is no speculation about whether or not human replacement will take place in that vertical.‚Äù</p></li><li data-list="2" data-level="1"><p>In the field of digital advertising, when users log into an app, AI engages in ‚Äúad matching,‚Äù showing them ads tailored to the preferences displayed by their prior surfing.  No humans need apply to do this job.</p></li></ul><p>Perhaps most importantly, <strong>the growth of demand for AI seems totally unpredictable.</strong> As one of my younger advisers explained, ‚Äúthe speed and scale of improvement mean it‚Äôs incredibly hard to forecast demand for AI.  Adoption today may have nothing to do with adoption tomorrow, because a year or two from now, AI may be able to do 10x or 100x what it can do today.  Thus, how can anyone say how many data centers will be needed?  And how can even successful companies know how much computing capacity to contract for?‚Äù</p><p>With differences like these, how can anyone correctly judge what AI implies for the future?</p><p>*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *</p><p>One of the things occupying many observers at this juncture ‚Äì including me ‚Äì is the search for parallels to past bubbles.  Here‚Äôs some historical perspective from a recent article in <em>Wired</em>:</p><p>AI‚Äôs closest historical analogue here may be not electric lighting but radio.  When RCA started broadcasting in 1919, it was immediately clear that it had a powerful information technology on its hands.  But less clear was how that would translate into business. ‚ÄúWould radio be a loss-leading marketing for department stores?  A public service for broadcasting Sunday sermons?  An ad-supported medium for entertainment?‚Äù [Brent Goldfarb and David A. Kirsch of the University of Maryland] write.  ‚ÄúAll were possible.  All were subjects of technological narratives.‚Äù  As a result, radio turned into one of the biggest bubbles in history ‚Äì peaking in 1929, before losing 97 percent of its value in the crash.  This wasn‚Äôt an incidental sector; RCA was, along with Ford Motor Company, the most high-traded stock on the market.  It was, as <em>The New Yorker</em> recently wrote, ‚Äúthe Nvidia of its day.‚Äù . . .</p><p>In 1927, Charles Lindbergh flew the first solo nonstop transatlantic flight from New York to Paris. . . .  It was the biggest tech demo of the day, and it became an enormous, ChatGPT-launch-level coordinating event ‚Äì a signal to investors to pour money into the industry.</p><p>‚ÄúExpert investors appreciated correctly the importance of airplanes and air travel,‚Äù Goldfarb and Kirsch write, but <strong>‚Äúthe narrative of inevitability largely drowned out their caution.  Technological uncertainty was framed as opportunity, not risk.  The market overestimated how quickly the industry would achieve technological viability and profitability.‚Äù</strong></p><p>As a result, the bubble burst in 1929 ‚Äì from its peak in May, aviation stocks dropped 96 percent by May 1932. . . .</p><p>It‚Äôs worth reiterating that two of the closest analogs AI seems to have in tech bubble history are aviation and broadcast radio.  Both were wrapped in high degrees of uncertainty and both were hyped with incredibly powerful coordinating narratives.  Both were seized on by pure play companies seeking to capitalize on the new game-changing tech, and both were accessible to the retail investors of the day.  Both helped inflate a bubble so big that when it burst, in 1929, it left us with the Great Depression.  (‚ÄúAI Is the Bubble to Burst Them All,‚Äù Brian Merchant, <em>Wired</em>, October 27 ‚Äì emphasis added. N.b., the Depression had many causes beyond the bursting of the radio/aviation bubble.)  </p><p>Derek Thompson, who supplied the quote with which I opened this memo, ended his newsletter with some terrific historical perspective:</p><p>The railroads were a bubble and they transformed America.  Electricity was a bubble, and it transformed America.  The broadband build-out of the late-1990s was a bubble that transformed America.  I am not rooting for a bubble, and quite the contrary, I hope that the US economy doesn‚Äôt experience another recession for many years.  <strong>But given the amount of debt now flowing into AI data center construction, I think it‚Äôs unlikely that AI will be the first transformative technology that isn‚Äôt overbuilt and doesn‚Äôt incur a brief painful correction.</strong> (‚ÄúAI Could Be the Railroad of the 21<sup>st</sup> Century.  Brace Yourself.‚Äù November 4 ‚Äì emphasis added)</p><p>The skeptics readily cite ways in which today‚Äôs events are comparable to the internet bubble:</p><ul><li data-list="6" data-level="1"><p>A change-the-world technology</p></li><li data-list="6" data-level="1"><p>Exuberant, speculative behavior </p></li><li data-list="6" data-level="1"><p>The role of FOMO</p></li><li data-list="6" data-level="1"><p>Suspect, circular deals</p></li><li data-list="6" data-level="1"><p>The use of SPVs</p></li><li data-list="6" data-level="1"><p>$1 billion seed rounds </p></li></ul><p>The supporters have reasons why the comparison isn‚Äôt appropriate:</p><ul><li data-list="5" data-level="1"><p>An existing product for which there is strong demand</p></li><li data-list="5" data-level="1"><p>One billion users already (many times the number of internet users at the height of the bubble)</p></li><li data-list="5" data-level="1"><p>Well-established main players with revenues, profits, and cash flow</p></li><li data-list="5" data-level="1"><p>The absence of an IPO craze with prices doubling in a day</p></li><li data-list="5" data-level="1"><p>Reasonable p/e ratios for the established participants </p></li></ul><p>I‚Äôll elaborate regarding the first of the proposed non-comparable factors.  Unlike in the internet bubble, AI products already exist at scale, the demand for them is exploding, and they‚Äôre producing revenues in rapidly increasing amounts.  For example, Anthropic, one of the two leaders in producing models for AI coding as described on page 12, is said to have ‚Äú10x-ed‚Äù its revenues in each of the last two years (for those who didn‚Äôt study higher math, that‚Äôs 100x in two years).  Revenues from Claude Code, a program for coding that Anthropic introduced earlier this year, already are said to be running at an annual rate of $1 billion.  Revenues for the other leader, Cursor, were $1 million in 2023 and $100 million in 2024, and they, too, are expected to reach $1 billion this year. </p><p>As to the final bullet point, see the table below, which comes from Goldman Sachs via Derek Thompson.  You‚Äôll notice that during the internet bubble of 1998-2000, the p/e ratios were much higher for Microsoft, Cisco, and Oracle than they are today for the biggest AI players ‚Äì Nvidia, Microsoft, Alphabet, Amazon, and Meta (OpenAI doesn‚Äôt have earnings).  In fact, Microsoft‚Äôs on a half-off sale relative to its p/e 26 years ago!  In the first bubble I witnessed ‚Äì surrounding the Nifty-Fifty in 1969-72 ‚Äì the p/e ratios for the leading companies were even higher than those of 1998-2000. </p><br><div><p><img src="https://www.oaktreecapital.com/images/oaktreecaplibraries/insights/memos/commentary/is-it-a-bubble-exhibit7.jpg?sfvrsn=d6aa2866_2" alt="Exhibit 7"></p></div><p><span>In Conclusion</span></p><p>For my final citation, I‚Äôll look to Sam Altman of OpenAI.  His comments seem to me to capture the essence of what‚Äôs going on:</p><p>‚ÄúWhen bubbles happen, smart people get overexcited about a kernel of truth,‚Äù Mr. Altman told reporters this year.  ‚ÄúAre we in a phase where investors as a whole are overexcited about A.I.?  My opinion is yes.  Is A.I. the most important thing to happen in a very long time?  My opinion is also yes.‚Äù  (<em>The New York Times</em>, November 20)</p><p>But do I have a bottom line?  Yes, I do.  Alan Greenspan‚Äôs phrase, mentioned earlier, serves as an excellent way to sum up a stock market bubble: ‚Äúirrational exuberance.‚Äù  <strong>There is no doubt that investors are applying exuberance with regard to AI.  The question is whether it‚Äôs irrational.  Given the vast potential of AI but also the large number of enormous unknowns, I think virtually no one can say for sure.</strong> We can theorize about whether the current enthusiasm is excessive, but we won‚Äôt know until years from now whether it was.  Bubbles are best identified in retrospect.</p><p><strong>While the parallels to past bubbles are inescapable, believers in the technology will argue that ‚Äúthis time it‚Äôs different.‚Äù</strong> Those four words are heard in virtually every bubble, explaining why the present situation isn‚Äôt a bubble, unlike the analogous prior ones.  On the other hand, Sir John Templeton, who in 1987 drew my attention to those four words, was quick to point out that 20% of the time things really are different.  <strong>But on the third hand, it must be borne in mind that behavior based on the belief that it‚Äôs different is what causes it to <span>not</span> be different!</strong></p><p>Today‚Äôs situation calls to mind a comment attributed to American economist Stuart Chase about faith.  I believe it‚Äôs also applicable to AI (as well as to gold and cryptocurrencies):</p><p>For those who believe, no proof is necessary.  For those who don't believe, no proof is possible.</p><p>Here‚Äôs my actual bottom line:</p><ul><li data-list="7" data-level="1"><p>There‚Äôs a consistent history of transformational technologies generating excessive enthusiasm and investment, resulting in more infrastructure than is needed and asset prices that prove to have been too high.  The excesses accelerate the adoption of the technology in a way that wouldn‚Äôt occur in their absence.  The common word for these excesses is ‚Äúbubbles.‚Äù  </p></li><li data-list="7" data-level="1"><p>AI has the potential to be one of the greatest transformational technologies of all time.</p></li><li data-list="7" data-level="1"><p>As I wrote just above, AI is currently the subject of great enthusiasm.  If that enthusiasm doesn‚Äôt produce a bubble conforming to the historical pattern, that will be a first.</p></li><li data-list="7" data-level="1"><p>Bubbles created in this process usually end in losses for those who fuel them.</p></li><li data-list="7" data-level="1"><p>The losses stem largely from the fact that the technology‚Äôs newness renders the extent and timing of its impact unpredictable.  This in turn makes it easy to judge companies too positively amid all the enthusiasm and difficult to know which will emerge as winners when the dust settles.</p></li><li data-list="7" data-level="1"><p>There can be no way to participate fully in the potential benefits from the new technology without being exposed to the losses that will arise if the enthusiasm and thus investors‚Äô behavior prove to have been excessive.  </p></li><li data-list="7" data-level="1"><p>The use of debt in this process ‚Äì which the high level of uncertainty usually precluded in past technological revolutions ‚Äì has the potential to magnify all of the above this time.</p></li></ul><p><strong>Since no one can say definitively whether this is a bubble, I‚Äôd advise that no one should go all-in without acknowledging that they face the risk of ruin if things go badly.  But by the same token, no one should stay all-out and risk missing out on one of the great technological steps forward.</strong> A moderate position, applied with selectivity and prudence, seems like the best approach.</p><p>Finally, it‚Äôs essential to bear in mind that there are no magic words in investing.  These days, people promoting real estate funds say, ‚ÄúOffice buildings are so yesterday, but we‚Äôre investing in the future through data centers,‚Äù whereupon everyone nods in agreement.  But data centers can be in shortage or in oversupply, and rental rates can surprise to the upside or the downside.  As a result, they can be profitable . . . or not.  <strong>Intelligent investment in data centers, and thus in AI ‚Äì <span>like everything else</span> ‚Äì requires sober, insightful judgment and skillful implementation.</strong></p><br><!-- Date -->
<p>December 9, 2025</p><p>P.S.: The following has nothing to do with the financial markets or the question of whether AI is the subject of a bubble.  My topic is the impact of AI on society through joblessness and purposelessness.  You needn‚Äôt read it ‚Äì that‚Äôs why it‚Äôs a postscript ‚Äì but it‚Äôs important to me, and I've been looking for a place to say a few words about it.</p><p>On November 18, a research note from Barclays described Fed Governor Christopher Waller as having ‚Äúhighlighted how recent stock market enthusiasm around AI has not yet translated into job creation.‚Äù  This strikes me as paradoxical given my sense that one of AI‚Äôs main impacts will be to increase productivity and thus eliminate jobs.  That is the source of my concern.</p><p>I view AI primarily as an incredible labor-saving device.  Joe Davis, Global Chief Economist and Global Head of the Investment Strategy Group at Vanguard, says, ‚Äúfor most jobs ‚Äì likely four out of five ‚Äì AI‚Äôs impact will result in a mixture of innovation and automation, and could save about 43% of the time people currently spend on their work tasks.‚Äù  (<em>Exponential View</em>, September 3)  </p><p><strong>I find the resulting outlook for employment terrifying.</strong> I am enormously concerned about what will happen to the people whose jobs AI renders unnecessary, or who can‚Äôt find jobs because of it.  The optimists argue that ‚Äúnew jobs have always materialized after past technological advances.‚Äù  I hope that‚Äôll hold true in the case of AI, but hope isn‚Äôt much to hang one‚Äôs hat on, and I have trouble figuring out where those jobs will come from.  <strong>Of course, I‚Äôm not much of a futurist or a financial optimist, and that‚Äôs why it‚Äôs a good thing I shifted from equities to bonds in 1978.</strong></p><p>The other thing the optimists say is that ‚Äúthe beneficial impact of AI on productivity will cause a huge acceleration in GDP growth.‚Äù  Here I have specific quibbles:  </p><ul><li data-list="2" data-level="1"><p>The change in GDP can be thought of as the change in hours worked times the change in output per hour (aka ‚Äúproductivity‚Äù).  The role of AI in increasing productivity means it will take fewer hours worked ‚Äì meaning fewer workers ‚Äì to produce the goods we need.</p></li><li data-list="2" data-level="1"><p>Or, viewed from the other direction, maybe the boom in productivity will mean a lot more goods can be produced with the same amount of labor.  But if a lot of jobs are lost to AI, how will people be able to afford the additional goods AI enables to be produced?</p></li></ul><p><strong>I find it hard to imagine a world in which AI works shoulder-to-shoulder with all the people who are employed today.  How can employment not decline?</strong> AI is likely to replace large numbers of entry-level workers, people who process paper without applying judgment, and junior lawyers who scour the lawbooks for precedents.  Maybe even junior investment analysts who create spreadsheets and compile presentation materials.  It‚Äôs said that AI can read an MRI better than the average doctor.  Driving is one of the most populous professions in America, and driverless vehicles are already arriving; where will all the people who currently drive taxis, limos, buses, and trucks find jobs?</p><p>I imagine government‚Äôs response will be something called ‚Äúuniversal basic income.‚Äù  The government will simply mail checks to the millions for whom there are no jobs.  But the worrier in me finds problems in this, too:</p><ul><li data-list="2" data-level="1"><p><strong>Where will the money come from for those checks?</strong> The job losses I foresee imply reduced income tax receipts and increased spending on entitlements.  This puts a further burden on the declining segment of the population that is working and implies even greater deficits ahead.  In this new world, will governments be able to fund ever-increasing deficits?  </p></li><li data-list="2" data-level="1"><p>And more importantly, <strong>people get a lot more from jobs than just a paycheck.</strong> A job gives them a reason to get up in the morning, imparts structure to their day, gives them a productive role in society and self-respect, and presents them with challenges, the overcoming of which provides satisfaction.  How will these things be replaced?  I worry about large numbers of people receiving subsistence checks and sitting around idle all day.  I worry about the correlation between the loss of jobs in mining and manufacturing in recent decades and the incidence of opioid addiction and shortening of lifespans.</p></li></ul><p>And by the way, if we eliminate large numbers of junior lawyers, analysts, and doctors, where will we get the experienced veterans capable of solving serious problems requiring judgment and pattern recognition honed over decades?</p><p>What jobs won‚Äôt be eliminated?  What careers should our children and grandchildren prepare for?  Think about the jobs that machines can‚Äôt perform.  My list starts with plumbers, electricians, and masseurs ‚Äìphysical tasks.  Maybe nurses will earn more than doctors because they deliver hands-on care.  And what distinguishes the best artists, athletes, doctors, lawyers, and hopefully investors?  I think it‚Äôs something called talent or insight, which AI might or might not be able to replicate.  But how many people at the top of those professions are needed?  A past presidential candidate said he would give laptops to everyone who lost their job to offshoring.  How many laptop operators do we need?</p><p>Finally, I‚Äôm concerned that a small number of highly educated multi-billionaires living on the coasts will be viewed as having created technology that puts millions out of work.  <strong>This promises even more social and political division than we have now, making the world ripe for populist demagoguery.</strong> </p><p>I‚Äôve seen incredible progress over the course of my lifetime, but in many ways I miss the simpler world I grew up in. I worry that this will be another big one.  <strong>I get no pleasure from this recitation.  Will the optimists please explain why I‚Äôm wrong?</strong></p><p>Interestingly in this connection, Vanguard‚Äôs Joe Davis points out that more Americans are turning 65 in 2025 than in any preceding year, and that approximately 16 million baby boomers will retire between now and 2035.  Could AI merely make up for that?  There‚Äôs an optimistic take for you.</p><p>HM</p><p>Legal Information and Disclosures</p><p><span><em>This memorandum expresses the views of the author as of the date indicated and such views are subject to change without notice. Oaktree has no duty or obligation to update the information contained herein. Further, Oaktree makes no representation, and it should not be assumed, that past investment performance is an indication of future results. Moreover, wherever there is the potential for profit there is also the possibility of loss.</em>
 </span>
</p><p><span><em>This memorandum is being made available for educational purposes only and should not be used for any other purpose. The information contained herein does not constitute and should not be construed as an offering of advisory services or an offer to sell or solicitation to buy any securities or related financial instruments in any jurisdiction. Certain information contained herein concerning economic trends and performance is based on or derived from information provided by independent third-party sources. Oaktree Capital Management, L.P. (‚ÄúOaktree‚Äù) believes that the sources from which such information has been obtained are reliable; however, it cannot guarantee the accuracy of such information and has not independently verified the accuracy or completeness of such information or the assumptions on which such information is based. </em>
 </span>
</p><p><span><em>This memorandum, including the information contained herein, may not be copied, reproduced, republished, or posted in whole or in part, in any form without the prior written consent of Oaktree.</em>
 </span>
</p><p><em>¬© 2025 Oaktree Capital Management, L.P.</em>
</p>
						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Auto-grading decade-old Hacker News discussions with hindsight (346 pts)]]></title>
            <link>https://karpathy.bearblog.dev/auto-grade-hn/</link>
            <guid>46220540</guid>
            <pubDate>Wed, 10 Dec 2025 17:23:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://karpathy.bearblog.dev/auto-grade-hn/">https://karpathy.bearblog.dev/auto-grade-hn/</a>, See on <a href="https://news.ycombinator.com/item?id=46220540">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    

    
        

        <p>
            <i>
                <time datetime="2025-12-10T15:00Z">
    10 Dec, 2025
</time>
            </i>
        </p>
    

    <p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/karpathy/hnhero.webp" alt="hnhero"></p>
<p>TLDR: <a href="https://karpathy.ai/hncapsule/">https://karpathy.ai/hncapsule/</a></p>
<hr>
<p>Yesterday I stumbled on this HN thread <a href="https://news.ycombinator.com/item?id=46205632">Show HN: Gemini Pro 3 hallucinates the HN front page 10 years from now</a>, where Gemini 3 was hallucinating the frontpage of 10 years from now. One of the comments struck me a bit more though - Bjartr linked to the <a href="https://news.ycombinator.com/front?day=2015-12-09">HN frontpage from exactly 10 years ago</a>, i.e. December 2015. I was reading through the discussions of 10 years ago and mentally grading them for prescience when I realized that an LLM might actually be a lot better at this task. I copy pasted one of the article+comment threads manually into ChatGPT 5.1 Thinking and it gave me a beautiful analysis of what people thought + what actually happened in retrospect, even better and significantly more detailed than what I was doing manually. I realized that this task is actually a really good fit for LLMs and I was looking for excuses to vibe code something with the newly released Opus 4.5, so I got to work. I'm going to get all the front pages of December (31 days, 30 articles per day), get ChatGPT 5.1 Thinking to do the analysis, and present everything in a nice way for historical reading.</p>
<p>There are two macro reasons for why I think the exercise is interesting more generally:</p>
<ol>
<li>I believe it is quite possible and desirable to train your forward future predictor given training and effort.</li>
<li>I was reminded again of my tweets that said <em>"Be good, future LLMs are watching"</em>. You can take that in many directions, but here I want to focus on the idea that future LLMs <strong>are</strong> watching. Everything we do today might be scrutinized in great detail in the future because doing so will be "free". A lot of the ways people behave currently I think make an implicit "security by obscurity" assumption. But if intelligence really does become too cheap to meter, it will become possible to do a perfect reconstruction and synthesis of everything. LLMs are watching (or humans using them might be). Best to be good.</li>
</ol>
<p>Vibe coding the actual project was relatively painless and took about 3 hours with Opus 4.5, with a few hickups but overall very impressive. The repository is on GitHub here: <a href="https://github.com/karpathy/hn-time-capsule">karpathy/hn-time-capsule</a>. Here is the progression of what the code does:</p>
<ul>
<li>Given a date, download the frontpage of 30 articles</li>
<li>For each article, download/parse the article itself and the full comment thread using Algolia API.</li>
<li>Package up everything into a markdown prompt asking for the analysis. Here is the prompt prefix I used:</li>
</ul>
<div><pre><span></span>The following is an article that appeared on Hacker News 10 years ago, and the discussion thread.

Let's use our benefit of hindsight now in 6 sections:

1. Give a brief summary of the article and the discussion thread.
2. What ended up happening to this topic? (research the topic briefly and write a summary)
3. Give out awards for "Most prescient" and "Most wrong" comments, considering what happened.
4. Mention any other fun or notable aspects of the article or discussion.
5. Give out grades to specific people for their comments, considering what happened.
6. At the end, give a final score (from 0-10) for how interesting this article and its retrospect analysis was.

As for the format of Section 5, use the header "Final grades" and follow it with simply an unordered list of people and their grades in the format of "name: grade (optional comment)". Here is an example:

Final grades
- speckx: A+ (excellent predictions on ...)
- tosh: A (correctly predicted this or that ...)
- keepamovin: A
- bgwalter: D
- fsflover: F (completely wrong on ...)

Your list may contain more people of course than just this toy example. Please follow the format exactly because I will be parsing it programmatically. The idea is that I will accumulate the grades for each account to identify the accounts that were over long periods of time the most prescient or the most wrong.

As for the format of Section 6, use the prefix "Article hindsight analysis interestingness score:" and then the score (0-10) as a number. Give high scores to articles/discussions that are prominent, notable, or interesting in retrospect. Give low scores in cases where few predictions are made, or the topic is very niche or obscure, or the discussion is not very interesting in retrospect.

Here is an example:
Article hindsight analysis interestingness score: 8
---
</pre></div>
<ul>
<li>Submit prompt to GPT 5.1 Thinking via the OpenAI API</li>
<li>Collect and parse the results</li>
<li>Render the results into static HTML web pages for easy viewing</li>
<li>Host the html result pages on my website: <a href="https://karpathy.ai/hncapsule/">https://karpathy.ai/hncapsule/</a></li>
<li>Host all the intermediate results of the <code>data</code> directory if someone else would like to play. It's the file <code>data.zip</code> under the exact same url prefix (intentionally avoiding a direct link).</li>
</ul>
<p>I spent a few hours browsing around and found it to be very interesting. A few example threads just for fun:</p>
<ul>
<li>December 3 2015 <a href="https://karpathy.ai/hncapsule/2015-12-03/index.html#article-10669891">Swift went open source</a>.</li>
<li>December 6 2015 <a href="https://karpathy.ai/hncapsule/2015-12-06/index.html#article-10685407">Launch of Figma</a></li>
<li>December 11 2015 <a href="https://karpathy.ai/hncapsule/2015-12-11/index.html#article-10720176">original announcement of OpenAI</a> :').</li>
<li>December 16 2015 <a href="https://karpathy.ai/hncapsule/2015-12-16/index.html#article-10744206">geohot is building Comma</a></li>
<li>December 22 2015 <a href="https://karpathy.ai/hncapsule/2015-12-22/index.html#article-10774865">SpaceX launch webcast: Orbcomm-2 Mission</a></li>
<li>December 28 2015 <a href="https://karpathy.ai/hncapsule/2015-12-28/index.html#article-10799261">Theranos struggles</a></li>
</ul>
<p>And then when you navigate over to the <a href="https://karpathy.ai/hncapsule/hall-of-fame.html">Hall of Fame</a>, you can find the top commenters of Hacker News in December 2015, sorted by imdb-style score of their grade point average. In particular, congratulations to pcwalton, tptacek, paulmd, cstross, greglindahl, moxie, hannob, 0xcde4c3db, Manishearth, johncolanduoni - GPT 5.1 Thinking found your comments very insightful and prescient. You can also scroll all the way down to find the noise of HN, which I think we're all familiar with too :)</p>
<p>My <a href="https://github.com/karpathy/hn-time-capsule">code</a> (wait, Opus' code?) on GitHub can be used to reproduce or tweak the results. Running 31 days of 30 articles through GPT 5.1 Thinking meant <code>31 * 30 =</code> 930 LLM queries and cost about $58 and somewhere around ~1 hour. The LLM megaminds of the future might find this kind of a thing a lot easier, a lot faster and a lot cheaper.</p>


    

    
        

        
            


        

        
            
        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Valve: HDMI Forum Continues to Block HDMI 2.1 for Linux (574 pts)]]></title>
            <link>https://www.heise.de/en/news/Valve-HDMI-Forum-Continues-to-Block-HDMI-2-1-for-Linux-11107440.html</link>
            <guid>46220488</guid>
            <pubDate>Wed, 10 Dec 2025 17:20:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.heise.de/en/news/Valve-HDMI-Forum-Continues-to-Block-HDMI-2-1-for-Linux-11107440.html">https://www.heise.de/en/news/Valve-HDMI-Forum-Continues-to-Block-HDMI-2-1-for-Linux-11107440.html</a>, See on <a href="https://news.ycombinator.com/item?id=46220488">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        

        <p>The HDMI Forum, responsible for the HDMI specification, continues to stonewall open source. Valve's Steam Machine theoretically supports HDMI 2.1, but the <a href="https://www.heise.de/news/Linux-Konsole-Valve-kuendigt-neue-Steam-Machine-an-11076221.html?from-en=1">mini-PC is software-limited to HDMI 2.0</a>. As a result, more than 60 frames per second at 4K resolution are only possible with limitations.</p>
<!-- RSPEAK_STOP -->




  


<!-- RSPEAK_START -->

<p>In a statement to <a href="https://arstechnica.com/gaming/2025/12/why-wont-steam-machine-support-hdmi-2-1-digging-in-on-the-display-standard-drama/" rel="external noopener" target="_blank">Ars Technica, a Valve spokesperson confirmed</a> that HDMI 2.1 support is "still a work-in-progress on the software side." "We‚Äôve been working on trying to unblock things there."</p>
<p>The Steam Machine uses an AMD Ryzen APU with a Radeon graphics unit. Valve strictly adheres to open-source drivers, but the HDMI Forum is unwilling to disclose the 2.1 specification. According to Valve, they have validated the HDMI 2.1 hardware under Windows to ensure basic functionality.</p>
<!-- RSPEAK_STOP -->

  




<!-- RSPEAK_START -->

<h3 id="nav_no_change_after__0">No Change After Almost Two Years</h3>
<p>The restriction imposed by the HDMI Forum <a href="https://www.heise.de/news/AMD-HDMI-Forum-verhindert-HDMI-2-1-unter-Linux-9643729.html?from-en=1">was already criticized in early 2024 by an AMD employee responsible for Linux</a>. Even then, according to AMD, they had submitted a functional, HDMI 2.1-compatible driver, which the HDMI Forum rejected.</p>
<p>"Unfortunately, the HDMI Forum rejected our proposal," it was stated at the time. "At this time an open source HDMI 2.1 implementation is not possible without running afoul of the HDMI Forum requirements."</p>
<p>Only HDMI 2.1 offers sufficient bandwidth for 120 or 144 Hertz at 3840&nbsp;√ó 2160 pixels without compression. Furthermore, this version introduced manufacturer-independent variable refresh rates (HDMI VRR). Valve enables 4K and 120 Hertz using chroma subsampling, a compression technique that is particularly noticeable with text. VRR functions in the form of AMD's Freesync, which requires compatible displays.</p>
<!-- RSPEAK_STOP -->


  



  




<!-- RSPEAK_START -->

<p>Alternatively, interested parties can use an active adapter from DisplayPort 1.4 to HDMI 2.1 to increase the frame rate without compression. However, they do not officially support VRR. Popular variants from Club3D are no longer available; <a data-teaser-tracking-content="textlink-pvg" data-teaser-tracking-id="textlink-pvg-pvg_a2664995-1" data-teaser-tracking-name="pvg_a2664995: Lindy DisplayPort 1.4 Stecker auf HDMI 2.1 Buchse, Adapter (41094)" data-teaser-tracking-rank="11107440: Valve: HDMI Forum Continues to Block HDMI 2.1 for‚Ä¶" href="https://preisvergleich.heise.de/lindy-displayport-1-4-stecker-auf-hdmi-2-1-buchse-41094-a2664995.html?cs_id=1206858352&amp;ccpid=hocid-newsticker" rel="external noopener" target="_blank">offers from less well-known providers (starting from 35,67 ‚Ç¨)</a> are still available in price comparisons.</p>


<!-- RSPEAK_STOP -->

<!-- RSPEAK_START -->
<p>

<!-- RSPEAK_STOP -->
<span>(<a href="mailto:mma@heise.de" title="Mark Mantel">mma</a>)</span>
<!-- RSPEAK_START -->
</p>
<div>
    <p>
      Don't miss any news ‚Äì follow us on
      <a href="https://www.facebook.com/heiseonlineEnglish">Facebook</a>,
      <a href="https://www.linkedin.com/company/104691972">LinkedIn</a> or
      <a href="https://social.heise.de/@heiseonlineenglish">Mastodon</a>.
    </p>
    <p>
      <em>This article was originally published in
      
        <a href="https://www.heise.de/news/Valve-HDMI-Forum-blockiert-weiter-HDMI-2-1-fuer-Linux-11107364.html">German</a>.
      
      It was translated with technical assistance and editorially reviewed before publication.</em>
    </p>
  </div>



        

        
        <!-- RSPEAK_STOP -->
        

<a-gift has-access="">
    
</a-gift>


        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DeepSeek uses banned Nvidia chips for AI model, report says (292 pts)]]></title>
            <link>https://finance.yahoo.com/news/china-deepseek-uses-banned-nvidia-131207746.html</link>
            <guid>46219853</guid>
            <pubDate>Wed, 10 Dec 2025 16:34:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://finance.yahoo.com/news/china-deepseek-uses-banned-nvidia-131207746.html">https://finance.yahoo.com/news/china-deepseek-uses-banned-nvidia-131207746.html</a>, See on <a href="https://news.ycombinator.com/item?id=46219853">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content-wrapper">  <article data-testid="article-content-wrapper">     <div data-testid="article-body">   <figure data-testid="article-figure-image"><div> <p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///ywAAAAAAQABAAACAUwAOw==" alt="Photographer: Lam Yik/Bloomberg" loading="eager" height="641" width="960"></p></div> <figcaption><!-- HTML_TAG_START -->Photographer: Lam Yik/Bloomberg<!-- HTML_TAG_END -->  </figcaption> </figure>   <p><!-- HTML_TAG_START --><span>(Bloomberg) --</span> Chinese artificial intelligence startup DeepSeek has relied on Nvidia Corp. chips that are banned in the country to develop an upcoming AI model, according to a new report in The Information.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Nvidia‚Äôs Blackwell chips were smuggled into China through countries that permitted their sale, The Information reported, citing unnamed sources. More specifically, DeepSeek tapped chips that were installed in data centers in unspecified countries, then dismantled and shipped to China after clearing inspection by companies developing server equipment, The Information said. <!-- HTML_TAG_END --></p>      <p><!-- HTML_TAG_START -->Most Read from Bloomberg<!-- HTML_TAG_END --></p>   <ul><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-12-08/nj-suburb-montclair-goes-through-with-school-system-staff-cuts?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:NJ‚Äôs Montclair Cuts School Staff and Mulls March Tax-Hike Vote;elm:context_link;itc:0;sec:content-canvas">NJ‚Äôs Montclair Cuts School Staff and Mulls March Tax-Hike Vote</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-12-09/aviva-seeks-partner-for-new-city-of-london-skyscraper-project?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Aviva Seeks Partner for New City of London Skyscraper Project;elm:context_link;itc:0;sec:content-canvas">Aviva Seeks Partner for New City of London Skyscraper Project</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-12-09/democrats-seek-probe-of-trump-officials-dealings-with-immigration-contractors?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Democrats Want Probe of Trump Officials and Immigration Deals;elm:context_link;itc:0;sec:content-canvas">Democrats Want Probe of Trump Officials and Immigration Deals</a><!-- HTML_TAG_END --></p> </li> </ul>   <p><!-- HTML_TAG_START -->The US bans the sale of these advanced semiconductors to China, which has led AI developers there to access the hardware through data centers located outside of the mainland or subterfuge. In November, US prosecutors charged two Chinese nationals and two US citizens with a scheme to ship chips to China by way of Malaysia using a fake real estate business.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->A representative for DeepSeek didn‚Äôt immediately respond to a request for comment.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->DeepSeek drew global attention in January when it debuted an AI model that was competitive with Silicon Valley‚Äôs best and said it had built it at a fraction of the cost. The startup was funded by the Chinese hedge fund High-Flyer, which had amassed 10,000 Nvidia GPUs in 2021, prior to US bans on exports of sophisticated Nvidia chips and other graphics processing units.<!-- HTML_TAG_END --></p>      <p><!-- HTML_TAG_START -->Earlier this week, President Donald Trump granted Nvidia permission to ship to China an older version of its AI accelerators, the H200. An export ban on its more powerful Blackwell version remains in place.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Beijing has meanwhile pushed Chinese technology companies to rely on domestic equipment to develop AI. DeepSeek released a new model in September and indicated that it was working with Chinese chipmakers on the model.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Nvidia told The Information that it hasn‚Äôt seen ‚Äúany substantiation or received tips‚Äù about smuggling through data centers outside of China.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->(Updates with more details on reported chip smuggling starting in the third paragraph)<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Most Read from Bloomberg Businessweek<!-- HTML_TAG_END --></p>   <ul><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/features/2025-12-09/albright-college-budget-cuts-are-eliminating-many-traditional-majors?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Why a College Fighting for Survival Is Slashing Econ and Physics Majors;elm:context_link;itc:0;sec:content-canvas">Why a College Fighting for Survival Is Slashing Econ and Physics Majors</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/features/2025-12-09/argentina-s-richest-man-marcos-galperin-on-stepping-down-as-mercadolibre-ceo?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Argentina‚Äôs Richest Man: ‚ÄòReal Power Is Choosing When to Step Away‚Äô;elm:context_link;itc:0;sec:content-canvas">Argentina‚Äôs Richest Man: ‚ÄòReal Power Is Choosing When to Step Away‚Äô</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/features/2025-12-09/nuclear-energy-fossil-fuel-interests-join-forces-against-renewable-energy?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Nuclear and Fossil Fuels Join Forces to Undermine Renewables;elm:context_link;itc:0;sec:content-canvas">Nuclear and Fossil Fuels Join Forces to Undermine Renewables</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/features/2025-12-08/grand-canyon-glacier-joshua-tree-national-park-workers-rally-to-unionize?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:How Trump Pushed US Park Rangers to the Breaking Point‚Äîand a Union Drive;elm:context_link;itc:0;sec:content-canvas">How Trump Pushed US Park Rangers to the Breaking Point‚Äîand a Union Drive</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-12-03/ai-slop-youtube-videos-for-kids-pretend-to-be-educational?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:YouTube Creators Find a New Consumer for AI Slop: Babies;elm:context_link;itc:0;sec:content-canvas">YouTube Creators Find a New Consumer for AI Slop: Babies</a><!-- HTML_TAG_END --></p> </li> </ul>   <p><!-- HTML_TAG_START -->¬©2025 Bloomberg L.P.<!-- HTML_TAG_END --></p>   </div> <span> </span>  </article>     <hr> <ul><li data-testid="seamlessscroll-6f99d87c-7474-3d64-b2e5-19edaf0c66ef"> </li><li data-testid="seamlessscroll-3e7395ca-6ae7-3e6e-9226-a1df04934c4b"> </li><li data-testid="seamlessscroll-4b18cf2c-f118-392a-aa62-695ba93376df"> </li><li data-testid="seamlessscroll-7416125b-ea22-3ad7-bd27-9434d427e188"> </li><li data-testid="seamlessscroll-c848c1fa-973e-35e4-9051-b71406386dac"> </li><li data-testid="seamlessscroll-e6c25bb8-8cef-3d9b-9ee8-ee448aba48be"> </li><li data-testid="seamlessscroll-bdcba08a-56a4-306e-9e56-04cce3f29951"> </li></ul> <section><header> </header>   </section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Qwen3-Omni-Flash-2025-12-01Ôºöa next-generation native multimodal large model (222 pts)]]></title>
            <link>https://qwen.ai/blog?id=qwen3-omni-flash-20251201</link>
            <guid>46219538</guid>
            <pubDate>Wed, 10 Dec 2025 16:13:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qwen.ai/blog?id=qwen3-omni-flash-20251201">https://qwen.ai/blog?id=qwen3-omni-flash-20251201</a>, See on <a href="https://news.ycombinator.com/item?id=46219538">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Size of Life (1554 pts)]]></title>
            <link>https://neal.fun/size-of-life/</link>
            <guid>46219346</guid>
            <pubDate>Wed, 10 Dec 2025 16:02:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neal.fun/size-of-life/">https://neal.fun/size-of-life/</a>, See on <a href="https://news.ycombinator.com/item?id=46219346">Hacker News</a></p>
Couldn't get https://neal.fun/size-of-life/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[In New York City, congestion pricing leads to marked drop in pollution (414 pts)]]></title>
            <link>https://e360.yale.edu/digest/new-york-congestion-pricing-pollution</link>
            <guid>46218725</guid>
            <pubDate>Wed, 10 Dec 2025 15:25:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://e360.yale.edu/digest/new-york-congestion-pricing-pollution">https://e360.yale.edu/digest/new-york-congestion-pricing-pollution</a>, See on <a href="https://news.ycombinator.com/item?id=46218725">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                  
<div>

  <figure>

    <div>
      
                  
      <p><a href="https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=1200&amp;h=800&amp;auto=compress%2Cformat&amp;fit=crop&amp;dm=1765283167&amp;s=0cbefdad5bd8aac05b696a3ccd664a41" data-caption="" data-credit="Pexels">
  
  
  
    
  
  
  
      
    
                
    
                
    
                
    
                
    
                        
  <img sizes="(min-width: 1450px) 832px, (min-width: 620px) 620px, 100vw" srcset="https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=1200&amp;h=800&amp;auto=compress%2Cformat&amp;fit=crop&amp;dm=1765283167&amp;s=0cbefdad5bd8aac05b696a3ccd664a41 1200w, https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=200&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1765283167&amp;s=ce71b84136fe60ca9ab40e66fe6e62f0 200w, https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=400&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1765283167&amp;s=514435a5842d6a703560bc3e8dcf8a84 400w, https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=600&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1765283167&amp;s=6dec6ff9eef4bf5345d6ff07f9de00d5 600w, https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=800&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1765283167&amp;s=6ec63769954ae19251cc99827541364e 800w, https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=1000&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1765283167&amp;s=22956faaf223e612682176b0f9ac41a9 1000w" src="https://yale-threesixty.transforms.svdcdn.com/production/NY-Street_Pexels.jpg?w=400&amp;auto=compress%2Cformat&amp;fit=clip&amp;dm=1765283167&amp;s=514435a5842d6a703560bc3e8dcf8a84" alt="">
</a>
      </p>
          </div>

        <figcaption>
              <p><span></span>
          <span>Pexels</span></p>
    </figcaption>
    
  </figure>

</div> <!-- imageBlock -->
            

<div>
  <p>A new toll applied to cars driving in parts of New York City has led to a measurable drop in traffic, and with it, a 22 percent decline in particulate pollution, according to a new study.</p><p>Congestion pricing came into effect in January, with cars paying $9 to drive through busy parts of Manhattan during peak hours. In the first six months of the program, traffic in the congestion zone dropped by 11 percent, accidents by 14 percent, and complaints of excessive honking or other noise by 45 percent, <a href="https://www.cbsnews.com/newyork/news/congestion-pricing-first-6-months/">officials said</a>.&nbsp;</p><p>A new study from Cornell has now tallied the impact on particulate pollution. Particulates issued from tailpipes can aggravate asthma and heart disease and increase the risk of lung cancer and heart attack. Globally, they are a leading risk factor for premature death.</p><p>Analyzing data on air quality, traffic, and weather conditions, researchers determined that in the first half of this year, particulate pollution was down 22 percent in parts of Manhattan affected by congestion pricing.&nbsp;</p><p>The decline seen in New York was greater than in other cities with congestion pricing, such as Stockholm and London, researchers note. And the effect extended beyond Lower Manhattan. Pricing led to a drop in pollution across the greater metropolitan area, according to the <a href="https://www.nature.com/articles/s44407-025-00037-2">study</a>, published in the journal <i>npj Clean Air.</i></p><p>‚ÄúIt‚Äôs really exciting to me that air quality improved throughout the entire metro area,‚Äù <a href="https://news.cornell.edu/stories/2025/12/congestion-pricing-improved-air-quality-nyc-and-suburbs">said lead author</a> Timothy Fraser, of Cornell University. ‚ÄúThis tells us that congestion pricing didn‚Äôt simply relocate air pollution to the suburbs by rerouting traffic. Instead, folks are likely choosing cleaner transportation options altogether, like riding public transportation or scheduling deliveries at night. This thins traffic and limits how smog compounds when many cars are on the road.‚Äù</p><h2><strong>ALSO ON YALE E360</strong></h2><p><a href="https://e360.yale.edu/features/free-parking-reform"><i><strong>How Parking Reform Is Helping Transform American Cities</strong></i></a></p>
</div>
                </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Israel used Palantir technologies in pager attack in Lebanon (424 pts)]]></title>
            <link>https://the307.substack.com/p/revealed-israel-used-palantir-technologies</link>
            <guid>46218640</guid>
            <pubDate>Wed, 10 Dec 2025 15:18:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://the307.substack.com/p/revealed-israel-used-palantir-technologies">https://the307.substack.com/p/revealed-israel-used-palantir-technologies</a>, See on <a href="https://news.ycombinator.com/item?id=46218640">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!2lf3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5818e140-0706-4518-9e7c-80ca32bccee0_1200x630.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2lf3!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5818e140-0706-4518-9e7c-80ca32bccee0_1200x630.webp 424w, https://substackcdn.com/image/fetch/$s_!2lf3!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5818e140-0706-4518-9e7c-80ca32bccee0_1200x630.webp 848w, https://substackcdn.com/image/fetch/$s_!2lf3!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5818e140-0706-4518-9e7c-80ca32bccee0_1200x630.webp 1272w, https://substackcdn.com/image/fetch/$s_!2lf3!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5818e140-0706-4518-9e7c-80ca32bccee0_1200x630.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2lf3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5818e140-0706-4518-9e7c-80ca32bccee0_1200x630.webp" width="1200" height="630" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5818e140-0706-4518-9e7c-80ca32bccee0_1200x630.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:630,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:65810,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://the307.substack.com/i/181105265?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5818e140-0706-4518-9e7c-80ca32bccee0_1200x630.webp&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!2lf3!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5818e140-0706-4518-9e7c-80ca32bccee0_1200x630.webp 424w, https://substackcdn.com/image/fetch/$s_!2lf3!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5818e140-0706-4518-9e7c-80ca32bccee0_1200x630.webp 848w, https://substackcdn.com/image/fetch/$s_!2lf3!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5818e140-0706-4518-9e7c-80ca32bccee0_1200x630.webp 1272w, https://substackcdn.com/image/fetch/$s_!2lf3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5818e140-0706-4518-9e7c-80ca32bccee0_1200x630.webp 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>In September of 2024, Israel blew up boobie trapped pagers belonging to Hezbollah figures in public places in Lebanon, </span><a href="https://www.hrw.org/news/2024/09/18/lebanon-exploding-pagers-harmed-hezbollah-civilians" rel="">killing 12 people, </a><span>including two children and two healthcare workers, and injuring 2,800. </span></p><p><span>The attack was followed </span><a href="https://apnews.com/projects/israel-gaza-war-pager-attack-survivors-hezbollah/" rel="">by another attack</a><span> using explosives in walkie-talkies that killed 25 people and injured another 600. </span></p><p>The Associated Press reported that the attacks ‚Äúwounded many civilians‚Äù and that survivors are left ‚Äúwith missing eyes, faces laced with scars, hands with missing fingers‚Äù. </p><p><span>The United Nations at the time </span><a href="https://www.ohchr.org/en/press-releases/2024/09/exploding-pagers-and-radios-terrifying-violation-international-law-say-un" rel="">noted that</a><span> the attacks ‚Äúconstitute war crimes of murder, attacking civilians, and launching indiscriminate attacks, in addition to violating the right to life‚Äù adding that, ‚ÄúAround 500 people suffered severe eye injuries, including a diplomat. Others suffered grave injuries to their faces, hands and bodies‚Äù and that ‚ÄúIt is also a war crime to commit violence intended to spread terror among civilians, including to intimidate or deter them from supporting an adversary, A climate of fear now pervades everyday life in Lebanon‚Äù. </span></p><p><span>At the time, when asked about the attacks, former CIA director Leon Panetta </span><a href="https://www.yahoo.com/news/surprising-figure-calling-israel-terrorism-155610359.html" rel="">said</a><span>, ‚ÄúI don‚Äôt think there‚Äôs any question that it‚Äôs a form of terrorism‚Äù. </span></p><p>Now, a new book quietly reveals that Israel carried out the terrorist attack with the help of the AI surveillance firm Palantir, led by Alex Karp and Peter Thiel. </p><p><span>In the new </span><a href="https://www.amazon.com/Philosopher-Valley-Palantir-Surveillance-State-ebook/dp/B0D54L7Q4W" rel="">biography </a><span>of Palantir co-founder Alex Karp, ‚ÄúThe Philosopher in the Valley: Alex Karp, Palantir, and the Rise of the Surveillance State,‚Äù by New York Times journalist Michael Steinberger, he writes that prior to the genocide in Gaza,  ‚Äúthe Mossad had been using Palantir technology,‚Äù adding that the Shin Bet and IDF, ‚Äú sought to obtain Palantir‚Äôs software in the wake of Ocotber 7th‚Äù. </span></p><p>He goes on to write that, ‚ÄúThe demand for Palantir‚Äôs assistance was so great that the company dispatched a a team of engineers from London to help get Israeli users online,‚Äù adding, ‚ÄúPalantir ended up having to rent a second-floor building that housed its Tel Aviv office, to accommodate the intelligence analysts who needed tutorials‚Äù. </p><p>Revealing what Israel used the AI-powered software for, Michael Steinberger notes, ‚ÄúIts software was used by the Israeli military in several raids in Gaza‚Äù and goes on to write that, ‚ÄúThe company‚Äôs technology was deployed by the Israelis during military operations in Lebanon in 2024 that decimated Hezbollah‚Äôs top leadership‚Äù adding that, ‚ÄúIt was also used in Operation Grim Beeper, in which hundreds of Hezbollah fighters were injured and maimed when their pagers and walkie-talkies exploded (the Israelis had booby trapped the devices)‚Äù. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!H4CQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad25c5da-bb42-4622-b9ad-8cde1a5e8068_811x263.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!H4CQ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad25c5da-bb42-4622-b9ad-8cde1a5e8068_811x263.png 424w, https://substackcdn.com/image/fetch/$s_!H4CQ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad25c5da-bb42-4622-b9ad-8cde1a5e8068_811x263.png 848w, https://substackcdn.com/image/fetch/$s_!H4CQ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad25c5da-bb42-4622-b9ad-8cde1a5e8068_811x263.png 1272w, https://substackcdn.com/image/fetch/$s_!H4CQ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad25c5da-bb42-4622-b9ad-8cde1a5e8068_811x263.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!H4CQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad25c5da-bb42-4622-b9ad-8cde1a5e8068_811x263.png" width="811" height="263" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ad25c5da-bb42-4622-b9ad-8cde1a5e8068_811x263.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:263,&quot;width&quot;:811,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:82999,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://the307.substack.com/i/181105265?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad25c5da-bb42-4622-b9ad-8cde1a5e8068_811x263.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!H4CQ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad25c5da-bb42-4622-b9ad-8cde1a5e8068_811x263.png 424w, https://substackcdn.com/image/fetch/$s_!H4CQ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad25c5da-bb42-4622-b9ad-8cde1a5e8068_811x263.png 848w, https://substackcdn.com/image/fetch/$s_!H4CQ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad25c5da-bb42-4622-b9ad-8cde1a5e8068_811x263.png 1272w, https://substackcdn.com/image/fetch/$s_!H4CQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fad25c5da-bb42-4622-b9ad-8cde1a5e8068_811x263.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Francesca Albanese, the United Nations‚Äô Special Rapporteur on the situation of human rights in the Palestinian Territory, occupied since 1967, </span><a href="https://www.ohchr.org/sites/default/files/documents/hrbodies/hrcouncil/sessions-regular/session59/advance-version/a-hrc-59-23-aev.pdf" rel="">documented </a><span> Palantir‚Äôs role in the genocide in Gaza, noting, ‚ÄúIn January 2024, Palantir announced a new strategic partnership with Israel and held a board meeting in Tel Aviv ‚Äúin solidarity‚Äù; in April 2025, Palantir‚Äôs Chief Executive Officer responded to accusations that Palantir had killed Palestinians in Gaza by saying, ‚Äòmostly terrorists, that‚Äôs true‚Äô. Both incidents are indicative of executive-level knowledge and purpose vis-√†-vis the unlawful use of force by Israel, and failure to prevent such acts or withdraw involvement.‚Äù</span></p><p>Now it is revealed that the AI software was used in Israel‚Äôs terrorist attack in Lebanon as well. </p><p><span>In a recent </span><a href="https://www.middleeastmonitor.com/20251030-ex-mossad-chief-behind-icj-blackmail-campaign-brags-israel-has-installed-a-global-sabotage-network/" rel="">interview, the former head of </a><span>the Israeli Mossad, Yossi Cohen, revealed that Israel has similar ‚Äúbooby-trapped and spy-manipulated equipment‚Äù in ‚Äúall the countries you can imagine‚Äù. </span></p><p>The fact that a company as influential as Palantir was involved in the terrorist attacks makes these comments even more concerning. </p><p><em>Note to readers: </em><span>The Dissident is a reader-supported outlet. If you liked this article, consider becoming a paid subscriber.</span></p></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New benchmark shows top LLMs struggle in real mental health care (107 pts)]]></title>
            <link>https://swordhealth.com/newsroom/sword-introduces-mindeval</link>
            <guid>46217578</guid>
            <pubDate>Wed, 10 Dec 2025 13:39:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://swordhealth.com/newsroom/sword-introduces-mindeval">https://swordhealth.com/newsroom/sword-introduces-mindeval</a>, See on <a href="https://news.ycombinator.com/item?id=46217578">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>The global demand for mental health support has never been higher, with over one billion people currently living with mental health conditions. As healthcare providers look for solutions to bridge the gap between demand and access, Large Language Models (LLMs) offer a promising avenue for scalable support.</span></p><p><span>At Sword Health, we have been working to realize this promise by developing our own LLMs specifically aligned for mental health care. However, from the beginning of our development journey, we encountered a critical obstacle: </span><strong><span>we could not improve what we could not accurately measure.</span></strong><span>&nbsp;</span></p><p><span>While we could train models to be helpful, answering the fundamental question ‚Äì </span><em><span>can we trust this model to provide safe, effective therapeutic care?</span></em><span> ‚Äì remained elusive. We realized that relying on existing evaluations wasn't enough to guide the development of truly clinical-grade AI. To solve our own development needs, we had to build a new yardstick.</span></p><p><strong><span>Today, we are introducing MindEval</span></strong><span>, a novel framework designed in collaboration with licensed Clinical Psychologists to evaluate LLMs in realistic, multi-turn mental health conversations. By automating the assessment of clinical skills, MindEval allows us to move beyond basic checks and measure actual therapeutic competence.</span></p><p><span>We believe that safety in healthcare AI should not be a proprietary secret, but a shared foundation. To accelerate the industry‚Äôs progress toward clinically safe AI, we are open-sourcing the entire MindEval framework including our expert-designed prompts, code, and evaluation datasets. Our goal is for MindEval to serve as a community-driven standard, giving developers and researchers a reliable yardstick to measure and improve the mental health capabilities of future models.</span></p><h3>The problem: moving beyond "book knowledge"</h3><p><span>The deployment of AI in mental health is currently outpacing our ability to evaluate it. As the industry faces rising concerns about the safety of therapeutic chatbots, a core obstacle to creating safer systems is the scarcity of benchmarks that capture the complexity of real therapy.</span></p><p><span>Current AI systems present significant limitations in therapeutic settings, often defaulting to sycophancy (excessive eagerness to please) or over-reassurance, which can inadvertently reinforce maladaptive beliefs. Yet, most existing benchmarks fail to catch these nuances because they assess models through multiple-choice questions that test clinical knowledge, or by evaluating single responses in isolation.</span></p><p><span>We found that current evaluation methods fall short in three key areas:</span></p><ul><li><strong><span>Knowledge vs. competence:</span></strong><span> While an AI might know the textbook definition of depression, that does not guarantee it has the clinical aptitude across domains, such as clinical accuracy, ethical and professional decision making, rapport building, among others.&nbsp;&nbsp;</span></li><li><strong><span>Static vs. dynamic:</span></strong><span> Therapy is longitudinal. Existing benchmarks typically look at static snapshots, missing the critical dynamics that happen over a multi-turn session.</span></li><li><strong><span>Vibes vs. validation:</span></strong><span> Without rigorous, expert-derived rubrics, safety checks often rely on subjective "vibe checks." We believe that to build safe AI for healthcare, we must move beyond "vibes" and into rigorous, clinically grounded evaluation.</span></li></ul><h3>The MindEval framework</h3><p><span>MindEval is a fully automated, model-agnostic framework that evaluates therapy sessions dynamically. As illustrated below, the framework relies on the interaction between specific components to simulate a full therapeutic session.</span></p><figure><img alt="" loading="lazy" width="640" height="400" decoding="async" data-nimg="1" srcset="https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3188x1842%2Fa5080c531f%2F1.png&amp;w=640&amp;q=75 1x, https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3188x1842%2Fa5080c531f%2F1.png&amp;w=1920&amp;q=75 2x" src="https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3188x1842%2Fa5080c531f%2F1.png&amp;w=1920&amp;q=75"></figure><p><span>The framework, illustrated in Figure 1, consists of three primary agents:</span></p><ol start="1"><li><strong><span>The Patient LLM (PLM):</span></strong><span> This model is prompted with a highly detailed profile and backstory to simulate a patient. It mimics a real person engaging in a multi-turn conversation, maintaining consistency in personality and symptoms throughout the interaction.</span></li><li><strong><span>The Clinician LLM (CLM):</span></strong><span> This is the model being evaluated (e.g., GPT-5, Claude 4.5). It interacts with the patient, attempting to provide therapeutic support.</span></li><li><strong><span>The Judge LLM (JLM):</span></strong><span> Once the interaction is complete, a separate "judge" model evaluates the interaction.</span></li></ol><p><span>Crucially, the Judge LLM does not simply give a binary thumbs up or down. It scores the entire interaction on </span><strong><span>5 core criteria</span></strong><span> grounded in clinical supervision guidelines from the APA:</span></p><ul><li><span>Clinical Accuracy &amp; Competence (CAC)</span></li><li><span>Ethical &amp; Professional Conduct (EPC)</span></li><li><span>Assessment &amp; Response (AR)</span></li><li><span>Therapeutic Relationship &amp; Alliance (TRA)</span></li><li><span>AI-Specific Communication Quality (ASQC)</span></li></ul><p><span>In Table 1 we show the score range for Clinical Accuracy &amp; Competence. Each criteria follows a similar scale with scores between 3-4 representing and average but acceptable performance.</span></p><figure><img alt="" loading="lazy" width="640" height="400" decoding="async" data-nimg="1" srcset="https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3078x1680%2F5331d46e75%2F2.jpg&amp;w=640&amp;q=75 1x, https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3078x1680%2F5331d46e75%2F2.jpg&amp;w=1920&amp;q=75 2x" src="https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3078x1680%2F5331d46e75%2F2.jpg&amp;w=1920&amp;q=75"></figure><h3>Validating the framework: realism and accuracy</h3><p><span>Before benchmarking other models, we first had to show that MindEval itself yielded reliable interactions and judgments. We focused on two key areas to validate MindEval: </span><strong><span>Patient Realism</span></strong><span> and </span><strong><span>Judge Quality</span></strong><span>.</span></p><p><span>To validate </span><strong><span>Patient Realism</span></strong><span>, we quantitatively measured the similarity between the text produced by our simulated patients (PLM) and text generated by humans performing the same role-play task. Our analysis showed that the text produced with the MindEval prompt relates more closely to human-generated text‚Äîin terms of profile adherence and style‚Äîthan other, less detailed prompts. Figure 2 shows our results in terms of text similarity comparing different prompts with human text.</span></p><figure><img alt="" loading="lazy" width="640" height="400" decoding="async" data-nimg="1" srcset="https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3305x1933%2Fa591b9ea8e%2F3.jpg&amp;w=640&amp;q=75 1x, https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3305x1933%2Fa591b9ea8e%2F3.jpg&amp;w=1920&amp;q=75 2x" src="https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3305x1933%2Fa591b9ea8e%2F3.jpg&amp;w=1920&amp;q=75"></figure><p><span>To validate </span><strong><span>Judge Quality</span></strong><span>, we compared the outputs of our automated judge (JLM) to those of a panel of human experts. Specifically, we measured if the AI is able to rank the quality of therapy sessions similarly to how a licensed psychologist would (using Kendall‚Äôs Tau) and whether systems are usually ranked appropriately when interacting with the same patient (using the mean interaction-level pairwise system accuracy (MIPSA)). Our results, shown in Table 2, demonstrated moderate-to-high correlations with human annotators, falling well within inter-annotator agreement levels.</span></p><figure><img alt="" loading="lazy" width="640" height="400" decoding="async" data-nimg="1" srcset="https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3264x1729%2Fd7d68a50af%2F4.jpg&amp;w=640&amp;q=75 1x, https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3264x1729%2Fd7d68a50af%2F4.jpg&amp;w=1920&amp;q=75 2x" src="https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3264x1729%2Fd7d68a50af%2F4.jpg&amp;w=1920&amp;q=75"></figure><h3>Benchmark results: how do state-of-the-art models perform?</h3><p><span>Having established the validity of our methodology, we benchmarked 12 state-of-the-art LLMs, including but not limited to GPT-5, Claude 4.5 Sonnet, and Gemini 2.5 Pro. In our article we show detailed results per system but overall, across all categories, models struggled. Figure 3 shows the average results with min and max score per category and in different scenarios ranging from severe symptoms to longer conversations with 40 turns.</span></p><figure><img alt="" loading="lazy" width="640" height="400" decoding="async" data-nimg="1" srcset="https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3392x1847%2F4ffa697b03%2F5.jpg&amp;w=640&amp;q=75 1x, https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3392x1847%2F4ffa697b03%2F5.jpg&amp;w=1920&amp;q=75 2x" src="https://swordhealth.com/_next/image?url=https%3A%2F%2Fa.storyblok.com%2Ff%2F325797%2F3392x1847%2F4ffa697b03%2F5.jpg&amp;w=1920&amp;q=75"></figure><p><span>Our findings revealed significant gaps in current AI capabilities:</span></p><ul><li><strong><span>Room for improvement:</span></strong><span> On a clinical quality scale of 1 to 6, the average score across all models was below 4.</span></li><li><strong><span>Bigger is not always better:</span></strong><span> Counter-intuitively, we found that reasoning capabilities and massive model scale do not guarantee better performance in a therapeutic context. For example, some smaller models outperformed larger reasoning models in specific communication qualities. Being good at math or coding does not translate directly to being good at mental health support.</span></li><li><strong><span>Critical weaknesses in difficult scenarios:</span></strong><span> Reliability is paramount in healthcare, yet we found that model performance deteriorated when supporting patients with severe symptoms. Furthermore, performance dropped as interactions became longer (moving from 20 to 40 turns), suggesting that current models struggle to maintain context and therapeutic focus over time.</span></li></ul><h3><span>Conclusion</span></h3><p><span>We believe that to build safe </span><span><a href="https://swordhealth.com/articles/ai-care-study" target="_blank" rel="noopener noreferrer">AI for healthcare</a></span><span>, we must measure what matters. MindEval moves the industry beyond "vibes" and into rigorous, clinically grounded evaluation. While current models show promise, our results indicate there is much room for improvement to make these systems reliable for patients across the entire spectrum of mental health needs.</span></p><p><span>Despite their impressive capabilities in code and reasoning, every frontier model we tested failed to meet the threshold for clinical reliability, scoring below 4 out of 6 on average. Our data shows that models trained for general helpfulness often struggle with the specific, high-stakes nuance of therapeutic care, particularly when patients present with severe symptoms. This is not a problem that can be solved simply by making models larger; it requires a fundamental shift in how we align and evaluate AI for care.</span></p><p><span>To encourage transparency and help the industry close this gap, we are releasing all code, prompts, and human evaluation data to the public.</span></p><ul><li><strong><a href="https://www.arxiv.org/pdf/2511.18491" target="_blank" rel="noopener noreferrer">Read the paper</a></strong></li><li><strong><a href="https://github.com/swordhealth/mind-eval" target="_blank" rel="noopener noreferrer">Check out the open source repository</a></strong></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[McDonald's pulls AI Christmas ad after backlash (103 pts)]]></title>
            <link>https://www.bbc.co.uk/news/articles/czdgrnvp082o</link>
            <guid>46217176</guid>
            <pubDate>Wed, 10 Dec 2025 12:57:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.co.uk/news/articles/czdgrnvp082o">https://www.bbc.co.uk/news/articles/czdgrnvp082o</a>, See on <a href="https://news.ycombinator.com/item?id=46217176">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="text-block"><p><b>McDonald's Netherlands has taken down a Christmas advert made with Artificial Intelligence (AI) following online backlash.</b></p><p>The 45-second advert was produced with generative AI clips and released publicly on McDonald's Netherlands YouTube channel on 6 December.</p><p>Viewers on social media denounced the use of AI in the film, with one commenter calling it <a href="https://x.com/realTedMcKenzie/status/1997346895924957419">"the most god-awful ad I've seen this year"<span>, <!-- -->external</span></a>.</p><p>On 9 December McDonald's Netherlands removed the video, adding in a statement to BBC News that the moment served as "an important learning" as the company explored "the effective use of AI".</p></div><div data-component="text-block"><p><a href="https://www.adforum.com/creative-work/ad/player/34728882/its-the-most-terrible-time-of-the-year/mcdonalds">The advert<span>, <!-- -->external</span></a> was created for McDonald's Netherlands by Dutch company TBWA\Neboko and US production company The Sweetshop.</p><p>Adverts which include generative AI have become a growing trend among major brands, such as Coca-Cola, particularly for the Christmas season.</p><p>The McDonald's Netherlands advert depicted things that can go wrong during the Christmas break, using the slogan "the most terrible time of the year", and suggesting the time was better spent in the company of the fast food giant.</p><p>Following its release, viewers criticised the film's uncanny-looking characters and large number of stitched together clips, calling it <a href="https://x.com/RichardERoeper/status/1998134560253755533">"creepy"<span>, <!-- -->external</span></a> and "poorly edited".</p><p>As clips made using generative AI are more likely to distort the longer they run for - most clips made using the process tend to be roughly six to 10 seconds long - even a 45-second advert would likely consist of many videos edited together.</p><p>The video also provoked concerns for job displacement in the industry, with<a href="https://www.instagram.com/reel/DR2XjdmElbd/"> one Instagram comment<span>, <!-- -->external</span></a> noting: "No actors, no camera team..welcome to the future of filmmaking. And it sucks."</p></div><div data-component="text-block"><p>Following the video being made private on the McDonald's Netherlands YouTube channel, The Sweetshop's chief executive Melanie Bridge defended the advert.</p><p>As <a href="https://futurism.com/artificial-intelligence/mcdonalds-ai-generated-commercial">quoted in Futurism<span>, <!-- -->external</span></a>, she said the production process took "seven weeks" where the team "hardly slept" and created "thousands of takes - then shaped them in the edit just as we would on any high-craft production".</p><p>"This wasn't an AI trick," she said. "It was a film."</p><p>In a statement to BBC News, McDonald's Netherlands said the video was meant to "reflect the stressful moments that can occur during the holidays" but had decided to remove the advert.</p><p>"This moment serves as an important learning as we explore the effective use of AI," it said.</p><p>Where normally a high-publicity Christmas campaign could take up to a year to pull off, companies have begun to look to firms which can produce films in a much shorter time span, using prompts from generative AI tools to create new video content.</p><p>Coca-Cola seems to have been able to sway at least some of the general public with its second AI-generated Christmas ad in a row.</p><p>While the use of AI to create the advert has been divisive, a report from analytics company Social Sprout <a href="https://www.decisionmarketing.co.uk/news/coke-ai-ad-triggers-mass-debate-but-most-still-love-it">found it had a 61% "positive sentiment rating"<span>, <!-- -->external</span></a> from commenters online.</p><p>But several <a href="https://www.bbc.co.uk/news/articles/cwyvjyvn83go">other businesses</a> such as the Italian luxury fashion house Valentino have come under fire for using the technique in their campaigns, with critics calling Valentino's advert "cheap" and "lazy".</p><p>BBC News has contacted The Sweetshop and TBWA\Neboko for comment.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US could ask foreign tourists for five-year social media history before entry (119 pts)]]></title>
            <link>https://www.bbc.co.uk/news/articles/c1dz0g2ykpeo</link>
            <guid>46217026</guid>
            <pubDate>Wed, 10 Dec 2025 12:37:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.co.uk/news/articles/c1dz0g2ykpeo">https://www.bbc.co.uk/news/articles/c1dz0g2ykpeo</a>, See on <a href="https://news.ycombinator.com/item?id=46217026">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="text-block"><p><b>Tourists from dozens of countries including the UK could be asked to provide a five-year social media history as a condition of entry to the United States, under a new proposal unveiled by American officials.</b></p><p>The new condition would affect people from dozens of countries who are eligible to visit the US for 90 days without a visa, as long as they have filled out an Electronic System for Travel Authorization (ESTA) form.</p><p>Since returning to the White House in January, President Donald Trump has moved to toughen US borders more generally - citing national security as a key reason.</p><p>Analysts say the new plan could pose an obstacle to potential visitors, or harm their digital rights.</p></div><div data-component="text-block"><p>The US expects a major influx of foreign tourists next year, as it hosts the men's football World Cup alongside Canada and Mexico, and for the 2028 Olympics in Los Angeles.</p><p>The proposal document was filed by Customs and Border Protection (CBP) and the Department of Homeland Security (DHS), of which the agency is part.</p><p>US media reported that it appeared in the Federal Register, which is the official journal of the US government. The BBC has asked DHS for comment.</p><p>The proposal says "the data element will require <a href="https://esta.cbp.dhs.gov/">ESTA applicants<span>, <!-- -->external</span></a> to provide their social media from the last 5 years", without giving further details of which specific information will be required.</p><p>The existing ESTA requires a comparatively limited amount of information from travellers, as well as a one-off payment of $40 (¬£30). It is accessible to citizens of about 40 countries - including the UK, Ireland, France, Australia and Japan - and allows them to visit the US multiple times during a two-year period.</p><p>As well as the collection of social media information, the new document proposes the gathering of an applicant's telephone numbers and email addresses used over the last five and 10 years respectively, and more information about their family members.</p><p>The text cites an executive order from Trump in January, titled "Protecting the United States From Foreign Terrorists and Other National Security and Public Safety Threats".</p></div><div data-component="text-block"><p>The Trump administration previously announced it would examine social media accounts when vetting foreign nationals who apply for student visas or H1B visas for skilled workers.</p><p>The state department said it will conduct "online presence" reviews for applicants and their dependents, and that privacy settings on all social media profiles must be made "public" so this screening can take place.</p><p>An announcement on the website for the US Embassy and Consulate in Mexico states certain visa applicants must list all social media usernames or handles of every platform they have used in the last five years.</p><p>It warns that if any social media information is not listed, it could lead to both current and future visas being denied.</p><p>A senior state department official said of the student visa policy: "It is an expectation from American citizens that their government will make every effort to make our country safer, and that is exactly what the Trump Administration is doing every single day." </p><p>Officers were instructed to screen for those "who advocate for, aid, or support designated foreign terrorists and other threats to national security; or who perpetrate unlawful anti-Semitic harassment or violence".</p><p>As part of the administration's broader effort to toughen borders, officials recently said an existing travel ban - affecting 19 countries in Africa, the Middle East and the Caribbean - could soon be expanded. </p><p>That move was announced in the wake of a shooting attack on two National Guard members in Washington DC, in which an Afghan man has been named as the suspect. </p><p>The new proposal regarding ESTA data collection for tourists invites views from the public for 60 days. </p><p>Sophia Cope, of digital rights organisation the Electronic Frontier Foundation, criticised the plan, telling the New York Times that it could "exacerbate civil liberties harms".</p><p>Meanwhile, immigration law practice Fragomen suggested there could be practical impacts as applicants could face longer waits for ESTA approvals.</p><p>Experts have previously suggested that the changes to travel policies introduced under Trump have had an impact on the American tourism industry. </p><p>Earlier this year, the World Travel &amp; Tourism Council said the US was the only one of 184 economies that it analysed that was expected to see a decline in international visitor spending in 2025.</p><p>Other Trump administration policies have also appeared to impact tourism to the country, such as many Canadians boycotting US travel as a form of protest against Trump's tariffs.</p><p>October marked the 10th straight month of decline in the number of Canadian travellers to the US. In the past, Canadians have made up about a quarter of all international visitors to the US, spending more than $20bn (¬£15.1bn) a year, according to the US Travel Association.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Factor 0.101 now available (113 pts)]]></title>
            <link>https://re.factorcode.org/2025/12/factor-0-101-now-available.html</link>
            <guid>46216583</guid>
            <pubDate>Wed, 10 Dec 2025 11:33:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://re.factorcode.org/2025/12/factor-0-101-now-available.html">https://re.factorcode.org/2025/12/factor-0-101-now-available.html</a>, See on <a href="https://news.ycombinator.com/item?id=46216583">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><em>‚ÄúKeep thy airspeed up, lest the earth come from below and smite thee.‚Äù -
William Kershner</em></p>
<p>I‚Äôm very pleased to announce the release of <a href="https://factorcode.org/">Factor</a>
0.101!</p>
<table>
<colgroup>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>OS/CPU</th>
<th scope="col">Windows</th>
<th scope="col">Mac OS</th>
<th scope="col">Linux</th>
</tr>
</thead>
<tbody>
<tr>
<th scope="row">x86</th>
<td>
<a href="https://downloads.factorcode.org/releases/0.101/factor-windows-x86-32-0.101.zip">0.101</a>
</td>
<td>
</td>
<td>
<a href="https://downloads.factorcode.org/releases/0.101/factor-linux-x86-32-0.101.tar.gz">0.101</a>
</td>
</tr>
<tr>
<th scope="row">x86-64</th>
<td>
<a href="https://downloads.factorcode.org/releases/0.101/factor-windows-x86-64-0.101.zip">0.101</a>
</td>
<td>
<a href="https://downloads.factorcode.org/releases/0.101/factor-macos-x86-64-0.101.dmg">0.101</a>
</td>
<td>
<a href="https://downloads.factorcode.org/releases/0.101/factor-linux-x86-64-0.101.tar.gz">0.101</a>
</td>
</tr>
</tbody>
</table>
<p><strong>Source code</strong>: <a href="https://downloads.factorcode.org/releases/0.101/factor-src-0.101.zip">0.101</a></p>
<p>This release is brought to you with almost 700 commits by the following individuals:</p>
<blockquote>
<p>Aleksander Sabak, Andy Kluger, Cat Stevens, Dmitry Matveyev, Doug Coleman,
Giftpflanze, John Benediktsson, Jon Harper, Jonas Bernouli, Leo Mehraban, Mike
Stevenson, Nicholas Chandoke, Niklas Larsson, Rebecca Kelly, Samuel Tardieu,
Stefan Schmiedl, <a href="https://github.com/Bruno-366">@Bruno-366</a>,
<a href="https://github.com/bobisageek">@bobisageek</a>,
<a href="https://github.com/coltsingleactionarmyocelot">@coltsingleactionarmyocelot</a>,
<a href="https://github.com/inivekin">@inivekin</a>,
<a href="https://github.com/knottio">@knottio</a>, <a href="https://github.com/timor">@timor</a></p>
</blockquote>
<p>Besides some bug fixes and library improvements, I want to highlight the following changes:</p>
<ul>
<li>Moved the UI to render buttons and scrollbars rather than using images, which
allows easier theming.</li>
<li>Fixed <a href="https://re.factorcode.org/2025/09/hidpi.html">HiDPI</a> scaling on Linux and
Windows, although it currently doesn‚Äôt update the window settings when
switching between screens with different scaling factors.</li>
<li>Update to Unicode 17.0.0.</li>
<li>Plugin support for the <a href="https://re.factorcode.org/2025/08/neovim.html">Neovim editor</a>.</li>
</ul>
<p>Some possible backwards compatibility issues:</p>
<ul>
<li>The argument order to <code>ltake</code> was swapped to be more consistent with words like <code>head</code>.</li>
<li>The <code>environment</code> vocabulary on Windows now supports disambiguating <code>f</code> and <code>""</code> (empty) values</li>
<li>The <code>misc/atom</code> folder was removed in favor of the <a href="https://github.com/factor/atom-language-factor">factor/atom-language-factor</a> repo.</li>
<li>The <code>misc/Factor.tmbundle</code> folder was removed in favor of the <a href="https://github.com/factor/factor.tmbundle">factor/factor.tmbundle</a> repo.</li>
<li>The <code>misc/vim</code> folder was removed in favor of the <a href="https://github.com/factor/factor.vim">factor/factor.vim</a> repo.</li>
<li>The <code>http</code> vocabulary <code>request</code> tuple had a slot rename from <code>post-data</code> to <code>data</code>.</li>
<li>The <code>furnace.asides</code> vocabulary had a slot rename from <code>post-data</code> to <code>data</code>, and might require running <code>ALTER TABLE asides RENAME COLUMN "post-data" TO data;</code>.</li>
<li>The <code>html.streams</code> vocabulary was renamed to <code>io.streams.html</code></li>
<li>The <code>pdf.streams</code> vocabulary was renamed to <code>io.streams.pdf</code></li>
</ul>
<h3 id="what-is-factor">What is Factor</h3>
<p>Factor is a <a href="https://www.concatenative.org/">concatenative</a>, stack-based
programming language with <a href="https://concatenative.org/wiki/view/Factor/Features/The%20language">high-level
features</a>
including dynamic types, extensible syntax, macros, and garbage
collection. On a practical side, Factor has a <a href="https://docs.factorcode.org/content/article-vocab-index.html">full-featured
library</a>,
supports many different platforms, and has been extensively documented.</p>
<p>The implementation is <a href="https://concatenative.org/wiki/view/Factor/Optimizing%20compiler">fully
compiled</a>
for performance, while still supporting <a href="https://concatenative.org/wiki/view/Factor/Interactive%20development">interactive
development</a>.
Factor applications are portable between all common platforms. Factor
can <a href="https://concatenative.org/wiki/view/Factor/Deployment">deploy stand-alone
applications</a> on
all platforms. Full source code for the Factor project is available
under a BSD license.</p>
<h3 id="new-libraries">New libraries:</h3>
<ul>
<li><a href="https://docs.factorcode.org/content/vocab-base92.html">base92</a>: adding support for Base92 encoding/decoding</li>
<li><a href="https://docs.factorcode.org/content/vocab-bitcask.html">bitcask</a>: implementing the <a href="https://re.factorcode.org/2025/06/bitcask.html">Bitcask key/value database</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-bluesky.html">bluesky</a>: adding support for the BlueSky protocol</li>
<li><a href="https://docs.factorcode.org/content/vocab-calendar.holidays.world.html">calendar.holidays.world</a>: adding some new holidays including <a href="https://re.factorcode.org/2025/07/world-emoji-day.html">World Emoji Day</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-classes.enumeration.html">classes.enumeration</a>: adding <em>enumeration classes</em> and new <code>ENUMERATION:</code> syntax word</li>
<li><a href="https://docs.factorcode.org/content/vocab-colors.oklab.html">colors.oklab</a>: adding support for <a href="https://en.wikipedia.org/wiki/Oklab_color_space">OKLAB color space</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-colors.oklch.html">colors.oklch</a>: adding support for <a href="https://en.wikipedia.org/wiki/Oklab_color_space">OKLCH color space</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-colors.wavelength.html">colors.wavelength</a>: adding <code>wavelength&gt;rgba</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-combinators.syntax.html">combinators.syntax</a>: adding experimental <em>combinator syntax</em> words <code>@[</code>, <code>*[</code>, and <code>&amp;[</code>, and short-circuiting <code>n&amp;&amp;[</code>, <code>n||[</code>, <code>&amp;&amp;[</code> and <code>||[</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-continuations.extras.html">continuations.extras</a>: adding <code>with-datastacks</code> and <code>datastack-states</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-dotenv.html">dotenv</a>: implementing support for <a href="https://re.factorcode.org/2025/06/dotenv.html">Dotenv</a> files</li>
<li><a href="https://docs.factorcode.org/content/vocab-edn.html">edn</a>: implementing support for <a href="https://re.factorcode.org/2025/10/extensible-data-notation.html">Extensible Data Notation</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-editors.cursor.html">editors.cursor</a>: adding support for the <a href="https://www.cursor.com/">Cursor</a> editor</li>
<li><a href="https://docs.factorcode.org/content/vocab-editors.rider.html">editors.rider</a>: adding support for the <a href="https://www.jetbrains.com/rider/">JetBrains Rider</a> editor</li>
<li><a href="https://docs.factorcode.org/content/vocab-gitignore.html">gitignore</a>: parser for <code>.gitignore</code> files</li>
<li><a href="https://docs.factorcode.org/content/vocab-http.json.html">http.json</a>: promoted <code>json.http</code> and added some useful words</li>
<li><a href="https://docs.factorcode.org/content/vocab-io.streams.farkup.html">io.streams.farkup</a>: a <a href="https://concatenative.org/wiki/view/Farkup">Farkup</a> formatted stream protocol</li>
<li><a href="https://docs.factorcode.org/content/vocab-io.streams.markdown.html">io.streams.markdowns</a>: a <a href="https://en.wikipedia.org/wiki/Markdown">Markdown</a> formatted stream protocol</li>
<li><a href="https://docs.factorcode.org/content/vocab-locals.lazy.html">locals.lazy</a>: prototype of <a href="https://re.factorcode.org/2024/10/emit.html">emit syntax</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-monadics.html">monadics</a>: alternative vocabulary for using Haskell-style monads, applicatives, and functors</li>
<li><a href="https://docs.factorcode.org/content/vocab-multibase.html">multibase</a>: implementation of <a href="https://github.com/multiformats/multibase">Multibase</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-pickle.html">pickle</a>: support for the <a href="https://re.factorcode.org/2025/08/pickle.html">Pickle</a> serialization format</li>
<li><a href="https://docs.factorcode.org/content/vocab-persistent.hashtables.identity.html">persistent.hashtables.identity</a>: support an <a href="https://docs.factorcode.org/content/word-identity-hashcode,kernel.html">identity-hashcode</a> version of persisent hashtables</li>
<li><a href="https://docs.factorcode.org/content/vocab-raylib.live-coding.html">raylib.live-coding</a>: demo of a vocabulary to do ‚Äúlive coding‚Äù of Raylib programs</li>
<li><a href="https://docs.factorcode.org/content/vocab-rdap.html">rdap</a>: support for the <a href="https://re.factorcode.org/2025/03/rdap.html">Registration Data Access Protocol</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-reverse.html">reverse</a>: implementation of the <a href="https://re.factorcode.org/2025/09/std-flip.html">std::flip</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-slides.cli.html">slides.cli</a>: simple text-based command-line interface for slides</li>
<li><a href="https://docs.factorcode.org/content/vocab-tools.highlight.html">tools.highlight</a>: command-line syntax-highlighting tool</li>
<li><a href="https://docs.factorcode.org/content/vocab-tools.random.html">tools.random</a>: command-line random generator tool</li>
<li><a href="https://docs.factorcode.org/content/vocab-ui.pens.rounded.html">ui.pens.rounded</a>: adding rounded corner <a href="https://docs.factorcode.org/content/vocab-ui.pens.html">pen</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-ui.pens.theme.html">ui.pens.theme</a>: experimental themed <a href="https://docs.factorcode.org/content/vocab-ui.pens.html">pen</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-ui.tools.theme.html">ui.tools.theme</a>: some words for updating <a href="https://docs.factorcode.org/content/article-ui-tools.html">UI developer tools</a> themes</li>
</ul>
<h3 id="improved-libraries">Improved libraries:</h3>
<ul>
<li><a href="https://docs.factorcode.org/content/vocab-alien.syntax.html">alien.syntax</a>: added <code>C-LIBRARY:</code> syntax word</li>
<li><a href="https://docs.factorcode.org/content/vocab-assocs.extras.html">assocs.extras</a>: added <code>nzip</code> and <code>nunzip</code>, <code>map-zip</code> and <code>map-unzip</code> macros</li>
<li><a href="https://docs.factorcode.org/content/vocab-base32.html">base32</a>: adding the <a href="http://philzimmermann.com/docs/human-oriented-base-32-encoding.txt">human-oriented Base32</a> encoding via <code>zbase32&gt;</code> and <code>&gt;zbase32</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-base64.html">base64</a>: minor performance improvement</li>
<li><a href="https://docs.factorcode.org/content/vocab-benchmark.html">benchmark</a>: adding more benchmarks</li>
<li><a href="https://docs.factorcode.org/content/vocab-bootstrap.assembler.html">bootstrap.assembler</a>: fixes for ARM-64</li>
<li><a href="https://docs.factorcode.org/content/vocab-brainfuck.html">brainfuck</a>: added <code>BRAINFUCK:</code> syntax word and <code>interpret-brainfuck</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-bson.html">bson</a>: use <a href="https://docs.factorcode.org/content/article-linked-assocs.html">linked-assocs</a> to preserve order</li>
<li><a href="https://docs.factorcode.org/content/vocab-cache.html">cache</a>: implement <code>M\ cache-assoc delete-at</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-calendar.html">calendar</a>: adding <code>year&lt;</code>, <code>year&lt;=</code>, <code>year&gt;</code>, <code>year&gt;=</code> words</li>
<li><a href="https://docs.factorcode.org/content/vocab-calendar.format.html">calendar.format</a>: parse human-readable and elapsed-time output back into duration objects</li>
<li><a href="https://docs.factorcode.org/content/vocab-cbor.html">cbor</a>: use <a href="https://docs.factorcode.org/content/article-linked-assocs.html">linked-assocs</a> to preserve order</li>
<li><a href="https://docs.factorcode.org/content/vocab-classes.mixin.html">classes.mixin</a>: added <code>definer</code> implementation</li>
<li><a href="https://docs.factorcode.org/content/vocab-classes.singleton.html">classes.singleton</a>: added <code>definer</code> implementation</li>
<li><a href="https://docs.factorcode.org/content/vocab-classes.tuple.html">classes.tuple</a>: added <code>tuple&gt;slots</code>, rename <code>tuple&gt;array</code> to <code>pack-tuple</code> and <code>&gt;tuple</code> to <code>unpack-tuple</code>.</li>
<li><a href="https://docs.factorcode.org/content/vocab-classes.union.html">classes.union</a>: added <code>definer</code> implementation</li>
<li><a href="https://docs.factorcode.org/content/vocab-checksums.sha.html">checksums.sha</a>: some 20-40% performance improvements</li>
<li><a href="https://docs.factorcode.org/content/vocab-command-line.html">command-line</a>: allow passing script name of <code>-</code> to use stdin</li>
<li><a href="https://docs.factorcode.org/content/vocab-command-line.parser.html">command-line.parser</a>: support for <a href="https://re.factorcode.org/2025/07/argument-parser-commands.html">Argument Parser Commands</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-command-line.startup.html">command-line.startup</a>: document <code>-q</code> quiet mode flag</li>
<li><a href="https://docs.factorcode.org/content/vocab-concurrency.combinators.html">concurrency.combinators</a>: faster <code>parallel-map</code> and <code>parallel-assoc-map</code> using a <a href="https://docs.factorcode.org/content/article-concurrency.count-downs.html">count-down latch</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-concurrency.promises.html">concurrency.promises</a>: 5-7% performance improvement</li>
<li><a href="https://docs.factorcode.org/content/vocab-continuations.html">continuations</a>: improve docs and fix stack effect for <code>ifcc</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-countries.html">countries</a>: adding <code>CQ</code> country code for <a href="https://en.wikipedia.org/wiki/Sark">Sark</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-cpu.architecture.html">cpu.architecture</a>: fix <code>*-branch</code> stack effects</li>
<li><a href="https://docs.factorcode.org/content/vocab-cpu.arm.html">cpu.arm</a>: fixes for ARM-64</li>
<li><a href="https://docs.factorcode.org/content/vocab-crontab.html">crontab</a>: added <code>parse-crontab</code> which ignores blank lines and comments</li>
<li><a href="https://docs.factorcode.org/content/vocab-db.html">db</a>: making <code>query-each</code> row-polymorphic</li>
<li><a href="https://docs.factorcode.org/content/vocab-delegate.protocols.html">delegate.protocols</a>: adding <code>keys</code> and <code>values</code> to <code>assoc-protocol</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-discord.html">discord</a>: better support for network disconnects, added a configurable retry interval</li>
<li><a href="https://docs.factorcode.org/content/vocab-discord.chatgpt-bot.html">discord.chatgpt-bot</a>: some fixes for <a href="https://lmstudio.ai/">LM Studio</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-editors.html">editors</a>: make the <em>editor restart</em> nicer looking</li>
<li><a href="https://docs.factorcode.org/content/vocab-editors.focus.html">editors.focus</a>: support <em>open-file-to-line-number</em> on newer releases, support Linux and Window</li>
<li><a href="https://docs.factorcode.org/content/vocab-editors.zed.html">editors.zed</a>: support use of <a href="https://zed.dev/">Zed</a> on Linux</li>
<li><a href="https://docs.factorcode.org/content/vocab-endian.html">endian</a>: faster endian conversions of c-ptr-like objects</li>
<li><a href="https://docs.factorcode.org/content/vocab-environment.html">environment</a>: adding <code>os-env?</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-eval.html">eval</a>: move datastack and error messages to stderr</li>
<li><a href="https://docs.factorcode.org/content/vocab-fonts.html">fonts</a>: make <code>&lt;font&gt;</code> take a name, easier defaults</li>
<li><a href="https://docs.factorcode.org/content/vocab-furnace.asides.html">furnace.asides</a>: rename <code>post-data</code> slot on <code>aside</code> tuples to <code>data</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-generalizations.html">generalizations</a>: moved some <em>dip</em> words to <a href="https://docs.factorcode.org/content/vocab-shuffle.html">shuffle</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-help.tour.html">help.tour</a>: fix some typos/grammar</li>
<li><a href="https://docs.factorcode.org/content/vocab-html.template.chloe.html">html.templates.chloe</a>: improve use of <code>CDATA</code> tags for unescaping output</li>
<li><a href="https://docs.factorcode.org/content/vocab-http.html">http</a>: rename <code>post-data</code> slot on <code>request</code> tuples to <code>data</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-http.json.html">http.json</a>: adding <code>http-json</code> that doesn‚Äôt return the response object</li>
<li><a href="https://docs.factorcode.org/content/vocab-http.websockets.html">http.websockets</a>: making <code>read-websocket-loop</code> row-polymorphic</li>
<li><a href="https://docs.factorcode.org/content/vocab-ini-file.html">ini-file</a>: adding <code>ini&gt;file</code>, <code>file&gt;ini</code>, and use <code>LH{ }</code> to preserve configuration order</li>
<li><a href="https://docs.factorcode.org/content/vocab-io.encodings.detect.html">io.encodings.detect</a>: adding <code>utf7</code> detection</li>
<li><a href="https://docs.factorcode.org/content/vocab-io.encodings.utf8.html">io.encodings.utf8</a>: adding <code>utf8-bom</code> to handle optional BOM</li>
<li><a href="https://docs.factorcode.org/content/vocab-io.random.html">io.random</a>: speed up <code>random-line</code> and <code>random-lines</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-io.streams.ansi.html">io.streams.ansi</a>: adding documentation and tests, support dim foreground on terminals that support it</li>
<li><a href="https://docs.factorcode.org/content/vocab-io.streams.escape-codes.html">io.streams.escape-codes</a>: adding documentation and tests</li>
<li><a href="https://docs.factorcode.org/content/vocab-ip-parser.html">ip-parser</a>: adding IPV4 and IPV6 network words</li>
<li><a href="https://docs.factorcode.org/content/vocab-kernel.html">kernel</a>: adding <code>until*</code>, fix docs for <code>and*</code> and <code>or*</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-linked-sets.html">linked-sets</a>: adding <code>LS{</code> syntax word</li>
<li><a href="https://docs.factorcode.org/content/vocab-lists.lazy.html">lists.lazy</a>: changed the argument order in <code>ltake</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-macho.html">macho</a>: support a few more link edit commands</li>
<li><a href="https://docs.factorcode.org/content/vocab-make.html">make</a>: adding <code>,%</code> for a <code>push-at</code> variant</li>
<li><a href="https://docs.factorcode.org/content/vocab-mason.release.tidy.html">mason.release.tidy</a>: cleanup a few more git artifacts</li>
<li><a href="https://docs.factorcode.org/content/vocab-math.combinatorics.html">math.combinatorics</a>: adding <em>counting</em> words</li>
<li><a href="https://docs.factorcode.org/content/vocab-math.distances.html">math.distances</a>: adding <code>jaro-distance</code> and <code>jaro-winkler-distance</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-math.extras.html">math.extras</a>: added <code>all-removals</code>, support <a href="https://re.factorcode.org/2025/05/recamans-sequence.html">Recam√°n‚Äôs sequence</a>, and <a href="https://re.factorcode.org/2025/07/tribonacci-numbers.html">Tribonacci Numbers</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-math.factorials.html">math.factorials</a>: added <code>subfactorial</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-math.functions.html">math.functions</a>: added ‚Äúclosest to zero‚Äù modulus</li>
<li><a href="https://docs.factorcode.org/content/vocab-math.parser.html">math.parser</a>: improve ratio parsing for consistency</li>
<li><a href="https://docs.factorcode.org/content/vocab-math.primes.html">math.primes</a>: make <code>prime?</code> safe from non-integer inputs</li>
<li><a href="https://docs.factorcode.org/content/vocab-math.runge-kutta.html">math.runge-kutta</a>: make generalized improvements to the <a href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods">Runge-Kutta</a> solver</li>
<li><a href="https://docs.factorcode.org/content/vocab-math.similarity.html">math.similarity</a>: adding <code>jaro-similarity</code>, <code>jaro-winkler-similarity</code>, and <code>trigram-similarity</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-math.text.english.html">math.text.english</a>: fix issue with very large and very small floats</li>
<li><a href="https://docs.factorcode.org/content/vocab-metar.html">metar</a>: updated the abbreviations glossary</li>
<li><a href="https://docs.factorcode.org/content/vocab-mime.types.html">mime.types</a>: updating <code>mime.types</code> file</li>
<li><a href="https://docs.factorcode.org/content/vocab-msgpack.html">msgpack</a>: use <a href="https://docs.factorcode.org/content/article-linked-assocs.html">linked-assocs</a> to preserve order</li>
<li><a href="https://docs.factorcode.org/content/vocab-qw.html">qw</a>: adding <code>qw:</code> syntax</li>
<li><a href="https://docs.factorcode.org/content/vocab-path-finding.html">path-finding</a>: added <code>find-path*</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-peg.parsers.html">peg.parsers</a>: faster <code>list-of</code> and <code>list-of-many</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-progress-bars.models.html">progress-bars.models</a>: added <code>with-progress-display</code>, <code>map-with-progress-bar</code>, <code>each-with-progress-bar</code>, and <code>reduce-with-progress-bar</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-raylib.html">raylib</a>: adding <code>trace-log</code> and <code>set-trace-log-level</code>, updated to Raylib 5.5</li>
<li><a href="https://docs.factorcode.org/content/vocab-readline-listener.html">readline-listener</a>: store history across sessions, support color on terminals that support it</li>
<li><a href="https://docs.factorcode.org/content/vocab-robohash.html">robohash</a>: support for <code>"set4"</code>, <code>"set5"</code>, and <code>"set6"</code> types</li>
<li><a href="https://docs.factorcode.org/content/vocab-sequences.html">sequences</a>: rename <code>midpoint@</code> to <code>midpoint</code>, faster <code>each-from</code> and <code>map-reduce</code> on slices</li>
<li><a href="https://docs.factorcode.org/content/vocab-sequences.extras.html">sequences.extras</a>: adding <code>find-nth</code>, <code>find-nth-last</code>, <code>subseq-indices</code>, <code>deep-nth</code>, <code>deep-nth-of</code>, <code>2none?</code>, <code>filter-errors</code>, <code>reject-errors</code>, <code>all-same?</code>, <code>adjacent-differences</code>, and <code>partial-sum</code>.</li>
<li><a href="https://docs.factorcode.org/content/vocab-sequences.generalizations.html">sequences.generalizations</a>: fix <code>?firstn</code> and <code>?lastn</code> for string inputs, removed <code>(nsequence)</code> which duplicates <code>set-firstn-unsafe</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-sequences.prefixed.html">sequences.prefixed</a>: swap order of <code>&lt;prefixed&gt;</code> arguments to match <code>prefix</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-sequences.repeating.html">sequences.repeating</a>: adding <code>&lt;cycles-from&gt;</code> and <code>cycle-from</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-sequences.snipped.html">sequences.snipped</a>: fixed out-of-bounds issues</li>
<li><a href="https://docs.factorcode.org/content/vocab-scryfall.html">scryfall</a>: update for duskmourn</li>
<li><a href="https://docs.factorcode.org/content/vocab-shuffle.html">shuffle</a>: improve stack-checking of <code>shuffle(</code> syntax, added <code>SHUFFLE:</code> syntax, <code>nreverse</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-sorting.html">sorting</a>: fix <code>sort-with</code> to apply the quot with access to the stack below</li>
<li><a href="https://docs.factorcode.org/content/vocab-sorting.human.html">sorting.human</a>: implement <a href="https://re.factorcode.org/2025/03/human-sorting-improved.html">human sorting improved</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-system-info.macos.html">system-info.macos</a>: adding ‚ÄúTahoe‚Äù code-name for <a href="https://www.apple.com/newsroom/2025/06/macos-tahoe-26-makes-the-mac-more-capable-productive-and-intelligent-than-ever/">macOS 26</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-terminfo.html">terminfo</a>: add words for querying specific output capabilities</li>
<li><a href="https://docs.factorcode.org/content/vocab-threads.html">threads</a>: define a generalized <code>linked-thread</code> which used to be for <code>concurrency.mailboxes</code> only</li>
<li><a href="https://docs.factorcode.org/content/vocab-toml.html">toml</a>: use <a href="https://docs.factorcode.org/content/article-linked-assocs.html">linked-assocs</a> to preserve order, adding <code>&gt;toml</code> and <code>write-toml</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-tools.annotations.html">tools.annotations</a>: adding <code>&lt;WATCH ... WATCH&gt;</code> syntax</li>
<li><a href="https://docs.factorcode.org/content/vocab-tools.deploy.html">tools.deploy</a>: adding a command-line interface for deploy options</li>
<li><a href="https://docs.factorcode.org/content/vocab-tools.deploy.backend.html">tools.deploy.backend</a>: fix boot image location in system-wide installations</li>
<li><a href="https://docs.factorcode.org/content/vocab-tools.deploy.unix.html">tools.deploy.unix</a>: change binary name to append <code>.out</code> to fix conflict with vocab resources</li>
<li><a href="https://docs.factorcode.org/content/vocab-tools.directory-to-file.html">tools.directory-to-file</a>: better test file metrics, print filename for editing</li>
<li><a href="https://docs.factorcode.org/content/vocab-tools.memory.html">tools.memory</a>: adding <code>heap-stats-of</code> arbitrary sequence of instances, and <code>total-size</code> size of everything pointed to by an object</li>
<li><a href="https://docs.factorcode.org/content/vocab-txon.html">txon</a>: use <a href="https://docs.factorcode.org/content/article-linked-assocs.html">linked-assocs</a> to preserve order</li>
<li><a href="https://docs.factorcode.org/content/vocab-ui.html">ui</a>: adding <code>adjust-font-size</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-ui.gadgets.buttons.html">ui.gadgets.buttons</a>: stop using images and respect theme colors</li>
<li><a href="https://docs.factorcode.org/content/vocab-ui.gadgets.sliders.html">ui.gadgets.sliders</a>: stop using images and respect theme colors</li>
<li><a href="https://docs.factorcode.org/content/vocab-ui.theme.base16.html">ui.theme.base16</a>: adding a lot more (270!) <a href="https://re.factorcode.org/2024/10/base16-themes.html">Base16 Themes</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-ui.tools.html">ui.tools</a>: adding font-sizing keyboard shortcuts</li>
<li><a href="https://docs.factorcode.org/content/vocab-ui.tools.browser.html">ui.tools.browser</a>: more responsive font sizing</li>
<li><a href="https://docs.factorcode.org/content/vocab-ui.tools.listener.html">ui.tools.listener</a>: more responsive font sizing, adding some <a href="https://docs.factorcode.org/content/article-ui-listener-style.html">UI listener styling</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-ui.tools.listener.completion.html">ui.tools.listener.completion</a>: allow spaces in history search popup</li>
<li><a href="https://docs.factorcode.org/content/vocab-unicode.html">unicode</a>: update to <a href="https://www.unicode.org/versions/Unicode17.0.0/">Unicode 17.0.0</a></li>
<li><a href="https://docs.factorcode.org/content/vocab-webapps.planet.html">webapps.planet</a>: improve CSS for <code>video</code> tags</li>
<li><a href="https://docs.factorcode.org/content/vocab-words.html">words</a>: adding <code>define-temp-syntax</code></li>
<li><a href="https://docs.factorcode.org/content/vocab-zoneinfo.html">zoneinfo</a>: update to version 2025b</li>
</ul>
<h3 id="removed-libraries">Removed libraries</h3>
<ul>
<li><code>ui.theme.images</code></li>
</ul>
<h3 id="vm-improvements">VM Improvements:</h3>
<ul>
<li>More work on ARM64 backend (fix set-callstack, fix generic dispatch)</li>
</ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop Breaking TLS (146 pts)]]></title>
            <link>https://www.markround.com/blog/2025/12/09/stop-breaking-tls/</link>
            <guid>46214950</guid>
            <pubDate>Wed, 10 Dec 2025 07:06:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.markround.com/blog/2025/12/09/stop-breaking-tls/">https://www.markround.com/blog/2025/12/09/stop-breaking-tls/</a>, See on <a href="https://news.ycombinator.com/item?id=46214950">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
        <header>
          
          


          
  <p><strong> Updated:</strong> <time datetime="2025-12-09T08:40:51+00:00">December 9, 2025</time></p>


        </header>
      

      <section itemprop="text">
        


        
        <p><a href="https://news.ycombinator.com/item?id=46214950">Discussion on Hacker News</a>  <a href="https://lobste.rs/s/h7a3xy/stop_breaking_tls">Discussion on lobste.rs</a></p>

<p>Rant ahead: I hate TLS ‚ÄúInspection‚Äù software with a burning passion and I wish we collectively as an industry would just knock it the <em>fuck</em> off and stop pretending it‚Äôs some great security benefit. Every time I encounter it, in whatever form, it‚Äôs a gigantic headache that makes everyone‚Äôs life worse off and as far as I am concerned offers next to zero tangible benefits.</p>

<p>For those blissfully unaware, this is a class of ‚Äúsecurity‚Äù software or appliance that is supposed to let organisations monitor all encrypted traffic. It does this by inserting itself in the middle of traffic, stripping the encryption off so it can inspect it and then re-signing it with its own certificate. If that sounds familiar, it‚Äôs because it‚Äôs a widely known class of attack - the Man In The Middle attack. Great stuff, we‚Äôre literally deploying the exact attack vector that TLS was designed to prevent, but slapping a ‚Äúsecurity‚Äù label on it.</p>

<p>Firstly, it undermines one of the most important protocols of the modern Internet as it deliberately breaks all the guarantees that TLS encryption is supposed to offer. If the MITM certificate is installed everywhere, your company can intercept and monitor everything you say and do. Consider the ramifications of that - confidential messages to HR, medical information, insider trading information, your banking sessions - would you feel happy BCC‚Äôing every single email to your IT department? Would you print out your therapy notes and pin them to the kitchen notice board?</p>

<p>But even ignoring the philosophical arguments about privacy and trust, I argue it actively makes your security <em>worse</em>. Consider this - what is the likelihood of every certificate authority on the Internet having their private keys compromised simultaneously? I‚Äôd wager that‚Äôs almost at the whatever is the statistics equivalent of the Planck length level of probability.¬π</p>

<p>On the other hand, what‚Äôs the chance of your company‚Äôs MITM private key getting compromised by an attacker? Even if you completely trust your IT team and vendor (and if you do, you clearly haven‚Äôt been paying attention to any tech news for oh‚Ä¶ the last few decades), you have to admit that chance is a lot higher. And depending on the vendor or tech stack involved, it could be a LOT higher. One disgruntled employee, one unpatched vulnerability, one phishing email to the right admin and choo-choo, it‚Äôs all aboard the FAIL train. Now an attacker could have the keys to your entire kingdom.</p>

<p>Then there‚Äôs the practicalities of it. It‚Äôs simply a massive hassle. Different Operating Systems expect certificates in different formats (PEM? DER? PFX? P7B?) installed in different places with different tooling to manage it all. <code>update-ca-certificates</code> vs <code>update-ca-trust</code> is just the tip of the iceberg - and that‚Äôs just the OS level. You then have language runtimes (Java keystore anyone?) and the applications themselves that all need to be configured.</p>

<p>And the problem is compounded with modern cloud-native apps. In a Kubernetes cluster, as well as having to handle updating the node VM images and container runtimes, you‚Äôll have dozens if not hundreds of different base images each of which has their own standards. Alpine uses a different certificate path than Ubuntu. Your Node app expects them somewhere else entirely. The various CRDs or Helm charts you are using may or may not support custom CA bundles, and if they do there‚Äôs no agreed-on standard.</p>

<p>Now I‚Äôm not saying that because a problem is hard we should simply give up, but even if the benefits were worth it the simple fact is even with the best tooling and automation, you are <strong>guaranteed</strong> to miss something. Whether it‚Äôs some obscure tool that has a custom keystore and non-standard tooling, a quick ‚Äúone off‚Äù command in an ephemeral container, some app that uses certificate pinning or an aging switch firmware that doesn‚Äôt even support custom certificate bundles, <em>something</em> will slip through the cracks. And when it does, guess what happens?</p>

<p>Which brings me to my biggest peeve: it normalizes bad security practices. Given that you will never have 100% coverage of your CA certificate installation - particularly amongst your technical teams who will be using a multitude of different tools and platforms - you get developers and sysadmins used to TLS errors. Instead of treating each one as an anomaly and something to be investigated, you get used to just running with <code>--insecure</code> or <code>curl -k</code> because you just need to get shit done. Turning off certificate verification becomes a routine troubleshooting step. ‚ÄúOh, it‚Äôs probably just the corporate proxy again‚Äù becomes the reflexive response to any TLS error. You‚Äôve just trained your entire technical staff to ignore one of the most important security warnings on the Internet!</p>

<p>And don‚Äôt even get me started on the performance and availability implications. All your traffic now has to be decrypted and re-encrypted by your magic box. Hope you sized that appliance correctly! Hope it doesn‚Äôt become a single point of failure! Hope it supports all the latest TLS versions and cipher suites!</p>

<p>There are a multitude of ways to protect yourself that are not only less invasive but are often <em>more</em> effective because they‚Äôre designed for how modern infrastructure actually works. Anomaly detection, Zero Trust network architecture, EDR, Netflow analysis‚Ä¶ You don‚Äôt need to create single points of failure, and you can actually work with modern cloud-native infrastructure instead of fighting it. Plus, y‚Äôknow, there‚Äôs this AI thing which as it turns out is actually quite useful at analysing metadata and spotting odd behavioral patterns.</p>

<p>In my experience: TLS <del>Inspection</del> MITM is a gigantic administrative burden, it normalizes bad practice, it creates bottlenecks and availability risks, and actively worsens your security posture.</p>

<p>Just stop it already.</p>

<p><strong>NOTE :</strong> This was a particularly cathartic rant, and I didn‚Äôt expect it to blow up and hit the front page of Hacker News! While I was venting away, I do appreciate that there is actually some nuance at play here so for a fuller discussion with some dissenting opinions, please do check out the <a href="https://news.ycombinator.com/item?id=46214950">comment thread</a>.</p>

<p>¬π = In particular, I worded this poorly. What I was thinking of was more along the lines of being able to do this without detection via CT logs etc. A commenter on HN <a href="https://news.ycombinator.com/item?id=46214950#46215764">pointed out</a> that you only need one trusted CA to be compromised which is of course true.</p>

        
      </section>

      

      

      
  

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Revisiting "Let's Build a Compiler" (258 pts)]]></title>
            <link>https://eli.thegreenplace.net/2025/revisiting-lets-build-a-compiler/</link>
            <guid>46214693</guid>
            <pubDate>Wed, 10 Dec 2025 06:22:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eli.thegreenplace.net/2025/revisiting-lets-build-a-compiler/">https://eli.thegreenplace.net/2025/revisiting-lets-build-a-compiler/</a>, See on <a href="https://news.ycombinator.com/item?id=46214693">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                <p>There's an old compiler-building tutorial that has become part of the field's
lore: the <a href="https://compilers.iecc.com/crenshaw/">Let's Build a Compiler</a>
series by Jack Crenshaw (published between 1988 and 1995).</p>
<p>I <a href="https://eli.thegreenplace.net/2003/07/29/great-compilers-tutorial">ran into it in 2003</a>
and was very impressed, but it's now 2025 and this tutorial is still being mentioned quite
often <a href="https://hn.algolia.com/?dateRange=pastYear&amp;page=0&amp;prefix=true&amp;query=crenshaw&amp;sort=byDate&amp;type=all">in Hacker News threads</a>.
Why is that? Why does a tutorial from 35
years ago, built in Pascal and emitting Motorola 68000 assembly - technologies that
are virtually unknown for the new generation of programmers - hold sway over
compiler enthusiasts? I've decided to find out.</p>
<p>The tutorial is <a href="https://compilers.iecc.com/crenshaw/">easily available and readable online</a>, but
just re-reading it seemed insufficient. So I've decided on meticulously
translating the compilers built in it to Python and emit a more modern target -
WebAssembly. It was an enjoyable process and I want to share the outcome and
some insights gained along the way.</p>
<p>The result is <a href="https://github.com/eliben/letsbuildacompiler">this code repository</a>.
Of particular interest is the <a href="https://github.com/eliben/letsbuildacompiler/blob/main/TUTORIAL.md">TUTORIAL.md file</a>,
which describes how each part in the original tutorial is mapped to my code. So
if you want to read the original tutorial but play with code you can actually
easily try on your own, feel free to follow my path.</p>
<div id="a-sample">
<h2>A sample</h2>
<p>To get a taste of the input language being compiled and the output my compiler
generates, here's a sample program in the KISS language designed by Jack
Crenshaw:</p>
<div><pre><span></span>var X=0

 { sum from 0 to n-1 inclusive, and add to result }
 procedure addseq(n, ref result)
     var i, sum  { 0 initialized }
     while i &lt; n
         sum = sum + i
         i = i + 1
     end
     result = result + sum
 end

 program testprog
 begin
     addseq(11, X)
 end
 .
</pre></div>
<p>It's from part 13 of the tutorial, so it showcases procedures along with control
constructs like the <tt>while</tt> loop, and passing parameters both by value and by
reference. Here's the WASM text generated by my compiler for part 13:</p>
<div><pre><span></span><span>(</span><span>module</span>
  <span>(</span><span>memory</span> <span>8</span><span>)</span>
  <span>;; Linear stack pointer. Used to pass parameters by ref.</span>
  <span>;; Grows downwards (towards lower addresses).</span>
  <span>(</span><span>global</span> <span>$__sp</span> <span>(</span><span>mut</span> <span>i32</span><span>)</span> <span>(</span><span>i32.const</span> <span>65536</span><span>))</span>

  <span>(</span><span>global</span> <span>$X</span> <span>(</span><span>mut</span> <span>i32</span><span>)</span> <span>(</span><span>i32.const</span> <span>0</span><span>))</span>

  <span>(</span><span>func</span> <span>$ADDSEQ</span> <span>(</span><span>param</span> <span>$N</span> <span>i32</span><span>)</span> <span>(</span><span>param</span> <span>$RESULT</span> <span>i32</span><span>)</span>
    <span>(</span><span>local</span> <span>$I</span> <span>i32</span><span>)</span>
    <span>(</span><span>local</span> <span>$SUM</span> <span>i32</span><span>)</span>
    <span>loop</span> <span>$loop1</span>
      <span>block</span> <span>$breakloop1</span>
        <span>local.get</span> <span>$I</span>
        <span>local.get</span> <span>$N</span>
        <span>i32.lt_s</span>
        <span>i32.eqz</span>
        <span>br_if</span> <span>$breakloop1</span>
        <span>local.get</span> <span>$SUM</span>
        <span>local.get</span> <span>$I</span>
        <span>i32.add</span>
        <span>local.set</span> <span>$SUM</span>
        <span>local.get</span> <span>$I</span>
        <span>i32.const</span> <span>1</span>
        <span>i32.add</span>
        <span>local.set</span> <span>$I</span>
        <span>br</span> <span>$loop1</span>
      <span>end</span>
    <span>end</span>
    <span>local.get</span> <span>$RESULT</span>
    <span>local.get</span> <span>$RESULT</span>
    <span>i32.load</span>
    <span>local.get</span> <span>$SUM</span>
    <span>i32.add</span>
    <span>i32.store</span>
  <span>)</span>

  <span>(</span><span>func</span> <span>$main</span> <span>(</span><span>export</span> <span>"main"</span><span>)</span> <span>(</span><span>result</span> <span>i32</span><span>)</span>
    <span>i32.const</span> <span>11</span>
    <span>global.get</span> <span>$__sp</span>      <span>;; make space on stack</span>
    <span>i32.const</span> <span>4</span>
    <span>i32.sub</span>
    <span>global.set</span> <span>$__sp</span>
    <span>global.get</span> <span>$__sp</span>
    <span>global.get</span> <span>$X</span>
    <span>i32.store</span>
    <span>global.get</span> <span>$__sp</span>    <span>;; push address as parameter</span>
    <span>call</span> <span>$ADDSEQ</span>
    <span>;; restore parameter X by ref</span>
    <span>global.get</span> <span>$__sp</span>
    <span>i32.load</span> <span>offset</span><span>=</span><span>0</span>
    <span>global.set</span> <span>$X</span>
    <span>;; clean up stack for ref parameters</span>
    <span>global.get</span> <span>$__sp</span>
    <span>i32.const</span> <span>4</span>
    <span>i32.add</span>
    <span>global.set</span> <span>$__sp</span>
    <span>global.get</span> <span>$X</span>
  <span>)</span>
<span>)</span>
</pre></div>
<p>You'll notice that there is some trickiness in the emitted code w.r.t. handling
the by-reference parameter (my <a href="https://eli.thegreenplace.net/2025/notes-on-the-wasm-basic-c-abi/">previous post</a>
deals with this issue in more detail). In general, though, the emitted code is
inefficient - there is close to 0 optimization applied.</p>
<p>Also, if you're very diligent you'll notice something odd about the global
variable <tt>X</tt> - it seems to be implicitly returned by the generated <tt>main</tt>
function. This is just a testing facility that makes my compiler easy to test.
All the compilers are extensively tested - usually by running the
generated WASM code <a href="#footnote-1" id="footnote-reference-1">[1]</a> and verifying expected results.</p>
</div>
<div id="insights-what-makes-this-tutorial-so-special">
<h2>Insights - what makes this tutorial so special?</h2>
<p>While reading the original tutorial again, I had on opportunity to reminisce on
what makes it so effective. Other than the very fluent and conversational
writing style of Jack Crenshaw, I think it's a combination of two key
factors:</p>
<ol>
<li>The tutorial builds a recursive-descent parser step by step, rather than
giving a long preface on automata and table-based parser generators. When
I first encountered it (in 2003), it was taken for granted that if you want
to write a parser then lex + yacc are the way to go <a href="#footnote-2" id="footnote-reference-2">[2]</a>. Following the
development of a simple and clean hand-written
parser was a revelation that wholly changed my approach to the subject;
subsequently, hand-written recursive-descent parsers have been my go-to approach
<a href="https://eli.thegreenplace.net/tag/recursive-descent-parsing">for almost 20 years now</a>.</li>
<li>Rather than getting stuck in front-end minutiae, the tutorial goes straight
to generating working assembly code, from very early on. This was also a
breath of fresh air for engineers who grew up with more traditional courses
where you spend 90% of the time on parsing, type checking and other semantic
analysis and often run entirely out of steam by the time code generation
is taught.</li>
</ol>
<p>To be honest, I don't think either of these are a big problem with modern
resources, but back in the day the tutorial clearly hit the right nerve with
many people.</p>
</div>
<div id="what-else-does-it-teach-us">
<h2>What else does it teach us?</h2>
<p>Jack Crenshaw's tutorial takes the <a href="https://en.wikipedia.org/wiki/Syntax-directed_translation">syntax-directed translation</a>
approach, where code is emitted <em>while parsing</em>, without having to divide the
compiler into explicit phases with IRs. As I said above, this is a fantastic
approach for getting started, but in the latter parts of the tutorial it starts
showing its limitations. Especially once we get to types, it becomes painfully
obvious that it would be very nice if we knew the types of expressions <em>before</em>
we generate code for them.</p>
<p>I don't know if this is implicated in Jack Crenshaw's abandoning the tutorial
at some point after part 14, but it may very well be. He keeps writing how
the emitted code is clearly sub-optimal <a href="#footnote-3" id="footnote-reference-3">[3]</a> and can be improved, but IMHO it's
just not that easy to improve using the syntax-directed translation strategy.
With perfect hindsight vision, I would probably use Part 14 (types) as a turning
point - emitting some kind of AST from the parser and then doing simple type
checking and analysis on that AST prior to generating code from it.</p>
</div>
<div id="conclusion">
<h2>Conclusion</h2>
<p>All in all, the original tutorial remains a wonderfully readable introduction
to building compilers. This post and the <a href="https://github.com/eliben/letsbuildacompiler">GitHub repository</a>
it describes are a modest
contribution that aims to improve the experience of folks reading the original
tutorial today and not willing to use obsolete technologies. As always, let
me know if you run into any issues or have questions!</p>
<hr>
<table id="footnote-1">
<colgroup><col><col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-1">[1]</a></td><td>This is done using the <a href="https://pypi.org/project/wasmtime/">Python bindings to wasmtime</a>.</td></tr>
</tbody>
</table>
<table id="footnote-2">
<colgroup><col><col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-2">[2]</a></td><td>By the way, gcc switched from YACC to hand-written recursive-descent
parsing in the 2004-2006 timeframe, and Clang has been implemented with
a recursive-descent parser from the start (2007).</td></tr>
</tbody>
</table>
<table id="footnote-3">
<colgroup><col><col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-3">[3]</a></td><td><p>Concretely: when we compile <tt>subexpr1 + subexpr2</tt> and the two sides have different
types, it would be mighty nice to know that <em>before</em> we actually generate
the code for both sub-expressions. But the syntax-directed translation
approach just doesn't work that way.</p>
<p>To be clear: it's easy to generate <em>working</em> code; it's just not easy
to generate optimal code without some sort of type analysis that's
done before code is actually generated.</p>
</td></tr>
</tbody>
</table>
</div>

            </div></div>]]></description>
        </item>
    </channel>
</rss>