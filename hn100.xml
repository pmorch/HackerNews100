<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 19 Sep 2024 10:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[US health system ranks last compared with peer nations, report finds – US news (111 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2024/sep/18/american-health-system-ranks-last</link>
            <guid>41588717</guid>
            <pubDate>Thu, 19 Sep 2024 05:08:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2024/sep/18/american-health-system-ranks-last">https://www.theguardian.com/us-news/2024/sep/18/american-health-system-ranks-last</a>, See on <a href="https://news.ycombinator.com/item?id=41588717">Hacker News</a></p>
Couldn't get https://www.theguardian.com/us-news/2024/sep/18/american-health-system-ranks-last: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla has fired their Chief Product Officer after cancer diagnosis (137 pts)]]></title>
            <link>https://mastodon.social/@stevetex/113162099798398758</link>
            <guid>41588667</guid>
            <pubDate>Thu, 19 Sep 2024 05:00:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.social/@stevetex/113162099798398758">https://mastodon.social/@stevetex/113162099798398758</a>, See on <a href="https://news.ycombinator.com/item?id=41588667">Hacker News</a></p>
Couldn't get https://mastodon.social/@stevetex/113162099798398758: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: My son might be blind – how to best support (137 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=41588200</link>
            <guid>41588200</guid>
            <pubDate>Thu, 19 Sep 2024 03:27:43 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=41588200">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=41588200: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Nintendo Files Suit for Infringement of Patent Rights Against Pocketpair, Inc (252 pts)]]></title>
            <link>https://www.nintendo.co.jp/corporate/release/en/2024/240919.html</link>
            <guid>41587214</guid>
            <pubDate>Thu, 19 Sep 2024 00:37:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nintendo.co.jp/corporate/release/en/2024/240919.html">https://www.nintendo.co.jp/corporate/release/en/2024/240919.html</a>, See on <a href="https://news.ycombinator.com/item?id=41587214">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="single_frame">
        <div>
          <p>September 19, 2024</p>
          <p>To Whom It May Concern</p>
          <p>
            The Pokémon Company<br>
            Nintendo Co., Ltd.
          </p>
        </div>
      
      <div>

        <p>
          Nintendo Co., Ltd. (HQ: Kyoto, Minami-ku, Japan; Representative Director and President: Shuntaro Furukawa, “Nintendo” hereafter), together with The Pokémon Company, filed a patent infringement lawsuit in the Tokyo District Court against Pocketpair, Inc. (HQ: 2-10-2 Higashigotanda, Shinagawa-ku, Tokyo, “Defendant” hereafter) on September 18, 2024.
        </p>
        <p>
          This lawsuit seeks an injunction against infringement and compensation for damages on the grounds that <i>Palworld</i>, a game developed and released by the Defendant, infringes multiple patent rights.
        </p>
        <p>
          Nintendo will continue to take necessary actions against any infringement of its intellectual property rights including the Nintendo brand itself, to protect the intellectual properties it has worked hard to establish over the years.
        </p>
      </div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ruby-SAML pwned by XML signature wrapping attacks (110 pts)]]></title>
            <link>https://ssoready.com/blog/engineering/ruby-saml-pwned-by-xml-signature-wrapping-attacks/</link>
            <guid>41586031</guid>
            <pubDate>Wed, 18 Sep 2024 21:59:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ssoready.com/blog/engineering/ruby-saml-pwned-by-xml-signature-wrapping-attacks/">https://ssoready.com/blog/engineering/ruby-saml-pwned-by-xml-signature-wrapping-attacks/</a>, See on <a href="https://news.ycombinator.com/item?id=41586031">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
            GitLab and others are affected. The blame lies in the SAML specification, and in credulous engineers that implement it.
        </p><div>
            <p><a href="https://nvd.nist.gov/vuln/detail/CVE-2024-45409">CVE-2024-45409</a> was published
on September 10, 2024. It’s yet another XML signature wrapping attack, this time
affecting the main Ruby implementation of SAML. The vuln allows an attacker log
in as any arbitrary user of the affected system.</p>
<p>This attack keeps coming up
<a href="https://lists.w3.org/Archives/Public/public-xmlsec/2009Nov/att-0019/Camera-Ready.pdf">again</a>
and <a href="https://www.cve.org/CVERecord?id=CVE-2020-5390">again</a>, and it keeps
affecting huge swaths of the internet — this time,
<a href="https://about.gitlab.com/releases/2024/09/17/patch-release-gitlab-17-3-3-released/#saml-authentication-bypass">GitLab</a>
and much of the Ruby ecosystem — at a time.</p>
<p>Here’s what this issue is, why it keeps happening, and what we can do about it.</p>
<h2 id="xml-signature-wrapping">XML Signature Wrapping</h2>
<p>XML signatures are the year 2000’s answer to
<a href="https://en.wikipedia.org/wiki/JSON_Web_Token">JWTs</a>. In 2024, JWTs are a very
common answer to “I need to sign some data and send it over the internet”. It’s
not a perfect spec, but it’s workable.</p>
<p>XML signatures do the same thing, but every conceivable step is much more
complicated.</p>
<p>All an XML signature does is let you cryptographically sign an XML document.
Same thing as what JWTs do with <code>alg: "RS256"</code> (no <code>ES256</code>, because remember:
the year is 2000).</p>
<p>There is exactly one sane way to cryptographically sign data:</p>
<ol>
<li>You take your message, and convert it to bytes</li>
<li>You sign the bytes, which produces some more bytes</li>
<li>You transmit two things: the message-bytes from (1), and the signature-bytes from (2)</li>
<li><a href="https://en.wikipedia.org/wiki/KISS_principle">Don’t get cute</a>.</li>
</ol>
<p>Steps 1-3 is what JWT does. It does step (3) by separating the message and the
signature with a period (<code>.</code>), which works because it also base64s the message
and the signature, and <code>.</code> can’t appear in base64. People hate on JWT because it
forgot about (4); it’s part of an overarching attempt to standardize all of
crypto under something called
<a href="https://datatracker.ietf.org/group/jose/documents/">JOSE</a> (and
<a href="https://datatracker.ietf.org/doc/html/rfc8152">COSE</a>), a bad idea. But overall
they’re pretty good. They work. You can mostly ignore the overreach on the part
of the spec authors.</p>
<p>XML Signatures takes a different approach. Instead, it:</p>
<ol>
<li>Lets you sign <em>subsets</em> of a message,</li>
<li>Or none of the message at all,</li>
<li>Because instead of sending a signature accompanying your message, you <em>edit the very message you’re signing</em> to sprinkle in some <code>&lt;ds:Signature&gt;</code> elements,</li>
<li>Each of which sign a different
subset of the message. A <code>ds:Signature</code> uses a URI to point to other parts of
the message, and say “here’s a signature for that part of the message”</li>
</ol>
<p>If you ignore the XML-ness of it all, it’s the equivalent of signing <code>{"email": "bob@company.com"}</code> by modifying it to be:</p>
<div><pre tabindex="0"><code data-lang="json"><span><span><span>{</span>
</span></span><span><span>   <span>"email"</span><span>:</span> <span>"bob@company.com"</span><span>,</span> 
</span></span><span><span>   <span>"__sig"</span><span>:</span> <span>{</span>
</span></span><span><span>      <span>"uri"</span><span>:</span> <span>"/email"</span><span>,</span> 
</span></span><span><span>      <span>"sig"</span><span>:</span> <span>"... signature for the string bob@company.com ..."</span>
</span></span><span><span>   <span>}</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>This is a bad idea. It introduces the need for some “signature discovery” step,
where you search through the document for signatures (<code>__sig</code> in my JSON
example; <code>&lt;ds:Signature&gt;</code> elements in XML signatures). It basically begs
engineers to do this:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>validate_xml</span><span>(</span><span>xml_document</span><span>):</span>
</span></span><span><span>    <span>for</span> <span>signature</span> <span>in</span> <span>find_xml_signature_elements</span><span>(</span><span>xml_document</span><span>):</span>
</span></span><span><span>        <span>element</span> <span>=</span> <span>resolve_uri</span><span>(</span><span>signature</span><span>[</span><span>"SignedInfo"</span><span>][</span><span>"Reference"</span><span>][</span><span>"URI"</span><span>],</span> <span>xml_document</span><span>)</span>
</span></span><span><span>        <span>verify_signature</span><span>(</span><span>element</span><span>,</span> <span>signature</span><span>[</span><span>"SignatureValue"</span><span>]</span>
</span></span></code></pre></div><p>Note that this doesn’t actually <em>do</em> anything if the document doesn’t have any
signature at all.</p>
<p>People write a ton of bugs related to this “signature discovery” step. Every
such bug is what they call a “XML Signature Wrapping” attack; someone wrote some
tricky XML that makes your code lose track of what’s actually being signed.</p>
<p>To anticipate the obvious suggestion: no, sadly you can’t just check whether the
top-level XML document is signed, because that’s not how SAML does it (more
later), and SAML is the only reason people do XML Signatures (again, more
later).</p>
<p>So you instead in practice have people adapting their previous code to make sure
that the part of the message they care about is, in fact, signed:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>validate_xml</span><span>(</span><span>xml_document</span><span>,</span> <span>uri_checklist</span><span>):</span>
</span></span><span><span>    <span>checked_uris</span> <span>=</span> <span>[]</span>
</span></span><span><span>    <span>for</span> <span>signature</span> <span>in</span> <span>find_xml_signature_elements</span><span>(</span><span>xml_document</span><span>):</span>
</span></span><span><span>        <span>element</span> <span>=</span> <span>resolve_uri</span><span>(</span><span>signature</span><span>[</span><span>"SignedInfo"</span><span>][</span><span>"Reference"</span><span>][</span><span>"URI"</span><span>],</span> <span>xml_document</span><span>)</span>
</span></span><span><span>        <span>verify_signature</span><span>(</span><span>element</span><span>,</span> <span>signature</span><span>[</span><span>"SignatureValue"</span><span>]</span>
</span></span><span><span>        <span>checked_uris</span><span>.</span><span>append</span><span>(</span><span>signature</span><span>[</span><span>"SignedInfo"</span><span>][</span><span>"Reference"</span><span>][</span><span>"URI"</span><span>])</span>
</span></span><span><span>    
</span></span><span><span>    <span>for</span> <span>uri</span> <span>in</span> <span>uri_checklist</span><span>:</span>
</span></span><span><span>        <span>if</span> <span>uri</span> <span>not</span> <span>in</span> <span>checked_uris</span><span>:</span>
</span></span><span><span>            <span>throw</span> <span>MissingSignatureError</span><span>()</span>
</span></span></code></pre></div><p>There are a million ways this goes wrong, but here’s the one <code>ruby-saml</code> ran
into: there’s nothing that guarantees the <code>URI</code> the signature points to is
unique.</p>
<p>So what you could do is take a legitimate message, and just stick some other
stuff into the message, reusing the same <code>URI</code>. And then hope your victim’s code
will get confused as to what it just signed.</p>
<p>Something like this:</p>
<div><pre tabindex="0"><code data-lang="xml"><span><span><span>&lt;Document&gt;</span>
</span></span><span><span>    <span>&lt;!-- a faked message; this is never actually signed --&gt;</span>
</span></span><span><span>    <span>&lt;ImportantStuff&gt;</span>
</span></span><span><span>        <span>&lt;Message</span> <span>id=</span><span>"dead[...]beef"</span><span>&gt;</span>
</span></span><span><span>            <span>&lt;Email&gt;</span>eve@evil.com<span>&lt;/Email&gt;</span>
</span></span><span><span>        <span>&lt;/Message&gt;</span>
</span></span><span><span>    <span>&lt;/ImportantStuff&gt;</span>
</span></span><span><span>    
</span></span><span><span>    <span>&lt;!-- attacker-supplied message, copied out of the ImportantStuff from a legit message --&gt;</span>
</span></span><span><span>    <span>&lt;Message</span> <span>id=</span><span>"dead[...]beef"</span><span>&gt;</span>
</span></span><span><span>        <span>&lt;Email&gt;</span>alice@customer.com<span>&lt;/Email&gt;</span>
</span></span><span><span>    <span>&lt;/Message&gt;</span>
</span></span><span><span>    
</span></span><span><span>    <span>&lt;!-- a signature for alice@customer.com --&gt;</span>
</span></span><span><span>    <span>&lt;Signature&gt;</span>
</span></span><span><span>        <span>&lt;SignedInfo&gt;</span>
</span></span><span><span>            <span>&lt;Reference</span> <span>URI=</span><span>"dead[...]beef"</span> <span>/&gt;</span>
</span></span><span><span>        <span>&lt;/SignedInfo&gt;</span>
</span></span><span><span>        <span>&lt;SignatureValue&gt;</span>... the correct signature, but for alice@customer.com ...<span>&lt;/SignatureValue&gt;</span>
</span></span><span><span>    <span>&lt;/Signature&gt;</span>
</span></span><span><span><span>&lt;/Document&gt;</span>
</span></span></code></pre></div><p>The victim code finds the signature, resolves the uri to the top-level
<code>Message</code>, but then later on would process <code>ImportantStuff</code> instead of
<code>Message</code>, if that’s where the <code>Message</code> is normally placed.</p>
<p>It’s a mess. Ruby-SAML patched this by <a href="https://github.com/SAML-Toolkits/ruby-saml/commit/4865d030cae9705ee5cdb12415c654c634093ae7">throwing if <code>resolve_uri</code> finds more
than one
match</a>.
But Ruby-SAML has no reliable way of validating which parts of an XML document
were signed, and so I wouldn’t be surprised if there were more issues in that
codebase lurking.</p>
<h2 id="saml-is-why-this-matters">SAML is why this matters</h2>
<p>Nobody cares about XML Signatures anymore, except in the context of SAML. SAML
is what people mean by “enterprise single-sign-on”, and it works by having an
Identity Provider (Okta, Microsoft Entra, Google Workspace, etc.) send a signed
XML message to a Service Provider (a B2B SaaS product). That message typically
just contains the logging in user’s email address. It’s an elaborate email
address transmission protocol.</p>
<p>Concretely, SAML requests are a POST from your user’s browser containing:</p>
<div><pre tabindex="0"><code data-lang="xml"><span><span><span>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
</span></span><span><span><span>&lt;saml2p:Response&gt;</span>
</span></span><span><span>    <span>&lt;saml2:Assertion</span> <span>ID=</span><span>"id2829877824622019702853127"</span><span>&gt;</span>
</span></span><span><span>        <span>&lt;saml2:Issuer&gt;</span>
</span></span><span><span>            http://www.okta.com/exkig8gdo63cjI4OD5d7
</span></span><span><span>        <span>&lt;/saml2:Issuer&gt;</span>
</span></span><span><span>        <span>&lt;ds:Signature&gt;</span>
</span></span><span><span>            <span>&lt;ds:SignedInfo&gt;</span>
</span></span><span><span>                <span>&lt;ds:Reference</span> <span>URI=</span><span>"#id2829877824622019702853127"</span><span>&gt;</span>
</span></span><span><span>                <span>&lt;/ds:Reference&gt;</span>
</span></span><span><span>            <span>&lt;/ds:SignedInfo&gt;</span>
</span></span><span><span>            <span>&lt;ds:SignatureValue&gt;</span>
</span></span><span><span>                n744L/[...]mDruC1H9E0Lz7sbZg==
</span></span><span><span>            <span>&lt;/ds:SignatureValue&gt;</span>
</span></span><span><span>        <span>&lt;/ds:Signature&gt;</span>
</span></span><span><span>        <span>&lt;saml2:Subject&gt;</span>
</span></span><span><span>            <span>&lt;saml2:NameID&gt;</span>
</span></span><span><span>                ulysse.carion@ssoready.com
</span></span><span><span>            <span>&lt;/saml2:NameID&gt;</span>
</span></span><span><span>        <span>&lt;/saml2:Subject&gt;</span>
</span></span><span><span>    <span>&lt;/saml2:Assertion&gt;</span>
</span></span><span><span><span>&lt;/saml2p:Response&gt;</span>
</span></span></code></pre></div><p>And “implementing SAML” mostly consists of:</p>
<ol>
<li>“Validating” the message, with all the fraught gotchas that entails</li>
<li>Logging in the user as <code>ulysse.carion@ssoready.com</code>.</li>
</ol>
<p>Notice how this is roughly the same shape of message that I laid out in the
previous example. I won’t disclose it here because that’d be irresponsible, but
you can do the same attack. You could get me to validate the message in step
(1), but then have some other thing in the message, also with
<code>ID="id2829877824622019702853127"</code>, that I use in step (2).</p>
<p>To repeat it again, the core dumb idea here is that you’re signing a message,
instead of signing bytes. XML Signatures interweaves cryptography and the XML
tree model into a messy knot. It’s really hard to make sure the message you’re
processing is the same as the bytes you verified.</p>
<h2 id="how-to-fix-this-disregard-the-spec">How to fix this: disregard the spec</h2>
<p>SAML library authors need to stop being so credulous about the spec.</p>
<p>When a specification is a collection of security flaws, responsible engineers
disregard the specification. Responsible engineers should disregard what the
SAML and XML Signatures spec authors wrote down, and instead implement the
secure thing at its core.</p>
<p>Put another way, the reason XML wrapping attacks keep coming up is that people
architect their code like this:</p>
<ol>
<li><code>saml-ruby</code> calls into some</li>
<li><code>xml-signatures-ruby</code> dependency or submodule</li>
</ol>
<p>This seems like good, sane composition. But XML Signatures is insane. It cannot
be composed. XML Signatures can’t say “yes this message is valid”. What it can
say is “these N potentially-overlapping subsets of this XML document are
correctly signed” (It’s actually <a href="https://ssoready.com/blog/engineering/xml-dsig-is-unfortunate/">considerably worse than
that</a>, but whatever). There’s no
building on top of XML Signatures.</p>
<p>So here’s the sane thing to do instead:</p>
<ol>
<li>Notice that every Identity Provider in the world has practically agreed to
shape their SAML payloads in the same shape.</li>
<li>Assume all messages shaped otherwise are invalid.</li>
<li>Disregard the <code>URI</code> in XML signatures.</li>
<li>Presume in advance that they’re signing exactly the subset of the SAML
payload they should be signing, which is also the subset of the payload
you’ll be processing later.</li>
<li>Verify <em>that</em> signature, and only that signature.</li>
</ol>
<p>In other words: forget XML signatures. Treat it as some weird relic. Just look
at the SAML payload, and implement the de-facto protocol that has emerged.</p>
<p>Ignore <a href="https://en.wikipedia.org/wiki/Robustness_principle">Postel</a>. When it
comes to processing cryptographic signatures, loosey-goosey isn’t “liberal”,
it’s libertine.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cloudflare misidentifies Hetzner IPs as being located in Iran (191 pts)]]></title>
            <link>https://gitlab.com/gitlab-com/gl-infra/production/-/issues/8121#note_1237201726</link>
            <guid>41585249</guid>
            <pubDate>Wed, 18 Sep 2024 20:46:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gitlab.com/gitlab-com/gl-infra/production/-/issues/8121#note_1237201726">https://gitlab.com/gitlab-com/gl-infra/production/-/issues/8121#note_1237201726</a>, See on <a href="https://news.ycombinator.com/item?id=41585249">Hacker News</a></p>
Couldn't get https://gitlab.com/gitlab-com/gl-infra/production/-/issues/8121#note_1237201726: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Comic Mono (350 pts)]]></title>
            <link>https://dtinth.github.io/comic-mono-font/</link>
            <guid>41585156</guid>
            <pubDate>Wed, 18 Sep 2024 20:36:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dtinth.github.io/comic-mono-font/">https://dtinth.github.io/comic-mono-font/</a>, See on <a href="https://news.ycombinator.com/item?id=41585156">Hacker News</a></p>
Couldn't get https://dtinth.github.io/comic-mono-font/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[LinkedIn is now using everyone's content to train their AI tool (348 pts)]]></title>
            <link>https://twitter.com/RachelTobac/status/1836471586624540705</link>
            <guid>41584486</guid>
            <pubDate>Wed, 18 Sep 2024 19:37:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/RachelTobac/status/1836471586624540705">https://twitter.com/RachelTobac/status/1836471586624540705</a>, See on <a href="https://news.ycombinator.com/item?id=41584486">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Is Tor still safe to use? (564 pts)]]></title>
            <link>https://blog.torproject.org/tor-is-still-safe/</link>
            <guid>41583847</guid>
            <pubDate>Wed, 18 Sep 2024 18:41:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.torproject.org/tor-is-still-safe/">https://blog.torproject.org/tor-is-still-safe/</a>, See on <a href="https://news.ycombinator.com/item?id=41583847">Hacker News</a></p>
Couldn't get https://blog.torproject.org/tor-is-still-safe/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Threatening to Ban Users for Asking Strawberry About Its Reasoning (263 pts)]]></title>
            <link>https://futurism.com/the-byte/openai-ban-strawberry-reasoning</link>
            <guid>41583605</guid>
            <pubDate>Wed, 18 Sep 2024 18:22:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://futurism.com/the-byte/openai-ban-strawberry-reasoning">https://futurism.com/the-byte/openai-ban-strawberry-reasoning</a>, See on <a href="https://news.ycombinator.com/item?id=41583605">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="incArticle"><h2>"Additional violations of this policy may result in loss of access to GPT-4o with Reasoning."</h2><h2>Ban Hammer</h2><p>OpenAI claims that its latest AI model, code-named "Strawberry"&nbsp;and released as o1-preview,&nbsp;is supposed to be capable of "reasoning." But understanding how its <a href="https://futurism.com/openai-strawberry-thought-process-scheming">thought process</a> works, apparently, is something that the ChatGPT maker is serious about keeping off-limits.</p><p>As <a href="https://arstechnica.com/information-technology/2024/09/openai-threatens-bans-for-probing-new-ai-models-reasoning-process/"><i>Ars Technica </i>reports</a>, OpenAI is now threatening to ban users that try to get the large language model to reveal how it thinks — a glaring example of how the company has long since <a href="https://futurism.com/openai-sleazy-company-creating-agi">abandoned its original vision</a> of championing open source AI.</p><p>According to accounts on social media, users are <a href="https://x.com/MarcoFigueroa/status/1834741170024726628">receiving emails</a> from the Microsoft-backed startup informing them that their requests made to <a href="https://futurism.com/the-byte/chatgpt-voice-mode-scream">ChatGPT</a> have been flagged for "attempting to circumvent safeguards."</p><p>"Additional violations of this policy may result in loss of access to GPT-4o with Reasoning," the emails state.</p><h2>Hush Hush</h2><p>This clampdown is more than a bit ironic given that a lot of the hype around Strawberry was built around its "chain-of-thought" reasoning that allowed the AI to articulate how it arrived at an answer, step by step. OpenAI chief technology officer Mira Murati <a href="https://www.wired.com/story/openai-o1-strawberry-problem-reasoning/">called this</a> a "new paradigm" for the technology.</p><p>Reports vary on what triggers the violations. As <i>Ars </i>found, some users claim that using the term "<a href="https://x.com/voooooogel/status/1834536216160768377">reasoning trace</a>" is what got them in trouble. Others say that even using the word "<a href="https://x.com/dyushag/status/1834379249731444820">reasoning</a>" on its own was enough to alert OpenAI's systems. Users can still see what is essentially a summary of Strawberry's thought process, but it's cobbled together by a second AI model and is heavily watered-down.</p><p>In a <a href="https://openai.com/index/learning-to-reason-with-llms/#hiding-the-chains-of-thought">blog post</a>, OpenAI argues that it needs to hide the chain-of-thought so that it wouldn't need to put a filter on how its AI thinks, in case it says stuff that isn't compliant with safety policies while thinking out loud. That way, developers can safely see its "raw" thought process behind-the-scenes.</p><p>But as the company freely admits, this measure also helps it maintain a "competitive advantage," staving off competitors from trying to ride its coattails.</p><h2>Red Alert</h2><p>The flipside of this approach, however, is that concentrates more responsibility for aligning the language language model into the hands of OpenAI, instead of democratizing it. That poses a problem for red-teamers, or programmers that try to hack AI models to make them safer.</p><p>"I'm not at all happy about this policy decision," AI researcher Simon Willison <a href="https://simonwillison.net/2024/Sep/12/openai-o1/">wrote on his blog</a>, as quoted by <i>Ars</i>. "As someone who develops against LLMs, interpretability and transparency are everything to me — the idea that I can run a complex prompt and have key details of how that prompt was evaluated hidden from me feels like a big step backwards."</p><p>As it stands, it seems that OpenAI is continuing down a path of keeping its AI models an ever more opaque black box.</p><p><strong>More on OpenAI: </strong><em><a href="https://futurism.com/openai-strawberry-thought-process-scheming">OpenAI's Strawberry "Thought Process" Sometimes Shows It Scheming to Trick Users</a></em></p><br></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Qwen2.5: A Party of Foundation Models (149 pts)]]></title>
            <link>https://qwenlm.github.io/blog/qwen2.5/</link>
            <guid>41583062</guid>
            <pubDate>Wed, 18 Sep 2024 17:42:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qwenlm.github.io/blog/qwen2.5/">https://qwenlm.github.io/blog/qwen2.5/</a>, See on <a href="https://news.ycombinator.com/item?id=41583062">Hacker News</a></p>
Couldn't get https://qwenlm.github.io/blog/qwen2.5/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Meta AI: "The Future of AI Is Open Source and Decentralized" (205 pts)]]></title>
            <link>https://twitter.com/AIatMeta/status/1834633042339741961</link>
            <guid>41583028</guid>
            <pubDate>Wed, 18 Sep 2024 17:40:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/AIatMeta/status/1834633042339741961">https://twitter.com/AIatMeta/status/1834633042339741961</a>, See on <a href="https://news.ycombinator.com/item?id=41583028">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I made crowdwave – imagine Twitter/Reddit but every post is a voicemail (133 pts)]]></title>
            <link>https://www.crowdwave.com</link>
            <guid>41582539</guid>
            <pubDate>Wed, 18 Sep 2024 17:07:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.crowdwave.com">https://www.crowdwave.com</a>, See on <a href="https://news.ycombinator.com/item?id=41582539">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Microplastics in the olfactory bulb of the human brain (155 pts)]]></title>
            <link>https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2823787</link>
            <guid>41582461</guid>
            <pubDate>Wed, 18 Sep 2024 17:01:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2823787">https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2823787</a>, See on <a href="https://news.ycombinator.com/item?id=41582461">Hacker News</a></p>
<div id="readability-page-1" class="page"><div method="post" action="./2823787" id="webform">
        



<div id="resources-panel">
    <div>
        <div><p>Figure 1. &nbsp;Microphotographs and Micro-Fourier Transform Infrared (μFTIR) Spectra of the Microplastics Found in the Olfactory Bulb Tissue</p><div><p><a href="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/zoi241151f1_1726069938.11827.png?Expires=1729710081&amp;Signature=QCuZnQ0k9y6BI-vcK4S099vHrkPKK4pNUEsOkOsS65cBAeo05eBph4tOdEQWVAUraoGI2EP6UqCIxmcqCA~h7vYbBWy8gCSqdr15P5iTPjy1J9Bgl6VhZ3mJnioKcwKBrfFlgQPM58iQq-lZS9NgItxr7DXhpmhEhxyzy2asDith6RX~VrbrdocFuJVNZ0ZEV-8Ct0WSrVHGWHr-EaiStzMptqZ4QYltsG1GkA95z4F2yJ~yPjiYmCvBJfSVusDrLEL8QsfChpiE6~Rda~oY-FbURmesRw~7MWQMCR~F7J2gMwaa9HwbmlYIx1~U31CHCTpGaYnmLoq9lVu41vZtSA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" target="_blank" path-from-xml="zoi241151f1" rel="nofollow"><img data-original="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151f1_1726069938.11827.png?Expires=1729710081&amp;Signature=QZvbXinwft9Y2sMFvQiC9Lkixf4zMOxAaQQ0wd5LIcRNtKjJjDx~E8sBpd6qer7EJT4aNwA2mgDCIidoxDK3YbmtXuJ25rYzG5bPvW7uMj5uKsGqzUIrNRhD49o1lfpG8lM-MnjEvG9yxEqHiJRDx1Sjlv6-JbgJu01pYti9o-JDWjO0i6jkLascPAUwf-Kc5fu8K-JZTZKVepdbgk1yzisI3dK0aI7K40zLmwJBKVlfjpF7qo8ErhLA6E6T7D03od8~gg7disv4BNucuRXg~SdagBPZh-mZepDgkxiJ09MBkyDBEkkmnZBZ4LncYfxCv5VsNNkPC45QmjqYs4PkXw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Microphotographs and Micro-Fourier Transform Infrared (μFTIR) Spectra of the Microplastics Found in the Olfactory Bulb Tissue" path-from-xml="zoi241151f1" src="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151f1_1726069938.11827.png?Expires=1729710081&amp;Signature=QZvbXinwft9Y2sMFvQiC9Lkixf4zMOxAaQQ0wd5LIcRNtKjJjDx~E8sBpd6qer7EJT4aNwA2mgDCIidoxDK3YbmtXuJ25rYzG5bPvW7uMj5uKsGqzUIrNRhD49o1lfpG8lM-MnjEvG9yxEqHiJRDx1Sjlv6-JbgJu01pYti9o-JDWjO0i6jkLascPAUwf-Kc5fu8K-JZTZKVepdbgk1yzisI3dK0aI7K40zLmwJBKVlfjpF7qo8ErhLA6E6T7D03od8~gg7disv4BNucuRXg~SdagBPZh-mZepDgkxiJ09MBkyDBEkkmnZBZ4LncYfxCv5VsNNkPC45QmjqYs4PkXw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA"></a></p></div><p>HQI indicates hit quality index.</p></div><div><p>Figure 2. &nbsp;Microphotographs and Micro-Fourier Transform Infrared (μFTIR) Spectra of the Main Microplastics Found in the Digested Olfactory Bulb</p><div><p><a href="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/zoi241151f2_1726069938.48024.png?Expires=1729710081&amp;Signature=4jtSPcsf57GMusDVBWIot6dubyudipWcrlSqWr-wcX59HXDBPdTG3kFfjWw6XI6m-2Hr0xNEilkeAVn1MKgdOFJ1hEOUBoqtF62L~vWU5BwemM2NVSZByMCYuCJe1o56bbshzwVBWeEeki5CF0Ee0CDFWUnQ9wEmEzIVLJV8GJjIAaUNNEVWnACMtmFaZ3DoOb0TNgLAVeZE3Uy1CB9EiEBPoE1If6pGKg~PTLeMomXFik460Wg7-0JlkuAPpxCuOGzPeoQgvJfyNJE3sZXzoRTgkrI-VDWgISkC6OJEhM4K-Smk5m0aUXKm05glloNp7hVw1TgMNbK6C6HjgALbcQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" target="_blank" path-from-xml="zoi241151f2" rel="nofollow"><img data-original="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151f2_1726069938.48024.png?Expires=1729710081&amp;Signature=LHtSGOVNsRZvzMl-hDFIF7vI~ftl6HMIIM2VU069icuwXQIGJDXFBwUp-qdsH75nAL0hxq7Zm4hbhjRF1~UGs~C2xxRfQocJXnA8QcHnljlUB6igCQStNKyC9axm3tiWMggpIHPd1YB6y3V93AMSs6bhoz4t1YTcEeVY0yQDSZ5UMHbV-VdQhMc5nhWo57NY~wSTnALuZEXDN2nxi2m1O8kAnW3Z0D18JRxeSr2ZBm-bxqpt54ir8764VUPFdyx7OhpDLSCnATK2-E3CfoEEN2dYKjarzZFz~oVLm7nYX-gTPJEwfM7KCl8EV0TKsSFegbDsnUNvhS-5SmCXXbcxsw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Microphotographs and Micro-Fourier Transform Infrared (μFTIR) Spectra of the Main Microplastics Found in the Digested Olfactory Bulb" path-from-xml="zoi241151f2" src="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151f2_1726069938.48024.png?Expires=1729710081&amp;Signature=LHtSGOVNsRZvzMl-hDFIF7vI~ftl6HMIIM2VU069icuwXQIGJDXFBwUp-qdsH75nAL0hxq7Zm4hbhjRF1~UGs~C2xxRfQocJXnA8QcHnljlUB6igCQStNKyC9axm3tiWMggpIHPd1YB6y3V93AMSs6bhoz4t1YTcEeVY0yQDSZ5UMHbV-VdQhMc5nhWo57NY~wSTnALuZEXDN2nxi2m1O8kAnW3Z0D18JRxeSr2ZBm-bxqpt54ir8764VUPFdyx7OhpDLSCnATK2-E3CfoEEN2dYKjarzZFz~oVLm7nYX-gTPJEwfM7KCl8EV0TKsSFegbDsnUNvhS-5SmCXXbcxsw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA"></a></p></div><p>HQI indicates hit quality index.</p></div> 
    </div>
    <div>
        <div><p>Table 1. &nbsp;Demographic and Autopsy Findings of the Decedents</p><div><p><a href="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/zoi241151t1_1726069938.06827.png?Expires=1729710081&amp;Signature=FHp9vawpZ5oKM~IWkyTX6QLbfo6wjn9VjURr8YG4Zagr-15-owTvEAd-QKhLVv-WXh99qEBG8scsh4nrm7UJqnPgbQsuAAshzWHTdj3FJNLbQF3uIKn-KoX23BmbZy~6PlRGDOqjw0Xdb1jdtXGX3eqMrfaIn5k95OvrRLJfbpRjo~4R5xt1UsR5r2fyT9tkxXZ1oa8WBxd4YGqGRmYM4knfRGJsURGnWMcro~snn7rWgMWDdwkV9FvGeYggQkq4p6c9FRp4KC3DR6ZYi3wLPyt0MyVt-TftEqggP9wO95MbolwDZaqnUFkST6bFsNwPIaAGXSp4Y3xoFyGG~H1njQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" target="_blank" path-from-xml="zoi241151t1" rel="nofollow"><img data-original="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151t1_1726069938.06827.png?Expires=1729710081&amp;Signature=qig~Pe2PXqkY6CAk0dlEUNilWvPs4BUm9-gyYlEZrDfnrlaAfm1Cdr7mpr-8bEd-80PxeRz2Hky9cF7Cqfa7tqmdrC4PHeRjqLASbi2WKbeH8yAPp-Hx6ncm6Ohj24rS8aqcn6mcxI~jdu27tmpbCe3srRBFhZsN9Qm93icYDCAh6GVdws-S5eQWyjwsph6SBFTOtmVvG6PB2JPiXKW-Kr4Nd~ZE3Or7tqPTVlaAhc8T-O0EaQVmKhu1shn899dScqgMhuHixVPhPRdekeaEIC~62CeGDQTcrbKNGuTAFf0shBMIiu94GiEZJ3B5TDAs2RHOcGmCsbTcFMUzoTeDnQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Demographic and Autopsy Findings of the Decedents" path-from-xml="zoi241151t1" src="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151t1_1726069938.06827.png?Expires=1729710081&amp;Signature=qig~Pe2PXqkY6CAk0dlEUNilWvPs4BUm9-gyYlEZrDfnrlaAfm1Cdr7mpr-8bEd-80PxeRz2Hky9cF7Cqfa7tqmdrC4PHeRjqLASbi2WKbeH8yAPp-Hx6ncm6Ohj24rS8aqcn6mcxI~jdu27tmpbCe3srRBFhZsN9Qm93icYDCAh6GVdws-S5eQWyjwsph6SBFTOtmVvG6PB2JPiXKW-Kr4Nd~ZE3Or7tqPTVlaAhc8T-O0EaQVmKhu1shn899dScqgMhuHixVPhPRdekeaEIC~62CeGDQTcrbKNGuTAFf0shBMIiu94GiEZJ3B5TDAs2RHOcGmCsbTcFMUzoTeDnQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA"></a></p></div></div><div><p>Table 2. &nbsp;Morphology and Polymeric Matrix of the Identified Particles and Fibers</p><div><p><a href="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/zoi241151t2_1726069938.56028.png?Expires=1729710081&amp;Signature=RxrLiyGB2eqeqzzbg5WtUVhvMGG-j5tqCmd2zzsibxPHX9IFi5YWBZFKUg6qG8SgFgBdgvhnrP~EodTOvstrdEwYqPzsaPgA-6LbcbzsMP19S4qQabtxaCgnXvZxAG2tqlaGV9vAayQ83NcwmMXmW-MnJ~-hJmuUjXfn3FzwGfwnUeYAIJSEP9vNWbBQFKHIO1cFRE468nDXWkQphhGYdMBezxoWHr6-GfrHDOualn2JmNQ-SBzhar9WqTbKh4bSgcuqqwvLjMFptPX8kE0y0ngW~X579~vSMbCCfIJn6mQbocNuCJJhIkI2ZWPMPHo4d-yCnMWy5Wi3kuXkEL1SSQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" target="_blank" path-from-xml="zoi241151t2" rel="nofollow"><img data-original="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151t2_1726069938.56028.png?Expires=1729710081&amp;Signature=1roKT0bzsxJYfCSxqyWZQbZ~LYnMpwA29lQafDRmKijcKqjFMmjBSHf14viy-Gc7sZB5AIZPrMwmLSqXfjzVlc4uHvIx~breOv4cJfwrx8qamvfH8CXs6TaWCAGdLNRfgp7HONMzSEcFhypfeBEkvsj8YkTfZegmHrjMBvVCBZ9Tot~vMKO7a0zZI373WkWCgsUrgbjPlMNLVgZ8VeXvD2P~pTLgiHroDQy9lP6HJBECn2Lxo99C0Y17lHCjq9-NfcoSxRDrsnTdbEvzip9pEXE8eITS3zuAdp7jSGANBoHE8vOt3bG21jW35q1U3M-OPLYL15Dwd970D8C~-3XeVA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Morphology and Polymeric Matrix of the Identified Particles and Fibers" path-from-xml="zoi241151t2" src="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151t2_1726069938.56028.png?Expires=1729710081&amp;Signature=1roKT0bzsxJYfCSxqyWZQbZ~LYnMpwA29lQafDRmKijcKqjFMmjBSHf14viy-Gc7sZB5AIZPrMwmLSqXfjzVlc4uHvIx~breOv4cJfwrx8qamvfH8CXs6TaWCAGdLNRfgp7HONMzSEcFhypfeBEkvsj8YkTfZegmHrjMBvVCBZ9Tot~vMKO7a0zZI373WkWCgsUrgbjPlMNLVgZ8VeXvD2P~pTLgiHroDQy9lP6HJBECn2Lxo99C0Y17lHCjq9-NfcoSxRDrsnTdbEvzip9pEXE8eITS3zuAdp7jSGANBoHE8vOt3bG21jW35q1U3M-OPLYL15Dwd970D8C~-3XeVA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA"></a></p></div></div> 
    </div>

        </div>

<div id="content-panel">
    
    
    



            
        

    <div>
        
    


            <div>
            <p>Original Investigation </p>
                <p>Environmental Health</p>
        </div>
        <p><span><span>September&nbsp;</span><span>16, </span><span>2024</span></span></p>
        
            
            
        <p><span>JAMA Netw Open. </span><span> 2024;7(9):e2440018. doi:10.1001/jamanetworkopen.2024.40018</span>
        </p>

 
    </div>
    
    

            <div data-userhasaccess="True">
    

            <p><a id="249905505"></a>
<span>Key Points</span></p><p><strong>Question</strong>&nbsp;
    <span>Can microplastics reach the olfactory bulb in the human brain?</span></p><p><strong>Findings</strong>&nbsp;
    <span>This case series analyzed the olfactory bulbs of 15 deceased individuals via micro-Fourier transform infrared spectroscopy and detected the presence of microplastics in the olfactory bulbs of 8 individuals. The predominant shapes were particles and fibers, with polypropylene being the most common polymer.</span></p><p><strong>Meaning</strong>&nbsp;
    <span>The presence of microplastics in the human olfactory bulb suggests the olfactory pathway as a potential entry route for microplastics into the brain, highlighting the need for further research on their neurotoxic effects and implications for human health.</span></p>            
<p><strong>Importance</strong>&nbsp;
    <span>Microplastic (MP) pollution is an emerging environmental and health concern. While MPs have been detected in various human tissues, their presence in the human brain has not been documented, raising important questions about potential neurotoxic effects and the mechanisms by which MPs might reach brain tissues.</span></p><p><strong>Objective</strong>&nbsp;
    <span>To determine the presence of MPs in the human olfactory bulb and to analyze their characteristics such as size, morphology, color, and polymeric composition.</span></p><p><strong>Design, Setting, and Participants</strong>&nbsp;
    <span>This case series study used a cross-sectional design involving the analysis of olfactory bulb tissues obtained from deceased individuals during routine coroner autopsies. The sampling procedures were conducted at São Paulo City Death Verification Service, with laboratory analysis carried out at the Brazilian Synchrotron Light Laboratory (LNLS). Participants included 15 adult individuals who had been residents of São Paulo for more than 5 years and underwent coroner autopsies. Exclusion criteria included previous neurosurgical interventions. Data analysis was performed in April 2024.</span></p><p><strong>Exposure</strong>&nbsp;
    <span>The primary exposure assessed was the presence of MPs in the olfactory bulb, analyzed through direct tissue examination and digested tissue filtration followed by micro-Fourier transform infrared spectroscopy.</span></p><p><strong>Main Outcomes and Measures</strong>&nbsp;
    <span>The main outcomes were the identification and characterization of MPs within the olfactory bulb, including their size, morphology, color, and polymeric composition.</span></p><p><strong>Results</strong>&nbsp;
    <span>The median age of the 15 deceased individuals was 69.5 years, ranging from 33 to 100 years, with 12 males and 3 females. MPs were detected in the olfactory bulbs of 8 out of 15 individuals. A total of 16 synthetic polymer particles and fibers were identified, with 75% being particles and 25% being fibers. The most common polymer detected was polypropylene (43.8%). Sizes of MPs ranged from 5.5 μm to 26.4 μm for particles, and the mean fiber length was 21.4 μm. Polymeric materials were absent in procedural blank and negative control filters, indicating minimal contamination risk.</span></p><p><strong>Conclusions and Relevance</strong>&nbsp;
    <span>This case series provides evidence of MPs found in the human olfactory bulb, suggesting a potential pathway for the translocation of MPs to the brain. The findings underscore the need for further research on the health implications of MP exposure, particularly concerning neurotoxicity and the potential for MPs to bypass the blood-brain barrier.</span></p>            
            
            <p>The ubiquity of microplastic (MP) pollution has become a pervasive environmental concern,<sup><a href="#zoi241151r1" data-tab-toggle=".tab-nav-references">1</a></sup> raising questions about its occurrence within the human body and its harmful effects.<sup><a href="#zoi241151r2" data-tab-toggle=".tab-nav-references">2</a></sup> While MPs have been detected in various organs of the human body, such as the lungs,<sup><a href="#zoi241151r3" data-tab-toggle=".tab-nav-references">3</a></sup><sup>,<a href="#zoi241151r4" data-tab-toggle=".tab-nav-references">4</a></sup> large and small intestines,<sup><a href="#zoi241151r5" data-tab-toggle=".tab-nav-references">5</a></sup> liver,<sup><a href="#zoi241151r6" data-tab-toggle=".tab-nav-references">6</a></sup> placenta,<sup><a href="#zoi241151r7" data-tab-toggle=".tab-nav-references">7</a></sup><sup>,<a href="#zoi241151r8" data-tab-toggle=".tab-nav-references">8</a></sup> semen,<sup><a href="#zoi241151r9" data-tab-toggle=".tab-nav-references">9</a></sup> and bloodstream,<sup><a href="#zoi241151r10" data-tab-toggle=".tab-nav-references">10</a></sup> to our knowledge, there have been no published studies to date reporting their presence in the human brain.</p>            <p>The presence of the blood-brain barrier (BBB) is likely an important limiting factor for the access of MPs to the human brain via hematogenous translocation. Despite this, some animal studies have shown that MPs can impair the BBB and reach the brain via oral ingestion, leading to neurotoxic effects.<sup><a href="#zoi241151r11" data-tab-toggle=".tab-nav-references">11</a></sup><sup>-<a href="#zoi241151r11" data-tab-toggle=".tab-nav-references">13</a></sup> Another potential entry site for micro- and nanoplastics (MNPs) in the human brain is the olfactory pathway.<sup><a href="#zoi241151r14" data-tab-toggle=".tab-nav-references">14</a></sup> This pathway involves olfactory neurons in the nasal that transmit information about odors to the central olfactory system of the brain. Olfactory axons pass through the cribriform plate (CP) of the ethmoid bone and reach the olfactory bulbs (OB), which are connected to the limbic system of the brain.</p>            <p>There are different levels of evidence suggesting that the olfactory pathway might allow the translocation of exogenous particles to the brain. Environmental black carbon particles have been detected in various human brain regions, with one of the highest concentrations found in the OB, measuring 420.8 particles/mm<sup>3</sup>.<sup><a href="#zoi241151r15" data-tab-toggle=".tab-nav-references">15</a></sup> Rarely, the 15- to 30-μm–sized ameboid form of Naegleria fowleri penetrates the brain via the nose, causing amebic meningoencephalitis.<sup><a href="#zoi241151r16" data-tab-toggle=".tab-nav-references">16</a></sup> Affected individuals typically present with the disease after contact with contaminated freshwater bodies or after rinsing the nose with nonsterile tap water.<sup><a href="#zoi241151r17" data-tab-toggle=".tab-nav-references">17</a></sup> Furthermore, the permeability of this barrier has been evoked as a possible quicker and safer drug delivery route to the brain,<sup><a href="#zoi241151r18" data-tab-toggle=".tab-nav-references">18</a></sup><sup>,<a href="#zoi241151r19" data-tab-toggle=".tab-nav-references">19</a></sup> as well as access to cerebrospinal fluid through nasal lymphatic vessels.<sup><a href="#zoi241151r20" data-tab-toggle=".tab-nav-references">20</a></sup></p>            <p>In this study, given the ubiquitous presence of MPs in the air<sup><a href="#zoi241151r21" data-tab-toggle=".tab-nav-references">21</a></sup> and their previous identification in the human nasal cavity,<sup><a href="#zoi241151r22" data-tab-toggle=".tab-nav-references">22</a></sup><sup>,<a href="#zoi241151r23" data-tab-toggle=".tab-nav-references">23</a></sup> we hypothesized that the smallest-size fraction of MPs could reach the OB. Therefore, we conducted an investigation into the presence of MPs within human OB obtained from 15 deceased individuals during coroner autopsies. We identified and analyzed various characteristics of the MPs, including their size, morphology, color, and polymeric composition.</p>            
            <p>This case series study was approved by the ethical board of the São Paulo University Medical School, in compliance with the Helsinki Declaration. Written informed consent was provided by the deceased individuals’ next of kin. The study was conducted from February 2023 to May 2024 and followed the <a href="https://www.ajo.com/article/S0002-9394(10)00690-2/fulltext">Reporting Guideline for Case Series</a>.<sup><a href="#zoi241151r46" data-tab-toggle=".tab-nav-references">46</a></sup></p>            
            <p>We obtained the bilateral OBs from 15 adult individuals who underwent routine coroner autopsies at the São Paulo City Death Verification Service of University of São Paulo to determine the cause of death. All individuals had been residents of São Paulo for more than 5 years. Cases in which the deceased had previously undergone neurosurgical interventions were not selected for the study. Information regarding previous occupations and underlying diseases was obtained through questionnaires administered to the next of kin. Additionally, autopsy reports were reviewed. We also collected samples from the OB of 2 stillbirths at 7 months gestation, as a negative control for the study. The collection of OBs took place between February 2023 and February 2024.</p>            <div>

                            <p>
                                Quality Control and Quality Assurance and Evaluation of Sample Processing
                            </p>
                        </div>
            <p>We implemented a plastic-free approach to safeguard the integrity of our results. This strategy facilitated a thorough assessment of potential sources of variability and error, thereby enhancing the reliability of our collected data. All procedures, from the OB sampling to the micro-Fourier transform infrared (μFTIR) spectroscopy analysis, followed the protocols recommended by several studies.<sup><a href="#zoi241151r24" data-tab-toggle=".tab-nav-references">24</a></sup><sup>-<a href="#zoi241151r24" data-tab-toggle=".tab-nav-references">26</a></sup> Briefly, all solutions were prefiltered through a Whatman cellulose filters with a mesh size of 0.45 μm. Stainless steel materials, glassware, and samples were covered with aluminum foil (before and after processing) to avoid airborne sample contamination. Ultrapure water with a resistivity of 18.2 mΩ was obtained from a Milli-Q purification device (Millipore Corp). Glass and stainless-steel materials were washed thoroughly using the purified water 3 times and then using acetone P.A. to remove any particles or fibers that have adhered to the glass. The scientific staff responsible for handling samples wore exclusively 100% cotton laboratory coats and were required to remove any plastic or textile bracelets, rings, and watches to minimize the risk of sample contamination. Clean latex gloves were used for all procedures. The samples were processed in a clean laminar flow cabinet (ISO class 5, SKU330313, Hipperquímica, SP, Brazil). Blank filters (47 mm) were used from the OB collection to the sample filtering to assess possible airborne contamination. A clean filter was also used as a negative control. Access to the μFTIR spectroscopy and the digestion/filtration room was restricted to the operators only, to avoid air flow in the room and the suspension/resuspension of possible atmospheric contaminants.</p>            
            <p>The presence of MPs in the OB was assessed in 2 ways: directly on the tissue and a digested assessment. The cryo-cuts method preserves the spatial context of MPs within the tissue, allowing their proximity to anatomical structures such as blood vessels to be observed. This is crucial for understanding potential pathways of MPs translocation and accumulation within the OB. The digestion method ensures that MPs that are deeply embedded in the tissue are not overlooked. Postdigestion, MPs are concentrated on filters, which can then be analyzed for a more accurate quantification and identification without interference from the tissue matrix. By combining these 2 methods, the study maximized the probability of detecting and characterizing MPs within the OB.</p>            
            <p>The left OB of each case was horizontally cryo-sectioned using a Leica CM1860 UV cryostat (Leica Biosystems) at 10 μm thickness and thaw-mounted onto 5 mm × 5 mm gold/chromium-coated silicon dioxide/silicon substrates. No fixatives were used for the tissue sections. The samples were then freeze-dried for 48 hours (Freezone 6 [Labconco Corp]) and examined by optical microscopy (Eclipse LV100ND [Nikon Instruments Inc]). The freeze-drying process maintains the integrity of biological tissues by extracting water without substantially compromising their structure. Futhermore, the presence of water molecules, characterized by strong hydrogen bonding, poses a considerable challenge in FTIR measurements, as they mask specific signals indicative of chemical compositions.<sup><a href="#zoi241151r27" data-tab-toggle=".tab-nav-references">27</a></sup></p>            <p>The procedures took place in a biosafety level 2 room in the Cryogenic Preparations Laboratory (LCRIO) at the Brazilian Synchrotron Light Laboratory (LNLS), National Center for Energy and Materials Research (CNPEM).</p>            <div>

                            <p>
                                Sample Digestion and Filtering
                            </p>
                        </div>
            <p>Immediately after sampling, the right OBs from 10 selected cases were individually frozen at −20 °C in glass vials, covered with aluminum foil, and sealed with a glass lid until the digestion. For 5 patients, there was no available tissue for digestion. The tissues were then incubated for 12 hours at 40 °C using the enzyme mixture Corolase 7089 (20 UHb/mL)<sup><a href="#zoi241151r4" data-tab-toggle=".tab-nav-references">4</a></sup> inside the laminar flux hood.</p>            <p>The solution was then filtered using a glass vacuum filtration system (Sigma-Aldrich) and silver membrane filters (25 mm in diameter and 0.45 microns pore size [Millipore]). Subsequently, the filters were kept individually in closed Petri dishes inside a glass dissector until the spectroscopy analysis. Due to the material characteristics, a recovery test was not feasible.</p>            <div>

                            <p>
                                Micro-Fourier Transform Infrared Spectroscopy
                            </p>
                        </div>
            <p>We performed single-point μFTIR microspectroscopy measurements in reflection mode using a diffraction-limited IR microscope (Cary 620 [Agilent Technologies]). The IR microscope is coupled to a Michelson interferometer responsible for the frequency demultiplexing of the mid-IR broadband response. We used a 1000 K Globar source and illumination and interferograms detection was done by using a high-sensitivity cryo-cooled Mercury–Cadmium-Telluride (MCT [Infrared Associates Inc]). After the interferometer, the IR beam was directed to a 25 × objective that produced an illumination spot of 420 μm × 420 μm on the sample’s surface. This field of view was further reduced to 50 to 100 μm by slits to concentrate the analysis around specific particles. The reflected light was collected through a confocal arrangement by the same objective lens and then directed to the MCT detector. FTIR spectra were generated by calculating the Fourier transforms of the recorded interferograms. The spectral resolution was configured at 16 cm<sup>−1</sup>, encompassing the range from 4000 to 700 cm<sup>−1</sup>. Each μFTIR spectrum was normalized to the spectrum of a clean gold surface, which served as a reference background. The cryo-cuts and digested filters were fully analyzed. The μFTIR analyses took place in the IMBUIA beamline at the Brazilian Synchrotron Light Laboratory (LNLS), National Center for Research in Energy and Materials (CNPEM).</p>            <p>The acquired spectra were processed manually using the KnowItAll Informatics System 2024 (John Wiley and Sons Inc). The comparative analysis was performed with the help of FTIR spectra libraries developed for MPs research, including the FTIR Library of Plastic Particles (FLOPP),<sup><a href="#zoi241151r28" data-tab-toggle=".tab-nav-references">28</a></sup> FTIR Library of Plastic Particles Sourced from the Environment (FLOPP-e),<sup><a href="#zoi241151r28" data-tab-toggle=".tab-nav-references">28</a></sup> siMPLe database,<sup><a href="#zoi241151r29" data-tab-toggle=".tab-nav-references">29</a></sup> and KnowItAll IR Spectral Library. We adopted a Hit Quality Index greater than 75% of agreement between characteristic bands of polymers observed in reference materials with bands observed in unknown particles or fibers.<sup><a href="#zoi241151r30" data-tab-toggle=".tab-nav-references">30</a></sup><sup>,<a href="#zoi241151r31" data-tab-toggle=".tab-nav-references">31</a></sup></p>            
            <p>We determined particle sizes by analyzing microphotographs obtained through μFTIR spectroscopy. ImageJ 1.54g software (US National Institutes of Health) was used for accurate measurements.</p>            
            <p>Descriptive analyses were performed using SPSS Statistics 26.0 software (IBM Inc). These analyses were performed in April 2024.</p>            
            <p>The median (range) age of the 15 deceased individuals was 69.5 (33-100) years. They included 12 males and 3 females. Demographic information is detailed in <a href="#zoi241151t1" data-tab-toggle=".tab-nav-figure-table">Table 1</a>. Apart from the 2 cases with histological evidence of previous ischemic cerebral infarction and 1 case with a subarachnoid hematoma due to a ruptured aneurysm of the middle cerebral artery, there were no cerebral histological abnormalities in the remaining cases. The mean (SD) mass of the OB (left or right) was 0.187 (0.050) g, ranging from 0.100 to 0.273 g.</p>            <p>A total of 16 synthetic polymer particles and fibers were identified in 8 out of the 15 deceased individuals, with a range from 1 to 4 MPs per OB. Of these, 75% were particles, of which 83.4% were fragments and 16.6% were spheres, while 25% were fibers with a length-to-width ratio exceeding 3. The particles had a mean (SD) length of 12.1 (7.2) μm, ranging from 5.5 to 26.4 μm, and a mean (SD) width of 8.9 (6.4) μm, ranging from 3.0 to 25.4 μm. The fibers exhibited a mean (SD) length of 21.4 (2.6) μm, ranging from 19.0 to 24.5 μm, and a mean (SD) width of 3.8 (1.8) μm, ranging from 3.0 to 6.0 μm.</p>            <p>In the procedural blank filters, we detected 2 cotton fibers, 2 silica beads, and 1 silicate fragment. Polymeric materials were absent in both the procedural blank and negative control filters. From the 2 collected samples in stillborn, we were able to analyze 1 case, which did not show the presence of MPs. The other case had insufficient material for analysis.</p>            <p>Polypropylene was the most prevalent polymer (43.8%), followed by polyamide, nylon, and polyethylene vinyl acetate (12.5%). This was followed by polyethylene, perlon polyamide, and wool-polypropylene, which accounted for 6.3%). Upon comparison with the reference spectral library of plastic materials, the identified MP particles and fibers exhibited indications of weathering. The μFTIR spectra of the weathered MPs differed substantially from those of pristine standard samples; multiple peaks in the spectra of weathered MPs were attenuated or entirely absent.</p>            <p>Microphotographs and μFTIR point-spectra showing the main types of MP detected in the OB are shown in <a href="#zoi241151f1" data-tab-toggle=".tab-nav-figure-table">Figure 1</a> and <a href="#zoi241151f2" data-tab-toggle=".tab-nav-figure-table">Figure 2</a>. The complete μFTIR point-spectra results of the digested OB are presented in the eFigure in <a data-tab-toggle=".tab-nav-supplemental" href="#note-ZOI241151-1">Supplement 1</a>. <a href="#zoi241151t2" data-tab-toggle=".tab-nav-figure-table">Table 2</a> provides details regarding the morphology, color, and chemical characterization of the particles and fibers.</p>            
            <p>To our knowledge, this is the first study in which the presence of MPs in the human brain was identified and characterized using μFTIR, allowing quantification and characterization of the morphology and polymeric matrix. Specifically, we detected particles as the predominant shape in the OB in 8 out of 15 individuals who underwent autopsy in Sao Paulo. Our data extend the notion that not only black carbon<sup><a href="#zoi241151r15" data-tab-toggle=".tab-nav-references">15</a></sup> but also MP accumulate in the OB in humans.</p>            <p>We believe that the anatomy of the cribriform plate of the ethmoid bone may serve as a gateway in the nasal passages from within the skull. This plate, situated between the frontal and sphenoid bones, lies horizontally and contains multiple foramina, each less than 1 mm in diameter.<sup><a href="#zoi241151r32" data-tab-toggle=".tab-nav-references">32</a></sup> The OB lies directly above it, and the olfactory neurons of the nasal mucosa reach the OB via the foramina of the cribriform plate. Recent studies have shown that part of the cerebrospinal fluid outflow occurs via lymphatic vessels that surround the olfactory axons, reaching the nasal mucosa and extending toward the nasal lymphoid tissue.<sup><a href="#zoi241151r33" data-tab-toggle=".tab-nav-references">33</a></sup> Ossification of the CP occurs by 1 year of age,<sup><a href="#zoi241151r34" data-tab-toggle=".tab-nav-references">34</a></sup> and the total area of the perforations is age-dependent; it is 3.79 to 3.99 mm<sup>2</sup> in those over 50 years of age and 5.61 to 7.91 mm<sup>2</sup> in those under 50 years of age. This decrease in the area over time, causing compression and dysfunction of the olfactory nerves, is thought to explain the decreased olfactory sensation in older individuals.<sup><a href="#zoi241151r35" data-tab-toggle=".tab-nav-references">35</a></sup> Furthermore, in mice, paracellular spaces in the olfactory epithelium can reach 5 to 20 μm in the medial-lateral dimension of the transport and a 10- to 100-μm range observed in the rostral-caudal dimension.<sup><a href="#zoi241151r36" data-tab-toggle=".tab-nav-references">36</a></sup> If a similar situation is observed in humans, this could represent another factor facilitating entry of larger particles in the brain via the cribriform plate.</p>            <p>Given the widespread presence of MPs in the air, some of which are associated with PM<sub>2.5</sub>,<sup><a href="#zoi241151r37" data-tab-toggle=".tab-nav-references">37</a></sup> the identification of MPs in the nose<sup><a href="#zoi241151r45" data-tab-toggle=".tab-nav-references">45</a></sup> and now in the OB, along with the vulnerable anatomical pathways, reinforces the notion that the olfactory pathway is an important entry site for exogenous particles to the brain. In previous epidemiological studies, exposure to PM<sub>2.5</sub> has been associated with neurological and psychiatric adverse outcomes, such as dementia.<sup><a href="#zoi241151r38" data-tab-toggle=".tab-nav-references">38</a></sup><sup>,<a href="#zoi241151r39" data-tab-toggle=".tab-nav-references">39</a></sup> Some neurodegenerative diseases, such as Parkinson disease, seem to have a connection with nasal abnormalities as initial symptoms.<sup><a href="#zoi241151r40" data-tab-toggle=".tab-nav-references">40</a></sup> In experimental studies, both exposures to PM<sub>2.5</sub> and MPs have shown to cause several neurotoxic effects, including disturbances on the brain development.<sup><a href="#zoi241151r41" data-tab-toggle=".tab-nav-references">41</a></sup><sup>,<a href="#zoi241151r42" data-tab-toggle=".tab-nav-references">42</a></sup> The cribriform plate reaches maturation at 1 to 2 years of age, which is a critical time window during which MP penetration into the brain could have negative effects on the organ maturation.</p>            <p>In this study, the MP polymeric matrix found in the OB corresponds to the most produced and manufactured plastics, such as polypropylene, nylon/polyamide, polyethylene and polyethylene vinyl acetate, present in packaging, clothes and home accessories, suggesting indoor environments as a major source of inhaled MPs.<sup><a href="#zoi241151r21" data-tab-toggle=".tab-nav-references">21</a></sup><sup>,<a href="#zoi241151r43" data-tab-toggle=".tab-nav-references">43</a></sup></p>            
            <p>This study has certain limitations. Although the olfactory pathway seems a likely exposure route, we cannot dismiss the possibility of multiple entry routes. MPs might have reached the OB either through systemic circulation, crossing the BBB, or via the respiratory pathway through the trigeminal nerve.<sup><a href="#zoi241151r44" data-tab-toggle=".tab-nav-references">44</a></sup> The biologic matrix of the OB tissues can be a confounding factor when analyzing MP spectra due to its similarity to some polymeric materials. Therefore, we were cautious to consider suspect particles as polymeric material only when spectral bands highly matched with weathered bands from MP libraries (HQI &gt;75%). In the filtered samples, the biological matrix was previously digested, not being an issue. Given the maximum spatial resolution (3 μm) of μFTIR spectroscopy setup and the limited capacity of analysis for other techniques, we were unable to detect nanoplastics. It is likely that the number of plastics in the submicron range with the potential to cause substantial biological damage would be far more numerous.</p>            <p>Avoiding contamination is one of the biggest challenges when analyzing MP. Due to the presence of MP fibers and particles in the air, we have used blank samples in all methodological procedures to detect contamination of the air. We found no MP in our procedural blanks, which supports the validity of our results. Furthermore, we had the opportunity to analyze the brains of 2 stillbirths. However, the status of brain tissue maceration made the analysis challenging due to difficulties in sampling and processing.</p>            
            <p>This case series describes the presence of MPs in the OB, mainly particles of the most commonly produced/processed polymers for clothing and packaging such as polypropylene and nylon. Our data support the idea that the olfactory pathway is an important entry site for environmental air pollutants. Considering the potential neurotoxic effects caused by MPs in the brain, and the widespread environmental contamination with plastics, our results should raise concern in the context of increasing prevalence of neurodegenerative diseases. Noninvasive imaging technologies, such as magnetic resonance imaging, are needed to overcome the current limitations in tissue analysis of different human organs and to improve the understanding of the health hazards of MPs.</p>            <div>
                                <p><a href="#top" data-tab-toggle=".tab-nav-full-text">Back to top</a></p><p>
                                Article Information
                            </p>
                        </div>
<p><strong>Accepted for Publication:</strong> August 22, 2024.</p><p><strong>Published:</strong> September 16, 2024. doi:10.1001/jamanetworkopen.2024.40018</p><p><strong>Open Access:</strong> This is an open access article distributed under the terms of the <a href="https://jamanetwork.com/pages/cc-by-license-permissions">CC-BY License</a>. © 2024 Amato-Lourenço LF et al. <i>JAMA Network Open</i>.</p><p><strong>Corresponding Author:</strong> Luís Fernando Amato-Lourenço, PhD, Freie Universität Berlin - Institut für Biologie, Altensteinstr 6D- 14195 Berlin, Germany (<a href="mailto:luisfamato@zedat.fu-berlin.de" target="_blank">luisfamato@zedat.fu-berlin.de</a>).</p><p><strong>Author Contributions:</strong>  Dr Amato-Lourenço and Prof Mauad had full access to all of the data in the study and take responsibility for the integrity of the data and the accuracy of the data analysis.</p><p><i>Concept and design:</i> Amato-Lourenço, Carvalho-Oliveira, Mauad.</p><p><i>Acquisition, analysis, or interpretation of data:</i> All authors.</p><p><i>Drafting of the manuscript:</i> Amato-Lourenço, Dantas, Carvalho-Oliveira, Mauad.</p><p><i>Critical review of the manuscript for important intellectual content:</i> Amato-Lourenço, Ribeiro Júnior, Ribeiro Paes, S. Rabelo, da Costa, Ando, Freitas, Bispo, Carvalho-Oliveira, Mauad.</p><p><i>Statistical analysis:</i> Amato-Lourenço, Freitas, Mauad.</p><p><i>Obtained funding:</i> Amato-Lourenço, Mauad.</p><p><i>Administrative, technical, or material support:</i> Amato-Lourenço, Dantas, Ribeiro Paes, Freitas, Bispo, Carvalho-Oliveira.</p><p><i>Supervision:</i> Amato-Lourenço, Carvalho-Oliveira, Mauad.</p><p><strong>Conflict of Interest Disclosures:</strong> None reported.</p><p><strong>Funding/Support:</strong> This study was financially supported by the Alexander von Humboldt Foundation (AvH), Germany, by the Plastic Soup Foundation, by the Brazilian Research Council (CNPq) grant 308023/2023-4 and Sao State Research Agency (FAPESP) grant 2021/10724-2.</p><p><strong>Role of the Funder/Sponsor:</strong> The funders had no role in the design and conduct of the study; collection, management, analysis, and interpretation of the data; preparation, review, or approval of the manuscript; and decision to submit the manuscript for publication.</p><p><strong>Data Sharing Statement:</strong> See <a data-tab-toggle=".tab-nav-supplemental" href="#note-ZOI241151-1">Supplement 2</a>.</p><p><strong>Additional Contributions:</strong> We would like to thank the São Paulo City Death Verification Service (SVOC) staff, the IMBUIA beamline at the Brazilian Synchrotron Light Laboratory (LNLS) for providing beamtime (proposal No. 20232740) and the technical support, Maria Westerbos and the Plastic Soup Foundation, Professor Dr Lukas Kenner and Professor Dra Verena Pichler for reviewing the manuscript before submission, and to Dr Walter Waldman for recommending the LNLS facilities to us. They were not compensated.</p>            
<div><div><p><a id="zoi241151r1">1.</a></p><p>Li
        &nbsp;Y﻿, Tao
        &nbsp;L﻿, Wang
        &nbsp;Q﻿, Wang
        &nbsp;F﻿, Li
        &nbsp;G﻿, Song
        &nbsp;M﻿. &nbsp;Potential health impact of microplastics: a review of environmental distribution, human exposure, and toxic effects.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Environ Health</i>. 2023;1(4):249-257. doi:<a href="https://dx.doi.org/10.1021/envhealth.3c00052">10.1021/envhealth.3c00052</a><a href="https://scholar.google.com/scholar_lookup?title=Potential%20health%20impact%20of%20microplastics%3A%20a%20review%20of%20environmental%20distribution%2C%20human%20exposure%2C%20and%20toxic%20effects.&amp;author=Y%20Li&amp;author=L%20Tao&amp;author=Q%20Wang&amp;author=F%20Wang&amp;author=G%20Li&amp;author=M%20Song&amp;publication_year=2023&amp;journal=Environ%20Health&amp;volume=1&amp;pages=249-257" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a><a href="https://doi.org/10.1021/envhealth.3c00052" target="_blank" xmlns:helper="urn:XsltStringHelper">Crossref</a><span data-targetid="10.1021/envhealth.3c00052" xmlns:helper="urn:XsltStringHelper"> </span></p></div><div><p><a id="zoi241151r25">25.</a></p><p>Gwinnett
        &nbsp;C﻿, Miller
        &nbsp;RZ﻿. &nbsp;Are we contaminating our samples? A preliminary study to investigate procedural contamination during field sampling and processing for microplastic and anthropogenic microparticles.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Mar Pollut Bull</i>. 2021;173(Pt B):113095. doi:<a href="https://dx.doi.org/10.1016/j.marpolbul.2021.113095">10.1016/j.marpolbul.2021.113095</a><a href="https://scholar.google.com/scholar_lookup?title=Are%20we%20contaminating%20our%20samples%3F%20A%20preliminary%20study%20to%20investigate%20procedural%20contamination%20during%20field%20sampling%20and%20processing%20for%20microplastic%20and%20anthropogenic%20microparticles.&amp;author=C%20Gwinnett&amp;author=RZ%20Miller&amp;publication_year=2021&amp;journal=Mar%20Pollut%20Bull&amp;volume=173&amp;pages=" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a><a href="https://doi.org/10.1016/j.marpolbul.2021.113095" target="_blank" xmlns:helper="urn:XsltStringHelper">Crossref</a><span data-targetid="10.1016/j.marpolbul.2021.113095" xmlns:helper="urn:XsltStringHelper"> </span></p></div><div><p><a id="zoi241151r29">29.</a></p><p>Primpke
        &nbsp;S﻿, Cross
        &nbsp;RK﻿, Mintenig
        &nbsp;SM﻿, 
    &nbsp;et al. &nbsp;Toward the systematic identification of microplastics in the environment: evaluation of a new independent software tool (siMPle) for spectroscopic analysis.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Appl Spectrosc</i>. 2020;74(9):1127-1138. doi:<a href="https://dx.doi.org/10.1177/0003702820917760">10.1177/0003702820917760</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/32193948" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Toward%20the%20systematic%20identification%20of%20microplastics%20in%20the%20environment%3A%20evaluation%20of%20a%20new%20independent%20software%20tool%20%28siMPle%29%20for%20spectroscopic%20analysis.&amp;author=S%20Primpke&amp;author=RK%20Cross&amp;author=SM%20Mintenig&amp;publication_year=2020&amp;journal=Appl%20Spectrosc&amp;volume=74&amp;pages=1127-1138" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a><a href="https://doi.org/10.1177/0003702820917760" target="_blank" xmlns:helper="urn:XsltStringHelper">Crossref</a><span data-targetid="10.1177/0003702820917760" xmlns:helper="urn:XsltStringHelper"> </span></p></div><div><p><a id="zoi241151r30">30.</a></p><p>Weisser
        &nbsp;J﻿, Pohl
        &nbsp;T﻿, Heinzinger
        &nbsp;M﻿, Ivleva
        &nbsp;NP﻿, Hofmann
        &nbsp;T﻿, Glas
        &nbsp;K﻿. &nbsp;The Identification of Microplastics Based on Vibrational Spectroscopy Data—A Critical Review of Data Analysis Routines. TrAC.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Trends Analyt Chem</i>. 2022;148:116535. doi:<a href="https://dx.doi.org/10.1016/j.trac.2022.116535">10.1016/j.trac.2022.116535</a><a href="https://scholar.google.com/scholar_lookup?title=The%20Identification%20of%20Microplastics%20Based%20on%20Vibrational%20Spectroscopy%20Data%E2%80%94A%20Critical%20Review%20of%20Data%20Analysis%20Routines.%20TrAC.&amp;author=J%20Weisser&amp;author=T%20Pohl&amp;author=M%20Heinzinger&amp;author=NP%20Ivleva&amp;author=T%20Hofmann&amp;author=K%20Glas&amp;publication_year=2022&amp;journal=Trends%20Analyt%20Chem&amp;volume=148&amp;pages=" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a><a href="https://doi.org/10.1016/j.trac.2022.116535" target="_blank" xmlns:helper="urn:XsltStringHelper">Crossref</a><span data-targetid="10.1016/j.trac.2022.116535" xmlns:helper="urn:XsltStringHelper"> </span></p></div><div><p><a id="zoi241151r31">31.</a></p><p>Morgado
        &nbsp;V﻿, Palma
        &nbsp;C﻿, Bettencourt da Silva
        &nbsp;RJN﻿. &nbsp;Microplastics identification by infrared spectroscopy - Evaluation of identification criteria and uncertainty by the Bootstrap method.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Talanta</i>. 2021;224:121814. doi:<a href="https://dx.doi.org/10.1016/j.talanta.2020.121814">10.1016/j.talanta.2020.121814</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/33379039" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Microplastics%20identification%20by%20infrared%20spectroscopy%20-%20Evaluation%20of%20identification%20criteria%20and%20uncertainty%20by%20the%20Bootstrap%20method.&amp;author=V%20Morgado&amp;author=C%20Palma&amp;author=RJN%20Bettencourt%20da%20Silva&amp;publication_year=2021&amp;journal=Talanta&amp;volume=224&amp;pages=" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div><div><p><a id="zoi241151r36">36.</a></p><p>Kincaid
        &nbsp;AE﻿, Ayers
        &nbsp;JI﻿, Bartz
        &nbsp;JC﻿. &nbsp;Specificity, size, and frequency of spaces that characterize the mechanism of bulk transepithelial transport of prions in the nasal cavities of hamsters and mice.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;J Virol</i>. 2016;90(18):8293-8301. doi:<a href="https://dx.doi.org/10.1128/JVI.01103-16">10.1128/JVI.01103-16</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/27384659" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Specificity%2C%20size%2C%20and%20frequency%20of%20spaces%20that%20characterize%20the%20mechanism%20of%20bulk%20transepithelial%20transport%20of%20prions%20in%20the%20nasal%20cavities%20of%20hamsters%20and%20mice.&amp;author=AE%20Kincaid&amp;author=JI%20Ayers&amp;author=JC%20Bartz&amp;publication_year=2016&amp;journal=J%20Virol&amp;volume=90&amp;pages=8293-8301" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div><div><p><a id="zoi241151r37">37.</a></p><p>Akhbarizadeh
        &nbsp;R﻿, Dobaradaran
        &nbsp;S﻿, Amouei Torkmahalleh
        &nbsp;M﻿, Saeedi
        &nbsp;R﻿, Aibaghi
        &nbsp;R﻿, Faraji Ghasemi
        &nbsp;F﻿. &nbsp;Suspended fine particulate matter (PM<sub>2.5</sub>), microplastics (MPs), and polycyclic aromatic hydrocarbons (PAHs) in air: their possible relationships and health implications.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Environ Res</i>. 2021;192:110339. doi:<a href="https://dx.doi.org/10.1016/j.envres.2020.110339">10.1016/j.envres.2020.110339</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/33068583" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Suspended%20fine%20particulate%20matter%20%28PM2.5%29%2C%20microplastics%20%28MPs%29%2C%20and%20polycyclic%20aromatic%20hydrocarbons%20%28PAHs%29%20in%20air%3A%20their%20possible%20relationships%20and%20health%20implications.&amp;author=R%20Akhbarizadeh&amp;author=S%20Dobaradaran&amp;author=M%20Amouei%20Torkmahalleh&amp;author=R%20Saeedi&amp;author=R%20Aibaghi&amp;author=F%20Faraji%20Ghasemi&amp;publication_year=2021&amp;journal=Environ%20Res&amp;volume=192&amp;pages=" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div><div><p><a id="zoi241151r38">38.</a></p><p>Braithwaite
        &nbsp;I﻿, Zhang
        &nbsp;S﻿, Kirkbride
        &nbsp;JB﻿, Osborn
        &nbsp;DPJ﻿, Hayes
        &nbsp;JF﻿. &nbsp;Air pollution (particulate matter) exposure and associations with depression, anxiety, bipolar, psychosis and suicide risk: a systematic review and meta-analysis.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Environ Health Perspect</i>. 2019;127(12):126002. doi:<a href="https://dx.doi.org/10.1289/EHP4595">10.1289/EHP4595</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/31850801" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Air%20pollution%20%28particulate%20matter%29%20exposure%20and%20associations%20with%20depression%2C%20anxiety%2C%20bipolar%2C%20psychosis%20and%20suicide%20risk%3A%20a%20systematic%20review%20and%20meta-analysis.&amp;author=I%20Braithwaite&amp;author=S%20Zhang&amp;author=JB%20Kirkbride&amp;author=DPJ%20Osborn&amp;author=JF%20Hayes&amp;publication_year=2019&amp;journal=Environ%20Health%20Perspect&amp;volume=127&amp;pages=" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div><div><p><a id="zoi241151r39">39.</a></p><p>Kioumourtzoglou
        &nbsp;MA﻿, Schwartz
        &nbsp;JD﻿, Weisskopf
        &nbsp;MG﻿, 
    &nbsp;et al. &nbsp;Long-term PM2.5 exposure and neurological hospital admissions in the northeastern United States.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Environ Health Perspect</i>. 2016;124(1):23-29. doi:<a href="https://dx.doi.org/10.1289/ehp.1408973">10.1289/ehp.1408973</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/25978701" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Long-term%20PM2.5%20exposure%20and%20neurological%20hospital%20admissions%20in%20the%20northeastern%20United%20States.&amp;author=MA%20Kioumourtzoglou&amp;author=JD%20Schwartz&amp;author=MG%20Weisskopf&amp;publication_year=2016&amp;journal=Environ%20Health%20Perspect&amp;volume=124&amp;pages=23-29" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div><div><p><a id="zoi241151r41">41.</a></p><p>Liu
        &nbsp;XQ﻿, Huang
        &nbsp;J﻿, Song
        &nbsp;C﻿, Zhang
        &nbsp;TL﻿, Liu
        &nbsp;YP﻿, Yu
        &nbsp;L﻿. &nbsp;Neurodevelopmental toxicity induced by PM2.5 exposure and its possible role in neurodegenerative and mental disorders.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Hum Exp Toxicol</i>. Published online August 3, 2023. doi:<a href="https://dx.doi.org/10.1177/09603271231191436">10.1177/09603271231191436</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/37537902" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Neurodevelopmental%20toxicity%20induced%20by%20PM2.5%20exposure%20and%20its%20possible%20role%20in%20neurodegenerative%20and%20mental%20disorders.&amp;author=XQ%20Liu&amp;author=J%20Huang&amp;author=C%20Song&amp;author=TL%20Zhang&amp;author=YP%20Liu&amp;author=L%20Yu&amp;publication_year=2023&amp;journal=Hum%20Exp%20Toxicol&amp;volume=&amp;pages=" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div><div><p><a id="zoi241151r44">44.</a></p><p>Jeong
        &nbsp;SH﻿, Jang
        &nbsp;JH﻿, Lee
        &nbsp;YB﻿. &nbsp;Drug delivery to the brain via the nasal route of administration: exploration of key targets and major consideration factors.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;J Pharm Investig</i>. 2023;53(1):119-152. doi:<a href="https://dx.doi.org/10.1007/s40005-022-00589-5">10.1007/s40005-022-00589-5</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/35910081" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Drug%20delivery%20to%20the%20brain%20via%20the%20nasal%20route%20of%20administration%3A%20exploration%20of%20key%20targets%20and%20major%20consideration%20factors.&amp;author=SH%20Jeong&amp;author=JH%20Jang&amp;author=YB%20Lee&amp;publication_year=2023&amp;journal=J%20Pharm%20Investig&amp;volume=53&amp;pages=119-152" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div></div>

</div>

        
    </div> 





 
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Senate Vote Tomorrow Could Give Helping Hand to Patent Trolls (199 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2024/09/senate-vote-tomorrow-could-give-helping-hand-patent-trolls</link>
            <guid>41582278</guid>
            <pubDate>Wed, 18 Sep 2024 16:50:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2024/09/senate-vote-tomorrow-could-give-helping-hand-patent-trolls">https://www.eff.org/deeplinks/2024/09/senate-vote-tomorrow-could-give-helping-hand-patent-trolls</a>, See on <a href="https://news.ycombinator.com/item?id=41582278">Hacker News</a></p>
Couldn't get https://www.eff.org/deeplinks/2024/09/senate-vote-tomorrow-could-give-helping-hand-patent-trolls: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[GM electric vehicles can now access Tesla Superchargers (162 pts)]]></title>
            <link>https://www.theverge.com/2024/9/18/24247122/gm-ev-tesla-supercharger-access-adapter-price</link>
            <guid>41582267</guid>
            <pubDate>Wed, 18 Sep 2024 16:49:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/9/18/24247122/gm-ev-tesla-supercharger-access-adapter-price">https://www.theverge.com/2024/9/18/24247122/gm-ev-tesla-supercharger-access-adapter-price</a>, See on <a href="https://news.ycombinator.com/item?id=41582267">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>General Motors says it has updated the software in its electric vehicles so its customers can finally use Tesla’s Supercharging network. </p><p>To gain immediate access, owners of electric Chevy, Cadillac, and GMC vehicles will need to purchase “GM approved” Tesla adapters through each brand’s smartphone app for $225. Future GM vehicles will come with Tesla’s charging port natively installed. </p><p>The announcement comes more than 15 months after <a href="https://www.theverge.com/2023/6/8/23754470/gm-tesla-ev-supercharger-nacs-elon-musk">GM first announced</a> it would adopt Tesla’s EV charging plug for its vehicles. The automaker had originally said it expected to complete the software coordination with Tesla by “early spring” 2024, but <a href="https://www.forbes.com/sites/sashalekach/2024/06/20/tesla-supercharger-adapters-delayed-for-all-general-motors-evs/">production bottlenecks</a> and <a href="https://www.theverge.com/2024/5/3/24147402/tesla-supercharger-layoffs-stalled-ev-infrastructure-projects">layoffs at Tesla</a> have delayed the process. </p><div><div role="button" aria-label="Zoom" tabindex="0"><figure><div><p><span><img alt="" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 1023px) 100vw, 744px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/376x251/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/384x256/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/415x277/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/480x320/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/540x360/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/640x427/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/750x500/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/828x552/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/1080x720/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/1200x800/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/1440x960/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/1920x1280/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/2048x1365/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/2400x1600/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:9504x6336/2400x1600/filters:focal(4752x3168:4753x3169):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25626334/GM___NACS_2.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div></figure></div><p><cite>Image: GM</cite></p></div><p>GM celebrated the news, noting that its customers will now have access to 17,800 Tesla Supercharger plugs for the first time. The lack of convenient and reliable charging is frequently cited in surveys of customers as a major obstacle to purchasing an electric vehicle. And Tesla’s Superchargers are widely seen as among the best EV charging networks in the world. </p><p>Starting with Ford last year, nearly every major automaker has publicly committed to adopting the <a href="https://driveelectric.gov/charging-connector">SAE J3400</a> fast charging plug, also known as the North American Charging Standard (NACS). The process will begin with a software update so non-Tesla vehicles can “talk” to Tesla’s Superchargers, as well as the use of an adapter. </p><p>GM says it plans on sourcing its NACS-approved adapters from multiple suppliers. That way, it’s not just relying on Tesla, which makes its own adapters at its gigafactory in Buffalo, New York, where production has been slow. Several other companies also make NACS adapters, including <a href="https://go.skimresources.com/?id=1025X1701640&amp;xs=1&amp;url=https%3A%2F%2Fev-lectron.com%2Fproducts%2Flectron-vortex-plug-tesla-supercharger-nacs-to-ccs-adapter">Lectron</a> and <a href="https://shop.qmerit.com/products/j1772-charger-adapter-copy">Qmerit</a>.  </p><p>Within the next few years, automakers say they will begin producing EVs with the NACS port built directly into the vehicle, enabling them to charge at Tesla stations without an adapter. </p><div><p>GM says it plans on sourcing its NACS-approved adapters from multiple suppliers</p></div><p>GM’s decision to sell the adapters, rather than give them away for free as some other companies have done, may ruffle some feathers. Both <a href="https://www.theverge.com/2024/2/29/24085844/ford-ev-adapter-tesla-supercharger-nacs">Ford</a> and <a href="https://www.theverge.com/2024/3/18/24104786/rivian-tesla-supercharger-access-adapter-free-r1t-r1s">Rivian</a> gave out free adapters for a limited time before making customers buy them. But GM said it won’t be offering any complimentary period to its customers. </p><p>GM is also updating its brand apps to allow customers to search for available Superchargers, check station status, initiate a charge, and pay for charging sessions. Tesla has said that non-Tesla owners would have to pay a little more to charge their vehicles than Tesla owners. </p><p>Tesla had a head start in building its own EV charging network, but other automakers are intent on catching up. GM is also involved in several projects to build new fast EV chargers, including with <a href="https://www.theverge.com/2024/9/12/24242068/gm-energy-evgo-ev-dc-fast-charging-network-flagship-locations">EVgo</a> and a consortium of other automakers through the <a href="https://www.theverge.com/24176160/ionna-ev-charging-dc-fast-headquarters-network">Ionna joint venture</a>. </p><p>Following GM, Tesla has said that it will coordinate next with Volvo, Polestar, Nissan, and Mercedes-Benz to grant their customers access to Superchargers. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama 3.1 Omni Model (269 pts)]]></title>
            <link>https://github.com/ictnlp/LLaMA-Omni</link>
            <guid>41582180</guid>
            <pubDate>Wed, 18 Sep 2024 16:42:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ictnlp/LLaMA-Omni">https://github.com/ictnlp/LLaMA-Omni</a>, See on <a href="https://news.ycombinator.com/item?id=41582180">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">🦙🎧 LLaMA-Omni: Seamless Speech Interaction with Large Language Models</h2><a id="user-content--llama-omni-seamless-speech-interaction-with-large-language-models" aria-label="Permalink: 🦙🎧 LLaMA-Omni: Seamless Speech Interaction with Large Language Models" href="#-llama-omni-seamless-speech-interaction-with-large-language-models"></a></p>
<blockquote>
<p dir="auto"><strong>Authors: <a href="https://fangqingkai.github.io/" rel="nofollow">Qingkai Fang</a>, <a href="https://scholar.google.com/citations?hl=en&amp;user=XwHtPyAAAAAJ" rel="nofollow">Shoutao Guo</a>, <a href="https://zhouyan19.github.io/zhouyan/" rel="nofollow">Yan Zhou</a>, <a href="https://scholar.google.com.hk/citations?user=dUgq6tEAAAAJ" rel="nofollow">Zhengrui Ma</a>, <a href="https://zhangshaolei1998.github.io/" rel="nofollow">Shaolei Zhang</a>, <a href="https://people.ucas.edu.cn/~yangfeng?language=en" rel="nofollow">Yang Feng*</a></strong></p>
</blockquote>
<p dir="auto"><a href="https://arxiv.org/abs/2409.06666" rel="nofollow"><img src="https://camo.githubusercontent.com/cf848c9cd376e15932b0cba092d5c6053463835849a56eac0c6a011d3ab107d5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f61725869762d323430392e30363636362d6233316231622e7376673f6c6f676f3d6172586976" alt="arXiv" data-canonical-src="https://img.shields.io/badge/arXiv-2409.06666-b31b1b.svg?logo=arXiv"></a>
<a href="https://huggingface.co/ICTNLP/Llama-3.1-8B-Omni" rel="nofollow"><img src="https://camo.githubusercontent.com/43ed5a97ea9a77d1afe95566b086cb8aed400254b78842e11ed83614f503df95/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f25463025394625413425393725323048756767696e675f466163652d4d6f64656c2d626c75652e737667" alt="model" data-canonical-src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging_Face-Model-blue.svg"></a>
<a href="https://github.com/ictnlp/LLaMA-Omni"><img src="https://camo.githubusercontent.com/77762e523530a02dd6ad9f1b9e4e9dd91c0bf748c684bd5cced64a3302047441/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769746875622d436f64652d6b657967656e2e7376673f6c6f676f3d676974687562" alt="code" data-canonical-src="https://img.shields.io/badge/Github-Code-keygen.svg?logo=github"></a></p>
<p dir="auto">LLaMA-Omni is a speech-language model built upon Llama-3.1-8B-Instruct. It supports low-latency and high-quality speech interactions, simultaneously generating both text and speech responses based on speech instructions.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/ictnlp/LLaMA-Omni/blob/main/images/model.png"><img src="https://github.com/ictnlp/LLaMA-Omni/raw/main/images/model.png" width="75%"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">💡 Highlights</h2><a id="user-content--highlights" aria-label="Permalink: 💡 Highlights" href="#-highlights"></a></p>
<ul dir="auto">
<li>
<p dir="auto">💪 <strong>Built on Llama-3.1-8B-Instruct, ensuring high-quality responses.</strong></p>
</li>
<li>
<p dir="auto">🚀 <strong>Low-latency speech interaction with a latency as low as 226ms.</strong></p>
</li>
<li>
<p dir="auto">🎧 <strong>Simultaneous generation of both text and speech responses.</strong></p>
</li>
<li>
<p dir="auto">♻️ <strong>Trained in less than 3 days using just 4 GPUs.</strong></p>
</li>
</ul>
<details open="">
  <summary>
    
    <span aria-label="Video description demo.mp4">demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/19513464/366072569-2b097af8-47d7-494f-b3b3-6be17ca0247a.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjY3MDI1MTQsIm5iZiI6MTcyNjcwMjIxNCwicGF0aCI6Ii8xOTUxMzQ2NC8zNjYwNzI1NjktMmIwOTdhZjgtNDdkNy00OTRmLWIzYjMtNmJlMTdjYTAyNDdhLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTE4VDIzMzAxNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhOGYwOTcwMTgwOWQ0MWNiYzQ0OWRhZDgyNWNhMDE2NjgwMmQxNjNkMzY4MmI2ZGU4ZmFlM2QwNjA2M2VjZjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.las91a8L1UW1B_MSTxqh8zBOpmbpiB26ZRr7hAb3Hvo" data-canonical-src="https://private-user-images.githubusercontent.com/19513464/366072569-2b097af8-47d7-494f-b3b3-6be17ca0247a.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjY3MDI1MTQsIm5iZiI6MTcyNjcwMjIxNCwicGF0aCI6Ii8xOTUxMzQ2NC8zNjYwNzI1NjktMmIwOTdhZjgtNDdkNy00OTRmLWIzYjMtNmJlMTdjYTAyNDdhLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTE4VDIzMzAxNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhOGYwOTcwMTgwOWQ0MWNiYzQ0OWRhZDgyNWNhMDE2NjgwMmQxNjNkMzY4MmI2ZGU4ZmFlM2QwNjA2M2VjZjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.las91a8L1UW1B_MSTxqh8zBOpmbpiB26ZRr7hAb3Hvo" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<ol dir="auto">
<li>Clone this repository.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/ictnlp/LLaMA-Omni
cd LLaMA-Omni"><pre>git clone https://github.com/ictnlp/LLaMA-Omni
<span>cd</span> LLaMA-Omni</pre></div>
<ol start="2" dir="auto">
<li>Install packages.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="conda create -n llama-omni python=3.10
conda activate llama-omni
pip install pip==24.0
pip install -e ."><pre>conda create -n llama-omni python=3.10
conda activate llama-omni
pip install pip==24.0
pip install -e <span>.</span></pre></div>
<ol start="3" dir="auto">
<li>Install <code>fairseq</code>.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/pytorch/fairseq
cd fairseq
pip install -e . --no-build-isolation"><pre>git clone https://github.com/pytorch/fairseq
<span>cd</span> fairseq
pip install -e <span>.</span> --no-build-isolation</pre></div>
<ol start="4" dir="auto">
<li>Install <code>flash-attention</code>.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="pip install flash-attn --no-build-isolation"><pre>pip install flash-attn --no-build-isolation</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Download the <code>Llama-3.1-8B-Omni</code> model from 🤗<a href="https://huggingface.co/ICTNLP/Llama-3.1-8B-Omni" rel="nofollow">Huggingface</a>.</p>
</li>
<li>
<p dir="auto">Download the <code>Whisper-large-v3</code> model.</p>
</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="import whisper
model = whisper.load_model(&quot;large-v3&quot;, download_root=&quot;models/speech_encoder/&quot;)"><pre>import whisper
model = whisper.load_model(<span><span>"</span>large-v3<span>"</span></span>, download_root=<span><span>"</span>models/speech_encoder/<span>"</span></span>)</pre></div>
<ol start="3" dir="auto">
<li>Download the unit-based HiFi-GAN vocoder.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="wget https://dl.fbaipublicfiles.com/fairseq/speech_to_speech/vocoder/code_hifigan/mhubert_vp_en_es_fr_it3_400k_layer11_km1000_lj/g_00500000 -P vocoder/
wget https://dl.fbaipublicfiles.com/fairseq/speech_to_speech/vocoder/code_hifigan/mhubert_vp_en_es_fr_it3_400k_layer11_km1000_lj/config.json -P vocoder/"><pre>wget https://dl.fbaipublicfiles.com/fairseq/speech_to_speech/vocoder/code_hifigan/mhubert_vp_en_es_fr_it3_400k_layer11_km1000_lj/g_00500000 -P vocoder/
wget https://dl.fbaipublicfiles.com/fairseq/speech_to_speech/vocoder/code_hifigan/mhubert_vp_en_es_fr_it3_400k_layer11_km1000_lj/config.json -P vocoder/</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Gradio Demo</h2><a id="user-content-gradio-demo" aria-label="Permalink: Gradio Demo" href="#gradio-demo"></a></p>
<ol dir="auto">
<li>Launch a controller.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python -m omni_speech.serve.controller --host 0.0.0.0 --port 10000"><pre>python -m omni_speech.serve.controller --host 0.0.0.0 --port 10000</pre></div>
<ol start="2" dir="auto">
<li>Launch a gradio web server.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python -m omni_speech.serve.gradio_web_server --controller http://localhost:10000 --port 8000 --model-list-mode reload --vocoder vocoder/g_00500000 --vocoder-cfg vocoder/config.json"><pre>python -m omni_speech.serve.gradio_web_server --controller http://localhost:10000 --port 8000 --model-list-mode reload --vocoder vocoder/g_00500000 --vocoder-cfg vocoder/config.json</pre></div>
<ol start="3" dir="auto">
<li>Launch a model worker.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python -m omni_speech.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path Llama-3.1-8B-Omni --model-name Llama-3.1-8B-Omni --s2s"><pre>python -m omni_speech.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path Llama-3.1-8B-Omni --model-name Llama-3.1-8B-Omni --s2s</pre></div>
<ol start="4" dir="auto">
<li>Visit <a href="http://localhost:8000/" rel="nofollow">http://localhost:8000/</a> and interact with LLaMA-3.1-8B-Omni!</li>
</ol>
<p dir="auto"><strong>Note: Due to the instability of streaming audio playback in Gradio, we have only implemented streaming audio synthesis without enabling autoplay. If you have a good solution, feel free to submit a PR. Thanks!</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Local Inference</h2><a id="user-content-local-inference" aria-label="Permalink: Local Inference" href="#local-inference"></a></p>
<p dir="auto">To run inference locally, please organize the speech instruction files according to the format in the <code>omni_speech/infer/examples</code> directory, then refer to the following script.</p>
<div dir="auto" data-snippet-clipboard-copy-content="bash omni_speech/infer/run.sh omni_speech/infer/examples"><pre>bash omni_speech/infer/run.sh omni_speech/infer/examples</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">LICENSE</h2><a id="user-content-license" aria-label="Permalink: LICENSE" href="#license"></a></p>
<p dir="auto">Our code is released under the Apache-2.0 License. Our model, as it is built on Llama 3.1, is required to comply with the <a href="https://llama.meta.com/llama3_1/license/" rel="nofollow">Llama 3.1 License</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<ul dir="auto">
<li><a href="https://github.com/haotian-liu/LLaVA">LLaVA</a>: The codebase we built upon.</li>
<li><a href="https://github.com/X-LANCE/SLAM-LLM">SLAM-LLM</a>: We borrow some code about speech encoder and speech adaptor.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<p dir="auto">If you have any questions, please feel free to submit an issue or contact <code>fangqingkai21b@ict.ac.cn</code>.</p>
<p dir="auto">If our work is useful for you, please cite as:</p>
<div data-snippet-clipboard-copy-content="@article{fang-etal-2024-llama-omni,
  title={LLaMA-Omni: Seamless Speech Interaction with Large Language Models},
  author={Fang, Qingkai and Guo, Shoutao and Zhou, Yan and Ma, Zhengrui and Zhang, Shaolei and Feng, Yang},
  journal={arXiv preprint arXiv:2409.06666},
  year={2024}
}"><pre><code>@article{fang-etal-2024-llama-omni,
  title={LLaMA-Omni: Seamless Speech Interaction with Large Language Models},
  author={Fang, Qingkai and Guo, Shoutao and Zhou, Yan and Ma, Zhengrui and Zhang, Shaolei and Feng, Yang},
  journal={arXiv preprint arXiv:2409.06666},
  year={2024}
}
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Star History</h2><a id="user-content-star-history" aria-label="Permalink: Star History" href="#star-history"></a></p>
<p dir="auto"><a href="https://star-history.com/#ictnlp/llama-omni&amp;Date" rel="nofollow"><img src="https://camo.githubusercontent.com/73a57c27c1f48fd90f61261b56699215fdd4b2267edd91ec8494c550fd34bc04/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6963746e6c702f6c6c616d612d6f6d6e6926747970653d44617465" alt="Star History Chart" data-canonical-src="https://api.star-history.com/svg?repos=ictnlp/llama-omni&amp;type=Date"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RabbitMQ 4.0 Released (235 pts)]]></title>
            <link>https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.0</link>
            <guid>41581942</guid>
            <pubDate>Wed, 18 Sep 2024 16:24:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.0">https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.0</a>, See on <a href="https://news.ycombinator.com/item?id=41581942">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pjax="true" data-test-selector="body-content" data-view-component="true"><p>RabbitMQ <code>4.0.0</code> is a new major release.</p>
<p>Starting June 1st, 2024, community support for this series will only be provided to <a href="https://github.com/rabbitmq/rabbitmq-server/blob/main/COMMUNITY_SUPPORT.md">regularly contributing users</a><br>
and those who hold a valid <a href="https://tanzu.vmware.com/rabbitmq/oss" rel="nofollow">commercial support license</a>.</p>
<h2>Highlights</h2>
<p>Some key improvements in this release are listed below.</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=whVqpgvep90" rel="nofollow">Khepri</a>, an <a href="https://github.com/rabbitmq/rabbitmq-server/pull/7206" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/7206/hovercard">alternative schema data store</a> developed to replace Mnesia,<br>
has matured and is now fully supported (it previously was an experimental feature)</li>
<li><a href="https://www.rabbitmq.com/blog/2024/08/05/native-amqp" rel="nofollow">AMQP 1.0 is now a core protocol</a> that is always enabled. Its plugin is now a no-op that only exists to simplify upgrades.</li>
<li>The AMQP 1.0 implementation is now significantly more efficient: its peak throughput is <a href="https://www.rabbitmq.com/blog/2024/08/21/amqp-benchmarks" rel="nofollow">more than double than that of 3.13.x</a><br>
on some workloads</li>
<li>Efficient sub-linear <a href="https://www.rabbitmq.com/blog/2024/08/28/quorum-queues-in-4.0#faster-recovery-of-long-queues" rel="nofollow">quorum queue recovery on node startup using checkpoints</a></li>
<li>Quorum queues now <a href="https://www.rabbitmq.com/blog/2024/08/28/quorum-queues-in-4.0#message-priorities" rel="nofollow">support priorities</a> (but not exactly the same way as classic queues)</li>
<li><a href="https://github.com/rabbitmq/rabbitmq-server/pull/10559" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10559/hovercard">AMQP 1.0 clients now can manage topologies</a> similarly to how AMQP 0-9-1 clients do it</li>
<li>The AMQP 1.0 convention (address format) used for interacting with with AMQP 0-9-1 entities <a href="https://www.rabbitmq.com/docs/next/amqp#addresses" rel="nofollow">is now easier to reason about</a></li>
<li>Mirroring (replication) of classic queues <a href="https://github.com/rabbitmq/rabbitmq-server/pull/9815" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/9815/hovercard">was removed</a> after several years of deprecation. For replicated messaging data types,<br>
use quorum queues and/or streams. Non-replicated classic queues remain and their development continues</li>
<li>Classic queue <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11112" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11112/hovercard">storage efficiency improvements</a>, in particular recovery time and storage of multi-MiB messages</li>
<li>Nodes with multiple enabled plugins and little on disk data to recover now <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10989" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10989/hovercard">start up to 20-30% faster</a></li>
<li>New exchange type: <a href="https://rabbitmq.com/docs/next/local-random-exchange" rel="nofollow">Local Random Exchange</a></li>
</ul>
<p>See Compatibility Notes below to learn about <strong>breaking or potentially breaking changes</strong> in this release.</p>
<h2>Breaking Changes and Compatibility Notes</h2>
<h3>Classic Queues is Now a Non-Replicated Queue Type</h3>
<p>After three years of deprecated, classic queue mirroring was completely removed in this version.<br>
<a href="https://www.rabbitmq.com/docs/quorum-queues" rel="nofollow">Quorum queues</a> and <a href="https://www.rabbitmq.com/docs/streams" rel="nofollow">streams</a> are two mature<br>
replicated data types offered by RabbitMQ 4.x. Classic queues continue being supported without any breaking changes<br>
for client libraries and applications but they are now a non-replicated queue type.</p>
<p>After an upgrade to 4.0, all classic queue mirroring-related parts of policies will have no effect.<br>
Classic queues will continue to work like before but with only one replica.</p>
<p>Clients will be able to connect to any node to publish to and consume from any non-replicated classic queues.<br>
Therefore applications will be able to use the same classic queues as before.</p>
<p>See <a href="https://www.rabbitmq.com/docs/migrate-mcq-to-qq" rel="nofollow">Mirrored Classic Queues Migration to Quorum Queues</a> for guidance<br>
on how to migrate to quorum queues for the parts of the system that really need to use replication.</p>
<h3>Quorum Queues Now Have a Default Redelivery Limit</h3>
<p>Quorum queues now have a default <a href="https://www.rabbitmq.com/docs/next/quorum-queues#poison-message-handling" rel="nofollow">redelivery limit</a> set to <code>20</code>.<br>
Messages that are redelivered 20 times or more will be <a href="https://www.rabbitmq.com/docs/dlx" rel="nofollow">dead-lettered</a> or dropped (removed).</p>
<p>This limit is necessary to protect nodes from consumers that run into infinite fail-requeue-fail-requeue loops. Such<br>
consumers can drive a node out of disk space by making a quorum queue Raft log grow forever without allowing compaction<br>
of older entries to happen.</p>
<p>If 20 deliveries per message is a common scenario for a queue, a dead-lettering target or a higher limit must be configured<br>
for such queues. The recommended way of doing that is via a <a href="https://www.rabbitmq.com/docs/parameters#policies" rel="nofollow">policy</a>.<br>
See the <a href="https://www.rabbitmq.com/docs/next/quorum-queues#poison-message-handling" rel="nofollow">Position Messaging Handling</a> section<br>
in the quorum queue documentation guide.</p>
<p>Note that increasing the limit is recommended against: usually the presence of messages that have been redelivered 20 times or more suggests<br>
that a consumer has entered a fail-requeue-fail-requeue loop, in which case even a much higher limit<br>
won't help avoid the dead-lettering.</p>
<p>For specific cases where the RabbitMQ configuration cannot be updated to include a dead letter policy<br>
the delivery limit can be disabled by setting a delivery limit configuration of <code>-1</code>. However, the RabbitMQ team<br>
strongly recommends keeping the delivery limit in place to ensure cluster availability isn't<br>
accidentally sacrificed.</p>
<h3>CQv1 Storage Implementation was Removed</h3>
<p>CQv1, <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10656" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10656/hovercard">the original classic queue storage layer, was removed</a><br>
except for the part that's necessary for upgrades to CQv2 (the 2nd generation).</p>
<p>In case <code>rabbitmq.conf</code> explicitly sets <code>classic_queue.default_version</code> to <code>1</code> like so</p>
<div data-snippet-clipboard-copy-content="# this configuration value is no longer supported,
# remove this line or set the version to 2
classic_queue.default_version = 1"><pre><span><span>#</span> this configuration value is no longer supported,</span>
<span><span>#</span> remove this line or set the version to 2</span>
<span>classic_queue.default_version</span> = 1</pre></div>
<p>nodes will now fail to start. Removing the line will make the node start and perform<br>
the migration from CQv1 to CQv2.</p>
<h3>Settings <code>cluster_formation.randomized_startup_delay_range.*</code> were Removed</h3>
<p>The following two deprecated <code>rabbitmq.conf</code> settings were <a href="https://github.com/rabbitmq/rabbitmq-server/pull/12050" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/12050/hovercard">removed</a>:</p>
<div data-snippet-clipboard-copy-content="cluster_formation.randomized_startup_delay_range.min
cluster_formation.randomized_startup_delay_range.max"><pre><code>cluster_formation.randomized_startup_delay_range.min
cluster_formation.randomized_startup_delay_range.max
</code></pre></div>
<p>RabbitMQ 4.0 will fail to boot if these settings are configured in <code>rabbitmq.conf</code>.</p>
<h3>Several Disk I/O-Related Metrics were Removed</h3>
<p>Several I/O-related metrics are dropped, they should be <a href="https://www.rabbitmq.com/docs/monitoring#system-metrics" rel="nofollow">monitored at the infrastructure and kernel layers</a></p>
<h3>Default Maximum Message Size Reduced to 16 MiB</h3>
<p>Default maximum message size is reduced to 16 MiB (from 128 MiB).</p>
<p>The limit can be increased via a <code>rabbitmq.conf</code> setting:</p>
<div data-snippet-clipboard-copy-content="# 32 MiB
max_message_size = 33554432"><pre><span><span>#</span> 32 MiB</span>
<span>max_message_size</span> = 33554432</pre></div>
<p>However, it is recommended that such large multi-MiB messages are put into a blob store, and their<br>
IDs are passed around in messages instead of the entire payload.</p>
<h3>AMQP 1.0</h3>
<p>RabbitMQ 3.13 <code>rabbitmq.conf</code> setting <code>rabbitmq_amqp1_0.default_vhost</code> is unsupported in RabbitMQ 4.0.</p>
<p>Instead <code>default_vhost</code> will be used to determine the default vhost an AMQP 1.0 client connects to(i.e. when the AMQP 1.0 client<br>
does not define the vhost in the <code>hostname</code> field of the <code>open</code> frame).</p>
<p>Starting with RabbitMQ 4.0, RabbitMQ strictly validates that<br>
<a href="https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-delivery-annotations" rel="nofollow">delivery annotations</a>,<br>
<a href="https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-message-annotations" rel="nofollow">message annotations</a>, and<br>
<a href="https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-footer" rel="nofollow">footer</a> contain only<br>
<a href="https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-annotations" rel="nofollow">non-reserved annotation keys</a>.<br>
As a result, clients can only send symbolic keys that begin with <code>x-</code>.</p>
<h3>MQTT</h3>
<p>RabbitMQ 3.13 <a href="https://www.rabbitmq.com/docs/configure#config-file" rel="nofollow">rabbitmq.conf</a> settings <code>mqtt.default_user</code>, <code>mqtt.default_password</code>,<br>
and <code>amqp1_0.default_user</code> are unsupported in RabbitMQ 4.0.</p>
<p>Instead, set the new RabbitMQ 4.0 settings <code>anonymous_login_user</code> and <code>anonymous_login_pass</code> (both values default to <code>guest</code>).<br>
For production scenarios, <a href="https://www.rabbitmq.com/docs/next/production-checklist#anonymous-login" rel="nofollow">disallow anonymous logins</a>.</p>
<h3>TLS Client (LDAP, Shovels, Federation) Defaults</h3>
<p>Starting with Erlang 26, client side <a href="https://www.rabbitmq.com/docs/ssl#peer-verification" rel="nofollow">TLS peer certificate chain verification</a> settings are enabled by default in most contexts:<br>
from federation links to shovels to TLS-enabled LDAP client connections.</p>
<p>If using TLS peer certificate chain verification is not practical or necessary, it can be disabled.<br>
Please refer to the docs of the feature in question, for example,<br>
this one <a href="http://rabbitmq.com/docs/ldap/#tls" rel="nofollow">on TLS-enabled LDAP client</a> connections,<br>
two others on <a href="https://www.rabbitmq.com/docs/shovel#tls" rel="nofollow">TLS-enabled dynamic shovels</a> and <a href="https://www.rabbitmq.com/docs/uri-query-parameters" rel="nofollow">dynamic shovel URI query parameters</a>.</p>
<h3>Shovels</h3>
<p>RabbitMQ Shovels will be able connect to a RabbitMQ 4.0 node via AMQP 1.0 only when the Shovel runs on a RabbitMQ node &gt;= <code>3.13.7</code>.</p>
<p>TLS-enabled Shovels will be affected by the TLS client default changes in Erlang 26 (see above).</p>
<h2>Erlang/OTP Compatibility Notes</h2>
<p>This release <a href="https://www.rabbitmq.com/docs/which-erlang" rel="nofollow">requires Erlang 26.2</a>.</p>
<p><a href="https://www.rabbitmq.com/docs/which-erlang#erlang-repositories" rel="nofollow">Provisioning Latest Erlang Releases</a> explains<br>
what package repositories and tools can be used to provision latest patch versions of Erlang 26.x.</p>
<h2>Release Artifacts</h2>
<p>RabbitMQ releases are distributed via <a href="https://github.com/rabbitmq/rabbitmq-server/releases">GitHub</a>.<br>
<a href="https://rabbitmq.com/docs/install-debian/" rel="nofollow">Debian</a> and <a href="https://rabbitmq.com/docs/install-rpm/" rel="nofollow">RPM packages</a> are available via<br>
repositories maintained by the RabbitMQ Core Team.</p>
<p><a href="https://hub.docker.com/_/rabbitmq/" rel="nofollow">Community Docker image</a>, <a href="https://community.chocolatey.org/packages/rabbitmq" rel="nofollow">Chocolatey package</a>, and the <a href="https://www.rabbitmq.com/docs/install-homebrew" rel="nofollow">Homebrew formula</a><br>
are other installation options. They are updated with a delay.</p>
<h2>Upgrading to 4.0</h2>
<h3>Documentation guides on upgrades</h3>
<p>See the <a href="https://www.rabbitmq.com/docs/upgrade" rel="nofollow">Upgrading guide</a> for documentation on upgrades and <a href="https://github.com/rabbitmq/rabbitmq-server/releases">GitHub releases</a><br>
for release notes of individual releases.</p>
<p>This release series only supports upgrades from <code>3.13.x</code>.</p>
<p>This release requires <strong>all feature flags</strong> in the 3.x series (specifically <code>3.13.x</code>) to be enabled before upgrading,<br>
there is no upgrade path from 3.12.14 (or a later patch release) straight to <code>4.0.0</code>.</p>
<h3>Required Feature Flags</h3>
<p>This release <a href="https://www.rabbitmq.com/docs/feature-flags#graduation" rel="nofollow">graduates</a> all feature flags introduced up to <code>3.13.0</code>.</p>
<p>All users must enable all stable [feature flags] before upgrading to 4.0 from<br>
the latest available 3.13.x patch release.</p>
<h3>Mixed version cluster compatibility</h3>
<p>RabbitMQ 4.0.0 nodes can run alongside <code>3.13.x</code> nodes. <code>4.0.x</code>-specific features can only be made available when all nodes in the cluster<br>
upgrade to 4.0.0 or a later patch release in the new series.</p>
<p>While operating in mixed version mode, some aspects of the system may not behave as expected. The list of known behavior changes will be covered in future updates.<br>
Once all nodes are upgraded to 4.0.0, these irregularities will go away.</p>
<p>Mixed version clusters are a mechanism that allows rolling upgrade and are not meant to be run for extended<br>
periods of time (no more than a few hours).</p>
<h3>Recommended Post-upgrade Procedures</h3>
<h4>Configure Dead Lettering or Increase the Limit for Frequently Redelivered Messages</h4>
<p>In environments where messages can experience 20 redeliveries, the affected queues should have <a href="https://www.rabbitmq.com/docs/dlx" rel="nofollow">dead lettering</a><br>
configured (usually via a <a href="https://www.rabbitmq.com/docs/parameters#policies" rel="nofollow">policy</a>) to make sure<br>
that messages that are redelivered 20 times are moved to a separate queue (or stream) instead of<br>
being dropped (removed) by the <a href="https://www.rabbitmq.com/docs/next/quorum-queues#poison-message-handling" rel="nofollow">crash-requeue-redelivery loop protection mechanism</a>.</p>
<p>Alternatively, the limit can be <a href="https://www.rabbitmq.com/docs/next/quorum-queues#poison-message-handling" rel="nofollow">increased</a> using a policy.<br>
This option is recommended against: usually the presence of messages that have been redelivered 20 times or more suggests<br>
that a consumer has entered a fail-requeue-fail-requeue loop, in which case even a much higher limit<br>
won't help avoid the dead-lettering.</p>
<h2>Changes Worth Mentioning</h2>
<p>This section is incomplete and will be expanded as 4.0 approaches its release candidate stage.</p>
<h3>Core Server</h3>
<h4>Enhancements</h4>
<ul>
<li>
<p>Efficient sub-linear quorum queue recovery on node startup using checkpoints.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10637" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10637/hovercard">#10637</a></p>
</li>
<li>
<p>Classic queue storage v2 (CQv2) optimizations. For example, CQv2 recovery time on node boot<br>
is now twice as fast for some data sets.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11112" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11112/hovercard">#11112</a></p>
</li>
<li>
<p>Node startup time improvements. For some environments, nodes with very small on disk data sets<br>
now start about 25% quicker.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10989" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10989/hovercard">#10989</a></p>
</li>
<li>
<p>Quorum queues now support <a href="https://www.rabbitmq.com/docs/next/quorum-queues#priorities" rel="nofollow">priorities</a>. However,<br>
there are difference with how priorities work in classic queues.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10637" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10637/hovercard">#10637</a></p>
</li>
<li>
<p>Per-message metadata stored in the quorum queue Raft log now uses less disk space.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/issues/8261" data-hovercard-type="issue" data-hovercard-url="/rabbitmq/rabbitmq-server/issues/8261/hovercard">#8261</a></p>
</li>
<li>
<p>Single Active Consumer (SAC) implementation of quorum queues now <a href="https://www.rabbitmq.com/blog/2024/08/28/quorum-queues-in-4.0#consumer-priorities-combined-with-single-active-consumer" rel="nofollow">respects</a> consumer priorities.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/issues/8261" data-hovercard-type="issue" data-hovercard-url="/rabbitmq/rabbitmq-server/issues/8261/hovercard">#8261</a></p>
</li>
<li>
<p><code>rabbitmq.conf</code> now supports <a href="https://www.rabbitmq.com/docs/next/configure#configuration-encryption" rel="nofollow">encrypted values</a><br>
with a prefix:</p>
<div data-snippet-clipboard-copy-content="default_user = bunnies-444
default_pass = encrypted:F/bjQkteQENB4rMUXFKdgsJEpYMXYLzBY/AmcYG83Tg8AOUwYP7Oa0Q33ooNEpK9"><pre><span>default_user</span> = bunnies-444
<span>default_pass</span> = encrypted:F/bjQkteQENB4rMUXFKdgsJEpYMXYLzBY/AmcYG83Tg8AOUwYP7Oa0Q33ooNEpK9</pre></div>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11989" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11989/hovercard">#11989</a></p>
</li>
<li>
<p>All feature flags up to <code>3.13.0</code> have <a href="https://www.rabbitmq.com/docs/feature-flags#graduation" rel="nofollow">graduated</a> and are now mandatory.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11659" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11659/hovercard">#11659</a></p>
</li>
<li>
<p>Quorum queues now use a default <a href="https://www.rabbitmq.com/docs/next/quorum-queues#poison-message-handling" rel="nofollow">redelivery limit</a> of 20.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11937" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11937/hovercard">#11937</a></p>
</li>
<li>
<p><code>queue_master_locator</code> queue setting has been deprecated in favor of <code>queue_leader_locator</code> used by quorum queues<br>
and streams.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/issues/10702" data-hovercard-type="issue" data-hovercard-url="/rabbitmq/rabbitmq-server/issues/10702/hovercard">#10702</a></p>
</li>
</ul>
<h3>AMQP 1.0</h3>
<h4>Bug Fixes</h4>
<ul>
<li>
<p>AMQP 0-9-1 to AMQP 1.0 string data type conversion improvements.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11715" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11715/hovercard">#11715</a></p>
</li>
</ul>
<h4>Enhancements</h4>
<ul>
<li>
<p><a href="https://www.rabbitmq.com/blog/2024/08/05/native-amqp" rel="nofollow">AMQP 1.0 is now a core protocol</a> that is always enabled.<br>
Its plugin is now a no-op that only exists to simplify upgrades.</p>
<p>GitHub issues: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/9022" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/9022/hovercard">#9022</a>, <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10662" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10662/hovercard">#10662</a></p>
</li>
<li>
<p>The AMQP 1.0 implementation is now significantly more efficient: its peak throughput is <a href="https://www.rabbitmq.com/blog/2024/08/21/amqp-benchmarks" rel="nofollow">more than double than that of 3.13.x</a><br>
on some workloads.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/9022" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/9022/hovercard">#9022</a></p>
</li>
<li>
<p>For AMQP 1.0, <a href="https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.0">resource alarms</a> only block inbound <code>TRANSFER</code> frames instead of blocking all traffic.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/9022" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/9022/hovercard">#9022</a></p>
</li>
<li>
<p>AMQP 1.0 clients now can manage topologies (queues, exchanges, bindings).</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10559" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10559/hovercard">#10559</a></p>
</li>
<li>
<p>AMQP 1.0 implementation now supports a new (v2) address format for referencing queues, exchanges, and so on.</p>
<p>GitHub issues: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11604" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11604/hovercard">#11604</a>, <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11618" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11618/hovercard">#11618</a></p>
</li>
<li>
<p>AMQP 1.0 implementation now supports consumer priorities.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11705" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11705/hovercard">#11705</a></p>
</li>
<li>
<p>Client-provided connection name will now be logged for AMQP 1.0 connections.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/issues/11958" data-hovercard-type="issue" data-hovercard-url="/rabbitmq/rabbitmq-server/issues/11958/hovercard">#11958</a></p>
</li>
</ul>
<h3>Streams</h3>
<h4>Enhancements</h4>
<ul>
<li>
<p>Stream filtering is now supported for AMQP 1.0 clients.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10098" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10098/hovercard">#10098</a></p>
</li>
</ul>
<h3>Prometheus Plugin</h3>
<h4>Enhancements</h4>
<ul>
<li>
<p><a href="https://www.rabbitmq.com/docs/memory-use" rel="nofollow">Detailed memory breakdown</a> metrics are now exposed via the Prometheus scraping endpoint.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/issues/11743" data-hovercard-type="issue" data-hovercard-url="/rabbitmq/rabbitmq-server/issues/11743/hovercard">#11743</a></p>
</li>
<li>
<p>New per-exchange and per-queue metrics.</p>
<p>Contributed by <a data-hovercard-type="user" data-hovercard-url="/users/LoisSotoLopez/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/LoisSotoLopez">@LoisSotoLopez</a>.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11559" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11559/hovercard">#11559</a></p>
</li>
<li>
<p>Shovel and Federation metrics are now available via two new plugins: <code>rabbitmq_shovel_prometheus</code> and <code>rabbitmq_federation_prometheus</code>.</p>
<p>Contributed by <a data-hovercard-type="user" data-hovercard-url="/users/SimonUnge/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/SimonUnge">@SimonUnge</a>.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11942" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11942/hovercard">#11942</a></p>
</li>
</ul>
<h3>Shovel Plugin</h3>
<h4>Enhancements</h4>
<ul>
<li>
<p>Shovels now can be configured to use pre-declared topologies. This is primarily useful in environments where<br>
schema definition comes from <a href="https://www.rabbitmq.com/docs/definitions" rel="nofollow">definitions</a>.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/issues/10501" data-hovercard-type="issue" data-hovercard-url="/rabbitmq/rabbitmq-server/issues/10501/hovercard">#10501</a></p>
</li>
</ul>
<h3>Local Random Exchange Plugin</h3>
<p>This is an initial release that includes <a href="https://www.rabbitmq.com/docs/next/local-random-exchange" rel="nofollow">Local Random Exchange</a>.</p>
<p>GitHub issues: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/8334" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/8334/hovercard">#8334</a>, <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10091" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10091/hovercard">#10091</a>.</p>
<h3>STOMP Plugin</h3>
<h4>Enhancements</h4>
<ul>
<li>
<p>STOMP now supports consumer priorities.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11947" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11947/hovercard">#11947</a></p>
</li>
</ul>
<h3>Dependency Changes</h3>
<ul>
<li>Ra was <a href="https://github.com/rabbitmq/ra/releases">upgraded to <code>2.14.0</code></a></li>
<li>Khepri was <a href="https://github.com/rabbitmq/khepri/releases">upgraded to <code>0.16.0</code></a></li>
<li>Cuttlefish was <a href="https://github.com/Kyorai/cuttlefish/releases">upgraded to <code>3.4.0</code></a></li>
</ul>
<h2>Source Code Archives</h2>
<p>To obtain source code of the entire distribution, please download the archive named <code>rabbitmq-server-4.0.0-rc.2.tar.xz</code><br>
instead of the source tarball produced by GitHub.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Twitter shut off API access; users volunteering their own data for an open API (115 pts)]]></title>
            <link>https://omarshehata.substack.com/p/twitter-shut-off-api-access-users</link>
            <guid>41581923</guid>
            <pubDate>Wed, 18 Sep 2024 16:23:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://omarshehata.substack.com/p/twitter-shut-off-api-access-users">https://omarshehata.substack.com/p/twitter-shut-off-api-access-users</a>, See on <a href="https://news.ycombinator.com/item?id=41581923">Hacker News</a></p>
Couldn't get https://omarshehata.substack.com/p/twitter-shut-off-api-access-users: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[CUNY paid Oracle $600M for its HR software (2013) (269 pts)]]></title>
            <link>http://pscbc.blogspot.com/2013/03/cuny-first-computer-system-to-aid.html</link>
            <guid>41581687</guid>
            <pubDate>Wed, 18 Sep 2024 16:08:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://pscbc.blogspot.com/2013/03/cuny-first-computer-system-to-aid.html">http://pscbc.blogspot.com/2013/03/cuny-first-computer-system-to-aid.html</a>, See on <a href="https://news.ycombinator.com/item?id=41581687">Hacker News</a></p>
Couldn't get http://pscbc.blogspot.com/2013/03/cuny-first-computer-system-to-aid.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Valkey 8.0.0 Is Out (108 pts)]]></title>
            <link>https://github.com/valkey-io/valkey/releases/tag/8.0.0</link>
            <guid>41581504</guid>
            <pubDate>Wed, 18 Sep 2024 15:58:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/valkey-io/valkey/releases/tag/8.0.0">https://github.com/valkey-io/valkey/releases/tag/8.0.0</a>, See on <a href="https://news.ycombinator.com/item?id=41581504">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pjax="true" data-test-selector="body-content" data-view-component="true"><p>Upgrade urgency LOW: This is the first release of Valkey 8.0, which<br>
includes stability and performance improvements over the second release<br>
candidate. This release is fully compatible with Redis OSS 7.2.4.</p>
<h2>Logging and Tooling Improvements</h2>
<ul>
<li>Added full client info to SHUTDOWN and CLUSTER FAILOVER logs for better traceability<br>
of requests. (<a data-error-text="Failed to load title" data-id="2452413935" data-permission-text="Title is private" data-url="https://github.com/valkey-io/valkey/issues/875" data-hovercard-type="pull_request" data-hovercard-url="/valkey-io/valkey/pull/875/hovercard" href="https://github.com/valkey-io/valkey/pull/875">#875</a>)</li>
</ul>
<h2>Bug fixes</h2>
<ul>
<li>Resolved issues in replicationSetPrimary where the primary node's IP/port updates were<br>
not correctly handled in the cluster gossip section. (<a data-error-text="Failed to load title" data-id="2493486852" data-permission-text="Title is private" data-url="https://github.com/valkey-io/valkey/issues/965" data-hovercard-type="pull_request" data-hovercard-url="/valkey-io/valkey/pull/965/hovercard" href="https://github.com/valkey-io/valkey/pull/965">#965</a>)</li>
<li>Fixed AOF base suffix during rewrites when modifying the aof-use-rdb-preamble setting,<br>
ensuring correct suffix caching to prevent inconsistencies. (<a data-error-text="Failed to load title" data-id="2459515722" data-permission-text="Title is private" data-url="https://github.com/valkey-io/valkey/issues/886" data-hovercard-type="pull_request" data-hovercard-url="/valkey-io/valkey/pull/886/hovercard" href="https://github.com/valkey-io/valkey/pull/886">#886</a>)</li>
<li>Addressed rare crashes in async IO threads with TLS by preventing concurrent read and<br>
write job overlap. (<a data-error-text="Failed to load title" data-id="2515856424" data-permission-text="Title is private" data-url="https://github.com/valkey-io/valkey/issues/1011" data-hovercard-type="pull_request" data-hovercard-url="/valkey-io/valkey/pull/1011/hovercard" href="https://github.com/valkey-io/valkey/pull/1011">#1011</a>)</li>
<li>Prevented AOF from being incorrectly disabled after loading RDB data, ensuring proper<br>
re-enabling of AOF. (<a data-error-text="Failed to load title" data-id="2512875224" data-permission-text="Title is private" data-url="https://github.com/valkey-io/valkey/issues/1001" data-hovercard-type="pull_request" data-hovercard-url="/valkey-io/valkey/pull/1001/hovercard" href="https://github.com/valkey-io/valkey/pull/1001">#1001</a>)</li>
<li>Triggered a save of the cluster configuration file before shutdown to prevent<br>
inconsistencies caused by unsaved node configuration changes. (<a data-error-text="Failed to load title" data-id="2426505535" data-permission-text="Title is private" data-url="https://github.com/valkey-io/valkey/issues/822" data-hovercard-type="pull_request" data-hovercard-url="/valkey-io/valkey/pull/822/hovercard" href="https://github.com/valkey-io/valkey/pull/822">#822</a>)</li>
<li>Fixed timing issue in CLUSTER SETSLOT to ensure replicas handle migration correctly<br>
when receiving the command before the gossip update. (<a data-error-text="Failed to load title" data-id="2501241170" data-permission-text="Title is private" data-url="https://github.com/valkey-io/valkey/issues/981" data-hovercard-type="pull_request" data-hovercard-url="/valkey-io/valkey/pull/981/hovercard" href="https://github.com/valkey-io/valkey/pull/981">#981</a>)</li>
</ul>
<h2>Performance</h2>
<ul>
<li>Optimized the handling of temporary set objects in SUNION and SDIFF commands, resulting<br>
in a 41% performance improvement for SUNION and 27% for SDIFF. (<a data-error-text="Failed to load title" data-id="2510141505" data-permission-text="Title is private" data-url="https://github.com/valkey-io/valkey/issues/996" data-hovercard-type="pull_request" data-hovercard-url="/valkey-io/valkey/pull/996/hovercard" href="https://github.com/valkey-io/valkey/pull/996">#996</a>)</li>
</ul>
<h2>Behavior Changes</h2>
<ul>
<li>Replicas now flush old data after checking RDB file is valid during disk-based replication,<br>
preventing partial data loss and ensuring a clean data load. (<a data-error-text="Failed to load title" data-id="2475276407" data-permission-text="Title is private" data-url="https://github.com/valkey-io/valkey/issues/926" data-hovercard-type="pull_request" data-hovercard-url="/valkey-io/valkey/pull/926/hovercard" href="https://github.com/valkey-io/valkey/pull/926">#926</a>)</li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Moshi: A speech-text foundation model for real time dialogue (236 pts)]]></title>
            <link>https://github.com/kyutai-labs/moshi</link>
            <guid>41581480</guid>
            <pubDate>Wed, 18 Sep 2024 15:56:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/kyutai-labs/moshi">https://github.com/kyutai-labs/moshi</a>, See on <a href="https://news.ycombinator.com/item?id=41581480">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Moshi: a speech-text foundation model for real time dialogue</h2><a id="user-content-moshi-a-speech-text-foundation-model-for-real-time-dialogue" aria-label="Permalink: Moshi: a speech-text foundation model for real time dialogue" href="#moshi-a-speech-text-foundation-model-for-real-time-dialogue"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/kyutai-labs/moshi/workflows/precommit/badge.svg"><img src="https://github.com/kyutai-labs/moshi/workflows/precommit/badge.svg" alt="precommit badge"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/kyutai-labs/moshi/workflows/Rust%20CI/badge.svg"><img src="https://github.com/kyutai-labs/moshi/workflows/Rust%20CI/badge.svg" alt="rust ci badge"></a></p>
<p dir="auto"><a href="https://kyutai.org/Moshi.pdf" rel="nofollow">[Read the paper]</a> <a href="https://moshi.chat/" rel="nofollow">[Demo]</a> <a href="https://huggingface.co/collections/kyutai/moshi-v01-release-66eaeaf3302bef6bd9ad7acd" rel="nofollow">[Hugging Face]</a></p>
<p dir="auto"><a href="https://kyutai.org/Moshi.pdf" rel="nofollow">Moshi</a> is a speech-text foundation model and <strong>full-duplex</strong> spoken dialogue framework.
It uses <a href="https://kyutai.org/Moshi.pdf" rel="nofollow">Mimi</a>, a state-of-the-art streaming neural audio codec. Mimi processes 24 kHz audio, down to a 12.5 Hz representation
with a bandwidth of 1.1 kbps, in a fully streaming manner (latency of 80ms, the frame size),
yet performs better than existing, non-streaming, codec like
<a href="https://github.com/ZhangXInFD/SpeechTokenizer">SpeechTokenizer</a> (50 Hz, 4kbps), or <a href="https://github.com/haoheliu/SemantiCodec-inference">SemantiCodec</a> (50 Hz, 1.3kbps).</p>
<p dir="auto">Moshi models <strong>two streams of audio</strong>: one corresponds to Moshi, and the other one to the user.
At inference, the stream from the user is taken from the audio input,
and the one for Moshi is sampled from the model's output. Along these two audio streams, Moshi predicts text tokens corresponding to its own speech, its <strong>inner monologue</strong>,
which greatly improves the quality of its generation. A small Depth Transformer models inter codebook dependencies for a given time step,
while a large, 7B parameter Temporal Transformer models the temporal dependencies. Moshi achieves a theoretical latency
of 160ms (80ms for the frame size of Mimi + 80ms of acoustic delay), with a practical overall latency as low as 200ms on an L4 GPU.</p>
<p dir="auto"><a href="https://moshi.chat/" rel="nofollow">Talk to Moshi</a> now on our live demo.</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/kyutai-labs/moshi/blob/main/moshi.png"><img src="https://github.com/kyutai-labs/moshi/raw/main/moshi.png" alt="Schema representing the structure of Moshi. Moshi models two streams of audio:
    one corresponds to Moshi, and the other one to the user. At inference, the audio stream of the user is taken from the audio input, and the audio stream for Moshi is sampled from the model's output. Along that, Moshi predicts text tokens corresponding to its own speech for improved accuracy. A small Depth Transformer models inter codebook dependencies for a given step." width="650px"></a></p>
<p dir="auto">Mimi builds on previous neural audio codecs such as <a href="https://arxiv.org/abs/2107.03312" rel="nofollow">SoundStream</a>
and <a href="https://github.com/facebookresearch/encodec">EnCodec</a>, adding a Transformer both in the encoder and decoder,
and adapting the strides to match an overall frame rate of 12.5 Hz. This allows Mimi to get closer to the
average frame rate of text tokens (~3-4 Hz), and limit the number of autoregressive steps in Moshi.
Similarly to SpeechTokenizer, Mimi uses a distillation loss so that the first codebook tokens match
a self-supervised representation from <a href="https://arxiv.org/abs/2110.13900" rel="nofollow">WavLM</a>, which allows modeling semantic and acoustic information with a single model. Interestingly, while Mimi is fully causal and streaming, it learns to match sufficiently well the non-causal
representation from WavLM, without introducing any delays. Finally, and similarly to <a href="https://arxiv.org/pdf/2210.14090" rel="nofollow">EBEN</a>,
Mimi uses <strong>only an adversarial training loss</strong>, along with feature matching, showing strong improvements in terms of
subjective quality despite its low bitrate.</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/kyutai-labs/moshi/blob/main/mimi.png"><img src="https://github.com/kyutai-labs/moshi/raw/main/mimi.png" alt="Schema representing the structure of Mimi, our proposed neural codec. Mimi contains a Transformer
in both its encoder and decoded, and achieves a frame rate closer to that of text tokens. This allows us to reduce
the number of auto-regressive steps taken by Moshi, thus reducing the latency of the model." width="800px"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Organisation of the repository</h2><a id="user-content-organisation-of-the-repository" aria-label="Permalink: Organisation of the repository" href="#organisation-of-the-repository"></a></p>
<p dir="auto">There are three separate versions of the moshi inference stack in this repo.</p>
<ul dir="auto">
<li>The Python version using PyTorch is in the <a href="https://github.com/kyutai-labs/moshi/blob/main/moshi"><code>moshi/</code></a> directory.</li>
<li>The Python version using MLX for M series Macs is in the <a href="https://github.com/kyutai-labs/moshi/blob/main/moshi_mlx"><code>moshi_mlx/</code></a> directory.</li>
<li>The Rust version used in production is in the <a href="https://github.com/kyutai-labs/moshi/blob/main/rust"><code>rust/</code></a> directory.
This contains in particular a Mimi implementation in Rust, with Python bindings available
as <code>rustymimi</code>.</li>
</ul>
<p dir="auto">Finally, the code for the live demo is provided in the <a href="https://github.com/kyutai-labs/moshi/blob/main/client"><code>client/</code></a> directory.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Models</h2><a id="user-content-models" aria-label="Permalink: Models" href="#models"></a></p>
<p dir="auto">We release three models:</p>
<ul dir="auto">
<li>our speech codec Mimi,</li>
<li>Moshi fine-tuned on a male synthetic voice (Moshiko),</li>
<li>Moshi fine-tuned on a female synthetic voice (Moshika).</li>
</ul>
<p dir="auto">Depending on the backend, the file format and quantization available will vary. Here is the list
of the HuggingFace repo with each model. Mimi is bundled in each of those, and always use the same checkpoint format.</p>
<ul dir="auto">
<li>Moshika for PyTorch (bf16): <a href="https://huggingface.co/kyutai/moshika-pytorch-bf16" rel="nofollow">kyutai/moshika-pytorch-bf16</a>.</li>
<li>Moshiko for PyTorch (bf16): <a href="https://huggingface.co/kyutai/moshiko-pytorch-bf16" rel="nofollow">kyutai/moshiko-pytorch-bf16</a>.</li>
<li>Moshika for MLX (int4, int8, bf16): <a href="https://huggingface.co/kyutai/moshika-mlx-q4" rel="nofollow">kyutai/moshika-mlx-q4</a>, <a href="https://huggingface.co/kyutai/moshika-mlx-q8" rel="nofollow">kyutai/moshika-mlx-q8</a>,  <a href="https://huggingface.co/kyutai/moshika-mlx-bf16" rel="nofollow">kyutai/moshika-mlx-bf16</a>.</li>
<li>Moshiko for MLX (int4, int8, bf16): <a href="https://huggingface.co/kyutai/moshiko-mlx-q4" rel="nofollow">kyutai/moshiko-mlx-q4</a>, <a href="https://huggingface.co/kyutai/moshiko-mlx-q8" rel="nofollow">kyutai/moshiko-mlx-q8</a>,  <a href="https://huggingface.co/kyutai/moshiko-mlx-bf16" rel="nofollow">kyutai/moshiko-mlx-bf16</a>.</li>
<li>Moshika for Rust/Candle (int8, bf16): <a href="https://huggingface.co/kyutai/moshika-candle-q8" rel="nofollow">kyutai/moshika-candle-q8</a>,  <a href="https://huggingface.co/kyutai/moshika-candle-bf16" rel="nofollow">kyutai/moshika-mlx-bf16</a>.</li>
<li>Moshiko for Rust/Candle (int8, bf16): <a href="https://huggingface.co/kyutai/moshiko-candle-q8" rel="nofollow">kyutai/moshiko-candle-q8</a>,  <a href="https://huggingface.co/kyutai/moshiko-candle-bf16" rel="nofollow">kyutai/moshiko-mlx-bf16</a>.</li>
</ul>
<p dir="auto">All models are released under the CC-BY 4.0 license.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<p dir="auto">You will need at least Python 3.10. For specific requirements, please check the individual backends
directories. You can install the PyTorch and MLX clients with the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install moshi      # moshi PyTorch, from PyPI
pip install moshi_mlx  # moshi MLX, from PyPI
# Or the bleeding edge versions for Moshi and Moshi-MLX.
pip install -e &quot;git+https://git@github.com/kyutai-labs/moshi.git#egg=moshi&amp;subdirectory=moshi&quot;
pip install -e &quot;git+https://git@github.com/kyutai-labs/moshi.git#egg=moshi_mlx&amp;subdirectory=moshi_mlx&quot;

pip install rustymimi  # mimi, rust implementation with Python bindings from PyPI"><pre>pip install moshi      <span><span>#</span> moshi PyTorch, from PyPI</span>
pip install moshi_mlx  <span><span>#</span> moshi MLX, from PyPI</span>
<span><span>#</span> Or the bleeding edge versions for Moshi and Moshi-MLX.</span>
pip install -e <span><span>"</span>git+https://git@github.com/kyutai-labs/moshi.git#egg=moshi&amp;subdirectory=moshi<span>"</span></span>
pip install -e <span><span>"</span>git+https://git@github.com/kyutai-labs/moshi.git#egg=moshi_mlx&amp;subdirectory=moshi_mlx<span>"</span></span>

pip install rustymimi  <span><span>#</span> mimi, rust implementation with Python bindings from PyPI</span></pre></div>
<p dir="auto">If you get an error when installing <code>moshi_mlx</code> or <code>rustymimi</code> (which <code>moshi_mlx</code> depends on),
you might need to install the <a href="https://rustup.rs/" rel="nofollow">Rust toolchain</a> to install <code>rustymimi</code> from sources.</p>
<p dir="auto">While we hope that the present codebase will work on Windows, we do not provide official support for it.
We have tested the MLX version on a MacBook Pro M3. At the moment, we do not support quantization
for the PyTorch version, so you will need a GPU with a significant amount of memory (24GB).</p>
<p dir="auto">For using the Rust backend, you will need a recent version of the <a href="https://rustup.rs/" rel="nofollow">Rust toolchain</a>.
To compile GPU support, you will also need the <a href="https://developer.nvidia.com/cuda-toolkit" rel="nofollow">CUDA</a> properly installed for your GPU, in particular with <code>nvcc</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<p dir="auto">If you wish to install from a clone of this repository, maybe to further develop Moshi, you can do the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# From the root of the clone of the repo
pip install -e 'moshi[dev]'
pip install -e 'moshi_mlx[dev]'
pre-commit install"><pre><span><span>#</span> From the root of the clone of the repo</span>
pip install -e <span><span>'</span>moshi[dev]<span>'</span></span>
pip install -e <span><span>'</span>moshi_mlx[dev]<span>'</span></span>
pre-commit install</pre></div>
<p dir="auto">If you wish to build locally <code>rustymimi</code> (assuming you have Rust properly installed):</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install maturin
maturin dev -r -m rust/mimi-pyo3/Cargo.toml"><pre>pip install maturin
maturin dev -r -m rust/mimi-pyo3/Cargo.toml</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Python (PyTorch)</h2><a id="user-content-python-pytorch" aria-label="Permalink: Python (PyTorch)" href="#python-pytorch"></a></p>
<p dir="auto">The PyTorch based API can be found in the <code>moshi</code> directory. It provides a streaming
version of the audio tokenizer (mimi) and the language model (moshi).</p>
<p dir="auto">In order to run in interactive mode, you need to start a server which will
run the model, you can then use either the web UI or a command line client.</p>
<p dir="auto">Start the server with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m moshi.server [--gradio-tunnel] [--hf-repo kyutai/moshika-pytorch-bf16]"><pre>python -m moshi.server [--gradio-tunnel] [--hf-repo kyutai/moshika-pytorch-bf16]</pre></div>
<p dir="auto">And then access the web UI on <a href="http://localhost:8998/" rel="nofollow">localhost:8998</a>. If your GPU is on a distant machine
with no direct access, <code>--gradio-tunnel</code> will create a tunnel with a URL accessible from anywhere.
Keep in mind that this tunnel goes through the US and can add significant latency (up to 500ms from Europe).
You can use <code>--gradio-tunnel-token</code> to set a fixed secret token and reuse the same address over time.
Alternatively, you might want to use SSH to redirect your connection.</p>
<p dir="auto">You can use <code>--hf-repo</code> to select a different pretrained model, by setting the proper Hugging Face repository.</p>
<p dir="auto">Accessing a server that is not localhost via http may cause issues with using
the microphone in the web UI (in some browsers this is only allowed using
https).</p>
<p dir="auto">A local client is also available, as</p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m moshi.client [--url URL_TO_GRADIO]"><pre>python -m moshi.client [--url URL_TO_GRADIO]</pre></div>
<p dir="auto">However note that, unlike the web browser, this client is barebone: It does not perform any echo cancellation,
nor does it try to compensate for a growing lag by skipping frames.</p>
<p dir="auto">For more information, in particular on how to use the API directly, please
checkout <a href="https://github.com/kyutai-labs/moshi/blob/main/moshi/README.md">moshi/README.md</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Python (MLX) for local inference on macOS</h2><a id="user-content-python-mlx-for-local-inference-on-macos" aria-label="Permalink: Python (MLX) for local inference on macOS" href="#python-mlx-for-local-inference-on-macos"></a></p>
<p dir="auto">Once you have installed <code>moshi_mlx</code>, you can run</p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m moshi_mlx.local -q 4   # weights quantized to 4 bits
python -m moshi_mlx.local -q 8   # weights quantized to 8 bits
# And using a different pretrained model:
python -m moshi_mlx.local -q 4 --hf-repo kyutai/moshika-mlx-q4
python -m moshi_mlx.local -q 8 --hf-repo kyutai/moshika-mlx-q8
# be careful to always match the `-q` and `--hf-repo` flag."><pre>python -m moshi_mlx.local -q 4   <span><span>#</span> weights quantized to 4 bits</span>
python -m moshi_mlx.local -q 8   <span><span>#</span> weights quantized to 8 bits</span>
<span><span>#</span> And using a different pretrained model:</span>
python -m moshi_mlx.local -q 4 --hf-repo kyutai/moshika-mlx-q4
python -m moshi_mlx.local -q 8 --hf-repo kyutai/moshika-mlx-q8
<span><span>#</span> be careful to always match the `-q` and `--hf-repo` flag.</span></pre></div>
<p dir="auto">This command line interface is also barebone. It does not perform any echo cancellation,
nor does it try to compensate for a growing lag by skipping frames.</p>
<p dir="auto">Alternatively you can run <code>python -m moshi_mlx.local_web</code> to use
the web UI, the connection is via http and will be at <a href="http://localhost:8998/" rel="nofollow">localhost:8998</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Rust</h2><a id="user-content-rust" aria-label="Permalink: Rust" href="#rust"></a></p>
<p dir="auto">In order to run the Rust inference server, use the following command from within
the <code>rust</code> directory:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo run --features cuda --bin moshi-backend -r -- --config moshi-backend/config.json standalone"><pre>cargo run --features cuda --bin moshi-backend -r -- --config moshi-backend/config.json standalone</pre></div>
<p dir="auto">When using macOS, you can replace <code>--features cuda</code> with <code>--features metal</code>.</p>
<p dir="auto">Alternatively you can use <code>config-q8.json</code> rather than <code>config.json</code> to use the
quantized q8 model. You can select a different pretrained model, e.g. Moshika,
by changing the <code>"hf_repo"</code> key in either file.</p>
<p dir="auto">Once the server has printed 'standalone worker listening', you can use the web
UI. By default the Rust server uses https so it will be at
<a href="https://localhost:8998/" rel="nofollow">localhost:8998</a>.</p>
<p dir="auto">You will get warnings about the site being unsafe. When using chrome you
can bypass these by selecting "Details" or "Advanced", then "Visit this unsafe
site" or "Proceed to localhost (unsafe)".</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Clients</h2><a id="user-content-clients" aria-label="Permalink: Clients" href="#clients"></a></p>
<p dir="auto">We recommend using the web UI as it provides additional echo cancellation that helps
the overall model quality. Note that most command will directly serve this UI
in the provided URL, and there is in general nothing more to do.</p>
<p dir="auto">Alternatively, we provide command line interfaces
for the Rust and Python versions, the protocol is the same as with the web UI so
there is nothing to change on the server side.</p>
<p dir="auto">For reference, here is the list of clients for Moshi.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Rust Command Line</h3><a id="user-content-rust-command-line" aria-label="Permalink: Rust Command Line" href="#rust-command-line"></a></p>
<p dir="auto">From within the <code>rust</code> directory, run the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo run --bin moshi-cli -r -- tui --host localhost"><pre>cargo run --bin moshi-cli -r -- tui --host localhost</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python with PyTorch</h3><a id="user-content-python-with-pytorch" aria-label="Permalink: Python with PyTorch" href="#python-with-pytorch"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">WebUI</h3><a id="user-content-webui" aria-label="Permalink: WebUI" href="#webui"></a></p>
<p dir="auto">The web UI can be built from this repo via the
following steps (these will require <code>npm</code> being installed).</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd client
npm install
npm run build"><pre><span>cd</span> client
npm install
npm run build</pre></div>
<p dir="auto">The web UI can then be found in the <code>client/dist</code> directory.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">The present code is provided under the MIT license for the Python parts, and Apache license for the Rust backend.
The web client code is provided under the MIT license.
Note that parts of this code is based on <a href="https://github.com/facebookresearch/audiocraft">AudioCraft</a>, released under
the MIT license.</p>
<p dir="auto">The weights for the models are released under the CC-BY 4.0 license.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<p dir="auto">If you use either Mimi or Moshi, please cite the following paper,</p>
<div data-snippet-clipboard-copy-content="@techreport{kyutai2024moshi,
    author = {Alexandre D\'efossez and Laurent Mazar\'e and Manu Orsini and Am\'elie Royer and
			  Patrick P\'erez and Herv\'e J\'egou and Edouard Grave and Neil Zeghidour},
    title = {Moshi: a speech-text foundation model for real-time dialogue},
    institution = {Kyutai},
    year={2024},
    month={September},
    url={http://kyutai.org/Moshi.pdf},
}"><pre><code>@techreport{kyutai2024moshi,
    author = {Alexandre D\'efossez and Laurent Mazar\'e and Manu Orsini and Am\'elie Royer and
			  Patrick P\'erez and Herv\'e J\'egou and Edouard Grave and Neil Zeghidour},
    title = {Moshi: a speech-text foundation model for real-time dialogue},
    institution = {Kyutai},
    year={2024},
    month={September},
    url={http://kyutai.org/Moshi.pdf},
}
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hezbollah hand-held radios explode, killing three, one day after pager blasts (183 pts)]]></title>
            <link>https://www.reuters.com/world/hezbollah-pager-explosions-live-2024-09-17/</link>
            <guid>41580853</guid>
            <pubDate>Wed, 18 Sep 2024 15:19:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/hezbollah-pager-explosions-live-2024-09-17/">https://www.reuters.com/world/hezbollah-pager-explosions-live-2024-09-17/</a>, See on <a href="https://news.ycombinator.com/item?id=41580853">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/hezbollah-pager-explosions-live-2024-09-17/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[0day Contest for End-of-Life Devices Announced (237 pts)]]></title>
            <link>https://www.districtcon.org/junkyard</link>
            <guid>41580502</guid>
            <pubDate>Wed, 18 Sep 2024 14:55:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.districtcon.org/junkyard">https://www.districtcon.org/junkyard</a>, See on <a href="https://news.ycombinator.com/item?id=41580502">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-blend-mode="NORMAL" data-block-type="2" data-blur="{&quot;enabled&quot;:true,&quot;filterType&quot;:&quot;backdrop&quot;,&quot;blurRadius&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:15.0}}" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-29c9efa8396ec1fdaff4">
  <h4>Give Us your Best (Or Worst) Zero-day VulnS.</h4><blockquote><pre><code>The Junkyard is a platform to showcase novel security research and support hobby and career development for security researchers.

We want you to bring your most impactful, creative, or most meme-worthy bugs in end-of-life (EOL) products, and demonstrate them live on stage. 

Winners get 💰 prizes 💰 to further future vulnerability research. First 20 submissions accepted will get additional swag!</code></pre></blockquote><h4>What’s In SCOPE? </h4><blockquote><pre><code>Any product (software or hardware) publicly listed by the vendor as EOL-ed at least one day before submission.
</code></pre><pre><code>In keeping with the conference ethos, we also require that:</code></pre><pre><code>- You commit as the researcher to responsible disclosure of the vulnerability (60-90 day disclosure windows with vendor);&nbsp;</code></pre><pre><code>- You conducted your research in accordance with US law and ethical practices; and</code></pre><pre><code>- You are not under any restrictions or sanctions from the US. </code></pre></blockquote><h4>PRIZES</h4><blockquote><pre><code>Prizes will depend on final sponsorship support, but are expected to range from <span data-text-attribute-id="91e7ca3d-2f2e-4329-86c9-dfc08b4b08f7">$100 to $5,000 USD</span>. These may change in cases of exceptional brilliance or lack thereof. All prizes and acceptance of results to the event are at DistrictCon’s sole discretion.
</code></pre><pre><code><span data-text-attribute-id="73c07bd6-ef0e-43f0-8094-b6baddc50c8d">Prizes will be awarded in the following categories to the top 2 scorers</span> (winner and runner up), so plan accordingly:</code></pre><p>❗ Most Impactful System ❗</p><p>🤡 Best Meme Target 🤡 </p><p>😈 Most Innovative Exploitation Technique 😈</p></blockquote><h4>WHAT SHOULD I EXPECT / How does the contest work?</h4><blockquote><pre><code>1️⃣ <span data-text-attribute-id="8a35ceb8-b046-4c89-b8c0-e1795c9edd31">Submit Your Target to DistrictCon
</span>
- Fill out the form on this page, tell us what target you're exploiting, and how much help you'll need with disclosure. Get proof that the target is EOL.

2️⃣ <span data-text-attribute-id="c3955729-e12f-41b2-bb99-e3384ea686eb">Disclose the Bug to the Vendor 
</span>
- We can help if needed!
 
3️⃣ <span data-text-attribute-id="d76b7490-2b52-4191-bc09-91b5d63d09e5">Create a Cover Name, 5-10 Min Talk + Demo</span>

- Attendees won’t know what your target will be until you reveal it on stage! The cover name is for the agenda.

4️⃣ <span data-text-attribute-id="a82afb1f-af00-494d-8e45-378c3b1ba9f0">Give us your Target Ahead of Time to Prep for Demo</span>

- We'll restore the target to a default configuration (in consultation with you) and prepare to have it on-stage for you to demonstrate against. If this doesn’t work for you, the item is big, etc - we’ll work with you for a video option, or try and source the device locally. 

5️⃣ <span data-text-attribute-id="f3ca0378-ac3b-4e4d-9779-3f4c963cd82a">Compete and Win!</span> 💰

When you come up on stage, you’ll share:</code></pre><pre><code>- Who you are, as much as you want</code></pre><pre><code>- The target, and why it matters</code></pre><pre><code>- Demonstrate the bug, explain how it works and the impact.

- Nothing will be live-streamed or recorded without your permission.</code></pre></blockquote><h4>Frequently asked Questions</h4><blockquote><pre><code><span data-text-attribute-id="ee601f96-5148-4251-b275-aa13197193f7">1) Is an EOL software or product in scope, even if there are components within it that are not EOL?
</span>
A: Yes, but there are caveats: the spirit of this event is to help identify and notify vendors of vulnerabilities in EOL software or products, and all submissions should be in this spirit.
If an EOL item has components that are not EOL within it, that’s fine. However, non-EOL components should not be the focus of the vulnerability or chain - we are not looking for exploits in current systems. If you have questions, please reach out via the submission process and we will work with you to ensure the submission is appropriate for the event.</code></pre><pre><code>
<span data-text-attribute-id="a64773bc-7087-4f7b-8765-1464461c1fb0">2) What should my Junkyard pitch at DistrictCon look like? </span>

For the maximum audience enjoyment and clarity of your awesome work, we prefer you presenting a live demo against the EOL system. We know this won't always be practical, so we will work with you during submission review to find the right way. As part of your demonstrated chain, the judges are (among other things) looking for proof of control and execution. 

Given the broad swath of valid targets, we know this may differ in what that means, but two "traditional" examples are to pop a shell and confirm root privileges, or demonstrate arbitrary code execution.</code></pre><pre><code>
<span data-text-attribute-id="4f60b934-ec85-40cd-99e1-da056f2b6634">3) What is EOL for Open Source, specifically with an archived repository? </span>

If the software you’re attempting to exploit is an archived repository, first ask if (a) the software moved to a new home and (b) is the archived repo a fork and the substantially similar project is still active? 

If the maintainer confirms they are not maintaining the given version or product, you should be good to go. Otherwise feel free to reach out to the DistrictCon Junkyard Team via the submission process, or via outreach@districtcon.org with additional questions.</code></pre></blockquote><h4>I have More questions.</h4><blockquote><pre><code>Additional details such as the responsible disclosure timelines and any assistance from the conference will be published when available. Please contact outreach@districtcon.org for more details.</code></pre><pre><code>In the case of similar bugs, our team will work privately with the submitters to deduplicate appropriately. </code></pre></blockquote>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A high-performance, zero-overhead, extensible Python compiler using LLVM (155 pts)]]></title>
            <link>https://github.com/exaloop/codon</link>
            <guid>41580326</guid>
            <pubDate>Wed, 18 Sep 2024 14:44:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/exaloop/codon">https://github.com/exaloop/codon</a>, See on <a href="https://news.ycombinator.com/item?id=41580326">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
 <a target="_blank" rel="noopener noreferrer" href="https://github.com/exaloop/codon/blob/develop/docs/img/codon.png?raw=true"><img src="https://github.com/exaloop/codon/raw/develop/docs/img/codon.png?raw=true" width="600" alt="Codon"></a>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">
  <a href="https://docs.exaloop.io/codon" rel="nofollow"><b>Docs</b></a>
  &nbsp;·&nbsp;
  <a href="https://docs.exaloop.io/codon/general/faq" rel="nofollow"><b>FAQ</b></a>
  &nbsp;·&nbsp;
  <a href="https://blog.exaloop.io/" rel="nofollow"><b>Blog</b></a>
  &nbsp;·&nbsp;
  <a href="https://join.slack.com/t/exaloop/shared_invite/zt-1jusa4kc0-T3rRWrrHDk_iZ1dMS8s0JQ" rel="nofollow">Chat</a>
  &nbsp;·&nbsp;
  <a href="https://docs.exaloop.io/codon/general/roadmap" rel="nofollow">Roadmap</a>
  &nbsp;·&nbsp;
  <a href="https://exaloop.io/benchmarks" rel="nofollow">Benchmarks</a>
</h3><a id="user-content---docs----faq----blog----chat----roadmap----benchmarks" aria-label="Permalink: Docs
  &nbsp;·&nbsp;
  FAQ
  &nbsp;·&nbsp;
  Blog
  &nbsp;·&nbsp;
  Chat
  &nbsp;·&nbsp;
  Roadmap
  &nbsp;·&nbsp;
  Benchmarks" href="#--docs----faq----blog----chat----roadmap----benchmarks"></a></p>
<a href="https://github.com/exaloop/codon/actions/workflows/ci.yml">
  <img src="https://github.com/exaloop/codon/actions/workflows/ci.yml/badge.svg" alt="Build Status">
</a>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is Codon?</h2><a id="user-content-what-is-codon" aria-label="Permalink: What is Codon?" href="#what-is-codon"></a></p>
<p dir="auto">Codon is a high-performance Python implementation that compiles to native machine code without
any runtime overhead. Typical speedups over vanilla Python are on the order of 10-100x or more, on
a single thread. Codon's performance is typically on par with (and sometimes better than) that of
C/C++. Unlike Python, Codon supports native multithreading, which can lead to speedups many times
higher still.</p>
<p dir="auto"><em>Think of Codon as Python reimagined for static, ahead-of-time compilation, built from the ground
up with best possible performance in mind.</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Goals</h3><a id="user-content-goals" aria-label="Permalink: Goals" href="#goals"></a></p>
<ul dir="auto">
<li>💡 <strong>No learning curve:</strong> Be as close to CPython as possible in terms of syntax, semantics and libraries</li>
<li>🚀 <strong>Top-notch performance:</strong> At <em>least</em> on par with low-level languages like C, C++ or Rust</li>
<li>💻 <strong>Hardware support:</strong> Full, seamless support for multicore programming, multithreading (no GIL!), GPU and more</li>
<li>📈 <strong>Optimizations:</strong> Comprehensive optimization framework that can target high-level Python constructs
and libraries</li>
<li>🔋 <strong>Interoperability:</strong> Full interoperability with Python's ecosystem of packages and libraries</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Non-goals</h3><a id="user-content-non-goals" aria-label="Permalink: Non-goals" href="#non-goals"></a></p>
<ul dir="auto">
<li>
<p dir="auto">❌ <em>Drop-in replacement for CPython:</em> Codon is not a drop-in replacement for CPython. There are some
aspects of Python that are not suitable for static compilation — we don't support these in Codon.
There are ways to use Codon in larger Python codebases via its <a href="https://docs.exaloop.io/codon/interoperability/decorator" rel="nofollow">JIT decorator</a>
or <a href="https://docs.exaloop.io/codon/interoperability/pyext" rel="nofollow">Python extension backend</a>. Codon also supports
calling any Python module via its <a href="https://docs.exaloop.io/codon/interoperability/python" rel="nofollow">Python interoperability</a>.
See also <a href="https://docs.exaloop.io/codon/general/differences" rel="nofollow"><em>"Differences with Python"</em></a> in the docs.</p>
</li>
<li>
<p dir="auto">❌ <em>New syntax and language constructs:</em> We try to avoid adding new syntax, keywords or other language
features as much as possible. While Codon does add some new syntax in a couple places (e.g. to express
parallelism), we try to make it as familiar and intuitive as possible.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto">Pre-built binaries for Linux (x86_64) and macOS (x86_64 and arm64) are available alongside <a href="https://github.com/exaloop/codon/releases">each release</a>.
Download and install with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="/bin/bash -c &quot;$(curl -fsSL https://exaloop.io/install.sh)&quot;"><pre>/bin/bash -c <span><span>"</span><span><span>$(</span>curl -fsSL https://exaloop.io/install.sh<span>)</span></span><span>"</span></span></pre></div>
<p dir="auto">Or you can <a href="https://docs.exaloop.io/codon/advanced/build" rel="nofollow">build from source</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">Codon is a Python-compatible language, and many Python programs will work with few if any modifications:</p>
<div dir="auto" data-snippet-clipboard-copy-content="def fib(n):
    a, b = 0, 1
    while a < n:
        print(a, end=' ')
        a, b = b, a+b
    print()
fib(1000)"><pre><span>def</span> <span>fib</span>(<span>n</span>):
    <span>a</span>, <span>b</span> <span>=</span> <span>0</span>, <span>1</span>
    <span>while</span> <span>a</span> <span>&lt;</span> <span>n</span>:
        <span>print</span>(<span>a</span>, <span>end</span><span>=</span><span>' '</span>)
        <span>a</span>, <span>b</span> <span>=</span> <span>b</span>, <span>a</span><span>+</span><span>b</span>
    <span>print</span>()
<span>fib</span>(<span>1000</span>)</pre></div>
<p dir="auto">The <code>codon</code> compiler has a number of options and modes:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# compile and run the program
codon run fib.py
# 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987

# compile and run the program with optimizations enabled
codon run -release fib.py
# 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987

# compile to executable with optimizations enabled
codon build -release -exe fib.py
./fib
# 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987

# compile to LLVM IR file with optimizations enabled
codon build -release -llvm fib.py
# outputs file fib.ll"><pre><span><span>#</span> compile and run the program</span>
codon run fib.py
<span><span>#</span> 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987</span>

<span><span>#</span> compile and run the program with optimizations enabled</span>
codon run -release fib.py
<span><span>#</span> 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987</span>

<span><span>#</span> compile to executable with optimizations enabled</span>
codon build -release -exe fib.py
./fib
<span><span>#</span> 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987</span>

<span><span>#</span> compile to LLVM IR file with optimizations enabled</span>
codon build -release -llvm fib.py
<span><span>#</span> outputs file fib.ll</span></pre></div>
<p dir="auto">See <a href="https://docs.exaloop.io/codon/general/intro" rel="nofollow">the docs</a> for more options and examples.</p>
<p dir="auto">You can import and use any Python package from Codon. For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from python import matplotlib.pyplot as plt
data = [x**2 for x in range(10)]
plt.plot(data)
plt.show()"><pre><span>from</span> <span>python</span> <span>import</span> <span>matplotlib</span>.<span>pyplot</span> <span>as</span> <span>plt</span>
<span>data</span> <span>=</span> [<span>x</span><span>**</span><span>2</span> <span>for</span> <span>x</span> <span>in</span> <span>range</span>(<span>10</span>)]
<span>plt</span>.<span>plot</span>(<span>data</span>)
<span>plt</span>.<span>show</span>()</pre></div>
<p dir="auto">(Just remember to set the <code>CODON_PYTHON</code> environment variable to the CPython shared library,
as explained in the <a href="https://docs.exaloop.io/codon/interoperability/python" rel="nofollow">the docs</a>.)</p>
<p dir="auto">This prime counting example showcases Codon's <a href="https://www.openmp.org/" rel="nofollow">OpenMP</a> support, enabled
with the addition of one line. The <code>@par</code> annotation tells the compiler to parallelize the
following <code>for</code>-loop, in this case using a dynamic schedule, chunk size of 100, and 16 threads.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from sys import argv

def is_prime(n):
    factors = 0
    for i in range(2, n):
        if n % i == 0:
            factors += 1
    return factors == 0

limit = int(argv[1])
total = 0

@par(schedule='dynamic', chunk_size=100, num_threads=16)
for i in range(2, limit):
    if is_prime(i):
        total += 1

print(total)"><pre><span>from</span> <span>sys</span> <span>import</span> <span>argv</span>

<span>def</span> <span>is_prime</span>(<span>n</span>):
    <span>factors</span> <span>=</span> <span>0</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span>(<span>2</span>, <span>n</span>):
        <span>if</span> <span>n</span> <span>%</span> <span>i</span> <span>==</span> <span>0</span>:
            <span>factors</span> <span>+=</span> <span>1</span>
    <span>return</span> <span>factors</span> <span>==</span> <span>0</span>

<span>limit</span> <span>=</span> <span>int</span>(<span>argv</span>[<span>1</span>])
<span>total</span> <span>=</span> <span>0</span>

<span>@<span>par</span>(<span>schedule</span><span>=</span><span>'dynamic'</span>, <span>chunk_size</span><span>=</span><span>100</span>, <span>num_threads</span><span>=</span><span>16</span>)</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span>(<span>2</span>, <span>limit</span>):
    <span>if</span> <span>is_prime</span>(<span>i</span>):
        <span>total</span> <span>+=</span> <span>1</span>

<span>print</span>(<span>total</span>)</pre></div>
<p dir="auto">Codon supports writing and executing GPU kernels. Here's an example that computes the
<a href="https://en.wikipedia.org/wiki/Mandelbrot_set" rel="nofollow">Mandelbrot set</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import gpu

MAX    = 1000  # maximum Mandelbrot iterations
N      = 4096  # width and height of image
pixels = [0 for _ in range(N * N)]

def scale(x, a, b):
    return a + (x/N)*(b - a)

@gpu.kernel
def mandelbrot(pixels):
    idx = (gpu.block.x * gpu.block.dim.x) + gpu.thread.x
    i, j = divmod(idx, N)
    c = complex(scale(j, -2.00, 0.47), scale(i, -1.12, 1.12))
    z = 0j
    iteration = 0

    while abs(z) <= 2 and iteration < MAX:
        z = z**2 + c
        iteration += 1

    pixels[idx] = int(255 * iteration/MAX)

mandelbrot(pixels, grid=(N*N)//1024, block=1024)"><pre><span>import</span> <span>gpu</span>

<span>MAX</span>    <span>=</span> <span>1000</span>  <span># maximum Mandelbrot iterations</span>
<span>N</span>      <span>=</span> <span>4096</span>  <span># width and height of image</span>
<span>pixels</span> <span>=</span> [<span>0</span> <span>for</span> <span>_</span> <span>in</span> <span>range</span>(<span>N</span> <span>*</span> <span>N</span>)]

<span>def</span> <span>scale</span>(<span>x</span>, <span>a</span>, <span>b</span>):
    <span>return</span> <span>a</span> <span>+</span> (<span>x</span><span>/</span><span>N</span>)<span>*</span>(<span>b</span> <span>-</span> <span>a</span>)

<span>@<span>gpu</span>.<span>kernel</span></span>
<span>def</span> <span>mandelbrot</span>(<span>pixels</span>):
    <span>idx</span> <span>=</span> (<span>gpu</span>.<span>block</span>.<span>x</span> <span>*</span> <span>gpu</span>.<span>block</span>.<span>dim</span>.<span>x</span>) <span>+</span> <span>gpu</span>.<span>thread</span>.<span>x</span>
    <span>i</span>, <span>j</span> <span>=</span> <span>divmod</span>(<span>idx</span>, <span>N</span>)
    <span>c</span> <span>=</span> <span>complex</span>(<span>scale</span>(<span>j</span>, <span>-</span><span>2.00</span>, <span>0.47</span>), <span>scale</span>(<span>i</span>, <span>-</span><span>1.12</span>, <span>1.12</span>))
    <span>z</span> <span>=</span> <span>0j</span>
    <span>iteration</span> <span>=</span> <span>0</span>

    <span>while</span> <span>abs</span>(<span>z</span>) <span>&lt;=</span> <span>2</span> <span>and</span> <span>iteration</span> <span>&lt;</span> <span>MAX</span>:
        <span>z</span> <span>=</span> <span>z</span><span>**</span><span>2</span> <span>+</span> <span>c</span>
        <span>iteration</span> <span>+=</span> <span>1</span>

    <span>pixels</span>[<span>idx</span>] <span>=</span> <span>int</span>(<span>255</span> <span>*</span> <span>iteration</span><span>/</span><span>MAX</span>)

<span>mandelbrot</span>(<span>pixels</span>, <span>grid</span><span>=</span>(<span>N</span><span>*</span><span>N</span>)<span>//</span><span>1024</span>, <span>block</span><span>=</span><span>1024</span>)</pre></div>
<p dir="auto">GPU programming can also be done using the <code>@par</code> syntax with <code>@par(gpu=True)</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">Please see <a href="https://docs.exaloop.io/codon" rel="nofollow">docs.exaloop.io</a> for in-depth documentation.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hezbollah hand-held radios detonate across Lebanon, sources say (237 pts)]]></title>
            <link>https://www.reuters.com/world/middle-east/israel-planted-explosives-hezbollahs-taiwan-made-pagers-say-sources-2024-09-18/</link>
            <guid>41580205</guid>
            <pubDate>Wed, 18 Sep 2024 14:34:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/middle-east/israel-planted-explosives-hezbollahs-taiwan-made-pagers-say-sources-2024-09-18/">https://www.reuters.com/world/middle-east/israel-planted-explosives-hezbollahs-taiwan-made-pagers-say-sources-2024-09-18/</a>, See on <a href="https://news.ycombinator.com/item?id=41580205">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/middle-east/israel-planted-explosives-hezbollahs-taiwan-made-pagers-say-sources-2024-09-18/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Bento: Jupyter Notebooks at Meta (164 pts)]]></title>
            <link>https://engineering.fb.com/2024/09/17/data-infrastructure/inside-bento-jupyter-notebooks-at-meta/</link>
            <guid>41580166</guid>
            <pubDate>Wed, 18 Sep 2024 14:30:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://engineering.fb.com/2024/09/17/data-infrastructure/inside-bento-jupyter-notebooks-at-meta/">https://engineering.fb.com/2024/09/17/data-infrastructure/inside-bento-jupyter-notebooks-at-meta/</a>, See on <a href="https://news.ycombinator.com/item?id=41580166">Hacker News</a></p>
Couldn't get https://engineering.fb.com/2024/09/17/data-infrastructure/inside-bento-jupyter-notebooks-at-meta/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[AI tool cuts unexpected deaths in hospital by 26%, Canadian study finds (197 pts)]]></title>
            <link>https://www.cbc.ca/news/health/ai-health-care-1.7322671</link>
            <guid>41579355</guid>
            <pubDate>Wed, 18 Sep 2024 13:17:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cbc.ca/news/health/ai-health-care-1.7322671">https://www.cbc.ca/news/health/ai-health-care-1.7322671</a>, See on <a href="https://news.ycombinator.com/item?id=41579355">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr">Inside a bustling unit at St. Michael's Hospital in downtown Toronto, one of Shirley Bell's patients was suffering from a cat&nbsp;bite and a fever, but otherwise appeared fine — until an alert from an AI-based early warning system showed he was sicker than he seemed.</p><p dir="ltr">While the nursing team usually checked blood work around noon, the technology flagged incoming results several hours beforehand. That warning showed&nbsp;the patient's white blood cell count was "really, really high,"&nbsp;recalled Bell, the clinical nurse educator for the hospital's general medicine program.</p><p dir="ltr">The cause turned out to be cellulitis, a bacterial skin infection. Without prompt treatment, it can lead to extensive tissue damage, amputations&nbsp;and even death. Bell said the patient was given antibiotics quickly to avoid those worst-case scenarios, in large part thanks to the team's in-house AI technology, dubbed Chartwatch.</p><p dir="ltr">"There's lots and lots of other scenarios where patients' conditions are flagged earlier, and the nurse is alerted earlier, and interventions are put in earlier," she said. "It's not replacing the nurse at the bedside; it's actually enhancing your nursing care."</p><p dir="ltr">A year-and-a-half-long study on Chartwatch, <a href="https://www.cmaj.ca/lookup/doi/10.1503/cmaj.240132"><u>published Monday</u></a> in the Canadian Medical Association Journal, found that use of the AI system led to a striking 26 per cent drop in the number of unexpected deaths among hospitalized patients.</p><p dir="ltr">"We're glad to see that we're saving lives," said co-author Dr. Muhammad Mamdani, vice-president of data science and advanced analytics at Unity Health Toronto and director of the University of Toronto Temerty Faculty of Medicine Centre for AI Research and Education in Medicine.&nbsp;</p><h2 dir="ltr">'A promising sign'</h2><p dir="ltr">The research team looked at more than 13,000 admissions to St. Michael's general internal medicine ward — an 84-bed unit caring for some of the hospital's most complex patients — to compare the impact of the tool among that patient population to thousands of admissions into other subspecialty units.&nbsp;</p><div dir="ltr"><ul><li><a href="https://www.cbc.ca/news/canada/sudbury/waive-the-wait-paperwork-doctors-1.7176165" text="This northern Ontario company is using AI to reduce paperwork at doctors' offices" flag="" data-contentid=""><span>This northern Ontario company is using AI to reduce paperwork at doctors' offices</span></a></li></ul></div><p dir="ltr">"At the same time period in the other units in our hospital that were not using Chartwatch, we did not see a change in these unexpected deaths," said lead author Dr. Amol Verma, a clinician-scientist at St. Michael's, one of three Unity Health Toronto hospital network sites, and Temerty professor of AI research and education in medicine at University of Toronto.&nbsp;</p><p dir="ltr">"That was a promising sign."</p><div dir="ltr"><ul><li><a href="https://www.cbc.ca/news/canada/prince-edward-island/pei-artificial-intelligence-1.6994961" text="AI will be critical for the future of rural health care in Canada, experts say" flag="" data-contentid=""><span>AI will be critical for the future of rural health care in Canada, experts say</span></a></li></ul></div><p dir="ltr">The Unity Health AI team started developing Chartwatch back in 2017, based on suggestions from staff that predicting deaths or serious illness could be key areas where machine learning could make a positive difference.</p><p dir="ltr">The technology underwent several years of rigorous development and testing before it was deployed in October&nbsp;2020, Verma said.</p><div dir="ltr"><figure><p><img loading="lazy" alt="Dr. Amol Verma, a clinician-scientist at St. Michael’s Hospital who helped lead the creation and testing of CHARTwatch, stands at a computer." srcset="https://i.cbc.ca/1.7322732.1726245155!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/dr-amol-verma.jpg 300w,https://i.cbc.ca/1.7322732.1726245155!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/dr-amol-verma.jpg 460w,https://i.cbc.ca/1.7322732.1726245155!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/dr-amol-verma.jpg 620w,https://i.cbc.ca/1.7322732.1726245155!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-amol-verma.jpg 780w,https://i.cbc.ca/1.7322732.1726245155!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/dr-amol-verma.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.7322732.1726245155!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-amol-verma.jpg" data-cy="image-img"></p><figcaption>Verma simulates the tool's use inside the downtown Toronto health-care facility.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure></div><p dir="ltr">"Chartwatch measures about 100 inputs from [a patient's] medical record that are currently routinely gathered in the process of delivering care," he explained. "So a patient's vital signs, their heart rate, their blood pressure … all of the lab test results that are done every day."</p><p dir="ltr">Working in the background alongside clinical teams, the tool monitors any changes in someone's medical record "and makes a dynamic prediction every hour about whether that patient is likely to deteriorate in the future," Verma told CBC News.</p><div dir="ltr"><ul><li><a href="https://www.cbc.ca/news/health/mammography-artificial-intelligence-scans-1.6954753" text="AI shows major promise in breast cancer detection, new studies suggest" flag="" data-contentid=""><span>AI shows major promise in breast cancer detection, new studies suggest</span></a></li></ul></div><p dir="ltr">That could mean someone getting sicker, or requiring intensive care, or even being on the brink of death, giving doctors and nurses a chance to intervene.&nbsp;</p><p dir="ltr">In some cases, those interventions involve escalating someone's level of treatment to save their life, or providing early palliative care in situations where patients can't be rescued.&nbsp;</p><p dir="ltr">In either case, the researchers said, Chartwatch appears to complement clinicians' own judgment and leads to better outcomes for fragile patients, helping to avoid more sudden and potentially preventable deaths.</p><h2 dir="ltr">AI on the rise in health care</h2><p>Beyond its uses in medicine, artificial intelligence is getting plenty of buzz — and blowback — in recent years.&nbsp;</p><p dir="ltr">From controversy around the use of machine learning software to crank out academic essays, to concerns over AI's capacity to create realistic audio and video content mimicking real celebrities, politicians, or average citizens, there have been plenty of reasons to be cautious about this emerging technology.</p><div dir="ltr"><ul><li><a href="https://www.cbc.ca/radio/thecurrent/canadian-researchers-use-ai-to-find-a-possible-treatment-for-bacteria-superbug-1.6859534" text="Canadian researchers use AI to find a possible treatment for bacteria superbug" flag="" data-contentid=""><span>Canadian researchers use AI to find a possible treatment for bacteria superbug</span></a></li></ul></div><p dir="ltr">Verma himself said he's long been wary. But in health care, he stressed, these tools have immense potential to combat the staff shortages plaguing Canada's health-care system by supplementing traditional bedside care.</p><p><em><strong>WATCH | How AI could revolutionize health care:<span><span><div title="How AI could change the future of our health care" role="button" tabindex="0" data-cy="player-placeholder-ui-container"><div><p><img src="https://i.cbc.ca/ais/1.5110182,1717208994588/full/max/0/default.jpg?im=Crop%2Crect%3D%280%2C0%2C1920%2C1080%29%3BResize%3D%28620%29" srcset="" alt="" loading="lazy"></p></div><div><h3>How AI could change the future of our health care</h3></div></div><span>Often called the future of health care, artificial intelligence is already finding a place in Canadian hospitals. But AI is far from perfect and some worry about the costs that could come with it.</span></span></span></strong></em></p><p dir="ltr">It's still the early days for many of those efforts. Various research teams, including private companies, are exploring ways to use AI for earlier cancer detection. Some studies suggest it has potential for <a href="https://ieeexplore.ieee.org/document/10669945?utm_campaign=2024-Q2-PR&amp;utm_source=KH_PR_Newsroom&amp;utm_medium=ieee_access&amp;utm_content=scientists_use_ai_to_detect_chronic_high_blood_pressure"><u>flagging hypertension</u></a> just by listening to someone's voice; others show it could scan brain patterns to <a href="https://nyulangone.org/news/what-happens-brain-after-Concussion-ai-may-be-only-way-find-answer"><u>detect signs of a concussion</u></a>.</p><div dir="ltr"><ul><li><a href="https://www.cbc.ca/radio/spark/from-virtual-care-apps-to-ai-algorithms-the-trouble-with-data-collection-in-healthcare-1.6759591" text="From virtual care apps to AI algorithms: the trouble with data collection in healthcare" flag="" data-contentid=""><span>From virtual care apps to AI algorithms: the trouble with data collection in healthcare</span></a></li></ul></div><p dir="ltr">Chartwatch is notable, Verma stressed, because of its success in keeping actual patients alive.</p><p dir="ltr">"Very few AI technologies have actually been implemented into clinical settings yet. This is, to our knowledge, one of the first in Canada that has actually been implemented to help us care for patients every day in our hospital," he said.</p><h2 dir="ltr">'Real world' look at AI's health-care impact</h2><p dir="ltr">The St. Michael's-based research does have limitations. The study took place during the COVID-19 pandemic, at a time when the health-care system faced an unusual set of challenges. The&nbsp;urban hospital's patient population is also distinct, the team acknowledged, given its high level of complex patients, including individuals facing homelessness, addiction&nbsp;and overlapping health issues.</p><p dir="ltr">"Our study was not a randomized controlled trial across multiple hospitals. It was within one organization, within one unit," Verma said. "So before we say that this tool can be used widely everywhere, I think we do need to do research on its use in multiple contexts."</p><div dir="ltr"><ul><li><a href="https://www.cbc.ca/news/opinion/opinion-chatgpt-artificial-intelligence-regulation-1.6731973" text="Regulating artificial intelligence: Things are about to get a lot more interesting" flag="Opinion" data-contentid=""><p><span>Opinion</span></p><span>Regulating artificial intelligence: Things are about to get a lot more interesting</span></a></li></ul></div><p dir="ltr">Dr. John-Jose Nunez, a psychiatrist and researcher with the University of British Columbia — who wasn't involved in the study — agreed the research needs to be replicated elsewhere to get a better sense of how well Chartwatch might work in other facilities. There also needs to be considerations around patient privacy, he added, with the use of any emerging AI technologies.</p><p dir="ltr">Still, he praised the study team for providing a "real-world" example of how&nbsp;machine learning can improve patient care.</p><p dir="ltr">"I really think of AI tools as becoming one more team member on the clinical care team,"&nbsp;he said.</p><div dir="ltr"><figure><p><img loading="lazy" alt="Dr. Muhammad Mamdani, vice president of data science and advanced analytics at Unity Health Toronto and director of the University of Toronto Temerty Faculty of Medicine Centre for AI Research and Education in Medicine. " srcset="https://i.cbc.ca/1.7322721.1726244753!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/dr-muhammad-mamdani.jpg 300w,https://i.cbc.ca/1.7322721.1726244753!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/dr-muhammad-mamdani.jpg 460w,https://i.cbc.ca/1.7322721.1726244753!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/dr-muhammad-mamdani.jpg 620w,https://i.cbc.ca/1.7322721.1726244753!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-muhammad-mamdani.jpg 780w,https://i.cbc.ca/1.7322721.1726244753!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/dr-muhammad-mamdani.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.7322721.1726244753!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-muhammad-mamdani.jpg" data-cy="image-img"></p><figcaption>CHARTwatch technology is 'saving lives,' said Dr. Muhammad Mamdani, vice president of data science and advanced analytics at Unity Health Toronto and director of the University of Toronto Temerty Faculty of Medicine Centre for AI Research and Education in Medicine. <!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure></div><p dir="ltr">The Unity Health team is hopeful their technology will roll out more widely in the future, within their own Toronto-based hospital network and beyond.</p><p>Much of that work is happening through <a href="https://geminimedicine.ca/"><u>GEMINI</u></a>, Canada's largest hospital data-sharing network for research and analytics, said Mamdani, Unity Health's vice-president of data science.</p><div><ul><li><a href="https://www.cbc.ca/radio/asithappens/as-it-happens-the-monday-edition-1.6415906/researchers-give-a-robot-hand-the-power-of-touch-designing-a-human-like-fingertip-1.6417499" text="Researchers give a robot hand the power of touch, designing a human-like fingertip" flag="" data-contentid=""><span>Researchers give a robot hand the power of touch, designing a human-like fingertip</span></a></li></ul></div><p dir="ltr">More than 30 hospitals across Ontario are working together, he said, offering opportunities to test Chartwatch and other AI tools in various clinical settings and hospitals.&nbsp;</p><p dir="ltr">"It just sets the groundwork now to be able to deploy these things well beyond our four walls," Mamdani said.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PeerTube 6.3 (169 pts)]]></title>
            <link>https://joinpeertube.org/news/release-6.3</link>
            <guid>41578752</guid>
            <pubDate>Wed, 18 Sep 2024 12:13:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://joinpeertube.org/news/release-6.3">https://joinpeertube.org/news/release-6.3</a>, See on <a href="https://news.ycombinator.com/item?id=41578752">Hacker News</a></p>
Couldn't get https://joinpeertube.org/news/release-6.3: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Why wordfreq will not be updated (1185 pts)]]></title>
            <link>https://github.com/rspeer/wordfreq/blob/master/SUNSET.md</link>
            <guid>41578483</guid>
            <pubDate>Wed, 18 Sep 2024 11:41:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rspeer/wordfreq/blob/master/SUNSET.md">https://github.com/rspeer/wordfreq/blob/master/SUNSET.md</a>, See on <a href="https://news.ycombinator.com/item?id=41578483">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true" aria-labelledby="file-name-id-wide file-name-id-mobile"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Why wordfreq will not be updated</h2><a id="user-content-why-wordfreq-will-not-be-updated" aria-label="Permalink: Why wordfreq will not be updated" href="#why-wordfreq-will-not-be-updated"></a></p>
<p dir="auto">The wordfreq data is a snapshot of language that could be found in various
online sources up through 2021. There are several reasons why it will not be
updated anymore.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Generative AI has polluted the data</h2><a id="user-content-generative-ai-has-polluted-the-data" aria-label="Permalink: Generative AI has polluted the data" href="#generative-ai-has-polluted-the-data"></a></p>
<p dir="auto">I don't think anyone has reliable information about post-2021 language usage by
humans.</p>
<p dir="auto">The open Web (via OSCAR) was one of wordfreq's data sources. Now the Web at
large is full of slop generated by large language models, written by no one to
communicate nothing. Including this slop in the data skews the word
frequencies.</p>
<p dir="auto">Sure, there was spam in the wordfreq data sources, but it was manageable and
often identifiable. Large language models generate text that masquerades as
real language with intention behind it, even though there is none, and their
output crops up everywhere.</p>
<p dir="auto">As one example, <a href="https://pshapira.net/2024/03/31/delving-into-delve/" rel="nofollow">Philip Shapira
reports</a> that ChatGPT
(OpenAI's popular brand of generative language model circa 2024) is obsessed
with the word "delve" in a way that people never have been, and caused its
overall frequency to increase by an order of magnitude.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Information that used to be free became expensive</h2><a id="user-content-information-that-used-to-be-free-became-expensive" aria-label="Permalink: Information that used to be free became expensive" href="#information-that-used-to-be-free-became-expensive"></a></p>
<p dir="auto">wordfreq is not just concerned with formal printed words. It collected more
conversational language usage from two sources in particular: Twitter and
Reddit.</p>
<p dir="auto">The Twitter data was always built on sand. Even when Twitter allowed free
access to a portion of their "firehose", the terms of use did not allow me to
distribute that data outside of the company where I collected it (Luminoso).
wordfreq has the frequencies that were built with that data as input, but the
collected data didn't belong to me and I don't have it anymore.</p>
<p dir="auto">Now Twitter is gone anyway, its public APIs have shut down, and the site has
been replaced with an oligarch's plaything, a spam-infested right-wing cesspool
called X. Even if X made its raw data feed available (which it doesn't), there
would be no valuable information to be found there.</p>
<p dir="auto">Reddit also stopped providing public data archives, and now they sell their
archives at a price that only OpenAI will pay.</p>
<p dir="auto">And given what's happening to the field, I don't blame them.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">I don't want to be part of this scene anymore</h2><a id="user-content-i-dont-want-to-be-part-of-this-scene-anymore" aria-label="Permalink: I don't want to be part of this scene anymore" href="#i-dont-want-to-be-part-of-this-scene-anymore"></a></p>
<p dir="auto">wordfreq used to be at the intersection of my interests. I was doing corpus
linguistics in a way that could also benefit natural language processing tools.</p>
<p dir="auto">The field I know as "natural language processing" is hard to find these days.
It's all being devoured by generative AI. Other techniques still exist but
generative AI sucks up all the air in the room and gets all the money. It's
rare to see NLP research that doesn't have a dependency on closed data
controlled by OpenAI and Google, two companies that I already despise.</p>
<p dir="auto">wordfreq was built by collecting a whole lot of text in a lot of languages.
That used to be a pretty reasonable thing to do, and not the kind of thing
someone would be likely to object to. Now, the text-slurping tools are mostly
used for training generative AI, and people are quite rightly on the defensive.
If someone is collecting all the text from your books, articles, Web site, or
public posts, it's very likely because they are creating a plagiarism machine
that will claim your words as its own.</p>
<p dir="auto">So I don't want to work on anything that could be confused with generative AI,
or that could benefit generative AI.</p>
<p dir="auto">OpenAI and Google can collect their own damn data. I hope they have to pay a
very high price for it, and I hope they're constantly cursing the mess that
they made themselves.</p>
<p dir="auto">— Robyn Speer</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>