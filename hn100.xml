<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 29 Apr 2025 19:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[I made my AI think harder by making it argue with itself (160 pts)]]></title>
            <link>https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts</link>
            <guid>43835445</guid>
            <pubDate>Tue, 29 Apr 2025 17:19:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts">https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts</a>, See on <a href="https://news.ycombinator.com/item?id=43835445">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">CoRT (Chain of Recursive Thoughts) 🧠🔄</h2><a id="user-content-cort-chain-of-recursive-thoughts-" aria-label="Permalink: CoRT (Chain of Recursive Thoughts) 🧠🔄" href="#cort-chain-of-recursive-thoughts-"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">TL;DR: I made my AI think harder by making it argue with itself repeatedly. It works stupidly well.</h2><a id="user-content-tldr-i-made-my-ai-think-harder-by-making-it-argue-with-itself-repeatedly-it-works-stupidly-well" aria-label="Permalink: TL;DR: I made my AI think harder by making it argue with itself repeatedly. It works stupidly well." href="#tldr-i-made-my-ai-think-harder-by-making-it-argue-with-itself-repeatedly-it-works-stupidly-well"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What is this?</h3><a id="user-content-what-is-this" aria-label="Permalink: What is this?" href="#what-is-this"></a></p>
<p dir="auto">CoRT makes AI models recursively think about their responses, generate alternatives, and pick the best one. It's like giving the AI the ability to doubt itself and try again... and again... and again.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Does it actually work?</h3><a id="user-content-does-it-actually-work" aria-label="Permalink: Does it actually work?" href="#does-it-actually-work"></a></p>
<p dir="auto">YES. I tested it with Mistral 3.1 24B and it went from "meh" to "holy crap", especially for such a small model, at programming tasks.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it works" href="#how-it-works"></a></p>
<ol dir="auto">
<li>AI generates initial response</li>
<li>AI decides how many "thinking rounds" it needs</li>
<li>For each round:
<ul dir="auto">
<li>Generates 3 alternative responses</li>
<li>Evaluates all responses</li>
<li>Picks the best one</li>
</ul>
</li>
<li>Final response is the survivor of this AI battle royale</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">Mistral 3.1 24B non CoRT
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/155454343/437931497-acbcf1f9-4715-4d2c-a31c-38b349602380.PNG?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU5NTUzMDEsIm5iZiI6MTc0NTk1NTAwMSwicGF0aCI6Ii8xNTU0NTQzNDMvNDM3OTMxNDk3LWFjYmNmMWY5LTQ3MTUtNGQyYy1hMzFjLTM4YjM0OTYwMjM4MC5QTkc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyOVQxOTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yYWM5NGExZDM2MjFkNDQwNTJjNjU4ZWFjMjhmZjE0MTFmMDI0NWYwYTNhNmE3NjQwMmZiMGE5YTY3MDU3ZWU1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.MCKzCjJu2WSO0eTyIyooBqtHE4t-nmWUBXpooUhmqas"><img src="https://private-user-images.githubusercontent.com/155454343/437931497-acbcf1f9-4715-4d2c-a31c-38b349602380.PNG?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU5NTUzMDEsIm5iZiI6MTc0NTk1NTAwMSwicGF0aCI6Ii8xNTU0NTQzNDMvNDM3OTMxNDk3LWFjYmNmMWY5LTQ3MTUtNGQyYy1hMzFjLTM4YjM0OTYwMjM4MC5QTkc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyOVQxOTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yYWM5NGExZDM2MjFkNDQwNTJjNjU4ZWFjMjhmZjE0MTFmMDI0NWYwYTNhNmE3NjQwMmZiMGE5YTY3MDU3ZWU1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.MCKzCjJu2WSO0eTyIyooBqtHE4t-nmWUBXpooUhmqas" alt="rec"></a></p>
<p dir="auto">Mistral 3.1 24B + CoRT
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/155454343/437931494-9c4f6af9-0a8f-4c62-920c-f272fce225c1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU5NTUzMDEsIm5iZiI6MTc0NTk1NTAwMSwicGF0aCI6Ii8xNTU0NTQzNDMvNDM3OTMxNDk0LTljNGY2YWY5LTBhOGYtNGM2Mi05MjBjLWYyNzJmY2UyMjVjMS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyOVQxOTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03N2E2YjQwNTUxNjE4ZGM3ZTZjZDAxMzRiY2JmZWI4NWIwOGM2YWE4ZTE2MGJkMzFlNjcyNmJhYWRhZTg5YjYzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Ti1DUkjHPlHiG_QhTD1LEG34q0x7Mt_lwjcrsSqIZ-4"><img src="https://private-user-images.githubusercontent.com/155454343/437931494-9c4f6af9-0a8f-4c62-920c-f272fce225c1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU5NTUzMDEsIm5iZiI6MTc0NTk1NTAwMSwicGF0aCI6Ii8xNTU0NTQzNDMvNDM3OTMxNDk0LTljNGY2YWY5LTBhOGYtNGM2Mi05MjBjLWYyNzJmY2UyMjVjMS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyOVQxOTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03N2E2YjQwNTUxNjE4ZGM3ZTZjZDAxMzRiY2JmZWI4NWIwOGM2YWE4ZTE2MGJkMzFlNjcyNmJhYWRhZTg5YjYzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Ti1DUkjHPlHiG_QhTD1LEG34q0x7Mt_lwjcrsSqIZ-4" alt="non-rec"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Try it yourself</h2><a id="user-content-try-it-yourself" aria-label="Permalink: Try it yourself" href="#try-it-yourself"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install -r requirements.txt
export OPENROUTER_API_KEY=&quot;your-key-here&quot;
python recursive-thinking-ai.py"><pre><span>pip</span> <span>install</span> <span>-</span><span>r</span> <span>requirements</span>.<span>txt</span>
<span>export</span> <span>OPENROUTER_API_KEY</span><span>=</span><span>"your-key-here"</span>
<span>python</span> <span>recursive</span><span>-</span><span>thinking</span><span>-</span><span>ai</span>.<span>py</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">The Secret Sauce</h3><a id="user-content-the-secret-sauce" aria-label="Permalink: The Secret Sauce" href="#the-secret-sauce"></a></p>
<p dir="auto">The magic is in:</p>
<ul dir="auto">
<li>Self-evaluation</li>
<li>Competitive alternative generation</li>
<li>Iterative refinement</li>
<li>Dynamic thinking depth</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Contributing</h3><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Found a way to make it even better? PR's welcome!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">License</h3><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT - Go wild with it</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[O3 beats a master-level GeoGuessr player, even with fake EXIF data (240 pts)]]></title>
            <link>https://sampatt.com/blog/2025-04-28-can-o3-beat-a-geoguessr-master</link>
            <guid>43835044</guid>
            <pubDate>Tue, 29 Apr 2025 16:48:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sampatt.com/blog/2025-04-28-can-o3-beat-a-geoguessr-master">https://sampatt.com/blog/2025-04-28-can-o3-beat-a-geoguessr-master</a>, See on <a href="https://news.ycombinator.com/item?id=43835044">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Indian court orders blocking of Proton Mail (138 pts)]]></title>
            <link>https://techcrunch.com/2025/04/29/indian-court-orders-blocking-of-proton-mail/</link>
            <guid>43834942</guid>
            <pubDate>Tue, 29 Apr 2025 16:41:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/04/29/indian-court-orders-blocking-of-proton-mail/">https://techcrunch.com/2025/04/29/indian-court-orders-blocking-of-proton-mail/</a>, See on <a href="https://news.ycombinator.com/item?id=43834942">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">A court in India has ordered the blocking of encrypted email provider Proton Mail across the country.</p>

<p>On Tuesday, the Karnataka High Court directed the Indian government to block Proton Mail, a popular email service known for its enhanced security, following a legal complaint filed by New Delhi-based M Moser Design Associates. The local firm alleged that its employees had received emails containing obscene and vulgar content sent via Proton Mail.</p>







<p>In a <a href="https://www.youtube.com/live/cnCfjfWGo_E?si=IP6J6aP31eX7EDkJ&amp;t=10419" target="_blank" rel="noreferrer noopener nofollow">Tuesday hearing streamed on YouTube</a>, Justice M Nagaprasanna ordered the Indian government to “block Proton Mail, bearing in mind the observations made in the course of the order,” under the Information Technology Act 2008.</p>

<p>In its <a href="https://karnatakajudiciary.kar.nic.in/newwebsite/casestatushck.php?params=UFdkQmZjM3lKOGY2TFZkZjkvNkVUdDJwWnVUZTFyOW9sSEgzYjdNcDNOZ0ZKY1JidGxnendDeUwxUWdmdlI2ZWpWbjFiWnpoNlNidEViaE5QS1NnK3c9PQ==" target="_blank" rel="noreferrer noopener nofollow">complaint</a> filed in January, the New Delhi-based firm called for the regulation or blocking of Proton Mail in India, as the email service reportedly refused to share details about the sender of the allegedly offensive emails, despite a police complaint.</p>

<p>Additional solicitor general Aravind Kamath, representing the Indian government, had earlier told the high court that the government might have a limited role in addressing the petitioner’s concerns and suggested criminal courts could seek the required information from Swiss authorities since the petitioner had made a complaint.</p>

<p>The block of Proton Mail has yet to take effect, based on TechCrunch’s checks of Proton Mail’s website in India. TechCrunch contacted Proton Mail for comment and will update this story if we hear back.</p>

<p>This is the latest legal tussle facing Proton Mail in India, its second ruling in as many years aimed at blocking the encrypted email service from operating in the country.</p>

<p>Last year, the police department of the southern state of Tamil Nadu had <a href="https://techcrunch.com/2024/02/16/india-may-block-proton-mail/" target="_blank" rel="noreferrer noopener">sought to block</a> Proton Mail after the email service was found to have been used for sending hoax bomb threats to local schools. The Indian government’s IT ministry reportedly notified internet providers to block Proton Mail at the request of law enforcement. However, the Swiss federal authorities <a href="https://proton.me/blog/india-block-proton-mail" target="_blank" rel="noreferrer noopener nofollow">intervened to prevent</a> the blocking of Proton Mail taking effect.</p>

<p>“Blocking access to Proton Mail simply prevents law-abiding citizens from communicating securely and does not prevent cybercriminals from sending threats with another email service, especially if the perpetrators are located outside of India,” Proton said at the time.</p>

<p>Nonetheless, in October 2024, the Delhi High Court <a href="https://indianexpress.com/article/cities/delhi/delhi-hc-questions-proton-mail-india-directs-mha-police-9660111/" target="_blank" rel="noreferrer noopener nofollow">asked</a> state police and the Indian government’s home ministry to investigate the alleged use of Proton Mail across the country. Kamath, the additional solicitor general, had assured the Karnataka High Court that he would examine the Delhi High Court’s observations on Proton Mail’s use in India.</p>
</div><div>
	
	
	
	

	
<div>
	<p>
		Jagmeet covers startups, tech policy-related updates, and all other major tech-centric developments from India for TechCrunch. He previously worked as a principal correspondent at NDTV. You can reach out to him at mail[at]journalistjagmeet[dot]com.	</p>
</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/jagmeet-singh/" data-event="button" href="https://techcrunch.com/author/jagmeet-singh/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox tab groups are here (299 pts)]]></title>
            <link>https://blog.mozilla.org/en/firefox/tab-groups-community/</link>
            <guid>43834101</guid>
            <pubDate>Tue, 29 Apr 2025 15:37:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mozilla.org/en/firefox/tab-groups-community/">https://blog.mozilla.org/en/firefox/tab-groups-community/</a>, See on <a href="https://news.ycombinator.com/item?id=43834101">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-78908">
  

  <div>
    
<p>What happens when 4,500 people ask for the same feature? At Firefox, we build it.</p>



<figure><video controls="" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/ENG-Tab-groups-animation-v101.mp4"></video><figcaption><em>Firefox tab groups now available</em></figcaption></figure>



<p>Tab groups have long been the most <a href="https://connect.mozilla.org/t5/ideas/native-tab-grouping-more-customizable-tab-bar/idi-p/303">requested idea</a> on <a href="https://connect.mozilla.org/">Mozilla Connect</a> – our community platform – and thanks to thousands of votes, comments and passionate feedback, it’s finally here. 🎉</p>



<p>But this is more than just a feature launch. It’s the story of what happens when community insight, real-world pain points, and a whole lot of curiosity come together.</p>



<h3><strong>A feature the community asked for, loud and clear</strong></h3>



<p>Just one day after Mozilla Connect quietly <a href="https://blog.mozilla.org/en/firefox/about-mozilla-connect/">launched</a> in March 2022, a <a href="https://connect.mozilla.org/t5/ideas/native-tab-grouping-more-customizable-tab-bar/idi-p/303">request</a> for tab groups appeared. We hadn’t even promoted the platform. There were no announcements. But the community found Mozilla Connect and rallied behind the request for tab groups.</p>



<p>“It’s still the number one most upvoted post on Mozilla Connect,” said Jon Siddoway, who helps surface user insights to Firefox teams. “Even when the feature was in beta, people were still voting for it and saying, ‘We want this.’”</p>



<p>At Mozilla, we work hard to make Firefox the best browser for you. Last year, we <a href="https://blog.mozilla.org/en/mozilla/heres-what-were-working-on-in-firefox/">shared</a> what we were working on – features that help you stay organized, like our handy sidebar, <a href="https://blog.mozilla.org/en/firefox/vertical-tabs-and-the-firefox-community/">vertical tabs</a> and tab groups. As we noted then, community feedback directly shaped what came next.&nbsp;</p>



<blockquote>
<p>“It’s still the number one most upvoted post on Mozilla Connect.” </p>
<cite>Jon Siddoway, product manager of Mozilla Connect</cite></blockquote>



<p>That early request kicked off a collaboration between the Firefox team and community. Before any code was written, Jon summarized comments, tracked trends across 64+ pages of feedback and brought key themes to the team.</p>



<p>That enthusiasm spilled into beta testing. Before the official <a href="https://connect.mozilla.org/t5/discussions/help-shape-the-future-of-tab-groups-in-firefox/m-p/89026">invite</a> to community members went out, many of them discovered the hidden toggle in the Nightly release, turned it on themselves, and started sharing how to use it. The team watched, learned and iterated from the sidelines.</p>



<h3><strong>Listening and learning from thousands of voices</strong></h3>



<p>Stefan Smagula, product manager for the tabs group feature, didn’t just skim the posts – he dove in.</p>



<p>“I read Mozilla Connect every day for the first month,” he said. “Sometimes the ideas confirmed what we were already thinking. Other times they were totally new and unexpected, like requests for nested tab groups.”</p>



<p>But with over 1,000 comments and many differing opinions, how do you make decisions?</p>



<blockquote>
<p>“Sometimes the ideas confirmed what we were already thinking. Other times they were totally new and unexpected.”</p>
<cite>Stefan Smagula, product manager at Firefox</cite></blockquote>



<p>“You try to get to the <em>underlying needs</em> behind each request,” Stefan explained. “Instead of just implementing one person’s idea, you look for the broader pattern — the thing that could help the most people.”</p>



<p>This approach helped shape a feature that balances flexibility with simplicity. With tab groups, you can drag and drop tabs into organized groups, label them by name or color, and stay focused. Whether you’re a <a href="https://blog.mozilla.org/en/firefox/firefox-tips/transform-firefox-into-minimalist-workspace/">minimalist</a> with 10 tabs or a power user juggling 10,000 (seriously — one of our colleagues does this), tab groups can help.</p>


<div>
<figure><img decoding="async" fetchpriority="high" width="1024" height="578" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/EN2-1024x578.png" alt="Browser window showing Firefox's tab grouping feature. A 'Create tab group' pop-up is open, with 'Thailand Trip' entered as the group name and a purple color selected. Tabs for 'Thailand Trip,' 'Google Flights,' 'Hotels.com,' and a 'New Tab' are visible, along with existing tab groups labeled 'Work,' 'Reading,' and 'Shopping.'" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/EN2-1024x578.png 1024w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/EN2-300x169.png 300w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/EN2-768x433.png 768w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/EN2-1000x564.png 1000w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/04/EN2.png 1136w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><em>Keep it together — group your tabs by trip, work, or whatever you need!</em></figcaption></figure></div>


<p>“Tab groups aren’t just about decluttering,” Stefan said. “It’s about reclaiming your flow and finding focus again.”</p>



<p>It also reinforced the team’s belief that done is never truly done.</p>



<blockquote>
<p>“Tab groups aren’t just about decluttering. It’s about reclaiming your flow and finding focus again.”</p>
<cite>Stefan Smagula, product manager at Firefox</cite></blockquote>



<h3><strong>What’s next: Make tab groups smarter</strong></h3>



<p>Once early testers began using tab groups in <a href="https://www.mozilla.org/en-US/firefox/channel/desktop/">Firefox Nightly and Beta</a>, feedback kept rolling in – both on Mozilla Connect and in places like <a href="https://blog.mozilla.org/en/firefox/firefox-subreddit/">Reddit</a> and X, where Stefan scouts for feedback. Many users wanted less friction and more flow when managing their tabs, which inspired the team to explore the next step: having the browser help organize things automatically.&nbsp;</p>



<p>Now, the team is experimenting with smart tab groups, a new AI-powered feature that suggests names and groups based on the tabs you have open. Other browsers might send your tab info to the cloud, but Firefox keeps it on your device. Your tabs stay private and never leave your device.</p>



<p>“I used to have 30 windows open, each with 30 or 40 tabs. Smart tab groups changed the way I work. It made it easier to find what I need and resume tasks faster,” said Stefan.</p>



<p>It’s just the beginning of what’s possible when you pair smart tech with real human needs.</p>



<blockquote>
<p>“I used to have 30 windows open, each with 30 or 40 tabs. Smart tab groups changed the way I work. It made it easier to find what I need and resume tasks faster.”</p>
<cite>Stefan Smagula, product manager at Firefox</cite></blockquote>



<h3><strong>Thank you – and keep the ideas coming</strong></h3>



<p>This feature wouldn’t exist without you. Your upvotes, comments, ideas and testing helped bring it to life.</p>



<p>As Stefan put it: “It’s extremely motivating to know how many people want this. It makes the hard work easier and more meaningful.”</p>



<p>So if you’ve ever felt tab overload — or if you just want your browser to feel a bit more like your own — try out tab groups. Share what you love and what you’d change.</p>



<blockquote>
<p>“It’s extremely motivating to know how many people want this. It makes the hard work easier and more meaningful.”</p>
<cite>Stefan Smagula, product manager at Firefox</cite></blockquote>



<p>You can join the conversation anytime on <a href="https://connect.mozilla.org/">Mozilla Connect</a>. 💬</p>



<a href="https://www.mozilla.org/en-US/firefox/new/?utm_source=blog.mozilla.org&amp;utm_medium=referral&amp;utm_campaign=blog-nav">
  <p><img width="800" height="800" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2024/05/fx_website_meta-image_tips-tricks_alt-04-1-800x800.webp" alt="" decoding="async" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2024/05/fx_website_meta-image_tips-tricks_alt-04-1-800x800.webp 800w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2024/05/fx_website_meta-image_tips-tricks_alt-04-1-150x150.webp 150w" sizes="(max-width: 800px) 100vw, 800px">  </p>
  <div>
     <h3>Get the browser that puts your privacy first — and always has </h3>      <p><span>Download Firefox</span>   </p></div>
</a>
  </div>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ArkFlow: High-performance Rust stream processing engine (102 pts)]]></title>
            <link>https://github.com/arkflow-rs/arkflow</link>
            <guid>43833310</guid>
            <pubDate>Tue, 29 Apr 2025 14:38:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/arkflow-rs/arkflow">https://github.com/arkflow-rs/arkflow</a>, See on <a href="https://news.ycombinator.com/item?id=43833310">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ArkFlow</h2><a id="user-content-arkflow" aria-label="Permalink: ArkFlow" href="#arkflow"></a></p>
<p dir="auto">English | <a href="https://github.com/arkflow-rs/arkflow/blob/main/README_zh.md">中文</a></p>
<p dir="auto"><a href="https://github.com/arkflow-rs/arkflow/actions/workflows/rust.yml"><img src="https://github.com/arkflow-rs/arkflow/actions/workflows/rust.yml/badge.svg" alt="Rust"></a>
<a href="https://github.com/arkflow-rs/arkflow/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/c355f200ea90fddaa407b6eaab303663a669248ea3ca7b1fcf77dbe04ff5f48c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d417061636865253230322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/license-Apache%202.0-blue.svg"></a></p>
<p dir="auto"><a href="https://www.producthunt.com/posts/arkflow?embed=true&amp;utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-arkflow" rel="nofollow"><img src="https://camo.githubusercontent.com/85bc9a37fb504dfdad5bf0aba5e7d0fe211288afd9a6a9c7a64e632f1bffbd0d/68747470733a2f2f6170692e70726f6475637468756e742e636f6d2f776964676574732f656d6265642d696d6167652f76312f66656174757265642e7376673f706f73745f69643d393432383034267468656d653d6c6967687426743d31373433313336323632333336" alt="ArkFlow - High-performance rust stream processing engine | Product Hunt" width="250" height="54" data-canonical-src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=942804&amp;theme=light&amp;t=1743136262336"></a></p>
<p dir="auto">High-performance Rust stream processing engine, providing powerful data stream processing capabilities, supporting
multiple input/output sources and processors.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>High Performance</strong>: Built on Rust and Tokio async runtime, offering excellent performance and low latency</li>
<li><strong>Multiple Data Sources</strong>: Support for Kafka, MQTT, HTTP, files, and other input/output sources</li>
<li><strong>Powerful Processing Capabilities</strong>: Built-in SQL queries, JSON processing, Protobuf encoding/decoding, batch
processing, and other processors</li>
<li><strong>Extensible</strong>: Modular design, easy to extend with new input, output, and processor components</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Building from Source</h3><a id="user-content-building-from-source" aria-label="Permalink: Building from Source" href="#building-from-source"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone the repository
git clone https://github.com/arkflow-rs/arkflow.git
cd arkflow

# Build the project
cargo build --release

# Run tests
cargo test"><pre><span><span>#</span> Clone the repository</span>
git clone https://github.com/arkflow-rs/arkflow.git
<span>cd</span> arkflow

<span><span>#</span> Build the project</span>
cargo build --release

<span><span>#</span> Run tests</span>
cargo <span>test</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<ol dir="auto">
<li>Create a configuration file <code>config.yaml</code>:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="logging:
  level: info
streams:
  - input:
      type: &quot;generate&quot;
      context: '{ &quot;timestamp&quot;: 1625000000000, &quot;value&quot;: 10, &quot;sensor&quot;: &quot;temp_1&quot; }'
      interval: 1s
      batch_size: 10

    pipeline:
      thread_num: 4
      processors:
        - type: &quot;json_to_arrow&quot;
        - type: &quot;sql&quot;
          query: &quot;SELECT * FROM flow WHERE value >= 10&quot;

    output:
      type: &quot;stdout&quot;
    error_output:
      type: &quot;stdout&quot;"><pre><span>logging</span>:
  <span>level</span>: <span>info</span>
<span>streams</span>:
  - <span>input</span>:
      <span>type</span>: <span><span>"</span>generate<span>"</span></span>
      <span>context</span>: <span><span>'</span>{ "timestamp": 1625000000000, "value": 10, "sensor": "temp_1" }<span>'</span></span>
      <span>interval</span>: <span>1s</span>
      <span>batch_size</span>: <span>10</span>

    <span>pipeline</span>:
      <span>thread_num</span>: <span>4</span>
      <span>processors</span>:
        - <span>type</span>: <span><span>"</span>json_to_arrow<span>"</span></span>
        - <span>type</span>: <span><span>"</span>sql<span>"</span></span>
          <span>query</span>: <span><span>"</span>SELECT * FROM flow WHERE value &gt;= 10<span>"</span></span>

    <span>output</span>:
      <span>type</span>: <span><span>"</span>stdout<span>"</span></span>
    <span>error_output</span>:
      <span>type</span>: <span><span>"</span>stdout<span>"</span></span></pre></div>
<ol start="2" dir="auto">
<li>Run ArkFlow:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="./target/release/arkflow --config config.yaml"><pre>./target/release/arkflow --config config.yaml</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration Guide</h2><a id="user-content-configuration-guide" aria-label="Permalink: Configuration Guide" href="#configuration-guide"></a></p>
<p dir="auto">ArkFlow uses YAML format configuration files, supporting the following main configuration items:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Top-level Configuration</h3><a id="user-content-top-level-configuration" aria-label="Permalink: Top-level Configuration" href="#top-level-configuration"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="logging:
  level: info  # Log level: debug, info, warn, error

streams: # Stream definition list
  - input:      # Input configuration
    # ...
    pipeline:   # Processing pipeline configuration
    # ...
    output:     # Output configuration
    # ...
    error_output: # Error output configuration
    # ...
    buffer:     # Buffer configuration
    # ... "><pre><span>logging</span>:
  <span>level</span>: <span>info  </span><span><span>#</span> Log level: debug, info, warn, error</span>

<span>streams</span>: <span><span>#</span> Stream definition list</span>
  - <span>input</span>:      <span><span>#</span> Input configuration</span>
    <span><span>#</span> ...</span>
    <span>pipeline</span>:   <span><span>#</span> Processing pipeline configuration</span>
    <span><span>#</span> ...</span>
    <span>output</span>:     <span><span>#</span> Output configuration</span>
    <span><span>#</span> ...</span>
    <span>error_output</span>: <span><span>#</span> Error output configuration</span>
    <span><span>#</span> ...</span>
    <span>buffer</span>:     <span><span>#</span> Buffer configuration</span>
    <span><span>#</span> ... </span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Input Components</h3><a id="user-content-input-components" aria-label="Permalink: Input Components" href="#input-components"></a></p>
<p dir="auto">ArkFlow supports multiple input sources:</p>
<ul dir="auto">
<li><strong>Kafka</strong>: Read data from Kafka topics</li>
<li><strong>MQTT</strong>: Subscribe to messages from MQTT topics</li>
<li><strong>HTTP</strong>: Receive data via HTTP</li>
<li><strong>File</strong>: Reading data from files(Csv,Json, Parquet, Avro, Arrow) using SQL</li>
<li><strong>Generator</strong>: Generate test data</li>
<li><strong>Database</strong>: Query data from databases(MySQL, PostgreSQL, SQLite, Duckdb)</li>
</ul>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="input:
  type: kafka
  brokers:
    - localhost:9092
  topics:
    - test-topic
  consumer_group: test-group
  client_id: arkflow
  start_from_latest: true"><pre><span>input</span>:
  <span>type</span>: <span>kafka</span>
  <span>brokers</span>:
    - <span>localhost:9092</span>
  <span>topics</span>:
    - <span>test-topic</span>
  <span>consumer_group</span>: <span>test-group</span>
  <span>client_id</span>: <span>arkflow</span>
  <span>start_from_latest</span>: <span>true</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Processors</h3><a id="user-content-processors" aria-label="Permalink: Processors" href="#processors"></a></p>
<p dir="auto">ArkFlow provides multiple data processors:</p>
<ul dir="auto">
<li><strong>JSON</strong>: JSON data processing and transformation</li>
<li><strong>SQL</strong>: Process data using SQL queries</li>
<li><strong>Protobuf</strong>: Protobuf encoding/decoding</li>
<li><strong>Batch Processing</strong>: Process messages in batches</li>
</ul>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pipeline:
  thread_num: 4
  processors:
    - type: json_to_arrow
    - type: sql
      query: &quot;SELECT * FROM flow WHERE value >= 10&quot;"><pre><span>pipeline</span>:
  <span>thread_num</span>: <span>4</span>
  <span>processors</span>:
    - <span>type</span>: <span>json_to_arrow</span>
    - <span>type</span>: <span>sql</span>
      <span>query</span>: <span><span>"</span>SELECT * FROM flow WHERE value &gt;= 10<span>"</span></span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Output Components</h3><a id="user-content-output-components" aria-label="Permalink: Output Components" href="#output-components"></a></p>
<p dir="auto">ArkFlow supports multiple output targets:</p>
<ul dir="auto">
<li><strong>Kafka</strong>: Write data to Kafka topics</li>
<li><strong>MQTT</strong>: Publish messages to MQTT topics</li>
<li><strong>HTTP</strong>: Send data via HTTP</li>
<li><strong>Standard Output</strong>: Output data to the console</li>
<li><strong>Drop</strong>: Discard data</li>
</ul>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="output:
  type: kafka
  brokers:
    - localhost:9092
  topic: 
    type: value
    value: test-topic
  client_id: arkflow-producer"><pre><span>output</span>:
  <span>type</span>: <span>kafka</span>
  <span>brokers</span>:
    - <span>localhost:9092</span>
  <span>topic</span>: 
    <span>type</span>: <span>value</span>
    <span>value</span>: <span>test-topic</span>
  <span>client_id</span>: <span>arkflow-producer</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Error Output Components</h3><a id="user-content-error-output-components" aria-label="Permalink: Error Output Components" href="#error-output-components"></a></p>
<p dir="auto">ArkFlow supports multiple error output targets:</p>
<ul dir="auto">
<li><strong>Kafka</strong>: Write error data to Kafka topics</li>
<li><strong>MQTT</strong>: Publish error messages to MQTT topics</li>
<li><strong>HTTP</strong>: Send error data via HTTP</li>
<li><strong>Standard Output</strong>: Output error data to the console</li>
<li><strong>Drop</strong>: Discard error data</li>
</ul>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="error_output:
  type: kafka
  brokers:
    - localhost:9092
  topic: 
    type: value
    value: error-topic
  client_id: error-arkflow-producer"><pre><span>error_output</span>:
  <span>type</span>: <span>kafka</span>
  <span>brokers</span>:
    - <span>localhost:9092</span>
  <span>topic</span>: 
    <span>type</span>: <span>value</span>
    <span>value</span>: <span>error-topic</span>
  <span>client_id</span>: <span>error-arkflow-producer</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Buffer Components</h3><a id="user-content-buffer-components" aria-label="Permalink: Buffer Components" href="#buffer-components"></a></p>
<p dir="auto">ArkFlow provides buffer capabilities to handle backpressure and temporary storage of messages:</p>
<ul dir="auto">
<li><strong>Memory Buffer</strong>: Memory buffer, for high-throughput scenarios and window aggregation</li>
</ul>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="buffer:
  type: memory
  capacity: 10000  # Maximum number of messages to buffer
  timeout: 10s  # Maximum time to buffer messages"><pre><span>buffer</span>:
  <span>type</span>: <span>memory</span>
  <span>capacity</span>: <span>10000</span>  <span><span>#</span> Maximum number of messages to buffer</span>
  <span>timeout</span>: <span>10s</span>  <span><span>#</span> Maximum time to buffer messages</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Kafka to Kafka Data Processing</h3><a id="user-content-kafka-to-kafka-data-processing" aria-label="Permalink: Kafka to Kafka Data Processing" href="#kafka-to-kafka-data-processing"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="streams:
  - input:
      type: kafka
      brokers:
        - localhost:9092
      topics:
        - test-topic
      consumer_group: test-group

    pipeline:
      thread_num: 4
      processors:
        - type: json_to_arrow
        - type: sql
          query: &quot;SELECT * FROM flow WHERE value > 100&quot;

    output:
      type: kafka
      brokers:
        - localhost:9092
      topic: processed-topic"><pre><span>streams</span>:
  - <span>input</span>:
      <span>type</span>: <span>kafka</span>
      <span>brokers</span>:
        - <span>localhost:9092</span>
      <span>topics</span>:
        - <span>test-topic</span>
      <span>consumer_group</span>: <span>test-group</span>

    <span>pipeline</span>:
      <span>thread_num</span>: <span>4</span>
      <span>processors</span>:
        - <span>type</span>: <span>json_to_arrow</span>
        - <span>type</span>: <span>sql</span>
          <span>query</span>: <span><span>"</span>SELECT * FROM flow WHERE value &gt; 100<span>"</span></span>

    <span>output</span>:
      <span>type</span>: <span>kafka</span>
      <span>brokers</span>:
        - <span>localhost:9092</span>
      <span>topic</span>: <span>processed-topic</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Generate Test Data and Process</h3><a id="user-content-generate-test-data-and-process" aria-label="Permalink: Generate Test Data and Process" href="#generate-test-data-and-process"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="streams:
  - input:
      type: &quot;generate&quot;
      context: '{ &quot;timestamp&quot;: 1625000000000, &quot;value&quot;: 10, &quot;sensor&quot;: &quot;temp_1&quot; }'
      interval: 1ms
      batch_size: 10000

    pipeline:
      thread_num: 4
      processors:
        - type: &quot;json_to_arrow&quot;
        - type: &quot;sql&quot;
          query: &quot;SELECT count(*) FROM flow WHERE value >= 10 group by sensor&quot;

    output:
      type: &quot;stdout&quot;"><pre><span>streams</span>:
  - <span>input</span>:
      <span>type</span>: <span><span>"</span>generate<span>"</span></span>
      <span>context</span>: <span><span>'</span>{ "timestamp": 1625000000000, "value": 10, "sensor": "temp_1" }<span>'</span></span>
      <span>interval</span>: <span>1ms</span>
      <span>batch_size</span>: <span>10000</span>

    <span>pipeline</span>:
      <span>thread_num</span>: <span>4</span>
      <span>processors</span>:
        - <span>type</span>: <span><span>"</span>json_to_arrow<span>"</span></span>
        - <span>type</span>: <span><span>"</span>sql<span>"</span></span>
          <span>query</span>: <span><span>"</span>SELECT count(*) FROM flow WHERE value &gt;= 10 group by sensor<span>"</span></span>

    <span>output</span>:
      <span>type</span>: <span><span>"</span>stdout<span>"</span></span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">ArkFlow Plugin</h2><a id="user-content-arkflow-plugin" aria-label="Permalink: ArkFlow Plugin" href="#arkflow-plugin"></a></p>
<p dir="auto"><a href="https://github.com/arkflow-rs/arkflow-plugin-examples">ArkFlow Plugin Examples</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">ArkFlow is licensed under the <a href="https://github.com/arkflow-rs/arkflow/blob/main/LICENSE">Apache License 2.0</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<p dir="auto">Discord: <a href="https://discord.gg/CwKhzb8pux" rel="nofollow">https://discord.gg/CwKhzb8pux</a></p>
<p dir="auto">If you like or are using this project to learn or start your solution, please give it a star⭐. Thanks!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[White House slams Amazon tariff price display "hostile and political" (134 pts)]]></title>
            <link>https://www.axios.com/2025/04/29/tariffs-amazon-prime-day-sellers-report</link>
            <guid>43832588</guid>
            <pubDate>Tue, 29 Apr 2025 13:49:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.axios.com/2025/04/29/tariffs-amazon-prime-day-sellers-report">https://www.axios.com/2025/04/29/tariffs-amazon-prime-day-sellers-report</a>, See on <a href="https://news.ycombinator.com/item?id=43832588">Hacker News</a></p>
Couldn't get https://www.axios.com/2025/04/29/tariffs-amazon-prime-day-sellers-report: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Performance optimization is hard because it's fundamentally a brute-force task (167 pts)]]></title>
            <link>https://purplesyringa.moe/blog/why-performance-optimization-is-hard-work/</link>
            <guid>43831705</guid>
            <pubDate>Tue, 29 Apr 2025 12:29:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://purplesyringa.moe/blog/why-performance-optimization-is-hard-work/">https://purplesyringa.moe/blog/why-performance-optimization-is-hard-work/</a>, See on <a href="https://news.ycombinator.com/item?id=43831705">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><time>April 29, 2025</time><a href="https://www.reddit.com/r/programming/comments/1kam686/why_performance_optimization_is_hard_work/"> Reddit</a></p><p>I’m not talking about skill, knowledge, or convincing a world focused on radical acceleration that optimization is necessary. Performance optimization is hard because it’s fundamentally a brute-force task, and there’s nothing you can do about it.</p><p>This post is a bit of a rant on my frustrations with code optimization. I’ll also try to give actionable advice, which I hope enchants your experience.</p><p>Certain optimizations can only work together, while others lead to pessimizations when combined. To be an expert means to know what optimization avenues exist; to be a master means to know which ones to choose.</p><p>I have a post on integer formatting in the works, covering a very particular algorithm design – and I <em>still</em> haven’t finished it because there’s like five different choices to make, I have no idea how they impact each other, and I need to analyze <eq><math><msup><mn>2</mn><mn>5</mn></msup></math></eq> variants to claim which one’s the best in conscience. Several of my projects are similarly stuck because I don’t have the willpower to implement a dozen combinations.</p><p>Pruning “obviously” suboptimal approaches is all but a heuristic. I like to think I’m more in tune with an x86-64 CPU than most people, and it still manages to surprise me from time to time. Dumb algorithms can become more applicable due to vectorization, smart code can fail due to <a href="https://en.wikipedia.org/wiki/Branch_predictor">branch misprediction</a> or <a href="https://en.wikipedia.org/wiki/Memory_disambiguation#Store_to_load_forwarding">store-to-load forwarding</a> gone wrong.</p><p>Optimization takes a lot of trial and error. I dislike the “intuition doesn’t work, profile your code” mantra because it seemingly says profiling is a viable replacement for theoretical calculations, which it isn’t. But I can’t argue that profiling is avoidable. I often joke that <code>perf report</code> is my go-to disassembler.</p><p>Worse yet, you can’t trust “obviously” good code either. In <a href="https://purplesyringa.moe/blog/the-ram-myth/">a previous post</a>, I optimized a single linear pass by replacing it with a superlinear sort. This is by no means a unique experience: just yesterday, I saw someone optimize best-of-class <a href="https://en.wikipedia.org/wiki/Barrett_reduction">Barrett reduction</a> by dividing the numbers as <code>double</code>s, rounding them, and computing the reminder from the quotient. It’s so stupid that it can’t possibly work, yet it does.</p><p>The good news is that the work here can be split among multiple people trying different approaches. Open-source projects in particular benefit from this, because contributors typically have different strengths and focus on different ideas. Try to reuse work by consulting your teammates or reading about others’ experiences in solving similar tasks.</p><p>A variation on this is algorithms where a <em>cut-off boundary</em> is present. You no longer choose whether to apply an optimization: you also need to select parameters via more trial and error. For example:</p><ul><li>Hybrid sorting algorithms can switch between different implementations due to high big-O constants,</li><li><a href="https://en.wikipedia.org/wiki/Fast_Fourier_transform">FFT</a> can switch between recursive and iterative approaches to better utilize processor cache.</li><li>Depending on data density, the optimal set structure might be bitsets, hash sets, or complementary hash sets.</li></ul><p>Modifying either of the alternative algorithms requires rebenchmarking to update the optimal boundary. Small modifications here can lead to <em>drastic</em> end performance changes due to interactions with CPU cache, branch and memory access prediction, the discrete nature of recursive cut-offs, and floating-point precision (for <a href="https://en.wikipedia.org/wiki/Sch%C3%B6nhage%E2%80%93Strassen_algorithm#Details">big integer multiplication via FFT</a>). Forgetting to rebenchmark and abandoning a prospective approach can easily leave <eq><math><mrow><mn>2</mn><mo>×</mo></mrow></math></eq> performance on the table.</p><p>For another example, consider a program that executes <eq><math><mi>n</mi></math></eq> times either action <eq><math><mi>A</mi></math></eq> or <eq><math><mi>B</mi></math></eq> depending on probability <eq><math><mi>p</mi></math></eq>. If <eq><math><mi>p</mi></math></eq> is far from <eq><math><mfrac><mn>1</mn><mn>2</mn></mfrac></math></eq>, branch prediction means it’s better to implement the switch with an <code>if</code>; if <eq><math><mi>p</mi></math></eq> is close to <eq><math><mfrac><mn>1</mn><mn>2</mn></mfrac></math></eq>, branch prediction will fail and a branchless approach will work better. Not only does the relative performance of <eq><math><mi>A</mi></math></eq> and <eq><math><mi>B</mi></math></eq> matter here, but the cost of branch misprediction matters as well, and that might depend not only on the CPU but on the precise code executed.</p><p>Ideally, you’d have a test bench that plots graphs and finds optimal parameter values automatically, even though getting this working can be draining. This way, running checks all the time becomes cheap and emotionally easier. Even if it takes half an hour, you can still work on something else in parallel.</p><p>The worst example of incompatible optimizations is those that fail due to external constraints.</p><p>One example is when two <a href="https://en.wikipedia.org/wiki/Lookup_table">LUTs</a> don’t fit in cache together, but do individually. You can sometimes fix this by splitting the computation into multiple passes, where each pass only needs to access helper data that does fit into cache. This does not necessarily mean two passes over <em>all</em> data, consuming <eq><math><mrow><mn>2</mn><mo>×</mo></mrow></math></eq> memory bandwidth – you can chunk the data and apply two passes on a chunk, which increases performance if the chunk fits into, say, L3. But sometimes that doesn’t work, and then I bash my head against the wall.</p><p>Register pressure is even worse because that is only a problem because of the ISA, not the <a href="https://en.wikipedia.org/wiki/Microarchitecture">microarchitecture</a>. The hardware has enough registers, they just aren’t exposed to user code. You can try to split data between general-purpose registers and vector registers, and that works as long as you seldom cross the GPR-SIMD boundary, but at that point, you might as well <a href="https://github.com/docker/cli/issues/267#issuecomment-695149477">change your profession</a>.</p><p>It doesn’t have to be that way. <a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGAs</a> enable you to design your own hardware (kind of, anyway), and alternative approaches like <a href="https://en.wikipedia.org/wiki/Interaction_nets">interaction nets</a> have a chance to make software-specified operations as optimal as operations that are usually implemented in hardware. But that’s not the world we live in, no, we live in the world where Intel keeps introducing useful instructions to AVX-512 only to abandon them later, so I need to choose between a CPU with <code>vp2intersect</code> or with <a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format">FP16</a>. So not only do you have to benchmark different code, you also have to test it on different CPUs to decide which EC2 instance to deploy it on.</p><p>The only advice I have for this is to try to achieve the best possible result, even if it’s worse than the theoretical optimum. Reduce the size of one of the LUTs by moving some calculations to runtime, rewrite a chunk of code in assembly to manage registers better, and when all else fails, accept that you have to make a choice.</p><p>“Compilers are smarter than humans” is a common mantra. It couldn’t be further from the truth. Any developer can see that the following two snippets are (supposed to be) equivalent:</p><pre><code><span>let</span> <span>condition1</span> = HashSet::<span>from</span>([a, b]).<span>contains</span>(&amp;c);
<span>let</span> <span>condition2</span> = a == c || b == c;
</code></pre><p>But compilers aren’t going to optimize the former into the latter (<a href="https://4comprehension.com/the-curious-case-of-jdk9-immutable-collections/">JVM’s JIT, in some cases, excluded</a>). They don’t reason in abstractions, and they certainly don’t reason in <em>your</em> auxiliary abstractions. This doesn’t just apply to high-level code: LLVM <a href="https://godbolt.org/z/j3ehhr3KT">does not even understand</a> that bitwise AND is an intersection.</p><p>No, compilers excel at something different from optimization: they turn higher-level languages into zero-cost abstractions, but there’s no ingenuity. Compilers are optimal transpilers – barring a few exceptions, they codegen exactly what you wrote in the source. They allow you to write assembly with the syntax and capabilities of Rust or C++, but don’t you dare forget that the <code>arr.map(|x| x / c)</code> you wrote will invoke <code>idiv</code> without performing obvious <a href="https://github.com/ridiculousfish/libdivide">libdivide</a>-style precalculations.</p><p>Sometimes I wonder if <code>-O2</code> should be renamed to <code>-fzero-cost-abstractions</code>.</p><p>This might make it sound like I’m arguing that compilers are only good at plumbing, but they aren’t even good at that. For example, they can be terrible at register allocation of all things. If a rarely executed chunk of code needs many registers, GCC satisfies that need by <a href="https://godbolt.org/z/53o1vdsfj">spilling variables accessed by the hot path</a> <em>on every iteration</em>, not only on entry to cold path. Clang handles this simple example better but fails in more complicated cases.</p><p>The lesson is never to trust the compiler blindly. Always check the disassembly, consult an instruction-level profiler like <code>perf</code>, and don’t be afraid to use this information to nudge the compiler to do the right thing if it leads to tangible improvements.</p><p>Despite obvious shortcomings, compilers don’t allow you to correct them on things they get wrong. There is no way to provide both optimized assembly and equivalent C code and let the compiler use the former in the general case and the latter in special cases. Custom calling conventions are mostly unsupported, and so is choosing between branchless and branchy code and any other assembly tricks. There are intrinsics, but LLVM and rustc <em>still</em> try to be smart and rewrite them, which sometimes causes pessimizations, leaving no alternative but to add an optimization barrier.</p><p><a href="https://egraphs-good.github.io/">e-graphs</a>, as popularized by <a href="https://cranelift.dev/">Cranelift</a>, try to tackle this problem, but to my knowledge, there hasn’t been much success in this field. I’m still hopeful, though.</p><p>For x86 processors, <a href="https://uops.info/table.html">uops.info</a> provides timing and port information for each instruction and many Intel and AMD CPUs. <a href="https://www.agner.org/optimize/">Agner Fog</a> wrote a manual on optimization for x86 processors and publishes his own tables. <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html">Intel Software Developer’s Manual</a> contains more than 5000 pages documenting not only the instruction set but many internal workings of their CPUs as well.</p><p>Apple Silicon has <em>nothing</em> like that. I have no goddamn idea how to work with M1+ processors. There’s <a href="https://dn721600.ca.archive.org/0/items/apple-silicon-cpu-optimization-guide/Apple-Silicon-CPU-Optimization-Guide.pdf">Apple Silicon CPU Optimization Guide</a>, which contains only 169 pages and reads like something people would write for novices, not experts. It reads like a tutorial you might find on HN, not something I would be interested in. It contains estimates of latencies and throughputs for some categories of instructions, but there’s frustratingly little tabular data, and it doesn’t mention <a href="https://stackoverflow.com/questions/56413517/what-is-instruction-fusion-in-contemporary-x86-processors">uop fusion</a> or provide port information. <a href="https://dougallj.github.io/applecpu/firestorm.html">Dougall Johnson’s research</a> is immensely valuable but only covers M1, not newer CPUs, and it still doesn’t answer many questions.</p><p>Even <a href="https://github.com/swiftlang/llvm-project/tree/next/llvm/lib/Target/AArch64">Apple’s LLVM fork</a> lacks scheduling annotations for Apple Silicon. How am I supposed to write efficient code when Apple doesn’t bother to tune their own compiler? Optimizing code for such a platform is 90% reverse engineering and 10% writing meaningful code – and writing meaningful code is already hard.</p><p>The right fix for this is to commit intellectual property theft, but I’m not allowed to say that, so I won’t. Oops.</p><p>Performance optimization is hard because you have to:</p><ul><li>Explore dozens of cases manually without losing your mind.</li><li>Iterate with inadequate tooling. (Profilers and <a href="https://llvm.org/docs/CommandGuide/llvm-mca.html">MCA</a> are useful, but they’re still toys that can’t match the underlying complexity.)</li><li><s>Jam squares into round holes until they fit.</s> Merge incompatible optimizations.</li><li>Deal with both corporate greed and cultural apathy.</li></ul><p>It’s not easy by any means, but it’s still something I enjoy doing, even though people often consider anything short of radical improvements a waste of time. To me, a 10% optimization is a form of art, but it’s not just that. Small improvements compound and help form a better user experience, even if no single optimization seems valuable on its own – much like improving data transfer rates has led to structural changes in how we process and utilize information.</p><p>Optimizations save time, and time is the one resource people don’t get enough of.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Programming languages should have a tree traversal primitive (126 pts)]]></title>
            <link>https://blog.tylerglaiel.com/p/programming-languages-should-have</link>
            <guid>43831628</guid>
            <pubDate>Tue, 29 Apr 2025 12:23:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.tylerglaiel.com/p/programming-languages-should-have">https://blog.tylerglaiel.com/p/programming-languages-should-have</a>, See on <a href="https://news.ycombinator.com/item?id=43831628">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>There should be a control flow construct in programming languages that can handle tree-like traversal in a nice way, similar to how for/foreach loops can handle linear traversal. It's a bit of a missing gap in the current set of control flow constructs most languages these days have settled on. Its a thing I end up having to do *all the time* and it seems like there should be some shortcuts for it.</p><p>I posted a thought about this recently and was thinking about how I would want something like that to look like. I can't find anything similar in any other languages. I'm most familiar with C++, so my sample code here is going to be C++-ish, but its general enough that you could fit it into basically anything else. I'm not a language design expert, so this is more of a loose idea than a formal proposal. </p><pre><code>for_tree(Node* N = mytreeroot; N != NULL; N : {N-&gt;left, N-&gt;right}){
	print(N-&gt;value);
}</code></pre><p>with the specifics removed, this is *almost* the same syntax as an existing for loop</p><pre><code>for_tree(init; condition; branch){
	//body
}</code></pre><p>It's basically a for loop that branches instead of continuing linearly. </p><p><span>"</span><strong>init</strong><span>" here runs when you enter the for_tree loop, exactly the same as a normal for loop</span><br><span>"</span><strong>condition</strong><span>" must be met to enter the body of the loop</span><br><span>"</span><strong>branch</strong><span>" evolves the initial value into multiple branches (it would have to compile down into recursive function calls here)</span></p><p>Well, this is significantly easier and less error prone than implementing recursive functions for every operation you'd want to do on every type of tree, plus all the relevant code ends up in-place and readable. This would likely compile down to the same code that a recursive function would anyway. It's just a nice shortcut, the same way for is a nice shortcut for gotos and labels.</p><pre><code>for_tree(Node* N = mytreeroot; N != NULL; N : {N-&gt;left, N-&gt;right}){
	print(N-&gt;value);
}</code></pre><p>would compile down into the equivalent of</p><pre><code>void for_tree_internal(Node* N){
	print(N-&gt;value);
	for(Node* n2 : {N-&gt;left, N-&gt;right}){
		if(n2 != NULL){
			for_tree_internal(n2);
		}
	}
}
for_tree_internal(mytreeroot);</code></pre><p>Doesn't for_tree(...) look a lot nicer and simpler and less error prone than needing to implement a recursive function for each operation you would want to do on a tree?</p><p>Additionally, for_tree would offer a few more benefits that you couldn't easily do with a recursive function, for instance being able to use break, continue, and return from within the function body. Those would behave similarly to how a for loop does.</p><pre><code>for_tree(Node* N = mytreeroot; N != NULL; N : {N-&gt;left, N-&gt;right}){
	if(N-&gt;value == 10) {
		found = true;
		break; //would break out of the entire for_tree block,
                       //unwinding the stack in the process
	}
}</code></pre><p>There is an additional flow construct that could be added here, "prune", which would prevent the loop from traversing into the branches off of the current node. </p><pre><code>for_tree(Node* N = mytreeroot; N != NULL; N : {N-&gt;left, N-&gt;right}){
	if(N-&gt;value == 10) {
		prune; //dont need to check any children of this node
	}
}</code></pre><p>Well a range based for loop requires that your tree exist in memory AND that you have an iterator defined for your tree. With for_tree you could operate on an entirely imperative tree, without needing to define any iterators or generator functions. Here's an example where I'm checking every single string composed of "a", "b", and "c" of length 8 or less.</p><pre><code>for_tree(string x = ""; x.size() &lt;= 8; x : {x+"a", x+"b", x+"c"}){
	print(x);
}</code></pre><p>This is an operation that requires "tree-like traversal" but is not iterating over a data structure that exists in memory. You can do that entire thing inside for_tree. It's entirely agnostic to any underlying data structures you are or aren't using. The "prune" flow described earlier is also something you can't get from a range based for loop. </p><p>There is a bit of a footgun here, which is that in that above string example its actually generating and rejecting all of the strings of length 9. A normal for loop *also* reaches the state after its last valid state before exiting, its just kind of not that much of an issue with a linear for loop where that will usually be like, one extra addition and conditional check. On the other hand, "one level deeper" in a tree traversal means checking the validity of multiple times as many leaf nodes as you need to. </p><p>You could resolve this manually in multiple ways, generate an empty branch list if you are at a leaf already</p><pre><code>for_tree(string x = ""; x.size() &lt;= 8; 
x : x.size() &lt; 8 ? {x+"a", x+"b", x+"c"} : {}){
	print(x);
}</code></pre><p>or just prune in the function body</p><pre><code>for_tree(string x = ""; x.size() &lt;= 8; x : {x+"a", x+"b", x+"c"}){
	print(x);
	if(x.size() == 8) prune;
}</code></pre><p>There may be a better way to resolve that, but would have to pull the syntax further away from a for loop I think. Anyway.</p><p><span>So, a depth first search is pretty simple, uses minimal extra memory, and works great with the stack that we are already using. BFS requires a lot of extra memory (enough that it would likely need to use the heap) and is more complex. If you really wanted to you could do an alternate function like for_tree_breadth_first(...), but I think the extra complexity needed for a BFS might be too much for a “primitive” construct.</span><br></p><p><span>Anyway, as a bonus here's a test C++ implementation that tries to get as close to this as possible with a bunch of templates and macros. The usage is uglier, and a few constructs do not work (ex, you cant return from within a for_tree here), but its kind of a neat proof of concept I think.</span><br></p><div itemprop="text" id="gist137690106" data-color-mode="light" data-light-theme="light" data-attrs="{&quot;innerHTML&quot;:&quot;<div id=\&quot;gist137690106\&quot; class=\&quot;gist\&quot;>\n    <div class=\&quot;gist-file\&quot; translate=\&quot;no\&quot; data-color-mode=\&quot;light\&quot; data-light-theme=\&quot;light\&quot;>\n      <div class=\&quot;gist-data\&quot;>\n        <div class=\&quot;js-gist-file-update-container js-task-list-container\&quot;>\n  <div id=\&quot;file-treetraversal-cpp\&quot; class=\&quot;file my-2\&quot;>\n    \n    <div itemprop=\&quot;text\&quot;\n      class=\&quot;Box-body p-0 blob-wrapper data type-c  \&quot;\n      style=\&quot;overflow: auto\&quot; tabindex=\&quot;0\&quot; role=\&quot;region\&quot;\n      aria-label=\&quot;treetraversal.cpp content, created by TylerGlaiel on 03:36AM today.\&quot;\n    >\n\n        \n<div class=\&quot;js-check-hidden-unicode js-blob-code-container blob-code-content\&quot;>\n\n  <template class=\&quot;js-file-alert-template\&quot;>\n  <div data-view-component=\&quot;true\&quot; class=\&quot;flash flash-warn flash-full d-flex flex-items-center\&quot;>\n  <svg aria-hidden=\&quot;true\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 16 16\&quot; version=\&quot;1.1\&quot; width=\&quot;16\&quot; data-view-component=\&quot;true\&quot; class=\&quot;octicon octicon-alert\&quot;>\n    <path d=\&quot;M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\&quot;></path>\n</svg>\n    <span>\n      This file contains hidden or bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.\n      <a class=\&quot;Link--inTextBlock\&quot; href=\&quot;https://github.co/hiddenchars\&quot; target=\&quot;_blank\&quot;>Learn more about bidirectional Unicode characters</a>\n    </span>\n\n\n  <div data-view-component=\&quot;true\&quot; class=\&quot;flash-action\&quot;>        <a href=\&quot;{{ revealButtonHref }}\&quot; data-view-component=\&quot;true\&quot; class=\&quot;btn-sm btn\&quot;>    Show hidden characters\n</a>\n</div>\n</div></template>\n<template class=\&quot;js-line-alert-template\&quot;>\n  <span aria-label=\&quot;This line has hidden Unicode characters\&quot; data-view-component=\&quot;true\&quot; class=\&quot;line-alert tooltipped tooltipped-e\&quot;>\n    <svg aria-hidden=\&quot;true\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 16 16\&quot; version=\&quot;1.1\&quot; width=\&quot;16\&quot; data-view-component=\&quot;true\&quot; class=\&quot;octicon octicon-alert\&quot;>\n    <path d=\&quot;M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z\&quot;></path>\n</svg>\n</span></template>\n\n  <table data-hpc class=\&quot;highlight tab-size js-file-line-container\&quot; data-tab-size=\&quot;8\&quot; data-paste-markdown-skip data-tagsearch-path=\&quot;treetraversal.cpp\&quot;>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L1\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;1\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC1\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>#<span class=\&quot;pl-k\&quot;>include</span> <span class=\&quot;pl-s\&quot;><span class=\&quot;pl-pds\&quot;>&amp;lt;</span>vector<span class=\&quot;pl-pds\&quot;>&amp;gt;</span></span></td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L2\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;2\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC2\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>#<span class=\&quot;pl-k\&quot;>include</span> <span class=\&quot;pl-s\&quot;><span class=\&quot;pl-pds\&quot;>&amp;lt;</span>string<span class=\&quot;pl-pds\&quot;>&amp;gt;</span></span></td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L3\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;3\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC3\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>#<span class=\&quot;pl-k\&quot;>include</span> <span class=\&quot;pl-s\&quot;><span class=\&quot;pl-pds\&quot;>&amp;lt;</span>iostream<span class=\&quot;pl-pds\&quot;>&amp;gt;</span></span></td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L4\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;4\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC4\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>\n</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L5\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;5\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC5\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;><span class=\&quot;pl-k\&quot;>enum</span> <span class=\&quot;pl-k\&quot;>class</span> <span class=\&quot;pl-en\&quot;>_tree_return</span> {</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L6\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;6\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC6\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    Continue = <span class=\&quot;pl-c1\&quot;>0</span>,</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L7\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;7\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC7\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    Prune,</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L8\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;8\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC8\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    Break</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L9\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;9\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC9\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>};</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L10\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;10\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC10\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>\n</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L11\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;11\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC11\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;><span class=\&quot;pl-k\&quot;>template</span>&amp;lt;<span class=\&quot;pl-k\&quot;>typename</span> T, <span class=\&quot;pl-k\&quot;>typename</span> F1, <span class=\&quot;pl-k\&quot;>typename</span> F2, <span class=\&quot;pl-k\&quot;>typename</span> F3&amp;gt;</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L12\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;12\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC12\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>_tree_return _for_tree(T initial, F1 condition, F2 branch, F3 visit) {</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L13\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;13\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC13\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    _tree_return result = <span class=\&quot;pl-c1\&quot;>visit</span>(initial);</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L14\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;14\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC14\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    <span class=\&quot;pl-k\&quot;>if</span>(result == _tree_return::Break) <span class=\&quot;pl-k\&quot;>return</span> _tree_return::Break;</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L15\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;15\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC15\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>\n</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L16\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;16\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC16\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    <span class=\&quot;pl-k\&quot;>if</span>(result != _tree_return::Prune) {</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L17\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;17\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC17\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>        <span class=\&quot;pl-k\&quot;>for</span>(T subnode : <span class=\&quot;pl-c1\&quot;>branch</span>(initial)) {</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L18\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;18\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC18\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>            <span class=\&quot;pl-k\&quot;>if</span>(<span class=\&quot;pl-c1\&quot;>condition</span>(subnode)) {</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L19\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;19\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC19\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>                _tree_return result = <span class=\&quot;pl-c1\&quot;>_for_tree</span>(subnode, condition, branch, visit);</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L20\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;20\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC20\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>                <span class=\&quot;pl-k\&quot;>if</span>(result == _tree_return::Break) <span class=\&quot;pl-k\&quot;>return</span> _tree_return::Break;</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L21\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;21\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC21\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>            }</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L22\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;22\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC22\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>        }</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L23\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;23\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC23\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    }</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L24\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;24\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC24\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    <span class=\&quot;pl-k\&quot;>return</span> _tree_return::Continue;</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L25\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;25\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC25\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>}</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L26\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;26\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC26\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>\n</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L27\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;27\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC27\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>#<span class=\&quot;pl-k\&quot;>define</span> <span class=\&quot;pl-en\&quot;>tree_break</span> <span class=\&quot;pl-k\&quot;>return</span> _tree_return::Break</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L28\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;28\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC28\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>#<span class=\&quot;pl-k\&quot;>define</span> <span class=\&quot;pl-en\&quot;>tree_prune</span> <span class=\&quot;pl-k\&quot;>return</span> _tree_return::Prune</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L29\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;29\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC29\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>#<span class=\&quot;pl-k\&quot;>define</span> <span class=\&quot;pl-en\&quot;>tree_continue</span> <span class=\&quot;pl-k\&quot;>return</span> _tree_return::Continue</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L30\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;30\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC30\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>\n</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L31\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;31\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC31\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>                                                          <span class=\&quot;pl-c\&quot;><span class=\&quot;pl-c\&quot;>//</span>v-- semicolon to not allow you to get the return value here</span></td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L32\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;32\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC32\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>#<span class=\&quot;pl-k\&quot;>define</span> <span class=\&quot;pl-en\&quot;>for_tree</span>(<span class=\&quot;pl-v\&quot;>XName, Xinitial, Condition, Branch, Visit</span>) ;_for_tree(Xinitial, \\</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L33\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;33\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC33\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>[&amp;amp;](decltype(Xinitial) XName){ <span class=\&quot;pl-k\&quot;>return</span> Condition; }, \\</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L34\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;34\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC34\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>[&amp;amp;](decltype(Xinitial) XName){ <span class=\&quot;pl-k\&quot;>return</span> std::vector&amp;lt;<span class=\&quot;pl-c1\&quot;>decltype</span>(Xinitial)&amp;gt;Branch; }, \\</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L35\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;35\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC35\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>[&amp;amp;](decltype(Xinitial) XName){ Visit; <span class=\&quot;pl-k\&quot;>return</span> _tree_return::Continue; })</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L36\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;36\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC36\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;><span class=\&quot;pl-c\&quot;><span class=\&quot;pl-c\&quot;>//</span>excuse the use of a std::vector in there, I guess you cant return an initialize_list from a lambda</span></td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L37\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;37\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC37\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;><span class=\&quot;pl-c\&quot;><span class=\&quot;pl-c\&quot;>//</span>that wouldn&amp;#39;t really be an issue if this was implemented at the language level instead of hacked together from lambdas and macros</span></td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L38\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;38\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC38\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>\n</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L39\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;39\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC39\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;><span class=\&quot;pl-k\&quot;>struct</span> <span class=\&quot;pl-en\&quot;>Node</span> {</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L40\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;40\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC40\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    Node* left = <span class=\&quot;pl-c1\&quot;>NULL</span>;</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L41\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;41\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC41\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    Node* right = <span class=\&quot;pl-c1\&quot;>NULL</span>;</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L42\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;42\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC42\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    std::string value;</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L43\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;43\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC43\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    <span class=\&quot;pl-en\&quot;>Node</span>(std::string value):value(value){}</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L44\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;44\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC44\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>};</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L45\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;45\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC45\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>\n</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L46\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;46\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC46\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;><span class=\&quot;pl-k\&quot;>int</span> <span class=\&quot;pl-en\&quot;>main</span>() {</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L47\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;47\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC47\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    <span class=\&quot;pl-c\&quot;><span class=\&quot;pl-c\&quot;>//</span>syntax is a little uglier than it could be if it was native</span></td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L48\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;48\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC48\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    </td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L49\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;49\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC49\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    <span class=\&quot;pl-c\&quot;><span class=\&quot;pl-c\&quot;>//</span>imperative tree sample</span></td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L50\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;50\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC50\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    <span class=\&quot;pl-c1\&quot;>for_tree</span>(x, <span class=\&quot;pl-c1\&quot;>std::string</span>(<span class=\&quot;pl-s\&quot;><span class=\&quot;pl-pds\&quot;>&amp;quot;</span><span class=\&quot;pl-pds\&quot;>&amp;quot;</span></span>), x.<span class=\&quot;pl-c1\&quot;>size</span>()&amp;lt;=<span class=\&quot;pl-c1\&quot;>8</span>, ({x+<span class=\&quot;pl-s\&quot;><span class=\&quot;pl-pds\&quot;>&amp;quot;</span>a<span class=\&quot;pl-pds\&quot;>&amp;quot;</span></span>, x+<span class=\&quot;pl-s\&quot;><span class=\&quot;pl-pds\&quot;>&amp;quot;</span>b<span class=\&quot;pl-pds\&quot;>&amp;quot;</span></span>, x+<span class=\&quot;pl-s\&quot;><span class=\&quot;pl-pds\&quot;>&amp;quot;</span>c<span class=\&quot;pl-pds\&quot;>&amp;quot;</span></span>}), {</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L51\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;51\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC51\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>        std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; std::endl;</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L52\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;52\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC52\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    });</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L53\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;53\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC53\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    </td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L54\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;54\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC54\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    <span class=\&quot;pl-c\&quot;><span class=\&quot;pl-c\&quot;>//</span>tree structure sample</span></td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L55\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;55\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC55\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    Node <span class=\&quot;pl-smi\&quot;>mytree</span>(<span class=\&quot;pl-s\&quot;><span class=\&quot;pl-pds\&quot;>&amp;quot;</span>root<span class=\&quot;pl-pds\&quot;>&amp;quot;</span></span>);</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L56\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;56\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC56\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    mytree.<span class=\&quot;pl-smi\&quot;>left</span> = <span class=\&quot;pl-k\&quot;>new</span> <span class=\&quot;pl-c1\&quot;>Node</span>(<span class=\&quot;pl-s\&quot;><span class=\&quot;pl-pds\&quot;>&amp;quot;</span>left<span class=\&quot;pl-pds\&quot;>&amp;quot;</span></span>);</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L57\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;57\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC57\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    mytree.<span class=\&quot;pl-smi\&quot;>right</span> = <span class=\&quot;pl-k\&quot;>new</span> <span class=\&quot;pl-c1\&quot;>Node</span>(<span class=\&quot;pl-s\&quot;><span class=\&quot;pl-pds\&quot;>&amp;quot;</span>right<span class=\&quot;pl-pds\&quot;>&amp;quot;</span></span>);</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L58\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;58\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC58\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    mytree.<span class=\&quot;pl-smi\&quot;>left</span>-&amp;gt;<span class=\&quot;pl-smi\&quot;>left</span> = <span class=\&quot;pl-k\&quot;>new</span> <span class=\&quot;pl-c1\&quot;>Node</span>(<span class=\&quot;pl-s\&quot;><span class=\&quot;pl-pds\&quot;>&amp;quot;</span>leftleft<span class=\&quot;pl-pds\&quot;>&amp;quot;</span></span>);</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L59\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;59\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC59\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    </td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L60\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;60\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC60\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    <span class=\&quot;pl-c1\&quot;>for_tree</span>(x, &amp;amp;mytree, x != <span class=\&quot;pl-c1\&quot;>NULL</span>, ({x-&amp;gt;<span class=\&quot;pl-smi\&quot;>left</span>, x-&amp;gt;<span class=\&quot;pl-smi\&quot;>right</span>}), {</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L61\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;61\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC61\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>        std::cout &amp;lt;&amp;lt; x-&amp;gt;<span class=\&quot;pl-smi\&quot;>value</span> &amp;lt;&amp;lt; std::endl;</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L62\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;62\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC62\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    });</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L63\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;63\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC63\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>\n</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L64\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;64\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC64\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>    <span class=\&quot;pl-k\&quot;>return</span> <span class=\&quot;pl-c1\&quot;>0</span>;</td>\n        </tr>\n        <tr>\n          <td id=\&quot;file-treetraversal-cpp-L65\&quot; class=\&quot;blob-num js-line-number js-blob-rnum\&quot; data-line-number=\&quot;65\&quot;></td>\n          <td id=\&quot;file-treetraversal-cpp-LC65\&quot; class=\&quot;blob-code blob-code-inner js-file-line\&quot;>}</td>\n        </tr>\n  </table>\n</div>\n\n\n    </div>\n\n  </div>\n</div>\n\n      </div>\n      <div class=\&quot;gist-meta\&quot;>\n        <a href=\&quot;https://gist.github.com/TylerGlaiel/7b6fa06628883148e4403b3cc616fdec/raw/f0d4bf0e8043ae6c6bdad2146daddbe9d0cb3b88/treetraversal.cpp\&quot; style=\&quot;float:right\&quot; class=\&quot;Link--inTextBlock\&quot;>view raw</a>\n        <a href=\&quot;https://gist.github.com/TylerGlaiel/7b6fa06628883148e4403b3cc616fdec#file-treetraversal-cpp\&quot; class=\&quot;Link--inTextBlock\&quot;>\n          treetraversal.cpp\n        </a>\n        hosted with &amp;#10084; by <a class=\&quot;Link--inTextBlock\&quot; href=\&quot;https://github.com\&quot;>GitHub</a>\n      </div>\n    </div>\n</div>\n&quot;,&quot;stylesheet&quot;:&quot;https://github.githubassets.com/assets/gist-embed-b1ee75c43dbe.css&quot;}" data-component-name="GitgistToDOM"><div data-view-component="true"><p><span>
  
    

    </span><span><span>
      This file contains hidden or bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
      </span><a href="https://github.co/hiddenchars" target="_blank" rel="">Learn more about bidirectional Unicode characters</a><span>
    </span></span><span>


  </span></p></div><table data-hpc="" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-path="treetraversal.cpp"><tbody><tr><td id="file-treetraversal-cpp-L1" data-line-number="1"></td><td id="file-treetraversal-cpp-LC1"><span>#</span><span>include</span><span> </span><span><span>&lt;</span><span>vector</span><span>&gt;</span></span></td></tr><tr><td id="file-treetraversal-cpp-L2" data-line-number="2"></td><td id="file-treetraversal-cpp-LC2"><span>#</span><span>include</span><span> </span><span><span>&lt;</span><span>string</span><span>&gt;</span></span></td></tr><tr><td id="file-treetraversal-cpp-L3" data-line-number="3"></td><td id="file-treetraversal-cpp-LC3"><span>#</span><span>include</span><span> </span><span><span>&lt;</span><span>iostream</span><span>&gt;</span></span></td></tr><tr><td id="file-treetraversal-cpp-L4" data-line-number="4"></td><td id="file-treetraversal-cpp-LC4">
</td></tr><tr><td id="file-treetraversal-cpp-L5" data-line-number="5"></td><td id="file-treetraversal-cpp-LC5"><span>enum</span><span> </span><span>class</span><span> </span><span>_tree_return</span><span> {</span></td></tr><tr><td id="file-treetraversal-cpp-L6" data-line-number="6"></td><td id="file-treetraversal-cpp-LC6"><span>    Continue = </span><span>0</span><span>,</span></td></tr><tr><td id="file-treetraversal-cpp-L7" data-line-number="7"></td><td id="file-treetraversal-cpp-LC7">    Prune,</td></tr><tr><td id="file-treetraversal-cpp-L8" data-line-number="8"></td><td id="file-treetraversal-cpp-LC8">    Break</td></tr><tr><td id="file-treetraversal-cpp-L9" data-line-number="9"></td><td id="file-treetraversal-cpp-LC9">};</td></tr><tr><td id="file-treetraversal-cpp-L10" data-line-number="10"></td><td id="file-treetraversal-cpp-LC10">
</td></tr><tr><td id="file-treetraversal-cpp-L11" data-line-number="11"></td><td id="file-treetraversal-cpp-LC11"><span>template</span><span>&lt;</span><span>typename</span><span> T, </span><span>typename</span><span> F1, </span><span>typename</span><span> F2, </span><span>typename</span><span> F3&gt;</span></td></tr><tr><td id="file-treetraversal-cpp-L12" data-line-number="12"></td><td id="file-treetraversal-cpp-LC12">_tree_return _for_tree(T initial, F1 condition, F2 branch, F3 visit) {</td></tr><tr><td id="file-treetraversal-cpp-L13" data-line-number="13"></td><td id="file-treetraversal-cpp-LC13"><span>    _tree_return result = </span><span>visit</span><span>(initial);</span></td></tr><tr><td id="file-treetraversal-cpp-L14" data-line-number="14"></td><td id="file-treetraversal-cpp-LC14"><span>    </span><span>if</span><span>(result == _tree_return::Break) </span><span>return</span><span> _tree_return::Break;</span></td></tr><tr><td id="file-treetraversal-cpp-L15" data-line-number="15"></td><td id="file-treetraversal-cpp-LC15">
</td></tr><tr><td id="file-treetraversal-cpp-L16" data-line-number="16"></td><td id="file-treetraversal-cpp-LC16"><span>    </span><span>if</span><span>(result != _tree_return::Prune) {</span></td></tr><tr><td id="file-treetraversal-cpp-L17" data-line-number="17"></td><td id="file-treetraversal-cpp-LC17"><span>        </span><span>for</span><span>(T subnode : </span><span>branch</span><span>(initial)) {</span></td></tr><tr><td id="file-treetraversal-cpp-L18" data-line-number="18"></td><td id="file-treetraversal-cpp-LC18"><span>            </span><span>if</span><span>(</span><span>condition</span><span>(subnode)) {</span></td></tr><tr><td id="file-treetraversal-cpp-L19" data-line-number="19"></td><td id="file-treetraversal-cpp-LC19"><span>                _tree_return result = </span><span>_for_tree</span><span>(subnode, condition, branch, visit);</span></td></tr><tr><td id="file-treetraversal-cpp-L20" data-line-number="20"></td><td id="file-treetraversal-cpp-LC20"><span>                </span><span>if</span><span>(result == _tree_return::Break) </span><span>return</span><span> _tree_return::Break;</span></td></tr><tr><td id="file-treetraversal-cpp-L21" data-line-number="21"></td><td id="file-treetraversal-cpp-LC21">            }</td></tr><tr><td id="file-treetraversal-cpp-L22" data-line-number="22"></td><td id="file-treetraversal-cpp-LC22">        }</td></tr><tr><td id="file-treetraversal-cpp-L23" data-line-number="23"></td><td id="file-treetraversal-cpp-LC23">    }</td></tr><tr><td id="file-treetraversal-cpp-L24" data-line-number="24"></td><td id="file-treetraversal-cpp-LC24"><span>    </span><span>return</span><span> _tree_return::Continue;</span></td></tr><tr><td id="file-treetraversal-cpp-L25" data-line-number="25"></td><td id="file-treetraversal-cpp-LC25">}</td></tr><tr><td id="file-treetraversal-cpp-L26" data-line-number="26"></td><td id="file-treetraversal-cpp-LC26">
</td></tr><tr><td id="file-treetraversal-cpp-L27" data-line-number="27"></td><td id="file-treetraversal-cpp-LC27"><span>#</span><span>define</span><span> </span><span>tree_break</span><span> </span><span>return</span><span> _tree_return::Break</span></td></tr><tr><td id="file-treetraversal-cpp-L28" data-line-number="28"></td><td id="file-treetraversal-cpp-LC28"><span>#</span><span>define</span><span> </span><span>tree_prune</span><span> </span><span>return</span><span> _tree_return::Prune</span></td></tr><tr><td id="file-treetraversal-cpp-L29" data-line-number="29"></td><td id="file-treetraversal-cpp-LC29"><span>#</span><span>define</span><span> </span><span>tree_continue</span><span> </span><span>return</span><span> _tree_return::Continue</span></td></tr><tr><td id="file-treetraversal-cpp-L30" data-line-number="30"></td><td id="file-treetraversal-cpp-LC30">
</td></tr><tr><td id="file-treetraversal-cpp-L31" data-line-number="31"></td><td id="file-treetraversal-cpp-LC31"><span>                                                          </span><span><span>//</span><span>v-- semicolon to not allow you to get the return value here</span></span></td></tr><tr><td id="file-treetraversal-cpp-L32" data-line-number="32"></td><td id="file-treetraversal-cpp-LC32"><span>#</span><span>define</span><span> </span><span>for_tree</span><span>(</span><span>XName, Xinitial, Condition, Branch, Visit</span><span>) ;_for_tree(Xinitial, \</span></td></tr><tr><td id="file-treetraversal-cpp-L33" data-line-number="33"></td><td id="file-treetraversal-cpp-LC33"><span>[&amp;](decltype(Xinitial) XName){ </span><span>return</span><span> Condition; }, \</span></td></tr><tr><td id="file-treetraversal-cpp-L34" data-line-number="34"></td><td id="file-treetraversal-cpp-LC34"><span>[&amp;](decltype(Xinitial) XName){ </span><span>return</span><span> std::vector&lt;</span><span>decltype</span><span>(Xinitial)&gt;Branch; }, \</span></td></tr><tr><td id="file-treetraversal-cpp-L35" data-line-number="35"></td><td id="file-treetraversal-cpp-LC35"><span>[&amp;](decltype(Xinitial) XName){ Visit; </span><span>return</span><span> _tree_return::Continue; })</span></td></tr><tr><td id="file-treetraversal-cpp-L36" data-line-number="36"></td><td id="file-treetraversal-cpp-LC36"><span><span>//</span><span>excuse the use of a std::vector in there, I guess you cant return an initialize_list from a lambda</span></span></td></tr><tr><td id="file-treetraversal-cpp-L37" data-line-number="37"></td><td id="file-treetraversal-cpp-LC37"><span><span>//</span><span>that wouldn't really be an issue if this was implemented at the language level instead of hacked together from lambdas and macros</span></span></td></tr><tr><td id="file-treetraversal-cpp-L38" data-line-number="38"></td><td id="file-treetraversal-cpp-LC38">
</td></tr><tr><td id="file-treetraversal-cpp-L39" data-line-number="39"></td><td id="file-treetraversal-cpp-LC39"><span>struct</span><span> </span><span>Node</span><span> {</span></td></tr><tr><td id="file-treetraversal-cpp-L40" data-line-number="40"></td><td id="file-treetraversal-cpp-LC40"><span>    Node* left = </span><span>NULL</span><span>;</span></td></tr><tr><td id="file-treetraversal-cpp-L41" data-line-number="41"></td><td id="file-treetraversal-cpp-LC41"><span>    Node* right = </span><span>NULL</span><span>;</span></td></tr><tr><td id="file-treetraversal-cpp-L42" data-line-number="42"></td><td id="file-treetraversal-cpp-LC42">    std::string value;</td></tr><tr><td id="file-treetraversal-cpp-L43" data-line-number="43"></td><td id="file-treetraversal-cpp-LC43"><span>    </span><span>Node</span><span>(std::string value):value(value){}</span></td></tr><tr><td id="file-treetraversal-cpp-L44" data-line-number="44"></td><td id="file-treetraversal-cpp-LC44">};</td></tr><tr><td id="file-treetraversal-cpp-L45" data-line-number="45"></td><td id="file-treetraversal-cpp-LC45">
</td></tr><tr><td id="file-treetraversal-cpp-L46" data-line-number="46"></td><td id="file-treetraversal-cpp-LC46"><span>int</span><span> </span><span>main</span><span>() {</span></td></tr><tr><td id="file-treetraversal-cpp-L47" data-line-number="47"></td><td id="file-treetraversal-cpp-LC47"><span>    </span><span><span>//</span><span>syntax is a little uglier than it could be if it was native</span></span></td></tr><tr><td id="file-treetraversal-cpp-L48" data-line-number="48"></td><td id="file-treetraversal-cpp-LC48">    </td></tr><tr><td id="file-treetraversal-cpp-L49" data-line-number="49"></td><td id="file-treetraversal-cpp-LC49"><span>    </span><span><span>//</span><span>imperative tree sample</span></span></td></tr><tr><td id="file-treetraversal-cpp-L50" data-line-number="50"></td><td id="file-treetraversal-cpp-LC50"><span>    </span><span>for_tree</span><span>(x, </span><span>std::string</span><span>(</span><span><span>"</span><span>"</span></span><span>), x.</span><span>size</span><span>()&lt;=</span><span>8</span><span>, ({x+</span><span><span>"</span><span>a</span><span>"</span></span><span>, x+</span><span><span>"</span><span>b</span><span>"</span></span><span>, x+</span><span><span>"</span><span>c</span><span>"</span></span><span>}), {</span></td></tr><tr><td id="file-treetraversal-cpp-L51" data-line-number="51"></td><td id="file-treetraversal-cpp-LC51">        std::cout &lt;&lt; x &lt;&lt; std::endl;</td></tr><tr><td id="file-treetraversal-cpp-L52" data-line-number="52"></td><td id="file-treetraversal-cpp-LC52">    });</td></tr><tr><td id="file-treetraversal-cpp-L53" data-line-number="53"></td><td id="file-treetraversal-cpp-LC53">    </td></tr><tr><td id="file-treetraversal-cpp-L54" data-line-number="54"></td><td id="file-treetraversal-cpp-LC54"><span>    </span><span><span>//</span><span>tree structure sample</span></span></td></tr><tr><td id="file-treetraversal-cpp-L55" data-line-number="55"></td><td id="file-treetraversal-cpp-LC55"><span>    Node </span><span>mytree</span><span>(</span><span><span>"</span><span>root</span><span>"</span></span><span>);</span></td></tr><tr><td id="file-treetraversal-cpp-L56" data-line-number="56"></td><td id="file-treetraversal-cpp-LC56"><span>    mytree.</span><span>left</span><span> = </span><span>new</span><span> </span><span>Node</span><span>(</span><span><span>"</span><span>left</span><span>"</span></span><span>);</span></td></tr><tr><td id="file-treetraversal-cpp-L57" data-line-number="57"></td><td id="file-treetraversal-cpp-LC57"><span>    mytree.</span><span>right</span><span> = </span><span>new</span><span> </span><span>Node</span><span>(</span><span><span>"</span><span>right</span><span>"</span></span><span>);</span></td></tr><tr><td id="file-treetraversal-cpp-L58" data-line-number="58"></td><td id="file-treetraversal-cpp-LC58"><span>    mytree.</span><span>left</span><span>-&gt;</span><span>left</span><span> = </span><span>new</span><span> </span><span>Node</span><span>(</span><span><span>"</span><span>leftleft</span><span>"</span></span><span>);</span></td></tr><tr><td id="file-treetraversal-cpp-L59" data-line-number="59"></td><td id="file-treetraversal-cpp-LC59">    </td></tr><tr><td id="file-treetraversal-cpp-L60" data-line-number="60"></td><td id="file-treetraversal-cpp-LC60"><span>    </span><span>for_tree</span><span>(x, &amp;mytree, x != </span><span>NULL</span><span>, ({x-&gt;</span><span>left</span><span>, x-&gt;</span><span>right</span><span>}), {</span></td></tr><tr><td id="file-treetraversal-cpp-L61" data-line-number="61"></td><td id="file-treetraversal-cpp-LC61"><span>        std::cout &lt;&lt; x-&gt;</span><span>value</span><span> &lt;&lt; std::endl;</span></td></tr><tr><td id="file-treetraversal-cpp-L62" data-line-number="62"></td><td id="file-treetraversal-cpp-LC62">    });</td></tr><tr><td id="file-treetraversal-cpp-L63" data-line-number="63"></td><td id="file-treetraversal-cpp-LC63">
</td></tr><tr><td id="file-treetraversal-cpp-L64" data-line-number="64"></td><td id="file-treetraversal-cpp-LC64"><span>    </span><span>return</span><span> </span><span>0</span><span>;</span></td></tr><tr><td id="file-treetraversal-cpp-L65" data-line-number="65"></td><td id="file-treetraversal-cpp-LC65">}</td></tr></tbody></table></div></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[After 53 years, a failed Soviet Venus spacecraft is crashing back to Earth (111 pts)]]></title>
            <link>https://gizmodo.com/after-53-years-a-failed-soviet-venus-spacecraft-is-crashing-back-to-earth-2000595234</link>
            <guid>43831602</guid>
            <pubDate>Tue, 29 Apr 2025 12:20:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/after-53-years-a-failed-soviet-venus-spacecraft-is-crashing-back-to-earth-2000595234">https://gizmodo.com/after-53-years-a-failed-soviet-venus-spacecraft-is-crashing-back-to-earth-2000595234</a>, See on <a href="https://news.ycombinator.com/item?id=43831602">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              
              
              <p>A 53-year-old Venus probe that failed to escape low Earth orbit is expected to make an uncontrolled reentry in the coming weeks. Built to withstand extreme heat, parts of the spacecraft could survive the descent and crash on Earth.</p> <p>The lander module from an old Soviet spacecraft is expected to reenter Earth’s atmosphere during the second week of May, according to Marco Langbroek, a satellite tracker based in Leiden, the Netherlands. “As this is a lander that was designed to survive passage through the Venus atmosphere, it is possible that it will survive reentry through the Earth atmosphere intact, and impact intact,” Langbroek wrote in a blog <a href="https://sattrackcam.blogspot.com/2025/04/kosmos-842-descent-craft-reentry.html">update</a>. “The risks involved are not particularly high, but not zero.”</p> <p>Kosmos 482 launched on March 31, 1972 from the Baikonur Cosmodrome spaceport in Kazakhstan. The mission was an attempt by the Soviet space program to reach Venus, but it failed to gain enough velocity to enter a transfer trajectory toward the scorching-hot planet. A malfunction resulted in an engine burn that wasn’t sufficient to reach Venus’ orbit and left the spacecraft in an elliptical Earth orbit, according to <a href="https://nssdc.gsfc.nasa.gov/nmc/spacecraft/display.action?id=1972-023A">NASA</a>. The spacecraft broke apart into four different pieces, with two of the smaller fragments reentering over Ashburton, New Zealand, two days after launch. Meanwhile, two remaining pieces, believed to be the payload and the detached upper-stage engine unit, entered a higher orbit measuring 130 by 6,089 miles (210 by 9,800 kilometers).</p> <p>The failed mission consisted of a carrier bus and a lander probe, which together form a spherical pressure vessel weighing more than 1,000 pounds (495 kilograms). Considering its mass, “risks are similar to that of a meteorite impact,” Langbroek wrote.</p>

 <p>As of now, it’s hard to determine exactly when the spacecraft will reenter. Langbroek estimates that the reentry will take place on May 10, but a more precise date will get clearer as the reentry date nears. It’s hard to pin down an exact date because the Sun, now in its active phase, is heating and expanding Earth’s atmosphere; it’s creating more atmospheric drag on orbiting objects, causing them to reenter sooner.</p> <p>It’s also difficult to determine where the spacecraft’s remains will end up on Earth, since that depends on when it reenters the atmosphere and breaks apart. Generally, the chances of spacecraft debris landing in an inhabited area are low, with a greater likelihood of it falling into a remote part of the ocean. Still, uncontrolled reentries do pose a small risk that shouldn’t be overlooked or ignored.</p>
                          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pyrefly - A faster Python type checker written in Rust (102 pts)]]></title>
            <link>https://pyrefly.org/</link>
            <guid>43831524</guid>
            <pubDate>Tue, 29 Apr 2025 12:13:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pyrefly.org/">https://pyrefly.org/</a>, See on <a href="https://news.ycombinator.com/item?id=43831524">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__docusaurus_skipToContent_fallback"><header><section><img src="https://pyrefly.org/img/Pyrefly-Brandmark-Invert.svg" alt="Pyrefly Logo"></section><p><span>A faster Python type checker written in Rust</span></p><section><a href="https://github.com/facebook/pyrefly/milestone/1"> <!-- -->Github<!-- --> </a><a href="https://pyrefly.org/try/"> <!-- -->Demo<!-- --> </a><a href="https://pyrefly.org/en/docs/"> <!-- -->Docs<!-- --> </a></section><section><p>Launching Spring 2025</p></section><section><li id="firefly"></li><li id="firefly"></li><li id="firefly"></li><li id="firefly"></li><li id="firefly"></li></section></header></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A Chrome extension that will auto-reject non-essential cookies (161 pts)]]></title>
            <link>https://blog.bymitch.com/posts/reject-cookies/</link>
            <guid>43831298</guid>
            <pubDate>Tue, 29 Apr 2025 11:49:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.bymitch.com/posts/reject-cookies/">https://blog.bymitch.com/posts/reject-cookies/</a>, See on <a href="https://news.ycombinator.com/item?id=43831298">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p><a href="https://chromewebstore.google.com/detail/bnbodofigkfjljnopfggfoecokhmhamc?utm_source=item-share-cb">Add the extension</a></p>
<p><img src="https://blog.bymitch.com/reject-cookies/reject-cookies-no.png" alt="Reject Cookies Logo" title="Logo"></p>
<h2 id="a-chrome-extension">A Chrome Extension</h2>
<p>Everyone can agree that cookie consent banners are frustrating. It might be one of the few unifying factors on the internet today. Even though it’s a couple clicks, the couple clicks are a pain, and the couple clicks can happen on many sites each day.</p>
<p>There are browser extensions out there that will auto-accept cookies like <a href="https://chromewebstore.google.com/detail/i-dont-care-about-cookies/fihnjjcciajhdojfnbdddfaoknhalnja">I don’t care about cookies</a> and it’s open source fork <a href="https://chromewebstore.google.com/detail/i-still-dont-care-about-c/edibdbjcniadpccecjdfdjjppcpchdlm">I still don’t care about cookies</a>. You can even chain this extension with another that will auto-clean up your cookies. This is an adequate solution and ascribes to <a href="https://en.wikipedia.org/wiki/Unix_philosophy">unix philosophy</a>.</p>
<p>Additionally, there are extensions like <a href="https://ublockorigin.com/">uBlock Origin</a> with additional filters to help ignore these annoying pop ups. Or <a href="https://privacybadger.org/">Privacy Badger</a> to block cookie trackers. Although there is space to provide an extension that just auto-rejects non essential cookies.</p>
<p>That’s what led to the “Reject Cookies” chrome extension. It will first attempt to reject the cookies on the page. If that is unsuccessful, it will then attempt to close the cookie pop up or banner. To comply with the regulations governing cookies under the <a href="https://gdpr.eu/cookies/">GDPR and the ePrivacy Directive you must</a></p>
<blockquote>
<p>Receive users’ consent before you use any cookies except strictly necessary cookies.</p>
</blockquote>
<p>So the omission of an acceptance should be on par with an explicit rejection. If you’re interested in how it works the code is <a href="https://github.com/mitch292/reject-cookies">open source and on github</a>, but let’s step through it at a high level.</p>
<h2 id="how-its-implemented">How it’s implemented</h2>
<p>Vibe coding is the answer. I leveraged Cursor and let it auto-select the model. This combination while extremely useful, did not serve me as well as recent past experience. On the project setup front, I had not previously written a Chrome extension. Having the Cursor agent set up the boilerplate was convenient. Although, it requested too liberal of permissions in the permissions to start and wouldn’t go and update them as the design of the app changed. Below is a snippet of the <code>manifest.json</code> to show what the permissions ended up looking like.</p>
<div><pre tabindex="0"><code data-lang="json"><span><span>{
</span></span><span><span>  <span>"permissions"</span>: [<span>"activeTab"</span>, <span>"sidePanel"</span>, <span>"tabs"</span>],
</span></span><span><span>  <span>"content_scripts"</span>: [
</span></span><span><span>    {
</span></span><span><span>      <span>"matches"</span>: [<span>"http://*/*"</span>, <span>"https://*/*"</span>],
</span></span><span><span>      <span>"js"</span>: [<span>"content.js"</span>]
</span></span><span><span>    }
</span></span><span><span>  ]
</span></span><span><span>}
</span></span></code></pre></div><p>Next on the implementation side of things, it started with a set of common selectors that could possibly be relevant to non-essential cookies. The problem was once again these selectors were extremely liberal things like elements with the class “accept”. I opted to take a more targeted approach and aim the logic at specific cookie consent vendors that most sites seem to leverage. Cursor’s agent was, as expected, not able to help much with this implementation.</p>
<p>The extension will go through the configured providers.</p>
<div><pre tabindex="0"><code data-lang="typescript"><span><span><span>const</span> <span>findAndClickRejectButtons</span> <span>=</span> () <span>=&gt;</span> {
</span></span><span><span>	<span>commonCookiePopupChecks</span>.<span>forEach</span>(({ <span>check</span>, <span>rejectOrClose</span> }) <span>=&gt;</span> {
</span></span><span><span>	  <span>if</span> (<span>check</span>()) {
</span></span><span><span>		<span>rejectOrClose</span>();
</span></span><span><span>		<span>// assume that there is only one cookie consent provider and we can exit
</span></span></span><span><span><span></span>		<span>return</span>;
</span></span><span><span>	  }
</span></span><span><span>	});
</span></span><span><span>  }
</span></span></code></pre></div><p>A check for a provider will look for a specific element that identifies it.</p>
<div><pre tabindex="0"><code data-lang="typescript"><span><span><span>const</span> <span>checkForOneTrust</span> <span>=</span> ()<span>:</span> <span>boolean</span> <span>=&gt;</span> <span>!!</span>document.<span>getElementById</span>(<span>'onetrust-consent-sdk'</span>);
</span></span></code></pre></div><p>Then attempt to reject the cookies and fallback to removing the consent banner or popup if it’s not able to reject the non-essential cookies.</p>
<div><pre tabindex="0"><code data-lang="typescript"><span><span><span>const</span> <span>closeOrRejectOneTrust</span> <span>=</span> () <span>=&gt;</span> {
</span></span><span><span>  <span>const</span> <span>rejectButton</span> <span>=</span> document.<span>getElementById</span>(<span>'onetrust-reject-all-handler'</span>);
</span></span><span><span>  <span>if</span> (<span>rejectButton</span>) {
</span></span><span><span>    <span>rejectButton</span>.<span>click</span>();
</span></span><span><span>    <span>return</span> <span>true</span>;
</span></span><span><span>  }
</span></span><span><span>
</span></span><span><span>  <span>const</span> <span>consentSDK</span> <span>=</span> document.<span>getElementById</span>(<span>'onetrust-consent-sdk'</span>);
</span></span><span><span>  <span>if</span> (<span>consentSDK</span>) {
</span></span><span><span>    <span>consentSDK</span>.<span>remove</span>();
</span></span><span><span>    <span>return</span> <span>true</span>;
</span></span><span><span>  }
</span></span><span><span>  <span>return</span> <span>false</span>;
</span></span><span><span>};
</span></span></code></pre></div><p>Not much more to it other than that.</p>
<p><img src="https://blog.bymitch.com/reject-cookies/reject-cookies-umbrella.png" alt="Reject Cookies Umbrella" title="Umbrella"></p>
<h2 id="help-it-get-better">Help it get better</h2>
<p><strong>Reject Cookies is still a work in progress.</strong> It can use your support to help cover more use cases and report bugs. As mentioned the design targets specific cookie consent implementations from different vendors. There are more vendors out there and different flavors of each vendors implementation. The side panel allows you to report sites where the cookie consent rejection was missed along with a place to report bugs or issues with the extension. The side panel can be accessed by clicking on the chrome extension’s menu in Chrome. You can also feel free to reach out to <a href="https://blog.bymitch.com/cdn-cgi/l/email-protection#81e8efe7eec1e3f8ece8f5e2e9afe2eeec"><span data-cfemail="5e373038311e3c2733372a3d36703d3133">[email&nbsp;protected]</span></a> with any feedback.</p>
<p><img src="https://blog.bymitch.com/reject-cookies/side-panel.png" alt="Side panel debugging screenshot" title="Side Panel"></p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Heart disease deaths worldwide linked to chemical widely used in plastics (188 pts)]]></title>
            <link>https://medicalxpress.com/news/2025-04-heart-disease-deaths-worldwide-linked.html</link>
            <guid>43831142</guid>
            <pubDate>Tue, 29 Apr 2025 11:35:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2025-04-heart-disease-deaths-worldwide-linked.html">https://medicalxpress.com/news/2025-04-heart-disease-deaths-worldwide-linked.html</a>, See on <a href="https://news.ycombinator.com/item?id=43831142">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2025/detergent-bottle.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2025/detergent-bottle.jpg" data-sub-html="Credit: Unsplash/CC0 Public Domain">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2025/detergent-bottle.jpg" alt="detergent bottle" title="Credit: Unsplash/CC0 Public Domain" width="800" height="530">
             <figcaption>
                Credit: Unsplash/CC0 Public Domain
            </figcaption>        </figure>
    </div><p>Daily exposure to certain chemicals used to make plastic household items could be linked to more than 365,000 global deaths from heart disease in 2018 alone, a new analysis of population surveys shows.</p>

                                        
                                                                                  
                                         

                                                                                                                                    <p>While the chemicals, called phthalates, are in widespread use globally, Africa, South Asia, and the Middle East populations bore a much larger share of the death toll than others—about half the total.</p>
<p>For decades, experts have connected health problems to exposure to certain phthalates found in cosmetics, detergents, solvents, plastic pipes, bug repellents, and other products. When these chemicals break down into microscopic particles and are ingested, studies have linked them to an increased risk of conditions ranging from obesity and diabetes to fertility issues and cancer.</p>
<p>Led by researchers at NYU Langone Health, the current study focused on a kind of phthalate called di-2-ethylhexyl phthalate (DEHP), which is used to make food containers, medical equipment, and other plastic softer and more flexible. Exposure has been shown in other studies to prompt an overactive immune response (inflammation) in the heart's arteries, which, over time, is associated with an increased risk of heart attack or stroke.</p>
<p>In their new analysis, the authors estimated that DEHP exposure contributed to 368,764 deaths, or more than 10% of all global mortality from <a href="https://medicalxpress.com/tags/heart+disease/" rel="tag">heart disease</a> in 2018 among men and women aged 55 through 64. A report on the findings is published in the journal <i>eBioMedicine</i>.</p>
<p>"By highlighting the connection between phthalates and a leading cause of death across the world, our findings add to the vast body of evidence that these chemicals present a tremendous danger to human health," said study lead author Sara Hyman, BS, an associate research scientist at NYU Grossman School of Medicine.</p>

                                                                                                                                                         
                                                                                                                                                                                                <p>According to the authors, the resulting economic burden from the deaths identified in their study was estimated to be around $510 billion and may have reached as high as $3.74 trillion.</p>
<p>In a past study from 2021, the research team tied phthalates to more than 50,000 premature deaths each year, mostly from heart disease, among older Americans. Their latest investigation is believed to be the first global estimate to date of cardiovascular mortality—or indeed any health outcome—resulting from exposure to the chemicals, says Hyman, who is also a graduate student at NYU School of Public Global Health.</p>
<p>For the research, the team used health and environmental data from dozens of population surveys to estimate DEHP exposure across 200 countries and territories. The information included urine samples containing chemical breakdown products left by the plastic additive. Mortality data was obtained from the Institute for Health Metrics and Evaluation, a research group in the US that collects medical information worldwide to identify trends in public health.</p>
<p>Among the key findings, the study showed that losses in Africa and in the combined region of East Asia and the Middle East accounted, respectively, for 30% and 25% of the mortality from heart disease linked to DEHP. Specifically, India had the highest death count at 39,677 deaths, followed by Pakistan and Egypt.</p>
<p>The larger heart death risks in these populations held true even after the researchers adjusted their statistical analysis to take into account population size within the studied age group.</p>

                                                                                                                                            <p>A possible explanation, the authors say, is that these countries face higher rates of exposure to the chemicals, possibly because they are undergoing a boom in plastic production but with fewer manufacturing restrictions than other regions.</p>
<p>"There is a clear disparity in which parts of the world bear the brunt of heightened heart risks from phthalates," said study senior author Leonardo Trasande, MD, MPP.</p>
<p>"Our results underscore the urgent need for global regulations to reduce exposure to these toxins, especially in areas most affected by rapid industrialization and plastic consumption," added Trasande, the Jim G. Hendrick, MD, Professor of Pediatrics at NYU Grossman School of Medicine.</p>
<p>Trasande, who is also a professor in the Department of Population Health, cautions that the analysis was not designed to establish that DEHP directly or alone caused heart disease and that higher death risks did not take into account other types of phthalates. Nor did it include mortality among those in other age groups. As a result, the overall death toll from heart disease connected to these chemicals is likely much higher, he says.</p>
<p>Trasande says that the researchers next plan to track how reductions in <a href="https://medicalxpress.com/tags/phthalate/" rel="tag">phthalate</a> exposure may, over time, affect global mortality rates, as well as to expand the study to other health concerns posed by the chemicals, such as preterm birth. Trasande also serves as director of NYU Grossman School of Medicine's Division of Environmental Pediatrics and the Center for the Investigation of Environmental Hazards.</p>

                                                                                                                                                                            
                                        											<div>
												                                                    <p><strong>More information:</strong>
                                                    Phthalate exposure from plastics and cardiovascular disease: global estimates of attributable mortality and years life lost, <i>eBioMedicine</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1016/j.ebiom.2025.105730" target="_blank">DOI: 10.1016/j.ebiom.2025.105730</a>
																								
																								</p>
																							</div>
                                        											
																					
                                                                                                                        
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Heart disease deaths worldwide linked to chemical widely used in plastics (2025, April 29)
                                                 retrieved 29 April 2025
                                                 from https://medicalxpress.com/news/2025-04-heart-disease-deaths-worldwide-linked.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon to display tariff costs for consumers (422 pts)]]></title>
            <link>https://punchbowl.news/article/tech/amazon-display-tariff-costs/</link>
            <guid>43831027</guid>
            <pubDate>Tue, 29 Apr 2025 11:17:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://punchbowl.news/article/tech/amazon-display-tariff-costs/">https://punchbowl.news/article/tech/amazon-display-tariff-costs/</a>, See on <a href="https://news.ycombinator.com/item?id=43831027">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                        <p><img width="1024" height="683" src="https://punchbowl.news/wp-content/uploads/GettyImages-2209820827.jpg" alt="Amazon will soon display how much of an item’s cost is derived from tariffs — right next to the product’s total listed price." decoding="async" srcset="https://punchbowl.news/wp-content/uploads/GettyImages-2209820827.jpg 1024w, https://punchbowl.news/wp-content/uploads/GettyImages-2209820827-300x200.jpg 300w, https://punchbowl.news/wp-content/uploads/GettyImages-2209820827-768x512.jpg 768w, https://punchbowl.news/wp-content/uploads/GettyImages-2209820827-50x33.jpg 50w" sizes="(max-width: 1024px) 100vw, 1024px">                        </p>

                        
                        
                        <div>
                                                            <p><strong>Amazon doesn’t want</strong>&nbsp;to shoulder the blame for the cost of President&nbsp;<strong>Donald Trump</strong>’<strong>s</strong>&nbsp;trade war.</p>
<p><strong>So the e-commerce giant</strong>&nbsp;will<strong>&nbsp;</strong>soon show how much Trump’s tariffs are adding to the price of each product, according to a person familiar with the plan.</p>
<p><strong>The shopping site&nbsp;</strong>will display how much of an item’s cost is derived from tariffs – right next to the product’s total listed price.</p>
                                
                                                                                        <div>
        <p><img src="https://punchbowl.news/wp-content/themes/punchbowl-news/assets/images/tech-icon.svg" alt="Subscripion logo">
        </p>
        <h4>You're seeing a preview of our <span>Premium Policy: Tech</span> coverage. Read the full story by <a href="https://punchbowl.news/pricing">subscribing here.</a></h4>
    </div>                            
                            
                            
                        </div>
                    </div><p>Editorial photos provided by Getty Images. Political ads courtesy of AdImpact.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Generative AI is not replacing jobs or hurting wages at all, say economists (288 pts)]]></title>
            <link>https://www.theregister.com/2025/04/29/generative_ai_no_effect_jobs_wages/</link>
            <guid>43830613</guid>
            <pubDate>Tue, 29 Apr 2025 10:08:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/04/29/generative_ai_no_effect_jobs_wages/">https://www.theregister.com/2025/04/29/generative_ai_no_effect_jobs_wages/</a>, See on <a href="https://news.ycombinator.com/item?id=43830613">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Instead of depressing wages or taking jobs, generative AI chatbots like ChatGPT, Claude, and Gemini have had almost no wage or labor impact so far – a finding that calls into question the huge capital expenditures required to create and run AI models.</p>
<p>In <a target="_blank" rel="nofollow" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5219933">a working paper</a> released earlier this month, economists Anders Humlum and Emilie Vestergaard looked at the labor market impact of AI chatbots on 11 occupations, covering 25,000 workers and 7,000 workplaces in Denmark in 2023 and 2024.</p>
<p>Many of these occupations have been described as being vulnerable to AI: accountants, customer support specialists, financial advisors, HR professionals, IT support specialists, journalists, legal professionals, marketing professionals, office clerks, software developers, and teachers.</p>

    

<p>Yet after Humlum, assistant professor of economics at the Booth School of Business, University of Chicago, and Vestergaard, a PhD student at the University of Copenhagen, analyzed the data, they found the labor and wage impact of chatbots to be minimal.</p>
<blockquote>

<p>AI chatbots have had no significant impact on earnings or recorded hours in any occupation</p>
</blockquote>
<p>"AI chatbots have had no significant impact on earnings or recorded hours in any occupation," the authors state in their paper.</p>
<p>The report should concern the tech industry, which has hyped AI's economic potential while plowing billions into infrastructure meant to support it. Early this year, OpenAI <a target="_blank" href="https://www.theregister.com/2025/01/06/altman_gpt_profits/">admitted</a> that it loses money per query even on its most expensive enterprise SKU, while companies like <a target="_blank" href="https://www.theregister.com/2025/04/09/microsoft_puts_more_datacenter_builds/">Microsoft</a> and <a target="_blank" href="https://www.theregister.com/2025/04/22/aws_datacenter_leases/">Amazon</a> are starting to pull back on their AI infrastructure spending in light of <a target="_blank" href="https://www.theregister.com/2025/03/14/ai_running_out_of_juice/">low</a> business adoption past a few <a target="_blank" rel="nofollow" href="https://www.wsj.com/articles/johnson-johnson-pivots-its-ai-strategy-a9d0631f">pilots</a>.</p>

        


        

<p>The problem isn't that workers are avoiding generative AI chatbots - quite the contrary. But they simply aren't yet equating to actual economic benefits.</p>
<blockquote>

<p>The adoption of these chatbots has been remarkably fast ... But then when we look at the economic outcomes, it really has not moved the needle</p>
</blockquote>
<p>"The adoption of these chatbots has been remarkably fast," Humlum told <em>The Register</em>. "Most workers in the exposed occupations have now adopted these chatbots. Employers are also shifting gears and actively encouraging it. But then when we look at the economic outcomes, it really has not moved the needle."</p>
<p>The researchers looked at the extent to which company investment in AI has contributed to worker adoption of AI tools, and also how chatbot adoption affected workplace processes.</p>
<p>While firm-led investment in AI boosted the adoption of AI tools — saving time for 64 to 90 percent of users across the studied occupations — chatbots had a mixed impact on work quality and satisfaction.</p>

        

<p>The economists found for example that "AI chatbots have created new job tasks for 8.4 percent of workers, including some who do not use the tools themselves."</p>
<p>In other words, AI is creating new work that cancels out some potential time savings from using AI in the first place.</p>
<p>"One very stark example that it's close to home for me is there are a lot of teachers who now say they spend time trying to detect whether their students are using ChatGPT to cheat on their homework," explained Humlum.</p>

        

<p>He also observed that a lot of workers now say they're spending time reviewing the quality of AI output or writing prompts.</p>
<p>Humlum argues that can be spun negatively, as a subtraction from potential productivity gains, or more positively, in the sense that automation tools historically have tended to generate more demand for workers in other tasks.</p>
<p>"These new job tasks create new demand for workers, which may boost their wages, if these are more high value added tasks," he said.</p>
<ul>

<li><a href="https://www.theregister.com/2025/04/28/ibm/">Artist formerly known as Indian Business Machines pledges $150B for US ops, R&amp;D</a></li>

<li><a href="https://www.theregister.com/2025/04/27/darpa_expmath_ai/">DARPA to 'radically' rev up mathematics research. And yes, with AI</a></li>

<li><a href="https://www.theregister.com/2025/04/25/google_admits_depreciation_costs_soaring/">Google admits depreciation costs are soaring amid furious bit barn build</a></li>

<li><a href="https://www.theregister.com/2025/04/24/sustainability_still_not_a_high/">Sustainability still not a high priority for datacenter industry</a></li>
</ul>
<p>But overall, the time savings from using AI was less than expected. According to the study, "users report average time savings of just 2.8 percent of work hours" from using AI tools. That's a bit more than one hour per 40 hour work week.</p>
<p>The authors note that this finding differs from other randomized controlled trials that have found productivity benefits on the order of <a target="_blank" rel="nofollow" href="https://academic.oup.com/qje/article/140/2/889/7990658">15 percent</a>. And they explain this discrepancy by saying that other studies have focused on occupations with high AI productivity potential and that real-world workers don't operate under the same conditions.</p>
<p>"So I think there are two key reasons why the real economic gains are lower than [the cited studies]," said Humlum, noting that his study relies on actual tax data.</p>
<p>"First, most tasks do not fall into that category where ChatGPT can just automate everything. And then second, we're in this middle phase where employers are still waking up to the new reality, and we're trying to figure out how to best really realize the potential in these tools. And just at this stage, it's just not been that much of a game changer."</p>
<p>Where there are productivity gains to be had, Humlum and Vestergaard estimate that only a small portion of that benefit – between 3 and 7 percent – gets passed through to workers in the form of higher earnings.</p>
<p>Humlum said while there are gains and time savings to be had, "there's definitely a question of who they really accrue to. And some of it could be the firms – we cannot directly look at firm profitability. Some of it could also just be that you save some time on existing tasks, but you're not really able to expand your output and therefore earn more.</p>
<p>"So it's like it saves you time writing emails. But if you cannot really take on more work or do something else that is really valuable, then that will put a damper on how much we should actually expect those time savings to affect your earning ability, your total hours, your wages."</p>
<p>Humlum said the impact of using AI chatbots, in the form of productivity, time savings, and work quality, can be improved through company commitment to internal education and evangelism. He pointed in particular to how firm initiatives can reduce the tool-usage gender gap – fewer women use these tools than men.</p>
<p>But doing so at this point doesn't show much promise of payoff.</p>
<p>"In terms of economic outcomes, when we're looking at hard metrics – in the administrative labor market data on earnings, wages – these tools have really not made a difference so far," said Humlum. "So I think that that puts in some sense an upper bound on what return we should expect from these tools, at least in the short run.</p>
<p>"My general conclusion is that any story that you want to tell about these tools being very transformative, needs to contend with the fact that at least two years after [the introduction of AI chatbots], they've not made a difference for economic outcomes." ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Flowcode – Turing-complete visual programming platform (142 pts)]]></title>
            <link>https://app.getflowcode.io/playground/example1</link>
            <guid>43830193</guid>
            <pubDate>Tue, 29 Apr 2025 09:04:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://app.getflowcode.io/playground/example1">https://app.getflowcode.io/playground/example1</a>, See on <a href="https://news.ycombinator.com/item?id=43830193">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Try Switching to Kagi (460 pts)]]></title>
            <link>https://daringfireball.net/2025/04/try_switching_to_kagi</link>
            <guid>43829490</guid>
            <pubDate>Tue, 29 Apr 2025 07:08:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daringfireball.net/2025/04/try_switching_to_kagi">https://daringfireball.net/2025/04/try_switching_to_kagi</a>, See on <a href="https://news.ycombinator.com/item?id=43829490">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="Box">



<p>Aaron Pressman, writing earlier this month in The Boston Globe, “<a href="https://www.bostonglobe.com/2025/04/01/business/google-search-problems-alternatives-kagi/">Why I Abandoned Google Search After 27 Years — and What I’m Using Instead</a>”:</p>

<blockquote>
  <p>The UK now requires travelers from America to obtain an electronic
travel authorization, or ETA. I wasn’t sure of the exact name of
the ETA, so I just searched “travel to UK.”</p>

<p>The results were all about obtaining an ETA and I picked a link
that looked like the official UK government site. It was not; the
official site was lower, below an AI summary, some sponsored
links, and other junk on the results page. Luckily for me, I did
get a legitimate travel pass — but the site I picked overcharged
me by about $70.</p>
</blockquote>

<p>I don’t know what the name for this sort of thing is, but it’s like a semi-scam. There are similar services to what Pressman ran into here for expedited passport renewals, for example — third-party companies that present themselves as official partners of the government that charge you extra for a service. But they just handle for you what you could just as easily do yourself, if you found the right place on the web to do it. A complete scam would be taking your money and giving you nothing (or a bogus document) in return. These semi-scams deliver the thing they’re promising, but charge you more than you should pay.</p>

<p>I just tried searching for “expedited passport renewal” <a href="https://www.google.com/search?q=expedited+passport+renewal">in Google</a> and <a href="https://kagi.com/search?q=expedited+passport+renewal">in Kagi</a>. Kagi presents as its first response the US State Department’s “<a href="https://travel.state.gov/content/travel/en/passports/get-fast.html">How to Get my U.S. Passport Fast</a>” page. Google has that same link listed 7th, below the fold even on a desktop browser window on a 27-inch display, behind four sponsored links (all of which look pretty official but aren’t), an AI Overview (which itself includes, in its own AI Overview sidebar, another link to the same “How to Get my U.S. Passport Fast” page), and another U.S. State Department webpage with general instructions for applying for a passport.</p>

<blockquote>
  <p>In the second case, last week, I needed to book a hotel for a
Passover trip to my brother’s in Connecticut. I knew there was a
cool hotel we had stayed at before near his house but I couldn’t
remember the name. I asked Google for hotels in the town where my
brother lives. Sure enough, one of the top results appeared on
first glance to be the official site of the hotel I wanted to
book. It was not. Once again, somewhat nefarious search engine
optimization techniques allowed a hotel aggregation site to jump
ahead in the results. And this time my error was even more costly,
to the tune of several hundred dollars in extra charges for two
hotel rooms.</p>

<p>Google has worked hard to eliminate truly fraudulent websites from
ending up in its results, and for that I am grateful. It is
undeniable that, in both instances, I should have been a more
careful consumer. But decades of relying on Google had taught me
that I didn’t have to be.</p>

<p>After I learned my lesson, I did some research in search of better
search. People I trust on the Internet, including the <a href="https://daringfireball.net/linked/2024/01/19/bray-google-kagi">Apple
blogger John Gruber</a> and <a href="https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/">novelist Cory Doctorow</a>,
recommended a new search engine called <a href="https://kagi.com/">Kagi</a>.</p>

<p>I gave it a few test runs. A search for “<a href="https://kagi.com/search?q=travel+to+uk">travel to UK</a>”
brought up the UK government page to apply for an ETA as the first
result. A search for a hotel in my brother’s town was topped by
the official site of the hotel I wanted. So I switched all my
default searches to Kagi.</p>
</blockquote>

<p>I keep trying to emphasize that I recommend switching to Kagi not because it’s more private (although it clearly is), not as a protest against Google (although for some, switching could be), not as a rejection of search ads dominating the top of Google’s results (although that’s true too), but simply because Kagi’s results are clearly better.</p>

<p>Like, even if I <a href="https://udm14.com/">use the magic <code>&amp;udm=14</code> parameter</a> with Google search, <a href="https://daringfireball.net/linked/2024/05/23/udm14">to get “disenshittified” results from Google</a>, I find I get <em>better</em> results from Kagi. When I know there’s one right answer (say, a specific article I remember reading and want to find again), Kagi is more likely than Google to list it first. If it’s a years-old article, Kagi is <em>way</em> more likely than Google to find it at all. For me, Google (and, alas, DuckDuckGo too) have largely stopped working reliably for finding not-recent stuff on the web. Not true with Kagi.</p>

<p>I used DuckDuckGo for years as my default search, and for those years, I found it largely on par with Google. But it felt like every once in a while — maybe, say, once or twice a month — DuckDuckGo would come up dry in its results. DuckDuckGo pioneered a trick <a href="https://duckduckgo.com/bangs">they call Bangs</a>. Include <code>!g</code> to any search terms, and instead of performing the search itself, DuckDuckGo will redirect that search to Google. They have a whole bunch of these Bangs — “!a” for Amazon search, “!nf” for Netflix. There are literally thousands of them (which of course they allow you to search for). The only one I ever really used though was <code>!g</code>, for redirecting my current search to Google because DuckDuckGo’s own results for the same terms was unsatisfying. My memory may not match with my actual usage, but like I said, I <em>feel</em> like I used this about once or twice a month for the several years I was using DuckDuckGo as my default search engine. Infrequently enough that it didn’t annoy me to the point of considering switching back to Google for default in-browser search, but frequently enough that I was annoyed enough to remember that I needed to use it at all.</p>

<p><a href="https://help.kagi.com/kagi/features/bangs.html">Kagi supports Bangs too</a>, including <code>!g</code> for Google web search. I can’t remember the last time I felt the need to try using it. It’s been months, many months. And, the last few times I’ve tried it, Google’s results were no more help than Kagi’s. Your mileage may vary, of course, but for me, unlike with DuckDuckGo, I effectively <em>never</em> find myself redirecting the same search to Google because I wasn’t happy with the results from Kagi. For context on my search usage, <a href="https://daringfireball.net/misc/2025/04/kagi-usage.png">my Kagi usage report</a> shows that I perform 400–800 web searches per month. (Kagi counts how often you search, for billing purposes, but <a href="https://kagi.com/privacy">does not keep a history</a> of <em>what</em> you searched for.)</p>

<p>Paying for Kagi today feels a <em>lot</em> like paying for HBO back in the cable TV heyday. Part of the deal is that you are paying for ad-free service, yes. But you’re also paying for noticeably higher quality. There were no shows like <em>The Sopranos</em>, <em>The Wire</em>, and <em>The Larry Sanders Show</em> on “free” TV channels, albeit with commercial interruptions. With HBO you got commercial-free entertainment <em>and</em> higher-quality shows and movies. Kagi is like that.<sup id="fnr1-2025-04-28"><a href="#fn1-2025-04-28">1</a></sup> It’s that good. No ads, no unwanted AI (but very good AI results if you want — just end your query with a question mark), <em>and</em> better search results.</p>





 <!-- PreviousNext -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spain is about to face the challenge of a "black start" (111 pts)]]></title>
            <link>https://arstechnica.com/science/2025/04/why-restarting-a-power-grid-is-so-hard/</link>
            <guid>43829356</guid>
            <pubDate>Tue, 29 Apr 2025 06:46:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/science/2025/04/why-restarting-a-power-grid-is-so-hard/">https://arstechnica.com/science/2025/04/why-restarting-a-power-grid-is-so-hard/</a>, See on <a href="https://news.ycombinator.com/item?id=43829356">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<h2>Local conditions</h2>
<p>While the grids in Spain and Portugal are connected to each other, they have limited connections to elsewhere. The only sources of external power to the grid come from France and Morocco, which are small connections, but they could be used to help black start some plants. Both blacked-out countries have significant hydropower, with Spain seeing it cover 10 percent of its demand and Portugal 25 percent. That's useful because hydro plants need very little in the way of an external power supply to start operating.</p>
<p>Beyond that, both countries have invested heavily in renewables, with Portugal supplying about half of its power from wind and hydro, having closed its last coal plant in 2021. Spain receives about 40 percent of its power from renewables at present.</p>
<p>Solar is not an ideal power source for black-starting the grid, given that it's unavailable for a significant chunk of the day. But solar panels produce direct current, with electronic systems matching it to the alternating current of the grid. With the right electronics, it can play a key role in keeping frequencies stable as grid segments are repowered. In productive areas, wind can provide black start power to other plants and doesn't need much external power to begin operations. It's unclear, however, whether the local wind hardware is equipped for black starts or if the local weather will cooperate (a quick check of the weather in various cities suggests it's relatively calm there).</p>
<p>Batteries have the potential to be incredibly helpful, since they also provide direct current that can be converted to any frequency needed, and so used for both starting up power plants or for frequency stabilization as segments of the grid are brought back online. Unfortunately, neither country has installed much grid-scale battery hardware yet. That's expected to change over the next few years in parallel with dramatically expanded solar power. But, at the moment, batteries will not be a huge help.</p>
<p>Regardless of how precisely the grid operators manage to handle this task in Spain and Portugal, they face a monumental challenge at the moment. If you're seeing estimates of several days for the restoration of power, it's because failing to meet this challenge will leave things back in the state they're in now.</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dear "Security Researchers" (164 pts)]]></title>
            <link>https://ftp.bit.nl/pub/debian/</link>
            <guid>43829080</guid>
            <pubDate>Tue, 29 Apr 2025 05:53:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ftp.bit.nl/pub/debian/">https://ftp.bit.nl/pub/debian/</a>, See on <a href="https://news.ycombinator.com/item?id=43829080">Hacker News</a></p>
<div id="readability-page-1" class="page">
<span>Dear "Security Researchers",<p>

Welcome to our *PUBLIC* OPEN SOURCE SOFTWARE MIRROR SERVER.<br>
Please DO NOT report this under our responsible disclosure policy.<br>
This is a PUBLIC service, with OPEN SOURCE SOFTWARE, and NOT a security threat to our company.<br>
There is NO SENSITIVE INFORMATION on this server.</p><p>

Thanks.</p></span>
<hr>
  <table>
   <tbody><tr><th><img src="https://ftp.bit.nl/icons/blank.gif" alt="[ICO]"></th><th><a href="https://ftp.bit.nl/pub/debian/?C=N;O=D">Name</a></th><th><a href="https://ftp.bit.nl/pub/debian/?C=M;O=A">Last modified</a></th><th><a href="https://ftp.bit.nl/pub/debian/?C=S;O=A">Size</a></th><th><a href="https://ftp.bit.nl/pub/debian/?C=D;O=A">Description</a></th></tr>
   <tr><th colspan="5"><hr></th></tr>
<tr><td><img src="https://ftp.bit.nl/icons/back.gif" alt="[PARENTDIR]"></td><td><a href="https://ftp.bit.nl/pub/">Parent Directory</a></td><td>&nbsp;</td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/hand.right.gif" alt="[   ]"></td><td><a href="https://ftp.bit.nl/pub/debian/README">README</a></td><td>2025-03-15 09:29  </td><td>1.2K</td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/unknown.gif" alt="[   ]"></td><td><a href="https://ftp.bit.nl/pub/debian/README.CD-manufacture">README.CD-manufacture</a></td><td>2010-06-26 11:52  </td><td>1.3K</td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/text.gif" alt="[TXT]"></td><td><a href="https://ftp.bit.nl/pub/debian/README.html">README.html</a></td><td>2025-03-15 09:29  </td><td>2.9K</td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/text.gif" alt="[TXT]"></td><td><a href="https://ftp.bit.nl/pub/debian/README.mirrors.html">README.mirrors.html</a></td><td>2017-03-04 21:08  </td><td>291 </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/text.gif" alt="[TXT]"></td><td><a href="https://ftp.bit.nl/pub/debian/README.mirrors.txt">README.mirrors.txt</a></td><td>2017-03-04 21:08  </td><td> 86 </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/dists/">dists/</a></td><td>2025-03-15 09:29  </td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/doc/">doc/</a></td><td>2025-04-29 03:52  </td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/unknown.gif" alt="[   ]"></td><td><a href="https://ftp.bit.nl/pub/debian/extrafiles">extrafiles</a></td><td>2025-04-29 04:27  </td><td>201K</td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/indices/">indices/</a></td><td>2025-04-29 04:26  </td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/compressed.gif" alt="[   ]"></td><td><a href="https://ftp.bit.nl/pub/debian/ls-lR.gz">ls-lR.gz</a></td><td>2025-04-29 04:18  </td><td> 15M</td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/pool/">pool/</a></td><td>2022-10-05 19:09  </td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/project/">project/</a></td><td>2008-11-18 00:05  </td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/tools/">tools/</a></td><td>2012-10-10 18:29  </td><td>  - </td><td>&nbsp;</td></tr>
<tr><td><img src="https://ftp.bit.nl/icons/folder.gif" alt="[DIR]"></td><td><a href="https://ftp.bit.nl/pub/debian/zzz-dists/">zzz-dists/</a></td><td>2023-10-07 13:07  </td><td>  - </td><td>&nbsp;</td></tr>
   <tr><th colspan="5"><hr></th></tr>
</tbody></table>



  <title>Debian Archive</title>
  <meta name="Modified" content="2025-03-15">



<h2>Debian Archive</h2>

<p>See <a href="https://www.debian.org/">https://www.debian.org/</a>
for information about Debian GNU/Linux.</p>

<h2>Current Releases</h2>

<p>Four Debian releases are available on the main site:</p>

<blockquote>
<dl>

<dt><a href="https://ftp.bit.nl/pub/debian/dists/buster/">Debian 10.13, or buster</a></dt>
<dd>Debian 10.13 was released Saturday, 10th September 2022.
<a href="https://www.debian.org/releases/buster/amd64/">Installation
and upgrading instructions</a>,
<a href="https://www.debian.org/releases/buster/">More information</a>
</dd>

<dt><a href="https://ftp.bit.nl/pub/debian/dists/bullseye/">Debian 11.11, or bullseye</a></dt>
<dd>Debian 11.11 was released Saturday, 31st August 2024.
<a href="https://www.debian.org/releases/bullseye/amd64/">Installation
and upgrading instructions</a>,
<a href="https://www.debian.org/releases/bullseye/">More information</a>
</dd>

<dt><a href="https://ftp.bit.nl/pub/debian/dists/bookworm/">Debian 12.10, or bookworm</a></dt>
<dd>Debian 12.10 was released Saturday, 15th March 2025.
<a href="https://www.debian.org/releases/bookworm/amd64/">Installation
and upgrading instructions</a>,
<a href="https://www.debian.org/releases/bookworm/">More information</a>
</dd>

<dt><a href="https://ftp.bit.nl/pub/debian/dists/testing/">Testing, or trixie</a></dt>
<dd>The current tested development snapshot is named trixie.<br>
Packages which have been tested in unstable and passed automated
tests propagate to this release.<br>
<a href="https://www.debian.org/releases/testing/">More information</a>
</dd>

<dt><a href="https://ftp.bit.nl/pub/debian/dists/unstable/">Unstable, or sid</a></dt>
<dd>The current development snapshot is named sid.<br>
Untested candidate packages for future releases.<br>
<a href="https://www.debian.org/releases/unstable/">More information</a>
</dd>
</dl>
</blockquote>

<h2>Old Releases</h2>

<p>Older releases of Debian are at
<a href="http://archive.debian.org/debian-archive/">http://archive.debian.org/debian-archive</a>
<br>
<a href="https://www.debian.org/distrib/archive">More information</a>
</p>

<h2>CDs</h2>

<p>For more information about Debian CDs, please see
<a href="https://ftp.bit.nl/pub/debian/README.CD-manufacture">README.CD-manufacture</a>.
<br>
<a href="https://www.debian.org/CD/">Further information</a>
</p>

<h2>Mirrors</h2>

<p>For more information about Debian mirrors, please see
<a href="https://ftp.bit.nl/pub/debian/README.mirrors.html">README.mirrors.html</a>.
<br>
<a href="https://www.debian.org/mirror/">Further information</a>
</p>

<h2>Other directories</h2>

<table summary="Other directories">
<tbody><tr><td><a href="https://ftp.bit.nl/pub/debian/doc/">doc</a></td>          <td>Debian documentation.</td></tr>
<tr><td><a href="https://ftp.bit.nl/pub/debian/indices/">indices</a></td>  <td>Various indices of the site.</td></tr>
<tr><td><a href="https://ftp.bit.nl/pub/debian/project/">project</a></td>  <td>Experimental packages and other miscellaneous files.</td></tr>
</tbody></table>




</div>]]></description>
        </item>
        <item>
            <title><![CDATA[LibreLingo – FOSS Alternative to Duolingo (616 pts)]]></title>
            <link>https://librelingo.app</link>
            <guid>43829035</guid>
            <pubDate>Tue, 29 Apr 2025 05:45:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://librelingo.app">https://librelingo.app</a>, See on <a href="https://news.ycombinator.com/item?id=43829035">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img alt="LibreLingo Mascot" src="https://librelingo.app/images/mascot-jetpack-noshadow.svg" data-test="mascot-jetpack"> </p> <p><h2><span data-tkey="index.subtitle">an experiment to create a community-driven language-learning platform</span></h2> </p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A single line of code cost $8000 (240 pts)]]></title>
            <link>https://pietrasiak.com/one-line-of-code-that-did-cost-dollar8000</link>
            <guid>43829006</guid>
            <pubDate>Tue, 29 Apr 2025 05:40:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pietrasiak.com/one-line-of-code-that-did-cost-dollar8000">https://pietrasiak.com/one-line-of-code-that-did-cost-dollar8000</a>, See on <a href="https://news.ycombinator.com/item?id=43829006">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><h2 id="6229ad4c359d4dbf908c56b33a98c24c">TLDR</h2></p><div><p>Due to a bug, our screen recorder app - <a target="_blank" href="http://screen.studio/">screen.studio</a> app kept downloading the auto-update file repeatedly, every 5 minutes for every single user. The update file is approximately 250MB. This resulted in <b>9 million file downloads and more than 2 petabytes (2,000,000 gigabytes)</b> of traffic on Google Cloud.</p></div><figure><div aria-owns="rmiz-modal-" data-rmiz=""><p><img loading="lazy" decoding="async" alt="Image without caption" src="https://image-forwarder.notaku.so/aHR0cHM6Ly93d3cubm90aW9uLnNvL2ltYWdlL2h0dHBzJTNBJTJGJTJGczMtdXMtd2VzdC0yLmFtYXpvbmF3cy5jb20lMkZzZWN1cmUubm90aW9uLXN0YXRpYy5jb20lMkZlMjZiZThjNS05ZDcxLTRmYTgtODBlYS1iNDdiNmNmNTg3Y2ElMkZVbnRpdGxlZC5wbmc_dGFibGU9YmxvY2smc3BhY2VJZD1iYTMzYWM4NC1mN2VjLTQwZDMtODU0MS0wNDMyODI5YzBkNDgmaWQ9NzNkMzk3N2YtNjJhNy00MmQ1LTk2ZTQtNThiYmQwMDc5NzMyJmNhY2hlPXYyJndpZHRoPTE2NzQuOTY4NzU="></p></div></figure><div><p>This screenshot might not look so scary at first, but take a look at the scale of it. For over a month, we generated at least 100Mib/s (a second!) and, at times, almost 1GiB/s of traffic (every single second!)</p></div><hr><div><p>That bug was painfully simple and stupid.</p></div><div><p>Screen Studio is a screen recorder for macOS. It is desktop app. It means we need some auto-updater to allow users to install the latest app version easily.</p></div><div><p>The app checks for the update every 5 minutes or when the user activates the app.</p></div><div><p>Normally, when the app detected the update - it downloaded it and stopped the 5 minutes interval until the user installed it and restarted it.</p></div><p><h2 id="86e96dd5a9a64f7eb2a3408771948538">Tragic refactor</h2></p><div><p>The problem with the auto-updater we had was that it would prompt the user to update the app as soon as it became available. This resulted in a popup appearing while users were recording the screen, which obviously provided a bad experience as it interrupted the recording the user was making.</p></div><div><p>While refactoring it, <b>I forgot to add the code to stop the 5-minute interval after the new version file was available and downloaded.</b></p></div><div><p>It meant <b>the app was downloading the same 250MB file, over and over again, every 5 minutes.</b></p></div><p><h2 id="8bc5a4ebee2d4a2387cb4af3e66bda00">Tragic context - app running in the background for weeks</h2></p><div><p>It turns out thousands of our users had the app running in the background, even though they were not using it or checking it <b>for weeks</b> (!). It meant thousands of users had auto-updater constantly running and downloading the new version file (250MB) over and over again every 5 minutes</p></div><p><h2 id="0c7c00acd73e4f7ba7a05ffd8ee2f5bf">The math</h2></p><div><p>Let’s do some quick math here.</p></div><ul><li>Doing something every 5 minutes means doing it approximately <b>288 times a day</b>.</li></ul><ul><li>The update file is about 250 MB, meaning <b>72 GB of downloads per user daily</b>.</li></ul><ul><li>We had this situation happening for <b>over a month before we noticed it</b>.</li></ul><ul><li>We had at least a <b>thousand such app instances running</b> in the background at any moment.</li></ul><ul><li><b>250 MB * 288 downloads per day * 30 days * 1000 users:</b></li></ul><figure><div aria-owns="rmiz-modal-" data-rmiz=""><p><img loading="lazy" decoding="async" alt="Image without caption" src="https://image-forwarder.notaku.so/aHR0cHM6Ly93d3cubm90aW9uLnNvL2ltYWdlL2h0dHBzJTNBJTJGJTJGczMtdXMtd2VzdC0yLmFtYXpvbmF3cy5jb20lMkZzZWN1cmUubm90aW9uLXN0YXRpYy5jb20lMkY1Y2FlZmVkYS0wMDFjLTQ2NDktODM2Zi1lMTI0MzM0NDRjMGUlMkZVbnRpdGxlZC5wbmc_dGFibGU9YmxvY2smc3BhY2VJZD1iYTMzYWM4NC1mN2VjLTQwZDMtODU0MS0wNDMyODI5YzBkNDgmaWQ9M2FjZmFjNzAtOTc2ZC00ZmI4LTkwYTgtMzU5NmQzMTFkZGFlJmNhY2hlPXYyJndpZHRoPTE2NzQuOTg0Mzc1"></p></div></figure><ul><li><b>2 000 000 gigabytes, </b></li></ul><ul><li><b>or 2 000 terabytes </b></li></ul><ul><li><b>or 2 petabytes of traffic.</b></li></ul><p><h2 id="b0ab8050379441e89f1489895de53ae8">Series of bad mistakes</h2></p><div><p><b>We did not have cost alerts on Google Cloud</b>. Before this situation occurred, we were paying at most $300 a month.</p></div><div><p>We were also not regularly checking the situation as it just worked.</p></div><div><p>We noticed it because my credit card started to block the transaction due to limits I had set on it (lucky me!).</p></div><figure><div aria-owns="rmiz-modal-" data-rmiz=""><p><img loading="lazy" decoding="async" alt="Image without caption" src="https://image-forwarder.notaku.so/aHR0cHM6Ly93d3cubm90aW9uLnNvL2ltYWdlL2h0dHBzJTNBJTJGJTJGczMtdXMtd2VzdC0yLmFtYXpvbmF3cy5jb20lMkZzZWN1cmUubm90aW9uLXN0YXRpYy5jb20lMkYxMWRhNDI1YS05YWU0LTRiZTgtOGIzNi1hMzc3MmQwOTdjMTElMkZVbnRpdGxlZC5wbmc_dGFibGU9YmxvY2smc3BhY2VJZD1iYTMzYWM4NC1mN2VjLTQwZDMtODU0MS0wNDMyODI5YzBkNDgmaWQ9NmE3M2JhYzgtZWMwYi00ZmJiLWJjOTctNzEyYjk4NDM3YmM4JmNhY2hlPXYyJndpZHRoPTI0MDA="></p></div></figure><p><h2 id="1bf63d5f09bb48f9a25dc3820bb49e03">Consequences for the users</h2></p><div><p>It was not only bad for us but even worse for some of the users.</p></div><div><p>As mentioned, the app was generating so much traffic. <b>It means it was their machine generating network traffic on their home router and their internet provider.</b></p></div><div><p>One of our users, who lived in a house, had their internet provider cancel their contract due to enormous traffic generated during a month. It was extremely problematic as there was no other internet provider available around.</p></div><div><p>We decided to take responsibility and offer to cover all the costs related to this situation.</p></div><div><p>Luckily, it was not needed as the person could figure out the situation with the provider without bigger problems.</p></div><div><p>That was, however, quite a terrible experience for that person and me. As a designer, I value the experience product I create provides to the users. And this was not even a bad experience; it was actually harmful.</p></div><p><h2 id="cba99c00ddec4d4890f45cf68e515c40">Summarising</h2></p><ul><li><b>Set alerts</b> on your cloud at all times.</li></ul><ul><li>Write your auto-updater code very carefully.</li></ul><ul><li>Actually, <b>write any code that has the potential to generate costs carefully</b>.</li></ul><ul><li>Add special signals you can change on your server, which the app will understand, such as a <b>forced update</b> that will install without asking the user.</li></ul><ul><li>Regularly check your cloud.</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oracle engineers caused five days software outage at U.S. hospitals (163 pts)]]></title>
            <link>https://www.cnbc.com/2025/04/28/oracle-engineers-caused-days-long-software-outage-at-us-hospitals.html</link>
            <guid>43828915</guid>
            <pubDate>Tue, 29 Apr 2025 05:25:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/04/28/oracle-engineers-caused-days-long-software-outage-at-us-hospitals.html">https://www.cnbc.com/2025/04/28/oracle-engineers-caused-days-long-software-outage-at-us-hospitals.html</a>, See on <a href="https://news.ycombinator.com/item?id=43828915">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108079907" data-test="InlineImage"><p>Larry Ellison, co-founder and executive chairman of Oracle Corp., speaks during the Oracle OpenWorld 2018 conference in San Francisco, California, U.S., on Monday, Oct. 22, 2018.</p><p>David Paul Morris | Bloomberg | Getty Images</p></div><div><p><span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/ORCL/">Oracle</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> engineers mistakenly triggered a five-day software outage at a number of Community Health Systems hospitals, causing the facilities to temporarily return to paper-based patient records.</p><p>CHS told CNBC that the outage involving Oracle Health, the company's electronic health record (EHR) system, affected "several" hospitals, leading them to activate "downtime procedures." Trade publication Becker's Hospital Review reported that 45 hospitals were hit.</p><p>The outage began on April 23, after engineers conducting maintenance work mistakenly deleted critical storage connected to a key database, a CHS spokesperson said in a statement. The outage was resolved on Monday, and was not related to a cyberattack or other security incident.</p><p>CHS is based in Tennessee and includes 72 hospitals in 14 states, according to the medical system's website.</p><p>"Despite this being a major outage, our hospitals were able to maintain services with no&nbsp;material impact," the spokesperson said. "We are proud of our clinical and support teams who worked through the multi-day outage with professionalism and a commitment to delivering high-quality, safe care for&nbsp;patients."&nbsp;</p></div><div><div role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="256" height="256" viewBox="0 0 256 256" aria-labelledby="title desc" role="img" focusable="false" preserveAspectRatio="xMinYMin"><title>Stock Chart Icon</title><desc>Stock chart icon</desc><g transform="translate(1.4065934065934016 1.4065934065934016) scale(2.81 2.81)"><path d="M 87.994 0 H 69.342 c -1.787 0 -2.682 2.16 -1.418 3.424 l 5.795 5.795 l -33.82 33.82 L 28.056 31.196 l -3.174 -3.174 c -1.074 -1.074 -2.815 -1.074 -3.889 0 L 0.805 48.209 c -1.074 1.074 -1.074 2.815 0 3.889 l 3.174 3.174 c 1.074 1.074 2.815 1.074 3.889 0 l 15.069 -15.069 l 14.994 14.994 c 1.074 1.074 2.815 1.074 3.889 0 l 1.614 -1.614 c 0.083 -0.066 0.17 -0.125 0.247 -0.202 l 37.1 -37.1 l 5.795 5.795 C 87.84 23.34 90 22.445 90 20.658 V 2.006 C 90 0.898 89.102 0 87.994 0 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 65.626 37.8 v 49.45 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 23.518 L 65.626 37.8 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 47.115 56.312 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 42.03 L 47.115 56.312 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 39.876 60.503 c -1.937 0 -3.757 -0.754 -5.127 -2.124 l -6.146 -6.145 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 59.844 C 41.952 60.271 40.933 60.503 39.876 60.503 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 22.937 46.567 L 11.051 58.453 c -0.298 0.298 -0.621 0.562 -0.959 0.8 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 48.004 L 22.937 46.567 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path></g></svg><p><img src="https://static-redesign.cnbcfm.com/dist/a54b41835a8b60db28c2.svg" alt="hide content"></p></div><p>Oracle stock this year</p></div><div><p>Oracle didn't immediately respond to CNBC's request for comment.</p><p>An EHR is a digital version of a patient's medical history that's updated by doctors and nurses. It's crucial software within the U.S. health-care system, and outages can cause serious disruptions to patient care. Oracle acquired EHR vendor Cerner in 2022 for $28.3 billion, becoming the second-biggest player in the market, behind Epic Systems.</p><p>Now that Oracle's systems are back online, CHS said that the impacted hospitals&nbsp;are working to "re-establish full functionality and return to normal operations and procedures."</p><p>Oracle's CHS error comes weeks after the company's federal electronic health record experienced a <a href="https://www.cnbc.com/2025/03/06/oracles-federal-electronic-health-record-suffered-nation-wide-outage-.html">nationwide outage</a>. Oracle has struggled with a thorny, years-long EHR rollout with the Department of Veterans Affairs, marred by patient safety concerns. The agency launched a&nbsp;<a href="https://news.va.gov/press-room/va-announces-strategic-review-of-electronic-health-record-modernization-program/" target="_blank">strategic review</a>&nbsp;of Cerner in 2021, before Oracle's acquisition, and it temporarily&nbsp;<a href="https://digital.va.gov/ehr-modernization/ehr-deployment-schedule/" target="_blank">paused deployment</a>&nbsp;of the software in 2023.</p><p><strong>WATCH:</strong> <a href="https://www.cnbc.com/video/2025/02/20/oracle-ceo-safra-catz-being-number-one-is-very-important.html">Interview with Oracle CEO Safra Catz</a></p></div><div id="Placeholder-ArticleBody-Video-108105025" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000367188" aria-labelledby="Placeholder-ArticleBody-Video-108105025"><p><img src="https://image.cnbcfm.com/api/v1/image/108105026-17400675801740067576-38548750502-1080pnbcnews.jpg?v=1740067578&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Oracle CEO Safra Catz: Being number one is very important"><span></span><span></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Knowledge-based society, my ass (328 pts)]]></title>
            <link>https://mihaiolteanu.me/knowledge-based-society-my-ass</link>
            <guid>43828713</guid>
            <pubDate>Tue, 29 Apr 2025 04:33:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mihaiolteanu.me/knowledge-based-society-my-ass">https://mihaiolteanu.me/knowledge-based-society-my-ass</a>, See on <a href="https://news.ycombinator.com/item?id=43828713">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="contents">

            

            <p>
            Right after I get admitted, I inform Professor that I also have a full-time
            job. He insists that we must start working right away. I quit as a result and
            instantly breathe a refined air. I am now a scientist! A week later I approach
            Professor and let him know I'm ready for work.
            </p>

            <p>
            "Ready for what?" he greets me as though our previous conversation didn't
            happen. I remind him that he's my PhD supervisor and that, at his proposal, we
            are studying the effects of electromagnetic fields on patients with carotid
            stent implants. "There is nothing for you to do at the University, you can
            stay home for now," he tells me. Is he really serious? Does he want me to do
            research from bed? I insist on reading materials related to our field of
            research. I want to start right away. But he can't recommend any.
            </p>

            <p>
            My first day of research is over. It's autumn 2009. I spend the following days
            of my academic life oversleeping and strolling the city parks. I actually
            enjoy this newfound freedom from the alarm clock. I think, not without a
            certain longing, of my former factory colleagues. How we used to laugh at the
            stupidest of things, how it all felt like a big family. But I have a new life
            now. An intellectual one.
            </p>

            <p>
            A few weeks go by. No word from Professor. It's exhausting to conduct research
            like this. I need some color. I approach Professor again and ask for basic
            research equipment, "I need an office, Professor," I begin, and, after a short
            while, I raise my stakes, "And a computer, too!"  I've gone too
            far. "Everybody is happy around here, except you!!!" he snaps at me. I get a
            feeling that I'm going nowhere with Professor.
            </p>

            <p>
            I approach the Head of Department. The Head listens carefully for my
            complaints and kindly informs me he doesn't mingle in Professor's business. It
            is up to my advisor to decide where the resources are allocated within his
            team. A nice way of deflecting responsibility.
            </p>

            <p>
            The Faculty's Dean doesn't give a damn either but I think he wants to avoid
            even more troubles seeing that I'm so stubborn. I soon receive an email from
            Professor as a result. He decides to offer me an office and a computer. Two
            months wasted. Even so, I celebrate my first academic victory.
            </p>

            <p>
            "Grab a computer and follow me," Professor instructs me a few days later. I
            can barely hide my enthusiasm. We take the stairs to the first floor. Then
            ground floor. Then basement. "Almost there," I hear Professor in the
            darkness. After two more turns he opens a big door and hands me over the
            keys. My office is a rather spacious but austere room in the University's
            basement. My initial enthusiasm is fading. There's a simple desk with a basic
            chair at one end and a small, too high to reach window at the other. The walls
            are immaculately white. A hospital-style metal locker where Professor keeps his
            valuables under key completes the picture. 
            </p>

            <p>
            "Doctoral Studies in Engineering Sciences for Developing the Knowledge-Based
            Society" is the name of our project. It pays me, and approximately one hundred
            other colleagues of mine, all PhD candidates, our €500/month scholarships, or
            about the average wage. It's one project from among the four thousand projects
            sponsored by the European Union's "Operational Program for Human Resources
            Development." This grandiose program, with an available budget of €5 billion,
            aims to "develop the human capital and increase competitiveness by bringing
            education and life-long learning in sync with a modern, flexible and inclusive
            labor market and increase future opportunities for 1.650.000 people." Yes,
            those are millions, 15.000 of which are to become PhD students! The Government
            says so, I it as fact.
            </p>

            <p>
            For my part, I have to publish at least three scientific papers, present my
            research at one international conference and successfully defend my thesis in
            public. I have exactly three years at my disposal. If I fail, I have to return
            my scholarship in full. It's also up to me to rejoin the labor market and take
            care of my future, possibly as a teaching assistant here, at the
            University. So I take things seriously and go to work each morning. I learn
            and labor as hard as I can.
            </p>

            <p>
            I begin with the documentation phase and I read, among others, a very detailed
            series of experiments: human subjects placed in anechoic chambers with all
            kinds of electromagnetic fields directed at them. They measure changes in
            sweat rate, breathing rate, exhaled humidity, body temperatures, blood
            pressure and everything one can imagine. They try to figure out how the body
            responds and adapts to such an external stimulus.
            </p>

            <p>
            I, for my side, have to see what happens inside the human neck artery when an
            implanted stent heats up under the influence of electromagnetic fields. How
            does the body react and compensate for such a temperature increase, if there
            is one? I have things to discover. But I also have zero lab equipment. Not
            even a digital thermometer, let alone medical equipment of the kind I would
            need. The whole medical engineering's lab, the one I took my computer from, is
            a room twice the size of my basement with ten desktop computers in it, a
            blackboard, a small window blocked by another building and an extra door for a
            special room: Professor's own office.
            </p>

            <p>
            Critically, I do not even get to see or touch a real stent. We don't have
            any. There are no interactions with patients, no collaboration with doctors
            and no conversations with other engineers from our University. I'm alone in my
            office. I'm not sure what people do around here. When the whole Department
            gathers around, I hear professors complaining about "kids these days" but zero
            technical discussions and hardly any interest in scientific topics. We are
            one-man teams, each working in their only little basements, so to speak.
            </p>

            <p>
            Professor reassures me that computer simulations are enough for our study. So
            I try to find software licenses plus realistic computer models for my stents
            and human heads. They all cost money and are hard to find. To develop them
            from scratch is outside my specialty. Ideally, I should understand a bit of
            human biology, too, but that's again outside my specialty. I wonder at this
            point if I actually have a specialty. What makes me qualified to approach
            these issues? Why would my "discoveries", born out of such meager
            possibilities, have any relevance for science?
            </p>

            <p>
            I don't lack motivation, though. I try to get a license for the €20k per year
            software we're using. It proves to be another catacombic adventure. The
            company offers two free licenses per public institution. I ask Professor for a
            license, but "There aren't any left," he informs me. "Don't we have two?" I
            insist. "Well, yes, but one license is on my laptop, which I always carry with
            me, and the other is on my office computer," he replies. I ask permission to
            his office to run some simulations from time to time, but "No, my office is
            closed and only I have the key." I conclude Professor has a terrible fondness
            for locks and keys. I drop it. I'm not sure what he does with two
            licenses. Maybe he sells them on the black market? Maybe Professor is a
            gangster? Who knows.
            </p>

            <p>
            One of my colleagues who is pursuing his PhD in the same Department under a
            different professor and a similar area of research, with whom I only cross
            paths when our blood pressure runs too high, happens to also work for a public
            institution. He applies for the two free licenses and is generous enough to
            offer me one.
            </p>

            <p>
            Another victory. But I'm fed up with these victories. It's exhausting to fight
            all these absurd battles. My time is running out. I have to write some papers
            soon. I accept my fate. I accept I'm not gonna be a scientist the way I've
            imagined more than a year ago. I don't see any future for me here at the
            University. As a result, I simplify things tremendously. I draw a big sphere
            and pretend it's a human head, I place a long metallic cylinder inside it and
            pretend it's a real stent and I place a simple antenna close by. Anything more
            complicated than this crashes my toy computer. I soon realize that I play
            scientist like kids play cop with water pistols.
            </p>

            <p>
            I get to publish my first paper in this way. I'm actually quite proud of it,
            given the circumstances. I actually start to enjoy writing. I put down my
            colleague as a co-author as a thank you for lending me the license. We've
            learned this trick from the professors who do it all the time with their
            books, papers and conferences. They are required, just as we are, to publish
            and look active in the community per their contract with the University.
            </p>
            
            <p>
            Out of curiosity, I start reading our school's newspaper, as my colleague
            calls our University's scientific journal. I soon spot inconsistencies. The
            wording is in plain, boring language with long introductions repeating the
            same generalities and facts known to all. But the style changes unexpectedly
            sometimes. I search these peculiar phrases online and my intuition is
            confirmed. Unacknowledged commandeering of intellectual labor via
            indiscriminate copy and paste practices. Plagiarism, in short. I find dozens
            of such instances. I see the name of our Head in there, too. I try to raise
            awareness for a month or two. Nobody gives a damn.
            </p><p>

            I stop reading the school's newspaper and concentrate on publishing my other
            papers instead. They are nothing more than variations on the first paper with
            different titles and different pictures. I let my computer run overnight and
            invent slightly different simulation scenarios and I underline different
            aspects of my results in each paper. After this, I take a more relaxed
            approach regarding my scientific pursuits, enjoy the show around me
            instead and stop giving a damn about Professor from now on.
            </p>
            
            <p>
            I notice the Head is emphasizing the "academic dress code" all the time. He
            even publishes an official Department guideline on this topic pressing us all
            to read it. I notice professors are always addressing each other formally even
            in informal settings, though they've been acquainted for years. This title
            caries great importance here. I myself make a blunder in this respect when I
            visit Professor's office one day for some official papers. I ask if he's
            around but I refer to him by his family name only. I get admonished for
            skipping the "professor" part. I apologies, add the missing title and address
            the question again. "No, Professor is not here!" comes the reply abruptly.
            </p>

            <p>
            Our Head both informs and threatens us, "Per the Department guidelines, every
            PhD candidate is required to teach for one semester. Find yourselves a seminar
            or a lab or I'll pick one for you." It so happens that I get friendly with an
            electronics department's professor. He asks me to be his teaching assistant. I
            inform the Head with great pleasure about this development and he, in turn,
            informs me with great satisfaction that "I do not give this position to PhD
            candidates." I insist, but in vain. I get used to insisting in vain. I get
            used to failing to figure out how this whole clusterfuck works. One colleague
            is appointed to teach C++ by the Head. "You know C++?" I ask enthusiastically,
            as I am looking to become a software engineer myself at this point. "I don't,"
            she informs me, "but there's enough time until Monday to learn it." It's
            Friday, the last day of my teaching career.
            </p>

            <p>
            Professor becomes my hero for a short time during a Department meeting. He
            insists that the design of high-voltage power lines is not actually a subject
            for his medical students. He wants more biology and medical related courses,
            instead. I truly believe in his vision. My mouth is wide open. But the Head
            again masterfully defends his position insisting on the necessity of assigning
            the minimum required number of hours per semester to each member of our
            Department, per the University guidelines. Nobody backs up my hero, not even
            he himself. The next topic on the agenda is the training of all our staff in
            the arts of digital blackboards "to help improve the teaching experience."
            </p>

            <p>
            I'm sinfully enjoying myself. What else do they do around here? Mrs. S. is our
            Department's team assistant. She's near retirement age and lives up in the
            attic. We visit her monthly to physically sign our presence in the attendance
            register. Sometimes she scolds us for signing in the wrong place, "That was a
            public holiday! You didn't work then, did you?!" There is no "Sir" nor
            "professor" with her. We are inhabiting a prestigious institution of higher
            learning, otherwise she would certainly call us morons. I'm wondering at the
            inefficiency on relying on handwritten notebooks for timekeeping. This
            Technical University has a Computer Science department, after all. But things
            are as they should be around here. There are many advantages to the analog
            methods. For instance, we avoid software bugs so this method is more precise,
            it fosters social interactions so it is more humane, we avoid proprietary
            software so users have complete control to modify the source code. We turn up
            once a month, sign and then we're free to do whatever. The Professor has given
            me the correct advice on that first day.
            </p>

            <p>
            The only constant human presence in the whole building during the warm summer
            days is the cleaning lady. I befriend her and we talk each morning. She
            provides me with paper towels and liquid soap for "When you might need it."
            Summer is vacation for both students and teachers, after all. From time to
            time I meet a stray professor in the hallways and they tell me I do a good
            job, always working, always studying, always present. Then, they excuses
            themselves with "I have to change my car's windshield" and other such
            important matters and then disappear for days or weeks on end.
            </p>

            <p>
            There's a big park with a lake nearby and a small river passes just behind the
            building. I often take small brakes from my academic life and stroll
            aimlessly. I sometimes watch the little fishes from the nearby bridge
            gathering in the shade of the willow trees. A kid approaches me one day, "Did
            you see the big one?" We chat a little. That's how I spend my
            days.
            </p>

            <p>
            With three months left, I send Professor my thesis. Days later, he warmly
            congratulates me, "You are an embarrassment to our city!" I stand
            alarmed. "Yes, you are ruining the prestige of our University!" I move closer.
            He points out a paragraph in my thesis where "almost impossible" is heavily
            underlined in red. "Something is either possible or impossible," he mocks me
            with a noticeable grin on his face. I update the offending sentence. I also
            fix a few typos in the following week and rephrase some paragraphs which were
            not to his liking. He eventually approves it. I present it in front of the
            whole Department, the last step before facing the official commission. It gets
            approved.
            </p>

            <p>
            My celebration is cut short a few days later. For some reason, it is of the
            utmost importance to have an actual, real-life experiment to confirm our
            theoretical results. "We can't present a theoretical thesis, we're a Technical
            University," Professor accuses me. I actually agree with him, though I have no
            soul left in this endeavor. How did he come up with this idea? I don't
            know. He probably got admonished by some higher-up. It was fine without it,
            the Department approved it, the Head approved it, it was ready for
            defending. Now it isn't. I shrug and accept it as another fact I can't
            understand nor influence.
            </p>

            <p>
            Professor finds a public institution to lend us their watermelon-sized
            anechoic chamber for two hours. We visit the supermarket one morning to buy
            pork chops for the human head. I want to bring to Professor's attention that
            we're studying a dynamic system and not dead meat. But it's autumn 2012
            already and the parks are in full color. It's way too late for any dialogue. I
            pull out a small plastic bag with a few miniature temperature sensors I bought
            the other day. Professor glues them to a metallic cylinder and inserts it in
            "the head." I see Professor was inspired by my way of handling the lack of
            real stents. I think it is a nail or wire of some sort but I'm not
            sure. Professor handles all the "sensitive equipment" himself. I take pictures
            and write down the results in a notebook. For the next two hours we gather
            temperature readings. I publish a paper with our findings shortly after,
            attach his name to it, update my thesis and everything is good again. I start
            to develop a faint feeling that I sleep better at night when I play along and
            nod approvingly to things I don't actually agree with instead of being
            pigheaded.
            </p>

            <p>
            The final day is approaching. Mrs. B., from the Department of Doctoral
            Studies, informs me that I personally have to prepare and bring in food,
            drinks and coffee for the commission when I defend my thesis. I refuse. She
            insists. I point out that the University charges €1000 per student for the
            final show, that each member of the commission is actually getting paid for
            their trouble and that all these expenses plus transport and accommodation are
            already sponsored by our project. She shows signs of slowly winning back her
            memory. Mrs. B. also informs me that I won't be able to hold back my tears
            upon successfully defending my thesis in front of family, friends and
            colleagues. I successfully defend my thesis a few days later and I refuse her
            that pleasure, too.
            </p>

            <p>
            We celebrate at a local restaurant with the whole Department and the
            commission of five professors that evening. I join out from politeness. There
            is not much science to celebrate. After dinner I shake hands with Professor
            and the Head. "He did make a lot of noise around here but he did a great job
            and has very nice results," the Professor praises me in front of the Head. I
            smile without saying anything. I leave the place and begin to think about the
            years in front of me. But Professor catches up with me. He is a changed man,
            "Let's keep working together!" He is brimming with enthusiasm. I refuse him
            politely but he keeps talking as though my previous answer carries no weight
            with him, as he always does. "Yes, let's keep cooperating on new projects
            together," he goes on and on. I don't know what's gotten into him. Maybe he
            likes his name on new papers too much? He begins to get on my nerves. I answer
            respectfully with simple no's to all of his questions and proposals. I
            eventually say my goodbyes to him and turn my back. I leave Professor in the
            dark alley and my basement behind for good.
            </p>

            <p>
                © Mihai Olteanu, 2025
            </p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Congress passes Take It Down act despite major flaws (220 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2025/04/congress-passes-take-it-down-act-despite-major-flaws</link>
            <guid>43828568</guid>
            <pubDate>Tue, 29 Apr 2025 03:57:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2025/04/congress-passes-take-it-down-act-despite-major-flaws">https://www.eff.org/deeplinks/2025/04/congress-passes-take-it-down-act-despite-major-flaws</a>, See on <a href="https://news.ycombinator.com/item?id=43828568">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <div>
        <div>
            <article role="article">
  
  
  <div><p>Today the U.S. House of Representatives passed the <a href="https://www.eff.org/deeplinks/2025/02/take-it-down-act-flawed-attempt-protect-victims-will-lead-censorship">TAKE IT DOWN</a> Act<span>, giving the powerful a dangerous new route to manipulate platforms&nbsp;into removing&nbsp;lawful&nbsp;speech that&nbsp;they&nbsp;simply don't like.&nbsp;President Trump himself has said that <a href="https://www.eff.org/deeplinks/2025/03/trump-calls-congress-pass-overbroad-take-it-down-act-so-he-can-use-it-censor">he would use</a> the law to censor his critics. The bill passed the Senate&nbsp;<a href="https://www.eff.org/deeplinks/2025/02/senate-passed-take-it-down-act-threatening-free-expression-and-due-process">in February</a>,&nbsp;and it now heads to the president's&nbsp;desk.&nbsp;</span></p>
<p><span>The takedown provision in TAKE IT DOWN applies to a much broader category of content—potentially any images involving intimate or sexual content—than the narrower NCII definitions found elsewhere in the bill. The takedown provision also lacks critical safeguards against frivolous or bad-faith takedown requests. Services will rely on automated filters, which are infamously blunt tools.&nbsp;They frequently flag legal content, from fair-use commentary to news reporting.&nbsp;The law’s tight time frame requires that apps and websites remove speech within 48 hours, rarely enough time to verify whether the speech is actually illegal. As a result, online service providers, particularly smaller ones, will likely choose to avoid the onerous legal risk by simply depublishing the speech rather than even attempting to verify it.<br></span></p>
<p>Congress is&nbsp;using the wrong approach to helping people whose intimate images are shared without their consent.&nbsp;TAKE IT DOWN pressures platforms to actively monitor speech, including speech that is presently encrypted. The law thus presents a huge threat to security and privacy online. While the bill is meant to address a serious problem, good intentions alone are not enough to make good policy.<span>&nbsp;</span>Lawmakers should be strengthening and enforcing existing legal protections for victims, rather than inventing new takedown regimes that are ripe for abuse.&nbsp;</p>

</div>

          </article>
    </div>
<div>
          <h2>Related Issues</h2>
            </div>

<div>
          <h2>Join EFF Lists</h2>
        
    </div>
<div>
          <h2>Related Updates</h2>
        <div>
        
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/04/texass-war-abortion-now-war-free-speech" rel="bookmark">Texas’s War on Abortion Is Now a War on Free Speech</a></h3>
            
    </header>
  
  
  <div><p><strong>Once again, the Texas legislature is coming after the most common method of safe and effective abortion today—medication abortion.</strong><a href="https://capitol.texas.gov/tlodocs/89R/billtext/pdf/SB02880I.pdf#navpanes=0">Senate Bill (S.B.) 2880</a>* seeks to prevent the sale and distribution of abortion pills—but it doesn’t stop there. By restricting access to certain information online, the bill tries to keep people...</p></div>

          </article>
  </div>
  
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/04/digital-identities-and-future-age-verification-europe" rel="bookmark">Digital Identities and the Future of Age Verification in Europe</a></h3>
            
    </header>
  
  
  <div><p><i>This is the first part of a three-part series about age verification in the European Union. In this blog post, we give an overview of the political debate around age verification and explore the age verification proposal introduced by the European Commission, based on digital identities. Part two takes a</i>...</p></div>

          </article>
  </div>
  
  
  
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/03/eff-joins-7amleh-campaign-reconnectgaza" rel="bookmark">EFF Joins 7amleh Campaign to #ReconnectGaza</a></h3>
            
    </header>
  
  
  <div><p>In times of conflict, the internet becomes more than just a tool—it is a lifeline, connecting those caught in chaos with the outside world. It carries voices that might otherwise be silenced, bearing witness to suffering and survival. Without internet access, communities become isolated, and the flow of critical information...</p></div>

          </article>
  </div>
  
  <div>
    <article role="article">
      <header>
                    <h3><a href="https://www.eff.org/deeplinks/2025/03/eff-stands-perkins-coie-and-rule-law" rel="bookmark">EFF Stands with Perkins Coie and the Rule of Law </a></h3>
            
    </header>
  
  
  <div><p>As a legal organization that has fought in court to defend the rights of technology users for almost 35 years, including numerous legal challenges to federal government overreach, Electronic Frontier Foundation unequivocally supports Perkins Coie’s challenge to the Trump administration’s shocking, vindictive, and unconstitutional <a href="https://www.whitehouse.gov/presidential-actions/2025/03/addressing-risks-from-perkins-coie-llp/" target="_blank" rel="noopener noreferrer">Executive Order</a>....</p></div>

          </article>
  </div>
    </div>    </div>
      </div>

      <div><h2>Related Issues</h2></div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why did Windows 7 log on slower for months if you had a solid color background? (456 pts)]]></title>
            <link>https://devblogs.microsoft.com/oldnewthing/20250428-00/?p=111121</link>
            <guid>43827214</guid>
            <pubDate>Mon, 28 Apr 2025 23:27:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/oldnewthing/20250428-00/?p=111121">https://devblogs.microsoft.com/oldnewthing/20250428-00/?p=111121</a>, See on <a href="https://news.ycombinator.com/item?id=43827214">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="single-wrapper">
    
    <article data-clarity-region="article" id="post-111121">
        <div data-bi-area="body_article" data-bi-id="post_page_body_article">
            <p>Personally, I use a solid color background. It was the default in Windows 95,¹ and I’ve stuck with that bluish-green background color ever since. It’s sort of like my comfort food.</p>
<p>Imagine my surprise when someone pointed me to a support article titled “<a title="The Welcome screen may be displayed for 30 seconds during the logon process after you set a solid color as the desktop background in Windows 7 or in Windows Server 2008 R2" href="https://support.microsoft.com/en-us/topic/the-welcome-screen-may-be-displayed-for-30-seconds-during-the-logon-process-after-you-set-a-solid-color-as-the-desktop-background-in-windows-7-or-in-windows-server-2008-r2-b4565ced-703a-cc85-bf9c-6b3d586d6421">The Welcome screen may be displayed for 30 seconds during the logon process after you set a solid color as the desktop background in Windows 7 or in Windows Server 2008 R2</a>.” Why is logon slower with a solid background?</p>
<p>After your logon has been authenticated, Windows sets up your desktop. There are a lot of things going on. The taskbar gets created. The components that are responsible for various system services are loaded and initialized. The desktop window is created and filled with icons. And the desktop background window loads up the desktop wallpaper and paints it to the screen.</p>
<p>The logon system waits for all of these pieces to report that they are ready, and when the all-clear signal is received from everybody, or when 30 seconds have elapsed, the logon system switches away from the Welcome screen.</p>
<p>Given that design, you can imagine the reason for the 30-second delay: It means that one of the pieces failed to report. Perhaps it was written like this:</p>
<pre>InitializeWallpaper()
{
    if (wallpaper bitmap defined)
    {
        LoadWallpaperBitmap();
    }
}

LoadWallpaperBitmap()
{
    locate the bitmap on disk
    load it into memory
    paint it on screen
    Report(WallpaperReady);
}
</pre>
<p>The code to report that the wallpaper is ready was inside the wallpaper bitmap code, which means that if you don’t have a wallpaper bitmap, the report is never made, and the logon system waits in vain for a report that will never arrive.</p>
<p>Later in the article, it notes a related article that calls out that if you have the “Hide desktop icons” group policy enabled, then you might also suffer from the 30-second delay.</p>
<p>Group policies are susceptible to this problem because they tend to be bolted on after the main code is written. When you have to add a group policy, you find the code that does the thing, and you put a giant “if policy allows” around it.</p>
<pre>// Original code
InitializeDesktopIcons()
{
    bind to the desktop folder
    enumerate the icons
    add them to the screen
    Report(DesktopIconsReady);
}

// Updated with group policy support

InitializeDesktopIcons()
{
    <span>if (desktop icons allowed by policy)</span>
    <span>{                                   </span>
        bind to the desktop folder
        enumerate the icons
        add them to the screen
        Report(DesktopIconsReady);
    <span>}                                   </span>
}
</pre>
<p>Oops, the scope of the “if” block extended past the report call, so if the policy is enabled, the icons are never reported as ready, and the logon system stays on the Welcome screen for the full 30 seconds.</p>
<p>Note that in both of these cases, it’s not that the logon is extended by 30 seconds. Rather, the Welcome screen stays on for the full 30 seconds rather than the actual time it took for all systems to report ready (which could be 5 seconds, or it could be 25 seconds, depending on your system’s performance).</p>
<p>If you look at the timestamps on the articles, you can see that the problem was fixed in November 2009, just a few months after Windows 7 was released in July 2009.</p>
<p>¹ Originally, I avoided bitmap backgrounds because they took up a lot of memory, and when you had only 4 or 8 megabytes of memory, eating three quarters of a megabyte of memory just for wallpaper was not a good return on investment.</p>
<p>Also, I tend to stick with default configurations because it makes bug filing easier. If the repro instructions are “install a system from scratch, then perform these steps”, you’re more likely to get traction than if you say “install a system from scratch, change these 50 settings from their defaults, and then perform these additional steps.” It’s much easier to justify a bug fix that affects the default configuration than a bug fix that requires that the user have changed settings from the default, particularly if those settings are obscure.</p>
        </div><!-- .entry-content -->

        <!-- AI Disclaimer -->
            </article>
    
</div><div><!-- Author section -->
            <h2>Author</h2>
            <div><div><p><img src="https://devblogs.microsoft.com/oldnewthing/wp-content/uploads/sites/38/2019/02/RaymondChen_5in-150x150.jpg" alt="Raymond Chen"></p></div><p>Raymond has been involved in the evolution of Windows for more than 30 years. In 2003, he began a Web site known as The Old New Thing which has grown in popularity far beyond his wildest imagination, a development which still gives him the heebie-jeebies. The Web site spawned a book, coincidentally also titled The Old New Thing (Addison Wesley 2007). He occasionally appears on the Windows Dev Docs Twitter account to tell stories which convey no useful information.</p></div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The 12-bit rainbow palette (302 pts)]]></title>
            <link>https://iamkate.com/data/12-bit-rainbow/</link>
            <guid>43827108</guid>
            <pubDate>Mon, 28 Apr 2025 23:12:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://iamkate.com/data/12-bit-rainbow/">https://iamkate.com/data/12-bit-rainbow/</a>, See on <a href="https://news.ycombinator.com/item?id=43827108">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <p>
        I designed the 12-bit rainbow palette for use on <a href="https://grid.iamkate.com/">National Grid: Live</a>. It consists of twelve colours chosen with consideration for how we perceive luminance, chroma, and hue:
      </p>
      <figure>
        <svg viewBox="0 0 480 40" width="480" height="40">
          <rect fill="#817" x="0" y="0" width="40" height="40"></rect>
          <rect fill="#a36" x="40" y="0" width="40" height="40"></rect>
          <rect fill="#c66" x="80" y="0" width="40" height="40"></rect>
          <rect fill="#e94" x="120" y="0" width="40" height="40"></rect>
          <rect fill="#ed0" x="160" y="0" width="40" height="40"></rect>
          <rect fill="#9d5" x="200" y="0" width="40" height="40"></rect>
          <rect fill="#4d8" x="240" y="0" width="40" height="40"></rect>
          <rect fill="#2cb" x="280" y="0" width="40" height="40"></rect>
          <rect fill="#0bc" x="320" y="0" width="40" height="40"></rect>
          <rect fill="#09c" x="360" y="0" width="40" height="40"></rect>
          <rect fill="#36b" x="400" y="0" width="40" height="40"></rect>
          <rect fill="#639" x="440" y="0" width="40" height="40"></rect>
        </svg>
      </figure>
      <p>
        The palette uses a 12-bit colour depth, so each colour requires only four characters when specified as a hexadecimal colour code in a <abbr>CSS</abbr> or <abbr>SVG</abbr> file:
      </p>
      <div id="palette">
        <p><span>#817</span></p>
        <p><span>#a35</span></p>
        <p><span>#c66</span></p>
        <p><span>#e94</span></p>
        <p><span>#ed0</span></p>
        <p><span>#9d5</span></p>
        <p><span>#4d8</span></p>
        <p><span>#2cb</span></p>
        <p><span>#0bc</span></p>
        <p><span>#09c</span></p>
        <p><span>#36b</span></p>
        <p><span>#639</span></p>
      </div>
      <h2>
        Designing the palette
      </h2>
      <p>
        Computers define colours in terms of red, green, and blue components, which are treated equally. However, we perceive these components as having differing luminance: compared to a pure red, a pure green looks much brighter and a pure blue looks much darker. As a result, a simple <abbr>RGB</abbr> rainbow palette has large changes in luminance between neighbouring colours. This can be seen by converting colours to greys of equal perceived luminance:
      </p>
      <figure>
        <svg viewBox="0 0 480 80" width="480" height="80">
          <rect fill="#ff00ff" x="0" y="0" width="40" height="40"></rect>
          <rect fill="#ff0080" x="40" y="0" width="40" height="40"></rect>
          <rect fill="#ff0000" x="80" y="0" width="40" height="40"></rect>
          <rect fill="#ff8000" x="120" y="0" width="40" height="40"></rect>
          <rect fill="#ffff00" x="160" y="0" width="40" height="40"></rect>
          <rect fill="#80ff00" x="200" y="0" width="40" height="40"></rect>
          <rect fill="#00ff00" x="240" y="0" width="40" height="40"></rect>
          <rect fill="#00ff80" x="280" y="0" width="40" height="40"></rect>
          <rect fill="#00ffff" x="320" y="0" width="40" height="40"></rect>
          <rect fill="#0080ff" x="360" y="0" width="40" height="40"></rect>
          <rect fill="#0000ff" x="400" y="0" width="40" height="40"></rect>
          <rect fill="#8000ff" x="440" y="0" width="40" height="40"></rect>
          <rect fill="#696969" x="0" y="40" width="40" height="40"></rect>
          <rect fill="#5b5b5b" x="40" y="40" width="40" height="40"></rect>
          <rect fill="#4c4c4c" x="80" y="40" width="40" height="40"></rect>
          <rect fill="#979797" x="120" y="40" width="40" height="40"></rect>
          <rect fill="#e2e2e2" x="160" y="40" width="40" height="40"></rect>
          <rect fill="#bcbcbc" x="200" y="40" width="40" height="40"></rect>
          <rect fill="#969696" x="240" y="40" width="40" height="40"></rect>
          <rect fill="#a4a4a4" x="280" y="40" width="40" height="40"></rect>
          <rect fill="#b3b3b3" x="320" y="40" width="40" height="40"></rect>
          <rect fill="#686868" x="360" y="40" width="40" height="40"></rect>
          <rect fill="#1d1d1d" x="400" y="40" width="40" height="40"></rect>
          <rect fill="#434343" x="440" y="40" width="40" height="40"></rect>
        </svg>
      </figure>
      <p>
        The <abbr>LCH</abbr> colour space is an alternative to the <abbr>RGB</abbr> colour space that defines colours in terms of luminance, chroma, and hue components. These components are perceptually uniform, which means that a change by a particular numerical amount will be perceived similarly for any colour.
      </p>
      <p>
        An <abbr>LCH</abbr> rainbow colour palette can be created by choosing fixed chroma and luminance values and varying the hue. However, the resulting palette looks unpleasant because yellow is darkened to brown, red is lightened to pink, and blue becomes very pale.
      </p>
      <p>
        A better approach is to allow the luminance to vary, but in a controlled way. Yellow is given the highest luminance, as it only looks yellow when bright. After choosing two other colours — a red and a blue in this case — the luminance can then be calculated for the other hues.
      </p>
      <p>
        Using a 12-bit colour depth limits the available colours, so slight changes to luminance, chroma, and hue must be made, but these are small enough not to be noticeable. The resulting palette has evenly-spaced hues, only small variations in chroma, and smoothly increasing and decreasing luminance:
      </p>
      <figure>
        <svg viewBox="0 0 480 80" width="480" height="80">
          <rect fill="#817" x="0" y="0" width="40" height="40"></rect>
          <rect fill="#a36" x="40" y="0" width="40" height="40"></rect>
          <rect fill="#c66" x="80" y="0" width="40" height="40"></rect>
          <rect fill="#e94" x="120" y="0" width="40" height="40"></rect>
          <rect fill="#ed0" x="160" y="0" width="40" height="40"></rect>
          <rect fill="#9d5" x="200" y="0" width="40" height="40"></rect>
          <rect fill="#4d8" x="240" y="0" width="40" height="40"></rect>
          <rect fill="#2cb" x="280" y="0" width="40" height="40"></rect>
          <rect fill="#0bc" x="320" y="0" width="40" height="40"></rect>
          <rect fill="#09c" x="360" y="0" width="40" height="40"></rect>
          <rect fill="#36b" x="400" y="0" width="40" height="40"></rect>
          <rect fill="#639" x="440" y="0" width="40" height="40"></rect>
          <rect fill="#404040" x="0" y="40" width="40" height="40"></rect>
          <rect fill="#5c5c5c" x="40" y="40" width="40" height="40"></rect>
          <rect fill="#848484" x="80" y="40" width="40" height="40"></rect>
          <rect fill="#a9a9a9" x="120" y="40" width="40" height="40"></rect>
          <rect fill="#c9c9c9" x="160" y="40" width="40" height="40"></rect>
          <rect fill="#b9b9b9" x="200" y="40" width="40" height="40"></rect>
          <rect fill="#a6a6a6" x="240" y="40" width="40" height="40"></rect>
          <rect fill="#979797" x="280" y="40" width="40" height="40"></rect>
          <rect fill="#858585" x="320" y="40" width="40" height="40"></rect>
          <rect fill="#717171" x="360" y="40" width="40" height="40"></rect>
          <rect fill="#606060" x="400" y="40" width="40" height="40"></rect>
          <rect fill="#4e4e4e" x="440" y="40" width="40" height="40"></rect>
        </svg>
      </figure>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The One-Person Framework in Practice (323 pts)]]></title>
            <link>https://link.mail.beehiiv.com/ss/c/u001.5SRwDQ9qxPQW8vmD5Do73b3R4eTCi2vXqPyztEk6wMFC9_fqEAcDVx6xEJ96T4BSMXrPS7z5exEBSTF4pF48z8SqJkJnkAwMUW9LtYdd8lWmvkDinT92nsk5HmXOHdWgLsysm9FMGrqmu7dnG57cXpga8ZOe8X0IV8pyeC3AswdRMaitfT307y7naP-_6W5CiolKhXCKrEndMGCW2PftFUu9ieYOxpVJ_fhu82gAh-4/4g1/wA_MG-I5SVCyR3KY66oEaQ/h30/h001.kLDFZMgisudi21zmTPbd_O8U7X98d4UxYqZjQTb_D7o</link>
            <guid>43826584</guid>
            <pubDate>Mon, 28 Apr 2025 21:58:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://link.mail.beehiiv.com/ss/c/u001.5SRwDQ9qxPQW8vmD5Do73b3R4eTCi2vXqPyztEk6wMFC9_fqEAcDVx6xEJ96T4BSMXrPS7z5exEBSTF4pF48z8SqJkJnkAwMUW9LtYdd8lWmvkDinT92nsk5HmXOHdWgLsysm9FMGrqmu7dnG57cXpga8ZOe8X0IV8pyeC3AswdRMaitfT307y7naP-_6W5CiolKhXCKrEndMGCW2PftFUu9ieYOxpVJ_fhu82gAh-4/4g1/wA_MG-I5SVCyR3KY66oEaQ/h30/h001.kLDFZMgisudi21zmTPbd_O8U7X98d4UxYqZjQTb_D7o">https://link.mail.beehiiv.com/ss/c/u001.5SRwDQ9qxPQW8vmD5Do73b3R4eTCi2vXqPyztEk6wMFC9_fqEAcDVx6xEJ96T4BSMXrPS7z5exEBSTF4pF48z8SqJkJnkAwMUW9LtYdd8lWmvkDinT92nsk5HmXOHdWgLsysm9FMGrqmu7dnG57cXpga8ZOe8X0IV8pyeC3AswdRMaitfT307y7naP-_6W5CiolKhXCKrEndMGCW2PftFUu9ieYOxpVJ_fhu82gAh-4/4g1/wA_MG-I5SVCyR3KY66oEaQ/h30/h001.kLDFZMgisudi21zmTPbd_O8U7X98d4UxYqZjQTb_D7o</a>, See on <a href="https://news.ycombinator.com/item?id=43826584">Hacker News</a></p>
Couldn't get https://link.mail.beehiiv.com/ss/c/u001.5SRwDQ9qxPQW8vmD5Do73b3R4eTCi2vXqPyztEk6wMFC9_fqEAcDVx6xEJ96T4BSMXrPS7z5exEBSTF4pF48z8SqJkJnkAwMUW9LtYdd8lWmvkDinT92nsk5HmXOHdWgLsysm9FMGrqmu7dnG57cXpga8ZOe8X0IV8pyeC3AswdRMaitfT307y7naP-_6W5CiolKhXCKrEndMGCW2PftFUu9ieYOxpVJ_fhu82gAh-4/4g1/wA_MG-I5SVCyR3KY66oEaQ/h30/h001.kLDFZMgisudi21zmTPbd_O8U7X98d4UxYqZjQTb_D7o: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Qwen3: Think deeper, act faster (780 pts)]]></title>
            <link>https://qwenlm.github.io/blog/qwen3/</link>
            <guid>43825900</guid>
            <pubDate>Mon, 28 Apr 2025 20:44:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qwenlm.github.io/blog/qwen3/">https://qwenlm.github.io/blog/qwen3/</a>, See on <a href="https://news.ycombinator.com/item?id=43825900">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><figure><img src="https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-banner.png" alt="Qwen3 Main Image" width="100%"></figure><p><a href="https://chat.qwen.ai/" target="_blank">QWEN CHAT</a>
<a href="https://github.com/QwenLM/Qwen3" target="_blank">GitHub</a>
<a href="https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f" target="_blank">Hugging Face</a>
<a href="https://modelscope.cn/collections/Qwen3-9743180bdc6b48" target="_blank">ModelScope</a>
<a href="https://www.kaggle.com/models/qwen-lm/qwen-3" target="_blank">Kaggle</a>
<a href="https://huggingface.co/spaces/Qwen/Qwen3-Demo" target="_blank">DEMO</a>
<a href="https://discord.gg/yPEP2vHTu4" target="_blank">DISCORD</a></p><h2 id="introduction">Introduction</h2><p>Today, we are excited to announce the release of <strong>Qwen3</strong>, the latest addition to the Qwen family of large language models. Our flagship model, <strong>Qwen3-235B-A22B</strong>, achieves competitive results in benchmark evaluations of coding, math, general capabilities, etc., when compared to other top-tier models such as DeepSeek-R1, o1, o3-mini, Grok-3, and Gemini-2.5-Pro. Additionally, the small MoE model, <strong>Qwen3-30B-A3B</strong>, outcompetes QwQ-32B with 10 times of activated parameters, and even a tiny model like Qwen3-4B can rival the performance of Qwen2.5-72B-Instruct.</p><figure><img src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3/qwen3-235a22.jpg" width="100%"></figure><figure><img src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3/qwen3-30a3.jpg" width="100%"></figure><p>We are open-weighting two MoE models: <strong>Qwen3-235B-A22B</strong>, a large model with 235 billion total parameters and 22 billion activated parameters, and <strong>Qwen3-30B-A3B</strong>, a smaller MoE model with 30 billion total parameters and 3 billion activated parameters. Additionally, six dense models are also open-weighted, including <strong>Qwen3-32B</strong>, <strong>Qwen3-14B</strong>, <strong>Qwen3-8B</strong>, <strong>Qwen3-4B</strong>, <strong>Qwen3-1.7B</strong>, and <strong>Qwen3-0.6B</strong>, under Apache 2.0 license.</p><table><thead><tr><th>Models</th><th>Layers</th><th>Heads (Q / KV)</th><th>Tie Embedding</th><th>Context Length</th></tr></thead><tbody><tr><td>Qwen3-0.6B</td><td>28</td><td>16 / 8</td><td>Yes</td><td>32K</td></tr><tr><td>Qwen3-1.7B</td><td>28</td><td>16 / 8</td><td>Yes</td><td>32K</td></tr><tr><td>Qwen3-4B</td><td>36</td><td>32 / 8</td><td>Yes</td><td>32K</td></tr><tr><td>Qwen3-8B</td><td>36</td><td>32 / 8</td><td>No</td><td>128K</td></tr><tr><td>Qwen3-14B</td><td>40</td><td>40 / 8</td><td>No</td><td>128K</td></tr><tr><td>Qwen3-32B</td><td>64</td><td>64 / 8</td><td>No</td><td>128K</td></tr></tbody></table><table><thead><tr><th>Models</th><th>Layers</th><th>Heads (Q / KV)</th><th># Experts (Total / Activated)</th><th>Context Length</th></tr></thead><tbody><tr><td>Qwen3-30B-A3B</td><td>48</td><td>32 / 4</td><td>128 / 8</td><td>128K</td></tr><tr><td>Qwen3-235B-A22B</td><td>94</td><td>64 / 4</td><td>128 / 8</td><td>128K</td></tr></tbody></table><p>The post-trained models, such as <strong>Qwen3-30B-A3B</strong>, along with their pre-trained counterparts (e.g., <strong>Qwen3-30B-A3B-Base</strong>), are now available on platforms like <strong>Hugging Face</strong>, <strong>ModelScope</strong>, and <strong>Kaggle</strong>. For deployment, we recommend using frameworks like <strong>SGLang</strong> and <strong>vLLM</strong>. For local usage, tools such as <strong>Ollama</strong>, <strong>LMStudio</strong>, <strong>MLX</strong>, <strong>llama.cpp</strong>, and <strong>KTransformers</strong> are highly recommended. These options ensure that users can easily integrate Qwen3 into their workflows, whether in research, development, or production environments.</p><p>We believe that the release and open-sourcing of Qwen3 will significantly advance the research and development of large foundation models. Our goal is to empower researchers, developers, and organizations around the world to build innovative solutions using these cutting-edge models.</p><p>Feel free to try Qwen3 out in Qwen Chat Web (<a href="https://chat.qwen.ai/">chat.qwen.ai</a>) and mobile APP!</p><h2 id="key-features">Key Features</h2><ul><li><strong>Hybrid Thinking Modes</strong></li></ul><p>Qwen3 models introduce a hybrid approach to problem-solving. They support two modes:</p><ol><li>Thinking Mode: In this mode, the model takes time to reason step by step before delivering the final answer. This is ideal for complex problems that require deeper thought.</li><li>Non-Thinking Mode: Here, the model provides quick, near-instant responses, suitable for simpler questions where speed is more important than depth.</li></ol><p>This flexibility allows users to control how much “thinking” the model performs based on the task at hand. For example, harder problems can be tackled with extended reasoning, while easier ones can be answered directly without delay. Crucially, the integration of these two modes greatly enhances the model’s ability to implement stable and efficient thinking budget control. As demonstrated above, Qwen3 exhibits scalable and smooth performance improvements that are directly correlated with the computational reasoning budget allocated. This design enables users to configure task-specific budgets with greater ease, achieving a more optimal balance between cost efficiency and inference quality.</p><figure><img src="https://qianwen-res.oss-accelerate.aliyuncs.com/assets/blog/qwen3/thinking_budget.png" width="100%"></figure><ul><li><strong>Multilingual Support</strong></li></ul><p>Qwen3 models are supporting <strong>119 languages and dialects</strong>. This extensive multilingual capability opens up new possibilities for international applications, enabling users worldwide to benefit from the power of these models.</p><table><thead><tr><th>Language Family</th><th>Languages &amp; Dialects</th></tr></thead><tbody><tr><td>Indo-European</td><td>English, French, Portuguese, German, Romanian, Swedish, Danish, Bulgarian, Russian, Czech, Greek, Ukrainian, Spanish, Dutch, Slovak, Croatian, Polish, Lithuanian, Norwegian Bokmål, Norwegian Nynorsk, Persian, Slovenian, Gujarati, Latvian, Italian, Occitan, Nepali, Marathi, Belarusian, Serbian, Luxembourgish, Venetian, Assamese, Welsh, Silesian, Asturian, Chhattisgarhi, Awadhi, Maithili, Bhojpuri, Sindhi, Irish, Faroese, Hindi, Punjabi, Bengali, Oriya, Tajik, Eastern Yiddish, Lombard, Ligurian, Sicilian, Friulian, Sardinian, Galician, Catalan, Icelandic, Tosk Albanian, Limburgish, Dari, Afrikaans, Macedonian, Sinhala, Urdu, Magahi, Bosnian, Armenian</td></tr><tr><td>Sino-Tibetan</td><td>Chinese (Simplified Chinese, Traditional Chinese, Cantonese), Burmese</td></tr><tr><td>Afro-Asiatic</td><td>Arabic (Standard, Najdi, Levantine, Egyptian, Moroccan, Mesopotamian, Ta’izzi-Adeni, Tunisian), Hebrew, Maltese</td></tr><tr><td>Austronesian</td><td>Indonesian, Malay, Tagalog, Cebuano, Javanese, Sundanese, Minangkabau, Balinese, Banjar, Pangasinan, Iloko, Waray (Philippines)</td></tr><tr><td>Dravidian</td><td>Tamil, Telugu, Kannada, Malayalam</td></tr><tr><td>Turkic</td><td>Turkish, North Azerbaijani, Northern Uzbek, Kazakh, Bashkir, Tatar</td></tr><tr><td>Tai-Kadai</td><td>Thai, Lao</td></tr><tr><td>Uralic</td><td>Finnish, Estonian, Hungarian</td></tr><tr><td>Austroasiatic</td><td>Vietnamese, Khmer</td></tr><tr><td>Other</td><td>Japanese, Korean, Georgian, Basque, Haitian, Papiamento, Kabuverdianu, Tok Pisin, Swahili</td></tr></tbody></table><ul><li><strong>Improved Agentic Capabilities</strong></li></ul><p>We have optimized the Qwen3 models for coding and agentic capabilities, and also we have strengthened the support of MCP as well. Below we provide examples to show how Qwen3 thinks and interacts with the environment.</p><h2 id="pre-training">Pre-training</h2><p>In terms of pretraining, the dataset for Qwen3 has been significantly expanded compared to Qwen2.5. While Qwen2.5 was pre-trained on 18 trillion tokens, Qwen3 uses nearly twice that amount, with approximately 36 trillion tokens covering 119 languages and dialects. To build this large dataset, we collected data not only from the web but also from PDF-like documents. We used Qwen2.5-VL to extract text from these documents and Qwen2.5 to improve the quality of the extracted content. To increase the amount of math and code data, we used Qwen2.5-Math and Qwen2.5-Coder to generate synthetic data. This includes textbooks, question-answer pairs, and code snippets.</p><p>The pre-training process consists of three stages. In the first stage (S1), the model was pretrained on over 30 trillion tokens with a context length of 4K tokens. This stage provided the model with basic language skills and general knowledge. In the second stage (S2), we improved the dataset by increasing the proportion of knowledge-intensive data, such as STEM, coding, and reasoning tasks. The model was then pretrained on an additional 5 trillion tokens. In the final stage, we used high-quality long-context data to extend the context length to 32K tokens. This ensures the model can handle longer inputs effectively.</p><figure><img src="https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-base.jpg" width="100%"></figure><p>Due to advancements in model architecture, increase in training data, and more effective training methods, the overall performance of Qwen3 dense base models matches that of Qwen2.5 base models with more parameters. For instance, Qwen3-1.7B/4B/8B/14B/32B-Base performs as well as Qwen2.5-3B/7B/14B/32B/72B-Base, respectively. Notably, in areas like STEM, coding, and reasoning, Qwen3 dense base models even outperform larger Qwen2.5 models. For Qwen3-MoE base models, they achieve similar performance to Qwen2.5 dense base models while using only 10% of the active parameters. This results in significant savings in both training and inference costs.</p><h2 id="post-training">Post-training</h2><figure><img src="https://qianwen-res.oss-accelerate.aliyuncs.com/assets/blog/qwen3/post-training.png" width="100%"></figure><p>To develop the hybrid model capable of both step-by-step reasoning and rapid responses, we implemented a four-stage training pipeline. This pipeline includes: (1) long chain-of-thought (CoT) cold start, (2) reasoning-based reinforcement learning (RL), (3) thinking mode fusion, and (4) general RL.</p><p>In the first stage, we fine-tuned the models using diverse long CoT data, covering various tasks and domains such as mathematics, coding, logical reasoning, and STEM problems. This process aimed to equip the model with fundamental reasoning abilities. The second stage focused on scaling up computational resources for RL, utilizing rule-based rewards to enhance the model’s exploration and exploitation capabilities.</p><p>In the third stage, we integrated non-thinking capabilities into the thinking model by fine-tuning it on a combination of long CoT data and commonly used instruction-tuning data. This data was generated by the enhanced thinking model from the second stage, ensuring a seamless blend of reasoning and quick response capabilities. Finally, in the fourth stage, we applied RL across more than 20 general-domain tasks to further strengthen the model’s general capabilities and correct undesired behaviors. These tasks included instruction following, format following, and agent capabilities, etc.</p><h2 id="develop-with-qwen3">Develop with Qwen3</h2><p>Below is a simple guide for you to use Qwen3 on different frameworks. First of all, we provide an standard example of using Qwen3-30B-A3B in Hugging Face transformers:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>modelscope</span> <span>import</span> <span>AutoModelForCausalLM</span><span>,</span> <span>AutoTokenizer</span>
</span></span><span><span>
</span></span><span><span><span>model_name</span> <span>=</span> <span>"Qwen/Qwen3-30B-A3B"</span>
</span></span><span><span>
</span></span><span><span><span># load the tokenizer and the model</span>
</span></span><span><span><span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_name</span><span>)</span>
</span></span><span><span><span>model</span> <span>=</span> <span>AutoModelForCausalLM</span><span>.</span><span>from_pretrained</span><span>(</span>
</span></span><span><span>    <span>model_name</span><span>,</span>
</span></span><span><span>    <span>torch_dtype</span><span>=</span><span>"auto"</span><span>,</span>
</span></span><span><span>    <span>device_map</span><span>=</span><span>"auto"</span>
</span></span><span><span><span>)</span>
</span></span><span><span>
</span></span><span><span><span># prepare the model input</span>
</span></span><span><span><span>prompt</span> <span>=</span> <span>"Give me a short introduction to large language model."</span>
</span></span><span><span><span>messages</span> <span>=</span> <span>[</span>
</span></span><span><span>    <span>{</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>prompt</span><span>}</span>
</span></span><span><span><span>]</span>
</span></span><span><span><span>text</span> <span>=</span> <span>tokenizer</span><span>.</span><span>apply_chat_template</span><span>(</span>
</span></span><span><span>    <span>messages</span><span>,</span>
</span></span><span><span>    <span>tokenize</span><span>=</span><span>False</span><span>,</span>
</span></span><span><span>    <span>add_generation_prompt</span><span>=</span><span>True</span><span>,</span>
</span></span><span><span>    <span>enable_thinking</span><span>=</span><span>True</span> <span># Switch between thinking and non-thinking modes. Default is True.</span>
</span></span><span><span><span>)</span>
</span></span><span><span><span>model_inputs</span> <span>=</span> <span>tokenizer</span><span>([</span><span>text</span><span>],</span> <span>return_tensors</span><span>=</span><span>"pt"</span><span>)</span><span>.</span><span>to</span><span>(</span><span>model</span><span>.</span><span>device</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span># conduct text completion</span>
</span></span><span><span><span>generated_ids</span> <span>=</span> <span>model</span><span>.</span><span>generate</span><span>(</span>
</span></span><span><span>    <span>**</span><span>model_inputs</span><span>,</span>
</span></span><span><span>    <span>max_new_tokens</span><span>=</span><span>32768</span>
</span></span><span><span><span>)</span>
</span></span><span><span><span>output_ids</span> <span>=</span> <span>generated_ids</span><span>[</span><span>0</span><span>][</span><span>len</span><span>(</span><span>model_inputs</span><span>.</span><span>input_ids</span><span>[</span><span>0</span><span>]):]</span><span>.</span><span>tolist</span><span>()</span> 
</span></span><span><span>
</span></span><span><span><span># parsing thinking content</span>
</span></span><span><span><span>try</span><span>:</span>
</span></span><span><span>    <span># rindex finding 151668 (&lt;/think&gt;)</span>
</span></span><span><span>    <span>index</span> <span>=</span> <span>len</span><span>(</span><span>output_ids</span><span>)</span> <span>-</span> <span>output_ids</span><span>[::</span><span>-</span><span>1</span><span>]</span><span>.</span><span>index</span><span>(</span><span>151668</span><span>)</span>
</span></span><span><span><span>except</span> <span>ValueError</span><span>:</span>
</span></span><span><span>    <span>index</span> <span>=</span> <span>0</span>
</span></span><span><span>
</span></span><span><span><span>thinking_content</span> <span>=</span> <span>tokenizer</span><span>.</span><span>decode</span><span>(</span><span>output_ids</span><span>[:</span><span>index</span><span>],</span> <span>skip_special_tokens</span><span>=</span><span>True</span><span>)</span><span>.</span><span>strip</span><span>(</span><span>"</span><span>\n</span><span>"</span><span>)</span>
</span></span><span><span><span>content</span> <span>=</span> <span>tokenizer</span><span>.</span><span>decode</span><span>(</span><span>output_ids</span><span>[</span><span>index</span><span>:],</span> <span>skip_special_tokens</span><span>=</span><span>True</span><span>)</span><span>.</span><span>strip</span><span>(</span><span>"</span><span>\n</span><span>"</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>print</span><span>(</span><span>"thinking content:"</span><span>,</span> <span>thinking_content</span><span>)</span>
</span></span><span><span><span>print</span><span>(</span><span>"content:"</span><span>,</span> <span>content</span><span>)</span>
</span></span></code></pre></div><p>To disable thinking, you just need to make changes to the argument <code>enable_thinking</code> like the following:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>text</span> <span>=</span> <span>tokenizer</span><span>.</span><span>apply_chat_template</span><span>(</span>
</span></span><span><span>    <span>messages</span><span>,</span>
</span></span><span><span>    <span>tokenize</span><span>=</span><span>False</span><span>,</span>
</span></span><span><span>    <span>add_generation_prompt</span><span>=</span><span>True</span><span>,</span>
</span></span><span><span>    <span>enable_thinking</span><span>=</span><span>False</span>  <span># True is the default value for enable_thinking.</span>
</span></span><span><span><span>)</span>
</span></span></code></pre></div><p>For deployment, you can use <code>sglang&gt;=0.4.6.post1</code> or <code>vllm&gt;=0.8.4</code> to create an OpenAI-compatible API endpoint:</p><ul><li><p>SGLang:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>python -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B --reasoning-parser qwen3
</span></span></code></pre></div></li><li><p>vLLM:</p><div><pre tabindex="0"><code data-lang="shell"><span><span>vllm serve Qwen/Qwen3-30B-A3B --enable-reasoning --reasoning-parser deepseek_r1
</span></span></code></pre></div></li></ul><p>If you use it for local development, you can use ollama by running a simple command <code>ollama run qwen3:30b-a3b</code> to play with the model, or you can use LMStudio or llama.cpp and ktransformers to build locally.</p><h3 id="advanced-usages">Advanced Usages</h3><p>We provide a soft switch mechanism that allows users to dynamically control the model’s behavior when enable_thinking=True. Specifically, you can add /think and /no_think to user prompts or system messages to switch the model’s thinking mode from turn to turn. The model will follow the most recent instruction in multi-turn conversations.</p><p>Here is an example of a multi-turn conversation:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>transformers</span> <span>import</span> <span>AutoModelForCausalLM</span><span>,</span> <span>AutoTokenizer</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>QwenChatbot</span><span>:</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>model_name</span><span>=</span><span>"Qwen/Qwen3-30B-A3B"</span><span>):</span>
</span></span><span><span>        <span>self</span><span>.</span><span>tokenizer</span> <span>=</span> <span>AutoTokenizer</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_name</span><span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>model</span> <span>=</span> <span>AutoModelForCausalLM</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_name</span><span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>history</span> <span>=</span> <span>[]</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>generate_response</span><span>(</span><span>self</span><span>,</span> <span>user_input</span><span>):</span>
</span></span><span><span>        <span>messages</span> <span>=</span> <span>self</span><span>.</span><span>history</span> <span>+</span> <span>[{</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>user_input</span><span>}]</span>
</span></span><span><span>
</span></span><span><span>        <span>text</span> <span>=</span> <span>self</span><span>.</span><span>tokenizer</span><span>.</span><span>apply_chat_template</span><span>(</span>
</span></span><span><span>            <span>messages</span><span>,</span>
</span></span><span><span>            <span>tokenize</span><span>=</span><span>False</span><span>,</span>
</span></span><span><span>            <span>add_generation_prompt</span><span>=</span><span>True</span>
</span></span><span><span>        <span>)</span>
</span></span><span><span>
</span></span><span><span>        <span>inputs</span> <span>=</span> <span>self</span><span>.</span><span>tokenizer</span><span>(</span><span>text</span><span>,</span> <span>return_tensors</span><span>=</span><span>"pt"</span><span>)</span>
</span></span><span><span>        <span>response_ids</span> <span>=</span> <span>self</span><span>.</span><span>model</span><span>.</span><span>generate</span><span>(</span><span>**</span><span>inputs</span><span>,</span> <span>max_new_tokens</span><span>=</span><span>32768</span><span>)[</span><span>0</span><span>][</span><span>len</span><span>(</span><span>inputs</span><span>.</span><span>input_ids</span><span>[</span><span>0</span><span>]):]</span><span>.</span><span>tolist</span><span>()</span>
</span></span><span><span>        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>tokenizer</span><span>.</span><span>decode</span><span>(</span><span>response_ids</span><span>,</span> <span>skip_special_tokens</span><span>=</span><span>True</span><span>)</span>
</span></span><span><span>
</span></span><span><span>        <span># Update history</span>
</span></span><span><span>        <span>self</span><span>.</span><span>history</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>user_input</span><span>})</span>
</span></span><span><span>        <span>self</span><span>.</span><span>history</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"assistant"</span><span>,</span> <span>"content"</span><span>:</span> <span>response</span><span>})</span>
</span></span><span><span>
</span></span><span><span>        <span>return</span> <span>response</span>
</span></span><span><span>
</span></span><span><span><span># Example Usage</span>
</span></span><span><span><span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
</span></span><span><span>    <span>chatbot</span> <span>=</span> <span>QwenChatbot</span><span>()</span>
</span></span><span><span>
</span></span><span><span>    <span># First input (without /think or /no_think tags, thinking mode is enabled by default)</span>
</span></span><span><span>    <span>user_input_1</span> <span>=</span> <span>"How many r's in strawberries?"</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"User: </span><span>{</span><span>user_input_1</span><span>}</span><span>"</span><span>)</span>
</span></span><span><span>    <span>response_1</span> <span>=</span> <span>chatbot</span><span>.</span><span>generate_response</span><span>(</span><span>user_input_1</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"Bot: </span><span>{</span><span>response_1</span><span>}</span><span>"</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>"----------------------"</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span># Second input with /no_think</span>
</span></span><span><span>    <span>user_input_2</span> <span>=</span> <span>"Then, how many r's in blueberries? /no_think"</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"User: </span><span>{</span><span>user_input_2</span><span>}</span><span>"</span><span>)</span>
</span></span><span><span>    <span>response_2</span> <span>=</span> <span>chatbot</span><span>.</span><span>generate_response</span><span>(</span><span>user_input_2</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"Bot: </span><span>{</span><span>response_2</span><span>}</span><span>"</span><span>)</span> 
</span></span><span><span>    <span>print</span><span>(</span><span>"----------------------"</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span># Third input with /think</span>
</span></span><span><span>    <span>user_input_3</span> <span>=</span> <span>"Really? /think"</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"User: </span><span>{</span><span>user_input_3</span><span>}</span><span>"</span><span>)</span>
</span></span><span><span>    <span>response_3</span> <span>=</span> <span>chatbot</span><span>.</span><span>generate_response</span><span>(</span><span>user_input_3</span><span>)</span>
</span></span><span><span>    <span>print</span><span>(</span><span>f</span><span>"Bot: </span><span>{</span><span>response_3</span><span>}</span><span>"</span><span>)</span>
</span></span></code></pre></div><h3 id="agentic-usages">Agentic Usages</h3><p>Qwen3 excels in tool calling capabilities. We recommend using <a href="https://github.com/QwenLM/Qwen-Agent">Qwen-Agent</a> to make the best use of agentic ability of Qwen3. Qwen-Agent encapsulates tool-calling templates and tool-calling parsers internally, greatly reducing coding complexity.</p><p>To define the available tools, you can use the MCP configuration file, use the integrated tool of Qwen-Agent, or integrate other tools by yourself.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>qwen_agent.agents</span> <span>import</span> <span>Assistant</span>
</span></span><span><span>
</span></span><span><span><span># Define LLM</span>
</span></span><span><span><span>llm_cfg</span> <span>=</span> <span>{</span>
</span></span><span><span>    <span>'model'</span><span>:</span> <span>'Qwen3-30B-A3B'</span><span>,</span>
</span></span><span><span>
</span></span><span><span>    <span># Use the endpoint provided by Alibaba Model Studio:</span>
</span></span><span><span>    <span># 'model_type': 'qwen_dashscope',</span>
</span></span><span><span>    <span># 'api_key': os.getenv('DASHSCOPE_API_KEY'),</span>
</span></span><span><span>
</span></span><span><span>    <span># Use a custom endpoint compatible with OpenAI API:</span>
</span></span><span><span>    <span>'model_server'</span><span>:</span> <span>'http://localhost:8000/v1'</span><span>,</span>  <span># api_base</span>
</span></span><span><span>    <span>'api_key'</span><span>:</span> <span>'EMPTY'</span><span>,</span>
</span></span><span><span>
</span></span><span><span>    <span># Other parameters:</span>
</span></span><span><span>    <span># 'generate_cfg': {</span>
</span></span><span><span>    <span>#         # Add: When the response content is `&lt;think&gt;this is the thought&lt;/think&gt;this is the answer;</span>
</span></span><span><span>    <span>#         # Do not add: When the response has been separated by reasoning_content and content.</span>
</span></span><span><span>    <span>#         'thought_in_content': True,</span>
</span></span><span><span>    <span>#     },</span>
</span></span><span><span><span>}</span>
</span></span><span><span>
</span></span><span><span><span># Define Tools</span>
</span></span><span><span><span>tools</span> <span>=</span> <span>[</span>
</span></span><span><span>    <span>{</span><span>'mcpServers'</span><span>:</span> <span>{</span>  <span># You can specify the MCP configuration file</span>
</span></span><span><span>            <span>'time'</span><span>:</span> <span>{</span>
</span></span><span><span>                <span>'command'</span><span>:</span> <span>'uvx'</span><span>,</span>
</span></span><span><span>                <span>'args'</span><span>:</span> <span>[</span><span>'mcp-server-time'</span><span>,</span> <span>'--local-timezone=Asia/Shanghai'</span><span>]</span>
</span></span><span><span>            <span>},</span>
</span></span><span><span>            <span>"fetch"</span><span>:</span> <span>{</span>
</span></span><span><span>                <span>"command"</span><span>:</span> <span>"uvx"</span><span>,</span>
</span></span><span><span>                <span>"args"</span><span>:</span> <span>[</span><span>"mcp-server-fetch"</span><span>]</span>
</span></span><span><span>            <span>}</span>
</span></span><span><span>        <span>}</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>  <span>'code_interpreter'</span><span>,</span>  <span># Built-in tools</span>
</span></span><span><span><span>]</span>
</span></span><span><span>
</span></span><span><span><span># Define Agent</span>
</span></span><span><span><span>bot</span> <span>=</span> <span>Assistant</span><span>(</span><span>llm</span><span>=</span><span>llm_cfg</span><span>,</span> <span>function_list</span><span>=</span><span>tools</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span># Streaming generation</span>
</span></span><span><span><span>messages</span> <span>=</span> <span>[{</span><span>'role'</span><span>:</span> <span>'user'</span><span>,</span> <span>'content'</span><span>:</span> <span>'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'</span><span>}]</span>
</span></span><span><span><span>for</span> <span>responses</span> <span>in</span> <span>bot</span><span>.</span><span>run</span><span>(</span><span>messages</span><span>=</span><span>messages</span><span>):</span>
</span></span><span><span>    <span>pass</span>
</span></span><span><span><span>print</span><span>(</span><span>responses</span><span>)</span>
</span></span></code></pre></div><h2 id="friends-of-qwen">Friends of Qwen</h2><p>Thanks to the support of so many friends. Qwen is nothing without its friends! We welcome more people or organizations to join our community and help us become better!</p><figure><img src="https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwen3-logo.png" width="100%"></figure><h2 id="future-work">Future Work</h2><p>Qwen3 represents a significant milestone in our journey toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI). By scaling up both pretraining and reinforcement learning (RL), we have achieved higher levels of intelligence. We have seamlessly integrated thinking and non-thinking modes, offering users the flexibility to control the thinking budget. Additionally, we have expanded support for a wide range of languages, enhancing global accessibility.</p><p>Looking ahead, we aim to enhance our models across multiple dimensions. This includes refining model architectures and training methodologies to achieve several key objectives: scaling data, increasing model size, extending context length, broadening modalities, and advancing RL with environmental feedback for long-horizon reasoning. We believe we are transitioning from an era focused on training models to one centered on training agents. Our next iteration promises to bring meaningful advancements to everyone’s work and life.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[One Million Chessboards (297 pts)]]></title>
            <link>https://eieio.games/blog/one-million-chessboards/</link>
            <guid>43825336</guid>
            <pubDate>Mon, 28 Apr 2025 19:52:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eieio.games/blog/one-million-chessboards/">https://eieio.games/blog/one-million-chessboards/</a>, See on <a href="https://news.ycombinator.com/item?id=43825336">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><a href="https://eieio.games/blog/one-million-chessboards/"></a><div><p>a million chessboards that anyone can play on</p><p>Apr 28, 2025</p></div></div>
<p>I made a website. It’s called <a href="https://onemillionchessboards.com/">One Million Chessboards</a>. It has one million chessboards on it.</p>
<p>Moving a piece moves it for everyone, instantly. There are no turns. You can move between boards.</p>
<div><video controls="" playsinline="" poster="https://eieio.games/images/one-million-chessboards/gameplay-firstframe.png" width="2136" height="1708" preload="metadata" alt="Gameplay from One Million Chessboards. The player moves a queen around on a grid of a million boards as pieces move around him."><p>Loading...</p></video><p>moving some pieces</p></div>
<!-- -->
<h2 id="toc:what">What</h2>
<p>Well last year I made this game called <a href="https://eieio.games/blog/one-million-checkboxes">One Million Checkboxes</a>.</p>
<p>It was a pretty fun time! So I thought I’d do something like this again.</p>
<p>I worked really hard on this one. I hope you like it.</p>
<h2 id="toc:how">How</h2>
<p>This was the most technically challenging thing that I’ve worked on in a long time. I’m going to save a full technical writeup until I see how my decisions pan out, since I think there’s a decent chance I’ll need to make a lot of changes.</p>
<p>But I’ll summarize a few things for you.</p>
<ul>
<li>Unlike One Million Checkboxes, I designed this for scale</li>
<li>The game runs on a single server (!)</li>
<li>The board is stored fully in-memory; it’s a 2D array of 64 million uint64s</li>
<li>The backend is written in go. This is my first go project.</li>
<li>I use a single writer thread, tons of reader threads, and coordinate access to the board with a mutex</li>
<li>The frontend optimistically applies all moves you make immediately. It then builds up a dependency graph of the moves you’ve made, and backs them out if it receives a conflicting update before the server acks your move.</li>
<li>The server ships zstd-compressed protobufs to the clients over websockets for state snapshots (approximately a 100x100 square around the client), move and capture updates, and acks/rejections for moves</li>
<li>Clients are grouped into 50x50 “zones” and only receive moves for zones adjacent to their current zone</li>
<li>Clients fetch global data (game stats, the minimap, etc) by polling via GET; data is cached in Cloudflare with a low TTL so this is much cheaper than shipping it over every websocket</li>
</ul>
<p>That last part - optimistic move application with what games people sometimes call “rollback” - is about 1,600 lines of code that took me a ~7 days of fulltime work to write. I don’t remember the last time I wrestled with a problem that hard!</p>
<p>As of 8 PM, 8 hours after launch, players have made about 1.3 million moves and there are about 400 concurrent users most of the time. Load on my server is neglibible!</p>
<h2 id="toc:can-i-play">Can I play</h2>
<p>Yes! <a href="https://onemillionchessboards.com/">Play it here</a>.</p>
<p>I really hope you like this one. More updates to come :)</p></article></div>]]></description>
        </item>
    </channel>
</rss>