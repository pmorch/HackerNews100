<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 10 Dec 2023 22:00:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Ratatui (154 pts)]]></title>
            <link>https://github.com/ratatui-org/ratatui</link>
            <guid>38593638</guid>
            <pubDate>Sun, 10 Dec 2023 18:28:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ratatui-org/ratatui">https://github.com/ratatui-org/ratatui</a>, See on <a href="https://news.ycombinator.com/item?id=38593638">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><details>
<summary>Table of Contents</summary>
<ul dir="auto">
<li><a href="#ratatui">Ratatui</a>
<ul dir="auto">
<li><a href="#installation">Installation</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#other-documentation">Other Documentation</a></li>
<li><a href="#quickstart">Quickstart</a></li>
<li><a href="#status-of-this-fork">Status of this fork</a></li>
<li><a href="#rust-version-requirements">Rust version requirements</a></li>
<li><a href="#widgets">Widgets</a>
<ul dir="auto">
<li><a href="#built-in">Built in</a></li>
<li><a href="#third-party-libraries-bootstrapping-templates-and-widgets">Third-party libraries, bootstrapping templates and
widgets</a></li>
</ul>
</li>
<li><a href="#apps">Apps</a></li>
<li><a href="#alternatives">Alternatives</a></li>
<li><a href="#acknowledgments">Acknowledgments</a></li>
<li><a href="#license">License</a></li>
</ul>
</li>
</ul>
</details>

<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/ratatui-org/ratatui/b33c878808c4c40591d7a2d9f9d94d6fee95a96f/examples/demo2.gif"><img src="https://raw.githubusercontent.com/ratatui-org/ratatui/b33c878808c4c40591d7a2d9f9d94d6fee95a96f/examples/demo2.gif" alt="Demo" data-animated-image=""></a></p>

<h2 tabindex="-1" dir="auto">Ratatui</h2>
<p dir="auto"><a href="https://ratatui.rs/" rel="nofollow">Ratatui</a> is a crate for cooking up terminal user interfaces in Rust. It is a lightweight
library that provides a set of widgets and utilities to build complex Rust TUIs. Ratatui was
forked from the <a href="https://crates.io/crates/tui" rel="nofollow">tui-rs</a> crate in 2023 in order to continue its development.</p>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">Add <code>ratatui</code> and <code>crossterm</code> as dependencies to your cargo.toml:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo add ratatui crossterm"><pre>cargo add ratatui crossterm</pre></div>
<p dir="auto">Ratatui uses <a href="https://crates.io/crates/crossterm" rel="nofollow">Crossterm</a> by default as it works on most platforms. See the <a href="https://ratatui.rs/installation/" rel="nofollow">Installation</a>
section of the <a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> for more details on how to use other backends (<a href="https://crates.io/crates/termion" rel="nofollow">Termion</a> /
<a href="https://crates.io/crates/termwiz" rel="nofollow">Termwiz</a>).</p>
<h2 tabindex="-1" dir="auto">Introduction</h2>
<p dir="auto">Ratatui is based on the principle of immediate rendering with intermediate buffers. This means
that for each frame, your app must render all widgets that are supposed to be part of the UI.
This is in contrast to the retained mode style of rendering where widgets are updated and then
automatically redrawn on the next frame. See the <a href="https://ratatui.rs/concepts/rendering/" rel="nofollow">Rendering</a> section of the <a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> for
more info.</p>
<h2 tabindex="-1" dir="auto">Other documentation</h2>
<ul dir="auto">
<li><a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> - explains the library's concepts and provides step-by-step tutorials</li>
<li><a href="https://github.com/ratatui-org/ratatui/tree/main/examples">Examples</a> - a collection of examples that demonstrate how to use the library.</li>
<li><a href="https://docs.rs/ratatui" rel="nofollow">API Documentation</a> - the full API documentation for the library on docs.rs.</li>
<li><a href="https://github.com/ratatui-org/ratatui/blob/main/CHANGELOG.md">Changelog</a> - generated by <a href="https://git-cliff.org/" rel="nofollow">git-cliff</a> utilizing <a href="https://www.conventionalcommits.org/" rel="nofollow">Conventional Commits</a>.</li>
<li><a href="https://github.com/ratatui-org/ratatui/blob/main/CONTRIBUTING.md">Contributing</a> - Please read this if you are interested in contributing to the project.</li>
<li><a href="https://github.com/ratatui-org/ratatui/blob/main/BREAKING-CHANGES.md">Breaking Changes</a> - a list of breaking changes in the library.</li>
</ul>
<h2 tabindex="-1" dir="auto">Quickstart</h2>
<p dir="auto">The following example demonstrates the minimal amount of code necessary to setup a terminal and
render "Hello World!". The full code for this example which contains a little more detail is in
<a href="https://github.com/ratatui-org/ratatui/blob/main/examples/hello_world.rs">hello_world.rs</a>. For more guidance on different ways to structure your application see the
<a href="https://ratatui.rs/concepts/application-patterns/" rel="nofollow">Application Patterns</a> and <a href="https://ratatui.rs/tutorials/hello-world/" rel="nofollow">Hello World tutorial</a> sections in the <a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> and the various
<a href="https://github.com/ratatui-org/ratatui/tree/main/examples">Examples</a>. There are also several starter templates available:</p>
<ul dir="auto">
<li><a href="https://github.com/ratatui-org/ratatui-template">ratatui-template</a></li>
<li><a href="https://ratatui-org.github.io/ratatui-async-template" rel="nofollow">ratatui-async-template</a> (book and template)</li>
</ul>
<p dir="auto">Every application built with <code>ratatui</code> needs to implement the following steps:</p>
<ul dir="auto">
<li>Initialize the terminal</li>
<li>A main loop to:
<ul dir="auto">
<li>Handle input events</li>
<li>Draw the UI</li>
</ul>
</li>
<li>Restore the terminal state</li>
</ul>
<p dir="auto">The library contains a [<code>prelude</code>] module that re-exports the most commonly used traits and
types for convenience. Most examples in the documentation will use this instead of showing the
full path of each type.</p>
<h3 tabindex="-1" dir="auto">Initialize and restore the terminal</h3>
<p dir="auto">The [<code>Terminal</code>] type is the main entry point for any Ratatui application. It is a light
abstraction over a choice of <code>Backend</code> implementations that provides functionality to draw
each frame, clear the screen, hide the cursor, etc. It is parametrized over any type that
implements the <code>Backend</code> trait which has implementations for <a href="https://crates.io/crates/crossterm" rel="nofollow">Crossterm</a>, <a href="https://crates.io/crates/termion" rel="nofollow">Termion</a> and
<a href="https://crates.io/crates/termwiz" rel="nofollow">Termwiz</a>.</p>
<p dir="auto">Most applications should enter the Alternate Screen when starting and leave it when exiting and
also enable raw mode to disable line buffering and enable reading key events. See the <a href="https://github.com/ratatui-org/ratatui/blob/main/backend"><code>backend</code>
module</a> and the <a href="https://ratatui.rs/concepts/backends/" rel="nofollow">Backends</a> section of the <a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> for more info.</p>
<h3 tabindex="-1" dir="auto">Drawing the UI</h3>
<p dir="auto">The drawing logic is delegated to a closure that takes a <code>Frame</code> instance as argument. The
<code>Frame</code> provides the size of the area to draw to and allows the app to render any <code>Widget</code>
using the provided <code>render_widget</code> method. See the <a href="https://ratatui.rs/how-to/widgets/" rel="nofollow">Widgets</a> section of the <a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> for
more info.</p>
<h3 tabindex="-1" dir="auto">Handling events</h3>
<p dir="auto">Ratatui does not include any input handling. Instead event handling can be implemented by
calling backend library methods directly. See the <a href="https://ratatui.rs/concepts/event-handling/" rel="nofollow">Handling Events</a> section of the <a href="https://ratatui.rs/" rel="nofollow">Ratatui
Website</a> for more info. For example, if you are using <a href="https://crates.io/crates/crossterm" rel="nofollow">Crossterm</a>, you can use the
<a href="https://docs.rs/crossterm/latest/crossterm/event/index.html" rel="nofollow"><code>crossterm::event</code></a> module to handle events.</p>
<h3 tabindex="-1" dir="auto">Example</h3>
<div dir="auto" data-snippet-clipboard-copy-content="use std::io::{self, stdout};
use crossterm::{
    event::{self, Event, KeyCode},
    ExecutableCommand,
    terminal::{disable_raw_mode, enable_raw_mode, EnterAlternateScreen, LeaveAlternateScreen}
};
use ratatui::{prelude::*, widgets::*};

fn main() -> io::Result<()> {
    enable_raw_mode()?;
    stdout().execute(EnterAlternateScreen)?;
    let mut terminal = Terminal::new(CrosstermBackend::new(stdout()))?;

    let mut should_quit = false;
    while !should_quit {
        terminal.draw(ui)?;
        should_quit = handle_events()?;
    }

    disable_raw_mode()?;
    stdout().execute(LeaveAlternateScreen)?;
    Ok(())
}

fn handle_events() -> io::Result<bool> {
    if event::poll(std::time::Duration::from_millis(50))? {
        if let Event::Key(key) = event::read()? {
            if key.kind == event::KeyEventKind::Press &amp;&amp; key.code == KeyCode::Char('q') {
                return Ok(true);
            }
       }
    }
    Ok(false)
}

fn ui(frame: &amp;mut Frame) {
    frame.render_widget(
        Paragraph::new(&quot;Hello World!&quot;)
            .block(Block::default().title(&quot;Greeting&quot;).borders(Borders::ALL)),
        frame.size(),
    );
}"><pre><span>use</span> std<span>::</span>io<span>::</span><span>{</span><span>self</span><span>,</span> stdout<span>}</span><span>;</span>
<span>use</span> crossterm<span>::</span><span>{</span>
    event<span>::</span><span>{</span><span>self</span><span>,</span> <span>Event</span><span>,</span> <span>KeyCode</span><span>}</span><span>,</span>
    <span>ExecutableCommand</span><span>,</span>
    terminal<span>::</span><span>{</span>disable_raw_mode<span>,</span> enable_raw_mode<span>,</span> <span>EnterAlternateScreen</span><span>,</span> <span>LeaveAlternateScreen</span><span>}</span>
<span>}</span><span>;</span>
<span>use</span> ratatui<span>::</span><span>{</span>prelude<span>::</span><span>*</span><span>,</span> widgets<span>::</span><span>*</span><span>}</span><span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> -&gt; io<span>::</span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span> <span>{</span>
    <span>enable_raw_mode</span><span>(</span><span>)</span>?<span>;</span>
    <span>stdout</span><span>(</span><span>)</span><span>.</span><span>execute</span><span>(</span><span>EnterAlternateScreen</span><span>)</span>?<span>;</span>
    <span>let</span> <span>mut</span> terminal = <span>Terminal</span><span>::</span><span>new</span><span>(</span><span>CrosstermBackend</span><span>::</span><span>new</span><span>(</span><span>stdout</span><span>(</span><span>)</span><span>)</span><span>)</span>?<span>;</span>

    <span>let</span> <span>mut</span> should_quit = <span>false</span><span>;</span>
    <span>while</span> !should_quit <span>{</span>
        terminal<span>.</span><span>draw</span><span>(</span>ui<span>)</span>?<span>;</span>
        should_quit = <span>handle_events</span><span>(</span><span>)</span>?<span>;</span>
    <span>}</span>

    <span>disable_raw_mode</span><span>(</span><span>)</span>?<span>;</span>
    <span>stdout</span><span>(</span><span>)</span><span>.</span><span>execute</span><span>(</span><span>LeaveAlternateScreen</span><span>)</span>?<span>;</span>
    <span>Ok</span><span>(</span><span>(</span><span>)</span><span>)</span>
<span>}</span>

<span>fn</span> <span>handle_events</span><span>(</span><span>)</span> -&gt; io<span>::</span><span>Result</span><span>&lt;</span><span>bool</span><span>&gt;</span> <span>{</span>
    <span>if</span> event<span>::</span><span>poll</span><span>(</span>std<span>::</span>time<span>::</span><span>Duration</span><span>::</span><span>from_millis</span><span>(</span><span>50</span><span>)</span><span>)</span>? <span>{</span>
        <span>if</span> <span>let</span> <span>Event</span><span>::</span><span>Key</span><span>(</span>key<span>)</span> = event<span>::</span><span>read</span><span>(</span><span>)</span>? <span>{</span>
            <span>if</span> key<span>.</span><span>kind</span> == event<span>::</span><span>KeyEventKind</span><span>::</span><span>Press</span> &amp;&amp; key<span>.</span><span>code</span> == <span>KeyCode</span><span>::</span><span>Char</span><span>(</span><span>'q'</span><span>)</span> <span>{</span>
                <span>return</span> <span>Ok</span><span>(</span><span>true</span><span>)</span><span>;</span>
            <span>}</span>
       <span>}</span>
    <span>}</span>
    <span>Ok</span><span>(</span><span>false</span><span>)</span>
<span>}</span>

<span>fn</span> <span>ui</span><span>(</span><span>frame</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Frame</span><span>)</span> <span>{</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Paragraph</span><span>::</span><span>new</span><span>(</span><span>"Hello World!"</span><span>)</span>
            <span>.</span><span>block</span><span>(</span><span>Block</span><span>::</span><span>default</span><span>(</span><span>)</span><span>.</span><span>title</span><span>(</span><span>"Greeting"</span><span>)</span><span>.</span><span>borders</span><span>(</span><span>Borders</span><span>::</span><span>ALL</span><span>)</span><span>)</span><span>,</span>
        frame<span>.</span><span>size</span><span>(</span><span>)</span><span>,</span>
    <span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">Running this example produces the following output:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ratatui-org/ratatui/blob/c3c3c289b1eb8d562afb1931adb4dc719cd48490/examples/docsrs-hello.png?raw=true"><img src="https://github.com/ratatui-org/ratatui/raw/c3c3c289b1eb8d562afb1931adb4dc719cd48490/examples/docsrs-hello.png?raw=true" alt="docsrs-hello"></a></p>
<h2 tabindex="-1" dir="auto">Layout</h2>
<p dir="auto">The library comes with a basic yet useful layout management object called <code>Layout</code> which
allows you to split the available space into multiple areas and then render widgets in each
area. This lets you describe a responsive terminal UI by nesting layouts. See the <a href="https://ratatui.rs/how-to/layout/" rel="nofollow">Layout</a>
section of the <a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> for more info.</p>
<div dir="auto" data-snippet-clipboard-copy-content="use ratatui::{prelude::*, widgets::*};

fn ui(frame: &amp;mut Frame) {
    let main_layout = Layout::new(
        Direction::Vertical,
        [
            Constraint::Length(1),
            Constraint::Min(0),
            Constraint::Length(1),
        ]
    )
    .split(frame.size());
    frame.render_widget(
        Block::new().borders(Borders::TOP).title(&quot;Title Bar&quot;),
        main_layout[0],
    );
    frame.render_widget(
        Block::new().borders(Borders::TOP).title(&quot;Status Bar&quot;),
        main_layout[2],
    );

    let inner_layout = Layout::new(
        Direction::Horizontal,
        [Constraint::Percentage(50), Constraint::Percentage(50)]
    )
    .split(main_layout[1]);
    frame.render_widget(
        Block::default().borders(Borders::ALL).title(&quot;Left&quot;),
        inner_layout[0],
    );
    frame.render_widget(
        Block::default().borders(Borders::ALL).title(&quot;Right&quot;),
        inner_layout[1],
    );
}"><pre><span>use</span> ratatui<span>::</span><span>{</span>prelude<span>::</span><span>*</span><span>,</span> widgets<span>::</span><span>*</span><span>}</span><span>;</span>

<span>fn</span> <span>ui</span><span>(</span><span>frame</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Frame</span><span>)</span> <span>{</span>
    <span>let</span> main_layout = <span>Layout</span><span>::</span><span>new</span><span>(</span>
        <span>Direction</span><span>::</span><span>Vertical</span><span>,</span>
        <span>[</span>
            <span>Constraint</span><span>::</span><span>Length</span><span>(</span><span>1</span><span>)</span><span>,</span>
            <span>Constraint</span><span>::</span><span>Min</span><span>(</span><span>0</span><span>)</span><span>,</span>
            <span>Constraint</span><span>::</span><span>Length</span><span>(</span><span>1</span><span>)</span><span>,</span>
        <span>]</span>
    <span>)</span>
    <span>.</span><span>split</span><span>(</span>frame<span>.</span><span>size</span><span>(</span><span>)</span><span>)</span><span>;</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Block</span><span>::</span><span>new</span><span>(</span><span>)</span><span>.</span><span>borders</span><span>(</span><span>Borders</span><span>::</span><span>TOP</span><span>)</span><span>.</span><span>title</span><span>(</span><span>"Title Bar"</span><span>)</span><span>,</span>
        main_layout<span>[</span><span>0</span><span>]</span><span>,</span>
    <span>)</span><span>;</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Block</span><span>::</span><span>new</span><span>(</span><span>)</span><span>.</span><span>borders</span><span>(</span><span>Borders</span><span>::</span><span>TOP</span><span>)</span><span>.</span><span>title</span><span>(</span><span>"Status Bar"</span><span>)</span><span>,</span>
        main_layout<span>[</span><span>2</span><span>]</span><span>,</span>
    <span>)</span><span>;</span>

    <span>let</span> inner_layout = <span>Layout</span><span>::</span><span>new</span><span>(</span>
        <span>Direction</span><span>::</span><span>Horizontal</span><span>,</span>
        <span>[</span><span>Constraint</span><span>::</span><span>Percentage</span><span>(</span><span>50</span><span>)</span><span>,</span> <span>Constraint</span><span>::</span><span>Percentage</span><span>(</span><span>50</span><span>)</span><span>]</span>
    <span>)</span>
    <span>.</span><span>split</span><span>(</span>main_layout<span>[</span><span>1</span><span>]</span><span>)</span><span>;</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Block</span><span>::</span><span>default</span><span>(</span><span>)</span><span>.</span><span>borders</span><span>(</span><span>Borders</span><span>::</span><span>ALL</span><span>)</span><span>.</span><span>title</span><span>(</span><span>"Left"</span><span>)</span><span>,</span>
        inner_layout<span>[</span><span>0</span><span>]</span><span>,</span>
    <span>)</span><span>;</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Block</span><span>::</span><span>default</span><span>(</span><span>)</span><span>.</span><span>borders</span><span>(</span><span>Borders</span><span>::</span><span>ALL</span><span>)</span><span>.</span><span>title</span><span>(</span><span>"Right"</span><span>)</span><span>,</span>
        inner_layout<span>[</span><span>1</span><span>]</span><span>,</span>
    <span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">Running this example produces the following output:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ratatui-org/ratatui/blob/c3c3c289b1eb8d562afb1931adb4dc719cd48490/examples/docsrs-layout.png?raw=true"><img src="https://github.com/ratatui-org/ratatui/raw/c3c3c289b1eb8d562afb1931adb4dc719cd48490/examples/docsrs-layout.png?raw=true" alt="docsrs-layout"></a></p>
<h2 tabindex="-1" dir="auto">Text and styling</h2>
<p dir="auto">The <code>Text</code>, <code>Line</code> and <code>Span</code> types are the building blocks of the library and are used in
many places. <code>Text</code> is a list of <code>Line</code>s and a <code>Line</code> is a list of <code>Span</code>s. A <code>Span</code>
is a string with a specific style.</p>
<p dir="auto">The <a href="https://github.com/ratatui-org/ratatui/blob/main/style"><code>style</code> module</a> provides types that represent the various styling options. The most
important one is <code>Style</code> which represents the foreground and background colors and the text
attributes of a <code>Span</code>. The <a href="https://github.com/ratatui-org/ratatui/blob/main/style"><code>style</code> module</a> also provides a <code>Stylize</code> trait that allows
short-hand syntax to apply a style to widgets and text. See the <a href="https://ratatui.rs/how-to/render/style-text/" rel="nofollow">Styling Text</a> section of the
<a href="https://ratatui.rs/" rel="nofollow">Ratatui Website</a> for more info.</p>
<div dir="auto" data-snippet-clipboard-copy-content="use ratatui::{prelude::*, widgets::*};

fn ui(frame: &amp;mut Frame) {
    let areas = Layout::new(
        Direction::Vertical,
        [
            Constraint::Length(1),
            Constraint::Length(1),
            Constraint::Length(1),
            Constraint::Length(1),
            Constraint::Min(0),
        ]
    )
    .split(frame.size());

    let span1 = Span::raw(&quot;Hello &quot;);
    let span2 = Span::styled(
        &quot;World&quot;,
        Style::new()
            .fg(Color::Green)
            .bg(Color::White)
            .add_modifier(Modifier::BOLD),
    );
    let span3 = &quot;!&quot;.red().on_light_yellow().italic();

    let line = Line::from(vec![span1, span2, span3]);
    let text: Text = Text::from(vec![line]);

    frame.render_widget(Paragraph::new(text), areas[0]);
    // or using the short-hand syntax and implicit conversions
    frame.render_widget(
        Paragraph::new(&quot;Hello World!&quot;.red().on_white().bold()),
        areas[1],
    );

    // to style the whole widget instead of just the text
    frame.render_widget(
        Paragraph::new(&quot;Hello World!&quot;).style(Style::new().red().on_white()),
        areas[2],
    );
    // or using the short-hand syntax
    frame.render_widget(Paragraph::new(&quot;Hello World!&quot;).blue().on_yellow(), areas[3]);
}"><pre><span>use</span> ratatui<span>::</span><span>{</span>prelude<span>::</span><span>*</span><span>,</span> widgets<span>::</span><span>*</span><span>}</span><span>;</span>

<span>fn</span> <span>ui</span><span>(</span><span>frame</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Frame</span><span>)</span> <span>{</span>
    <span>let</span> areas = <span>Layout</span><span>::</span><span>new</span><span>(</span>
        <span>Direction</span><span>::</span><span>Vertical</span><span>,</span>
        <span>[</span>
            <span>Constraint</span><span>::</span><span>Length</span><span>(</span><span>1</span><span>)</span><span>,</span>
            <span>Constraint</span><span>::</span><span>Length</span><span>(</span><span>1</span><span>)</span><span>,</span>
            <span>Constraint</span><span>::</span><span>Length</span><span>(</span><span>1</span><span>)</span><span>,</span>
            <span>Constraint</span><span>::</span><span>Length</span><span>(</span><span>1</span><span>)</span><span>,</span>
            <span>Constraint</span><span>::</span><span>Min</span><span>(</span><span>0</span><span>)</span><span>,</span>
        <span>]</span>
    <span>)</span>
    <span>.</span><span>split</span><span>(</span>frame<span>.</span><span>size</span><span>(</span><span>)</span><span>)</span><span>;</span>

    <span>let</span> span1 = <span>Span</span><span>::</span><span>raw</span><span>(</span><span>"Hello "</span><span>)</span><span>;</span>
    <span>let</span> span2 = <span>Span</span><span>::</span><span>styled</span><span>(</span>
        <span>"World"</span><span>,</span>
        <span>Style</span><span>::</span><span>new</span><span>(</span><span>)</span>
            <span>.</span><span>fg</span><span>(</span><span>Color</span><span>::</span><span>Green</span><span>)</span>
            <span>.</span><span>bg</span><span>(</span><span>Color</span><span>::</span><span>White</span><span>)</span>
            <span>.</span><span>add_modifier</span><span>(</span><span>Modifier</span><span>::</span><span>BOLD</span><span>)</span><span>,</span>
    <span>)</span><span>;</span>
    <span>let</span> span3 = <span>"!"</span><span>.</span><span>red</span><span>(</span><span>)</span><span>.</span><span>on_light_yellow</span><span>(</span><span>)</span><span>.</span><span>italic</span><span>(</span><span>)</span><span>;</span>

    <span>let</span> line = <span>Line</span><span>::</span><span>from</span><span>(</span><span>vec</span><span>!</span><span>[</span>span1, span2, span3<span>]</span><span>)</span><span>;</span>
    <span>let</span> text<span>:</span> <span>Text</span> = <span>Text</span><span>::</span><span>from</span><span>(</span><span>vec</span><span>!</span><span>[</span>line<span>]</span><span>)</span><span>;</span>

    frame<span>.</span><span>render_widget</span><span>(</span><span>Paragraph</span><span>::</span><span>new</span><span>(</span>text<span>)</span><span>,</span> areas<span>[</span><span>0</span><span>]</span><span>)</span><span>;</span>
    <span>// or using the short-hand syntax and implicit conversions</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Paragraph</span><span>::</span><span>new</span><span>(</span><span>"Hello World!"</span><span>.</span><span>red</span><span>(</span><span>)</span><span>.</span><span>on_white</span><span>(</span><span>)</span><span>.</span><span>bold</span><span>(</span><span>)</span><span>)</span><span>,</span>
        areas<span>[</span><span>1</span><span>]</span><span>,</span>
    <span>)</span><span>;</span>

    <span>// to style the whole widget instead of just the text</span>
    frame<span>.</span><span>render_widget</span><span>(</span>
        <span>Paragraph</span><span>::</span><span>new</span><span>(</span><span>"Hello World!"</span><span>)</span><span>.</span><span>style</span><span>(</span><span>Style</span><span>::</span><span>new</span><span>(</span><span>)</span><span>.</span><span>red</span><span>(</span><span>)</span><span>.</span><span>on_white</span><span>(</span><span>)</span><span>)</span><span>,</span>
        areas<span>[</span><span>2</span><span>]</span><span>,</span>
    <span>)</span><span>;</span>
    <span>// or using the short-hand syntax</span>
    frame<span>.</span><span>render_widget</span><span>(</span><span>Paragraph</span><span>::</span><span>new</span><span>(</span><span>"Hello World!"</span><span>)</span><span>.</span><span>blue</span><span>(</span><span>)</span><span>.</span><span>on_yellow</span><span>(</span><span>)</span><span>,</span> areas<span>[</span><span>3</span><span>]</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">Running this example produces the following output:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ratatui-org/ratatui/blob/c3c3c289b1eb8d562afb1931adb4dc719cd48490/examples/docsrs-styling.png?raw=true"><img src="https://github.com/ratatui-org/ratatui/raw/c3c3c289b1eb8d562afb1931adb4dc719cd48490/examples/docsrs-styling.png?raw=true" alt="docsrs-styling"></a></p>

<h2 tabindex="-1" dir="auto">Status of this fork</h2>
<p dir="auto">In response to the original maintainer <a href="https://github.com/fdehau"><strong>Florian Dehau</strong></a>'s issue
regarding the <a href="https://github.com/fdehau/tui-rs/issues/654" data-hovercard-type="issue" data-hovercard-url="/fdehau/tui-rs/issues/654/hovercard">future of <code>tui-rs</code></a>, several members of
the community forked the project and created this crate. We look forward to continuing the work
started by Florian ðŸš€</p>
<p dir="auto">In order to organize ourselves, we currently use a <a href="https://discord.gg/pMCEU9hNEj" rel="nofollow">Discord server</a>,
feel free to join and come chat! There is also a <a href="https://matrix.org/" rel="nofollow">Matrix</a> bridge available at
<a href="https://matrix.to/#/#ratatui:matrix.org" rel="nofollow">#ratatui:matrix.org</a>.</p>
<p dir="auto">While we do utilize Discord for coordinating, it's not essential for contributing.
Our primary open-source workflow is centered around GitHub.
For significant discussions, we rely on GitHub â€” please open an issue, a discussion or a PR.</p>
<p dir="auto">Please make sure you read the updated <a href="https://github.com/ratatui-org/ratatui/blob/main/CONTRIBUTING.md">contributing</a> guidelines, especially if
you are interested in working on a PR or issue opened in the previous repository.</p>
<h2 tabindex="-1" dir="auto">Rust version requirements</h2>
<p dir="auto">Since version 0.23.0, The Minimum Supported Rust Version (MSRV) of <code>ratatui</code> is 1.67.0.</p>
<h2 tabindex="-1" dir="auto">Widgets</h2>
<h3 tabindex="-1" dir="auto">Built in</h3>
<p dir="auto">The library comes with the following
<a href="https://docs.rs/ratatui/latest/ratatui/widgets/index.html" rel="nofollow">widgets</a>:</p>
<ul dir="auto">
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.BarChart.html" rel="nofollow">BarChart</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/block/struct.Block.html" rel="nofollow">Block</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/calendar/index.html" rel="nofollow">Calendar</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/canvas/struct.Canvas.html" rel="nofollow">Canvas</a> which allows
rendering <a href="https://docs.rs/ratatui/latest/ratatui/widgets/canvas/index.html" rel="nofollow">points, lines, shapes and a world
map</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Chart.html" rel="nofollow">Chart</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Clear.html" rel="nofollow">Clear</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Gauge.html" rel="nofollow">Gauge</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.List.html" rel="nofollow">List</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Paragraph.html" rel="nofollow">Paragraph</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/scrollbar/struct.Scrollbar.html" rel="nofollow">Scrollbar</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Sparkline.html" rel="nofollow">Sparkline</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Table.html" rel="nofollow">Table</a></li>
<li><a href="https://docs.rs/ratatui/latest/ratatui/widgets/struct.Tabs.html" rel="nofollow">Tabs</a></li>
</ul>
<p dir="auto">Each widget has an associated example which can be found in the <a href="https://github.com/ratatui-org/ratatui/blob/main/examples">examples</a> folder. Run
each examples with cargo (e.g. to run the gauge example <code>cargo run --example gauge</code>), and quit by
pressing <code>q</code>.</p>
<p dir="auto">You can also run all examples by running <code>cargo make run-examples</code> (requires <code>cargo-make</code> that can
be installed with <code>cargo install cargo-make</code>).</p>
<h3 tabindex="-1" dir="auto">Third-party libraries, bootstrapping templates and widgets</h3>
<ul dir="auto">
<li><a href="https://github.com/uttarayan21/ansi-to-tui">ansi-to-tui</a> â€” Convert ansi colored text to
<code>ratatui::text::Text</code></li>
<li><a href="https://github.com/uttarayan21/color-to-tui">color-to-tui</a> â€” Parse hex colors to
<code>ratatui::style::Color</code></li>
<li><a href="https://github.com/ratatui-org/rust-tui-template">rust-tui-template</a> â€” A template for
bootstrapping a Rust TUI application with Tui-rs &amp; crossterm</li>
<li><a href="https://github.com/jkelleyrtp/tui-builder">tui-builder</a> â€” Batteries-included MVC framework for
Tui-rs + Crossterm apps</li>
<li><a href="https://github.com/kegesch/tui-clap-rs">tui-clap</a> â€” Use clap-rs together with Tui-rs</li>
<li><a href="https://github.com/kegesch/tui-log-rs">tui-log</a> â€” Example of how to use logging with Tui-rs</li>
<li><a href="https://github.com/gin66/tui-logger">tui-logger</a> â€” Logger and Widget for Tui-rs</li>
<li><a href="https://github.com/veeso/tui-realm">tui-realm</a> â€” Tui-rs framework to build stateful applications
with a React/Elm inspired approach</li>
<li><a href="https://github.com/veeso/tui-realm-treeview">tui-realm-treeview</a> â€” Treeview component for
Tui-realm</li>
<li><a href="https://github.com/EdJoPaTo/tui-rs-tree-widget">tui-rs-tree-widgets</a> â€” Widget for tree data
structures.</li>
<li><a href="https://github.com/markatk/tui-windows-rs">tui-windows</a> â€” Tui-rs abstraction to handle multiple
windows and their rendering</li>
<li><a href="https://github.com/rhysd/tui-textarea">tui-textarea</a> â€” Simple yet powerful multi-line text editor
widget supporting several key shortcuts, undo/redo, text search, etc.</li>
<li><a href="https://github.com/sayanarijit/tui-input">tui-input</a> â€” TUI input library supporting multiple
backends and tui-rs.</li>
<li><a href="https://github.com/a-kenji/tui-term">tui-term</a> â€” A pseudoterminal widget library
that enables the rendering of terminal applications as ratatui widgets.</li>
</ul>
<h2 tabindex="-1" dir="auto">Apps</h2>
<p dir="auto">Check out the list of more than 50 <a href="https://github.com/ratatui-org/ratatui/wiki/Apps-using-Ratatui">Apps using
<code>Ratatui</code></a>!</p>
<h2 tabindex="-1" dir="auto">Alternatives</h2>
<p dir="auto">You might want to checkout <a href="https://github.com/gyscos/Cursive">Cursive</a> for an alternative solution
to build text user interfaces in Rust.</p>
<h2 tabindex="-1" dir="auto">Acknowledgments</h2>
<p dir="auto">Special thanks to <a href="https://github.com/nawok"><strong>Pavel Fomchenkov</strong></a> for his work in designing <strong>an
awesome logo</strong> for the ratatui project and ratatui-org organization.</p>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto"><a href="https://github.com/ratatui-org/ratatui/blob/main/LICENSE">MIT</a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Paris-Based Startup and OpenAI Competitor Mistral AI Valued at $2B (250 pts)]]></title>
            <link>https://www.unite.ai/paris-based-startup-and-openai-competitor-mistral-ai-valued-at-2-billion/</link>
            <guid>38593616</guid>
            <pubDate>Sun, 10 Dec 2023 18:25:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.unite.ai/paris-based-startup-and-openai-competitor-mistral-ai-valued-at-2-billion/">https://www.unite.ai/paris-based-startup-and-openai-competitor-mistral-ai-valued-at-2-billion/</a>, See on <a href="https://news.ycombinator.com/item?id=38593616">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mvp-content-main"><p>In a significant development for the European artificial intelligence sector, Paris-based startup <a href="https://mistral.ai/">Mistral AI</a> has achieved a noteworthy milestone. The company has successfully secured a substantial investment of â‚¬450 million, propelling its valuation to an impressive $2 billion. This funding round marks a pivotal moment, not only for Mistral AI but also for the burgeoning European AI landscape, signifying the region's increasing prominence in the global AI arena.</p><p>Leading the charge in this investment round is Andreessen Horowitz, a prominent name in the venture capital world, demonstrating a strong vote of confidence in Mistral AI's potential. Joining the fray are tech giants Nvidia Corp and Salesforce, contributing an additional â‚¬120 million in convertible debt. This diverse array of investors, encompassing both traditional venture capital and major tech corporations, underscores the wide-ranging appeal and potential of Mistral AI's technology and vision.</p><p>This influx of capital is a testament to Mistral AI's innovative approach and its perceived potential to disrupt the AI industry. With this substantial financial backing, Mistral AI is poised to advance its research and development, expand its reach, and further cement its position as a leading player in the AI domain. The scale of this investment round also reflects the growing recognition of the strategic importance of AI technologies and the increasing competition to lead in this transformative field.</p><h2><strong>Technological Advancements and Market Impact</strong></h2><p>Mistral AI stands at the forefront of innovation with its flagship product, Mistral 7B, a large language model (LLM) renowned for its efficiency and advanced capabilities. Released under the open-source Apache 2.0 license, Mistral 7B represents a significant leap in AI technology, characterized by its customized training, tuning, and data processing methods.</p><p>What sets Mistral 7B apart is its ability to compress knowledge and facilitate deep reasoning capacities, even with fewer parameters compared to other models in the market. This optimized approach not only enhances the model's performance but also contributes to sustainability by reducing training time, costs, and environmental impact.</p><p>The successful deployment of Mistral 7B has positioned Mistral AI as a key player in the AI market and a competitor to OpenAI. Its impact extends across various industries, offering potential transformations in fields such as healthcare, education, finance, and manufacturing. The company's ability to provide high-performance, scalable solutions is poised to impact how these sectors leverage AI for innovation and efficiency.</p><h2><strong>European AI Landscape and Competitive Edge</strong></h2><p>Mistral AI's recent funding round is a clear indicator of Europe's rapidly growing stature in the global AI landscape. Historically, European ventures in AI have lagged behind their counterparts in the US and Asia in terms of investment and innovation. However, Mistral AI's success, alongside other significant investments, marks a decisive shift, showcasing Europe's rising potential and commitment to AI innovation.</p><p>In the competitive arena of generative AI, Mistral AI distinguishes itself with its open-source approach and focus on creating scalable and efficient models. This strategy sets it apart from established giants such as OpenAI, Google AI, and DeepMind, offering a unique value proposition to the market. By prioritizing accessibility and efficiency, Mistral AI not only contributes to the democratization of AI technology but also positions itself as a formidable competitor in the global AI race.</p><p>The trajectory of Mistral AI and the burgeoning European AI sector signals a vibrant and dynamic future for AI development. With substantial investments pouring into European AI startups, the region is rapidly catching up and carving out its niche in the highly competitive and ever-evolving field of artificial intelligence.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sigil II, a Doom WAD from J.Romero, has been released (146 pts)]]></title>
            <link>https://doomwiki.org/wiki/SIGIL_II</link>
            <guid>38593248</guid>
            <pubDate>Sun, 10 Dec 2023 17:40:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://doomwiki.org/wiki/SIGIL_II">https://doomwiki.org/wiki/SIGIL_II</a>, See on <a href="https://news.ycombinator.com/item?id=38593248">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="monaco_shrinkwrap_main">
		
					<!-- ARTICLE -->

				<article id="article" role="main" aria-labelledby="firstHeading">
					<a id="top"></a>
															
										<div id="bodyContent">
						<h2 id="siteSub">From DoomWiki.org</h2>
																								
						<!-- start content -->
<div id="mw-content-text" lang="en" dir="ltr"><table>
<tbody><tr>
<th colspan="2"> <i>SIGIL II</i>
</th></tr>
<tr>
<td colspan="2"> <a href="https://doomwiki.org/wiki/File:SIGIL_II_title.png" title="Title screen"><img alt="Title screen" src="https://doomwiki.org/w/images/thumb/a/a4/SIGIL_II_title.png/320px-SIGIL_II_title.png" width="320" height="240"></a>
</td></tr>
<tr>
<th> Author
</th>
<td> John Romero
</td></tr>
<tr>
<th> <a href="https://doomwiki.org/wiki/Source_port" title="Source port">Port</a>
</th>
<td> <a href="https://doomwiki.org/wiki/Limit-removing" title="Limit-removing">Limit-removing</a>
</td></tr>
<tr>
<th> <a href="https://doomwiki.org/wiki/IWAD" title="IWAD">IWAD</a>
</th>
<td> Doom
</td></tr>
<tr>
<th> Year
</th>
<td> <a href="https://doomwiki.org/wiki/Timeline_of_mod_releases#2023" title="Timeline of mod releases">2023</a>
</td></tr>
<tr>
<th> Link
</th>
<td> <a rel="nofollow" href="https://romero.com/sigil">Official site</a>
</td></tr>


</tbody></table>
<div id="infobox-timelystub"><table><tbody><tr><td><a href="https://doomwiki.org/wiki/File:Work_outdated.png"><img alt="Work outdated.png" src="https://doomwiki.org/w/images/thumb/3/39/Work_outdated.png/40px-Work_outdated.png" width="40" height="40"></a></td><td><i>This <b>stub</b> article makes use of facts and/or references about ongoing events and may need to be updated frequently. Information here may become outdated quickly. Please help the <a href="https://doomwiki.org/wiki/Doom_Wiki" title="Doom Wiki">Doom Wiki</a> by <a rel="nofollow" href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit">keeping it up to date.</a></i></td></tr></tbody></table></div>
<p><b>SIGIL II</b> is a sequel to <a href="https://doomwiki.org/wiki/SIGIL" title="SIGIL">SIGIL</a> by <a href="https://doomwiki.org/wiki/John_Romero" title="John Romero">John Romero</a> and <a href="https://en.wikipedia.org/wiki/Romero_Games" title="wikipedia:Romero Games">Romero Games</a>. It was announced through a video interview with <a href="https://doomwiki.org/wiki/Bridgeburner56" title="Bridgeburner56">Bridgeburner56</a> which premiered through the Realms Deep online indie games convention on <a href="https://doomwiki.org/wiki/Timeline#2021" title="Timeline">August 15, 2021</a>.<sup id="cite_ref-blues1_1-0"><a href="#cite_note-blues1-1">[1]</a></sup><sup id="cite_ref-bb1_2-0"><a href="#cite_note-bb1-2">[2]</a></sup> It is a <a href="https://doomwiki.org/wiki/Doom" title="Doom">Doom</a> episode, and was released December 10, 2023.<sup id="cite_ref-releasetweet_3-0"><a href="#cite_note-releasetweet-3">[3]</a></sup>
</p><p>It was previously stated that <a href="https://en.wikipedia.org/wiki/Buckethead" title="wikipedia:Buckethead">Buckethead</a> would return to contribute music,<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup> but later materials indicate that the digital OST will instead be produced by Thorr. It also features an alternative and bespoke <a href="https://doomwiki.org/wiki/MIDI" title="MIDI">MIDI</a> soundtrack by <a href="https://doomwiki.org/wiki/James_Paddock_(Jimmy)" title="James Paddock (Jimmy)">James Paddock (Jimmy)</a>, whose MIDIs were already featured in SIGIL.
</p><p>SIGIL II opened for pre-orders on November 2, 2023, through Romero's romero.com store.<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup>
</p>
<div id="toc"><p id="toctitle"><h2>Contents</h2></p>
<ul>
<li><a href="#Pre-release"><span>1</span> <span>Pre-release</span></a></li>
<li><a href="#Pre-orders"><span>2</span> <span>Pre-orders</span></a></li>
<li><a href="#Physical_distributions"><span>3</span> <span>Physical distributions</span></a></li>
<li><a href="#Content"><span>4</span> <span>Content</span></a>
<ul>
<li><a href="#Changes"><span>4.1</span> <span>Changes</span></a></li>
<li><a href="#Levels"><span>4.2</span> <span>Levels</span></a></li>
<li><a href="#MIDI_soundtrack"><span>4.3</span> <span>MIDI soundtrack</span></a></li>
<li><a href="#Original_soundtrack"><span>4.4</span> <span>Original soundtrack</span></a></li>
<li><a href="#Built-in_demos"><span>4.5</span> <span>Built-in demos</span></a></li>
</ul>
</li>
<li><a href="#External_links"><span>5</span> <span>External links</span></a></li>
<li><a href="#References"><span>6</span> <span>References</span></a></li>
</ul>
</div>

<h2><span id="Pre-release">Pre-release</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=1" title="Edit section: Pre-release">edit</a><span>]</span></span></h2>
<p>Romero announced on December 8, 2022, that he would stream the building of a SIGIL II level on December 10, 2022â€”Doom's 29th release anniversaryâ€”at 5:00 PM Eastern time on Twitch.<sup id="cite_ref-dec8tweet_6-0"><a href="#cite_note-dec8tweet-6">[6]</a></sup> He also noted at this time that the episode will again consist of nine levels, and that it will be for Doom rather than Doom II (earlier use of the term <a href="https://doomwiki.org/wiki/Megawad" title="Megawad">megawad</a> made this somewhat unclear).
</p><p>A previously released level, "<a href="https://doomwiki.org/wiki/One_Humanity" title="One Humanity">One Humanity</a>," was released as a standalone WAD for charity on March 2, 2022. However that level was for Doom II, and Romero has since reassigned it to the "Hellion" project for Doom II.<sup id="cite_ref-pagbtweet_7-0"><a href="#cite_note-pagbtweet-7">[7]</a></sup>
</p>
<h2><span id="Pre-orders">Pre-orders</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=2" title="Edit section: Pre-orders">edit</a><span>]</span></span></h2>
<p>Pre-orders for physical editions of SIGIL II opened on November 2, 2023, via Romero's romero.com store. Three separate editions were available, with the two higher limited editions selling out within an hour:
</p>
<ul><li> Shotgun Shell USB Edition (â‚¬69.95)</li>
<li> 3.5" floppy + Shotgun Shell USB Edition (â‚¬89.95, limited to 166 copies)</li>
<li> 5.25" and 3.5" floppies + Shotgun Shell USB + shirt (â‚¬154.95, limited to 30 copies)</li></ul>
<h2><span id="Physical_distributions">Physical distributions</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=3" title="Edit section: Physical distributions">edit</a><span>]</span></span></h2>
<p>Shared contents of all three physical editions include the following:
</p>
<ul><li> Custom SIGIL II big box</li>
<li> SIGIL II cover poster (A3 size)</li>
<li> Romero Games full-size cinch bag</li>
<li> Sticker sheet with five stickers</li>
<li> Shotgun glitter sticker</li>
<li> SIGIL II disk pin</li>
<li> SIGIL II "Gates of Hell" heavy superpin</li>
<li> Extra code for SIGIL II WAD with music via email</li>
<li> Shotgun shell USB containing:
<ul><li> SIGIL II nine-level WAD file</li>
<li> Making of SIGIL II video</li>
<li> Making of SIGIL II story by David L. Craddock</li>
<li> SIGIL II original soundtrack by Thorr</li>
<li> SIGIL II original MIDI soundtrack by <a href="https://doomwiki.org/wiki/James_Paddock_(Jimmy)" title="James Paddock (Jimmy)">James Paddock (Jimmy)</a></li>
<li> README file</li></ul></li></ul>
<h2><span id="Content">Content</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=4" title="Edit section: Content">edit</a><span>]</span></span></h2>
<h3><span id="Changes">Changes</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=5" title="Edit section: Changes">edit</a><span>]</span></span></h3>
<p>The spider mastermind had its <a href="https://doomwiki.org/wiki/Hit_point" title="Hit point">health value</a> increased from 4000 to 9000. Otherwise, it functions the exact same as <a href="https://doomwiki.org/wiki/Vanilla" title="Vanilla">vanilla</a>.
</p>
<h3><span id="Levels">Levels</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=6" title="Edit section: Levels">edit</a><span>]</span></span></h3>
<p>All maps except E6M9 also include a <a href="https://doomwiki.org/wiki/Deathmatch_arena" title="Deathmatch arena">deathmatch arena</a>.
</p>
<ul><li> <a href="https://doomwiki.org/wiki/E6M1:_Cursed_Darkness_(SIGIL_II)" title="E6M1: Cursed Darkness (SIGIL II)">E6M1: Cursed Darkness</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M2:_Violent_Hatred_(SIGIL_II)" title="E6M2: Violent Hatred (SIGIL II)">E6M2: Violent Hatred</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M3:_Twilight_Desolation_(SIGIL_II)" title="E6M3: Twilight Desolation (SIGIL II)">E6M3: Twilight Desolation</a> <i>(exit to secret level)</i></li>
<li> <a href="https://doomwiki.org/wiki/E6M4:_Fragments_of_Sanity_(SIGIL_II)" title="E6M4: Fragments of Sanity (SIGIL II)">E6M4: Fragments of Sanity</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M5:_Wrathful_Reckoning_(SIGIL_II)" title="E6M5: Wrathful Reckoning (SIGIL II)">E6M5: Wrathful Reckoning</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M6:_Vengeance_Unleashed_(SIGIL_II)" title="E6M6: Vengeance Unleashed (SIGIL II)">E6M6: Vengeance Unleashed</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M7:_Descent_Into_Terror_(SIGIL_II)" title="E6M7: Descent Into Terror (SIGIL II)">E6M7: Descent Into Terror</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M8:_Abyss_of_Despair_(SIGIL_II)" title="E6M8: Abyss of Despair (SIGIL II)">E6M8: Abyss of Despair</a></li>
<li> <a href="https://doomwiki.org/wiki/E6M9:_Shattered_Homecoming_(SIGIL_II)" title="E6M9: Shattered Homecoming (SIGIL II)">E6M9: Shattered Homecoming</a> <i>(secret level)</i></li></ul>
<table role="presentation">

<tbody><tr>
<td>
<h3><span id="MIDI_soundtrack">MIDI soundtrack</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=7" title="Edit section: MIDI soundtrack">edit</a><span>]</span></span></h3>
<p>All track composed by <a href="https://doomwiki.org/wiki/James_Paddock_(Jimmy)" title="James Paddock (Jimmy)">James Paddock (Jimmy)</a>.
</p>
<ul><li> E6M1: "Nightmare Overture"</li>
<li> E6M2: "Sleep of Reason"</li>
<li> E6M3: "Cathedral Rock"</li>
<li> E6M4: "Fractures"</li>
<li> E6M5: "Hexaphobia"</li>
<li> E6M6: "Walls of the Minotaur"</li>
<li> E6M7: "The Impenetrable Dark"</li>
<li> E6M8: "Final Impact"</li>
<li> E6M9: "I'm the Doomguy with the Gun"</li></ul>
<ul><li> <a href="https://doomwiki.org/wiki/Title_screen" title="Title screen">Title screen</a>: "Doomsday Draws Near"</li>
<li> <a href="https://doomwiki.org/wiki/Intermission_screen" title="Intermission screen">Intermission screen</a>: "The Horror To Come"</li></ul>
</td>
<td>
<h3><span id="Original_soundtrack">Original soundtrack</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=8" title="Edit section: Original soundtrack">edit</a><span>]</span></span></h3>
<p>All track composed by THORR.
</p>
<ul><li> E6M1: </li>
<li> E6M2: </li>
<li> E6M3: </li>
<li> E6M4: </li>
<li> E6M5: </li>
<li> E6M6: </li>
<li> E6M7: </li>
<li> E6M8: </li>
<li> E6M9: </li></ul>
</td></tr></tbody></table>
<h3><span id="Built-in_demos">Built-in demos</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=9" title="Edit section: Built-in demos">edit</a><span>]</span></span></h3>
<p>This WAD features four <a href="https://doomwiki.org/wiki/Demo#Built-in_demos" title="Demo">built-in demos</a>. All require Ultimate Doom v1.9 to view them. The demo levels are:
</p>
<table>
<tbody><tr>
<th> Demo
</th>
<th> Level
</th>
<th> <a href="https://doomwiki.org/wiki/Skill_level#Doom_and_Doom_II_skill_levels" title="Skill level">Skill</a>
</th>
<th> <a href="https://doomwiki.org/wiki/Tic" title="Tic">Tics</a>
</th>
<th> Length
</th></tr>
<tr>
<td> DEMO1
</td>
<td> <a href="https://doomwiki.org/wiki/E6M1:_Cursed_Darkness_(SIGIL_II)" title="E6M1: Cursed Darkness (SIGIL II)">E6M1: Cursed Darkness</a>
</td>
<td> 4
</td>
<td> 1702
</td>
<td> 0:48.63
</td></tr>
<tr>
<td> DEMO2
</td>
<td> <a href="https://doomwiki.org/wiki/E6M2:_Violent_Hatred_(SIGIL_II)" title="E6M2: Violent Hatred (SIGIL II)">E6M2: Violent Hatred</a>
</td>
<td> 4
</td>
<td> 2154
</td>
<td> 1:01.54
</td></tr>
<tr>
<td> DEMO3
</td>
<td> <a href="https://doomwiki.org/wiki/E6M4:_Fragments_of_Sanity_(SIGIL_II)" title="E6M4: Fragments of Sanity (SIGIL II)">E6M4: Fragments of Sanity</a>
</td>
<td> 4
</td>
<td> 1912
</td>
<td> 0:54.63
</td></tr>
<tr>
<td> DEMO4
</td>
<td> <a href="https://doomwiki.org/wiki/E6M6:_Vengeance_Unleashed_(SIGIL_II)" title="E6M6: Vengeance Unleashed (SIGIL II)">E6M6: Vengeance Unleashed</a>
</td>
<td> 4
</td>
<td> 2163
</td>
<td> 1:01.80
</td></tr></tbody></table>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=10" title="Edit section: External links">edit</a><span>]</span></span></h2>
<ul><li> <a rel="nofollow" href="https://romero.com/sigil">Official site</a></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://doomwiki.org/w/index.php?title=SIGIL_II&amp;action=edit&amp;section=11" title="Edit section: References">edit</a><span>]</span></span></h2>
<ol>
<li id="cite_note-blues1-1"><span><a href="#cite_ref-blues1_1-0">â†‘</a></span> <span>&nbsp;(15 August 2021). <a rel="nofollow" href="https://www.bluesnews.com/s/239609/sigil-2-for-doom-ii-revealed">"Sigil 2 for DOOM II Revealed."</a> <i>Blue's News.</i> Retrieved 16 August 2021.</span>
</li>
<li id="cite_note-bb1-2"><span><a href="#cite_ref-bb1_2-0">â†‘</a></span> <span><a href="https://doomwiki.org/wiki/Bridgeburner56" title="Bridgeburner56">Bridgeburner</a>&nbsp;(6 July 2021). <a rel="nofollow" href="https://www.youtube.com/watch?v=CHkAgjlu1Ts&amp;ab_channel=Bridgeburner">"Burning Bridges With Bridgeburner â€“ #06 John Romero on the Art of Level Design."</a> <i><a href="https://en.wikipedia.org/wiki/YouTube" title="wikipedia:YouTube">YouTube</a>.</i> Retrieved 16 August 2021.</span>
</li>
<li id="cite_note-releasetweet-3"><span><a href="#cite_ref-releasetweet_3-0">â†‘</a></span> <span><a href="https://doomwiki.org/wiki/John_Romero" title="John Romero">Romero, John</a>&nbsp;(9 December 2023). <a rel="nofollow" href="https://twitter.com/romero/status/1733672932734304666">"Free WAD for SIGIL II is up: https://romero.com/sigil."</a> <i>Twitter.</i> Retrieved 9 December 2023.</span>
</li>
<li id="cite_note-4"><span><a href="#cite_ref-4">â†‘</a></span> <span>Romero Games Ltd.&nbsp;(20 September 2022). <a rel="nofollow" href="https://www.youtube.com/watch?v=9UPqPI3um8Q">"Ask Romero | Episode 3."</a> <i>YouTube.</i> Retrieved 21 October 2022.</span>
</li>
<li id="cite_note-5"><span><a href="#cite_ref-5">â†‘</a></span> <span>Romero, John&nbsp;(2 November 2023). <a rel="nofollow" href="https://twitter.com/romero/status/1720049920764190773">"SIGIL II preorders open TONIGHT at 6 p.m. GMT on http://Romero.com. All proceeds from sales of SIGIL II and SIGIL II merch support future WAD development. Thank you for playing my games."</a> <i>Twitter.</i> Retrieved 2 November 2023.</span>
</li>
<li id="cite_note-dec8tweet-6"><span><a href="#cite_ref-dec8tweet_6-0">â†‘</a></span> <span>Romero, John&nbsp;(8 December 2022). <a rel="nofollow" href="https://twitter.com/romero/status/1600982842452119552">"For DOOMâ€™s 29th birthday on Dec 10, Iâ€™ll be live streaming me building a new level for SIGIL II, another nine-level WAD, which will be released for DOOMâ€™s 30th. Join me at https://twitch.tv/theromero on Dec 10 at 5 pm ET."</a> <i>Twitter.</i> Retrieved 8 December 2022.</span>
</li>
<li id="cite_note-pagbtweet-7"><span><a href="#cite_ref-pagbtweet_7-0">â†‘</a></span> <span><a href="https://doomwiki.org/wiki/Pedro_Arturo_Gomez_Blanco_(PAGB666)" title="Pedro Arturo Gomez Blanco (PAGB666)">Blanco, Pedro</a>&nbsp;(25 November 2023). <a rel="nofollow" href="https://twitter.com/pagb666/status/1728543771149643856">"So... Romero just unveiled that the follow up to Sigil II will be "Hellion", a full 32 level effort ðŸ‘€."</a> <i>Twitter.</i> Retrieved 28 November 2023.</span>
</li>
</ol>

<!-- 
NewPP limit report
Cached time: 20231210195927
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.120 seconds
Real time usage: 0.127 seconds
Preprocessor visited node count: 1030/1000000
Preprocessor generated node count: 4455/1000000
Postâ€expand include size: 9721/2097152 bytes
Template argument size: 6579/2097152 bytes
Highest expansion depth: 8/40
Expensive parser function count: 1/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%   81.661      1 - -total
 18.30%   14.946      5 - Template:Cite_web_text
 14.96%   12.215      1 - Template:Wad
 13.16%   10.748      2 - Template:Cite_web
 11.51%    9.402     13 - Template:Maplinkgen
 10.54%    8.605      1 - Template:TimelyStub
  7.77%    6.343      1 - Template:TimeIssueBox
  5.88%    4.801      7 - Template:Condfullstop
  5.22%    4.260      1 - Template:BaseInfoBox
  2.95%    2.408      3 - Template:Wp
-->

<!-- Saved in parser cache with key doomwikidb:stable-pcache:idhash:50613-0!*!0!!en!4!* and timestamp 20231210195927 and revision id 427587
 -->
</div>
						<!-- end content -->
												
					</div>

				</article>
				<!-- /ARTICLE -->
				
			<!-- ARTICLE FOOTER -->
			
				<!-- /ARTICLE FOOTER -->

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Inert pesticide ingredients may be more toxic to bees than scientists thought (122 pts)]]></title>
            <link>https://theconversation.com/inert-ingredients-in-pesticides-may-be-more-toxic-to-bees-than-scientists-thought-218005</link>
            <guid>38593008</guid>
            <pubDate>Sun, 10 Dec 2023 17:07:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/inert-ingredients-in-pesticides-may-be-more-toxic-to-bees-than-scientists-thought-218005">https://theconversation.com/inert-ingredients-in-pesticides-may-be-more-toxic-to-bees-than-scientists-thought-218005</a>, See on <a href="https://news.ycombinator.com/item?id=38593008">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Bees help pollinate over a third of the worldâ€™s crops, contributing <a href="https://www.ipbes.net/article/press-release-pollinators-vital-our-food-supply-under-threat">an estimated US$235 billion to $577 billion</a> in value to global agriculture. They also face a myriad of stresses, including pathogens and parasites, loss of suitable food sources and habitat, <a href="https://theconversation.com/how-air-pollution-is-making-life-tougher-for-bugs-213122">air pollution</a> and <a href="https://theconversation.com/bees-face-many-challenges-and-climate-change-is-ratcheting-up-the-pressure-190296">climate-driven weather extremes</a>.</p>

<p>A <a href="https://doi.org/10.1038/s41598-023-46948-6">recent study</a> has identified another important but understudied pressure on bees: â€œinertâ€ ingredients in pesticides. </p>

<p>All pesticide products in the U.S. contain <a href="https://www.epa.gov/ingredients-used-pesticide-products/basic-information-about-pesticide-ingredients">active and inert ingredients</a>. Active ingredients are designed to kill or control a specific insect, weed or fungus and are listed on product labels. All other ingredients â€“ emulsifiers, solvents, carriers, aerosol propellants, fragrances, dyes and such â€“ are considered inert.</p>

<p>The new study exposed honeybees to two treatments: the isolated active ingredients in the fungicide <a href="https://www3.epa.gov/pesticides/chem_search/ppls/007969-00199-20221130.pdf">Pristine</a>, which is used to control <a href="https://agriculture.basf.us/content/dam/cxm/agriculture/crop-protection/products/documents/BASF_Pristine_Almonds_TIB_medres.pdf">fungal diseases in almonds</a> and <a href="https://www3.epa.gov/pesticides/chem_search/ppls/007969-00199-20221130.pdf">other crops</a>, and the whole Pristine formulation, including inert ingredients. The results were quite surprising: The whole formulation impaired honeybeesâ€™ memory, while the active ingredients alone did not. </p>

<p>This suggests that the inert ingredients in the formula were actually what made Pristine toxic to bees â€“ either because the inerts were toxic on their own or because combining them with the active ingredients made the active ingredients more toxic. As a <a href="https://scholar.google.com/citations?user=B1qAtjIAAAAJ&amp;hl=en">social scientist focusing on bee declines</a>, I believe that either way, these findings have important implications for pesticide regulation and bee health. </p>

<figure>
            <p><iframe data-src="https://www.youtube.com/embed/QKTRYP2OF44?wmode=transparent&amp;start=0" frameborder="0" allowfullscreen="" width="100%" height="400"></iframe></p>
            <figcaption><span>Threats to bees include single-crop agriculture, habitat loss, air pollution and pesticide exposure.</span></figcaption>
          </figure>

<h2>What are inert ingredients?</h2>

<p>Inert ingredients have a variety of functions. They may extend a pesticideâ€™s shelf life, reduce risks for people who apply the pesticides or help a pesticide work better. Some inerts, called adjuvants, help pesticides stick to plant surfaces, reduce pesticide drift or help active ingredients better penetrate a plantâ€™s surface. </p>

<p>The â€œinertâ€ label is a colloquial misnomer, though. As <a href="https://www.epa.gov/ingredients-used-pesticide-products/basic-information-about-pesticide-ingredients">the U.S. Environmental Protection Agency notes</a>, inerts arenâ€™t necessarily inactive or even nontoxic. In fact, pesticide users <a href="https://doi.org/10.1289%2Fehp.118-a168">sometimes know very little</a> about how inerts function in a pesticide formula. Thatâ€™s partly because they are regulated very differently than active ingredients. </p>

<h2>Measuring bee effects</h2>

<p>Under the <a href="https://www.epa.gov/laws-regulations/summary-federal-insecticide-fungicide-and-rodenticide-act">Federal Insecticide, Fungicide, and Rodenticide Act</a>, or FIFRA, the EPA oversees pesticide regulation in the U.S. To register a pesticide product for outdoor use, chemical companies must provide <a href="https://www.epa.gov/sites/default/files/2016-07/documents/guidance-exposure-effects-testing-assessing-risks-bees.pdf">reliable risk assessment data</a> on the active ingredientsâ€™ toxicity for bees, including the results of an acute honeybee contact test. </p>

<p>The acute contact test tracks how honeybees react to a pesticide application over a short period of time. It also aims to establish the dose of a pesticide that will kill 50% of a group of honeybees, a value known as the LD50. To determine the LD50, scientists apply the pesticide to beesâ€™ midsections and then observe the bees for 48 to 96 hours for signs of poisoning. </p>



<p>In 2016, the EPA <a href="https://www.epa.gov/sites/default/files/2016-07/documents/guidance-exposure-effects-testing-assessing-risks-bees.pdf">expanded its data requirements</a> by requiring an acute honeybee oral toxicity test, in which adult bees are fed a chemical, as well as a 21-day honeybee larval test that tracks larval reaction to an agrochemical from the egg to their emergence as adult bees. </p>

<p>These tests all help the agency determine what potential risk an active ingredient may pose for honeybees, along with other data. Based on the information from these varied tests, pesticides are labeled as nontoxic, moderately toxic or highly toxic. </p>

<h2>A chemical black box</h2>

<p>Despite this rigorous testing, much remains unknown about how safe pesticides are for bees. This is particularly true for pesticides that have sublethal or chronic toxicities â€“ in other words, pesticides that donâ€™t cause immediate death or obvious signs of poisoning but have other significant effects.</p>

<p>This lack of knowledge about sublethal and chronic effects is problematic, because bees can be repeatedly exposed over long time spans to pesticides on floral nectar or pollen, or to pesticide contamination that builds up <a href="https://doi.org/10.1371/journal.pone.0009754">in beehives</a>. They even may be exposed <a href="https://doi.org/10.1093/aesa/saaa041">through miticides</a> that beekeepers use to control Varroa mites, a <a href="https://www.ars.usda.gov/pacific-west-area/tucson-az/carl-hayden-bee-research-center/research/varroa/varroa-overview/">devastating bee parasite</a>.</p>

<p>Complicating the issue, symptoms of sublethal exposure are often more subtle or take longer to become apparent than acute or lethal toxicity. <a href="https://dx.doi.org/10.5772/62487">Symptoms might include</a> abnormal foraging and learning ability, decreased egg laying by the queen, wing deformation, stunted growth or decreased colony survival. The EPA doesnâ€™t always require chemical companies to perform the tests that could detect these symptoms.</p>

<p>Inert ingredients add another level of mystery. While the EPA reviews and <a href="https://www.epa.gov/ingredients-used-pesticide-products/basic-information-about-pesticide-ingredients">must approve all inert ingredients</a>, it does not require the same toxicity testing as for active ingredients. </p>

<p>This is because under FIFRA, inert ingredients are protected as trade secrets, or <a href="https://www.epa.gov/ingredients-used-pesticide-products/basic-information-about-pesticide-ingredients">confidential business information</a>. Only the total percentage of inert ingredients is required on the label, often lumped together and described as â€œother ingredients.â€</p>

<figure>
            <a href="https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="A box shows that a pesticide has 0.375% active ingredients and 99.625% 'other' ingredients." data-src="https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=167&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=167&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=167&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=210&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=210&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/563091/original/file-20231203-27-omw458.gif?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=210&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px"></p></a>
            <figcaption>
              <span>Sample pesticide ingredient label from an EPA training guide, showing that just 0.375% of ingredients are disclosed and tested for bee safety.</span>
              <span><a href="https://www.epa.gov/pesticide-labels/label-review-training-module-3-special-issues-page-34">EPA</a></span>
            </figcaption>
          </figure>

<h2>Sublethal weapons</h2>

<p>A growing body of evidence suggests that inerts are not as harmless as the name suggests. For example, exposure to two types of adjuvants â€“ organosilicone and nonionic surfactants â€“ can <a href="https://doi.org/10.1371/journal.pone.0040848">impair honeybeesâ€™ learning performance</a>. Bees rely on learning and memory functions to gather food and return to the hive, so losing these crucial skills can endanger a colonyâ€™s survival. </p>

<p>Inerts can also affect bumblebees. In a 2021 study, exposure to alcohol ethoxylates, a coformulant in the fungicide Amistar, <a href="https://doi.org/10.1038/s41598-021-00919-x">killed 30% of the bees exposed to it</a> and caused a number of sublethal effects.</p>

<p>While some inerts may be nontoxic on their own, itâ€™s hard to predict what will happen when they are combined with active ingredients. Research has shown that when two or more agrochemicals are combined, they can <a href="https://doi.org/10.1038/s41586-021-03787-7">become more toxic for bees</a> than when applied on their own. This is known as <a href="https://www.ccohs.ca/oshanswers/chemicals/synergism.html">synergistic toxicity</a>. </p>

<p>Synergism can also occur when inerts are combined with pesticides. Another 2021 study showed that adjuvants that were nontoxic on their own caused <a href="https://doi.org/10.1007/s41348-021-00541-z">increased colony mortality when combined with insecticides</a>. </p>

<figure>
            <a href="https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="A bee in flight, covered with yellow pollen grains." data-src="https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=237&amp;fit=clip" data-srcset="https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=506&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=506&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=506&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=635&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=635&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=635&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/563093/original/file-20231203-17-uekt6o.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=237&amp;fit=clip"></p></a>
            <figcaption>
              <span>A sweat bee (<em>Halictus ligatus</em>) covered with pollen.</span>
              <span><a href="https://flic.kr/p/dJ9ZZ4">Sam Droege, USGS/Flickr</a></span>
            </figcaption>
          </figure>

<h2>A better testing strategy</h2>

<p>Mounting evidence on the toxicity of inerts points to three key changes that could better support bee health and minimize beesâ€™ exposure to potential stressors. </p>

<p>First, environmental risk assessments for pesticides could test the whole pesticide formulation, including inert ingredients, to provide a more complete picture of a pesticideâ€™s toxicity to bees. This is already done <a href="https://www.epa.gov/pollinator-protection/pollinator-risk-assessment-guidance">in some cases</a> but could be required for all outdoor uses where bees are at risk of exposure.</p>

<p>Second, inerts could be identified on product labels to enable independent research and risk assessment. </p>

<p>Third, more testing could be required on pesticidesâ€™ long-term sublethal effects on bees, such as learning impairment. Such research would be especially relevant for pesticides that are applied to blooming crops or flowers that attract bees.</p>

<p>Researchers and environmental groups have been arguing for changes like these since <a href="https://doi.org/10.1289/ehp.9374">at least 2006</a>. However, because pesticide regulation is dictated by federal law, changes require congressional action. This would be challenging politically, since it would increase the regulatory burden on the chemical industry. </p>

<p>Nonetheless, rising concerns about <a href="https://doi.org/10.1146/annurev-ento-011118-111847">bumblebee declines</a> and beekeepersâ€™ significant <a href="https://beeinformed.org/wp-content/uploads/2023/06/BIP-2022-23-Loss-Abstract.pdf">annual colony losses</a> make a strong case for a more precautionary approach to pesticide regulation. With a growing world population and <a href="https://theconversation.com/cop28-7-food-and-agriculture-innovations-needed-to-protect-the-climate-and-feed-a-rapidly-growing-world-218414">food supplies under increasing stress</a>, supporting beesâ€™ contribution to agriculture is more important then ever.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Methane under the seabed is thawing as oceans warm â€“ it's worse than we thought (164 pts)]]></title>
            <link>https://theconversation.com/frozen-methane-under-the-seabed-is-thawing-as-oceans-warm-and-things-are-worse-than-we-thought-216054</link>
            <guid>38592450</guid>
            <pubDate>Sun, 10 Dec 2023 16:05:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/frozen-methane-under-the-seabed-is-thawing-as-oceans-warm-and-things-are-worse-than-we-thought-216054">https://theconversation.com/frozen-methane-under-the-seabed-is-thawing-as-oceans-warm-and-things-are-worse-than-we-thought-216054</a>, See on <a href="https://news.ycombinator.com/item?id=38592450">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Buried beneath the oceans surrounding continents is a naturally occurring frozen form of methane and water. Sometimes dubbed â€œfire-iceâ€ as you can literally set light to it, marine methane hydrate can melt as the climate warms, uncontrollably releasing methane â€“ a potent greenhouse gas â€“ into the ocean and possibly the atmosphere. </p>

<p>Colleagues and I have just published <a href="https://rdcu.be/dsTTt">research</a> showing more of this methane hydrate is vulnerable to warming than previously thought. This is a worry as that hydrate contains about as much carbon as all of the remaining oil and gas on Earth. </p>

<p>Releasing it from the seabed could cause the oceans to become more acidic and the climate to warm further. This is a dangerous set of circumstances. </p>

<p>The massive venting of methane from similar ancient marine hydrate reservoirs has been linked to some of the severest and most rapid climate changes in the Earthâ€™s history. There is even evidence that the process has started again near the <a href="https://www.nature.com/articles/nature11528">east coast of the US</a>. </p>

<p>I have worked on hydrates for over a decade, mainly looking at the methane hydrate offshore of Mauritania, West Africa. Recently I have taken 3D seismic data intended to reveal oil and gas and repurposed it to map out the hydrates under the ocean floor. Ultimately, I wanted to work out if climate change is causing methane to bubble to the surface. </p>

<p>3D seismic is the geologistâ€™s equivalent of the doctorâ€™s CT scan. It can cover hundreds of square kilometres, and can reveal hydrates a few kilometres below the seabed. Hydrate is easily identified in these giant surveys because the sound waves created by a source of seismic energy towed by a ship reflect off the bottom of the hydrate layers.  </p>

<h2>Looking for methane using 3D seismic imagery</h2>

<p>As I settled into a new way of life during the first COVID lockdown in early 2020, I reopened the much-studied dataset and started mapping again. I knew there were many examples of hydrate that had thawed as a result of warming since the last glacial period peaked some 20,000 years ago, and I knew we could detect this on the 3D datasets. </p>

<p>But what was the fate of the methane? Did it reach the oceans and atmosphere? Because if it did, this is a major clue that it could happen again.</p>

<p>Around continents, where the oceans are relatively shallow, hydrate is only just cold enough to remain frozen. So it is very vulnerable to any warming, and that is why these areas have been the focus of most scientific investigations. </p>

<figure>
            <a href="https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="World map with shaded areas near the coasts" data-src="https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=357&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=357&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=357&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=449&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=449&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=449&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/564518/original/file-20231208-19-eq32kq.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Where known methane hydrates can be found.</span>
              <span><a href="https://www.researchgate.net/figure/Estimated-methane-hydrate-occurrences-in-the-world-This-map-is-taken-from-the-World_fig2_277009736">World Ocean Review (data: Wallmann et al)</a>, <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a></span>
            </figcaption>
          </figure>

<p>The good news is that only 3.5% of the worldâ€™s hydrate resides in the vulnerable zone, in this precarious state. Most hydrate is instead deemed to be â€œsafeâ€, buried hundreds of metres below the seabed in deeper waters tens of kilometres further from land.</p>

<p>But frozen methane in the deep ocean may vulnerable after all. In oceans and seas where the water is deeper than around 450 metres to 700 metres are layer upon layer of sediment that contains the hydrate. And some of it is deeply buried and warmed geothermally by the Earth so, despite being hundreds of metres below the seafloor, it is right at the point of instability. </p>

<p>Some layers of sediment are permeable and create a complex underground plumbing for the gas to move through if itâ€™s liberated during climatic warming. Just like holding a football underwater methane gas wants to push upwards because of its buoyancy and burst through the 100s of metres of sediment layers. </p>

<p>Imposed upon this complex geology has been the seven glacials (or ice ages) and interglacials, which warmed and cooled the system repeatedly over the last million years.</p>

<figure>
            <a href="https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><p><img alt="Diagram cross section of sea bed showing rock strata, and map of craters." data-src="https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=336&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=336&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=336&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=422&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=422&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=422&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/564031/original/file-20231206-32134-khhda0.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p></a>
            <figcaption>
              <span>Example of the sort of seismic images the author used. Left: reflections that represent sedimentary strata and a vertical pipe where methane has pushed upwards and a buried crater that formed as methane vented into the ancient ocean. Right: a map showing other examples of these craters.</span>
              <span><span>Richard Davies</span>, <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA</a></span>
            </figcaption>
          </figure>

<h2>Methane is migrating</h2>

<p>During this first lockdown of 2020 I found spectacular evidence that during warm periods during the last million or so years methane migrated laterally, upwards and landwards toward Africa and leaked in much shallower water. Beneath a layer of up to 80 metres of sediment are 23 giant craters on the ancient seabed, each one kilometre wide and up to 50 metres deep, big enough to be filled with multiple Wembley stadiums. </p>

<p>The seismic imaging provides the tell tale signs of methane immediately below the craters. And similar craters elsewhere form due to prolonged or explosive release of gas at the seabed. </p>

<p>These craters are not located in the vulnerable zone where all the attention has been â€“ they are landward of it at about 330 metres water depth. With the discovery in hand, I gathered an international team of scientists (modellers, physicists, geoscientists) to work out what caused the formation of these remarkable things and when they formed. Our results are now published in <a href="https://rdcu.be/dsTTt">Nature Geoscience</a>.</p>

<p>We believe they formed as a result of repeated warming periods. These periods impacted hydrate in the deep ocean and the released methane migrated up to 40km towards the continent, to be vented beyond the shallowest hydrate deposits. So during a warming world the volume of hydrate that will be vulnerable to leaking methane is more significant than previously thought. </p>

<p>The positive outlook is that there are many natural barriers to this methane. But be warned, we expect that in some places on earth, as we warm the planet, methane from the deep will escape into our oceans.</p>

<hr>

<figure>
            <p><img alt="Imagine weekly climate newsletter" data-src="https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=237&amp;fit=clip" data-srcset="https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=600&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=600&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=600&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=754&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=754&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=754&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/434988/original/file-20211201-21-13avx6y.png?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=237&amp;fit=clip"></p>
            <figcaption>
              <span></span>
              
            </figcaption>
          </figure>

<p><strong><em>Donâ€™t have time to read about climate change as much as youâ€™d like?</em></strong>
<br><em><a href="https://theconversation.com/uk/newsletters/imagine-57?utm_source=TCUK&amp;utm_medium=linkback&amp;utm_campaign=Imagine&amp;utm_content=DontHaveTimeTop">Get a weekly roundup in your inbox instead.</a> Every Wednesday, The Conversationâ€™s environment editor writes Imagine, a short email that goes a little deeper into just one climate issue. <a href="https://theconversation.com/uk/newsletters/imagine-57?utm_source=TCUK&amp;utm_medium=linkback&amp;utm_campaign=Imagine&amp;utm_content=DontHaveTimeBottom">Join the 20,000+ readers whoâ€™ve subscribed so far.</a></em></p>

<hr>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Warrant Showing the U.S. Government Is Monitoring Push Notifications (186 pts)]]></title>
            <link>https://www.404media.co/us-government-warrant-monitoring-push-notifications-apple-google-yahoo/</link>
            <guid>38592243</guid>
            <pubDate>Sun, 10 Dec 2023 15:40:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/us-government-warrant-monitoring-push-notifications-apple-google-yahoo/">https://www.404media.co/us-government-warrant-monitoring-push-notifications-apple-google-yahoo/</a>, See on <a href="https://news.ycombinator.com/item?id=38592243">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          <div>
              
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p><em>This article was produced in collaboration&nbsp;</em><a href="https://www.courtwatch.news/?utm_source=substack&amp;utm_medium=web&amp;utm_campaign=substack_profile" rel="noreferrer noopener"><em><u>with Court Watch</u></em></a><em>, an independent outlet that unearths overlooked court records.</em></p><p>The U.S. government is demanding that tech companies provide information related to push notifications in order to identify a targetâ€™s specific device, <a href="https://www.documentcloud.org/documents/24192651-push-notification-search-warrant-application?ref=404media.co"><u>according to a court record</u></a> reviewed by 404 Media. The finding comes as Senator Ron Wyden published a letter on Wednesday warning that the U.S. and foreign governments are making such surveillance demands around push notifications to Apple and Google.&nbsp;</p><p>It is not totally clear if the demand for data related to push notifications mentioned in the court record is one and the same as that described at a high level in Wydenâ€™s letter. Regardless, the court record provides more clarity on the legal mechanisms being used in at least some cases to request information related to push notifications, and what sort of crimes this novel surveillance technique is being used against.&nbsp;</p><p>â€œIn the spring of 2022, my office received a tip that government agencies in foreign countries were demanding smartphone â€˜pushâ€™ notification records from Google and Apple. My staff have been investigating this tip for the past year, which included contacting Apple and Google,â€ <a href="https://www.documentcloud.org/documents/24191267-wyden_smartphone_push_notification_surveillance_letter_to_doj_-_signed?ref=404media.co"><u>the letter</u></a> from Senator Wyden to Attorney General Merrick B. Garland reads. <a href="https://www.reuters.com/technology/cybersecurity/governments-spying-apple-google-users-through-push-notifications-us-senator-2023-12-06/?ref=404media.co"><u>Reuters was first to report</u></a> the letter.</p><div><p>ðŸ“±</p><p><b><strong>Do you know anything else about push notification surveillance? I would love to hear from you. Using a non-work device, you can message me securely on Signal at +44 20 8133 5190. Otherwise, send me an email at joseph@404media.co.</strong></b></p></div><p>As the letter explains, push notifications are not sent directly from an app provider to a userâ€™s smartphone. Instead, â€œthey pass through a kind of digital post office run by the phoneâ€™s operating system provider,â€ typically meaning Apple or Google.&nbsp;</p><p>When a user gets a push notification on their phone, Apple or Google receive a lot of information, including metadata that shows which app received a notification, and which phone and associated Google or Apple account it was to be sent to, Wyden says in his letter. In some cases, unencrypted content like the actual text displayed in the notification may be included too, Wyden adds.</p><p>The letter does not disclose the legal mechanism used by governments to demand this data from Apple or Google. But the court record reviewed by 404 Media does include some specifics around push notification demands. <a href="https://www.courtwatch.news/?ref=404media.co"><u>Court Watch</u></a> shared the record with 404 Media. The record is a search warrant application from May 2020 related to the investigation of a person suspected of theft or bribery concerning programs receiving federal funds.</p>
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>In the search warrant application for information associated with a specific Yahoo email account, an FBI Special Agent writes under a section of the record entitled â€œBackground Information Regarding Provider Servicesâ€ that when a user of a mobile app installs and launches an app, the app will direct the device to obtain a â€œPush Token.â€ This is â€œa unique identifier that allows the provider associated with the application [...] to locate the device on which the application is installed.â€</p><figure><div><p><img src="https://www.404media.co/content/images/2023/12/push-notifications-1.png" width="1064" height="538" loading="lazy" alt="" srcset="https://www.404media.co/content/images/size/w600/2023/12/push-notifications-1.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/push-notifications-1.png 1000w, https://www.404media.co/content/images/2023/12/push-notifications-1.png 1064w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.404media.co/content/images/2023/12/push-notifications-2.png" width="1040" height="422" loading="lazy" alt="" srcset="https://www.404media.co/content/images/size/w600/2023/12/push-notifications-2.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/push-notifications-2.png 1000w, https://www.404media.co/content/images/2023/12/push-notifications-2.png 1040w" sizes="(min-width: 720px) 720px"></p></div><figcaption><p dir="ltr"><span>Screenshots from the search warrant application.</span></p></figcaption></figure><p>The court record then points specifically to Apple and Google, adding â€œAfter the applicable push notification (e.g., Apple Push Notifications (APN) or Google Cloud Messaging) sends a Push Token to the device, the Token is then sent to the application, which in turn sends the Push Token to the applicationâ€™s server/provider.â€ When a company then sends push notifications, it sends both the token itself and what the court record describes as the â€œpayloadâ€ associated with the notification, â€œthe substance of what needs to be sent by the application to the device.â€</p><p>The Special Agent adds that these Push Tokens are stored on the relevant tech companyâ€™s servers, and that these may help identify a specific phone or computer used by the target. Or, as the Special Agent puts it, â€œAccordingly, the computers of PROVIDER are likely to contain useful information that may help to identify the specific device(s) used by a particular subscriber to access the subscriberâ€™s PROVIDER account via the mobile application.â€</p><p>It is not clear if this is boilerplate language that has been included in the search warrant application or whether the agent was specifically seeking this information from Yahoo.</p><p>As Wydenâ€™s letter continues, â€œas with all of the other information these companies store for or about their users, because Apple and Google deliver push notification data, they can be secretly compelled by governments to hand over this information.â€</p><p>Wyden concludes the letter by saying that Apple and Google should be permitted to â€œgenerally reveal whether they have been compelled to facilitate this surveillance practice,â€ and to publish aggregate data on the number of demands they have received. When Reuters contacted Apple for comment, the company told the outlet that Wydenâ€™s letter gave them the opening needed to share more details about how governments monitor push notifications.</p><p>â€œIn this case, the federal government prohibited us from sharing any information,â€ Apple told Reuters in a statement. â€œNow that this method has become public we are updating our transparency reporting to detail these kinds of requests.â€ Reuters cited a source familiar with the matter who described the foreign governments involved in making the requests as democracies allied to the U.S. government.</p><p>Apple did not immediately respond to 404 Mediaâ€™s request for comment on the legal mechanisms used against push notification-related data. A Google spokesperson told 404 Media in an emailed statement that â€œWe were the first major company to publish a public transparency report sharing the number and types of government requests for user data we receive, including the requests referred to by Senator Wyden. We share the Senatorâ€™s commitment to keeping users informed about these requests.â€</p>
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>The full section of the court record discussing push notifications is included below.</p><blockquote><em>PROVIDER also allows its subscribers to access its various services through an application that can be installed on and accessed via cellular telephones and other mobile devices. This application is associated with the subscriberâ€™s PROVIDER account. In my training and experience, I have learned that when the user of a mobile application installs and launches the application on a device (such as a cellular telephone), the application directs the device in question to obtain a Push Token, a unique identifier that allows the provider associated with the application (such as PROVIDER) to locate the device on which the application is installed. After the applicable push notification (e.g., Apple Push Notifications (APN) or Google Cloud Messaging) sends a Push Token to the device, the Token is then sent to the application, which in turn sends the Push Token to the applicationâ€™s server/provider. Thereafter, whenever the provider needs to send notifications to the userâ€™s device, it sends both the Push Token and the payload associated with the notification (i.e., the substance of what needs to be sent by the application to the device). To ensure this process works, Push Tokens associated with a subscriberâ€™s account are stored on the providerâ€™s server(s). Accordingly, the computers of PROVIDER are likely to contain useful information that may help to identify the specific device(s) used by a particular subscriber to access the subscriberâ€™s PROVIDER account via the mobile application.</em></blockquote>
                    <div>
    <div>
      <p>About the author</p>
      <p>Joseph is an award-winning investigative journalist focused on generating impact. His work has triggered hundreds of millions of dollars worth of fines, shut down tech companies, and much more.</p>
      
    </div>
      <p><img data-src="/content/images/2023/08/404-joseph-01-1.jpg" alt="Joseph Cox" src="https://www.404media.co/content/images/2023/08/404-joseph-01-1.jpg">  
      </p>
  </div>
          </div>
        </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Write your own retro compiler (217 pts)]]></title>
            <link>http://t3x.org/t3x/0/book.html</link>
            <guid>38591662</guid>
            <pubDate>Sun, 10 Dec 2023 14:18:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://t3x.org/t3x/0/book.html">http://t3x.org/t3x/0/book.html</a>, See on <a href="https://news.ycombinator.com/item?id=38591662">Hacker News</a></p>
<div id="readability-page-1" class="page">



<hr>

<center><h2>RETRO COMPILER</h2></center>

<center><p>
Lulu Press, 2023 â€¢ 339 pages â€¢ 91 figures â€¢ 6"&nbsp;x&nbsp;9" format<br>
All code from the book is in the public domain!
</p></center>

<a href="http://t3x.org/t3x/0/retro.jpg"><img src="http://t3x.org/t3x/0/retro-s.jpg"></a>

<center><p>
<a href="https://www.lulu.com/shop/nils-holm/write-your-own-retro-compiler/ebook/product-zmm9z72.html?page=1&amp;pageSize=4">Order a <b>PDF</b> copy at Lulu.com</a><br>
<a href="https://www.lulu.com/shop/nils-m-holm/write-your-own-retro-compiler/paperback/product-e778nrw.html?page=1&amp;pageSize=4">Order a <b>paperback</b> copy at Lulu.com</a><br>
<a href="http://t3x.org/t3x/0/toc.pdf">View the Table of Contents (PDF)</a><br>
<a href="http://t3x.org/t3x/0/retro-compiler-sample.pdf">Read some sample pages (PDF)</a><br>
<a href="http://t3x.org/t3x/0/t3x0-12.zip">Download the Sources</a><br>
</p></center>

<h2>Enjoy old computers?</h2>
<h2>New to compiler-writing?</h2>
<h2>This book has you covered!</h2>

<p>Study the complete source code for a self-hosting compiler
that runs on and generates code for CP/M on the Z80 processor.
No prior knowledge in the field of compiler construction is required.
The <a href="http://t3x.org/t3x/0/index.html">T3X/0</a> language that is discussed and
implemented in the book
has its roots in Pascal and BCPL and is very simple. A full 20-page
manual is contained in the book.
</p>

<p><b>Prerequisits</b>: The reader should know at least
one procedural programming language, such as C or Pascal,
and at least one assembly language, ideally the one for the
Z80 CPU. They should also know the basics of the CP/M
operating system. For the determined autodicact a short
introduction to Z80 assembly language is also included in
the book.
</p>

<h2>This book cuts no corners!</h2>

<p>Everything is discussed in great details with lots of diagrams,
tables, and examples.</p>

<ul>
 <li>Lexical analysis
 </li><li>Syntax analysis
 </li><li>Code generation
 </li><li>Simple optimizations
 </li><li>The BDOS interface
 </li><li>The run time library
</li></ul>

<p>Get the code: <a href="http://t3x.org/t3x/0/index.html">www.t3x.org/t3x/0/</a>
</p>

<hr>

<p><a href="http://t3x.org/contact.html">contact</a> &nbsp;|&nbsp;
<a href="http://t3x.org/privacy.html">privacy</a>
</p>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bad news, Emacs (297 pts)]]></title>
            <link>https://eshelyaron.com/posts/2023-12-10-bad-news.html</link>
            <guid>38591584</guid>
            <pubDate>Sun, 10 Dec 2023 14:07:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eshelyaron.com/posts/2023-12-10-bad-news.html">https://eshelyaron.com/posts/2023-12-10-bad-news.html</a>, See on <a href="https://news.ycombinator.com/item?id=38591584">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<header>

<p role="doc-subtitle">Troubles registered in Emacs 30</p>
</header><p>Created on <span><span>[2023-12-10]</span></span>, last updated <span><span>[2023-12-10]</span></span></p>

<p>
<b>NOTE:</b> the following contains several hyperboles that reflect my
emotions, and should probably be taken with a grain of salt, or not at
all. While I am intentionally expressing criticism, I most sincerely
hope not to offend anyone.
</p>
<p>
The <a href="https://eshelyaron.com/notes/emacs.html" title="Notes about Emacs (this free software text OS thingy here)">Emacs</a> master branch is brokenâ€”for good, it seems. Emacs
maintainers accepted a heavy-handed, harmful change, disregarding
concerns voiced by multiple users and developers. Iâ€™ve created a
fixed, and improved, Emacs fork. Iâ€™ll be using and developing this
fork, and youâ€™re welcome to join.
</p>
<p>
Letâ€™s take a step back. What is the Emacs master branch? Thatâ€™s
essentially the development version of Emacs, and what will soon
become Emacs version 30. Many Emacs hackers and enthusiasts track the
master branch to enjoy all of the latest developments and
improvements. Thanks to the tireless work of the Emacs maintainers in
scrutinizing incoming patches, the Emacs master branch has been very
stable in recent years. But a few weeks ago, Emacs master users got a
very unpleasant surprise.
</p>
<div>
<pre><span>commit 589e6ae1fb983bfba42f20906773555037246e45</span>
<span>Author: Thierry Volpiatto</span>
<span>Date:   Sun Nov 19 20:42:56 2023 +0100</span>

<span>Improve register-preview (bug#66394)</span>

<span>    A minibuffer is used now instead of read-key.</span>
    ...
</pre>
</div>
<p>
This commit crippled all user interaction with Emacs registers,
turning commands such as <code>C-x r s</code>, once smooth and frictionless, into
a cumbersome and painful mess. Concretely, instead of just typing the
key for the register you want to operate on, you now get a fully blown
minibuffer for inserting a single key. This is nonsensical in various
ways, but most staggering is probably the fact that you now need to
confirm your register selection by pressing another <code>RET</code>, effectively
doubling the work you have to do for the simplest task of specifying a
single character.
</p>
<p>
Emacs registers (used to) provide a perfect UX. Silky smooth, really.
But no more, not in GNU Emacs 30. Itâ€™s gone, without as much as a
<code>NEWS</code> entry to inform the unwary user about this regression.
</p>
<p>
Surely, itâ€™s not too late to revert one bad change, right? Thatâ€™s
what I thought, unfortunately the Emacs maintainers seem bent on
dismissing the communityâ€™s outcry in an unwarranted and misguided
attempt to save face.
</p>
<p>
In fact, the core problems with this change were brought up already in
the first technical <a href="https://yhetil.org/emacs/87sf67qqmp.fsf@web.de/">comment</a> regarding this patch proposal, from
Michael Heerdegen:
</p>
<blockquote>
<p>
If your version is accepted, I would vote for an option to get the old
behavior back. Your intended behavior is safer but requires more keys
(at least confirmation with RET). Some people might prefer the old
way.
</p>
</blockquote>
<p>
Well, duh! If youâ€™re gonna change long standing Emacs behavior, it
better be optional and backward compatible, people have been using
this thing for decades, after all. Hmm apparently, the patch author,
Thierry, doesnâ€™t see it that way:
</p>
<blockquote>
<p>
There is only RET as additional key and it is a good thing IMO as it
let the time to user to see what he is doing.
</p>
</blockquote>
<p>
This rather arrogant statement, and the approach that underlies it,
led us to where we are today. After some further discussion, <a href="https://eshelyaron.com/notes/eli-zaretskii.html" title="Notes about Eli Zaretskii (Emacs maintainer)">Eli
Zaretskii</a> applied this patch to Emacs master. Iâ€™m not sure he
understood the breaking nature of this change when he did that, which
I think might be even more disconcerting.
</p>
<p>
Soon after, Bastien Guerry chimed in, saying:
</p>
<blockquote>
<p>
I use registers ~100 times a day, so enhancements here are very
welcome, thanks!
</p>
<p>
I wonder about this [change], though. It badly hinders my usual flow,
where I do remember what registers I use and like to store new ones
quickly.
</p>
</blockquote>
<p>
Sounds like a clear and honest testimony from an esteemed community
member. But wait, no, Thierry doesnâ€™t think so, he thinks itâ€™s all
for the better and his change is all right. At this point I got
somewhat involved, and seconded Bastienâ€™s request to restore the
previous, perfectly good behavior, at least optionally. Thierry
wasnâ€™t willing to fix this damage, so Eli asked me to help out:
</p>
<blockquote>
<p>
So maybe a better way forward is for someone, perhaps you Eshel, to
add whatever is needed to provide optionally the previous behavior?
</p>
<p>
Would you like to work on that?
</p>
</blockquote>
<p>
Easy enough. I crafted and <a href="https://yhetil.org/emacs/m1wmtvnfpn.fsf@dazzs-mbp.home/">posted</a> a couple of patches that add some
bells and whistles from Thierryâ€™s patch in an optional and compatible
manner. Itâ€™s really not that hard to make no harm in this case. But
my work was disregarded just as well, sadly. Thierry didnâ€™t like how
I reverted his change to use the minibuffer for reading a single key,
which is exactly the root cause of the problems I tried to fixâ€”and
in fact I did fix it, just not in Emacs master, but in my new fork.
</p>
<p>
Since then, <a href="https://yhetil.org/emacs/CA+Nei8MfEw_iDj3Xjbzop+7n-oqNp1jSJcweOgEQMKUkB3mifQ@mail.gmail.com/">another bug report</a> came in from an Emacs master branch
user that suffered from one of the consequences of this change (a
specific regression that I spelled out days before, but was ignored,
for some reason), and several users reached out to the Emacs
development in request to restore the previous behavior in an ongoing
thread titled <a href="https://yhetil.org/emacs/CAFgA-y2wUR0tGRk+RkUGn2TF2YoMyf3B=+78TGyDZP5+Ew2uyA@mail.gmail.com/">â€œPlease, Restore Previous Behavior for
jump-to-registerâ€</a>. Astonishingly, the maintainers seem insistent
not to budge, and Emacs 30 will thus likely suck.
</p>
<p>
I find the willingness of the Emacs maintainers to entertain this bad
behavior (of both a rouge developer and of Emacs itself) at the
expense of user experience, unacceptable. This demonstrates clear
disrespect for Emacs user preferences, and indeed their freedom.
</p>
<p>
For me, this freedom is the number one reason for using Emacs, so I
obviously wonâ€™t use an Emacs that forces on me weird breaking changes.
For that reason Iâ€™ve created a new Emacs branch, the â€œmainâ€ branch,
which was born from the master branch before this registers fiasco.
</p>
<p>
If these changes will be reverted before Emacs 30, Iâ€™ll surely
consider switching back to building Emacs from the upstream master
branch. But in the meantime, and for the foreseeable future, Iâ€™ll be
keeping my main branch up to date by cherry picking (only) good
changes from the master branch. And of course, I also improve it with
developments of my own.
</p>
<p>
If youâ€™re interested, feel free to checkout my main branch from here:
</p>
<div>
<pre>git clone git://git.eshelyaron.com/emacs.git

git clone https://git.sr.ht/~eshel/emacs
</pre>
</div>
<p>
Iâ€™ll be happy to coordinate and incorporate otherâ€™s work. <a href="https://eshelyaron.com/cdn-cgi/l/email-protection#513c3411342239343d2830233e3f7f323e3c">Let me know</a>
if you have any suggestions, thoughts, or nice harmless patches that I
should try out.
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Best UI design courses for hackers? (219 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38591437</link>
            <guid>38591437</guid>
            <pubDate>Sun, 10 Dec 2023 13:37:43 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38591437">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38592333"><td></td></tr>
                <tr id="38593315"><td></td></tr>
            <tr id="38592464"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592464" href="https://news.ycombinator.com/vote?id=38592464&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Iâ€™m a fairly experienced product designer and this book has been incredibly valuable even for me. Lots of <i>extremely</i> practical insights packed in here. IMO a must-read for engineers and designers alike, if youâ€™re building something where you need to care about point-and-click UI at all.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592989"><td></td></tr>
            <tr id="38592629"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592629" href="https://news.ycombinator.com/vote?id=38592629&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Should be noted, this booked was created by the Tailwind CSS folks (before Tailwind existed IIRC).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592912"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592912" href="https://news.ycombinator.com/vote?id=38592912&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Came here to mention Refactoring UI. I think the structure makes it very valuable: Each one is focused on a particular problem or topic. So if you need help with font weights or spacing or shadows there is a chapter for that and I often go back and look at a specific chapter when I encounter a problem.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592065"><td></td></tr>
                <tr id="38592383"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592383" href="https://news.ycombinator.com/vote?id=38592383&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Whenever this question comes up, the usual suspects like "The Design of Everyday things" get mentioned and I can't help wonder what it would be like if someone asked for books about learning to program [websites] and kept getting "Godel, Escher Bach", "Zen and Art of Motorcycle Maintenance" or "Meditations" by Marcus Aurelius.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38592555"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592555" href="https://news.ycombinator.com/vote?id=38592555&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>Unless you read The art of war you cannot possibly become a 10x ninja developer. /s<p>More seriously, I have read the design of everyday things about 10 years ago and it was one of the most boring books I have ever had to go through. I only remember doorknobs and something about affordances. Read refactoringUI as well, some vague shiny UI tips of which can't remember any but 'have decent spacing'. I still can't design even a simple form. I am starting to suspect that if one wants to be good at web design one needs to start doing lots of web design until one gets better. Reading books may come later to place that practical knowledge in some coherent mental framework.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593057"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593057" href="https://news.ycombinator.com/vote?id=38593057&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>These books are a solid foundation for design education, but also design is its own deep field of expertise that youâ€™re not going to learn after a a book or two. Both things can be true.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592721"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38592721" href="https://news.ycombinator.com/vote?id=38592721&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>Thatâ€™s interesting. I went through that book not that long ago and I found it fascinating. I had a hard time putting it down.<p>I found that the concepts he covers in that book can even be applied for good software API design.</p><p>Also, he did spoil doors for me. Pretty much every building I go into now annoys me because of the stupid door handles they pick.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38593131"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593131" href="https://news.ycombinator.com/vote?id=38593131&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>DOET is very helpful in getting you to understand how to think from a user perspective.<p>I found it to be one of the most useful books in my development as an application programmer.</p><p>It teaches you how to see UI
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592541"><td></td></tr>
                  <tr id="38592206"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592206" href="https://news.ycombinator.com/vote?id=38592206&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>Woah, that's a long list of resources, thanks. I've read a few of those ((1), (2), (7)).<p>(3) is new to me. Will give it a read for sure.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592194"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592194" href="https://news.ycombinator.com/vote?id=38592194&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Anyone heard from Tog (#4 above)? The cert on his website, asktog.com, appears to have expired and no new content since 2014.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592665"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592665" href="https://news.ycombinator.com/vote?id=38592665&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>I am a longtime developer but I'm passionate about design and UX. I'm always on the lookout for materials that I can give my team and other developers to help them get better at design. It's not a course, but "The Non-Designer's Design Book" (ISBN 978-0133966152, Robin Williams) is the best material for design fundamentals I've found. It's very approachable for anyone and it's broadly applicable across all kinds of design. Everyone I have convinced to read it has loved it, and I've seen an improvement in output and understanding. I highly recommend this if you have an interest in design.<p>Refactoring UI is also valuable and can be impactful, though it's heavily web focused and is more like a Web Component Design Cookbook rather than foundational knowledge.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592996"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592996" href="https://news.ycombinator.com/vote?id=38592996&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>I found Design for Hackers[1] to be an incredibly informative book; it provides a great deal of insight into UI patterns, color schemes and selections, and overall UI design. It's definitely more oriented towards graphical UIs but provides enough general insight into design considerations that you could generalize it for TUIs and CLIs if needed.<p>[1]: <a href="https://designforhackers.com/" rel="nofollow noreferrer">https://designforhackers.com/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592264"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592264" href="https://news.ycombinator.com/vote?id=38592264&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>It's definitely not cheap, but I would be surprised if Erik Kennedy's <a href="https://www.learnui.design/" rel="nofollow noreferrer">https://www.learnui.design</a> isn't the best course out there.  In fact, he has three courses:<p>1. UI design</p><p>2. UX design</p><p>3. Landing Page design</p><p>I own all 3 and they are among the best purchases I've ever made, even at the cost.  Erik is a former programmer who has taken the engineers mindset and systematically analyzed and broken down the various parts of UI design.  It is very practical, which was something that was lacking in most resources I found when I was in your position.</p><p>If anyone is interested, I would recommend starting with the UI course, which probably runs around $1000.  Unfortunately It is only available at certain intervals, probably every 6-8 weeks.</p><p>If the cost is intimidating, you can get a lot out of his blog, which will also give you a taste of how he thinks about design: <a href="https://www.learnui.design/blog/" rel="nofollow noreferrer">https://www.learnui.design/blog/</a>.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593306"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593306" href="https://news.ycombinator.com/vote?id=38593306&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Seconding this. Not cheap, but so worth the money. Learn UI design and RefactoringUI are the best resources I've found for engineers who want to learn design. I'm just starting Erik's Landing Page course now, and so far it's also really good.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592693"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592693" href="https://news.ycombinator.com/vote?id=38592693&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>With RefactoringUI and Erik's course, I think the 3rd I would use to complete my top 3 is Shift Nudge (<a href="https://shiftnudge.com/" rel="nofollow noreferrer">https://shiftnudge.com/</a>).<p>There's a fair amount of overlap between all of them, so if you want to Pareto minmax it, I would recommend starting with Refactoring UI, which should help provide practical solutions to many situations and get rid of the most egregious horrors you might commit.</p><p>Of course, UI design goes much deeper than anything those courses can teach, but they're a great start.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593028"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593028" href="https://news.ycombinator.com/vote?id=38593028&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>&gt; <a href="https://shiftnudge.com/" rel="nofollow noreferrer">https://shiftnudge.com/</a><p>Only commenting about it as that site is a course about designing interfaces: to me the font on that site borderline is ridiculous, with the flat lines on the t/f/g, narrow L, an ampersand that looks like an 'e' with a long tail. Makes it hard to read
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592661"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592661" href="https://news.ycombinator.com/vote?id=38592661&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>Seems like a gem of a resource; took a look at the blog, and already found a great principle ("rule of locality; place button where the data is") which I had violated just today. Thanks for the recommendation.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592720"><td></td></tr>
            <tr id="38591962"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38591962" href="https://news.ycombinator.com/vote?id=38591962&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>Not sure if this fits your goal of a UI design course, but I found Josh Comeau's CSS for JS Devs course to be a great way to learn the fundamentals of CSS in a way that resonated with my developer mindset.<p><a href="https://css-for-js.dev/" rel="nofollow noreferrer">https://css-for-js.dev/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38592184"><td></td></tr>
                  <tr id="38592557"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592557" href="https://news.ycombinator.com/vote?id=38592557&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><br><div>
                  <p><span>None. The thing is for UX you have something like don't make me think but UI is a matter of taste so everyone has their own rules which might not appeal to you. You can check out the windows 95 design docs as that might give you some ideas and then I would suggest using an uncommon UI component library and let that do the heavy lifting till you can hire a designer.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592783"><td></td></tr>
            <tr id="38593289"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593289" href="https://news.ycombinator.com/vote?id=38593289&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span>I am a long-time developer who's always dreamed of building an indie software business but design skills hold me back. I find it funny how people always talk about "technical" founders but never about design founders even though design is often just as useful, if not more useful, especially in the early stages where you can build the best product in the world but if it doesn't look good, nobody will try it.<p>I am also especially bad at design and visual art skills in general. I recognize this and get plenty of feedback around it. So this year I set out to improve to at least try to get to "mediocre" instead of "terrible".</p><p>Refactoring UI and Erik Kennedys blog / class are mentioned and are great resources and I own both.</p><p>I did Dribbble's Figma UI design class which was $600. It's biggest strength is that its a cohort based class, and cohort classes tend to have much higher finishing rates than self-paced classes. Their instructor will review your Figma designs but only if you finish in time so if you want to get your $600 worth you better open up Figma, so I recommend it for that reason. Kennedy's is self-paced and while it's extremely high quality, I haven't even worked through most of it for this reason.</p><p>Of course, the single most important thing you can do is build lots of UIs. If you're like me, your UIs will suck, but if you do it more regularly, you will also notice more UI/UX techniques on other websites. I save all those in a Notion database organized by category and refer to them.</p><p>One last thing I almost never see mentioned but it was a really good piece of advice. I told someone that I was between hiring contractor designers for my project, and trying to improve at design and do it myself. One person told me, it's not mutually exclusive. So you can design an app, and it will probably look bad. Then hire an experienced UI/UX designer off Upwork to do a better job. And pay attention to the decisions they made and the decsions you made and compare the difference. Figma is a great tool these days because it's much more collaborative than just getting a big stack of PNGs or SVGs at the end, you can discuss design choices in Figma comments as the designer works.</p><p>One final thing I really struggle with that is worth noting - professional designers will make several versions and iterations of everything, each screen and each component on that screen. And then pick the best one. The Dribbble instructor said, the best design is almost never the first one. This is time consuming and tedious if you don't love design but it's how you get the best results.</p><p>If you just have a one-off project and don't truly care about improving at design, the simplest option is to hire a contractor. UI/UX is not something you learn in a weekend and then you're good to go, it's more like learning a language or an instrument in that you're either going to invest a lot of time to learn it well or you're going to suck. It's pretty affordable to hire-out because it's mostly up-front work.</p><p>Hiring contractors and spending for classes is the expensive route but spending money can expedite the process. But, there's lots of free resources if you're broke. The single most important thing is design a lot, and pay attention to other people's designs and what they're doing.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592699"><td></td></tr>
            <tr id="38592835"><td></td></tr>
            <tr id="38591921"><td></td></tr>
                <tr id="38591933"><td></td></tr>
            <tr id="38592190"><td></td></tr>
                  <tr id="38592768"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592768" href="https://news.ycombinator.com/vote?id=38592768&amp;how=up&amp;goto=item%3Fid%3D38591437"></a></center>    </td><td><p><span><i>&gt; At the same time, I'd also love to learn more about more "down to earth" tutorials/examples/exercises/courses to build practical UI skills. Something above "react tutorials", but something below Victor's "Magic Ink"</i><p>I have no recommendations for UI in general but for practical UI skills I really like Every Layout [1] which covers common page layouts and how to make them responsive beyond just media queries.</p><p>[1] <a href="https://every-layout.dev/" rel="nofollow noreferrer">https://every-layout.dev/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: How to inform YouTube a video is no longer under copyright? (156 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38591080</link>
            <guid>38591080</guid>
            <pubDate>Sun, 10 Dec 2023 12:27:42 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38591080">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I was importing this video <a href="https://www.youtube.com/watch?v=IADZtE2-Aws" rel="nofollow noreferrer">https://www.youtube.com/watch?v=IADZtE2-Aws</a> into my youtube account, famous tracking shot from Wings 1927, and at the copyright determination step Youtube told me it was under copyright but the owner allows it to be shown on Youtube.</p><p>Which is incorrect - it entered public domain in 2023.</p><p>Makes me wonder if there is some metadata in this file that is newer than the film and that is what is copyrighted, or is it that the copyright was claimed on years past and Youtube neglected to check when that claim was going to run out?</p><p>How does one let them know that the copyright has run out?</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AST-grep(sg) is a CLI tool for code structural search, lint, and rewriting (205 pts)]]></title>
            <link>https://github.com/ast-grep/ast-grep</link>
            <guid>38590984</guid>
            <pubDate>Sun, 10 Dec 2023 12:03:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ast-grep/ast-grep">https://github.com/ast-grep/ast-grep</a>, See on <a href="https://news.ycombinator.com/item?id=38590984">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/dc3ff2bbe41af92af0afa8105b1229c826c9b7adbb05d37c5e0b0eaa18b89da1/68747470733a2f2f6173742d677265702e6769746875622e696f2f6c6f676f2e737667"><img src="https://camo.githubusercontent.com/dc3ff2bbe41af92af0afa8105b1229c826c9b7adbb05d37c5e0b0eaa18b89da1/68747470733a2f2f6173742d677265702e6769746875622e696f2f6c6f676f2e737667" alt="ast-grep" data-canonical-src="https://ast-grep.github.io/logo.svg"></a>
</p>
<p dir="auto">
   <a target="_blank" rel="noopener noreferrer" href="https://github.com/ast-grep/ast-grep/actions/workflows/coverage.yaml/badge.svg"><img src="https://github.com/ast-grep/ast-grep/actions/workflows/coverage.yaml/badge.svg" alt="coverage badge"></a>
   <a href="https://app.codecov.io/gh/ast-grep/ast-grep" rel="nofollow"><img src="https://camo.githubusercontent.com/d8d716c0c9beb8e3004d061631b83b4d6f41a108f0b78f2939ab7878b2579634/68747470733a2f2f636f6465636f762e696f2f67682f6173742d677265702f6173742d677265702f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d33375658384832455756" data-canonical-src="https://codecov.io/gh/ast-grep/ast-grep/branch/main/graph/badge.svg?token=37VX8H2EWV"></a>
   <a href="https://discord.gg/4YZjf6htSQ" rel="nofollow"><img alt="Discord" src="https://camo.githubusercontent.com/3a74194a0e5c9e27439faa7bdc32e508773e7736b634cd170c8fb794a760e1e9/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313130373734393834373732323838393231373f6c6162656c3d446973636f7264" data-canonical-src="https://img.shields.io/discord/1107749847722889217?label=Discord"></a>
   <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4fc855230a38e496d1c72bf7b9ead49a30c041ca40d5b194673791e48aec1d13/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6173742d677265702f6173742d677265703f7374796c653d736f6369616c"><img src="https://camo.githubusercontent.com/4fc855230a38e496d1c72bf7b9ead49a30c041ca40d5b194673791e48aec1d13/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6173742d677265702f6173742d677265703f7374796c653d736f6369616c" alt="Badge" data-canonical-src="https://img.shields.io/github/stars/ast-grep/ast-grep?style=social"></a>
   <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/26e88f931ac539893b3f3b380cce6c9c5ddb57740225f7a04f213ba549029731/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f6173742d677265702f6173742d677265703f7374796c653d736f6369616c"><img src="https://camo.githubusercontent.com/26e88f931ac539893b3f3b380cce6c9c5ddb57740225f7a04f213ba549029731/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f6173742d677265702f6173742d677265703f7374796c653d736f6369616c" alt="Badge" data-canonical-src="https://img.shields.io/github/forks/ast-grep/ast-grep?style=social"></a>
   <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/8b61c99823bdbbde4e60e46c99459abe796c62cd49394bbb8cfdefdc6e8acc84/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73706f6e736f72732f48657272696e67746f6e4461726b686f6c6d653f7374796c653d736f6369616c"><img alt="GitHub Sponsors" src="https://camo.githubusercontent.com/8b61c99823bdbbde4e60e46c99459abe796c62cd49394bbb8cfdefdc6e8acc84/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73706f6e736f72732f48657272696e67746f6e4461726b686f6c6d653f7374796c653d736f6369616c" data-canonical-src="https://img.shields.io/github/sponsors/HerringtonDarkholme?style=social"></a>
</p>
<h2 tabindex="-1" dir="auto">ast-grep(sg)</h2>
<p dir="auto">ast-grep(sg) is a CLI tool for code structural search, lint, and rewriting.</p>
<h2 tabindex="-1" dir="auto">Introduction</h2>
<p dir="auto">ast-grep is a AST-based tool to search code by pattern code. Think it as your old-friend <code>grep</code> but it matches AST nodes instead of text.
You can write patterns as if you are writing ordinary code. It will match all code that has the same syntactical structure.
You can use <code>$</code> sign + upper case letters as wildcard, e.g. <code>$MATCH</code>, to match any single AST node. Think it as REGEX dot <code>.</code>, except it is not textual.</p>
<p dir="auto">Try the <a href="https://ast-grep.github.io/playground.html" rel="nofollow">online playground</a> for a taste!</p>
<h2 tabindex="-1" dir="auto">Demo</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/2883231/183275066-8d9c342f-46cb-4fa5-aa4e-b98aac011869.gif"><img src="https://user-images.githubusercontent.com/2883231/183275066-8d9c342f-46cb-4fa5-aa4e-b98aac011869.gif" alt="output" data-animated-image=""></a></p>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">You can install it from <a href="https://docs.npmjs.com/downloading-and-installing-node-js-and-npm" rel="nofollow">npm</a>, <a href="https://pypi.org/" rel="nofollow">pip</a>, <a href="https://doc.rust-lang.org/cargo/getting-started/installation.html" rel="nofollow">cargo</a>, <a href="https://brew.sh/" rel="nofollow">homebrew</a> or <a href="https://scoop.sh/" rel="nofollow">scoop</a>!</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install --global @ast-grep/cli
pip install ast-grep-cli
cargo install ast-grep

# install via homebrew, thank @henryhchchc
brew install ast-grep

# install via scoop, thank @brian6932
scoop install main/ast-grep"><pre>npm install --global @ast-grep/cli
pip install ast-grep-cli
cargo install ast-grep

<span><span>#</span> install via homebrew, thank @henryhchchc</span>
brew install ast-grep

<span><span>#</span> install via scoop, thank @brian6932</span>
scoop install main/ast-grep</pre></div>
<p dir="auto">Or you can build ast-grep from source. You need install rustup, clone the repository and then</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo install --path ./crates/cli"><pre>cargo install --path ./crates/cli</pre></div>
<p dir="auto"><a href="https://repology.org/project/ast-grep/versions" rel="nofollow">Packages</a> are available on other platforms too.</p>
<h2 tabindex="-1" dir="auto">Command line usage example</h2>
<p dir="auto">ast-grep has following form.</p>
<div data-snippet-clipboard-copy-content="sg --pattern 'var code = $PATTERN' --rewrite 'let code = new $PATTERN' --lang ts"><pre><code>sg --pattern 'var code = $PATTERN' --rewrite 'let code = new $PATTERN' --lang ts
</code></pre></div>
<h3 tabindex="-1" dir="auto">Example</h3>
<ul dir="auto">
<li><a href="https://twitter.com/Hchan_mgn/status/1547061516993699841?s=20&amp;t=ldDoj4U2nq-FRKQkU5GWXA" rel="nofollow">Rewrite code in null coalescing operator</a></li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="sg -p '$A &amp;&amp; $A()' -l ts -r '$A?.()'"><pre>sg -p <span><span>'</span>$A &amp;&amp; $A()<span>'</span></span> -l ts -r <span><span>'</span>$A?.()<span>'</span></span></pre></div>
<ul dir="auto">
<li><a href="https://twitter.com/Hchan_mgn/status/1561802312846278657" rel="nofollow">Rewrite</a> <a href="https://github.com/ecyrbe/zodios#migrate-to-v8">Zodios</a></li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="sg -p 'new Zodios($URL,  $CONF as const,)' -l ts -r 'new Zodios($URL, $CONF)' -i"><pre>sg -p <span><span>'</span>new Zodios($URL,  $CONF as const,)<span>'</span></span> -l ts -r <span><span>'</span>new Zodios($URL, $CONF)<span>'</span></span> -i</pre></div>
<ul dir="auto">
<li><a href="https://twitter.com/Hchan_mgn/status/1560108625460355073" rel="nofollow">Implement eslint rule using YAML.</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Sponsor</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/HerringtonDarkholme/sponsors/main/sponsorkit/sponsors.svg"><img src="https://raw.githubusercontent.com/HerringtonDarkholme/sponsors/main/sponsorkit/sponsors.svg" alt="Sponsors"></a></p>
<p dir="auto">If you find ast-grep interesting and useful for your work, please <a href="https://github.com/sponsors/HerringtonDarkholme">buy me a coffee</a>
so I can spend more time on the project!</p>
<h2 tabindex="-1" dir="auto">Feature Highlight</h2>
<p dir="auto">ast-grep's core is an algorithm to search and replace code based on abstract syntax tree produced by tree-sitter.
It can help you to do lightweight static analysis and massive scale code manipulation in an intuitive way.</p>
<p dir="auto">Key highlights:</p>
<ul dir="auto">
<li>
<p dir="auto">An intuitive pattern to find and replace AST.
ast-grep's pattern looks like ordinary code you would write every day. (You can call the pattern is isomorphic to code).</p>
</li>
<li>
<p dir="auto">jQuery like API for AST traversal and manipulation.</p>
</li>
<li>
<p dir="auto">YAML configuration to write new linting rules or code modification.</p>
</li>
<li>
<p dir="auto">Written in compiled language, with tree-sitter based parsing and utilizing multiple cores.</p>
</li>
<li>
<p dir="auto">Beautiful command line interface :)</p>
</li>
</ul>
<p dir="auto">ast-grep's vision is to democratize abstract syntax tree magic and to liberate one from cumbersome AST programming!</p>
<ul dir="auto">
<li>If you are an open source library author, ast-grep can help your library users adopt breaking changes more easily.</li>
<li>if you are a tech lead in your team, ast-grep can help you enforce code best practice tailored to your business need.</li>
<li>If you are a security researcher, ast-grep can help you write rules much faster.</li>
</ul>
<h2 tabindex="-1" dir="auto">CLI Screenshot</h2>
<h3 tabindex="-1" dir="auto">Search</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Command</th>
<th>Screenshot</th>
</tr>
</thead>
<tbody>
<tr>
<td>Search</td>
<td><code>sg -p 'Some($A)' -l rs</code></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/2883231/237472835-002db3a2-8a79-4838-ad5c-563634183c3f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDIyMjQzMDUsIm5iZiI6MTcwMjIyNDAwNSwicGF0aCI6Ii8yODgzMjMxLzIzNzQ3MjgzNS0wMDJkYjNhMi04YTc5LTQ4MzgtYWQ1Yy01NjM2MzQxODNjM2YucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQUlXTkpZQVg0Q1NWRUg1M0ElMkYyMDIzMTIxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzEyMTBUMTYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NWIyNWE0Njg3MTIzMTcxN2M0ZTc5NTUzMjU0NGE0YjM2MjAzYmVkNTRjOGNkZDdmZjBlMDQzZWNlMDNiOGUyZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.N7tdkaARi1aVKUjol8r6xJdQLctzMvmozKUIhFB4W_M"><img src="https://private-user-images.githubusercontent.com/2883231/237472835-002db3a2-8a79-4838-ad5c-563634183c3f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDIyMjQzMDUsIm5iZiI6MTcwMjIyNDAwNSwicGF0aCI6Ii8yODgzMjMxLzIzNzQ3MjgzNS0wMDJkYjNhMi04YTc5LTQ4MzgtYWQ1Yy01NjM2MzQxODNjM2YucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQUlXTkpZQVg0Q1NWRUg1M0ElMkYyMDIzMTIxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzEyMTBUMTYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NWIyNWE0Njg3MTIzMTcxN2M0ZTc5NTUzMjU0NGE0YjM2MjAzYmVkNTRjOGNkZDdmZjBlMDQzZWNlMDNiOGUyZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.N7tdkaARi1aVKUjol8r6xJdQLctzMvmozKUIhFB4W_M" alt="image"></a></td>
</tr>
<tr>
<td>Rewrite</td>
<td><code>sg -p '$F &amp;&amp; $F($$$ARGS)' -r '$F?.($$$ARGS)' -l ts</code></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/2883231/237473699-ad9394d8-3aea-4b96-8d54-6e01f06174d2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDIyMjQzMDUsIm5iZiI6MTcwMjIyNDAwNSwicGF0aCI6Ii8yODgzMjMxLzIzNzQ3MzY5OS1hZDkzOTRkOC0zYWVhLTRiOTYtOGQ1NC02ZTAxZjA2MTc0ZDIucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQUlXTkpZQVg0Q1NWRUg1M0ElMkYyMDIzMTIxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzEyMTBUMTYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MDc3ZGRmMDc3MTM1MWVkYTFjZTEzYWE0YWExMjQ1YWU5OTFlM2IwNThjNjE1ZTQ1YTY2ZGZiNjlkZjVjMGZiYyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.ZwL2RdCmRJkJLps3pNWMelmbl6UdQN_fY_JRQ0mwrGw"><img src="https://private-user-images.githubusercontent.com/2883231/237473699-ad9394d8-3aea-4b96-8d54-6e01f06174d2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDIyMjQzMDUsIm5iZiI6MTcwMjIyNDAwNSwicGF0aCI6Ii8yODgzMjMxLzIzNzQ3MzY5OS1hZDkzOTRkOC0zYWVhLTRiOTYtOGQ1NC02ZTAxZjA2MTc0ZDIucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQUlXTkpZQVg0Q1NWRUg1M0ElMkYyMDIzMTIxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzEyMTBUMTYwMDA1WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MDc3ZGRmMDc3MTM1MWVkYTFjZTEzYWE0YWExMjQ1YWU5OTFlM2IwNThjNjE1ZTQ1YTY2ZGZiNjlkZjVjMGZiYyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.ZwL2RdCmRJkJLps3pNWMelmbl6UdQN_fY_JRQ0mwrGw" alt="image"></a></td>
</tr>
<tr>
<td>Report</td>
<td><code>sg scan</code></td>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/2883231/187094977-fd544d4b-64de-4bba-8bea-8c0de047b352.png"><img src="https://user-images.githubusercontent.com/2883231/187094977-fd544d4b-64de-4bba-8bea-8c0de047b352.png" alt="image"></a></td>
</tr>
</tbody>
</table>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stealthy Linux rootkit found in the wild after going undetected for 2 years (205 pts)]]></title>
            <link>https://arstechnica.com/security/2023/12/stealthy-linux-rootkit-found-in-the-wild-after-going-undetected-for-2-years/</link>
            <guid>38590827</guid>
            <pubDate>Sun, 10 Dec 2023 11:26:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/security/2023/12/stealthy-linux-rootkit-found-in-the-wild-after-going-undetected-for-2-years/">https://arstechnica.com/security/2023/12/stealthy-linux-rootkit-found-in-the-wild-after-going-undetected-for-2-years/</a>, See on <a href="https://news.ycombinator.com/item?id=38590827">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">



<article itemscope="" itemtype="http://schema.org/NewsArticle" id="">
      <div>
        <header>
            <h4>
      MORE FUN WITH ROOTKITS    â€”
</h4>
            
            <h2 itemprop="description">Krasue infects telecom firms in Thailand using techniques for staying under the radar.</h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/09/trojan-backdoor-800x534.jpg" alt="Trojan horse on top of blocks of hexadecimal programming codes. Illustration of the concept of online hacking, computer spyware, malware and ransomware.">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 578:single/related:4c57568bce8854ee188540936f006902 --><!-- empty -->
<p>Stealthy and multifunctional Linux malware that has been infecting telecommunications companies went largely unnoticed for two years until being documented for the first time by researchers on Thursday.</p>
<p>Researchers from security firm Group-IB have named the remote access trojan â€œKrasue,â€ after a nocturnal spirit <a href="https://en.wikipedia.org/wiki/Krasue">depicted in Southeast Asian folklore </a> â€œfloating in mid-air, with no torso, just her intestines hanging from below her chin.â€ The researchers chose the name because evidence to date shows it almost exclusively targets victims in Thailand and â€œposes a severe risk to critical systems and sensitive data given that it is able to grant attackers remote access to the targeted network.</p>
<p>According to the researchers:</p>
<blockquote>
<ul>
<li aria-level="1">Krasue is a Linux Remote Access Trojan that has been active since 20 and predominantly targets organizations in Thailand.</li>
<li aria-level="1">Group-IB can confirm that telecommunications companies were targeted by Krasue.</li>
<li aria-level="1">The malware contains several embedded rootkits to support different Linux kernel versions.</li>
<li aria-level="1">Krasueâ€™s rootkit is drawn from public sources (3 open-source Linux Kernel Module rootkits), as is the case with many Linux rootkits.</li>
<li aria-level="1">The rootkit can hook the `kill()` syscall, network-related functions, and file listing operations in order to hide its activities and evade detection.</li>
<li aria-level="1">Notably, Krasue uses RTSP (Real-Time Streaming Protocol) messages to serve as a disguised â€œalive ping,â€ a tactic rarely seen in the wild.</li>
<li aria-level="1">This Linux malware, Group-IB researchers presume, is deployed during the later stages of an attack chain in order to maintain access to a victim host.</li>
<li aria-level="1">Krasue is likely to either be deployed as part of a botnet or sold by initial access brokers to other cybercriminals.</li>
<li aria-level="1">Group-IB researchers believe that Krasue was created by the same author as the XorDdos Linux Trojan, documented by <a href="https://www.microsoft.com/en-us/security/blog/2022/05/19/rise-in-xorddos-a-deeper-look-at-the-stealthy-ddos-malware-targeting-linux-devices/">Microsoft in a March 2022 blog post</a>, or someone who had access to the latterâ€™s source code.</li>
</ul>
</blockquote>
<p>During the initialization phase, the rootkit conceals its own presence. It then proceeds to hook the <b>`kill()`</b> syscall, network-related functions, and file listing operations, thereby obscuring its activities and evading detection.</p>                                            
                                                        
<p>The researchers have so far been unable to determine precisely how Krasue gets installed. Possible infection vectors include through vulnerability exploitation, credential-stealing or -guessing attacks, or by unwittingly being installed as trojan stashed in an installation file or update masquerading as legitimate software.</p>
<p>The three open source rootkit packages incorporated into Krasue are:</p>
<ul>
<li aria-level="1"><a href="https://github.com/m0nad/Diamorphine">Diamorphine</a></li>
<li aria-level="1"><a href="https://github.com/mncoppola/suterusu">Suterusu</a></li>
<li aria-level="1"><a href="https://github.com/jermeyyy/rooty">Rooty</a></li>
</ul>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/krasue.jpg" data-height="828" data-width="1794" alt="An image showing salient research points of Krasue."><img alt="An image showing salient research points of Krasue." src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/krasue-640x295.jpg" width="640" height="295" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/12/krasue-1280x591.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/krasue.jpg" data-height="828" data-width="1794">Enlarge</a> <span>/</span> An image showing salient research points of Krasue.</p><p>Group-IB</p></figcaption></figure>
<p>Rootkits are a type of malware that hides directories, files, processes, and other evidence of its presence to the operating system itâ€™s installed on. By hooking legitimate Linux processes, the malware is able to suspend them at select points and interject functions that conceal its presence. Specifically, it hides files and directories beginning with the names â€œauwdâ€ and â€œvmware_helperâ€ from directory listings and hides ports 52695 and 52699, where communications to attacker-controlled servers occur. Intercepting the kill() syscall also allows the trojan to survive Linux commands attempting to abort the program and shut it down.</p>

                                                </div>

            
            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/security/2023/12/stealthy-linux-rootkit-found-in-the-wild-after-going-undetected-for-2-years/2/">2</a> <a href="https://arstechnica.com/security/2023/12/stealthy-linux-rootkit-found-in-the-wild-after-going-undetected-for-2-years/2/"><span>Next <span>â†’</span></span></a></span></nav>
            
        </section>
    </div>

<section>
          
    
    <p>
      <section>
        <a href="https://arstechnica.com/author/dan-goodin">Dan Goodin</a>
        Dan Goodin is Senior Security Editor at Ars Technica, where he oversees coverage of malware, computer espionage, botnets, hardware hacking, encryption, and passwords. In his spare time, he enjoys gardening, cooking, and following the independent music scene.      </section>
    </p>

  </section>

  </article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fuzzy Finding with Emacs Instead of Fzf (115 pts)]]></title>
            <link>https://www.masteringemacs.org/article/fuzzy-finding-emacs-instead-of-fzf</link>
            <guid>38590164</guid>
            <pubDate>Sun, 10 Dec 2023 08:47:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.masteringemacs.org/article/fuzzy-finding-emacs-instead-of-fzf">https://www.masteringemacs.org/article/fuzzy-finding-emacs-instead-of-fzf</a>, See on <a href="https://news.ycombinator.com/item?id=38590164">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    
    
    
      
    
    
      
    
    
      
        <section>
          fzf is a popular tool among command line hackers. But if you're an Emacs user, it's hard to use as it requires an interactive terminal. What if you could use Emacs to do the fuzzy finding instead of fzf?
        </section>
      
      
        <figure>
          <img src="https://www.masteringemacs.org/static/uploads/article-images/gnu-standing-on-piles-of-paper.jpg">
        </figure>
      
      
        
      
      
        <p>Updated for <strong>emacs 28</strong></p>
      
      <img src="https://www.masteringemacs.org/static/img/fleuron2.gif">
      
<p>Filtering long lists of output on the command line usually involves taking the list of items â€“ maybe the output of <code>ls</code>, <code>git</code> or <code>find</code> â€“ and doing something with it. If youâ€™re lucky you can mechanically filter the list with pipes and <code>grep</code>. If youâ€™re unlucky and you canâ€™t think of a heuristic, youâ€™ll have to sift through the output with a pager like <code>less</code> and remember the items you want to keep.</p><figure>
   <img src="https://www.masteringemacs.org/static/uploads/fzf.png" alt="fzf filtering output from apt-cache search intended for apt-get">
<figcaption><code>fzf</code> filtering output from <code>apt-cache search</code> intended for <code>apt-get</code></figcaption>
</figure><p>Typically you do this because you want to cherry pick a subset of the items and feed them into another command, like <code>rm</code>, <code>cat</code> or <code>apt-get</code> as the picture above illustrates.</p><p>But the manual way is tedious and slow. And thatâ€™s the problem <a href="https://github.com/junegunn/fzf">fzf</a> tries to solve. The premise is simple: you feed it (via stdin) a list of items, and it displays a curses-like window where you can â€œfuzzy findâ€ and select the items you care about. Itâ€™s designed to slot into command substitutions and pipes â€” like an interactive <code>grep</code>.</p><p>So that got me thinking. Thereâ€™s no reason why you canâ€™t use Emacs to do this instead of <code>fzf</code>! Emacs has better fuzzy finding and itâ€™s the text editor youâ€™re already using, so why not use Emacs?</p><p>Another reason to ditch <code>fzf</code> is that you might be using <a href="https://masteringemacs.org/article/running-shells-in-emacs-overview">a shell and not a terminal emulator in Emacs</a>. Itâ€™s not impossible to run curses apps in <code>shell-mode</code>, but it is harder.</p><h2 id="ezf-emacs-fuzzy-finder">EZF: Emacs Fuzzy Finder</h2><figure>
   <img src="https://www.masteringemacs.org/static/uploads/ezf-example-optimised.gif" alt="Fuzzy matching with Helm">
<figcaption><code>ezf</code> filtering output from <code>apt-cache</code> before passing it back to the shell</figcaption>
</figure><p>So the game plan is simple:</p><dl><dt>Build a shell script</dt><dd><p>This is the shell-facing part that we feed into pipes and command substitution sub-shells.</p><p>It must talk to <code>emacsclient</code>, the client in the Emacs client-server duo. That way itâ€™ll run in your existing Emacs instance and it wonâ€™t interrupt your workflow if you also use â€“ as you well should! â€“ Emacs as your shell or terminal emulator.</p></dd><dt>Write some Elisp glue code</dt><dd><p>Weâ€™ll need a few functions capable of letting you filter and select the match candidates you like. Luckily this is generally very easy.</p></dd><dt>Return the picked candidates</dt><dd><p>After matching and selecting the candidates we want to keep, we must return them from whence they came. Weâ€™ll need to be mindful of annoying bagatelles like proper quoting.</p></dd><dt>Make it easy to extend</dt><dd><p>It should be easy to extend or modify to suit individual tastes.</p><p>Weâ€™ll add a few command switches to <code>ezf</code> to highlight how easy it is to pass customizable switches through bash into Emacs.</p></dd></dl><h3 id="sending-to-emacss-standard-input">Sending to Emacsâ€™s standard input</h3><p>Letâ€™s start with the shell script. Iâ€™ve done it in <code>bash</code>. Thereâ€™s a number of little gotchas and workarounds required for this to work well. So the scriptâ€™s freighted with one or two annoying hacks.</p><p>Chiefly, itâ€™s not possible to ask <code>emacsclient</code> or even <code>emacs</code> to read directly from a file descriptor device. So process substitution with <code>&lt;(ls ...)</code> is out. I donâ€™t know why, as Emacs is absolutely 100% capable of <em>doing</em> it inside Emacs. So Iâ€™m chalking it up to oversight.</p><p>That means we have to work around that problem with real files. Iâ€™m using <code>mktemp</code> to <code>cat</code> standard input to a temporary file. To avoid clobbering your <code>tmpfs</code> with junk files, thereâ€™s a <code>trap</code> to clean up when the script exits.</p><p>Now all we need to do is add a little command argument parsing: I want <code>-c</code> to let us choose the completion tool to invoke in Emacs; and <code>-f</code> is there to pick the field offset to return. The latter is particularly useful if you have a line of text and you want just the first word, for example.</p><p>After that, thereâ€™s a little bit of house keeping in case you exit out of the selection process without picking anything. Oh, when you tell <code>emacsclient</code> to evaluate elisp itâ€™ll use <code>prin1</code> to emit the representation of the Lisp object to standard output, and that forces quote symbols around strings, even if we donâ€™t really want that. Sieving the output from Emacs through a pipe to <code>xargs</code> cunningly strips the quotes.</p><pre><code><span>#!/usr/bin/env bash</span>
<span>set</span> <span>-o</span> nounset -o errexit -o pipefail

<span>field=</span>nil
<span># the elisp function to use for completing read</span>
<span>candidate_fn=</span>ezf-default
<span>while</span> <span>getopts</span> c:f: OPT<span>;</span> <span>do</span>
    <span>case</span> <span>$OPT</span><span> in</span>
        c<span>)</span>
            <span>candidate_fn=$OPTARG</span>
            <span>;;</span>
        f<span>)</span>
            <span>field=$OPTARG</span>
            <span>;;</span>
        *<span>)</span>
            <span>echo</span> <span>"usage: </span><span>${0##</span>*/<span>}</span><span> [-f field] [-c candidate-fn]"</span>
            <span>exit</span> 2
    <span>esac</span>
<span>done</span>
<span>shift</span> <span>$((</span> OPTIND - 1 <span>))</span>
<span>OPTIND=</span>1

<span>ezftmp=</span><span>"</span><span>$(</span><span>mktemp</span><span>)</span><span>"</span>
<span>trap</span> <span>'rm -f -- "$ezftmp"'</span> EXIT
<span>&gt;</span> <span>"</span><span>$ezftmp</span><span>"</span> <span>cat</span> -
<span># xargs is there to strip the "" from the beginning and end of the output from Emacs.</span>
<span>selection=$(</span><span>emacsclient</span> -e <span>"(ezf </span><span>\"</span><span>$ezftmp</span><span>\"</span><span> </span><span>$field</span><span> #'</span><span>$candidate_fn</span><span>)"</span> <span>|</span> <span>xargs</span><span>)</span>
<span>if [[</span> <span>"</span><span>$selection</span><span>"</span> <span>==</span> <span>"nil"</span><span> ]]</span>; <span>then</span>
    <span>exit</span> 1
<span>else</span>
   <span>echo</span> <span>"</span><span>$selection</span><span>"</span>
<span>fi</span></code></pre><p>Iâ€™ve named it <code>ezf.sh</code> (symlinked to <code>ezf</code>) so all you need to do is put it somewhere on your <code>PATH</code>.</p><h3 id="filtering-in-emacs">Filtering in Emacs</h3><p>Completion in Emacs is a complex subject matter and one soused in bike shedding and personal opinion. So Iâ€™ve kept things open and made it work with <code>completing-read</code> â€“ well, specifically <code>completing-read-multiple</code> so you can pick multiple items.</p><p>If youâ€™re unsure how that fits into <em>your</em> completion framework, then my article on <a href="https://www.masteringemacs.org/article/understanding-minibuffer-completion">understanding Minibuffer Completion</a> is a good place to start. If you want IDO to work with it, youâ€™ll have to tweak the code yourself. Luckily I have <a href="https://www.masteringemacs.org/article/find-files-faster-recent-files-package">an example here</a> to get you started.</p><p>Iâ€™ve also made it work out of the box with Helm which, as we all know, is awesome. Helm in particular is perfect for this as it comes with great fuzzy matching, multiple selection <em>and</em> itâ€™s easy to add custom actions like returning matches to the shell <em>and</em> opening them as files in Emacs, for example.</p><p>Thereâ€™s three parts: two completion mechanisms and a generic wrapper that turns lists of candidates into usable output.</p><pre><code>(<span>defun</span><span> ezf-default </span>(filename)
  <span>"EZF completion with your default completion system."</span>
  (completing-read-multiple
   <span>"Pick a Candidate: "</span>
   (with-temp-buffer
     (insert-file-contents-literally filename <span>nil</span>)
     (string-lines (buffer-string) <span>t</span>))))</code></pre><p><code>completing-read-multiple</code> takes a prompt and a list of strings. And thatâ€™s all you need to get Emacsâ€™s completion system to work. I create a temporary buffer to hold the file contents before itâ€™s split up into lines. If you want NULL-separated output, this is the place to change it.</p><p>If youâ€™re wondering why Iâ€™m using a buffer, you should read my article <a href="https://www.masteringemacs.org/article/why-emacs-has-buffers">Why Emacs has Buffers</a>.</p><pre><code>(<span>defun</span><span> ezf-helm </span>(filename)
  <span>"EZF completion with `helm'."</span>
  <span>;; Uncomment if you want Helm to full screen.</span>
  <span>;; (helm-set-local-variable 'helm-full-frame t)</span>
  (helm :sources
        (helm-build-in-file-source <span>"EZF Completion"</span> filename
          :action (<span>lambda</span> (_) (helm-marked-candidates)))))</code></pre><p>For Helm the solution is similar. Iâ€™m using Helmâ€™s ability to build candidates directly from a file. If you want to add more than one action then I recommend you use <code>helm-make-actions</code> to build the alist.</p><p>Now for the generic wrapper. Its job is to take a list of strings you picked from a candidate function and turn it into something the shell can properly read. If you specified <code>-f</code> to <code>ezf</code> then itâ€™ll also split the string and only use the field index you chose.</p><pre><code><span>;; If you start Emacs's server some other way, you can remove this.</span>
(server-start)

(<span>defvar</span><span> ezf-separators </span><span>" "</span>
  <span>"Regexp of separators `ezf' should use to split a line."</span>)

(<span>defun</span><span> ezf </span>(filename &amp;optional field completing-fn)
  <span>"Wrapper that calls COMPLETION-FN with FILENAME.</span>

<span>Optionally split each line of string by `ezf-separators' if FIELD</span>
<span>is non-nil and return FIELD.</span>

<span>If COMPLETING-FN is nil default to `ezf-default'."</span>
  (when-let (candidates (<span>funcall</span> (<span>or</span> completing-fn 'ezf-default) filename))
    (mapconcat (<span>lambda</span> (candidate)
                 (shell-quote-argument
                  (<span>if</span> field
                      (<span>nth</span> (<span>1-</span> field) (split-string candidate ezf-separators <span>t</span> <span>" "</span>))
                    candidate)))
               candidates
               <span>" "</span>)))</code></pre><p>Here the goal is simply to take a <code>filename</code> containing our candidates; an optional <code>completing-fn</code>, as set by passing <code>-c</code> to <code>ezf</code>; and an optional <code>field</code> index.</p><p><code>ezf-separators</code> is a regular expression to split each line by. So if you want NULL-delimited support then you can easily add that and a switch to go along with it.</p><p>Because weâ€™re taking unsanitized candidates and passing them through our completion system, itâ€™s good form to ensure the filtered candidates are properly escaped when we hand them back to the shell. Thatâ€™s what <code>shell-quote-argument</code> does. <code>mapconcat</code> merely ensures the quoted candidates are space-separated as thatâ€™s what shells expect. (And if you want NULL separation you should change this also.)</p><p>Because the last value is by convention the value that is returned from a function in Lisp, we know that the output of <code>emacsclient</code> is the result of the <code>mapconcat</code> form if we selected any matches, and <code>nil</code> otherwise.</p><p>With all this in place itâ€™s time to test it:</p><figure>
   <img src="https://www.masteringemacs.org/static/uploads/ezf-default.svg" alt="fuzzy matching with ezf, the Emacs fuzzy finder">
<figcaption>Fuzzy matching dictionary words with Emacs and <code>ezf</code></figcaption>
</figure><p>Yep. Looks good.</p><p>This tool is able to do most of the things youâ€™d use <code>fzf</code> for, and all from within the comfort of your Emacs. Itâ€™ll work just fine in Eshell also if you donâ€™t push it too hard. Eshellâ€™s support for pipes and redirection is not as good as regular shells, but with a little bit of work it could be made to work there too, with or without the bash script. And of course you can use it from Terminals also: the ones you run from inside Emacs, and external ones also.</p><h2 id="example-use-cases">Example Use Cases</h2><p>Hereâ€™s a few examples of how you can use the tool. It goes without saying that itâ€™s a bit threadbare compared to <code>fzf</code>, but I think itâ€™s easy enough to extend to suit your own needs. This is also a great way to get your hands dirty with elisp if you have never done any before.</p><p>Iâ€™m going to point out that <code>M-x helm-locate</code> already does this, but you can use GNU <code>locate</code> to track down files matching a regex pattern and then open them in <code>emacsclient</code>:</p><pre><code>$ <span>emacsclient</span> <span>$(</span><span>locate</span> -r <span>'[.]py$'</span> <span>|</span> <span>ezf</span><span>)</span></code></pre><p>GNU <code>locate</code> works by querying a database that updates whenever you call <code>updatedb</code>. Itâ€™s probably the one of fastest cached file searchers available today. You can have multiple databases with different configurations (one for your home directory and another for the whole file system) to further speed it up. I highly recommend you look into using it if you regularly sweep your file system looking for files.</p><p>Finding and installing packages with <code>apt-get</code> and <code>apt-cache</code>:</p><pre><code>$ <span>apt-get</span> install <span>$(</span><span>apt-cache</span> search <span>&lt;</span>term<span>&gt;</span> <span>|</span> <span>ezf</span> -f 1<span>)</span></code></pre><p>Change directories. Try playing around with the arguments to <code>find</code>, or use something simpler like <code>ls</code>:</p><pre><code>$ <span>cd</span> <span>$(</span><span>find</span> . -maxdepth 3 -type d <span>|</span> <span>ezf</span><span>)</span></code></pre><h2 id="next-steps">Next Steps</h2><p>I think this is a pretty good example of how you can combine the power of Emacs and a little bit of gnarly shell script magic. And this is really just the beginning. You can take the shell script and hook it up to all manner of crazy Emacs stuff: <code>M-x dired</code>; sending stuff to a buffer for editing; and more.</p><p>You can also find it on Github here: <a href="https://github.com/mickeynp/ezf">EZF</a>.</p>

    
    
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Can we do better than Git for version control? (106 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38590080</link>
            <guid>38590080</guid>
            <pubDate>Sun, 10 Dec 2023 08:28:38 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38590080">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="38590080">
      <td><span></span></td>      <td><center><a id="up_38590080" href="https://news.ycombinator.com/vote?id=38590080&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=38590080">Ask HN: Can we do better than Git for version control?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_38590080">103 points</span> by <a href="https://news.ycombinator.com/user?id=slalomskiing">slalomskiing</a> <span title="2023-12-10T08:28:38"><a href="https://news.ycombinator.com/item?id=38590080">12 hours ago</a></span> <span id="unv_38590080"></span> | <a href="https://news.ycombinator.com/hide?id=38590080&amp;goto=item%3Fid%3D38590080">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Can%20we%20do%20better%20than%20Git%20for%20version%20control%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=38590080&amp;auth=f2b679cac7015fcd9eb7f8bafb4e57f31caa0ce1">favorite</a> | <a href="https://news.ycombinator.com/item?id=38590080">177&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>Do you think itâ€™s possible to make a better version control system than Git?</p><p>Or is it a solved problem and Git is the endgame of VCS</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table><table>
            <tbody><tr id="38591669"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38591669" href="https://news.ycombinator.com/vote?id=38591669&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>A lot of people these days have just been thrown into the fire with Git as the first and only VCS theyâ€™ve ever seen.<p>Iâ€™m not that old, but Iâ€™m old enough to have used RCS, CVS, SVN, then finally Git. I started using Git super early, before GitHub existed. You may not believe me, but Git was the answer to all my prayers. All those previous systems had fundamental architectural flaws that made them a complete nightmare to use on a team for any serious work.</p><p>Git has no such problem. Thereâ€™s nothing it canâ€™t do. Instead, the only limitation is on the user being able to know how to get Git to do what they want it to do. Thankfully, thatâ€™s always solvable with a quick read of the documentation or web search.</p><p>I understand that people might want to make it easier, since the UI is complex, but thatâ€™s never going to work. If you abstract away the complexity of the UI, you will necessarily abstract away the power. If you abstract away the power, you are no longer solving all the problems that Git solved. People just donâ€™t realize what problems are being solved because they never lived through those problems with the previous VCSes.</p><p>You know whatâ€™s easier than building a new VCS better than Git? You know whatâ€™s easier than using a different VCS from the rest of the world? You know whatâ€™s easier than designing a miraculous abstraction on top of Git?</p><p>Learning Git.</p><p>Whatever effort you are putting into seeking or building an alternative, instead put that effort towards becoming a Git expert. It will be a lot less effort with a lot more benefit. Trust me on this. It will be well worth it for your career and for your personal computing life as well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593116"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593116" href="https://news.ycombinator.com/vote?id=38593116&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>While I feel like this is generally true for most programmers and knowledge workers, Git is absolutely not suited to the workflow of several industries, including the one I work in: games.<p>Working with an engine like Unreal Engine for a project of any reasonable size requires working with both hundreds of thousands of active files (my current project's repo's HEAD has ~400k) and hundreds of gigabytes of active files, many of which are many GB on their own.  Our repository (in perforce) is currently in the order of 10TB.</p><p>Git, even with LFS and partial clone and shallow copies and fsnotify just falls apart at this scale.  Add to that the necessity for less-technical people (artists, designers, VFX, audio, etc) to use it, and it is really just a non starter.</p><p>I absolutely loathe Perforce (having used and occasionally admin'd it professionally since 2007), but I begrudgingly admit that is is currently the only publicly available VCS that can fulfill all of the requirements of this industry in a practical way.  Plastic and the others just aren't there yet.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593293"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593293" href="https://news.ycombinator.com/vote?id=38593293&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>This could be solved with references rather than copies if your tools integrated them. e.g. dependencies can be ref'd with source/name and version. To ensure availability all such used blobs could be stored efficiently elsewhere and versioned.<p>It's great that Perforce works and I've heard others in the graphics field using it, so it satisfies a need. Don't know if/when it would be a general need for say GitHub users.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38594054"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38594054" href="https://news.ycombinator.com/vote?id=38594054&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>This post is a terrible failure of imagination that would make one stop language development as C because it was so much better than Assembly.<p>If you have no problems with Git, then Iâ€™m happy for you. I certainly have problems with Git, eg its inability to handle large repositories meaningfully (enjoy a Chromium checkout!), the arcane CLI commands, the shut-your-eyes-and-hope of moving commits between branches and other sharp edges.</p><p>That Git has been as resilient as it has is largely a function of being written by Torvalds and GitHub network effects. It isnâ€™t for lack of better/as good features found in other VCS methodologies.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594107"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38594107" href="https://news.ycombinator.com/vote?id=38594107&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>git still has issues with lots of files. I downloaded the sec Edgar database as files and I thought it would be nice way to store and watch changes.<p>Nope.</p><p>So slow. It does not like millions of files. And all my tooling that does a â€œquickâ€ git status locked up the terminal, vs code, etc.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594484"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38594484" href="https://news.ycombinator.com/vote?id=38594484&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Did you try the file system daemon (git fsmonitor--daemon start) thatâ€™s built into git that was designed to speed up git status on many files?</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38594083"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38594083" href="https://news.ycombinator.com/vote?id=38594083&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; its inability to handle large repositories meaningfully<p>Out of curiousity, what other SCM tools can pull this off better?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594232"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38594232" href="https://news.ycombinator.com/vote?id=38594232&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I havenâ€™t played with many because I simply donâ€™t have the time between work (Googleâ€™s Piper and Git) and kids. Piper handles the monorepo by only offering files when requested by the file system at the specified commit (this is probably a gross or even incorrect simplification, but is how it presents to the user).<p>There are good reasons that one should keep the whole commit history to distribute a source of truth, but at the same time if one is going to place full trust in something like GitHub (as many do), thereâ€™s no reason that full trust canâ€™t be given to a similar website that provides a Piper model with some mechanism to request more than one commit to be brought to local storage (to get more sources of truth).</p><p>End of the day, a large repo checkout is going to be limited by either your network, your CPU/storage to perform archive expansions, or frequently both. I get the impression that Android and Chromium are expanding faster than those other things are improving, but have no data to back that up.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38592860"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592860" href="https://news.ycombinator.com/vote?id=38592860&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;I understand that people might want to make it easier, since the UI is complex, but thatâ€™s never going to work. If you abstract away the complexity of the UI, you will necessarily abstract away the power.<p>I disagree, really.</p><p>There is not fundamental reason why you cannot have user-friendly UI for 98% of the cases and some "advanced" for those 2%.</p><p>Just like GUIs have "advanced" settings, the CLI can have well designed 10 commands for basic usage that are taught to newbies and then advanced ones.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594082"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38594082" href="https://news.ycombinator.com/vote?id=38594082&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>The problem is that for 99.99% of the people engaged in the debate over if git is good or not and should be replaced the correct answer for them is "stop fighting it and just learn git" because there's nothing better.  They need to stop thinking about how git sucks because that is literally getting in the way of their career goals and is self-sabotage.<p>And if anyone seriously wants to try to replace git they need to understand how git works first at the level of an advanced expert first anyway.  At that point, you can have the discussion about how to make git, with better LFS/monorepo support, with a more pleasant UI/UX, etc.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                      <tr id="38593029"><td></td></tr>
                <tr id="38593397"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593397" href="https://news.ycombinator.com/vote?id=38593397&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I would say that Mercurial has a simpler UX than Git without being less powerful. I think Jujutsu (see other posts here), which I started, also has simpler UX and is more powerful than Git in many ways. Have you looked at either of those?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38593349"><td></td></tr>
            <tr id="38593055"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593055" href="https://news.ycombinator.com/vote?id=38593055&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;Do it then. Many have tried. All have failed. Talk is cheap.<p>I'm, just like many other people using GitHub Desktop (or Git Kraken or Git Extension, but I dont like this one)</p><p>when I'm working in GUI environment, that's proof that it is possible.</p><p>The problem with creating 3rd party tool that's CLI wrapper is that you cannot rely on it being installed on the system.</p><p>That's why such solutions usually fail - because you risk relying on stuff that may not get traction and you'd be better sticking to "official" syntax in long run.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593865"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38593865" href="https://news.ycombinator.com/vote?id=38593865&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I'll share here my positive opinion of GitExtensions (on Windows). It has really helped me use and better understand Git, while also helping me define and share workflows with my colleagues..<p>Other GUIs, like the ones embedded in VisualStudio, VSCode or Rider, try to sell skipping some cognitive steps for some operations as simplifying or speeding up dev flow. 
I find they are just offering extra (beyond what git itself offers) ways of shooting yourself in the foot.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593322"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38593322" href="https://news.ycombinator.com/vote?id=38593322&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Is gitk still a thing that's available with git? Not as full featured but great for viewing and good with many commits/files.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38593107"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593107" href="https://news.ycombinator.com/vote?id=38593107&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; I understand that people might want to make it easier, since the UI is complex, but thatâ€™s never going to work. If you abstract away the complexity of the UI, you will necessarily abstract away the power.<p>There's a lot of "useless" complexity in the Git UI. The naming of the commands and the underlying concepts are quite inconsistent. The commands themselves are inconsistent. It's rare to see somebody, even git fans, to dispute that the UI is far from optimal. And the warts in the UI are being improved.</p><p>These UI warts start to become invisible when you get used to them, but e.g. when teaching git they become painfully obvious again.</p><p>The underlying git architecture is simple and it's the simplicity that makes git powerful. Powerful tools don't necessarily need complex interfaces. In fact power often comes from simple interfaces that compose well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38591865"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38591865" href="https://news.ycombinator.com/vote?id=38591865&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>The git model has fundamental limitations because it saves snapshots rather than changes, and doesn't capture some metadata changes like renames.  A tool like Darcs or one of its spiritual descendants will have fewer merge conflicts than git.<p>Totally agree on your main point though.  The benefits of switching are far lower than the costs.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593067"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593067" href="https://news.ycombinator.com/vote?id=38593067&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;it saves snapshots rather than changes<p>Once you understand this, GIT makes a whole lot more sense. The trouble with failed merges is an artifact of trying to appear like it tracks deltas. Merge conflicts when you're the only programmer on a product (but have multiple computers) are maddening.</p><p>I blew away .git and everything in it, restarting a repository, more than once because I couldn't resolve a merge conflict, before I learned that simple fact.</p><p>I've got from .zip files of my source code on floppy disks, to SVN, then Mercurial, and finally GIT.  GIT is amazing, though the UI is a pain, as most agree.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593134"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593134" href="https://news.ycombinator.com/vote?id=38593134&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>&gt; <i>doesn't capture some metadata changes like renames</i><p>If you rename the file using git and that is the only change in your file, then it works:</p><pre><code>  git mv oldfile newfile
</code></pre>
Commit that change and the rename is in your history.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38593187"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593187" href="https://news.ycombinator.com/vote?id=38593187&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>the rename won't be in your history because the tree and commit objects don't support renames<p>the tooling infers a rename based on the lack of a content change
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593994"><td></td></tr>
                        <tr id="38592375"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592375" href="https://news.ycombinator.com/vote?id=38592375&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; ..because it saves snapshots rather than changes..<p>I might be misremembering the technical details, but isn't that only the case in a git repo with zero pack files?</p><p>Will grant that the lack of metadata on renames can be issue when a file is heavily refactored alongside it's relocation.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38592938"><td></td></tr>
                        <tr id="38594257"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38594257" href="https://news.ycombinator.com/vote?id=38594257&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>i mostly agree that git can do almost anything (but see the limitations others bring up), however this claim is easy to disprove:<p><i>Whatever effort you are putting into seeking or building an alternative, instead put that effort towards becoming a Git expert.</i></p><p>building an alternative naturally is more work than to learn git for one person, but not everyone needs to do that. a few people building an alternative could save the learning effort of many more people.</p><p>instead i'd like to point out a different reason why rebuilding git may not solve the problem:</p><p>git is good because it is powerful and flexible.</p><p>that power and flexibility by necessity makes git more complex and difficult to use.</p><p>you can build a simpler system, but then half of todays git users won't be able to use it because it won't have the features they need.</p><p>and a system that has all the features of git today and also solves the problems it currently has will be even more complex and less straigt forward to use.</p><p>the best approach is probably to have a common backend that has all the power and flexibility needed, and multiple different frontends that are simplified to only expose the features needed for a particular workflow.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592752"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592752" href="https://news.ycombinator.com/vote?id=38592752&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Git keeps the entire history on your local machine, this becomes a problem if your project grows to several hundred GB (not untypical in game dev). Even SVN was much better for working with large repositories, you only needed a big server. Git is quite nice for "source code only projects though".</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38593268"><td></td></tr>
            <tr id="38593146"><td></td></tr>
            <tr id="38592863"><td></td></tr>
                <tr id="38593532"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593532" href="https://news.ycombinator.com/vote?id=38593532&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Overall LFS feels a very hacky tacked on solution with warts.<p>Git LFS is horrible if you mistakenly add some file(s) to LFS.</p><p>Restoring to LFS-less state is supposed to be easy but it is always very painful.</p><p>There should be a way to tell repo - I do not want any LFS at all. In practice this is painful, and it is easier to start a new repo....</p><p>Also for some reason Github/Microsoft decided to "monetize" LFS. The freebie limits are 1GB for hosting AND transfer! Then the charges get very expensive.</p><p>I am not sure why Github LFS is priced like some AWS S3 plan not OneDrive plan.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594881"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38594881" href="https://news.ycombinator.com/vote?id=38594881&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>GitHub charges for LFS and has since they initially introduced it, way before Microsoft was involved. Also, the pricing model is changing and will include a minimum of 10GiB for free (250GiB for Team/Enterprise customers). Itâ€™s cost-recovery and abuse-prevention, though, not some nefarious scheme. And funny you mention AWS S3... what costs might GitHub be recovering? ;)<p>Microsoftâ€™s homegrown LFS implementation (in Azure DevOps) does not and has never charged for LFS. Itâ€™s nice to have friends with a cloud blob storage service!</p><p>Source: I was the product manager for Azure Reposâ€™s LFS server and am currently the product manager for all things Git at GitHub.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38593115"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593115" href="https://news.ycombinator.com/vote?id=38593115&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Have seen various teams have major issues with LFS - becoming quite a support overhead to keep art teams productive.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38593135"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38593135" href="https://news.ycombinator.com/vote?id=38593135&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Yeah exactly this. Git LFS is supposed to fix the problem, but I haven't seen it working flawlessly either yet.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38594330"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38594330" href="https://news.ycombinator.com/vote?id=38594330&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Interesting, I had issues using Git LFS to store images for my personal site. I thought I just didn't know how to use it properly...</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38593302"><td></td></tr>
                        <tr id="38593312"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593312" href="https://news.ycombinator.com/vote?id=38593312&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>That's what i liked about git too. It felt like a powerful, ready to use tool. CVS and SVN were more bureaucratic, slower and limited. Took zero second for me to drop everything else.<p>The underlying model is alien to many, it requires non black box approach to get out of pits sometimes but to me it's always worth knowing.</p><p>The only decision I dislike about git is the soldered staging area idea. There's a reason why most people end up stashing 109 times a day, and I think there's a golden idea in merging the two
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38594195"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38594195" href="https://news.ycombinator.com/vote?id=38594195&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Wholeheartedly agree.<p>Going from SVN to Mercurial was a night and day experience. Going from Mercurial to Git was a marginal improvement initially but a lasting change long-term.</p><p>Then there are the "visual" VCSes like Rational and TFS that are designed to _only_ work within an IDE and grokking them involves wading through hundreds of pages of corporate tech docs.</p><p>VCSes (or at least the ones I used) were generally awful before Git.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38591965"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38591965" href="https://news.ycombinator.com/vote?id=38591965&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Along what axis do you want the VCS to be "better" than git?<p>For example, git's cli user interface is monstrous (yes, I know, you personally have 800 cli commands memorized and get them all right every time, that doesn't make it "good"). From the outset, the maintainers of git basically decided "it's too much work to make all the cli flags behave and interact consistently" so they didn't. This allowed git to grow fast, at the cost of the cli user experience.</p><p>That said, git is big enough that multiple companies have come along and "solved" the git UI problem. None of these aftermarket UI layers are perfect, but there are enough of them and they are different enough that you can probably find one that is good enough for you, along whatever axis you personally dislike the git UI (examples include [0], [1], [2], which tackle very different user workflow problems).</p><p>[0] <a href="https://git-fork.com/" rel="nofollow noreferrer">https://git-fork.com/</a></p><p>[1] <a href="https://graphite.dev/" rel="nofollow noreferrer">https://graphite.dev/</a></p><p>[2] <a href="https://news.ycombinator.com/item?id=7565885">https://news.ycombinator.com/item?id=7565885</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593053"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593053" href="https://news.ycombinator.com/vote?id=38593053&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I generally don't hear too many complaints about GIT in the Windows/.NET development world, probably because there are good UI front ends and there's not as much 'tough guy' cred from sticking to the CLI. Visual Studio does a decent job of abstracting the GIT nuances, but I personally use GIT Extensions, which looks and feels much better on Windows than the other cross platform UIs.<p>I drop to the CLI occasionally, especially for multi step or automated scripts, but you can pry a nice visual commit graph and full featured integrated diff viewer from my dead hands. GIT is powerful and option-laden; the perfect tool for a UI to aide in discoverability. The CLI feels like programming in a text editor vs a real IDE
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593634"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593634" href="https://news.ycombinator.com/vote?id=38593634&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; Visual Studio does a decent job of abstracting the GIT nuances, but I personally use GIT Extensions, which looks and feels much better on Windows than the other cross platform UIs.<p>IDEs and text editors sometimes have nice Git integrations in the UI, but I wanted standalone software that I can use for anything from various programming projects, to something like gamedev projects (with Git LFS) or arbitrary documents.</p><p>In the end, I just forked over some money for GitKraken, it's pretty good, especially with multiple accounts on the same platforms, when you want to switch between them easily: <a href="https://www.gitkraken.com/" rel="nofollow noreferrer">https://www.gitkraken.com/</a></p><p>There's also Sourcetree which I used before then, kind of sluggish but feature complete: <a href="https://www.sourcetreeapp.com/" rel="nofollow noreferrer">https://www.sourcetreeapp.com/</a></p><p>For something more lightweight, I also enjoyed Git Cola on various OSes: <a href="https://git-cola.github.io/" rel="nofollow noreferrer">https://git-cola.github.io/</a> Even Git documentation has a page on the software out there, a good deal of which is free and has good platform support: <a href="https://git-scm.com/downloads/guis" rel="nofollow noreferrer">https://git-scm.com/downloads/guis</a></p><p>Quite frankly, I spend like 90% of the time using a GUI interface nowadays, when I want to easily merge things, or include very specific code blocks across multiple files in a commit, or handle most of the other common operations. Of course, sometimes there's a need to drop down to the CLI, but you're right that some GUI software feels like it actually improves the usability here.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593939"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593939" href="https://news.ycombinator.com/vote?id=38593939&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I too am a fervent GitExtensions apostle.<p>I really wish the 4.* release supported a dark theme, it's the only thing keeping me on the 3.* release, and I dread the day I'll have to switch for whatever reason...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593639"><td></td></tr>
                        <tr id="38590336"><td></td></tr>
                <tr id="38593087"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593087" href="https://news.ycombinator.com/vote?id=38593087&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I tried this, and I loved it. It works very well with my workflow.<p>Perhaps the author can explain - when you clone the repo with</p><p>jj git clone</p><p>It pulls down a branch that is auto generated like pull-(hash)</p><p>I canâ€™t understand how not to get that corrupted so when I do a jj log, I get very weird branches or heads or Iâ€™m not sure what.</p><p>Another way to say it is that everything works great until I have to pull down the repo from another machine - then the branch history is not what I expect. And I just couldnâ€™t make sense of it or get it to square with what I expected.</p><p>I actually created a custom GPT and fed it the jj code and documentation to try and get it to explain it to me to no avail. Jj is so good, Iâ€™m willing to give up IDE integration with git if I could just crack this nut.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593508"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593508" href="https://news.ycombinator.com/vote?id=38593508&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Just echoing Martin, but: if you can show the repository that is causing this, or at least a screenshot (or something) showing what you're seeing and post it on GitHub, one of us should at least be able to help figure out what's going on.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38593285"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593285" href="https://news.ycombinator.com/vote?id=38593285&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I can't tell what the problem is based on that description. Feel free to file a bug report, or start a GitHub discussion, or ask on Discord.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590797"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590797" href="https://news.ycombinator.com/vote?id=38590797&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Surprised this is done in Rust. I could never imagine not doing the v1 of something like this in Python or similar, to be able to change things quickly. Maybe the design was very clear on the person's mind.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38593971"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593971" href="https://news.ycombinator.com/vote?id=38593971&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I'm not particularly productive in python. The code gets shat out faster but it's a comparatively weak language for capital-P Programming â€” lack of types means repeating and checking yourself <i>a lot</i>.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38593575"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593575" href="https://news.ycombinator.com/vote?id=38593575&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>There are other advantages aside from the static types debate in the other replies. The need for efficient version control systems is a constant and ongoing battle; you can pick the right data structures (for example, Git's issues with large files are more of a data structure problem than one of raw efficiency) but at the end of the day Python will often be behind on raw performance. Rust will hopefully let us embed the Jujutsu libraries inside other languages, something you can only achieve today in Git with something like libgit2. Finally, a lot of the infrastructure we get to use, like nextest and cargo-insta are simply fantastic even if I have my qualms about Cargo.<p>Most of the developers (some of them being former Mercurial and Git developers) including me generally seem to like it. Based on my own experience, I think it's a pretty excellent choice, but I'd be a bit biased as a die-hard Haskell/C programmer for something fast with types.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592367"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592367" href="https://news.ycombinator.com/vote?id=38592367&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I feel the opposite way.<p>Even though Python is the language Iâ€™ve used most, I wouldnâ€™t want to use it for something with a lot of uncertainty and that will suffer many changes. Type systems make it so much easier to change things early on without breaking everything. Iâ€™d probably pick F# or similar.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593343"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593343" href="https://news.ycombinator.com/vote?id=38593343&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>The current DVCS solution at Google is based on Mercurial, which is written in Python. Having worked on that for many years, I didn't want to write jj in Python. We've had problems with the performance of the current solution. Also, as others have said in sibling replies, refactoring Python is not fun due to lack of static types (I know it's gotten better).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38591747"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38591747" href="https://news.ycombinator.com/vote?id=38591747&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Rust is a fabulous language for refactoring.  Strong types and complete matching make it almost completely impossible to miss a spot when making a change</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38593327"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593327" href="https://news.ycombinator.com/vote?id=38593327&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Python certainly lets you change things quickly, because it does not let you automatically enforce any invariants; this is why it lets you get into such extraordinary inconsistent states so easily! I personally could never imagine trying to make a jigsaw out of jelly because "it's v1 and I'll make v2 properly".</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38590380"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590380" href="https://news.ycombinator.com/vote?id=38590380&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yes. From the creators of Sqlite, you got Fossil.<p>One of the most amazing things about Fossil is how you can track the history of a file not just backwards, but also forwards, something which is pretty whacky with git.</p><p><a href="https://www.fossil-scm.org/" rel="nofollow noreferrer">https://www.fossil-scm.org</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590883"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590883" href="https://news.ycombinator.com/vote?id=38590883&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>100% fossil. there has been a few threads.. and always someone points out edge cases that are only to be solved using git.. well i dont think so. you can actually go into the sqlite db and change stuff. i've recently started playing with its server api to direct user feedback from web to fossils ticketing system. it is just mature and feature packed and i honestly hope it will get as much recognition as sqlite someday.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592421"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592421" href="https://news.ycombinator.com/vote?id=38592421&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>The only thing I wish git handled better out of the box, with without any flags/setup, is large/binary assets.<p>LFS is ok but it still feels like a kludge to me.</p><p>The cli does not bother me, there are many tools that offer alternatives/overlays/UIs. Not saying it is perfect or even good, but it's good enough - for me at least.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593068"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593068" href="https://news.ycombinator.com/vote?id=38593068&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>exactly right! lfs is "<i>kinda okay?</i>" at best. i just wish binary support was just part of git natively.<p>honestly keeping the large binaries as loose objects would be fine except for performance. which should be something that could be improved with cow filesystems (lfs does use this, but limited by what git's implementation can support)</p><p>or it may be enough to incrementally improve lfs, i do see that ssh support is showing up which might help a little. need to do something about smudge/clean filters too, which would require new support in git itself.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590348"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590348" href="https://news.ycombinator.com/vote?id=38590348&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>The inner workings of git are not overly complicated. The real problem is git only provides a thin layer on top of the inner workings. Itâ€™s not git that needs replacing, (itâ€™s just saving blobs of data) itâ€™s the user interface on top that is confusing.  The problem with simplifying the user interface is that abstracting away the complexity is super difficult.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590474"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590474" href="https://news.ycombinator.com/vote?id=38590474&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Git feels a lot like pgp to me: somehow we're not managing to make things simple enough for use by the general public, even when you only need a few buttons and input fields.<p>There's differences, such as that pgp is more complicated under the hood and it being a cryptographic system that needs to be foolproof whereas in git you can nuke and re-clone without data loss most of the time, let alone confidentiality/integrity loss. It just feels very similar in that only expert users properly use it and most people who could make use of it don't bother learning because the interfaces available are such a struggle (beyond basic operations anyway)</p><p>Whether it can all be solved with a simpler user interface, or whether it would require a simpler underlying system to be able to make simpler standard operations, is where I'm not sure
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593554"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593554" href="https://news.ycombinator.com/vote?id=38593554&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Git does have one big architectural problem IMO - native unit of storage is a blob, not a diff. Things like rebase, cherry-pick, 3-way merge, etc would be much easier in a world where the storage model was â€œdiffsâ€ instead of â€œblobsâ€.
This would have resulted in simpler CLI tools with fewer pitfalls.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38594577"><td></td></tr>
                  <tr id="38590499"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590499" href="https://news.ycombinator.com/vote?id=38590499&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Not overly complicated, but super difficult to abstract is somewhat of a contradiction. Maybe the inner workings are complicated, but not complicated to implement right once you understand them.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590309"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590309" href="https://news.ycombinator.com/vote?id=38590309&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yes, there must be a better solution. Git is (usually) better than the alternatives, but it is far from being good. Especially the discoverability of its features is a mess - arcane command line incantations, magic processes. Sometimes only a prayer helps before running the 12th command you found on stackoverflow in desperation. Once you leave the pull-commit-push-merge-rebase circle, you gotta hope that god helps you, because no one else will (or more like no one else can).<p>Unless of course you spend time to learn git, but its complexity is closing up to C++. And using a VCS shouldn't require that amount of effort. It should just get out the way (I must admit, git usually gets out of the way, as long as you use only the base commands... but when it gets in the way, that's when the fun starts)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592262"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592262" href="https://news.ycombinator.com/vote?id=38592262&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>What do you recommend for non-programmers, who would still benefit from version control system.<p>Examples:
- Book author using markdown / static site generator to publish a book. Uses visual editors like Typora. 
- Product designers for open-source hardware. Various design files, SVG etc.</p><p>Iâ€™ve experimented with a â€œGUI onlyâ€ git flow - just to see what is possible, so I could introduce the concept to others.</p><p>I found GitHub desktop app (<a href="https://desktop.github.com/)did" rel="nofollow noreferrer">https://desktop.github.com/)did</a> a great job of visually showing git flows and functions, but for a non-tech/programmming person, the tool would be daunting.</p><p>Curiosity what your suggested tech stack would be - sans Terminalâ€¦
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594164"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38594164" href="https://news.ycombinator.com/vote?id=38594164&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>i'd probably recommend Mercurial, say a UI like TortoiseHq. It has 90% of the value of git with a much better interface.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38594596"><td></td></tr>
                  <tr id="38592288"><td></td></tr>
            <tr id="38593241"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593241" href="https://news.ycombinator.com/vote?id=38593241&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yes, it will be superseded.  Will the new thing be â€œbetter?â€   I guess that depends on the metric and needs.   â€œlsâ€ was done but exa/eza came along and they have users.<p>Pondering it, most of the easy things I can think about are really workflow issues on top of git.  Git doesnâ€™t exactly enforce them all though so maybe tighter integration would be a reason to change from git if it could not be adapted.   Short of that, itâ€™s hard to imagine that a new generation of engineers simply wonâ€™t do a new thing to do a new thing; there will be a â€œgit considered harmfulâ€ article or a â€œmodernâ€ replacement for git.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590414"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590414" href="https://news.ycombinator.com/vote?id=38590414&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Besides the frontend problems with git that everybody talks about, the backend could be improved. It's now line-oriented. It would be more useful if it knew about the semantics of the language you were writing so it could show you semantic differences. That might also provide a mode for binary files which git doesn't handle very well now.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590432"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590432" href="https://news.ycombinator.com/vote?id=38590432&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Actually, itâ€™s not the backend which is line oriented, itâ€™s the front end. The backend doesnâ€™t dissect files, it stores the entire new file when even one line is changed and relies on object compression to find the similarity in the rest.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590433"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590433" href="https://news.ycombinator.com/vote?id=38590433&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Before we can get a vcs that understand semantic diffs, we need a way to communicate semantic diffs.  That way each file type can have its own â€œsemantic differâ€. Similar to how language servers help abstract away the differences for IDEs</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590477"><td></td></tr>
                <tr id="38590525"><td></td></tr>
                <tr id="38594273"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38594273" href="https://news.ycombinator.com/vote?id=38594273&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>The diffs don't have to be line-oriented if you are using a diffing tool that isn't based on line changes.<p>Git itself just stores snapshots of your files, then you can bring your own diffing tool that works in any way you'd like, it's not limited to line based diffing.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592667"><td></td></tr>
            <tr id="38590968"><td></td></tr>
                              <tr id="38593993"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593993" href="https://news.ycombinator.com/vote?id=38593993&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>there was such a thing for c#, called semantic-merge by Codice Software, a Spanish company that after being bought by Unity, killed it...</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590607"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590607" href="https://news.ycombinator.com/vote?id=38590607&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Don't know about a better solution, but there might be a better interface. My pet theory is that focusing more on the fact that a repo is a directed graph would help. Make the language more graph-like (less "commit" more "node", less "branch" more "path", less "repo" more "graph"). This kind of thinking would, I think, expose a bunch more primitives that should be surfaced more explicitly than they are (lots of things are "possible but not easy" in git), and make it easier to learn for anyone with a math background. And make web searches easier too.<p>(Pretty sure I've said this before and it's been shot down before, so...)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590442"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590442" href="https://news.ycombinator.com/vote?id=38590442&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>As far as I can tell, Pijul[0] aims to have better conflict resolution and merge correctness.
I'm not super into the theory, so I can't explain it very well, but it looks promising.<p>[0] <a href="https://pijul.org/" rel="nofollow noreferrer">https://pijul.org/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38594749"><td></td></tr>
            <tr id="38590444"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590444" href="https://news.ycombinator.com/vote?id=38590444&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>An obvious area for improvement would be semantic version control.<p>If the VCS would have an understanding of not only what has changed but also how this affects the code, it could deduce a lot if interesting facts about commit blocks.</p><p>Like ignoring simple refactorings (e.g. renamings), reducing merge conflicts, etc.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590411"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590411" href="https://news.ycombinator.com/vote?id=38590411&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Subversion was really good. It wasn't perfect, but it was relatively painless.<p>Instead everyone switched to a "distributed" version control system that is such a pain in the ass it is all now hosted by a single company.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590429"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590429" href="https://news.ycombinator.com/vote?id=38590429&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>My first job used SVN and it limited workflows compared to git. Branches are more expensive, so people adapt their workflows. I used git-svn on that job, which allowed me to refactor locally; not a feature available to me or others once pushed.<p>My colleagues evaluated git and thought it was too complicated. A few years and a lot of employments later, theyâ€™re all using git. I donâ€™t know if it was peer pressure from enough young recruits, but the verdict is clear: git is better than SVN.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593250"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593250" href="https://news.ycombinator.com/vote?id=38593250&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>My very first programming job used Subversion. Even as a freshly minted programmer I knew we were using it completely wrong.<p>My first assignment was to spend several days picking apart an extremely nasty merge conflict from two branches nearly six months diverged. That was a <i>very</i> stupid thing to trust me with, as a major refactor was being blessed by my idiot hands.</p><p>Management could not figure out how they wanted to maintain a master/production branch.</p><p>Our 'trunk' was the develop branch, and any time we wanted to push to production.... We deleted the master branch and made a copy of develop. Master branch had no history, you had to track it back into develop and hope you found a trailhead from there.</p><p>It was a very bad time, and we were left with a <i>very</i> bad product. By the time I left, the codebase was so rotten and broken that we'd abandoned all hope of fixing the deeper issues.</p><p>I really hated subversion, but mostly the company was just unbelievably mismanaged. I'm sure you can use SVN in a sane way, just not like this
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590473"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590473" href="https://news.ycombinator.com/vote?id=38590473&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Many companies host git besides github (gitlab and bitbucket to name two), and you can spin up one of your own in about 1 minute on your hardware or on a private cloud vps.<p>A github server is much easier to set up than a subversion server. The reason people use github is because it's free, and because it has issue tracking and a wiki and forking which plain git knows nothing about.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590544"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38590544" href="https://news.ycombinator.com/vote?id=38590544&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>And nowadays it offers so much more like the GHAS, codespaces, copilot, actions and workflows etc that companies who get entrenched would need half a dozen different vendors to cover the feature set if they were to migrate from GitHub.<p>And in general I feel that their gh cli tool doesnâ€™t get enough praise. Being able to do easy API calls and queries for use in shell scripts (or just the terminal) is great, and the gh copilot is occasionally useful as a refresher for command syntax, or for deciphering some oddball git command you found online.</p><p>Itâ€™s a massive beast to tackle, and few people have a reason to. I donâ€™t see anything doing what git does having a chance at competing with it. It requires a paradigm shift and a completely new product/approach to versioning to break the git dominance.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590530"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38590530" href="https://news.ycombinator.com/vote?id=38590530&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>You can absolutely spin up vanilla git on your own machine, but try using it for a week. From some quick Googles it looks like Github has 80% market share of version control with Dollar Store Github (Gitlab) picking up the rest. Everyone uses the pretty tool stack built on top of it because it is overly complex. Git didn't add anything profound that couldn't have been added as a feature to another VCS.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592637"><td></td></tr>
                <tr id="38593165"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38593165" href="https://news.ycombinator.com/vote?id=38593165&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>The intention I got from @dreamcompiler was that "A git server is much easier to set up than a subversion server.", which I feel is true.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38593615"><td></td></tr>
                  <tr id="38593024"><td></td></tr>
                  <tr id="38593587"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593587" href="https://news.ycombinator.com/vote?id=38593587&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; A github server is much easier to set up than a subversion server.<p>Oh here we go again. You are wrong my friend. Firing up a basic SVN server is a matter of minutes. You just need to run several simple commands.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590694"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590694" href="https://news.ycombinator.com/vote?id=38590694&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Torvalds liked to code on planes back when you couldn't use the internet and that's just about the only use-case I've ever heard where I agree distributed makes sense.<p>Kids these days can't even code at all without chat-GPT, there's a central server hosting the git repo anyway, the whole architecture feels like it was designed for dial-up.</p><p>I can't think of anything that was doable 30 years ago compute and bandwidth-wise, that we can't do today due to performance reasons, except client-server source control...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590426"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590426" href="https://news.ycombinator.com/vote?id=38590426&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Please, Github is so much more than git hosting. If all it offered was source hosting, no one would care for it.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590471"><td></td></tr>
                <tr id="38590503"><td></td></tr>
                <tr id="38593735"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38593735" href="https://news.ycombinator.com/vote?id=38593735&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I think the meaning of the sentence you're replying to is that GitHub's features are a superset of Git's features which seems true?<p>"Github isn't all git [some features of GitHub are not in Git], but all git is Github [but all features of Git are in GitHub]."</p><p>Maybe my interpretation is incorrect?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="38590509"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590509" href="https://news.ycombinator.com/vote?id=38590509&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I recently started a new job that uses SVN, one thing that really catches me out is that it doesn't automatically add new files. Is there some easy trick I am missing to tell SVN to automatically track everything recursively under a folder?</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590291"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590291" href="https://news.ycombinator.com/vote?id=38590291&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Of course there is a room for improvement... One of the biggest issues is usability/user experience: pull, fetch, checkout, commit, push, rebase - what is all this and what is the exact meaning? I need simple English terms for my work - like update and save - nothing more. Why do I need to worry about implementation details and terms? If I can not explain it to my wife, then I can not use it for binary documents which she needs to store in a repo... in this case Subversion is a better version-control-system for her documents... Just SVN Update/SVN Commit - nothing more to learn in Subversion...</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590643"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590643" href="https://news.ycombinator.com/vote?id=38590643&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Imagine an electronic engineer complaining about an oscilloscope being hard to use because he cannot explain what all those knobs do to his wife. We are professionals, our tools should be powerful for the advanced user, not beginner friendly.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38592853"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592853" href="https://news.ycombinator.com/vote?id=38592853&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>A tool can be both beginner friendly AND powerful for advanced users.<p>Speaking of your analogy, the role that most software developers fullfil is not an engineer wondering about the oscilloscope, but rather the construction worker installing electrical fixtures wondering why the cable clamp has such a weird interface. Both the oscilloscope engineer in an office and the worker doing the field work would benefit from having a simple and reliable tool fit for purpose of cable clamping.</p><p>There is certainly a need for competent and "proper" software engineering that require special tools and detailed training, but I would argue it's niche and filled by people who build the tools themselves.</p><p>IMO the largest share of developers today are doing brick-laying work (which of course takes skill, I am not underestimating it) and would benefit a lot from having simpler tools - they don't need to know how to use an oscilloscope at all.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38592755"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592755" href="https://news.ycombinator.com/vote?id=38592755&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Yes, but if the oscilloscope has some buttons that take out the entire companyâ€™s codebase if pressed wrong.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38592359"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592359" href="https://news.ycombinator.com/vote?id=38592359&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>There has been a lot of push to commoditize software engineering. Unfortunately that has resulted in a swarm of people who want developer salaries without the work or expertise.<p>Git definitely has some warts but you are right. It is an industry tool for expert, professional use. Some complexity is inherent to the problem of version control.</p><p>Learning how to use your tools is part of ANY trade.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38592963"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38592963" href="https://news.ycombinator.com/vote?id=38592963&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;It is an industry tool for expert, professional use.<p>If you were talking about things like Kubernetes, LLVM, Ghidra then I'd agree.</p><p>But no git. This is not some expert tool.</p><p>This tool's purpose is literally to manage your characters' history, that's it.</p><p>Git could be used by any other profession that deals with letters - article writers, book writers, etc, etc.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592193"><td></td></tr>
            <tr id="38592903"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38592903" href="https://news.ycombinator.com/vote?id=38592903&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;We are professionals, our tools should be powerful for the advanced user, not beginner friendly.<p>You can have both - powerful and user friendly.</p><p>This idea that engineer's tools must be a mess that is fine as long as enables to do something is idiotic.</p><p>The same argument was repeated whenever C or C++ vs Rust discussions were happening</p><p>"Just learn C and memory management (and all the quirks)"</p><p>"Just use this new language constructs and you're fine..."</p><p>and in reality we ended with a lot of CVEs - 70% in both Chrome and Windows were related to mem. issues.</p><p>There's absolutely no reason why git's CLI cannot be better than it currently is. Once again - there is no reason.</p><p>Proof? There are CLI wrappers or even GUIs like GitHub Desktop that make whole experience way better.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590330"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590330" href="https://news.ycombinator.com/vote?id=38590330&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>To be honest, I canâ€™t even imagine what you imagine â€œgit saveâ€  and â€œgit updateâ€ would even do in an alternate universe.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590396"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38590396" href="https://news.ycombinator.com/vote?id=38590396&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>This is funny because in PR oriented development I started treating commits in the same way as "save" in IDE,<p>it's just backup of current state with irrelevant commit message. Everything is described at the end of the work in PR's description and squash merged.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38592328"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38592328" href="https://news.ycombinator.com/vote?id=38592328&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Giant PRs that are squashed into one commit are an anti-pattern. Every commit should contain exactly one logical change AND a descriptive commit message.<p>Unfortunately a good chunk of the industry doesn't have the discipline to do this.</p><p>If you have ever worked in a project where there was discipline around committing, you know there is lots of value in doing so (rebasing becomes easier, you unlock the power of bisect, log is actually useful).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38591537"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38591537" href="https://news.ycombinator.com/vote?id=38591537&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>But then you can't use blame to look at the current code state. And it also becomes a nightmare to revert your changes.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38591486"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38591486" href="https://news.ycombinator.com/vote?id=38591486&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>when i started out with git i made an alias to immediately do "git add . &amp;&amp; git commit -m 'lazy' &amp;&amp; git push" to make it easy to always save my work and ensure its on the server too. git pull is easy enough to remember + type, but i could imagine just calling it update</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38591554"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38591554" href="https://news.ycombinator.com/vote?id=38591554&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I would imagine git save is commit, and update is pull?<p>I think they just want to replace some of the words with alternatives that <i>they</i> prefer. Because at some point someone is going to winge that update should be syncronise and not pull, and save should be push and therefore git is the worst.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590458"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590458" href="https://news.ycombinator.com/vote?id=38590458&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Then you might be better off with something like Subversion indeed.<p>Git is distributed, and that means you can't get away from push, pull and fetch, however you name them.</p><p>If want you want is a way to avoid making "New New Presentation FINAL 2", then pretty much all features of most source control systems are superfluous.</p><p>To me that doesn't mean Git needs fixing, it means it's definitely not the right tool for your job.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590478"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590478" href="https://news.ycombinator.com/vote?id=38590478&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>If the specific words used are the problem, using aliases is a straightforward way to fix them. If you do it for someone, it will break the possibility of searching for help online though.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38594482"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38594482" href="https://news.ycombinator.com/vote?id=38594482&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I think git has become the standard now. I used git as the reference point when I had to implement a custom version control system for a product .  Also many things can be built on top of git, like GitHub for instance</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38593062"><td></td></tr>
            <tr id="38593117"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593117" href="https://news.ycombinator.com/vote?id=38593117&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>My experience is that the power of any technology unfolds gradually - with git it's like okay let's master the commands for a single repository on a single server for a single user up to a certain level of adequacy.  Then (depending on need), let's add multiple repositories on the same single server for the same single user.  Then add multiple servers (including a git remote server).  Then add multiple users ... etc ... of course the magic of git is you can unfold those needs in any sequence.  Often when I find I do not understand something (that I thought I understood), I go back in scope to an earlier unfolding, eliminating other factors.<p>I'm sure git can be improved, but I think the biggest improvement comes from the user being improved with their understanding of the scope of capabilities.  I have yet to see a good tutorial on this (among the plethora of git tutorials out there).  This reminds me of the (excellent) video where the "Harvard Professor Explains Algorithms in 5 Levels of Difficulty" [1]</p><p>[1] <a href="https://www.youtube.com/watch?v=fkIvmfqX-t0" rel="nofollow noreferrer">https://www.youtube.com/watch?v=fkIvmfqX-t0</a></p><p>I would love to see a Channel where that is the entire theme - explaining everything in 5 levels of difficulty.</p><p>All this being said, at each of the "5 levels of difficulty" of git, are there improvements to be made.  I'm sure there are.  It would be good to focus the answer on each of those levels.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590467"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590467" href="https://news.ycombinator.com/vote?id=38590467&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>In my opinion the feature Git has always been missing is version control of branches. Of course the immediate consequence would be that you'd be able to roll back changes to branches but there'd be some more fundamental consequences as well. I'm pretty sure some of the problems with GUI's/wrappers around Git break down because there's no tracking of branches/tags.<p>Besides that it's pretty much endgame in my opinion if you consider only the functionality it's meant to solve. If another "better" VCS would ever become popular I feel it would have to be a drastic change to the way of working with VCS, even more drastic than SVN to Git was. There's some cruft in Git that could probably be taken away, and that would make Git better in a theoretical sense, but in the real world that would never happen (unless we get sideswiped by another industry or platform).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590511"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590511" href="https://news.ycombinator.com/vote?id=38590511&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Can you clarify what you mean by "version control of branches"? Branches in Git are just labels of objects. Are you talking about having a history of which objects a branch has previously labelled, like the reflog?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590569"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38590569" href="https://news.ycombinator.com/vote?id=38590569&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yeah, I feel the reflog is more of a tool to do introspection on a git repository than that is a tool for collaboration. It's just something I've felt was missing from Git. If you're looking at the main branch of a repository, what was the previous version of that branch?<p>The way we work around that missing feature is by tagging commits so we don't forget what revision a release was made at for example. A sequence of release tags basically is a meta branch, a history of the release branch, but managed manually instead of through git.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38592393"><td></td></tr>
                        <tr id="38590486"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590486" href="https://news.ycombinator.com/vote?id=38590486&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Locally thereâ€™s a kind of version control for branches in the â€œgit reflogâ€ where you can see how a branch alias has been moved</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38591708"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38591708" href="https://news.ycombinator.com/vote?id=38591708&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Yes we can. The shortcomings of git are that it doesn't handle binary files well, and you can't clone a slice of a repo. the system after git will handle both of those. mono repo or not is not a question with aftergit because you can clone just a subdir and work there, without the overhead of cloning the whole thing, but also without the weight of keeping up with commits happening outside of your directory.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38594976"><td></td></tr>
                  <tr id="38593443"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593443" href="https://news.ycombinator.com/vote?id=38593443&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Maybe there are certain domains where you could obviously do better. Take an artist wanting to version control images, i could imagine specialized tools that could be much better. For programming, there could be improvements for versioning groups of repositories that work together perhaps.<p>For standard needs, probably going to be difficult.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593672"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593672" href="https://news.ycombinator.com/vote?id=38593672&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>We've been working on a data version control system called "oxen" optimized for large unstructured datasets that we are seeing more and more with the advent of many of the generative AI techniques.<p>Many of these datasets have many many images, videos, audio files, text as well as structured tabular datasets that git or git-lfs just falls flat on.</p><p>Would love anyone to kick the tires on it and let us know what you think:</p><p><a href="https://github.com/Oxen-AI/oxen-release">https://github.com/Oxen-AI/oxen-release</a></p><p>The commands are mirrored after git so it is easy to learn, but optimized under the hood for larger datasets.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593898"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593898" href="https://news.ycombinator.com/vote?id=38593898&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Yes, I think that we can do better than plain text as the source of truth, and thus git would probably need to change.<p>There's work around a bunch of languages that are not based on text, some have their own editor or a tool to manage a canonical representation in text for you that would make them friendlier to git.</p><pre><code>  - https://github.com/yairchu/awesome-structure-editors/blob/main/README.md</code></pre></span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590425"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590425" href="https://news.ycombinator.com/vote?id=38590425&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>You could probably do better, yes. But if someone is to do better, I'd hope they actually learn git first.<p>A lot of alternative tools come up because of people writing them being unwilling to learn git. There are a handful of concepts and a few handfuls of commands and thats it.</p><p>And once someone learns git throroughly, they usually come to see that it is actually good enough, and dont bother making something new.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590443"><td></td></tr>
                  <tr id="38590377"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590377" href="https://news.ycombinator.com/vote?id=38590377&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I do believe that it is possible, at least at the API (cli) level.<p>While git is good under the hood, then it has not really user-friendly interface.</p><p>Also git heavily benefits from GitHub's success, which locks us with git :(</p><p>I wrote about it here <a href="https://trolololo.xyz/github" rel="nofollow noreferrer">https://trolololo.xyz/github</a> - GitHub is really good, but there's a small problem with that
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593902"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593902" href="https://news.ycombinator.com/vote?id=38593902&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Iâ€™ve worked with git since 2016. I guess I must not be a power user because beyond using like six got commands Iâ€™ve never had any issues or felt like man my workflow is interrupted.<p>What features do you think need to be improved? From a purely UX pov I think git is probably the best software Iâ€™ve used. It just works.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38594062"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38594062" href="https://news.ycombinator.com/vote?id=38594062&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I think the nomenclature could have been better, and less technical people would use it.  Calling it commit when itâ€™s essentially a save is good start . Yes I know it isnâ€™t exactly the same as saving but who cares.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590508"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590508" href="https://news.ycombinator.com/vote?id=38590508&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>There are already various ways in which mercurial or perforce are better than git, and big companies like Google and Meta have hacked on the systems they started with so much that one can hardly say theyâ€™re still perforce/hg. There can be disadvantages there but it seems obvious to me that better systems are possible. It feels to me like the real question is whether GitHub is the endgame.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590489"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590489" href="https://news.ycombinator.com/vote?id=38590489&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I think Git itself is probably too entrenched to be displaced by now, but I recently came across Graphite (<a href="https://graphite.dev/" rel="nofollow noreferrer">https://graphite.dev/</a>) and, while itâ€™s all still Git under the hood, it abstracts away many of the common pain points (stacking PRs, rebasing) and has nice integrations with GitHub and VS Code.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38590516"><td></td></tr>
                  <tr id="38593357"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593357" href="https://news.ycombinator.com/vote?id=38593357&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Really depends on "what".<p>I use a wiki which internally uses RCS, but you never see it. The only reason I even know is that I needed to scan older versions of some assets and it was straightforward compared to what you'd expect with Git. (Other bonus, attachments and meta pages are stored as actual files. With a little bit of code you can cobble together an automated page builder for e.g. physical assets.)</p><p>I consider rsync --link-dest a version control system.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590504"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590504" href="https://news.ycombinator.com/vote?id=38590504&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I more or less consider it a solved problem.<p>You're mostly going to hear from people here who are annoyed with Git or otherwise more interested in the topic of version control than the median developer. For me, I think it provides a quite robust and well thought-out set of primitives, and then composes them upwards in ways which are about as good as one can expect.</p><p>Some stuff obviously isn't well supported. Using the same Git repo to hold large binaries as well as source code is not well supported unless you reach for LFS - that's the biggest downside I see.</p><p>Fossil would be my next bet. I'm waiting for someone to make an archaeology.co to rival GitHub.com for it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593374"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593374" href="https://news.ycombinator.com/vote?id=38593374&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;I think it provides a quite robust and well thought-out set of primitives<p>The existence of the staging area is a poorly thought out part of the design. No other VCS uses it because it was a bad idea that makes the simple case of commuting changes more complicated.</p><p>&gt;Fossil would be my next bet. I'm waiting for someone to make an archaeology.co to rival GitHub.com for it.</p><p>Which is exactly why fossil will not be the next big VCS. Ignoring all of the projects on Github add forcing people to move to a less featureful, less integrated, less familial forge just to use a new source control system is a hard sell. The approach of Sapling and Jujutsu where they support the git protocol so that they can be used Github will make them much easier to adopt since it can happen incremenetally and it fully replace git for people.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38593977"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38593977" href="https://news.ycombinator.com/vote?id=38593977&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Git has problems but is mostly alright, cli aside.<p>Git as practiced by GitHub and gitlab is <i>awful</i> quite a lot of the time.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590480"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590480" href="https://news.ycombinator.com/vote?id=38590480&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Git is great for keeping track of logical history, but personally I find that it is missing tools for handling physical history. Reflog is a step in the right direction but it has a limited size and AFAIK it is not possible to share a reflog between clones. Which leaves "cp -r repo repo.backup" as the best option.<p>Of course, as long as you only do additive changes via commit/merge/revert, the logical history is equivalent to the physical history, but commands like rebase break this model. And despite the flaws of rebase workflows, sometimes it is the best option, like when maintaining a fork.</p><p>To my surprise Vim actually has something like this - logical history with undo/redo and physical history with g+/g-/:earlier/:later</p><p>Another thing I would like is some way to "fold" multiple small commits into one bigger one (for display purposes only) as it would let me split large diffs into minimal, self-contained commits while maintaining a reasonable git history.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590490"><td></td></tr>
                <tr id="38590559"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38590559" href="https://news.ycombinator.com/vote?id=38590559&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>The simple explanation:
Logical history - what you see when you do "git log --all".
Physical history - doing "git log --all" every time a repository updates and then storing each output as an entry into another history log. Kind of a "history of histories"<p>The complex explanation: a git repository at a particular time consists (mostly) of a graph of commits. This graph represents the logical history of code changes in the repository. The graph can be updated in an append-only fashion (using commit/merge/revert) or in a destructive way like with rebase and reset. The physical history is simply the history of the graph over time.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590885"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38590885" href="https://news.ycombinator.com/vote?id=38590885&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>in other words the history of the graph is the physical history<p>and the logical history is the filesets which are the nodes in the graph which is the branching sequence of commits</p><p>the issue is that the 'logical history' is the reason git was built</p><p>and the 'physical history', seems to me, is only feasible because we have the regular git sequence of commits
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="38594076"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38594076" href="https://news.ycombinator.com/vote?id=38594076&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>To me, "Could there be something better than git?" is not the important question.<p>What matters is if git is good enough.</p><p>Or more specifically, is if git good enough for X when X is something that is actually being done.</p><p>I mean, git is good enough for my very minimal needs and the needs of people with much more sophisticated needs than mine (e.g. the Linux team). And since I know more about git than any other VCS (in part because there are better resources for learning git than any other VCS) learning another VCS for the sake of learning another VCS wouldn't help me get anything done.</p><p>None of that means git is good enough for your needs, but statistically, it probably is good enough for your needs because statistically, most difficulties with git are related to training and knowledge since the mathematics underpinning git are (to the best of my understanding) sound.</p><p>Which also implies (not accidentally) that being better than git requires better resources for learning the new VCS than git has, and that's a very tall order.</p><p>Good luck.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38593071"><td></td></tr>
            <tr id="38590528"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590528" href="https://news.ycombinator.com/vote?id=38590528&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>git could be thousand of times more user-friendly,
but its too command-line centric, so workflow is
limited to complex "sub tool invocations".
GUIs for git exist but they add extreme overhead 
for simple workflows, perhaps some "standard web interface"  
 backend should be prioritized( Github is popular due their UI).
Another alternative is simplifying arcane command invocations,
i'd expect "git workflow_commandX file_target" instead
of tons of switches and parameters. There should be hundreds
of such "standard shortcut commands" to reduce mistakes.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590514"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590514" href="https://news.ycombinator.com/vote?id=38590514&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I'm not sure git is so bad that we need something different. It's certainly awkward at times, but it is also mostly a side-tool: not the thing you think of when you think of being a developer, yet every dev uses it.<p>I suspect most people use just a tiny subset of git day-to-day, and google the rest when it comes up.</p><p>For this reason, I think if git is replaced, it won't be because whatever comes along will be better objectively, it will be because a few reasons are touted that most people don't understand but are willing to repeat, and some momentum builds behind the alternative.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590187"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590187" href="https://news.ycombinator.com/vote?id=38590187&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Many tried, few succeded.
SVN - client-server principle, but bad at merging branches
mercurial - one of the competitors after the linix kernel devs searched a new version control system, its users die out, since git is more popular, very similar to git
bazaar - mostly used for ubuntu, since launchpad is only providing bazaar as vcs</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38592698"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592698" href="https://news.ycombinator.com/vote?id=38592698&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Launchpad added Git support years ago. Also, bzr pre-dates git by a tiny bit, too. But sadly git won.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592514"><td></td></tr>
                <tr id="38592830"><td></td></tr>
                <tr id="38593301"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38593301" href="https://news.ycombinator.com/vote?id=38593301&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>To clarify, jj is not derived from Mercurial, but it's heavily inspired by it. The current DVCS solution at Google (called Fig) is based on Mercurial, however. But we're hoping to replace it by jj.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38590456"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590456" href="https://news.ycombinator.com/vote?id=38590456&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>It would be hard to get past the network effects. Just like how we are stuck with SMTP, JavaScript, PDF, HTML, etc.<p>The only way I could see it changing is if we have a complete paradigm shift. This is what happened when we went from SVN to Git (centralised to distributed).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38592548"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38592548" href="https://news.ycombinator.com/vote?id=38592548&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>SVN is only 5 years older than git, and while git is distributed, people basically use it like it's a centralized VCS these days.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590501"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590501" href="https://news.ycombinator.com/vote?id=38590501&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>Something that is better should be able to track moves, not just store state. Moves of files and even partial content moved within (text) files. Unfortunately, that needs a tight coupling to the editor, so I doubt that's going to happen.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590238"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590238" href="https://news.ycombinator.com/vote?id=38590238&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I'm sure we can, the question is, can we make an alternative to GitHub?  I wouldn't be surprised if there are already several better ones, but I've never looked, because I already know Git, and my chances of convincing anyone to use a better one seem low, and they rarely seem to have as big of an ecosystem.<p>If it doesn't have multiple clouds providers with pull requests, and at least one of those clouds providers isn't a megacorp, it probably won't be the safe boring choice, unless it's fully P2P.</p><p>It needs to be packaged in distros,  have GUI integrations, etc.</p><p>Fossil looks really cool, I really like how they integrate the wikis and issues.  But I don't know anyone who uses it, and the cloud providers seem to be smaller "Could go away any time" companies.</p><p>I've never really explored any other VCSes, because none ever seem like they're going to be serious competitors.</p><p>I'd be more interested in enhancing Git, but it seems a lot of the most interesting git plugins and extensions aren't updated, like GitTorrent.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38594179"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38594179" href="https://news.ycombinator.com/vote?id=38594179&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Re: GitHub alternatives, I've been looking at this for a while as I'm keen to not have everything centralised and Microsoft are hardly the most trustworthy...<p>There are some GithHub-alikes, the most obvious is GitLab which you can also host yourself but all (or at least some of) the extras you get for free with GitHub are behind payment walls.</p><p>My current favourite is Codeberg, it uses Forgejo underneath (which is a fork of Gitea itself a fork of Gogs - all of which you can self host). Codeberg is run by a non-profit and are very much aligned with my ideals. They are also slowly adding nice features like their Woodpecker CI.</p><p>One that is growing in popularity and is a little less "GitHub-y" is SourceHut (which also has Mercurial support).</p><p>The main issue is that GitHub has really cornered the market. They give so much out for free that is difficult for others to compete with and it has become the de-facto place to host your project. This can mean that hosting anywhere other than GitHub will limit discoverability and contributions from people if they don't want to make an account or work out how to deal with whatever forge you are using.</p><p>However one thing that is coming that may help alleviate some of that is forge federation which will allow you to interact with various forges from your "home" forge - which hopefully prevents the need to make an account to make PRs or raise issues.</p><p>Edit: I see your other comment now, what could a better GitHub be that supports a better-than-git VCS. Well there did used to be places to host Darcs projects like the Darcs Hub but I don't know if some of the newers ones like Pijul or Jujutsu have any forge support yet.</p><p>Edit2: Oh it seems Pijul has "The Nest" for hosting.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590520"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590520" href="https://news.ycombinator.com/vote?id=38590520&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; the question is, can we make an alternative to GitHub? I wouldn't be surprised if there are already several better ones, but I've never looked, because I already know Git<p>Â¿Que?</p><p>If you're wondering whether we can make something better than GitHub, there's dozens of git hosting alternatives that you might like better such as Forgejo and GitLab.</p><p>If you're saying "but I already know git", then there's still dozens of alternative hosting sites or methods!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590587"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38590587" href="https://news.ycombinator.com/vote?id=38590587&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>GitHub is the one everyone else uses though, which means you can have everything in one place, so they have the advantage.<p>There are others that are <i>almost</i> as good, I suppose what I should have said is "Can we make something better than GitHub for the hypothetical better non-git VCS", since without that it's hard to imagine using anything but Git.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38591548"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38591548" href="https://news.ycombinator.com/vote?id=38591548&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Pretty sure alternative git services are still larger than alternative source control systems, yet OP is asking about alternatives to git which will be even smaller. The whole point is that the person wants to use something else. If your argument is that Microsoft GitHub is the largest and therefore the best, it's circular reasoning and will forever remain that way.<p>We should all stay on Facebook also if they're the best because everyone's on Facebook and the network effect has benefits; somehow it seems people have more sense than that and we can actually switch to smaller services which are more aligned with what we want
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="38590739"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590739" href="https://news.ycombinator.com/vote?id=38590739&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yes, but due to its simplicity + extensibility + widespread adoption, I wouldnâ€™t be surprised if weâ€™re still using Git 100+ years from now.<p>The current trend (most popular and IMO likely to succeed) is to make tools (â€œlayersâ€) which work on top of Git, like more intuitive UI/patterns (<a href="https://github.com/jesseduffield/lazygit">https://github.com/jesseduffield/lazygit</a>, <a href="https://github.com/arxanas/git-branchless">https://github.com/arxanas/git-branchless</a>) and smart merge resolvers (<a href="https://github.com/Symbolk/IntelliMerge">https://github.com/Symbolk/IntelliMerge</a>, <a href="https://docs.plasticscm.com/semanticmerge/how-to-configure/semanticmerge-configuration-guide#HowtoconfigurewithGit" rel="nofollow noreferrer">https://docs.plasticscm.com/semanticmerge/how-to-configure/s...</a>). Git it so flexible, even things that it handles terribly by default, it handles
fine with layers: e.g., large binary files via git-lfs (<a href="https://git-lfs.com/" rel="nofollow noreferrer">https://git-lfs.com</a>) and merge conflicts in non-textual files by custom merge resolvers like Unityâ€™s (<a href="https://flashg.github.io/GitMerge-for-Unity/" rel="nofollow noreferrer">https://flashg.github.io/GitMerge-for-Unity/</a>).</p><p>Perhaps in the future, almost everyone will keep using Git at the core, but have so many layers to make it more intuitive and provide better merges, that what theyâ€™re using barely resembles Git at all. This flexibility and the fact that nearly everything is designed for Git and integrates with Git, are why I doubt itâ€™s ever going away.</p><p>Some alternatives for thought:</p><p>- pijul (<a href="https://pijul.org/" rel="nofollow noreferrer">https://pijul.org</a>), a completely different VCS which allegedly has better merges/rebases. In beta, but I rarely hear about it nowadays and have heard more bad than good. I donâ€™t think we can implement this alternate rebases in Git, but maybe we donâ€™t need to; even after reading the website, I donâ€™t understand why pijulâ€™s merges are better, and in particular I canâ€™t think of a concrete example nor does pijul provide one.</p><p>- Unison (<a href="https://www.unison-lang.org/" rel="nofollow noreferrer">https://www.unison-lang.org</a>). This isnâ€™t a VCS, but a language with a radical approach to code representation: instead of code being text stored in files, code is ASTs referenced by hash and stored in essentially a database. Among other advantages, the main one is that you can rename symbols and they will automatically propagate to dependencies, because the symbols are referenced by their hash instead of their name. I believe this automatic renaming will be common in the future, whether itâ€™s implemented by a layer on top of Git or alternate code representation like Unison (to be clear, Unisonâ€™s codebases are designed to work with Git, and the Unison project itself is stored in Git repos).</p><p>- SVN, the other widespread VCS. Google or ask ChatGPT â€œGit vs SVNâ€ and youâ€™ll get answers like this (<a href="https://www.linode.com/docs/guides/svn-vs-git/" rel="nofollow noreferrer">https://www.linode.com/docs/guides/svn-vs-git/</a>, <a href="https://stackoverflow.com/a/875" rel="nofollow noreferrer">https://stackoverflow.com/a/875</a>). Basically, SVN is easier to understand and handles large files better, Git is decentralized and more popular. But what about the differences which canâ€™t be resolved by layers, like lazygit for intuition and git-lfs for large files? It seems to me like even companies with centralized private repositories use Git, meaning Git will probably win in the long term, but I donâ€™t work at those companies so I donâ€™t really know.</p><p>- Mercurial and Fossil, the other widespread VCSs. It seems these are more similar to Git and the main differences are in the low-level implementation (<a href="https://stackoverflow.com/a/892688" rel="nofollow noreferrer">https://stackoverflow.com/a/892688</a>, <a href="https://fossil-scm.org/home/doc/trunk/www/fossil-v-git.wiki#:~:text=Both%20Fossil%20and%20Git%20store,emphasis%20on%20the%20entire%20DAG" rel="nofollow noreferrer">https://fossil-scm.org/home/doc/trunk/www/fossil-v-git.wiki#...</a>.). It actually seems like most people prefer Mercurial and Fossil over Git and would use them if they had the same popularity, or at least if they had Gitâ€™s popularity and Git had Mercury or Fossilâ€™s. But again, these VCSs are so similar that with layers, you can probably create a Git experience which has their advantages and almost copies their UI.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593203"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593203" href="https://news.ycombinator.com/vote?id=38593203&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>The canonical example of a merge that is impossible via Git's `recursive` is a base of "AB" (where each character appears on a single line but I've omitted the newlines for brevity), branch 1 is one commit containing "AXB", and branch 2 which is a commit "GAB" followed by another commit "ABGAB". Then the recursive merge of the two branches into each other cannot tell which AB pair in branch 2 the X from branch 1 should be inserted into, because it never sees the first commit of branch 2 which tells you that the "original" AB is the one after the G. `recursive` cannot distinguish between "AXBGAB" and "ABGAXB" as possibilities. A merge algorithm which looks at every commit can know that "ABGAXB" is more faithful to the actual sequence of events, because it knows which AB pair the X was inserted into on branch 1.<p>(Another plausibly correct answer of course would be "AXBGAXB", but again `recursive` doesn't know enough to guess this answer.)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590450"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590450" href="https://news.ycombinator.com/vote?id=38590450&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yes. Here are areas where git sucks:<p>* UX, obviously.</p><p>* Large files (LFS is a not-very-good poorly integrated hack)</p><p>* Very large projects (big company codebases). Poor support for sparse/partial checkouts, stateful operations (e.g. git status still scans the whole repo every time on Linux), poor &amp; buggy support for submodules.</p><p>* Conflict resolution. It's about as basic as it can be. E.g. even zdiff3 doesn't give you quite enough information to resolve some conflicts (you want the diff for the change that introduced the conflict). The diff algorithms are all fast but dumb. Patch based VCS systems (Darcs, Pijul) are apparently better here.</p><p>IMO the most interesting projects that are trying to solve any of these (but not all of them sadly) are Jujitsu and Pijul.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590538"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590538" href="https://news.ycombinator.com/vote?id=38590538&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; The diff algorithms are all fast but dumb. Patch based VCS systems (Darcs, Pijul) are apparently better here.<p>Isnt one of git's core features that it can work as a patch based system?</p><p>It's my understanding (and please correct me if I'm wrong) that Linux patches can come in via mailing list, as a diff. That would make the person committing different from the owner of the change (also reflected in git's design)? Do Darcs and Pijul just have a string of patches on top of the original source file?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38591009"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38591009" href="https://news.ycombinator.com/vote?id=38591009&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Got can apply patches, yes. But I mean when it has two commits (which are snapshots, not patches) and it uses a diff algorithm to synthesise a patch between them.<p>It uses an algorithm which is great from a computer science point of view (low algorithmic complexity, minimal length, etc.) but pretty bad from a semantic point of view (splitting up blocks, etc.).</p><p>There are a couple of attempts to improve this (DiffSitter, Difftastic) but they don't integrate with GUIs yet.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38590382"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590382" href="https://news.ycombinator.com/vote?id=38590382&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Perforce.<p>As for DVCS, the best one I've used is Darcs: <a href="https://darcs.net/" rel="nofollow noreferrer">https://darcs.net/</a> There are some sticky wickets (specifically, exponential-time conflict resolution) that hindered its adoption.</p><p>Thankfully, there's Pijul, which is like Darcs but a) solves that problem; and b) is written in Rust! The perfect DVCS, probably! <a href="https://pijul.org/" rel="nofollow noreferrer">https://pijul.org/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590142"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590142" href="https://news.ycombinator.com/vote?id=38590142&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I personally think that Fossil is a good example that's extant and used in serious projects. There's that one called pijul which also looks good in theory, but I haven't worked with it. I think version control in general is a little broken before you even get to the software level, but those are two projects tackling some of the problems. And Fossil, I think, is more suited to the scale most people operate on.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38594093"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38594093" href="https://news.ycombinator.com/vote?id=38594093&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>I feel like git is poorly thought out. If a group of dedicated smart people set out to build a version control system, I doubt they would end up with git.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38591107"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38591107" href="https://news.ycombinator.com/vote?id=38591107&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; Or is it a solved problem and Git is the endgame of VCS<p>I've read so many comments to the effect that "X is a solved problem" when it clearly wasn't that I've come to conclude that the phrase means the opposite of its surface value...</p><p>I'm pretty sure that Git is not the end-of-line as far as VCSs go. Whether <i>I</i> will ever change my VCS, again, ever, that is an entirely different question. I've been through so many of them (RCS; a bit of CVS; a bit of Subversion which promised to be CVS-without-the-flaws, which it was not; Mercurial, because hey it was written in Python, so must be good, right? right?; <i>finally</i> Git; and of course the usual `report-v4-revision-good-one.doc` renaming game; plus a plethora of backup solutions, some really bad ones among them)â€”so <i>many</i> of them I'd be loathe to switch to yet another one, except <i>maybe</i> Fossil, which I almost did.</p><p>So yeah, I had totally forgotten about <a href="https://fossil-scm.org/" rel="nofollow noreferrer">https://fossil-scm.org</a> ; the reason it didn't become my go-to solution is probably mainly the fault of github.com, which I find too good to be ignored, and I don't want an 'impedance mismatch' between my system and their system. But maybe it would be doable and maybe Fossil is good enough to be worth it; at any rate, go read their docs, especially where they compare themselves directly to Git and give lots of good reasons for their way of doing things. This is the same people who are doing SQLite, so I'd say a trustworthy source of reliably top quality software.</p><p>Other than that, my personal way of dealing with the complexities of Git is to avoid using parts that I don't need or don't know about well enough (i.e. almost all of it). I use it to check in changes, give one line of comment, and upload to github.com; then of course cloning and updating existing repos as well as setting up a new ones is within my skill set. Branching and merging not so much. So it's like `git` plus `clone`, `add`, `commit`, `push`, that's all; also, I use Sublime Merge for part of these (reviewing changes, adding related changed chunks, commit) which I must recommend for the piece of fine software that it is.</p><p>I also at some point toyed with gitless (I think it was called) which promised to be Git, but simpler for the simple things and you can always fall back to Git proper where called for; this I find a good proposition that I like (Markdown: fall back to HTML; CoffeeScript: fall back to JavaScript) but somehow gitless didn't stick with me; I <i>guess</i> that's b/c I've already tempered down my usage of Git to a point near absolute zero, and command line history + Sublime Merge does the rest.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38593164"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593164" href="https://news.ycombinator.com/vote?id=38593164&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt;Mercurial, because hey it was written in Python, so must be good, right? right?;<p>Well, I can't really say that that's why, but yeah. Mercurial's pretty great.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38592826"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38592826" href="https://news.ycombinator.com/vote?id=38592826&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>Yes.<p>IMHO the next VCS model should follow a centralized-first, decentralized optional model. Which would be a flip of the decentralized-first model of git.</p><p>I also think GitHub is in a unique space to really innovate on git and itâ€™s a shame theyâ€™re not.</p><p>For example, I shouldnâ€™t need to make a fork to make a PR. Thatâ€™s absurd and the GitHub server should be able to apply ACLs based on the push identity.</p><p>Thereâ€™s a couple more of these suggestions I can think of, but yeah, GitHub should do more in this space.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590168"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590168" href="https://news.ycombinator.com/vote?id=38590168&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>git : version control :: vim : editors<p>There is definately scope for a beginner friendly UI/UX. Julia Evans has a post lately about confusing aspect of git. Ability to version control  large files (like git-lfs) would be a nice addition.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38590846"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590846" href="https://news.ycombinator.com/vote?id=38590846&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>The best feature of Git is that itâ€™s used virtually everywhere. I donâ€™t really care about anything else, I just know I wonâ€™t contribute to a repo if it doesnâ€™t use Git.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38590440"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590440" href="https://news.ycombinator.com/vote?id=38590440&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><br><div>
                  <p><span>No, git is perfectly fine. You just need to study it to master it, just like every other tool we use in our craft.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38593255"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38593255" href="https://news.ycombinator.com/vote?id=38593255&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>"Fine" is not "optimal". The mere fact that something does the job does not make it the best possible thing that does the job.<p>The most trivial example of a thing that is wrong with Git and which no amount of getting better with the tool can possibly help is "once you generate a conflict, you cannot perform any other versioning operations until you fix the conflict or revert". In particular, for example, you cannot commit a partial resolution of a conflict: you simply have to bail out and try and put your histories in a state that is more acceptable to the merge algorithms before trying again.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38590405"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38590405" href="https://news.ycombinator.com/vote?id=38590405&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>I am not sure if we will ever be able to replace git with anything else. It is so ubiquitous and just "good enough" for most developers, that the pain of switching to a completely new system would far outweight the benefits. Therefore the only solution that I see is a versioning system that is fully backward compatible with git, maybe just a better API layer on top of git. Facebook tried something similar with Sapling.<p>For a new versioning system we do not need twenty different choices. We need one  free, open, and solid solution that everybody uses.</p><p>What the main leaders of the industry should really is to found a groupo that defines that standard. This would be their chance to really make the world a (slightly)  better place.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38590434"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38590434" href="https://news.ycombinator.com/vote?id=38590434&amp;how=up&amp;goto=item%3Fid%3D38590080"></a></center>    </td><td><p><span>&gt; It is so ubiquitous<p>It wasn't until 2011 that Subversion dropped below 50% market share in the Eclipse Community Survey. Something new and shiny will come along and replace git.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux: Ext4 data corruption in 6.1.64-1 (203 pts)]]></title>
            <link>https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843</link>
            <guid>38589389</guid>
            <pubDate>Sun, 10 Dec 2023 05:33:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843">https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843</a>, See on <a href="https://news.ycombinator.com/item?id=38589389">Hacker News</a></p>
<div id="readability-page-1" class="page">
<h2>Debian Bug report logs - 
<a href="mailto:1057843@bugs.debian.org">#1057843</a><br>
linux: ext4 data corruption in 6.1.64-1</h2>
<p><a href="https://bugs.debian.org/cgi-bin/version.cgi?found=linux%2F6.1.64-1;absolute=0;info=1;package=src%3Alinux;fixed=linux%2F6.1.66-1;collapse=1"><img alt="version graph" src="https://bugs.debian.org/cgi-bin/version.cgi?found=linux%2F6.1.64-1;absolute=0;height=2;package=src%3Alinux;width=2;fixed=linux%2F6.1.66-1;collapse=1"></a></p>




<p><a href="mailto:1057843@bugs.debian.org">Reply</a> or <a href="mailto:1057843-subscribe@bugs.debian.org">subscribe</a> to this bug.</p>
<p>Toggle useless messages</p>

<div><hr><p>
<a name="1"></a>
<!-- request_addr: debian-bugs-dist@lists.debian.org, debian-release@lists.debian.org, carnil@debian.org, adsb@debian.org, Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt; -->
<!-- time:1702130943 -->
<strong>Report forwarded</strong>
to <code>debian-bugs-dist@lists.debian.org, debian-release@lists.debian.org, carnil@debian.org, adsb@debian.org, Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt;</code>:<br>
<code>Bug#1057843</code>; Package <code>src:linux</code>.
 (Sat, 09 Dec 2023 14:09:03 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=2">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=2">mbox</a>, <a href="#1">link</a>).</p></div>

<div><hr><p>
<a name="3"></a>
<!-- request_addr: Salvatore Bonaccorso &lt;carnil@debian.org&gt; -->
<!-- time:1702130943 -->
<strong>Acknowledgement sent</strong>
to <code>Salvatore Bonaccorso &lt;carnil@debian.org&gt;</code>:<br>
New Bug report received and forwarded.  Copy sent to <code>debian-release@lists.debian.org, carnil@debian.org, adsb@debian.org, Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt;</code>.
 (Sat, 09 Dec 2023 14:09:03 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=4">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=4">mbox</a>, <a href="#3">link</a>).</p></div>

<hr><p><a name="5"></a><a name="msg5"></a><a href="#5">Message #5</a> received at submit@bugs.debian.org (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=5">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=5">mbox</a>, <a href="mailto:1057843@bugs.debian.org?In-Reply-To=%3C170213085751.880636.15744973723197230632.reportbug%40eldamar.lan%3E&amp;subject=Re%3A%20linux%3A%20ext4%20data%20corruption%20in%206.1.64-1&amp;References=%3C170213085751.880636.15744973723197230632.reportbug%40eldamar.lan%3E&amp;body=On%20Sat%2C%2009%20Dec%202023%2015%3A07%3A37%20%2B0100%20Salvatore%20Bonaccorso%20%3Ccarnil%40debian.org%3E%20wrote%3A%0A%3E%20Source%3A%20linux%0A%3E%20Version%3A%206.1.64-1%0A%3E%20Severity%3A%20grave%0A%3E%20Tags%3A%20upstream%0A%3E%20Justification%3A%20causes%20non-serious%20data%20loss%0A%3E%20X-Debbugs-Cc%3A%20debian-release%40lists.debian.org%2C%20carnil%40debian.org%2C%20adsb%40debian.org%0A%3E%20%0A%3E%20Hi%0A%3E%20%0A%3E%20I%27m%20filling%20this%20for%20visibility.%0A%3E%20%0A%3E%20There%20might%20be%20a%20ext4%20data%20corruption%20issue%20with%20the%20kernel%20released%0A%3E%20in%20the%2012.3%20bookworm%20point%20release%20%28which%20is%20addressed%20in%206.1.66%0A%3E%20upstream%20already%29.%0A%3E%20%0A%3E%20The%20report%20about%20the%20regression%20and%20some%20details%3A%0A%3E%20%0A%3E%20https%3A%2F%2Flore.kernel.org%2Fstable%2F20231205122122.dfhhoaswsfscuhc3%40quack3%2F%0A%3E%20%0A%3E%20Regards%2C%0A%3E%20Salvatore%0A%3E%20%0A%3E%20%0A">reply</a>):</p>

<pre>Source: linux
Version: 6.1.64-1
Severity: grave
Tags: upstream
Justification: causes non-serious data loss
X-Debbugs-Cc: debian-release@lists.debian.org, carnil@debian.org, adsb@debian.org

Hi

I'm filling this for visibility.

There might be a ext4 data corruption issue with the kernel released
in the 12.3 bookworm point release (which is addressed in 6.1.66
upstream already).

The report about the regression and some details:

<a href="https://lore.kernel.org/stable/20231205122122.dfhhoaswsfscuhc3@quack3/">https://lore.kernel.org/stable/20231205122122.dfhhoaswsfscuhc3@quack3/</a>

Regards,
Salvatore


</pre>

<div><hr><p>
<a name="6"></a>
<!-- command:tag -->
<!-- requester: Salvatore Bonaccorso &lt;carnil@debian.org&gt; -->
<!-- request_addr: control@bugs.debian.org -->
<!-- time:1702132023 -->
<!-- new_data:
$new_data = {
              &#39;keywords&#39; =&gt; &#39;confirmed upstream&#39;
            };
-->
<!-- old_data:
$old_data = {
              &#39;keywords&#39; =&gt; &#39;upstream&#39;
            };
-->
<strong>Added tag(s) confirmed.</strong>
Request was from <code>Salvatore Bonaccorso &lt;carnil@debian.org&gt;</code>
to <code>control@bugs.debian.org</code>.
 (Sat, 09 Dec 2023 14:27:03 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=7">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=7">mbox</a>, <a href="#6">link</a>).</p></div>



<div><hr><p>
<a name="10"></a>
<!-- request_addr: debian-bugs-dist@lists.debian.org, Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt; -->
<!-- time:1702132562 -->
<strong>Information forwarded</strong>
to <code>debian-bugs-dist@lists.debian.org, Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt;</code>:<br>
<code>Bug#1057843</code>; Package <code>src:linux</code>.
 (Sat, 09 Dec 2023 14:36:02 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=11">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=11">mbox</a>, <a href="#10">link</a>).</p></div>

<div><hr><p>
<a name="12"></a>
<!-- request_addr: Salvatore Bonaccorso &lt;carnil@debian.org&gt; -->
<!-- time:1702132562 -->
<strong>Acknowledgement sent</strong>
to <code>Salvatore Bonaccorso &lt;carnil@debian.org&gt;</code>:<br>
Extra info received and forwarded to list.  Copy sent to <code>Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt;</code>.
 (Sat, 09 Dec 2023 14:36:02 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=13">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=13">mbox</a>, <a href="#12">link</a>).</p></div>

<hr><p><a name="14"></a><a name="msg14"></a><a href="#14">Message #14</a> received at 1057843@bugs.debian.org (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=14">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=14">mbox</a>, <a href="mailto:1057843@bugs.debian.org?In-Reply-To=%3CZXR6p7Ze8RwcC3Ax%40eldamar.lan%3E&amp;subject=Re%3A%20Bug%231057843%3A%20linux%3A%20ext4%20data%20corruption%20in%206.1.64-1&amp;References=%3C170213085751.880636.15744973723197230632.reportbug%40eldamar.lan%3E%0A%20%3CZXR6p7Ze8RwcC3Ax%40eldamar.lan%3E&amp;body=On%20Sat%2C%209%20Dec%202023%2015%3A33%3A11%20%2B0100%20Salvatore%20Bonaccorso%20%3Ccarnil%40debian.org%3E%20wrote%3A%0A%3E%20Running%20the%20single%20test%20with%20ext4%3A%0A%3E%20%0A%3E%20%23%20LTP_SINGLE_FS_TYPE%3Dext4%20LTP_DEV_FS_TYPE%3Dext4%20.%2Fpreadv03_64%0A%3E%20tst_device.c%3A96%3A%20TINFO%3A%20Found%20free%20device%200%20%27%2Fdev%2Floop0%27%0A%3E%20tst_test.c%3A1690%3A%20TINFO%3A%20LTP%20version%3A%2020230929-194-g5c096b2cf%0A%3E%20tst_test.c%3A1574%3A%20TINFO%3A%20Timeout%20per%20run%20is%200h%2000m%2030s%0A%3E%20tst_supported_fs_types.c%3A149%3A%20TINFO%3A%20WARNING%3A%20testing%20only%20ext4%0A%3E%20tst_supported_fs_types.c%3A90%3A%20TINFO%3A%20Kernel%20supports%20ext4%0A%3E%20tst_supported_fs_types.c%3A55%3A%20TINFO%3A%20mkfs.ext4%20does%20exist%0A%3E%20tst_test.c%3A1650%3A%20TINFO%3A%20%3D%3D%3D%20Testing%20on%20ext4%20%3D%3D%3D%0A%3E%20tst_test.c%3A1105%3A%20TINFO%3A%20Formatting%20%2Fdev%2Floop0%20with%20ext4%20opts%3D%27%27%20extra%20opts%3D%27%27%0A%3E%20mke2fs%201.47.0%20%285-Feb-2023%29%0A%3E%20tst_test.c%3A1119%3A%20TINFO%3A%20Mounting%20%2Fdev%2Floop0%20to%20%2Ftmp%2FLTP_preWBHd7l%2Fmntpoint%20fstyp%3Dext4%20flags%3D0%0A%3E%20preadv03.c%3A102%3A%20TINFO%3A%20Using%20block%20size%20512%0A%3E%20preadv03.c%3A77%3A%20TFAIL%3A%20Buffer%20wrong%20at%200%20have%2062%20expected%2061%0A%3E%20preadv03.c%3A77%3A%20TFAIL%3A%20Buffer%20wrong%20at%200%20have%2062%20expected%2061%0A%3E%20preadv03.c%3A66%3A%20TFAIL%3A%20preadv%28O_DIRECT%29%20read%200%20bytes%2C%20expected%20512%0A%3E%20%0A%3E%20Summary%3A%0A%3E%20passed%20%20%200%0A%3E%20failed%20%20%203%0A%3E%20broken%20%20%200%0A%3E%20skipped%20%200%0A%3E%20warnings%200%0A%3E%20%0A%3E%20%0A">reply</a>):</p>

<pre>Running the single test with ext4:

# LTP_SINGLE_FS_TYPE=ext4 LTP_DEV_FS_TYPE=ext4 ./preadv03_64
tst_device.c:96: TINFO: Found free device 0 '/dev/loop0'
tst_test.c:1690: TINFO: LTP version: 20230929-194-g5c096b2cf
tst_test.c:1574: TINFO: Timeout per run is 0h 00m 30s
tst_supported_fs_types.c:149: TINFO: WARNING: testing only ext4
tst_supported_fs_types.c:90: TINFO: Kernel supports ext4
tst_supported_fs_types.c:55: TINFO: mkfs.ext4 does exist
tst_test.c:1650: TINFO: === Testing on ext4 ===
tst_test.c:1105: TINFO: Formatting /dev/loop0 with ext4 opts='' extra opts=''
mke2fs 1.47.0 (5-Feb-2023)
tst_test.c:1119: TINFO: Mounting /dev/loop0 to /tmp/LTP_preWBHd7l/mntpoint fstyp=ext4 flags=0
preadv03.c:102: TINFO: Using block size 512
preadv03.c:77: TFAIL: Buffer wrong at 0 have 62 expected 61
preadv03.c:77: TFAIL: Buffer wrong at 0 have 62 expected 61
preadv03.c:66: TFAIL: preadv(O_DIRECT) read 0 bytes, expected 512

Summary:
passed   0
failed   3
broken   0
skipped  0
warnings 0


</pre>

<div><hr><p>
<a name="15"></a>
<!-- command:tag -->
<!-- requester: Salvatore Bonaccorso &lt;carnil@debian.org&gt; -->
<!-- request_addr: control@bugs.debian.org -->
<!-- time:1702132743 -->
<!-- new_data:
$new_data = {
              &#39;keywords&#39; =&gt; &#39;upstream fixed-upstream confirmed&#39;
            };
-->
<!-- old_data:
$old_data = {
              &#39;keywords&#39; =&gt; &#39;confirmed upstream&#39;
            };
-->
<strong>Added tag(s) fixed-upstream.</strong>
Request was from <code>Salvatore Bonaccorso &lt;carnil@debian.org&gt;</code>
to <code>control@bugs.debian.org</code>.
 (Sat, 09 Dec 2023 14:39:03 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=16">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=16">mbox</a>, <a href="#15">link</a>).</p></div>

<div><hr><p>
<a name="17"></a>
<!-- request_addr: debian-bugs-dist@lists.debian.org, Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt; -->
<!-- time:1702133822 -->
<strong>Information forwarded</strong>
to <code>debian-bugs-dist@lists.debian.org, Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt;</code>:<br>
<code>Bug#1057843</code>; Package <code>src:linux</code>.
 (Sat, 09 Dec 2023 14:57:02 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=18">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=18">mbox</a>, <a href="#17">link</a>).</p></div>

<div><hr><p>
<a name="19"></a>
<!-- request_addr: Salvatore Bonaccorso &lt;carnil@debian.org&gt; -->
<!-- time:1702133822 -->
<strong>Acknowledgement sent</strong>
to <code>Salvatore Bonaccorso &lt;carnil@debian.org&gt;</code>:<br>
Extra info received and forwarded to list.  Copy sent to <code>Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt;</code>.
 (Sat, 09 Dec 2023 14:57:02 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=20">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=20">mbox</a>, <a href="#19">link</a>).</p></div>

<hr><p><a name="21"></a><a name="msg21"></a><a href="#21">Message #21</a> received at 1057843@bugs.debian.org (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=21">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=21">mbox</a>, <a href="mailto:1057843@bugs.debian.org?body=On%20Sat%2C%209%20Dec%202023%2015%3A53%3A03%20%2B0100%20Salvatore%20Bonaccorso%20%3Ccarnil%40debian.org%3E%20wrote%3A%0A%3E%20Hi%2C%0A%3E%20%0A%3E%20On%20Sat%2C%20Dec%2009%2C%202023%20at%2003%3A07%3A37PM%20%2B0100%2C%20Salvatore%20Bonaccorso%20wrote%3A%0A%3E%20%3E%20Source%3A%20linux%0A%3E%20%3E%20Version%3A%206.1.64-1%0A%3E%20%3E%20Severity%3A%20grave%0A%3E%20%3E%20Tags%3A%20upstream%0A%3E%20%3E%20Justification%3A%20causes%20non-serious%20data%20loss%0A%3E%20%3E%20X-Debbugs-Cc%3A%20debian-release%40lists.debian.org%2C%20carnil%40debian.org%2C%20adsb%40debian.org%0A%3E%20%3E%20%0A%3E%20%3E%20Hi%0A%3E%20%3E%20%0A%3E%20%3E%20I%27m%20filling%20this%20for%20visibility.%0A%3E%20%3E%20%0A%3E%20%3E%20There%20might%20be%20a%20ext4%20data%20corruption%20issue%20with%20the%20kernel%20released%0A%3E%20%3E%20in%20the%2012.3%20bookworm%20point%20release%20%28which%20is%20addressed%20in%206.1.66%0A%3E%20%3E%20upstream%20already%29.%0A%3E%20%3E%20%0A%3E%20%3E%20The%20report%20about%20the%20regression%20and%20some%20details%3A%0A%3E%20%3E%20%0A%3E%20%3E%20https%3A%2F%2Flore.kernel.org%2Fstable%2F20231205122122.dfhhoaswsfscuhc3%40quack3%2F%0A%3E%20%0A%3E%206.1.66%20upstream%20fixes%20the%20issue%3A%0A%3E%20%0A%3E%20%23%20uname%20-a%0A%3E%20Linux%20bookworm-amd64%206.1.0-15-amd64%20%231%20SMP%20PREEMPT_DYNAMIC%20Debian%206.1.66-1%20%282023-12-06%29%20x86_64%20GNU%2FLinux%0A%3E%20%23%20LTP_SINGLE_FS_TYPE%3Dext4%20LTP_DEV_FS_TYPE%3Dext4%20.%2Fpreadv03_64%0A%3E%20tst_device.c%3A96%3A%20TINFO%3A%20Found%20free%20device%200%20%27%2Fdev%2Floop0%27%0A%3E%20tst_test.c%3A1690%3A%20TINFO%3A%20LTP%20version%3A%2020230929-194-g5c096b2cf%0A%3E%20tst_test.c%3A1574%3A%20TINFO%3A%20Timeout%20per%20run%20is%200h%2000m%2030s%0A%3E%20tst_supported_fs_types.c%3A149%3A%20TINFO%3A%20WARNING%3A%20testing%20only%20ext4%0A%3E%20tst_supported_fs_types.c%3A90%3A%20TINFO%3A%20Kernel%20supports%20ext4%0A%3E%20tst_supported_fs_types.c%3A55%3A%20TINFO%3A%20mkfs.ext4%20does%20exist%0A%3E%20tst_test.c%3A1650%3A%20TINFO%3A%20%3D%3D%3D%20Testing%20on%20ext4%20%3D%3D%3D%0A%3E%20tst_test.c%3A1105%3A%20TINFO%3A%20Formatting%20%2Fdev%2Floop0%20with%20ext4%20opts%3D%27%27%20extra%20opts%3D%27%27%0A%3E%20mke2fs%201.47.0%20%285-Feb-2023%29%0A%3E%20tst_test.c%3A1119%3A%20TINFO%3A%20Mounting%20%2Fdev%2Floop0%20to%20%2Ftmp%2FLTP_preGGYjTj%2Fmntpoint%20fstyp%3Dext4%20flags%3D0%0A%3E%20preadv03.c%3A102%3A%20TINFO%3A%20Using%20block%20size%20512%0A%3E%20preadv03.c%3A87%3A%20TPASS%3A%20preadv%28O_DIRECT%29%20read%20512%20bytes%20successfully%20with%20content%20%27a%27%20expectedly%0A%3E%20preadv03.c%3A87%3A%20TPASS%3A%20preadv%28O_DIRECT%29%20read%20512%20bytes%20successfully%20with%20content%20%27a%27%20expectedly%0A%3E%20preadv03.c%3A87%3A%20TPASS%3A%20preadv%28O_DIRECT%29%20read%20512%20bytes%20successfully%20with%20content%20%27b%27%20expectedly%0A%3E%20%0A%3E%20Summary%3A%0A%3E%20passed%20%20%203%0A%3E%20failed%20%20%200%0A%3E%20broken%20%20%200%0A%3E%20skipped%20%200%0A%3E%20warnings%200%0A%3E%20%0A%3E%20Regards%2C%0A%3E%20Salvatore%0A%3E%20%0A%3E%20%0A&amp;References=%3C170213085751.880636.15744973723197230632.reportbug%40eldamar.lan%3E%0A%20%3CZXR_TwLmkoTlM7Il%40eldamar.lan%3E&amp;subject=Re%3A%20Bug%231057843%3A%20linux%3A%20ext4%20data%20corruption%20in%206.1.64-1&amp;In-Reply-To=%3CZXR_TwLmkoTlM7Il%40eldamar.lan%3E">reply</a>):</p>

<pre>Hi,

On Sat, Dec 09, 2023 at 03:07:37PM +0100, Salvatore Bonaccorso wrote:
&gt; Source: linux
&gt; Version: 6.1.64-1
&gt; Severity: grave
&gt; Tags: upstream
&gt; Justification: causes non-serious data loss
&gt; X-Debbugs-Cc: debian-release@lists.debian.org, carnil@debian.org, adsb@debian.org
&gt; 
&gt; Hi
&gt; 
&gt; I'm filling this for visibility.
&gt; 
&gt; There might be a ext4 data corruption issue with the kernel released
&gt; in the 12.3 bookworm point release (which is addressed in 6.1.66
&gt; upstream already).
&gt; 
&gt; The report about the regression and some details:
&gt; 
&gt; <a href="https://lore.kernel.org/stable/20231205122122.dfhhoaswsfscuhc3@quack3/">https://lore.kernel.org/stable/20231205122122.dfhhoaswsfscuhc3@quack3/</a>

6.1.66 upstream fixes the issue:

# uname -a
Linux bookworm-amd64 6.1.0-15-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.66-1 (2023-12-06) x86_64 GNU/Linux
# LTP_SINGLE_FS_TYPE=ext4 LTP_DEV_FS_TYPE=ext4 ./preadv03_64
tst_device.c:96: TINFO: Found free device 0 '/dev/loop0'
tst_test.c:1690: TINFO: LTP version: 20230929-194-g5c096b2cf
tst_test.c:1574: TINFO: Timeout per run is 0h 00m 30s
tst_supported_fs_types.c:149: TINFO: WARNING: testing only ext4
tst_supported_fs_types.c:90: TINFO: Kernel supports ext4
tst_supported_fs_types.c:55: TINFO: mkfs.ext4 does exist
tst_test.c:1650: TINFO: === Testing on ext4 ===
tst_test.c:1105: TINFO: Formatting /dev/loop0 with ext4 opts='' extra opts=''
mke2fs 1.47.0 (5-Feb-2023)
tst_test.c:1119: TINFO: Mounting /dev/loop0 to /tmp/LTP_preGGYjTj/mntpoint fstyp=ext4 flags=0
preadv03.c:102: TINFO: Using block size 512
preadv03.c:87: TPASS: preadv(O_DIRECT) read 512 bytes successfully with content 'a' expectedly
preadv03.c:87: TPASS: preadv(O_DIRECT) read 512 bytes successfully with content 'a' expectedly
preadv03.c:87: TPASS: preadv(O_DIRECT) read 512 bytes successfully with content 'b' expectedly

Summary:
passed   3
failed   0
broken   0
skipped  0
warnings 0

Regards,
Salvatore


</pre>

<div><hr><p>
<a name="22"></a>
<!-- command:tag -->
<!-- requester: Salvatore Bonaccorso &lt;carnil@debian.org&gt; -->
<!-- request_addr: control@bugs.debian.org -->
<!-- time:1702139223 -->
<!-- new_data:
$new_data = {
              &#39;keywords&#39; =&gt; &#39;upstream confirmed pending fixed-upstream&#39;
            };
-->
<!-- old_data:
$old_data = {
              &#39;keywords&#39; =&gt; &#39;upstream fixed-upstream confirmed&#39;
            };
-->
<strong>Added tag(s) pending.</strong>
Request was from <code>Salvatore Bonaccorso &lt;carnil@debian.org&gt;</code>
to <code>control@bugs.debian.org</code>.
 (Sat, 09 Dec 2023 16:27:03 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=23">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=23">mbox</a>, <a href="#22">link</a>).</p></div>

<div><hr><p>
<a name="24"></a>
<!-- request_addr: Salvatore Bonaccorso &lt;carnil@debian.org&gt; -->
<!-- time:1702144808 -->
<strong>Reply sent</strong>
to <code>Salvatore Bonaccorso &lt;carnil@debian.org&gt;</code>:<br>
You have taken responsibility.
 (Sat, 09 Dec 2023 18:00:08 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=25">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=25">mbox</a>, <a href="#24">link</a>).</p></div>

<div><hr><p>
<a name="26"></a>
<!-- request_addr: Salvatore Bonaccorso &lt;carnil@debian.org&gt; -->
<!-- time:1702144808 -->
<strong>Notification sent</strong>
to <code>Salvatore Bonaccorso &lt;carnil@debian.org&gt;</code>:<br>
Bug acknowledged by developer.
 (Sat, 09 Dec 2023 18:00:08 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=27">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=27">mbox</a>, <a href="#26">link</a>).</p></div>

<hr><p><a name="28"></a><a name="msg28"></a><a href="#28">Message #28</a> received at 1057843-close@bugs.debian.org (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=28">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=28">mbox</a>, <a href="mailto:1057843@bugs.debian.org?body=On%20Sat%2C%2009%20Dec%202023%2017%3A56%3A32%20%2B0000%20Debian%20FTP%20Masters%20%3Cftpmaster%40ftp-master.debian.org%3E%20wrote%3A%0A%3E%20Source%3A%20linux%0A%3E%20Source-Version%3A%206.1.66-1%0A%3E%20Done%3A%20Salvatore%20Bonaccorso%20%3Ccarnil%40debian.org%3E%0A%3E%20%0A%3E%20We%20believe%20that%20the%20bug%20you%20reported%20is%20fixed%20in%20the%20latest%20version%20of%0A%3E%20linux%2C%20which%20is%20due%20to%20be%20installed%20in%20the%20Debian%20FTP%20archive.%0A%3E%20%0A%3E%20A%20summary%20of%20the%20changes%20between%20this%20version%20and%20the%20previous%20one%20is%0A%3E%20attached.%0A%3E%20%0A%3E%20Thank%20you%20for%20reporting%20the%20bug%2C%20which%20will%20now%20be%20closed.%20%20If%20you%0A%3E%20have%20further%20comments%20please%20address%20them%20to%201057843%40bugs.debian.org%2C%0A%3E%20and%20the%20maintainer%20will%20reopen%20the%20bug%20report%20if%20appropriate.%0A%3E%20%0A%3E%20Debian%20distribution%20maintenance%20software%0A%3E%20pp.%0A%3E%20Salvatore%20Bonaccorso%20%3Ccarnil%40debian.org%3E%20%28supplier%20of%20updated%20linux%20package%29%0A%3E%20%0A%3E%20%28This%20message%20was%20generated%20automatically%20at%20their%20request%3B%20if%20you%0A%3E%20believe%20that%20there%20is%20a%20problem%20with%20it%20please%20contact%20the%20archive%0A%3E%20administrators%20by%20mailing%20ftpmaster%40ftp-master.debian.org%29%0A%3E%20%0A%3E%20%0A%3E%20-----BEGIN%20PGP%20SIGNED%20MESSAGE-----%0A%3E%20Hash%3A%20SHA512%0A%3E%20%0A%3E%20Format%3A%201.8%0A%3E%20Date%3A%20Sat%2C%2009%20Dec%202023%2016%3A48%3A39%20%2B0100%0A%3E%20Source%3A%20linux%0A%3E%20Architecture%3A%20source%0A%3E%20Version%3A%206.1.66-1%0A%3E%20Distribution%3A%20bookworm%0A%3E%20Urgency%3A%20medium%0A%3E%20Maintainer%3A%20Debian%20Kernel%20Team%20%3Cdebian-kernel%40lists.debian.org%3E%0A%3E%20Changed-By%3A%20Salvatore%20Bonaccorso%20%3Ccarnil%40debian.org%3E%0A%3E%20Closes%3A%201032104%201057790%201057843%0A%3E%20Changes%3A%0A%3E%20%20linux%20%286.1.66-1%29%20bookworm%3B%20urgency%3Dmedium%0A%3E%20%20.%0A%3E%20%20%20%20%2A%20New%20upstream%20stable%20update%3A%0A%3E%20%20%20%20%20%20https%3A%2F%2Fwww.kernel.org%2Fpub%2Flinux%2Fkernel%2Fv6.x%2FChangeLog-6.1.65%0A%3E%20%20%20%20%20%20-%20afs%3A%20Fix%20afs_server_list%20to%20be%20cleaned%20up%20with%20RCU%0A%3E%20%20%20%20%20%20-%20afs%3A%20Make%20error%20on%20cell%20lookup%20failure%20consistent%20with%20OpenAFS%0A%3E%20%20%20%20%20%20-%20%5Barm64%2Carmhf%5D%20drm%2Fpanel%3A%20simple%3A%20Fix%20Innolux%20G101ICE-L01%20bus%20flags%0A%3E%20%20%20%20%20%20-%20%5Barm64%2Carmhf%5D%20drm%2Fpanel%3A%20simple%3A%20Fix%20Innolux%20G101ICE-L01%20timings%0A%3E%20%20%20%20%20%20-%20wireguard%3A%20use%20DEV_STATS_INC%28%29%0A%3E%20%20%20%20%20%20-%20ata%3A%20pata_isapnp%3A%20Add%20missing%20error%20check%20for%20devm_ioport_map%28%29%0A%3E%20%20%20%20%20%20-%20%5Bx86%5D%20drm%2Fi915%3A%20do%20not%20clean%20GT%20table%20on%20error%20path%0A%3E%20%20%20%20%20%20-%20%5Barm64%2Carmhf%5D%20drm%2Frockchip%3A%20vop%3A%20Fix%20color%20for%20RGB888%2FBGR888%20format%20on%20VOP%0A%3E%20%20%20%20%20%20%20%20full%0A%3E%20%20%20%20%20%20-%20HID%3A%20fix%20HID%20device%20resource%20race%20between%20HID%20core%20and%20debugging%20support%0A%3E%20%20%20%20%20%20-%20ipv4%3A%20Correct%2Fsilence%20an%20endian%20warning%20in%20__ip_do_redirect%0A%3E%20%20%20%20%20%20-%20net%3A%20usb%3A%20ax88179_178a%3A%20fix%20failed%20operations%20during%20ax88179_reset%0A%3E%20%20%20%20%20%20-%20net%2Fsmc%3A%20avoid%20data%20corruption%20caused%20by%20decline%0A%3E%20%20%20%20%20%20-%20%5Barmhf%5D%20arm%2Fxen%3A%20fix%20xen_vcpu_info%20allocation%20alignment%0A%3E%20%20%20%20%20%20-%20%5Bamd64%2Carm64%5D%20amd-xgbe%3A%20handle%20corner-case%20during%20sfp%20hotplug%0A%3E%20%20%20%20%20%20-%20%5Bamd64%2Carm64%5D%20amd-xgbe%3A%20handle%20the%20corner-case%20during%20tx%20completion%0A%3E%20%20%20%20%20%20-%20%5Bamd64%2Carm64%5D%20amd-xgbe%3A%20propagate%20the%20correct%20speed%20and%20duplex%20status%0A%3E%20%20%20%20%20%20-%20afs%3A%20Return%20ENOENT%20if%20no%20cell%20DNS%20record%20can%20be%20found%0A%3E%20%20%20%20%20%20-%20afs%3A%20Fix%20file%20locking%20on%20R%2FO%20volumes%20to%20operate%20in%20local%20mode%0A&amp;In-Reply-To=%3CE1rC1Z2-0039fW-ST%40fasolo.debian.org%3E&amp;References=%3CE1rC1Z2-0039fW-ST%40fasolo.debian.org%3E&amp;subject=Re%3A%20Bug%231057843%3A%20fixed%20in%20linux%206.1.66-1">reply</a>):</p>

<pre>Source: linux
Source-Version: 6.1.66-1
Done: Salvatore Bonaccorso &lt;carnil@debian.org&gt;

We believe that the bug you reported is fixed in the latest version of
linux, which is due to be installed in the Debian FTP archive.

A summary of the changes between this version and the previous one is
attached.

Thank you for reporting the bug, which will now be closed.  If you
have further comments please address them to 1057843@bugs.debian.org,
and the maintainer will reopen the bug report if appropriate.

Debian distribution maintenance software
pp.
Salvatore Bonaccorso &lt;carnil@debian.org&gt; (supplier of updated linux package)

(This message was generated automatically at their request; if you
believe that there is a problem with it please contact the archive
administrators by mailing ftpmaster@ftp-master.debian.org)


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

Format: 1.8
Date: Sat, 09 Dec 2023 16:48:39 +0100
Source: linux
Architecture: source
Version: 6.1.66-1
Distribution: bookworm
Urgency: medium
Maintainer: Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt;
Changed-By: Salvatore Bonaccorso &lt;carnil@debian.org&gt;
Closes: <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1032104">1032104</a> <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057790">1057790</a> <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843">1057843</a>
Changes:
 linux (6.1.66-1) bookworm; urgency=medium
 .
   * New upstream stable update:
     <a href="https://www.kernel.org/pub/linux/kernel/v6.x/ChangeLog-6.1.65">https://www.kernel.org/pub/linux/kernel/v6.x/ChangeLog-6.1.65</a>
     - afs: Fix afs_server_list to be cleaned up with RCU
     - afs: Make error on cell lookup failure consistent with OpenAFS
     - [arm64,armhf] drm/panel: simple: Fix Innolux G101ICE-L01 bus flags
     - [arm64,armhf] drm/panel: simple: Fix Innolux G101ICE-L01 timings
     - wireguard: use DEV_STATS_INC()
     - ata: pata_isapnp: Add missing error check for devm_ioport_map()
     - [x86] drm/i915: do not clean GT table on error path
     - [arm64,armhf] drm/rockchip: vop: Fix color for RGB888/BGR888 format on VOP
       full
     - HID: fix HID device resource race between HID core and debugging support
     - ipv4: Correct/silence an endian warning in __ip_do_redirect
     - net: usb: ax88179_178a: fix failed operations during ax88179_reset
     - net/smc: avoid data corruption caused by decline
     - [armhf] arm/xen: fix xen_vcpu_info allocation alignment
     - [amd64,arm64] amd-xgbe: handle corner-case during sfp hotplug
     - [amd64,arm64] amd-xgbe: handle the corner-case during tx completion
     - [amd64,arm64] amd-xgbe: propagate the correct speed and duplex status
     - afs: Return ENOENT if no cell DNS record can be found
     - afs: Fix file locking on R/O volumes to operate in local mode
     - mm,kfence: decouple kfence from page granularity mapping judgement
     - i40e: use ERR_PTR error print in i40e messages
     - i40e: Fix adding unsupported cloud filters
     - [arm64] USB: dwc3: qcom: fix resource leaks on probe deferral
     - [arm64] USB: dwc3: qcom: fix ACPI platform device leak
     - lockdep: Fix block chain corruption
     - cifs: minor cleanup of some headers
     - smb3: allow dumping session and tcon id to improve stats analysis and
       debugging
     - cifs: print last update time for interface list
     - cifs: distribute channels across interfaces based on speed
     - cifs: account for primary channel in the interface list
     - cifs: fix leak of iface for primary channel
     - ext4: add a new helper to check if es must be kept
     - ext4: factor out __es_alloc_extent() and __es_free_extent()
     - ext4: use pre-allocated es in __es_insert_extent()
     - ext4: use pre-allocated es in __es_remove_extent()
     - ext4: using nofail preallocation in ext4_es_remove_extent()
     - ext4: using nofail preallocation in ext4_es_insert_delayed_block()
     - ext4: using nofail preallocation in ext4_es_insert_extent()
     - ext4: fix slab-use-after-free in ext4_es_insert_extent()
     - ext4: make sure allocate pending entry not fail
     - NFSD: Fix "start of NFS reply" pointer passed to nfsd_cache_update()
     - NFSD: Fix checksum mismatches in the duplicate reply cache
     - ACPI: resource: Skip IRQ override on ASUS ExpertBook B1402CVA
     - swiotlb-xen: provide the "max_mapping_size" method
     - bcache: replace a mistaken IS_ERR() by IS_ERR_OR_NULL() in
       btree_gc_coalesce()
     - md: fix bi_status reporting in md_end_clone_io
     - bcache: fixup multi-threaded bch_sectors_dirty_init() wake-up race
     - io_uring/fs: consider link-&gt;flags when getting path for LINKAT
     - [s390x] dasd: protect device queue against concurrent access
     - USB: serial: option: add Luat Air72*U series products
     - hv_netvsc: fix race of netvsc and VF register_netdevice
     - hv_netvsc: Fix race of register_netdevice_notifier and VF register
     - hv_netvsc: Mark VF as slave before exposing it to user-mode
     - dm-delay: fix a race between delay_presuspend and delay_bio
     - bcache: check return value from btree_node_alloc_replacement()
     - bcache: prevent potential division by zero error
     - bcache: fixup init dirty data errors
     - bcache: fixup lock c-&gt;root error
     - USB: serial: option: add Fibocom L7xx modules
     - USB: serial: option: fix FM101R-GL defines
     - USB: serial: option: don't claim interface 4 for ZTE MF290
     - usb: typec: tcpm: Skip hard reset when in error recovery
     - [arm64,armhf] USB: dwc2: write HCINT with INTMASK applied
     - [arm64,armhf] usb: dwc3: Fix default mode initialization
     - [arm64,armhf] usb: dwc3: set the dma max_seg_size
     - [arm64] USB: dwc3: qcom: fix software node leak on probe errors
     - [arm64] USB: dwc3: qcom: fix wakeup after probe deferral
     - io_uring: fix off-by one bvec index
     <a href="https://www.kernel.org/pub/linux/kernel/v6.x/ChangeLog-6.1.66">https://www.kernel.org/pub/linux/kernel/v6.x/ChangeLog-6.1.66</a>
     - cifs: Fix FALLOC_FL_ZERO_RANGE by setting i_size if EOF moved
     - cifs: Fix FALLOC_FL_INSERT_RANGE by setting i_size after EOF moved
     - smb: client: report correct st_size for SMB and NFS symlinks
     - pinctrl: avoid reload of p state in list iteration
     - firewire: core: fix possible memory leak in create_units()
     - mmc: sdhci-pci-gli: Disable LPM during initialization
     - mmc: cqhci: Increase recovery halt timeout
     - mmc: cqhci: Warn of halt or task clear failure
     - mmc: cqhci: Fix task clearing in CQE error recovery
     - mmc: block: Retry commands in CQE error recovery
     - mmc: block: Do not lose cache flush during CQE error recovery
     - mmc: block: Be sure to wait while busy in CQE error recovery
     - ALSA: hda: Disable power-save on KONTRON SinglePC
     - ALSA: hda/realtek: Headset Mic VREF to 100%
     - ALSA: hda/realtek: Add supported ALC257 for ChromeOS
     - dm-verity: align struct dm_verity_fec_io properly
     - scsi: Change SCSI device boolean fields to single bit flags
     - scsi: sd: Fix system start for ATA devices
     - drm/amd: Enable PCIe PME from D3
     - drm/amdgpu: Force order between a read and write to the same address
     - drm/amd/display: Include udelay when waiting for INBOX0 ACK
     - drm/amd/display: Remove min_dst_y_next_start check for Z8
     - drm/amd/display: Use DRAM speed from validation for dummy p-state
     - drm/amd/display: Update min Z8 residency time to 2100 for DCN314
     - drm/amd/display: fix ABM disablement
     - dm verity: initialize fec io before freeing it
     - dm verity: don't perform FEC for failed readahead IO
     - nvme: check for valid nvme_identify_ns() before using it
     - [x86] cpufreq/amd-pstate: Fix the return value of amd_pstate_fast_switch()
     - dma-buf: fix check in dma_resv_add_fence
     - bcache: revert replacing IS_ERR_OR_NULL with IS_ERR
     - [amd64] iommu/vt-d: Add MTL to quirk list to skip TE disabling
     - [powerpc*] KVM: PPC: Book3S HV: Fix KVM_RUN clobbering FP/VEC user
       registers
     - [powerpc*] Don't clobber f0/vs0 during fp|altivec register save
       (Closes: #<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1032104">1032104</a>)
     - btrfs: add dmesg output for first mount and last unmount of a filesystem
     - btrfs: ref-verify: fix memory leaks in btrfs_ref_tree_mod()
     - btrfs: fix off-by-one when checking chunk map includes logical address
     - btrfs: send: ensure send_fd is writable
     - btrfs: make error messages more clear when getting a chunk map
     - btrfs: fix 64bit compat send ioctl arguments not initializing version
       member
     - Input: xpad - add HyperX Clutch Gladiate Support
     - wifi: cfg80211: fix CQM for non-range use
     - [arm64,armhf] USB: xhci-plat: fix legacy PHY double init
     - USB: core: Change configuration warnings to notices
     - usb: config: fix iteration issue in 'usb_get_bos_descriptor()'
     - ipv4: igmp: fix refcnt uaf issue when receiving igmp query packet
     - [arm64] dpaa2-eth: increase the needed headroom to account for alignment
     - net: stmmac: xgmac: Disable FPE MMC interrupts
     - r8169: prevent potential deadlock in rtl8169_close
     - [x86] KVM: x86: Fix lapic timer interrupt lost after loading a snapshot.
     - PCI: Lengthen reset delay for VideoPropulsion Torrent QN16e card
     - spi: Fix null dereference on suspend
     - drm/amd/display: Restore rptr/wptr for DMCUB as workaround
     - drm/amd/display: Guard against invalid RPTR/WPTR being set
     - [armhf] cpufreq: imx6q: don't warn for disabling a non-existing frequency
     - [armhf] cpufreq: imx6q: Don't disable 792 Mhz OPP unnecessarily
     - [amd64] iommu/vt-d: Omit devTLB invalidation requests when TES=0
     - [amd64] iommu/vt-d: Allocate pasid table in device probe path
     - [amd64] iommu/vt-d: Add device_block_translation() helper
     - [amd64] iommu/vt-d: Disable PCI ATS in legacy passthrough mode
     - [amd64] iommu/vt-d: Make context clearing consistent with context mapping
     - drm/amd/pm: fix a memleak in aldebaran_tables_init
     - mmc: core: add helpers mmc_regulator_enable/disable_vqmmc
     - mmc: sdhci-sprd: Fix vqmmc not shutting down after the card was pulled
     - drm/amd/display: Expand kernel doc for DC
     - drm/amd/display: clean code-style issues in dcn30_set_mpc_shaper_3dlut
     - drm/amd/display: Fix the delta clamping for shaper LUT
     - drm/amd/display: Fix MPCC 1DLUT programming
     - r8169: disable ASPM in case of tx timeout
     - r8169: fix deadlock on RTL8125 in jumbo mtu mode (Closes: #<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057790">1057790</a>)
     - xen: Allow platform PCI interrupt to be shared
     - xen: simplify evtchn_do_upcall() call maze
     - [x86] xen: fix percpu vcpu_info allocation
     - [x86] apic/msi: Fix misconfigured non-maskable MSI quirk
     - iomap: update ki_pos a little later in iomap_dio_complete
       (Closes: #<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843">1057843</a>)
 .
   [ Salvatore Bonaccorso ]
   * Bump ABI to 15
   * [rt] Update to 6.1.66-rt19
Checksums-Sha1:
 75d087cfc109545360cb85628ca2068a656f58bf 290924 linux_6.1.66-1.dsc
 bec397772676a6f06e2fde4c2328bcdc0beaea06 137491816 linux_6.1.66.orig.tar.xz
 af301e107224490faeda530343f96f17c0684f71 1580256 linux_6.1.66-1.debian.tar.xz
 348664cfbc75b567cf6256557f0c3d09fc8f7997 7065 linux_6.1.66-1_source.buildinfo
Checksums-Sha256:
 769e7dae9fe82bc29b55eb606fda6b0cc6221294a2ba3d7e7fcc78de84683f61 290924 linux_6.1.66-1.dsc
 71edfafca7cd8eaae26a8d29c1091bd39cfc2d196de38570b159c94f0d3e1ad5 137491816 linux_6.1.66.orig.tar.xz
 907af29ab9ff38594df378ba5c60619110389b92ba2a09a21adc0382f76e0240 1580256 linux_6.1.66-1.debian.tar.xz
 342dddfc2e87c8e8211e130e19253e23c1f5952036f29b4c9a7f9273c074d94a 7065 linux_6.1.66-1_source.buildinfo
Files:
 505a701b509c26df837dc4a6ff0f0844 290924 kernel optional linux_6.1.66-1.dsc
 ea8af00da46c0f6392324e83554102a2 137491816 kernel optional linux_6.1.66.orig.tar.xz
 307f584ef754457e172ad498979cba6c 1580256 kernel optional linux_6.1.66-1.debian.tar.xz
 2f1f205c788b2a730a7e7a89145dbf7d 7065 kernel optional linux_6.1.66-1_source.buildinfo

-----BEGIN PGP SIGNATURE-----

iQKmBAEBCgCQFiEERkRAmAjBceBVMd3uBUy48xNDz0QFAmV0kZ5fFIAAAAAALgAo
aXNzdWVyLWZwckBub3RhdGlvbnMub3BlbnBncC5maWZ0aGhvcnNlbWFuLm5ldDQ2
NDQ0MDk4MDhDMTcxRTA1NTMxRERFRTA1NENCOEYzMTM0M0NGNDQSHGNhcm5pbEBk
ZWJpYW4ub3JnAAoJEAVMuPMTQ89ErmUP/RZZN1ZMRy2nqQWPqXDrMUci6fOWcUCj
ZPAH/B9D9/+FYyRylJz8NENzJj82ZfNAUdKNMG0odp85pe6UOwvi6qMVIrsM3UrB
AQEbzEA0CS8XSTD2qdmOe2EaWHi0LvnopIQRGFy5Z3auQOk+EADbibRi2qZjM0Te
+Y1++jfXXLjbY5o+2oJMzaxZLBYRBcQizWfRKWjX4tmwcAZppABFShB5XEBlbeKx
8TZ6HhacpW3UImc1CTi8wFeO3T27bn4HQ9mLeW5vLh8bzbB3wnzmFzOn2wJj8Qf8
lRe6+oolFewZ57hBJjvDoK4CwQ9hapwPMJpAaG1NpE4QXIAAapb3OD5DP8vpsoTQ
bORrs3kvDRCA1ooCmGaEW7JBlolLl/mMxrIR4yGMzkXnA37UmAJ/PfmAJJO81J+H
cAhHdicTGrs6KQfNBBQzHC9vBJZNJ3Z5PpAXUncGQUDRueEz9kJXdwzZDkOf5DCC
JHrBXn7EZQLANXTeCg0za6/29VwURbSmUWXLk914sHb4xEPO/ivOpZAT8baB0JTV
hF8J6rzTyqsbv7gOFgOgrCCCvh5XU9Nvl7W3mRIHwiCdBKr39goL2V1S08kt0bmS
RLW+46T5U3Flcr5UGoIoEoBsav16aaHfaQ7mx182GGoAJqUf6tM4PuC4mDt1W4pQ
4o6djxs85N9S
=gQo4
-----END PGP SIGNATURE-----



</pre>

<div><hr><p>
<a name="29"></a>
<!-- request_addr: debian-bugs-dist@lists.debian.org, Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt; -->
<!-- time:1702195205 -->
<strong>Information forwarded</strong>
to <code>debian-bugs-dist@lists.debian.org, Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt;</code>:<br>
<code>Bug#1057843</code>; Package <code>src:linux</code>.
 (Sun, 10 Dec 2023 08:00:05 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=30">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=30">mbox</a>, <a href="#29">link</a>).</p></div>

<div><hr><p>
<a name="31"></a>
<!-- request_addr: Stephan VerbÃ¼cheln &lt;verbuecheln@posteo.de&gt; -->
<!-- time:1702195205 -->
<strong>Acknowledgement sent</strong>
to <code>Stephan VerbÃ¼cheln &lt;verbuecheln@posteo.de&gt;</code>:<br>
Extra info received and forwarded to list.  Copy sent to <code>Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt;</code>.
 (Sun, 10 Dec 2023 08:00:05 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=32">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=32">mbox</a>, <a href="#31">link</a>).</p></div>

<hr><p><a name="33"></a><a name="msg33"></a><a href="#33">Message #33</a> received at 1057843@bugs.debian.org (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=33">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=33">mbox</a>, <a href="mailto:1057843@bugs.debian.org?body=On%20Sun%2C%2010%20Dec%202023%2007%3A56%3A36%20%2B0000%20Stephan%20%3D%3FISO-8859-1%3FQ%3FVerb%3DFCcheln%3F%3D%20%3Cverbuecheln%40posteo.de%3E%20wrote%3A%0A%3E%20Are%20there%20any%20guidelines%20for%20affected%20users%20who%20already%20updated%20before%0A%3E%20they%20got%20the%20warning%3F%0A%3E%20%0A%3E%20Interesting%20questions%20for%20affected%20users%3A%0A%3E%20-%20Is%20it%20safe%20to%20assume%20that%20other%20filesystems%20%28like%20BTRFS%29%20are%20not%0A%3E%20affected%3F%0A%3E%20-%20Does%20this%20cause%20filesystem%20corruption%20or%20only%20file%20corruption%3F%0A%3E%20-%20Does%20this%20affect%20metadata%20or%20only%20file%20contents%3F%0A%3E%20-%20Is%20there%20a%20way%20to%20detect%20corrupted%20files%3F%0A%3E%20-%20If%20metadata%20is%20not%20affected%2C%20is%20it%20safe%20to%20assume%20that%20all%20files%20with%0A%3E%20a%20modification%20date%20older%20than%20the%20update%20are%20fine%3F%0A%3E%20-%20Does%20it%20help%20to%20shut%20down%20services%20%28such%20as%20Apache%29%20or%20the%20whole%0A%3E%20machine%20until%20the%20fix%20is%20available%3F%0A%3E%20%0A%3E%20%0A%3E%20%0A&amp;References=%3C170213085751.880636.15744973723197230632.reportbug%40eldamar.lan%3E%0A%09%20%3CZXR_TwLmkoTlM7Il%40eldamar.lan%3E%0A%20%3Ceb683128391f1068690f55df4383d7e585d89cb5.camel%40posteo.de%3E&amp;subject=Re%3A%20Bug%231057843%3A%20Guidelines%20for%20affected%20users&amp;In-Reply-To=%3Ceb683128391f1068690f55df4383d7e585d89cb5.camel%40posteo.de%3E">reply</a>):</p>

<pre>Are there any guidelines for affected users who already updated before
they got the warning?

Interesting questions for affected users:
- Is it safe to assume that other filesystems (like BTRFS) are not
affected?
- Does this cause filesystem corruption or only file corruption?
- Does this affect metadata or only file contents?
- Is there a way to detect corrupted files?
- If metadata is not affected, is it safe to assume that all files with
a modification date older than the update are fine?
- Does it help to shut down services (such as Apache) or the whole
machine until the fix is available?



</pre>

<div><hr><p>
<a name="34"></a>
<!-- request_addr: debian-bugs-dist@lists.debian.org, Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt; -->
<!-- time:1702201323 -->
<strong>Information forwarded</strong>
to <code>debian-bugs-dist@lists.debian.org, Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt;</code>:<br>
<code>Bug#1057843</code>; Package <code>src:linux</code>.
 (Sun, 10 Dec 2023 09:42:03 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=35">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=35">mbox</a>, <a href="#34">link</a>).</p></div>

<div><hr><p>
<a name="36"></a>
<!-- request_addr: Dale Richards &lt;dale@dalerichards.net&gt; -->
<!-- time:1702201323 -->
<strong>Acknowledgement sent</strong>
to <code>Dale Richards &lt;dale@dalerichards.net&gt;</code>:<br>
Extra info received and forwarded to list.  Copy sent to <code>Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt;</code>.
 (Sun, 10 Dec 2023 09:42:03 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=37">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=37">mbox</a>, <a href="#36">link</a>).</p></div>

<hr><p><a name="38"></a><a name="msg38"></a><a href="#38">Message #38</a> received at 1057843@bugs.debian.org (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=38">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=38">mbox</a>, <a href="mailto:1057843@bugs.debian.org?In-Reply-To=%3Ca722c3143849adf970ef67050861bf686dfb6933.camel%40dalerichards.net%3E&amp;References=%3Ca722c3143849adf970ef67050861bf686dfb6933.camel%40dalerichards.net%3E&amp;subject=Re%3A%20Bug%231057843%3A%20Guidelines%20for%20affected%20users&amp;body=On%20Sun%2C%2010%20Dec%202023%2009%3A39%3A21%20%2B0000%20Dale%20Richards%20%3Cdale%40dalerichards.net%3E%20wrote%3A%0A%3E%20On%20Sun%2C%2010%20Dec%202023%2007%3A56%3A36%20%2B0000%20Stephan%20%3D%3FISO-8859-%0A%3E%201%3FQ%3FVerb%3DFCcheln%3F%3D%20%3Cverbuecheln%40posteo.de%3E%20wrote%3A%0A%3E%20%3E%0A%3E%20%3E%20-%20Is%20it%20safe%20to%20assume%20that%20other%20filesystems%20%28like%20BTRFS%29%20are%20not%0A%3E%20%3E%20affected%3F%0A%3E%20%3E%20-%20Does%20this%20cause%20filesystem%20corruption%20or%20only%20file%20corruption%3F%0A%3E%20%3E%20-%20Does%20this%20affect%20metadata%20or%20only%20file%20contents%3F%0A%3E%20%3E%20-%20Is%20there%20a%20way%20to%20detect%20corrupted%20files%3F%0A%3E%20%3E%20-%20If%20metadata%20is%20not%20affected%2C%20is%20it%20safe%20to%20assume%20that%20all%20files%0A%3E%20with%0A%3E%20%3E%20a%20modification%20date%20older%20than%20the%20update%20are%20fine%3F%0A%3E%20%3E%20-%20Does%20it%20help%20to%20shut%20down%20services%20%28such%20as%20Apache%29%20or%20the%20whole%0A%3E%20%3E%20machine%20until%20the%20fix%20is%20available%3F%0A%3E%20%0A%3E%20The%20bug%20appears%20to%20be%20triggered%20when%20an%20-%3Eend_io%20handler%20returns%20a%20non-%0A%3E%20zero%20value%20to%20iomap%20after%20a%20direct%20IO%20write.%0A%3E%20%0A%3E%20It%20looks%20like%20the%20ext4%20handler%20is%20the%20only%20one%20that%20returns%20non-zero%20in%0A%3E%20kernel%206.1.64%2C%20so%20for%20now%20one%20can%20assume%20that%20only%20ext4%20filesystems%20are%0A%3E%20affected.%0A%3E%20%0A%3E%20The%20bug%20corrupts%20file%20data%20during%20a%20direct%20write%20operation%2C%20so%20I%20would%0A%3E%20also%20assume%20that%20files%20last%20modified%20before%206.1.64%20was%20installed%20will%0A%3E%20not%20be%20corrupted.%0A%3E%20%0A%3E%20As%20far%20as%20I%20can%20tell%2C%20the%20corruption%20only%20affects%20file%20data%20%28not%0A%3E%20metadata%29%20but%20perhaps%20someone%20with%20more%20kernel%20experience%20than%20me%20can%0A%3E%20confirm.%0A%3E%20%0A%3E%20Best%20regards%2C%0A%3E%20Dale%20Richards%0A%3E%20%0A%3E%20%0A%3E%20%0A">reply</a>):</p>

<pre>On Sun, 10 Dec 2023 07:56:36 +0000 Stephan =?ISO-8859-
1?Q?Verb=FCcheln?= &lt;verbuecheln@posteo.de&gt; wrote:
&gt;
&gt; - Is it safe to assume that other filesystems (like BTRFS) are not
&gt; affected?
&gt; - Does this cause filesystem corruption or only file corruption?
&gt; - Does this affect metadata or only file contents?
&gt; - Is there a way to detect corrupted files?
&gt; - If metadata is not affected, is it safe to assume that all files
with
&gt; a modification date older than the update are fine?
&gt; - Does it help to shut down services (such as Apache) or the whole
&gt; machine until the fix is available?

The bug appears to be triggered when an -&gt;end_io handler returns a non-
zero value to iomap after a direct IO write.

It looks like the ext4 handler is the only one that returns non-zero in
kernel 6.1.64, so for now one can assume that only ext4 filesystems are
affected.

The bug corrupts file data during a direct write operation, so I would
also assume that files last modified before 6.1.64 was installed will
not be corrupted.

As far as I can tell, the corruption only affects file data (not
metadata) but perhaps someone with more kernel experience than me can
confirm.

Best regards,
Dale Richards



</pre>

<div><hr><p>
<a name="39"></a>
<!-- request_addr: debian-bugs-dist@lists.debian.org, Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt; -->
<!-- time:1702202583 -->
<strong>Information forwarded</strong>
to <code>debian-bugs-dist@lists.debian.org, Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt;</code>:<br>
<code>Bug#1057843</code>; Package <code>src:linux</code>.
 (Sun, 10 Dec 2023 10:03:03 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=40">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=40">mbox</a>, <a href="#39">link</a>).</p></div>

<div><hr><p>
<a name="41"></a>
<!-- request_addr: Umberto Zappi &lt;uzappi@gmail.com&gt; -->
<!-- time:1702202583 -->
<strong>Acknowledgement sent</strong>
to <code>Umberto Zappi &lt;uzappi@gmail.com&gt;</code>:<br>
Extra info received and forwarded to list.  Copy sent to <code>Debian Kernel Team &lt;debian-kernel@lists.debian.org&gt;</code>.
 (Sun, 10 Dec 2023 10:03:03 GMT) (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=42">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=42">mbox</a>, <a href="#41">link</a>).</p></div>

<hr><p><a name="43"></a><a name="msg43"></a><a href="#43">Message #43</a> received at 1057843@bugs.debian.org (<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;msg=43">full text</a>, <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1057843;mbox=yes;msg=43">mbox</a>, <a href="mailto:1057843@bugs.debian.org?body=On%20Sun%2C%2010%20Dec%202023%2010%3A58%3A31%20%2B0100%20Umberto%20Zappi%20%3Cuzappi%40gmail.com%3E%20wrote%3A%0A%3E%20Are%20there%20any%20guidelines%20for%20affected%20users%20who%20already%20updated%20before%0A%3E%20they%20got%20the%20warning%3F%0A%3E%20%0A%3E%20For%20example%2C%20is%20it%20fine%20to%20start%20with%20the%20previous%20kernel%0A%3E%206.1.0-13-amd64%20%28version%206.1.55-1%29%20%3F%0A%3E%20%0A%3E%20Thanks%0A%3E%20UmbertoZ.%0A&amp;References=%3CCAD0%3Df%2BDguJ%3Dti9tvcvB1XJ%2Bsjcs-dRUKJvL4Lnv%2BzcbSDKSjbA%40mail.gmail.com%3E&amp;subject=Re%3A%20Bug%231057843%3A%20Guidelines%20for%20affected%20users%20which%20use%20etx4&amp;In-Reply-To=%3CCAD0%3Df%2BDguJ%3Dti9tvcvB1XJ%2Bsjcs-dRUKJvL4Lnv%2BzcbSDKSjbA%40mail.gmail.com%3E">reply</a>):</p>

<pre>[<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?att=0;bug=1057843;msg=43">Message part 1</a> (text/plain, inline)]</pre>
<pre>Are there any guidelines for affected users who already updated before
they got the warning?

For example, is it fine to start with the previous kernel
6.1.0-13-amd64 (version 6.1.55-1) ?

Thanks
UmbertoZ.
</pre>
<pre>[<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?att=1;bug=1057843;msg=43">Message part 2</a> (text/html, inline)]</pre>

<hr>
<p>Send a report that <a href="https://bugs.debian.org/cgi-bin/bugspam.cgi?bug=1057843">this bug log contains spam</a>.</p>
<hr>
<address>Debian bug tracking system administrator &lt;<a href="mailto:owner@bugs.debian.org">owner@bugs.debian.org</a>&gt;.
Last modified:
<!--timestamp-->Sun Dec 10 11:56:12 2023<!--end timestamp-->; 
Machine Name:
<!--machinename-->buxtehude<!--machinename-->
<p>
<a href="https://www.debian.org/Bugs/">Debian Bug tracking system</a>
</p>
<p>
  Debbugs is free software and licensed under the terms of the GNU
  Public License version 2. The current version can be obtained
  from <a href="https://bugs.debian.org/debbugs-source/">https://bugs.debian.org/debbugs-source/</a>.
</p>
<p>
Copyright Â© 1999 Darren O. Benham,
1997,2003 nCipher Corporation Ltd,
1994-97 Ian Jackson,
2005-2017 Don Armstrong, and many other contributors.
</p>
</address>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trippy â€“ A Network Diagnostic Tool (226 pts)]]></title>
            <link>https://trippy.cli.rs/</link>
            <guid>38588858</guid>
            <pubDate>Sun, 10 Dec 2023 03:46:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trippy.cli.rs/">https://trippy.cli.rs/</a>, See on <a href="https://news.ycombinator.com/item?id=38588858">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      
      

      <p><a href="https://github.com/fujiapple852/trippy/actions/workflows/ci.yml"><img src="https://github.com/fujiapple852/trippy/workflows/CI/badge.svg" alt="Continuous integration"></a>
<a href="https://crates.io/crates/trippy/0.9.0"><img src="https://img.shields.io/crates/v/trippy.svg" alt="Crate"></a>
<a href="https://repology.org/project/trippy/versions"><img src="https://repology.org/badge/tiny-repos/trippy.svg" alt="Packaging status"></a>
<a href="https://matrix.to/#/#trippy-dev:matrix.org"><img src="https://img.shields.io/badge/matrix/trippy-dev:matrix.org-blue" alt="#trippy-dev:matrix.org"></a></p>

<h2 id="trippy">Trippy</h2>

<p>Trippy combines the functionality of traceroute and ping and is designed to assist with the analysis of networking
issues.</p>

<p><img src="https://trippy.cli.rs/assets/0.8.0/trippy.gif" alt="trippy"></p>

<h2 id="navigation">Navigation</h2>

<!-- TOC -->

<ul>
  <li><a href="#trippy">Trippy</a>
    <ul>
      <li><a href="#features">Features</a></li>
      <li><a href="#versions">Versions</a></li>
      <li><a href="#distributions">Distributions</a></li>
      <li><a href="#privileges">Privileges</a></li>
      <li><a href="#usage-examples">Usage Examples</a></li>
      <li><a href="#command-reference">Command Reference</a></li>
      <li><a href="#theme-reference">Theme Reference</a></li>
      <li><a href="#key-bindings-reference">Key Bindings Reference</a></li>
      <li><a href="#configuration-reference">Configuration Reference</a></li>
      <li><a href="#frequently-asked-questions">Frequently Asked Questions</a></li>
      <li><a href="#acknowledgements">Acknowledgements</a></li>
      <li><a href="#license">License</a></li>
    </ul>
  </li>
</ul>

<!-- TOC -->

<h2 id="features">Features</h2>

<ul>
  <li>Trace using multiple protocols:
    <ul>
      <li><code>ICMP</code>, <code>UDP</code> &amp; <code>TCP</code></li>
      <li><code>IPv4</code> &amp; <code>IPv6</code></li>
    </ul>
  </li>
  <li>Customizable tracing options:
    <ul>
      <li>packet size &amp; payload pattern</li>
      <li>start and maximum time-to-live (TTL)</li>
      <li>minimum and maximum round duration</li>
      <li>round end grace period &amp; maximum number of unknown hops</li>
      <li>source &amp; destination port (<code>TCP</code> &amp; <code>UDP</code>)</li>
      <li>source address and source interface</li>
      <li><code>TOS</code> (aka <code>DSCP + ECN</code>)</li>
    </ul>
  </li>
  <li>Support for <code>classic</code>, <code>paris</code>
and <code>dublin</code> <a href="https://en.wikipedia.org/wiki/Equal-cost_multi-path_routing">Equal Cost Multi-path Routing</a>
strategies (<a href="https://github.com/fujiapple852/trippy/issues/274">tracking issue</a>)</li>
  <li>RFC4884 <a href="https://datatracker.ietf.org/doc/html/rfc4884">ICMP Multi-Part Messages</a>
    <ul>
      <li>Generic Extension Objects</li>
      <li>MPLS Label Stacks</li>
    </ul>
  </li>
  <li>Unprivileged mode</li>
  <li>Tui interface:
    <ul>
      <li>Trace multiple targets simultaneously from a single instance of Trippy</li>
      <li>Per hop stats (sent, received, loss%, last, avg, best, worst, stddev &amp; status)</li>
      <li>Per hop round-trip-time (RTT) history and frequency distributing charts</li>
      <li>Interactive chart of RTT for all hops in a trace with zooming capability</li>
      <li>Interactive GeoIp world map</li>
      <li>Isolate and filter by individual tracing flows</li>
      <li>Customizable color theme &amp; key bindings</li>
      <li>Configuration via both command line arguments and a configuration file</li>
      <li>Show multiple hosts per hop with ability to cap display to N hosts and show frequency %</li>
      <li>Show hop details and navigate hosts within each hop</li>
      <li>Freeze/unfreeze the Tui, reset the stats, flush the cache, preserve screen on exit</li>
      <li>Responsive UI with adjustable refresh rate</li>
      <li>Hop privacy</li>
    </ul>
  </li>
  <li>DNS:
    <ul>
      <li>Use system, external (Google <code>8.8.8.8</code> or Cloudflare <code>1.1.1.1</code>) or custom resolver</li>
      <li>Lazy reverse DNS queries</li>
      <li>Lookup <a href="https://en.wikipedia.org/wiki/Autonomous_system_(Internet)">autonomous system</a> number (ASN) and name</li>
    </ul>
  </li>
  <li>GeoIp:
    <ul>
      <li>Lookup and display GeoIp information from local <code>mmdb</code> files</li>
    </ul>
  </li>
  <li>Generate tracing reports:
    <ul>
      <li><code>json</code>, <code>csv</code> &amp; tabular (pretty-printed and markdown)</li>
      <li>Tracing <code>flows</code> report</li>
      <li>Graphviz <code>dot</code> charts</li>
      <li>configurable reporting cycles</li>
    </ul>
  </li>
  <li>Runs on multiple platform (macOS, Linux, NetBSD, FreeBSD, Windows)</li>
  <li>Capabilities aware application (Linux only)</li>
</ul>

<h2 id="versions">Versions</h2>

<p>The following table lists ths versions of Trippy that are available and links to the corresponding release note and
documentation:</p>

<table>
  <thead>
    <tr>
      <th>Version</th>
      <th>Release Date</th>
      <th>Status</th>
      <th>Release Note</th>
      <th>Documentation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0.10.0-dev</td>
      <td>n/a</td>
      <td>Development</td>
      <td>n/a</td>
      <td><a href="https://github.com/fujiapple852/trippy/tree/master">docs</a></td>
    </tr>
    <tr>
      <td>0.9.0</td>
      <td>2023-11-30</td>
      <td>Current</td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/tag/0.9.0">note</a></td>
      <td><a href="https://github.com/fujiapple852/trippy/tree/0.9.0">docs</a></td>
    </tr>
    <tr>
      <td>0.8.0</td>
      <td>2023-05-15</td>
      <td>Previous</td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/tag/0.8.0">note</a></td>
      <td><a href="https://github.com/fujiapple852/trippy/tree/0.8.0">docs</a></td>
    </tr>
    <tr>
      <td>0.7.0</td>
      <td>2023-03-25</td>
      <td>Deprecated</td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/tag/0.7.0">note</a></td>
      <td><a href="https://github.com/fujiapple852/trippy/tree/0.7.0">docs</a></td>
    </tr>
    <tr>
      <td>0.6.0</td>
      <td>2022-08-19</td>
      <td>Deprecated</td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/tag/0.6.0">note</a></td>
      <td><a href="https://github.com/fujiapple852/trippy/tree/0.6.0">docs</a></td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>[!NOTE]
Only the <em>latest patch versions</em> of both the <em>current</em> and <em>previous</em> releases of Trippy are supported.</p>
</blockquote>

<h2 id="distributions">Distributions</h2>

<p><a href="https://repology.org/project/trippy/versions"><img src="https://repology.org/badge/vertical-allrepos/trippy.svg" alt="Packaging status"></a></p>

<h3 id="cargo">Cargo</h3>

<p><a href="https://crates.io/crates/trippy/0.9.0"><img src="https://img.shields.io/crates/v/trippy" alt="Crates.io"></a></p>



<h3 id="snap-linux">Snap (Linux)</h3>

<p><a href="https://snapcraft.io/trippy"><img src="https://snapcraft.io/trippy/badge.svg" alt="trippy"></a></p>



<h3 id="homebrew-macos">Homebrew (macOS)</h3>

<p><a href="https://formulae.brew.sh/formula/trippy"><img src="https://repology.org/badge/version-for-repo/homebrew/trippy.svg" alt="Homebrew package"></a></p>



<h3 id="winget-windows">WinGet (Windows)</h3>

<p><a href="https://github.com/microsoft/winget-pkgs/tree/master/manifests/f/FujiApple/Trippy/0.9.0"><img src="https://repology.org/badge/version-for-repo/winget/trippy.svg" alt="winget package"></a></p>



<h3 id="scoop-windows">Scoop (Windows)</h3>

<p><a href="https://github.com/ScoopInstaller/Main/blob/master/bucket/trippy.json"><img src="https://repology.org/badge/version-for-repo/scoop/trippy.svg" alt="Scoop package"></a></p>



<h3 id="netbsd">NetBSD</h3>

<p><a href="https://pkgsrc.se/net/trippy"><img src="https://repology.org/badge/version-for-repo/pkgsrc_current/trippy.svg" alt="pkgsrc current package"></a></p>



<h3 id="freebsd">FreeBSD</h3>

<p><a href="https://www.freshports.org/net/trippy/"><img src="https://repology.org/badge/version-for-repo/freebsd/trippy.svg" alt="FreeBSD port"></a></p>



<h3 id="pacman-arch-linux">Pacman (Arch Linux)</h3>

<p><a href="https://archlinux.org/packages/extra/x86_64/trippy"><img src="https://repology.org/badge/version-for-repo/arch/trippy.svg" alt="Arch package"></a></p>



<h3 id="nix">Nix</h3>

<p><a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/tools/networking/trippy/default.nix"><img src="https://repology.org/badge/version-for-repo/nix_unstable/trippy.svg" alt="nixpkgs unstable package"></a></p>



<h3 id="docker">Docker</h3>

<p><a href="https://hub.docker.com/r/fujiapple/trippy/"><img src="https://img.shields.io/docker/v/fujiapple/trippy" alt="Docker Image Version (latest by date)"></a></p>

<div><pre><code>docker run <span>-it</span> fujiapple/trippy
</code></pre></div>

<h3 id="binary-asset-download">Binary Asset Download</h3>

<table>
  <thead>
    <tr>
      <th>OS</th>
      <th>Arch</th>
      <th>Env</th>
      <th>Current</th>
      <th>Previous</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Linux</td>
      <td><code>x86_64</code></td>
      <td><code>gnu</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-x86_64-unknown-linux-gnu.tar.gz">0.9.0</a></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.8.0/trippy-0.8.0-x86_64-unknown-linux-gnu.tar.gz">0.8.0</a></td>
    </tr>
    <tr>
      <td>Linux</td>
      <td><code>x86_64</code></td>
      <td><code>musl</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-x86_64-unknown-linux-musl.tar.gz">0.9.0</a></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.8.0/trippy-0.8.0-x86_64-unknown-linux-musl.tar.gz">0.8.0</a></td>
    </tr>
    <tr>
      <td>Linux</td>
      <td><code>aarch64</code></td>
      <td><code>gnu</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-aarch64-unknown-linux-gnu.tar.gz">0.9.0</a></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.8.0/trippy-0.8.0-aarch64-unknown-linux-gnu.tar.gz">0.8.0</a></td>
    </tr>
    <tr>
      <td>Linux</td>
      <td><code>aarch64</code></td>
      <td><code>musl</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-aarch64-unknown-linux-musl.tar.gz">0.9.0</a></td>
      <td>n/a</td>
    </tr>
    <tr>
      <td>Linux</td>
      <td><code>arm7</code></td>
      <td><code>gnueabihf</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-armv7-unknown-linux-gnueabihf.tar.gz">0.9.0</a></td>
      <td>n/a</td>
    </tr>
    <tr>
      <td>Linux</td>
      <td><code>arm7</code></td>
      <td><code>musleabi</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-armv7-unknown-linux-musleabi.tar.gz">0.9.0</a></td>
      <td>n/a</td>
    </tr>
    <tr>
      <td>Linux</td>
      <td><code>arm7</code></td>
      <td><code>musleabihf</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-armv7-unknown-linux-musleabihf.tar.gz">0.9.0</a></td>
      <td>n/a</td>
    </tr>
    <tr>
      <td>macOS</td>
      <td><code>x86_64</code></td>
      <td><code>darwin</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-x86_64-apple-darwin.tar.gz">0.9.0</a></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.8.0/trippy-0.8.0-x86_64-apple-darwin.tar.gz">0.8.0</a></td>
    </tr>
    <tr>
      <td>macOS</td>
      <td><code>aarch64</code></td>
      <td><code>darwin</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-aarch64-apple-darwin.tar.gz">0.9.0</a></td>
      <td>n/a</td>
    </tr>
    <tr>
      <td>Windows</td>
      <td><code>x86_64</code></td>
      <td><code>msvc</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-x86_64-pc-windows-msvc.zip">0.9.0</a></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.8.0/trippy-0.8.0-x86_64-pc-windows-msvc.zip">0.8.0</a></td>
    </tr>
    <tr>
      <td>Windows</td>
      <td><code>x86_64</code></td>
      <td><code>gnu</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-x86_64-pc-windows-gnu.zip">0.9.0</a></td>
      <td>n/a</td>
    </tr>
    <tr>
      <td>Windows</td>
      <td><code>aarch64</code></td>
      <td><code>msvc</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-aarch64-pc-windows-msvc.zip">0.9.0</a></td>
      <td>n/a</td>
    </tr>
    <tr>
      <td>FreeBSD</td>
      <td><code>x86_64</code></td>
      <td>n/a</td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-x86_64-unknown-freebsd.tar.gz">0.9.0</a></td>
      <td>n/a</td>
    </tr>
    <tr>
      <td>NetBSD</td>
      <td><code>x86_64</code></td>
      <td>n/a</td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-x86_64-unknown-netbsd.tar.gz">0.9.0</a></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.8.0/trippy-0.8.0-x86_64-unknown-netbsd.tar.gz">0.8.0</a></td>
    </tr>
    <tr>
      <td>RPM</td>
      <td><code>x86_64</code></td>
      <td><code>gnu</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy-0.9.0-x86_64.rpm">0.9.0</a></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.8.0/trippy-0.8.0-x86_64.rpm">0.8.0</a></td>
    </tr>
    <tr>
      <td>Debian</td>
      <td><code>x86_64</code></td>
      <td><code>gnu</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy_x86_64-unknown-linux-gnu_0.9.0_amd64.deb">0.9.0</a></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.8.0/trippy_x86_64-unknown-linux-gnu_0.8.0_amd64.deb">0.8.0</a></td>
    </tr>
    <tr>
      <td>Debian</td>
      <td><code>x86_64</code></td>
      <td><code>musl</code></td>
      <td><a href="https://github.com/fujiapple852/trippy/releases/download/0.9.0/trippy_x86_64-unknown-linux-musl_0.9.0_amd64.deb">0.9.0</a></td>
      <td>n/a</td>
    </tr>
  </tbody>
</table>

<h2 id="privileges">Privileges</h2>

<p>Trippy normally requires elevated privileges due to the use of raw sockets. Enabling the required privileges for your
platform can be achieved in several ways, as outlined below. Trippy can also be used without elevated privileged on
certain platforms, with some limitations.</p>

<h3 id="unix">Unix</h3>

<p>1: Run as <code>root</code> user via <code>sudo</code>:</p>



<p>2: <code>chown</code> <code>trip</code> as the <code>root</code> user and set the <code>setuid</code> bit:</p>

<div><pre><code><span>sudo chown </span>root <span>$(</span>which trip<span>)</span> <span>&amp;&amp;</span> <span>sudo chmod</span> +s <span>$(</span>which trip<span>)</span>
</code></pre></div>

<p>3: [Linux only] Set the <code>CAP_NET_RAW</code> capability:</p>

<div><pre><code><span>sudo </span>setcap CAP_NET_RAW+p <span>$(</span>which trip<span>)</span>
</code></pre></div>

<blockquote>
  <p>[!NOTE]<br>
Trippy is a capability aware application and will add <code>CAP_NET_RAW</code> to the effective set if it is present in the
allowed set. Trippy will drop all capabilities after creating the raw sockets.</p>
</blockquote>

<h3 id="windows">Windows</h3>

<p>Trippy must be run with Administrator privileges on Windows.</p>

<h3 id="unprivileged-mode">Unprivileged mode</h3>

<p>Trippy allows running in an unprivileged mode for all tracing modes (<code>ICMP</code>, <code>UDP</code> and <code>TCP</code>) on platforms which support
that feature.</p>

<blockquote>
  <p>[!NOTE]
Unprivileged mode is currently only supported on macOS. Linux support is possible and may be added in the future.
Unprivileged mode is not supported on NetBSD, FreeBSD or Windows as these platforms do not support
the <code>IPPROTO_ICMP</code> socket type. See <a href="https://github.com/fujiapple852/trippy/issues/101">#101</a> for further information.</p>
</blockquote>

<p>The unprivileged mode can be enabled by adding the <code>--unprivileged</code> (<code>-u</code>) command line flag or by adding
the <code>unprivileged</code> entry in the <code>trippy</code> section of the <a href="#configuration-reference">configuration file</a>:</p>

<div><pre><code><span>[trippy]</span>
<span>unprivileged</span> <span>=</span> <span>true</span>
</code></pre></div>

<blockquote>
  <p>[!NOTE]
The <code>paris</code> and <code>dublin</code> <code>ECMP</code> strategies are not supported in unprivileged mode as these require
manipulating the <code>UDP</code> and <code>IP</code> and headers which in turn requires the use of a raw socket.</p>
</blockquote>

<h2 id="usage-examples">Usage Examples</h2>

<p>Basic usage with default parameters:</p>



<p>Trace without requiring elevated privileges (supported platforms only, see <a href="#privileges">privileges</a>):</p>

<div><pre><code>trip example.com <span>--unprivileged</span>
</code></pre></div>

<p>Trace using the <code>udp</code> (or <code>tcp</code> or <code>icmp</code>) protocol (also aliases <code>--icmp</code>, <code>--udp</code> &amp; <code>--tcp</code>):</p>



<p>Trace to multiple targets simultaneously (<code>icmp</code> protocol only,
see <a href="https://github.com/fujiapple852/trippy/issues/72">#72</a>):</p>

<div><pre><code>trip example.com google.com crates.io
</code></pre></div>

<p>Trace with a minimum round time of <code>250ms</code> and a grace period of <code>50ms</code>:</p>

<div><pre><code>trip example.com <span>-i</span> 250ms <span>-g</span> 50ms
</code></pre></div>

<p>Trace with a custom first and maximum <code>time-to-live</code>:</p>

<div><pre><code>trip example.com <span>--first-ttl</span> 2 <span>--max-ttl</span> 10
</code></pre></div>

<p>Use custom destination port <code>443</code> for <code>tcp</code> tracing:</p>

<div><pre><code>trip example.com <span>-p</span> tcp <span>-P</span> 443
</code></pre></div>

<p>Use custom source port <code>5000</code> for <code>udp</code> tracing:</p>

<div><pre><code>trip example.com <span>-p</span> udp <span>-S</span> 5000
</code></pre></div>

<p>Use the <code>dublin</code> (or <code>paris</code>) ECMP routing strategy for <code>udp</code> with fixed source and destination ports:</p>

<div><pre><code>trip example.com <span>-p</span> udp <span>-R</span> dublin <span>-S</span> 5000 <span>-P</span> 3500
</code></pre></div>

<p>Trace with a custom source address:</p>

<div><pre><code>trip example.com <span>-p</span> tcp <span>-A</span> 127.0.0.1
</code></pre></div>

<p>Trace with a source address determined by the IPv4 address for interface <code>en0</code>:</p>

<div><pre><code>trip example.com <span>-p</span> tcp <span>-I</span> en0
</code></pre></div>

<p>Trace using <code>IPv6</code>:</p>



<p>Generate a <code>json</code> (or <code>csv</code>, <code>pretty</code>, <code>markdown</code>) tracing report with 5 rounds of data:</p>

<div><pre><code>trip example.com <span>-m</span> json <span>-C</span> 5
</code></pre></div>

<p>Generate a <a href="https://graphviz.org/">Graphviz</a> <code>DOT</code> file report of all tracing flows for a TCP trace after 5 rounds:</p>

<div><pre><code>trip example.com <span>--tcp</span> <span>-m</span> dot <span>-C</span> 5
</code></pre></div>

<p>Generate a textual report of all tracing flows for a UDP trace after 5 rounds:</p>

<div><pre><code>trip example.com <span>--udp</span> <span>-m</span> flows <span>-C</span> 5
</code></pre></div>

<p>Perform DNS queries using the <code>google</code> DNS resolver (or <code>cloudflare</code>, <code>system</code>, <code>resolv</code>):</p>

<div><pre><code>trip example.com <span>-r</span> google
</code></pre></div>

<p>Lookup AS information for all discovered IP addresses (not yet available for the <code>system</code> resolver,
see <a href="https://github.com/fujiapple852/trippy/issues/66">#66</a>):</p>

<div><pre><code>trip example.com <span>-r</span> google <span>-z</span>
</code></pre></div>

<p>Lookup and display <code>short</code> (or <code>long</code> or <code>location</code> or <code>off</code>) GeoIp information from a <code>mmdb</code> file:</p>

<div><pre><code>trip example.com <span>--geoip-mmdb-file</span> GeoLite2-City.mmdb <span>--tui-geoip-mode</span> short
</code></pre></div>

<p>Parse <code>icmp</code> extensions:</p>



<p>Hide the IP address, hostname and GeoIp for the first two hops:</p>

<div><pre><code>trip example.com <span>--tui-privacy-max-ttl</span> 2
</code></pre></div>

<p>Customize the color theme:</p>

<div><pre><code>trip example.com <span>--tui-theme-colors</span> bg-color<span>=</span>blue,text-color<span>=</span>ffff00
</code></pre></div>

<p>List all Tui items that can have a custom color theme:</p>

<div><pre><code>trip <span>--print-tui-theme-items</span>
</code></pre></div>

<p>Customize the key bindings:</p>

<div><pre><code>trip example.com <span>--tui-key-bindings</span> previous-hop<span>=</span>k,next-hop<span>=</span>j,quit<span>=</span>shift-q
</code></pre></div>

<p>List all Tui commands that can have a custom key binding:</p>

<div><pre><code>trip <span>--print-tui-binding-commands</span>
</code></pre></div>

<p>Specify the location of the Trippy config file:</p>

<div><pre><code>trip example.com <span>--config-file</span> /path/to/trippy.toml
</code></pre></div>

<p>Generate a template configuration file:</p>

<div><pre><code>trip <span>--print-config-template</span> <span>&gt;</span> trippy.toml
</code></pre></div>

<p>Generate <code>bash</code> shell completions (or <code>fish</code>, <code>powershell</code>, <code>zsh</code>, <code>elvish</code>):</p>



<p>Run in <code>silent</code> tracing mode and output <code>compact</code> trace logging with <code>full</code> span events:</p>

<div><pre><code>trip example.com <span>-m</span> silent <span>-v</span> <span>--log-format</span> compact <span>--log-span-events</span> full
</code></pre></div>

<h2 id="command-reference">Command Reference</h2>

<blockquote>
  <p>[!NOTE]
Trippy command line arguments may be given in any order and my occur both before and after the targets.</p>
</blockquote>

<div><pre><code>A network diagnostic tool

Usage: trip [OPTIONS] [TARGETS]...

Arguments:
  [TARGETS]...
          A space delimited list of hostnames and IPs to trace

Options:
  -c, --config-file &lt;CONFIG_FILE&gt;
          Config file

  -m, --mode &lt;MODE&gt;
          Output mode [default: tui]

          Possible values:
          - tui:      Display interactive TUI
          - stream:   Display a continuous stream of tracing data
          - pretty:   Generate an pretty text table report for N cycles
          - markdown: Generate a markdown text table report for N cycles
          - csv:      Generate a CSV report for N cycles
          - json:     Generate a JSON report for N cycles
          - dot:      Generate a Graphviz DOT file for N cycles
          - flows:    Display all flows
          - silent:   Do not generate any tracing output for N cycles

  -u, --unprivileged
          Trace without requiring elevated privileges on supported platforms
          [default: false]

  -p, --protocol &lt;PROTOCOL&gt;
          Tracing protocol [default: icmp]

          Possible values:
          - icmp: Internet Control Message Protocol
          - udp:  User Datagram Protocol
          - tcp:  Transmission Control Protocol

      --udp
          Trace using the UDP protocol

      --tcp
          Trace using the TCP protocol

      --icmp
          Trace using the ICMP protocol

  -4, --ipv4
          Use IPv4 only

  -6, --ipv6
          Use IPv6 only

  -P, --target-port &lt;TARGET_PORT&gt;
          The target port (TCP &amp; UDP only) [default: 80]

  -S, --source-port &lt;SOURCE_PORT&gt;
          The source port (TCP &amp; UDP only) [default: auto]

  -A, --source-address &lt;SOURCE_ADDRESS&gt;
          The source IP address [default: auto]

  -I, --interface &lt;INTERFACE&gt;
          The network interface [default: auto]

  -i, --min-round-duration &lt;MIN_ROUND_DURATION&gt;
          The minimum duration of every round [default: 1s]

  -T, --max-round-duration &lt;MAX_ROUND_DURATION&gt;
          The maximum duration of every round [default: 1s]

  -g, --grace-duration &lt;GRACE_DURATION&gt;
          The period of time to wait for additional ICMP responses after the
          target has responded [default: 100ms]

      --initial-sequence &lt;INITIAL_SEQUENCE&gt;
          The initial sequence number [default: 33000]

  -R, --multipath-strategy &lt;MULTIPATH_STRATEGY&gt;
          The Equal-cost Multi-Path routing strategy (UDP only) [default:
          classic]

          Possible values:
          - classic:
            The src or dest port is used to store the sequence number
          - paris:
            The UDP `checksum` field is used to store the sequence number
          - dublin:
            The IP `identifier` field is used to store the sequence number

  -U, --max-inflight &lt;MAX_INFLIGHT&gt;
          The maximum number of in-flight ICMP echo requests [default: 24]

  -f, --first-ttl &lt;FIRST_TTL&gt;
          The TTL to start from [default: 1]

  -t, --max-ttl &lt;MAX_TTL&gt;
          The maximum number of TTL hops [default: 64]

      --packet-size &lt;PACKET_SIZE&gt;
          The size of IP packet to send (IP header + ICMP header + payload)
          [default: 84]

      --payload-pattern &lt;PAYLOAD_PATTERN&gt;
          The repeating pattern in the payload of the ICMP packet [default: 0]

  -Q, --tos &lt;TOS&gt;
          The TOS (i.e. DSCP+ECN) IP header value (TCP and UDP only) [default: 0]

  -e, --icmp-extensions
          Parse ICMP extensions

      --read-timeout &lt;READ_TIMEOUT&gt;
          The socket read timeout [default: 10ms]

  -r, --dns-resolve-method &lt;DNS_RESOLVE_METHOD&gt;
          How to perform DNS queries [default: system]

          Possible values:
          - system:     Resolve using the OS resolver
          - resolv:     Resolve using the `/etc/resolv.conf` DNS configuration
          - google:     Resolve using the Google `8.8.8.8` DNS service
          - cloudflare: Resolve using the Cloudflare `1.1.1.1` DNS service

  -y, --dns-resolve-all
          Trace to all IPs resolved from DNS lookup [default: false]

      --dns-timeout &lt;DNS_TIMEOUT&gt;
          The maximum time to wait to perform DNS queries [default: 5s]

  -z, --dns-lookup-as-info
          Lookup autonomous system (AS) information during DNS queries [default:
          false]

  -a, --tui-address-mode &lt;TUI_ADDRESS_MODE&gt;
          How to render addresses [default: host]

          Possible values:
          - ip:   Show IP address only
          - host: Show reverse-lookup DNS hostname only
          - both: Show both IP address and reverse-lookup DNS hostname

      --tui-as-mode &lt;TUI_AS_MODE&gt;
          How to render AS information [default: asn]

          Possible values:
          - asn:          Show the ASN
          - prefix:       Display the AS prefix
          - country-code: Display the country code
          - registry:     Display the registry name
          - allocated:    Display the allocated date
          - name:         Display the AS name

      --tui-icmp-extension-mode &lt;TUI_ICMP_EXTENSION_MODE&gt;
          How to render ICMP extensions [default: off]

          Possible values:
          - off:  Do not show `icmp` extensions
          - mpls: Show MPLS label(s) only
          - full: Show full `icmp` extension data for all known extensions
          - all:  Show full `icmp` extension data for all classes

      --tui-geoip-mode &lt;TUI_GEOIP_MODE&gt;
          How to render GeoIp information [default: short]

          Possible values:
          - off:      Do not display GeoIp data
          - short:    Show short format
          - long:     Show long format
          - location: Show latitude and Longitude format

  -M, --tui-max-addrs &lt;TUI_MAX_ADDRS&gt;
          The maximum number of addresses to show per hop [default: auto]

  -s, --tui-max-samples &lt;TUI_MAX_SAMPLES&gt;
          The maximum number of samples to record per hop [default: 256]

      --tui-max-flows &lt;TUI_MAX_FLOWS&gt;
          The maximum number of flows to show [default: 64]

      --tui-preserve-screen
          Preserve the screen on exit [default: false]

      --tui-refresh-rate &lt;TUI_REFRESH_RATE&gt;
          The Tui refresh rate [default: 100ms]

      --tui-privacy-max-ttl &lt;TUI_PRIVACY_MAX_TTL&gt;
          The maximum ttl of hops which will be masked for privacy [default: 0]

      --tui-theme-colors &lt;TUI_THEME_COLORS&gt;
          The TUI theme colors [item=color,item=color,..]

      --print-tui-theme-items
          Print all TUI theme items and exit

      --tui-key-bindings &lt;TUI_KEY_BINDINGS&gt;
          The TUI key bindings [command=key,command=key,..]

      --print-tui-binding-commands
          Print all TUI commands that can be bound and exit

  -C, --report-cycles &lt;REPORT_CYCLES&gt;
          The number of report cycles to run [default: 10]

  -G, --geoip-mmdb-file &lt;GEOIP_MMDB_FILE&gt;
          The MaxMind City GeoLite2 mmdb file

      --generate &lt;GENERATE&gt;
          Generate shell completion

          [possible values: bash, elvish, fish, powershell, zsh]

      --print-config-template
          Print a template toml config file and exit

      --log-format &lt;LOG_FORMAT&gt;
          The debug log format [default: pretty]

          Possible values:
          - compact: Display log data in a compact format
          - pretty:  Display log data in a pretty format
          - json:    Display log data in a json format
          - chrome:  Display log data in Chrome trace format

      --log-filter &lt;LOG_FILTER&gt;
          The debug log filter [default: trippy=debug]

      --log-span-events &lt;LOG_SPAN_EVENTS&gt;
          The debug log format [default: off]

          Possible values:
          - off:    Do not display event spans
          - active: Display enter and exit event spans
          - full:   Display all event spans

  -v, --verbose
          Enable verbose debug logging

  -h, --help
          Print help (see a summary with '-h')

  -V, --version
          Print version
</code></pre></div>

<h2 id="theme-reference">Theme Reference</h2>

<p>The following table lists the default Tui color theme. These can be overridden with the <code>--tui-theme-colors</code> command
line option.</p>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>bg-color</code></td>
      <td>The default background color</td>
      <td><code>Black</code></td>
    </tr>
    <tr>
      <td><code>border-color</code></td>
      <td>The default color of borders</td>
      <td><code>Gray</code></td>
    </tr>
    <tr>
      <td><code>text-color</code></td>
      <td>The default color of text</td>
      <td><code>Gray</code></td>
    </tr>
    <tr>
      <td><code>tab-text-color</code></td>
      <td>The color of the text in traces tabs</td>
      <td><code>Green</code></td>
    </tr>
    <tr>
      <td><code>hops-table-header-bg-color</code></td>
      <td>The background color of the hops table header</td>
      <td><code>White</code></td>
    </tr>
    <tr>
      <td><code>hops-table-header-text-color</code></td>
      <td>The color of text in the hops table header</td>
      <td><code>Black</code></td>
    </tr>
    <tr>
      <td><code>hops-table-row-active-text-color</code></td>
      <td>The color of text of active rows in the hops table</td>
      <td><code>Gray</code></td>
    </tr>
    <tr>
      <td><code>hops-table-row-inactive-text-color</code></td>
      <td>The color of text of inactive rows in the hops table</td>
      <td><code>DarkGray</code></td>
    </tr>
    <tr>
      <td><code>hops-chart-selected-color</code></td>
      <td>The color of the selected series in the hops chart</td>
      <td><code>Green</code></td>
    </tr>
    <tr>
      <td><code>hops-chart-unselected-color</code></td>
      <td>The color of the unselected series in the hops chart</td>
      <td><code>Gray</code></td>
    </tr>
    <tr>
      <td><code>hops-chart-axis-color</code></td>
      <td>The color of the axis in the hops chart</td>
      <td><code>DarkGray</code></td>
    </tr>
    <tr>
      <td><code>frequency-chart-bar-color</code></td>
      <td>The color of bars in the frequency chart</td>
      <td><code>Green</code></td>
    </tr>
    <tr>
      <td><code>frequency-chart-text-color</code></td>
      <td>The color of text in the bars of the frequency chart</td>
      <td><code>Gray</code></td>
    </tr>
    <tr>
      <td><code>flows-chart-bar-selected-color</code></td>
      <td>The color of the selected flow bar in the flows chart</td>
      <td><code>Green</code></td>
    </tr>
    <tr>
      <td><code>flows-chart-bar-unselected-color</code></td>
      <td>The color of the unselected flow bar in the flows chart</td>
      <td><code>DarkGray</code></td>
    </tr>
    <tr>
      <td><code>flows-chart-text-current-color</code></td>
      <td>The color of the current flow text in the flows chart</td>
      <td><code>LightGreen</code></td>
    </tr>
    <tr>
      <td><code>flows-chart-text-non-current-color</code></td>
      <td>The color of the non-current flow text in the flows chart</td>
      <td><code>White</code></td>
    </tr>
    <tr>
      <td><code>samples-chart-color</code></td>
      <td>The color of the samples chart</td>
      <td><code>Yellow</code></td>
    </tr>
    <tr>
      <td><code>help-dialog-bg-color</code></td>
      <td>The background color of the help dialog</td>
      <td><code>Blue</code></td>
    </tr>
    <tr>
      <td><code>help-dialog-text-color</code></td>
      <td>The color of the text in the help dialog</td>
      <td><code>Gray</code></td>
    </tr>
    <tr>
      <td><code>settings-dialog-bg-color</code></td>
      <td>The background color of the settings dialog</td>
      <td><code>blue</code></td>
    </tr>
    <tr>
      <td><code>settings-tab-text-color</code></td>
      <td>The color of the text in settings dialog tabs</td>
      <td><code>green</code></td>
    </tr>
    <tr>
      <td><code>settings-table-header-text-color</code></td>
      <td>The color of text in the settings table header</td>
      <td><code>black</code></td>
    </tr>
    <tr>
      <td><code>settings-table-header-bg-color</code></td>
      <td>The background color of the settings table header</td>
      <td><code>white</code></td>
    </tr>
    <tr>
      <td><code>settings-table-row-text-color</code></td>
      <td>The color of text of rows in the settings table</td>
      <td><code>gray</code></td>
    </tr>
    <tr>
      <td><code>map-world-color</code></td>
      <td>The color of the map world diagram</td>
      <td><code>white</code></td>
    </tr>
    <tr>
      <td><code>map-radius-color</code></td>
      <td>The color of the map accuracy radius circle</td>
      <td><code>yellow</code></td>
    </tr>
    <tr>
      <td><code>map-selected-color</code></td>
      <td>The color of the map selected item box</td>
      <td><code>green</code></td>
    </tr>
    <tr>
      <td><code>map-info-panel-border-color</code></td>
      <td>The color of border of the map info panel</td>
      <td><code>gray</code></td>
    </tr>
    <tr>
      <td><code>map-info-panel-bg-color</code></td>
      <td>The background color of the map info panel</td>
      <td><code>black</code></td>
    </tr>
    <tr>
      <td><code>map-info-panel-text-color</code></td>
      <td>The color of text in the map info panel</td>
      <td><code>gray</code></td>
    </tr>
  </tbody>
</table>

<p>The supported colors are:</p>

<ul>
  <li><code>Black</code>, <code>Red</code>, <code>Green</code>, <code>Yellow</code>, <code>Blue</code>, <code>Magenta</code>, <code>Cyan</code>, <code>Gray</code>, <code>DarkGray</code>, <code>LightRed</code>, <code>LightGreen</code>, <code>LightYellow</code>, <code>LightBlue</code>, <code>LightMagenta</code>, <code>LightCyan</code>, <code>White</code></li>
</ul>

<p>Color names are case-insensitive and may contain dashes. Raw hex values, such as <code>ffffff</code> for white, may also be used.</p>

<h2 id="key-bindings-reference">Key Bindings Reference</h2>

<p>The following table lists the default Tui command key bindings. These can be overridden with the <code>--tui-key-bindings</code>
command line option.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>toggle-help</code></td>
      <td>Toggle help</td>
      <td><code>h</code></td>
    </tr>
    <tr>
      <td><code>toggle-help-alt</code></td>
      <td>Toggle help (alternative binding)</td>
      <td><code>?</code></td>
    </tr>
    <tr>
      <td><code>toggle-settings</code></td>
      <td>Toggle settings</td>
      <td><code>s</code></td>
    </tr>
    <tr>
      <td><code>next-hop</code></td>
      <td>Select next hop</td>
      <td><code>down</code></td>
    </tr>
    <tr>
      <td><code>previous-hop</code></td>
      <td>Select previous hop</td>
      <td><code>up</code></td>
    </tr>
    <tr>
      <td><code>next-trace</code></td>
      <td>Select next trace</td>
      <td><code>right</code></td>
    </tr>
    <tr>
      <td><code>previous-trace</code></td>
      <td>Select previous trace</td>
      <td><code>left</code></td>
    </tr>
    <tr>
      <td><code>next-hop-address</code></td>
      <td>Select next hop address</td>
      <td><code>.</code></td>
    </tr>
    <tr>
      <td><code>previous-hop-address</code></td>
      <td>Select previous hop address</td>
      <td><code>,</code></td>
    </tr>
    <tr>
      <td><code>address-mode-ip</code></td>
      <td>Show IP address only</td>
      <td><code>i</code></td>
    </tr>
    <tr>
      <td><code>address-mode-host</code></td>
      <td>Show hostname only</td>
      <td><code>n</code></td>
    </tr>
    <tr>
      <td><code>address-mode-both</code></td>
      <td>Show both IP address and hostname</td>
      <td><code>b</code></td>
    </tr>
    <tr>
      <td><code>toggle-freeze</code></td>
      <td>Toggle freezing the display</td>
      <td><code>ctrl+f</code></td>
    </tr>
    <tr>
      <td><code>toggle-chart</code></td>
      <td>Toggle the chart</td>
      <td><code>c</code></td>
    </tr>
    <tr>
      <td><code>toggle-map</code></td>
      <td>Toggle the GeoIp map</td>
      <td><code>m</code></td>
    </tr>
    <tr>
      <td><code>toggle-flows</code></td>
      <td>Toggle the flows</td>
      <td><code>f</code></td>
    </tr>
    <tr>
      <td><code>toggle-privacy</code></td>
      <td>Toggle the hop privacy</td>
      <td><code>p</code></td>
    </tr>
    <tr>
      <td><code>expand-hosts</code></td>
      <td>Expand the hosts shown per hop</td>
      <td><code>]</code></td>
    </tr>
    <tr>
      <td><code>expand-hosts-max</code></td>
      <td>Expand the hosts shown per hop to the maximum</td>
      <td><code>}</code></td>
    </tr>
    <tr>
      <td><code>contract-hosts</code></td>
      <td>Contract the hosts shown per hop</td>
      <td><code>[</code></td>
    </tr>
    <tr>
      <td><code>contract-hosts-min</code></td>
      <td>Contract the hosts shown per hop to the minimum</td>
      <td><code>{</code></td>
    </tr>
    <tr>
      <td><code>chart-zoom-in</code></td>
      <td>Zoom in the chart</td>
      <td><code>=</code></td>
    </tr>
    <tr>
      <td><code>chart-zoom-out</code></td>
      <td>Zoom out the chart</td>
      <td><code>-</code></td>
    </tr>
    <tr>
      <td><code>clear-trace-data</code></td>
      <td>Clear all trace data</td>
      <td><code>ctrl+r</code></td>
    </tr>
    <tr>
      <td><code>clear-dns-cache</code></td>
      <td>Flush the DNS cache</td>
      <td><code>ctrl+k</code></td>
    </tr>
    <tr>
      <td><code>clear-selection</code></td>
      <td>Clear the current selection</td>
      <td><code>esc</code></td>
    </tr>
    <tr>
      <td><code>toggle-as-info</code></td>
      <td>Toggle AS info display</td>
      <td><code>z</code></td>
    </tr>
    <tr>
      <td><code>toggle-hop-details</code></td>
      <td>Toggle hop details</td>
      <td><code>d</code></td>
    </tr>
    <tr>
      <td><code>quit</code></td>
      <td>Quit the application</td>
      <td><code>q</code></td>
    </tr>
  </tbody>
</table>

<p>The supported modifiers are: <code>shift</code>, <code>ctrl</code>, <code>alt</code>, <code>super</code>, <code>hyper</code> &amp; <code>meta</code>. Multiple modifiers may be specified, for
example <code>ctrl+shift+b</code>.</p>

<h2 id="configuration-reference">Configuration Reference</h2>

<p>Trippy can be configured with via command line arguments or an optional configuration file. If a given configuration
item is specified in both the configuration file and via a command line argument then the latter will take precedence.</p>

<p>The configuration file location may be provided to Trippy via the <code>-c</code> (<code>--config-file</code>) argument. If not provided,
Trippy will attempt to locate a <code>trippy.toml</code> or <code>.trippy.toml</code> configuration file in one of the following locations:</p>

<ul>
  <li>The current directory</li>
  <li>The user home directory</li>
  <li>the XDG config directory (Unix only): <code>$XDG_CONFIG_HOME</code> or <code>~/.config</code></li>
  <li>the Windows data directory (Windows only): <code>%APPDATA%</code></li>
</ul>

<p>An annotated template configuration file is available
for <a href="https://github.com/fujiapple852/trippy/blob/0.8.0/trippy-config-sample.toml">0.8.0</a>
and <a href="https://github.com/fujiapple852/trippy/blob/0.9.0/trippy-config-sample.toml">0.9.0</a>.</p>

<p>Trippy (version <code>0.9.0</code> or later) can generate a template configuration file:</p>

<div><pre><code>trip <span>--print-config-template</span> <span>&gt;</span> trippy.toml
</code></pre></div>

<h2 id="frequently-asked-questions">Frequently Asked Questions</h2>

<h3 id="why-does-trippy-show-awaiting-data">Why does Trippy show â€œAwaiting dataâ€¦â€?</h3>

<blockquote>
  <p>[!IMPORTANT]<br>
If you are using Windows you
<em>must</em> <a href="#how-do-i-allow-incoming-icmp-traffic-in-the-windows-defender-firewall">configure</a>
the Windows Defender firewall to allow incoming ICMP traffic</p>
</blockquote>

<p>When Trippy shows â€œAwaiting dataâ€¦â€ it means that it has received zero responses for the probes sent in a trace. This
indicates that either probes are not being sent or, more typically, responses are not being received.</p>

<p>Check that local and network firewalls allow ICMP traffic and that the system <code>traceroute</code> (or <code>tracert.exe</code> on
Windows) works as expected. Note that on Windows, even if <code>tracert.exe</code> works as expected, you
<em>must</em> <a href="#how-do-i-allow-incoming-icmp-traffic-in-the-windows-defender-firewall">configure</a> the Windows Defender
firewall to allow incoming ICMP traffic.</p>

<p>For deeper diagnostics you can run tools such as https://www.wireshark.org and https://www.tcpdump.org to verify that
icmp requests and responses are being send and received.</p>



<h3 id="how-do-i-allow-incoming-icmp-traffic-in-the-windows-defender-firewall">How do I allow incoming ICMP traffic in the Windows Defender firewall?</h3>

<p>The Windows Defender firewall rule can be created using PowerShell:</p>

<div><pre><code>New-NetFirewallRule <span>-DisplayName</span> <span>"ICMP Trippy Allow"</span> <span>-Name</span> ICMP_TRIPPY_ALLOW <span>-Protocol</span> ICMPv4 <span>-Action</span> Allow
</code></pre></div>

<p>The rule can be enabled and disabled as follows:</p>

<div><pre><code>Enable-NetFirewallRule ICMP_TRIPPY_ALLOW
Disable-NetFirewallRule ICMP_TRIPPY_ALLOW
</code></pre></div>

<p>The Windows Defender firewall rule may also be configured manually,
see <a href="https://github.com/fujiapple852/trippy/issues/578#issuecomment-1565149826">here</a> for a step-by-step guide.</p>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>Trippy is made possible by <a href="https://github.com/ratatui-org/ratatui">ratatui</a> (
formerly <a href="https://github.com/fdehau/tui-rs">tui-rs</a>),
<a href="https://github.com/crossterm-rs/crossterm">crossterm</a> as well
as <a href="https://github.com/fujiapple852/trippy/blob/master/Cargo.toml">several</a> foundational Rust libraries.</p>

<p>Trippy draws heavily from <a href="https://github.com/traviscross/mtr">mtr</a> and also incorporates ideas
from both <a href="https://github.com/libparistraceroute/libparistraceroute">libparistraceroute</a>
&amp; <a href="https://github.com/insomniacslk/dublin-traceroute">Dublin Traceroute</a>.</p>

<p>The Trippy networking code is inspired by <a href="https://github.com/libpnet/libpnet">pnet</a> and some elements of that codebase
are incorporated in Trippy.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Autonomous_system_(Internet)">AS</a> data is retrieved from
the <a href="https://team-cymru.com/community-services/ip-asn-mapping/#dns">IP to ASN Mapping Service</a> provided
by <a href="https://team-cymru.com/">Team Cymru</a>.</p>

<p>The <a href="https://trippy.cli.rs/">trippy.cli.rs</a> CNAME hosting is provided by <a href="https://cli.rs/">cli.rs</a>.</p>

<h2 id="license">License</h2>

<p>This project is distributed under the terms of the Apache License (Version 2.0).</p>

<p>Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in time by you, as defined
in the Apache-2.0 license, shall be licensed as above, without any additional terms or conditions.</p>

<p>See <a href="https://trippy.cli.rs/LICENSE">LICENSE</a> for details.</p>

<p>Copyright 2022 <a href="https://github.com/fujiapple852/trippy/graphs/contributors">Trippy Contributors</a></p>


      
      
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Waveterm (136 pts)]]></title>
            <link>https://www.waveterm.dev/</link>
            <guid>38588790</guid>
            <pubDate>Sun, 10 Dec 2023 03:33:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.waveterm.dev/">https://www.waveterm.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=38588790">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-framer-name="Frame 624716" name="Frame 624716"><div><p>Open Source and Extensible</p></div><div><p>Open Source and Extensible</p></div><div><p>Open Source and Extensible</p></div><div><p>Open Source and Extensible</p></div><div><p>Wave is open-source, Apache 2.0 License, and designed for extensibility. We would love to work with you to add additional renderers and applications into Wave. Please suggest extensions you'd like to see in Wave or, better yet, contribute one!</p></div><div><p>Wave is open-source, Apache 2.0 License, and designed for extensibility. We would love to work with you to add additional renderers and applications into Wave. Please suggest extensions you'd like to see in Wave or, better yet, contribute one!</p></div><div><p>Wave is open-source, Apache 2.0 License, and designed for extensibility. We would love to work with you to add additional renderers and applications into Wave. Please suggest extensions you'd like to see in Wave or, better yet, contribute one!</p></div><div><p>Wave is open-source, Apache 2.0 License, and designed for extensibility. We would love to work with you to add additional renderers and applications into Wave. Please suggest extensions you'd like to see in Wave or, better yet, contribute one!</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cramming a tiny program into a tiny ELF file (111 pts)]]></title>
            <link>https://tmpout.sh/3/22.html</link>
            <guid>38588379</guid>
            <pubDate>Sun, 10 Dec 2023 02:12:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tmpout.sh/3/22.html">https://tmpout.sh/3/22.html</a>, See on <a href="https://news.ycombinator.com/item?id=38588379">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><pre>                                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                       â–„â–„â–„â–„â–„ â–„â–„â–„â–„â–„ â–„â–„â–„â–„â–„       â”‚
                                                       â”‚ â–ˆ   â–ˆ â–ˆ â–ˆ â–ˆ   â–ˆ       â”‚
                                                       â”‚ â–ˆ   â–ˆ â–ˆ â–ˆ â–ˆâ–€â–€â–€â–€       â”‚
                                                       â”‚ â–ˆ   â–ˆ   â–ˆ â–ˆ     â–„     â”‚
                                                       â”‚                 â–„â–„â–„â–„â–„ â”‚
                                                       â”‚                 â–ˆ   â–ˆ â”‚
                                                       â”‚                 â–ˆ   â–ˆ â”‚
                                                       â”‚                 â–ˆâ–„â–„â–„â–ˆ â”‚
                                                       â”‚                 â–„   â–„ â”‚
                                                       â”‚                 â–ˆ   â–ˆ â”‚
                                                       â”‚                 â–ˆ   â–ˆ â”‚
                                                       â”‚                 â–ˆâ–„â–„â–„â–ˆ â”‚
                                                       â”‚                 â–„â–„â–„â–„â–„ â”‚
Cramming a Tiny Program into a Tiny ELF File:          â”‚                   â–ˆ   â”‚
A Case Study                                           â”‚                   â–ˆ   â”‚
~ lm978                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ˆ â”€â”€â”˜

-- Introduction ----------------------------------------------------------------

Last fall, I was rereading Brian Raiter's article on tiny ELF programs [1], when
I decided to try the challenge myself and create the tiniest x86_64 ELF program
on Linux; I was unaware at the time of others' attempts to answer the question.
To avoid missing any edge cases that could help, I decided to work from first
principles, reading the source of the Linux kernel's ELF loader and deriving
the requirements from that. At first, after ruling out all smaller offsets of
the program header, I concluded that offset 0x18 was the smallest possible,
yielding an 80-byte program that returns 42:

00000000: 7f45 4c46 b0e7 40b7 2a0f 0500 0000 0000  .ELF..@.*.......
00000010: 0200 3e00 0000 0000 0100 0000 0100 0000  ..&gt;.............
00000020: 1800 0000 0000 0000 1800 0000 0100 0000  ................
00000030: 0000 0000 0000 3800 0100 0000 0000 0000  ......8.........
00000040: 0100 0000 0000 0000 0000 0000 0000 0000  ................

(This 80-byte size was already known by Brian Raiter and a few others [2],
though not widely publicized.) This summer, I found Nathan Otterness's 2021
article [3] concluding that 105 bytes is the minimum size, and to put the issue
to rest, I decided to write my own article with a full analysis of the 80-byte
minimum.

However, in the process of repeating my analysis, I remembered that I had only
considered executables of type ET_EXEC, and not ET_DYN. As it turned out, this
was a mistake: with ET_DYN, the program header can just barely be placed at
offset 0xc. Annoyingly, the entry point is fixed to the 'jg .+0x47' at the very
start of the file, so another jump has to be placed at offset 0x47, past the end
of the headers. Overall, this yields a 73-byte program that returns 42:

00000000: 7f45 4c46 b0e7 40b7 2a0f 0500 0100 0000  .ELF..@.*.......
00000010: 0300 3e00 0c00 0000 0000 0000 0c00 0000  ..&gt;.............
00000020: 0c00 0000 0000 0000 0000 0000 0000 3800  ..............8.
00000030: 0100 0000 0000 3800 0100 0000 0000 0000  ......8.........
00000040: 0000 0000 0000 00eb bb                   .........

Unless I made another mistake, this is the absolute minimum size for an ELF file
containing an x86_64 program, modulo the precise definition of a "program". I
plan to publish the full analysis later this year.

-- A Simple Challenge, and a Straightforward Solution --------------------------

But once I had established the minimum size, I was inspired by Otterness's
article to turn it into the tiniest x86_64 Hello World program. The natural
rules for this challenge are pretty simple: write the 14 bytes "Hello, world!\n"
to stdout, exit with code 0, and produce no other side effects. Of course, the
actual process of golfing the program is far from simple.

First, let's start with our 80-byte pattern, which doesn't include a mandatory
instruction at offset 0x47. This allows us to put our entire 14-byte string at
offset 0x48, immediately following phdr-&gt;p_memsz. To place our instructions so
that they won't interfere with the header fields, we can use a template that I
created in my analysis:

00000000: 7f45 4c46 **** **** **** **** **** ****  .ELF............
00000010: 0200 3e00 **** **** 0100 0000 pppp pp00  ..&gt;.............
00000020: 1800 0000 0000 0000 1800 0000 pppp pp00  ................
00000030: **** **** **** 3800 0100 qqqq qqqq qq00  ......8.........
00000040: 0100 qqqq qqqq qq00 **** **** **** ****  ................

Here, the p, q, and * characters are all placeholders. There are a couple extra
restrictions on their values for the program to be loadable. 0xpppppp must be
odd, so that phdr-&gt;p_flags includes PF_X. Also, if the system doesn't support
5-level paging, then 0xpppppp can't be larger than 0x007fff, and 0xqqqqqqqqqq
can't be larger than 0x007fffffff.

The template has enough space for us to write our program with a straightforward
instruction sequence, with no special tricks necessary, apart from using
'pop rdi' to set rdi to 1. The value comes from argc, as saved onto the initial
process stack by the kernel. Adapting this sequence to work when argc != 1 is
left as an exercise to the reader.

0x1:
  rex.RB rex.WR rex.RX  /* "ELF" in ELFMAG                 */
  mov al, 1             /* nr = 1 = __NR_write             */
  pop rdi               /* fd = argc = 1                   */
  lea rsi, [rip+0x3a]   /* buf = "Hello, world!\n"         */
  jmp 0x14
0x14:
  mov dl, 14            /* count = 14                      */
  jmp 0x30
0x30:
  syscall               /* write(1, "Hello, world!\n", 14) */
  mov al, 231           /* nr = 231 = __NR_exit_group      */
  jmp 0x3a
0x3a:
  xor edi, edi          /* error_code = 0                  */
  syscall               /* exit_group(0)                   */
0x48:
  .ascii "Hello, world!\n"

This yields an 86-byte Hello World program:

00000000: 7f45 4c46 b001 5f48 8d35 3a00 0000 eb04  .ELF.._H.5:.....
00000010: 0300 3e00 b20e eb18 0100 0000 0100 0000  ..&gt;.............
00000020: 1800 0000 0000 0000 1800 0000 0100 0000  ................
00000030: 0f05 b0e7 eb04 3800 0100 31ff 0f05 0000  ......8...1.....
00000040: 0100 31ff 0f05 0000 4865 6c6c 6f2c 2077  ..1.....Hello, w
00000050: 6f72 6c64 210a                           orld!.

Clearly, this is the tiniest program we can write while keeping the string in
one piece: the template doesn't let us put it any earlier in the file. Even our
offset-0xc pattern doesn't help: there are only 11 bytes of free space before
the mandatory jump instruction, so the 14-byte string would have to be placed
after it, at offset 0x49. If we want to make the program any tinier, we'll have
to divide the string into multiple chunks in the file, then reassemble them at
runtime.

-- Division and Reassembly -----------------------------------------------------

When we divide the string, it makes sense to use the offset-0xc pattern instead
of the longer offset-0x18 pattern. The template for this offset includes a long
block of 28 immutable header bytes after the initial free space:

00000000: 7f45 4c46 **** **** **** **** 0100 0000  .ELF............
00000010: 0300 3e00 0c00 0000 0000 0000 0c00 0000  ..&gt;.............
00000020: 0c00 0000 0000 0000 **** **** pppp pppp  ................
00000030: pppp pp00 qqqq 3800 0100 rr00 **** ****  ......8.........
00000040: **** ****                                ..

In this case, we have phdr-&gt;p_filesz = 0x00pppppppppppppp and phdr-&gt;p_memsz =
0x00rr00010038qqqq, with three different alternatives for their values. Either

1. the file size &lt;= phdr-&gt;p_filesz &lt;= 0xfff;
2. phdr-&gt;p_filesz == phdr-&gt;p_memsz; or
3. phdr-&gt;p_filesz &lt; phdr-&gt;p_memsz, and (phdr-&gt;p_filesz &amp; 0xfff) == 0xff4.

In practice, we'll be using the 3rd alternative, so that we can store additional
instructions within phdr-&gt;p_filesz. Once again, if the system doesn't support
5-level paging, then the two values must both be at most 0x00007fffffffffff (or
rather, a few megabytes less, to leave room for the process stack). Also, if the
system *does* support 5-level paging, and phdr-&gt;p_memsz is above that size, then
the vm.overcommit_memory sysctl must be set to 1 ("always overcommit"), to allow
the kernel to map enough terabytes of read-write memory.

When reassembling the string from two parts, we need to write it into a region
of writable memory. This leaves us a choice: should we push it onto the stack,
or should we write it into the program image, which is mapped as WX? The stack
can be written to very easily, using the family of 'push' instructions. But the
program image already contains one of the parts, leaving only the other part to
be written.

For now, let's start with an approach writing to the program image. We can
actually still join the two parts with a 'push' instruction, if we first use a
'pop rsp' to replace the stack pointer with a pointer into the image. To obtain
this pointer, we can replace a 'jmp rel8' with a 'call rel32', adding only 3
bytes to the instruction sequence, down from the 7 bytes required by a typical
'lea r64, [rip+disp32]'. Then, to minimize stack wrangling, we can place the
'call' directly before "orld!\n", so that 'pop rsp; push r64' is sufficient to
join the two parts. Finally, prior to the 'call', we can use an ordinary
'mov r64, imm64' to load the first part "Hello, w" into a register.

When fitting the instructions into the template, we must be careful to satisfy
the 0xff4 requirement on phdr-&gt;p_filesz: its first byte must be 0xf4, and its
second byte must be 0x0f, 0x1f, ..., or 0xff. Best utilizing these two bytes is
one of our main goals in arranging the sequence. The first byte can be either
skipped past with a dummy instruction like 'test al, 0xf4' (a8 f4), or used at
the end of a 3-byte encoding of 'mov rsi, rsp' (48 8b f4). Meanwhile, the second
byte can be used for 'syscall' (0f 05), 'pop rdi' (5f), or any of the multibyte
encodings of 'pop r/m64' (8f ...) or 'push r/m64' (ff ...).

Altogether, we have a somewhat twisty instruction sequence, starting with a
'jrcxz 0x3c' to jump to the first instruction of the trailing free space, and
using both 'mov rsi, rsp' and 'pop rdi' to cover the 0xff4 in phdr-&gt;p_filesz.
The resulting file takes 84 bytes.

0x0:
  jg 0x47                      /* "\177E" in ELFMAG               */
0x47:
  jrcxz 0x3c
0x3c:
  pop rax                      /* nr = argc = 1 = __NR_write      */
  mov rcx, 0x77202c6f6c6c6548  /* rcx = 'Hello, w'                */
  jrcxz 0x3c                   /* (not taken)                     */
  call 0x28                    /* [rsp] = "orld!\n"               */
  .ascii "orld!\n"
0x28:
  pop rsp                      /* rsp = "orld!\n"                 */
  push rax                     /* [rsp] = 1                       */
  mov rsi, rsp /* 48 8b f4 */  /* buf + 0x8 = "orld!\n"           */
  pop rdi      /* 5f */        /* fd = 1                          */
  push rcx                     /* buf = "Hello, world!\n"         */
  mov dl, 14                   /* len = 14                        */
  jmp 0x4
0x4:
  syscall                      /* write(1, "Hello, world!\n", 14) */
  mov al, 231                  /* nr = 231 = __NR_exit_group      */
  xor edi, edi                 /* error_code = 0                  */
  syscall                      /* exit_group(0)                   */

00000000: 7f45 4c46 0f05 b0e7 31ff 0f05 0100 0000  .ELF....1.......
00000010: 0300 3e00 0c00 0000 0000 0000 0c00 0000  ..&gt;.............
00000020: 0c00 0000 0000 0000 5c50 488b f45f 51b2  ........\PH.._Q.
00000030: 0eeb d100 0000 3800 0100 d200 5848 b948  ......8.....XH.H
00000040: 656c 6c6f 2c20 77e3 f3e8 daff ffff 6f72  ello, w.......or
00000050: 6c64 210a                                ld!.

Since phdr-&gt;p_memsz = 0x00d2000100380000, this program requires 5-level paging
to run. Luckily, even if you don't own a recent Intel Xeon processor that
supports it natively, you can emulate 5-level paging with QEMU and a guest that
enables CONFIG_X86_5LEVEL in its kernel. Personally, I use a premade Arch Linux
VM image [4], since it is small and quick to boot. Emulating 5-level paging in
QEMU just takes an extra argument to set the CPU model:

$ qemu-system-x86_64 -cpu qemu64,la57 -m 512 Arch-Linux-x86_64-basic.qcow2

[arch@archlinux ~]$ sudo sysctl vm.overcommit_memory=1
vm.overcommit_memory = 1
[arch@archlinux ~]$ ./program; echo $?
Hello, world!
0

At this point, our main bottleneck for improving the size is the big fat 5-byte
'call rel32' before the "orld!\n" part; it blocks us from moving that part any
earlier in the file. One approach to avoid the call is to use two imm64 operands
to load the two parts, but that would require placing the 'mov' instruction for
the "Hello, w" part at offset 0x49 or later, and ultimately it wouldn't end up
saving any bytes at all. If only we had some way to separate the strings from
the instructions, so as to use fewer bytes in the trailing free space...

-- The Almighty SYSCALL Instruction --------------------------------------------

The AMD64 psABI [5] has something curious to say about syscalls on Linux:

  A system-call is done via the syscall instruction. The kernel destroys
  registers %rcx and %r11.

This is pretty vague; what nefarious things could the kernel possibly be doing
with those registers!? The answer lies not in the psABI, but in the entry for
the SYSRET instruction in Intel's SDM (and its counterpart in AMD's manual):

  SYSRET is a companion instruction to the SYSCALL instruction. It returns
  from an OS system-call handler to user code at privilege level 3. It does so
  by loading RIP from RCX and loading RFLAGS from R11.

This means that rcx is effectively guaranteed to contain the return address on
return from a 'syscall' instruction. Thus, after running a syscall (even one
that has no external side effects), we have a pointer into the program image,
which we can use to push 8 bytes from anywhere in the file onto the stack, with
only a 3-byte 'push [rcx+disp8]'.

A no-op 'syscall' at the start of the instruction sequence costs us 2 extra
bytes, but we can make up for it by using only 4 basic blocks instead of 5,
saving a 2-byte jump instruction. We can use the conveniently-sized 8-byte space
at offset 0x4 to store the "Hello, w" part, and leave the "orld!\n" part at the
end of the file. Then, at runtime, we can push the two parts to the stack with a
pair of 'push' instructions.

Thus, by the power of the almighty SYSCALL instruction, we can make our code a
bit less twisty, and thereby shrink our file from 84 to 81 bytes.

0x0:
  jg 0x47                      /* "\177E" in ELFMAG               */
0x4:
  .ascii "Hello, w"
0x47:
  jrcxz 0x3c
0x3c:
  syscall                      /* read(0, NULL, 0)                */
  pop rax                      /* nr = argc = 1 = __NR_write      */
  push rax                     /* [rsp] = 1                       */
  pop rdi                      /* fd = 1                          */
  push [rcx+0xd]               /* rsp = "orld!\n"                 */
  push [rcx-0x3a]              /* rsp = "Hello, world!\n"         */
  jrcxz 0x3c                   /* (not taken)                     */
  jmp 0x28
  .ascii "orld!\n"
0x28:
  mov dl, 14                   /* len = 14                        */
  mov rsi, rsp /* 48 8b f4 */  /* buf = "Hello, world!\n"         */
  syscall      /* 0f 05 */     /* write(1, "Hello, world!\n", 14) */
  mov al, 231                  /* nr = 231 = __NR_exit_group      */
  mov dil, 0x0 /* 40 b7 00 */  /* error_code = 0                  */
  syscall                      /* exit_group(0)                   */

00000000: 7f45 4c46 4865 6c6c 6f2c 2077 0100 0000  .ELFHello, w....
00000010: 0300 3e00 0c00 0000 0000 0000 0c00 0000  ..&gt;.............
00000020: 0c00 0000 0000 0000 b20e 488b f40f 05b0  ..........H.....
00000030: e740 b700 0f05 3800 0100 b800 0f05 5850  .@....8.......XP
00000040: 5fff 710d ff71 c6e3 f3eb dd6f 726c 6421  _.q..q.....orld!
00000050: 0a                                       .

(Note that as our no-op syscall, we attempt to read the stdin stream for 0
bytes. Could this be considered a side effect? If stdin is redirected to a
special file from some random driver or subsystem in the kernel, pretty much
anything could happen when it receives a 0-byte read request from userspace.
However, apart from FUSE, I am not aware of any driver that doesn't simply
discard or reject such a read request, so I wouldn't consider this a serious
issue.)

-- Ouroboros Programming -------------------------------------------------------

  á½ &lt;Î´á½²&gt; ÎºÏÎºÎ»Î¿Ï‚ á¼Ï€Î¯Ï€ÎµÎ´Î¿Î½ ÏƒÏ‡á¿†Î¼Î¬ á¼ÏƒÏ„Î¹Î½ á½‘Ï€á½¸ Î¼Î¹á¾¶Ï‚ Î³ÏÎ±Î¼Î¼á¿†Ï‚ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿Î½, ÎºÎ±á½¶ Ï„Î±ÏÏ„á¿ƒ
  ÎºÏ…ÎºÎ»Î¹Îºá½¸Î½ á½€Î½Î¿Î¼Î¬Î¶ÎµÏ„Î±Î¹ ÏƒÏ‡á¿†Î¼Î± á¼€Ï†' á¼‘Î±Ï…Ï„Î¿á¿¦ á¼€ÏÏ‡ÏŒÎ¼ÎµÎ½Î¿Î½ ÎºÎ±á½¶ Îµá¼°Ï‚ á¼‘Î±Ï…Ï„á½¸Î½ á¼€Î½Î±ÏƒÏ„ÏÎ­Ï†Î¿Î½Ï„Î¿Ï‚
  ÎºÎ±á½¶ Î¼Î·Î´Î±Î¼Î¿á¿¦ Ï€ÎµÏÎ±Ï„Î¿Ï…Î¼Î­Î½Î¿Ï…. á½…Î¸ÎµÎ½ ÎºÎ±á½¶ Î‘á¼°Î³ÏÏ€Ï„Î¹Î¿Î¹ ÎºÎ±Î¸' á¼±ÎµÏá½¸Î½ Î»ÏŒÎ³Î¿Î½ Î´ÏÎ¬ÎºÎ¿Î½Ï„Î±
  Î¿á½ÏÎ·Î²ÏŒÏÎ¿Î½ Ï„Î±á¿–Ï‚ Ï€Ï…ÏÎ±Î¼Î¯ÏƒÎ¹Î½ á¼Î³Î³Î»ÏÏ†Î¿Ï…ÏƒÎ¹Î½. [6]

  Now, the circle is a plane figure bounded by a single line, and thus a shape
  that begins from itself and ends with itself is called "circular"--which is
  particularly [true of] time which returns into itself and is never
  terminated. Hence also the Egyptians, in accordance with a sacred discourse,
  carve a serpent eating its tail on their pyramids. [7]

So says John Lydus (translated by Mischa Hooker) regarding the symbol of the
ouroboros. Though our program is required to terminate, we can design it so that
it returns into itself, as the ouroboros does. At this point, our instruction
sequence both begins and ends with a 'syscall', and we are already forced to
jump from the end to the start. Thus, we can close the circle, letting the
instruction pointer advance once more into the initial 'syscall', so that we no
longer need the final 'syscall'. This allows us to save 2 bytes.

However, adapting the program in this way isn't entirely trivial, since we can't
use 'mov rsi, rsp' to cover the 0xf4 byte in phdr-&gt;p_filesz. (There's no way to
set rsp to its final value early enough in the code.) Instead, we can use that
byte to help us set rax to 1. First, we write 'cmp al, 0xf4' (3c f4), covering
the 0xf4 byte. Since al is 0 at this point, the comparison will always set the
carry flag. Then, at the end of phdr-&gt;p_filesz, we write 'adc al, 0x0' (14 00),
covering the 0x00 byte. As long as the carry flag is not cleard between the two
instructions, the latter will set al to 1, as desired.

However, there's a catch to this trick. It only works      .----.
if rax starts at 0, but our program begins with the      .' o  /------.
no-op read(0, NULL, 0) syscall, which uses rax for      /     /SYSCALL '-.
its return value. If it fails, rax will be set to a    '   JMP'.-----.POP '.
negative errno value, and our trick won't set it to    | OR     '.    '-.CM \
1 properly. Thus, for our program to work, stdin      / X .-----'        \ P \
must be a readable stream. Since lots of command-    / V /     .          \ P \
line applications can't cope with a missing or      ' O .      |\          . U '
bizzare stdin stream, I think that this is a        | M | .----' '------.  | S |
reasonable restriction for a Hello World            | L | |Hello, world!|  | H |
program, akin to requiring that argc == 1.          | L | '-------------'  | M |
                                                    . A '                  ' O .
When we remove the final 'syscall', rotate the       \ C \                / V /
program so it returns to the initial 'syscall',       \ S \              / A /
and use our trick to set rax to 1, we obtain a         \ YS'-.        .-'CD /
79-byte program. Now, our Hello World has become        '. POP'------'PMJ .'
even tinier than the original return-42 program!          '-. HSUPHSUP .-'
                                                             '--------'
0x0:
  jg 0x47                         /* "\177E" in ELFMAG               */
0x4:
  .ascii "Hello, w"
0x47:
  jmp 0x28
  .ascii "orld!\n"
0x28:
  syscall                         /* read(0, NULL, 0) = 0            */
  pop rdi                         /* fd = argc = 1                   */
  cmp al, 0xf4    /* 3c f4 */     /* CF = 1                          */
  push [rcx+0x1f] /* ff 71 1f */  /* rsp = "orld!\n"                 */
  mov dl, 14                      /* len = 14                        */
  adc al, 0x0     /* 14 00 */     /* nr = 1 = __NR_write             */
  jmp 0x3c
0x3c:
  push [rcx-0x26]                 /* rsp = "Hello, world!\n"         */
  push rsp                        /* [rsp] = "Hello, world!\n"       */
  pop rsi                         /* buf = "Hello, world!\n"         */
  syscall                         /* write(1, "Hello, world!\n", 14) */
  mov al, 231                     /* nr = 231 = __NR_exit_group      */
  xor edi, edi                    /* error_code = 0                  */
  jmp 0x28
0x28:
  syscall                         /* exit_group(0)                   */

00000000: 7f45 4c46 4865 6c6c 6f2c 2077 0100 0000  .ELFHello, w....
00000010: 0300 3e00 0c00 0000 0000 0000 0c00 0000  ..&gt;.............
00000020: 0c00 0000 0000 0000 0f05 5f3c f4ff 711f  .........._&lt;..q.
00000030: b20e 1400 eb06 3800 0100 1500 ff71 da54  ......8......q.T
00000040: 5e0f 05b0 e731 ffeb df6f 726c 6421 0a    ^....1...orld!.

-- Tightening the Loop ---------------------------------------------------------

Recall that the ouroboros begins from itself and ends with itself. In the art of
Ouroboros Programming, we must unify the beginning and the end, creating a whole
that encompasses both. Our program begins by setting the arguments for write(),
and ends by setting the arguments for exit_group(). How can we turn these two
sections into one, so that we only need a single 'syscall' instruction?

Since it has only one argument, exit_group() is pretty simple to call. We can
modify the logic of the larger part of the loop so that it sets rax = __NR_write
and rdi = 1 on the first iteration, then sets rax = __NR_exit_group and rdi = 0
on the second iteration. We can leave the rest of the logic unmodified, since it
only sets the value of rsi after pushing the two parts.

Setting rdi is trivial: since we already have 'pop rdi' early in the program to
set its value to argc = 1, we can push a 0 to the stack right before calling
write(), so it will be read by 'pop rdi'. Meanwhile, setting rax is trickier,
since we want it to have a large initial value only on the second iteration.
Luckily, we can do this with only 1 additional byte, by adding 'xchg ebx, eax'
to the start of the loop, and 'mov bl, 230' at the end of the loop. (The loop
increments al by 1, so by the end of the second iteration, rax will become
__NR_exit_group = 231.)

Finally, since there's no more room for the "orld!\n" part at the end of the
file, we can move it over to offset 0x3c, so that the jump can skip right past
it. Compared to the last program, we have added 1 byte to 'mov al, 231', and
removed 1 byte from 'xor edi, edi', so those balance out. We still save 2 bytes
from merging the two 'syscall' instructions, so our program is now 77 bytes.

0x0:
  jg 0x47                         /* "\177E" in ELFMAG               */
0x4:
  .ascii "Hello, w"
0x3c:
  .ascii "orld!\n"
0x47:
  syscall                         /* read(0, NULL, 0) = 0            */
  xchg ebx, eax                   /* (no-op)                         */
  pop rdi                         /* fd = argc = 1                   */
  jmp 0x28
0x28:
  push [rcx-0xd]                  /* rsp = "orld!\n"                 */
  cmp al, 0xf4    /* 3c f4 */     /* CF = 1                          */
  push [rcx-0x45] /* ff 71 bb */  /* rsp = "Hello, world!\n"         */
  push rsp                        /* [rsp] = "Hello, world!\n"       */
  pop rsi                         /* buf = "Hello, world!\n"         */
  adc al, 0x0     /* 14 00 */     /* nr = 1 = __NR_write             */
  jmp 0x42
0x42:
  push rdx                        /* [rsp] = 0                       */
  mov dl, 14                      /* len = 14                        */
  mov bl, 230                     /* rbx = 230                       */
  syscall                         /* write(1, "Hello, world!\n", 14) */
  xchg ebx, eax                   /* nr = 230                        */
  pop rdi                         /* error_code = 0                  */
  jmp 0x28
0x28:
  push [rcx-0xd]
  cmp al, 0xf4    /* 3c f4 */     /* CF = 1                          */
  push [rcx-0x45] /* ff 71 bb */
  push rsp
  pop rsi
  adc al, 0x0     /* 14 00 */     /* nr = 231 = __NR_exit_group      */
  jmp 0x42
0x42:
  push rdx
  mov dl, 14
  mov bl, 230
  syscall                         /* exit_group(0)                   */

00000000: 7f45 4c46 4865 6c6c 6f2c 2077 0100 0000  .ELFHello, w....
00000010: 0300 3e00 0c00 0000 0000 0000 0c00 0000  ..&gt;.............
00000020: 0c00 0000 0000 0000 ff71 f33c f4ff 71bb  .........q.&lt;..q.
00000030: 545e 1400 eb0c 3800 0100 1500 6f72 6c64  T^....8.....orld
00000040: 210a 52b2 0eb3 e60f 0593 5feb db         !.R......._..

This is the end of the line: I don't know of any trick, method, or strategy that
can make this program any tinier. I'm reluctant to say that this is the absolute
minimum size; after all, anything can happen with self-modifying code, and
there's too much free space to simulate every wild possibility of what it could
do. However, I doubt that this program could be made any smaller through
conventional means.

-- Hello World in the Real World -----------------------------------------------

The tinier versions of this program have all required 5-level paging, to get as
much use as possible out of phdr-&gt;p_filesz. It would be nice if we could have a
slightly longer program that anyone can run at home, outside of a VM. Adapting
our program in this way isn't actually all that difficult: the main difference
is that phdr-&gt;p_filesz has to end in four 0x00 bytes, so that it doesn't become
greater than phdr-&gt;p_memsz. We can reuse these bytes within an 'adc eax, 0x0'
(15 00 00 00 00) instruction, to set rax to 1.

Apart from that, adapting the program to 4-level paging just involves rotating
the instructions around. The version presented here is 81 bytes, but I'm not
quite so certain that a conventional 80-byte version isn't possible.

0x0:
  jg 0x47                    /* "\177E" in ELFMAG               */
0x4:
  .ascii "Hello, w"
0x3c:
  .ascii "orld!\n"
0x47:
  syscall                    /* read(0, NULL, 0) = 0            */
  jmp 0x28
0x28:
  xchg ebx, eax              /* (no-op)                         */
  mov dl, 14                 /* len = 14                        */
  cmp al, 0xf4 /* 3c f4 */   /* CF = 1                          */
  pop rdi                    /* fd = argc = 1                   */
  nop
  adc eax, 0x0 /* 15 ... */  /* nr = 1 = __NR_write             */
  jmp 0x3c
0x3c:
  push [rcx+0x2]             /* rsp = "orld!\n"                 */
  push [rcx-0x45]            /* rsp = "Hello, world!\n"         */
  push rsp                   /* [rsp] = "Hello, world!\n"       */
  pop rsi                    /* buf = "Hello, world!\n"         */
  mov bl, 230                /* rbx = 230                       */
  push rbp                   /* [rsp] = 0                       */
  syscall                    /* write(1, "Hello, world!\n", 14) */
  jmp 0x28
0x28:
  xchg ebx, eax              /* nr = 230                        */
  mov dl, 14
  cmp al, 0xf4 /* 3c f4 */   /* CF = 1                          */
  pop rdi                    /* error_code = 0                  */
  nop
  adc eax, 0x0 /* 15 ...*/   /* nr = 231 = __NR_exit_group      */
  jmp 0x3c
0x3c:
  push [rcx+0x2]
  push [rcx-0x45]
  push rsp
  pop rsi
  mov bl, 230
  push rbp
  syscall                    /* exit_group(0)                   */

00000000: 7f45 4c46 4865 6c6c 6f2c 2077 0100 0000  .ELFHello, w....
00000010: 0300 3e00 0c00 0000 0000 0000 0c00 0000  ..&gt;.............
00000020: 0c00 0000 0000 0000 93b2 0e3c f45f 9015  ...........&lt;._..
00000030: 0000 0000 eb06 3800 0100 0000 ff71 02ff  ......8......q..
00000040: 71bb 545e b3e6 550f 05eb dd6f 726c 6421  q.T^..U....orld!
00000050: 0a                                       .

-- Conclusion ------------------------------------------------------------------

This entire task has perhaps been not very exciting from an ELF perspective;
we've merely golfed a short x86_64 program within the peculiar constraints set
out at the beginning. However, I think tasks like these provide partial answers
to the eternal question of Kolmogorov complexity: "What sorts of programs can be
expressed within an ELF file of a given length?" I've always been fascinated by
this, since clearly any given program has an optimal length, as a mathematical
property of the kernel and the processor. And as far as I know, the question for
ELF files hasn't been studied very thoroughly; since any programs has to work
around the headers, the format has been relatively unpopular for sizecoding. (Or
perhaps the unpopularity just stems from the lack of simple MMIO on Linux...)

Regardless, I hope that this can serve as a case study of the sort of "thinking
outside the box" that can be helpful when golfing binary programs. At many
points while writing this, I thought that I'd surely reached the limit of how
tiny I could make the program, only for that limit to be broken by a brand-new
technique different from what I'd previously been trying. Much of this, I think,
arises from the flexiblity of control flow in binary code: a jump is no larger
than any other instruction, so even with only a few basic blocks, there are
countless ways to thread the program execution between them.

This is particularly exemplified by my dramatically-named Ouroboros Programming
(for which I am sure a more appropriate name already exists). Most instructions
are general-purpose, so instead of thinking only in terms of an instruction's
immediate function, we can also consider all of its possible alternative
functions. Thus, a 'syscall' instruction isn't just some particular syscall, but
every single syscall in the kernel that we're able to set up the arguments for.
And a 'pop' instruction doesn't care whether we used a 'push' to store the data
behind [rsp]; it just cares that it ended up there one way or another.

It all raises the question, just how much code could we be reusing for multiple
purposes in our golfed programs, if only the opportunities weren't so difficult
to recognize? If my experience with this task is any lesson, it's more than we
would think.

-- References ------------------------------------------------------------------

[1] https://www.muppetlabs.com/~breadbox/software/tiny/teensy.html
[2] https://www.muppetlabs.com/~breadbox/software/tiny/return42.html
[3] https://nathanotterness.com/2021/10/tiny_elf_modernized.html
[4] https://gitlab.archlinux.org/archlinux/arch-boxes
[5] https://gitlab.com/x86-psABIs/x86-64-ABI
[6] https://archive.org/details/ioannislaurenti00wuengoog/page/39
[7] https://archive.org/details/JohnLydusOnTheMonthsTr.Hooker2ndEd.2017/page/n82

</pre></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Factors driving a productivity explosion (116 pts)]]></title>
            <link>https://fortune.com/2023/12/09/what-is-fueling-productivity-boom-four-reasons/</link>
            <guid>38588012</guid>
            <pubDate>Sun, 10 Dec 2023 01:10:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fortune.com/2023/12/09/what-is-fueling-productivity-boom-four-reasons/">https://fortune.com/2023/12/09/what-is-fueling-productivity-boom-four-reasons/</a>, See on <a href="https://news.ycombinator.com/item?id=38588012">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>America is back to work. The productivity of U.S. workers grew 5.2% in the third quarter, according to the latest <a href="https://www.bls.gov/productivity/" target="_self" rel="">Bureau of Labor Statistics report</a>, released Wednesday. Thatâ€™s the fastest pace of growth since the third quarter of 2020. Productivity also grew last quarter, by 2.4%, making these the first two consecutive quarters of productivity growth in nearly three years.&nbsp;</p><div>



<p>Thatâ€™s a welcome turn of fate after <a href="https://fortune.com/2023/05/05/remote-work-productivity-5-straight-quarters-decline-gregory-daco/" target="_self" rel="">five consecutive quarters</a> of declining productivity, the reasons for which have been up for plenty of debate. The dispute has been raging <a href="https://fortune.com/2023/08/03/remote-workers-less-productive-research/" target="_self" rel="">for years now</a> as executives and workers alike attempt to uncover what exactly leads to lowered output and morale. Many CEOs have <a href="https://fortune.com/2023/11/14/remote-work-productivity-goldman-sachs-nyu-total-factor-thomas-philippon/" target="_self" rel="">pointed fingers</a> at remote work, arguing that languishing on the couch has made it significantly easier for employees to extend less effortâ€”which over time yanks total company production down. But the data <a href="https://fortune.com/2023/08/04/remote-work-productivity-second-quarter-gdp-growth-return-to-office/" target="_self" rel="">hasnâ€™t borne that out</a>â€”offices have been no more full as productivity rose. And economists have <a href="https://fortune.com/2023/05/05/remote-work-productivity-5-straight-quarters-decline-gregory-daco/" target="_self" rel="">mainly chalked the decline up to</a> everything from sluggish economic activity to higher-than-usual job turnover.&nbsp;&nbsp;&nbsp;</p>



<p>It may be too soon to tell if last quarterâ€™s productivity surge is a flash in the panâ€”or what exactly is fueling the growthâ€”but it still might be worth getting excited about. The productivity boom is very encouraging, according to Gregory Daco, chief economist at EY-Parthenon, the global strategy consulting segment of <a href="https://fortune.com/company/ey/" target="_blank" rel="">EY</a>, a Big Four consultancy firm.&nbsp;</p>



<p>â€œWeâ€™ve seen something that rarely occurs outside recessions: Productivity accelerated in a pro-cyclical manner, in line with the overall pace of economic activity, and positive growth in terms of the labor market,â€ he tells <em>Fortune.&nbsp;</em></p>



<p>Essentially, Daco adds, productivity has rebounded above its 2017-to-2019 norms, which he believes indicates that itâ€™s â€œnot just a quick bounceback,â€ but actually stronger than the prior trendâ€”a positive development.&nbsp;</p>



<p>Itâ€™s underpinned by four main factors unique to our current circumstances, Daco posits: Less turnover, more solid flexible arrangements, upped attention to costs, and more meticulous investing. Conspicuously missing from this list? A return to office, which Daco maintains has a negligible impact on productivity. (Future of work experts <a href="https://fortune.com/2023/11/30/wfh-rates-2026-nick-bloom/" target="_self" rel="">could have told you that</a> all along.)&nbsp;&nbsp;</p>



<h2><strong>Big Four</strong></h2>



<p>When the U.S. reported its fifth straight quarter of productivity declines <a href="https://fortune.com/2023/05/05/remote-work-productivity-5-straight-quarters-decline-gregory-daco/" target="_self" rel="">back in May</a>â€”the longest such stretch since World War IIâ€”it followed two years of the <a href="https://fortune.com/2023/10/03/number-of-people-quitting-pre-pandemic-rates/" target="_self" rel="">Great Resignation</a> and <a href="https://fortune.com/2023/06/21/gen-z-millennial-employees-job-hopping/" target="_self" rel="">job hopping</a>. â€œWhen an employee thatâ€™s been there for a few months has to train someone who just joinedâ€”and that person may not necessarily stay for that longâ€”that creates a massive productivity hit,â€ Daco says. â€œThe person thatâ€™s been there for three months wonâ€™t be anywhere near as productive as the person there for multiple years.â€ Then the cycle repeats: Having them train someone else will mean the <em>next</em> person will be even <em>less</em> efficient.</p>



<p>But such worker churn has since fallen from its <a href="https://fortune.com/2023/10/19/ceo-departures-highest-level-on-record-great-resignation/" target="_self" rel="">fever pitch</a>â€”the quits rate has <a href="https://fortune.com/2023/10/03/number-of-people-quitting-pre-pandemic-rates/" target="_self" rel="">dropped back</a> to its 2019 rate. â€œEmployees are staying longer with their employers, and attrition rates are much lower,â€ Daco explains, adding that this makes employees better trained and more efficient.</p>



<p>Another thing thatâ€™s changedâ€”adapting to hybrid work. Earlier this year, many workers were still navigating this workplace compromise. Now, most office workers log on remotely just shy of 30% of the time, and that figure <a href="https://fortune.com/preview/2023/12/08/productivity-boom-ey-parthenon-reasons/" target="_self" rel="">hasnâ€™t moved</a> in many months. That <a href="https://fortune.com/2023/09/12/hybrid-work-new-norm-return-to-office/" target="_self" rel="">hybrid work has become the norm</a> means fewer organizational changes, which means more time to actually focus on the work.&nbsp;</p>



<p>Being in a â€œpost-pandemic shock environmentâ€ is why we had five consecutive quarters of contraction in productivity, Daco says. â€œNow weâ€™re getting more settled, and people are finding balance in their flexible arrangements, and thatâ€™s driving more productive outputs.â€</p>



<p>The other two factors are more external. Last year, inflation <a href="https://fortune.com/2023/06/13/inflation-cools-may-cpi-consumer-price-index-report-economy-recession/" target="_self" rel="">hit a 40-year-high</a>. That left businesses paying extra attention to cost management, cutting back on expenses like <a href="https://fortune.com/2022/11/14/elon-musk-twitter-employee-free-meal-perks-cut/" target="_self" rel="">free lunch </a>and even resorting to <a href="http://layoffs.fyi/" target="_self" rel="">rounds of layoffs</a>. Now, the story in late 2023 into 2024 is one of cost fatigue, which Daco says is a bit of a departure from the inflation narrative that characterized the 2020s thus far.&nbsp;</p>



<p>â€œEveryone is fatigued by the elevated costs of goods, services, labor, capital, interest rates, inventoryâ€”everything,â€ he says. â€œSo bosses donâ€™t want to let good talent go.â€ Instead, theyâ€™re having to find ways to improve productivity, such as investing in increased employee engagement and long-term retention and leveraging technological innovations like generative A.I.</p>



<p>And, in an environment where the cost of capital and interest rates <a href="https://fortune.com/2023/10/12/long-term-interest-rates-spiking-could-recessionor-us-economy-carlsson-szlezak-swartz/" target="_self" rel="">are spiking</a>, businesses scrutinize their decisions much more than they would otherwise in a strong economic climate. â€œYouâ€™re going to be much more careful with your investments,â€ Daco says. â€œThat means that youâ€™re going to focus on the investment decisions that bring the highest returns.â€&nbsp;</p>



<p>In other words: No unnecessary spending or innovationâ€”focus on the most lucrative business levers, and divert all the resources and productivity to them.&nbsp;</p>



<h2><strong>Office attendance and work output? Not so black and white </strong></h2>



<p>Bolstered by Dacoâ€™s four-point explanation, the new BLS data puts to rest the idea that <a href="https://fortune.com/2023/11/30/wfh-rates-2026-nick-bloom/" target="_self" rel=""><em>where </em>work happens</a> is consequential in the productivity debate. Experts have <a href="https://fortune.com/2023/07/20/hybrid-work-problems-annie-dean-meta-atlassian/" target="_self" rel="">maintained that exact point</a> for years.&nbsp;</p>



<p>Evidence of productivity differences between remote and in-person work isnâ€™t black and white, Daco says; thereâ€™s a â€œhuge diffusionâ€ of gains and losses. â€œI donâ€™t know if return-to-office policies have had much of an effect one way or another, because the arguments are clear both ways,â€ he adds. â€œIt really depends on the culture and the reasoning behind the [policies].â€</p>



<p>Often when someone is forced to do something, they tend to be less efficient, he says. Once people feel more comfortable and stable in an arrangement, their productivity tends to recover.&nbsp;</p>



<p>Asked point blank whether a move towards greater in-person attendance may definitively improve productivity, Daco demurs. â€œIâ€™m not answering the question, because there isnâ€™t any clear-cut evidence that [this yearâ€™s Labor Day mandates] really shifted things that much.â€&nbsp;</p>



<p>By the time many of those <a href="https://fortune.com/2023/09/06/remote-work-return-to-office-ceos-gamble-pandemic-hybrid-policy/" target="_self" rel="">Labor Day mandates</a> were instated, they were already in place to some degree, and the half-and-half in-person split wasnâ€™t entirely new. And, running counter to remote work expert Nick Bloomâ€™s prediction that remote work will eventually <a href="https://fortune.com/2023/08/31/ai-remote-workers-threat-nick-bloom-work-from-home/" target="_self" rel="">edge out office work</a> as the dominant format, Daco says he expects an increase in office work in coming years.</p>



<p>â€œWeâ€™ll never get back toâ€”well, never say neverâ€”but weâ€™re unlikely to get back to 100% office attendance,â€ he says. â€œBut I wouldnâ€™t be surprised if we still creep back up, especially if labor market conditions start to deteriorate and we see layoffs and more unemployment.â€&nbsp;</p>



<p>At that point, he says, the incentive will be greater for workers to be present instead of out of sightâ€”which, theyâ€™d hope, would make their bosses <a href="https://fortune.com/2023/11/15/remote-work-makes-it-easier-to-fire-ken-griffin-citadel/" target="_self" rel="">hesitant to fire them first</a>. Though of course, bosses could also take the approach of assessing workers on their productivity rates. Which, conveniently, are doing pretty well these days.</p></div><p>Subscribe to the CEO Daily newsletter to get the CEO perspective on the biggest headlines in business. <a href="https://www.fortune.com/newsletters/ceo-daily?&amp;itm_source=fortune&amp;itm_medium=article_tout&amp;itm_campaign=ceo_daily" target="_self" rel="">Sign up</a> for free.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[65% increase in "significant" Air Traffic Control incidents in 2023 (220 pts)]]></title>
            <link>https://www.nytimes.com/2023/12/02/business/air-traffic-controllers-safety.html</link>
            <guid>38587340</guid>
            <pubDate>Sat, 09 Dec 2023 23:35:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2023/12/02/business/air-traffic-controllers-safety.html">https://www.nytimes.com/2023/12/02/business/air-traffic-controllers-safety.html</a>, See on <a href="https://news.ycombinator.com/item?id=38587340">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2023/12/02/business/air-traffic-controllers-safety.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Open source alternative to ChatGPT and ChatPDF-like AI tools (213 pts)]]></title>
            <link>https://github.com/SecureAI-Tools/SecureAI-Tools</link>
            <guid>38587052</guid>
            <pubDate>Sat, 09 Dec 2023 23:02:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/SecureAI-Tools/SecureAI-Tools">https://github.com/SecureAI-Tools/SecureAI-Tools</a>, See on <a href="https://news.ycombinator.com/item?id=38587052">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">SecureAI Tools</h2>
<p dir="auto">Private and secure AI tools for everyone's productivity.</p>
<p dir="auto"><a href="https://discord.gg/YTyPGHcYP9" rel="nofollow"><img src="https://camo.githubusercontent.com/fa9f3bc30878e81e1f1185116459d5c7545de20691b02704fc3e02c242531b65/68747470733a2f2f646362616467652e76657263656c2e6170702f6170692f7365727665722f595479504748635950393f7374796c653d666c617426636f6d706163743d74727565" alt="Discord" data-canonical-src="https://dcbadge.vercel.app/api/server/YTyPGHcYP9?style=flat&amp;compact=true"></a></p>
<h2 tabindex="-1" dir="auto">Highlights</h2>
<ul dir="auto">
<li><strong>Chat with AI</strong>: Allows you to chat with AI models (i.e. ChatGPT).</li>
<li><strong>Chat with Documents</strong>: Allows you to chat with documents (PDFs for now). Demo videos below</li>
<li><strong>Local inference</strong>: Runs AI models locally. Supports 100+ open-source (and semi-open-source) AI models through <a href="https://ollama.ai/library" rel="nofollow">Ollama</a>.</li>
<li><strong>Built-in authentication</strong>: A simple email/password authentication so it can be opened to internet and accessed from anywhere.</li>
<li><strong>Built-in user management</strong>: So family members or coworkers can use it as well if desired.</li>
<li><strong>Self-hosting optimized</strong>: Comes with necessary scripts and docker-compose files to get started in under 5 minutes.</li>
<li><strong>Lightweight</strong>: A simple web app with SQLite DB to avoid having to run docker container for DB. Data is persisted on host machine through docker volumes</li>
</ul>
<h2 tabindex="-1" dir="auto">Demos</h2>
<h4 tabindex="-1" dir="auto">Chat with documents demo: OpenAI's GPT3.5</h4>
<p dir="auto"><a href="https://www.youtube.com/watch?v=Br2D3G9O47s" rel="nofollow"><img src="https://camo.githubusercontent.com/9c020ee9a9c39f400b5b609ffc5980fa34bcc4bbc372221d0c9c8c62c9ceb95e/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f427232443347394f3437732f302e6a7067" alt="Chat with documents demo: OpenAI's GPT3.5" data-canonical-src="https://img.youtube.com/vi/Br2D3G9O47s/0.jpg"></a></p>
<h4 tabindex="-1" dir="auto">Chat with documents demo: Locally running Mistral (M2 MacBook)</h4>
<p dir="auto"><a href="https://www.youtube.com/watch?v=UvRHL6f_w74" rel="nofollow"><img src="https://camo.githubusercontent.com/491fb33329828504bbdc3ca9a1a5669f14916ab88a8828a0775a3cc3bb093f48/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f557652484c36665f7737342f302e6a7067" alt="Chat with documents demo: Locally running Mistral" data-canonical-src="https://img.youtube.com/vi/UvRHL6f_w74/0.jpg"></a></p>
<h2 tabindex="-1" dir="auto">Install</h2>
<h3 tabindex="-1" dir="auto">Docker Compose [Recommended]</h3>
<h4 tabindex="-1" dir="auto">1. Create a directory</h4>
<div data-snippet-clipboard-copy-content="mkdir secure-ai-tools &amp;&amp; cd secure-ai-tools"><pre><code>mkdir secure-ai-tools &amp;&amp; cd secure-ai-tools
</code></pre></div>
<h4 tabindex="-1" dir="auto">2. Run set-up script</h4>
<p dir="auto">The script downloads <code>docker-compose.yml</code> and generates a <code>.env</code> file with sensible defaults.</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -sL https://github.com/SecureAI-Tools/SecureAI-Tools/releases/latest/download/set-up.sh | sh"><pre>curl -sL https://github.com/SecureAI-Tools/SecureAI-Tools/releases/latest/download/set-up.sh <span>|</span> sh</pre></div>
<h4 tabindex="-1" dir="auto">3. [Optional] Edit <code>.env</code> file</h4>
<p dir="auto">Customize the <code>.env</code> file created in the above step to your liking.</p>
<h4 tabindex="-1" dir="auto">4. [Optional] On Linux machine with Nvidia GPUs, enable GPU support</h4>
<p dir="auto">To accelerate inference on Linux machines, you will need to enable GPUs. This is not strictly required as the inference service will run on CPU-only mode as well, but it will be slow on CPU. So if your machine has Nvidia GPU then this step is recommended.</p>
<ol dir="auto">
<li>Install <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation" rel="nofollow">Nvidia container toolkit</a> if not already installed.</li>
<li>Uncomment the <code>deploy:</code> block in <code>docker-compose.yml</code> file. It gives inference service access to Nvidia GPUs.</li>
</ol>
<h4 tabindex="-1" dir="auto">5. Run docker compose</h4>

<h4 tabindex="-1" dir="auto">6. Post-installation set-up</h4>
<ol dir="auto">
<li>
<p dir="auto">Login at <a href="http://localhost:28669/log-in" rel="nofollow">http://localhost:28669/log-in</a> using the initial credentials below, and change the password.</p>
<ul dir="auto">
<li>
<p dir="auto">Email</p>
<div data-snippet-clipboard-copy-content="bruce@wayne-enterprises.com"><pre><code>bruce@wayne-enterprises.com
</code></pre></div>
</li>
<li>
<p dir="auto">Password</p>

</li>
</ul>
</li>
<li>
<p dir="auto">Set up the AI model by going to <a href="http://localhost:28669/-/settings?tab=ai" rel="nofollow">http://localhost:28669/-/settings?tab=ai</a></p>
</li>
<li>
<p dir="auto">Navigate to <a href="http://localhost:28669/-" rel="nofollow">http://localhost:28669/-</a> and start using AI tools</p>
</li>
</ol>
<h2 tabindex="-1" dir="auto">Features wishlist</h2>
<p dir="auto">A set of features on our todo list (in no particular order).</p>
<ul dir="auto">
<li>âœ… Chat with documents</li>
<li>âœ… Support for OpenAI, Claude etc APIs</li>
<li>Support for markdown rendering</li>
<li>Chat sharing</li>
<li>Mobile friendly UI</li>
<li>Specify AI model at chat-creation time</li>
<li>Prompt templates library</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Matter of Millimeters: The story of Qantas flight 32 (557 pts)]]></title>
            <link>https://admiralcloudberg.medium.com/a-matter-of-millimeters-the-story-of-qantas-flight-32-bdaa62dc98e7</link>
            <guid>38586773</guid>
            <pubDate>Sat, 09 Dec 2023 22:30:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://admiralcloudberg.medium.com/a-matter-of-millimeters-the-story-of-qantas-flight-32-bdaa62dc98e7">https://admiralcloudberg.medium.com/a-matter-of-millimeters-the-story-of-qantas-flight-32-bdaa62dc98e7</a>, See on <a href="https://news.ycombinator.com/item?id=38586773">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://admiralcloudberg.medium.com/?source=post_page-----bdaa62dc98e7--------------------------------"><div aria-hidden="false"><p><img alt="Admiral Cloudberg" src="https://miro.medium.com/v2/resize:fill:88:88/2*pZPMtIONqtJYi2xHYD_Ivg.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><figure><figcaption>Officials observe damage to the engine of a Qantas A380 after it made an emergency landing in Singapore. (Reuters)</figcaption></figure><p id="8705">On the 4th of November 2010, a Qantas Airbus A380 was rocked by a catastrophic engine failure minutes after takeoff from Singapore, hurling fragments of a turbine disk through its wings and fuselage in multiple locations. The explosion damaged almost every major system on the airplane, from the flight controls and fuel tanks to hydraulics and pneumatics. Faced with a barrage of diverse failure warnings and an airplane of uncertain integrity, the flight crew worked together to make a series of critical decisions that would get their enormous airplane back on the ground. And in the end, despite one curveball after another â€” including landing gear problems, loss of braking power, and an engine that refused to shut down â€” they not only landed the plane, but did so without putting a scratch on any of the 469 passengers and crew.</p><p id="5ab9">The cause of the incident would ultimately be traced deep inside the number two engine to a single oil pipe that had been manufactured with a wall that was slightly too thin. How this seemingly tiny defect came about, and how it nearly brought down the worldâ€™s largest passenger plane, represent a story equally as fascinating as that of the flight itself, tracing back years to encompass questionable drawing board decisions, hidden flaws in the machining logic, and faulty assumptions about engine behavior. Time and time again, the problem slipped through the gaps in the system, tumbling down the long slope toward disaster â€” only to be stopped at the last moment, not only by the pilots themselves, but by a number of explicit protections built into the design of the A380, each of which played a crucial role in containing the fallout from a failure that exceeded the manufacturerâ€™s worst expectations. The story of Qantas flight 32, as told herein, is therefore not only the tale of a dramatic emergency, but a testament to the safety of aviation today â€” a story that should make every reader feel a little less fearful of flight.</p><p id="1a65">â—Šâ—Šâ—Š</p><figure><figcaption>A brand new Airbus A380 takes to the skies. (Pascal Le Segretain)</figcaption></figure><p id="dab4">Introduced to service in 2007, the double decker, four-engine A380 is by far the largest passenger aircraft in the world, exceeding the vaunted Boeing 747 in almost every measurement. Awesome to behold and pleasant to fly, thereâ€™s not much to dislike about the A380 â€” unless youâ€™re an airline, in which case most major carriers dismissed the behemoth as too large for their operating models. Indeed, analystsâ€™ assessment today is that the A380 was built for a market that had shrunk considerably by the time it actually entered service, and as a result, production ended in 2021 with only 254 built, some of which have already been scrapped. For an extraordinarily expensive aircraft equipped with some of the most advanced technology of any airliner, the collective result of immense effort and imagination, such a fate is unfortunate, but the reasons behind it, and the future of the type, are topics for a different article.</p><p id="5896">Despite the above, some airlines did find the A380 suitable for their operations, including Qantas, the flag carrier of Australia. Qantas ordered 10 A380s to be delivered in 2008, of which eight are still flying today. It was the very first of these, registered as VH-OQA and nicknamed Nancy-Bird Walton after the pioneering Australian aviator, that would come to be involved in the events of the 4th of November 2010.</p><figure><figcaption>VH-OQA, the aircraft involved in the accident. (Andrei Dimofte)</figcaption></figure><p id="5e90">On that date, VH-OQA arrived in Singapore for a scheduled stopover on a marathon London-to-Sydney trip, where it took on fuel, passengers, and a new flight crew for the last leg to Australia. The plane was essentially full, with 440 of 450 passenger seats filled, plus a massive complement of 29 crewmembers, including no less than five pilots. Although the A380 is normally flown by only two pilots, Qantas had also rostered a second officer as a relief crewmember; a check airman was conducting a line check on the captain; and another check airman was training the first check airman, so the cockpit was certainly crowded.</p><p id="ff17">In command, and under examination, was 53-year-old Captain Richard Champion de Crespigny, a veteran airman with over 15,000 hours of experience and 32 years in aviation. The other crewmembers consisted of First Officer Matt Hicks, Second Officer Mark Johnson, Check Captain Harry Wubben, and Senior Check Captain David Evans. The five crewmembers had a combined 140 years in aviation and 71,000 hours of flying experience, an incredible total that is rarely equaled.</p><p id="70ee">At 9:56 a.m. local time, with Captain de Crespigny at the controls, Qantas flight 32 departed Singapore and proceeded southeast across the strait toward Indonesia, passing over the densely populated island of Batam. All parameters still appeared normal as the A380 climbed through 7,000 feet, four minutes after takeoff. There was no indication that a catastrophic failure was in fact just seconds away.</p><p id="bece">â—Šâ—Šâ—Š</p><figure><figcaption>A Rolls-Royce Trent 900 engine with a man for scale. (Wikimedia user Tangopaso)</figcaption></figure><p id="4196">The Airbus A380 is powered by four massive Rolls-Royce RB211 Trent 900-series high-bypass turbofan engines, each producing up to 84,000 lbf of thrust. Designed specifically for the A380, the Trent 900 was produced at several locations in the United Kingdom and was sold in competition with the American-built GP7200 jointly developed by Pratt &amp; Whitney and General Electric.</p><p id="9d52">Understanding what happened aboard Qantas flight 32 requires that I subject you to a description of the structure of certain very specific parts of the engine.</p><p id="e805">Like all high-bypass jet engines, the Trent 900 consists of four main sections: the fan, the compressors, the combustion chamber, and the turbines. During normal operation, air is forced backward and pressurized by a series of increasingly powerful compressors before being fed into the combustion chamber, where it is mixed with fuel and ignited. The combustion creates mechanical energy that spins a series of turbines, which in turn power the compressors, as well as the fan at the front of the engine, which accelerates large quantities of so-called bypass air around the outside of the engine core to generate most of the thrust output.</p><figure><figcaption>Locations of turbines and compressors on the Trent 900. (FAA)</figcaption></figure><p id="dcf5">Most turbofan engines examined in my articles have a high pressure compressor and a low pressure compressor, which correspond to high- and low-pressure turbines. These turbines are connected to their respective compressor sections by concentric drive shafts. However, the Trent 900 differs from this layout slightly, because it also has an intermediate pressure compressor with a corresponding intermediate pressure turbine, in between the high and low pressure sections. It also differs in that the fan itself doubles as the low pressure compressor. (From now on, for brevityâ€™s sake, the abbreviations LP, IP, and HP will be used for low pressure, intermediate pressure, and high pressure, respectively.)</p><figure><figcaption>In this cutaway diagram of the IP turbine area, Iâ€™ve drawn blue boxes around the components mentioned in the following paragraph. (ATSB)</figcaption></figure><p id="48a2">On the Trent 900, the HP and IP turbine sections at the rear of the engine each consist of a single-stage turbine disk. Blades around the circumference of each disk capture mechanical energy from hot combustion gases flowing through what is known as the â€œannulus gas path.â€ These gases spin the disk, which is attached by a drive arm to its associated drive shaft. The shaft then transfers the turbineâ€™s rotational energy forward to the corresponding compressor at the front of the engine.</p><figure><figcaption>This clip from an FAA video helps visualize the cutaway of the HP/IP bearing assembly. Note the location of the bearing chamber, which is depicted full of oil, and the pipe leading into it. Watch the full video here: <a href="https://www.youtube.com/watch?v=sYxVin_FFxQ" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=sYxVin_FFxQ</a></figcaption></figure><p id="dfc8">In order to support the turbine disks and shafts while still allowing them to rotate freely, the engine features a complex system of bearings. The HP and IP turbine sections have a common bearing assembly, called the HP/IP bearing hub, which encircles the drive shafts and holds them in place while allowing free rotation of the shafts within.</p><p id="d60c">To prevent wear on the bearings, the space inside the bearing hub, called the bearing chamber, is constantly filled with pressurized oil that keeps everything gliding smoothly. This oil is supplied primarily by an oil feed pipe that runs from the main engine oil supply, past the annulus gas path, and down into the HP/IP bearing hub, where it injects oil through a filter and into the bearing chamber.</p><p id="d009">The structure of the bearing hub consists of an inner and outer hub section, such that an empty buffer space exists between the bearing chamber and the rest of the engine. The oil feed pipe runs through both sections in order to reach the bearing chamber. The last segment of this pipe, a few centimeters in length, is welded in place during manufacture of the bearing hub, and the main portion of the pipe is fitted to it later. This fixed final segment that passes through the buffer space between the inner and outer sections of the HP/IP bearing hub is called the â€œstub pipe.â€</p><p id="5d37">For reasons that will be examined in detail later, this tiny oil feed stub pipe triggered an escalating sequence of events within the space of mere seconds as Qantas flight 32 climbed away from Singapore.</p><p id="1540">Within the â„–2 engine, located in the inboard position on the left wing, a crack in the oil feed stub pipe caused it to begin leaking oil less than four minutes after takeoff. The leak was small, but the oil within the pipe was highly pressurized, resulting in an atomized spray into the buffer space between the inner and outer sections of the HP/IP bearing hub. The temperature inside this buffer space was likely between 365 and 375ËšC, well above the 280-degree auto-ignition temperature of the engine oil, so the spray immediately ignited.</p><figure><figcaption>An FAA animation of the failure sequence leading up to the explosion aboard Qantas 32, annotated by me. This should be really helpful for visualizing the following paragraph. (FAA)</figcaption></figure><p id="eb6e">At the forward end of the bearing hub, a triple seal is attached to the hub structure to isolate the buffer space, which has a low internal pressure, from the area behind the high pressure turbine disk, where pressure is higher. But as the fire in the buffer space expanded, it impinged upon this seal, causing it to fail. With the low-pressure area no longer sealed off, highly pressurized air from the annulus gas path was drawn toward it, bursting down past the high pressure turbine disk and into the buffer space. This rush of air coming in through the forward end of the buffer space blasted the fire aft, propelling it like a blowtorch against the corresponding seal at the other end, which also failed. The burning oil â€œblowtorchâ€ was then able to make direct contact with the drive arm connecting the IP turbine disk to its drive shaft, located directly behind the HP/IP bearing hub. Already under considerable stress as a result of normal engine operation, the drive arm failed under the withering heat within a matter of seconds.</p><p id="8614">This entire sequence, from the initiation of the oil leak to the failure of the drive arm, lasted considerably less than one minute.</p><figure><figcaption>The turbine disk disintegrates. (ATSB)</figcaption></figure><p id="66fa">Now, with the drive arm broken, the IP turbine disk was not directly connected to anything, which is (to use the technical jargon) a really big problem. A turbine disk is subjected to considerable mechanical energy from the annulus gas path, and that doesnâ€™t go away when the drive arm breaks, but what does go away is any ability to transfer that energy somewhere other than the turbine disk itself. During normal operations, this energy is used to turn the intermediate compressors, which requires considerable force. But this load path only exists when the turbine disk is connected to the drive shaft, so when the drive arm broke, the only way for the disk to absorb all that energy was to spin fasterâ€¦ and fasterâ€¦ and fasterâ€¦</p><p id="bea9">Within the space of four seconds, the energy from the annular gas flow accelerated the IP turbine past its critical speed, until centrifugal forces exceeded the ultimate strength of the nickel alloy disk. The red-hot, wildly spinning disk instantly fractured into several sections, which rocketed outward in multiple directions at incomprehensible speed.</p><figure><figcaption>The disk fragments neatly ripped out everything within the diskâ€™s plane of rotation. (ATSB)</figcaption></figure><p id="60d0">Engine designers do their best to make sure that the engine structure can contain flying debris like individual fan and turbine blades, but the amount of energy contained within those types of projectiles is a fraction of that within a piece of a burst disk. For engineering purposes, disk fragments are assumed to have infinite energy at the moment of release; they will cut through any reasonable material and cannot be contained.</p><p id="c241">When the IP turbine disk on Qantas flight 32 suddenly burst, nothing could stop the resulting fragments, which cut through the engine case and cowling like butter, cleaving a neat circumferential fissure all the way around the engine within the plane where the disk used to be. Within a fraction of a second, one of these disk fragments exited the engine downward and to the left, propelled toward the distant ground, but several more traveled in the opposite direction. One fragment shot to the right, entered the belly area below the cargo hold, plowed through several structural stringers and wire bundles, then exited out the other side, never to be seen again. Two more fragments rocketed upward, carving paths of destruction through the interior of the left wing before emerging from its upper surface, at which point they too disappeared into space. Numerous smaller pieces, such as dislodged turbine blades and fragments of engine structure, also peppered various parts of the aircraft, including the wings and fuselage.</p><figure><figcaption>The trajectories of the various fragments. (ATSB)</figcaption></figure><p id="9749">On board the plane, the pilots and passengers heard two distinct bangs in very short succession, which were followed in the cockpit by a sudden, overwhelming cascade of warnings. The plane yawed slightly to the left and the autothrust system disconnected. Recognizing that a serious malfunction had occurred, Captain de Crespigny pressed the altitude hold button on the autopilot to level the plane, and then everyoneâ€™s attention turned to the ECAM.</p><p id="7051">The Electronic Centralized Aircraft Monitoring system, or ECAM, presents the crew with warnings, cautions, and advisories related to the degradation or failure of a huge range of aircraft systems, along with the associated abnormal or emergency procedures. A feature of most modern airliners, ECAM displays have transformed the way pilots deal with in-flight emergencies, helping ensure swift and correct action in response to almost any conceivable mechanical failure. Today, this system would be put to the test.</p><p id="9357">The first message to appear on the ECAM screen was an ENG 2 TURBINE OVERHEAT warning, which was followed within the next 20 seconds by another 34 messages of varying alert levels. The highest priority messages, displayed at the top of the list, all indicated a major problem with the â„–2 engine, but strangely enough, not its outright failure, because the engine â€” minus the IP turbine disk and everything in line with it â€” was in fact still turning. Following the indicated ECAM actions, Captain de Crespigny reduced power to the damaged engine, but instead of correcting the problem, an â€œENG 2 FIREâ€ warning flashed on the screen for one or two seconds, then disappeared.</p><figure><figcaption>A flight crewmember took this photo of the instrument panel during the flight, showing several messages, including a red â€œwarningâ€ level message, on the ECAM display. (ATSB)</figcaption></figure><p id="5ff0">As First Officer Hicks made a pan-pan call to air traffic control, one level short of â€œmayday,â€ the crew decided that the engine was likely severely damaged and elected to shut it down. As they moved to reduce power, an ENG 2 FAIL message finally appeared on the ECAM. The pilots also attempted to actuate both of the engineâ€™s two built-in fire extinguishers, but only one of them actually fired, and neither of the confirmation lights illuminated. However, as they scrolled through the seemingly unending list of ECAM alerts, only one or two of which could be displayed at one time, it became clear that the engine and its fire extinguishers were hardly the only systems having issues.</p><p id="f41b">When the fragments of the IP turbine disk passed through the wing and belly of the A380, they caused considerable secondary damage along the way, not only to the â„–2 engine but also to the left wing fuel tank, which sprang a leak; the leading edge wing slat extension mechanism, which took a direct hit; and the aircraftâ€™s electrical system. Additionally, two wire looms in the leading edge of the wing and in the belly area were completely severed, collectively affecting about 650 wires that carried critical information to and from almost every conceivable aircraft system. A brief and hardly exhaustive summary of the damage to the aircraft included impact damage to the left wing upper and lower skin, front spar, internal ribs, and wing-to-fuselage joint; loss of control over the green (left) hydraulic pumps; degradation of the yellow (right) hydraulic system; loss of AC electrical power from engines 1 and 2; loss of one of four AC power distribution systems; loss of functionality of all leading edge slats; partial loss of functionality of the spoilers and ailerons; degradation of control over all remaining engines, resulting in loss of the autothrust system; loss of functionality of the left wing landing gear brakes and anti-skid on the right wing gear brakes; severe disruption of the pneumatic system; loss of both the â„–1 and â„–2 low fuel pressure shutoff valves; degradation of the fuel quantity indicating system; reduction in fuel transfer capability; loss of the fuel jettison system; loss of fire protection capability on engines 1 and 2; and much more besides.</p><figure><figcaption>A map of operational flight controls surfaces [green] and inoperative surfaces [red]. (ATSB)</figcaption></figure><p id="3733">One of the most serious malfunctions was the loss of the green hydraulic system. Although the system itself was not breached, the severed wires stopped all the green hydraulic pumps, resulting in a loss of pressure that rendered inoperative all systems reliant upon it. Unlike some other wide body aircraft, the A380 has only two hydraulic systems â€” green and yellow â€” which mainly supply the left and right sides of the aircraft, respectively. Instead of more redundant hydraulic systems, the A380 has independent backup hydraulic actuators on each individual flight control surface, ensuring that even a total loss of both hydraulic systems will result in minimal flight control difficulties. Nevertheless, direct damage had degraded the planeâ€™s roll control, eliminating the left middle aileron (the A380 has three on each wing) and left wing spoilers 4 and 6. The loss of green hydraulic pressure also caused the failure of the outboard ailerons on both wings, spoilers 2 and 8 on each wing, and spoiler 4 on the right wing. However, the built-in redundancy in the A380 was so great that the remaining spoiler and aileron panels were sufficient to maneuver the airplane despite what amounted to a 65% loss of roll control capability.</p><p id="2987">Initially, the hydraulic system indications confused the crew. Their initial impression was that the damage was confined to the left side of the airplane, so they were surprised to see an indication related to the yellow (right) hydraulic system mixed in with all the other ECAM messages, and they briefly considered whether the messages might be spurious. The same possibility was considered by Qantas technicians on the ground, who were receiving live telemetry data from the aircraft. But by accessing detailed electronic status pages for each aircraft system and cross-checking what was not working, the pilots were able to come to the conclusion that all the failures were most likely real.</p><figure><figcaption>A passenger took this photo in flight, showing turbine fragment exit holes in the upper surface of the wing. (ATSB)</figcaption></figure><p id="6f42">At that point the crew needed to make a decision: should they land immediately, or should they wait to action all of the abnormal procedures associated with the dozens of ECAM messages? Assessing that the aircraft was controllable with the autopilot both on and off, they eventually came to an agreement that it was safe to remain airborne, and that they would rather make sure all crewmembers had a complete understanding of the health of every aircraft system before coming in for a landing. The last thing they needed was a surprise on final approach that would force them to go around.</p><p id="4fbd">Having chosen this course of action, the crew requested clearance to enter a holding pattern, and ATC granted them permission to circle over the ocean northeast of Singapore. The crew estimated that it would take at least 30 minutes to work through all of the ECAM actions.</p><p id="5692">In the meantime, the cabin crew had been attempting to get the pilotsâ€™ attention using the emergency call button, but all the pilots were so focused on the failures that they initially didnâ€™t notice. Only now did they send Second Officer Mark Johnson to assess the situation in the cabin, whereupon a Qantas pilot riding as a passenger in the upper deck drew his attention to the in-flight entertainment system, which featured a live view of the aircraft from a tail-mounted camera. The digital stream clearly showed a much more literal stream of fuel pouring from the left wing and into the aircraftâ€™s wake, which was also visible with the naked eye from the lower deck. Johnson proceeded down to check for himself, at which point he also observed for the first time that there were two gaping holes in the top of the left wing, surrounded by jagged metal, where the turbine disk fragments had exited.</p><p id="4acc">According to Check Captain David Evans, the cabin crew were concerned that so many passengers were watching the live feed from the tail camera, but in a collective decision, the pilots elected not to turn it off because, in their view, the feed suddenly cutting out would probably be more alarming than anything that could be seen on it.</p><p id="ec59">â—Šâ—Šâ—Š</p><figure><figcaption>Part of the turbine disk caused serious damage to a building. (ATSB/Posmetro newspaper)</figcaption></figure><p id="3a4e">Meanwhile on the ground, events were taking an unexpected turn. On Batam Island in Indonesia, debris from the â„–2 engine plunged into a populated area shortly after the failure, resulting in surprise and alarm. Among the debris was a large portion of the failed IP turbine disk, which fell with such force that it cleaved straight through a building, razing a brick wall. Thankfully, no one on Batam was hurt by the debris. However, photographs of locals holding airplane wreckage in what appeared to be Qantas livery were soon posted to Twitter, where they were taken as indications that a Qantas airplane had actually crashed somewhere over Batam. Qantas engineers already knew that the plane was still flying, but they were unable to contact the crew to find out more information. And outside that bubble, the news that a Qantas A380 had possibly gone down spread so quickly that even investors reacted while the plane was still in the air. In fact, the first time Qantasâ€™s CEO learned of the situation was when he received a call asking why the companyâ€™s stock price was dropping.</p><figure><figcaption>People collect pieces of the fallen engine cowling on Batam. (Reuters)</figcaption></figure><p id="3597">Up in the air, such concerns were far from the minds of the crew. Working through one ECAM procedure after another, they slowly stabilized various disrupted systems, but as they did so, one problem in particular was getting worse: their fuel situation. With fuel leaking prodigiously from the left wing tank, an imbalance had developed between the left and right wings, prompting an ECAM alert instructing them to open the fuel transfer valves to equalize the fuel levels. However, with a leak clearly occurring and other ECAM messages indicating damage to the fuel transfer system, after a detailed discussion the pilots concluded that following the computerâ€™s instructions would be inadvisable â€” a great example of why experience and judgment are still necessary even on an aircraft as highly automated as the A380.</p><p id="95dd">In the end, it took 55 minutes to clear all of the ECAM messages, an unprecedented length of time that was certainly far beyond anything any of the pilots had previously imagined. But even then, more considerations remained before they could land. Most notably, the airplane was still more than 40 tons over its maximum landing weight, and among the failures that had occurred was the loss of the fuel jettison system, so it would be impossible to reduce their weight by dumping fuel. The possibility of remaining in the air until they had burned the extra fuel was considered, but with an increasing fuel imbalance between the right and left wings and a 65% loss of roll control, the pilots determined that this would be irresponsible. Their conclusion was that they had to land soon, even if they were over the maximum weight. But would any of the runways at Singapore be long enough to accommodate a significantly overweight A380 with degraded brakes, several faulty spoilers, and no reverse thrust on engine 2? There was certainly reason to doubt.</p><figure><figcaption>The complete flight path of flight 32, including its extensive hold. (ATSB)</figcaption></figure><p id="0409">In order to find out for sure, Captain de Crespigny instructed the two Check Captains to determine their required landing distance using the Airbus performance software installed on laptop computers stored in the cockpit. The detailed software allowed them to enter various parameters including the weather, runway condition, and any systems failures, and then calculate whether it was possible to land. But when everything had been entered, the program spit out an unhelpful answer: â€œno result.â€<br> When calculating the landing distance, the software applied a generic â€œoperational coefficientâ€ to account conservatively for variations in pilot techniques that could result in less efficient deceleration. The problem, as investigators would later discover, was that the software applied the coefficient again whenever another system failure was added. With so many system failures on the aircraft, the coefficient was applied a total of 9 times, resulting in a calculated landing distance considerably greater than the length of the available runway. However, Check Captain Evans was able to fix the problem by manually entering their actual landing weight, overriding the programâ€™s assumption of a maximum landing weight. By specifying an landing weight in excess of the maximum, the system logic changed to apply the operational coefficient only once â€” for unrelated and obscure reasons â€” and lo and behold, when he ran the numbers this time, the computer said they could just barely land on any of the 4,000-meter runways at Singapore Changi Airport, with only 100 meters to spare. It wasnâ€™t much, but with no better runways anywhere nearby, it would have to do.</p><figure><figcaption>Indonesian police pose with a fallen piece of the airplane. (AP)</figcaption></figure><p id="1b49">Finally ready to commit, Captain de Crespigny now removed the aircraft from its holding pattern and began maneuvering for approach. The crew requested fire trucks on landing due to the fuel leak, and advised the cabin crew to prepare for an on-ground emergency if they overran the runway. They aligned with the runway from considerably farther away than usual in order minimize maneuvering, since the controls felt rather sluggish â€” mainly the result of the degraded roll control. Captain de Crespigny subsequently carried out further manual control checks during the approach to make sure that the controllability characteristics remained consistent as First Officer Hicks progressively extended the flaps. The pilots also decided to leave engines 1 and 4 at a constant thrust level and adjust their airspeed using only engine 3, because that engine was least affected by the various electronic control system failures.</p><p id="4004">The problems only continued, however. Due to the failure of the green hydraulic system, the landing gear did not drop when the gear lever was selected â€œdown,â€ forcing the pilots to use a backup system that gravity drops the gear instead. Fortunately, this was successful. Captain de Crespigny also had to maintain a very narrow airspeed band, because there was only a fine margin between the slowest safe speed in the air, below which they would stall, and the highest safe speed on touchdown, above which they would overrun the runway. De Crespigny later recalled that the safe band between these speeds was probably only three or four knots. At one point, the airplane even generated an automatic low energy alert, warning that their airspeed was dropping too low for their present configuration â€” so de Crespigny increased power slightly on engine 3, and the alert went away.</p><p id="3866">Nevertheless, with the help of the Airbusâ€™s still operational fly-by-wire system and mostly undamaged controls, de Crespigny was able to thread the needle, greasing it onto runway 20C at Changi Airport at 11:46, just shy of two hours after the flight took off. A stall warning briefly sounded just before touchdown, but a split second later they were on the ground and the matter was moot. The pilots applied those brakes that were still working, activated reverse thrust on engine 3 â€” the A380 only has reversers on its inboard engines â€” and hoped that it would be enough. The deceleration was not exactly exuberant, but considering how much it takes to stop something the size of an A380 even on a good day, it was impressive enough. Nevertheless, it was not until fairly late in the rollout that the pilots felt certain that they would stop on the runway, and ultimately the performance software was not far off the mark: by the time the plane ground to a halt, only 150 meters remained of the 4,000-meter runway.</p><figure><figcaption>Firefighters spray foam on the airplane after its emergency landing. (Reuters)</figcaption></figure><p id="de92">And yet at that point, even if some of the passengers thought their ordeal was over, it turned out that there was more to come. As the pilots shut down the engines, they observed that the brake temperature on the left body gear brakes had risen alarmingly. These had been the only working brakes on the left side of the aircraft and were subject to considerable strain during the landing, causing them to overheat; the overheating in turn caused four tires to deflate. To make matters worse, fuel was still leaking from the wing, and there was genuine concern that a fire could erupt if spilled fuel contacted the hot brakes. And on top of that, when engines 3 and 4 were shut down, the plane lost electrical power, and when they tried to start the auxiliary power unit, it wouldnâ€™t hook up the electrical system because of damage to the distribution infrastructure. Operating solely on emergency electrical power, the plane now had only one working VHF radio, and it took a few moments for the crew to figure out which one that was so that de Crespigny could contact the airport fire services.</p><figure><figcaption>People disembark from flight 32. (Richard de Crespigny)</figcaption></figure><p id="7d03">Upon making contact with the fire crew, de Crespigny urged them to cool down the brakes, but the firefighter in charge replied with surprising news: the â„–1 engine was still running, even though the crew had already carried out the shutdown procedure. Damage to systems in the wing had rendered the â„–1 fuel shutoff valves inoperative, preventing the crew from shutting the engine down by normal means. Both fire extinguisher bottles in engine â„–1 were also inoperative, preventing the crew from shutting it down by pulling the emergency fire handle. Unable to resolve the issue, de Crespigny instead urged firefighters to approach the brakes while staying as far as possible from the inlet and exhaust ends of the â„–1 engine. If firefighters got too close to the inlet, they could be sucked into the fan; alternatively, approaching too close behind would result in severe burns, not to mention the jet blast. Nevertheless, the fire crews managed to get close enough to douse the brakes with foam, averting a conflagration.</p><p id="5d18">Throughout this period, the crew also debated whether or not to evacuate the passengers. An evacuation is not always an easy call: statistics show that around 5 to 10% of passengers who evacuate by the emergency escape slides sustain serious injuries, and with 440 passengers on board, including elderly and disabled, that was potentially a rather large number of people. Considering that the fire risk had been tamped down, the crew ultimately agreed that the safest place for the passengers was on the plane â€” at least for the moment. The flight attendants were asked to move to their stations on the right side of the aircraft to be ready for an emergency evacuation, should the calculus suddenly change, while the pilots attempted to call for a set of stairs to be brought to the aircraft. But with the only working radio being used to liaison with the firefighters, the only other working communications systems aboard the powered-down airplane were the pilotsâ€™ cell phones. It took quite some time, and several abortive attempts, before they managed to get through to someone at Qantas who could call the airport services company at Changi Airport and tell them to send a set of boarding stairs.</p><figure><figcaption>Firefighters attempt to drown the still-running â„–1 engine. (Reuters)</figcaption></figure><p id="8955">After 50 minutes aboard the increasingly sweltering airplane â€” without power, there was no air conditioning â€” the stairs finally arrived, and the disembarkation began. It ultimately took an hour to get everyone off through a single exit in an orderly manner, but in the end, all 440 passengers walked away without a single injury.</p><p id="0740">As for the still-running â„–1 engine, Qantas engineers eventually concluded that the only way to shut it down was to drown it with firefighting foam. Firefighters then poured huge amounts of water and foam into the intake, which proved successful, as the engine finally spooled down and stopped at 14:53, more than three hours after the aircraft landed.</p><p id="e852">â—Šâ—Šâ—Š</p><figure><figcaption>The crew of flight 32; from left to right: Mark Johnson, Matt Hicks, Richard de Crespigny, David Evans, and Harry Wubben. (Richard de Crespigny)</figcaption></figure><p id="a7ba">The news that the crippled Qantas A380 had landed safely in Singapore came as a great relief to all, especially those who were on board the airplane, who immediately heaped praise on the crew. Captain de Crespigny, in an exemplary act of professionalism, even handed out his personal phone number and stayed for two hours in the Qantas lounge in Singapore to answer passengersâ€™ questions about the flight. He and his crew were hailed as heroes, and not without reason. The sheer number of failures aboard the A380 eclipsed almost any other incident, at least on an aircraft with modern failure monitoring technology. Levelheaded decision-making, teamwork, and crew resource management helped the crew collectively determine the course of action least likely to result in injury or loss of life, with perfect results.</p><p id="0e19">The aircraft itself, however, helped quite a lot. The design of the flight control system ensured that the impact on controllability was limited, even with serious damage to the ailerons and the loss of one of two hydraulic systems. Despite its size, the A380 is known to respond very gracefully to control inputs thanks to the design of its fly-by-wire system, which during the incident remained fully intact, allowing the pilots to focus primarily on decision-making rather than handling the airplane. The ECAM and the detailed systems pages also helped the pilots take full stock of the extent of the failures in a way that was not necessarily possible two decades earlier. Without minimizing the actions of the crew in any way, itâ€™s also fair to say that the design of the A380 incorporated such redundancy and such high safety margins that the risk of a catastrophic crash was probably very low, even with so much damage to the airplane.</p><figure><figcaption>Dark colored residue inside the fuel tank near the breaches testified to a brief flash fire. (ATSB)</figcaption></figure><p id="4acb">However, there were a couple of places where the potential for worse damage existed. It goes without saying that if any of the turbine fragments had entered the passenger cabin, there would have been injuries, if not fatalities, even if the plane later landed safely. And perhaps even more worrying, investigators later found signs of a very brief flash fire inside the left wing fuel tank, which likely occurred when an extremely hot turbine fragment contacted fuel vapors in the tank ullage. Research conducted as part of the investigation into the 1996 crash of TWA flight 800, which was caused by an explosion of the center fuel tank, found that the wing tanks on commercial airliners contained flammable fuel-air mixtures around 7% of the time. However, on Qantas flight 32, the temperature in the tank was too low for the fuel-air mixture to reach a flammable concentration, and investigators determined that the brief ignition of vapors during passage of the turbine fragment likely failed to raise the temperature of the rest of the fuel sufficiently to sustain combustion. Had this fuel continued to burn, causing an explosion or sustained wing fire, then the outcome could have been very different.</p><figure><figcaption>Severed wires in the wing leading edge. (ATSB)</figcaption></figure><p id="b8cd">Even though these worst case scenarios didnâ€™t happen, the level of damage was still far beyond anything Airbus or Rolls-Royce had anticipated, and both companies were keen to know why â€” as were investigators with the Australian Transport Safety Bureau (ATSB), who were charged with finding out. Initial efforts established that an oil leak caused an internal fire that led to the failure of the IP turbine disk drive arm, as described previously. But that didnâ€™t answer one of the manufacturersâ€™ most burning questions, which was why the disk was allowed to overspeed until it burst â€” because according to the engineâ€™s design philosophy, this should never have happened.</p><p id="d712">The risk posed by a burst engine disk, whether itâ€™s a fan, compressor, or turbine, is well known in the industry. Numerous catastrophic accidents have occurred as a result of burst disks, either due to overspeed or material defects. Demonstrated side effects of burst disks include severe flight control damage (<a rel="noopener" href="https://admiralcloudberg.medium.com/fields-of-fortune-the-crash-of-united-airlines-flight-232-9cf65ae14c68">see United flight 232, Sioux City, Iowa, 1989,</a> in which fan disk debris resulted in the failure of all hydraulic systems, a loss of control on landing, and 111 deaths); direct fatal impacts to passengers (<a rel="noopener" href="https://admiralcloudberg.medium.com/written-in-metal-the-story-of-delta-air-lines-flight-1288-1205599c1b55">see Delta flight 1288, Pensacola, Florida, 1996,</a> in which a compressor disk entered the passenger cabin on takeoff, killing two passengers); and in-flight fires (<a rel="noopener" href="https://admiralcloudberg.medium.com/under-the-iron-curtain-the-crashes-of-lot-polish-airlines-flights-007-and-5055-f0f1c0ba4a64">see LOT Polish Airlines flight 5055, Warsaw, Poland, 1987,</a> which crashed after a fragment of a burst turbine disk started a fire in the baggage compartment, killing 183). Accidents such as these inform aircraft certification guidelines, which classify a disk failure as a â€œhazardousâ€ event whose probability must be â€œextremely remoteâ€ (defined as one event or less per 100 million operating hours). And just in case such an event were to happen anyway, rules introduced following the United accident in Sioux City also require manufacturers to minimize the potential secondary failures that could occur as a result, which was part of why the A380 had individual backup hydraulics for all critical control surfaces.</p><figure><figcaption>Officials inspect the damaged â„–2 engine. (Reuters)</figcaption></figure><p id="31ed">In general, the accident aboard flight 32 demonstrated that the requirements for damage minimization were met, with the exception of the resultant inability to cut fuel to the â„–1 engine, which was explicitly defined in certification guidelines as undesirable. This success alone distinguished it from previous, fatal disk release accidents. But Rolls-Royce was concerned that the disk burst at all. During development of the Trent 900, the company calculated that in the event that the IP turbine disk became disconnected from the drive shaft, the disk would not accelerate fast enough to burst. Essentially, it was believed that without the turbine to drive it, the IP compressor would decelerate until air no longer flowed smoothly over its blades, causing a compressor stall that would subsequently spread to the HP compressor behind it. This should lead to an engine surge, in which the disruption of airflow through the compressor section allows pressurized air from the combustion chamber to surge forward toward the front of the engine. In theory, this would reduce the amount of air flowing rearward through the annulus gas path and over the IP turbine, relieving the load on the turbine and preventing it from accelerating beyond its critical speed.</p><p id="a052">A key assumption here was that the IP compressor stall would happen faster than the advanced electronic engine control system could detect the surge and reduce fuel flow, which would bring down the combustion chamber pressure to clear the surge and restore normal airflow. In the actual event, investigators found that although the IP compressor stalled and a surge occurred, the automatic reduction in fuel flow came swiftly enough to enable the partial recovery of the HP compressor, which resumed forcing pressurized air into the combustion chamber and thence over the turbine. This unexpectedly robust airflow provided the mechanical energy required to accelerate the IP turbine disk beyond its critical speed. Rolls-Royce engineers were unable to conclusively determine why this occurred. Nevertheless, to prevent it from happening again, the company developed an IP turbine overspeed function for the electronic engine control that directly monitors the IP turbine disk and instantly cuts fuel flow to the engine if the disk starts spinning too fast.</p><p id="3d9e">â—Šâ—Šâ—Š</p></div><div><p id="03b1">Of course, if youâ€™ve gotten this far, then youâ€™re probably aware that one critical question remains. This entire chain of events began when the oil feed stub pipe â€” remember that? â€” developed a leak. If you need a refresher, this was the short segment of pipe that passed through the outer and inner sections of the bearing hub to deliver oil to the bearing chamber. So why did this happen?</p><p id="14f4">The answer, as it turns out, was visible to the naked eye. When investigators removed the faulty pipe, they found that one wall of the pipe was simply too thin. Unable to withstand the stresses of normal operation, it began suffering from metal fatigue and failed after only 677 flights.</p><figure><figcaption>How the oil feed stub pipe and its fittings were constructed. (ATSB, annotations mine)</figcaption></figure><p id="014e">The oil feed stub pipe was designed to have a slightly wider inner diameter at the bottom end in order to accommodate a filter. This required widening the interior diameter of the pipe by drilling a â€œcounter boreâ€ in from one end, as shown above. The center of the counter bore should be aligned with the center of the main bore. But on the stub pipe recovered from the failed Qantas engine, the counter bore was displaced to one side by approximately half a millimeter, resulting in an irregular wall thickness that varied from 1.42 mm on one side to only 0.35 mm on the other. It was this extra thin part of the pipe wall that failed on flight 32.</p><p id="b98e">The story of how the counter bore became offset by half a millimeter has implications that far outstrip the physical size of the error. The following section is going to involve some fairly complex discussions of the design and manufacturing process, but I hope youâ€™ll bear with me.</p><figure><figcaption>How the bores for the stub pipe were defined according to the design drawings. (ATSB, annotations mine)</figcaption></figure><p id="bafb">When the designs for the HP/IP bearing hub assembly were drawn up during the early 2000s, the design engineers followed standard practice by defining the position and dimensions of the oil feed stub pipe and associated features relative to a fixed point, referred to as a â€œdatum.â€ This point, designated datum AA, was defined as the hole in the outer section of the bearing hub through which the oil feed stub pipe passes on its way to the bearing chamber. This hole will henceforth be known as the â€œouter clearance hole.â€ All other aspects of the stub pipe fitting were positioned with respect to the centerline of this hole.</p><p id="c311">In line with the outer clearance hole, the designs also called for an â€œinterference boreâ€ in the inner hub into which the bottom end of the stub pipe would fit. The interference bore was designed to be very slightly narrower than the stub pipe so that the pipe end, once tapped firmly into place within it, would be held inside by friction. This bore was required to be centered on datum AA so as to keep it perfectly aligned with the outer clearance hole.</p><p id="a407">Next, an â€œinner hub counter boreâ€ would be drilled in from the inside of the inner hub, meeting in the middle with the interference bore. This was the hole through which the oil from the stub pipe would enter the bearing chamber.</p><p id="2407">Then, once these holes were machined, the oil feed stub pipe itself would be inserted through the outer clearance hole and into the interference bore, then welded in place.</p></div><div><p id="6465">Finally, working from the inside through the inner hub counter bore, the stub pipe counter bore would be drilled to a specified depth to accommodate the filter. (This was the bore that was later found to be offset by half a millimeter.) According to the design specifications, the stub pipe counter bore should be in line with datum AA, with a tolerance of Ã˜ 0.10 mm. In plain English, that means that the center of the counter bore should lie within a 0.10-mm-diameter circle centered on datum AA. It does not mean that the bore can be 0.10 mm from the datum, but rather <em>that the bore can lie within 0.05 mm of the datum in any direction, for a total range of possible positions measuring 0.10 mm across.</em> (Hereinafter, the term â€œoffsetâ€ refers to the distance of a given point from the datum, while the terms â€œtoleranceâ€ and â€œnon-conformance,â€ indicated with the â€œÃ˜â€ symbol, refer to the diameter of a circle centered on the datum with its edge at the given point. As confusing as this may be for some readers, this is how tolerances are measured in real life engineering, so if engineers can deal with it, so can you (hopefully).)</p><figure><figcaption>How the stub pipe and its fittings were defined according to the manufacturing stage drawings. (ATSB, annotations mine)</figcaption></figure><p id="78a8">In any case, when it came time to plan the actual manufacture of the bearing hub assembly, some changes had to be made to this process. The basic problem was that once the oil feed stub pipe was inserted into the hub assembly, it would no longer be possible for the machining computer to find the location of datum AA, because the outer clearance hole by which it was defined would be too full of stub pipe. That meant that it would be impossible to determine exactly where the oil feed stub pipe counter bore should subsequently be drilled.</p><p id="bb4c">In order to fix this problem, Rolls-Royce manufacturing engineers decided to redefine the position of the stub pipe counter bore with relation to a new datum, named datum M, which corresponded to the center of the inner hub counter bore. At the same time, the tolerance for the stub pipe counter bore was changed from Ã˜ 0.10 mm to Ã˜ 0.20 mm for unknown reasons. But the bigger problem was that the position of the stub pipe itself was determined by the position of the interference bore, which was still defined by datum AA. Because the position of the inner hub counter bore did not have a specified tolerance relative to datum AA â€” in fact, in the original design plan, its position didnâ€™t matter much at all â€” there was no direct assurance that datum M would line up with datum AA, and thus it could not be assured that the stub pipe would line up with its own counter bore either. At this point you might already be starting to see the problem.</p><figure><figcaption>How the series of bores was actually drilled. (ATSB, annotations mine)</figcaption></figure><p id="4890">The actual manufacturing process, based on the above specifications that were written into the manufacturing stage drawings, proceeded as follows. First, the basic hub assemblies were delivered to the Rolls-Royce machining plant in Hucknall, UK, with the outer clearance hole already drilled (and datum AA thus defined), but without the interference bore or the inner hub counter bore (datum M). Instead, a reference hole was drilled, with reference to datum AA, in the location that would later become the inner hub counter bore. A temporary timing pin was inserted into this reference hole, which was then used by the computerized machining equipment to orient the hub so that the machining arm aligned with datum AA. So far so good.</p><p id="4b4c">Subsequently, the interference bore was drilled, with reference to datum AA. Then came the most dastardly part: in order to drill the inner hub counter bore, the timing pin had to be removed, but the machine also needed to remember its location in order to know where to drill. Therefore, the machining computer used specialized probes to measure and record the position of the timing pin within three-dimensional space, allowing subsequent removal of the pin. At that point the only thing ensuring the correct alignment of the inner hub counter bore â€” and thus datum M, and thus the stub pipe counter bore â€” was the assumption that the recorded position of the timing pin remained accurate.</p><figure><figcaption>Can you see the offset in the drilled position of the inner hub counter bore? (ATSB)</figcaption></figure><p id="b667">Unfortunately, that assumption proved incorrect. The problem was that while the interference bore had been drilled from the outside, the inner hub counter bore had to be drilled from the inside, which necessitated the reconfiguration of the clamps holding the hub assembly in place, in order to make room for the machining arm. During this process, the hub assembly sometimes â€” but not always â€” shifted imperceptibly.</p><p id="5634">If the hub shifted, then when the machining process resumed, the recorded location of the timing pin (and thus datum AA) would by slightly offset from its actual, new location, and the machine would subsequently drill the inner hub counter bore offset by an equal amount. That meant that datum M â€” again, defined as the center of the inner hub counter bore â€” would also be offset from datum AA by that amount.</p><p id="b4db">Subsequently, the stub pipe was inserted through the outer clearance hole and into the interference bore, where it was welded in place. The stub pipe counter bore was then drilled into the end of the pipe with reference to datum M, which, again, would be offset if the hub had shifted. In the case of the components involved in the accident, the hub presumably shifted by just under half a millimeter, resulting in an equal offset of both the inner hub counter bore and the stub pipe counter bore relative to the pipe itself. As a side effect, one wall of the pipe was too thin.</p><figure><figcaption>The final product is created with a thin stub pipe wall. The best way to notice this offset of the stub pipe counter bore is by measuring the position of the interference bore relative to datum M. Measuring the interference bore relative to datum AA will not reveal the error. (ATSB)</figcaption></figure><p id="5f50">In the original design, no stub pipe wall thickness was specified; instead, adequate wall thickness was ensured by the alignment of both the pipe (via the interference bore) and its counter bore with the same datum (AA). The fact that this assurance could be lost when using the reworked manufacturing process was not recognized at the time, nor were the subsequent inspections tailored to find such a defect.</p><p id="7fa8">In this regard, two inspections are of note, both of which involved the use of a computerized coordinate machine, or CMM. One of these, known as OP 230, involved only the measurement of the stub pipe counter bore position relative to datum M, which provided no useful information as to its position relative to the pipe itself. A visual inspection was also conducted at this stage, but it was not possible for an inspector to observe the stub pipe wall thickness at the counter bore because this end of the pipe was welded inside the interference bore, completely out of sight.</p><p id="6d6e">Another inspection, called OP 70, occurred prior to OP 230 and presented a better opportunity to notice the error. During this inspection, the CMM measured the position of the interference bore relative to datum M, even though it was machined with reference to datum AA. If datum M and datum AA were offset by more than the specified tolerance for the interference bore, this should have caused the CMM to report an error in the position of the interference bore. The tolerance for this bore was supposed to be Ã˜ 0.05 mm according to the design drawings, but was changed to Ã˜ 0.5 mm in the manufacturing drawings without explanation. Even so, the non-conformance on the accident hub was between Ã˜ 0.90 and Ã˜ 0.98 (an offset of 0.45â€“0.49 mm), which should have been flagged by the machine. The CMM records from the accident hub were not retained, so it was not possible for investigators to confirm that the error was actually registered. However, even if it was, a follow-up inspection might have concluded that the error was false â€” because the manufacturing drawings specified the position of the interference bore relative to datum AA, and inspectors were generally unaware that the CMM was actually measuring the position of the bore relative to datum M. Therefore, if inspectors saw that the position of the interference bore was flagged as out of tolerance, they could refer to the manufacturing drawings, check the boreâ€™s position with reference to datum AA, find everything to be normal, and give the hub a clean bill of health.</p><figure><figcaption>A coordinate measuring machine used at the Hucknall facility. (ATSB)</figcaption></figure><p id="7b08">For the above reasons, numerous HP/IP bearing assembly hubs were released for service with oil feed stub pipe walls that may or may not have been too thin. No one was aware of this until 2009, after the accident hub was manufactured, when Hucknall Casings and Structures decided to change the datum for the oil feed stub pipe counter bore in order to simplify the manufacturing process. The change called for the use of datum AF, which was defined as the center of the pipeâ€™s main bore, to position the pipeâ€™s counter bore. Subsequently, two previously manufactured stub pipe counter bores were measured against this new datum and found to have a non-conformance of Ã˜ 0.5 mm (or an offset of 0.25 mm, about half that of the accident pipe). As a reminder, the tolerance for the stub pipe counter bore was supposed to be Ã˜ 0.20 (for a maximum permissible offset of 0.1 mm).</p><p id="8af6">This problem was soon called to the attention of a design engineer, who escalated it up the chain of command in order to figure out what to do about the approximately 100 oil feed stub pipes that had already been released for service. At issue was whether the error would have safety implications. If there were no safety implications, then the plant could issue what it termed a â€œretrospective concession,â€ allowing the improperly manufactured products to remain in service. But if there were safety implications, then there would need to be corrective actions, perhaps even a recall. In order to find out, a manufacturing engineer was assigned to conduct a statistical analysis of the likely distribution of oil stub pipe counter bore non-conformances based on measurements taken on nine previously manufactured hubs that were still at the facility. Using a statistical analysis program, the engineer found that the likely maximum non-conformance of any stub pipe counter bore was Ã˜ 0.7 mm (an offset of 0.35 mm). Engineering calculations showed that the resulting wall thickness would not seriously alter the service life of the stub pipe, which meant that there was no safety implications.</p><figure><figcaption>The revised manufacturing datum was much more robust, but the implications for previously produced hub assemblies were not adequately appreciated. (ATSB)</figcaption></figure><p id="2b98">In reality, this statistical analysis was flawed because of the low number of data points, and the lack of assurance that the dataset of nine hubs was representative of hubs manufactured in previous years. Therefore, the result should really have been read as â€œa maximum likely non-conformance of Ã˜ 0.7 mm plus or minus an uncertainty factor of unspecified magnitude.â€ However, the engineer was unfamiliar with the statistical analysis program and failed to clearly convey this uncertainty in the report that was submitted to the Non-Conformance Authority, the engineer empowered to make decisions about the acceptability of non-conformances. The Non-Conformance Authority took the report to mean that there were no safety implications, and signed off on the retroactive concession allowing the affected pipes, including the accident pipe, to remain in service.</p><p id="dd46">Investigators noted that according to Rolls-Royceâ€™s internal procedures, a retrospective concession also required the signatures of the Business Quality Director and more importantly the Chief Engineer, who had the power to decide whether any fleet-wide actions were warranted. Neither of these signatures were obtained for the retrospective concession that was granted to the oil feed stub pipes. The ATSB observed that the Hucknall facility was using the same paperwork for retrospective concessions as it used for concessions on non-conforming parts that were caught in-house, which did not require these extra signatures, so no signature field for them was provided. There was also nothing on the paperwork to indicate whether a concession was retrospective or not. As such, the Non-Conformance Authority might have been unaware that they lacked the right to unilaterally approve the concession without the consent of a higher-ranking engineer.</p><p id="8d31">â—Šâ—Šâ—Š</p><figure><figcaption>Another view of the damaged engine. (ATSB)</figcaption></figure><p id="d612">After the accident, measurements were taken on all in-service HP/IP bearing oil feed stub pipes to determine the alignment of their counter bores. The majority were outside the Ã˜ 0.20 mm tolerance on the manufacturing drawings, and several of them had non-conformances greater than the Ã˜ 0.7 mm predicted by the statistical analysis. Four of the stub pipes had non-conformances even greater than the accident pipe, and two were found to have a staggering non-conformance in the vicinity of Ã˜ 1.2 mm. These pipes likely would have failed in service, potentially causing repeats of the Qantas incident, had they not been caught.</p><p id="41f7">Investigators also criticized the culture within the Hucknall facility that manufactured the HP/IP bearing hubs, identifying signs of complacency and widespread procedural non-compliance. A paperwork review showed that the required signatures were missing from 131 out of 138 retrospective concessions issued between 2009 and 2011, and a large number of minor non-conformances had not been properly handled through the normal chain of command. An internal review in 2007 had also previously found that the Hucknall facility lacked a â€œstrong focus on quality within the business.â€ This appeared to extend to the creation of the original manufacturing drawings, which had been altered from the design drawings without the consent of the design engineers. Furthermore, initial inspections at the start of the production run were supposed to verify that the manufacturing process was creating products that satisfied the â€œdesign intent,â€ but the initial products were checked against the manufacturing drawings, not the design drawings. This verification was circular in nature and did nothing to ensure that the design intent was actually met. Had the design drawings been used, as procedures demanded, engineers likely would have been discovered that the process was not producing stub pipes with the required tolerances.</p><p id="b31e">â—Šâ—Šâ—Š</p><figure><figcaption>Another passenger view of the upper wing surface damage. (Reuters)</figcaption></figure><p id="0fd0">Following the accident, a long list of safety actions were taken to prevent a recurrence and incorporate lessons learned. A non-exhaustive list of these safety actions includes the following:</p><p id="b3a3">Â· Qantas temporarily grounded its A380 fleet between November 4 to November 27, 2010.</p><p id="9958">Â· The European Aviation Safety Agency issued an airworthiness directive mandating inspections of all Trent 900 oil feed stub pipes.</p><p id="3705">Â· Rolls-Royce developed an IP turbine overspeed protection system. Airbus issued a mandatory service bulletin requiring its installation on All A380s within 10 flights.</p><p id="b61b">Â· The entire original production run of HP/IP bearing hubs was removed from service and scrapped. All other HP/IP bearing hubs with an oil feed stub pipe wall thickness less than 0.7 mm were also removed from service.</p><p id="9bdc">Â· Rolls-Royce revised its procedures to ensure consultation between manufacturing and design engineers over the design intent of newly introduced parts.</p><p id="d73d">Â· A number of efforts were initiated to change the culture around non-conformances at the Hucknall facility.</p><p id="b015">Â· Rolls-Royce ended the practice of retrospective concessions and instituted a new program for dealing with non-conforming parts that escaped into service.</p><p id="8ced">Â· Airbus modified the landing performance software to more accurately predict the actual performance of the airplane at all landing weights.</p><p id="dfff">Collectively, these reforms have done much to ensure that Rolls-Royce continues to produce quality products, and to maintain the perfect safety record of the Airbus A380, which to date has never suffered an accident resulting in injury to passengers.</p><p id="959f">â—Šâ—Šâ—Š</p><figure><figcaption>Large sections of the airplaneâ€™s wing had to be replaced, among other repairs, but it eventually flew again. (Qantas)</figcaption></figure><p id="70b1">If you have made it this far, I first of all commend your patience, and/or your nerdiness. And second, I will speculate that everything youâ€™ve read thus far has probably left a positive impression of modern aviation safety. The sequence of events required to merely wound, not kill, this Airbus A380 was absurdly long, passing numerous gates at which the progress toward disaster could have been stopped. And yet the system still held its ground. According to the swiss cheese model of safety, an accident happens when the holes in the stacked swiss cheese slices align, allowing a hazard to pass straight through unhindered. The hazard in this case penetrated countless swiss cheese slices, from the drawing board to the manufacturing floor to the inspection room and beyond. But the industry has put up so many slices of cheese that even this impressive run was insufficient to put a scratch on so much as a single passenger. Even the airplane itself ultimately survived: after a marathon repair that lasted 535 days and cost $139 million, the A380 Nancy-Bird Walton triumphantly returned to the skies in 2012.</p><p id="0a27">A number of intangible lessons can be drawn from both the successes and failures along the road to Qantas 32, from the continued importance of experience and judgment in the cockpit, to the negative consequences of believing that a tiny non-conformance couldnâ€™t possibly be consequential. The fact remains that a deviation of less than half a millimeter nearly brought down the worldâ€™s largest passenger airliner. Aviation is, and has always been, unforgiving of even the smallest flaws. The devices, designs, and decisions that kept Qantas flight 32 in the air didnâ€™t appear from nothing, but are rather the collective result of rules, regulations, and forward-thinking policies imposed by people upon that unforgiving substrate. In that sense, the upshot of the drama aboard flight 32 is that at the end of the day, the system is working.</p><p id="883e">_______________________________________________________________</p><p id="2f3b"><em>Donâ€™t forget to listen to Controlled Pod Into Terrain, my new podcast (with slides!), where I discuss aerospace disasters with my cohosts Ariadne and J! </em><a href="https://www.youtube.com/@ControlledPodIntoTerrain" rel="noopener ugc nofollow" target="_blank"><em>Check out our channel here</em></a><em>, and </em><a href="https://www.youtube.com/watch?v=sEEuyZ4_qHo" rel="noopener ugc nofollow" target="_blank"><em>listen to our latest episode, in which we break down the incredibly poor decision-making aboard Pinnacle Airlines flight 3701. </em></a><em>Alternatively, download audio-only versions via </em><a href="https://rss.com/podcasts/cpit/" rel="noopener ugc nofollow" target="_blank"><em>RSS.com</em></a><em>, or look us up on Spotify!</em></p><p id="7809">_______________________________________________________________</p><p id="52c0"><a href="https://www.reddit.com/r/CatastrophicFailure/comments/18eg22j/2010_the_near_crash_of_qantas_flight_32_an_engine/?" rel="noopener ugc nofollow" target="_blank">Join the discussion of this article on Reddit</a></p><p id="5f25"><a href="https://www.patreon.com/Admiral_Cloudberg" rel="noopener ugc nofollow" target="_blank">Support me on Patreon</a> (Note: I do not earn money from views on Medium!)</p><p id="af1f"><a href="https://twitter.com/KyraCloudy" rel="noopener ugc nofollow" target="_blank">Follow me on Twitter</a></p><p id="c488">Visit <a href="https://www.reddit.com/r/AdmiralCloudberg/" rel="noopener ugc nofollow" target="_blank">r/admiralcloudberg</a> to read and discuss over 250 similar articles</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gooey: Turn almost any Python command line program into a full GUI application (676 pts)]]></title>
            <link>https://github.com/chriskiehl/Gooey</link>
            <guid>38586767</guid>
            <pubDate>Sat, 09 Dec 2023 22:30:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/chriskiehl/Gooey">https://github.com/chriskiehl/Gooey</a>, See on <a href="https://news.ycombinator.com/item?id=38586767">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Gooey</h2>
<p dir="auto">Turn (almost) any Python 3 Console Program into a GUI application with one line</p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/1-0-4-title-card.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/1-0-4-title-card.png"></a>
</p>
<h2 tabindex="-1" dir="auto">Table of Contents</h2>
<ul dir="auto">
<li><a href="#gooey">Gooey</a></li>
<li><a href="#table-of-contents">Table of contents</a></li>
<li><a href="#latest-update">Latest Update</a></li>
<li><a href="#quick-start">Quick Start</a>
<ul dir="auto">
<li><a href="#installation-instructions">Installation Instructions</a></li>
<li><a href="#usage">Usage</a></li>
<li><a href="#examples">Examples</a></li>
</ul>
</li>
<li><a href="#what-is-it">What It Is</a></li>
<li><a href="#why">Why Is It</a></li>
<li><a href="#who-is-this-for">Who is this for</a></li>
<li><a href="#how-does-it-work">How does it work</a></li>
<li><a href="#internationalization">Internationalization</a></li>
<li><a href="#global-configuration">Global Configuration</a></li>
<li><a href="#layout-customization">Layout Customization</a></li>
<li><a href="#run-modes">Run Modes</a>
<ul dir="auto">
<li><a href="#advanced">Full/Advanced</a></li>
<li><a href="#basic">Basic</a></li>
<li><a href="#no-config">No Config</a></li>
</ul>
</li>
<li><a href="#menus">Menus</a></li>
<li><a href="#dynamic-validation">Dynamic Validation</a></li>
<li><a href="#lifecycle-events-and-ui-control">Lifecycle Events and UI control</a></li>
<li><a href="#showing-progress">Showing Progress</a>
<ul dir="auto">
<li><a href="#elapsed--remaining-time">Elapsed / Remaining Time</a></li>
</ul>
</li>
<li><a href="#customizing-icons">Customizing Icons</a></li>
<li><a href="#packaging">Packaging</a></li>
<li><a href="#screenshots">Screenshots</a></li>
<li><a href="#wanna-help">Contributing</a></li>
<li><a href="#image-credits">Image Credits</a></li>
</ul>
<hr>
<h2 tabindex="-1" dir="auto">Quick Start</h2>
<h3 tabindex="-1" dir="auto">Installation instructions</h3>
<p dir="auto">The easiest way to install Gooey is via <code>pip</code></p>

<p dir="auto">Alternatively, you can install Gooey by cloning the project to your local directory</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/chriskiehl/Gooey.git"><pre><code>git clone https://github.com/chriskiehl/Gooey.git
</code></pre></div>
<p dir="auto">run <code>setup.py</code></p>

<h3 tabindex="-1" dir="auto">Usage</h3>
<p dir="auto">Gooey is attached to your code via a simple decorator on whichever method has your <code>argparse</code> declarations (usually <code>main</code>).</p>
<div data-snippet-clipboard-copy-content="from gooey import Gooey

@Gooey      <--- all it takes! :)
def main():
  parser = ArgumentParser(...)
  # rest of code"><pre><code>from gooey import Gooey

@Gooey      &lt;--- all it takes! :)
def main():
  parser = ArgumentParser(...)
  # rest of code
</code></pre></div>
<p dir="auto">Different styling and functionality can be configured by passing arguments into the decorator.</p>
<div data-snippet-clipboard-copy-content="# options
@Gooey(advanced=Boolean,          # toggle whether to show advanced config or not 
       language=language_string,  # Translations configurable via json
       auto_start=True,           # skip config screens all together
       target=executable_cmd,     # Explicitly set the subprocess executable arguments
       program_name='name',       # Defaults to script name
       program_description,       # Defaults to ArgParse Description
       default_size=(610, 530),   # starting size of the GUI
       required_cols=1,           # number of columns in the &quot;Required&quot; section
       optional_cols=2,           # number of columns in the &quot;Optional&quot; section
       dump_build_config=False,   # Dump the JSON Gooey uses to configure itself
       load_build_config=None,    # Loads a JSON Gooey-generated configuration
       monospace_display=False)   # Uses a mono-spaced font in the output screen
)
def main():
  parser = ArgumentParser(...)
  # rest of code"><pre><code># options
@Gooey(advanced=Boolean,          # toggle whether to show advanced config or not 
       language=language_string,  # Translations configurable via json
       auto_start=True,           # skip config screens all together
       target=executable_cmd,     # Explicitly set the subprocess executable arguments
       program_name='name',       # Defaults to script name
       program_description,       # Defaults to ArgParse Description
       default_size=(610, 530),   # starting size of the GUI
       required_cols=1,           # number of columns in the "Required" section
       optional_cols=2,           # number of columns in the "Optional" section
       dump_build_config=False,   # Dump the JSON Gooey uses to configure itself
       load_build_config=None,    # Loads a JSON Gooey-generated configuration
       monospace_display=False)   # Uses a mono-spaced font in the output screen
)
def main():
  parser = ArgumentParser(...)
  # rest of code
</code></pre></div>
<p dir="auto">See: <a href="#how-does-it-work">How does it Work</a> section for details on each option.</p>
<p dir="auto">Gooey will do its best to choose sensible widget defaults to display in the GUI. However, if more fine tuning is desired, you can use the drop-in replacement <code>GooeyParser</code> in place of <code>ArgumentParser</code>. This lets you control which widget displays in the GUI. See: <a href="#gooeyparser">GooeyParser</a></p>
<div data-snippet-clipboard-copy-content="from gooey import Gooey, GooeyParser

@Gooey
def main():
  parser = GooeyParser(description=&quot;My Cool GUI Program!&quot;) 
  parser.add_argument('Filename', widget=&quot;FileChooser&quot;)
  parser.add_argument('Date', widget=&quot;DateChooser&quot;)
  ..."><pre><code>from gooey import Gooey, GooeyParser

@Gooey
def main():
  parser = GooeyParser(description="My Cool GUI Program!") 
  parser.add_argument('Filename', widget="FileChooser")
  parser.add_argument('Date', widget="DateChooser")
  ...
</code></pre></div>
<h3 tabindex="-1" dir="auto">Examples</h3>
<p dir="auto">Gooey downloaded and installed? Great! Wanna see it in action? Head over the the <a href="https://github.com/chriskiehl/GooeyExamples">Examples Repository</a> to download a few ready-to-go example scripts. They'll give you a quick tour of all Gooey's various layouts, widgets, and features.</p>
<p dir="auto"><a href="https://github.com/chriskiehl/GooeyExamples/archive/master.zip">Direct Download</a></p>
<h2 tabindex="-1" dir="auto">What is it?</h2>
<p dir="auto">Gooey converts your Console Applications into end-user-friendly GUI applications. It lets you focus on building robust, configurable programs in a familiar way, all without having to worry about how it will be presented to and interacted with by your average user.</p>
<h2 tabindex="-1" dir="auto">Why?</h2>
<p dir="auto">Because as much as we love the command prompt, the rest of the world looks at it like an ugly relic from the early '80s. On top of that, more often than not programs need to do more than just one thing, and that means giving options, which previously meant either building a GUI, or trying to explain how to supply arguments to a Console Application. Gooey was made to (hopefully) solve those problems. It makes programs easy to use, and pretty to look at!</p>
<h2 tabindex="-1" dir="auto">Who is this for?</h2>
<p dir="auto">If you're building utilities for yourself, other programmers, or something which produces a result that you want to capture and pipe over to another console application (e.g. *nix philosophy utils), Gooey probably isn't the tool for you. However, if you're building 'run and done,' around-the-office-style scripts, things that shovel bits from point A to point B, or simply something that's targeted at a non-programmer, Gooey is the perfect tool for the job. It lets you build as complex of an application as your heart desires all while getting the GUI side for free.</p>
<h2 tabindex="-1" dir="auto">How does it work?</h2>
<p dir="auto">Gooey is attached to your code via a simple decorator on whichever method has your <code>argparse</code> declarations.</p>
<div data-snippet-clipboard-copy-content="@Gooey
def my_run_func():
  parser = ArgumentParser(...)
  # rest of code"><pre><code>@Gooey
def my_run_func():
  parser = ArgumentParser(...)
  # rest of code
</code></pre></div>
<p dir="auto">At run-time, it parses your Python script for all references to <code>ArgumentParser</code>. (The older <code>optparse</code> is currently not supported.) These references are then extracted, assigned a <code>component type</code> based on the <code>'action'</code> they provide, and finally used to assemble the GUI.</p>
<h4 tabindex="-1" dir="auto">Mappings:</h4>
<p dir="auto">Gooey does its best to choose sensible defaults based on the options it finds. Currently, <code>ArgumentParser._actions</code> are mapped to the following <code>WX</code> components.</p>
<table>
<thead>
<tr>
<th>Parser Action</th>
<th>Widget</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>store</td>
<td>TextCtrl</td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f54e9f5e-07c5-11e5-86e5-82f011c538cf.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f54e9f5e-07c5-11e5-86e5-82f011c538cf.png"></a></td>
</tr>
<tr>
<td>store_const</td>
<td>CheckBox</td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f538c850-07c5-11e5-8cbe-864badfa54a9.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f538c850-07c5-11e5-8cbe-864badfa54a9.png"></a></td>
</tr>
<tr>
<td>store_true</td>
<td>CheckBox</td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f538c850-07c5-11e5-8cbe-864badfa54a9.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f538c850-07c5-11e5-8cbe-864badfa54a9.png"></a></td>
</tr>
<tr>
<td>store_False</td>
<td>CheckBox</td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f538c850-07c5-11e5-8cbe-864badfa54a9.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f538c850-07c5-11e5-8cbe-864badfa54a9.png"></a></td>
</tr>
<tr>
<td>version</td>
<td>CheckBox</td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f538c850-07c5-11e5-8cbe-864badfa54a9.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f538c850-07c5-11e5-8cbe-864badfa54a9.png"></a></td>
</tr>
<tr>
<td>append</td>
<td>TextCtrl</td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f54e9f5e-07c5-11e5-86e5-82f011c538cf.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f54e9f5e-07c5-11e5-86e5-82f011c538cf.png"></a></td>
</tr>
<tr>
<td>count</td>
<td>DropDown &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f53ccbe4-07c5-11e5-80e5-510e2aa22922.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f53ccbe4-07c5-11e5-80e5-510e2aa22922.png"></a></td>
</tr>
<tr>
<td>Mutually Exclusive Group</td>
<td>RadioGroup</td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f553feb8-07c5-11e5-9d5b-eaa4772075a9.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f553feb8-07c5-11e5-9d5b-eaa4772075a9.png"></a></td>
</tr>
<tr>
<td>choice &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td>DropDown</td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f54e4da6-07c5-11e5-9e66-d8e6d7f18ac6.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f54e4da6-07c5-11e5-9e66-d8e6d7f18ac6.png"></a></td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto">GooeyParser</h3>
<p dir="auto">If the above defaults aren't cutting it, you can control the exact widget type by using the drop-in <code>ArgumentParser</code> replacement <code>GooeyParser</code>. This gives you the additional keyword argument <code>widget</code>, to which you can supply the name of the component you want to display. Best part? You don't have to change any of your <code>argparse</code> code to use it. Drop it in, and you're good to go.</p>
<p dir="auto"><strong>Example:</strong></p>
<div data-snippet-clipboard-copy-content="from argparse import ArgumentParser
....

def main(): 
    parser = ArgumentParser(description=&quot;My Cool Gooey App!&quot;)
    parser.add_argument('filename', help=&quot;name of the file to process&quot;) "><pre><code>from argparse import ArgumentParser
....

def main(): 
    parser = ArgumentParser(description="My Cool Gooey App!")
    parser.add_argument('filename', help="name of the file to process") 
</code></pre></div>
<p dir="auto">Given then above, Gooey would select a normal <code>TextField</code> as the widget type like this:</p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f5393e20-07c5-11e5-88e9-c153fc3ecfaa.PNG"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f5393e20-07c5-11e5-88e9-c153fc3ecfaa.PNG"></a>
</p>
<p dir="auto">However, by dropping in <code>GooeyParser</code> and supplying a <code>widget</code> name, you can display a much more user friendly <code>FileChooser</code></p>
<div data-snippet-clipboard-copy-content="from gooey import GooeyParser
....

def main(): 
    parser = GooeyParser(description=&quot;My Cool Gooey App!&quot;)
    parser.add_argument('filename', help=&quot;name of the file to process&quot;, widget='FileChooser') "><pre><code>from gooey import GooeyParser
....

def main(): 
    parser = GooeyParser(description="My Cool Gooey App!")
    parser.add_argument('filename', help="name of the file to process", widget='FileChooser') 
</code></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f53ae23e-07c5-11e5-8757-c8aa6f3013b5.PNG"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f53ae23e-07c5-11e5-8757-c8aa6f3013b5.PNG"></a></p>
<p dir="auto"><strong>Custom Widgets:</strong></p>
<table>
<thead>
<tr>
<th>Widget</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>DirChooser, FileChooser, MultiFileChooser, FileSaver, MultiFileSaver</td>
<td><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f5483b28-07c5-11e5-9d01-1935635fc22d.gif"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f5483b28-07c5-11e5-9d01-1935635fc22d.gif" width="400" data-animated-image=""></a></p></td>
</tr>
<tr>
<td>DateChooser/TimeChooser   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f544756a-07c5-11e5-86d6-862ac146ad35.gif"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f544756a-07c5-11e5-86d6-862ac146ad35.gif" width="400" data-animated-image=""></a></p> <p dir="auto">Please note that for both of these widgets the values passed to the application will always be in <a href="https://www.wxpython.org/Phoenix/docs/html/wx.DateTime.html#wx.DateTime.FormatISOTime" rel="nofollow">ISO format</a> while localized values may appear in some parts of the GUI depending on end-user settings.</p></td>
</tr>
<tr>
<td>PasswordField</td>
<td><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/28953722-eae72cca-788e-11e7-8fa1-9a1ef332a053.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/28953722-eae72cca-788e-11e7-8fa1-9a1ef332a053.png" width="400"></a></p></td>
</tr>
<tr>
<td>Listbox</td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/31590191-fadd06f2-b1c0-11e7-9a49-7cbf0c6d33d1.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/31590191-fadd06f2-b1c0-11e7-9a49-7cbf0c6d33d1.png" alt="image"></a></td>
</tr>
<tr>
<td>BlockCheckbox</td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/46922288-9296f200-cfbb-11e8-8b0d-ddde08064247.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/46922288-9296f200-cfbb-11e8-8b0d-ddde08064247.png" alt="image"></a> <br> The default InlineCheck box can look less than ideal if a large help text block is present. <code>BlockCheckbox</code> moves the text block to the normal position and provides a short-form <code>block_label</code> for display next to the control. Use <code>gooey_options.checkbox_label</code> to control the label text</td>
</tr>
<tr>
<td>ColourChooser   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td><p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/21027844/72672451-0752aa80-3a0f-11ea-86ed-8303bd3e54b5.gif"><img src="https://user-images.githubusercontent.com/21027844/72672451-0752aa80-3a0f-11ea-86ed-8303bd3e54b5.gif" width="400" data-animated-image=""></a></p></td>
</tr>
<tr>
<td>FilterableDropdown</td>
<td><p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/chriskiehl/GooeyImages/images/readme-images/filterable-dropdown.gif"><img src="https://raw.githubusercontent.com/chriskiehl/GooeyImages/images/readme-images/filterable-dropdown.gif" width="400" data-animated-image=""></a></p></td>
</tr>
<tr>
<td>IntegerField</td>
<td><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/integer-field.PNG"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/integer-field.PNG" width="400"></a></p></td>
</tr>
<tr>
<td>DecimalField</td>
<td><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/decimal-field.PNG"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/decimal-field.PNG" width="400"></a></p></td>
</tr>
<tr>
<td>Slider</td>
<td><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/slider.PNG"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/slider.PNG" width="400"></a></p></td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Internationalization</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f52e9f1a-07c5-11e5-8f31-36a8fc14ac02.jpg"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f52e9f1a-07c5-11e5-8f31-36a8fc14ac02.jpg"></a></p>
<p dir="auto">Gooey is international ready and easily ported to your host language. Languages are controlled via an argument to the <code>Gooey</code> decorator.</p>
<div data-snippet-clipboard-copy-content="@Gooey(language='russian')
def main(): 
    ... "><pre><code>@Gooey(language='russian')
def main(): 
    ... 
</code></pre></div>
<p dir="auto">All program text is stored externally in <code>json</code> files. So adding new language support is as easy as pasting a few key/value pairs in the <code>gooey/languages/</code> directory.</p>
<p dir="auto">Thanks to some awesome <a href="https://github.com/chriskiehl/Gooey/graphs/contributors">contributors</a>, Gooey currently comes pre-stocked with over 18 different translations!</p>
<p dir="auto">Want to add another one? Submit a <a href="https://github.com/chriskiehl/Gooey/compare">pull request!</a></p>
<hr>
<h2 tabindex="-1" dir="auto">Global Configuration</h2>
<p dir="auto">Just about everything in Gooey's overall look and feel can be customized by passing arguments to the decorator.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Summary</th>
</tr>
</thead>
<tbody>
<tr>
<td>encoding</td>
<td>Text encoding to use when displaying characters (default: 'utf-8')</td>
</tr>
<tr>
<td>use_legacy_titles</td>
<td>Rewrites the default argparse group name from "Positional" to "Required". This is primarily for retaining backward compatibility with previous versions of Gooey (which had poor support/awareness of groups and did its own naive bucketing of arguments).</td>
</tr>
<tr>
<td>advanced</td>
<td>Toggles whether to show the 'full' configuration screen, or a simplified version</td>
</tr>
<tr>
<td>auto_start</td>
<td>Skips the configuration all together and runs the program immediately</td>
</tr>
<tr>
<td>language</td>
<td>Tells Gooey which language set to load from the <code>gooey/languages</code> directory.</td>
</tr>
<tr>
<td>target</td>
<td>Tells Gooey how to re-invoke itself. By default Gooey will find python, but this allows you to specify the program (and arguments if supplied).</td>
</tr>
<tr>
<td>suppress_gooey_flag</td>
<td>Should be set when using a custom <code>target</code>. Prevent Gooey from injecting additional CLI params</td>
</tr>
<tr>
<td>program_name</td>
<td>The name displayed in the title bar of the GUI window. If not supplied, the title defaults to the script name pulled from <code>sys.argv[0]</code>.</td>
</tr>
<tr>
<td>program_description</td>
<td>Sets the text displayed in the top panel of the <code>Settings</code> screen. Defaults to the description pulled from <code>ArgumentParser</code>.</td>
</tr>
<tr>
<td>default_size</td>
<td>Initial size of the window</td>
</tr>
<tr>
<td>fullscreen</td>
<td>start Gooey in fullscreen mode</td>
</tr>
<tr>
<td>required_cols</td>
<td>Controls how many columns are in the Required Arguments section <br> <g-emoji alias="warning">âš ï¸</g-emoji> <strong>Deprecation notice:</strong> See <a href="https://github.com/chriskiehl/Gooey#layout-customization">Layout Customization</a> for modern layout controls</td>
</tr>
<tr>
<td>optional_cols</td>
<td>Controls how many columns are in the Optional Arguments section <br> <g-emoji alias="warning">âš ï¸</g-emoji> <strong>Deprecation notice:</strong> See <a href="https://github.com/chriskiehl/Gooey#layout-customization">Layout Customization</a> for modern layout controls</td>
</tr>
<tr>
<td>dump_build_config</td>
<td>Saves a <code>json</code> copy of its build configuration on disk for reuse/editing</td>
</tr>
<tr>
<td>load_build_config</td>
<td>Loads a <code>json</code> copy of its build configuration from disk</td>
</tr>
<tr>
<td>monospace_display</td>
<td>Uses a mono-spaced font in the output screen <br> <g-emoji alias="warning">âš ï¸</g-emoji> <strong>Deprecation notice:</strong> See <a href="https://github.com/chriskiehl/Gooey#layout-customization">Layout Customization</a> for modern font configuration</td>
</tr>
<tr>
<td>image_dir</td>
<td>Path to the directory in which Gooey should look for custom images/icons</td>
</tr>
<tr>
<td>language_dir</td>
<td>Path to the directory in which Gooey should look for custom languages files</td>
</tr>
<tr>
<td>disable_stop_button</td>
<td>Disable the <code>Stop</code> button when running</td>
</tr>
<tr>
<td>show_stop_warning</td>
<td>Displays a warning modal before allowing the user to force termination of your program</td>
</tr>
<tr>
<td>force_stop_is_error</td>
<td>Toggles whether an early termination by the shows the success or error screen</td>
</tr>
<tr>
<td>show_success_modal</td>
<td>Toggles whether or not to show a summary modal after a successful run</td>
</tr>
<tr>
<td>show_failure_modal</td>
<td>Toggles whether or not to show a summary modal on failure</td>
</tr>
<tr>
<td>show_restart_button</td>
<td>Toggles whether or not to show the restart button at the end of execution</td>
</tr>
<tr>
<td>run_validators</td>
<td>Controls whether or not to have Gooey perform validation before calling your program</td>
</tr>
<tr>
<td>poll_external_updates</td>
<td>(Experimental!) When True, Gooey will call your code with a <code>gooey-seed-ui</code> CLI argument and use the response to fill out dynamic values in the UI (See: <a href="#using-dynamic-values">Using Dynamic Values</a>)</td>
</tr>
<tr>
<td>use_cmd_args</td>
<td>Substitute any command line arguments provided at run time for the default values specified in the Gooey configuration</td>
</tr>
<tr>
<td>return_to_config</td>
<td>When True, Gooey will return to the configuration settings window upon successful run</td>
</tr>
<tr>
<td>progress_regex</td>
<td>A text regex used to pattern match runtime progress information. See: <a href="#showing-progress">Showing Progress</a> for a detailed how-to</td>
</tr>
<tr>
<td>progress_expr</td>
<td>A python expression applied to any matches found via the <code>progress_regex</code>. See: <a href="#showing-progress">Showing Progress</a> for a detailed how-to</td>
</tr>
<tr>
<td>hide_progress_msg</td>
<td>Option to hide textual progress updates which match the <code>progress_regex</code>. See: <a href="#showing-progress">Showing Progress</a> for a detailed how-to</td>
</tr>
<tr>
<td>disable_progress_bar_animation</td>
<td>Disable the progress bar</td>
</tr>
<tr>
<td>timing_options</td>
<td>This contains the options for displaying time remaining and elapsed time, to be used with <code>progress_regex</code> and <code>progress_expr</code>. <a href="#elapsed--remaining-time">Elapsed / Remaining Time</a>. Contained as a dictionary with the options <code>show_time_remaining</code> and <code>hide_time_remaining_on_complete</code>. Eg: <code>timing_options={'show_time_remaining':True,'hide_time_remaining_on_complete':True}</code></td>
</tr>
<tr>
<td>show_time_remaining</td>
<td>Disable the time remaining text see <a href="#elapsed--remaining-time">Elapsed / Remaining Time</a></td>
</tr>
<tr>
<td>hide_time_remaining_on_complete</td>
<td>Hide time remaining on complete screen see <a href="#elapsed--remaining-time">Elapsed / Remaining Time</a></td>
</tr>
<tr>
<td>requires_shell</td>
<td>Controls whether or not the <code>shell</code> argument is used when invoking your program. <a href="https://stackoverflow.com/questions/3172470/actual-meaning-of-shell-true-in-subprocess#3172488" rel="nofollow">More info here</a></td>
</tr>
<tr>
<td>shutdown_signal</td>
<td>Specifies the <code>signal</code> to send to the child process when the <code>stop</code> button is pressed. See <a href="https://github.com/chriskiehl/Gooey/tree/master/docs">Gracefully Stopping</a> in the docs for more info.</td>
</tr>
<tr>
<td>navigation</td>
<td>Sets the "navigation" style of Gooey's top level window. <br>Options: <table> <thead> <tr><th>TABBED</th><th>SIDEBAR</th></tr></thead> <tbody> <tr> <td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464826-2a946ba2-ee47-11e7-92a4-4afeb49dc9ca.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464826-2a946ba2-ee47-11e7-92a4-4afeb49dc9ca.png" width="200" height="auto"></a></td><td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464847-9918fbb0-ee47-11e7-8d5f-0d42631c2bc0.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464847-9918fbb0-ee47-11e7-8d5f-0d42631c2bc0.png" width="200" height="auto"></a></td></tr></tbody></table></td>
</tr>
<tr>
<td>sidebar_title</td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34472159-1bfedbd0-ef10-11e7-8bc3-b6d69febb8c3.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34472159-1bfedbd0-ef10-11e7-8bc3-b6d69febb8c3.png" width="250" height="auto"></a> Controls the heading title above the SideBar's navigation pane. Defaults to: "Actions"</td>
</tr>
<tr>
<td>show_sidebar</td>
<td>Show/Hide the sidebar in when navigation mode == <code>SIDEBAR</code></td>
</tr>
<tr>
<td>body_bg_color</td>
<td>HEX value of the main Gooey window</td>
</tr>
<tr>
<td>header_bg_color</td>
<td>HEX value of the header background</td>
</tr>
<tr>
<td>header_height</td>
<td>height in pixels of the header</td>
</tr>
<tr>
<td>header_show_title</td>
<td>Show/Hide the header title</td>
</tr>
<tr>
<td>header_show_subtitle</td>
<td>Show/Hide the header subtitle</td>
</tr>
<tr>
<td>footer_bg_color</td>
<td>HEX value of the Footer background</td>
</tr>
<tr>
<td>sidebar_bg_color</td>
<td>HEX value of the Sidebar's background</td>
</tr>
<tr>
<td>terminal_panel_color</td>
<td>HEX value of the terminal's panel</td>
</tr>
<tr>
<td>terminal_font_color</td>
<td>HEX value of the font displayed in Gooey's terminal</td>
</tr>
<tr>
<td>terminal_font_family</td>
<td>Name of the Font Family to use in the terminal</td>
</tr>
<tr>
<td>terminal_font_weight</td>
<td>Weight of the font (<code>constants.FONTWEIGHT_NORMAL</code>, <code>constants.FONTWEIGHT_XXX</code>)</td>
</tr>
<tr>
<td>terminal_font_size</td>
<td>Point size of the font displayed in the terminal</td>
</tr>
<tr>
<td>error_color</td>
<td>HEX value of the text displayed when a validation error occurs</td>
</tr>
<tr>
<td>richtext_controls</td>
<td>Switch on/off the console support for terminal control sequences (limited support for font weight and color). Defaults to : False. See <a href="https://github.com/chriskiehl/Gooey/tree/master/docs">docs</a> for additional details</td>
</tr>
<tr>
<td>menus</td>
<td>Show custom menu groups and items (see: <a href="#menus">Menus</a></td>
</tr>
<tr>
<td>clear_before_run</td>
<td>When true, previous output will be cleared from the terminal when running program again</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Layout Customization</h2>
<p dir="auto">You can achieve fairly flexible layouts with Gooey by using a few simple customizations.</p>
<p dir="auto">At the highest level, you have several overall layout options controllable via various arguments to the Gooey decorator.</p>
<table>
<thead>
<tr>
<th><code>show_sidebar=True</code></th>
<th><code>show_sidebar=False</code></th>
<th><code>navigation='TABBED'</code></th>
<th><code>tabbed_groups=True</code></th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464847-9918fbb0-ee47-11e7-8d5f-0d42631c2bc0.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464847-9918fbb0-ee47-11e7-8d5f-0d42631c2bc0.png" width="400"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/35487799-762aa308-0434-11e8-8eb3-1e9fab2d13ae.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/35487799-762aa308-0434-11e8-8eb3-1e9fab2d13ae.png" width="400"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464835-5ba9b0e4-ee47-11e7-9561-55e3647c2165.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464835-5ba9b0e4-ee47-11e7-9561-55e3647c2165.png" width="400"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464826-2a946ba2-ee47-11e7-92a4-4afeb49dc9ca.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464826-2a946ba2-ee47-11e7-92a4-4afeb49dc9ca.png" width="400"></a></td>
</tr>
</tbody>
</table>
<p dir="auto"><strong>Grouping Inputs</strong></p>
<p dir="auto">By default, if you're using Argparse with Gooey, your inputs will be split into two buckets: <code>positional</code> and <code>optional</code>. However, these aren't always the most descriptive groups to present to your user. You can arbitrarily bucket inputs into logic groups and customize the layout of each.</p>
<p dir="auto">With <code>argparse</code> this is done via <code>add_argument_group()</code></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/35487956-a4c9915e-0436-11e8-8a11-fd21528aedf0.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/35487956-a4c9915e-0436-11e8-8a11-fd21528aedf0.png" width="410"></a></p>
<div data-snippet-clipboard-copy-content="parser = ArgumentParser()
search_group = parser.add_argument_group(
    &quot;Search Options&quot;, 
    &quot;Customize the search options&quot;
)"><pre><code>parser = ArgumentParser()
search_group = parser.add_argument_group(
    "Search Options", 
    "Customize the search options"
)
</code></pre></div>
<p dir="auto">You can add arguments to the group as normal</p>
<div data-snippet-clipboard-copy-content="search_group.add_argument(
    '--query', 
    help='Base search string'
) "><pre><code>search_group.add_argument(
    '--query', 
    help='Base search string'
) 
</code></pre></div>
<p dir="auto">Which will display them as part of the group within the UI.</p>
<h2 tabindex="-1" dir="auto">Run Modes</h2>
<p dir="auto">Gooey has a handful of presentation modes so you can tailor its layout to your content type and user's level or experience.</p>
<h3 tabindex="-1" dir="auto">Advanced</h3>
<p dir="auto">The default view is the "full" or "advanced" configuration screen. It has two different layouts depending on the type of command line interface it's wrapping. For most applications, the flat layout will be the one to go with, as its layout matches best to the familiar CLI schema of a primary command followed by many options (e.g. Curl, FFMPEG).</p>
<p dir="auto">On the other side is the Column Layout. This one is best suited for CLIs that have multiple paths or are made up of multiple little tools each with their own arguments and options (think: git). It displays the primary paths along the left column, and their corresponding arguments in the right. This is a great way to package a lot of varied functionality into a single app.</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f06a36cc-08ad-11e5-843e-9322df96d4d6.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f06a36cc-08ad-11e5-843e-9322df96d4d6.png"></a>
</p>
<p dir="auto">Both views present each action in the <code>Argument Parser</code> as a unique GUI component. It makes it ideal for presenting the program to users which are unfamiliar with command line options and/or Console Programs in general. Help messages are displayed along side each component to make it as clear as possible which each widget does.</p>
<p dir="auto"><strong>Setting the layout style:</strong></p>
<p dir="auto">Currently, the layouts can't be explicitly specified via a parameter (on the TODO!). The layouts are built depending on whether or not there are <code>subparsers</code> used in your code base. So, if you want to trigger the <code>Column Layout</code>, you'll need to add a <code>subparser</code> to your <code>argparse</code> code.</p>
<p dir="auto">It can be toggled via the <code>advanced</code> parameter in the <code>Gooey</code> decorator.</p>
<div data-snippet-clipboard-copy-content="@gooey(advanced=True)
def main():
    # rest of code   "><pre><code>@gooey(advanced=True)
def main():
    # rest of code   
</code></pre></div>
<hr>
<h3 tabindex="-1" dir="auto">Basic</h3>
<p dir="auto">The basic view is best for times when the user is familiar with Console Applications, but you still want to present something a little more polished than a simple terminal. The basic display is accessed by setting the <code>advanced</code> parameter in the <code>gooey</code> decorator to <code>False</code>.</p>
<div data-snippet-clipboard-copy-content="@gooey(advanced=False)
def main():
    # rest of code  "><pre><code>@gooey(advanced=False)
def main():
    # rest of code  
</code></pre></div>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f53a4306-07c5-11e5-8e63-b510d6db9953.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f53a4306-07c5-11e5-8e63-b510d6db9953.png"></a>
</p>
<hr>
<h3 tabindex="-1" dir="auto">No Config</h3>
<p dir="auto">No Config pretty much does what you'd expect: it doesn't show a configuration screen. It hops right to the <code>display</code> section and begins execution of the host program. This is the one for improving the appearance of little one-off scripts.</p>
<p dir="auto">To use this mode, set <code>auto_start=True</code> in the Gooey decorator.</p>
<div dir="auto" data-snippet-clipboard-copy-content="@Gooey(auto_start=True) 
def main (): 
    ... "><pre><span>@<span>Gooey</span>(<span>auto_start</span><span>=</span><span>True</span>)</span> 
<span>def</span> <span>main</span> (): 
    ... </pre></div>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f54fe6f2-07c5-11e5-92e4-f72a2ae12862.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/f54fe6f2-07c5-11e5-92e4-f72a2ae12862.png"></a>
</p>
<hr>
<h3 tabindex="-1" dir="auto">Menus</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/47250909-74782a00-d3df-11e8-88ac-182d06c4435a.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/47250909-74782a00-d3df-11e8-88ac-182d06c4435a.png" alt="image"></a></p>
<blockquote>
<p dir="auto">Added 1.0.2</p>
</blockquote>
<p dir="auto">You can add a Menu Bar to the top of Gooey with customized menu groups and items.</p>
<p dir="auto">Menus are specified on the main <code>@Gooey</code> decorator as a list of maps.</p>
<div data-snippet-clipboard-copy-content="@Gooey(menu=[{}, {}, ...])"><pre><code>@Gooey(menu=[{}, {}, ...])
</code></pre></div>
<p dir="auto">Each map is made up of two key/value pairs</p>
<ol dir="auto">
<li><code>name</code> - the name for this menu group</li>
<li><code>items</code> - the individual menu items within this group</li>
</ol>
<p dir="auto">You can have as many menu groups as you want. They're passed as a list to the <code>menu</code> argument on the <code>@Gooey</code> decorator.</p>
<div data-snippet-clipboard-copy-content="@Gooey(menu=[{'name': 'File', 'items: []},
             {'name': 'Tools', 'items': []},
             {'name': 'Help', 'items': []}])"><pre><code>@Gooey(menu=[{'name': 'File', 'items: []},
             {'name': 'Tools', 'items': []},
             {'name': 'Help', 'items': []}])
</code></pre></div>
<p dir="auto">Individual menu items in a group are also just maps of key / value pairs. Their exact key set varies based on their <code>type</code>, but two keys will always be present:</p>
<ul dir="auto">
<li><code>type</code> - this controls the behavior that will be attached to the menu item as well as the keys it needs specified</li>
<li><code>menuTitle</code> - the name for this MenuItem</li>
</ul>
<p dir="auto">Currently, three types of menu options are supported:</p>
<ul dir="auto">
<li>AboutDialog</li>
<li>MessageDialog</li>
<li>Link</li>
<li>HtmlDialog</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/47251026-9ffc1400-d3e1-11e8-9095-982a6367561b.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/47251026-9ffc1400-d3e1-11e8-9095-982a6367561b.png" width="400" height="auto"></a></p>
<p dir="auto"><strong>About Dialog</strong> is your run-of-the-mill About Dialog. It displays program information such as name, version, and license info in a standard native AboutBox.</p>
<p dir="auto">Schema</p>
<ul dir="auto">
<li><code>name</code> - (<em>optional</em>)</li>
<li><code>description</code> - (<em>optional</em>)</li>
<li><code>version</code> - (<em>optional</em>)</li>
<li><code>copyright</code> - (<em>optional</em>)</li>
<li><code>license</code> - (<em>optional</em>)</li>
<li><code>website</code> - (<em>optional</em>)</li>
<li><code>developer</code> - (<em>optional</em>)</li>
</ul>
<p dir="auto">Example:</p>
<div data-snippet-clipboard-copy-content="{
    'type': 'AboutDialog',
    'menuTitle': 'About',
    'name': 'Gooey Layout Demo',
    'description': 'An example of Gooey\'s layout flexibility',
    'version': '1.2.1',
    'copyright': '2018',
    'website': 'https://github.com/chriskiehl/Gooey',
    'developer': 'http://chriskiehl.com/',
    'license': 'MIT'
}"><pre><code>{
    'type': 'AboutDialog',
    'menuTitle': 'About',
    'name': 'Gooey Layout Demo',
    'description': 'An example of Gooey\'s layout flexibility',
    'version': '1.2.1',
    'copyright': '2018',
    'website': 'https://github.com/chriskiehl/Gooey',
    'developer': 'http://chriskiehl.com/',
    'license': 'MIT'
}
</code></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/47250925-bbfeb600-d3df-11e8-88a8-5ba838e9466d.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/47250925-bbfeb600-d3df-11e8-88a8-5ba838e9466d.png" width="400" height="auto"></a></p>
<p dir="auto"><strong>MessageDialog</strong> is a generic informational dialog box. You can display anything from small alerts, to long-form informational text to the user.</p>
<p dir="auto">Schema:</p>
<ul dir="auto">
<li><code>message</code> - (<em>required</em>) the text to display in the body of the modal</li>
<li><code>caption</code> - (<em>optional</em>) the caption in the title bar of the modal</li>
</ul>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
    'type': 'MessageDialog',
    'menuTitle': 'Information',
    'message': 'Hey, here is some cool info for ya!',
    'caption': 'Stuff you should know'
}"><pre>{
    <span>'type'</span>: <span>'MessageDialog'</span>,
    <span>'menuTitle'</span>: <span>'Information'</span>,
    <span>'message'</span>: <span>'Hey, here is some cool info for ya!'</span>,
    <span>'caption'</span>: <span>'Stuff you should know'</span>
}</pre></div>
<p dir="auto"><strong>Link</strong> is for sending the user to an external website. This will spawn their default browser at the URL you specify.</p>
<p dir="auto">Schema:</p>
<ul dir="auto">
<li><code>url</code> - (<em>required</em>) - the fully qualified URL to visit</li>
</ul>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
    'type': 'Link',
    'menuTitle': 'Visit Out Site',
    'url': 'http://www.example.com'
}"><pre>{
    <span>'type'</span>: <span>'Link'</span>,
    <span>'menuTitle'</span>: <span>'Visit Out Site'</span>,
    <span>'url'</span>: <span>'http://www.example.com'</span>
}</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/docs/menus/html-dialog.PNG"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/docs/menus/html-dialog.PNG" width="400" height="auto"></a></p>
<p dir="auto"><strong>HtmlDialog</strong> gives you full control over what's displayed in the message dialog (bonus: people can copy/paste text from this one!).</p>
<p dir="auto">Schema:</p>
<ul dir="auto">
<li><code>caption</code> - (<em>optional</em>) the caption in the title bar of the modal</li>
<li><code>html</code> - (<em>required</em>) the html you want displayed in the dialog. Note: only a small subset of HTML is supported. <a href="https://wxpython.org/Phoenix/docs/html/html_overview.html" rel="nofollow">See the WX docs for more info</a>.</li>
</ul>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
    'type': 'HtmlDialog',
    'menuTitle': 'Fancy Dialog!',
    'caption': 'Demo of the HtmlDialog',
    'html': '''
    <body bgcolor=&quot;white&quot;>
        <img src=/path/to/your/image.png&quot; /> 
        <h1>Hello world!</h1> 
        <p><font color=&quot;red&quot;>Lorem ipsum dolor sit amet, consectetur</font></p>
    </body>
    '''
}
"><pre>{
    <span>'type'</span>: <span>'HtmlDialog'</span>,
    <span>'menuTitle'</span>: <span>'Fancy Dialog!'</span>,
    <span>'caption'</span>: <span>'Demo of the HtmlDialog'</span>,
    <span>'html'</span>: <span>'''</span>
<span>    &lt;body bgcolor="white"&gt;</span>
<span>        &lt;img src=/path/to/your/image.png" /&gt; </span>
<span>        &lt;h1&gt;Hello world!&lt;/h1&gt; </span>
<span>        &lt;p&gt;&lt;font color="red"&gt;Lorem ipsum dolor sit amet, consectetur&lt;/font&gt;&lt;/p&gt;</span>
<span>    &lt;/body&gt;</span>
<span>    '''</span>
}</pre></div>
<p dir="auto"><strong>A full example:</strong></p>
<p dir="auto">Two menu groups ("File" and "Help") with four menu items between them.</p>
<div dir="auto" data-snippet-clipboard-copy-content="@Gooey(
    program_name='Advanced Layout Groups',
    menu=[{
        'name': 'File',
        'items': [{
                'type': 'AboutDialog',
                'menuTitle': 'About',
                'name': 'Gooey Layout Demo',
                'description': 'An example of Gooey\'s layout flexibility',
                'version': '1.2.1',
                'copyright': '2018',
                'website': 'https://github.com/chriskiehl/Gooey',
                'developer': 'http://chriskiehl.com/',
                'license': 'MIT'
            }, {
                'type': 'MessageDialog',
                'menuTitle': 'Information',
                'caption': 'My Message',
                'message': 'I am demoing an informational dialog!'
            }, {
                'type': 'Link',
                'menuTitle': 'Visit Our Site',
                'url': 'https://github.com/chriskiehl/Gooey'
            }]
        },{
        'name': 'Help',
        'items': [{
            'type': 'Link',
            'menuTitle': 'Documentation',
            'url': 'https://www.readthedocs.com/foo'
        }]
    }]
)"><pre><span>@<span>Gooey</span>(</span>
<span>    <span>program_name</span><span>=</span><span>'Advanced Layout Groups'</span>,</span>
<span>    <span>menu</span><span>=</span>[{</span>
<span>        <span>'name'</span>: <span>'File'</span>,</span>
<span>        <span>'items'</span>: [{</span>
<span>                <span>'type'</span>: <span>'AboutDialog'</span>,</span>
<span>                <span>'menuTitle'</span>: <span>'About'</span>,</span>
<span>                <span>'name'</span>: <span>'Gooey Layout Demo'</span>,</span>
<span>                <span>'description'</span>: <span>'An example of Gooey<span>\'</span>s layout flexibility'</span>,</span>
<span>                <span>'version'</span>: <span>'1.2.1'</span>,</span>
<span>                <span>'copyright'</span>: <span>'2018'</span>,</span>
<span>                <span>'website'</span>: <span>'https://github.com/chriskiehl/Gooey'</span>,</span>
<span>                <span>'developer'</span>: <span>'http://chriskiehl.com/'</span>,</span>
<span>                <span>'license'</span>: <span>'MIT'</span></span>
<span>            }, {</span>
<span>                <span>'type'</span>: <span>'MessageDialog'</span>,</span>
<span>                <span>'menuTitle'</span>: <span>'Information'</span>,</span>
<span>                <span>'caption'</span>: <span>'My Message'</span>,</span>
<span>                <span>'message'</span>: <span>'I am demoing an informational dialog!'</span></span>
<span>            }, {</span>
<span>                <span>'type'</span>: <span>'Link'</span>,</span>
<span>                <span>'menuTitle'</span>: <span>'Visit Our Site'</span>,</span>
<span>                <span>'url'</span>: <span>'https://github.com/chriskiehl/Gooey'</span></span>
<span>            }]</span>
<span>        },{</span>
<span>        <span>'name'</span>: <span>'Help'</span>,</span>
<span>        <span>'items'</span>: [{</span>
<span>            <span>'type'</span>: <span>'Link'</span>,</span>
<span>            <span>'menuTitle'</span>: <span>'Documentation'</span>,</span>
<span>            <span>'url'</span>: <span>'https://www.readthedocs.com/foo'</span></span>
<span>        }]</span>
<span>    }]</span>
<span>)</span></pre></div>
<hr>
<h3 tabindex="-1" dir="auto">Dynamic Validation</h3>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464861-0e82c214-ee48-11e7-8f4a-a8e00721efef.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464861-0e82c214-ee48-11e7-8f4a-a8e00721efef.png" width="400" height="auto"></a></p>
<blockquote>
<p dir="auto"><g-emoji alias="warning">âš ï¸</g-emoji>
Note! This functionality is experimental and likely to be unstable. Its API may be changed or removed altogether. Feedback/thoughts on this feature is welcome and encouraged!</p>
</blockquote>
<blockquote>
<p dir="auto"><g-emoji alias="warning">âš ï¸</g-emoji>
See <a href="https://github.com/chriskiehl/Gooey/blob/master">Release Notes</a> for guidance on upgrading from 1.0.8 to 1.2.0</p>
</blockquote>
<p dir="auto">Before passing the user's inputs to your program, Gooey can optionally run a special pre-flight validation to check that all arguments pass your specified validations.</p>
<p dir="auto"><strong>How does it work?</strong></p>
<p dir="auto">Gooey piggy backs on the <code>type</code> parameter available to most Argparse Argument types.</p>
<div dir="auto" data-snippet-clipboard-copy-content="parser.add_argument('--some-number', type=int)
parser.add_argument('--some-number', type=float)"><pre><span>parser</span>.<span>add_argument</span>(<span>'--some-number'</span>, <span>type</span><span>=</span><span>int</span>)
<span>parser</span>.<span>add_argument</span>(<span>'--some-number'</span>, <span>type</span><span>=</span><span>float</span>)</pre></div>
<p dir="auto">In addition to simple builtins like <code>int</code> and <code>float</code>, you can supply your own function to the <code>type</code> parameter to vet the incoming values.</p>
<div dir="auto" data-snippet-clipboard-copy-content="def must_be_exactly_ten(value): 
    number = int(value) 
    if number == 10:
        return number
    else: 
        raise TypeError(&quot;Hey! you need to provide exactly the number 10!&quot;)
        
        
def main(): 
    parser = ArgumentParser()
    parser.add_argument('--ten', type=must_be_exactly_ten)"><pre><span>def</span> <span>must_be_exactly_ten</span>(<span>value</span>): 
    <span>number</span> <span>=</span> <span>int</span>(<span>value</span>) 
    <span>if</span> <span>number</span> <span>==</span> <span>10</span>:
        <span>return</span> <span>number</span>
    <span>else</span>: 
        <span>raise</span> <span>TypeError</span>(<span>"Hey! you need to provide exactly the number 10!"</span>)
        
        
<span>def</span> <span>main</span>(): 
    <span>parser</span> <span>=</span> <span>ArgumentParser</span>()
    <span>parser</span>.<span>add_argument</span>(<span>'--ten'</span>, <span>type</span><span>=</span><span>must_be_exactly_ten</span>)</pre></div>
<p dir="auto"><strong>How to enable the pre-flight validation</strong></p>
<p dir="auto">By default, Gooey won't run the validation. Why? This feature is fairly experimental and does a lot of intense Monkey Patching behind the scenes. As such, it's currently opt-in.</p>
<p dir="auto">You enable to validation by telling Gooey you'd like to subscribe to the <code>VALIDATE_FORM</code> event.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from gooey import Gooey, Events 

@Gooey(use_events=[Events.VALIDATE_FORM])
def main(): 
    ... "><pre><span>from</span> <span>gooey</span> <span>import</span> <span>Gooey</span>, <span>Events</span> 

<span>@<span>Gooey</span>(<span>use_events</span><span>=</span>[<span>Events</span>.<span>VALIDATE_FORM</span>])</span>
<span>def</span> <span>main</span>(): 
    ... </pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/dynamic-validation-1-2-0.JPG"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/dynamic-validation-1-2-0.JPG"></a></p>
<p dir="auto">Now, when you run Gooey, before it invokes your main program, it'll send a separate pre-validation check and record any issues raised from your <code>type</code> functions.</p>
<p dir="auto"><strong>Full Code Example</strong></p>
<div data-snippet-clipboard-copy-content="from gooey import Gooey, Events
from argparse import ArgumentParser

def must_be_exactly_ten(value):
    number = int(value)
    if number == 10:
        return number
    else:
        raise TypeError(&quot;Hey! you need to provide exactly the number 10!&quot;)

@Gooey(program_name='Validation Example', use_events=[Events.VALIDATE_FORM])
def main():
    parser = ArgumentParser(description=&quot;Checkout this validation!&quot;)
    parser.add_argument('--ten', metavar='This field should be 10', type=must_be_exactly_ten)
    args = parser.parse_args()
    print(args)"><pre><code>from gooey import Gooey, Events
from argparse import ArgumentParser

def must_be_exactly_ten(value):
    number = int(value)
    if number == 10:
        return number
    else:
        raise TypeError("Hey! you need to provide exactly the number 10!")

@Gooey(program_name='Validation Example', use_events=[Events.VALIDATE_FORM])
def main():
    parser = ArgumentParser(description="Checkout this validation!")
    parser.add_argument('--ten', metavar='This field should be 10', type=must_be_exactly_ten)
    args = parser.parse_args()
    print(args)
</code></pre></div>
<hr>
<h2 tabindex="-1" dir="auto">Lifecycle Events and UI control</h2>
<blockquote>
<p dir="auto"><g-emoji alias="warning">âš ï¸</g-emoji>
Note! This functionality is experimental. Its API may be changed or removed altogether. Feedback on this feature is welcome and encouraged!</p>
</blockquote>
<p dir="auto">As of 1.2.0, Gooey now exposes coarse grain lifecycle hooks to your program. This means you can now take additional follow-up actions in response to successful runs or failures and even control the current state of the UI itself!</p>
<p dir="auto">Currently, two primary hooks are exposed:</p>
<ul dir="auto">
<li><code>on_success</code></li>
<li><code>on_error</code></li>
</ul>
<p dir="auto">These fire exactly when you'd expect: after your process has completed.</p>
<p dir="auto"><strong>Anatomy of an lifecycle handler</strong>:</p>
<p dir="auto">Both <code>on_success</code> and <code>on_error</code> have the same type signature.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from typing import Mapping, Any, Optional
from gooey.types import PublicGooeyState  

def on_success(args: Mapping[str, Any], state: PublicGooeyState) -> Optional[PublicGooeyState]:
    &quot;&quot;&quot;
    You can do anything you want in the handler including 
    returning an updated UI state for your next run!   
    &quot;&quot;&quot; 
    return state
    
def on_error(args: Mapping[str, Any], state: PublicGooeyState) -> Optional[PublicGooeyState]:
    &quot;&quot;&quot;
    You can do anything you want in the handler including 
    returning an updated UI state for your next run!   
    &quot;&quot;&quot; 
    return state    "><pre><span>from</span> <span>typing</span> <span>import</span> <span>Mapping</span>, <span>Any</span>, <span>Optional</span>
<span>from</span> <span>gooey</span>.<span>types</span> <span>import</span> <span>PublicGooeyState</span>  

<span>def</span> <span>on_success</span>(<span>args</span>: <span>Mapping</span>[<span>str</span>, <span>Any</span>], <span>state</span>: <span>PublicGooeyState</span>) <span>-&gt;</span> <span>Optional</span>[<span>PublicGooeyState</span>]:
    <span>"""</span>
<span>    You can do anything you want in the handler including </span>
<span>    returning an updated UI state for your next run!   </span>
<span>    """</span> 
    <span>return</span> <span>state</span>
    
<span>def</span> <span>on_error</span>(<span>args</span>: <span>Mapping</span>[<span>str</span>, <span>Any</span>], <span>state</span>: <span>PublicGooeyState</span>) <span>-&gt;</span> <span>Optional</span>[<span>PublicGooeyState</span>]:
    <span>"""</span>
<span>    You can do anything you want in the handler including </span>
<span>    returning an updated UI state for your next run!   </span>
<span>    """</span> 
    <span>return</span> <span>state</span>    </pre></div>
<ul dir="auto">
<li><strong>args</strong> This is the parsed Argparse object (e.g. the output of <code>parse_args()</code>). This will be a mapping of the user's arguments as existed when your program was invoked.</li>
<li><strong>state</strong> This is the current state of Gooey's UI. If your program uses subparsers, this currently just lists the state of the active parser/form. Whatever updated version of this state you return will be reflected in the UI!</li>
</ul>
<p dir="auto"><strong>Attaching the handlers:</strong></p>
<p dir="auto">Handlers are attached when instantiating the <code>GooeyParser</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="parser = GooeyParser(
    on_success=my_success_handler,
    on_failure=my_failure_handler)"><pre><span>parser</span> <span>=</span> <span>GooeyParser</span>(
    <span>on_success</span><span>=</span><span>my_success_handler</span>,
    <span>on_failure</span><span>=</span><span>my_failure_handler</span>)</pre></div>
<p dir="auto"><strong>Subscribing to the lifecycle events</strong></p>
<p dir="auto">Just like <a href="#dynamic-validation">Validation</a>, these lifecycle events are opt-in. Pass the event you'd like to subscribe to into the <code>use_events</code> Gooey decorator argument.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from gooey import Gooey, Events 

@Gooey(use_events=[Events.ON_SUCCESS, Events.ON_ERROR])
def main(): 
    ... "><pre><span>from</span> <span>gooey</span> <span>import</span> <span>Gooey</span>, <span>Events</span> 

<span>@<span>Gooey</span>(<span>use_events</span><span>=</span>[<span>Events</span>.<span>ON_SUCCESS</span>, <span>Events</span>.<span>ON_ERROR</span>])</span>
<span>def</span> <span>main</span>(): 
    ... </pre></div>
<hr>
<h2 tabindex="-1" dir="auto">Showing Progress</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/45590349-55bbda80-b8eb-11e8-9aed-b4fe377756ac.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/45590349-55bbda80-b8eb-11e8-9aed-b4fe377756ac.png" width="420"></a></p>
<p dir="auto">Giving visual progress feedback with Gooey is easy! If you're already displaying textual progress updates, you can tell Gooey to hook into that existing output in order to power its Progress Bar.</p>
<p dir="auto">For simple cases, output strings which resolve to a numeric representation of the completion percentage (e.g. <code>Progress 83%</code>) can be pattern matched and turned into a progress bar status with a simple regular expression (e.g. <code>@Gooey(progress_regex=r"^progress: (\d+)%$")</code>).</p>
<p dir="auto">For more complicated outputs, you can pass in a custom evaluation expression (<code>progress_expr</code>) to transform regular expression matches as needed.</p>
<p dir="auto">Output strings which satisfy the regular expression can be hidden from the console via the <code>hide_progress_msg</code> parameter (e.g. <code>@Gooey(progress_regex=r"^progress: (\d+)%$", hide_progress_msg=True)</code>.</p>
<p dir="auto"><strong>Regex and Processing Expression</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="@Gooey(progress_regex=r&quot;^progress: (?P<current>\d+)/(?P<total>\d+)$&quot;,
       progress_expr=&quot;current / total * 100&quot;)"><pre><span>@<span>Gooey</span>(<span>progress_regex</span><span>=</span><span>r"^progress: (?P&lt;current&gt;\d+)/(?P&lt;total&gt;\d+)$"</span>,</span>
<span>       <span>progress_expr</span><span>=</span><span>"current / total * 100"</span>)</span></pre></div>
<p dir="auto"><strong>Program Output:</strong></p>
<div data-snippet-clipboard-copy-content="progress: 1/100
progress: 2/100
progress: 3/100
..."><pre><code>progress: 1/100
progress: 2/100
progress: 3/100
...
</code></pre></div>
<p dir="auto">There are lots of options for telling Gooey about progress as your program is running. Checkout the <a href="https://github.com/chriskiehl/GooeyExamples">Gooey Examples</a> repository for more detailed usage and examples!</p>
<h3 tabindex="-1" dir="auto">Elapsed / Remaining Time</h3>
<p dir="auto">Gooey also supports tracking elapsed / remaining time when progress is used! This is done in a similar manner to that of the project <a href="https://github.com/tqdm/tqdm">tqdm</a>. This can be enabled with <code>timing_options</code>, the <code>timing_options</code> argument takes in a dictionary with the keys <code>show_time_remaining</code> and <code>hide_time_remaining_on_complete</code>. The default behavior is True for <code>show_time_remaining</code> and False for <code>hide_time_remaining_on_complete</code>. This will only work when <code>progress_regex</code> and <code>progress_expr</code> are used.</p>
<div dir="auto" data-snippet-clipboard-copy-content="@Gooey(progress_regex=r&quot;^progress: (?P<current>\d+)/(?P<total>\d+)$&quot;,
       progress_expr=&quot;current / total * 100&quot;,
       timing_options = {
        'show_time_remaining':True,
        'hide_time_remaining_on_complete':True,
    })"><pre><span>@<span>Gooey</span>(<span>progress_regex</span><span>=</span><span>r"^progress: (?P&lt;current&gt;\d+)/(?P&lt;total&gt;\d+)$"</span>,</span>
<span>       <span>progress_expr</span><span>=</span><span>"current / total * 100"</span>,</span>
<span>       <span>timing_options</span> <span>=</span> {</span>
<span>        <span>'show_time_remaining'</span>:<span>True</span>,</span>
<span>        <span>'hide_time_remaining_on_complete'</span>:<span>True</span>,</span>
<span>    })</span></pre></div>
<hr>
<h2 tabindex="-1" dir="auto">Customizing Icons</h2>
<p dir="auto">Gooey comes with a set of six default icons. These can be overridden with your own custom images/icons by telling Gooey to search additional directories when initializing. This is done via the <code>image_dir</code> argument to the <code>Gooey</code> decorator.</p>
<div data-snippet-clipboard-copy-content="@Gooey(program_name='Custom icon demo', image_dir='/path/to/my/image/directory')
def main():
    # rest of program"><pre><code>@Gooey(program_name='Custom icon demo', image_dir='/path/to/my/image/directory')
def main():
    # rest of program
</code></pre></div>
<p dir="auto">Images are discovered by Gooey based on their <em>filenames</em>. So, for example, in order to supply a custom configuration icon, simply place an image with the filename <code>config_icon.png</code> in your images directory. These are the filenames which can be overridden:</p>
<ul dir="auto">
<li>program_icon.png</li>
<li>success_icon.png</li>
<li>running_icon.png</li>
<li>loading_icon.gif</li>
<li>config_icon.png</li>
<li>error_icon.png</li>
</ul>
<h2 tabindex="-1" dir="auto">Packaging</h2>
<p dir="auto">Thanks to some <a href="https://github.com/chriskiehl/Gooey/issues/58" data-hovercard-type="issue" data-hovercard-url="/chriskiehl/Gooey/issues/58/hovercard">awesome contributors</a>, packaging Gooey as an executable is super easy.</p>
<p dir="auto">The tl;dr <a href="https://github.com/pyinstaller/pyinstaller">pyinstaller</a> version is to drop this <a href="https://raw.githubusercontent.com/chriskiehl/Gooey/master/docs/packaging/build-win.spec" rel="nofollow">build.spec</a> into the root directory of your application. Edit its contents so that the <code>APPPNAME</code> and <code>name</code> are relevant to your project and the <code>pathex</code> value points to your applications root, then execute <code>pyinstaller -F --windowed build.spec</code> to bundle your app into a ready-to-go executable.</p>
<p dir="auto">Detailed step by step instructions can be found <a href="https://github.com/chriskiehl/Gooey/blob/master/docs/packaging/Packaging-Gooey.md">here</a>.</p>
<h2 tabindex="-1" dir="auto">Screenshots</h2>
<table>
<thead>
<tr>
<th>Flat Layout</th>
<th>Column Layout</th>
<th>Success Screen</th>
<th>Error Screen</th>
<th>Warning Dialog</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/4414e54e-0965-11e5-964b-f717a7adaac6.jpg"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/4414e54e-0965-11e5-964b-f717a7adaac6.jpg"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/4411b824-0965-11e5-905a-3a2b5df0efb3.jpg"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/4411b824-0965-11e5-905a-3a2b5df0efb3.jpg"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/44165442-0965-11e5-8edf-b8305353285f.jpg"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/44165442-0965-11e5-8edf-b8305353285f.jpg"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/4410dcce-0965-11e5-8243-c1d832c05887.jpg"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/4410dcce-0965-11e5-8243-c1d832c05887.jpg"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/4415432c-0965-11e5-9190-17f55460faf3.jpg"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/4415432c-0965-11e5-9190-17f55460faf3.jpg"></a></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Custom Groups</th>
<th>Tabbed Groups</th>
<th>Tabbed Navigation</th>
<th>Sidebar Navigation</th>
<th>Input Validation</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464824-c044d57a-ee46-11e7-9c35-6e701a7c579a.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464824-c044d57a-ee46-11e7-9c35-6e701a7c579a.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464826-2a946ba2-ee47-11e7-92a4-4afeb49dc9ca.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464826-2a946ba2-ee47-11e7-92a4-4afeb49dc9ca.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464835-5ba9b0e4-ee47-11e7-9561-55e3647c2165.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464835-5ba9b0e4-ee47-11e7-9561-55e3647c2165.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464847-9918fbb0-ee47-11e7-8d5f-0d42631c2bc0.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464847-9918fbb0-ee47-11e7-8d5f-0d42631c2bc0.png"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464861-0e82c214-ee48-11e7-8f4a-a8e00721efef.png"><img src="https://github.com/chriskiehl/GooeyImages/raw/images/readme-images/34464861-0e82c214-ee48-11e7-8f4a-a8e00721efef.png"></a></td>
</tr>
</tbody>
</table>
<hr>
<h2 tabindex="-1" dir="auto">Wanna help?</h2>
<p dir="auto">Code, translation, documentation, or graphics? All pull requests are welcome. Just make sure to checkout <a href="https://github.com/chriskiehl/Gooey/blob/master/CONTRIBUTING.md">the contributing guidelines</a> first.</p>
</article>
          </div></div>]]></description>
        </item>
    </channel>
</rss>