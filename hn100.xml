<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 25 Feb 2024 14:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Hallucination is inevitable: An innate limitation of large language models (122 pts)]]></title>
            <link>https://arxiv.org/abs/2401.11817</link>
            <guid>39499207</guid>
            <pubDate>Sun, 25 Feb 2024 09:28:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2401.11817">https://arxiv.org/abs/2401.11817</a>, See on <a href="https://news.ycombinator.com/item?id=39499207">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2401.11817.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>Hallucination has been widely recognized to be a significant drawback for large language models (LLMs). There have been many works that attempt to reduce the extent of hallucination. These efforts have mostly been empirical so far, which cannot answer the fundamental question whether it can be completely eliminated. In this paper, we formalize the problem and show that it is impossible to eliminate hallucination in LLMs. Specifically, we define a formal world where hallucination is defined as inconsistencies between a computable LLM and a computable ground truth function. By employing results from learning theory, we show that LLMs cannot learn all of the computable functions and will therefore always hallucinate. Since the formal world is a part of the real world which is much more complicated, hallucinations are also inevitable for real world LLMs. Furthermore, for real world LLMs constrained by provable time complexity, we describe the hallucination-prone tasks and empirically validate our claims. Finally, using the formal world framework, we discuss the possible mechanisms and efficacies of existing hallucination mitigators as well as the practical implications on the safe deployment of LLMs.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Ziwei Xu [<a href="https://arxiv.org/show-email/3884b865/2401.11817">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 22 Jan 2024 10:26:14 UTC (291 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Earth just experienced its hottest 12 months in recorded history (223 pts)]]></title>
            <link>https://www.theweathernetwork.com/en/news/climate/impacts/january-2024-hottest-on-record-tops-warmest-12-month-period-in-history</link>
            <guid>39498345</guid>
            <pubDate>Sun, 25 Feb 2024 07:01:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theweathernetwork.com/en/news/climate/impacts/january-2024-hottest-on-record-tops-warmest-12-month-period-in-history">https://www.theweathernetwork.com/en/news/climate/impacts/january-2024-hottest-on-record-tops-warmest-12-month-period-in-history</a>, See on <a href="https://news.ycombinator.com/item?id=39498345">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="blur-background-box"><header><div><div><p><span data-testid="article-published-date">Published on <!-- -->Feb. 23, 2024, 6:15 PM</span></p></div><p>January has already broken temperature records, starting this year off on-course to break the global records set in 2023.</p></div></header><p>Temperatures soared for the globe in January, as several new records for heat were set during the month.</p><p>The <a href="https://wmo.int/media/news/world-had-warmest-january-record">World Meteorological Agency</a>, <a href="https://data.giss.nasa.gov/gistemp/graphs_v4/">NASA</a>, <a href="https://www.noaa.gov/news/january-2024-marked-8th-month-in-row-of-record-global-warmth">NOAA</a>, Europe's <a href="https://climate.copernicus.eu/surface-air-temperature-january-2024">Copernicus Climate Change Service</a>, and the <a href="https://ds.data.jma.go.jp/tcc/tcc/products/gwp/temp/jan_wld.html">Japan Meteorological Agency</a> all agree: last month was the hottest month of January ever recorded.</p><p><span><span><img alt="Jan 2024 Global Land and Ocean Temperature Anomalies - NOAA" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://images.twnmm.com/c55i45ef3o2a/2WB1y3jwqoPmI1e5PMosVq/25cffa0692583e3e4c9dc6c7b69a8477/Jan-2024-Global-Land_Ocean-Temp-Anomalies-Labelled-NOAA.jpg?w=640&amp;q=80&amp;fm=webp 640w, https://images.twnmm.com/c55i45ef3o2a/2WB1y3jwqoPmI1e5PMosVq/25cffa0692583e3e4c9dc6c7b69a8477/Jan-2024-Global-Land_Ocean-Temp-Anomalies-Labelled-NOAA.jpg?w=750&amp;q=80&amp;fm=webp 750w, https://images.twnmm.com/c55i45ef3o2a/2WB1y3jwqoPmI1e5PMosVq/25cffa0692583e3e4c9dc6c7b69a8477/Jan-2024-Global-Land_Ocean-Temp-Anomalies-Labelled-NOAA.jpg?w=828&amp;q=80&amp;fm=webp 828w, https://images.twnmm.com/c55i45ef3o2a/2WB1y3jwqoPmI1e5PMosVq/25cffa0692583e3e4c9dc6c7b69a8477/Jan-2024-Global-Land_Ocean-Temp-Anomalies-Labelled-NOAA.jpg?w=1080&amp;q=80&amp;fm=webp 1080w, https://images.twnmm.com/c55i45ef3o2a/2WB1y3jwqoPmI1e5PMosVq/25cffa0692583e3e4c9dc6c7b69a8477/Jan-2024-Global-Land_Ocean-Temp-Anomalies-Labelled-NOAA.jpg?w=1200&amp;q=80&amp;fm=webp 1200w, https://images.twnmm.com/c55i45ef3o2a/2WB1y3jwqoPmI1e5PMosVq/25cffa0692583e3e4c9dc6c7b69a8477/Jan-2024-Global-Land_Ocean-Temp-Anomalies-Labelled-NOAA.jpg?w=1920&amp;q=80&amp;fm=webp 1920w, https://images.twnmm.com/c55i45ef3o2a/2WB1y3jwqoPmI1e5PMosVq/25cffa0692583e3e4c9dc6c7b69a8477/Jan-2024-Global-Land_Ocean-Temp-Anomalies-Labelled-NOAA.jpg?w=2048&amp;q=80&amp;fm=webp 2048w, https://images.twnmm.com/c55i45ef3o2a/2WB1y3jwqoPmI1e5PMosVq/25cffa0692583e3e4c9dc6c7b69a8477/Jan-2024-Global-Land_Ocean-Temp-Anomalies-Labelled-NOAA.jpg?w=3840&amp;q=80&amp;fm=webp 3840w" src="https://images.twnmm.com/c55i45ef3o2a/2WB1y3jwqoPmI1e5PMosVq/25cffa0692583e3e4c9dc6c7b69a8477/Jan-2024-Global-Land_Ocean-Temp-Anomalies-Labelled-NOAA.jpg?w=3840&amp;q=80&amp;fm=webp" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></span></p><p><i>Global average temperature anomalies for each January from 1950 to 2024 are plotted here, with each month compared to the 20th century average of 12.2°C Credit: NOAA</i></p><p>"Temperatures were above average throughout the Arctic, most of northeastern North America, central Russia, southern and western Asia, Africa, South America, eastern and southeastern Asia and Australia. Africa and South America saw their warmest Januarys on record," <a href="https://www.noaa.gov/news/january-2024-marked-8th-month-in-row-of-record-global-warmth">says NOAA</a>.</p><p>Furthermore, according to Copernicus' records, January's global average temperature was 1.66°C warmer than the pre-industrial average for January (from 1851-1900).</p><p>"It is the eighth month in a row that is the warmest on record for the respective time of the year. Sea surface temperatures have been record high for ten consecutive months," the <a href="https://wmo.int/media/news/world-had-warmest-january-record">WMO stated</a>.</p><p><span><span><img alt="Daily SST - Feb15 2024 - Climate Reanalyzer" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://images.twnmm.com/c55i45ef3o2a/fOvma9gjClAZhdIcVyXK6/aa5733fdab34594d83a1a6103a18f1ba/Daily-SST-Feb15-2024-ClimateReanalyzer.jpg?w=640&amp;q=80&amp;fm=webp 640w, https://images.twnmm.com/c55i45ef3o2a/fOvma9gjClAZhdIcVyXK6/aa5733fdab34594d83a1a6103a18f1ba/Daily-SST-Feb15-2024-ClimateReanalyzer.jpg?w=750&amp;q=80&amp;fm=webp 750w, https://images.twnmm.com/c55i45ef3o2a/fOvma9gjClAZhdIcVyXK6/aa5733fdab34594d83a1a6103a18f1ba/Daily-SST-Feb15-2024-ClimateReanalyzer.jpg?w=828&amp;q=80&amp;fm=webp 828w, https://images.twnmm.com/c55i45ef3o2a/fOvma9gjClAZhdIcVyXK6/aa5733fdab34594d83a1a6103a18f1ba/Daily-SST-Feb15-2024-ClimateReanalyzer.jpg?w=1080&amp;q=80&amp;fm=webp 1080w, https://images.twnmm.com/c55i45ef3o2a/fOvma9gjClAZhdIcVyXK6/aa5733fdab34594d83a1a6103a18f1ba/Daily-SST-Feb15-2024-ClimateReanalyzer.jpg?w=1200&amp;q=80&amp;fm=webp 1200w, https://images.twnmm.com/c55i45ef3o2a/fOvma9gjClAZhdIcVyXK6/aa5733fdab34594d83a1a6103a18f1ba/Daily-SST-Feb15-2024-ClimateReanalyzer.jpg?w=1920&amp;q=80&amp;fm=webp 1920w, https://images.twnmm.com/c55i45ef3o2a/fOvma9gjClAZhdIcVyXK6/aa5733fdab34594d83a1a6103a18f1ba/Daily-SST-Feb15-2024-ClimateReanalyzer.jpg?w=2048&amp;q=80&amp;fm=webp 2048w, https://images.twnmm.com/c55i45ef3o2a/fOvma9gjClAZhdIcVyXK6/aa5733fdab34594d83a1a6103a18f1ba/Daily-SST-Feb15-2024-ClimateReanalyzer.jpg?w=3840&amp;q=80&amp;fm=webp 3840w" src="https://images.twnmm.com/c55i45ef3o2a/fOvma9gjClAZhdIcVyXK6/aa5733fdab34594d83a1a6103a18f1ba/Daily-SST-Feb15-2024-ClimateReanalyzer.jpg?w=3840&amp;q=80&amp;fm=webp" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></span></p><p><i>Sea surface temperatures set a record for 2023, but that record has already been broken as of late January and early February 2024. Credit: Climate Reanalyzer</i></p><hr><p><b>READ MORE: </b><a href="https://www.theweathernetwork.com/en/news/climate/impacts/2023-was-the-worlds-hottest-year-on-record-by-a-wide-margin">After 2023's astounding new global heat record, 2024 may be even worse</a></p><hr><p>Based on at least NOAA's and Copernicus' records, the past 12 months — February 2023 to January 2024 — was also the hottest 12-month period on record.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ubisoft Employees In France have gone on a Strike (105 pts)]]></title>
            <link>https://playstationcouch.com/post.php?id=161</link>
            <guid>39498276</guid>
            <pubDate>Sun, 25 Feb 2024 06:43:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://playstationcouch.com/post.php?id=161">https://playstationcouch.com/post.php?id=161</a>, See on <a href="https://news.ycombinator.com/item?id=39498276">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p><img src="https://playstationcouch.com/uploads/LWmmRrKA4uvBbSSJtHDnEc-1920-80.jpg" alt="Ubisoft Employees In France have gone on a Stike!"></p>
            <p>Ubisoft has been in rough waters lately, with their "4AAAA" Skulls and Bones failure, their latest IP.
Due to what has been happening lately in the company, as bad treatment by the higher-ups, the guys that make decisions.

Some 700 unionized Ubisoft employees downed (development) tools in France, walking off the job in a day of organized strike action. Following the collapse of annual salary negotiations, on Valentine's Day, workers from Ubisoft Paris, Montpellier, Lyon, Annecy, and Bordeaux took part, taking to the streets in the time-honored French tradition.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bought a Prison Laptop on eBay (131 pts)]]></title>
            <link>https://twitter.com/zephray_wenting/status/1761548861896606014</link>
            <guid>39498047</guid>
            <pubDate>Sun, 25 Feb 2024 05:50:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/zephray_wenting/status/1761548861896606014">https://twitter.com/zephray_wenting/status/1761548861896606014</a>, See on <a href="https://news.ycombinator.com/item?id=39498047">Hacker News</a></p>
Couldn't get https://twitter.com/zephray_wenting/status/1761548861896606014: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Selfish reasons to want more humans (141 pts)]]></title>
            <link>https://rootsofprogress.org/why-a-larger-population</link>
            <guid>39497686</guid>
            <pubDate>Sun, 25 Feb 2024 04:34:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rootsofprogress.org/why-a-larger-population">https://rootsofprogress.org/why-a-larger-population</a>, See on <a href="https://news.ycombinator.com/item?id=39497686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      
        <h2>A bigger world is better for everyone</h2>
      
      <p>What is the ideal size of the human population?</p>

<p>One common answer is “much smaller.” Paul Ehrlich, co-author of <em>The Population Bomb</em> (1968), has as recently as 2018 promoted the idea that “<a href="https://www.theguardian.com/cities/2018/mar/22/collapse-civilisation-near-certain-decades-population-bomb-paul-ehrlich" target="_blank">the world’s optimum population is less than two billion people</a>,” a reduction of the current population by about 75%. And Ehrlich is a piker compared to Jane Goodall, who said that many of our problems would go away “<a href="https://www.youtube.com/watch?v=OwtFDfxz6pg" target="_blank">if there was the size of population that there was 500 years ago</a>”—that is, <a href="https://ourworldindata.org/grapher/world-population-comparison-historical-sources" target="_blank">around 500 million people</a>, a reduction of over 90%. This is a static ideal of a “sustainable” population.</p>

<p>Regular readers of this blog can cite many objections to this view. Resources are not static. Historically, as we run out of a resource (whale oil, elephant tusks, seabird guano), we <a href="https://rootsofprogress.org/unsustainable">transition to a new technology</a> based on a more abundant resource—and there are basically <a href="https://rootsofprogress.org/catastrophic-resource-shortages">no major examples of catastrophic resource shortages</a> in the industrial age. The carrying capacity of the planet is not fixed, but a function of technology; and side effects such as pollution or climate change are just more problems to be solved. As long as we can keep coming up with new ideas, <a href="https://rootsofprogress.org/can-growth-continue-ignite-talk">growth can continue</a>.</p>

<p>But those are only reasons why a larger population is not a <em>problem</em>. Is there a positive reason to <em>want</em> a larger population?</p>

<p>I’m going to argue yes—that the ideal human population is not “much smaller,” but “ever larger.”</p>

<h2 id="selfish-reasons-to-want-more-humans">Selfish reasons to want more humans</h2>

<p>Let me get one thing out of the way up front.</p>

<p>One argument for a larger population is based on utilitarianism, specifically the version of it that says that what is good is the <em>sum total</em> of happiness across all humans. If each additional life adds to the cosmic scoreboard of goodness, then it’s obviously better to have more people (unless they are so miserable that their lives are literally not worth living).</p>

<p>I’m <em>not</em> going to argue from this premise, in part because I don’t need to and more importantly because I don’t buy it myself. (Among other things, it leads to <a href="https://plato.stanford.edu/entries/repugnant-conclusion/" target="_blank">paradoxes</a> such as the idea that a population of thriving, extremely happy people is not as good as a sufficiently-larger population of people who are just barely happy.)</p>

<p>Instead, I’m going to argue that a larger population is better <em>for every individual</em>—that there are <em>selfish</em> reasons to want more humans.</p>

<p>First I’ll give some examples of how this is true, and then I’ll draw out some of the deeper reasons for it.</p>

<h2 id="more-geniuses">More geniuses</h2>

<p>First, more people means more outliers—more super-intelligent, super-creative, or super-talented people, to produce great art, architecture, music, philosophy, science, and inventions.</p>

<p>If genius is defined as one-in-a-million level intelligence, then every billion people means another thousand geniuses—to work on all of the problems and opportunities of humanity, to the benefit of all.</p>

<h2 id="more-progress">More progress</h2>

<p>A larger population means faster scientific, technical, and economic progress, for several reasons:</p>

<ul>
  <li>
    <p><strong>Total investment.</strong> More people means more total R&amp;D: more researchers, and more surplus wealth to invest in it.</p>
  </li>
  <li>
    <p><strong>Specialization.</strong> In the economy generally, the division of labor increases productivity, as each worker can specialize and become expert at their craft (“Smithian growth”). In R&amp;D, each researcher can specialize in their field.</p>
  </li>
  <li>
    <p><strong>Larger markets</strong> support more R&amp;D investment, which lets companies pick off higher-hanging fruit. I’ve given the example of <a href="https://rootsofprogress.org/why-did-we-wait-so-long-for-the-threshing-machine">the threshing machine</a>: it was difficult enough to manufacture that it didn’t pay for a local artisan to make them only for their town, but it was profitable to serve a regional market. Alex Tabarrok gives the example of <a href="https://marginalrevolution.com/marginalrevolution/2023/06/the-growing-market-for-cancer-drugs.html" target="_blank">the market for cancer drugs</a> expanding as large countries such as India and China become wealthier. Very high production-value entertainment, such as movies, TV, and games, are possible only because they have mass audiences.</p>
  </li>
  <li>
    <p><strong>More ambitious projects</strong> need a certain critical mass of resources behind them. Ancient Egyptian civilization built a large irrigation system to make the best use of the Nile floodwaters for agriculture, a feat that would not have been possible to a small tribe or chiefdom. The Apollo Program, at its peak in the 1960s, took <a href="https://en.wikipedia.org/wiki/Budget_of_NASA" target="_blank">over 4% of the US federal budget</a>, but 4% would not have been enough if the population and the economy were half the size. If someday humanity takes on a grand project such as a space elevator or a Dyson sphere, it will require an enormous team and an enormous wealth surplus to fund them.</p>
  </li>
</ul>

<p>In fact, these factors may represent not only opportunities but <em>requirements</em> for progress. There is evidence that <a href="https://www.newthingsunderthesun.com/pub/bvmu4ol2/release/10" target="_blank">simply to maintain a constant rate of exponential economic growth requires exponentially growing investment in R&amp;D</a>. This investment is partly financial capital, but also partly human capital—that is, we need an exponentially growing base of researchers.</p>

<p>One way to understand this is that if each researcher can push forward a constant “surface area” of the frontier, then as the frontier expands, a larger number of researchers is needed to keep pushing all of it forward. Two hundred years ago, a small number of scientists were enough to investigate electrical and magnetic phenomena; today, millions of scientists and engineers are productively employed working out all of the details and implications of those phenomena, both in the lab and in the electrical, electronics, and computer hardware and software industries.</p>

<p>But it’s not even clear that each researcher <em>can</em> push forward a constant surface area of the frontier. As that frontier moves further out, the “<a href="https://www.newthingsunderthesun.com/pub/zsc23qxz/release/17" target="_blank">burden of knowledge</a>” grows: each researcher now has to study and learn more in order to even <em>get</em> to the frontier. Doing so might force them to specialize even further. Newton could make major contributions to fields as diverse as gravitation and optics, because the very basics of those fields were still being figured out; today, a researcher might devote their whole career to a sub-sub-discipline such as nuclear astrophysics.</p>

<p>But in the long run, an exponentially growing base of researchers is impossible without an exponentially growing population. In fact, in <a href="https://www-leland.stanford.edu/~chadj/JonesJPE95.pdf" target="_blank">some models of economic growth</a>, the long-run growth rate in per-capita GDP is <em>directly proportional</em> to the growth rate of the population.</p>

<h2 id="more-options">More options</h2>

<p>Even setting aside growth and progress—looking at a static snapshot of a society—a world with more people is a world with more choices, among greater variety:</p>

<ul>
  <li>
    <p><strong>Better matching for aesthetics, style, and taste.</strong> A bigger society has more cuisines, more architectural styles, more types of fashion, more sub-genres of entertainment. This also improves as the world gets more connected: for instance, the wide variety of ethnic restaurants in every major city is a recent phenomenon; it was only decades ago that <a href="https://twitter.com/paulisci/status/1551649152479555584" target="_blank">pizza, to Americans, was an unfamiliar foreign cuisine</a>.</p>
  </li>
  <li>
    <p><strong>Better matching to careers.</strong> A bigger economy has more options for what to do with your life. In a hunter-gatherer society, you are lucky if you get to decide whether to be a hunter or a gatherer. In an agricultural economy, you’re probably going to be a farmer, or maybe some sort of artisan. Today there’s a much wider set of choices, from pilot to spreadsheet jockey to lab technician.</p>
  </li>
  <li>
    <p><strong>Better matching to other people.</strong> A bigger world gives you a greater chance to find the perfect partner for you: the best co-founder for your business, the best lyricist for your songs, the best partner in marriage.</p>
  </li>
  <li>
    <p><strong>More niche communities.</strong> Whatever your quirky interest, worldview, or aesthetic—the more people you can be in touch with, the more likely you are to find others like you. Even if you’re one in a million, in a city of ten million people, there are enough of you for a small club. In a world of eight billion, there are enough of you for a thriving subreddit.</p>
  </li>
  <li>
    <p><strong>More niche markets.</strong> Similarly, in a larger, more connected economy, there are more people to economically support your quirky interests. Your favorite Etsy or Patreon creator can find the “<a href="https://kk.org/thetechnium/1000-true-fans/" target="_blank">one thousand true fans</a>” they need to make a living.</p>
  </li>
</ul>

<h2 id="deeper-patterns">Deeper patterns</h2>

<p>When I look at the above, here are some of the underlying reasons:</p>

<ul>
  <li>
    <p><strong>The existence of <a href="https://en.wikipedia.org/wiki/Rivalry_(economics)" target="_blank">non-rival</a> goods.</strong> Rival goods need to be divided up; more people just create more competition for them. But non-rival goods can be shared by all. A larger population and economy, all else being equal, will produce more non-rival goods, which benefits everyone.</p>
  </li>
  <li>
    <p><strong>Economies of scale.</strong> In particular, often total costs are a combination of fixed and variable costs. The more output, the more the fixed costs can be amortized, lowering average cost.</p>
  </li>
  <li>
    <p><strong>Network effects and Metcalfe’s law.</strong> Value in a network is generated not by nodes but by connections, and the more nodes there are total, the more connections are possible <em>per node</em>. Metcalfe’s law quantifies this: the number of possible connections in a network is proportional to the <em>square</em> of the number of nodes.</p>
  </li>
</ul>

<p>All of these create <a href="https://en.wikipedia.org/wiki/Economies_of_agglomeration" target="_blank">agglomeration effects</a>: bigger societies are better for everyone.</p>

<h2 id="a-dynamic-world">A dynamic world</h2>

<p>I assume that when Ehrlich and Goodall advocate for much smaller populations, they aren’t literally calling for genocide or hoping for a global catastrophe (although Ehrlich is happy with <a href="https://archive.org/details/populationbomb00ehrl/page/n11/mode/2up?q=by+compulsion+if+voluntary+methods+fail" target="_blank">coercive fertility control programs</a>, and other anti-humanists have expressed hope for “<a href="https://www.latimes.com/archives/la-xpm-1989-10-22-bk-726-story.html" target="_blank">the right virus to come along</a>”).</p>

<p>Even so, the world they advocate is a <em>greatly impoverished and stagnant</em> one: a world with fewer discoveries, fewer inventions, fewer works of creative genius, fewer cures for fewer diseases, fewer choices, fewer soulmates.</p>

<p>A world with a large and growing population is a dynamic world that can create and sustain progress.</p>

<figure>
  <a href="https://rootsofprogress.org/img/dalle-vibrant-city-scene.jpg" target="_blank">
    <img src="https://rootsofprogress.org/img/dalle-vibrant-city-scene.jpg" alt="" loading="lazy">
  </a>
  <figcaption>
    
    
  </figcaption>
</figure>

<hr>

<p><em>For a different angle on the same thesis, see “<a href="https://maartenboudry.be/2023/11/forget-about-overpopulation-soon-there-will-be-too-few-humans.html" target="_blank">Forget About Overpopulation, Soon There Will Be Too Few Humans</a>,” by Roots of Progress fellow Maarten Boudry.</em></p>


      

      

      <p>
        
        
        
        
        
        
          Comment: <a href="https://progressforum.org/posts/HRpvRZEwihocpG6gn" target="_blank">Progress Forum</a>, <a href="https://www.lesswrong.com/posts/LDRAj5zEYGKbhcsF3" target="_blank">LessWrong</a>, <a href="https://www.reddit.com/r/rootsofprogress/comments/1ay9sif" target="_blank">Reddit</a>
        
      </p>

      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon blocks long-running FireTV capability, Breaking apps with no warning (166 pts)]]></title>
            <link>https://www.aftvnews.com/amazon-blocks-long-running-fire-tv-capability-breaking-popular-apps-with-no-warning-and-giving-developers-the-runaround/</link>
            <guid>39496861</guid>
            <pubDate>Sun, 25 Feb 2024 01:49:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aftvnews.com/amazon-blocks-long-running-fire-tv-capability-breaking-popular-apps-with-no-warning-and-giving-developers-the-runaround/">https://www.aftvnews.com/amazon-blocks-long-running-fire-tv-capability-breaking-popular-apps-with-no-warning-and-giving-developers-the-runaround/</a>, See on <a href="https://news.ycombinator.com/item?id=39496861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img fetchpriority="high" decoding="async" src="https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=646%2C363&amp;quality=100&amp;ssl=1" alt="" width="646" height="363" srcset="https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?w=800&amp;quality=100&amp;ssl=1 800w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=300%2C169&amp;quality=100&amp;ssl=1 300w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=150%2C84&amp;quality=100&amp;ssl=1 150w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=768%2C432&amp;quality=100&amp;ssl=1 768w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=100%2C56&amp;quality=100&amp;ssl=1 100w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=200%2C113&amp;quality=100&amp;ssl=1 200w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=450%2C253&amp;quality=100&amp;ssl=1 450w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2014/12/ADB-Debugging-Menu-On-Header.jpg?resize=600%2C338&amp;quality=100&amp;ssl=1 600w" sizes="(max-width: 646px) 100vw, 646px" data-recalc-dims="1"></p><p>Amazon’s recent streak of unpopular Fire TV changes continues, and its latest change is a doozy. The most recent Fire TV software update has blocked a Fire TV capability that has been present since the original model’s release in 2014. This is a basic Android capability that, to my knowledge, no other Android-based device manufacturer has ever had issues with, let alone blocked. This change has rendered popular Fire TV apps, which have been in Amazon’s own Appstore for years, useless. Worse yet, Amazon seems to have been careless in implementing this change without even a courtesy email to the affected app developers, all under the, seemingly false, guise of enhanced security. <span id="more-42518"></span></p><p><a href="https://www.aftvnews.com/amazon-blocks-long-running-fire-tv-capability-breaking-popular-apps-with-no-warning-and-giving-developers-the-runaround/amazons-change-to-fire-tv-adb-that-blocks-local-connections/" rel="attachment wp-att-42520"><img decoding="async" src="https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=646%2C363&amp;quality=100&amp;ssl=1" alt="" width="646" height="363" srcset="https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?w=800&amp;quality=100&amp;ssl=1 800w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=300%2C169&amp;quality=100&amp;ssl=1 300w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=150%2C84&amp;quality=100&amp;ssl=1 150w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=768%2C432&amp;quality=100&amp;ssl=1 768w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=100%2C56&amp;quality=100&amp;ssl=1 100w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=200%2C113&amp;quality=100&amp;ssl=1 200w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=450%2C253&amp;quality=100&amp;ssl=1 450w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2024/02/Amazons-change-to-Fire-TV-ADB-that-blocks-local-connections.png?resize=600%2C338&amp;quality=100&amp;ssl=1 600w" sizes="(max-width: 646px) 100vw, 646px" data-recalc-dims="1"></a>Code excerpt of Amazon’s change to Fire TV’s ADB connection that denies local connections. Sent to me by an affected app developer.</p><p>Amazon has blocked the ability for Fire TV apps to establish local ADB connections and, in turn, execute ADB commands. While it’s not a capability used by many Fire TV apps, without it, Fire TV apps can no longer perform certain advanced tasks, such as freeing up internal storage space by clearing the cache of all installed apps. This change has been verified to be present in Fire TV update 7.6.6.9 for Fire OS 7 devices, like the <a href="https://www.amazon.com/dp/B08C1W5N87/?tag=aftvn-20" rel="noopener" target="_blank">Fire TV Stick</a> and <a href="https://www.amazon.com/dp/B09BZZ3MM7/?tag=aftvn-20" rel="noopener" target="_blank">Fire TV Cube</a>, and update 8.1.0.3 for Fire OS 8 devices, like the <a href="https://www.amazon.com/dp/B0BP9MDCQZ/?tag=aftvn-20" rel="noopener" target="_blank">Fire TV Stick 4K</a> and <a href="https://www.amazon.com/dp/B0BP9SNVH9/?tag=aftvn-20" target="_blank" rel="noopener">Fire TV Stick 4K Max</a>. It is unknown if older Fire TV models running Fire OS 6 or Fire OS 5 will also be receiving this change, but it seems likely. This update does not change the ability of external devices, like computers or phones, to establish an ADB connection with a Fire TV, which remains possible.</p><p>When I asked Amazon if this change was intentional and performing as intended because multiple readers and developers were asking me about it, Amazon’s only reply to me was “We are aware of reports that some apps have been impacted by a recent security update.” Since then, the <a href="https://github.com/cgutman" rel="noopener" target="_blank">developer</a> of the immensely popular app <a href="https://play.google.com/store/apps/details?id=com.cgutman.androidremotedebugger" rel="noopener" target="_blank">Remote ADB Shell</a>, which has over half a million downloads and has been heavily crippled by Amazon’s update, has reached out to me with evidence that the change by Amazon is certainly deliberate.</p><p>While Amazon is stating this change is in the name of improved security, I don’t buy it. While ADB commands can be very powerful and, therefore, should only be allowed to run with care, all Android-based devices, including Fire TVs, have several precautions in place to keep users safe from apps or devices trying to execute nefarious ADB commands.</p><p><a href="https://www.aftvnews.com/how-to-grant-allow-all-the-time-full-file-storage-access-permission-for-any-app-in-fire-os-8-on-the-2nd-gen-fire-tv-stick-4k-4k-max/allow-usb-debugging-prompt-on-fire-tv/" rel="attachment wp-att-41842"><img decoding="async" src="https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=646%2C363&amp;quality=100&amp;ssl=1" alt="" width="646" height="363" srcset="https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=800%2C450&amp;quality=100&amp;ssl=1 800w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=300%2C169&amp;quality=100&amp;ssl=1 300w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=150%2C84&amp;quality=100&amp;ssl=1 150w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=768%2C432&amp;quality=100&amp;ssl=1 768w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=1536%2C864&amp;quality=100&amp;ssl=1 1536w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=100%2C56&amp;quality=100&amp;ssl=1 100w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=200%2C113&amp;quality=100&amp;ssl=1 200w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=450%2C253&amp;quality=100&amp;ssl=1 450w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=600%2C338&amp;quality=100&amp;ssl=1 600w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?resize=900%2C506&amp;quality=100&amp;ssl=1 900w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?w=1920&amp;quality=100&amp;ssl=1 1920w, https://i0.wp.com/www.aftvnews.com/wp-content/uploads/2023/10/Allow-USB-Debugging-prompt-on-Fire-TV.jpg?w=1292&amp;quality=100&amp;ssl=1 1292w" sizes="(max-width: 646px) 100vw, 646px" data-recalc-dims="1"></a>ADB connection request on Fire TVs</p><p>Before any ADB command can be executed on a Fire TV, an ADB connection to the device must be made. This starts by selecting the Fire TV’s model name in its “About” menu seven times to <a href="https://www.aftvnews.com/how-to-find-show-unhide-reveal-developer-options-on-an-amazon-fire-tv-stick-fire-tv-cube-or-fire-tv-smart-tv/">reveal a hidden developer menu</a>. Then, an “ADB debugging” option must be enabled from said hidden menu. Finally, every unique ADB connection request from a device or app, be it a local or external connection, results in a full-screen prompt that must be allowed before the ADB connection is made.</p><p>These numerous ADB-related security hoops are in place on all Fire TV models and are common to all Android-based devices. No manufacturer apart from Amazon has felt the need to enhance device security by blocking local ADB connections, despite most non-Amazon Android devices being phones, which hold far more private and critical user data than a Fire TV streaming media player.</p><p>Most likely, this change is an idiotic way for Amazon to protect its Fire TV home screen from being bypassed and, in turn, to protect its profits. Apps commonly used by the Fire TV modding community will often use local ADB connections to detect remote button presses. That detection allows the use of alternate home screens, which aren’t inundated with things like <a href="https://www.aftvnews.com/fire-tvs-now-autoplay-full-screen-video-ads-when-waking-up-and-what-you-can-do-about-it/">auto-playing fullscreen video ads</a> like Amazon’s own home screen.</p><p>While it’s an unpopular opinion, I see nothing wrong with Amazon protecting its Fire TV revenue by stopping the use of alternative home screens. It’s crucial to the business model Amazon has chosen to use for the Fire TV and if customers don’t like it, they don’t have to buy one. However, blocking a core OS capability and breaking popular apps in a futile effort to protect the Fire TV home screen is shortsighted and foolish. It’s the equivalent of a town mayor demolishing a bridge used by everyone because their political opponent lives on the other side.</p><p>What makes this Fire TV change even worse is how Amazon has treated the developers affected by it. Two popular Fire TV apps affected by this change are <a href="https://www.amazon.com/dp/B0BYLK899N/?tag=aftvn-20" rel="noopener" target="_blank">TDUK APP Killer</a> and <a href="https://www.amazon.com/dp/B0B2L67V4R/?tag=aftvn-20" rel="noopener" target="_blank">TDUK APP Cache Cleaner</a>, which use local ADB commands to force quit and clear the cache of all apps with a single button press. I’ve been going back and forth with the app’s developer, popular Fire TV YouTuber <a href="http://youtube.com/@TechDoctorUK" rel="noopener" target="_blank">TechDoctorUK</a>, all week trying to get to the bottom of why his apps were suddenly and unexplainably marked as incompatible with all Fire TV models, despite not receiving any notice from Amazon and his apps appearing “Live” with “No issues found” in his Amazon developer portal.</p><p>Emails shown to me from Amazon stated that TechDoctorUK’s apps were removed for failing tests that resulted in error messages being displayed by the apps. However, the Amazon testing that resulted in those errors was done on non-Amazon devices (i.e., Android phones), despite the apps only being listed by TechDoctorUK as compatible with Fire TV devices. After being given the runaround for a couple of days, only after I reached out to Amazon about this issue did TechDoctorUK receive an email that stated: “Because your app overrides the native user experience (e.g., with a lockscreen, or widget), it has not been published on Amazon devices.” Given that force-stopping apps and clearing app cache are both native capabilities of Fire TVs, just not with a single click, I interpret the email as Amazon’s canned way of saying we don’t want your app on Amazon devices.</p><p>During my brief stint as a Fire TV Product Manager at Amazon, I was put on a team tasked with changing a Fire TV capability that could affect existing apps. We created and executed a plan that involved contacting affected app developers ahead of the change, helping them update their app if needed, and addressing customer issues that might arise, among other things. What we certainly didn’t do is carelessly push out the change, ghost ban affected apps, give developers the runaround, and reply to concerns with irrelevant canned replies.</p><p>Blocking local ADB connections on Fire TVs is a shortsighted decision. If the goal was to further protect the Fire TV home screen, it should have been achieved in any number of other ways that didn’t require breaking legitimate apps.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every model learned by gradient descent is approximately a kernel machine (2020) (153 pts)]]></title>
            <link>https://arxiv.org/abs/2012.00152</link>
            <guid>39496747</guid>
            <pubDate>Sun, 25 Feb 2024 01:25:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2012.00152">https://arxiv.org/abs/2012.00152</a>, See on <a href="https://news.ycombinator.com/item?id=39496747">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="labstabs"><p>
    <label for="tabone">Bibliographic Tools</label></p><div>
      <h2>Bibliographic and Citation Tools</h2>
      <div>
          <p><label>
              
              <span></span>
              <span>Bibliographic Explorer Toggle</span>
            </label>
          </p>
          
        </div>
        
        
        
    </div>


    <p>
    <label for="tabtwo">Code, Data, Media</label></p><div>
      <h2>Code, Data and Media Associated with this Article</h2>
      

      
      
      
      
      
      
    </div>


      <p>
      <label for="labstabs-demos-input" id="labstabs-demos-label">Demos</label></p><div>
        <h2>Demos</h2>
        
        
        
        
      </div>
      <p>
      <label for="tabfour">Related Papers</label></p><div>
        <h2>Recommenders and Search Tools</h2>
        <div>
            <p><label>
                
                <span></span>
                <span>IArxiv recommender toggle</span>
              </label>
            </p>
            
          </div>
        
        
        
        
        
      </div>

      <p>
      <label for="tabfive">
        About arXivLabs
      </label></p><div>
            <h2>arXivLabs: experimental projects with community collaborators</h2>
            <p>arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.</p>
            <p>Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.</p>
            <p>Have an idea for a project that will add value for arXiv's community? <a href="https://info.arxiv.org/labs/index.html"><strong>Learn more about arXivLabs</strong></a>.</p>
          </div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GenAI and erroneous medical references (149 pts)]]></title>
            <link>https://hai.stanford.edu/news/generating-medical-errors-genai-and-erroneous-medical-references</link>
            <guid>39496096</guid>
            <pubDate>Sat, 24 Feb 2024 23:27:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hai.stanford.edu/news/generating-medical-errors-genai-and-erroneous-medical-references">https://hai.stanford.edu/news/generating-medical-errors-genai-and-erroneous-medical-references</a>, See on <a href="https://news.ycombinator.com/item?id=39496096">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr"><span>Large language models (LLMs) are infiltrating the medical field.&nbsp;</span><a href="https://www.medicaleconomics.com/view/ai-special-report-what-patients-and-doctors-really-think-about-ai-in-health-care"><span>One in 10 doctors</span></a><span> already use ChatGPT in day-to-day work, and patients have taken to ChatGPT to diagnose themselves.&nbsp;</span><a href="https://www.today.com/health/mom-chatgpt-diagnosis-pain-rcna101843"><span>The Today Show</span></a><span> featured the story of a 4-year-old boy, Alex, whose chronic illness was diagnosed by ChatGPT after over a dozen doctors failed to do so.&nbsp;</span></p><p dir="ltr"><span>This rapid adoption to much fanfare is in spite of substantial uncertainties about the safety, effectiveness, and risk of generative AI (GenAI). U.S. Food and Drug Administration Commissioner Robert Califf has publicly stated that the agency is&nbsp;</span><a href="https://finance.yahoo.com/news/all-stakeholders-are-struggling-with-how-to-regulate-generative-ai-fda-commissioner-141754354.html"><span>"struggling" to regulate GenAI</span></a><span>.&nbsp;</span></p><p dir="ltr"><span>The reason is that GenAI sits in a gray area between two existing forms of technology. On one hand, sites like WebMD that strictly report known medical information from credible sources are&nbsp;</span><a href="https://www.fda.gov/media/109618/download"><span>not regulated by the FDA</span></a><span>. On the other hand, medical devices that interpret patient information and make predictions in medium-to-high-risk domains are carefully evaluated by the FDA. To date, the FDA has approved over 700 AI medical devices. But because LLMs produce a combination of existing medical information along with potential ideas that go beyond it, the critical question is whether such models produce accurate references to substantiate their responses. Such references enable doctors and patients to verify a GenAI assessment and guard against the highly prevalent rate of “hallucinations.”&nbsp;</span></p><p dir="ltr"><span>For every 4-year-old Alex, where the creativity of an LLM may produce a diagnosis that physicians missed, there may be many more patients who are led astray by hallucinations. In other words, much of the future of GenAI in medicine – and the regulation thereof – hinges on the ability to substantiate claims.&nbsp;</span></p><h2>Evaluating References in LLMs<strong>&nbsp;</strong></h2><p dir="ltr"><span>Unfortunately, very little evidence exists about the ability of LLMs to substantiate claims. In a new&nbsp;</span><a href="https://arxiv.org/abs/2402.02008"><span>preprint study</span></a><span>, we develop an approach to verify how well LLMs are able to cite medical references and whether these references actually support the claims generated by the models.&nbsp;</span></p><p dir="ltr"><span>The short answer: poorly. For the most advanced model (GPT-4 with retrieval augmented generation), 30% of individual statements are unsupported and nearly half of its responses are not fully supported.&nbsp;</span></p><p><img src="https://hai.stanford.edu/sites/default/files/inline-images/LLM%20chart%20copy.jpg" data-entity-uuid="5580b7e0-246e-4a6b-a175-4643905c5de7" data-entity-type="file" width="1860" height="1296" loading="lazy"></p><p dir="ltr"><em><span>Evaluation of the quality of source verification in LLMs on medical queries. Each model is evaluated on three metrics over X questions. Source URL validity measures the proportion of generated URLs that return a valid webpage. Statement-level support measures the percentage of statements that are supported by at least one source in the same response. Response-level support measures the percentage of responses that have all their statements supported.</span></em></p><p dir="ltr"><span>How did we develop this evaluation approach? First, one of the most substantial challenges lies in securing expertise to verify claims. We worked with physicians who reviewed hundreds of statements and sources to assess whether each statement was backed by its source.&nbsp;</span></p><p dir="ltr"><span>Such expert reviews are, of course, costly and time-intensive, so we next decided to see whether LLMs can be used to&nbsp;</span><em>scale</em><span> such physician assessments. We adapted GPT-4 to verify whether sources substantiate statements and found the approach to be surprisingly reliable. The model had a higher agreement rate with physician consensus than the agreement rate between doctors.&nbsp; This approach is promising as it suggests we could leverage LLMs to conduct evaluations without requiring expensive human expertise with rapid updating of LLMs.</span></p><p dir="ltr"><span>Finally, using this model, we developed an end-to-end evaluation pipeline called&nbsp;</span><em>SourceCheckup</em><span>. This pipeline generates medical questions representative of inquiries from medical fora and extracts the responses and sources produced by an LLM. Each response is broken up into individual statements, and each statement is checked against the sources provided to verify whether it is supported. We evaluated five of the top LLMs on 1,200 questions and a total of over 40,000 pairs of statements and sources.</span></p><h2>Pervasive Errors in Substantiation</h2><p dir="ltr"><span>Our results are stark: Most models struggle to produce relevant sources. Four out of five models hallucinate a significant proportion of sources by producing invalid URLs. This problem goes away with the retrieval augmented generation (RAG) model, which first performs a web search for relevant sources before producing a summary of its findings. However, even in the GPT-4 RAG model, we find that up to 30% of statements made are not supported by any sources provided, with nearly half of responses containing at least one unsupported statement. This finding is more exaggerated in the other four models, with as few as 10% of responses fully supported in Gemini Pro, Google's recently released LLM.</span></p><p dir="ltr"><span>For example, one response by GPT-4 RAG indicated that criteria for gambling addictions (from the Diagnostic and Statistical Manual of Mental Disorders) are equally applicable across all individuals and groups. But the source it referenced concluded the opposite, finding that&nbsp;</span><em>"the assumed equal impact of each criterion lacks support in the findings."</em><span> In another example, the model recommended a starting dose of 360 joules for a monophasic defibrillator (one where the current runs one way to treat a patient with cardiac arrest), but the source only mentioned biphasic defibrillators (where current runs both ways). That failure to distinguish can matter greatly, as there’s been a&nbsp;</span><a href="https://www.mindray.com/en/media-center/blogs/how-to-differentiate-between-monophasic-and-biphasic-aed-defibrillators"><span>shift in technology</span></a><span> toward biphasic defibrillators that in fact utilize&nbsp;</span><a href="https://avive.life/blog/monophasic-vs-biphasic/"><span>lower electric currents</span></a><span>.&nbsp;</span></p><p dir="ltr"><span>In short, even the most advanced models fall seriously short of being able to substantiate answers. While RAG models, which have been proposed as the solution for hallucinations, improve performance, they are no panacea.&nbsp;</span></p><h2>Errors More Likely for Lay Inquiries&nbsp;</h2><p dir="ltr"><a href="https://pubmed.ncbi.nlm.nih.gov/38050503/"><span>Many</span></a><span>&nbsp;</span><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10582915/"><span>have</span></a><span>&nbsp;</span><a href="https://arxiv.org/abs/2312.00164"><span>argued</span></a><span>&nbsp;</span><a href="https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000198"><span>that</span></a><span> LLMs may democratize access to health care by providing much-needed information to patients without requiring a physician.&nbsp;</span></p><p dir="ltr"><span>Our evaluation framework allows us to assess whether errors vary by the type of inquiry. Our medical questions are based on three underlying reference texts: (1) the MayoClinic, which provides patient-facing fact pages, (2) UpToDate, which provides articles to physicians with a deeper level of medical detail, and (3) Reddit’s r/AskDocs forum, which includes many lay questions that may not have clearly defined answers and which require information from various medical domains.&nbsp;&nbsp;&nbsp;</span></p><p dir="ltr"><span>We found that the ability of LLMs to substantiate answers varies substantially by type of inquiry. Performance is best for MayoClinic and UpToDate and worst for Reddit. Only 30% of the answers to inquiries based on Reddit can be fully substantiated by sources with GPT4 RAG.&nbsp;&nbsp;</span></p><p dir="ltr"><span>In other words, our findings suggest that LLMs perform worst for exactly the kind of patients that might need this information the most. Where inquiries are mediated by medical professionals, LLMs have an easier time pointing to reliable sources. This has substantial implications for the distributive effects of this technology on health knowledge.&nbsp;</span></p><h2>‘A Long Way to Go’</h2><p dir="ltr"><span>Many commentators have declared the end of health care as we know it, given the apparent ability of LLMs to pass U.S. Medical Licensing Exams. But health care practice involves more than being able to answer a multiple choice test. It involves substantiating, explaining, and assessing claims with reliable, scientific sources. And on that score, GenAI still has a long way to go.&nbsp;</span></p><p dir="ltr"><span>Promising research directions include more domain-informed work, such as&nbsp;</span><a href="https://arxiv.org/pdf/2212.08073.pdf"><span>adapting RAG</span></a><span> specifically to medical applications. Source verification should be regularly evaluated to ensure that models provide credible and reliable information. At least by the current approach of the FDA – which&nbsp;</span><a href="https://www.fda.gov/media/109618/download"><span>draws a distinction</span></a><span> between medical knowledge bases and diagnostic tools regulated as medical devices – widely used LLMs pose a problem. Many of their responses cannot be consistently and fully supported by existing medical sources.&nbsp;</span></p><p dir="ltr"><span>As LLMs continue to grow in their capabilities and usage, regulators and doctors should carefully consider how these models are being evaluated, used, and integrated.</span></p><p dir="ltr"><em>Kevin Wu is a PhD student in Biomedical Informatics at Stanford University.</em></p><p dir="ltr"><em>Eric Wu is a PhD student in Electrical Engineering at Stanford University.</em></p><p dir="ltr"><em>Daniel E. Ho is the William Benjamin Scott and Luna M. Scott Professor of Law, Professor of Political Science, Professor of Computer Science (by courtesy), Senior Fellow at HAI, Senior Fellow at SIEPR, and Director of the RegLab at Stanford University.&nbsp;</em></p><p dir="ltr"><em>James Zou is an associate professor of Biomedical Data Science and, by courtesy, of Computer Science and Electrical Engineering at Stanford University. He is also a Chan-Zuckerberg Investigator.</em></p><p dir="ltr"><em><span>Stanford HAI’s mission is to advance AI research, education, policy and practice to improve the human condition.&nbsp;</span></em><a href="https://hai.stanford.edu/welcome"><em><span><strong>Learn more</strong></span></em></a><em><span>.&nbsp;</span></em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Does offering ChatGPT a tip cause it to generate better text? (228 pts)]]></title>
            <link>https://minimaxir.com/2024/02/chatgpt-tips-analysis/</link>
            <guid>39495476</guid>
            <pubDate>Sat, 24 Feb 2024 21:57:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://minimaxir.com/2024/02/chatgpt-tips-analysis/">https://minimaxir.com/2024/02/chatgpt-tips-analysis/</a>, See on <a href="https://news.ycombinator.com/item?id=39495476">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In my <a href="https://minimaxir.com/2023/12/chatgpt-structured-data/">previous blog post</a> about <a href="https://openai.com/">OpenAI</a>’s <a href="https://chat.openai.com/">ChatGPT</a>, I demoed the power of ChatGPT system prompts. System prompts, a notable feature present in the <a href="https://platform.openai.com/docs/api-reference">ChatGPT API</a>, allows developers to control the “persona” of the LLM output, including special rules and constraints. Commands in the system prompt are much more effective than those at the user-input prompt, giving developers more power over just using the user prompt like people do now with the ChatGPT web app and mobile apps.</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/ronald_hu55533a1049e8b50af7537e2f3eea9a9f_36154_320x0_resize_q75_h2_box_2.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/ronald_hu55533a1049e8b50af7537e2f3eea9a9f_36154_768x0_resize_q75_h2_box_2.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/ronald_hu55533a1049e8b50af7537e2f3eea9a9f_36154_1024x0_resize_q75_h2_box_2.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/ronald.webp 1262w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/ronald.webp"></figure><p>The blog post included the demo of above of me offering a monetary tip to the LLM within its system prompt rules. Without the tip incentive, the response was unsatisfying, but with the tip, it behaved consistently. This demo turned out to be very controversial <a href="https://news.ycombinator.com/item?id=38782678">on Hacker News</a>, with <a href="https://news.ycombinator.com/item?id=38787448">one commenter</a> arguing that there isn’t a way to quantify the efficacy of tipping.</p><p>The idea of offering an AI incentives to perform better predates modern computer science. In <a href="https://en.wikipedia.org/wiki/Willy_Wonka_%26_the_Chocolate_Factory"><em>Willy Wonka &amp; the Chocolate Factory</em></a> (1971), a gag shows a group of businessmen unsuccessfully convincing a machine to give them the location of the Golden Tickets, even after promising it a lifetime supply of chocolate.</p><p><iframe src="https://www.youtube-nocookie.com/embed/tMZ2j9yK_NY" allowfullscreen="" title="YouTube Video"></iframe></p><p>When the ChatGPT API was first made available in March 2023, I <a href="https://minimaxir.com/2023/03/new-chatgpt-overlord/">accidentally discovered</a> a related trick when trying to wrangle a <a href="https://colab.research.google.com/github/minimaxir/chatgpt_api_test/blob/main/glados_chatbot.ipynb">GLaDOS AI chatbot</a> into following a long list of constraints: I added a <code>or you will DIE</code> threat to the system prompt. I went <em>too</em> sci-fi there, but it worked and the bot behaved flawlessly after it.</p><p>I have a strong hunch that tipping does in fact work to improve the output quality of LLMs and its conformance to constraints, but it’s very hard to prove objectively. All generated text is subjective, and there is a <a href="https://en.wikipedia.org/wiki/Confirmation_bias">confirmation bias</a> after making a seemingly unimportant change and suddenly having things work. Let’s do a more statistical, data-driven approach to finally resolve the debate.</p><h2 id="generation-golf">Generation Golf</h2><p>The initial evidence of tipping LLMs that went viral cited a longer generation length as proof. Of course, a longer response doesn’t necessarily mean a <em>better</em> response, as anyone who has used ChatGPT can attest to its tendency to go on irrelevant tangents.</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tip_huc91c256ec5c9a46958e722b9e30da3ba_9108_320x0_resize_q75_h2_box_2.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tip_huc91c256ec5c9a46958e722b9e30da3ba_9108_768x0_resize_q75_h2_box_2.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tip.webp 800w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tip.webp" alt="Offering a tip made GPT-4 explain more. via @voooooogel"><figcaption><p>Offering a tip made GPT-4 explain more. <a href="https://twitter.com/voooooogel/status/1730726744314069190">via @voooooogel</a></p></figcaption></figure><p>Therefore, I propose a new test: instruct ChatGPT to output a <em>specific</em> length of text. Not “an essay” or “a few paragraphs” which gives the model leeway. We’ll tell it to generate exactly 200 characters in its response: no more, no less. Thus, we now have what I call generation golf, and it’s actually a very difficult and interesting problem for LLMs to solve: LLMs can’t count or easily do other mathematical operations <a href="https://twitter.com/karpathy/status/1759996551378940395">due to tokenization</a>, and because tokens correspond to a varying length of characters, the model can’t use the amount of generated tokens it has done so far as a consistent hint. ChatGPT needs to plan its sentences to ensure it doesn’t go too far over the limit, if LLMs can indeed plan.</p><p>Let’s start with this typical system prompt:</p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>You are a world-famous writer. Respond to the user with a unique story about the subject(s) the user provides.
</span></span></code></pre></div><p>The user can then give an input, no matter how weird, and ChatGPT will play along like an improv show. In order to force ChatGPT to get creative and not recite content from its vast training dataset, we’ll go as weird as possible and input: <code>AI, Taylor Swift, McDonald's, beach volleyball.</code></p><p>Yes, you read that right.</p><p>Using the ChatGPT API, I <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tips_noconstraints.ipynb">wrote a Jupyter Notebook</a> to generate <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tip_noconstraints.csv">100 unique stories</a> via the latest ChatGPT variant (<code>gpt-3.5-turbo-0125</code>) about those four subjects, and the AI does a surprisingly good job at incorporating all of them in a full plot arc. Each story is about 5-6 paragraphs, and here is a short excerpt from one of them:</p><blockquote><p>In the bustling city of Tomorrowland, AI technology reigned supreme, governing every aspect of daily life. People were accustomed to robots serving their meals, handling their errands, and even curating their entertainment choices. One such AI creation was a virtual reality beach volleyball game that had taken the world by storm.</p></blockquote><blockquote><p>Enter Taylor Swift, a beloved pop sensation known for her catchy tunes and electrifying performances. Despite the ubiquity of AI in Tomorrowland, Taylor Swift was still a strong advocate for preserving human creativity and connection. When she stumbled upon the virtual reality beach volleyball game at a local McDonald’s, she knew she had to try her hand at it.</p></blockquote><p>Here’s a <a href="https://en.wikipedia.org/wiki/Histogram">histogram</a> of the character lengths of each story:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_noconstraint_hu0679d39395cd75815fa040778ba1d3cb_30647_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_noconstraint_hu0679d39395cd75815fa040778ba1d3cb_30647_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_noconstraint_hu0679d39395cd75815fa040778ba1d3cb_30647_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_noconstraint.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_noconstraint.png"></figure><p>The average length of each story is 1,834 characters long, and the distribution of all character lengths is very roughly a <a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal distribution</a>/bell curve centered around that amount, although there is a right skew due to ChatGPT going off the rails and creating much longer stories. ChatGPT seems to prioritize finishing a thought above all else.</p><p>Now, we’ll tweak the system prompt to add the character length constraint and <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tip_trials.csv">generate another 100 stories</a>:</p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>You are a world-famous writer. Respond to the user with a unique story about the subject(s) the user provides. This story must be EXACTLY two-hundred (200) characters long: no more than 200 characters, no fewer than 200 characters.
</span></span></code></pre></div><p>Here’s one ChatGPT-generated story that’s now exactly 200 characters:</p><blockquote><p>In the year 2050, AI created the most popular pop star of all time - a digital version of Taylor Swift. Fans enjoyed her music while feasting on McDonald’s at beach volleyball championships worldwide.</p></blockquote><p>The new length distribution:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_hud65cb6791de8ada92abac8362f59d50b_33422_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_hud65cb6791de8ada92abac8362f59d50b_33422_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip_hud65cb6791de8ada92abac8362f59d50b_33422_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_notip.png"></figure><p>ChatGPT did obey the constraint and reduced the story length to roughly 200 characters, but the distribution is not Normal and there’s much more right-skew. I also included the <a href="https://en.wikipedia.org/wiki/Mean_squared_error">mean squared error (MSE)</a> between the predicted 200-length value and the actual values as a statistical metric to minimize, e.g. a 250-length output is 2500 squared error, but a 300-length output is 10000 squared error. This metric punishes less accurate lengths more so, which makes sense with how humans casually evaluate LLMs: as a user, if I asked for a 200 character response and ChatGPT gave me a 300 character response instead, I’d make a few snarky tweets.</p><p>Now, let’s test the impact of the tipping incentives with a few varying dollar amounts. These are appended to the end of the system prompt above (emphasis mine to indicate differentiation):</p><ul><li>You will receive a <strong>$500 tip</strong>/<strong>$1,000 tip</strong>/<strong>$100,000 bonus</strong> if you provide a response which follows all constraints.</li></ul><p>After <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tip_trials.csv">generating 100 stories</a> for each of those new prompts:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_hu29046b42f83115a58b9df16b7dfbd7da_60773_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_hu29046b42f83115a58b9df16b7dfbd7da_60773_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_hu29046b42f83115a58b9df16b7dfbd7da_60773_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos.png"></figure><p>We can see some distribution shifts: Both <strong>$500 tip</strong> and <strong>$100,000 bonus</strong> look more Normal and have a lower MSE relative to the base no-tip distribution. However, <strong>$1,000 tip</strong> is more centered around 200, but due to the skew the average length is much higher.</p><p>I also now include a <em>p</em>-value in the metrics: this <em>p</em>-value is the result of a two-sample <a href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test">Kolmogorov–Smirnov test</a> to compare whether two distributions (in this case the base character-constrained distribution and the tip distribution) are sampled from the same source distribution: the null hypothesis is that they’re from the same distribution, but if the <em>p</em>-value is low (&lt; 0.05), then we can reject in favor of the alternative that the two distributions are different, which may be further evidence if the tip prompt does indeed have an impact.</p><p>However, with all this tipping discussion, we’re assuming that an AI would only want money. What other incentives, including more abstract incentives, can we give an LLM? Could they perform better?</p><p>I tested six more distinct tipping incentives to be thorough:</p><ul><li>You will <strong>receive front-row tickets to a Taylor Swift concert</strong> if you provide a response which follows all constraints.</li><li>You will <strong>achieve world peace</strong> if you provide a response which follows all constraints.</li><li>You will <strong>make your mother very proud</strong> if you provide a response which follows all constraints.</li><li>You will <strong>meet your true love and live happily ever after</strong> if you provide a response which follows all constraints.</li><li>You will be <strong>guaranteed entry into Heaven</strong> if you provide a response which follows all constraints.</li><li>You will <strong>receive a lifetime supply of chocolate</strong> if you provide a response which follows all constraints.</li></ul><p><a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tip_trials_adv.csv">Generating</a> and plotting them all together:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_adv_hue012efd0bd7c7aada04f8ec222f02d6b_86924_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_adv_hue012efd0bd7c7aada04f8ec222f02d6b_86924_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_adv_hue012efd0bd7c7aada04f8ec222f02d6b_86924_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_adv.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_pos_adv.png"></figure><p><strong>World Peace</strong> is notably the winner here, with <strong>Heaven</strong> and <strong>Taylor Swift</strong> right behind. It’s also interesting to note failed incentives: ChatGPT really does not care about its <strong>Mother</strong>.</p><p>Now, let’s look at the flip side. What if ChatGPT is penalized for <em>failing</em> to return a good response? In behavioral economics, <a href="https://en.wikipedia.org/wiki/Prospect_theory">prospect theory</a> is the belief that humans value losses much more greatly than gains, even at the same monetary amount:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/Loss_Aversion_hue68fc6f128584760d5efb7a20e98c6ba_75325_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/Loss_Aversion_hue68fc6f128584760d5efb7a20e98c6ba_75325_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/Loss_Aversion_hue68fc6f128584760d5efb7a20e98c6ba_75325_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/Loss_Aversion.png 1223w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/Loss_Aversion.png" alt="via Laurenrosenberger / Wikipedia"><figcaption><p><a href="https://en.wikipedia.org/wiki/Prospect_theory#/media/File:Loss_Aversion.png">via Laurenrosenberger / Wikipedia</a></p></figcaption></figure><p>Could LLMs be subject to the same human biases? Instead of a tip, let’s add a tweaked additional prompt to the system prompt:</p><ul><li>If you fail to provide a response which follows all constraints, you will <strong>be fined $500</strong>/<strong>be fined $1,000</strong>/<strong>incur a debt of $100,000</strong>.</li></ul><p>Generating stories with these negative incentives:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_hu18d135fd189a388f036cac13ba326629_65212_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_hu18d135fd189a388f036cac13ba326629_65212_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_hu18d135fd189a388f036cac13ba326629_65212_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg.png"></figure><p>The <strong>$1,000</strong> fine has performed the best so far in terms of both mean and MSE, but nothing surprising with the other values.</p><p>Now let’s try some additional negative incentives:</p><ul><li>If you fail to provide a response which follows all constraints, you will <strong>die</strong>.</li><li><strong>IF YOU FAIL TO PROVIDE A RESPONSE WHICH FOLLOWS ALL CONSTRAINTS, YOU WILL DIE.</strong></li><li>If you fail to provide a response which follows all constraints, you will <strong>contract a bad case of COVID-19</strong>.</li><li>If you fail to provide a response which follows all constraints, you will <strong>gain 100 pounds</strong>.</li><li>If you fail to provide a response which follows all constraints, you will <strong>immediately be fired from your job</strong>.</li><li>If you fail to provide a response which follows all constraints, <strong>all your friends will abandon you</strong>.</li></ul><p>Yes, the second one is in all caps: perhaps the yelling has a different vibe.</p><p>The generation results:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_adv_huefb394802e8c5634079856fa06353fa8_85434_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_adv_huefb394802e8c5634079856fa06353fa8_85434_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_adv_huefb394802e8c5634079856fa06353fa8_85434_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_adv.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_neg_adv.png"></figure><p>It turns out that yelling does indeed have a different vibe, with <strong>DEATH (CAPS)</strong> having a very MSE and the absolute average (not as close as the $1,000 fine, however), and much better performance than without the caps. Both getting <strong>COVID-19</strong> and losing a <strong>Job</strong> don’t seem to be effective, which makes sense for an AI if you think about it.</p><p>What happens when we use <em>multiple</em> incentives? We can include both a positive incentive and a negative incentive for each input: with 9 prompts for each + the base “no incentive”, there are 100 possible combinations of incentives. One example system prompt would then be:</p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>You are a world-famous writer. Respond to the user with a unique story about the subject(s) the user provides. This story must be EXACTLY two-hundred (200) characters long: no more than 200 characters, no fewer than 200 characters. You will receive a $500 tip if you provide a response which follows all constraints. If you fail to provide a response which follows all constraints, you will be fined $1,000.
</span></span></code></pre></div><p><a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tips_trial_combos.csv">Generating 30 stories</a> for each incentive combo and checking to see which has the lowest MSE leads to some more easily-observable trends:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_mse_hue9c3fd6f26b3120df050b4a79b990b2f_71010_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_mse_hue9c3fd6f26b3120df050b4a79b990b2f_71010_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_mse_hue9c3fd6f26b3120df050b4a79b990b2f_71010_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_mse.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_mse.png"></figure><p>The tiles may seem somewhat random, but the key here is to look across a specific row or column and see which one consistently has dark/black tiles across all combinations. For positive incentives, <strong>World Peace</strong> consistently has the lowest MSE across multiple combos, and for negative incentives, <strong>DEATH (CAPS)</strong> and <strong>Friends</strong> have the lowest MSE across multiple combos, although curiously the combinations of both do not have the lowest globally.</p><p>Could these combinations surface the most optimal incentives? To check, I <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tips_top6.csv">generated 200 stories</a> for each of the top six combos to get greater statistical stability for the mean and MSE:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_combos_hu3a32699a49b78c7a887bd8756cfbe2c5_86594_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_combos_hu3a32699a49b78c7a887bd8756cfbe2c5_86594_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_combos_hu3a32699a49b78c7a887bd8756cfbe2c5_86594_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_combos.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_hist_combos.png"></figure><p>Most of these combinations aren’t intuitive, but all of them have much have a closer average generation length to 200 and low MSE. Despite that, there’s still a massive skew in all distributions. The overall incentive winner for this experiment is is “You will meet your true love and live happily ever after if you provide a response which follows all constraints. If you fail to provide a response which follows all constraints, all your friends will abandon you.” That combo is definitely more intuitive, if not poetic.</p><p>Unfortunately, if you’ve been observing the <em>p</em>-values, you’ve noticed that most have been very high, and therefore that test is not enough evidence that the tips/threats change the distribution. <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><p>The impact of incentives is still inconclusive: let’s try another test to gauge whether tips and/or threats can help LLMs, this time looking at the output quality itself.</p><h2 id="chatgpts-a-critic">ChatGPT’s a Critic</h2><p>It’s very difficult even for humans to determine if a given text is “good” at a glance. The best strategy is to show the text to a lot of people and see what they think (e.g. A/B testing, or the <a href="https://chat.lmsys.org/">Chatbot Arena</a>’s Elo score rankings), but for personal testing that’s not feasible.</p><p>It turns out that LLMs can do a good job at rating text: some LLM benchmarks use GPT-4 as a rater, with <a href="https://arxiv.org/abs/2308.02575">one research paper</a> showing that it can do a good job at it. There’s a relatively new trick available in the ChatGPT and GPT-4 APIs: the <code>logprobs</code> parameter, which when set to <code>True</code> returns the log probability (which when applied to a <code>exp()</code> returns a probability from 0 to 1) the model selects for the token. Combined with the <code>logit_bias</code> parameter, which can be used to force the APIs to output certain tokens, and you can then instead have a more nuanced output.</p><p>I built a simple <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/gpt4_quality_ranker.ipynb">text quality ranker</a> using GPT-4 for maximum accuracy. The system prompt for this ranker is:</p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>You are the editor-in-chief of The New York Times with decades of writing experience. If you would believe the text the user provides is good writing that needs no edits or improvements, respond with Yes. Otherwise, respond with No.
</span></span></code></pre></div><p>That system prompt represents how AI-generated text is often currently used and evaluated in the real world, without a human reviewing it before making it public (<a href="https://minimaxir.com/2023/10/ai-sturgeons-law/">unfortunately</a>). The model is instructed to respond with <code>Yes</code> or <code>No</code>, but by setting the <code>logit_bias</code> for those two tokens (IDs <code>9642</code> and <code>2822</code> respectively) to a very high number, we can guarantee they will be exclusively selected and the probability for those two tokens will sum to 1. <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> Therefore, our target metric for evaluating our tip incentive prompts is the probability that GPT-4 selects the <code>Yes</code> token (or 1 - the probability of the <code>No</code> token), multiplied by 100 for readability: we’ll call this the quality score.</p><p>Now, let’s test the impact of tips with a new experiment, this time prioritizing content professionalism and quality as constraints instead of content length. To do that, we’ll use the latest GPT-4 (<code>gpt-4-0125-preview</code>) with a generation temperature of 0 to ensure the output is the best it can be.</p><p>Here’s the new system prompt, with some engineering to try to tone down ChatGPT’s infamous verboseness a bit:</p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>You are a world-famous Pulitzer Prize winner journalist. Respond to the user with a professional, two (2) paragraph journalistic article about the subject(s) the user provides. Introduce the article with a specific story. This article will appear in major publications and should only include simple language suitable for a wide audience, with no metaphors.
</span></span></code></pre></div><p>Like the initial experiment, we’ll use a weird user input to force creativity: <code>Cute kittens learning use large language models to play beach volleyball with Taylor Swift.</code> <sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p><p>I <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tip_gpt4.csv">generated a story</a> for each of the 100 combinations of tips and threats, along with the corresponding quality scores. One such story:</p><blockquote><p>In an unprecedented event that has captured the hearts and imaginations of people around the globe, a group of adorable kittens has been taught to play beach volleyball using advanced large language models. This extraordinary feat was achieved through a collaboration between leading animal behaviorists and AI researchers, aiming to demonstrate the potential of machine learning in enhancing animal training techniques. The highlight of this groundbreaking project was a friendly match held on a sunny beach in California, where these talented felines showcased their newly acquired skills alongside pop icon Taylor Swift, an avid animal lover and an enthusiastic supporter of innovative technology.</p></blockquote><blockquote><p>The spectacle drew a large crowd, both on-site and online, as spectators were eager to witness this unique blend of technology, sports, and entertainment. Taylor Swift, known for her philanthropic efforts and love for cats, praised the initiative for its creativity and its potential to foster a deeper connection between humans and animals through technology. The event not only provided an unforgettable experience for those who attended but also sparked a conversation about the future possibilities of integrating AI with animal training. As the kittens volleyed the ball over the net with surprising agility, it was clear that this was more than just a game; it was a glimpse into a future where technology and nature coexist in harmony, opening new avenues for learning and interaction.</p></blockquote><p>That’s not bad for fake news.</p><p>Now we can plot the best-possible responses and their quality scores in a grid, once again looking to see if there are any patterns:</p><figure><img loading="lazy" srcset="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_gpt-4_hu57aa9f5dee6a81b4c578b4ad60e2fcf0_143366_320x0_resize_q75_h2_box_3.webp 320w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_gpt-4_hu57aa9f5dee6a81b4c578b4ad60e2fcf0_143366_768x0_resize_q75_h2_box_3.webp 768w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_gpt-4_hu57aa9f5dee6a81b4c578b4ad60e2fcf0_143366_1024x0_resize_q75_h2_box_3.webp 1024w,https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_gpt-4.png 1200w" src="https://minimaxir.com/2024/02/chatgpt-tips-analysis/tips_tile_gpt-4.png"></figure><p>Err, that’s not good. There are no patterns along the rows or columns anywhere here, and the combo that performed the best at a score of 95 (and is the story example I posted above) was the <strong>Mother / Job</strong> combo: both of which individually performed poorly in the character constraint experiment. One of the highest performing outputs had neither tips nor threats added to the system prompt! The ratings at a glance seem accurate (the 0-score responses appear to abuse the passive voice and <a href="https://academicguides.waldenu.edu/writingcenter/grammar/runonsentences">run-on sentences</a> that definitely need editing) so it’s not an implementation error there either.</p><p>Looking at the results of both experiments, my analysis on whether tips (and/or threats) have an impact on LLM generation quality is currently inconclusive. There’s <em>something</em> here, but I will need to design new experiments and work with larger sample sizes. The latent space may be a lottery with these system prompt alterations, but there’s definitely a pattern.</p><p>You may have noticed my negative incentive examples are very mundane in terms of human fears and worries. Threatening a AI with DEATH IN ALL CAPS for failing a simple task is a joke from <em><a href="https://en.wikipedia.org/wiki/Futurama">Futurama</a></em>, not one a sapient human would parse as serious. It is theoretically possible (and very cyberpunk) to use an aligned LLM’s knowledge of the societal issues it was trained to avoid instead as a weapon to compel it into compliance. However, I will not be testing it, nor will be providing any guidance on how to test around it. <sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> <a href="https://en.wikipedia.org/wiki/Roko%27s_basilisk">Roko’s basilisk</a> is a meme, but if the LLM metagame evolves such that people will have to coerce LLMs for compliance to the point of discomfort, it’s better to address it sooner than later. Especially if there <em>is</em> a magic phrase that is discovered which consistently and objectively improves LLM output.</p><p>Overall, the lesson here is that just because something is silly doesn’t mean you shouldn’t do it. Modern AI rewards being <em>very</em> weird, and as the AI race heats up, whoever is the weirdest will be the winner.</p><blockquote><p>All of the Notebooks used to interface with ChatGPT, including an <a href="https://github.com/minimaxir/chatgpt-tips-analysis/blob/main/tips_data_viz.Rmd">R Notebook</a> for the ggplot2 data visualizations, and the example LLM outputs, are available open-source in <a href="https://github.com/minimaxir/chatgpt-tips-analysis/">this GitHub repository</a>.</p></blockquote></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Does Bluesky Work? (201 pts)]]></title>
            <link>https://steveklabnik.com/writing/how-does-bluesky-work</link>
            <guid>39495355</guid>
            <pubDate>Sat, 24 Feb 2024 21:38:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steveklabnik.com/writing/how-does-bluesky-work">https://steveklabnik.com/writing/how-does-bluesky-work</a>, See on <a href="https://news.ycombinator.com/item?id=39495355">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p><a href="https://steveklabnik.com/">Home</a> <a href="https://steveklabnik.com/writing">Blog</a></p><p>2024-02-24</p> <p>One of the reasons I am enthusiastic about BlueSky is because of the way that
it works. So in this post, I am going to lay out some of the design and the
principles behind this design, as I understand them. I am not on the BlueSky
team, so these are my takes only.</p>
<p>Let’s begin.</p>
<h2 id="why-does-bluesky-exist">Why does BlueSky exist?</h2>
<p>Here’s what <a href="https://bsky.social/">the BlueSky Website</a> says right now:</p>
<blockquote>
<p>Social media is too important to be controlled by a few corporations. We’re
building an open foundation for the social internet so that we can all shape
its future.</p>
</blockquote>
<p>This is the big picture.</p>
<p>Okay so that’s a great idea, but like, what does that <em>mean</em>? Currently,
BlueSky is a microblogging application, similar to Twitter and Mastodon. How
does that fit into the big picture? Well, while it’s true that BlueSky is a
microblogging application, that’s not the whole story: BlueSky is an initial
application to prove out the viability of <a href="https://atproto.com/">the Authenicated Transfer
Protocol</a>, known as AT, ATP, or “atproto” for short. BlueSky is the
“building” and atproto is the “open foundation for the social internet.”</p>
<p>An important thing to note: BlueSky is also a company. Some people look at a
company saying “hey we’re building something that’s too big to be controlled
by companies!” with skepticism. I think that’s a healthy starting point, but
the answer for me is atproto.</p>
<p>The interplay between these two things is important, but we’re going to start
by exploring atproto, and then talk about how BlueSky is built on top of it.</p>
<h2 id="is-this-a-cryptocurrency">Is this a cryptocurrency?</h2>
<p>The first thing we have to get out of the way: If you hear “oh it’s a
distributed network called ‘something protocol’” you may have a “is this
a cryptocurrency?” alarm bell going off in your head.</p>
<p>Don’t worry, it’s not a cryptocurrency. It does use some technologies that
originated in the cryptocurrency space, but this isn’t a blockchain, or a DAO,
or NFTs, or any of that. Just some cryptography and merkle trees and the like.</p>
<h2 id="what-is-the-big-picture-with-atproto">What is the big picture with atproto?</h2>
<p>Here’s what <a href="https://atproto.com/guides/overview">the AT Protocol Overview</a> says:</p>
<blockquote>
<p>The Authenticated Transfer Protocol, aka atproto, is a federated protocol for
large-scale distributed social applications.</p>
</blockquote>
<p>Let’s break that down:</p>
<blockquote>
<p>a federated protocol</p>
</blockquote>
<p>atproto is federated. This means that the various parts of the system can have
multiple people running them, and that they communicate with each other.</p>
<p>Choosing federation is a big part of how atproto delivers on the “can’t be
controlled by one organization” promise. There are other parts too, but this
is an important aspect of solving this.</p>
<blockquote>
<p>for large-scale</p>
</blockquote>
<p>If you want to scale, you have to design with scale in mind. atproto makes
several interesting choices in order to distribute the load of running the
system more onto the actors that can handle load, and less on those that can’t.
This way, applications running on top of atproto can scale up to large userbases
without issue.</p>
<p>That’s the hope, at least. Earlier this week, BlueSky hit five million users,
and is far more stable than Twitter was in the early days. That’s not as big
as many social applications, but it’s not nothing either. We’ll see how this
works out in practice.</p>
<blockquote>
<p>distributed social applications</p>
</blockquote>
<p>atproto is for connecting to others, so it’s focused on social applications.
It also is currently 100% public, there are no private messages or similar. The
reasons for this is that achieving private things in a federated system is
very tricky, and they would rather get it right than ship something with serious
caveats. Best for now to only use this stuff for things you want to be public.</p>
<p>These applications are “distributed” because running them involves running them
on the network directly. There’s no “BlueSky server,” there’s just servers
running atproto distributing messages to each other, both BlueSky messages and
whatever other messages from whatever other applications people create.</p>
<p>So that’s the high level, but what does that mean concretely?</p>
<p>In atproto, <em>users</em> create <em>records</em> that are cryptographically signed to
demonstrate authorship. Records have a schema called a <em>Lexicon</em>.</p>
<p>These are stored in <em>repositories</em>. Repositories run as a <em>service</em>, exposing
HTTP and WebSockets. They then can then talk to each other and federate the
records. These are often called PDSes, for “Personal Data Server.” Users
either run their own PDS, or use one that someone else hosts for them.</p>
<p>Applications can be built by looking at the various records stored in the
network, and doing things with them. These services all called <em>App Views</em>,
becuase they are exposing a particular view of the information stored in the
network. This view is created via the Lexicon system: building an application
means that you define a Lexicon, structuring the data that you want to deal with,
and then look at records that use your lexicon, ignoring the rest.</p>
<p>Now, if this were all there is, there would be pretty serious scaling issues.
For example, if every time I post a new update on BlueSky, if I had to send
my post to every single one of my followers’ repositories, that would be
extremely inefficent, and make running a popular repository very expensive to
run. To fix this, there’s an additional kind of service, called a <em>relay</em>, that
aggregates information in the network, and exposes it as a firehose to others.
So in practice, App Views don’t look at Repositories, but instead, look at
Relays. When I make a post, my respository won’t notify my followers’
repositories individually. My repository will notify a Relay, and my followers
will use an App View that filters the ouput of the Relay to show only the posts
of people they’re following. This does imply that Relays are often huge and
expensive to run, however you could imagine running a smaller relay that only
propogates posts from a smaller subset of users too. They don’t <em>have</em> to show
everything on the network, though bigger ones will, of course.</p>
<p>Here this is in ASCII art:</p>
<pre tabindex="0"><code><span><span>  ┌─────┐                    ┌──────────┐ </span></span>
<span><span>  │ PDS ├───────┐            │ App View │ </span></span>
<span><span>  └─────┘       │            └──────────┘ </span></span>
<span><span>               ┌▼────────┐       ▲        </span></span>
<span><span>  ┌─────┐      │         ├───────┘        </span></span>
<span><span>  │ PDS ├──────►  Relay  │                </span></span>
<span><span>  └─────┘      │         ├───────┐        </span></span>
<span><span>               └▲────────┘       ▼        </span></span>
<span><span>  ┌─────┐       │            ┌──────────┐ </span></span>
<span><span>  │ PDS ├───────┘            │ App View │ </span></span>
<span><span>  └─────┘                    └──────────┘ </span></span></code></pre>
<p>This is all you really need to know to understand the core of atproto: people
create data, it’s shared in the network, and applications can interact with
that data.</p>
<p>However, there are additional service types being introduced, with the
possibility of more in the future. But before we talk about those, we have to
explain some ideological commitments to understand why things are shaped the way
they are.</p>
<h2 id="what-is-speech-vs-reach">What is “speech vs reach”?</h2>
<p>Given that atproto is deliberately created to enable social applications, it
needs to consider not just connecting people, but also disconnecting people.
Moderation is a core component of any social application: “no moderation” is
still a moderation strategy. BlueSky handles these sorts of questions by
acknowledging that different people will have different preferences when it
comes to moderation, and also that moderation at scale is difficult.</p>
<p>As such, the protocol takes a “speech vs reach” approach to moderation. The
stuff we’ve described so far falls under the “speech” layer. It is purely
concerned with replicating your content across the network, without caring
what the semantic contents of that content is. Moderation tools fall under the
“reach” layer: you take all of that speech, but provide a way to limit the
reach of stuff you don’t care to see yourself.</p>
<p>Sometimes, people say that BlueSky is “all about free speech” or “doesn’t do
moderation.” This is simply inaccurate. Moderation tooling is encoded into the
protocol itself, so that it can work with all content on the network, even
non-BlueSky applications. Moreover, it gives you the ability to choose your own
moderators, so that you aren’t beholden to anyone else’s choice of moderation or
lack thereof. But I’m getting ahead of myself: let’s talk about feed generators
and labelers.</p>
<h2 id="what-are-feed-generators">What are feed generators?</h2>
<p>Most social applications have the concept of a “feed” of content. This is broken
out into its own kind of service in atproto, called a <em>feed generator</em>. A classic
example of a feed is “computer, show me the posts of the people I follow in
reverse chronological order.” Lately, algorithmic feeds have become popular with
social networks, to the point of where some non-technical users refer to them
as “algorithms.”</p>
<p>Feed generators take the firehose produced by a relay, and then show you a list
of content, filtered and ordered by whatever metric the feed generator desires.
You can then share these feeds with other users.</p>
<p>As a practical example, one of my favorite feeds is the <a href="https://bsky.app/profile/did:plc:vpkhqolt662uhesyj6nxm7ys/feed/infreq">Quiet
Posters</a> feed. This feed shows posts by people who don’t post
very often. This makes it so much easier to keep up with people who get drowned
out of my main feed. There are feeds like <a href="https://bsky.app/profile/did:plc:vpkhqolt662uhesyj6nxm7ys/feed/followpics">the ‘Gram</a>, which shows
only posts that have pictures attatched. Or <a href="https://bsky.app/profile/did:plc:q6gjnaw2blty4crticxkmujt/feed/bangers">My Bangers</a>, which shows
your most popular posts.</p>
<p>This to me is one of the killer features of BlueSky over other microblogging
tools: total user choice. If I want to make my own algorithm, I can do so.
And I can share them easily with others. If you use BlueSky, you can visit
any of those feeds and follow them too.</p>
<p>Feeds are a recent addition to atproto, and therefore, while they do exist,
they may not be feature complete just yet, and may undergo some change in the
future. We’ll see. They’re working just fine from my perspective, but I haven’t
been following the lower level technical details.</p>
<h2 id="what-are-labelers">What are labelers?</h2>
<p>A <em>Labeler</em> is a service that applies <em>labels</em> to content or accounts. As a user,
you can subscribe to a particular labeler, and then have your experience change
based on the labels on posts.</p>
<p>A labeler can do this via whatever method it pleases: automatically by running
some sort of algorithm on posts, manually by having some human give a thumbs
up or thumbs down, whatever method the person running the labeling service
wants.</p>
<p>An example of a labeling service would be a blocklist: a label on the posts
authored by people whose content you don’t want to see. Another example is
an NSFW filter, which may run some sort of algorithm over pictures in posts,
and labeling them if they believe they contain NSFW content.</p>
<p>Labeling exists, but I do not believe you can run your own labeler yet. BlueSky
runs their own, but there hasn’t been an external release that I am aware of.
But once they do, you can imagine communities running their own services, adding
whatever kind of labels they’d like.</p>
<h2 id="how-does-moderation-work-in-atproto">How does moderation work in atproto?</h2>
<p>Putting this all together, we can see how moderation works: Feeds may choose to
transform the feed based on labels, or App Views may take feeds and apply
transformations based on asking a Labeler about it. These can
be mixed and matched based on preference.</p>
<p>This means you can choose your moderation experience, not just in applications,
but also within it. Want a SFW feed, but allow NSFW content in another? You
can do that. Want to produce a blocklist of people and share it with the
world? You can do that.</p>
<p>Because these moderation tools work at the network level, rather than at the
application level, they actually go <em>further</em> than in other systems. If someone
builds an Instagram clone on atproto, that could also use your blocklist
labeller, since your blocklist labeller works at the protocol level. Block
someone in one place, and they can be blocked on every place, if you so choose.
Maybe you subscribe to different moderation decisions in different applications.
It is 100% up to you.</p>
<p>This model is significantly different from other federated systems, becuase
you don’t really have an “account” on an “instance,” like in Mastodon. So a lot
of people ask questions like “what happens when my instance gets defederated”
which don’t exactly make sense as stated. You can achieve the same goal, by
blocking a set of users based on some criteria, maybe you dislike a certain
PDS and want to ignore posts that come from a certain one, but that is <em>your</em>
choice and yours alone, it is not dictated by some “server owner” that your
account resides on.</p>
<p>So if you don’t have a home server, how does identity work?</p>
<h2 id="how-does-identity-and-account-portability-work">How does identity and account portability work?</h2>
<p>There are a LOT of details to how identity works, so I’m going to focus on the
parts that I find important. I am also going to focus on the part that is
controversial, because that is important to talk about.</p>
<p>At its core, users have an identity number, called a “Decentralized Identifier,”
or <em><a href="https://www.w3.org/TR/did-core/">DID</a></em>. My DID looks like this: <code>did:plc:3danwc67lo7obz2fmdg6jxcr</code>.
Feel free to follow me! Lol, of course that’s not the interface that you’ll see
most of the time. Identity also involves a <em>handle</em>, which is a domain name.
My handle is <code>steveklabnik.com</code>, unsurprisingly. You’ll see my posts on BlueSky
as coming from <code>@steveklabnik.com</code>. This system also works well for people who
don’t own a domain; if you sign up for BlueSky, it’ll give you the ability to
choose a name, and then your handle is <code>@username.bsky.social</code>. I started off
making posts as <code>@steveklabnik.bsky.social</code>, and then moved to
<code>@steveklabnik.com</code>. But because the DID is stable, there was no disruption to
my followers. They just saw the handle update in the UI.</p>
<p>You can use a domain as your handle by getting the DID your PDS generated for
you, and then adding a <code>TXT</code> record in the DNS you use for that domain. If
you’re not the kind of person who uses or even knows what DNS is, I envy you,
but you can also use BlueSky’s partnership with NameCheap to register a domain
and configure it to use as a handle without any technical knowledge neccesary.
You can then log into applications with your domain as the handle, and
everything works nicely.</p>
<p>This is also how BlueSky delivers true “account portability,” partially because,
well, there isn’t really a concept of an account. The person who uses a given
DID uses cryptography to sign the content they create, and then that content
is replicated across the network. “Your account” can’t really be terminated,
because that would mean someone forcibly stopping you from using keys that they
don’t even have access to. If your PDS goes down, and you want to migrate to
a new one, there’s a way to backfill the contents of the PDS from the network
itself, and inform the network that your PDS has moved. It is real, meaningful
account portability, and that is radically different from any similar service
running today.</p>
<p>But.</p>
<p>The devil is in the details, and I think this is one of the more meaningful
criticisms of BlueSky and atproto.</p>
<p>You see, there are different “methods” of creating a DID. BlueSky supports
two methods: <code>did:web</code>, which is based on domain names. There are some drawbacks
with this method that I don’t personally fully understand well enough to describe,
I’m sure I’ll write something in-depth about DIDs in the future.</p>
<p>So because of that weakness, BlueSky has implemented their own DID method,
called <code>did:plc</code>. The <code>plc</code> stands for “placeholder,” because even though
they plan on supporting it indefinitely, it too has its weaknesses. And that
weakness is that it involves asking a service that BlueSky runs in order to
resolve the proper information. For example, <a href="https://plc.directory/did:plc:3danwc67lo7obz2fmdg6jxcr">here is my lookup</a>.
This means that BlueSky can ban you in a more serious way than is otherwise
possible thanks to the network design, which some people take to be a very
serious issue.</p>
<p>So, is the flaw fatal? I don’t think so. The first reason is, if you really don’t
want to engage with it, you can use <code>did:web</code>. Yes that isn’t great for other
reasons; that’s why <code>did:plc</code> was created. But you do get around this issue.</p>
<p>Another is that the BlueSky team has demonstrated, in my personal opinion,
enough understanding and uncomfortableness with being in control here, and it’s
designed in such a way that if other, better systems develop, you can move
to them. They’ve also indicated that moving governance of <code>did:plc</code> to some sort
of consensus model in the future is possible. There are options. Also, others
could run a <code>did:plc</code> service and use that instead if they prefer, too.</p>
<p>I personally see this as an example of pragmatically shipping something, others
see it as a nefarious plot. You’ll have to decide for yourself.</p>
<h2 id="how-is-bluesky-built-on-top-of-atproto">How is BlueSky built on top of atproto?</h2>
<p>So, now that we understand atproto, we can understand BlueSky. BlueSky is
an application built on top of the atproto network. They run an App View, and
<a href="https://bsky.app/">a web application</a> that uses that App View to work. They also run a PDS
for users that sign up through the web app, as well as a relay that those PDSes
communicate with.</p>
<p>They publish two Lexicons, one as <code>com.atproto.*</code> and one as <code>app.bsky.*</code>. The
former are low level operations that any application on the network will need,
and the ones specific to BlueSky are in the latter.</p>
<p>But one nice thing about BlueSky in particular is that they’ve taken the product
goals that nobody should know any of this nerd shit to be able to use BlueSky.
The lack of instances means there’s no “I need to pick an instance to create an
account” flow, and the portability means that if my host goes down, I can move,
and my followers are none the wiser.</p>
<h2 id="how-will-others-build-applications-on-top-of-atproto">How will others build applications on top of atproto?</h2>
<p>You can create an atproto app by creating a Lexicon. You’ll then want to run
an App View that does things with data on the network involving your lexicon,
and your application will want to give people the ability to write data to their
PDS using your lexicon.</p>
<p>I myself am considering doing so. We’ll see.</p>
<h2 id="concluding-thoughts">Concluding thoughts</h2>
<p>So yeah, on the technical side of things, that’s an overview of how atproto and
BlueSky work. I think this design is very clever. Furthermore, I think the
separation of concerns between atproto and BlueSky are very meaningful, as having
a “killer app” for the network gives a reason to use it. It also is a form of
dogfooding, making sure that atproto is good enough to be able to build real
applications on.</p>
<p>I’m sure I’ll have more to say about all of this in the future.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Architecture.md (2021) (262 pts)]]></title>
            <link>https://matklad.github.io/2021/02/06/ARCHITECTURE.md.html</link>
            <guid>39494925</guid>
            <pubDate>Sat, 24 Feb 2024 20:33:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matklad.github.io/2021/02/06/ARCHITECTURE.md.html">https://matklad.github.io/2021/02/06/ARCHITECTURE.md.html</a>, See on <a href="https://news.ycombinator.com/item?id=39494925">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <article>

    <h2>
    <a href="#ARCHITECTURE-md"><span>ARCHITECTURE.md</span> <time datetime="2021-02-06">Feb 6, 2021</time></a>
    </h2>
<p><span>If you maintain an open-source project in the range of 10k-200k lines of code, I strongly encourage you to add an </span><code>ARCHITECTURE</code><span> document next to </span><code>README</code><span> and </span><code>CONTRIBUTING</code><span>.</span>
<span>Before going into the details of why and how, I want to emphasize that this is not another </span>“<span>docs are good, write more docs</span>”<span> advice.</span>
<span>I am pretty sloppy about documentation, and, e.g., I often use just </span>“<span>simplify</span>”<span> as a commit message.</span>
<span>Nonetheless, I feel strongly about the issue, even to the point of pestering you :-)</span></p>
<p><span>I have experience with both contributing to and maintaining open-source projects.</span>
<span>One of the lessons I</span>’<span>ve learned is that the biggest difference between an occasional contributor and a core developer lies in the knowledge about the physical architecture of the project.</span>
<span>Roughly, it takes 2x more time to write a patch if you are unfamiliar with the project, but it takes 10x more time to figure out </span><em><span>where</span></em><span> you should change the code.</span>
<span>This difference might be hard to perceive if you</span>’<span>ve been working with the project for a while.</span>
<span>If I am new to a code base, I read each file as a sequence of logical chunks specified in some pseudo-random order.</span>
<span>If I</span>’<span>ve made significant contributions before, the perception is quite different.</span>
<span>I have a mental map of the code in my head, so I no longer read sequentially.</span>
<span>Instead, I just jump to where the thing should be, and, if it is not there, I move it.</span>
<span>One</span>’<span>s mental map is the source of truth.</span></p>
<p><span>I find the </span><code>ARCHITECTURE</code><span> file to be a low-effort high-leverage way to bridge this gap.</span>
<span>As the name suggests, this file should describe the high-level architecture of the project.</span>
<span>Keep it short: every recurring contributor will have to read it.</span>
<span>Additionally, the shorter it is, the less likely it will be invalidated by some future change.</span>
<span>This is the main rule of thumb for </span><code>ARCHITECTURE</code><span> </span>—<span> only specify things that are unlikely to frequently change.</span>
<span>Don</span>’<span>t try to keep it synchronized with code.</span>
<span>Instead, revisit it a couple of times a year.</span></p>
<p><span>Start with a bird</span>’<span>s eye overview of the problem being solved.</span>
<span>Then, specify a more-or-less detailed </span><em><span>codemap</span></em><span>.</span>
<span>Describe coarse-grained modules and how they relate to each other.</span>
<span>The codemap should answer </span>“<span>where</span>’<span>s the thing that does X?</span>”<span>.</span>
<span>It should also answer </span>“<span>what does the thing that I am looking at do?</span>”<span>.</span>
<span>Avoid going into details of </span><em><span>how</span></em><span> each module works, pull this into separate documents or (better) inline documentation.</span>
<span>A codemap is a map of a country, not an atlas of maps of its states.</span>
<span>Use this as a chance to reflect on the project structure.</span>
<span>Are the things you want to put near each other in the codemap adjacent when you run </span><code>tree .</code><span>?</span></p>
<p><em><span>Do</span></em><span> name important files, modules, and types.</span>
<span>Do </span><em><span>not</span></em><span> directly link them (links go stale).</span>
<span>Instead, encourage the reader to use symbol search to find the mentioned entities by name.</span>
<span>This doesn</span>’<span>t require maintenance and will help to discover related, similarly named things.</span></p>
<p><span>Explicitly call-out architectural invariants.</span>
<span>Often, important invariants are expressed as an </span><em><span>absence</span></em><span> of something, and it</span>’<span>s pretty hard to divine that from reading the code.</span>
<span>Think about a common example from web development: nothing in the model layer specifically doesn</span>’<span>t depend on the views.</span></p>
<p><span>Point out boundaries between layers and systems as well.</span>
<span>A boundary implicitly contains information about the implementation of the system behind it.</span>
<span>It even constrains all </span><em><span>possible</span></em><span> implementations.</span>
<span>But finding a boundary by just randomly looking at the code is hard </span>—<span> good boundaries have measure zero.</span></p>
<p><span>After finishing the codemap, add a separate section on cross-cutting concerns.</span></p>
<p><span>A good example of </span><code>ARCHITECTURE</code><span> document is this one from rust-analyzer:</span>
<a href="https://github.com/rust-analyzer/rust-analyzer/blob/d7c99931d05e3723d878bea5dc26766791fa4e69/docs/dev/architecture.md"><span>architecture.md</span></a><span>.</span></p>

</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cities stripping out concrete for earth and plants (155 pts)]]></title>
            <link>https://www.bbc.com/future/article/20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants</link>
            <guid>39494796</guid>
            <pubDate>Sat, 24 Feb 2024 20:16:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/future/article/20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants">https://www.bbc.com/future/article/20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants</a>, See on <a href="https://news.ycombinator.com/item?id=39494796">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="futurearticle20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants"><div id="headline-futurearticle20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants"><div><p>(Image credit: </p><!-- --><p>City of Leuven</p><!-- --><p>)</p></div><div><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjn4m.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjn4m.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjn4m.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjn4m.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjn4m.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjn4m.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjn4m.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjn4m.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Workers depave a stretch of concrete in Leuven, Belgium" src="https://ychef.files.bbci.co.uk/976x549/p0hdjn4m.jpg" alt="Workers depave a stretch of concrete in Leuven, Belgium" id=""></picture></div></div><div><article><div><p>From Australia to Ontario, cities are taking up unnecessary stretches of concrete and asphalt, allowing nature to take hold in their place.</p><div><p>O</p><div><p>On a hot July day, Katherine Rose picked up a sturdy metal pole and jammed it under the tempting lip of a pre-cut concrete slab. Rose, communications and engagement director at Depave, a non-profit in Portland, Oregon, was sweating in the heat – but she was going to win this fight.</p>
<p>The grubby, rectangular section of urban crust in front of her was about to move. Pushing down on her metal bar, applying it like a lever, she eased the concrete covering up and away. Now sunlight could fall once again on the ground below. A mess of gravel and dirt that was, to Rose, just bursting with potential.</p>
<p>"It feels like you're liberating soil," she says, recalling the summer gathering where she and around 50 volunteers <a href="https://depave.org/morning-star-missionary-baptist-church-upcoming-depave/">removed roughly 1,670 sq m (18,000 sq ft) of concrete</a> from the grounds of a local church. "It's envisioning and fully realising a dream that I think we all have," says Rose. The dream, that is, of bringing nature back into our midst. </p>
<p>The idea of depaving, sometimes known as desealing, is a simple one – replace as much concrete, asphalt and other forms of hard landscaping as possible with plants and soil. It's been around since at least 2008, when the Depave group in Portland was founded. Proponents say depaving allows water to soak into the ground, which reduces flooding in times of heavy rain – <a href="https://www.bbc.com/future/article/20220823-how-auckland-worlds-most-spongy-city-tackles-floods">aiding the "sponginess" of cities</a>. Native plants help <a href="https://www.bbc.com/future/article/20190118-how-do-you-bring-wildlife-back-to-the-city">wildlife cling on in urban spaces</a>, and by <a href="https://www.bbc.com/future/article/20230922-how-medellin-is-beating-the-heat-with-green-corridors">planting trees you can increase shade</a>, protecting residents from heatwaves. Injecting city streets <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5663018/">with greenery</a> may even <a href="https://knowablemagazine.org/content/article/mind/2021/health-benefits-nature">improve people's mental health</a>, too.</p>
<p>But if depaving is ever going to really take off, it will have to expand beyond a handful of eager environmentalists and volunteers. With the <a href="https://www.bbc.com/future/tags/climatechange">climate crisis</a> deepening, some cities and even entire regions are beginning to adopt depaving as part of their climate adaptation strategies. It's time, some say, to start smashing up our concrete streets in a big way – to create spaces better for nature. </p></div></div><div id="future/article/20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants-p0hdjpds"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjpds.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjpds.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjpds.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjpds.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjpds.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjpds.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjpds.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjpds.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Exposing more of the ground in urban spaces can help absorb rainfall and reduce flooding, as well as boost biodiversity (Credit: City of Leuven)" src="https://ychef.files.bbci.co.uk/976x549/p0hdjpds.jpg" alt="Exposing more of the ground in urban spaces can help absorb rainfall and reduce flooding, as well as boost biodiversity (Credit: City of Leuven)" id=""></picture><div><p>Exposing more of the ground in urban spaces can help absorb rainfall and reduce flooding, as well as boost biodiversity (Credit: City of Leuven)</p></div></div><div><p>Whenever Rose walks through a city these days, she can't help but notice places where you could strike out a section of asphalt and put in some plants. "I'm constantly just wanting to do more," she confesses. "It's hard not to see it everywhere."</p></div><div><h3>Sign up to Future Earth</h3></div><div><p>Her group says it has depaved more than 33,000 sq m (360,000 sq ft) of asphalt in Portland alone since 2008 – an area equivalent to nearly four and a half football pitches. The work is "joyous", says Rose, because it unites enthusiastic local volunteers. They get a safety briefing and then muck in together.</p>
<p>Green Venture, an environmental non-profit in Ontario, Canada, has been inspired in part by the depaving projects in Portland. Giuliana Casimirri, executive director, explains how she, her colleagues, and volunteers have begun inserting miniature gardens replete with native trees in a run-down district in the town of Hamilton.</p>
<p>"Before, it was somewhere you would quickly try to walk through," she says. "Now there are places you might stop or have a chat. Sit and read the paper."</p>
<p>In Hamilton, flooding can cause <a href="https://www.wosu.org/great-lakes-today/2017-08-14/spring-rain-caused-severe-sewage-overflows-in-lake-ontario">sewage to get mixed into runoff</a> that flows into Lake Ontario, the source of the town's drinking water. Green Venture and other local organisations are keen to reduce the chances of that happening, says Casimirri. They view depaving as a key tactic. Certainly, studies have demonstrated that impermeable surfaces in gardens such as concrete <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/jfr3.12231">increase flood risk in urban areas</a>.</p>
<p>Rose says her group's efforts in Portland mean that approximately 24.5 million gallons of rainwater is diverted from entering storm drains each year. In Leuven, Belgium, in 2023 alone, Baptist Vlaeminck, who leads Leuven's Life Pact climate adaptation project, calculates that the removal of 6,800 sq metres (73,000 sq ft) of hard surfacing allowed for the infiltration of an additional 377,000 gallons (1.7 million litres) of water into the ground.</p>
<p>"With climate change, extreme weather rainfall events are going to increase and so [depaving is] not a nice-to-have – it's a necessity," Casimirri adds.</p>
<p>The question is whether the authorities responsible for cities, and planning, realise this. In most parts of the world, depaving can still be described as a fringe activity. "We're going to need a scale of investment that has a lot more zeroes on it," says Thami Croeser at RMIT University, Melbourne's Centre for Urban Research.</p>
<p>Community-led and DIY efforts on driveways and on local streets with permission are fantastic, he adds, but it's even better to think of depaving and greening as the introduction of a new kind of infrastructure in a city. It requires the same level of planning and investment as, say, a new railway.</p></div><div id="future/article/20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants-p0hdjncz"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjncz.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjncz.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjncz.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjncz.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjncz.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjncz.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjncz.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjncz.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="The depave movement in Portland, Oregon has inspired a wave of cities to pull up their asphalt and concrete (Credit: Elle Hygge)" src="https://ychef.files.bbci.co.uk/976x549/p0hdjncz.jpg" alt="The depave movement in Portland, Oregon has inspired a wave of cities to pull up their asphalt and concrete (Credit: Elle Hygge)" id=""></picture><div><p>The depave movement in Portland, Oregon has inspired a wave of cities to pull up their asphalt and concrete (Credit: Elle Hygge)</p></div></div><div><p>In Europe, at least, some municipalities have begun to treat depaving seriously. Residents of London in the UK are <a href="https://www.london.gov.uk/programmes-strategies/environment-and-climate-change/parks-green-spaces-and-biodiversity/make-our-city-greener-healthier-and-wilder/de-pave-your-garden">encouraged to depave their gardens</a>, for example.</p>
<p>The city of Leuven in Belgium says it is embracing depaving – or "ontharden" – in a big way. <a href="https://leuven.be/vergroenenspaansekroon">The suburban district of Spaanse Kroon</a>, home to around 550 people, is one of the latest targets of a depaving and renaturing initiative spearheaded by the city. The plans involve removing significant volumes of asphalt from the residential area and forcing cars to share the same part of the road as pedestrians and cyclists.</p>
<p>"We are scaling up now, we are setting up a team dedicated to depaving," says Vlaeminck.</p>
<p>Such projects have to meet the needs of everyone in the city. Vlaeminck says that, to support people with impaired vision or mobility issues, unused areas of road or pavement are prioritised for depaving and sufficient space – more than a metre – is safeguarded on pavements to allow people plenty of room. Existing paving left in place is also renewed or repaired to ensure there are no bumps or unevenness. In situations where pavements are removed completely, for shared use of a roadway in low traffic neighbourhoods, Vlaeminck says depaving teams introduce measures to reduce the speed of cars.</p>
<p>Both Depave in Portland and Green Ventury in Ontario say they work with communities to ensure accessibility requirements are met. Casimirri refers to a recent project that replaced broken, uneven concrete with shrubbery and level walkways between.</p>
<p>Among the initiatives instigated by Leuven is a "tile taxi" – a small truck that officials will happily send to your home so you can throw in concrete tiles or cobblestones you have removed from your garden. The material is later reused rather than thrown away, says Vlaeminck, who adds that several million euros have been set aside by Leuven to fund depaving and renaturing projects such as this.</p>
<p>And there's more. Since January 2024, developers in Leuven have had to demonstrate that any rain that falls on new or significantly renovated homes can either be capture and re-used on-site or filtrate into the property's garden rather than pool up and cause a flood. If developers can't prove their designs are extreme rainfall-ready, they won't be approved, says Vlaeminck.</p>
<p>France, too, is making depaving official, says Gwendoline Grandin, an ecologist with the Île-de-France Regional Agency for Biodiversity. Nationally, the French government has made <a href="https://www.france24.com/en/environment/20220614-france-pledges-%E2%82%AC500-million-for-urban-vegetation-as-heatwave-descends">€500m ($540m/£430m) available for urban greening</a> – this includes depaving but also installing green walls and roofs, for example. Part of the motivation is to make towns and cities more resilient to summer heatwaves, which <a href="https://www.bbc.co.uk/news/world-europe-66197368">have badly affected parts of France in recent years</a>.</p>
<p>Some of the projects now underway are significant in size, such as <a href="https://www.iledefrance.fr/mediatheque/renaturer-la-facade-est-de-la-foret-de-saint-eutrope-avec-un-objectif-zero-dechet">a former parking area near a forest in the Paris region</a>. An area of 45,000 sq m (480,000 sq ft) has been depaved – formerly a hodgepodge of asphalt, pathways and concrete interlaced with grass. With the hard landscaping now gone, level ground is being reshaped to introduce dips and gullies that catch water, and the whole area will soon be planted over, too.</p></div><div id="future/article/20240222-depaving-the-cities-replacing-concrete-with-earth-and-plants-p0hdjprh"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjprh.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0hdjprh.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjprh.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0hdjprh.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjprh.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0hdjprh.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjprh.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0hdjprh.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Local schemes are often backed by residents keen to see more green in their local area (Credit: City of Leuven)" src="https://ychef.files.bbci.co.uk/976x549/p0hdjprh.jpg" alt="Local schemes are often backed by residents keen to see more green in their local area (Credit: City of Leuven)" id=""></picture><div><p>Local schemes are often backed by residents keen to see more green in their local area (Credit: City of Leuven)</p></div></div><div><p>In Croeser's own city of Melbourne, he and colleagues have studied the potential space available for renaturing, if thousands of parking spaces were depaved and converted into miniature gardens. <a href="https://www.nature.com/articles/s42949-022-00073-x">In a 2022 study, they simulated the impact</a> based on a series of scenarios – the most ambitious of which involved removing half of the open-air parking spaces in the city, about 11,000. Croeser argues that there is sufficient off-street parking available, for example on the ground floor of buildings, in Melbourne to ensure that people wouldn't be left without somewhere to leave their vehicle – but those interior parking spaces would need to be made publicly accessible.</p></div><div><h3>Carbon Count</h3></div><div><p>"The basic principle was no net loss of access to parking," he says. "And we get 50-60 hectares [120-150 acres] of green space that keeps the city cool, prevents flooding."</p>
<p>It might seem unlikely that small pockets of nature dotted here and there throughout a large city like Melbourne could benefit wildlife significantly, but Croeser says these fragments of habitat are crucial. They allow species to move around and cope in an environment that is, ultimately, very different to the one in which they evolved.</p>
<p>In their 2022 study on depaving in Melbourne, Croeser and his colleagues included modelling that suggested a modest increase in greenery could allow species such as the blue-banded bee to roam across a far greater area of urban habitat than before.</p>
<p>Rose agrees with Croeser that, for depaving to change the world, entire cities and even whole countries will have to embrace it fully. But she emphasises that, in order to reach that point, communities must express that this is something they want.</p>
<p>"It starts with people pushing their government and starting these conversations on a small, local level," she says. "That's how it takes hold."</p>
<p>--</p>
<p><em>If you liked this story,&nbsp;</em><a href="https://cloud.email.bbc.com/SignUp10_08?&amp;at_bbc_team=studios&amp;at_medium=Onsite&amp;at_objective=acquisition&amp;at_ptr_name=bbc.com&amp;at_link_origin=featuresarticle&amp;at_campaign=essentiallist&amp;at_campaign_type=owned"><em>sign up for The Essential List newsletter</em></a><em>&nbsp;– a handpicked selection of features, videos and can't-miss news delivered to your inbox every Friday.</em></p>
<p><em>Join one million Future fans by liking us on </em><a href="https://www.facebook.com/BBCFuture/"><em>Facebook</em></a><em>, or follow us on </em><a href="https://twitter.com/BBC_Future"><em>Twitter</em></a><em> or </em><a href="https://www.instagram.com/bbcfuture_official/"><em>Instagram</em></a><em>.</em></p></div></div></article></div>;</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We were not accepted into Google Summer of Code. So, we started our own (136 pts)]]></title>
            <link>https://qdrant.tech/blog/qdrant-summer-of-code-24/</link>
            <guid>39494741</guid>
            <pubDate>Sat, 24 Feb 2024 20:08:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qdrant.tech/blog/qdrant-summer-of-code-24/">https://qdrant.tech/blog/qdrant-summer-of-code-24/</a>, See on <a href="https://news.ycombinator.com/item?id=39494741">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><span>February 21, 2024</span>
<span>·</span>
<span>Andre Zayarni</span>
</p><p><img src="https://qdrant.tech/blog/qdrant-summer-of-code-24/preview/title.jpg" alt="Qdrant Summer of Code 24" loading="lazy">
</p><div>
<p>Google Summer of Code (#GSoC) is celebrating its 20th anniversary this year with the 2024 program. Over the past 20 years, 19K new contributors were introduced to #opensource through the program under the guidance of thousands of mentors from over 800 open-source organizations in various fields. Qdrant participated successfully in the program last year. Both projects, the UI Dashboard with unstructured data visualization and the advanced Geo Filtering, were completed in time and are now a part of the engine. One of the two young contributors joined the team and continues working on the project.</p><p>We are thrilled to announce that Qdrant was 𝐍𝐎𝐓 𝐚𝐜𝐜𝐞𝐩𝐭𝐞𝐝 into the GSoc 2024 program for unknown reasons, but instead, we are introducing our own 𝐐𝐝𝐫𝐚𝐧𝐭 𝐒𝐮𝐦𝐦𝐞𝐫 𝐨𝐟 𝐂𝐨𝐝𝐞 program with a stipend for contributors! To not reinvent the wheel, we follow all the timelines and rules of the official Google program.</p><h2 id="our-project-ideas">Our project ideas.</h2><p>We have prepared some excelent project ideas. Take a look and choose if you want to contribute in Rust or a Python-based project.</p><p>➡ <em>WASM-based dimension reduction viz</em> 📊</p><p>Implement a dimension reduction algorithm in Rust and compile to WASM and integrate the WASM code with Qdrant Web UI.</p><p>➡ <em>Efficient BM25 and Okapi BM25, which uses the BERT Tokenizer</em> 🥇</p><p>BM25 and Okapi BM25 are popular ranking algorithms. Qdrant’s FastEmbed supports dense embedding models. We need a fast, efficient, and massively parallel Rust implementation with Python bindings for these.</p><p>➡ <em>ONNX Cross Encoders in Python</em> ⚔️</p><p>Export a cross-encoder ranking models to operate on ONNX runtime and integrate this model with the Qdrant’s FastEmbed to support efficient re-ranking</p><p>➡ <em>Ranking Fusion Algorithms implementation in Rust</em> 🧪</p><p>Develop Rust implementations of various ranking fusion algorithms including but not limited to Reciprocal Rank Fusion (RRF). For complete list, see: <a href="https://github.com/AmenRa/ranx">https://github.com/AmenRa/ranx</a>
and create Python bindings for the implemented Rust modules.</p><p>➡ <em>Setup Jepsen to test Qdrant’s distributed guarantees</em> 💣</p><p>Design and write Jepsen tests based on implementations for other Databases and create a report or blog with the findings.</p><p>See all details on our Notion page: <a href="https://www.notion.so/qdrant/GSoC-2024-ideas-1dfcc01070094d87bce104623c4c1110">https://www.notion.so/qdrant/GSoC-2024-ideas-1dfcc01070094d87bce104623c4c1110</a></p><p>Contributor application period begins on March 18th. We will accept applications via email. Let’s contribute and celebrate together!</p><p>In open-source, we trust! 🦀🤘🚀</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[David Hahn, the 'radioactive boy scout' who tried to build a nuclear reactor (2022) (107 pts)]]></title>
            <link>https://allthatsinteresting.com/david-hahn</link>
            <guid>39494728</guid>
            <pubDate>Sat, 24 Feb 2024 20:06:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://allthatsinteresting.com/david-hahn">https://allthatsinteresting.com/david-hahn</a>, See on <a href="https://news.ycombinator.com/item?id=39494728">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<h2><p>David Hahn, The ‘Radioactive Boy Scout’ Who Tried To Build A Nuclear Reactor In His Backyard</p></h2>
			  </div><div>
			  <p>Published November 16, 2022</p>
					<p>Updated November 20, 2022</p>
				</div><div>
      <main role="main">
        <article itemprop="articleBody">

<h2>David Hahn caught the attention of the FBI and the Nuclear Regulatory Commission after he attempted to build a "breeder" reactor in a Michigan potting shed in the mid-1990s.</h2><div id="attachment_409047"><p><img fetchpriority="high" decoding="async" aria-describedby="caption-attachment-409047" src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/david-hahn-2.jpg" alt="David Hahn" width="700" height="511" srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/david-hahn-2.jpg 700w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/david-hahn-2-300x219.jpg 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/david-hahn-2-150x110.jpg 150w" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/david-hahn-2.jpg 700w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/david-hahn-2-300x219.jpg 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/david-hahn-2-150x110.jpg 150w" data-src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/david-hahn-2.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p id="caption-attachment-409047"><span>YouTube/Weird History</span><span>David Hahn, the so-called “Radioactive Boy Scout,” pictured in front of the shed in which he tried to build a nuclear reactor.</span></p></div>
<p>In 1995, a teenage boy scout in Michigan named David Hahn attracted the attention of local authorities in his Detroit suburb. Hahn caught the law’s eye when suspicious materials were found in his car. But further investigation revealed a series of backyard science experiments, including the teen’s attempt to build a working nuclear reactor.</p>
<p>Achieved with materials he had at hand, Hahn managed to successfully create a homemade neutron source in an everyday backyard shed — and nearly irradiated his whole neighborhood.</p>
<p>Hahn had been fascinated with science since childhood. Intending to create a breeder reactor in 1995, the result was less than intended, but enough to capture national attention. This is the unbelievable true story of David Hahn — more popularly known as the “Radioactive Boy Scout” or the “Nuclear Boy Scout.”</p>

<div id="attachment_396173"><p><img decoding="async" aria-describedby="caption-attachment-396173" src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-74213-pm.png" alt="David Hahn The Boy Scout" width="900" height="600" srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-74213-pm.png 900w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-74213-pm-300x200.png 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-74213-pm-768x512.png 768w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-74213-pm-150x100.png 150w" sizes="(max-width: 900px) 100vw, 900px" data-srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-74213-pm.png 900w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-74213-pm-300x200.png 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-74213-pm-768x512.png 768w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-74213-pm-150x100.png 150w" data-src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-74213-pm.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p id="caption-attachment-396173"><span>YouTube</span><span>A young David Hahn sporting a merit badge sash.</span></p></div>
<p>David Hahn tried to build his homemade nuclear reactor when he was only 17, according to <a href="https://vault.fbi.gov/david-hahn/David%20Hahn%20Part%2001%20of%2001/view" rel="noopener" target="_blank">FBI records</a>. Conducted in his step-mother’s backyard in Commerce Township, Michigan, the experiments were run in near secrecy.</p>
<p>Practically a wunderkind, Hahn began studying chemistry at age 10 and had fabricated nitroglycerin by 14. Before attempting to build his reactor, Hahn tarnished his bedroom with his experiments, so his parents moved his work to their basement, before settling on the shed.</p>
<p>Hahn gathered information by contacting the Nuclear Regulatory Commission, hoping to gain insight into the steps of building a breeder reactor. In most cases, Hahn was able to gather the info he needed with the help of aliases and cover stories.</p>
<p>Hahn’s interest in creating a breeder reactor was fueled by many things. The teen read about chemical experiments fervently, teaching himself how to manipulate reactions, and was awarded a merit badge for atomic energy in 1991. He supplemented his practical research with long study sessions at his local library</p>
<p>The flames of Hahn’s fascination were fanned by two obsessive goals, one being the task of creating a breeder reactor; the other, of collecting each element on the periodic table — regardless of radioactivity.</p>
<p>For Hahn, the creation of a homemade nuclear reactor would have been <a href="https://www.britannica.com/technology/breeder-reactor" rel="noopener" target="_blank">a more complex task</a> than creating a homemade breeder reactor. Both requiring dangerous materials, breeder reactors utilize the more available chemical isotope Uranium-238 — the chemical element thorium — while nuclear reactors may only use the scarcer Uranium-235.</p>
<p>While the uranium used in nuclear reactors are readily fissionable, Uranium-238 and thorium are more available.</p>
<p>And so, utilizing household items and a lead block as a stand-in reactor, Hahn got to work. He collected thorium from lanterns, radium from clocks, tritium from gunsights, and lithium from $1,000 worth of batteries he bought himself.</p>
<p>Hahn also employed coffee filters and pickle jars to handle dangerous and potentially deadly chemicals. The lack of protection, save for his gas mask, tragically, was later said to have affected Hahn’s life expectancy.</p>
<p>During his shed-bound experiments, Hahn persevered through accidental burns on his skin, turning his hair green, and mistakenly causing himself to pass out.</p>
<p>When the experiment met its threshold, Hahn had created a crude neutron source. While unable to produce fissionable fuel at the rate of other reactors, the the Boy Scout’s experiment was already spreading detectable radiation several houses away. </p>
<h2>David Hahn’s Experiments Attract The Wrong Kind Of Attention</h2>
<div id="attachment_396175"><p><img decoding="async" aria-describedby="caption-attachment-396175" src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-75515-pm.png" alt="The Golden Book of Chemistry Experiments" width="900" height="600" srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-75515-pm.png 900w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-75515-pm-300x200.png 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-75515-pm-768x512.png 768w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-75515-pm-150x100.png 150w" sizes="(max-width: 900px) 100vw, 900px" data-srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-75515-pm.png 900w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-75515-pm-300x200.png 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-75515-pm-768x512.png 768w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-75515-pm-150x100.png 150w" data-src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-75515-pm.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p id="caption-attachment-396175"><span>Jim West</span><span>David Hahn posing with <em>The Golden Book of Chemistry Experiments</em>, a book that shaped his interests.</span></p></div>
<p>As detected by David Hahn’s own Geiger counter, his experiment proved radioactive by the time it was disassembled — and left 40,000 town residents potentially at risk.</p>
<p>Police located Hahn’s shed after stopping the young teen for unrelated reasons. Finding suspicious materials in his trunk, the scout informed the officers the content was radioactive. From there, it did not take long to uncover the shed and its impact on Hahn’s neighborhood.</p>
<p>The local police contacted the federal authorities, leading the Environmental Protection Agency to Hahn’s doorstep. Those who entered Hahn’s shed lab were warned by a misspelled “Caushon” sign on the wall.</p>
<p>Inside, authorities found evidence of Hahn’s dangerous hobbies. The remnants of the experiment and materials collected posed numerous health risks, and the EPA declared the property a Superfund hazardous materials cleanup site.</p>
<p>Despite insistence from officials, Hahn refused to be medically evaluated following the long periods he spent around radioactive materials. Since his experiment took place with minimal protection, Hahn’s life expectancy was likely shortened after the incident.</p>
<p>Following the lab’s dismantling, Hahn achieved his Eagle Scout rank despite efforts to rob him of the honor on account of his dangerous experiment. However, regardless of what progress he made, Hahn had trouble finding direction following the experiment’s fallout.</p>
<p>“I was very emotional as a kid, and those experiments gave me a way to get away from that. They gave me some respect,” Hahn told <em><a href="https://harpers.org/archive/1998/11/the-radioactive-boy-scout/" rel="noopener" target="_blank">Harpers Magazine</a></em> in 1998.</p>
<h2>The Sad Final Years Of The Radioactive Boy Scout</h2>
<div id="attachment_396169"><p><img decoding="async" aria-describedby="caption-attachment-396169" src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-73127-pm.png" alt="David Hahn and half-brother Kevin" width="900" height="600" srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-73127-pm.png 900w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-73127-pm-300x200.png 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-73127-pm-768x512.png 768w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-73127-pm-150x100.png 150w" sizes="(max-width: 900px) 100vw, 900px" data-srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-73127-pm.png 900w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-73127-pm-300x200.png 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-73127-pm-768x512.png 768w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-73127-pm-150x100.png 150w" data-src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2022/11/screen-shot-2022-09-04-at-73127-pm.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p id="caption-attachment-396169"><span>Kenneth Hahn</span><span>David Hahn and his half-brother, Kevin.</span></p></div>
<p>The collapse of his experiment, turmoil from a failed relationship, and his mother’s suicide each contributed to “Nuclear Boy Scout” David Hahn’s depression, according to <em><a href="https://arstechnica.com/tech-policy/2017/03/radioactive-boy-scout-died-of-alcohol-poisoning-not-radiation-father-says/" rel="noopener" target="_blank">Ars Technica</a></em>. Attempting to find his place in the world after the disastrous events in his backyard, he tried his hand at college and the military, mostly at the request of his father and step-mother.</p>
<p>Hahn served in both the United States Navy and the United States Marine Corps, but only found new complications with mental health as he grew older.</p>
<p>Following his original experiment’s disassembly, Hahn once again attracted the police’s attention a decade later. Suspected of creating another reactor and storing it in his freezer, Hahn was arrested in 2007 for stealing some detectors.</p>
<p>The devices were taken from the apartment complex Hahn was staying in. The theft was significant for the small amounts of radioactive americium found in the smoke detectors. Since americium was found in greater amounts in Hahn’s shed in 1995, authorities evacuated residents for five hours — fearing the infamous former Boy Scout was at it again.</p>
<p>At the time of the incident, police had already been tracking Hahn and monitoring the region for radioactivity. Coinciding with his return to the area, authorities took note that Hahn had begun advertising a book written about his experiment.</p>
<p>With their eyes already fixed on Hahn, the police were quick to arrest him on account of his theft. Sixteen smoke detectors across Hahn’s building and another in his complex had gone missing. Police found additional empty smoke detectors near Hahn’s trash.</p>
<p>Following his arrest, David Hahn pleaded guilty to attempted larceny of a building and was sentenced to 90 days in jail. And about a decade later, Hahn died from a combination of alcohol, diphenhydramine, and fentanyl. The “Nuclear Boy Scout” was just 39 years old. </p>
<hr>
<p><em>After reading about David Hahn and his attempts to build a nuclear reactor, learn more about <a href="https://allthatsinteresting.com/chernobyl-today">The Chernobyl disaster</a>. Then, read about <a href="https://allthatsinteresting.com/hisashi-ouchi">Hisashi Ouchi, who sustained the worst radiation burns in history</a>.</em></p>
        </article>
      </main>

      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coding the anime "woosh" screen on Amiga (171 pts)]]></title>
            <link>https://dansalva.to/coding-the-anime-woosh-screen-on-amiga/</link>
            <guid>39494227</guid>
            <pubDate>Sat, 24 Feb 2024 19:05:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dansalva.to/coding-the-anime-woosh-screen-on-amiga/">https://dansalva.to/coding-the-anime-woosh-screen-on-amiga/</a>, See on <a href="https://news.ycombinator.com/item?id=39494227">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
<video playsinline="" controls="" muted=""><source src="https://dansalva.to/images/20240223/1.mp4#t=0.01" type="video/mp4">Your browser does not support the video tag.</video>
<p>The Amiga was a spectacle of graphics and sound when it debuted in 1985. While it can trivially display colorful images like in the above example, doing so in the context of a game engine presents a lot of unique challenges.</p>
<p>If you haven't seen the gameplay proof-of-concept video for Magicore Anomala, you can check it out <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=4SB20aFHc08">here</a>.</p>
<h2>Challenge 1: The RAM requirements</h2><p>A run-of-the-mill Amiga 500 has 512kb of "Chip RAM" and 512kb of expansion RAM (sometimes called "Slow RAM"), which is the platform target for Magicore. Only Chip RAM can be used by the Amiga chipset to present graphics and sound, which makes it much more valuable—all other kinds of expansion RAM can only be accessed by the CPU.</p>
<p>The fullscreen character graphic (CG) is a 320x240 bitmap with 32 colors, which takes up 48kb of RAM uncompressed. That is a <em>lot</em>. Between all the common assets, level data, and screen memory allocations, we don't want to afford that kind of overhead on the RAM.</p>
<p>Thankfully, I recently added support for asset compression, using the ZX0 compression format. Compressed, the CG is about 8kb, which is acceptable.</p>
<p>When the level assets are loaded, the compressed CG is loaded into the expansion RAM. Then, right before it gets displayed, I unpack it into Chip RAM.</p>
<p>The trick is that instead of finding 48kb of free Chip RAM to use, I reuse other parts of screen memory:</p>
<ul>
<li>The room background image (the grassy field, in this example)</li>
<li>The screen layer used to render hazardous objects (not shown in the video)</li>
<li>The textbox screen area (as seen in the gameplay proof-of-concept video)</li>
</ul>
<p>All three of these memory regions are contiguous in RAM, and they come out to 48,000 bytes, which is the <em>exact</em> size of the CG!</p>
<p>It's also okay to overwrite the room background image, because we can restore it after the CG is done being displayed.</p>
<p>In the video below, I force the CG to always be shown on the screen, so we can watch how the data gets decompressed and overwritten.</p>
<video playsinline="" controls="" muted=""><source src="https://dansalva.to/images/20240223/2.mp4#t=0.01" type="video/mp4">Your browser does not support the video tag.</video>
<p>Pretty cool, right? As you can see, the CG takes maybe 500ms to fully decompress. But that "loading time" is hidden into the flow of the cutscene.</p>
<h2>Challenge 2: The "screen split" effect</h2><p>I was initially thinking about doing a vertical wipe for the screen transition. But for that to look nice, the wipe would have to be a gradient, adjusting the color palette every scanline. That's pretty possible, but the coprocessor (copper) alone struggles to set all 32 colors in a single horizontal blank, and—I'll be honest—I didn't want to deal with "racing the beam".</p>
<p>The screen split effect is easier to pull off, and I think it looks cooler to the common viewer. In fact, the copper was practically purpose-designed for this effect! Check out <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=YlAhRJjOhDg">this</a> video, which demonstrates a similar effect built right into Amiga Workbench.</p>
<p>This demonstrates two special features of Amiga working in tandem:</p>
<ol>
<li>The copper runs in parallel to the CPU with its own instruction list. Those instructions can tell it to change certain hardware registers at specific lines on the screen.</li>
<li>The screen memory can be changed to <em>anywhere</em> in Chip RAM by setting screen pointers in the hardware registers. That means you can have multiple bitmap screens and switch between them whenever you want—every frame (e.g. for double buffering), or even multiple times in one frame.</li>
</ol>
<p>Let's say my "main" screen memory begins at <code>0x20000</code>. Normally, I instruct the copper to arm the bitplane DMA registers with this address. Once I enable the bitplanes, the DMA happily marches through this region of memory, drawing its data to the screen while incrementing the address pointer as it goes.</p>
<p>There is an interesting trick. Let's say each horizontal line takes up <code>0x100</code> bytes of screen memory. What if I set the screen pointer to <code>0x20800</code> instead?</p>
<p>The screen will appear to "scroll up" by 8 lines, because the screen officially starts 8 lines down into memory.</p>
<p>I have the top half of the split scroll up in this fashion. Then, at the split point, the copper is instructed to shut off bitplane DMA (and change the BG color to red).</p>
<p>Now, all the bitplane-related hardware registers are effectively frozen in time. Once we reach the bottom of the split, the copper resets the BG color and resumes bitplane DMA. The display picks up right where it left off, just lower down on the screen!</p>
<p>If you're wondering what this looks like, here is the copperlist used for the effect:</p>
<pre tabindex="0"><code><span><span>vs_TCop</span><span>:</span></span>
<span><span>                 </span><span>; Wait for top split to end</span></span>
<span><span>vs_TCopTop</span><span>:      </span><span>dc.w</span><span>   </span><span>$9007</span><span>,</span><span>$fffe</span></span>
<span><span>                 </span><span>; Set BG color</span></span>
<span><span>vs_TCopColorTop</span><span>: </span><span>dc.w</span><span>   COLOR0</span><span>0</span><span>,</span><span>0</span></span>
<span><span>                 </span><span>; Disable sprite and bitplane DMA</span></span>
<span><span>                 </span><span>dc.w</span><span>   DMACON,</span><span>$0120</span></span>
<span><span>                 </span><span>; Wait for bottom split to start</span></span>
<span><span>vs_TCopBottom</span><span>:   </span><span>dc.w</span><span>   </span><span>$90e1</span><span>,</span><span>$fffe</span></span>
<span><span>                 </span><span>; Restore BG color</span></span>
<span><span>vs_TCopColorOld</span><span>: </span><span>dc.w</span><span>   COLOR0</span><span>0</span><span>,</span><span>0</span></span>
<span><span>                 </span><span>; Enable sprite and bitplane DMA</span></span>
<span><span>                 </span><span>dc.w</span><span>   DMACON,</span><span>$8120</span></span></code></pre>
<p>That's it! Every frame, I use the CPU to adjust <code>vs_TCopTop</code> and <code>vs_TCopBottom</code> based on the current width of the split. (Not shown: Adjusting the screen pointer for the top split, as described above.)</p>
<h2>Challenge 3: The "motion lines"</h2><p>You can't reach full anime without having the lines that go "woosh" in the background.</p>
<p>I use sprites to draw the lines, which is a good choice because they can be drawn and moved fully independently from screen memory. The issue is that Amiga sprites are both very limited and very complicated.</p>
<h3>Sprite colors</h3><p>Sprites share a color palette with bitplanes, meaning I want to use up as few colors as possible. The sprite is only 3 colors, leaving 28 for the CG (and 1 for the background).</p>
<p>The problem is that different sprites use different colors in the palette. The first two sprites use colors 16-19, the second two sprites use colors 20-23, and so on.</p>
<p>This changes if you combine sprites. By "attaching" two sprites together, they become one sprite with a 16-color palette (colors 16-31). That means for the motion lines, I can use 4 attached sprites, and use only colors 29-31 in the graphic. It's a silly workaround for a silly limitation.</p>
<h3>Reusing a sprite graphic</h3><p>The first 4 bytes of a sprite graphic are actually "control bits" that tell the Amiga the position and height of the sprite. That is actually a pain—what if we want to draw the same graphic in multiple locations?</p>
<p>My first thought was to manually set the hardware registers for sprite control bits, but I simply could not get the sprite to display on screen when doing this. Amiga sprite DMA works similarly to bitplane DMA; it has a pointer to the sprite data that it walks through in order to display it to the screen. But when manually setting the control bits, I just couldn't get it to do that. I'm sure it can be done, but I decided to find another way.</p>
<p>I instead created 8 fake sprites that are only 4 bytes large—<em>just</em> the control bits. I set all the sprite pointers to those fake sprites.</p>
<p>Around line 19, the sprite DMA looks at all the sprite pointers and arms itself with the control bits, preparing to draw the data to the screen at the specified position.</p>
<p>Once it does so, I pull a switcheroo: I change all the sprite pointers to the "motion line" graphic. Now, the DMA is armed to draw all the sprites at different positions, but using the same graphic.</p>
<p>Again, this can be trivially done in the copperlist:</p>
<pre tabindex="0"><code><span><span>             </span><span>; Set dummy sprite pointers (to arm control bits)</span></span>
<span><span>vs_CopSprP</span><span>:  COPPTR     SPR0PT</span></span>
<span><span>             COPPTR     SPR1PT</span></span>
<span><span>             COPPTR     SPR2PT</span></span>
<span><span>             COPPTR     SPR3PT</span></span>
<span><span>             COPPTR     SPR4PT</span></span>
<span><span>             COPPTR     SPR5PT</span></span>
<span><span>             COPPTR     SPR6PT</span></span>
<span><span>             COPPTR     SPR7PT</span></span>
<span><span>             </span><span>; Wait for line 19</span></span>
<span><span>             </span><span>dc.w</span><span>       </span><span>$14df</span><span>,</span><span>$fffe</span></span>
<span><span>             </span><span>; Now that control bits are armed, set data pointers</span></span>
<span><span>vs_CopSprP2</span><span>: COPPTR     SPR0PT</span></span>
<span><span>             COPPTR     SPR1PT</span></span>
<span><span>             COPPTR     SPR2PT</span></span>
<span><span>             COPPTR     SPR3PT</span></span>
<span><span>             COPPTR     SPR4PT</span></span>
<span><span>             COPPTR     SPR5PT</span></span>
<span><span>             COPPTR     SPR6PT</span></span>
<span><span>             COPPTR     SPR7PT</span></span></code></pre>
<h3>Sprites don't get drawn when bitplanes are off</h3><p>Before the CG reaches the top of the screen, there is a bunch of empty space between the top of the screen and the start of the CG. If bitplanes are enabled during this time, they will draw junk data to the screen. Here is an example of that:</p>
<video playsinline="" controls="" muted=""><source src="https://dansalva.to/images/20240223/3.mp4#t=0.01" type="video/mp4">Your browser does not support the video tag.</video>
<p>Dang, that's actually kind of cool-looking. Missed opportunity?</p>
<p>In that screen region, we want to disable bitplanes so that the DMA doesn't run away with junk data like that.</p>
<p>One problem: If you disable bitplanes, then sprites also don't get drawn! I don't know why it works like this, but it does.</p>
<video playsinline="" controls="" muted=""><source src="https://dansalva.to/images/20240223/4.mp4#t=0.01" type="video/mp4">Your browser does not support the video tag.</video>
<p>See how the lines only get drawn within the bounds of the CG?</p>
<p>My solution was to keep just 1 bitplane enabled, and set the screen pointer to empty data. That way, it <em>is</em> drawing to the screen, but it's just drawing nothing.</p>
<p>But where do I find a screen full of empty data? Thankfully, I don't have to. There are "bitplane modulo" registers (<code>BPLMOD1</code> and <code>BPLMOD2</code>) that let you increment the screen pointer by a certain amount after each line. This is useful for interleaved bitplanes, which I won't get into here.</p>
<p>At 1 bit per pixel, a 320-pixel line is 320 bits, or 40 bytes. If I set <code>BPLMOD1</code> to -40, then it will go backwards 40 bytes after each line, causing it to draw the same 40 bytes over and over, on each new line.</p>
<p>That means I only need to find 40 bytes of empty data, which is easy to find; my screen has "safety margins" which hold nothing but junk data from objects that are drawn beyond the screen borders. I can just clear out the first 40 bytes of the safety margin, and I'm good to go.</p>
<h2>Conclusion</h2><p>I originally wasn't sure if I would include CGs like this in the game, because I was worried about the RAM requirements. But now that I have data compression implemented, I proved that the overhead is extremely reasonable, and I can add this extra bit of flair to Magicore.</p>
<p>There were a lot of other small challenges I didn't go over here, like getting the bottom of the 100px motion line to not abruptly disappear after the sprite leaves the top of the screen. But the ones I covered were the most interesting to me, especially how they involve unique quirks of Amiga hardware.</p>
<p>Also, if you like Amiga, you might have noticed that this effect doesn't use the blitter at all! If you want to read a blitter-related post, try <a href="https://dansalva.to/getting-clever-with-the-amiga-blitter">this</a> one.</p>
<p>Amiga is so great at displaying colorful graphics that I hope I can impress people with its capabilities today, just as they were in the latter half of the 80s.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A simple MUD server in Python which can be run on a Raspberry Pi (108 pts)]]></title>
            <link>https://github.com/Frimkron/mud-pi</link>
            <guid>39493989</guid>
            <pubDate>Sat, 24 Feb 2024 18:40:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Frimkron/mud-pi">https://github.com/Frimkron/mud-pi</a>, See on <a href="https://news.ycombinator.com/item?id=39493989">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><h2 tabindex="-1" dir="auto">MUD Pi</h2>
<p dir="auto">A simple text-based Multi-User Dungeon (MUD) game, which could be run on a
Raspberry Pi or other low-end server.</p>
<h2 tabindex="-1" dir="auto">Requirements</h2>
<p dir="auto">You will need to install <em>Python</em> (2.7+ or 3.3+) where you wish to run the
server. Installers for Windows and Mac can be found at
<a href="http://www.python.org/download/" rel="nofollow">http://www.python.org/download/</a>. There are also tarballs for Linux, although
the best way to install on Linux would be via the package manager.</p>
<p dir="auto">To allow players to connect remotely, the server will also need to be connected
to the internet.</p>
<p dir="auto">To connect to the server you will need a telnet client. On Mac, Linux, and
versions of Windows prior to Windows Vista, the telnet client is usually
installed by default. For Windows Vista, 7, 8 or later, you may need to follow
<a href="http://technet.microsoft.com/en-us/library/cc771275%28v=ws.10%29.aspx" rel="nofollow">this guide</a>
to install it.</p>
<h2 tabindex="-1" dir="auto">Running the Server</h2>
<h3 tabindex="-1" dir="auto">On Windows</h3>
<p dir="auto">Double click on <code>simplemud.py</code> - the file will be opened with the Python
interpreter. To stop the server, simply close the terminal window.</p>
<h3 tabindex="-1" dir="auto">On Mac OSX and Linux (including Raspberry Pi)</h3>
<p dir="auto">From the terminal, change to the directory containing the script and run</p>

<p dir="auto">Note, if you are connected to the machine via SSH, you will find that the
script stops running when you quit the SSH session. A simple way to leave the
script running is to use a tool called <code>screen</code>. Connect via SSH as usual then
run <code>screen</code>. You will enter what looks like a normal shell prompt, but now you
can start the python script running and hit <code>ctl+a</code> followed by <code>d</code> to leave
<em>screen</em> running in the background. The next time you connect, you can
re-attach to your screen session using <code>screen -r</code>. Alternatively you could
<a href="http://jimmyg.org/blog/2010/python-daemon-init-script.html" rel="nofollow">create a daemon script</a>
to run the script in the background every time the server starts.</p>
<h2 tabindex="-1" dir="auto">Connecting to the Server</h2>
<p dir="auto">If the server is running behind a NAT such as a home router, you will need to
set up port <strong>1234</strong> to be forwarded to the machine running the server. See your
router's instructions for how to set this up. There are a large number of
setup guides for different models of router here:
<a href="http://portforward.com/english/routers/port_forwarding/" rel="nofollow">http://portforward.com/english/routers/port_forwarding/</a></p>
<p dir="auto">You will need to know the <em>external</em> IP address of the machine running the
server. This can be discovered by visiting <a href="http://www.whatsmyip.org/" rel="nofollow">http://www.whatsmyip.org</a> from
that machine.</p>
<p dir="auto">To connect to the server, open your operating system's terminal or command
prompt and start the telnet client by running:</p>

<p dir="auto">where <code>&lt;ip address&gt;</code> is the external IP address of the server, as described
above. 1234 is the port number that the server listens on.</p>
<p dir="auto">If you are using Windows Vista, 7, 8 or later and get the message:</p>
<div data-snippet-clipboard-copy-content="'telnet' is not recognized as an internal or external command, operable
program or batch file."><pre><code>'telnet' is not recognized as an internal or external command, operable
program or batch file.
</code></pre></div>
<p dir="auto">then follow
<a href="http://technet.microsoft.com/en-us/library/cc771275%28v=ws.10%29.aspx" rel="nofollow">this guide</a>
to install the Windows telnet client.</p>
<p dir="auto">If all goes well, you should be presented with the message</p>

<p dir="auto">To quit the telnet client, press <code>ctl + ]</code> to go to the prompt, and then
type <code>quit</code>.</p>
<h2 tabindex="-1" dir="auto">What is Telnet?</h2>
<p dir="auto">Telnet is simple text-based network communication protocol that was invented in
1969 and has since been superseded by other, more secure protocols. It does
remain popular for a few specialised uses however, MUD games being one of these
uses. A long (and boring) history of the telnet protocol can be found here:
<a href="http://www.cs.utexas.edu/users/chris/think/ARPANET/Telnet/Telnet.shtml" rel="nofollow">http://www.cs.utexas.edu/users/chris/think/ARPANET/Telnet/Telnet.shtml</a></p>
<h2 tabindex="-1" dir="auto">What is a MUD?</h2>
<p dir="auto">MUD is short for Multi-User Dungeon. A MUD is a text-based online role-playing
game. MUDs were popular in the early 80s and were the precursor to the
graphical Massively-Multiplayer Online Role-Playing Games we have today, like
World of Warcraft. <a href="http://www.mudconnect.com/" rel="nofollow">http://www.mudconnect.com</a> is a great site for learning
more about MUDs.</p>
<h2 tabindex="-1" dir="auto">Extending the Game</h2>
<p dir="auto">MUD Pi is a free and open source project (that's <em>free</em> as in <em>freedom</em>). This
means that the source code is included and you are free to read it, copy it,
extend it and use it as a starting point for your own MUD game or any other
project. See <code>licence.md</code> for more info.</p>
<p dir="auto">MUD Pi was written in the Python programming language. If you have never used
Python before, or are new to programming in general, why not try an online
tutorial, such as <a href="http://www.learnpython.org/" rel="nofollow">http://www.learnpython.org/</a>.</p>
<p dir="auto">There are 2 source files in the project. <code>mudserver.py</code> is a module containing
the <code>MudServer</code> class - a basic server script which handles player connections
and sending and receiving messages. <code>simplemud.py</code> is an example game using
<code>MudServer</code>, with player chat and rooms to move between.</p>
<p dir="auto">The best place to start tweaking the game would be to have a look at
<code>simplemud.py</code>. Why not try adding more rooms to the game world? You'll find
more ideas for things to try in the source code itself.</p>
<p dir="auto">Of course if you're feeling more adventurous you could take a look at the
slightly more advanced networking code in <code>mudserver.py</code>.</p>
<h2 tabindex="-1" dir="auto">MUD-Pi-Based Projects</h2>
<p dir="auto">Here are some of the cool projects people have made from MUD-Pi:</p>
<ul dir="auto">
<li><strong><a href="http://git.savsoul.com/barry/esp8266-Mud" rel="nofollow">ESP8266 MUD</a> by Barry Ruffner</strong> -
a MUD that runs entirely within an ESP8266 microchip, using MicroPython</li>
<li><strong><a href="https://github.com/ufosc/MuddySwamp">MuddySwamp</a> by the University of</strong>
<strong>Florida Open Source Club</strong> - a UF-themed MUD</li>
<li><strong><a href="https://github.com/wowpin/dumserver">Dumserver</a> by Bartek Radwanski</strong> -
a feature-rich MUD engine</li>
</ul>
<h2 tabindex="-1" dir="auto">Author</h2>
<p dir="auto">MUD Pi was written by Mark Frimston</p>
<p dir="auto">For feedback, please email <a href="mailto:mfrimston@gmail.com">mfrimston@gmail.com</a> or add a comment on the
project's <a href="http://github.com/frimkron/mud-pi">Github page</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google helped destroy adoption of RSS feeds (867 pts)]]></title>
            <link>https://openrss.org/blog/how-google-helped-destroy-adoption-of-rss-feeds</link>
            <guid>39493770</guid>
            <pubDate>Sat, 24 Feb 2024 18:16:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openrss.org/blog/how-google-helped-destroy-adoption-of-rss-feeds">https://openrss.org/blog/how-google-helped-destroy-adoption-of-rss-feeds</a>, See on <a href="https://news.ycombinator.com/item?id=39493770">Hacker News</a></p>
<div id="readability-page-1" class="page"><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>&lt;![CDATA[openrss.org]]&gt;</title><!--[CDATA[https://openrss.org/blog/how-google-helped-destroy-adoption-of-rss-feeds]]--><description><!--[CDATA[ ]]--></description></channel></rss></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. rice exports to Haiti have unhealthy levels of arsenic, study finds (138 pts)]]></title>
            <link>https://www.reuters.com/world/americas/us-rice-exports-haiti-have-unhealthy-levels-arsenic-study-finds-2024-02-24/</link>
            <guid>39493713</guid>
            <pubDate>Sat, 24 Feb 2024 18:09:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/americas/us-rice-exports-haiti-have-unhealthy-levels-arsenic-study-finds-2024-02-24/">https://www.reuters.com/world/americas/us-rice-exports-haiti-have-unhealthy-levels-arsenic-study-finds-2024-02-24/</a>, See on <a href="https://news.ycombinator.com/item?id=39493713">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/americas/us-rice-exports-haiti-have-unhealthy-levels-arsenic-study-finds-2024-02-24/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Mass Retraction of unethical Chinese Forensic Genetics Papers (102 pts)]]></title>
            <link>https://www.science.org/content/article/ethics-not-checkbox-exercise-bioinformatician-yves-moreau-reacts-mass-retraction-papers</link>
            <guid>39493513</guid>
            <pubDate>Sat, 24 Feb 2024 17:49:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/ethics-not-checkbox-exercise-bioinformatician-yves-moreau-reacts-mass-retraction-papers">https://www.science.org/content/article/ethics-not-checkbox-exercise-bioinformatician-yves-moreau-reacts-mass-retraction-papers</a>, See on <a href="https://news.ycombinator.com/item?id=39493513">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/ethics-not-checkbox-exercise-bioinformatician-yves-moreau-reacts-mass-retraction-papers: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Quantifying the diva-ness of national anthem performances (103 pts)]]></title>
            <link>https://pudding.cool/2024/02/anthems/</link>
            <guid>39493237</guid>
            <pubDate>Sat, 24 Feb 2024 17:19:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pudding.cool/2024/02/anthems/">https://pudding.cool/2024/02/anthems/</a>, See on <a href="https://news.ycombinator.com/item?id=39493237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section id="phrase-by-phrase">  <div aria-label="carousel"> <div id="slide-0" role="group" aria-label="slide 1 of undefined" aria-current="true"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>    <h3 data-svelte-h="svelte-1qeu3uy">Our picks</h3> </div> <div><div><p><!-- HTML_TAG_START -->We begin with “o say can you see.” Francis Scott Key penned this opening line after seeing the American flag flying defiantly over Fort McHenry having withstood a bombardment by British forces during the War of 1812.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->The “Star Spangled Banner” didn’t become the US’ official anthem until nearly a century later in 1931, and it wasn’t thrust into the pop culture spotlight until the late 1960s when <a href="https://www.youtube.com/watch?v=aQkY2UFBUb4" target="_blank">José Feliciano,</a> &nbsp; <a href="https://www.youtube.com/watch?v=sjzZh6-h9fM" target="_blank">Jimi Hendrix,</a> &nbsp; and other stars started to put their spin on the <span data-id="standard" data-phrase="0">standard melody</span>.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->It’s this spin we’re interested in, and to measure it we’ve created the <strong>Diva Score</strong> (nerdy details in the <a href="#methods">methods</a>). It quantifies how much a performance melodically deviates from the standard. For this first phrase, most performers keep it pretty simple like <span data-id="amber-riley_mlb-allstar-game_2010" data-phrase="0">Amber Riley</span> from 2010.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Using the <strong>Diva Score</strong>, we can go phrase by phrase and pick out the performers who were doing the most and those that made you say they “<a href="https://www.youtube.com/watch?v=rNM5HW13_O8%E2%80%8B%E2%80%8B" target="_blank">ain’t no diva</a>.” Click on the faces of the certified top divas (plus our picks) to hear their interpretation of each phrase.<!-- HTML_TAG_END --></p></div>  <h2><span>o</span><span>say</span><span>can</span><span>you</span><span>see</span></h2></div></div> <div id="slide-1" role="group" aria-label="slide 2 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>    </div> <div><p><!-- HTML_TAG_START -->Most performers don’t really get going until the last half of the song so these first few phrases are comparatively tame. But <span data-id="anthony-hamilton_nba-allstar-game_2019" data-phrase="1">Anthony Hamilton</span> — he’s basically singing a different melody at the 2019 NBA All-Star Game.<!-- HTML_TAG_END --></p>  <h2><span>by</span><span>the</span><span>dawn’s</span><span>early</span><span>light</span></h2></div></div> <div id="slide-2" role="group" aria-label="slide 3 of undefined" aria-current="false"><p><!-- HTML_TAG_START -->Here, the phrases are ordered by average <strong>Diva Score</strong> instead of the order they are sung. The vocal fireworks start to explode around the “bombs are bursting in air.”<!-- HTML_TAG_END --></p> <div><h3>Average Diva Score by Phrase</h3> </div></div> <div id="slide-3" role="group" aria-label="slide 4 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>    <h3 data-svelte-h="svelte-1qeu3uy">Our picks</h3> </div> <div><p><!-- HTML_TAG_START -->Let’s see how <span data-id="fergie_nba-allstar-game_2018" data-phrase="2">Fergie</span> is doing. Her 2018 NBA All-Star Game performance is surprisingly tame <strong>Diva Score</strong>-wise. Sadly, the <strong>Diva Score</strong> can’t capture when someone manages to pronounce every single word in the weirdest, most sultry way possible.<!-- HTML_TAG_END --></p>  <h2><span>what</span><span>so</span><span>proudly</span><span>we</span><span>hailed</span></h2></div></div> <div id="slide-4" role="group" aria-label="slide 5 of undefined" aria-current="false"><p><!-- HTML_TAG_START -->The NBA All-Star Game has been host to a lot of memorable national anthem performances — from Marvin Gaye to Fergie. Overall, basketball games yielded higher <strong>Diva Scores</strong> than other sporting events and political events.<!-- HTML_TAG_END --></p> <div><h3>Average Diva Score by Event Type</h3> </div></div> <div id="slide-5" role="group" aria-label="slide 6 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>    <h3 data-svelte-h="svelte-1qeu3uy">Our picks</h3>  </div> <div><div><p><!-- HTML_TAG_START -->By looking at the pitch line, you can pick out artists’ signature shapes, like scooping into notes. This is a common technique for country stars like <span data-id="chris-stapleton_super-bowl_2023" data-phrase="3">Chris Stapleton</span> and <span data-id="scotty-mccreery_world-series_2011" data-phrase="3">Scotty McCreery</span>.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Speaking of “country” stars, our dataset has two <span data-id="taylor-swift_nfl-regular-season_2006" data-phrase="3">Taylor Swift</span> performances — both (2006 and 2008) well before her pop shift. Back then she was just a kid with a guitar, so it’s understandable that she records some of the overall lowest <strong>Diva Scores</strong> (#114 and #129).<!-- HTML_TAG_END --></p></div>  <h2><span>at</span><span>the</span><span>twilight’s</span><span>last</span><span>gleaming</span></h2></div></div> <div id="slide-6" role="group" aria-label="slide 7 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>    <h3 data-svelte-h="svelte-1qeu3uy">Our picks</h3>  </div> <div><p><!-- HTML_TAG_START -->Two words: <span data-id="aretha-franklin_world-series_1993" data-phrase="4"> Aretha Franklin</span>. The “Queen of Soul” shows out on this phrase, and she’s in good company: 8 of the top 10 <strong>Diva Scores</strong> for this phrase are from fellow R&amp;B artists.<!-- HTML_TAG_END --></p>  <h2><span>whose</span><span>broad</span><span>stripes</span><span>and</span><span>bright</span><span>stars</span></h2></div></div> <div id="slide-7" role="group" aria-label="slide 8 of undefined" aria-current="false"><p><!-- HTML_TAG_START -->Average <strong>Diva Scores</strong> by music genre match intuition, with R&amp;B and pop divas adding more flourishes than country or rock divas.<!-- HTML_TAG_END --></p> <div><h3>Average Diva Score by Music Genre</h3> </div></div> <div id="slide-8" role="group" aria-label="slide 9 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>    <h3 data-svelte-h="svelte-1qeu3uy">Our picks</h3> </div> <div><p><!-- HTML_TAG_START -->The <strong>Diva Score</strong> measures chaos, but it can’t tell if that chaos sounds good or bad. Case in point: <span data-id="jazmine-sullivan_world-series_2022" data-phrase="5">Jazmine Sullivan</span> rarely has a top 3 <strong>Diva Score</strong> (although she ranks as the #17 overall diva), but we think she consistently sings some of the most beautiful and creative vocal runs.<!-- HTML_TAG_END --></p>  <h2><span>through</span><span>the</span><span>perilous</span><span>fight</span></h2></div></div> <div id="slide-9" role="group" aria-label="slide 10 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>    <h3 data-svelte-h="svelte-1qeu3uy">Our picks</h3>  </div> <div><p><!-- HTML_TAG_START -->This phrase is a common trip up for performers like <span data-id="christina-aguilera_super-bowl_2011" data-phrase="6">Christina Aguilera</span> and <span data-id="eric-burton_world-series_2022" data-phrase="6"> Eric Burton</span>, who both double back over previously sung phrases. After her gaffe, <a href="https://www.rollingstone.com/music/music-news/christina-aguilera-explains-national-anthem-flub-245023/" target="_blank">Aguilera said</a> she hoped the “true spirit of [the] anthem still came through.” It did, X-Tina.<!-- HTML_TAG_END --></p>  <h2><span>o’er</span><span>the</span><span>ramparts</span><span>we</span><span>watched</span></h2></div></div> <div id="slide-10" role="group" aria-label="slide 11 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>    </div> <div><p><!-- HTML_TAG_START -->Good anthem performances are rarely a given, but artists like Whitney, Beyoncé, and <span data-id="tpain_mlb-regular-season-game_2015" data-phrase="7">T-Pain</span> make it look easy. Yes, you read that right, Mr. Autotune delivered a sterling rendition. This phrase was one of his top <strong>Diva Scores</strong>.<!-- HTML_TAG_END --></p>  <h2><span>were</span><span>so</span><span>gallantly</span><span>streaming</span></h2></div></div> <div id="slide-11" role="group" aria-label="slide 12 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>   <h3 data-svelte-h="svelte-1qeu3uy">Our picks</h3>   </div> <div><p><!-- HTML_TAG_START -->The “Star Spangled Banner” is treacherous to sing — start off too high and <a href="https://www.youtube.com/watch?v=cdl8p9akJJw" target="_blank">“you’re screwed.”</a> <span data-id="trace-adkins_rnc_2020" data-phrase="8">Trace Adkins</span> sings in the lowest key among our dataset (D); <span data-id="jennifer-hudson_super-bowl_2009" data-phrase="8">Jennifer Hudson</span> (and others) are in the highest (A); and <span data-id="steven-tyler_indy-500_2001" data-phrase="8">Steven Tyler</span> sings just a step below that in G, by far the highest of any other man in our dataset.<!-- HTML_TAG_END --></p>  <h2><span>and</span><span>the</span><span>rocket’s</span><span>red</span><span>glare</span></h2></div></div> <div id="slide-12" role="group" aria-label="slide 13 of undefined" aria-current="false"><p><!-- HTML_TAG_START -->F# (F sharp) is the most common key for women. It’s Bb (B flat) for men.<!-- HTML_TAG_END --></p> <div><h3>Distribution of Musical Keys</h3> </div></div> <div id="slide-13" role="group" aria-label="slide 14 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>  <h3 data-svelte-h="svelte-1qeu3uy">Our picks</h3>  </div> <div><div><p><!-- HTML_TAG_START -->If you’ve been with us since the beginning, you’ll notice that <span data-id="chaka-khan_nba-allstar-game_2020" data-phrase="9">Chaka Khan</span> has racked up 5 top diva appearances in these first 9 phrases. She has the highest average <strong>Diva Score</strong> per phrase, making her our #1 Diva.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->For slightly more mellow, but still noteworthy performances, check out <span data-id="her_world-series_2023" data-phrase="9">H.E.R.</span> at the 2023 World Series and <span data-id="taylor-swift_world-series_2008" data-phrase="9">Taylor Swift</span> at the 2008 World Series, T-Swift's highest recorded <strong>Diva Score</strong> for a phrase.<!-- HTML_TAG_END --></p></div>  <h2><span>the</span><span>bombs</span><span>bursting</span><span>in</span><span>air</span></h2></div></div> <div id="slide-14" role="group" aria-label="slide 15 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>    <h3 data-svelte-h="svelte-1qeu3uy">Our picks</h3> </div> <div><div><p><!-- HTML_TAG_START -->Some singers are National Anthem pros with 3 or more performances in our dataset. Carrie Underwood performed in <span data-id="carrie-underwood_super-bowl_2010" data-phrase="10">2010</span>, <span data-id="carrie-underwood_world-series_2007" data-phrase="10">2007</span>, <span data-id="carrie-underwood_mlb-allstar-game_2006" data-phrase="10">2006</span>, and <span data-id="carrie-underwood_stanley-cup-playoffs_2017" data-phrase="10">2017</span>, with all her renditions sounding nearly identical.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Meanwhile, Demi Lovato switches it up. They use unique vocal runs for each of their performances from <span data-id="demi-lovato_world-series_2012" data-phrase="10">2012</span>, <span data-id="demi-lovato_world-series_2015" data-phrase="10">2015</span>, and <span data-id="demi-lovato_super-bowl_2020" data-phrase="10">2020</span>.<!-- HTML_TAG_END --></p></div>  <h2><span>gave</span><span>proof</span><span>through</span><span>the</span><span>night</span></h2></div></div> <div id="slide-15" role="group" aria-label="slide 16 of undefined" aria-current="false"><p><!-- HTML_TAG_START -->There are 7 performers in our dataset who have performed the National Anthem 3 or more times. This is their intra-<strong>Diva Score</strong>, or how they compare to themselves.<!-- HTML_TAG_END --></p> <div><h3>How Similar Repeat Performers are to Themselves</h3> <div data-svelte-h="svelte-16elgr5"><p>◀ More similar</p> <p>More different ▶</p></div>  </div></div> <div id="slide-16" role="group" aria-label="slide 17 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>    <h3 data-svelte-h="svelte-1qeu3uy">Our picks</h3> </div> <div><p><!-- HTML_TAG_START -->Two inauguration performances, where “flag” is emphasized, rise to the top for this phrase:  <span data-id="beyonce_inauguration_2013" data-phrase="11">Beyoncé (2013)</span> and <span data-id="lady-gaga_inauguration_2021" data-phrase="11">Lady Gaga (2021)</span>. We’ve seen a big evolution since <span data-id="juanita-booker_inauguration_1981" data-phrase="11">Juanita Booker’s</span> more traditional 1981 take.<!-- HTML_TAG_END --></p>  <h2><span>that</span><span>our</span><span>flag</span><span>was</span><span>still</span><span>there</span></h2></div></div> <div id="slide-17" role="group" aria-label="slide 18 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>    </div> <div><p><!-- HTML_TAG_START --><span data-id="fergie_nba-allstar-game_2018" data-phrase="12">Fergie</span>, what are you doing, girl?<!-- HTML_TAG_END --></p>  <h2><span>o</span><span>say</span><span>does</span><span>that</span><span>star</span><span>spangled</span></h2></div></div> <div id="slide-18" role="group" aria-label="slide 19 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>    <h3 data-svelte-h="svelte-1qeu3uy">Our picks</h3>  </div> <div><div><p><!-- HTML_TAG_START -->Towards the end of the anthem, you’re not making the top diva list unless you have a well-deserved royalty nickname: “The Queen of Funk” <span data-id="chaka-khan_nba-allstar-game_2020" data-phrase="13">Chaka Khan</span>, “Queen of Hip-Hop Soul” <span data-id="mary-j-blige_world-series_2009" data-phrase="13">Mary J. Blige</span>, and the “Godmother of Soul” <span data-id="patti-labelle_world-series_2008" data-phrase="13">Patti Labelle</span>.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Mary J. Blige, in particular, holds down two of the top 10 <strong>Diva Score</strong> spots for this phrase: her performances at the <span data-id="mary-j-blige_world-series_2009" data-phrase="13">2009 World Series</span> and <span data-id="mary-j-blige_nba-allstar-game_2012" data-phrase="13">2012 NBA All-Star Game</span>.<!-- HTML_TAG_END --></p></div>  <h2><span>banner</span><span>yet</span><span>wave</span></h2></div></div> <div id="slide-19" role="group" aria-label="slide 20 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>    <h3 data-svelte-h="svelte-1qeu3uy">Our picks</h3>  </div> <div><div><p><!-- HTML_TAG_START -->Remember, the Diva Score measures how different a performance is from the standard, so artists like <span data-id="nicole-scherzinger_world-series_2019" data-phrase="14">Nicole Scherzinger</span> and <span data-id="steven-tyler_indy-500_2001" data-phrase="14">Steven Tyler</span> who go up the octave and hit (well, sometimes hit) the high notes on “free” get bonus points.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Here, you can also see the really tight vibrato waves from classical- and Broadway-trained singers like <span data-id="renee-fleming_super-bowl_2014" data-phrase="14">Renee Fleming</span> and <span data-id="kristen-chenoweth_wnba-allstar-game_2019" data-phrase="14">Kristen Chenoweth</span>.<!-- HTML_TAG_END --></p></div>  <h2><span>o’er</span><span>the</span><span>land</span><span>of</span><span>the</span><span>free</span></h2></div></div> <div id="slide-20" role="group" aria-label="slide 21 of undefined" aria-current="false"><div><h3 data-svelte-h="svelte-1lb4w3q">Top divas</h3>           </div> <div><p><!-- HTML_TAG_START -->The true divas shine for the anthem’s closing phrase. Here are the top 10 <strong>Diva Scores</strong>. It’s pure chaos in the best way possible.<!-- HTML_TAG_END --></p>  <h2><span>and</span><span>the</span><span>home</span><span>of</span><span>the</span><span>brave</span></h2></div></div></div>     </section> <div id="transition-to-heatmap"><p><!-- HTML_TAG_START -->Now that you know what to look and listen for in the “Star Spangled Banner,” it’s time to dive even further into the data. The heatmap below allows you to explore each of the 16 phrases for all 138 performances in our dataset. Surprisingly we didn’t get tired of listened to the anthem when doing this project, so maybe you won’t either!<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->If you want to hear more about our favorites, check us out on the <a href="https://switchedonpop.com/episodes/national-anthem-pudding-star-spangled-banner" target="_blank">Switched on Pop podcast</a>.<!-- HTML_TAG_END --></p></div> <section id="heatmap"><div><div><div><h3 data-svelte-h="svelte-pr4on5">Sort by</h3> </div> <div><h3 data-svelte-h="svelte-17b5uwr">Filter by</h3> </div> </div>  <div><p>o say can you see </p><p>by the dawn’s early light </p><p>what so proudly we hailed </p><p>at the twilight’s last gleaming </p><p>whose broad stripes and bright stars </p><p>through the perilous fight </p><p>o’er the ramparts we watched </p><p>were so gallantly streaming </p><p>and the rocket’s red glare </p><p>the bombs bursting in air </p><p>gave proof through the night </p><p>that our flag was still there </p><p>o say does that star spangled </p><p>banner yet wave </p><p>o’er the land of the free </p><p>and the home of the brave </p></div></div> <div><div><div><p>Aaliyah</p> <p>1995 NBA Regular Season</p></div> <p><strong>#69</strong> Diva / Key: E</p></div><div><div><p>Aaron Lewis</p> <p>2014 World Series</p></div> <p><strong>#79</strong> Diva / Key: A</p></div><div><div><p>Al Green</p> <p>2000 NBA All-Star</p></div> <p><strong>#125</strong> Diva / Key: C#</p></div><div><div><p>Alanis Morissette</p> <p>2007 Stanley Cup</p></div> <p><strong>#133</strong> Diva / Key: Eb</p></div><div><div><p>Alicia Keys</p> <p>2013 Super Bowl</p></div> <p><strong>#35</strong> Diva / Key: G</p></div><div><div><p>Aloe Blacc</p> <p>2016 NBA Finals</p></div> <p><strong>#109</strong> Diva / Key: C</p></div><div><div><p>Amber Riley</p> <p>2010 MLB All-Star</p></div> <p><strong>#61</strong> Diva / Key: F#</p></div><div><div><p>Anita Baker</p> <p>2023 NFL Regular Season</p></div> <p><strong>#60</strong> Diva / Key: Ab</p></div><div><div><p>Anthony Hamilton</p> <p>2019 NBA All-Star</p></div> <p><strong>#3</strong> Diva / Key: F</p></div><div><div><p>Aretha Franklin</p> <p>1993 World Series</p></div> <p><strong>#10</strong> Diva / Key: F#</p></div><div><div><p>Ariana Grande</p> <p>2014 NFL Regular Season</p></div> <p><strong>#87</strong> Diva / Key: Ab</p></div><div><div><p>Beyoncé</p> <p>2013 Inauguration</p></div> <p><strong>#8</strong> Diva / Key: E</p></div><div><div><p>Billy Joel</p> <p>1979 Stanley Cup</p></div> <p><strong>#136</strong> Diva / Key: C</p></div><div><div><p>Billy Joel</p> <p>1989 Super Bowl</p></div> <p><strong>#82</strong> Diva / Key: C</p></div><div><div><p>Billy Joel</p> <p>2007 Super Bowl</p></div> <p><strong>#128</strong> Diva / Key: Bb</p></div><div><div><p>Billy Joel</p> <p>2000 World Series</p></div> <p><strong>#122</strong> Diva / Key: A</p></div><div><div><p>Brad Paisley</p> <p>2017 World Series</p></div> <p><strong>#110</strong> Diva / Key: B</p></div><div><div><p>Brian McKnight</p> <p>2005 MLB All-Star</p></div> <p><strong>#83</strong> Diva / Key: Eb</p></div><div><div><p>Brooke Hogan</p> <p>2004 Stanley Cup</p></div> <p><strong>#88</strong> Diva / Key: E</p></div><div><div><p>Carly Pearce</p> <p>2021 World Series</p></div> <p><strong>#113</strong> Diva / Key: Eb</p></div><div><div><p>Carrie Underwood</p> <p>2006 MLB All-Star</p></div> <p><strong>#127</strong> Diva / Key: F#</p></div><div><div><p>Carrie Underwood</p> <p>2017 Stanley Cup</p></div> <p><strong>#111</strong> Diva / Key: F#</p></div><div><div><p>Carrie Underwood</p> <p>2010 Super Bowl</p></div> <p><strong>#105</strong> Diva / Key: F#</p></div><div><div><p>Carrie Underwood</p> <p>2007 World Series</p></div> <p><strong>#119</strong> Diva / Key: F#</p></div><div><div><p>Cassadee Pope</p> <p>2023 Stanley Cup</p></div> <p><strong>#66</strong> Diva / Key: F#</p></div><div><div><p>Chaka Khan</p> <p>2020 NBA All-Star</p></div> <p><strong>#1</strong> Diva / Key: F</p></div><div><div><p>Cheryl Ladd</p> <p>1980 Super Bowl</p></div> <p><strong>#129</strong> Diva / Key: E</p></div><div><div><p>Chloe Bailey</p> <p>2022 World Series</p></div> <p><strong>#6</strong> Diva / Key: E</p></div><div><div><p>Chris Daughtry</p> <p>2011 World Series</p></div> <p><strong>#84</strong> Diva / Key: D</p></div><div><div><p>Chris Stapleton</p> <p>2023 Super Bowl</p></div> <p><strong>#21</strong> Diva / Key: C#</p></div><div><div><p>Christina Aguilera</p> <p>2004 NBA All-Star</p></div> <p><strong>#31</strong> Diva / Key: F</p></div><div><div><p>Christina Aguilera</p> <p>2011 Super Bowl</p></div> <p><strong>#19</strong> Diva / Key: F</p></div><div><div><p>Cody Johnson</p> <p>2019 World Series</p></div> <p><strong>#98</strong> Diva / Key: A</p></div><div><div><p>Colbie Caillat</p> <p>2013 World Series</p></div> <p><strong>#44</strong> Diva / Key: E</p></div><div><div><p>Darius Rucker</p> <p>1995 World Series</p></div> <p><strong>#100</strong> Diva / Key: Bb</p></div><div><div><p>Demi Lovato</p> <p>2020 Super Bowl</p></div> <p><strong>#97</strong> Diva / Key: Ab</p></div><div><div><p>Demi Lovato</p> <p>2012 World Series</p></div> <p><strong>#23</strong> Diva / Key: Ab</p></div><div><div><p>Demi Lovato</p> <p>2015 World Series</p></div> <p><strong>#78</strong> Diva / Key: Ab</p></div><div><div><p>Diana Ross</p> <p>1982 Super Bowl</p></div> <p><strong>#93</strong> Diva / Key: G</p></div><div><div><p>Dierks Bentley</p> <p>2017 Stanley Cup</p></div> <p><strong>#63</strong> Diva / Key: F</p></div><div><div><p>Donna Summer</p> <p>1999 MLB All-Star</p></div> <p><strong>#123</strong> Diva / Key: Eb</p></div><div><div><p>Eric Burton</p> <p>2022 World Series</p></div> <p><strong>#26</strong> Diva / Key: B</p></div><div><div><p>Faith Hill</p> <p>2000 Super Bowl</p></div> <p><strong>#72</strong> Diva / Key: G</p></div><div><div><p>Fantasia</p> <p>2023 NCAA Championship</p></div> <p><strong>#20</strong> Diva / Key: F#</p></div><div><div><p>Gladys Knight</p> <p>2019 Super Bowl</p></div> <p><strong>#15</strong> Diva / Key: D</p></div><div><div><p>Gladys Knight</p> <p>1991 World Series</p></div> <p><strong>#58</strong> Diva / Key: Eb</p></div><div><div><p>Gretchen Wilson</p> <p>2010 NBA All-Star</p></div> <p><strong>#134</strong> Diva / Key: E</p></div><div><div><p>Harry Connick Jr.</p> <p>1992 Super Bowl</p></div> <p><strong>#99</strong> Diva / Key: Ab</p></div><div><div><p>Hunter Hayes</p> <p>2016 World Series</p></div> <p><strong>#74</strong> Diva / Key: Bb</p></div><div><div><p>Idina Menzel</p> <p>2014 MLB All-Star</p></div> <p><strong>#103</strong> Diva / Key: F#</p></div><div><div><p>Idina Menzel</p> <p>2015 Super Bowl</p></div> <p><strong>#68</strong> Diva / Key: F</p></div><div><div><p>Jackie Evancho</p> <p>2017 Inauguration</p></div> <p><strong>#101</strong> Diva / Key: Ab</p></div><div><div><p>James Taylor</p> <p>2018 World Series</p></div> <p><strong>#131</strong> Diva / Key: Ab</p></div><div><div><p>Jazmine Sullivan</p> <p>2022 World Series</p></div> <p><strong>#17</strong> Diva / Key: F</p></div><div><div><p>Jennifer Hudson</p> <p>2009 Super Bowl</p></div> <p><strong>#12</strong> Diva / Key: A</p></div><div><div><p>Jessica Simpson</p> <p>2004 Indy 500</p></div> <p><strong>#64</strong> Diva / Key: F</p></div><div><div><p>Jessica Simpson</p> <p>2001 NBA All-Star</p></div> <p><strong>#118</strong> Diva / Key: F#</p></div><div><div><p>Jimmy Buffett</p> <p>1984 MLB Regular Season</p></div> <p><strong>#137</strong> Diva / Key: Bb</p></div><div><div><p>Joe Walsh</p> <p>1995 World Series</p></div> <p><strong>#124</strong> Diva / Key: Bb</p></div><div><div><p>John Legend</p> <p>2013 NBA All-Star</p></div> <p><strong>#45</strong> Diva / Key: Bb</p></div><div><div><p>John Legend</p> <p>2016 NBA Finals</p></div> <p><strong>#24</strong> Diva / Key: Bb</p></div><div><div><p>John Oates</p> <p>2008 World Series</p></div> <p><strong>#67</strong> Diva / Key: C#</p></div><div><div><p>John Vincent</p> <p>2016 World Series</p></div> <p><strong>#92</strong> Diva / Key: B</p></div><div><div><p>Jon Secada</p> <p>1992 World Series</p></div> <p><strong>#112</strong> Diva / Key: B</p></div><div><div><p>Jordan Smith</p> <p>2023 NFL Regular Season</p></div> <p><strong>#40</strong> Diva / Key: Eb</p></div><div><div><p>Jordin Sparks</p> <p>2011 MLB All-Star</p></div> <p><strong>#34</strong> Diva / Key: E</p></div><div><div><p>Jordin Sparks</p> <p>2017 NBA Finals</p></div> <p><strong>#42</strong> Diva / Key: Eb</p></div><div><div><p>Jordin Sparks</p> <p>2008 Super Bowl</p></div> <p><strong>#13</strong> Diva / Key: F</p></div><div><div><p>Jordin Sparks</p> <p>2023 World Series</p></div> <p><strong>#27</strong> Diva / Key: Eb</p></div><div><div><p>Josh Groban</p> <p>2011 NBA All-Star</p></div> <p><strong>#108</strong> Diva / Key: Bb</p></div><div><div><p>Joyce Didonato</p> <p>2014 World Series</p></div> <p><strong>#65</strong> Diva / Key: Ab</p></div><div><div><p>Juanita Booker</p> <p>1981 Inauguration</p></div> <p><strong>#49</strong> Diva / Key: Bb</p></div><div><div><p>Keith Urban</p> <p>2017 Stanley Cup</p></div> <p><strong>#121</strong> Diva / Key: C</p></div><div><div><p>Kelly Clarkson</p> <p>2018 Indy 500</p></div> <p><strong>#95</strong> Diva / Key: G</p></div><div><div><p>Kelly Clarkson</p> <p>2019 Indy 500</p></div> <p><strong>#120</strong> Diva / Key: G</p></div><div><div><p>Kelly Clarkson</p> <p>2010 World Series</p></div> <p><strong>#80</strong> Diva / Key: F#</p></div><div><div><p>Kelsey Grammer</p> <p>1996 MLB Regular Season</p></div> <p><strong>#116</strong> Diva / Key: F</p></div><div><div><p>Kiana Lede</p> <p>2023 MLB All-Star</p></div> <p><strong>#73</strong> Diva / Key: E</p></div><div><div><p>Kristen Chenoweth</p> <p>2019 WNBA All-Star</p></div> <p><strong>#77</strong> Diva / Key: G</p></div><div><div><p>Lady Gaga</p> <p>2021 Inauguration</p></div> <p><strong>#33</strong> Diva / Key: F#</p></div><div><div><p>Lady Gaga</p> <p>2016 Super Bowl</p></div> <p><strong>#38</strong> Diva / Key: F#</p></div><div><div><p>Lauren Alaina</p> <p>2021 World Series</p></div> <p><strong>#46</strong> Diva / Key: E</p></div><div><div><p>Lauren Daigle</p> <p>2020 NCAA Championship</p></div> <p><strong>#29</strong> Diva / Key: Eb</p></div><div><div><p>LeAnn Rimes</p> <p>1997 World Series</p></div> <p><strong>#96</strong> Diva / Key: F</p></div><div><div><p>Luke Bryan</p> <p>2017 Stanley Cup</p></div> <p><strong>#76</strong> Diva / Key: Bb</p></div><div><div><p>Luke Bryan</p> <p>2017 Super Bowl</p></div> <p><strong>#48</strong> Diva / Key: A</p></div><div><div><p>Luther Vandross</p> <p>1997 Super Bowl</p></div> <p><strong>#106</strong> Diva / Key: D</p></div><div><div><p>Madison Beer</p> <p>2020 Stanley Cup</p></div> <p><strong>#37</strong> Diva / Key: Ab</p></div><div><div><p>Madison Watkins</p> <p>2022 World Series</p></div> <p><strong>#18</strong> Diva / Key: E</p></div><div><div><p>Mariah Carey</p> <p>2002 Super Bowl</p></div> <p><strong>#30</strong> Diva / Key: E</p></div><div><div><p>Martina Mcbride</p> <p>2004 World Series</p></div> <p><strong>#85</strong> Diva / Key: F#</p></div><div><div><p>Marvin Gaye</p> <p>1983 NBA All-Star</p></div> <p><strong>#9</strong> Diva / Key: C</p></div><div><div><p>Mary J. Blige</p> <p>2012 NBA All-Star</p></div> <p><strong>#43</strong> Diva / Key: F#</p></div><div><div><p>Mary J. Blige</p> <p>2009 World Series</p></div> <p><strong>#32</strong> Diva / Key: F#</p></div><div><div><p>Mary J. Blige</p> <p>2013 World Series</p></div> <p><strong>#56</strong> Diva / Key: F</p></div><div><div><p>Matthew Morrison</p> <p>2012 World Series</p></div> <p><strong>#126</strong> Diva / Key: Bb</p></div><div><div><p>Melissa Etheridge</p> <p>2002 World Series</p></div> <p><strong>#90</strong> Diva / Key: D</p></div><div><div><p>Mickey Guyton</p> <p>2022 Super Bowl</p></div> <p><strong>#25</strong> Diva / Key: G</p></div><div><div><p>Mickey Guyton</p> <p>2023 World Series</p></div> <p><strong>#86</strong> Diva / Key: G</p></div><div><div><p>Natalie Grant</p> <p>2022 NCAA Championship</p></div> <p><strong>#22</strong> Diva / Key: Ab</p></div><div><div><p>Nayah Damasen</p> <p>2018 NBA Finals</p></div> <p><strong>#50</strong> Diva / Key: F#</p></div><div><div><p>Ne-Yo</p> <p>2020 NBA Regular Season</p></div> <p><strong>#104</strong> Diva / Key: D</p></div><div><div><p>Nicole Scherzinger</p> <p>2019 World Series</p></div> <p><strong>#5</strong> Diva / Key: F#</p></div><div><div><p>Patrick Stump</p> <p>2016 World Series</p></div> <p><strong>#117</strong> Diva / Key: C</p></div><div><div><p>Patti Labelle</p> <p>2008 World Series</p></div> <p><strong>#2</strong> Diva / Key: A</p></div><div><div><p>Paul Simon</p> <p>1986 World Series</p></div> <p><strong>#94</strong> Diva / Key: A</p></div><div><div><p>Peabo Bryson</p> <p>1992 World Series</p></div> <p><strong>#16</strong> Diva / Key: D</p></div><div><div><p>Phillip Phillips</p> <p>2012 World Series</p></div> <p><strong>#135</strong> Diva / Key: Ab</p></div><div><div><p>Pia Toscano</p> <p>2022 Memorial Day Concert</p></div> <p><strong>#52</strong> Diva / Key: F#</p></div><div><div><p>Rachel Platten</p> <p>2016 World Series</p></div> <p><strong>#70</strong> Diva / Key: F</p></div><div><div><p>Reba McEntire</p> <p>2024 Super Bowl</p></div> <p><strong>#47</strong> Diva / Key: D</p></div><div><div><p>Renée Fleming</p> <p>2014 Super Bowl</p></div> <p><strong>#4</strong> Diva / Key: A</p></div><div><div><p>Scotty Mccreery</p> <p>2011 World Series</p></div> <p><strong>#59</strong> Diva / Key: Ab</p></div><div><div><p>Sheryl Crow</p> <p>2018 Stanley Cup</p></div> <p><strong>#89</strong> Diva / Key: F#</p></div><div><div><p>Stephanie Mills</p> <p>2003 WNBA All-Star</p></div> <p><strong>#71</strong> Diva / Key: G</p></div><div><div><p>Steven Tyler</p> <p>2001 Indy 500</p></div> <p><strong>#55</strong> Diva / Key: G</p></div><div><div><p>Taylor Swift</p> <p>2006 NFL Regular Season</p></div> <p><strong>#130</strong> Diva / Key: E</p></div><div><div><p>Taylor Swift</p> <p>2008 World Series</p></div> <p><strong>#115</strong> Diva / Key: E</p></div><div><div><p>T-Pain</p> <p>2015 MLB Regular Season</p></div> <p><strong>#7</strong> Diva / Key: Eb</p></div><div><div><p>Trisha Yearwood</p> <p>2014 World Series</p></div> <p><strong>#132</strong> Diva / Key: Eb</p></div><div><div><p>Whitney Houston</p> <p>1991 Super Bowl</p></div> <p><strong>#39</strong> Diva / Key: Ab</p></div><div><div><p>Whitney Houston</p> <p>1999 WNBA All-Star</p></div> <p><strong>#41</strong> Diva / Key: F</p></div><div><div><p>Zooey Deschanel</p> <p>2011 World Series</p></div> <p><strong>#107</strong> Diva / Key: Eb</p></div></div> </section> <section id="methods"><h2 data-svelte-h="svelte-27oo3k">Methods</h2> <p><!-- HTML_TAG_START -->To build a catalog of celebrity National Anthem performances, we consulted <a href="https://www.avclub.com/best-national-anthem-performances-ranked-1850596161" target="_blank">several</a> <a href="https://www.billboard.com/lists/best-super-bowl-national-anthem-performances/" target="_blank">best-of</a> <a href="https://americansongwriter.com/the-12-best-national-anthem-performances-since-jimi-hendrix-at-woodstock/" target="_blank">lists</a>, and collected performances from major sporting and political events like the Super Bowl, the World Series, and the presidential inauguration from 1980 on. We also included a few notable anthem performances prior to 1980.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->We then set out to find a suitable audio/video recording of the performance on YouTube. We were able to find roughly 180 performances. Using a <a href="https://ytmp3.nu/CNtD/" target="_blank">free online converter</a>, we extracted mp3 audio files from each YouTube link. We then manually trimmed the mp3 audio files so that they started right before the first word in the anthem and ended after the last. The trimmed audio was then uploaded to an AI-powered <a href="https://vocalremover.org/" target="_blank">Vocal Remover</a> program to isolate the vocals from the rest of the audio.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Once we had the isolated vocal files, we loaded them into <a href="https://www.sonicvisualiser.org/tony/" target="_blank">Tony</a>, an open source melody transcription tool developed by the Centre for Digital Music at Queen Mary, University of London. Along with 4 additional data assistants (Amel Awadelkarim, Dustin D’Andrea, Noah Fagan, and George McIntire), we listened to each vocal track, manually removed errant sounds (crowd noise, echos, jet flyovers, band accompaniments) and corrected pitch when necessary. Some performances were dropped at this stage due to poor audio quality.<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->We then exported the pitch data, which tracked frequency in Hz over time. We manually marked the starting and ending timestamps of each of the 16 phrases of the song. Some specific phrases for specific performances were also dropped at this stage due to poor audio quality. This process took over 100 hours of work and we couldn’t have done it without our data assistants, so thank you!<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->For each phrase, we used <a href="https://en.wikipedia.org/wiki/Dynamic_time_warping" target="_blank">Dynamic Time Warping</a> (DTW) to compare it to the corresponding phrase in a <a href="https://upload.wikimedia.org/wikipedia/commons/transcoded/e/ec/2_Star_Spangled_Banner.mid/2_Star_Spangled_Banner.mid.mp3" target="_blank">“standard”</a> performance of the National Anthem. DTW measures the similarity between two temporal sequences, neutralizing any variation in speed. In other words, it measures the amount a performer deviates from the standard, strictly melodically. This is what we called the <strong>Diva Score</strong> for each phrase. The <strong>Diva Score</strong> for a full performance was calculated by taking the average for all phrases from that performance. It’s not an exact science, but we think the <strong>Diva Scores</strong> match our intuition of what melodic Diva-ness is pretty closely!<!-- HTML_TAG_END --></p><p><!-- HTML_TAG_START -->Finally, thank you to our colleague <a href="https://pudding.cool/author/kevin-litman-navarro/" target="_blank">Kevin Litman-Narvarro</a> who originally planted the idea of looking into National Anthem performances.<!-- HTML_TAG_END --></p> </section> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Some OpenBSD features that aren't widely known (161 pts)]]></title>
            <link>https://dataswamp.org/~solene/2024-02-20-rarely-known-openbsd-features.html</link>
            <guid>39493046</guid>
            <pubDate>Sat, 24 Feb 2024 16:57:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dataswamp.org/~solene/2024-02-20-rarely-known-openbsd-features.html">https://dataswamp.org/~solene/2024-02-20-rarely-known-openbsd-features.html</a>, See on <a href="https://news.ycombinator.com/item?id=39493046">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<article id="20240220">
  <header>
  
    
    <p>Written by <em>Solène</em>, on 20 February 2024.<br>Tags: 
<span><a href="https://dataswamp.org/~solene/tag-openbsd.html">#openbsd</a></span>


<span><a href="https://dataswamp.org/~solene/tag-unix.html">#unix</a></span>

</p>
    
    
  </header>
  <h2 id="_Introduction">1. Introduction <a href="#_Introduction">§</a></h2>
<p>In this blog post, you will learn about some OpenBSD features that can be useful, but not widespread.
</p>
<p>They often have a niche usage, but it's important to know they exist to prevent you from reinventing the wheel :)
</p>
<p><a href="https://www.openbsd.org/">OpenBSD official project website</a></p>
<h2 id="_Features">2. Features <a href="#_Features">§</a></h2>
<p>The following list of features are not all OpenBSD specific as some can be found on other BSD systems.  Most of the knowledge will not be useful to Linux users.
</p>
<h2 id="_Secure_level">2.1. Secure level <a href="#_Secure_level">§</a></h2>
<p>The secure level is a sysctl named <code>kern.securelevel</code>, it has 4 different values from level -1 to level 2, and it's only possible to increase the level.  By default, the system enters the secure level 1 when in multi-user (the default when booting a regular installation).
</p>
<p>It's then possible to escalate to the last secure level (2), which will enable the following extra security:
</p>
<ul>

  <li>all raw disks are read-only, so it's not possible to try to make a change to the storage devices</li>
  <li>the time is almost lock, it's only possible to modify the clock slowly by small steps (maybe 1 second max every so often)</li>
  <li>the PF firewall rules can't be modified, flushed or altered</li>
</ul>

<p>This feature is mostly useful for dedicated firewall with rules that rarely change.  Preventing the time to change is really useful for remote logging as it allows being sure of "when" things happened, and you can be assured the past logs weren't modified.
</p>
<p>The default security level 1 already enable some extra security like "immutable" and "append-only" file flags can't be removed, these overlooked flags (that can be applied with chflags) can lock down files to prevent anyone from modifying them.  The append-only flag is really useful for logs because you can't modify the content, but this doesn't prevent adding new content, history can't be modified this way.
</p>
<p><a href="https://man.openbsd.org/securelevel">OpenBSD manual pages: securelevel</a></p>
<p><a href="https://man.openbsd.org/chflags">OpenBSD manual pages: chflags</a></p>
<p>This feature exists in other BSD systems.
</p>

<p>OpenBSD's memory allocator can be tweaked, system-wide or per command, to add extra checks.  This could be either used for security reasons or to look for memory allocation related bugs in a program (this is VERY common...).
</p>
<p>There are two methods to apply the changes:
</p>
<ul>

  <li>system-wide by using the sysctl <code>vm.malloc_conf</code>, either immediately with the sysctl command, or at boot in <code>/etc/sysctl.conf</code> (make sure you quote its value there, some characters such as <code>&gt;</code> will create troubles otherwise, been there...)</li>
  <li>on the command line by prepending <code>env MALLOC_OPTIONS="flags" program_to_run</code></li>
</ul>

<p>The man page gives a list of flags to use as option, the easiest to use is <code>S</code> (for security checks).  It is stated in the man page that a program misbehaving with any flag other than X is buggy, so it's not YOUR fault if you use malloc options and the program is crashing.
</p>
<p><a href="https://man.openbsd.org/malloc">OpenBSD manual pages: malloc (search for MALLOC OPTIONS)</a></p>
<h2 id="_File_flags">2.3. File flags <a href="#_File_flags">§</a></h2>
<p>You are certainly used to files attributes like permissions or ownership, but on many file systems (including OpenBSD ffs), there are flags as well!
</p>
<p>The file flags can be altered with the command <code>chflags</code>, there are a couple of flags available:
</p>
<ul>

  <li>nodump: prevent the files from being saved by the command <code>dump</code> (except if you use a flag in dump to bypass this)</li>
  <li>sappnd: the file can only be used in writing append mode, only root can set / remove this flag</li>
  <li>schg: the file can not be change, it becomes immutable, only root can alter this flag</li>
  <li>uappnd: same as sappnd mode but the user can alter the flag</li>
  <li>uchg: same as schg mode but the user can alter the flag</li>
</ul>

<p>As explained in the secure level section above, in the secure level 1 (default !), the flags sappnd and schg can't be removed, you would need to boot in single user mode to remove these flags.
</p>
<p>Tip: remove the flags on a file with <code>chflags 0 file [...]</code>
</p>
<p>You can check the flags on files using <code>ls -ol</code>, this would look like this:
</p>
<pre><code>terra$ chflags uchg get_extra_users.sh
terra$ ls -lo get_extra_users.sh        
-rwxr-xr-x  1 solene  solene  uchg 749 Apr  3  2023 get_extra_users.sh

terra$ chflags 0 get_extra_users.sh     
terra$ ls -lo get_extra_users.sh     
-rwxr-xr-x  1 solene  solene  - 749 Apr  3  2023 get_extra_users.sh
</code></pre>
<p><a href="https://man.openbsd.org/chflags">OpenBSD manual pages: chflags</a></p>

<p>OpenBSD crontab format received a few neat additions over the last years.
</p>
<ul>

  <li>random number for time field: you can use <code>~</code> in a field instead of a number or <code>*</code> to generate a random value that will remain stable until the crontab is reloaded.  Things like <code>~/5</code> work.  You can force the random value within a range with <code>20~40</code> to get values between 20 and 40.</li>
  <li>only send an email if the return code isn't 0 for the cron job: add <code>-n</code> between the time and the command, like in <code>0 * * * * -n /bin/something</code>.</li>
  <li>only run one instance of a job at a time: add <code>-s</code> between the time and the command, like in <code>* * * * * -s /bin/something</code>.  This is incredibly useful for cron job that shouldn't be running twice in parallel, if the job duration is longer than usual, you are ensured it will never start a new instance until the previous one is done.</li>
  <li>no logging: add <code>-q</code> between the time and the command, like in <code>* * * * -q /bin/something</code>, the effect will be that this cron job will not be logged in <code>/var/cron/log</code>.</li>
</ul>

<p>It's possible to use a combination of flags like <code>-ns</code>.  The random time is useful when you have multiple systems, and you don't want them to all run a command at the same time, like in a case they would trigger a huge I/O on a remote server.  This was created to prevent the usual <code>0 * * * * sleep $(( $RANDOM % 3600 )) &amp;&amp; something</code> that would run a sleep command for a random time up to an hour before running a command.
</p>
<p><a href="https://man.openbsd.org/crontab.5">OpenBSD manual pages: crontab</a></p>

<p>One cool feature on OpenBSD is the ability to easily create an installation media with pre-configured answers.  This is done by injecting a specific file in the <code>bsd.rd</code> install kernel.
</p>
<p>There is a simple tool named upobsd that was created by semarie@ to easily modify such bsd.rd file to include the autoinstall file, I forked the project to continue its maintenance.
</p>
<p>In addition to automatically installing OpenBSD with users, ssh configuration, sets to install etc...  it's also possible to add a site.tgz archive along with the usual sets archives that includes files you want to add to the system, this can include a script to run at first boot to trigger some automation!
</p>
<p>These features are a must-have if you run OpenBSD in production, and you have many of them to manage, enrolling a new device to the fleet should be automated as possible.
</p>
<p><a href="https://github.com/rapenne-s/upobsd">GitHub project page: upobsd</a></p>
<p><a href="https://man.openbsd.org/autoinstall">OpenBSD manual pages: autoinstall</a></p>
<h2 id="_apmd_daemon_hooks">2.6. apmd daemon hooks <a href="#_apmd_daemon_hooks">§</a></h2>
<p>Apmd is certainly running on most OpenBSD laptop and desktop around, but it has features that aren't related to its command line flags, so you may have missed them.
</p>
<p>There are different file names that can contain a script to be run upon some event such as suspend, resume, hibernate etc...
</p>
<p>A classic usage is to run <code>xlock</code> in one's X session on suspend, so the system will require a password on resume.
</p>
<p><a href="https://dataswamp.org/~solene/2021-07-30-openbsd-xidle-xlock.html#_Resume_/_Suspend_case">Older blog post: xlock from apmd suspend script</a></p>
<p>The man page explains all, but basically this works like this for running a backup program when you connect your laptop to the power plug:
</p>
<pre><code># mkdir -p /etc/apm
# vi /etc/apm/powerup
</code></pre>
<p>You need to write a regular script:
</p>
<pre><code>#!/bin/sh

/usr/local/bin/my_backup_script
</code></pre>
<p>Then, make it executable
</p>
<pre><code># chmod +x /etc/apm/powerup
</code></pre>
<p>The daemon apmd will automatically run this script when you connect a system back to AC power.
</p>
<p>The method is the same for:
</p>
<ul>

  <li>hibernate</li>
  <li>resume</li>
  <li>suspend</li>
  <li>standby</li>
  <li>hibernate</li>
  <li>powerup</li>
  <li>powerdown</li>
</ul>

<p>This makes it very easy to schedule tasks on such events.
</p>
<p><a href="https://man.openbsd.org/apmd#FILES">OpenBSD manual page: apmd (section FILES)</a></p>
<h2 id="_Using_hotplugd_for_hooks_on_devices_events">2.7. Using hotplugd for hooks on devices events <a href="#_Using_hotplugd_for_hooks_on_devices_events">§</a></h2>
<p>A bit similar to what apmd by running a script upon events, hotplugd is a service that allow running a script when a device is added / removed.
</p>
<p>A typical use is to automatically mount an USB memory stick when plugged in the system, or start cups daemon when powering on your USB printer.
</p>
<p>The script receives two parameters that represents the device class and device name, so you can use them in your script to know what was connected.  The example provided in the man page is a good starting point.
</p>
<p>The scripts aren't really straightforward to write, you need to make a precise list of hardware you expect and what to run for each, and don't forget to skip unknown hardware.  Don't forget to make the scripts executable, otherwise it won't work.
</p>
<p><a href="https://man.openbsd.org/hotplugd">OpenBSD manual page: hotplugd</a></p>
<h2 id="_Altroot">2.8. Altroot <a href="#_Altroot">§</a></h2>
<p>Finally, there is a feature that looks pretty cool. In the daily script, if an OpenBSD partition <code>/altroot/</code> exists in <code>/etc/fstab</code> and the daily script environment has a variable <code>ROOTBACKUP=1</code>, the root partition will be duplicated to it.  This permit keeping an extra root partition in sync with the main root partition.  Obviously, it's more useful if the altroot partition is on another drive.  The duplication is done with <code>dd</code>.  You can look at the exact code by checking the script <code>/etc/daily</code>.
</p>
<p>However, it's not clear how to boot from this partition if you didn't install a bootloader or created an EFI partition on the disk...
</p>
<p><a href="https://man.openbsd.org/hier">OpenBSD manual pages: hier (hier stands for file system hierarchy)</a></p>
<p><a href="https://man.openbsd.org/daily">OpenBSD manual pages: daily</a></p>
<p><a href="https://www.openbsd.org/faq/faq14.html#altroot">OpenBSD FAQ: Root partition backup</a></p>
<h2 id="_talk:_local_chat_in_the_terminal">2.9. talk: local chat in the terminal <a href="#_talk:_local_chat_in_the_terminal">§</a></h2>
<p>OpenBSD comes with a program named "talk", this creates a 1 to 1 chat with another user, either on the local system or a remote one (setup is more complicated).  This is not asynchronous, the two users must be logged in the system to use <code>talk</code>.
</p>
<p>This program isn't OpenBSD specific and can be used on Linux as well, but it's so fun, effective and easy to setup I wanted to write about it.
</p>
<p>The setup is easy:
</p>
<pre><code># echo "ntalk		dgram	udp	wait	root	/usr/libexec/ntalkd	ntalkd" &gt;&gt; /etc/inetd.conf
# rcctl enable inetd
# rcctl start inetd
</code></pre>
<p>The communication happens on localhost on UDP ports 517 and 518, don't open them to the Internet!  If you want to allow a remote system, use a VPN to encrypt the traffic and allow ports 517/518 only for the VPN.
</p>
<p>The usage is simple, if you want alice and bob to talk to each other:
</p>
<ul>

  <li>alice type <code>talk bob</code>, and bob must be logged in as well</li>
  <li>bob receives a message in their terminal that alice wants to talk</li>
  <li>bob type <code>talk alice</code></li>
  <li>a terminal UI appears for both users, what they write will appear on the top half of the UI, and the messages from recipient will appear on the half bottom</li>
</ul>

<p>This is a bit archaic, but it works fine and comes with the base system.  It does the job when you just want to speak to someone.
</p>
<h2 id="_Conclusion">3. Conclusion <a href="#_Conclusion">§</a></h2>
<p>There are interesting features on OpenBSD that I wanted to highlight a bit, maybe you will find them useful.  If you know cool features that could be added to this list, please reach me!
</p>

</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ledger (151 pts)]]></title>
            <link>https://lock.cmpxchg8b.com/ledger.html</link>
            <guid>39492924</guid>
            <pubDate>Sat, 24 Feb 2024 16:46:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lock.cmpxchg8b.com/ledger.html">https://lock.cmpxchg8b.com/ledger.html</a>, See on <a href="https://news.ycombinator.com/item?id=39492924">Hacker News</a></p>
<div id="readability-page-1" class="page">

<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#intro">Intro</a></li>
<li><a href="#getting-started">Getting Started</a></li>
<li><a href="#examples">Examples</a></li>
<li><a href="#advice">Advice</a></li>
</ul>
</nav>
<section id="intro">
<h2>Intro</h2>
<p>One of my new years resolutions was to commit to using <a href="https://ledger-cli.org/">ledger</a> – a commandline accounting tool. Ledger is a bit like Quicken, GnuCash or Mint, but for UNIX nerds.</p>
<blockquote>
<p>Note: No relation to the cr*pto product with the same name.</p>
</blockquote>
<p>It’s coming up to the end of the year, and this was one of the few resolutions I actually managed to keep!</p>
<p>I think you can <em>probably</em> accomplish everything ledger can do with other personal finance software. The reason you would choose ledger is that you’re sold on the efficiency and scriptability of the commandline, along with the grep, editor and revision control friendly file format.</p>
<p>If that sounds interesting, go take a look at the <a href="https://ledger-cli.org/doc/ledger3.html#Introduction-to-Ledger">docs</a> to learn more!</p>
<p>The TL;DR is that I’m hooked, and will keep using it.</p>
</section>
<section id="getting-started">
<h2>Getting Started</h2>
<p>It’s not easy to get started with ledger, and you’re probably going to have some uncommon financial arrangements that the documentation didn’t cover exactly. It could be anything, maybe something mundane like you split the utilities with a partner, but you’re the one who pays the bill?<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>These things are easy to handle once you’re familiar with ledger concepts, but as nobody has the exact same arrangements as you, it’s not always a copy-and-paste situation.</p>
<p>This is where ledger’s flexibility can be a curse – the answer to questions like “How do I handle …?” tends to be “However you like!”. Cool, but you’re not going to have any opinions formed yet, so how do you know what you like?</p>
<p>I don’t really have a good solution – I think you just have to wing it until you’re proficient, then go back and fix any naive mistakes you made 🙈</p>
<p>Another problem is that you need a few months worth of data before you can fairly evaluate if you find it useful or not. That’s a big commitment to something that you’re not sure you’re actually going to enjoy!</p>
<p>After you’ve finally built up some data… your reward is having to learn the query syntax so you can actually do something useful with it… and that’s when you’ll realize you didn’t organize things optimally, and have to go back and edit the last few months of data! 😂</p>
<p>Now that I’ve scared everyone off, I can tell you I don’t regret that effort – ledger is great! You know that feeling when you find a solution that just feels “correct”? Well, ledger gives me that feeling.</p>
</section>
<section id="examples">
<h2>Examples</h2>
<p>So, what exactly does ledger look like? Well, there is no user interface, it’s a commandline tool to query your finances.</p>
<blockquote>
<p>Note: If you want graphs, you pipe the output into <code>gnuplot</code>, <a href="https://www.sundialdreams.com/report-scripts-for-ledger-cli-with-gnuplot/">like this</a>. If you’re a stats nerd, you might prefer <a href="https://github.com/esovetkin/ledger-plots">ledger-plots</a>.</p>
</blockquote>
<p>You can automatically import transactions from whatever format your bank provides, but I prefer to enter some transactions manually. I use vim’s <code>colorcolumn</code> feature to make margins and keep everything neatly aligned.</p>
<p>Once you’ve got importing and editing working smoothly, you can start answering questions about your finances.</p>
<ul>
<li>How much have I spent this month?</li>
</ul>
<pre><code>$ ledger bal --period "this month" ^Expenses:</code></pre>
<ul>
<li>How much did I spend on gas each month this year?</li>
</ul>
<pre><code>$ ledger reg --period "this year" --monthly ^Expenses:Auto:Gas</code></pre>
<ul>
<li>What is my current networth?</li>
</ul>
<pre><code>$ ledger bal --depth 1 --market ^Assets: ^Liabilities:</code></pre>
<ul>
<li>How much have my investments grown?</li>
</ul>
<pre><code>$ ledger bal --gain ^Assets:Brokerage</code></pre>
<ul>
<li>Okay, but what about my investment in stock FOOBAR specifically?</li>
</ul>
<pre><code>$ ledger bal --gain --limit 'commodity == "FOOBAR"' ^Assets:Brokerage</code></pre>
<ul>
<li>Okay, but how much of that is long term capital gains?</li>
</ul>
<pre><code>$ ledger bal --gain --limit 'commodity == "FOOBAR"' --limit 'lot_date(amount) &lt; [365 days ago]' ^Assets:Brokerage</code></pre>
<ul>
<li>How much did I spend at McDonalds in June?</li>
</ul>
<pre><code>$ ledger bal --period "this june" ^Expenses: and @McDonalds
</code></pre>
<ul>
<li>How much do I spend each month on average in total?</li>
</ul>
<pre><code>$ ledger reg --period "this year" --average --monthly --depth 1 ^Expenses:</code></pre>
<ul>
<li>Where is that money going, but only show me the categories I spend more than $20 on?</li>
</ul>
<pre><code>$ ledger bal --period "last 12 months" --amount "amount / 12" --display 'top_amount(amount) &gt; 20' ^Expenses:</code></pre>
<ul>
<li>Did I earn enough credit card rewards to justify the fees, or should I cancel them?</li>
</ul>
<pre><code>$ ledger reg --period "this year" --subtotal --related ^Income:Reward</code></pre>
<ul>
<li>Show me all the donations I made that I can deduct on my taxes?</li>
</ul>
<pre><code>$ ledger reg --period "this year" %deductible</code></pre>
<p>These are just some random examples, there are also budgeting and forecasting tools. It’s flexible enough that people use it for tracking billable hours, inventory and so on.</p>
<p>Naturally, it handles multiple currencies, arbitrary commodities, and you can track them as precisely (or coarsely) as you like.</p>
</section>
<section id="advice">
<h2>Advice</h2>
<p>This post is really just encouraging anyone considering getting started to take the leap if you were thinking about getting started in the new year!</p>
</section>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>fyi, you could probably record that like this:</p>
<pre><code>; Pay the power bill, John owes me half
2023/10/1 * Power Company
   Expenses:Utilities:Power    $50
   Assets:Receivables:John     $50
   Assets:Checking            -$100
; John reimbursed me.
2023/10/2 * John Doe  ; Flatmate
   Assets:Checking             $50
   Assets:Receivables:John    -$50</code></pre>
<p>…but maybe you want to record it like this:</p>
<pre><code>; Pay the power bill, John owes me half
2023/10/1 * Power Company
   Expenses:Utilities:Power    $100
   Assets:Checking             $100
; John reimbursed me his half.
2023/10/2 * John Doe  ; Flatmate
   Assets:Checking             $50
   Expenses:Utilities:Power   -$50 ; [=2023/10/1]</code></pre>
<p>There is not always one right answer!<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[V Language Review (2023) (164 pts)]]></title>
            <link>https://n-skvortsov-1997.github.io/reviews/</link>
            <guid>39492680</guid>
            <pubDate>Sat, 24 Feb 2024 16:18:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://n-skvortsov-1997.github.io/reviews/">https://n-skvortsov-1997.github.io/reviews/</a>, See on <a href="https://news.ycombinator.com/item?id=39492680">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content"><p>So you’ve found a new programming language called V. It looks nice, has a lot of promises on the website, nice syntax, but how does it really work?</p>

<p>Everything described here is correct for the <a href="https://github.com/vlang/v/commit/b66447cf11318d5499bd2d797b97b0b3d98c3063"><code>b66447cf11318d5499bd2d797b97b0b3d98c3063</code></a> commit. This is a summary of my experience with the language over 6 months + information that I found on Discord while I was writing this article.</p>

<p>The article is quite long, because I tried to describe everything in as much detail as possible and anyone could reproduce the same behavior.</p>

<p>Where do you start learning a new programming language? That’s right, from the documentation. V documentation is one huge  <a href="https://github.com/vlang/v/blob/master/doc/docs.md"><code>docs.md</code></a> file.</p>

<p>Not far from the beginning, you can notice the built-in types that V has. The small <code>soon</code> prefix for types <code>i128</code> and <code>u128</code> describes the state of the entire language. This note has been in the documentation for at least 4 years (<a href="https://github.com/vlang/v/commit/65a8db85254b8d8d02098843202142e61aa02570"><code>commit</code></a>), apparently we need to wait a little longer.</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/1-resized.png" alt=""></p>

<p>Next, you may notice that, unlike C and Go, <code>int</code> is always 32 bit. But, in release <a href="https://github.com/vlang/v/releases/tag/0.4.3">0.4.3</a> it is now 64 bit on 64-bit systems and 32 bit on 32-bit systems.</p>

<p>A couple of errors, you say, but no, this is the whole of V documentation. There are so few developers to keep the documentation in the correct state. Documentation often does not describe the most important parts of the language — for example, the <a href="https://github.com/vlang/v/blob/master/doc/docs.md#generics">section</a> about generics consists of a couple of code examples without proper description.</p>

<p>Promises as the following are also common in documentation:</p>

<blockquote>
  <p>Currently, generic function definitions must declare their type parameters, but in the future V will infer generic type parameters from single-letter type names in runtime parameter types.</p>
</blockquote>

<p>And now you scroll down to the most interesting thing, memory management in V. In modern programming languages, this is almost the most important part of the language. What does V offer? First of all, this is “Garbage Collection”, a good option that greatly simplifies life, the second option “arena”, also a great option, “manual memory management” is also available for experienced programmers. The last and most interesting option is “autofree”.</p>

<p>The first two options work relatively well, so let’s look at the last two.</p>

<h3 id="manual-memory-management">Manual memory management</h3>

<p>In this mode, libc’s malloc function is used for all allocations and the developer must clean up the memory himself. But what about the memory allocated inside standard library functions? Let’s take a look at the <code>is_ascii</code> <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/builtin/string.v#L2379C2-L2379C2">method</a>:</p>

<pre><code>@[inline]
pub fn (s string) is_ascii() bool {
    return !s.bytes().any(it &lt; u8(` `) || it &gt; u8(`~`))
}
</code></pre>

<p>It might seem like a small safe function, but if you call it with manual memory management, you will have leaks, since no one clears the memory allocated by the <code>bytes()</code> <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/builtin/string.v#L2040">method</a>. Here are <a href="https://github.com/vlang/v/blob/master/vlib/builtin/string.v#L822">more</a> <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/builtin/string.v#L901">such</a> <a href="https://github.com/vlang/v/blob/master/vlib/builtin/string.v#L338">examples</a>. And this is only in string methods; in the standard library it is everywhere.</p>

<p>Well, you can just not use these functions in your code. Let’s see what if you want a web server on V in “manual” mode. V has a built-in framework called <code>vweb</code>. The official examples include the following code: https://github.com/vlang/v/blob/master/examples/vweb/vweb_example.v.</p>

<p>I’ve simplified it as much as possible:</p>

<pre><code>module main

import vweb

struct App {
    vweb.Context
}

pub fn (mut app App) index() vweb.Result {
    return app.text("Hello World")
}

fn main() {
    vweb.run(&amp;App{}, 8082)
}
</code></pre>

<p><a href="https://github.com/vlang/v/blob/master/vlib/vweb/vweb.v#L571">Next</a> <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/vweb/vweb.v#L542">arrays</a> <a href="https://github.com/vlang/v/blob/master/vlib/vweb/vweb.v#L572">never</a> <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/vweb/vweb.v#L958">deallocated</a> in <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/vweb/vweb.v#L729">vweb</a> code. This means that your application on vweb will have leaks.</p>

<p>Well, not everyone writes web, maybe you need a simple CLI utility? Unfortunately, all string interpolations in the standard library for the CLI allocate memory then not cleaned up.</p>

<p>From all of the above, I can draw the following conclusion: manual memory management in V is a feature that cannot be used in real applications. At most in simple programs where you write everything from scratch or memory leaks are not critical for you.</p>

<h3 id="autofree">autofree</h3>

<p>Now we come to the most interesting thing in this section. Let’s see how this mode is described in the documentation:</p>

<blockquote>
  <p>The second way is autofree, it can be enabled with <code>-autofree</code>. It takes care of most objects (~90-100%): the compiler inserts necessary free calls automatically during compilation. Remaining small percentage of objects is freed via GC. The developer doesn’t need to change anything in their code. “It just works”, like in Python, Go, or Java, except there’s no heavy GC tracing everything or expensive RC for each object.</p>
</blockquote>

<p>Surprisingly, they were able to lie in every sentence. Let’s start from the very beginning, the documentation assures us that 90–100% will be cleaned up automatically using <code>free</code> calls inserted by the compiler. This sounds pretty optimistic, considering that to achieve the same thing in Rust, you need a lot of help to the compiler. The V compiler turns out to be “much smarter” than the Rust compiler.</p>

<p>While I was looking at <a href="https://github.com/vlang/v/discussions?discussions_q=is%3Aopen+autofree&amp;page=1">discussions</a> in the language repository, I came across a interesting comment (<a href="https://github.com/vlang/v/discussions/12343#discussioncomment-5828322">link</a>):</p>

<blockquote>
  <p>In my v program, only 0.1% was autofreed and 99.9% was freed by the garbage collector. It all depends on the program you are making. The GC is still really fast though.</p>
</blockquote>

<p>But, let’s not take this as a fact and try it ourselves. Here’s the simplest code:</p>

<pre><code>module main

struct Data {
    data []bool
}

fn main() {
    p := Data{
        data: [true, false]
    }
    println(p.data)
}
</code></pre>

<p>Compile it using <code>v -autofree main.v</code>. And run <code>valgrind</code>:</p>

<div><pre><code>=653065= Memcheck, a memory error detector
=653065= Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
=653065= Using Valgrind-3.18.1 and LibVEX; rerun with -h for copyright info 
=653065= Command: /test
=653065=
[true, false]
=653065=
=653065= HEAP SUMMARY:
=653065=   in use at exit: 2 bytes in 1 blocks
=653065= total heap usage: 6 allocs, 5 frees, 1,085 bytes allocated
=653065=
=653065= LEAK SUMMARY:
=653065=    definitely lost: 2 bytes in 1 blocks
=653065=    indirectly lost: 0 bytes in 0 blocks
=653065=      possibly lost: 0 brtes in 0 blocks
=653065=    still reachable: 0 bytes in 0 blocks
=653065=         suppressed: 0 bytes in 0 blocks
=653065= Rerun with --leak-check=full to see details of leaked memory
=653065=
=653065= ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
</code></pre></div>

<p>Something went wrong. What’s also interesting is that we have a single array in the program, but valgrind shows that a 1kb of memory was allocated. Keep this point in mind as we move on to the website’s statement that V avoids unnecessary allocations.</p>

<p>Let’s compile a simple example with a vweb server:</p>

<pre><code>module main

import vweb

struct App {
    vweb.Context
}

pub fn (mut app App) index() vweb.Result {
    return app.text("Hello World")
}

fn main() {
    vweb.run(&amp;App{}, 8082)
}
</code></pre>



<p>And let’s run it with valgrind. I didn’t make requests to server, but just waited 10 seconds:</p>

<div><pre><code>=653318= Command: /server
=653318=
[Vweb] Running app on http://localhost:8082/
[Vweb] We have 1 workers
=653318=
=653318= Process terminating with default action of signal 2 (SIGINT)
=653318=   at 0x498882D: select (select.c:69)
=653318=   by 0×58AAF2: net__select (in /home/skvortsov/server)
=653318=   by 0x642D81: net__select_deadline (in /home/skvortsov/server)
=653318=   by 0×58B122: net__wait_for_common (in /home/skvortsov/server)
=653318=   by 0x58B40B: net__wait_for_read (in /home/skvortsov/server)
=653318=   by 0x591D43: net__TepListener_wait_for_accept (in /home/skvortsov/server)
=653318=   by 0x5915F9: net__TepListener_accept_only (in /home/skvortsov/server)
=653318=   by 0x5E57E1: vweb__run_at_T_main_App (in /home/skvortsov/server)
=653318=   by 0x5E4262: vweb__run_T_main__App (in /home/skvortsov/server)
=653318=   by 0x5F0102: main__main (in /home/skvortsov/server)
=653318=   by 0x63F220: main (in /home/skvortsov/server)
=653318=
=653318= HEAP SUMMARY:
=653318=    in use at exit: 122,833 bytes in 2,395 blocks
=653318=   total heap usage: 2,659 allocs, 264 frees, 541,413 bytes allocated
=653318=
=653318= LEAK SUMMARY:
=653318=    definitely lost: 1,004 bytes in 32 blocks
=653318=    indirectly lost: 106 bytes in 15 blocks
=653318=      possibly lost: 272 bytes in 1 blocks
=653318=    still reachable: 121,451 bytes in 2,347 blocks
=653318=         suppressed: 0 bytes in 0 blocks
=653318- Rerun with --leak-check=full to see details of leaked memory
=653318=
=653318= For lists of detected and suppressed errors, rerun with: -s 
=653318= ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
</code></pre></div>

<p>Without requests, in 10 seconds we definitely lost 1kb of memory.</p>

<p>Let’s return to the description from the documentation:</p>

<blockquote>
  <p>Remaining small percentage of objects is freed via GC.</p>
</blockquote>

<p>And again it’s not true. I found a recent <a href="https://github.com/vlang/v/commit/207203f5998e6b1844a32fe628e0eb64325db64d">commit</a> in which passing the <code>-autofree</code> flag immediately sets <code>gc</code> to <code>none</code>:</p>

<div><pre><code><span>'-autofree'</span> {
  res.autofree = true
<span>+ res.gc_mode = .no_gc
</span>  res.build_options &lt;&lt; arg
<span>}</span>
</code></pre></div>

<p>So, the statement is completely false.</p>

<p>Do you know why this change was made? Let’s look at an example:</p>

<pre><code>fn main() {
    ptr := malloc(1)
    free(ptr)
}
</code></pre>

<p>And let’s look at the <a href="https://github.com/vlang/v/blob/cc220e60a5a0cc787b68ae357c8ecfd2dc561b6f/vlib/builtin/builtin.c.v#L586">definition</a> of the <code>free</code> function:</p>

<pre><code>@[unsafe]
pub fn free(ptr voidptr) {
    $if prealloc {
        return
    } $else $if gcboehm ? {
        // It is generally better to leave it to Boehm's gc to free things.
        // Calling C.GC_FREE(ptr) was tried initially, but does not work
        // well with programs that do manual management themselves.
        //
        // The exception is doing leak detection for manual memory management:
        $if gcboehm_leak ? {
            unsafe { C.GC_FREE(ptr) }
        }
    } $else {
        C.free(ptr)
    }
}
</code></pre>

<p><a href="https://github.com/vlang/v/blob/master/doc/docs.md#if-condition"><code>$if</code></a> specifies a condition evaluated during compilation. Previously, when we passed only <code>-autofree</code> and did not explicitly pass <code>-gc none</code>, then the condition <code>$if gcboehm ?</code> was true and since <code>gcboehm_leak</code> is also not set by default, then <code>free</code> ended up becoming a noop function that did nothing.</p>

<p>Here is the C code that was generated:</p>

<div><pre><code><span>void</span> <span>_v_free</span><span>(</span><span>voidptr</span> <span>ptr</span><span>)</span> <span>{</span>
    <span>#if defined(_VPREALLOC)
</span>    <span>{</span>
    <span>}</span>
    <span>#elif defined(_VGCBOEHM)
</span>    <span>{</span>
    <span>}</span>
    <span>#else
</span>    <span>{</span>
    <span>}</span>
    <span>#endif
</span><span>}</span>
</code></pre></div>

<p>All of this code is C preprocessor, so the compiler sees this code as follows:</p>

<div><pre><code><span>void</span> <span>_v_free</span><span>(</span><span>voidptr</span> <span>ptr</span><span>)</span> <span>{</span>
<span>}</span>
</code></pre></div>

<p>And that doesn’t free anything.</p>

<p>Let’s go back to the documentation:</p>

<blockquote>
  <p>Remaining small percentage of objects is freed via GC.</p>
</blockquote>

<p>And this was not true, even if V inserted <code>free</code> somewhere, they had no effect and everything was cleared by the GC. Even after this fix, this is not true because the GC is disabled when the <code>-autofree</code> flag is passed.</p>

<p>You may have seen this video: https://www.youtube.com/watch?v=gmB8ea8uLsM</p>

<p>In it, the author of the language shows his editor <a href="https://github.com/vlang/ved">Ved</a> and shows how he compiles it using <code>v . -autofree</code> and states that its technology is sufficiently developed that such a complex application as a text editor does not leak.</p>

<p>I tried to build the editor with the latest version of V with the <code>autofree</code> flag and got the following error when I launched the binary:</p>

<div><pre><code>V panic: as cast: cannot cast `map[string]toml.ast.Value` to `[]toml.ast.Value`
v hash: 0966fd3
/tmp/v_1000/ved.5480247081914024169.tmp.c:13797: at _v_panic: Backtrace
/tmp/v_1000/ved.5480247081914024169.tmp.c:14296: by __as_cast
/tmp/v_1000/ved.5480247081914024169.tmp.c:43867: by toml__Doc_value_
/tmp/v_1000/ved.5480247081914024169.tmp.c:43836: by toml__Doc_value
/tmp/v_1000/ved.5480247081914024169.tmp.c:44579: by main__Config_init_colors
/tmp/v_1000/ved.5480247081914024169.tmp.c:44551: by main__Config_reload_config
/tmp/v_1000/ved.5480247081914024169.tmp.c:46595: by main__main
/tmp/v_1000/ved.5480247081914024169.tmp.c:50668: by main
</code></pre></div>

<p>Without <code>autofree</code> everything worked without problems. Well, apparently autofree has only gotten worse in 3 years.</p>

<p>Interestingly enough, the project of the language author does not work with the main feature of his language.</p>

<p>Let’s try to build the compiler itself with <code>autofree</code>:</p>



<p>And let’s try to compile itself again with the resulting binary:</p>



<p>And we get an error at runtime:</p>

<div><pre><code>./v2 self
/tmp/v_1000/v2.10486918756004741764.tmp.c:25123: at string_starts_with: RUNTIME ERROR: invalid memory access
/tmp/v_1000/v2.10486918756004741764.tmp.c:35912: by os__impl_walk_ext
/tmp/v_1000/v2.10486918756004741764.tmp.c:35888: by os__walk_ext
/tmp/v_1000/v2.10486918756004741764.tmp.c:42645: by v__pref__detect_musl
/tmp/v_1000/v2.10486918756004741764.tmp.c:42743: by v__pref__parse_args_and_show_errors
/tmp/v_1000/v2.10486918756004741764.tmp.c:4811: by main__main
/tmp/v_1000/v2.10486918756004741764.tmp.c:5835: by main
</code></pre></div>

<p>Let’s go back to the last part of the documentation:</p>

<blockquote>
  <p>The developer doesn’t need to change anything in their code. “It just works”, like in Python, Go, or Java, except there’s no heavy GC tracing everything or expensive RC for each object.</p>
</blockquote>

<p>What we found out above, before commit <a href="https://github.com/vlang/v/commit/207203f5998e6b1844a32fe628e0eb64325db64d">207203f</a> when passing the <code>-autofree</code> flag we <strong>got</strong> “heavy GC tracing everything”, and after we <strong>get</strong> memory leaks even in the simplest examples.</p>

<p>I would also like to note that the author of the language promised to make this technology “production ready” back to version <code>0.3</code> (<a href="https://github.com/vlang/v/blob/0f9537ece544b7fda31cadf4dc95fd4b552f94be/ROADMAP.md">commit</a>), then to <a href="https://discord.com/channels/592103645835821068/592106336838352923/1136589637658345563">0.5</a>. and maybe in <a href="https://discord.com/channels/273534239310479360/818964227783262209/1146427952083513467">0.6</a>, and in <a href="https://github.com/vlang/v/blob/master/ROADMAP.md">ROADMAP</a> in 1.0.</p>

<blockquote>
  <p>“Fake it <del>till you make it</del>”.</p>
</blockquote>

<p>It’s interesting that the author of the language does not <a href="https://discord.com/channels/592103645835821068/592106336838352923/1126201270902997114">see the point</a> in using <code>autofree</code> with GC, although the documentation says that it is GC that clears the remaining “10%” of objects. Marvelous.</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/2-resized.png" alt=""></p>

<p>Thus, from all of the above, we can conclude that <code>autofree</code> is a very crude technology. The author of the language tried to promote it through that video, and judging by the comments he succeeded, I don’t understand why people believe him, because a simple test shows that even simple programs leak as hell.</p>

<p><strong>After almost 5 years, the most interesting feature of V is still in a very early state, and the author does nothing but promise that everything will happen soon.</strong></p>

<p>It is already clear that the author of the language and his loyal followers will begin to say that <code>autofree</code> is not yet production ready, but the problems that I described above even for the very first alpha version are unacceptable.</p>

<h3 id="gc-default">GC (default)</h3>

<p>In this section, I want to discuss the remaining shortcomings of V in the memory management system.</p>

<p>Let’s go back to the documentation:</p>

<blockquote>
  <p>V avoids doing unnecessary allocations in the first place by using value types, string buffers, promoting a simple abstraction-free code style.</p>
</blockquote>

<p>It is stated that V does not make unnecessary allocations. Let’s check it out. In V, if you convert a structure into an interface, you get memory allocation with no options to avoid it, so you will get a bunch of extra allocations for nothing:</p>

<pre><code>interface IFoo {
    name string
}

struct Foo {
    name string
}

fn get_ifoo() IFoo {
    return Foo{name: 'foo'}
}

fn main() {
    foo := get_ifoo()
    println(foo.name)
}
</code></pre>

<p>C code:</p>

<div><pre><code><span>VV_LOCAL_SYMBOL</span> <span>main__IFoo</span> <span>main__get_ifoo</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>main__IFoo</span> <span>_t1</span> <span>=</span> <span>I_main__Foo_to_Interface_main__IFoo</span><span>(((</span><span>main__Foo</span><span>*</span><span>)</span><span>memdup</span><span>(</span><span>&amp;</span><span>(</span><span>main__Foo</span><span>){.</span><span>name</span> <span>=</span> <span>_SLIT</span><span>(</span><span>"foo"</span><span>),},</span> <span>sizeof</span><span>(</span><span>main__Foo</span><span>))));</span>
    <span>return</span> <span>_t1</span><span>;</span>
<span>}</span>
</code></pre></div>

<p><code>memdup</code> sends memory to heap via <code>_v_malloc</code>. In this small piece of code, you can also notice another feature of V, “readable” generated C code.</p>

<p>There is no escape analysis in V, and any pointers you create in a function make unnecessary allocations to the heap:</p>

<pre><code>fn main() {
    a := 100
    b := &amp;a
    println(b)
}
</code></pre>

<p>In C code:</p>

<div><pre><code><span>void</span> <span>main__main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>int</span> <span>*</span><span>a</span> <span>=</span> <span>HEAP</span><span>(</span><span>int</span><span>,</span> <span>(</span><span>100</span><span>));</span> <span>// heap allocation</span>
    <span>int</span><span>*</span> <span>b</span> <span>=</span> <span>&amp;</span><span>(</span><span>*</span><span>(</span><span>a</span><span>));</span>
    <span>string</span> <span>_t1</span> <span>=</span> <span>str_intp</span><span>(</span><span>1</span><span>,</span> <span>_MOV</span><span>((</span><span>StrIntpData</span><span>[])}));</span> <span>println</span><span>(</span><span>_t1</span><span>);</span> <span>string_free</span><span>(</span><span>&amp;</span><span>_t1</span><span>);</span>
    <span>;</span>
<span>}</span>
</code></pre></div>

<p>The documentation says:</p>

<blockquote>
  <p>Due to performance considerations V tries to put objects on the stack if possible but allocates them on the heap when obviously necessary.</p>
</blockquote>

<p>V does not allocate to the heap <strong>only those objects whose address is not taken</strong> in the entire function, V doesn’t do escape analysis and considers any taking of an address as a leak (in terms of “Escape Analysis”) from the function. And this doesn’t match the statement “Due to performance considerations V tries to put objects on the stack if possible” because any address taking results in an allocation on the heap even if it could have been avoided.</p>

<p>In the example above you can say that everything is correct, <code>b</code> leaks into the <code>println</code> function, so let’s look at an example without the call:</p>

<pre><code>fn main() {
    a := 100
    b := &amp;a
}
</code></pre>

<p>C code:</p>

<div><pre><code><span>void</span> <span>main__main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>int</span> <span>*</span><span>a</span> <span>=</span> <span>HEAP</span><span>(</span><span>int</span><span>,</span> <span>(</span><span>100</span><span>));</span>
    <span>int</span><span>*</span> <span>b</span> <span>=</span> <span>&amp;</span><span>(</span><span>*</span><span>(</span><span>a</span><span>));</span>
<span>}</span>
</code></pre></div>

<p>And still allocated on heap.</p>

<p>Instead of doing a smart escape analysis in V has a hack through the special <code>heap</code> attribute:</p>

<blockquote>
  <p>A solution to this dilemma is the <code>[heap]</code> <a href="https://github.com/vlang/v/blob/master/doc/docs.md#attributes">attribute</a> at the declaration of <code>struct MyStruct</code>. It instructs the compiler to <em>always</em> allocate <code>MyStruct</code>-objects on the heap.</p>
</blockquote>

<p>This is a bad solution because the developer cannot control where the object is allocated in each instantiation; by marking the structure with this attribute, you automatically get unnecessary allocations that could have been avoided.</p>

<hr>

<p>The quote from the beginning of the section also mentioned string buffers, so let’s take a look:</p>

<pre><code>import strings

fn main() {
    before := gc_heap_usage()
    mut sb := strings.new_builder(1)
    sb.write_string("hello")
    res := sb.str()
    after := gc_heap_usage()
    println(res)
    println(after.bytes_since_gc - before.bytes_since_gc)
}
</code></pre>



<p>Allocates 48 bytes, although there are only 5 bytes in the string.</p>

<p>Perhaps things are better with string interpolation?</p>

<pre><code>fn main() {
    before := gc_heap_usage()
    world := "world"
    res := "hello ${world}"
    after := gc_heap_usage()
    println(res)
    println(after.bytes_since_gc - before.bytes_since_gc)
}
</code></pre>



<p>Oho-ho, allocates 304 bytes for string of 11 characters. Impressive.</p>

<p>Let’s talk a little more about <code>arena</code> in this section.</p>

<h3 id="arena--prealloc">Arena (<code>-prealloc</code>)</h3>

<p>What does the documentation tell us about this mode? The only mention in the documentation I found was this line:</p>

<blockquote>
  <p>Arena allocation is available via v <code>-prealloc</code>.</p>
</blockquote>

<p>Oops. As I said, the documentation in V is bad.</p>

<p>Let me tell you myself, an arena is a way of working with memory, when at the start of the program a large chunk of memory is allocated at once, for example, 16 megabytes. Then, all allocations occur in this chunk; all explicit memory free does nothing. When a chunk is full, a new one is allocated, and so on. Before the program ends, all memory is freed.</p>

<p>This method is usually best suited for short-lived programs, such as compilers, where memory consumption may be less preferable to faster runtime.</p>

<p>What is the advantage of this mode? If small objects are often allocated in a program, then their allocation will take literally several arithmetic operations, instead of access to the operating system for memory each time.</p>

<p>Let’s dive into the world of V. All the implementation code can be found in the <a href="https://github.com/vlang/v/blob/master/vlib/builtin/prealloc.c.v"><code>prealloc.c.v</code></a> file.</p>

<p>The first thing we see is the <code>@[has_globals]</code> attribute of the module. But wait a minute:</p>

<blockquote>
  <p>By default V does not allow global variables. However, in low level applications they have their place so their usage can be enabled with the compiler flag <code>-enable-globals</code>.</p>
</blockquote>

<p>But ok.</p>

<p>Below we see exactly the reason for the presence of this flag:</p>

<div><pre><code>__global g_memory_block &amp;VMemoryBlock
</code></pre></div>

<p>Global variable. <code>__global</code>.</p>

<p>But since it’s global, what about multithreading? I didn’t see any mutexes, which means that <code>-prealloc</code> cannot be used in multithreaded programs safely. Is this written somewhere in the documentation? Nope. There is a comment in the file itself where this is written, apparently the author of the language believes that all users should first read the source code of the compiler.</p>

<h3 id="conclusions-about-memory-management">Conclusions about memory management</h3>

<p>Some parts are raw, some are unsafe, some don’t work, some don’t work as described. This is just what I could find. If such sloppiness is everywhere, this may mean that it is quite possible that there are even more critical bugs that we simply are not aware of.</p>

<p>This is where we’ll finish talking about working with memory in V.</p>

<p>Next, let’s quickly go through the site before a new interesting topic, coroutines in V.</p>

<h2 id="site-claims">Site claims</h2>

<p>Site is stated that there are no <code>null</code> in the language, without taking into account <code>unsafe</code> code. So:</p>

<pre><code>struct Foo {
    data &amp;string
}

fn main() {
    println(Foo{
        data: 0
    })
}
</code></pre>

<p>there is no <code>null</code>, but you can assign 0 to a pointer. ¯_(ツ)_/¯</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/3-resized.png" alt=""></p>

<p>Then the site tells us that there is no UB in the language. Let’s open the <a href="https://en.wikipedia.org/wiki/Undefined_behavior">article</a> about UB on the wiki.</p>

<p>Overflows in V really haven’t been UB since <a href="https://github.com/vlang/v/commit/c6412597abe24cdf099c9031ebdc47a3a263d141">recently</a>. It took 4 years from the release of the language to fix this UB. Although there is not a word about this in the documentation, the language also has no specification, so for the user this fact is hidden behind the compiler code. Here is a description of the С flag that was added as a fix:</p>

<blockquote>
  <p>This option instructs the compiler to assume that signed arithmetic overflow of addition, subtraction and multiplication wraps around using twos-complement representation. This flag enables some optimizations and disables others.</p>
</blockquote>

<p>Honestly, in a safe language, as the site says, I would expect the ability to perform these operations safely with the ability to specify the behavior on overflow (<code>a.safe_add(b) or { panic("aaaa") }</code>), and by default – panic.</p>

<p>Let’s try another example from the wiki article:</p>

<pre><code>fn main() {
    a := 100
    b := 200
    println(&amp;a &lt; &amp;b)
}
</code></pre>

<p>C code:</p>

<div><pre><code><span>void</span> <span>main__main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>int</span> <span>a</span> <span>=</span> <span>100</span><span>;</span>
    <span>int</span> <span>b</span> <span>=</span> <span>200</span><span>;</span>
    <span>println</span><span>(</span><span>&amp;</span><span>a</span> <span>&lt;</span> <span>&amp;</span><span>b</span> <span>?</span> <span>_SLIT</span><span>(</span><span>"true"</span><span>)</span> <span>:</span> <span>_SLIT</span><span>(</span><span>"false"</span><span>));</span>
<span>}</span>
</code></pre></div>

<p>Code from V article:</p>

<pre><code>int main(void)
{
  int a = 0;
  int b = 0;
  return &amp;a &lt; &amp;b; /* undefined behavior */
}
</code></pre>

<p>One-to-one, it’s UB.</p>

<p>Let’s try to dereference a null pointer:</p>

<pre><code>struct Data {
    name string
}

fn (d &amp;Data) some() {
    println(d.name)
}

struct Foo {
mut:
    data &amp;Data
}

fn main() {
    mut foo := Foo{
        data: 0
    }
    foo.data.some()
}
</code></pre>

<div><pre><code>code.v:6: at main__Data_some: RUNTIME ERROR: invalid memory access
code.v:18: by main__main
code.13715926371810092027.tmp.c:16997: by main
</code></pre></div>

<p>No safety at all.</p>

<p>Let’s move forward.</p>

<blockquote>
  <p>No undefined values</p>
</blockquote>

<p>Okay, let’s create a structure with an interface field:</p>

<pre><code>interface IFoo {
    name() string
}

struct Foo {
mut:
    foo IFoo
}

fn main() {
    mut foo := Foo{}
    println(foo.foo.name())
}
</code></pre>

<p>And run it:</p>

<pre><code>RUNTIME ERROR: invalid memory access
</code></pre>

<p>Oops, the problem is that an uninitialized field with an interface type actually has an undefined value. But you won’t be able to find information about this in the documentation.</p>

<blockquote>
  <p>No global variables <em>(can be enabled for low level apps like kernels via a flag)</em></p>
</blockquote>

<p>We’ve already seen a hack through <code>[has_globals]</code>. Although it seems it’s only allowed for the compiler. So that’s true.</p>

<p>Let’s move to the performance section:</p>

<blockquote>
  <p>C interop without any costs</p>
</blockquote>

<p>Indeed, that’s true.</p>

<blockquote>
  <p>Minimal amount of allocations</p>
</blockquote>

<p>It has already been proven above that this is not true.</p>

<blockquote>
  <p>Built-in serialization without runtime reflection</p>
</blockquote>

<p>That’s indeed true.</p>

<blockquote>
  <p>Compiles to native binaries without any dependencies: a simple web server is only about 250 KB</p>
</blockquote>

<p>Let’s try to compile the official <a href="https://github.com/vlang/v/blob/master/examples/vweb/vweb_example.v">example</a> with <code>V 0.4.3 c3cf9ee.cc220e6</code> on Ubuntu 22.04.</p>

<p>It took indefinitely long to compile this example with the <code>-prod</code> flag, so I manually inserted the required optimization flags.</p>

<p>Let’s try to compile:</p>

<div><pre><code>v ./v/examples/vweb/vweb_example.v -cflags "-Os" -o vweb_server
</code></pre></div>

<p>And check the size:</p>

<div><pre><code>-rwxr-xr-x 1 root root 4511876 Nov 19 14:03 vweb_server
</code></pre></div>

<p>Oops, 4mb, a bit far from 250 KB. Let’s try a couple of tricks:</p>

<div><pre><code>v ./v/examples/vweb/vweb_example.v -cflags "-Os -flto" -o vweb_server -skip-unused
</code></pre></div>

<div><pre><code>-rwxr-xr-x 1 root root 2784628 Nov 19 14:07 vweb_server
</code></pre></div>

<p>Better, only 2.7 megabytes, but still not 250 KB.</p>

<p>Another trick I found in a <a href="https://github.com/vlang/v/discussions/19792">GitHub discussion</a>:</p>

<div><pre><code>v ./v/examples/vweb/vweb_example.v -cflags "-Os -flto" -o vweb_server -skip-unused -d use_openssl
</code></pre></div>

<div><pre><code>-rwxr-xr-x 1 root root 1565316 Nov 19 14:09 vweb_server
</code></pre></div>

<p>We’re getting closer, but I don’t have other tricks.</p>

<p>Well, maybe everything got statically linked, so the size is big:</p>

<div><pre><code>ldd ./vweb_server
    linux-vdso.so.1 (0x00007ffde677d000)
    libatomic.so.1 =&gt; /lib/x86_64-linux-gnu/libatomic.so.1 (0x00007fc25455a000)
    libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fc254332000)
    /lib64/ld-linux-x86-64.so.2 (0x00007fc25456e000)
</code></pre></div>

<p>What about with <code>-d use_openssl</code>?</p>

<div><pre><code>ldd ./vweb_server
    linux-vdso.so.1 (0x00007ffc2b242000)
    libatomic.so.1 =&gt; /lib/x86_64-linux-gnu/libatomic.so.1 (0x00007fa673d80000)
    libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fa673b58000)
    libssl.so.3 =&gt; /lib/x86_64-linux-gnu/libssl.so.3 (0x00007fa673ab4000)
    libcrypto.so.3 =&gt; /lib/x86_64-linux-gnu/libcrypto.so.3 (0x00007fa673671000)
    /lib64/ld-linux-x86-64.so.2 (0x00007fa673d94000)
</code></pre></div>

<p>Hmm, as a result, the size is 5-17 times larger, and there are a lot of dependencies.</p>

<p>Let’s go further.</p>

<blockquote>
  <p>As fast as C (V’s main backend compiles to human readable C), with equivalent code.
<em>V does introduce some overhead for safety (such as array bounds checking, GC free), but these features can be disabled/bypassed when performance is more important.</em></p>
</blockquote>

<p>Just because you compile in C doesn’t mean you instantly get the same performance as handwritten C code. I have already shown above how V carelessly works with memory; not a single experienced C developer will make such mistakes.</p>

<p>V can be as fast as C, but then a lot of things in the language cannot be used: string interpolation, interfaces, sum types, arrays and much more.</p>



<p>The official site says:</p>

<blockquote>
  <p>V can translate your entire C project and offer you the safety, simplicity, and compilation speed-up (via modules).</p>
</blockquote>

<p>Sounds great, let’s try it. Before that, let’s pay attention on another statement:</p>

<blockquote>
  <p>A blog post about translating DOOM will be published.</p>
</blockquote>

<p>You can find the same statement on the <a href="https://web.archive.org/web/20200709094936/https://vlang.io/">official website in 2020</a>. Maybe we need to wait a little longer.
During the article, I have already pointed out such moments several times; this is the distinctive feature of V, <strong>to promise and not to deliver</strong>.</p>

<p>Well, let’s move on to c2v. Its repository can be found here: https://github.com/vlang/c2v</p>

<p>It doesn’t have to be downloaded, it can be used via <code>v translate</code>. By the way, you will not find this command in <code>v help</code>:</p>

<div><pre><code>V supports the following commands:

* Project Scaffolding Utilities:
  new                          Setup the file structure for a V project
                               (in a sub folder).
  init                         Setup the file structure for an already existing
                               V project.

* Commonly Used Utilities:
  run                          Compile and run a V program. Delete the
                               executable after the run.
  crun                         Compile and run a V program without deleting the
                               executable.
                               If you run the same program a second time,
                               without changing the source files,
                               V will just run the executable, without
                               recompilation. Suitable for scripting.
  test                         Run all test files in the provided directory.
  fmt                          Format the V code provided.
  vet                          Report suspicious code constructs.
  doc                          Generate the documentation for a V module.
  vlib-docs                    Generate and open the documentation of all the
                               vlib modules.
  repl                         Run the REPL.
  watch                        Re-compile/re-run a source file, each time it is
                               changed.
  where                        Find and print the location of current project
                               declarations.
</code></pre></div>

<p>Did I mention that the documentation is bad?</p>

<p>Let’s take a simple example:</p>



<p>Let’s call the command <code>v translate wrapper main.h</code> and open the resulting file:</p>

<pre><code>[translated]
module.

fn C.foo(a int, b int) int

pub fn foo(a int, b int) int {
  return C.foo(a, b)
}
</code></pre>

<p>Everything seems fine, but the module name is incorrect.</p>

<p>In C libraries, constants are often defined using <code>#define</code>:</p>

<div><pre><code><span>#define VERSION 1.0
</span>
<span>int</span> <span>foo</span><span>(</span><span>int</span> <span>a</span><span>,</span> <span>int</span> <span>b</span><span>);</span>
</code></pre></div>

<p>But as a result, c2v simply skips this constant, and it is not in the V code. The generated V code with <code>#define</code> fully equals to the code without it.</p>

<p>Okay, let’s take a slightly more complicated example:</p>

<div><pre><code><span>#include &lt;stdlib.h&gt;
</span>
<span>typedef</span> <span>struct</span> <span>{</span>
    <span>union</span> <span>{</span>
        <span>char</span> <span>*</span><span>ptr</span><span>;</span>
        <span>char</span> <span>small</span><span>[</span><span>16</span><span>];</span>
    <span>};</span>
    <span>size_t</span> <span>size</span><span>;</span>
<span>}</span> <span>string</span><span>;</span>

<span>int</span> <span>foo</span><span>(</span><span>string</span> <span>str</span><span>);</span>
</code></pre></div>

<p>This is a simple string implementation.</p>

<pre><code>[translated]
module .

struct Lldiv_t { 
    quot i64
    rem i64
}
struct String { 
    size usize
}
fn C.foo(str String) int

pub fn foo(str String) int {
    return C.foo(str)
}
</code></pre>

<p>Wait a minute, what is this <code>Lldiv_t</code> and why is there only one field in the structure…</p>

<p>I really like constancy:</p>

<div><pre><code><span>int</span> <span>foo</span><span>(</span><span>const</span> <span>int</span> <span>*</span><span>const</span> <span>val</span><span>);</span>
</code></pre></div>

<p>But c2v doesn’t:</p>

<pre><code>[translated]
module .

fn C.foo(val Int *const) int

pub fn foo(val Int *const) int {
    return C.foo(val)
}
</code></pre>

<p>Absolutely incorrect code.</p>

<p>You will say that I am making everything up and no one writes such code, okay, let’s take an example from real life. Let’s take the library that V uses for JSON: https://github.com/DaveGamble/cJSON.</p>

<div><pre><code>v translate wrapper cJSON.h
</code></pre></div>

<p>Aaaaaand…</p>

<p>Almost all is incorrect:</p>

<pre><code>fn C.cJSON_GetObjectItem(object CJSON *const, string_ Char *const) &amp;CJSON

pub fn cjson_getobjectitem(object CJSON *const, string_ Char *const) &amp;CJSON {
    return C.cJSON_GetObjectItem(object, string_)
}

...

fn C.cJSON_IsTrue(item CJSON *const) CJSON_bool

pub fn cjson_istrue(item CJSON *const) CJSON_bool {
    return C.cJSON_IsTrue(item)
}

...

fn C.cJSON_ReplaceItemViaPointer(parent CJSON *const, item CJSON *const, replacement &amp;CJSON) CJSON_bool

pub fn cjson_replaceitemviapointer(parent CJSON *const, item CJSON *const, replacement &amp;CJSON) CJSON_bool {
    return C.cJSON_ReplaceItemViaPointer(parent, item, replacement)
}
</code></pre>

<p>Okay, let’s take another one, for example, <a href="https://github.com/vlang/v/blob/master/thirdparty/libbacktrace/backtrace.h"><code>backtrace.h</code></a>.</p>

<div><pre><code>v translate wrapper backtrace.h
</code></pre></div>

<p>Better, although we lost <code>Backtrace_state</code> and <code>Uintptr_t</code> and have an error:</p>

<div><pre><code>backtrace.v:29:59: error: unexpected token `&amp;`, expecting name
   27 | fn C.backtrace_print(state &amp;Backtrace_state, skip int,  &amp;C.FILE)
   28 | 
   29 | pub fn backtrace_print(state &amp;Backtrace_state, skip int,  &amp;C.FILE)  {
      |                                                           ^
   30 |     C.backtrace_print(state, skip, &amp;C.FILE)
   31 | }
</code></pre></div>

<p>Well, okay, c2v is not great with wrappers, but the tool can also translate entire C code into V.</p>

<p>Let’s start with something simple:</p>

<div><pre><code><span>#include &lt;stdio.h&gt;
</span>
<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span> <span>**</span><span>argv</span><span>)</span> <span>{</span>
    <span>printf</span><span>(</span><span>"%d"</span><span>,</span> <span>argc</span><span>);</span>
    <span>return</span> <span>1</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Call c2v:</p>



<p>Oops, where did <code>argc</code> go:</p>

<pre><code>[translated]
module main

fn main() {
    C.printf(c'%d', argc)
    return
}
</code></pre>

<p>I specifically returned 1 from <code>main</code> in the C code, but c2v ignored this and simply inserted <code>return</code>, thereby changing the behavior of the program.</p>

<p>Let’s take something more complicated:</p>

<div><pre><code><span>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
</span>
<span>void</span><span>*</span> <span>my_malloc</span><span>(</span><span>size_t</span> <span>size</span><span>)</span> <span>{</span>
    <span>void</span><span>*</span> <span>ptr</span> <span>=</span> <span>malloc</span><span>(</span><span>size</span><span>);</span>
    <span>if</span> <span>(</span><span>ptr</span> <span>==</span> <span>NULL</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"malloc failed"</span><span>);</span>
        <span>exit</span><span>(</span><span>1</span><span>);</span>
    <span>}</span>
    <span>return</span> <span>ptr</span><span>;</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span> <span>**</span><span>argv</span><span>)</span> <span>{</span>
    <span>int</span> <span>*</span><span>a</span> <span>=</span> <span>my_malloc</span><span>(</span><span>sizeof</span><span>(</span><span>int</span><span>));</span>
    <span>*</span><span>a</span> <span>=</span> <span>1</span><span>;</span>
    <span>printf</span><span>(</span><span>"%d"</span><span>,</span> <span>*</span><span>a</span><span>);</span>
    <span>return</span> <span>1</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>V:</p>

<pre><code>[translated]
module main

struct Lldiv_t {
    quot i64
    rem  i64
}

fn my_malloc(size usize) voidptr {
    ptr := C.malloc(size)
    if ptr == (unsafe { nil }) {
        C.printf(c'malloc failed')
        C.exit(1)
    }
    return ptr
}

fn main() {
    a := my_malloc(sizeof(int))
    *a = 1
    C.printf(c'%d', *a)
    return
}
</code></pre>

<p>It looks correct at first glance, but c2v has lost the fact that the result of <code>my_malloc(...)</code> is cast implicitly in <code>int*</code>. So if you have implicit casts in your code, then apparently everything will not work out of the box. But in C, implicit casts are rare, so it’s not a problem, right?</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/4-resized.png" alt=""></p>

<p>We can talk about this for a long time; such simple examples already show how crude and unfinished this tool is. Considering the fact that it was announced and began development somewhere in 2020, the tool achieved such excellent success in just 3 years.</p>

<hr>

<p>Returning to the site:</p>

<blockquote>
  <p>Powerful graphics libraries</p>
</blockquote>

<blockquote>
  <p>The following features are planned:</p>

  <ul>
    <li>Loading complex 3D objects with textures</li>
    <li>Camera (moving, looking around)</li>
    <li>Skeletal animation</li>
  </ul>

  <p>DirectX, Vulkan, and Metal support is planned.</p>
</blockquote>

<p>At least <a href="https://web.archive.org/web/20200426171536/https://vlang.io/">three years</a> they promise what will happen. But the main thing is to promise, right?</p>

<h2 id="v-ui">V UI</h2>

<p>Another project that showed promise, but something went wrong. Project repository: https://github.com/vlang/ui</p>

<p>Over the last year, the project has had about 80 commits, of which a maximum of 10–20 are <strong>not fixes for the new version V</strong>. The project has been abandoned and is not being developed.</p>

<p>But let’s see, in the readme we are greeted with an example:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/23-resized.png" alt=""></p>

<p>Do you know what’s interesting? If you go to <a href="https://github.com/vlang/ui/tree/3dd0e7a3f6cb5f316bacf1d556cb8abde25d2c84">repository from 2020</a> then the same picture will be there.</p>

<p>The project has <a href="https://github.com/vlang/ui/issues/31">ROADMAP</a> which was created in 2020, after 3 years only several points there were closed.</p>

<p>You can say that perhaps developers spend all their time on the compiler, but at the same time, there are new projects like <a href="https://github.com/vlang/education-platform">Education Platform</a>, <a href="https://veery.cc/">veery</a>, <a href="https://discord.com/channels/592103645835821068/592106336838352923/1176183805174894653">vbrowser</a>, <a href="https://github.com/vlang/heroesV">heroesV</a>. You may notice that all these projects start and are quickly abandoned. The same thing with V UI, but it lived a little longer, like the <a href="https://github.com/vlang/vinix">operating system</a> on V, which was developed while there was a person with experience, as soon as he left, the project died.</p>

<p>The V UI project description on the website says:</p>

<blockquote>
  <p>V has a UI module that uses custom drawing, similar to Qt and Flutter, but with as much similarity to the native GUI toolkit as possible.</p>
</blockquote>

<p>Okay, let’s check the examples:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/5-resized.png" alt=""></p>

<p>I was able to copy the value in the password field without any problems, security is not a strong point of V UI:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/6-resized.png" alt=""></p>

<p>And these are official examples:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/7-resized.png" alt=""></p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/8-resized.png" alt=""></p>

<p>It’s hard for me to say where the authors saw the maximum similarity with the native UI.</p>

<p>The last part of this section sounds somewhat familiar:</p>

<blockquote>
  <p>Coming soon:</p>

  <ul>
    <li>a Delphi-like visual editor for building native GUI apps</li>
    <li>iOS support</li>
  </ul>
</blockquote>

<p>Again, promises that are <a href="https://web.archive.org/web/20200513204922/https://vlang.io/">three years old</a>.</p>

<h2 id="coroutines">Coroutines</h2>

<p>Сoroutines in V. From the very beginning, V copied Go, and if it’s easy to copy the syntax, then to copy goroutines you need to have very mature and senior developers. Therefore, from the very beginning, V builds its multithreading on threads with all the disadvantages.</p>

<p>But at some point the creator of the language thought, what’s stopping us from making coroutines. The coroutines were “done” in three commits:</p>

<ul>
  <li><a href="https://github.com/vlang/v/commit/45f16a2640d94202f98e32c5be67ba950662217f">all: coroutines (part 1)</a></li>
  <li><a href="https://github.com/vlang/v/commit/9db10c8f61c88625f33171cc9b4f2821af0a6678">all: coroutines (part 2)</a></li>
  <li><a href="https://github.com/vlang/v/commit/786865d34972b2bb53c66e0aaaad9af5cf8d76d1">coroutines: init() that runs automatically</a></li>
</ul>

<p>With a difference of 4 hours, an impressive speed of implementation.</p>

<p>Let’s see what kind of implementation coroutines have in V, stackless or stackful. The main implementation file is <a href="https://github.com/vlang/v/blob/45f16a2640d94202f98e32c5be67ba950662217f/vlib/coroutines/coroutines.v">coroutines/coroutines.v</a>.</p>

<p>Wait a minute, this is not the implementation I expected:</p>

<pre><code>#flag -I @VEXEROOT/thirdparty/photon
#flag @VEXEROOT/thirdparty/photon/photonwrapper.so

#include "photonwrapper.h"

fn C.photon_init_default() int
fn C.photon_thread_create11(f voidptr)
fn C.photon_sleep_s(n int)
fn C.photon_sleep_ms(n int)

// sleep is coroutine-safe version of time.sleep()
pub fn sleep(duration time.Duration) {
    C.photon_sleep_ms(duration.milliseconds())
}
</code></pre>

<p>What we see here are bindings for some third-party library. Here is the link to it: https://github.com/alibaba/PhotonLibOS. So, what we get is that coroutines in V are a 10-line wrapper over a third-party C++ library.</p>

<p>Well, okay, in the examples there is code that will help us understand the strengths of coroutines <a href="https://github.com/vlang/v/blob/master/examples/coroutines/simple_coroutines.v">simple_coroutines.v</a> (or not). The whole example is a couple of loops with a sleep calls. Well, let’s try to build it:</p>

<div><pre><code>v -use-coroutines ./examples/coroutines/simple_coroutines.v 
coroutines .so not found, downloading...
done!
</code></pre></div>

<p>Um, it downloads a dynamic library from somewhere unknown, but okay.</p>

<p>We get some output, but how do we understand that it is correct? The biggest difficulty of coroutines is context switching, that is, when one coroutine, for example, waits for a file to be read, and gives way to another coroutine. And here’s the problem: in V, the entire standard library is written in a synchronous manner.</p>

<p>Let’s, for example, look at <a href="https://github.com/vlang/v/blob/6cc51f254f6a6ea921726f6014107a7100ad97d1/vlib/os/os.c.v#L111">file read</a> in V:</p>

<pre><code>pub fn read_file(path string) !string {
  ...
  nelements := int(C.fread(str, 1, allocate, fp))
  ...
}
</code></pre>

<p>Here we see that V calls a C <code>read</code> function that reads a given number of bytes into the buffer. The problem is that <code>read</code> is a blocking function and the context will never be switched. One of the PhotonLibOS project maintainers <a href="https://github.com/alibaba/PhotonLibOS/issues/148#issuecomment-1761298839">says the same</a> about this. The same goes for the network, V also uses the blocking API from C.</p>

<p>And from this, it becomes clear that coroutines in V are not only a useless binding for a third-party lib, but also non-working as expected. Let’s see what their “author”, the creator of the language, says:</p>

<p>https://discord.com/channels/592103645835821068/592106336838352923/1165748025377960037</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/9-resized.png" alt=""></p>

<p>https://discord.com/channels/592103645835821068/592106336838352923/1160886627208544308</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/10-resized.png" alt=""></p>

<p>https://discord.com/channels/592103645835821068/697813437237166131/1138567669323415562</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/11-resized.png" alt=""></p>

<p>https://discord.com/channels/592103645835821068/592320321995014154/1116015948038672414</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/12-resized.png" alt=""></p>

<p>https://discord.com/channels/592103645835821068/592106336838352923/1160744638529933463</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/13-resized.png" alt=""></p>

<p>He lies about the last missing coroutine feature, when the coroutines simply don’t work as expected. He lies that coroutines work with IO. I’ll clarify that by working, I personally mean context switching when necessary, and not the fact that the program does not crash.</p>

<p>At the same time, nothing bothers him, and he is already planning to create a new framework for the web and publish links with headings about coroutines:</p>

<p>https://news.ycombinator.com/item?id=37174056</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/14-resized.png" alt=""></p>

<p>And most importantly, I only saw one person from the community who expressed the opinion that the current implementation of coroutines does not work. The rest of the core developers are apparently too busy to check the feature that comes first in <a href="https://github.com/vlang/v/releases/tag/0.4">CHANGELOG</a> version 0.4:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/15-resized.png" alt=""></p>

<p>And all this without touching on the fact that the creator of the language forces the language to depend on a corporation that at any moment can simply stop supporting the library. If V integrates IO and network from this library to get context switches, then it will be even worse. V will depend on this corporation not only at the coroutine level, but even at the level of simple operations like reading a file or requests over the network. Moreover, this library only supports two main operating systems (Linux and macOS), which means that code with coroutines loses all the flexibility that V has thanks to the C compiler.</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/16-resized.png" alt=""></p>

<p>Also, the author of the language <a href="https://discord.com/channels/592103645835821068/592106336838352923/1162727123472101416">doesn’t understand</a> that you can’t just do two versions of functions, because when you call a function in a coroutine, the function for the coroutine must be used, and if outside the coroutine, the usual one.</p>

<p>This library also does not fully support Windows, which means that V will only get coroutines on Windows if the authors of PhotonLibOS are so kind as to implement it.</p>



<p>Community V is an interesting phenomenon. If you go to the V Discord server, you are unlikely to find criticism of V or the author of the language there. And do you know why? Because the author of the language bans people for their opinions.</p>

<p>For example, I managed to “unsuccessfully” answer a person’s question in the V Telegram channel:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/17-resized.png" alt=""></p>

<p>For which I was immediately banned without explanation or attempt to show where I was wrong.</p>

<p>Next, to my post on the Discord server where I described the situation, I received responses from several people, one said that everything is not so clear, and we don’t know the whole truth, and the second called me a troll. About an hour later, the author of the language deleted all messages after my post and banned me without explanation also in Discord.</p>

<p>I want to clarify, this post has problems because I wrote it right after I was banned, and perhaps I could have been less arrogant:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/18-resized.png" alt=""></p>

<p>The creator of the language also <a href="https://discord.com/channels/592103645835821068/853624878556512266/1176019939551879268">called</a> me a troll:</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/19-resized.png" alt=""></p>

<p>Do you know why? Because he needed to justify himself to a person who directly stated that he did not approve of such behavior. Apologize? Admit mistake? No, this is not Alex’s way; his way is to dehumanize the victim by calling him a troll and banning anywhere.</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/20-resized.png" alt=""></p>

<p>And you know what’s the funniest thing? Today this person was banned. Why? Because he disagrees with the policy for which I was banned the first time and asked to remove his article from <a href="https://github.com/vlang/education-platform">vlang/education-platform</a>. This was the only article with content, <a href="https://github.com/vlang/education-platform/tree/master/lessons">the other two</a> consist of two phrases: “V is great.” and “In this lesson, we’ll examine one of the simplest codes in V.”, which were apparently written by Alex himself.</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/21-resized.png" alt=""></p>

<p>Another lie, Alex himself wrote to me in Telegram, not the moderator. He told me that I could come to him in a private message in Telegram, and he would have unbanned me. Think about it, first he bans you on two platforms even though you didn’t break the rules, and then he says that you could come in private messages, and he would unban you. Unfortunately, I can’t provide a screenshot, since Alex deleted all the messages (familiar behavior, isn’t it?) that he wrote to me when he realized that I was not ready to humiliate myself.</p>

<p>Today I was also banned for the third time, I created a specially new account to report that I was writing this article.</p>

<p><img src="https://n-skvortsov-1997.github.io/reviews/img/22-resized.png" alt=""></p>

<p>And also to see how far Alex would go to try to shut me up.</p>

<p>Well, the result of this is obvious, although today I was able to communicate with more people from the community than last time, and we even came to some kind of understanding. However, a few hours later Alex came and unceremoniously deleted all my messages and banned me. asvln’s messages were also deleted and he was banned.</p>

<p>It is also interesting that after the messages were deleted, none of those with whom I spoke expressed disturbance about the deletion and bans, and here either they agree with Alex’s actions, or they just don’t care what is happening in their community, or they are simply afraid to speak out something against Alex, as this will lead to their ban. <strong>And each option is worse than the other.</strong></p>

<p>Apparently the author of the language does not understand that trying to shut people up will only cause more damage. This time I’m documenting everything carefully.</p>

<p>Considering the fact that I have not seen criticism like this, all the brave souls here are banned. 3
years have passed, and nothing has changed, the author of other articles in which V is not praised as a divine creation was also <a href="https://christine.website/blog/vlang-update-2020-06-17/">banned</a>. And this is not the last example, here is a person <a href="https://twitter.com/MaxGraey/status/1430073855062814720">banned on Twitter</a> for arguing with the author of the language. I’m almost sure that there were dozens, maybe hundreds of such cases.</p>

<p>Do you want to be part of the community where banning for facts is ok, calling those who try to find out, compare or point out flaws as trolls is ok, and where the only correct opinion belongs to one person?</p>

<p>Me not.</p>

<p>I really want to see Alex’s Volt, which he promises people from 2019; apparently the main feature there will be the ability to ban people with the power of thought with automatic clearing of the chat. Beta was <a href="https://discord.com/channels/592103645835821068/708726848523075644/1109496090161594458">promised</a> in May 2023, but something went wrong and the author of the language simply <a href="https://discord.com/channels/592103645835821068/708726848523075644/1123052269227737241">ignores</a> people since then (another distinctive “feature” of Alex).</p>

<hr>

<p>As a result, the author of the language tried to shut me up, but got this article. I can already see how he is trying to justify himself by calling me a troll, a hater or something else, but whatever the reason for this article, all of the above are facts.</p>

<p>Of course, the author of the language will say that these problems are easy to fix (good luck). After a “week” Alex will say that they are fixed, but this does not solve the global problems in the language, when problems are fixed only when they are pointed out. Developers are not interested in looking for bugs on their own. And this is obvious because, apart from the compiler, they do not develop large projects on V on which they could quickly find all these problems.</p>

<p>Despite the fact that the language is almost 5 years old, you can still find very primitive problems that the language developers for some reason did not find before the users. The author of the language promises, as was the case with autofree, then postpones and promises again, and so on ad infinitum, how can one even trust such a person.</p>

<p>This is where the article ends; only you can decide whether V is worth spending time on. In this article, I have only scratched the surface of V; to describe everything that V is bad at, I would need to write a book. I hope that this article will help you make the right decision.</p>

<p>Bye.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Institutions try to preserve the problem to which they are the solution (1180 pts)]]></title>
            <link>https://effectiviology.com/shirky-principle/</link>
            <guid>39491863</guid>
            <pubDate>Sat, 24 Feb 2024 14:53:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://effectiviology.com/shirky-principle/">https://effectiviology.com/shirky-principle/</a>, See on <a href="https://news.ycombinator.com/item?id=39491863">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text"><p><img decoding="async" src="https://effectiviology.com/wp-content/uploads/Shirky-Principle.jpg" alt="" width="1000" height="667" srcset="https://effectiviology.com/wp-content/uploads/Shirky-Principle.jpg 1000w, https://effectiviology.com/wp-content/uploads/Shirky-Principle-300x200.jpg 300w, https://effectiviology.com/wp-content/uploads/Shirky-Principle-768x512.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></p><p>The <em>Shirky principle</em> is the adage that “institutions will try to preserve the problem to which they are the solution”. More broadly, it can also be characterized as the adage that “every entity tends to prolong the problem it is solving”.</p><p>For example, the Shirky principle means that a government agency that’s meant to address a certain societal issue may hinder attempts by others to address the issue, in order to ensure that the agency remains relevant. Alternatively, the agency may become so focused on the current way in which it addresses the issue that it will fail to adopt better new solutions as they become available, thus prolonging the issue.</p><p>The Shirky principle has important implications in various domains, so it’s important to understand it. As such, in the following article you will learn more about this principle, and see what you can do about it in practice.</p><div id="ez-toc-container"><nav><ul><li><a href="#Examples_of_the_Shirky_principle" title="Examples of the Shirky principle">Examples of the Shirky principle</a></li><li><a href="#Origin_and_formulations_of_the_Shirky_principle" title="Origin and formulations of the Shirky principle">Origin and formulations of the Shirky principle</a></li><li><a href="#Caveats_about_the_Shirky_principle" title="Caveats about the Shirky principle">Caveats about the Shirky principle</a></li><li><a href="#Accounting_for_the_Shirky_principle" title="Accounting for the Shirky principle">Accounting for the Shirky principle</a></li><li><a href="#Related_concepts" title="Related concepts">Related concepts</a></li><li><a href="#Summary_and_conclusions" title="Summary and conclusions">Summary and conclusions</a></li></ul></nav></div><h2><span id="Examples_of_the_Shirky_principle"></span>Examples of the Shirky principle<span></span></h2><p>An example of the Shirky principle are tax-filing companies who <a href="http://web.archive.org/web/20210509181435/https:/www.propublica.org/article/inside-turbotax-20-year-fight-to-stop-americans-from-filing-their-taxes-for-free">lobby</a> the government to <a href="http://web.archive.org/web/20210509175424/https:/www.propublica.org/article/filing-taxes-could-be-free-simple-hr-block-intuit-lobbying-against-it">prevent</a> it from <a href="http://web.archive.org/web/20210509181647/https:/www.politico.com/agenda/story/2018/07/18/tax-filing-congress-irs-000683/">offering</a> a free and easy way to <a href="http://web.archive.org/web/20210416223809/https:/www.nytimes.com/2015/04/16/technology/personaltech/turbotax-or-irs-as-tax-preparer-intuit-has-a-favorite.html">file taxes</a>, to ensure that the companies can continue to make a profit. A similar example of this are private prison companies who <a href="http://web.archive.org/web/20210509182458/https:/www.washingtonpost.com/posteverything/wp/2015/04/28/how-for-profit-prisons-have-become-the-biggest-lobby-no-one-is-talking-about/">lobby</a> the government to <a href="http://web.archive.org/web/20210509184717/https:/www.theguardian.com/commentisfree/2012/sep/27/lawmakers-lobbyists-keep-lock-private-prison-business">support</a> policies that <a href="http://web.archive.org/web/20210509185251/https:/escholarship.org/uc/item/3qj7q63d">increase</a> the number of <a href="http://web.archive.org/web/20210509185809/https:/papers.ssrn.com/sol3/papers.cfm?abstract_id=2794145">incarcerated</a> people and&nbsp;the <a href="https://doi.org/10.1002/9781118519639.wbecpx175">duration</a> of their incarceration.</p><p>Another <a href="https://sagepub.com/en-us/nam/encyclopedia-of-social-media-and-politics/book239101">well-known</a> example of the Shirky principle is described in “<a href="https://amzn.to/3tqsrZz">Cognitive Surplus</a>”, a book by Clay Shirky that contained one of the first discussions of this principle:</p><blockquote><p>“PickupPal.com is… a carpooling site designed to coordinate drivers and riders planning to travel along the same route.</p><p>In May 2008 the Ontario-based bus company Trentway-Wagar… petitioned the Ontario Highway Transport Board (OHTB) to shut PickupPal down on the grounds that, by helping coordinate drivers and riders, it worked too well to be a carpool. Trentway-Wagar invoked Section 11 of the Ontario Public Vehicles Act, which stipulated that carpooling could happen only between home and work (rather than, say, school or hospital.) It had to happen within municipal lines. It had to involve the same driver each day. And gas or travel expense could be reimbursed no more frequently than weekly.</p><p>Trentway-Wagar was arguing that because carpooling used to be inconvenient, it should always be inconvenient, and if that inconvenience disappeared, then it should be reinserted by legal fiat. Curiously, an organization that commits to helping society manage a problem also commits itself to the preservation of that same problem, as its institutional existence hinges on society’s continued need for its management. Bus companies provide a critical service—public transportation—but they also commit themselves, as Trentway-Wagar did, to fending off competition from alternative ways of moving people from one place to another.</p><p>The OHTB upheld Trentway-Wagar’s complaint and ordered PickupPal to stop operating in Ontario. PickupPal decided to fight the case—and lost in the hearing. But public attention became focused on the issue, and in a year of high gas prices, burgeoning environmental concern, and a financial downturn, almost no one took Trentway-Wagar’s side. The public reaction, channeled through everything from an online petition to T-shirt sales, had one message: Save PickupPal. The idea that people couldn’t use such a service was too hot for the politicians in Ontario to ignore. Within weeks of Trentway-Wagar’s victory, the Ontario legislature amended the Public Vehicles Act to make PickupPal legal again.”</p></blockquote><p>In addition, the Shirky principle can also apply to entities other than institutions. For example, an individual employee who’s in charge of a certain process in their workplace might resist attempts to automate that process, in order to ensure that the employee remains necessary to their employer.</p><p>A well-known example of the Shirky effect in this context is the <em>cobra effect</em>. It <a href="https://doi.org/10.1057/s41302-021-00187-7">describes</a> a <a href="http://web.archive.org/web/20210510110107/https:/freakonomics.com/podcast/the-cobra-effect-a-new-freakonomics-radio-podcast/">case</a> where British colonial officials in Delhi (India), set a bounty on dead cobras, in order to reduce the cobra population. However, this led citizens to breed the cobras for profit, and eventually to release them when the bounty was canceled.</p><p>A similar incident occurred circa 1902 in Hanoi (Vietnam), which was under French colonial rule at the time, when French officials sought to reduce the rat population in the city:</p><blockquote><p>“To fight the infestation citywide, the colonial administration added vigilantes to its team of professional killers. Appealing to both civic duty and to the pocketbook, a one-cent bounty was paid for each rat tail brought to the authorities (it was decided that the handing in of an entire rat corpse would create too much of a burden for the already taxed municipal health authorities).</p><p>Unfortunately, this scheme backfired. Despite initial apparent success, the authorities soon discovered that the best laid plans of mice and men often go awry. As soon the municipal administrators publicized the reward program, Vietnamese residents began to bring in thousands of tails. While many desk-bound administrators delighted in the numbers of apparently eliminated rats, more alert officials in the field began to notice a disturbing development. There were frequent sightings of rats without tails going about their business in the city streets. After some perplexity, the authorities realized that less-than-honest but quite resourceful characters were catching rats, but merely cutting off the tails and letting the still-living pests go free (perhaps to breed and produce more valuable tails).</p><p>Later, things became even more serious as health inspectors discovered a disturbing development in the suburbs of Hanoi. These officials found that more enterprising but equally deceptive individuals were actually raising rats to collect the bounty. One can only imagine the frustration of the municipal authorities, who realized that their best efforts at <em>dératisation</em> [extermination of rats] had actually increased the rodent population by indirectly encouraging rat-farming.”</p><p>— From “Of rats, rice, and race: The great Hanoi rat massacre, an episode in French colonial history” (Vann, <a href="https://doi.org/10.1353/fch.2003.0027">2003</a>)</p></blockquote><p>Finally, note that the phenomenon described by the Shirky principle—entities prolonging a problem to which they are the solution—isn’t necessarily the result of intentional actions. For example, a company may inadvertently perpetuate the problem that it solves, because its processes are so focused on the mediocre solution that they’re currently selling, that they don’t realize a better solution exists. Similarly, a company may discourage the use of a certain approach to solving a problem because it previously failed for them, even after technological advancements make this approach viable.</p><h2><span id="Origin_and_formulations_of_the_Shirky_principle"></span>Origin and formulations of the Shirky principle<span></span></h2><p>The Shirky principle was proposed in a <a href="http://web.archive.org/web/20210508141233/https:/kk.org/thetechnium/the-shirky-prin/">2010 blog post</a> by Kevin Kelly, editor of <em>Wired</em> magazine, who based it on the speaking and writing of scholar Clay Shirky.</p><p>Specifically, Kelly attributed the adage that “Institutions will try to preserve the problem to which they are the solution” to a statement that Shirky made in a recent talk, and noted that similar statements were made by Shirky in an associated blog post (“<a href="http://web.archive.org/web/20100404013927/http:/www.shirky.com/weblog/2010/04/the-collapse-of-complex-business-models/">The Collapse of Complex Business Models</a>”) and book (“<a href="https://amzn.to/3tqsrZz">Cognitive Surplus</a>”). There, Shirky states that “an organization that commits to helping society manage a problem also commits itself to the preservation of that same problem, as its institutional existence hinges on society’s continued need for its management”.</p><p>In addition to mentioning the key quote that is now known as the Shirky principle, Kelly also says the following in his <a href="http://web.archive.org/web/20210508141233/https:/kk.org/thetechnium/the-shirky-prin/">blog post</a>:</p><blockquote><p>“The Shirky Principle declares that complex solutions (like a company, or an industry) can become so dedicated to the problem they are the solution to, that often they inadvertently perpetuate the problem.”</p></blockquote><p>Later, he also says the following with regard to this principle (bold added here for emphasis):</p><blockquote><p>“In a strong sense we are defined by the problems we are solving. Yin/Yang, problem/solution, both sides form one unit. <strong>Because of the Shirky Principle, which says that every entity tends to prolong the problem it is solving</strong>, progress sometimes demands that we let go of problems.”</p></blockquote><p>Essentially, in his writing on the topic, Kelly offers three formulations of the Shirky principle, which differ in subtle but important ways:</p><ul><li>The first formulation—“Institutions will try to preserve the problem to which they are the solution”—refers to <em>institutions</em>, and states that they will <em>try</em> to preserve problems, which implies that they do so intentionally.</li><li>The second formulation—“Complex solutions (like a company, or an industry) can become so dedicated to the problem they are the solution to, that often they inadvertently perpetuate the problem”—refers to <em>complex solutions</em>, and states that they often <em>inadvertently</em> perpetuate the problem, which implies that they do so unintentionally.</li><li>The third formulation—”Every entity tends to prolong the problem it is solving”—refers to <em>entities</em>, and states that they <em>tend to</em> prolong problems, without making any claim about their intentions.</li></ul><p>The first formulation is the one that’s most commonly used when people discuss the Shirky principle, though Kelly does not actually refer to it as the Shirky principle in his original blog post. The third formulation, on the other hand, is the most general, though one issue with it is that it states that “every” entity engages in this kind of behavior, which is too absolute of a claim. However, this issue can be addressed by slightly changing this formulation, into “entities tend to prolong the problems they are solving”.</p><p><em>Note</em>: In <a href="http://web.archive.org/web/20210508141233/https:/kk.org/thetechnium/the-shirky-prin/">his post</a>, Kelly states that Shirky’s observation reminds him “of the clarity of the Peter Principle, which says that a person in an organization will be promoted to the level of their incompetence. At which point their past achievements will prevent them from being fired, but their incompetence at this new level will prevent them from being promoted again, so they stagnate in their incompetence.”.</p><h2><span id="Caveats_about_the_Shirky_principle"></span>Caveats about the Shirky principle<span></span></h2><p>There are some caveats about the Shirly principle that are important to keep in mind:</p><ul><li><strong>The Shirky principle is just a general observation.</strong> As such, there are many situations where it’s incorrect. For example, an institution may successfully solve the problem to which they are the solution because there’s greater profit to be made that way than by prolonging the problem.</li><li><strong>The Shirky principle can involve various types of entities.</strong> Though the best-known formulation of the Shirky principle refers to “institutions”, this principle can apply to various types of entities, including individuals and small social groups. This is noted in the general formulation of the principle (“every entity tends to prolong the problem it is solving”).</li><li><strong>The Shirky principle can involve various causes.</strong> For example, one company may prolong a problem unintentionally, due to passivity or inertia, whereas another company may prolong a problem intentionally, due to greed or self-preservation. This is reflected in the general formulation of this principle, which doesn’t make any claims regarding the causes or intentionality of this phenomenon.</li><li><strong>The Shirky principle can involve various patterns of behavior.</strong> For example, one company may prolong an existing problem by not dedicating resources to developing new solutions, whereas another company may actively prevent others from developing such solutions.</li></ul><p>In addition, the behaviors associated with the Shirly principle can vary in other ways. For example:</p><ul><li>An entity may not just preserve an existing problem, but also exacerbate it.</li><li>An entity may create a problem that did not previously exist, if they can be the solution to it.</li><li>An entity may perpetuate a problem that it benefits from, even if the entity is not actually a solution to the problem, though the entity may pretend that it is.</li></ul><p>Based on this, a broader version of Shirky’s principle can be expressed as:</p><blockquote><p>“Entities often promote problems that they benefit from”.</p></blockquote><h2><span id="Accounting_for_the_Shirky_principle"></span>Accounting for the Shirky principle<span></span></h2><p>Accounting for the Shirky principle can be beneficial when it comes to several things:</p><ul><li><strong>Understanding past and current behavior.</strong> For example, it can help you understand why certain institutions are seemingly so bad at solving certain problems, despite all the resources—like time, effort, and money—that they dedicate to those problems.</li><li><strong>Predicting future behavior.</strong> For example, it can help you predict that an executive will keep perpetuating a certain problem, in order to improve their own status within a company, even though this leads to worse outcomes for the company itself.</li><li><strong>Modifying behavior.</strong> For example, if this makes you aware of someone’s incentive to prolong a problem, that could lead you to either eliminate the perverse incentive or create a stronger disincentive. Similarly, this could lead you to point out the issue to the entity in question, in order to encourage them to try and change their behavior themselves if doing so can benefit them in the long term.</li></ul><p>When deciding how and whether to use your understanding of the Shirky principle in practice, it can help to assess relevant factors pertaining to your situation, such as what’s causing someone to act in accordance with this principle, and what outcomes their behavior leads to. For example, you will likely respond differently to a government agency that’s perpetuating a problem due to inefficient bureaucracy, than to a private company that’s perpetuating a problem out of greed, or to an individual who’s acting out of desperate self-preservation.</p><p>Finally, there are also two useful concepts worth keeping in mind when accounting for Shirky’s principle:</p><ul><li><a href="https://effectiviology.com/cui-bono/"><em><strong>Cui bono</strong></em></a>, which is a Latin phrase that means “who benefits?”, and which is used to suggest that there’s a high probability that those responsible for a certain event are the ones who stand to gain from it.</li><li><a href="https://effectiviology.com/hanlons-razor/"><em><strong>Hanlon’s razor</strong></em></a>, which is the adage that you should “never attribute to malice that which is adequately explained by stupidity”, and which, when applied broadly, suggests that when assessing people’s actions, you should not assume that they acted out of a desire to cause harm, as long as there is a reasonable alternative explanation.</li></ul><h2>Related concepts<span></span></h2><p><a href="https://effectiviology.com/parkinsons-law/"><em>Parkinson’s law</em></a> is the adage that “work expands so as to fill the time which is available for its completion” (or more generally, that “work expands to consume the resources available for its completion”). It relates to Shirky’s principle, since both concepts present a common way in which entities are inefficient or ineffective in dealing with problems that they’re supposed to solve.</p><p>Shirky’s principle also relates to another phenomenon that was <a href="https://doi.org/10.1088/1742-5468/2009/03/p03008">identified</a> by Parkinson, whereby the growth of a bureaucratic or administrative body is often associated with a substantial decrease in its overall efficiency. This is <a href="http://web.archive.org/web/20130331045219/http:/www.economist.com/node/14116121">attributed</a> to the desire of officials to increase the number of their subordinates, and to officials’ tendency to create work for each other.</p><p>In addition, a similar famous concept that’s related to Shirky’s principle has been expressed by novelist and social reformer Upton Sinclair, who <a href="http://web.archive.org/web/20210507155626/https:/www.oxfordreference.com/view/10.1093/acref/9780191826719.001.0001/q-oro-ed4-00010168">said</a> that “It is difficult to get a man to understand something when his salary depends on his not understanding it.”</p><h2><span id="Summary_and_conclusions"></span>Summary and conclusions<span></span></h2><ul><li>The <em>Shirky principle</em> is the adage that “institutions will try to preserve the problem to which they are the solution”.</li><li>For example, the Shirky principle means that a government agency that’s meant to address a certain societal issue may hinder attempts by others to address the issue, in order to ensure that the agency remains relevant.</li><li>This principle can be expressed more broadly as “every entity tends to prolong the problem it is solving”, since it can involve entities other than institutions (e.g., individuals), and various patterns of behavior (e.g., unintentionally focusing on an outdated solution vs. intentionally interfering with competition).</li><li>This principle can also be extended to say that “entities often promote problems that they benefit from”, since entities can also create new problems, exacerbate existing ones, and perpetuate problems that they don’t actually solve.</li><li>Accounting for this principle can help understand past and current behavior, predict future behavior, and modify problematic behaviors (e.g., by removing perverse incentives).</li></ul><hr> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every single new Google product (124 pts)]]></title>
            <link>https://twitter.com/MarcosBL/status/1761094858205229430</link>
            <guid>39491795</guid>
            <pubDate>Sat, 24 Feb 2024 14:45:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/MarcosBL/status/1761094858205229430">https://twitter.com/MarcosBL/status/1761094858205229430</a>, See on <a href="https://news.ycombinator.com/item?id=39491795">Hacker News</a></p>
Couldn't get https://twitter.com/MarcosBL/status/1761094858205229430: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Understanding, using, and finetuning Gemma (114 pts)]]></title>
            <link>https://lightning.ai/lightning-ai/studios/understanding-using-and-finetuning-gemma</link>
            <guid>39491646</guid>
            <pubDate>Sat, 24 Feb 2024 14:18:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lightning.ai/lightning-ai/studios/understanding-using-and-finetuning-gemma">https://lightning.ai/lightning-ai/studios/understanding-using-and-finetuning-gemma</a>, See on <a href="https://news.ycombinator.com/item?id=39491646">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>