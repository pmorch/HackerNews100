<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 24 Jul 2024 16:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[CrowdStrike offers a $10 apology gift card to say sorry for outage (109 pts)]]></title>
            <link>https://techcrunch.com/2024/07/24/crowdstrike-offers-a-10-apology-gift-card-to-say-sorry-for-outage/</link>
            <guid>41058261</guid>
            <pubDate>Wed, 24 Jul 2024 15:49:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/07/24/crowdstrike-offers-a-10-apology-gift-card-to-say-sorry-for-outage/">https://techcrunch.com/2024/07/24/crowdstrike-offers-a-10-apology-gift-card-to-say-sorry-for-outage/</a>, See on <a href="https://news.ycombinator.com/item?id=41058261">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">CrowdStrike, the cybersecurity firm <a href="https://techcrunch.com/2024/07/19/what-we-know-about-crowdstrikes-update-fail-thats-causing-global-outages-and-travel-chaos/">that crashed millions of computers with a botched update</a> all over the world last week, is offering its partners a $10 Uber Eats gift card as an apology, according to <a rel="nofollow" href="https://x.com/1337ice_cream/status/1815958499496472859?s=46&amp;t=lLf2YRXhv7kG_Tw6dp_nCA">several</a> <a rel="nofollow" href="https://x.com/hasminesita/status/1815856664568090836?s=46&amp;t=lLf2YRXhv7kG_Tw6dp_nCA">people</a> <a rel="nofollow" href="https://x.com/david__exe/status/1815908023296221372?s=46&amp;t=lLf2YRXhv7kG_Tw6dp_nCA">who</a> <a rel="nofollow" href="https://x.com/christappin/status/1816039053357375720?s=46&amp;t=lLf2YRXhv7kG_Tw6dp_nCA">say</a> <a rel="nofollow" href="https://x.com/keatonincyber/status/1815955882838221225?s=46&amp;t=lLf2YRXhv7kG_Tw6dp_nCA">they</a> received the gift card, as well as a source who also received one.</p>

<p>On Tuesday, a source told TechCrunch that they received an email from CrowdStrike offering them the gift card because the company recognizes “the additional work that the July 19 incident has caused.”&nbsp;</p>

	
	


<p>“And for that, we send our heartfelt thanks and apologies for the inconvenience,” the email read, according to a screenshot shared by the source. The <a rel="nofollow" href="https://x.com/64uni_lions/status/1815928437774995555?s=46&amp;t=lLf2YRXhv7kG_Tw6dp_nCA">same email</a> was also posted on X by someone else. “To express our gratitude, your next cup of coffee or late night snack is on us!”</p>

<figure><img decoding="async" width="1858" height="1542" src="https://techcrunch.com/wp-content/uploads/2024/07/crowdstrike-ubereats-voucher-gift-card.png?w=680" alt="" srcset="https://techcrunch.com/wp-content/uploads/2024/07/crowdstrike-ubereats-voucher-gift-card.png 1858w, https://techcrunch.com/wp-content/uploads/2024/07/crowdstrike-ubereats-voucher-gift-card.png?resize=150,124 150w, https://techcrunch.com/wp-content/uploads/2024/07/crowdstrike-ubereats-voucher-gift-card.png?resize=300,249 300w, https://techcrunch.com/wp-content/uploads/2024/07/crowdstrike-ubereats-voucher-gift-card.png?resize=768,637 768w, https://techcrunch.com/wp-content/uploads/2024/07/crowdstrike-ubereats-voucher-gift-card.png?resize=680,564 680w, https://techcrunch.com/wp-content/uploads/2024/07/crowdstrike-ubereats-voucher-gift-card.png?resize=1200,996 1200w, https://techcrunch.com/wp-content/uploads/2024/07/crowdstrike-ubereats-voucher-gift-card.png?resize=1536,1275 1536w" sizes="(max-width: 1858px) 100vw, 1858px"><figcaption>A screenshot of the email sent to partners by CrowdStrike after the July 19 incident (Image: TechCrunch)</figcaption></figure>

<p>The email was sent in the name of <a rel="nofollow" href="https://www.crowdstrike.com/about-crowdstrike/executive-team/daniel-bernard/">Daniel Bernard</a>, the company’s chief business officer, according to a screenshot of the email seen by TechCrunch According to <a rel="nofollow" href="https://x.com/david__exe/status/1815908023296221372?s=46&amp;t=lLf2YRXhv7kG_Tw6dp_nCA">one post</a> on X, in the United Kingdom the voucher was worth £7.75, or roughly $10 at today’s exchange rate.</p>

<p>On Wednesday, some of the people who posted about the gift card said that when they went to redeem the offer, they got an error message saying the voucher had been canceled. When TechCrunch checked the voucher, the Uber Eats page provided an error message that said the gift card “has been canceled by the issuing party and is no longer valid.”</p>

<p>CrowdStrike did not immediately respond to a request for comment.&nbsp;</p>

<p>On Friday, CrowdStrike released a faulty update that rendered around 8.5 million Windows devices unusable, <a rel="nofollow" href="https://blogs.microsoft.com/blog/2024/07/20/helping-our-customers-through-the-crowdstrike-outage/">according to Microsoft</a>. The update caused the affected computers to be stuck at the infamous “blue screen of death,” or BSOD, a bright blue error screen with a message that is shown when Windows crashed or cannot load because of a critical software failure.</p>

	
	



<p>The outage caused delays at airports in Amsterdam, Berlin, Dubai, and London, and <a rel="nofollow" href="https://x.com/US_Stormwatch/status/1814268813879206397">across the United States</a>. It also caused <a rel="nofollow" href="https://www.beckersspine.com/orthopedic-spine-practices-improving-profits/60138-hospitals-halt-non-urgent-surgeries-amid-global-it-outage.html#:~:text=Hospitals%20across%20the%20U.S.%20postponed,affecting%20computers%20and%20servers%20worldwide.">several</a> <a rel="nofollow" href="https://www.reuters.com/business/healthcare-pharmaceuticals/two-german-hospitals-cancel-elective-operations-citing-global-it-outage-2024-07-19/">hospitals</a> to halt surgeries, and paralyzed countless businesses all over the world.&nbsp;</p>
<div>
		<h4>Contact Us</h4><p>
		Do you have more information about the CrowdStrike outage? From a non-work device, you can contact Lorenzo Franceschi-Bicchierai securely on Signal at +1 917 257 1382, or via Telegram and Keybase @lorenzofb, or <a href="mailto:lorenzo@techcrunch.com/">email</a><a href="mailto:lorenzo@techcrunch.com/">.</a> You also can contact TechCrunch via <a href="https://techcrunch.com/got-a-tip/">SecureDrop</a>.	</p></div>
	

<p>Since the outage began on Friday, CrowdStrike has <a rel="nofollow" href="https://www.crowdstrike.com/falcon-content-update-remediation-and-guidance-hub/">regularly published updates</a> on its efforts to figure out what caused the mass outage. In an update on Wednesday, the company said that because of a bug during the process to check that updates are ready to be released to customer devices, the faulty code “passed validation despite containing problematic content data.”</p>

	
	


<p>The company also published apologies from its CEO George Kurtz, as well as its chief security officer Shawn Henry.&nbsp;</p>

<p>“All of CrowdStrike understands the gravity and impact of the situation,” Kurtz <a rel="nofollow" href="https://www.crowdstrike.com/falcon-content-update-remediation-and-guidance-hub/#:~:text=contacting%20CrowdStrike%20Support.-,Statement%20from%20our%20CEO,-Sent%202024%2D07">said in a message</a> published on the company’s site. “Nothing is more important to me than the trust and confidence that our customers and partners have put into CrowdStrike. As we resolve this incident, you have my commitment to provide full transparency on how this occurred and steps we’re taking to prevent anything like this from happening again.”</p>

<p>Henry <a rel="nofollow" href="https://www.linkedin.com/posts/shawn-henry-372bb74b_on-friday-we-failed-you-and-for-that-im-activity-7220983915421806592-VhPP/">wrote on Linkedin</a> that “we failed you, and for that I’m deeply sorry.”</p>

<p>“I’ve been in my professional life for almost 40 years, and my North Star has always been to ‘protect good people from bad things,’” Henry wrote. “The past two days have been the most challenging 48 hours for me over 12+ years. The confidence we built in drips over the years was lost in buckets within hours, and it was a gut punch.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Large Enough – Mistral AI (166 pts)]]></title>
            <link>https://mistral.ai/news/mistral-large-2407/</link>
            <guid>41058107</guid>
            <pubDate>Wed, 24 Jul 2024 15:32:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/mistral-large-2407/">https://mistral.ai/news/mistral-large-2407/</a>, See on <a href="https://news.ycombinator.com/item?id=41058107">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img src="https://mistral.ai/images/news/mistral-large-2407/mistral-large-mini.png" alt="Detailed benchmarks" width="5%"></p><p>This latest generation continues to push the boundaries of cost efficiency, speed, and performance. Mistral Large 2 is exposed on la Plateforme and enriched with new features to facilitate building innovative AI applications.</p><h3 id="mistral-large-2">Mistral Large 2</h3><p>Mistral Large 2 has a 128k context window and supports dozens of languages including French, German, Spanish, Italian, Portuguese, Arabic, Hindi, Russian, Chinese, Japanese, and Korean, along with 80+ coding languages including Python, Java, C, C++, JavaScript, and Bash.</p><p>Mistral Large 2 is designed for single-node inference with long-context applications in mind – its size of 123 billion parameters allows it to run at large throughput on a single node.
We are releasing Mistral Large 2 under the <a href="https://mistral.ai/licenses/MRL-0.1.md">Mistral Research License</a>, that allows usage and modification for research and non-commercial usages.</p><h5 id="general-performance">General performance</h5><p>Mistral Large 2 sets a new frontier in terms of performance / cost of serving on evaluation metrics. In particular, on MMLU, the pretrained version achieves an accuracy of 84.0%, and sets a new point on the performance/cost Pareto front of open models.</p><h5 id="code--reasoning">Code &amp; Reasoning</h5><p>Following our experience with <a href="https://mistral.ai/news/codestral/">Codestral 22B</a> and <a href="https://mistral.ai/news/codestral-mamba/">Codestral Mamba</a>, we trained Mistral Large 2 on a very large proportion of code. Mistral Large 2 vastly outperforms the previous Mistral Large, and performs on par with leading models such as GPT-4o, Claude 3 Opus, and Llama 3 405B.</p><p><img src="https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-performance.png" alt="Detailed benchmarks" width="100%"></p><p>A significant effort was also devoted to enhancing the model’s reasoning capabilities. One of the key focus areas during training was to minimize the model’s tendency to “hallucinate” or generate plausible-sounding but factually incorrect or irrelevant information. This was achieved by fine-tuning the model to be more cautious and discerning in its responses, ensuring that it provides reliable and accurate outputs.</p><p>Additionally, the new Mistral Large 2 is trained to acknowledge when it cannot find solutions or does not have sufficient information to provide a confident answer. This commitment to accuracy is reflected in the improved model performance on popular mathematical benchmarks, demonstrating its enhanced reasoning and problem-solving skills:</p><p><img src="https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-code-generation.png" alt="Detailed benchmarks" width="100%"></p><p>Performance accuracy on code generation benchmarks (all models were benchmarked through the same evaluation pipeline)</p><p><img src="https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-multiple.png" alt="Detailed benchmarks" width="100%"></p><p>Performance accuracy on MultiPL-E (all models were benchmarked through the same evaluation pipeline, except for the "paper" row)</p><div><p><img src="https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-code-generation-2.png" alt="Detailed benchmarks" width="100%"></p><p>Performance accuracy on GSM8K (8-shot) and MATH (0-shot, no CoT) generation benchmarks (all models were benchmarked through the same evaluation pipeline)</p></div><h5 id="instruction-following--alignment">Instruction following &amp; Alignment</h5><p>We drastically improved the instruction-following and conversational capabilities of Mistral Large 2. The new Mistral Large 2 is particularly better at following precise instructions and handling long multi-turn conversations. Below we report the performance on MT-Bench, Wild Bench, and Arena Hard benchmarks:</p><div><p><img src="https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-instruction.png" alt="Detailed benchmarks" width="100%"></p><p>Performance on general alignment benchmarks (all models were benchmarked through the same evalutation pipeline)</p></div><p>On some benchmarks, generating lengthy responses tends to improve the scores. However, in many business applications, conciseness is paramount – short model generations facilitate quicker interactions and are more cost-effective for inference. This is why we spent a lot of effort to ensure that generations remain succinct and to the point whenever possible. The graph below reports the average length of generations of different models on questions from the MT Bench benchmark:</p><p><img src="https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-mtbench.png" alt="MT Bench benchmarks" width="100%"></p><h5 id="language-diversity">Language diversity</h5><p>A large fraction of business use cases today involve working with multilingual documents. While the majority of models are English-centric, the new Mistral Large 2 was trained on a large proportion of multilingual data. In particular, it excels in English, French, German, Spanish, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, Korean, Arabic, and Hindi. Below are the performance results of Mistral Large 2 on the multilingual MMLU benchmark, compared to the previous Mistral Large, Llama 3.1 models, and to Cohere’s Command R+.</p><p><img src="https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-mmlu.png" alt="Detailed benchmarks" width="70%"></p><div><p><img src="https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-language-diversity.png" alt="Detailed benchmarks" width="100%"></p><p>Performance on Multilingual MMLU (measured on the base pretrained model)</p></div><h5 id="tool-use--function-calling">Tool Use &amp; Function Calling</h5><p>Mistral Large 2 is equipped with enhanced function calling and retrieval skills and has undergone training to proficiently execute both parallel and sequential function calls, enabling it to serve as the power engine of complex business applications.</p><p><img src="https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-tool-use.png" alt="Detailed benchmarks" width="100%"></p><h5 id="try-mistral-large-2-on-la-plateforme">Try Mistral Large 2 on la Plateforme</h5><p>You can use Mistral Large 2 today via <a href="https://console.mistral.ai/">la Plateforme</a> under the name <code>mistral-large-2407</code>, and test it on le Chat. It is available under the version 24.07 (a YY.MM versioning system that we are applying to all our models), and the API name <code>mistral-large-2407</code>. Weights for the instruct model are <a href="https://models.mistralcdn.com/mistral-large-2407/mistral-large-instruct-2407.tar">available</a> and are also hosted on <a href="https://huggingface.co/mistralai/Mistral-Large-Instruct-2407">HuggingFace</a>.</p><p>we are consolidating the offering on la Plateforme around two general purpose models, Mistral Nemo and Mistral Large, and two specialist models, Codestral and Embed. As we progressively deprecate older models on la Plateforme, all Apache models (Mistral 7B, Mixtral 8x7B and 8x22B, Codestral Mamba, Mathstral) remain available for deployment and fine-tuning using our SDK mistral-inference and mistral-finetune.</p><p>Starting today, we are extending fine-tuning capabilities on la Plateforme: those are now available for Mistral Large, Mistral Nemo and Codestral.</p><h5 id="access-mistral-models-through-cloud-service-providers">Access Mistral models through cloud service providers</h5><p>We are proud to partner with leading cloud service providers to bring the new Mistral Large 2 to a global audience. In particular, today we are expanding our partnership with Google Cloud Platform to bring Mistral AI’s models on <a href="https://cloud.google.com/blog/products/ai-machine-learning/codestral-and-mistral-large-v2-on-vertex-ai?e=48754805&amp;hl=en">Vertex AI</a> via a Managed API. Mistral AI’s best models are now available on Vertex AI, in addition to Azure AI Studio, Amazon Bedrock and IBM watsonx.ai.</p><h5 id="availability-timeline-of-mistral-ai-models">Availability timeline of Mistral AI models</h5><p><img src="https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-availability.png" alt="Detailed benchmarks" width="100%"></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google is the only search engine that works on Reddit now thanks to AI deal (160 pts)]]></title>
            <link>https://www.404media.co/google-is-the-only-search-engine-that-works-on-reddit-now-thanks-to-ai-deal/</link>
            <guid>41057033</guid>
            <pubDate>Wed, 24 Jul 2024 13:41:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/google-is-the-only-search-engine-that-works-on-reddit-now-thanks-to-ai-deal/">https://www.404media.co/google-is-the-only-search-engine-that-works-on-reddit-now-thanks-to-ai-deal/</a>, See on <a href="https://news.ycombinator.com/item?id=41057033">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
<!--kg-card-begin: html-->
  <div>
    <h5>Subscribe</h5>
    <div>
      <p>Join the newsletter to get the latest updates.</p>
      <form data-members-form="subscribe">
        
        
        <div>
          
          <p>
            Great! Check your inbox and click the link.
          </p>
        </div>
        <div>
          
          <p>
            Please enter a valid email address.
          </p>
        </div>
      </form>
    </div>
  </div>

<!--kg-card-end: html-->
<div><p>🖥️</p><p><i><em>404 Media is an independent website whose work is written, reported, and owned by human journalists and whose intended audience is real people, not AI scrapers, bots, or a search algorithm. Sign up to support our work and for free access to this article. </em></i><a href="https://www.404media.co/why-404-media-needs-your-email-address/" rel="noreferrer"><i><em>Learn why we require this here</em></i></a><i><em>.</em></i></p></div><p>Google is now the only search engine that can surface results from Reddit, making one of the web’s most valuable repositories of user generated content exclusive to the internet’s already dominant search engine.</p><p>If you use Bing, DuckDuckGo, Mojeek, Qwant or any other alternative search engine that doesn’t rely on Google’s indexing and search Reddit by using “site:reddit.com,” you will not see any results from the last week. DuckDuckGo is currently turning up seven links when searching Reddit, but provides no data on where the links go or why, instead only saying that “We would like to show you a description here but the site won't allow us.” Older results will still show up, but these search engines are no longer able to “crawl” Reddit, meaning that Google is the only search engine that will turn up results from Reddit going forward. Searching for Reddit still works on <a href="https://www.404media.co/friendship-ended-with-google-now-kagi-is-my-best-friend/" rel="noreferrer">Kagi</a>, an independent, paid search engine that buys part of its search index from Google.</p><p>The news shows how Google’s near monopoly on search is now actively hindering other companies’ ability to compete at a time when Google is facing increasing criticism over the quality of its search results. And while neither Reddit or Google responded to a request for comment, it appears that the exclusion of other search engines is the result of a multi-million dollar deal that gives Google the right to scrape Reddit for data to train its AI products.</p><p>“They’re [Reddit] killing everything for search but Google,” Colin Hayhurst, CEO of the search engine Mojeek told me on a call.&nbsp;</p>
</div><div>
  <div>
    <h2>This post is for paid members only</h2>
    <p>Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.</p>
    <p><a href="https://www.404media.co/membership/">Subscribe</a>
  </p></div>
  <div>
    <h2>Sign up for free access to this post</h2>
    <p>Free members get access to posts like this one along with an email round-up of our week's stories.</p>
    <p><a href="https://www.404media.co/signup/">Subscribe</a>
  </p></div>
  <p>Already have an account? <a href="https://www.404media.co/signin/" data-portal="signin">Sign in</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You got a null result. Will anyone publish it? (122 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-024-02383-9</link>
            <guid>41056387</guid>
            <pubDate>Wed, 24 Jul 2024 12:35:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-024-02383-9">https://www.nature.com/articles/d41586-024-02383-9</a>, See on <a href="https://news.ycombinator.com/item?id=41056387">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>Evolutionary biologist Natalie Pilakouta thought it would be an easy theory to test: fish living in Iceland’s geothermal hot springs prefer warmer water than do members of the same species that live in cooler lakes nearby. Yet, when she came to the end of her two-year study, what she found was inconclusive — given the choice, both populations of fish preferred the same, cooler waters. Her postdoctoral supervisor urged her to set aside the findings and move on to other studies: “It’s a failed experiment,” she was told. “You must have done something wrong.”</p><p>The words stung because publications are a crucial piece of academic currency, particularly for an early-career researcher, and she knew she’d face an uphill struggle to find a home for her results. Moreover, she felt a sense of urgency to share the counter-intuitive findings, which undermine the assumption that aquatic life might evolve a preference for higher temperatures in response to global warming.</p><p>Pilakouta, who is based at the University of St Andrews, UK, was one of the lucky ones. After submitting her findings to seven journals over six years, her study was finally published<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup> in January 2023. But her experience illustrates <a href="https://www.nature.com/articles/d41586-024-01389-7" data-track="click" data-label="https://www.nature.com/articles/d41586-024-01389-7" data-track-category="body text link">academia’s oft-bemoaned ‘file-drawer problem’</a>, in which findings with null or negative results — those that fail to find a relationship between variables or groups, or that go against the preconceived hypothesis — gather dust in favour of studies with positive or significant findings. A 2022 survey of scientists in France, for instance, found that 75% were willing to publish null results they had produced, but only 12.5% were able to do so<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>. Over time, this bias in publications distorts the scientific record, and a focus on significant results can encourage researchers to selectively report their data or exaggerate the statistical importance of their findings. It also wastes time and money, because researchers might duplicate studies that had already been conducted but not published. Some evidence suggests that the problem is getting worse, with fewer negative results seeing the light of day<sup><a href="#ref-CR3" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">3</a></sup> over time.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-024-01389-7" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02383-9/d41586-024-02383-9_27154836.jpg"><p>Illuminating ‘the ugly side of science’: fresh incentives for reporting negative results</p></a>
 </article><p>Funders, publishers and researchers are not sitting idle. Many journals now encourage teams to submit plans and protocols for experiments before conducting them, so that the journals can review the proposals and commit to publishing the results, whatever the outcome. Hundreds of journals now offer such ‘registered reports’, and the number of journals adopting this approach has doubled since 2018.</p><p>A laser focus on positive results is not the only way to do science, says Brian Nosek, executive director of the Center for Open Science in Charlottesville, Virginia. Nosek and a constellation of researchers across the world have been pushing to rewrite how research is conducted, challenging the very definition of success. This includes a crackdown on the nefarious side of science — misconduct such as plagiarism — but also a call to curb some of the ‘softer’ transgressions such as selective reporting, with a view to <a href="https://www.nature.com/articles/d41586-023-02876-z" data-track="click" data-label="https://www.nature.com/articles/d41586-023-02876-z" data-track-category="body text link">publishing more negative findings</a>. These changes have started to materialize across the publishing industry, as preprint servers proliferate and publishers adopt new manuscript formats, launch journals dedicated to null results and call for special issues.</p><p>“We can surely do better,” Nosek says.</p><h2><b>Hidden results</b></h2><p>Researchers have noted the file-drawer problem for decades. But the bigger problems it was causing did not become clear until the early 2010s, when they set out to reproduce the findings of several foundational experiments in psychology and medical science, and found that they could not. Scientists began to study the extent of this ‘replication crisis’ and the problem of publication bias.</p><p>Their research laid bare just how often negative results were being buried. In an analysis of more than 300,000 scientific conference presentations, informal posters or talks that scientists often endeavour to turn into papers, fewer than 40% were published in peer-reviewed journals, and negative or null findings were far less likely to be published than positive results<sup><a href="#ref-CR4" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">4</a></sup>.</p><p>The extent of publication bias varies by discipline and by country, but the problem seems to have worsened over time. An analysis of 4,600 papers from 1990 to 2007 found that publication bias had increased by 22% over that period<sup><a href="#ref-CR3" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">3</a></sup>.</p><p>There could be real-world implications to such a skew in publications. Among 74 registered clinical trials evaluating antidepressants, for example, nearly one-third remained unpublished; these trials were much more likely to show negative than positive results<sup><a href="#ref-CR5" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">5</a></sup>. Judging by the publications alone, 94% of the trials looked as if they returned positive results, whereas a drug-approval panel judged that 51% did.</p><p>This selective reporting creates an inflated perception of drug efficacies, one compounded by meta-analyses — surveys of the published literature — that contain mainly studies with positive results.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-02876-z" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02383-9/d41586-024-02383-9_27374058.jpg"><p>How early-career researchers can learn to trust negative data: five simple steps</p></a>
 </article><p>The bias is present despite the fact that investigators conducting clinical trials in the United States are mandated by law to report their results, regardless of outcome; there can be billions of dollars at stake and trial participants who have given their time and expect the results to be published. These results illustrate “how high a hill there is to climb”, Nosek says.</p><p>Adding to the likelihood of bias, studies with negative or null findings are often given stricter scrutiny than those with positive findings, especially if the positive findings “confirm something we think is true”, says Steven Goodman, founder of the Stanford Program on Research Rigor and Reproducibility at the Stanford School of Medicine in California.</p><p>Jessica Payne, a cognitive neuroscientist at the University of Notre Dame in South Bend, Indiana, says that there’s still a perception that scientists must have had some flaw in their research design if a study returns negative or null results.</p><p>Indeed, according to a survey of 480 economists<sup><a href="#ref-CR6" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">6</a></sup>, studies with null results are perceived to be less publishable, of lower quality and less important than studies with large and significant results, even when features such as sample size are held constant — a phenomenon known as the null result penalty. If anything, Goodman says, a study with a large effect size should be scrutinized much more than one with a null finding.</p><h2><b>Cultural bias </b></h2><p>The replication crisis made one fact crystal clear: incentive structures in academia are not always in line with research integrity and reproducibility. That has a large role in why so few negative studies are published, says Anne Scheel, a metascientist at Utrecht University in the Netherlands.</p><p>At the crux of both academic misconduct and publication bias is the same ‘publish or perish’ culture, perpetuated by academic institutions, research funders, scholarly journals and scientists themselves, that rewards researchers when they publish findings in prestigious venues, Scheel says.</p><p>But these academic gatekeepers have biases, say some critics, who argue that funders and top-tier journals often crave novelty and attention-grabbing findings. Journal editors worry that pages full of null results will attract fewer readers, says Simine Vazire, a psychologist at the University of Melbourne in Australia and editor of the journal <i>Psychological Science</i>.</p><p>This creates a tight feedback loop between researchers and journals. To attract journals with findings that seem new and noteworthy, some scientists might be tempted to change their hypothesis after seeing the results, or to release only a portion of the data, or to perform statistical tricks, Nosek says.</p><h2><b>Positive solutions</b></h2><p>To encourage more researchers to report null results, journals and funders are trying several schemes. One of the most significant changes to come out of the replication crisis is the expansion of preregistration (see ‘Registrations on the rise’), in which researchers must state their hypothesis and the outcomes they intend to measure in a public database at the outset of their study (this is already the norm in clinical trials).</p><figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-024-02383-9/d41586-024-02383-9_27365096.png?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-024-02383-9/d41586-024-02383-9_27365096.png?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="REGISTRATIONS ON THE RISE. Chart shows the number of study plans uploaded by researchers is increasing each year." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-024-02383-9/d41586-024-02383-9_27365096.png">
  <figcaption>
   <p><span>Source: OSF.IO</span></p>
  </figcaption>
 </picture>
</figure><p>The preregistration model nudges researchers to be faithful to the original intent of their study, but it doesn’t address biases that might affect whether they submit their findings to a journal, nor the biases of journal editors and reviewers in deciding what to publish, Nosek says.</p><p>Instead, he and his colleagues have been focusing on promoting and evaluating the registered report model — similar to a preregistered report, but with the initial plan published by a journal, along with a commitment to peer-review and publish the results.</p><p>Preliminary data look promising: when Scheel and her colleagues compared the results of 71 registered reports with a random sample of 152 standard psychology manuscripts, they found that 44% of the registered reports had positive results, compared with 96% of the standard publications<sup><a href="#ref-CR7" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">7</a></sup> (see ‘Intent to publish’). And Nosek and his colleagues found that reviewers scored psychology and neuroscience registered reports higher on metrics of research rigour and quality compared with papers published under the standard model<sup><a href="#ref-CR8" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">8</a></sup>.</p><figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-024-02383-9/d41586-024-02383-9_27365092.png?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-024-02383-9/d41586-024-02383-9_27365092.png?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="INTENT TO PUBLISH. Chart shows registered reports are much more likely to yield negative results" loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-024-02383-9/d41586-024-02383-9_27365092.png">
  <figcaption>
   <p><span>Source: Ref. 7</span></p>
  </figcaption>
 </picture>
</figure><p>When the format launched in 2012, only a handful of journals published registered reports; now more than 300 offer the format, including <i>PLoS ONE</i> and <i>Nature</i>, which is published by Springer Nature (<i>Nature</i>’s news team is editorially independent from its journal team). Since starting to offer the format in February 2023, <i>Nature</i> has yet to publish any registered reports, but its sibling journal <a href="https://www.nature.com/nathumbehav/research-articles?type=registered-report" data-track="click" data-label="https://www.nature.com/nathumbehav/research-articles?type=registered-report" data-track-category="body text link"><i>Nature Human Behaviour</i> has</a>.</p><p>Although the format has gained in popularity, there are still some kinks to be ironed out, researchers say. Earlier this year, Christine Blume, a sleep researcher at the University of Basel in Switzerland, published her first registered report<sup><a href="#ref-CR9" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">9</a></sup> on how light affects human circadian rhythms in <i>Nature Human Behaviour.</i> Although she liked receiving feedback on her study design before data collection — “it made me feel that I had the best study design to answer the question I set out to address,” she says — she found it frustrating that the feedback process can span months, even though researchers have a limited time in which to spend grant money.</p><p>These practical concerns are important to address, Nosek says. He admits that his own paper about the quality of registered reports<sup><a href="#ref-CR8" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">8</a></sup> was not itself a registered report, because the grant money was expiring and the team didn’t have time to go through a lengthy approval process and complete its analysis. “We cannot dismiss pragmatics, but what we can do is think about how we lower the barrier so that more of these circumstances can be dealt with,” he says.</p><p>Journals that offer registered reports are not spread equally across disciplines; most are in psychology and, more recently, neuroscience. Few physical-science journals offer the format — even though null results, such as the failure of the Large Hadron Collider near Geneva in Switzerland to find new subatomic particles since the Higgs boson, have been an important part of progress. Emily Sena, a translational-medicine researcher and metascientist at the University of Edinburgh, UK, says that few academics in preclinical fields have been keen to try the format, especially when there is already so much red tape before researchers can begin their experiments.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-024-01347-3" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02383-9/d41586-024-02383-9_27374054.jpg"><p>Disputed dark-matter claim to be tested by new lab in South Korea</p></a>
 </article><p>The format has been slow to catch on among researchers, says Vazire. “We’re not receiving many registered-report submissions.”</p><p>Sena and her colleagues have been spreading the word about registered reports and helping journal editors to feel equipped to review submissions, she says. Some funders are providing cash incentives: in 2022, the <a href="https://www.cos.io/blog/funding-consciousness-research" data-track="click" data-label="https://www.cos.io/blog/funding-consciousness-research" data-track-category="body text link">Center for Open Science</a> offered up to US$50,000 to consciousness researchers willing to publish a registered report for their work.</p><p>It will be important to track how these interventions affect marginalized groups in academia, Sena says. Academics of colour are more likely to be on a fixed contract, so they have less wiggle room to embrace formats that might be better for science overall but less helpful for individual scientists, she says.</p><p>The Center for Open Science is planning to run trials in which researchers are randomly assigned to use either the standard publication model or a registered report, to evaluate the rigour, acceptance rate and timelines of the resulting publications. Results are expected by 2027.</p><p>Not every effort to reduce publication bias has borne fruit. One that has seldom worked, Nosek says, is to set up journals with the express purpose of publishing null results. These efforts are well intentioned, he says, but often do not work because a journal can become identified with studies that weren’t able to be published elsewhere. “It can’t provide the reward that researchers need,” he says.</p><p>Payne was a co-editor at one of these journals, <i>Experimental Results</i>, published by Cambridge University Press. After only three years, the journal ceased publication in 2023 despite carrying the “imprimatur of Cambridge”, she says.</p><p>There’s an increasingly popular do-it-yourself route to publishing negative results: posting a manuscript on a preprint server. Publishing a preprint can offer an opportunity to showcase research without the pressure of journal submission. This option can be especially helpful for early-career researchers, Pilakouta says. Still, it takes time to write up a result, regardless of where it appears, and publishing on preprint servers is unlikely to offer researchers enough of an incentive to justify the time, Goodman says.</p><h2><b>Null nuance</b></h2><p>Advocates acknowledge that not every study that returns a null result is worthy of publishing. Goodman says he encourages researchers to publish null and negative findings that are “informative”, meaning they come from studies and analyses that are designed rigorously, question previous results and open up fresh areas for exploration.</p><p>For example, there is a long-held idea that the womb is sterile — that the uterus and fetus are free of microorganisms. But, beginning in 2010, a series of papers found microbial contamination in the placenta, calling the hypothesis into question and suggesting that some complications of pregnancy could be linked to bacteria. It wasn’t until 2019 that a study of placental samples from 537 women — by far the largest number in an analysis of this kind — rigorously showed the absence of any bacterial signal. That study set a benchmark for investigating the microbiome of tissues that carry few microorganisms and that can therefore give rise to false-positive results, and suggested that bacterial infection is not a common cause of problems in pregnancy<sup><a href="#ref-CR10" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">10</a></sup>.</p><p>Blume says it’s important to extract something insightful from the data, even if they are inconclusive. For example, in 2022 she found that although artificial light suppresses the hormone melatonin, that didn’t equate to a change in sleep quality<sup><a href="#ref-CR11" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">11</a></sup>. The message that melatonin isn’t necessarily a proxy for sleep quality might have helped that study to get published, she says.</p><p>As long as researchers continue to seek publication in prestigious outlets, publication bias won’t go away, Goodman predicts. Still, he is surprised at how much progress has been made in the past decade: top-tier journals pledging to accept rigorous studies, regardless of outcome, would have been “unheard of” even five or ten years ago, he says.</p><p>Pilakouta now leads a laboratory and can set an example for her undergraduate and graduate students. But she’s also seen first-hand how deeply engrained the thirst for positive findings is. “It concerns me how early it starts,” she says. Next time she gets a null result, she says, she’s hopeful that it won’t take seven years to publish it.</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Micromouse (129 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Micromouse</link>
            <guid>41055230</guid>
            <pubDate>Wed, 24 Jul 2024 09:36:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Micromouse">https://en.wikipedia.org/wiki/Micromouse</a>, See on <a href="https://news.ycombinator.com/item?id=41055230">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div lang="en" dir="ltr" id="mw-content-text">
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Micromouse_maze.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Micromouse_maze.jpg/220px-Micromouse_maze.jpg" decoding="async" width="220" height="165" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Micromouse_maze.jpg/330px-Micromouse_maze.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Micromouse_maze.jpg/440px-Micromouse_maze.jpg 2x" data-file-width="4224" data-file-height="3168"></a><figcaption>Micromouse maze</figcaption></figure>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Micromouse_Green_Giant_V1.3.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Micromouse_Green_Giant_V1.3.jpg/220px-Micromouse_Green_Giant_V1.3.jpg" decoding="async" width="220" height="147" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Micromouse_Green_Giant_V1.3.jpg/330px-Micromouse_Green_Giant_V1.3.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Micromouse_Green_Giant_V1.3.jpg/440px-Micromouse_Green_Giant_V1.3.jpg 2x" data-file-width="1280" data-file-height="853"></a><figcaption>Micromouse robot</figcaption></figure>
<p><b>Micromouse</b> is an event where small <a href="https://en.wikipedia.org/wiki/Robot" title="Robot">robotic</a> mice compete to solve a 16×16 <a href="https://en.wikipedia.org/wiki/Maze" title="Maze">maze</a>. It began in the late 1970s.<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> Events are held worldwide, and are most popular in the <a href="https://en.wikipedia.org/wiki/United_Kingdom" title="United Kingdom">UK</a>, <a href="https://en.wikipedia.org/wiki/United_States" title="United States">U.S.</a>, <a href="https://en.wikipedia.org/wiki/Japan" title="Japan">Japan</a>, <a href="https://en.wikipedia.org/wiki/Singapore" title="Singapore">Singapore</a>, <a href="https://en.wikipedia.org/wiki/India" title="India">India</a>, <a href="https://en.wikipedia.org/wiki/South_Korea" title="South Korea">South Korea</a> and becoming popular in subcontinent countries such as <a href="https://en.wikipedia.org/wiki/Sri_Lanka" title="Sri Lanka">Sri Lanka</a>.
</p><p>The maze is made up of a 16×16 grid of cells, each 180&nbsp;mm square with walls 50&nbsp;mm high.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup> The mice are completely <a href="https://en.wikipedia.org/wiki/Autonomous_robot" title="Autonomous robot">autonomous robots</a> that must find their way from a predetermined starting position to the central area of the maze unaided. The mouse needs to keep track of where it is, discover walls as it explores, map out the maze and detect when it has reached the goal. Having reached the goal, the mouse will typically perform additional searches of the maze until it has found an optimal route from the start to the finish. Once the optimal route has been found, the mouse will traverse that route in the shortest achievable time.
</p><p>Competitions<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup><sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup> and conferences<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup> are run regularly.
</p>
<meta property="mw:PageProp/toc">
<div><h2 id="Half-Size_Micromouse">Half-Size Micromouse</h2><p><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Micromouse&amp;action=edit&amp;section=1" title="Edit section: Half-Size Micromouse"><span>edit</span></a><span>]</span></span></p></div>
<p>A version of Micromouse called the Half-Size Micromouse was introduced at the 30th All Japan Micromouse Competition in 2009.<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup><sup id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup> Instead of a 16×16 maze, the Half-Size competition uses up to a 32×32 maze. Cell and wall dimensions have been reduced by half,<sup id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup> providing a new challenge.
</p><p>There have been half-size competitions in Europe in Hungary in 2015<sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup> and the UK in 2018.<sup id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup>
</p>


<p>Mice used in competitions employ the fundamental elements of <a href="https://en.wikipedia.org/wiki/Robot_navigation" title="Robot navigation">robot navigation</a>, including mapping, planning, and localization. Additionally, they optimize their path through the maze using various <a href="https://en.wikipedia.org/wiki/Search_algorithm" title="Search algorithm">search algorithms</a>. Common search algorithms use variations of the Bellman <a href="https://en.wikipedia.org/wiki/Flood_fill" title="Flood fill">flood-fill</a> method,<sup id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup> <a href="https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm" title="Dijkstra's algorithm">Dijkstra's algorithm</a>, <a href="https://en.wikipedia.org/wiki/A*_search_algorithm" title="A* search algorithm">A* search algorithm</a>, among various <a href="https://en.wikipedia.org/wiki/Graph_traversal" title="Graph traversal">graph traversal</a> and <a href="https://en.wikipedia.org/wiki/Tree_traversal" title="Tree traversal">tree traversal</a> algorithms.
</p>

<p>Mice can run at over three meters per second, depending on the maze design. Some of the best micromouse builders are Yusuke Kato,<sup id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup> Ng Beng Kiat<sup id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup> and Fumitaka Nakashima.<sup id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup> The current world record is 3.921 seconds<sup id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup> and is held by Ng Beng Kiat.
</p><p>Performance in recent years has improved considerably. As of 2015, winning mice are likely to run with forward acceleration and braking well over 1g.<sup id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup> Cornering with <a href="https://en.wikipedia.org/wiki/Acceleration" title="Acceleration">centripetal acceleration</a> as high as 2g is possible. Micromice are among the highest-performing autonomous robots.
</p><p>Most recently, robots are being equipped with a fan to create a partial vacuum under the mouse while it is running.<sup id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup><sup id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup><sup id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup> The additional downforce available has made possible a huge improvement in performance. Compared to a non-fan mouse, the newer robots are likely to be able to achieve centripetal accelerations of 6g or more. Straight line accelerations can easily exceed 2.5g.
</p>

<div>
<ol>
<li id="cite_note-1"><span><b><a href="#cite_ref-1">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.micromouseonline.com/micromouse-book/history/">"History"</a>. <i>Micromouse Online</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Micromouse+Online&amp;rft.atitle=History&amp;rft_id=http%3A%2F%2Fwww.micromouseonline.com%2Fmicromouse-book%2Fhistory%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.cs.york.ac.uk/micromouse/Rules/Maze_Solver_Rules.pdf">"UK Micromouse Maze Solver Rules"</a> <span>(PDF)</span>. <i>University of York Department of Computer Science</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=University+of+York+Department+of+Computer+Science&amp;rft.atitle=UK+Micromouse+Maze+Solver+Rules&amp;rft_id=https%3A%2F%2Fwww.cs.york.ac.uk%2Fmicromouse%2FRules%2FMaze_Solver_Rules.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><cite><a rel="nofollow" href="http://micromouseusa.com/">"Micromouse USA - USA Micromouse Fans Site"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Micromouse+USA+-+USA+Micromouse+Fans+Site&amp;rft_id=http%3A%2F%2Fmicromouseusa.com%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-4"><span><b><a href="#cite_ref-4">^</a></b></span> <span><cite><a rel="nofollow" href="https://ukmars.org/index.php/Main_Page">"UK Micromouse and Robotics Society"</a>. <i>ukmars.org</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ukmars.org&amp;rft.atitle=UK+Micromouse+and+Robotics+Society&amp;rft_id=https%3A%2F%2Fukmars.org%2Findex.php%2FMain_Page&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-5"><span><b><a href="#cite_ref-5">^</a></b></span> <span><cite><a rel="nofollow" href="https://ukmars.org/index.php/Minos">"Minos - UK Micromouse and Robotics Society"</a>. <i>ukmars.org</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ukmars.org&amp;rft.atitle=Minos+-+UK+Micromouse+and+Robotics+Society&amp;rft_id=https%3A%2F%2Fukmars.org%2Findex.php%2FMinos&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-6"><span><b><a href="#cite_ref-6">^</a></b></span> <span><cite id="CITEREFrobolaboN">robolaboN. <a rel="nofollow" href="https://www.youtube.com/watch?v=bszRuwK3yIs">"MicroMouse All Japan contest 2009 half size preliminary"</a>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211212/bszRuwK3yIs">Archived</a> from the original on 2021-12-12 – via YouTube.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=MicroMouse+All+Japan+contest+2009+half+size+preliminary&amp;rft.au=robolaboN&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DbszRuwK3yIs&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-7"><span><b><a href="#cite_ref-7">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=aN5vYrrSdKQ"><i>Japan 2009 half-size micromouse contest final</i></a>. <i><a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a></i>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211210/aN5vYrrSdKQ">Archived</a> from the original on 2021-12-10.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Japan+2009+half-size+micromouse+contest+final&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DaN5vYrrSdKQ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-8"><span><b><a href="#cite_ref-8">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.ntf.or.jp/mouse/micromouse2010/rulehalf-EN.html">"NTF -New Technology Foundation-Micromouse2010"</a>. <i>www.ntf.or.jp</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.ntf.or.jp&amp;rft.atitle=NTF+-New+Technology+Foundation-Micromouse2010&amp;rft_id=http%3A%2F%2Fwww.ntf.or.jp%2Fmouse%2Fmicromouse2010%2Frulehalf-EN.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.pcbway.com/project/sponsor/The_first_Half_size_Micromouse_competition_in_Europe.html">"The first Half-size Micromouse competition in Europe- Sponsor - PCBWay"</a>. <i>www.pcbway.com</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.pcbway.com&amp;rft.atitle=The+first+Half-size+Micromouse+competition+in+Europe-+Sponsor+-+PCBWay&amp;rft_id=https%3A%2F%2Fwww.pcbway.com%2Fproject%2Fsponsor%2FThe_first_Half_size_Micromouse_competition_in_Europe.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-10"><span><b><a href="#cite_ref-10">^</a></b></span> <span><a rel="nofollow" href="https://www.youtube.com/watch?v=jsHbhUYqG0I"><span>UK Half size MicroMouse contest?????</span></a> on <a href="https://en.wikipedia.org/wiki/YouTube_video_(identifier)" title="YouTube video (identifier)">YouTube</a></span>
</li>
<li id="cite_note-11"><span><b><a href="#cite_ref-11">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.micromouseonline.com/micromouse-book/mazes-and-maze-solving/solving-the-maze/#axzz1uapduejO">"Solving the maze"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Solving+the+maze&amp;rft_id=http%3A%2F%2Fwww.micromouseonline.com%2Fmicromouse-book%2Fmazes-and-maze-solving%2Fsolving-the-maze%2F%23axzz1uapduejO&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-12"><span><b><a href="#cite_ref-12">^</a></b></span> <span><cite><a rel="nofollow" href="http://blog.livedoor.jp/robolabo/">"ロボット工作研究室 - livedoor Blog（ブログ）"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=%E3%83%AD%E3%83%9C%E3%83%83%E3%83%88%E5%B7%A5%E4%BD%9C%E7%A0%94%E7%A9%B6%E5%AE%A4+-+livedoor+Blog%EF%BC%88%E3%83%96%E3%83%AD%E3%82%B0%EF%BC%89&amp;rft_id=http%3A%2F%2Fblog.livedoor.jp%2Frobolabo%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-13"><span><b><a href="#cite_ref-13">^</a></b></span> <span><cite><a rel="nofollow" href="https://sites.google.com/site/ngbengkiat/">"Ng Beng Kiat"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Ng+Beng+Kiat&amp;rft_id=https%3A%2F%2Fsites.google.com%2Fsite%2Fngbengkiat%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-14"><span><b><a href="#cite_ref-14">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20130605025335/http://homepage1.nifty.com/hfd01577/index.html">"第４実験室"</a>. Archived from <a rel="nofollow" href="http://homepage1.nifty.com/hfd01577/index.html">the original</a> on 2013-06-05<span>. Retrieved <span>2013-05-24</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=%E7%AC%AC%EF%BC%94%E5%AE%9F%E9%A8%93%E5%AE%A4&amp;rft_id=http%3A%2F%2Fhomepage1.nifty.com%2Fhfd01577%2Findex.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-15"><span><b><a href="#cite_ref-15">^</a></b></span> <span><cite><a rel="nofollow" href="https://spectrum.ieee.org/automaton/robotics/diy/meet-the-new-worlds-fastest-micromouse">"Meet the New World's Fastest Micromouse Robot"</a>. 21 November 2011.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Meet+the+New+World%27s+Fastest+Micromouse+Robot&amp;rft.date=2011-11-21&amp;rft_id=https%3A%2F%2Fspectrum.ieee.org%2Fautomaton%2Frobotics%2Fdiy%2Fmeet-the-new-worlds-fastest-micromouse&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-16"><span><b><a href="#cite_ref-16">^</a></b></span> <span><cite id="CITEREFHarrison2017">Harrison, Peter (3 August 2017). <a rel="nofollow" href="http://www.micromouseonline.com/2017/08/03/micromouse-hard-acceleration/">"Micromouse Hard Acceleration"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Micromouse+Hard+Acceleration&amp;rft.date=2017-08-03&amp;rft.aulast=Harrison&amp;rft.aufirst=Peter&amp;rft_id=http%3A%2F%2Fwww.micromouseonline.com%2F2017%2F08%2F03%2Fmicromouse-hard-acceleration%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-17"><span><b><a href="#cite_ref-17">^</a></b></span> <span><cite id="CITEREFHarrison2017">Harrison, Peter (10 October 2017). <a rel="nofollow" href="http://www.micromouseonline.com/2017/10/11/taiwan-micromouse-intelligent-robot-contest-2017/">"Taiwan Micromouse Contest 2017"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Taiwan+Micromouse+Contest+2017&amp;rft.date=2017-10-10&amp;rft.aulast=Harrison&amp;rft.aufirst=Peter&amp;rft_id=http%3A%2F%2Fwww.micromouseonline.com%2F2017%2F10%2F11%2Ftaiwan-micromouse-intelligent-robot-contest-2017%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-18"><span><b><a href="#cite_ref-18">^</a></b></span> <span><cite id="CITEREFHarrison2018">Harrison, Peter (18 February 2018). <a rel="nofollow" href="http://www.micromouseonline.com/2018/02/18/more-suck-less-slip/">"More suck, less slip"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=More+suck%2C+less+slip&amp;rft.date=2018-02-18&amp;rft.aulast=Harrison&amp;rft.aufirst=Peter&amp;rft_id=http%3A%2F%2Fwww.micromouseonline.com%2F2018%2F02%2F18%2Fmore-suck-less-slip%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
<li id="cite_note-19"><span><b><a href="#cite_ref-19">^</a></b></span> <span><cite id="CITEREFBy2008">By (27 November 2008). <a rel="nofollow" href="https://hackaday.com/2008/11/26/vacuum-micromouse/">"Vacuum micromouse"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Vacuum+micromouse&amp;rft.date=2008-11-27&amp;rft.au=By&amp;rft_id=https%3A%2F%2Fhackaday.com%2F2008%2F11%2F26%2Fvacuum-micromouse%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMicromouse"></span></span>
</li>
</ol></div>

<ul><li><a rel="nofollow" href="https://www.youtube.com/watch?v=ZMQbHMgK2rw"><span>The Fastest Maze-Solving Competition On Earth</span></a> on <a href="https://en.wikipedia.org/wiki/YouTube_video_(identifier)" title="YouTube video (identifier)">YouTube</a></li></ul>
<!-- 
NewPP limit report
Parsed by mw‐api‐int.eqiad.main‐ccc4f6dcd‐5hkxv
Cached time: 20240724102302
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.445 seconds
Real time usage: 0.534 seconds
Preprocessor visited node count: 1177/1000000
Post‐expand include size: 26213/2097152 bytes
Template argument size: 1220/2097152 bytes
Highest expansion depth: 18/100
Expensive parser function count: 2/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 62178/5000000 bytes
Lua time usage: 0.288/10.000 seconds
Lua memory usage: 4940426/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  480.738      1 -total
 68.47%  329.153      1 Template:Reflist
 51.26%  246.437     17 Template:Cite_web
 20.41%   98.112      1 Template:Short_description
 11.96%   57.512      2 Template:Pagetype
  9.27%   44.556      2 Template:YouTube
  5.87%   28.237      1 Template:See_also
  4.85%   23.309      5 Template:Main_other
  4.09%   19.682      1 Template:SDcat
  4.04%   19.443      2 Template:Replace
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:266014-0!canonical and timestamp 20240724102302 and revision id 1236374847. Rendering was triggered because: api-parse
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MPPP – The first 'designer drug' disaster (2023) (136 pts)]]></title>
            <link>https://www.chm.bris.ac.uk/motm/mppp/mppph.htm</link>
            <guid>41053383</guid>
            <pubDate>Wed, 24 Jul 2024 03:32:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chm.bris.ac.uk/motm/mppp/mppph.htm">https://www.chm.bris.ac.uk/motm/mppp/mppph.htm</a>, See on <a href="https://news.ycombinator.com/item?id=41053383">Hacker News</a></p>
<div id="readability-page-1" class="page">

<table id="centre">
<tbody><tr>
<td>
<p><img src="https://www.chm.bris.ac.uk/clrline.gif" width="400" height="3" alt=""></p> 

<h3>1-methyl-4-phenyl-4-propionoxypiperidine,<br>or Desmethylprodine or ‘reversed meperidine’</h3>

<h3>The first ‘designer drug’ disaster</h3>

<p><img src="https://www.chm.bris.ac.uk/clrline.gif" width="400" height="3" alt=""></p> 

<p id="centre"><a href="mailto:s.cotton@bham.ac.uk">Simon Cotton</a><br>
<a href="http://www.birmingham.ac.uk/schools/chemistry/index.aspx">University of Birmingham</a></p>

<p><img src="https://www.chm.bris.ac.uk/clrline.gif" width="400" height="3" alt=""></p> 

<p id="centre">Molecule of the Month August 2023<br><span>Also available: <a href="https://www.chm.bris.ac.uk/motm/mppp/mpppjs.htm">JSMol</a> version.</span></p>

<p><img src="https://www.chm.bris.ac.uk/clrline.gif" width="400" height="3" alt=""></p> 

</td><td><img src="https://www.chm.bris.ac.uk/motm/mppp/structure.gif" width="362" height="354" alt="Structure of MPPP" title="Structure of MPPP"></td>

</tr>
</tbody></table>

<h2><img src="https://www.chm.bris.ac.uk/motm/mppp/dd.jpg" width="350" height="" alt="Designer drugs" title="Designer drugs">What is a designer drug?</h2>

<p>The origin of the term is credited to Dr Gary L. Henderson, of the University of California at Davis. A designer drug is based on the structure of an existing drug – which may be naturally sourced from a plant (like <a href="http://www.chm.bris.ac.uk/motm/cocaine/cocaineh.htm">cocaine</a> or <a href="http://www.chm.bris.ac.uk/motm/morphine/Morphine.htm">morphine</a>) or be synthetic (like <a href="http://www.chm.bris.ac.uk/motm/methamphetamine/methh.htm">amphetamine</a>) - but with a slightly different structure (often done by changing a side-chain) designed to make it undetectable in routine drug tests. These slight changes to its structure also change the properties of the drug in the body, sometimes dangerously. Thus, recently this has meant the ‘bath salts’ such as mephedrone in place of cathinone (khat), with amphetamine-like effects, or the ‘spice’ drugs, which affect the ‘<a href="http://www.chm.bris.ac.uk/motm/cannabidiol/cannabidiolh.htm">cannabinoid</a>’ receptor and may produce similar symptoms to marijuana.</p>

<h2>So how long has this ‘designer drug’ been around?</h2>

<p>What we call MPPP was first reported in the <i>Journal of Organic Chemistry</i> in 1947 by Albert Ziering and John Lee of the pharmaceutical company Hofmann-La Roche. They were trying to make better painkillers, though MPPP turned out to be no better than existing ones. They tested MPPP on lab rats and found that it seemed to be safe. To make it, you first react 1-methyl-4-piperidone with phenyllithium, then esterify the resulting alcohol with propionic anhydride.</p> 

<p id="centre"><img src="https://www.chm.bris.ac.uk/motm/mppp/synthesis.gif" width="944" height="350" alt="Synthesis of MPPP" title="Synthesis of MPPP"></p>

<h2>Why is it called reversed meperidine?</h2>

<p>In comparison with the meperidine (a.k.a. pethidine or Demerol, the first synthetic opioid painkiller, originally reported in 1939), the ester group in MPPP is the other way round – it is an isomer of meperidine.</p>

<p id="centre"><img src="https://www.chm.bris.ac.uk/motm/mppp/reversed.gif" width="760" height="350" alt="MPPP and meperidene" title="MPPP and meperidene"></p>

<h2>So who did find out the nasty side to the molecule?</h2>

<p>A young chemistry graduate named Barry Kidston suddenly developed Parkinson’s disease in 1976, when he was only 23. For nearly a decade, he had been abusing a wide range of drugs, such as marijuana, amphetamines and barbiturates, before finally focussing upon opiates like meperidine and codeine. During the summer of 1976 he discovered the 1947 report of MPPP and decided to try that, successfully making it and testing it on himself, finding that it had an opiate-like ‘high’. He then repeated this synthesis several times. Whether he got over-confident in his ability or not, he seems to have taken some shortcuts in the synthesis and in 1976 developed a state of ‘muteness, severe rigidity, weakness, tremor, flat facial expression, and altered sensorium’, being unable to speak. He was admitted to a psychiatric ward.</p>

<h2>So what happened next?</h2>

<p>A number of treatments were tried. After treatments with a number of drugs including <i>levodopa</i> (a drug which the body converts into dopamine, used to treat Parkinson’s disease), his condition improved, and he received a number of medications until in September 1978 he was found dead from an overdose of cocaine and codeine, having  continued on a path of drug abuse. Post-mortem examination of the brain revealed major destruction of nerve cells in the <i>substantia nigra</i> region, something also observed with Parkinson’s patients. They examined his laboratory in 1976 and found not just the MPPP but also an impurity formed at high temperatures, MPTP.  This was tested on rats (and also on hamsters and guinea pigs), but without revealing any Parkinson’s symptom, so the cause remained a mystery. The medics studying the case wrote it up for publication in a journal called <i>Psychiatry Research</i>, and the medical world largely ignored it for a few years.</p>

<p id="centre"><a href="https://www.chm.bris.ac.uk/motm/mppp/mptp.mol"><img src="https://www.chm.bris.ac.uk/motm/mppp/mptp.gif" width="400" height="132" alt="MPTP" title="MPTP"></a><br>
MPTP</p>

<table>
<tbody><tr>
<td id="centre"><img src="https://www.chm.bris.ac.uk/motm/mppp/langston.jpg" width="250" height="297" alt="Dr J. William Langston" title="Dr J. William Langston"><br>
Dr J. William Langston<br>
<small>[Photo: <a href="https://www.journalofparkinsonsdisease.com/blog/neuroscientists_corner/profile-j-william-langston"><i>J. Parkinson's Dis</i>.</a>]</small></td>

<td><h2>So what changed?</h2>

<p>In 1982, Dr J. William Langston, the Director of Neurology of the Santa Clara Valley Medical Centre in San José, was called in to examine George Carillo, a 42-year-old heroin addict who had just been admitted into the centre’s locked psychiatry unit. Carillo was ‘frozen’ – he could not move or talk. They spotted limited finger movement and after a while he was able to write very slowly: ‘I’m not sure what is happening to me. I only know I can’t function normally. I can’t move right.’ These symptoms of Parkinson’s disease had suddenly come on, over just a few weeks. And then he said he’d been taking heroin. The man’s 30-year-old girlfriend Juanita had the same symptoms. This puzzled Langston. People in their 30s and 40s were not supposed to get Parkinson’s. Certainly not from taking heroin. Then Langston found out about Bill and David, a young pair of brothers some 30 miles away in Santa Cruz, who had taken a ‘synthetic heroin’ and displayed similar ‘frozen’ symptoms. Through publicising these four cases, they learned of a drug dealer named Toby and his 21-year-old girlfriend Connie, with exactly the same history. At that point, someone recalled the article that had appeared in <i>Psychiatry Research</i>.</p></td>
<td id="centre"><img src="https://www.chm.bris.ac.uk/motm/mppp/carillo.jpg" width="241" height="350" alt="George Carillo" title="George Carillo"><br>
George Carillo - a 'frozen addict'</td>
</tr>
</tbody></table>

<h2>And?</h2>

<p>Samples of the drugs which they had taken were sent for analysis, and found that what was supposed to be MPPP was largely made up of the impurity MPTP. Animal testing was extended to monkeys, and it was found that MPTP selectively kills cells in the <i>substantia nigra</i>, an area of the brain important in areas like motor control and learning, in rhesus and squirrel monkeys, just as in humans, so it affects the brains of primates in a different way to other animals.</p>

<p>Eventually George, Juanita and Connie were able to receive an experimental surgery in Sweden, during which they underwent transplanting <i>substantia nigra</i> cells from aborted foetuses into the damaged parts of their brains, and this helped them recover much of their motor function.</p>

<h2>How had this happened?</h2>

<p>Kidston seemed to have taken some short cuts in his synthesis in 1976, as had the West-Coast entrepreneur in 1982. If you try to carry out the esterification to make MPPP at too high a temperature, or too low a pH, an elimination reaction occurs. When Langston followed up the original 1947 synthesis of MPPP by going to the library of Stanford University, he found that the paper by Ziering and Lee had been cut out from the volume of <i>Journal of Organic Chemistry</i> with a razor blade. Obviously the chemist making this ‘new heroin’ did not want others in on the game.</p>

<p id="centre"><img src="https://www.chm.bris.ac.uk/motm/mppp/mppp-plus.gif" width="900" height="588" alt="Synthesis of MPP+" title="Synthesis of MPP+"></p>

<p>MPPP contains a tertiary carbon, which readily eliminates a carboxylate (a good ‘leaving group’) to generate a tertiary carbocation; this in turn loses H<sup>+</sup> and is converted into 1-methyl-4-phenyl-1,2,3,6-tetrahydropyridine (MPTP). MPTP can cross the blood-brain barrier and, once in the brain, is mistaken for dopamine by monoamine oxidase (MAO) enzymes. Thus MPTP undergoes oxidation, forming MPP<sup>+</sup>, the species which is responsible for the neuronal damage.</p>

<h2>Did any good come from this?</h2>

<p>It has led to some new understandings about possible causes of Parkinson’s disease. For one thing, people spotted that MPP<sup>+</sup> had a similar structure to the herbicide <i>Paraquat</i>, and scientists are working on a link between Parkinson’s and herbicide use.</p> 



<p>But - above all - the story of MPPP is another warning, a horrible one, about the dangers of dabbling in the wrong sort of chemistry.</p> 

<p><img src="https://www.chm.bris.ac.uk/clrline.gif" width="400" height="3" alt=""></p> 

<h2>Bibliography</h2>

<ul>
<li>A. Ziering and J. Lee, <i>J. Org. Chem</i>., 1947, <b>12</b>, 911-914 (synthesis of MPPP).</li>
<li>G. C. Davis, A. C. Williams, S. P. Markey, M. H. Ebert, E. D. Caine, C. M. Reichert and I. J. Kopin, 
<i>Psychiatry Research</i>, 1979, <b>1</b>, 249-254 (Barry Kidston diagnosed).</li>
<li>J. W. Langston, P. Ballard, J. W. Tetrud and I. Irwin, <i>Science</i>, 1983, 
<b>219</b>, 979-980 (chronic Parkinsonism in humans due to a product of meperidine-analogue synthesis).</li>
<li>R. S. Burns, C. C. Chieh, S. P. Markey, M. H., Ebert, D. M. Jacobowitz and I. J. Kopin, 
<i>Proc. Natl. Acad. Sci. USA</i>, 1983, <b>80</b>, 4546-4550 (testing MPTP in rhesus monkeys).</li>
<li>J. W. Langston, I Irwin, E. B. Langston and L. S. Forno, <i>Science</i>, 1984, 
<b>225</b>, 1480-1482 (pargyline prevents MPTP-induced Parkinsonism in primates).</li>
<li>J. W. Langston, I. Irwin, E. B. Langston and L. S. Forno, <i>Neurosci. Lett</i>., 1984, 
<b>48</b>, 87-92. (MPP<sup>+</sup> as a toxin selective to the <i>substantia nigra</i>).</li>
<li>J. N. Johannessen and S. P. Markey, <i>Drug and Alcohol Dependence</i>, 1984, 
<b>13</b>, 367-374 (analysis of MPTP/MPPP mixture).</li>
<li>P. A. Ballard, J. W. Tetrud and J. W. Langston, <i>Neurology</i>, 1985, <b>35</b>, 949-956. (human Parkinsonism due to MPTP).</li>
<li>R. M. Baum, <i>Chem. Eng. News</i>, 1985, <b>63</b>, 7–16 (designer drugs)</li>
<li>I. J. Kopin, <i>Environmental Health Perspectives</i>, 1987, <b>75</b>, 45-51 (MPTP and Parkinson’s disease).</li>
<li>G. L. Henderson, <i>J. Forensic Sci</i>., 1988, <b>33</b>, 569-575 (designer drugs)</li>
<li>H. Widner, J. Tetrud, S. Rehncrona, B. Snow, P. Brundin, B. Gustavii, A. Björklund, O. Lindvall and J. W. Langston, <i>N. Engl. J. Med</i>., 1992, <b>327</b>, 1556-1563 (transplantation of fetal dopaminergic neurons as a treatment for MPTP-induced Parkinsonism).</li>
<li>D. M. Perrine, <i>The Chemistry of Mind-Altering Drugs</i>, Washington DC, American Chemical Society, 1996, pp 78-81. (MPPP and the MPTP story).</li>
<li>J. W. Langston and J. Palfreman, <i>The case of the frozen addicts: how the solution of an extraordinary medical mystery spawned a revolution in the understanding and treatment of Parkinson's disease</i>, New York, Pantheon, 1996.</li>
<li>C. M. Tanner, F. Kamel <i>et al., Environ. Health Perspect.</i>, 2011, <b>119</b>, 866-872 (Rotenone, Paraquat, and Parkinson’s Disease).</li>
<li>F. Kamel, <i>Science</i>, 2013, <b>341</b>, 722-723 (herbicide-Parkinson’s link).</li>
<li>J. W. Langston, <i>Journal of Parkinson’s Disease</i>, 2017, <b>7</b>, S11–S22 (MPPP and the MPTP story)</li>
<li>C. Vaccari, R. El Dib. and J. L. V. de Camargo, <i>Systematic Reviews</i>, 2017, <b>6</b>, 98 (Paraquat and Parkinson’s disease: a systematic review protocol).</li>
<li><a href="https://neuwritesd.org/2016/08/18/mind-your-ps-and-ts-how-tainted-drugs-revolutionized-parkinsons-research/">How tainted drugs revolutionized Parkinsons research</a></li> 
<li><a href="https://www.journalofparkinsonsdisease.com/blog/neuroscientists_corner/profile-j-william-langston">Profile of Dr William Langston</a></li>
<li><a href="https://www.scientificamerican.com/article/parkinsons-disease-and-pesticides-whats-the-connection/">Parkinsons disease and pesticides - what's the connection?</a></li>
</ul>

<p><img src="https://www.chm.bris.ac.uk/clrline.gif" width="560" height="3" alt=""></p> 

<p><img src="https://www.chm.bris.ac.uk/cgi-bin/Count.cgi?df=mppph.dat|md=7|pad=Y|dd=D" alt="counter"><img src="https://www.chm.bris.ac.uk/backto.gif" width="29" height="29" alt=""> <a href="https://www.chm.bris.ac.uk/motm/motm.htm">Back to Molecule of the Month page</a>.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[DOI:<a href="http://dx.doi.org/10.6084/m9.figshare.22013048">10.6084/m9.figshare.22013048</a>]</p>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[What "consent" looks like for the DEA and TSA (215 pts)]]></title>
            <link>https://papersplease.org/wp/2024/07/23/what-consent-really-looks-like-for-the-dea-and-tsa/</link>
            <guid>41053329</guid>
            <pubDate>Wed, 24 Jul 2024 03:16:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://papersplease.org/wp/2024/07/23/what-consent-really-looks-like-for-the-dea-and-tsa/">https://papersplease.org/wp/2024/07/23/what-consent-really-looks-like-for-the-dea-and-tsa/</a>, See on <a href="https://news.ycombinator.com/item?id=41053329">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primary" role="main">	
			
<article id="post-18773">
			
	
	<p><span>Jul</span>
		<span>23</span>
		<span>2024</span>
	</p>
		
	<div>
		<p>The Drug Enforcement Agency (DEA) and the Transportation Security Administration (TSA) have been <a href="https://papersplease.org/wp/2015/05/01/secondary-inspection-used-as-pretext-for-airport-drug-searches/">working together</a> for years to steal travelers’ money.</p>
<p>The DEA <a href="https://papersplease.org/wp/2016/08/10/dea-recruits-airline-travel-industry-staff-to-inform-on-travelers/">pays informers</a> to finger people who might be flying with large amounts of cash, and gets the TSA to identify these people when they go through TSA checkpoints at airports, claims that they “consent” to be searched, and then finds any money they are carrying and seizes it through “civil forfeiture”.</p>
<p>The DEA carries out <a href="https://papersplease.org/wp/2016/10/03/how-the-dea-uses-travel-company-spies-to-confiscate-travelers-cash/">similar cash-seizure operations on Amtrak trains</a> — mostly domestic trains that don’t cross the US border — in collaboration with US Customs and Border Protection (CBP).</p>
<p>A new <a href="https://www.youtube.com/watch?v=0XBzV0bDZdQ">video</a> released by the <a href="https://ij.org/press-release/new-institute-for-justice-video-exposes-unconstitutional-airport-interdiction-tactic">Institute for Justice</a> shows how this “consent” works in practice.</p>
<p>In the w <a href="https://www.youtube.com/watch?v=0XBzV0bDZdQ">video</a>, a DEA agent won’t take “<a href="https://www.youtube.com/watch?v=0XBzV0bDZdQ">I don’t consent to a search</a>” for an answer. The agent follows an airline passenger onto their plane (without objection by airline staff), snatches the passenger’s carry-on bag, carries it off the plane, and refuses to return it. The agent claims the right to keep the passenger’s bag as long as it takes to get a warrant (although they don’t have that right, and don’t actually get a warrant).</p>
<p>This is not meaningful “consent”, and it’s not a valid legal basis for a search.</p>
<p>An ongoing <a href="https://www.courtlistener.com/docket/16702479/brown-v-transportation-security-adminstration/">class-action lawsuit</a> by the <a href="https://ij.org/case/dea-tsa-forfeitures/">Institute for Justice</a> on behalf&nbsp; of air travelers who have been searched without probable cause on the pretextual claim of “consent” in order to find, seize, and “forfeit” their cash has shown just how common this pattern of illegal search and seizure is.</p>
<p>We reported on the <a href="https://papersplease.org/wp/2020/01/17/is-the-tsa-screening-for-threats-to-aviation-or-for-cash-and-drugs/">filing&nbsp; of this lawsuit</a> in 2020, and on the <a href="https://papersplease.org/wp/2021/04/05/can-tsa-checkpoints-be-used-as-a-general-law-enforcement-dragnet/">first substantive ruling</a> in the case, in favor of the plaintiffs and allowing the case to move forward, in 2021.</p>
<p>Since then, the case has <a href="https://www.courtlistener.com/docket/16702479/brown-v-transportation-security-adminstration/">bogged down</a> in foot-dragging by the DEA and TSA, <a href="https://storage.courtlistener.com/recap/gov.uscourts.pawd.263087/gov.uscourts.pawd.263087.127.0.pdf">resisting discovery</a> of their records of&nbsp; searches and seizures of cash from travelers at airports.</p>
<p>The DEA and TSA continue to claim — despite the <a href="https://papersplease.org/wp/2021/04/05/can-tsa-checkpoints-be-used-as-a-general-law-enforcement-dragnet/">initial ruling against them</a> on this point —&nbsp; that they don’t have an actionable “policy” of targeting travelers with cash for searches because they haven’t put this policy in writing. But the latest <a href="https://storage.courtlistener.com/recap/gov.uscourts.pawd.263087/gov.uscourts.pawd.263087.127.0.pdf">status report</a> on discovery to date indicates that the DEA and TSA have made thousands of seizures of “bulk currency” from air travelers in recent years. This is clearly a routine and officially sanctioned agency practice, whether or not anyone has put it in writing.</p>
<p>The DEA and TSA claim that the volume of records of these searches and seizures would make producing them unduly burdensome. But the volume of these records is symptomatic of the scale and systemic nature of the problem — which is what the plaintiffs are trying to prove. The plaintiffs have suggested examining a statistical sample of the records of airport searches and seizures, but the DEA and TSA are resisting even that.</p>
<p>We wish the plaintiffs in this case and their lawyers success in their pursuit of justice for travelers.</p>
			</div>
</article><!-- #post-18773 -->
	<!-- #nav-below -->
	

	<!-- #comments .comments-area -->
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama 3.1 in C (172 pts)]]></title>
            <link>https://github.com/trholding/llama2.c/blob/master/runq.c</link>
            <guid>41053201</guid>
            <pubDate>Wed, 24 Jul 2024 02:49:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/trholding/llama2.c/blob/master/runq.c">https://github.com/trholding/llama2.c/blob/master/runq.c</a>, See on <a href="https://news.ycombinator.com/item?id=41053201">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to GitHub Copilot&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>GitHub Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>

                  <li>
      
      <div>
              <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Resources&quot;,&quot;action&quot;:&quot;click to go to Learning Pathways&quot;,&quot;label&quot;:&quot;ref_cta:Learning Pathways;&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Resources&quot;,&quot;action&quot;:&quot;click to go to White papers, Ebooks, Webinars&quot;,&quot;label&quot;:&quot;ref_cta:White papers, Ebooks, Webinars;&quot;}" href="https://resources.github.com/">
      White papers, Ebooks, Webinars

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Resources&quot;,&quot;action&quot;:&quot;click to go to Customer Stories&quot;,&quot;label&quot;:&quot;ref_cta:Customer Stories;&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Resources&quot;,&quot;action&quot;:&quot;click to go to Partners&quot;,&quot;label&quot;:&quot;ref_cta:Partners;&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Enterprise&quot;,&quot;action&quot;:&quot;click to go to Enterprise platform&quot;,&quot;label&quot;:&quot;ref_cta:Enterprise platform;&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>Enterprise platform</p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:trholding/llama2.c" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="IZvnxnjD4Vd_v2KOcFzS-gPxR3zfAwmBnem7joVbuavmz6NE-6R4sBLm4nC9Kz-DNtEsKAG-NJQkk8S__2CfZg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="trholding/llama2.c" data-current-org="" data-current-owner="trholding" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=trholding%2Fllama2.c" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/trholding/llama2.c/blob/master/runq.c&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="aa82c133db6d523ea13008f4930b35ea9001ce8a896581a81164d1b902248a90" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: We made glhf.chat – run almost any open-source LLM, including 405B (151 pts)]]></title>
            <link>https://glhf.chat/landing/home</link>
            <guid>41052934</guid>
            <pubDate>Wed, 24 Jul 2024 01:52:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://glhf.chat/landing/home">https://glhf.chat/landing/home</a>, See on <a href="https://news.ycombinator.com/item?id=41052934">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Run<br> <!-- -->(almost)<br> <!-- -->any<br> <!-- -->language<br> <!-- -->model</h2><div><p>We use</p><!-- --> <p><a href="https://docs.vllm.ai/en/stable/">vLLM</a></p><!-- --><p>and a custom-built, autoscaling GPU scheduler to run</p><!-- --> <p><span>(almost)</span></p><!-- --><p>any open-source large language model for you: just paste a link to the Hugging Face repo. You can use our chat UI, or our OpenAI-compatible API. We'll let you use up to eight Nvidia A100 80Gb GPUs.</p></div><div><p>Works with any full-weight or 4-bit AWQ repo on Hugging Face that vLLM supports, including:</p><ul><li>Meta Llama 3.1 405b Instruct (and 70b, and 8b)</li><li>Qwen 2 72b</li><li>Mixtral 8x22b</li><li>Gemma 2 27b</li><li>Deepseek V2 Coder Lite (support for the full model is in the works)</li><li>Phi-3</li></ul><p>And many more. We'll run full-weight finetunes as well, like those from Nous Research or uncensored anti-refusal abliterated models.</p></div><p>For the most popular models, we proxy to always-on inference providers for you automatically. For the more bespoke models, we'll spin up a cluster for you on-demand, and spin it down once you're done using it.</p><p>It's free during the beta period, while we work out the kinks and figure out how to price it. Once the beta is over, we expect to significantly beat pricing of the major cloud GPU vendors due to our ability to run the models multi-tenant.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Origin of Emacs in 1976 (160 pts)]]></title>
            <link>https://onlisp.co.uk/On-the-Origin-of-Emacs-in-1976.html</link>
            <guid>41052593</guid>
            <pubDate>Wed, 24 Jul 2024 00:49:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://onlisp.co.uk/On-the-Origin-of-Emacs-in-1976.html">https://onlisp.co.uk/On-the-Origin-of-Emacs-in-1976.html</a>, See on <a href="https://news.ycombinator.com/item?id=41052593">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="On-the-Origin-of-Emacs-in-1976">

<hr>


<p>(Date: 23 Jul 2024)
</p>
<p>Summary:
EMACS was developed at the MIT AI Lab in 1976.  The specifics of the
origin have been documented by different people in various places.
</p>
<p>There is an interesting thread which was discussed on the blog of the
late Dan Weinreb, and preserved by archive.org.  Ultimately, Guy
Steele pulled up his records (in the form of printed emails).  The
below is an extract which is of historical interest and includes
emails from the first couple months of Emacs in 1976.  I quote some
sections and include the verbatim text at the bottom, which starts
with an ITS email from RMS to GLS.
</p>
<p>Dan Weinreb introduces
</p><blockquote>
<p>And now, here’s the mail from Guy Steele. I think this is the
best information we are ever going to get, and that this is
the last word on the topic.
</p></blockquote>


<p>The summary from Guy Steele is:-
</p><blockquote>
<p>My conclusions: (1) Clearly, by the end of 1976 and thereafter, RMS was
doing the bulk of EMACS development work, but it was not an “overnight”
takeover. For a period of seven weeks, anyway, he had some implementation
help from others (at least GLS, MOON, and JLK), and certainly had help
with design and debugging from these and others (DLW, EAK, ED).
He may have become the “principal hacker” more quickly than that,
however, perhaps in the space of a week or less; but remember that
in the AI lab culture, what I here call “principal hacker” (not a term used
at the time) was a “first among equals”, not an exclusive owner.
</p>
<p>(2) Moon’s involvement was not “hidden”.
</p>
<p>(3) RMS is responsible for the names “E” and “EMACS”.
RMS still deserves 99% or 99.9% or 99.99% or 99.999% of the credit
for taking a package of TECO macros and turning it into the most
powerful editor on the planet, twice (first in TECO and then with ELISP),
pouring in enormous amounts of effort and creativity over many years.
He also deserves credit for working with the early user community to
work out the initial set of key bindings and command names. I don’t
think RMS has any reason to deny the people who helped him out during
the first few months their due share of credit. They gave of their time
and creativity freely, in the best spirit of contributing to the community.
</p>
<p>–GLS
</p></blockquote>



<p>The sources are:
Beginning of thread
<a href="https://web.archive.org/web/20121107150708/http://danweinreb.org/blog/rebuttal-to-stallmans-story-about-the-formation-of-symbolics-and-lmi#comments">https://web.archive.org/web/20121107150708/http://danweinreb.org/blog/rebuttal-to-stallmans-story-about-the-formation-of-symbolics-and-lmi#comments</a>
<a href="https://web.archive.org/web/20121107150522/http://danweinreb.org/blog/why-did-symbolics-fail">why did symbolics fail</a>
<a href="https://web.archive.org/web/20121107150708/http://danweinreb.org/blog/rebuttal-to-stallmans-story-about-the-formation-of-symbolics-and-lmi#comment-65">rebuttal</a>
</p>



<blockquote>
<p>Moon
Moon Says:
November 15th, 2007 at 9:08 pm
</p>
<p>All true, so far as I can remember.
</p>
<p>But in all fairness I have to say that Stallman greatly improved Emacs
after he “liberated” it from Guy and me.
</p></blockquote>



<p>The early history of Emacs was followed-up compiled by Adrienne:
</p>
<blockquote>
<p>The question of Steele’s role in the creation and development of EMACS appears to be an old issue that continues to rear its head, although Stallman addressed this as far back as 1987 in his article “Emacs the Full Screen Editor” [8] and just this year in the comp.lang.lisp thread “teco, rms, gosling, mocklisp” on 28 July: [2, viper-2]
</p>
<p>| Guy Steel played a role in starting the development of Emacs in
| 1975. He developed the key bindings, I designed the internal
| platform, and we worked together for the first night of
| implementation. After that he dropped out.
</p>
<p>Guy Steele concurred: [3, Pitman 8 August]
</p>
<p>| Except for the minor misspelling of my name :-) , I concur with
| everything in RMS’ response. Feel free to post this reply to the
| discussion thread.
</p></blockquote>



<blockquote>
<p>Adrienne Says:
November 25th, 2007 at 4:13 pm
</p>
<p>Dan Weinreb:
</p>
<p>I contacted Stallman drawing his attention to the comments posted in this blog. With regard to your assertions that Guy L. Steele Jr. and David Moon were the authors of the original TECO-based Emacs, Stallman has requested that I inform you that your claim is false.
</p>
<p>In an email message to me dated Thursday, 22 November 2007, Stallman stated:
</p>
<p>| Weinreb is wrong. Moon was never involved in developing Emacs.
</p>
<p>In a further message dated Saturday, 24 November 2007, Stallman reiterated:
</p>
<p>| Please post that I told you that this claim is false. Steele and I
| worked together for the first night of writing code for Emacs, and
| then Steele dropped out. Moon was not involved.
</p>
<p>Sincerely
Adrienne
</p>
<p>cc
* Richard M. Stallman
* Guy L. Steele, Jr.
</p></blockquote>



<blockquote>
<p>My conclusions: (1) Clearly, by the end of 1976 and thereafter, RMS was
doing the bulk of EMACS development work, but it was not an “overnight”
takeover. For a period of seven weeks, anyway, he had some implementation
help from others (at least GLS, MOON, and JLK), and certainly had help
with design and debugging from these and others (DLW, EAK, ED).
He may have become the “principal hacker” more quickly than that,
however, perhaps in the space of a week or less; but remember that
in the AI lab culture, what I here call “principal hacker” (not a term used
at the time) was a “first among equals”, not an exclusive owner.
</p>
<p>(2) Moon’s involvement was not “hidden”.
</p>
<p>(3) RMS is responsible for the names “E” and “EMACS”.
RMS still deserves 99% or 99.9% or 99.99% or 99.999% of the credit
for taking a package of TECO macros and turning it into the most
powerful editor on the planet, twice (first in TECO and then with ELISP),
pouring in enormous amounts of effort and creativity over many years.
He also deserves credit for working with the early user community to
work out the initial set of key bindings and command names. I don’t
think RMS has any reason to deny the people who helped him out during
the first few months their due share of credit. They gave of their time
and creativity freely, in the best spirit of contributing to the community.
</p>
<p>–GLS
</p></blockquote>





<p>Full verbatim quotation from Dan Weinreb:
</p>
<pre>dlweinreb Says:
November 28th, 2007 at 2:37 am

I wasn’t going to keep this origin-of-Emacs topic going, but today,
Guy Steele today sent a very long piece of mail to me, Richard
Stallman, and Adrienne Thompson, in reply to mail from Stallman, who
asked Guy:

Weinreb says that Moon did something important (though he is vague
about what) in starting Emacs. If Moon was involved, he must have
hidden it from me. Do you know what’s going on here?

First some preliminary comments from me:

- Secret decoder: GLS is Guy Steele, RMS is of course Richard
Stallman, DLW is Dan Weinreb (me), Moon is David Moon, Ed is Ed
Schwalenberg who was beta-testing along with me, CBF is Charles
Frankston, EAK is Earl Killian, ECC is Gene Cicarelli, RMF is Bob
Frankston, and JLK is John Kulp.

- I agree that I’m somewhat vague on precisely which things Moon
did. I remember that there was a part of “?” called the “loader” that
was part of the underlying infrastructure, and I recall that Moon
developed this initially. Evidently Stallman improved upon it later
(see first email below), as he surely improved upon everything as time
went by. Moon also worked on the “MM macros”, which meant “commands
that had descriptive English names instead of being one or two
keystrokes”, corresponding to today’s Meta-X commands. The MM macros
feature was brought into “?” from one of the Emacs predecessors,
sometimes called TMACS, that was developed and used by Moon,
CBF, EAK, and ECC. RMF had already figured out how to extract the MM commands
from TMACS and insert them into TECMAC, one of the other Emacs
predecessors, and I borrowed (copied) that code from him. It soon
became clear that what we had here was a mess, and the right thing to
do was to all join forces and come up with a single code base that had
the best of all the ideas in it. Thus was the project born that
turned into Emacs.

- The reason the mail looks funny is that it predates the Internet;
some of what you see is Arpanet mail, and some (like the first one) is
internal ITS mail.

- Guy sent PDF files of scans, which I have no way of posting here,
but he quotes all the important stuff below.

- It would be even better had there been email from the previous
week, but, gee, you can’t have everything.

And now, here’s the mail from Guy Steele. I think this is the
best information we are ever going to get, and that this is
the last word on the topic.

——

I think all of us have been relying on our memories, which can
fail in various ways. Last time around I checked my file folder
of notes about Emacs, which has some useful information, but
not a lot about who did what. Now I have some more information
to offer. I’m going to quote email I received during the last
part of 1976. The attached PDF files are scans I made today from
my paper archives of that email. I may have committed typographical
errors in quoting the email below; if in doubt, consult the scans.

On October 23, 1976, RMS sent this email to GLS:

RMS@@MIT-AI 10/23/76 02:11:39
To: GLS at MIT-AI
I HAVE HACKED ?MACS A LOT. IT NOW HAS
AN IMPROVED LOADER MACRO AND SUITABLE PURIFY MACRO.
THE PURIFY MACRO HAS BEEN DEBUYGGED, AND WINS;
I HAVEN’T TESTED THE LOADER ON THE RESULT THOUGH.

Comments: (a) At this point the new proposed consolidated set of
TECO macros for real-time editing was called “?”. I had chosen this
name as a kind of stubborn joke, because a non-alphabetical character
as the name of a program was just a little harder to invoke from DDT;
also, it followed the example of the @ program, which had just recently
taken over from the @ command in TECO for creating program listings
—another project that I started and then RMS markedly improved over
the years. However, the @ program was useless without command-line
arguments, so no one ever wanted to type @^K to start it, whereas
it was desirable to start a frequently-used editor by typing a single-character
name and then ^K, and I knew it, and I was being a bit mulish about it.

(b) This email was sent just to GLS. From the fact that he was
reporting progress to me, I infer from this that RMS did not yet regard
himself as the “owner” or “principal hacker” of this project. (While the
AI Lab culture did support the notion that in principle anyone could hack
on any program, in practice it was also well-understood that certain
people had superior knowledge about certain programs, and that superior
knowledge was consulted and paid due respect. I wouldn’t have dreamed
of hacking on TECO without consulting RMS, and he would not have hacked
on LISP without consulting JONL or me.)

On October 29, 1976, GLS sent this email to RMS:

GLS@@MIT-AI 10/29/76 15:20:31
To: RMS at MIT-AI
CC: GLS at MIT-AI
See .TECO.;?VARS &gt; for a ? variables macro.
It has some hair for pushing and popping
variables as well as getting and setting them.
Suggestions appreciated for reducing hair.

Comment: Six days later, I am still working on the implementation.
I think that explodes the pretty myth that the project was handed over
to RMS literally overnight. (However, as we will see, it did occur fairly
quickly, as such things go.)

On October 31, 1976, RMS sent this email to GLS:

RMS@@MIT-AI 10/31/76 01:15:37
To: GLS at MIT-AI
I MOVED ?VARS INTO ?MACS
UNDER THE NAME ^^ VARIABLES (THAT’S 2 UPARROWS).
I PARTIALLY DEBUGGED IT; READING AND WRITING WORK BUT
NOT PUSHING AND POPPING.
TO GET A ?, DO :XT ?;
THEN DO MMLIST COMMANDS$$ AND MMLIST REDEFINITIONS$$.

Comment: I believe that by this point I thought of RMS as principal
hacker on the project, or at least the most active contributor; I’m feeding
him little chunks of code as I am able, and he does the integration.

The next day:

RMS@@MIT-AI 11/01/76 03:53:45
To: GLS at MIT-AI
m.v now works completely.
List commands implemented.
lisp indentation command works (meta-I).
MIDAS, TECO and LISP editing modes defined.

Comments: RMS still sends me reports on his progress. (The Lisp indentation
macro was the “big one” that he and I worked on together in a single ten-hour
hack session.)

On November 10:

RMS@@MIT-AI 11/10/76 21:46:03
To: EAK at MIT-AI, CBF at MIT-AI, GLS at MIT-AI, ED at MIT-AI
To: DLW at MIT-AI, MOON at MIT-AI
Unless anyone can think of a better idea, I think we should
rename ? to E.

DLW@@MIT-AI 11/10/76 21:49:07
To: MOON ay MIT-AI, DLW at MIT-AI, ED at MIT-AI, GLS at MIT-AI
To: CBF at MIT-AI, EAK at MIT-AI, RMS at MIT-AI
Another idea is to call it formally “QMARK” with a link
existing for “QM” .

Comment: Note that MOON is among the interested parties. Most of
these addressees were implementors of macro packages that were
predecessors of ?MACS and had user constituencies.

GLS@@MIT-AI 11/11/76 14:43:03
To: MOON ay MIT-AI, DLW at MIT-AI, ED at MIT-AI, GLS at MIT-AI
To: CBF at MIT-AI, EAK at MIT-AI, RMS at MIT-AI
Well, for hack value TS ? ought to exist (yes, you CAN
get DDT to load it under that name!), but E is a good
abbreviation.

Comment: Finally, I capitulate on the name (thank goodness).

Later that day:

GLS@@MIT-AI 11/11/76 16:39:50
To: CBF at MIT-AI, EAK at MIT-AI, ED at MIT-AI, MOON ay MIT-AI
To: DLW at MIT-AI, RMS at MIT-AI
CC: GLS at MIT-AI
My current tentative suggestions for ? command placement
are in TGQ;?CHARS &gt; on AI. (They aren’t even completely
what I want, now that I have talked with RMS, but at
least some desirable features are listed even if they aren’t
where we want them to be.)

Comment: The key bindings are still in flux, and I’m still
involved in determining those key bindings.

MOON@@MIT-AI 11/11/76 21:28:51
To: INFO-E at MIT-AI
You are now on the INFO-E @ AI mailing list. (Used to be called INFO-?).

Comment: Moon creates the INFO-E mailing list. Looks like the name
change has been agreed upon.

RMS@@MIT-AI 11/12/76 03:53:31
To: INFO-E at MIT-AI
LOTS OF COMMANDS MOVED.
NEW PURIFIER (USING FO) NOW UP, GIVING
TREMENDOUD INCREASE IN SPEED, ESPECIALLY FOR DOCUMENTATION
MACROS.

DLW sends several messages to (BUG EMACS) and (BUG E); he and
Moon are the principal testers of the new editor, shaking out many
bugs.

MOON@@MIT-AI 11/14/76 04:40:49 Re: Changes
To: INFO-E at MIT-AI
[1] RMS’s many bug fixes and changes of this afternoon compiled and installed.
[2] MM LIST FILES renamed to MM LIST LOADED FILES
[3] New MM macros:
LIST FILES compact directory listing
LIST DIRECTORIES compact, sorted listing of M.F.D.
LIST TECO FS FLAGS compact, sorted listing of Teco FS flags
DUMP RMAIL don’t try it!
RMAIL temporary access to rmail – seems to have
a few bugs. In particular, don’t try
to get the minibuffer inside rmail’s ^R
command – you’ll be sorry!
EDIT ..D edit the delimiter table
VIEW Q-REGISTER try to view any type of Q-register
[4] Note that MM LIST should be an acceptable
abbreviation for most such commands. Note that RMAIL needs
to be rewritten.
[5] For those who don’t know MM DIRED has worked for a few days.

Comment: From the fact that Moon first cites RMS’s work in item [1]
and then goes on to cite other changes to EMACS, this seems to imply
that these other items are things Moon was working on (and they strike
me as his style of things to work on).

MOON@@MIT-AI 11/14/76 19:14:06
To: (BUG E) at MIT-AI
M.I lossage – if you are using a multicharacter command, e.g. ^XB..Z,
and type part of it fast, you end up seeing at the bottom of the screen
something like “.:z” – it seems the right thing would be to save up all
non-echoed chars in a string in ..0 (which q-r gets reset at the right times)
and echo them all when echoing starts. And flush the colon. This would
also allow hairy commands to use long prompts by putting a string in ..0
before calling .I the first time.

Comment: This message testifies to Moon’s intimate knowledge of the inner
workings of TECO and the fledgling EMACS.

RMS@@MIT-AI 11/16/76 22:05:41
To: INFO-E at MIT-AI
EMACS^K and E^K now exist, and run links to EMACS;TS &gt;.
:NT EMACS; will still load up from scratch.
Note that the file [PRFY] is no longer loaded by default.

Comment: the birth of EMACS as a stand-alone program
under that name (and the name E)! (Though note that the
(BUG EMACS) mailing list had already existed for a couple
of days, and that the previous way to start the macros was
to say “:NT EMACS”.)

gls@@MIT-AI (Sent by BRS@@MIT-AI) 11/17/76 12:44:06
To: (BUG E) at MIT-AI
Grumble! If CTRL-META-[ is gobbled, then I can’t use it to insert Q!

Comment: This was a reference to the Crunchly cartoon of 5/19/1973.
(You can see it in _The New Hacker’s Dictionary_.)

MOON@@MIT-AI 11/17/76 23:32:45 Re: Featurama EMACS
To: INFO-EMACS at MIT-AI
MM TECORD $ teco command $
^R puts current line at top of screen, ^U^R at bottom,
^U^U^R puts top of current defun, paragraph, etc. at top of screen.
Warning- this may get moved to another character.
Multiple consecutive deletes act like one as far as the ..K ring
is concerned; thus one ^Y will get it all back.
^K accepts negative arguments just like meta and control-meta versions.
A few bugs fixed.

Comment: Moon is still involved.

RMS@@MIT-AI 11/19/76 04:49:41
To: GLS at MIT-AI, MOON at MIT-AI, DLW at MIT-AI, ED at MIT-AI
I have just written some winning Meta, Control, and Control-Meta
prefix characters, and I am desperately in need of a good idea
of where to put them. The Meta and Control-Meta prefixes should
be easy to type on ordinary terminals. One idea is to put them
on ^W and ^L, but then 1) where to put ^R Kill Region, and
2) does ^L^L clear the screen or move left?
A possible place for the Control-Meta prefix is ^C,
which has the advantace of being easy to remember for
an ex-TECMAC user.

Comment: RMS confers with me, DLW, Ed, and Moon on design.

On 11/27/76, RMS sends out a long message to INFO-E reporting
mane changes he has made. By this point RMS appears to be doing
most of the work, and I think Moon is doing much less implementation
work.

On 11/30/76, RMS send a message to INFO-E, and two more on 12/05/76,
and three more on 12/11/76.

On 12/10/76, JLK sent a message to INFO-E announcing 18 or 19
new features. Comment: John Kulp (an implementor of one of
the predecessor macro packages) was actively involved in EMACS
development as late as December 10.

My conclusions: (1) Clearly, by the end of 1976 and thereafter, RMS was
doing the bulk of EMACS development work, but it was not an “overnight”
takeover. For a period of seven weeks, anyway, he had some implementation
help from others (at least GLS, MOON, and JLK), and certainly had help
with design and debugging from these and others (DLW, EAK, ED).
He may have become the “principal hacker” more quickly than that,
however, perhaps in the space of a week or less; but remember that
in the AI lab culture, what I here call “principal hacker” (not a term used
at the time) was a “first among equals”, not an exclusive owner.

(2) Moon’s involvement was not “hidden”.

(3) RMS is responsible for the names “E” and “EMACS”.

RMS still deserves 99% or 99.9% or 99.99% or 99.999% of the credit
for taking a package of TECO macros and turning it into the most
powerful editor on the planet, twice (first in TECO and then with ELISP),
pouring in enormous amounts of effort and creativity over many years.
He also deserves credit for working with the early user community to
work out the initial set of key bindings and command names. I don’t
think RMS has any reason to deny the people who helped him out during
the first few months their due share of credit. They gave of their time
and creativity freely, in the best spirit of contributing to the community.

–GLS
</pre>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pnut: A C to POSIX Shell Compiler you can Trust (140 pts)]]></title>
            <link>https://pnut.sh</link>
            <guid>41052446</guid>
            <pubDate>Wed, 24 Jul 2024 00:22:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pnut.sh">https://pnut.sh</a>, See on <a href="https://news.ycombinator.com/item?id=41052446">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <div>
                <p>
                    <h5>Write C</h5>
                </p>
                <p>
                    Write your script in plain-old C, no new language to learn.
                </p>
                <p><img src="https://pnut.sh/code.png" alt="Write Image">
            </p></div>
            <div>
                <p>
                    <h5>Human readable</h5>
                </p>
                <p>
                    Pnut's output is designed to be human-readable, making it
                    easy to inspect, debug and maintain code.
                </p>
                <p><img src="https://pnut.sh/code-shell.png" alt="Compile Image">
                </p>
            </div>
            <div>
                <p>
                    <h5>Runs everywhere</h5>
                </p>
                <p>
                    Pnut's output runs on any POSIX-compliant shell, from bash to
                    zsh, across all major operating systems including Linux,
                    macOS, and Windows.
                </p>
            </div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scrapscript: A functional, content-addressable programming language (165 pts)]]></title>
            <link>https://github.com/tekknolagi/scrapscript</link>
            <guid>41052371</guid>
            <pubDate>Wed, 24 Jul 2024 00:08:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tekknolagi/scrapscript">https://github.com/tekknolagi/scrapscript</a>, See on <a href="https://news.ycombinator.com/item?id=41052371">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Scrapscript Interpreter</h2><a id="user-content-scrapscript-interpreter" aria-label="Permalink: Scrapscript Interpreter" href="#scrapscript-interpreter"></a></p>
<p dir="auto">See <a href="https://scrapscript.org/" rel="nofollow">scrapscript.org</a> for some more information. Keep
in mind that the syntax on the website will change a little bit in the coming
weeks to match this repository.</p>
<p dir="auto">Take a look inside <a href="https://github.com/tekknolagi/scrapscript/blob/trunk/scrapscript.py">scrapscript.py</a> and all of its tests to get
an idea for how the language works.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">We support python3.8+.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# With a file
python3 scrapscript.py eval examples/0_home/factorial.scrap

# With a string literal
python3 scrapscript.py apply &quot;1 + 2&quot;

# With a REPL
python3 scrapscript.py repl"><pre><span><span>#</span> With a file</span>
python3 scrapscript.py <span>eval</span> examples/0_home/factorial.scrap

<span><span>#</span> With a string literal</span>
python3 scrapscript.py apply <span><span>"</span>1 + 2<span>"</span></span>

<span><span>#</span> With a REPL</span>
python3 scrapscript.py repl</pre></div>
<p dir="auto">or with <a href="https://justine.lol/cosmopolitan/index.html" rel="nofollow">Cosmopolitan</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="./build-com

# With a file
./scrapscript.com eval examples/0_home/factorial.scrap

# With a string literal
./scrapscript.com apply &quot;1 + 2&quot;

# With a REPL
./scrapscript.com repl"><pre>./build-com

<span><span>#</span> With a file</span>
./scrapscript.com <span>eval</span> examples/0_home/factorial.scrap

<span><span>#</span> With a string literal</span>
./scrapscript.com apply <span><span>"</span>1 + 2<span>"</span></span>

<span><span>#</span> With a REPL</span>
./scrapscript.com repl</pre></div>
<p dir="auto">(if you have an exec format error and use Zsh, either upgrade Zsh or prefix
with <code>sh</code>)</p>
<p dir="auto">or with Docker:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# With a file (mount your local directory)
docker run --mount type=bind,source=&quot;$(pwd)&quot;,target=/mnt -i -t ghcr.io/tekknolagi/scrapscript:trunk eval /mnt/examples/0_home/factorial.scrap

# With a string literal
docker run -i -t ghcr.io/tekknolagi/scrapscript:trunk apply &quot;1 + 2&quot;

# With a REPL
docker run -i -t ghcr.io/tekknolagi/scrapscript:trunk repl"><pre><span><span>#</span> With a file (mount your local directory)</span>
docker run --mount type=bind,source=<span><span>"</span><span><span>$(</span>pwd<span>)</span></span><span>"</span></span>,target=/mnt -i -t ghcr.io/tekknolagi/scrapscript:trunk <span>eval</span> /mnt/examples/0_home/factorial.scrap

<span><span>#</span> With a string literal</span>
docker run -i -t ghcr.io/tekknolagi/scrapscript:trunk apply <span><span>"</span>1 + 2<span>"</span></span>

<span><span>#</span> With a REPL</span>
docker run -i -t ghcr.io/tekknolagi/scrapscript:trunk repl</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">The experimental compiler:</h3><a id="user-content-the-experimental-compiler" aria-label="Permalink: The experimental compiler:" href="#the-experimental-compiler"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Normal ELF</h4><a id="user-content-normal-elf" aria-label="Permalink: Normal ELF" href="#normal-elf"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="./scrapscript.py compile some.scrap  # produces output.c
./scrapscript.py compile some.scrap --compile  # produces a.out"><pre>./scrapscript.py compile some.scrap  <span><span>#</span> produces output.c</span>
./scrapscript.py compile some.scrap --compile  <span><span>#</span> produces a.out</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Cosmopolitan</h4><a id="user-content-cosmopolitan" aria-label="Permalink: Cosmopolitan" href="#cosmopolitan"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="CC=~/Downloads/cosmos/bin/cosmocc ./scrapscript.py compile some.scrap  --compile # produces a.out"><pre>CC=<span>~</span>/Downloads/cosmos/bin/cosmocc ./scrapscript.py compile some.scrap  --compile <span><span>#</span> produces a.out</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Wasm</h4><a id="user-content-wasm" aria-label="Permalink: Wasm" href="#wasm"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="CC=/opt/wasi-sdk/bin/clang \
CFLAGS=-D_WASI_EMULATED_MMAN \
LDFLAGS=-lwasi-emulated-mman \
./scrapscript.py compile some.scrap --compile  # produces a.out"><pre>CC=/opt/wasi-sdk/bin/clang \
CFLAGS=-D_WASI_EMULATED_MMAN \
LDFLAGS=-lwasi-emulated-mman \
./scrapscript.py compile some.scrap --compile  <span><span>#</span> produces a.out</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running Tests</h2><a id="user-content-running-tests" aria-label="Permalink: Running Tests" href="#running-tests"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 scrapscript.py test"><pre>python3 scrapscript.py <span>test</span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Taking my diabetes treatment into my own hands (2024) (256 pts)]]></title>
            <link>https://martin.janiczek.cz/2024/07/23/taking-my-diabetes-treatment-into-my-own-hands.html</link>
            <guid>41052365</guid>
            <pubDate>Wed, 24 Jul 2024 00:06:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://martin.janiczek.cz/2024/07/23/taking-my-diabetes-treatment-into-my-own-hands.html">https://martin.janiczek.cz/2024/07/23/taking-my-diabetes-treatment-into-my-own-hands.html</a>, See on <a href="https://news.ycombinator.com/item?id=41052365">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
  

  <div itemprop="articleBody">
    <p>First of all, this blogpost is kinda long. Let me prove to you reading it <em>will</em> actually have some payoff:</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/04-original-and-best.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/04-original-and-best.png" alt="See, I wrote something!"></a></p>

<p>OK, now that you’ll stay, let’s start from the beginning…</p>

<hr>

<p>I’m a Type 1 diabetic. This means my pancreas doesn’t produce insulin (which allows cells to use blood glucose for energy) and I have to provide it externally.</p>

<p>This is a finnicky process, because you need to balance your glucose in the right “zone” - not too high (hyperglycemia, &gt;10 mmol/l, is a long-term danger to your body) and not too low (hypoglycemia, &lt;4 mmol/l, is a short-term danger to your body). If it’s too high, you need to inject insulin, and if it’s too low, you need to eat some sugars.</p>

<p>A commonly used metaphor for this is flying a plane. There are games illustrating the process as well: click blue button, bird flies down, click orange button, bird flies up. Too high bad, too low bad, just right good.</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/icarus.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/icarus.png" alt="A game showing the process"></a></p>

<p>The issues with manually managing this process you’ve inherited from your douchebag pancreas are manifold:</p>

<ul>
  <li>the insulin doesn’t act immediately, there’s around 20min delay (depending on the brand) before your blood glucose goes down</li>
  <li>the <em>food</em> doesn’t act immediately, there’s around 20min delay (depending on the food!) before your blood glucose goes up
    <ul>
      <li>simple sugars (eg. fruit) are faster (and stop acting faster as well)</li>
      <li>complex sugars (rice / potatoes / …) are slower. You usually want your blood glucose as constant and flat as possible. The worst thing you can do is to go from hypo to hyper to hypo to hyper in huge amplitude swings.</li>
      <li>fats also somehow affect the digestion of sugars. I can’t be bothered to remember how, I just ignore them honestly.</li>
    </ul>
  </li>
  <li>injecting insulin ~15min before you start eating would do <em>wonders</em> for neutralizing the BG spike, the issue is, nobody does it, because what if you then get a smaller serving at the restaurant or it gets delayed? What if you get called somewhere urgently and can’t finish your meal? People usually inject right before the meal / after the meal as a result.</li>
  <li>there’s no generic formula (that I know of) for estimating how much will a gram of sugar increase your blood glucose, nor how much will an unit of insulin decrease your blood glucose. <em>It’s all vibes.</em></li>
  <li>mathematical models <em>do</em> exist but you need to find your body’s parameters - I’ll get to it below!</li>
  <li>the body has its own emergency reserves of glucose, which it can sometimes decide to use (though beware, this system turns off when you’re drunk), so <em>maybe</em> the Snickers bar you just ate to save your life wasn’t actually needed anymore, and you end up with a hyper</li>
  <li>you’re not quite yourself during a hypo (you get slower, dumber, I’ve heard of people getting stuck in thought loops in front of an open fridge), and so even though you intellectually know you just ate enough to get back into the correct levels <em>eventually</em>, your brain is screaming at you <strong>“EAT! YOU’RE DYING! I AM LOW ON SUGAR <em>NOW!!</em>“</strong> and in my case this leads to overcompensating quite knowingly and willingly. <em>Yeah one more yoghurt can’t hurt.</em> Well…</li>
  <li>insulin doesn’t work when eaten, you need to inject yourself with it (though nowadays we do it under skin, not into veins, I sure am glad I’m not living 50 years ago) or inhale it. Since injections aren’t the most pleasant thing in the world, the dosage is usually limited to 4x a day (to counteract the three main meals + a long-acting different type of insulin once a day), even though you’d be more stable if you injected more often, with smaller doses.
    <ul>
      <li>(no experience with inhalations here, so I’ll skip this)</li>
      <li>(insulin pumps do exist, I’ll mention those briefly in a moment… maybe)</li>
    </ul>
  </li>
  <li>measuring your blood glucose level is painful if you are using test strips and need to prick your fingers to provide a blood drop, so measuring your sugar is usually limited to 4-6x a day – again, even though it would be better to have more data points.
    <ul>
      <li>this is less of a problem nowadays with Continuous Glucose Monitoring systems like Freestyle Libre, which you install into your arm once every 14 days and get a measurement every minute through Bluetooth to your phone</li>
    </ul>
  </li>
  <li>things like physical effort, illness, stress, <em>heck, even seasons of the year</em> do all affect how your body behaves and reacts to sugar / insulin</li>
  <li>there’s this damn thing called <a href="https://en.wikipedia.org/wiki/Dawn_phenomenon">dawn phenomenon</a> that some diabetics, me included, experience: in the morning your sugar will just start going up and up. If you wanted to sleep in on the weekend, well tough luck, you’re now in the 15 mmol/l range.</li>
</ul>

<p>I hope this incomplete list gives you an idea of how wonky the process of trying to make your blood glucose stay in the right levels is.</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/phone.jpeg">
<img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/phone.jpeg" alt="My 7-day average">
</a>
</p>

<p>My treatment is usually: keep the Freestyle Libre app on my phone open as much as possible and when I see my BG’s getting high, I inject a small amount of insulin. How much? No idea. <em>IT’S ALL VIBES.</em></p>

<p>But sometimes the app is yelling at you: “you’re at 15 mmol/l for an hour now, idiot!” and you just don’t (want to) pay attention. Alert fatigue is a real thing.</p>

<p>I have some recommended insulin dosages that we’ve settled on with my diabetologist, whom I visit every three months. So my regimen can look like:</p>

<ul>
  <li>Breakfast: inject 18 units, eat 24g of sugars</li>
  <li>Lunch: inject 22 units, eat 60g of sugars</li>
  <li>Dinner: inject 21 units, eat 60g of sugars</li>
  <li>Before sleep: inject 32 units of long-acting insulin</li>
</ul>

<p>And then I see my diabetologist, she looks at the 7d / 14d / 30d averages and says “maybe you can try fixing the 15:00 hypers you’re getting quite regularly, by injecting more insulin before lunch. You should also lose weight, when you started coming here you had 80kg, now you’re a centurion. Like seriously, WTF. OK cool bye, see you in 3 months!”</p>

<p>Lovely.</p>

<p>If you can’t tell, the thing that irks me the most about the whole thing is: <em><span>Ï̷̛̛̮̏̀̊͠T̵̨̡̏͝’̵̧͍̐̂̑̈́͐̐͜S̸͉̖͒̈̀̕͝ ̴̢̺̤̜͎͚̙́Ạ̷͕̱͖͙̉̊L̴̼̞̺̤̞̬̟̅̈́L̷̠̔̏̐̃̚ ̴̞̊͛͝V̸͇͚̱͑̄̈̌̊Ḯ̴̧̧͚̰̞̈́͝B̸̡̬̪͊̌͂̓̐E̵͙̼̰̞̹͇̎̽̈́̓Ş̷̱͍͖̼͍̯̉̾͊̂̾͝</span>.</em> I’d seriously appreciate it if my diabetologist used a model, or a simulation of some kind, got my body’s parameters there somehow, and found the improvements to my schedule <em>that way</em>. Maybe she has some expert knowledge in her head but from my perspective it’s all guessworks. Err, I mean <span>v̴̼̂i̴̥̇b̸̠̌e̶͙̕ś̴̲</span>.</p>

<p>And this is where my programmer mind comes in.</p>

<hr>

<p>There are people who take <strong>insulin pumps</strong> (which provide insulin in very small very frequent doses and are ~permanently injected into your body, but are otherwise dumb as a brick) and combine them with <strong>continuous glucose monitors,</strong> and make the glucose measurements inform and control the pump. This is called “closed loop” or “artificial pancreas”, and getting one officially is very hard or impossible: not FDA approved yet / you need to be part of an university study to get one / … It’s one of those things that “will be here in 5 years”, <em>they say every year for the past 30 years.</em></p>

<blockquote>
  <p>Aside: I try not to be too butthurt about it: CGMs have just recently started being available and even fully sponsored by the Czech health insurance companies, and having a 1440-datapoints-a-day graph is a <em>MASSIVE</em> improvement compared to pricking your finger 4x a day and getting 4 datapoints for your blood glucose graph with nothing in between. So, the artificial pancreas is slowly coming. Unlike nuclear fusion.</p>
</blockquote>

<p>The most prominent of these people hacking their devices together, in my social bubble at least, is <a href="https://www.hanselman.com/">Scott Hanselman</a>, the Microsoft programmer guy. (Check out his <a href="https://www.youtube.com/watch?v=uNhYhlBQoEY">talk</a>.) He’s a T1DM as well and has been promoting the <a href="https://wearenotwaiting.net/">#WeAreNotWaiting</a> initiative where people take their own pump and their own CGM and hack them together despite the healthcare companies’ pleas that it’s not approved and not safe etc. #TheyAreNotWaiting.</p>

<p>And that is really inspirational.</p>

<p>I don’t have a pump myself (and to have a chance of getting one I’d first have to find another diabetologist, which makes this into a <em>“too much work, can’t be bothered”</em> issue for me), so I can’t currently do quite what they are doing, but I can go with the high-level idea and #NotWait in my own way.</p>

<hr>

<p>A few days ago I was fumbling down the stairs to our kitchen at ~3:00 in the morning to fix my hypo. (Night hypoglycemias are <em>especially</em> bad: what if you don’t wake up?) On the stairs I had the thought: why the hell is there no app into which I’d put my past X blood glucose values, my usual daily schedule, my weight, height, gender, age, whatever, and it would let me play with some kind of prediction (interactively!) and find good dosages / meal times / injection times? Then I would have a potentially good target to get to, and over the course of a few days I could gradually adjust my real dosage to that level and see how it behaves, and hopefully stay in the 4-10 mmol/l range much more easily.</p>

<p>Why doesn’t such a thing exist?</p>

<p>(Coincidentally I’ve also started chatting about this and other app ideas with <a href="https://twitter.com/lambdapriest">John Pavlick</a>. Thanks for your encouragement, John!)</p>

<p>So I started googling. Turns out there are <em>many</em> papers detailing differential equations for a model of how glucose and insulin interact, and how an artificial pancreas could get you to the correct range automatically. The issue is, I DON’T HAVE AN ARTIFICIAL PANCREAS. I have four daily injections. Give me something useful for those!</p>

<p>There’s not too much to pick from.</p>

<blockquote>
  <p>To be honest, I also don’t really know how to translate those differential equations into a simulation algorithm, even if I found a good model. I’m guessing I need to write an <a href="https://en.wikipedia.org/wiki/Ordinary_differential_equation">ODE</a> solver like <a href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods">Runge-Kutta</a> for the specific set of equations and somehow find <em>my</em> specific parameters for it. It’s been a while since I studied this in uni.</p>
</blockquote>

<p>One of the links led me to <a href="https://diabetes.zcu.cz/">diabetes.zcu.cz</a> though, and in particular their <a href="https://diabetes.zcu.cz/smartcgms/">SmartCGMS</a> app (open-source too!). From the screenshots it seemed kinda relevant, or at least similar to what I had in mind for my dream app.</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/smartcgms.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/smartcgms.png" alt="SmartCGMS"></a></p>

<p>So I sent an email to the authors. Found one maintainer on GitHub and wrote them an email detailing my woes and the app I’d love to write, and whether they could point me to some existing software or good papers on modelling multiple-dose-injection treatment (as opposed to a pump / artificial pancreas).</p>

<p>What they gave me was better than I could imagine. (Thanks again, <a href="https://github.com/MartinUbl">Martin</a>!) They had a wrapper for the core SmartCGMS engine (which contains <a href="https://github.com/SmartCGMS/core/blob/dffdd89a274144d0e9ecbe9f581db9eca0e4b8ed/model/src/bergman/bergman.cpp#L82">implementations of some of these models</a> already) for the C# language. The API was quite simple:</p>

<ul>
  <li><code>.Create(...)</code> - initialize the simulation</li>
  <li><code>.Step()</code> - step one time-unit (typically a minute) in the simulation</li>
  <li><code>.ScheduleInsulinBasalRate(double unitsPerHour)</code> - schedule a (pump, sadly) insulin dosage</li>
  <li><code>.ScheduleInsulinBolus(double units)</code> - schedule a short-acting insulin injection</li>
  <li><code>.ScheduleCarbohydratesIntake(double grams)</code> - schedule food consumption</li>
  <li><code>.Terminate()</code> - stop the simulation</li>
</ul>

<p>And then there was the current simulation state:</p>

<ul>
  <li><code>.BloodGlucose</code> - current blood sugar, in mmol/l</li>
  <li><code>.InterstitialGlucose</code> - glucose in your interstitial fluid - let’s skip it, not important</li>
  <li><code>.InsulinOnBoard</code> - how much insulin is still left to be absorbed</li>
  <li><code>.CarbohydratesOnBoard</code> - how much sugar is still left to be absorbed</li>
</ul>

<p>As you can see, with some caveats this would let me make a simulation for my daily schedule.</p>

<p>So a few moments later I had something like this (in C# but here presented as Elm)</p>

<pre><code>type IntakeType
  = BasalInsulin -- long-acting
  | BolusInsulin -- short-acting
  | Carbs        -- fooooooooooooood!

type alias Intake =
  { intakeType : IntakeType
  , amount : Float
  , timeMinutes : Int
  }

type alias Input =
  { basalInsulin : Intake
  , bolusInsulins : List Intake
  , carbs : List Intake
  }

type alias OutputRow =
  { minute : Float
  , bloodGlucose : Float
  , carbohydratesOnBoard : Float
  , insulinOnBoard : Float
  , interstitialGlucose : Float
  }

simulate : Input -&gt; Int -&gt; List OutputRow
simulate input days =
  ...

mySchedule : Input
mySchedule =
  { basalInsulin = Intake BasalInsulin (22 * 60) 32
  , bolusInsulins =
      [ Intake BolusInsulin (10 * 60) 18
      , Intake BolusInsulin (13 * 60) 22
      , Intake BolusInsulin (19 * 60) 21
      ]
  , carbs =
      [ Intake Carbs (10 * 60) 24
      , Intake Carbs (13 * 60) 60
      , Intake Carbs (19 * 60) 60
      , Intake Carbs (22 * 60) 24
      ]
  }

myPrediction : List OutputRow
myPrediction =
  simulate mySchedule 3
</code></pre>

<p>Never have I copied the resulting CSV into Google Sheets so fast. Tada:</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/00-accidental-art.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/00-accidental-art.png" alt="I'm the artist now."></a></p>

<p>Oh, wait, that’s not it. Cool piece of accidental art though! Now let me use the correct column for the X axis.</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/01-google-sheets.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/01-google-sheets.png" alt="Google Sheets"></a></p>

<p>Well hot damn. The graph actually makes sense!</p>

<p>Granted, it’s not <em>me</em> in the graph but I can simulate <em>someone</em> now!</p>

<p><em>Let’s stash away “I need to actually simulate</em> me, <em>you know” as a TODO for future Martin and continue.</em></p>

<hr>

<p>Next I made a Windows Forms application with an OxyPlot chart so that I don’t need to write a CSV to a file and manually copy it to Google Sheets.</p>

<blockquote>
  <p>Aside: what do you .NET folks use nowadays? MAUI? WPF? Xamarin Forms? It’s kinda confusing for an outsider.</p>
</blockquote>

<p>This took me a while to figure out (I’m not a C# guy; honestly I’ve thought about rewriting this into F# instead the moment I had to start learning about event handlers and delegates), but I succeeded:</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/02-initial-graph.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/02-initial-graph.png" alt="Initial graph"></a></p>

<p>There’s one little issue with seeing just the first day of the simulation though, and that’s the fact that I inject my basal (long-acting) insulin at 22:00. So for the majority of the first day the glucose will just be higher because I haven’t injected the long-acting insulin yet. So let’s simulate more days just to see what happens.</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/03-ranges.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/03-ranges.png" alt="Ranges"></a></p>

<p>Oh wow, it gets periodic by day 3! Cool!</p>

<p>As you can see I’ve also added the hypo- and hyperglycemic ranges so that it’s clearer where the “Goldilocks zone” lies. As it turns out, my insulin dosage is absolutely inappropriate for the person simulated by SmartCGMS right now. Hitting such severe hypoglycemia, they’d probably be dead by now (or their liver has to work overtime on dosing that emergency glucose).</p>

<p>OK, well then, now it’s just a small step from simulating a hardcoded</p>

<pre><code>mySchedule : Input
mySchedule =
  { basalInsulin = Intake BasalInsulin (22 * 60) 32
  , bolusInsulins =
      [ Intake BolusInsulin (10 * 60) 18
      , Intake BolusInsulin (13 * 60) 22
      , Intake BolusInsulin (19 * 60) 21
      ]
  , carbs =
      [ Intake Carbs (10 * 60) 24
      , Intake Carbs (13 * 60) 60
      , Intake Carbs (19 * 60) 60
      , Intake Carbs (22 * 60) 24
      ]
  }
</code></pre>

<p>to automatically finding a more optimal dosage!</p>

<hr>

<p>I’ve opened the NuGet package manager, wrote <code>genetic</code> and installed the most popular package: <a href="https://github.com/giacomelli/GeneticSharp">GeneticSharp</a>. Turns out it’s <em>really solid.</em> It needed me to provide the usual stuff: chromosomes, crossover, selection, population size, termination criteria… and the fitness function.</p>

<p>The fitness function actually deserves a fuller description. It looks like this:</p>

<pre><code>fitness : Input -&gt; Float
fitness input =
  let
    output : List OutputRow
    output = simulate input 3

    longtermHypos = output |&gt; List.takeLast (24*60) |&gt; List.count (\row -&gt; row.bloodGlucose &lt; 4)
    longtermHypers = output |&gt; List.takeLast (24*60) |&gt; List.count (\row -&gt; row.bloodGlucose &gt;= 10)
    ...

    longtermHyposNormalized = longtermHypos / List.length output
    longtermHypersNormalized = longtermHypers / List.length output
    ...

    longtermHyposWeight = 15
    longtermHypersWeight = 12
    ...

    weightSum = longtermHyposWeight + longtermHypersWeight + ...
  in
  ( longtermHyposNormalized * longtermHyposWeight
  + longtermHypersNormalized * longtermHypersWeight
  + ...
  ) / weightSum
</code></pre>

<p><em>(Yes I know stuff is computed needlessly here; in the real C# code I’m doing all the intermediate result reuse you wish I did here, but I’m optimizing for understanding instead here.)</em></p>

<p>Turns out I care about many things. The following list evolved gradually but I’m only giving you the final version:</p>
<ul>
  <li>minimize # of hypoglycemic readings in the (stabilized) last day</li>
  <li>minimize # of hyperglycemic readings in the last day</li>
  <li>as small amplitude between min and max glucose reading as possible in the last day</li>
  <li>minimize the sum of bolus insulin dosages</li>
  <li>minimize the basal insulin dosage</li>
  <li>minimize # of hypoglycemic readings in the stabilization phase (first 2 days)</li>
  <li>minimize # of hyperglycemic readings in the stabilization phase</li>
</ul>

<p>Note that I don’t care about all of those equally. I’ve actually sorted the above list by priority: long-term hypos are the most urgent, the temporary hypers while the system settles I care about the least. I’m encoding that via the weights. Each of the normalized measurements is a number <code>0..1</code>, which then gets multiplied by the weight.</p>

<p>I’m not quite sure whether this is the right way to encode multiple concerns into a single number, but it’s the best I could come up with without consulting math books, and it seems to work well. At least I couldn’t find a case where an input with lower (better) fitness was less preferable to me (according to my brain’s fuzzy intuition) than another input with higher (worse) fitness.</p>

<p>If I was able to construct all the values and sort them, I’d probably do something like</p>

<pre><code>allCombinations
  |&gt; List.sortBy (\output -&gt;
       [ longtermHypos output
       , longtermHypers output
       , amplitude output
       , ...
       ]
     )
</code></pre>

<p>(that is, I can order outputs pairwise), but that’s not how the genetic programming libraries work. I believe explicitly not going through the whole space is one of their very top priorities :)</p>

<blockquote>
  <p>Aside: how many inputs are there? This to me looks like permutations with repetitions (order does matter), <code>n^r</code> , so in my case <code>injectionPossibilities ^ injectionCount</code>, and for my specific example schedule, <code>51^4</code>  (assuming I can inject <code>0..50</code> units of insulin). That’s around 6.7 million.</p>
</blockquote>

<p>So this could be bruteforceable. But I have to run the whole simulation inside the fitness function, and it takes around a second or two.</p>

<p>At least it’s parallelizable then! (And believe me, I’m making use of my 16 cores.)</p>

<p>Given it’s a pure function (basically… the results vary around the 10th decimal digit - negligible), I can memoize the fitness function for the input of four ints. The genetic algorithm ends up repeating some guesses quite a lot near the end of the simulation, so this actually saves a lot of time.</p>

<p>Writing a memoization function in C# was a breath of fresh air, coming from the pure FP world of Elm:</p>

<pre><code>private Dictionary&lt;List&lt;Intake&gt;, double&gt; fitnessCache = new(new IntakesSameAmount());

// ...

if (fitnessCache.TryGetValue(amounts, out var cachedFitness))
    return cachedFitness;

// ...

var fitness = Fitness(newInput);
fitnessCache.Add(amounts, fitness);
return fitness;
</code></pre>

<p><em>Amazing what you can do with a bit of mutation. Yeah I’ll go return my Elm badge now.</em></p>

<hr>

<p>So, with this fitness function created, I can now run the genetic algorithm. Let’s add a button and some more info to the UI, and start it off!</p>

<p><a href="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/04-original-and-best.png"><img src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/04-original-and-best.png" alt="Intakes on the side, and a button"></a></p>

<p><em>WELL HOT DAMN.</em> It has optimized the insulin intakes and the patient (again, sadly not <em>me</em>) is now stable inside the 4-10 mmol/l range.</p>

<p>That’s really magical. I feel like I’ve solved diabetes. Of course it’s not as simple. There will always  be unexpected things and changes you need to react to. You’ll have hypers, you’ll have hypos and it’s OK. But still. It managed to squeeze the blood glucose into the correct range.</p>

<hr>

<p>So, what do I need to make this useful <em>to me?</em></p>

<p>I feel like interactivity would go a long way. Being able to add injections or meals, move them up and down, left and right, and seeing the graph change based on that, would give the diabetic much better understanding than the <em>“OK I’m gonna inject more before lunch today and see what happens two hours from now”</em> feedback loop, or even worse, the <em>“consult a doctor every three months”</em> one. Did I mention I’m a big fan of short feedback loops?</p>

<p>Of course, it needs to simulate <em>me</em> instead of somebody else. I can’t use these optimized dosages because my body reacts differently. I need to consult this with the SmartCGMS folks, but the process will likely involve me downloading my historical blood glucose data off my Freestyle Libre sensor and somebody somewhere fitting the model parameters to that data. The math escapes me but it can be done.</p>

<p>Another issue is that the algorithm is optimized for pumps, and my basal (long-acting) insulin will need to be tracked into the model a bit differently. Right now it’s as if I was injecting 1/24-th of the dosage every hour, instead of the full dosage once a day. But once the specific insulin brand and its behaviour is tracked in the software, I will be able to call <code>.ScheduleInsulinBasal(double units)</code> and all should be well (and more precise), hopefully.</p>

<p>So, there’s a bunch of stuff yet to be done and collaborate with the SmartCGMS folks on, but I’m <em>really</em> excited by this, and feel empowered taking care of my diabetes better than I thought I could. WE’VE GOT THE TECHNOLOGY! Genetic algorithms and Markov Chains, baby!</p>

<hr>

<p>What’s that? I didn’t mention Markov Chains <em>once</em> in the article?</p>

<p>Oh yeah, well, I experimented with a bunch of stuff. To end off the blogpost, here’s a stupid random walk arriving at a value iteratively. (Change each intake by a random value <code>-2..+2</code>, and if the fitness of that tweaked input is better, keep the change, otherwise rollback.)</p>

<video src="https://martin.janiczek.cz/assets/images/2024-07-23-taking-my-diabetes-treatment-into-my-own-hands/recording.mp4" controls="">
</video>

    <hr>





  </div>

  
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You can opt out of airport face scans (254 pts)]]></title>
            <link>https://www.vox.com/future-perfect/360952/summer-travel-airport-facial-recognition-scan</link>
            <guid>41051327</guid>
            <pubDate>Tue, 23 Jul 2024 21:50:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vox.com/future-perfect/360952/summer-travel-airport-facial-recognition-scan">https://www.vox.com/future-perfect/360952/summer-travel-airport-facial-recognition-scan</a>, See on <a href="https://news.ycombinator.com/item?id=41051327">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Here’s something I’m embarrassed to admit: Even though I’ve been reporting on <a href="https://www.vox.com/future-perfect/2019/4/27/18518598/ai-facial-recognition-ban-apple-amazon-microsoft">the problems</a> with <a href="https://www.vox.com/future-perfect/2019/5/16/18625137/ai-facial-recognition-ban-san-francisco-surveillance">facial recognition</a> for <a href="https://www.theatlantic.com/international/archive/2018/08/china-surveillance-technology-muslims/567443/">half a dozen years</a>, I have allowed my face to be scanned at airports. Not once. Not twice. Many times. </p><p>There are lots of reasons for that. For one thing, traveling is stressful. I feel time pressure to make it to my gate quickly and social pressure not to hold up long lines. (This alone makes it feel like I’m not truly consenting to the face scans so much as being coerced into them.) Plus, I’m always getting “randomly selected” for additional screenings, maybe because of my Middle Eastern background. So I get nervous about doing anything that might lead to extra delays or interrogations.</p><p>But the main reason I haven’t declined airport face scans is actually very simple: I had no idea I could opt out. </p><p>It turns out that saying no is not only doable, but <a href="https://keepbeyond.com/optout/">surprisingly easy</a> — at least in theory. Everyone, regardless of citizenship, can opt out when it comes to domestic flights in the US. (For international flights, US citizens can opt out but foreign nationals have to participate in face scanning, <a href="https://www.cbp.gov/about/congressional-resources/testimony/statement-record-assessing-cbps-use-facial-recognition-technology">with some exceptions</a>.) Simply stand away from the camera or keep your face covered with a mask, present your ID, and say, “I opt out of biometrics. I want the standard verification process.” </p><div><p>In theory, an officer is then supposed to manually look over your ID and compare it to your face, as they used to do before facial recognition. But in practice, there have been <a href="https://www.washingtonpost.com/technology/2023/07/11/tsa-airport-security-facial-recognition/">reports of passengers — even a senator — facing resistance or intimidation</a> when they try to go this route. </p></div><p>The Transportation Security Administration (TSA) and Customs and Border Protection (CBP) are also supposed to have clear signs informing passengers of the right to opt out. But at many airports, you have to look really, really hard to spot that message. Be prepared to crane your neck at an unnatural angle or squint at a very small font!</p><p>This is why the Algorithmic Justice League, a nonprofit that sheds light on AI harms, launched a campaign this month called <a href="https://www.ajl.org/campaigns/fly">“Freedom Flyers”</a> to raise awareness of your right to opt out. The timing is perfect: The TSA <a href="https://thehill.com/regulation/transportation/4738416-transportation-security-administration-record-air-travel-day/">recorded</a> an all-time record day for air travel on June 23, with nearly 3 million people screened at the country’s airports as summer vacation season picked up. </p><p>Now is the ideal time to make sure you know your rights when you pass through airport security — and understand exactly what’s at stake. The implications go way beyond air travel. </p><div><p id="how-facial-recognition-works-at-the-airport"><h2>How facial recognition works at the airport</h2></p></div><p>In the US, <a href="https://apnews.com/article/facial-recognition-tsa-airport-security-privacy-7b97462591c49184d1cb19cda9c95211">over 80 airports</a> are currently piloting facial recognition technology. The TSA’s goal is to roll out the tech in all of the more than 430 airports that it covers, <a href="https://www.tsa.gov/sites/default/files/tsa_biometrics_roadmap.pdf">arguing</a> that this kind of automation would reduce “friction” at airports — meaning, presumably, how long it takes passengers to move through security. </p><p>That should raise some eyebrows, because there are known risks with this AI technology, from the possibility that your face data will be <a href="https://www.oversight.gov/report/dhs/review-cbps-major-cybersecurity-incident-during-2019-biometric-pilot">stolen due to breaches</a> to the chance that you’ll be <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html">misidentified as a criminal suspect — and jailed</a>. Neither of these are hypothetical scenarios; the former has happened due to CBP system vulnerabilities and the latter has happened at the hands of police. And then, of course, there’s <a href="https://www.vox.com/future-perfect/22916602/ai-bias-fairness-tradeoffs-artificial-intelligence">AI bias</a>; facial recognition tech is known to disproportionately <a href="https://www.vox.com/future-perfect/2019/4/19/18412674/ai-bias-facial-recognition-black-gay-transgender">misidentify people of color</a>. (A CBP spokesperson insisted that the agency’s facial comparison algorithm “shows virtually no measurable differential performance in results based on demographic factors.”)</p><p>But as dangerous as face recognition can be if it goes wrong, a greater concern could be what happens if it’s seen to work as intended. When I asked <a href="https://www.vox.com/future-perfect/23365558/future-perfect-50-ai-joy-buolamwini-founder-algorithmic-justice-league">Joy Buolamwini</a>, the founder of the Algorithmic Justice League, what worries her about the use of this tech in airports, she said, “The big one for me is normalizing surveillance.”</p><p>Buolamwini argued that airport face recognition is a way of acclimating the public to having more and more sensitive information taken. “I see this on a longer trajectory,” she said. “And they’ve shown you the trajectory.”</p><p>She was referring to <a href="https://www.tsa.gov/sites/default/files/tsa_biometrics_roadmap.pdf">a roadmap released in 2018 by the TSA</a>. It distinguishes between two types of facial recognition: There’s one-to-one matching, where the TSA compares the photo in your passport with the photo they take of you at the airport, to make sure that the photos match. (If you ever use your face to unlock your iPhone, this is the kind of facial recognition you’re using.)</p><p>Then there’s one-to-many matching, where your image is compared with images of others. One-to-many matching is already in use by CBP and airline partners in that they compare a passenger’s photo to a database of government documents (like US passports) for verification, TSA press secretary Carter Langston told me by email.</p><p>A particularly worrisome form of one-to-many matching is live biometrics. “Live biometrics is the <em>Minority Report</em> kind of thing — where you’re just walking around and they can identify you,” Buolamwini said. And if everyone’s face becomes fair game for live biometrics, your likeness could one day be checked against a criminal database any time you walk through a drug store or show up at a protest, which may <a href="https://www.vox.com/future-perfect/2019/5/16/18625137/ai-facial-recognition-ban-san-francisco-surveillance">create a dangerous chilling effect</a> across society. </p><p>The TSA’s own 2018 roadmap says they aim to use “live biometrics” in the future. However, Langston disputed Buolamwini’s interpretation of that term. “That interpretation of TSA’s use case is nothing that I have heard anyone involved in the program indicate. TSA’s use case is and continues to be about identity verification,” he told me.</p><p>For now, Buolamwini said, “You might hear people say ‘Oh, we’re only doing one-to-one matching. You show us your ID, you show us your face, and we delete the data.’” But, she stressed, the full story is more complicated.</p><div><p id="do-airports-really-delete-your-photo-after-taking-it"><h2>Do airports really delete your photo after taking it?</h2></p></div><p>The first thing to know is that if you’re not a US citizen, you have no guarantee that your photo will be deleted. </p><p>In fact, <a href="https://www.cbp.gov/sites/default/files/assets/documents/2022-Sep/CPE%20Final%20Report%20Traveler%20Verification%20Service%2020220815%20Final_%20Redacted_0.pdf">according to CBP documents</a>, “Facial images for in-scope [noncitizen] travelers are also transmitted to the Department’s Automated Biometric Identification System (IDENT) and Homeland Advanced Recognition Technology System (HART). All biometrics of in-scope travelers are transmitted to IDENT/HART as encounters and are retained for 75 years in support of immigration, border management, and law enforcement activities.”</p><p>That means your photo could end up in the database for the rest of your life. What’s more, CBP <a href="https://www.dhs.gov/sites/default/files/publications/privacy-pia-cbp056-tvs-february2021.pdf">notes</a> that “CBP may share information with federal, state, and local authorities, which may be authorized to use the information for purposes beyond the scope of CBP’s mission.”</p><p>If you’re a US citizen, you might breathe a bit easier upon reading on the CBP <a href="https://www.cbp.gov/travel/biometrics/biometric-privacy-policy">website</a>, “CBP retains U.S. citizen photos for no more than 12 hours after identity verification, and only for continuity of operations purposes.” But even so, Buolamwini says, there’s reason to wonder whether all your data is really deleted after those 12 hours.</p><p>When you submit to facial recognition, the tech analyzes a photo of your face and creates what’s called a “face print” or “face template.” This is not an image — it comes in the form of a series of numbers. You can think of it as your face’s metadata. </p><p>The problem is, even if airports do delete your photo, that does not necessarily mean they’re deleting your face print. And that face print is the real informational gold. Researchers have shown that <a href="https://ieeexplore.ieee.org/document/8338413">they can reconstruct an image of your actual face</a> as long as they’ve got the face print. </p><p>I asked CBP what happens to that precious series of numbers. A CBP spokesperson did not answer the question about whether face prints get deleted in time for publication. After we published this story, the CBP spokesperson said that “CBP does not store or share the templates generated during the matching process, for either US citizens or non-citizens.”</p><div><p id="if-youve-already-let-airports-scan-your-face-is-there-a-point-in-saying-no-next-time"><h2>If you’ve already let airports scan your face, is there a point in saying no next time?</h2></p></div><p>Maybe you’re in the same situation as me. Maybe you’ve already let airports scan your face. And maybe you’re wondering whether saying no in the future will make any difference, given that your face data is probably already in a database — or two — or three. (Separate from TSA, your individual airline may also scan your face instead of your boarding pass before letting you on the plane, though airlines <a href="https://www.pcmag.com/opinions/you-can-say-no-to-face-scans-for-airplane-boarding">say</a> you can opt out for domestic flights.)</p><p>Buolamwini’s opinion? It’s definitely still worth declining the face scan next time you fly. “Every opt-out opportunity is a way to vote for your biometric rights,” she said.</p><p>We’ve already seen that when there’s enough of a public outcry, it can lead to deletion of face data. After Facebook’s facial recognition system sparked a class-action lawsuit, government investigations, and public furor, the company ended up <a href="https://www.nytimes.com/2021/11/02/technology/facebook-facial-recognition.html">deleting the face prints of more than a billion users</a> in 2021. </p><p>“Face purges can and do happen,” Buolamwini said. </p><p>Remember, the TSA’s stated reason for rolling out facial recognition in airports is to minimize friction. If you’re unhappy about the use of the tech, you can consider generating more friction next time you fly. </p><div><p><em>A version of this story originally appeared in the </em><a href="https://www.vox.com/future-perfect"><em><strong>Future Perfect</strong></em></a><em> newsletter. </em><a href="https://www.vox.com/pages/future-perfect-newsletter-signup"><em><strong>Sign up here!</strong></em></a></p></div><p><em><strong>Update, July 19, 2:30 pm ET: </strong>This story was originally published July 17 and has been updated with new comment from US Customs and Border Protection.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ESA report shows unsustainable levels of orbital debris (105 pts)]]></title>
            <link>https://payloadspace.com/esa-report-shows-unsustainable-levels-of-orbital-debris/</link>
            <guid>41051257</guid>
            <pubDate>Tue, 23 Jul 2024 21:41:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://payloadspace.com/esa-report-shows-unsustainable-levels-of-orbital-debris/">https://payloadspace.com/esa-report-shows-unsustainable-levels-of-orbital-debris/</a>, See on <a href="https://news.ycombinator.com/item?id=41051257">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primary"><p><span>Related Stories</span></p><div><div><h2> <a href="https://payloadspace.com/asteroid-watchers-fret-about-politicians-facing-dangerous-neos/" data-wpel-link="internal">Asteroid Watchers Fret About Politicians Facing Dangerous NEOs</a></h2><p>“I know what I would prefer [to do], but Congress will tell us to wait,”</p> <p><span><time datetime="2024-07-01T08:14:49-04:00">July 1, 2024</time><time datetime="2024-07-01T18:25:23-04:00">July 1, 2024</time></span></p></div><div><h2> <a href="https://payloadspace.com/spacex-will-destroy-the-iss/" data-wpel-link="internal">SpaceX Will Destroy The ISS</a></h2><p>NASA will pay SpaceX $843M to develop the US Deorbit Vehicle.</p> <p><span><time datetime="2024-06-27T08:13:19-04:00">June 27, 2024</time><time datetime="2024-06-27T08:13:21-04:00">June 27, 2024</time></span></p></div><div><h2> <a href="https://payloadspace.com/kayhan-space-releases-satcat-space-intelligence-tool/" data-wpel-link="internal">Kayhan Space Releases Satcat Space Intelligence Tool</a></h2><p>The Satcat database catalogs 60,000+ objects in orbit, from active satellites to drifting debris</p> <p><span><time datetime="2024-06-14T08:45:39-04:00">June 14, 2024</time><time datetime="2024-06-14T09:21:50-04:00">June 14, 2024</time></span></p></div><div><h2> <a href="https://payloadspace.com/astroscale-shares-surge-in-market-debut/" data-wpel-link="internal">Astroscale Shares Surge in Market Debut</a></h2><p>Astroscale’s IPO proves there’s value in junk stocks—space junk stocks, that is.</p> <p><span><time datetime="2024-06-06T08:23:46-04:00">June 6, 2024</time><time datetime="2024-06-06T08:23:48-04:00">June 6, 2024</time></span></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hydrothermal explosion at Yellowstone National Park (489 pts)]]></title>
            <link>https://www.jhnewsandguide.com/the_hole_scroll/video-biscuit-basin-geyser-explodes-sending-yellowstone-tourists-packing/article_6862fda2-4923-11ef-b5c4-abdc9bc8cd83.html</link>
            <guid>41050055</guid>
            <pubDate>Tue, 23 Jul 2024 19:49:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jhnewsandguide.com/the_hole_scroll/video-biscuit-basin-geyser-explodes-sending-yellowstone-tourists-packing/article_6862fda2-4923-11ef-b5c4-abdc9bc8cd83.html">https://www.jhnewsandguide.com/the_hole_scroll/video-biscuit-basin-geyser-explodes-sending-yellowstone-tourists-packing/article_6862fda2-4923-11ef-b5c4-abdc9bc8cd83.html</a>, See on <a href="https://news.ycombinator.com/item?id=41050055">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p><label for="field-postal-state-super-purchase">
                            State
                        </label>
                        
                    </p>
                    <p><label for="field-postal-postcode-super-purchase">
                            Zip Code
                        </label>
                        
                    </p>
                    <p><label for="field-postal-country-super-purchase">
                            Country
                        </label>
                        
                    </p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: All VC Funded Startups Aggregated (Statistics) (370 pts)]]></title>
            <link>https://old.reddit.com/r/LeadGeneration/comments/1ea8r16/httpswwwredditcomremailcomments1ea8qd2i_built_a/</link>
            <guid>41049968</guid>
            <pubDate>Tue, 23 Jul 2024 19:41:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/LeadGeneration/comments/1ea8r16/httpswwwredditcomremailcomments1ea8qd2i_built_a/">https://old.reddit.com/r/LeadGeneration/comments/1ea8r16/httpswwwredditcomremailcomments1ea8qd2i_built_a/</a>, See on <a href="https://news.ycombinator.com/item?id=41049968">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="searchexpando"><p><label>limit my search to r/LeadGeneration</label></p><div id="moresearchinfo"><p>use the following search parameters to narrow your results:</p><dl><dt>subreddit:<i>subreddit</i></dt><dd>find submissions in "subreddit"</dd><dt>author:<i>username</i></dt><dd>find submissions by "username"</dd><dt>site:<i>example.com</i></dt><dd>find submissions from "example.com"</dd><dt>url:<i>text</i></dt><dd>search for "text" in url</dd><dt>selftext:<i>text</i></dt><dd>search for "text" in self post contents</dd><dt>self:yes (or self:no)</dt><dd>include (or exclude) self posts</dd><dt>nsfw:yes (or nsfw:no)</dt><dd>include (or exclude) results marked as NSFW</dd></dl><p>e.g. <code>subreddit:aww site:imgur.com dog</code></p><p><a href="https://www.reddit.com/wiki/search">see the search faq for details.</a></p></div><p><a href="https://www.reddit.com/wiki/search" id="search_showmore">advanced search: by author, subreddit...</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Drive scans files for copyright infringement (119 pts)]]></title>
            <link>https://twitter.com/1littlecoder/status/1815830211612586255</link>
            <guid>41049799</guid>
            <pubDate>Tue, 23 Jul 2024 19:26:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/1littlecoder/status/1815830211612586255">https://twitter.com/1littlecoder/status/1815830211612586255</a>, See on <a href="https://news.ycombinator.com/item?id=41049799">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Dtui – TUI for introspecting the state of the system/session dbus (123 pts)]]></title>
            <link>https://github.com/Troels51/dtui</link>
            <guid>41049587</guid>
            <pubDate>Tue, 23 Jul 2024 19:02:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Troels51/dtui">https://github.com/Troels51/dtui</a>, See on <a href="https://news.ycombinator.com/item?id=41049587">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-turbo-body="">
      


    <div>
      <p><a href="#start-of-content" data-skip-target-assigned="false">Skip to content</a>

      <span data-view-component="true">
    <span data-view-component="true"></span>
</span></p><react-partial partial-name="keyboard-shortcuts-dialog" data-ssr="false">
  
  
  
</react-partial>




      

          

              


<header role="banner" data-color-mode="light" data-light-theme="light" data-dark-theme="dark">
  <h2>Navigation Menu</h2>

  

  <div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to GitHub Copilot&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>GitHub Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>

                  <li>
      
      <div>
              <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Resources&quot;,&quot;action&quot;:&quot;click to go to Learning Pathways&quot;,&quot;label&quot;:&quot;ref_cta:Learning Pathways;&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Resources&quot;,&quot;action&quot;:&quot;click to go to White papers, Ebooks, Webinars&quot;,&quot;label&quot;:&quot;ref_cta:White papers, Ebooks, Webinars;&quot;}" href="https://resources.github.com/">
      White papers, Ebooks, Webinars

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Resources&quot;,&quot;action&quot;:&quot;click to go to Customer Stories&quot;,&quot;label&quot;:&quot;ref_cta:Customer Stories;&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Resources&quot;,&quot;action&quot;:&quot;click to go to Partners&quot;,&quot;label&quot;:&quot;ref_cta:Partners;&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Enterprise&quot;,&quot;action&quot;:&quot;click to go to Enterprise platform&quot;,&quot;label&quot;:&quot;ref_cta:Enterprise platform;&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>Enterprise platform</p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:Troels51/dtui" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="iNFEo17eoEhx68nX1ah1qnP50ea2DZ2BsGSVntvIGnA4TOoV_ZpFXXYif7rJr3SAsQd_2ud6WgS0KI0Ne0rKpg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="Troels51/dtui" data-current-org="" data-current-owner="Troels51" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=Troels51%2Fdtui" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/Troels51/dtui&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5ffa21cc0f6b7fafdbdc67d8d4881aaee91662ed68ced721344461a53d1c242c" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a>
        </p></div>
      </div>
</header>

      
    </div>

  








    


    
    <include-fragment data-base-src="https://github.com/notifications/beta/shelf"></include-fragment>





  <div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  





    






  
  

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div id="repo-content-pjax-container">

  

  <include-fragment src="/Troels51/dtui/spoofed_commit_check/16905326a9ce5d219992bda48f5fbde4ce68b4e2" data-test-selector="spoofed-commit-check"></include-fragment>

  <div data-view-component="true">      





















<react-partial partial-name="repos-overview" data-ssr="true">
  
  
  <div data-target="react-partial.reactRoot"><div><h2>Repository files navigation</h2><nav aria-label="Repository files"><ul role="list"><li><a href="#" aria-current="page"><span data-component="icon"></span><span data-component="text" data-content="README">README</span></a></li></ul></nav></div><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">dtui</h2><a id="user-content-dtui" aria-label="Permalink: dtui" href="#dtui"></a></p>
<p dir="auto"><a href="https://github.com/Troels51/dtui/actions/workflows/build.yml"><img src="https://github.com/Troels51/dtui/actions/workflows/build.yml/badge.svg" alt="build"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/aee2700f32aa3b1fdf4d62aafe45e53193f8b607949a679595f75c9a291aa508/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f647475693f6c696e6b3d68747470732533412532462532466372617465732e696f25324663726174657325324664747569"><img src="https://camo.githubusercontent.com/aee2700f32aa3b1fdf4d62aafe45e53193f8b607949a679595f75c9a291aa508/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f647475693f6c696e6b3d68747470732533412532462532466372617465732e696f25324663726174657325324664747569" alt="Crates.io Version" data-canonical-src="https://img.shields.io/crates/v/dtui?link=https%3A%2F%2Fcrates.io%2Fcrates%2Fdtui"></a></p>
<p dir="auto">A small TUI for d-termining the state of your dbus.
It will show you the current services running and allow you to introspect objects and their interfaces in those services</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Troels51/dtui/blob/main/images/dtui.png"><img src="https://github.com/Troels51/dtui/raw/main/images/dtui.png" alt="Example"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build</h2><a id="user-content-build" aria-label="Permalink: Build" href="#build"></a></p>
<p dir="auto">To build install Rust and cargo, then run build</p>

<p dir="auto">To run from cargo</p>

</article></div></div>
</react-partial>

      </div></div>

</turbo-frame>


    </main>
  </div>

          




    <ghcc-consent id="ghcc" data-initial-cookie-consent-allowed="" data-cookie-consent-required="true"></ghcc-consent>


  

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open="">
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog="">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Olympics officials try to catch “motor doping” (207 pts)]]></title>
            <link>https://spectrum.ieee.org/motor-doping-cycling</link>
            <guid>41049399</guid>
            <pubDate>Tue, 23 Jul 2024 18:43:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/motor-doping-cycling">https://spectrum.ieee.org/motor-doping-cycling</a>, See on <a href="https://news.ycombinator.com/item?id=41049399">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="How Olympics Officials Try to Catch “Motor Doping”"><p>A French cycling official confronts a rider suspected of doping and ends up jumping onto the hood of a van making a high-speed getaway. This isn’t a tragicomedy starring <a href="https://en.wikipedia.org/wiki/G%C3%A9rard_Depardieu" target="_blank">Gérard Depardieu</a>, sending up the sport’s well-earned reputation for cheating. This scenario played out in May at the <a href="https://www.cyclingweekly.com/news/motor-doping-suspect-runs-down-race-organiser-while-escaping-inspection" target="_blank">Routes de l’Oise cycling competition</a> near Paris, and the van was believed to contain evidence of a distinctly 21st-century cheat: a hidden electric motor.<strong></strong></p><p>Cyclists call it “motor doping.” At the Paris Olympics opening on Friday, officials will be deploying electromagnetic scanners and X-ray imaging to combat it, as cyclists race for gold in and around the French capital. The officials’ prey can be quite small: Cycling experts say just 20 or 30 watts of extra power is enough to tilt the field and clinch a race.</p><p>Motor doping has been confirmed only once in professional cycling, way back in 2016. And the sport’s governing body, the <a href="https://www.uci.org/" target="_blank"><u>Union Cycliste Internationale</u></a> (UCI), has since introduced increasingly sophisticated motor-detection methods. But illicit motors remain a scourge at high-profile amateur events like the Routes de l’Oise. Some top professionals, past and present, continue to raise an alarm.</p><p>“It’s 10 years now that we’re speaking about this…. If you want to settle this issue you have to invest.” <strong>—Jean-Christophe Péraud, former Union Cycliste Internationale official</strong></p><p>Riders and experts reached by <em><a href="https://spectrum.ieee.org/">IEEE Spectrum</a></em> say it’s unlikely that technological doping still exists at the professional level. “I’m confident it’s not happening any more. I think as soon as we began to speak about it, it stopped. Because at a high level it’s too dangerous for a team and an athlete,” says <a href="https://www.procyclingstats.com/rider/jean-christophe-peraud" target="_blank"><u>Jean-Christophe Péraud</u></a>, an <a href="https://olympics.com/en/athletes/jean-christophe-peraud" target="_blank"><u>Olympic silver medalist</u></a> who <strong></strong>was UCI’s first <a href="https://www.uci.org/pressrelease/the-uci-presents-a-robust-action-plan-to-combat-technological-fraud/6omY2RZitUwewjShNVCAYH" target="_blank">Manager of Equipment and the Fight against Technological Fraud</a>. </p><p>But trust is limited. Cycling is still recovering from the scandals surrounding U.S. Olympian Lance Armstrong, whose extensive use of transfusions and drugs to boost blood-oxygen levels fueled <a href="https://www.theguardian.com/sport/2015/mar/09/lance-armstrong-uci-colluded-circ-report-cycling" target="_blank"><u>allegations of collusion by UCI officials</u></a> and threats to <a href="https://www.reuters.com/article/idUSBRE90E0ZX/" target="_blank"><u>boot cycling out of the Olympics</u></a>. </p><p>Many—including Péraud—say more vigilance is needed. The solution may be next-generation detection tech: onboard scanners that provide continuous assurance that human muscle alone is powering the sport’s dramatic sprints and climbs.</p><h2>How Officials Have Hunted for Motor Doping in Cycling</h2><p>Rumors of hidden motors first <a href="https://www.france24.com/en/20100602-fabio-cancellara-youtube-video-motorized-bike-rubbish-cycling-cheating" target="_blank"><u>swirled into the mainstream in 2010</u></a> after a Swiss cyclist clinched several European events with stunning accelerations. At the time the UCI lacked means of detecting concealed motors, and its technical director promised to “speed up” work on a “quick and efficient way” to do so. </p><p>The UCI began with <a href="https://road.cc/content/news/188441-mechanical-doping-uci-tested-and-rejected-thermal-imaging-detect-motors" target="_blank"><u>infrared cameras</u></a>, but they are useless for pre- and post-race checks when a hidden motor is cold. Not until 2015, amidst <a href="https://www.espn.com/sports/endurance/story/_/id/13272428/endurance-sports-velonews-tour-de-france-leader-chris-froome-facing-more-accusations" target="_blank"><u>further motor doping rumors</u></a> and <a href="https://road.cc/content/news/186575-hidden-motors-used-strade-bianche-claims-french-tv-video#:~:text=Jean-Pierre%20Vedry,%20the%20former,no%20reply,%20no%20checks.%E2%80%9D" target="_blank"><u>allegations of UCI inaction</u></a>, did the organization begin beta testing a better tool: an iPad-based “magnetometric tablet” scanner. </p><p>According to the UCI, an adapter plugged into one of these tablet scanners creates an ambient magnetic field. Then, a magnetometer and custom software register disruptions to the field that may indicate the presence of metal or magnets in and around a bike’s carbon-fiber frame.</p><p>UCI’s tablets delivered in their debut appearance, at the 2016 Cyclocross World Championships held that year in Belgium. Scans of bikes at the rugged event—a blend of road and mountain biking—<a href="https://www.cxmagazine.com/motor-mechanical-doping-femke-van-den-driessche-suspected-2016-cyclocross-world-championships-update" target="_blank"><u>flagged a bike</u></a> bearing the name of local favorite Femke Van den Driessche. Closer inspection revealed a motor and battery lodged within the hollow frame element that angles down from a bike’s saddle to its pedals, and wires connecting the seat tube’s hidden hardware to a push-button switch under the handlebars. </p><p><img alt="person in biking gear pushing bike up a hill on muddy terrain" data-rm-shortcode-id="7595488c2c38efa50c0515ed1fc5e689" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/person-in-biking-gear-pushing-bike-up-a-hill-on-muddy-terrain.jpg?id=52956711&amp;width=980" height="1875" id="57041" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/person-in-biking-gear-pushing-bike-up-a-hill-on-muddy-terrain.jpg?id=52956711&amp;width=980" width="2500"><small placeholder="Add Photo Caption...">In 2016, a concealed motor was found in a bike bearing Belgian cyclist Femke Van Den Driessche’s name at the world cyclo-cross championships. (Van Den Driessche is shown here with a different bike.)</small><small placeholder="Add Photo Credit...">AFP/Getty Images</small></p><p>Van den Driessche, banned from competition for six years, withdrew from racing while maintaining her innocence. (Giovambattista Lera, the amateur cyclist implicated earlier this year in France, <u><a href="https://road.cc/content/news/cyclist-accused-motor-doping-denies-wrong-doing-308633" target="_blank">also denies using electric assistance</a></u> in competition.)</p><p>The motor in Van den Driessche’s bike engaged with the bike’s crankshaft and added 200 W of power. The equipment’s Austrian manufacturer, <a href="https://web.archive.org/web/20171015031645/http://www.vivax-assist.com/en/" target="_blank"><u>Vivax Drive</u></a>, is now defunct. But anyone with cash to spare can experience 200 W of extra push via a racer equipped by Monaco-based HPS-Bike, such as the HPS-equipped <a href="https://www.lotuscars.com/en-GB/type-136" target="_blank">Lotus Type 136 racing bike</a> from U.K. sports car producer Lotus Group, which starts at £15,199 (US $19,715).<strong></strong></p><p>HPS founder &amp; CEO <a href="https://www.linkedin.com/in/harry-gibbings-ab8065201/?originalSubdomain=mc" target="_blank"><u>Harry Gibbings</u></a> says the company seeks to empower weekend riders who don’t want to struggle up steep hills or who need an extra boost here and there to keep up with the pack. Gibbings says the technology is not available for retrofits, and is thus off limits to would-be cheats. Still, <a href="https://www.ride-hps.com/watt-assist/" target="_blank"><u>the HPS Watt Assist system</u></a> shows the outer bounds of what’s possible in discreet high-performance electric assist. </p><p>The 30-millimeter-diameter, 300-gram motor, is manufactured by Swiss motor maker <a href="https://www.maxongroup.com/en" target="_blank"><u>Maxon Group</u></a>, and Gibbings says it uses essentially the same power-dense brushless design that’s propelling NASA’s <a href="https://robotsguide.com/robots/perseverance" target="_blank">Perseverance rover</a> on Mars. HPS builds the motor into a bike’s downtube, the frame element angling up from a bike’s crank toward its handlebars. </p><p>Notwithstanding persistent media speculation about <a href="https://spectrum.ieee.org/tag/electric-motors">electric motors</a> built into rear hubs or solid wheels, Gibbings says only a motor placed in a frame’s tubes can add power without jeopardizing the look, feel, and performance of a racing bike. </p><h2>UCI’s New Techniques to Spot Cheating in Cycling</h2><p>Professional cycling got its most sophisticated detection systems in 2018, after criticism of UCI motor-doping policies <a href="https://www.bbc.com/sport/cycling/41347950.amp" target="_blank"><u>helped fuel a change of leadership</u></a>. Incoming President David Lappartient <a href="http://www.apple.com/" target="_blank"><u>appointed Péraud to push detection</u></a> to new levels, and five months later UCI announced its first X-ray equipment at a press conference in Geneva. </p><p>Unlike the tablet scanners, which yield many false positives and require dismantling of suspect bikes, X-ray imaging is definitive. The <a href="https://www.youtube.com/watch?v=-iRwwquk7v0&amp;t=3s" target="_blank"><u>detector</u></a> is built into a shielded container and driven to events.</p><p>UCI told the cycling press that its X-ray cabinet would “remove any suspicion regarding race results.” And it says it maintains a high level of testing, with close to <a href="https://www.uci.org/pressrelease/the-uci-unveils-its-programme-to-combat-doping-and-technological-fraud-for/5j3GqEVkRlbPZaa3HfwVag#:~:text=At%20last%20year's%20Tour%20de,of%20technological%20fraud%20were%20detected." target="_blank"><u>1,000 motor-doping checks at last year’s Tour de France</u></a>. </p><p>UCI declined to speak with <em>IEEE Spectrum</em> about its motor-detection program, including plans for the Paris Olympics. But it appears to have stepped up vigilance. Lappartient recently acknowledged that UCI’s controls are “<a href="https://www.theguardian.com/sport/article/2024/jun/27/uci-to-pay-whistleblowers-for-motor-doping-tip-offs-at-tour-de-france?CMP=share_btn_url" target="_blank"><u>not 100 percent secure</u></a>” and announced a reward for whistleblowers who deliver evidence of motor fraud. In May, UCI once again <a href="https://www.uci.org/pressrelease/uci-appoints-nicholas-raudenski-as-head-of-the-fight-against-technological/2pu13dvS3ykOj9YOiCg4Aj" target="_blank"><u>appointed a motor-doping czar</u></a>—a first since <a href="https://www.insidethegames.biz/articles/1096111/peraud-loses-uci-role" target="_blank">Péraud departed</a> amidst budget cuts in 2020. Among other duties, former U.S. Department of Homeland Security criminal investigator Nicholas Raudenski is tasked with “development of new methods to detect technological fraud.” </p><p>Unlike the tablet scanners, X-ray imaging is definitive.</p><p>Péraud is convinced that only real-time monitoring of bikes throughout major races can prove that motor fraud is in the past, since big races provide ample opportunities to sneak in an additional bike and thus evade UCI’s current tools.</p><p>UCI has already laid the groundwork for such live monitoring, partnering with France’s <a href="https://www.cea.fr/english/Pages/Welcome.aspx" target="_blank">Alternative Energies and Atomic Energy Commission</a> (Commissariat à l’énergie atomique et aux énergies alternatives, or CEA) to capitalize on the national lab’s deep magnetometry expertise. UCI disclosed some details at its 2018 Geneva press conference, where a CEA official <a href="https://www.uci.org/article/the-uci-presents-a-robust-action-plan-to-combat-technological-fraud-185708/1RaUU9mAQ4qkyXKwN0rXp0" target="_blank"><u>presented its concept</u></a>: an embedded, high-resolution magnetometer to detect a hidden motor’s electromagnetic signature and wirelessly alert officials via receivers on race support vehicles. </p><p>As of June 2018, CEA researchers in Grenoble had <a href="https://www.minatec.org/en/cycling-detecting-hidden-electric-motors/" target="_blank"><u>identified an appropriate magnetometer</u></a> and were evaluating the electromagnetic noise that could challenge the system—“from rotating wheels and pedals to passing motorcycles and cars.” </p><p>Mounting detectors on every bike would not be cheap, but Péraud says he is convinced that cycling needs it: “It’s 10 years now that we’re speaking about this…. If you want to settle this issue you have to invest.” </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why is it so hard to share links on LinkedIn? (125 pts)]]></title>
            <link>https://tedium.co/2024/07/23/linkedin-complex-linking-schemes/</link>
            <guid>41049016</guid>
            <pubDate>Tue, 23 Jul 2024 18:08:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tedium.co/2024/07/23/linkedin-complex-linking-schemes/">https://tedium.co/2024/07/23/linkedin-complex-linking-schemes/</a>, See on <a href="https://news.ycombinator.com/item?id=41049016">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<p><strong>LinkedIn is a social network</strong> that deeply confuses me. It’s a social network that sends messages with such a level of vagueness, seemingly to ensure you’ll never figure them out.</p>
<p>It gamifies profile-viewing in a way that feels less professional and more creepy. Plus, it charges money—a lot of money—for most of its features. It’s a hugely successful network, one that some have suggested is the true heir to the “new Twitter” discourse.</p>
<p>But it has an algorithmic problem that must be called out: Despite the fact that “link” is literally in the network’s name, the network has an allergy towards external links.</p>
<p>And increasingly desperate posters and social media marketers are going through comically complex hoops to work around it. Recently, I caught a video from a guy named <a href="https://www.linkedin.com/in/markpjung/">Mark P. Jung</a>, a consultant whose startup <a href="https://authorityb2b.com/">Authority B2B</a> basically teaches companies and desired influencers the road they need to take to attain LinkedIn success. And to me, it seemed like he was trying to sell some magic beans that appear to actually function.</p>
</div><div>
    
<p>Jung, in a video <a href="https://www.linkedin.com/feed/update/urn:li:activity:7220040502555897856/">shared by content marketer Lindsay McGuire</a>, characterizes the changes as “interesting UI decisions” made since Microsoft acquired the company about eight years ago, changes that have invalidated linking hacks used by the network in prior eras.</p>
<p><a href="https://www.linkedin.com/feed/update/urn:li:activity:7220040502555897856/"><img data-src="https://images.tedium.co/uploads/zeroclick.jpg" width="1000" height="529" alt="Zeroclick" src="https://images.tedium.co/uploads/zeroclick.jpg"></a></p>
<p><em>Jung, in the video of his <a href="https://www.linkedin.com/feed/update/urn:li:activity:7220040502555897856/">that drew attention recently</a>. The use of the term “zero-click” is telling.</em></p>
<p>“Back in the day, people used to sort of get around LinkedIn stuff by just dropping a link in the comments and saying, ‘Hey, check out the comments,’” Jung explains. “Problem is, LinkedIn actually parses if you're the first person to comment in your post, if you're the first person to add a link, even if you actually write, like, the website, but remove the .com and say ‘dot com,’ this algorithm is on to you. It's immediately going to take your post and downrank it.”</p>
<p>So basically, Jung explains the alternative options for sharing a link on LinkedIn as such:</p>
<ol>
<li><strong>Post your thing,</strong> making it sufficiently long so the algorithm might enjoy it.  </li>
<li><strong>Get a little engagement</strong> on said thing, so you signal the post has some interest.</li>
<li><strong>Wait about 15 or 20 minutes.</strong>  </li>
<li><strong>Edit the post,</strong> adding content equivalent to up to 15 percent of the post length, including a URL (which you should shortlink, using a service like Bitly, because every character of the URL counts against the added length). </li>
<li><strong>If you did it right,</strong> watch number go up.</li>
</ol>
<p>Does that sound like a lot of work for a single social post? You betcha. You basically have to make this someone’s job because of how long it takes to do. And it’s likely why every post on LinkedIn is like 100,000 words.</p>
<p>To be clear, my beef is not with Jung, who knows how to build social influence and understands the secrets to algorithmic growth. He sounds like someone who spent his time in the salt mines and doesn’t particularly like that it works like this, either. That he knows about it, apparently having uncovered it through a bunch of trial and error with client work, and is sharing his secrets, is fair.</p>
<p>Rather, my issue is with LinkedIn itself, which has clearly put in a lot of work to devalue the link, even more than other networks that do the same thing, like Instagram and Facebook.</p>
<p>At the ISP and mobile provider level, <a href="https://www.eff.org/deeplinks/2016/02/zero-rating-what-it-is-why-you-should-care">there’s this concept called zero-rating</a>, in which an internet provider provides free access to a selection of sites without the sites counting against the bandwidth limits. (An example of this is T-Mobile <a href="https://www.theregister.com/2015/12/23/youtube_t_mobile_us/">limiting users to 480p-quality videos</a> when streaming on mobile, but requiring you to pay an upcharge for higher-quality videos.) It is seen as a controversial workaround for net neutrality rules—though, while it’s still out there, it has become less of a problem in developed nations as internet connections have gotten faster and more unlimited. LinkedIn is doing something similar with its platform, something called zero-click content, as Jung puts it.</p>
<p>The terminology Jung uses is more telling than you might expect—essentially, it basically implies a social media version of zero-rating, which is a very controversial concept on telecom circles. LinkedIn wants you to create more content for its platform, and it wants you to do so at the cost of any outwardly facing content. So, it downranks anything it sees as damaging to that goal, even if it means breaking the original point of the internet in the process. It is essentially the same concept as zero-rating, except at a more granular level.</p>
<p>The problem with this is twofold: First, it forces content on LinkedIn to take an extremely unnatural shape that doesn’t make sense for a social media platform, often extending well beyond what people want out of it, and two, it limits reach to anyone that doesn’t play by LinkedIn’s rules. It’s a free-trade issue, essentially, and LinkedIn is dominant enough in its niche of business content that a regulator should look into this.</p>
<p>In many ways, social media has these kinds of issues in spades—including on that site I still call Twitter, which has forced people to write gigantic threads instead of linking to blog posts, and Instagram, which is so dominant that it has allowed the creation of secondary businesses around the link in bio.</p>
<p>This is what social media has become, an attempt to work around algorithms, rather than a way to engage with people. <a href="https://www.anildash.com/2019/12/10/link-in-bio-is-how-they-tried-to-kill-the-web/">As Anil Dash wrote</a> back in 2019, with a focus on Instagram rather than LinkedIn, social media seems to be doing all it can to destroy the value of the link:</p>
<blockquote><p>There are some legitimate reasons platforms limit links. Spammers abuse links. Trust is hard to verify around links—too many scammers make links that look real, but lead to sketchy sites. Building a system to monitor all the links being posted on a big platform does take some cost. Maybe you can have a link again, if you are already in the 1% most influential users on the platform and put it in a story—the part of Instagram's experience that drives the engagement metrics they care about. Maybe you just give up, and pay for links, by buying advertising.</p>
<p>But killing off links is a strategy. It may be presented as a cost-saving measure, or as a way of reducing the sharing of untrusted links. But it is a strategy, designed to keep people from the open web, the place where they can control how, and whether, someone makes money off of an audience. The web is where we can make sites that don’t abuse data in the ways that Facebook properties do.</p>
</blockquote>
<p>If you’re committed to one ecosystem or another, you’re really committed. And LinkedIn wants committed users. But on the other hand, people don’t run their entire lives on LinkedIn. It’s not like Nike or Blackstone or your local cupcake shop or your local neighborhood content hustlers can just live on LinkedIn. But LinkedIn acts as if that’s what you need to do to get ahead, and it feels like something we should start talking about in earnest.</p>
<p>What is the value of the link? Why are there so many barricades between the audience you’ve built and the link you want to share? (Hint: They think it’s not really your audience.) And when should regulators step in to ensure that our social networks aren’t impeding commerce by impeding links?</p>
<p>I know Lina Khan is pretty busy these days, but it feels like a question she might be well-suited to help answer.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Turing's topological proof that every written alphabet is finite (2010) (120 pts)]]></title>
            <link>https://divisbyzero.com/2010/05/27/turings-topological-proof-that-every-written-alphabet-is-finite/</link>
            <guid>41048777</guid>
            <pubDate>Tue, 23 Jul 2024 17:43:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://divisbyzero.com/2010/05/27/turings-topological-proof-that-every-written-alphabet-is-finite/">https://divisbyzero.com/2010/05/27/turings-topological-proof-that-every-written-alphabet-is-finite/</a>, See on <a href="https://news.ycombinator.com/item?id=41048777">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-2912">
	

	<div>
			<p>Recently one of my colleagues was reading <a href="http://en.wikipedia.org/wiki/Alan_Turing">Alan Turing</a>‘s groundbreaking 1936 article “<a href="http://books.google.com/books?id=x7mMr4twnloC&amp;lpg=PA58&amp;dq=%22definable%20numbers%22%20turing&amp;pg=PA58#v=onepage&amp;q&amp;f=false">On Computable Numbers with an Application to the Entscheidungsproblem.</a>” This is the article in which Turing introduced the <a href="http://en.wikipedia.org/wiki/Turing_machine">turing machine</a>, solved Hilbert’s <a href="http://en.wikipedia.org/wiki/Entscheidungsproblem">Entscheidungsproblem</a> (`decision problem’), and proved that the <a href="http://en.wikipedia.org/wiki/Halting_problem">halting problem</a> is undecidable. It is viewed by many as the foundation of computer science.</p>
<p>My colleague shared it with me because it contains a neat use of topology. In this paper Turing gives a topological argument that every written alphabet must be finite. For example, our alphabet has 26 letters, 52 including both capital and lower case, 10 numerals, numerous punctuation marks, etc. Finitely many. Even if we came up with a scheme to generate new symbols, we would only be able to create finitely many.</p>
<p>Here is the explanation in Turing’s own words (we’re particularly interested in the accompanying footnote).</p>
<blockquote><p>Computing is normally done by writing certain symbols on paper. We may suppose this paper is divided into squares like a child’s arithmetic book… I shall… suppose that the number of symbols which may be printed is finite. If we were to allow an infinity of symbols, then there would be symbols differing to an arbitrarily small extent.<sup>*</sup> The effect of this restriction of the number of symbols is not very serious. It is always possible to use sequences of symbols in the place of single symbols. Thus an Arabic numeral such as 17 or 999999999999999 is normally treated as a single symbol. Similarly in any European language words are treated as single symbols (Chinese, however, attempts to have an enumerable infinity of symbols). The differences from our point of view between the single and compound symbols is that the compound symbols, if they are too lengthy, cannot be observed at one glance. This is in accordance with experience. We cannot tell at a glance whether 9999999999999999 and 999999999999999 are the same.</p>
<p><sup>*</sup>If we regard a symbol as literally printed on a square we may suppose that the square is <img src="https://s0.wp.com/latex.php?latex=%7B0%5Cle+x+%5Cle+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B0%5Cle+x+%5Cle+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B0%5Cle+x+%5Cle+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{0\le x \le 1}">, <img src="https://s0.wp.com/latex.php?latex=%7B0+%5Cle+y+%5Cle+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B0+%5Cle+y+%5Cle+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B0+%5Cle+y+%5Cle+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{0 \le y \le 1}">. The symbol is defined as a set of points in this square, viz. the set occupied by printer’s ink. If these sets are restricted to be measurable, we can define the “distance” between two symbols as the cost of transforming one symbol into the other if the cost of moving unit area of printer’s ink unit distance is unity, and there is an infinite supply of ink at <img src="https://s0.wp.com/latex.php?latex=%7Bx+%3D+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bx+%3D+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bx+%3D+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{x = 2}">, <img src="https://s0.wp.com/latex.php?latex=%7By+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7By+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7By+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{y = 0}">. With this topology, the symbols form a conditionally compact space.</p></blockquote>
<p>Here’s my more modern topological interpretation of this claim.</p>
<p><strong>Terms from topology</strong></p>
<p>I am assuming that the reader is familiar with the terms metric, metric space, topological space, and compact set.</p>
<p>As a brief refresher, recall that a function <img src="https://s0.wp.com/latex.php?latex=%7Bd%3AX%5Ctimes+X%5Crightarrow+%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd%3AX%5Ctimes+X%5Crightarrow+%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd%3AX%5Ctimes+X%5Crightarrow+%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d:X\times X\rightarrow \mathbb{R}}"> is a <i><a href="http://en.wikipedia.org/wiki/Metric_space">metric</a></i> on <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{X}"> if for any elements <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%5Cin+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%5Cin+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%5Cin+X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{a,b,c\in X}">,</p>
<ol>
<li> <img src="https://s0.wp.com/latex.php?latex=%7Bd%28a%2Cb%29%5Cge+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd%28a%2Cb%29%5Cge+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd%28a%2Cb%29%5Cge+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d(a,b)\ge 0}">, with equality iff <img src="https://s0.wp.com/latex.php?latex=%7Ba%3Db%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Ba%3Db%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Ba%3Db%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{a=b}">,</li>
<li> <img src="https://s0.wp.com/latex.php?latex=%7Bd%28a%2Cb%29%3Dd%28b%2Ca%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd%28a%2Cb%29%3Dd%28b%2Ca%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd%28a%2Cb%29%3Dd%28b%2Ca%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d(a,b)=d(b,a)}">, and</li>
<li> <img src="https://s0.wp.com/latex.php?latex=%7Bd%28a%2Cb%29%2Bd%28b%2Cc%29%5Cge+d%28a%2Cc%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd%28a%2Cb%29%2Bd%28b%2Cc%29%5Cge+d%28a%2Cc%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd%28a%2Cb%29%2Bd%28b%2Cc%29%5Cge+d%28a%2Cc%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d(a,b)+d(b,c)\ge d(a,c)}">.</li>
</ol>
<p>If <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{X}"> has a metric <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d}">, then we say that <img src="https://s0.wp.com/latex.php?latex=%7B%28X%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%28X%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%28X%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{(X,d)}"> is a <em>metric space</em>. Given a metric we can define open neighborhoods, and thus generate a topology. So every metric space is a topological space.</p>
<p>A subset <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A}"> of a topological space <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{X}"> is <i><a href="http://en.wikipedia.org/wiki/Compact_space">compact</a></i> if every open cover of <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A}"> has a finite subcover. In ordinary Euclidean space being compact is equivalent to being closed and bounded. In this discussion we let <img src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{F(X)}"> denote the set of all compact subsets of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{X}">.</p>
<p><strong>The Hausdorff metric</strong></p>
<p>We would like to speak about the distance between two compact sets. That is, we’d like a metric for the set <img src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{F(X)}">.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7B%28X%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%28X%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%28X%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{(X,d)}"> be a metric space and <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A}"> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{B}"> be two compact subsets of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{X}">. Suppose <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{a}"> is the point in <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A}"> farthest from any point in <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{B}"> and that this distance is <img src="https://s0.wp.com/latex.php?latex=%7Bd%28a%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd%28a%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd%28a%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d(a,B)}">. Similarly, suppose <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{b}"> is the point in <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{B}"> farthest from any point in <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A}"> and that this distance is <img src="https://s0.wp.com/latex.php?latex=%7Bd%28b%2CA%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd%28b%2CA%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd%28b%2CA%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d(b,A)}">. Then the Hausdorff distance between <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A}"> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{B}">, <img src="https://s0.wp.com/latex.php?latex=%7BD%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BD%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BD%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{D(A,B)}">, is the larger of <img src="https://s0.wp.com/latex.php?latex=%7Bd%28a%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd%28a%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd%28a%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d(a,B)}"> and <img src="https://s0.wp.com/latex.php?latex=%7Bd%28b%2CA%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd%28b%2CA%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd%28b%2CA%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d(b,A)}">. It is not difficult to show that <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{D}"> satisfies the properties of a metric listed above. This is the <i><a href="http://en.wikipedia.org/wiki/Hausdorff_metric">Hausdorff metric</a></i>.</p>
<p>For example, suppose <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A}">, <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{B}">, <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{C}">, and <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{D}"> are the colored sets shown below. The farthest point in <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A}"> from <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{B}"> (marked <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{a}"> in the diagram) is 4 units away. Similarly, the farthest point in <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{B}"> from <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A}"> (marked <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{b}">) is 3 units away. Thus <img src="https://s0.wp.com/latex.php?latex=%7BD%28A%2CB%29%3D%5Cmax%5C%7B3%2C4%5C%7D%3D4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BD%28A%2CB%29%3D%5Cmax%5C%7B3%2C4%5C%7D%3D4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BD%28A%2CB%29%3D%5Cmax%5C%7B3%2C4%5C%7D%3D4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{D(A,B)=\max\{3,4\}=4}">. In the next picture, the blue set <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{C}"> is a subset of the green set <img src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{E}">. Thus <img src="https://s0.wp.com/latex.php?latex=%7Bd%28c%2CE%29%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd%28c%2CE%29%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd%28c%2CE%29%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d(c,E)=0}"> for every <img src="https://s0.wp.com/latex.php?latex=%7Bc%5Cin+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bc%5Cin+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bc%5Cin+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{c\in C}">. The point <img src="https://s0.wp.com/latex.php?latex=%7Be%5Cin+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Be%5Cin+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Be%5Cin+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{e\in E}"> is farthest from <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{C}">, with <img src="https://s0.wp.com/latex.php?latex=%7Bd%28e%2CC%29%3D0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bd%28e%2CC%29%3D0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bd%28e%2CC%29%3D0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{d(e,C)=0.5}">. Thus <img src="https://s0.wp.com/latex.php?latex=%7BD%28C%2CE%29%3D%5Cmax%5C%7B0%2C0.5%5C%7D%3D0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BD%28C%2CE%29%3D%5Cmax%5C%7B0%2C0.5%5C%7D%3D0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BD%28C%2CE%29%3D%5Cmax%5C%7B0%2C0.5%5C%7D%3D0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{D(C,E)=\max\{0,0.5\}=0.5}">.</p>
<p><img src="https://divisbyzero.com/wp-content/uploads/2010/05/hausdorff.png?w=400" alt="" width="400"></p>
<p>One nice property of the Hausdorff metric is that if <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{X}"> is a compact space, then so is <img src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{F(X)}">.</p>
<p><strong>Proof of Turing’s claim</strong></p>
<p>We would like to prove that any written alphabet is finite. First, we make the following assumptions.</p>
<ol>
<li> Each symbol can be drawn inside a given square. More specifically, we will assume that each symbol is a compact subset of <img src="https://s0.wp.com/latex.php?latex=%7B%5B0%2C1%5D%5Ctimes%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5B0%2C1%5D%5Ctimes%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5B0%2C1%5D%5Ctimes%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{[0,1]\times[0,1]}">.</li>
<li> The human eye cannot tell two symbols apart when they are too similar. That is, there is an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\varepsilon>0}"> such that any symbols <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%5Csubset+%5B0%2C1%5D%5Ctimes%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%2CB%5Csubset+%5B0%2C1%5D%5Ctimes%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%2CB%5Csubset+%5B0%2C1%5D%5Ctimes%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A,B\subset [0,1]\times[0,1]}"> with <img src="https://s0.wp.com/latex.php?latex=%7BD%28A%2CB%29%3C%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BD%28A%2CB%29%3C%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BD%28A%2CB%29%3C%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{D(A,B)<\varepsilon}"> are visually indistinguishable.</li>
</ol>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7BX%3D%5B0%2C1%5D%5Ctimes%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BX%3D%5B0%2C1%5D%5Ctimes%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BX%3D%5B0%2C1%5D%5Ctimes%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{X=[0,1]\times[0,1]}">. Then <img src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{F(X)}"> is the set of all possible symbols. Since <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{X}"> is compact, so is <img src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{F(X)}">.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7BB_%7B%5Cvarepsilon%7D%28A%29%3D%5C%7BB%5Cin+F%28X%29%5Ccolon+D%28A%2CB%29%3C%5Cvarepsilon%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BB_%7B%5Cvarepsilon%7D%28A%29%3D%5C%7BB%5Cin+F%28X%29%5Ccolon+D%28A%2CB%29%3C%5Cvarepsilon%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BB_%7B%5Cvarepsilon%7D%28A%29%3D%5C%7BB%5Cin+F%28X%29%5Ccolon+D%28A%2CB%29%3C%5Cvarepsilon%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{B_{\varepsilon}(A)=\{B\in F(X)\colon D(A,B)<\varepsilon\}}"> denote the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\varepsilon}">-ball around <img src="https://s0.wp.com/latex.php?latex=%7BA%5Cin+F%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%5Cin+F%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%5Cin+F%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A\in F(X)}"> using the Hausdorff metric. Then the set of all possible <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\varepsilon}">-balls, <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7BB_%7B%5Cvarepsilon%7D%28A%29%3AA%5Cin+F%28X%29%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5C%7BB_%7B%5Cvarepsilon%7D%28A%29%3AA%5Cin+F%28X%29%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5C%7BB_%7B%5Cvarepsilon%7D%28A%29%3AA%5Cin+F%28X%29%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\{B_{\varepsilon}(A):A\in F(X)\}}">, is an open cover of <img src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{F(X)}">. Since <img src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{F(X)}"> is compact, there exists a finite subcover, <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7BB_%7B%5Cvarepsilon%7D%28A_%7B1%7D%29%2C%5Cldots%2CB_%7B%5Cvarepsilon%7D%28A_%7Bn%7D%29%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5C%7BB_%7B%5Cvarepsilon%7D%28A_%7B1%7D%29%2C%5Cldots%2CB_%7B%5Cvarepsilon%7D%28A_%7Bn%7D%29%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5C%7BB_%7B%5Cvarepsilon%7D%28A_%7B1%7D%29%2C%5Cldots%2CB_%7B%5Cvarepsilon%7D%28A_%7Bn%7D%29%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{\{B_{\varepsilon}(A_{1}),\ldots,B_{\varepsilon}(A_{n})\}}">.</p>
<p>From this we can conclude that every symbol <img src="https://s0.wp.com/latex.php?latex=%7BA%5Cin+F%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA%5Cin+F%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA%5Cin+F%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A\in F(X)}"> is visually indistinguishable from at least one of the <img src="https://s0.wp.com/latex.php?latex=%7BA_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BA_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BA_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{A_{i}}">. That is, there can be no more than <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}"> visually distinct symbols. In particular, there can be no written alphabet with more than <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}"> letters!</p>
<p>[Note: in (1) we assume that all symbols are compact subsets of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{X}">. We could have dropped the compactness assumption, but if we did then the Hausdorff metric becomes a <a href="http://en.wikipedia.org/wiki/Pseudometric_space">pseudometric</a> and things get a little messier.]</p>
<p><strong>Extensions</strong></p>
<p>There is nothing special about assuming our figures are letters in an alphabet. Using the same reasoning, we can conclude that it is possible to draw only finitely many pictures with a black pen on a given canvas.</p>
<p>What if we are allowed to use color? Suppose that the visible spectrum of colors is a compact set <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{Y}">. Two colors that are very similar are visually indistinguishable. Thus we can use the identical argument, but now a symbol is a compact subset of <img src="https://s0.wp.com/latex.php?latex=%7B%5B0%2C1%5D%5Ctimes%5B0%2C1%5D%5Ctimes+Y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%5B0%2C1%5D%5Ctimes%5B0%2C1%5D%5Ctimes+Y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%5B0%2C1%5D%5Ctimes%5B0%2C1%5D%5Ctimes+Y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{[0,1]\times[0,1]\times Y}">, to conclude that there are only finitely many color pictures on a given canvas.</p>
					</div><!-- .entry-inner -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chinese-born chemist cleared of last conviction under US’s espionage probe (149 pts)]]></title>
            <link>https://www.chemistryworld.com/news/chinese-born-chemist-cleared-of-last-conviction-under-uss-espionage-probe/4019849.article</link>
            <guid>41048747</guid>
            <pubDate>Tue, 23 Jul 2024 17:41:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chemistryworld.com/news/chinese-born-chemist-cleared-of-last-conviction-under-uss-espionage-probe/4019849.article">https://www.chemistryworld.com/news/chinese-born-chemist-cleared-of-last-conviction-under-uss-espionage-probe/4019849.article</a>, See on <a href="https://news.ycombinator.com/item?id=41048747">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Following a five-year legal battle, Chinese-born former University of Kansas chemistry professor Feng ‘Franklin’ Tao, who was <a href="https://www.chemistryworld.com/news/us-chemistry-professor-convicted-under-now-defunct-china-initiative/4015510.article">arrested and convicted under the former Trump administration’s now-defunct ‘China Initiative’</a>, has been vindicated. An appeals court in Denver, Colorado has <a href="https://x.com/Profleoyu/status/1811593615514259592">acquitted Tao of his one remaining conviction</a> that he made a false statement about his relationship with a Chinese university.</p>
<p>In April 2022, Tao – a permanent US resident who before his arrest in 2019 had served as a tenured associate professor at the University of Kansas since 2014 – was not only convicted of making a ‘materially false statement’, but also of three counts of wire fraud. He faced up to 20 years in prison and substantial fines. However, he <a href="https://www.chemistryworld.com/news/us-chemist-feng-tao-avoids-prison-sentence-for-hiding-ties-to-china/4016855.article">was subsequently acquitted of the wire fraud charges and so only the now-overturned false statements conviction remained</a>. Ultimately, he was sentenced to time served with a $100 (£81) fine.</p>
<p>At issue in the new ruling, issued 11 July, is whether Tao’s lack of disclosure about his affiliation with Fuzhou University in China affected federal agency funding decisions. The Denver appeals court agreed 2-1 that it was irrelevant because Tao had no grant proposals pending before those two agencies in question – the US Department of Energy and National Science Foundation – at the time he made his affiliation statement.</p>
<p>Tao’s lawyer, Peter Zeidenberg welcomed the court’s ruling. ‘Even though there was not a scintilla of evidence that Dr Tao was engaged in espionage or theft of trade secrets, the government nevertheless relentlessly investigated him and ultimately charged him with 10 felonies – all based on an alleged omission on a single internal form he submitted to the University of Kansas research office and which was never shared with any federal agency,’ he stated. Those initial 10 charges were first reduced to three, then one, and now zero.</p>
<p>Zeidenberg emphasised that Tao’s reputation has been ‘unfairly dragged to the mud’, and he was ‘wrongly fired’ by the University of Kansas. ‘Dr Tao, a world-renowned expert in catalysis, has been unable to do his research, depriving all of us who benefit from scientific advances,’ Zeidenberg continued, noting that his legal fight has virtually bankrupted his family. Even with assistance from friends and family and a GoFundMe campaign, Tao still owes over $1 million in legal fees, he said.</p>
<p>Tao was one of an estimated two dozen academics who were charged under the US government’s China Initiative. The programme, launched in<strong> </strong>2018 to counter trade secret theft and economic espionage, was widely criticised as racially biased and harmful to academic freedom. It was eventually <a href="https://www.chemistryworld.com/news/us-ends-anti-espionage-china-initiative/4015301.article">terminated under President Biden in 2022</a> following <a href="https://www.chemistryworld.com/news/us-programme-targeting-researchers-with-china-links-crumbling-under-intense-scrutiny/4014572.article">the dismissal of many of the government’s criminal cases that were brought against university researchers under the initiative</a>.</p>
<p>The Asian–American Scholar Forum <a href="https://www.aasforum.org/2024/07/17/aasf-celebrates-dr-franklin-taos-appeal-victory/">called Tao’s latest court win ‘a significant victory’</a> and celebrated it as ‘a crucial step toward rectifying the unjust treatment of Chinese American and immigrant scientists under the now-defunct China Initiative’.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Warsaw came close to never being rebuilt (2015) (191 pts)]]></title>
            <link>https://culture.pl/en/article/how-warsaw-came-close-to-never-being-rebuilt</link>
            <guid>41048677</guid>
            <pubDate>Tue, 23 Jul 2024 17:33:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://culture.pl/en/article/how-warsaw-came-close-to-never-being-rebuilt">https://culture.pl/en/article/how-warsaw-came-close-to-never-being-rebuilt</a>, See on <a href="https://news.ycombinator.com/item?id=41048677">Hacker News</a></p>
Couldn't get https://culture.pl/en/article/how-warsaw-came-close-to-never-being-rebuilt: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Zerox – Document OCR with GPT-mini (200 pts)]]></title>
            <link>https://github.com/getomni-ai/zerox</link>
            <guid>41048194</guid>
            <pubDate>Tue, 23 Jul 2024 16:49:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/getomni-ai/zerox">https://github.com/getomni-ai/zerox</a>, See on <a href="https://news.ycombinator.com/item?id=41048194">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/getomni-ai/zerox/blob/main/examples/heroImage.png"><img src="https://github.com/getomni-ai/zerox/raw/main/examples/heroImage.png" alt="Hero Image"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Zerox OCR</h2><a id="user-content-zerox-ocr" aria-label="Permalink: Zerox OCR" href="#zerox-ocr"></a></p>
<p dir="auto">A dead simple way of OCR-ing a document for AI ingestion. Documents are meant to be a visual representation after all. With weird layouts, tables, charts, etc. The vision models just make sense!</p>
<p dir="auto">The general logic:</p>
<ul dir="auto">
<li>Pass in a PDF (URL or file buffer)</li>
<li>Turn the PDF into a series of images</li>
<li>Pass each image to GPT and ask nicely for Markdown</li>
<li>Aggregate the responses and return Markdown</li>
</ul>
<p dir="auto">Sounds pretty basic! But with the <code>gpt-4o-mini</code> this method is price competitive with existing products, with meaningfully better results.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Pricing Comparison</h4><a id="user-content-pricing-comparison" aria-label="Permalink: Pricing Comparison" href="#pricing-comparison"></a></p>
<p dir="auto">This is how the pricing stacks up to other document processers. Running 1,000 pages with Zerox uses about 25M input tokens and 0.4M output tokens.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Service</th>
<th>Cost</th>
<th>Accuracy</th>
<th>Table Quality</th>
</tr>
</thead>
<tbody>
<tr>
<td>AWS Textract <a href="https://aws.amazon.com/textract/pricing/#:~:text=Amazon%20Textract%20API%20pricing" rel="nofollow">[1]</a></td>
<td>$1.50 / 1,000 pages</td>
<td>Low</td>
<td>Low</td>
</tr>
<tr>
<td>Google Document AI <a href="https://cloud.google.com/document-ai/pricing" rel="nofollow">[2]</a></td>
<td>$1.50 / 1,000 pages</td>
<td>Low</td>
<td>Low</td>
</tr>
<tr>
<td>Azure Document AI <a href="https://azure.microsoft.com/en-us/pricing/details/ai-document-intelligence/" rel="nofollow">[3]</a></td>
<td>$1.50 / 1,000 pages</td>
<td>Mid</td>
<td>Low</td>
</tr>
<tr>
<td>Unstructured (PDF) <a href="https://unstructured.io/api-key-hosted#:~:text=Cost%20and%20Usage%20%0AGuidelines" rel="nofollow">[4]</a></td>
<td>$10.00 / 1,000 pages</td>
<td>Mid</td>
<td>Mid</td>
</tr>
<tr>
<td>------------------------</td>
<td>--------------------</td>
<td>--------</td>
<td>-------------</td>
</tr>
<tr>
<td>Zerox (gpt-mini)</td>
<td>$ 4.00 / 1,000 pages</td>
<td>High</td>
<td>High</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>

<p dir="auto">Zerox uses <code>graphicsmagick</code> and <code>ghostscript</code> for the pdf =&gt; image processing step. These should be pulled automatically, but you may need to manually install.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><strong>With file URL</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { zerox } from &quot;zerox&quot;;

const result = await zerox({
  filePath: &quot;https://omni-demo-data.s3.amazonaws.com/test/cs101.pdf&quot;,
  openaiAPIKey: process.env.OPENAI_API_KEY,
});"><pre><span>import</span> <span>{</span> <span>zerox</span> <span>}</span> <span>from</span> <span>"zerox"</span><span>;</span>

<span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>zerox</span><span>(</span><span>{</span>
  <span>filePath</span>: <span>"https://omni-demo-data.s3.amazonaws.com/test/cs101.pdf"</span><span>,</span>
  <span>openaiAPIKey</span>: <span>process</span><span>.</span><span>env</span><span>.</span><span>OPENAI_API_KEY</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><strong>From local path</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="import path from &quot;path&quot;;
import { zerox } from &quot;zerox&quot;;

const result = await zerox({
  filePath: path.resolve(__dirname, &quot;./cs101.pdf&quot;),
  openaiAPIKey: process.env.OPENAI_API_KEY,
});"><pre><span>import</span> <span>path</span> <span>from</span> <span>"path"</span><span>;</span>
<span>import</span> <span>{</span> <span>zerox</span> <span>}</span> <span>from</span> <span>"zerox"</span><span>;</span>

<span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>zerox</span><span>(</span><span>{</span>
  <span>filePath</span>: <span>path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span> <span>"./cs101.pdf"</span><span>)</span><span>,</span>
  <span>openaiAPIKey</span>: <span>process</span><span>.</span><span>env</span><span>.</span><span>OPENAI_API_KEY</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Options</h3><a id="user-content-options" aria-label="Permalink: Options" href="#options"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="const result = await zerox({
  // Required
  filePath: &quot;path/to/file&quot;,
  openaiAPIKey: process.env.OPENAI_API_KEY,

  // Optional
  concurrency: 10, // Number of pages to run at a time.
  maintainFormat: false, // Slower but helps maintain consistent formatting.
  cleanup: true, // Clear images from tmp after run.
  outputDir: undefined, // Save combined result.md to a file
  tempDir: &quot;/os/tmp&quot;, // Directory to use for temporary files (default: system temp directory)
});"><pre><span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>zerox</span><span>(</span><span>{</span>
  <span>// Required</span>
  <span>filePath</span>: <span>"path/to/file"</span><span>,</span>
  <span>openaiAPIKey</span>: <span>process</span><span>.</span><span>env</span><span>.</span><span>OPENAI_API_KEY</span><span>,</span>

  <span>// Optional</span>
  <span>concurrency</span>: <span>10</span><span>,</span> <span>// Number of pages to run at a time.</span>
  <span>maintainFormat</span>: <span>false</span><span>,</span> <span>// Slower but helps maintain consistent formatting.</span>
  <span>cleanup</span>: <span>true</span><span>,</span> <span>// Clear images from tmp after run.</span>
  <span>outputDir</span>: <span>undefined</span><span>,</span> <span>// Save combined result.md to a file</span>
  <span>tempDir</span>: <span>"/os/tmp"</span><span>,</span> <span>// Directory to use for temporary files (default: system temp directory)</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">The <code>maintainFormat</code> option trys to return the markdown in a consistent format by passing the output of a prior page in as additional context for the next page. This requires the requests to run synchronously, so it's a lot slower. But valueable if your documents have a lot of tabular data, or frequently have tables that cross pages.</p>
<div data-snippet-clipboard-copy-content="Request #1 => page_1_image
Request #2 => page_1_markdown + page_2_image
Request #3 => page_2_markdown + page_3_image"><pre><code>Request #1 =&gt; page_1_image
Request #2 =&gt; page_1_markdown + page_2_image
Request #3 =&gt; page_2_markdown + page_3_image
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example Output</h3><a id="user-content-example-output" aria-label="Permalink: Example Output" href="#example-output"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  completionTime: 10038,
  fileName: 'invoice_36258',
  inputTokens: 25543,
  outputTokens: 210,
  pages: [
    {
      content: '# INVOICE # 36258\n' +
        '**Date:** Mar 06 2012  \n' +
        '**Ship Mode:** First Class  \n' +
        '**Balance Due:** $50.10  \n' +
        '## Bill To:\n' +
        'Aaron Bergman  \n' +
        '98103, Seattle,  \n' +
        'Washington, United States  \n' +
        '## Ship To:\n' +
        'Aaron Bergman  \n' +
        '98103, Seattle,  \n' +
        'Washington, United States  \n' +
        '\n' +
        '| Item                                       | Quantity | Rate   | Amount  |\n' +
        '|--------------------------------------------|----------|--------|---------|\n' +
        &quot;| Global Push Button Manager's Chair, Indigo | 1        | $48.71 | $48.71  |\n&quot; +
        '| Chairs, Furniture, FUR-CH-4421             |          |        |         |\n' +
        '\n' +
        '**Subtotal:** $48.71  \n' +
        '**Discount (20%):** $9.74  \n' +
        '**Shipping:** $11.13  \n' +
        '**Total:** $50.10  \n' +
        '---\n' +
        '**Notes:**  \n' +
        'Thanks for your business!  \n' +
        '**Terms:**  \n' +
        'Order ID : CA-2012-AB10015140-40974  ',
      page: 1,
      contentLength: 747
    }
  ]
}"><pre><span>{</span>
  <span>completionTime</span>: <span>10038</span><span>,</span>
  <span>fileName</span>: <span>'invoice_36258'</span><span>,</span>
  <span>inputTokens</span>: <span>25543</span><span>,</span>
  <span>outputTokens</span>: <span>210</span><span>,</span>
  <span>pages</span>: <span>[</span>
    <span>{</span>
      <span>content</span>: <span>'# INVOICE # 36258\n'</span> <span>+</span>
        <span>'**Date:** Mar 06 2012  \n'</span> <span>+</span>
        <span>'**Ship Mode:** First Class  \n'</span> <span>+</span>
        <span>'**Balance Due:** $50.10  \n'</span> <span>+</span>
        <span>'## Bill To:\n'</span> <span>+</span>
        <span>'Aaron Bergman  \n'</span> <span>+</span>
        <span>'98103, Seattle,  \n'</span> <span>+</span>
        <span>'Washington, United States  \n'</span> <span>+</span>
        <span>'## Ship To:\n'</span> <span>+</span>
        <span>'Aaron Bergman  \n'</span> <span>+</span>
        <span>'98103, Seattle,  \n'</span> <span>+</span>
        <span>'Washington, United States  \n'</span> <span>+</span>
        <span>'\n'</span> <span>+</span>
        <span>'| Item                                       | Quantity | Rate   | Amount  |\n'</span> <span>+</span>
        <span>'|--------------------------------------------|----------|--------|---------|\n'</span> <span>+</span>
        <span>"| Global Push Button Manager's Chair, Indigo | 1        | $48.71 | $48.71  |\n"</span> <span>+</span>
        <span>'| Chairs, Furniture, FUR-CH-4421             |          |        |         |\n'</span> <span>+</span>
        <span>'\n'</span> <span>+</span>
        <span>'**Subtotal:** $48.71  \n'</span> <span>+</span>
        <span>'**Discount (20%):** $9.74  \n'</span> <span>+</span>
        <span>'**Shipping:** $11.13  \n'</span> <span>+</span>
        <span>'**Total:** $50.10  \n'</span> <span>+</span>
        <span>'---\n'</span> <span>+</span>
        <span>'**Notes:**  \n'</span> <span>+</span>
        <span>'Thanks for your business!  \n'</span> <span>+</span>
        <span>'**Terms:**  \n'</span> <span>+</span>
        <span>'Order ID : CA-2012-AB10015140-40974  '</span><span>,</span>
      <span>page</span>: <span>1</span><span>,</span>
      <span>contentLength</span>: <span>747</span>
    <span>}</span>
  <span>]</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">License</h3><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License.</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>