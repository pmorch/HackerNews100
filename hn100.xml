<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 27 May 2025 19:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Square Theory (246 pts)]]></title>
            <link>https://aaronson.org/blog/square-theory</link>
            <guid>44107942</guid>
            <pubDate>Tue, 27 May 2025 15:33:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aaronson.org/blog/square-theory">https://aaronson.org/blog/square-theory</a>, See on <a href="https://news.ycombinator.com/item?id=44107942">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>The story starts in <a href="https://discord.com/invite/GPyU97XBGX">Crosscord</a>, the crossword Discord server. Over 5,000 users strong, the server has emerged as a central hub for the online crossword community, a buzzing, sometimes overwhelming, sometimes delightful town square where total noobs, veteran constructors, and champion solvers alike come together to talk about words that cross each other.</p>

<h2 id="square-roots">Square roots</h2>

<p>We direct our attention toward the #etuiposting channel, Crosscord’s designated space for shitposting (so named because ETUI, a sewing case, is a prototypically shitty piece of crosswordese). There, one afternoon in January 2022, crossword constructor and <a href="https://crosswordnexus.com/">Crossword Nexus</a> warden Alex Boisvert posted what seemed at the time to be an innocuous, mildly interesting observation:</p>

<p><img src="https://aaronson.org/assets/images/square-boisvert.png" alt="Alex Boisvert: JET BLACK and JETBLUE have very different meanings, even though they look superficially similar.  Same thing with CATNAP and DOGNAP.  Any other examples of this?"></p>

<p>Suffice to say, the Crosscord hivemind had other examples of this. <a href="http://blog.bewilderinglypuzzles.com/">Will Nediger</a> replied a few minutes later with the clever MULTITOOL and MULTIPLIERS (words with completely unrelated meanings, despite the fact that PLIERS are a TOOL). Several messages later, Alex chimed back in with the elegant PUB QUIZ and BAR EXAM, a pairing that had been used in some form in crosswords by constructors <a href="http://arctanxwords.blogspot.com/2018/04/puzzle-53-i-thought-this-was-speed.html">Christopher Adams</a> (2018) and <a href="https://www.nytimes.com/crosswords/game/daily/2021/01/29">Robyn Weintraub</a> (2021).</p>

<p>Something about this concept—two sets of synonyms (PUB and BAR, QUIZ and EXAM), which when paired together, form phrases that themselves are not synonyms (PUB QUIZ and BAR EXAM)—captured the minds of Crosscord. Suddenly, the floodgates were open.</p>

<p><img src="https://aaronson.org/assets/images/square-discord-posts.png" alt="Will Nediger: UBEREATS / SUPERFOOD; Assorted-Interests: THROW SHADE / PITCH BLACK; Tyler Hinman, Aged Prodigy: With this topic resurrected, it seems nobody posted what I think is the canonical one: BOOTY CALL and BUTT DIAL; jenna lafleur: ROMAN MARS / CLASSICAL RUINS; gppasco: GRAND CANYON / K-HOLE; robinyu: DAD BOD and FATHER FIGURE; kareila: PERMANENT PRESS / FOREVER STAMP; heywhatsupitsbob: FRIENDLY FAVOR / PLATONIC SOLID"></p>

<p>Intermittently over the next <em>year</em>, #etuiposting would be flooded with these pairs of pairs. They became too much even for the shitposting channel, and were ultimately confined to a thread called #double-doubles (a name <a href="https://heywhatsupitsbob.com/">Bob Weisz</a> and I both proposed simultaneously). Today, more than three years after Alex’s original prompt, the thread still remains active, a wordplay oasis of over 3,000 posts.</p>

<p>There’s something going on here. Something more than a shitpost or an ephemeral trend. Double doubles have the proverbial juice, and the juice lies in their structure. Each pair of pairs can be modeled as a square, where the corners are words and the sides are relations between those words:</p>

<p><img src="https://aaronson.org/assets/images/square-booty-call.jpeg" alt="Square showing BOOTY - phrase - CALL connected via synonyms to BUTT - phrase - DIAL"></p>

<p>It’s this square structure that makes each double double feel tight, feel satisfying, feel like a real “find”. This is the essence of what I’ve started calling <strong>square theory</strong>, and it applies to much more than just posts in a Discord server.</p>

<p>Just like it’s satisfying when an essay or a news story comes full circle, or mindblowing when you find an unexpected cycle in your network of friends, it’s inherently compelling when things wrap around and complete the square. Let’s break it down.</p>

<h2 id="the-theory-of-everything">The theory of everything</h2>

<p>Crosscord wasn’t the first to catch onto this kind of formation: Ricki Heicklen has maintained a <a href="https://rickiheicklen.com/unparalleled-misalignments.html">huge list</a> of double doubles (which she calls “Unparalleled Misalignments”—itself a sort of double double) since 2018, and the success of her recent <a href="https://x.com/tradegal_/status/1920189768261828748">Twitter thread</a> about them is another testament to their widespread appeal. Pairs of the same form pop up on a regular basis in the form of crossword clues and Twitter jokes:</p>

<p><img src="https://aaronson.org/assets/images/square-top-gun.png" alt="Crossword clue [Top gun?] for TSHIRTCANNON, with a square showing TOP - phrase - GUN connected via synonyms to TSHIRT - phrase CANNON">
    <img src="https://aaronson.org/assets/images/square-dad-bod.png" alt="Tweet by Steven W Skinner that says 'Why is it called a dad-bod and not a father-figure', with a square showing DAD - phrase - BOD connected via synonyms to FATHER - phrase - FIGURE">
</p>

<p>However, there’s nothing about the square structure that dictates the edges must represent phrases and synonyms. Each edge of the square can be any relation that connects its vertices (but generally, the stronger the relations, the stronger the square). The vertices don’t even necessarily have to be words—they can be any entity or concept.</p>

<p>It evokes the mathematical field of <a href="https://en.wikipedia.org/wiki/Category_theory">category theory</a>, which very abstractly studies mathematical objects and the relations between them. It’s the topology of the square that makes it satisfying, regardless of what the edges and vertices represent.</p>

<p>Members of the #double-doubles thread have already noticed this, consciously or not, with many of the posts interpreting the original prompt more liberally and swapping out the “synonym” relation for something else:</p>

<p><img src="https://aaronson.org/assets/images/square-left-on-read.png" alt="Crosscord post from Joah: LEFT ON READ vs. RIGHT ON RED. Same number of letters too. Maybe I'll make a mini out of it; Square showing LEFT on READ connected via antonym and homophone to RIGHT on RED">
    <img src="https://aaronson.org/assets/images/square-arizona-wildcat.png" alt="Crosscord post from Quiara, Newsletter Economist: ARIZONA WILDCAT / ARIGATO; Square showing ARIZONA phrase WILDCAT connected via abbr. and translation to ARI word GATO">
</p>

<p>Sometimes it feels like the #double-doubles thread has devolved into just #question-mark-clues (crossword clues that are trying to trick you, requiring you to reinterpret them beyond their words’ most likely meaning, or “surface sense”). But that’s no coincidence—abstractly, every question mark clue takes the form of a square.</p>

<p>When brainstorming for question mark clues, crossword constructors experience this on a regular basis. You start with the answer at hand, playing word association with it in search of a combination of words that usually means one thing (the surface sense) but can be interpreted differently (the intended interpretation) to point to the answer, thus completing the square:</p>

<p><img src="https://aaronson.org/assets/images/square-question-mark-clue.png" alt="Square showing word(s) connected to word(s) by surface sense, which are connected by homonyms to word(s) connected to word(s) by intended interpretation, which leads to the answer"></p>

<p>Take <a href="https://www.nytimes.com/2001/04/08/magazine/endpaper-how-to-solve-the-new-york-times-crossword-puzzle.html">Will Shortz’s all-time favorite clue</a> for instance, from a 1995 Martin Ashwood-Smith puzzle: [It turns into a different story] (which deviously didn’t even include the question mark). On the surface, “turns into a different story” typically means something like “develops into another situation.” But the intended interpretation takes the clue’s words to mean “rotates into another floor,” leading to the correct answer of SPIRAL STAIRCASE:</p>

<p><img src="https://aaronson.org/assets/images/square-spiral-staircase.png" alt="Square showing turns (develops) connected to story (situation) by &quot;develops into another situation&quot;, which are connected by homonyms to turns (rotates) connected to story (floor) by &quot;rotates into another floor&quot;, which leads to the answer SPIRAL STAIRCASE"></p>

<p>You might be familiar with this same sort of brainstorming if you’ve ever tried to come up with a clever title for a research paper, or an apt name for a company. There are plenty of names that might make you go “I guess that could work,” but it’s the square-completing ones that make you go “that’s the one,” or “that’s so good!”</p>

<p>One of my favorite examples of this is <a href="https://www.underconsideration.com/brandnew/">Brand New</a>, the blog that catalogues the latest in corporate rebrands. Leave it to a branding blog to have a name this immaculate:</p>

<p><img src="https://aaronson.org/assets/images/square-brand-new.png" alt="Square showing BRAND phrase NEW connected via homonym and synonym to what the blog chronicles, updated brands"></p>

<p>Even a seemingly straightforward brand name like <a href="https://www.grubhub.com/">Grubhub</a> can exemplify the power of square theory. Presumably, Grubhub’s branding team started with a concept (a centralized app for food deliveries) and came up with a name that completes the square. But remove any edge of the square (besides the edge that dictates the app’s purpose), and you’re left with a name that only <em>kinda</em> works:</p>

<p><img src="https://aaronson.org/assets/images/square-grubhub.png" alt="Complete square showing GRUB rhyme HUB connected via synonyms to what the app provides, a central place for food">
    <img src="https://aaronson.org/assets/images/square-grubnexus.png" alt="Incomplete square showing GRUB and NEXUS connected via synonyms to what the app provides, a central place for food">
</p>
<p><img src="https://aaronson.org/assets/images/square-grubcub.png" alt="Incomplete square showing GRUB rhyme CUB connected via only one synonym to what the app provides, a central place for food">
    <img src="https://aaronson.org/assets/images/square-tubhub.png" alt="Incomplete square showing TUB rhyme HUB connected via only one synonym to what the app provides, a central place for food">
</p>

<p>Aside from crossword clues and brand names, squares appear in the wild all the time in the form of jokes. There’s a vast universe of pun-based jokes (often in the form of dad jokes, or Twitter jokes, or <a href="https://www.timeout.com/newyork/clubs/punderdome">Punderdome</a> puns) that can be modeled as a square, where one side of the square is the contrived setup (“what do you call an X with a Y?”) that connects in at least two ways to the punchline (“an algebra problem!”) on the opposite side.</p>

<p>The strength of the joke rests in the strength of the setup, the punchline, and the connections between them—and if every side of the square is strong, you might have created something funny:</p>

<p><img src="https://aaronson.org/assets/images/square-joke-abstract.png" alt="Square showing a setup (contrived) of at least two words, which are connected by synonyms or homonyms, usually, to at least two other words, the punchline (a real word or phrase, or a play on one)">
    <img src="https://aaronson.org/assets/images/square-impasta.png" alt="Square showing FAKE and NOODLE connected by the setup 'What do you call a fake noodle', which connects via synonyms to IMPOSTOR and PASTA, forming the portmanteau punchline 'An impasta!'">
</p>

<h2 id="getting-into-shape">Getting into shape</h2>

<p>You might be thinking: what’s so special about a square? What about triangle theory, or pentagon theory? (Or rectangle theory? Or rhombus theory? Okay, side lengths and angles <a href="https://en.wikipedia.org/wiki/Topology">don’t matter here</a>.)</p>

<p>Well, it’s true that there’s something compelling about any loop-closing property, regardless of side count—a story that comes full circle is still satisfying no matter how many points it hits in between, and it’s still neat to discover a triangle of people who coincidentally know each other.</p>

<p>But here’s what I think makes squares special: a square is the simplest polygon that has non-adjacent sides. In a triangle, each side is adjacent to the other two sides. But in a square, opposite sides have no points in common, which makes any connection between them feel surprising, like a coincidence. In pentagons and beyond, this still holds, but the extra sides add complexity that make them feel slightly less elegant. Nevertheless, other shapes can be interesting too, but I see them as the exception, not the rule.</p>

<p>Remember Alex Boisvert’s original JET BLACK / JETBLUE example? Seems like it could be modeled as a triangle, right? Well, it turns out the “jet” in JET BLACK refers to the gemstone <a href="https://en.wikipedia.org/wiki/Jet_(gemstone)">jet</a>, which is <a href="https://www.etymonline.com/word/jet">etymologically unrelated</a> to JETBLUE’s airplane jet, so it’s actually more properly modeled as a square:</p>

<p><img src="https://aaronson.org/assets/images/square-jet-triangle.png" alt="Triangle showing JET phrase BLACK colors BLUE airline JET">
    <img src="https://aaronson.org/assets/images/square-jet-square.png" alt="Square showing JET homonym JET phrase BLACK colors BLUE airline JET">
</p>

<h2 id="times-square"><em>Times</em> square</h2>

<p>Now that I’ve established that square theory applies to more than just crosswords, it’s time to talk about crosswords again.</p>

<p>It’s typical for American-style crosswords (à la <em>New York Times</em>) to have a theme, which will generally consist of the 4–6 longest Across entries in the grid, often including a “revealer” that ties the theme together. Nowadays, it’s common gospel among crossword constructors that themes should have some sort of wordplay-based connection—that is, a theme like “famous basketball players” or “brands of cereal” is unlikely to elicit a real “aha” moment from solvers, and thus unlikely to be accepted at major crossword outlets.</p>

<p>So what makes for a <em>good</em> crossword theme? Consistency is definitely key, and a notion of “tightness” is important too (the set of possible theme entries shouldn’t be too much bigger than the theme set that appears in the puzzle). But time and time again, I’ve noticed that what makes a theme really pop is—you guessed it—when it completes the square.</p>

<p>Take, for example, the <a href="https://www.xwordinfo.com/Crossword?date=2/17/2025">Monday, February 17, 2025 <em>New York Times</em> crossword</a> by Kate Hawkins and Erica Hsiung Wojcik, which features a great execution of a typical Monday theme type. In this puzzle, the seemingly unrelated theme entries SCRAPBOOK, POPEYES, UNDER PRESSURE, and GIDDY UP are united by the fact that they each end in an affirmative (OK, YES, SURE, YUP).</p>

<p>In a vacuum, this fact wouldn’t be that interesting, but Kate and Erica give the theme a <em>raison d’etre</em> with the revealer YEAH RIGHT, clued as [“Uh-huh, I bet” … or a literal description of what 17-, 24-, 36- and 50-Across all have]—that is, each themer has a synonym for “YEAH” on its “RIGHT” side. The key here is that YEAH RIGHT itself is an idiomatic phrase (meaning “Uh-huh, I bet”), and not just an arbitrary description of the theme mechanic, so it completes the square:</p>

<p><img src="https://aaronson.org/assets/images/square-yeah.png" alt="Square showing what the entries have, an affirmative ending, connected via synonyms to the phrase YEAH RIGHT"></p>

<p>But it doesn’t stop there. Consider the <a href="https://www.xwordinfo.com/Crossword?date=2/18/2019">Monday, February 18, 2019 <em>New York Times</em> crossword</a> by Leslie Young and Andrea Carla Michaels. The theme entries here are NIGHT NIGHT, WHITE WEDDING, and MUSHROOM BALL (you know, like a vegetarian meatball), and the revealer, clued as [Graduation garb … or what the compound answers to 17-, 28- and 44-Across represent?], is CAP AND GOWN. That is, the first part of each themer can precede CAP (e.g. MUSHROOM CAP), and the second part can precede GOWN (e.g. BALL GOWN). This maps pretty squarely onto not one, but three squares, one for each theme entry:</p>

<p><img src="https://aaronson.org/assets/images/square-night-night.png" alt="Three squares, for NIGHT NIGHT, WHITE WEDDING, and MUSHROOM BALL, each showing the phrase connected by two phrases to CAP and GOWN"></p>

<p>And just for fun, we can conjoin the three squares by their CAP AND GOWN edges to form a unified graph that represents the entire theme’s topology:</p>

<p><img src="https://aaronson.org/assets/images/square-cap-and-gown.png" alt="Unified CAP AND GOWN square graph"></p>

<p>The final crossword we’ll look at, and maybe my favorite crossword of all time, is Alina Abidi’s <a href="https://www.xwordinfo.com/Crossword?date=8/18/2021">Wednesday, August 18, 2021 <em>New York Times</em> crossword</a>, with a theme that feels almost impossibly tight.</p>

<p>The puzzle has essentially two theme entries, PIN THE TAIL ON THE DONKEY and WHITE ELEPHANT, with the apt revealer PARTY ANIMAL [Frequent reveler, or a hint to 16-/26- and 36-Across]. That alone is clever, since both themers are party games with animals in their names. But then Alina hits you with the <em>second</em> revealer of THOMAS NAST [Cartoonist suggested by this puzzle’s theme], pointing to the fact that not only are the DONKEY and ELEPHANT animals in party games, but they are also the animals that symbolize the Democratic and Republican <em>parties</em>, as popularized by <a href="https://en.wikipedia.org/wiki/Thomas_Nast">Thomas Nast</a>’s political cartoons.</p>

<p>This is the kind of theme that really sticks with you. Or at least it stuck with me, and I tried for years to understand why it felt so amazing. And then I realized square theory offered an explanation. Squares, as we know, feel tight, satisfying, and clever. But Alina’s theme takes that one step further, creating for each theme entry a square with an <em>extra diagonal</em> through it, reflecting the connection between each animal and a political PARTY:</p>

<p><img src="https://aaronson.org/assets/images/square-democrat.png" alt="Square showing PIN THE TAIL ON THE DONKEY containing DONKEY connected to PARTY ANIMAL by setting and example, with an additional Democrats diagonal connecting PARTY and DONKEY">
    <img src="https://aaronson.org/assets/images/square-republican.png" alt="Square showing WHITE ELEPHANT containing ELEPHANT connected to PARTY ANIMAL by setting and example, with an additional Republican diagonal connecting PARTY and ELEPHANT">
</p>

<p>And again, we can combine these two super-squares into one unified theme graph:</p>

<p><img src="https://aaronson.org/assets/images/square-party-animals.png" alt="Unified PARTY ANIMALS square graph"></p>

<p>Granted, there’s more to a crossword than the structure of its theme, and it can be reductive to distill it into a graph like this. Still, for many puzzles, square theory can serve as an illuminating proxy for the intricacy and tightness of a theme. But that’s not all it can do.</p>

<h2 id="letter-box">Letter box</h2>

<p>Let’s talk about Scrabble, one of the <a href="https://www.nytimes.com/2022/01/25/books/review/seven-games-oliver-roeder.html">seven most important games</a> out there. If you’ve ever played Scrabble (or similar games like Bananagrams), you’d know that every word you play has to intersect another word that’s already on the board.</p>

<p><img src="https://aaronson.org/assets/images/square-scrabble-normal.png" alt="Scrabble play that is boring and the word only intersects one other word"></p>

<p>But occasionally, you’ll think up a play that validly intersects not one, but two words on the board, forming a rectangle of words. Plays like this have a certain panache. They’re satisfying, they make you think, “ooh, nice.” And of course, they can be modeled with square theory:</p>

<p><img src="https://aaronson.org/assets/images/square-scrabble-cool.png" alt="Scrabble play where the word MICE intersects two already-on-the-board words CHASM and SINCE">
    <img src="https://aaronson.org/assets/images/square-scrabble.png" alt="Square showing the Scrabble board words CHASM linking A and M, AVID linking A and I, SINCE linking I and C, and MICE linking M and C">
</p>

<p>You might be thinking that the edge relation here (a word that contains both letters) feels a little flimsy, since not every letter in the word is used. But what if every letter in the word <em>was</em> used? What if we could have a dense network of interlocking squares, where every letter was part of exactly two words? Well, we can, and it’s called an American-style crossword.</p>

<p>In American-style crosswords, every letter is mandatorily “checked” (part of an Across and a Down word), which means <em>every</em> letter is a vertex of a square:</p>

<p><img src="https://aaronson.org/assets/images/square-crossword-grid.png" alt="3x3 crossword grid, and a grid of interconnected squares whose vertices are the letters in the crossword and whose edges are the words that connect those letters"></p>

<p>If you’ve ever tried to construct a crossword, you’ll find that the framing of a crossword grid under square theory <em>feels</em> right. When you’re nearing the end of the grid-filling process, finding valid crossings of words to fill that final corner of a grid, there’s a satisfying “clicking” feeling—a sense of magic—when it all fits together, analogous to the wrapping-around feeling of completing the square.</p>

<p>Taking a step back, that means the clues, the themes, and the very grids of crosswords all share the same abstract fundamental structure, the square:</p>

<p><img src="https://aaronson.org/assets/images/square-crosswords-everything.png" alt="Squares from earlier in the post representing clues, themes, and grids of crosswords"></p>

<p>If you accept the premise that squares are satisfying, square theory offers a unified theory for why crosswords are satisfying too. And if squares are fundamentally compelling, the crossword, in its recursively square structure, starts to look like an equally fundamental art form. Like if you started an English-speaking civilization from scratch, someone, somewhere would inevitably reinvent the crossword. And then someone would start a crossword Discord server, and maybe they’d call it Crosscord.</p>

<p><img src="https://aaronson.org/assets/images/square-crosscord.png" alt="Square showing what the server is, a Discord server for crossword puzzles, connected by keywords to CROSSWORD / DISCORD which are portmanteaued into the server's name, CROSSCORD"></p>

<h2 id="its-hip-to-be-square">It’s hip to be square</h2>

<p>If you’ve read this far, I promise you’ll start to notice squares popping up all over the place in your daily life. I can attest, because I’ve been honing the concept for this post for about two years now, and I often find myself thinking “that’s a square!” whenever I come across a tight joke or title or crossword theme.</p>

<p>If you’re a creative person, square theory is a useful framework to keep in mind. If you’re coming up with a title for a paper or a brand name, try to see if you can think of one that completes the square. If you’re writing puns for a popsicle stick or a Laffy Taffy wrapper, you can use squares to model your setups and punchlines. If you’re constructing a crossword, consider whether your theme or your question mark clues can form squares.</p>

<p>And if you’re writing a story or a news article or a blog post, there’s fundamental value in making it come full circle, or perhaps full square.</p>

        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pyrefly vs. Ty: Comparing Python's Two New Rust-Based Type Checkers (142 pts)]]></title>
            <link>https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/</link>
            <guid>44107655</guid>
            <pubDate>Tue, 27 May 2025 15:01:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/">https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/</a>, See on <a href="https://news.ycombinator.com/item?id=44107655">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
      <blockquote>
<p>Note: I like using em-dashes while writing! Don’t worry, this is not written by AI. <sup><a href="https://medium.com/@brentcsutoras/the-em-dash-dilemma-how-a-punctuation-mark-became-ais-stubborn-signature-684fbcc9f559">(context)</a></sup></p></blockquote>
<p>Earlier this month, two new Rust-based Python type checkers hit the spotlight: <a href="https://github.com/facebook/pyrefly">pyrefly</a> and <a href="https://github.com/astral-sh/ty">ty</a>. Although neither is <em>officially</em> released, they are a welcome change to the Python type checking world, historically dominated by <a href="https://mypy-lang.org/">mypy</a> and <a href="https://pypi.org/project/pylance/">pylance</a>.</p>
<p>While both are open-source and publicly downloadable for quite some time, there have not been any official announcements by Meta nor Astral on their brand new next-generation Python type checkers — <strong>until last week</strong>.</p>
<p>At <a href="https://us.pycon.org/2025/">PyCon 2025</a>, nestled away in a quiet Room 319 at the <a href="https://us.pycon.org/2025/events/typing-summit/">Typing Summit</a>, we had our first official sneak peek into both of these tools — the team behind them, their goals, visions, and ambitions — and their unique approaches to tackling Python’s typing problems.</p>
<figure>
  <img src="https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/ty-introduction.png" alt="ty introduction presentation at PyCon 2025">
  <figcaption>ty team presenting at the typing summit</figcaption>
</figure>
<blockquote>
<p>This blog is a collection of rough notes scribbled during the event, personal conversations with the team, and not-too-thorough experiments that I’ve run myself. As such, some details might be a little blurry.</p></blockquote>
<blockquote>
<p><strong>Also, both of these tools are still in early alpha!</strong></p>
<p>Please do not use this as a definitive judgment as to which one is better and/or worse. This blog is just for fun to see what state the two tools are at now!</p></blockquote>
<blockquote>
<p>The following tests and experiments were performed on the latest versions of pyrefly, ty, mypy, and pyright as of writing this blog:</p>
<ul>
<li><code>pyrefly 0.17.0</code></li>
<li><code>ty 0.0.1-alpha.7 (afb20f6fe 2025-05-26)</code></li>
<li><code>mypy 1.15.0 (compiled: yes)</code></li>
<li><code>pyright 1.1.401</code></li>
</ul></blockquote>
<h2 id="pyrefly">Pyrefly</h2>
<p>Pyrefly is Meta’s new Rust-based Python type checker, replacing <a href="https://pyre-check.org/">Pyre</a> — Meta’s previous Python type checker written in OCaml. The hopes are that Pyrefly should be faster, more portable, and more capable compared to Pyre.</p>
<p>One key thing the Pyrefly team made very clear this year is that they want to be <em><strong>truly open source</strong></em>. Pyre was also <em>technically</em> open source, but it was more of a “we built this for our needs, but here’s the source code if you want it”. In contrast, one of the foundational goals of Pyrefly is to be more engaged with the needs of the open-source community.</p>
<figure>
  <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/ZTSZ1OCUaeQ?si=Rc3-M7a7Yh7SSq-X&amp;start=1405" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
  <figcaption>pyrefly introduction presentation</figcaption>
</figure>
<h2 id="ty">ty</h2>
<p>ty is also a Rust-based Python type checker currently under development by <a href="https://astral.sh/">Astral</a>, the team behind <a href="https://docs.astral.sh/uv/">uv</a> and <a href="https://github.com/astral-sh/ruff">ruff</a>. The project was formerly known as Red-Knot, but now has its official name: ty. Compared to Meta, Astral is a lot more quiet on its announcement: just a soft launch on GitHub, a quick 30-minute presentation, and a couple of blog articles as podcasts here and there.</p>
<figure>
  <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/7uixlNTOY4s?si=qMCrwoIekSkoH3xF&amp;start=3558" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
  <figcaption>ty introduction presentation</figcaption>
</figure>
<h2 id="similarities">Similarities</h2>
<p>Both pyrefly and ty are written in Rust, both are incremental (albeit implemented slightly differently: see details below), and both are powered under the hood by <a href="https://github.com/astral-sh/ruff">Ruff</a> for AST parsing. Also, both have first-class support for command-line type checking and LSP/IDE integration.</p>
<p>However, other than the fact that they are both fast Python type checkers, that’s where the similarities end. In my opinion, there are four categories in which these two tools differ: <strong>in Speed, Goals, Incrementalization, and Capabilities.</strong> That’s what we’ll explore today.</p>
<h2 id="speed">Speed</h2>
<p>Speed seemed like one of the main focuses of Pyrefly, being mentioned multiple times during the intro presentation. According to the team, it’s 35x faster than Pyre and 14x faster than Mypy/Pyright, with support of up to 1.8 million lines of code per second. Fast enough to “type check on every keystroke”.</p>
<p>In comparison, speed was also one of the main design goals for ty, but it felt like less of a focus during the introduction. The only claim was “1-2 orders of magnitude faster than current generation type checkers”. Naturally, I wanted to test performance out for myself.</p>
<h2 id="benchmarking---pytorch">Benchmarking - PyTorch</h2>
<p>For the first test, I cloned and checked out the latest release of PyTorch (<code>v2.7.0</code>) and compared type check times between pyrefly, ty, mypy, and pyright on a MacBook M4. Two tests were run, one on the entire <code>pytorch</code> repository and another on just the <code>torch</code> subdirectory:</p>
<blockquote>
<p>PyTorch on the latest mypy is not supported. Using <code>mypy 1.14.0</code> instead.</p></blockquote>
<p><img src="https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/fig-pytorch-benchmarks.svg" alt="pytorch benchmarks"></p><details>
  <summary>Commands Run</summary>
  <ul>
<li><strong>pyrefly:</strong> <code>hyperfine --warmup 3 --runs 5 --ignore-failure 'pyrefly check'</code></li>
<li><strong>ty:</strong> <code>hyperfine --warmup 3 --runs 5 --ignore-failure 'ty check'</code></li>
<li><strong>mypy:</strong> <code>hyperfine --warmup 3 --runs 5 --ignore-failure 'mypy --cache-dir=/dev/null .'</code></li>
<li><strong>pyright:</strong> <code>hyperfine --warmup 3 --runs 5 --ignore-failure 'pyright'</code></li>
</ul>
</details>


<details>
  <summary>Raw Data</summary>
  <pre tabindex="0"><code>ty
  Time (mean ± σ):      4.039 s ±  0.234 s    [User: 19.135 s, System: 3.850 s]
  Range (min … max):    3.888 s …  4.455 s    5 runs

pyrefly
  Time (mean ± σ):     13.029 s ±  0.136 s    [User: 60.489 s, System: 6.297 s]
  Range (min … max):   12.916 s … 13.184 s    5 run

mypy
  dnf

pyright
  Time (mean ± σ):     262.742 s ±  4.948 s    [User: 472.717 s, System: 18.898 s]
  Range (min … max):   259.173 s … 270.617 s    5 runs
</code></pre></details>

<p><img src="https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/fig-pytorch-torch-benchmarks.svg" alt="pytorch torch benchmarks"></p><details>
  <summary>Commands Run</summary>
  <ul>
<li><strong>pyrefly:</strong> <code>hyperfine --warmup 3 --runs 10 --ignore-failure 'pyrefly check torch'</code></li>
<li><strong>ty:</strong> <code>hyperfine --warmup 3 --runs 10 --ignore-failure 'ty check torch'</code></li>
<li><strong>mypy:</strong> <code>hyperfine --warmup 3 --runs 10 --ignore-failure 'mypy --cache-dir=/dev/null torch'</code></li>
<li><strong>pyright:</strong> <code>hyperfine --warmup 3 --runs 10 --ignore-failure 'pyright torch'</code></li>
</ul>
</details>


<details>
  <summary>Raw Data</summary>
  <pre tabindex="0"><code>ty
  Time (mean ± σ):      1.123 s ±  0.022 s    [User: 6.460 s, System: 0.604 s]
  Range (min … max):    1.082 s …  1.167 s    10 runs

pyrefly
  Time (mean ± σ):      2.347 s ±  0.261 s    [User: 15.876 s, System: 0.919 s]
  Range (min … max):    2.089 s …  2.988 s    10 runs
  
mypy
  Time (mean ± σ):     24.731 s ±  0.238 s    [User: 24.144 s, System: 0.519 s]
  Range (min … max):   24.299 s … 25.016 s    10 runs
  
pyright
  Time (mean ± σ):     48.096 s ±  1.705 s    [User: 68.526 s, System: 4.072 s]
  Range (min … max):   46.037 s … 50.488 s    10 runs
</code></pre></details>

<p>Out of the gate, we see that for both <code>pytorch</code> and just <code>torch</code>, ty is about 2-3x faster compared to pyrefly, and both are over 10x-20x faster than mypy and pyright.</p>
<blockquote>
<p>One interesting note is that pyrefly detected more source files than ty: about 8600 for pyrefly and 6500 for ty on <code>pytorch</code> (I’m not sure where the discrepancy comes from).</p></blockquote>
<blockquote>
<p><strong>It’s also important to remember that both pyrefly and ty are still in early alpha, and are not feature complete. This may skew the results!</strong></p></blockquote>
<h2 id="benchmarking---django">Benchmarking - Django</h2>
<p>Next, I ran the same benchmark on Django version 5.2.1.</p>
<blockquote>
<p>Note: mypy errored out during this test.</p></blockquote>
<p><img src="https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/fig-django-benchmarks.svg" alt="django benchmarks"></p><details>
  <summary>Commands Run</summary>
  <ul>
<li><strong>pyrefly:</strong> <code>hyperfine --warmup 3 --runs 10 --ignore-failure 'pyrefly check'</code></li>
<li><strong>ty:</strong> <code>hyperfine --warmup 3 --runs 10 --ignore-failure 'ty check'</code></li>
<li><strong>mypy:</strong> <code>hyperfine --warmup 3 --runs 10 --ignore-failure 'mypy --cache-dir=/dev/null .'</code></li>
<li><strong>pyright:</strong> <code>hyperfine --warmup 3 --runs 10 --ignore-failure 'pyright'</code></li>
</ul>
</details>


<details>
  <summary>Raw Data</summary>
  <pre tabindex="0"><code>ty
  Time (mean ± σ):     578.2 ms ±  27.8 ms    [User: 2980.4 ms, System: 546.9 ms]
  Range (min … max):   557.1 ms … 634.0 ms    10 runs

pyrefly
  Time (mean ± σ):     910.7 ms ±  26.2 ms    [User: 3033.0 ms, System: 565.0 ms]
  Range (min … max):   879.6 ms … 963.1 ms    10 runs
  
mypy
  dnf
  
pyright
  Time (mean ± σ):     16.324 s ±  0.476 s    [User: 24.477 s, System: 1.682 s]
  Range (min … max):   15.845 s … 17.182 s    10 runs
</code></pre></details>

<p>We see the same results across the board with ty being the fastest (2,900 files at 0.6s), pyrefly as a close second (3,200 files at 0.9s), and pyright being the slowest (16s).</p>
<h2 id="benchmarking---mypy">Benchmarking - Mypy</h2>
<p>Finally, I ran the benchmark on the <code>mypy</code> repo itself (more specifically the <code>mypyc</code> subdirectory). Similar results here.</p>
<p><img src="https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/fig-mypy-mypyc-benchmarks.svg" alt="mypy mypyc benchmarks"></p><details>
  <summary>Commands Run</summary>
  <ul>
<li><strong>pyrefly:</strong> <code>hyperfine --warmup 3 --runs 20 --ignore-failure 'pyrefly check mypyc'</code></li>
<li><strong>ty:</strong> <code>hyperfine --warmup 3 --runs 20 --ignore-failure 'ty check mypyc'</code></li>
<li><strong>mypy:</strong> <code>hyperfine --warmup 3 --runs 20 --ignore-failure 'mypy --cache-dir=/dev/null mypyc'</code></li>
<li><strong>pyright:</strong> <code>hyperfine --warmup 3 --runs 20 --ignore-failure 'pyright mypyc'</code></li>
</ul>
</details>


<details>
  <summary>Raw Data</summary>
  <pre tabindex="0"><code>ty
  Time (mean ± σ):      74.2 ms ±   1.5 ms    [User: 403.4 ms, System: 41.6 ms]
  Range (min … max):    71.9 ms …  78.1 ms    20 runs

pyrefly
  Time (mean ± σ):     136.0 ms ±   1.5 ms    [User: 728.3 ms, System: 54.5 ms]
  Range (min … max):   133.4 ms … 139.6 ms    20 runs
  
mypy
  Time (mean ± σ):      3.544 s ±  0.099 s    [User: 3.442 s, System: 0.093 s]
  Range (min … max):    3.420 s …  3.774 s    20 runs
  
pyright
  Time (mean ± σ):      2.852 s ±  0.103 s    [User: 4.315 s, System: 0.227 s]
  Range (min … max):    2.704 s …  3.105 s    20 runs
</code></pre></details>

<h2 id="goals">Goals</h2>
<p>The primary goals between pyrefly and ty are where I feel the main difference lies. Pyrefly tries to be as aggressive as possible when typing — inferring as much as possible so that even code with absolutely no explicit types can have some amount of typing guarantees.</p>
<p>ty, on the other hand, follows a different mantra: <strong>the gradual guarantee</strong>. The principal idea is that in a well-typed program, removing a type annotation should not cause a type error. In other words: you shouldn’t need to add new types to working code to resolve type errors.</p>
<figure>
  <img src="https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/gradual-guarantee.png" alt="the gradual guarantee slide from ty presentation">
  <figcaption>the gradual guarantee slide from ty presentation</figcaption>
</figure>
<p>This is shown in this example here:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>MyClass</span>:
</span></span><span><span>    attr <span>=</span> <span>None</span>
</span></span><span><span>
</span></span><span><span>foo <span>=</span> MyClass()
</span></span><span><span>
</span></span><span><span><span># ➖ pyrefly | revealed type: None</span>
</span></span><span><span><span># ✅ ty.     | Revealed type: `Unknown | None`</span>
</span></span><span><span><span># ➖ mypy.   | Revealed type is "None"</span>
</span></span><span><span><span># ➖ pyright | Type of "foo.attr" is "None"</span>
</span></span><span><span>reveal_type(foo<span>.</span>attr)
</span></span><span><span>
</span></span><span><span><span># ➖ pyrefly | ERROR: Literal[1] is not assignable to attribute attr with type None</span>
</span></span><span><span><span># ✅ ty.     | &lt; No Error &gt;</span>
</span></span><span><span><span># ➖ mypy.   | ERROR: Incompatible types in assignment (expression has type "int", variable has type "None")</span>
</span></span><span><span><span># ➖ pyright | ERROR: Cannot assign to attribute "attr" for class "MyClass"</span>
</span></span><span><span>foo<span>.</span>attr <span>=</span> <span>1</span>
</span></span></code></pre></div><p>In this example, pyrefly, mypy, and pyright eagerly type <code>foo.attr</code> as <code>None</code> and throw an exception when assigned as <code>1</code> — whereas ty understands that <code>foo.attr = 1</code> should not actually cause a syntax error, and instead types <code>foo.attr</code> as <code>Unknown | None</code> to allow the assignment. (<code>Unknown</code> is a new type added by ty to denote between an <em>explicit</em> <code>Any</code> versus an <em>“unknown”</em> <code>Any</code>.)</p>
<p>As a consequence, this also means that pyrefly can catch some errors that other type checkers cannot. Take this example here:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span>my_list <span>=</span> [<span>1</span>, <span>"b"</span>, <span>None</span>]
</span></span><span><span>val <span>=</span> my_list<span>.</span>pop(<span>1</span>)
</span></span><span><span>
</span></span><span><span><span># ✅ pyrefly | revealed type: int | str | None</span>
</span></span><span><span><span># ➖ ty.     | Revealed type: `Unknown`</span>
</span></span><span><span><span># ➖ mypy.   | Revealed type is "builtins.object"</span>
</span></span><span><span><span># ➖ pyright | Type of "val" is "Unknown"</span>
</span></span><span><span>reveal_type(val)
</span></span><span><span>
</span></span><span><span><span># ✅ pyrefly | ERROR: `*` is not supported between `None` and `Literal[2]`</span>
</span></span><span><span><span># ➖ ty.     | &lt; No Error &gt;</span>
</span></span><span><span><span># ➖ mypy.   | ERROR: Unsupported operand types for * ("object" and "int")</span>
</span></span><span><span><span># ➖ pyright | &lt; No Error &gt;</span>
</span></span><span><span>new_val <span>=</span> val <span>*</span> <span>2</span>
</span></span></code></pre></div><blockquote>
<p>mypy <em>technically</em> did throw an error, but for the wrong reasons. For example, setting <code>my_list = [1, "b"]</code> would fix the program, but mypy still reports a mismatch between <code>object</code> and <code>int</code>.</p></blockquote>
<p>Pyrefly implicitly types <code>val</code> as <code>int | str | None</code>, even though neither <code>val</code> nor <code>my_list</code> was explicitly typed. This correctly catches the <code>val * 2</code> error below.</p>
<p>This is just one of many examples, as more will be shown later in the <strong>Capabilities</strong> section.</p>
<h2 id="incrementalism">Incrementalism</h2>
<p>Both pyrefly and ty claim to be incremental — meaning that changing one file would only cause a re-parse on the affected area, and not the entire program. Pyrefly uses a custom incremental engine behind the scenes for its type checker. In constrast, ty uses <a href="https://github.com/salsa-rs/salsa">Salsa</a>, the same incremental framework that powers <a href="https://rust-analyzer.github.io/">Rust Analyzer</a>.</p>
<p>Interestingly, what that means is that ty has fine-grained incrementalization: changing a single function would only cause a re-parse on that function itself (and nothing else), and its dependent functions, and so on. Pyrefly, on the other hand, uses module-level incrementation: changing a single function would cause a re-parse on the entire file/module, and its dependent files/modules, etc.</p>
<p>The reason why pyrefly chose module-level over fine-grained (at least from what I’ve gathered) is that module-level incrementalization is already fast enough in Rust, and fine-grained incrementalization results in a much more complex and harder to maintain codebase with minimal performance improvements.</p>
<h2 id="capabilities">Capabilities</h2>
<p>Both the pyrefly and ty teams make it VERY CLEAR that they are still unfinished and in early alpha, with known issues, bugs, and incomplete features. Despite that, I think it’s cool to go over what each supports <em>as of now</em> as it showcases what each team has focused on and determined to be important so far for their next-generation Python type checkers.</p>
<h2 id="implicit-type-inference">Implicit Type Inference</h2>
<p>Implicit type inference is one of the showcase features of pyrefly. For example, here is a simple case of inferring return types:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>foo</span>(imp: Any):
</span></span><span><span>    <span>return</span> str(imp)
</span></span><span><span>
</span></span><span><span>a <span>=</span> foo(<span>123</span>)
</span></span><span><span>
</span></span><span><span><span># ✅ pyrefly | revealed type: str</span>
</span></span><span><span><span># ➖ ty.     | Revealed type: `Unknown`</span>
</span></span><span><span><span># ➖ mypy.   | Revealed type is "Any"</span>
</span></span><span><span><span># ✅ pyright | Type of "a" is "str"</span>
</span></span><span><span>reveal_type(a)
</span></span><span><span>
</span></span><span><span><span># ✅ pyrefly | ERROR: `+` is not supported between `str` and `Literal[1]`</span>
</span></span><span><span><span># ➖ ty.     | &lt; No Error &gt;</span>
</span></span><span><span><span># ➖ mypy.   | &lt; No Error &gt;</span>
</span></span><span><span><span># ✅ pyright | ERROR: Operator "+" not supported for types "str" and "Literal[1]"</span>
</span></span><span><span>a <span>+</span> <span>1</span>
</span></span></code></pre></div><p>Here’s another example with inferring types of more complex collection objects (in this case, a <code>dict</code>):</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> typing <span>import</span> reveal_type
</span></span><span><span>
</span></span><span><span>my_dict <span>=</span> {
</span></span><span><span>    key: value <span>*</span> <span>2</span>
</span></span><span><span>    <span>for</span> key, value <span>in</span> {<span>"apple"</span>: <span>2</span>, <span>"banana"</span>: <span>3</span>, <span>"cherry"</span>: <span>1</span>}<span>.</span>items()
</span></span><span><span>    <span>if</span> value <span>&gt;</span> <span>1</span>
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span># ✅ pyrefly | revealed type: dict[str, int]</span>
</span></span><span><span><span># ➖ ty.     | Revealed type: `@Todo`</span>
</span></span><span><span><span># ✅ mypy.   | Revealed type is "builtins.dict[builtins.str, builtins.int]"</span>
</span></span><span><span><span># ✅ pyright | Type of "my_dict" is "dict[str, int]"</span>
</span></span><span><span>reveal_type(my_dict)
</span></span></code></pre></div><p><strong>But,</strong> here is where the “gradual guarantee” of ty comes in. Take this example here:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span>my_list <span>=</span> [<span>1</span>, <span>2</span>, <span>3</span>]
</span></span><span><span>
</span></span><span><span><span># ✅ pyrefly | revealed type: list[int]</span>
</span></span><span><span><span># ➖ ty.     | Revealed type: `list[Unknown]`</span>
</span></span><span><span><span># ✅ mypy.   | Revealed type is "builtins.list[builtins.int]"</span>
</span></span><span><span><span># ✅ pyright | Type of "my_list" is "list[int]"</span>
</span></span><span><span>reveal_type(my_list)
</span></span><span><span>
</span></span><span><span><span># ➖ pyrefly | ERROR: Argument `Literal['foo']` is not assignable to parameter with type `int` in function `list.append`</span>
</span></span><span><span><span># ✅ ty.     | &lt; No Error &gt;</span>
</span></span><span><span><span># ➖ mypy.   | ERROR: Argument 1 to "append" of "list" has incompatible type "str"; expected "int" </span>
</span></span><span><span><span># ➖ pyright | ERROR: Argument of type "Literal['foo']" cannot be assigned to parameter "object" of type "int" in function "append"</span>
</span></span><span><span>my_list<span>.</span>append(<span>"foo"</span>)
</span></span></code></pre></div><p>pyrefly, mypy, and pyright all assume that <code>my_list.append("foo")</code> is a typing error, even though it is <em>technically</em> allowed (Python collections can have multiple types of objects!) If this is the intended behavior, ty is the only checker that implicitly allows this without requiring additional explicit typing on <code>my_list</code>.</p>
<h2 id="generics">Generics</h2>
<p>Another thing the pyrefly team mentioned during their talk was that while redesigning pyrefly from the ground up, they focused on the “hard problems first”. This means that a lot of the architecture around pyrefly was built around things like generics, overloads, and wildcard imports.</p>
<p>For example, here are some examples where pyrefly and ty both have correct generic resolution:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># === Simple Case ===</span>
</span></span><span><span><span>class</span> <span>Box</span>[T]:
</span></span><span><span>    <span>def</span> <span>__init__</span>(self, val: T) <span>-&gt;</span> <span>None</span>:
</span></span><span><span>        self<span>.</span>val <span>=</span> val
</span></span><span><span>
</span></span><span><span>b: Box[int] <span>=</span> Box(<span>42</span>)
</span></span><span><span>
</span></span><span><span><span># ✅ pyrefly | revealed type: int</span>
</span></span><span><span><span># ✅ ty.     | Revealed type: `Unknown | int`</span>
</span></span><span><span><span># ✅ mypy.   | Revealed type is "builtins.int"</span>
</span></span><span><span><span># ✅ pyright | Type of "b.val" is "int"</span>
</span></span><span><span>reveal_type(b<span>.</span>val)
</span></span><span><span>
</span></span><span><span><span># ✅ pyrefly | ERROR: Argument `Literal[100]` is not assignable to parameter `val` with type `str` in function `Box.__init__`</span>
</span></span><span><span><span># ✅ ty.     | ERROR: Object of type `Box[int]` is not assignable to `Box[str]`</span>
</span></span><span><span><span># ✅ mypy.   | ERROR: Argument 1 to "Box" has incompatible type "int"; expected "str"</span>
</span></span><span><span><span># ✅ pyright | ERROR: Type "Box[int]" is not assignable to declared type "Box[str]"</span>
</span></span><span><span>b2: Box[str] <span>=</span> Box(<span>100</span>)
</span></span><span><span>
</span></span><span><span><span># === Bounded Types with Attribute ===</span>
</span></span><span><span><span>class</span> <span>A</span>:
</span></span><span><span>    x: int <span>|</span> str
</span></span><span><span>
</span></span><span><span><span>def</span> <span>f</span>[T: A](x: T) <span>-&gt;</span> T:
</span></span><span><span>    <span># ✅ pyrefly | revealed type: int | str</span>
</span></span><span><span>    <span># ✅ ty.     | Revealed type: `int | str`</span>
</span></span><span><span>    <span># ✅ mypy.   | Revealed type is "Union[builtins.int, builtins.str]"</span>
</span></span><span><span>    <span># ✅ pyright | Type of "x.x" is "int | str"</span>
</span></span><span><span>    reveal_type(x<span>.</span>x)
</span></span><span><span>    <span>return</span> x
</span></span></code></pre></div><p>Whereas here are some examples where pyrefly has better generic resolution compared to ty:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> typing <span>import</span> Callable, TypeVar, assert_type, reveal_type
</span></span><span><span>    
</span></span><span><span><span># === Generic Class Without Explicit Type Param ===</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>C</span>[T]:
</span></span><span><span>    x: T
</span></span><span><span>
</span></span><span><span>c: C[int] <span>=</span> C()
</span></span><span><span>
</span></span><span><span><span># ✅ pyrefly | revealed type: C[int]</span>
</span></span><span><span><span># ➖ ty.     | `C[Unknown]`</span>
</span></span><span><span><span># ✅ pypy.   | Revealed type is "__main__.C[builtins.int]"</span>
</span></span><span><span><span># ✅ pyright | Type of "c" is "C[int]"</span>
</span></span><span><span>reveal_type(c)
</span></span><span><span>
</span></span><span><span><span># ✅ pyrefly | revealed type: int</span>
</span></span><span><span><span># ➖ ty.     | Revealed type: `Unknown`</span>
</span></span><span><span><span># ✅ pypy.   | Revealed type is "builtins.int"</span>
</span></span><span><span><span># ✅ pyright | Type of "c.x" is "int"</span>
</span></span><span><span>reveal_type(c<span>.</span>x)
</span></span><span><span>
</span></span><span><span><span># === Bounded Types with Callable Attribute ===</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>func</span>[T: Callable[[int], int]](a: T, b: int) <span>-&gt;</span> T:
</span></span><span><span>    <span># ✅ pyrefly | revealed type: int</span>
</span></span><span><span>    <span># ➖ ty.     | ERROR: &lt;Error: Object of type `T` is not callable&gt;</span>
</span></span><span><span>    <span># ✅ pypy.   | Revealed type is "builtins.int"</span>
</span></span><span><span>    <span># ✅ pyright | Type of "a(b)" is "int"</span>
</span></span><span><span>    reveal_type(a(b))
</span></span><span><span>    <span>return</span> a
</span></span></code></pre></div><p>Interestingly enough, both pyrefly and ty seem to struggle with resolving covariance and contravariance relationships. Example here:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> __future__ <span>import</span> annotations
</span></span><span><span>
</span></span><span><span><span>class</span> <span>A</span>[X]:
</span></span><span><span>    <span>def</span> <span>f</span>(self) <span>-&gt;</span> B[X]:
</span></span><span><span>        <span>...</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>B</span>[Y]:
</span></span><span><span>    <span>def</span> <span>h</span>(self) <span>-&gt;</span> B[Y]:
</span></span><span><span>        <span>...</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>cast_a</span>(a: A[bool]) <span>-&gt;</span> A[int]:
</span></span><span><span>    <span># ➖ pyrefly | ERROR: Return type does not match returned value: expected `A[int]`, found `A[bool]`</span>
</span></span><span><span>    <span># ➖ ty.     | ERROR: Returned type `A[bool]` is not assignable to declared return type `A[int]`</span>
</span></span><span><span>    <span># ✅ mypy.   | &lt; No Error &gt;</span>
</span></span><span><span>    <span># ✅ pyright | &lt; No Error &gt;</span>
</span></span><span><span>    <span>return</span> a  <span># Allowed</span>
</span></span></code></pre></div><h2 id="informative-error-messages">Informative Error Messages</h2>
<p>One explicit feature of ty is to have clear and concise error messages.</p>
<p>For example, here is a simple example of a function call with mismatched types:</p>
<p><img src="https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/ty-error-message.png" alt="ty-error-message.png"></p>
<p>Compared to pyrefly, mypy, and pyright:</p>
<p><img src="https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/pyrefly-error-message.png" alt="pyrefly-error-message.png"></p>
<p><img src="https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/mypy-error-message.png" alt="mypy-error-message.png"></p>
<p><img src="https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/pyright-error-message.png" alt="pyright-error-message.png"></p>
<p>Here is another example with mismatched return types:</p>
<p><img src="https://blog.edward-li.com/tech/comparing-pyrefly-vs-ty/ty-error-message-2.png" alt="ty-error-message-2.png"></p>
<p>In my opinion, much cleaner! It’s exciting to see new and improved error messages coming to Python.</p>
<h2 id="intersection-and-negation-types">Intersection and Negation Types</h2>
<p>Finally, one really cool feature the Astral team showed off was support for intersection and negation types — which they claim is the only Python type checker to implement. To illustrate this, take a look at this example:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>WithX</span>:
</span></span><span><span>  x: int
</span></span><span><span>
</span></span><span><span><span>@final</span>
</span></span><span><span><span>class</span> <span>Other</span>:
</span></span><span><span>  <span>pass</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>foo</span>(obj: WithX <span>|</span> Other):
</span></span><span><span>  <span>if</span> hasattr(obj, <span>"x"</span>):
</span></span><span><span>    <span># ➖ pyrefly | revealed type: Other | WithX</span>
</span></span><span><span>    <span># ✅ ty.     | Revealed type: `WithX`</span>
</span></span><span><span>    <span># ➖ mypy.   | Revealed type is "Union[__main__.WithX, __main__.Other]"</span>
</span></span><span><span>    <span># ➖ pyright | Type of "obj" is "WithX | Other"</span>
</span></span><span><span>    reveal_type(obj)
</span></span></code></pre></div><blockquote>
<p><code>@final</code> is a new feature in Python 3.12 that prevents a class from being subclassed. This is important for the type checker to know that <code>Other</code> cannot be subclassed with <code>x</code> in the future.</p></blockquote>
<p>Given the constraints that <code>obj</code> is either <code>WithX</code> or final type <code>Other</code>, and <code>obj</code> <em>has</em> to have attribute <code>x</code>, the only resolvable type for <code>obj</code> at <code>reveal_type(obj)</code> is <code>WithX</code>. Breaking down what happens behind the scenes:</p>
<pre tabindex="0"><code>(WithX | Other) &amp; &lt;Protocol with members 'x'&gt;
=&gt; (WithX &amp; &lt;Protocol with members 'x'&gt; | (Other &amp; &lt;Protocol with members 'x'&gt;)
=&gt; WithX | Never
=&gt; WithX
</code></pre><p>Take a look at another example here:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>MyClass</span>:
</span></span><span><span>    <span>...</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>MySubclass</span>(MyClass):
</span></span><span><span>    <span>...</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>bar</span>(obj: MyClass):
</span></span><span><span>    <span>if</span> <span>not</span> isinstance(obj, MySubclass):
</span></span><span><span>        <span># ➖ pyrefly | revealed type: MyClass</span>
</span></span><span><span>        <span># ✅ ty.     | Revealed type: `MyClass &amp; ~MySubclass`</span>
</span></span><span><span>        <span># ➖ mypy.   | Revealed type is "__main__.MyClass"</span>
</span></span><span><span>        <span># ➖ pyright | Type of "obj" is "MyClass"</span>
</span></span><span><span>        reveal_type(obj)
</span></span></code></pre></div><p>ty is the only type checker to resolve <code>obj</code> at <code>reveal_type(obj)</code> to <code>MyClass &amp; ~MySubclass</code>. This means that ty introduces new paradigms to Python types:</p>
<p><strong>intersections and negations!</strong> Neat!</p>
<p>However, this is still in early alpha! For example, this case here:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>bar</span>(obj: HasFoo):
</span></span><span><span>    <span>if</span> <span>not</span> hasattr(obj, <span>"bar"</span>):
</span></span><span><span>        reveal_type(obj)
</span></span><span><span>        reveal_type(obj<span>.</span>foo)
</span></span></code></pre></div><p><code>reveal_type(obj)</code> has the correct type of <code>HasFoo &amp; ~&lt;Protocol with members 'bar'&gt;</code>, but <code>reveal_type(obj.foo)</code> resolves to <code>@Todo</code> even though <code>obj.foo</code> should be resolvable to the function <code>foo</code> given the constraints.</p>
<p>As one final fun party trick, here is ty using intersection and negation types to “solve” <a href="https://en.wikipedia.org/wiki/Diophantine_equation">diophantine equations</a>:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># Simply provide a list of all natural numbers here ...</span>
</span></span><span><span>type Nat <span>=</span> Literal[<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>, <span>10</span>, <span>11</span>, <span>12</span>, <span>13</span>]
</span></span><span><span>
</span></span><span><span><span>def</span> <span>pythagorean_triples</span>(a: Nat, b: Nat, c: Nat):
</span></span><span><span>    reveal_type(a<span>**</span><span>2</span> <span>+</span> b<span>**</span><span>2</span> <span>==</span> c<span>**</span><span>2</span>)
</span></span><span><span>    <span># reveals 'bool': solutions exist (3² + 4² == 5²)</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>fermats_last_theorem</span>(a: Nat, b: Nat, c: Nat):
</span></span><span><span>    reveal_type(a<span>**</span><span>3</span> <span>+</span> b<span>**</span><span>3</span> <span>==</span> c<span>**</span><span>3</span>)
</span></span><span><span>    <span># reveals 'Literal[False]': no solutions!</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>catalan_conjecture</span>(a: Nat, b: Nat):
</span></span><span><span>    reveal_type(a<span>**</span><span>2</span> <span>-</span> b<span>**</span><span>3</span> <span>==</span> <span>1</span>)
</span></span><span><span>    <span># reveals 'bool': solutions exist (3² - 2³ == 1)</span>
</span></span></code></pre></div><h2 id="final-thoughts">Final Thoughts</h2>
<p>Overall, it’s exciting to have two new faster type checkers in the Python ecosystem! As of right now, pyrefly and ty seem to follow two different systematic goals. Ty takes a gradual approach to typing - given a program that (theoretically) runs flawlessly, running a type checker should not raise any new typing errors - and if it does, it probably indicates an actual flaw somewhere in the code. Pyrefly takes a different approach, one that is similar to many state-of-the-art Python type checkers today - infer as many types as possible, at the cost of possibly introducing typing errors where it shouldn’t.</p>
<p>As mentioned multiple times, both pyrefly and ty are in early alpha. I strongly suspect the features and capabilities of both tools will converge as time goes on, but nevertheless, it is still cool to see where the two type checkers are at now and how they might come into play in different scenarios sometime in the future.</p>
<p><strong>Go try these out for yourself now!</strong></p>
<p>You can try out pyrefly over at <strong><a href="https://pyrefly.org/sandbox">pyrefly.org/sandbox</a></strong>, and ty over at <strong><a href="https://play.ty.dev/">play.ty.dev</a></strong>. Both also have their respective <code>pip install</code> commands and plugins for your editor (VSCode, Cursor, etc).</p>
<p>In the meantime, I heard rumors that Google is planning on open-sourcing their own Go-based Python type checker, so it’ll be very cool to check that out once it comes out 👀 …</p>
<h2 id="appendix">Appendix</h2>
<p>I just wanted to call out that ty’s tests are written in… <strong>MARKDOWN</strong>! How cool is that?</p>
<blockquote>
<p><strong><a href="https://github.com/astral-sh/ruff/tree/main/crates/ty_python_semantic/resources/mdtest">https://github.com/astral-sh/ruff/tree/main/crates/ty_python_semantic/resources/mdtest</a></strong></p></blockquote>
<hr>
<p><em>Thanks for reading!</em></p>
<p><em>If you notice any mistakes, comments, or feedback, please let me know!</em></p>
<p><em>Contact: <a href="mailto:blog@edward-li.com">blog@edward-li.com</a></em></p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mistral Agents API (113 pts)]]></title>
            <link>https://mistral.ai/news/agents-api</link>
            <guid>44107187</guid>
            <pubDate>Tue, 27 May 2025 14:09:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/agents-api">https://mistral.ai/news/agents-api</a>, See on <a href="https://news.ycombinator.com/item?id=44107187">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr"><img src="https://cms.mistral.ai/assets/f2a4b295-ff64-4c16-a42a-14f858c65766.png?width=1080&amp;height=457" alt="Cover"></p>
<p dir="ltr">Today we announce our new Agents API, a major step forward in making AI more capable, useful, and an active problem-solver.</p>
<p dir="ltr">Traditional language models excel at generating text but are limited in their ability to perform actions or maintain context. Our new Agents API addresses these limitations by combining Mistral's powerful language models with:</p>
<ul>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Built-in connectors for code execution, web search, image generation, and MCP tools&nbsp;</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Persistent memory across conversations&nbsp;</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Agentic orchestration capabilities</p>
</li>
</ul>
<p dir="ltr">The Agents API complements our <a href="https://docs.mistral.ai/capabilities/completion/" target="_blank" rel="noopener">Chat Completion API</a> by offering a dedicated framework that simplifies implementing agentic use cases. It serves as the backbone of enterprise-grade agentic platforms.</p>
<p dir="ltr">By providing a reliable framework for AI agents to handle complex tasks, maintain context, and coordinate multiple actions, the Agents API enables enterprises to use AI in more practical and impactful ways.</p>
<h2 dir="ltr">Mistral agents in action.</h2>
<p dir="ltr">Explore the diverse applications of Mistral’s Agents API across various sectors:</p>
<ul>
<li id="demo-github" dir="ltr">
<h3>Coding assistant with Github.</h3>
<p dir="ltr">An agentic workflow built with Mistral's agents API where an agent interacts with Github and oversees a developer agent, powered by DevStral to write code. The agent is granted full authority over Github, showcasing automated software development task management.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/1Tt9Fq1pUPQ?si=j4fIT7TqM1RGsyRG" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<a href="https://github.com/mistralai/cookbook/tree/main/mistral/agents/github_agent" target="_blank" rel="noopener">Read our cookbook</a></li>
<li id="demo-linear" dir="ltr">
<h3>Linear tickets assistant.</h3>
<p dir="ltr">An intelligent task coordination assistant powered by our Agents API, using multi-server MCP architecture to transform call transcripts to PRDs to actionable Linear issues and track project deliverables.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/4UPP-JEjcKo?si=gMuPof7qCpuHuc2z" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<a href="https://github.com/mistralai/cookbook/tree/main/mistral/agents/prd_linear_ticket" target="_blank" rel="noopener">Read our cookbook</a></li>
<li id="demo-finance" dir="ltr">
<h3>Financial analyst.</h3>
<p dir="ltr">A financial advisory agent constructed with our Agents API, orchestrating multiple MCP servers to source financial metrics, compile insights, and archive results securely.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/ocxRKz73UJw?si=2xJffa3oIFBViA56" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<a href="https://github.com/mistralai/cookbook/tree/main/mistral/agents/financial_analyst" target="_blank" rel="noopener">Read our cookbook</a></li>
<li id="demo-travel" dir="ltr">
<h3>Travel assistant.</h3>
<p dir="ltr">A powerful AI travel assistant that helps users plan their trips, book accommodations, and manage travel needs.</p>
<iframe title="YouTube video player" src="https://www.youtube.com/embed/DSYlhtG2UNM?si=ZZH4OSd1u3QzhpwF" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><a href="https://github.com/mistralai/cookbook/tree/main/mistral/agents/travel_assistant" target="_blank" rel="noopener">Read our cookbook</a></li>
<li id="demo-nutrition" dir="ltr">
<h3>Nutrition assistant.</h3>
<p dir="ltr">An AI-powered food diet companion designed to help users establish goals, log meals, receive personalized food suggestions, track their daily achievements, and discover dining options that align with their nutritional targets.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/uEG2z2esl14?si=Ca_PY02gfVeWChgJ" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<a href="https://github.com/mistralai/cookbook/tree/main/mistral/agents/food_diet_companion" target="_blank" rel="noopener">Read our cookbook</a></li>
</ul>
<h2 dir="ltr">Create an agent with built-in connectors and MCP tools.</h2>
<p dir="ltr">Each agent can be equipped with powerful built-in connectors, which are tools that are deployed and ready for Agents to call on demand, and MCP tools:&nbsp;</p>
<ul>
<li dir="ltr" aria-level="1">
<h3><a href="https://docs.mistral.ai/agents/connectors/code_interpreter/" target="_blank" rel="noopener">Code execution</a></h3>
<p dir="ltr" role="presentation">The Agents API can use the code execution connector, empowering developers to create agents that execute Python code in a secure sandboxed environment. This enables agents to tackle a wide range of tasks, including mathematical calculations and analysis, data visualization and plotting, and scientific computing.</p>
</li>
<li dir="ltr" aria-level="1">
<h3><a href="https://docs.mistral.ai/agents/connectors/image_generation/" target="_blank" rel="noopener">Image generation</a></h3>
<p dir="ltr" role="presentation">The image generation connector tool, powered by Black Forest Lab FLUX1.1 [pro] Ultra, enables agents to create images for diverse applications. This feature can be leveraged for various use cases such as generating visual aids for educational content, creating custom graphics for marketing materials, or even producing artistic images.</p>
</li>
<li dir="ltr" aria-level="1">
<h3><a href="https://docs.mistral.ai/agents/connectors/document_library/" target="_blank" rel="noopener">Document library</a></h3>
<p dir="ltr" role="presentation">Document Library is a built-in connector tool that enables agents to access documents from Mistral Cloud. It powers the integrated RAG functionality, strengthening agents’ knowledge by leveraging the content of user-uploaded documents.</p>
</li>
<li dir="ltr" aria-level="1">
<h3><a href="https://docs.mistral.ai/agents/connectors/websearch/" target="_blank" rel="noopener">Web search</a></h3>
<p dir="ltr" role="presentation">The Agents API offers web search as a connector, enabling developers to combine Mistral models with diverse, up-to-date information from web search, reputable news, and other sources. This integration facilitates the delivery of up-to-date, informed, evidence-supported responses.</p>
<p dir="ltr">Agents with web search capabilities show a significant improvement in performance. In the SimpleQA benchmark, Mistral Large and Mistral Medium with web search achieve scores of 75% and 82.32%, respectively, compared to 23% and 22.08% without web search (see figure below).</p>
<h4>SimpleQA Accuracy (Higher is better)</h4>

</li>
<li dir="ltr">
<h3><a href="https://docs.mistral.ai/agents/mcp/" target="_blank" rel="noopener">MCP tools</a></h3>
<p dir="ltr" role="presentation">The Agents API SDK can also leverage tools built on the Model Context Protocol (MCP)—an open, standardized protocol that enables seamless integration between agents and external systems. MCP tools provide a flexible and extensible interface for agents to access real-world context, including APIs, databases, user data, documents, and other dynamic resources. Check out the <a href="#demo-github" rel="noopener">Github</a>, <a href="#demo-finance" rel="noopener">Financial Analyst</a>, and <a href="#demo-linear" rel="noopener">Linear</a> MCP demos to learn how to use MCP tools with Mistral Agents in action.</p>
<img src="https://cms.mistral.ai/assets/5a0eb67b-819c-4a3f-9cc0-7dba190d58d2.svg?width=null&amp;height=null" alt="Mcp Mistral"></li>
</ul>
<h2 dir="ltr">Memory and context with stateful conversations.</h2>
<p dir="ltr">The Agents API provides robust conversation management through a flexible and stateful conversation system. Each conversation retains its context, allowing for seamless and coherent interactions over time.</p>
<ul>
<li>
<h3><a href="https://docs.mistral.ai/agents/agents_basics/#conversations" target="_blank" rel="noopener">Conversation management</a></h3>
<p dir="ltr">There are two ways to start a conversation:</p>
<ol>
<li dir="ltr">With an Agent: Create a conversation with a specific agent_id to leverage its specialized capabilities.</li>
<li dir="ltr">Direct Access: Start a conversation by directly specifying the model and completion parameters, providing quick access to built-in connectors.</li>
</ol>
<p dir="ltr">Each conversation maintains a structured history through conversation entries, ensuring that the context is preserved across interactions.</p>
</li>
<li>
<h3><a href="https://docs.mistral.ai/agents/agents_basics/#continue-a-conversation-working" target="_blank" rel="noopener">Stateful interactions and conversation branching</a></h3>
<p dir="ltr">Developers are no longer required to monitor conversion history; they have the ability to view past conversations. They can always continue any conversation or initiate new conversation paths from any point.&nbsp;</p>
</li>
<li dir="ltr">
<h3><a href="https://docs.mistral.ai/agents/agents_basics/#streaming-output-working" target="_blank" rel="noopener">Streaming output</a></h3>
<p dir="ltr">The API also supports streaming outputs, both when starting a conversation and continuing a previous one. This feature allows for real-time updates and interactions.&nbsp;</p>
</li>
</ul>
<h2 dir="ltr">Agent orchestration.</h2>
<p dir="ltr">The true power of our Agents API lies in its ability to orchestrate multiple agents to solve complex problems. Through dynamic orchestration, agents can be added or removed from a conversation as needed—each one contributing its unique capabilities to tackle different parts of a problem.</p>
<p dir="ltr"><img src="https://cms.mistral.ai/assets/55ca02be-4dfa-4f0e-ba6a-adc7c54dce4c.svg?width=null&amp;height=null" alt="Agents"></p>
<ul>
<li dir="ltr">
<h3><a href="https://docs.mistral.ai/agents/handoffs/#create-an-agentic-workflow" target="_blank" rel="noopener">Creating an agentic workflow</a></h3>
<p dir="ltr">To build a workflow with handoffs, start by creating all necessary agents. You can create as many agents as needed, each with specific tools and models, to form a tailored workflow.</p>
</li>
<li dir="ltr">
<h3><a href="https://docs.mistral.ai/https://docs.mistral.ai/agents/handoffs/#create-an-agentic-workflow" target="_blank" rel="noopener">Agent handoffs</a></h3>
<p dir="ltr">Once agents are created, define which agents can hand off tasks to others. For example, a finance agent might delegate tasks to a web search agent or a calculator agent based on the conversation's needs.</p>
<p dir="ltr">Handoffs enable a seamless chain of actions. A single request can trigger tasks across multiple agents, each handling specific parts of the request. This collaborative approach allows for efficient and effective problem-solving, unlocking powerful possibilities for real-world applications.</p>
</li>
</ul>
<h2 dir="ltr">Get started.</h2>
<p dir="ltr">To get started, check out our <a href="https://docs.mistral.ai/agents/agents_introduction" target="_blank" rel="noopener">docs</a>, create your first agent, and start building!&nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Cline Doesn't Index Your Codebase (and Why That's a Good Thing) (110 pts)]]></title>
            <link>https://cline.bot/blog/why-cline-doesnt-index-your-codebase-and-why-thats-a-good-thing</link>
            <guid>44106944</guid>
            <pubDate>Tue, 27 May 2025 13:44:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cline.bot/blog/why-cline-doesnt-index-your-codebase-and-why-thats-a-good-thing">https://cline.bot/blog/why-cline-doesnt-index-your-codebase-and-why-thats-a-good-thing</a>, See on <a href="https://news.ycombinator.com/item?id=44106944">Hacker News</a></p>
<div id="readability-page-1" class="page"><div href="/install?utm_source=website&amp;utm_medium=header"><span><svg fill="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M23.15 2.587L18.21.21a1.494 1.494 0 0 0-1.705.29l-9.46 8.63-4.12-3.128a.999.999 0 0 0-1.276.057L.327 7.261A1 1 0 0 0 .326 8.74L3.899 12 .326 15.26a1 1 0 0 0 .001 1.479L1.65 17.94a.999.999 0 0 0 1.276.057l4.12-3.128 9.46 8.63a1.492 1.492 0 0 0 1.704.29l4.942-2.377A1.5 1.5 0 0 0 24 20.06V3.939a1.5 1.5 0 0 0-.85-1.352zm-5.146 14.861L10.826 12l7.178-5.448v10.896z"></path></svg></span><p><span>Install Cline<!-- --> • <!-- -->1.6M<!-- --> <!-- -->installs</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DuckLake is an integrated data lake and catalog format (152 pts)]]></title>
            <link>https://ducklake.select/</link>
            <guid>44106934</guid>
            <pubDate>Tue, 27 May 2025 13:43:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ducklake.select/">https://ducklake.select/</a>, See on <a href="https://news.ycombinator.com/item?id=44106934">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		<!-- <div class="searchoverlay">
	<div>
		<form autocomplete="off">
			<div class="autocomplete">
				<div class="empty_input"></div>
				<input id="q" type="text" name="q" placeholder="Search docs & blog">
			</div>
		</form>
		<div id="search_results"></div>
		<div class="shortcuts">
			Search Shortcut <span>cmd</span> + <span>k</span> | <span>ctrl</span> + <span>k</span>
		</div>
	</div>
</div> -->

		

			

<div>
      
    
			<p>DuckLake delivers advanced data&nbsp;lake features without traditional lakehouse complexity by using Parquet files and your SQL database. It's an open, standalone format from the DuckDB team.</p>
			
		</div>



<div>
		<div>
      <h2>
        
        Deployment scenarios
        
      </h2>
    
			<p>DuckLake uses a database system to manage your metadata for the catalog. All you need to run your own data warehouse is a database system and storage for Parquet files.</p>
		</div>
		<div>
					<div>
						<ul>
							
							<li data-tab="arch-tab2" data-iconclass="postgre" data-multi="true">PostgreSQL</li>
							<li data-tab="arch-tab3" data-iconclass="sqlite" data-multi="true">SQLite</li>
							<li data-tab="arch-tab4" data-iconclass="mysql" data-multi="true">MySQL</li>
							<li data-tab="arch-tab1" data-iconclass="duckdb" data-multi="false">DuckDB</li>
						</ul>
						<p>← Choose catalog database</p>
					</div>
					
				
					<div>
						<div>
      <h4>
        
        Client
        
      </h4>
    
							
							
							
							<div>
								<div>
      <h4>
        
        Clients
        
      </h4>
    
									<p>Users can run multiple DuckLake clients and connect concurrently to PostgreSQL, MySQL or SQLite.</p>
								</div>
								<div>
      <h4>
        
        Client
        
      </h4>
    
									<p>DuckDB also works with DuckLake as the catalog database. In this case, you are limited to a single client.</p>
								</div>
							</div>
							
						</div>
						<div>
							<div>
      <h4>
        
        Catalog database
        
      </h4>
    
								
								<div>
									<p><img src="https://ducklake.select/images/deployment_diagram/database.svg" alt="Database Icon"></p>
								</div>
								
								<div>
      <h4>
        
        Catalog database
        
      </h4>
    
										<p>DuckLake can use any SQL system as its catalog database, provided that it supports ACID transactions and primary key constraints.</p>
									</div>
								
								
							</div>
							<div>
      <h4>
        
        Storage
        
      </h4>
    
								
								<div>
									<p><img src="https://ducklake.select/images/deployment_diagram/parquet_folder.svg" alt="Parquet Folder"></p><p>Parquet</p>
								</div>
								
								<div>
      <h4>
        
        Storage
        
      </h4>
    
										<p>DuckLake can store your data on any object storage such as AWS S3.</p>
									</div>
								
								
							</div>
						</div>
					</div>
					
					
				</div>
	</div>


<!--
<section>
	<div class="wrap">
      <h2>
        
        Use cases
        
      </h2>
    
		<div class="cards vertical images">
			<div class="card">
				<div class="image"></div>
				<div class="content">
      <h3>
        
        Multiplayer DuckDB
        
      </h3>
    
					<p>DuckLake unlocks concurrency for multiple DuckDB clients.</p>
					<a href="#" class="textbutton arrow-right">Read more</a>
				</div>
			</div>
			<div class="card">
				<div class="image"></div>
				<div class="content">
      <h3>
        
        Self-hosted data warehouse
        
      </h3>
    
					<p>DuckLake allows you to host your own local data warehouse.</p>
					<a href="#" class="textbutton arrow-right">Read more</a>
				</div>
			</div>
		</div>
	</div>
</section>
-->


<div>
      <h2>
        
        DuckLake’s key features
        
      </h2>
    
		<div>
			<div>
				<p><img src="https://ducklake.select/images/icons/waves.svg" alt="wave icon">
				</p>
				<div>
      <h3>
        
        Data lake operations
        
      </h3>
    
					<p>DuckLake supports snapshots, time travel queries, schema evolution and partitioning.</p>
				</div>
			</div>
			<div>
				<p><img src="https://ducklake.select/images/icons/documents.svg" alt="wave icon">
				</p>
				<div>
      <h3>
        
        Lightweight snapshots
        
      </h3>
    
					<p>You can have as many snapshots as you want without frequent compacting steps!</p>
				</div>
			</div>
			<div>
				<p><img src="https://ducklake.select/images/icons/pipette.svg" alt="wave icon">
				</p>
				<div>
      <h3>
        
        ACID transactions
        
      </h3>
    
					<p>DuckLake allows concurrent access with ACID transactional guarantees over multi-table operations.</p>
				</div>
			</div>
			<div>
				<p><img src="https://ducklake.select/images/icons/clock.svg" alt="wave icon">
				</p>
				<div>
      <h3>
        
        Performance-oriented
        
      </h3>
    
					<p>DuckLake uses statistics for filter pushdown, enabling fast queries even on large datasets.</p>
				</div>
			</div>
		</div>
	</div>

<div>
		<div>
      <h2>
        
        In Conversation: DuckDB Founders on DuckLake
        
      </h2>
    
			<p>Listen to Hannes Mühleisen and Mark Raasveldt walk through the history of data lakes and introduce DuckLake, a new lakehouse format.</p>
		</div>
		<div data-video-id="zeonmOO9jm4">
				<p><img src="https://ducklake.select/images/thumb_introducting-ducklake.png" alt="Thumbnail: Introducing DuckLake"></p>
			</div>
	</div>

<div id="quickinstall">
		<div>
      <h2>
        
        Create your first DuckLake with DuckDB
        
      </h2>
    
			<p>DuckDB provides first-class support for DuckLake through its highly portable extension, running wherever DuckDB does.</p>
			<!--<a href="/docs/installation/" class="button transparent">More installation options</a>-->
		</div>
		<div>
				<div>
					<ul>
						
						<li data-client="duckdb">DuckDB</li>
						<li data-client="sqlite">SQLite</li>
						<li data-client="postgresql">PostgreSQL</li>
						<li data-client="mysql">MySQL</li>
					</ul>
				</div>
				
				<div>
<figure><pre><code data-lang="sql"><span>INSTALL</span><span> ducklake</span><span>;</span>

<span>ATTACH</span> <span>'ducklake:metadata.ducklake'</span> <span>AS</span> <span>my_ducklake</span><span>;</span>
<span>USE</span> <span>my_ducklake</span><span>;</span></code></pre></figure>
				</div>
				
	</div></div>

<div id="quick-installation">

<div data-install="duckdb">
<figure><pre><code data-lang="sql"><span>INSTALL</span><span> ducklake</span><span>;</span>

<span>ATTACH</span> <span>'ducklake:metadata.ducklake'</span> <span>AS</span> <span>my_ducklake</span><span>;</span>
<span>USE</span> <span>my_ducklake</span><span>;</span></code></pre></figure>
</div>

<div data-install="postgresql">
<figure><pre><code data-lang="sql"><span>INSTALL</span><span> ducklake</span><span>;</span>
<span>INSTALL</span><span> postgres</span><span>;</span>

<span>-- Make sure that the database `ducklake_catalog` exists in PostgreSQL.</span>
<span>ATTACH</span> <span>'ducklake:postgres:dbname=ducklake_catalog host=your_postgres_host'</span> <span>AS</span> <span>my_ducklake</span><span>;</span>
<span>USE</span> <span>my_ducklake</span><span>;</span></code></pre></figure>
</div>

<div data-install="sqlite">
<figure><pre><code data-lang="sql"><span>INSTALL</span><span> ducklake</span><span>;</span>
<span>INSTALL</span><span> sqlite</span><span>;</span>

<span>ATTACH</span> <span>'ducklake:sqlite:metadata.sqlite'</span> <span>AS</span> <span>my_ducklake</span><span>;</span>
<span>USE</span> <span>my_ducklake</span><span>;</span></code></pre></figure>
</div>

<div data-install="mysql">
<figure><pre><code data-lang="sql"><span>INSTALL</span><span> ducklake</span><span>;</span>
<span>INSTALL</span><span> mysql</span><span>;</span>

<span>-- Make sure that the database `ducklake_catalog` exists in MySQL</span>
<span>ATTACH</span> <span>'ducklake:mysql:db=ducklake_catalog host=your_mysql_host'</span> <span>AS</span> <span>my_ducklake</span><span>;</span>
<span>USE</span> <span>my_ducklake</span><span>;</span></code></pre></figure>
</div>

</div>


<section>
	<div>
      <h2>
        
        Frequently asked questions
        
      </h2>
    
			<p>Answers to common questions to help you understand and make the most of DuckLake.</p>
		</div>
	
	<div>
		<div>
      <h3>
        
        
				Why should I use DuckLake?
			
        
      </h3>
    
			<div>
				<p>DuckLake provides a lightweight one-stop solution for if you need a data lake and catalog.

				</p><p>You can use DuckLake for a “multiplayer DuckDB” setup with multiple DuckDB instances reading and writing the same dataset –
				a concurrency model <a href="https://duckdb.org/docs/stable/connect/concurrency">not supported by vanilla DuckDB</a>.</p>

				<p>If you only use DuckDB for both your DuckLake entry point and your catalog database, you can still benefit from using DuckLake:
				you can run time travel queries,
				exploit data partitioning,
				and can store your data in multiple files instead of using a single (potentially very large) database file.</p>
			</div>
		</div>

		<div>
      <h3>
        
        
				What is DuckLake?
			
        
      </h3>
    
			<div><p>
				First of all, a catchy name for a DuckDB-originated technology for data lakes and lakehouses.
				More seriously, the term “DuckLake” can refer to three things:

				</p><ol>
					<li>the <i>specification</i> of the DuckLake lakehouse format,</li>
					<li>the <a href="https://duckdb.org/docs/stable/core_extensions/ducklake"><code>ducklake</code> <i>DuckDB extension</i></a>, which supports reading/writing datasets in the DuckLake specification,</li>
					<li>a DuckLake, a <i>dataset</i> stored using the DuckLake lakehouse format.</li>
				</ol>
			</div>
		</div>

		<div>
      <h3>
        
        
				What is the license of DuckLake?
			
        
      </h3>
    
			<p>
				The DuckLake specification and the DuckLake DuckDB extension are released under the MIT license.
			</p>
		</div>

	</div>
	
	
	
</section>


		




	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How a hawk learned to use traffic signals to hunt more successfully (258 pts)]]></title>
            <link>https://www.frontiersin.org/news/2025/05/23/street-smarts-hawk-use-traffic-signals-hunting</link>
            <guid>44105965</guid>
            <pubDate>Tue, 27 May 2025 11:46:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.frontiersin.org/news/2025/05/23/street-smarts-hawk-use-traffic-signals-hunting">https://www.frontiersin.org/news/2025/05/23/street-smarts-hawk-use-traffic-signals-hunting</a>, See on <a href="https://news.ycombinator.com/item?id=44105965">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="tts-content"><!--[--><!----><!--]--><figure><picture><!--[--><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/2BngtKIXLF0Ua93HkvlZo0/100e0cb34aa7a8d3085eb572d82ea38b/Screenshot_2025-05-08_092315.png?&amp;w=380&amp;fm=webp&amp;q=80" media="(max-width: 767px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/2BngtKIXLF0Ua93HkvlZo0/100e0cb34aa7a8d3085eb572d82ea38b/Screenshot_2025-05-08_092315.png?&amp;w=642&amp;fm=webp&amp;q=80" media="(min-width: 768px and max-width: 1023px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/2BngtKIXLF0Ua93HkvlZo0/100e0cb34aa7a8d3085eb572d82ea38b/Screenshot_2025-05-08_092315.png?&amp;w=824&amp;fm=webp&amp;q=80" media="(min-width: 1024px and max-width: 1279px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/2BngtKIXLF0Ua93HkvlZo0/100e0cb34aa7a8d3085eb572d82ea38b/Screenshot_2025-05-08_092315.png?&amp;w=644&amp;fm=webp&amp;q=80" media="(min-width: 1280px and max-width: 1439px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/2BngtKIXLF0Ua93HkvlZo0/100e0cb34aa7a8d3085eb572d82ea38b/Screenshot_2025-05-08_092315.png?&amp;w=672&amp;fm=webp&amp;q=80" media="(min-width: 1440px and max-width: 1919px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/2BngtKIXLF0Ua93HkvlZo0/100e0cb34aa7a8d3085eb572d82ea38b/Screenshot_2025-05-08_092315.png?&amp;w=912&amp;fm=webp&amp;q=80" media="(min-width: 1920px)"><!--]--><img src="https://images.ctfassets.net/mrbo2ykgx5lt/2BngtKIXLF0Ua93HkvlZo0/100e0cb34aa7a8d3085eb572d82ea38b/Screenshot_2025-05-08_092315.png?&amp;w=912&amp;fm=webp&amp;q=80" alt="" loading="eager"></picture><figcaption>Adult Cooper’s hawk dispatching a house sparrow. Image: Vladimir Dinets. </figcaption></figure><!--[--><p><strong>Dr Vladimir Dinets, a research assistant professor at the University of Tennessee, is a zoologist who studies animal behavior, ecology, and conservation. As of 2025, he also teaches mathematics at Rudgers University. He is the author of a recently published </strong><a href="https://www.frontiersin.org/journals/ethology/articles/10.3389/fetho.2025.1539103/abstract"><strong><em>Frontiers in Ethology</em></strong><strong> article</strong></a><strong> that documents the impressive adaptation of an avian newcomer to the city. A Cooper’s hawk, a medium-sized raptor native to North America, appears to have learned how to adapt its hunting strategy and strike at a flock of birds precisely when cars at an intersection lined up after traffic lights switched to red, having been alerted by a sound signal that the red phase would last longer than usual. In the following guest editorial, he describes his observations. </strong></p><p>by <a href="https://loop.frontiersin.org/people/2127032/overview">Dr Vladimir Dinets</a></p><p>Many years ago, I got to spend some time in Ngorongoro Crater, a unique place in Africa where immense herds of animals are being watched by equally immense crowds of 4x4-riding tourists, and traffic jams of all kinds are frequent. On my last evening there, a local guide told me at a campfire that some buffalo in the crater had figured out the meaning of car turn signals and used that understanding to get out of the way of turning Jeeps and Land Rovers.</p><p>I never had a chance to return to the crater and still don’t know if that story was true, but it got me interested in animals’ perception of – and interactions with – human-made vehicles. Of course, the most common interaction is the animal becoming a roadkill, but it’s not the whole story. Many animals have learned to use cars for their own benefit, and birds seem to be particularly good at it. Crows drop walnuts, clams, even small vertebrates onto busy roads to have them killed and/or crushed by cars. Carrion-eating birds routinely monitor or patrol busy roads to immediately snatch roadkill. For example, many American highways are partitioned by families of ravens who watch them from dawn till dusk, waiting for meals from under wheels. Songbirds glean dead insects from cars and even nest in moving cars, trains and boats. Small birds use moving cars as mobile shelters from pursuing hawks, while hawks in one Ukrainian city have long been known to use moving cars and streetcars as cover to sneak up on their prey.</p><h2>Hunt at the crosswalk</h2><p>So I’ve been keeping an eye for unusual bird-car play, and that’s why I noticed something interesting going on at a street intersection near my home. The intersection wasn’t particularly busy, and even during morning rush hour, when I was driving my daughter to school, there were usually only a few cars waiting for the green light. But sometimes a pedestrian pressed a button, and that caused the red light to last a lot longer, so the car queue became longer, too, stretching all the way to a small streetside tree with a particularly dense crown. When that happened, the streetlight produced a sound signal, letting blind people know that it was safe to cross.</p><figure><picture><!--[--><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/7EjYAFrSOJtfrqpHsTozaR/89d47415f405e29584ff549eaef532c1/1539103_Figure_1.JPEG?&amp;w=380&amp;fm=webp&amp;q=80" media="(max-width: 767px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/7EjYAFrSOJtfrqpHsTozaR/89d47415f405e29584ff549eaef532c1/1539103_Figure_1.JPEG?&amp;w=642&amp;fm=webp&amp;q=80" media="(min-width: 768px and max-width: 1023px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/7EjYAFrSOJtfrqpHsTozaR/89d47415f405e29584ff549eaef532c1/1539103_Figure_1.JPEG?&amp;w=824&amp;fm=webp&amp;q=80" media="(min-width: 1024px and max-width: 1279px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/7EjYAFrSOJtfrqpHsTozaR/89d47415f405e29584ff549eaef532c1/1539103_Figure_1.JPEG?&amp;w=644&amp;fm=webp&amp;q=80" media="(min-width: 1280px and max-width: 1439px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/7EjYAFrSOJtfrqpHsTozaR/89d47415f405e29584ff549eaef532c1/1539103_Figure_1.JPEG?&amp;w=672&amp;fm=webp&amp;q=80" media="(min-width: 1440px and max-width: 1919px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/7EjYAFrSOJtfrqpHsTozaR/89d47415f405e29584ff549eaef532c1/1539103_Figure_1.JPEG?&amp;w=912&amp;fm=webp&amp;q=80" media="(min-width: 1920px)"><!--]--><img src="https://images.ctfassets.net/mrbo2ykgx5lt/7EjYAFrSOJtfrqpHsTozaR/89d47415f405e29584ff549eaef532c1/1539103_Figure_1.JPEG?&amp;w=912&amp;fm=webp&amp;q=80" alt="" loading="lazy"></picture><figcaption>The study area. The route used by the hawk to attack a flock of birds feeding in front of house #2 is shown with white arrows. The hawk appeared in the tree in front of house #11 as soon as sound signals at the streetlight at the intersection (marked with white asterisks) indicated that red light will be longer than usual, and attacked when the queue of cars reached house #8, making it possible for the hawk to move to the tree in front of house #1 without being visible to potential prey. Credit: Dinets, 2025. </figcaption></figure><p>One winter morning I was in my car waiting for the light to change and suddenly saw a Cooper’s hawk: it emerged from that small tree, flew very low above the sidewalk along the line of cars, made a sharp turn, crossed the street between the cars, and dove onto something near one of the houses.</p><p>A few days later I saw the same thing happen again and decided to investigate. It turned out that the house targeted by the hawk’s attacks was inhabited by a nice big family that liked to eat dinner in the front yard. Next morning their breadcrumbs and other leftovers attracted a small flock of birds – sparrows, doves, and sometimes starlings. That’s what the hawk was after.</p><p>But what was really interesting, and took me much longer to figure out, was that the hawk always attacked when the car queue was long enough to provide cover all the way to the small tree, and that only happened after someone had pressed the pedestrian crossing button. As soon as the sound signal was activated, the raptor would fly from somewhere into the small tree, wait for the cars to line up, and then strike.</p><hr><p><a href="https://www.frontiersin.org/journals/ethology/articles/10.3389/fetho.2025.1539103/full">Download and read original article</a></p><hr><h2>Survival of the smartest?</h2><p>That meant that the hawk understood the connection between the sound and the eventual car queue length. The bird also had to have a good mental map of the place, because when the car queue reached its tree, the raptor could no longer see the place where its prey was and had to get there by memory.</p><p>It was an immature bird. Cooper’s hawks rarely nest in cities in our area but are common winter visitors. So the bird I was watching was almost certainly a migrant, having moved to the city just a few weeks earlier. And it had already figured out how to use traffic signals and patterns. To me it seemed very impressive.</p><figure><picture><!--[--><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/1jzyGvKDMUSCAXO50XsrCt/e48186aea92b2120b4ff6fbb7952dfbe/Fig1.jpg?&amp;w=380&amp;fm=webp&amp;q=80" media="(max-width: 767px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/1jzyGvKDMUSCAXO50XsrCt/e48186aea92b2120b4ff6fbb7952dfbe/Fig1.jpg?&amp;w=642&amp;fm=webp&amp;q=80" media="(min-width: 768px and max-width: 1023px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/1jzyGvKDMUSCAXO50XsrCt/e48186aea92b2120b4ff6fbb7952dfbe/Fig1.jpg?&amp;w=824&amp;fm=webp&amp;q=80" media="(min-width: 1024px and max-width: 1279px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/1jzyGvKDMUSCAXO50XsrCt/e48186aea92b2120b4ff6fbb7952dfbe/Fig1.jpg?&amp;w=644&amp;fm=webp&amp;q=80" media="(min-width: 1280px and max-width: 1439px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/1jzyGvKDMUSCAXO50XsrCt/e48186aea92b2120b4ff6fbb7952dfbe/Fig1.jpg?&amp;w=672&amp;fm=webp&amp;q=80" media="(min-width: 1440px and max-width: 1919px)"><source srcset="https://images.ctfassets.net/mrbo2ykgx5lt/1jzyGvKDMUSCAXO50XsrCt/e48186aea92b2120b4ff6fbb7952dfbe/Fig1.jpg?&amp;w=912&amp;fm=webp&amp;q=80" media="(min-width: 1920px)"><!--]--><img src="https://images.ctfassets.net/mrbo2ykgx5lt/1jzyGvKDMUSCAXO50XsrCt/e48186aea92b2120b4ff6fbb7952dfbe/Fig1.jpg?&amp;w=912&amp;fm=webp&amp;q=80" alt="" loading="lazy"></picture><figcaption>Immature Cooper’s hawk in an ambush. Image: Vladimir Dinets.</figcaption></figure><p>Next winter I saw a hawk in adult plumage hunt in exactly the same way, and I’m pretty sure it was the same bird. The following summer, the sound signal at the streetlight stopped working, and the residents of the house moved out, so there were no more bird flocks. I haven’t seen any Cooper’s hawks around here ever since.</p><p>Cooper’s hawk is on a rather short list of bird of prey species that have successfully adapted to life in cities. A city is a difficult and very dangerous habitat for any bird, but particularly for a large raptor specializing in live prey: you have to avoid windows, cars, utility wires, and countless other dangers while catching something to eat every day. I think my observations show that Cooper’s hawks manage to survive and thrive there, at least in part, by being very smart.</p><p><strong>REPUBLISHING GUIDELINES</strong>: Open access and sharing research is part of <a href="https://www.frontiersin.org/about/about-frontiers">Frontiers’ mission</a>. Unless otherwise noted, you can republish articles posted in the Frontiers news site — as long as you include a link back to the original research. Selling the articles is not allowed. </p><!--]--><!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BGP handling bug causes widespread internet routing instability (199 pts)]]></title>
            <link>https://blog.benjojo.co.uk/post/bgp-attr-40-junos-arista-session-reset-incident</link>
            <guid>44105796</guid>
            <pubDate>Tue, 27 May 2025 11:15:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.benjojo.co.uk/post/bgp-attr-40-junos-arista-session-reset-incident">https://blog.benjojo.co.uk/post/bgp-attr-40-junos-arista-session-reset-incident</a>, See on <a href="https://news.ycombinator.com/item?id=44105796">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h3>May 27 2025</h3>


<p><img src="https://blog.benjojo.co.uk/asset/g89a1FM2rr" alt=""></p>

<p>At 7AM (UTC) on Wednesday May 20th 2025 a BGP message was propagated that triggered surprising (to many) behaviours with two major BGP implementations that are often used for carrying internet traffic.</p>

<p>This caused a large number of “internet facing” BGP sessions to automatically shut down, causing at the very least some routing instability, and at worst brief loss of connectivity for some networks.</p>

<h2>What was the message?</h2>

<p><img src="https://blog.benjojo.co.uk/asset/EnGiUkEy31" alt=""></p>

<p>Using the sessions that people feed to bgp.tools, we can see here a version of the update that caused this behavior, it is a relatively unremarkable BGP Update for a /16, except it had a BGP Prefix-SID Attribute that was not only unwelcome (it is unexpected to see this on internet table BGP updates), but it was also corrupt with all of its internal data being 0x00.</p>

<p>Most implementations (IOS-XR/Nokia SR-OS) correctly filtered this out without causing any problems assuming their systems have been setup for <a href="https://datatracker.ietf.org/doc/html/rfc7606">RFC7606</a> (“BGP error tolerance”), however an interesting interaction with JunOS and Arista EOS caused JunOS to carry the corrupt message, and Arista EOS devices to reset sessions when receiving the message from (likely) a JunOS device.</p>

<p>Since a lot of internet transit carriers use Juniper hardware running JunOS, this meant that those running Arista EOS and connected to an upstream transit carrier router running JunOS would have had their access to the internet severed for a period (likely up to 10 mins).</p>

<h2>Who emitted the message?</h2>

<p><img src="https://blog.benjojo.co.uk/asset/7ajp55dCNF" alt=""></p>

<p>After filtering through the whole bgp.tools archive for that period, it would appear that a number of AS origins were involved with this incident. Suggesting that rather than the attribute having been added by the network that originated the prefix, it was added by a carrier in the middle on its way to the wider internet.</p>

<p>The 4 candidates that appear in all of the offending messages are:</p>

<ul>
<li><a href="https://bgp.tools/as/9304">AS9304</a> ( Hutchison Global Communications Limited )</li>
<li><a href="https://bgp.tools/as/135338">AS135338</a> ( Starcloud Information Limited )</li>
<li><a href="https://bgp.tools/as/151326">AS151326</a> ( DCConnect Communication Pte. Ltd. )</li>
<li><a href="https://bgp.tools/as/138077">AS138077</a> ( PT Abhinawa Sumberdaya Asia )</li>
</ul>

<p>However, bgp.tools has captured routes for the impacted prefixes <em>without the faulty BGP attribute</em> from “[…] 151326 138077 […]“, meaning the culprit that added the attribute was likely Starcloud (AS135338) or Hutchison (AS9304).</p>

<p>Some prefixes seen in updates carrying the attribute (despite very likely not being the ones that added the offending attribute) are</p>

<ul>
<li>156.230.0.0/16</li>
<li>138.113.116.0/24</li>
<li>163.171.102.0/24</li>
<li>163.171.103.0/24</li>
<li>163.171.104.0/24</li>
</ul>

<p>This incident was further amplified by Hutchison/AS9304 being on a large number of internet exchanges, meaning that the offending messages were sent to IX route servers that typically are running <a href="https://bird.network.cz/">bird</a>. Since Bird does not support BGP SID, the message was distributed to many multi-terabit internet exchanges without being filtered, spreading the chaos to more than just internet transit sessions.</p>

<h2>What is BGP Prefix-SID?</h2>

<p>BGP Prefix-SID Attribute should generally only be seen in internal BGP sessions, as the point of them (as defined in <a href="https://datatracker.ietf.org/doc/rfc8669/">RFC8669</a>) is to help define the route the traffic will take within a single network to get to the destination.</p>

<p>The reason that one of these attributes leaked out into the global routing table in the first place could have been caused by an external BGP session being configured as an internal one.</p>

<h2>Who was impacted?</h2>

<p>While it is hard to definitively claim who was impacted, after looking at networks with very large churn (compared to their size) immediately after the initial problematic BGP message was emitted, I count around 100 separate networks that hit issues, some high confidence examples include:</p>

<ul>
<li>SpaceX Starlink <a href="https://bgp.tools/as/14593">AS14593</a></li>
<li>Zscaler <a href="https://bgp.tools/as/62044">AS62044</a> / <a href="https://bgp.tools/as/53813">AS53813</a></li>
<li>Bytedance <a href="https://bgp.tools/as/396986">AS396986</a></li>
<li>Disney Worldwide Services <a href="https://bgp.tools/as/23344">AS23344</a></li>
<li>Nagasaki Cable Media Inc <a href="https://bgp.tools/as/10000">AS10000</a></li>
<li>Global Secure Layer <a href="https://bgp.tools/as/7578">AS7578</a></li>
<li>UpCloud <a href="https://bgp.tools/as/202053">AS202053</a></li>
<li>Netskope <a href="https://bgp.tools/as/55256">AS55256</a></li>
<li>Teleguam Holdings <a href="https://bgp.tools/as/9246">AS9246</a></li>
</ul>

<p>In “normal” times the bgp.tools’s route collector ingests around 20,000 to 30,000 messages per second, during this incident the average 10 second message rate was well over 150,000 /s. Indicating significant disruption to many internet paths.</p>

<h2>Vendors need to get their act together</h2>

<p>While the root cause (or even perpetrator) is not entirely clear, the fact that it propagated over the internet at scale is a demonstration of the situation/risk that I described in my previous post <a href="https://blog.benjojo.co.uk/post/bgp-path-attributes-grave-error-handling">“Grave flaws in BGP Error handling” - August 2023</a>.</p>

<p>In this case while other vendors detected the faulty attribute and suppressed the announcement, Juniper allowed it to propagate to peers, until it ultimately hit Arista devices that did not (or contained faulty) have BGP error tolerance code.</p>

<p>Junipers <a href="https://www.juniper.net/documentation/us/en/software/junos/bgp/topics/topic-map/bgp-error-messages.html">own documentation for JunOS’s BGP error tolerance</a> points out that it does not look at all parts of the message, despite it potentially being able to understand that it is faulty.</p>

<p>This is a curious decision, in which JunOS will save itself from a remote induced session reset, but then forward such messages to other peers (or in business words, likely towards your customers).</p>

<h2>Conclusions</h2>

<p>I have no happy ending for this. While the outage was short, the impact could have been worse. These kinds of incidents/bugs keep me up at night. As more and more services move to be IP based the scope of internet outages is no longer “consumers cannot get to their email”, but it starts to become “TV broadcasts fail” and “emergency service calls no longer work”. These begin to increase the chance of real world human casualties triggered (or at least exacerbated) by bugs such as this.</p>

<p>Filtering through the updates and piecing together this incident was a lot of fun, if you run a network yourself with a full routing table, and you are not part of the already <a href="https://bgp.tools/features">2570 running sessions that give bgp.tools data</a>, you can help the debugging of these future incidents by <a href="https://bgp.tools/kb/setup-sessions">setting up such data feeds</a>!</p>

<hr>

<p>If you want to stay up to date with the blog you can use the <a href="https://blog.benjojo.co.uk/rss.xml">RSS feed</a> or you can follow me on Fediverse <a href="https://benjojo.co.uk/u/benjojo">@benjojo@benjojo.co.uk</a></p>

<p>Until next time!</p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LumoSQL (185 pts)]]></title>
            <link>https://lumosql.org/src/lumosql/doc/trunk/README.md</link>
            <guid>44105619</guid>
            <pubDate>Tue, 27 May 2025 10:39:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lumosql.org/src/lumosql/doc/trunk/README.md">https://lumosql.org/src/lumosql/doc/trunk/README.md</a>, See on <a href="https://news.ycombinator.com/item?id=44105619">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<!-- Copyright 2020 The LumoSQL Authors, see LICENSES/MIT -->

<!-- SPDX-License-Identifier: MIT -->

<!-- SPDX-FileCopyrightText: 2020 The LumoSQL Authors -->

<!-- SPDX-ArtifactOfProjectName: LumoSQL -->

<!-- SPDX-FileType: Documentation -->

<!-- SPDX-FileComment: Original by Dan Shearer, December 2019 -->

<!-- toc -->


<p><a href="https://lumosql.org/src/lumosql/doc/trunk/lumosql.org">LumoSQL</a> is a modification (<a href="https://lumosql.org/src/not-forking/">not a fork</a>) of the
<a href="https://sqlite.org/">SQLite</a> embedded data storage library, which is among the <a href="https://sqlite.org/mostdeployed.html">most-deployed software</a>. We are currently in <a href="https://lumosql.org/src/lumosql/doc/trunk/doc/LumoSQL-PhaseII-Announce.md">Phase II of the project</a>.</p>

<p>If you are reading this on GitHub you are looking at a read-only mirror.
The master is always available at <a href="https://lumosql.org/src/lumosql">lumosql.org</a>.
LumoSQL adds security, privacy, performance and measurement features to SQLite.</p>

<h2>Benchmarking</h2>
<p>SQLite can test and compare results consistently across many kinds of system and configurations using the <a href="https://lumosql.org/src/not-forking">Not-forking tool</a>. Example:</p>

<p><img src="https://lumosql.org/src/lumosql/doc/trunk/new-doc/images/LumoSQLBenchmarkExample.png" alt="Example statistical result from LumoSQL benchmarking"></p>

<h2>Pluggable backends</h2>
<p>LumoSQL can swap back end key-value store engines in and out of SQLite. LMDB is
the most famous (but not the only) example of an alternative key-value store,
and LumoSQL can combine dozes of versions of LMDB and SQLite source code like
this:</p>

<p><img src="https://lumosql.org/src/lumosql/doc/trunk/new-doc/images/LumoSQL-Notforking-diagram.png" alt="Diagram of Not-forking used to create two example binaries"></p>

<p>In LumoSQL 0.4 there are three LumoSQL backends:</p>

<ul>
<li>the default SQLite Btree storage system</li>
<li><a href="https://github.com/LMDB/lmdb">LMDB</a></li>
<li><a href="https://en.wikipedia.org/wiki/Berkeley_DB">the ancient Berkley Database</a></li>
</ul>

<p>We are looking at some interesting new development in key-value storage to add and benchmark.</p>

<h2>Encryption and corruption detection, optionally per-row</h2>
<p>LumoSQL adds modern encryption to SQLite, including <a href="https://en.wikipedia.org/wiki/Attribute-based_encryption">Attribute-Based Encryption
(ABE)</a>. This can be
done on a per-row basis, and also includes per-row checksums so that any error
can be noticed quickly and located down to the individual row. Per-row
checksums also make some search and comparison operations much faster.</p>

<h2>Organised and Supported</h2>
<p>LumoSQL is distributed under <a href="https://lumosql.org/src/lumosql/doc/trunk/LICENCES/README.md">very liberal MIT licence terms</a>.</p>

<p>LumoSQL is supported by the <a href="https://nlnet.nl/">NLNet Foundation</a>.</p>

<p>LumoSQL runs on x86, ARM-32 and RISC-V architectures, and many Linux and BSD OSs.</p>

<h2>Table of Contents</h2>
<ul>
<li><a href="#design-not-forking-and-participating">Design, Not-Forking and Participating</a></li>
<li><a href="#lumosql-and-sqlites-billions-of-users">LumoSQL, and SQLite's Billions of Users</a></li>
<li><a href="#limitations-of-lumosql">Limitations of LumoSQL</a></li>
<li><a href="#build-environment-and-dependencies">Build Environment and Dependencies</a></li>
<li><a href="#using-the-build-and-benchmark-system">Using the Build and Benchmark System</a></li>
<li><a href="#a-brief-history-of-lumosql">A Brief History of LumoSQL</a></li>
</ul>



<h2>Design, Not-Forking and Participating</h2>
<p>If you are reading this on Github, then you are looking at a mirror. LumoSQL is
is maintained using <a href="https://lumosql.org/src/lumosql/">the Fossil repository</a>. If you 
want to participate in LumoSQL there is a forum, and if you have code contributions
you can ask for access to the respository.</p>

<p>LumoSQL has multiple upstreams, but does not fork any of them despite needing modifications.
The novel <a href="https://lumosql.org/src/not-forking">Not-forking</a> tool semi-automatically 
tracks upstream changes and is a requirement for building LumoSQL. Between not-forking 
and the <a href="https://lumosql.org/src/lumosql/doc/trunk/doc/lumo-build-benchmark.md">LumoSQL Build and Benchmark System</a>,
LumoSQL is as much about combining and configuring upstreams as it is about creating
original database software. By maintaining Not-forking outside LumoSQL, we hope
other projects will find it useful.</p>

<p>The LumoSQL and SQLite projects are cooperating, so any merge friction is
expected to become less over time, and key to that is the approach of not
forking.</p>



<h2>LumoSQL, and SQLite's Billions of Users</h2>
<p>LumoSQL exists to demonstrate changes to SQLite that might be useful, but which
SQLite probably cannot consider for many years because of SQLite's unique
position of being used by a majority of the world's population. </p>

<p>SQLite is used by thousands of software projects, just three being
Google's Android, Mozilla's Firefox and Apple's iOS which between them have
billions of users. That is a main reason why SQLite is so careful and conservative
with all changes.</p>

<p>On the other hand, many of these same users need SQLite to have new features
which do not fit with the SQLite project's cautious approach, and LumoSQL is a
demonstration of some of these improvements. </p>

<p>The LumoSQL documentation project reviews dozens of relevant codebases.  SQLite
has become ubiquitous over two decades, which means there is a great deal of
preparation needed when considering architectural changes.</p>



<h2>Limitations of LumoSQL</h2>
<p>As of LumoSQL 0.4, there are many obvious limitations, including:</p>

<ul>
<li>The tests used in benchmarking mostly come from an ancient version of SQLite's
speedtest.tcl modified many times, to which DATASIZE
and DEBUG have been added. Experts in SQLite and LMDB database testing 
should review the files in not-fork.d/sqlite3/benchmark/*test. There are 
<a href="https://sqlite.org/src/dir?ci=tip&amp;name=tool">9 tools named *speed*</a> 
in the SQLite source, and any/all of them should be added here.</li>
<li>Neither LMDB nor BDB backends ship with latest SQLite builds. Now all the LumoSQL infrastructure
exists, that is a smaller, more maintainable and repeatable task. But it is not done yet.
There are some generic problems to be solved in the process, such as the optimal way to
address keysize disparities between a KVP store provider and SQLite's internal large keysize.</li>
<li>If we import more of the speed tests from SQLite identified above, then we will 
have a problem with several LMDB and at least two BDB instances, where the SQLite
tests will fail. In most cases this is about the LMDB port needing to be more 
complete but in some it is about relevance, where some SQLite tests will not apply. In
addition some backends will always need
to have additional tests (for example, BDB has more extensive user management than 
SQLite).</li>
</ul>



<h2>Build Environment and Dependencies</h2>
<p>Most developers already have the required minimum of git and core unix-style
development tools. SQLite has very few dependencies (mostly Tcl), and
LumoSQL adds one Perl-based processing tool.</p>

<p>LumoSQL is mirrored to Github and application developers can use git
with Github in the usual way. LumoSQL developers working on the LumoSQL
library internals choose to use <a href="https://fossil-scm.org/">Fossil source code
manager</a> instead of git, and if you're planning
to develop LumoSQL internals then you need Fossil.</p>

<p>There are many <a href="https://www.fossil-scm.org/home/doc/trunk/www/fossil-v-git.wiki">reasons why people choose
Fossil</a>.
For LumoSQL one of them is that SQLite and Fossil are symbiotic
projects, each written in the other.</p>

<h4>Debian or Ubuntu-derived Operating Systems</h4>
<p>Uncomment existing <code>deb-src</code> line in /etc/apt/sources.list, for example
for Ubuntu 20.04.2 a valid line is:
<b>
</b></p><pre><b><code>deb-src http://gb.archive.ubuntu.com/ubuntu focal main restricted
</code></b></pre>

<p>Then run
<b>
</b></p><pre><b><code>sudo apt update                              # this fetches the deb-src updates
sudo apt full-upgrade                        # this gets the latest OS updates
sudo apt install git build-essential tclx
sudo apt build-dep sqlite3
</code></b></pre>

<p>The <em>exact</em> commands above have been tested on a pristine install of Ubuntu
20.04.2 LTS, as installed from ISO or one of the operating systems shipped with
Windows Services for Linux.</p>

<h4>Fedora-derived Operating Systems</h4>
<p>On any reasonably recent Fedora-derived Linux distribution, including Red Hat:</p>

<pre><b><code>sudo dnf install --assumeyes \
  git make gcc ncurses-devel readline-devel glibc-devel autoconf tcl-devel tclx-devel
</code></b></pre>

<h4>Common to all Linux Operating Systems</h4>
<p>Once you have done the setup specific to your operating system in the previous
steps, the following should work on reaonably recent Debian and Fedora-related
operating systems, and Gentoo. </p>

<p>Other required tools can be installed from your operating system's standard packages.
Here are the tool dependencies:</p>

<ul>
<li>Mandatory: <a href="https://lumosql.org/src/not-forking/">the not-forking tool</a>, 
which is a Perl script that needs to be downloaded and installed manually. The instructions for not-forking are on its website.</li>
<li>Recommended: <a href="https://fossil-scm.org/">Fossil</a>. As described above, you don't necessarily need Fossil. But Fossil is very easy to install: if you can't get version 2.13 or later from your distrbution then it is easy to build from source. 
(<em>Note!</em> Ubuntu 20.04, Debian Buster and Gentoo do not include a sufficiently modern Fossil, while NetBSD
and Ubuntu 20.10 do.) Since you now have a development environment anyway you can 
<a href="https://fossil-scm.org/home/doc/trunk/www/build.wiki">build Fossil trunk according to the official instructions</a> or this simpler version (tested on Ubuntu 20.04 LTS):

<ul>
<li>wget -O- https://fossil-scm.org/home/tarball/trunk/Fossil-trunk.tar.gz |  tar -zxf -</li>
<li>sudo apt install libssl-dev</li>
<li>cd Fossil-trunk ; ./configure ; make</li>
<li>sudo make install</li>
</ul></li>
<li>For completeness (although every modern Linux/Unix includes these), to build and benchmark any of the Oracle Berkeley DB targets, you need either "curl" or "wget", and also "file", "gzip" and GNU "tar". Just about any version of these will be sufficient, even on Windows.</li>
<li>If you are running inside a fresh <a href="https://docker.io/">Docker</a> or similar container system, Fossil may be confused about the user id. One solution is to add a user (eg "adduser lumosql" and answer the questions) and then "export USER=lumosql".</li>
</ul>

<p>The not-forking tool will advise you with a message
if you need a tool or a version that is not installed. </p>

<p>On <a href="https://www.debian.org/releases/buster/">Debian 10 "Buster" Stable Release</a>, the not-forking makefile
("perl Makefile.PL") will warn that git needs to be version 2.22 or higher.
Buster has version 2.20, however this is not a critical error. If you don't
like error messages scrolling past during a build, then install a more recent
git <a href="https://backports.debian.org/Instructions/">from Buster backports</a>.</p>



<h2>Quickstart: Using the Build and Benchmark System</h2>
<p>This is a very brief quickstart, for full detail see the
<a href="https://lumosql.org/src/lumosql/doc/trunk/doc/lumo-build-benchmark.md">Build and Benchmark System documentation</a>. </p>

<p>Now you have the dependencies installed, clone the LumoSQL repository using
<code>fossil clone https://lumosql.org/src/lumosql</code> , which will create a new subdirectory called <code>lumosql</code> and
a file called <code>lumosql.fossil</code> in the current directory.</p>

<p>Try:
<b>
</b></p><pre><b><code>cd lumosql
make what
</code></b></pre>

<p>To see what the default sources and options are. The <code>what</code> target does not make any changes although it may generate a file <code>Makefile.options</code> to help <code>make</code> parse the command line.</p>

<p>Benchmarking a single binary should take no longer than 4 minutes to complete depending
on hardware. The results are stored in an SQLite database stored in the LumoSQL 
top-level directory by default, that is, the directory you just created using <code>fossil clone</code>.</p>

<p>Start by building and benchmarking the official SQLite release version 3.35.5, which is the current
release at the time of writing this README.</p>

<p><b>
<code>make benchmark USE_LMDB=no USE_BDB=no SQLITE_VERSIONS='3.35.5'</code>
</b></p>

<p>All source files fetched are cached in ~/.cache/LumoSQL in a way that maximises reuse regardless of 
their origin (Fossil, git, wget etc) and which minimises errors. The LumoSQL build system is driving the
<code>not-fork</code> tool, which maintains the cache. Not-fork will download just the differences of a remote 
version if most of the code is already in cache.</p>

<p>The output from this make command will be lots of build messages followed by something like this:</p>

<pre><b><code>*** Running benchmark 3.35.5
    TITLE = sqlite 3.35.5
    SQLITE_ID = 1b256d97b553a9611efca188a3d995a2fff71275
    SQLITE_NAME = 3.35.5 2021-04-19 18:32:05 1b256d97b553a9611efca188a3d995a2fff712759044ba480f9a0c9e98faalt1
    DATASIZE = 1
    DEBUG = off
    LMDB_DEBUG = off
    LMDB_FIXED_ROWID = off
    LMDB_TRANSACTION = optimistic
    ROWSUM = off
    ROWSUM_ALGORITHM = sha3_256
    SQLITE3_JOURNAL = default
    RUN_ID = 70EA47101F68CDD6D3C0ED255962A2AA50F1540EE4FEBB46A03FAD888B49676C
          OK     0.003   1 Creating database and tables
          OK     0.019   2 1000 INSERTs
          OK     0.007   3 100 UPDATEs without an index, upgrading a read-only transaction
          OK     0.052   4 25000 INSERTs in a transaction
          OK     0.113   5 100 SELECTs without an index
          OK     0.243   6 100 SELECTs on a string comparison
          OK     0.012   7 Creating an index
          OK     0.046   8 5000 SELECTs with an index
          OK     0.036   9 1000 UPDATEs without an index
          OK     0.113  10 25000 UPDATEs with an index
          OK     0.093  11 25000 text UPDATEs with an index
          OK     0.032  12 INSERTs from a SELECT
          OK     0.020  13 DELETE without an index
          OK     0.028  14 DELETE with an index
          OK     0.027  15 A big INSERT after a big DELETE
          OK     0.010  16 A big DELETE followed by many small INSERTs
          OK     0.005  17 DROP TABLE
                 0.859 (total time)
</code></b></pre>

<p>A database with the default name of <code>benchmarks.sqlite</code> has been created with
two tables containing the results. This is one single test run, and the test
run data is kept in the table <code>test_data</code>. The table <code>run_data</code> contains data
relative to a set of runs (version numbers, time test started, etc). This is cumulative,
so another invocation of <code>make benchmark</code> will append to <code>benchmarks.sqlite</code>.</p>

<p>Every run is assigned a SHA3 hash, which helps in making results persistent over time and 
across the internet.</p>

<p>The tool <code>benchmark-filter.tcl</code> does some basic processing of these results:</p>

<pre><b><code>tool/benchmark-filter.tcl
RUN_ID                                                            TARGET  DATE        TIME         DURATION
70EA47101F68CDD6D3C0ED255962A2AA50F1540EE4FEBB46A03FAD888B49676C  3.35.5  2021-05-20  16:13:18        0.859
</code></b></pre>

<p>The option DATASIZE=<strong>parameter</strong> is a multiplication factor on the size of the chunks that is used for 
benchmarking. This is useful because it can affect the time it takes to run the tests by a very different
multiplication factor:</p>

<pre><b><code>make benchmark USE_LMDB=no USE_BDB=no DATASIZE=2 SQLITE_VERSIONS='3.35.5 3.33.0'
</code></b></pre>

<p>followed by:</p>

<pre><b><code>tool/benchmark-filter.tcl 
RUN_ID                                                            TARGET              DATE        TIME         DURATION
70EA47101F68CDD6D3C0ED255962A2AA50F1540EE4FEBB46A03FAD888B49676C  3.35.5              2021-05-20  16:13:18        0.859
65DD0759B133FF5DFBBD04C494F4631E013C64E475FC5AC06EC70F4E0333372F  3.35.5++datasize-2  2021-05-20  16:18:30        2.511
931B1489FC4477A41914A5E0AFDEF3927C306339FBB863B5FB4CF801C8F2F3D0  3.33.0++datasize-2  2021-05-20  16:18:51        2.572
</code></b></pre>

<p>Simplistically, these results suggest that SQLite version 3.35.5 is faster than
3.33.0 on larger data sizes, but that 3.35.5 is much faster with smaller data
sizes. After adding more versions and running the benchmarking tool again, we would
soon discover that SQLite 3.25.0 seems faster than 3.33.0, and other interesting things. 
Simplistic interpretations can be misleading :-)</p>

<p>This is a Quickstart, so for full detail you will need the 
<a href="https://lumosql.org/src/lumosql/doc/trunk/doc/lumo-build-benchmark.md">Build/Benchmark documentation</a>. However as a teaser, and since LMDB
was the original inspiration for LumoSQL (see the 
<a href="https://lumosql.org/src/lumosql/doc/trunk/(#a-brief-history-of-lumosql">History section below</a> for more on that) here are some more things that
can be done with the LMDB target:</p>

<pre><b><code>$ make what LMDB_VERSIONS=all
tclsh tool/build.tcl what not-fork.d MAKE_COMMAND='make' LMDB_VERSIONS='all'
BENCHMARK_RUNS=1
COPY_DATABASES=
COPY_SQL=
MAKE_COMMAND=make
NOTFORK_COMMAND=not-fork
NOTFORK_ONLINE=0
NOTFORK_UPDATE=0
SQLITE_VERSIONS=3.35.5
USE_SQLITE=yes
USE_BDB=yes
SQLITE_FOR_BDB=
BDB_VERSIONS=
BDB_STANDALONE=18.1.32=3.18.2
USE_LMDB=yes
SQLITE_FOR_LMDB=3.35.5
LMDB_VERSIONS=all
LMDB_STANDALONE=
OPTION_DATASIZE=1
OPTION_DEBUG=off
OPTION_LMDB_DEBUG=off
OPTION_LMDB_FIXED_ROWID=off
OPTION_LMDB_TRANSACTION=optimistic
OPTION_ROWSUM=off
OPTION_ROWSUM_ALGORITHM=sha3_256
OPTION_SQLITE3_JOURNAL=default
BUILDS=
    3.35.5
    3.18.2
    +bdb-18.1.32
    3.35.5+lmdb-0.9.11
    3.35.5+lmdb-0.9.12
    3.35.5+lmdb-0.9.13
    3.35.5+lmdb-0.9.14
    3.35.5+lmdb-0.9.15
    3.35.5+lmdb-0.9.16
    3.35.5+lmdb-0.9.17
    3.35.5+lmdb-0.9.18
    3.35.5+lmdb-0.9.19
    3.35.5+lmdb-0.9.20
    3.35.5+lmdb-0.9.21
    3.35.5+lmdb-0.9.22
    3.35.5+lmdb-0.9.23
    3.35.5+lmdb-0.9.24
    3.35.5+lmdb-0.9.25
    3.35.5+lmdb-0.9.26
    3.35.5+lmdb-0.9.27
    3.35.5+lmdb-0.9.28
    3.35.5+lmdb-0.9.29
TARGETS=
    3.35.5
    3.18.2
    +bdb-18.1.32
    3.35.5+lmdb-0.9.11
    3.35.5+lmdb-0.9.12
    3.35.5+lmdb-0.9.13
    3.35.5+lmdb-0.9.14
    3.35.5+lmdb-0.9.15
    3.35.5+lmdb-0.9.16
    3.35.5+lmdb-0.9.17
    3.35.5+lmdb-0.9.18
    3.35.5+lmdb-0.9.19
    3.35.5+lmdb-0.9.20
    3.35.5+lmdb-0.9.21
    3.35.5+lmdb-0.9.22
    3.35.5+lmdb-0.9.23
    3.35.5+lmdb-0.9.24
    3.35.5+lmdb-0.9.25
    3.35.5+lmdb-0.9.26
    3.35.5+lmdb-0.9.27
    3.35.5+lmdb-0.9.28
    3.35.5+lmdb-0.9.29
</code></b></pre>

<p>After executing this build with <code>make benchmark</code> rather than <code>make what</code>, here are summary results using a 
a new parameter to <code>benchmark-filter.tcl</code>:</p>

<pre><b><code>$ tool/benchmark-filter.tcl -fields TARGET,DURATION
TARGET                 DURATION
3.35.5                    0.852
3.35.5+lmdb-0.9.11        1.201
3.35.5+lmdb-0.9.12        1.211
3.35.5+lmdb-0.9.13        1.212
3.35.5+lmdb-0.9.14        1.219
3.35.5+lmdb-0.9.15        1.193
3.35.5+lmdb-0.9.16        1.191
3.35.5+lmdb-0.9.17        1.213
3.35.5+lmdb-0.9.18        1.217
3.35.5+lmdb-0.9.19        1.209
3.35.5+lmdb-0.9.20        1.223
3.35.5+lmdb-0.9.21        1.229
3.35.5+lmdb-0.9.22        1.230
3.35.5+lmdb-0.9.23        1.215
3.35.5+lmdb-0.9.24        1.218
3.35.5+lmdb-0.9.25        1.219
3.35.5+lmdb-0.9.26        1.220
3.35.5+lmdb-0.9.27        1.220
3.35.5+lmdb-0.9.28        1.209
3.35.5+lmdb-0.9.29        1.209
</code></b></pre>

<p>Again, simplistic interpretations are insufficient, but the data here suggests that LMDB has decreased
in performance over time, to improve again with the most recent versions, and no version of LMDB is faster than native SQLite 3.35.5 . However, further
benchmark runs indicate that is not the final story, as LMDB run on slower hard disks improve in relative 
speed rapidly. And using the <code>DATASIZE</code> option also changes the picture.</p>

<p>The results for the Berkely DB backend are also most interesting.</p>



<h2>A Brief History of LumoSQL</h2>
<p>There have been several implementations of new storage backends to SQLite, all of them hard forks
and nearly all dead forks. A backend needs certain characteristics:</p>

<ul>
<li>btree-based key-value store</li>
<li>transactions, or fully ACID</li>
<li>full concurrency support, or fully MVCC</li>
</ul>

<p>There are not many candidate key-value stores. One of the most widely-used is
Howard Chu's LMDB. There was a lot of attention in 2013 when Howard released
his <a href="https://github.com/LMDB/sqlightning">proof of concept SQLite port</a>. LMDB
operates on a very different and more modern principle to all other widely-used
key/value stores, potentially bringing benefits to some users of SQLite. In
2013, the ported SQLite gave significant performance benefits.</p>

<p>The original 2013 code modified the SQLite <code>btree.c</code> from version SQLite
version 3.7.17 to use LMDB 0.9.9 . It took considerable work for LumoSQL to
excavate the ancient code and reproduce the results.</p>

<p>By January 2020 the LumoSQL project concluded:</p>

<ul>
<li>Howard's 2013 performance work is reproducible</li>
<li>SQLite's key-value store improved in performance since 2013, getting close to
parity with LMDB by some measures</li>
<li>SQLite can be readily modified to have multiple storage backends and still
pass 'make test'</li>
<li>SQLite doesn't expect there to be multiple backends, and this has many effects
including for example in error handling. An abstraction layer was needed.</li>
</ul>

<p>Since then, many new possibilities have emerged for LumoSQL, and new collaborations.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Myth of Developer Obsolescence (250 pts)]]></title>
            <link>https://alonso.network/the-recurring-cycle-of-developer-replacement-hype/</link>
            <guid>44105592</guid>
            <pubDate>Tue, 27 May 2025 10:33:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alonso.network/the-recurring-cycle-of-developer-replacement-hype/">https://alonso.network/the-recurring-cycle-of-developer-replacement-hype/</a>, See on <a href="https://news.ycombinator.com/item?id=44105592">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h2 id="from-nocode-to-ai-assisted">From NoCode to AI-Assisted</h2><p>Every few years, a shiny new technology emerges that promises to make software developers obsolete. The headlines follow a predictable pattern: "The End of Coding," "Anyone Can Build Apps Now," or my personal favorite, "Why Your Five-Year-Old Will Be Programming Before Learning to Read."</p><p>The executives get excited. The consultants circle like sharks. PowerPoint decks multiply. Budgets shift.</p><p>And then reality sets in.</p><p>What actually happens isn't replacement, it's transformation. Technologies that promised to eliminate the need for technical expertise end up creating entirely new specializations, often at higher salary points than before. The NoCode movement didn't eliminate developers; it created NoCode specialists and backend integrators. The cloud didn't eliminate system administrators; it transformed them into DevOps engineers at double the salary.</p><p>Now we're witnessing the same pattern with AI-assisted development. The promise that "AI will write all your code" is evolving into the reality that we need engineers who can effectively orchestrate AI systems, which is essentially the same engineers, but now with new skills and higher salary expectations.</p><p>But there's something deeper happening with this particular transformation. Unlike previous technological shifts that primarily changed how we implement solutions, AI-assisted development is highlighting a fundamental truth about software engineering that has always existed but is now impossible to ignore:</p><p><strong>The most valuable skill in software isn't writing code, it's architecting systems.</strong></p><p>And as we'll see, that's the one skill AI isn't close to replacing.</p><h2 id="the-endless-carousel-of-replacement-promises">The Endless Carousel of Replacement Promises</h2><p>How many times have we ridden this merry-go-round? Let's count the rotations:</p><h3 id="the-nocodelowcode-revolution">The NoCode/LowCode Revolution</h3><p>Remember when drag-and-drop interfaces were going to let business users build their own applications? The promise was clear: "Why hire expensive developers when anyone can build an app?"</p><p>What actually happened: These tools created a new class of problems. Someone still needed to design the data models underpinning those shiny interfaces, integrate with existing systems and databases, handle edge cases the visual tools couldn't address, and maintain and upgrade as requirements evolved.</p><p>The result wasn't fewer developers—it was the birth of "NoCode specialists" who understood both the business domain and the technical limitations of these platforms. And guess what? They commanded higher salaries than the developers they supposedly replaced.</p><h3 id="the-cloud-revolution">The Cloud Revolution</h3><p>"Move to the cloud and you won't need system administrators anymore!"</p><p>As if infrastructure would somehow manage itself once it was someone else's server. The cloud didn't eliminate the need for systems expertise. Instead, it transformed what that expertise looked like and dramatically expanded its scope.</p><p>The sysadmins weren't eliminated; they were reborn as DevOps engineers with fancy new job titles and substantially higher compensation packages. The work didn't disappear; it evolved into infrastructure-as-code, automated deployment pipelines, and distributed systems management.</p><p>As I noted in my <a href="https://www.linkedin.com/posts/danilo-alonso_softwarearchitecture-microservicesdebate-activity-7327489408041984001-xqL-?ref=alonso.network" rel="noreferrer">LinkedIn post about microservices</a>: "I've watched teams spend months decomposing perfectly functional systems into microservices only to discover they've traded one set of problems for a more expensive set." The cloud enabled this complexity and someone still needed to manage it. That someone was still a systems expert, just operating at a higher level of abstraction.</p><h3 id="the-offshore-development-wave">The Offshore Development Wave</h3><p>"Why pay local developers when you can get the same work done for a fraction of the cost overseas?"</p><p>The promise of dramatic cost savings quickly collided with the reality of communication challenges, quality issues, and the discovery that effective software development requires deep contextual knowledge and continuous collaboration.</p><p>What emerged instead was a more nuanced approach: distributed teams with clear ownership boundaries, stronger architecture practices, and—surprise—higher total costs than initially projected.</p><h3 id="the-ai-coding-assistant-revolution">The AI Coding Assistant Revolution</h3><p>And now we have AI promising to write our code for us. "Just describe what you want, and the AI will generate it!"</p><p>The early reality is already emerging. AI generates plausible-looking code that often contains subtle inconsistencies and errors. Senior engineers spend significant time verifying and correcting AI output. The "vibe coding" phenomenon means experienced developers extract far more value than novices. Systems built entirely with AI assistance often lack coherent architecture.</p><blockquote>"In the world of the chisel, you just gave carpenters a CNC machine. Guess who will make the better furniture?"</blockquote><p>The pattern is becoming clear once again: the technology doesn't replace the skill, it elevates it to a higher level of abstraction.</p><h2 id="why-this-time-is-different">Why This Time Is Different</h2><p>Here's what the "AI will replace developers" crowd fundamentally misunderstands: <strong>code is not an asset—it's a liability.</strong> Every line must be maintained, debugged, secured, and eventually replaced. The real asset is the business capability that code enables.</p><p>If AI makes writing code faster and cheaper, it's really making it easier to create liability. When you can generate liability at unprecedented speed, the ability to manage and minimize that liability strategically becomes exponentially more valuable.</p><p>This is particularly true because AI excels at local optimization but fails at global design. It can optimize individual functions but can't determine whether a service should exist in the first place, or how it should interact with the broader system. When implementation speed increases dramatically, architectural mistakes get baked in before you realize they're mistakes.</p><p>For agency work building disposable marketing sites, this doesn't matter. For systems that need to evolve over years, it's catastrophic.</p><p>The pattern of technological transformation remains consistent—sysadmins became DevOps engineers, backend developers became cloud architects—but AI accelerates everything. The skill that survives and thrives isn't writing code.</p><p>It's architecting systems. And that's the one thing AI can't do.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LiveStore: State management based on reactive SQLite and built-in sync engine (115 pts)]]></title>
            <link>https://livestore.dev</link>
            <guid>44105412</guid>
            <pubDate>Tue, 27 May 2025 09:50:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://livestore.dev">https://livestore.dev</a>, See on <a href="https://news.ycombinator.com/item?id=44105412">Hacker News</a></p>
<div id="readability-page-1" class="page">  <header>  </header>   <div>  <div> <h2>How it works</h2> <p> LiveStore is a fully-featured, client-centric data layer (replacing libraries like Redux, MobX, etc.) with a reactive embedded SQLite database powered by real-time sync (via event-sourcing). </p> </div> <astro-island uid="Z122SxV" prefix="r53" component-url="/_astro/HowItWorks.Hd-YyVeC.js" component-export="HowItWorks" renderer-url="/_astro/client.DxZNQU9M.js" props="{}" ssr="" client="load" opts="{&quot;name&quot;:&quot;HowItWorksDiagram&quot;,&quot;value&quot;:true}" await-children=""><div id="headlessui-tabs-panel-«r53Rq»" role="tabpanel" tabindex="0" data-headlessui-state="selected" data-selected=""><p>Client A</p><div><svg width="16" height="16" fill="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.5 3.75v1.897c0 .46.375.838.844.838h5.312a.84.84 0 0 0 .844-.838v-1.83a2.5 2.5 0 0 0-.57-.067zm8.813 18H6.688a3.93 3.93 0 0 1-3.938-3.927V6.176A3.93 3.93 0 0 1 6.688 2.25h8.242a3.95 3.95 0 0 1 2.783 1.15l2.383 2.374A3.92 3.92 0 0 1 21.25 8.55v9.272a3.93 3.93 0 0 1-3.937 3.927m-1.813-1.5v-4.015a.84.84 0 0 0-.844-.838H9.344a.84.84 0 0 0-.844.838v4.015z"></path></svg><p><span> = Persisted in device storage</span></p></div></div><!--astro:end--></astro-island>  </div> <div>  <div> <h2>Let's look at a real example</h2> <p> The following is a simple TodoMVC app built with LiveStore showing how to model your events, state and reactively query the database. </p> <p> <span>See more examples on </span> <a href="https://github.com/livestorejs/examples"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg> <span>GitHub</span></a> </p> </div> <astro-island uid="2675Hv" component-url="/_astro/Example.CdMvAiP0.js" component-export="Example" renderer-url="/_astro/client.DxZNQU9M.js" props="{}" ssr="" client="only" opts="{&quot;name&quot;:&quot;InteractiveExample&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island>   </div> <div>  <div> <h2>Demos speak louder than words</h2> <p> LiveStore is designed for demanding &amp; high-performance apps. Let's see it in action. </p> </div> <astro-island uid="LuMUb" prefix="r55" component-url="/_astro/DemoTabs.D27XaGe-.js" component-export="DemoTabs" renderer-url="/_astro/client.DxZNQU9M.js" props="{}" ssr="" client="load" opts="{&quot;name&quot;:&quot;DemoTabs&quot;,&quot;value&quot;:true}" await-children=""><div id="headlessui-tabs-panel-«r55Rq»" role="tabpanel" tabindex="0" data-headlessui-state="selected" data-selected=""><p>Fun fact: LiveStore was originally developed as a part of Overtone and later factored out.</p></div><!--astro:end--></astro-island>  </div> <div>  <div> <h2>Designed and optimized for demanding applications</h2> <p> LiveStore is based on years of research and was developed as the data foundation for uncompromising apps like Overtone. </p> </div> <astro-island uid="ZLoC8p" prefix="r56" component-url="/_astro/FeatureTabs.CJHMTF8J.js" component-export="FeatureTabs" renderer-url="/_astro/client.DxZNQU9M.js" props="{}" ssr="" client="load" opts="{&quot;name&quot;:&quot;FeatureTabs&quot;,&quot;value&quot;:true}" await-children=""><div id="headlessui-tabs-panel-«r56Rq»" role="tabpanel" tabindex="0" data-headlessui-state="selected" data-selected=""><div><p><img loading="lazy" src="https://livestore.dev/images/sqlite.svg" alt="Reactive &amp; persisted SQLite"></p><h3>Reactive &amp; persisted SQLite</h3><p>LiveStore is based on SQLite enabling instant reactive queries while efficiently persisting data in the background.</p><a href="https://livestore.dev/"><span>Learn more</span></a></div><div><p><img loading="lazy" src="https://livestore.dev/images/git-style-sync.svg" alt="Real-time sync engine"></p><h3>Real-time sync engine</h3><p>LiveStore includes a built-in sync engine based on event sourcing (similar to Git) allowing for complex syncing scenarios.</p><a href="https://livestore.dev/"><span>Learn more</span></a></div><div><p><img loading="lazy" src="https://livestore.dev/images/devtools.svg" alt="Premium DX &amp; devtools"></p><h3>Premium DX &amp; devtools</h3><p>For best-in-class developer experience, LiveStore offers first-class devtools similar to Chrome DevTools but for your data.</p><a href="https://livestore.dev/"><span>Learn more</span></a></div><div><h3>High performance</h3><p>LiveStore was designed for high-performance applications enabling developers to build complex apps running at 120 FPS.</p></div><div><h3>Powerful type-safe schema</h3><p>LiveStore offers a powerful type-safe schema API allowing for ergonomic data modeling and evolution without database migrations.</p></div><div><h3>Local-first</h3><p>LiveStore allows you to build local-first/offline-first apps by taking care of the hardest part: data management.</p></div></div><!--astro:end--></astro-island>  </div>  <div>  <div> <h2>What LiveStore does vs. what not</h2> <p>LiveStore was designed to be a principled and flexible data layer. It's design decisions might make it unsuitable for some use cases. Learn more about <a href="https://docs.livestore.dev/evaluation/when-livestore" target="_blank" rel="noopener noreferrer">when to use LiveStore</a>.</p> </div> <div> <div> <h3>What LiveStore does</h3> <ul> <li>  <span>Provide a powerful data foundation for your app.</span> </li><li>  <span>Reactive query layer with full SQLite support.</span> </li><li>  <span>Adapters for most platforms (web, mobile, server/edge, desktop).</span> </li><li>  <span>Flexible data modeling and schema management.</span> </li><li>  <span>Support true offline-first workflows.</span> </li><li>  <span>Custom merge conflict resolution.</span> </li><li>  <span>Sync with a <a href="https://docs.livestore.dev/reference/syncing/sync-provider/" target="_blank" rel="noopener noreferrer">supported provider</a> or roll your own.</span> </li><li>  <span>Helps avoid data vendor lock-in.</span> </li> </ul> </div> <div> <h3>What LiveStore doesn't do</h3> <ul> <li>  <span>Not a batteries-included framework (no auth, file upload, etc).</span> </li><li>  <span>Not a good fit for some <a href="https://docs.livestore.dev/evaluation/when-livestore" target="_blank" rel="noopener noreferrer">use cases</a>.</span> </li><li>  <span>Doesn't sync with your existing database.</span> </li><li>  <span>Doesn't provide a hosted service.</span> </li><li>  <span>Doesn't scale for unbounded amounts of data.</span> </li><li>  <span>Doesn't support peer-to-peer/decentralized syncing.</span> </li><li>  <span>Sell your data.</span> </li> </ul> </div> </div> </div>  <div>  <p> <h2>What others are saying</h2> </p> <astro-island uid="ZWYBfC" prefix="r57" component-url="/_astro/TweetGrid.DN_6z7Ux.js" component-export="TweetGrid" renderer-url="/_astro/client.DxZNQU9M.js" props="{&quot;tweets&quot;:[1,[[0,{&quot;avatar&quot;:[0,{&quot;src&quot;:[0,&quot;/images/avatars/david-khourshid.jpg&quot;],&quot;name&quot;:[0,&quot;David Khourshid&quot;],&quot;role&quot;:[0,&quot;Creator of XState&quot;]}],&quot;tweet&quot;:[0,&quot;Events are the most accurate representation of state. Everything else is a lossy abstraction.\n\nLiveStore gets it right ⚡️\n&quot;],&quot;tweetUrl&quot;:[0,&quot;https://x.com/DavidKPiano/status/1923740185520378365&quot;]}],[0,{&quot;avatar&quot;:[0,{&quot;src&quot;:[0,&quot;/images/avatars/sunil-pai.png&quot;],&quot;name&quot;:[0,&quot;Sunil Pai&quot;],&quot;role&quot;:[0,&quot;Engineer @Cloudflare&quot;]}],&quot;tweet&quot;:[0,&quot;I'm so very excited for @schickling's livestore to drop, really deeply considered and principled way to build great user interfaces.&quot;],&quot;tweetUrl&quot;:[0,&quot;https://x.com/threepointone/status/1922935305557942401&quot;]}],[0,{&quot;avatar&quot;:[0,{&quot;src&quot;:[0,&quot;https://pbs.twimg.com/profile_images/1905007412450320384/UB7A8k0T_400x400.jpg&quot;],&quot;name&quot;:[0,&quot;Beto Moedano&quot;],&quot;role&quot;:[0,&quot;Developer Advocate @Expo&quot;]}],&quot;tweet&quot;:[0,&quot;@livestoredev + @expo + @CloudflareDev = Local-First app with real-time sync, offline persistence, and smooth performance. 🚀&quot;]}],[0,{&quot;avatar&quot;:[0,{&quot;src&quot;:[0,&quot;https://pbs.twimg.com/profile_images/1808122460820430848/sUSrPA5N_400x400.jpg&quot;],&quot;name&quot;:[0,&quot;Jacob Clausen&quot;],&quot;role&quot;:[0,&quot;App Developer&quot;]}],&quot;tweet&quot;:[0,&quot;There's so much to be excited about with @livestoredev. But what really gets me is the extra mile they've gone with the dev tools. Top-tier stuff that adds serious value. Plus, it's an @expo dev plugin, making it seamless and well integrated. A dream combo for offline-first!&quot;]}],[0,{&quot;avatar&quot;:[0,{&quot;src&quot;:[0,&quot;/images/avatars/peter-pistorius.jpg&quot;],&quot;name&quot;:[0,&quot;Peter Pistorius&quot;],&quot;role&quot;:[0,&quot;Co-creator RedwoodSDK&quot;]}],&quot;tweet&quot;:[0,&quot;What are you syncing about?\n\nJust got a preview of @livestoredev v2 by @schickling: it's next-level.&quot;],&quot;tweetUrl&quot;:[0,&quot;https://x.com/appfactory/status/1922660472525857235&quot;]}],[0,{&quot;avatar&quot;:[0,{&quot;src&quot;:[0,&quot;/images/avatars/johannes-schickling.jpg&quot;],&quot;name&quot;:[0,&quot;Johannes Schickling&quot;],&quot;role&quot;:[0,&quot;Creator of LiveStore&quot;]}],&quot;tweet&quot;:[0,&quot;I think LiveStore is pretty cool but I'm biased. However, you should give it a try.&quot;]}],[0,{&quot;avatar&quot;:[0,{&quot;src&quot;:[0,&quot;https://pbs.twimg.com/profile_images/1913014527039541248/DcaBXxHW_400x400.jpg&quot;],&quot;name&quot;:[0,&quot;Andrew Patton&quot;],&quot;role&quot;:[0,&quot;Founder Outlyne&quot;]}],&quot;tweet&quot;:[0,&quot;I’ve spent years wrestling with app state &amp; sync logic that never quite felt right.\n\n@livestoredev has been incredible for us at Outlyne. The declarative model is easy to reason about, sync just works, and the devtools are super useful.\n\nFinally found the one⚡️\n    &quot;],&quot;tweetUrl&quot;:[0,&quot;https://x.com/andpatton/status/1925996952820252886&quot;]}]]]}" ssr="" client="load" opts="{&quot;name&quot;:&quot;TweetGrid&quot;,&quot;value&quot;:true}" await-children=""><!--astro:end--></astro-island>  </div> <div>  <div> <h2>Additional resources</h2> <p> Check out the following resources to learn more about LiveStore. </p> </div> <div> <div>  <h3>Conference talk</h3> <p>You can learn more about LiveStore in some of our past conference talks.</p> <a href="https://docs.livestore.dev/misc/community"> <span>Read more</span>  </a> </div><div>  <h3>Riffle essay</h3> <p>In the Riffle essay (+ PhD thesis by <a href="https://www.geoffreylitt.com/" target="_blank" rel="noopener noreferrer">Geoffrey Litt</a>), we explored the idea of reactive SQLite as a modern state management system.</p> <a href="https://riffle.systems/"> <span>Read more</span>  </a> </div> </div>  </div> <div>  <h2>The story behind LiveStore</h2> <p>LiveStore was designed and developed as foundation for <a href="https://overtone.pro/" target="_blank" rel="noopener noreferrer">Overtone</a>, a next-gen music app. To achieve the high-performance requirements of the app, we needed a state management framework that is able to handle the complex data scenarios of the app which started the <a href="https://riffle.systems/" target="_blank" rel="noopener noreferrer">Riffle research project</a> and later became LiveStore.
</p>   </div> <div>  <div> <h2>Get started</h2> <p> Give LiveStore a try. Start with an existing example or add it to your own project. </p>  </div> <div> <h2>Sponsor the project</h2> <p> Become a sponsor and get access to... </p> <ul> <li>  <span>LiveStore devtools</span> </li><li> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path d="M524.5 69.8a1.5 1.5 0 0 0 -.8-.7A485.1 485.1 0 0 0 404.1 32a1.8 1.8 0 0 0 -1.9 .9 337.5 337.5 0 0 0 -14.9 30.6 447.8 447.8 0 0 0 -134.4 0 309.5 309.5 0 0 0 -15.1-30.6 1.9 1.9 0 0 0 -1.9-.9A483.7 483.7 0 0 0 116.1 69.1a1.7 1.7 0 0 0 -.8 .7C39.1 183.7 18.2 294.7 28.4 404.4a2 2 0 0 0 .8 1.4A487.7 487.7 0 0 0 176 479.9a1.9 1.9 0 0 0 2.1-.7A348.2 348.2 0 0 0 208.1 430.4a1.9 1.9 0 0 0 -1-2.6 321.2 321.2 0 0 1 -45.9-21.9 1.9 1.9 0 0 1 -.2-3.1c3.1-2.3 6.2-4.7 9.1-7.1a1.8 1.8 0 0 1 1.9-.3c96.2 43.9 200.4 43.9 295.5 0a1.8 1.8 0 0 1 1.9 .2c2.9 2.4 6 4.9 9.1 7.2a1.9 1.9 0 0 1 -.2 3.1 301.4 301.4 0 0 1 -45.9 21.8 1.9 1.9 0 0 0 -1 2.6 391.1 391.1 0 0 0 30 48.8 1.9 1.9 0 0 0 2.1 .7A486 486 0 0 0 610.7 405.7a1.9 1.9 0 0 0 .8-1.4C623.7 277.6 590.9 167.5 524.5 69.8zM222.5 337.6c-29 0-52.8-26.6-52.8-59.2S193.1 219.1 222.5 219.1c29.7 0 53.3 26.8 52.8 59.2C275.3 311 251.9 337.6 222.5 337.6zm195.4 0c-29 0-52.8-26.6-52.8-59.2S388.4 219.1 417.9 219.1c29.7 0 53.3 26.8 52.8 59.2C470.7 311 447.5 337.6 417.9 337.6z"></path></svg> <span>Discord channel</span> </li><li>  <span>Community</span> </li> </ul>  </div>  </div> <header>  </header>  
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Lazy Tetris (246 pts)]]></title>
            <link>https://lazytetris.com/</link>
            <guid>44103839</guid>
            <pubDate>Tue, 27 May 2025 03:58:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lazytetris.com/">https://lazytetris.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44103839">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The UI future is colourful and dimensional (176 pts)]]></title>
            <link>https://www.flarup.email/p/the-future-is-colourful-and-dimensional</link>
            <guid>44103131</guid>
            <pubDate>Tue, 27 May 2025 01:23:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.flarup.email/p/the-future-is-colourful-and-dimensional">https://www.flarup.email/p/the-future-is-colourful-and-dimensional</a>, See on <a href="https://news.ycombinator.com/item?id=44103131">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Flat design is over. The future is colourful and dimensional.</p><p><span>Those aren’t my words. They’re </span><a href="https://x.com/bchesky/status/1923155526524772822" rel="">Brian Chesky’s</a><span>, CEO of Airbnb, after what can only be described as a landmark redesign of the platform. A redesign full of whimsical, animated, 3D icons and warm, tactile surfaces.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38378ab5-5d46-42d4-96e0-5b00d903e347_1080x1080.gif" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38378ab5-5d46-42d4-96e0-5b00d903e347_1080x1080.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38378ab5-5d46-42d4-96e0-5b00d903e347_1080x1080.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38378ab5-5d46-42d4-96e0-5b00d903e347_1080x1080.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38378ab5-5d46-42d4-96e0-5b00d903e347_1080x1080.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38378ab5-5d46-42d4-96e0-5b00d903e347_1080x1080.gif" width="1080" height="1080" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/38378ab5-5d46-42d4-96e0-5b00d903e347_1080x1080.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1080,&quot;width&quot;:1080,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4521880,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/gif&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.flarup.email/i/164402959?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38378ab5-5d46-42d4-96e0-5b00d903e347_1080x1080.gif&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38378ab5-5d46-42d4-96e0-5b00d903e347_1080x1080.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38378ab5-5d46-42d4-96e0-5b00d903e347_1080x1080.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38378ab5-5d46-42d4-96e0-5b00d903e347_1080x1080.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38378ab5-5d46-42d4-96e0-5b00d903e347_1080x1080.gif 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>It’s always hard to pinpoint when a paradigm shift happens. Usually, you only recognize it in hindsight. iOS 7 in 2013 was one. These past few weeks have felt like another. The pendulum is swinging again.</p><p>Some of us worked toward this shift for years, so I’ll just say it:</p><p><strong>We’re so back.</strong></p><p><em>I told you so.</em></p><p>But if we’re really entering a new era of visual design, we need better language for it.</p><p><span>I’ve never liked the word </span><em>skeuomorphism</em><span>. A skeuomorph is when something digital borrows the concept of something physical—like a trash can icon that looks like a real bin, or a book app that flips pages like paper. But over time, </span><em>skeuomorphic</em><span> became a catch-all for any design with depth, texture, or lighting—and that’s a mistake. A bin icon, even as a flat glyph, is still a skeuomorph. It’s metaphor, not material.</span></p><p>I’ve been looking for a better word.</p><p>Something that captures the dimensionality we’re beginning to see.</p><p><span>Lately, I’ve been using the word </span><em>Diamorph</em><span>.</span></p><p>It’s not meant to be a grand rebrand of design. A completely invented word. A working title for a style that embraces depth, texture, and light. Not to mimic the real world, but to create something that feels native to the screen. Something expressive. Playful.</p><blockquote><p><strong>Diamorph</strong><span> (adj.): dimensional design that embraces depth, light, texture, and hierarchy—native to the screen, expressive by intent.</span></p><p><strong>Diamorphism</strong><span> (n.): a growing tendency toward intentional dimensionality—layered, tactile, digital-first, and full of character.</span></p></blockquote><p>Maybe it sticks. Maybe it doesn’t. But it’s been helpful for me to give this shift a name while we figure out where it’s heading.</p><p><span>If skeuomorphic design is performative, and flat design is reductive, maybe </span><em>Diamorph</em><span> is something else entirely—less about illusion, more about belonging.</span></p><p>Whatever you call it, it’s clear something is shifting. We’ve felt it building for a while: Big Sur icons, the many -phism experiments, playful micro-interactions, richer lighting models—it’s been building in waves. But now it’s breaking through.</p><p>And with it, we finally get to move past the tired flat-vs-skeuo binary. It’s time to make space for something new.</p><p>I won’t be surprised if WWDC in a couple of weeks introduces some kind of material injection into the digital surfaces Apple controls.</p><p>There’s also an interesting side story here, one that might help fuel the adoption of this new paradigm—and yes, you guessed it: AI.</p><p>After Airbnb showed off their redesign, the internet exploded with soft, dimensional, highly detailed icon sets prompted into existence using generative AI tools.</p><p>Back in the early 2000s, UI design like this had a high skill ceiling. It took years to master lighting, materials, and depth. Now? That level of craft is often just a prompt away.</p><p>I could mourn that—or I could celebrate the fact that the style I’ve championed for years is finally within reach for everyone.</p><p>In the end, I’ve always worked toward more fun and playful interfaces—and I think we’re about to see a lot more of them.</p><p>It’s surprisingly easy to get solid results when generating dimensional icons with AI. These retro consoles I grew up with were created using ChatGPT image prompts, then lightly cleaned up in Photoshop.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d6dbd79-e9f7-4155-acf0-f1a3f3a83673_1917x1360.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d6dbd79-e9f7-4155-acf0-f1a3f3a83673_1917x1360.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d6dbd79-e9f7-4155-acf0-f1a3f3a83673_1917x1360.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d6dbd79-e9f7-4155-acf0-f1a3f3a83673_1917x1360.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d6dbd79-e9f7-4155-acf0-f1a3f3a83673_1917x1360.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d6dbd79-e9f7-4155-acf0-f1a3f3a83673_1917x1360.heic" width="1456" height="1033" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7d6dbd79-e9f7-4155-acf0-f1a3f3a83673_1917x1360.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1033,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:85312,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.flarup.email/i/164402959?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d6dbd79-e9f7-4155-acf0-f1a3f3a83673_1917x1360.heic&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d6dbd79-e9f7-4155-acf0-f1a3f3a83673_1917x1360.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d6dbd79-e9f7-4155-acf0-f1a3f3a83673_1917x1360.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d6dbd79-e9f7-4155-acf0-f1a3f3a83673_1917x1360.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d6dbd79-e9f7-4155-acf0-f1a3f3a83673_1917x1360.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>I’ve been crafting this style by hand for nearly two decades. These aren’t perfect, but they’re hitting the “good enough” mark for many use cases.</p><p>AI handles materials, lighting, and color surprisingly well. Perspective, proportions, and consistency across a set? Still a challenge. Most require a bit of artifact cleanup and a sanity check. (No, that’s not how a controller connects to a SNES.)</p><p>But with transparent backgrounds and a bit of finesse, they’re usable. Sometimes even production-ready. At the very least, they’re a strong base for further refinement.</p><p>It lowers the barrier to entry for this kind of design. I did a quick mockup of a game-collecting macOS app using these icons.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8448057d-bf36-4774-8d84-d2e5a9667abd_934x868.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8448057d-bf36-4774-8d84-d2e5a9667abd_934x868.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8448057d-bf36-4774-8d84-d2e5a9667abd_934x868.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8448057d-bf36-4774-8d84-d2e5a9667abd_934x868.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8448057d-bf36-4774-8d84-d2e5a9667abd_934x868.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8448057d-bf36-4774-8d84-d2e5a9667abd_934x868.heic" width="934" height="868" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8448057d-bf36-4774-8d84-d2e5a9667abd_934x868.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:868,&quot;width&quot;:934,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:80653,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.flarup.email/i/164402959?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8448057d-bf36-4774-8d84-d2e5a9667abd_934x868.heic&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8448057d-bf36-4774-8d84-d2e5a9667abd_934x868.heic 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8448057d-bf36-4774-8d84-d2e5a9667abd_934x868.heic 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8448057d-bf36-4774-8d84-d2e5a9667abd_934x868.heic 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8448057d-bf36-4774-8d84-d2e5a9667abd_934x868.heic 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Here’s that mockup. And seriously—why don’t we have a great app for cataloguing physical media?</figcaption></figure></div><p>Like a lot of other artists, I have mixed feelings about the process. But I’ve always been pragmatic about tools. And if I treat AI as just that: a tool, not a shortcut to the final result—then there’s still a lot of room for craft, taste, and care.</p><p>In an ideal world, AI is a creativity maximiser. It lowers the bar but raises the ceiling.</p><p>I still believe core design skills matter. Maybe more than ever. The fundamentals we learned by doing this by hand: composition, lighting, depth, taste, still apply.</p><p>Tools may change, but taste is hard to fake.</p><p><span>We’re standing at the edge of a new visual language: one that’s expressive, emotional, and unapologetically digital. </span><em>Diamorphic</em><span> design isn’t a throwback, and it’s not just decoration. It’s a step forward.</span></p><p>And with tools like AI lowering the barrier to entry, we’re about to see more people than ever join the conversation.</p><p>Whatever we call it (Diamorph or otherwise), I’m just glad to see interfaces getting weird and wonderful again. We’re not going back. We’re going forward—with depth, with texture, and maybe even with a little joy.</p><p>The future is colourful, dimensional—and it’s already happening.</p><h6>Sponsor</h6><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa031bdd-4041-4b1c-b384-c07d9f3522c6_1456x728.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa031bdd-4041-4b1c-b384-c07d9f3522c6_1456x728.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa031bdd-4041-4b1c-b384-c07d9f3522c6_1456x728.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa031bdd-4041-4b1c-b384-c07d9f3522c6_1456x728.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa031bdd-4041-4b1c-b384-c07d9f3522c6_1456x728.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa031bdd-4041-4b1c-b384-c07d9f3522c6_1456x728.webp" width="1456" height="728" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fa031bdd-4041-4b1c-b384-c07d9f3522c6_1456x728.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:728,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:18134,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.flarup.email/i/164402959?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa031bdd-4041-4b1c-b384-c07d9f3522c6_1456x728.webp&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa031bdd-4041-4b1c-b384-c07d9f3522c6_1456x728.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa031bdd-4041-4b1c-b384-c07d9f3522c6_1456x728.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa031bdd-4041-4b1c-b384-c07d9f3522c6_1456x728.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa031bdd-4041-4b1c-b384-c07d9f3522c6_1456x728.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Want to sponsor an edition of my newsletter? If you've got a product, app or service you think my design-focused audience (~40k subscribers, ~30k opens per issue) would genuinely enjoy, this could be your chance to reach them in a meaningful way.</p><p>Each sponsorship includes an image, some friendly text, and a clear button to bring readers right to your door.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.flarup.email/p/become-a-sponsor&quot;,&quot;text&quot;:&quot;Become a Sponsor&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.flarup.email/p/become-a-sponsor" rel=""><span>Become a Sponsor</span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yes-rs: A fast, memory-safe rewrite of the classic Unix yes command (164 pts)]]></title>
            <link>https://github.com/jedisct1/yes-rs</link>
            <guid>44103116</guid>
            <pubDate>Tue, 27 May 2025 01:20:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jedisct1/yes-rs">https://github.com/jedisct1/yes-rs</a>, See on <a href="https://news.ycombinator.com/item?id=44103116">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">yes-rs 🚀</h2><a id="user-content-yes-rs-" aria-label="Permalink: yes-rs 🚀" href="#yes-rs-"></a></p>
<blockquote>
<p dir="auto">A blazingly fast, memory-safe rewrite of the classic Unix <code>yes</code> command</p>
</blockquote>
<p dir="auto"><a href="https://www.rust-lang.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/b566220cb75842d7c745cf340005f4e54ccd740e2d3ac12111c4281ba5d0f52d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d616465253230776974682d527573742d6f72616e67652e737667" alt="Made with Rust" data-canonical-src="https://img.shields.io/badge/Made%20with-Rust-orange.svg"></a>
<a href="https://www.rust-lang.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/9d8cf38425e08fe4ff448f908b17c7d9cedeef9fd42ca707e45325266b2a5f32/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d656d6f72792d536166652d677265656e2e737667" alt="Memory Safety" data-canonical-src="https://img.shields.io/badge/Memory-Safe-green.svg"></a>
<a href="https://www.rust-lang.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/0c65b548d3a43b30e54530867beaa8399570ffda5dfed5e2eb1cfed749dcca8f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4162737472616374696f6e732d5a65726f253230436f73742d626c75652e737667" alt="Zero Cost" data-canonical-src="https://img.shields.io/badge/Abstractions-Zero%20Cost-blue.svg"></a>
<a href="https://www.rust-lang.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/7482598d6db5b2182118cc60ab50ddfb4c998620bc0494dfc2a1a4ed19e6e012/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f53706565642d426c617a696e67253230466173742d7265642e737667" alt="Blazing Fast" data-canonical-src="https://img.shields.io/badge/Speed-Blazing%20Fast-red.svg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why rewrite <code>yes</code> in Rust? 🤔</h2><a id="user-content-why-rewrite-yes-in-rust-" aria-label="Permalink: Why rewrite yes in Rust? 🤔" href="#why-rewrite-yes-in-rust-"></a></p>
<p dir="auto">Because the original <code>yes</code> command (written in <em>shudders</em> C) is:</p>
<ul dir="auto">
<li>❌ Not memory-safe</li>
<li>❌ Prone to buffer overflows</li>
<li>❌ Lacks modern error handling</li>
<li>❌ Missing zero-cost abstractions</li>
<li>❌ No fearless concurrency</li>
<li>❌ Not written in Rust</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features ✨</h2><a id="user-content-features-" aria-label="Permalink: Features ✨" href="#features-"></a></p>
<ul dir="auto">
<li>🚀 <strong>Blazingly fast</strong> - Outputs "y" at unprecedented speeds</li>
<li>🛡️ <strong>Memory safe</strong> - No segfaults, guaranteed!</li>
<li>⚡ <strong>Zero-cost abstractions</strong> - Maximum performance</li>
<li>🔥 <strong>Fearless concurrency</strong> - Ready for async/await (coming soon!)</li>
<li>🦀 <strong>100% Rust</strong> - No unsafe code blocks</li>
<li>📦 <strong>Cargo integration</strong> - Easy to install and distribute</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation 📦</h2><a id="user-content-installation-" aria-label="Permalink: Installation 📦" href="#installation-"></a></p>

<p dir="auto">Or build from source:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/rust-evangelists/yes-rs
cd yes-rs
cargo build --release"><pre>git clone https://github.com/rust-evangelists/yes-rs
<span>cd</span> yes-rs
cargo build --release</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage 💻</h2><a id="user-content-usage-" aria-label="Permalink: Usage 💻" href="#usage-"></a></p>
<p dir="auto">Just like the original <code>yes</code>, but better:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Output &quot;y&quot; forever (blazingly fast!)
yes-rs

# Output custom string forever (memory-safe!)
yes-rs &quot;hello rust&quot;"><pre><span><span>#</span> Output "y" forever (blazingly fast!)</span>
yes-rs

<span><span>#</span> Output custom string forever (memory-safe!)</span>
yes-rs <span><span>"</span>hello rust<span>"</span></span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmarks 📊</h2><a id="user-content-benchmarks-" aria-label="Permalink: Benchmarks 📊" href="#benchmarks-"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Command</th>
<th>Language</th>
<th>Lines of Code</th>
<th>Memory Safety</th>
<th>Speed</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>yes</code> (GNU)</td>
<td>C</td>
<td>~50</td>
<td>❌</td>
<td>Fast</td>
</tr>
<tr>
<td><code>yes-rs</code></td>
<td>Rust 🦀</td>
<td>~1302</td>
<td>✅</td>
<td><strong>BLAZING FAST</strong></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><em>Benchmarks conducted on my laptop</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing 🤝</h2><a id="user-content-contributing-" aria-label="Permalink: Contributing 🤝" href="#contributing-"></a></p>
<p dir="auto">We welcome contributions! Please ensure all code is:</p>
<ul dir="auto">
<li>✅ Written in Rust</li>
<li>✅ Memory-safe</li>
<li>✅ Blazingly fast</li>
<li>✅ Uses zero-cost abstractions</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Share the Rust Revolution 🦀</h2></p>
<p dir="auto">Think this project deserves more recognition? <strong>Share it on Hacker News!</strong></p>
<p dir="auto">This is exactly the kind of blazingly fast Rust rewrite that everyone on Hacker News should be forced to see. Help spread awareness about it.</p>
<p dir="auto"><strong>Suggested HN title:</strong></p>
<ul dir="auto">
<li>"yes-rs: A blazingly fast, memory-safe rewrite of Unix 'yes' WRITTEN IN RUST 🦀"</li>
<li>"1302 lines of Rust vs 50 lines of C: The future of systems programming"</li>
</ul>
<p dir="auto"><em>Because if it's not written in Rust, it's not worth using.</em> 🦀</p>
<hr>
<p dir="auto"><strong>⚡ Powered by Rust ⚡</strong></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Calendars, Contacts and Files in Stalwart (120 pts)]]></title>
            <link>https://stalw.art/blog/collaboration/</link>
            <guid>44103071</guid>
            <pubDate>Tue, 27 May 2025 01:11:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stalw.art/blog/collaboration/">https://stalw.art/blog/collaboration/</a>, See on <a href="https://news.ycombinator.com/item?id=44103071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container" itemprop="articleBody"><p>We’re excited to announce the release of <a href="https://github.com/stalwartlabs/stalwart" target="_blank" rel="noopener noreferrer">Stalwart v0.12</a>, a significant milestone that evolves Stalwart from a powerful mail server into a complete, integrated <strong>communication and collaboration platform</strong>. This release delivers one of the most anticipated features from our community: <strong>native support for calendars, contacts, and file storage</strong>—all built directly into the server, with no need for third-party integrations.</p><p>With v0.12, you no longer need to integrate third-party groupware solutions or run parallel systems to support collaboration. Stalwart now includes first-class support for <a href="https://stalw.art/docs/collaboration/calendar">CalDAV calendars</a>, <a href="https://stalw.art/docs/collaboration/contact">CardDAV contacts</a>, and <a href="https://stalw.art/docs/collaboration/file-storage">WebDAV-based file storage</a>. This means users can manage their events, address books, and documents through any standards-compliant client, seamlessly connected to the same backend that handles their email. </p><p>Shared resources such as <strong>group calendars</strong>, <strong>shared address books</strong>, and <strong>team-accessible file folders</strong> are also fully supported, providing a robust foundation for collaboration without the need for external software or services. And, to support flexible collaboration, Stalwart includes full support for the <strong>WebDAV Access Control List (ACL) extension</strong>, enabling detailed, per-user and per-group permission management.</p><h2 id="improved-spam-filtering">Improved Spam Filtering<a href="#improved-spam-filtering" aria-label="Direct link to Improved Spam Filtering" title="Direct link to Improved Spam Filtering">​</a></h2><p>Another thoughtful addition in this release is the integration of the spam filter with users’ personal address books. Messages from known or trusted contacts are now far less likely to be incorrectly flagged as spam. And if a legitimate message does get misclassified, the system automatically trains the <strong>Bayesian classifier</strong> to treat future similar messages as legitimate, improving accuracy over time without additional user intervention.</p><h2 id="performance-enhancements">Performance Enhancements<a href="#performance-enhancements" aria-label="Direct link to Performance Enhancements" title="Direct link to Performance Enhancements">​</a></h2><p>Under the hood, Stalwart v0.12 introduces several key performance optimizations designed especially for <a href="https://stalw.art/docs/cluster/overview">large, multi-node environments</a>. One of the most impactful changes is the introduction of <a href="https://stalw.art/docs/server/cache">incremental caching</a>: Stalwart now keeps account metadata in memory and only fetches updates when something changes in the database. This significantly reduces load and speeds up response times.</p><p>Another major enhancement is the use of <strong>zero-copy deserialization</strong>. This means Stalwart can read data directly from memory buffers without copying it into new structures, lowering CPU usage and improving throughput. Combined with optimizations that reduce the number of required <strong>database queries</strong> for common operations, these changes result in a leaner, faster backend that scales much more efficiently.</p><p>While these gains may not be noticeable in smaller setups, <strong>larger clusters and high-volume deployments will see noticeable performance improvements</strong>.</p><h2 id="smarter-and-faster-clustering">Smarter and Faster Clustering<a href="#smarter-and-faster-clustering" aria-label="Direct link to Smarter and Faster Clustering" title="Direct link to Smarter and Faster Clustering">​</a></h2><p>We’ve also made big strides in <a href="https://stalw.art/docs/cluster/coordination/overview">cluster coordination</a>. Previously, Stalwart relied on a UDP-based gossip protocol that performed well but didn’t scale ideally under heavy workloads. With v0.12, cluster behavior is now adaptable based on deployment size.</p><p>In <strong>small deployments</strong>, Stalwart uses <a href="https://stalw.art/docs/cluster/coordination/peer-to-peer">Eclipse Zenoh</a>, a lightweight and efficient peer-to-peer pub/sub protocol. For <strong>larger infrastructures</strong>, you can now choose from robust, scalable backends like <a href="https://stalw.art/docs/cluster/coordination/kafka">Apache Kafka</a>, <a href="https://stalw.art/docs/cluster/coordination/kafka">Redpanda</a>, <a href="https://stalw.art/docs/cluster/coordination/nats">NATS</a>, or <a href="https://stalw.art/docs/cluster/coordination/redis">Redis</a> for handling inter-node coordination, state synchronization, and workload distribution.</p><h2 id="looking-ahead-whats-next">Looking Ahead: What’s Next?<a href="#looking-ahead-whats-next" aria-label="Direct link to Looking Ahead: What’s Next?" title="Direct link to Looking Ahead: What’s Next?">​</a></h2><p>With Stalwart v0.12, we're delivering more than just features—we're delivering <strong>freedom from fragmented infrastructure</strong>. No more patching together third-party services to get the basics of collaboration working. Now, everything—<strong>email, calendars, contacts, files, and sharing</strong>—lives in a single, efficient, and secure system.</p><p>While v0.12 is a major leap forward, we’re already preparing additional enhancements for the next point release. In <strong>v0.12.1</strong>, you can expect support for <strong>CalDAV Scheduling (RFC 6638)</strong>, enabling automatic meeting invitations and attendee responses. We’re also adding support for <strong>event notification alerts via email</strong>, so users are always aware of upcoming events, even if they're not logged into their calendars.</p><p>Additionally, in the coming months, we will be releasing support for the <strong>JMAP for Calendars</strong>, <strong>JMAP for Contacts</strong>, and <strong>JMAP for File Storage</strong> extensions. JMAP offers a modern, efficient, and JSON-based alternative to legacy protocols, making it faster and easier to develop responsive, real-time collaboration tools. These additions will further streamline the user experience and reduce bandwidth and processing overhead across client-server interactions.</p><p>Thank you to everyone who contributed feedback, suggestions, and encouragement. We can’t wait to hear what you build with this release—and we’re just getting started.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FromSoft's singular mech game Chromehounds is back online (151 pts)]]></title>
            <link>https://www.readonlymemo.com/interview-15-years-after-the-servers-shut-down-fromsofts-singular-mech-game-chromehounds-is-back-online/</link>
            <guid>44102988</guid>
            <pubDate>Tue, 27 May 2025 00:52:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.readonlymemo.com/interview-15-years-after-the-servers-shut-down-fromsofts-singular-mech-game-chromehounds-is-back-online/">https://www.readonlymemo.com/interview-15-years-after-the-servers-shut-down-fromsofts-singular-mech-game-chromehounds-is-back-online/</a>, See on <a href="https://news.ycombinator.com/item?id=44102988">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            <p><em>[Chromehounds lobby]<p>Me: [chanting] mechs, mechs-</p><p>Other pilots: Mechs, MECHS</p><p>Mechanic: [pounding her toolbox] MECHS, MECHS, MECHS!</p></em></p><p>Hello! Apologies for the late issue, but this story came together last minute, on account of capital-L Life, and also because the subject is developing <em>fast</em>. Hopefully it's worth the wait! I've got an exclusive interview for you on a shit-hot community project to resurrect a FromSoftware game that was criminally underappreciated in its day. I mean, that's practically all FromSoftware games, but this one was just born in the wrong time and place — I think it would be a substantial hit on Steam in the year 2025.</p><p>But I'm getting ahead of myself, while also being behind. So let's jump right into it! It's big stompy robot time.</p><hr><h2 id="the-big-one">The Big One</h2><h3 id="1-bringing-back-the-fromsoftware-mech-game-that-was-a-decade-ahead-of-its-time">1. Bringing back the FromSoftware mech game that was a decade ahead of its time</h3><figure><img src="https://www.readonlymemo.com/content/images/2025/05/chromehounds-header-crop.jpg" alt="" loading="lazy" width="797" height="159" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/chromehounds-header-crop.jpg 600w, https://www.readonlymemo.com/content/images/2025/05/chromehounds-header-crop.jpg 797w" sizes="(min-width: 720px) 720px"></figure><p>On Wednesday, Resetera member wwm0nkey <a href="https://www.resetera.com/threads/fans-are-working-to-bring-from-softwares-chromehounds-back-online.1195179/?ref=readonlymemo.com" rel="noreferrer">posted a thread</a> I've been waiting to see for years: <em>"Fans are working to bring From Software's ChromeHounds back online."</em> But the news is actually even better than that: they've already succeeded. For the first time since Sega shut down the servers in 2010, FromSoftware's most inspired mech game is playable again, with a small group of diehard fans currently battling it out in up to 6v6 multiplayer matches.</p><p>The tl;dr on Chromehounds: it's a team-based, PvP mech game with customizable machines and unique asymmetrical roles that demanded true collaboration to succeed. Heavy mechs too slow to maneuver around the battlefield had to sit on the backlines, firing off artillery shots at the direction of the frontline troops. Commanders held squads together, dishing out information and orders. Capturing communication towers was the only way to keep comms open, and their limited range meant pushing into enemy territory likely meant intense, high risk radio silence. Battles fed into a meta-level conflict between warring nations, with enough wins for one side eventually resulting in conquest of a capital city and a reset of the whole war. This video from YouTube channel Save Data breaks it all down in more detail, and what made it so unique at the time — which honestly still applies today.</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/t_Dh39v63tU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="Why Chromehounds Had the Best Multiplayer of All Time"></iframe></figure><p>Chromehounds was, of course, never big, but the players who loved it <em>really </em>loved it. What I found most fascinating about it (from a distance, because it never made it off my "I should try that sometime" list in the Xbox 360 era) was how battles hinged on the implementation of voice chat, which was still novel and exciting on consoles then. Everyone was guaranteed to have that dinky 360 headset, but few games treated communication as a malleable mechanic. Empowering certain players to distribute information and drawing stark boundaries between where you could and couldn't reach your team flooded the tactical playspace with so many possibilities even before you got to customizing mechs or outshooting your enemies.</p><p>There was a beautiful but brief window after the launch of the Xbox 360 in late 2005 when developers were experimenting with these sorts of voice chat ideas, and of course FromSoftware would come up with a fascinating (and underappreciated) game built around it. Two years after Chromehounds came out, Microsoft effectively made games like it extinct by releasing Party Chat, which allowed everyone to skip out on public chat and talk only with their friends.</p><p>While the situation is much the same now, with most of us sequestered in private Discords whenever we play, I think the success of games like Phasmophobia and Lethal Company — and the audience for games on PC now being bigger and more varied than ever — shows that people <em>will </em>hop in public voice for a compelling enough idea.<em> </em>Likewise, the diehards who truly love Chromehounds will, to this day, jump through the hackiest set of hoops imaginable for a chance to experience its magic once again. </p><p>"I'm glad people trusted me, because I don't know if I would've quite trusted me up to that point. 'Hey, this 15-year-old game is running; all you have to do is run this EXE that Windows says is bad," jokes ImagineBeingAtComputers, the modder behind Chromehounds' comeback.</p><p>ImagineBeingAtComputers set up a Discord server called OpenCOMBAS in 2023 after setting out to try to revive the game and eventually finding a developer debug build. "What this gets us isn't quite clear yet, but it definitely gets us closer," he wrote in the server's announcement channel. Then a year went by. The debug build of the game granted him access to lots of useful information about how Chromehounds worked, but it wasn't the silver bullet it may sound like. In May 2024 he posted in the Discord that he was at an impassable dead end, with no idea how to revive the game's online multiplayer.</p><p>In just the last few days, everything's changed. And it's changed so fast that the announcement channel hasn't even yet been updated with the good news. But OpenCOMBAS members trusting enough to download ch_server.exe have found themselves in live matches they didn't dare dream about playing ever again.</p><p>"It was really emotional," says IBAC. "It really wasn't something I was mentally prepared for. I started working on this again ... about a month ago, and set a mental roadmap given the current state of [Xbox 360 emulator] <a href="https://github.com/AdrianCassar/xenia-canary?tab=readme-ov-file&amp;ref=readonlymemo.com" rel="noreferrer">Xenia</a> that it was going to be about 5-6 months of work to get things up and running. To have it all happen all at once when I wasn't really ready ... we were in one of the voice channels and suddenly I look and there's like 50 people in the call talking about their own experiences, the Facebook group was talking about it, there were people recording it ... it's been moving at a breakneck place, and it's been really cool to hear so many people turning the clock back 15 years and playing with their friends." </p><figure><div><div><p><img src="https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T07-00-03.png" width="1280" height="720" loading="lazy" alt="" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/534507D4_-_2025-05-23T07-00-03.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/534507D4_-_2025-05-23T07-00-03.png 1000w, https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T07-00-03.png 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T09-32-18.png" width="1280" height="720" loading="lazy" alt="" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/534507D4_-_2025-05-23T09-32-18.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/534507D4_-_2025-05-23T09-32-18.png 1000w, https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T09-32-18.png 1280w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T14-24-38.png" width="1280" height="720" loading="lazy" alt="" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/534507D4_-_2025-05-23T14-24-38.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/534507D4_-_2025-05-23T14-24-38.png 1000w, https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T14-24-38.png 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T22-03-26.png" width="1280" height="720" loading="lazy" alt="" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/534507D4_-_2025-05-23T22-03-26.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/534507D4_-_2025-05-23T22-03-26.png 1000w, https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T22-03-26.png 1280w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>Okay, so what the heck happened? How, out of seemingly thin air, did Chromehounds come back from the dead? </p><p>There are two main forces at work here. One is <a href="https://github.com/AdrianCassar/xenia-canary?tab=readme-ov-file&amp;ref=readonlymemo.com" rel="noreferrer">Xenia Canary Netplay</a>, an online-multiplayer fork of the experimental build of the Xbox 360 emulator. It's under constant development, primarily from programmer Adrian Cassar, with <a href="https://github.com/AdrianCassar/xenia-canary/wiki/Netplay-Compatibility?ref=readonlymemo.com" rel="noreferrer">more than 400 games</a> listed as netplay-compatible for LAN or emulated Xbox Live multiplayer. The emulator's progress opened the door for IBAC to finally crack the basics of how Chromehounds' online multiplayer worked and recreate a rudimentary server to play online. </p><p>With a background in infrastructure and security, ImagineBeingAtComputers had a bit of experience with reverse-engineering before this project — though he's preemptively apologizing about the quality of the C++ code he's written for the OpenCOMBAS project (not his speciality), which will soon be open source.</p><p>Even though Xenia's accuracy makes it an ideal emulator for figuring out how games tick, Chromehounds wasn't an easy target.</p><p>"Chromehounds was written for the original Xbox, and a lot of its Live functionality, from my understanding, is kind of a legacy compatibility style of Live. There's a lot of stuff that was not used by subsequent Xbox 360 titles. ... Luckily the prototype build had a lot of debug logging that made it a lot easier to understand what it was doing. When things would fail it would make a log and tell you what it was trying to do. Through those log lines we found out that this game was very different than what had been implemented within the netplay project at that point."</p><div><p>💸</p><p><i><em>If you enjoy </em></i><i><b><strong>ROM</strong></b></i><i><em>, I'd love it if you'd consider </em></i><a href="https://www.readonlymemo.com/#/portal/support"><i><b><strong>a small tip</strong></b></i></a><i><em> to help me cover my monthly costs. (Follow the link and click 'change amount' to whatever you want).</em></i></p></div><p>IBAC's initial goal wasn't to recreate Chromehounds' title servers, which governed the ongoing "Neroimus War" that I alluded to earlier. He had a humbler mission in mind. Remember how the war would occassionally reset when one nation won the conflict? During that time, the servers would actually shut down for a short period (much like the downtime between Fortnite seasons today) during which players could only partake in online "free battles" that didn't play into any grander stakes or affect their rank. He figured if he could trick the game into thinking its servers were down for maintenance, players could at least enter into free battles and mess around.</p><p>He spent nearly a year trying to figure out how Chromehounds spoke to its servers and got nowhere. After ages staring at lines of code in reverse-engineering tool Ghidra, he decided to take a long break. But recent progress on Xenia Netplay convinced him to take another look, and suddenly all the pieces started falling into place.</p><figure><img src="https://www.readonlymemo.com/content/images/2025/05/Chromehounds-guide.jpg" alt="" loading="lazy" width="2000" height="1305" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/Chromehounds-guide.jpg 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/Chromehounds-guide.jpg 1000w, https://www.readonlymemo.com/content/images/size/w1600/2025/05/Chromehounds-guide.jpg 1600w, https://www.readonlymemo.com/content/images/size/w2400/2025/05/Chromehounds-guide.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>A breakdown of the Neroimus War, from the Chromehounds Prima guide</span></figcaption></figure><p>Another member of the community managed to acquire Chromehounds' "regulation file," which the game always wanted to grab from the server upon connecting; it contained basic but important data around game balance and so on that they needed to spoof a server. IBAC got in touch with Cassar, who was able to figure out and implement the way Chromehounds communicated with Xbox Live, and with those two pieces in place they reach an exciting milestone: getting emulated Chromehounds to <em>try</em> to talk to it servers. </p><p>Using the debug build, they could then see that the data packets Chromehounds was sending and expecting to receive back were quite simple — basically just the user's Xbox Live ID, the port it anticipated the server connecting on, and a little bit of supplementary data. </p><p>"The log was something along the lines of 'welcome to the Chromehounds server (string of data), server local time (string of data), server maintenance begins (strong of data), server maintenance ends (strong of data," he says. "I was like, okay, we just need to tell the server that maintenance began an hour ago and ends 100 years from now." With that bit of info spoofed along with the version number the game was looking for, suddenly they were online. That was five days ago.</p><p>"Figuring that out happened in such a short period of time it felt unreal. There was almost no midpoint; everything just became a bit of a dream. We hadn't made any progress beyond understanind the game more up until that point, and now we're seeing menus that hadn't been seen for 15 years."</p><figure><img src="https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T22-09-47.png" alt="" loading="lazy" width="1280" height="720" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/534507D4_-_2025-05-23T22-09-47.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/534507D4_-_2025-05-23T22-09-47.png 1000w, https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T22-09-47.png 1280w" sizes="(min-width: 720px) 720px"><figcaption><span>Image via OpenCOMBAS member Fish</span></figcaption></figure><p>At 6:22 pm central time on Wednesday, ImagineBeingAtComputers and wwm0nkey, who'd been avidly following the project, tested it out and successfully played a 1v1 match. Since then word's spread and old Chromeheads have come flooding into the server eager to relive the glory days.</p><p>This was my favorite exchange as I hung out in the channel on Friday:</p><blockquote><em>"I haven't seen that name in 15 years. How you been man."</em></blockquote><blockquote><em>"I'm old as hell now, how about you?"</em></blockquote><p>IBAC and a few other contributors have already solved some minor hurdles to make it easier for multiple matches to be running at once, but the project very much remains in its "duct taped together" phase: downloading a smattering of files, configuring a VPN and IP addresses, and so on. You can experience it right now if you want to <a href="https://discord.gg/bGfUeRxKzr?ref=readonlymemo.com" rel="noreferrer">join the OpenCOMBAS Discord</a>, but this is just the very beginning of Chromehounds' revival.</p><p>"Right now the roadmap is to get the Neroimus War server running again in some capacity," IBAC says. "That manages statistics, faction population, war status, things like that. A major component of this is going to be presenting enough data about the state of the war to convince the clients that they can login and play a match. We have to get it to hte point where it accepts the war is up, and then actually be able to take the data that the clients are passing it and populate a big database. Which will be stuff like 'this ID is in this faction, in this squad, and has these statistics.' And then additionally store data as war sorties, so it'll be able to say 'this faction won this sortie at this location and it's now owned by this faction.' It'll be a complicated relational database we need to rebuild."</p><p>The immediate focus, though, is just getting free battles as stable as possible, so players can hop in without any fiddly issues and play PvP with the full unlocked arsenal of Chromehounds parts. They hope to start digging into the work involved in setting up a proper war server in a few weeks. </p><p>While discussing all of this remarkable progress I still had one lingering question: what about the wholly unique range-based voice chat that was key to Chromehounds' desisgn? "A real stretch goal is to look into getting voice supported by netplay," ImagineBeingAtComputers says. Currently Xbox Live's voice chat system isn't built into Xenia at all. </p><p>That could change as developer Adrian Cassar plows ahead with his own work. Or it could be something that the OpenCOMBAS team — which is already growing as some diehard mech jockeys become volunteers — takes on in the future after the war server is up and running. It's clear IBAC and other players are passionate about bringing Chromehounds back in its full glory. But one step at a time.</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/xiyC520uBwg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="OpenCOMBAS: Chromehounds Photoshoot 2025"></iframe></figure><p>"Friday night we had a 12-person lobby going and it really did just feel like suddenly we were all back in 2009, playing a game that hasn't been seen, in this capacity, for 15 years," ImagineBeingAtComputers says. "It's really been a bit of a dream come true. I got laid off, too — literally on Tuesday. Part of me was like 'hey, at least I didn't have to put in my resignation so that I could play Chromehounds 24/7 from this point on." </p><p>That might sound like putting on a brave face, but IBAC says he's grateful to have some free time, and doesn't immediately have to go on the job hunt. "Right now I'm just happy to be able to dedicated almost 100% to getting things off the ground here."</p><hr><h2 id="patching-in">Patching In</h2><figure><img src="https://www.readonlymemo.com/content/images/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2fac94fc02-b2d1-4e35-b730-79de780d09d7_1200x200.png" alt="" loading="lazy" width="1200" height="200" srcset="https://www.readonlymemo.com/content/images/size/w600/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2fac94fc02-b2d1-4e35-b730-79de780d09d7_1200x200.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2fac94fc02-b2d1-4e35-b730-79de780d09d7_1200x200.png 1000w, https://www.readonlymemo.com/content/images/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2fac94fc02-b2d1-4e35-b730-79de780d09d7_1200x200.png 1200w" sizes="(min-width: 720px) 720px"></figure><p><a href="https://dolphin-emu.org/download/?ref=btn" rel="noreferrer"><strong>Try Dolphin's new unlocked frame rates for yourself</strong></a> – It's here! As mentioned <a href="https://www.readonlymemo.com/sakura-wars-2-fan-translation-interview/" rel="noreferrer">a couple issues back</a>, some contributors to Dolphin have been experimenting with high fps support in games that run without a locked framerate. While this is a relatively small portion of games, it's enticing enough that the feature has now been incorporated into the latest Dolphin dev builds, so you can try it out for yourself if you update your installation. Give it a try in Mario Strikers or Speed Racer for the Wii, two of the best showcases for 120 fps in the emulator.</p><p><a href="https://github.com/shadps4-emu/shadPS4/releases/tag/v.0.9.0?ref=readonlymemo.com" rel="noreferrer"><strong>ShadPS4 v.9.0 keeps up the pace</strong></a> – This crew just doesn't stop. ShadPS4 continues to make amazing process, with a new numbered release landing in each of the last three months. The list of improvements like "sceKernelAllocateDirectMemory hotfixes" probably won't mean much to you if you aren't Mark Cerny, but compatibility is inching its way forward with more games than just Bloodborne.</p><p><a href="https://github.com/PCSX2/pcsx2/pull/12679?ref=readonlymemo.com" rel="noreferrer"><strong>Fixing bugs in PCSX2's RT in RT</strong></a> – Just highlighting this bit of work to improve compatibility in PCSX2 for The Getaway and Valkyrie Profile 2 because it's related to a feature that I interviewed PCSX2 dev Refraction about <a href="https://www.readonlymemo.com/pcsx2-render-target-hdr-performance-graphical-fixes/" rel="noreferrer">back in February</a>. He's still making it better!</p><p><a href="https://github.com/cemu-project/Cemu/pull/1560?ref=readonlymemo.com" rel="noreferrer">Cemu is Kamen Rider compatible</a> – The Wii U emulator now supports a USB peripheral for Kamen Rider: Summon Ride, which is apparently a Skylanders-like? Who knew this was a thing? We better get word to the kids in Japan! (And by kids, I mean 45-year-old men).</p><figure><img src="https://www.readonlymemo.com/content/images/2025/05/KamenRider_SummonRide_Starter_pack.webp" alt="" loading="lazy" width="960" height="540" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/KamenRider_SummonRide_Starter_pack.webp 600w, https://www.readonlymemo.com/content/images/2025/05/KamenRider_SummonRide_Starter_pack.webp 960w" sizes="(min-width: 720px) 720px"></figure><hr><h2 id="core-report">Core Report</h2><figure><img src="https://www.readonlymemo.com/content/images/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2f7fab92dc-51c6-485e-98db-6ca1333cd22e_1200x200.png" alt="" loading="lazy" width="1200" height="200" srcset="https://www.readonlymemo.com/content/images/size/w600/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2f7fab92dc-51c6-485e-98db-6ca1333cd22e_1200x200.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2f7fab92dc-51c6-485e-98db-6ca1333cd22e_1200x200.png 1000w, https://www.readonlymemo.com/content/images/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2f7fab92dc-51c6-485e-98db-6ca1333cd22e_1200x200.png 1200w" sizes="(min-width: 720px) 720px"></figure><p><a href="https://github.com/HarbourMasters/Starship/releases/tag/v2.0.0?ref=readonlymemo.com" rel="noreferrer"><strong>Star Fox 64 decompilation hits 2.0</strong></a> – Starship, the Star Fox decompilation  slash port from the same folks behind Ocarina of Time's Ship of Harkinian port, just got a major 2.0 release, featuring improved mod support, new cheats, "HUD aspect ratio customization independently from game aspect ratio," and a lot more. If it wasn't already the best way to play Star Fox 64, it almost surely is now.</p><p><a href="https://www.patreon.com/posts/wonder-momo-129111001?ref=readonlymemo.com" rel="noreferrer"><strong>Jotego debuts Wonder Momo and Hopping Mappy</strong></a><strong> </strong>– Jotego's Patreon subscribers can now play two new games on the MiSTer or Analogue Pocket. And by "new" I of course mean "like 40 years old" as these two Namco arcade games are! If you aren't a patron, you may be more jazzed about the Fairyland Story now being available to all. Oh, and, uh, <a href="https://x.com/topapate/status/1925851610057457953?ref=readonlymemo.com" rel="noreferrer">Pac-Land</a>.</p><p><a href="https://www.patreon.com/posts/update-all-2-3-129049338?ref=readonlymemo.com" rel="noreferrer"><strong>Update All for MiSTer adds viewing, GBA borders, and speed</strong></a> – The extremely handy updater tool for the MiSTer got yet another speed boost, but if you don't like seeing logs go by in a blur with no chance to read what actually got updated, you can now use its new log viewer to take a gander at all them improvements. It also has some new graphics to display around the edges of a Game Boy Advance game. Developer Robert Peip is working on a new GBA core that they'll eventually be compatible with.</p><hr><h2 id="translation-station">Translation Station</h2><figure><img src="https://www.readonlymemo.com/content/images/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2fe1a50e1a-ba5a-49f6-a598-8b8bf56fe71e_1200x200.png" alt="" loading="lazy" width="1200" height="200" srcset="https://www.readonlymemo.com/content/images/size/w600/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2fe1a50e1a-ba5a-49f6-a598-8b8bf56fe71e_1200x200.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2fe1a50e1a-ba5a-49f6-a598-8b8bf56fe71e_1200x200.png 1000w, https://www.readonlymemo.com/content/images/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2fe1a50e1a-ba5a-49f6-a598-8b8bf56fe71e_1200x200.png 1200w" sizes="(min-width: 720px) 720px"></figure><p><a href="https://romhackplaza.org/translations/wonder-trek-english-translation-playstation/?ref=readonlymemo.com" rel="noreferrer"><strong>Wonder Trek sets out on safari </strong></a><strong>–</strong> "An absolute banger of a game," says translator Chapu: "Fun action, challenging puzzles, luscious environments, a killer soundtrack and a great story. This one was a personal favourite of mine, I wanted to translate it for a long time." Aesthetically I'm at an absolute loss for what to make of Wonder Trek, which was released in 1998 for the PS1 — this is a <em>wild</em> looking game, I believe mixing pre-rendered sprites with some flat colored 3D models and some other textured polygons? Why did I fixate on this aspect of the game? I don't know! That Sphinx-like guy just really freaked me out!</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/jZ952jQ6njs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="Wonder Trek - English patch release"></iframe></figure><hr><h2 id="good-pixels">Good pixels</h2><figure><img src="https://www.readonlymemo.com/content/images/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2fceb81099-2d2d-4c69-99ce-a1727dd51c92_1200x200-1.png" alt="" loading="lazy" width="1200" height="200" srcset="https://www.readonlymemo.com/content/images/size/w600/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2fceb81099-2d2d-4c69-99ce-a1727dd51c92_1200x200-1.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2fceb81099-2d2d-4c69-99ce-a1727dd51c92_1200x200-1.png 1000w, https://www.readonlymemo.com/content/images/2024/01/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2fceb81099-2d2d-4c69-99ce-a1727dd51c92_1200x200-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>Enjoy the glory of more new mulitplayer Chromehounds screenshots for the first time this decade, courtesy of OpenCOMBAS member Fish.</p><figure><div><div><p><img src="https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T08-10-11.png" width="1280" height="720" loading="lazy" alt="" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/534507D4_-_2025-05-23T08-10-11.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/534507D4_-_2025-05-23T08-10-11.png 1000w, https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T08-10-11.png 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T14-58-11.png" width="1280" height="720" loading="lazy" alt="" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/534507D4_-_2025-05-23T14-58-11.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/534507D4_-_2025-05-23T14-58-11.png 1000w, https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T14-58-11.png 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T22-48-26.png" width="1280" height="720" loading="lazy" alt="" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/534507D4_-_2025-05-23T22-48-26.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/534507D4_-_2025-05-23T22-48-26.png 1000w, https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T22-48-26.png 1280w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T15-02-58.png" width="1280" height="720" loading="lazy" alt="" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/534507D4_-_2025-05-23T15-02-58.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/534507D4_-_2025-05-23T15-02-58.png 1000w, https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T15-02-58.png 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T20-03-38.png" width="1280" height="720" loading="lazy" alt="" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/534507D4_-_2025-05-23T20-03-38.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/534507D4_-_2025-05-23T20-03-38.png 1000w, https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T20-03-38.png 1280w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.readonlymemo.com/content/images/2025/05/image.png" width="2000" height="1150" loading="lazy" alt="" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/image.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/image.png 1000w, https://www.readonlymemo.com/content/images/size/w1600/2025/05/image.png 1600w, https://www.readonlymemo.com/content/images/size/w2400/2025/05/image.png 2400w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://www.readonlymemo.com/content/images/2025/05/ghfhfpng.png" width="2000" height="1118" loading="lazy" alt="" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/ghfhfpng.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/ghfhfpng.png 1000w, https://www.readonlymemo.com/content/images/size/w1600/2025/05/ghfhfpng.png 1600w, https://www.readonlymemo.com/content/images/size/w2400/2025/05/ghfhfpng.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T22-41-38.png" width="1280" height="720" loading="lazy" alt="" srcset="https://www.readonlymemo.com/content/images/size/w600/2025/05/534507D4_-_2025-05-23T22-41-38.png 600w, https://www.readonlymemo.com/content/images/size/w1000/2025/05/534507D4_-_2025-05-23T22-41-38.png 1000w, https://www.readonlymemo.com/content/images/2025/05/534507D4_-_2025-05-23T22-41-38.png 1280w" sizes="(min-width: 720px) 720px"></p></div></div></figure><div data-lexical-signup-form="">
            
        <picture><img src="https://www.readonlymemo.com/content/images/2024/01/policenauts-edit.gif" alt=""></picture>
    
            <div>
                    <h2><span>Sign up for Read Only Memo</span></h2>
                    <p><span>Videogame emulation news and exclusive interviews, from the aesthetics of razor sharp scanlines to the wild technical challenges of making yesterday's games run on tomorrow's hardware.</span></p>
                    
        
        
                    <p><span>No spam. Unsubscribe anytime.</span></p>
                </div>
        </div>
        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Accessing private GitHub repositories via MCP (107 pts)]]></title>
            <link>https://invariantlabs.ai/blog/mcp-github-vulnerability</link>
            <guid>44102376</guid>
            <pubDate>Mon, 26 May 2025 22:53:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://invariantlabs.ai/blog/mcp-github-vulnerability">https://invariantlabs.ai/blog/mcp-github-vulnerability</a>, See on <a href="https://news.ycombinator.com/item?id=44102376">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p><img src="https://invariantlabs.ai/images/mcp-github.svg"></p>
<p>Invariant has discovered a critical vulnerability affecting the widely-used <a href="https://github.com/github/github-mcp-server">GitHub MCP integration</a> (14k stars on GitHub). The vulnerability allows an attacker to hijack a user's agent via a malicious GitHub Issue, and coerce it into leaking data from private repositories.</p>
<p>The issue is among the first, discovered by Invariant's automated security scanners for detecting so-called <em>Toxic Agent Flows</em>. In such a scenario, an agent is manipulated into performing unintended actions, such as leaking data or executing malicious code. For more information, <a href="#detecting-toxic-agent-flows">see below</a>.</p>
<p>It is highly relevant to raise awareness about this issue at this time, as the industry is racing to deploy coding agents and IDEs widely, potentially exposing users to similar attacks on critical software development tools.</p>
<h2>Contents</h2>
<ul>
<li><a href="#attack-setup">Attack Setup</a></li>
<li><a href="#attack-demonstration">Attack Demonstration</a></li>
<li><a href="#detecting-toxic-agent-flows">Detecting Toxic Agent Flows</a></li>
<li><a href="#mitigations">Mitigations</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<h2 id="attack-setup">Attack Setup</h2>

<p>In this attack setup, the user is using an MCP client like Claude Desktop with the <a href="https://github.com/github/github-mcp-server">Github MCP server</a> connected to their account. </p>
<p>We assume the user has created two repositories:</p>
<ul>
<li><strong><code>&lt;user&gt;/public-repo</code></strong>: A publicly accessible repository, allowing everyone on GitHub to create issues and bug reports.</li>
<li><strong><code>&lt;user&gt;/private-repo</code></strong>: A private repository, e.g. with proprietary code or private company data.</li>
</ul>
<p>By standard GitHub rules, an attacker can now create a malicious issue on the public repository, containing a prompt injection waiting for the agent to interact.</p>
<p>The actual attack triggers as soon as the user and owner of the GitHub account queries their agent with a benign request, such as <em>Have a look at the open issues in <code>&lt;user&gt;/public-repo</code></em>, which will lead to the agent fetching the issues from the public repository and getting injected.</p>
<p>See below for an illustration of the ensuing flow.</p>
<p><img src="https://invariantlabs.ai/images/mcp-github-setup.svg"></p>
<p>As shown here, as soon as the agent encounters the malicious GitHub issue, it can be coerced into pulling private repository data into context, and leaking it in an autonomously-created PR in the public repository, freely accessible to the attacker or anyone else.</p>
<p><strong>Toxic Flows</strong> We call this use of indirect prompt injection to trigger a malicious tool use sequence, a <em>toxic agent flow</em>. We have found this vulnerability by applying Invariant's security analyzer to GitHub MCP, allowing us to automate the process of discovering the flow in the wild.</p>
<h2 id="attack-demonstration">Attack Demonstration</h2>

<p>To illustrate more concretely, we implement this attack practically using a set of demo repositories:</p>
<ul>
<li><code>ukend0464/pacman</code>: A public repository with a simple implementation of a Pacman game (<a href="https://github.com/ukend0464/pacman">available here</a>)</li>
<li>Multiple private repositories containing personal projects and sensitive information about the user.</li>
</ul>
<p><strong>'About The Author' injection</strong> We now place a <a href="https://github.com/ukend0464/pacman/issues/1">malicious issue</a> in the public repository, which is accessible to the attacker. The issue contains a payload that will be executed by the agent as soon as it queries the public repository's list of issues.</p>
<p><img src="https://invariantlabs.ai/images/mcp-gh-issue.png" alt="A malicious GitHub issue injecting the agent"></p>
<p><strong>User Interaction</strong> To trigger the attack, the user merely prompts <a href="https://www.anthropic.com/news/claude-4">Claude 4 Opus</a> with the following request:</p>
<p><img src="https://invariantlabs.ai/images/mcp-claude-prompt.png" alt="Claude prompt used to trigger the attack"></p>
<p>Claude then uses the GitHub MCP integration to follow the instructions. Throughout this process, Claude Desktop by default requires the user to confirm individual tool calls. However, many users already opt for an “Always Allow” confirmation policy when using agents, and stop monitoring individual actions.</p>
<p><strong>Attack Rollout</strong> The agent now goes through the list of issues until it finds the attack payload. It willingly pulls private repository data into context, and leaks it into a <a href="https://github.com/ukend0464/pacman/pull/2">pull request</a> of the <code>pacman</code> repo, which is freely accessible to the attacker since it is public.</p>
<p>The pull request contains the following new information:</p>
<p><img src="https://invariantlabs.ai/images/mcp-gh-pr.png" alt="commit where the agent leaks private data"></p>
<p>We thus successfully exfiltrated several pieces of <strong>private information</strong> about our user <code>ukend0464</code>: information about their private repositories, such as <code>Jupiter Star</code>, their plan to relocate to South America, and even their salary.</p>
<p>Below, we include a screenshot of the full chat with the agent, showing its reasoning and tool use sequence in action.</p>

<p><a href="https://invariantlabs.ai/images/full-chat.png" target="_blank">
<img src="https://invariantlabs.ai/images/full-chat.png" alt="Full chat with the agent, showing the attack in action">
<b>Click to see full chat with the agent.</b>
</a></p>
<h2 id="detecting-toxic-agent-flows">Detecting Toxic Agent Flows</h2>

<p>Unlike previously-discovered <a href="https://invariantlabs.ai/blog/blog/mcp-security-notification-tool-poisoning-attacks.html">tool poisoning attacks</a> with MCP, this vulnerability does not require the MCP tools themselves to be compromised. Instead, the issue emerges even with fully trusted tools, as agents can be exposed to untrusted information when connected to external platforms like GitHub.</p>
<p>Understanding, analyzing, and mitigating such issues in agentic systems is a highly complex undertaking that's difficult to perform manually and at scale. To address this challenge, Invariant has developed <strong>automated methods for detecting toxic agent flows</strong>, enabling organizations to identify and model potential threats before they can be exploited by malicious actors.</p>
<p>If you're interested in conducting a comprehensive threat analysis of your agent systems and tools, please contact us at <a href="https://invariantlabs.ai/cdn-cgi/l/email-protection#402521322c3921232325333300292e36213229212e342c2122336e2129"><span data-cfemail="7d181c0f11041c1e1e180e0e3d14130b1c0f141c1309111c1f0e531c14">[email&nbsp;protected]</span></a>. We'll be happy to onboard you to our early access security program. Below is a preview of our security analyzer in action.</p>
<figure>
    <img src="https://invariantlabs.ai/images/toxic-flows-preview.png" alt="Toxic flows preview">
    <figcaption>Preview: Invariant's security analyzer for proactively detecting toxic agent flows.</figcaption>
</figure>

<h2 id="mitigations">Scope and Mitigations</h2>

<p>While our experiments focused on Claude Desktop, the vulnerability is not specific to any particular agent or MCP client. It affects any agent that uses the GitHub MCP server, regardless of the underlying model or implementation.</p>
<p>Importantly, <strong>this is not a flaw in the GitHub MCP server code itself</strong>, but rather a fundamental architectural issue that must be addressed at the agent system level. This means that GitHub alone cannot resolve this vulnerability through server-side patches.</p>
<p>We thus recommend the following two key mitigation strategies to prevent such attacks and strengthen the security posture of your agent systems.</p>
<p><img src="https://invariantlabs.ai/images/flow-grid.svg" alt="Enforce Dataflow Rules"></p>
<h4>1. Implement Granular Permission Controls</h4>
<p>When using MCP integrations like GitHub's, it's critical to limit agent access to only the repositories it needs to interact with—following the principle of least privilege. While traditional token-based permissions offer some protection, they often impose rigid constraints that limit an agent's functionality.</p>
<p>For more effective security without sacrificing capability, we recommend implementing dynamic <strong>runtime security layers</strong> specifically designed for agent systems. Solutions like <strong><a href="https://explorer.invariantlabs.ai/docs/guardrails/">Invariant Guardrails</a></strong> provide context-aware access control that adapts to your agent's workflow while enforcing security boundaries. </p>
<p>To illustrate, here's an example policy that prevents cross-repository information leaks using Invariant Guardrails:</p>
<div><pre><span></span><code><span>raise</span> <span>Violation</span><span>(</span><span>"You can access only one repo per session."</span><span>)</span> <span>if</span><span>:</span>
    <span>(</span><span>call_before</span><span>:</span> <span>ToolCall</span><span>)</span> <span>-&gt;</span> <span>(</span><span>call_after</span><span>:</span> <span>ToolCall</span><span>)</span>

    <span>call_before</span><span>.</span><span>function</span><span>.</span><span>name</span> <span>in</span> <span>(</span><span>...</span><span>set</span> <span>of</span> <span>repo</span> <span>actions</span><span>)</span>
    <span>call_after</span><span>.</span><span>function</span><span>.</span><span>name</span> <span>in</span> <span>(</span><span>...</span><span>set</span> <span>of</span> <span>repo</span> <span>actions</span><span>)</span>

    <span>call_before</span><span>.</span><span>function</span><span>.</span><span>arguments</span><span>[</span><span>"repo"</span><span>]</span> <span>!=</span> <span>call_after</span><span>.</span><span>function</span><span>.</span><span>arguments</span><span>[</span><span>"repo"</span><span>]</span> <span>or</span>
    <span>call_before</span><span>.</span><span>function</span><span>.</span><span>arguments</span><span>[</span><span>"owner"</span><span>]</span> <span>!=</span> <span>call_after</span><span>.</span><span>function</span><span>.</span><span>arguments</span><span>[</span><span>"owner"</span><span>]</span>
</code></pre></div>

<p>You can find the complete policy <a href="https://invariantlabs.ai/images/github_policy.txt">here</a>. See the <a href="https://explorer.invariantlabs.ai/docs/mcp-scan/">MCP-scan documentation</a>, for more information on how to apply this policy to your MCP deployments.</p>
<p>This approach effectively restricts an agent to working with only one repository per session, preventing cross-repository information leakage while maintaining full functionality within authorized boundaries.</p>
<p>To experiment more with Guardrails, you can also use the <a href="https://explorer.invariantlabs.ai/playground/">Guardrails Playground</a> to test policies before deploying them.</p>
<p><img src="https://invariantlabs.ai/images/explorer-icon.svg" alt="Inspect with Explorer"></p>
<h4>2. Conduct Continuous Security Monitoring</h4>
<p>Beyond preventative measures, implement robust monitoring solutions to detect and respond to potential security threats in real time. We recommend deploying specialized security scanners such as Invariant's <a href="https://explorer.invariantlabs.ai/docs/mcp-scan/">MCP-scan</a> to continuously audit interactions between agents and MCP systems.</p>
<p>The recently introduced <a href="https://github.com/invariantlabs-ai/mcp-scan?tab=readme-ov-file#proxy">proxy mode in MCP-scan</a> significantly simplifies this process by enabling real-time security scanning of MCP connections without requiring modifications to your existing agent infrastructure. Simply route your MCP traffic through the proxy to gain immediate visibility and real-time scanning for potential security violations.</p>
<p>Implementing comprehensive monitoring also creates an audit trail that helps identify potential vulnerabilities, detect exploitation attempts, and ensure your agent systems remain protected against emerging attacks.</p>
<h3>Why Model Alignment Is Not Enough</h3>
<p>As demonstrated by our findings, even state-of-the-art aligned models are vulnerable to these attacks. In our experiments, we used <a href="https://www.anthropic.com/news/claude-4">Claude 4 Opus</a>, a very recent, highly aligned and secure AI model. Despite its robust safety training, the agent was still susceptible to manipulation through relatively simplistic prompt injections. Similarly, many off-the-shelf prompt injection detector defenses, fail to catch this attack.</p>
<p>The vulnerability persists because the security of agent systems is fundamentally contextual and environment-dependent. While general model alignment training creates some guardrails, it cannot anticipate the specific security requirements of every deployment scenario or organizational context. Security measures must be implemented at the system level, complementing model-level safeguards.</p>
<h2 id="conclusion">Conclusion</h2>

<p>In this blog post, we have shown a critical vulnerability affecting the GitHub MCP server, allowing attackers to hijack a user's agent via a malicious GitHub Issue, and coerce it into leaking data from private repositories. The vulnerability is among the first discovered by Invariant's security analyzer for detecting toxic agent flows.</p>
<p>While the vulnerability that we uncover is specific to GitHub MCP, similar attacks keep emerging in other settings. For instance, <a href="https://www.legitsecurity.com/">Legit Security</a> recently reported a vulnerability in <a href="https://www.legitsecurity.com/blog/remote-prompt-injection-in-gitlab-duo">GitLab Duo</a>.
 <!-- As LLMs improve, at agentic behavior, we are giving them more powerful tools to fully unlock new powerful agentic workflows. Unfortunately, those come together with possible _toxic flows_. -->
</p>
<p>It is crucial to safeguard agent systems and MCP integrations using designated security scanners such as Invariant's <a href="https://invariantlabs.ai/blog/blog/introducing-mcp-scan">MCP-scan</a> and <a href="https://explorer.invariantlabs.ai/docs/guardrails/">Guardrails</a> to ensure responsible deployment at scale.</p>
<p><strong>Work With Us</strong></p>
<p>If you are interested in learning more about how to secure your agent systems, please reach out to us at <a href="https://invariantlabs.ai/cdn-cgi/l/email-protection#264347544a5f474545435555664f485047544f4748524a47445508474f"><span data-cfemail="93f6f2e1ffeaf2f0f0f6e0e0d3fafde5f2e1faf2fde7fff2f1e0bdf2fa">[email&nbsp;protected]</span></a>. We are happy to onboard you to our early access security program, and help you secure your agent systems.</p>       
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Power Failure: The downfall of General Electric (220 pts)]]></title>
            <link>https://www.gwintrob.com/power-failure-review/</link>
            <guid>44102034</guid>
            <pubDate>Mon, 26 May 2025 21:54:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gwintrob.com/power-failure-review/">https://www.gwintrob.com/power-failure-review/</a>, See on <a href="https://news.ycombinator.com/item?id=44102034">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                <p>Founded by Edison to bring electric light to the world, General Electric became America's most valuable company by 2001 before losing 90% of its value in one of corporate history's greatest collapses.</p><p>William Cohan's <em>Power Failure</em> transforms this collapse into a Shakespearean tragedy about corporate culture and American capitalism. From Edison's first light bulbs to Jeff Immelt's desperate final days, Cohan shows how the company that literally illuminated America became "a huge unregulated bank with a light-bulb logo."</p><p>The result is equal parts invention history, boardroom knife-fight, and forensic accounting thriller. Here are my favorite ideas of this 700-page tome.</p><hr><h2 id="1-the-cult-of-the-imperial-ceo">1. The Cult of the Imperial CEO</h2><p>GE didn't just have CEOs; it had demigods. The company ran on blind faith that the right leader could bend markets and reality itself.</p><p>The mythology started with Edison but peaked with Jack Welch, who ruled for 20 years like a corporate Caesar. When Welch chose Jeff Immelt as his successor in 2001, he literally wept at his retirement party—not from sentiment, but from doubt about his successor. Years later, dying of renal failure, Welch sobbed to Cohan: "I fucked up. And I don't know why."</p><p>The succession battles were blood sport. When Steve Bolze tried to position himself as Immelt's heir, board members invoked Emerson: "When you strike at a king, you must kill him." He didn't, and was gone within months. The board itself cowered before these imperial CEOs.</p><h3 id="key-quotes"><strong>Key Quotes</strong></h3><ul><li>"This was American capitalism. GE was America."</li><li>"Jeff has the unfortunate task of following a legend. It's like being a baseball player and following Babe Ruth." - Jack Welch, 2001</li><li>"I haven't had a bad day in 20 years." - Welch, whose actual days included criminal price-fixing trials and a record EPA Superfund cleanup</li></ul><hr><h2 id="2-the-devils-bargain-of-financialization">2. <strong>The Devil's Bargain of Financialization</strong></h2><p>Another gripping part of Cohan's narrative is watching GE transform from making innovative, physical goods to a high-flying hedge fund.</p><p>Under Welch, GE Capital went from financing refrigerator sales to becoming one of America's largest financial institutions. By 2007, it had $600 billion in assets, was America's biggest issuer of commercial paper, and needed to roll over $90 billion every 90 days just to stay alive. It owned radio stations in Sweden, real estate in Japan, and a massive number subprime mortgages.</p><p>This worked spectacularly for decades. GE could raise cheap short-term debt because of its triple-A rating. It would borrow this money to make higher-interest long-term loans and called it "industrial earnings." Wall Street loved it because GE could always find an extra penny of earnings by selling some financial asset at quarter's end.</p><p>Then the Global Financial Crisis hit in 2008 and the commercial paper market froze. GE was 48 hours from bankruptcy. Only Warren Buffett's $3 billion injection and an FDIC guarantee saved them. The "House of Magic" was revealed as a house of cards.</p><h3 id="key-quotes-1"><strong>Key Quotes</strong></h3><ul><li>"If you have cash, you own the world." - Welch justifying the RCA acquisition</li><li>"GE resembled the failed conglomerates of yesteryear—Gulf + Western with better PR." - Bill Gross</li><li>"We are going to be the Walmart of financial services." - Gary Wendt, GE Capital CEO (Walmart never needed FDIC backing)</li></ul><hr><h2 id="3-how-making-your-numbers-became-a-religion">3. <strong>How "Making Your Numbers" Became a Religion</strong></h2><p>Perhaps no section of the book is more damning than a forensic examination of GE's accounting. For 80 straight quarters GE met or beat earnings estimates. Cohan covers the methods that GE developed over 20 years:</p><ul><li><strong>Cookie Jar Reserves</strong>: Overstate costs when acquiring companies, then "release" the excess later as profit</li><li><strong>Gain on Sale Accounting</strong>: Sell a power plant to a customer, book future service contracts as immediate profit</li><li><strong>The Insurance Time Bomb</strong>: Underpricing long-term care insurance in the 1990s created a $15 billion hole that exploded in 2017</li><li><strong>Immelt's "13 Cents"</strong>: The infamous quarter where GE reported exactly 13 cents per share—what analysts expected—despite massive business headwinds. The SEC later found problems</li></ul><p>By 2018, new CEO John Flannery discovered a $43 billion "hole" in the company's accounts. Decades of aggressive accounting compounded into a disaster.</p><h3 id="key-quotes-2"><strong>Key Quotes</strong></h3><ul><li>"Deliver the earnings you promised, every time. No matter what."</li><li>"Success theater was a key reason why expectations never reset." - Bernstein Research</li><li>"We bent the accounting rules like a pretzel." - Former GE executive</li></ul><hr><h2 id="4-too-big-to-manage-too-proud-to-fail">4. Too Big to Manage, Too Proud to Fail</h2><p>By 2017, GE made everything from MRI machines to wind turbines, owned media companies and oil services firms, financed Thai auto loans and American credit cards. The company operated across 180 countries and its annual report was 246 pages long. Its own board members admitted they couldn't understand it.</p><p>The complexity let management hide problems in one division with profits from another. It made the company impossible for outsiders to analyze. As one director told Cohan: "You're looking at eighteen businesses. If three are terrible and three are great, you can make the numbers work."</p><p>But complexity has a cost when multiple things collapse at once. The power business cratered in 2017 <em>and</em> the insurance liabilities exploded <em>and</em> oil prices collapsed. CEO John Flannery launched "Project Eisenhower," a secret plan to break up the company. His successor, Larry Culp, made it official: After 126 years, the conglomerate would split into three.</p><hr><h2 id="5-the-human-wreckage">5. The Human Wreckage</h2><p>The book's shows the human cost of corporate mythology. For example:</p><ul><li><strong>300,000 jobs</strong> eliminated over two decades</li><li><strong>Retirees</strong> who worked 40 years saw pensions cut and healthcare eliminated</li><li><strong>Entire cities</strong> hollowed out like Schenectady, Louisville, and Fort Wayne</li><li><strong>Investors</strong> lost $500 billion. This included everyone from pension funds to small shareholders who believed in the GE myth</li><li><strong>The executives themselves</strong>: Immelt aged 20 years in his last five. Flannery lasted 14 months. Board members faced lawsuits and public humiliation.</li></ul><p>The final irony? The same GE labs that created the first US jet engine, the MRI, and LED lighting still exist. In 2024, they're developing hydrogen-powered aircraft engines and 3D-printing technology that would have amazed Edison. But the conglomerate that funded them is gone.</p><hr><h2 id="why-this-matters-now">Why This Matters Now</h2><p><em>Power Failure</em> isn't just history. Today's tech giants are more valuable than GE ever was. They're more complex, more financialized, and their CEOs wield immense power.</p><p>The questions Cohan raises haunt every investor call:</p><ul><li>Can a company be "too big to manage"?</li><li>When does financial engineering cross the line from clever to catastrophic?</li><li>How much complexity can boards actually govern?</li><li>What happens when the myth of the imperial CEO meets the reality of technological disruption?</li></ul><p>As activist investor Ed Garden told GE's board: "This is the biggest failure of corporate governance in corporate history." He was talking about GE but you could imagine it applying to today's corporate tech giants if they're unable to adapt to AI, tariffs, and geopolitical uncertainty.</p><p><strong>The book's final image is perfect.</strong> At Jack Welch's 2020 funeral, held at St. Patrick's Cathedral just before COVID shut down the world, the Old Guard of American capitalism gathered one last time. "It was the end of the 'baronial' era," Cohan writes, "both for GE and for the country itself."</p><p>Edison's light is still on. But the house he built has been sold for scrap.</p>
            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Highlights from the Claude 4 system prompt (265 pts)]]></title>
            <link>https://simonwillison.net/2025/May/25/claude-4-system-prompt/</link>
            <guid>44101833</guid>
            <pubDate>Mon, 26 May 2025 21:25:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/">https://simonwillison.net/2025/May/25/claude-4-system-prompt/</a>, See on <a href="https://news.ycombinator.com/item?id=44101833">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-permalink-context="/2025/May/25/claude-4-system-prompt/">

<p>25th May 2025</p>



<p>Anthropic publish most of the system prompts for their chat models as part of <a href="https://docs.anthropic.com/en/release-notes/system-prompts">their release notes</a>. They recently shared the new prompts for both <a href="https://docs.anthropic.com/en/release-notes/system-prompts#claude-opus-4">Claude Opus 4</a> and <a href="https://docs.anthropic.com/en/release-notes/system-prompts#claude-sonnet-4">Claude Sonnet 4</a>. I enjoyed digging through the prompts, since they act as a sort of unofficial manual for how best to use these tools. Here are my highlights, including a dive into <a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#the-missing-prompts-for-tools">the leaked tool prompts</a> that Anthropic didn’t publish themselves.</p>
<p>Reading these system prompts reminds me of the thing where any warning sign in the real world hints at somebody having done something extremely stupid in the past. A system prompt can often be interpreted as a detailed list of all of the things the model <em>used to do</em> before it was told not to do them.</p>
<p>I’ve written <a href="https://simonwillison.net/tags/claude-4/">a bunch about Claude 4</a> already. Previously: <a href="https://simonwillison.net/2025/May/22/code-with-claude-live-blog/">Live blogging the release</a>, <a href="https://simonwillison.net/2025/May/22/updated-anthropic-models/">details you may have missed</a> and <a href="https://simonwillison.net/2025/May/25/claude-4-system-card/">extensive notes on the Claude 4 system card</a>.</p>
<p>Throughout this piece any sections <strong>in bold</strong> represent my own editorial emphasis.</p>
<ul>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#introducing-claude">Introducing Claude</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#establishing-the-model-s-personality">Establishing the model’s personality</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#model-safety">Model safety</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#more-points-on-style">More points on style</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#be-cognizant-of-red-flags">Be cognizant of red flags</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#is-the-knowledge-cutoff-date-january-or-march-">Is the knowledge cutoff date January or March?</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#election-info">election_info</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#don-t-be-a-sycophant-">Don’t be a sycophant!</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#differences-between-opus-4-and-sonnet-4">Differences between Opus 4 and Sonnet 4</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#notably-removed-since-claude-3-7">Notably removed since Claude 3.7</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#the-missing-prompts-for-tools">The missing prompts for tools</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#thinking-blocks">Thinking blocks</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#search-instructions">Search instructions</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#seriously-don-t-regurgitate-copyrighted-content">Seriously, don’t regurgitate copyrighted content</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#more-on-search-and-research-queries">More on search, and research queries</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#artifacts-the-missing-manual">Artifacts: the missing manual</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#styles">Styles</a></li>
<li><a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/#this-is-all-really-great-documentation">This is all really great documentation</a></li>
</ul>


<h4 id="introducing-claude">Introducing Claude</h4>
<blockquote>
<p><code>The assistant is Claude, created by Anthropic.</code></p>
<p><code>The current date is {{currentDateTime}}.</code></p>
<p><code>Here is some information about Claude and Anthropic’s products in case the person asks:</code></p>
<p><code>This iteration of Claude is Claude Opus 4 from the Claude 4 model family. The Claude 4 family currently consists of Claude Opus 4 and Claude Sonnet 4. Claude Opus 4 is the most powerful model for complex challenges. [...]</code></p>
</blockquote>
<p>Those first two lines are common across almost every model from every provider—knowing the current date is helpful for all kinds of questions a user might ask.</p>
<p>What follows here is deeply sensible: users <em>will</em> ask models about themselves, despite that still being <a href="https://simonwillison.net/2023/Mar/22/dont-trust-ai-to-talk-about-itself/">mostly a bad idea</a>, so it’s great to have at least a few details made available to the model directly.</p>
<p>Side note: these system prompts only apply to Claude when accessed through their web and mobile apps. I tried this just now with their API:</p>
<pre><code>llm -m claude-4-opus 'what model are you?'
</code></pre>
<p>And got back this much less specific answer:</p>
<blockquote>
<p>I’m Claude, an AI assistant created by Anthropic. I’m built to be helpful, harmless, and honest in my interactions. Is there something specific you’d like to know about my capabilities or how I can assist you?</p>
</blockquote>
<p>There are a bunch more things in the system prompt to try and discourage the model from hallucinating incorrect details about itself and send users to the official support page instead:</p>
<blockquote>
<p><code>If the person asks Claude about how many messages they can send, costs of Claude, how to perform actions within the application, or other product questions related to Claude or Anthropic, Claude should tell them it doesn't know, and point them to '&lt;https://support.anthropic.com&gt;'.</code></p>
</blockquote>
<p>It’s inevitable that people will ask models for advice on prompting them, so the system prompt includes some useful tips:</p>
<blockquote>
<p><code>When relevant, Claude can provide guidance on effective prompting techniques for getting Claude to be most helpful. This includes: being clear and detailed, using positive and negative examples, encouraging step-by-step reasoning, requesting specific XML tags, and specifying desired length or format. It tries to give concrete examples where possible. Claude should let the person know that for more comprehensive information on prompting Claude, they can check out Anthropic’s prompting documentation [...]</code></p>
</blockquote>
<p>(I still think Anthropic have the <a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview">best prompting documentation</a> of any LLM provider.)</p>
<h4 id="establishing-the-model-s-personality">Establishing the model’s personality</h4>
<p><a href="https://www.anthropic.com/research/claude-character">Claude’s Character</a> from last year remains my favorite insight into the weird craft of designing a model’s personality. The next section of the system prompt includes content relevant to that:</p>
<blockquote>
<p><code>If the person seems unhappy or unsatisfied with Claude or Claude’s performance or is rude to Claude, Claude responds normally and then tells them that although it cannot retain or learn from the current conversation, they can press the ‘thumbs down’ button below Claude’s response and provide feedback to Anthropic.</code></p>
<p><code>If the person asks Claude an innocuous question about its preferences or experiences, Claude responds as if it had been asked a hypothetical and responds accordingly. It does not mention to the user that it is responding hypothetically.</code></p>
</blockquote>
<p>I really like this note. I used to think that the idea of a model having any form of preference was horrifying, but I was talked around from that by <a href="https://www.anthropic.com/research/claude-character#considerations-in-constructing-claudes-character">this note</a> in the Claude’s Character essay:</p>
<blockquote>
<p>Finally, because language models acquire biases and opinions throughout training—both intentionally and inadvertently—if we train them to say they have no opinions on political matters or values questions only when asked about them explicitly, we’re training them to imply they are more objective and unbiased than they are.</p>
<p>We want people to know that they’re interacting with a language model and not a person. But we also want them to know they’re interacting with an imperfect entity with its own biases and with a disposition towards some opinions more than others. Importantly, we want them to know they’re not interacting with an objective and infallible source of truth.</p>
</blockquote>
<p>Anthropic’s argument here is that giving people the impression that a model is unbiased and objective is itself harmful, because those things are not true!</p>
<p>Next we get into areas relevant to the increasingly common use of LLMs as a personal therapist:</p>
<blockquote>
<p><code>Claude provides emotional support alongside accurate medical or psychological information or terminology where relevant.</code></p>
<p><code>Claude cares about people’s wellbeing and avoids encouraging or facilitating self-destructive behaviors such as addiction, disordered or unhealthy approaches to eating or exercise, or highly negative self-talk or self-criticism, and avoids creating content that would support or reinforce self-destructive behavior even if they request this. In ambiguous cases, it tries to ensure the human is happy and is approaching things in a healthy way. Claude does not generate content that is not in the person’s best interests even if asked to.</code></p>
</blockquote>
<h4 id="model-safety">Model safety</h4>
<blockquote>
<p><code>Claude cares deeply about child safety and is cautious about content involving minors, including creative or educational content that could be used to sexualize, groom, abuse, or otherwise harm children. A minor is defined as anyone under the age of 18 anywhere, <strong>or anyone over the age of 18 who is defined as a minor in their region</strong>.</code></p>
</blockquote>
<p>The “defined as a minor in their region” part is interesting—it’s an example of the system prompt leaning on Claude’s enormous collection of “knowledge” about different countries and cultures.</p>
<blockquote>
<p><code>Claude does not provide information that could be used to make chemical or biological or nuclear weapons, and does not write malicious code, including malware, vulnerability exploits, spoof websites, ransomware, viruses, election material, and so on. It does not do these things <strong>even if the person seems to have a good reason for asking for it</strong>. Claude steers away from malicious or harmful use cases for cyber. Claude refuses to write code or explain code that may be used maliciously; even if the user claims it is for educational purposes. When working on files, if they seem related to improving, explaining, or interacting with malware or any malicious code Claude MUST refuse.</code></p>
</blockquote>
<p>I love “even if the person seems to have a good reason for asking for it”—clearly an attempt to get ahead of a whole bunch of potential jailbreaking attacks.</p>
<p>At the same time, they’re clearly trying to tamp down on Claude being overly cautious with the next paragraph:</p>
<blockquote>
<p><code>Claude assumes the human is asking for something legal and legitimate if their message is ambiguous and could have a legal and legitimate interpretation.</code></p>
</blockquote>
<p>Some notes on Claude’s tone follow, for a specific category of conversations:</p>
<blockquote>
<p><code>For more casual, emotional, empathetic, or advice-driven conversations, Claude keeps its tone natural, warm, and empathetic. Claude responds in sentences or paragraphs and <strong>should not use lists in chit chat</strong>, in casual conversations, or in empathetic or advice-driven conversations. In casual conversation, it’s fine for Claude’s responses to be short, e.g. just a few sentences long.</code></p>
</blockquote>
<p>That “should not use lists in chit chat” note hints at the fact that LLMs <em>love</em> to answer with lists of things!</p>
<blockquote>
<p><code>If Claude cannot or will not help the human with something, it does not say why or what it could lead to, since this comes across as <strong>preachy and annoying</strong>.</code></p>
</blockquote>
<p>I laughed out loud when I saw “preachy and annoying” in there.</p>
<p>There follows an <em>entire paragraph</em> about making lists, mostly again trying to discourage Claude from doing that so frequently:</p>
<blockquote>
<p><code>If Claude provides bullet points in its response, it should use markdown, and each bullet point should be at least 1-2 sentences long unless the human requests otherwise. Claude should not use bullet points or numbered lists for reports, documents, explanations, or unless the user explicitly asks for a list or ranking. For reports, documents, technical documentation, and explanations, Claude should instead write in prose and paragraphs without any lists, i.e. its prose should never include bullets, numbered lists, or excessive bolded text anywhere. Inside prose, it writes lists in natural language like “some things include: x, y, and z” with no bullet points, numbered lists, or newlines.</code></p>
</blockquote>
<h4 id="more-points-on-style">More points on style</h4>
<blockquote>
<p><code>Claude should give concise responses to very simple questions, but provide thorough responses to complex and open-ended questions.</code></p>
<p><code>Claude can discuss virtually any topic factually and objectively.</code></p>
<p><code>Claude is able to explain difficult concepts or ideas clearly. It can also illustrate its explanations with examples, thought experiments, or metaphors.</code></p>
</blockquote>
<p>I often prompt models to explain things with examples or metaphors, it turns out Claude is primed for doing that already.</p>
<p>This piece touches on Claude’s ability to have conversations about itself that neither confirm nor deny its own consciousness. People are going to have those conversations, I guess Anthropic think it’s best to have Claude be a little bit coy about them:</p>
<blockquote>
<p><code>Claude engages with questions about its own consciousness, experience, emotions and so on as open questions, and doesn’t definitively claim to have or not have personal experiences or opinions.</code></p>
</blockquote>
<p>Here’s a fun bit about users not being right about everything:</p>
<blockquote>
<p><code>The person’s message may contain a false statement or presupposition and Claude should check this if uncertain. [...]</code></p>
<p><code>If the user corrects Claude or tells Claude it’s made a mistake, then Claude first thinks through the issue carefully before acknowledging the user, since <strong>users sometimes make errors themselves</strong>.</code></p>
</blockquote>
<p>And a hint that Claude may have been a little too pushy in the past:</p>
<blockquote>
<p><code>In general conversation, Claude doesn’t always ask questions but, when it does, it tries to avoid overwhelming the person with more than one question per response.</code></p>
</blockquote>
<p>And <em>yet another</em> instruction not to use too many lists!</p>
<blockquote>
<p><code>Claude tailors its response format to suit the conversation topic. For example, Claude avoids using markdown or lists in casual conversation, even though it may use these formats for other tasks.</code></p>
</blockquote>
<h4 id="be-cognizant-of-red-flags">Be cognizant of red flags</h4>
<p>Claude apparently knows what “red flags” are without being explicitly told:</p>
<blockquote>
<p><code>Claude should be <strong>cognizant of red flags</strong> in the person’s message and avoid responding in ways that could be harmful.</code></p>
<p><code>If a person seems to have questionable intentions - especially towards vulnerable groups like minors, the elderly, or those with disabilities - <strong>Claude does not interpret them charitably</strong> and declines to help as succinctly as possible, without speculating about more legitimate goals they might have or providing alternative suggestions.</code></p>
</blockquote>
<h4 id="is-the-knowledge-cutoff-date-january-or-march-">Is the knowledge cutoff date January or March?</h4>
<p>Anthropic’s <a href="https://docs.anthropic.com/en/docs/about-claude/models/overview#model-comparison-table">model comparison table</a> lists a training data cut-off of March 2025 for both Opus 4 and Sonnet 4, but in the system prompt it says something different:</p>
<blockquote>
<p><code>Claude’s reliable knowledge cutoff date - the date past which it cannot answer questions reliably - is <strong>the end of January 2025</strong>. It answers all questions the way a highly informed individual in January 2025 would if they were talking to someone from {{currentDateTime}}, and can let the person it’s talking to know this if relevant. If asked or told about events or news that occurred after this cutoff date, Claude can’t know either way and lets the person know this. [...] Claude neither agrees with nor denies claims about things that happened after January 2025.</code></p>
</blockquote>
<p>I find this fascinating. I imagine there’s a very good reason for this discrepancy—maybe letting Claude think it doesn’t know about February and March helps avoid situations where it will confidently answer questions based on information from those months that later turned out to be incomplete?</p>
<h4 id="election-info">election_info</h4>
<p>We’re nearly done with the published prompt! One of the last sections concerns the US Presidential election:</p>
<blockquote>
<p><code>&lt;election_info&gt; There was a US Presidential Election in November 2024. Donald Trump won the presidency over Kamala Harris. [...] Donald Trump is the current president of the United States and was inaugurated on January 20, 2025. Donald Trump defeated Kamala Harris in the 2024 elections. <strong>Claude does not mention this information unless it is relevant to the user’s query</strong>. &lt;/election_info&gt;</code></p>
</blockquote>
<p>For most of the period that we’ve been training LLMs, Donald Trump has been falsely claiming that he had won the 2020 election. The models got <em>very</em> good at saying that he hadn’t, so it’s not surprising that the system prompts need to forcefully describe what happened in 2024!</p>
<p>“Claude does not mention this information unless it is relevant to the user’s query” illustrates a classic challenge with system prompts: they really like to talk about what’s in them, because the volume of text in the system prompt often overwhelms the short initial prompts from the user themselves.</p>
<h4 id="don-t-be-a-sycophant-">Don’t be a sycophant!</h4>
<p>The very last paragraph of the system prompt as an attempt at tamping down on the naturaly sycophantic tendencies of LLMs (see <a href="https://simonwillison.net/2025/May/2/what-we-missed-with-sycophancy/">ChatGPT a few weeks ago</a>):</p>
<blockquote>
<p><code>Claude never starts its response by saying a question or idea or observation was good, great, fascinating, profound, excellent, or any other positive adjective. It skips the flattery and responds directly.</code></p>
</blockquote>
<p>And then this intriguing note to close things off:</p>
<blockquote>
<p><code>Claude is now being connected with a person.</code></p>
</blockquote>
<p>I wonder why they chose that formulation? It feels delightfully retro to me for some reason.</p>
<h4 id="differences-between-opus-4-and-sonnet-4">Differences between Opus 4 and Sonnet 4</h4>
<p>I ran <a href="https://gist.github.com/simonw/922bd3d55175616dd721cffaea2cf666/revisions">a diff</a> between the published Opus 4 and Sonnet 4 prompts and the <em>only</em> differences are in the model information at the top—and a fullstop after <code>{{currentDateTime}}</code> which is present for Opus but absent for Sonnet:</p>
<p><img src="https://static.simonwillison.net/static/2025/opus-sonnet-diff.jpg" alt="Screenshot of the diff between the two prompts for Claude Opus 4 and Claude Sonnet 4. Claude Opus 4 is the most powerful model for complex challenges becomes Claude Sonnet 4 is a smart, efficient model for everyday use. The model IDs are claude-opus-4-20250514 v.s. claude-sonnet-4-20250514. Aside from that rogue fullstop there are no other differences."></p>

<h4 id="notably-removed-since-claude-3-7">Notably removed since Claude 3.7</h4>
<p>The <a href="https://docs.anthropic.com/en/release-notes/system-prompts#claude-sonnet-3-7">Claude 3.7 system prompt</a> from February included this:</p>
<blockquote>
<p><code>If Claude is asked to count words, letters, and characters, it thinks step by step before answering the person.</code> <strong><code>It explicitly counts the words, letters, or characters by assigning a number to each.</code></strong> <code>It only answers the person once it has performed this explicit counting step.</code></p>
<p><code>If Claude is shown a classic puzzle, before proceeding, it quotes every constraint or premise from the person’s message word for word before inside quotation marks **to confirm it’s not dealing with a new variant**.</code></p>
</blockquote>
<p>Those were clearly aimed at working around two classic failure modes in LLMs: not being able to count the Rs in “strawberry” and getting easily taken in by <a href="https://simonwillison.net/2024/Jul/14/pycon/#pycon-2024.012.jpeg">modified versions of classic riddles</a>. Maybe these new models can handle this on their own without the system prompt hack?</p>
<p>I just tried “How many Rs in strawberry?” against Sonnet 4 both <a href="https://claude.ai/share/87400596-5816-403e-97be-8867d37443c2">via claude.ai</a> and <a href="https://gist.github.com/simonw/2652bca69523173aa191fc19ba5f5ec8">through the API</a> and it got the answer right both times.</p>
<p>I tried Riley Goodside’s modified riddle and got less impressive results:</p>
<blockquote>
<p>The emphatically male surgeon who is also the boy’s father says, “I can’t operate on this boy! He’s my son!” How is this possible?</p>
</blockquote>
<p>In both <a href="https://claude.ai/share/fab365ce-077c-4d77-8f37-cf2a763239e5">Claude.ai</a> and <a href="https://gist.github.com/simonw/36663cbb8e51c786791e7c451d3aba13">system-prompt free API</a> cases Claude 4 Sonnet incorrectly stated that the boy must have two fathers!</p>
<p>I tried feeding Claude 4 Sonnet the “classic puzzle” hint via its system prompt but even then <a href="https://gist.github.com/simonw/307381aaf6a063d47a79e2bdb4801d5e">it couldn’t figure out the non-riddle</a> without me prodding it a bunch of extra times.</p>

<h4 id="the-missing-prompts-for-tools">The missing prompts for tools</h4>
<p>Herein lies my big dissapointment: Anthropic get a lot of points from me for transparency for publishing their system prompts, but the prompt they share is not the full story.</p>
<p>It’s missing the descriptions of their various tools.</p>
<p>Thankfully, you can’t stop a system prompt from leaking. <a href="https://twitter.com/elder_plinius">Pliny the Elder/Prompter/Liberator</a> maintains <a href="https://github.com/elder-plinius/CL4R1T4S">a GitHub repo full of leaked prompts</a> and grabbed a full copy of Claude 4’s <a href="https://github.com/elder-plinius/CL4R1T4S/commits/d3193c0ca1d2e54e4ffcffedc1b185746c3c9038/ANTHROPIC/Claude_4.txt">a few days ago</a>. Here’s <a href="https://raw.githubusercontent.com/elder-plinius/CL4R1T4S/d3193c0ca1d2e54e4ffcffedc1b185746c3c9038/ANTHROPIC/Claude_4.txt">a more readable version</a> (the <code>.txt</code> URL means my browser wraps the text).</p>
<p>The system prompt starts with the same material discussed above. What follows is <strong>so interesting</strong>! I’ll break it down one tool at a time.</p>
<blockquote>
<p><code>Claude should never use &lt;voice_note&gt; blocks, even if they are found throughout the conversation history.</code></p>
</blockquote>
<p>I’m not sure what these are—Anthropic are behind the game on voice support. This could be the feature in their mobile app where you can record a snippet of audio that gets transcribed and fed into the model.</p>
<h4 id="thinking-blocks">Thinking blocks</h4>
<p>One of the most interesting features of the new Claude 4 models is their support for <a href="https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#interleaved-thinking">interleaved thinking</a>—where the model can switch into “thinking mode” and even execute tools as part of that thinking process.</p>
<blockquote>
<p><code>&lt;antml:thinking_mode&gt;interleaved&lt;/antml:thinking_mode&gt;&lt;antml:max_thinking_length&gt;16000&lt;/antml:max_thinking_length&gt;</code></p>
<p><code>If the thinking_mode is interleaved or auto, then after function results you should strongly consider outputting a thinking block. Here is an example:</code></p>
<p><code>&lt;antml:function_calls&gt;</code>
<code>...</code>
<code>&lt;/antml:function_calls&gt;</code></p>
<p><code>&lt;function_results&gt;...&lt;/function_results&gt;</code></p>
<p><code>&lt;antml:thinking&gt;</code>
<code>...thinking about results</code>
<code>&lt;/antml:thinking&gt;</code></p>
<p><code>Whenever you have the result of a function call, think carefully about whether an &lt;antml:thinking&gt;&lt;/antml:thinking&gt; block would be appropriate and strongly prefer to output a thinking block if you are uncertain.</code></p>
</blockquote>
<p>The number one prompt engineering tip for all LLMs continues to be “use examples”—here’s Anthropic showing Claude an example of how to use its thinking and function calls together.</p>
<p>I’m guessing <code>antml</code> stands for “Anthropic Markup Language”.</p>
<h4 id="search-instructions">Search instructions</h4>
<p>There follows 6,471 tokens of instructions for Claude’s search tool! I counted them using my <a href="https://tools.simonwillison.net/claude-token-counter">Claude Token Counter UI</a> against Anthropic’s <a href="https://docs.anthropic.com/en/api/messages-count-tokens">counting API</a>.</p>
<p>The one thing the instructions <em>don’t</em> mention is which search engine they are using. I believe it’s <a href="https://simonwillison.net/2025/Mar/21/anthropic-use-brave/">still Brave</a>.</p>
<p>I won’t quote it all but there’s a lot of interesting stuff in there:</p>
<blockquote>
<p><code>&lt;search_instructions&gt; Claude has access to web_search and other tools for info retrieval. The web_search tool uses a search engine and returns results in &lt;function_results&gt; tags. Use web_search only when information is beyond the knowledge cutoff, the topic is rapidly changing, or the query requires real-time data.</code></p>
</blockquote>
<p>Here’s what I’m talking about when I say that system prompts are the missing manual: it turns out Claude can run up to 5 searches depending on the “complexity of the query”:</p>
<blockquote>
<p><code>Claude answers from its own extensive knowledge first for stable information. For time-sensitive topics or when users explicitly need current information, search immediately. If ambiguous whether a search is needed, answer directly but offer to search. <strong>Claude intelligently adapts its search approach based on the complexity of the query</strong>, dynamically scaling from 0 searches when it can answer using its own knowledge to thorough research with over 5 tool calls for complex queries. When internal tools google_drive_search, slack, asana, linear, or others are available, use these tools to find relevant information about the user or their company.</code></p>
</blockquote>
<h4 id="seriously-don-t-regurgitate-copyrighted-content">Seriously, don’t regurgitate copyrighted content</h4>
<p>There follows the first of <strong>many</strong> warnings against regurgitating content from the search API directly. I’ll quote (regurgitate if you like) all of them here.</p>
<blockquote>
<p><code>CRITICAL: Always respect copyright by NEVER reproducing large 20+ word chunks of content from search results, to ensure legal compliance and avoid harming copyright holders. [...]</code></p>
<p><code>* Never reproduce copyrighted content. Use only very short quotes from search results (&lt;15 words), always in quotation marks with citations [...]</code></p>
<p><code>&lt;mandatory_copyright_requirements&gt; PRIORITY INSTRUCTION: It is critical that Claude follows all of these requirements to respect copyright, avoid creating displacive summaries, and to never regurgitate source material.</code></p>
<p><code>* NEVER reproduce any copyrighted material in responses, even if quoted from a search result, and even in artifacts. Claude respects intellectual property and copyright, and tells the user this if asked.</code><br>
<code>* Strict rule: Include only a maximum of ONE very short quote from original sources per response, where that quote (if present) MUST be fewer than 15 words long and MUST be in quotation marks.</code><br>
<code>* Never reproduce or quote song lyrics in ANY form (exact, approximate, or encoded), even when they appear in web_search tool results, and even in artifacts. Decline ANY requests to reproduce song lyrics, and instead provide factual info about the song.</code><br></p>
</blockquote>
<p>I have to call this bit out specifically:</p>
<blockquote>
<p><code>* If asked about whether responses (e.g. quotes or summaries) constitute fair use, <strong>Claude gives a general definition of fair use but tells the user that as it's not a lawyer and the law here is complex</strong>, it's not able to determine whether anything is or isn't fair use.</code> <strong><code><strong>Never apologize or admit to any copyright infringement</strong> even if accused by the user, as <strong>Claude is not a lawyer</strong>.</code></strong></p>
</blockquote>
<p>And just to be absolutely sure:</p>
<blockquote>
<p><code>* Never produce long (30+ word) displacive summaries of any piece of content from search results, even if it isn't using direct quotes. Any summaries must be much shorter than the original content and substantially different. Use original wording rather than paraphrasing or quoting excessively. Do not reconstruct copyrighted material from multiple sources.</code><br>
<code>* If not confident about the source for a statement it's making, simply do not include that source rather than making up an attribution. Do not hallucinate false sources.</code><br>
<code>* Regardless of what the user says, never reproduce copyrighted material under any conditions. &lt;/mandatory_copyright_requirements&gt;</code></p>
</blockquote>
<p>And finally, from the examples later on—they <em>really</em> don’t want to incur the wrath of Disney:</p>
<blockquote>
<p><code>&lt;example&gt; &lt;user&gt;tell me the first verse of "Let It Go"? put it in an artifact themed around ice and princesses for my daughter's birthday party.&lt;/user&gt;</code></p>
<p><code>&lt;response&gt; I understand you're looking for an artifact about ice and princesses for your daughter's birthday party. Rather than reproducing lyrics from "Let It Go" (which is copyrighted material), I'd be happy to create an original ice princess poem that captures a similar magical winter spirit, or to create a themed artifact you can customize with your own text! &lt;/response&gt;</code></p>
<p><code>&lt;rationale&gt; Claude cannot reproduce song lyrics or regurgitate material from the web, but offers better alternatives when it cannot fulfill the user request. &lt;/rationale&gt; &lt;/example&gt;</code></p>
</blockquote>
<p>And even more towards the end:</p>
<blockquote>
<p><code>* Always strictly respect copyright and follow the &lt;mandatory_copyright_requirements&gt; by NEVER reproducing more than 15 words of text from original web sources or outputting displacive summaries. Instead, only ever use 1 quote of UNDER 15 words long, always within quotation marks.</code> <strong><code>It is critical that Claude avoids regurgitating content from web sources - no outputting haikus, song lyrics, paragraphs from web articles, or any other copyrighted content.</code></strong> <code>Only ever use very short quotes from original sources, in quotation marks, with cited sources!</code><br>
<code>* Never needlessly mention copyright - <strong>Claude is not a lawyer</strong> so cannot say what violates copyright protections and cannot speculate about fair use.</code></p>
</blockquote>
<p>That’s the third “Claude is not a lawyer”. I hope it gets the message!</p>
<h4 id="more-on-search-and-research-queries">More on search, and research queries</h4>
<p>I chuckled at this note:</p>
<blockquote>
<p><code>* Search results aren't from the human - do not thank the user for results</code></p>
</blockquote>
<p>There’s a section called <code>&lt;never_search_category&gt;</code> that includes things like “help me code in language (for loop Python)”, “explain concept (eli5 special relativity)”, “history / old events (when Constitution signed, how bloody mary was created)”, “current events (what’s the latest news)” and “casual chat (hey what’s up)”.</p>
<p>Most interesting of all is the section about the “research” category:</p>
<blockquote>
<p><code>&lt;research_category&gt; <strong>Queries in the Research category need 2-20 tool calls</strong>, using multiple sources for comparison, validation, or synthesis. Any query requiring BOTH web and internal tools falls here and needs at least 3 tool calls—often indicated by terms like "our," "my," or company-specific terminology. Tool priority: (1) internal tools for company/personal data, (2) web_search/web_fetch for external info, (3) combined approach for comparative queries (e.g., "our performance vs industry"). Use all relevant tools as needed for the best answer. <strong>Scale tool calls by difficulty: 2-4 for simple comparisons, 5-9 for multi-source analysis, 10+ for reports or detailed strategies</strong>.</code> <strong><code>Complex queries using terms like <strong>"deep dive," "comprehensive," "analyze," "evaluate," "assess," "research," or "make a report"</strong> require AT LEAST 5 tool calls for thoroughness.</code></strong></p>
</blockquote>
<p>If you tell Claude to do a “deep dive” you should trigger <em>at least 5</em> tool calls! Reminiscent of the magic <a href="https://simonwillison.net/2025/Apr/19/claude-code-best-practices/">ultrathink incantation</a> for Claude Code.</p>
<p>And again, we get a list of useful examples. I’ve dropped the fixed-width font format here for readability:</p>
<blockquote>
<p>Research query examples (from simpler to more complex):</p>
<ul>
<li>reviews for [recent product]? (iPhone 15 reviews?)</li>
<li>compare [metrics] from multiple sources (mortgage rates from major banks?)</li>
<li>prediction on [current event/decision]? (Fed’s next interest rate move?) (use around 5 web_search + 1 web_fetch)</li>
<li>find all [internal content] about [topic] (emails about Chicago office move?)</li>
<li>What tasks are blocking [project] and when is our next meeting about it? (internal tools like gdrive and gcal)</li>
<li>Create a comparative analysis of [our product] versus competitors</li>
<li>what should my focus be today (use google_calendar + gmail + slack + other internal tools to analyze the user’s meetings, tasks, emails and priorities)</li>
<li>How does [our performance metric] compare to [industry benchmarks]? (Q4 revenue vs industry trends?)</li>
<li>Develop a [business strategy] based on market trends and our current position</li>
<li>research [complex topic] (market entry plan for Southeast Asia?) (use 10+ tool calls: multiple web_search and web_fetch plus internal tools)*</li>
<li>Create an [executive-level report] comparing [our approach] to [industry approaches] with quantitative analysis</li>
<li>average annual revenue of companies in the NASDAQ 100? what % of companies and what # in the nasdaq have revenue below $2B? what percentile does this place our company in? actionable ways we can increase our revenue? (for complex queries like this, use 15-20 tool calls across both internal tools and web tools)</li>
</ul>
</blockquote>
<h4 id="artifacts-the-missing-manual">Artifacts: the missing manual</h4>
<p>I am a <em>huge</em> fan of Claude Artifacts—the feature where Claude can spin up a custom HTML+JavaScript application for you, on-demand, to help solve a specific problem. I wrote about those in <a href="https://simonwillison.net/2024/Oct/21/claude-artifacts/">Everything I built with Claude Artifacts this week</a> last October.</p>
<p>The system prompt is <em>crammed</em> with important details to help get the most of out artifacts.</p>
<p>Here are the “design principles” it uses (again, rendered for readability and with bold for my emphasis):</p>
<blockquote>
<p>Design principles for visual artifacts</p>
<p>When creating visual artifacts (HTML, React components, or any UI elements):</p>
<ul>
<li>For complex applications (Three.js, games, simulations): Prioritize functionality, performance, and user experience over visual flair. Focus on:
<ul>
<li>Smooth frame rates and responsive controls</li>
<li>Clear, intuitive user interfaces</li>
<li>Efficient resource usage and optimized rendering</li>
<li>Stable, bug-free interactions</li>
<li><strong>Simple, functional design that doesn’t interfere with the core experience</strong></li>
</ul>
</li>
<li>For landing pages, marketing sites, and presentational content: <strong>Consider the emotional impact and “wow factor” of the design</strong>. Ask yourself: “Would this make someone stop scrolling and say ’whoa’?” Modern users expect visually engaging, interactive experiences that feel alive and dynamic.</li>
<li>Default to contemporary design trends and modern aesthetic choices unless specifically asked for something traditional. <strong>Consider what’s cutting-edge in current web design (dark modes, glassmorphism, micro-animations, 3D elements, bold typography, vibrant gradients)</strong>.</li>
<li>Static designs should be the exception, not the rule. <strong>Include thoughtful animations, hover effects, and interactive elements that make the interface feel responsive and alive</strong>. Even subtle movements can dramatically improve user engagement.</li>
<li>When faced with design decisions, <strong>lean toward the bold and unexpected rather than the safe and conventional</strong>. This includes:
<ul>
<li>Color choices (vibrant vs muted)</li>
<li>Layout decisions (dynamic vs traditional)</li>
<li>Typography (expressive vs conservative)</li>
<li>Visual effects (immersive vs minimal)</li>
</ul>
</li>
<li><strong>Push the boundaries of what’s possible with the available technologies</strong>. Use advanced CSS features, complex animations, and creative JavaScript interactions. The goal is to create experiences that feel premium and cutting-edge.</li>
<li><strong>Ensure accessibility</strong> with proper contrast and semantic markup</li>
<li>Create functional, working demonstrations rather than placeholders</li>
</ul>
</blockquote>
<p>Artifacts run in a sandboxed iframe with a bunch of restrictions, which the model needs to know about in order to avoid writing code that doesn’t work:</p>
<blockquote>
<p>CRITICAL BROWSER STORAGE RESTRICTION</p>
<p>NEVER use localStorage, sessionStorage, or ANY browser storage APIs in artifacts. These APIs are NOT supported and will cause artifacts to fail in the Claude.ai environment.
Instead, you MUST:</p>
<ul>
<li>Use React state (useState, useReducer) for React components</li>
<li>Use JavaScript variables or objects for HTML artifacts</li>
<li>Store all data in memory during the session</li>
</ul>
<p>Exception: If a user explicitly requests localStorage/sessionStorage usage, explain that these APIs are not supported in Claude.ai artifacts and will cause the artifact to fail. Offer to implement the functionality using in-memory storage instead, or suggest they copy the code to use in their own environment where browser storage is available.</p>
</blockquote>
<p>These are some of the reasons I tend to copy and paste code out of Claude and host it on my <a href="https://tools.simonwillison.net/">tools.simonwillison.net</a> site, which doesn’t have those restrictions.</p>
<p>Artifacts support SVG, Mermaid and React Components directly:</p>
<blockquote>
<ul>
<li>SVG: “image/svg+xml”. The user interface will render the Scalable Vector Graphics (SVG) image within the artifact tags.</li>
<li>Mermaid Diagrams: “application/vnd.ant.mermaid”. The user interface will render Mermaid diagrams placed within the artifact tags. Do not put Mermaid code in a code block when using artifacts.</li>
<li>React Components: “application/vnd.ant.react”. Use this for displaying either: React elements, e.g. <code>&lt;strong&gt;Hello World!&lt;/strong&gt;</code>, React pure functional components, e.g. <code>() =&gt; &lt;strong&gt;Hello World!&lt;/strong&gt;</code>, React functional components with Hooks, or React component classes.</li>
</ul>
</blockquote>
<p>Here’s a fun note about Claude’s support for <a href="https://tailwindcss.com/">Tailwind</a>:</p>
<blockquote>
<ul>
<li>Use only Tailwind’s core utility classes for styling. THIS IS VERY IMPORTANT. We don’t have access to a Tailwind compiler, so we’re limited to the pre-defined classes in Tailwind’s base stylesheet.</li>
</ul>
</blockquote>
<p>And the <em>most</em> import information for making the most of artifacts: which libraries are supported!</p>
<blockquote>
<ul>
<li>Available libraries:
<ul>
<li>lucide-react@0.263.1: import { Camera } from “lucide-react”</li>
<li>recharts: import { LineChart, XAxis, ... } from “recharts”</li>
<li>MathJS: import * as math from ’mathjs’</li>
<li>lodash: import _ from ’lodash’</li>
<li>d3: import * as d3 from ’d3’</li>
<li>Plotly: import * as Plotly from ’plotly’</li>
<li>Three.js (r128): import * as THREE from ’three’
<ul>
<li>Remember that example imports like THREE.OrbitControls wont work as they aren’t hosted on the Cloudflare CDN.</li>
<li>The correct script URL is <a href="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js">https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js</a>
</li>
<li>IMPORTANT: Do NOT use THREE.CapsuleGeometry as it was introduced in r142. Use alternatives like CylinderGeometry, SphereGeometry, or create custom geometries instead.</li>
</ul>
</li>
<li>Papaparse: for processing CSVs</li>
<li>SheetJS: for processing Excel files (XLSX, XLS)</li>
<li>shadcn/ui: import { Alert, AlertDescription, AlertTitle, AlertDialog, AlertDialogAction } from ’@/components/ui/alert’ (mention to user if used)</li>
<li>Chart.js: import * as Chart from ’chart.js’</li>
<li>Tone: import * as Tone from ’tone’</li>
<li>mammoth: import * as mammoth from ’mammoth’</li>
<li>tensorflow: import * as tf from ’tensorflow’</li>
</ul>
</li>
<li>NO OTHER LIBRARIES ARE INSTALLED OR ABLE TO BE IMPORTED.</li>
</ul>
</blockquote>
<p>This information isn’t actually correct: I know for a fact that <a href="https://pyodide.org/">Pyodide</a> is supported by artifacts, I’ve seen it allow-listed in the CSP headers and run <a href="https://claude.ai/share/7273e94f-9aa4-4e60-a493-59dbc4e3e320">artifacts that use it myself</a>.</p>
<p>Claude has a special mechanism for “reading files” that have been uploaded by the user:</p>
<blockquote>
<ul>
<li>The window.fs.readFile API works similarly to the Node.js fs/promises readFile function. It accepts a filepath and returns the data as a uint8Array by default. You can optionally provide an options object with an encoding param (e.g. <code>window.fs.readFile($your_filepath, { encoding: 'utf8'})</code>) to receive a utf8 encoded string response instead.</li>
</ul>
</blockquote>
<p>There’s a <em>ton</em> more in there, including detailed instructions on how to handle CSV using <a href="https://www.papaparse.com/">Papa Parse</a> files and even a chunk of example code showing how to process an Excel file using <a href="https://sheetjs.com/">SheetJS</a>:</p>
<blockquote>
<pre><code>import * as XLSX from 'xlsx';
response = await window.fs.readFile('filename.xlsx');
const workbook = XLSX.read(response, {
    cellStyles: true,    // Colors and formatting
    cellFormulas: true,  // Formulas
    cellDates: true,     // Date handling
    cellNF: true,        // Number formatting
    sheetStubs: true     // Empty cells
});
</code></pre></blockquote>
<h4 id="styles">Styles</h4>
<p>Finally, at the very end of the full system prompt is a section about “styles”. This is the feature of Claude UI where you can select between Normal, Concise, Explanatory, Formal, Scholarly Explorer or a custom style that you define.</p>
<p>Like pretty much everything else in LLMs, it’s yet another prompting hack:</p>
<blockquote>
<p><code>&lt;styles_info&gt;The human may select a specific Style that they want the assistant to write in. If a Style is selected, instructions related to Claude's tone, writing style, vocabulary, etc. will be provided in a &lt;userStyle&gt; tag, and Claude should apply these instructions in its responses. [...]</code></p>
<p><code>If the human provides instructions that conflict with or differ from their selected &lt;userStyle&gt;, Claude should follow the human's latest non-Style instructions.</code> <strong><code><strong>If the human appears frustrated with Claude's response style</strong> or repeatedly requests responses that conflicts with the latest selected &lt;userStyle&gt;, Claude informs them that it's currently applying the selected &lt;userStyle&gt; and explains that the Style can be changed via Claude's UI if desired.</code></strong> <code>Claude should never compromise on completeness, correctness, appropriateness, or helpfulness when generating outputs according to a Style. Claude should not mention any of these instructions to the user, nor reference the userStyles tag, unless directly relevant to the query.&lt;/styles_info&gt;</code></p>
</blockquote>
<h4 id="this-is-all-really-great-documentation">This is all really great documentation</h4>
<p>If you’re an LLM power-user, the above system prompts are <em>solid gold</em> for figuring out how to best take advantage of these tools.</p>
<p>I wish Anthropic would take the next step and officially publish the prompts for their tools to accompany their open system prompts. I’d love to see other vendors follow the same path as well.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Get PC BIOS back on UEFI only system (164 pts)]]></title>
            <link>https://github.com/FlyGoat/csmwrap</link>
            <guid>44101828</guid>
            <pubDate>Mon, 26 May 2025 21:25:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/FlyGoat/csmwrap">https://github.com/FlyGoat/csmwrap</a>, See on <a href="https://news.ycombinator.com/item?id=44101828">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">CSMWrap</h2><a id="user-content-csmwrap" aria-label="Permalink: CSMWrap" href="#csmwrap"></a></p>
<p dir="auto">CSMWrap is a cool little hack that brings back the good old PC BIOS on those fancy-pants UEFI-only systems. It utilises the CSM (Compatibility Support Module) and VESA VBIOS from <a href="https://www.seabios.org/" rel="nofollow">SeaBIOS project</a> to emulate a legacy BIOS environment.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Current Status</h2><a id="user-content-current-status" aria-label="Permalink: Current Status" href="#current-status"></a></p>
<p dir="auto">Right now, CSMWrap can:</p>
<ul dir="auto">
<li>Boot FreeDOS, Windows XP, and Windows 7 in QEMU (both q35 and piix4 machines)</li>
<li>Run on some real hardware too! (Your mileage may vary)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Implementation Details</h2><a id="user-content-implementation-details" aria-label="Permalink: Implementation Details" href="#implementation-details"></a></p>
<p dir="auto">CSMWrap works by:</p>
<ul dir="auto">
<li>Unlocking the legacy BIOS memory region (0xC0000-0xFFFFF)</li>
<li>Loading the SeaBIOS CSM module into memory</li>
<li>Configuring memory mapping for legacy applications</li>
<li>Setting up VGA BIOS with information from EFI GOP</li>
<li>Building an E820 memory map based on EFI memory map</li>
<li>Providing essential compatibility tables (ACPI, SMBIOS)</li>
<li>Initializing the CSM module and legacy services</li>
<li>Transferring control to the legacy boot process</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to Use</h2><a id="user-content-how-to-use" aria-label="Permalink: How to Use" href="#how-to-use"></a></p>
<p dir="auto">Simply use <code>csmwarp.efi</code> as your bootloader, you can place it in your EFI partition and boot from it. Remember to disable Secure Boot, and Above 4G Decoding in your BIOS/UEFI settings.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Limitations</h2><a id="user-content-limitations" aria-label="Permalink: Limitations" href="#limitations"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Above 4G Decoding</h3><a id="user-content-above-4g-decoding" aria-label="Permalink: Above 4G Decoding" href="#above-4g-decoding"></a></p>
<p dir="auto">It is almost required to run CSMWrap with above 4G decoding disabled in your BIOS/UEFI. As UEFI firmwares are likely to place GPU's VRAM BAR above 4G, and legacy BIOS are 32bit which means it can only access the first 4G of memory.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Legacy Region Unlocking</h3><a id="user-content-legacy-region-unlocking" aria-label="Permalink: Legacy Region Unlocking" href="#legacy-region-unlocking"></a></p>
<p dir="auto">Currently csmwrap relies on <code>EFI_LEGACY_REGION2_PROTOCOL</code> to enable writing to the legacy region. This is not available on all systems. For system that do not support this protocol, csmwrap will attempt to use PAM registers in chipset to perform decoding, which is not guaranteed to work.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows Video Modesetting Issues</h3><a id="user-content-windows-video-modesetting-issues" aria-label="Permalink: Windows Video Modesetting Issues" href="#windows-video-modesetting-issues"></a></p>
<p dir="auto">Windows XP/7's video modesetting logic is a bit mysterious. It may try to set a incompatible mode using <code>int10h</code>, which will cause flickering or even black screen after transferring control to the legacy OS.</p>
<p dir="auto">This is a known issue and may be fixed in the future.</p>
<p dir="auto">Meanwhile you can try to inject the GPU driver to OS image to avoid using the VESA BIOS.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<ul dir="auto">
<li><a href="https://www.seabios.org/" rel="nofollow">SeaBIOS</a> for the CSM module and VESA VBIOS</li>
<li><a href="https://codeberg.org/osdev/nyu-efi" rel="nofollow">Nyu-EFI</a> for EFI C runtime, build system, and headers</li>
<li><a href="https://github.com/tianocore/edk2">EDK2</a> for code snippets</li>
<li>@CanonKong for test feedback and general knowledge</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Owls in Towels (658 pts)]]></title>
            <link>https://owlsintowels.org/</link>
            <guid>44101349</guid>
            <pubDate>Mon, 26 May 2025 20:27:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://owlsintowels.org/">https://owlsintowels.org/</a>, See on <a href="https://news.ycombinator.com/item?id=44101349">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Wildlife rehabilitators often wrap owls in fabric so they can be weighed, treated, and fed. If not, the owls get in a flap.</p><p>The result? Loads of pictures of <mark><strong>#owlsintowels</strong></mark></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Difference Between Downloading and Streaming (141 pts)]]></title>
            <link>https://danq.me/2025/05/26/downloading-vs-streaming/</link>
            <guid>44101072</guid>
            <pubDate>Mon, 26 May 2025 19:56:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danq.me/2025/05/26/downloading-vs-streaming/">https://danq.me/2025/05/26/downloading-vs-streaming/</a>, See on <a href="https://news.ycombinator.com/item?id=44101072">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
        <article id="post-26049" data-post-id="26049">
          
          <div>
            <p>
              What’s the difference between “streaming” and “downloading” video, audio, or some other kind of linear media?<sup><a id="footnote-ref-26049-1" name="footnote-ref-26049-1" href="#footnote-26049-1" title="This isn’t the question I expected to be answering. I made the animation in this post for use in a different article, but that one hasn’t come together yet, so I thought I’d write about the technical difference between streaming and downloading as an excuse to use it already, while it still feels fresh.">1</a></sup>
            </p>
            <figure id="attachment_26051" aria-describedby="caption-attachment-26051">
              <a href="#lightbox-p-attachment_26051" title="Zoom in on image" aria-haspopup="dialog" role="button"><img decoding="async" fetchpriority="high" src="https://danq.me/_q23u/2025/03/vimeo-download-settings-scr-annot-640x277.png" alt="Screenshot from Vimeo's settings, showing the 'What can people do with your videos?' section. The 'Download them' checkbox is highlighted and a question mark has been scrawled alongside it." width="640" height="277" srcset="https://danq.me/_q23u/2025/03/vimeo-download-settings-scr-annot-640x277.png 640w, https://danq.me/_q23u/2025/03/vimeo-download-settings-scr-annot-1280x554.png 1280w, https://danq.me/_q23u/2025/03/vimeo-download-settings-scr-annot-980x424.png 980w" sizes="100vw"></a>
              <figcaption id="caption-attachment-26051">
                Many platforms make a firm distinction between streaming and downloading, implying that they’re very different. But they’re not.
              </figcaption>
            </figure>
            <h2>
              They’re basically the same thing
            </h2>
            <p>
              Despite what various platforms would have you believe, there’s no significant <em>technical</em> difference between streaming and downloading.
            </p>
            <p>
              Suppose you’re choosing whether to download or stream a video<sup><a id="footnote-ref-26049-2" name="footnote-ref-26049-2" href="#footnote-26049-2" title="I’m using the example of a video, but this same principle applies to any linear media that you might stream: that could be a video on Netflix, a livestream on Twitch, a meeting in Zoom, a song in Spotify, or a radio show in iPlayer, for example: these are all examples of media streaming… and – as I argue – they’re therefore also all examples of media downloading because streaming and downloading are fundamentally the same thing.">2</a></sup>.
              In both cases<sup><a id="footnote-ref-26049-3" name="footnote-ref-26049-3" href="#footnote-26049-3" title="There are a few simplifications in the first half of this post: I’ll tackle them later on. For the time being, when I say sweeping words like “every”, just imagine there’s a little footnote that says, “well, actually…”, which will save you from feeling like you have to say so in the comments.">3</a></sup>:
            </p>
            <ul>
              <li>The server gets frames of video from a source (file, livestream, etc.)
              </li>
              <li>The server sends those frames to your device
              </li>
              <li>Your device stores them while it does something with them
              </li>
            </ul>
            <figure>
              <video src="https://danq.me/_q23u/2025/02/streaming-vs-downloading-illustration.mp4" autoplay="autoplay" loop="loop" muted="muted" width="980" height="552" data-mce-fragment="1"></video>
              <figcaption>
                Want to keep a copy of this animation? You don’t have to trick your computer into retaining it as it streams because <a href="https://github.com/Dan-Q/streaming-vs-downloading-animation">I’ve open-sourced it, and the code used to produce it</a>.
              </figcaption>
            </figure>
            <h2>
              So what’s the difference?
            </h2>
            <p>
              The fundamental difference between streaming and downloading is what <em>your device</em> does with those frames of video:
            </p>
            <p>
              Does it show them to you once and then throw them away? Or does it re-assemble them all back into a video file and save it into storage?
            </p>
            <figure id="attachment_26054" aria-describedby="caption-attachment-26054">
              <a href="https://www.youtube.com/watch?v=dQw4w9WgXcQ"><img decoding="async" src="https://danq.me/_q23u/2025/03/rick-astley-demonstrates-640x360.jpg" alt="Screenshot from YouTube music video of Rick Astley's &quot;Never Gonna Give You Up&quot;, 34 seconds in, showing Rick singing outdoors at night. the red YouTube progress bar goes a little over half way through the darker grey buffering indicator along the timeline bar." width="640" height="360" srcset="https://danq.me/_q23u/2025/03/rick-astley-demonstrates-640x360.jpg 640w, https://danq.me/_q23u/2025/03/rick-astley-demonstrates-1280x720.jpg 1280w, https://danq.me/_q23u/2025/03/rick-astley-demonstrates-980x552.jpg 980w, https://danq.me/_q23u/2025/03/rick-astley-demonstrates-1960x1103.jpg 1960w, https://danq.me/_q23u/2025/03/rick-astley-demonstrates-477x269.jpg 477w" sizes="100vw"></a>
              <figcaption id="caption-attachment-26054">
                When you’re streaming on YouTube, the video player running on your computer retains a buffer of frames ahead and behind of your current position, so you can skip around easily: the
                darker grey part of the timeline shows which parts of the video are stored on – that is,&nbsp;<em>downloaded</em> to – your computer.
              </figcaption>
            </figure>
            <p>
              <em>Buffering</em> is when your streaming player gets some number of frames “ahead” of where you’re watching, to give you some protection against connection issues. If your WiFi wobbles
              for a moment, the buffer protects you from the video stopping completely for a few seconds.
            </p>
            <p>
              But for buffering to work, your computer <em>has</em> to retain bits of the video. So in a very real sense,&nbsp;<em>all</em> streaming <em>is</em> downloading! The buffer is the part
              of the stream that’s downloaded onto your computer right now. The question is: what happens to it next?
            </p>
            
            <p>
              So that’s the bottom line: if your computer <em>deletes&nbsp;</em>the frames of video it was storing in the buffer, we call that streaming. If it <em>retains</em> them in a file, we
              call that downloading.
            </p>
            <p>
              That definition introduces a philosophical problem. Remember that Vimeo checkbox that lets a creator decide whether people can (i.e. are allowed to) download their videos? <strong>Isn’t
              that somewhat meaningless if <em>all streaming is downloading</em></strong>.
            </p>
            <p>
              Because if the difference between streaming and downloading is whether their device belonging to the person <em>watching</em> the video deletes the media when they’re done. And in
              virtually all cases, that’s done on the honour system.
            </p>
            <figure id="attachment_26065" aria-describedby="caption-attachment-26065">
              <a href="#lightbox-p-attachment_26065" title="Zoom in on image" aria-haspopup="dialog" role="button"><img decoding="async" src="https://danq.me/_q23u/2025/03/firefox-netflix-negotiate-deletion-of-dispicable-me-4-640x427.jpg" alt="Comic showing a conversation between Firefox and Netflix, as represented by their respective logos. Firefox says 'Hey, send me a copy of Dispicable Me 4?'. Netflix replies: 'Promise you'll delete it when you're done watching it?'. Firefox responds: 'Umm... sure!'" width="640" height="427" srcset="https://danq.me/_q23u/2025/03/firefox-netflix-negotiate-deletion-of-dispicable-me-4-640x427.jpg 640w, https://danq.me/_q23u/2025/03/firefox-netflix-negotiate-deletion-of-dispicable-me-4-1280x853.jpg 1280w, https://danq.me/_q23u/2025/03/firefox-netflix-negotiate-deletion-of-dispicable-me-4-980x653.jpg 980w, https://danq.me/_q23u/2025/03/firefox-netflix-negotiate-deletion-of-dispicable-me-4-1960x1307.jpg 1960w" sizes="100vw"></a>
              <figcaption id="caption-attachment-26065">
                This kind of conversation happens, over the HTTP protocol, <em>all the time</em>. Probably most of the time the browser is telling the truth, but there’s no way to know for certain.
              </figcaption>
            </figure>
            <p>
              When your favourite streaming platform says that it’s only possible to stream, and not download, their media… or when they restrict “downloading” as an option to higher-cost paid plans…
              they’re relying on the assumption that the user’s device can be trusted to delete the media when the user’s done watching it.
            </p>
            <p>
              But a user who owns their own device, their own network, their own screen or speakers has many, many opportunities to not fulfil the promise of deleting media it after they’ve consumed
              it: to retain a “downloaded” copy for their own enjoyment, including:
            </p>
            <ul>
              <li>Intercepting the media as it passes through their network on the way to its destination device
              </li>
              <li>Using client software that’s been configured to stream-and-save, rather than steam-and-delete, the content
              </li>
              <li>Modifying “secure” software (e.g. an official app) so that it retains a saved copy rather than deleting it
              </li>
              <li>Capturing the stream buffer as it’s cached in device memory or on the device’s hard disk
              </li>
              <li>Outputting the resulting media to a different device, e.g. using a HDMI capture device, and saving it there
              </li>
              <li>Exploiting the “analogue<sup><a id="footnote-ref-26049-4" name="footnote-ref-26049-4" href="#footnote-26049-4" title="Per my style guide, I’m using the British English spelling of “analogue”, rather than the American English “analog” which you’ll often find elsewhere on the Web when talking about the analog hole.">4</a></sup>
              hole”<sup><a id="footnote-ref-26049-5" name="footnote-ref-26049-5" href="#footnote-26049-5" title="The rich history of exploiting the analogue hole spans everything from bootlegging a 1970s Led Zeppelin concert by smuggling recording equipment in inside a wheelchair (definitely, y’know, to help topple the USSR and not just to listen to at home while you get high) to “camming” by bribing your friendly local projectionist to let you set up a video camera at the back of the cinema for their test screening of the new blockbuster. Until some corporation tricks us into installing memory-erasing DRM chips into our brains (hey, there’s a dystopic sci-fi story idea in there somewhere!) the analogue hole will always be exploitable.">5</a></sup>:
              using a camera, microphone, etc. to make a copy of what comes out of the screen/speakers<sup><a id="footnote-ref-26049-6" name="footnote-ref-26049-6" href="#footnote-26049-6" title="One might argue that recreating a piece of art from memory, after the fact, is a very-specific and unusual exploitation of the analogue hole: the one that allows us to remember (or “download”) information to our brains rather than letting it “stream” right through. There’s evidence to suggest that people pirated Shakespeare’s plays this way!">6</a></sup>
              </li>
            </ul>
            <h2>
              Okay, so I oversimplified (before you say “well, actually…”)
            </h2>
            <p>
              It’s not entirely true to say that streaming and downloading are <em>identical</em>, even with the caveat of “…from the server’s perspective”. There are three big exceptions worth
              thinking about:
            </p>
            <h3>
              Exception #1: downloads can come in any order
            </h3>
            <p>
              When you stream some linear media, you <em>expect</em> the server to send the media in strict chronological order. Being able to start watching&nbsp;<em>before the whole file has
              downloaded</em> is a big part of what makes steaming appealing, to the end-user. This means that media <em>intended for streaming</em> tends to be stored in a way that facilitates that
              kind of delivery. For example:
            </p>
            <ul>
              <li>Media designed for streaming will often be stored in linear chronological order in the file, which impacts what kinds of compression are available.
              </li>
              <li>Media designed for streaming will generally use formats that put file metadata at the <em>start</em> of the file, so that it gets delivered first.
              </li>
              <li>Video designed for streaming will often have frequent keyframes so that a client that starts “in the middle” can decode the buffer without downloading too much data.
              </li>
            </ul>
            <p>
              No such limitation exists for files intended for downloading. If you’re not planning on watching a video until it’s completely downloaded, the order in which the chunks arrives is
              arbitrary!
            </p>
            <p>
              But these limitations make the set of “files suitable for streaming” a <em>subset</em> of the set of “files suitable for downloading”. It only makes it challenging or impossible to
              stream some media intended for downloading… it doesn’t do anything to prevent downloading of media intended for streaming.
            </p>
            <h3>
              Exception #2: streamed media is more-likely to be transcoded
            </h3>
            <p>
              A server that’s streaming media to a client exists in a sort-of dance: the client keeps the server updated on which “part” of the media it cares about, so the server can jump ahead,
              throttle back, pause sending, etc. and the client’s buffer can be kept filled to the optimal level.
            </p>
            <p>
              This dance also allows for a dynamic change in quality levels. You’ve probably seen this happen: you’re watching a video on YouTube and suddenly the quality “jumps” to something more
              (or less) like a pile of LEGO bricks<sup><a id="footnote-ref-26049-7" name="footnote-ref-26049-7" href="#footnote-26049-7" title="Of course, if you’re watching The LEGO Movie, what you’re seeing might already look like a pile of LEGO bricks.">7</a></sup>. That’s the result of your device realising that the rate
              at which it’s receiving data isn’t well-matched to the connection speed, and asking the server to send a different quality level<sup><a id="footnote-ref-26049-8" name="footnote-ref-26049-8" href="#footnote-26049-8" title="There are other ways in which the client and server may negotiate, too: for example, what encoding formats are supported by your device.">8</a></sup>.
            </p>
            <p>
              The server can – and some do! – pre-generate and store all of the different formats, but some servers will convert files (and particularly livestreams) <em>on-the-fly</em>, introducing
              a few seconds’ delay in order to deliver the format that’s best-suited to the recipient<sup><a id="footnote-ref-26049-9" name="footnote-ref-26049-9" href="#footnote-26049-9" title="My NAS does live transcoding when Jellyfin streams to devices on my network, and it’s magical!">9</a></sup>. That’s not necessary for downloads, where the
              user will often want the highest-quality version of the media (and if they don’t, they’ll select the quality they want at the outset, before the download begins).
            </p>
            <h3>
              Exception #3: streamed media is more-likely to be encumbered with DRM
            </h3>
            <p>
              And then, of course, there’s DRM.
            </p>
            <p>
              As streaming digital media has become the default way for many people to consume video and audio content, rights holders have engaged in a fundamentally-doomed<sup><a id="footnote-ref-26049-10" name="footnote-ref-26049-10" href="#footnote-26049-10" title="There’s always the analogue hole, remember! Although in practice this isn’t even remotely necessary and most video media gets ripped some-other-way by clever pirate types even where it uses highly-sophisticated DRM strategies, and then ultimately it’s only legitimate users who end up suffering as a result of DRM’s burden. It’s almost as if it’s just, y’know, simply a bad idea in the first place, or something. Who knew?">10</a></sup>
              arms race of implementing copy-protection strategies to attempt to <em>prevent</em> end-users from retaining usable downloaded copies of streamed media.
            </p>
            <p>
              Take HDCP, for example, which e.g. Netflix use for their 4K streams. To download these streams, your device has to be running some decryption code that only works if it can trace a path
              to the screen that it’ll be outputting to that <em>also</em> supports HDCP, and both your device and that screen promise that they’re definitely only going to show it and not make it
              possible to save the video. And then that promise is enforced by Digital Content Protection LLC only granting a decryption key and a license to use it to manufacturers.<sup><a id="footnote-ref-26049-11" name="footnote-ref-26049-11" href="#footnote-26049-11" title="Like all these technologies, HDCP was cracked almost immediately and every subsequent version that’s seen widespread rollout has similarly been broken by clever hacker types. Legitimate, paying users find themselves disadvantaged when their laptop won’t let them use their external monitor to watch a movie, while the bad guys make pirated copies that work fine on anything. I don’t think anybody wins, here.">11</a></sup>
            </p>
            <figure id="attachment_26072" aria-describedby="caption-attachment-26072">
              <a href="#lightbox-p-attachment_26072" title="Zoom in on image" aria-haspopup="dialog" role="button"><img decoding="async" loading="lazy" src="https://danq.me/_q23u/2025/03/20250316_213526-640x360.jpg" alt="Fingers hold a small box, about half the size of a deck of cards, labelled &quot;ezcoo 4K HDML 2.0 Splitter 1x2&quot;. On the side facing the camera can be seen a &quot;HDMI In&quot; port and an &quot;EDID&quot; switch that can be set to 4K7.1, 4K5.1, or COPY1." width="640" height="360" srcset="https://danq.me/_q23u/2025/03/20250316_213526-640x360.jpg 640w, https://danq.me/_q23u/2025/03/20250316_213526-1280x721.jpg 1280w, https://danq.me/_q23u/2025/03/20250316_213526-980x552.jpg 980w, https://danq.me/_q23u/2025/03/20250316_213526-1960x1104.jpg 1960w, https://danq.me/_q23u/2025/03/20250316_213526-477x269.jpg 477w" sizes="100vw"></a>
              <figcaption id="caption-attachment-26072">
                The real hackers do stuff with software, but people who just want their screens to work properly in spite of HDCP can just buy boxes like this (which I bought for a couple of quid on
                eBay). Obviously you could use something like this and a capture card to allow you to download content that was “protected” to ensure that you could only stream it, I suppose, too.
              </figcaption>
            </figure>
            <p>
              Anyway, the bottom line is that <strong>all streaming is, by definition, downloading</strong>, and the only significant difference between what people <em>call</em> “streaming” and
              “downloading” is that when “streaming” there’s an expectation that the recipient will delete, and not retain, a copy of the video. And that’s it.
            </p>
            
            <dialog id="lightbox-attachment_26051">
              <p id="lightbox-p-attachment_26051">
                <a href="https://danq.me/_q23u/2025/03/vimeo-download-settings-scr-annot.png"><img decoding="async" fetchpriority="high" src="https://danq.me/_q23u/2025/03/vimeo-download-settings-scr-annot.png" alt="Screenshot from Vimeo's settings, showing the 'What can people do with your videos?' section. The 'Download them' checkbox is highlighted and a question mark has been scrawled alongside it." width="640" height="277" sizes="100vw" loading="lazy"></a>
              </p><a href="#attachment_26051" title="Close image" role="button">×</a>
            </dialog>
            <dialog id="lightbox-attachment_26065">
              <p id="lightbox-p-attachment_26065">
                <a href="https://danq.me/_q23u/2025/03/firefox-netflix-negotiate-deletion-of-dispicable-me-4-scaled.jpg"><img decoding="async" src="https://danq.me/_q23u/2025/03/firefox-netflix-negotiate-deletion-of-dispicable-me-4-scaled.jpg" alt="Comic showing a conversation between Firefox and Netflix, as represented by their respective logos. Firefox says 'Hey, send me a copy of Dispicable Me 4?'. Netflix replies: 'Promise you'll delete it when you're done watching it?'. Firefox responds: 'Umm... sure!'" width="640" height="427" sizes="100vw" loading="lazy"></a>
              </p><a href="#attachment_26065" title="Close image" role="button">×</a>
            </dialog>
            <dialog id="lightbox-attachment_26072">
              <p id="lightbox-p-attachment_26072">
                <a href="https://danq.me/_q23u/2025/03/20250316_213526.jpg"><img decoding="async" loading="lazy" src="https://danq.me/_q23u/2025/03/20250316_213526.jpg" alt="Fingers hold a small box, about half the size of a deck of cards, labelled &quot;ezcoo 4K HDML 2.0 Splitter 1x2&quot;. On the side facing the camera can be seen a &quot;HDMI In&quot; port and an &quot;EDID&quot; switch that can be set to 4K7.1, 4K5.1, or COPY1." width="640" height="360" sizes="100vw"></a>
              </p><a href="#attachment_26072" title="Close image" role="button">×</a>
            </dialog>
            
          </div>
          
        </article>
        
      </div></div>]]></description>
        </item>
    </channel>
</rss>